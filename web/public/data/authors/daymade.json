{
  "author": {
    "id": "daymade",
    "display_name": "daymade",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/4291901?u=97bd8025b818b6e74ca25313ef2de8cdc3dd9325&v=4",
    "url": "https://github.com/daymade",
    "bio": "ËµÑÊ∑±ÂÄü‰π¶‰∏ìÂÆ∂",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 35,
      "total_commands": 0,
      "total_skills": 35,
      "total_stars": 516,
      "total_forks": 57
    }
  },
  "marketplaces": [
    {
      "name": "daymade-skills",
      "version": null,
      "description": "Professional Claude Code skills for GitHub operations, document conversion, diagram generation, statusline customization, Teams communication, repomix utilities, skill creation, CLI demo generation, LLM icon access, Cloudflare troubleshooting, UI design system extraction, professional presentation creation, YouTube video downloading, secure repomix packaging, ASR transcription correction, video comparison quality analysis, comprehensive QA testing infrastructure, prompt optimization with EARS methodology, session history recovery, documentation cleanup, format-controlled deep research report generation with evidence tracking, PDF generation with Chinese font support, CLAUDE.md progressive disclosure optimization, CCPM skill registry search and management, Promptfoo LLM evaluation framework, iOS app development with XcodeGen and SwiftUI, fact-checking with automated corrections, Twitter/X content fetching, intelligent macOS disk space recovery, skill quality review and improvement, GitHub contribution strategy, complete internationalization/localization setup, plugin/skill troubleshooting with diagnostic tools, and evidence-based competitor analysis with source citations",
      "owner_info": {
        "name": "daymade",
        "email": "daymadev89@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "daymade/claude-code-skills",
      "repo_url": "https://github.com/daymade/claude-code-skills",
      "repo_description": "Professional Claude Code skills marketplace featuring production-ready skills for enhanced development workflows.",
      "homepage": "",
      "signals": {
        "stars": 516,
        "forks": 57,
        "pushed_at": "2026-01-29T16:08:34Z",
        "created_at": "2025-10-22T11:17:31Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 26683
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 70231
        },
        {
          "path": "claude-code-history-files-finder",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-history-files-finder/SKILL.md",
          "type": "blob",
          "size": 5402
        },
        {
          "path": "claude-md-progressive-disclosurer",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-md-progressive-disclosurer/SKILL.md",
          "type": "blob",
          "size": 11123
        },
        {
          "path": "claude-skills-troubleshooting",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-skills-troubleshooting/SKILL.md",
          "type": "blob",
          "size": 4755
        },
        {
          "path": "cli-demo-generator",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-demo-generator/SKILL.md",
          "type": "blob",
          "size": 8897
        },
        {
          "path": "cloudflare-troubleshooting",
          "type": "tree",
          "size": null
        },
        {
          "path": "cloudflare-troubleshooting/SKILL.md",
          "type": "blob",
          "size": 9861
        },
        {
          "path": "competitors-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "competitors-analysis/SKILL.md",
          "type": "blob",
          "size": 7000
        },
        {
          "path": "deep-research",
          "type": "tree",
          "size": null
        },
        {
          "path": "deep-research/SKILL.md",
          "type": "blob",
          "size": 7351
        },
        {
          "path": "demos",
          "type": "tree",
          "size": null
        },
        {
          "path": "demos/README.md",
          "type": "blob",
          "size": 4664
        },
        {
          "path": "docs-cleaner",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs-cleaner/SKILL.md",
          "type": "blob",
          "size": 2952
        },
        {
          "path": "fact-checker",
          "type": "tree",
          "size": null
        },
        {
          "path": "fact-checker/README.md",
          "type": "blob",
          "size": 5374
        },
        {
          "path": "fact-checker/SKILL.md",
          "type": "blob",
          "size": 8229
        },
        {
          "path": "github-contributor",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-contributor/SKILL.md",
          "type": "blob",
          "size": 5354
        },
        {
          "path": "github-ops",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-ops/SKILL.md",
          "type": "blob",
          "size": 6338
        },
        {
          "path": "i18n-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "i18n-expert/SKILL.md",
          "type": "blob",
          "size": 5263
        },
        {
          "path": "iOS-APP-developer",
          "type": "tree",
          "size": null
        },
        {
          "path": "iOS-APP-developer/SKILL.md",
          "type": "blob",
          "size": 9462
        },
        {
          "path": "llm-icon-finder",
          "type": "tree",
          "size": null
        },
        {
          "path": "llm-icon-finder/SKILL.md",
          "type": "blob",
          "size": 3378
        },
        {
          "path": "macos-cleaner",
          "type": "tree",
          "size": null
        },
        {
          "path": "macos-cleaner/SKILL.md",
          "type": "blob",
          "size": 31914
        },
        {
          "path": "markdown-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "markdown-tools/SKILL.md",
          "type": "blob",
          "size": 5002
        },
        {
          "path": "meeting-minutes-taker",
          "type": "tree",
          "size": null
        },
        {
          "path": "meeting-minutes-taker/SKILL.md",
          "type": "blob",
          "size": 31450
        },
        {
          "path": "mermaid-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "mermaid-tools/SKILL.md",
          "type": "blob",
          "size": 5558
        },
        {
          "path": "pdf-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "pdf-creator/SKILL.md",
          "type": "blob",
          "size": 2008
        },
        {
          "path": "ppt-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "ppt-creator/SKILL.md",
          "type": "blob",
          "size": 11414
        },
        {
          "path": "prompt-optimizer",
          "type": "tree",
          "size": null
        },
        {
          "path": "prompt-optimizer/SKILL.md",
          "type": "blob",
          "size": 7941
        },
        {
          "path": "promptfoo-evaluation",
          "type": "tree",
          "size": null
        },
        {
          "path": "promptfoo-evaluation/SKILL.md",
          "type": "blob",
          "size": 9819
        },
        {
          "path": "qa-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "qa-expert/SKILL.md",
          "type": "blob",
          "size": 10569
        },
        {
          "path": "repomix-safe-mixer",
          "type": "tree",
          "size": null
        },
        {
          "path": "repomix-safe-mixer/SKILL.md",
          "type": "blob",
          "size": 7871
        },
        {
          "path": "repomix-unmixer",
          "type": "tree",
          "size": null
        },
        {
          "path": "repomix-unmixer/README.md",
          "type": "blob",
          "size": 4874
        },
        {
          "path": "repomix-unmixer/SKILL.md",
          "type": "blob",
          "size": 8267
        },
        {
          "path": "skill-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "skill-creator/SKILL.md",
          "type": "blob",
          "size": 23320
        },
        {
          "path": "skill-reviewer",
          "type": "tree",
          "size": null
        },
        {
          "path": "skill-reviewer/SKILL.md",
          "type": "blob",
          "size": 4837
        },
        {
          "path": "skills-search",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills-search/SKILL.md",
          "type": "blob",
          "size": 4181
        },
        {
          "path": "statusline-generator",
          "type": "tree",
          "size": null
        },
        {
          "path": "statusline-generator/SKILL.md",
          "type": "blob",
          "size": 6733
        },
        {
          "path": "teams-channel-post-writer",
          "type": "tree",
          "size": null
        },
        {
          "path": "teams-channel-post-writer/SKILL.md",
          "type": "blob",
          "size": 4752
        },
        {
          "path": "transcript-fixer",
          "type": "tree",
          "size": null
        },
        {
          "path": "transcript-fixer/SKILL.md",
          "type": "blob",
          "size": 6878
        },
        {
          "path": "twitter-reader",
          "type": "tree",
          "size": null
        },
        {
          "path": "twitter-reader/SKILL.md",
          "type": "blob",
          "size": 1750
        },
        {
          "path": "ui-designer",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui-designer/SKILL.md",
          "type": "blob",
          "size": 6923
        },
        {
          "path": "video-comparer",
          "type": "tree",
          "size": null
        },
        {
          "path": "video-comparer/README.md",
          "type": "blob",
          "size": 9873
        },
        {
          "path": "video-comparer/SKILL.md",
          "type": "blob",
          "size": 5422
        },
        {
          "path": "youtube-downloader",
          "type": "tree",
          "size": null
        },
        {
          "path": "youtube-downloader/SKILL.md",
          "type": "blob",
          "size": 18424
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"daymade-skills\",\n  \"owner\": {\n    \"name\": \"daymade\",\n    \"email\": \"daymadev89@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Professional Claude Code skills for GitHub operations, document conversion, diagram generation, statusline customization, Teams communication, repomix utilities, skill creation, CLI demo generation, LLM icon access, Cloudflare troubleshooting, UI design system extraction, professional presentation creation, YouTube video downloading, secure repomix packaging, ASR transcription correction, video comparison quality analysis, comprehensive QA testing infrastructure, prompt optimization with EARS methodology, session history recovery, documentation cleanup, format-controlled deep research report generation with evidence tracking, PDF generation with Chinese font support, CLAUDE.md progressive disclosure optimization, CCPM skill registry search and management, Promptfoo LLM evaluation framework, iOS app development with XcodeGen and SwiftUI, fact-checking with automated corrections, Twitter/X content fetching, intelligent macOS disk space recovery, skill quality review and improvement, GitHub contribution strategy, complete internationalization/localization setup, plugin/skill troubleshooting with diagnostic tools, and evidence-based competitor analysis with source citations\",\n    \"version\": \"1.30.0\",\n    \"homepage\": \"https://github.com/daymade/claude-code-skills\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"skill-creator\",\n      \"description\": \"Essential meta-skill for creating effective Claude Code skills with initialization scripts, validation, packaging, marketplace registration, and privacy best practices\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.4.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"skill-creation\",\n        \"claude-code\",\n        \"development\",\n        \"tooling\",\n        \"workflow\",\n        \"meta-skill\",\n        \"essential\"\n      ],\n      \"skills\": [\n        \"./skill-creator\"\n      ]\n    },\n    {\n      \"name\": \"github-ops\",\n      \"description\": \"Comprehensive GitHub operations using gh CLI and GitHub API for pull requests, issues, repositories, workflows, and API interactions\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"github\",\n        \"gh-cli\",\n        \"pull-request\",\n        \"issues\",\n        \"workflows\",\n        \"api\"\n      ],\n      \"skills\": [\n        \"./github-ops\"\n      ]\n    },\n    {\n      \"name\": \"markdown-tools\",\n      \"description\": \"Convert documents (PDFs, Word, PowerPoint) to high-quality markdown with multi-tool orchestration. Supports Quick Mode (fast, single tool) and Heavy Mode (best quality, multi-tool merge with segment-level selection). Features PyMuPDF4LLM for LLM-optimized PDF conversion, pandoc for DOCX/PPTX structure preservation, quality validation with HTML reports, and image extraction with metadata\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.2.0\",\n      \"category\": \"document-conversion\",\n      \"keywords\": [\n        \"markdown\",\n        \"pdf\",\n        \"docx\",\n        \"pptx\",\n        \"pymupdf4llm\",\n        \"pandoc\",\n        \"markitdown\",\n        \"heavy-mode\",\n        \"quality-validation\"\n      ],\n      \"skills\": [\n        \"./markdown-tools\"\n      ]\n    },\n    {\n      \"name\": \"mermaid-tools\",\n      \"description\": \"Generate Mermaid diagrams from markdown with automatic PNG/SVG rendering and extraction from documents\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"documentation\",\n      \"keywords\": [\n        \"mermaid\",\n        \"diagrams\",\n        \"visualization\",\n        \"flowchart\",\n        \"sequence\"\n      ],\n      \"skills\": [\n        \"./mermaid-tools\"\n      ]\n    },\n    {\n      \"name\": \"statusline-generator\",\n      \"description\": \"Configure Claude Code statuslines with multi-line layouts, cost tracking via ccusage, git status, and customizable colors\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"customization\",\n      \"keywords\": [\n        \"statusline\",\n        \"ccusage\",\n        \"git-status\",\n        \"customization\",\n        \"prompt\"\n      ],\n      \"skills\": [\n        \"./statusline-generator\"\n      ]\n    },\n    {\n      \"name\": \"teams-channel-post-writer\",\n      \"description\": \"Create professional Microsoft Teams channel posts with Adaptive Cards, formatted announcements, and corporate communication standards\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"communication\",\n      \"keywords\": [\n        \"teams\",\n        \"microsoft\",\n        \"adaptive-cards\",\n        \"communication\",\n        \"announcements\"\n      ],\n      \"skills\": [\n        \"./teams-channel-post-writer\"\n      ]\n    },\n    {\n      \"name\": \"repomix-unmixer\",\n      \"description\": \"Extract files from repomix packaged formats (XML, Markdown, JSON) with automatic format detection and validation\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"utilities\",\n      \"keywords\": [\n        \"repomix\",\n        \"unmix\",\n        \"extract\",\n        \"xml\",\n        \"conversion\"\n      ],\n      \"skills\": [\n        \"./repomix-unmixer\"\n      ]\n    },\n    {\n      \"name\": \"llm-icon-finder\",\n      \"description\": \"Find and access AI/LLM model brand icons from lobe-icons library in SVG/PNG/WEBP formats\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"assets\",\n      \"keywords\": [\n        \"icons\",\n        \"ai-models\",\n        \"llm\",\n        \"branding\",\n        \"lobe-icons\"\n      ],\n      \"skills\": [\n        \"./llm-icon-finder\"\n      ]\n    },\n    {\n      \"name\": \"cli-demo-generator\",\n      \"description\": \"Generate professional animated CLI demos and terminal recordings with VHS. Supports automated generation, batch processing, and interactive recording for documentation and tutorials\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"cli\",\n        \"demo\",\n        \"terminal\",\n        \"vhs\",\n        \"gif\",\n        \"recording\",\n        \"animation\",\n        \"documentation\"\n      ],\n      \"skills\": [\n        \"./cli-demo-generator\"\n      ]\n    },\n    {\n      \"name\": \"cloudflare-troubleshooting\",\n      \"description\": \"Investigate and resolve Cloudflare configuration issues using API-driven evidence gathering. Use when troubleshooting ERR_TOO_MANY_REDIRECTS, SSL errors, DNS issues, or any Cloudflare-related problems\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"cloudflare\",\n        \"troubleshooting\",\n        \"ssl\",\n        \"dns\",\n        \"api\",\n        \"debugging\",\n        \"devops\"\n      ],\n      \"skills\": [\n        \"./cloudflare-troubleshooting\"\n      ]\n    },\n    {\n      \"name\": \"ui-designer\",\n      \"description\": \"Extract design systems from reference UI images and generate implementation-ready UI design prompts. Use when users provide UI screenshots/mockups and want to create consistent designs\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"design\",\n      \"keywords\": [\n        \"ui\",\n        \"design-system\",\n        \"mockup\",\n        \"screenshot\",\n        \"design-extraction\",\n        \"mvp\"\n      ],\n      \"skills\": [\n        \"./ui-designer\"\n      ]\n    },\n    {\n      \"name\": \"ppt-creator\",\n      \"description\": \"Create professional slide decks from topics or documents. Generates structured content with data-driven charts, speaker notes, and complete PPTX files. Applies persuasive storytelling principles (Pyramid Principle, assertion-evidence). Supports multiple formats (Marp, PowerPoint). Use for presentations, pitches, slide decks, or keynotes\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"presentation\",\n        \"powerpoint\",\n        \"pptx\",\n        \"slides\",\n        \"marp\",\n        \"charts\",\n        \"data-visualization\",\n        \"pyramid-principle\"\n      ],\n      \"skills\": [\n        \"./ppt-creator\"\n      ]\n    },\n    {\n      \"name\": \"youtube-downloader\",\n      \"description\": \"Download YouTube videos and HLS streams (m3u8) from platforms like Mux, Vimeo, etc. using yt-dlp and ffmpeg. Use when users request downloading videos, extracting audio, handling protected streams with authentication headers, or troubleshooting download issues like nsig extraction failures, 403 errors, or cookie extraction problems\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.1.0\",\n      \"category\": \"utilities\",\n      \"keywords\": [\n        \"youtube\",\n        \"yt-dlp\",\n        \"video-download\",\n        \"audio-extraction\",\n        \"mp3\",\n        \"download\",\n        \"hls\",\n        \"m3u8\",\n        \"ffmpeg\",\n        \"streaming\",\n        \"mux\",\n        \"vimeo\"\n      ],\n      \"skills\": [\n        \"./youtube-downloader\"\n      ]\n    },\n    {\n      \"name\": \"repomix-safe-mixer\",\n      \"description\": \"Safely package codebases with repomix by automatically detecting and removing hardcoded credentials before packing. Use when packaging code for distribution, creating reference packages, or when the user mentions security concerns about sharing code with repomix\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"security\",\n      \"keywords\": [\n        \"repomix\",\n        \"security\",\n        \"credentials\",\n        \"secrets-scanning\",\n        \"safe-packaging\",\n        \"secret-detection\",\n        \"code-security\"\n      ],\n      \"skills\": [\n        \"./repomix-safe-mixer\"\n      ]\n    },\n    {\n      \"name\": \"transcript-fixer\",\n      \"description\": \"Corrects speech-to-text (ASR/STT) transcription errors in meeting notes, lecture recordings, interviews, and voice memos through dictionary-based rules and AI corrections. Supports Chinese domain names, AI fallback to Claude Code, and iterative dictionary building. Use when users mention transcript correction, ASR errors, speech-to-text mistakes, homophone errors, or working with transcription files\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.1.0\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"transcription\",\n        \"asr\",\n        \"stt\",\n        \"speech-to-text\",\n        \"correction\",\n        \"ai\",\n        \"meeting-notes\",\n        \"nlp\"\n      ],\n      \"skills\": [\n        \"./transcript-fixer\"\n      ]\n    },\n    {\n      \"name\": \"video-comparer\",\n      \"description\": \"Compare two videos and generate interactive HTML reports with quality metrics (PSNR, SSIM) and frame-by-frame visual comparisons. Use when analyzing compression results, evaluating codec performance, or assessing video quality differences\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"media\",\n      \"keywords\": [\n        \"video\",\n        \"comparison\",\n        \"quality-analysis\",\n        \"psnr\",\n        \"ssim\",\n        \"compression\",\n        \"ffmpeg\",\n        \"codec\"\n      ],\n      \"skills\": [\n        \"./video-comparer\"\n      ]\n    },\n    {\n      \"name\": \"qa-expert\",\n      \"description\": \"Comprehensive QA testing infrastructure with autonomous LLM execution, Google Testing Standards (AAA pattern), and OWASP security testing. Use when establishing QA processes, writing test cases, executing test plans, tracking bugs with P0-P4 classification, calculating quality metrics, enforcing quality gates, or preparing third-party QA handoffs. Enables 100x faster test execution via master prompts\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"qa\",\n        \"testing\",\n        \"test-cases\",\n        \"bug-tracking\",\n        \"google-standards\",\n        \"owasp\",\n        \"security\",\n        \"automation\",\n        \"quality-gates\",\n        \"metrics\"\n      ],\n      \"skills\": [\n        \"./qa-expert\"\n      ]\n    },\n    {\n      \"name\": \"prompt-optimizer\",\n      \"description\": \"Transform vague prompts into precise, well-structured specifications using EARS (Easy Approach to Requirements Syntax) methodology. Use when users provide loose requirements, ambiguous feature descriptions, need to enhance prompts for AI-generated code/products/documents, request prompt optimization, or want to improve requirements engineering. Applies domain theories (GTD, BJ Fogg, Gestalt, AIDA, Zero Trust) and structured Role/Skills/Workflows/Examples/Formats framework\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.1.0\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"prompt-engineering\",\n        \"ears\",\n        \"requirements\",\n        \"specifications\",\n        \"optimization\",\n        \"domain-theory\",\n        \"prompt-enhancement\",\n        \"ai-prompting\"\n      ],\n      \"skills\": [\n        \"./prompt-optimizer\"\n      ]\n    },\n    {\n      \"name\": \"claude-code-history-files-finder\",\n      \"description\": \"Find and recover content from Claude Code session history files. Use when searching for deleted files, tracking changes across sessions, analyzing conversation history, or recovering code/documents from previous Claude interactions. Triggers include mentions of session history, recover deleted, find in history, previous conversation, or .claude/projects\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"session-history\",\n        \"recovery\",\n        \"deleted-files\",\n        \"conversation-history\",\n        \"file-tracking\",\n        \"claude-code\",\n        \"history-analysis\"\n      ],\n      \"skills\": [\n        \"./claude-code-history-files-finder\"\n      ]\n    },\n    {\n      \"name\": \"docs-cleaner\",\n      \"description\": \"Consolidates redundant documentation while preserving all valuable content. Use when cleaning up documentation bloat, merging redundant docs, reducing documentation sprawl, or consolidating multiple files covering the same topic\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"documentation\",\n        \"cleanup\",\n        \"consolidation\",\n        \"redundancy\",\n        \"merge\",\n        \"docs\"\n      ],\n      \"skills\": [\n        \"./docs-cleaner\"\n      ]\n    },\n    {\n      \"name\": \"pdf-creator\",\n      \"description\": \"Create PDF documents from markdown with proper Chinese font support using weasyprint. Use when converting markdown to PDF, generating formal documents (legal filings, trademark applications, reports), or when Chinese typography is required. Triggers include convert to PDF, generate PDF, markdown to PDF, or printable documents\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"document-conversion\",\n      \"keywords\": [\n        \"pdf\",\n        \"markdown\",\n        \"weasyprint\",\n        \"chinese-fonts\",\n        \"document-generation\",\n        \"legal\",\n        \"reports\",\n        \"typography\"\n      ],\n      \"skills\": [\n        \"./pdf-creator\"\n      ]\n    },\n    {\n      \"name\": \"claude-md-progressive-disclosurer\",\n      \"description\": \"Optimize user CLAUDE.md files by applying progressive disclosure principles. This skill should be used when users want to reduce CLAUDE.md bloat, move detailed content to references, extract reusable patterns into skills, or improve context efficiency. Triggers include optimize CLAUDE.md, reduce CLAUDE.md size, apply progressive disclosure, or complaints about CLAUDE.md being too long\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.1\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"claude-md\",\n        \"progressive-disclosure\",\n        \"optimization\",\n        \"context-efficiency\",\n        \"configuration\",\n        \"token-savings\"\n      ],\n      \"skills\": [\n        \"./claude-md-progressive-disclosurer\"\n      ]\n    },\n    {\n      \"name\": \"skills-search\",\n      \"description\": \"Search, discover, install, and manage Claude Code skills from the CCPM registry. Use when users want to find skills for specific tasks, install skills by name, list installed skills, get skill details, or manage their Claude Code skill collection. Triggers include find skills, search for plugins, install skill, list installed skills, or any CCPM registry operations\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"ccpm\",\n        \"skills\",\n        \"search\",\n        \"install\",\n        \"registry\",\n        \"plugin\",\n        \"marketplace\",\n        \"discovery\",\n        \"skill-management\"\n      ],\n      \"skills\": [\n        \"./skills-search\"\n      ]\n    },\n    {\n      \"name\": \"promptfoo-evaluation\",\n      \"description\": \"Configures and runs LLM evaluation using Promptfoo framework. Use when setting up prompt testing, creating evaluation configs (promptfooconfig.yaml), writing Python custom assertions, implementing llm-rubric for LLM-as-judge, or managing few-shot examples in prompts. Triggers on keywords like promptfoo, eval, LLM evaluation, prompt testing, or model comparison\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"promptfoo\",\n        \"evaluation\",\n        \"llm-testing\",\n        \"prompt-testing\",\n        \"assertions\",\n        \"llm-rubric\",\n        \"few-shot\",\n        \"model-comparison\"\n      ],\n      \"skills\": [\n        \"./promptfoo-evaluation\"\n      ]\n    },\n    {\n      \"name\": \"iOS-APP-developer\",\n      \"description\": \"Develops iOS applications with XcodeGen, SwiftUI, and SPM. Use when configuring XcodeGen project.yml, resolving SPM dependency issues, deploying to devices, handling code signing, debugging camera/AVFoundation, iOS version compatibility issues, or fixing Library not loaded @rpath framework errors. Includes state machine testing patterns for @MainActor classes\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.1.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"ios\",\n        \"xcodegen\",\n        \"swiftui\",\n        \"spm\",\n        \"avfoundation\",\n        \"camera\",\n        \"code-signing\",\n        \"device-deployment\",\n        \"swift\",\n        \"xcode\",\n        \"testing\"\n      ],\n      \"skills\": [\n        \"./iOS-APP-developer\"\n      ]\n    },\n    {\n      \"name\": \"fact-checker\",\n      \"description\": \"Verifies factual claims in documents using web search and official sources, then proposes corrections with user confirmation. Use when the user asks to fact-check, verify information, validate claims, check accuracy, or update outdated information in documents. Supports AI model specs, technical documentation, statistics, and general factual statements\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"fact-checking\",\n        \"verification\",\n        \"accuracy\",\n        \"sources\",\n        \"validation\",\n        \"corrections\",\n        \"web-search\"\n      ],\n      \"skills\": [\n        \"./fact-checker\"\n      ]\n    },\n    {\n      \"name\": \"twitter-reader\",\n      \"description\": \"Fetch Twitter/X post content by URL using jina.ai API to bypass JavaScript restrictions. Use when Claude needs to retrieve tweet content including author, timestamp, post text, images, and thread replies. Supports individual posts or batch fetching from x.com or twitter.com URLs\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"utilities\",\n      \"keywords\": [\n        \"twitter\",\n        \"x\",\n        \"social-media\",\n        \"jina\",\n        \"content-fetching\",\n        \"api\",\n        \"scraping\",\n        \"threads\"\n      ],\n      \"skills\": [\n        \"./twitter-reader\"\n      ]\n    },\n    {\n      \"name\": \"macos-cleaner\",\n      \"description\": \"Intelligent macOS disk space analysis and cleanup with safety-first philosophy. Use when users report disk space issues, need to clean their Mac, or want to understand storage consumption. Analyzes system caches, application remnants, large files, and development environments (Docker, Homebrew, npm, pip) with risk categorization (Safe/Caution/Keep) and requires explicit user confirmation before any deletions. Includes Mole visual tool integration for hybrid workflow\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.1.0\",\n      \"category\": \"utilities\",\n      \"keywords\": [\n        \"macos\",\n        \"disk-space\",\n        \"cleanup\",\n        \"cache\",\n        \"storage\",\n        \"developer-tools\",\n        \"docker\",\n        \"homebrew\",\n        \"system-maintenance\",\n        \"safety\"\n      ],\n      \"skills\": [\n        \"./macos-cleaner\"\n      ]\n    },\n    {\n      \"name\": \"skill-reviewer\",\n      \"description\": \"Reviews and improves Claude Code skills against official best practices. Supports three modes - self-review (validate your own skills), external review (evaluate others' skills), and auto-PR (fork, improve, submit). Use when checking skill quality, reviewing skill repositories, or contributing improvements to open-source skills\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"skill-review\",\n        \"best-practices\",\n        \"claude-code\",\n        \"quality-assurance\",\n        \"open-source\",\n        \"contribution\",\n        \"auto-pr\"\n      ],\n      \"skills\": [\n        \"./skill-reviewer\"\n      ]\n    },\n    {\n      \"name\": \"github-contributor\",\n      \"description\": \"Strategic guide for becoming an effective GitHub contributor. Covers opportunity discovery, project selection, high-quality PR creation, and reputation building. Use when looking to contribute to open-source projects, building GitHub presence, or learning contribution best practices\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"github\",\n        \"open-source\",\n        \"contribution\",\n        \"pull-request\",\n        \"reputation\",\n        \"contributor\",\n        \"oss\"\n      ],\n      \"skills\": [\n        \"./github-contributor\"\n      ]\n    },\n    {\n      \"name\": \"i18n-expert\",\n      \"description\": \"Complete internationalization/localization setup and auditing for UI codebases. Configure i18n frameworks, replace hard-coded strings with translation keys, ensure locale parity between en-US and zh-CN, and validate pluralization and formatting. Use when setting up i18n for React/Next.js/Vue apps, auditing existing implementations, replacing hard-coded strings, ensuring proper error code mapping, or validating pluralization and date/time/number formatting across locales\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"developer-tools\",\n      \"keywords\": [\n        \"i18n\",\n        \"internationalization\",\n        \"localization\",\n        \"translation\",\n        \"react-i18next\",\n        \"next-intl\",\n        \"vue-i18n\",\n        \"locale\",\n        \"multilingual\",\n        \"globalization\"\n      ],\n      \"skills\": [\n        \"./i18n-expert\"\n      ]\n    },\n    {\n      \"name\": \"claude-skills-troubleshooting\",\n      \"description\": \"Diagnose and resolve Claude Code plugin and skill configuration issues. Debug plugin installation, enablement, and activation problems with systematic workflows. Use when plugins are installed but not showing in available skills list, skills are not activating as expected, troubleshooting enabledPlugins configuration in settings.json, debugging 'plugin not working' or 'skill not showing' issues, or understanding plugin state architecture and lifecycle\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"utilities\",\n      \"keywords\": [\n        \"troubleshooting\",\n        \"debugging\",\n        \"plugins\",\n        \"skills\",\n        \"diagnostics\",\n        \"configuration\",\n        \"enabledPlugins\",\n        \"settings\",\n        \"marketplace\"\n      ],\n      \"skills\": [\n        \"./claude-skills-troubleshooting\"\n      ]\n    },\n    {\n      \"name\": \"meeting-minutes-taker\",\n      \"description\": \"Transform meeting transcripts into high-fidelity, structured meeting minutes with iterative review. Features speaker identification via feature analysis (word count, speaking style, topic focus) with context.md team directory mapping, intelligent file naming from content, integration with markdown-tools and transcript-fixer for pre-processing, evidence-based recording with speaker quotes, Mermaid diagrams for architecture discussions, and multi-turn parallel generation with UNION merge\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.1.0\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"meeting\",\n        \"minutes\",\n        \"transcript\",\n        \"notes\",\n        \"speaker-identification\",\n        \"mermaid\",\n        \"quotes\",\n        \"action-items\"\n      ],\n      \"skills\": [\n        \"./meeting-minutes-taker\"\n      ]\n    },\n    {\n      \"name\": \"deep-research\",\n      \"description\": \"Generate format-controlled research reports with evidence tracking, citations, and iterative review. Use when users request research reports, literature reviews, market or industry analysis, competitive landscapes, policy or technical briefs, or strict report templates and section formatting\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"documentation\",\n      \"keywords\": [\n        \"research\",\n        \"report\",\n        \"analysis\",\n        \"literature-review\",\n        \"market-research\",\n        \"citations\",\n        \"evidence\",\n        \"deepresearch\"\n      ],\n      \"skills\": [\n        \"./deep-research\"\n      ]\n    },\n    {\n      \"name\": \"competitors-analysis\",\n      \"description\": \"Analyze competitor repositories with evidence-based approach. Use when tracking competitors, creating competitor profiles, or generating competitive analysis. All analysis must be based on actual cloned code, never assumptions. Triggers include analyze competitor, add competitor, competitive analysis, or Á´ûÂìÅÂàÜÊûê\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"version\": \"1.0.0\",\n      \"category\": \"productivity\",\n      \"keywords\": [\n        \"competitors\",\n        \"competitive-analysis\",\n        \"competitor-tracking\",\n        \"evidence-based\",\n        \"market-research\",\n        \"Á´ûÂìÅÂàÜÊûê\",\n        \"code-analysis\"\n      ],\n      \"skills\": [\n        \"./competitors-analysis\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# Claude Code Skills Marketplace\n\n<div align=\"center\">\n\n[![English](https://img.shields.io/badge/Language-English-blue)](./README.md)\n[![ÁÆÄ‰Ωì‰∏≠Êñá](https://img.shields.io/badge/ËØ≠Ë®Ä-ÁÆÄ‰Ωì‰∏≠Êñá-red)](./README.zh-CN.md)\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Skills](https://img.shields.io/badge/skills-35-blue.svg)](https://github.com/daymade/claude-code-skills)\n[![Version](https://img.shields.io/badge/version-1.30.0-green.svg)](https://github.com/daymade/claude-code-skills)\n[![Claude Code](https://img.shields.io/badge/Claude%20Code-2.0.13+-purple.svg)](https://claude.com/code)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](./CONTRIBUTING.md)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/daymade/claude-code-skills/graphs/commit-activity)\n\n</div>\n\nProfessional Claude Code skills marketplace featuring 35 production-ready skills for enhanced development workflows.\n\n## üìë Table of Contents\n\n- [üåü Essential Skill: skill-creator](#-essential-skill-skill-creator)\n- [üöÄ Quick Installation](#-quick-installation)\n- [üá®üá≥ Chinese User Guide](#-chinese-user-guide)\n- [üì¶ Other Available Skills](#-other-available-skills)\n- [üé¨ Interactive Demo Gallery](#-interactive-demo-gallery)\n- [üéØ Use Cases](#-use-cases)\n- [üìö Documentation](#-documentation)\n- [üõ†Ô∏è Requirements](#Ô∏è-requirements)\n- [‚ùì FAQ](#-faq)\n- [ü§ù Contributing](#-contributing)\n- [üìÑ License](#-license)\n\n---\n\n## üåü Essential Skill: skill-creator\n\n**‚≠ê Start here if you want to create your own skills!**\n\nThe `skill-creator` is the **meta-skill** that enables you to build, validate, and package your own Claude Code skills. It's the most important tool in this marketplace because it empowers you to extend Claude Code with your own specialized workflows.\n\n### Why skill-creator First?\n\n- **üéØ Foundation**: Learn how skills work by creating your own\n- **üõ†Ô∏è Complete Toolkit**: Initialization, validation, and packaging scripts included\n- **üìñ Best Practices**: Learn from production-ready examples\n- **üöÄ Quick Start**: Generate skill templates in seconds\n- **‚úÖ Quality Assurance**: Built-in validation ensures your skills meet standards\n\n### Quick Install\n\n**In Claude Code (in-app):**\n```text\n/plugin marketplace add daymade/claude-code-skills\n```\n\nThen:\n1. Select **Browse and install plugins**\n2. Select **daymade/claude-code-skills**\n3. Select **skill-creator**\n4. Select **Install now**\n\n**From your terminal (CLI):**\n```bash\nclaude plugin marketplace add https://github.com/daymade/claude-code-skills\n# Marketplace name: daymade-skills (from marketplace.json)\nclaude plugin install skill-creator@daymade-skills\n```\n\n### What You Can Do\n\nAfter installing skill-creator, simply ask Claude Code:\n\n```\n\"Create a new skill called my-awesome-skill in ~/my-skills\"\n\n\"Validate my skill at ~/my-skills/my-awesome-skill\"\n\n\"Package my skill at ~/my-skills/my-awesome-skill for distribution\"\n```\n\nClaude Code, with skill-creator loaded, will guide you through the entire skill creation process - from understanding your requirements to packaging the final skill.\n\nüìö **Full documentation**: [skill-creator/SKILL.md](./skill-creator/SKILL.md)\n\n### Live Demos\n\n**üìù Initialize New Skill**\n\n![Initialize Skill Demo](./demos/skill-creator/init-skill.gif)\n\n**‚úÖ Validate Skill Structure**\n\n![Validate Skill Demo](./demos/skill-creator/validate-skill.gif)\n\n**üì¶ Package Skill for Distribution**\n\n![Package Skill Demo](./demos/skill-creator/package-skill.gif)\n\n---\n\n## üöÄ Quick Installation\n\n### Install Inside Claude Code (In-App)\n\n```text\n/plugin marketplace add daymade/claude-code-skills\n```\n\nThen:\n1. Select **Browse and install plugins**\n2. Select **daymade/claude-code-skills**\n3. Select the plugin you want\n4. Select **Install now**\n\n### Automated Installation (Recommended)\n\n**macOS/Linux:**\n```bash\ncurl -fsSL https://raw.githubusercontent.com/daymade/claude-code-skills/main/scripts/install.sh | bash\n```\n\n**Windows (PowerShell):**\n```powershell\niwr -useb https://raw.githubusercontent.com/daymade/claude-code-skills/main/scripts/install.ps1 | iex\n```\n\n### Manual Installation\n\nAdd the marketplace:\n```bash\nclaude plugin marketplace add https://github.com/daymade/claude-code-skills\n```\n\nMarketplace name is `daymade-skills` (from marketplace.json). Use `@daymade-skills` when installing plugins.\nDo not use the repo path as a marketplace name (e.g. `@daymade/claude-code-skills` will fail).\nIn Claude Code, use `/plugin ...` slash commands. In your terminal, use `claude plugin ...`.\n\n**Essential Skill** (recommended first install):\n```bash\nclaude plugin install skill-creator@daymade-skills\n```\n\n**Install Other Skills:**\n```bash\n# GitHub operations\nclaude plugin install github-ops@daymade-skills\n\n# Document conversion\nclaude plugin install markdown-tools@daymade-skills\n\n# Diagram generation\nclaude plugin install mermaid-tools@daymade-skills\n\n# Statusline customization\nclaude plugin install statusline-generator@daymade-skills\n\n# Teams communication\nclaude plugin install teams-channel-post-writer@daymade-skills\n\n# Repomix extraction\nclaude plugin install repomix-unmixer@daymade-skills\n\n# AI/LLM icons\nclaude plugin install llm-icon-finder@daymade-skills\n\n# CLI demo generation\nclaude plugin install cli-demo-generator@daymade-skills\n\n# Cloudflare diagnostics\nclaude plugin install cloudflare-troubleshooting@daymade-skills\n\n# UI design system extraction\nclaude plugin install ui-designer@daymade-skills\n\n# Presentation creation\nclaude plugin install ppt-creator@daymade-skills\n\n# YouTube video/audio downloading\nclaude plugin install youtube-downloader@daymade-skills\n\n# Secure repomix packaging\nclaude plugin install repomix-safe-mixer@daymade-skills\n\n# ASR transcript correction\nclaude plugin install transcript-fixer@daymade-skills\n\n# Video comparison and quality analysis\nclaude plugin install video-comparer@daymade-skills\n\n# QA testing infrastructure with autonomous execution\nclaude plugin install qa-expert@daymade-skills\n\n# Prompt optimization using EARS methodology\nclaude plugin install prompt-optimizer@daymade-skills\n\n# Session history recovery\nclaude plugin install claude-code-history-files-finder@daymade-skills\n\n# Documentation consolidation\nclaude plugin install docs-cleaner@daymade-skills\n\n# PDF generation with Chinese font support\nclaude plugin install pdf-creator@daymade-skills\n\n# CLAUDE.md progressive disclosure optimization\nclaude plugin install claude-md-progressive-disclosurer@daymade-skills\n\n# CCPM skill registry search and management\nclaude plugin install skills-search@daymade-skills\n\n# Promptfoo LLM evaluation framework\nclaude plugin install promptfoo-evaluation@daymade-skills\n\n# iOS app development\nclaude plugin install iOS-APP-developer@daymade-skills\n\n# Twitter/X content fetching\nclaude plugin install twitter-reader@daymade-skills\n\n# Skill quality review and improvement\nclaude plugin install skill-reviewer@daymade-skills\n\n# GitHub contribution strategy\nclaude plugin install github-contributor@daymade-skills\n```\n\nEach skill can be installed independently - choose only what you need!\n\n---\n\n## üá®üá≥ Chinese User Guide\n\n**For Chinese users:** We highly recommend using [CC-Switch](https://github.com/farion1231/cc-switch) to manage Claude Code API provider configurations.\n\nCC-Switch enables you to:\n- ‚úÖ Quickly switch between different API providers (DeepSeek, Qwen, GLM, etc.)\n- ‚úÖ Test endpoint response times to find the fastest provider\n- ‚úÖ Manage MCP server configurations\n- ‚úÖ Auto-backup and import/export settings\n- ‚úÖ Cross-platform support (Windows, macOS, Linux)\n\n**Setup:** Download from [Releases](https://github.com/farion1231/cc-switch/releases), install, add your API configs, and switch via UI or system tray.\n\n### Complete Chinese Documentation\n\nFor full documentation in Chinese, see [README.zh-CN.md](./README.zh-CN.md).\n\n---\n\n## üì¶ Other Available Skills\n\n### 1. **github-ops** - GitHub Operations Suite\n\nComprehensive GitHub operations using gh CLI and GitHub API.\n\n**When to use:**\n- Creating, viewing, or managing pull requests\n- Managing issues and repository settings\n- Querying GitHub API endpoints\n- Working with GitHub Actions workflows\n- Automating GitHub operations\n\n**Key features:**\n- PR creation with JIRA integration\n- Issue management workflows\n- GitHub API (REST & GraphQL) operations\n- Workflow automation\n- Enterprise GitHub support\n\n**üé¨ Live Demo**\n\n![GitHub Ops Demo](./demos/github-ops/create-pr.gif)\n\n---\n\n### 2. **markdown-tools** - Document Conversion Suite\n\nConverts documents to markdown with Windows/WSL path handling and PDF image extraction.\n\n**When to use:**\n- Converting .doc/.docx/PDF/PPTX to markdown\n- Extracting images from PDF files\n- Processing Confluence exports\n- Handling Windows/WSL path conversions\n\n**Key features:**\n- Multi-format document conversion\n- PDF image extraction using PyMuPDF\n- Windows/WSL path automation\n- Confluence export processing\n- Helper scripts for path conversion and image extraction\n\n**üé¨ Live Demo**\n\n![Markdown Tools Demo](./demos/markdown-tools/convert-docs.gif)\n\n---\n\n### 3. **mermaid-tools** - Diagram Generation\n\nExtracts Mermaid diagrams from markdown and generates high-quality PNG images.\n\n**When to use:**\n- Converting Mermaid diagrams to PNG\n- Extracting diagrams from markdown files\n- Processing documentation with embedded diagrams\n- Creating presentation-ready visuals\n\n**Key features:**\n- Automatic diagram extraction\n- High-resolution PNG generation\n- Smart sizing based on diagram type\n- Customizable dimensions and scaling\n- WSL2 Chrome/Puppeteer support\n\n**üé¨ Live Demo**\n\n![Mermaid Tools Demo](./demos/mermaid-tools/extract-diagrams.gif)\n\n---\n\n### 4. **statusline-generator** - Statusline Customization\n\nConfigures Claude Code statuslines with multi-line layouts and cost tracking.\n\n**When to use:**\n- Customizing Claude Code statusline\n- Adding cost tracking (session/daily)\n- Displaying git status\n- Multi-line layouts for narrow screens\n- Color customization\n\n**Key features:**\n- Multi-line statusline layouts\n- ccusage cost integration\n- Git branch status indicators\n- Customizable colors\n- Portrait screen optimization\n\n**üé¨ Live Demo**\n\n![Statusline Generator Demo](./demos/statusline-generator/customize-statusline.gif)\n\n---\n\n### 5. **teams-channel-post-writer** - Teams Communication\n\nCreates educational Teams channel posts for internal knowledge sharing.\n\n**When to use:**\n- Writing Teams posts about features\n- Sharing Claude Code best practices\n- Documenting lessons learned\n- Creating internal announcements\n- Teaching effective prompting patterns\n\n**Key features:**\n- Post templates with proven structure\n- Writing guidelines for quality content\n- \"Normal vs Better\" example patterns\n- Emphasis on underlying principles\n- Ready-to-use markdown templates\n\n**üé¨ Live Demo**\n\n![Teams Channel Post Writer Demo](./demos/teams-channel-post-writer/write-post.gif)\n\n---\n\n### 6. **repomix-unmixer** - Repository Extraction\n\nExtracts files from repomix-packed repositories and restores directory structures.\n\n**When to use:**\n- Unmixing repomix output files\n- Extracting packed repositories\n- Restoring file structures\n- Reviewing repomix content\n- Converting repomix to usable files\n\n**Key features:**\n- Multi-format support (XML, Markdown, JSON)\n- Auto-format detection\n- Directory structure preservation\n- UTF-8 encoding support\n- Comprehensive validation workflows\n\n**üé¨ Live Demo**\n\n![Repomix Unmixer Demo](./demos/repomix-unmixer/extract-repo.gif)\n\n---\n\n### 7. **llm-icon-finder** - AI/LLM Brand Icon Finder\n\nAccess 100+ AI model and LLM provider brand icons from lobe-icons library.\n\n**When to use:**\n- Finding brand icons for AI models/providers\n- Downloading logos for Claude, GPT, Gemini, etc.\n- Getting icons in multiple formats (SVG/PNG/WEBP)\n- Building AI tool documentation\n- Creating presentations about LLMs\n\n**Key features:**\n- 100+ AI/LLM model icons\n- Multiple format support (SVG, PNG, WEBP)\n- URL generation for direct access\n- Local download capabilities\n- Searchable icon catalog\n\n**üé¨ Live Demo**\n\n![LLM Icon Finder Demo](./demos/llm-icon-finder/find-icons.gif)\n\n---\n\n### 8. **cli-demo-generator** - CLI Demo Generation\n\nGenerate professional animated CLI demos and terminal recordings with VHS automation.\n\n**When to use:**\n- Creating demos for documentation\n- Recording terminal workflows as GIFs\n- Generating animated tutorials\n- Batch-generating multiple demos\n- Showcasing CLI tools\n\n**Key features:**\n- Automated demo generation from command lists\n- Batch processing with YAML/JSON configs\n- Interactive recording with asciinema\n- Smart timing based on command complexity\n- Multiple output formats (GIF, MP4, WebM)\n- VHS tape file templates\n\n**üé¨ Live Demo**\n\n![CLI Demo Generator Demo](./demos/cli-demo-generator/generate-demo.gif)\n\n---\n\n### 9. **cloudflare-troubleshooting** - Cloudflare Diagnostics\n\nInvestigate and resolve Cloudflare configuration issues using API-driven evidence gathering.\n\n**When to use:**\n- Site shows ERR_TOO_MANY_REDIRECTS\n- SSL/TLS configuration errors\n- DNS resolution problems\n- Cloudflare-related issues\n\n**Key features:**\n- Evidence-based investigation methodology\n- Comprehensive Cloudflare API reference\n- SSL/TLS mode troubleshooting (Flexible, Full, Strict)\n- DNS, cache, and firewall diagnostics\n- Agentic approach with optional helper scripts\n\n**üé¨ Live Demo**\n\n![Cloudflare Troubleshooting Demo](./demos/cloudflare-troubleshooting/diagnose-redirect-loop.gif)\n\n---\n\n### 10. **ui-designer** - UI Design System Extractor\n\nExtract design systems from reference UI images and generate implementation-ready design prompts.\n\n**When to use:**\n- Have UI screenshots/mockups to analyze\n- Need to extract color palettes, typography, spacing\n- Building MVP UI matching reference aesthetics\n- Creating consistent design systems\n- Generating multiple UI variations\n\n**Key features:**\n- Systematic design system extraction from images\n- Color palette, typography, component analysis\n- Interactive MVP PRD generation\n- Template-driven workflow (design system ‚Üí PRD ‚Üí implementation prompt)\n- Multi-variation UI generation (3 mobile, 2 web)\n- React + Tailwind CSS + Lucide icons\n\n**üé¨ Live Demo**\n\n![UI Designer Demo](./demos/ui-designer/extract-design-system.gif)\n\n---\n\n### 11. **ppt-creator** - Professional Presentation Creation\n\nCreate persuasive, audience-ready slide decks from topics or documents with data-driven charts and dual-format PPTX output.\n\n**When to use:**\n- Creating presentations, pitch decks, or keynotes\n- Need structured content with professional storytelling\n- Require data visualization and charts\n- Want complete PPTX files with speaker notes\n- Building business reviews or product pitches\n\n**Key features:**\n- Pyramid Principle structure (conclusion ‚Üí reasons ‚Üí evidence)\n- Assertion-evidence slide framework\n- Automatic data synthesis and chart generation (matplotlib)\n- Dual-path PPTX creation (Marp CLI + document-skills:pptx)\n- Complete orchestration: content ‚Üí data ‚Üí charts ‚Üí PPTX with charts\n- 45-60 second speaker notes per slide\n- Quality scoring with auto-refinement (target: 75/100)\n\n**üé¨ Live Demo**\n\n![PPT Creator Demo](./demos/ppt-creator/create-presentation.gif)\n\n---\n\n### 12. **youtube-downloader** - YouTube Video & Audio Downloader\n\nDownload YouTube videos and audio using yt-dlp with robust error handling and automatic workarounds for common issues.\n\n**When to use:**\n- Downloading YouTube videos or playlists\n- Extracting audio from YouTube videos as MP3\n- Experiencing yt-dlp download failures or nsig extraction errors\n- Need help with format selection or quality options\n- Working with YouTube content in regions with access restrictions\n\n**Key features:**\n- Auto PO Token provider (Docker-first, browser fallback) for high-quality access\n- Browser-cookie verification for ‚Äúnot a bot‚Äù prompts (privacy-friendly)\n- Audio-only download with MP3 conversion\n- Format listing and custom format selection\n- Output directory customization\n- Proxy-aware downloads for restricted environments\n\n**üé¨ Live Demo**\n\n![YouTube Downloader Demo](./demos/youtube-downloader/download-video.gif)\n\n---\n\n### 13. **repomix-safe-mixer** - Secure Repomix Packaging\n\nSafely package codebases with repomix by automatically detecting and removing hardcoded credentials before packing.\n\n**When to use:**\n- Packaging code with repomix for distribution or sharing\n- Creating reference packages from proprietary codebases\n- Security concerns about accidentally exposing credentials\n- Pre-commit security checks for hardcoded secrets\n- Auditing codebases for credential exposure\n\n**Key features:**\n- Detects 20+ credential patterns (AWS, Supabase, Stripe, OpenAI, etc.)\n- Scan ‚Üí Report ‚Üí Pack workflow with automatic blocking\n- Standalone security scanner for pre-commit hooks\n- Environment variable replacement guidance\n- JSON output for CI/CD integration\n- Exclude patterns for false positive handling\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\n---\n\n### 14. **transcript-fixer** - ASR Transcription Correction\n\nCorrect speech-to-text (ASR/STT) transcription errors through dictionary-based rules and AI-powered corrections with automatic pattern learning.\n\n**When to use:**\n- Correcting meeting notes, lecture recordings, or interview transcripts\n- Fixing Chinese/English homophone errors and technical terminology\n- Building domain-specific correction dictionaries\n- Improving transcript accuracy through iterative learning\n- Collaborating with teams on shared correction knowledge bases\n\n**Key features:**\n- Two-stage correction pipeline (dictionary + AI)\n- Automatic pattern detection and learning\n- Domain-specific dictionaries (general, embodied_ai, finance, medical)\n- SQLite-based correction repository\n- Team collaboration with import/export\n- GLM API integration for AI corrections\n- Cost optimization through dictionary promotion\n\n**Example workflow:**\n```bash\n# Initialize and add corrections\nuv run scripts/fix_transcription.py --init\nuv run scripts/fix_transcription.py --add \"ÈîôËØØËØç\" \"Ê≠£Á°ÆËØç\" --domain general\n\n# Run full correction pipeline\nuv run scripts/fix_transcription.py --input meeting.md --stage 3\n\n# Review and approve learned patterns\nuv run scripts/fix_transcription.py --review-learned\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [transcript-fixer/references/](./transcript-fixer/references/) for workflow guides, SQL queries, troubleshooting, best practices, team collaboration, and API setup.\n\n**Requirements**: Python 3.6+, uv package manager, GLM API key (get from https://open.bigmodel.cn/)\n\n---\n\n### 15. **video-comparer** - Video Comparison and Quality Analysis\n\nCompare two videos and generate interactive HTML reports with quality metrics and frame-by-frame visual comparisons.\n\n**When to use:**\n- Comparing original and compressed videos\n- Analyzing video compression quality and efficiency\n- Evaluating codec performance or bitrate reduction impact\n- Assessing before/after compression results\n- Quality analysis for video encoding workflows\n\n**Key features:**\n- Quality metrics calculation (PSNR, SSIM)\n- Frame-by-frame visual comparison with three viewing modes:\n  - Slider mode: Drag to reveal differences\n  - Side-by-side mode: Simultaneous display\n  - Grid mode: Compact 2-column layout\n- Video metadata extraction (codec, resolution, bitrate, duration, file size)\n- Self-contained HTML reports (no server required, works offline)\n- Security features (path validation, resource limits, timeout controls)\n- Multi-platform FFmpeg support (macOS, Linux, Windows)\n\n**Example usage:**\n```bash\n# Basic comparison\npython3 scripts/compare.py original.mp4 compressed.mp4\n\n# Custom output and frame interval\npython3 scripts/compare.py original.mp4 compressed.mp4 -o report.html --interval 10\n\n# Batch processing\nfor original in originals/*.mp4; do\n    compressed=\"compressed/$(basename \"$original\")\"\n    output=\"reports/$(basename \"$original\" .mp4).html\"\n    python3 scripts/compare.py \"$original\" \"$compressed\" -o \"$output\"\ndone\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [video-comparer/references/](./video-comparer/references/) for quality metrics interpretation, FFmpeg commands, and configuration options.\n\n**Requirements**: Python 3.8+, FFmpeg/FFprobe (install via `brew install ffmpeg`, `apt install ffmpeg`, or `winget install ffmpeg`)\n\n---\n\n### 16. **qa-expert** - Comprehensive QA Testing Infrastructure\n\nEstablish world-class QA testing processes with autonomous LLM execution, Google Testing Standards, and OWASP security best practices.\n\n**When to use:**\n- Setting up QA infrastructure for new or existing projects\n- Writing standardized test cases following Google Testing Standards (AAA pattern)\n- Implementing security testing (OWASP Top 10 coverage)\n- Executing comprehensive test plans with automatic progress tracking\n- Filing bugs with proper P0-P4 severity classification\n- Calculating quality metrics and enforcing quality gates\n- Enabling autonomous LLM-driven test execution (100x speedup)\n- Preparing QA documentation for third-party team handoffs\n\n**Key features:**\n- **One-command initialization**: Complete QA infrastructure with templates, CSVs, and documentation\n- **Autonomous execution**: Master prompt enables LLM to auto-execute all tests, auto-track results, auto-file bugs\n- **Google Testing Standards**: AAA pattern compliance, 90% coverage targets, fail-fast validation\n- **OWASP security testing**: 90% Top 10 coverage with specific attack vectors\n- **Quality gates enforcement**: 100% execution, ‚â•80% pass rate, 0 P0 bugs, ‚â•80% code coverage\n- **Ground Truth Principle**: Prevents doc/CSV sync issues (test docs = authoritative source)\n- **Bug tracking**: P0-P4 classification with detailed repro steps and environment info\n- **Day 1 onboarding**: 5-hour guide for new QA engineers\n- **30+ LLM prompts**: Ready-to-use prompts for specific QA tasks\n- **Metrics dashboard**: Test execution progress, pass rate, bug analysis, quality gates status\n\n**Example usage:**\n```bash\n# Initialize QA project (creates full infrastructure)\npython3 scripts/init_qa_project.py my-app ./\n\n# Calculate quality metrics and gates status\npython3 scripts/calculate_metrics.py tests/TEST-EXECUTION-TRACKING.csv\n\n# For autonomous execution, copy master prompt from:\n# references/master_qa_prompt.md ‚Üí paste to LLM ‚Üí auto-executes 342 tests over 5 weeks\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [qa-expert/references/](./qa-expert/references/) for:\n- `master_qa_prompt.md` - Single command for autonomous execution (100x speedup)\n- `google_testing_standards.md` - AAA pattern, coverage thresholds, OWASP testing\n- `day1_onboarding.md` - 5-hour onboarding timeline for new QA engineers\n- `ground_truth_principle.md` - Preventing doc/CSV sync issues\n- `llm_prompts_library.md` - 30+ ready-to-use QA prompts\n\n**Requirements**: Python 3.8+\n\n**üí° Innovation**: The autonomous execution capability (via master prompt) enables LLM to execute entire test suites 100x faster than manual execution, with zero human error in tracking. Perfect for third-party QA handoffs - just provide the master prompt and they can start testing immediately.\n\n---\n\n### 17. **prompt-optimizer** - Prompt Engineering with EARS Methodology\n\nTransform vague prompts into precise, well-structured specifications using EARS (Easy Approach to Requirements Syntax) - a methodology created by Rolls-Royce for converting natural language into testable requirements.\n\n**Methodology inspired by:** [ÈòøÊòüAIÂ∑•‰ΩúÂÆ§ (A-Xing AI Studio)](https://mp.weixin.qq.com/s/yUVX-9FovSq7ZGChkHpuXQ), which pioneered combining EARS with domain theory grounding for practical prompt enhancement.\n\n**When to use:**\n- Converting loose requirements into structured specifications\n- Optimizing prompts for AI code generation or content creation\n- Breaking down vague feature requests into atomic, testable statements\n- Adding domain theory grounding to technical requirements\n- Transforming \"build X\" requests into detailed implementation specs\n- Learning prompt engineering best practices with proven frameworks\n\n**Key features:**\n- **EARS transformation**: 5 sentence patterns (ubiquitous, event-driven, state-driven, conditional, unwanted behavior)\n- **6-step optimization workflow**: Analyze ‚Üí Transform ‚Üí Identify theories ‚Üí Extract examples ‚Üí Enhance ‚Üí Present\n- **Domain theory catalog**: 40+ frameworks mapped to 10 domains (productivity, UX, gamification, learning, e-commerce, security)\n- **Structured prompt framework**: Role/Skills/Workflows/Examples/Formats template\n- **Advanced techniques**: Multi-stakeholder requirements, non-functional specs, complex conditional logic\n- **Complete examples**: Procrastination app, e-commerce product page, learning dashboard, password reset\n- **Theory grounding**: GTD, BJ Fogg Behavior Model, Gestalt Principles, AIDA, Zero Trust, and more\n- **Progressive disclosure**: Bundled references (ears_syntax.md, domain_theories.md, examples.md)\n\n**Example usage:**\n```markdown\n# Before (vague)\n\"Build me a password reset feature\"\n\n# After EARS transformation (7 atomic requirements)\n1. When user clicks \"Forgot Password\", the system shall display email input field\n2. When user submits valid email, the system shall send password reset link valid for 1 hour\n3. When user clicks reset link, the system shall verify token has not expired\n4. When token is valid, the system shall display password creation form requiring minimum 12 characters, 1 uppercase, 1 number, 1 special character\n5. When user submits new password meeting requirements, the system shall hash password with bcrypt and invalidate reset token\n6. When user attempts password reset more than 3 times in 1 hour, the system shall block further attempts for 1 hour\n7. If reset token has expired, the system shall display error message and option to request new link\n\n# Enhanced with domain theories\n- Zero Trust Architecture (verify at each step)\n- Defense in Depth (rate limiting + token expiration + password complexity)\n- Progressive Disclosure (multi-step UX flow)\n\n# Full prompt includes Role, Skills, Workflows, Examples, Formats\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [prompt-optimizer/references/](./prompt-optimizer/references/) for:\n- `ears_syntax.md` - Complete EARS patterns and transformation rules\n- `domain_theories.md` - 40+ theories mapped to domains with selection guidance\n- `examples.md` - Full transformation examples with before/after comparisons\n\n**üí° Innovation**: EARS methodology eliminates ambiguity by forcing explicit conditions, triggers, and measurable criteria. Combined with domain theory grounding (GTD, BJ Fogg, Gestalt, etc.), it transforms \"build a todo app\" into a complete specification with behavioral psychology principles, UX best practices, and concrete test cases - enabling test-driven development from day one.\n\n---\n\n### 18. **claude-code-history-files-finder** - Session History Recovery\n\nFind and recover content from Claude Code session history files stored in `~/.claude/projects/`.\n\n**When to use:**\n- Recovering deleted or lost files from previous Claude Code sessions\n- Searching for specific code across conversation history\n- Tracking file modifications across multiple sessions\n- Finding sessions containing specific keywords or implementations\n\n**Key features:**\n- **Session search**: Find sessions by keywords with frequency ranking\n- **Content recovery**: Extract files from Write tool calls with deduplication\n- **Statistics analysis**: Message counts, tool usage breakdown, file operations\n- **Batch operations**: Process multiple sessions with keyword filtering\n- **Streaming processing**: Handle large session files (>100MB) efficiently\n\n**Example usage:**\n```bash\n# List recent sessions for a project\npython3 scripts/analyze_sessions.py list /path/to/project\n\n# Search sessions for keywords\npython3 scripts/analyze_sessions.py search /path/to/project \"ComponentName\" \"featureX\"\n\n# Recover deleted files from a session\npython3 scripts/recover_content.py ~/.claude/projects/.../session.jsonl -k DeletedComponent -o ./recovered/\n\n# Get session statistics\npython3 scripts/analyze_sessions.py stats /path/to/session.jsonl --show-files\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [claude-code-history-files-finder/references/](./claude-code-history-files-finder/references/) for:\n- `session_file_format.md` - JSONL structure and extraction patterns\n- `workflow_examples.md` - Detailed recovery and analysis workflows\n\n---\n\n### 19. **docs-cleaner** - Documentation Consolidation\n\nConsolidate redundant documentation while preserving all valuable content.\n\n**When to use:**\n- Cleaning up documentation bloat across projects\n- Merging redundant docs covering the same topics\n- Reducing documentation sprawl after rapid development\n- Consolidating multiple files into authoritative sources\n\n**Key features:**\n- **Content preservation**: Never lose valuable information during cleanup\n- **Redundancy detection**: Identify overlapping documentation\n- **Smart merging**: Combine related docs while maintaining structure\n- **Validation**: Ensure consolidated docs are complete and accurate\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\n---\n\n### 20. **skills-search** - CCPM Skill Registry Search\n\nSearch, discover, install, and manage Claude Code skills from the CCPM (Claude Code Plugin Manager) registry.\n\n**When to use:**\n- Finding skills for specific tasks (e.g., \"find PDF skills\")\n- Installing skills by name\n- Listing currently installed skills\n- Getting detailed information about a skill\n- Managing your Claude Code skill collection\n\n**Key features:**\n- **Registry search**: Search CCPM registry with `ccpm search <query>`\n- **Skill installation**: Install skills with `ccpm install <skill-name>`\n- **Version support**: Install specific versions with `@version` syntax\n- **Bundle installation**: Install pre-configured skill bundles (web-dev, content-creation, developer-tools)\n- **Multiple formats**: Supports registry names, GitHub owner/repo, and full URLs\n- **Skill info**: Get detailed skill information with `ccpm info <skill-name>`\n\n**Example usage:**\n```bash\n# Search for skills\nccpm search pdf              # Find PDF-related skills\nccpm search \"code review\"    # Find code review skills\n\n# Install skills\nccpm install skill-creator                # From registry\nccpm install daymade/skill-creator        # From GitHub\nccpm install skill-creator@1.0.0          # Specific version\n\n# List and manage\nccpm list                    # List installed skills\nccpm info skill-creator      # Get skill details\nccpm uninstall pdf-processor # Remove a skill\n\n# Install bundles\nccpm install-bundle web-dev  # Install web development skills bundle\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [skills-search/SKILL.md](./skills-search/SKILL.md) for complete command reference\n\n**Requirements**: CCPM CLI (`npm install -g @daymade/ccpm`)\n\n---\n\n### 21. **pdf-creator** - PDF Creation with Chinese Font Support\n\nCreate professional PDF documents from markdown with proper Chinese typography using WeasyPrint.\n\n**When to use:**\n- Converting markdown to PDF for sharing or printing\n- Generating formal documents (legal filings, reports)\n- Ensuring correct Chinese font rendering\n\n**Key features:**\n- WeasyPrint + Markdown conversion pipeline\n- Built-in Chinese font fallbacks\n- A4 layout defaults with print-friendly margins\n- Batch conversion scripts\n\n**Example usage:**\n```bash\nuv run --with weasyprint --with markdown scripts/md_to_pdf.py input.md output.pdf\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [pdf-creator/SKILL.md](./pdf-creator/SKILL.md) for setup and workflow details.\n\n**Requirements**: Python 3.8+, `weasyprint`, `markdown`\n\n---\n\n### 22. **claude-md-progressive-disclosurer** - CLAUDE.md Optimization\n\nOptimize user CLAUDE.md files using progressive disclosure to reduce context bloat while preserving critical rules.\n\n**When to use:**\n- CLAUDE.md is too long or repetitive\n- Need to move detailed procedures into references\n- Want to extract reusable workflows into skills\n\n**Key features:**\n- Section classification (keep/move/extract/remove)\n- Before/after line-count reporting\n- Reference file and pointer formats\n- Best-practice optimization workflow\n\n**Example usage:**\n```\n\"Optimize my ~/.claude/CLAUDE.md using progressive disclosure and propose a plan.\"\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [claude-md-progressive-disclosurer/SKILL.md](./claude-md-progressive-disclosurer/SKILL.md).\n\n---\n\n### 23. **promptfoo-evaluation** - Promptfoo LLM Evaluation\n\nConfigure and run LLM evaluations with Promptfoo for prompt testing and model comparisons.\n\n**When to use:**\n- Setting up prompt tests and eval configs\n- Comparing LLM outputs across providers\n- Adding custom assertions or LLM-as-judge grading\n\n**Key features:**\n- promptfooconfig.yaml templates\n- Python custom assertions\n- llm-rubric scoring guidance\n- Built-in preview (echo provider) workflows\n\n**Example usage:**\n```bash\nnpx promptfoo@latest init\nnpx promptfoo@latest eval\nnpx promptfoo@latest view\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [promptfoo-evaluation/references/promptfoo_api.md](./promptfoo-evaluation/references/promptfoo_api.md).\n\n**Requirements**: Node.js (Promptfoo via `npx promptfoo@latest`)\n\n---\n\n### 24. **iOS-APP-developer** - iOS App Development\n\nBuild, configure, and debug iOS apps with XcodeGen, SwiftUI, and Swift Package Manager.\n\n**When to use:**\n- Setting up XcodeGen `project.yml`\n- Fixing SPM dependency or embed issues\n- Handling code signing and device deployment errors\n- Debugging camera/AVFoundation problems\n\n**Key features:**\n- XcodeGen project templates\n- SPM dynamic framework embedding fixes\n- Code signing and provisioning guidance\n- Device deployment and troubleshooting checklists\n\n**Example usage:**\n```bash\nxcodegen generate\nxcodebuild -destination 'platform=iOS Simulator,name=iPhone 17' build\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [iOS-APP-developer/references/xcodegen-full.md](./iOS-APP-developer/references/xcodegen-full.md).\n\n**Requirements**: macOS + Xcode, XcodeGen\n\n---\n\n### 25. **twitter-reader** - Twitter/X Content Fetching\n\nFetch Twitter/X post content using Jina.ai API to bypass JavaScript restrictions without authentication.\n\n**When to use:**\n- Retrieving tweet content for analysis or documentation\n- Fetching thread replies and conversation context\n- Extracting images and media from posts\n- Batch downloading multiple tweets for reference\n\n**Key features:**\n- No JavaScript rendering or browser automation needed\n- No Twitter authentication required\n- Returns markdown-formatted content with metadata\n- Supports both individual and batch fetching\n- Includes author, timestamp, post text, images, and replies\n- Environment variable configuration for secure API key management\n\n**Example usage:**\n```bash\n# Set your Jina API key (get from https://jina.ai/)\nexport JINA_API_KEY=\"your_api_key_here\"\n\n# Fetch a single tweet\ncurl \"https://r.jina.ai/https://x.com/USER/status/TWEET_ID\" \\\n  -H \"Authorization: Bearer ${JINA_API_KEY}\"\n\n# Batch fetch multiple tweets\nscripts/fetch_tweets.sh \\\n  \"https://x.com/user/status/123\" \\\n  \"https://x.com/user/status/456\"\n\n# Fetch to file using Python script\npython scripts/fetch_tweet.py https://x.com/user/status/123 output.md\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [twitter-reader/SKILL.md](./twitter-reader/SKILL.md) for full details and URL format support.\n\n**Requirements**:\n- **Jina.ai API key** (get from https://jina.ai/ - free tier available)\n- **curl** (pre-installed on most systems)\n- **Python 3.6+** (for Python script)\n\n---\n\n### 26. **macos-cleaner** - Intelligent macOS Disk Space Recovery\n\n**The safest way to reclaim disk space on macOS.** Analyze system caches, application remnants, large files, and development environments with intelligent categorization and interactive cleanup.\n\n**Why macos-cleaner stands out:**\n- **Safety-First Philosophy**: Never deletes without explicit user confirmation. Every operation includes risk assessment (üü¢ Safe / üü° Caution / üî¥ Keep).\n- **Intelligence Over Automation**: Analyzes first, explains thoroughly, then lets you decide. Unlike one-click cleaners that blindly delete, we help you understand what you're removing and why.\n- **Developer-Friendly**: Deep analysis of Docker, Homebrew, npm, pip caches - tools that generic cleaners miss.\n- **Transparent & Educational**: Every recommendation includes an explanation of what the file is, why it's safe (or not), and what happens if you delete it.\n- **Professional Quality**: Built by developers who know the pain of accidentally deleting important files. Includes comprehensive safety checks and Time Machine backup recommendations.\n\n**Our design principles:**\n1. **User Control First**: You make the decisions, we provide the insights\n2. **Explain Everything**: No mysterious deletions - full transparency on impact\n3. **Conservative Defaults**: When uncertain, we preserve rather than delete\n4. **Developer Context**: Understand development tool caches, not just system files\n5. **Hybrid Approach**: Combine script precision with visual tools (Mole integration)\n\n**When to use:**\n- Your Mac is running out of disk space (>80% full)\n- You're a developer with Docker/npm/pip/Homebrew caches piling up\n- You want to understand what's consuming space, not just delete blindly\n- You need to clean up after uninstalled applications\n- You prefer understanding over automation\n\n**Key features:**\n- **Smart Cache Analysis**: Categorizes system caches, app caches, logs by safety level\n- **Application Remnant Detection**: Finds orphaned data from uninstalled apps with confidence scoring\n- **Large File Discovery**: Intelligent categorization (videos, archives, databases, disk images, build artifacts)\n- **Development Environment Cleanup**: Docker (images, containers, volumes, build cache), Homebrew, npm, pip, old Git repos\n- **Interactive Safe Deletion**: Batch confirmation, selective deletion, undo-friendly (uses Trash when possible)\n- **Before/After Reports**: Track space recovery with detailed breakdown\n- **Mole Integration**: Seamless workflow with visual cleanup tool for GUI preferences\n- **Risk Categorization**: Every item labeled with safety level and explanation\n- **Time Machine Awareness**: Recommends backups before large deletions (>10 GB)\n\n**What makes us different:**\n- ‚úÖ **Trust Through Transparency**: Other cleaners hide what they delete. We show everything and explain why.\n- ‚úÖ **Developer-Centric**: We clean Docker, not just browser caches. We understand `.git` directories, `node_modules`, and build artifacts.\n- ‚úÖ **Safety Checks Built-In**: Protection against deleting system files, user data, credentials, active databases, or files in use.\n- ‚úÖ **Educational**: Learn what's safe to delete and why, so you can maintain your Mac confidently.\n- ‚ùå **Not a One-Click Solution**: We don't delete automatically. If you want \"clean everything now\", use other tools. We're for users who want control.\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install macos-cleaner@daymade-skills\n\n# Ask Claude Code to analyze your Mac\n\"My Mac is running out of space, help me analyze what's using storage\"\n\n# Claude will:\n# 1. Run comprehensive disk analysis\n# 2. Present categorized findings with safety levels\n# 3. Explain each category (caches, remnants, large files, dev tools)\n# 4. Recommend cleanup approach\n# 5. Execute ONLY what you confirm\n\n# Example analysis output:\nüìä Disk Space Analysis\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nTotal:     500 GB\nUsed:      450 GB (90%)\nAvailable:  50 GB (10%)\n\nüü¢ Safe to Clean (95 GB):\n  - System caches:     45 GB (apps regenerate automatically)\n  - Homebrew cache:     5 GB (reinstalls when needed)\n  - npm cache:          3 GB (safe to clear)\n  - Old logs:           8 GB (diagnostic data only)\n  - Trash:             34 GB (already marked for deletion)\n\nüü° Review Recommended (62 GB):\n  - Large downloads:   38 GB (may contain important files)\n  - App remnants:       8 GB (verify apps are truly uninstalled)\n  - Docker images:     12 GB (may be in use)\n  - Old .git repos:     4 GB (verify project is archived)\n\nüî¥ Keep Unless Certain (0 GB):\n  - No high-risk items detected\n\nRecommendation: Start with üü¢ Safe items (95 GB), then review üü° items together.\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [macos-cleaner/references/](./macos-cleaner/references/) for:\n- `cleanup_targets.md` - Detailed explanations of every cleanup target\n- `mole_integration.md` - How to combine scripts with Mole visual tool\n- `safety_rules.md` - Comprehensive safety guidelines and what to never delete\n\n**Requirements**:\n- **Python 3.6+** (pre-installed on macOS)\n- **macOS** (tested on macOS 10.15+)\n- **Optional**: [Mole](https://github.com/tw93/Mole) for visual cleanup interface\n\n---\n\n### 27. **fact-checker** - Document Fact-Checking\n\nVerify factual claims in documents using web search and official sources, then propose corrections with user confirmation.\n\n**When to use:**\n- Fact-checking documents for accuracy\n- Verifying AI model specifications and technical documentation\n- Updating outdated information in documents\n- Validating statistical claims and benchmarks\n- Checking API capabilities and version numbers\n\n**Key features:**\n- Web search integration with authoritative sources\n- AI model specification verification\n- Technical documentation accuracy checks\n- Statistical data validation\n- Automated correction reports with user confirmation\n- Supports general factual statements and technical claims\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install fact-checker@daymade-skills\n\n# Fact-check a document\n\"Please fact-check this section about AI model capabilities\"\n\n# Verify technical specs\n\"Check if these Claude model specifications are still accurate\"\n\n# Update outdated info\n\"Verify and update the version numbers in this documentation\"\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [fact-checker/SKILL.md](./fact-checker/SKILL.md) for full workflow and claim types.\n\n**Requirements**:\n- Web search access (via Claude Code)\n\n---\n\n### 28. **skill-reviewer** - Skill Quality Review & Improvement\n\nReview and improve Claude Code skills against official best practices with three powerful modes.\n\n**When to use:**\n- Validating your own skills before publishing\n- Evaluating others' skill repositories\n- Contributing improvements to open-source skills via auto-PR\n- Ensuring skills follow marketplace standards\n\n**Key features:**\n- **Self-review mode**: Run automated validation via skill-creator scripts\n- **External review mode**: Clone, analyze, and generate improvement reports\n- **Auto-PR mode**: Fork ‚Üí improve ‚Üí submit PR with additive-only changes\n- **Evaluation checklist**: Frontmatter, instructions, resources verification\n- **Additive-only principle**: Never delete files when contributing to others\n- **PR guidelines**: Tone recommendations and professional templates\n- **Auto-install dependencies**: Automatically installs skill-creator if missing\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install skill-reviewer@daymade-skills\n\n# Self-review your skill\n\"Validate my skill at ~/my-skills/my-awesome-skill\"\n\n# Review external skill repository\n\"Review the skills at https://github.com/user/skill-repo\"\n\n# Auto-PR improvements\n\"Fork, improve, and submit PR for https://github.com/user/skill-repo\"\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [skill-reviewer/references/](./skill-reviewer/references/) for:\n- `evaluation_checklist.md` - Complete skill evaluation criteria\n- `pr_template.md` - Professional PR description template\n- `marketplace_template.json` - Marketplace configuration template\n\n---\n\n### 29. **github-contributor** - GitHub Contribution Strategy\n\nStrategic guide for becoming an effective GitHub contributor and building your open-source reputation.\n\n**When to use:**\n- Looking for projects to contribute to\n- Learning contribution best practices\n- Building your GitHub presence and reputation\n- Understanding how to write high-quality PRs\n\n**Key features:**\n- **Four contribution types**: Documentation, Code Quality, Bug Fixes, Features\n- **Project selection criteria**: What makes a good first project vs red flags\n- **PR excellence workflow**: Before ‚Üí During ‚Üí After submission checklist\n- **Reputation building ladder**: Documentation ‚Üí Bug Fixes ‚Üí Features ‚Üí Maintainer\n- **GitHub CLI commands**: Quick reference for fork, PR, issue operations\n- **Conventional commit format**: Type, scope, description structure\n- **Common mistakes**: What to avoid and best practices\n\n**Contribution types explained:**\n```\nLevel 1: Documentation fixes (lowest barrier, high impact)\n    ‚Üì (build familiarity)\nLevel 2: Code quality (medium effort, demonstrates skill)\n    ‚Üì (understand codebase)\nLevel 3: Bug fixes (high impact, builds trust)\n    ‚Üì (trusted contributor)\nLevel 4: Feature additions (highest visibility)\n    ‚Üì (potential maintainer)\n```\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install github-contributor@daymade-skills\n\n# Find good first issues\n\"Help me find projects with good first issues in Python\"\n\n# Write a high-quality PR\n\"Guide me through creating a PR for this bug fix\"\n\n# Build contribution strategy\n\"Help me plan a contribution strategy for building my GitHub profile\"\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [github-contributor/references/](./github-contributor/references/) for:\n- `pr_checklist.md` - Complete PR quality checklist\n- `project_evaluation.md` - How to evaluate projects for contribution\n- `communication_templates.md` - Issue and PR communication templates\n\n---\n\n### 31. **i18n-expert** - Internationalization & Localization\n\nComplete internationalization/localization setup and auditing for UI codebases. Configure i18n frameworks, replace hard-coded strings with translation keys, ensure locale parity between en-US and zh-CN, and validate pluralization and formatting.\n\n**When to use:**\n- Setting up i18n for new React/Next.js/Vue applications\n- Auditing existing i18n implementations for key parity and completeness\n- Replacing hard-coded strings with translation keys\n- Ensuring proper error code mapping to localized messages\n- Validating pluralization, date/time/number formatting across locales\n- Implementing language switching and SEO metadata localization\n\n**Key features:**\n- Library selection and setup (react-i18next, next-intl, vue-i18n)\n- Key architecture and locale file organization (JSON, YAML, PO, XLIFF)\n- Translation generation strategy (AI, professional, manual)\n- Routing and language detection/switching\n- SEO and metadata localization\n- RTL support for applicable locales\n- Key parity validation between en-US and zh-CN\n- Pluralization and formatting validation\n- Error code mapping to localized messages\n- Bundled i18n_audit.py script for key usage extraction\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install i18n-expert@daymade-skills\n\n# Setup i18n for a new project\n\"Set up i18n for my React app with English and Chinese support\"\n\n# Audit existing i18n implementation\n\"Audit the i18n setup and find missing translation keys\"\n\n# Replace hard-coded strings\n\"Replace all hard-coded strings in this component with i18n keys\"\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [i18n-expert/SKILL.md](./i18n-expert/SKILL.md) for complete workflow and architecture guidance.\n\n**Requirements**:\n- **Python 3.6+** (for audit script)\n- **React/Next.js/Vue** (framework-specific i18n library)\n\n---\n\n### 32. **claude-skills-troubleshooting** - Plugin & Skill Troubleshooting\n\nDiagnose and resolve Claude Code plugin and skill configuration issues. Debug plugin installation, enablement, and activation problems with systematic workflows.\n\n**When to use:**\n- Plugins installed but not showing in available skills list\n- Skills not activating as expected despite installation\n- Troubleshooting enabledPlugins configuration in settings.json\n- Debugging \"plugin not working\" or \"skill not showing\" issues\n- Understanding plugin state architecture and lifecycle\n\n**Key features:**\n- Quick diagnosis via diagnostic script (detects installed vs enabled mismatch)\n- Plugin state architecture documentation (installed_plugins.json vs settings.json)\n- Marketplace cache freshness detection and update guidance\n- Known GitHub issues tracking (#17832, #19696, #17089, #13543, #16260)\n- Batch enable script for missing plugins from a marketplace\n- Skills vs Commands architecture explanation\n- Comprehensive diagnostic commands reference\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install claude-skills-troubleshooting@daymade-skills\n\n# Run diagnostic\npython3 scripts/diagnose_plugins.py\n\n# Batch enable missing plugins\npython3 scripts/enable_all_plugins.py daymade-skills\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [claude-skills-troubleshooting/SKILL.md](./claude-skills-troubleshooting/SKILL.md) for complete troubleshooting workflow and architecture guidance.\n\n**Requirements**: None (uses Claude Code built-in Python)\n\n---\n\n### 33. **meeting-minutes-taker** - Meeting Minutes Generator\n\nTransform meeting transcripts into high-fidelity, structured meeting minutes with iterative human review.\n\n**When to use:**\n- Meeting transcript provided and minutes/notes/summaries requested\n- Multiple versions of meeting minutes need merging without content loss\n- Existing minutes need review against original transcript for missing items\n\n**Key features:**\n- Multi-pass parallel generation with UNION merge strategy\n- Evidence-based recording with speaker quotes\n- Mermaid diagrams for architecture discussions\n- Iterative human-in-the-loop refinement workflow\n- Cross-AI comparison for bias reduction\n- Completeness checklist for systematic review\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install meeting-minutes-taker@daymade-skills\n\n# Then provide a meeting transcript and request minutes\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [meeting-minutes-taker/SKILL.md](./meeting-minutes-taker/SKILL.md) for complete workflow and template guidance.\n\n**Requirements**: None\n\n---\n\n### 34. **deep-research** - Research Report Generator\n\nGenerate format-controlled research reports with evidence tracking and citations.\n\n**When to use:**\n- Need a structured research report, literature review, or market/industry analysis\n- Require strict section formatting or a template to be enforced\n- Need evidence mapping, citations, and source quality review\n- Want multi-pass synthesis to avoid missing key findings\n\n**Key features:**\n- Report spec and format contract workflow\n- Evidence table with source quality rubric\n- Multi-pass complete drafting with UNION merge\n- Citation verification and conflict handling\n- Ready-to-use report template and formatting rules\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install deep-research@daymade-skills\n\n# Then provide a report spec or template and request a deep research report\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [deep-research/SKILL.md](./deep-research/SKILL.md) and [deep-research/references/research_report_template.md](./deep-research/references/research_report_template.md) for workflow and structure.\n\n**Requirements**: None\n\n---\n\n### 35. **competitors-analysis** - Evidence-Based Competitor Tracking\n\nAnalyze competitor repositories with evidence-based approach. All analysis must be based on actual cloned code, never assumptions.\n\n**When to use:**\n- Track and analyze competitor products or technologies\n- Create evidence-based competitor profiles\n- Generate competitive analysis reports\n- Need to document technical decisions with cited sources\n\n**Key features:**\n- Pre-analysis checklist to ensure repositories are cloned locally\n- Forbidden patterns to prevent assumptions (\"Êé®Êµã...\", \"ÂèØËÉΩ...\", \"Â∫îËØ•...\")\n- Required patterns for source citation (file:line_number format)\n- Tech stack analysis guides for Node.js, Python, Rust projects\n- Directory structure conventions for organized competitor tracking\n- Bundled templates: profile template, analysis checklist\n- Management script for batch clone/pull/status operations\n\n**Example usage:**\n```bash\n# Install the skill\nclaude plugin install competitors-analysis@daymade-skills\n\n# Then ask Claude to analyze a competitor\n\"ÂàÜÊûêÁ´ûÂìÅ https://github.com/org/repo\"\n\"Ê∑ªÂä†Á´ûÂìÅÂà∞ flowzero ‰∫ßÂìÅÁöÑÁ´ûÂìÅÂàóË°®\"\n```\n\n**üé¨ Live Demo**\n\n*Coming soon*\n\nüìö **Documentation**: See [competitors-analysis/SKILL.md](./competitors-analysis/SKILL.md) and [competitors-analysis/references/](./competitors-analysis/references/) for templates.\n\n**Requirements**: Git (for cloning repositories)\n\n---\n\n## üé¨ Interactive Demo Gallery\n\nWant to see all demos in one place with click-to-enlarge functionality? Check out our [interactive demo gallery](./demos/index.html) or browse the [demos directory](./demos/).\n\n## üéØ Use Cases\n\n### For GitHub Workflows\nUse **github-ops** to streamline PR creation, issue management, and API operations.\n\n### For Documentation\nCombine **markdown-tools** for document conversion and **mermaid-tools** for diagram generation to create comprehensive documentation. Use **llm-icon-finder** to add brand icons.\n\n### For Research & Analysis\nUse **deep-research** to produce format-controlled research reports with evidence tables and citations. Combine with **fact-checker** to validate claims or with **twitter-reader** for social-source collection.\n\n### For Competitive Intelligence\nUse **competitors-analysis** to track and analyze competitor repositories with evidence-based approach. All findings are sourced from actual code (file:line_number), eliminating speculation. Combine with **deep-research** for comprehensive competitive landscape reports.\n\n### For PDF & Printable Documents\nUse **pdf-creator** to convert markdown to print-ready PDFs with proper Chinese font support for formal documents and reports.\n\n### For Team Communication\nUse **teams-channel-post-writer** to share knowledge and **statusline-generator** to track costs while working.\n\n### For Repository Management & Security\nUse **repomix-unmixer** to extract and validate repomix-packed skills or repositories. Use **repomix-safe-mixer** to package codebases securely, automatically detecting and blocking hardcoded credentials before distribution.\n\n### For Skill Development\nUse **skill-creator** (see [Essential Skill](#-essential-skill-skill-creator) section above) to build, validate, and package your own Claude Code skills following best practices.\n\n### For Presentations & Business Communication\nUse **ppt-creator** to generate professional slide decks with data visualizations, structured storytelling, and complete PPTX output for pitches, reviews, and keynotes.\n\n### For Video Quality Analysis\nUse **video-comparer** to analyze compression results, evaluate codec performance, and generate interactive comparison reports. Combine with **youtube-downloader** to compare different quality downloads.\n\n### For Media & Content Download\nUse **youtube-downloader** to download YouTube videos and extract audio from videos with automatic workarounds for common download issues.\n\n### For Transcription & ASR Correction\nUse **transcript-fixer** to correct speech-to-text errors in meeting notes, lectures, and interviews through dictionary-based rules and AI-powered corrections with automatic learning.\n\n### For Meeting Documentation\nUse **meeting-minutes-taker** to transform raw meeting transcripts into structured, evidence-based minutes. Combine with **transcript-fixer** to clean up ASR errors before generating minutes. Features multi-pass generation with UNION merge to avoid content loss.\n\n### For QA Testing & Quality Assurance\nUse **qa-expert** to establish comprehensive QA testing infrastructure with autonomous LLM execution, Google Testing Standards, and OWASP security testing. Perfect for project launches, third-party QA handoffs, and enforcing quality gates (100% execution, ‚â•80% pass rate, 0 P0 bugs). The master prompt enables 100x faster test execution with zero tracking errors.\n\n### For Prompt Engineering & Requirements Engineering\nUse **prompt-optimizer** to transform vague feature requests into precise EARS specifications with domain theory grounding. Perfect for product requirements documents, AI-assisted coding, and learning prompt engineering best practices. Combine with **skill-creator** to create well-structured skill prompts, or with **ppt-creator** to ensure presentation content requirements are clearly specified.\n\n### For Session History & File Recovery\nUse **claude-code-history-files-finder** to recover deleted files from previous Claude Code sessions, search for specific implementations across conversation history, or track file evolution over time. Essential for recovering accidentally deleted code or finding that feature implementation you remember but can't locate.\n\n### For Documentation Maintenance\nUse **docs-cleaner** to consolidate redundant documentation while preserving valuable content. Perfect for cleaning up documentation sprawl after rapid development phases or merging overlapping docs into authoritative sources.\n\n### For CLAUDE.md Optimization\nUse **claude-md-progressive-disclosurer** to reduce CLAUDE.md bloat by moving detailed sections into references while keeping core rules visible.\n\n### For Skill Discovery & Management\nUse **skills-search** to find, install, and manage Claude Code skills from the CCPM registry. Perfect for discovering new skills for specific tasks, installing skill bundles for common workflows, and keeping your skill collection organized.\n\n### For LLM Evaluation & Model Comparison\nUse **promptfoo-evaluation** to set up prompt tests, compare model outputs, and run automated evaluations with custom assertions.\n\n### For iOS App Development\nUse **iOS-APP-developer** to configure XcodeGen projects, resolve SPM dependency issues, and troubleshoot code signing or device deployment.\n\n### For macOS System Maintenance & Disk Space Recovery\nUse **macos-cleaner** to intelligently analyze and reclaim disk space on macOS with safety-first approach. Unlike one-click cleaners that blindly delete, macos-cleaner explains what each file is, categorizes by risk level (üü¢/üü°/üî¥), and requires explicit confirmation before any deletion. Perfect for developers dealing with Docker/Homebrew/npm/pip cache bloat, users wanting to understand storage consumption, or anyone who values transparency over automation. Combines script-based precision with optional Mole visual tool integration for hybrid workflow.\n\n### For Twitter/X Content Research\nUse **twitter-reader** to fetch tweet content without JavaScript rendering or authentication. Perfect for documenting social media discussions, archiving threads, analyzing tweet content, or gathering reference material from Twitter/X. Combine with **markdown-tools** to convert fetched content into other formats, or with **repomix-safe-mixer** to package research collections securely.\n\n### For Skill Quality & Open-Source Contributions\nUse **skill-reviewer** to validate your own skills against best practices before publishing, or to review and improve others' skill repositories. Combine with **github-contributor** to find high-impact open-source projects, create professional PRs, and build your contributor reputation. Perfect for developers who want to contribute to the Claude Code ecosystem or any GitHub project systematically.\n\n### For Internationalization & Localization\nUse **i18n-expert** to set up complete i18n infrastructure for React/Next.js/Vue applications, audit existing implementations for missing translation keys, and ensure locale parity between en-US and zh-CN. Perfect for teams launching products to global markets, maintaining multi-language UIs, or replacing hard-coded strings with proper i18n keys. Combine with **skill-creator** to create locale-aware skills, or with **docs-cleaner** to consolidate documentation across multiple languages.\n\n### For Plugin & Skill Troubleshooting\nUse **claude-skills-troubleshooting** to diagnose and resolve Claude Code plugin and skill configuration issues. Debug why plugins appear installed but don't show in available skills, understand the installed_plugins.json vs settings.json enabledPlugins architecture, and batch-enable missing plugins from a marketplace. Essential for marketplace maintainers debugging installation issues, developers troubleshooting skill activation, or anyone confused by the GitHub #17832 auto-enable bug.\n\n## üìö Documentation\n\nEach skill includes:\n- **SKILL.md**: Core instructions and workflows\n- **scripts/**: Executable utilities (Python/Bash)\n- **references/**: Detailed documentation\n- **assets/**: Templates and resources (where applicable)\n\n### Quick Links\n\n- **github-ops**: See `github-ops/references/api_reference.md` for API documentation\n- **markdown-tools**: See `markdown-tools/references/conversion-examples.md` for conversion scenarios\n- **mermaid-tools**: See `mermaid-tools/references/setup_and_troubleshooting.md` for setup guide\n- **statusline-generator**: See `statusline-generator/references/color_codes.md` for customization\n- **teams-channel-post-writer**: See `teams-channel-post-writer/references/writing-guidelines.md` for quality standards\n- **repomix-unmixer**: See `repomix-unmixer/references/repomix-format.md` for format specifications\n- **skill-creator**: See `skill-creator/SKILL.md` for complete skill creation workflow\n- **llm-icon-finder**: See `llm-icon-finder/references/icons-list.md` for available icons\n- **cli-demo-generator**: See `cli-demo-generator/references/vhs_syntax.md` for VHS syntax and `cli-demo-generator/references/best_practices.md` for demo guidelines\n- **cloudflare-troubleshooting**: See `cloudflare-troubleshooting/references/api_overview.md` for API documentation\n- **ui-designer**: See `ui-designer/SKILL.md` for design system extraction workflow\n- **ppt-creator**: See `ppt-creator/references/WORKFLOW.md` for 9-stage creation process and `ppt-creator/references/ORCHESTRATION_OVERVIEW.md` for automation\n- **youtube-downloader**: See `youtube-downloader/SKILL.md` for usage examples and troubleshooting\n- **repomix-safe-mixer**: See `repomix-safe-mixer/references/common_secrets.md` for detected credential patterns\n- **video-comparer**: See `video-comparer/references/video_metrics.md` for quality metrics interpretation and `video-comparer/references/configuration.md` for customization options\n- **transcript-fixer**: See `transcript-fixer/references/workflow_guide.md` for step-by-step workflows and `transcript-fixer/references/team_collaboration.md` for collaboration patterns\n- **qa-expert**: See `qa-expert/references/master_qa_prompt.md` for autonomous execution (100x speedup) and `qa-expert/references/google_testing_standards.md` for AAA pattern and OWASP testing\n- **prompt-optimizer**: See `prompt-optimizer/references/ears_syntax.md` for EARS transformation patterns, `prompt-optimizer/references/domain_theories.md` for theory catalog, and `prompt-optimizer/references/examples.md` for complete transformations\n- **claude-code-history-files-finder**: See `claude-code-history-files-finder/references/session_file_format.md` for JSONL structure and `claude-code-history-files-finder/references/workflow_examples.md` for recovery workflows\n- **docs-cleaner**: See `docs-cleaner/SKILL.md` for consolidation workflows\n- **deep-research**: See `deep-research/references/research_report_template.md` for report structure and `deep-research/references/source_quality_rubric.md` for source triage\n- **pdf-creator**: See `pdf-creator/SKILL.md` for PDF conversion and font setup\n- **claude-md-progressive-disclosurer**: See `claude-md-progressive-disclosurer/SKILL.md` for CLAUDE.md optimization workflow\n- **skills-search**: See `skills-search/SKILL.md` for CCPM CLI commands and registry operations\n- **promptfoo-evaluation**: See `promptfoo-evaluation/references/promptfoo_api.md` for evaluation patterns\n- **iOS-APP-developer**: See `iOS-APP-developer/references/xcodegen-full.md` for XcodeGen options and project.yml details\n- **twitter-reader**: See `twitter-reader/SKILL.md` for API key setup and URL format support\n- **macos-cleaner**: See `macos-cleaner/references/cleanup_targets.md` for detailed cleanup target explanations, `macos-cleaner/references/mole_integration.md` for Mole visual tool integration, and `macos-cleaner/references/safety_rules.md` for comprehensive safety guidelines\n- **skill-reviewer**: See `skill-reviewer/references/evaluation_checklist.md` for complete evaluation criteria, `skill-reviewer/references/pr_template.md` for PR templates, and `skill-reviewer/references/marketplace_template.json` for marketplace configuration\n- **github-contributor**: See `github-contributor/references/pr_checklist.md` for PR quality checklist, `github-contributor/references/project_evaluation.md` for project evaluation criteria, and `github-contributor/references/communication_templates.md` for issue/PR templates\n- **i18n-expert**: See `i18n-expert/SKILL.md` for complete i18n setup workflow, key architecture guidance, and audit procedures\n- **claude-skills-troubleshooting**: See `claude-skills-troubleshooting/SKILL.md` for plugin troubleshooting workflow and architecture\n- **fact-checker**: See `fact-checker/SKILL.md` for fact-checking workflow and claim verification process\n- **competitors-analysis**: See `competitors-analysis/SKILL.md` for evidence-based analysis workflow and `competitors-analysis/references/profile_template.md` for competitor profile template\n\n## üõ†Ô∏è Requirements\n\n- **Claude Code** 2.0.13 or higher\n- **Python 3.6+** (for scripts in multiple skills)\n- **gh CLI** (for github-ops)\n- **markitdown** (for markdown-tools)\n- **mermaid-cli** (for mermaid-tools)\n- **yt-dlp** (for youtube-downloader): `brew install yt-dlp` or `pip install yt-dlp`\n- **FFmpeg/FFprobe** (for video-comparer): `brew install ffmpeg`, `apt install ffmpeg`, or `winget install ffmpeg`\n- **weasyprint, markdown** (for pdf-creator)\n- **VHS** (for cli-demo-generator): `brew install vhs`\n- **Jina.ai API key** (for twitter-reader): Free tier available at https://jina.ai/\n- **asciinema** (optional, for cli-demo-generator interactive recording)\n- **ccusage** (optional, for statusline cost tracking)\n- **pandas & matplotlib** (optional, for ppt-creator chart generation)\n- **Marp CLI** (optional, for ppt-creator Marp PPTX export): `npm install -g @marp-team/marp-cli`\n- **Mole** (optional, for macos-cleaner visual cleanup): Download from https://github.com/tw93/Mole\n- **repomix** (for repomix-safe-mixer): `npm install -g repomix`\n- **CCPM CLI** (for skills-search): `npm install -g @daymade/ccpm`\n- **Promptfoo** (for promptfoo-evaluation): `npx promptfoo@latest`\n- **macOS + Xcode, XcodeGen** (for iOS-APP-developer)\n\n## ‚ùì FAQ\n\n### How do I know which skills to install?\n\nStart with **skill-creator** if you want to create your own skills. Otherwise, browse the [Other Available Skills](#-other-available-skills) section and install what matches your workflow.\n\n### Can I use these skills without Claude Code?\n\nNo, these skills are specifically designed for Claude Code. You'll need Claude Code 2.0.13 or higher.\n\n### How do I update skills?\n\nUse the same install command to update:\n```bash\nclaude plugin install skill-name@daymade-skills\n```\n\n### Can I contribute my own skill?\n\nAbsolutely! See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines. We recommend using the skill-creator to ensure your skill meets quality standards.\n\n### Are these skills safe to use?\n\nYes, all skills are open-source and reviewed. The code is available in this repository for inspection.\n\n### How do Chinese users handle API access?\n\nWe recommend using [CC-Switch](https://github.com/farion1231/cc-switch) to manage API provider configurations. See the [Chinese User Guide](#-chinese-user-guide) section above.\n\n### What's the difference between skill-creator and other skills?\n\n**skill-creator** is a meta-skill - it helps you create other skills. The other skills are end-user skills that provide specific functionalities (GitHub ops, document conversion, etc.). If you want to extend Claude Code with your own workflows, start with skill-creator.\n\n---\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to:\n\n1. Open issues for bugs or feature requests\n2. Submit pull requests with improvements\n3. Share feedback on skill quality\n\n### Skill Quality Standards\n\nAll skills in this marketplace follow:\n- Imperative/infinitive writing style\n- Progressive disclosure pattern\n- Proper resource organization\n- Comprehensive documentation\n- Tested and validated\n\n## üìÑ License\n\nThis marketplace is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## ‚≠ê Support\n\nIf you find these skills useful, please:\n- ‚≠ê Star this repository\n- üêõ Report issues\n- üí° Suggest improvements\n- üì¢ Share with your team\n\n## üîó Related Resources\n\n- [Claude Code Documentation](https://docs.claude.com/en/docs/claude-code)\n- [Agent Skills Guide](https://docs.claude.com/en/docs/claude-code/skills)\n- [Plugin Marketplaces](https://docs.claude.com/en/docs/claude-code/plugin-marketplaces)\n- [Anthropic Skills Repository](https://github.com/anthropics/skills)\n\n## üìû Contact\n\n- **GitHub**: [@daymade](https://github.com/daymade)\n- **Email**: daymadev89@gmail.com\n- **Repository**: [daymade/claude-code-skills](https://github.com/daymade/claude-code-skills)\n\n---\n\n**Built with ‚ù§Ô∏è using the skill-creator skill for Claude Code**\n\nLast updated: 2026-01-22 | Marketplace version 1.23.0\n",
        "claude-code-history-files-finder/SKILL.md": "---\nname: claude-code-history-files-finder\ndescription: Finds and recovers content from Claude Code session history files. This skill should be used when searching for deleted files, tracking changes across sessions, analyzing conversation history, or recovering code from previous Claude interactions. Triggers include mentions of \"session history\", \"recover deleted\", \"find in history\", \"previous conversation\", or \".claude/projects\".\n---\n\n# Claude Code History Files Finder\n\nExtract and recover content from Claude Code's session history files stored in `~/.claude/projects/`.\n\n## Capabilities\n\n- Recover deleted or lost files from previous sessions\n- Search for specific code or content across conversation history\n- Analyze file modifications across past sessions\n- Track tool usage and file operations over time\n- Find sessions containing specific keywords or topics\n\n## Session File Locations\n\nSession files are stored at `~/.claude/projects/<normalized-path>/<session-id>.jsonl`.\n\nFor detailed JSONL structure and extraction patterns, see `references/session_file_format.md`.\n\n## Core Operations\n\n### 1. List Sessions for a Project\n\nFind all session files for a specific project:\n\n```bash\npython3 scripts/analyze_sessions.py list /path/to/project\n```\n\nShows most recent sessions with timestamps and sizes.\n\nOptional: `--limit N` to show only N sessions (default: 10).\n\n### 2. Search Sessions for Keywords\n\nLocate sessions containing specific content:\n\n```bash\npython3 scripts/analyze_sessions.py search /path/to/project keyword1 keyword2\n```\n\nReturns sessions ranked by keyword frequency with:\n- Total mention count\n- Per-keyword breakdown\n- Session date and path\n\nOptional: `--case-sensitive` for exact matching.\n\n### 3. Recover Deleted Content\n\nExtract files from session history:\n\n```bash\npython3 scripts/recover_content.py /path/to/session.jsonl\n```\n\nExtracts all Write tool calls and saves files to `./recovered_content/`.\n\n**Filtering by keywords**:\n\n```bash\npython3 scripts/recover_content.py session.jsonl -k ModelLoading FRONTEND deleted\n```\n\nRecovers only files matching any keyword in their path.\n\n**Custom output directory**:\n\n```bash\npython3 scripts/recover_content.py session.jsonl -o ./my_recovery/\n```\n\n### 4. Analyze Session Statistics\n\nGet detailed session metrics:\n\n```bash\npython3 scripts/analyze_sessions.py stats /path/to/session.jsonl\n```\n\nReports:\n- Message counts (user/assistant)\n- Tool usage breakdown\n- File operation counts (Write/Edit/Read)\n\nOptional: `--show-files` to list all file operations.\n\n## Workflow Examples\n\nFor detailed workflow examples including file recovery, tracking file evolution, and batch operations, see `references/workflow_examples.md`.\n\n## Recovery Best Practices\n\n### Deduplication\n\n`recover_content.py` automatically keeps only the latest version of each file. If a file was written multiple times in a session, only the final version is saved.\n\n### Keyword Selection\n\nChoose distinctive keywords that appear in:\n- File names or paths\n- Function/class names\n- Unique strings in code\n- Error messages or comments\n\n### Output Organization\n\nCreate descriptive output directories:\n\n```bash\n# Bad\npython3 scripts/recover_content.py session.jsonl -o ./output/\n\n# Good\npython3 scripts/recover_content.py session.jsonl -o ./recovered_deleted_docs/\npython3 scripts/recover_content.py session.jsonl -o ./feature_xy_history/\n```\n\n### Verification\n\nAfter recovery, always verify content:\n\n```bash\n# Check file list\nls -lh ./recovered_content/\n\n# Read recovery report\ncat ./recovered_content/recovery_report.txt\n\n# Spot-check content\nhead -20 ./recovered_content/ImportantFile.jsx\n```\n\n## Limitations\n\n### What Can Be Recovered\n\n‚úÖ Files written using Write tool\n‚úÖ Code shown in markdown blocks (partial extraction)\n‚úÖ File paths from Edit/Read operations\n\n### What Cannot Be Recovered\n\n‚ùå Files never written to disk (only discussed)\n‚ùå Files deleted before session start\n‚ùå Binary files (images, PDFs) - only paths available\n‚ùå External tool outputs not captured in session\n\n### File Versions\n\n- Only captures state when Write tool was called\n- Intermediate edits between Write calls are lost\n- Edit operations show deltas, not full content\n\n## Troubleshooting\n\n### No Sessions Found\n\n```bash\n# Verify project path normalization\nls ~/.claude/projects/ | grep -i \"project-name\"\n\n# Check actual projects directory\nls -la ~/.claude/projects/\n```\n\n### Empty Recovery\n\nPossible causes:\n- Files were edited (Edit tool) but never written (Write tool)\n- Keywords don't match file paths in session\n- Session predates file creation\n\nSolutions:\n- Try `--show-edits` flag to see Edit operations\n- Broaden keyword search\n- Search adjacent sessions\n\n### Large Session Files\n\nFor sessions >100MB:\n- Scripts use streaming (line-by-line processing)\n- Memory usage remains constant\n- Processing may take 1-2 minutes\n\n## Security & Privacy\n\n### Before Sharing Recovered Content\n\nSession files may contain:\n- Absolute paths with usernames\n- API keys or credentials\n- Company-specific information\n\nAlways sanitize before sharing:\n\n```bash\n# Remove absolute paths\nsed -i '' 's|/Users/[^/]*/|/Users/username/|g' file.js\n\n# Verify no credentials\ngrep -i \"api_key\\|password\\|token\" recovered_content/*\n```\n\n### Safe Storage\n\nRecovered content inherits sensitivity from original sessions. Store securely and follow organizational policies for handling session data.\n",
        "claude-md-progressive-disclosurer/SKILL.md": "---\nname: claude-md-progressive-disclosurer\ndescription: |\n  Optimize CLAUDE.md files using progressive disclosure.\n  Goal: Maximize LLM working efficiency, NOT minimize line count.\n  Use when: User wants to optimize CLAUDE.md, complains about context issues, or file exceeds 500 lines.\n---\n\n# CLAUDE.md Ê∏êËøõÂºèÊä´Èú≤‰ºòÂåñÂô®\n\n## Ê†∏ÂøÉÁêÜÂøµ\n\n> \"ÊâæÂà∞ÊúÄÂ∞èÁöÑÈ´ò‰ø°Âè∑ token ÈõÜÂêàÔºåÊúÄÂ§ßÂåñÊúüÊúõÁªìÊûúÁöÑÂèØËÉΩÊÄß„ÄÇ\" ‚Äî Anthropic\n\n**ÁõÆÊ†áÊòØÊúÄÂ§ßÂåñ LLM Â∑•‰ΩúÊïàËÉΩÔºåËÄåÈùûÊúÄÂ∞èÂåñË°åÊï∞„ÄÇ**\n\n### ‰∏§Â±ÇÊû∂ÊûÑ\n\n```\nLevel 1 (CLAUDE.md) - ÊØèÊ¨°ÂØπËØùÈÉΩÂä†ËΩΩ\n‚îú‚îÄ‚îÄ ‰ø°ÊÅØËÆ∞ÂΩïÂéüÂàô               ‚Üê Èò≤Ê≠¢Êú™Êù•ËÜ®ËÉÄÁöÑËá™ÊàëÁ∫¶Êùü\n‚îú‚îÄ‚îÄ Reference Á¥¢ÂºïÔºàÂºÄÂ§¥Ôºâ     ‚Üê ÂÖ•Âè£1ÔºöÈÅáÂà∞ÈóÆÈ¢òÊü•ËøôÈáå\n‚îú‚îÄ‚îÄ Ê†∏ÂøÉÂëΩ‰ª§Ë°®\n‚îú‚îÄ‚îÄ ÈìÅÂæã/Á¶Å‰ª§ÔºàÂê´‰ª£Á†ÅÁ§∫‰æãÔºâ\n‚îú‚îÄ‚îÄ Â∏∏ËßÅÈîôËØØËØäÊñ≠ÔºàÁóáÁä∂‚ÜíÂéüÂõ†‚Üí‰øÆÂ§çÔºâ\n‚îú‚îÄ‚îÄ ‰ª£Á†ÅÊ®°ÂºèÔºàÂèØÁõ¥Êé•Â§çÂà∂Ôºâ\n‚îú‚îÄ‚îÄ ÁõÆÂΩïÊò†Â∞ÑÔºàÂäüËÉΩ‚ÜíÊñá‰ª∂Ôºâ\n‚îú‚îÄ‚îÄ ‰øÆÊîπ‰ª£Á†ÅÂâçÂøÖËØª             ‚Üê ÂÖ•Âè£2ÔºöÊîπ‰ª£Á†ÅÂâçÊü•ËøôÈáå\n‚îî‚îÄ‚îÄ Reference Ëß¶ÂèëÁ¥¢ÂºïÔºàÊú´Â∞æÔºâ ‚Üê ÂÖ•Âè£3ÔºöÈïøÂØπËØùÂêéÂ§çËø∞\n\nLevel 2 (references/) - ÊåâÈúÄÂç≥Êó∂Âä†ËΩΩ\n‚îú‚îÄ‚îÄ ËØ¶ÁªÜ SOP ÊµÅÁ®ã\n‚îú‚îÄ‚îÄ ËæπÁºòÊÉÖÂÜµÂ§ÑÁêÜ\n‚îú‚îÄ‚îÄ ÂÆåÊï¥ÈÖçÁΩÆÁ§∫‰æã\n‚îî‚îÄ‚îÄ ÂéÜÂè≤ÂÜ≥Á≠ñËÆ∞ÂΩï\n```\n\n### Â§öÂÖ•Âè£ÂéüÂàôÔºàÈáçË¶ÅÔºÅÔºâ\n\nÂêå‰∏Ä Level 2 ËµÑÊ∫êÂèØ‰ª•Êúâ**Â§ö‰∏™ÂÖ•Âè£**ÔºåÊúçÂä°‰∫é‰∏çÂêåÊü•ÊâæË∑ØÂæÑÔºö\n\n| ÂÖ•Âè£ | ‰ΩçÁΩÆ | Ëß¶ÂèëÂú∫ÊôØ | Áî®Êà∑ÂøÉÊÄÅ |\n|------|------|----------|----------|\n| Reference Á¥¢Âºï | ÂºÄÂ§¥ | ÈÅáÂà∞ÈîôËØØ/ÈóÆÈ¢ò | \"Âá∫ bug ‰∫ÜÔºåÊü•Âì™‰∏™ÊñáÊ°£Ôºü\" |\n| ‰øÆÊîπ‰ª£Á†ÅÂâçÂøÖËØª | ‰∏≠Èó¥ | ÂáÜÂ§áÊîπ‰ª£Á†Å | \"ÊàëË¶ÅÊîπ XÔºåË¶ÅÊ≥®ÊÑè‰ªÄ‰πàÔºü\" |\n| Reference Ëß¶ÂèëÁ¥¢Âºï | Êú´Â∞æ | ÈïøÂØπËØùÂÆö‰Ωç | \"ÂàöÊâçËØ¥ÁöÑÈÇ£‰∏™ÊñáÊ°£ÊòØÂì™‰∏™Ôºü\" |\n\n**Ëøô‰∏çÊòØÈáçÂ§çÔºåÊòØÂ§öÂÖ•Âè£„ÄÇ** Â∞±ÂÉè‰π¶ÊúâÁõÆÂΩïÔºàÊåâÁ´†ËäÇÔºâ„ÄÅÁ¥¢ÂºïÔºàÊåâÂÖ≥ÈîÆËØçÔºâ„ÄÅÂø´ÈÄüÂèÇËÄÉÂç°ÔºàÊåâ‰ªªÂä°Ôºâ„ÄÇ\n\n---\n\n## ‰ºòÂåñÂ∑•‰ΩúÊµÅ\n\n### Step 1: Â§á‰ªΩ\n\n```bash\ncp CLAUDE.md CLAUDE.md.bak.$(date +%Y%m%d_%H%M%S)\n```\n\n### Step 2: ÂÜÖÂÆπÂàÜÁ±ª\n\nÂØπÊØè‰∏™Á´†ËäÇÂàÜÁ±ªÔºö\n\n| ÈóÆÈ¢ò | ÊòØ | Âê¶ |\n|------|----|-----|\n| È´òÈ¢ë‰ΩøÁî®Ôºü | Level 1 | ‚Üì |\n| ËøùÂèçÂêéÊûú‰∏•ÈáçÔºü | Level 1 | ‚Üì |\n| Êúâ‰ª£Á†ÅÊ®°ÂºèÈúÄË¶ÅÁõ¥Êé•Â§çÂà∂Ôºü | Level 1 ‰øùÁïôÊ®°Âºè | ‚Üì |\n| ÊúâÊòéÁ°ÆËß¶ÂèëÊù°‰ª∂Ôºü | Level 2 + Ëß¶ÂèëÊù°‰ª∂ | ‚Üì |\n| ÂéÜÂè≤/ÂèÇËÄÉËµÑÊñôÔºü | Level 2 | ËÄÉËôëÂà†Èô§ |\n\n### Step 3: ÂàõÂª∫ Reference Êñá‰ª∂\n\nÂëΩÂêçÔºö`docs/references/{‰∏ªÈ¢ò}-sop.md`\n\n### Step 4: Êõ¥Êñ∞ Level 1\n\n1. **Âú®ÂºÄÂ§¥Ê∑ªÂä†„Äå‰ø°ÊÅØËÆ∞ÂΩïÂéüÂàô„Äç**ÔºàÈ°πÁõÆÊ¶ÇËø∞‰πãÂêéÔºåReference Á¥¢Âºï‰πãÂâçÔºâ\n2. **Ê∑ªÂä† Reference Á¥¢Âºï**ÔºàÁ¥ßÈöè‰ø°ÊÅØËÆ∞ÂΩïÂéüÂàô‰πãÂêéÔºâ\n3. Áî®Ëß¶ÂèëÊù°‰ª∂Ê†ºÂºèÊõøÊç¢ËØ¶ÁªÜÂÜÖÂÆπ\n4. ‰øùÁïô‰ª£Á†ÅÊ®°ÂºèÂíåÈîôËØØËØäÊñ≠\n5. **Ê∑ªÂä†„Äå‰øÆÊîπ‰ª£Á†ÅÂâçÂøÖËØª„ÄçË°®Ê†º**ÔºàÊåâ\"Ë¶ÅÊîπ‰ªÄ‰πà\"Á¥¢ÂºïÔºâ\n6. **Âú®Êú´Â∞æÂÜçÊîæ‰∏Ä‰ªΩËß¶ÂèëÁ¥¢ÂºïË°®**\n\n### Step 5: È™åËØÅ\n\n```bash\n# Ê£ÄÊü•ÂºïÁî®Êñá‰ª∂Â≠òÂú®\ngrep -oh '`[^`]*\\.md`' CLAUDE.md | sed 's/`//g' | while read f; do\n  test -f \"$f\" && echo \"‚úì $f\" || echo \"‚úó MISSING: $f\"\ndone\n```\n\n---\n\n## Level 1 ÂÜÖÂÆπÂàÜÁ±ª\n\n### üî¥ ÁªùÂØπ‰∏çËÉΩÁßªËµ∞\n\n| ÂÜÖÂÆπÁ±ªÂûã | ÂéüÂõ† |\n|---------|------|\n| **Ê†∏ÂøÉÂëΩ‰ª§** | È´òÈ¢ë‰ΩøÁî® |\n| **ÈìÅÂæã/Á¶Å‰ª§** | ËøùÂèçÂêéÊûú‰∏•ÈáçÔºåÂøÖÈ°ªÂßãÁªàÂèØËßÅ |\n| **‰ª£Á†ÅÊ®°Âºè** | LLM ÈúÄË¶ÅÁõ¥Êé•Â§çÂà∂ÔºåÈÅøÂÖçÈáçÊñ∞Êé®ÂØº |\n| **ÈîôËØØËØäÊñ≠** | ÂÆåÊï¥ÁöÑÁóáÁä∂‚ÜíÂéüÂõ†‚Üí‰øÆÂ§çÊµÅÁ®ã |\n| **ÁõÆÂΩïÊò†Â∞Ñ** | Â∏ÆÂä© LLM Âø´ÈÄüÂÆö‰ΩçÊñá‰ª∂ |\n| **Ëß¶ÂèëÁ¥¢ÂºïË°®** | Â∏ÆÂä© LLM Âú®ÈïøÂØπËØù‰∏≠ÂÆö‰Ωç Level 2 |\n\n### üü° ‰øùÁïôÊëòË¶Å + Ëß¶ÂèëÊù°‰ª∂\n\n| ÂÜÖÂÆπÁ±ªÂûã | Level 1 | Level 2 |\n|---------|---------|---------|\n| SOP ÊµÅÁ®ã | Ëß¶ÂèëÊù°‰ª∂ + ÂÖ≥ÈîÆÈô∑Èò± | ÂÆåÊï¥Ê≠•È™§ |\n| ÈÖçÁΩÆÁ§∫‰æã | ÊúÄÂ∏∏Áî®ÁöÑ 1-2 ‰∏™ | ÂÆåÊï¥ÈÖçÁΩÆ |\n| API ÊñáÊ°£ | Â∏∏Áî®ÊñπÊ≥ïÁ≠æÂêç | ÂÆåÊï¥ÂèÇÊï∞ËØ¥Êòé |\n\n### üü¢ ÂèØ‰ª•ÂÆåÂÖ®ÁßªËµ∞\n\n| ÂÜÖÂÆπÁ±ªÂûã | ÂéüÂõ† |\n|---------|------|\n| ÂéÜÂè≤ÂÜ≥Á≠ñËÆ∞ÂΩï | ‰ΩéÈ¢ëËÆøÈóÆ |\n| ÊÄßËÉΩÊï∞ÊçÆ | ÂèÇËÄÉÊÄßË¥® |\n| ÊäÄÊúØÂÄ∫Âä°Ê∏ÖÂçï | ÊåâÈúÄÊü•Áúã |\n| ËæπÁºòÊÉÖÂÜµ | ÊúâÊòéÁ°ÆËß¶ÂèëÊù°‰ª∂Êó∂ÂÜçÂä†ËΩΩ |\n\n---\n\n## ÂºïÁî®Ê†ºÂºèÔºàÂõõÁßçÔºâ\n\n### 1. ËØ¶ÁªÜÊ†ºÂºèÔºàÊ≠£Êñá‰∏≠ÁöÑÈáçË¶ÅÂºïÁî®Ôºâ\n\n```markdown\n**üìñ ‰ΩïÊó∂ËØª `docs/references/xxx-sop.md`**Ôºö\n- [ÂÖ∑‰ΩìÈîôËØØ‰ø°ÊÅØÔºåÂ¶Ç `ERR_DLOPEN_FAILED`]\n- [ÂÖ∑‰ΩìÂú∫ÊôØÔºåÂ¶Ç\"Ê∑ªÂä†Êñ∞ÁöÑÂéüÁîüÊ®°ÂùóÊó∂\"]\n\n> ÂåÖÂê´Ôºö[ÂÖ≥ÈîÆËØç 1]„ÄÅ[ÂÖ≥ÈîÆËØç 2]„ÄÅ[‰ª£Á†ÅÊ®°Êùø]„ÄÇ\n```\n\n### 2. ÈóÆÈ¢òËß¶ÂèëË°®Ê†ºÔºàÂºÄÂ§¥/Êú´Â∞æÁ¥¢ÂºïÔºâ\n\n```markdown\n## Reference Á¥¢ÂºïÔºàÈÅáÂà∞ÈóÆÈ¢òÂÖàÊü•ËøôÈáåÔºâ\n\n| Ëß¶ÂèëÂú∫ÊôØ | ÊñáÊ°£ | Ê†∏ÂøÉÂÜÖÂÆπ |\n|----------|------|---------|\n| `ERR_DLOPEN_FAILED` | `native-modules-sop.md` | ABI Êú∫Âà∂„ÄÅÊáíÂä†ËΩΩ |\n| ÊâìÂåÖÂêé `Cannot find module` | `vite-sop.md` | MODULES_TO_COPY |\n```\n\n### 3. ‰ªªÂä°Ëß¶ÂèëË°®Ê†ºÔºà‰øÆÊîπ‰ª£Á†ÅÂâçÂøÖËØªÔºâ\n\n```markdown\n## ‰øÆÊîπ‰ª£Á†ÅÂâçÂøÖËØª\n\n| ‰Ω†Ë¶ÅÊîπ‰ªÄ‰πà | ÂÖàËØªËøô‰∏™ | ÂÖ≥ÈîÆÈô∑Èò± |\n|-----------|---------|---------|\n| ÂéüÁîüÊ®°ÂùóÁõ∏ÂÖ≥ | `native-modules-sop.md` | ÂøÖÈ°ªÊáíÂä†ËΩΩÔºõelectron-rebuild ‰ºöÈùôÈªòÂ§±Ë¥• |\n| ÊâìÂåÖÈÖçÁΩÆ | `packaging-sop.md` | DMG contents ÂøÖÈ°ªÁî®ÂáΩÊï∞ÂΩ¢Âºè |\n```\n\n### 4. ÂÜÖËÅîÊ†ºÂºèÔºàÁÆÄÁü≠ÂºïÁî®Ôºâ\n\n```markdown\nÂÆåÊï¥ÊµÅÁ®ãËßÅ `database-sop.md`ÔºàFTS5 ËΩ¨‰πâ„ÄÅÂÅ•Â∫∑Ê£ÄÊü•Ôºâ„ÄÇ\n```\n\n**Â§öÊ†∑ÊÄßÂéüÂàô**Ôºö‰∏çË¶ÅÊâÄÊúâÂºïÁî®ÈÉΩÁî®Âêå‰∏ÄÊ†ºÂºè„ÄÇ\n\n---\n\n## ÂõõÊù°Ê†∏ÂøÉÂéüÂàô\n\n### ÂéüÂàô 0ÔºöÊ∑ªÂä†„Äå‰ø°ÊÅØËÆ∞ÂΩïÂéüÂàô„ÄçÔºàÈò≤Ê≠¢Êú™Êù•ËÜ®ËÉÄÔºâ\n\n**ÈóÆÈ¢ò**Ôºö‰ºòÂåñÂÆåÊàêÂêéÔºåÁî®Êà∑‰ºöÁªßÁª≠Ë¶ÅÊ±Ç Claude \"ËÆ∞ÂΩïËøô‰∏™‰ø°ÊÅØÂà∞ CLAUDE.md\"ÔºåÂ¶ÇÊûúÊ≤°ÊúâËßÑÂàôÊåáÂØºÔºåCLAUDE.md ‰ºöÂÜçÊ¨°ËÜ®ËÉÄ„ÄÇ\n\n**Ëß£ÂÜ≥**ÔºöÂú® CLAUDE.md ÂºÄÂ§¥ÔºàÈ°πÁõÆÊ¶ÇËø∞‰πãÂêéÔºâÊ∑ªÂä†„Äå‰ø°ÊÅØËÆ∞ÂΩïÂéüÂàô„ÄçÔºö\n\n```markdown\n## ‰ø°ÊÅØËÆ∞ÂΩïÂéüÂàôÔºàClaude ÂøÖËØªÔºâ\n\nÊú¨ÊñáÊ°£ÈááÁî®**Ê∏êËøõÂºèÊä´Èú≤**Êû∂ÊûÑÔºå‰ºòÂåñ LLM Â∑•‰ΩúÊïàËÉΩ„ÄÇ\n\n### Level 1ÔºàÊú¨Êñá‰ª∂ÔºâÂè™ËÆ∞ÂΩï\n\n| Á±ªÂûã | Á§∫‰æã |\n|------|------|\n| Ê†∏ÂøÉÂëΩ‰ª§Ë°® | `pnpm run restart` |\n| ÈìÅÂæã/Á¶Å‰ª§ | ÂøÖÈ°ªÊáíÂä†ËΩΩÂéüÁîüÊ®°Âùó |\n| Â∏∏ËßÅÈîôËØØËØäÊñ≠ | ÁóáÁä∂‚ÜíÂéüÂõ†‚Üí‰øÆÂ§çÔºàÂÆåÊï¥ÊµÅÁ®ãÔºâ |\n| ‰ª£Á†ÅÊ®°Âºè | ÂèØÁõ¥Êé•Â§çÂà∂ÁöÑ‰ª£Á†ÅÂùó |\n| ÁõÆÂΩïÂØºËà™ | ÂäüËÉΩ‚ÜíÊñá‰ª∂Êò†Â∞Ñ |\n| Ëß¶ÂèëÁ¥¢ÂºïË°® | ÊåáÂêë Level 2 ÁöÑÂÖ•Âè£ |\n\n### Level 2Ôºàdocs/references/ÔºâËÆ∞ÂΩï\n\n| Á±ªÂûã | Á§∫‰æã |\n|------|------|\n| ËØ¶ÁªÜ SOP ÊµÅÁ®ã | ÂÆåÊï¥ÁöÑ 20 Ê≠•Êìç‰ΩúÊåáÂçó |\n| ËæπÁºòÊÉÖÂÜµÂ§ÑÁêÜ | ÁΩïËßÅÈîôËØØÁöÑËØäÊñ≠ |\n| ÂÆåÊï¥ÈÖçÁΩÆÁ§∫‰æã | ÊâÄÊúâÂèÇÊï∞ÁöÑËØ¥Êòé |\n| ÂéÜÂè≤ÂÜ≥Á≠ñËÆ∞ÂΩï | ‰∏∫‰ªÄ‰πàËøôÊ†∑ËÆæËÆ° |\n\n### Áî®Êà∑Ë¶ÅÊ±ÇËÆ∞ÂΩï‰ø°ÊÅØÊó∂\n\n1. **Âà§Êñ≠ÊòØÂê¶È´òÈ¢ë‰ΩøÁî®**Ôºö\n   - ÊòØ ‚Üí ÂÜôÂÖ• CLAUDE.mdÔºàLevel 1Ôºâ\n   - Âê¶ ‚Üí ÂÜôÂÖ•ÂØπÂ∫î reference Êñá‰ª∂ÔºàLevel 2Ôºâ\n\n2. **Level 1 ÂºïÁî® Level 2 ÂøÖÈ°ªÂåÖÂê´**Ôºö\n   - Ëß¶ÂèëÊù°‰ª∂Ôºà‰ªÄ‰πàÊÉÖÂÜµËØ•ËØªÔºâ\n   - ÂÜÖÂÆπÊëòË¶ÅÔºàËØª‰∫ÜËÉΩÂæóÂà∞‰ªÄ‰πàÔºâ\n\n3. **Á¶ÅÊ≠¢**Ôºö\n   - Âú® Level 1 ÊîæÁΩÆ‰ΩéÈ¢ëÁöÑËØ¶ÁªÜÊµÅÁ®ã\n   - ÂºïÁî® Level 2 ‰ΩÜ‰∏çÂÜôËß¶ÂèëÊù°‰ª∂\n```\n\n**ÂéüÂõ†**ÔºöËøôÊù°ËßÑÂàôËÆ© Claude Ëá™Â∑±Áü•ÈÅì‰ªÄ‰πàËØ•ËÆ∞Âú®Âì™ÈáåÔºåÂÆûÁé∞\"Ëá™ÊàëÁ∫¶Êùü\"ÔºåÈÅøÂÖçÂêéÁª≠ÂØπËØù‰∏≠ CLAUDE.md ÂÜçÊ¨°ËÜ®ËÉÄ„ÄÇ\n\n### ÂéüÂàô 1ÔºöËß¶ÂèëÁ¥¢ÂºïË°®ÊîæÂºÄÂ§¥ÂíåÊú´Â∞æ\n\n**ÂéüÂõ†**ÔºöLLM Ê≥®ÊÑèÂäõÂëà U ÂûãÂàÜÂ∏É‚Äî‚ÄîÂºÄÂ§¥ÂíåÊú´Â∞æÂº∫Ôºå‰∏≠Èó¥Âº±„ÄÇ\n\n| ‰ΩçÁΩÆ | ‰ΩúÁî® |\n|------|------|\n| **ÂºÄÂ§¥** | ÂØπËØùÂºÄÂßãÊó∂Âª∫Á´ãÂÖ®Â±ÄËÆ§Áü•Ôºö\"ÊúâÂì™‰∫õ Level 2 ÂèØÁî®\" |\n| **Êú´Â∞æ** | ÂØπËØùÂèòÈïøÂêéÂ§çËø∞ÊèêÈÜíÔºö\"Áé∞Âú®Â∫îËØ•ËØªÂì™‰∏™ Level 2\" |\n\n```markdown\n<!-- CLAUDE.md ÂºÄÂ§¥ÔºàÈ°πÁõÆÊ¶ÇËø∞‰πãÂêéÔºâ -->\n## Reference Á¥¢Âºï\n\n| Ëß¶ÂèëÂú∫ÊôØ | ÊñáÊ°£ | Ê†∏ÂøÉÂÜÖÂÆπ |\n|---------|------|---------|\n| ABI ÈîôËØØ | `native-modules-sop.md` | ÊáíÂä†ËΩΩÊ®°Âºè |\n| ÊâìÂåÖÊ®°ÂùóÁº∫Â§± | `vite-sop.md` | MODULES_TO_COPY |\n\n... (Ê≠£ÊñáÂÜÖÂÆπ) ...\n\n<!-- CLAUDE.md Êú´Â∞æÔºàÂÜçÊîæ‰∏Ä‰ªΩÔºâ -->\n## Reference Ëß¶ÂèëÁ¥¢Âºï\n\n| Ëß¶ÂèëÂú∫ÊôØ | ÊñáÊ°£ | Ê†∏ÂøÉÂÜÖÂÆπ |\n|---------|------|---------|\n| ABI ÈîôËØØ | `native-modules-sop.md` | ÊáíÂä†ËΩΩÊ®°Âºè |\n| ÊâìÂåÖÊ®°ÂùóÁº∫Â§± | `vite-sop.md` | MODULES_TO_COPY |\n```\n\n### ÂéüÂàô 2ÔºöÂºïÁî®ÂøÖÈ°ªÊúâËß¶ÂèëÊù°‰ª∂\n\n**ÈîôËØØ**Ôºö`ËØ¶ËßÅ native-modules-sop.md`\n\n**Ê≠£Á°Æ**Ôºö\n```markdown\n**üìñ ‰ΩïÊó∂ËØª `native-modules-sop.md`**Ôºö\n- ÈÅáÂà∞ `ERR_DLOPEN_FAILED` ÈîôËØØ\n- ÈúÄË¶ÅÊ∑ªÂä†Êñ∞ÁöÑÂéüÁîüÊ®°Âùó\n\n> ÂåÖÂê´ÔºöABI Êú∫Âà∂„ÄÅÊáíÂä†ËΩΩÊ®°Âºè„ÄÅÊâãÂä®‰øÆÂ§çÂëΩ‰ª§\n```\n\n**ÂéüÂõ†**ÔºöÊ≤°ÊúâËß¶ÂèëÊù°‰ª∂ÔºåLLM ‰∏çÁü•ÈÅì‰ªÄ‰πàÊó∂ÂÄôËØ•ÂéªËØª„ÄÇ\n\n### ÂéüÂàô 3Ôºö‰ª£Á†ÅÊ®°ÂºèÂøÖÈ°ª‰øùÁïôÂú® Level 1\n\n**ÈîôËØØ**ÔºöÊää‰ª£Á†ÅÁ§∫‰æãÁßªÂà∞ Level 2ÔºåLevel 1 Âè™ÂÜô\"‰ΩøÁî®ÊáíÂä†ËΩΩÊ®°Âºè\"„ÄÇ\n\n**Ê≠£Á°Æ**ÔºöLevel 1 ‰øùÁïôÂÆåÊï¥ÁöÑÂèØÂ§çÂà∂‰ª£Á†ÅÔºö\n```javascript\n// ‚úÖ Ê≠£Á°ÆÔºöÊáíÂä†ËΩΩÔºåÂè™Âú®ÈúÄË¶ÅÊó∂Âä†ËΩΩ\nlet _Database = null;\nfunction getDatabase() {\n  if (!_Database) {\n    _Database = require(\"better-sqlite3\");\n  }\n  return _Database;\n}\n```\n\n**ÂéüÂõ†**ÔºöLLM ÈúÄË¶ÅÁõ¥Êé•Â§çÂà∂‰ª£Á†ÅÔºåÁßªËµ∞ÂêéÊØèÊ¨°ÈÉΩË¶ÅÈáçÊñ∞Êé®ÂØºÊàñËØªÂèñ Level 2„ÄÇ\n\n---\n\n## ÂèçÊ®°ÂºèË≠¶Âëä\n\n### ‚ö†Ô∏è ÂèçÊ®°Âºè 1ÔºöËøáÂ∫¶Á≤æÁÆÄ\n\n**Ê°à‰æã**ÔºöÊää 2937 Ë°åÂéãÁº©Âà∞ 165 Ë°å\n\n**ÁªìÊûú**Ôºö\n- ‰∏¢Â§±‰ª£Á†ÅÊ®°ÂºèÔºåÊØèÊ¨°ÈáçÊñ∞Êé®ÂØº\n- ‰∏¢Â§±ËØäÊñ≠ÊµÅÁ®ãÔºåÈÅáÈîô‰∏çÁü•Êü•Âì™\n- ‰∏¢Â§±ÁõÆÂΩïÊò†Â∞ÑÔºåÊâæÊñá‰ª∂ÊïàÁéá‰Ωé\n\n**Ê≠£Á°Æ**Ôºö‰øùÁïôÊâÄÊúâÈ´òÈ¢ë‰ΩøÁî®ÁöÑÂÜÖÂÆπÔºåÂç≥‰ΩøË°åÊï∞ËæÉÂ§ö„ÄÇ\n\n### ‚ö†Ô∏è ÂèçÊ®°Âºè 2ÔºöÊó†Ëß¶ÂèëÊù°‰ª∂ÁöÑÂºïÁî®\n\n**Ê°à‰æã**Ôºö`ËØ¶ËßÅ xxx.md`\n\n**ÈóÆÈ¢ò**ÔºöLLM ‰∏çÁü•ÈÅì‰ΩïÊó∂Âä†ËΩΩÔºåË¶Å‰πàÂøΩÁï•ÔºåË¶Å‰πàÊØèÊ¨°ÈÉΩËØª„ÄÇ\n\n**Ê≠£Á°Æ**ÔºöËß¶ÂèëÊù°‰ª∂ + ÂÜÖÂÆπÊëòË¶Å„ÄÇ\n\n### ‚ö†Ô∏è ÂèçÊ®°Âºè 3ÔºöÁßªËµ∞‰ª£Á†ÅÊ®°Âºè\n\n**Ê°à‰æã**ÔºöÊääÂ∏∏Áî®‰ª£Á†ÅÁ§∫‰æãÁßªÂà∞ Level 2\n\n**ÈóÆÈ¢ò**ÔºöLLM ÊØèÊ¨°ÂÜô‰ª£Á†ÅÈÉΩË¶ÅÂÖàËØª Level 2ÔºåÂ¢ûÂä†Âª∂ËøüÂíå token Ê∂àËÄó„ÄÇ\n\n**Ê≠£Á°Æ**ÔºöÈ´òÈ¢ë‰ΩøÁî®ÁöÑ‰ª£Á†ÅÊ®°Âºè‰øùÁïôÂú® Level 1„ÄÇ\n\n### ‚ö†Ô∏è ÂèçÊ®°Âºè 4ÔºöÂà†Èô§ËÄåÈùûÁßªÂä®\n\n**Ê°à‰æã**ÔºöÂà†Èô§\"‰∏çÈáçË¶Å\"ÁöÑÁ´†ËäÇ\n\n**ÈóÆÈ¢ò**Ôºö‰ø°ÊÅØ‰∏¢Â§±ÔºåÊú™Êù•ÈúÄË¶ÅÊó∂Êó†Â§ÑÂèØÊü•„ÄÇ\n\n**Ê≠£Á°Æ**ÔºöÁßªÂà∞ Level 2Ôºå‰øùÁïôËß¶ÂèëÊù°‰ª∂„ÄÇ\n\n---\n\n## ‰ø°ÊÅØÈáèÊ£ÄÈ™å\n\n### ‚úÖ Ê≠£Á°ÆÁöÑ‰ø°ÊÅØÈáè\n\n| Ê£ÄÈ™åÈ°π | ÈÄöËøáÊ†áÂáÜ |\n|--------|---------|\n| Êó•Â∏∏ÂëΩ‰ª§ | ‰∏çÈúÄË¶ÅËØª Level 2 |\n| Â∏∏ËßÅÈîôËØØ | ÊúâÂÆåÊï¥ËØäÊñ≠ÊµÅÁ®ã |\n| ‰ª£Á†ÅÁºñÂÜô | ÊúâÂèØÂ§çÂà∂ÁöÑÊ®°Âºè |\n| ÁâπÂÆöÈóÆÈ¢ò | Áü•ÈÅìËØªÂì™‰∏™ Level 2 |\n| Ëß¶ÂèëÁ¥¢Âºï | Âú®ÊñáÊ°£Êú´Â∞æÔºåË°®Ê†ºÂΩ¢Âºè |\n\n### ‚ùå ‰∏çË∂≥ÁöÑ‰ø°Âè∑\n\n- LLM ÂèçÂ§çÈóÆÂêåÊ†∑ÁöÑÈóÆÈ¢ò\n- LLM ÊØèÊ¨°ÈáçÊñ∞Êé®ÂØº‰ª£Á†ÅÊ®°Âºè\n- Áî®Êà∑ÈúÄË¶ÅÂèçÂ§çÊèêÈÜíËßÑÂàô\n\n### ‚ùå ËøáÂ§öÁöÑ‰ø°Âè∑\n\n- Â§ßÊÆµ‰ΩéÈ¢ëËØ¶ÁªÜÊµÅÁ®ãÂú® Level 1\n- **ÂÆåÂÖ®Áõ∏ÂêåÁöÑÂÜÖÂÆπ**Âú®Â§öÂ§ÑÔºàÊ≥®ÊÑèÔºöÂ§öÂÖ•Âè£ÊåáÂêëÂêå‰∏ÄËµÑÊ∫ê ‚â† ÈáçÂ§çÔºâ\n- ËæπÁºòÊÉÖÂÜµÂíåÂ∏∏ËßÅÊÉÖÂÜµÊ∑∑Âú®‰∏ÄËµ∑\n\n---\n\n## È°πÁõÆÁ∫ß vs Áî®Êà∑Á∫ß\n\n| Áª¥Â∫¶ | Áî®Êà∑Á∫ß | È°πÁõÆÁ∫ß |\n|------|--------|--------|\n| ‰ΩçÁΩÆ | `~/.claude/CLAUDE.md` | `È°πÁõÆ/CLAUDE.md` |\n| References | `~/.claude/references/` | `docs/references/` |\n| Ë°åÊï∞ÂèÇËÄÉ | 100-300 | 300-600 |\n\n---\n\n## Âø´ÈÄüÊ£ÄÊü•Ê∏ÖÂçï\n\n‰ºòÂåñÂÆåÊàêÂêéÔºåÊ£ÄÊü•Ôºö\n\n- [ ] **„Äå‰ø°ÊÅØËÆ∞ÂΩïÂéüÂàô„ÄçÂú®ÊñáÊ°£ÂºÄÂ§¥**ÔºàÈò≤Ê≠¢Êú™Êù•ËÜ®ËÉÄÔºâ\n- [ ] **Reference Á¥¢ÂºïÂú®ÊñáÊ°£ÂºÄÂ§¥**ÔºàÂÖ•Âè£1ÔºöÈÅáÂà∞ÈóÆÈ¢òÊü•ËøôÈáåÔºâ\n- [ ] Ê†∏ÂøÉÂëΩ‰ª§Ë°®ÂÆåÊï¥\n- [ ] ÈìÅÂæã/Á¶Å‰ª§Êúâ‰ª£Á†ÅÁ§∫‰æã\n- [ ] Â∏∏ËßÅÈîôËØØÊúâÂÆåÊï¥ËØäÊñ≠ÊµÅÁ®ãÔºàÁóáÁä∂‚ÜíÂéüÂõ†‚Üí‰øÆÂ§çÔºâ\n- [ ] ‰ª£Á†ÅÊ®°ÂºèÂèØÁõ¥Êé•Â§çÂà∂\n- [ ] ÁõÆÂΩïÊò†Â∞ÑÔºàÂäüËÉΩ‚ÜíÊñá‰ª∂Ôºâ\n- [ ] **„Äå‰øÆÊîπ‰ª£Á†ÅÂâçÂøÖËØª„ÄçË°®Ê†º**ÔºàÂÖ•Âè£2ÔºöÊåâ\"Ë¶ÅÊîπ‰ªÄ‰πà\"Á¥¢ÂºïÔºâ\n- [ ] **Reference Ëß¶ÂèëÁ¥¢ÂºïÂú®ÊñáÊ°£Êú´Â∞æ**ÔºàÂÖ•Âè£3ÔºöÈïøÂØπËØùÂêéÂ§çËø∞Ôºâ\n- [ ] ÊØè‰∏™ Level 2 ÂºïÁî®ÈÉΩÊúâËß¶ÂèëÊù°‰ª∂\n- [ ] ÂºïÁî®ÁöÑÊñá‰ª∂ÈÉΩÂ≠òÂú®\n",
        "claude-skills-troubleshooting/SKILL.md": "---\nname: claude-skills-troubleshooting\ndescription: Diagnose and resolve Claude Code plugin and skill issues. This skill should be used when plugins are installed but not showing in available skills list, skills are not activating as expected, or when troubleshooting enabledPlugins configuration in settings.json. Triggers include \"plugin not working\", \"skill not showing\", \"installed but disabled\", or \"enabledPlugins\" issues.\n---\n\n# Claude Skills Troubleshooting\n\n## Overview\n\nDiagnose and resolve common Claude Code plugin and skill configuration issues. This skill provides systematic debugging workflows for plugin installation, enablement, and activation problems.\n\n## Quick Diagnosis\n\nRun the diagnostic script to identify common issues:\n\n```bash\npython3 scripts/diagnose_plugins.py\n```\n\nThe script checks:\n- Installed vs enabled plugins mismatch\n- Missing enabledPlugins entries in settings.json\n- Stale marketplace cache\n- Invalid plugin configurations\n\n## Common Issues\n\n### Issue 1: Plugin Installed But Not Showing in Available Skills\n\n**Symptoms:**\n- `/plugin` shows plugin as installed\n- Skill not appearing in Skill tool's available list\n- Plugin metadata exists in `installed_plugins.json`\n\n**Root Cause:** Known bug ([GitHub #17832](https://github.com/anthropics/claude-code/issues/17832)) - plugins are added to `installed_plugins.json` but NOT automatically added to `enabledPlugins` in `settings.json`.\n\n**Diagnosis:**\n```bash\n# Check if plugin is in installed_plugins.json\ncat ~/.claude/plugins/installed_plugins.json | grep \"plugin-name\"\n\n# Check if plugin is enabled in settings.json\ncat ~/.claude/settings.json | grep \"plugin-name\"\n```\n\n**Solution:**\n```bash\n# Option 1: Use CLI to enable\nclaude plugin enable plugin-name@marketplace-name\n\n# Option 2: Manually edit settings.json\n# Add to enabledPlugins section:\n# \"plugin-name@marketplace-name\": true\n```\n\n### Issue 2: Understanding Plugin State Architecture\n\n**Key files:**\n\n| File | Purpose |\n|------|---------|\n| `~/.claude/plugins/installed_plugins.json` | Registry of ALL plugins (installed + disabled) |\n| `~/.claude/settings.json` ‚Üí `enabledPlugins` | Controls which plugins are ACTIVE |\n| `~/.claude/plugins/known_marketplaces.json` | Registered marketplace sources |\n| `~/.claude/plugins/cache/` | Actual plugin files |\n\n**A plugin is active ONLY when:**\n1. Exists in `installed_plugins.json` (registered)\n2. Listed in `settings.json` ‚Üí `enabledPlugins` with value `true`\n\n### Issue 3: Marketplace Cache Stale\n\n**Symptoms:**\n- GitHub has latest changes\n- Install finds plugin but gets old version\n- Newly added plugins not visible\n\n**Solution:**\n```bash\n# Update marketplace cache\nclaude plugin marketplace update marketplace-name\n\n# Or clear and re-fetch\nrm -rf ~/.claude/plugins/cache/marketplace-name\nclaude plugin marketplace update marketplace-name\n```\n\n### Issue 4: Plugin Not Found in Marketplace\n\n**Common causes (in order of likelihood):**\n\n1. **Local changes not pushed to GitHub** - Most common!\n   ```bash\n   git status\n   git push\n   claude plugin marketplace update marketplace-name\n   ```\n\n2. **marketplace.json configuration error**\n   ```bash\n   python3 -m json.tool .claude-plugin/marketplace.json\n   ```\n\n3. **Skill directory missing**\n   ```bash\n   ls -la skill-name/SKILL.md\n   ```\n\n## Diagnostic Commands Reference\n\n| Purpose | Command |\n|---------|---------|\n| List marketplaces | `claude plugin marketplace list` |\n| Update marketplace | `claude plugin marketplace update {name}` |\n| Install plugin | `claude plugin install {plugin}@{marketplace}` |\n| Enable plugin | `claude plugin enable {plugin}@{marketplace}` |\n| Disable plugin | `claude plugin disable {plugin}@{marketplace}` |\n| Uninstall plugin | `claude plugin uninstall {plugin}@{marketplace}` |\n| Check installed | `cat ~/.claude/plugins/installed_plugins.json \\| jq '.plugins \\| keys'` |\n| Check enabled | `cat ~/.claude/settings.json \\| jq '.enabledPlugins'` |\n\n## Batch Enable Missing Plugins\n\nTo enable all installed but disabled plugins from a marketplace:\n\n```bash\npython3 scripts/enable_all_plugins.py marketplace-name\n```\n\n## Skills vs Commands Architecture\n\nClaude Code has two types of user-invocable extensions:\n\n1. **Skills** (in `skills/` directory)\n   - Auto-activated based on description matching\n   - Loaded when user request matches skill description\n\n2. **Commands** (in `commands/` directory)\n   - Explicitly invocable via `/command-name`\n   - Appears in Skill tool's available list\n   - Requires command file (e.g., `commands/seer.md`)\n\nIf a skill should be explicitly invocable, add a corresponding command file.\n\n## References\n\n- See `references/known_issues.md` for GitHub issue tracking\n- See `references/architecture.md` for detailed plugin architecture\n",
        "cli-demo-generator/SKILL.md": "---\nname: cli-demo-generator\ndescription: This skill should be used when users want to create animated CLI demos, terminal recordings, or command-line demonstration GIFs. It supports both manual tape file creation and automated demo generation from command descriptions. Use when users mention creating demos, recording terminal sessions, or generating animated GIFs of CLI workflows.\n---\n\n# CLI Demo Generator\n\nGenerate professional animated CLI demos with ease. This skill supports both automated generation from command descriptions and manual control for custom demos.\n\n## When to Use This Skill\n\nTrigger this skill when users request:\n- \"Create a demo showing how to install my package\"\n- \"Generate a CLI demo of these commands\"\n- \"Make an animated GIF of my terminal workflow\"\n- \"Record a terminal session and convert to GIF\"\n- \"Batch generate demos from this config\"\n- \"Create an interactive typing demo\"\n\n## Core Capabilities\n\n### 1. Automated Demo Generation (Recommended)\n\nUse the `auto_generate_demo.py` script for quick, automated demo creation. This is the easiest and most common approach.\n\n**Basic Usage:**\n```bash\nscripts/auto_generate_demo.py \\\n  -c \"npm install my-package\" \\\n  -c \"npm run build\" \\\n  -o demo.gif\n```\n\n**With Options:**\n```bash\nscripts/auto_generate_demo.py \\\n  -c \"command1\" \\\n  -c \"command2\" \\\n  -o output.gif \\\n  --title \"Installation Demo\" \\\n  --theme \"Dracula\" \\\n  --width 1400 \\\n  --height 700\n```\n\n**Script Parameters:**\n- `-c, --command`: Command to include (can be specified multiple times)\n- `-o, --output`: Output GIF file path (required)\n- `--title`: Demo title (optional, shown at start)\n- `--theme`: VHS theme (default: Dracula)\n- `--font-size`: Font size (default: 16)\n- `--width`: Terminal width (default: 1400)\n- `--height`: Terminal height (default: 700)\n- `--no-execute`: Generate tape file only, don't execute VHS\n\n**Smart Features:**\n- Automatic timing based on command complexity\n- Optimized sleep durations (1-3s depending on operation)\n- Proper spacing between commands\n- Professional defaults\n\n### 2. Batch Demo Generation\n\nUse `batch_generate.py` for creating multiple demos from a configuration file.\n\n**Configuration File (YAML):**\n```yaml\ndemos:\n  - name: \"Install Demo\"\n    output: \"install.gif\"\n    title: \"Installation\"\n    theme: \"Dracula\"\n    commands:\n      - \"npm install my-package\"\n      - \"npm run build\"\n\n  - name: \"Usage Demo\"\n    output: \"usage.gif\"\n    commands:\n      - \"my-package --help\"\n      - \"my-package run\"\n```\n\n**Usage:**\n```bash\nscripts/batch_generate.py config.yaml --output-dir ./demos\n```\n\n**When to Use Batch Generation:**\n- Creating a suite of related demos\n- Documenting multiple features\n- Generating demos for tutorials or documentation\n- Maintaining consistent demo series\n\n### 3. Interactive Recording\n\nUse `record_interactive.sh` for recording live terminal sessions.\n\n**Usage:**\n```bash\nscripts/record_interactive.sh output.gif \\\n  --theme \"Dracula\" \\\n  --width 1400\n```\n\n**Recording Process:**\n1. Script starts asciinema recording\n2. Type commands naturally in your terminal\n3. Press Ctrl+D when finished\n4. Script auto-converts to GIF via VHS\n\n**When to Use Interactive Recording:**\n- Demonstrating complex workflows\n- Showing real command output\n- Capturing live interactions\n- Recording debugging sessions\n\n### 4. Manual Tape File Creation\n\nFor maximum control, create VHS tape files manually using templates.\n\n**Available Templates:**\n- `assets/templates/basic.tape` - Simple command demo\n- `assets/templates/interactive.tape` - Typing simulation\n\n**Example Workflow:**\n1. Copy template: `cp assets/templates/basic.tape my-demo.tape`\n2. Edit commands and timing\n3. Generate GIF: `vhs < my-demo.tape`\n\nConsult `references/vhs_syntax.md` for complete VHS syntax reference.\n\n## Workflow Guidance\n\n### For Simple Demos (1-3 commands)\n\nUse automated generation for quick results:\n\n```bash\nscripts/auto_generate_demo.py \\\n  -c \"echo 'Hello World'\" \\\n  -c \"ls -la\" \\\n  -o hello-demo.gif \\\n  --title \"Hello Demo\"\n```\n\n### For Multiple Related Demos\n\nCreate a batch configuration file and use batch generation:\n\n1. Create `demos-config.yaml` with all demo definitions\n2. Run: `scripts/batch_generate.py demos-config.yaml --output-dir ./output`\n3. All demos generate automatically with consistent settings\n\n### For Interactive/Complex Workflows\n\nUse interactive recording to capture real behavior:\n\n```bash\nscripts/record_interactive.sh my-workflow.gif\n# Type commands naturally\n# Ctrl+D when done\n```\n\n### For Custom Timing/Layout\n\nCreate manual tape file with precise control:\n\n1. Start with template or generate base tape with `--no-execute`\n2. Edit timing, add comments, customize layout\n3. Generate: `vhs < custom-demo.tape`\n\n## Best Practices\n\nRefer to `references/best_practices.md` for comprehensive guidelines. Key recommendations:\n\n**Timing:**\n- Quick commands (ls, pwd): 1s sleep\n- Standard commands (grep, cat): 2s sleep\n- Heavy operations (install, build): 3s+ sleep\n\n**Sizing:**\n- Standard: 1400x700 (recommended)\n- Compact: 1200x600\n- Presentations: 1800x900\n\n**Themes:**\n- Documentation: Nord, GitHub Dark\n- Code demos: Dracula, Monokai\n- Presentations: High-contrast themes\n\n**Duration:**\n- Target: 15-30 seconds\n- Maximum: 60 seconds\n- Create series for complex topics\n\n## Troubleshooting\n\n### VHS Not Installed\n\n```bash\n# macOS\nbrew install vhs\n\n# Linux (via Go)\ngo install github.com/charmbracelet/vhs@latest\n```\n\n### Asciinema Not Installed\n\n```bash\n# macOS\nbrew install asciinema\n\n# Linux\nsudo apt install asciinema\n```\n\n### Demo File Too Large\n\n**Solutions:**\n1. Reduce duration (shorter sleep times)\n2. Use smaller dimensions (1200x600)\n3. Consider MP4 format: `Output demo.mp4`\n4. Split into multiple shorter demos\n\n### Output Not Readable\n\n**Solutions:**\n1. Increase font size: `--font-size 18`\n2. Use wider terminal: `--width 1600`\n3. Choose high-contrast theme: `--theme \"Dracula\"`\n4. Test on target display device\n\n## Examples\n\n### Example 1: Quick Install Demo\n\nUser request: \"Create a demo showing npm install\"\n\n```bash\nscripts/auto_generate_demo.py \\\n  -c \"npm install my-package\" \\\n  -o install-demo.gif \\\n  --title \"Package Installation\"\n```\n\n### Example 2: Multi-Step Tutorial\n\nUser request: \"Create a demo showing project setup with git clone, install, and run\"\n\n```bash\nscripts/auto_generate_demo.py \\\n  -c \"git clone https://github.com/user/repo.git\" \\\n  -c \"cd repo\" \\\n  -c \"npm install\" \\\n  -c \"npm start\" \\\n  -o setup-demo.gif \\\n  --title \"Project Setup\" \\\n  --theme \"Nord\"\n```\n\n### Example 3: Batch Generation\n\nUser request: \"Generate demos for all my CLI tool features\"\n\n1. Create `features-demos.yaml`:\n```yaml\ndemos:\n  - name: \"Help Command\"\n    output: \"help.gif\"\n    commands: [\"my-tool --help\"]\n\n  - name: \"Init Command\"\n    output: \"init.gif\"\n    commands: [\"my-tool init\", \"ls -la\"]\n\n  - name: \"Run Command\"\n    output: \"run.gif\"\n    commands: [\"my-tool run --verbose\"]\n```\n\n2. Generate all:\n```bash\nscripts/batch_generate.py features-demos.yaml --output-dir ./demos\n```\n\n### Example 4: Interactive Session\n\nUser request: \"Record me using my CLI tool interactively\"\n\n```bash\nscripts/record_interactive.sh my-session.gif --theme \"Tokyo Night\"\n# User types commands naturally\n# Ctrl+D to finish\n```\n\n## Bundled Resources\n\n### scripts/\n- **`auto_generate_demo.py`** - Automated demo generation from command lists\n- **`batch_generate.py`** - Generate multiple demos from YAML/JSON config\n- **`record_interactive.sh`** - Record and convert interactive terminal sessions\n\n### references/\n- **`vhs_syntax.md`** - Complete VHS tape file syntax reference\n- **`best_practices.md`** - Demo creation guidelines and best practices\n\n### assets/\n- **`templates/basic.tape`** - Basic command demo template\n- **`templates/interactive.tape`** - Interactive typing demo template\n- **`examples/batch-config.yaml`** - Example batch configuration file\n\n## Dependencies\n\n**Required:**\n- VHS (https://github.com/charmbracelet/vhs)\n\n**Optional:**\n- asciinema (for interactive recording)\n- PyYAML (for batch YAML configs): `pip install pyyaml`\n\n## Output Formats\n\nVHS supports multiple output formats:\n\n```tape\nOutput demo.gif     # GIF (default, best for documentation)\nOutput demo.mp4     # MP4 (better compression for long demos)\nOutput demo.webm    # WebM (smaller file size)\n```\n\nChoose based on use case:\n- **GIF**: Documentation, README files, easy embedding\n- **MP4**: Longer demos, better quality, smaller size\n- **WebM**: Web-optimized, smallest file size\n\n## Summary\n\nThis skill provides three main approaches:\n\n1. **Automated** (`auto_generate_demo.py`) - Quick, easy, smart defaults\n2. **Batch** (`batch_generate.py`) - Multiple demos, consistent settings\n3. **Interactive** (`record_interactive.sh`) - Live recording, real output\n\nChoose the approach that best fits the user's needs. For most cases, automated generation is the fastest and most convenient option.\n",
        "cloudflare-troubleshooting/SKILL.md": "---\nname: cloudflare-troubleshooting\ndescription: Investigate and resolve Cloudflare configuration issues using API-driven evidence gathering. Use when troubleshooting ERR_TOO_MANY_REDIRECTS, SSL errors, DNS issues, or any Cloudflare-related problems. Focus on systematic investigation using Cloudflare API to examine actual configuration rather than making assumptions.\n---\n\n# Cloudflare Troubleshooting\n\n## Core Principle\n\n**Investigate with evidence, not assumptions.** Always query Cloudflare API to examine actual configuration before diagnosing issues. The skill's value is the systematic investigation methodology, not predetermined solutions.\n\n## Investigation Methodology\n\n### 1. Gather Credentials\n\nRequest from user:\n- Domain name\n- Cloudflare account email\n- Cloudflare Global API Key (or API Token)\n\nGlobal API Key location: Cloudflare Dashboard ‚Üí My Profile ‚Üí API Tokens ‚Üí View Global API Key\n\n### 2. Get Zone Information\n\nFirst step for any Cloudflare troubleshooting - obtain the zone ID:\n\n```bash\ncurl -s -X GET \"https://api.cloudflare.com/client/v4/zones?name=<domain>\" \\\n  -H \"X-Auth-Email: <email>\" \\\n  -H \"X-Auth-Key: <api_key>\" | jq '.'\n```\n\nExtract `zone_id` from `result[0].id` for subsequent API calls.\n\n### 3. Investigate Systematically\n\nFor each issue, gather evidence before making conclusions. Use Cloudflare API to inspect:\n- Current configuration state\n- Recent changes (if audit log available)\n- Related settings that might interact\n\n## Common Investigation Patterns\n\n### Redirect Loops (ERR_TOO_MANY_REDIRECTS)\n\n**Evidence gathering sequence:**\n\n1. **Check SSL/TLS mode:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/settings/ssl\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n   Look for: `result.value` - tells current SSL mode\n\n2. **Check Always Use HTTPS setting:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/settings/always_use_https\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n3. **Check Page Rules for redirects:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/pagerules\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n   Look for: `forwarding_url` or `always_use_https` actions\n\n4. **Test origin server directly (if possible):**\n   ```bash\n   curl -I -H \"Host: <domain>\" https://<origin_ip>\n   ```\n\n**Diagnosis logic:**\n- SSL mode \"flexible\" + origin enforces HTTPS = redirect loop\n- Multiple redirect rules can conflict\n- Check browser vs curl behavior differences\n\n**Fix:**\n```bash\ncurl -X PATCH \"https://api.cloudflare.com/client/v4/zones/{zone_id}/settings/ssl\" \\\n  -H \"X-Auth-Email: email\" \\\n  -H \"X-Auth-Key: key\" \\\n  -H \"Content-Type: application/json\" \\\n  --data '{\"value\":\"full\"}'\n```\n\nPurge cache after fix:\n```bash\ncurl -X POST \"https://api.cloudflare.com/client/v4/zones/{zone_id}/purge_cache\" \\\n  -H \"X-Auth-Email: email\" \\\n  -H \"X-Auth-Key: key\" \\\n  -d '{\"purge_everything\":true}'\n```\n\n### DNS Issues\n\n**Evidence gathering:**\n\n1. **List DNS records:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/dns_records\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n2. **Check external DNS resolution:**\n   ```bash\n   dig <domain>\n   dig @8.8.8.8 <domain>\n   ```\n\n3. **Check DNSSEC status:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/dnssec\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n**Look for:**\n- Missing A/AAAA/CNAME records\n- Incorrect proxy status (proxied vs DNS-only)\n- TTL values\n- Conflicting records\n\n### SSL Certificate Errors\n\n**Evidence gathering:**\n\n1. **Check SSL certificate status:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/ssl/certificate_packs\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n2. **Check origin certificate (if using Full Strict):**\n   ```bash\n   openssl s_client -connect <origin_ip>:443 -servername <domain>\n   ```\n\n3. **Check SSL settings:**\n   - Minimum TLS version\n   - TLS 1.3 status\n   - Opportunistic Encryption\n\n**Common issues:**\n- Error 526: SSL mode is \"strict\" but origin cert invalid\n- Error 525: SSL handshake failure at origin\n- Provisioning delay: Wait 15-30 minutes for Universal SSL\n\n### Origin Server Errors (502/503/504)\n\n**Evidence gathering:**\n\n1. **Check if origin is reachable:**\n   ```bash\n   curl -I -H \"Host: <domain>\" https://<origin_ip>\n   ```\n\n2. **Check DNS records point to correct origin:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/dns_records\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n3. **Review load balancer config (if applicable):**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/load_balancers\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n4. **Check firewall rules:**\n   ```bash\n   curl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/firewall/rules\" \\\n     -H \"X-Auth-Email: email\" \\\n     -H \"X-Auth-Key: key\"\n   ```\n\n## Learning New APIs\n\nWhen encountering issues not covered above, consult Cloudflare API documentation:\n\n1. **Browse API reference:** https://developers.cloudflare.com/api/\n2. **Search for relevant endpoints** using issue keywords\n3. **Check API schema** to understand available operations\n4. **Test with GET requests** first to understand data structure\n5. **Make changes with PATCH/POST** after confirming approach\n\n**Pattern for exploring new APIs:**\n```bash\n# List available settings for a zone\ncurl -X GET \"https://api.cloudflare.com/client/v4/zones/{zone_id}/settings\" \\\n  -H \"X-Auth-Email: email\" \\\n  -H \"X-Auth-Key: key\"\n```\n\n## API Reference Overview\n\nConsult `references/api_overview.md` for:\n- Common endpoints organized by category\n- Request/response schemas\n- Authentication patterns\n- Rate limits and error handling\n\nConsult `references/ssl_modes.md` for:\n- Detailed SSL/TLS mode explanations\n- Platform compatibility\n- Security implications\n\nConsult `references/common_issues.md` for:\n- Issue patterns and symptoms\n- Investigation checklists\n- Platform-specific notes\n\n## Best Practices\n\n### Evidence-Based Investigation\n\n1. **Query before assuming** - Use API to check actual state\n2. **Gather multiple data points** - Cross-reference settings\n3. **Check related configurations** - Settings often interact\n4. **Verify externally** - Use dig/curl to confirm\n5. **Test incrementally** - One change at a time\n\n### API Usage\n\n1. **Parse JSON responses** - Use `jq` or python for readability\n2. **Check success field** - `\"success\": true/false` in responses\n3. **Handle errors gracefully** - Read `errors` array in responses\n4. **Respect rate limits** - Cloudflare API has limits\n5. **Use appropriate methods:**\n   - GET: Retrieve information\n   - PATCH: Update settings\n   - POST: Create resources / trigger actions\n   - DELETE: Remove resources\n\n### Making Changes\n\n1. **Gather evidence first** - Understand current state\n2. **Identify root cause** - Don't guess\n3. **Apply targeted fix** - Change only what's needed\n4. **Purge cache if needed** - Especially for SSL/redirect changes\n5. **Verify fix** - Re-query API to confirm\n6. **Inform user of wait times:**\n   - Edge server propagation: 30-60 seconds\n   - DNS propagation: Up to 48 hours\n   - Browser cache: Requires manual clear\n\n### Security\n\n- Never log API keys in output\n- Warn if user shares credentials in public context\n- Recommend API Tokens with scoped permissions over Global API Key\n- Use read-only operations for investigation\n\n## Workflow Template\n\n```\n1. Gather: domain, email, API key\n2. Get zone_id via zones API\n3. Investigate:\n   - Query relevant APIs for evidence\n   - Check multiple related settings\n   - Verify with external tools (dig, curl)\n4. Analyze evidence to determine root cause\n5. Apply fix via appropriate API endpoint\n6. Purge cache if configuration change affects delivery\n7. Verify fix via API query and external testing\n8. Inform user of resolution and any required actions\n```\n\n## Example: Complete Investigation\n\nWhen user reports \"site shows ERR_TOO_MANY_REDIRECTS\":\n\n```bash\n# 1. Get zone ID\ncurl -s -X GET \"https://api.cloudflare.com/client/v4/zones?name=example.com\" \\\n  -H \"X-Auth-Email: user@example.com\" \\\n  -H \"X-Auth-Key: abc123\" | jq '.result[0].id'\n\n# 2. Check SSL mode (primary suspect for redirect loops)\ncurl -s -X GET \"https://api.cloudflare.com/client/v4/zones/ZONE_ID/settings/ssl\" \\\n  -H \"X-Auth-Email: user@example.com\" \\\n  -H \"X-Auth-Key: abc123\" | jq '.result.value'\n\n# If returns \"flexible\" and origin is GitHub Pages/Netlify/Vercel:\n\n# 3. Fix by changing to \"full\"\ncurl -X PATCH \"https://api.cloudflare.com/client/v4/zones/ZONE_ID/settings/ssl\" \\\n  -H \"X-Auth-Email: user@example.com\" \\\n  -H \"X-Auth-Key: abc123\" \\\n  -H \"Content-Type: application/json\" \\\n  --data '{\"value\":\"full\"}'\n\n# 4. Purge cache\ncurl -X POST \"https://api.cloudflare.com/client/v4/zones/ZONE_ID/purge_cache\" \\\n  -H \"X-Auth-Email: user@example.com\" \\\n  -H \"X-Auth-Key: abc123\" \\\n  -d '{\"purge_everything\":true}'\n\n# 5. Inform user: Wait 60 seconds, clear browser cache, retry\n```\n\n## When Scripts Are Useful\n\nThe bundled scripts (`scripts/check_cloudflare_config.py`, `scripts/fix_ssl_mode.py`) serve as:\n- **Reference implementations** of investigation patterns\n- **Quick diagnostic tools** when Python is available\n- **Examples** of programmatic API usage\n\nHowever, **prefer direct API calls via Bash/curl** for flexibility and transparency. Scripts should not limit capability - use them when convenient, but use raw API calls when needed for:\n- Unfamiliar scenarios\n- Edge cases\n- Learning/debugging\n- Operations not covered by scripts\n\nThe investigation methodology and API knowledge is the core skill, not the scripts.\n",
        "competitors-analysis/SKILL.md": "---\nname: competitors-analysis\ndescription: Analyze competitor repositories with evidence-based approach. Use when tracking competitors, creating competitor profiles, or generating competitive analysis. CRITICAL - all analysis must be based on actual cloned code, never assumptions. Triggers include \"analyze competitor\", \"add competitor\", \"competitive analysis\", or \"Á´ûÂìÅÂàÜÊûê\".\ncontext: fork\nagent: general-purpose\nallowed-tools: Read, Grep, Glob, Bash(git *), Bash(mkdir *), Bash(ls *), Bash(wc *)\nargument-hint: [product-name] [competitor-url]\n---\n\n# Competitors Analysis\n\nEvidence-based competitor tracking and analysis. **All analysis must be based on actual code, never assumptions.**\n\n## CRITICAL: Evidence-Based Analysis Only\n\n**Âú®ÂºÄÂßãÂàÜÊûê‰πãÂâçÔºåÂøÖÈ°ªÂÆåÊàê‰ª•‰∏ãÊ£ÄÊü•Ôºö**\n\n### Pre-Analysis Checklist\n\n- [ ] ‰ªìÂ∫ìÂ∑≤ÂÖãÈöÜÂà∞Êú¨Âú∞ `~/Workspace/competitors/{product}/`\n- [ ] ÂèØ‰ª• `ls` Êü•ÁúãÁõÆÂΩïÁªìÊûÑ\n- [ ] ÂèØ‰ª• `cat package.json` (ÊàñÁ≠âÊïàÈÖçÁΩÆÊñá‰ª∂) ËØªÂèñÁâàÊú¨‰ø°ÊÅØ\n- [ ] ÂèØ‰ª• `git log -1` Á°ÆËÆ§‰ª£Á†ÅÊòØÊúÄÊñ∞ÁöÑ\n\n**Â¶ÇÊûú‰ª•‰∏ä‰ªª‰Ωï‰∏ÄÈ°πÊú™ÂÆåÊàêÔºåÂÅúÊ≠¢ÂàÜÊûêÔºåÂÖàÂÆåÊàêÂÖãÈöÜÊìç‰Ωú„ÄÇ**\n\n### Forbidden Patterns (Á¶ÅÊ≠¢ÁöÑË°®Ëø∞)\n\n| Á¶ÅÊ≠¢ | ÂéüÂõ† |\n|------|------|\n| \"Êé®Êµã...\"„ÄÅ\"ÂèØËÉΩ...\"„ÄÅ\"Â∫îËØ•...\" | Ê≤°ÊúâËØÅÊçÆÊîØÊåÅ |\n| \"Êû∂ÊûÑÂõæÔºàÊé®ÊµãÁâàÔºâ\" | ÂøÖÈ°ªÂü∫‰∫éÂÆûÈôÖ‰ª£Á†Å |\n| \"Êú™ÂÖ¨ÂºÄ\"„ÄÅ\"Êú™Êä´Èú≤\" | Â¶ÇÊûú‰∏çÁü•ÈÅìÂ∞±‰∏çË¶ÅÂÜô |\n| ‰∏çÂ∏¶Êù•Ê∫êÁöÑÊäÄÊúØÁªÜËäÇ | Êó†Ê≥ïÈ™åËØÅ |\n\n### Required Patterns (ÂøÖÈ°ªÁöÑË°®Ëø∞)\n\n| Ê≠£Á°ÆÊ†ºÂºè | Á§∫‰æã |\n|----------|------|\n| ÊäÄÊúØÁªÜËäÇ + (Êù•Ê∫ê: Êñá‰ª∂:Ë°åÂè∑) | \"‰ΩøÁî® better-sqlite3 (Êù•Ê∫ê: package.json:88)\" |\n| Áõ¥Êé•ÂºïÁî® + Êù•Ê∫ê | `> \"description text\" (README.md:3)` |\n| ÁâàÊú¨Âè∑ + Êù•Ê∫ê | \"ÁâàÊú¨ 1.3.3 (package.json:2)\" |\n\n---\n\n## Analysis Workflow\n\n### Step 1: Clone Repository (ÂøÖÈ°ª)\n\n```bash\n# ÂàõÂª∫‰∫ßÂìÅÁ´ûÂìÅÁõÆÂΩï\nmkdir -p ~/Workspace/competitors/{product-name}\n\n# ÂÖãÈöÜÁ´ûÂìÅ‰ªìÂ∫ì (SSHÔºåÂ§±Ë¥•ÂàôÈáçËØï)\ncd ~/Workspace/competitors/{product-name}\ngit clone git@github.com:org/repo.git\n```\n\n**ÁΩëÁªúÈóÆÈ¢òÂ§ÑÁêÜ**: ‰∏≠ÂõΩÁΩëÁªúÁéØÂ¢ÉÂèØËÉΩÈúÄË¶ÅÂ§öÊ¨°ÈáçËØï„ÄÇ\n\n### Step 2: Gather Facts (Êî∂ÈõÜ‰∫ãÂÆû)\n\nÊåâÈ°∫Â∫èËØªÂèñ‰ª•‰∏ãÊñá‰ª∂ÔºåËÆ∞ÂΩïÂÖ≥ÈîÆ‰ø°ÊÅØÔºö\n\n**2.1 È°πÁõÆÂÖÉÊï∞ÊçÆ**\n```bash\n# Node.js È°πÁõÆ\ncat package.json | head -20      # name, version, description\ncat package.json | grep -A50 dependencies\n\n# Python È°πÁõÆ\ncat pyproject.toml               # Êàñ setup.py, requirements.txt\n\n# Rust È°πÁõÆ\ncat Cargo.toml\n```\n\n**2.2 È°πÁõÆÁªìÊûÑ**\n```bash\nls -la                           # Ê†πÁõÆÂΩïÁªìÊûÑ\nls src/                          # Ê∫êÁ†ÅÁõÆÂΩï\nfind . -name \"*.md\" -maxdepth 2  # ÊñáÊ°£Êñá‰ª∂\n```\n\n**2.3 Ê†∏ÂøÉÊ®°Âùó**\n```bash\n# ÊâæÂà∞ÂÖ•Âè£Êñá‰ª∂\ncat main.js | head -50           # Êàñ index.js, app.py, main.rs\n# ÊâæÂà∞Ê†∏ÂøÉ helpers/utils\nls src/helpers/ 2>/dev/null || ls src/utils/ 2>/dev/null\n```\n\n**2.4 README ÂíåÊñáÊ°£**\n```bash\ncat README.md | head -100        # ÂÆòÊñπÊèèËø∞\ncat CHANGELOG.md | head -50      # ÁâàÊú¨ÂéÜÂè≤\n```\n\n### Step 3: Deep Dive (Ê∑±ÂÖ•ÂàÜÊûê)\n\nÈíàÂØπÂÖ≥ÈîÆÊäÄÊúØÁÇπÔºåËØªÂèñÂÖ∑‰ΩìÂÆûÁé∞Êñá‰ª∂Ôºö\n\n```bash\n# Á§∫‰æãÔºöÂàÜÊûê ASR ÂÆûÁé∞\ncat src/helpers/whisper.js       # ËØªÂèñÂÆåÊï¥Êñá‰ª∂\ngrep -n \"class.*Manager\" src/helpers/*.js  # ÊâæÂà∞Ê†∏ÂøÉÁ±ª\n```\n\n**ËÆ∞ÂΩïÊ†ºÂºè**:\n```\n| Êñá‰ª∂ | Ë°åÂè∑ | ÂèëÁé∞ |\n|------|------|------|\n| whisper.js | 33-35 | ‰ΩøÁî® WhisperServerManager |\n```\n\n### Step 4: Write Profile (Êí∞ÂÜôÂàÜÊûê)\n\n‰ΩøÁî® [references/profile_template.md](references/profile_template.md) Ê®°ÊùøÔºåÁ°Æ‰øùÊØè‰∏™ÊäÄÊúØÁªÜËäÇÈÉΩÊúâÊù•Ê∫êÊ†áÊ≥®„ÄÇ\n\n### Step 5: Post-Analysis Verification (ÂàÜÊûêÂêéÈ™åËØÅ)\n\n**Ëá™Ê£ÄÊ∏ÖÂçï**:\n\n- [ ] ÊâÄÊúâÁâàÊú¨Âè∑ÈÉΩÊúâÊù•Ê∫êÊ†áÊ≥®Ôºü\n- [ ] ÊâÄÊúâÊäÄÊúØÊ†àÈÉΩÊù•Ëá™ package.json/Cargo.tomlÔºü\n- [ ] Êû∂ÊûÑÊèèËø∞Âü∫‰∫éÂÆûÈôÖ‰ª£Á†ÅÁªìÊûÑÔºü\n- [ ] Ê≤°Êúâ\"Êé®Êµã\"„ÄÅ\"ÂèØËÉΩ\"Á≠âËØçÊ±áÔºü\n- [ ] ÂØπÊØîË°®‰∏≠ÁöÑÁ´ûÂìÅÊï∞ÊçÆÈÉΩÊúâÊù•Ê∫êÔºü\n\n---\n\n## Directory Structure\n\n```\n~/Workspace/competitors/\n‚îú‚îÄ‚îÄ flowzero/              # Flowzero ÁöÑÁ´ûÂìÅ\n‚îÇ   ‚îú‚îÄ‚îÄ openwhispr/        # git clone ÁöÑ‰ªìÂ∫ì\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ {product-name}/        # ÂÖ∂‰ªñ‰∫ßÂìÅ\n\n{project}/docs/competitors/\n‚îú‚îÄ‚îÄ README.md              # Á¥¢ÂºïÔºàÊ†áÊ≥®ÂàÜÊûêÁä∂ÊÄÅÔºâ\n‚îú‚îÄ‚îÄ profiles/\n‚îÇ   ‚îî‚îÄ‚îÄ {competitor}.md    # Âü∫‰∫é‰ª£Á†ÅÁöÑÂàÜÊûê\n‚îú‚îÄ‚îÄ landscape/\n‚îú‚îÄ‚îÄ insights/\n‚îî‚îÄ‚îÄ updates/2026/\n```\n\n---\n\n## Templates and Checklists\n\n| ÊñáÊ°£ | Áî®ÈÄî |\n|------|------|\n| [references/profile_template.md](references/profile_template.md) | Á´ûÂìÅÂàÜÊûêÊä•ÂëäÊ®°Êùø |\n| [references/analysis_checklist.md](references/analysis_checklist.md) | ÂàÜÊûêÂâç/‰∏≠/ÂêéÊ£ÄÊü•Ê∏ÖÂçï |\n\n**ÂÖ≥ÈîÆË¶ÅÊ±Ç**:\n1. È°∂ÈÉ®ÂøÖÈ°ªÊ†áÊ≥®Êï∞ÊçÆÊù•Ê∫êË∑ØÂæÑÂíå commit hash\n2. ÊØè‰∏™ÊäÄÊúØÁªÜËäÇÂøÖÈ°ªÊúâ (Êù•Ê∫ê: Êñá‰ª∂:Ë°åÂè∑)\n3. ÂºïÁî® README ÂÜÖÂÆπÂøÖÈ°ªÊ†áÊ≥®Ë°åÂè∑\n4. Êó†Ê≥ïÈ™åËØÅÁöÑÊ†áËÆ∞‰∏∫\"ÂæÖÈ™åËØÅ\"Âπ∂ËØ¥ÊòéÂéüÂõ†\n5. ÂàÜÊûêÂÆåÊàêÂêéËøêË°åÊ£ÄÊü•Ê∏ÖÂçï‰∏≠ÁöÑÈ™åËØÅÂëΩ‰ª§\n\n---\n\n## Tech Stack Analysis Guide\n\n### Node.js / JavaScript\n\n| ‰ø°ÊÅØ | Êù•Ê∫êÊñá‰ª∂ | ÂÖ≥ÈîÆÂ≠óÊÆµ |\n|------|----------|----------|\n| ÁâàÊú¨ | package.json | `version` |\n| ‰æùËµñ | package.json | `dependencies`, `devDependencies` |\n| ÂÖ•Âè£ | package.json | `main`, `scripts.start` |\n| Ê°ÜÊû∂ | package.json | electron, react, vite Á≠â |\n\n### Python\n\n| ‰ø°ÊÅØ | Êù•Ê∫êÊñá‰ª∂ | ÂÖ≥ÈîÆÂ≠óÊÆµ |\n|------|----------|----------|\n| ÁâàÊú¨ | pyproject.toml | `[project].version` |\n| ‰æùËµñ | pyproject.toml / requirements.txt | `dependencies` |\n| ÂÖ•Âè£ | pyproject.toml | `[project.scripts]` |\n\n### Rust\n\n| ‰ø°ÊÅØ | Êù•Ê∫êÊñá‰ª∂ | ÂÖ≥ÈîÆÂ≠óÊÆµ |\n|------|----------|----------|\n| ÁâàÊú¨ | Cargo.toml | `[package].version` |\n| ‰æùËµñ | Cargo.toml | `[dependencies]` |\n\n---\n\n## Common Mistakes to Avoid\n\n### 1. Ë∑≥ËøáÂÖãÈöÜÁõ¥Êé•ÂàÜÊûê\n\n‚ùå ÈîôËØØ: ‰ªé GitHub ÁΩëÈ°µÊàñ WebFetch Ëé∑Âèñ‰ø°ÊÅØÂêéÁõ¥Êé•ÂÜôÂàÜÊûê\n‚úÖ Ê≠£Á°Æ: ÂøÖÈ°ª `git clone` Âà∞Êú¨Âú∞ÔºåÁî® `Read` Â∑•ÂÖ∑ËØªÂèñÊñá‰ª∂\n\n### 2. Ê∑∑Âêà‰∫ãÂÆûÂíåÊé®Êµã\n\n‚ùå ÈîôËØØ:\n```markdown\n## ÊäÄÊúØÊ†à\n- Electron (Êé®ÊµãÂü∫‰∫éÊ°åÈù¢Â∫îÁî®ÁâπÂæÅ)\n- ÂèØËÉΩ‰ΩøÁî®‰∫Ü React\n```\n\n‚úÖ Ê≠£Á°Æ:\n```markdown\n## ÊäÄÊúØÊ†à (Êù•Ê∫ê: package.json)\n| ‰æùËµñ | ÁâàÊú¨ | Êù•Ê∫ê |\n|------|------|------|\n| electron | 36.9.5 | package.json:68 |\n| react | 19.1.0 | package.json:96 |\n```\n\n### 3. ‰ΩøÁî®ËøáÊó∂‰ø°ÊÅØ\n\n‚ùå ÈîôËØØ: ÂàÜÊûêÊó∂‰∏çÊ£ÄÊü• git logÔºå‰ΩøÁî®ËøáÊó∂ÁöÑ‰ª£Á†Å\n‚úÖ Ê≠£Á°Æ: ÂàÜÊûêÂâçËøêË°å `git pull`ÔºåËÆ∞ÂΩïÂàÜÊûêÊó∂ÁöÑ commit hash\n\n### 4. ÂØπÊØîË°®‰∏≠Á´ûÂìÅÊï∞ÊçÆÊó†Êù•Ê∫ê\n\n‚ùå ÈîôËØØ:\n```markdown\n| Áª¥Â∫¶ | Á´ûÂìÅ | Êàë‰ª¨ |\n|------|------|------|\n| ÊîØÊåÅËØ≠Ë®Ä | 25Áßç | 58Áßç |\n```\n\n‚úÖ Ê≠£Á°Æ:\n```markdown\n| Áª¥Â∫¶ | Á´ûÂìÅ | Êù•Ê∫ê | Êàë‰ª¨ |\n|------|------|------|------|\n| ÊîØÊåÅËØ≠Ë®Ä | 25Áßç | modelRegistryData.json:9-35 | 58Áßç (FunASR ÂÆòÊñπÊñáÊ°£) |\n```\n\n---\n\n## Scripts\n\nSee [scripts/update-competitors.sh](scripts/update-competitors.sh) for repository management.\n\n```bash\n./scripts/update-competitors.sh clone   # ÂÖãÈöÜÊâÄÊúâÁ´ûÂìÅ\n./scripts/update-competitors.sh pull    # Êõ¥Êñ∞ÊâÄÊúâÁ´ûÂìÅ\n./scripts/update-competitors.sh status  # Ê£ÄÊü•Áä∂ÊÄÅ\n```\n",
        "deep-research/SKILL.md": "---\nname: deep-research\ndescription: |\n  Generate format-controlled research reports with evidence tracking, citations, and iterative review. This skill should be used when users request a research report, literature review, market or industry analysis, competitive landscape, policy or technical brief, or require a strict report template and section formatting that a single deepresearch pass cannot reliably enforce.\n---\n\n# Deep Research\n\nCreate high-fidelity research reports with strict format control, evidence mapping, and multi-pass synthesis.\n\n## Quick Start\n\n1. Clarify the report spec and format contract\n2. Build a research plan and query set\n3. Collect evidence with the deepresearch tool (multi-pass if needed)\n4. Triage sources and build an evidence table\n5. Draft the full report in multiple complete passes (parallel subagents)\n6. UNION merge, enforce format compliance, verify citations\n7. Present draft for human review and iterate\n\n## Core Workflow\n\nCopy this checklist and track progress:\n\n```\nDeep Research Progress:\n- [ ] Step 1: Intake and format contract\n- [ ] Step 2: Research plan and query set\n- [ ] Step 3: Evidence collection (deepresearch tool)\n- [ ] Step 4: Source triage and evidence table\n- [ ] Step 5: Outline and section map\n- [ ] Step 6: Multi-pass full drafting (parallel subagents)\n- [ ] Step 7: UNION merge and format compliance\n- [ ] Step 8: Evidence and citation verification\n- [ ] Step 9: Present draft for human review and iterate\n```\n\n### Step 1: Intake and Format Contract\n\nEstablish the report requirements before any research:\n\n- Confirm audience, purpose, scope, time range, and geography\n- Lock output format: Markdown, DOCX, slides, or user-provided template\n- Capture required sections and exact formatting rules\n- Confirm citation style (footnotes, inline, numbered, APA, etc.)\n- Confirm length targets per section\n- Ask for any existing style guide or sample report\n\nCreate a concise report spec file:\n\n```\nReport Spec:\n- Audience:\n- Purpose:\n- Scope:\n- Time Range:\n- Geography:\n- Required Sections:\n- Section Formatting Rules:\n- Citation Style:\n- Output Format:\n- Length Targets:\n- Tone:\n- Must-Include Sources:\n- Must-Exclude Topics:\n```\n\nIf a user provides a template or an example report, treat it as a hard constraint and mirror the structure.\n\n### Step 2: Research Plan and Query Set\n\nDefine the research strategy before calling tools:\n\n- Break the main question into 3-7 subquestions\n- Define key entities, keywords, and synonyms\n- Identify primary sources vs secondary sources\n- Define disqualifiers (outdated, low quality, opinion-only)\n- Assemble a query set per section\n\nUse [references/research_plan_checklist.md](references/research_plan_checklist.md) for guidance.\n\n### Step 3: Evidence Collection (Deepresearch Tool)\n\nUse the deepresearch tool to collect evidence and citations.\n\n- Run multiple complete passes if coverage is uncertain\n- Vary query phrasing to reduce blind spots\n- Preserve raw tool output in files for traceability\n\n**File structure (recommended):**\n```\n<output_dir>/research/<topic-name>/\n  deepresearch_pass1.md\n  deepresearch_pass2.md\n  deepresearch_pass3.md\n```\n\nIf deepresearch is unavailable, rely on user-provided sources only and state limitations explicitly.\n\n### Step 4: Source Triage and Evidence Table\n\nNormalize and score sources before drafting:\n\n- De-duplicate sources across passes\n- Score sources using [references/source_quality_rubric.md](references/source_quality_rubric.md)\n- Build an evidence table mapping claims to sources\n\nEvidence table minimum columns:\n\n- Source ID\n- Title\n- Publisher\n- Date\n- URL or reference\n- Quality tier (A/B/C)\n- Notes\n\n### Step 5: Outline and Section Map\n\nCreate an outline that enforces the format contract:\n\n- Use the template in [references/research_report_template.md](references/research_report_template.md)\n- Produce a section map with required elements per section\n- Confirm ordering and headings match the report spec\n\n### Step 6: Multi-Pass Full Drafting (Parallel Subagents)\n\nAvoid single-pass drafting; generate multiple complete reports, then merge.\n\n#### Preferred Strategy: Parallel Subagents (Complete Draft Each)\n\nUse the Task tool to spawn parallel subagents with isolated context. Each subagent must:\n\n- Load the report spec, outline, and evidence table\n- Draft the FULL report (all sections)\n- Enforce formatting rules and citation style\n\n**Implementation pattern:**\n```\nTask(subagent_type=\"general-purpose\", prompt=\"Draft complete report ...\", run_in_background=false) -> version1.md\nTask(subagent_type=\"general-purpose\", prompt=\"Draft complete report ...\", run_in_background=false) -> version2.md\nTask(subagent_type=\"general-purpose\", prompt=\"Draft complete report ...\", run_in_background=false) -> version3.md\n```\n\n**Write drafts to files, not conversation context:**\n```\n<output_dir>/intermediate/<topic-name>/version1.md\n<output_dir>/intermediate/<topic-name>/version2.md\n<output_dir>/intermediate/<topic-name>/version3.md\n```\n\n### Step 7: UNION Merge and Format Compliance\n\nMerge using UNION, never remove content without evidence-based justification:\n\n- Keep all unique findings from all versions\n- Consolidate duplicates while preserving the most detailed phrasing\n- Ensure every claim in the merged draft has a cited source\n- Enforce the exact section order, headings, and formatting\n- Re-run formatting rules from [references/formatting_rules.md](references/formatting_rules.md)\n\n### Step 8: Evidence and Citation Verification\n\nVerify traceability:\n\n- Every numeric claim has at least one source\n- Every recommendation references supporting evidence\n- No orphan claims without citations\n- Dates and time ranges are consistent\n- Conflicts are explicitly called out with both sources\n\nUse [references/completeness_review_checklist.md](references/completeness_review_checklist.md).\n\n### Step 9: Present Draft for Human Review and Iterate\n\nPresent the draft as a reviewable version:\n\n- Emphasize that format compliance and factual accuracy need human review\n- Accept edits to format, structure, and scope\n- If the user provides another AI output, cross-compare and UNION merge\n\n## Output Requirements\n\n- Match the requested language and tone\n- Preserve technical terms in English\n- Respect the report spec and formatting rules\n- Include a references section or bibliography\n\n## Reference Files\n\n| File | When to Load |\n| --- | --- |\n| [research_report_template.md](references/research_report_template.md) | Build outline and draft structure |\n| [formatting_rules.md](references/formatting_rules.md) | Enforce section formatting and citation rules |\n| [source_quality_rubric.md](references/source_quality_rubric.md) | Score and triage sources |\n| [research_plan_checklist.md](references/research_plan_checklist.md) | Build research plan and query set |\n| [completeness_review_checklist.md](references/completeness_review_checklist.md) | Review for coverage, citations, and compliance |\n\n## Anti-Patterns\n\n- Single-pass drafting without parallel complete passes\n- Splitting passes by section instead of full report drafts\n- Ignoring the format contract or user template\n- Claims without citations or evidence table mapping\n- Mixing conflicting dates without calling out discrepancies\n- Copying external AI output without verification\n- Deleting intermediate drafts or raw research outputs\n",
        "demos/README.md": "# Skill Demonstrations\n\nThis directory contains automated demonstrations of each skill using [VHS (Video Home System)](https://github.com/charmbracelet/vhs) by Charmbracelet.\n\nVHS allows you to write terminal recordings as code, making demos reproducible, version-controllable, and typo-free.\n\n## üìÅ Demo Structure\n\n```\ndemos/\n‚îú‚îÄ‚îÄ skill-creator/\n‚îÇ   ‚îú‚îÄ‚îÄ init-skill.tape          # Initialize a new skill\n‚îÇ   ‚îú‚îÄ‚îÄ validate-skill.tape       # Validate skill quality\n‚îÇ   ‚îî‚îÄ‚îÄ package-skill.tape        # Package for distribution\n‚îú‚îÄ‚îÄ github-ops/\n‚îÇ   ‚îî‚îÄ‚îÄ create-pr.tape            # Create pull requests\n‚îú‚îÄ‚îÄ markdown-tools/\n‚îÇ   ‚îî‚îÄ‚îÄ convert-docs.tape         # Convert documents\n‚îî‚îÄ‚îÄ generate_all_demos.sh         # Generate all GIFs\n```\n\n## üé¨ Generating Demos\n\n### Prerequisites\n\nInstall VHS:\n\n**macOS:**\n```bash\nbrew install vhs\n```\n\n**Linux (with Go):**\n```bash\ngo install github.com/charmbracelet/vhs@latest\n```\n\n**Or download from:**\nhttps://github.com/charmbracelet/vhs/releases\n\n### Generate All Demos\n\n```bash\n./generate_all_demos.sh\n```\n\nThis will:\n1. Find all `.tape` files\n2. Generate corresponding `.gif` files\n3. Report success/failure for each demo\n\n### Generate a Specific Demo\n\n```bash\nvhs < skill-creator/init-skill.tape\n```\n\nThis creates `demos/skill-creator/init-skill.gif`.\n\n## üìù Creating New Demos\n\n### VHS Tape File Format\n\nA `.tape` file consists of commands that VHS executes in a virtual terminal:\n\n```tape\n# Output configuration\nOutput demos/my-skill/my-demo.gif\n\n# Terminal settings\nSet FontSize 16\nSet Width 1400\nSet Height 700\nSet Theme \"Dracula\"\nSet Padding 20\n\n# Demo script\nType \"echo Hello World\" Sleep 500ms\nEnter\nSleep 2s\n```\n\n### Common VHS Commands\n\n| Command | Description | Example |\n|---------|-------------|---------|\n| `Output` | Set output file path | `Output demos/skill/demo.gif` |\n| `Set FontSize` | Set terminal font size | `Set FontSize 18` |\n| `Set Width/Height` | Set terminal dimensions | `Set Width 1400` |\n| `Set Theme` | Set color theme | `Set Theme \"Dracula\"` |\n| `Type` | Type text | `Type \"ls -la\"` |\n| `Type@<speed>` | Type with custom speed | `Type@500ms \"slow typing\"` |\n| `Enter` | Press Enter key | `Enter` |\n| `Sleep` | Pause execution | `Sleep 2s` |\n| `Ctrl+C` | Send Ctrl+C | `Ctrl+C` |\n\n### Demo Guidelines\n\nWhen creating new demos:\n\n1. **Keep demos short** - Under 30 seconds ideally\n2. **Use readable font size** - 16-18pt minimum\n3. **Show realistic usage** - Practical, real-world examples\n4. **Add brief comments** - Explain what's happening\n5. **Use consistent theme** - Dracula theme recommended\n6. **Test before committing** - Generate and review the GIF\n\n### Example: Creating a New Demo\n\n1. **Create the tape file:**\n```bash\ntouch demos/my-skill/my-workflow.tape\n```\n\n2. **Write the demo script:**\n```tape\nOutput demos/my-skill/my-workflow.gif\n\nSet FontSize 16\nSet Width 1400\nSet Height 700\nSet Theme \"Dracula\"\nSet Padding 20\n\nType \"# My Skill Demo\" Sleep 500ms Enter\nSleep 1s\n\nType \"echo 'Step 1: Setup'\" Sleep 500ms\nEnter\nSleep 2s\n\nType \"echo 'Step 2: Execute'\" Sleep 500ms\nEnter\nSleep 2s\n```\n\n3. **Generate the GIF:**\n```bash\nvhs < demos/my-skill/my-workflow.tape\n```\n\n4. **Review the output:**\n```bash\nopen demos/my-skill/my-workflow.gif  # macOS\nxdg-open demos/my-skill/my-workflow.gif  # Linux\n```\n\n## üé® Themes\n\nVHS supports various themes. We use \"Dracula\" for consistency, but you can try:\n\n- `Dracula` (default)\n- `Nord`\n- `Monokai`\n- `Solarized Dark`\n- `Tokyo Night`\n\n## üìö Resources\n\n- **VHS Documentation**: https://github.com/charmbracelet/vhs\n- **VHS Examples**: https://github.com/charmbracelet/vhs/tree/main/examples\n- **Tape File Syntax**: https://github.com/charmbracelet/vhs/blob/main/syntax.md\n\n## üîß Troubleshooting\n\n### VHS not found\n\nEnsure VHS is in your PATH:\n```bash\nwhich vhs\n```\n\n### Permission denied\n\nMake the generation script executable:\n```bash\nchmod +x generate_all_demos.sh\n```\n\n### Demo generation fails\n\nCheck the tape file syntax:\n```bash\nvhs validate < demos/my-skill/my-demo.tape\n```\n\n### GIF file too large\n\nReduce dimensions or duration:\n```tape\nSet Width 1200  # Smaller width\nSet Height 600  # Smaller height\nSleep 1s        # Shorter pauses\n```\n\n## üìù Adding Demos to README\n\nAfter generating demos, add them to the main README.md:\n\n```markdown\n### skill-creator - Skill Development Toolkit\n\n<div align=\"center\">\n  <img src=\"./demos/skill-creator/init-skill.gif\" alt=\"Initialize Skill Demo\" width=\"800\"/>\n</div>\n\nGuide for creating effective Claude Code skills...\n```\n\n---\n\n**Pro Tip**: Demos are automatically regenerated by CI/CD when tape files change (coming soon!).\n",
        "docs-cleaner/SKILL.md": "---\nname: docs-cleaner\ndescription: Consolidates redundant documentation while preserving all valuable content. This skill should be used when users want to clean up documentation bloat, merge redundant docs, reduce documentation sprawl, or consolidate multiple files covering the same topic. Triggers include \"clean up docs\", \"consolidate documentation\", \"too many doc files\", \"merge these docs\", or when documentation exceeds 500 lines across multiple files covering similar topics.\n---\n\n# Documentation Cleaner\n\nConsolidate redundant documentation while preserving 100% of valuable content.\n\n## Core Principle\n\n**Critical evaluation before deletion.** Never blindly delete. Analyze each section's unique value before proposing removal. The goal is reduction without information loss.\n\n## Workflow\n\n### Phase 1: Discovery\n\n1. Identify all documentation files covering the topic\n2. Count total lines across files\n3. Map content overlap between documents\n\n### Phase 2: Value Analysis\n\nFor each document, create a section-by-section analysis table:\n\n| Section | Lines | Value | Reason |\n|---------|-------|-------|--------|\n| API Reference | 25 | Keep | Unique endpoint documentation |\n| Setup Steps | 40 | Condense | Verbose but essential |\n| Test Results | 30 | Delete | One-time record, not reference |\n\nValue categories:\n- **Keep**: Unique, essential, frequently referenced\n- **Condense**: Valuable but verbose\n- **Delete**: Duplicate, one-time, self-evident, outdated\n\nSee `references/value_analysis_template.md` for detailed criteria.\n\n### Phase 3: Consolidation Plan\n\nPropose target structure:\n\n```\nBefore: 726 lines (3 files, high redundancy)\nAfter:  ~100 lines (1 file + reference in CLAUDE.md)\nReduction: 86%\nValue preserved: 100%\n```\n\n### Phase 4: Execution\n\n1. Create consolidated document with all valuable content\n2. Delete redundant source files\n3. Update references (CLAUDE.md, README, imports)\n4. Verify no broken links\n\n## Value Preservation Checklist\n\nBefore finalizing, confirm preservation of:\n\n- [ ] Essential procedures (setup, configuration)\n- [ ] Key constraints and gotchas\n- [ ] Troubleshooting guides\n- [ ] Technical debt / roadmap items\n- [ ] External links and references\n- [ ] Debug tips and code snippets\n\n## Anti-Patterns\n\n| Pattern | Problem | Solution |\n|---------|---------|----------|\n| Blind deletion | Loses valuable information | Section-by-section analysis first |\n| Keeping everything | No reduction achieved | Apply value criteria strictly |\n| Multiple sources of truth | Future divergence | Single authoritative location |\n| Orphaned references | Broken links | Update all references after consolidation |\n\n## Output Artifacts\n\nA successful cleanup produces:\n\n1. **Consolidated document** - Single source of truth\n2. **Value analysis** - Section-by-section justification\n3. **Before/after metrics** - Lines reduced, value preserved\n4. **Updated references** - CLAUDE.md or README with pointer to new location\n",
        "fact-checker/README.md": "# Fact Checker\n\nVerify factual claims in documents using web search and official sources, then apply corrections with user confirmation.\n\n## Features\n\n- ‚úÖ Comprehensive fact verification across multiple domains\n- üîç Searches authoritative sources (official docs, API specs, academic papers)\n- üìä Generates detailed correction reports with sources\n- ü§ñ Auto-applies corrections after user approval\n- üïê Adds temporal context to prevent information decay\n\n## Supported Claim Types\n\n- **AI Model Specifications**: Context windows, pricing, features, benchmarks\n- **Technical Documentation**: API capabilities, version numbers, library features\n- **Statistical Data**: Metrics, benchmark scores, performance data\n- **General Facts**: Any verifiable factual statement\n\n## Usage Examples\n\n### Example 1: Update Outdated AI Model Info\n\n```\nUser: Fact-check the AI model specifications in section 2.1\n```\n\n**What happens:**\n1. Identifies claims: \"Claude 3.5 Sonnet: 200K tokens\", \"GPT-4o: 128K tokens\"\n2. Searches official documentation for current models\n3. Finds: Claude Sonnet 4.5, GPT-5.2 with updated specs\n4. Generates correction report with sources\n5. Applies fixes after user confirms\n\n### Example 2: Verify Technical Claims\n\n```\nUser: Check if these library versions are still current\n```\n\n**What happens:**\n1. Extracts version numbers from document\n2. Checks package registries (npm, PyPI, etc.)\n3. Identifies outdated versions\n4. Suggests updates with changelog references\n\n### Example 3: Validate Statistics\n\n```\nUser: Verify the benchmark scores in this section\n```\n\n**What happens:**\n1. Identifies numerical claims and metrics\n2. Searches official benchmark publications\n3. Compares document values vs. source data\n4. Flags discrepancies with authoritative links\n\n## Workflow\n\nThe skill follows a 5-step process:\n\n```\nFact-checking Progress:\n- [ ] Step 1: Identify factual claims\n- [ ] Step 2: Search authoritative sources\n- [ ] Step 3: Compare claims against sources\n- [ ] Step 4: Generate correction report\n- [ ] Step 5: Apply corrections with user approval\n```\n\n## Source Evaluation\n\n**Preferred sources (in order):**\n1. Official product pages and documentation\n2. API documentation and developer guides\n3. Official blog announcements\n4. GitHub releases (for open source)\n\n**Use with caution:**\n- Third-party aggregators (verify against official sources)\n- Blog posts and articles (cross-reference)\n\n**Avoid:**\n- Outdated documentation\n- Unofficial wikis without citations\n- Speculation and rumors\n\n## Real-World Example\n\n**Before:**\n```markdown\nAI Â§ßÊ®°ÂûãÁöÑ\"‰∏ä‰∏ãÊñáÁ™óÂè£\"‰∏çÊñ≠ÂçáÁ∫ßÔºö\n- Claude 3.5 Sonnet: 200K tokensÔºàÁ∫¶ 15 ‰∏áÊ±âÂ≠óÔºâ\n- GPT-4o: 128K tokensÔºàÁ∫¶ 10 ‰∏áÊ±âÂ≠óÔºâ\n- Gemini 1.5 Pro: 2M tokensÔºàÁ∫¶ 150 ‰∏áÊ±âÂ≠óÔºâ\n```\n\n**After fact-checking:**\n```markdown\nAI Â§ßÊ®°ÂûãÁöÑ\"‰∏ä‰∏ãÊñáÁ™óÂè£\"‰∏çÊñ≠ÂçáÁ∫ßÔºàÊà™Ëá≥ 2026 Âπ¥ 1 ÊúàÔºâÔºö\n- Claude Sonnet 4.5: 200K tokensÔºàÁ∫¶ 15 ‰∏áÊ±âÂ≠óÔºâ\n- GPT-5.2: 400K tokensÔºàÁ∫¶ 30 ‰∏áÊ±âÂ≠óÔºâ\n- Gemini 3 Pro: 1M tokensÔºàÁ∫¶ 75 ‰∏áÊ±âÂ≠óÔºâ\n```\n\n**Changes made:**\n- ‚úÖ Updated Claude 3.5 Sonnet ‚Üí Claude Sonnet 4.5\n- ‚úÖ Corrected GPT-4o (128K) ‚Üí GPT-5.2 (400K)\n- ‚úÖ Fixed Gemini 1.5 Pro (2M) ‚Üí Gemini 3 Pro (1M)\n- ‚úÖ Added temporal marker \"Êà™Ëá≥ 2026 Âπ¥ 1 Êúà\"\n\n## Installation\n\n```bash\n# Via CCPM (recommended)\nccpm install @daymade-skills/fact-checker\n\n# Manual installation\nDownload fact-checker.zip and install through Claude Code\n```\n\n## Trigger Keywords\n\nThe skill activates when you mention:\n- \"fact-check this document\"\n- \"verify these claims\"\n- \"check if this is accurate\"\n- \"update outdated information\"\n- \"validate the data\"\n\n## Configuration\n\nNo configuration required. The skill works out of the box.\n\n## Limitations\n\n**Cannot verify:**\n- Subjective opinions or judgments\n- Future predictions or specifications\n- Claims requiring paywalled sources\n- Disputed facts without authoritative consensus\n\n**For such cases**, the skill will:\n- Note the limitation in the report\n- Suggest qualification language\n- Recommend user research or expert consultation\n\n## Best Practices\n\n### For Authors\n\n1. **Run regularly**: Fact-check documents periodically to catch outdated info\n2. **Include dates**: Add temporal markers like \"as of [date]\" to claims\n3. **Cite sources**: Keep original source links for future verification\n4. **Review reports**: Always review the correction report before applying changes\n\n### For Fact-Checking\n\n1. **Be specific**: Target specific sections rather than entire books\n2. **Verify critical claims first**: Prioritize high-impact information\n3. **Cross-reference**: For important claims, verify across multiple sources\n4. **Update regularly**: Technical specs change frequently - recheck periodically\n\n## Development\n\nCreated with skill-creator v1.2.2 following Anthropic's best practices.\n\n**Testing:**\n- Verified on Claude Sonnet 4.5, Opus 4.5, and Haiku 4\n- Tested with real-world documentation updates\n- Validated correction workflow with user approval gates\n\n## Version History\n\n### 1.0.0 (2026-01-05)\n- Initial release\n- Support for AI models, technical docs, statistics\n- Auto-correction with user approval\n- Comprehensive source evaluation framework\n\n## License\n\nMIT License - See repository for details\n\n## Contributing\n\nIssues and pull requests welcome at [daymade/claude-code-skills](https://github.com/daymade/claude-code-skills)\n",
        "fact-checker/SKILL.md": "---\nname: fact-checker\ndescription: Verifies factual claims in documents using web search and official sources, then proposes corrections with user confirmation. Use when the user asks to fact-check, verify information, validate claims, check accuracy, or update outdated information in documents. Supports AI model specs, technical documentation, statistics, and general factual statements.\n---\n\n# Fact Checker\n\nVerify factual claims in documents and propose corrections backed by authoritative sources.\n\n## When to use\n\nTrigger when users request:\n- \"Fact-check this document\"\n- \"Verify these AI model specifications\"\n- \"Check if this information is still accurate\"\n- \"Update outdated data in this file\"\n- \"Validate the claims in this section\"\n\n## Workflow\n\nCopy this checklist to track progress:\n\n```\nFact-checking Progress:\n- [ ] Step 1: Identify factual claims\n- [ ] Step 2: Search authoritative sources\n- [ ] Step 3: Compare claims against sources\n- [ ] Step 4: Generate correction report\n- [ ] Step 5: Apply corrections with user approval\n```\n\n### Step 1: Identify factual claims\n\nScan the document for verifiable statements:\n\n**Target claim types:**\n- Technical specifications (context windows, pricing, features)\n- Version numbers and release dates\n- Statistical data and metrics\n- API capabilities and limitations\n- Benchmark scores and performance data\n\n**Skip subjective content:**\n- Opinions and recommendations\n- Explanatory prose\n- Tutorial instructions\n- Architectural discussions\n\n### Step 2: Search authoritative sources\n\nFor each claim, search official sources:\n\n**AI models:**\n- Official announcement pages (anthropic.com/news, openai.com/index, blog.google)\n- API documentation (platform.claude.com/docs, platform.openai.com/docs)\n- Developer guides and release notes\n\n**Technical libraries:**\n- Official documentation sites\n- GitHub repositories (releases, README)\n- Package registries (npm, PyPI, crates.io)\n\n**General claims:**\n- Academic papers and research\n- Government statistics\n- Industry standards bodies\n\n**Search strategy:**\n- Use model names + specification (e.g., \"Claude Opus 4.5 context window\")\n- Include current year for recent information\n- Verify from multiple sources when possible\n\n### Step 3: Compare claims against sources\n\nCreate a comparison table:\n\n| Claim in Document | Source Information | Status | Authoritative Source |\n|-------------------|-------------------|--------|---------------------|\n| Claude 3.5 Sonnet: 200K tokens | Claude Sonnet 4.5: 200K tokens | ‚ùå Outdated model name | platform.claude.com/docs |\n| GPT-4o: 128K tokens | GPT-5.2: 400K tokens | ‚ùå Incorrect version & spec | openai.com/index/gpt-5-2 |\n\n**Status codes:**\n- ‚úÖ Accurate - claim matches sources\n- ‚ùå Incorrect - claim contradicts sources\n- ‚ö†Ô∏è Outdated - claim was true but superseded\n- ‚ùì Unverifiable - no authoritative source found\n\n### Step 4: Generate correction report\n\nPresent findings in structured format:\n\n```markdown\n## Fact-Check Report\n\n### Summary\n- Total claims checked: X\n- Accurate: Y\n- Issues found: Z\n\n### Issues Requiring Correction\n\n#### Issue 1: Outdated AI Model Reference\n**Location:** Line 77-80 in docs/file.md\n**Current claim:** \"Claude 3.5 Sonnet: 200K tokens\"\n**Correction:** \"Claude Sonnet 4.5: 200K tokens\"\n**Source:** https://platform.claude.com/docs/en/build-with-claude/context-windows\n**Rationale:** Claude 3.5 Sonnet has been superseded by Claude Sonnet 4.5 (released Sept 2025)\n\n#### Issue 2: Incorrect Context Window\n**Location:** Line 79 in docs/file.md\n**Current claim:** \"GPT-4o: 128K tokens\"\n**Correction:** \"GPT-5.2: 400K tokens\"\n**Source:** https://openai.com/index/introducing-gpt-5-2/\n**Rationale:** 128K was output limit; context window is 400K. Model also updated to GPT-5.2\n```\n\n### Step 5: Apply corrections with user approval\n\n**Before making changes:**\n\n1. Show the correction report to the user\n2. Wait for explicit approval: \"Should I apply these corrections?\"\n3. Only proceed after confirmation\n\n**When applying corrections:**\n\n```python\n# Use Edit tool to update document\n# Example:\nEdit(\n    file_path=\"docs/03-ÂÜô‰ΩúËßÑËåÉ/AIËæÖÂä©ÂÜô‰π¶ÊñπÊ≥ïËÆ∫.md\",\n    old_string=\"- Claude 3.5 Sonnet: 200K tokensÔºàÁ∫¶ 15 ‰∏áÊ±âÂ≠óÔºâ\",\n    new_string=\"- Claude Sonnet 4.5: 200K tokensÔºàÁ∫¶ 15 ‰∏áÊ±âÂ≠óÔºâ\"\n)\n```\n\n**After corrections:**\n\n1. Verify all edits were applied successfully\n2. Note the correction summary (e.g., \"Updated 4 claims in section 2.1\")\n3. Remind user to commit changes\n\n## Search best practices\n\n### Query construction\n\n**Good queries** (specific, current):\n- \"Claude Opus 4.5 context window 2026\"\n- \"GPT-5.2 official release announcement\"\n- \"Gemini 3 Pro token limit specifications\"\n\n**Poor queries** (vague, generic):\n- \"Claude context\"\n- \"AI models\"\n- \"Latest version\"\n\n### Source evaluation\n\n**Prefer official sources:**\n1. Product official pages (highest authority)\n2. API documentation\n3. Official blog announcements\n4. GitHub releases (for open source)\n\n**Use with caution:**\n- Third-party aggregators (llm-stats.com, etc.) - verify against official sources\n- Blog posts and articles - cross-reference claims\n- Social media - only for announcements, verify elsewhere\n\n**Avoid:**\n- Outdated documentation\n- Unofficial wikis without citations\n- Speculation and rumors\n\n### Handling ambiguity\n\nWhen sources conflict:\n\n1. Prioritize most recent official documentation\n2. Note the discrepancy in the report\n3. Present both sources to the user\n4. Recommend contacting vendor if critical\n\nWhen no source found:\n\n1. Mark as ‚ùì Unverifiable\n2. Suggest alternative phrasing: \"According to [Source] as of [Date]...\"\n3. Recommend adding qualification: \"approximately\", \"reported as\"\n\n## Special considerations\n\n### Time-sensitive information\n\nAlways include temporal context:\n\n**Good corrections:**\n- \"Êà™Ëá≥ 2026 Âπ¥ 1 Êúà\" (As of January 2026)\n- \"Claude Sonnet 4.5 (released September 2025)\"\n\n**Poor corrections:**\n- \"Latest version\" (becomes outdated)\n- \"Current model\" (ambiguous timeframe)\n\n### Numerical precision\n\nMatch precision to source:\n\n**Source says:** \"approximately 1 million tokens\"\n**Write:** \"1M tokens (approximately)\"\n\n**Source says:** \"200,000 token context window\"\n**Write:** \"200K tokens\" (exact)\n\n### Citation format\n\nInclude citations in corrections:\n\n```markdown\n> **Ê≥®**ÔºöÂÖ∑‰Ωì‰∏ä‰∏ãÊñáÁ™óÂè£‰ª•Ê®°ÂûãÂÆòÊñπÊñáÊ°£‰∏∫ÂáÜÔºåÊú¨‰π¶ÂÜô‰ΩúÊó∂‰ΩøÁî® Claude Sonnet 4.5 ‰∏∫‰∏ªË¶ÅÂ∑•ÂÖ∑„ÄÇ\n```\n\nLink to sources when possible.\n\n## Examples\n\n### Example 1: Technical specification update\n\n**User request:** \"Fact-check the AI model context windows in section 2.1\"\n\n**Process:**\n1. Identify claims: Claude 3.5 Sonnet (200K), GPT-4o (128K), Gemini 1.5 Pro (2M)\n2. Search official docs for current models\n3. Find: Claude Sonnet 4.5, GPT-5.2, Gemini 3 Pro\n4. Generate report showing discrepancies\n5. Apply corrections after approval\n\n### Example 2: Statistical data verification\n\n**User request:** \"Verify the benchmark scores in chapter 5\"\n\n**Process:**\n1. Extract numerical claims\n2. Search for official benchmark publications\n3. Compare reported vs. source values\n4. Flag any discrepancies with source links\n5. Update with verified figures\n\n### Example 3: Version number validation\n\n**User request:** \"Check if these library versions are still current\"\n\n**Process:**\n1. List all version numbers mentioned\n2. Check package registries (npm, PyPI, etc.)\n3. Identify outdated versions\n4. Suggest updates with changelog references\n5. Update after user confirms\n\n## Quality checklist\n\nBefore completing fact-check:\n\n- [ ] All factual claims identified and categorized\n- [ ] Each claim verified against official sources\n- [ ] Sources are authoritative and current\n- [ ] Correction report is clear and actionable\n- [ ] Temporal context included where relevant\n- [ ] User approval obtained before changes\n- [ ] All edits verified successful\n- [ ] Summary provided to user\n\n## Limitations\n\n**This skill cannot:**\n- Verify subjective opinions or judgments\n- Access paywalled or restricted sources\n- Determine \"truth\" in disputed claims\n- Predict future specifications or features\n\n**For such cases:**\n- Note the limitation in the report\n- Suggest qualification language\n- Recommend user research or expert consultation\n",
        "github-contributor/SKILL.md": "---\nname: github-contributor\ndescription: Strategic guide for becoming an effective GitHub contributor. Covers opportunity discovery, project selection, high-quality PR creation, and reputation building. Use when looking to contribute to open-source projects, building GitHub presence, or learning contribution best practices.\n---\n\n# GitHub Contributor\n\nStrategic guide for becoming an effective GitHub contributor and building your open-source reputation.\n\n## The Strategy\n\n**Core insight**: Many open-source projects have room for improvement. By contributing high-quality PRs, you:\n- Build contributor reputation\n- Learn from top codebases\n- Expand professional network\n- Create public proof of skills\n\n## Contribution Types\n\n### 1. Documentation Improvements\n\n**Lowest barrier, high impact.**\n\n- Fix typos, grammar, unclear explanations\n- Add missing examples\n- Improve README structure\n- Translate documentation\n\n```\nOpportunity signals:\n- \"docs\", \"documentation\" labels\n- Issues asking \"how do I...\"\n- Outdated screenshots or examples\n```\n\n### 2. Code Quality Enhancements\n\n**Medium effort, demonstrates technical skill.**\n\n- Fix linter warnings\n- Add type annotations\n- Improve error messages\n- Refactor for readability\n\n```\nOpportunity signals:\n- \"good first issue\" label\n- \"tech debt\" or \"refactor\" labels\n- Code without tests\n```\n\n### 3. Bug Fixes\n\n**High impact, builds trust.**\n\n- Reproduce and fix reported bugs\n- Add regression tests\n- Document root cause\n\n```\nOpportunity signals:\n- \"bug\" label with reproduction steps\n- Issues with many thumbs up\n- Stale bugs (maintainers busy)\n```\n\n### 4. Feature Additions\n\n**Highest effort, highest visibility.**\n\n- Implement requested features\n- Add integrations\n- Performance improvements\n\n```\nOpportunity signals:\n- \"help wanted\" label\n- Features with clear specs\n- Issues linked to roadmap\n```\n\n## Project Selection\n\n### Good First Projects\n\n| Criteria | Why |\n|----------|-----|\n| Active maintainers | PRs get reviewed |\n| Clear contribution guide | Know expectations |\n| \"good first issue\" labels | Curated entry points |\n| Recent merged PRs | Project is alive |\n| Friendly community | Supportive feedback |\n\n### Red Flags\n\n- No activity in 6+ months\n- Many open PRs without review\n- Hostile issue discussions\n- No contribution guidelines\n\n### Finding Projects\n\n```bash\n# GitHub search for good first issues\ngh search issues \"good first issue\" --language=python --sort=created\n\n# Search by topic\ngh search repos \"topic:cli\" --sort=stars --limit=20\n\n# Find repos you use\n# Check dependencies in your projects\n```\n\n## PR Excellence\n\n### Before Writing Code\n\n```\nPre-PR Checklist:\n- [ ] Read CONTRIBUTING.md\n- [ ] Check existing PRs for similar changes\n- [ ] Comment on issue to claim it\n- [ ] Understand project conventions\n- [ ] Set up development environment\n```\n\n### Writing the PR\n\n**Title**: Clear, conventional format\n\n```\nfeat: Add support for YAML config files\nfix: Resolve race condition in connection pool\ndocs: Update installation instructions for Windows\nrefactor: Extract validation logic into separate module\n```\n\n**Description**: Structured and thorough\n\n```markdown\n## Summary\n[What this PR does in 1-2 sentences]\n\n## Motivation\n[Why this change is needed]\n\n## Changes\n- [Change 1]\n- [Change 2]\n\n## Testing\n[How you tested this]\n\n## Screenshots (if UI)\n[Before/After images]\n```\n\n### After Submitting\n\n- Respond to feedback promptly\n- Make requested changes quickly\n- Be grateful for reviews\n- Don't argue, discuss\n\n## Building Reputation\n\n### The Contribution Ladder\n\n```\nLevel 1: Documentation fixes\n    ‚Üì (build familiarity)\nLevel 2: Small bug fixes\n    ‚Üì (understand codebase)\nLevel 3: Feature contributions\n    ‚Üì (trusted contributor)\nLevel 4: Maintainer status\n```\n\n### Consistency Over Volume\n\n```\n‚ùå 10 PRs in one week, then nothing\n‚úÖ 1-2 PRs per week, sustained\n```\n\n### Engage Beyond PRs\n\n- Answer questions in issues\n- Help triage bug reports\n- Review others' PRs (if welcome)\n- Join project Discord/Slack\n\n## Common Mistakes\n\n### Don't\n\n- Submit drive-by PRs without context\n- Argue with maintainers\n- Ignore code style guidelines\n- Make massive changes without discussion\n- Ghost after submitting\n\n### Do\n\n- Start with small, focused PRs\n- Follow project conventions exactly\n- Communicate proactively\n- Accept feedback gracefully\n- Build relationships over time\n\n## Workflow Template\n\n```\nContribution Workflow:\n- [ ] Find project with \"good first issue\"\n- [ ] Read contribution guidelines\n- [ ] Comment on issue to claim\n- [ ] Fork and set up locally\n- [ ] Make focused changes\n- [ ] Test thoroughly\n- [ ] Write clear PR description\n- [ ] Respond to review feedback\n- [ ] Celebrate when merged! üéâ\n```\n\n## Quick Reference\n\n### GitHub CLI Commands\n\n```bash\n# Fork a repo\ngh repo fork owner/repo --clone\n\n# Create PR\ngh pr create --title \"feat: ...\" --body \"...\"\n\n# Check PR status\ngh pr status\n\n# View project issues\ngh issue list --repo owner/repo --label \"good first issue\"\n```\n\n### Commit Message Format\n\n```\n<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer]\n```\n\nTypes: `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`\n\n## References\n\n- `references/pr_checklist.md` - Complete PR quality checklist\n- `references/project_evaluation.md` - How to evaluate projects\n- `references/communication_templates.md` - Issue/PR templates\n",
        "github-ops/SKILL.md": "---\nname: github-ops\ndescription: Provides comprehensive GitHub operations using gh CLI and GitHub API. Activates when working with pull requests, issues, repositories, workflows, or GitHub API operations including creating/viewing/merging PRs, managing issues, querying API endpoints, and handling GitHub workflows in enterprise or public GitHub environments.\n---\n\n# GitHub Operations\n\n## Overview\n\nThis skill provides comprehensive guidance for GitHub operations using the `gh` CLI tool and GitHub REST/GraphQL APIs. Use this skill when performing any GitHub-related tasks including pull request management, issue tracking, repository operations, workflow automation, and API interactions.\n\n## When to Use This Skill\n\nThis skill activates for tasks involving:\n- Creating, viewing, editing, or merging pull requests\n- Managing GitHub issues or repository settings\n- Querying GitHub API endpoints (REST or GraphQL)\n- Working with GitHub Actions workflows\n- Performing bulk operations on repositories\n- Integrating with GitHub Enterprise\n- Automating GitHub operations via CLI or API\n\n## Core Operations\n\n### Pull Requests\n\n```bash\n# Create PR with NOJIRA prefix (bypasses JIRA enforcement checks)\ngh pr create --title \"NOJIRA: Your PR title\" --body \"PR description\"\n\n# List and view PRs\ngh pr list --state open\ngh pr view 123\n\n# Manage PRs\ngh pr merge 123 --squash\ngh pr review 123 --approve\ngh pr comment 123 --body \"LGTM\"\n```\n\nüìö See `references/pr_operations.md` for comprehensive PR workflows\n\n**PR Title Convention:**\n- With JIRA ticket: `GR-1234: Descriptive title`\n- Without JIRA ticket: `NOJIRA: Descriptive title`\n\n### Issues\n\n```bash\n# Create and manage issues\ngh issue create --title \"Bug: Issue title\" --body \"Issue description\"\ngh issue list --state open --label bug\ngh issue edit 456 --add-label \"priority-high\"\ngh issue close 456\n```\n\nüìö See `references/issue_operations.md` for detailed issue management\n\n### Repositories\n\n```bash\n# View and manage repos\ngh repo view --web\ngh repo clone owner/repo\ngh repo create my-new-repo --public\n```\n\n### Workflows\n\n```bash\n# Manage GitHub Actions\ngh workflow list\ngh workflow run workflow-name\ngh run watch run-id\ngh run download run-id\n```\n\nüìö See `references/workflow_operations.md` for advanced workflow operations\n\n### GitHub API\n\nThe `gh api` command provides direct access to GitHub REST API endpoints. Refer to `references/api_reference.md` for comprehensive API endpoint documentation.\n\n**Basic API operations:**\n```bash\n# Get PR details via API\ngh api repos/{owner}/{repo}/pulls/{pr_number}\n\n# Add PR comment\ngh api repos/{owner}/{repo}/issues/{pr_number}/comments \\\n  -f body=\"Comment text\"\n\n# List workflow runs\ngh api repos/{owner}/{repo}/actions/runs\n```\n\nFor complex queries requiring multiple related resources, use GraphQL. See `references/api_reference.md` for GraphQL examples.\n\n## Authentication and Configuration\n\n```bash\n# Login to GitHub\ngh auth login\n\n# Login to GitHub Enterprise\ngh auth login --hostname github.enterprise.com\n\n# Check authentication status\ngh auth status\n\n# Set default repository\ngh repo set-default owner/repo\n\n# Configure gh settings\ngh config set editor vim\ngh config set git_protocol ssh\ngh config list\n```\n\n## Output Formats\n\nControl output format for programmatic processing:\n\n```bash\n# JSON output\ngh pr list --json number,title,state,author\n\n# JSON with jq processing\ngh pr list --json number,title | jq '.[] | select(.title | contains(\"bug\"))'\n\n# Template output\ngh pr list --template '{{range .}}{{.number}}: {{.title}}{{\"\\n\"}}{{end}}'\n```\n\nüìö See `references/best_practices.md` for shell patterns and automation strategies\n\n## Quick Reference\n\n**Most Common Operations:**\n```bash\ngh pr create --title \"NOJIRA: Title\" --body \"Description\"  # Create PR\ngh pr list                                                  # List PRs\ngh pr view 123                                              # View PR details\ngh pr checks 123                                            # Check PR status\ngh pr merge 123 --squash                                    # Merge PR\ngh pr comment 123 --body \"LGTM\"                            # Comment on PR\ngh issue create --title \"Title\" --body \"Description\"       # Create issue\ngh workflow run workflow-name                               # Run workflow\ngh repo view --web                                          # Open repo in browser\ngh api repos/{owner}/{repo}/pulls/{pr_number}              # Direct API call\n```\n\n## Resources\n\n### references/pr_operations.md\n\nComprehensive pull request operations including:\n- Detailed PR creation patterns (JIRA integration, body from file, targeting branches)\n- Viewing and filtering strategies\n- Review workflows and approval patterns\n- PR lifecycle management\n- Bulk operations and automation examples\n\nLoad this reference when working with complex PR workflows or bulk operations.\n\n### references/issue_operations.md\n\nDetailed issue management examples including:\n- Issue creation with labels and assignees\n- Advanced filtering and search\n- Issue lifecycle and state management\n- Bulk operations on multiple issues\n- Integration with PRs and projects\n\nLoad this reference when managing issues at scale or setting up issue workflows.\n\n### references/workflow_operations.md\n\nAdvanced GitHub Actions workflow operations including:\n- Workflow triggers and manual runs\n- Run monitoring and debugging\n- Artifact management\n- Secrets and variables\n- Performance optimization strategies\n\nLoad this reference when working with CI/CD workflows or debugging failed runs.\n\n### references/best_practices.md\n\nShell scripting patterns and automation strategies including:\n- Output formatting (JSON, templates, jq)\n- Pagination and large result sets\n- Error handling and retry logic\n- Bulk operations and parallel execution\n- Enterprise GitHub patterns\n- Performance optimization\n\nLoad this reference when building automation scripts or handling enterprise deployments.\n\n### references/api_reference.md\n\nContains comprehensive GitHub REST API endpoint documentation including:\n- Complete API endpoint reference with examples\n- Request/response formats\n- Authentication patterns\n- Rate limiting guidance\n- Webhook configurations\n- Advanced GraphQL query patterns\n\nLoad this reference when performing complex API operations or when needing detailed endpoint specifications.\n",
        "i18n-expert/SKILL.md": "---\nname: i18n-expert\ndescription: This skill should be used when setting up, auditing, or enforcing internationalization/localization in UI codebases (React/TS, i18next or similar, JSON locales), including installing/configuring the i18n framework, replacing hard-coded strings, ensuring en-US/zh-CN coverage, mapping error codes to localized messages, and validating key parity, pluralization, and formatting.\n---\n\n# I18n Expert\n\n## Overview\n\nDeliver a complete i18n setup + audit pass: configure the i18n framework, replace user-facing strings with keys, ensure locale parity, and validate pluralization/formatting for en-US and zh-CN.\n\n## Core Capabilities\n\n- Library selection and setup (React, Next.js, Vue).\n- Key architecture and locale file organization.\n- Translation generation and quality strategy (AI, professional, manual).\n- Routing and language detection/switching.\n- SEO and metadata localization (when applicable).\n- RTL support (only if RTL locales are in scope).\n\n## Scope Inputs (ask if unclear)\n\n- Framework and routing style.\n- Existing i18n state (none, partial, legacy).\n- Target locales (default: en-US + zh-CN).\n- Translation quality needs (AI vs professional vs manual).\n- Locale formats in use (JSON, YAML, PO, XLIFF).\n- Formality/cultural requirements (if any).\n\n## Workflow (Audit -> Fix -> Validate)\n\n1) Confirm scope and locale targets\n- Identify the i18n framework and locale locations.\n- Confirm locales; default to en-US + zh-CN when specified.\n\n2) Setup i18n baseline (if missing)\n- Choose a framework-appropriate library (e.g., React: react-i18next; Next.js: next-intl; Vue: vue-i18n).\n- Install packages and create the i18n entry/config file.\n- Wire the provider at the app root and load locale resources.\n- Add a language switcher and persistence (route/param/localStorage) as appropriate.\n- Establish locale file layout and key namespaces.\n- If routing is locale-aware, define the locale segment strategy early (subpath, subdomain, query param).\n - If metadata is user-facing, include translation for titles/descriptions.\n\n3) Audit key usage and locale parity\n- Run:\n  ```bash\n  python scripts/i18n_audit.py --src <src-root> --locale <path/to/en-US.json> --locale <path/to/zh-CN.json>\n  ```\n- Treat missing keys/parity gaps as blockers.\n- Manually verify dynamic keys (`t(var)`).\n\n4) Find raw user-facing strings\n- Search:\n  ```bash\n  rg -n --glob '<src>/**/*.{ts,tsx,js,jsx}' \"<[^>]+>[^<{]*[A-Za-z][^<{]*<\"\n  rg -n --glob '<src>/**/*.{ts,tsx,js,jsx}' \"aria-label=\\\"[^\\\"]+\\\"|title=\\\"[^\\\"]+\\\"|placeholder=\\\"[^\\\"]+\\\"\"\n  ```\n- Localize accessibility labels.\n\n5) Replace strings with keys\n- Use `t('namespace.key')` for UI text.\n- For plurals use `t('key', { count })` + `_one/_other` keys.\n- Use Intl/app formatters for time/date/number.\n\n6) Localize error handling (critical)\n- Map error codes to localized keys; show localized UI only.\n- Log raw error details only.\n- Provide localized fallback for unknown codes.\n\n7) Update locale files\n- Add missing keys in both locales.\n- Keep placeholders consistent; avoid renames unless requested.\n- Generate translations using the agreed method; preserve placeholders and plural rules.\n\n8) Validate\n- Re-run the audit until missing/parity issues are zero.\n- Validate JSON (e.g., `python -m json.tool <file>`).\n- Update tests asserting visible text.\n\n## Guardrails\n\n- Never expose raw `error.message` to UI; show localized strings only.\n- Do not add extra locales unless explicitly requested.\n- Prefer structured namespaces (e.g., `errors.*`, `buttons.*`, `workspace.*`).\n- Keep translations concise and consistent.\n- Some technical/brand terms should remain untranslated (e.g., product name, API, MCP, Bash).\n\n## Deliverables (expected outputs)\n\n- i18n config/provider wiring.\n- Locale files for each target language.\n- Replaced UI strings with stable keys.\n- Language switcher and persistence (if applicable).\n- Updated tests for visible text.\n\n## Architecture Guidance (keep concise)\n\n- Key structure: prefer nested namespaces by area (e.g., `common.buttons.save`, `pricing.tier.pro`).\n- File layout: one file per locale or per-locale namespaces; keep keys in sync across locales.\n- Placeholders: preserve `{name}`/`{{name}}` exactly; validate plurals by locale rules.\n- Formatting: use Intl/app helpers for date, time, number, and list formatting.\n- SEO/metadata: localize titles and descriptions if the app exposes them.\n- RTL: only needed for RTL locales; use logical CSS properties and test layout.\n- Non-web surfaces (Electron main-process dialogs, CLI prompts, native menus) need localization too.\n\n## Performance Notes (short)\n\n- Lazy-load locale bundles when the app supports it.\n- Split large locale files by namespace.\n\n## Failure Modes (watchlist)\n\n- Missing translations: fall back to default locale and log warnings.\n- RTL layout issues: verify logical CSS and test pages.\n- SEO missing: ensure alternates and metadata are localized when applicable.\n\n## Validation Checklist (short)\n\n- No missing keys and no raw UI strings.\n- Locale switching works and persists.\n- Plurals and formatting verified in both locales.\n - Fallback locale configured.\n\n## Resources\n\n### scripts/\n- `scripts/i18n_audit.py`: Extracts `t('key')` usage and compares against locale JSON files.\n",
        "iOS-APP-developer/SKILL.md": "---\nname: developing-ios-apps\ndescription: Develops iOS applications with XcodeGen, SwiftUI, and SPM. Triggers on XcodeGen project.yml configuration, SPM dependency issues, device deployment problems, code signing errors, camera/AVFoundation debugging, iOS version compatibility, or \"Library not loaded @rpath\" framework errors. Use when building iOS apps, fixing Xcode build failures, or deploying to real devices.\n---\n\n# iOS App Development\n\nBuild, configure, and deploy iOS applications using XcodeGen and Swift Package Manager.\n\n## Critical Warnings\n\n| Issue | Cause | Solution |\n|-------|-------|----------|\n| \"Library not loaded: @rpath/Framework\" | XcodeGen doesn't auto-embed SPM dynamic frameworks | **Build in Xcode GUI first** (not xcodebuild). See [Troubleshooting](#spm-dynamic-framework-not-embedded) |\n| `xcodegen generate` loses signing | Overwrites project settings | Configure in `project.yml` target settings, not global |\n| Command-line signing fails | Free Apple ID limitation | Use Xcode GUI or paid developer account ($99/yr) |\n| \"Cannot be set when automaticallyAdjustsVideoMirroring is YES\" | Setting `isVideoMirrored` without disabling automatic | Set `automaticallyAdjustsVideoMirroring = false` first. See [Camera](#camera--avfoundation) |\n\n## Quick Reference\n\n| Task | Command |\n|------|---------|\n| Generate project | `xcodegen generate` |\n| Build simulator | `xcodebuild -destination 'platform=iOS Simulator,name=iPhone 17' build` |\n| Build device (paid account) | `xcodebuild -destination 'platform=iOS,name=DEVICE' -allowProvisioningUpdates build` |\n| Clean DerivedData | `rm -rf ~/Library/Developer/Xcode/DerivedData/PROJECT-*` |\n| Find device name | `xcrun xctrace list devices` |\n\n## XcodeGen Configuration\n\n### Minimal project.yml\n\n```yaml\nname: AppName\noptions:\n  bundleIdPrefix: com.company\n  deploymentTarget:\n    iOS: \"16.0\"\n\nsettings:\n  base:\n    SWIFT_VERSION: \"6.0\"\n\npackages:\n  SomePackage:\n    url: https://github.com/org/repo\n    from: \"1.0.0\"\n\ntargets:\n  AppName:\n    type: application\n    platform: iOS\n    sources:\n      - path: AppName\n    settings:\n      base:\n        INFOPLIST_FILE: AppName/Info.plist\n        PRODUCT_BUNDLE_IDENTIFIER: com.company.appname\n        CODE_SIGN_STYLE: Automatic\n        DEVELOPMENT_TEAM: TEAM_ID_HERE\n    dependencies:\n      - package: SomePackage\n```\n\n### Code Signing Configuration\n\n**Personal (free) account**: Works in Xcode GUI only. Command-line builds require paid account.\n\n```yaml\n# In target settings\nsettings:\n  base:\n    CODE_SIGN_STYLE: Automatic\n    DEVELOPMENT_TEAM: TEAM_ID  # Get from Xcode ‚Üí Settings ‚Üí Accounts\n```\n\n**Get Team ID**:\n```bash\nsecurity find-identity -v -p codesigning | head -3\n```\n\n## iOS Version Compatibility\n\n### API Changes by Version\n\n| iOS 17+ Only | iOS 16 Compatible |\n|--------------|-------------------|\n| `.onChange { old, new in }` | `.onChange { new in }` |\n| `ContentUnavailableView` | Custom VStack |\n| `AVAudioApplication` | `AVAudioSession` |\n| `@Observable` macro | `@ObservableObject` |\n| SwiftData | CoreData/Realm |\n\n### Lowering Deployment Target\n\n1. Update `project.yml`:\n```yaml\ndeploymentTarget:\n  iOS: \"16.0\"\n```\n\n2. Fix incompatible APIs:\n```swift\n// iOS 17\n.onChange(of: value) { oldValue, newValue in }\n// iOS 16\n.onChange(of: value) { newValue in }\n\n// iOS 17\nContentUnavailableView(\"Title\", systemImage: \"icon\")\n// iOS 16\nVStack {\n    Image(systemName: \"icon\").font(.system(size: 48))\n    Text(\"Title\").font(.title2.bold())\n}\n\n// iOS 17\nAVAudioApplication.shared.recordPermission\n// iOS 16\nAVAudioSession.sharedInstance().recordPermission\n```\n\n3. Regenerate: `xcodegen generate`\n\n## Device Deployment\n\n### First-time Setup\n\n1. Connect device via USB\n2. Trust computer on device\n3. In Xcode: Settings ‚Üí Accounts ‚Üí Add Apple ID\n4. Select device in scheme dropdown\n5. Run (`Cmd + R`)\n6. On device: Settings ‚Üí General ‚Üí VPN & Device Management ‚Üí Trust\n\n### Command-line Build (requires paid account)\n\n```bash\nxcodebuild \\\n  -project App.xcodeproj \\\n  -scheme App \\\n  -destination 'platform=iOS,name=DeviceName' \\\n  -allowProvisioningUpdates \\\n  build\n```\n\n### Common Issues\n\n| Error | Solution |\n|-------|----------|\n| \"Library not loaded: @rpath/Framework\" | SPM dynamic framework not embedded. Build in Xcode GUI first, then CLI works |\n| \"No Account for Team\" | Add Apple ID in Xcode Settings ‚Üí Accounts |\n| \"Provisioning profile not found\" | Free account limitation. Use Xcode GUI or get paid account |\n| Device not listed | Reconnect USB, trust computer on device, restart Xcode |\n| DerivedData won't delete | Close Xcode first: `pkill -9 Xcode && rm -rf ~/Library/Developer/Xcode/DerivedData/PROJECT-*` |\n\n### Free vs Paid Developer Account\n\n| Feature | Free Apple ID | Paid ($99/year) |\n|---------|---------------|-----------------|\n| Xcode GUI builds | ‚úÖ | ‚úÖ |\n| Command-line builds | ‚ùå | ‚úÖ |\n| App validity | 7 days | 1 year |\n| App Store | ‚ùå | ‚úÖ |\n| CI/CD | ‚ùå | ‚úÖ |\n\n## SPM Dependencies\n\n### SPM Dynamic Framework Not Embedded\n\n**Root Cause**: XcodeGen doesn't generate the \"Embed Frameworks\" build phase for SPM dynamic frameworks (like RealmSwift, Realm). The app builds successfully but crashes on launch with:\n\n```\ndyld: Library not loaded: @rpath/RealmSwift.framework/RealmSwift\n  Referenced from: /var/containers/Bundle/Application/.../App.app/App\n  Reason: image not found\n```\n\n**Why This Happens**:\n- Static frameworks (most SPM packages) are linked into the binary - no embedding needed\n- Dynamic frameworks (RealmSwift, etc.) must be copied into the app bundle\n- XcodeGen generates link phase but NOT embed phase for SPM packages\n- `embed: true` in project.yml causes build errors (XcodeGen limitation)\n\n**The Fix** (Manual, one-time per project):\n1. Open project in Xcode GUI\n2. Select target ‚Üí General ‚Üí Frameworks, Libraries\n3. Find the dynamic framework (RealmSwift)\n4. Change \"Do Not Embed\" ‚Üí \"Embed & Sign\"\n5. Build and run from Xcode GUI first\n\n**After Manual Fix**: Command-line builds (`xcodebuild`) will work because Xcode persists the embed setting in project.pbxproj.\n\n**Identifying Dynamic Frameworks**:\n```bash\n# Check if a framework is dynamic\nfile ~/Library/Developer/Xcode/DerivedData/PROJECT-*/Build/Products/Debug-iphoneos/FRAMEWORK.framework/FRAMEWORK\n# Dynamic: \"Mach-O 64-bit dynamically linked shared library\"\n# Static: \"current ar archive\"\n```\n\n### Adding Packages\n\n```yaml\npackages:\n  AudioKit:\n    url: https://github.com/AudioKit/AudioKit\n    from: \"5.6.5\"\n  RealmSwift:\n    url: https://github.com/realm/realm-swift\n    from: \"10.54.6\"\n\ntargets:\n  App:\n    dependencies:\n      - package: AudioKit\n      - package: RealmSwift\n        product: RealmSwift  # Explicit product name when package has multiple\n```\n\n### Resolving Dependencies (China proxy)\n\n```bash\ngit config --global http.proxy http://127.0.0.1:1082\ngit config --global https.proxy http://127.0.0.1:1082\nxcodebuild -scmProvider system -resolvePackageDependencies\n```\n\n**Never clear global SPM cache** (`~/Library/Caches/org.swift.swiftpm`). Re-downloading is slow.\n\n## Camera / AVFoundation\n\nCamera preview requires real device (simulator has no camera).\n\n### Quick Debugging Checklist\n\n1. **Permission**: Added `NSCameraUsageDescription` to Info.plist?\n2. **Device**: Running on real device, not simulator?\n3. **Session running**: `session.startRunning()` called on background thread?\n4. **View size**: UIViewRepresentable has non-zero bounds?\n5. **Video mirroring**: Disabled `automaticallyAdjustsVideoMirroring` before setting `isVideoMirrored`?\n\n### Video Mirroring (Front Camera)\n\n**CRITICAL**: Must disable automatic adjustment before setting manual mirroring:\n\n```swift\n// WRONG - crashes with \"Cannot be set when automaticallyAdjustsVideoMirroring is YES\"\nconnection.isVideoMirrored = true\n\n// CORRECT - disable automatic first\nconnection.automaticallyAdjustsVideoMirroring = false\nconnection.isVideoMirrored = true\n```\n\n### UIViewRepresentable Sizing Issue\n\nUIViewRepresentable in ZStack may have zero bounds. Fix with explicit frame:\n\n```swift\n// BAD: UIViewRepresentable may get zero size in ZStack\nZStack {\n    CameraPreviewView(session: session)  // May be invisible!\n    OtherContent()\n}\n\n// GOOD: Explicit sizing\nZStack {\n    GeometryReader { geo in\n        CameraPreviewView(session: session)\n            .frame(width: geo.size.width, height: geo.size.height)\n    }\n    .ignoresSafeArea()\n    OtherContent()\n}\n```\n\n### Debug Logging Pattern\n\nAdd logging to trace camera flow:\n\n```swift\nimport os\nprivate let logger = Logger(subsystem: \"com.app\", category: \"Camera\")\n\nfunc start() async {\n    logger.info(\"start() called, isRunning=\\(self.isRunning)\")\n    // ... setup code ...\n    logger.info(\"session.startRunning() completed\")\n}\n\n// For CGRect (doesn't conform to CustomStringConvertible)\nlogger.info(\"bounds=\\(NSCoder.string(for: self.bounds))\")\n```\n\nFilter in Console.app by subsystem.\n\n**For detailed camera implementation**: See [references/camera-avfoundation.md](references/camera-avfoundation.md)\n\n## Resources\n\n- [references/xcodegen-full.md](references/xcodegen-full.md) - Complete project.yml options\n- [references/swiftui-compatibility.md](references/swiftui-compatibility.md) - iOS version API differences\n- [references/camera-avfoundation.md](references/camera-avfoundation.md) - Camera preview debugging\n- [references/testing-mainactor.md](references/testing-mainactor.md) - Testing @MainActor classes (state machines, regression tests)\n",
        "llm-icon-finder/SKILL.md": "---\nname: llm-icon-finder\ndescription: Finding and accessing AI/LLM model brand icons from lobe-icons library. Use when users need icon URLs, want to download brand logos for AI models/providers/applications (Claude, GPT, Gemini, etc.), or request icons in SVG/PNG/WEBP formats.\n---\n\n# Finding AI/LLM Brand Icons\n\nAccess AI/LLM model brand icons and logos from the [lobe-icons](https://github.com/lobehub/lobe-icons) library. The library contains 100+ icons for models (Claude, GPT, Gemini), providers (OpenAI, Anthropic, Google), and applications (ComfyUI, LobeChat).\n\n## Icon Formats and Variants\n\n**Available formats**: SVG (scalable), PNG (raster), WEBP (compressed)\n**Theme variants**: light, dark, and color (some icons)\n\n## CDN URL Patterns\n\nConstruct URLs using these patterns:\n\n```\n# SVG\nhttps://raw.githubusercontent.com/lobehub/lobe-icons/refs/heads/master/packages/static-svg/{light|dark}/{icon-name}.svg\n\n# PNG\nhttps://raw.githubusercontent.com/lobehub/lobe-icons/refs/heads/master/packages/static-png/{light|dark}/{icon-name}.png\n\n# WEBP\nhttps://raw.githubusercontent.com/lobehub/lobe-icons/refs/heads/master/packages/static-webp/{light|dark}/{icon-name}.webp\n\n# Color variant (append -color to icon-name)\nhttps://raw.githubusercontent.com/lobehub/lobe-icons/refs/heads/master/packages/static-png/dark/{icon-name}-color.png\n```\n\n**Icon naming convention**: Lowercase, hyphenated (e.g., `claude`, `chatglm`, `openai`, `huggingface`)\n\n## Workflow\n\nWhen users request icons:\n\n1. Identify icon name (usually lowercase company/model name, hyphenated if multi-word)\n2. Determine format (default: PNG) and theme (default: dark)\n3. Construct CDN URL using pattern above\n4. Provide URL to user\n5. If download requested, use Bash tool with curl\n6. Include web viewer link: `https://lobehub.com/icons/{icon-name}`\n\n## Finding Icon Names\n\n**Common icons**: See `references/icons-list.md` for comprehensive list organized by category (Models, Providers, Applications, Chinese AI)\n\n**Uncertain names**:\n- Browse https://lobehub.com/icons\n- Try variations (e.g., company name vs product name: `alibaba` vs `alibabacloud`)\n- Check for `-color` variants if standard URL fails\n\n**Chinese AI models**: Support Chinese queries (e.g., \"Êô∫Ë∞±\" ‚Üí `chatglm`, \"Êúà‰πãÊöóÈù¢\" ‚Üí `moonshot`)\n\n## Examples\n\n**Single icon request**:\n```\nUser: \"Claude icon\"\n‚Üí Provide: https://raw.githubusercontent.com/lobehub/lobe-icons/refs/heads/master/packages/static-png/dark/claude.png\n‚Üí Also mention color variant and web viewer link\n```\n\n**Multiple icons download**:\n```bash\ncurl -o openai.svg \"https://raw.githubusercontent.com/lobehub/lobe-icons/.../dark/openai.svg\"\ncurl -o anthropic.svg \"https://raw.githubusercontent.com/lobehub/lobe-icons/.../dark/anthropic.svg\"\n```\n\n**Chinese query**:\n```\nUser: \"Êâæ‰∏Ä‰∏ãÊô∫Ë∞±ÁöÑÂõæÊ†á\"\n‚Üí Identify: Êô∫Ë∞± = ChatGLM ‚Üí icon name: chatglm\n‚Üí Provide URLs and mention related icons (zhipu, codegeex)\n```\n\n## Troubleshooting\n\nIf URL returns 404:\n1. Try `-color` suffix variant\n2. Check alternate naming (e.g., `chatgpt` vs `gpt`, `google` vs `gemini`)\n3. Direct user to https://lobehub.com/icons to browse\n4. Search repository: https://github.com/lobehub/lobe-icons\n\n## Reference Files\n\n- `references/icons-list.md` - Comprehensive list of 100+ available icons by category\n- `references/developer-info.md` - npm installation and React usage examples\n",
        "macos-cleaner/SKILL.md": "---\nname: macos-cleaner\ndescription: Analyze and reclaim macOS disk space through intelligent cleanup recommendations. This skill should be used when users report disk space issues, need to clean up their Mac, or want to understand what's consuming storage. Focus on safe, interactive analysis with user confirmation before any deletions.\n---\n\n# macOS Cleaner\n\n## Overview\n\nIntelligently analyze macOS disk usage and provide actionable cleanup recommendations to reclaim storage space. This skill follows a **safety-first philosophy**: analyze thoroughly, present clear findings, and require explicit user confirmation before executing any deletions.\n\n**Target users**: Users with basic technical knowledge who understand file systems but need guidance on what's safe to delete on macOS.\n\n## Core Principles\n\n1. **Safety First, Never Bypass**: NEVER execute dangerous commands (`rm -rf`, `mo clean`, etc.) without explicit user confirmation. No shortcuts, no workarounds.\n2. **Value Over Vanity**: Your goal is NOT to maximize cleaned space. Your goal is to identify what is **truly useless** vs **valuable cache**. Clearing 50GB of useful cache just to show a big number is harmful.\n3. **Network Environment Awareness**: Many users (especially in China) have slow/unreliable internet. Re-downloading caches can take hours. A cache that saves 30 minutes of download time is worth keeping.\n4. **Impact Analysis Required**: Every cleanup recommendation MUST include \"what happens if deleted\" column. Never just list items without explaining consequences.\n5. **Patience Over Speed**: Disk scans can take 5-10 minutes. NEVER interrupt or skip slow operations. Report progress to user regularly.\n6. **User Executes Cleanup**: After analysis, provide the cleanup command for the user to run themselves. Do NOT auto-execute cleanup.\n7. **Conservative Defaults**: When in doubt, don't delete. Err on the side of caution.\n\n**ABSOLUTE PROHIBITIONS:**\n- ‚ùå NEVER run `rm -rf` on user directories automatically\n- ‚ùå NEVER run `mo clean` without dry-run preview first\n- ‚ùå NEVER use `docker volume prune -f` or `docker system prune -a --volumes`\n- ‚ùå NEVER skip analysis steps to save time\n- ‚ùå NEVER append `--help` to Mole commands (except `mo --help`)\n- ‚ùå NEVER recommend deleting useful caches just to inflate cleanup numbers\n\n## Workflow Decision Tree\n\n```\nUser reports disk space issues\n           ‚Üì\n    Quick Diagnosis\n           ‚Üì\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ             ‚îÇ\nImmediate    Deep Analysis\n Cleanup      (continue below)\n    ‚îÇ             ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n           ‚Üì\n  Present Findings\n           ‚Üì\n   User Confirms\n           ‚Üì\n   Execute Cleanup\n           ‚Üì\n  Verify Results\n```\n\n## Step 1: Quick Diagnosis with Mole\n\n**Primary tool**: Use Mole for disk analysis. It provides comprehensive, categorized results.\n\n### 1.1 Pre-flight Checks\n\n```bash\n# Check Mole installation and version\nwhich mo && mo --version\n\n# If not installed\nbrew install tw93/tap/mole\n\n# Check for updates (Mole updates frequently)\nbrew info tw93/tap/mole | head -5\n\n# Upgrade if outdated\nbrew upgrade tw93/tap/mole\n```\n\n### 1.2 Choose Analysis Method\n\n**IMPORTANT**: Use `mo analyze` as the primary analysis tool, NOT `mo clean --dry-run`.\n\n| Command | Purpose | Use When |\n|---------|---------|----------|\n| `mo analyze` | Interactive disk usage explorer (TUI tree view) | **PRIMARY**: Understanding what's consuming space |\n| `mo clean --dry-run` | Preview cleanup categories | **SECONDARY**: Only after `mo analyze` to see cleanup preview |\n\n**Why prefer `mo analyze`:**\n- Dedicated disk analysis tool with interactive tree navigation\n- Allows drilling down into specific directories\n- Shows actual disk usage breakdown, not just cleanup categories\n- More informative for understanding storage consumption\n\n### 1.3 Run Analysis via tmux\n\n**IMPORTANT**: Mole requires TTY. Always use tmux from Claude Code.\n\n**CRITICAL TIMING NOTE**: Home directory scans are SLOW (5-10 minutes or longer for large directories). Inform user upfront and wait patiently.\n\n```bash\n# Create tmux session\ntmux new-session -d -s mole -x 120 -y 40\n\n# Run disk analysis (PRIMARY tool - interactive TUI)\ntmux send-keys -t mole 'mo analyze' Enter\n\n# Wait for scan - BE PATIENT!\n# Home directory scanning typically takes 5-10 minutes\n# Report progress to user regularly\nsleep 60 && tmux capture-pane -t mole -p\n\n# Navigate the TUI with arrow keys\ntmux send-keys -t mole Down    # Move to next item\ntmux send-keys -t mole Enter   # Expand/select item\ntmux send-keys -t mole 'q'     # Quit when done\n```\n\n**Alternative: Cleanup preview (use AFTER mo analyze)**\n```bash\n# Run dry-run preview (SAFE - no deletion)\ntmux send-keys -t mole 'mo clean --dry-run' Enter\n\n# Wait for scan (report progress to user every 30 seconds)\n# Be patient! Large directories take 5-10 minutes\nsleep 30 && tmux capture-pane -t mole -p\n```\n\n### 1.4 Progress Reporting\n\nReport scan progress to user regularly:\n\n```\nüìä Disk Analysis in Progress...\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚è±Ô∏è Elapsed: 2 minutes\n\nCurrent status:\n‚úÖ Applications: 49.5 GB (complete)\n‚úÖ System Library: 10.3 GB (complete)\n‚è≥ Home: scanning... (this may take 5-10 minutes)\n‚è≥ App Library: pending\n\nI'm waiting patiently for the scan to complete.\nWill report again in 30 seconds...\n```\n\n### 1.5 Present Final Findings\n\nAfter scan completes, present structured results:\n\n```\nüìä Disk Space Analysis (via Mole)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nFree space: 27 GB\n\nüßπ Recoverable Space (dry-run preview):\n\n‚û§ User Essentials\n  ‚Ä¢ User app cache:     16.67 GB\n  ‚Ä¢ User app logs:      102.3 MB\n  ‚Ä¢ Trash:              642.9 MB\n\n‚û§ Browser Caches\n  ‚Ä¢ Chrome cache:       1.90 GB\n  ‚Ä¢ Safari cache:       4 KB\n\n‚û§ Developer Tools\n  ‚Ä¢ uv cache:           9.96 GB\n  ‚Ä¢ npm cache:          (detected)\n  ‚Ä¢ Docker cache:       (detected)\n  ‚Ä¢ Homebrew cache:     (detected)\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nTotal recoverable: ~30 GB\n\n‚ö†Ô∏è This was a dry-run preview. No files were deleted.\n```\n\n## Step 2: Deep Analysis Categories\n\nScan the following categories systematically. Reference `references/cleanup_targets.md` for detailed explanations.\n\n### Category 1: System & Application Caches\n\n**Locations to analyze:**\n- `~/Library/Caches/*` - User application caches\n- `/Library/Caches/*` - System-wide caches (requires sudo)\n- `~/Library/Logs/*` - Application logs\n- `/var/log/*` - System logs (requires sudo)\n\n**Analysis script:**\n```bash\nscripts/analyze_caches.py --user-only\n```\n\n**Safety level**: üü¢ Generally safe to delete (apps regenerate caches)\n\n**Exceptions to preserve:**\n- Browser caches while browser is running\n- IDE caches (may slow down next startup)\n- Package manager caches (Homebrew, pip, npm)\n\n### Category 2: Application Remnants\n\n**Locations to analyze:**\n- `~/Library/Application Support/*` - App data\n- `~/Library/Preferences/*` - Preference files\n- `~/Library/Containers/*` - Sandboxed app data\n\n**Analysis approach:**\n1. List installed applications in `/Applications`\n2. Cross-reference with `~/Library/Application Support`\n3. Identify orphaned folders (app uninstalled but data remains)\n\n**Analysis script:**\n```bash\nscripts/find_app_remnants.py\n```\n\n**Safety level**: üü° Caution required\n- ‚úÖ Safe: Folders for clearly uninstalled apps\n- ‚ö†Ô∏è Check first: Folders for apps you rarely use\n- ‚ùå Keep: Active application data\n\n### Category 3: Large Files & Duplicates\n\n**Analysis script:**\n```bash\nscripts/analyze_large_files.py --threshold 100MB --path ~\n```\n\n**Find duplicates (optional, resource-intensive):**\n```bash\n# Use fdupes if installed\nif command -v fdupes &> /dev/null; then\n  fdupes -r ~/Documents ~/Downloads\nfi\n```\n\n**Present findings:**\n```\nüì¶ Large Files (>100MB):\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n1. movie.mp4                    4.2 GB  ~/Downloads\n2. dataset.csv                  1.8 GB  ~/Documents/data\n3. old_backup.zip               1.5 GB  ~/Desktop\n...\n\nüîÅ Duplicate Files:\n- screenshot.png (3 copies)     15 MB each\n- document_v1.docx (2 copies)   8 MB each\n```\n\n**Safety level**: üü° User judgment required\n\n### Category 4: Development Environment Cleanup\n\n**Targets:**\n- Docker: images, containers, volumes, build cache\n- Homebrew: cache, old versions\n- Node.js: `node_modules`, npm cache\n- Python: pip cache, `__pycache__`, venv\n- Git: `.git` folders in archived projects\n\n**Analysis script:**\n```bash\nscripts/analyze_dev_env.py\n```\n\n**Example findings:**\n```\nüê≥ Docker Resources:\n- Unused images:      12 GB\n- Stopped containers:  2 GB\n- Build cache:         8 GB\n- Orphaned volumes:    3 GB\nTotal potential:      25 GB\n\nüì¶ Package Managers:\n- Homebrew cache:      5 GB\n- npm cache:           3 GB\n- pip cache:           1 GB\nTotal potential:       9 GB\n\nüóÇÔ∏è  Old Projects:\n- archived-project-2022/.git  500 MB\n- old-prototype/.git          300 MB\n```\n\n**Cleanup commands (require confirmation):**\n```bash\n# Homebrew cleanup (safe)\nbrew cleanup -s\n\n# npm _npx only (safe - temporary packages)\nrm -rf ~/.npm/_npx\n\n# pip cache (use with caution)\npip cache purge\n```\n\n**Docker cleanup - SPECIAL HANDLING REQUIRED:**\n\n‚ö†Ô∏è **NEVER use these commands:**\n```bash\n# ‚ùå DANGEROUS - deletes ALL volumes without confirmation\ndocker volume prune -f\ndocker system prune -a --volumes\n```\n\n‚úÖ **Correct approach - per-volume confirmation:**\n```bash\n# 1. List all volumes\ndocker volume ls\n\n# 2. Identify which projects each volume belongs to\ndocker volume inspect <volume_name>\n\n# 3. Ask user to confirm EACH project they want to delete\n# Example: \"Do you want to delete all volumes for 'ragflow' project?\"\n\n# 4. Delete specific volumes only after confirmation\ndocker volume rm ragflow_mysql_data ragflow_redis_data\n```\n\n**Safety level**: üü¢ Homebrew/npm cleanup, üî¥ Docker volumes require per-project confirmation\n\n## Step 3: Integration with Mole\n\n**Mole** (https://github.com/tw93/Mole) is a **command-line interface (CLI)** tool for comprehensive macOS cleanup. It provides interactive terminal-based analysis and cleanup for caches, logs, developer tools, and more.\n\n**CRITICAL REQUIREMENTS:**\n\n1. **TTY Environment**: Mole requires a TTY for interactive commands. Use `tmux` when running from Claude Code or scripts.\n2. **Version Check**: Always verify Mole is up-to-date before use.\n3. **Safe Help Command**: Only `mo --help` is safe. Do NOT append `--help` to other commands.\n\n**Installation check and upgrade:**\n\n```bash\n# Check if installed and get version\nwhich mo && mo --version\n\n# If not installed\nbrew install tw93/tap/mole\n\n# Check for updates\nbrew info tw93/tap/mole | head -5\n\n# Upgrade if needed\nbrew upgrade tw93/tap/mole\n```\n\n**Using Mole with tmux (REQUIRED for Claude Code):**\n\n```bash\n# Create tmux session for TTY environment\ntmux new-session -d -s mole -x 120 -y 40\n\n# Run analysis (safe, read-only)\ntmux send-keys -t mole 'mo analyze' Enter\n\n# Wait for scan (be patient - can take 5-10 minutes for large directories)\nsleep 60\n\n# Capture results\ntmux capture-pane -t mole -p\n\n# Cleanup when done\ntmux kill-session -t mole\n```\n\n**Available commands (from `mo --help`):**\n\n| Command | Safety | Description |\n|---------|--------|-------------|\n| `mo --help` | ‚úÖ Safe | View all commands (ONLY safe help) |\n| `mo analyze` | ‚úÖ Safe | Disk usage explorer (read-only) |\n| `mo status` | ‚úÖ Safe | System health monitor |\n| `mo clean --dry-run` | ‚úÖ Safe | Preview cleanup (no deletion) |\n| `mo clean` | ‚ö†Ô∏è DANGEROUS | Actually deletes files |\n| `mo purge` | ‚ö†Ô∏è DANGEROUS | Remove project artifacts |\n| `mo uninstall` | ‚ö†Ô∏è DANGEROUS | Remove applications |\n\n**Reference guide:**\nSee `references/mole_integration.md` for detailed tmux workflow and troubleshooting.\n\n## Multi-Layer Deep Exploration with Mole\n\n**CRITICAL**: For comprehensive analysis, you MUST perform multi-layer exploration, not just top-level scans. This section documents the proven workflow for navigating Mole's TUI.\n\n### Navigation Commands\n\n```bash\n# Create session\ntmux new-session -d -s mole -x 120 -y 40\n\n# Start analysis\ntmux send-keys -t mole 'mo analyze' Enter\n\n# Wait for initial scan\nsleep 8 && tmux capture-pane -t mole -p\n\n# Navigation keys (send via tmux)\ntmux send-keys -t mole Enter    # Enter/expand selected directory\ntmux send-keys -t mole Left     # Go back to parent directory\ntmux send-keys -t mole Down     # Move to next item\ntmux send-keys -t mole Up       # Move to previous item\ntmux send-keys -t mole 'q'      # Quit TUI\n\n# Capture current view\ntmux capture-pane -t mole -p\n```\n\n### Multi-Layer Exploration Workflow\n\n**Step 1: Top-level overview**\n```bash\n# Start mo analyze, wait for initial menu\ntmux send-keys -t mole 'mo analyze' Enter\nsleep 8 && tmux capture-pane -t mole -p\n\n# Example output:\n# 1. Home           289.4 GB (58.5%)\n# 2. App Library    145.2 GB (29.4%)\n# 3. Applications    49.5 GB (10.0%)\n# 4. System Library  10.3 GB (2.1%)\n```\n\n**Step 2: Enter largest directory (Home)**\n```bash\ntmux send-keys -t mole Enter\nsleep 10 && tmux capture-pane -t mole -p\n\n# Example output:\n# 1. Library       144.4 GB (49.9%)\n# 2. Workspace      52.0 GB (18.0%)\n# 3. .cache         19.3 GB (6.7%)\n# 4. Applications   17.0 GB (5.9%)\n# ...\n```\n\n**Step 3: Drill into specific directories**\n```bash\n# Go to .cache (3rd item: Down Down Enter)\ntmux send-keys -t mole Down Down Enter\nsleep 5 && tmux capture-pane -t mole -p\n\n# Example output:\n# 1. uv           10.3 GB (55.6%)\n# 2. modelscope    5.5 GB (29.5%)\n# 3. huggingface   887.8 MB (4.7%)\n```\n\n**Step 4: Navigate back and explore another branch**\n```bash\n# Go back to parent\ntmux send-keys -t mole Left\nsleep 2\n\n# Navigate to different directory\ntmux send-keys -t mole Down Down Down Down Enter  # Go to .npm\nsleep 5 && tmux capture-pane -t mole -p\n```\n\n**Step 5: Deep dive into Library**\n```bash\n# Back to Home, then into Library\ntmux send-keys -t mole Left\ntmux send-keys -t mole Up Up Up Up Up Up Enter  # Go to Library\nsleep 10 && tmux capture-pane -t mole -p\n\n# Example output:\n# 1. Application Support  37.1 GB\n# 2. Containers          35.4 GB\n# 3. Developer           17.8 GB  ‚Üê Xcode is here\n# 4. Caches               8.2 GB\n```\n\n### Recommended Exploration Path\n\nFor comprehensive analysis, follow this exploration tree:\n\n```\nmo analyze\n‚îú‚îÄ‚îÄ Home (Enter)\n‚îÇ   ‚îú‚îÄ‚îÄ Library (Enter)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Developer (Enter) ‚Üí Xcode/DerivedData, iOS DeviceSupport\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Caches (Enter) ‚Üí Playwright, JetBrains, etc.\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Application Support (Enter) ‚Üí App data\n‚îÇ   ‚îú‚îÄ‚îÄ .cache (Enter) ‚Üí uv, modelscope, huggingface\n‚îÇ   ‚îú‚îÄ‚îÄ .npm (Enter) ‚Üí _cacache, _npx\n‚îÇ   ‚îú‚îÄ‚îÄ Downloads (Enter) ‚Üí Large files to review\n‚îÇ   ‚îú‚îÄ‚îÄ .Trash (Enter) ‚Üí Confirm trash contents\n‚îÇ   ‚îî‚îÄ‚îÄ miniconda3/other dev tools (Enter) ‚Üí Check last used time\n‚îú‚îÄ‚îÄ App Library ‚Üí Usually overlaps with ~/Library\n‚îî‚îÄ‚îÄ Applications ‚Üí Installed apps\n```\n\n### Time Expectations\n\n| Directory | Scan Time | Notes |\n|-----------|-----------|-------|\n| Top-level menu | 5-8 seconds | Fast |\n| Home directory | 5-10 minutes | Large, be patient |\n| ~/Library | 3-5 minutes | Many small files |\n| Subdirectories | 2-30 seconds | Varies by size |\n\n### Example Complete Session\n\n```bash\n# 1. Create session\ntmux new-session -d -s mole -x 120 -y 40\n\n# 2. Start analysis and get overview\ntmux send-keys -t mole 'mo analyze' Enter\nsleep 8 && tmux capture-pane -t mole -p\n\n# 3. Enter Home\ntmux send-keys -t mole Enter\nsleep 10 && tmux capture-pane -t mole -p\n\n# 4. Enter .cache to see dev caches\ntmux send-keys -t mole Down Down Enter\nsleep 5 && tmux capture-pane -t mole -p\n\n# 5. Back to Home, then to .npm\ntmux send-keys -t mole Left\nsleep 2\ntmux send-keys -t mole Down Down Down Down Enter\nsleep 5 && tmux capture-pane -t mole -p\n\n# 6. Back to Home, enter Library\ntmux send-keys -t mole Left\nsleep 2\ntmux send-keys -t mole Up Up Up Up Up Up Enter\nsleep 10 && tmux capture-pane -t mole -p\n\n# 7. Enter Developer to see Xcode\ntmux send-keys -t mole Down Down Down Enter\nsleep 5 && tmux capture-pane -t mole -p\n\n# 8. Enter Xcode\ntmux send-keys -t mole Enter\nsleep 5 && tmux capture-pane -t mole -p\n\n# 9. Enter DerivedData to see projects\ntmux send-keys -t mole Enter\nsleep 5 && tmux capture-pane -t mole -p\n\n# 10. Cleanup\ntmux kill-session -t mole\n```\n\n### Key Insights from Exploration\n\nAfter multi-layer exploration, you will discover:\n\n1. **What projects are using DerivedData** - specific project names\n2. **Which caches are actually large** - uv vs npm vs others\n3. **Age of files** - Mole shows \">3mo\", \">7mo\", \">1yr\" markers\n4. **Specific volumes and their purposes** - Docker project data\n5. **Downloads that can be cleaned** - old dmgs, duplicate files\n\n## Anti-Patterns: What NOT to Delete\n\n**CRITICAL**: The following items are often suggested for cleanup but should NOT be deleted in most cases. They provide significant value that outweighs the space they consume.\n\n### Items to KEEP (Anti-Patterns)\n\n| Item | Size | Why NOT to Delete | Real Impact of Deletion |\n|------|------|-------------------|------------------------|\n| **Xcode DerivedData** | 10+ GB | Build cache saves 10-30 min per full rebuild | Next build takes 10-30 minutes longer |\n| **npm _cacache** | 5+ GB | Downloaded packages cached locally | `npm install` redownloads everything (30min-2hr in China) |\n| **~/.cache/uv** | 10+ GB | Python package cache | Every Python project reinstalls deps from PyPI |\n| **Playwright browsers** | 3-4 GB | Browser binaries for automation testing | Redownload 2GB+ each time (30min-1hr) |\n| **iOS DeviceSupport** | 2-3 GB | Required for device debugging | Redownload from Apple when connecting device |\n| **Docker stopped containers** | <500 MB | May restart anytime with `docker start` | Lose container state, need to recreate |\n| **~/.cache/huggingface** | varies | AI model cache | Redownload large models (hours) |\n| **~/.cache/modelscope** | varies | AI model cache (China) | Same as above |\n| **JetBrains caches** | 1+ GB | IDE indexing and caches | IDE takes 5-10 min to re-index |\n\n### Why This Matters\n\n**The vanity trap**: Showing \"Cleaned 50GB!\" feels good but:\n- User spends next 2 hours redownloading npm packages\n- Next Xcode build takes 30 minutes instead of 30 seconds\n- AI project fails because models need redownload\n\n**The right mindset**: \"I found 50GB of caches. Here's why most of them are actually valuable and should be kept...\"\n\n### What IS Actually Safe to Delete\n\n| Item | Why Safe | Impact |\n|------|----------|--------|\n| **Trash** | User already deleted these files | None - user's decision |\n| **Homebrew old versions** | Replaced by newer versions | Rare: can't rollback to old version |\n| **npm _npx** | Temporary npx executions | Minor: npx re-downloads on next use |\n| **Orphaned app remnants** | App already uninstalled | None - app doesn't exist |\n| **Specific unused Docker volumes** | Projects confirmed abandoned | None - if truly abandoned |\n\n## Report Format Requirements\n\nEvery cleanup report MUST follow this format with impact analysis:\n\n```markdown\n## Disk Analysis Report\n\n### Classification Legend\n| Symbol | Meaning |\n|--------|---------|\n| üü¢ | **Absolutely Safe** - No negative impact, truly unused |\n| üü° | **Trade-off Required** - Useful cache, deletion has cost |\n| üî¥ | **Do Not Delete** - Contains valuable data or actively used |\n\n### Findings\n\n| Item | Size | Classification | What It Is | Impact If Deleted |\n|------|------|----------------|------------|-------------------|\n| Trash | 643 MB | üü¢ | Files you deleted | None |\n| npm _npx | 2.1 GB | üü¢ | Temp npx packages | Minor redownload |\n| npm _cacache | 5 GB | üü° | Package cache | 30min-2hr redownload |\n| DerivedData | 10 GB | üü° | Xcode build cache | 10-30min rebuild |\n| Docker volumes | 11 GB | üî¥ | Project databases | **DATA LOSS** |\n\n### Recommendation\nOnly items marked üü¢ are recommended for cleanup.\nItems marked üü° require your judgment based on usage patterns.\nItems marked üî¥ require explicit confirmation per-item.\n```\n\n## High-Quality Report Template\n\nAfter multi-layer exploration, present findings using this proven template:\n\n```markdown\n## üìä Á£ÅÁõòÁ©∫Èó¥Ê∑±Â∫¶ÂàÜÊûêÊä•Âëä\n\n**ÂàÜÊûêÊó•Êúü**: YYYY-MM-DD\n**‰ΩøÁî®Â∑•ÂÖ∑**: Mole CLI + Â§öÂ±ÇÁõÆÂΩïÊé¢Á¥¢\n**ÂàÜÊûêÂéüÂàô**: ÂÆâÂÖ®Á¨¨‰∏ÄÔºå‰ª∑ÂÄº‰ºò‰∫éËôöËç£\n\n---\n\n### ÊÄªËßà\n\n| Âå∫Âüü | ÊÄªÂç†Áî® | ÂÖ≥ÈîÆÂèëÁé∞ |\n|------|--------|----------|\n| **Home** | XXX GB | LibraryÂç†‰∏ÄÂçä(XXX GB) |\n| **App Library** | XXX GB | ‰∏éHome/LibraryÈáçÂè†ÁªüËÆ° |\n| **Applications** | XXX GB | Â∫îÁî®Êú¨‰Ωì |\n\n---\n\n### üü¢ ÁªùÂØπÂÆâÂÖ®ÂèØÂà†Èô§ (Á∫¶ X.X GB)\n\n| È°πÁõÆ | Â§ßÂ∞è | ‰ΩçÁΩÆ | Âà†Èô§ÂêéÂΩ±Âìç | Ê∏ÖÁêÜÂëΩ‰ª§ |\n|------|------|------|-----------|---------|\n| **Â∫üÁ∫∏ÁØì** | XXX MB | ~/.Trash | Êó† - ‰Ω†Â∑≤ÂÜ≥ÂÆöÂà†Èô§ÁöÑÊñá‰ª∂ | Ê∏ÖÁ©∫Â∫üÁ∫∏ÁØì |\n| **npm _npx** | X.X GB | ~/.npm/_npx | ‰∏ãÊ¨° npx ÂëΩ‰ª§ÈáçÊñ∞‰∏ãËΩΩ | `rm -rf ~/.npm/_npx` |\n| **Homebrew ÊóßÁâàÊú¨** | XX MB | /opt/homebrew | Êó† - Â∑≤Ë¢´Êñ∞ÁâàÊú¨Êõø‰ª£ | `brew cleanup --prune=0` |\n\n**Â∫üÁ∫∏ÁØìÂÜÖÂÆπÈ¢ÑËßà**:\n- [ÂàóÂá∫‰∏ªË¶ÅÊñá‰ª∂]\n\n---\n\n### üü° ÈúÄË¶Å‰Ω†Á°ÆËÆ§ÁöÑÈ°πÁõÆ\n\n#### 1. [È°πÁõÆÂêç] (X.X GB) - [Áä∂ÊÄÅÊèèËø∞]\n\n| Â≠êÁõÆÂΩï | Â§ßÂ∞è | ÊúÄÂêé‰ΩøÁî® |\n|--------|------|----------|\n| [Â≠êÁõÆÂΩï1] | X.X GB | >X‰∏™Êúà |\n| [Â≠êÁõÆÂΩï2] | X.X GB | >X‰∏™Êúà |\n\n**ÈóÆÈ¢ò**: [ÈúÄË¶ÅÁî®Êà∑ÂõûÁ≠îÁöÑÈóÆÈ¢ò]\n\n---\n\n#### 2. Downloads ‰∏≠ÁöÑÊóßÊñá‰ª∂ (X.X GB)\n\n| Êñá‰ª∂/ÁõÆÂΩï | Â§ßÂ∞è | Âπ¥ÈæÑ | Âª∫ËÆÆ |\n|-----------|------|------|------|\n| [Êñá‰ª∂1] | X.X GB | - | [Âª∫ËÆÆ] |\n| [Êñá‰ª∂2] | XXX MB | >X‰∏™Êúà | [Âª∫ËÆÆ] |\n\n**Âª∫ËÆÆ**: ÊâãÂä®Ê£ÄÊü• DownloadsÔºåÂà†Èô§Â∑≤‰∏çÈúÄË¶ÅÁöÑÊñá‰ª∂„ÄÇ\n\n---\n\n#### 3. ÂÅúÁî®ÁöÑ Docker È°πÁõÆ Volumes\n\n| È°πÁõÆÂâçÁºÄ | ÂèØËÉΩÂåÖÂê´ÁöÑÊï∞ÊçÆ | ÈúÄË¶Å‰Ω†Á°ÆËÆ§ |\n|---------|--------------|-----------|\n| `project1_*` | MySQL, Redis | ËøòÂú®Áî®ÂêóÔºü |\n| `project2_*` | Postgres | ËøòÂú®Áî®ÂêóÔºü |\n\n**Ê≥®ÊÑè**: Êàë‰∏ç‰ºö‰ΩøÁî® `docker volume prune -f`ÔºåÂè™‰ºöÂú®‰Ω†Á°ÆËÆ§ÂêéÂà†Èô§ÁâπÂÆöÈ°πÁõÆÁöÑ volumes„ÄÇ\n\n---\n\n### üî¥ ‰∏çÂª∫ËÆÆÂà†Èô§ÁöÑÈ°πÁõÆ (Êúâ‰ª∑ÂÄºÁöÑÁºìÂ≠ò)\n\n| È°πÁõÆ | Â§ßÂ∞è | ‰∏∫‰ªÄ‰πàË¶Å‰øùÁïô |\n|------|------|-------------|\n| **Xcode DerivedData** | XX GB | [È°πÁõÆÂêç]ÁöÑÁºñËØëÁºìÂ≠òÔºåÂà†Èô§Âêé‰∏ãÊ¨°ÊûÑÂª∫ÈúÄË¶ÅXÂàÜÈíü |\n| **npm _cacache** | X.X GB | ÊâÄÊúâ‰∏ãËΩΩËøáÁöÑ npm ÂåÖÔºåÂà†Èô§ÂêéÈúÄË¶ÅÈáçÊñ∞‰∏ãËΩΩ |\n| **~/.cache/uv** | XX GB | Python ÂåÖÁºìÂ≠òÔºåÈáçÊñ∞‰∏ãËΩΩÂú®‰∏≠ÂõΩÁΩëÁªú‰∏ãÂæàÊÖ¢ |\n| [ÂÖ∂‰ªñÊúâ‰ª∑ÂÄºÁöÑÁºìÂ≠ò] | X.X GB | [‰øùÁïôÂéüÂõ†] |\n\n---\n\n### üìã ÂÖ∂‰ªñÂèëÁé∞\n\n| È°πÁõÆ | Â§ßÂ∞è | ËØ¥Êòé |\n|------|------|------|\n| **OrbStack/Docker** | XX GB | Ê≠£Â∏∏ÁöÑ VM/ÂÆπÂô®Âç†Áî® |\n| [ÂÖ∂‰ªñÂèëÁé∞] | X.X GB | [ËØ¥Êòé] |\n\n---\n\n### Êé®ËçêÊìç‰Ωú\n\n**Á´ãÂç≥ÂèØÊâßË°å** (Êó†ÈúÄÁ°ÆËÆ§):\n```bash\n# 1. Ê∏ÖÁ©∫Â∫üÁ∫∏ÁØì (XXX MB)\n# ÊâãÂä®: Finder ‚Üí Ê∏ÖÁ©∫Â∫üÁ∫∏ÁØì\n\n# 2. npm _npx (X.X GB)\nrm -rf ~/.npm/_npx\n\n# 3. Homebrew ÊóßÁâàÊú¨ (XX MB)\nbrew cleanup --prune=0\n```\n\n**È¢ÑËÆ°ÈáäÊîæ**: ~X.X GB\n\n---\n\n**ÈúÄË¶Å‰Ω†Á°ÆËÆ§ÂêéÊâßË°å**:\n\n1. **[È°πÁõÆ1]** - [Á°ÆËÆ§ÈóÆÈ¢ò]\n2. **[È°πÁõÆ2]** - [Á°ÆËÆ§ÈóÆÈ¢ò]\n3. **Docker È°πÁõÆ** - ÂëäËØâÊàëÂì™‰∫õÈ°πÁõÆÁ°ÆÂÆö‰∏çÁî®‰∫Ü\n```\n\n### Report Quality Checklist\n\nBefore presenting the report, verify:\n\n- [ ] Every item has \"Impact If Deleted\" explanation\n- [ ] üü¢ items are truly safe (Trash, _npx, old versions)\n- [ ] üü° items require user decision (age info, usage patterns)\n- [ ] üî¥ items explain WHY they should be kept\n- [ ] Docker volumes listed by project, not blanket prune\n- [ ] Network environment considered (China = slow redownload)\n- [ ] No recommendations to delete useful caches just to inflate numbers\n- [ ] Clear action items with exact commands\n\n## Step 4: Present Recommendations\n\nFormat findings into actionable recommendations with risk levels:\n\n```markdown\n# macOS Cleanup Recommendations\n\n## Summary\nTotal space recoverable: ~XX GB\nCurrent usage: XX%\n\n## Recommended Actions\n\n### üü¢ Safe to Execute (Low Risk)\nThese are safe to delete and will be regenerated as needed:\n\n1. **Empty Trash** (~12 GB)\n   - Location: ~/.Trash\n   - Command: `rm -rf ~/.Trash/*`\n\n2. **Clear System Caches** (~45 GB)\n   - Location: ~/Library/Caches\n   - Command: `rm -rf ~/Library/Caches/*`\n   - Note: Apps may be slightly slower on next launch\n\n3. **Remove Homebrew Cache** (~5 GB)\n   - Command: `brew cleanup -s`\n\n### üü° Review Recommended (Medium Risk)\nReview these items before deletion:\n\n1. **Large Downloads** (~38 GB)\n   - Location: ~/Downloads\n   - Action: Manually review and delete unneeded files\n   - Files: [list top 10 largest files]\n\n2. **Application Remnants** (~8 GB)\n   - Apps: [list detected uninstalled apps]\n   - Locations: [list paths]\n   - Action: Confirm apps are truly uninstalled before deleting data\n\n### üî¥ Keep Unless Certain (High Risk)\nOnly delete if you know what you're doing:\n\n1. **Docker Volumes** (~3 GB)\n   - May contain important data\n   - Review with: `docker volume ls`\n\n2. **Time Machine Local Snapshots** (~XX GB)\n   - Automatic backups, will be deleted when space needed\n   - Command to check: `tmutil listlocalsnapshots /`\n```\n\n## Step 5: Execute with Confirmation\n\n**CRITICAL**: Never execute deletions without explicit user confirmation.\n\n**Interactive confirmation flow:**\n\n```python\n# Example from scripts/safe_delete.py\ndef confirm_delete(path: str, size: str, description: str) -> bool:\n    \"\"\"\n    Ask user to confirm deletion.\n\n    Args:\n        path: File/directory path\n        size: Human-readable size\n        description: What this file/directory is\n\n    Returns:\n        True if user confirms, False otherwise\n    \"\"\"\n    print(f\"\\nüóëÔ∏è  Confirm Deletion\")\n    print(f\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n    print(f\"Path:        {path}\")\n    print(f\"Size:        {size}\")\n    print(f\"Description: {description}\")\n\n    response = input(\"\\nDelete this item? [y/N]: \").strip().lower()\n    return response == 'y'\n```\n\n**For batch operations:**\n\n```python\ndef batch_confirm(items: list) -> list:\n    \"\"\"\n    Show all items, ask for batch confirmation.\n\n    Returns list of items user approved.\n    \"\"\"\n    print(\"\\nüìã Items to Delete:\")\n    print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n    for i, item in enumerate(items, 1):\n        print(f\"{i}. {item['path']} ({item['size']})\")\n\n    print(\"\\nOptions:\")\n    print(\"  'all'    - Delete all items\")\n    print(\"  '1,3,5'  - Delete specific items by number\")\n    print(\"  'none'   - Cancel\")\n\n    response = input(\"\\nYour choice: \").strip().lower()\n\n    if response == 'none':\n        return []\n    elif response == 'all':\n        return items\n    else:\n        # Parse numbers\n        indices = [int(x.strip()) - 1 for x in response.split(',')]\n        return [items[i] for i in indices if 0 <= i < len(items)]\n```\n\n## Step 6: Verify Results\n\nAfter cleanup, verify the results and report back:\n\n```bash\n# Compare before/after\ndf -h /\n\n# Calculate space recovered\n# (handled by scripts/cleanup_report.py)\n```\n\n**Report format:**\n\n```\n‚úÖ Cleanup Complete!\n\nBefore: 450 GB used (90%)\nAfter:  385 GB used (77%)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nRecovered: 65 GB\n\nBreakdown:\n- System caches:        45 GB\n- Downloads:            12 GB\n- Homebrew cache:        5 GB\n- Application remnants:  3 GB\n\n‚ö†Ô∏è Notes:\n- Some applications may take longer to launch on first run\n- Deleted items cannot be recovered unless you have Time Machine backup\n- Consider running this cleanup monthly\n\nüí° Maintenance Tips:\n- Set up automatic Homebrew cleanup: `brew cleanup` weekly\n- Review Downloads folder monthly\n- Enable \"Empty Trash Automatically\" in Finder preferences\n```\n\n## Safety Guidelines\n\n### Always Preserve\n\nNever delete these without explicit user instruction:\n- `~/Documents`, `~/Desktop`, `~/Pictures` content\n- Active project directories\n- Database files (*.db, *.sqlite)\n- Configuration files for active apps\n- SSH keys, credentials, certificates\n- Time Machine backups\n\n### Require Sudo Confirmation\n\nThese operations require elevated privileges. Ask user to run commands manually:\n- Clearing `/Library/Caches` (system-wide)\n- Clearing `/var/log` (system logs)\n- Clearing `/private/var/folders` (system temp)\n\nExample prompt:\n```\n‚ö†Ô∏è This operation requires administrator privileges.\n\nPlease run this command manually:\n  sudo rm -rf /Library/Caches/*\n\n‚ö†Ô∏è You'll be asked for your password.\n```\n\n### Backup Recommendation\n\nBefore executing any cleanup >10GB, recommend:\n\n```\nüí° Safety Tip:\nBefore cleaning XX GB, consider creating a Time Machine backup.\n\nQuick backup check:\n  tmutil latestbackup\n\nIf no recent backup, run:\n  tmutil startbackup\n```\n\n## Troubleshooting\n\n### \"Operation not permitted\" errors\n\nmacOS may block deletion of certain system files due to SIP (System Integrity Protection).\n\n**Solution**: Don't force it. These protections exist for security.\n\n### App crashes after cache deletion\n\nRare but possible. **Solution**: Restart the app, it will regenerate necessary caches.\n\n### Docker cleanup removes important data\n\n**Prevention**: Always list Docker volumes before cleanup:\n```bash\ndocker volume ls\ndocker volume inspect <volume_name>\n```\n\n## Resources\n\n### scripts/\n\n- `analyze_caches.py` - Scan and categorize cache directories\n- `find_app_remnants.py` - Detect orphaned application data\n- `analyze_large_files.py` - Find large files with smart filtering\n- `analyze_dev_env.py` - Scan development environment resources\n- `safe_delete.py` - Interactive deletion with confirmation\n- `cleanup_report.py` - Generate before/after reports\n\n### references/\n\n- `cleanup_targets.md` - Detailed explanations of each cleanup target\n- `mole_integration.md` - How to use Mole alongside this skill\n- `safety_rules.md` - Comprehensive list of what to never delete\n\n## Usage Examples\n\n### Example 1: Quick Cache Cleanup\n\nUser request: \"My Mac is running out of space, can you help?\"\n\nWorkflow:\n1. Run quick diagnosis\n2. Identify system caches as quick win\n3. Present findings: \"45 GB in ~/Library/Caches\"\n4. Explain: \"These are safe to delete, apps will regenerate them\"\n5. Ask confirmation\n6. Execute: `rm -rf ~/Library/Caches/*`\n7. Report: \"Recovered 45 GB\"\n\n### Example 2: Development Environment Cleanup\n\nUser request: \"I'm a developer and my disk is full\"\n\nWorkflow:\n1. Run `scripts/analyze_dev_env.py`\n2. Present Docker + npm + Homebrew findings\n3. Explain each category\n4. Provide cleanup commands with explanations\n5. Let user execute (don't auto-execute Docker cleanup)\n6. Verify results\n\n### Example 3: Finding Large Files\n\nUser request: \"What's taking up so much space?\"\n\nWorkflow:\n1. Run `scripts/analyze_large_files.py --threshold 100MB`\n2. Present top 20 large files with context\n3. Categorize: videos, datasets, archives, disk images\n4. Let user decide what to delete\n5. Execute confirmed deletions\n6. Suggest archiving to external drive\n\n## Best Practices\n\n1. **Start Conservative**: Begin with obviously safe targets (caches, trash)\n2. **Explain Everything**: Users should understand what they're deleting\n3. **Show Examples**: List 3-5 example files from each category\n4. **Respect User Pace**: Don't rush through confirmations\n5. **Document Results**: Always show before/after space usage\n6. **Educate**: Include maintenance tips in final report\n7. **Integrate Tools**: Suggest Mole for users who prefer GUI\n\n## When NOT to Use This Skill\n\n- User wants automatic/silent cleanup (against safety-first principle)\n- User needs Windows/Linux cleanup (macOS-specific skill)\n- User has <10% disk usage (no cleanup needed)\n- User wants to clean system files requiring SIP disable (security risk)\n\nIn these cases, explain limitations and suggest alternatives.\n",
        "markdown-tools/SKILL.md": "---\nname: markdown-tools\ndescription: Converts documents to markdown with multi-tool orchestration for best quality. Supports Quick Mode (fast, single tool) and Heavy Mode (best quality, multi-tool merge). Use when converting PDF/DOCX/PPTX files to markdown, extracting images from documents, validating conversion quality, or needing LLM-optimized document output.\n---\n\n# Markdown Tools\n\nConvert documents to high-quality markdown with intelligent multi-tool orchestration.\n\n## Dual Mode Architecture\n\n| Mode | Speed | Quality | Use Case |\n|------|-------|---------|----------|\n| **Quick** (default) | Fast | Good | Drafts, simple documents |\n| **Heavy** | Slower | Best | Final documents, complex layouts |\n\n## Quick Start\n\n### Installation\n\n```bash\n# Required: PDF/DOCX/PPTX support\nuv tool install \"markitdown[pdf]\"\npip install pymupdf4llm\nbrew install pandoc\n```\n\n### Basic Conversion\n\n```bash\n# Quick Mode (default) - fast, single best tool\nuv run --with pymupdf4llm --with markitdown scripts/convert.py document.pdf -o output.md\n\n# Heavy Mode - multi-tool parallel execution with merge\nuv run --with pymupdf4llm --with markitdown scripts/convert.py document.pdf -o output.md --heavy\n\n# Check available tools\nuv run scripts/convert.py --list-tools\n```\n\n## Tool Selection Matrix\n\n| Format | Quick Mode Tool | Heavy Mode Tools |\n|--------|----------------|------------------|\n| PDF | pymupdf4llm | pymupdf4llm + markitdown |\n| DOCX | pandoc | pandoc + markitdown |\n| PPTX | markitdown | markitdown + pandoc |\n| XLSX | markitdown | markitdown |\n\n### Tool Characteristics\n\n- **pymupdf4llm**: LLM-optimized PDF conversion with native table detection and image extraction\n- **markitdown**: Microsoft's universal converter, good for Office formats\n- **pandoc**: Excellent structure preservation for DOCX/PPTX\n\n## Heavy Mode Workflow\n\nHeavy Mode runs multiple tools in parallel and selects the best segments:\n\n1. **Parallel Execution**: Run all applicable tools simultaneously\n2. **Segment Analysis**: Parse each output into segments (tables, headings, images, paragraphs)\n3. **Quality Scoring**: Score each segment based on completeness and structure\n4. **Intelligent Merge**: Select best version of each segment across tools\n\n### Merge Criteria\n\n| Segment Type | Selection Criteria |\n|--------------|-------------------|\n| Tables | More rows/columns, proper header separator |\n| Images | Alt text present, local paths preferred |\n| Headings | Proper hierarchy, appropriate length |\n| Lists | More items, nested structure preserved |\n| Paragraphs | Content completeness |\n\n## Image Extraction\n\n```bash\n# Extract images with metadata\nuv run --with pymupdf scripts/extract_pdf_images.py document.pdf -o ./assets\n\n# Generate markdown references file\nuv run --with pymupdf scripts/extract_pdf_images.py document.pdf --markdown refs.md\n```\n\nOutput:\n- Images: `assets/img_page1_1.png`, `assets/img_page2_1.jpg`\n- Metadata: `assets/images_metadata.json` (page, position, dimensions)\n\n## Quality Validation\n\n```bash\n# Validate conversion quality\nuv run --with pymupdf scripts/validate_output.py document.pdf output.md\n\n# Generate HTML report\nuv run --with pymupdf scripts/validate_output.py document.pdf output.md --report report.html\n```\n\n### Quality Metrics\n\n| Metric | Pass | Warn | Fail |\n|--------|------|------|------|\n| Text Retention | >95% | 85-95% | <85% |\n| Table Retention | 100% | 90-99% | <90% |\n| Image Retention | 100% | 80-99% | <80% |\n\n## Merge Outputs Manually\n\n```bash\n# Merge multiple markdown files\npython scripts/merge_outputs.py output1.md output2.md -o merged.md\n\n# Show segment attribution\npython scripts/merge_outputs.py output1.md output2.md -o merged.md --verbose\n```\n\n## Path Conversion (Windows/WSL)\n\n```bash\n# Windows ‚Üí WSL conversion\npython scripts/convert_path.py \"C:\\Users\\name\\Documents\\file.pdf\"\n# Output: /mnt/c/Users/name/Documents/file.pdf\n```\n\n## Common Issues\n\n**\"No conversion tools available\"**\n```bash\n# Install all tools\npip install pymupdf4llm\nuv tool install \"markitdown[pdf]\"\nbrew install pandoc\n```\n\n**FontBBox warnings during PDF conversion**\n- Harmless font parsing warnings, output is still correct\n\n**Images missing from output**\n- Use Heavy Mode for better image preservation\n- Or extract separately with `scripts/extract_pdf_images.py`\n\n**Tables broken in output**\n- Use Heavy Mode - it selects the most complete table version\n- Or validate with `scripts/validate_output.py`\n\n## Bundled Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `convert.py` | Main orchestrator with Quick/Heavy mode |\n| `merge_outputs.py` | Merge multiple markdown outputs |\n| `validate_output.py` | Quality validation with HTML report |\n| `extract_pdf_images.py` | PDF image extraction with metadata |\n| `convert_path.py` | Windows to WSL path converter |\n\n## References\n\n- `references/heavy-mode-guide.md` - Detailed Heavy Mode documentation\n- `references/tool-comparison.md` - Tool capabilities comparison\n- `references/conversion-examples.md` - Batch operation examples\n",
        "meeting-minutes-taker/SKILL.md": "---\nname: meeting-minutes-taker\ndescription: |\n  Transforms raw meeting transcripts into high-fidelity, structured meeting minutes with iterative review for completeness. This skill should be used when (1) a meeting transcript is provided and meeting minutes, notes, or summaries are requested, (2) multiple versions of meeting minutes need to be merged without losing content, (3) existing minutes need to be reviewed against the original transcript for missing items, (4) transcript has anonymous speakers like \"Speaker 1/2/3\" that need identification. Features include: speaker identification via feature analysis (word count, speaking style, topic focus) with context.md team directory mapping, intelligent file naming from content, integration with transcript-fixer for pre-processing, evidence-based recording with speaker quotes, Mermaid diagrams for architecture discussions, multi-turn parallel generation to avoid content loss, and iterative human-in-the-loop refinement.\n---\n\n# Meeting Minutes Taker\n\nTransform raw meeting transcripts into comprehensive, evidence-based meeting minutes through iterative review.\n\n## Quick Start\n\n**Pre-processing (Optional but Recommended):**\n- **Document conversion**: Use `markdown-tools` skill to convert .docx/.pdf to Markdown first (preserves tables/images)\n- **Transcript cleanup**: Use `transcript-fixer` skill to fix ASR/STT errors if transcript quality is poor\n- **Context file**: Prepare `context.md` with team directory for accurate speaker identification\n\n**Core Workflow:**\n1. Read the transcript provided by user\n2. Load project-specific context file if provided by user (optional)\n3. **Intelligent file naming**: Auto-generate filename from content (see below)\n4. **Speaker identification**: If transcript has \"Speaker 1/2/3\", identify speakers before generation\n5. **Multi-turn generation**: Use multiple passes or subagents with isolated context, merge using UNION\n6. Self-review using [references/completeness_review_checklist.md](references/completeness_review_checklist.md)\n7. Present draft to user for human line-by-line review\n8. **Cross-AI comparison** (optional): Human may provide output from other AI tools (e.g., Gemini, ChatGPT) - merge to reduce bias\n9. Iterate on feedback until human approves final version\n\n### Intelligent File Naming\n\nAuto-generate output filename from transcript content:\n\n**Pattern**: `YYYY-MM-DD-<topic>-<type>.md`\n\n| Component | Source | Examples |\n|-----------|--------|----------|\n| Date | Transcript metadata or first date mention | `2026-01-25` |\n| Topic | Main discussion subject (2-4 words, kebab-case) | `api-design`, `product-roadmap` |\n| Type | Meeting category | `review`, `sync`, `planning`, `retro`, `kickoff` |\n\n**Examples:**\n- `2026-01-25-order-api-design-review.md`\n- `2026-01-20-q1-sprint-planning.md`\n- `2026-01-18-onboarding-flow-sync.md`\n\n**Ask user to confirm** the suggested filename before writing.\n\n## Core Workflow\n\nCopy this checklist and track progress:\n\n```\nMeeting Minutes Progress:\n- [ ] Step 0 (Optional): Pre-process transcript with transcript-fixer\n- [ ] Step 1: Read and analyze transcript\n- [ ] Step 1.5: Speaker identification (if transcript has \"Speaker 1/2/3\")\n  - [ ] Analyze speaker features (word count, style, topic focus)\n  - [ ] Match against context.md team directory (if provided)\n  - [ ] Present speaker mapping to user for confirmation\n- [ ] Step 1.6: Generate intelligent filename, confirm with user\n- [ ] Step 1.7: Quality assessment (optional, affects processing depth)\n- [ ] Step 2: Multi-turn generation (PARALLEL subagents with Task tool)\n  - [ ] Create transcript-specific dir: <output_dir>/intermediate/<transcript-name>/\n  - [ ] Launch 3 Task subagents IN PARALLEL (single message, 3 Task tool calls)\n    - [ ] Subagent 1 ‚Üí <output_dir>/intermediate/<transcript-name>/version1.md\n    - [ ] Subagent 2 ‚Üí <output_dir>/intermediate/<transcript-name>/version2.md\n    - [ ] Subagent 3 ‚Üí <output_dir>/intermediate/<transcript-name>/version3.md\n  - [ ] Merge: UNION all versions, AGGRESSIVELY include ALL diagrams ‚Üí draft_minutes.md\n  - [ ] Final: Compare draft against transcript, add omissions\n- [ ] Step 3: Self-review for completeness\n- [ ] Step 4: Present draft to user for human review\n- [ ] Step 5: Cross-AI comparison (if human provides external AI output)\n- [ ] Step 6: Iterate on human feedback (expect multiple rounds)\n- [ ] Step 7: Human approves final version\n\nNote: <output_dir> = directory where final meeting minutes will be saved (e.g., project-docs/meeting-minutes/)\nNote: <transcript-name> = name derived from transcript file (e.g., 2026-01-15-product-api-design)\n```\n\n### Step 1: Read and Analyze Transcript\n\nAnalyze the transcript to identify:\n- Meeting topic and attendees\n- Key decisions with supporting quotes\n- Action items with owners\n- Deferred items / open questions\n\n### Step 1.5: Speaker Identification (When Needed)\n\n**Trigger**: Transcript only has generic labels like \"Speaker 1\", \"Speaker 2\", \"ÂèëË®Ä‰∫∫1\", etc.\n\n**Approach** (inspired by Anker Skill):\n\n#### Phase A: Feature Analysis (Pattern Recognition)\n\nFor each speaker, analyze:\n\n| Feature | What to Look For |\n|---------|-----------------|\n| **Word count** | Total words spoken (high = senior/lead, low = observer) |\n| **Segment count** | Number of times they speak (frequent = active participant) |\n| **Avg segment length** | Average words per turn (long = presenter, short = responder) |\n| **Filler ratio** | % of filler words (ÂØπ/ÂóØ/Âïä/Â∞±ÊòØ/ÁÑ∂Âêé) - low = prepared speaker |\n| **Speaking style** | Formal/informal, technical depth, decision authority |\n| **Topic focus** | Areas they discuss most (backend, frontend, product, etc.) |\n| **Interaction pattern** | Do others ask them questions? Do they assign tasks? |\n\n**Example analysis output:**\n```\nSpeaker Analysis:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Speaker  ‚îÇ Words  ‚îÇ Segments ‚îÇ Avg Length  ‚îÇ Filler %    ‚îÇ Role Guess             ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ ÂèëË®Ä‰∫∫1  ‚îÇ 41,736 ‚îÇ 93       ‚îÇ 449 chars   ‚îÇ 3.6%        ‚îÇ ‰∏ªËÆ≤‰∫∫ (99% of content)‚îÇ\n‚îÇ ÂèëË®Ä‰∫∫2  ‚îÇ 101    ‚îÇ 8        ‚îÇ 13 chars    ‚îÇ 4.0%        ‚îÇ ÂØπËØùËÄÖ (short responses)‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\nInference rules:\n- Âç†ÊØî > 70% + Âπ≥ÂùáÈïøÂ∫¶ > 100Â≠ó ‚Üí ‰∏ªËÆ≤‰∫∫\n- Âπ≥ÂùáÈïøÂ∫¶ < 50Â≠ó ‚Üí ÂØπËØùËÄÖ/ÂìçÂ∫îËÄÖ\n- ËØ≠Ê∞îËØçÂç†ÊØî < 5% ‚Üí Ê≠£Âºè/ÂáÜÂ§áÂÖÖÂàÜ\n- ËØ≠Ê∞îËØçÂç†ÊØî > 10% ‚Üí ÈùûÊ≠£Âºè/Âç≥ÂÖ¥ÂèëË®Ä\n```\n\n#### Phase B: Context Mapping (If Context File Provided)\n\nWhen user provides a project context file (e.g., `context.md`):\n\n1. Load team directory section\n2. Match feature patterns to known team members\n3. Cross-reference roles with speaking patterns\n\n**Context file should include:**\n```markdown\n## Team Directory\n| Name | Role | Communication Style |\n|------|------|---------------------|\n| Alice | Backend Lead | Technical, decisive, assigns backend tasks |\n| Bob | PM | Product-focused, asks requirements questions |\n| Carol | TPM | Process-focused, tracks timeline/resources |\n```\n\n#### Phase C: Confirmation Before Proceeding\n\n**CRITICAL**: Never silently assume speaker identity.\n\nPresent analysis summary to user:\n```\nSpeaker Analysis:\n- Speaker 1 ‚Üí Alice (Backend Lead) - 80% confidence based on: technical focus, task assignment pattern\n- Speaker 2 ‚Üí Bob (PM) - 75% confidence based on: product questions, requirements discussion\n- Speaker 3 ‚Üí Carol (TPM) - 70% confidence based on: timeline concerns, resource tracking\n\nPlease confirm or correct these mappings before I proceed.\n```\n\nAfter user confirmation, apply mappings consistently throughout the document.\n\n### Step 1.7: Transcript Quality Assessment (Optional)\n\nEvaluate transcript quality to determine processing depth:\n\n**Scoring Criteria (1-10 scale):**\n\n| Factor | Score Impact |\n|--------|-------------|\n| **Content volume** | >10k chars: +2, 5-10k: +1, <2k: cap at 3 |\n| **Filler word ratio** | <5%: +2, 5-10%: +1, >10%: -1 |\n| **Speaker clarity** | Main speaker >80%: +1 (clear presenter) |\n| **Technical depth** | High technical content: +1 |\n\n**Quality Tiers:**\n\n| Score | Tier | Processing Approach |\n|-------|------|---------------------|\n| ‚â•8 | **High** | Full structured minutes with all sections, diagrams, quotes |\n| 5-7 | **Medium** | Standard minutes, focus on key decisions and action items |\n| <5 | **Low** | Summary only - brief highlights, skip detailed transcription |\n\n**Example assessment:**\n```\nüìä Transcript Quality Assessment:\n- Content: 41,837 chars (+2)\n- Filler ratio: 3.6% (+2)\n- Main speaker: 99% (+1)\n- Technical depth: High (+1)\n‚Üí Quality Score: 10/10 (High)\n‚Üí Recommended: Full structured minutes with diagrams\n```\n\n**User decision point**: If quality is Low (<5), ask user:\n> \"Transcript quality is low (Á¢éÁâáÂØπËØù/Âô™Èü≥ËæÉÂ§ö). Generate full minutes or summary only?\"\n\n### Step 2: Multi-Turn Initial Generation (Critical)\n\n**A single pass will absolutely lose content.** Use multi-turn generation with **redundant complete passes**:\n\n#### Core Principle: Multiple Complete Passes + UNION Merge\n\nEach pass generates **COMPLETE minutes (all sections)** from the full transcript. Multiple passes with isolated context catch different details. UNION merge consolidates all findings.\n\n**‚ùå WRONG: Narrow-focused passes** (wastes tokens, causes bias)\n```\nPass 1: Only extract decisions\nPass 2: Only extract action items\nPass 3: Only extract discussion\n```\n\n**‚úÖ CORRECT: Complete passes with isolated context**\n```\nPass 1: Generate COMPLETE minutes (all sections) ‚Üí version1.md\nPass 2: Generate COMPLETE minutes (all sections) with fresh context ‚Üí version2.md\nPass 3: Generate COMPLETE minutes (all sections) with fresh context ‚Üí version3.md\nMerge: UNION all versions, consolidate duplicates ‚Üí draft_minutes.md\n```\n\n#### Strategy A: Sequential Multi-Pass (Complete Minutes Each Pass)\n\n```\nPass 1: Read transcript ‚Üí Generate complete minutes ‚Üí Write to: <output_dir>/intermediate/version1.md\nPass 2: Fresh context ‚Üí Read transcript ‚Üí Generate complete minutes ‚Üí Write to: <output_dir>/intermediate/version2.md\nPass 3: Fresh context ‚Üí Read transcript ‚Üí Generate complete minutes ‚Üí Write to: <output_dir>/intermediate/version3.md\nMerge: Read all versions ‚Üí UNION merge (consolidate duplicates) ‚Üí Write to: draft_minutes.md\nFinal: Compare draft against transcript ‚Üí Add any remaining omissions ‚Üí final_minutes.md\n```\n\n#### Strategy B: Parallel Multi-Agent (Complete Minutes Each Agent) - PREFERRED\n\n**MUST use the Task tool** to spawn multiple subagents with **isolated context**, each generating **complete minutes**:\n\n**Implementation using Task tool:**\n```\n// Launch ALL 3 subagents in PARALLEL (single message, multiple Task tool calls)\nTask(subagent_type=\"general-purpose\", prompt=\"Generate complete meeting minutes from transcript...\", run_in_background=false) ‚Üí version1.md\nTask(subagent_type=\"general-purpose\", prompt=\"Generate complete meeting minutes from transcript...\", run_in_background=false) ‚Üí version2.md\nTask(subagent_type=\"general-purpose\", prompt=\"Generate complete meeting minutes from transcript...\", run_in_background=false) ‚Üí version3.md\n\n// After all complete:\nMain Agent: Read all versions ‚Üí UNION merge, consolidate duplicates ‚Üí draft_minutes.md\n```\n\n**CRITICAL: Subagent Prompt Must Include:**\n1. Full path to transcript file\n2. Full path to output file (version1.md, version2.md, version3.md in transcript-specific subdirectory)\n3. Context files to load (project-specific context if provided, meeting_minutes_template.md)\n4. Reference images/documents if provided by user\n5. Output language requirement (match user's language preference, preserve technical terms in English)\n6. Quote formatting requirement (see Quote Formatting Requirements section below)\n\n**Why multiple complete passes work:**\n- Each pass independently analyzes the SAME content\n- Different context states catch different details (no single pass catches everything)\n- Pass 1 might catch decision X but miss action item Y\n- Pass 2 might catch action item Y but miss decision X\n- UNION merge captures both X and Y\n\n**Why isolated context matters:**\n- Each pass/agent starts fresh without prior assumptions\n- No cross-contamination between passes\n- Different \"perspectives\" emerge naturally from context isolation\n\n#### Progressive Context Offloading (Use File System)\n\n**Critical: Write each pass output to files, not conversation context.**\n\n**Path Convention:** All intermediate files should be created in a **transcript-specific subdirectory** under `<output_dir>/intermediate/` to avoid conflicts between different transcripts being processed.\n\n**CRITICAL: Use transcript-specific subdirectory structure:**\n```\n<output_dir>/intermediate/<transcript-name>/version1.md\n<output_dir>/intermediate/<transcript-name>/version2.md\n<output_dir>/intermediate/<transcript-name>/version3.md\n```\n\nExample: If final minutes will be `project-docs/meeting-minutes/2026-01-14-api-design.md`, then:\n- Intermediate files: `project-docs/meeting-minutes/intermediate/2026-01-14-api-design/version1.md`\n- This prevents conflicts when multiple transcripts are processed in the same session\n- The `intermediate/` folder should be added to `.gitignore` (temporary working files)\n\n```\n// Create transcript-specific subdirectory first\nmkdir: <output_dir>/intermediate/<transcript-name>/\n\n// Launch all 3 subagents IN PARALLEL (must be single message with 3 Task tool calls)\nTask 1 ‚Üí Write to: <output_dir>/intermediate/<transcript-name>/version1.md (complete minutes)\nTask 2 ‚Üí Write to: <output_dir>/intermediate/<transcript-name>/version2.md (complete minutes)\nTask 3 ‚Üí Write to: <output_dir>/intermediate/<transcript-name>/version3.md (complete minutes)\n\nMerge Phase:\n  Read: <output_dir>/intermediate/<transcript-name>/version1.md\n  Read: <output_dir>/intermediate/<transcript-name>/version2.md\n  Read: <output_dir>/intermediate/<transcript-name>/version3.md\n  ‚Üí UNION merge, consolidate duplicates, INCLUDE ALL DIAGRAMS ‚Üí Write to: draft_minutes.md\n\nFinal Review:\n  Read: draft_minutes.md\n  Read: original_transcript.md\n  ‚Üí Compare & add omissions ‚Üí Write to: final_minutes.md\n```\n\n**Benefits of file-based context offloading:**\n- Conversation context stays clean (avoids token overflow)\n- Intermediate results persist (can be re-read if needed)\n- Each pass starts with fresh context window\n- Merge phase reads only what it needs\n- **Human can inspect intermediate files for review** - Critical for understanding what each pass captured\n- Supports very long transcripts that exceed context limits\n- **Enables post-hoc debugging** - If final output is missing something, human can trace which pass missed it\n\n**IMPORTANT: Always preserve intermediate versions in transcript-specific subdirectory:**\n- `<output_dir>/intermediate/<transcript-name>/version1.md`, `version2.md`, `version3.md` - Each subagent output\n- These files help human reviewers understand the merge process\n- Do NOT delete intermediate files after merge\n- Human may want to compare intermediate versions to understand coverage gaps\n- **Add `intermediate/` to `.gitignore`** - These are temporary working files, not final deliverables\n- **Transcript-specific subdirectory** prevents conflicts when processing multiple transcripts\n\n#### Output Requirements\n\n- **Chinese output** with English technical terms preserved\n- **Evidence-based decisions** - Every significant decision needs a supporting quote\n- **Structured sections** - Executive Summary, Key Decisions, Discussion, Action Items, Parking Lot\n- **Proper quote formatting** - See Quote Formatting Requirements section below\n- **Mermaid diagrams** (STRONGLY ENCOURAGED) - Visual diagrams elevate minutes beyond pure text:\n  - **ER diagrams** for database/schema discussions\n  - **Sequence diagrams** for data flow and API interactions\n  - **Flowcharts** for process/workflow decisions\n  - **State diagrams** for state machine discussions\n  - Diagrams make minutes significantly easier for humans to review and understand\n- **Context-first document structure** - Place all reviewed artifacts (UI mockups, API docs, design images) at the TOP of the document (after metadata, before Executive Summary) to establish context before decisions; copy images to `assets/<meeting-name>/` folder and embed inline using `![description](assets/...)` syntax; include brief descriptions with the visuals - this creates \"next level\" human-readable minutes where readers understand what was discussed before reading the discussion\n- **Speaker attribution** - Correctly attribute decisions to speakers\n\n#### Key Rules\n\n- Never assume - Ask user to confirm if unclear\n- Quote controversial decisions verbatim\n- Assign action items to specific people, not teams\n- Preserve numerical values (ranges, counts, priorities)\n- **Always use multiple passes** - Single turn is guaranteed to lose content\n- **Normalize equivalent terminology** - Treat trivial variations (e.g., \"backend architecture\" vs \"backend\", \"API endpoint\" vs \"endpoint\") as equivalent; do NOT point out or highlight such differences between speakers\n- **Single source of truth** - Place each piece of information in ONE location only; avoid duplicating tables, lists, or summaries across sections (e.g., API list belongs in Discussion OR Reference, not both)\n\n### Step 3: Self-Review for Completeness\n\nAfter initial generation, immediately review against transcript:\n\n```\nCompleteness Checklist:\n- [ ] All discussion topics covered?\n- [ ] All decisions have supporting quotes?\n- [ ] All speakers attributed correctly?\n- [ ] All action items have specific owners?\n- [ ] Numerical values preserved (ranges, counts)?\n- [ ] Entity relationships captured?\n- [ ] State machines complete (all states listed)?\n```\n\nIf gaps found, add missing content silently without mentioning what was missed.\n\n### Step 4: Present to User for Human Review\n\nPresent the complete minutes as a **draft for human review**. Emphasize:\n- Minutes require careful line-by-line human review\n- Domain experts catch terminology conflicts AI may miss\n- Final version emerges through iterative refinement\n\nUser may:\n- Accept as-is (rare for complex meetings)\n- Request deeper review for missing content\n- Identify terminology issues (e.g., naming conflicts with existing systems)\n- Provide another AI's output for cross-comparison\n\n### Step 5: Cross-AI Comparison (Reduces Bias)\n\n**When human provides output from another AI tool** (e.g., Gemini, ChatGPT, etc.):\n\nThis step is valuable because:\n- **Different AI models have different biases** - Each AI catches different details\n- **Cross-validation** - Content appearing in both outputs is likely accurate\n- **Gap detection** - Content in one but not the other reveals potential omissions\n- **Error correction** - One AI may catch factual errors the other missed (e.g., wrong date, wrong attendee name)\n\n**Comparison Process:**\n1. Read the external AI output carefully\n2. Identify items present in external output but missing from our draft\n3. Verify each item against original transcript before adding (don't blindly copy)\n4. Identify items where external AI has errors (wrong facts) - note but don't copy errors\n5. UNION merge valid new content into our draft\n6. Document any corrections made based on cross-comparison\n\n**Example findings from cross-AI comparison:**\n- Missing decision about API authentication method ‚úì (add to our draft)\n- Missing naming convention specification ‚úì (add to our draft)\n- Wrong date (2026-01-13 vs actual 2026-01-14) ‚úó (don't copy error)\n- Wrong attendee name ‚úó (don't copy error)\n- Missing database performance concern ‚úì (add to parking lot)\n\n### Step 6: Iterate on Human Feedback (Critical)\n\n**When user requests deeper review** (\"deep review\", \"check again\", \"anything missing\"):\n\n1. Re-read transcript section by section\n2. Compare each section against current minutes\n3. Look for: entities, field names, numerical ranges, state transitions, trade-offs, deferred items\n4. Add any omitted content\n5. Never claim \"nothing missing\" without thorough section-by-section review\n\n**When user provides another version to merge:**\n\nMerge Principle: **UNION, never remove**\n\n1. Keep ALL content from existing version\n2. Add ALL new content from incoming version\n3. Consolidate duplicates (don't repeat same info)\n4. Preserve more detailed version when depth differs\n5. Maintain logical section numbering\n\n### Aggressive Diagram Inclusion (CRITICAL)\n\n**During merge phase, MUST aggressively include ALL diagrams from ALL versions.**\n\nDiagrams are high-value content that took effort to generate. Different subagents may produce different diagrams based on what they focused on. Missing a diagram during merge is a significant loss.\n\n**Merge diagram strategy:**\n1. **Inventory ALL diagrams** from each version (v1, v2, v3)\n2. **Include ALL unique diagrams** - don't assume a diagram is redundant\n3. **If similar diagrams exist**, keep the more detailed/complete one\n4. **Check every section** that could contain diagrams: Executive Summary, Discussion, API design, State machines, Data flow, etc.\n\n**Common diagram types to look for:**\n- Sequence diagrams (data flow, API interactions)\n- ER diagrams (database schema, table relationships)\n- State diagrams (state machines, status transitions)\n- Flowcharts (decision flows, process workflows)\n- Component diagrams (system architecture)\n\n**Example: Missed diagram from v3**\nIf v3 has a flowchart for \"Status Query Mechanism\" but v1/v2 don't have it, that flowchart MUST appear in the merged output. Don't assume it's covered by other diagrams.\n\n## Output Language\n\n- **Primary:** Match the language of the transcript (or user's preference if specified)\n- **Preserve in English:** Technical terms, entity names, abbreviations (standard practice)\n- **Quotes:** Keep original language from transcript\n\n## Reference Files\n\n| File | When to Load |\n|------|--------------|\n| [meeting_minutes_template.md](references/meeting_minutes_template.md) | First generation - Contains template structure |\n| [completeness_review_checklist.md](references/completeness_review_checklist.md) | During review steps - Contains completeness checks |\n| [context_file_template.md](references/context_file_template.md) | When helping user create context.md - Contains team directory template |\n| Project context file (user-provided) | When user provides project-specific context (team directory, terminology, conventions) |\n\n### Recommended Pre-processing Pipeline\n\n**Full pipeline for .docx transcripts:**\n\n```\nStep 0: markdown-tools      # Convert .docx ‚Üí Markdown (preserves tables/images)\n        ‚Üì\nStep 0.5: transcript-fixer  # Fix ASR errors (optional, if quality is poor)\n        ‚Üì\nStep 1+: meeting-minutes-taker  # Generate structured minutes\n```\n\n**Commands:**\n```bash\n# 1. Install markitdown (one-time)\nuv tool install \"markitdown[pdf]\"\n\n# 2. Convert .docx to markdown\nmarkitdown \"ÂΩïÈü≥ËΩ¨ÂÜô.docx\" -o transcript.md\n\n# 3. Then use meeting-minutes-taker on transcript.md\n```\n\n**Benefits of combo workflow:**\n- **Tables preserved**: markitdown converts Word tables to Markdown tables\n- **Images extracted**: Can be embedded in final minutes\n- **Cleaner quotes**: transcript-fixer removes ASR typos before quote extraction\n- **Accurate speaker ID**: Style analysis works better on clean text\n- **Ê≠£‰∫§ËÆæËÆ°**: Each skill does one thing well, composable pipeline\n\n## Common Patterns\n\n### Architecture Discussions ‚Üí Mermaid Diagrams (Next-Level Minutes)\n\n**Diagrams elevate meeting minutes beyond pure text.** They make complex discussions immediately understandable for human reviewers. Always look for opportunities to add visual diagrams.\n\n#### When to Use Diagrams:\n- **Data flow discussions** ‚Üí Sequence diagram\n- **Database schema discussions** ‚Üí ER diagram\n- **Process/workflow decisions** ‚Üí Flowchart\n- **State machine discussions** ‚Üí State diagram\n- **System architecture** ‚Üí Component diagram\n\n#### Example: Data Flow (Sequence Diagram)\n\n```mermaid\nsequenceDiagram\n    participant FE as Frontend\n    participant BE as Backend\n    participant SVC as External Service\n    participant DB as Database\n    FE->>BE: Click \"Submit Order\"\n    BE->>SVC: POST /process (send data)\n    SVC-->>BE: Return {status}\n    BE->>DB: Save result\n    BE-->>FE: Return success\n```\n\n#### Example: Database Schema (ER Diagram)\n\n```mermaid\nerDiagram\n    ORDER ||--o{ ORDER_ITEM : \"1:N\"\n    ORDER {\n        uuid id PK\n        string customer_name\n        decimal total_amount\n    }\n    ORDER_ITEM {\n        uuid id PK\n        uuid order_id FK\n        int quantity\n    }\n```\n\n#### Example: Version Switching (Workflow Diagram)\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant System\n    Note over System: Current: V2 Active\n    User->>System: Create V3 (inactive)\n    User->>System: Set V2 inactive\n    User->>System: Set V3 active\n    Note over System: New: V3 Active\n```\n\n### Quote Formatting Requirements (CRITICAL)\n\n**Quotes MUST use proper markdown blockquote format on separate lines:**\n\n**‚ùå WRONG: Inline quote format**\n```markdown\n* **Quote:** > \"This is wrong\" - **Speaker**\n```\n\n**‚úÖ CORRECT: Blockquote on separate lines**\n```markdown\n* **Quote:**\n  > \"This is the correct format\" - **Speaker**\n```\n\n**‚úÖ CORRECT: Multiple quotes**\n```markdown\n* **Quote:**\n  > \"First quote from the discussion\" - **Speaker1**\n  > \"Second quote supporting the same decision\" - **Speaker2**\n```\n\n**Key formatting rules:**\n- `* **Quote:**` on its own line (no quote content on this line)\n- Blank line NOT needed after `* **Quote:**`\n- Quote content indented with 2 spaces, then `> ` prefix\n- Speaker attribution at end of quote line: `- **SpeakerName**`\n- Multiple quotes use same indentation, each on its own line\n\n### Technical Decisions ‚Üí Decision Block\n\n```markdown\n### 2.X [Category] Decision Title\n\n* **Decision:** Specific decision made\n* **Logic:**\n  * Reasoning point 1\n  * Reasoning point 2\n* **Quote:**\n  > \"Exact quote from transcript\" - **Speaker Name**\n```\n\n### Deferred Items ‚Üí Parking Lot\n\nItems with keywords like \"defer to later\", \"Phase 2\", \"not in MVP\" go to Parking Lot with context.\n\n## Human-in-the-Loop Iteration (Essential)\n\nMeeting minutes are **not one-shot outputs**. High-quality minutes emerge through multiple review cycles:\n\n### Why Human Review is Critical\n\n1. **Terminology conflicts**: Humans know existing system naming (e.g., \"Note\" already means comments in the existing system)\n2. **Domain context**: Humans catch when a term could be confused with another (e.g., \"UserProfile\" vs \"Account\")\n3. **Organizational knowledge**: Humans know team conventions and prior decisions\n4. **Completeness gaps**: Humans can request \"deep review\" review when something feels missing\n\n### Example Iteration Pattern\n\n```\nRound 1: Initial generation\n  ‚îî‚îÄ Human review: \"Check original transcript for missing items\"\nRound 2: Deep transcript review, add omitted content\n  ‚îî‚îÄ Human review: \"UserProfile conflicts with existing Account entity naming\"\nRound 3: Update terminology to use \"CustomerProfile\" instead\n  ‚îî‚îÄ Human review: \"Note field conflicts with existing Comment system\"\nRound 4: Update to use \"Annotation\" instead of \"Note\"\n  ‚îî‚îÄ Human approval: Final version ready\n```\n\n### Key Principle\n\n**The AI generates the first draft; humans refine to the final version.** Never assume the first output is complete or uses correct terminology. Always encourage human review and be ready for multiple iteration cycles.\n\n## Anti-Patterns\n\n- ‚ùå **Single-pass generation** - One turn through transcript will absolutely lose content\n- ‚ùå **Divided sections without overlap** - Each pass must cover FULL transcript, not split by sections\n- ‚ùå **Narrow-focused passes** - Each pass must generate COMPLETE minutes (all sections), not just one section type (wastes tokens, causes bias)\n- ‚ùå Generic summaries without supporting quotes\n- ‚ùå Action items assigned to \"team\" instead of specific person\n- ‚ùå Missing numerical values (priorities, ranges, state counts)\n- ‚ùå State machines with incomplete states\n- ‚ùå Circular debate transcribed verbatim instead of summarized\n- ‚ùå Removing content during multi-version merge\n- ‚ùå Claiming \"nothing missing\" without section-by-section review\n- ‚ùå Treating first draft as final without human review\n- ‚ùå Using terminology without checking for conflicts with existing systems\n- ‚ùå Shared context between subagents (causes cross-contamination and missed content)\n- ‚ùå Keeping all intermediate outputs in conversation context (causes token overflow, use file system)\n- ‚ùå **Pure text minutes without diagrams** - Architecture/schema discussions deserve visual representation\n- ‚ùå **Deleting intermediate files after merge** - Preserve for human review and debugging\n- ‚ùå **Blindly copying external AI output** - Always verify against transcript before merging\n- ‚ùå **Ignoring cross-AI comparison opportunity** - Different AI models catch different details\n- ‚ùå **Sequential subagent execution** - MUST launch v1, v2, v3 subagents in PARALLEL using multiple Task tool calls in a single message\n- ‚ùå **Flat intermediate directory** - MUST use transcript-specific subdirectory `intermediate/<transcript-name>/` to avoid conflicts\n- ‚ùå **Inline quote formatting** - Quotes MUST use blockquote format on separate lines, not inline `> \"quote\"`\n- ‚ùå **Omitting diagrams during merge** - MUST aggressively include ALL diagrams from ALL versions, even if they seem similar\n- ‚ùå **Highlighting trivial terminology variations** - Do NOT point out differences like \"backend architecture\" vs \"backend\" or \"API\" vs \"endpoint\" between speakers; these are equivalent terms and highlighting such differences is disrespectful\n- ‚ùå **Duplicate content across sections** - Do NOT repeat the same information in multiple sections (e.g., API endpoint table in both \"Discussion\" and \"Reference\"); place content in ONE authoritative location and reference it if needed\n- ‚ùå **Creating non-existent links** - Do NOT create markdown links to files that don't exist in the repo (e.g., `[doc.md](reviewed-document)`); use plain text for external/local documents not in the repository\n- ‚ùå **Losing content during consolidation** - When moving or consolidating sections, verify ALL bullet points and details are preserved; never summarize away specific details like \"supports batch operations\" or \"button triggers auto-save\"\n- ‚ùå **Appending domain details to role titles** - Use ONLY the Role column from Team Directory for speaker attribution (e.g., \"Backend\", \"Frontend\", \"TPM\"); do NOT append specializations like \"Backend, Infrastructure\" or \"Backend, Business Logic\" - all team members with the same role should have identical attribution\n",
        "mermaid-tools/SKILL.md": "---\nname: mermaid-tools\ndescription: Extracts Mermaid diagrams from markdown files and generates high-quality PNG images using bundled scripts. Activates when working with Mermaid diagrams, converting diagrams to PNG, extracting diagrams from markdown, or processing markdown files with embedded Mermaid code.\n---\n\n# Mermaid Tools\n\n## Overview\n\nThis skill enables extraction of Mermaid diagrams from markdown files and generation of high-quality PNG images. The skill bundles all necessary scripts (`extract-and-generate.sh`, `extract_diagrams.py`, and `puppeteer-config.json`) in the `scripts/` directory for portability and reliability.\n\n## Core Workflow\n\n### Standard Diagram Extraction and Generation\n\nExtract Mermaid diagrams from a markdown file and generate PNG images using the bundled `extract-and-generate.sh` script:\n\n```bash\ncd ~/.claude/skills/mermaid-tools/scripts\n./extract-and-generate.sh \"<markdown_file>\" \"<output_directory>\"\n```\n\n**Parameters:**\n- `<markdown_file>`: Path to the markdown file containing Mermaid diagrams\n- `<output_directory>`: (Optional) Directory for output files. Defaults to `<markdown_file_directory>/diagrams`\n\n**Example:**\n```bash\ncd ~/.claude/skills/mermaid-tools/scripts\n./extract-and-generate.sh \"/path/to/document.md\" \"/path/to/output\"\n```\n\n### What the Script Does\n\n1. **Extracts** all Mermaid code blocks from the markdown file\n2. **Numbers** them sequentially (01, 02, 03, etc.) in order of appearance\n3. **Generates** `.mmd` files for each diagram\n4. **Creates** high-resolution PNG images with smart sizing\n5. **Validates** all generated PNG files\n\n### Output Files\n\nFor each diagram, the script generates:\n- `01-diagram-name.mmd` - Extracted Mermaid code\n- `01-diagram-name.png` - High-resolution PNG image\n\nThe numbering ensures diagrams maintain their order from the source document.\n\n## Advanced Usage\n\n### Custom Dimensions and Scaling\n\nOverride default dimensions using environment variables:\n\n```bash\ncd ~/.claude/skills/mermaid-tools/scripts\nMERMAID_WIDTH=1600 MERMAID_HEIGHT=1200 ./extract-and-generate.sh \"<markdown_file>\" \"<output_directory>\"\n```\n\n**Available variables:**\n- `MERMAID_WIDTH` (default: 1200) - Base width in pixels\n- `MERMAID_HEIGHT` (default: 800) - Base height in pixels\n- `MERMAID_SCALE` (default: 2) - Scale factor for high-resolution output\n\n### High-Resolution Output for Presentations\n\n```bash\ncd ~/.claude/skills/mermaid-tools/scripts\nMERMAID_WIDTH=2400 MERMAID_HEIGHT=1800 MERMAID_SCALE=4 ./extract-and-generate.sh \"<markdown_file>\" \"<output_directory>\"\n```\n\n### Print-Quality Output\n\n```bash\ncd ~/.claude/skills/mermaid-tools/scripts\nMERMAID_SCALE=5 ./extract-and-generate.sh \"<markdown_file>\" \"<output_directory>\"\n```\n\n## Smart Sizing Feature\n\nThe script automatically adjusts dimensions based on diagram type (detected from filename):\n\n- **Timeline/Gantt**: 2400√ó400 (wide and short)\n- **Architecture/System/Caching**: 2400√ó1600 (large and detailed)\n- **Monitoring/Workflow/Sequence/API**: 2400√ó800 (wide for process flows)\n- **Default**: 1200√ó800 (standard size)\n\nContext-aware naming in the extraction process helps trigger appropriate smart sizing.\n\n## Important Principles\n\n### Use Bundled Scripts\n\n**CRITICAL**: Use the bundled `extract-and-generate.sh` script from this skill's `scripts/` directory. All necessary dependencies are bundled together.\n\n### Change to Script Directory\n\nRun the script from its own directory to properly locate dependencies (`extract_diagrams.py` and `puppeteer-config.json`):\n\n```bash\ncd ~/.claude/skills/mermaid-tools/scripts\n./extract-and-generate.sh \"<markdown_file>\" \"<output_directory>\"\n```\n\nRunning the script without changing to the scripts directory first may fail due to missing dependencies.\n\n## Prerequisites Verification\n\nBefore running the script, verify dependencies are installed:\n\n1. **mermaid-cli**: `mmdc --version`\n2. **Google Chrome**: `google-chrome-stable --version`\n3. **Python 3**: `python3 --version`\n\nIf any are missing, consult `references/setup_and_troubleshooting.md` for installation instructions.\n\n## Troubleshooting\n\nFor detailed troubleshooting guidance, refer to `references/setup_and_troubleshooting.md`, which covers:\n\n- Browser launch failures\n- Permission issues\n- No diagrams found\n- Python extraction failures\n- Output quality issues\n- Diagram-specific sizing problems\n\nQuick fixes for common issues:\n\n**Permission denied:**\n```bash\nchmod +x ~/.claude/skills/mermaid-tools/scripts/extract-and-generate.sh\n```\n\n**Low quality output:**\n```bash\nMERMAID_SCALE=3 ./extract-and-generate.sh \"<markdown_file>\" \"<output_directory>\"\n```\n\n**Chrome/Puppeteer errors:**\nVerify all WSL2 dependencies are installed (see references for full list).\n\n## Bundled Resources\n\n### scripts/\n\nThis skill bundles all necessary scripts for Mermaid diagram generation:\n\n- **extract-and-generate.sh** - Main script that orchestrates extraction and PNG generation\n- **extract_diagrams.py** - Python script for extracting Mermaid code blocks from markdown\n- **puppeteer-config.json** - Chrome/Puppeteer configuration for WSL2 environment\n\nAll scripts must be run from the `scripts/` directory to properly locate dependencies.\n\n### references/setup_and_troubleshooting.md\n\nComprehensive reference documentation including:\n- Complete prerequisite installation instructions\n- Detailed environment variable reference\n- Extensive troubleshooting guide\n- WSL2-specific Chrome dependency setup\n- Validation procedures\n\nLoad this reference when dealing with setup issues, installation problems, or advanced customization needs.",
        "pdf-creator/SKILL.md": "---\nname: pdf-creator\ndescription: Create PDF documents from markdown with proper Chinese font support using weasyprint. This skill should be used when converting markdown to PDF, generating formal documents (legal, trademark filings, reports), or when Chinese typography is required. Triggers include \"convert to PDF\", \"generate PDF\", \"markdown to PDF\", or any request for creating printable documents.\n---\n\n# PDF Creator\n\nCreate professional PDF documents from markdown with proper Chinese font support.\n\n## Quick Start\n\nConvert a single markdown file:\n\n```bash\nuv run --with weasyprint --with markdown scripts/md_to_pdf.py input.md output.pdf\n```\n\nBatch convert multiple files:\n\n```bash\nuv run --with weasyprint --with markdown scripts/batch_convert.py *.md --output-dir ./pdfs\n```\n\n## macOS Environment Setup\n\nIf encountering library errors, set these environment variables first:\n\n```bash\nexport DYLD_LIBRARY_PATH=\"/opt/homebrew/lib:$DYLD_LIBRARY_PATH\"\nexport PKG_CONFIG_PATH=\"/opt/homebrew/lib/pkgconfig:$PKG_CONFIG_PATH\"\n```\n\n## Font Configuration\n\nThe scripts use these Chinese fonts (with fallbacks):\n\n| Font Type | Primary | Fallbacks |\n|-----------|---------|-----------|\n| Body text | Songti SC | SimSun, STSong, Noto Serif CJK SC |\n| Headings | Heiti SC | SimHei, STHeiti, Noto Sans CJK SC |\n\n## Output Specifications\n\n- **Page size**: A4\n- **Margins**: 2.5cm top/bottom, 2cm left/right\n- **Body font**: 12pt, 1.8 line height\n- **Max file size**: Designed to stay under 2MB for form submissions\n\n## Common Use Cases\n\n1. **Legal documents**: Trademark filings, contracts, evidence lists\n2. **Reports**: Business reports, technical documentation\n3. **Formal letters**: Official correspondence requiring print format\n\n## Troubleshooting\n\n**Problem**: Chinese characters display as boxes\n**Solution**: Ensure Songti SC or other Chinese fonts are installed on the system\n\n**Problem**: `weasyprint` import error\n**Solution**: Run with `uv run --with weasyprint --with markdown` to ensure dependencies\n",
        "ppt-creator/SKILL.md": "---\nname: ppt-creator\ndescription: \"Create professional slide decks from topics or documents. Generates structured content with data-driven charts, speaker notes, and complete PPTX files. Applies persuasive storytelling principles (Pyramid Principle, assertion-evidence). Supports multiple formats (Marp, PowerPoint). Use for presentations, pitches, slide decks, or keynotes.\"\n---\n\n# PPT Creator\n\n> **Goal**: Transform a simple topic into a presentation-ready, high-quality slide deck. When key information is missing, use the minimal intake form (references/INTAKE.md) to gather context or apply safe defaults. Then follow the workflow (references/WORKFLOW.md) to produce an outline, slide drafts, charts, and speaker notes. After generation, self-evaluate using the rubric (references/RUBRIC.md); if the score is < 75, automatically refine up to 2 iterations until ‚â• 75 before delivery. See **Deliverables** section for final output structure.\n\n## When to Use This Skill\n\nUse this skill when the user requests:\n- \"Make a presentation/deck/PPT/slides\" on any topic\n- \"Improve/optimize a presentation/pitch/demo\"\n- Converting scattered materials into a structured, persuasive slide deck\n- Creating presentations with data visualization and speaker notes\n- Building decks for business reviews, product pitches, educational content, or reports\n\n## Quick Start\n\n1. **Gather Intent**: If critical information is missing, ask the **10 Minimal Questions** (references/INTAKE.md). If the user doesn't respond after 2 prompts, use the **safe default** for each item and clearly note assumptions in speaker notes.\n\n2. **Structure the Story**: Apply the **Pyramid Principle** to establish \"one conclusion ‚Üí 3-5 top-level reasons ‚Üí supporting evidence.\" Each slide uses **assertion-style headings** (complete sentences), with body content providing evidence (charts/tables/diagrams/data points). Templates are in references/TEMPLATES.md.\n\n3. **Choose Charts**: Use the **Chart Selection Dictionary** in references/VIS-GUIDE.md to pick the most appropriate visualization for each point. If the user provides data (tables/CSV), **optionally** call `scripts/chartkit.py` to generate PNG charts; otherwise, create placeholder diagrams with a list of required data fields.\n\n4. **Layout & Style**: Follow references/STYLE-GUIDE.md for font sizes, line spacing, white space, contrast ratios, color palettes, and accessibility (WCAG AA compliance).\n\n5. **Speaker Notes**: Generate 45-60 second speaker notes for each slide, structured as: opening ‚Üí core assertion ‚Üí evidence explanation ‚Üí transition.\n\n6. **Self-Check & Score**: Use references/CHECKLIST.md for a pre-flight check, then score with references/RUBRIC.md. If total score < 75, identify the weakest 3 items and refine; repeat scoring (max 2 iterations).\n\n7. **Deliverables** (all saved to `/output/`):\n   - `/output/slides.md`: Markdown slides (Marp/Reveal.js compatible), with assertion-style headings + bullet points/chart placeholders + notes\n   - `/output/assets/*.png`: Generated charts (if applicable)\n   - `/output/notes.md`: Full speaker notes and delivery outline\n   - `/output/refs.md`: Citations and data sources\n   - `/output/presentation.pptx`: If `python-pptx` is available, export to PPTX; otherwise, keep Markdown and include instructions for \"one-click conversion to PPTX\" in the first screen (does not block delivery)\n\n## Orchestration Mode (End-to-End Automation)\n\nWhen the user requests a \"complete\" or \"presentation-ready\" deliverable, ppt-creator automatically orchestrates the full pipeline: content creation ‚Üí data synthesis ‚Üí chart generation ‚Üí dual-path PPTX creation (Marp + document-skills:pptx) ‚Üí chart insertion. This typically delivers TWO complete PPTX files with different styling for user comparison.\n\n**Activation**: Phrases like \"complete PPTX\", \"final deliverable\", \"ready for presentation\"\n**Duration**: 4-6 minutes (parallel execution)\n**Output**: presentation_marp_with_charts.pptx + presentation_pptx_with_charts.pptx\n\nFor orchestration details, see `references/ORCHESTRATION_OVERVIEW.md` (start here), then navigate to specialized guides as needed.\n\n## Core Principles (Must Follow)\n\n- **Information Organization**: Conclusion first, then evidence (Pyramid Principle). Each slide conveys **only 1 core idea**. Headings must be **testable assertion sentences**, not topic labels.\n- **Evidence-First**: Use charts/tables/evidence blocks instead of long paragraphs; limit to 3-5 bullet points per slide.\n- **Data Visualization**: Chart selection and labeling (axes/units/sources) must comply with references/VIS-GUIDE.md. If data is insufficient, provide \"placeholder chart + list of missing fields.\"\n- **Accessibility**: Color and text contrast must meet AA standards (see STYLE-GUIDE). Provide alt/readable descriptions for charts and images.\n- **Reusability**: Use consistent naming, stable paths, reproducible output. Do not hard-code random numbers in code.\n- **Safety & Dependencies**: Do not scrape the web without permission. Only run scripts when user provides data. If `matplotlib/pandas` are unavailable, fall back to text + placeholder diagram instructions.\n\n## Workflow Overview\n\n**Stage 0 - Archive Input**: Record user's original request, defaults used, and assumptions made.\n\n**Stage 1 - Structure Goals**: Rewrite the goal into \"who takes what action when\" (clear CTA).\n\n**Stage 2 - Storyline**: Use Pyramid Principle to define \"one-sentence conclusion ‚Üí 3-5 first-level reasons ‚Üí evidence.\"\n\n**Stage 3 - Outline & Slide Titles**: Create a 12-15 slide chapter skeleton. Each slide has one assertion-style heading.\n\n**Stage 4 - Evidence & Charts**: Use the Chart Selection Dictionary from VIS-GUIDE. If data is provided, call chartkit.py to generate PNGs; otherwise, create placeholder + required field list.\n\n**Stage 5 - Layout & Accessibility**: Apply STYLE-GUIDE for font sizes, spacing, contrast ratios, color palettes; unify units and decimal places.\n\n**Stage 6 - Speaker Notes**: Generate 45-60 second notes per slide: opening ‚Üí assertion ‚Üí evidence explanation ‚Üí transition.\n\n**Stage 7 - Self-Check & Scoring**: Run CHECKLIST; score with RUBRIC. If score < 75, focus on weakest 3 items, refine, re-score (max 2 iterations).\n\n**Stage 8 - Package Deliverables**: Generate `/output/` directory with slides.md / notes.md / refs.md / assets/*.png. If `python-pptx` is available, export PPTX.\n\n**Stage 9 - Reuse Instructions**: Append a \"5-step guide to replace data/colors with your own\" at the end of notes.md.\n\n## Resources\n\n### references/INTAKE.md\n**Minimal 10-Item Questionnaire** (use defaults if missing):\n1. Who is the audience? (Default: general public)\n2. Core objective? (Default: \"understand and accept\" a proposition)\n3. Desired action/decision? (Default: agree to move to next step after the meeting)\n4. Duration & slide count limit? (Default: 15-20 min, 12-15 slides)\n5. Tone & style? (Default: professional, clear, friendly)\n6. Topic scope & boundaries? (Default: given topic + 1 layer related)\n7. Must-include points/taboos? (Default: none)\n8. Available data/tables? (Default: none; can generate structure placeholder + list required fields)\n9. Brand & visual constraints? (Default: built-in neutral theme)\n10. Deliverable format preference? (Default: slides.md + optional PNG charts; export PPTX if available)\n\n### references/WORKFLOW.md\nDetailed step-by-step process from \"topic\" to \"presentation-ready output.\"\n\n### references/TEMPLATES.md\n**Slide Template Library** (assertion-evidence style):\n- Cover, Table of Contents, Problem Statement, Opportunity/Goal, Solution Overview, Evidence 1-3, Risk & Mitigation, Case Study/Comparison, Roadmap/Timeline, Conclusion & Actions, Backup Slides\n- Micro-templates: Comparison (A vs B), Pyramid Summary, Process 4-Step, KPI Dashboard, Geographic Distribution, Funnel, Pareto, Sensitivity, Cost Structure (Waterfall), Contribution (Stacked)\n\n### references/VIS-GUIDE.md\n**Data Visualization Selection & Labeling Standards**:\n- Chart Selection Dictionary (common questions ‚Üí chart types)\n- Labeling & units (axes, units, data scope, time range; source in footer)\n- Accessibility & contrast (WCAG 2.1 AA: text vs background ‚â• 4.5:1; UI elements ‚â• 3:1)\n- Assertion-Evidence writing tips\n\n### references/STYLE-GUIDE.md\n**Layout & Style** (neutral theme, supports brand replacement):\n- Canvas: 16:9; safe margins ‚â• 48px; grid column spacing 24px\n- Fonts: Chinese (Source Han Sans/PingFang/Hiragino Sans), English (Inter/Calibri)\n- Font sizes: Heading 34-40, Subheading 24-28, Body 18-22, Footer 14-16\n- Line spacing: Heading 1.1, Body 1.3; bullet spacing ‚â• 8px\n- Color palette (AA compliant): Dark ink #1F2937 / Background #FFFFFF / Accent #2563EB / Emphasis #DC2626\n- Components: unified 6-8px border radius; charts and images with 8px padding\n- Images: add brief alt descriptions for screen readers\n- Page density: ‚â§ 70 words per slide (excluding captions)\n\n### references/RUBRIC.md\n**PPT Quality Scoring Rubric** (100 points; ‚â• 75 to deliver):\nEach item scored 0-10:\n1. **Goal Clarity**: Audience, objective, CTA well-defined\n2. **Story Structure**: Pyramid structure complete, hierarchy clear\n3. **Slide Assertions**: Headings are \"assertion sentences\" supported by evidence\n4. **Evidence Quality**: Data/cases/citations sufficient, credible, consistent calibration\n5. **Chart Fit**: Correct selection, complete labeling, readable\n6. **Visual & Accessibility**: Contrast, font size, white space, color compliance\n7. **Coherence & Transitions**: Natural chapter and page transitions\n8. **Speakability**: 45-60 sec per slide, natural language\n9. **Deliverables Complete**: slides.md / notes.md / refs.md / (optional) assets/*.png\n10. **Robustness**: Gaps explicitly marked, fallback plan & next steps provided\n\nSelf-evaluation process: Run CHECKLIST first, then score each item and write top 3 low-scoring items + improvement actions. If total < 75, apply actions and re-score (max 2 iterations).\n\n### references/CHECKLIST.md\nPre-flight checklist for final quality assurance before delivery.\n\n### references/EXAMPLES.md\n**Two Usage Examples**:\n- **Example A**: Ultra-simple topic (\"coffee\") ‚Üí trigger minimal questionnaire, generate 12-page framework with placeholder charts\n- **Example B**: Small business monthly review with attached CSV ‚Üí parse data, select charts per VIS-GUIDE, call chartkit.py, refine 1-2 iterations if score < 75\n\n### scripts/chartkit.py\n**Minimal chart renderer** for ppt-creator.\n\n**Usage**:\n```bash\npython scripts/chartkit.py \\\n  --data path/to/data.csv \\\n  --type line \\\n  --x date \\\n  --y sales profit \\\n  --out output/assets \\\n  --filename kpi_trend.png \\\n  --title \"Monthly KPIs\"\n```\n\n**Notes**:\n- Requires: `pandas`, `matplotlib`\n- Fallback: If packages unavailable, print instruction message and exit(0)\n- Uses matplotlib defaults for readability (no hard-coded brand colors)\n\n## Advanced Tips\n\n- This skill **complements** (not conflicts with) Anthropic's built-in PowerPoint generation capabilities. Use this skill to produce \"high-quality structure & content,\" then optionally invoke system capabilities to export the final PPTX file.\n- For complex data analysis needs, combine with other skills (e.g., data analysis, charting) before invoking ppt-creator.\n- The skill is designed to be forgiving: missing information triggers safe defaults rather than blocking progress.\n",
        "prompt-optimizer/SKILL.md": "---\nname: prompt-optimizer\ndescription: Transform vague prompts into precise, well-structured specifications using EARS (Easy Approach to Requirements Syntax) methodology. This skill should be used when users provide loose requirements, ambiguous feature descriptions, or need to enhance prompts for AI-generated code, products, or documents. Triggers include requests to \"optimize my prompt\", \"improve this requirement\", \"make this more specific\", or when raw requirements lack detail and structure.\n---\n\n# Prompt Optimizer\n\n## Overview\n\nOptimize vague prompts into precise, actionable specifications using EARS (Easy Approach to Requirements Syntax) - a Rolls-Royce methodology for transforming natural language into structured, testable requirements.\n\n**Methodology inspired by:** This skill's approach to combining EARS with domain theory grounding was inspired by [ÈòøÊòüAIÂ∑•‰ΩúÂÆ§ (A-Xing AI Studio)](https://mp.weixin.qq.com/s/yUVX-9FovSq7ZGChkHpuXQ), which demonstrated practical EARS application for prompt enhancement.\n\n**Four-layer enhancement process:**\n\n1. **EARS syntax transformation** - Convert descriptive language to normative specifications\n2. **Domain theory grounding** - Apply relevant industry frameworks (GTD, BJ Fogg, Gestalt, etc.)\n3. **Example extraction** - Surface concrete use cases with real data\n4. **Structured prompt generation** - Format using Role/Skills/Workflows/Examples/Formats framework\n\n## When to Use\n\nApply when:\n- User provides vague feature requests (\"build a dashboard\", \"create a reminder app\")\n- Requirements lack specific conditions, triggers, or measurable outcomes\n- Natural language descriptions need conversion to testable specifications\n- User explicitly requests prompt optimization or requirement refinement\n\n## Six-Step Optimization Workflow\n\n### Step 1: Analyze Original Requirement\n\nIdentify weaknesses:\n- **Overly broad** - \"Add user authentication\" ‚Üí Missing password requirements, session management\n- **Missing triggers** - \"Send notifications\" ‚Üí Missing when/why notifications trigger\n- **Ambiguous actions** - \"Make it user-friendly\" ‚Üí No measurable usability criteria\n- **No constraints** - \"Process payments\" ‚Üí Missing security, compliance requirements\n\n### Step 2: Apply EARS Transformation\n\nConvert requirements to EARS patterns. See `references/ears_syntax.md` for complete syntax rules.\n\n**Five core patterns:**\n1. **Ubiquitous**: `The system shall <action>`\n2. **Event-driven**: `When <trigger>, the system shall <action>`\n3. **State-driven**: `While <state>, the system shall <action>`\n4. **Conditional**: `If <condition>, the system shall <action>`\n5. **Unwanted behavior**: `If <condition>, the system shall prevent <unwanted action>`\n\n**Quick example:**\n```\nBefore: \"Create a reminder app with task management\"\n\nAfter (EARS):\n1. When user creates a task, the system shall guide decomposition into executable sub-tasks\n2. When task deadline is within 30 minutes AND user has not started, the system shall send notification with sound alert\n3. When user completes a sub-task, the system shall update progress and provide positive feedback\n```\n\n**Transformation checklist:**\n- [ ] Identify implicit conditions and make explicit\n- [ ] Specify triggering events or states\n- [ ] Use precise action verbs (shall, must, should)\n- [ ] Add measurable criteria (\"within 30 minutes\", \"at least 8 characters\")\n- [ ] Break compound requirements into atomic statements\n- [ ] Remove ambiguous language (\"user-friendly\", \"fast\")\n\n### Step 3: Identify Domain Theories\n\nMatch requirements to established frameworks. See `references/domain_theories.md` for full catalog.\n\n**Common domain mappings:**\n- **Productivity** ‚Üí GTD, Pomodoro, Eisenhower Matrix\n- **Behavior Change** ‚Üí BJ Fogg Model (B=MAT), Atomic Habits\n- **UX Design** ‚Üí Hick's Law, Fitts's Law, Gestalt Principles\n- **Security** ‚Üí Zero Trust, Defense in Depth, Privacy by Design\n\n**Selection process:**\n1. Identify primary domain from requirement keywords\n2. Match to 2-4 complementary theories\n3. Apply theory principles to specific features\n4. Cite theories in enhanced prompt for credibility\n\n### Step 4: Extract Concrete Examples\n\nGenerate specific examples with real data:\n- User scenarios: \"When user logs in on mobile device...\"\n- Data examples: \"Product: 'Laptop', Price: $999, Stock: 15\"\n- Workflow examples: \"Task: Write report ‚Üí Sub-tasks: Research (2h), Draft (3h), Edit (1h)\"\n\nExamples must be **realistic**, **specific**, **varied** (success/error/edge cases), and **testable**.\n\n### Step 5: Generate Enhanced Prompt\n\nStructure using the standard framework:\n\n```markdown\n# Role\n[Specific expert role with domain expertise]\n\n## Skills\n- [Core capability 1]\n- [Core capability 2]\n[List 5-8 skills aligned with domain theories]\n\n## Workflows\n1. [Phase 1] - [Key activities]\n2. [Phase 2] - [Key activities]\n[Complete step-by-step process]\n\n## Examples\n[Concrete examples with real data, not placeholders]\n\n## Formats\n[Precise output specifications:\n- File types, structure requirements\n- Design/styling expectations\n- Technical constraints\n- Deliverable checklist]\n```\n\n**Quality criteria:**\n- **Role specificity**: \"Product designer specializing in time management apps\" > \"Designer\"\n- **Theory grounding**: Reference frameworks explicitly\n- **Actionable workflows**: Clear inputs/outputs and decision points\n- **Concrete examples**: Real data, not \"Example 1\", \"Example 2\"\n- **Measurable formats**: Specific requirements, not \"good design\"\n\n### Step 6: Present Optimization Results\n\nOutput in structured format:\n\n```markdown\n## Original Requirement\n[User's vague requirement]\n\n**Identified Issues:**\n- [Issue 1: e.g., \"Lacks specific trigger conditions\"]\n- [Issue 2: e.g., \"No measurable success criteria\"]\n\n## EARS Transformation\n[Numbered list of EARS-formatted requirements]\n\n## Domain & Theories\n**Primary Domain:** [e.g., Authentication Security]\n\n**Applicable Theories:**\n- **[Theory 1]** - [Brief relevance]\n- **[Theory 2]** - [Brief relevance]\n\n## Enhanced Prompt\n[Complete Role/Skills/Workflows/Examples/Formats prompt]\n\n---\n\n**How to use:**\n[Brief guidance on applying the prompt]\n```\n\n## Advanced Techniques\n\nFor complex scenarios, see `references/advanced_techniques.md`:\n- **Multi-stakeholder requirements** - EARS statements for each user type\n- **Non-functional requirements** - Performance, security, scalability with quantified thresholds\n- **Complex conditional logic** - Nested conditions with boolean operators\n\n## Quick Reference\n\n**Do's:**\n‚úÖ Break down compound requirements (one EARS statement per requirement)\n‚úÖ Specify measurable criteria (numbers, timeframes, percentages)\n‚úÖ Include error/edge cases\n‚úÖ Ground in established theories\n‚úÖ Use concrete examples with real data\n\n**Don'ts:**\n‚ùå Avoid vague language (\"fast\", \"user-friendly\")\n‚ùå Don't assume implicit knowledge\n‚ùå Don't mix multiple actions in one statement\n‚ùå Don't use placeholders in examples\n\n## Resources\n\nLoad these reference files as needed:\n\n- **`references/ears_syntax.md`** - Complete EARS syntax rules, all 5 patterns, transformation guidelines, benefits\n- **`references/domain_theories.md`** - 40+ theories mapped to 10 domains (productivity, UX, gamification, learning, e-commerce, security, etc.)\n- **`references/examples.md`** - Four complete transformation examples (procrastination app, e-commerce product page, learning dashboard, password reset security) with before/after comparisons and reusable template\n- **`references/advanced_techniques.md`** - Multi-stakeholder requirements, non-functional specs, complex conditional logic patterns\n\n**When to load references:**\n- EARS syntax clarification needed ‚Üí `ears_syntax.md`\n- Domain theory selection requires extensive options ‚Üí `domain_theories.md`\n- User requests multiple optimization examples ‚Üí `examples.md`\n- Complex requirements with multiple stakeholders or non-functional specs ‚Üí `advanced_techniques.md`\n",
        "promptfoo-evaluation/SKILL.md": "---\nname: promptfoo-evaluation\ndescription: Configures and runs LLM evaluation using Promptfoo framework. Use when setting up prompt testing, creating evaluation configs (promptfooconfig.yaml), writing Python custom assertions, implementing llm-rubric for LLM-as-judge, or managing few-shot examples in prompts. Triggers on keywords like \"promptfoo\", \"eval\", \"LLM evaluation\", \"prompt testing\", or \"model comparison\".\n---\n\n# Promptfoo Evaluation\n\n## Overview\n\nThis skill provides guidance for configuring and running LLM evaluations using [Promptfoo](https://www.promptfoo.dev/), an open-source CLI tool for testing and comparing LLM outputs.\n\n## Quick Start\n\n```bash\n# Initialize a new evaluation project\nnpx promptfoo@latest init\n\n# Run evaluation\nnpx promptfoo@latest eval\n\n# View results in browser\nnpx promptfoo@latest view\n```\n\n## Configuration Structure\n\nA typical Promptfoo project structure:\n\n```\nproject/\n‚îú‚îÄ‚îÄ promptfooconfig.yaml    # Main configuration\n‚îú‚îÄ‚îÄ prompts/\n‚îÇ   ‚îú‚îÄ‚îÄ system.md           # System prompt\n‚îÇ   ‚îî‚îÄ‚îÄ chat.json           # Chat format prompt\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îî‚îÄ‚îÄ cases.yaml          # Test cases\n‚îî‚îÄ‚îÄ scripts/\n    ‚îî‚îÄ‚îÄ metrics.py          # Custom Python assertions\n```\n\n## Core Configuration (promptfooconfig.yaml)\n\n```yaml\n# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json\ndescription: \"My LLM Evaluation\"\n\n# Prompts to test\nprompts:\n  - file://prompts/system.md\n  - file://prompts/chat.json\n\n# Models to compare\nproviders:\n  - id: anthropic:messages:claude-sonnet-4-5-20250929\n    label: Claude-4.5-Sonnet\n  - id: openai:gpt-4.1\n    label: GPT-4.1\n\n# Test cases\ntests: file://tests/cases.yaml\n\n# Default assertions for all tests\ndefaultTest:\n  assert:\n    - type: python\n      value: file://scripts/metrics.py:custom_assert\n    - type: llm-rubric\n      value: |\n        Evaluate the response quality on a 0-1 scale.\n      threshold: 0.7\n\n# Output path\noutputPath: results/eval-results.json\n```\n\n## Prompt Formats\n\n### Text Prompt (system.md)\n\n```markdown\nYou are a helpful assistant.\n\nTask: {{task}}\nContext: {{context}}\n```\n\n### Chat Format (chat.json)\n\n```json\n[\n  {\"role\": \"system\", \"content\": \"{{system_prompt}}\"},\n  {\"role\": \"user\", \"content\": \"{{user_input}}\"}\n]\n```\n\n### Few-Shot Pattern\n\nEmbed examples directly in prompt or use chat format with assistant messages:\n\n```json\n[\n  {\"role\": \"system\", \"content\": \"{{system_prompt}}\"},\n  {\"role\": \"user\", \"content\": \"Example input: {{example_input}}\"},\n  {\"role\": \"assistant\", \"content\": \"{{example_output}}\"},\n  {\"role\": \"user\", \"content\": \"Now process: {{actual_input}}\"}\n]\n```\n\n## Test Cases (tests/cases.yaml)\n\n```yaml\n- description: \"Test case 1\"\n  vars:\n    system_prompt: file://prompts/system.md\n    user_input: \"Hello world\"\n    # Load content from files\n    context: file://data/context.txt\n  assert:\n    - type: contains\n      value: \"expected text\"\n    - type: python\n      value: file://scripts/metrics.py:custom_check\n      threshold: 0.8\n```\n\n## Python Custom Assertions\n\nCreate a Python file for custom assertions (e.g., `scripts/metrics.py`):\n\n```python\ndef get_assert(output: str, context: dict) -> dict:\n    \"\"\"Default assertion function.\"\"\"\n    vars_dict = context.get('vars', {})\n\n    # Access test variables\n    expected = vars_dict.get('expected', '')\n\n    # Return result\n    return {\n        \"pass\": expected in output,\n        \"score\": 0.8,\n        \"reason\": \"Contains expected content\",\n        \"named_scores\": {\"relevance\": 0.9}\n    }\n\ndef custom_check(output: str, context: dict) -> dict:\n    \"\"\"Custom named assertion.\"\"\"\n    word_count = len(output.split())\n    passed = 100 <= word_count <= 500\n\n    return {\n        \"pass\": passed,\n        \"score\": min(1.0, word_count / 300),\n        \"reason\": f\"Word count: {word_count}\"\n    }\n```\n\n**Key points:**\n- Default function name is `get_assert`\n- Specify function with `file://path.py:function_name`\n- Return `bool`, `float` (score), or `dict` with pass/score/reason\n- Access variables via `context['vars']`\n\n## LLM-as-Judge (llm-rubric)\n\n```yaml\nassert:\n  - type: llm-rubric\n    value: |\n      Evaluate the response based on:\n      1. Accuracy of information\n      2. Clarity of explanation\n      3. Completeness\n\n      Score 0.0-1.0 where 0.7+ is passing.\n    threshold: 0.7\n    provider: openai:gpt-4.1  # Optional: override grader model\n```\n\n**Best practices:**\n- Provide clear scoring criteria\n- Use `threshold` to set minimum passing score\n- Default grader uses available API keys (OpenAI ‚Üí Anthropic ‚Üí Google)\n\n## Common Assertion Types\n\n| Type | Usage | Example |\n|------|-------|---------|\n| `contains` | Check substring | `value: \"hello\"` |\n| `icontains` | Case-insensitive | `value: \"HELLO\"` |\n| `equals` | Exact match | `value: \"42\"` |\n| `regex` | Pattern match | `value: \"\\\\d{4}\"` |\n| `python` | Custom logic | `value: file://script.py` |\n| `llm-rubric` | LLM grading | `value: \"Is professional\"` |\n| `latency` | Response time | `threshold: 1000` |\n\n## File References\n\nAll paths are relative to config file location:\n\n```yaml\n# Load file content as variable\nvars:\n  content: file://data/input.txt\n\n# Load prompt from file\nprompts:\n  - file://prompts/main.md\n\n# Load test cases from file\ntests: file://tests/cases.yaml\n\n# Load Python assertion\nassert:\n  - type: python\n    value: file://scripts/check.py:validate\n```\n\n## Running Evaluations\n\n```bash\n# Basic run\nnpx promptfoo@latest eval\n\n# With specific config\nnpx promptfoo@latest eval --config path/to/config.yaml\n\n# Output to file\nnpx promptfoo@latest eval --output results.json\n\n# Filter tests\nnpx promptfoo@latest eval --filter-metadata category=math\n\n# View results\nnpx promptfoo@latest view\n```\n\n## Troubleshooting\n\n**Python not found:**\n```bash\nexport PROMPTFOO_PYTHON=python3\n```\n\n**Large outputs truncated:**\nOutputs over 30000 characters are truncated. Use `head_limit` in assertions.\n\n**File not found errors:**\nEnsure paths are relative to `promptfooconfig.yaml` location.\n\n## Echo Provider (Preview Mode)\n\nUse the **echo provider** to preview rendered prompts without making API calls:\n\n```yaml\n# promptfooconfig-preview.yaml\nproviders:\n  - echo  # Returns prompt as output, no API calls\n\ntests:\n  - vars:\n      input: \"test content\"\n```\n\n**Use cases:**\n- Preview prompt rendering before expensive API calls\n- Verify Few-shot examples are loaded correctly\n- Debug variable substitution issues\n- Validate prompt structure\n\n```bash\n# Run preview mode\nnpx promptfoo@latest eval --config promptfooconfig-preview.yaml\n```\n\n**Cost:** Free - no API tokens consumed.\n\n## Advanced Few-Shot Implementation\n\n### Multi-turn Conversation Pattern\n\nFor complex few-shot learning with full examples:\n\n```json\n[\n  {\"role\": \"system\", \"content\": \"{{system_prompt}}\"},\n\n  // Few-shot Example 1\n  {\"role\": \"user\", \"content\": \"Task: {{example_input_1}}\"},\n  {\"role\": \"assistant\", \"content\": \"{{example_output_1}}\"},\n\n  // Few-shot Example 2 (optional)\n  {\"role\": \"user\", \"content\": \"Task: {{example_input_2}}\"},\n  {\"role\": \"assistant\", \"content\": \"{{example_output_2}}\"},\n\n  // Actual test\n  {\"role\": \"user\", \"content\": \"Task: {{actual_input}}\"}\n]\n```\n\n**Test case configuration:**\n\n```yaml\ntests:\n  - vars:\n      system_prompt: file://prompts/system.md\n      # Few-shot examples\n      example_input_1: file://data/examples/input1.txt\n      example_output_1: file://data/examples/output1.txt\n      example_input_2: file://data/examples/input2.txt\n      example_output_2: file://data/examples/output2.txt\n      # Actual test\n      actual_input: file://data/test1.txt\n```\n\n**Best practices:**\n- Use 1-3 few-shot examples (more may dilute effectiveness)\n- Ensure examples match the task format exactly\n- Load examples from files for better maintainability\n- Use echo provider first to verify structure\n\n## Long Text Handling\n\nFor Chinese/long-form content evaluations (10k+ characters):\n\n**Configuration:**\n\n```yaml\nproviders:\n  - id: anthropic:messages:claude-sonnet-4-5-20250929\n    config:\n      max_tokens: 8192  # Increase for long outputs\n\ndefaultTest:\n  assert:\n    - type: python\n      value: file://scripts/metrics.py:check_length\n```\n\n**Python assertion for text metrics:**\n\n```python\nimport re\n\ndef strip_tags(text: str) -> str:\n    \"\"\"Remove HTML tags for pure text.\"\"\"\n    return re.sub(r'<[^>]+>', '', text)\n\ndef check_length(output: str, context: dict) -> dict:\n    \"\"\"Check output length constraints.\"\"\"\n    raw_input = context['vars'].get('raw_input', '')\n\n    input_len = len(strip_tags(raw_input))\n    output_len = len(strip_tags(output))\n\n    reduction_ratio = 1 - (output_len / input_len) if input_len > 0 else 0\n\n    return {\n        \"pass\": 0.7 <= reduction_ratio <= 0.9,\n        \"score\": reduction_ratio,\n        \"reason\": f\"Reduction: {reduction_ratio:.1%} (target: 70-90%)\",\n        \"named_scores\": {\n            \"input_length\": input_len,\n            \"output_length\": output_len,\n            \"reduction_ratio\": reduction_ratio\n        }\n    }\n```\n\n## Real-World Example\n\n**Project:** Chinese short-video content curation from long transcripts\n\n**Structure:**\n```\ntiaogaoren/\n‚îú‚îÄ‚îÄ promptfooconfig.yaml          # Production config\n‚îú‚îÄ‚îÄ promptfooconfig-preview.yaml  # Preview config (echo provider)\n‚îú‚îÄ‚îÄ prompts/\n‚îÇ   ‚îú‚îÄ‚îÄ tiaogaoren-prompt.json   # Chat format with few-shot\n‚îÇ   ‚îî‚îÄ‚îÄ v4/system-v4.md          # System prompt\n‚îú‚îÄ‚îÄ tests/cases.yaml              # 3 test samples\n‚îú‚îÄ‚îÄ scripts/metrics.py            # Custom metrics (reduction ratio, etc.)\n‚îú‚îÄ‚îÄ data/                         # 5 samples (2 few-shot, 3 eval)\n‚îî‚îÄ‚îÄ results/\n```\n\n**See:** `/Users/tiansheng/Workspace/prompts/tiaogaoren/` for full implementation.\n\n## Resources\n\nFor detailed API reference and advanced patterns, see [references/promptfoo_api.md](references/promptfoo_api.md).\n",
        "qa-expert/SKILL.md": "---\nname: qa-expert\ndescription: This skill should be used when establishing comprehensive QA testing processes for any software project. Use when creating test strategies, writing test cases following Google Testing Standards, executing test plans, tracking bugs with P0-P4 classification, calculating quality metrics, or generating progress reports. Includes autonomous execution capability via master prompts and complete documentation templates for third-party QA team handoffs. Implements OWASP security testing and achieves 90% coverage targets.\nkeywords: [qa, testing, test-cases, bug-tracking, google-standards, owasp, security, automation, quality-gates, metrics]\n---\n\n# QA Expert\n\nEstablish world-class QA testing processes for any software project using proven methodologies from Google Testing Standards and OWASP security best practices.\n\n## When to Use This Skill\n\nTrigger this skill when:\n- Setting up QA infrastructure for a new or existing project\n- Writing standardized test cases (AAA pattern compliance)\n- Executing comprehensive test plans with progress tracking\n- Implementing security testing (OWASP Top 10)\n- Filing bugs with proper severity classification (P0-P4)\n- Generating QA reports (daily summaries, weekly progress)\n- Calculating quality metrics (pass rate, coverage, gates)\n- Preparing QA documentation for third-party team handoffs\n- Enabling autonomous LLM-driven test execution\n\n## Quick Start\n\n**One-command initialization**:\n```bash\npython scripts/init_qa_project.py <project-name> [output-directory]\n```\n\n**What gets created**:\n- Directory structure (`tests/docs/`, `tests/e2e/`, `tests/fixtures/`)\n- Tracking CSVs (`TEST-EXECUTION-TRACKING.csv`, `BUG-TRACKING-TEMPLATE.csv`)\n- Documentation templates (`BASELINE-METRICS.md`, `WEEKLY-PROGRESS-REPORT.md`)\n- Master QA Prompt for autonomous execution\n- README with complete quickstart guide\n\n**For autonomous execution** (recommended): See `references/master_qa_prompt.md` - single copy-paste command for 100x speedup.\n\n## Core Capabilities\n\n### 1. QA Project Initialization\n\nInitialize complete QA infrastructure with all templates:\n\n```bash\npython scripts/init_qa_project.py <project-name> [output-directory]\n```\n\nCreates directory structure, tracking CSVs, documentation templates, and master prompt for autonomous execution.\n\n**Use when**: Starting QA from scratch or migrating to structured QA process.\n\n### 2. Test Case Writing\n\nWrite standardized, reproducible test cases following AAA pattern (Arrange-Act-Assert):\n\n1. Read template: `assets/templates/TEST-CASE-TEMPLATE.md`\n2. Follow structure: Prerequisites (Arrange) ‚Üí Test Steps (Act) ‚Üí Expected Results (Assert)\n3. Assign priority: P0 (blocker) ‚Üí P4 (low)\n4. Include edge cases and potential bugs\n\n**Test case format**: TC-[CATEGORY]-[NUMBER] (e.g., TC-CLI-001, TC-WEB-042, TC-SEC-007)\n\n**Reference**: See `references/google_testing_standards.md` for complete AAA pattern guidelines and coverage thresholds.\n\n### 3. Test Execution & Tracking\n\n**Ground Truth Principle** (critical):\n- **Test case documents** (e.g., `02-CLI-TEST-CASES.md`) = **authoritative source** for test steps\n- **Tracking CSV** = execution status only (do NOT trust CSV for test specifications)\n- See `references/ground_truth_principle.md` for preventing doc/CSV sync issues\n\n**Manual execution**:\n1. Read test case from category document (e.g., `02-CLI-TEST-CASES.md`) ‚Üê **always start here**\n2. Execute test steps exactly as documented\n3. Update `TEST-EXECUTION-TRACKING.csv` **immediately** after EACH test (never batch)\n4. File bug in `BUG-TRACKING-TEMPLATE.csv` if test fails\n\n**Autonomous execution** (recommended):\n1. Copy master prompt from `references/master_qa_prompt.md`\n2. Paste to LLM session\n3. LLM auto-executes, auto-tracks, auto-files bugs, auto-generates reports\n\n**Innovation**: 100x faster vs manual + zero human error in tracking + auto-resume capability.\n\n### 4. Bug Reporting\n\nFile bugs with proper severity classification:\n\n**Required fields**:\n- Bug ID: Sequential (BUG-001, BUG-002, ...)\n- Severity: P0 (24h fix) ‚Üí P4 (optional)\n- Steps to Reproduce: Numbered, specific\n- Environment: OS, versions, configuration\n\n**Severity classification**:\n- **P0 (Blocker)**: Security vulnerability, core functionality broken, data loss\n- **P1 (Critical)**: Major feature broken with workaround\n- **P2 (High)**: Minor feature issue, edge case\n- **P3 (Medium)**: Cosmetic issue\n- **P4 (Low)**: Documentation typo\n\n**Reference**: See `BUG-TRACKING-TEMPLATE.csv` for complete template with examples.\n\n### 5. Quality Metrics Calculation\n\nCalculate comprehensive QA metrics and quality gates status:\n\n```bash\npython scripts/calculate_metrics.py <path/to/TEST-EXECUTION-TRACKING.csv>\n```\n\n**Metrics dashboard includes**:\n- Test execution progress (X/Y tests, Z% complete)\n- Pass rate (passed/executed %)\n- Bug analysis (unique bugs, P0/P1/P2 breakdown)\n- Quality gates status (‚úÖ/‚ùå for each gate)\n\n**Quality gates** (all must pass for release):\n| Gate | Target | Blocker |\n|------|--------|---------|\n| Test Execution | 100% | Yes |\n| Pass Rate | ‚â•80% | Yes |\n| P0 Bugs | 0 | Yes |\n| P1 Bugs | ‚â§5 | Yes |\n| Code Coverage | ‚â•80% | Yes |\n| Security | 90% OWASP | Yes |\n\n### 6. Progress Reporting\n\nGenerate QA reports for stakeholders:\n\n**Daily summary** (end-of-day):\n- Tests executed, pass rate, bugs filed\n- Blockers (or None)\n- Tomorrow's plan\n\n**Weekly report** (every Friday):\n- Use template: `WEEKLY-PROGRESS-REPORT.md` (created by init script)\n- Compare against baseline: `BASELINE-METRICS.md`\n- Assess quality gates and trends\n\n**Reference**: See `references/llm_prompts_library.md` for 30+ ready-to-use reporting prompts.\n\n### 7. Security Testing (OWASP)\n\nImplement OWASP Top 10 security testing:\n\n**Coverage targets**:\n1. **A01: Broken Access Control** - RLS bypass, privilege escalation\n2. **A02: Cryptographic Failures** - Token encryption, password hashing\n3. **A03: Injection** - SQL injection, XSS, command injection\n4. **A04: Insecure Design** - Rate limiting, anomaly detection\n5. **A05: Security Misconfiguration** - Verbose errors, default credentials\n6. **A07: Authentication Failures** - Session hijacking, CSRF\n7. **Others**: Data integrity, logging, SSRF\n\n**Target**: 90% OWASP coverage (9/10 threats mitigated).\n\nEach security test follows AAA pattern with specific attack vectors documented.\n\n## Day 1 Onboarding\n\nFor new QA engineers joining a project, complete 5-hour onboarding guide:\n\n**Read**: `references/day1_onboarding.md`\n\n**Timeline**:\n- Hour 1: Environment setup (database, dev server, dependencies)\n- Hour 2: Documentation review (test strategy, quality gates)\n- Hour 3: Test data setup (users, CLI, DevTools)\n- Hour 4: Execute first test case\n- Hour 5: Team onboarding & Week 1 planning\n\n**Checkpoint**: By end of Day 1, environment running, first test executed, ready for Week 1.\n\n## Autonomous Execution (‚≠ê Recommended)\n\nEnable LLM-driven autonomous QA testing with single master prompt:\n\n**Read**: `references/master_qa_prompt.md`\n\n**Features**:\n- Auto-resume from last completed test (reads tracking CSV)\n- Auto-execute test cases (Week 1-5 progression)\n- Auto-track results (updates CSV after each test)\n- Auto-file bugs (creates bug reports for failures)\n- Auto-generate reports (daily summaries, weekly reports)\n- Auto-escalate P0 bugs (stops testing, notifies stakeholders)\n\n**Benefits**:\n- 100x faster execution vs manual\n- Zero human error in tracking\n- Consistent bug documentation\n- Immediate progress visibility\n\n**Usage**: Copy master prompt, paste to LLM, let it run autonomously for 5 weeks.\n\n## Adapting for Your Project\n\n### Small Project (50 tests)\n- Timeline: 2 weeks\n- Categories: 2-3 (e.g., Frontend, Backend)\n- Daily: 5-7 tests\n- Reports: Daily summary only\n\n### Medium Project (200 tests)\n- Timeline: 4 weeks\n- Categories: 4-5 (CLI, Web, API, DB, Security)\n- Daily: 10-12 tests\n- Reports: Daily + weekly\n\n### Large Project (500+ tests)\n- Timeline: 8-10 weeks\n- Categories: 6-8 (multiple components)\n- Daily: 10-15 tests\n- Reports: Daily + weekly + bi-weekly stakeholder\n\n## Reference Documents\n\nAccess detailed guidelines from bundled references:\n\n- **`references/day1_onboarding.md`** - 5-hour onboarding guide for new QA engineers\n- **`references/master_qa_prompt.md`** - Single command for autonomous LLM execution (100x speedup)\n- **`references/llm_prompts_library.md`** - 30+ ready-to-use prompts for specific QA tasks\n- **`references/google_testing_standards.md`** - AAA pattern, coverage thresholds, fail-fast validation\n- **`references/ground_truth_principle.md`** - Preventing doc/CSV sync issues (critical for test suite integrity)\n\n## Assets & Templates\n\nTest case templates and bug report formats:\n\n- **`assets/templates/TEST-CASE-TEMPLATE.md`** - Complete template with CLI and security examples\n\n## Scripts\n\nAutomation scripts for QA infrastructure:\n\n- **`scripts/init_qa_project.py`** - Initialize QA infrastructure (one command setup)\n- **`scripts/calculate_metrics.py`** - Generate quality metrics dashboard\n\n## Common Patterns\n\n### Pattern 1: Starting Fresh QA\n```\n1. python scripts/init_qa_project.py my-app ./\n2. Fill in BASELINE-METRICS.md (document current state)\n3. Write test cases using assets/templates/TEST-CASE-TEMPLATE.md\n4. Copy master prompt from references/master_qa_prompt.md\n5. Paste to LLM ‚Üí autonomous execution begins\n```\n\n### Pattern 2: LLM-Driven Testing (Autonomous)\n```\n1. Read references/master_qa_prompt.md\n2. Copy the single master prompt (one paragraph)\n3. Paste to LLM conversation\n4. LLM executes all 342 test cases over 5 weeks\n5. LLM updates tracking CSVs automatically\n6. LLM generates weekly reports automatically\n```\n\n### Pattern 3: Adding Security Testing\n```\n1. Read references/google_testing_standards.md (OWASP section)\n2. Write TC-SEC-XXX test cases for each OWASP threat\n3. Target 90% coverage (9/10 threats)\n4. Document mitigations in test cases\n```\n\n### Pattern 4: Third-Party QA Handoff\n```\n1. Ensure all templates populated\n2. Verify BASELINE-METRICS.md complete\n3. Package tests/docs/ folder\n4. Include references/master_qa_prompt.md for autonomous execution\n5. QA team can start immediately (Day 1 onboarding ‚Üí 5 weeks testing)\n```\n\n## Success Criteria\n\nThis skill is effective when:\n- ‚úÖ Test cases are reproducible by any engineer\n- ‚úÖ Quality gates objectively measured\n- ‚úÖ Bugs fully documented with repro steps\n- ‚úÖ Progress visible in real-time (CSV tracking)\n- ‚úÖ Autonomous execution enabled (LLM can execute full plan)\n- ‚úÖ Third-party QA teams can start testing immediately\n",
        "repomix-safe-mixer/SKILL.md": "---\nname: repomix-safe-mixer\ndescription: Safely package codebases with repomix by automatically detecting and removing hardcoded credentials before packing. Use when packaging code for distribution, creating reference packages, or when the user mentions security concerns about sharing code with repomix.\n---\n\n# Repomix Safe Mixer\n\n## Overview\n\nSafely package codebases with repomix by automatically detecting and removing hardcoded credentials.\n\nThis skill prevents accidental credential exposure when packaging code with repomix. It scans for hardcoded secrets (API keys, database credentials, tokens), reports findings, and ensures safe packaging.\n\n**When to use**: When packaging code with repomix for distribution, creating shareable reference packages, or whenever security concerns exist about hardcoded credentials in code.\n\n## Core Workflow\n\n### Standard Safe Packaging\n\nUse `safe_pack.py` from this skill's `scripts/` directory for the complete workflow: scan ‚Üí report ‚Üí pack.\n\n```bash\npython3 scripts/safe_pack.py <directory>\n```\n\n**What it does**:\n1. Scans directory for hardcoded credentials\n2. Reports findings with file/line details\n3. Blocks packaging if secrets found\n4. Packs with repomix only if scan is clean\n\n**Example**:\n```bash\npython3 scripts/safe_pack.py ./my-project\n```\n\n**Output if clean**:\n```\nüîç Scanning ./my-project for hardcoded secrets...\n‚úÖ No secrets detected!\nüì¶ Packing ./my-project with repomix...\n‚úÖ Packaging complete!\n   Package is safe to distribute.\n```\n\n**Output if secrets found**:\n```\nüîç Scanning ./my-project for hardcoded secrets...\n‚ö†Ô∏è  Security Scan Found 3 Potential Secrets:\n\nüî¥ supabase_url: 1 instance(s)\n   - src/client.ts:5\n     Match: https://ghyttjckzmzdxumxcixe.supabase.co\n\n‚ùå Cannot pack: Secrets detected!\n```\n\n### Options\n\n**Custom output file**:\n```bash\npython3 scripts/safe_pack.py \\\n  ./my-project \\\n  --output package.xml\n```\n\n**With repomix config**:\n```bash\npython3 scripts/safe_pack.py \\\n  ./my-project \\\n  --config repomix.config.json\n```\n\n**Exclude patterns from scanning**:\n```bash\npython3 scripts/safe_pack.py \\\n  ./my-project \\\n  --exclude '.*test.*' '.*\\.example'\n```\n\n**Force pack (dangerous, skip scan)**:\n```bash\npython3 scripts/safe_pack.py \\\n  ./my-project \\\n  --force  # ‚ö†Ô∏è NOT RECOMMENDED\n```\n\n## Standalone Secret Scanning\n\nUse `scan_secrets.py` from this skill's `scripts/` directory for scanning only (without packing).\n\n```bash\npython3 scripts/scan_secrets.py <directory>\n```\n\n**Use cases**:\n- Verify cleanup after removing credentials\n- Pre-commit security checks\n- Audit existing codebases\n\n**Example**:\n```bash\npython3 scripts/scan_secrets.py ./my-project\n```\n\n**JSON output for programmatic use**:\n```bash\npython3 scripts/scan_secrets.py \\\n  ./my-project \\\n  --json\n```\n\n**Exclude patterns**:\n```bash\npython3 scripts/scan_secrets.py \\\n  ./my-project \\\n  --exclude '.*test.*' '.*example.*' '.*SECURITY_AUDIT\\.md'\n```\n\n## Detected Secret Types\n\nThe scanner detects common credential patterns including:\n\n**Cloud Providers**:\n- AWS Access Keys (`AKIA...`)\n- Cloudflare R2 Account IDs and Access Keys\n- Supabase Project URLs and Anon Keys\n\n**API Keys**:\n- Stripe Keys (`sk_live_...`, `pk_live_...`)\n- OpenAI API Keys (`sk-...`)\n- Google Gemini API Keys (`AIza...`)\n- Generic API Keys\n\n**Authentication**:\n- JWT Tokens (`eyJ...`)\n- OAuth Client Secrets\n- Private Keys (`-----BEGIN PRIVATE KEY-----`)\n- Turnstile Keys (`0x...`)\n\nSee `references/common_secrets.md` for complete list and patterns.\n\n## Handling Detected Secrets\n\nWhen secrets are found:\n\n### Step 1: Review Findings\n\nExamine each finding to verify it's a real credential (not a placeholder or example).\n\n### Step 2: Replace with Environment Variables\n\n**Before**:\n```javascript\nconst SUPABASE_URL = \"https://ghyttjckzmzdxumxcixe.supabase.co\";\nconst API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\";\n```\n\n**After**:\n```javascript\nconst SUPABASE_URL = import.meta.env.VITE_SUPABASE_URL || \"https://your-project-ref.supabase.co\";\nconst API_KEY = import.meta.env.VITE_API_KEY || \"your-api-key-here\";\n\n// Validation\nif (!import.meta.env.VITE_SUPABASE_URL) {\n  console.error(\"‚ö†Ô∏è Missing VITE_SUPABASE_URL environment variable\");\n}\n```\n\n### Step 3: Create .env.example\n\n```bash\n# Example environment variables\nVITE_SUPABASE_URL=https://your-project-ref.supabase.co\nVITE_API_KEY=your-api-key-here\n\n# Instructions:\n# 1. Copy this file to .env\n# 2. Replace placeholders with real values\n# 3. Never commit .env to version control\n```\n\n### Step 4: Verify Cleanup\n\nRun scanner again to confirm secrets removed:\n```bash\npython3 scripts/scan_secrets.py ./my-project\n```\n\n### Step 5: Safe Pack\n\nOnce clean, package safely:\n```bash\npython3 scripts/safe_pack.py ./my-project\n```\n\n## Post-Exposure Actions\n\nIf credentials were already exposed (e.g., committed to git, shared publicly):\n\n1. **Rotate credentials immediately** - Generate new keys/tokens\n2. **Revoke old credentials** - Disable compromised credentials\n3. **Audit usage** - Check logs for unauthorized access\n4. **Monitor** - Set up alerts for unusual activity\n5. **Update deployment** - Deploy code with new credentials\n6. **Document incident** - Record what was exposed and actions taken\n\n## Common False Positives\n\nThe scanner skips common false positives:\n\n**Placeholders**:\n- `your-api-key`, `example-key`, `placeholder-value`\n- `<YOUR_API_KEY>`, `${API_KEY}`, `TODO: add key`\n\n**Test/Example files**:\n- Files matching `.*test.*`, `.*example.*`, `.*sample.*`\n\n**Comments**:\n- Lines starting with `//`, `#`, `/*`, `*`\n\n**Environment variable references** (correct usage):\n- `process.env.API_KEY`\n- `import.meta.env.VITE_API_KEY`\n- `Deno.env.get('API_KEY')`\n\nUse `--exclude` to skip additional patterns if needed.\n\n## Integration with Repomix\n\nThis skill works with standard repomix:\n\n**Default usage** (no config):\n```bash\npython3 scripts/safe_pack.py ./project\n```\n\n**With repomix config**:\n```bash\npython3 scripts/safe_pack.py \\\n  ./project \\\n  --config repomix.config.json\n```\n\n**Custom output location**:\n```bash\npython3 scripts/safe_pack.py \\\n  ./project \\\n  --output ~/Downloads/package-clean.xml\n```\n\nThe skill runs repomix internally after security validation, passing through config and output options.\n\n## Example Workflows\n\n### Workflow 1: Package a Clean Project\n\n```bash\n# Scan and pack in one command\npython3 scripts/safe_pack.py \\\n  ~/workspace/my-project \\\n  --output ~/Downloads/my-project-package.xml\n```\n\n### Workflow 2: Clean and Package a Project with Secrets\n\n```bash\n# Step 1: Scan to discover secrets\npython3 scripts/scan_secrets.py ~/workspace/my-project\n\n# Step 2: Review findings and replace credentials with env vars\n# (Edit files manually or with automation)\n\n# Step 3: Verify cleanup\npython3 scripts/scan_secrets.py ~/workspace/my-project\n\n# Step 4: Package safely\npython3 scripts/safe_pack.py \\\n  ~/workspace/my-project \\\n  --output ~/Downloads/my-project-clean.xml\n```\n\n### Workflow 3: Audit Before Commit\n\n```bash\n# Pre-commit hook: scan for secrets\npython3 scripts/scan_secrets.py . --json\n\n# Exit code 1 if secrets found (blocks commit)\n# Exit code 0 if clean (allows commit)\n```\n\n## Resources\n\n**References**:\n- `references/common_secrets.md` - Complete credential pattern catalog\n\n**Scripts**:\n- `scripts/scan_secrets.py` - Standalone security scanner\n- `scripts/safe_pack.py` - Complete scan ‚Üí pack workflow\n\n**Related Skills**:\n- `repomix-unmixer` - Extracts files from repomix packages\n- `skill-creator` - Creates new Claude Code skills\n\n## Security Note\n\nThis skill detects common patterns but may not catch all credential types. Always:\n- Review findings manually\n- Rotate exposed credentials\n- Use .env.example templates\n- Validate environment variables\n- Monitor for unauthorized access\n\n**Not a replacement for**: Secret scanning in CI/CD, git history scanning, or comprehensive security audits.\n",
        "repomix-unmixer/README.md": "# Repomix Unmixer Skill\n\nA Claude Code skill for extracting files from repomix-packed repositories and restoring their original directory structure.\n\n## Overview\n\nRepomix packs entire repositories into single AI-friendly files (XML, Markdown, or JSON). This skill reverses that process, extracting all files and restoring the original directory structure.\n\n## Quick Start\n\n### Installation\n\n1. Download `repomix-unmixer.zip`\n2. Extract to `~/.claude/skills/repomix-unmixer/`\n3. Restart Claude Code\n\n### Basic Usage\n\nExtract a repomix file:\n\n```bash\npython3 ~/.claude/skills/repomix-unmixer/scripts/unmix_repomix.py \\\n  \"<path_to_repomix_file>\" \\\n  \"<output_directory>\"\n```\n\nExample:\n\n```bash\npython3 ~/.claude/skills/repomix-unmixer/scripts/unmix_repomix.py \\\n  \"/path/to/skills.xml\" \\\n  \"/tmp/extracted-skills\"\n```\n\n## Features\n\n- **Multi-format support**: XML (default), Markdown, and JSON repomix formats\n- **Auto-detection**: Automatically detects repomix format\n- **Structure preservation**: Restores original directory structure\n- **UTF-8 encoding**: Handles international characters correctly\n- **Progress reporting**: Shows extraction progress and statistics\n- **Validation workflows**: Includes comprehensive validation guides\n\n## Supported Formats\n\n### XML Format (default)\n```xml\n<file path=\"relative/path/to/file.ext\">\ncontent here\n</file>\n```\n\n### Markdown Format\n````markdown\n### File: relative/path/to/file.ext\n\n```language\ncontent here\n```\n````\n\n### JSON Format\n```json\n{\n  \"files\": [\n    {\"path\": \"file.ext\", \"content\": \"content here\"}\n  ]\n}\n```\n\n## Bundled Resources\n\n### scripts/unmix_repomix.py\nMain unmixing script with:\n- Format auto-detection\n- Multi-format parsing (XML, Markdown, JSON)\n- Directory structure creation\n- Progress reporting\n\n### references/repomix-format.md\nComprehensive format documentation:\n- XML, Markdown, and JSON format specifications\n- Extraction patterns and regex\n- Edge cases and examples\n- Format detection logic\n\n### references/validation-workflow.md\nDetailed validation procedures:\n- File count verification\n- Directory structure validation\n- Content integrity checks\n- Skill-specific validation for Claude Code skills\n- Quality assurance checklists\n\n## Common Use Cases\n\n### Unmix Claude Skills\n```bash\npython3 ~/.claude/skills/repomix-unmixer/scripts/unmix_repomix.py \\\n  \"skills.xml\" \"/tmp/review-skills\"\n\n# Review and validate\ntree /tmp/review-skills\n\n# Install if valid\ncp -r /tmp/review-skills/* ~/.claude/skills/\n```\n\n### Extract Repository for Review\n```bash\npython3 ~/.claude/skills/repomix-unmixer/scripts/unmix_repomix.py \\\n  \"repo-output.xml\" \"/tmp/review-repo\"\n\n# Review structure\ntree /tmp/review-repo\n```\n\n### Restore from Backup\n```bash\npython3 ~/.claude/skills/repomix-unmixer/scripts/unmix_repomix.py \\\n  \"backup.xml\" \"~/workspace/restored-project\"\n```\n\n## Validation\n\nAfter extraction, validate the results:\n\n1. **Check file count**: Verify extracted count matches expected\n2. **Review structure**: Use `tree` to inspect directory layout\n3. **Spot check content**: Read a few files to verify integrity\n4. **Run validation**: For skills, use skill-creator validation\n\nFor detailed validation procedures, see `references/validation-workflow.md`.\n\n## Requirements\n\n- Python 3.6 or higher\n- Standard library only (no external dependencies)\n\n## Skill Activation\n\nThis skill activates when:\n- Unmixing a repomix output file\n- Extracting files from a packed repository\n- Restoring original directory structure\n- Reviewing repomix-packed content\n- Converting repomix output back to usable files\n\n## Best Practices\n\n1. **Extract to temp directories** - Always extract to `/tmp` for initial review\n2. **Verify file count** - Check extracted count matches expectations\n3. **Review structure** - Inspect directory layout before use\n4. **Check content** - Spot-check files for integrity\n5. **Use validation tools** - For skills, use skill-creator validation\n6. **Preserve originals** - Keep the repomix file as backup\n\n## Troubleshooting\n\n### No Files Extracted\n- Verify input file is a valid repomix file\n- Check format (XML/Markdown/JSON)\n- Refer to `references/repomix-format.md`\n\n### Permission Errors\n- Ensure output directory is writable\n- Use `mkdir -p` to create directory first\n- Check file permissions\n\n### Encoding Issues\n- Script uses UTF-8 by default\n- Verify repomix file encoding\n- Check for special characters\n\n## Version\n\n- **Version**: 1.0.0\n- **Created**: 2025-10-22\n- **Last Updated**: 2025-10-22\n\n## License\n\nThis skill follows the same license as Claude Code.\n\n## Support\n\nFor issues or questions:\n1. Check `references/repomix-format.md` for format details\n2. Review `references/validation-workflow.md` for validation help\n3. Inspect the script source code at `scripts/unmix_repomix.py`\n4. Report issues to the skill creator\n\n## Credits\n\nCreated using the skill-creator skill for Claude Code.\n",
        "repomix-unmixer/SKILL.md": "---\nname: repomix-unmixer\ndescription: Extracts files from repomix-packed repositories, restoring original directory structures from XML/Markdown/JSON formats. Activates when users need to unmix repomix files, extract packed repositories, restore file structures from repomix output, or reverse the repomix packing process.\n---\n\n# Repomix Unmixer\n\n## Overview\n\nThis skill extracts files from repomix-packed repositories and restores their original directory structure. Repomix packs entire repositories into single AI-friendly files (XML, Markdown, or JSON), and this skill reverses that process to restore individual files.\n\n## When to Use This Skill\n\nThis skill activates when:\n- Unmixing a repomix output file (*.xml, *.md, *.json)\n- Extracting files from a packed repository\n- Restoring original directory structure from repomix format\n- Reviewing or validating repomix-packed content\n- Converting repomix output back to usable files\n\n## Core Workflow\n\n### Standard Unmixing Process\n\nExtract all files from a repomix file and restore the original directory structure using the bundled `unmix_repomix.py` script:\n\n```bash\npython3 scripts/unmix_repomix.py \\\n  \"<path_to_repomix_file>\" \\\n  \"<output_directory>\"\n```\n\n**Parameters:**\n- `<path_to_repomix_file>`: Path to the repomix output file (XML, Markdown, or JSON)\n- `<output_directory>`: Directory where files will be extracted (will be created if doesn't exist)\n\n**Example:**\n```bash\npython3 scripts/unmix_repomix.py \\\n  \"/path/to/repomix-output.xml\" \\\n  \"/tmp/extracted-files\"\n```\n\n### What the Script Does\n\n1. **Parses** the repomix file format (XML, Markdown, or JSON)\n2. **Extracts** each file path and content\n3. **Creates** the original directory structure\n4. **Writes** each file to its original location\n5. **Reports** extraction progress and statistics\n\n### Output\n\nThe script will:\n- Create all necessary parent directories\n- Extract all files maintaining their paths\n- Print extraction progress for each file\n- Display total count of extracted files\n\n**Example output:**\n```\nUnmixing /path/to/skill.xml...\nOutput directory: /tmp/extracted-files\n\n‚úì Extracted: github-ops/SKILL.md\n‚úì Extracted: github-ops/references/api_reference.md\n‚úì Extracted: markdown-tools/SKILL.md\n...\n\n‚úÖ Successfully extracted 20 files!\n\nExtracted files are in: /tmp/extracted-files\n```\n\n## Supported Formats\n\n### XML Format (default)\n\nRepomix XML format structure:\n```xml\n<file path=\"relative/path/to/file.ext\">\nfile content here\n</file>\n```\n\nThe script uses regex to match `<file path=\"...\">content</file>` blocks.\n\n### Markdown Format\n\nFor markdown-style repomix output with file markers:\n```markdown\n## File: relative/path/to/file.ext\n```\nfile content\n```\n```\n\nRefer to `references/repomix-format.md` for detailed format specifications.\n\n### JSON Format\n\nFor JSON-style repomix output:\n```json\n{\n  \"files\": [\n    {\n      \"path\": \"relative/path/to/file.ext\",\n      \"content\": \"file content here\"\n    }\n  ]\n}\n```\n\n## Common Use Cases\n\n### Use Case 1: Unmix Claude Skills\n\nExtract skills that were shared as a repomix file:\n\n```bash\npython3 scripts/unmix_repomix.py \\\n  \"/path/to/skills.xml\" \\\n  \"/tmp/unmixed-skills\"\n```\n\nThen review, validate, or install the extracted skills.\n\n### Use Case 2: Extract Repository for Review\n\nExtract a packed repository to review its structure and contents:\n\n```bash\npython3 scripts/unmix_repomix.py \\\n  \"/path/to/repo-output.xml\" \\\n  \"/tmp/review-repo\"\n\n# Review the structure\ntree /tmp/review-repo\n```\n\n### Use Case 3: Restore Working Files\n\nRestore files from a repomix backup to a working directory:\n\n```bash\npython3 scripts/unmix_repomix.py \\\n  \"/path/to/backup.xml\" \\\n  \"~/workspace/restored-project\"\n```\n\n## Validation Workflow\n\nAfter unmixing, validate the extracted files are correct:\n\n1. **Check file count**: Verify the number of extracted files matches expectations\n2. **Review structure**: Use `tree` or `ls -R` to inspect directory layout\n3. **Spot check content**: Read a few key files to verify content integrity\n4. **Run validation**: For skills, use the skill-creator validation tools\n\nRefer to `references/validation-workflow.md` for detailed validation procedures, especially for unmixing Claude skills.\n\n## Important Principles\n\n### Always Specify Output Directory\n\nAlways provide an output directory to avoid cluttering the current working directory:\n\n```bash\n# Good: Explicit output directory\npython3 scripts/unmix_repomix.py \\\n  \"input.xml\" \"/tmp/output\"\n\n# Avoid: Default output (may clutter current directory)\npython3 scripts/unmix_repomix.py \"input.xml\"\n```\n\n### Use Temporary Directories for Review\n\nExtract to temporary directories first for review:\n\n```bash\n# Extract to /tmp for review\npython3 scripts/unmix_repomix.py \\\n  \"skills.xml\" \"/tmp/review-skills\"\n\n# Review the contents\ntree /tmp/review-skills\n\n# If satisfied, copy to final destination\ncp -r /tmp/review-skills ~/.claude/skills/\n```\n\n### Verify Before Overwriting\n\nNever extract directly to important directories without review:\n\n```bash\n# Bad: Might overwrite existing files\npython3 scripts/unmix_repomix.py \\\n  \"repo.xml\" \"~/workspace/my-project\"\n\n# Good: Extract to temp, review, then move\npython3 scripts/unmix_repomix.py \\\n  \"repo.xml\" \"/tmp/extracted\"\n# Review, then:\nmv /tmp/extracted ~/workspace/my-project\n```\n\n## Troubleshooting\n\n### No Files Extracted\n\n**Issue**: Script completes but no files are extracted.\n\n**Possible causes:**\n- Wrong file format (not a repomix file)\n- Unsupported repomix format version\n- File path pattern doesn't match\n\n**Solution:**\n1. Verify the input file is a repomix output file\n2. Check the format (XML/Markdown/JSON)\n3. Examine the file structure manually\n4. Refer to `references/repomix-format.md` for format details\n\n### Permission Errors\n\n**Issue**: Cannot write to output directory.\n\n**Solution:**\n```bash\n# Ensure output directory is writable\nmkdir -p /tmp/output\nchmod 755 /tmp/output\n\n# Or use a directory you own\npython3 scripts/unmix_repomix.py \\\n  \"input.xml\" \"$HOME/extracted\"\n```\n\n### Encoding Issues\n\n**Issue**: Special characters appear garbled in extracted files.\n\n**Solution:**\nThe script uses UTF-8 encoding by default. If issues persist:\n- Check the original repomix file encoding\n- Verify the file was created correctly\n- Report the issue with specific character examples\n\n### Path Already Exists\n\n**Issue**: Files exist at extraction path.\n\n**Solution:**\n```bash\n# Option 1: Use a fresh output directory\npython3 scripts/unmix_repomix.py \\\n  \"input.xml\" \"/tmp/output-$(date +%s)\"\n\n# Option 2: Clear the directory first\nrm -rf /tmp/output && mkdir /tmp/output\npython3 scripts/unmix_repomix.py \\\n  \"input.xml\" \"/tmp/output\"\n```\n\n## Best Practices\n\n1. **Extract to temp directories** - Always extract to `/tmp` or similar for initial review\n2. **Verify file count** - Check that extracted file count matches expectations\n3. **Review structure** - Use `tree` to inspect directory layout before use\n4. **Check content** - Spot-check a few files to ensure content is intact\n5. **Use validation tools** - For skills, use skill-creator validation after unmixing\n6. **Preserve originals** - Keep the original repomix file as backup\n\n## Resources\n\n### scripts/unmix_repomix.py\n\nMain unmixing script that:\n- Parses repomix XML/Markdown/JSON formats\n- Extracts file paths and content using regex\n- Creates directory structures automatically\n- Writes files to their original locations\n- Reports extraction progress and statistics\n\nThe script is self-contained and requires only Python 3 standard library.\n\n### references/repomix-format.md\n\nComprehensive documentation of repomix file formats including:\n- XML format structure and examples\n- Markdown format patterns\n- JSON format schema\n- File path encoding rules\n- Content extraction patterns\n- Format version differences\n\nLoad this reference when dealing with format-specific issues or supporting new repomix versions.\n\n### references/validation-workflow.md\n\nDetailed validation procedures for extracted content including:\n- File count verification steps\n- Directory structure validation\n- Content integrity checks\n- Skill-specific validation using skill-creator tools\n- Quality assurance checklists\n\nLoad this reference when users need to validate unmixed skills or verify extraction quality.\n",
        "skill-creator/SKILL.md": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks‚Äîthey transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter metadata (required)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ name: (required)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ description: (required)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions (required)\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/          - Executable code (Python/Bash/etc.)\n    ‚îú‚îÄ‚îÄ references/       - Documentation intended to be loaded into context as needed\n    ‚îî‚îÄ‚îÄ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n##### YAML Frontmatter Reference\n\nAll frontmatter fields except `description` are optional. Configure skill behavior using these fields between `---` markers:\n\n```yaml\n---\nname: my-skill\ndescription: What this skill does and when to use it. Use when...\ncontext: fork\nagent: Explore\ndisable-model-invocation: true\nallowed-tools: Read, Grep, Bash(git *)\n---\n```\n\n| Field | Required | Description |\n|-------|----------|-------------|\n| `name` | No | Display name for the skill. If omitted, uses the directory name. Lowercase letters, numbers, and hyphens only (max 64 characters). |\n| `description` | Recommended | What the skill does and when to use it. Claude uses this to decide when to apply the skill. If omitted, uses the first paragraph of markdown content. |\n| `context` | No | **Set to `fork` to run in a forked subagent context.** This is critical for skills that should be available to subagents spawned via the Task tool. Without `context: fork`, the skill runs inline in the main conversation. |\n| `agent` | No | Which subagent type to use when `context: fork` is set. Options: `Explore`, `Plan`, `general-purpose`, or custom agents from `.claude/agents/`. Default: `general-purpose`. |\n| `disable-model-invocation` | No | Set to `true` to prevent Claude from automatically loading this skill. Use for workflows you want to trigger manually with `/name`. Default: `false`. |\n| `user-invocable` | No | Set to `false` to hide from the `/` menu. Use for background knowledge users shouldn't invoke directly. Default: `true`. |\n| `allowed-tools` | No | Tools Claude can use without asking permission when this skill is active. Supports wildcards: `Read, Grep, Bash(git *)`, `Bash(npm *)`, `Bash(docker compose *)`. |\n| `model` | No | Model to use when this skill is active. |\n| `argument-hint` | No | Hint shown during autocomplete to indicate expected arguments. Example: `[issue-number]` or `[filename] [format]`. |\n| `hooks` | No | Hooks scoped to this skill's lifecycle. Example: `hooks: { pre-invoke: [{ command: \"echo Starting\" }] }`. See Claude Code Hooks documentation. |\n\n**Special placeholder:** `$ARGUMENTS` in skill content is replaced with text the user provides after the skill name. For example, `/deep-research quantum computing` replaces `$ARGUMENTS` with `quantum computing`.\n\n##### When to Use `context: fork`\n\nUse `context: fork` when the skill:\n- Performs multi-step autonomous tasks (research, analysis, code generation)\n- Should be available to subagents spawned via the Task tool\n- Needs isolated context that won't pollute the main conversation\n- Contains explicit task instructions (not just guidelines or reference content)\n\n**Example: Task-based skill with subagent execution:**\n```yaml\n---\nname: deep-research\ndescription: Research a topic thoroughly using multiple sources\ncontext: fork\nagent: Explore\n---\n\nResearch $ARGUMENTS thoroughly:\n1. Find relevant files using Glob and Grep\n2. Read and analyze the code\n3. Summarize findings with specific file references\n```\nWhen invoked as `/deep-research authentication flow`, `$ARGUMENTS` becomes `authentication flow`.\n\n**Example: Reference skill that runs inline:**\n```yaml\n---\nname: api-conventions\ndescription: API design patterns for this codebase\n---\n\nWhen writing API endpoints:\n- Use RESTful naming conventions\n- Return consistent error formats\n```\n\n##### Invocation Control\n\n| Frontmatter | You can invoke | Claude can invoke | Subagents can use |\n|-------------|----------------|-------------------|-------------------|\n| (default) | Yes | Yes | No (runs inline) |\n| `context: fork` | Yes | Yes | Yes |\n| `disable-model-invocation: true` | Yes | No | No |\n| `context: fork` + `disable-model-invocation: true` | Yes | No | Yes (when explicitly delegated) |\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill‚Äîthis keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n##### Privacy and Path References\n\n**CRITICAL**: Skills intended for public distribution must not contain user-specific or company-specific information:\n\n- **Forbidden**: Absolute paths to user directories (`/home/username/`, `/Users/username/`, `/mnt/c/Users/username/`)\n- **Forbidden**: Personal usernames, company names, department names, product names\n- **Forbidden**: OneDrive paths, cloud storage paths, or any environment-specific absolute paths\n- **Forbidden**: Hardcoded skill installation paths like `~/.claude/skills/` or `/Users/username/Workspace/claude-code-skills/`\n- **Allowed**: Relative paths within the skill bundle (`scripts/example.py`, `references/guide.md`)\n- **Allowed**: Standard placeholders (`~/workspace/project`, `username`, `your-company`)\n- **Best practice**: Reference bundled scripts using simple relative paths like `scripts/script_name.py` - Claude will resolve the actual location\n\n##### Versioning\n\n**CRITICAL**: Skills should NOT contain version history or version numbers in SKILL.md:\n\n- **Forbidden**: Version sections (`## Version`, `## Changelog`, `## Release History`) in SKILL.md\n- **Forbidden**: Version numbers in SKILL.md body content\n- **Correct location**: Skill versions are tracked in marketplace.json under `plugins[].version`\n- **Rationale**: Marketplace infrastructure manages versioning; SKILL.md should be timeless content focused on functionality\n- **Example**: Instead of documenting v1.0.0 ‚Üí v1.1.0 changes in SKILL.md, update the version in marketplace.json only\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n### Skill Creation Best Practice\n\nAnthropic has wrote skill authoring best practices, you SHOULD retrieve it before you create or update any skills, the link is https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices.md\n\n## ‚ö†Ô∏è CRITICAL: Edit Skills at Source Location\n\n**NEVER edit skills in `~/.claude/plugins/cache/`** ‚Äî that's a read-only cache directory. All changes there are:\n- Lost when cache refreshes\n- Not synced to source control\n- Wasted effort requiring manual re-merge\n\n**ALWAYS verify you're editing the source repository:**\n```bash\n# WRONG - cache location (read-only copy)\n~/.claude/plugins/cache/daymade-skills/my-skill/1.0.0/my-skill/SKILL.md\n\n# RIGHT - source repository\n/path/to/your/claude-code-skills/my-skill/SKILL.md\n```\n\n**Before any edit**, confirm the file path does NOT contain `/cache/` or `/plugins/cache/`.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Determining the appropriate level of freedom for Claude\n3. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\n**Match specificity to task risk:**\n- **High freedom (text instructions)**: Multiple valid approaches exist; context determines best path (e.g., code reviews, troubleshooting, content analysis)\n- **Medium freedom (pseudocode with parameters)**: Preferred patterns exist with acceptable variation (e.g., API integration patterns, data processing workflows)\n- **Low freedom (exact scripts)**: Operations are fragile, consistency critical, sequence matters (e.g., PDF rotation, database migrations, form validation)\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n**When updating an existing skill**: Scan all existing reference files to check if they need corresponding updates. New features often require updates to architecture, workflow, or other existing documentation to maintain consistency.\n\n#### Reference File Naming\n\nFilenames must be self-explanatory without reading contents.\n\n**Pattern**: `<content-type>_<specificity>.md`\n\n**Examples**:\n- ‚ùå `commands.md`, `cli_usage.md`, `reference.md`\n- ‚úÖ `script_parameters.md`, `api_endpoints.md`, `database_schema.md`\n\n**Test**: Can someone understand the file's contents from the name alone?\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\nTo complete SKILL.md, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used?\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n### Step 5: Sanitization Review (Optional)\n\n**Ask the user before executing this step:** \"This skill appears to be extracted from a business project. Would you like me to perform a sanitization review to remove business-specific content before public distribution?\"\n\nSkip this step if:\n- The skill was created from scratch for public use\n- The user explicitly declines sanitization\n- The skill is intended for internal/private use only\n\n**When to perform sanitization:**\n- Skill was extracted from a business/internal project\n- Skill contains domain-specific examples from real systems\n- Skill will be distributed publicly or to other teams\n\n**Sanitization process:**\n\n1. **Load the checklist**: Read [references/sanitization_checklist.md](references/sanitization_checklist.md) for detailed guidance\n\n2. **Run automated scans** to identify potential sensitive content:\n   ```bash\n   # Product/project names, person names, paths\n   grep -rniE \"portal|underwriting|mercury|glean|/Users/|/home/\" skill-folder/\n\n   # Chinese characters (if skill should be English-only)\n   grep -rn '[‰∏Ä-Èæ•]' skill-folder/\n   ```\n\n3. **Review and replace** each category:\n   - Product/project names ‚Üí generic terms\n   - Person names ‚Üí \"Alice\", \"Bob\", role-based references\n   - Entity names ‚Üí generic entities (ORDER, USER, PRODUCT)\n   - Folder structures ‚Üí generic paths\n   - Internal jargon ‚Üí industry-standard terms\n   - Language-specific content ‚Üí translate or remove\n\n4. **Verify completeness**:\n   - Re-run all grep patterns (should return no matches)\n   - Read through skill to ensure coherence\n   - Confirm skill still functions correctly\n\n**Common replacements:**\n\n| Business-Specific | Generic Replacement |\n|-------------------|---------------------|\n| \"Mercury Prepared\" | \"the project\" |\n| \"Reviewer Portal\" | \"the application\" |\n| \"Oliver will handle...\" | \"Alice will handle...\" |\n| `REVIEW_RESULT` | `ORDER` |\n| `risk_level` | `status` |\n| \"ultrathink\" | \"deep review\" |\n| \"ÂêéÈù¢ÂÜçËØ¥\" | \"defer to later\" |\n\n### Step 6: Security Review\n\nBefore packaging or distributing a skill, run the security scanner to detect hardcoded secrets and personal information:\n\n```bash\n# Required before packaging\npython scripts/security_scan.py <path/to/skill-folder>\n\n# Verbose mode includes additional checks for paths, emails, and code patterns\npython scripts/security_scan.py <path/to/skill-folder> --verbose\n```\n\n**Detection coverage:**\n- Hardcoded secrets (API keys, passwords, tokens) via gitleaks\n- Personal information (usernames, emails, company names) in verbose mode\n- Unsafe code patterns (command injection risks) in verbose mode\n\n**First-time setup:** Install gitleaks if not present:\n\n```bash\n# macOS\nbrew install gitleaks\n\n# Linux/Windows - see script output for installation instructions\n```\n\n**Exit codes:**\n- `0` - Clean (safe to package)\n- `1` - High severity issues\n- `2` - Critical issues (MUST fix before distribution)\n- `3` - gitleaks not installed\n- `4` - Scan error\n\n**Remediation for detected secrets:**\n\n1. Remove hardcoded secrets from all files\n2. Use environment variables: `os.environ.get(\"API_KEY\")`\n3. Rotate credentials if previously committed to git\n4. Re-run scan to verify fixes before packaging\n\n### Step 7: Packaging a Skill\n\nOnce the skill is ready, it should be packaged into a distributable zip file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - **Path reference integrity** - all `scripts/`, `references/`, and `assets/` paths mentioned in SKILL.md must exist\n\n2. **Package** the skill if validation passes, creating a zip file named after the skill (e.g., `my-skill.zip`) that includes all files and maintains the proper directory structure for distribution.\n\n**Common validation failure:** If SKILL.md references `scripts/my_script.py` but the file doesn't exist, validation will fail with \"Missing referenced files: scripts/my_script.py\". Ensure all bundled resources exist before packaging.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 8: Update Marketplace\n\nAfter packaging, update the marketplace registry to include the new or updated skill.\n\n**For new skills**, add an entry to `.claude-plugin/marketplace.json`:\n\n```json\n{\n  \"name\": \"skill-name\",\n  \"description\": \"Copy from SKILL.md frontmatter description\",\n  \"source\": \"./\",\n  \"strict\": false,\n  \"version\": \"1.0.0\",\n  \"category\": \"developer-tools\",\n  \"keywords\": [\"relevant\", \"keywords\"],\n  \"skills\": [\"./skill-name\"]\n}\n```\n\n**For updated skills**, bump the version in `plugins[].version` following semver:\n- Patch (1.0.x): Bug fixes, typo corrections\n- Minor (1.x.0): New features, additional references\n- Major (x.0.0): Breaking changes, restructured workflows\n\n**Also update** `metadata.version` and `metadata.description` if the overall plugin collection changed significantly.\n\n### Step 9: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n\n**Refinement filter:** Only add what solves observed problems. If best practices already cover it, don't duplicate.\n",
        "skill-reviewer/SKILL.md": "---\nname: skill-reviewer\ndescription: Reviews and improves Claude Code skills against official best practices. Supports three modes - self-review (validate your own skills), external review (evaluate others' skills), and auto-PR (fork, improve, submit). Use when checking skill quality, reviewing skill repositories, or contributing improvements to open-source skills.\n---\n\n# Skill Reviewer\n\nReview and improve Claude Code skills against official best practices.\n\n## Setup (Auto-Install Dependencies)\n\nBefore using this skill, ensure `skill-creator` is installed for automated validation.\n\n**Auto-install sequence:**\n\n```bash\n# 1. Check if skill-creator exists\nSKILL_CREATOR=$(find ~/.claude/plugins/cache -name \"skill-creator\" -type d 2>/dev/null | head -1)\n\n# 2. If not found, install it\nif [ -z \"$SKILL_CREATOR\" ]; then\n  claude plugin marketplace add https://github.com/daymade/claude-code-skills\n  claude plugin install skill-creator@daymade-skills\n  SKILL_CREATOR=$(find ~/.claude/plugins/cache -name \"skill-creator\" -type d 2>/dev/null | head -1)\nfi\n\necho \"skill-creator location: $SKILL_CREATOR\"\n```\n\n## Three Modes\n\n### Mode 1: Self-Review\n\nCheck your own skill before publishing.\n\n**Automated validation** (run after setup):\n\n```bash\n# Quick validation\npython3 \"$SKILL_CREATOR\"/*/quick_validate.py <target-skill>\n\n# Security scan\npython3 \"$SKILL_CREATOR\"/*/security_scan.py <target-skill> --verbose\n```\n\n**Manual evaluation**: See `references/evaluation_checklist.md`.\n\n### Mode 2: External Review\n\nEvaluate someone else's skill repository.\n\n```\nReview Workflow:\n- [ ] Clone repository to /tmp/\n- [ ] Read ALL documentation first\n- [ ] Identify author's intent\n- [ ] Run evaluation checklist\n- [ ] Generate improvement report\n```\n\n### Mode 3: Auto-PR\n\nFork, improve, and submit PR to external skill repository.\n\n```\nAuto-PR Workflow:\n- [ ] Fork repository (gh repo fork)\n- [ ] Create feature branch\n- [ ] Apply additive improvements only\n- [ ] Self-review: respect check passed?\n- [ ] Create PR with detailed explanation\n```\n\n## Evaluation Checklist (Quick)\n\n| Category | Check | Status |\n|----------|-------|--------|\n| **Frontmatter** | name present? | |\n| | description present? | |\n| | description in third-person? | |\n| | includes trigger conditions? | |\n| **Instructions** | imperative form? | |\n| | under 500 lines? | |\n| | workflow pattern? | |\n| **Resources** | no hardcoded paths? | |\n| | scripts have error handling? | |\n\nFull checklist: `references/evaluation_checklist.md`\n\n## Core Principle: Additive Only\n\nWhen improving external skills, NEVER:\n- Delete existing files\n- Remove functionality\n- Change primary language\n- Rename components\n\nALWAYS:\n- Add new capabilities\n- Preserve original content\n- Explain every change\n\n```\n‚ùå \"Removed metadata.json (non-standard)\"\n‚úÖ \"Added marketplace.json (metadata.json preserved)\"\n\n‚ùå \"Rewrote README in English\"\n‚úÖ \"Added README.en.md (Chinese preserved as default)\"\n```\n\n## Common Issues & Fixes\n\n### Issue: Description Not Third-Person\n\n```yaml\n# Before\ndescription: Browse YouTube videos and summarize them.\n\n# After\ndescription: Browses YouTube videos and generates summaries. Use when...\n```\n\n### Issue: Missing Trigger Conditions\n\n```yaml\n# Before\ndescription: Processes PDF files.\n\n# After\ndescription: Extracts text from PDFs. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n```\n\n### Issue: No Workflow Pattern\n\nAdd checklist for complex tasks:\n\n```markdown\n## Workflow\n\nCopy this checklist:\n\n\\`\\`\\`\nTask Progress:\n- [ ] Step 1: ...\n- [ ] Step 2: ...\n\\`\\`\\`\n```\n\n### Issue: Missing Marketplace Support\n\n```bash\nmkdir -p .claude-plugin\n# Create marketplace.json from template\n```\n\nSee `references/marketplace_template.json`.\n\n## PR Guidelines\n\nWhen submitting PRs to external repos:\n\n### Tone\n\n```\n‚ùå \"Your skill doesn't follow best practices\"\n‚úÖ \"This PR aligns with best practices for better discoverability\"\n\n‚ùå \"Fixed the incorrect description\"\n‚úÖ \"Improved description with trigger conditions\"\n```\n\n### Required Sections\n\n1. **Summary** - What this PR does\n2. **What's NOT Changed** - Show respect for original\n3. **Rationale** - Why each change helps\n4. **Test Plan** - How to verify\n\nTemplate: `references/pr_template.md`\n\n## Self-Review Checklist\n\nBefore submitting any PR:\n\n```\nRespect Check:\n- [ ] No files deleted?\n- [ ] No functionality removed?\n- [ ] Original language preserved?\n- [ ] Author's design decisions respected?\n- [ ] All changes are additive?\n- [ ] PR explains the \"why\"?\n```\n\n## References\n\n- `references/evaluation_checklist.md` - Full evaluation checklist\n- `references/pr_template.md` - PR description template\n- `references/marketplace_template.json` - marketplace.json template\n- Best practices: https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices\n",
        "skills-search/SKILL.md": "---\nname: skills-search\ndescription: This skill should be used when users want to search, discover, install, or manage Claude Code skills from the CCPM registry. Triggers include requests like \"find skills for PDF\", \"search for code review skills\", \"install cloudflare-troubleshooting\", \"list my installed skills\", \"what does skill-creator do\", or any mention of finding/installing/managing Claude Code skills or plugins.\n---\n\n# Skills Search\n\n## Overview\n\nSearch, discover, and manage Claude Code skills from the CCPM (Claude Code Plugin Manager) registry. This skill wraps the `ccpm` CLI to provide seamless skill discovery and installation.\n\n## Quick Start\n\n```bash\n# Search for skills\nccpm search <query>\n\n# Install a skill\nccpm install <skill-name>\n\n# List installed skills\nccpm list\n\n# Get skill details\nccpm info <skill-name>\n```\n\n## Commands Reference\n\n### Search Skills\n\nSearch the CCPM registry for skills matching a query.\n\n```bash\nccpm search <query> [options]\n\nOptions:\n  --limit <n>    Maximum results (default: 10)\n  --json         Output as JSON\n```\n\n**Examples:**\n```bash\nccpm search pdf              # Find PDF-related skills\nccpm search \"code review\"    # Find code review skills\nccpm search cloudflare       # Find Cloudflare tools\nccpm search --limit 20 react # Find React skills, show 20 results\n```\n\n### Install Skills\n\nInstall a skill to make it available in Claude Code.\n\n```bash\nccpm install <skill-name> [options]\n\nOptions:\n  --project      Install to current project only (default: user-level)\n  --force        Force reinstall even if already installed\n```\n\n**Examples:**\n```bash\nccpm install pdf-processor                    # Install pdf-processor skill\nccpm install @daymade/skill-creator           # Install namespaced skill\nccpm install cloudflare-troubleshooting       # Install troubleshooting skill\nccpm install react-component-builder --project # Install for current project only\n```\n\n**Important:** After installing a skill, Claude Code must be restarted for the skill to become available.\n\n### List Installed Skills\n\nShow all currently installed skills.\n\n```bash\nccpm list [options]\n\nOptions:\n  --json         Output as JSON\n```\n\n**Output includes:**\n- Skill name and version\n- Installation scope (user/project)\n- Installation path\n\n### Get Skill Information\n\nShow detailed information about a skill from the registry.\n\n```bash\nccpm info <skill-name>\n```\n\n**Output includes:**\n- Name, description, version\n- Author and repository\n- Download count and tags\n- Dependencies (if any)\n\n**Example:**\n```bash\nccpm info skill-creator\n```\n\n### Uninstall Skills\n\nRemove an installed skill.\n\n```bash\nccpm uninstall <skill-name> [options]\n\nOptions:\n  --global       Uninstall from user-level installation\n  --project      Uninstall from project-level installation\n```\n\n**Example:**\n```bash\nccpm uninstall pdf-processor\n```\n\n## Workflow: Finding and Installing Skills\n\nWhen a user needs functionality that might be available as a skill:\n\n1. **Search** for relevant skills:\n   ```bash\n   ccpm search <relevant-keywords>\n   ```\n\n2. **Review** the search results - check download counts and descriptions\n\n3. **Get details** on promising skills:\n   ```bash\n   ccpm info <skill-name>\n   ```\n\n4. **Install** the chosen skill:\n   ```bash\n   ccpm install <skill-name>\n   ```\n\n5. **Inform user** to restart Claude Code to use the new skill\n\n## Popular Skills\n\nCommon skills users may want:\n\n| Skill | Purpose |\n|-------|---------|\n| `skill-creator` | Create new Claude Code skills |\n| `pdf-processor` | PDF manipulation and analysis |\n| `docx` | Word document processing |\n| `xlsx` | Excel spreadsheet operations |\n| `pptx` | PowerPoint presentation creation |\n| `cloudflare-troubleshooting` | Debug Cloudflare issues |\n| `prompt-optimizer` | Improve prompt quality |\n\n## Troubleshooting\n\n### \"ccpm: command not found\"\n\nInstall CCPM globally:\n```bash\nnpm install -g @daymade/ccpm\n```\n\nFor more information, visit [CCPM official website](https://ccpm.dev).\n\n### Skill not available after install\n\nRestart Claude Code - skills are loaded at startup.\n\n### Permission errors\n\nTry installing with user scope (default) or check write permissions to `~/.claude/skills/`.\n",
        "statusline-generator/SKILL.md": "---\nname: statusline-generator\ndescription: Configures and customizes Claude Code statuslines with multi-line layouts, cost tracking via ccusage, git status indicators, and customizable colors. Activates for statusline setup, installation, configuration, customization, color changes, cost display, git status integration, or troubleshooting statusline issues.\n---\n\n# Statusline Generator\n\n## Overview\n\nThis skill provides tools and guidance for creating and customizing Claude Code statuslines. It generates multi-line statuslines optimized for portrait screens, integrates with `ccusage` for session/daily cost tracking, displays git branch status, and supports color customization.\n\n## When to Use This Skill\n\nThis skill activates for:\n- Statusline configuration requests for Claude Code\n- Cost information display (session/daily costs)\n- Multi-line layouts for portrait or narrow screens\n- Statusline color or format customization\n- Statusline display or cost tracking issues\n- Git status or path shortening features\n\n## Quick Start\n\n### Basic Installation\n\nInstall the default multi-line statusline:\n\n1. Run the installation script:\n   ```bash\n   bash scripts/install_statusline.sh\n   ```\n\n2. Restart Claude Code to see the statusline\n\nThe default statusline displays:\n- **Line 1**: `username (model) [session_cost/daily_cost]`\n- **Line 2**: `current_path`\n- **Line 3**: `[git:branch*+]`\n\n### Manual Installation\n\nAlternatively, manually install by:\n\n1. Copy `scripts/generate_statusline.sh` to `~/.claude/statusline.sh`\n2. Make it executable: `chmod +x ~/.claude/statusline.sh`\n3. Update `~/.claude/settings.json`:\n   ```json\n   {\n     \"statusLine\": {\n       \"type\": \"command\",\n       \"command\": \"bash /home/username/.claude/statusline.sh\",\n       \"padding\": 0\n     }\n   }\n   ```\n\n## Statusline Features\n\n### Multi-Line Layout\n\nThe statusline uses a 3-line layout optimized for portrait screens:\n\n```\nusername (Sonnet 4.5 [1M]) [$0.26/$25.93]\n~/workspace/java/ready-together-svc\n[git:feature/branch-name*+]\n```\n\n**Benefits:**\n- Shorter lines fit narrow screens\n- Clear visual separation of information types\n- No horizontal scrolling needed\n\n### Cost Tracking Integration\n\nCost tracking via `ccusage`:\n- **Session Cost**: Current conversation cost\n- **Daily Cost**: Total cost for today\n- **Format**: `[$session/$daily]` in magenta\n- **Caching**: 2-minute cache to avoid performance impact\n- **Background Fetch**: First run loads costs asynchronously\n\n**Requirements:** `ccusage` must be installed and in PATH. See `references/ccusage_integration.md` for installation and troubleshooting.\n\n### Model Name Shortening\n\nModel names are automatically shortened:\n- `\"Sonnet 4.5 (with 1M token context)\"` ‚Üí `\"Sonnet 4.5 [1M]\"`\n- `\"Opus 4.1 (with 500K token context)\"` ‚Üí `\"Opus 4.1 [500K]\"`\n\nThis saves horizontal space while preserving key information.\n\n### Git Status Indicators\n\nGit branch status shows:\n- **Yellow**: Clean branch (no changes)\n- **Red**: Dirty branch (uncommitted changes)\n- **Indicators**:\n  - `*` - Modified or staged files\n  - `+` - Untracked files\n  - Example: `[git:main*+]` - Modified files and untracked files\n\n### Path Shortening\n\nPaths are shortened:\n- Home directory replaced with `~`\n- Example: `/home/username/workspace/project` ‚Üí `~/workspace/project`\n\n### Color Scheme\n\nDefault colors optimized for visibility:\n- **Username**: Bright Green (`\\033[01;32m`)\n- **Model**: Bright Cyan (`\\033[01;36m`)\n- **Costs**: Bright Magenta (`\\033[01;35m`)\n- **Path**: Bright White (`\\033[01;37m`)\n- **Git (clean)**: Bright Yellow (`\\033[01;33m`)\n- **Git (dirty)**: Bright Red (`\\033[01;31m`)\n\n## Customization\n\n### Changing Colors\n\nCustomize colors by editing `~/.claude/statusline.sh` and modifying the ANSI color codes in the final `printf` statement. See `references/color_codes.md` for available colors.\n\n**Example: Change username to blue**\n```bash\n# Find this line:\nprintf '\\033[01;32m%s\\033[00m \\033[01;36m(%s)\\033[00m%s\\n\\033[01;37m%s\\033[00m\\n%s' \\\n\n# Change \\033[01;32m (green) to \\033[01;34m (blue):\nprintf '\\033[01;34m%s\\033[00m \\033[01;36m(%s)\\033[00m%s\\n\\033[01;37m%s\\033[00m\\n%s' \\\n```\n\n### Single-Line Layout\n\nConvert to single-line layout by modifying the final `printf`:\n\n```bash\n# Replace:\nprintf '\\033[01;32m%s\\033[00m \\033[01;36m(%s)\\033[00m%s\\n\\033[01;37m%s\\033[00m\\n%s' \\\n    \"$username\" \"$model\" \"$cost_info\" \"$short_path\" \"$git_info\"\n\n# With:\nprintf '\\033[01;32m%s\\033[00m \\033[01;36m(%s)\\033[00m:\\033[01;37m%s\\033[00m%s%s' \\\n    \"$username\" \"$model\" \"$short_path\" \"$git_info\" \"$cost_info\"\n```\n\n### Disabling Cost Tracking\n\nIf `ccusage` is unavailable or not desired:\n\n1. Comment out the cost section in the script (lines ~47-73)\n2. Remove `%s` for `$cost_info` from the final `printf`\n\nSee `references/ccusage_integration.md` for details.\n\n### Adding Custom Elements\n\nAdd custom information (e.g., hostname, time):\n\n```bash\n# Add variable before final printf:\nhostname=$(hostname -s)\ncurrent_time=$(date +%H:%M)\n\n# Update printf to include new elements:\nprintf '\\033[01;32m%s@%s\\033[00m \\033[01;36m(%s)\\033[00m%s [%s]\\n...' \\\n    \"$username\" \"$hostname\" \"$model\" \"$cost_info\" \"$current_time\" ...\n```\n\n## Troubleshooting\n\n### Costs Not Showing\n\n**Check:**\n1. Is `ccusage` installed? Run `which ccusage`\n2. Test `ccusage` manually: `ccusage session --json --offline -o desc`\n3. Wait 5-10 seconds after first display (background fetch)\n4. Check cache: `ls -lh /tmp/claude_cost_cache_*.txt`\n\n**Solution:** See `references/ccusage_integration.md` for detailed troubleshooting.\n\n### Colors Hard to Read\n\n**Solution:** Adjust colors for your terminal background using `references/color_codes.md`. Bright colors (`01;3X`) are generally more visible than regular (`00;3X`).\n\n### Statusline Not Updating\n\n**Check:**\n1. Verify settings.json points to correct script path\n2. Ensure script is executable: `chmod +x ~/.claude/statusline.sh`\n3. Restart Claude Code\n\n### Git Status Not Showing\n\n**Check:**\n1. Are you in a git repository?\n2. Test git commands: `git branch --show-current`\n3. Check git permissions in the directory\n\n## Resources\n\n### scripts/generate_statusline.sh\nMain statusline script with all features (multi-line, ccusage, git, colors). Copy this to `~/.claude/statusline.sh` for use.\n\n### scripts/install_statusline.sh\nAutomated installation script that copies the statusline script and updates settings.json.\n\n### references/color_codes.md\nComplete ANSI color code reference for customizing statusline colors. Load when users request color customization.\n\n### references/ccusage_integration.md\nDetailed explanation of ccusage integration, caching strategy, JSON structure, and troubleshooting. Load when users experience cost tracking issues or want to understand how it works.",
        "teams-channel-post-writer/SKILL.md": "---\nname: teams-channel-post-writer\ndescription: Creates educational Teams channel posts for internal knowledge sharing about Claude Code features, tools, and best practices. Applies when writing posts, announcements, or documentation to teach colleagues effective Claude Code usage, announce new features, share productivity tips, or document lessons learned. Provides templates, writing guidelines, and structured approaches emphasizing concrete examples, underlying principles, and connections to best practices like context engineering. Activates for content involving Teams posts, channel announcements, feature documentation, or tip sharing.\n---\n\n# Teams Channel Post Writer\n\n## Overview\n\nCreate well-structured, educational Teams channel posts for internal knowledge sharing about Claude Code features and best practices. This skill provides templates, writing guidelines, and a structured workflow to produce consistent, actionable content that helps colleagues learn effective Claude Code usage.\n\n## When to Use This Skill\n\nThis skill activates when creating Teams channel posts to:\n- Announce and explain new Claude Code features\n- Share Claude Code tips and best practices\n- Teach effective prompting patterns and workflows\n- Connect features to broader engineering principles (e.g., context engineering)\n- Document lessons learned from using Claude Code\n\n## Workflow\n\n### 1. Understand the Topic\n\nGather information about what to write about:\n- Research the feature/topic thoroughly using official documentation\n- Verify release dates and version numbers from changelogs\n- Identify the core benefit or principle the post should teach\n- Collect concrete examples from real usage\n\n**Research checklist:**\n- [ ] Found official release date/version number\n- [ ] Verified feature behavior through testing or documentation\n- [ ] Identified authoritative sources to link to\n- [ ] Understood the underlying principle or best practice\n\n### 2. Plan the Content\n\nBased on the writing guidelines in `references/writing-guidelines.md`, plan:\n- **Hook**: What's new or important about this topic?\n- **Core principle**: What best practice does this illustrate?\n- **Examples**: What concrete prompts or workflows demonstrate this?\n- **Call-to-action**: What should readers try next?\n\n### 3. Draft Using the Template\n\nStart with the template in `assets/post-template.md` and fill in:\n\n1. **Title**: Use an emoji and clear description\n2. **Introduction**: Include release date and brief context\n3. **What it is**: 1-2 sentence explanation\n4. **How to use it**: Show \"Normal vs Better\" pattern with explicit instructions\n5. **Why use it**: Explain the underlying principle with 4 key benefits\n6. **Examples**: Provide 3+ realistic, concrete prompts\n7. **Options/Settings**: List key configurations or parameters\n8. **Call-to-action**: End with actionable next step\n9. **Learn more**: Link to authoritative resources\n\n### 4. Apply Writing Guidelines\n\nReview the draft against the quality checklist in `references/writing-guidelines.md`:\n- Educational and helpful tone\n- \"Normal/Better\" pattern (not \"Wrong/Correct\")\n- Concrete, realistic examples\n- Explains the \"why\" with principles\n- Clear structure with bullets and formatting\n- Verified facts and dates\n\n### 5. Save and Share\n\nSave the final post to your team's documentation location with a descriptive filename like \"Claude Code Tips.md\" or \"[Topic Name].md\"\n\n## Key Principles\n\n### Show, Don't Just Tell\nAlways include concrete examples users can adapt. Use \"Normal vs Better\" comparisons to demonstrate improvements without making readers feel criticized.\n\n### Connect to Principles\nDon't just describe features‚Äîexplain the underlying best practices. For example, connect the Explore agent to \"context offloading\" principles in context engineering.\n\n### Make it Actionable\nBe explicit about invocation patterns. Users should be able to copy/paste examples and immediately use them.\n\n### Verify Everything\nAlways research release dates, verify feature behavior, and link to authoritative sources. Accuracy builds trust.\n\n## Resources\n\n### references/writing-guidelines.md\nComprehensive writing guidelines including:\n- Tone and style standards\n- Structure patterns for different post types\n- Formatting conventions\n- Research requirements\n- Quality checklist\n\nReference this file for detailed guidance on tone, structure, and quality standards.\n\n### assets/post-template.md\nReady-to-use markdown template with placeholder structure for:\n- Title and introduction\n- Feature explanation\n- Usage examples\n- Benefits and principles\n- Options and settings\n- Call-to-action and resources\n\nCopy this template as a starting point for new posts, then customize the content while maintaining the proven structure.",
        "transcript-fixer/SKILL.md": "---\nname: transcript-fixer\ndescription: Corrects speech-to-text transcription errors in meeting notes, lectures, and interviews using dictionary rules and AI. Learns patterns to build personalized correction databases. Use when working with transcripts containing ASR/STT errors, homophones, or Chinese/English mixed content requiring cleanup.\n---\n\n# Transcript Fixer\n\nCorrect speech-to-text transcription errors through dictionary-based rules, AI-powered corrections, and automatic pattern detection. Build a personalized knowledge base that learns from each correction.\n\n## When to Use This Skill\n\n- Correcting ASR/STT errors in meeting notes, lectures, or interviews\n- Building domain-specific correction dictionaries\n- Fixing Chinese/English homophone errors or technical terminology\n- Collaborating on shared correction knowledge bases\n\n## Prerequisites\n\n**Python execution must use `uv`** - never use system Python directly.\n\nIf `uv` is not installed:\n```bash\n# macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows PowerShell\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n## Quick Start\n\n**Recommended: Use Enhanced Wrapper** (auto-detects API key, opens HTML diff):\n\n```bash\n# First time: Initialize database\nuv run scripts/fix_transcription.py --init\n\n# Process transcript with enhanced UX\nuv run scripts/fix_transcript_enhanced.py input.md --output ./corrected\n```\n\nThe enhanced wrapper automatically:\n- Detects GLM API key from shell configs (checks lines near `ANTHROPIC_BASE_URL`)\n- Moves output files to specified directory\n- Opens HTML visual diff in browser for immediate feedback\n\n**Alternative: Use Core Script Directly**:\n\n```bash\n# 1. Set API key (if not auto-detected)\nexport GLM_API_KEY=\"<api-key>\"  # From https://open.bigmodel.cn/\n\n# 2. Add common corrections (5-10 terms)\nuv run scripts/fix_transcription.py --add \"ÈîôËØØËØç\" \"Ê≠£Á°ÆËØç\" --domain general\n\n# 3. Run full correction pipeline\nuv run scripts/fix_transcription.py --input meeting.md --stage 3\n\n# 4. Review learned patterns after 3-5 runs\nuv run scripts/fix_transcription.py --review-learned\n```\n\n**Output files**:\n- `*_stage1.md` - Dictionary corrections applied\n- `*_stage2.md` - AI corrections applied (final version)\n- `*_ÂØπÊØî.html` - Visual diff (open in browser for best experience)\n\n**Generate word-level diff** (recommended for reviewing corrections):\n```bash\nuv run scripts/generate_word_diff.py original.md corrected.md output.html\n```\n\nThis creates an HTML file showing word-by-word differences with clear highlighting:\n- üî¥ `japanese 3 pro` ‚Üí üü¢ `Gemini 3 Pro` (complete word replacements)\n- Easy to spot exactly what changed without character-level noise\n\n## Example Session\n\n**Input transcript** (`meeting.md`):\n```\n‰ªäÂ§©Êàë‰ª¨ËÆ®ËÆ∫‰∫ÜÂ∑®ÂçáÊô∫ËÉΩÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇ\nËÇ°‰ª∑Á≥ªÁªüÈúÄË¶Å‰ºòÂåñÔºåÁõÆÂâçÊÄßËÉΩ‰∏çÂ§üÂ•Ω„ÄÇ\n```\n\n**After Stage 1** (`meeting_stage1.md`):\n```\n‰ªäÂ§©Êàë‰ª¨ËÆ®ËÆ∫‰∫ÜÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇ  ‚Üê \"Â∑®Âçá\"‚Üí\"ÂÖ∑Ë∫´\" corrected\nËÇ°‰ª∑Á≥ªÁªüÈúÄË¶Å‰ºòÂåñ,ÁõÆÂâçÊÄßËÉΩ‰∏çÂ§üÂ•Ω„ÄÇ  ‚Üê Unchanged (not in dictionary)\n```\n\n**After Stage 2** (`meeting_stage2.md`):\n```\n‰ªäÂ§©Êàë‰ª¨ËÆ®ËÆ∫‰∫ÜÂÖ∑Ë∫´Êô∫ËÉΩÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇ\nÊ°ÜÊû∂Á≥ªÁªüÈúÄË¶Å‰ºòÂåñÔºåÁõÆÂâçÊÄßËÉΩ‰∏çÂ§üÂ•Ω„ÄÇ  ‚Üê \"ËÇ°‰ª∑\"‚Üí\"Ê°ÜÊû∂\" corrected by AI\n```\n\n**Learned pattern detected:**\n```\n‚úì Detected: \"ËÇ°‰ª∑\" ‚Üí \"Ê°ÜÊû∂\" (confidence: 85%, count: 1)\n  Run --review-learned after 2 more occurrences to approve\n```\n\n## Core Workflow\n\nThree-stage pipeline stores corrections in `~/.transcript-fixer/corrections.db`:\n\n1. **Initialize** (first time): `uv run scripts/fix_transcription.py --init`\n2. **Add domain corrections**: `--add \"ÈîôËØØËØç\" \"Ê≠£Á°ÆËØç\" --domain <domain>`\n3. **Process transcript**: `--input file.md --stage 3`\n4. **Review learned patterns**: `--review-learned` and `--approve` high-confidence suggestions\n\n**Stages**: Dictionary (instant, free) ‚Üí AI via GLM API (parallel) ‚Üí Full pipeline\n**Domains**: `general`, `embodied_ai`, `finance`, `medical`, or custom names including Chinese (e.g., `ÁÅ´ÊòüÂä†ÈÄüÂô®`, `ÂÖ∑Ë∫´Êô∫ËÉΩ`)\n**Learning**: Patterns appearing ‚â•3 times at ‚â•80% confidence move from AI to dictionary\n\nSee `references/workflow_guide.md` for detailed workflows, `references/script_parameters.md` for complete CLI reference, and `references/team_collaboration.md` for collaboration patterns.\n\n## Critical Workflow: Dictionary Iteration\n\n**MUST save corrections after each fix.** This is the skill's core value.\n\nAfter fixing errors manually, immediately save to dictionary:\n```bash\nuv run scripts/fix_transcription.py --add \"ÈîôËØØËØç\" \"Ê≠£Á°ÆËØç\" --domain general\n```\n\nSee `references/iteration_workflow.md` for complete iteration guide with checklist.\n\n## AI Fallback Strategy\n\nWhen GLM API is unavailable (503, network issues), the script outputs `[CLAUDE_FALLBACK]` marker.\n\nClaude Code should then:\n1. Analyze the text directly for ASR errors\n2. Fix using Edit tool\n3. **MUST save corrections to dictionary** with `--add`\n\n## Database Operations\n\n**MUST read `references/database_schema.md` before any database operations.**\n\nQuick reference:\n```bash\n# View all corrections\nsqlite3 ~/.transcript-fixer/corrections.db \"SELECT * FROM active_corrections;\"\n\n# Check schema version\nsqlite3 ~/.transcript-fixer/corrections.db \"SELECT value FROM system_config WHERE key='schema_version';\"\n```\n\n## Stages\n\n| Stage | Description | Speed | Cost |\n|-------|-------------|-------|------|\n| 1 | Dictionary only | Instant | Free |\n| 2 | AI only | ~10s | API calls |\n| 3 | Full pipeline | ~10s | API calls |\n\n## Bundled Resources\n\n**Scripts:**\n- `ensure_deps.py` - Initialize shared virtual environment (run once, optional)\n- `fix_transcript_enhanced.py` - Enhanced wrapper (recommended for interactive use)\n- `fix_transcription.py` - Core CLI (for automation)\n- `generate_word_diff.py` - Generate word-level diff HTML for reviewing corrections\n- `examples/bulk_import.py` - Bulk import example\n\n**References** (load as needed):\n- **Critical**: `database_schema.md` (read before DB operations), `iteration_workflow.md` (dictionary iteration best practices)\n- Getting started: `installation_setup.md`, `glm_api_setup.md`, `workflow_guide.md`\n- Daily use: `quick_reference.md`, `script_parameters.md`, `dictionary_guide.md`\n- Advanced: `sql_queries.md`, `file_formats.md`, `architecture.md`, `best_practices.md`\n- Operations: `troubleshooting.md`, `team_collaboration.md`\n\n## Troubleshooting\n\nVerify setup health with `uv run scripts/fix_transcription.py --validate`. Common issues:\n- Missing database ‚Üí Run `--init`\n- Missing API key ‚Üí `export GLM_API_KEY=\"<key>\"` (obtain from https://open.bigmodel.cn/)\n- Permission errors ‚Üí Check `~/.transcript-fixer/` ownership\n\nSee `references/troubleshooting.md` for detailed error resolution and `references/glm_api_setup.md` for API configuration.\n",
        "twitter-reader/SKILL.md": "---\nname: twitter-reader\ndescription: Fetch Twitter/X post content by URL using jina.ai API to bypass JavaScript restrictions. Use when Claude needs to retrieve tweet content including author, timestamp, post text, images, and thread replies. Supports individual posts or batch fetching from x.com or twitter.com URLs.\n---\n\n# Twitter Reader\n\nFetch Twitter/X post content without needing JavaScript or authentication.\n\n## Prerequisites\n\nYou need a Jina API key to use this skill:\n\n1. Visit https://jina.ai/ to sign up (free tier available)\n2. Get your API key from the dashboard\n3. Set the environment variable:\n\n```bash\nexport JINA_API_KEY=\"your_api_key_here\"\n```\n\n## Quick Start\n\nFor a single tweet, use curl directly:\n\n```bash\ncurl \"https://r.jina.ai/https://x.com/USER/status/TWEET_ID\" \\\n  -H \"Authorization: Bearer ${JINA_API_KEY}\"\n```\n\nFor multiple tweets, use the bundled script:\n\n```bash\nscripts/fetch_tweets.sh url1 url2 url3\n```\n\n## What Gets Returned\n\n- **Title**: Post author and content preview\n- **URL Source**: Original tweet link\n- **Published Time**: GMT timestamp\n- **Markdown Content**: Full post text with media descriptions\n\n## Bundled Scripts\n\n### fetch_tweet.py\n\nPython script for fetching individual tweets.\n\n```bash\npython scripts/fetch_tweet.py https://x.com/user/status/123 output.md\n```\n\n### fetch_tweets.sh\n\nBash script for batch fetching multiple tweets.\n\n```bash\nscripts/fetch_tweets.sh \\\n  \"https://x.com/user/status/123\" \\\n  \"https://x.com/user/status/456\"\n```\n\n## URL Formats Supported\n\n- `https://x.com/USER/status/ID`\n- `https://twitter.com/USER/status/ID`\n- `https://x.com/...` (redirects work automatically)\n\n## Environment Variables\n\n- `JINA_API_KEY`: Required. Your Jina.ai API key for accessing the reader API\n",
        "ui-designer/SKILL.md": "---\nname: ui-designer\ndescription: Extract design systems from reference UI images and generate implementation-ready UI design prompts. Use when users provide UI screenshots/mockups and want to create consistent designs, generate design systems, or build MVP UIs matching reference aesthetics.\n---\n\n# UI Designer\n\n## Overview\n\nThis skill enables systematic extraction of design systems from reference UI images through a multi-step workflow: analyze visual patterns ‚Üí generate design system documentation ‚Üí create PRD ‚Üí produce implementation-ready UI prompts.\n\n## When to Use\n\n- User provides UI screenshots, mockups, or design references\n- Need to extract color palettes, typography, spacing from existing designs\n- Want to generate design system documentation from visual examples\n- Building MVP UI that should match reference aesthetics\n- Creating multiple UI variations following consistent design principles\n\n## Workflow\n\n### Step 1: Gather Inputs\n\nRequest from user:\n- **Reference images directory**: Path to folder containing UI screenshots/mockups\n- **Project idea file**: Document describing the product concept and goals\n- **Existing PRD** (optional): If PRD already exists, skip Step 3\n\n### Step 2: Extract Design System from Images\n\n**Use Task tool with general-purpose subagent**, providing:\n\n**Prompt template** from `assets/design-system.md`:\n- Analyze color palettes (primary, secondary, accent, functional colors)\n- Extract typography (font families, sizes, weights, line heights)\n- Identify component styles (buttons, cards, inputs, icons)\n- Document spacing system\n- Note animations/transitions patterns\n- Include dark mode variants if present\n\n**Attach reference images** to the subagent context.\n\n**Output**: Complete design system markdown following the template format\n\n**Save to**: `documents/designs/{image_dir_name}_design_system.md`\n\n### Step 3: Generate MVP PRD (if not provided)\n\n**Use Task tool with general-purpose subagent**, providing:\n\n**Prompt template** from `assets/app-overview-generator.md`:\n- Replace `{È°πÁõÆËÉåÊôØ}` with content from project idea file\n- The template guides through: elevator pitch, problem statement, target audience, USP, features list, UX/UI considerations\n\n**Interact with user** to refine and clarify product requirements\n\n**Output**: Structured PRD markdown\n\n**Save as variable** for Step 4 (optionally save to `documents/prd/`)\n\n### Step 4: Compose Final UI Implementation Prompt\n\nCombine design system and PRD using `assets/vibe-design-template.md`:\n\n**Substitutions:**\n- `{È°πÁõÆËÆæËÆ°ÊåáÂçó}` ‚Üí Design system from Step 2\n- `{È°πÁõÆMVP PRD}` ‚Üí PRD from Step 3 or provided PRD file\n\n**Result**: Complete, implementation-ready prompt containing:\n- Design aesthetics principles\n- Project-specific color/typography guidelines\n- App overview and feature requirements\n- Implementation tasks (multiple UI variations, component structure)\n\n**Save to**: `documents/ux-design/{idea_file_name}_design_prompt_{timestamp}.md`\n\n### Step 5: Verify React Environment\n\nCheck for existing React project:\n```bash\nfind . -name \"package.json\" -exec grep -l \"react\" {} \\;\n```\n\nIf none found, inform user:\n```bash\nnpx create-react-app my-app\ncd my-app\nnpm install -D tailwindcss postcss autoprefixer\nnpx tailwindcss init -p\nnpm install lucide-react\n```\n\n### Step 6: Implement UI\n\nUse the final composed prompt from Step 4 to implement UI in React project.\n\nThe prompt instructs to:\n- Create multiple design variations (3 for mobile, 2 for web)\n- Organize as separate components: `[solution-name]/pages/[page-name].jsx`\n- Aggregate all variations in showcase page\n\n## Template Assets\n\n### assets/design-system.md\n\nTemplate for extracting visual design patterns. Includes sections for:\n- Color palette (primary, secondary, accent, functional, backgrounds)\n- Typography (font families, weights, text styles)\n- Component styles (buttons, cards, inputs, icons)\n- Spacing system (4dp-48dp scale)\n- Animations (durations, easing curves)\n- Dark mode variants\n\nUse this template when analyzing reference images to ensure comprehensive design system coverage.\n\n### assets/app-overview-generator.md\n\nTemplate for collaborative PRD generation. Guides through:\n- Elevator pitch\n- Problem statement and target audience\n- Unique selling proposition\n- Platform targets\n- Feature list with user stories\n- UX/UI considerations per screen\n\nDesigned for interactive refinement with user to clarify requirements.\n\n### assets/vibe-design-template.md\n\nFinal implementation prompt template combining design system and PRD. Includes:\n- Aesthetic principles (minimalism, whitespace, color theory, typography hierarchy)\n- Practical requirements (Tailwind CSS, Lucide icons, responsive design)\n- Task specifications (multiple variations, component organization)\n\nThis template produces prompts ready for UI implementation without further modification.\n\n## Best Practices\n\n### Image Analysis\n\n- Read all images before starting analysis\n- Look for patterns across multiple screens\n- Note both explicit styles (colors, fonts) and implicit principles (spacing, hierarchy)\n- Capture dark mode if present in references\n\n### Design System Extraction\n\n- Be systematic: cover all template sections\n- Use specific values (hex codes, px sizes) not generic descriptions\n- Document the \"why\" for design choices when inferable\n- Include variants (hover states, disabled states)\n\n### PRD Generation\n\n- Engage user interactively to clarify ambiguities\n- Suggest features based on problem understanding\n- Ensure MVP scope is realistic\n- Document UX considerations per screen/interaction\n\n### Output Organization\n\n- Save design system with descriptive filename (based on image dir name)\n- Save final prompt with timestamp for version tracking\n- Keep all outputs in `documents/` directory for easy reference\n- Preserve intermediate outputs for iteration\n\n## Example Usage\n\n**User provides:**\n- `reference-images/saas-dashboard/` (5 screenshots)\n- `ideas/project-management-app.md` (project concept)\n\n**Execute workflow:**\n\n1. Read 5 images from `reference-images/saas-dashboard/`\n2. Use Task tool ‚Üí design-system.md template ‚Üí analyze images\n3. Save to `documents/designs/saas-dashboard_design_system.md`\n4. Use Task tool ‚Üí app-overview-generator.md with project concept\n5. Refine PRD through user interaction\n6. Combine design system + PRD using vibe-design-template.md\n7. Save to `documents/ux-design/project-management-app_design_prompt_20251025_153000.md`\n8. Check React environment, inform user if setup needed\n9. Implement UI using final prompt\n\n## Notes\n\n- This is a **high freedom** workflow‚Äîadapt steps based on context\n- Templates provide structure but encourage thoughtful analysis over rote filling\n- User interaction during PRD generation is critical for quality\n- Final prompt quality directly impacts UI implementation success\n- Preserve all intermediate outputs for iteration and refinement\n",
        "video-comparer/README.md": "# Video Comparer\n\nA professional video comparison tool that analyzes compression quality and generates interactive HTML reports. Compare original vs compressed videos with detailed metrics (PSNR, SSIM) and frame-by-frame visual comparisons.\n\n## Features\n\n### üéØ Video Analysis\n- **Metadata Extraction**: Codec, resolution, frame rate, bitrate, duration, file size\n- **Quality Metrics**: PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index)\n- **Compression Analysis**: Size and bitrate reduction percentages\n\n### üñºÔ∏è Interactive Comparison\n- **Three Viewing Modes**:\n  - **Slider Mode**: Interactive before/after slider using img-comparison-slider\n  - **Side-by-Side Mode**: Simultaneous display of both frames\n  - **Grid Mode**: Compact 2-column layout\n- **Zoom Controls**: 50%-200% zoom with real image dimension scaling\n- **Responsive Design**: Works on desktop, tablet, and mobile\n\n### üîí Security & Reliability\n- **Path Validation**: Prevents directory traversal attacks\n- **Command Injection Prevention**: No shell=True in subprocess calls\n- **Resource Limits**: File size and timeout restrictions\n- **Comprehensive Error Handling**: User-friendly error messages\n\n## Quick Start\n\n### Prerequisites\n\n1. **Python 3.8+** (for type hints and modern features)\n2. **FFmpeg** (required for video analysis)\n\n```bash\n# macOS\nbrew install ffmpeg\n\n# Ubuntu/Debian\nsudo apt install ffmpeg\n\n# Windows\n# Download from https://ffmpeg.org/download.html\n```\n\n### Basic Usage\n\n```bash\n# Navigate to the skill directory\ncd /path/to/video-comparer\n\n# Compare two videos\npython3 scripts/compare.py original.mp4 compressed.mp4\n\n# Open the generated report\nopen comparison.html  # macOS\n# or\nxdg-open comparison.html  # Linux\n# or\nstart comparison.html  # Windows\n```\n\n### Command Line Options\n\n```bash\npython3 scripts/compare.py <original> <compressed> [options]\n\nArguments:\n  original      Path to original video file\n  compressed    Path to compressed video file\n\nOptions:\n  -o, --output PATH     Output HTML report path (default: comparison.html)\n  --interval SECONDS    Frame extraction interval in seconds (default: 5)\n  -h, --help           Show help message\n```\n\n### Examples\n\n```bash\n# Basic comparison\npython3 scripts/compare.py original.mp4 compressed.mp4\n\n# Custom output file\npython3 scripts/compare.py original.mp4 compressed.mp4 -o report.html\n\n# Extract frames every 10 seconds (fewer frames, faster processing)\npython3 scripts/compare.py original.mp4 compressed.mp4 --interval 10\n\n# Compare with absolute paths\npython3 scripts/compare.py ~/Videos/original.mov ~/Videos/compressed.mov\n\n# Batch comparison\nfor original in originals/*.mp4; do\n    compressed=\"compressed/$(basename \"$original\")\"\n    python3 scripts/compare.py \"$original\" \"$compressed\" -o \"reports/$(basename \"$original\" .mp4).html\"\ndone\n```\n\n## Supported Formats\n\n| Format | Extension | Notes |\n|--------|-----------|-------|\n| MP4    | `.mp4`    | Recommended, widely supported |\n| MOV    | `.mov`    | Apple QuickTime format |\n| AVI    | `.avi`    | Legacy format |\n| MKV    | `.mkv`    | Matroska container |\n| WebM   | `.webm`   | Web-optimized format |\n\n## Output Report\n\nThe generated HTML report includes:\n\n### 1. Video Parameters Comparison\n- **Codec**: Video compression format (h264, hevc, vp9, etc.)\n- **Resolution**: Width √ó Height in pixels\n- **Frame Rate**: Frames per second\n- **Bitrate**: Data rate (kbps/Mbps)\n- **Duration**: Total video length\n- **File Size**: Storage requirement\n- **Filenames**: Original file names\n\n### 2. Quality Analysis\n- **Size Reduction**: Percentage of storage saved\n- **Bitrate Reduction**: Percentage of bandwidth saved\n- **PSNR**: Peak Signal-to-Noise Ratio (dB)\n  - 30-35 dB: Acceptable quality\n  - 35-40 dB: Good quality\n  - 40+ dB: Excellent quality\n- **SSIM**: Structural Similarity Index (0.0-1.0)\n  - 0.90-0.95: Good quality\n  - 0.95-0.98: Very good quality\n  - 0.98+: Excellent quality\n\n### 3. Frame-by-Frame Comparison\n- Interactive slider for detailed comparison\n- Side-by-side viewing for overall assessment\n- Grid layout for quick scanning\n- Zoom controls (50%-200%)\n- Timestamp labels for each frame\n\n## Configuration\n\n### Constants in `scripts/compare.py`\n\n```python\nALLOWED_EXTENSIONS = {'.mp4', '.mov', '.avi', '.mkv', '.webm'}\nMAX_FILE_SIZE_MB = 500          # Maximum file size limit\nFFMPEG_TIMEOUT = 300            # FFmpeg timeout (5 minutes)\nFFPROBE_TIMEOUT = 30            # FFprobe timeout (30 seconds)\nBASE_FRAME_HEIGHT = 800         # Frame height for comparison\nFRAME_INTERVAL = 5              # Default frame extraction interval\n```\n\n### Customizing Frame Resolution\n\nTo change the frame resolution for comparison:\n\n```python\n# In scripts/compare.py\nBASE_FRAME_HEIGHT = 1200  # Higher resolution (larger file size)\n# or\nBASE_FRAME_HEIGHT = 600   # Lower resolution (smaller file size)\n```\n\n## Performance\n\n### Processing Time\n- **Metadata Extraction**: < 5 seconds\n- **Quality Metrics**: 1-2 minutes (depends on video duration)\n- **Frame Extraction**: 30-60 seconds (depends on video length and interval)\n- **Report Generation**: < 10 seconds\n\n### File Sizes\n- **Input Videos**: Up to 500MB each (configurable)\n- **Generated Report**: 2-5MB (depends on frame count)\n- **Temporary Files**: Auto-cleaned during processing\n\n### Resource Usage\n- **Memory**: ~200-500MB during processing\n- **Disk Space**: ~100MB temporary files\n- **CPU**: Moderate (video decoding)\n\n## Security Features\n\n### Path Validation\n- ‚úÖ Converts all paths to absolute paths\n- ‚úÖ Verifies files exist and are readable\n- ‚úÖ Checks file extensions against whitelist\n- ‚úÖ Validates file size before processing\n\n### Command Injection Prevention\n- ‚úÖ All subprocess calls use argument lists\n- ‚úÖ No `shell=True` in subprocess calls\n- ‚úÖ User input never passed to shell\n- ‚úÖ FFmpeg arguments validated and escaped\n\n### Resource Limits\n- ‚úÖ File size limit enforcement\n- ‚úÖ Timeout limits for FFmpeg operations\n- ‚úÖ Temporary files auto-cleanup\n- ‚úÖ Memory usage monitoring\n\n## Troubleshooting\n\n### Common Issues\n\n#### \"FFmpeg not found\"\n```bash\n# Install FFmpeg using your package manager\nbrew install ffmpeg          # macOS\nsudo apt install ffmpeg      # Ubuntu/Debian\nsudo yum install ffmpeg      # CentOS/RHEL/Fedora\n```\n\n#### \"File too large: X MB\"\n```bash\n# Options:\n1. Compress videos before comparison\n2. Increase MAX_FILE_SIZE_MB in compare.py\n3. Use shorter video clips\n```\n\n#### \"Operation timed out\"\n```bash\n# For very long videos:\npython3 scripts/compare.py original.mp4 compressed.mp4 --interval 10\n# or\n# Increase FFMPEG_TIMEOUT in compare.py\n```\n\n#### \"No frames extracted\"\n- Check if videos are playable in media player\n- Verify videos have sufficient duration (> interval seconds)\n- Ensure FFmpeg can decode the codec\n\n#### \"Frame count mismatch\"\n- Videos have different durations or frame rates\n- Script automatically truncates to minimum frame count\n- Warning is displayed in output\n\n### Debug Mode\n\nEnable verbose output by modifying the script:\n\n```python\n# Add at the top of compare.py\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n```\n\n## Architecture\n\n### File Structure\n```\nvideo-comparer/\n‚îú‚îÄ‚îÄ SKILL.md                      # Skill description and invocation\n‚îú‚îÄ‚îÄ README.md                     # This file\n‚îú‚îÄ‚îÄ assets/\n‚îÇ   ‚îî‚îÄ‚îÄ template.html            # HTML report template\n‚îú‚îÄ‚îÄ references/\n‚îÇ   ‚îú‚îÄ‚îÄ video_metrics.md         # Quality metrics reference\n‚îÇ   ‚îî‚îÄ‚îÄ ffmpeg_commands.md       # FFmpeg command examples\n‚îî‚îÄ‚îÄ scripts/\n    ‚îî‚îÄ‚îÄ compare.py               # Main comparison script (696 lines)\n```\n\n### Code Organization\n\n- **compare.py**: Main script with all functionality\n  - Input validation and security checks\n  - FFmpeg integration and command execution\n  - Video metadata extraction\n  - Quality metrics calculation (PSNR, SSIM)\n  - Frame extraction and processing\n  - HTML report generation\n\n- **template.html**: Interactive report template\n  - Responsive CSS Grid layout\n  - Web Components for slider functionality\n  - Base64-encoded image embedding\n  - Interactive controls and zoom\n\n### Dependencies\n\n- **Python Standard Library**: os, subprocess, json, pathlib, tempfile, base64\n- **External Tools**: FFmpeg, FFprobe (must be installed separately)\n- **Web Components**: img-comparison-slider (loaded from CDN)\n\n## Contributing\n\n### Development Setup\n\n```bash\n# Clone the repository\ngit clone <repository-url>\ncd video-comparer\n\n# Create virtual environment (optional but recommended)\npython3 -m venv venv\nsource venv/bin/activate  # macOS/Linux\n# or\nvenv\\Scripts\\activate     # Windows\n\n# Install FFmpeg (see Prerequisites section)\n# Test the installation\npython3 scripts/compare.py --help\n```\n\n### Code Style\n\n- **Python**: PEP 8 compliance\n- **Type Hints**: All function signatures\n- **Docstrings**: All public functions and classes\n- **Error Handling**: Comprehensive exception handling\n- **Security**: Input validation and sanitization\n\n### Testing\n\n```bash\n# Test with sample videos (you'll need to provide these)\npython3 scripts/compare.py test/original.mp4 test/compressed.mp4\n\n# Test error handling\npython3 scripts/compare.py nonexistent.mp4 also_nonexistent.mp4\npython3 scripts/compare.py original.txt compressed.txt\n```\n\n## License\n\nThis skill is part of the claude-code-skills collection. See the main repository for license information.\n\n## Support\n\nFor issues and questions:\n1. Check this README for troubleshooting\n2. Review the SKILL.md file for detailed usage instructions\n3. Ensure FFmpeg is properly installed\n4. Verify video files are supported formats\n\n## Changelog\n\n### v1.0.0\n- Initial release\n- Video metadata extraction\n- PSNR and SSIM quality metrics\n- Frame extraction and comparison\n- Interactive HTML report generation\n- Security features and error handling\n- Responsive design and mobile support",
        "video-comparer/SKILL.md": "---\nname: video-comparer\ndescription: This skill should be used when comparing two videos to analyze compression results or quality differences. Generates interactive HTML reports with quality metrics (PSNR, SSIM) and frame-by-frame visual comparisons. Triggers when users mention \"compare videos\", \"video quality\", \"compression analysis\", \"before/after compression\", or request quality assessment of compressed videos.\n---\n\n# Video Comparer\n\n## Overview\n\nCompare two videos and generate an interactive HTML report analyzing compression results. The script extracts video metadata, calculates quality metrics (PSNR, SSIM), and creates frame-by-frame visual comparisons with three viewing modes: slider, side-by-side, and grid.\n\n## When to Use This Skill\n\nUse this skill when:\n- Comparing original and compressed videos\n- Analyzing video compression quality and efficiency\n- Evaluating codec performance or bitrate reduction impact\n- Users mention \"compare videos\", \"video quality\", \"compression analysis\", or \"before/after compression\"\n\n## Core Usage\n\n### Basic Command\n\n```bash\npython3 scripts/compare.py original.mp4 compressed.mp4\n```\n\nGenerates `comparison.html` with:\n- Video parameters (codec, resolution, bitrate, duration, file size)\n- Quality metrics (PSNR, SSIM, size/bitrate reduction percentages)\n- Frame-by-frame comparison (default: frames at 5s intervals)\n\n### Command Options\n\n```bash\n# Custom output file\npython3 scripts/compare.py original.mp4 compressed.mp4 -o report.html\n\n# Custom frame interval (larger = fewer frames, faster processing)\npython3 scripts/compare.py original.mp4 compressed.mp4 --interval 10\n\n# Batch comparison\nfor original in originals/*.mp4; do\n    compressed=\"compressed/$(basename \"$original\")\"\n    output=\"reports/$(basename \"$original\" .mp4).html\"\n    python3 scripts/compare.py \"$original\" \"$compressed\" -o \"$output\"\ndone\n```\n\n## Requirements\n\n### System Dependencies\n\n**FFmpeg and FFprobe** (required for video analysis and frame extraction):\n\n```bash\n# macOS\nbrew install ffmpeg\n\n# Ubuntu/Debian\nsudo apt update && sudo apt install ffmpeg\n\n# Windows\n# Download from https://ffmpeg.org/download.html\n# Or use: winget install ffmpeg\n```\n\n**Python 3.8+** (uses type hints, f-strings, pathlib)\n\n### Video Specifications\n\n- **Supported formats:** `.mp4` (recommended), `.mov`, `.avi`, `.mkv`, `.webm`\n- **File size limit:** 500MB per video (configurable)\n- **Processing time:** ~1-2 minutes for typical videos; varies by duration and frame interval\n\n## Script Behavior\n\n### Automatic Validation\n\nThe script automatically validates:\n- FFmpeg/FFprobe installation and availability\n- File existence, extensions, and size limits\n- Path security (prevents directory traversal)\n\nClear error messages with resolution guidance appear when validation fails.\n\n### Quality Metrics\n\nThe script calculates two standard quality metrics:\n\n**PSNR (Peak Signal-to-Noise Ratio):** Pixel-level similarity measurement (20-50 dB scale, higher is better)\n\n**SSIM (Structural Similarity Index):** Perceptual similarity measurement (0.0-1.0 scale, higher is better)\n\nFor detailed interpretation scales and quality thresholds, consult `references/video_metrics.md`.\n\n### Frame Extraction\n\nThe script extracts frames at specified intervals (default: 5 seconds), scales them to consistent height (800px) for comparison, and embeds them as base64 data URLs in self-contained HTML. Temporary files are automatically cleaned after processing.\n\n### Output Report\n\nThe generated HTML report includes:\n- **Slider Mode**: Drag to reveal original vs compressed (default)\n- **Side-by-Side Mode**: Simultaneous display for direct comparison\n- **Grid Mode**: Compact 2-column layout\n- **Zoom Controls**: 50%-200% magnification\n- Self-contained format (no server required, works offline)\n\n## Important Implementation Details\n\n### Security\n\nThe script implements:\n- Path validation (absolute paths, prevents directory traversal)\n- Command injection prevention (no `shell=True`, validated arguments)\n- Resource limits (file size, timeouts)\n- Custom exceptions: `ValidationError`, `FFmpegError`, `VideoComparisonError`\n\n### Common Error Scenarios\n\n**\"FFmpeg not found\"**: Install FFmpeg via platform package manager (see Requirements section)\n\n**\"File too large\"**: Compress videos before comparison, or adjust `MAX_FILE_SIZE_MB` in `scripts/compare.py`\n\n**\"Operation timed out\"**: Increase `FFMPEG_TIMEOUT` constant or use larger `--interval` value (processes fewer frames)\n\n**\"Frame count mismatch\"**: Videos have different durations/frame rates; script auto-truncates to minimum frame count and shows warning\n\n## Configuration\n\nThe script includes adjustable constants for file size limits, timeouts, frame dimensions, and extraction intervals. To customize behavior, edit the constants at the top of `scripts/compare.py`. For detailed configuration options and their impacts, consult `references/configuration.md`.\n\n## Reference Materials\n\nConsult these files for detailed information:\n- **`references/video_metrics.md`**: Quality metrics interpretation (PSNR/SSIM scales, compression targets, bitrate guidelines)\n- **`references/ffmpeg_commands.md`**: FFmpeg command reference (metadata extraction, frame extraction, troubleshooting)\n- **`references/configuration.md`**: Script configuration options and adjustable constants\n- **`assets/template.html`**: HTML report template for customizing viewing modes and styling",
        "youtube-downloader/SKILL.md": "---\nname: youtube-downloader\ndescription: Download YouTube videos and HLS streams (m3u8) from platforms like Mux, Vimeo, etc. using yt-dlp and ffmpeg. Use this skill when users request downloading videos, extracting audio, handling protected streams with authentication headers, or troubleshooting download issues like nsig extraction failures, 403 errors, or cookie extraction problems.\n---\n\n# YouTube Downloader\n\n## Overview\n\nEnable reliable video and audio downloads from YouTube and HLS streaming platforms (Mux, Vimeo, etc.) using yt-dlp and ffmpeg. This skill provides workflows for:\n- YouTube downloads (up to 4K) using PO token providers or browser cookies\n- HLS stream downloads with authentication headers\n- Handling protected content and troubleshooting common download failures\n\n## Non-Technical User Experience (Default)\n\nAssume the user is non-technical. Do not ask them to run commands. Execute everything yourself and report progress in plain language. Avoid mentioning tooling unless the user asks.\n\n**Default flow:**\n1. Ask for the URL (if not provided).\n2. Fetch video metadata (title/uploader/duration/thumbnail) and confirm it matches the user's intent.\n   - If yt-dlp is blocked by ‚Äúconfirm you‚Äôre not a bot‚Äù, fall back to YouTube oEmbed for title/uploader/thumbnail (duration may be unknown).\n3. Offer simple choices (video vs. audio-only, quality, subtitles, save location).\n4. Proceed with sensible defaults if the user does not specify:\n   - Video download at best quality\n   - MP4 merged output\n   - Single video only (no playlists)\n5. Download and report the final file path, file size, and resolution (if video).\n\n**Offer choices in user-friendly terms:**\n- ‚ÄúDownload the video in best quality (default)‚Äù\n- ‚ÄúDownload audio only (MP3)‚Äù\n- ‚ÄúPick a quality: 1080p / 720p / 480p / 360p‚Äù\n- ‚ÄúInclude subtitles (if available)‚Äù\n- ‚ÄúSave to the Downloads folder (default) or tell me another folder‚Äù\n\n**Always render the thumbnail when available:**\n- If metadata includes a thumbnail URL, include it using Markdown image syntax: `![Thumbnail](URL)`.\n\n**Ask before doing extra work:**\n- Confirm playlist downloads (can be large).\n- Confirm installing/upgrading dependencies if missing.\n- Ask before extracting browser cookies.\n- If using cookies, never mention cookie counts or raw cookie details in user-facing responses. Say ‚Äúused your Chrome login session‚Äù.\n- If verification is required, automatically set up a local PO Token helper (no user actions). If Docker is missing or fails, do **not** attempt to install Docker‚Äîswitch to the browser-based PO Token provider instead.\n\n**Legal/Safety reminder (brief):**\n- Proceed only if the user has the rights or permission to download the content.\n\n**Response template (use plain language, no commands):**\n```\n![Thumbnail](THUMBNAIL_URL)\n\nTitle: ‚Ä¶\nChannel: ‚Ä¶\nDuration: ‚Ä¶\n\nI can help you:\n1) Download the video (best quality, MP4)\n2) Download audio only (MP3)\n3) Pick a specific quality (1080p/720p/480p/360p)\n4) Include subtitles (if available)\n\nWhere should I save it? (Default: Downloads folder)\n```\n\n**If the user says ‚Äújust download‚Äù:**\n- Proceed with defaults and confirm when the download finishes.\n  - If blocked by a 403, automatically set up the verification helper and retry.\n\n## Reliable Download SOP (Internal)\n\nFollow this SOP to avoid common failures and confusion:\n\n1. Quote URLs in shell commands (zsh treats `?` as a glob). Example: `'https://www.youtube.com/watch?v=VIDEO_ID'`.\n2. Ensure proxy is active for both yt-dlp and PO Token providers (HTTP_PROXY/HTTPS_PROXY/ALL_PROXY).\n3. If you see ‚ÄúSign in to confirm you‚Äôre not a bot‚Äù, request permission and use browser cookies. Do not proceed without cookies.\n4. Start a PO Token provider before downloading (fail fast if it cannot start).\n   - Use Docker bgutil provider when available.\n   - If Docker is missing or fails, switch to browser-based WPC provider.\n5. If cookies are in use, prefer the `web_safari` player client. Otherwise prefer `mweb` for PO tokens.\n6. Keep the browser window open while WPC is minting tokens. Ensure Chrome can reach YouTube through the same proxy.\n7. If you get ‚ÄúOnly images are available‚Äù or ‚ÄúRequested format is not available‚Äù, treat it as a PO Token failure and retry after fixing token provider/browser state.\n8. If you get SSL EOF or fragment errors, treat it as a proxy/network issue. Retry with progressive formats and/or a better proxy.\n\n## Agent Execution Checklist (Internal)\n\n- Run `scripts/download_video.py URL --info` (add `--cookies-from-browser chrome` if permission granted) to fetch metadata and thumbnail.\n- If yt-dlp metadata fails, rely on the script‚Äôs oEmbed fallback for title/uploader/thumbnail and note that duration may be unavailable.\n- If a thumbnail URL is present, render it in the response with Markdown image syntax.\n- Ask the user to choose video vs. audio-only and (optionally) a quality preset.\n- Use a friendly default save location (Downloads folder) unless the user specifies a folder.\n- For subtitles, run with `--subtitles` and the requested `--sub-lang`.\n- After download, report file name, size, and resolution (if video) in plain language.\n- If download fails with 403/fragment errors, retry once with non-m3u8 progressive formats.\n- If ‚ÄúSign in to confirm you‚Äôre not a bot‚Äù appears, request cookie access and retry with cookies + `web_safari`.\n- If ‚ÄúOnly images are available‚Äù appears, treat it as PO Token failure and retry after fixing provider/browser state.\n- Start the PO Token provider before downloads (`--auto-po-token` default). Fail fast if it cannot start.\n- If Docker-based provider fails (common in China), automatically fall back to the browser-based WPC provider (it may briefly open a browser window).\n- If the WPC provider is used, keep the browser window open until download starts. If the browser fails to launch, set the Chrome path explicitly.\n- If the PO Token provider times out, restart it once and retry.\n- If a system proxy is configured, pass it into the provider container. If the proxy points to 127.0.0.1/localhost, rewrite it to `host.docker.internal` for Docker.\n\n## When to Use This Skill\n\nThis skill should be invoked when users:\n- Request downloading YouTube videos or playlists\n- Want to extract audio from YouTube videos\n- Experience yt-dlp download failures or limited format availability\n- Need help with format selection or quality options\n- Report only low-quality (360p) formats available\n- Ask about downloading YouTube content in specific quality (1080p, 4K, etc.)\n- Need to convert downloaded WebM videos to MP4 format for wider compatibility\n- Request downloading HLS streams (m3u8) from platforms like Mux, Vimeo, or other streaming services\n- Need to download protected streams that require authentication headers\n\n## Prerequisites\n\n### 1. Verify yt-dlp Installation (Run this yourself)\n\n```bash\nwhich yt-dlp\nyt-dlp --version\n```\n\nIf not installed or outdated (< 2025.10.22):\n\n```bash\nbrew upgrade yt-dlp  # macOS\n# or\npip install --upgrade yt-dlp  # Cross-platform\n```\n\n**Critical**: Outdated yt-dlp versions cause nsig extraction failures and missing formats.\n\n### 2. Check Current Quality Access (Run this yourself)\n\nBefore downloading, check available formats:\n\n```bash\nyt-dlp -F \"https://youtu.be/VIDEO_ID\"\n```\n\n**If only format 18 (360p) appears**: PO token provider setup needed for high-quality access.\n\n## High-Quality Download Workflow\n\n### Step 1: Install PO Token Provider (One-time Setup)\n\nFor 1080p/1440p/4K access, install a PO token provider plugin into yt-dlp's Python environment:\n\n```bash\n# Find yt-dlp's Python path (interpreter used by yt-dlp)\nhead -1 $(which yt-dlp)\n\n# Install plugin using the interpreter from the line above\n<YTDLP_PYTHON> -m pip install bgutil-ytdlp-pot-provider\n```\n\n**Verification**: Run `yt-dlp -F \"VIDEO_URL\"` again. Look for formats 137 (1080p), 271 (1440p), or 313 (4K).\n\nSee `references/po-token-setup.md` for detailed setup instructions and troubleshooting.\n\n### Step 2: Download with Best Quality\n\nOnce PO token provider is installed:\n\n```bash\n# Download best quality up to 1080p\nyt-dlp -f \"bestvideo[height<=1080]+bestaudio/best\" \"VIDEO_URL\"\n\n# Download best available quality (4K if available)\nyt-dlp -f \"bestvideo+bestaudio/best\" \"VIDEO_URL\"\n```\n\n### Step 3: Verify Download Quality\n\n```bash\n# Check video resolution\nffprobe -v error -select_streams v:0 -show_entries stream=width,height,codec_name -of default=noprint_wrappers=1 video.mp4\n```\n\nExpected output for 1080p:\n```\ncodec_name=vp9\nwidth=1920\nheight=1080\n```\n\n## Alternative: Browser Cookies Method\n\nIf PO token provider setup is problematic, use browser cookies:\n\n```bash\n# Firefox\nyt-dlp --cookies-from-browser firefox -f \"bestvideo[height<=1080]+bestaudio/best\" \"VIDEO_URL\"\n\n# Chrome\nyt-dlp --cookies-from-browser chrome -f \"bestvideo[height<=1080]+bestaudio/best\" \"VIDEO_URL\"\n```\n\n**Benefits**: Access to age-restricted and members-only content.\n**Requirements**:\n- Must be logged into YouTube in the specified browser.\n- Browser and yt-dlp must use the same IP/proxy.\n- Do not use Android client with cookies (Android client does not support cookies).\n\n## Common Tasks\n\n### Audio-Only Download (Run this yourself)\n\nExtract audio as MP3:\n\n```bash\nyt-dlp -x --audio-format mp3 \"VIDEO_URL\"\n```\n\n### Custom Output Directory (Run this yourself)\n\n```bash\nyt-dlp -P ~/Downloads/YouTube \"VIDEO_URL\"\n```\n\n### Download with Subtitles (Run this yourself)\n\n```bash\nyt-dlp --write-subs --sub-lang en \"VIDEO_URL\"\n```\n\n### Playlist Download (Run this yourself)\n\n```bash\nyt-dlp -f \"bestvideo[height<=1080]+bestaudio/best\" \"PLAYLIST_URL\"\n```\n\n### Convert WebM to MP4 (Run this yourself)\n\nYouTube high-quality downloads often use WebM format (VP9 codec). Convert to MP4 for wider compatibility:\n\n```bash\n# Check if ffmpeg is installed\nwhich ffmpeg || brew install ffmpeg  # macOS\n\n# Convert WebM to MP4 with good quality settings\nffmpeg -i \"video.webm\" -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k \"video.mp4\"\n```\n\n**Parameters explained:**\n- `-c:v libx264`: Use H.264 video codec (widely compatible)\n- `-preset medium`: Balance between encoding speed and file size\n- `-crf 23`: Constant Rate Factor for quality (18-28 range, lower = better quality)\n- `-c:a aac`: Use AAC audio codec\n- `-b:a 128k`: Audio bitrate 128 kbps\n\n**Tip**: Conversion maintains 1080p resolution and provides ~6x encoding speed on modern hardware.\n\n## Troubleshooting Quick Reference\n\n### Only 360p Available (Format 18)\n\n**Cause**: Missing PO token provider or outdated yt-dlp.\n\n**Solution**:\n1. Update yt-dlp: `brew upgrade yt-dlp`\n2. Install PO token provider (see Step 1 above)\n3. Or use browser cookies method\n\n### Sign in to Confirm You‚Äôre Not a Bot\n\n**Cause**: YouTube requires authentication to proceed.\n\n**Solution**:\n1. Request permission and use browser cookies (`--cookies-from-browser chrome`).\n2. Ensure the browser and yt-dlp use the same IP/proxy.\n3. Retry with `web_safari` client if needed.\n\n### Only Images Available / Requested Format Not Available\n\n**Cause**: PO tokens not applied or provider/browser verification failed.\n\n**Solution**:\n1. Verify PO Token provider is running before download.\n2. Keep the browser window open if using WPC.\n3. If cookies are in use, prefer `web_safari` client and retry.\n\n### nsig Extraction Failed\n\n**Symptoms**:\n```\nWARNING: [youtube] nsig extraction failed: Some formats may be missing\n```\n\n**Solution**:\n1. Update yt-dlp to latest version\n2. Install PO token provider\n3. If still failing and PO tokens are disabled, use Android client: `yt-dlp --extractor-args \"youtube:player_client=android\" \"VIDEO_URL\"`\n\n### SSL EOF / Fragment Errors\n\n**Cause**: Proxy or network instability.\n\n**Solution**:\n1. Retry with progressive formats (non-m3u8).\n2. Switch to a more stable proxy/node.\n3. Avoid closing the PO token browser window during download.\n\n### Slow Downloads or Network Errors\n\nFor users in China or behind restrictive proxies:\n- Downloads may be slow due to network conditions\n- Allow sufficient time for completion\n- yt-dlp automatically retries on transient failures\n\n### PO Token Warning (Harmless)\n\n```\nWARNING: android client https formats require a GVS PO Token\n```\n\n**Action**: Ignore if download succeeds. This indicates Android client has limited format access without PO tokens.\n\n## Bundled Script Reference\n\n### scripts/download_video.py\n\nUse this convenience wrapper to auto-start a PO Token provider by default for high-quality downloads. Use it yourself and report results to the user without asking them to run commands.\n\n**Basic usage:**\n```bash\nscripts/download_video.py \"VIDEO_URL\"\n```\n\n**Arguments:**\n- `url` - YouTube video URL (required)\n- `-o, --output-dir` - Output directory\n- `--output-template` - Output filename template (yt-dlp syntax)\n- `-f, --format` - Format specification\n- `-q, --quality` - Quality preset (best, 1080p, 720p, 480p, 360p, worst). Default: best (skipped for `--audio-only`)\n- `-a, --audio-only` - Extract audio as MP3\n- `--subtitles` - Download subtitles if available\n- `--sub-lang` - Subtitle languages (comma-separated, default: en)\n- `--cookies-from-browser` - Load cookies from a browser (e.g., chrome, firefox)\n- `--cookies-file` - Load cookies from a cookies.txt file\n- `--player-client` - Use a specific YouTube player client (e.g., web_safari)\n- `--auto-po-token` - Auto-start PO Token provider (default; uses Docker if available, otherwise switches to browser-based provider)\n- `--no-auto-po-token` - Disable auto PO Token setup\n- `--proxy` - Proxy URL for yt-dlp and the PO Token provider (e.g., http://127.0.0.1:1082)\n- `--wpc-browser-path` - Browser executable path for WPC provider\n- `-F, --list-formats` - List available formats\n- `--merge-format` - Merge output container (e.g., mp4, mkv). Default: mp4\n- `--playlist` - Allow playlist downloads (default: single video only)\n- `--info` - Print title/uploader/duration/thumbnail and exit\n- `--no-android-client` - Disable Android client fallback\n\n**Note**: Use the Android client only when PO tokens are disabled. Keep PO tokens enabled for high quality.\n\n## Quality Expectations\n\n| Setup | 360p | 720p | 1080p | 1440p | 4K |\n|-------|------|------|-------|-------|-----|\n| **Auto PO token (default)** | ‚úì | ‚úì | ‚úì | ‚úì | ‚úì |\n| Android client only | ‚úì | ‚úó | ‚úó | ‚úó | ‚úó |\n| PO token provider (manual) | ‚úì | ‚úì | ‚úì | ‚úì | ‚úì |\n| Browser cookies | ‚úì | ‚úì | ‚úì | ‚úì | ‚úì |\n\n## HLS Stream Downloads (m3u8)\n\nFor streaming platforms like Mux, Vimeo, and other HLS-based services, use ffmpeg as the primary tool. These streams often require authentication headers that yt-dlp may not handle correctly.\n\n### Identifying HLS Streams\n\nHLS streams use `.m3u8` playlist files:\n- Master playlist: Lists multiple quality options\n- Rendition playlist: Contains actual video/audio segment URLs\n\n### Download Workflow\n\n#### Step 1: Obtain the Stream URL\n\nGet the m3u8 URL from the video source. For protected streams:\n1. Open browser DevTools ‚Üí Network tab\n2. Play the video\n3. Filter for \"m3u8\" to find the playlist URLs\n4. Copy the rendition URL (usually contains quality info like \"rendition.m3u8\")\n\n#### Step 2: Identify Required Headers\n\nMany CDNs require authentication headers:\n- **Referer**: Origin website (e.g., `https://maven.com/`)\n- **Origin**: Same as Referer for CORS\n- **User-Agent**: Browser identification\n\nCheck the Network tab to see which headers the browser sends.\n\n#### Step 3: Download with ffmpeg\n\nUse ffmpeg with the `-headers` flag for protected streams:\n\n```bash\nffmpeg -headers \"Referer: https://example.com/\" \\\n  -protocol_whitelist file,http,https,tcp,tls,crypto,httpproxy \\\n  -i \"https://cdn.example.com/path/rendition.m3u8?params\" \\\n  -c copy -bsf:a aac_adtstoasc \\\n  output.mp4\n```\n\n**Key parameters:**\n- `-headers`: Set HTTP headers (critical for authentication)\n- `-protocol_whitelist`: Enable required protocols for HLS\n- `-c copy`: Stream copy (no re-encoding, faster)\n- `-bsf:a aac_adtstoasc`: Fix AAC audio compatibility\n\n**Common header patterns:**\n```bash\n# Single header\n-headers \"Referer: https://example.com/\"\n\n# Multiple headers\n-headers \"Referer: https://example.com/\" \\\n-headers \"User-Agent: Mozilla/5.0...\"\n\n# Alternative syntax\n-headers $'Referer: https://example.com/\\r\\nUser-Agent: Mozilla/5.0...'\n```\n\n### Handling Separate Audio/Video Streams\n\nSome platforms (like Mux) deliver audio and video separately:\n\n1. **Download audio stream:**\n```bash\nffmpeg -headers \"Referer: https://example.com/\" \\\n  -protocol_whitelist file,http,https,tcp,tls,crypto,httpproxy \\\n  -i \"https://cdn.example.com/audio/rendition.m3u8\" \\\n  -c copy audio.m4a\n```\n\n2. **Download video stream:**\n```bash\nffmpeg -headers \"Referer: https://example.com/\" \\\n  -protocol_whitelist file,http,https,tcp,tls,crypto,httpproxy \\\n  -i \"https://cdn.example.com/video/rendition.m3u8\" \\\n  -c copy video.mp4\n```\n\n3. **Merge streams:**\n```bash\nffmpeg -i video.mp4 -i audio.m4a -c copy merged.mp4\n```\n\n### Troubleshooting HLS Downloads\n\n#### 403 Forbidden Errors\n\n**Cause**: Missing or incorrect authentication headers.\n\n**Solution**:\n1. Verify Referer header matches the video source website\n2. Check if additional headers (Origin, User-Agent) are needed\n3. Ensure the m3u8 URL includes all query parameters from browser\n\n#### yt-dlp Stuck on Cookie Extraction\n\n**Symptom**: `Extracting cookies from chrome` hangs indefinitely.\n\n**Solution**: Use ffmpeg directly instead of yt-dlp for HLS streams.\n\n#### Protocol Not Whitelisted\n\n**Error**: `Protocol 'https' not on whitelist 'file,crypto,data'`\n\n**Solution**: Add `-protocol_whitelist file,http,https,tcp,tls,crypto,httpproxy`\n\n#### Empty Segments or No Streams\n\n**Cause**: Expired signatures in the m3u8 URLs.\n\n**Solution**:\n1. Get fresh URLs from browser DevTools\n2. Download immediately after obtaining URLs\n3. Look for rendition URLs with updated signature parameters\n\n### Performance Tips\n\n- HLS downloads typically run at 10-15x realtime speed\n- No re-encoding with `-c copy` (fastest)\n- Monitor download with real-time progress display\n- Use absolute output paths to avoid directory confusion\n\n## Further Reading\n\n- **PO Token Setup**: See `references/po-token-setup.md` for detailed installation and troubleshooting\n- **yt-dlp Documentation**: https://github.com/yt-dlp/yt-dlp\n- **Format Selection Guide**: https://github.com/yt-dlp/yt-dlp#format-selection\n"
      },
      "plugins": [
        {
          "name": "skill-creator",
          "description": "Essential meta-skill for creating effective Claude Code skills with initialization scripts, validation, packaging, marketplace registration, and privacy best practices",
          "source": "./",
          "strict": false,
          "version": "1.4.0",
          "category": "developer-tools",
          "keywords": [
            "skill-creation",
            "claude-code",
            "development",
            "tooling",
            "workflow",
            "meta-skill",
            "essential"
          ],
          "skills": [
            "./skill-creator"
          ],
          "categories": [
            "claude-code",
            "developer-tools",
            "development",
            "essential",
            "meta-skill",
            "skill-creation",
            "tooling",
            "workflow"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install skill-creator@daymade-skills"
          ]
        },
        {
          "name": "github-ops",
          "description": "Comprehensive GitHub operations using gh CLI and GitHub API for pull requests, issues, repositories, workflows, and API interactions",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "github",
            "gh-cli",
            "pull-request",
            "issues",
            "workflows",
            "api"
          ],
          "skills": [
            "./github-ops"
          ],
          "categories": [
            "api",
            "developer-tools",
            "gh-cli",
            "github",
            "issues",
            "pull-request",
            "workflows"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install github-ops@daymade-skills"
          ]
        },
        {
          "name": "markdown-tools",
          "description": "Convert documents (PDFs, Word, PowerPoint) to high-quality markdown with multi-tool orchestration. Supports Quick Mode (fast, single tool) and Heavy Mode (best quality, multi-tool merge with segment-level selection). Features PyMuPDF4LLM for LLM-optimized PDF conversion, pandoc for DOCX/PPTX structure preservation, quality validation with HTML reports, and image extraction with metadata",
          "source": "./",
          "strict": false,
          "version": "1.2.0",
          "category": "document-conversion",
          "keywords": [
            "markdown",
            "pdf",
            "docx",
            "pptx",
            "pymupdf4llm",
            "pandoc",
            "markitdown",
            "heavy-mode",
            "quality-validation"
          ],
          "skills": [
            "./markdown-tools"
          ],
          "categories": [
            "document-conversion",
            "docx",
            "heavy-mode",
            "markdown",
            "markitdown",
            "pandoc",
            "pdf",
            "pptx",
            "pymupdf4llm",
            "quality-validation"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install markdown-tools@daymade-skills"
          ]
        },
        {
          "name": "mermaid-tools",
          "description": "Generate Mermaid diagrams from markdown with automatic PNG/SVG rendering and extraction from documents",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "documentation",
          "keywords": [
            "mermaid",
            "diagrams",
            "visualization",
            "flowchart",
            "sequence"
          ],
          "skills": [
            "./mermaid-tools"
          ],
          "categories": [
            "diagrams",
            "documentation",
            "flowchart",
            "mermaid",
            "sequence",
            "visualization"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install mermaid-tools@daymade-skills"
          ]
        },
        {
          "name": "statusline-generator",
          "description": "Configure Claude Code statuslines with multi-line layouts, cost tracking via ccusage, git status, and customizable colors",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "customization",
          "keywords": [
            "statusline",
            "ccusage",
            "git-status",
            "customization",
            "prompt"
          ],
          "skills": [
            "./statusline-generator"
          ],
          "categories": [
            "ccusage",
            "customization",
            "git-status",
            "prompt",
            "statusline"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install statusline-generator@daymade-skills"
          ]
        },
        {
          "name": "teams-channel-post-writer",
          "description": "Create professional Microsoft Teams channel posts with Adaptive Cards, formatted announcements, and corporate communication standards",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "communication",
          "keywords": [
            "teams",
            "microsoft",
            "adaptive-cards",
            "communication",
            "announcements"
          ],
          "skills": [
            "./teams-channel-post-writer"
          ],
          "categories": [
            "adaptive-cards",
            "announcements",
            "communication",
            "microsoft",
            "teams"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install teams-channel-post-writer@daymade-skills"
          ]
        },
        {
          "name": "repomix-unmixer",
          "description": "Extract files from repomix packaged formats (XML, Markdown, JSON) with automatic format detection and validation",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "utilities",
          "keywords": [
            "repomix",
            "unmix",
            "extract",
            "xml",
            "conversion"
          ],
          "skills": [
            "./repomix-unmixer"
          ],
          "categories": [
            "conversion",
            "extract",
            "repomix",
            "unmix",
            "utilities",
            "xml"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install repomix-unmixer@daymade-skills"
          ]
        },
        {
          "name": "llm-icon-finder",
          "description": "Find and access AI/LLM model brand icons from lobe-icons library in SVG/PNG/WEBP formats",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "assets",
          "keywords": [
            "icons",
            "ai-models",
            "llm",
            "branding",
            "lobe-icons"
          ],
          "skills": [
            "./llm-icon-finder"
          ],
          "categories": [
            "ai-models",
            "assets",
            "branding",
            "icons",
            "llm",
            "lobe-icons"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install llm-icon-finder@daymade-skills"
          ]
        },
        {
          "name": "cli-demo-generator",
          "description": "Generate professional animated CLI demos and terminal recordings with VHS. Supports automated generation, batch processing, and interactive recording for documentation and tutorials",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "cli",
            "demo",
            "terminal",
            "vhs",
            "gif",
            "recording",
            "animation",
            "documentation"
          ],
          "skills": [
            "./cli-demo-generator"
          ],
          "categories": [
            "animation",
            "cli",
            "demo",
            "developer-tools",
            "documentation",
            "gif",
            "recording",
            "terminal",
            "vhs"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install cli-demo-generator@daymade-skills"
          ]
        },
        {
          "name": "cloudflare-troubleshooting",
          "description": "Investigate and resolve Cloudflare configuration issues using API-driven evidence gathering. Use when troubleshooting ERR_TOO_MANY_REDIRECTS, SSL errors, DNS issues, or any Cloudflare-related problems",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "cloudflare",
            "troubleshooting",
            "ssl",
            "dns",
            "api",
            "debugging",
            "devops"
          ],
          "skills": [
            "./cloudflare-troubleshooting"
          ],
          "categories": [
            "api",
            "cloudflare",
            "debugging",
            "developer-tools",
            "devops",
            "dns",
            "ssl",
            "troubleshooting"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install cloudflare-troubleshooting@daymade-skills"
          ]
        },
        {
          "name": "ui-designer",
          "description": "Extract design systems from reference UI images and generate implementation-ready UI design prompts. Use when users provide UI screenshots/mockups and want to create consistent designs",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "design",
          "keywords": [
            "ui",
            "design-system",
            "mockup",
            "screenshot",
            "design-extraction",
            "mvp"
          ],
          "skills": [
            "./ui-designer"
          ],
          "categories": [
            "design",
            "design-extraction",
            "design-system",
            "mockup",
            "mvp",
            "screenshot",
            "ui"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install ui-designer@daymade-skills"
          ]
        },
        {
          "name": "ppt-creator",
          "description": "Create professional slide decks from topics or documents. Generates structured content with data-driven charts, speaker notes, and complete PPTX files. Applies persuasive storytelling principles (Pyramid Principle, assertion-evidence). Supports multiple formats (Marp, PowerPoint). Use for presentations, pitches, slide decks, or keynotes",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "productivity",
          "keywords": [
            "presentation",
            "powerpoint",
            "pptx",
            "slides",
            "marp",
            "charts",
            "data-visualization",
            "pyramid-principle"
          ],
          "skills": [
            "./ppt-creator"
          ],
          "categories": [
            "charts",
            "data-visualization",
            "marp",
            "powerpoint",
            "pptx",
            "presentation",
            "productivity",
            "pyramid-principle",
            "slides"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install ppt-creator@daymade-skills"
          ]
        },
        {
          "name": "youtube-downloader",
          "description": "Download YouTube videos and HLS streams (m3u8) from platforms like Mux, Vimeo, etc. using yt-dlp and ffmpeg. Use when users request downloading videos, extracting audio, handling protected streams with authentication headers, or troubleshooting download issues like nsig extraction failures, 403 errors, or cookie extraction problems",
          "source": "./",
          "strict": false,
          "version": "1.1.0",
          "category": "utilities",
          "keywords": [
            "youtube",
            "yt-dlp",
            "video-download",
            "audio-extraction",
            "mp3",
            "download",
            "hls",
            "m3u8",
            "ffmpeg",
            "streaming",
            "mux",
            "vimeo"
          ],
          "skills": [
            "./youtube-downloader"
          ],
          "categories": [
            "audio-extraction",
            "download",
            "ffmpeg",
            "hls",
            "m3u8",
            "mp3",
            "mux",
            "streaming",
            "utilities",
            "video-download",
            "vimeo",
            "youtube",
            "yt-dlp"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install youtube-downloader@daymade-skills"
          ]
        },
        {
          "name": "repomix-safe-mixer",
          "description": "Safely package codebases with repomix by automatically detecting and removing hardcoded credentials before packing. Use when packaging code for distribution, creating reference packages, or when the user mentions security concerns about sharing code with repomix",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "security",
          "keywords": [
            "repomix",
            "security",
            "credentials",
            "secrets-scanning",
            "safe-packaging",
            "secret-detection",
            "code-security"
          ],
          "skills": [
            "./repomix-safe-mixer"
          ],
          "categories": [
            "code-security",
            "credentials",
            "repomix",
            "safe-packaging",
            "secret-detection",
            "secrets-scanning",
            "security"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install repomix-safe-mixer@daymade-skills"
          ]
        },
        {
          "name": "transcript-fixer",
          "description": "Corrects speech-to-text (ASR/STT) transcription errors in meeting notes, lecture recordings, interviews, and voice memos through dictionary-based rules and AI corrections. Supports Chinese domain names, AI fallback to Claude Code, and iterative dictionary building. Use when users mention transcript correction, ASR errors, speech-to-text mistakes, homophone errors, or working with transcription files",
          "source": "./",
          "strict": false,
          "version": "1.1.0",
          "category": "productivity",
          "keywords": [
            "transcription",
            "asr",
            "stt",
            "speech-to-text",
            "correction",
            "ai",
            "meeting-notes",
            "nlp"
          ],
          "skills": [
            "./transcript-fixer"
          ],
          "categories": [
            "ai",
            "asr",
            "correction",
            "meeting-notes",
            "nlp",
            "productivity",
            "speech-to-text",
            "stt",
            "transcription"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install transcript-fixer@daymade-skills"
          ]
        },
        {
          "name": "video-comparer",
          "description": "Compare two videos and generate interactive HTML reports with quality metrics (PSNR, SSIM) and frame-by-frame visual comparisons. Use when analyzing compression results, evaluating codec performance, or assessing video quality differences",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "media",
          "keywords": [
            "video",
            "comparison",
            "quality-analysis",
            "psnr",
            "ssim",
            "compression",
            "ffmpeg",
            "codec"
          ],
          "skills": [
            "./video-comparer"
          ],
          "categories": [
            "codec",
            "comparison",
            "compression",
            "ffmpeg",
            "media",
            "psnr",
            "quality-analysis",
            "ssim",
            "video"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install video-comparer@daymade-skills"
          ]
        },
        {
          "name": "qa-expert",
          "description": "Comprehensive QA testing infrastructure with autonomous LLM execution, Google Testing Standards (AAA pattern), and OWASP security testing. Use when establishing QA processes, writing test cases, executing test plans, tracking bugs with P0-P4 classification, calculating quality metrics, enforcing quality gates, or preparing third-party QA handoffs. Enables 100x faster test execution via master prompts",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "qa",
            "testing",
            "test-cases",
            "bug-tracking",
            "google-standards",
            "owasp",
            "security",
            "automation",
            "quality-gates",
            "metrics"
          ],
          "skills": [
            "./qa-expert"
          ],
          "categories": [
            "automation",
            "bug-tracking",
            "developer-tools",
            "google-standards",
            "metrics",
            "owasp",
            "qa",
            "quality-gates",
            "security",
            "test-cases",
            "testing"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install qa-expert@daymade-skills"
          ]
        },
        {
          "name": "prompt-optimizer",
          "description": "Transform vague prompts into precise, well-structured specifications using EARS (Easy Approach to Requirements Syntax) methodology. Use when users provide loose requirements, ambiguous feature descriptions, need to enhance prompts for AI-generated code/products/documents, request prompt optimization, or want to improve requirements engineering. Applies domain theories (GTD, BJ Fogg, Gestalt, AIDA, Zero Trust) and structured Role/Skills/Workflows/Examples/Formats framework",
          "source": "./",
          "strict": false,
          "version": "1.1.0",
          "category": "productivity",
          "keywords": [
            "prompt-engineering",
            "ears",
            "requirements",
            "specifications",
            "optimization",
            "domain-theory",
            "prompt-enhancement",
            "ai-prompting"
          ],
          "skills": [
            "./prompt-optimizer"
          ],
          "categories": [
            "ai-prompting",
            "domain-theory",
            "ears",
            "optimization",
            "productivity",
            "prompt-engineering",
            "prompt-enhancement",
            "requirements",
            "specifications"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install prompt-optimizer@daymade-skills"
          ]
        },
        {
          "name": "claude-code-history-files-finder",
          "description": "Find and recover content from Claude Code session history files. Use when searching for deleted files, tracking changes across sessions, analyzing conversation history, or recovering code/documents from previous Claude interactions. Triggers include mentions of session history, recover deleted, find in history, previous conversation, or .claude/projects",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "session-history",
            "recovery",
            "deleted-files",
            "conversation-history",
            "file-tracking",
            "claude-code",
            "history-analysis"
          ],
          "skills": [
            "./claude-code-history-files-finder"
          ],
          "categories": [
            "claude-code",
            "conversation-history",
            "deleted-files",
            "developer-tools",
            "file-tracking",
            "history-analysis",
            "recovery",
            "session-history"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install claude-code-history-files-finder@daymade-skills"
          ]
        },
        {
          "name": "docs-cleaner",
          "description": "Consolidates redundant documentation while preserving all valuable content. Use when cleaning up documentation bloat, merging redundant docs, reducing documentation sprawl, or consolidating multiple files covering the same topic",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "productivity",
          "keywords": [
            "documentation",
            "cleanup",
            "consolidation",
            "redundancy",
            "merge",
            "docs"
          ],
          "skills": [
            "./docs-cleaner"
          ],
          "categories": [
            "cleanup",
            "consolidation",
            "docs",
            "documentation",
            "merge",
            "productivity",
            "redundancy"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install docs-cleaner@daymade-skills"
          ]
        },
        {
          "name": "pdf-creator",
          "description": "Create PDF documents from markdown with proper Chinese font support using weasyprint. Use when converting markdown to PDF, generating formal documents (legal filings, trademark applications, reports), or when Chinese typography is required. Triggers include convert to PDF, generate PDF, markdown to PDF, or printable documents",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "document-conversion",
          "keywords": [
            "pdf",
            "markdown",
            "weasyprint",
            "chinese-fonts",
            "document-generation",
            "legal",
            "reports",
            "typography"
          ],
          "skills": [
            "./pdf-creator"
          ],
          "categories": [
            "chinese-fonts",
            "document-conversion",
            "document-generation",
            "legal",
            "markdown",
            "pdf",
            "reports",
            "typography",
            "weasyprint"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install pdf-creator@daymade-skills"
          ]
        },
        {
          "name": "claude-md-progressive-disclosurer",
          "description": "Optimize user CLAUDE.md files by applying progressive disclosure principles. This skill should be used when users want to reduce CLAUDE.md bloat, move detailed content to references, extract reusable patterns into skills, or improve context efficiency. Triggers include optimize CLAUDE.md, reduce CLAUDE.md size, apply progressive disclosure, or complaints about CLAUDE.md being too long",
          "source": "./",
          "strict": false,
          "version": "1.0.1",
          "category": "productivity",
          "keywords": [
            "claude-md",
            "progressive-disclosure",
            "optimization",
            "context-efficiency",
            "configuration",
            "token-savings"
          ],
          "skills": [
            "./claude-md-progressive-disclosurer"
          ],
          "categories": [
            "claude-md",
            "configuration",
            "context-efficiency",
            "optimization",
            "productivity",
            "progressive-disclosure",
            "token-savings"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install claude-md-progressive-disclosurer@daymade-skills"
          ]
        },
        {
          "name": "skills-search",
          "description": "Search, discover, install, and manage Claude Code skills from the CCPM registry. Use when users want to find skills for specific tasks, install skills by name, list installed skills, get skill details, or manage their Claude Code skill collection. Triggers include find skills, search for plugins, install skill, list installed skills, or any CCPM registry operations",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "ccpm",
            "skills",
            "search",
            "install",
            "registry",
            "plugin",
            "marketplace",
            "discovery",
            "skill-management"
          ],
          "skills": [
            "./skills-search"
          ],
          "categories": [
            "ccpm",
            "developer-tools",
            "discovery",
            "install",
            "marketplace",
            "plugin",
            "registry",
            "search",
            "skill-management",
            "skills"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install skills-search@daymade-skills"
          ]
        },
        {
          "name": "promptfoo-evaluation",
          "description": "Configures and runs LLM evaluation using Promptfoo framework. Use when setting up prompt testing, creating evaluation configs (promptfooconfig.yaml), writing Python custom assertions, implementing llm-rubric for LLM-as-judge, or managing few-shot examples in prompts. Triggers on keywords like promptfoo, eval, LLM evaluation, prompt testing, or model comparison",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "promptfoo",
            "evaluation",
            "llm-testing",
            "prompt-testing",
            "assertions",
            "llm-rubric",
            "few-shot",
            "model-comparison"
          ],
          "skills": [
            "./promptfoo-evaluation"
          ],
          "categories": [
            "assertions",
            "developer-tools",
            "evaluation",
            "few-shot",
            "llm-rubric",
            "llm-testing",
            "model-comparison",
            "prompt-testing",
            "promptfoo"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install promptfoo-evaluation@daymade-skills"
          ]
        },
        {
          "name": "iOS-APP-developer",
          "description": "Develops iOS applications with XcodeGen, SwiftUI, and SPM. Use when configuring XcodeGen project.yml, resolving SPM dependency issues, deploying to devices, handling code signing, debugging camera/AVFoundation, iOS version compatibility issues, or fixing Library not loaded @rpath framework errors. Includes state machine testing patterns for @MainActor classes",
          "source": "./",
          "strict": false,
          "version": "1.1.0",
          "category": "developer-tools",
          "keywords": [
            "ios",
            "xcodegen",
            "swiftui",
            "spm",
            "avfoundation",
            "camera",
            "code-signing",
            "device-deployment",
            "swift",
            "xcode",
            "testing"
          ],
          "skills": [
            "./iOS-APP-developer"
          ],
          "categories": [
            "avfoundation",
            "camera",
            "code-signing",
            "developer-tools",
            "device-deployment",
            "ios",
            "spm",
            "swift",
            "swiftui",
            "testing",
            "xcode",
            "xcodegen"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install iOS-APP-developer@daymade-skills"
          ]
        },
        {
          "name": "fact-checker",
          "description": "Verifies factual claims in documents using web search and official sources, then proposes corrections with user confirmation. Use when the user asks to fact-check, verify information, validate claims, check accuracy, or update outdated information in documents. Supports AI model specs, technical documentation, statistics, and general factual statements",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "productivity",
          "keywords": [
            "fact-checking",
            "verification",
            "accuracy",
            "sources",
            "validation",
            "corrections",
            "web-search"
          ],
          "skills": [
            "./fact-checker"
          ],
          "categories": [
            "accuracy",
            "corrections",
            "fact-checking",
            "productivity",
            "sources",
            "validation",
            "verification",
            "web-search"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install fact-checker@daymade-skills"
          ]
        },
        {
          "name": "twitter-reader",
          "description": "Fetch Twitter/X post content by URL using jina.ai API to bypass JavaScript restrictions. Use when Claude needs to retrieve tweet content including author, timestamp, post text, images, and thread replies. Supports individual posts or batch fetching from x.com or twitter.com URLs",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "utilities",
          "keywords": [
            "twitter",
            "x",
            "social-media",
            "jina",
            "content-fetching",
            "api",
            "scraping",
            "threads"
          ],
          "skills": [
            "./twitter-reader"
          ],
          "categories": [
            "api",
            "content-fetching",
            "jina",
            "scraping",
            "social-media",
            "threads",
            "twitter",
            "utilities",
            "x"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install twitter-reader@daymade-skills"
          ]
        },
        {
          "name": "macos-cleaner",
          "description": "Intelligent macOS disk space analysis and cleanup with safety-first philosophy. Use when users report disk space issues, need to clean their Mac, or want to understand storage consumption. Analyzes system caches, application remnants, large files, and development environments (Docker, Homebrew, npm, pip) with risk categorization (Safe/Caution/Keep) and requires explicit user confirmation before any deletions. Includes Mole visual tool integration for hybrid workflow",
          "source": "./",
          "strict": false,
          "version": "1.1.0",
          "category": "utilities",
          "keywords": [
            "macos",
            "disk-space",
            "cleanup",
            "cache",
            "storage",
            "developer-tools",
            "docker",
            "homebrew",
            "system-maintenance",
            "safety"
          ],
          "skills": [
            "./macos-cleaner"
          ],
          "categories": [
            "cache",
            "cleanup",
            "developer-tools",
            "disk-space",
            "docker",
            "homebrew",
            "macos",
            "safety",
            "storage",
            "system-maintenance",
            "utilities"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install macos-cleaner@daymade-skills"
          ]
        },
        {
          "name": "skill-reviewer",
          "description": "Reviews and improves Claude Code skills against official best practices. Supports three modes - self-review (validate your own skills), external review (evaluate others' skills), and auto-PR (fork, improve, submit). Use when checking skill quality, reviewing skill repositories, or contributing improvements to open-source skills",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "skill-review",
            "best-practices",
            "claude-code",
            "quality-assurance",
            "open-source",
            "contribution",
            "auto-pr"
          ],
          "skills": [
            "./skill-reviewer"
          ],
          "categories": [
            "auto-pr",
            "best-practices",
            "claude-code",
            "contribution",
            "developer-tools",
            "open-source",
            "quality-assurance",
            "skill-review"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install skill-reviewer@daymade-skills"
          ]
        },
        {
          "name": "github-contributor",
          "description": "Strategic guide for becoming an effective GitHub contributor. Covers opportunity discovery, project selection, high-quality PR creation, and reputation building. Use when looking to contribute to open-source projects, building GitHub presence, or learning contribution best practices",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "github",
            "open-source",
            "contribution",
            "pull-request",
            "reputation",
            "contributor",
            "oss"
          ],
          "skills": [
            "./github-contributor"
          ],
          "categories": [
            "contribution",
            "contributor",
            "developer-tools",
            "github",
            "open-source",
            "oss",
            "pull-request",
            "reputation"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install github-contributor@daymade-skills"
          ]
        },
        {
          "name": "i18n-expert",
          "description": "Complete internationalization/localization setup and auditing for UI codebases. Configure i18n frameworks, replace hard-coded strings with translation keys, ensure locale parity between en-US and zh-CN, and validate pluralization and formatting. Use when setting up i18n for React/Next.js/Vue apps, auditing existing implementations, replacing hard-coded strings, ensuring proper error code mapping, or validating pluralization and date/time/number formatting across locales",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "developer-tools",
          "keywords": [
            "i18n",
            "internationalization",
            "localization",
            "translation",
            "react-i18next",
            "next-intl",
            "vue-i18n",
            "locale",
            "multilingual",
            "globalization"
          ],
          "skills": [
            "./i18n-expert"
          ],
          "categories": [
            "developer-tools",
            "globalization",
            "i18n",
            "internationalization",
            "locale",
            "localization",
            "multilingual",
            "next-intl",
            "react-i18next",
            "translation",
            "vue-i18n"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install i18n-expert@daymade-skills"
          ]
        },
        {
          "name": "claude-skills-troubleshooting",
          "description": "Diagnose and resolve Claude Code plugin and skill configuration issues. Debug plugin installation, enablement, and activation problems with systematic workflows. Use when plugins are installed but not showing in available skills list, skills are not activating as expected, troubleshooting enabledPlugins configuration in settings.json, debugging 'plugin not working' or 'skill not showing' issues, or understanding plugin state architecture and lifecycle",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "utilities",
          "keywords": [
            "troubleshooting",
            "debugging",
            "plugins",
            "skills",
            "diagnostics",
            "configuration",
            "enabledPlugins",
            "settings",
            "marketplace"
          ],
          "skills": [
            "./claude-skills-troubleshooting"
          ],
          "categories": [
            "configuration",
            "debugging",
            "diagnostics",
            "enabledplugins",
            "marketplace",
            "plugins",
            "settings",
            "skills",
            "troubleshooting",
            "utilities"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install claude-skills-troubleshooting@daymade-skills"
          ]
        },
        {
          "name": "meeting-minutes-taker",
          "description": "Transform meeting transcripts into high-fidelity, structured meeting minutes with iterative review. Features speaker identification via feature analysis (word count, speaking style, topic focus) with context.md team directory mapping, intelligent file naming from content, integration with markdown-tools and transcript-fixer for pre-processing, evidence-based recording with speaker quotes, Mermaid diagrams for architecture discussions, and multi-turn parallel generation with UNION merge",
          "source": "./",
          "strict": false,
          "version": "1.1.0",
          "category": "productivity",
          "keywords": [
            "meeting",
            "minutes",
            "transcript",
            "notes",
            "speaker-identification",
            "mermaid",
            "quotes",
            "action-items"
          ],
          "skills": [
            "./meeting-minutes-taker"
          ],
          "categories": [
            "action-items",
            "meeting",
            "mermaid",
            "minutes",
            "notes",
            "productivity",
            "quotes",
            "speaker-identification",
            "transcript"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install meeting-minutes-taker@daymade-skills"
          ]
        },
        {
          "name": "deep-research",
          "description": "Generate format-controlled research reports with evidence tracking, citations, and iterative review. Use when users request research reports, literature reviews, market or industry analysis, competitive landscapes, policy or technical briefs, or strict report templates and section formatting",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "documentation",
          "keywords": [
            "research",
            "report",
            "analysis",
            "literature-review",
            "market-research",
            "citations",
            "evidence",
            "deepresearch"
          ],
          "skills": [
            "./deep-research"
          ],
          "categories": [
            "analysis",
            "citations",
            "deepresearch",
            "documentation",
            "evidence",
            "literature-review",
            "market-research",
            "report",
            "research"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install deep-research@daymade-skills"
          ]
        },
        {
          "name": "competitors-analysis",
          "description": "Analyze competitor repositories with evidence-based approach. Use when tracking competitors, creating competitor profiles, or generating competitive analysis. All analysis must be based on actual cloned code, never assumptions. Triggers include analyze competitor, add competitor, competitive analysis, or Á´ûÂìÅÂàÜÊûê",
          "source": "./",
          "strict": false,
          "version": "1.0.0",
          "category": "productivity",
          "keywords": [
            "competitors",
            "competitive-analysis",
            "competitor-tracking",
            "evidence-based",
            "market-research",
            "Á´ûÂìÅÂàÜÊûê",
            "code-analysis"
          ],
          "skills": [
            "./competitors-analysis"
          ],
          "categories": [
            "code-analysis",
            "competitive-analysis",
            "competitor-tracking",
            "competitors",
            "evidence-based",
            "market-research",
            "productivity",
            "Á´ûÂìÅÂàÜÊûê"
          ],
          "install_commands": [
            "/plugin marketplace add daymade/claude-code-skills",
            "/plugin install competitors-analysis@daymade-skills"
          ]
        }
      ]
    }
  ]
}