{
  "author": {
    "id": "Lucklyric",
    "display_name": "Xinyao(Alvin) Sun",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/7803070?u=5f503a0ec8da6ba4dd16b7b9124d94b8d19df3b8&v=4",
    "url": "https://github.com/Lucklyric",
    "bio": "Co-Founder & Chief Scientific Officer @ Matrix Labs Inc. | Adjunct Professor @ Computing Science Department, University of Alberta",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 3,
      "total_commands": 0,
      "total_skills": 2,
      "total_stars": 26,
      "total_forks": 3
    }
  },
  "marketplaces": [
    {
      "name": "cc-dev-tools",
      "version": "2.1.0",
      "description": "Claude Code marketplace containing development tools and AI integrations for advanced workflows",
      "owner_info": {
        "name": "0xasun"
      },
      "keywords": [],
      "repo_full_name": "Lucklyric/cc-dev-tools",
      "repo_url": "https://github.com/Lucklyric/cc-dev-tools",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 26,
        "forks": 3,
        "pushed_at": "2026-01-12T23:35:14Z",
        "created_at": "2025-10-21T01:24:14Z",
        "license": "Apache-2.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1023
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 653
        },
        {
          "path": "plugins/codex/README.md",
          "type": "blob",
          "size": 7149
        },
        {
          "path": "plugins/codex/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/skills/codex",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/skills/codex/SKILL.md",
          "type": "blob",
          "size": 20223
        },
        {
          "path": "plugins/codex/skills/codex/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/skills/codex/references/advanced-patterns.md",
          "type": "blob",
          "size": 11854
        },
        {
          "path": "plugins/codex/skills/codex/references/cli-features.md",
          "type": "blob",
          "size": 3357
        },
        {
          "path": "plugins/codex/skills/codex/references/codex-config.md",
          "type": "blob",
          "size": 4622
        },
        {
          "path": "plugins/codex/skills/codex/references/codex-help.md",
          "type": "blob",
          "size": 12035
        },
        {
          "path": "plugins/codex/skills/codex/references/command-patterns.md",
          "type": "blob",
          "size": 5598
        },
        {
          "path": "plugins/codex/skills/codex/references/examples.md",
          "type": "blob",
          "size": 3421
        },
        {
          "path": "plugins/codex/skills/codex/references/file-context.md",
          "type": "blob",
          "size": 3892
        },
        {
          "path": "plugins/codex/skills/codex/references/session-workflows.md",
          "type": "blob",
          "size": 6661
        },
        {
          "path": "plugins/gemini",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 663
        },
        {
          "path": "plugins/gemini/README.md",
          "type": "blob",
          "size": 7079
        },
        {
          "path": "plugins/gemini/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/skills/gemini",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/skills/gemini/SKILL.md",
          "type": "blob",
          "size": 16926
        },
        {
          "path": "plugins/gemini/skills/gemini/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/skills/gemini/references/command-patterns.md",
          "type": "blob",
          "size": 6961
        },
        {
          "path": "plugins/gemini/skills/gemini/references/file-context.md",
          "type": "blob",
          "size": 3710
        },
        {
          "path": "plugins/gemini/skills/gemini/references/gemini-help.md",
          "type": "blob",
          "size": 7709
        },
        {
          "path": "plugins/gemini/skills/gemini/references/model-selection.md",
          "type": "blob",
          "size": 9577
        },
        {
          "path": "plugins/gemini/skills/gemini/references/session-workflows.md",
          "type": "blob",
          "size": 7383
        },
        {
          "path": "plugins/telegram-notifier",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/telegram-notifier/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/telegram-notifier/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 454
        },
        {
          "path": "plugins/telegram-notifier/README.md",
          "type": "blob",
          "size": 4159
        },
        {
          "path": "plugins/telegram-notifier/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/telegram-notifier/hooks/hooks.json",
          "type": "blob",
          "size": 2254
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"cc-dev-tools\",\n  \"description\": \"Claude Code marketplace containing development tools and AI integrations for advanced workflows\",\n  \"version\": \"2.1.0\",\n  \"owner\": {\n    \"name\": \"0xasun\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"codex\",\n      \"source\": \"./plugins/codex\",\n      \"description\": \"Invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Supports intelligent model selection, session continuation, and safe defaults.\"\n    },\n    {\n      \"name\": \"gemini\",\n      \"source\": \"./plugins/gemini\",\n      \"description\": \"Google Gemini CLI integration for Claude Code. Provides access to Gemini AI models with intelligent model selection, session continuation, and safe defaults.\"\n    },\n    {\n      \"name\": \"telegram-notifier\",\n      \"source\": \"./plugins/telegram-notifier\",\n      \"description\": \"Telegram notifications for Claude Code response completion, subagent tasks, and system notifications. Configurable via environment variables with dry-run mode for testing.\"\n    }\n  ]\n}\n",
        "plugins/codex/.claude-plugin/plugin.json": "{\n  \"name\": \"codex\",\n  \"description\": \"Invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Triggers: 'use codex', 'ask codex', 'run codex', 'codex cli', 'GPT-5 reasoning', 'OpenAI reasoning'. Supports intelligent model selection, session continuation, and safe defaults.\",\n  \"version\": \"2.1.0\",\n  \"author\": {\n    \"name\": \"0xasun\"\n  },\n  \"repository\": \"https://github.com/Lucklyric/cc-dev-tools\",\n  \"homepage\": \"https://github.com/Lucklyric/cc-dev-tools/tree/main/plugins/codex\",\n  \"keywords\": [\"codex\", \"ai\", \"mcp\", \"reasoning\", \"development\", \"gpt-5\", \"openai\"],\n  \"license\": \"Apache-2.0\",\n  \"skills\": [\"./skills/codex\"]\n}\n",
        "plugins/codex/README.md": "# Codex CLI Integration Plugin\n\nOpenAI Codex (GPT-5.2) integration for Claude Code, providing high-reasoning capabilities for complex coding tasks.\n\n## Overview\n\nThis plugin enables Claude Code users to invoke OpenAI's Codex CLI with GPT-5.2 models for advanced reasoning, complex implementations, and architectural design. It provides intelligent model selection, session continuation, and safe defaults for seamless integration.\n\n## Features\n\n- **High-Reasoning Capabilities**: GPT-5.2 with xhigh reasoning effort for maximum capability\n- **Intelligent Model Selection**: Automatic selection between `gpt-5.2-codex` (coding) and `gpt-5.2` (reasoning) models\n- **Session Continuation**: Resume previous conversations with `codex exec resume --last`\n- **Safe Sandbox Defaults**: Read-only for general tasks, workspace-write for code editing\n- **Web Search Integration**: Built-in web search for research and documentation lookup\n- **Non-Interactive Execution**: Optimized for Claude Code's non-terminal bash environment\n\n## Prerequisites\n\n1. **Codex CLI** (v0.72.0 or later for gpt-5.2-codex and xhigh)\n   ```bash\n   # Install Codex CLI (follow OpenAI's installation instructions)\n   codex --version  # Should show v0.72.0+\n   ```\n\n2. **Authentication**\n   ```bash\n   codex login\n   ```\n   Authenticate with your OpenAI account (requires API access)\n\n3. **API Access**\n   - OpenAI API key with GPT-5.2 access\n   - Codex CLI API access enabled\n\n## Installation\n\nThis plugin is part of the cc-dev-tools marketplace. To install:\n\n1. Add the marketplace:\n   ```bash\n   /marketplace add https://github.com/Lucklyric/cc-dev-tools\n   ```\n\n2. Install the plugin:\n   ```bash\n   /plugin install codex@cc-dev-tools\n   ```\n\n3. Restart Claude Code\n\n## Usage\n\n### Basic Invocation\n\nThe skill is automatically invoked when you mention \"Codex\" or request complex coding assistance:\n\n```\nUser: \"Use Codex to design a binary search tree in Rust\"\n```\n\n### Model Selection\n\n**Code Editing Tasks (GPT-5.2-Codex)**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Implement thread-safe queue in Python\"\n```\n\n**General Reasoning Tasks (GPT-5.2)**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Design a distributed cache system\"\n```\n\n### Session Management\n\n```bash\n# Start a new session (automatic on first request)\ncodex exec -m gpt-5.2-codex \"Implement authentication system\"\n\n# Resume most recent session\ncodex exec resume --last\n\n# Continue with new prompt in same session\ncodex exec resume --last \"Now implement the login flow\"\n```\n\n### Advanced Options\n\n**With Web Search**:\n```bash\ncodex exec -m gpt-5.2-codex --enable web_search_request \\\n  -c model_reasoning_effort=xhigh \\\n  \"Research React 19 Server Components\"\n```\n\n**Custom Reasoning Effort**:\n```bash\ncodex exec -m gpt-5.2 -c model_reasoning_effort=medium \\\n  \"Explain quicksort algorithm\"\n```\n\n**Different Sandbox Modes**:\n```bash\n# Read-only (for reasoning tasks)\ncodex exec -m gpt-5.2 -s read-only \"Review code\"\n\n# Workspace-write (for code editing)\ncodex exec -m gpt-5.2-codex -s workspace-write \"Refactor module\"\n\n# Full access (advanced users only)\ncodex exec -m gpt-5.2 -s danger-full-access \"Complex task\"\n```\n\n## Configuration\n\n### Default Settings\n\n| Parameter | Default Value | CLI Flag | Notes |\n|-----------|---------------|----------|-------|\n| Model (coding) | `gpt-5.2-codex` | `-m gpt-5.2-codex` | Optimized for agentic coding (56.4% SWE-Bench Pro) |\n| Model (reasoning) | `gpt-5.2` | `-m gpt-5.2` | High-reasoning general model |\n| Sandbox (coding) | `workspace-write` | `-s workspace-write` | Can edit files |\n| Sandbox (reasoning) | `read-only` | `-s read-only` | Safe for reviews |\n| Reasoning Effort | `xhigh` | `-c model_reasoning_effort=xhigh` | Maximum reasoning capability |\n| Web Search | Enabled when appropriate | `--enable web_search_request` | Context-dependent |\n\n### Reasoning Effort Levels\n\n- **xhigh**: Maximum reasoning (default for all tasks)\n- **high**: High reasoning\n- **medium**: Balanced reasoning and speed\n- **low**: Fast responses, less reasoning\n\n## Model Comparison\n\n| Model | Use Case | Sandbox | Reasoning |\n|-------|----------|---------|-----------|\n| GPT-5.2-Codex | Code editing, implementation, refactoring | workspace-write | xhigh |\n| GPT-5.2 | Architecture, design, reviews, analysis | read-only | xhigh |\n\n### Fallback Chain\n- **Coding**: `gpt-5.2-codex` → `gpt-5.2` → `gpt-5.1-codex-max`\n- **Reasoning effort**: `xhigh` → `high` → `medium`\n\n## Troubleshooting\n\n### CLI Not Installed\n```bash\n# Check if Codex CLI is installed\ncodex --version\n\n# If not found, follow OpenAI's installation guide\n```\n\n### Authentication Required\n```bash\n# Authenticate with OpenAI\ncodex login\n```\n\n### \"stdout is not a terminal\" Error\n\n**Problem**: Using `codex` instead of `codex exec` in non-interactive environment\n\n**Solution**: Always use `codex exec` in Claude Code:\n```bash\n# WRONG\ncodex -m gpt-5.1 \"prompt\"\n\n# CORRECT\ncodex exec -m gpt-5.1 \"prompt\"\n```\n\n### Session Not Found\n```bash\n# Check if there are previous sessions\ncodex exec resume --list\n\n# Start a new session\ncodex exec -m gpt-5.1 \"New task\"\n```\n\n### API Rate Limits\n\nIf you encounter rate limits, check your OpenAI API usage dashboard. The plugin uses high-reasoning models which may have different rate limits.\n\n## Documentation\n\n- **SKILL.md**: Complete skill definition and usage guide\n- **references/codex-help.md**: Full CLI reference\n- **references/command-patterns.md**: Common command templates\n- **references/session-workflows.md**: Multi-turn conversation patterns\n- **references/advanced-patterns.md**: Advanced usage patterns\n- **references/codex-config.md**: Configuration options\n\n## Version Compatibility\n\n- **Minimum**: Codex CLI v0.72.0 (for gpt-5.2-codex and xhigh)\n- **Recommended**: Latest stable version\n- **Models**: GPT-5.2-Codex (coding), GPT-5.2 (reasoning)\n\n## When to Use Codex vs Gemini vs Claude\n\n**Use Codex when:**\n- You need GPT-5.2's high-reasoning capabilities with xhigh effort\n- Complex coding tasks require gpt-5.2-codex (optimized for agentic coding)\n- Architecture and system design with maximum reasoning\n- Code reviews requiring deep analysis\n\n**Use Gemini when:**\n- You need Google's latest AI models\n- Research with web search is important\n- Free tier OAuth access (Codex requires API key)\n- Creative or general reasoning tasks\n\n**Use Claude (native) when:**\n- Simple queries within Claude Code's capabilities\n- No external AI needed\n- Quick responses preferred\n\n## Rate Limits & Costs\n\n**Note**: Codex CLI uses OpenAI's API, which may have associated costs:\n- GPT-5.2 and GPT-5.2-Codex usage is billed per token\n- xhigh reasoning effort may consume more tokens\n- Check OpenAI's pricing for current rates\n\n## Contributing\n\nThis plugin follows the cc-dev-tools marketplace structure:\n- Plugin root: `plugins/codex/`\n- Metadata: `.claude-plugin/plugin.json`\n- Skill definition: `skills/codex/SKILL.md`\n- References: `skills/codex/references/`\n\n## License\n\nApache-2.0\n\n## Author\n\n0xasun\n\n## Repository\n\nhttps://github.com/Lucklyric/cc-dev-tools\n\n## Version\n\n2.1.0\n",
        "plugins/codex/skills/codex/SKILL.md": "---\nname: codex\nversion: 2.1.0\ndescription: This skill should be used when the user wants to invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Trigger phrases include \"use codex\", \"ask codex\", \"run codex\", \"call codex\", \"codex cli\", \"GPT-5 reasoning\", \"OpenAI reasoning\", or when users request complex implementation challenges, advanced reasoning, architecture design, or high-reasoning model assistance. Automatically triggers on codex-related requests and supports session continuation for iterative development.\n---\n\n# Codex: High-Reasoning AI Assistant for Claude Code\n\n---\n\n## DEFAULT MODEL: Task-Based Model Selection with Read-Only Default\n\n**Codex uses task-based model selection. Sandbox is `read-only` by default - only use `workspace-write` when user explicitly requests file editing.**\n\n| Task Type | Model | Sandbox (default) | Sandbox (explicit edit) |\n|-----------|-------|-------------------|------------------------|\n| Code-related tasks | `gpt-5.2-codex` | read-only | workspace-write |\n| General tasks | `gpt-5.2` | read-only | workspace-write |\n\n- **Code-related tasks**: Use `gpt-5.2-codex` - optimized for agentic coding (56.4% SWE-Bench Pro)\n- **General tasks**: Use `gpt-5.2` - high-reasoning general model\n- **Sandbox default**: Always `read-only` unless user explicitly requests editing\n- **Explicit editing**: Only when user says \"edit\", \"modify\", \"write changes\", etc., use `workspace-write`\n- Always use `-c model_reasoning_effort=xhigh` for maximum capability\n\n```bash\n# Code task (read-only default)\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"analyze this function implementation\"\n\n# General task (read-only default)\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"explain this architecture\"\n\n# Code task with explicit edit request\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"edit this file to add the feature\"\n\n# General task with explicit edit request\ncodex exec -m gpt-5.2 -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"modify the documentation file\"\n```\n\n### Model Fallback Chain\n\nIf the primary model is unavailable, fallback gracefully:\n1. **Code tasks**: `gpt-5.2-codex` → `gpt-5.2` → `gpt-5.1-codex-max`\n2. **General tasks**: `gpt-5.2` → `gpt-5.1` → `gpt-5.1-codex-max`\n3. **Reasoning effort**: `xhigh` → `high` → `medium`\n\n---\n\n## CRITICAL: Always Use `codex exec`\n\n**MUST USE**: `codex exec` for ALL Codex CLI invocations in Claude Code.\n\n**NEVER USE**: `codex` (interactive mode) - will fail with \"stdout is not a terminal\"\n**ALWAYS USE**: `codex exec` (non-interactive mode)\n\n**Examples:**\n- `codex exec -m gpt-5.2 \"prompt\"` (CORRECT)\n- `codex -m gpt-5.2 \"prompt\"` (WRONG - will fail)\n- `codex exec resume --last` (CORRECT)\n- `codex resume --last` (WRONG - will fail)\n\n**Why?** Claude Code's bash environment is non-terminal/non-interactive. Only `codex exec` works in this environment.\n\n---\n\n## IMPORTANT: Interactive vs Exec Mode Flags\n\n**Some Codex CLI flags are ONLY available in interactive mode, NOT in `codex exec`.**\n\n| Flag | Interactive `codex` | `codex exec` | Alternative for exec |\n|------|---------------------|--------------|---------------------|\n| `--search` | ✅ Available | ❌ NOT available | `--enable web_search_request` |\n| `-a/--ask-for-approval` | ✅ Available | ❌ NOT available | `--full-auto` or `-c approval_policy=...` |\n| `--add-dir` | ✅ Available | ✅ Available | N/A |\n| `--full-auto` | ✅ Available | ✅ Available | N/A |\n\n**For web search in exec mode**:\n```bash\n# CORRECT - works in codex exec\ncodex exec --enable web_search_request \"research topic\"\n\n# WRONG - --search only works in interactive mode\ncodex --search \"research topic\"\n```\n\n**For approval control in exec mode**:\n```bash\n# CORRECT - works in codex exec\ncodex exec --full-auto \"task\"\ncodex exec -c approval_policy=on-request \"task\"\n\n# WRONG - -a only works in interactive mode\ncodex -a on-request \"task\"\n```\n\n---\n\n## Trigger Examples\n\nThis skill activates when users say phrases like:\n- \"Use codex to analyze this architecture\"\n- \"Ask codex about this design decision\"\n- \"Run codex on this problem\"\n- \"Call codex for help with this implementation\"\n- \"I need GPT-5 reasoning for this task\"\n- \"Get OpenAI's high-reasoning model on this\"\n- \"Continue with codex\" or \"Resume the codex session\"\n- \"Codex, help me with...\" or simply \"Codex\"\n\n## When to Use This Skill\n\nThis skill should be invoked when:\n- User explicitly mentions \"Codex\" or requests Codex assistance\n- User needs help with complex coding tasks, algorithms, or architecture\n- User requests \"high reasoning\" or \"advanced implementation\" help\n- User needs complex problem-solving or architectural design\n- User wants to continue a previous Codex conversation\n\n## How It Works\n\n### Detecting New Codex Requests\n\nWhen a user makes a request, first determine the task type (code vs general), then determine sandbox based on explicit edit request:\n\n**Step 1: Determine Task Type (Model Selection)**\n- **Code-related tasks**: Use `gpt-5.2-codex` - for implementation, refactoring, code analysis, debugging, etc.\n- **General tasks**: Use `gpt-5.2` - for architecture design, explanations, reviews, documentation, etc.\n\n**Step 2: Determine Sandbox (Edit Permission)**\n- **Default**: `read-only` - safe for all tasks unless user explicitly requests editing\n- **Explicit edit request**: `workspace-write` - ONLY when user explicitly says to edit/modify/write files\n\n**Code-related task examples**:\n- Read-only: \"Analyze this function\", \"Review this implementation\", \"Debug this code\"\n- With editing: \"Edit this file to fix the bug\", \"Modify the function\", \"Refactor and save\"\n\n**General task examples**:\n- Read-only: \"Design a queue data structure\", \"Explain this algorithm\", \"Review the architecture\"\n- With editing: \"Update the documentation file\", \"Modify the README\"\n\n**⚠️ Important**: The key distinction for sandbox is whether the user explicitly asks for file modifications. Use `workspace-write` ONLY when user says \"edit\", \"modify\", \"write changes\", \"save\", etc.\n\n### Bash CLI Command Structure\n\n**IMPORTANT**: Always use `codex exec` for non-interactive execution. Claude Code's bash environment is non-terminal, so the interactive `codex` command will fail with \"stdout is not a terminal\" error.\n\n#### Code Task (Read-Only Default)\n\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<code-related prompt>\"\n```\n\n#### General Task (Read-Only Default)\n\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<general prompt>\"\n```\n\n#### Code Task with Explicit Edit Request\n\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<edit code prompt>\"\n```\n\n#### General Task with Explicit Edit Request\n\n```bash\ncodex exec -m gpt-5.2 -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<edit general files prompt>\"\n```\n\n**Why `codex exec`?**\n- Non-interactive mode required for automation and Claude Code integration\n- Produces clean output suitable for parsing\n- Works in non-TTY environments (like Claude Code's bash)\n\n### Model Selection Logic\n\n**Step 1: Choose Model Based on Task Type**\n\n**Use `gpt-5.2-codex` for code-related tasks:**\n- Implementation, refactoring, code analysis\n- Debugging, fixing bugs, optimization\n- Any task involving code understanding or modification\n\n**Use `gpt-5.2` for general tasks:**\n- Architecture and system design\n- Explanations, documentation, reviews\n- Planning, strategy, general reasoning\n\n**Step 2: Choose Sandbox Based on Edit Intent**\n\n**Use `read-only` (DEFAULT):**\n- Analysis, review, explanation tasks\n- ANY task where user does NOT explicitly request file editing\n\n**Use `workspace-write` (ONLY when explicitly requested):**\n- User explicitly says \"edit this file\", \"modify the code\", \"write changes\"\n- User explicitly asks to \"make edits\" or \"save the changes\"\n- User explicitly requests \"refactor and save\" or \"implement and write\"\n\n**Fallback Models**: `gpt-5.1-codex-max` and `gpt-5.1` are available if primary models are unavailable. See fallback chain in DEFAULT MODEL section.\n\n### Default Configuration\n\nAll Codex invocations use these defaults unless user specifies otherwise:\n\n| Parameter | Default Value | CLI Flag | Notes |\n|-----------|---------------|----------|-------|\n| Model (code tasks) | `gpt-5.2-codex` | `-m gpt-5.2-codex` | For code-related tasks |\n| Model (general tasks) | `gpt-5.2` | `-m gpt-5.2` | For general tasks |\n| Sandbox (default) | `read-only` | `-s read-only` | Safe default for ALL tasks |\n| Sandbox (explicit edit) | `workspace-write` | `-s workspace-write` | Only when user explicitly requests editing |\n| Reasoning Effort | `xhigh` | `-c model_reasoning_effort=xhigh` | Maximum reasoning capability |\n| Verbosity | `medium` | `-c model_verbosity=medium` | Balanced output detail |\n| Web Search | `enabled` | `--enable web_search_request` | Access to up-to-date information |\n\n### CLI Flags Reference\n\n**Codex CLI Version**: 0.80.0+ (requires 0.80.0+ for gpt-5.2-codex and xhigh)\n\n| Flag | Values | Description |\n|------|--------|-------------|\n| `-m, --model` | `gpt-5.2-codex`, `gpt-5.2`, `gpt-5.1-codex-max`, `gpt-5.1` | Model selection |\n| `-s, --sandbox` | `read-only`, `workspace-write`, `danger-full-access` | Sandbox mode |\n| `-c, --config` | `key=value` | Config overrides (e.g., `model_reasoning_effort=high`) |\n| `-C, --cd` | directory path | Working directory |\n| `-p, --profile` | profile name | Use config profile |\n| `--enable` | feature name | Enable a feature (e.g., `web_search_request`) |\n| `--disable` | feature name | Disable a feature |\n| `-i, --image` | file path(s) | Attach image(s) to initial prompt |\n| `--add-dir` | directory path | Additional writable directory (repeatable) |\n| `--full-auto` | flag | Convenience for workspace-write sandbox with on-request approval |\n| `--oss` | flag | Use local open source model provider |\n| `--local-provider` | `lmstudio`, `ollama` | Specify local provider (with --oss) |\n| `--skip-git-repo-check` | flag | Allow running outside Git repository |\n| `--output-schema` | file path | JSON Schema file for response shape |\n| `--color` | `always`, `never`, `auto` | Color settings for output |\n| `--json` | flag | Print events as JSONL |\n| `-o, --output-last-message` | file path | Save last message to file |\n| `--dangerously-bypass-approvals-and-sandbox` | flag | Skip confirmations (DANGEROUS) |\n\n### Configuration Parameters\n\nPass these as `-c key=value`:\n\n- `model_reasoning_effort`: `minimal`, `low`, `medium`, `high`, `xhigh`\n  - **CLI default**: `high` - The Codex CLI defaults to high reasoning\n  - **Skill default**: `xhigh` - This skill explicitly uses xhigh for maximum capability\n  - **`xhigh`**: Extra-high reasoning for maximum capability (supported by gpt-5.2 and gpt-5.1-codex-max)\n  - Use `xhigh` for complex architectural refactoring, long-horizon tasks, or when quality is more important than speed\n- `model_verbosity`: `low`, `medium`, `high` (default: `medium`)\n- `model_reasoning_summary`: `auto`, `concise`, `detailed`, `none` (default: `auto`)\n- `sandbox_workspace_write.writable_roots`: JSON array of additional writable directories (e.g., `[\"/path1\",\"/path2\"]`)\n- `approval_policy`: `untrusted`, `on-failure`, `on-request`, `never` (approval behavior)\n\n**Additional Writable Directories**:\n\nUse `--add-dir` flag (preferred) or config:\n```bash\n# Using --add-dir for multiple directories\ncodex exec --add-dir /path1 --add-dir /path2 \"task\"\n\n# Alternative - config approach\ncodex exec -c 'sandbox_workspace_write.writable_roots=[\"/path1\",\"/path2\"]' \"task\"\n```\n\n### Model Selection Guide\n\n**Available Models**:\n- `gpt-5.2-codex` - Code tasks (implementation, refactoring, debugging)\n- `gpt-5.2` - General tasks (architecture, reviews, explanations)\n\n**Default**: `gpt-5.2-codex` for code tasks, `gpt-5.2` for general tasks with `xhigh` reasoning effort.\n\n## Session Continuation\n\n### Detecting Continuation Requests\n\nWhen user indicates they want to continue a previous Codex conversation:\n- Keywords: \"continue\", \"resume\", \"keep going\", \"add to that\"\n- Follow-up context referencing previous Codex work\n- Explicit request like \"continue where we left off\"\n\n### Resuming Sessions\n\nFor continuation requests, use the `codex resume` command:\n\n#### Resume Most Recent Session (Recommended)\n\n```bash\ncodex exec resume --last\n```\n\nThis automatically continues the most recent Codex session with all previous context maintained.\n\n#### Resume Specific Session\n\n```bash\ncodex exec resume <session-id>\n```\n\nResume a specific session by providing its UUID. Get session IDs from previous Codex output or by running `codex exec resume --last` to see the most recent session.\n\n**Note**: The interactive session picker (`codex resume` without arguments) is NOT available in non-interactive/Claude Code environments. Always use `--last` or provide explicit session ID.\n\n### Decision Logic: New vs. Continue\n\n**Use `codex exec -m ... \"<prompt>\"`** when:\n- User makes a new, independent request\n- No reference to previous Codex work\n- User explicitly wants a \"fresh\" or \"new\" session\n\n**Use `codex exec resume --last`** when:\n- User indicates continuation (\"continue\", \"resume\", \"add to that\")\n- Follow-up question building on previous Codex conversation\n- Iterative development on same task\n\n### Session History Management\n\n- Codex CLI automatically saves session history\n- No manual session ID tracking needed\n- Sessions persist across Claude Code restarts\n- Use `codex exec resume --last` to access most recent session\n- Use `codex exec resume <session-id>` for specific sessions\n\n## Error Handling\n\n### Simple Error Response Strategy\n\nWhen errors occur, return clear, actionable messages without complex diagnostics:\n\n**Error Message Format:**\n```\nError: [Clear description of what went wrong]\n\nTo fix: [Concrete remediation action]\n\n[Optional: Specific command example]\n```\n\n### Common Errors\n\n#### Command Not Found\n\n```\nError: Codex CLI not found\n\nTo fix: Install Codex CLI and ensure it's available in your PATH\n\nCheck installation: codex --version\n```\n\n#### Authentication Required\n\n```\nError: Not authenticated with Codex\n\nTo fix: Run 'codex login' to authenticate\n\nAfter authentication, try your request again.\n```\n\n#### Invalid Configuration\n\n```\nError: Invalid model specified\n\nTo fix:\n- For coding tasks: Use 'gpt-5.2-codex' with workspace-write sandbox\n- For reasoning tasks: Use 'gpt-5.2' with read-only sandbox\n\nExample (coding): codex exec -m gpt-5.2-codex -s workspace-write -c model_reasoning_effort=xhigh \"implement feature\"\nExample (reasoning): codex exec -m gpt-5.2 -s read-only -c model_reasoning_effort=xhigh \"explain architecture\"\n```\n\n### Troubleshooting\n\n**First Steps for Any Issues:**\n1. Check Codex CLI built-in help: `codex --help`, `codex exec --help`, `codex exec resume --help`\n2. Consult official documentation: [https://github.com/openai/codex/tree/main/docs](https://github.com/openai/codex/tree/main/docs)\n3. Verify skill resources in `references/` directory\n\n**Skill not being invoked?**\n- Check that request matches trigger keywords (Codex, complex coding, high reasoning, etc.)\n- Explicitly mention \"Codex\" in your request\n- Try: \"Use Codex to help me with...\"\n\n**Session not resuming?**\n- Verify you have a previous Codex session (check command output for session IDs)\n- Try: `codex exec resume --last` to resume most recent session\n- If no history exists, start a new session first\n\n**\"stdout is not a terminal\" error?**\n- Always use `codex exec` instead of plain `codex` in Claude Code\n- Claude Code's bash environment is non-interactive/non-terminal\n\n**Errors during execution?**\n- Codex CLI errors are passed through directly\n- Check Codex CLI logs for detailed diagnostics\n- Verify working directory permissions if using workspace-write\n- Check official Codex docs for latest updates and known issues\n\n## Examples\n\n### Code Analysis (Read-Only)\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Analyze this function implementation\"\n```\n\n### Code Editing (Explicit Request)\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Edit this file to implement the feature\"\n```\n\n### Session Continuation\n```bash\ncodex exec resume --last\n```\n\n**See**: `references/examples.md` for more examples including web search, file context, and code review patterns.\n\n---\n\n## Code Review Subcommand (v0.71.0+)\n\nThe `codex review` subcommand provides non-interactive code review capabilities:\n\n```bash\n# Review uncommitted changes (staged, unstaged, untracked)\ncodex review --uncommitted\n\n# Review changes against a base branch\ncodex review --base main\n\n# Review a specific commit\ncodex review --commit abc123\n\n# Review with custom instructions\ncodex review --uncommitted \"Focus on security vulnerabilities\"\n\n# Non-interactive via exec\ncodex exec review --uncommitted\n```\n\n**Review Options**:\n| Flag | Description |\n|------|-------------|\n| `--uncommitted` | Review staged, unstaged, and untracked changes |\n| `--base <BRANCH>` | Review changes against the given base branch |\n| `--commit <SHA>` | Review the changes introduced by a commit |\n| `--title <TITLE>` | Optional commit title for review summary |\n\n---\n\n## CLI Features Reference\n\nFor detailed CLI feature documentation, see `references/cli-features.md`.\n\n**Quick Reference** - Common features:\n- `--enable web_search_request` - Enable web search\n- `-i, --image` - Attach images to prompts\n- `--add-dir` - Add writable directories\n- `--full-auto` - Low-friction workspace-write mode\n- `--json` - JSONL output for programmatic processing\n\n---\n\n## File Context Passing\n\n**IMPORTANT**: Pass file paths to Codex CLI instead of embedding file content in prompts. This enables Codex to read files autonomously.\n\n**Quick reference**:\n- Use `-C /path` to set working directory\n- Use `--add-dir /path` for additional directories\n- Use `@path/to/file` syntax for explicit file references\n\n```bash\n# Example: analyze file with explicit @ syntax\ncodex exec -m gpt-5.2-codex -s read-only \\\n  \"Analyze @src/auth.ts and compare with @src/session.ts\"\n\n# Example: multi-directory analysis\ncodex exec -m gpt-5.2-codex -s read-only \\\n  --add-dir /shared/libs \\\n  \"Review how auth module uses shared utilities\"\n```\n\n**See**: `references/file-context.md` for complete file context documentation.\n\n---\n\n## Best Practices\n\n### 1. Use Descriptive Requests\n\n**Good**: \"Help me implement a thread-safe queue with priority support in Python\"\n**Vague**: \"Code help\"\n\nClear, specific requests get better results from high-reasoning models.\n\n### 2. Indicate Continuation Clearly\n\n**Good**: \"Continue with that queue implementation - add unit tests\"\n**Unclear**: \"Add tests\" (might start new session)\n\nExplicit continuation keywords help the skill choose the right command.\n\n### 3. Specify Permissions When Needed\n\n**Good**: \"Refactor this code (allow file writing)\"\n**Risky**: Assuming permissions without specifying\n\nMake your intent clear when you need workspace-write permissions.\n\n### 4. Leverage High Reasoning\n\nThe skill defaults to high reasoning effort - perfect for:\n- Complex algorithms\n- Architecture design\n- Performance optimization\n- Security reviews\n\n## Reference Documentation\n\nFor detailed information, consult these reference files:\n\n### Core References\n- **`references/file-context.md`** - File and directory context passing guide\n- **`references/examples.md`** - Complete command examples by use case\n- **`references/cli-features.md`** - Feature flags and CLI options\n\n### Workflow References\n- **`references/command-patterns.md`** - Common codex exec usage patterns\n- **`references/session-workflows.md`** - Session continuation and resume workflows\n- **`references/advanced-patterns.md`** - Complex configuration and flag combinations\n\n### CLI References\n- **`references/codex-help.md`** - Codex CLI command reference\n- **`references/codex-config.md`** - Full configuration options\n",
        "plugins/codex/skills/codex/references/advanced-patterns.md": "# Advanced Configuration Examples\n\n---\n\n## ⚠️ CRITICAL: Always Use `codex exec`\n\n**ALL commands in this document use `codex exec` - this is mandatory in Claude Code.**\n\n❌ **NEVER**: `codex -m ...` or `codex --flag ...` (will fail with \"stdout is not a terminal\")\n✅ **ALWAYS**: `codex exec -m ...` or `codex exec --flag ...` (correct non-interactive mode)\n\nClaude Code's bash environment is non-terminal. Plain `codex` commands will NOT work.\n\n---\n\n## Custom Model Selection\n\n### Example 1: General Reasoning Task\n\n**User Request**: \"Review this code for architecture issues\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Review this code for architecture issues\"\n```\n\n**Why**: Architectural review is a reasoning task - use gpt-5.2 with read-only sandbox.\n\n---\n\n### Example 2: Code Editing Task\n\n**User Request**: \"Implement the authentication module\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Implement the authentication module\"\n```\n\n**Why**: Implementation requires file writing and code generation - use gpt-5.2-codex (56.4% SWE-Bench Pro).\n\n---\n\n## Workspace Write Permission\n\n### Example 3: Allow File Modifications\n\n**User Request**: \"Have Codex refactor this codebase (allow file writing)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Refactor this codebase for better maintainability\"\n```\n\n**Permission**: `workspace-write` allows Codex to modify files directly.\n\n⚠️ **Warning**: Only use `workspace-write` when you trust the operation and want file modifications.\n\n---\n\n### Example 4: Read-Only Code Review\n\n**User Request**: \"Review this code for security vulnerabilities (read-only)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Review this code for security vulnerabilities\"\n```\n\n**Permission**: `read-only` prevents file modifications - safer for review tasks.\n\n---\n\n## Web Search Integration\n\n### Example 5: Research Latest Patterns\n\n**User Request**: \"Research latest Python async patterns and implement them (enable web search)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"Research latest Python async patterns and implement them\"\n```\n\n**Feature**: `--enable web_search_request` enables web search for up-to-date information.\n\n---\n\n### Example 6: Security Best Practices Research\n\n**User Request**: \"Use web search to find latest JWT security best practices, then review this auth code\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"Find latest JWT security best practices and review this auth code\"\n```\n\n---\n\n## Reasoning Effort Control\n\n### Example 7: Maximum Reasoning for Complex Algorithm\n\n**User Request**: \"Design an optimal algorithm for distributed consensus (maximum reasoning)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Design an optimal algorithm for distributed consensus\"\n```\n\n**Default**: Already uses `xhigh` reasoning effort.\n\n---\n\n### Example 8: Quick Code Review (Lower Reasoning)\n\n**User Request**: \"Quick syntax check on this code (low reasoning)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=low \\\n  \"Quick syntax check on this code\"\n```\n\n**Use Case**: Fast turnaround for simple tasks. Override xhigh when speed matters more than depth.\n\n---\n\n## Verbosity Control\n\n### Example 9: Detailed Explanation\n\n**User Request**: \"Explain this algorithm in detail (high verbosity)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  -c model_verbosity=high \\\n  \"Explain this algorithm in detail\"\n```\n\n**Output**: Comprehensive, detailed explanation.\n\n---\n\n### Example 10: Concise Summary\n\n**User Request**: \"Briefly review this code (low verbosity)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  -c model_verbosity=low \\\n  \"Review this code\"\n```\n\n**Output**: Concise, focused feedback.\n\n---\n\n## Working Directory Control\n\n### Example 11: Specific Project Directory\n\n**User Request**: \"Work in the backend directory and review the API code\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  -C ./backend \\\n  \"Review the API code\"\n```\n\n**Feature**: `-C` flag sets working directory for Codex.\n\n---\n\n## Approval Policy\n\n### Example 12: Request Approval for Shell Commands\n\n**User Request**: \"Implement the build script (ask before running commands)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  -a on-request \\\n  \"Implement the build script\"\n```\n\n**Safety**: `-a on-request` requires approval before executing shell commands.\n\n---\n\n## Combined Advanced Configuration\n\n### Example 13: Full-Featured Request\n\n**User Request**: \"Use web search to find latest security practices, review my auth module in detail with high reasoning, allow file fixes if needed (ask for approval)\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  -c model_verbosity=high \\\n  -a on-request \\\n  --enable web_search_request \\\n  \"Find latest security practices, review my auth module in detail, and fix issues\"\n```\n\n**Features**:\n- Web search enabled (`--enable web_search_request`)\n- Maximum reasoning (`model_reasoning_effort=xhigh`)\n- Detailed output (`model_verbosity=high`)\n- File writing allowed (`workspace-write`)\n- Requires approval for commands (`-a on-request`)\n\n---\n\n## Decision Tree: When to Use GPT-5.2 vs GPT-5.2-Codex\n\n### Use GPT-5.2 (General Reasoning) For:\n\n```\n┌─────────────────────────────────────┐\n│     Architecture & Design           │\n│  - System architecture              │\n│  - API design                       │\n│  - Data structure design            │\n│  - Algorithm analysis               │\n├─────────────────────────────────────┤\n│     Analysis & Review               │\n│  - Code reviews                     │\n│  - Security audits                  │\n│  - Performance analysis             │\n│  - Quality assessment               │\n├─────────────────────────────────────┤\n│     Explanation & Learning          │\n│  - Concept explanations             │\n│  - Documentation review             │\n│  - Trade-off analysis               │\n│  - Best practices guidance          │\n└─────────────────────────────────────┘\n```\n\n### Use GPT-5.2-Codex (Agentic Coding) For:\n\n```\n┌─────────────────────────────────────┐\n│     Code Editing                    │\n│  - Modify existing files            │\n│  - Implement features               │\n│  - Refactoring                      │\n│  - Bug fixes                        │\n├─────────────────────────────────────┤\n│     Code Generation                 │\n│  - Write new code                   │\n│  - Generate boilerplate             │\n│  - Create test files                │\n│  - Scaffold projects                │\n├─────────────────────────────────────┤\n│     Long-Horizon Tasks              │\n│  - Multi-file changes               │\n│  - Complex refactoring              │\n│  - Migration scripts                │\n│  - Architectural overhauls          │\n└─────────────────────────────────────┘\n```\n\n**Note**: gpt-5.2-codex has native context compaction for long-horizon work (56.4% SWE-Bench Pro).\n\n---\n\n## Sandbox Mode Decision Matrix\n\n| Task | Recommended Sandbox | Rationale |\n|------|---------------------|-----------|\n| Code review | `read-only` | No modifications needed |\n| Architecture design | `read-only` | Planning phase only |\n| Security audit | `read-only` | Analysis without changes |\n| Implement feature | `workspace-write` | Requires file modifications |\n| Refactor code | `workspace-write` | Must edit existing files |\n| Generate new files | `workspace-write` | Creates new files |\n| Bug fix | `workspace-write` | Edits source files |\n\n---\n\n## Configuration Profiles\n\n### Create a Config Profile\n\nYou can create reusable configuration profiles in `~/.codex/config.toml`:\n\n```toml\n[profiles.review]\nmodel = \"gpt-5.2\"\nsandbox = \"read-only\"\nmodel_reasoning_effort = \"xhigh\"\nmodel_verbosity = \"medium\"\n\n[profiles.implement]\nmodel = \"gpt-5.2-codex\"\nsandbox = \"workspace-write\"\nmodel_reasoning_effort = \"xhigh\"\napproval_policy = \"on-request\"\n```\n\n### Use Profile in Skill\n\n**User Request**: \"Use the review profile to analyze this code\"\n\n**Skill Executes**:\n```bash\ncodex exec -p review \"Analyze this code\"\n```\n\n**Result**: Uses all settings from `[profiles.review]`.\n\n---\n\n## Best Practices\n\n### 1. Match Model to Task Type\n\n- **Thinking/Design** → GPT-5.2 (general reasoning)\n- **Doing/Coding** → GPT-5.2-Codex (agentic coding)\n\n### 2. Use Safe Defaults, Override Intentionally\n\n- Default to `read-only` unless file writing is explicitly needed\n- Default to `xhigh` reasoning for all tasks (maximum capability)\n- Reduce reasoning effort only for simple, quick tasks\n\n### 3. Combine Web Search with xhigh Reasoning\n\nFor best results researching current practices:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  --enable web_search_request \\\n  -c model_reasoning_effort=xhigh \\\n  \"Research latest distributed systems patterns\"\n```\n\n### 4. Request Approval for Risky Operations\n\nUse `-a on-request` when:\n- Working with production code\n- Running shell commands\n- Making broad changes\n\n---\n\n## Common Patterns\n\n### Pattern 1: Research → Design → Implement\n\n**Phase 1 - Research** (GPT-5.2 + web search):\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  --enable web_search_request \\\n  -c model_reasoning_effort=xhigh \\\n  \"Research latest authentication patterns\"\n```\n\n**Phase 2 - Design** (GPT-5.2 + xhigh reasoning):\n```bash\ncodex exec resume --last\n# \"Design the authentication system based on research\"\n```\n\n**Phase 3 - Implement** (GPT-5.2-Codex + workspace-write):\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Implement the authentication system we designed\"\n```\n\n---\n\n### Pattern 2: Review → Fix → Verify\n\n**Review** (GPT-5.2 + read-only):\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Review this code for security issues\"\n```\n\n**Fix** (GPT-5.2-Codex + workspace-write):\n```bash\ncodex exec resume --last\n# \"Fix the security issues identified\"\n```\n\n**Verify** (GPT-5.2 + read-only):\n```bash\ncodex exec resume --last\n# \"Verify the fixes are correct\"\n```\n\n---\n\n## Next Steps\n\n- **Basic usage**: See [basic-usage.md](./basic-usage.md)\n- **Session continuation**: See [session-continuation.md](./session-continuation.md)\n- **Full documentation**: See [../SKILL.md](../SKILL.md)\n- **CLI reference**: See [../resources/codex-help.md](../resources/codex-help.md)\n- **Config reference**: See [../resources/codex-config.md](../resources/codex-config.md)\n",
        "plugins/codex/skills/codex/references/cli-features.md": "# Codex CLI Features Reference\n\nThis document provides a comprehensive reference for Codex CLI features and flags.\n\n## Feature Flags (`--enable` / `--disable`)\n\nEnable or disable specific Codex features:\n\n```bash\ncodex exec --enable web_search_request \"Research latest patterns\"\ncodex exec --disable some_feature \"Run without feature\"\n```\n\n## Image Attachment (`-i, --image`)\n\nAttach images to prompts for visual analysis:\n\n```bash\ncodex exec -i screenshot.png \"Analyze this UI design\"\ncodex exec -i diagram1.png -i diagram2.png \"Compare these architectures\"\n```\n\n## Additional Directories (`--add-dir`) (v0.71.0+)\n\nAdd writable directories beyond the primary workspace:\n\n```bash\ncodex exec --add-dir /shared/libs --add-dir /config \"task\"\n```\n\n## Full Auto Mode (`--full-auto`)\n\nConvenience flag for low-friction execution:\n\n```bash\ncodex exec --full-auto \"task\"\n# Equivalent to: -s workspace-write with on-request approval\n```\n\n## Non-Git Environments (`--skip-git-repo-check`)\n\nRun Codex outside Git repositories:\n\n```bash\ncodex exec --skip-git-repo-check \"Help with this script\"\n```\n\n## Structured Output (`--output-schema`)\n\nDefine JSON schema for model responses:\n\n```bash\ncodex exec --output-schema schema.json \"Generate structured data\"\n```\n\n## Output Coloring (`--color`)\n\nControl colored output (always, never, auto):\n\n```bash\ncodex exec --color never \"Run in CI/CD pipeline\"\n```\n\n## Web Search in Exec Mode\n\n**Note**: `--search` flag is interactive-only. Use `--enable` for exec mode:\n\n```bash\n# CORRECT for codex exec\ncodex exec --enable web_search_request \"research topic\"\n\n# WRONG - --search only works in interactive mode\ncodex --search \"research topic\"\n```\n\n## Feature Flags List (`codex features list`) (v0.71.0+)\n\nInspect and manage Codex feature flags:\n\n```bash\n# List all feature flags with their states\ncodex features list\n```\n\n### Stable Features\n\n| Feature | Default | Description |\n|---------|---------|-------------|\n| `web_search_request` | false | Enable web search capability |\n| `parallel` | true | Parallel execution |\n| `shell_tool` | true | Shell command execution |\n| `undo` | true | Undo functionality |\n| `view_image_tool` | true | Image viewing capability |\n| `warnings` | true | Display warnings |\n\n### Experimental/Beta Features\n\n| Feature | Stage | Default | Description |\n|---------|-------|---------|-------------|\n| `exec_policy` | experimental | true | Execution policy control |\n| `remote_compaction` | experimental | true | Remote compaction |\n| `unified_exec` | experimental | false | Unified execution mode |\n| `rmcp_client` | experimental | false | RMCP client support |\n| `apply_patch_freeform` | beta | false | Freeform patch application |\n| `skills` | experimental | false | Skills support |\n| `shell_snapshot` | experimental | false | Shell state snapshots |\n| `remote_models` | experimental | false | Remote model support |\n\nEnable/disable features with `--enable` and `--disable`:\n\n```bash\ncodex exec --enable web_search_request \"research task\"\ncodex exec --disable parallel \"run sequentially\"\n```\n\n## JSONL Output (`--json`) (v0.71.0+)\n\nStream events as JSONL for programmatic processing:\n\n```bash\ncodex exec --json \"task\" > events.jsonl\n```\n\n## Save Last Message (`-o/--output-last-message`) (v0.71.0+)\n\nWrite the final agent message to a file:\n\n```bash\ncodex exec -o result.txt \"generate summary\"\n```\n",
        "plugins/codex/skills/codex/references/codex-config.md": "Config reference\nKey\tType / Values\tNotes\nmodel\tstring\tModel to use (e.g., gpt-5.1-codex).\nmodel_provider\tstring\tProvider id from model_providers (default: openai).\nmodel_context_window\tnumber\tContext window tokens.\nmodel_max_output_tokens\tnumber\tMax output tokens.\napproval_policy\tuntrusted | on-failure | on-request | never\tWhen to prompt for approval.\nsandbox_mode\tread-only | workspace-write | danger-full-access\tOS sandbox policy.\nsandbox_workspace_write.writable_roots\tarray\tExtra writable roots in workspace‑write.\nsandbox_workspace_write.network_access\tboolean\tAllow network in workspace‑write (default: false).\nsandbox_workspace_write.exclude_tmpdir_env_var\tboolean\tExclude $TMPDIR from writable roots (default: false).\nsandbox_workspace_write.exclude_slash_tmp\tboolean\tExclude /tmp from writable roots (default: false).\nnotify\tarray\tExternal program for notifications.\ninstructions\tstring\tCurrently ignored; use experimental_instructions_file or AGENTS.md.\nmcp_servers.<id>.command\tstring\tMCP server launcher command (stdio servers only).\nmcp_servers.<id>.args\tarray\tMCP server args (stdio servers only).\nmcp_servers.<id>.env\tmap<string,string>\tMCP server env vars (stdio servers only).\nmcp_servers.<id>.url\tstring\tMCP server url (streamable http servers only).\nmcp_servers.<id>.bearer_token_env_var\tstring\tenvironment variable containing a bearer token to use for auth (streamable http servers only).\nmcp_servers.<id>.enabled\tboolean\tWhen false, Codex skips starting the server (default: true).\nmcp_servers.<id>.startup_timeout_sec\tnumber\tStartup timeout in seconds (default: 10). Timeout is applied both for initializing MCP server and initially listing tools.\nmcp_servers.<id>.tool_timeout_sec\tnumber\tPer-tool timeout in seconds (default: 60). Accepts fractional values; omit to use the default.\nmcp_servers.<id>.enabled_tools\tarray\tRestrict the server to the listed tool names.\nmcp_servers.<id>.disabled_tools\tarray\tRemove the listed tool names after applying enabled_tools, if any.\nmodel_providers.<id>.name\tstring\tDisplay name.\nmodel_providers.<id>.base_url\tstring\tAPI base URL.\nmodel_providers.<id>.env_key\tstring\tEnv var for API key.\nmodel_providers.<id>.wire_api\tchat | responses\tProtocol used (default: chat).\nmodel_providers.<id>.query_params\tmap<string,string>\tExtra query params (e.g., Azure api-version).\nmodel_providers.<id>.http_headers\tmap<string,string>\tAdditional static headers.\nmodel_providers.<id>.env_http_headers\tmap<string,string>\tHeaders sourced from env vars.\nmodel_providers.<id>.request_max_retries\tnumber\tPer‑provider HTTP retry count (default: 4).\nmodel_providers.<id>.stream_max_retries\tnumber\tSSE stream retry count (default: 5).\nmodel_providers.<id>.stream_idle_timeout_ms\tnumber\tSSE idle timeout (ms) (default: 300000).\nproject_doc_max_bytes\tnumber\tMax bytes to read from AGENTS.md.\nprofile\tstring\tActive profile name.\nprofiles.<name>.*\tvarious\tProfile‑scoped overrides of the same keys.\nhistory.persistence\tsave-all | none\tHistory file persistence (default: save-all).\nhistory.max_bytes\tnumber\tCurrently ignored (not enforced).\nfile_opener\tvscode | vscode-insiders | windsurf | cursor | none\tURI scheme for clickable citations (default: vscode).\ntui\ttable\tTUI‑specific options.\ntui.notifications\tboolean | array\tEnable desktop notifications in the tui (default: false).\nhide_agent_reasoning\tboolean\tHide model reasoning events.\nshow_raw_agent_reasoning\tboolean\tShow raw reasoning (when available).\nmodel_reasoning_effort\tminimal | low | medium | high | xhigh\tResponses API reasoning effort.\nmodel_reasoning_summary\tauto | concise | detailed | none\tReasoning summaries.\nmodel_verbosity\tlow | medium | high\tGPT‑5 text verbosity (Responses API).\nmodel_supports_reasoning_summaries\tboolean\tForce‑enable reasoning summaries.\nmodel_reasoning_summary_format\tnone | experimental\tForce reasoning summary format.\nchatgpt_base_url\tstring\tBase URL for ChatGPT auth flow.\nexperimental_instructions_file\tstring (path)\tReplace built‑in instructions (experimental).\nexperimental_use_exec_command_tool\tboolean\tUse experimental exec command tool.\nprojects.<path>.trust_level\tstring\tMark project/worktree as trusted (only \"trusted\" is recognized).\ntools.web_search_request\tboolean\tEnable web search tool (default: false). Deprecated alias: tools.web_search\nforced_login_method\tchatgpt | api\tOnly allow Codex to be used with ChatGPT or API keys.\nforced_chatgpt_workspace_id\tstring (uuid)\tOnly allow Codex to be used with the specified ChatGPT workspace.\ntools.view_image\tboolean\tEnable the view_image tool so Codex can attach local image files from the workspace (default: false).\n",
        "plugins/codex/skills/codex/references/codex-help.md": "# Codex CLI Help Reference\n\n**Version**: 0.71.0\n\n## IMPORTANT: Interactive vs Exec Mode Differences\n\nSome flags are ONLY available in interactive `codex` mode, NOT in `codex exec`:\n\n| Flag | Interactive `codex` | `codex exec` |\n|------|---------------------|--------------|\n| `--search` | ✅ Available | ❌ NOT available |\n| `-a/--ask-for-approval` | ✅ Available | ❌ NOT available |\n| `--add-dir` | ✅ Available | ✅ Available |\n| `--full-auto` | ✅ Available | ✅ Available |\n\n## Main Command: `codex --help`\n\n```\nCodex CLI\n\nIf no subcommand is specified, options will be forwarded to the interactive CLI.\n\nUsage: codex [OPTIONS] [PROMPT]\n       codex [OPTIONS] <COMMAND> [ARGS]\n\nCommands:\n  exec        Run Codex non-interactively [aliases: e]\n  review      Run a code review non-interactively\n  login       Manage login\n  logout      Remove stored authentication credentials\n  mcp         [experimental] Run Codex as an MCP server and manage MCP servers\n  mcp-server  [experimental] Run the Codex MCP server (stdio transport)\n  app-server  [experimental] Run the app server or related tooling\n  completion  Generate shell completion scripts\n  sandbox     Run commands within a Codex-provided sandbox [aliases: debug]\n  apply       Apply the latest diff produced by Codex agent as a `git apply` to your local working\n              tree [aliases: a]\n  resume      Resume a previous interactive session (picker by default; use --last to continue the\n              most recent)\n  cloud       [EXPERIMENTAL] Browse tasks from Codex Cloud and apply changes locally\n  features    Inspect feature flags\n  help        Print this message or the help of the given subcommand(s)\n\nArguments:\n  [PROMPT]\n          Optional user prompt to start the session\n\nOptions:\n  -c, --config <key=value>\n          Override a configuration value that would otherwise be loaded from `~/.codex/config.toml`.\n          Use a dotted path (`foo.bar.baz`) to override nested values. The `value` portion is parsed\n          as TOML. If it fails to parse as TOML, the raw string is used as a literal.\n\n          Examples: - `-c model=\"o3\"` - `-c 'sandbox_permissions=[\"disk-full-read-access\"]'` - `-c\n          shell_environment_policy.inherit=all`\n\n      --enable <FEATURE>\n          Enable a feature (repeatable). Equivalent to `-c features.<name>=true`\n\n      --disable <FEATURE>\n          Disable a feature (repeatable). Equivalent to `-c features.<name>=false`\n\n  -i, --image <FILE>...\n          Optional image(s) to attach to the initial prompt\n\n  -m, --model <MODEL>\n          Model the agent should use\n\n      --oss\n          Convenience flag to select the local open source model provider. Equivalent to -c\n          model_provider=oss; verifies a local LM Studio or Ollama server is running\n\n      --local-provider <OSS_PROVIDER>\n          Specify which local provider to use (lmstudio or ollama). If not specified with --oss,\n          will use config default or show selection\n\n  -p, --profile <CONFIG_PROFILE>\n          Configuration profile from config.toml to specify default options\n\n  -s, --sandbox <SANDBOX_MODE>\n          Select the sandbox policy to use when executing model-generated shell commands\n\n          [possible values: read-only, workspace-write, danger-full-access]\n\n  -a, --ask-for-approval <APPROVAL_POLICY>\n          Configure when the model requires human approval before executing a command\n\n          Possible values:\n          - untrusted:  Only run \"trusted\" commands (e.g. ls, cat, sed) without asking for user\n            approval. Will escalate to the user if the model proposes a command that is not in the\n            \"trusted\" set\n          - on-failure: Run all commands without asking for user approval. Only asks for approval if\n            a command fails to execute, in which case it will escalate to the user to ask for\n            un-sandboxed execution\n          - on-request: The model decides when to ask the user for approval\n          - never:      Never ask for user approval Execution failures are immediately returned to\n            the model\n\n      --full-auto\n          Convenience alias for low-friction sandboxed automatic execution (-a on-request, --sandbox\n          workspace-write)\n\n      --dangerously-bypass-approvals-and-sandbox\n          Skip all confirmation prompts and execute commands without sandboxing. EXTREMELY\n          DANGEROUS. Intended solely for running in environments that are externally sandboxed\n\n  -C, --cd <DIR>\n          Tell the agent to use the specified directory as its working root\n\n      --search\n          Enable web search (off by default). When enabled, the native Responses `web_search` tool\n          is available to the model (no per‑call approval)\n\n          NOTE: This flag is ONLY available in interactive mode, NOT in `codex exec`\n\n      --add-dir <DIR>\n          Additional directories that should be writable alongside the primary workspace\n\n  -h, --help\n          Print help (see a summary with '-h')\n\n  -V, --version\n          Print version\n```\n\n## Exec Command: `codex exec --help`\n\n**NOTE**: `--search` and `-a/--ask-for-approval` are NOT available in exec mode.\n\n```\nRun Codex non-interactively\n\nUsage: codex exec [OPTIONS] [PROMPT] [COMMAND]\n\nCommands:\n  resume  Resume a previous session by id or pick the most recent with --last\n  review  Run a code review against the current repository\n  help    Print this message or the help of the given subcommand(s)\n\nArguments:\n  [PROMPT]\n          Initial instructions for the agent. If not provided as an argument (or if `-` is used),\n          instructions are read from stdin\n\nOptions:\n  -c, --config <key=value>\n          Override a configuration value that would otherwise be loaded from `~/.codex/config.toml`.\n          Use a dotted path (`foo.bar.baz`) to override nested values. The `value` portion is parsed\n          as TOML. If it fails to parse as TOML, the raw string is used as a literal.\n\n          Examples: - `-c model=\"o3\"` - `-c 'sandbox_permissions=[\"disk-full-read-access\"]'` - `-c\n          shell_environment_policy.inherit=all`\n\n      --enable <FEATURE>\n          Enable a feature (repeatable). Equivalent to `-c features.<name>=true`\n\n      --disable <FEATURE>\n          Disable a feature (repeatable). Equivalent to `-c features.<name>=false`\n\n  -i, --image <FILE>...\n          Optional image(s) to attach to the initial prompt\n\n  -m, --model <MODEL>\n          Model the agent should use\n\n      --oss\n          Use open-source provider\n\n      --local-provider <OSS_PROVIDER>\n          Specify which local provider to use (lmstudio or ollama). If not specified with --oss,\n          will use config default or show selection\n\n  -s, --sandbox <SANDBOX_MODE>\n          Select the sandbox policy to use when executing model-generated shell commands\n\n          [possible values: read-only, workspace-write, danger-full-access]\n\n  -p, --profile <CONFIG_PROFILE>\n          Configuration profile from config.toml to specify default options\n\n      --full-auto\n          Convenience alias for low-friction sandboxed automatic execution (-a on-request, --sandbox\n          workspace-write)\n\n      --dangerously-bypass-approvals-and-sandbox\n          Skip all confirmation prompts and execute commands without sandboxing. EXTREMELY\n          DANGEROUS. Intended solely for running in environments that are externally sandboxed\n\n  -C, --cd <DIR>\n          Tell the agent to use the specified directory as its working root\n\n      --skip-git-repo-check\n          Allow running Codex outside a Git repository\n\n      --add-dir <DIR>\n          Additional directories that should be writable alongside the primary workspace\n\n      --output-schema <FILE>\n          Path to a JSON Schema file describing the model's final response shape\n\n      --color <COLOR>\n          Specifies color settings for use in the output\n\n          [default: auto]\n          [possible values: always, never, auto]\n\n      --json\n          Print events to stdout as JSONL\n\n  -o, --output-last-message <FILE>\n          Specifies file where the last message from the agent should be written\n\n  -h, --help\n          Print help (see a summary with '-h')\n\n  -V, --version\n          Print version\n```\n\n## Review Command: `codex review --help`\n\n```\nRun a code review non-interactively\n\nUsage: codex review [OPTIONS] [PROMPT]\n\nArguments:\n  [PROMPT]\n          Custom review instructions. If `-` is used, read from stdin\n\nOptions:\n  -c, --config <key=value>\n          Override a configuration value\n\n      --uncommitted\n          Review staged, unstaged, and untracked changes\n\n      --base <BRANCH>\n          Review changes against the given base branch\n\n      --enable <FEATURE>\n          Enable a feature (repeatable)\n\n      --commit <SHA>\n          Review the changes introduced by a commit\n\n      --disable <FEATURE>\n          Disable a feature (repeatable)\n\n      --title <TITLE>\n          Optional commit title to display in the review summary\n\n  -h, --help\n          Print help\n```\n\n## Exec Resume Command: `codex exec resume --help`\n\n```\nResume a previous session by id or pick the most recent with --last\n\nUsage: codex exec resume [OPTIONS] [SESSION_ID] [PROMPT]\n\nArguments:\n  [SESSION_ID]\n          Conversation/session id (UUID). When provided, resumes this session. If omitted, use\n          --last to pick the most recent recorded session\n\n  [PROMPT]\n          Prompt to send after resuming the session. If `-` is used, read from stdin\n\nOptions:\n  -c, --config <key=value>\n          Override a configuration value that would otherwise be loaded from `~/.codex/config.toml`.\n          Use a dotted path (`foo.bar.baz`) to override nested values. The `value` portion is parsed\n          as TOML. If it fails to parse as TOML, the raw string is used as a literal.\n\n          Examples: - `-c model=\"o3\"` - `-c 'sandbox_permissions=[\"disk-full-read-access\"]'` - `-c\n          shell_environment_policy.inherit=all`\n\n      --last\n          Resume the most recent recorded session (newest) without specifying an id\n\n      --enable <FEATURE>\n          Enable a feature (repeatable). Equivalent to `-c features.<name>=true`\n\n      --disable <FEATURE>\n          Disable a feature (repeatable). Equivalent to `-c features.<name>=false`\n\n  -h, --help\n          Print help (see a summary with '-h')\n```\n\n## Features Command: `codex features list`\n\n```\nInspect feature flags\n\nUsage: codex features list\n\nLists all known features with their stage (stable/beta/experimental) and effective state (enabled/disabled).\n\nCurrent features (v0.71.0):\n- undo (stable, default: true)\n- parallel (stable, default: true)\n- view_image_tool (stable, default: true)\n- shell_tool (stable, default: true)\n- warnings (stable, default: true)\n- web_search_request (stable, default: false)\n- exec_policy (experimental, default: true)\n- remote_compaction (experimental, default: true)\n- unified_exec (experimental, default: false)\n- rmcp_client (experimental, default: false)\n- apply_patch_freeform (beta, default: false)\n- skills (experimental, default: false)\n```\n\n## Cloud Command: `codex cloud --help` (EXPERIMENTAL)\n\n```\n[EXPERIMENTAL] Browse tasks from Codex Cloud and apply changes locally\n\nUsage: codex cloud [OPTIONS] [COMMAND]\n\nCommands:\n  exec    Submit a new Codex Cloud task without launching the TUI\n  status  Show the status of a Codex Cloud task\n  apply   Apply the diff for a Codex Cloud task locally\n  diff    Show the unified diff for a Codex Cloud task\n  help    Print this message or the help of the given subcommand(s)\n```\n\n## Model Support (v0.71.0)\n\n**Available Models**:\n- `gpt-5.2` - Latest model with all reasoning levels (NEW)\n- `gpt-5.1` - General high-reasoning model\n- `gpt-5.1-codex-max` - Maximum capability code editing (27-42% faster)\n- `gpt-5.1-codex` - Standard code editing (backward compatibility)\n\n**Reasoning Effort Levels** (all supported by gpt-5.2):\n- `low` - Minimal reasoning\n- `medium` - Balanced reasoning\n- `high` - High reasoning (default)\n- `xhigh` - Extra-high reasoning for maximum capability\n",
        "plugins/codex/skills/codex/references/command-patterns.md": "# Basic Usage Examples\n\n---\n\n## ⚠️ CRITICAL: Always Use `codex exec`\n\n**ALL commands in this document use `codex exec` - this is mandatory in Claude Code.**\n\n❌ **NEVER**: `codex -m ...` (will fail with \"stdout is not a terminal\")\n✅ **ALWAYS**: `codex exec -m ...` (correct non-interactive mode)\n\nClaude Code's bash environment is non-terminal. Plain `codex` commands will NOT work.\n\n---\n\n## Example 1: General Reasoning Task - Queue Design\n\n### User Request\n\"Help me design a queue data structure in Python\"\n\n### What Happens\n\n1. **Claude detects** the reasoning task (queue design)\n2. **Skill is invoked** autonomously\n3. **Codex CLI is called** with gpt-5.2 (high-reasoning general model):\n\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Help me design a queue data structure in Python\"\n```\n\n4. **Codex responds** with xhigh-reasoning architectural guidance on queue design\n5. **Session is auto-saved** for potential continuation\n\n### Expected Output\n\nCodex provides:\n- Queue design principles and trade-offs\n- Multiple implementation approaches (list-based, deque, linked-list)\n- Performance characteristics (O(1) enqueue/dequeue)\n- Thread-safety considerations\n- Usage examples and best practices\n\n---\n\n## Example 2: Code Editing Task - Implement Queue\n\n### User Request\n\"Edit my Python file to implement the queue with thread-safety\"\n\n### What Happens\n\n1. **Skill detects** code editing request\n2. **Uses gpt-5.2-codex** (optimized for agentic coding - 56.4% SWE-Bench Pro):\n\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Edit my Python file to implement the queue with thread-safety\"\n```\n\n3. **Codex performs code editing** with xhigh reasoning capability\n4. **Files are modified** (workspace-write sandbox)\n\n### Expected Output\n\nCodex:\n- Edits the target Python file\n- Implements thread-safe queue using `threading.Lock`\n- Adds proper synchronization primitives\n- Includes docstrings and type hints\n- Provides usage examples\n\n---\n\n## Example 3: Explicit Codex Request\n\n### User Request\n\"Use Codex to design a REST API for a blog system\"\n\n### What Happens\n\n1. **Explicit \"Codex\" mention** triggers skill\n2. **Codex invoked** with general reasoning settings:\n\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Design a REST API for a blog system\"\n```\n\n3. **xhigh-reasoning analysis** provides comprehensive API design\n\n### Expected Output\n\nCodex delivers:\n- RESTful endpoint design (GET/POST/PUT/DELETE)\n- Resource modeling (posts, authors, comments)\n- Authentication and authorization strategy\n- Data validation approaches\n- API versioning recommendations\n- Error handling patterns\n\n---\n\n## Example 4: Complex Algorithm Design\n\n### User Request\n\"Help me implement a binary search tree with balancing\"\n\n### What Happens\n\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Help me implement a binary search tree with balancing\"\n```\n\n### Expected Output\n\nCodex provides:\n- BST fundamentals and invariants\n- AVL vs Red-Black tree trade-offs\n- Rotation algorithms (left, right, left-right, right-left)\n- Insertion and deletion with rebalancing\n- Complexity analysis\n- Implementation guidance\n\n---\n\n## Example 5: Complex Refactoring with xhigh\n\n### User Request\n\"Refactor the authentication system with comprehensive security improvements\"\n\n### What Happens\n\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Refactor the authentication system with comprehensive security improvements\"\n```\n\n### Expected Output\n\nCodex provides:\n- Deep architectural analysis of current system\n- Comprehensive security vulnerability assessment\n- Multi-layered refactoring strategy\n- Implementation of security best practices\n- Detailed reasoning about trade-offs\n- Long-horizon planning for complex changes (native context compaction)\n\n**Note**: xhigh is the default reasoning effort for all Codex invocations. gpt-5.2-codex has native context compaction ideal for long-horizon refactoring tasks.\n\n---\n\n## Model Selection Summary\n\n| Task Type | Model | Sandbox | Reasoning | Example |\n|-----------|-------|---------|-----------|---------|\n| General reasoning | `gpt-5.2` | `read-only` | xhigh | \"Design a queue\" |\n| Architecture design | `gpt-5.2` | `read-only` | xhigh | \"Design REST API\" |\n| Code review | `gpt-5.2` | `read-only` | xhigh | \"Review this code\" |\n| Code editing | `gpt-5.2-codex` | `workspace-write` | xhigh | \"Edit file to add X\" |\n| Complex refactoring | `gpt-5.2-codex` | `workspace-write` | xhigh | \"Refactor auth system\" |\n| Implementation | `gpt-5.2-codex` | `workspace-write` | xhigh | \"Implement function Y\" |\n\n**Note**: `gpt-5.2-codex` is optimized for agentic coding (56.4% SWE-Bench Pro) with native context compaction. Always use `xhigh` reasoning effort for maximum capability.\n\n### Fallback Chain\n- **Coding**: `gpt-5.2-codex` → `gpt-5.2` → `gpt-5.1-codex-max`\n- **Reasoning effort**: `xhigh` → `high` → `medium`\n\n---\n\n## Tips for Best Results\n\n1. **Be specific** in your requests - detailed prompts get better reasoning\n2. **Indicate task type** clearly (design vs. implementation)\n3. **Mention permissions** when you need file writes (\"allow file writing\")\n4. **Use continuation** for iterative development (see session-continuation.md)\n\n---\n\n## Next Steps\n\n- **Continue a session**: See [session-continuation.md](./session-continuation.md)\n- **Advanced config**: See [advanced-config.md](./advanced-config.md)\n- **Full documentation**: See [../SKILL.md](../SKILL.md)\n",
        "plugins/codex/skills/codex/references/examples.md": "# Codex Examples\n\nComplete examples showing common Codex invocation patterns.\n\n## Code Tasks (Read-Only Default)\n\n### Example 1: Code Analysis\n\n**User Request**: \"Analyze this function implementation and suggest improvements\"\n\n**Command**:\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Analyze this function implementation and suggest improvements\"\n```\n\n**Result**: Code-related task uses gpt-5.2-codex with read-only sandbox (default). No file modifications.\n\n### Example 2: Architecture Review\n\n**User Request**: \"Help me design a binary search tree architecture in Rust\"\n\n**Command**:\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Help me design a binary search tree architecture in Rust\"\n```\n\n**Result**: General task uses gpt-5.2 with read-only sandbox (default). Session automatically saved for continuation.\n\n### Example 3: Web Search Research\n\n**User Request**: \"Use Codex with web search to research async patterns\"\n\n**Command**:\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"Research async patterns\"\n```\n\n**Result**: Code-related research uses gpt-5.2-codex with read-only sandbox (default) and web search enabled.\n\n## Code Tasks (Explicit Edit Request)\n\n### Example 4: File Editing\n\n**User Request**: \"Edit this file to implement the BST insert method\"\n\n**Command**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Edit this file to implement the BST insert method\"\n```\n\n**Result**: User explicitly said \"Edit this file\" - code task uses gpt-5.2-codex with workspace-write permissions.\n\n### Example 5: Refactoring\n\n**User Request**: \"Refactor and save the authentication system code\"\n\n**Command**:\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Refactor and save the authentication system code\"\n```\n\n**Result**: User explicitly said \"Refactor and save\" - code task uses gpt-5.2-codex with workspace-write for file modifications.\n\n## Session Continuation\n\n### Example 6: Resume Previous Session\n\n**User Request**: \"Continue with the BST - add a deletion method\"\n\n**Command**:\n```bash\ncodex exec resume --last\n```\n\n**Result**: Codex resumes the previous BST session and continues with deletion method implementation, maintaining full context.\n\n### Example 7: Resume with New Prompt\n\n**User Request**: \"Continue where we left off and add error handling\"\n\n**Command**:\n```bash\ncodex exec resume --last\n# Codex maintains previous context and continues with error handling\n```\n\n## File Context Examples\n\n### Example 8: Analyze Specific File\n\n**User Request**: \"Analyze @src/auth.ts for security issues\"\n\n**Command**:\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  \"Analyze @src/auth.ts for security issues\"\n```\n\n### Example 9: Multi-Directory Analysis\n\n**User Request**: \"Compare how frontend and backend handle authentication\"\n\n**Command**:\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  --add-dir /frontend/src \\\n  --add-dir /backend/src \\\n  \"Compare how frontend and backend handle authentication\"\n```\n\n## Code Review\n\n### Example 10: Review Uncommitted Changes\n\n**Command**:\n```bash\ncodex exec review --uncommitted\n```\n\n### Example 11: Review Against Branch\n\n**Command**:\n```bash\ncodex review --base main \"Focus on security vulnerabilities\"\n```\n",
        "plugins/codex/skills/codex/references/file-context.md": "# File Context Passing\n\n**IMPORTANT**: When users reference files or directories in their requests, pass file paths to Codex CLI instead of embedding file content in the prompt. This enables Codex to read and explore files autonomously using its native capabilities.\n\n## Benefits\n\n- **Reduced token usage**: File content not embedded in prompts\n- **Large file support**: Codex handles files natively without truncation\n- **Better performance**: Codex optimizes file reading internally\n- **Unchanged workflow**: Works with natural file references\n\n## Directory Context (`-C` flag)\n\nUse `-C` to set the working directory for Codex operations:\n\n```bash\n# Set working directory to project root\ncodex exec -m gpt-5.2-codex -s read-only -C /path/to/project \\\n  \"Analyze the authentication module\"\n\n# Codex will explore files within /path/to/project\n```\n\n## Additional Directories (`--add-dir` flag)\n\nUse `--add-dir` to include directories outside the primary workspace:\n\n```bash\n# Include shared libraries directory\ncodex exec -m gpt-5.2-codex -s read-only \\\n  --add-dir /shared/libs \\\n  \"Review how the auth module uses shared utilities\"\n\n# Include multiple directories\ncodex exec -m gpt-5.2-codex -s read-only \\\n  --add-dir /shared/libs \\\n  --add-dir /config \\\n  \"Analyze configuration usage across the codebase\"\n```\n\n## File Context Examples\n\n```bash\n# Analyze a specific file (Codex reads it autonomously)\ncodex exec -m gpt-5.2-codex -s read-only \\\n  \"Analyze the implementation in src/auth/login.ts\"\n\n# Review multiple files\ncodex exec -m gpt-5.2-codex -s read-only \\\n  \"Compare the implementations in src/v1/api.ts and src/v2/api.ts\"\n\n# Work with files across directories\ncodex exec -m gpt-5.2-codex -s read-only \\\n  --add-dir /shared/types \\\n  \"Check how src/services/user.ts uses types from the shared directory\"\n```\n\n## Directory Context Examples\n\n```bash\n# Analyze entire directory\ncodex exec -m gpt-5.2-codex -s read-only -C /project/src \\\n  \"Review the architecture of this module\"\n\n# Multi-directory codebase analysis\ncodex exec -m gpt-5.2-codex -s read-only \\\n  --add-dir /frontend/src \\\n  --add-dir /backend/src \\\n  \"Analyze how frontend and backend communicate\"\n```\n\n## Path Detection\n\nThe skill automatically detects file/directory paths in user requests:\n\n**Auto-detected patterns**:\n- Paths with separators: `src/auth/login.ts`, `lib/utils.py`\n- Relative paths: `./config.json`, `../shared/types.ts`\n- Absolute paths: `/home/user/project/file.rs`\n- Common extensions: `.ts`, `.js`, `.py`, `.rs`, `.go`, etc.\n\n**Explicit syntax** (`@` prefix):\n- Use `@path/to/file` for explicit file references\n- Example: \"Analyze @src/auth.ts and @src/session.ts\"\n- Multiple files: \"Compare @v1/api.ts with @v2/api.ts\"\n- Directories: \"Review @src/services/ architecture\"\n\n```bash\n# Complete example using @ prefix syntax\ncodex exec -m gpt-5.2-codex -s read-only \\\n  \"Analyze @src/auth.ts and compare with @src/session.ts\"\n\n# Directory reference with @ prefix\ncodex exec -m gpt-5.2-codex -s read-only \\\n  \"Review the structure of @src/components/ directory\"\n```\n\n## Path Resolution\n\n- Relative paths are resolved against the current working directory\n- Absolute paths are passed directly to Codex\n- The skill converts all paths to absolute before invoking CLI\n\n## When NOT to Embed File Content\n\n**DO NOT** read files and embed content in prompts when:\n- User mentions specific file paths in their request\n- Request involves analyzing, reviewing, or understanding code\n- Working with large files (>10KB)\n- Multi-file operations are requested\n\n**Instead**: Pass file paths to Codex and let it read files autonomously.\n\n## Edge Cases\n\n- **Missing files**: Codex reports the error with context\n- **Files outside workspace**: Use `--add-dir` to include external directories\n- **Binary files**: Codex determines if it can process the file\n- **Large directories**: Codex handles exploration internally\n",
        "plugins/codex/skills/codex/references/session-workflows.md": "# Session Continuation Examples\n\n---\n\n## ⚠️ CRITICAL: Always Use `codex exec`\n\n**ALL commands in this document use `codex exec` - this is mandatory in Claude Code.**\n\n❌ **NEVER**: `codex resume ...` (will fail with \"stdout is not a terminal\")\n✅ **ALWAYS**: `codex exec resume ...` (correct non-interactive mode)\n\nClaude Code's bash environment is non-terminal. Plain `codex` commands will NOT work.\n\n---\n\n## Example 1: Basic Session Continuation\n\n### Initial Request\n**User**: \"Help me design a queue data structure in Python\"\n\n**Skill Executes**:\n```bash\ncodex exec -m gpt-5.1 -s read-only \\\n  -c model_reasoning_effort=high \\\n  \"Help me design a queue data structure in Python\"\n```\n\n**Codex Response**: Provides queue design with multiple approaches.\n\n**Session Auto-Saved**: Codex CLI saves this session automatically.\n\n---\n\n### Follow-Up Request\n**User**: \"Continue with that queue - now add thread-safety\"\n\n**Skill Detects**: Continuation keywords (\"continue with that\")\n\n**Skill Executes**:\n```bash\ncodex exec resume --last\n```\n\n**Codex Response**: Resumes previous session, maintains context about the queue design, and adds thread-safety implementation building on the previous discussion.\n\n**Context Maintained**: All previous conversation history is available to Codex.\n\n---\n\n## Example 2: Multi-Turn Iterative Development\n\n### Turn 1: Initial Design\n**User**: \"Design a REST API for a blog system\"\n\n```bash\ncodex exec -m gpt-5.1 -s read-only \\\n  -c model_reasoning_effort=high \\\n  \"Design a REST API for a blog system\"\n```\n\n**Output**: API endpoint design, resource modeling, etc.\n\n---\n\n### Turn 2: Add Authentication\n**User**: \"Add authentication to that API design\"\n\n**Skill Executes**:\n```bash\ncodex exec resume --last\n```\n\n**Output**: Codex continues from previous API design and adds JWT/OAuth authentication strategy.\n\n---\n\n### Turn 3: Add Error Handling\n**User**: \"Now add comprehensive error handling\"\n\n**Skill Executes**:\n```bash\ncodex exec resume --last\n```\n\n**Output**: Codex builds on previous API + auth design and adds error handling patterns.\n\n---\n\n### Turn 4: Implementation\n**User**: \"Implement the user authentication endpoint\"\n\n**Skill Executes**:\n```bash\ncodex exec resume --last\n```\n\n**Output**: Codex uses all previous context to implement the auth endpoint with full understanding of the API design.\n\n**Result**: After 4 turns, you have a complete API with design, auth, error handling, and initial implementation - all with maintained context.\n\n---\n\n## Example 3: Explicit Resume Command\n\n### When to Use Interactive Picker\n\nIf you have multiple Codex sessions and want to choose which one to continue:\n\n**User**: \"Show me my Codex sessions and let me pick which to resume\"\n\n**Manual Command** (run outside skill):\n```bash\ncodex exec resume --last\n```\n\nThis opens an interactive picker showing:\n```\nRecent Codex Sessions:\n1. Queue data structure design (30 minutes ago)\n2. REST API for blog system (2 hours ago)\n3. Binary search tree implementation (yesterday)\n\nSelect session to resume:\n```\n\n---\n\n## Example 4: Resuming After Claude Code Restart\n\n### Scenario\n1. You worked on a queue design with Codex\n2. Closed Claude Code\n3. Reopened Claude Code days later\n\n### Resume Request\n**User**: \"Continue where we left off with the queue implementation\"\n\n**Skill Executes**:\n```bash\ncodex exec resume --last\n```\n\n**Result**: Codex resumes the most recent session (the queue work) with full context maintained across Claude Code restarts.\n\n**Why It Works**: Codex CLI persists session history independently of Claude Code.\n\n---\n\n## Continuation Keywords\n\nThe skill detects continuation requests when you use phrases like:\n\n- \"Continue with that\"\n- \"Resume the previous session\"\n- \"Keep going\"\n- \"Add to that\"\n- \"Now add X\" (implies building on previous)\n- \"Continue where we left off\"\n- \"Follow up on that\"\n\n---\n\n## Decision Tree: New Session vs. Resume\n\n```\nUser makes request\n│\n├─ Contains continuation keywords?\n│  │\n│  ├─ YES → Use `codex exec resume --last`\n│  │\n│  └─ NO → Check context\n│     │\n│     ├─ References previous Codex work?\n│     │  │\n│     │  ├─ YES → Use `codex exec resume --last`\n│     │  │\n│     │  └─ NO → New session: `codex exec -m ... \"prompt\"`\n│\n└─ User explicitly says \"new\" or \"fresh\"?\n   │\n   └─ YES → Force new session even if continuation keywords present\n```\n\n---\n\n## Session History Management\n\n### Automatic Save\n- Every Codex session is automatically saved by Codex CLI\n- No manual session ID tracking needed\n- Sessions persist across:\n  - Claude Code restarts\n  - Terminal sessions\n  - System reboots\n\n### Accessing History\n```bash\n# Resume most recent (recommended for skill)\ncodex exec resume --last\n\n# Interactive picker (manual use)\ncodex exec resume --last\n\n# List sessions (manual use)\ncodex list\n```\n\n---\n\n## Best Practices\n\n### 1. Use Clear Continuation Language\n\n**Good**:\n- \"Continue with that queue implementation - add unit tests\"\n- \"Resume the API design session and add rate limiting\"\n\n**Less Clear**:\n- \"Add tests\" (ambiguous - new or continue?)\n- \"Rate limiting\" (no continuation context)\n\n### 2. Build Incrementally\n\nStart with high-level design, then iterate:\n1. Design (new session)\n2. Add feature A (resume)\n3. Add feature B (resume)\n4. Implement (resume with full context)\n\n### 3. Leverage Context Accumulation\n\nEach resumed session has ALL previous context:\n- Design decisions\n- Trade-offs discussed\n- Code patterns chosen\n- Error handling approaches\n\nThis allows Codex to provide increasingly sophisticated, context-aware assistance.\n\n---\n\n## Troubleshooting\n\n### \"No previous sessions found\"\n\n**Cause**: Codex CLI history is empty (no prior sessions)\n\n**Fix**: Start a new session first:\n```bash\ncodex exec -m gpt-5.1\"Design a queue\"\n```\n\nThen subsequent \"continue\" requests will work.\n\n---\n\n### Session Not Resuming Correctly\n\n**Symptoms**: Resume works but context seems lost\n\n**Possible Causes**:\n- Multiple sessions mixed together\n- User explicitly requested \"fresh start\"\n\n**Fix**: Use interactive picker to select correct session:\n```bash\ncodex exec resume --last\n```\n\n---\n\n### Multiple Sessions Confusion\n\n**Scenario**: Working on two projects, want to resume specific one\n\n**Solution**:\n1. Be explicit: \"Resume the queue design session\" (skill will use --last)\n2. Or manually: `codex exec resume --last` (or `codex exec resume <session-id>`) → pick correct session\n\n---\n\n## Next Steps\n\n- **Advanced config**: See [advanced-config.md](./advanced-config.md)\n- **Basic examples**: See [basic-usage.md](./basic-usage.md)\n- **Full docs**: See [../SKILL.md](../SKILL.md)\n",
        "plugins/gemini/.claude-plugin/plugin.json": "{\n  \"name\": \"gemini\",\n  \"description\": \"Google Gemini CLI integration for Claude Code. Triggers: 'use gemini', 'ask gemini', 'run gemini', 'gemini cli', 'Google AI', 'Gemini reasoning'. Provides access to Gemini AI models with intelligent model selection, session continuation, and safe defaults.\",\n  \"version\": \"1.2.0\",\n  \"author\": {\n    \"name\": \"0xasun\"\n  },\n  \"repository\": \"https://github.com/Lucklyric/cc-dev-tools\",\n  \"homepage\": \"https://github.com/Lucklyric/cc-dev-tools/tree/main/plugins/gemini\",\n  \"keywords\": [\"gemini\", \"ai\", \"google\", \"reasoning\", \"development\", \"gemini-3\", \"gemini-2.5\"],\n  \"license\": \"Apache-2.0\",\n  \"skills\": [\"./skills/gemini\"]\n}\n",
        "plugins/gemini/README.md": "# Gemini CLI Integration Plugin\n\nGoogle Gemini AI integration for Claude Code, providing access to Gemini's advanced models through a local CLI.\n\n## Overview\n\nThis plugin enables Claude Code users to invoke Google's Gemini AI models for complex reasoning tasks, research, and development assistance. It provides intelligent model selection, session continuation, and safe defaults for seamless integration.\n\n## Features\n\n- **Unified Model Selection**: Defaults to Gemini 3 Pro for ALL tasks (coding and reasoning)\n- **Version-Based Mapping**: User requests like \"use 3\" automatically map to the latest 3.x model\n- **Session Continuation**: Resume previous conversations with `-r latest` or `-r <index>`\n- **Safe Defaults**: Auto-edit approval mode and disabled sandbox for trusted environments\n- **Extensions Support**: Built-in web search and MCP server integration\n- **Headless Execution**: Optimized for Claude Code's non-interactive bash environment\n\n## Prerequisites\n\n1. **Gemini CLI** (v0.21.1 or later for Gemini 3 Pro)\n   ```bash\n   npm install -g @google/gemini-cli@latest\n   ```\n\n2. **Authentication**\n   ```bash\n   gemini login\n   ```\n   Authenticate via OAuth (personal Google account) or API key\n\n3. **Gemini 3 Pro Access** (Optional)\n   - Google AI Ultra subscription\n   - Paid Gemini API key\n   - Vertex API key with Gemini 3 access\n   - Waitlist approval + Preview Features enabled\n\n## Important: Preview Features & Headless Mode\n\n**If you're using OAuth free tier**, there's a known issue with preview features in headless mode:\n\n### The Issue\n\nWhen `previewFeatures: true` in `~/.gemini/settings.json`, Gemini CLI automatically routes **all** requests to Gemini 3 Pro, even when you explicitly request `-m gemini-2.5-pro`. Since free tier OAuth accounts don't have Gemini 3 Pro access, this causes **404 \"Requested entity was not found\"** errors.\n\n### The Solution\n\n**Option 1: Disable Preview Features (Recommended for Headless)**\n\nEdit `~/.gemini/settings.json`:\n```json\n{\n  \"general\": {\n    \"previewFeatures\": false\n  }\n}\n```\n\n**Option 2: Use Gemini 2.5 Flash (Always Works)**\n\nThe plugin automatically falls back to `gemini-2.5-flash` when other models are unavailable. Flash always works with free tier OAuth.\n\n### Unified Fallback Strategy\n\nThis plugin implements a three-step fallback chain for ALL tasks:\n\n1. **Try Gemini 3 Pro** (`gemini-3-pro-preview`) - Primary for all tasks\n2. **Fallback to Gemini 2.5 Pro** (`gemini-2.5-pro`) - If 3 Pro unavailable\n3. **Fallback to Gemini 2.5 Flash** (`gemini-2.5-flash`) - Always works\n\nIf you see 404 errors, the plugin will automatically retry with the next fallback. To prevent this issue, disable preview features as shown above.\n\n## Installation\n\nThis plugin is part of the cc-dev-tools marketplace. To install:\n\n1. Add the marketplace:\n   ```bash\n   /marketplace add https://github.com/Lucklyric/cc-dev-tools\n   ```\n\n2. Install the plugin:\n   ```bash\n   /plugin install gemini@cc-dev-tools\n   ```\n\n3. Restart Claude Code\n\n## Usage\n\n### Basic Invocation\n\nThe skill is automatically invoked when you mention \"Gemini\" or request Gemini assistance:\n\n```\nUser: \"Gemini, design a microservices architecture for e-commerce\"\n```\n\n### Model Selection\n\n**Default (Gemini 3 Pro for ALL tasks)**:\n```bash\ngemini -m gemini-3-pro-preview \"Design a distributed cache\"\n```\n\n**Code Editing (Also uses Gemini 3 Pro)**:\n```bash\ngemini -m gemini-3-pro-preview \"Refactor this function\"\n```\n\n**Version-Based Requests**:\n- \"use 3\" → `gemini-3-pro-preview`\n- \"use 2.5\" → `gemini-2.5-pro`\n- \"use flash\" → `gemini-2.5-flash`\n\n### Session Management\n\n```bash\n# List sessions\ngemini --list-sessions\n\n# Resume most recent\ngemini -r latest\n\n# Resume specific session\ngemini -r 3\n\n# Continue with new prompt\ngemini -r latest \"Continue our discussion about caching\"\n```\n\n### Advanced Options\n\n**With Web Search**:\n```bash\ngemini -m gemini-3-pro-preview -e web_search \"Research React 19 features\"\n```\n\n**With Sandbox**:\n```bash\ngemini -m gemini-2.5-pro -s \"Analyze suspicious code\"\n```\n\n**JSON Output**:\n```bash\ngemini -m gemini-2.5-pro --output-format json \"List design patterns\"\n```\n\n## Configuration\n\n### Default Settings\n\n| Parameter | Default | Override |\n|-----------|---------|----------|\n| Model | `gemini-3-pro-preview` | `-m <model>` |\n| Approval Mode | `auto_edit` | `--approval-mode <mode>` |\n| Sandbox | `false` | `-s` |\n| Output Format | `text` | `--output-format <format>` |\n| Extensions | All enabled | `-e <extensions>` |\n\n### Approval Modes\n\n- **default**: Prompt for all tool actions\n- **auto_edit**: Auto-approve edit operations only (recommended)\n- **yolo** (`-y`): Auto-approve all actions (use with caution)\n\n## Rate Limits\n\n**Free Tier (OAuth)**:\n- 60 requests per minute\n- 1,000 requests per day\n- 1M token context window (Gemini 2.5 Pro)\n\n**Gemini 3 Pro**:\n- May have stricter quotas\n- Automatic fallback to 2.5 models when exhausted\n\n## Model Comparison\n\n| Model | Use Case | Context | Speed | Access |\n|-------|----------|---------|-------|--------|\n| Gemini 3 Pro | ALL tasks (default) | 1M tokens | Medium | Preview |\n| Gemini 2.5 Pro | Fallback for all tasks | 1M tokens | Fast | Free |\n| Gemini 2.5 Flash | Last resort fallback | Unknown | Fastest | Free |\n\n**Note**: Gemini 3 Pro is used for ALL tasks by default. Fallback to older models only when primary is unavailable.\n\n## Troubleshooting\n\n### CLI Not Installed\n```bash\nnpm install -g @google/gemini-cli@latest\n```\n\n### Authentication Required\n```bash\ngemini login\n```\n\n### Rate Limit Exceeded\nWait for reset or upgrade to paid tier\n\n### Gemini 3 Pro Unavailable\n- Enable Preview Features in settings\n- Or use fallback: `gemini-2.5-pro`\n\n### Session Not Found\n```bash\ngemini --list-sessions  # Check available sessions\n```\n\n## Documentation\n\n- **SKILL.md**: Complete skill definition and usage guide\n- **references/gemini-help.md**: Full CLI reference\n- **references/command-patterns.md**: Common command templates\n- **references/session-workflows.md**: Multi-turn conversation patterns\n- **references/model-selection.md**: Model selection decision tree\n\n## Version Compatibility\n\n- **Minimum**: Gemini CLI v0.21.1 (for Gemini 3 Pro support)\n- **Recommended**: Latest stable version\n- **Breaking Changes**: `-p` flag deprecated (use positional prompts)\n\n## When to Use Gemini vs Codex vs Claude\n\n**Use Gemini when:**\n- You need Google's latest AI models\n- Research with web search is important\n- You prefer Google's AI capabilities\n- Codex is unavailable or rate-limited\n\n**Use Codex when:**\n- You need GPT-5.1's reasoning capabilities\n- High-reasoning tasks require OpenAI models\n\n**Use Claude (native) when:**\n- Simple queries within Claude Code's capabilities\n- No external AI needed\n\n## Contributing\n\nThis plugin follows the cc-dev-tools marketplace structure:\n- Plugin root: `plugins/gemini/`\n- Metadata: `.claude-plugin/plugin.json`\n- Skill definition: `skills/gemini/SKILL.md`\n- References: `skills/gemini/references/`\n\n## License\n\nApache-2.0\n\n## Version\n\n1.2.0\n\n## Author\n\n0xasun\n\n## Repository\n\nhttps://github.com/Lucklyric/cc-dev-tools\n",
        "plugins/gemini/skills/gemini/SKILL.md": "---\nname: gemini\nversion: 1.2.0\ndescription: This skill should be used when the user wants to invoke Google Gemini CLI for complex reasoning tasks, research, and AI assistance. Trigger phrases include \"use gemini\", \"ask gemini\", \"run gemini\", \"call gemini\", \"gemini cli\", \"Google AI\", \"Gemini reasoning\", or when users request Google's AI models, need advanced reasoning capabilities, research with web search, or want to continue previous Gemini conversations. Automatically triggers on Gemini-related requests and supports session continuation for iterative development.\n---\n\n# Gemini: Google AI Assistant for Claude Code\n\n---\n\n## DEFAULT MODEL: Gemini 3 Pro\n\n**The default model for ALL Gemini invocations is `gemini-3-pro-preview`.**\n\n- Always use `gemini-3-pro-preview` unless user explicitly requests another model\n- This is the highest reasoning model available\n- Fallback to `gemini-2.5-flash` ONLY on 404/access errors\n\n```bash\n# Default invocation - ALWAYS use gemini-3-pro-preview\ngemini -m gemini-3-pro-preview \"your prompt here\"\n```\n\n---\n\n## CRITICAL: Positional Prompts Required\n\n**REQUIRED**: Use positional prompts for Gemini CLI invocations.\n\n**DEPRECATED**: `-p/--prompt` flag is officially deprecated and will be removed in a future version.\n\n**Examples:**\n- `gemini -m gemini-3-pro-preview \"prompt\"` (CORRECT - positional)\n- `gemini -m gemini-3-pro-preview -p \"prompt\"` (DEPRECATED - avoid using)\n- `gemini -r latest` (CORRECT - session resume)\n\n**Warning from CLI help**: \"[deprecated: Use the positional prompt instead. This flag will be removed in a future version.]\"\n\n**Why?** As of Gemini CLI v0.20.0, the `-p` flag is explicitly marked deprecated. Use positional prompts for forward compatibility.\n\n---\n\n## IMPORTANT: Preview Features & OAuth Free Tier\n\n**For OAuth free tier users in headless mode:**\n\nWhen `previewFeatures: true` in `~/.gemini/settings.json`, the CLI routes ALL requests to Gemini 3 Pro (even `-m gemini-2.5-pro`). Since free tier doesn't have Gemini 3 access, this causes 404 errors.\n\n**Solution**: Disable preview features for reliable headless operation:\n```json\n// ~/.gemini/settings.json\n{\n  \"general\": {\n    \"previewFeatures\": false\n  }\n}\n```\n\n**Plugin Behavior**: This skill automatically falls back to `gemini-2.5-flash` when encountering 404 errors. Flash always works with OAuth free tier.\n\n---\n\n## Trigger Examples\n\nThis skill activates when users say phrases like:\n- \"Use gemini to research this topic\"\n- \"Ask gemini about this design pattern\"\n- \"Run gemini on this analysis\"\n- \"Call gemini for help with this problem\"\n- \"I need Google AI for this task\"\n- \"Get Gemini's reasoning on this\"\n- \"Continue with gemini\" or \"Resume the gemini session\"\n- \"Gemini, help me with...\" or simply \"Gemini\"\n- \"Use Gemini 3\" or \"Use Gemini 2.5\"\n\n## When to Use This Skill\n\nThis skill should be invoked when:\n- User explicitly mentions \"Gemini\" or requests Gemini assistance\n- User needs Google's AI models for reasoning, research, or analysis\n- User requests complex problem-solving or architectural design\n- User needs research capabilities with web search integration\n- User wants to continue a previous Gemini conversation\n- User needs an alternative to Codex or Claude for specific tasks\n\n## How It Works\n\n### Detecting New Gemini Requests\n\nWhen a user makes a request, **default to read-only mode (default approval)** unless they explicitly request file editing:\n\n**Use `gemini-3-pro-preview` for ALL tasks with `default` approval mode:**\n- Architecture, design, reviews, research\n- Explanations, analysis, problem-solving\n- Code analysis and understanding\n- ANY task where user does NOT explicitly request file editing\n\n**Approval Mode Selection:**\n- **`default`** (default): For all tasks - prompts for approval on edits (safe)\n- **`auto_edit`**: ONLY when user explicitly requests file editing\n- **`yolo`**: When user explicitly wants full auto-approval (use with caution)\n\n**⚠️ Explicit Edit Request**: If the user explicitly asks to \"edit files\", \"modify code\", \"write changes\", or \"make edits\" - ONLY then use `--approval-mode auto_edit` to enable file modifications.\n\n**Fallback Chain** (if primary unavailable):\n1. `gemini-3-pro-preview` (primary - highest capability)\n2. `gemini-2.5-pro` (stable general reasoning)\n3. `gemini-2.5-flash` (fast, always available)\n\n**Example requests**: \"Design a distributed cache\", \"Explain CQRS pattern\", \"Analyze this code\"\n\n### Bash CLI Command Structure\n\n**IMPORTANT**: Gemini CLI works differently from Codex - no `exec` subcommand needed. Use positional prompts directly.\n\n#### Default Command (Read-Only) - Use for ALL Tasks\n\n```bash\ngemini -m gemini-3-pro-preview \\\n  \"Design a microservices architecture for e-commerce\"\n```\n\n#### Explicit Edit Request Only - When User Asks to Edit Files\n\n```bash\ngemini -m gemini-3-pro-preview \\\n  --approval-mode auto_edit \\\n  \"Edit this file to refactor the function\"\n```\n\n#### For Session Continuation\n\n```bash\n# Resume most recent session\ngemini -r latest\n\n# Resume specific session by index\ngemini -r 3\n\n# Resume and add new prompt\ngemini -r latest \"Continue our discussion about caching strategies\"\n```\n\n**Why positional prompts?**\n- Simpler, more direct syntax\n- Future-proof (recommended by Gemini CLI)\n- Works in non-TTY environments (like Claude Code's bash)\n- No separate `exec` command needed\n\n### Model Selection Logic\n\n**Use `gemini-3-pro-preview` (default for ALL tasks):**\n- Code editing, refactoring, implementation\n- Designing architecture or system design\n- Conducting research or analysis\n- Explaining complex concepts\n- Planning implementation strategies\n- General problem-solving and advanced reasoning\n\n**Fallback to `gemini-2.5-pro` when:**\n- Gemini 3 Pro unavailable or quota exhausted\n- User explicitly requests \"Gemini 2.5\" or \"use 2.5\"\n- Stable, production-ready tasks\n\n**Fallback to `gemini-2.5-flash` when:**\n- Both Gemini 3 Pro and 2.5 Pro unavailable\n- Fast iterations needed (explicit user request)\n- Simple, quick responses (explicit user request)\n\n### Version-Based Model Mapping\n\nWhen users mention a version number, map to the latest model in that family:\n\n| User Request | Maps To | Actual Model ID |\n|--------------|---------|-----------------|\n| \"use 3\" / \"Gemini 3\" | Latest 3.x Pro | `gemini-3-pro-preview` |\n| \"use 2.5\" | 2.5 Pro | `gemini-2.5-pro` |\n| \"use flash\" | 2.5 Flash | `gemini-2.5-flash` |\n| No version specified | Latest Pro (ALL tasks) | `gemini-3-pro-preview` |\n\n**See**: `references/model-selection.md` for detailed model selection guidance and decision tree.\n\n### Default Configuration\n\nAll Gemini invocations use these defaults unless user specifies otherwise:\n\n| Parameter | Default Value | CLI Flag | Notes |\n|-----------|---------------|----------|-------|\n| Model | `gemini-3-pro-preview` | `-m gemini-3-pro-preview` | For ALL tasks (highest capability) |\n| Model (fallback 1) | `gemini-2.5-pro` | `-m gemini-2.5-pro` | If Gemini 3 Pro unavailable |\n| Model (fallback 2) | `gemini-2.5-flash` | `-m gemini-2.5-flash` | Always works on free tier |\n| Approval Mode (default) | `default` | No flag | Safe default - prompts for edits |\n| Approval Mode (editing) | `auto_edit` | `--approval-mode auto_edit` | Only when user explicitly requests editing |\n| Sandbox | `false` (disabled) | No flag | Sandbox disabled by default |\n| Output Format | `text` | No flag | Human-readable text output |\n| Web Search | Enabled when appropriate | `-e web_search` (if needed) | Context-dependent |\n\n**Rationale for Defaults:**\n- **Gemini 3 Pro for ALL tasks**: Highest capability model, optimized for both reasoning and code\n- **Fallback chain**: gemini-3-pro-preview → gemini-2.5-pro → gemini-2.5-flash\n- **default mode**: Safe default that prompts for approval on edits\n- **auto_edit mode**: Only use when user explicitly requests file editing\n- **No sandbox**: Claude Code environment assumed trusted\n- **Text output**: Default for human consumption (use `--output-format json` for parsing)\n\n**Note**: If you have `previewFeatures: true` in settings, disable it for reliable headless operation (see warning above).\n\n### Error Handling\n\nThe skill handles these common errors gracefully:\n\n#### CLI Not Installed\n\n**Error**: `command not found: gemini`\n\n**Message**: \"Gemini CLI not installed. Install from: https://github.com/google-gemini/gemini-cli\"\n\n**Action**: User must install Gemini CLI before using this skill\n\n#### Authentication Required\n\n**Error**: Output contains \"auth\" or \"authentication\"\n\n**Message**: \"Authentication required. Run: `gemini login` to authenticate with your Google account\"\n\n**Action**: User must authenticate via OAuth or API key\n\n#### Rate Limit Exceeded\n\n**Error**: Output contains \"quota\" or \"rate limit\" or status 429\n\n**Message**: \"Rate limit exceeded (60 req/min, 1000 req/day free tier). Retry in X seconds or upgrade account.\"\n\n**Action**: Wait for rate limit reset or upgrade to paid tier\n\n#### Model Unavailable\n\n**Error**: Output contains \"model not found\" or \"404\" or status 403\n\n**Message**: \"Model unavailable. Trying fallback model...\"\n\n**Action**: Automatically retry with fallback:\n- `gemini-3-pro-preview` unavailable → try `gemini-2.5-pro`\n- `gemini-2.5-pro` unavailable → try `gemini-2.5-flash`\n\n#### Session Not Found\n\n**Error**: Using `-r` flag but session doesn't exist\n\n**Message**: \"Session not found. Use `gemini --list-sessions` to see available sessions.\"\n\n**Action**: User should list sessions or start new session\n\n#### Gemini 3 Pro Access Denied\n\n**Error**: Status 403 or \"preview access required\"\n\n**Message**: \"Gemini 3 Pro requires preview access. Enable Preview Features in settings or use `gemini-2.5-pro` instead.\"\n\n**Action**: Either enable preview features, get API key, or use 2.5 models\n\n**See**: `references/gemini-help.md` for complete CLI reference and troubleshooting.\n\n---\n\n## Examples\n\n### Basic Invocation (General Reasoning)\n\n```bash\n# Design system architecture\ngemini -m gemini-3-pro-preview \"Design a scalable payment processing system\"\n\n# Research with web search\ngemini -m gemini-3-pro-preview -e web_search \"Research latest React 19 features\"\n\n# Explain complex concept\ngemini -m gemini-3-pro-preview \"Explain the CAP theorem with real-world examples\"\n```\n\n### Code Editing Tasks\n\n```bash\n# Refactoring (uses gemini-3-pro-preview for all tasks)\ngemini -m gemini-3-pro-preview \"Refactor this function for better readability\"\n\n# Fix syntax errors\ngemini -m gemini-3-pro-preview \"Fix the syntax errors in this JavaScript code\"\n\n# Optimize performance\ngemini -m gemini-3-pro-preview \"Optimize this database query for better performance\"\n```\n\n### Session Management\n\n```bash\n# Start a session (automatic)\ngemini -m gemini-3-pro-preview \"Design an authentication system\"\n\n# List available sessions\ngemini --list-sessions\n\n# Resume most recent\ngemini -r latest\n\n# Resume specific session\ngemini -r 3\n\n# Continue with new prompt\ngemini -r latest \"Now help me implement the login flow\"\n```\n\n### With Output Formatting\n\n```bash\n# JSON output for parsing\ngemini -m gemini-2.5-pro --output-format json \"List top 5 design patterns\"\n\n# Streaming JSON for real-time\ngemini -m gemini-2.5-pro --output-format stream-json \"Explain async patterns\"\n```\n\n### Approval Modes\n\n```bash\n# Default mode (prompt for all)\ngemini -m gemini-2.5-pro --approval-mode default \"Review this code\"\n\n# Auto-edit (auto-approve edits only)\ngemini -m gemini-2.5-pro --approval-mode auto_edit \"Refactor this module\"\n\n# YOLO mode (auto-approve ALL - use with caution)\ngemini -m gemini-2.5-pro --approval-mode yolo \"Deploy to production\"\n```\n\n### Sandbox Mode\n\n```bash\n# Enable sandbox for untrusted code\ngemini -m gemini-2.5-pro -s \"Analyze this suspicious code snippet\"\n\n# Disabled by default (trusted environment)\ngemini -m gemini-2.5-pro \"Review this internal codebase\"\n```\n\n### Extensions & MCP Integration\n\nGemini CLI supports extensions and Model Context Protocol (MCP) servers for enhanced functionality.\n\n```bash\n# List available extensions\ngemini --list-extensions\n\n# Use specific extensions (web search, code analysis, etc.)\ngemini -m gemini-3-pro-preview -e web_search \"Research React 19 features\"\n\n# Use all extensions (default)\ngemini -m gemini-3-pro-preview \"Design system architecture\"\n```\n\n**Note**: This plugin does not implement custom extensions or MCP servers. Users can configure extensions and MCP servers through the Gemini CLI's standard configuration in `~/.gemini/settings.json`. Extensions are enabled by default when appropriate for the task.\n\n### Additional Directories (`--include-directories`) (v0.20.0+)\n\nInclude additional directories in workspace context:\n\n```bash\n# Single directory\ngemini -m gemini-3-pro-preview --include-directories /shared/libs \"task\"\n\n# Multiple directories (comma-separated)\ngemini -m gemini-3-pro-preview --include-directories /path1,/path2 \"task\"\n\n# Multiple directories (repeated flag)\ngemini -m gemini-3-pro-preview --include-directories /path1 --include-directories /path2 \"task\"\n```\n\n**Note**: Disabled in restrictive sandbox profiles.\n\n---\n\n## File Context Passing\n\n**IMPORTANT**: Pass file paths to Gemini CLI instead of embedding file content in prompts. This enables Gemini to read files autonomously.\n\n**Quick reference**:\n- Use `--include-directories /path` for additional directories\n- Use `@path/to/file` syntax for explicit file references\n\n```bash\n# Example: analyze file with explicit @ syntax\ngemini -m gemini-3-pro-preview \\\n  \"Analyze @src/auth.ts and compare with @src/session.ts\"\n\n# Example: multi-directory analysis\ngemini -m gemini-3-pro-preview \\\n  --include-directories /shared/libs \\\n  \"Review how auth module uses shared utilities\"\n```\n\n**See**: `references/file-context.md` for complete file context documentation.\n\n---\n\n### Accessibility (`--screen-reader`) (v0.20.0+)\n\nEnable screen reader mode for accessibility:\n\n```bash\ngemini -m gemini-3-pro-preview --screen-reader \"task\"\n```\n\n### Interactive with Prompt (`-i/--prompt-interactive`) (v0.20.0+)\n\nExecute a prompt and continue in interactive mode:\n\n```bash\ngemini -m gemini-3-pro-preview -i \"initial prompt here\"\n```\n\n**Note**: Limited applicability for Claude Code skills which use non-interactive mode.\n\n### Experimental ACP Mode (`--experimental-acp`)\n\nStart agent in Agent Control Protocol mode for programmatic interaction:\n\n```bash\ngemini --experimental-acp \"task\"\n```\n\n**Note**: Experimental feature. Works with `GEMINI_API_KEY` environment variable.\n\n---\n\n## Reference Documentation\n\nFor detailed information, consult these reference files:\n\n### Core References\n- **`references/file-context.md`** - File and directory context passing guide\n- **`references/model-selection.md`** - Model selection decision tree and version mapping\n\n### Workflow References\n- **`references/command-patterns.md`** - Common command templates organized by use case\n- **`references/session-workflows.md`** - Multi-turn conversation patterns and best practices\n\n### CLI References\n- **`references/gemini-help.md`** - Complete Gemini CLI help output and flag reference\n\n---\n\n## Tips & Best Practices\n\n1. **Always Specify Model**: Use `-m` flag explicitly for predictable behavior\n2. **Use Positional Prompts**: Prefer `gemini \"prompt\"` over deprecated `-p` flag\n3. **Enable Web Search When Needed**: Add `-e web_search` for research tasks\n4. **Resume Sessions for Complex Tasks**: Use `-r latest` for multi-turn conversations\n5. **Start with Gemini 3 Pro**: Default to `gemini-3-pro-preview`, fallback to 2.5 models\n6. **Use Appropriate Approval Mode**: `auto_edit` for code, `default` for untrusted tasks\n7. **Monitor Rate Limits**: 60 req/min, 1000 req/day on free tier\n8. **Check CLI Availability**: Validate `command -v gemini` before invocation\n\n---\n\n## Differences from Codex\n\n| Feature | Codex CLI | Gemini CLI |\n|---------|-----------|------------|\n| Invocation | `codex exec \"prompt\"` | `gemini \"prompt\"` |\n| Subcommand | Required (`exec`) | Not needed |\n| Positional Prompts | Not supported | Preferred |\n| Session Resume | `codex exec resume --last` | `gemini -r latest` |\n| Models | GPT-5.2, GPT-5.2-Codex | Gemini 3 Pro, 2.5 Pro/Flash |\n| Provider | OpenAI (via Codex) | Google |\n\n---\n\n## When to Use Gemini vs Codex vs Claude\n\n**Use Gemini when:**\n- You need Google's latest models\n- Research with web search is important\n- You prefer Google's AI capabilities\n- Codex is unavailable or rate-limited\n- Task benefits from Gemini's strengths\n\n**Use Codex when:**\n- You need GPT-5.1's reasoning capabilities\n- Task requires high-reasoning model\n- Code editing with specific Codex optimizations\n- You're already using Codex workflow\n\n**Use Claude (native) when:**\n- Simple queries within Claude Code's capabilities\n- No external AI needed\n- Quick responses preferred\n- Task doesn't require specialized models\n\n---\n\n## Version Compatibility\n\n**Minimum Gemini CLI**: v0.23.0\n\nFor questions or issues, consult `references/gemini-help.md` or run `gemini --help`.\n",
        "plugins/gemini/skills/gemini/references/command-patterns.md": "# Gemini CLI Command Patterns\n\n**Purpose**: Common command templates for Gemini CLI integration\n**Version**: v0.16.0+\n**Last Updated**: 2025-11-18\n\n## Basic Invocation Patterns\n\n### One-Shot Queries (Headless Mode)\n\n```bash\n# Preferred syntax (positional prompt)\ngemini -m gemini-3-pro-preview \"Explain the observer pattern in software design\"\n\n# Alternative (deprecated -p flag, still works)\ngemini -m gemini-3-pro-preview -p \"Explain the observer pattern in software design\"\n\n# With stdin input\necho \"function add(a, b) { return a + b; }\" | gemini -m gemini-3-pro-preview \"Explain this code\"\n```\n\n### Model Selection\n\n```bash\n# Use Gemini 3 Pro (default for complex reasoning)\ngemini -m gemini-3-pro-preview \"Design a microservices architecture\"\n\n# Use Gemini 2.5 Pro (stable, general reasoning)\ngemini -m gemini-2.5-pro \"Review this API design\"\n\n# Use Gemini 2.5 Flash (faster, code-focused)\ngemini -m gemini-2.5-flash \"Refactor this function for performance\"\n```\n\n### Version-Based Model Selection\n\nWhen user requests a specific version, map to the latest model in that family:\n\n```bash\n# User says \"use Gemini 3\" or \"use 3\" → Latest 3.x Pro\ngemini -m gemini-3-pro-preview \"Design a distributed caching system\"\n\n# User says \"use Gemini 2.5\" for general tasks → 2.5 Pro\ngemini -m gemini-2.5-pro \"Explain the CAP theorem with examples\"\n\n# User says \"use Gemini 2.5\" for code editing → 2.5 Flash\ngemini -m gemini-2.5-flash \"Refactor this module for readability\"\n\n# No version specified → Default to latest Pro\ngemini -m gemini-3-pro-preview \"Research microservices best practices\"\n```\n\n**Fallback Strategy** (when primary model unavailable):\n\n```bash\n# Try Gemini 3 Pro first\ngemini -m gemini-3-pro-preview \"Complex reasoning task\" 2>&1\n\n# If quota exhausted, fallback to 2.5 Pro (general) or 2.5 Flash (code)\nif [ $? -ne 0 ]; then\n    # For general reasoning\n    gemini -m gemini-2.5-pro \"Complex reasoning task\"\n\n    # OR for code editing\n    # gemini -m gemini-2.5-flash \"Complex reasoning task\"\nfi\n```\n\n## Output Formatting\n\n### Text Output (Default)\n\n```bash\ngemini -m gemini-3-pro-preview \"What is dependency injection?\"\n```\n\n### JSON Output (Programmatic)\n\n```bash\ngemini -m gemini-3-pro-preview --output-format json \"List top 5 design patterns\"\n```\n\n### Streaming JSON (Real-time)\n\n```bash\ngemini -m gemini-3-pro-preview --output-format stream-json \"Explain async/await in JavaScript\"\n```\n\n## Approval Modes & Security\n\n### Default Mode (Prompt for all actions)\n\n```bash\n# Explicit\ngemini -m gemini-3-pro-preview --approval-mode default \"Refactor this code\"\n\n# Implicit (no flag = default)\ngemini -m gemini-3-pro-preview \"Refactor this code\"\n```\n\n### Auto-Edit Mode (Auto-approve edit tools only)\n\n```bash\ngemini -m gemini-3-pro-preview --approval-mode auto_edit \"Fix bugs in this file\"\n```\n\n### YOLO Mode (Auto-approve all tools)\n\n```bash\n# Long form\ngemini -m gemini-3-pro-preview --approval-mode yolo \"Deploy to production\"\n\n# Short form\ngemini -m gemini-3-pro-preview -y \"Deploy to production\"\n```\n\n## Sandbox Mode\n\n### Enable Sandbox\n\n```bash\ngemini -m gemini-3-pro-preview -s \"Run untrusted code analysis\"\n```\n\n### Disable Sandbox (Default)\n\n```bash\ngemini -m gemini-3-pro-preview \"Analyze trusted codebase\"\n```\n\n## Session Management\n\n### List Sessions\n\n```bash\ngemini --list-sessions\n```\n\n### Resume Sessions\n\n```bash\n# Resume most recent session\ngemini -r latest\n\n# Resume specific session by index\ngemini -r 3\n\n# Resume and add new prompt\ngemini -r latest \"Continue from where we left off\"\n```\n\n### Delete Sessions\n\n```bash\ngemini --delete-session 5\n```\n\n## Extensions & MCP\n\n### List Available Extensions\n\n```bash\ngemini -l\n# or\ngemini --list-extensions\n```\n\n### Use Specific Extensions\n\n```bash\ngemini -e web_search,code_analysis \"Research React best practices\"\n```\n\n### Use All Extensions (Default)\n\n```bash\ngemini \"Research React best practices\"\n```\n\n## Workspace Context\n\n### Include Additional Directories\n\n```bash\ngemini --include-directories ./lib,./tests \"Analyze the full project\"\n\n# Or multiple flags\ngemini --include-directories ./lib --include-directories ./tests \"Analyze project\"\n```\n\n## Combined Patterns\n\n### Production-Safe Code Review\n\n```bash\ngemini -m gemini-2.5-pro \\\n  --approval-mode default \\\n  --output-format json \\\n  \"Review this pull request for security issues\"\n```\n\n### Fast Code Refactoring\n\n```bash\ngemini -m gemini-2.5-flash \\\n  --approval-mode auto_edit \\\n  \"Refactor these functions for better performance\"\n```\n\n### Research with Web Search\n\n```bash\ngemini -m gemini-3-pro-preview \\\n  -e web_search \\\n  --output-format text \\\n  \"What are the latest trends in GraphQL?\"\n```\n\n### Sandbox Testing\n\n```bash\ngemini -m gemini-2.5-pro \\\n  -s \\\n  --approval-mode default \\\n  \"Test this suspicious code snippet\"\n```\n\n## Claude Code Integration Patterns\n\n### Skill Invocation (via Claude)\n\n```bash\n# Basic invocation from skill\ngemini -m gemini-3-pro-preview \"Explain microservices\"\n\n# With explicit approval mode\ngemini -m gemini-2.5-pro --approval-mode auto_edit \"Fix type errors\"\n\n# With JSON output for parsing\ngemini -m gemini-2.5-flash --output-format json \"List API endpoints\"\n```\n\n### Error Handling Pattern\n\n```bash\n# Check CLI availability\nif ! command -v gemini &> /dev/null; then\n    echo \"Error: Gemini CLI not installed\"\n    exit 1\nfi\n\n# Execute with error capture\ngemini -m gemini-3-pro-preview \"task\" 2>&1 || echo \"Gemini CLI failed\"\n```\n\n## Model Selection by Task Type\n\n### Complex Reasoning (General)\n\n```bash\ngemini -m gemini-3-pro-preview \"Design system architecture\"\n```\n\n### Code Review & Analysis\n\n```bash\ngemini -m gemini-2.5-pro \"Review this pull request\"\n```\n\n### Fast Code Editing\n\n```bash\ngemini -m gemini-2.5-flash \"Fix syntax errors in this file\"\n```\n\n## Anti-Patterns (Avoid These)\n\n```bash\n# ❌ Using -p flag (deprecated)\ngemini -p \"prompt\"  # Will be removed in future\n\n# ❌ Using -i for headless mode\ngemini -i \"prompt\"  # This starts interactive mode, not one-shot\n\n# ❌ Hardcoding model without fallback\n# Always have fallback logic when gemini-3-pro-preview unavailable\n\n# ❌ Using YOLO mode without user confirmation\n# Always require explicit user approval for YOLO mode\n```\n\n## Best Practices\n\n1. **Prefer Positional Prompts**: Use `gemini \"prompt\"` instead of `gemini -p \"prompt\"`\n2. **Specify Model Explicitly**: Always use `-m` flag for predictable behavior\n3. **Use Appropriate Approval Mode**: Default for untrusted tasks, auto_edit for code editing\n4. **Enable Sandbox for Unknown Code**: Use `-s` when analyzing untrusted input\n5. **Format Output for Parsing**: Use `--output-format json` when processing results programmatically\n6. **Resume Sessions When Needed**: Use `-r latest` for multi-turn conversations\n7. **Validate CLI Availability**: Always check `command -v gemini` before invocation\n\n## See Also\n\n- `gemini-help.md` - Full CLI reference\n- `session-workflows.md` - Session continuation patterns\n- `model-selection.md` - Model selection guidance\n",
        "plugins/gemini/skills/gemini/references/file-context.md": "# File Context Passing\n\n**IMPORTANT**: When users reference files or directories in their requests, pass file paths to Gemini CLI instead of embedding file content in the prompt. This enables Gemini to read and explore files autonomously.\n\n## Benefits\n\n- **Reduced token usage**: File content not embedded in prompts\n- **Large file support**: Gemini handles files natively without truncation\n- **Better performance**: Gemini optimizes file reading internally\n- **Unchanged workflow**: Works with natural file references\n\n## Directory Context (`--include-directories` flag)\n\nUse `--include-directories` to include additional directories:\n\n```bash\n# Include shared libraries directory\ngemini -m gemini-3-pro-preview \\\n  --include-directories /shared/libs \\\n  \"Review how the auth module uses shared utilities\"\n\n# Include multiple directories (comma-separated)\ngemini -m gemini-3-pro-preview \\\n  --include-directories /shared/libs,/config \\\n  \"Analyze configuration usage across the codebase\"\n\n# Include multiple directories (repeated flag)\ngemini -m gemini-3-pro-preview \\\n  --include-directories /shared/libs \\\n  --include-directories /config \\\n  \"Analyze configuration usage\"\n```\n\n## File Context Examples\n\n```bash\n# Analyze a specific file (include path in prompt)\ngemini -m gemini-3-pro-preview \\\n  \"Analyze the implementation in src/auth/login.ts\"\n\n# Review multiple files (paths in prompt)\ngemini -m gemini-3-pro-preview \\\n  \"Compare the implementations in src/v1/api.ts and src/v2/api.ts\"\n\n# Work with files across directories\ngemini -m gemini-3-pro-preview \\\n  --include-directories /shared/types \\\n  \"Check how src/services/user.ts uses types from /shared/types\"\n```\n\n## Directory Context Examples\n\n```bash\n# Analyze entire directory\ngemini -m gemini-3-pro-preview \\\n  \"Review the architecture of the src/ module\"\n\n# Multi-directory codebase analysis\ngemini -m gemini-3-pro-preview \\\n  --include-directories /frontend/src,/backend/src \\\n  \"Analyze how frontend and backend communicate\"\n```\n\n## Path Detection\n\nThe skill automatically detects file/directory paths in user requests:\n\n**Auto-detected patterns**:\n- Paths with separators: `src/auth/login.ts`, `lib/utils.py`\n- Relative paths: `./config.json`, `../shared/types.ts`\n- Absolute paths: `/home/user/project/file.rs`\n- Common extensions: `.ts`, `.js`, `.py`, `.rs`, `.go`, etc.\n\n**Explicit syntax** (`@` prefix):\n- Use `@path/to/file` for explicit file references\n- Example: \"Analyze @src/auth.ts and @src/session.ts\"\n- Multiple files: \"Compare @v1/api.ts with @v2/api.ts\"\n- Directories: \"Review @src/services/ architecture\"\n\n```bash\n# Complete example using @ prefix syntax\ngemini -m gemini-3-pro-preview \\\n  \"Analyze @src/auth.ts and compare with @src/session.ts\"\n\n# Directory reference with @ prefix\ngemini -m gemini-3-pro-preview \\\n  \"Review the structure of @src/components/ directory\"\n```\n\n## Path Resolution\n\n- Relative paths are resolved against the current working directory\n- Absolute paths are passed directly to Gemini\n- The skill converts all paths to absolute before invoking CLI\n\n## When NOT to Embed File Content\n\n**DO NOT** read files and embed content in prompts when:\n- User mentions specific file paths in their request\n- Request involves analyzing, reviewing, or understanding code\n- Working with large files (>10KB)\n- Multi-file operations are requested\n\n**Instead**: Pass file paths to Gemini and let it read files autonomously.\n\n## Edge Cases\n\n- **Missing files**: Gemini reports the error with context\n- **Files outside workspace**: Use `--include-directories` to include external directories\n- **Binary files**: Gemini determines if it can process the file\n- **Large directories**: Gemini handles exploration internally\n",
        "plugins/gemini/skills/gemini/references/gemini-help.md": "# Gemini CLI Help Reference\n\n**Version**: v0.20.0\n**Source**: Output from `gemini --help`\n**Last Updated**: 2025-12-10\n\n## Command Overview\n\n```\nUsage: gemini [options] [command]\n\nGemini CLI - Launch an interactive CLI, use -p/--prompt for non-interactive mode\n```\n\n## Commands\n\n- `gemini [query..]` - Launch Gemini CLI (default)\n- `gemini mcp` - Manage MCP servers\n- `gemini extensions <command>` - Manage Gemini CLI extensions\n\n## Positionals\n\n- `query` - Positional prompt. Defaults to one-shot; use `-i`/`--prompt-interactive` for interactive mode\n\n## Options\n\n### Core Flags\n\n- `-d, --debug` - Run in debug mode [boolean] [default: false]\n- `-m, --model` - Model to use [string]\n- `-p, --prompt` - Prompt text appended to stdin input [string]\n  **DEPRECATED**: Use positional prompt instead. This flag will be removed in a future version.\n- `-i, --prompt-interactive` - Execute prompt and continue in interactive mode [string]\n- `-s, --sandbox` - Run in sandbox [boolean]\n\n### Approval & Security\n\n- `-y, --yolo` - Automatically accept all actions (YOLO mode) [boolean] [default: false]\n- `--approval-mode` - Set approval mode [string]\n  **Choices**: `default` (prompt for approval), `auto_edit` (auto-approve edit tools), `yolo` (auto-approve all tools)\n- `--allowed-tools` - Tools allowed to run without confirmation [array]\n\n### Session Management\n\n- `-r, --resume` - Resume previous session [string]\n  Use `\"latest\"` for most recent or index number (e.g., `--resume 5`)\n- `--list-sessions` - List available sessions for current project and exit [boolean]\n- `--delete-session` - Delete session by index number [string]\n\n### Extensions & MCP\n\n- `-e, --extensions` - List of extensions to use [array]\n  If not provided, all extensions are used\n- `-l, --list-extensions` - List all available extensions and exit [boolean]\n- `--allowed-mcp-server-names` - Allowed MCP server names [array]\n\n### Workspace & Context (v0.20.0+)\n\n- `--include-directories` - Additional directories to include in workspace [array]\n  Comma-separated or multiple `--include-directories` flags\n- `--screen-reader` - Enable screen reader mode for accessibility [boolean]\n\n### Output\n\n- `-o, --output-format` - Format of CLI output [string]\n  **Choices**: `text`, `json`, `stream-json`\n\n### Meta\n\n- `-v, --version` - Show version number [boolean]\n- `-h, --help` - Show help [boolean]\n- `--experimental-acp` - Start agent in ACP mode [boolean]\n\n## Full CLI Output (v0.20.0)\n\n```\nUsage: gemini [options] [command]\n\nGemini CLI - Launch an interactive CLI, use -p/--prompt for non-interactive mode\n\nCommands:\n  gemini [query..]             Launch Gemini CLI  [default]\n  gemini mcp                   Manage MCP servers\n  gemini extensions <command>  Manage Gemini CLI extensions.  [aliases: extension]\n\nPositionals:\n  query  Positional prompt. Defaults to one-shot; use -i/--prompt-interactive for interactive.\n\nOptions:\n  -d, --debug                     Run in debug mode?  [boolean] [default: false]\n  -m, --model                     Model  [string]\n  -p, --prompt                    Prompt. Appended to input on stdin (if any).  [deprecated: Use the positional prompt instead. This flag will be removed in a future version.] [string]\n  -i, --prompt-interactive        Execute the provided prompt and continue in interactive mode  [string]\n  -s, --sandbox                   Run in sandbox?  [boolean]\n  -y, --yolo                      Automatically accept all actions (aka YOLO mode)?  [boolean] [default: false]\n      --approval-mode             Set the approval mode: default (prompt for approval), auto_edit (auto-approve edit tools), yolo (auto-approve all tools)  [string] [choices: \"default\", \"auto_edit\", \"yolo\"]\n      --experimental-acp          Starts the agent in ACP mode  [boolean]\n      --allowed-mcp-server-names  Allowed MCP server names  [array]\n      --allowed-tools             Tools that are allowed to run without confirmation  [array]\n  -e, --extensions                A list of extensions to use. If not provided, all extensions are used.  [array]\n  -l, --list-extensions           List all available extensions and exit.  [boolean]\n  -r, --resume                    Resume a previous session. Use \"latest\" for most recent or index number (e.g. --resume 5)  [string]\n      --list-sessions             List available sessions for the current project and exit.  [boolean]\n      --delete-session            Delete a session by index number (use --list-sessions to see available sessions).  [string]\n      --include-directories       Additional directories to include in the workspace (comma-separated or multiple --include-directories)  [array]\n      --screen-reader             Enable screen reader mode for accessibility.  [boolean]\n  -o, --output-format             The format of the CLI output.  [string] [choices: \"text\", \"json\", \"stream-json\"]\n  -v, --version                   Show version number  [boolean]\n  -h, --help                      Show help  [boolean]\n```\n\n## Usage Patterns\n\n### Headless/Non-Interactive Mode\n\n```bash\n# Preferred: Positional prompt\ngemini -m gemini-3-pro-preview \"Explain quicksort algorithm\"\n\n# Deprecated but still works: -p flag\ngemini -m gemini-3-pro-preview -p \"Explain quicksort algorithm\"\n\n# With output formatting\ngemini -m gemini-3-pro-preview --output-format json \"Analyze this code\"\n\n# With approval mode\ngemini -m gemini-3-pro-preview --approval-mode auto_edit \"Refactor this function\"\n```\n\n### Session Management\n\n```bash\n# List sessions\ngemini --list-sessions\n\n# Resume latest session\ngemini -r latest\n\n# Resume specific session by index\ngemini -r 5\n\n# Delete session\ngemini --delete-session 3\n```\n\n### Interactive Mode\n\n```bash\n# Start interactive session\ngemini\n\n# Execute prompt then continue interactively\ngemini -i \"Start by explaining React hooks\"\n```\n\n### Workspace Expansion (v0.20.0+)\n\n```bash\n# Include additional directories\ngemini -m gemini-3-pro-preview --include-directories /shared/libs \"task\"\n\n# Multiple directories (comma-separated)\ngemini -m gemini-3-pro-preview --include-directories /path1,/path2 \"task\"\n\n# Multiple directories (repeated flag)\ngemini -m gemini-3-pro-preview --include-directories /path1 --include-directories /path2 \"task\"\n```\n\n### Accessibility (v0.20.0+)\n\n```bash\n# Enable screen reader mode\ngemini -m gemini-3-pro-preview --screen-reader \"task\"\n```\n\n## Important Notes\n\n1. **Positional Prompts**: Required as of v0.20.0 (preferred over `-p` flag)\n2. **Deprecation Warning**: `-p/--prompt` flag officially deprecated, will be removed in future versions\n3. **Session Resume**: Fully supported via `-r/--resume` flag\n4. **Approval Modes**: Three levels (default, auto_edit, yolo)\n5. **Output Formats**: Text (default), JSON, or streaming JSON for programmatic use\n6. **MCP Integration**: Built-in support for Model Context Protocol servers\n7. **Extensions**: Plugin system for custom commands and functionality\n8. **Accessibility**: New `--screen-reader` flag for screen reader support\n\n## Session Index Format\n\nSessions are identified by:\n- `\"latest\"` keyword for most recent session\n- Integer index (e.g., `0`, `1`, `2`, etc.)\n- Retrieved via `--list-sessions` command\n\n## Compatibility Notes\n\n- **Minimum Version**: v0.20.0\n- **Changes in v0.20.0**:\n  - `-p` flag officially deprecated (use positional prompts)\n  - New `--include-directories` flag for workspace expansion\n  - New `--screen-reader` flag for accessibility\n  - New `--experimental-acp` flag for Agent Control Protocol mode\n- **Future Deprecations**: `-p/--prompt` flag will be removed\n\n## See Also\n\n- `command-patterns.md` - Common command templates\n- `session-workflows.md` - Multi-turn conversation patterns\n- `model-selection.md` - Model selection guidance\n",
        "plugins/gemini/skills/gemini/references/model-selection.md": "# Gemini Model Selection Guide\n\n**Purpose**: Guide for selecting the right Gemini model for your task\n**Version**: v0.21.1+\n**Last Updated**: 2025-12-21\n\n## Quick Reference\n\n| Task Type | Recommended Model | Reason |\n|-----------|------------------|---------|\n| ALL tasks (default) | `gemini-3-pro-preview` | Highest capability, best for all problems |\n| Fallback (if 3 Pro unavailable) | `gemini-2.5-pro` | Stable, reliable, 1M context |\n| Last resort fallback | `gemini-2.5-flash` | Always available on free tier |\n\n**Note**: Use `gemini-3-pro-preview` for ALL tasks by default. Fallback to older models only when primary is unavailable.\n\n## Version-Based Model Mapping\n\n### Concept\n\nWhen users mention a version number (e.g., \"use Gemini 3\"), map to the latest model in that family for future-proofing.\n\n### Current Mappings (as of Dec 2025)\n\n| User Request | Maps To | Actual Model ID | Status | Notes |\n|--------------|---------|-----------------|--------|-------|\n| \"Gemini 3\" or \"use 3\" | Latest 3.x Pro | `gemini-3-pro-preview` | Preview | Requires preview access |\n| \"Gemini 2.5\" or \"use 2.5\" | 2.5 Pro | `gemini-2.5-pro` | Stable | 1M tokens context |\n| \"use flash\" | 2.5 Flash | `gemini-2.5-flash` | Stable | Fast, always available |\n| No version specified | Latest Pro (ALL tasks) | `gemini-3-pro-preview` | Preview | **DEFAULT** |\n\n### Future-Proofing Strategy\n\n```\nUser says \"3\" → Plugin maps to latest_3x_pro\n                 Currently: gemini-3-pro-preview\n                 Future:    gemini-3-pro (when stable)\n                           gemini-3.1-pro (when released)\n\nUser says \"2.5\" → Plugin maps to gemini-2.5-pro\n                  (No longer task-differentiated)\n\nNo version specified → gemini-3-pro-preview for ALL tasks\n```\n\n**Maintenance**: Update mapping table when new models release\n\n## Model Family Overview\n\n### Gemini 3 Family (Latest - Preview)\n\n**gemini-3-pro-preview**\n- **Status**: Preview (requires access)\n- **Context**: 1M tokens\n- **Strengths**: Cutting-edge reasoning, complex problem-solving\n- **Use Cases**: System architecture, complex algorithms, research\n- **Access**: Google AI Ultra subscribers, paid API keys, or waitlist\n- **Availability**: May be quota-limited on free tier\n\n```bash\ngemini -m gemini-3-pro-preview \"Design a distributed caching system\"\n```\n\n### Gemini 2.5 Family (Stable)\n\n**gemini-2.5-pro**\n- **Status**: Stable, production-ready\n- **Context**: 1M tokens\n- **Strengths**: General reasoning, balanced performance\n- **Use Cases**: Code review, technical writing, general assistance\n- **Access**: Free tier (60 req/min, 1000 req/day)\n\n```bash\ngemini -m gemini-2.5-pro \"Review this API design for best practices\"\n```\n\n**gemini-2.5-flash**\n- **Status**: Stable, production-ready\n- **Context**: Unknown (likely lower than Pro)\n- **Strengths**: Speed, code generation/editing\n- **Use Cases**: Quick refactoring, syntax fixes, fast iterations\n- **Access**: Free tier (60 req/min, 1000 req/day)\n\n```bash\ngemini -m gemini-2.5-flash \"Refactor this function for better performance\"\n```\n\n**gemini-2.5-flash-lite** (if available)\n- **Status**: Stable (check CLI for availability)\n- **Strengths**: Highest throughput, lowest cost\n- **Use Cases**: High-volume simple tasks\n- **Note**: May have reduced capabilities\n\n## Task-Based Selection\n\n### Single Model for All Tasks\n\n**Use `gemini-3-pro-preview` for ALL task types:**\n\n```\nALL Tasks (Any Complexity)\n    ↓\n    gemini-3-pro-preview (primary)\n    ↓ (if unavailable)\n    gemini-2.5-pro (fallback 1)\n    ↓ (if unavailable)\n    gemini-2.5-flash (fallback 2)\n```\n\n### By Task Type (All Use Same Model)\n\n**Research & Design**\n- Model: `gemini-3-pro-preview`\n- Example: \"Design a microservices architecture\"\n\n**Code Review & Analysis**\n- Model: `gemini-3-pro-preview`\n- Example: \"Review this pull request for bugs\"\n\n**Code Generation & Editing**\n- Model: `gemini-3-pro-preview`\n- Example: \"Refactor this code for readability\"\n\n**General Questions**\n- Model: `gemini-3-pro-preview`\n- Example: \"Explain the CAP theorem\"\n\n**Rationale**: Gemini 3 Pro provides highest capability for all task types. No task differentiation needed.\n\n## Selection Decision Tree\n\n```\nSTART: User makes request\n  │\n  ├─> User specifies model? ─────────────────┐\n  │   (e.g., -m gemini-2.5-pro)               │\n  │   YES ──> Use specified model ──> END     │\n  │   NO ───> Continue                        │\n  │                                           │\n  ├─> User mentions version? ────────────────┤\n  │   (e.g., \"use 3\" or \"use 2.5\")           │\n  │   YES ──> Map to latest in family ──> END│\n  │   NO ───> Continue                        │\n  │                                           │\n  ├─> Use gemini-3-pro-preview (ALL tasks)   │\n  │                                           │\n  └─> Apply fallback if primary unavailable  │\n      (quota exhausted, access denied)        │\n      gemini-3-pro-preview → gemini-2.5-pro  │\n                          → gemini-2.5-flash │\n      └──────────────────────────────────────┘\n```\n\n## Fallback Strategy\n\n### Unified Fallback Chain\n\n**Reason**: Quota exhausted, access denied, or service issue\n\n**Fallback Logic** (same for ALL task types):\n```\ngemini-3-pro-preview unavailable\n  │\n  └─> gemini-2.5-pro\n      │\n      └─> gemini-2.5-flash (always available)\n```\n\n**Implementation Pattern**:\n```bash\n# Try Gemini 3 Pro first (all tasks)\ngemini -m gemini-3-pro-preview \"Your task\" 2>&1\n\n# If fails with quota/access error, retry with fallback\nif [ $? -ne 0 ]; then\n    gemini -m gemini-2.5-pro \"Your task\"\nfi\n```\n\n## Free Tier Considerations\n\n### Rate Limits (OAuth Free Tier)\n\n- **60 requests per minute**\n- **1,000 requests per day**\n- **Context**: 1M tokens with Gemini 2.5 Pro\n\n### Quota Management\n\n**Gemini 3 Pro (Preview)**:\n- May have stricter quotas\n- May auto-switch to lower tier when exhausted\n- Monitor for 429 (rate limit) or 403 (quota exceeded) errors\n\n**Gemini 2.5 Models**:\n- More generous free tier quotas\n- Better availability\n- Recommended for high-volume usage\n\n### Cost Optimization\n\n```\nHigh volume, simple tasks → gemini-2.5-flash (fastest, cheapest)\nModerate volume, general → gemini-2.5-pro (balanced)\nLow volume, complex → gemini-3-pro-preview (best quality)\n```\n\n## Model Capabilities Comparison\n\n| Capability | Gemini 3 Pro | Gemini 2.5 Pro | Gemini 2.5 Flash |\n|-----------|--------------|----------------|------------------|\n| Reasoning | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| Code Generation | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |\n| Speed | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |\n| Context Window | 1M tokens | 1M tokens | Unknown |\n| Stability | Preview | Stable | Stable |\n| Free Tier Access | Limited | Yes | Yes |\n\n## Access Requirements\n\n### Gemini 3 Pro Access\n\n**Preview Features Required**:\n1. Update Gemini CLI to v0.16.x+\n2. Enable Preview Features in CLI settings\n3. Have one of:\n   - Google AI Ultra subscription\n   - Paid Gemini API key\n   - Vertex API key with Gemini 3 access\n   - Waitlist approval (free tier users)\n\n**Verification**:\n```bash\ngemini -m gemini-3-pro-preview \"test\" 2>&1\n\n# Success: Model responds\n# Failure: 404 \"model not found\" or 403 \"access denied\"\n```\n\n### Gemini 2.5 Access\n\n**Always Available** (free tier):\n- `gemini-2.5-pro`\n- `gemini-2.5-flash`\n\nNo special access required.\n\n## Best Practices\n\n1. **Default to Gemini 3 Pro for ALL tasks**: Use `gemini-3-pro-preview` regardless of task type\n2. **Implement Graceful Fallback**: Use chain: gemini-3-pro-preview → gemini-2.5-pro → gemini-2.5-flash\n3. **No Task Differentiation Needed**: Gemini 3 Pro handles coding and reasoning equally well\n4. **Monitor Quotas**: Track rate limits and use fallback chain when needed\n5. **Update Mapping Table**: Review quarterly for new model releases\n6. **Test Access**: Verify Gemini 3 Pro access before defaulting to it\n7. **Use Explicit Model Selection**: Specify `-m gemini-3-pro-preview` rather than relying on CLI defaults\n\n## Updating This Guide\n\nWhen new models are released:\n\n1. Update \"Current Mappings\" table\n2. Add new model to \"Model Family Overview\"\n3. Update \"Model Capabilities Comparison\"\n4. Revise fallback logic if needed\n5. Update examples with new model IDs\n6. Test all command patterns\n7. Update \"Last Updated\" date\n\n## Example Selection Scenarios\n\n### Scenario 1: System Architecture Design\n\n**Task**: \"Design a scalable payment processing system\"\n**Selection**: `gemini-3-pro-preview` (default for all tasks)\n**Fallback**: `gemini-2.5-pro` → `gemini-2.5-flash`\n\n```bash\ngemini -m gemini-3-pro-preview \"Design a scalable payment processing system\"\n```\n\n### Scenario 2: Code Fix\n\n**Task**: \"Fix the syntax error in this JavaScript\"\n**Selection**: `gemini-3-pro-preview` (default for all tasks)\n**Fallback**: `gemini-2.5-pro` → `gemini-2.5-flash`\n\n```bash\ngemini -m gemini-3-pro-preview \"Fix the syntax error in this code\"\n```\n\n### Scenario 3: Pull Request Review\n\n**Task**: \"Review this pull request for best practices\"\n**Selection**: `gemini-3-pro-preview` (default for all tasks)\n**Fallback**: `gemini-2.5-pro` → `gemini-2.5-flash`\n\n```bash\ngemini -m gemini-3-pro-preview \"Review this pull request\"\n```\n\n## See Also\n\n- `gemini-help.md` - Full CLI reference\n- `command-patterns.md` - Common command templates\n- `session-workflows.md` - Session continuation patterns\n",
        "plugins/gemini/skills/gemini/references/session-workflows.md": "# Gemini CLI Session Workflows\n\n**Purpose**: Guide for session management and multi-turn conversations\n**Version**: v0.16.0+\n**Last Updated**: 2025-11-18\n\n**Note**: Session management features documented here are available in Gemini CLI v0.16.0+ but may not be directly accessible through Claude Code's headless integration. See limitations section below.\n\n## Overview\n\nGemini CLI supports session persistence for multi-turn conversations, allowing you to resume previous interactions and build on context across multiple invocations.\n\n## Session Basics\n\n### What is a Session?\n\nA session is a conversation thread with Gemini that:\n- Maintains conversation history\n- Preserves context across turns\n- Can be resumed later\n- Is stored locally in `~/.gemini/`\n\n### Session Lifecycle\n\n```\nCreate → Use → Pause → Resume → Complete → Archive/Delete\n```\n\n## Session Management Commands\n\n### List Available Sessions\n\n```bash\ngemini --list-sessions\n```\n\n**Example Output**:\n```\nAvailable sessions:\n 0: \"test non-interactive mode\" (5 minutes ago)\n 1: \"architecture design discussion\" (1 hour ago)\n 2: \"code review session\" (yesterday)\n```\n\n### Resume a Session\n\n```bash\n# Resume most recent session\ngemini -r latest\n\n# Resume specific session by index\ngemini -r 0\ngemini -r 1\ngemini -r 2\n\n# Resume and add new prompt\ngemini -r latest \"Continue our discussion about microservices\"\n```\n\n### Delete a Session\n\n```bash\n# Delete session by index\ngemini --delete-session 0\n\n# Delete after listing\ngemini --list-sessions\ngemini --delete-session 2\n```\n\n## Session Workflows\n\n### Workflow 1: Iterative Development\n\n**Scenario**: Building a feature across multiple sessions\n\n```bash\n# Session 1: Initial design\ngemini -m gemini-3-pro-preview \"Design a user authentication system\"\n# ... conversation happens ...\n\n# Later: Resume to implement\ngemini -r latest \"Now help me implement the login component\"\n\n# Even later: Review and refine\ngemini -r latest \"Review the implementation for security issues\"\n```\n\n### Workflow 2: Research Continuation\n\n**Scenario**: Deep research across multiple timeframes\n\n```bash\n# Day 1: Start research\ngemini -m gemini-3-pro-preview -e web_search \"Research GraphQL best practices\"\n\n# Day 2: Continue research\ngemini -r latest \"Now compare GraphQL with REST for our use case\"\n\n# Day 3: Make decision\ngemini -r latest \"Based on our research, recommend the best approach\"\n```\n\n### Workflow 3: Code Review Marathon\n\n**Scenario**: Reviewing multiple files in sequence\n\n```bash\n# Start with first file\ngemini -m gemini-2.5-pro \"Review this authentication module\"\n\n# Resume for next file (context preserved)\ngemini -r latest \"Now review the authorization module\"\n\n# Continue pattern\ngemini -r latest \"Review the session management module\"\n```\n\n### Workflow 4: Collaborative Debugging\n\n**Scenario**: Debugging complex issues over time\n\n```bash\n# Initial investigation\ngemini -m gemini-2.5-pro \"Help debug this memory leak\"\n\n# After implementing first fix\ngemini -r latest \"The leak still occurs. Here's the new log output...\"\n\n# Final resolution\ngemini -r latest \"Confirmed fixed! Summarize what we found\"\n```\n\n## Best Practices\n\n### When to Use Sessions\n\n✅ **Good Use Cases**:\n- Complex multi-step tasks\n- Iterative design and implementation\n- Long-running research projects\n- Code review across multiple files\n- Debugging sessions spanning multiple attempts\n\n❌ **Poor Use Cases**:\n- Quick one-off queries\n- Unrelated tasks\n- Simple factual questions\n- When context doesn't matter\n\n### Session Management Tips\n\n1. **Name Sessions Meaningfully**: Use descriptive names for easy identification\n2. **Clean Up Regularly**: Delete completed sessions to reduce clutter\n3. **Use Latest Wisely**: `gemini -r latest` is convenient but verify you're resuming the right session\n4. **Context Limits**: Very long sessions may hit context window limits\n5. **Explicit Resume**: When in doubt, use numeric index rather than `latest`\n\n### Session Organization\n\n```bash\n# Pattern: One session per feature/task\n# Session 0: \"auth-implementation\"\n# Session 1: \"payment-integration\"\n# Session 2: \"performance-optimization\"\n\n# Check which session you need\ngemini --list-sessions\n\n# Resume the right one\ngemini -r 1  # payment-integration\n```\n\n## Session Storage\n\n### Location\n\nSessions are stored in:\n```\n~/.gemini/\n├── sessions/\n│   ├── session-0.json\n│   ├── session-1.json\n│   └── session-2.json\n└── settings.json\n```\n\n### Privacy & Security\n\n- Sessions stored locally only\n- No automatic cloud sync\n- Contains conversation history\n- May include sensitive code/data\n- Should be included in `.gitignore`\n\n## Interactive vs Non-Interactive Sessions\n\n### Interactive Mode\n\n```bash\n# Start interactive session\ngemini\n\n# Session automatically created\n# Type /chat save mytag to save with tag\n# Type /chat resume mytag to resume later\n```\n\n### Non-Interactive Mode (Headless)\n\n```bash\n# Sessions work with -r flag\ngemini -r latest \"New prompt here\"\n\n# But creating NEW sessions requires prompt-interactive\ngemini -i \"Start session with this prompt\"\n```\n\n## Limitations in Claude Code Integration\n\n⚠️ **Important**: Claude Code's bash environment is non-interactive/headless, which means:\n\n1. **No Interactive Session Commands**: Commands like `/chat save` and `/chat resume` don't work in headless mode\n2. **Resume Flag May Work**: The `-r` flag SHOULD work for resuming, but hasn't been tested in headless context\n3. **Session Creation**: New sessions created automatically on first invocation\n4. **Session Persistence**: Sessions persist across Claude Code skill invocations if using same working directory\n\n### Workaround for Claude Code\n\nSince full session management may not be available in headless mode, consider:\n- Using one-shot queries for each invocation\n- Maintaining conversation context at the plugin level (if needed)\n- Documenting session management as manual user workflow outside Claude Code\n\n## Advanced Patterns\n\n### Session Branching\n\n```bash\n# Main session\ngemini -r 0 \"Implement approach A\"\n\n# Try alternative without affecting main session\ngemini \"Try approach B instead\"  # New session\n\n# Return to main session\ngemini -r 0 \"Continue with approach A\"\n```\n\n### Session Cleanup Script\n\n```bash\n#!/bin/bash\n# cleanup-old-sessions.sh\n\n# List sessions\ngemini --list-sessions\n\n# Delete sessions older than 7 days (manual inspection required)\n# No automated deletion to prevent data loss\n```\n\n## Troubleshooting\n\n### Session Not Found\n\n```bash\n$ gemini -r 5\nError: Session 5 not found\n\n# Solution: List sessions first\n$ gemini --list-sessions\n# Use valid index\n```\n\n### Lost Session Context\n\n```bash\n# If session seems to have lost context:\n# 1. Verify you're resuming correct session\ngemini --list-sessions\n\n# 2. Resume with summary prompt\ngemini -r 2 \"Summarize what we discussed so far\"\n\n# 3. If context truly lost, start fresh\ngemini \"Let's restart our discussion about...\"\n```\n\n### Session Conflicts\n\n```bash\n# If multiple sessions seem to interfere:\n# 1. Check current sessions\ngemini --list-sessions\n\n# 2. Delete unused sessions\ngemini --delete-session 1\ngemini --delete-session 3\n\n# 3. Start fresh with clear naming\ngemini \"New session: payment gateway integration\"\n```\n\n## See Also\n\n- `gemini-help.md` - Full CLI reference\n- `command-patterns.md` - Common command templates\n- `model-selection.md` - Model selection guidance\n",
        "plugins/telegram-notifier/.claude-plugin/plugin.json": "{\n  \"name\": \"telegram-notifier\",\n  \"description\": \"Telegram notifications for Claude Code response completion, subagent tasks, and system notifications\",\n  \"version\": \"0.1.1\",\n  \"author\": {\n    \"name\": \"0xasun\"\n  },\n  \"repository\": \"https://github.com/Lucklyric/cc-dev-tools\",\n  \"homepage\": \"https://github.com/Lucklyric/cc-dev-tools/tree/main/plugins/telegram-notifier\",\n  \"keywords\": [\"telegram\", \"notifications\", \"hooks\"],\n  \"license\": \"Apache-2.0\"\n}\n",
        "plugins/telegram-notifier/README.md": "# Telegram Notifier Plugin\n\nReceive Telegram notifications when Claude Code completes responses, subagent tasks finish, or system notifications occur.\n\n## Features\n\n- **Stop Hook**: Notifies when Claude Code completes a response\n- **SubagentStop Hook**: Notifies when subagent tasks complete\n- **Notification Hook**: Forwards Claude Code system notifications\n- **Custom Messages**: Customize notification messages via environment variables\n- **Dry-Run Mode**: Test configuration without sending real notifications\n\n## Quick Setup\n\n### 1. Create a Telegram Bot\n\n1. Open Telegram and search for `@BotFather`\n2. Send `/newbot` command\n3. Follow prompts to name your bot\n4. Copy the **bot token** (looks like `123456789:ABCdefGHIjklMNOpqrsTUVwxyz`)\n\n### 2. Get Your Chat ID\n\n1. Start a conversation with your new bot (send any message)\n2. Open this URL in browser (replace TOKEN with your bot token):\n   ```\n   https://api.telegram.org/bot<TOKEN>/getUpdates\n   ```\n3. Find `\"chat\":{\"id\":123456789}` in the response - that's your chat ID\n\n### 3. Set Environment Variables\n\nAdd to your shell profile (`~/.zshrc`, `~/.bashrc`, etc.):\n\n```bash\nexport CC_TELEGRAM_BOT_TOKEN=\"your-bot-token-here\"\nexport CC_TELEGRAM_CHAT_ID=\"your-chat-id-here\"\n```\n\nReload your shell:\n```bash\nsource ~/.zshrc  # or ~/.bashrc\n```\n\n### 4. Install the Plugin\n\n```bash\nclaude plugins add cc-dev-tools/telegram-notifier\n```\n\n### 5. Verify Setup\n\nTest your credentials:\n```bash\ncurl -s -X POST \"https://api.telegram.org/bot$CC_TELEGRAM_BOT_TOKEN/sendMessage\" \\\n  -d \"chat_id=$CC_TELEGRAM_CHAT_ID\" \\\n  -d \"text=Test from Claude Code setup\"\n```\n\n## Environment Variables\n\n### Required\n\n| Variable | Description |\n|----------|-------------|\n| `CC_TELEGRAM_BOT_TOKEN` | Bot API token from BotFather |\n| `CC_TELEGRAM_CHAT_ID` | Target chat ID for notifications |\n\n### Optional (Custom Messages)\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `CC_TELEGRAM_STOP_MSG` | `Claude Code response completed at {timestamp}` | Custom message for Stop events |\n| `CC_TELEGRAM_SUBAGENT_MSG` | `Claude Code subagent completed at {timestamp}` | Custom message for SubagentStop events |\n| `CC_TELEGRAM_NOTIFY_MSG` | `Claude Code notification` | Custom message for Notification events |\n\n### Optional (Control)\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `CC_TELEGRAM_DRY_RUN` | `false` | Set to `true` to log messages without sending |\n\n## Custom Message Examples\n\n```bash\n# Simple custom messages\nexport CC_TELEGRAM_STOP_MSG=\"Claude session finished\"\nexport CC_TELEGRAM_SUBAGENT_MSG=\"Background task done\"\nexport CC_TELEGRAM_NOTIFY_MSG=\"Alert from Claude\"\n\n# With timestamp (default behavior)\nexport CC_TELEGRAM_STOP_MSG=\"Claude Code response completed at $(date '+%Y-%m-%d %H:%M:%S')\"\n\n# With project info\nexport CC_TELEGRAM_STOP_MSG=\"Done working on $(basename $(pwd))\"\n```\n\n**Tip**: Use `$()` for shell expansions that should evaluate at notification time.\n\n## Dry-Run Mode\n\nTest your configuration without sending real notifications:\n\n```bash\nexport CC_TELEGRAM_DRY_RUN=\"true\"\n```\n\nWhen enabled, the plugin prints `[DRY RUN] <message>` to the terminal instead of sending to Telegram.\n\n## Events That Trigger Notifications\n\n| Event | Default Message | When |\n|-------|-----------------|------|\n| Stop | Claude Code response completed at {time} | Claude Code completes a response |\n| SubagentStop | Claude Code subagent completed at {time} | Background agent finishes |\n| Notification | Claude Code notification | System notification |\n\n## Troubleshooting\n\n### No notifications received\n\n1. Verify environment variables are set:\n   ```bash\n   echo $CC_TELEGRAM_BOT_TOKEN\n   echo $CC_TELEGRAM_CHAT_ID\n   ```\n\n2. Test manually:\n   ```bash\n   curl -s -X POST \"https://api.telegram.org/bot$CC_TELEGRAM_BOT_TOKEN/sendMessage\" \\\n     -d \"chat_id=$CC_TELEGRAM_CHAT_ID\" \\\n     -d \"text=Test message\"\n   ```\n\n3. Check if bot is blocked - ensure you've sent at least one message to your bot\n\n### \"Failed to send Telegram notification\" error\n\n- Network connectivity issue\n- Invalid bot token or chat ID\n- Bot was deleted or disabled\n\n## License\n\nApache-2.0\n",
        "plugins/telegram-notifier/hooks/hooks.json": "{\n  \"hooks\": {\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"if [[ -n \\\"$CC_TELEGRAM_BOT_TOKEN\\\" && -n \\\"$CC_TELEGRAM_CHAT_ID\\\" ]]; then MESSAGE=\\\"${CC_TELEGRAM_STOP_MSG:-Claude Code response completed at $(date '+%Y-%m-%d %H:%M:%S')}\\\"; if [[ \\\"${CC_TELEGRAM_DRY_RUN:-false}\\\" == \\\"true\\\" ]]; then echo \\\"[DRY RUN] $MESSAGE\\\"; else curl -s -X POST \\\"https://api.telegram.org/bot$CC_TELEGRAM_BOT_TOKEN/sendMessage\\\" -d \\\"chat_id=$CC_TELEGRAM_CHAT_ID\\\" -d \\\"text=$MESSAGE\\\" -d \\\"parse_mode=HTML\\\" >/dev/null 2>&1 || echo \\\"Failed to send Telegram notification\\\"; fi; else echo \\\"Telegram notification skipped: Set CC_TELEGRAM_BOT_TOKEN and CC_TELEGRAM_CHAT_ID\\\"; fi\"\n          }\n        ]\n      }\n    ],\n    \"SubagentStop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"if [[ -n \\\"$CC_TELEGRAM_BOT_TOKEN\\\" && -n \\\"$CC_TELEGRAM_CHAT_ID\\\" ]]; then MESSAGE=\\\"${CC_TELEGRAM_SUBAGENT_MSG:-Claude Code subagent completed at $(date '+%Y-%m-%d %H:%M:%S')}\\\"; if [[ \\\"${CC_TELEGRAM_DRY_RUN:-false}\\\" == \\\"true\\\" ]]; then echo \\\"[DRY RUN] $MESSAGE\\\"; else curl -s -X POST \\\"https://api.telegram.org/bot$CC_TELEGRAM_BOT_TOKEN/sendMessage\\\" -d \\\"chat_id=$CC_TELEGRAM_CHAT_ID\\\" -d \\\"text=$MESSAGE\\\" -d \\\"parse_mode=HTML\\\" >/dev/null 2>&1 || echo \\\"Failed to send Telegram notification\\\"; fi; else echo \\\"Telegram notification skipped: Set CC_TELEGRAM_BOT_TOKEN and CC_TELEGRAM_CHAT_ID\\\"; fi\"\n          }\n        ]\n      }\n    ],\n    \"Notification\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"if [[ -n \\\"$CC_TELEGRAM_BOT_TOKEN\\\" && -n \\\"$CC_TELEGRAM_CHAT_ID\\\" ]]; then MESSAGE=\\\"${CC_TELEGRAM_NOTIFY_MSG:-Claude Code notification}\\\"; if [[ \\\"${CC_TELEGRAM_DRY_RUN:-false}\\\" == \\\"true\\\" ]]; then echo \\\"[DRY RUN] $MESSAGE\\\"; else curl -s -X POST \\\"https://api.telegram.org/bot$CC_TELEGRAM_BOT_TOKEN/sendMessage\\\" -d \\\"chat_id=$CC_TELEGRAM_CHAT_ID\\\" -d \\\"text=$MESSAGE\\\" -d \\\"parse_mode=HTML\\\" >/dev/null 2>&1 || echo \\\"Failed to send Telegram notification\\\"; fi; else echo \\\"Telegram notification skipped: Set CC_TELEGRAM_BOT_TOKEN and CC_TELEGRAM_CHAT_ID\\\"; fi\"\n          }\n        ]\n      }\n    ]\n  }\n}\n"
      },
      "plugins": [
        {
          "name": "codex",
          "source": "./plugins/codex",
          "description": "Invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Supports intelligent model selection, session continuation, and safe defaults.",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add Lucklyric/cc-dev-tools",
            "/plugin install codex@cc-dev-tools"
          ]
        },
        {
          "name": "gemini",
          "source": "./plugins/gemini",
          "description": "Google Gemini CLI integration for Claude Code. Provides access to Gemini AI models with intelligent model selection, session continuation, and safe defaults.",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add Lucklyric/cc-dev-tools",
            "/plugin install gemini@cc-dev-tools"
          ]
        },
        {
          "name": "telegram-notifier",
          "source": "./plugins/telegram-notifier",
          "description": "Telegram notifications for Claude Code response completion, subagent tasks, and system notifications. Configurable via environment variables with dry-run mode for testing.",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add Lucklyric/cc-dev-tools",
            "/plugin install telegram-notifier@cc-dev-tools"
          ]
        }
      ]
    }
  ]
}