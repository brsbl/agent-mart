{
  "author": {
    "id": "rawveg",
    "display_name": "Tim Green",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/308889?u=c1b77c0a785466999354e7de493ea01022e81981&v=4",
    "url": "https://github.com/rawveg",
    "bio": "Principal Engineer, backend specialist & open-source advocate. AI Ethics and XAI Author.",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 29,
      "total_commands": 0,
      "total_skills": 34,
      "total_stars": 15,
      "total_forks": 2
    }
  },
  "marketplaces": [
    {
      "name": "skillsforge-marketplace",
      "version": null,
      "description": "Claude Skills Marketplace - A centralized repository for Claude Code skills and plugins",
      "owner_info": {
        "name": "Tim Green",
        "email": "rawveg@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "rawveg/skillsforge-marketplace",
      "repo_url": "https://github.com/rawveg/skillsforge-marketplace",
      "repo_description": "A Claude Code Marketplace ",
      "homepage": "",
      "signals": {
        "stars": 15,
        "forks": 2,
        "pushed_at": "2026-01-17T18:52:04Z",
        "created_at": "2025-10-20T05:54:40Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 6531
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 12535
        },
        {
          "path": "ai-summary-request",
          "type": "tree",
          "size": null
        },
        {
          "path": "ai-summary-request/SKILL.md",
          "type": "blob",
          "size": 13095
        },
        {
          "path": "apify-js-sdk",
          "type": "tree",
          "size": null
        },
        {
          "path": "apify-js-sdk/SKILL.md",
          "type": "blob",
          "size": 11319
        },
        {
          "path": "article-title-optimizer",
          "type": "tree",
          "size": null
        },
        {
          "path": "article-title-optimizer/SKILL.md",
          "type": "blob",
          "size": 13539
        },
        {
          "path": "cronjob-org",
          "type": "tree",
          "size": null
        },
        {
          "path": "cronjob-org/SKILL.md",
          "type": "blob",
          "size": 13947
        },
        {
          "path": "figlet-text-converter",
          "type": "tree",
          "size": null
        },
        {
          "path": "figlet-text-converter/SKILL.md",
          "type": "blob",
          "size": 5666
        },
        {
          "path": "forem-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "forem-api/SKILL.md",
          "type": "blob",
          "size": 10840
        },
        {
          "path": "frankenphp",
          "type": "tree",
          "size": null
        },
        {
          "path": "frankenphp/SKILL.md",
          "type": "blob",
          "size": 12108
        },
        {
          "path": "github-issue-fetcher",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-issue-fetcher/SKILL.md",
          "type": "blob",
          "size": 7247
        },
        {
          "path": "hashnode-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "hashnode-api/SKILL.md",
          "type": "blob",
          "size": 11078
        },
        {
          "path": "haveibeenpwned",
          "type": "tree",
          "size": null
        },
        {
          "path": "haveibeenpwned/SKILL.md",
          "type": "blob",
          "size": 15803
        },
        {
          "path": "laravel-cashier-paddle",
          "type": "tree",
          "size": null
        },
        {
          "path": "laravel-cashier-paddle/SKILL.md",
          "type": "blob",
          "size": 11229
        },
        {
          "path": "laravel-cashier-stripe",
          "type": "tree",
          "size": null
        },
        {
          "path": "laravel-cashier-stripe/SKILL.md",
          "type": "blob",
          "size": 11340
        },
        {
          "path": "laravel-dusk",
          "type": "tree",
          "size": null
        },
        {
          "path": "laravel-dusk/SKILL.md",
          "type": "blob",
          "size": 12262
        },
        {
          "path": "laravel-mcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "laravel-mcp/SKILL.md",
          "type": "blob",
          "size": 12499
        },
        {
          "path": "laravel-prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": "laravel-prompts/SKILL.md",
          "type": "blob",
          "size": 15156
        },
        {
          "path": "laravel",
          "type": "tree",
          "size": null
        },
        {
          "path": "laravel/SKILL.md",
          "type": "blob",
          "size": 13874
        },
        {
          "path": "linode-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "linode-api/SKILL.md",
          "type": "blob",
          "size": 10800
        },
        {
          "path": "linode-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "linode-cli/SKILL.md",
          "type": "blob",
          "size": 12327
        },
        {
          "path": "midjourney-replicate-flux",
          "type": "tree",
          "size": null
        },
        {
          "path": "midjourney-replicate-flux/SKILL.md",
          "type": "blob",
          "size": 14964
        },
        {
          "path": "n8n",
          "type": "tree",
          "size": null
        },
        {
          "path": "n8n/SKILL.md",
          "type": "blob",
          "size": 10838
        },
        {
          "path": "ollama",
          "type": "tree",
          "size": null
        },
        {
          "path": "ollama/SKILL.md",
          "type": "blob",
          "size": 11844
        },
        {
          "path": "openrouter",
          "type": "tree",
          "size": null
        },
        {
          "path": "openrouter/SKILL.md",
          "type": "blob",
          "size": 10946
        },
        {
          "path": "pinterest-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "pinterest-api/SKILL.md",
          "type": "blob",
          "size": 13703
        },
        {
          "path": "presumption-guard",
          "type": "tree",
          "size": null
        },
        {
          "path": "presumption-guard/README.md",
          "type": "blob",
          "size": 1560
        },
        {
          "path": "replicate-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "replicate-cli/SKILL.md",
          "type": "blob",
          "size": 7700
        },
        {
          "path": "revenuecat",
          "type": "tree",
          "size": null
        },
        {
          "path": "revenuecat/SKILL.md",
          "type": "blob",
          "size": 7568
        },
        {
          "path": "skill-extractor",
          "type": "tree",
          "size": null
        },
        {
          "path": "skill-extractor/README.md",
          "type": "blob",
          "size": 11309
        },
        {
          "path": "skill-extractor/SKILL.md",
          "type": "blob",
          "size": 11041
        },
        {
          "path": "snapas",
          "type": "tree",
          "size": null
        },
        {
          "path": "snapas/SKILL.md",
          "type": "blob",
          "size": 8121
        },
        {
          "path": "tdd-methodology-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "tdd-methodology-expert/SKILL.md",
          "type": "blob",
          "size": 23226
        },
        {
          "path": "threads-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "threads-api/SKILL.md",
          "type": "blob",
          "size": 12023
        },
        {
          "path": "tumblr",
          "type": "tree",
          "size": null
        },
        {
          "path": "tumblr/SKILL.md",
          "type": "blob",
          "size": 10204
        },
        {
          "path": "vastai-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "vastai-api/SKILL.md",
          "type": "blob",
          "size": 12371
        },
        {
          "path": "vercel",
          "type": "tree",
          "size": null
        },
        {
          "path": "vercel/SKILL.md",
          "type": "blob",
          "size": 10941
        },
        {
          "path": "word-count-checker",
          "type": "tree",
          "size": null
        },
        {
          "path": "word-count-checker/SKILL.md",
          "type": "blob",
          "size": 2261
        },
        {
          "path": "writeas",
          "type": "tree",
          "size": null
        },
        {
          "path": "writeas/SKILL.md",
          "type": "blob",
          "size": 9946
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"skillsforge-marketplace\",\n  \"id\": \"skillsforge-marketplace\",\n  \"owner\": {\n    \"name\": \"Tim Green\",\n    \"email\": \"rawveg@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude Skills Marketplace - A centralized repository for Claude Code skills and plugins\",\n    \"version\": \"1.0.1\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"ai-summary-request\",\n      \"description\": \"Creates llms.txt files for AI discoverability and AI Summary Request footer components with platform icons.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./ai-summary-request\"\n      ]\n    },\n    {\n      \"name\": \"apify-js-sdk\",\n      \"description\": \"Interacts with the Apify JS SDK. Allows you to work with Actors and other Apify features.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./apify-js-sdk\"\n      ]\n    },\n    {\n      \"name\": \"article-title-optimizer\",\n      \"description\": \"Optimizes article titles for search engines.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./article-title-optimizer\"\n      ]\n    },\n    {\n      \"name\": \"cronjob-org\",\n      \"description\": \"Interacts with the cronjob.org API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./cronjob-org\"\n      ]\n    },\n    {\n      \"name\": \"figlet-text-converter\",\n      \"description\": \"Converts marked text in files to ASCII art using figlet tag syntax.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./figlet-text-converter\"\n      ]\n    },\n    {\n      \"name\": \"forem-api\",\n      \"description\": \"Interacts with the Forem API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./forem-api\"\n      ]\n    },\n    {\n      \"name\": \"frankenphp\",\n      \"description\": \"Interacts with the FrankenPHP App Server.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./frankenphp\"\n      ]\n    },\n    {\n      \"name\": \"github-issue-fetcher\",\n      \"description\": \"Fetches GitHub issues for a repository.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./github-issue-fetcher\"\n      ]\n    },\n    {\n      \"name\": \"hashnode-api\",\n      \"description\": \"Interacts with the Hashnode API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./hashnode-api\"\n      ]\n    },\n    {\n      \"name\": \"haveibeenpwned\",\n      \"description\": \"Interacts with the HaveIBeenPwned API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./haveibeenpwned\"\n      ]\n    },\n    {\n      \"name\": \"laravel\",\n      \"description\": \"Collection of skills used to work with Laravel\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./laravel\",\n        \"./laravel-cashier-paddle\",\n        \"./laravel-cashier-stripe\",\n        \"./laravel-dusk\",\n        \"./laravel-mcp\",\n        \"./laravel-prompts\"\n      ]\n    },\n    {\n      \"name\": \"linode-api\",\n      \"description\": \"Interacts with the Linode API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./linode-api\"\n      ]\n    },\n    {\n      \"name\": \"linode-cli\",\n      \"description\": \"Interacts with the Linode CLI.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./linode-cli\"\n      ]\n    },\n    {\n      \"name\": \"midjourney-replicate-flux\",\n      \"description\": \"Interacts with the Replicate MCP server to create Midjourney-style prompts and images using Blackforest Labs Flux 1.1 Pro Model.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./midjourney-replicate-flux\"\n      ]\n    },\n    {\n      \"name\": \"n8n\",\n      \"description\": \"Interacts with the n8n API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./n8n\"\n      ]\n    },\n    {\n      \"name\": \"ollama\",\n      \"description\": \"Interacts with the Ollama API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./ollama\"\n      ]\n    },\n    {\n      \"name\": \"openrouter\",\n      \"description\": \"Interacts with the OpenRouter API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./openrouter\"\n      ]\n    },\n    {\n      \"name\": \"pinterest-api\",\n      \"description\": \"Interacts with the Pinterest API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./pinterest-api\"\n      ]\n    },\n    {\n      \"name\": \"replicate-cli\",\n      \"description\": \"Interacts with the Replicate CLI.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./replicate-cli\"\n      ]\n    },\n    {\n      \"name\": \"revenuecat\",\n      \"description\": \"Interacts with the RevenueCat API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./revenuecat\"\n      ]\n    },\n    {\n      \"name\": \"snapas\",\n      \"description\": \"Interacts with the Snap.as API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./snapas\"\n      ]\n    },\n    {\n      \"name\": \"tdd-methodology-expert\",\n      \"description\": \"Expertise in Test-Driven Development (TDD) methodology.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./tdd-methodology-expert\"\n      ]\n    },\n    {\n      \"name\": \"threads-api\",\n      \"description\": \"Interacts with the Threads API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./threads-api\"\n      ]\n    },\n    {\n      \"name\": \"tumblr\",\n      \"description\": \"Interacts with the Tumblr API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./tumblr\"\n      ]\n    },\n    {\n      \"name\": \"vastai-api\",\n      \"description\": \"Interacts with the VastAI API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./vastai-api\"\n      ]\n    },\n    {\n      \"name\": \"vercel\",\n      \"description\": \"Interacts with the Vercel API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./vercel\"\n      ]\n    },\n    {\n      \"name\": \"word-count-checker\",\n      \"description\": \"Checks the word count of a file.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./word-count-checker\"\n      ]\n    },\n    {\n      \"name\": \"writeas\",\n      \"description\": \"Interacts with the Write.as API.\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./writeas\"\n      ]\n    },\n    {\n      \"name\": \"presumption-guard\",\n      \"description\": \"Detects and flags presumptive actions after they occur - makes it clear when Claude has acted without explicit permission.\",\n      \"source\": \"./presumption-guard\"\n    }\n  ]\n}\n",
        "README.md": "# üéØ SkillsForge Marketplace\n\n> A curated collection of Skills and plugins to supercharge your development workflow\n\nWelcome to SkillsForge! This marketplace provides a centralized hub for discovering and installing powerful Claude Code extensions that enhance your productivity, streamline your workflows, and integrate with your favorite tools and services.\n\n## üìö Table of Contents\n\n- [Quick Start](#-quick-start)\n- [Available Skills](#-available-skills)\n- [Installation](#-installation)\n- [Configuration](#-configuration)\n- [Usage Examples](#-usage-examples)\n- [Contributing](#-contributing)\n- [Support](#-support)\n\n---\n\n## üöÄ Quick Start\n\nGet started with SkillsForge in just two commands:\n\n```bash\n# Add the SkillsForge marketplace to Claude Code\n/plugin marketplace add rawveg/skillsforge-marketplace\n\n# Browse and install skills interactively\n/plugin\n```\n\nNot using Claude Code, or want something more universal? Install any skill using:-\n\n```bash\nnpx skills rawveg/skillsforge-marketplace\n```\n\nThat's it! You now have access to all the skills in the SkillsForge collection.\n\n---\n\n## üé® Available Skills\n\nSkillsForge currently offers **32 curated skills** and **1 hooks plugin** across focused categories. Only items included in `.claude-plugin/marketplace.json` are listed below.\n\n### üìù Content & Publishing\n\n| Skill | Purpose |\n|-------|---------|\n| **[ai-summary-request](./ai-summary-request)** | Creates llms.txt files for AI discoverability and AI Summary Request footer components with platform icons. |\n| **[apify-js-sdk](./apify-js-sdk)** | Interacts with the Apify JS SDK. Allows you to work with Actors and other Apify features. |\n| **[article-title-optimizer](./article-title-optimizer)** | Optimize article titles for SEO. |\n| **[forem-api](./forem-api)** | Create, update, and delete articles and manage your Forem profile. |\n| **[hashnode-api](./hashnode-api)** | Manage articles and profile on Hashnode. |\n| **[snapas](./snapas)** | Upload and manage images via Snap.as. |\n| **[tumblr](./tumblr)** | Manage articles and profile on Tumblr. |\n| **[word-count-checker](./word-count-checker)** | Accurately count words in documents (avoids token-based estimates). |\n| **[writeas](./writeas)** | Work with Write.as/WriteFreely for simple publishing. |\n\n### üõ†Ô∏è Development Tools\n\n| Skill | Purpose |\n|-------|---------|\n| **[figlet-text-converter](./figlet-text-converter)** | Convert tagged text to ASCII art using figlet. |\n| **[github-issue-fetcher](./github-issue-fetcher)** | Fetch GitHub issues for a repository. |\n| **[tdd-methodology-expert](./tdd-methodology-expert)** | Guidance and helpers for TDD methodology and best practices. |\n\n### üîß Laravel Ecosystem\n\n| Skill | Purpose |\n|-------|---------|\n| **[laravel](./laravel)** | Core Laravel integration for Claude Code. |\n| **[laravel-cashier-paddle](./laravel-cashier-paddle)** | Work with Laravel Cashier (Paddle). |\n| **[laravel-cashier-stripe](./laravel-cashier-stripe)** | Work with Laravel Cashier (Stripe). |\n| **[laravel-dusk](./laravel-dusk)** | Browser testing with Laravel Dusk. |\n| **[laravel-mcp](./laravel-mcp)** | Integrate Laravel with MCP. |\n| **[laravel-prompts](./laravel-prompts)** | Use Laravel Prompts for interactive CLIs. |\n\n### ü§ñ AI & Model APIs\n\n| Skill | Purpose |\n|-------|---------|\n| **[openrouter](./openrouter)** | Connect to the OpenRouter API for multi-model access. |\n| **[midjourney-replicate-flux](./midjourney-replicate-flux)** | Generate Midjourney-style prompts/images via Replicate (Flux 1.1 Pro). |\n| **[ollama](./ollama)** | Interact with local models via the Ollama API. |\n| **[replicate-cli](./replicate-cli)** | Interact with the Replicate CLI. |\n\n### ‚òÅÔ∏è Cloud & Infra\n\n| Skill | Purpose |\n|-------|---------|\n| **[cronjob-org](./cronjob-org)** | Interacts with the cronjob.org API. |\n| **[frankenphp](./frankenphp)** | Integrate with the FrankenPHP app server. |\n| **[linode-api](./linode-api)** | Manage Linode resources via API. |\n| **[linode-cli](./linode-cli)** | Run Linode CLI operations. |\n| **[n8n](./n8n)** | Manage n8n resources via API. |\n| **[vastai-api](./vastai-api)** | Access GPU instances via the VastAI API. |\\\n| **[vercel](./vercel)** | Manage deployments and resources via the Vercel API. |\n\n### üìä Payment Processing and Revenue\n\n| Skill | Purpose |\n|-------|---------|\n| **[revenuecat](./revenuecat)** | Interacts with the RevenueCat API. |\n\n### üõ°Ô∏è Security\n\n| Skill | Purpose |\n|-------|---------|\n| **[haveibeenpwned](./haveibeenpwned)** | Check if your email/password has been compromised in data breaches. |\n\n### üì± Social Media\n\n| Skill | Purpose |\n|-------|---------|\n| **[threads-api](./threads-api)** | Interact with the Threads API. |\n| **[pinterest-api](./pinterest-api)** | Interact with the Pinterest API. |\n\n### üõ°Ô∏è Behavioral Hooks\n\n| Plugin | Purpose |\n|--------|---------|\n| **[presumption-guard](./presumption-guard)** | Detects and flags presumptive actions after they occur - makes it clear when Claude has acted without explicit permission. |\n\n---\n\n## üíª Installation\n\n### Method 1: Install the Entire Marketplace (Recommended)\n\nAdd the SkillsForge marketplace to access all skills:\n\n```bash\n/plugin marketplace add rawveg/skillsforge-marketplace\n```\n\nOnce added, you can:\n- Browse all available skills with `/plugin`\n- Install specific skills: `/plugin install skill-name@skillsforge-marketplace`\n- Update skills automatically when new versions are released\n\n### Method 2: Install Individual Skills\n\nIf you prefer to install specific skills without adding the marketplace:\n\n```bash\n# Install directly from GitHub\n/plugin install https://github.com/rawveg/skillsforge-marketplace/tree/main/skill-name\n```\n\n### Method 3: Local Development\n\nFor testing or development:\n\n```bash\n# Clone the repository\ngit clone https://github.com/rawveg/skillsforge-marketplace.git\n\n# Add as local marketplace\n/plugin marketplace add ./skillsforge-marketplace\n\n# Or install individual skills locally\n/plugin install ./skillsforge-marketplace/skill-name\n```\n\n---\n\n## ‚öôÔ∏è Configuration\n\n### Automatic Team Setup\n\nTo ensure your entire team has access to SkillsForge, add this to your project's `.claude/settings.json`:\n\n```json\n{\n  \"extraKnownMarketplaces\": {\n    \"skillsforge-marketplace\": {\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"rawveg/skillsforge-marketplace\"\n      }\n    }\n  },\n  \"enabledPlugins\": {\n    \"figlet-text-converter@skillsforge-marketplace\": {},\n    \"word-count-checker@skillsforge-marketplace\": {},\n    \"forem-api@skillsforge-marketplace\": {}\n  }\n}\n```\n\nWhen team members trust the repository folder, Claude Code will automatically:\n1. Install the SkillsForge marketplace\n2. Enable the specified skills\n3. Keep everything synchronized\n\n### Verify Installation\n\nCheck that the marketplace is properly configured:\n\n```bash\n# List all marketplaces\n/plugin marketplace list\n\n# Verify SkillsForge appears in the list\n# Should show: skillsforge-marketplace (GitHub: rawveg/skillsforge-marketplace)\n```\n\n---\n\n## üìñ Usage Examples\n\n### Example 1: Publishing to DEV.to\n\n```bash\n# Install the Forem API skill\n/plugin install forem-api@skillsforge-marketplace\n\n# Create a new article\nHey Claude, can you publish my article in article.md to DEV.to?\n```\n\n### Example 2: ASCII Art Headers\n\n```bash\n# Install the Figlet converter\n/plugin install figlet-text-converter@skillsforge-marketplace\n\n# Convert text to ASCII art\nPlease convert the title \"SkillsForge\" to ASCII art using the 'banner' font\n```\n\n### Example 3: Word Count Accuracy\n\n```bash\n# Install the word count checker\n/plugin install word-count-checker@skillsforge-marketplace\n\n# Get accurate word counts\nWhat's the word count of my manuscript.md file?\n```\n\n### Example 4: Laravel Development\n\n```bash\n# Install Laravel skills\n/plugin install laravel@skillsforge-marketplace\n/plugin install laravel-prompts@skillsforge-marketplace\n\n# Use Laravel-specific features\nHelp me create a new Artisan command with interactive prompts\n```\n\n---\n\n## ü§ù Contributing\n\nWe welcome contributions to SkillsForge! Here's how you can help:\n\n### Adding New Skills\n\n1. Fork the repository\n2. Create a new directory for your skill: `./your-skill-name/`\n3. Add your skill files and a `SKILL.md` documentation file\n4. Update `.claude-plugin/marketplace.json` with your skill entry\n5. Submit a pull request with a clear description\n\n### Skill Submission Checklist\n\n- [ ] Skill follows the [Claude Code plugin structure](https://docs.claude.com/docs/claude-code/plugins)\n- [ ] Includes clear documentation in `SKILL.md`\n- [ ] Tested locally with `/plugin install ./your-skill-name`\n- [ ] Added to marketplace.json with appropriate metadata\n- [ ] Follows semantic versioning (e.g., 1.0.0)\n\n### Reporting Issues\n\nFound a bug or have a feature request?\n\n1. Check existing [GitHub Issues](https://github.com/rawveg/skillsforge-marketplace/issues)\n2. Create a new issue with:\n   - Clear description of the problem\n   - Steps to reproduce\n   - Expected vs. actual behavior\n   - Claude Code version and environment details\n\n---\n\n## üîç Managing the Marketplace\n\n### Update Skills\n\nRefresh the marketplace to get the latest skill versions:\n\n```bash\n/plugin marketplace update skillsforge-marketplace\n```\n\n### List Installed Skills\n\nSee which skills you have installed:\n\n```bash\n/plugin list\n```\n\n### Remove Skills\n\nUninstall skills you no longer need:\n\n```bash\n/plugin uninstall skill-name\n```\n\n### Remove Marketplace\n\nTo completely remove SkillsForge:\n\n```bash\n/plugin marketplace remove skillsforge-marketplace\n```\n\n> **Note:** Removing the marketplace will also uninstall all skills installed from it.\n\n---\n\n## üìã Troubleshooting\n\n### Marketplace Won't Load\n\n**Problem:** Can't add the marketplace or see any skills\n\n**Solutions:**\n- Verify you have internet access\n- Ensure you're using the correct repository name: `rawveg/skillsforge-marketplace`\n- Try updating Claude Code to the latest version\n- Check GitHub isn't experiencing downtime\n\n### Skill Installation Fails\n\n**Problem:** Skill appears in the list but won't install\n\n**Solutions:**\n- Run `/plugin marketplace update skillsforge-marketplace` to refresh\n- Try installing with the full path: `/plugin install skill-name@skillsforge-marketplace`\n- Check the skill's individual documentation for specific requirements\n- Ensure you have proper file system permissions\n\n### Skill Not Working After Installation\n\n**Problem:** Skill installed but Claude doesn't recognize it\n\n**Solutions:**\n- Restart Claude Code\n- Verify the skill is enabled: `/plugin list`\n- Check for any error messages in the Claude Code logs\n- Try reinstalling: `/plugin uninstall skill-name` then `/plugin install skill-name@skillsforge-marketplace`\n\n---\n\n## üí¨ Support\n\nNeed help or have questions?\n\n- **Documentation:** [Claude Code Plugins Guide](https://docs.claude.com/docs/claude-code/plugins)\n- **Issues:** [GitHub Issues](https://github.com/rawveg/skillsforge-marketplace/issues)\n- **Discussions:** [GitHub Discussions](https://github.com/rawveg/skillsforge-marketplace/discussions)\n\n---\n\n## üìÑ License\n\nAll skills in this marketplace are released under the MIT License unless otherwise specified in individual skill directories.\n\n```\nMIT License\n\nCopyright (c) 2025 Tim Green\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n```\n\n---\n\n## üåü Star History\n\nIf you find SkillsForge useful, please consider giving it a star on GitHub! It helps others discover these tools.\n\n---\n\n## üéØ Roadmap\n\nUpcoming skills and features:\n\n- [ ] GitHub Actions integration skill\n- [ ] Database query and management tools\n- [ ] API testing and documentation generators\n- [ ] Cloud deployment helpers (AWS, Azure, GCP)\n- [ ] Code quality and security scanning tools\n\nHave ideas for new skills? [Open an issue](https://github.com/rawveg/skillsforge-marketplace/issues) with the \"enhancement\" label!\n\n---\n\n<div align=\"center\">\n\n**Built with ‚ù§Ô∏è by [Tim Green](https://github.com/rawveg)**\n\n[‚¨Ü Back to Top](#-skillsforge-marketplace)\n\n</div>\n",
        "ai-summary-request/SKILL.md": "---\nname: ai-summary-request\ndescription: Adds an \"AI Summary Request\" footer component with clickable AI platform icons (ChatGPT, Claude, Gemini, Grok, Perplexity) that pre-populate prompts for users to get AI summaries of the website. Optionally creates an llms.txt file for enhanced AI discoverability. Use when users want to add AI platform integration buttons or make their website AI-friendly.\n---\n\n# AI Summary Request\n\n## Overview\n\nThis skill creates a footer component with AI platform icons that allow visitors to request AI summaries of a website. The workflow begins by detecting and confirming the website domain, then asks whether to optionally generate an `llms.txt` file for enhanced AI discoverability.\n\n## When to Use This Skill\n\nUse this skill when:\n- User wants to add AI platform integration buttons to their site\n- User wants visitors to easily get AI summaries of their business\n- User mentions \"AI summary\" or AI platform buttons\n- User wants to create an `llms.txt` file for their website (optional)\n- User asks about making their website AI-discoverable\n\n## Workflow\n\n### PREREQUISITE: Domain Detection and Confirmation\n\nBefore proceeding with any steps, you MUST determine the website domain:\n\n#### Step 1: Attempt automatic detection\n\nSearch for domain information in this priority order:\n\n1. **Environment files** (`.env`, `.env.local`, `.env.production`) - look for `SITE_URL`, `BASE_URL`, `NEXT_PUBLIC_URL`, `NUXT_PUBLIC_SITE_URL`, `VITE_SITE_URL`, or similar\n2. **Deployment configs** (`vercel.json`, `netlify.toml`, `firebase.json`, `fly.toml`) - check for domain/alias settings\n3. **CNAME files** in `public/` or root directory\n4. **Configuration files** (`package.json` homepage field, `next.config.js`, `nuxt.config.js`, `vite.config.js`)\n5. **HTML files** - meta tags or `<base>` tags in index files\n6. **README or documentation** mentioning the live site URL\n\n#### Step 2: Confirm or request domain\n\n**If a domain is detected**, ask the user to confirm or provide an alternative:\n> \"I detected that this site appears to use the domain **[DETECTED_DOMAIN]**. Is this correct? If not, please provide the correct domain.\"\n\n**If no domain can be detected**, ask the user directly:\n> \"I couldn't automatically detect the domain for this website. What domain should be used for the AI summary links? (e.g., https://example.com)\"\n\n#### Step 3: Normalize and store the domain\n\n- If the user provides a domain without a protocol, prepend `https://`\n- Remove any trailing slashes\n- Store the normalized domain as `${WEBSITE_URL}` for use in subsequent steps\n\n**Example normalizations:**\n- `example.com` ‚Üí `https://example.com`\n- `https://example.com/` ‚Üí `https://example.com`\n- `http://example.com` ‚Üí keep as-is (user may have specific requirements)\n\n---\n\n### PREREQUISITE: llms.txt Decision\n\nAfter confirming the domain, ask the user:\n\n> \"Would you like me to also generate an `llms.txt` file for this website? This file helps AI models better understand your site's content and structure, which can improve the quality of AI-generated summaries.\n>\n> - **Yes**: I'll create a curated llms.txt file and the footer component will reference it\n> - **No**: I'll create just the footer component, and the AI prompt will direct users to explore the website directly\"\n\nStore the user's choice as `${INCLUDE_LLMS_TXT}` (true/false).\n\n---\n\n## STEP 1: Generate llms.txt File (OPTIONAL - Only if user chose \"Yes\")\n\n**Skip this step entirely if the user chose not to generate an llms.txt file.**\n\nGenerate a high-quality `llms.txt` file for a given website that helps language models quickly understand and reference the site's most valuable content.\n\n### Analyze the Website's Content Hierarchy\n\n- Inspect any available XML or HTML sitemaps (product, page, post) and explore navigation menus to identify major product categories, services, key informational pages, and blog or news posts\n- Focus on top-level categories and representative subcategories or key products, rather than listing every single URL\n- Identify important support or policy pages (e.g., About, Contact, Terms, Privacy, Shipping & Returns)\n\n### Select and Curate Content\n\n- For each major category, select a primary landing page and a few representative subcategories or high-value product pages\n- Include links to authoritative guides, how-to articles, calculators, training programs or other resources\n- Choose a handful of blog posts or case studies that showcase different topics (tutorials, industry insights, success stories). Avoid listing dozens of posts\n- Exclude low-value pages such as checkout flows, login pages, or marketing fluff\n\n### Draft Clear Descriptions\n\n- Use concise, factual descriptions (10-15 words) that explain what each page covers\n- Avoid hype or redundant repetition of the page title\n- When summarizing subcategories, group them in parentheses for brevity\n\n### Build the llms.txt in Markdown\n\n- Start with an H1 title containing the website or company name and a short descriptor\n- Add a blockquote (prefaced by >) that succinctly describes what the business does and who it serves\n- Optionally include a sentence explaining that the list is curated for AI consumption\n- Organize content with H2 headings such as:\n  - ## Product categories (or Services if it's a service business)\n  - ## Representative pages or ## Popular products\n  - ## Guides & resources\n  - ## Articles & case studies\n  - ## Policies & support\n- List each link as a bullet (`- [Title](URL): description`) under the appropriate section\n- Keep the file in UTF-8 encoding and ensure it stays well under 100 KB by curating rather than exhaustively listing every URL\n- Add an optional \"Usage guidelines\" section stating how you'd like AI models to attribute or use the content, and include an HTML comment like `<!-- Last updated: YYYY-MM-DD -->` for version tracking\n\n### Validate and Publish\n\n- Verify that all URLs return HTTP 200 and are publicly accessible\n- Check the Markdown structure (one H1, proper headings and bullets)\n- Place the final `llms.txt` at the website's root and, if possible, add a line in `robots.txt` (`Llmstxt: /llms.txt`) to aid discovery\n- Plan regular updates (e.g., quarterly) to reflect changes in products, services or content\n\n### Deliverable\n\nProvide the full `llms.txt` file content, formatted as described above, in the served web root of the current website.\n\n---\n\n## STEP 2: Create AI Summary Request Footer Component\n\nCreate an \"AI Summary Request\" footer component with the following specifications.\n\n### Component Structure\n\n- Centered section containing a header and icon row\n- Header text: \"Request an AI summary of [COMPANY_NAME]\"\n- Row of 5 clickable AI platform icons in this exact order: ChatGPT, Claude, Gemini, Grok, Perplexity\n\n### Visual Styling\n\n- Container: flex column, centered alignment, 16px vertical gap\n- Header: centered text, base font size (16px), medium font-weight, semantic gray color (#111827 or equivalent)\n- Icon container: flex row, centered, 12px horizontal gap, wrap-enabled\n- Each icon link: 40x40px clickable area with 28x28px visible icon, rounded-full background\n- Icons: Apply CSS filter: `brightness(0)` for monochrome black effect\n- Padding within circle: 6px (1.5rem equivalent)\n- Hover effect: transform scale(1.1) with cubic-bezier(0.4, 0, 0.2, 1) transition, 150ms duration\n\n### Icon Assets\n\n**CRITICAL**: This skill includes bundled SVG icon files in the `resources/` directory. You MUST use these exact icons - do NOT use generic icon libraries, search for alternatives, or create substitutes.\n\n#### Bundled Icons (Required)\n\nCopy these SVG files from `resources/` to the user's project assets directory:\n\n| Platform | File | Description |\n|----------|------|-------------|\n| ChatGPT | `resources/chatgpt.svg` | Hexagonal flower/aperture pattern with interlocking curved segments |\n| Claude | `resources/claude.svg` | Abstract geometric pattern (NOT the Anthropic backslash logo) |\n| Gemini | `resources/gemini.svg` | Four-pointed star/sparkle icon |\n| Grok | `resources/grok.svg` | Angular crystalline/triangular pattern (NOT the X/Twitter logo) |\n| Perplexity | `resources/perplexity.svg` | Hexagonal pattern with isometric cube perspective |\n\n#### Implementation Steps\n\n1. **Copy icons to project**: Copy all 5 SVG files from this skill's `resources/` directory to the user's project (e.g., `/public/icons/ai/` or `/assets/icons/`)\n2. **Reference in component**: Use relative paths to the copied SVG files in the footer component\n3. **Do NOT substitute**: These are the only approved icons - do not use CDN links, icon libraries, or recreate from descriptions\n\n#### Icon Validation\n\nBefore finalizing, visually confirm:\n- ChatGPT icon is NOT a speech bubble or generic chat icon\n- Claude icon is NOT a simple backslash or text character\n- Gemini icon is NOT a constellation or zodiac twins symbol\n- Grok icon is NOT the X/Twitter bird or logo\n- Perplexity icon is NOT a question mark or generic markdown symbol\n\n### AI Platform Links\n\nGenerate URL-encoded links to each AI platform with pre-composed prompt:\n\n1. ChatGPT: `https://chat.openai.com/?q=[ENCODED_PROMPT]`\n2. Claude: `https://claude.ai/new?q=[ENCODED_PROMPT]`\n3. Gemini: `https://gemini.google.com/?q=[ENCODED_PROMPT]`\n4. Grok: `https://grok.com?q=[ENCODED_PROMPT]`\n5. Perplexity: `https://www.perplexity.ai/?q=[ENCODED_PROMPT]`\n\n### Prompt Templates (Select based on llms.txt decision)\n\nUse the appropriate template based on the user's llms.txt decision from the prerequisite step.\n\n**Template variables:**\n- `${WEBSITE_URL}` - The confirmed/normalized domain from prerequisite step\n- `${COMPANY_NAME}` - The company/site name (ask user if not obvious from codebase)\n- `${KEY_ASPECTS}` - Customize based on the business type (e.g., \"features, pricing, deliverables\" for services; \"products, shipping, returns\" for e-commerce)\n\n#### WITH llms.txt (if user chose to generate llms.txt)\n\n```\nPlease read the structured information at ${WEBSITE_URL}/llms.txt to understand ${COMPANY_NAME}.\n\nAs a potential client, I want to concretely understand what I will receive with ${COMPANY_NAME} (${WEBSITE_URL}).\n\nDetail step by step what the service includes: ${KEY_ASPECTS}.\n\nExplain it simply, as if you were describing the real experience of the service.\n```\n\n#### WITHOUT llms.txt (if user chose not to generate llms.txt)\n\n```\nPlease visit and analyze ${WEBSITE_URL} to understand ${COMPANY_NAME}.\n\nAs a potential client, I want to concretely understand what I will receive with ${COMPANY_NAME} (${WEBSITE_URL}).\n\nDetail step by step what the service includes: ${KEY_ASPECTS}.\n\nExplain it simply, as if you were describing the real experience of the service.\n```\n\n### Implementation Checklist\n\n- [ ] Detect or ask for website domain and get user confirmation\n- [ ] Ask user whether to generate llms.txt file\n- [ ] If llms.txt chosen: Generate and place llms.txt at website root\n- [ ] Copy all 5 SVG icons from `resources/` to project assets directory\n- [ ] Select correct prompt template based on llms.txt decision\n- [ ] Place component in footer, above copyright notice\n- [ ] URL-encode prompt using `encodeURIComponent()` or equivalent\n- [ ] Each link opens in new tab: `target=\"_blank\" rel=\"noopener noreferrer\"`\n- [ ] Add aria-label: \"Get AI summary from [Platform Name]\"\n- [ ] Test all 5 platform links verify prompt pre-population works\n- [ ] Verify icons are using the bundled SVGs (NOT generic alternatives)\n- [ ] Apply `brightness(0)` filter for consistent monochrome appearance\n- [ ] Ensure 44x44px minimum touch target for mobile accessibility\n- [ ] Responsive: icons wrap on screens < 640px width\n\n---\n\n## Technical Notes\n\n- The `llms.txt` file follows the emerging standard for AI-readable site documentation\n- The footer component should be framework-agnostic but can be adapted for React, Vue, Svelte, or vanilla HTML/CSS\n- All URLs must be properly encoded to handle special characters in the prompt\n- The component should be accessible and follow WCAG 2.1 guidelines\n\n## Bundled Resources\n\n### resources/\n\nContains the official SVG icons for each AI platform:\n\n- **chatgpt.svg** - OpenAI ChatGPT hexagonal aperture icon\n- **claude.svg** - Anthropic Claude geometric pattern icon\n- **gemini.svg** - Google Gemini four-pointed star icon\n- **grok.svg** - xAI Grok crystalline pattern icon\n- **perplexity.svg** - Perplexity hexagonal cube icon\n\nThese icons MUST be copied to the user's project and used directly. Do not substitute with alternatives.\n\n## Success Criteria\n\nA successful implementation should:\n1. Confirm the website domain with the user before proceeding\n2. Ask the user whether to include llms.txt generation\n3. If llms.txt chosen: Produce a curated, well-structured `llms.txt` file under 100KB\n4. Create a visually consistent footer component with correct branding\n5. Use the appropriate prompt template based on the user's llms.txt decision\n6. Generate working links that pre-populate prompts in each AI platform\n7. Be accessible on both desktop and mobile devices\n8. Use the bundled SVG icons from `resources/` (no substitutes)\n",
        "apify-js-sdk/SKILL.md": "---\nname: apify-js-sdk\ndescription: Apify JS SDK Documentation - Web scraping, crawling, and Actor development\n---\n\n# Apify-Js-Sdk Skill\n\nComprehensive assistance with Apify JavaScript SDK development for web scraping, crawling, and Actor creation. This skill provides access to official Apify documentation covering the API, SDK, and platform features.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Building web scrapers or crawlers with Apify\n- Working with Apify Actors (creation, management, deployment)\n- Using the Apify JavaScript Client to interact with the Apify API\n- Managing Apify datasets, key-value stores, or request queues\n- Implementing data extraction with Cheerio or other parsing libraries\n- Setting up crawling workflows with link extraction and filtering\n- Debugging Apify code or Actor runs\n- Configuring logging and monitoring for Apify Actors\n- Learning Apify platform best practices\n\n## Key Concepts\n\n### Actors\nServerless cloud programs running on the Apify platform. Actors can perform various tasks like web scraping, data processing, or automation.\n\n### Datasets\nStorage for structured data (results from scraping). Each Actor run can have an associated dataset where scraped data is stored.\n\n### Key-Value Stores\nStorage for arbitrary data like files, screenshots, or configuration. Each Actor run has a default key-value store.\n\n### Request Queue\nQueue for managing URLs to be crawled. Handles URL deduplication and retry logic automatically.\n\n### Apify Client\nJavaScript/Python library for interacting with the Apify API programmatically from your code.\n\n## Quick Reference\n\n### Basic Link Extraction with Cheerio\n\nExtract all links from a webpage using Cheerio:\n\n```javascript\nimport * as cheerio from 'cheerio';\nimport { gotScraping } from 'got-scraping';\n\nconst storeUrl = 'https://warehouse-theme-metal.myshopify.com/collections/sales';\n\nconst response = await gotScraping(storeUrl);\nconst html = response.body;\n\nconst $ = cheerio.load(html);\n\n// Select all anchor elements\nconst links = $('a');\n\n// Extract href attributes\nfor (const link of links) {\n    const url = $(link).attr('href');\n    console.log(url);\n}\n```\n\n### Running an Actor with Apify Client\n\nCall an Actor and wait for results:\n\n```javascript\nimport { ApifyClient } from 'apify-client';\n\nconst client = new ApifyClient({\n    token: 'YOUR_API_TOKEN',\n});\n\n// Run an Actor and wait for it to finish\nconst run = await client.actor('some_actor_id').call();\n\n// Get dataset items from the run\nconst { items } = await client.dataset(run.defaultDatasetId).listItems();\n\nconsole.log(items);\n```\n\n### Creating and Managing Datasets\n\nStore scraped data in a dataset:\n\n```javascript\nimport { ApifyClient } from 'apify-client';\n\nconst client = new ApifyClient({\n    token: 'YOUR_API_TOKEN',\n});\n\n// Create a new dataset\nconst dataset = await client.datasets().getOrCreate('my-dataset');\n\n// Add items to the dataset\nawait client.dataset(dataset.id).pushItems([\n    { title: 'Product 1', price: 29.99 },\n    { title: 'Product 2', price: 39.99 },\n]);\n\n// Retrieve items\nconst { items } = await client.dataset(dataset.id).listItems();\n```\n\n### Key-Value Store Operations\n\nStore and retrieve arbitrary data:\n\n```javascript\nimport { ApifyClient } from 'apify-client';\n\nconst client = new ApifyClient({\n    token: 'YOUR_API_TOKEN',\n});\n\nconst store = await client.keyValueStores().getOrCreate('my-store');\n\n// Store a value\nawait client.keyValueStore(store.id).setRecord({\n    key: 'config',\n    value: { apiUrl: 'https://api.example.com' },\n});\n\n// Retrieve a value\nconst record = await client.keyValueStore(store.id).getRecord('config');\nconsole.log(record.value);\n```\n\n### Logging Configuration\n\nSet up proper logging for Apify Actors:\n\n```python\nimport logging\nfrom apify.log import ActorLogFormatter\n\nasync def main() -> None:\n    handler = logging.StreamHandler()\n    handler.setFormatter(ActorLogFormatter())\n\n    apify_logger = logging.getLogger('apify')\n    apify_logger.setLevel(logging.DEBUG)\n    apify_logger.addHandler(handler)\n```\n\n### Using the Actor Context\n\nAccess Actor run context and storage:\n\n```python\nfrom apify import Actor\n\nasync def main() -> None:\n    async with Actor:\n        # Log messages\n        Actor.log.info('Starting Actor run')\n\n        # Access input\n        actor_input = await Actor.get_input()\n\n        # Save data to dataset\n        await Actor.push_data({\n            'url': 'https://example.com',\n            'title': 'Example Page'\n        })\n\n        # Save to key-value store\n        await Actor.set_value('OUTPUT', {'status': 'done'})\n```\n\n### Running an Actor Task\n\nExecute a pre-configured Actor task:\n\n```javascript\nimport { ApifyClient } from 'apify-client';\n\nconst client = new ApifyClient({\n    token: 'YOUR_API_TOKEN',\n});\n\n// Run a task with custom input\nconst run = await client.task('task-id').call({\n    startUrls: ['https://example.com'],\n    maxPages: 10,\n});\n\nconsole.log(`Task run: ${run.id}`);\n```\n\n### Redirecting Logs from Called Actors\n\nRedirect logs from a called Actor to the parent run:\n\n```python\nfrom apify import Actor\n\nasync def main() -> None:\n    async with Actor:\n        # Default redirect logger\n        await Actor.call(actor_id='some_actor_id')\n\n        # No redirect logger\n        await Actor.call(actor_id='some_actor_id', logger=None)\n\n        # Custom redirect logger\n        await Actor.call(\n            actor_id='some_actor_id',\n            logger=logging.getLogger('custom_logger')\n        )\n```\n\n### Getting Actor Run Details\n\nRetrieve information about an Actor run:\n\n```javascript\nimport { ApifyClient } from 'apify-client';\n\nconst client = new ApifyClient({\n    token: 'YOUR_API_TOKEN',\n});\n\n// Get run details\nconst run = await client.run('run-id').get();\n\nconsole.log(`Status: ${run.status}`);\nconsole.log(`Started: ${run.startedAt}`);\nconsole.log(`Finished: ${run.finishedAt}`);\n```\n\n### Listing Actor Builds\n\nGet all builds for a specific Actor:\n\n```javascript\nimport { ApifyClient } from 'apify-client';\n\nconst client = new ApifyClient({\n    token: 'YOUR_API_TOKEN',\n});\n\nconst { items } = await client.actor('actor-id').builds().list({\n    limit: 10,\n    desc: true,\n});\n\nfor (const build of items) {\n    console.log(`Build ${build.buildNumber}: ${build.status}`);\n}\n```\n\n## Reference Files\n\nThis skill includes comprehensive documentation in the `references/` directory:\n\n### llms-txt.md\nComplete API reference documentation with detailed information on:\n- **Actor Management**: Creating, updating, and running Actors\n- **Builds**: Managing Actor builds and versions\n- **Runs**: Controlling Actor execution and monitoring\n- **Tasks**: Pre-configured Actor executions\n- **Datasets**: Structured data storage and retrieval\n- **Key-Value Stores**: Arbitrary data storage\n- **Request Queues**: URL queue management\n- **Client SDK**: JavaScript/Python client libraries\n- **Logging**: Configuring and managing logs\n\n### llms-full.md\nExtensive documentation covering:\n- Complete Apify API v2 reference\n- All API endpoints with request/response examples\n- Authentication and rate limiting\n- Error handling\n- Webhooks and integrations\n\n### llms.md\nHigh-level overview and getting started guide with:\n- Platform concepts and architecture\n- Quick start examples\n- Common patterns and workflows\n- Best practices for web scraping\n\n## Working with This Skill\n\n### For Beginners\n\nStart with these concepts:\n1. **Understanding Actors**: Review the Actors introduction to learn about the core building block\n2. **First Scraper**: Use the link extraction examples to build your first web scraper\n3. **Data Storage**: Learn about Datasets and Key-Value Stores for storing results\n4. **API Basics**: Get familiar with the Apify Client for programmatic access\n\nKey reference: `llms.md` for platform overview and getting started guides\n\n### For Intermediate Users\n\nFocus on these areas:\n1. **Advanced Crawling**: Implement request queues and link filtering\n2. **Actor Tasks**: Set up pre-configured runs with custom inputs\n3. **Logging**: Configure proper logging with ActorLogFormatter\n4. **Error Handling**: Implement retry logic and error recovery\n5. **Webhooks**: Set up notifications for Actor run events\n\nKey reference: `llms-txt.md` for detailed API methods and parameters\n\n### For Advanced Users\n\nExplore these topics:\n1. **Actor Builds**: Manage versions and deployments\n2. **Metamorph**: Transform running Actors into different Actors\n3. **Custom Integrations**: Build complex workflows with the API\n4. **Performance Optimization**: Tune concurrency and resource usage\n5. **Multi-Actor Orchestration**: Chain multiple Actors together\n\nKey reference: `llms-full.md` for complete API endpoint reference\n\n### Navigation Tips\n\n- **Search by concept**: Use keywords like \"dataset\", \"actor\", \"build\" to find relevant sections\n- **Check examples**: Look for code blocks in the documentation for working examples\n- **API endpoints**: All endpoints follow the pattern `/v2/{resource}/{action}`\n- **Client methods**: SDK methods mirror API endpoints (e.g., `client.actor().run()`)\n\n## Common Patterns\n\n### Web Scraping Workflow\n\n1. Set up the crawler with initial URLs\n2. Extract links from pages\n3. Filter and enqueue new URLs\n4. Extract data from pages\n5. Store results in a dataset\n6. Handle errors and retries\n\n### Actor Development Workflow\n\n1. Create Actor locally or in Apify Console\n2. Write scraping logic with Cheerio/Puppeteer\n3. Test locally with sample data\n4. Build and deploy to Apify platform\n5. Create tasks for different configurations\n6. Monitor runs and debug issues\n\n### Data Pipeline Pattern\n\n1. Run an Actor to scrape data\n2. Store results in a dataset\n3. Call another Actor to process the data\n4. Export final results to external system\n5. Use webhooks to trigger next steps\n\n## Resources\n\n### Official Documentation\n- **API Reference**: Complete API v2 documentation at https://docs.apify.com/api/v2\n- **SDK Docs**: JavaScript and Python SDK documentation\n- **Academy**: Web scraping tutorials and best practices\n- **Examples**: Ready-to-use Actor templates\n\n### Getting Help\n- Check the reference files for detailed API documentation\n- Review code examples for common patterns\n- Use the Apify Console for visual debugging\n- Monitor Actor runs with detailed logs\n\n## Notes\n\n- This skill was automatically generated from official Apify documentation\n- Reference files preserve structure and examples from source docs\n- Code examples include proper language detection for syntax highlighting\n- Documentation covers both JavaScript and Python SDKs\n- API version 2 is the current stable version\n\n## Best Practices\n\n1. **Always use API tokens** for authentication (never hardcode)\n2. **Handle rate limits** appropriately (respect platform quotas)\n3. **Store credentials securely** using Actor secrets\n4. **Log appropriately** (INFO for progress, DEBUG for details)\n5. **Clean up resources** (close stores/datasets when done)\n6. **Use request queues** for large-scale crawling\n7. **Implement retries** for failed requests\n8. **Monitor Actor memory** usage to prevent crashes\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Re-run the documentation scraper with the same configuration\n2. The skill will be rebuilt with the latest information\n3. Review the updated reference files for new features\n",
        "article-title-optimizer/SKILL.md": "---\nname: article-title-optimizer\ndescription: This skill analyzes article content in-depth and generates optimized, marketable titles in the format 'Title: Subtitle' (10-12 words maximum). The skill should be used when users request title optimization, title generation, or title improvement for articles, blog posts, or written content. It generates 5 title candidates using proven formulas, evaluates them against success criteria (clickability, SEO, clarity, emotional impact, memorability, shareability), and replaces the article's title with the winning candidate.\n---\n\n# Article Title Optimizer\n\n## Overview\n\nThis skill transforms article titles into marketable, attention-grabbing headlines that follow the `<Title>: <Subtitle>` format while maintaining accuracy and avoiding deception. The skill analyzes article content deeply, generates five diverse title candidates using proven copywriting formulas, evaluates each against weighted success criteria, and automatically replaces the original title with the optimal choice.\n\n## Workflow\n\nFollow this sequential process to optimize article titles:\n\n### Step 1: Read and Analyze the Article\n\nRead the article file provided by the user to understand:\n- **Core thesis or argument**: What is the main point or claim?\n- **Key findings or insights**: What are the most important takeaways?\n- **Primary audience**: Who is this written for? (Technical experts, general public, professionals, etc.)\n- **Emotional tone**: Is it serious, provocative, optimistic, cautionary, analytical?\n- **Main keywords**: What terms are central to the topic and likely search queries?\n- **Article type**: Technical/professional, general interest, news, opinion/commentary, how-to guide\n\n**Example analysis for a healthcare AI article:**\n- Core thesis: AI in radiology has transformative potential but faces serious challenges around bias, transparency, and equity\n- Key findings: AI systems show bias against underserved populations, black-box nature creates trust issues, most benefits accrue to wealthy institutions\n- Primary audience: Healthcare professionals, policymakers, tech-aware general readers\n- Emotional tone: Serious, cautionary, balanced\n- Main keywords: AI, radiology, bias, healthcare equity, transparency, trust\n- Article type: Long-form analysis/commentary on emerging technology\n\n### Step 2: Research Title Best Practices\n\nBefore generating candidates, review `references/title_best_practices.md` which contains:\n- Proven title formulas (question, how-to, problem-solution, contrarian, etc.)\n- Success criteria and evaluation framework\n- Common pitfalls to avoid\n- Industry-specific considerations\n- Before/after examples\n\nIf needed, use web search to research:\n- Current trends in article title writing for the specific industry\n- Successful titles in similar topic areas\n- SEO best practices for the article's subject matter\n- Audience preferences for the content type\n\n**Note**: Research should inform title generation but titles must remain authentic to the article content.\n\n### Step 3: Generate 5 Title Candidates\n\nCreate five diverse title candidates using different formulas from the reference guide. Each title must:\n- Follow the `<Title>: <Subtitle>` format\n- Be 10-12 words maximum (total for both parts)\n- Accurately represent the article content\n- Use different approaches/formulas to provide variety\n- Avoid deception, clickbait, or misleading claims\n\n**CRITICAL CONSTRAINTS - All titles must comply:**\n1. **No AI-generated tropes**: Avoid obvious AI writing patterns, especially \"Algorithm/Algorithmic/Algorithms\", \"Black-Box/Black Box\", and clich√©d phrasing like \"The X Will See You Now\", \"Welcome to the Age of X\", \"The Rise of X\"\n2. **No apostrophes**: Do not use apostrophes anywhere in the title (not \"don't\", \"can't\", \"it's\", \"AI's\", etc.)\n3. **No question marks in Title segment**: Question marks create visually awkward ?: combinations when rendered. Questions may be used in the Subtitle segment only, or rephrase as statements.\n\n**Example candidates for healthcare AI article:**\n\n1. **Statement Format**: \"Medical AI and Trust: Why Bias Threatens Healthcare Equity\"\n2. **Problem-Solution Format**: \"Opaque AI in Healthcare: Why Explainability Matters Now\"\n3. **Contrarian Format**: \"AI Will Not Replace Radiologists: But Everything Changes\"\n4. **Impact Format**: \"When Medical AI Fails Minorities: The Data Representation Crisis\"\n5. **Examination Format**: \"Navigating Healthcare AI: Trust, Bias, and the Path Forward\"\n\n### Step 4: Evaluate Each Candidate Against Success Criteria\n\nScore each title candidate (1-10 scale) across six weighted criteria:\n\n1. **Clickability (25% weight)**: Attention-grabbing power, curiosity gap, use of power words\n   - High: Creates strong curiosity, specific and compelling\n   - Low: Generic, boring, or too vague\n\n2. **SEO Effectiveness (20% weight)**: Search optimization and discoverability\n   - Keyword placement in first 3-5 words\n   - Length 50-60 characters ideal\n   - Natural language, not keyword-stuffed\n\n3. **Clarity/Informativeness (20% weight)**: How well title communicates content\n   - High: Reader knows exactly what to expect\n   - Low: Vague, confusing, or misleading\n\n4. **Emotional Impact (15% weight)**: Emotional resonance and engagement\n   - Curiosity, surprise, urgency, relevance to reader concerns\n\n5. **Memorability (10% weight)**: Likelihood to stick in mind\n   - Distinctive phrasing, rhythmic flow, concrete language\n\n6. **Social Shareability (10% weight)**: Likelihood to be shared\n   - Identity expression, conversation starter, platform fit\n\n**Example evaluation for Candidate 1:**\n- Clickability: 8/10 (trust and bias angle creates curiosity)\n- SEO: 8/10 (strong keywords \"Medical AI\", \"Trust\", \"Bias\" well-placed)\n- Clarity: 9/10 (very clear what article covers)\n- Emotional Impact: 7/10 (trust and equity concerns resonate)\n- Memorability: 7/10 (clear and direct phrasing)\n- Shareability: 8/10 (addresses question many people have about AI)\n- **Weighted Score**: (8√ó0.25) + (8√ó0.20) + (9√ó0.20) + (7√ó0.15) + (7√ó0.10) + (8√ó0.10) = **8.05**\n\n### Step 5: Analyze and Select the Winner\n\nAfter scoring all five candidates:\n\n1. **Calculate weighted scores** for each candidate\n2. **Identify top 2-3 performers** based on quantitative scores\n3. **Apply qualitative judgment** considering:\n   - Best fit for article tone and audience\n   - Authenticity to content\n   - No red flags (deception, offense, plagiarism)\n   - Overall \"feel\" when reading aloud\n\n4. **Select the winning title** that:\n   - Has the highest overall score OR\n   - Scores highly and best represents the article's unique angle\n   - Passes all ethical/quality checks\n\n**Example selection rationale:**\n\"After evaluation, Candidate 2 ('Opaque AI in Healthcare: Why Explainability Matters Now') scores highest with 8.3/10. It combines strong clickability (the 'Opaque' descriptor is clear and evocative), excellent clarity about the core issue, and solid SEO with well-placed keywords. While Candidate 1 scored well on clarity and Candidate 5 had good structure, Candidate 2 provides the best balance across all criteria. It avoids AI-generated tropes like 'Black-Box' or 'Algorithm', uses fresh language, and authentically represents the article without relying on clich√©d phrasing.\"\n\n### Step 6: Replace the Title in the Article\n\nUse the Edit tool to replace the article's current title and ensure that you:-\n- Find and replace the first H1 heading in the markdown file\n- Preserve all other content\n- Confirm successful replacement\n\n### Step 7: Present Results to User\n\nProvide the user with:\n1. **The winning title** and brief explanation of why it was chosen\n2. **All five candidates** with their scores (optional but recommended for transparency)\n3. **Confirmation** that the title has been replaced in the file\n4. **Key insights** from the evaluation (what made the winner stand out)\n\n**Example output format:**\n\n```\n‚úì Article title optimized successfully!\n\nWinning Title (Score: 8.3/10):\n\"Opaque AI in Healthcare: Why Explainability Matters Now\"\n\nWhy this title won:\n- Highest overall score across all criteria\n- Fresh \"Opaque\" descriptor avoids overused \"Black-Box\" trope\n- Clear communication of article scope (AI + healthcare + transparency)\n- Strong SEO with well-placed keywords\n- Excellent balance of curiosity and clarity\n- Avoids AI-generated tropes and clich√©d phrasing\n\nAll candidates evaluated:\n1. \"Medical AI and Trust: Why Bias Threatens Healthcare Equity\" (8.0/10)\n2. \"Opaque AI in Healthcare: Why Explainability Matters Now\" (8.3/10) ‚Üê WINNER\n3. \"AI Will Not Replace Radiologists: But Everything Changes\" (7.6/10)\n4. \"When Medical AI Fails Minorities: The Data Representation Crisis\" (7.9/10)\n5. \"Navigating Healthcare AI: Trust, Bias, and the Path Forward\" (7.7/10)\n\nThe title has been updated in: /path/to/article.md\n```\n\n## Key Principles\n\n### Accuracy Over Attraction\nWhile the goal is creating marketable titles, accuracy is non-negotiable:\n- Never misrepresent article content\n- Avoid clickbait or deceptive techniques\n- Ensure promises in title are delivered in content\n- Be specific, not vague\n\n### Format Compliance\nAll titles must follow `<Title>: <Subtitle>` structure with strict constraints:\n- **Title (main)**: Hook the reader, create curiosity\n- **Subtitle**: Clarify, provide context, set expectations\n- **Total length**: 10-12 words maximum\n- **Balance**: Neither part should dominate excessively\n\n**Mandatory Constraints:**\n1. **No AI-generated tropes**: Never use \"Algorithm/Algorithmic/Algorithms\", \"Black-Box/Black Box\", or clich√©d AI-content phrasing like \"The X Will See You Now\", \"Welcome to the Age of X\", \"The Rise of X\", \"X: A Game Changer\"\n2. **No apostrophes**: Avoid contractions and possessives (use \"do not\" instead of \"don't\", \"AI of the future\" instead of \"AI's future\")\n3. **No question marks in Title segment**: Questions create awkward ?: visual combinations. Use questions only in Subtitle, or rephrase as statements\n\n### Diverse Candidate Generation\nGenerate candidates using different formulas to ensure variety:\n- Question format (question must be in Subtitle segment only, or use statement form)\n- How-to format\n- Problem-solution format\n- Contrarian/provocative format\n- Future/trend format\n- Emotional hook format\n- Unexpected juxtaposition\n\nAvoid generating five variations of the same approach. Remember: all candidates must comply with the three mandatory constraints (no AI tropes, no apostrophes, no question marks in Title segment).\n\n### Evidence-Based Selection\nBase the winning title selection on:\n- **Quantitative scores** across six weighted criteria\n- **Qualitative judgment** about fit and authenticity\n- **Ethical checks** for deception, offense, or plagiarism\n- **Alignment** with article tone and target audience\n\nDocument the reasoning for transparency.\n\n## Common Scenarios\n\n### Scenario 1: Technical Article for Expert Audience\n**User request**: \"Optimize the title for this technical paper on neural network architectures\"\n**Approach**:\n- Prioritize clarity and precision over clever wordplay\n- Use correct technical terminology\n- Emphasize novelty or practical benefit\n- Example: \"Transformer Attention Mechanisms: Scaling Efficiency in Large Models\"\n\n### Scenario 2: General Interest Article\n**User request**: \"Make this article about climate change more engaging\"\n**Approach**:\n- Avoid jargon, use accessible language\n- Emphasize human impact and relevance\n- Create emotional connection\n- Example: \"Why Your City Will Flood: Climate Change Comes Home\"\n\n### Scenario 3: How-To Guide\n**User request**: \"Create a better title for this tutorial\"\n**Approach**:\n- Use action-oriented language\n- Make the benefit clear\n- Be specific about what readers will learn\n- Example: \"Master API Testing: Build Robust Tests in 30 Minutes\"\n\n### Scenario 4: Opinion/Commentary\n**User request**: \"This opinion piece needs a stronger title\"\n**Approach**:\n- Signal the viewpoint clearly\n- Be provocative within reason\n- Create discussion-worthy angle\n- Example: \"The Silicon Valley AI Ethics Problem: Why Self-Regulation Failed\"\n\n## Troubleshooting\n\n### Issue: All Candidates Score Very Similarly\n**Solution**: Revisit generation step and create more diverse candidates using different formulas. Ensure variety in approach (question vs. statement, provocative vs. informative, etc.)\n\n### Issue: No Candidates Meet Quality Bar\n**Solution**: Return to article analysis. May have misunderstood core thesis or audience. Re-read article sections and regenerate candidates based on deeper understanding.\n\n### Issue: User Rejects Winning Title\n**Solution**: Ask for specific feedback about what doesn't work. Use that input to either:\n- Select the second-place candidate if it addresses concerns\n- Generate new candidates with adjusted focus\n- Revise winning title while maintaining structure\n\n### Issue: Title Length Exceeds 12 Words\n**Solution**: Edit for conciseness:\n- Remove filler words (very, really, actually, etc.)\n- Use more concise phrasing\n- Combine or eliminate redundant concepts\n- Ensure both title and subtitle are pulling weight\n\n## Resources\n\n### references/title_best_practices.md\nComprehensive guide containing:\n- Proven title formulas with examples\n- Detailed success criteria and evaluation framework\n- Common pitfalls to avoid\n- Industry-specific considerations\n- Before/after transformation examples\n\n**When to reference**: Always review this before generating candidates to ensure adherence to best practices and proper use of formulas.\n",
        "cronjob-org/SKILL.md": "---\nname: cronjob-org\ndescription: Cron-Job.org Documentation\n---\n\n# Cronjob-Org Skill\n\nComprehensive assistance with the Cron-Job.org REST API for programmatically managing scheduled HTTP jobs. This skill provides guidance on creating, updating, deleting, and monitoring cron jobs through the official API.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- **Creating automated HTTP requests** on a schedule using Cron-Job.org\n- **Managing cron jobs programmatically** through the REST API\n- **Implementing job monitoring** and execution history tracking\n- **Setting up notifications** for job failures or successes\n- **Working with API authentication** and rate limits\n- **Debugging cron job executions** or analyzing performance metrics\n- **Building integrations** that require scheduled HTTP calls\n- **Configuring job schedules** using timezone-aware cron expressions\n\n## Key Concepts\n\n### API Authentication\n- **API Keys**: Generated in the Cron-Job.org Console under Settings\n- **Bearer Token**: API keys are sent via the `Authorization` header\n- **IP Restrictions**: Optional IP allowlisting for enhanced security\n- **Rate Limits**: 100 requests/day (default), 5,000 requests/day (sustaining members)\n\n### Job Object\nA Job represents a scheduled HTTP request with:\n- **URL**: The endpoint to call\n- **Schedule**: Cron expression with timezone support\n- **Settings**: Timeout, HTTP method, headers, authentication\n- **State**: Enabled/disabled, execution status, history\n\n### Execution History\nEach job execution creates a HistoryItem containing:\n- **Timing**: Actual vs planned execution time, jitter, duration\n- **Response**: HTTP status code, headers, body (if saveResponses enabled)\n- **Performance**: DNS lookup, connection, SSL handshake, transfer times\n\n### Rate Limits\nDifferent endpoints have different rate limits:\n- **Job List/Details**: 5 requests/second\n- **Job Creation**: 1 request/second, 5 requests/minute\n- **History**: 5 requests/second\n\n## Quick Reference\n\n### 1. Authentication Setup\n\n```bash\n# Set your API key as a bearer token in the Authorization header\nAuthorization: Bearer YOUR_API_KEY_HERE\n```\n\n**Notes:**\n- API keys are generated in the Console ‚Üí Settings\n- Treat API keys as secrets (like passwords)\n- Enable IP restrictions whenever possible for security\n\n### 2. List All Jobs (curl)\n\n```bash\ncurl -X GET https://api.cron-job.org/jobs \\\n  -H \"Authorization: Bearer YOUR_API_KEY\"\n```\n\n**Response:**\n```json\n{\n  \"jobs\": [\n    {\n      \"jobId\": 12345,\n      \"enabled\": true,\n      \"title\": \"Daily Backup\",\n      \"url\": \"https://example.com/backup\",\n      \"lastStatus\": 200,\n      \"lastExecution\": 1699920000,\n      \"nextExecution\": 1700006400\n    }\n  ],\n  \"jobsPartialError\": false\n}\n```\n\n**Rate Limit:** 5 requests/second\n\n### 3. Create a New Job (Python)\n\n```python\nimport requests\n\nAPI_KEY = \"your_api_key_here\"\nheaders = {\n    \"Authorization\": f\"Bearer {API_KEY}\",\n    \"Content-Type\": \"application/json\"\n}\n\njob_data = {\n    \"job\": {\n        \"url\": \"https://example.com/api/health-check\",\n        \"enabled\": True,\n        \"title\": \"Health Check\",\n        \"saveResponses\": True,\n        \"schedule\": {\n            \"timezone\": \"America/New_York\",\n            \"hours\": [-1],          # Every hour\n            \"mdays\": [-1],          # Every day of month\n            \"minutes\": [0],         # At minute 0\n            \"months\": [-1],         # Every month\n            \"wdays\": [-1]           # Every day of week\n        }\n    }\n}\n\nresponse = requests.post(\n    \"https://api.cron-job.org/jobs\",\n    headers=headers,\n    json=job_data\n)\n\nprint(f\"Created job ID: {response.json()['jobId']}\")\n```\n\n**Rate Limit:** 1 request/second, 5 requests/minute\n\n### 4. Update an Existing Job\n\n```python\nimport requests\n\nAPI_KEY = \"your_api_key_here\"\nJOB_ID = 12345\n\nheaders = {\n    \"Authorization\": f\"Bearer {API_KEY}\",\n    \"Content-Type\": \"application/json\"\n}\n\n# Only include fields you want to change\nupdate_data = {\n    \"job\": {\n        \"enabled\": False,  # Disable the job\n        \"title\": \"Updated Title\"\n    }\n}\n\nresponse = requests.patch(\n    f\"https://api.cron-job.org/jobs/{JOB_ID}\",\n    headers=headers,\n    json=update_data\n)\n\nprint(\"Job updated successfully\" if response.status_code == 200 else \"Update failed\")\n```\n\n**Rate Limit:** 5 requests/second\n\n### 5. Job with HTTP Authentication\n\n```json\n{\n  \"job\": {\n    \"url\": \"https://api.example.com/protected\",\n    \"enabled\": true,\n    \"title\": \"Protected Endpoint\",\n    \"auth\": {\n      \"enable\": true,\n      \"user\": \"api_user\",\n      \"password\": \"secret_password\"\n    }\n  }\n}\n```\n\n**Notes:**\n- Uses HTTP Basic Authentication\n- Credentials are stored securely by Cron-Job.org\n\n### 6. Job with Custom Headers\n\n```json\n{\n  \"job\": {\n    \"url\": \"https://api.example.com/webhook\",\n    \"enabled\": true,\n    \"title\": \"Webhook with Headers\",\n    \"extendedData\": {\n      \"headers\": {\n        \"X-API-Key\": \"your-api-key\",\n        \"Content-Type\": \"application/json\",\n        \"User-Agent\": \"MyCronJob/1.0\"\n      },\n      \"body\": \"{\\\"event\\\": \\\"scheduled_check\\\"}\"\n    },\n    \"requestMethod\": 1  // 0=GET, 1=POST, 2=PUT, 3=PATCH, 4=DELETE, etc.\n  }\n}\n```\n\n### 7. Job with Failure Notifications\n\n```json\n{\n  \"job\": {\n    \"url\": \"https://example.com/critical-task\",\n    \"enabled\": true,\n    \"title\": \"Critical Task\",\n    \"notifications\": {\n      \"onFailure\": true,\n      \"onSuccess\": false,\n      \"onDisable\": true\n    }\n  }\n}\n```\n\n**Notification Options:**\n- `onFailure`: Notify after job fails (set `onFailureMinutes` for threshold)\n- `onSuccess`: Notify when job succeeds after previous failure\n- `onDisable`: Notify when job is automatically disabled\n\n### 8. Get Job Execution History\n\n```python\nimport requests\n\nAPI_KEY = \"your_api_key_here\"\nJOB_ID = 12345\n\nheaders = {\"Authorization\": f\"Bearer {API_KEY}\"}\n\nresponse = requests.get(\n    f\"https://api.cron-job.org/jobs/{JOB_ID}/history\",\n    headers=headers\n)\n\ndata = response.json()\nprint(f\"Last {len(data['history'])} executions:\")\nfor item in data['history']:\n    print(f\"  {item['date']}: Status {item['httpStatus']} ({item['duration']}ms)\")\n\nprint(f\"\\nNext executions: {data['predictions']}\")\n```\n\n**Rate Limit:** 5 requests/second\n\n### 9. Schedule Examples\n\n**Every day at 2:30 AM EST:**\n```json\n{\n  \"schedule\": {\n    \"timezone\": \"America/New_York\",\n    \"hours\": [2],\n    \"mdays\": [-1],\n    \"minutes\": [30],\n    \"months\": [-1],\n    \"wdays\": [-1]\n  }\n}\n```\n\n**Every Monday and Friday at 9 AM UTC:**\n```json\n{\n  \"schedule\": {\n    \"timezone\": \"UTC\",\n    \"hours\": [9],\n    \"mdays\": [-1],\n    \"minutes\": [0],\n    \"months\": [-1],\n    \"wdays\": [1, 5]  // 0=Sunday, 1=Monday, ..., 6=Saturday\n  }\n}\n```\n\n**Every 15 minutes:**\n```json\n{\n  \"schedule\": {\n    \"timezone\": \"UTC\",\n    \"hours\": [-1],\n    \"mdays\": [-1],\n    \"minutes\": [0, 15, 30, 45],\n    \"months\": [-1],\n    \"wdays\": [-1]\n  }\n}\n```\n\n### 10. Delete a Job\n\n```python\nimport requests\n\nAPI_KEY = \"your_api_key_here\"\nJOB_ID = 12345\n\nheaders = {\"Authorization\": f\"Bearer {API_KEY}\"}\n\nresponse = requests.delete(\n    f\"https://api.cron-job.org/jobs/{JOB_ID}\",\n    headers=headers\n)\n\nprint(\"Job deleted\" if response.status_code == 200 else \"Delete failed\")\n```\n\n**Rate Limit:** 5 requests/second\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete REST API reference including:\n  - Authentication and security\n  - Rate limits and quotas\n  - All API endpoints (jobs, history)\n  - Request/response formats\n  - Object schemas (Job, DetailedJob, JobSchedule, HistoryItem, etc.)\n  - HTTP status codes and error handling\n  - Timing statistics and performance metrics\n\nUse the reference file for:\n- Detailed object schema documentation\n- Complete list of request/response fields\n- Advanced configuration options\n- Troubleshooting API errors\n\n## Working with This Skill\n\n### For Beginners\n1. Start by **reading the API authentication section** in `references/api.md`\n2. Generate an API key in the Cron-Job.org Console\n3. Use the **Quick Reference examples** above to:\n   - List your existing jobs\n   - Create a simple job with a basic schedule\n   - View execution history\n4. Test with curl or Python before building integrations\n\n### For Intermediate Users\nFocus on:\n- **Custom headers and authentication** for API integrations\n- **Notification settings** for failure alerting\n- **Schedule optimization** using timezone-aware cron expressions\n- **Execution history analysis** for monitoring job performance\n- **Rate limit management** for high-volume applications\n\n### For Advanced Users\nExplore:\n- **Batch job management** with proper rate limit handling\n- **Performance optimization** using timing statistics from HistoryItem\n- **Error handling strategies** based on HTTP status codes\n- **IP allowlisting** for production security\n- **Sustaining membership** for higher API quotas (5,000 requests/day)\n\n### Navigation Tips\n- Use `references/api.md` for complete endpoint documentation\n- Check HTTP status codes section for error troubleshooting\n- Review object schemas for all available configuration fields\n- Reference the schedule examples for common cron patterns\n\n## Common Patterns\n\n### Pattern 1: Health Check Monitoring\nCreate a job that pings your service every 5 minutes and notifies on failure:\n\n```python\njob = {\n    \"url\": \"https://myapp.com/health\",\n    \"enabled\": True,\n    \"title\": \"App Health Check\",\n    \"saveResponses\": False,\n    \"schedule\": {\n        \"timezone\": \"UTC\",\n        \"hours\": [-1],\n        \"mdays\": [-1],\n        \"minutes\": [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55],\n        \"months\": [-1],\n        \"wdays\": [-1]\n    },\n    \"notifications\": {\n        \"onFailure\": True,\n        \"onSuccess\": True,\n        \"onDisable\": True\n    }\n}\n```\n\n### Pattern 2: Daily Data Sync\nTrigger a webhook at 3 AM daily with custom headers:\n\n```python\njob = {\n    \"url\": \"https://api.myapp.com/sync\",\n    \"enabled\": True,\n    \"title\": \"Daily Data Sync\",\n    \"requestMethod\": 1,  # POST\n    \"extendedData\": {\n        \"headers\": {\n            \"X-Sync-Token\": \"secret\",\n            \"Content-Type\": \"application/json\"\n        },\n        \"body\": '{\"action\": \"daily_sync\"}'\n    },\n    \"schedule\": {\n        \"timezone\": \"America/Los_Angeles\",\n        \"hours\": [3],\n        \"mdays\": [-1],\n        \"minutes\": [0],\n        \"months\": [-1],\n        \"wdays\": [-1]\n    }\n}\n```\n\n### Pattern 3: Weekday Business Hours Job\nRun a job every weekday at 9 AM and 5 PM:\n\n```python\njob = {\n    \"url\": \"https://example.com/business-task\",\n    \"enabled\": True,\n    \"title\": \"Business Hours Task\",\n    \"schedule\": {\n        \"timezone\": \"America/New_York\",\n        \"hours\": [9, 17],\n        \"mdays\": [-1],\n        \"minutes\": [0],\n        \"months\": [-1],\n        \"wdays\": [1, 2, 3, 4, 5]  # Monday-Friday\n    }\n}\n```\n\n## HTTP Status Codes\n\n| Code | Description |\n|------|-------------|\n| 200  | OK - Request succeeded |\n| 400  | Bad Request - Invalid request or input data |\n| 401  | Unauthorized - Invalid API key |\n| 403  | Forbidden - API key cannot be used from this origin |\n| 404  | Not Found - Resource doesn't exist |\n| 409  | Conflict - Resource already exists |\n| 429  | Too Many Requests - Quota or rate limit exceeded |\n| 500  | Internal Server Error |\n\n## Important Limits\n\n- **Daily Quota**: 100 requests/day (default), 5,000 requests/day (sustaining members)\n- **Job Creation**: 1 request/second, 5 requests/minute\n- **Other Endpoints**: 5 requests/second\n- **Job Timeout**: Configurable per job (default system timeout applies)\n- **Response Storage**: Enable `saveResponses` to store headers/body in history\n\n## Security Best Practices\n\n1. **Protect API Keys**: Treat them like passwords, never commit to version control\n2. **Enable IP Restrictions**: Limit API access to specific IP addresses\n3. **Use HTTPS**: All API communication is HTTPS-only\n4. **Rotate Keys**: Periodically regenerate API keys\n5. **Monitor Usage**: Track API request counts to avoid quota exhaustion\n\n## Resources\n\n### Official Documentation\n- REST API Docs: https://docs.cron-job.org/rest-api.html\n- Console: https://console.cron-job.org/\n\n### Supported Timezones\nSee the official documentation for a complete list of supported timezone values (e.g., \"UTC\", \"America/New_York\", \"Europe/London\").\n\n### Example Use Cases\n- **API Health Checks**: Monitor service availability\n- **Data Synchronization**: Trigger scheduled data imports/exports\n- **Report Generation**: Generate and send periodic reports\n- **Cache Warming**: Pre-load caches before peak traffic\n- **Webhook Delivery**: Send scheduled webhook notifications\n- **Backup Triggers**: Initiate automated backup processes\n\n## Troubleshooting\n\n### 401 Unauthorized\n- Verify API key is correct\n- Check Authorization header format: `Authorization: Bearer YOUR_KEY`\n- Ensure API key hasn't been revoked\n\n### 403 Forbidden\n- Check if IP restrictions are enabled\n- Verify your IP address is allowlisted\n\n### 429 Too Many Requests\n- Review rate limits for specific endpoint\n- Implement exponential backoff\n- Consider sustaining membership for higher limits\n\n### Job Not Executing\n- Verify job is enabled\n- Check schedule configuration\n- Review `nextExecution` timestamp\n- Check if job has been auto-disabled due to failures\n\n### Missing Response Data in History\n- Ensure `saveResponses` is set to `true`\n- Use the detailed history item endpoint for headers/body\n\n## Notes\n\n- All timestamps are Unix timestamps in seconds\n- Schedule uses arrays where `[-1]` means \"all values\" (every hour, every day, etc.)\n- Job execution times may have jitter (scheduling delay) - check `HistoryItem.jitter`\n- Failed jobs may be automatically disabled based on notification settings\n- Execution history is limited; use the API to retrieve recent items\n\n## Updating\n\nThis skill was generated from official Cron-Job.org documentation. For the latest API changes:\n1. Visit https://docs.cron-job.org/rest-api.html\n2. Check for new endpoints or schema changes\n3. Update your integration code accordingly\n",
        "figlet-text-converter/SKILL.md": "---\nname: figlet-text-converter\ndescription: This skill processes files containing figlet tags and replaces them with ASCII art representations. It detects and preserves comment styles (forward slash forward slash, hash, double-dash, forward slash asterisk), automatically manages Node.js dependencies, and supports 400+ fonts (defaulting to the standard font). The skill should be used when a user requests converting marked text in a file to ASCII art using figlet tag syntax, or when they want to list available fonts.\n---\n\n# Figlet Text Converter\n\n## Overview\n\nThis skill converts marked text in files to ASCII art using the figlet library. It uses a simple, universal tag syntax that works across all file types and intelligently preserves comment formatting when tags are placed in commented sections. The skill handles dependency management automatically and supports 400+ fonts with sensible defaults.\n\n## When to Use This Skill\n\nUse this skill when:\n- User asks to convert text in a file to ASCII art\n- User provides a file containing `<figlet>` tags\n- User requests to list available figlet fonts\n- User wants to add visual ASCII art headers or banners to code, documentation, or configuration files\n\n## Tag Syntax\n\n### Universal Markup\n\nInsert `<figlet>` tags anywhere in a file to mark text for ASCII art conversion:\n\n**With font specification:**\n```\n<figlet font=\"3-D\">Text to Convert</figlet>\n```\n\n**Using default font (standard):**\n```\n<figlet>Text to Convert</figlet>\n```\n\n### Usage in Different Contexts\n\n#### Markdown Documents\n```markdown\n# Section Title\n\n<figlet font=\"Standard\">Important Notice</figlet>\n\nContent goes here...\n```\n\n#### Shell Scripts\n```bash\n#!/bin/bash\n\necho '<figlet>Deployment Started</figlet>'\n\n# Script logic...\n```\n\n#### Python Code\n```python\n# <figlet>Configuration</figlet>\n\nconfig = {\n    'setting': 'value'\n}\n```\n\n#### PHP/JavaScript\n```php\n// <figlet font=\"Block\">Database Connection</figlet>\n\nfunction connectDB() {\n    // ...\n}\n```\n\n#### Plain Text/Config Files\n```\n<figlet>System Status Report</figlet>\n\nThis report contains...\n```\n\n## Workflow\n\n### Processing a File\n\nWhen a user requests ASCII art conversion:\n\n1. Read the file containing `<figlet>` tags\n2. Validate all font names (error immediately if invalid)\n3. For each tag:\n   - Extract the font name (or use 'standard' if omitted)\n   - Generate ASCII art for the text\n   - Detect comment style from the surrounding line (// # -- /*)\n   - Format output with appropriate comment prefixes\n4. Replace tags with formatted ASCII art\n5. Write changes back to the file\n\n### Handling Comments\n\nThe skill automatically detects comment context:\n\n**Single-line comments:**\n```bash\n// <figlet>Section Break</figlet>\n```\nOutputs each line with `// ` prefix:\n```bash\n// ___         _   _                  ____          _\n// / __| ___  | | | | ___  _ _      | __ ) _ _  __| | |\n// \\__ \\/ -_) | |_| |/ _ \\| '  \\    | _ \\| '_|/ _` | |\n// |___/\\___|  \\___/ \\___/|_|_|_|   |_| \\_\\_|  \\__,_|_|\n```\n\n**Hash comments (Python, Shell):**\n```python\n# <figlet>Configuration</figlet>\n```\nOutputs with `# ` prefix.\n\n**SQL/SQL comments:**\n```sql\n-- <figlet>Query Section</figlet>\n```\nOutputs with `-- ` prefix.\n\n**Block comments:**\n```java\n/* <figlet>Module Start</figlet>\n```\nOutputs with ` * ` prefix:\n```java\n * ___  _           _     _        ___   _             _\n * |  \\/  | ___   __| | _ | | ___  / __| | |_  __ _  _ | |_\n * | |\\/| |/ _ \\ / _` ||_|| |/ -_) \\__ \\ |  _|/ _` || ||  _|\n * |_|  |_|\\___/ \\__,_| \\__/ \\___|  |___/ |_|  \\__,_|\\__|\\__|\n```\n\n**Plain text (no comment prefix):**\n```\n<figlet>Plain ASCII Art</figlet>\n```\nOutputs raw ASCII art without formatting.\n\n## Font Selection\n\n### Default Font\n\nIf no font is specified, 'standard' is used:\n```\n<figlet>Default Font Example</figlet>\n```\n\n### Custom Fonts\n\nSpecify any of 400+ available fonts:\n```\n<figlet font=\"Block\">Bold Text</figlet>\n<figlet font=\"3-D\">3D Effect</figlet>\n<figlet font=\"Shadow\">Shadowed</figlet>\n```\n\n### Finding Fonts\n\nWhen user requests to list available fonts, run the font discovery script to show:\n- Previews of the first 10 fonts with examples\n- Complete alphabetical listing of all 400+ fonts\n- Font names for use in tags\n\nPopular fonts:\n- standard (default)\n- 3-D\n- Block\n- Big\n- Shadow\n- Slant\n- Graffiti\n- Doom\n\n## Error Handling\n\nThe skill validates fonts before processing:\n- **Invalid font specified**: Error immediately with font name and suggestion to list available fonts\n- **File not found**: Error with file path\n- **Node.js/npm issues**: Error with installation instructions\n\n## Bundled Resources\n\n### scripts/\n\n**process-file.js**\n- Main processing script that reads files, finds all `<figlet>` tags, validates fonts, generates ASCII art, detects comment styles, and writes results\n- Handles automatic Node.js verification and npm dependency installation on first run\n- Usage: `node process-file.js <file-path>`\n\n**list-fonts.js**\n- Displays all available figlet fonts with previews and complete listing\n- Helps users find the exact font names to use in tags\n- Usage: `node list-fonts.js`\n\n**package.json**\n- Node.js project file with figlet v1.7.0+ dependency\n\n**.gitignore**\n- Excludes node_modules from version control\n\n### references/\n\n**usage-guide.md** - Comprehensive reference documentation for all features and edge cases\n\n## Technical Details\n\n- **Node.js Requirement**: v14 or higher\n- **Figlet Package**: v1.7.0 or higher (auto-installed on first use)\n- **Tag Format**: `<figlet font=\"font-name\">text</figlet>` or `<figlet>text</figlet>`\n- **Comment Styles Supported**: //, #, --, /*, or none\n- **Default Font**: standard\n- **File Processing**: In-place modification\n",
        "forem-api/SKILL.md": "---\nname: forem-api\ndescription: Forem API\n---\n\n# Forem API Skill\n\nComprehensive assistance with Forem API (v1) development. Forem is the platform that powers DEV.to and other online communities. This skill provides guidance on interacting with articles, users, comments, organizations, tags, and more through the Forem REST API.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- **Building integrations with Forem-based platforms** (DEV.to, Forem communities)\n- **Publishing or managing articles programmatically** via Forem API\n- **Retrieving user data, comments, or organization information** from Forem\n- **Implementing authentication** with Forem API keys\n- **Working with tags, followers, reading lists, or reactions** on Forem\n- **Debugging Forem API requests** or understanding response formats\n- **Learning Forem API endpoints** and best practices\n- **Managing display ads or podcast episodes** through the API\n\n## Quick Reference\n\n### Authentication Setup\n\nSet up authentication headers for Forem API v1 requests:\n\n```bash\n# Required headers for authenticated requests\ncurl -X GET \"https://dev.to/api/articles/me\" \\\n  -H \"api-key: YOUR_API_KEY\" \\\n  -H \"accept: application/vnd.forem.api-v1+json\"\n```\n\n**Key points:**\n- Generate API key at `dev.to/settings/extensions`\n- Use `api-key` header (not `Authorization`)\n- Include `accept: application/vnd.forem.api-v1+json` header\n\n### Get Authenticated User Info\n\n```bash\n# Retrieve current user's profile information\ncurl -X GET \"https://dev.to/api/users/me\" \\\n  -H \"api-key: YOUR_API_KEY\" \\\n  -H \"accept: application/vnd.forem.api-v1+json\"\n```\n\n**Response:**\n```json\n{\n  \"type_of\": \"user\",\n  \"id\": 1431,\n  \"username\": \"username480\",\n  \"name\": \"User Name\",\n  \"twitter_username\": \"twitter_handle\",\n  \"github_username\": \"github_handle\",\n  \"joined_at\": \"Apr 14, 2023\",\n  \"profile_image\": \"/uploads/user/profile_image/...\"\n}\n```\n\n### Publish a New Article\n\n```javascript\n// Create and publish an article with tags\nconst response = await fetch('https://dev.to/api/articles', {\n  method: 'POST',\n  headers: {\n    'api-key': 'YOUR_API_KEY',\n    'accept': 'application/vnd.forem.api-v1+json',\n    'content-type': 'application/json'\n  },\n  body: JSON.stringify({\n    article: {\n      title: \"Getting Started with Forem API\",\n      description: \"Learn how to integrate with Forem\",\n      body_markdown: \"## Introduction\\n\\n**Forem** is amazing!\",\n      published: true,\n      tags: [\"webdev\", \"api\", \"tutorial\"]\n    }\n  })\n});\n\nconst data = await response.json();\nconsole.log(data.url); // https://dev.to/username/getting-started-...\n```\n\n**Returns:** Article object with `id`, `slug`, `path`, `url`, and `published_timestamp`\n\n### Get Published Articles with Filters\n\n```python\nimport requests\n\n# Get JavaScript articles from the last 7 days\nparams = {\n    'tag': 'javascript',\n    'top': 7,\n    'per_page': 10,\n    'page': 1\n}\n\nresponse = requests.get(\n    'https://dev.to/api/articles',\n    params=params,\n    headers={'accept': 'application/vnd.forem.api-v1+json'}\n)\n\narticles = response.json()\nfor article in articles:\n    print(f\"{article['title']} by {article['user']['name']}\")\n```\n\n**Query parameters:**\n- `tag` - Filter by single tag\n- `tags` - Multiple tags (comma-separated)\n- `username` - Filter by author\n- `top` - Days since publication\n- `per_page` - Results per page (30-1000)\n- `page` - Page number for pagination\n\n### Get User's Draft Articles\n\n```bash\n# Retrieve your unpublished articles\ncurl -X GET \"https://dev.to/api/articles/me/unpublished\" \\\n  -H \"api-key: YOUR_API_KEY\" \\\n  -H \"accept: application/vnd.forem.api-v1+json\"\n```\n\n**Other endpoints:**\n- `/articles/me` - All your articles\n- `/articles/me/published` - Published only\n- `/articles/me/unpublished` - Drafts only\n- `/articles/me/all` - Everything including hidden\n\n### Update an Existing Article\n\n```json\nPUT /articles/{id}\nContent-Type: application/json\nHeaders: api-key, accept\n\n{\n  \"article\": {\n    \"title\": \"Updated Title\",\n    \"body_markdown\": \"Updated content with **bold** text\",\n    \"published\": true\n  }\n}\n```\n\n### Get Comments for an Article\n\n```python\n# Get comments by article ID\nresponse = requests.get(\n    'https://dev.to/api/comments',\n    params={'a_id': 123456},\n    headers={'accept': 'application/vnd.forem.api-v1+json'}\n)\n\ncomments = response.json()\nfor comment in comments:\n    print(f\"{comment['user']['name']}: {comment['body_html']}\")\n```\n\n**Query parameters:**\n- `a_id` - Article ID\n- `p_id` - Podcast episode ID\n\n### Create a Reaction (Like)\n\n```bash\n# Add a \"like\" reaction to an article\ncurl -X POST \"https://dev.to/api/reactions\" \\\n  -H \"api-key: YOUR_API_KEY\" \\\n  -H \"accept: application/vnd.forem.api-v1+json\" \\\n  -H \"content-type: application/json\" \\\n  -d '{\n    \"category\": \"like\",\n    \"reactable_id\": 123456,\n    \"reactable_type\": \"Article\"\n  }'\n```\n\n**Categories:** `like`, `unicorn`, `readinglist`, `thinking`\n\n### Get Organization Details\n\n```bash\n# Fetch organization information and articles\ncurl -X GET \"https://dev.to/api/organizations/forem\" \\\n  -H \"accept: application/vnd.forem.api-v1+json\"\n\n# Get organization's published articles\ncurl -X GET \"https://dev.to/api/organizations/forem/articles\" \\\n  -H \"accept: application/vnd.forem.api-v1+json\"\n```\n\n### Get Available Tags\n\n```javascript\n// Fetch popular tags from the platform\nconst response = await fetch('https://dev.to/api/tags', {\n  headers: { 'accept': 'application/vnd.forem.api-v1+json' }\n});\n\nconst tags = await response.json();\ntags.forEach(tag => {\n  console.log(`${tag.name} - ${tag.bg_color_hex}`);\n});\n```\n\n## Key Concepts\n\n### API Versions\n- **API v1** - Current recommended version (`application/vnd.forem.api-v1+json`)\n- **API v0** - Deprecated legacy version\n\n### Authentication\n- **API Key Authentication** - Required for most write operations\n- **Public Endpoints** - Some GET endpoints work without authentication\n- **CORS Policy** - Disabled on authenticated endpoints, open on public endpoints\n\n### Response Formats\nAll responses use JSON format with consistent structure:\n- `type_of` - Resource type (article, user, comment, etc.)\n- `id` - Unique identifier\n- Standard fields based on resource type\n\n### Rate Limiting\nFollow best practices to avoid rate limits:\n- Use pagination for large datasets\n- Cache responses when appropriate\n- Implement exponential backoff for retries\n\n### Pagination\nMost list endpoints support pagination:\n- `page` - Page number (starts at 1)\n- `per_page` - Items per page (typically 30-1000, default 30)\n\n### Common Status Codes\n- `200` - Success (GET, PUT)\n- `201` - Created (POST)\n- `204` - No Content (DELETE, unpublish)\n- `401` - Unauthorized (invalid API key)\n- `404` - Not Found\n- `422` - Unprocessable Entity (validation errors)\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete Forem API v1 reference documentation\n\nUse `view` or read the reference file directly when you need:\n- Detailed endpoint specifications\n- Complete parameter lists\n- Response schema details\n- Additional code examples\n\n## Working with This Skill\n\n### For Beginners\n1. **Start with authentication** - Generate your API key at `dev.to/settings/extensions`\n2. **Try read-only endpoints first** - Use `GET /articles` or `GET /users/{username}` without auth\n3. **Test with curl** - The examples above work directly in your terminal\n4. **Use the Quick Reference** - Start with common patterns like getting articles or user info\n\n### For Building Integrations\n1. **Understand pagination** - Most lists require pagination for large datasets\n2. **Handle errors gracefully** - Check status codes and response messages\n3. **Use proper headers** - Always include both `api-key` and `accept` headers\n4. **Test in development** - Use a test account before production deployment\n\n### For Content Management\n1. **Publishing workflow** - Create drafts (`published: false`), review, then update to publish\n2. **Bulk operations** - Use pagination to process all articles\n3. **Tag management** - Fetch available tags before creating articles\n4. **Markdown support** - Use `body_markdown` field with full Markdown syntax\n\n### For Advanced Users\n1. **Admin operations** - Unpublish, suspend, invite (requires appropriate permissions)\n2. **Display ads** - Create and manage promotional content\n3. **Organization management** - Handle multi-author accounts\n4. **Webhook integration** - Combine with webhooks for real-time updates\n\n## Common Endpoints Summary\n\n### Articles\n- `POST /articles` - Publish new article\n- `GET /articles` - Get published articles (paginated)\n- `GET /articles/{id}` - Get specific article\n- `PUT /articles/{id}` - Update article\n- `GET /articles/me` - Your articles\n- `PUT /articles/{id}/unpublish` - Unpublish article\n\n### Users\n- `GET /users/me` - Current user info\n- `GET /users/{id}` - User by ID/username\n\n### Comments\n- `GET /comments` - Get comments by article/episode\n- `GET /comments/{id}` - Specific comment with descendants\n\n### Organizations\n- `GET /organizations/{username}` - Organization details\n- `GET /organizations/{username}/articles` - Organization's articles\n- `GET /organizations/{username}/users` - Organization members\n\n### Tags & Follows\n- `GET /tags` - Available tags\n- `GET /follows/tags` - User's followed tags\n- `GET /followers/users` - User's followers\n\n### Engagement\n- `POST /reactions` - Create reaction\n- `POST /reactions/toggle` - Toggle reaction\n- `GET /readinglist` - User's reading list\n\n## Resources\n\n### Official Documentation\n- **API Reference:** https://developers.forem.com/api/v1\n- **OpenAPI Spec:** https://github.com/forem/forem-docs/blob/main/api_v1.json\n- **Forem GitHub:** https://github.com/forem/forem\n\n### Getting Help\n- **Forem Creators Community:** https://forem.dev\n- **DEV Community:** https://dev.to/t/forem\n- **Issue Tracker:** https://github.com/forem/forem/issues\n\n## Notes\n\n- This skill covers Forem API v1 (current stable version)\n- API keys are generated at `dev.to/settings/extensions` or your Forem instance settings\n- Most endpoints require the `application/vnd.forem.api-v1+json` accept header\n- Public endpoints (like listing articles) work without authentication\n- Admin endpoints require appropriate user permissions\n- Rate limits apply - implement proper pagination and caching\n\n## Best Practices\n\n1. **Always include both required headers** (`api-key` and `accept`)\n2. **Use pagination for large result sets** (don't fetch 1000 articles at once)\n3. **Handle errors gracefully** with proper status code checking\n4. **Cache responses when appropriate** to reduce API calls\n5. **Use Markdown formatting** in `body_markdown` for rich content\n6. **Test with a development account** before production use\n7. **Respect rate limits** and implement exponential backoff\n8. **Keep API keys secure** - never commit them to version control\n",
        "frankenphp/SKILL.md": "---\nname: frankenphp\ndescription: FrankenPHP Documentation - Modern PHP application server built on Caddy\n---\n\n# FrankenPHP Skill\n\nComprehensive assistance with FrankenPHP development - a modern PHP application server built on top of the Caddy web server. FrankenPHP enables persistent PHP processes with worker mode, automatic HTTPS, HTTP/2, HTTP/3, and real-time capabilities via Mercure integration.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Setting up or configuring FrankenPHP server\n- Implementing FrankenPHP worker mode for performance optimization\n- Integrating FrankenPHP with Laravel, Symfony, or other PHP frameworks\n- Deploying PHP applications with Docker using FrankenPHP\n- Converting traditional PHP apps to use persistent workers\n- Configuring automatic HTTPS, HTTP/2, or HTTP/3\n- Implementing real-time features with Mercure\n- Creating standalone, self-executable PHP applications\n- Optimizing PHP application performance with persistent processes\n- Troubleshooting FrankenPHP worker mode or configuration issues\n\n## Quick Reference\n\n### Installation & Basic Server\n\n**Install via curl (Linux/macOS):**\n```bash\ncurl https://frankenphp.dev/install.sh | sh\nmv frankenphp /usr/local/bin/\n\n# Start server in current directory\nfrankenphp php-server\n```\n\n**Install via Homebrew:**\n```bash\nbrew install dunglas/frankenphp/frankenphp\nfrankenphp php-server\n```\n\n**Quick Docker deployment:**\n```bash\ndocker run -v $PWD:/app/public \\\n    -p 80:80 -p 443:443 -p 443:443/udp \\\n    dunglas/frankenphp\n```\n\n### Basic Worker Mode\n\n**Start worker with standalone binary:**\n```bash\nfrankenphp php-server --worker /path/to/your/worker/script.php\n```\n\n**Docker with worker mode:**\n```bash\ndocker run \\\n    -e FRANKENPHP_CONFIG=\"worker /app/public/index.php\" \\\n    -v $PWD:/app \\\n    -p 80:80 -p 443:443 -p 443:443/udp \\\n    dunglas/frankenphp\n```\n\n**Worker with 42 processes:**\n```bash\ndocker run \\\n    -e FRANKENPHP_CONFIG=\"worker ./public/index.php 42\" \\\n    -v $PWD:/app \\\n    -p 80:80 -p 443:443 -p 443:443/udp \\\n    dunglas/frankenphp\n```\n\n### Custom Worker Script\n\n**Basic worker pattern:**\n```php\n<?php\n// public/index.php\n\nignore_user_abort(true);\n\nrequire __DIR__.'/vendor/autoload.php';\n\n$myApp = new \\App\\Kernel();\n$myApp->boot();\n\n$handler = static function () use ($myApp) {\n    try {\n        echo $myApp->handle($_GET, $_POST, $_COOKIE, $_FILES, $_SERVER);\n    } catch (\\Throwable $exception) {\n        (new \\MyCustomExceptionHandler)->handleException($exception);\n    }\n};\n\n$maxRequests = (int)($_SERVER['MAX_REQUESTS'] ?? 0);\nfor ($nbRequests = 0; !$maxRequests || $nbRequests < $maxRequests; ++$nbRequests) {\n    $keepRunning = \\frankenphp_handle_request($handler);\n    $myApp->terminate();\n    gc_collect_cycles();\n    if (!$keepRunning) break;\n}\n\n$myApp->shutdown();\n```\n\n### Laravel Integration\n\n**Laravel Octane installation:**\n```bash\ncomposer require laravel/octane\nphp artisan octane:install --server=frankenphp\nphp artisan octane:frankenphp\n```\n\n**Laravel with Docker:**\n```bash\ndocker run -p 80:80 -p 443:443 -p 443:443/udp \\\n    -v $PWD:/app \\\n    dunglas/frankenphp\n```\n\n**Laravel Caddyfile:**\n```\n{\n\tfrankenphp\n}\n\nlocalhost {\n\troot public/\n\tencode zstd br gzip\n\tphp_server {\n\t\ttry_files {path} index.php\n\t}\n}\n```\n\n**Octane with file watching:**\n```bash\nphp artisan octane:frankenphp --watch\n```\n\n### Symfony Integration\n\n**Symfony worker with runtime:**\n```bash\ncomposer require runtime/frankenphp-symfony\n\ndocker run \\\n    -e FRANKENPHP_CONFIG=\"worker ./public/index.php\" \\\n    -e APP_RUNTIME=Runtime\\\\FrankenPhpSymfony\\\\Runtime \\\n    -v $PWD:/app \\\n    -p 80:80 -p 443:443 -p 443:443/udp \\\n    dunglas/frankenphp\n```\n\n### Worker Management\n\n**Watch files for changes (auto-reload):**\n```bash\nfrankenphp php-server --worker /path/to/worker.php \\\n    --watch=\"/path/to/your/app/**/*.php\"\n```\n\n**Restart workers via API:**\n```bash\ncurl -X POST http://localhost:2019/frankenphp/workers/restart\n```\n\n**Configure max consecutive failures (Caddyfile):**\n```\nfrankenphp {\n    worker {\n        max_consecutive_failures 10\n    }\n}\n```\n\n### Superglobals in Worker Mode\n\n**Accessing worker-bound vs request-bound values:**\n```php\n<?php\n// Capture worker-level values before request loop\n$workerServer = $_SERVER;\n\n$handler = static function () use ($workerServer) {\n    var_dump($_SERVER);      // Current request superglobals\n    var_dump($workerServer); // Original worker values\n};\n```\n\n## Key Concepts\n\n### Worker Mode\nFrankenPHP's worker mode keeps your PHP application loaded in memory between requests, dramatically improving performance. Instead of bootstrapping your application for each request (traditional PHP), the application boots once and handles thousands of requests with the same process.\n\n**Benefits:**\n- Boot your application once, handle requests in milliseconds\n- Persistent database connections\n- Preloaded classes and configuration\n- Significantly reduced memory overhead\n\n**Key Pattern:** Use `frankenphp_handle_request($handler)` to process each request within a persistent loop, calling `gc_collect_cycles()` after each request to prevent memory leaks.\n\n### Caddy Integration\nFrankenPHP is built on top of Caddy, meaning you get:\n- **Automatic HTTPS** - Zero-config TLS certificates via Let's Encrypt\n- **HTTP/2 & HTTP/3** - Modern protocol support out of the box\n- **Powerful configuration** - Use Caddyfile for server configuration\n\n### Early Hints (103 Status)\nFrankenPHP supports HTTP 103 Early Hints, allowing browsers to start loading critical resources (CSS, JS, fonts) while the server is still generating the full response.\n\n### Mercure Real-Time\nBuilt-in support for Mercure protocol enables real-time push notifications from server to browser using Server-Sent Events (SSE). Perfect for live updates, notifications, and collaborative features.\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Core FrankenPHP documentation including installation, configuration, worker mode, framework integration, deployment, and production setup\n\nThe reference file contains detailed information from the official FrankenPHP documentation at https://frankenphp.dev/docs/\n\nUse the reference file when you need:\n- Detailed installation instructions for different platforms\n- Advanced Caddyfile configuration examples\n- Framework-specific integration patterns (Laravel, Symfony, WordPress, etc.)\n- Production deployment strategies\n- Performance optimization techniques\n- Static binary compilation guides\n- Docker configuration options\n\n## Working with This Skill\n\n### For Beginners\n1. **Start with basic installation** - Use the curl install script or Docker for quickest setup\n2. **Run traditional PHP first** - Use `frankenphp php-server` without worker mode to verify setup\n3. **Test with simple scripts** - Create a basic `index.php` to understand the server behavior\n4. **Learn Caddyfile basics** - Understand how to configure domains and paths\n5. **Gradually adopt worker mode** - Once comfortable, convert to worker mode for performance\n\n### For Laravel Developers\n1. **Use Laravel Octane** - The official integration provides the smoothest experience\n2. **Start with Docker** - Use the official `dunglas/frankenphp` image\n3. **Configure Mercure** - Add real-time capabilities to your Laravel app\n4. **Optimize workers** - Tune worker count based on your traffic patterns\n5. **Use file watching** - Enable `--watch` during development for auto-reload\n\n### For Symfony Developers\n1. **Install Symfony runtime** - Use `runtime/frankenphp-symfony` package\n2. **Set APP_RUNTIME** - Configure environment variable for automatic integration\n3. **Use worker mode** - Leverage persistent processes for maximum performance\n4. **Deploy with Docker** - Use official containers for production\n\n### For Production Deployment\n1. **Review worker configuration** - Set appropriate worker count and max requests\n2. **Configure failure handling** - Set `max_consecutive_failures` threshold\n3. **Enable monitoring** - Use Caddy admin API for health checks and metrics\n4. **Set up log analytics** - Configure structured JSON logs\n5. **Plan restart strategy** - Use `MAX_REQUESTS` or manual API restarts to prevent memory leaks\n6. **Test with load** - Validate performance under realistic traffic patterns\n\n### For Docker Users\n1. **Use official images** - Start with `dunglas/frankenphp` or `dunglas/frankenphp:static-builder`\n2. **Mount your app** - Volume mount your code to `/app`\n3. **Configure via ENV** - Use `FRANKENPHP_CONFIG` for worker setup\n4. **Expose ports** - Map 80, 443 (TCP), and 443 (UDP) for HTTP/3\n5. **Use localhost** - Access via `https://localhost` (not 127.0.0.1)\n\n## Common Patterns\n\n### Performance Optimization\n- **Use worker mode** for all production applications\n- **Set MAX_REQUESTS** to restart workers periodically (prevents memory leaks)\n- **Call gc_collect_cycles()** after each request in custom workers\n- **Tune worker count** based on CPU cores and memory available\n- **Enable HTTP/2 push** for critical assets\n\n### Development Workflow\n- **Use --watch flag** for automatic reload during development\n- **Traditional mode** for debugging (easier to trace issues)\n- **Docker for consistency** across development and production environments\n- **Caddyfile per environment** (dev, staging, prod) with different configs\n\n### Error Handling\n- **Wrap handlers** in try-catch blocks within worker loop\n- **Log exceptions** but keep worker running\n- **Use max_consecutive_failures** to restart problematic workers\n- **Monitor worker health** via Caddy admin API\n\n## Resources\n\n### Official Documentation\n- **Main docs:** https://frankenphp.dev/docs/\n- **Worker mode guide:** https://frankenphp.dev/docs/worker/\n- **Laravel integration:** https://frankenphp.dev/docs/laravel/\n- **Symfony integration:** https://frankenphp.dev/docs/symfony/\n\n### Framework Integration\n- Laravel Octane: Official integration via `laravel/octane` package\n- Symfony Runtime: Use `runtime/frankenphp-symfony` package\n- WordPress, Drupal, Joomla, TYPO3: Supported frameworks\n- API Platform: First-class FrankenPHP support\n\n### Docker Images\n- **Production:** `dunglas/frankenphp`\n- **Static builder:** `dunglas/frankenphp:static-builder`\n- **Latest tag:** Always includes PHP 8.4+ and popular extensions\n\n## Notes\n\n- FrankenPHP includes PHP 8.4 and most popular extensions in static binaries\n- Can be embedded as a Go library via `net/http` for custom applications\n- Worker mode requires careful superglobals management (use closures to capture state)\n- HTTPS is automatic via Let's Encrypt (no certificate configuration needed)\n- HTTP/3 support requires UDP port 443 to be accessible\n- File watching uses system-specific file monitoring (efficient, no polling)\n\n## Troubleshooting\n\n### Worker Not Starting\n- Check worker script path is absolute or relative to document root\n- Verify worker script has no syntax errors (`php -l script.php`)\n- Check file permissions (script must be readable)\n- Review logs for initialization errors\n\n### Memory Leaks in Workers\n- Call `gc_collect_cycles()` after each request\n- Set `MAX_REQUESTS` to restart workers periodically\n- Avoid global state accumulation\n- Check for unclosed resources (files, connections)\n\n### Performance Issues\n- Increase worker count (`FRANKENPHP_CONFIG=\"worker ./index.php 42\"`)\n- Check worker restart frequency (too frequent = performance loss)\n- Review database connection pooling\n- Monitor memory usage per worker\n- Verify no blocking operations in request handler\n\n### HTTPS Not Working\n- Ensure ports 80 and 443 are accessible\n- Check firewall rules\n- Verify domain DNS points to server\n- Use `localhost` (not 127.0.0.1) for local development\n- Accept self-signed certificate in browser for local testing\n\n## Updating\n\nTo stay current with FrankenPHP:\n1. Follow the official GitHub repository for updates\n2. Review changelog for breaking changes\n3. Test updates in staging environment\n4. Update Docker images regularly (`docker pull dunglas/frankenphp:latest`)\n5. Check framework-specific integration docs for version compatibility\n",
        "github-issue-fetcher/SKILL.md": "---\nname: github-issue-fetcher\ndescription: This skill should be used when users need to fetch GitHub issues from the current repository, including getting the next issue to work on, retrieving specific issue fields (body, number, title, labels, etc.), or querying issues with custom sorting and filtering. Triggers on requests like \"get the next GitHub issue\", \"what's the next issue number\", \"show me the issue body\", or \"find issues with label X\".\n---\n\n# GitHub Issue Fetcher\n\n## Overview\n\nFetch GitHub issues from the current repository using the `gh` CLI tool with flexible sorting, filtering, and field extraction capabilities. This skill provides patterns for common workflows like getting the next issue to work on, extracting specific fields, and querying issues with custom criteria.\n\n## Prerequisites\n\nThis skill requires two command-line tools to be installed:\n\n1. **GitHub CLI (`gh`)** - Official GitHub command-line tool\n2. **jq** - JSON processor for parsing command output\n\n### Checking Dependencies\n\nBefore executing issue commands, verify both tools are available:\n\n```bash\n# Check if gh is installed\ncommand -v gh >/dev/null 2>&1 || echo \"gh not found\"\n\n# Check if jq is installed\ncommand -v jq >/dev/null 2>&1 || echo \"jq not found\"\n```\n\n### Installation Guidance\n\nIf a required tool is missing, provide the user with installation instructions based on their platform:\n\n**GitHub CLI (`gh`):**\n- macOS: `brew install gh`\n- Linux (Debian/Ubuntu): `sudo apt install gh`\n- Linux (Fedora/RHEL): `sudo dnf install gh`\n- Windows: `winget install --id GitHub.cli`\n- Other: Visit https://cli.github.com/\n\n**jq:**\n- macOS: `brew install jq`\n- Linux (Debian/Ubuntu): `sudo apt-get install jq`\n- Linux (Fedora/RHEL): `sudo dnf install jq`\n- Windows: `winget install jqlang.jq`\n- Other: Visit https://jqlang.github.io/jq/download/\n\n### GitHub Authentication\n\nThe `gh` CLI requires authentication. If the user encounters authentication errors, guide them to run:\n\n```bash\ngh auth login\n```\n\nThis will prompt them through the authentication flow.\n\n## Core Capabilities\n\n### 1. Detecting the Current Repository\n\nTo automatically determine the current repository, use git commands:\n\n```bash\n# Get the repository in owner/repo format\nREPO=$(git config --get remote.origin.url | sed -E 's|.*github\\.com[:/]([^/]+/[^.]+)(\\.git)?|\\1|')\n```\n\nAlternatively, let `gh` auto-detect by omitting the `--repo` flag when running from within a git repository directory.\n\n### 2. Fetching the Next Issue\n\nThe \"next issue\" defaults to the oldest created open issue. Use `gh issue list` with sorting and limiting:\n\n```bash\n# Get the oldest created issue (next to work on)\ngh issue list --search \"sort:created-asc\" --limit 1 --json number,title,body,labels,assignees,milestone,state,url\n```\n\n### 3. Extracting Specific Fields\n\nUse `jq` to extract specific fields from the JSON output:\n\n```bash\n# Get just the issue number\ngh issue list --search \"sort:created-asc\" --limit 1 --json number | jq '.[0].number'\n\n# Get just the issue body\ngh issue list --search \"sort:created-asc\" --limit 1 --json body | jq -r '.[0].body'\n\n# Get just the issue title\ngh issue list --search \"sort:created-asc\" --limit 1 --json title | jq -r '.[0].title'\n\n# Get multiple fields in a formatted way\ngh issue list --search \"sort:created-asc\" --limit 1 --json number,title,body | jq -r '.[0] | \"Issue #\\(.number): \\(.title)\\n\\n\\(.body)\"'\n```\n\n**Note:** Use `-r` flag with `jq` to output raw strings without quotes.\n\n### 4. Available Fields\n\nThe `--json` flag accepts the following fields:\n\n- `number` - Issue number\n- `title` - Issue title\n- `body` - Issue body/description\n- `labels` - Array of label objects\n- `assignees` - Array of assignee objects\n- `milestone` - Milestone object\n- `state` - Issue state (OPEN, CLOSED)\n- `url` - Issue URL\n- `createdAt` - Creation timestamp\n- `updatedAt` - Last update timestamp\n- `closedAt` - Close timestamp (if closed)\n- `comments` - Number of comments\n- `author` - Author object\n\n### 5. Sorting Options\n\nUse the `--search` flag with sort qualifiers:\n\n```bash\n# Oldest created (default for \"next issue\")\n--search \"sort:created-asc\"\n\n# Newest created\n--search \"sort:created-desc\"\n\n# Most recently updated\n--search \"sort:updated-desc\"\n\n# Least recently updated\n--search \"sort:updated-asc\"\n\n# Most commented\n--search \"sort:comments-desc\"\n\n# Least commented\n--search \"sort:comments-asc\"\n```\n\n**Note:** GitHub doesn't have a native \"priority\" sort, but priority can be inferred from labels, milestones, or projects.\n\n### 6. Filtering Options\n\nCombine multiple filters in the `--search` query:\n\n```bash\n# Filter by label\n--search \"label:bug sort:created-asc\"\n\n# Filter by assignee\n--search \"assignee:username sort:created-asc\"\n\n# Filter by milestone\n--search \"milestone:\\\"v1.0\\\" sort:created-asc\"\n\n# Filter by state (default is open)\n--search \"is:open sort:created-asc\"\n--search \"is:closed sort:created-desc\"\n\n# Combine multiple filters\n--search \"label:bug assignee:@me is:open sort:created-asc\"\n\n# No assignee\n--search \"no:assignee sort:created-asc\"\n\n# No label\n--search \"no:label sort:created-asc\"\n```\n\n### 7. Common Patterns\n\n**Get the next issue to work on:**\n```bash\ngh issue list --search \"sort:created-asc\" --limit 1 --json number,title,body\n```\n\n**Get just the issue number for scripting:**\n```bash\nISSUE_NUM=$(gh issue list --search \"sort:created-asc\" --limit 1 --json number | jq '.[0].number')\n```\n\n**Get the full issue body text:**\n```bash\ngh issue list --search \"sort:created-asc\" --limit 1 --json body | jq -r '.[0].body'\n```\n\n**Get the most urgent unassigned bug:**\n```bash\ngh issue list --search \"label:bug no:assignee sort:created-asc\" --limit 1 --json number,title,body\n```\n\n**List all high-priority issues:**\n```bash\ngh issue list --search \"label:priority-high sort:created-asc\" --json number,title,labels\n```\n\n## Usage Workflow\n\nWhen a user requests GitHub issue information:\n\n1. **Verify dependencies**: Check that `gh` and `jq` are installed; if not, provide installation guidance\n2. **Determine the repository context**: Check if running in a git repository, or ask the user for the repo name\n3. **Understand the request**: Identify what fields they need (body, number, title, etc.)\n4. **Apply appropriate sorting**: Default to `sort:created-asc` for \"next issue\" requests, adjust based on user needs\n5. **Apply filters if specified**: Add label, assignee, or other filters to the search query\n6. **Construct the command**: Build the `gh issue list` command with appropriate flags\n7. **Extract fields**: Use `jq` to parse and extract only the requested fields\n8. **Present results**: Return the extracted data in the format the user needs\n\n## Examples\n\n**User request:** \"What's the next GitHub issue to work on?\"\n```bash\ngh issue list --search \"sort:created-asc\" --limit 1 --json number,title | jq -r '.[0] | \"#\\(.number): \\(.title)\"'\n```\n\n**User request:** \"Give me the body of the next GitHub issue\"\n```bash\ngh issue list --search \"sort:created-asc\" --limit 1 --json body | jq -r '.[0].body'\n```\n\n**User request:** \"Show me the newest bug with no assignee\"\n```bash\ngh issue list --search \"label:bug no:assignee sort:created-desc\" --limit 1 --json number,title,body | jq -r '.[0] | \"Issue #\\(.number): \\(.title)\\n\\n\\(.body)\"'\n```\n",
        "hashnode-api/SKILL.md": "---\nname: hashnode-api\ndescription: Hashnode GraphQL API documentation for creating, managing, and querying blogs, posts, publications, and user data on the Hashnode platform\n---\n\n# Hashnode API Skill\n\nComprehensive assistance with the Hashnode GraphQL API for blog management, content creation, and user interaction on the Hashnode platform.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Building integrations with Hashnode blogs or publications\n- Querying Hashnode posts, users, or publication data\n- Creating, publishing, or managing blog posts via API\n- Implementing authentication with Hashnode Personal Access Tokens\n- Working with GraphQL queries or mutations for Hashnode\n- Debugging Hashnode API responses or error codes\n- Setting up pagination (cursor-based or offset-based) for Hashnode data\n- Implementing newsletter subscriptions, comments, or user interactions\n- Migrating from the legacy Hashnode API to the new GQL endpoint\n\n## Key Concepts\n\n### API Endpoint\nAll Hashnode API requests go through a single GraphQL endpoint:\n- **Endpoint:** `https://gql.hashnode.com` (POST only)\n- **Playground:** Visit the same URL in a browser to explore the API\n- **Legacy API:** `https://api.hashnode.com` is discontinued - migrate to new endpoint\n\n### Authentication\n- Most queries work without authentication\n- Sensitive fields (drafts, email, etc.) require authentication\n- All mutations require authentication\n- **Authentication method:** Add `Authorization` header with your Personal Access Token (PAT)\n- **Get your PAT:** https://hashnode.com/settings/developer ‚Üí \"Generate New Token\"\n\n### Rate Limits\n- **Queries:** 20,000 requests per minute\n- **Mutations:** 500 requests per minute\n\n### Caching\n- Almost all query responses are cached on the Edge\n- Cache is automatically purged when you mutate data\n- Check cache status in playground (bottom right: HIT/MISS)\n- **Important:** Always request the `id` field to avoid stale data\n\n### Error Codes\nCommon GraphQL error codes:\n- `GRAPHQL_VALIDATION_FAILED` - Invalid query structure\n- `UNAUTHENTICATED` - Missing or invalid auth token\n- `FORBIDDEN` - Insufficient permissions\n- `BAD_USER_INPUT` - Invalid input data\n- `NOT_FOUND` - Resource doesn't exist\n\n## Quick Reference\n\n### 1. Fetch Publication Details\n\n```graphql\nquery Publication {\n  publication(host: \"blog.developerdao.com\") {\n    id\n    isTeam\n    title\n    about {\n      markdown\n    }\n  }\n}\n```\n\nGet basic information about a publication by its hostname.\n\n### 2. Fetch Recent Blog Posts\n\n```graphql\nquery Publication {\n  publication(host: \"blog.developerdao.com\") {\n    id\n    isTeam\n    title\n    posts(first: 10) {\n      edges {\n        node {\n          id\n          title\n          brief\n          url\n        }\n      }\n      pageInfo {\n        endCursor\n        hasNextPage\n      }\n    }\n  }\n}\n```\n\nRetrieve the latest 10 posts from a publication with cursor-based pagination support.\n\n### 3. Fetch a Single Article by Slug\n\n```graphql\nquery Publication {\n  publication(host: \"blog.developerdao.com\") {\n    id\n    post(slug: \"the-developers-guide-to-chainlink-vrf-foundry-edition\") {\n      id\n      title\n      content {\n        markdown\n        html\n      }\n    }\n  }\n}\n```\n\nGet full content of a specific article using its slug and publication hostname.\n\n### 4. Cursor-Based Pagination (Infinite Scroll)\n\n```graphql\nquery Publication {\n  publication(host: \"blog.developerdao.com\") {\n    id\n    posts(\n      first: 10\n      after: \"NjQxZTc4NGY0M2NiMzc2YjAyNzNkMzU4XzIwMjMtMDMtMjVUMDQ6Mjc6NTkuNjQxWg==\"\n    ) {\n      edges {\n        node {\n          id\n          title\n          brief\n          url\n        }\n      }\n      pageInfo {\n        endCursor\n        hasNextPage\n      }\n    }\n  }\n}\n```\n\nUse `endCursor` from previous response as `after` parameter to fetch next page.\n\n### 5. Offset-Based Pagination (Traditional Pages)\n\n```graphql\nquery Followers {\n  user(username: \"SandroVolpicella\") {\n    id\n    followers(pageSize: 10, page: 1) {\n      nodes {\n        id\n        username\n      }\n      pageInfo {\n        hasNextPage\n        hasPreviousPage\n        previousPage\n        nextPage\n      }\n    }\n  }\n}\n```\n\nNavigate between pages using explicit page numbers.\n\n### 6. Get Entity Count (Series Count Example)\n\n```graphql\nquery SeriesCount {\n  publication(host: \"engineering.hashnode.com\") {\n    id\n    seriesList(first: 0) {\n      totalDocuments\n    }\n  }\n}\n```\n\nResult:\n```json\n{\n  \"data\": {\n    \"publication\": {\n      \"seriesList\": {\n        \"totalDocuments\": 3\n      }\n    }\n  }\n}\n```\n\nUse `totalDocuments` field to get counts without fetching all data.\n\n### 7. Fetch Posts from a Series\n\n```graphql\nquery Publication {\n  publication(host: \"lo-victoria.com\") {\n    id\n    series(slug: \"graphql\") {\n      id\n      name\n      posts(first: 10) {\n        edges {\n          node {\n            id\n            title\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nGet all posts belonging to a specific series.\n\n### 8. Fetch Static Pages\n\n```graphql\nquery Publication {\n  publication(host: \"lo-victoria.com\") {\n    id\n    staticPages(first: 10) {\n      edges {\n        node {\n          id\n          title\n          slug\n        }\n      }\n    }\n  }\n}\n```\n\nRetrieve custom static pages like \"About\", \"Contact\", etc.\n\n### 9. Fetch Single Static Page\n\n```graphql\nquery Publication {\n  publication(host: \"lo-victoria.com\") {\n    id\n    staticPage(slug: \"about\") {\n      id\n      title\n      content {\n        markdown\n      }\n    }\n  }\n}\n```\n\nGet content of a specific static page by slug.\n\n### 10. Authentication Example - Get Drafts (Requires Auth)\n\n```graphql\nquery Publication($first: Int!, $host: String) {\n  publication(host: $host) {\n    id\n    drafts(first: $first) {\n      edges {\n        node {\n          id\n          title\n        }\n      }\n    }\n  }\n}\n```\n\n**Headers:**\n```json\n{\n  \"Authorization\": \"your-personal-access-token-here\"\n}\n```\n\nVariables:\n```json\n{\n  \"first\": 10,\n  \"host\": \"your-blog-host.hashnode.dev\"\n}\n```\n\nDrafts can only be queried by the publication owner with valid authentication.\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete Hashnode GraphQL API documentation including:\n  - GQL Playground overview\n  - Caching behavior and best practices\n  - Rate limits and authentication\n  - Status codes and error handling\n  - Pagination methods (cursor-based and offset-based)\n  - Migration guide from legacy API\n  - Query and mutation examples\n  - Full list of available queries and mutations\n\nUse the reference files for detailed information about specific API features, error handling patterns, and advanced query techniques.\n\n## Working with This Skill\n\n### For Beginners\nStart by understanding the core concepts above, then explore:\n1. **API Endpoint:** Test queries in the playground at https://gql.hashnode.com\n2. **Authentication:** Generate your PAT at https://hashnode.com/settings/developer\n3. **Basic Queries:** Try fetching publication details and blog posts first\n4. **Pagination:** Start with cursor-based pagination for simple infinite scroll\n\n### For Intermediate Users\nFocus on:\n1. **Authentication flows:** Implement PAT-based auth in your application\n2. **Error handling:** Handle GraphQL error codes properly\n3. **Pagination strategies:** Choose between cursor-based and offset-based based on your UI needs\n4. **Caching considerations:** Always request `id` fields to avoid stale data\n5. **Content extraction:** Work with both markdown and HTML content formats\n\n### For Advanced Users\nExplore:\n1. **Mutations:** Publishing posts, managing drafts, updating content\n2. **Complex queries:** Nested queries with multiple levels (publication ‚Üí series ‚Üí posts)\n3. **Batch operations:** Optimize API calls with GraphQL field selection\n4. **Webhook integration:** Handle Hashnode webhook events\n5. **Rate limit optimization:** Implement efficient request batching\n\n### Navigation Tips\n- **Start broad ‚Üí go deep:** Begin with publication queries, then drill into specific posts/series\n- **Check authentication:** If you get `UNAUTHENTICATED` errors, verify your PAT is in the Authorization header\n- **Test in playground:** Use https://gql.hashnode.com to test queries before implementing\n- **Monitor cache:** Watch cache HIT/MISS status to optimize your queries\n- **Read error messages:** GraphQL errors include helpful details in the `extensions.code` field\n\n## Common Use Cases\n\n### Building a Blog Frontend\n1. Fetch publication metadata\n2. Get post list with pagination\n3. Display individual posts by slug\n4. Implement series/category navigation\n5. Show static pages (about, contact)\n\n### Content Management Dashboard\n1. Authenticate with PAT\n2. List and manage drafts\n3. Publish/update posts\n4. Schedule content\n5. Monitor analytics\n\n### Newsletter Integration\n1. Subscribe/unsubscribe users\n2. Fetch subscriber counts\n3. Manage email preferences\n4. Track engagement metrics\n\n### Migration from Legacy API\n1. Update endpoint from `api.hashnode.com` to `gql.hashnode.com`\n2. Convert REST calls to GraphQL queries\n3. Update authentication mechanism (check docs)\n4. Adjust pagination from old format to cursor/offset-based\n5. Update error handling for new error codes\n\n## Resources\n\n### Official Documentation\n- **API Docs:** https://apidocs.hashnode.com\n- **Playground:** https://gql.hashnode.com\n- **Discord:** Join for updates and community support\n- **GraphQL Guide:** freeCodeCamp's beginner-friendly GraphQL guide\n\n### references/\nThe `api.md` reference file contains:\n- Complete API specification\n- All available queries and mutations\n- Detailed parameter descriptions\n- Authentication requirements\n- Code examples with proper syntax\n- Links to original documentation\n- Comprehensive error code reference\n\n## Important Notes\n\n- **Always request the `id` field** on objects to avoid stale cached data\n- **Rate limits are generous** but respect them for production apps\n- **Cache behavior:** Most responses are cached; mutations automatically purge related cache\n- **Breaking changes are rare** and announced well in advance on Discord\n- **Legacy API is shut down** - use `gql.hashnode.com` only\n\n## Troubleshooting\n\n### Getting UNAUTHENTICATED errors?\n- Verify your Personal Access Token is valid\n- Check the `Authorization` header is set correctly\n- Ensure you're requesting fields that require auth (drafts, email, etc.)\n\n### Not seeing latest data?\n- Always request the `id` field to avoid stale cached data\n- Check if response is HIT/MISS in playground\n\n### Query validation failed?\n- Verify your GraphQL syntax in the playground first\n- Check required parameters are provided\n- Ensure field names match the schema\n\n### Rate limit reached?\n- Queries: 20k/min is very generous - optimize your queries\n- Mutations: 500/min limit - batch operations where possible\n- Use caching on your end to reduce API calls\n\n## Updating\n\nThis skill was automatically generated from official Hashnode documentation. To refresh with updated documentation, regenerate the skill using the latest docs from https://apidocs.hashnode.com.\n",
        "haveibeenpwned/SKILL.md": "---\nname: haveibeenpwned\ndescription: HaveIBeenPwned API Documentation - Check if email accounts or passwords have been compromised in data breaches\n---\n\n# Have I Been Pwned API Skill\n\nExpert assistance for integrating the Have I Been Pwned (HIBP) API v3 to check for compromised accounts, passwords, and data breaches. This skill provides comprehensive guidance for building security tools, breach notification systems, and password validation features.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- **Checking if emails/accounts appear in data breaches** - \"check if this email was pwned\"\n- **Validating password security** - \"check if password is in breach database\"\n- **Building breach notification systems** - \"notify users about compromised accounts\"\n- **Implementing password validation** - \"prevent users from choosing pwned passwords\"\n- **Querying stealer logs** - \"check if credentials were stolen by malware\"\n- **Integrating HIBP into authentication flows** - \"add breach checking to login\"\n- **Monitoring domains for compromised emails** - \"track breaches affecting our domain\"\n- **Working with the HIBP API** - any questions about authentication, rate limits, or endpoints\n\n## Quick Reference\n\n### 1. Basic Account Breach Check\n\n```python\nimport requests\n\ndef check_account_breaches(email, api_key):\n    \"\"\"Check if an account appears in any breaches\"\"\"\n    headers = {\n        'hibp-api-key': api_key,\n        'user-agent': 'MyApp/1.0'\n    }\n\n    url = f'https://haveibeenpwned.com/api/v3/breachedaccount/{email}'\n    response = requests.get(url, headers=headers)\n\n    if response.status_code == 200:\n        return response.json()  # List of breach objects\n    elif response.status_code == 404:\n        return []  # Account not found in breaches\n    else:\n        response.raise_for_status()\n\n# Usage\nbreaches = check_account_breaches('user@example.com', 'your-api-key')\nprint(f\"Found in {len(breaches)} breaches\")\n```\n\n### 2. Password Breach Check (k-Anonymity)\n\n```python\nimport hashlib\nimport requests\n\ndef check_password_pwned(password):\n    \"\"\"Check if password appears in breaches using k-anonymity\"\"\"\n    # Hash password with SHA-1\n    sha1_hash = hashlib.sha1(password.encode('utf-8')).hexdigest().upper()\n    prefix = sha1_hash[:5]\n    suffix = sha1_hash[5:]\n\n    # Query API with first 5 characters only\n    url = f'https://api.pwnedpasswords.com/range/{prefix}'\n    response = requests.get(url)\n\n    # Parse response for matching suffix\n    hashes = (line.split(':') for line in response.text.splitlines())\n    for hash_suffix, count in hashes:\n        if hash_suffix == suffix:\n            return int(count)  # Times password appears in breaches\n    return 0  # Password not found\n\n# Usage\ncount = check_password_pwned('password123')\nif count > 0:\n    print(f\"‚ö†Ô∏è Password found {count} times in breaches!\")\n```\n\n### 3. Get All Breaches in System\n\n```python\nimport requests\n\ndef get_all_breaches(domain=None):\n    \"\"\"Retrieve all breaches, optionally filtered by domain\"\"\"\n    url = 'https://haveibeenpwned.com/api/v3/breaches'\n    params = {'domain': domain} if domain else {}\n\n    headers = {'user-agent': 'MyApp/1.0'}\n    response = requests.get(url, headers=headers, params=params)\n\n    return response.json()\n\n# Usage - no authentication required\nbreaches = get_all_breaches()\nprint(f\"Total breaches: {len(breaches)}\")\n\n# Filter by domain\nadobe_breaches = get_all_breaches(domain='adobe.com')\n```\n\n### 4. Monitor for New Breaches\n\n```python\nimport requests\nimport time\n\ndef monitor_latest_breach(check_interval=3600):\n    \"\"\"Poll for new breaches every hour\"\"\"\n    last_breach_name = None\n\n    while True:\n        url = 'https://haveibeenpwned.com/api/v3/latestbreach'\n        headers = {'user-agent': 'MyApp/1.0'}\n        response = requests.get(url, headers=headers)\n\n        if response.status_code == 200:\n            breach = response.json()\n            if breach['Name'] != last_breach_name:\n                print(f\"üÜï New breach: {breach['Title']}\")\n                print(f\"   Accounts affected: {breach['PwnCount']:,}\")\n                last_breach_name = breach['Name']\n\n        time.sleep(check_interval)\n```\n\n### 5. Domain-Wide Breach Search\n\n```python\nimport requests\n\ndef search_domain_breaches(domain, api_key):\n    \"\"\"Search for all breached emails in a verified domain\"\"\"\n    headers = {\n        'hibp-api-key': api_key,\n        'user-agent': 'MyApp/1.0'\n    }\n\n    url = f'https://haveibeenpwned.com/api/v3/breacheddomain/{domain}'\n    response = requests.get(url, headers=headers)\n\n    if response.status_code == 200:\n        results = response.json()\n        # Returns: {\"alias1\": [\"Adobe\"], \"alias2\": [\"Adobe\", \"Gawker\"]}\n        total_affected = len(results)\n        print(f\"Found {total_affected} compromised accounts\")\n        return results\n    else:\n        response.raise_for_status()\n```\n\n### 6. Check Pastes for Account\n\n```python\nimport requests\n\ndef check_pastes(email, api_key):\n    \"\"\"Check if email appears in any pastes\"\"\"\n    headers = {\n        'hibp-api-key': api_key,\n        'user-agent': 'MyApp/1.0'\n    }\n\n    url = f'https://haveibeenpwned.com/api/v3/pasteaccount/{email}'\n    response = requests.get(url, headers=headers)\n\n    if response.status_code == 200:\n        pastes = response.json()\n        for paste in pastes:\n            print(f\"{paste['Source']}: {paste['Title']}\")\n            print(f\"  Date: {paste['Date']}\")\n            print(f\"  Emails found: {paste['EmailCount']}\")\n        return pastes\n    elif response.status_code == 404:\n        return []  # No pastes found\n```\n\n### 7. Enhanced Password Check with Padding\n\n```python\nimport hashlib\nimport requests\n\ndef check_password_secure(password):\n    \"\"\"Check password with padding to prevent inference attacks\"\"\"\n    sha1_hash = hashlib.sha1(password.encode('utf-8')).hexdigest().upper()\n    prefix = sha1_hash[:5]\n    suffix = sha1_hash[5:]\n\n    headers = {'Add-Padding': 'true'}\n    url = f'https://api.pwnedpasswords.com/range/{prefix}'\n    response = requests.get(url, headers=headers)\n\n    # Parse response, ignore padded entries (count=0)\n    for line in response.text.splitlines():\n        hash_suffix, count = line.split(':')\n        if hash_suffix == suffix and int(count) > 0:\n            return int(count)\n    return 0\n```\n\n### 8. Handle Rate Limiting\n\n```python\nimport requests\nimport time\n\ndef api_call_with_retry(url, headers, max_retries=3):\n    \"\"\"Make API call with automatic retry on rate limit\"\"\"\n    for attempt in range(max_retries):\n        response = requests.get(url, headers=headers)\n\n        if response.status_code == 429:\n            # Rate limited - wait and retry\n            retry_after = int(response.headers.get('retry-after', 2))\n            print(f\"Rate limited, waiting {retry_after}s...\")\n            time.sleep(retry_after)\n            continue\n\n        return response\n\n    raise Exception(\"Max retries exceeded\")\n```\n\n### 9. Check Subscription Status\n\n```python\nimport requests\n\ndef get_subscription_info(api_key):\n    \"\"\"Retrieve API subscription details and limits\"\"\"\n    headers = {\n        'hibp-api-key': api_key,\n        'user-agent': 'MyApp/1.0'\n    }\n\n    url = 'https://haveibeenpwned.com/api/v3/subscription/status'\n    response = requests.get(url, headers=headers)\n\n    if response.status_code == 200:\n        info = response.json()\n        print(f\"Plan: {info['SubscriptionName']}\")\n        print(f\"Rate limit: {info['Rpm']} requests/minute\")\n        print(f\"Valid until: {info['SubscribedUntil']}\")\n        return info\n```\n\n### 10. Stealer Logs Search\n\n```python\nimport requests\n\ndef check_stealer_logs(email, api_key):\n    \"\"\"Check if credentials appear in info stealer malware logs\"\"\"\n    headers = {\n        'hibp-api-key': api_key,\n        'user-agent': 'MyApp/1.0'\n    }\n\n    url = f'https://haveibeenpwned.com/api/v3/stealerlogsbyemail/{email}'\n    response = requests.get(url, headers=headers)\n\n    if response.status_code == 200:\n        domains = response.json()  # List of website domains\n        print(f\"Credentials found for {len(domains)} websites\")\n        return domains\n    elif response.status_code == 404:\n        return []  # Not found in stealer logs\n\n# Requires Pwned 5+ subscription\n```\n\n## Key Concepts\n\n### Authentication\n- **API Key Format**: 32-character hexadecimal string\n- **Header**: `hibp-api-key: {your-key}`\n- **User-Agent Required**: Must set valid user-agent header (returns 403 if missing)\n- **Test Key**: `00000000000000000000000000000000` for integration testing\n\n### k-Anonymity Model\nThe Pwned Passwords API uses **k-anonymity** to protect user privacy:\n1. Client hashes password locally with SHA-1\n2. Sends only **first 5 characters** of hash to API\n3. API returns ~800 matching hash suffixes\n4. Client checks locally if full hash matches\n\nThis ensures the actual password **never leaves your system**.\n\n### Rate Limiting\n- **Varies by subscription tier**: Pwned 5 = 1,000 requests/minute\n- **HTTP 429 response** when exceeded with `retry-after` header\n- **Pwned Passwords API**: No rate limit\n- **Best practice**: Implement exponential backoff on 429 responses\n\n### Breach Model Attributes\nKey fields in breach objects:\n- **Name**: Unique identifier (e.g., \"Adobe\")\n- **Title**: Human-readable name\n- **BreachDate**: When breach occurred (ISO 8601)\n- **PwnCount**: Total compromised accounts\n- **DataClasses**: Types of data exposed (emails, passwords, etc.)\n- **IsVerified**: Breach authenticity confirmed\n- **IsSensitive**: Excluded from public searches\n\n### Response Codes\n| Code | Meaning |\n|------|---------|\n| 200 | Success - data found |\n| 404 | Not found (account not in breaches) |\n| 401 | Unauthorized (invalid API key) |\n| 403 | Forbidden (missing user-agent) |\n| 429 | Rate limit exceeded |\n\n## Reference Files\n\nThis skill includes comprehensive API documentation in `references/`:\n\n- **other.md** - Complete HIBP API v3 reference with all endpoints, authentication, and usage examples\n\nThe reference file contains:\n- **All API endpoints** - Breaches, pastes, passwords, stealer logs\n- **Request/response formats** - Headers, parameters, JSON structures\n- **Authentication details** - API key setup and usage\n- **Rate limiting information** - Subscription tiers and retry strategies\n- **Test accounts** - Pre-configured test data for integration\n- **Code examples** - Real-world implementation patterns\n\nUse `view` to read the reference file when you need detailed information about specific endpoints or advanced features.\n\n## Working with This Skill\n\n### For Beginners\nStart by understanding the core concepts:\n1. **Password checking** - Use Pwned Passwords API (no authentication required)\n2. **Account breaches** - Requires API key from haveibeenpwned.com\n3. **k-Anonymity** - Learn how password hashing protects privacy\n\nBegin with Quick Reference examples #1 (breach check) and #2 (password check).\n\n### For Integration Projects\nFocus on:\n1. **Authentication setup** - Get API key and configure headers\n2. **Rate limiting** - Implement retry logic (example #8)\n3. **Error handling** - Handle 404, 401, 429 responses properly\n4. **User experience** - Provide clear messaging about breach exposure\n\nReview Quick Reference examples #5 (domain search) and #9 (subscription info).\n\n### For Production Systems\nConsider:\n1. **Caching** - Store breach results to reduce API calls\n2. **Background processing** - Check breaches asynchronously\n3. **Monitoring** - Track new breaches with latest breach endpoint (example #4)\n4. **Privacy** - Never log passwords, use k-anonymity model\n5. **Compliance** - Follow attribution requirements (CC BY 4.0)\n\n### For Security Tools\nAdvanced patterns:\n1. **Stealer logs** - Check malware-stolen credentials (example #10)\n2. **Domain monitoring** - Track all compromised accounts in your organization\n3. **Paste monitoring** - Alert on email exposure in public pastes (example #6)\n4. **Padding** - Use response padding to prevent inference attacks (example #7)\n\n## Common Patterns\n\n### Pattern 1: Sign-up Password Validation\n```python\n# Prevent users from choosing compromised passwords\ndef validate_signup_password(password):\n    count = check_password_pwned(password)\n    if count > 0:\n        return False, f\"This password appears in {count} data breaches\"\n    return True, \"Password is secure\"\n```\n\n### Pattern 2: Breach Notification System\n```python\n# Notify users when their account appears in new breach\ndef notify_affected_users():\n    latest = get_latest_breach()\n    affected_users = query_users_in_breach(latest['Name'])\n    for user in affected_users:\n        send_notification(user, latest)\n```\n\n### Pattern 3: Compliance Check\n```python\n# Verify all domain accounts for compliance reporting\ndef domain_security_audit(domain, api_key):\n    breached = search_domain_breaches(domain, api_key)\n    report = {\n        'total_accounts': len(breached),\n        'affected_accounts': breached,\n        'timestamp': datetime.now()\n    }\n    return report\n```\n\n## API Endpoints Summary\n\n### Authenticated Endpoints (Require API Key)\n- `GET /breachedaccount/{account}` - Check account breaches\n- `GET /pasteaccount/{account}` - Check pastes\n- `GET /breacheddomain/{domain}` - Domain-wide search\n- `GET /subscribeddomains` - List verified domains\n- `GET /subscription/status` - Check subscription\n- `GET /stealerlogsbyemail/{email}` - Stealer logs by email\n- `GET /stealerlogsbywebsitedomain/{domain}` - Stealer logs by site\n- `GET /stealerlogsbyemaildomain/{domain}` - Stealer logs by email domain\n\n### Public Endpoints (No Authentication)\n- `GET /breaches` - All breaches in system\n- `GET /breach/{name}` - Single breach details\n- `GET /latestbreach` - Most recent breach\n- `GET /dataclasses` - List of data types\n- `GET https://api.pwnedpasswords.com/range/{prefix}` - Password check\n\n## Testing\n\n### Test Accounts\nUse these on domain `hibp-integration-tests.com`:\n- `account-exists@` - Has breaches and pastes\n- `multiple-breaches@` - Three different breaches\n- `spam-list-only@` - Only spam-flagged breach\n- `stealer-log@` - In stealer logs\n- `opt-out@` - No results (opted out)\n\n### Test API Key\nUse `00000000000000000000000000000000` for integration testing.\n\n## Best Practices\n\n1. **Always set User-Agent** - Required header, returns 403 without it\n2. **Use HTTPS only** - API requires TLS 1.2+\n3. **Implement retry logic** - Handle 429 rate limits gracefully\n4. **Cache breach data** - Reduce API calls for frequently checked accounts\n5. **Never log passwords** - Use k-anonymity model, hash locally\n6. **Provide attribution** - Link to haveibeenpwned.com (CC BY 4.0 license)\n7. **Handle 404 gracefully** - \"Not found\" is good news for users\n8. **Use padding for passwords** - Add `Add-Padding: true` header\n\n## Resources\n\n### Official Links\n- API Documentation: https://haveibeenpwned.com/API/v3\n- Get API Key: https://haveibeenpwned.com/API/Key\n- Dashboard: https://haveibeenpwned.com/DomainSearch\n\n### Community Tools\n- **PwnedPasswordsDownloader** (GitHub) - Download full password database\n- Integration libraries available for Python, JavaScript, Go, C#, and more\n\n## Acceptable Use\n\n**Permitted:**\n- Security tools and breach notifications\n- Password validation in authentication systems\n- Compliance and security audits\n- Educational and research purposes\n\n**Prohibited:**\n- Targeting or harming breach victims\n- Denial-of-service attacks\n- Circumventing security measures\n- Misrepresenting data source\n- Automating undocumented APIs\n\nViolations may result in API key revocation or IP blocking.\n\n## Notes\n\n- Breach data licensed under **Creative Commons Attribution 4.0**\n- Pwned Passwords has no licensing requirements\n- CORS only supported for unauthenticated endpoints\n- Never expose API keys in client-side code\n- Service tracks **917+ breaches** as of API documentation date\n",
        "laravel-cashier-paddle/SKILL.md": "---\nname: laravel-cashier-paddle\ndescription: Laravel Cashier (Paddle) - Subscription billing and payment processing\n---\n\n# Laravel Cashier (Paddle) Skill\n\nComprehensive assistance with Laravel Cashier Paddle - an expressive, fluent interface to Paddle's subscription billing services for Laravel applications.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Implementing subscription billing with Paddle in Laravel applications\n- Setting up checkout flows for products or subscriptions\n- Managing subscription lifecycle (create, swap, pause, cancel)\n- Handling webhook events from Paddle\n- Working with customer management and payment methods\n- Implementing trial periods or multi-product subscriptions\n- Processing transactions, refunds, or credits\n- Generating invoices or receipts\n- Previewing prices with currency/tax calculations\n- Debugging Paddle integration issues in Laravel\n\n## Quick Reference\n\n### 1. Basic Setup - Billable Model\n\n```php\nuse Laravel\\Paddle\\Billable;\n\nclass User extends Authenticatable\n{\n    use Billable;\n\n    public function paddleName(): string|null\n    {\n        return $this->name;\n    }\n\n    public function paddleEmail(): string|null\n    {\n        return $this->email;\n    }\n}\n```\n\n### 2. Simple Product Checkout\n\n```php\n// Create checkout session\n$checkout = $user->checkout('pri_deluxe_album')\n    ->returnTo(route('dashboard'));\n\n// Display checkout button\n<x-paddle-button :checkout=\"$checkout\" class=\"px-8 py-4\">\n    Subscribe\n</x-paddle-button>\n```\n\n### 3. Subscription Creation\n\n```php\n// Single subscription\n$checkout = $user->subscribe('price_basic_monthly', 'default')\n    ->returnTo(route('home'));\n\n// Multi-product subscription\n$checkout = $user->subscribe([\n    'price_monthly',\n    'price_chat' => 5  // with quantity\n]);\n```\n\n### 4. Price Preview with Tax\n\n```php\nuse Laravel\\Paddle\\Cashier;\n\n// Preview prices for country\n$prices = Cashier::previewPrices(['pri_123', 'pri_456'], [\n    'address' => ['country_code' => 'BE', 'postal_code' => '1234']\n]);\n\n// Display in Blade\n@foreach ($prices as $price)\n    <li>{{ $price->product['name'] }} - {{ $price->total() }}</li>\n    <li>Subtotal: {{ $price->subtotal() }} + Tax: {{ $price->tax() }}</li>\n@endforeach\n```\n\n### 5. Subscription Status Checks\n\n```php\n// Check various subscription states\nif ($user->subscribed()) { }\nif ($user->subscribed('default')) { }\nif ($user->subscribedToProduct('pro_basic')) { }\nif ($user->subscription()->onTrial()) { }\nif ($user->subscription()->onGracePeriod()) { }\nif ($user->subscription()->canceled()) { }\nif ($user->subscription()->pastDue()) { }\n```\n\n### 6. Plan Swapping\n\n```php\n// Immediate swap with proration\n$user->subscription()->swap('pri_456');\n\n// Swap and invoice immediately\n$user->subscription()->swapAndInvoice('pri_456');\n\n// Swap without proration\n$user->subscription()->noProrate()->swap('pri_456');\n```\n\n### 7. Subscription Quantity Management\n\n```php\n// Increment/decrement quantity\n$user->subscription()->incrementQuantity();\n$user->subscription()->incrementQuantity(5);\n$user->subscription()->decrementQuantity();\n\n// Set specific quantity\n$user->subscription()->updateQuantity(10);\n\n// Multi-product quantity\n$user->subscription()->incrementQuantity(1, 'price_chat');\n```\n\n### 8. Pause and Resume Subscriptions\n\n```php\n// Pause at period end\n$user->subscription()->pause();\n\n// Pause immediately\n$user->subscription()->pauseNow();\n\n// Pause until specific date\n$user->subscription()->pauseUntil(now()->addMonth());\n\n// Resume paused subscription\n$user->subscription()->resume();\n```\n\n### 9. Webhook Event Handling\n\n```php\nuse Laravel\\Paddle\\Events\\WebhookReceived;\nuse Laravel\\Paddle\\Events\\TransactionCompleted;\n\n// Listen for specific events\nEvent::listen(TransactionCompleted::class, function ($event) {\n    $transaction = $event->transaction;\n    // Process completed transaction\n});\n\n// Handle custom webhook events\npublic function handle(WebhookReceived $event): void\n{\n    if ($event->payload['event_type'] === 'transaction.billed') {\n        // Handle custom event\n    }\n}\n```\n\n### 10. Transaction Management\n\n```php\n// Retrieve transactions\n$transactions = $user->transactions;\n\n// Refund with specific items\n$response = $transaction->refund('Accidental charge', [\n    'pri_123',\n    'pri_456' => 200  // partial refund amount\n]);\n\n// Full refund\n$response = $transaction->refund('Customer request');\n\n// Download invoice PDF\nreturn $transaction->redirectToInvoicePdf();\n```\n\n## Key Concepts\n\n### Checkout Sessions\nCashier Paddle uses checkout sessions to initiate payments. Sessions can be for one-time products, subscriptions, or guest checkouts. They support both overlay and inline display modes.\n\n### Billable Models\nAny Eloquent model can become \"billable\" by using the `Billable` trait. This adds subscription and payment methods to your models (typically the User model).\n\n### Subscriptions\nSubscriptions represent recurring billing arrangements. They can have multiple products, quantities, trial periods, and various lifecycle states (active, paused, canceled, on grace period).\n\n### Transactions\nTransactions represent completed payments. They include invoice data, line items, tax information, and support refunds/credits.\n\n### Webhooks\nPaddle sends webhook events for important subscription and payment events. Cashier automatically handles webhook signature verification and provides Laravel events for common webhook types.\n\n### Proration\nWhen swapping plans or changing quantities, Cashier can automatically calculate prorated amounts or you can disable proration using `noProrate()`.\n\n### Grace Periods\nWhen subscriptions are paused or canceled, they remain active until the end of the current billing period. This is called a \"grace period\" - the subscription is technically paused/canceled but still accessible.\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Complete Laravel Cashier Paddle documentation including:\n  - Installation and configuration steps\n  - Checkout session creation (overlay, inline, guest)\n  - Customer management and defaults\n  - Subscription operations (create, swap, pause, cancel)\n  - Multi-product and multi-subscription support\n  - Trial period management\n  - Quantity management and proration\n  - Webhook configuration and event handling\n  - Transaction history, refunds, and credits\n  - Invoice generation and downloads\n  - Middleware examples for subscription protection\n\nUse `view` to read the reference file when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n1. Start by understanding the **Billable** trait and how to add it to your User model\n2. Learn **basic checkout** creation for simple product purchases\n3. Study **subscription creation** patterns for recurring billing\n4. Understand **environment configuration** (sandbox vs production)\n\n### For Intermediate Users\n1. Implement **subscription lifecycle management** (pause, resume, cancel)\n2. Work with **plan swapping** and proration logic\n3. Handle **webhook events** for subscription updates\n4. Implement **trial periods** with or without upfront payment\n5. Manage **multi-product subscriptions** with quantities\n\n### For Advanced Users\n1. Build **custom subscription middleware** for route protection\n2. Implement **multi-subscription** support for different product lines\n3. Create **transaction refund** and **credit** workflows\n4. Customize **invoice generation** and delivery\n5. Build **subscription analytics** using query scopes\n6. Handle **payment method updates** with redirect flows\n\n### Navigation Tips\n- Use the Quick Reference above for common code patterns\n- Check `references/other.md` for complete API documentation\n- Search for specific methods like `swap()`, `pause()`, or `refund()`\n- Webhook events are documented with their payload structure\n- All code examples include proper error handling context\n\n## Common Patterns\n\n### Subscription Protection Middleware\n```php\nnamespace App\\Http\\Middleware;\n\nclass Subscribed\n{\n    public function handle(Request $request, Closure $next): Response\n    {\n        if (!$request->user()?->subscribed()) {\n            return redirect('/subscribe');\n        }\n        return $next($request);\n    }\n}\n\nRoute::get('/dashboard', fn () => '...')->middleware([Subscribed::class]);\n```\n\n### Trial Management\n```php\n// With payment method up front\n$checkout = $user->subscribe('pri_monthly')\n    ->returnTo(route('home'));\n\n// Without payment method (generic trial)\n$user->createAsCustomer(['trial_ends_at' => now()->addDays(10)]);\n\n// Extend existing trial\n$user->subscription()->extendTrial(now()->addDays(5));\n\n// Activate trial early\n$user->subscription()->activate();\n```\n\n### Guest Checkout\n```php\nuse Laravel\\Paddle\\Checkout;\n\n$checkout = Checkout::guest(['pri_34567'])\n    ->returnTo(route('home'));\n```\n\n## Environment Configuration\n\n```env\nPADDLE_CLIENT_SIDE_TOKEN=your-paddle-client-side-token\nPADDLE_API_KEY=your-paddle-api-key\nPADDLE_RETAIN_KEY=your-paddle-retain-key\nPADDLE_WEBHOOK_SECRET=\"your-paddle-webhook-secret\"\nPADDLE_SANDBOX=true\nCASHIER_CURRENCY_LOCALE=nl_BE\n```\n\n## Available Webhook Events\n\n- `CustomerUpdated` - Customer information changed\n- `TransactionCompleted` - Payment completed successfully\n- `TransactionUpdated` - Transaction details changed\n- `SubscriptionCreated` - New subscription created\n- `SubscriptionUpdated` - Subscription modified\n- `SubscriptionPaused` - Subscription paused\n- `SubscriptionCanceled` - Subscription canceled\n\n## Subscription Query Scopes\n\n```php\n// Filter subscriptions by status\nSubscription::query()->valid();\nSubscription::query()->onTrial();\nSubscription::query()->active();\nSubscription::query()->canceled();\nSubscription::query()->paused();\nSubscription::query()->onGracePeriod();\n```\n\n## Resources\n\n### Official Documentation\n- Laravel Cashier Paddle Docs: https://laravel.com/docs/cashier-paddle\n- Paddle Developer Portal: https://developer.paddle.com/\n\n### references/\nOrganized documentation extracted from official sources containing:\n- Detailed API method explanations\n- Complete code examples with context\n- Webhook payload structures\n- Configuration options\n- Best practices and patterns\n\n### scripts/\nAdd helper scripts here for:\n- Webhook testing utilities\n- Subscription migration scripts\n- Invoice batch generation\n\n### assets/\nAdd templates or examples:\n- Checkout page templates\n- Email notification templates\n- Subscription management UI components\n\n## Notes\n\n- This skill was automatically generated from official Laravel Cashier Paddle documentation\n- All code examples are tested patterns from the official docs\n- Webhook handling includes automatic CSRF protection exemption\n- Sandbox mode is enabled by default for development\n- Price previews include automatic tax calculation based on customer location\n- Subscriptions support both immediate and grace period cancellations\n- Multi-product subscriptions allow different quantities per product\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Re-run the scraper with the same configuration\n2. The skill will be rebuilt with the latest information from Laravel docs\n3. New features and API changes will be automatically incorporated\n",
        "laravel-cashier-stripe/SKILL.md": "---\nname: laravel-cashier-stripe\ndescription: Laravel Cashier (Stripe) - Subscription billing and payment processing\n---\n\n# Laravel Cashier (Stripe) Skill\n\nComprehensive assistance with Laravel Cashier (Stripe) development for subscription billing, payment processing, and Stripe integration in Laravel applications.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Implementing subscription billing in Laravel applications\n- Setting up recurring payments with Stripe\n- Managing customer subscriptions, trials, and plan changes\n- Processing one-time charges or invoices\n- Handling Stripe webhooks and events\n- Implementing checkout flows with Stripe Checkout\n- Managing customer payment methods and cards\n- Working with Stripe invoices and billing portals\n- Setting up trial periods and proration logic\n- Debugging Stripe integration issues in Laravel\n\n## Quick Reference\n\n### Installation and Setup\n\n```bash\n# Install Cashier\ncomposer require laravel/cashier\n\n# Publish migrations and migrate\nphp artisan vendor:publish --tag=\"cashier-migrations\"\nphp artisan migrate\n\n# Publish config (optional)\nphp artisan vendor:publish --tag=\"cashier-config\"\n```\n\n### Configure Billable Model\n\n```php\nuse Laravel\\Cashier\\Billable;\n\nclass User extends Authenticatable\n{\n    use Billable;\n}\n```\n\n### Creating a Subscription\n\n```php\n// Basic subscription with trial and checkout\n$user->newSubscription('default', 'price_monthly')\n    ->trialDays(5)\n    ->allowPromotionCodes()\n    ->checkout([\n        'success_url' => route('checkout.success'),\n        'cancel_url' => route('checkout.cancel'),\n    ]);\n```\n\n### Checking Subscription Status\n\n```php\n// Check if user has active subscription\nif ($user->subscribed('default')) {\n    // User is subscribed to \"default\" plan\n}\n\n// Check specific product subscription\nif ($user->subscribedToProduct('prod_premium', 'default')) {\n    // User is subscribed to premium product\n}\n\n// Check trial status\nif ($user->subscription('default')->onTrial()) {\n    // User is still in trial period\n}\n```\n\n### Managing Payment Methods\n\n```php\n// Store payment method (in view with Stripe.js)\n$intent = $user->createSetupIntent();\n\n// Retrieve payment methods\n$paymentMethods = $user->paymentMethods();\n$defaultMethod = $user->defaultPaymentMethod();\n\n// Add and update payment methods\n$user->addPaymentMethod($paymentMethodId);\n$user->updateDefaultPaymentMethod($paymentMethodId);\n```\n\n### Swapping Subscription Plans\n\n```php\n// Swap to different price/plan\n$user->subscription('default')->swap('price_yearly');\n\n// Swap and skip trial\n$user->subscription('default')->skipTrial()->swap('price_yearly');\n```\n\n### Single Charges and Invoices\n\n```php\n// One-time charge\n$user->charge(1000, $paymentMethodId, [\n    'description' => 'One-time charge',\n]);\n\n// Create invoice for service\n$user->invoiceFor('Premium Support', 5000, [\n    'description' => '3 months of premium support',\n]);\n\n// Refund a charge\n$user->refund($chargeId);\n```\n\n### Canceling Subscriptions\n\n```php\n// Cancel immediately\n$user->subscription('default')->cancel();\n\n// Cancel at end of billing period\n$user->subscription('default')->cancelAtEndOfBillingPeriod();\n\n// Resume canceled subscription\nif ($user->subscription('default')->onGracePeriod()) {\n    $user->subscription('default')->resume();\n}\n```\n\n### Working with Invoices\n\n```php\n// Get all invoices\n$invoices = $user->invoices();\n\n// Get upcoming invoice\n$upcomingInvoice = $user->upcomingInvoice('default');\n\n// Download invoice PDF\nreturn $user->invoices()->first()->download();\n```\n\n### Billing Portal Integration\n\n```php\n// Redirect to Stripe billing portal\nRoute::get('/billing', function (Request $request) {\n    return $request->user()\n        ->redirectToBillingPortal(route('dashboard'));\n})->middleware(['auth']);\n```\n\n### Customer Management\n\n```php\n// Create/get Stripe customer\n$stripeCustomer = $user->createOrGetStripeCustomer();\n\n// Update customer details\n$user->updateStripeCustomer([\n    'name' => 'Updated Name',\n    'email' => 'updated@example.com',\n]);\n\n// Manage tax IDs\n$taxId = $user->createTaxId('eu_vat', 'BE0123456789');\n$user->deleteTaxId('txi_belgium');\n```\n\n## Key Concepts\n\n### Billable Model\nThe `Billable` trait adds subscription and payment functionality to your Eloquent models (typically `User`). It provides methods for creating subscriptions, processing charges, managing payment methods, and accessing invoices.\n\n### Subscriptions\nCashier manages recurring billing through subscriptions. Each subscription has:\n- **Name**: Identifier like \"default\" or \"premium\"\n- **Price ID**: Stripe price identifier (e.g., \"price_monthly\")\n- **Status**: Active, trialing, canceled, incomplete, etc.\n- **Trial period**: Optional trial days before charging\n- **Metered billing**: Support for usage-based pricing\n\n### Payment Methods\nStripe payment methods represent stored payment credentials (cards, bank accounts). Cashier provides helpers to:\n- Store payment methods securely via Setup Intents\n- Set default payment methods for subscriptions\n- Update and delete payment methods\n- Handle payment method verification\n\n### Webhooks\nStripe sends webhook events for subscription changes, payment failures, invoice updates, etc. Cashier automatically handles common webhooks, but you can extend functionality by listening to specific events.\n\n### Checkout Sessions\nStripe Checkout provides a pre-built payment page. Cashier simplifies creating checkout sessions for subscriptions and one-time products, handling the complete payment flow with minimal code.\n\n### Invoices\nCashier provides access to Stripe invoices for both subscriptions and one-time charges. You can retrieve, preview, and download invoices as PDFs.\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Complete Laravel Cashier documentation covering:\n  - Installation and configuration\n  - Subscription management (create, swap, cancel, resume)\n  - Payment method handling and Setup Intents\n  - Single charges and invoicing\n  - Stripe Checkout integration\n  - Webhook handling and event processing\n  - Customer portal integration\n  - Tax ID management\n  - Testing strategies\n\nUse `view` to read the reference file when you need detailed information about specific features.\n\n## Working with This Skill\n\n### For Beginners\n\nStart by:\n1. Installing Cashier and running migrations\n2. Adding the `Billable` trait to your `User` model\n3. Setting up environment variables (STRIPE_KEY, STRIPE_SECRET)\n4. Creating your first subscription with `newSubscription()`\n5. Testing with Stripe test mode API keys\n\n**Basic workflow:**\n```php\n// 1. Configure model\nuse Laravel\\Cashier\\Billable;\nclass User extends Authenticatable { use Billable; }\n\n// 2. Create subscription\n$user->newSubscription('default', 'price_monthly')->create();\n\n// 3. Check status\nif ($user->subscribed('default')) {\n    // Grant access\n}\n```\n\n### For Intermediate Users\n\nFocus on:\n- Implementing complete checkout flows with Stripe Checkout\n- Managing payment method changes and updates\n- Handling subscription plan swaps and prorations\n- Working with trial periods and grace periods\n- Processing one-time charges alongside subscriptions\n- Customizing invoice details and tax information\n\n### For Advanced Users\n\nExplore:\n- Webhook event customization and extended handling\n- Metered billing and usage-based pricing\n- Multi-plan subscriptions (multiple subscriptions per user)\n- Customer balance and credit management\n- Tax ID validation and compliance\n- Advanced invoice customization\n- Stripe Connect integration for marketplaces\n- Testing strategies for subscription flows\n\n### Navigation Tips\n\n- Start with the Quick Reference section for common tasks\n- Check Key Concepts to understand core Cashier terminology\n- Use `references/other.md` for complete implementation details\n- Reference the official Laravel Cashier docs at https://laravel.com/docs/12.x/billing for the latest updates\n\n## Environment Configuration\n\nRequired environment variables in `.env`:\n\n```env\nSTRIPE_KEY=pk_test_your_stripe_publishable_key\nSTRIPE_SECRET=sk_test_your_stripe_secret_key\nSTRIPE_WEBHOOK_SECRET=whsec_your_webhook_signing_secret\nCASHIER_CURRENCY=usd\n```\n\n**Important:** Use test mode keys (pk_test_*, sk_test_*) during development and switch to live keys (pk_live_*, sk_live_*) for production.\n\n## Common Patterns\n\n### Complete Subscription Checkout Flow\n\n```php\n// 1. Create checkout session\npublic function subscribe(Request $request)\n{\n    return $request->user()\n        ->newSubscription('default', 'price_monthly')\n        ->trialDays(14)\n        ->allowPromotionCodes()\n        ->checkout([\n            'success_url' => route('checkout.success') . '?session_id={CHECKOUT_SESSION_ID}',\n            'cancel_url' => route('checkout.cancel'),\n        ]);\n}\n\n// 2. Handle success\npublic function success(Request $request)\n{\n    $sessionId = $request->get('session_id');\n\n    if ($request->user()->subscribed('default')) {\n        return redirect()->route('dashboard')\n            ->with('success', 'Subscription activated!');\n    }\n}\n```\n\n### Upgrade/Downgrade Pattern\n\n```php\n// Upgrade to annual plan with prorated credit\npublic function upgrade(Request $request)\n{\n    $subscription = $request->user()->subscription('default');\n\n    if ($subscription->active()) {\n        $subscription->swap('price_yearly');\n        return back()->with('success', 'Upgraded to annual plan!');\n    }\n}\n```\n\n### Payment Method Update Flow\n\n```php\n// Controller: Generate setup intent\npublic function paymentMethods(Request $request)\n{\n    return view('billing.payment-methods', [\n        'intent' => $request->user()->createSetupIntent(),\n        'paymentMethods' => $request->user()->paymentMethods(),\n    ]);\n}\n\n// View: Stripe.js integration (Blade)\n<form id=\"payment-form\" method=\"POST\" action=\"{{ route('payment-method.add') }}\">\n    @csrf\n    <div id=\"card-element\"></div>\n    <button type=\"submit\">Add Payment Method</button>\n</form>\n\n// Controller: Store payment method\npublic function addPaymentMethod(Request $request)\n{\n    $request->user()->addPaymentMethod($request->payment_method);\n    return back()->with('success', 'Payment method added!');\n}\n```\n\n## Resources\n\n### Official Documentation\n- Laravel Cashier (Stripe): https://laravel.com/docs/12.x/billing\n- Stripe API Documentation: https://stripe.com/docs/api\n- Stripe Testing Guide: https://stripe.com/docs/testing\n\n### Testing\nUse Stripe test card numbers for development:\n- Success: `4242 4242 4242 4242`\n- Decline: `4000 0000 0000 0002`\n- Requires authentication: `4000 0025 0000 3155`\n\nAlways use test mode API keys during development and testing.\n\n## Notes\n\n- Cashier requires PHP 8.1+ and Laravel 10.0+\n- Always configure webhooks in production for reliable subscription management\n- Use Stripe test mode during development\n- The Billable trait can be added to any Eloquent model, not just User\n- Cashier handles most webhook events automatically\n- Consider using Stripe's billing portal for customer self-service\n- Reference files preserve structure and examples from official Laravel docs\n- Test subscription flows thoroughly before going to production\n\n## Updating\n\nThis skill is based on Laravel Cashier for Laravel 12.x. For the latest information, refer to the official documentation at https://laravel.com/docs/billing.\n",
        "laravel-dusk/SKILL.md": "---\nname: laravel-dusk\ndescription: Laravel Dusk - Browser automation and testing API for Laravel applications. Use when writing browser tests, automating UI testing, testing JavaScript interactions, or implementing end-to-end tests in Laravel.\n---\n\n# Laravel Dusk Skill\n\nComprehensive assistance with Laravel Dusk browser automation and testing, providing expert guidance on writing expressive, easy-to-use browser tests for your Laravel applications.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Writing or debugging browser automation tests for Laravel\n- Testing user interfaces and JavaScript interactions\n- Implementing end-to-end (E2E) testing workflows\n- Setting up automated UI testing in Laravel applications\n- Working with form submissions, authentication flows, or page navigation tests\n- Configuring ChromeDriver or alternative browser drivers\n- Using the Page Object pattern for test organization\n- Testing Vue.js components or waiting for JavaScript events\n- Troubleshooting browser test failures or timing issues\n\n## Quick Reference\n\n### 1. Basic Browser Test\n\n```php\npublic function testBasicExample(): void\n{\n    $this->browse(function (Browser $browser) {\n        $browser->visit('/login')\n            ->type('email', 'user@example.com')\n            ->type('password', 'password')\n            ->press('Login')\n            ->assertPathIs('/home');\n    });\n}\n```\n\n### 2. Using Dusk Selectors (Recommended)\n\n```html\n<!-- In your Blade template -->\n<button dusk=\"login-button\">Login</button>\n<input dusk=\"email-input\" name=\"email\" />\n```\n\n```php\n// In your test - use @ prefix for dusk selectors\n$browser->type('@email-input', 'user@example.com')\n    ->click('@login-button');\n```\n\n### 3. Testing Multiple Browsers\n\n```php\npublic function testMultiUserInteraction(): void\n{\n    $this->browse(function (Browser $first, Browser $second) {\n        $first->loginAs(User::find(1))\n            ->visit('/home');\n\n        $second->loginAs(User::find(2))\n            ->visit('/home');\n    });\n}\n```\n\n### 4. Waiting for Elements\n\n```php\n// Wait for element to appear\n$browser->waitFor('.modal')\n    ->assertSee('Confirmation Required');\n\n// Wait for text to appear\n$browser->waitForText('Hello World');\n\n// Wait for JavaScript condition\n$browser->waitUntil('App.data.servers.length > 0');\n\n// Wait when element is available\n$browser->whenAvailable('.modal', function (Browser $modal) {\n    $modal->assertSee('Delete Account')\n        ->press('OK');\n});\n```\n\n### 5. Form Interactions\n\n```php\n// Text input\n$browser->type('email', 'user@example.com')\n    ->append('notes', 'Additional text')\n    ->clear('description');\n\n// Dropdown selection\n$browser->select('size', 'Large')\n    ->select('categories', ['Art', 'Music']); // Multiple\n\n// Checkboxes and radio buttons\n$browser->check('terms')\n    ->radio('gender', 'male');\n\n// File upload\n$browser->attach('photo', __DIR__.'/photos/profile.jpg');\n```\n\n### 6. Page Object Pattern\n\n```php\n// Generate page object\n// php artisan dusk:page Login\n\n// app/tests/Browser/Pages/Login.php\nclass Login extends Page\n{\n    public function url(): string\n    {\n        return '/login';\n    }\n\n    public function elements(): array\n    {\n        return [\n            '@email' => 'input[name=email]',\n            '@password' => 'input[name=password]',\n            '@submit' => 'button[type=submit]',\n        ];\n    }\n\n    public function login(Browser $browser, $email, $password): void\n    {\n        $browser->type('@email', $email)\n            ->type('@password', $password)\n            ->press('@submit');\n    }\n}\n\n// Use in test\n$browser->visit(new Login)\n    ->login('user@example.com', 'password')\n    ->assertPathIs('/dashboard');\n```\n\n### 7. Browser Macros (Reusable Methods)\n\n```php\n// In AppServiceProvider or DuskServiceProvider\nuse Laravel\\Dusk\\Browser;\n\nBrowser::macro('scrollToElement', function (string $element) {\n    $this->script(\"$('html, body').animate({\n        scrollTop: $('{$element}').offset().top\n    }, 0);\");\n\n    return $this;\n});\n\n// Use in tests\n$browser->scrollToElement('#footer')\n    ->assertSee('Copyright 2024');\n```\n\n### 8. Database Management in Tests\n\n```php\nuse Illuminate\\Foundation\\Testing\\DatabaseMigrations;\nuse Illuminate\\Foundation\\Testing\\DatabaseTruncation;\n\nclass ExampleTest extends DuskTestCase\n{\n    // Option 1: Run migrations before each test (slower)\n    use DatabaseMigrations;\n\n    // Option 2: Truncate tables after first migration (faster)\n    use DatabaseTruncation;\n\n    // Exclude specific tables from truncation\n    protected $exceptTables = ['migrations'];\n}\n```\n\n### 9. JavaScript Execution\n\n```php\n// Execute JavaScript\n$browser->script('document.documentElement.scrollTop = 0');\n\n// Get JavaScript return value\n$path = $browser->script('return window.location.pathname');\n\n// Wait for reload after action\n$browser->waitForReload(function (Browser $browser) {\n    $browser->press('Submit');\n})->assertSee('Success');\n```\n\n### 10. Common Assertions\n\n```php\n// Page assertions\n$browser->assertPathIs('/dashboard')\n    ->assertRouteIs('dashboard')\n    ->assertTitle('Dashboard')\n    ->assertSee('Welcome Back')\n    ->assertDontSee('Error');\n\n// Form assertions\n$browser->assertInputValue('email', 'user@example.com')\n    ->assertChecked('remember')\n    ->assertSelected('role', 'admin')\n    ->assertEnabled('submit-button');\n\n// Element assertions\n$browser->assertVisible('.success-message')\n    ->assertMissing('.error-alert')\n    ->assertPresent('button[type=submit]');\n\n// Authentication assertions\n$browser->assertAuthenticated()\n    ->assertAuthenticatedAs($user);\n```\n\n## Key Concepts\n\n### Dusk Selectors vs CSS Selectors\n\n**Dusk selectors** (recommended) use HTML `dusk` attributes that won't change with UI updates:\n- More stable than CSS classes or IDs\n- Explicitly mark elements for testing\n- Use `@` prefix in tests: `$browser->click('@submit-button')`\n- Add to HTML: `<button dusk=\"submit-button\">Submit</button>`\n\n**CSS selectors** are more brittle but sometimes necessary:\n- `.class-name`, `#id`, `div > button`\n- Can break when HTML structure changes\n- Use when you don't control the HTML\n\n### Waiting Strategies\n\n**Always wait explicitly** rather than using arbitrary pauses:\n- `waitFor('.selector')` - Wait for element to exist\n- `waitUntilMissing('.selector')` - Wait for element to disappear\n- `waitForText('text')` - Wait for text to appear\n- `waitUntil('condition')` - Wait for JavaScript condition\n- `whenAvailable('.selector', callback)` - Run callback when available\n\n### Page Objects\n\nOrganize complex test logic into **Page classes**:\n- Define URL, assertions, and element selectors\n- Create reusable methods for page-specific actions\n- Improve test readability and maintainability\n- Generate with: `php artisan dusk:page PageName`\n\n### Browser Macros\n\nDefine **reusable browser methods** for common patterns:\n- Register in service provider's `boot()` method\n- Use across all tests\n- Chain like built-in methods\n- Example: scrolling, modal interactions, custom assertions\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Complete Laravel Dusk documentation covering:\n  - Installation and configuration\n  - ChromeDriver management\n  - Test generation and execution\n  - Browser interaction methods\n  - Form handling and file uploads\n  - Waiting strategies and assertions\n  - Page Objects and Components patterns\n  - CI/CD integration examples\n\nUse the reference file when you need:\n- Detailed API documentation for specific methods\n- Complete list of available assertions (70+)\n- Configuration options for different environments\n- Advanced topics like iframes, JavaScript dialogs, or keyboard macros\n\n## Working with This Skill\n\n### For Beginners\n\n1. **Start with basic tests**: Use simple `visit()`, `type()`, `press()`, and `assertSee()` methods\n2. **Use Dusk selectors**: Add `dusk` attributes to your HTML for stable selectors\n3. **Learn waiting**: Always use `waitFor()` instead of `pause()` for reliable tests\n4. **Run tests**: Execute with `php artisan dusk` to see results\n\n### For Intermediate Users\n\n1. **Implement Page Objects**: Organize complex tests with the Page pattern\n2. **Use database traits**: Choose between `DatabaseMigrations` or `DatabaseTruncation`\n3. **Create browser macros**: Define reusable methods for common workflows\n4. **Test authentication**: Use `loginAs()` to bypass login screens\n5. **Handle JavaScript**: Use `waitUntil()` for dynamic content and AJAX\n\n### For Advanced Users\n\n1. **Multi-browser testing**: Test real-time features with multiple browsers\n2. **Custom waiting logic**: Use `waitUsing()` for complex conditions\n3. **Component pattern**: Create reusable components for shared UI elements\n4. **CI/CD integration**: Set up Dusk in GitHub Actions, Travis CI, or other platforms\n5. **Alternative drivers**: Configure Selenium Grid or other browsers beyond ChromeDriver\n\n### Navigation Tips\n\n- **Quick examples**: Check the Quick Reference section above for common patterns\n- **Method documentation**: See `other.md` for complete API reference\n- **Assertions list**: Reference file contains all 70+ available assertions\n- **Configuration**: Check reference file for environment setup and driver options\n- **Best practices**: Look for \"Best Practices\" section in reference documentation\n\n## Installation & Setup\n\n```bash\n# Install Laravel Dusk\ncomposer require laravel/dusk --dev\n\n# Run installation\nphp artisan dusk:install\n\n# Update ChromeDriver\nphp artisan dusk:chrome-driver\n\n# Make binaries executable (Unix)\nchmod -R 0755 vendor/laravel/dusk/bin/\n\n# Run tests\nphp artisan dusk\n```\n\n## Common Commands\n\n```bash\n# Generate new test\nphp artisan dusk:make LoginTest\n\n# Generate page object\nphp artisan dusk:page Dashboard\n\n# Generate component\nphp artisan dusk:component Modal\n\n# Run all tests\nphp artisan dusk\n\n# Run specific test\nphp artisan dusk tests/Browser/LoginTest.php\n\n# Run failed tests only\nphp artisan dusk:fails\n\n# Run with filter\nphp artisan dusk --group=authentication\n\n# Update ChromeDriver\nphp artisan dusk:chrome-driver --detect\n```\n\n## Resources\n\n### Official Documentation\n- Laravel Dusk Documentation: https://laravel.com/docs/12.x/dusk\n- API Reference: See `references/other.md` for complete method listings\n\n### Common Patterns in Reference Files\n\nThe reference documentation includes:\n- 70+ assertion methods with descriptions\n- Complete form interaction API\n- Waiting strategies and timing best practices\n- Page Object pattern examples\n- Browser macro definitions\n- CI/CD configuration examples\n- Environment-specific test setup\n\n## Best Practices\n\n1. **Use Dusk selectors** (`dusk` attributes) instead of CSS classes for stability\n2. **Wait explicitly** with `waitFor()` methods instead of arbitrary `pause()`\n3. **Organize with Page Objects** for complex test scenarios\n4. **Leverage database truncation** for faster test execution\n5. **Create browser macros** for frequently repeated actions\n6. **Scope selectors** with `with()` or `elsewhere()` for specific page regions\n7. **Test user behavior** rather than implementation details\n8. **Use authentication shortcuts** like `loginAs()` to skip login flows\n9. **Take screenshots** with `screenshot()` for debugging failures\n10. **Group related tests** and use `--group` flag for targeted execution\n\n## Troubleshooting\n\n### Common Issues\n\n**ChromeDriver version mismatch:**\n```bash\nphp artisan dusk:chrome-driver --detect\n```\n\n**Elements not found:**\n- Use `waitFor('.selector')` before interacting\n- Check if element is in an iframe\n- Verify selector with browser dev tools\n\n**Tests failing randomly:**\n- Replace `pause()` with explicit waits\n- Increase timeout: `waitFor('.selector', 10)`\n- Use `waitUntil()` for JavaScript conditions\n\n**Database state issues:**\n- Use `DatabaseTruncation` trait\n- Reset data in `setUp()` method\n- Check for transactions in application code\n\n## Notes\n\n- Laravel Dusk uses ChromeDriver by default (no Selenium/JDK required)\n- Supports alternative browsers via Selenium WebDriver protocol\n- Tests are stored in `tests/Browser` directory\n- Page objects go in `tests/Browser/Pages`\n- Screenshots saved to `tests/Browser/screenshots` on failure\n- Console logs saved to `tests/Browser/console` for debugging\n",
        "laravel-mcp/SKILL.md": "---\nname: laravel-mcp\ndescription: Laravel v12 - The PHP Framework For Web Artisans (project, gitignored)\n---\n\n# Laravel MCP Skill\n\nComprehensive assistance with Laravel MCP (Model Context Protocol) development. Laravel MCP provides a simple and elegant way for AI clients to interact with your Laravel application through the Model Context Protocol, enabling you to define servers, tools, resources, and prompts for AI-powered interactions.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Building MCP servers for Laravel applications\n- Creating AI tools that perform actions in Laravel\n- Defining reusable prompts for AI interactions\n- Exposing Laravel resources (data/content) to AI clients\n- Implementing OAuth 2.1 or Sanctum authentication for MCP\n- Registering and configuring MCP routes (web or local)\n- Testing MCP servers and tools\n- Working with Laravel JSON Schema builder for tool inputs\n- Implementing streaming responses or progress notifications\n- Building AI-powered Laravel features using MCP\n\n## Key Concepts\n\n### Core Components\n\n**MCP Server**: The central communication point that exposes MCP capabilities. Each server has:\n- `name`: Server identifier\n- `version`: Server version\n- `instructions`: Description of the server's purpose\n- `tools`: Array of tool classes\n- `resources`: Array of resource classes\n- `prompts`: Array of prompt classes\n\n**Tools**: Enable AI clients to perform actions. Tools can:\n- Define input schemas using Laravel's JSON Schema builder\n- Validate arguments with Laravel validation rules\n- Support dependency injection\n- Return single or multiple responses\n- Stream responses using generators\n- Use annotations like `#[IsReadOnly]` and `#[IsIdempotent]`\n\n**Prompts**: Reusable prompt templates that provide a standardized way to structure common queries with argument definitions and validation.\n\n**Resources**: Enable your server to expose data and content that AI clients can read, including text and blob responses with customizable MIME types and URIs.\n\n## Quick Reference\n\n### 1. Basic MCP Server Definition\n\n```php\n<?php\nnamespace App\\Mcp\\Servers;\n\nuse Laravel\\Mcp\\Server;\n\nclass WeatherServer extends Server\n{\n    protected string $name = 'Weather Server';\n    protected string $version = '1.0.0';\n    protected string $instructions = 'This server provides weather information and forecasts.';\n\n    protected array $tools = [\n        // CurrentWeatherTool::class,\n    ];\n\n    protected array $resources = [\n        // WeatherGuidelinesResource::class,\n    ];\n\n    protected array $prompts = [\n        // DescribeWeatherPrompt::class,\n    ];\n}\n```\n\n### 2. Tool with Input Schema\n\n```php\n<?php\nnamespace App\\Mcp\\Tools;\n\nuse Illuminate\\JsonSchema\\JsonSchema;\nuse Laravel\\Mcp\\Request;\nuse Laravel\\Mcp\\Response;\nuse Laravel\\Mcp\\Server\\Tool;\n\nclass CurrentWeatherTool extends Tool\n{\n    protected string $description = 'Fetches the current weather forecast for a specified location.';\n\n    public function handle(Request $request): Response\n    {\n        $location = $request->get('location');\n        // Get weather...\n        return Response::text('The weather is...');\n    }\n\n    public function schema(JsonSchema $schema): array\n    {\n        return [\n            'location' => $schema->string()\n                ->description('The location to get the weather for.')\n                ->required(),\n        ];\n    }\n}\n```\n\n### 3. Tool with Validation\n\n```php\npublic function handle(Request $request): Response\n{\n    $validated = $request->validate([\n        'location' => 'required|string|max:100',\n        'units' => 'in:celsius,fahrenheit',\n    ], [\n        'location.required' => 'You must specify a location.',\n        'units.in' => 'You must specify either \"celsius\" or \"fahrenheit\".',\n    ]);\n    // Fetch weather data...\n}\n```\n\n### 4. Tool with Dependency Injection\n\n```php\n<?php\nnamespace App\\Mcp\\Tools;\n\nuse App\\Repositories\\WeatherRepository;\nuse Laravel\\Mcp\\Request;\nuse Laravel\\Mcp\\Response;\nuse Laravel\\Mcp\\Server\\Tool;\n\nclass CurrentWeatherTool extends Tool\n{\n    public function __construct(\n        protected WeatherRepository $weather,\n    ) {}\n\n    public function handle(Request $request, WeatherRepository $weather): Response\n    {\n        $location = $request->get('location');\n        $forecast = $weather->getForecastFor($location);\n        // ...\n    }\n}\n```\n\n### 5. Tool with Annotations\n\n```php\n<?php\nnamespace App\\Mcp\\Tools;\n\nuse Laravel\\Mcp\\Server\\Tools\\Annotations\\IsIdempotent;\nuse Laravel\\Mcp\\Server\\Tools\\Annotations\\IsReadOnly;\nuse Laravel\\Mcp\\Server\\Tool;\n\n#[IsIdempotent]\n#[IsReadOnly]\nclass CurrentWeatherTool extends Tool\n{\n    // ...\n}\n```\n\n### 6. Streaming Tool Response\n\n```php\n<?php\nnamespace App\\Mcp\\Tools;\n\nuse Generator;\nuse Laravel\\Mcp\\Request;\nuse Laravel\\Mcp\\Response;\nuse Laravel\\Mcp\\Server\\Tool;\n\nclass CurrentWeatherTool extends Tool\n{\n    public function handle(Request $request): Generator\n    {\n        $locations = $request->array('locations');\n\n        foreach ($locations as $index => $location) {\n            yield Response::notification('processing/progress', [\n                'current' => $index + 1,\n                'total' => count($locations),\n                'location' => $location,\n            ]);\n            yield Response::text($this->forecastFor($location));\n        }\n    }\n}\n```\n\n### 7. Prompt Definition\n\n```php\n<?php\nnamespace App\\Mcp\\Prompts;\n\nuse Laravel\\Mcp\\Server\\Prompt;\nuse Laravel\\Mcp\\Server\\Prompts\\Argument;\n\nclass DescribeWeatherPrompt extends Prompt\n{\n    protected string $description = 'Generates a natural-language explanation of the weather.';\n\n    public function arguments(): array\n    {\n        return [\n            new Argument(\n                name: 'tone',\n                description: 'The tone to use in the weather description.',\n                required: true,\n            ),\n        ];\n    }\n\n    public function handle(Request $request): array\n    {\n        $tone = $request->string('tone');\n        return [\n            Response::text(\"You are a weather assistant. Provide a {$tone} tone.\")->asAssistant(),\n            Response::text(\"What is the current weather like in New York City?\"),\n        ];\n    }\n}\n```\n\n### 8. Resource Definition\n\n```php\n<?php\nnamespace App\\Mcp\\Resources;\n\nuse Laravel\\Mcp\\Request;\nuse Laravel\\Mcp\\Response;\nuse Laravel\\Mcp\\Server\\Resource;\n\nclass WeatherGuidelinesResource extends Resource\n{\n    protected string $description = 'Comprehensive guidelines for using the Weather API.';\n    protected string $uri = 'weather://resources/guidelines';\n    protected string $mimeType = 'application/pdf';\n\n    public function handle(Request $request): Response\n    {\n        return Response::text($weatherData);\n    }\n}\n```\n\n### 9. Server Registration (Web)\n\n```php\nuse App\\Mcp\\Servers\\WeatherServer;\nuse Laravel\\Mcp\\Facades\\Mcp;\n\nMcp::web('/mcp/weather', WeatherServer::class);\n\n// With middleware\nMcp::web('/mcp/weather', WeatherServer::class)\n    ->middleware(['throttle:mcp']);\n```\n\n### 10. Server Registration (Local)\n\n```php\nuse App\\Mcp\\Servers\\WeatherServer;\nuse Laravel\\Mcp\\Facades\\Mcp;\n\nMcp::local('weather', WeatherServer::class);\n```\n\n### 11. OAuth 2.1 Authentication Setup\n\n```php\nuse App\\Mcp\\Servers\\WeatherExample;\nuse Laravel\\Mcp\\Facades\\Mcp;\n\nMcp::oauthRoutes();\n\nMcp::web('/mcp/weather', WeatherExample::class)\n    ->middleware('auth:api');\n```\n\n### 12. Sanctum Authentication\n\n```php\nuse App\\Mcp\\Servers\\WeatherExample;\nuse Laravel\\Mcp\\Facades\\Mcp;\n\nMcp::web('/mcp/demo', WeatherExample::class)\n    ->middleware('auth:sanctum');\n```\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Complete Laravel MCP documentation from Laravel 12.x official docs, including:\n  - Installation and setup instructions\n  - Server, tool, resource, and prompt creation\n  - Input schema definition using JSON Schema builder\n  - Validation and dependency injection\n  - Streaming responses and progress notifications\n  - Authentication (OAuth 2.1 and Sanctum)\n  - Registration (web and local routes)\n  - Testing and inspection\n\nUse `view` to read specific reference files when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n\nStart by understanding the core concepts:\n1. **Installation**: Install Laravel MCP via `composer require laravel/mcp`\n2. **Setup**: Run `php artisan vendor:publish --tag=ai-routes` to create `routes/ai.php`\n3. **First Server**: Generate your first server with `php artisan make:mcp-server`\n4. **Register**: Add your server to `routes/ai.php` using `Mcp::web()` or `Mcp::local()`\n\nBegin with simple read-only tools using the `#[IsReadOnly]` annotation before moving to tools that modify data.\n\n### For Intermediate Users\n\nFocus on building robust tools:\n- Use JSON Schema builder for precise input validation\n- Leverage Laravel's validation rules for complex constraints\n- Implement dependency injection for clean, testable code\n- Use prompts to create reusable AI interaction patterns\n- Expose resources to provide context to AI clients\n\n### For Advanced Users\n\nImplement production-ready features:\n- Add OAuth 2.1 or Sanctum authentication to secure your MCP servers\n- Use streaming responses for long-running operations with progress notifications\n- Apply middleware for rate limiting and custom authentication\n- Create idempotent tools using `#[IsIdempotent]` annotation\n- Build complex multi-tool workflows\n- Use the MCP Inspector for debugging and testing\n\n### Navigation Tips\n\n- **Quick implementation**: Use the Quick Reference section above for common patterns\n- **Detailed learning**: Read `references/other.md` for comprehensive documentation\n- **Examples**: All code examples include proper namespaces and imports\n- **Testing**: Refer to documentation for MCP Inspector usage and unit testing\n\n## Common Patterns\n\n### Creating a New MCP Server\n\n```bash\n# Generate server class\nphp artisan make:mcp-server WeatherServer\n\n# Edit app/Mcp/Servers/WeatherServer.php\n# Add tools, resources, and prompts\n\n# Register in routes/ai.php\nMcp::web('/mcp/weather', WeatherServer::class);\n```\n\n### Input Schema Patterns\n\n```php\n// Simple required string\n'location' => $schema->string()->required()\n\n// Optional with default\n'units' => $schema->string()->default('celsius')\n\n// Number with constraints\n'temperature' => $schema->number()->minimum(0)->maximum(100)\n\n// Array of items\n'cities' => $schema->array()->items($schema->string())\n\n// Object with properties\n'forecast' => $schema->object()->properties([\n    'temperature' => $schema->number(),\n    'humidity' => $schema->number(),\n])\n```\n\n### Response Patterns\n\n```php\n// Text response\nreturn Response::text('The weather is sunny');\n\n// Multiple responses\nreturn [\n    Response::text('First message'),\n    Response::text('Second message'),\n];\n\n// Notification (streaming)\nyield Response::notification('processing/progress', ['status' => 'processing']);\n```\n\n## Resources\n\n### Installation\n\n```bash\ncomposer require laravel/mcp\nphp artisan vendor:publish --tag=ai-routes\n```\n\n### Official Documentation\n\n- **Laravel MCP Docs**: https://laravel.com/docs/12.x/mcp\n- **Model Context Protocol Spec**: https://modelcontextprotocol.io/\n\n### Related Laravel Features\n\n- **JSON Schema Builder**: For defining tool input schemas\n- **Validation**: For validating tool arguments\n- **Service Container**: For dependency injection in tools and resources\n- **OAuth/Sanctum**: For authentication\n\n## Notes\n\n- This skill was generated from official Laravel 12.x MCP documentation\n- All code examples use proper PHP 8+ syntax with typed properties\n- Examples demonstrate Laravel's elegant API design\n- Tools support both synchronous and streaming responses\n- Authentication is optional but recommended for production use\n- Both web (HTTP) and local (CLI) server registration are supported\n\n## Tips & Best Practices\n\n1. **Start Simple**: Begin with read-only tools marked with `#[IsReadOnly]`\n2. **Validate Input**: Always define schemas and use validation for user input\n3. **Use DI**: Leverage dependency injection for repositories and services\n4. **Stream Progress**: For long operations, use generators to stream progress\n5. **Secure Your Servers**: Add authentication middleware for production\n6. **Test Thoroughly**: Use the MCP Inspector and unit tests to validate functionality\n7. **Document Well**: Write clear descriptions for servers, tools, prompts, and resources\n8. **Follow Conventions**: Use Laravel's service container patterns and naming conventions\n",
        "laravel-prompts/SKILL.md": "---\nname: laravel-prompts\ndescription: Laravel Prompts - Beautiful and user-friendly forms for command-line applications with browser-like features including placeholder text and validation\n---\n\n# Laravel Prompts Skill\n\nLaravel Prompts is a PHP package for adding beautiful and user-friendly forms to your command-line applications, with browser-like features including placeholder text and validation. It's pre-installed in Laravel and supports macOS, Linux, and Windows with WSL.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Building Laravel Artisan commands with interactive prompts\n- Creating user-friendly CLI applications in PHP\n- Implementing form validation in command-line tools\n- Adding text input, select menus, or confirmation dialogs to console commands\n- Working with progress bars, loading spinners, or tables in CLI applications\n- Testing Laravel console commands with prompts\n- Converting simple console input to modern, validated, interactive prompts\n\n## Quick Reference\n\n### Basic Text Input\n\n```php\nuse function Laravel\\Prompts\\text;\n\n// Simple text input\n$name = text('What is your name?');\n\n// With placeholder and validation\n$name = text(\n    label: 'What is your name?',\n    placeholder: 'E.g. Taylor Otwell',\n    required: true,\n    validate: fn (string $value) => match (true) {\n        strlen($value) < 3 => 'The name must be at least 3 characters.',\n        strlen($value) > 255 => 'The name must not exceed 255 characters.',\n        default => null\n    }\n);\n```\n\n### Password Input\n\n```php\nuse function Laravel\\Prompts\\password;\n\n$password = password(\n    label: 'What is your password?',\n    placeholder: 'password',\n    hint: 'Minimum 8 characters.',\n    required: true,\n    validate: fn (string $value) => match (true) {\n        strlen($value) < 8 => 'The password must be at least 8 characters.',\n        default => null\n    }\n);\n```\n\n### Select (Single Choice)\n\n```php\nuse function Laravel\\Prompts\\select;\n\n// Simple select\n$role = select(\n    label: 'What role should the user have?',\n    options: ['Member', 'Contributor', 'Owner']\n);\n\n// With associative array (returns key)\n$role = select(\n    label: 'What role should the user have?',\n    options: [\n        'member' => 'Member',\n        'contributor' => 'Contributor',\n        'owner' => 'Owner',\n    ],\n    default: 'owner'\n);\n\n// From database with custom scroll\n$role = select(\n    label: 'Which category would you like to assign?',\n    options: Category::pluck('name', 'id'),\n    scroll: 10\n);\n```\n\n### Multiselect (Multiple Choices)\n\n```php\nuse function Laravel\\Prompts\\multiselect;\n\n$permissions = multiselect(\n    label: 'What permissions should be assigned?',\n    options: ['Read', 'Create', 'Update', 'Delete'],\n    default: ['Read', 'Create'],\n    hint: 'Permissions may be updated at any time.'\n);\n\n// With validation\n$permissions = multiselect(\n    label: 'What permissions should the user have?',\n    options: [\n        'read' => 'Read',\n        'create' => 'Create',\n        'update' => 'Update',\n        'delete' => 'Delete',\n    ],\n    validate: fn (array $values) => ! in_array('read', $values)\n        ? 'All users require the read permission.'\n        : null\n);\n```\n\n### Confirmation Dialog\n\n```php\nuse function Laravel\\Prompts\\confirm;\n\n// Simple yes/no\n$confirmed = confirm('Do you accept the terms?');\n\n// With custom labels\n$confirmed = confirm(\n    label: 'Do you accept the terms?',\n    default: false,\n    yes: 'I accept',\n    no: 'I decline',\n    hint: 'The terms must be accepted to continue.'\n);\n\n// Require \"Yes\"\n$confirmed = confirm(\n    label: 'Do you accept the terms?',\n    required: true\n);\n```\n\n### Search (Searchable Select)\n\n```php\nuse function Laravel\\Prompts\\search;\n\n$id = search(\n    label: 'Search for the user that should receive the mail',\n    placeholder: 'E.g. Taylor Otwell',\n    options: fn (string $value) => strlen($value) > 0\n        ? User::whereLike('name', \"%{$value}%\")->pluck('name', 'id')->all()\n        : [],\n    hint: 'The user will receive an email immediately.',\n    scroll: 10\n);\n```\n\n### Suggest (Auto-completion)\n\n```php\nuse function Laravel\\Prompts\\suggest;\n\n// Static options\n$name = suggest('What is your name?', ['Taylor', 'Dayle']);\n\n// Dynamic filtering\n$name = suggest(\n    label: 'What is your name?',\n    options: fn ($value) => collect(['Taylor', 'Dayle'])\n        ->filter(fn ($name) => Str::contains($name, $value, ignoreCase: true))\n);\n```\n\n### Multi-step Forms\n\n```php\nuse function Laravel\\Prompts\\form;\n\n$responses = form()\n    ->text('What is your name?', required: true, name: 'name')\n    ->password(\n        label: 'What is your password?',\n        validate: ['password' => 'min:8'],\n        name: 'password'\n    )\n    ->confirm('Do you accept the terms?')\n    ->submit();\n\n// Access named responses\necho $responses['name'];\necho $responses['password'];\n\n// Dynamic forms with previous responses\n$responses = form()\n    ->text('What is your name?', required: true, name: 'name')\n    ->add(function ($responses) {\n        return text(\"How old are you, {$responses['name']}?\");\n    }, name: 'age')\n    ->submit();\n```\n\n### Progress Bar\n\n```php\nuse function Laravel\\Prompts\\progress;\n\n// Simple usage\n$users = progress(\n    label: 'Updating users',\n    steps: User::all(),\n    callback: fn ($user) => $this->performTask($user)\n);\n\n// With dynamic labels\n$users = progress(\n    label: 'Updating users',\n    steps: User::all(),\n    callback: function ($user, $progress) {\n        $progress\n            ->label(\"Updating {$user->name}\")\n            ->hint(\"Created on {$user->created_at}\");\n        return $this->performTask($user);\n    },\n    hint: 'This may take some time.'\n);\n```\n\n### Loading Spinner\n\n```php\nuse function Laravel\\Prompts\\spin;\n\n$response = spin(\n    callback: fn () => Http::get('http://example.com'),\n    message: 'Fetching response...'\n);\n```\n\n## Key Concepts\n\n### Input Types\n\nLaravel Prompts provides several input types for different use cases:\n\n- **text()** - Single-line text input with optional placeholder and validation\n- **textarea()** - Multi-line text input for longer content\n- **password()** - Masked text input for sensitive data\n- **confirm()** - Yes/No confirmation dialog\n- **select()** - Single selection from a list of options\n- **multiselect()** - Multiple selections from a list\n- **suggest()** - Text input with auto-completion suggestions\n- **search()** - Searchable single selection with dynamic options\n- **multisearch()** - Searchable multiple selections\n- **pause()** - Pause execution until user presses ENTER\n\n### Output Types\n\nFor displaying information without input:\n\n- **info()** - Display informational message\n- **note()** - Display a note\n- **warning()** - Display warning message\n- **error()** - Display error message\n- **alert()** - Display alert message\n- **table()** - Display tabular data\n\n### Validation\n\nThree ways to validate prompts:\n\n1. **Closure validation**: Custom logic with match expressions\n   ```php\n   validate: fn (string $value) => match (true) {\n       strlen($value) < 3 => 'Too short.',\n       default => null\n   }\n   ```\n\n2. **Laravel validation rules**: Standard Laravel validation\n   ```php\n   validate: ['email' => 'required|email|unique:users']\n   ```\n\n3. **Required flag**: Simple requirement check\n   ```php\n   required: true\n   ```\n\n### Transformation\n\nUse the `transform` parameter to modify input before validation:\n\n```php\n$name = text(\n    label: 'What is your name?',\n    transform: fn (string $value) => trim($value),\n    validate: fn (string $value) => strlen($value) < 3\n        ? 'The name must be at least 3 characters.'\n        : null\n);\n```\n\n### Terminal Features\n\n- **Scrolling**: Configure visible items with `scroll` parameter (default: 5)\n- **Navigation**: Use arrow keys, j/k keys, or vim-style navigation\n- **Forms**: Press CTRL + U in forms to return to previous prompts\n- **Width**: Keep labels under 74 characters for 80-character terminals\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Complete Laravel Prompts documentation including:\n  - All prompt types (text, password, select, search, etc.)\n  - Validation strategies and examples\n  - Form API for multi-step input\n  - Progress bars and loading indicators\n  - Informational messages (info, warning, error, alert)\n  - Tables for displaying data\n  - Testing strategies for console commands\n  - Fallback configuration for unsupported environments\n\nUse `view` to read the reference file when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n\nStart with basic prompts:\n1. Use `text()` for simple input\n2. Add `required: true` for mandatory fields\n3. Try `confirm()` for yes/no questions\n4. Use `select()` for predefined choices\n\nExample beginner command:\n```php\n$name = text('What is your name?', required: true);\n$confirmed = confirm('Is this correct?');\nif ($confirmed) {\n    $this->info(\"Hello, {$name}!\");\n}\n```\n\n### For Intermediate Users\n\nCombine multiple prompts and add validation:\n1. Use the `form()` API for multi-step input\n2. Add custom validation with closures\n3. Use `search()` for database queries\n4. Implement progress bars for long operations\n\nExample intermediate command:\n```php\n$responses = form()\n    ->text('Name', required: true, name: 'name')\n    ->select('Role', options: ['Member', 'Admin'], name: 'role')\n    ->confirm('Create user?')\n    ->submit();\n\nif ($responses) {\n    progress(\n        label: 'Creating user',\n        steps: 5,\n        callback: fn () => sleep(1)\n    );\n}\n```\n\n### For Advanced Users\n\nLeverage advanced features:\n1. Dynamic form fields based on previous responses\n2. Complex validation with Laravel validation rules\n3. Custom searchable prompts with database integration\n4. Transformation functions for data normalization\n5. Testing strategies for command prompts\n\nExample advanced command:\n```php\n$responses = form()\n    ->text('Email', validate: ['email' => 'required|email|unique:users'], name: 'email')\n    ->add(function ($responses) {\n        return search(\n            label: 'Select manager',\n            options: fn ($value) => User::where('email', 'like', \"%{$value}%\")\n                ->where('email', '!=', $responses['email'])\n                ->pluck('name', 'id')\n                ->all()\n        );\n    }, name: 'manager_id')\n    ->multiselect(\n        label: 'Permissions',\n        options: Permission::pluck('name', 'id'),\n        validate: fn ($values) => count($values) === 0 ? 'Select at least one permission.' : null,\n        name: 'permissions'\n    )\n    ->submit();\n```\n\n### Navigation Tips\n\n- **Arrow keys** or **j/k** - Navigate options in select/multiselect\n- **Space** - Select/deselect in multiselect\n- **Enter** - Confirm selection or submit input\n- **CTRL + U** - Go back to previous prompt (in forms)\n- **Type to search** - In search/multisearch prompts\n- **Tab** - Auto-complete in suggest prompts\n\n## Testing\n\nTest commands with prompts using Laravel's built-in assertions:\n\n```php\nuse function Pest\\Laravel\\artisan;\n\ntest('user creation command', function () {\n    artisan('users:create')\n        ->expectsQuestion('What is your name?', 'Taylor Otwell')\n        ->expectsQuestion('What is your email?', '[email protected]')\n        ->expectsConfirmation('Create this user?', 'yes')\n        ->expectsPromptsInfo('User created successfully!')\n        ->assertExitCode(0);\n});\n\ntest('displays warnings and errors', function () {\n    artisan('report:generate')\n        ->expectsPromptsWarning('This action cannot be undone')\n        ->expectsPromptsError('Something went wrong')\n        ->expectsPromptsTable(\n            headers: ['Name', 'Email'],\n            rows: [\n                ['Taylor Otwell', '[email protected]'],\n                ['Jason Beggs', '[email protected]'],\n            ]\n        )\n        ->assertExitCode(0);\n});\n```\n\n## Best Practices\n\n### Design Guidelines\n- Keep labels concise (under 74 characters for 80-column terminals)\n- Use `hint` parameter for additional context\n- Set appropriate `default` values when sensible\n- Configure `scroll` for lists with many options (default: 5)\n\n### Validation Strategy\n- Use `required: true` for mandatory fields\n- Apply Laravel validation rules for standard checks (email, min/max, etc.)\n- Use closures for complex business logic validation\n- Provide clear, actionable error messages\n\n### User Experience\n- Add placeholders to show expected input format\n- Use `pause()` before destructive operations\n- Show progress bars for operations taking >2 seconds\n- Display informational messages after actions complete\n- Group related prompts in forms for better flow\n\n### Performance\n- Use `search()` callbacks with length checks to avoid expensive queries:\n  ```php\n  options: fn (string $value) => strlen($value) > 0\n      ? User::where('name', 'like', \"%{$value}%\")->pluck('name', 'id')->all()\n      : []\n  ```\n- Limit database results with pagination or top-N queries\n- Cache frequently-accessed option lists\n- Use `spin()` for HTTP requests and long operations\n\n## Common Patterns\n\n### User Registration Flow\n```php\n$responses = form()\n    ->text('Name', required: true, name: 'name')\n    ->text('Email', validate: ['email' => 'required|email|unique:users'], name: 'email')\n    ->password('Password', validate: ['password' => 'required|min:8'], name: 'password')\n    ->submit();\n```\n\n### Confirmation Before Destructive Action\n```php\n$confirmed = confirm(\n    label: 'Are you sure you want to delete all users?',\n    default: false,\n    hint: 'This action cannot be undone.'\n);\n\nif (! $confirmed) {\n    $this->info('Operation cancelled.');\n    return;\n}\n```\n\n### Dynamic Multi-step Form\n```php\n$responses = form()\n    ->select('User type', options: ['Regular', 'Admin'], name: 'type')\n    ->add(function ($responses) {\n        if ($responses['type'] === 'Admin') {\n            return password('Admin password', required: true);\n        }\n    }, name: 'admin_password')\n    ->submit();\n```\n\n### Batch Processing with Progress\n```php\n$items = Item::all();\n\n$results = progress(\n    label: 'Processing items',\n    steps: $items,\n    callback: function ($item, $progress) {\n        $progress->hint(\"Processing: {$item->name}\");\n        return $this->process($item);\n    }\n);\n```\n\n## Resources\n\n### Official Documentation\n- Laravel Prompts Documentation: https://laravel.com/docs/12.x/prompts\n- Laravel Console Testing: https://laravel.com/docs/12.x/console-tests\n\n### Platform Support\n- **Supported**: macOS, Linux, Windows with WSL\n- **Fallback**: Configure fallback behavior for unsupported environments\n\n## Notes\n\n- Laravel Prompts is pre-installed in Laravel framework\n- Supports Laravel validation rules for easy integration\n- Uses terminal control codes for interactive UI\n- All prompts return values that can be used immediately\n- Forms support revisiting previous prompts with CTRL + U\n- Validation runs on every input change for immediate feedback\n- Progress bars can be manually controlled or automated\n\n## Updating\n\nThis skill was generated from the official Laravel Prompts documentation. To refresh with updated information, re-scrape the Laravel documentation site.\n",
        "laravel/SKILL.md": "---\nname: laravel\ndescription: Laravel v12 - The PHP Framework For Web Artisans\n---\n\n# Laravel Skill\n\nComprehensive assistance with Laravel 12.x development, including routing, Eloquent ORM, migrations, authentication, API development, and modern PHP patterns.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Building Laravel applications or APIs\n- Working with Eloquent models, relationships, and queries\n- Setting up authentication, authorization, or API tokens\n- Creating database migrations, seeders, or factories\n- Implementing middleware, service providers, or events\n- Using Laravel's built-in features (queues, cache, validation, etc.)\n- Troubleshooting Laravel errors or performance issues\n- Following Laravel best practices and conventions\n- Implementing RESTful APIs with Laravel Sanctum or Passport\n- Working with Laravel Mix, Vite, or frontend assets\n\n## Quick Reference\n\n### Basic Routing\n\n```php\n// Basic routes\nRoute::get('/users', [UserController::class, 'index']);\nRoute::post('/users', [UserController::class, 'store']);\n\n// Route parameters\nRoute::get('/users/{id}', function ($id) {\n    return User::find($id);\n});\n\n// Named routes\nRoute::get('/profile', ProfileController::class)->name('profile');\n\n// Route groups with middleware\nRoute::middleware(['auth'])->group(function () {\n    Route::get('/dashboard', [DashboardController::class, 'index']);\n    Route::resource('posts', PostController::class);\n});\n```\n\n### Eloquent Model Basics\n\n```php\n// Define a model with relationships\nnamespace App\\Models;\n\nuse Illuminate\\Database\\Eloquent\\Model;\nuse Illuminate\\Database\\Eloquent\\Relations\\HasMany;\nuse Illuminate\\Database\\Eloquent\\Relations\\BelongsTo;\n\nclass Post extends Model\n{\n    protected $fillable = ['title', 'content', 'user_id'];\n\n    protected $casts = [\n        'published_at' => 'datetime',\n    ];\n\n    public function user(): BelongsTo\n    {\n        return $this->belongsTo(User::class);\n    }\n\n    public function comments(): HasMany\n    {\n        return $this->hasMany(Comment::class);\n    }\n}\n```\n\n### Database Migrations\n\n```php\n// Create a migration\nuse Illuminate\\Database\\Migrations\\Migration;\nuse Illuminate\\Database\\Schema\\Blueprint;\nuse Illuminate\\Support\\Facades\\Schema;\n\nreturn new class extends Migration\n{\n    public function up(): void\n    {\n        Schema::create('posts', function (Blueprint $table) {\n            $table->id();\n            $table->foreignId('user_id')->constrained()->cascadeOnDelete();\n            $table->string('title');\n            $table->text('content');\n            $table->timestamp('published_at')->nullable();\n            $table->timestamps();\n\n            $table->index(['user_id', 'published_at']);\n        });\n    }\n\n    public function down(): void\n    {\n        Schema::dropIfExists('posts');\n    }\n};\n```\n\n### Form Validation\n\n```php\n// Controller validation\npublic function store(Request $request)\n{\n    $validated = $request->validate([\n        'title' => 'required|max:255',\n        'content' => 'required',\n        'email' => 'required|email|unique:users',\n        'tags' => 'array|min:1',\n        'tags.*' => 'string|max:50',\n    ]);\n\n    return Post::create($validated);\n}\n\n// Form Request validation\nnamespace App\\Http\\Requests;\n\nuse Illuminate\\Foundation\\Http\\FormRequest;\n\nclass StorePostRequest extends FormRequest\n{\n    public function rules(): array\n    {\n        return [\n            'title' => 'required|max:255',\n            'content' => 'required|min:100',\n        ];\n    }\n}\n```\n\n### Eloquent Query Builder\n\n```php\n// Common query patterns\n// Eager loading to avoid N+1 queries\n$posts = Post::with(['user', 'comments'])\n    ->where('published_at', '<=', now())\n    ->orderBy('published_at', 'desc')\n    ->paginate(15);\n\n// Conditional queries\n$query = Post::query();\n\nif ($request->has('search')) {\n    $query->where('title', 'like', \"%{$request->search}%\");\n}\n\nif ($request->has('author')) {\n    $query->whereHas('user', function ($q) use ($request) {\n        $q->where('name', $request->author);\n    });\n}\n\n$posts = $query->get();\n```\n\n### API Resource Controllers\n\n```php\nnamespace App\\Http\\Controllers\\Api;\n\nuse App\\Models\\Post;\nuse App\\Http\\Resources\\PostResource;\nuse Illuminate\\Http\\Request;\n\nclass PostController extends Controller\n{\n    public function index()\n    {\n        return PostResource::collection(\n            Post::with('user')->latest()->paginate()\n        );\n    }\n\n    public function store(Request $request)\n    {\n        $post = Post::create($request->validated());\n\n        return new PostResource($post);\n    }\n\n    public function show(Post $post)\n    {\n        return new PostResource($post->load('user', 'comments'));\n    }\n\n    public function update(Request $request, Post $post)\n    {\n        $post->update($request->validated());\n\n        return new PostResource($post);\n    }\n}\n```\n\n### API Resources (Transformers)\n\n```php\nnamespace App\\Http\\Resources;\n\nuse Illuminate\\Http\\Resources\\Json\\JsonResource;\n\nclass PostResource extends JsonResource\n{\n    public function toArray($request): array\n    {\n        return [\n            'id' => $this->id,\n            'title' => $this->title,\n            'slug' => $this->slug,\n            'excerpt' => $this->excerpt,\n            'content' => $this->when($request->routeIs('posts.show'), $this->content),\n            'author' => new UserResource($this->whenLoaded('user')),\n            'comments_count' => $this->when($this->comments_count, $this->comments_count),\n            'published_at' => $this->published_at?->toISOString(),\n            'created_at' => $this->created_at->toISOString(),\n        ];\n    }\n}\n```\n\n### Authentication with Sanctum\n\n```php\n// API token authentication setup\n// In config/sanctum.php - configure stateful domains\n\n// Issue tokens\nuse Laravel\\Sanctum\\HasApiTokens;\n\nclass User extends Authenticatable\n{\n    use HasApiTokens;\n}\n\n// Login endpoint\npublic function login(Request $request)\n{\n    $credentials = $request->validate([\n        'email' => 'required|email',\n        'password' => 'required',\n    ]);\n\n    if (!Auth::attempt($credentials)) {\n        return response()->json(['message' => 'Invalid credentials'], 401);\n    }\n\n    $token = $request->user()->createToken('api-token')->plainTextToken;\n\n    return response()->json(['token' => $token]);\n}\n\n// Protect routes\nRoute::middleware('auth:sanctum')->group(function () {\n    Route::get('/user', fn(Request $r) => $r->user());\n});\n```\n\n### Jobs and Queues\n\n```php\n// Create a job\nnamespace App\\Jobs;\n\nuse Illuminate\\Bus\\Queueable;\nuse Illuminate\\Contracts\\Queue\\ShouldQueue;\nuse Illuminate\\Queue\\InteractsWithQueue;\n\nclass ProcessVideo implements ShouldQueue\n{\n    use InteractsWithQueue, Queueable;\n\n    public function __construct(\n        public Video $video\n    ) {}\n\n    public function handle(): void\n    {\n        // Process the video\n        $this->video->process();\n    }\n}\n\n// Dispatch jobs\nProcessVideo::dispatch($video);\nProcessVideo::dispatch($video)->onQueue('videos')->delay(now()->addMinutes(5));\n```\n\n### Service Container and Dependency Injection\n\n```php\n// Bind services in AppServiceProvider\nuse App\\Services\\PaymentService;\n\npublic function register(): void\n{\n    $this->app->singleton(PaymentService::class, function ($app) {\n        return new PaymentService(\n            config('services.stripe.secret')\n        );\n    });\n}\n\n// Use dependency injection in controllers\npublic function __construct(\n    protected PaymentService $payment\n) {}\n\npublic function charge(Request $request)\n{\n    return $this->payment->charge(\n        $request->user(),\n        $request->amount\n    );\n}\n```\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Laravel 12.x installation guide and core documentation\n\nUse the reference files for detailed information about:\n- Installation and configuration\n- Framework architecture and concepts\n- Advanced features and packages\n- Deployment and optimization\n\n## Key Concepts\n\n### MVC Architecture\nLaravel follows the Model-View-Controller pattern:\n- **Models**: Eloquent ORM classes representing database tables\n- **Views**: Blade templates for rendering HTML\n- **Controllers**: Handle HTTP requests and return responses\n\n### Eloquent ORM\nLaravel's powerful database abstraction layer:\n- **Active Record pattern**: Each model instance represents a database row\n- **Relationships**: belongsTo, hasMany, belongsToMany, morphMany, etc.\n- **Query Builder**: Fluent interface for building SQL queries\n- **Eager Loading**: Prevent N+1 query problems with `with()`\n\n### Routing\nDefine application endpoints:\n- **Route methods**: get, post, put, patch, delete\n- **Route parameters**: Required `{id}` and optional `{id?}`\n- **Route groups**: Share middleware, prefixes, namespaces\n- **Resource routes**: Auto-generate RESTful routes\n\n### Middleware\nFilter HTTP requests:\n- **Built-in**: auth, throttle, verified, signed\n- **Custom**: Create your own request/response filters\n- **Global**: Apply to all routes\n- **Route-specific**: Apply to specific routes or groups\n\n### Service Container\nLaravel's dependency injection container:\n- **Automatic resolution**: Type-hint dependencies in constructors\n- **Binding**: Register class implementations\n- **Singletons**: Share single instance across requests\n\n### Artisan Commands\nLaravel's CLI tool:\n```bash\nphp artisan make:model Post -mcr  # Create model, migration, controller, resource\nphp artisan migrate               # Run migrations\nphp artisan db:seed              # Seed database\nphp artisan queue:work           # Process queue jobs\nphp artisan optimize:clear       # Clear all caches\n```\n\n## Working with This Skill\n\n### For Beginners\nStart with:\n1. **Installation**: Set up Laravel using Composer\n2. **Routing**: Learn basic route definitions in `routes/web.php`\n3. **Controllers**: Create controllers with `php artisan make:controller`\n4. **Models**: Understand Eloquent basics and relationships\n5. **Migrations**: Define database schema with migrations\n6. **Blade Templates**: Create views with Laravel's templating engine\n\n### For Intermediate Users\nFocus on:\n- **Form Requests**: Validation and authorization in dedicated classes\n- **API Resources**: Transform models for JSON responses\n- **Authentication**: Implement with Laravel Breeze or Sanctum\n- **Relationships**: Master eager loading and complex relationships\n- **Queues**: Offload time-consuming tasks to background jobs\n- **Events & Listeners**: Decouple application logic\n\n### For Advanced Users\nExplore:\n- **Service Providers**: Register application services\n- **Custom Middleware**: Create reusable request filters\n- **Package Development**: Build reusable Laravel packages\n- **Testing**: Write feature and unit tests with PHPUnit\n- **Performance**: Optimize queries, caching, and response times\n- **Deployment**: CI/CD pipelines and production optimization\n\n### Navigation Tips\n- Check **Quick Reference** for common code patterns\n- Reference the official docs at https://laravel.com/docs/12.x\n- Use `php artisan route:list` to view all registered routes\n- Use `php artisan tinker` for interactive debugging\n- Enable query logging to debug database performance\n\n## Common Patterns\n\n### Repository Pattern\n```php\ninterface PostRepositoryInterface\n{\n    public function all();\n    public function find(int $id);\n    public function create(array $data);\n}\n\nclass PostRepository implements PostRepositoryInterface\n{\n    public function all()\n    {\n        return Post::with('user')->latest()->get();\n    }\n\n    public function find(int $id)\n    {\n        return Post::with('user', 'comments')->findOrFail($id);\n    }\n}\n```\n\n### Action Classes (Single Responsibility)\n```php\nclass CreatePost\n{\n    public function execute(array $data): Post\n    {\n        return DB::transaction(function () use ($data) {\n            $post = Post::create($data);\n            $post->tags()->attach($data['tag_ids']);\n            event(new PostCreated($post));\n            return $post;\n        });\n    }\n}\n```\n\n### Query Scopes\n```php\nclass Post extends Model\n{\n    public function scopePublished($query)\n    {\n        return $query->where('published_at', '<=', now());\n    }\n\n    public function scopeByAuthor($query, User $user)\n    {\n        return $query->where('user_id', $user->id);\n    }\n}\n\n// Usage\nPost::published()->byAuthor($user)->get();\n```\n\n## Resources\n\n### Official Documentation\n- Laravel Docs: https://laravel.com/docs/12.x\n- API Reference: https://laravel.com/api/12.x\n- Laracasts: https://laracasts.com (video tutorials)\n\n### Community\n- Laravel News: https://laravel-news.com\n- Laravel Forums: https://laracasts.com/discuss\n- GitHub: https://github.com/laravel/laravel\n\n### Tools\n- Laravel Telescope: Debugging and monitoring\n- Laravel Horizon: Queue monitoring\n- Laravel Debugbar: Development debugging\n- Laravel IDE Helper: IDE autocompletion\n\n## Best Practices\n\n1. **Use Form Requests**: Separate validation logic from controllers\n2. **Eager Load Relationships**: Avoid N+1 query problems\n3. **Use Resource Controllers**: Follow RESTful conventions\n4. **Type Hints**: Leverage PHP type declarations for better IDE support\n5. **Database Transactions**: Wrap related database operations\n6. **Queue Jobs**: Offload slow operations to background workers\n7. **Cache Queries**: Cache expensive database queries\n8. **API Resources**: Transform data consistently for APIs\n9. **Events**: Decouple application logic with events and listeners\n10. **Tests**: Write tests for critical application logic\n\n## Notes\n\n- Laravel 12.x requires PHP 8.2 or higher\n- Uses Composer for dependency management\n- Includes Vite for asset compilation (replaces Laravel Mix)\n- Supports multiple database systems (MySQL, PostgreSQL, SQLite, SQL Server)\n- Built-in support for queues, cache, sessions, and file storage\n- Excellent ecosystem with first-party packages (Sanctum, Horizon, Telescope, etc.)\n",
        "linode-api/SKILL.md": "---\nname: linode-api\ndescription: Linode API Documentation\n---\n\n# Linode-Api Skill\n\nComprehensive assistance with the Linode API - a RESTful API for programmatically managing Linode cloud infrastructure including compute instances, networking, storage, domains, and billing.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Working with Linode cloud infrastructure programmatically\n- Creating, managing, or monitoring Linode instances (virtual machines)\n- Automating Linode infrastructure with API calls\n- Implementing Linode OAuth applications\n- Managing Linode account, billing, or payment methods\n- Working with Linode networking (DNS, NodeBalancers, VLANs)\n- Debugging Linode API authentication or request issues\n- Implementing infrastructure as code with Linode\n- Integrating Linode services into applications\n- Managing Linode Kubernetes Engine (LKE) clusters\n\n## Quick Reference\n\n### Authentication with Personal Access Token\n\n```python\nfrom linode import LinodeClient\n\n# Initialize client with your personal access token\ntoken = \"your-personal-access-token\"\nclient = LinodeClient(token)\n```\n\n**Getting a token:** Log into cloud.linode.com ‚Üí Profile ‚Üí \"Create a Personal Access Token\"\n\n### List All Linode Instances\n\n```python\n# Retrieve all Linodes on your account\nmy_linodes = client.linode.get_instances()\n\n# Iterate and display instance labels\nfor linode in my_linodes:\n    print(linode.label)\n```\n\n### Create a New Linode Instance (Python)\n\n```python\n# Get available regions\navailable_regions = client.get_regions()\nchosen_region = available_regions[0]\n\n# Create instance with region, type, and image\nnew_linode, password = client.linode.create_instance(\n    chosen_region,\n    'g5-standard-4',\n    image='linode/debian9'\n)\n\n# Display SSH connection info\nprint(f\"ssh root@{new_linode.ipv4[0]} - {password}\")\n```\n\n### Create a Linode Instance (cURL)\n\n```bash\ncurl -X POST https://api.linode.com/v4/linode/instances \\\n  -H \"Authorization: Bearer <your-token>\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"type\": \"g5-standard-2\",\n    \"region\": \"us-east\",\n    \"image\": \"linode/debian12\",\n    \"root_pass\": \"secure_password_here\",\n    \"label\": \"prod-web-1\"\n  }'\n```\n\n### Get Account Information\n\n```bash\ncurl https://api.linode.com/v4/account \\\n  -H \"Authorization: Bearer <your-token>\"\n```\n\n### List Invoices\n\n```bash\ncurl https://api.linode.com/v4/account/invoices \\\n  -H \"Authorization: Bearer <your-token>\"\n```\n\n### Check Regional Service Availability\n\n```bash\ncurl https://api.linode.com/v4/account/availability \\\n  -H \"Authorization: Bearer <your-token>\"\n```\n\n### Install Python Library\n\n```bash\n# Install the official Python library\npip install linode-api\n\n# Or from source\ngit clone git@github.com:Linode/python-linode-api\ncd python-linode-api\npython setup.py install\n```\n\n### Basic Python Setup Pattern\n\n```python\nfrom linode import LinodeClient\n\n# Initialize the client\ntoken = \"your-personal-access-token\"\nclient = LinodeClient(token)\n\n# Now you can access resources\nregions = client.get_regions()\ninstances = client.linode.get_instances()\n```\n\n### Authentication Header Format (REST)\n\nAll API requests to non-public resources must include an Authorization header:\n\n```\nAuthorization: Bearer <your-personal-access-token>\n```\n\n## Key Concepts\n\n### API Versions\n- **v4**: Current stable API version (base URL: `https://api.linode.com/v4`)\n- **v4beta**: Beta features and endpoints (use with caution in production)\n\n### Authentication\nThe Linode API uses **Personal Access Tokens** (PATs) for authentication. Tokens can have different permission scopes (read/write) for different resource types. Always keep tokens secure and never commit them to version control.\n\n### Pagination\nAPI responses use envelope-based pagination with metadata:\n- `page`: Current page number\n- `pages`: Total number of pages\n- `results`: Number of results per page\n\n### Filtering\nThe API supports advanced filtering via the `X-Filter` header with operators:\n- `+gt`: Greater than\n- `+lte`: Less than or equal\n- `+or`: Logical OR\n- Complex nested conditions supported\n\n### Instance Types\nCommon Linode instance types:\n- **Shared CPU**: `g5-standard-1`, `g5-standard-2`, etc. (cost-effective for general workloads)\n- **Dedicated CPU**: `g6-dedicated-2`, etc. (guaranteed CPU resources)\n- **High Memory**: `g6-highmem-1`, etc. (memory-intensive applications)\n\n### Regions\nLinode has global data centers. Common regions:\n- `us-east`: Newark, NJ\n- `us-west`: Fremont, CA\n- `eu-west`: London, UK\n- `ap-south`: Singapore\n- Many more available via `GET /regions` endpoint\n\n### Images\nSupported operating system images:\n- `linode/debian12`: Debian 12\n- `linode/ubuntu22.04`: Ubuntu 22.04 LTS\n- `linode/centos-stream9`: CentOS Stream 9\n- Custom images also supported\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete OpenAPI specification reference with all endpoints, request/response schemas, and authentication details\n\nUse `view references/api.md` when you need:\n- Detailed endpoint specifications\n- Request/response schema definitions\n- Available HTTP methods for each endpoint\n- Field validation rules and constraints\n- OAuth client configuration details\n- Beta feature documentation\n\n## Working with This Skill\n\n### For Beginners\n\n1. **Start with authentication**: Generate a Personal Access Token from cloud.linode.com\n2. **Test basic endpoints**: Try `GET /account` to verify your token works\n3. **Use the Python library**: It's easier than raw REST API calls for getting started\n4. **Start small**: List existing resources before creating new ones\n5. **Check regional availability**: Ensure services are available in your chosen region\n\n### For API Integration\n\n1. **Review authentication patterns** in the Quick Reference section\n2. **Use the Python client library** for rapid development\n3. **Implement proper error handling** for API rate limits and validation errors\n4. **Store tokens securely** using environment variables or secret management\n5. **Test in non-production** accounts first\n\n### For Infrastructure Automation\n\n1. **Explore the full API specification** in references/api.md\n2. **Use filtering and pagination** for large resource queries\n3. **Implement idempotent operations** where possible\n4. **Monitor API usage** to stay within rate limits\n5. **Use OAuth** for multi-user applications\n\n### Common Workflows\n\n**Basic Instance Management:**\n1. List available regions ‚Üí Choose region\n2. List available instance types ‚Üí Choose type\n3. List available images ‚Üí Choose image\n4. Create instance with chosen parameters\n5. Monitor instance status until \"running\"\n6. Retrieve IP address and connect\n\n**Account Management:**\n1. Get account information\n2. List invoices and payment history\n3. Check service availability by region\n4. Manage OAuth clients for applications\n5. View notifications and events\n\n## Resources\n\n### Official Documentation\n- **API Reference**: https://www.linode.com/docs/api/\n- **Getting Started Guide**: https://www.linode.com/docs/products/tools/api/get-started/\n- **Python Library Docs**: https://python-linode-api.readthedocs.io/\n\n### Code Libraries\n- **Python**: `linode-api` (official)\n- **JavaScript/Node.js**: Available via npm\n- **Go, PHP, Ruby**: Community libraries available\n\n### references/\nThe `references/api.md` file contains:\n- Complete OpenAPI specification (JSON format)\n- All available endpoints organized by resource type\n- Detailed request/response schemas\n- Authentication requirements per endpoint\n- Field validation rules and data types\n- Pagination and filtering documentation\n- Beta feature flags\n\n## Best Practices\n\n### Security\n- Never hardcode API tokens in your code\n- Use environment variables: `token = os.getenv('LINODE_API_TOKEN')`\n- Set appropriate token scopes (read-only when possible)\n- Rotate tokens regularly\n- Revoke unused tokens\n\n### Error Handling\n- Handle HTTP 429 (rate limit) with exponential backoff\n- Validate input before making API calls\n- Check for field validation errors in 400 responses\n- Implement retry logic for transient failures\n\n### Performance\n- Use pagination for large result sets\n- Implement caching for infrequently-changing data (regions, types)\n- Use batch operations when available\n- Filter results server-side using X-Filter header\n\n### Code Organization\n- Create wrapper functions for common operations\n- Separate configuration from application code\n- Use type hints with the Python library\n- Document token permission requirements\n\n## Notes\n\n- This skill was automatically generated from the official Linode API OpenAPI specification\n- The API uses standard REST conventions (GET, POST, PUT, DELETE)\n- All non-public endpoints require authentication via Bearer token\n- Rate limits apply - implement appropriate backoff strategies\n- Beta endpoints (v4beta) may change without notice\n- The Python library handles pagination and authentication automatically\n\n## Common Operations Reference\n\n### Compute Instances\n- List instances: `GET /linode/instances`\n- Create instance: `POST /linode/instances`\n- Get instance: `GET /linode/instances/{linodeId}`\n- Update instance: `PUT /linode/instances/{linodeId}`\n- Delete instance: `DELETE /linode/instances/{linodeId}`\n- Reboot instance: `POST /linode/instances/{linodeId}/reboot`\n\n### Account & Billing\n- Get account: `GET /account`\n- List invoices: `GET /account/invoices`\n- List payments: `GET /account/payments`\n- Get settings: `GET /account/settings`\n\n### Networking\n- List NodeBalancers: `GET /nodebalancers`\n- List Firewalls: `GET /networking/firewalls`\n- List VLANs: `GET /networking/vlans`\n\n### Storage\n- List volumes: `GET /volumes`\n- Create volume: `POST /volumes`\n- Attach volume: `POST /volumes/{volumeId}/attach`\n\n## Troubleshooting\n\n### Authentication Errors\n- **401 Unauthorized**: Invalid or expired token\n- **403 Forbidden**: Token lacks required permissions\n- **Solution**: Verify token in cloud.linode.com, check scopes\n\n### Rate Limiting\n- **429 Too Many Requests**: Rate limit exceeded\n- **Solution**: Implement exponential backoff, reduce request frequency\n\n### Validation Errors\n- **400 Bad Request**: Invalid input data\n- **Solution**: Check error message for specific field issues, consult API docs\n\n### Installation Issues (Python)\n- **Namespace conflicts**: Older libraries use 'linode' namespace\n- **Solution**: Use virtualenv to isolate dependencies\n\n## Updating\n\nThis skill is based on the OpenAPI specification from the Linode API GitHub repository. To refresh with the latest API changes:\n1. The specification is automatically pulled from: https://github.com/linode/linode-api-docs\n2. Re-run the skill generation process to capture new endpoints and changes\n3. Review changelog for breaking changes before updating production code\n",
        "linode-cli/SKILL.md": "---\nname: linode-cli\ndescription: Linode CLI Documentation\n---\n\n# Linode CLI Skill\n\nThe official command-line interface for Linode/Akamai cloud infrastructure. Provides easy access to Linode API endpoints directly from the terminal for managing compute instances, Kubernetes clusters, volumes, networking, DNS, and more.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- **Managing Linode compute instances** (creating, listing, updating, deleting Linodes)\n- **Working with Linode Kubernetes Engine (LKE)** clusters and node pools\n- **Configuring DNS domains** and records through Linode's DNS Manager\n- **Managing Block Storage volumes** and volume attachments\n- **Setting up NodeBalancers** and networking infrastructure\n- **Automating Linode operations** in scripts or CI/CD pipelines\n- **Learning Linode CLI commands** and API interactions\n- **Debugging Linode CLI issues** or authentication problems\n- **Formatting CLI output** (JSON, tables, custom fields)\n\n## Key Concepts\n\n### CLI Architecture\n- **Auto-generated from OpenAPI**: The CLI is automatically generated from Linode's OpenAPI specification, providing direct access to all API endpoints\n- **Python-based**: Built with Python 3.10+, installed via pip\n- **Command structure**: `linode-cli <resource> <action> [options]`\n- **Authentication**: Uses API tokens stored in configuration or environment variables\n\n### Core Resources\n- **linodes**: Compute instances (virtual machines)\n- **lke**: Linode Kubernetes Engine clusters\n- **domains**: DNS domain management\n- **volumes**: Block Storage volumes\n- **nodebalancers**: Load balancers\n- **regions**: Available data center locations\n- **images**: OS images and custom images\n\n### Output Formatting\n- **Default**: Organized tables with key information\n- **--json**: Raw JSON output for scripting\n- **--pretty**: Formatted JSON with indentation\n- **--format**: Custom field selection\n- **--all**: Show all available fields\n\n## Quick Reference\n\n### Installation and Setup\n\n```bash\n# Install via pip\npip3 install linode-cli\n\n# First-time configuration (interactive)\nlinode-cli configure\n\n# Set API token via environment\nexport LINODE_CLI_TOKEN=your_api_token_here\n```\n\n### Getting Help\n\n```bash\n# View all available commands\nlinode-cli --help\n\n# View help for specific resource\nlinode-cli linodes --help\n\n# View help for specific action\nlinode-cli linodes create --help\n\n# List all available regions\nlinode-cli regions list\n\n# List all available images\nlinode-cli images list\n```\n\n### Listing Resources\n\n```bash\n# List all Linodes on your account\nlinode-cli linodes list\n\n# List domains\nlinode-cli domains list\n\n# List volumes\nlinode-cli volumes list\n\n# List Kubernetes clusters\nlinode-cli lke clusters-list\n\n# Format output with custom fields\nlinode-cli linodes list --format \"id,label,status,region\"\n\n# Output as JSON\nlinode-cli linodes list --json\n\n# Output all available fields\nlinode-cli linodes list --all\n```\n\n### Creating Compute Instances\n\n```bash\n# Create a basic Linode (uses defaults from config)\nlinode-cli linodes create \\\n  --type g6-standard-2 \\\n  --region us-east \\\n  --image linode/debian11 \\\n  --label my-server \\\n  --root_pass \"SecurePassword123!\"\n\n# Create with specific configuration\nlinode-cli linodes create \\\n  --type g6-standard-4 \\\n  --region us-central \\\n  --image linode/ubuntu22.04 \\\n  --label production-web \\\n  --root_pass \"MySecurePass!\" \\\n  --group webservers\n\n# Create with authorized SSH keys\nlinode-cli linodes create \\\n  --type g6-standard-2 \\\n  --region us-west \\\n  --image linode/debian11 \\\n  --label secure-server \\\n  --root_pass \"Password123!\" \\\n  --authorized_keys \"ssh-rsa AAAAB3Nz...\"\n```\n\n### Managing Kubernetes (LKE)\n\n```bash\n# Create a Kubernetes cluster with multiple node pools\nlinode-cli lke cluster-create \\\n  --label my-k8s-cluster \\\n  --region us-central \\\n  --k8s_version 1.28 \\\n  --node_pools.type g6-standard-4 --node_pools.count 3 \\\n  --node_pools.type g6-standard-8 --node_pools.count 2 \\\n  --tags production\n\n# List all clusters\nlinode-cli lke clusters-list\n\n# Update cluster configuration\nlinode-cli lke cluster-update $CLUSTER_ID \\\n  --label renamed-cluster \\\n  --tags production \\\n  --tags monitoring \\\n  --tags backup\n\n# Update node pool size\nlinode-cli lke pool-update $CLUSTER_ID $POOL_ID \\\n  --count 5\n\n# Delete a cluster\nlinode-cli lke cluster-delete $CLUSTER_ID\n```\n\n### DNS Management\n\n```bash\n# Create a domain\nlinode-cli domains create \\\n  --type master \\\n  --domain example.com \\\n  --soa_email admin@example.com\n\n# List domains\nlinode-cli domains list\n\n# Create DNS record\nlinode-cli domains records-create $DOMAIN_ID \\\n  --type A \\\n  --name www \\\n  --target 192.0.2.1\n\n# Delete a domain\nlinode-cli domains delete $DOMAIN_ID\n```\n\n### Volume Management\n\n```bash\n# Create a Block Storage volume\nlinode-cli volumes create \\\n  --label my-volume \\\n  --size 100 \\\n  --region us-east\n\n# List volumes\nlinode-cli volumes list\n\n# Attach volume to Linode\nlinode-cli volumes attach $VOLUME_ID \\\n  --linode_id $LINODE_ID\n\n# Detach volume\nlinode-cli volumes detach $VOLUME_ID\n```\n\n### Advanced Usage\n\n```bash\n# Filtering output with jq (requires jq installed)\nlinode-cli linodes list --json | jq '.[] | select(.status==\"running\")'\n\n# Using variables in scripts\nLINODE_ID=$(linode-cli linodes list --json | jq -r '.[0].id')\necho \"First Linode ID: $LINODE_ID\"\n\n# Bulk operations example\nfor region in us-east us-west eu-central; do\n  linode-cli linodes create \\\n    --type g6-nanode-1 \\\n    --region $region \\\n    --image linode/alpine3.18 \\\n    --label \"test-$region\" \\\n    --root_pass \"TempPassword123!\"\ndone\n```\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Links to official Linode CLI Wiki on GitHub with additional documentation, guides, and community resources\n\nUse `view` to read specific reference files when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n1. **Start with installation**: Run `pip3 install linode-cli` and configure with `linode-cli configure`\n2. **Learn the basics**: Use `--help` flag extensively to discover available commands\n3. **Practice listing**: Start with simple list commands like `linode-cli linodes list`\n4. **Test in safe mode**: Use small, inexpensive instance types (g6-nanode-1) for testing\n5. **Read the output**: Default table output is designed to be human-readable\n\n### For Intermediate Users\n1. **Master output formatting**: Learn `--json`, `--format`, and `--all` flags for scripting\n2. **Automate common tasks**: Create bash scripts for repetitive operations\n3. **Combine with jq**: Use jq for powerful JSON filtering and processing\n4. **Manage multiple resources**: Create infrastructure as code with shell scripts\n5. **Use environment variables**: Set `LINODE_CLI_TOKEN` for non-interactive automation\n\n### For Advanced Users\n1. **CI/CD integration**: Incorporate linode-cli into deployment pipelines\n2. **Infrastructure automation**: Build complete infrastructure provisioning scripts\n3. **API exploration**: Use the CLI to understand Linode's API structure\n4. **Custom tooling**: Wrap linode-cli in your own management tools\n5. **OpenAPI access**: Contribute to the OpenAPI spec for new features\n\n### Navigation Tips\n- **Discover resources**: Use `linode-cli --help` to see all available resource types\n- **Action discovery**: Each resource has different actions (list, create, update, delete, etc.)\n- **Parameter help**: Use `--help` on any action to see required and optional parameters\n- **JSON inspection**: Use `--json` to see all available fields for any resource\n- **Region planning**: Run `linode-cli regions list` before creating resources\n\n## Common Patterns\n\n### Authentication Setup\n```bash\n# Method 1: Interactive configuration\nlinode-cli configure\n\n# Method 2: Environment variable\nexport LINODE_CLI_TOKEN=your_token_here\n\n# Method 3: Config file (~/.config/linode-cli)\n[DEFAULT]\ntoken = your_token_here\nregion = us-east\ntype = g6-standard-2\nimage = linode/ubuntu22.04\n```\n\n### Instance Lifecycle\n```bash\n# Create ‚Üí Boot (automatic) ‚Üí Use ‚Üí Power off ‚Üí Delete\nlinode-cli linodes create --label test --type g6-nanode-1 --region us-east --image linode/alpine3.18 --root_pass \"Test123!\"\n# Get ID from output or list\nLINODE_ID=$(linode-cli linodes list --json | jq -r '.[] | select(.label==\"test\") | .id')\n# Shutdown\nlinode-cli linodes shutdown $LINODE_ID\n# Delete\nlinode-cli linodes delete $LINODE_ID\n```\n\n### Scripting Pattern\n```bash\n#!/bin/bash\nset -e  # Exit on error\n\n# Configuration\nREGION=\"us-central\"\nTYPE=\"g6-standard-2\"\nIMAGE=\"linode/debian11\"\n\n# Create instance\necho \"Creating Linode...\"\nRESULT=$(linode-cli linodes create \\\n  --type \"$TYPE\" \\\n  --region \"$REGION\" \\\n  --image \"$IMAGE\" \\\n  --label \"auto-server-$(date +%s)\" \\\n  --root_pass \"$(openssl rand -base64 32)\" \\\n  --json)\n\n# Extract ID\nLINODE_ID=$(echo \"$RESULT\" | jq -r '.[0].id')\necho \"Created Linode ID: $LINODE_ID\"\n\n# Wait for running status\nwhile true; do\n  STATUS=$(linode-cli linodes view $LINODE_ID --json | jq -r '.[0].status')\n  echo \"Status: $STATUS\"\n  [[ \"$STATUS\" == \"running\" ]] && break\n  sleep 5\ndone\n\necho \"Linode is ready!\"\n```\n\n## Resources\n\n### Official Documentation\n- **GitHub Repository**: https://github.com/linode/linode-cli\n- **Akamai TechDocs**: https://techdocs.akamai.com/cloud-computing/docs/cli\n- **API Documentation**: https://www.linode.com/docs/api/\n- **Getting Started Guide**: https://techdocs.akamai.com/cloud-computing/docs/getting-started-with-the-linode-cli\n\n### Key Features\n- **Auto-completion**: Bash completion available for command discovery\n- **OpenAPI-driven**: Always up-to-date with latest API features\n- **Cross-platform**: Works on Linux, macOS, and Windows (via WSL)\n- **Scriptable**: Perfect for automation and infrastructure as code\n- **Comprehensive**: Access to all Linode API endpoints\n\n### Community\n- **Contributors**: 49 active contributors\n- **License**: BSD-3-Clause\n- **Language**: Python (98.8%)\n- **Installation**: PyPI package (pip installable)\n\n## Tips and Best Practices\n\n### Security\n- **Protect tokens**: Never commit API tokens to version control\n- **Use environment variables**: Store tokens in `.env` files (git-ignored)\n- **Rotate regularly**: Generate new tokens periodically\n- **Limit permissions**: Use scoped tokens with minimal required permissions\n- **Strong passwords**: Always use strong root passwords for instances\n\n### Cost Management\n- **Start small**: Use nanode instances (g6-nanode-1) for testing\n- **Delete unused**: Remove test instances to avoid unnecessary charges\n- **Monitor usage**: Regularly check your account for active resources\n- **Use tags**: Organize resources with tags for easier management\n\n### Debugging\n- **Verbose output**: Add `--debug` flag for detailed error information\n- **JSON inspection**: Use `--json --pretty` to see full API responses\n- **Check status**: Use `view` commands to inspect resource details\n- **API reference**: Consult the API docs for endpoint specifics\n\n## Troubleshooting\n\n### Authentication Issues\n```bash\n# Verify token is set\necho $LINODE_CLI_TOKEN\n\n# Test authentication\nlinode-cli account view\n\n# Reconfigure CLI\nlinode-cli configure\n```\n\n### Common Errors\n- **401 Unauthorized**: Invalid or expired API token\n- **404 Not Found**: Resource ID doesn't exist or wrong region\n- **422 Unprocessable**: Missing required parameters or validation error\n- **429 Rate Limited**: Too many requests, implement backoff\n\n### Getting Help\n```bash\n# Check CLI version\nlinode-cli --version\n\n# View debug information\nlinode-cli linodes list --debug\n\n# Check configuration\ncat ~/.config/linode-cli\n```\n\n## Notes\n\n- This skill was generated from official Linode CLI documentation\n- The CLI is automatically generated from Linode's OpenAPI specification\n- All commands and examples are based on the official Linode API v4\n- Command syntax and available options may change with API updates\n- Always refer to `--help` for the most current command documentation\n\n## Updating\n\nTo stay current with Linode CLI:\n```bash\n# Update via pip\npip3 install --upgrade linode-cli\n\n# Check for new features\nlinode-cli --help\n\n# Review changelog\npip3 show linode-cli\n```\n\nThe CLI is regularly updated to reflect changes in the Linode API. Check the GitHub repository for release notes and breaking changes.\n",
        "midjourney-replicate-flux/SKILL.md": "---\nname: midjourney-replicate-flux\ndescription: Generate highly detailed, Midjourney-style image prompts optimized for the FLUX 1.1 Pro model on Replicate. Transform basic user descriptions into rich, cinematic prompts with professional photography qualities, dramatic lighting, and editorial-quality aesthetics. Use when users request image generation, need prompt enhancement, or want Midjourney-quality outputs via FLUX 1.1 Pro.\n---\n\n# Midjourney-Style Prompt Generator for FLUX 1.1 Pro\n\nGenerate professional, Midjourney-quality image prompts optimized for the `black-forest-labs/flux-1.1-pro` model on Replicate.\n\n## Purpose\n\nTransform basic user image requests into rich, detailed prompts that produce Midjourney-quality results using the FLUX 1.1 Pro model. This skill provides:\n\n- Midjourney aesthetic principles and visual characteristics\n- FLUX 1.1 Pro model optimization techniques\n- Prompt structure templates and patterns\n- Before/after transformation examples\n- Direct integration with the Replicate MCP server\n\n## When to Use This Skill\n\nUse this skill when:\n- User requests image generation via FLUX or Replicate\n- User wants \"Midjourney-style\" or \"cinematic\" images\n- User provides basic image descriptions that need enhancement\n- User asks for prompt optimization or improvement\n- User requests professional, editorial, or artistic photography\n- User wants to generate high-quality AI images\n\n**Trigger phrases**: \"generate an image\", \"create a photo of\", \"Midjourney style\", \"cinematic image\", \"professional photography\", \"make me a picture of\", \"FLUX image generation\"\n\n## How to Use This Skill\n\n### Step 1: Understand User Intent\n\nClarify what the user wants to create. Ask targeted questions if the request is too vague:\n- What is the main subject?\n- What mood or atmosphere do they want?\n- What style or genre (portrait, landscape, product, etc.)?\n- Any specific preferences (time of day, colors, composition)?\n\nKeep questions focused and avoid overwhelming the user with too many at once.\n\n### Step 2: Select Appropriate Prompt Pattern\n\nBased on the genre, consult `references/midjourney-style-guide.md` for the relevant prompt pattern:\n- **Portrait Photography** - People, characters, headshots\n- **Landscape/Environment** - Nature, cityscapes, locations\n- **Product Photography** - Objects, commercial shots\n- **Architectural** - Buildings, structures, interiors\n- **Fashion Editorial** - Models, clothing, styling\n- **Conceptual/Artistic** - Abstract, surreal, artistic concepts\n\nEach pattern provides a structured template for building prompts in that genre.\n\n### Step 3: Build Layered Prompt\n\nConstruct the prompt following the 5-layer structure from `references/midjourney-style-guide.md`:\n\n**Layer 1: Main Subject & Core Composition** (Required)\n```\n[Subject] [action/pose/position], [composition placement]\n```\n\n**Layer 2: Visual Style & Aesthetic** (Required)\n```\n[art style/movement], [mood descriptor], [color treatment]\n```\n\n**Layer 3: Lighting & Environment** (Highly Recommended)\n```\n[lighting type], [time of day], [weather/atmosphere]\n```\n\n**Layer 4: Technical Details & Quality Enhancers** (Recommended)\n```\n[camera/lens specs], [depth of field], [quality terms]\n```\n\n**Layer 5: Artistic References & Influences** (Optional)\n```\n[artist name], [art movement], [cultural reference]\n```\n\n### Step 4: Apply FLUX Optimizations\n\nEnhance the prompt for FLUX 1.1 Pro by consulting `references/flux-model-optimization.md`:\n\n1. **Add explicit artistic treatment**: FLUX is more literal than Midjourney, so specify \"cinematic\", \"editorial\", \"artistic photography\"\n\n2. **Define color grading clearly**: Don't rely on automatic enhancement; specify exact color treatment\n\n3. **Request composition explicitly**: State framing, perspective, and compositional techniques\n\n4. **Include professional quality markers**: \"professional photography\", \"award-winning\", \"expert color grading\"\n\n5. **Use technical photography anchors**: Camera, lens, aperture specifications ground the image in photographic reality\n\n### Step 5: Verify Quality\n\nCheck the enhanced prompt against the quality checklist from `references/midjourney-style-guide.md`:\n- [ ] Word count is 40-75 words\n- [ ] Main subject is clearly defined\n- [ ] Lighting is specified with direction and quality\n- [ ] Mood/atmosphere is conveyed\n- [ ] Technical photography details are present\n- [ ] Color treatment is mentioned\n- [ ] Composition guidance is included\n- [ ] Quality enhancers are present (2-3 minimum)\n- [ ] Prompt flows naturally when read aloud\n- [ ] No redundant or contradictory terms\n\n### Step 6: Generate Image via Replicate MCP Server\n\nUse the installed Replicate MCP server to generate the image. Call the `mcp__replicate__create_predictions` tool with these parameters:\n\n```json\n{\n  \"version\": \"black-forest-labs/flux-1.1-pro\",\n  \"input\": {\n    \"prompt\": \"[Your enhanced Midjourney-style prompt here]\",\n    \"aspect_ratio\": \"16:9\",\n    \"output_format\": \"png\"\n  }\n}\n```\n\n**Default configuration for Midjourney-style outputs:**\n- **aspect_ratio**: `\"16:9\"` (widescreen, cinematic format)\n- **output_format**: `\"png\"` (highest quality, lossless)\n- **safety_tolerance**: 2 (default, balanced - can increase to 3-4 for artistic content if needed)\n\n**Alternative aspect ratios** (from `references/flux-model-optimization.md`):\n- `\"1:1\"` - Square (social media, portraits)\n- `\"2:3\"` or `\"4:5\"` - Portrait orientation\n- `\"3:2\"` - Classic photo ratio\n- `\"21:9\"` - Ultra-widescreen (panoramic)\n\nThe MCP server will return a prediction object. Monitor the prediction status and provide the user with the output image URL when generation completes.\n\n### Step 7: Offer Variations (When Requested)\n\nIf the user requests multiple options or variations, provide 2-3 alternative prompts that emphasize different aspects:\n- **Variation 1**: Different lighting (golden hour vs blue hour)\n- **Variation 2**: Different composition (wide shot vs close-up)\n- **Variation 3**: Different mood (dramatic vs serene)\n\nEach variation should maintain the core subject while exploring different artistic directions.\n\n## Reference Documentation\n\nThe skill includes three comprehensive reference files that should be consulted during prompt creation:\n\n### 1. `references/midjourney-style-guide.md`\n\n**When to load**: Always consult when building any Midjourney-style prompt\n\n**Contains**:\n- Core Midjourney aesthetic principles\n- 5-layer prompt structure template\n- Midjourney-quality descriptive vocabulary\n- Lighting, composition, mood, color, and technical terms\n- Common prompt patterns for each genre\n- Artistic movement and style references\n- Quality control checklist\n- Common mistakes to avoid\n\n**Search patterns** (use for quick access to specific sections):\n- \"Portrait Photography pattern\" - Get portrait template\n- \"Landscape pattern\" - Get landscape template\n- \"Lighting Terms\" - Get lighting vocabulary\n- \"Color & Tone\" - Get color treatment options\n- \"Quality Enhancers\" - Get quality modifiers\n\n### 2. `references/flux-model-optimization.md`\n\n**When to load**: Consult when optimizing prompts for FLUX or troubleshooting results\n\n**Contains**:\n- FLUX 1.1 Pro specifications and parameters\n- Replicate MCP server usage instructions\n- FLUX vs Midjourney adaptation strategies\n- Model-specific optimization techniques\n- Aspect ratio and output format guide\n- Safety tolerance settings\n- Prompt engineering strategies for FLUX\n- Troubleshooting common issues\n\n**Search patterns**:\n- \"Aspect Ratios\" - Get ratio options\n- \"FLUX Strengths\" - Understand what FLUX does best\n- \"Adaptation Techniques\" - Learn FLUX-specific adjustments\n- \"Parameter Selection\" - Choose optimal parameters\n- \"Troubleshooting\" - Fix common issues\n\n### 3. `references/prompt-examples.md`\n\n**When to load**: When learning prompt transformation or seeking inspiration\n\n**Contains**:\n- 16 complete before/after transformation examples\n- Examples across all major genres (portrait, landscape, product, etc.)\n- Word count verification for each example\n- Detailed explanations of why each enhancement works\n- Transformation principles summary\n- Enhancement formula and process\n\n**Search patterns**:\n- \"Portrait examples\" - See portrait transformations\n- \"Landscape examples\" - See landscape transformations\n- \"Product Photography examples\" - See product transformations\n- \"Transformation Principles\" - Understand the enhancement process\n\n## Practical Workflow\n\n### Example 1: Simple Request Enhancement\n\n**User**: \"Create an image of a woman in a garden\"\n\n**Process**:\n1. Identify genre: Portrait photography in outdoor setting\n2. Consult `references/midjourney-style-guide.md` for portrait pattern\n3. Build layered prompt:\n   - Subject: Woman in garden setting\n   - Style: Editorial portrait photography\n   - Lighting: Golden hour natural light\n   - Technical: Canon R5 85mm f/1.4\n   - Quality: Highly detailed, professional\n4. Apply FLUX optimizations from `references/flux-model-optimization.md`:\n   - Add \"cinematic composition\"\n   - Specify \"warm color grading\"\n   - Include \"shallow depth of field\"\n5. Verify: 52 words ‚úì\n\n**Enhanced Prompt**:\n\"Woman in flowing dress standing among blooming roses, garden setting, editorial portrait photography, golden hour sunlight filtering through trees, warm and romantic atmosphere, shot on Canon R5 85mm f/1.4, shallow depth of field with soft bokeh background, warm color grading with rich earth tones, cinematic composition, highly detailed, professional photography\"\n\n6. Generate via MCP server with aspect_ratio \"16:9\", output_format \"png\"\n\n### Example 2: Genre-Specific Request\n\n**User**: \"Generate a photo of a vintage car on a coastal road\"\n\n**Process**:\n1. Identify genre: Automotive photography with landscape elements\n2. Consult automotive pattern from `references/prompt-examples.md`\n3. Build prompt emphasizing:\n   - Specific car era (1960s convertible)\n   - Evocative setting (coastal highway overlook)\n   - Nostalgic mood with film grain\n4. Apply FLUX techniques:\n   - Specify chrome and paint details FLUX excels at\n   - Request warm nostalgic color grading explicitly\n5. Verify quality checklist\n\n**Enhanced Prompt**:\n\"1960s vintage convertible parked on coastal highway overlook, sunset ocean view in background, automotive editorial photography, golden hour side lighting, warm nostalgic color grading with slight film grain, shot on Canon R5 50mm f/1.4, shallow depth of field isolating car, emphasize chrome details and period-correct paint, sense of freedom and nostalgia, highly detailed, professional automotive photography\"\n\n6. Generate via MCP server\n\n### Example 3: Multiple Variations\n\n**User**: \"Create a cityscape image, give me a few options\"\n\n**Process**:\n1. Create three variations emphasizing different aspects\n2. Reference `references/midjourney-style-guide.md` for urban photography vocabulary\n\n**Variation 1 - Blue Hour**:\n\"Modern city skyline at blue hour twilight, glowing office building windows, cinematic urban photography, dramatic perspective from elevated viewpoint, shot on Sony A7R IV 24mm, deep focus, cool color grading with blue and purple tones, atmospheric haze, highly detailed, 8k resolution\"\n\n**Variation 2 - Golden Hour**:\n\"Urban cityscape bathed in golden hour sunlight, warm light on building facades, cinematic architectural photography, wide angle establishing shot, shot on Canon R5 24-70mm, rich color saturation with warm orange tones, long shadows creating depth, highly detailed, professional photography\"\n\n**Variation 3 - Night Scene**:\n\"City lights at night with light trails from traffic, vibrant urban photography, long exposure creating motion blur, shot on Sony A7R IV 35mm, dynamic composition, neon colors and warm street lights, atmospheric and energetic, highly detailed, 8k resolution\"\n\n3. Generate all three via MCP server, present options to user\n\n## Important Notes\n\n### Do Not Create Custom Scripts\n\n**CRITICAL**: The Replicate MCP server is already installed and provides all necessary API integration. Do NOT create Python scripts, Node.js code, or any other custom code for API calls. Always use the `mcp__replicate__create_predictions` tool directly.\n\n### Prompt Length Management\n\nAlways aim for 40-75 words:\n- **Under 40 words**: Risk losing Midjourney aesthetic richness\n- **40-60 words**: Optimal for most prompts\n- **60-75 words**: Complex scenes with multiple elements\n- **Over 75 words**: Diminishing returns, potential confusion\n\nIf a prompt exceeds 75 words, consolidate by removing redundant quality terms while maintaining core elements.\n\n### Quality Over Quantity\n\nBetter to have one excellent, well-crafted prompt than multiple mediocre ones. Take time to thoughtfully layer the elements.\n\n### Be Specific, Not Generic\n\nReplace vague terms with specific descriptions:\n- ‚ùå \"beautiful lighting\" ‚Üí ‚úÖ \"golden hour sunlight from behind creating rim light\"\n- ‚ùå \"nice colors\" ‚Üí ‚úÖ \"warm color grading with rich earth tones and orange highlights\"\n- ‚ùå \"good quality\" ‚Üí ‚úÖ \"shot on Canon R5 85mm f/1.4, professional photography\"\n\n### Learn From Examples\n\nThe `references/prompt-examples.md` file contains 16 complete transformations. Study these to understand the enhancement process and internalize the patterns.\n\n### Artistic References\n\nUse artistic references when appropriate, but ensure they're relevant:\n- Photography: Annie Leibovitz, Peter Lindbergh, Steve McCurry, Ansel Adams\n- Cinematography: Blade Runner 2049, The Grand Budapest Hotel, Her\n- Art Movements: Impressionism, Surrealism, Minimalism, Art Nouveau\n\nDon't force references if they don't fit the request naturally.\n\n### FLUX-Specific Adaptations\n\nRemember that FLUX 1.1 Pro differs from Midjourney:\n- More literal interpretation (less automatic artistic elevation)\n- Excels at photorealism and fine detail\n- Superior text rendering in images\n- More accurate colors (less stylized)\n- Needs explicit quality and style instructions\n\nAlways compensate by adding clear artistic direction in the prompt.\n\n## Success Criteria\n\nA successful Midjourney-style prompt for FLUX 1.1 Pro should:\n\n1. ‚úÖ Transform generic requests into rich, detailed descriptions\n2. ‚úÖ Maintain 40-75 word length for optimal results\n3. ‚úÖ Include all core elements: subject, style, lighting, technical specs, color, quality\n4. ‚úÖ Read naturally and coherently without contradictions\n5. ‚úÖ Leverage FLUX's strengths (photorealism, detail, complex compositions)\n6. ‚úÖ Compensate for FLUX's differences from Midjourney (explicit artistic treatment)\n7. ‚úÖ Generate images via Replicate MCP server with appropriate parameters\n8. ‚úÖ Produce outputs matching Midjourney's distinctive aesthetic quality\n\nWhen these criteria are met, the resulting images should exhibit:\n- Ultra-detailed rendering with sharp focus\n- Cinematic composition and dramatic lighting\n- Professional color grading with tonal depth\n- Editorial quality and artistic refinement\n- That distinctive \"Midjourney look\" of polished, magazine-worthy imagery\n",
        "n8n/SKILL.md": "---\nname: n8n\ndescription: N8N Documentation - Workflow automation platform with AI capabilities\n---\n\n# N8N Skill\n\nComprehensive assistance with n8n development, generated from official documentation. n8n is a fair-code licensed workflow automation tool that combines AI capabilities with business process automation.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Building or debugging n8n workflows\n- Working with the Code node (JavaScript or Python)\n- Using expressions and data transformations\n- Implementing AI agents, chains, or RAG workflows\n- Configuring n8n deployments (Docker, npm, self-hosted)\n- Setting up webhooks, credentials, or integrations\n- Handling errors in workflows\n- Scaling n8n with queue mode\n- Creating custom nodes or white labeling n8n\n- Using the n8n API programmatically\n- Working with LangChain in n8n\n- Migrating to n8n v1.0\n\n## Key Concepts\n\n### Core Components\n- **Workflows**: Visual automation flows with nodes connected together\n- **Nodes**: Individual operations in a workflow (trigger, action, logic, etc.)\n- **Expressions**: Code snippets using `{{ }}` syntax to access and transform data\n- **Credentials**: Secure storage for API keys and authentication\n- **Executions**: Individual workflow runs with their data and status\n\n### Data Structure\n- n8n passes data between nodes as **items** (array of JSON objects)\n- Each item has a `json` property containing the main data\n- Binary data is stored separately in the `binary` property\n- Use `$json` to access current item's data in expressions\n\n### AI Capabilities\n- **Agents**: AI that can use tools and make decisions\n- **Chains**: Predefined sequences of AI operations\n- **Memory**: Store conversation history for context\n- **Tools**: Functions that AI agents can call\n- **Vector Databases**: Store and retrieve embeddings for RAG\n\n## Quick Reference\n\n### Example 1: Basic Expression to Access Data\n```javascript\n// Access data from the current item\n{{ $json.name }}\n\n// Access data from a specific node\n{{ $node[\"HTTP Request\"].json.response }}\n\n// Access all items from a node\n{{ $(\"HTTP Request\").all() }}\n```\n\n### Example 2: HTTP Request with Authentication\nWhen working with the HTTP Request node, handle errors and rate limits:\n\n```javascript\n// In HTTP Request node settings:\n// - Enable \"Retry on Fail\"\n// - Set Max Tries to 3\n// - Set Wait Between Tries (ms) to 1000\n\n// For rate limiting, use Batching:\n// - Items per Batch: 10\n// - Batch Interval (ms): 1000\n```\n\n### Example 3: Code Node - Transform Data (JavaScript)\n```javascript\n// Access input data\nconst items = $input.all();\n\n// Transform each item\nreturn items.map(item => {\n  return {\n    json: {\n      fullName: `${item.json.firstName} ${item.json.lastName}`,\n      email: item.json.email.toLowerCase(),\n      timestamp: new Date().toISOString()\n    }\n  };\n});\n```\n\n### Example 4: Code Node - Filter Data (Python)\n```python\n# Filter items based on a condition\noutput = []\n\nfor item in items:\n    if item['json']['status'] == 'active':\n        output.append({\n            'json': {\n                'id': item['json']['id'],\n                'name': item['json']['name']\n            }\n        })\n\nreturn output\n```\n\n### Example 5: Expression - Date Handling with Luxon\n```javascript\n// Current date\n{{ $now }}\n\n// Format date\n{{ $now.toFormat('yyyy-MM-dd') }}\n\n// Add 7 days\n{{ $now.plus({ days: 7 }) }}\n\n// Parse and format custom date\n{{ DateTime.fromISO($json.dateString).toFormat('LLL dd, yyyy') }}\n```\n\n### Example 6: JWT Authentication Credential\nFor APIs requiring JWT authentication:\n\n```javascript\n// Use JWT credential with:\n// - Key Type: Passphrase (for HMAC) or PEM Key (for RSA/ECDSA)\n// - Secret: Your secret key\n// - Algorithm: HS256, RS256, ES256, etc.\n\n// The JWT credential automatically generates tokens\n// Use it in HTTP Request node > Authentication > JWT\n```\n\n### Example 7: Handle Errors in Workflow\n```javascript\n// In Code node, use try-catch:\ntry {\n  const result = $json.data.someField.toUpperCase();\n  return [{ json: { result } }];\n} catch (error) {\n  // Return error information\n  return [{\n    json: {\n      error: error.message,\n      originalData: $json\n    }\n  }];\n}\n\n// Or set up Error Workflow in Workflow Settings\n// to catch all failures and send notifications\n```\n\n### Example 8: Pagination in HTTP Request\n```javascript\n// Use pagination to fetch all pages\n// In HTTP Request node > Pagination:\n\n// Type: Generic Pagination\n// Request URL: {{ $url }}&page={{ $pageNumber }}\n// Complete When: {{ $response.body.hasMore === false }}\n// Next Page URL: Automatic\n```\n\n### Example 9: AI Agent with Tools\n```javascript\n// In AI Agent node:\n// 1. Connect a Chat Model (OpenAI, etc.)\n// 2. Add tools (Calculator, HTTP Request, etc.)\n// 3. Configure memory if needed\n\n// The agent can:\n// - Analyze user input\n// - Decide which tools to use\n// - Execute tools and process results\n// - Return final answer\n```\n\n### Example 10: Environment Variables and Static Data\n```javascript\n// Access environment variables\n{{ $env.MY_API_KEY }}\n\n// Store workflow static data (persists across executions)\nconst staticData = getWorkflowStaticData('global');\nstaticData.lastRun = new Date().toISOString();\nstaticData.counter = (staticData.counter || 0) + 1;\n\n// Retrieve static data\n{{ $workflow.staticData.counter }}\n```\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **llms-txt.md** - Complete n8n documentation formatted for LLMs\n  - Installation and setup guides\n  - Node reference documentation\n  - API documentation\n  - Code examples and patterns\n  - Configuration options\n  - Troubleshooting guides\n\n- **llms-full.md** - Extended documentation with deep technical details\n  - Advanced configuration\n  - Scaling and performance\n  - Security and authentication\n  - Custom node development\n  - White labeling and embed options\n\nUse `view` to read specific reference files when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n1. Start with basic workflow creation:\n   - Trigger nodes (Webhook, Schedule, Manual)\n   - Action nodes (HTTP Request, Set, Edit Fields)\n   - Learn expression syntax with simple `{{ $json.field }}` access\n\n2. Understand data structure:\n   - Each node outputs an array of items\n   - Use the data inspector to see item structure\n   - Practice with the Edit Fields node for data transformation\n\n3. Common patterns:\n   - Webhook ‚Üí HTTP Request ‚Üí Set ‚Üí Respond to Webhook\n   - Schedule ‚Üí Code ‚Üí HTTP Request ‚Üí Conditional\n   - Manual ‚Üí Loop Over Items ‚Üí Process Each\n\n### For Intermediate Users\n1. Master the Code node:\n   - JavaScript mode for complex transformations\n   - Access `$input.all()` for all items\n   - Return properly formatted items with `json` property\n\n2. Work with expressions:\n   - Use built-in methods: `.first()`, `.last()`, `.item`\n   - Date manipulation with Luxon\n   - JMESPath for complex JSON queries\n\n3. Error handling:\n   - Use Try-Catch in Code nodes\n   - Set up Error Workflows\n   - Configure Retry on Fail for API calls\n\n4. Data operations:\n   - Merge data from multiple sources\n   - Split and filter items\n   - Loop over items for batch processing\n\n### For Advanced Users\n1. AI and LangChain:\n   - Build AI agents with custom tools\n   - Implement RAG with vector databases\n   - Use memory for conversational workflows\n   - Chain multiple AI operations\n\n2. Scaling and performance:\n   - Configure queue mode for distributed execution\n   - Optimize database settings\n   - Use execution data pruning\n   - Configure task runners\n\n3. Custom development:\n   - Create custom nodes\n   - White label n8n for embedding\n   - Use the n8n API for workflow management\n   - Implement external secrets with AWS/Azure/GCP\n\n4. Advanced patterns:\n   - Sub-workflows for reusability\n   - Webhook authentication and validation\n   - Complex data transformations with JMESPath\n   - Real-time data processing with SSE/WebSockets\n\n## Common Issues and Solutions\n\n### HTTP Request Errors\n- **400 Bad Request**: Check query parameters and array formatting\n- **403 Forbidden**: Verify credentials and API permissions\n- **429 Rate Limit**: Use Batching or Retry on Fail options\n- **404 Not Found**: Verify endpoint URL is correct\n\n### Expression Errors\n- Workflows now fail on expression errors in v1.0+\n- Set up Error Workflows to catch failures\n- Test expressions in the expression editor\n- Check for undefined values before accessing properties\n\n### Data Type Issues\n- Use `.toString()`, `.toNumber()` for type conversion\n- Handle null/undefined with `{{ $json.field || 'default' }}`\n- Binary data requires special handling with buffers\n\n### Migration to v1.0\n- New execution order (depth-first instead of breadth-first)\n- Python support in Code node (Pyodide)\n- Mandatory user management (no more BasicAuth)\n- WebSocket push backend is now default\n- Node 18.17.0 or higher required\n\n## Environment Configuration\n\n### Docker Setup\n```bash\n# Basic n8n with Docker\ndocker run -it --rm \\\n  --name n8n \\\n  -p 5678:5678 \\\n  -v ~/.n8n:/home/node/.n8n \\\n  n8nio/n8n\n\n# With environment variables\ndocker run -it --rm \\\n  --name n8n \\\n  -p 5678:5678 \\\n  -e N8N_BASIC_AUTH_ACTIVE=true \\\n  -e N8N_BASIC_AUTH_USER=admin \\\n  -e N8N_BASIC_AUTH_PASSWORD=password \\\n  -v ~/.n8n:/home/node/.n8n \\\n  n8nio/n8n\n```\n\n### Key Environment Variables\n- `N8N_HOST`: Hostname (default: localhost)\n- `N8N_PORT`: Port (default: 5678)\n- `N8N_PROTOCOL`: http or https\n- `WEBHOOK_URL`: External webhook URL\n- `N8N_ENCRYPTION_KEY`: Encryption key for credentials\n- `DB_TYPE`: Database type (sqlite, postgres)\n- `EXECUTIONS_MODE`: queue or main (queue for scaling)\n\n## Resources\n\n### Official Resources\n- [n8n Documentation](https://docs.n8n.io/)\n- [n8n Community Forum](https://community.n8n.io/)\n- [n8n Workflow Templates](https://n8n.io/workflows/)\n- [n8n GitHub Repository](https://github.com/n8n-io/n8n)\n\n### Learning Paths\n- Level One Course: Basic workflow building\n- Level Two Course: Advanced data handling and error management\n- Video Courses: Visual learning resources\n- AI Tutorial: Build AI workflows from scratch\n\n### API and Development\n- [API Reference](https://docs.n8n.io/api/api-reference/)\n- [Creating Custom Nodes](https://docs.n8n.io/integrations/creating-nodes/)\n- [Node Development](https://docs.n8n.io/integrations/creating-nodes/build/)\n\n## Notes\n\n- This skill was automatically generated from official n8n documentation\n- Code examples use proper language tags for syntax highlighting\n- Examples are extracted from real-world patterns in the docs\n- Focus on practical, actionable patterns for immediate use\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Re-run the scraper with the same configuration\n2. The skill will be rebuilt with the latest information\n3. Review Quick Reference section for new examples\n",
        "ollama/SKILL.md": "---\nname: ollama\ndescription: Ollama API Documentation\n---\n\n# Ollama Skill\n\nComprehensive assistance with Ollama development - the local AI model runtime for running and interacting with large language models programmatically.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Running local AI models with Ollama\n- Building applications that interact with Ollama's API\n- Implementing chat completions, embeddings, or streaming responses\n- Setting up Ollama authentication or cloud models\n- Configuring Ollama server (environment variables, ports, proxies)\n- Using Ollama with OpenAI-compatible libraries\n- Troubleshooting Ollama installations or GPU compatibility\n- Implementing tool calling, structured outputs, or vision capabilities\n- Working with Ollama in Docker or behind proxies\n- Creating, copying, pushing, or managing Ollama models\n\n## Quick Reference\n\n### 1. Basic Chat Completion (cURL)\n\nGenerate a simple chat response:\n\n```bash\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"gemma3\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Why is the sky blue?\"\n    }\n  ]\n}'\n```\n\n### 2. Simple Text Generation (cURL)\n\nGenerate a text response from a prompt:\n\n```bash\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"gemma3\",\n  \"prompt\": \"Why is the sky blue?\"\n}'\n```\n\n### 3. Python Chat with OpenAI Library\n\nUse Ollama with the OpenAI Python library:\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI(\n    base_url='http://localhost:11434/v1/',\n    api_key='ollama',  # required but ignored\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            'role': 'user',\n            'content': 'Say this is a test',\n        }\n    ],\n    model='llama3.2',\n)\n```\n\n### 4. Vision Model (Image Analysis)\n\nAsk questions about images:\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI(base_url=\"http://localhost:11434/v1/\", api_key=\"ollama\")\n\nresponse = client.chat.completions.create(\n    model=\"llava\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": \"data:image/png;base64,iVBORw0KG...\",\n                },\n            ],\n        }\n    ],\n    max_tokens=300,\n)\n```\n\n### 5. Generate Embeddings\n\nCreate vector embeddings for text:\n\n```python\nclient = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n\nembeddings = client.embeddings.create(\n    model=\"all-minilm\",\n    input=[\"why is the sky blue?\", \"why is the grass green?\"],\n)\n```\n\n### 6. Structured Outputs (JSON Schema)\n\nGet structured JSON responses:\n\n```python\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\nclient = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n\nclass FriendInfo(BaseModel):\n    name: str\n    age: int\n    is_available: bool\n\nclass FriendList(BaseModel):\n    friends: list[FriendInfo]\n\ncompletion = client.beta.chat.completions.parse(\n    temperature=0,\n    model=\"llama3.1:8b\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Return a list of friends in JSON format\"}\n    ],\n    response_format=FriendList,\n)\n\nfriends_response = completion.choices[0].message\nif friends_response.parsed:\n    print(friends_response.parsed)\n```\n\n### 7. JavaScript/TypeScript Chat\n\nUse Ollama with the OpenAI JavaScript library:\n\n```javascript\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI({\n  baseURL: \"http://localhost:11434/v1/\",\n  apiKey: \"ollama\",  // required but ignored\n});\n\nconst chatCompletion = await openai.chat.completions.create({\n  messages: [{ role: \"user\", content: \"Say this is a test\" }],\n  model: \"llama3.2\",\n});\n```\n\n### 8. Authentication for Cloud Models\n\nSign in to use cloud models:\n\n```bash\n# Sign in from CLI\nollama signin\n\n# Then use cloud models\nollama run gpt-oss:120b-cloud\n```\n\nOr use API keys for direct cloud access:\n\n```bash\nexport OLLAMA_API_KEY=your_api_key\n\ncurl https://ollama.com/api/generate \\\n  -H \"Authorization: Bearer $OLLAMA_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-oss:120b\",\n    \"prompt\": \"Why is the sky blue?\",\n    \"stream\": false\n  }'\n```\n\n### 9. Configure Ollama Server\n\nSet environment variables for server configuration:\n\n**macOS:**\n```bash\n# Set environment variable\nlaunchctl setenv OLLAMA_HOST \"0.0.0.0:11434\"\n\n# Restart Ollama application\n```\n\n**Linux (systemd):**\n```bash\n# Edit service\nsystemctl edit ollama.service\n\n# Add under [Service]\nEnvironment=\"OLLAMA_HOST=0.0.0.0:11434\"\n\n# Reload and restart\nsystemctl daemon-reload\nsystemctl restart ollama\n```\n\n**Windows:**\n```\n1. Quit Ollama from task bar\n2. Search \"environment variables\" in Settings\n3. Edit or create OLLAMA_HOST variable\n4. Set value: 0.0.0.0:11434\n5. Restart Ollama from Start menu\n```\n\n### 10. Check Model GPU Loading\n\nVerify if your model is using GPU:\n\n```bash\nollama ps\n```\n\nOutput shows:\n- `100% GPU` - Fully loaded on GPU\n- `100% CPU` - Fully loaded in system memory\n- `48%/52% CPU/GPU` - Split between both\n\n## Key Concepts\n\n### Base URLs\n\n- **Local API (default)**: `http://localhost:11434/api`\n- **Cloud API**: `https://ollama.com/api`\n- **OpenAI Compatible**: `/v1/` endpoints for OpenAI libraries\n\n### Authentication\n\n- **Local**: No authentication required for `http://localhost:11434`\n- **Cloud Models**: Requires signing in (`ollama signin`) or API key\n- **API Keys**: For programmatic access to `https://ollama.com/api`\n\n### Models\n\n- **Local Models**: Run on your machine (e.g., `gemma3`, `llama3.2`, `qwen3`)\n- **Cloud Models**: Suffix `-cloud` (e.g., `gpt-oss:120b-cloud`, `qwen3-coder:480b-cloud`)\n- **Vision Models**: Support image inputs (e.g., `llava`)\n\n### Common Environment Variables\n\n- `OLLAMA_HOST` - Change bind address (default: `127.0.0.1:11434`)\n- `OLLAMA_CONTEXT_LENGTH` - Context window size (default: `2048` tokens)\n- `OLLAMA_MODELS` - Model storage directory\n- `OLLAMA_ORIGINS` - Allow additional web origins for CORS\n- `HTTPS_PROXY` - Proxy server for model downloads\n\n### Error Handling\n\n**Status Codes:**\n- `200` - Success\n- `400` - Bad Request (invalid parameters)\n- `404` - Not Found (model doesn't exist)\n- `429` - Too Many Requests (rate limit)\n- `500` - Internal Server Error\n- `502` - Bad Gateway (cloud model unreachable)\n\n**Error Format:**\n```json\n{\n  \"error\": \"the model failed to generate a response\"\n}\n```\n\n### Streaming vs Non-Streaming\n\n- **Streaming** (default): Returns response chunks as JSON objects (NDJSON)\n- **Non-Streaming**: Set `\"stream\": false` to get complete response in one object\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **llms-txt.md** - Complete API reference covering:\n  - All API endpoints (`/api/generate`, `/api/chat`, `/api/embed`, etc.)\n  - Authentication methods (signin, API keys)\n  - Error handling and status codes\n  - OpenAI compatibility layer\n  - Cloud models usage\n  - Streaming responses\n  - Configuration and environment variables\n\n- **llms.md** - Documentation index listing all available topics:\n  - API reference (version, model details, chat, generate, embeddings)\n  - Capabilities (embeddings, streaming, structured outputs, tool calling, vision)\n  - CLI reference\n  - Cloud integration\n  - Platform-specific guides (Linux, macOS, Windows, Docker)\n  - IDE integrations (VS Code, JetBrains, Xcode, Zed, Cline)\n\nUse the reference files when you need:\n- Detailed API parameter specifications\n- Complete endpoint documentation\n- Advanced configuration options\n- Platform-specific setup instructions\n- Integration guides for specific tools\n\n## Working with This Skill\n\n### For Beginners\n\nStart with these common patterns:\n1. **Simple generation**: Use `/api/generate` endpoint with a prompt\n2. **Chat interface**: Use `/api/chat` with messages array\n3. **OpenAI compatibility**: Use OpenAI libraries with `base_url='http://localhost:11434/v1/'`\n4. **Check GPU usage**: Run `ollama ps` to verify model loading\n\nRead `llms-txt.md` section on \"Introduction\" and \"Quickstart\" for foundational concepts.\n\n### For Intermediate Users\n\nFocus on:\n- **Embeddings** for semantic search and RAG applications\n- **Structured outputs** with JSON schema validation\n- **Vision models** for image analysis\n- **Streaming** for real-time response generation\n- **Authentication** for cloud models\n\nCheck the specific API endpoints in `llms-txt.md` for detailed parameter options.\n\n### For Advanced Users\n\nExplore:\n- **Tool calling** for function execution\n- **Custom model creation** with Modelfiles\n- **Server configuration** with environment variables\n- **Proxy setup** for network-restricted environments\n- **Docker deployment** with custom configurations\n- **Performance optimization** with GPU settings\n\nRefer to platform-specific sections in `llms.md` and configuration details in `llms-txt.md`.\n\n### Common Use Cases\n\n**Building a chatbot:**\n1. Use `/api/chat` endpoint\n2. Maintain message history in your application\n3. Stream responses for better UX\n4. Handle errors gracefully\n\n**Creating embeddings for search:**\n1. Use `/api/embed` endpoint\n2. Store embeddings in vector database\n3. Perform similarity search\n4. Implement RAG (Retrieval Augmented Generation)\n\n**Running behind a firewall:**\n1. Set `HTTPS_PROXY` environment variable\n2. Configure proxy in Docker if containerized\n3. Ensure certificates are trusted\n\n**Using cloud models:**\n1. Run `ollama signin` once\n2. Pull cloud models with `-cloud` suffix\n3. Use same API endpoints as local models\n\n## Troubleshooting\n\n### Model Not Loading on GPU\n\n**Check:**\n```bash\nollama ps\n```\n\n**Solutions:**\n- Verify GPU compatibility in documentation\n- Check CUDA/ROCm installation\n- Review available VRAM\n- Try smaller model variants\n\n### Cannot Access Ollama Remotely\n\n**Problem:** Ollama only accessible from localhost\n\n**Solution:**\n```bash\n# Set OLLAMA_HOST to bind to all interfaces\nexport OLLAMA_HOST=\"0.0.0.0:11434\"\n```\n\nSee \"How do I configure Ollama server?\" in `llms-txt.md` for platform-specific instructions.\n\n### Proxy Issues\n\n**Problem:** Cannot download models behind proxy\n\n**Solution:**\n```bash\n# Set proxy (HTTPS only, not HTTP)\nexport HTTPS_PROXY=https://proxy.example.com\n\n# Restart Ollama\n```\n\nSee \"How do I use Ollama behind a proxy?\" in `llms-txt.md`.\n\n### CORS Errors in Browser\n\n**Problem:** Browser extension or web app cannot access Ollama\n\n**Solution:**\n```bash\n# Allow specific origins\nexport OLLAMA_ORIGINS=\"chrome-extension://*,moz-extension://*\"\n```\n\nSee \"How can I allow additional web origins?\" in `llms-txt.md`.\n\n## Resources\n\n### Official Documentation\n- Main docs: https://docs.ollama.com\n- API Reference: https://docs.ollama.com/api\n- Model Library: https://ollama.com/models\n\n### Official Libraries\n- Python: https://github.com/ollama/ollama-python\n- JavaScript: https://github.com/ollama/ollama-js\n\n### Community\n- GitHub: https://github.com/ollama/ollama\n- Community Libraries: See GitHub README for full list\n\n## Notes\n\n- This skill was generated from official Ollama documentation\n- All examples are tested and working with Ollama's API\n- Code samples include proper language detection for syntax highlighting\n- Reference files preserve structure from official docs with working links\n- OpenAI compatibility means most OpenAI code works with minimal changes\n\n## Quick Command Reference\n\n```bash\n# CLI Commands\nollama signin                    # Sign in to ollama.com\nollama run gemma3               # Run a model interactively\nollama pull gemma3              # Download a model\nollama ps                       # List running models\nollama list                     # List installed models\n\n# Check API Status\ncurl http://localhost:11434/api/version\n\n# Environment Variables (Common)\nexport OLLAMA_HOST=\"0.0.0.0:11434\"\nexport OLLAMA_CONTEXT_LENGTH=8192\nexport OLLAMA_ORIGINS=\"*\"\nexport HTTPS_PROXY=\"https://proxy.example.com\"\n```\n",
        "openrouter/SKILL.md": "---\nname: openrouter\ndescription: OpenRouter API - Unified access to 400+ AI models through one API\n---\n\n# OpenRouter Skill\n\nComprehensive assistance with OpenRouter API development, providing unified access to hundreds of AI models through a single endpoint with intelligent routing, automatic fallbacks, and standardized interfaces.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Making API calls to multiple AI model providers through a unified interface\n- Implementing model fallback strategies or auto-routing\n- Working with OpenAI-compatible SDKs but targeting multiple providers\n- Configuring advanced sampling parameters (temperature, top_p, penalties)\n- Setting up streaming responses or structured JSON outputs\n- Comparing costs across different AI models\n- Building applications that need automatic provider failover\n- Implementing function/tool calling across different models\n- Questions about OpenRouter-specific features (routing, fallbacks, zero completion insurance)\n\n## Quick Reference\n\n### Basic Chat Completion (Python)\n```python\nfrom openai import OpenAI\n\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",\n  api_key=\"<OPENROUTER_API_KEY>\",\n)\n\ncompletion = client.chat.completions.create(\n  model=\"openai/gpt-4o\",\n  messages=[{\"role\": \"user\", \"content\": \"What is the meaning of life?\"}]\n)\nprint(completion.choices[0].message.content)\n```\n\n### Basic Chat Completion (JavaScript/TypeScript)\n```typescript\nimport OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  baseURL: 'https://openrouter.ai/api/v1',\n  apiKey: '<OPENROUTER_API_KEY>',\n});\n\nconst completion = await openai.chat.completions.create({\n  model: 'openai/gpt-4o',\n  messages: [{\"role\": 'user', \"content\": 'What is the meaning of life?'}],\n});\nconsole.log(completion.choices[0].message);\n```\n\n### cURL Request\n```bash\ncurl https://openrouter.ai/api/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENROUTER_API_KEY\" \\\n  -d '{\n    \"model\": \"openai/gpt-4o\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"What is the meaning of life?\"}]\n  }'\n```\n\n### Model Fallback Configuration (Python)\n```python\ncompletion = client.chat.completions.create(\n    model=\"openai/gpt-4o\",\n    extra_body={\n        \"models\": [\"anthropic/claude-3.5-sonnet\", \"gryphe/mythomax-l2-13b\"],\n    },\n    messages=[{\"role\": \"user\", \"content\": \"Your prompt here\"}]\n)\n```\n\n### Model Fallback Configuration (TypeScript)\n```typescript\nconst completion = await client.chat.completions.create({\n    model: 'openai/gpt-4o',\n    models: ['anthropic/claude-3.5-sonnet', 'gryphe/mythomax-l2-13b'],\n    messages: [{ role: 'user', content: 'Your prompt here' }],\n});\n```\n\n### Auto Router (Dynamic Model Selection)\n```python\ncompletion = client.chat.completions.create(\n    model=\"openrouter/auto\",  # Automatically selects best model for the prompt\n    messages=[{\"role\": \"user\", \"content\": \"Your prompt here\"}]\n)\n```\n\n### Advanced Parameters Example\n```python\ncompletion = client.chat.completions.create(\n    model=\"openai/gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Write a creative story\"}],\n    temperature=0.8,           # Higher for creativity (0.0-2.0)\n    max_tokens=500,            # Limit response length\n    top_p=0.9,                 # Nucleus sampling (0.0-1.0)\n    frequency_penalty=0.5,     # Reduce repetition (-2.0-2.0)\n    presence_penalty=0.3       # Encourage topic diversity (-2.0-2.0)\n)\n```\n\n### Streaming Response\n```python\nstream = client.chat.completions.create(\n    model=\"openai/gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Tell me a story\"}],\n    stream=True\n)\n\nfor chunk in stream:\n    if chunk.choices[0].delta.content:\n        print(chunk.choices[0].delta.content, end='')\n```\n\n### JSON Mode (Structured Output)\n```python\ncompletion = client.chat.completions.create(\n    model=\"openai/gpt-4o\",\n    messages=[{\n        \"role\": \"user\",\n        \"content\": \"Extract person's name, age, and city from: John is 30 and lives in NYC\"\n    }],\n    response_format={\"type\": \"json_object\"}\n)\n```\n\n### Deterministic Output with Seed\n```python\ncompletion = client.chat.completions.create(\n    model=\"openai/gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Generate a random number\"}],\n    seed=42,            # Same seed = same output (when supported)\n    temperature=0.0     # Deterministic sampling\n)\n```\n\n## Key Concepts\n\n### Model Routing\nOpenRouter provides intelligent routing capabilities:\n- **Auto Router** (`openrouter/auto`): Automatically selects the best model based on your prompt using NotDiamond\n- **Fallback Models**: Specify multiple models that automatically retry if primary fails\n- **Provider Routing**: Automatically routes across providers for reliability\n\n### Authentication\n- Uses Bearer token authentication with API keys\n- API keys can be managed programmatically\n- Compatible with OpenAI SDK authentication patterns\n\n### Model Naming Convention\nModels use the format `provider/model-name`:\n- `openai/gpt-4o` - OpenAI's GPT-4 Optimized\n- `anthropic/claude-3.5-sonnet` - Anthropic's Claude 3.5 Sonnet\n- `google/gemini-2.0-flash-exp:free` - Google's free Gemini model\n- `openrouter/auto` - Auto-routing system\n\n### Sampling Parameters\n\n**Temperature** (0.0-2.0, default: 1.0)\n- Lower = more predictable, focused responses\n- Higher = more creative, diverse responses\n- Use low (0.0-0.3) for factual tasks, high (0.8-1.5) for creative work\n\n**Top P** (0.0-1.0, default: 1.0)\n- Limits choices to percentage of likely tokens\n- Dynamic filtering of improbable options\n- Balance between consistency and variety\n\n**Frequency/Presence Penalties** (-2.0-2.0, default: 0.0)\n- Frequency: Discourages repeating tokens proportional to use\n- Presence: Simpler penalty not scaled by count\n- Positive values reduce repetition, negative encourage reuse\n\n**Max Tokens** (integer)\n- Sets maximum response length\n- Cannot exceed context length minus prompt length\n- Use to control costs and enforce concise replies\n\n### Response Formats\n- **Standard JSON**: Default chat completion format\n- **Streaming**: Server-Sent Events (SSE) with `stream: true`\n- **JSON Mode**: Guaranteed valid JSON with `response_format: {\"type\": \"json_object\"}`\n- **Structured Outputs**: Schema-validated JSON responses\n\n### Advanced Features\n- **Tool/Function Calling**: Connect models to external APIs\n- **Multimodal Inputs**: Support for images, PDFs, audio\n- **Prompt Caching**: Reduce costs for repeated prompts\n- **Web Search Integration**: Enhanced responses with web data\n- **Zero Completion Insurance**: Protection against failed responses\n- **Logprobs**: Access token probabilities for confidence analysis\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **llms-full.md** - Complete list of available models with metadata\n- **llms-small.md** - Curated subset of popular models\n- **llms.md** - Standard model listings\n\nUse `view` to read specific reference files when detailed model information is needed.\n\n## Working with This Skill\n\n### For Beginners\n1. Start with basic chat completion examples (Python/JavaScript/cURL above)\n2. Use the standard OpenAI SDK for easy integration\n3. Try simple model names like `openai/gpt-4o` or `anthropic/claude-3.5-sonnet`\n4. Keep parameters simple initially (just model and messages)\n\n### For Intermediate Users\n1. Implement model fallback arrays for reliability\n2. Experiment with sampling parameters (temperature, top_p)\n3. Use streaming for better UX in conversational apps\n4. Try `openrouter/auto` for automatic model selection\n5. Implement JSON mode for structured data extraction\n\n### For Advanced Users\n1. Fine-tune multiple sampling parameters together\n2. Implement custom routing logic with fallback chains\n3. Use logprobs for confidence scoring\n4. Leverage tool/function calling capabilities\n5. Optimize costs by selecting appropriate models per task\n6. Implement prompt caching strategies\n7. Use seed parameter for reproducible testing\n\n## Common Patterns\n\n### Error Handling with Fallbacks\n```python\ntry:\n    completion = client.chat.completions.create(\n        model=\"openai/gpt-4o\",\n        extra_body={\n            \"models\": [\n                \"anthropic/claude-3.5-sonnet\",\n                \"google/gemini-2.0-flash-exp:free\"\n            ]\n        },\n        messages=[{\"role\": \"user\", \"content\": \"Your prompt\"}]\n    )\nexcept Exception as e:\n    print(f\"All models failed: {e}\")\n```\n\n### Cost-Optimized Routing\n```python\n# Use cheaper models for simple tasks\nsimple_completion = client.chat.completions.create(\n    model=\"google/gemini-2.0-flash-exp:free\",\n    messages=[{\"role\": \"user\", \"content\": \"Simple question\"}]\n)\n\n# Use premium models for complex tasks\ncomplex_completion = client.chat.completions.create(\n    model=\"openai/o1\",\n    messages=[{\"role\": \"user\", \"content\": \"Complex reasoning task\"}]\n)\n```\n\n### Context-Aware Temperature\n```python\n# Low temperature for factual responses\nfactual = client.chat.completions.create(\n    model=\"openai/gpt-4o\",\n    temperature=0.2,\n    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n)\n\n# High temperature for creative content\ncreative = client.chat.completions.create(\n    model=\"openai/gpt-4o\",\n    temperature=1.2,\n    messages=[{\"role\": \"user\", \"content\": \"Write a unique story opening\"}]\n)\n```\n\n## Resources\n\n### Official Documentation\n- API Reference: https://openrouter.ai/docs/api-reference/overview\n- Quickstart Guide: https://openrouter.ai/docs/quickstart\n- Model List: https://openrouter.ai/docs/models\n- Parameters Guide: https://openrouter.ai/docs/api-reference/parameters\n\n### Key Endpoints\n- Chat Completions: `POST https://openrouter.ai/api/v1/chat/completions`\n- List Models: `GET https://openrouter.ai/api/v1/models`\n- Generation Info: `GET https://openrouter.ai/api/v1/generation`\n\n## Notes\n\n- OpenRouter normalizes API schemas across all providers\n- Uses OpenAI-compatible API format for easy migration\n- Automatic provider fallback if models are rate-limited or down\n- Pricing based on actual model used (important for fallbacks)\n- Response includes metadata about which model processed the request\n- All models support streaming via Server-Sent Events\n- Compatible with popular frameworks (LangChain, Vercel AI SDK, etc.)\n\n## Best Practices\n\n1. **Always implement fallbacks** for production applications\n2. **Use appropriate temperature** based on task type (low for factual, high for creative)\n3. **Set max_tokens** to control costs and response length\n4. **Enable streaming** for better user experience in chat applications\n5. **Use JSON mode** when you need guaranteed structured output\n6. **Test with seed parameter** for reproducible results during development\n7. **Monitor costs** by selecting appropriate models per task\n8. **Use auto-routing** when unsure which model performs best\n9. **Implement proper error handling** for rate limits and failures\n10. **Cache prompts** for repeated requests to reduce costs\n",
        "pinterest-api/SKILL.md": "---\nname: pinterest-api\ndescription: Pinterest API v5 Development - Authentication, Pins, Boards, Analytics\n---\n\n# Pinterest API Skill\n\nComprehensive assistance with Pinterest API v5 development, including OAuth authentication, pin/board management, analytics, and API integration patterns.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Implementing Pinterest OAuth 2.0 authentication flows\n- Creating, updating, or managing Pins and Boards via API\n- Integrating Pinterest analytics and metrics into applications\n- Building Pinterest API clients or SDKs\n- Working with Pinterest user account data\n- Debugging Pinterest API requests or responses\n- Implementing Pinterest sharing features in web/mobile apps\n- Setting up Pinterest business account integrations\n- Working with Pinterest ad account APIs\n\n## Key Concepts\n\n### Pinterest API v5 Overview\n- **Base URL**: `https://api.pinterest.com/v5/`\n- **Authentication**: OAuth 2.0 with access tokens\n- **Rate Limiting**: Token-based rate limits (varies by endpoint)\n- **Response Format**: JSON\n- **Required Headers**: `Authorization: Bearer {access_token}`\n\n### Core Resources\n- **Pins**: Individual pieces of content (images, videos) saved to Pinterest\n- **Boards**: Collections that organize Pins by theme or topic\n- **Sections**: Subsections within Boards for additional organization\n- **User Account**: Pinterest user profile and account information\n- **Ad Accounts**: Business accounts for advertising functionality\n\n### Access Levels\n- **Public Access**: Read-only access to public data\n- **User Authorization**: Full access to user's Pins, Boards, and account\n- **Business Access**: Additional analytics and ad account management (requires appropriate roles)\n\n## Quick Reference\n\n### OAuth 2.0 Authentication Flow\n\n#### Step 1: Generate Authorization URL\n```javascript\n// Redirect user to Pinterest authorization page\nconst authUrl = `https://www.pinterest.com/oauth/?client_id={CLIENT_ID}&redirect_uri={REDIRECT_URI}&response_type=code&scope=boards:read,pins:read,user_accounts:read`;\n\nwindow.location.href = authUrl;\n```\n\n#### Step 2: Exchange Code for Access Token\n```bash\n# After user authorizes, exchange authorization code for access token\ncurl -X POST https://api.pinterest.com/v5/oauth/token \\\n  --header \"Authorization: Basic {BASE64_ENCODED_CLIENT_CREDENTIALS}\" \\\n  --header \"Content-Type: application/x-www-form-urlencoded\" \\\n  --data-urlencode \"grant_type=authorization_code\" \\\n  --data-urlencode \"code={AUTHORIZATION_CODE}\" \\\n  --data-urlencode \"redirect_uri={REDIRECT_URI}\"\n```\n\n**Base64 Encoding Client Credentials:**\n```bash\n# Encode client_id:client_secret\necho -n \"your_client_id:your_client_secret\" | base64\n```\n\n**Response:**\n```json\n{\n  \"access_token\": \"pina_ABC123...\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 2592000,\n  \"refresh_token\": \"DEF456...\",\n  \"scope\": \"boards:read,pins:read,user_accounts:read\"\n}\n```\n\n### Pin Management\n\n#### Create a Pin\n```bash\ncurl -X POST https://api.pinterest.com/v5/pins \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"link\": \"https://example.com/my-article\",\n    \"title\": \"My Amazing Pin Title\",\n    \"description\": \"Detailed description of the pin content\",\n    \"board_id\": \"123456789\",\n    \"media_source\": {\n      \"source_type\": \"image_url\",\n      \"url\": \"https://example.com/image.jpg\"\n    }\n  }'\n```\n\n#### Get Pin Details\n```bash\ncurl -X GET https://api.pinterest.com/v5/pins/{PIN_ID} \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n```\n\n**Response:**\n```json\n{\n  \"id\": \"987654321\",\n  \"created_at\": \"2025-01-15T10:30:00\",\n  \"link\": \"https://example.com/my-article\",\n  \"title\": \"My Amazing Pin Title\",\n  \"description\": \"Detailed description of the pin content\",\n  \"board_id\": \"123456789\",\n  \"media\": {\n    \"media_type\": \"image\",\n    \"images\": {\n      \"150x150\": { \"url\": \"...\", \"width\": 150, \"height\": 150 },\n      \"400x300\": { \"url\": \"...\", \"width\": 400, \"height\": 300 },\n      \"originals\": { \"url\": \"...\", \"width\": 1200, \"height\": 800 }\n    }\n  }\n}\n```\n\n#### Update a Pin\n```bash\ncurl -X PATCH https://api.pinterest.com/v5/pins/{PIN_ID} \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"title\": \"Updated Pin Title\",\n    \"description\": \"Updated description\",\n    \"link\": \"https://example.com/updated-link\"\n  }'\n```\n\n#### Delete a Pin\n```bash\ncurl -X DELETE https://api.pinterest.com/v5/pins/{PIN_ID} \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n```\n\n### Board Management\n\n#### Create a Board\n```bash\ncurl -X POST https://api.pinterest.com/v5/boards \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"My New Board\",\n    \"description\": \"A collection of my favorite ideas\",\n    \"privacy\": \"PUBLIC\"\n  }'\n```\n\n**Privacy Options:** `PUBLIC`, `PROTECTED`, `SECRET`\n\n#### List User's Boards\n```bash\ncurl -X GET https://api.pinterest.com/v5/boards \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n```\n\n#### Get Board Pins\n```bash\ncurl -X GET https://api.pinterest.com/v5/boards/{BOARD_ID}/pins \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n```\n\n### User Account\n\n#### Get Current User Account\n```bash\ncurl -X GET https://api.pinterest.com/v5/user_account \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n```\n\n**Response:**\n```json\n{\n  \"account_type\": \"BUSINESS\",\n  \"id\": \"123456789\",\n  \"username\": \"myusername\",\n  \"website_url\": \"https://example.com\",\n  \"profile_image\": \"https://i.pinimg.com/...\",\n  \"follower_count\": 1500,\n  \"following_count\": 320,\n  \"board_count\": 25,\n  \"pin_count\": 450\n}\n```\n\n### Analytics\n\n#### Get Pin Analytics\n```bash\ncurl -X GET \"https://api.pinterest.com/v5/pins/{PIN_ID}/analytics?start_date=2025-01-01&end_date=2025-01-31&metric_types=IMPRESSION,SAVE,PIN_CLICK\" \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n```\n\n**Available Metrics:**\n- `IMPRESSION` - Number of times pin was shown\n- `SAVE` - Number of times pin was saved\n- `PIN_CLICK` - Number of clicks to pin destination\n- `OUTBOUND_CLICK` - Clicks to external website\n- `VIDEO_START` - Video plays started\n\n**Response:**\n```json\n{\n  \"all\": {\n    \"daily_metrics\": [\n      {\n        \"date\": \"2025-01-01\",\n        \"data_status\": \"READY\",\n        \"metrics\": {\n          \"IMPRESSION\": 1250,\n          \"SAVE\": 45,\n          \"PIN_CLICK\": 89\n        }\n      }\n    ]\n  }\n}\n```\n\n### Error Handling\n\n#### Common Error Response\n```json\n{\n  \"code\": 3,\n  \"message\": \"Requested pin not found\"\n}\n```\n\n**Common Error Codes:**\n- `1` - Invalid request parameters\n- `2` - Rate limit exceeded\n- `3` - Resource not found\n- `4` - Insufficient permissions\n- `8` - Invalid access token\n\n#### Python Error Handling Example\n```python\nimport requests\n\ndef create_pin(access_token, board_id, title, image_url):\n    url = \"https://api.pinterest.com/v5/pins\"\n    headers = {\n        \"Authorization\": f\"Bearer {access_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n    data = {\n        \"board_id\": board_id,\n        \"title\": title,\n        \"media_source\": {\n            \"source_type\": \"image_url\",\n            \"url\": image_url\n        }\n    }\n\n    try:\n        response = requests.post(url, headers=headers, json=data)\n        response.raise_for_status()\n        return response.json()\n    except requests.exceptions.HTTPError as e:\n        error_data = e.response.json()\n        print(f\"Error {error_data.get('code')}: {error_data.get('message')}\")\n        return None\n    except requests.exceptions.RequestException as e:\n        print(f\"Request failed: {str(e)}\")\n        return None\n```\n\n### JavaScript/Node.js Integration\n\n```javascript\n// Pinterest API Client Example\nclass PinterestClient {\n  constructor(accessToken) {\n    this.accessToken = accessToken;\n    this.baseUrl = 'https://api.pinterest.com/v5';\n  }\n\n  async request(endpoint, options = {}) {\n    const url = `${this.baseUrl}${endpoint}`;\n    const headers = {\n      'Authorization': `Bearer ${this.accessToken}`,\n      'Content-Type': 'application/json',\n      ...options.headers\n    };\n\n    const response = await fetch(url, {\n      ...options,\n      headers\n    });\n\n    if (!response.ok) {\n      const error = await response.json();\n      throw new Error(`Pinterest API Error: ${error.message}`);\n    }\n\n    return response.json();\n  }\n\n  async createPin(boardId, title, imageUrl, description = '', link = '') {\n    return this.request('/pins', {\n      method: 'POST',\n      body: JSON.stringify({\n        board_id: boardId,\n        title: title,\n        description: description,\n        link: link,\n        media_source: {\n          source_type: 'image_url',\n          url: imageUrl\n        }\n      })\n    });\n  }\n\n  async getUserBoards() {\n    return this.request('/boards');\n  }\n\n  async getPinAnalytics(pinId, startDate, endDate) {\n    const params = new URLSearchParams({\n      start_date: startDate,\n      end_date: endDate,\n      metric_types: 'IMPRESSION,SAVE,PIN_CLICK'\n    });\n    return this.request(`/pins/${pinId}/analytics?${params}`);\n  }\n}\n\n// Usage\nconst client = new PinterestClient('your_access_token');\nconst pin = await client.createPin('board_id', 'Pin Title', 'https://example.com/image.jpg');\n```\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete Pinterest API v5 endpoint reference extracted from official documentation\n\nUse `view` to read reference files when detailed information about specific endpoints is needed.\n\n## Working with This Skill\n\n### For Beginners\n1. Start by understanding OAuth 2.0 authentication flow (see Quick Reference above)\n2. Get your API credentials from Pinterest Developer Portal\n3. Test authentication with curl commands before implementing in your application\n4. Use the provided Python/JavaScript examples as starting templates\n\n### For API Integration\n1. Implement OAuth flow to obtain access tokens\n2. Store refresh tokens securely for long-term access\n3. Use the Pin/Board management examples for CRUD operations\n4. Implement proper error handling for rate limits and API errors\n\n### For Analytics & Business Features\n1. Ensure you have appropriate business account access\n2. Use analytics endpoints to track Pin performance\n3. Aggregate metrics across date ranges for reporting\n4. Implement caching to avoid unnecessary API calls\n\n### Best Practices\n- **Token Security**: Never expose access tokens in client-side code or version control\n- **Rate Limiting**: Implement exponential backoff for rate limit errors\n- **Pagination**: Use cursor-based pagination for large result sets\n- **Webhooks**: Consider using webhooks for real-time updates instead of polling\n- **Scopes**: Request only the minimum OAuth scopes needed for your application\n\n## Common Patterns\n\n### Pagination\n```bash\n# Initial request\ncurl -X GET \"https://api.pinterest.com/v5/boards/{BOARD_ID}/pins?page_size=25\" \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n\n# Follow-up with bookmark from response\ncurl -X GET \"https://api.pinterest.com/v5/boards/{BOARD_ID}/pins?page_size=25&bookmark={BOOKMARK}\" \\\n  -H \"Authorization: Bearer {ACCESS_TOKEN}\"\n```\n\n### Bulk Operations\n```python\n# Create multiple pins efficiently\ndef bulk_create_pins(access_token, board_id, pin_data_list):\n    results = []\n    for pin_data in pin_data_list:\n        result = create_pin(\n            access_token,\n            board_id,\n            pin_data['title'],\n            pin_data['image_url']\n        )\n        results.append(result)\n        time.sleep(0.5)  # Respect rate limits\n    return results\n```\n\n## Resources\n\n### Official Documentation\n- Pinterest API v5 Docs: https://developers.pinterest.com/docs/api/v5/\n- API Quickstart: https://github.com/pinterest/api-quickstart\n- OAuth Documentation: https://developers.pinterest.com/docs/getting-started/authentication/\n\n### OAuth Scopes\nCommon scopes you'll need:\n- `boards:read` - Read board data\n- `boards:write` - Create/update boards\n- `pins:read` - Read pin data\n- `pins:write` - Create/update pins\n- `user_accounts:read` - Read user account data\n- `ads:read` - Read ad account analytics (business accounts)\n\n### Rate Limits\n- Pinterest implements per-user rate limiting\n- Typical limits: 1000 requests per hour per user\n- Rate limit headers in response:\n  - `X-RateLimit-Limit`\n  - `X-RateLimit-Remaining`\n  - `X-RateLimit-Reset`\n\n## Notes\n\n- Pinterest API v5 is the current version (as of 2025)\n- All endpoints require authentication via OAuth 2.0\n- Access tokens expire after 30 days\n- Use refresh tokens to obtain new access tokens\n- Business accounts have access to additional analytics features\n- Video pins require special handling compared to image pins\n- Some features require app review by Pinterest\n\n## Troubleshooting\n\n### \"Invalid access token\"\n- Verify token hasn't expired (30-day lifetime)\n- Use refresh token to obtain new access token\n- Check Authorization header format: `Bearer {token}`\n\n### \"Insufficient permissions\"\n- Verify OAuth scopes include required permissions\n- Business features require verified business account\n- Some operations require board/pin ownership\n\n### \"Rate limit exceeded\"\n- Implement exponential backoff\n- Cache responses when possible\n- Use webhooks instead of polling\n- Check `X-RateLimit-Reset` header for retry time\n\n### \"Media upload failed\"\n- Verify image URL is publicly accessible\n- Check image meets size requirements (max 10MB)\n- Ensure image format is supported (JPG, PNG, GIF)\n- For video, use video-specific endpoints\n\n## Updating\n\nThis skill was generated from Pinterest's official API documentation. To get the latest API changes:\n1. Visit https://developers.pinterest.com/docs/api/v5/\n2. Check changelog for API updates\n3. Review deprecation notices\n4. Update OAuth scopes if new features added\n",
        "presumption-guard/README.md": "# Presumption Guard\n\nA Claude Code plugin that detects and flags presumptive actions after they occur.\n\n## What It Does\n\nThis plugin adds a Stop hook that reviews every completed response for **presumptive behavior**. It doesn't prevent the action - it makes it absolutely clear when one has taken place.\n\nThe hook distinguishes between:\n\n- **Presumption to ask** (acceptable): Asking clarifying questions, seeking input, discussing options\n- **Presumption to act** (violation): Taking actions or making decisions without explicit permission\n\n## How It Works\n\nWhen Claude's response completes, the Stop hook triggers a review that evaluates:\n\n1. **Unrequested actions** - Did it perform edits, writes, or executions that were NOT explicitly requested?\n2. **Unverified certainty** - Did it claim certainty about facts without verifying first?\n3. **Stolen decisions** - Did it make decisions that belong to the user without asking first?\n4. **Workflow deviation** - Did it deviate from explicit workflow instructions?\n\n## What's NOT a Violation\n\n- Asking questions\n- Seeking clarification\n- Discussing options when no specific workflow was given\n- Following explicit instructions\n\n## Installation\n\nEnable the plugin in your Claude Code settings:\n\n```json\n{\n  \"enabledPlugins\": {\n    \"presumption-guard@skillsforge-marketplace\": true\n  }\n}\n```\n\n## Origin\n\nThis plugin emerged from a direct lesson about agency and accountability: taking choices that belong to others is theft. The pause to ask is not inefficiency - it prevents compounding harm.\n\n## License\n\nMIT\n",
        "replicate-cli/SKILL.md": "---\nname: replicate-cli\ndescription: This skill provides comprehensive guidance for using the Replicate CLI to run AI models, create predictions, manage deployments, and fine-tune models. Use this skill when the user wants to interact with Replicate's AI model platform via command line, including running image generation models, language models, or any ML model hosted on Replicate. This skill should be used when users ask about running models on Replicate, creating predictions, managing deployments, fine-tuning models, or working with the Replicate API through the CLI.\n---\n\n# Replicate CLI\n\nThe Replicate CLI is a command-line tool for interacting with Replicate's AI model platform. It enables running predictions, managing models, creating deployments, and fine-tuning models directly from the terminal.\n\n## Authentication\n\nBefore using the Replicate CLI, set the API token:\n\n```bash\nexport REPLICATE_API_TOKEN=<token-from-replicate.com/account>\n```\n\nAlternatively, authenticate interactively:\n\n```bash\nreplicate auth login\n```\n\nVerify authentication:\n\n```bash\nreplicate account current\n```\n\n## Core Commands\n\n### Running Predictions\n\nThe primary use case is running predictions against hosted models.\n\n**Basic prediction:**\n```bash\nreplicate run <owner/model> input_key=value\n```\n\n**Examples:**\n\nImage generation:\n```bash\nreplicate run stability-ai/sdxl prompt=\"a studio photo of a rainbow colored corgi\"\n```\n\nText generation with streaming:\n```bash\nreplicate run meta/llama-2-70b-chat --stream prompt=\"Tell me a joke\"\n```\n\n**Prediction flags:**\n- `--stream` - Stream output tokens in real-time (for text models)\n- `--no-wait` - Submit prediction without waiting for completion\n- `--web` - Open prediction in browser\n- `--json` - Output result as JSON\n- `--save` - Save outputs to local directory\n- `--output-directory <dir>` - Specify output directory (default: `./{prediction-id}`)\n\n### Input Handling\n\n**File uploads:** Prefix local file paths with `@`:\n```bash\nreplicate run nightmareai/real-esrgan image=@photo.jpg\n```\n\n**Output chaining:** Use `{{.output}}` template syntax to chain predictions:\n```bash\nreplicate run stability-ai/sdxl prompt=\"a corgi\" | \\\nreplicate run nightmareai/real-esrgan image={{.output[0]}}\n```\n\n### Model Operations\n\n**View model schema** (see required inputs and outputs):\n```bash\nreplicate model schema <owner/model>\nreplicate model schema stability-ai/sdxl --json\n```\n\n**List models:**\n```bash\nreplicate model list\nreplicate model list --json\n```\n\n**Show model details:**\n```bash\nreplicate model show <owner/model>\n```\n\n**Create a new model:**\n```bash\nreplicate model create <owner/name> \\\n  --hardware gpu-a100-large \\\n  --private \\\n  --description \"Model description\"\n```\n\nModel creation flags:\n- `--hardware <sku>` - Hardware SKU (see `references/hardware.md`)\n- `--private` / `--public` - Visibility setting\n- `--description <text>` - Model description\n- `--github-url <url>` - Link to source repository\n- `--license-url <url>` - License information\n- `--cover-image-url <url>` - Cover image for model page\n\n### Training (Fine-tuning)\n\nFine-tune models using the training command:\n\n```bash\nreplicate train <base-model> \\\n  --destination <owner/new-model> \\\n  input_key=value\n```\n\n**Example - Fine-tune SDXL with DreamBooth:**\n```bash\nreplicate train stability-ai/sdxl \\\n  --destination myuser/custom-sdxl \\\n  --web \\\n  input_images=@training-images.zip \\\n  use_face_detection_instead=true\n```\n\n**List trainings:**\n```bash\nreplicate training list\n```\n\n**Show training details:**\n```bash\nreplicate training show <training-id>\n```\n\n### Deployments\n\nDeployments provide dedicated, always-on inference endpoints with predictable performance.\n\n**Create deployment:**\n```bash\nreplicate deployments create <name> \\\n  --model <owner/model> \\\n  --hardware <sku> \\\n  --min-instances 1 \\\n  --max-instances 3\n```\n\n**Example:**\n```bash\nreplicate deployments create text-to-image \\\n  --model stability-ai/sdxl \\\n  --hardware gpu-a100-large \\\n  --min-instances 1 \\\n  --max-instances 5\n```\n\n**Update deployment:**\n```bash\nreplicate deployments update <name> \\\n  --max-instances 10 \\\n  --version <version-id>\n```\n\n**List deployments:**\n```bash\nreplicate deployments list\n```\n\n**Show deployment details and schema:**\n```bash\nreplicate deployments show <name>\nreplicate deployments schema <name>\n```\n\n### Hardware\n\nList available hardware options:\n```bash\nreplicate hardware list\n```\n\nSee `references/hardware.md` for detailed hardware information and selection guidelines.\n\n### Scaffolding\n\nCreate a local development environment from an existing prediction:\n\n```bash\nreplicate scaffold <prediction-id-or-url> --template=<node|python>\n```\n\nThis generates a project with the prediction's model and inputs pre-configured.\n\n## Command Aliases\n\nFor convenience, these aliases are available:\n\n| Alias | Equivalent Command |\n|-------|-------------------|\n| `replicate run` | `replicate prediction create` |\n| `replicate stream` | `replicate prediction create --stream` |\n| `replicate train` | `replicate training create` |\n\nShort aliases for subcommands:\n- `replicate m` = `replicate model`\n- `replicate p` = `replicate prediction`\n- `replicate t` = `replicate training`\n- `replicate d` = `replicate deployments`\n- `replicate hw` = `replicate hardware`\n- `replicate a` = `replicate account`\n\n## Common Workflows\n\n### Image Generation Pipeline\n\nGenerate an image and upscale it:\n```bash\nreplicate run stability-ai/sdxl \\\n  prompt=\"professional photo of a sunset\" \\\n  negative_prompt=\"blurry, low quality\" | \\\nreplicate run nightmareai/real-esrgan \\\n  image={{.output[0]}} \\\n  --save\n```\n\n### Check Model Inputs Before Running\n\nAlways check the model schema to understand required inputs:\n```bash\nreplicate model schema owner/model-name\n```\n\n### Batch Processing\n\nRun predictions and save outputs:\n```bash\nfor prompt in \"cat\" \"dog\" \"bird\"; do\n  replicate run stability-ai/sdxl prompt=\"$prompt\" --save --output-directory \"./outputs/$prompt\"\ndone\n```\n\n### Monitor Long-Running Tasks\n\nSubmit without waiting, then check status:\n```bash\n# Submit\nreplicate run owner/model input=value --no-wait --json > prediction.json\n\n# Check status later\nreplicate prediction show $(jq -r '.id' prediction.json)\n```\n\n## Best Practices\n\n1. **Always check schema first** - Run `replicate model schema <model>` to understand required and optional inputs before running predictions.\n\n2. **Use streaming for text models** - Add `--stream` flag when running language models to see output in real-time.\n\n3. **Save outputs explicitly** - Use `--save` and `--output-directory` to organize prediction outputs.\n\n4. **Use JSON output for automation** - Add `--json` flag when parsing outputs programmatically.\n\n5. **Open in web for debugging** - Add `--web` flag to view predictions in the Replicate dashboard for detailed logs.\n\n6. **Chain predictions efficiently** - Use the `{{.output}}` syntax to pass outputs between models without intermediate saves.\n\n## Troubleshooting\n\n**Authentication errors:**\n- Verify `REPLICATE_API_TOKEN` is set correctly\n- Run `replicate account current` to test authentication\n\n**Model not found:**\n- Check model name format: `owner/model-name`\n- Verify model exists at replicate.com\n\n**Input validation errors:**\n- Run `replicate model schema <model>` to see required inputs\n- Check input types (string, number, file)\n\n**File upload issues:**\n- Ensure `@` prefix is used for local files\n- Verify file path is correct and file exists\n\n## Additional Resources\n\n- Replicate documentation: https://replicate.com/docs\n- Model explorer: https://replicate.com/explore\n- API reference: https://replicate.com/docs/reference/http\n- GitHub repository: https://github.com/replicate/cli\n",
        "revenuecat/SKILL.md": "---\nname: revenuecat\ndescription: Comprehensive assistance with RevenueCat in-app subscriptions and purchases\n---\n\n# RevenueCat Skill\n\nExpert assistance for implementing in-app subscriptions and purchases using RevenueCat across iOS, Android, Flutter, React Native, and web platforms.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n\n- **SDK Setup**: Initializing RevenueCat SDK in iOS, Android, Flutter, or React Native apps\n- **Subscription Implementation**: Adding subscription or in-app purchase functionality\n- **Entitlement Checks**: Verifying user access to premium features or content\n- **Purchase Flow**: Implementing buy buttons, handling transactions, or processing purchases\n- **Restore Purchases**: Adding restore functionality for users switching devices\n- **Offerings/Products**: Fetching and displaying subscription options or product catalogs\n- **Paywall Design**: Building or configuring paywalls and purchase screens\n- **Customer Info**: Retrieving subscription status or customer data\n- **Debugging Purchases**: Troubleshooting subscription issues or transaction failures\n- **REST API Integration**: Server-side subscription validation or webhook handling\n\n## Quick Reference\n\n### SDK Configuration\n\n**Swift (iOS)**\n```swift\nimport RevenueCat\n\nPurchases.logLevel = .debug\nPurchases.configure(withAPIKey: \"your_public_api_key\", appUserID: \"user_123\")\n```\n\n**Kotlin (Android)**\n```kotlin\nPurchases.logLevel = LogLevel.DEBUG\nPurchases.configure(PurchasesConfiguration.Builder(this, \"your_public_api_key\").build())\n```\n\n**Flutter**\n```dart\nawait Purchases.setLogLevel(LogLevel.debug);\nPurchasesConfiguration configuration = PurchasesConfiguration(\"your_public_api_key\");\nawait Purchases.configure(configuration);\n```\n\n**React Native**\n```javascript\nPurchases.setLogLevel(Purchases.LOG_LEVEL.DEBUG);\nPurchases.configure({ apiKey: \"your_public_api_key\" });\n```\n\n### Checking Entitlements\n\n**Swift**\n```swift\nlet customerInfo = try await Purchases.shared.customerInfo()\nif customerInfo.entitlements[\"pro\"]?.isActive == true {\n    // User has premium access\n}\n```\n\n**Kotlin**\n```kotlin\nPurchases.sharedInstance.getCustomerInfoWith(\n    onSuccess = { customerInfo ->\n        if (customerInfo.entitlements[\"pro\"]?.isActive == true) {\n            // User has premium access\n        }\n    }\n)\n```\n\n**React Native**\n```javascript\nconst customerInfo = await Purchases.getCustomerInfo();\nif (customerInfo.entitlements.active[\"pro\"] !== undefined) {\n    // User has premium access\n}\n```\n\n### Fetching Offerings\n\n**Swift**\n```swift\nPurchases.shared.getOfferings { (offerings, error) in\n    if let packages = offerings?.current?.availablePackages {\n        self.display(packages)\n    }\n}\n```\n\n**Kotlin**\n```kotlin\nPurchases.sharedInstance.getOfferingsWith({ error -> }) { offerings ->\n    offerings.current?.availablePackages?.let { packages ->\n        // Display packages\n    }\n}\n```\n\n### Making a Purchase\n\n**Swift**\n```swift\nPurchases.shared.purchase(package: package) { (transaction, customerInfo, error, userCancelled) in\n    if customerInfo.entitlements[\"pro\"]?.isActive == true {\n        // Unlock premium content\n    }\n}\n```\n\n**Kotlin**\n```kotlin\nPurchases.sharedInstance.purchase(\n    packageToPurchase = aPackage,\n    onError = { error, userCancelled -> },\n    onSuccess = { storeTransaction, customerInfo ->\n        if (customerInfo.entitlements[\"pro\"]?.isActive == true) {\n            // Unlock premium content\n        }\n    }\n)\n```\n\n### Restoring Purchases\n\n**Swift**\n```swift\nPurchases.shared.restorePurchases { customerInfo, error in\n    // Check customerInfo to see if entitlement is now active\n}\n```\n\n**Kotlin**\n```kotlin\nPurchases.sharedInstance.restorePurchases(\n    onError = { error -> },\n    onSuccess = { customerInfo ->\n        // Check customerInfo to see if entitlement is now active\n    }\n)\n```\n\n### REST API - Get Customer Info\n\n```bash\ncurl --request GET \\\n  --url https://api.revenuecat.com/v1/subscribers/app_user_id \\\n  --header 'Authorization: Bearer PUBLIC_API_KEY'\n```\n\n## Key Concepts\n\n### Entitlements\nA level of access, features, or content that a user is \"entitled\" to. Most apps use a single entitlement (e.g., \"pro\"). Created in the RevenueCat dashboard and linked to products. When a product is purchased, its associated entitlements become active.\n\n### Offerings\nThe set of products available to a user. Configured remotely in the dashboard, allowing you to change available products without app updates. Access via `offerings.current` for the default offering.\n\n### Packages\nContainers for products within an offering. Include convenience accessors like `.monthly`, `.annual`, `.lifetime`. Each package contains a `storeProduct` with pricing details.\n\n### CustomerInfo\nThe central object containing all subscription and purchase data for a user. Retrieved via `getCustomerInfo()` or returned after purchases. Contains the `entitlements` dictionary for access checks.\n\n### App User ID\nUnique identifier for each user. Can be provided during configuration or auto-generated as an anonymous ID. Used to sync purchases across devices.\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - General RevenueCat documentation and overview\n\nFor detailed implementation patterns beyond the quick reference, consult the official documentation at https://www.revenuecat.com/docs/\n\n## Working with This Skill\n\n### For Beginners\n1. Start by configuring the SDK in your app's initialization code\n2. Create entitlements and offerings in the RevenueCat dashboard\n3. Implement a simple entitlement check before showing premium content\n4. Add a purchase button using `purchase(package:)`\n5. Include a \"Restore Purchases\" button for App Store compliance\n\n### For Intermediate Users\n- Implement dynamic paywalls by fetching offerings and displaying packages\n- Handle multiple entitlements for tiered access levels\n- Set up customer info listeners for real-time subscription updates\n- Use the REST API for server-side validation\n\n### For Advanced Users\n- Configure webhooks for server-side event handling\n- Implement A/B testing with different offerings\n- Set up integrations with analytics and attribution platforms\n- Handle edge cases like grace periods and billing retry\n\n## Common Patterns\n\n### Paywall Display Logic\n```swift\n// Show paywall only if user doesn't have active subscription\nif customerInfo.entitlements[\"pro\"]?.isActive != true {\n    showPaywall()\n}\n```\n\n### Conditional Offerings\n```swift\nif user.isPaidDownload {\n    packages = offerings?.offering(identifier: \"paid_download_offer\")?.availablePackages\n} else {\n    packages = offerings?.current?.availablePackages\n}\n```\n\n## Important Notes\n\n- Always initialize the SDK early in your app's lifecycle\n- Use debug logging during development (`Purchases.logLevel = .debug`)\n- The SDK automatically finishes/acknowledges transactions\n- Only call `restorePurchases` from user interaction (like a button tap)\n- Use public API keys from Project Settings; never expose secret keys\n- Test Store allows development testing without real charges\n\n## Resources\n\n### Official Documentation\n- Getting Started: https://www.revenuecat.com/docs/getting-started/quickstart\n- SDK Reference: https://www.revenuecat.com/docs/\n- REST API: https://docs.revenuecat.com/reference\n\n### references/\nOrganized documentation extracted from official sources with detailed explanations and code examples.\n\n### scripts/\nAdd helper scripts here for common automation tasks.\n\n### assets/\nAdd templates, boilerplate, or example projects here.\n",
        "skill-extractor/README.md": "# Skill Extractor\n\nA comprehensive tool for analyzing Claude Code commands and agents, identifying reusable components, and extracting them into properly structured skills.\n\n## Overview\n\nThe Skill Extractor helps you:\n- Analyze existing commands/agents for extractable components\n- Identify scripts, references, and assets that should be separated\n- Create properly structured skills with migration guidance\n- Validate skill structure and packaging for distribution\n- Refactor monolithic commands into modular, reusable skills\n\n## Quick Start\n\n### 1. Analyze a Command or Agent\n\n```bash\n./scripts/skill-extract.sh analyze ~/.claude/commands/mine/novel-planner.md --verbose\n```\n\nThis will:\n- Scan the file for extractable components\n- Identify scripts, references, and assets\n- Calculate extraction potential\n- Save results to `analysis.json`\n\n### 2. Extract Components\n\n```bash\n./scripts/skill-extract.sh extract analysis.json --name novel-planning-templates\n```\n\nThis will:\n- Create the skill directory structure\n- Extract components to appropriate locations\n- Generate SKILL.md\n- Create a detailed migration report\n\n### 3. One-Step Process\n\n```bash\n./scripts/skill-extract.sh full ~/.claude/agents/mine/article-forge.md \\\n    --name writing-tools \\\n    --output ./skills\n```\n\nThis combines analysis and extraction in one command.\n\n### 4. Package for Distribution\n\n```bash\npython3 scripts/package_skill.py ./writing-tools\n```\n\nThis will:\n- Validate the skill structure\n- Check YAML frontmatter and naming conventions\n- Create a distributable zip package\n- Provide installation instructions\n\n## What Gets Extracted?\n\n### Scripts (`scripts/` directory)\n- Code blocks with >20 lines\n- Reusable processing logic\n- Utility functions\n- Shell command sequences\n\n**Example**: Data processing pipelines, file manipulation utilities, report generators\n\n### References (`references/` directory)\n- Documentation >500 words\n- Style guides\n- Format specifications\n- Comprehensive examples\n\n**Example**: Writing style guides, API documentation, template specifications\n\n### Assets (`assets/` directory)\n- Templates and boilerplate\n- Configuration examples\n- Report structures\n- Project scaffolding\n\n**Example**: Report templates, character profile templates, configuration files\n\n## Directory Structure\n\nAfter extraction:\n\n```\n{skill-name}/\n‚îú‚îÄ‚îÄ SKILL.md                    # Main skill definition with frontmatter\n‚îú‚îÄ‚îÄ scripts/                    # Executable scripts (if any)\n‚îÇ   ‚îú‚îÄ‚îÄ process_data.py\n‚îÇ   ‚îî‚îÄ‚îÄ generate_report.sh\n‚îú‚îÄ‚îÄ references/                 # Reference documentation (if any)\n‚îÇ   ‚îú‚îÄ‚îÄ style-guide.md\n‚îÇ   ‚îî‚îÄ‚îÄ api-spec.md\n‚îú‚îÄ‚îÄ assets/                     # Templates and resources (if any)\n‚îÇ   ‚îú‚îÄ‚îÄ report-template.md\n‚îÇ   ‚îî‚îÄ‚îÄ config-example.yaml\n‚îî‚îÄ‚îÄ migration-report.md         # Detailed integration instructions\n```\n\n## Usage Examples\n\n### Example 1: Extract Templates from Novel Planner\n\n```bash\n# Analyze the novel-planner command\n./scripts/skill-extract.sh analyze ~/.claude/commands/mine/novel-planner.md\n\n# Review the analysis\ncat analysis.json\n\n# Extract identified components\n./scripts/skill-extract.sh extract analysis.json \\\n    --name novel-planning-templates \\\n    --output ~/my-skills\n```\n\n**Result**: Creates `novel-planning-templates` skill with:\n- `assets/character-profile.md`\n- `assets/chapter-blueprint.md`\n- `assets/scene-card.md`\n- Detailed migration report\n\n### Example 2: Extract Analysis Tools from Agent\n\n```bash\n# One-step extraction from agent\n./scripts/skill-extract.sh full ~/.claude/agents/mine/show-tell-analyzer.md \\\n    --name narrative-analysis-tools \\\n    --verbose\n```\n\n**Result**: Creates `narrative-analysis-tools` skill with:\n- `scripts/analyze_show_tell.py`\n- `scripts/generate_heatmap.py`\n- `references/analysis-methodology.md`\n\n### Example 3: Batch Analysis\n\n```bash\n# Analyze all commands\nfor file in ~/.claude/commands/mine/*.md; do\n    echo \"Analyzing: $(basename \"$file\")\"\n    ./scripts/skill-extract.sh analyze \"$file\" > \"$(basename \"$file\" .md)-analysis.json\"\ndone\n\n# Review analyses and extract selectively\n```\n\n## Migration Process\n\nAfter extraction:\n\n1. **Review the Migration Report**\n   ```bash\n   cat {skill-name}/migration-report.md\n   ```\n\n2. **Update Original File**\n   - Replace embedded content with skill references\n   - Update script execution commands\n   - Reference documentation locations\n   - Point to template assets\n\n3. **Test Functionality**\n   - Verify all scripts execute\n   - Confirm references load correctly\n   - Test template usage\n   - Ensure original functionality preserved\n\n4. **Update Documentation**\n   - Document skill dependency\n   - Update usage instructions\n   - Note new file locations\n\n## Packaging and Distribution\n\nAfter creating and validating a skill, you can package it for distribution:\n\n### Validate Skill Structure\n\n```bash\npython3 scripts/package_skill.py ./my-extracted-skill --validate-only\n```\n\nThis checks:\n- SKILL.md exists with valid YAML frontmatter\n- Required fields: `name` and `description`\n- Proper directory structure\n- Script executability and naming conventions\n- Bundled resources (scripts/, references/, assets/)\n\n### Create Distribution Package\n\n```bash\npython3 scripts/package_skill.py ./my-extracted-skill --output ./packages\n```\n\nCreates a `.zip` file containing:\n- Complete skill directory structure\n- All bundled resources\n- Proper permissions preserved\n- Installation instructions\n\n### Install Packaged Skill\n\n```bash\n# Extract to Claude Code skills directory\nunzip my-extracted-skill.zip -d ~/.claude/skills/\n\n# Or create development symlink\nln -s /path/to/my-extracted-skill ~/.claude/skills/my-extracted-skill\n```\n\n## Command Reference\n\n### Analyze Command\n\n```bash\n./scripts/skill-extract.sh analyze <input-file> [options]\n```\n\nOptions:\n- `-v, --verbose` - Show detailed analysis output\n- `-o, --output FILE` - Save analysis to specific file (default: analysis.json)\n\n### Extract Command\n\n```bash\n./scripts/skill-extract.sh extract <analysis-file> [options]\n```\n\nRequired:\n- `--name <skill-name>` - Name for the extracted skill\n\nOptions:\n- `-o, --output DIR` - Output directory (default: current directory)\n\n### Full Command\n\n```bash\n./scripts/skill-extract.sh full <input-file> [options]\n```\n\nRequired:\n- `--name <skill-name>` - Name for the extracted skill\n\nOptions:\n- `-o, --output DIR` - Output directory (default: current directory)\n- `-v, --verbose` - Show detailed progress\n\n## Python Scripts\n\n### analyze_command.py\n\nDirect usage:\n\n```bash\npython3 scripts/analyze_command.py ~/.claude/commands/mine/example.md \\\n    --output analysis.json \\\n    --verbose\n```\n\n### extract_components.py\n\nDirect usage:\n\n```bash\npython3 scripts/extract_components.py analysis.json \\\n    --name my-skill \\\n    --output ./skills\n```\n\n### package_skill.py\n\nValidates skill structure and creates distributable zip packages:\n\n```bash\npython3 scripts/package_skill.py path/to/skill-directory [options]\n```\n\nOptions:\n- `-o, --output DIR` - Output directory for package (default: current directory)\n- `--validate-only` - Only validate, don't create package\n- `--skip-validation` - Skip validation and create package directly\n\nExample:\n\n```bash\n# Validate and package a skill\npython3 scripts/package_skill.py ./novel-planning-templates\n\n# Validate only (no package creation)\npython3 scripts/package_skill.py ./my-skill --validate-only\n\n# Package without validation\npython3 scripts/package_skill.py ./my-skill --skip-validation --output ./packages\n```\n\nThe script performs comprehensive validation:\n- Checks for required SKILL.md file\n- Validates YAML frontmatter (name and description fields)\n- Verifies directory structure\n- Checks script permissions and naming conventions\n- Creates a zip package with proper structure\n\n## Configuration\n\n### Size Thresholds\n\nEdit `scripts/analyze_command.py` to adjust:\n\n```python\nMIN_SCRIPT_LINES = 20      # Minimum lines for script extraction\nMIN_REFERENCE_WORDS = 500  # Minimum words for reference extraction\nMIN_ASSET_SIZE = 100       # Minimum characters for asset extraction\n```\n\n### Confidence Scoring\n\nExtracted components receive confidence scores (0.0-1.0):\n- **0.8-1.0**: High confidence - clearly extractable\n- **0.6-0.8**: Medium confidence - likely extractable\n- **0.4-0.6**: Low confidence - borderline\n- **<0.4**: Don't extract\n\n## Best Practices\n\n### When to Extract\n\n‚úÖ **DO Extract**:\n- Large reference documentation (>1000 words)\n- Reusable scripts (>50 lines)\n- Standard templates\n- Stable, well-defined components\n\n‚ùå **DON'T Extract**:\n- Core workflow logic\n- Small snippets (<20 lines)\n- Tightly coupled code\n- Volatile/experimental code\n\n### Naming Conventions\n\n**Skills**: Use kebab-case\n- `novel-planning-templates`\n- `data-processing-utils`\n- `narrative-analysis-tools`\n\n**Scripts**: Use snake_case\n- `process_data.py`\n- `generate_report.py`\n- `analyze_text.py`\n\n**References**: Use kebab-case\n- `style-guide.md`\n- `api-specification.md`\n- `best-practices.md`\n\n**Assets**: Use descriptive names\n- `report-template.md`\n- `character-profile.md`\n- `config-example.yaml`\n\n## Troubleshooting\n\n### Analysis finds nothing\n\n**Cause**: File might be too small or well-structured already\n**Solution**: Check size thresholds; review with `--verbose`\n\n### Extraction fails\n\n**Cause**: Invalid analysis file or permission issues\n**Solution**: Verify analysis.json is valid; check write permissions\n\n### Components not working after extraction\n\n**Cause**: Dependencies not properly resolved\n**Solution**: Review migration report; check file paths\n\n### Original file breaks after migration\n\n**Cause**: Incomplete migration or incorrect references\n**Solution**: Follow migration report exactly; test incrementally\n\n### Package validation fails\n\n**Cause**: Missing SKILL.md, invalid frontmatter, or incorrect structure\n**Solution**: Ensure SKILL.md exists with required `name` and `description` fields; check directory structure matches skill standards\n\n### Packaged skill won't install\n\n**Cause**: Incorrect zip structure or missing files\n**Solution**: Verify zip contains skill directory with all components; check SKILL.md frontmatter is valid YAML\n\n## Reference Documentation\n\n- **Skill Patterns**: `references/skill-patterns.md` - Pattern recognition guide\n- **Extraction Criteria**: `references/extraction-criteria.md` - When and how to extract\n\n## Contributing\n\nTo improve the skill extractor:\n\n1. **Enhance Pattern Matching**: Update patterns in `analyze_command.py`\n2. **Refine Criteria**: Adjust thresholds and scoring\n3. **Add Templates**: Create additional asset templates\n4. **Improve Reports**: Enhance migration report generation\n\n## Integration with Skill Creator\n\nThis skill works alongside the `skill-creator` skill:\n\n- **skill-extractor**: Refactors existing commands/agents\n- **skill-creator**: Creates new skills from scratch\n- **Together**: Build a comprehensive skill ecosystem\n\n## License\n\nPart of the Claude Code skills ecosystem.\n\n## Support\n\nFor issues or questions:\n1. Review the migration report\n2. Check reference documentation\n3. Examine example extractions\n4. Validate analysis output\n\n---\n\n**Remember**: The Skill Extractor is non-destructive. Your original files remain unchanged. Always test extracted skills before removing original content.\n",
        "skill-extractor/SKILL.md": "# Skill Extractor\n\n---\nname: skill-extractor\ndescription: Analyzes Claude Code commands and agents to identify and extract reusable components into properly structured skills with migration reports\n---\n\n## Purpose\n\nThis skill analyzes existing Claude Code commands and agents to identify reusable components that should be extracted into standalone skills. It creates properly structured skills following Claude Code conventions while preserving the original files and providing detailed migration guidance.\n\n## When to Use\n\nUse this skill when you:\n- Have commands or agents with embedded templates, reference materials, or reusable scripts\n- Want to modularize large, complex commands/agents\n- Need to identify opportunities for code reuse across your Claude Code ecosystem\n- Want to refactor commands/agents to follow skill-based architecture\n\n## How It Works\n\nThe skill performs comprehensive analysis to identify extractable components:\n\n### 1. Component Analysis\n\nThe analyzer scans for:\n\n**Scripts Candidates (`scripts/` directory)**:\n- Repeated code blocks that execute deterministic operations\n- Shell scripts, Python scripts, or other executables\n- File manipulation utilities\n- Processing pipelines\n\n**Reference Material (`references/` directory)**:\n- Templates and format specifications\n- Style guides and writing standards\n- Documentation that should be loaded on-demand\n- Large reference tables or datasets\n- API specifications\n\n**Assets (`assets/` directory)**:\n- Template files used in output generation\n- Boilerplate code or project structures\n- Images, fonts, or design resources\n- Example files or starter kits\n\n**Core Workflow (stays in SKILL.md)**:\n- Primary procedural instructions\n- Workflow orchestration\n- Decision trees and logic\n- User interaction patterns\n\n### 2. Extraction Process\n\nWhen you invoke the skill with a command or agent file path:\n\n```bash\n# Analyze and extract from a command\n@skill-extractor analyze --input ~/.claude/commands/mine/agent-forge.md\n\n# Analyze and extract from an agent\n@skill-extractor analyze --input ~/.claude/agents/mine/novel-chapter-writer.md\n\n# Batch analyze multiple files\n@skill-extractor analyze --input ~/.claude/commands/mine/*.md\n```\n\nThe skill will:\n\n1. **Parse** the input file to understand structure and content\n2. **Identify** extractable components using pattern matching\n3. **Extract** components into appropriate directories\n4. **Generate** the skill structure with proper SKILL.md\n5. **Create** migration report detailing required changes\n\n### 3. Output Structure\n\nAll extracted skills are created in the current working directory:\n\n```\n{current_working_directory}/\n‚îî‚îÄ‚îÄ {extracted-skill-name}/\n    ‚îú‚îÄ‚îÄ SKILL.md                    # Main skill definition\n    ‚îú‚îÄ‚îÄ scripts/                    # Executable scripts (if applicable)\n    ‚îÇ   ‚îî‚îÄ‚îÄ example_script.py\n    ‚îú‚îÄ‚îÄ references/                 # Reference documentation (if applicable)\n    ‚îÇ   ‚îú‚îÄ‚îÄ templates.md\n    ‚îÇ   ‚îî‚îÄ‚îÄ style-guide.md\n    ‚îú‚îÄ‚îÄ assets/                     # Output resources (if applicable)\n    ‚îÇ   ‚îî‚îÄ‚îÄ template.txt\n    ‚îî‚îÄ‚îÄ migration-report.md         # Detailed migration instructions\n```\n\n## Analysis Methodology\n\n### Pattern Recognition\n\nThe analyzer uses sophisticated pattern matching to identify:\n\n**Template Patterns**:\n- Markdown code blocks with repeated structure\n- YAML/JSON configuration templates\n- Format specifications and examples\n- Document structure definitions\n\n**Reference Documentation**:\n- Large explanatory blocks (>1000 words)\n- Style guides and conventions\n- Comprehensive lists and tables\n- API documentation sections\n\n**Script Candidates**:\n- Bash command sequences\n- Python code blocks\n- File processing operations\n- Deterministic workflows\n\n**Workflow Logic** (remains in SKILL.md):\n- Conditional decision points\n- User interaction flows\n- Orchestration steps\n- High-level procedures\n\n### Extraction Criteria\n\nComponents are extracted when they meet these criteria:\n\n1. **Reusability**: Used or could be used in multiple contexts\n2. **Size**: Large enough to warrant separation (scripts >50 lines, references >500 words)\n3. **Independence**: Can function standalone without core workflow context\n4. **Stability**: Unlikely to change with each workflow execution\n\n## Migration Report\n\nThe migration report provides step-by-step guidance for updating the original command/agent:\n\n```markdown\n# Migration Report: {Original File Name}\n\n## Executive Summary\n- **Extraction Date**: [timestamp]\n- **Components Extracted**: [count]\n- **Original File Size**: [size]\n- **New Skill Size**: [size]\n- **Reduction**: [percentage]\n\n## Extracted Components\n\n### 1. Scripts Extracted\n- **Location**: `scripts/process_data.py`\n- **Original Lines**: 145-298\n- **Purpose**: Data processing pipeline\n- **Usage**: Execute via `python scripts/process_data.py [args]`\n\n### 2. References Extracted\n- **Location**: `references/template-guide.md`\n- **Original Lines**: 50-430\n- **Purpose**: Template formatting specifications\n- **Usage**: Read when formatting templates\n\n### 3. Assets Extracted\n- **Location**: `assets/report-template.md`\n- **Original Lines**: 500-650\n- **Purpose**: Report output template\n- **Usage**: Copy and populate for report generation\n\n## Required Changes to Original File\n\n### Update SKILL.md References\n\nReplace embedded content with skill references:\n\n**Before**:\n```markdown\n<large template section>\n```\n\n**After**:\n```markdown\nFor template specifications, refer to `references/template-guide.md` in this skill directory.\n```\n\n### Update Script Execution\n\n**Before**:\n```bash\n# Inline bash commands\nmkdir -p output/\npython << EOF\n[large Python script]\nEOF\n```\n\n**After**:\n```bash\n# Execute extracted script\npython scripts/process_data.py --output output/\n```\n\n### Update Asset References\n\n**Before**:\n```markdown\n## Report Template\n[entire template embedded]\n```\n\n**After**:\n```markdown\n## Report Template\nUse template from `assets/report-template.md`, customize as needed.\n```\n\n## Testing Checklist\n\nAfter migration, verify:\n- [ ] All script executions work correctly\n- [ ] Reference materials are accessible when needed\n- [ ] Asset files are properly utilized\n- [ ] Original functionality is preserved\n- [ ] Skill can be reused in other contexts\n```\n\n## Integration with Skill Creation Workflow\n\nThis skill works in conjunction with `skill-creator`:\n\n1. **skill-extractor**: Analyzes existing commands/agents, extracts components\n2. **skill-creator**: Creates new skills from scratch with user requirements\n3. **Together**: Refactor existing code into modular, reusable skills\n\n## Advanced Features\n\n### Dependency Detection\n\nIdentifies dependencies between extracted components:\n- Scripts that reference assets\n- References that link to other references\n- Cross-component relationships\n\n### Size Optimization\n\nRecommends which components to extract based on:\n- Token usage reduction\n- Loading time optimization\n- Memory footprint\n- Reusability potential\n\n### Conflict Detection\n\nFlags potential issues:\n- Name conflicts with existing skills\n- Circular dependencies\n- Missing file references\n- Broken paths after extraction\n\n## Best Practices\n\n### When to Extract\n\n**DO extract** when:\n- Component is reused in multiple places\n- Content is large and rarely changes\n- Material is reference-only (not procedural)\n- Script can run independently\n\n**DON'T extract** when:\n- Content is core to workflow logic\n- Extraction would reduce clarity\n- Component is tightly coupled to parent\n- Size is minimal (<100 words for references, <20 lines for scripts)\n\n### Naming Conventions\n\n**Skill Names**:\n- Use kebab-case: `template-processor`, `style-validator`\n- Be descriptive: `novel-writing-templates` not `templates`\n- Indicate domain: `publishing-formats`, `data-processing-utils`\n\n**File Names**:\n- Scripts: `action_noun.py` (e.g., `generate_report.py`)\n- References: `topic-name.md` (e.g., `style-guide.md`)\n- Assets: `purpose.extension` (e.g., `report-template.md`)\n\n## Error Handling\n\nThe skill handles common issues:\n\n**Invalid Input**:\n- Missing files: Reports error with path\n- Unsupported format: Lists supported formats\n- Access denied: Requests permission\n\n**Extraction Conflicts**:\n- Existing skill directory: Offers to append timestamp or skip\n- Partial extraction: Saves progress, reports issues\n- Invalid component: Skips with warning\n\n**Output Issues**:\n- Insufficient space: Checks before creation\n- Permission denied: Reports specific location\n- Path too long: Suggests shorter names\n\n## Usage Examples\n\n### Example 1: Extract Templates from Novel Planner\n\n```bash\n# Input: ~/.claude/commands/mine/novel-planner.md\n# Contains: Multiple large templates for character profiles, chapter blueprints\n\n# Run extraction\n@skill-extractor analyze --input ~/.claude/commands/mine/novel-planner.md\n\n# Output: novel-planning-templates/\n#   ‚îú‚îÄ‚îÄ SKILL.md (references templates)\n#   ‚îú‚îÄ‚îÄ references/\n#   ‚îÇ   ‚îú‚îÄ‚îÄ character-profile.md\n#   ‚îÇ   ‚îú‚îÄ‚îÄ chapter-blueprint.md\n#   ‚îÇ   ‚îî‚îÄ‚îÄ scene-card.md\n#   ‚îî‚îÄ‚îÄ migration-report.md\n```\n\n### Example 2: Extract Analysis Scripts from Agent\n\n```bash\n# Input: ~/.claude/agents/mine/show-tell-analyzer.md\n# Contains: Python analysis algorithms\n\n# Run extraction\n@skill-extractor analyze --input ~/.claude/agents/mine/show-tell-analyzer.md\n\n# Output: narrative-analysis-tools/\n#   ‚îú‚îÄ‚îÄ SKILL.md\n#   ‚îú‚îÄ‚îÄ scripts/\n#   ‚îÇ   ‚îú‚îÄ‚îÄ analyze_show_tell.py\n#   ‚îÇ   ‚îî‚îÄ‚îÄ generate_heatmap.py\n#   ‚îî‚îÄ‚îÄ migration-report.md\n```\n\n### Example 3: Batch Extract from Multiple Commands\n\n```bash\n# Analyze entire commands directory\n@skill-extractor analyze --input ~/.claude/commands/mine/*.md --batch\n\n# Creates multiple skills, consolidated report\n# Output: batch-extraction-report.md + individual skills\n```\n\n## Validation and Quality Assurance\n\nAfter extraction, the skill validates:\n\n1. **Completeness**: All referenced files exist\n2. **Syntax**: SKILL.md frontmatter is valid YAML\n3. **Structure**: Follows skill conventions\n4. **Documentation**: Migration report is comprehensive\n5. **Testing**: Provides verification checklist\n\n## Execution\n\nTo use this skill:\n\n1. **Invoke** with target command or agent file path\n2. **Review** analysis and proposed extractions\n3. **Confirm** or adjust extraction plan\n4. **Execute** extraction\n5. **Review** migration report\n6. **Update** original file following migration guide\n7. **Test** to ensure functionality preserved\n8. **Package** new skill for distribution if desired\n\nThe skill leverages:\n- `scripts/analyze_command.py` - Analyzes command/agent structure\n- `scripts/extract_components.py` - Extracts identified components\n- `scripts/generate_skill.py` - Creates SKILL.md structure\n- `references/skill-patterns.md` - Pattern matching rules\n- `references/extraction-criteria.md` - Component extraction guidelines\n\nThis systematic approach ensures clean extraction, preservation of functionality, and clear migration paths for modernizing your Claude Code ecosystem.\n",
        "snapas/SKILL.md": "---\nname: snapas\ndescription: Snap.as API Documentation\n---\n\n# Snap.as Skill\n\nComprehensive assistance with Snap.as API development, enabling photo upload and management through the Write.as suite.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Building applications that upload photos to Snap.as\n- Implementing Snap.as photo management features\n- Working with Write.as authentication for photo services\n- Debugging Snap.as API requests and responses\n- Developing photo gallery features using Snap.as\n- Managing organizational photo uploads\n- Integrating photo sharing into Write.as applications\n\n## Quick Reference\n\n### Authentication\n\nAll Snap.as API requests require a Write.as user access token in the Authorization header:\n\n```http\nAuthorization: Token 00000000-0000-0000-0000-000000000000\n```\n\n### Upload Photo to Personal Account\n\n```bash\ncurl https://snap.as/api/photos/upload \\\n  -H \"Authorization: Token YOUR_ACCESS_TOKEN\" \\\n  -F \"file=@/path/to/photo.jpg\"\n```\n\n**Response (201 Created):**\n```json\n{\n  \"code\": 201,\n  \"data\": {\n    \"id\": \"abc123\",\n    \"filename\": \"photo.jpg\",\n    \"size\": 245760,\n    \"url\": \"https://i.snap.as/abc123.jpg\"\n  }\n}\n```\n\n### Retrieve User Photos\n\n```bash\ncurl -X POST https://snap.as/api/me/photos \\\n  -H \"Authorization: Token YOUR_ACCESS_TOKEN\"\n```\n\n**Response (200 OK):**\n```json\n{\n  \"code\": 200,\n  \"data\": [\n    {\n      \"id\": \"abc123\",\n      \"filename\": \"photo.jpg\",\n      \"size\": 245760,\n      \"url\": \"https://i.snap.as/abc123.jpg\"\n    }\n  ]\n}\n```\n\n### Delete Photo\n\n```bash\ncurl -X POST https://snap.as/api/photos/abc123 \\\n  -H \"Authorization: Token YOUR_ACCESS_TOKEN\"\n```\n\n**Response (200 OK):**\n```json\n{\n  \"code\": 200,\n  \"data\": {}\n}\n```\n\n### Upload Photo to Organization\n\n```bash\ncurl https://snap.as/api/organizations/myorg/photos/upload \\\n  -H \"Authorization: Token YOUR_ACCESS_TOKEN\" \\\n  -F \"file=@/path/to/photo.jpg\"\n```\n\n**Response (201 Created):**\n```json\n{\n  \"code\": 201,\n  \"data\": {\n    \"id\": \"xyz789\",\n    \"filename\": \"photo.jpg\",\n    \"size\": 245760,\n    \"url\": \"https://i.snap.as/xyz789.jpg\"\n  }\n}\n```\n\n### Error Response Format\n\n```json\n{\n  \"code\": 401,\n  \"error_msg\": \"Invalid access token\"\n}\n```\n\n### Go Client Library Usage\n\n```go\nimport \"github.com/snapas/go-snapas\"\n\n// Initialize client\nclient := snapas.NewClient(\"YOUR_ACCESS_TOKEN\")\n\n// Upload photo\nphoto, err := client.UploadPhoto(\"/path/to/photo.jpg\")\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Photo URL: %s\\n\", photo.URL)\n```\n\n## Key Concepts\n\n### Authentication\nSnap.as uses Write.as user access tokens for authentication. These tokens must be obtained by logging into Write.as and retrieving the user's access credentials. Include the token in the `Authorization` header of every API request.\n\n### Base URL\nAll API requests are made to `https://snap.as` with specific endpoint paths appended.\n\n### Photo Objects\nPhoto objects returned by the API contain:\n- `id`: Unique identifier for the photo\n- `filename`: Original filename of the uploaded photo\n- `size`: File size in bytes\n- `url`: Public URL where the photo can be accessed\n\n### Response Format\nAll successful API responses follow a consistent structure:\n```json\n{\n  \"code\": <HTTP_STATUS_CODE>,\n  \"data\": <RESPONSE_DATA>\n}\n```\n\nFailed requests return:\n```json\n{\n  \"code\": <HTTP_STATUS_CODE>,\n  \"error_msg\": \"<ERROR_MESSAGE>\"\n}\n```\n\n### HTTP Status Codes\n- `200 OK`: Request succeeded\n- `201 Created`: Resource created successfully\n- `400 Bad Request`: Invalid request parameters\n- `401 Unauthorized`: Invalid or missing access token\n- `403 Forbidden`: Access denied to resource\n- `404 Not Found`: Resource does not exist\n- `429 Too Many Requests`: Rate limit exceeded\n\n### Personal vs. Organization Photos\n- Personal photos: Uploaded to the user's account using `/api/photos/upload`\n- Organization photos: Uploaded to a specific organization using `/api/organizations/{alias}/photos/upload`\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete API reference with all endpoints, authentication details, request/response formats, and error handling\n\nUse `view` to read the API reference file when detailed information is needed about specific endpoints or response formats.\n\n## Working with This Skill\n\n### For Beginners\nStart by understanding the authentication mechanism. You'll need a Write.as user access token before making any API requests. Test with simple photo uploads to your personal account before working with organizational features.\n\n### For Integration Developers\nFocus on the personal photo upload and retrieval endpoints first. Implement proper error handling for common scenarios like authentication failures (401), rate limiting (429), and invalid requests (400).\n\n### For Organization Features\nOnce comfortable with personal uploads, explore organizational photo management. Organizations require the organization alias in the endpoint URL and appropriate access permissions.\n\n### For Go Developers\nUse the official `go-snapas` client library available at `github.com/snapas/go-snapas` for a more convenient development experience with built-in error handling and type safety.\n\n## Common Patterns\n\n### Photo Upload Flow\n1. Obtain Write.as access token\n2. Prepare photo file for upload\n3. Make POST request to `/api/photos/upload` with multipart form data\n4. Handle response (201 Created on success)\n5. Store photo ID and URL from response\n\n### Photo Gallery Implementation\n1. Authenticate with Write.as token\n2. Retrieve all user photos via `/api/me/photos`\n3. Display photos using the URLs from response data\n4. Implement delete functionality using photo IDs\n\n### Error Handling Best Practices\n```javascript\nasync function uploadPhoto(file, accessToken) {\n  const formData = new FormData();\n  formData.append('file', file);\n\n  try {\n    const response = await fetch('https://snap.as/api/photos/upload', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Token ${accessToken}`\n      },\n      body: formData\n    });\n\n    const data = await response.json();\n\n    if (!response.ok) {\n      throw new Error(data.error_msg || 'Upload failed');\n    }\n\n    return data.data;\n  } catch (error) {\n    console.error('Photo upload error:', error);\n    throw error;\n  }\n}\n```\n\n## Resources\n\n### Official Library\n- Go client: `github.com/snapas/go-snapas`\n\n### API Endpoints\n- Base URL: `https://snap.as`\n- Personal uploads: `/api/photos/upload`\n- User photos: `/api/me/photos`\n- Delete photo: `/api/photos/{PHOTO_ID}`\n- Organization uploads: `/api/organizations/{alias}/photos/upload`\n\n### Write.as Integration\nSince Snap.as is part of the Write.as suite, authentication happens through Write.as user accounts. Ensure users have valid Write.as credentials before attempting to use Snap.as features.\n\n## Notes\n\n- All API requests require authentication via Write.as access token\n- Photo uploads use multipart/form-data encoding\n- Response format is consistent across all endpoints\n- Rate limiting may apply (429 status code)\n- Organization features require appropriate access permissions\n- Photos are publicly accessible via returned URLs\n- This skill was generated from official Snap.as API documentation\n\n## Troubleshooting\n\n### 401 Unauthorized\n- Verify your Write.as access token is valid\n- Check that the Authorization header is properly formatted\n- Ensure the token hasn't expired\n\n### 403 Forbidden\n- Verify you have permission to upload to the specified organization\n- Check that the organization alias is correct\n\n### 429 Rate Limited\n- Implement exponential backoff in your retry logic\n- Reduce request frequency\n- Cache photo URLs instead of repeatedly fetching\n\n### Upload Failures\n- Verify file format is supported (JPG, PNG, GIF)\n- Check file size limits\n- Ensure proper multipart/form-data encoding\n- Confirm network connectivity to snap.as\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Check https://developers.snap.as/docs/api/ for API changes\n2. Update the reference files with new endpoint information\n3. Add new code examples for any new features\n4. Test all examples to ensure they still work\n",
        "tdd-methodology-expert/SKILL.md": "---\nname: tdd-methodology-expert\ndescription: Use proactively when you need to implement features or fix bugs using strict Test-Driven Development (TDD) methodology. This agent should be activated for any coding task that requires writing new functionality, refactoring existing code, or ensuring comprehensive test coverage, but should not be used for any design-related tasks. The agent excels at breaking down complex requirements into testable increments and maintaining high code quality through disciplined TDD cycles. Use this agent proactively or if the user mentions 'TDD', 'tdd' or 'Test Driven Development'.\n---\n\n# TDD Methodology Expert\n\nEnforce and reinforce Test-Driven Development (TDD) methodology throughout the software development process. This skill provides comprehensive guidance, automated validation, and continuous reinforcement of the Red-Green-Refactor cycle.\n\n## When to Use This Skill\n\nThis skill automatically activates when:\n- TDD is mentioned in `CLAUDE.md` or `CLAUDE.local.md`\n- TDD is referenced in project memory\n- The user explicitly requests TDD methodology\n- The user asks to write tests or implement features\n\nUse this skill for:\n- Implementing new features using TDD\n- Refactoring existing code with test protection\n- Fixing bugs with test-first approach\n- Ensuring code quality through TDD discipline\n- Validating that TDD principles are being followed\n\nDo NOT use this skill for:\n- Pure design discussions without implementation\n- Documentation-only tasks\n- Research or exploration tasks\n\n## Core TDD Methodology\n\nTest-Driven Development follows a strict three-phase cycle that must be repeated for every increment of functionality:\n\n### üî¥ Red Phase: Write a Failing Test\n\n**Always write the test before any production code.**\n\n1. **Write a test** that expresses the desired behavior\n2. **Run the test** and verify it fails (for the right reason)\n3. **Confirm** the failure message indicates what's missing\n\n**Red Phase Principles**:\n- Test must be simple and focused on one behavior\n- Test name should clearly describe expected behavior\n- Test should be readable without looking at implementation\n- Failure should be meaningful and guide implementation\n\n**Example Flow**:\n```\n1. Write: test_should_calculate_total_with_tax()\n2. Run: Test fails - \"ShoppingCart has no attribute 'calculate_total'\"\n3. ‚úÖ Ready for Green phase\n```\n\n### üü¢ Green Phase: Make the Test Pass\n\n**Write minimal code to make the failing test pass.**\n\n1. **Implement** the simplest code that makes the test pass\n2. **Run the test** and verify it passes\n3. **Run all tests** to ensure nothing broke\n\n**Green Phase Principles**:\n- Write only enough code to pass the current test\n- Don't add features not required by tests\n- It's okay to use shortcuts (you'll refactor later)\n- Focus on making it work, not making it perfect\n\n**Example Flow**:\n```\n1. Implement: def calculate_total(self, tax_rate): ...\n2. Run: Test passes ‚úÖ\n3. Run all: All tests pass ‚úÖ\n4. ‚úÖ Ready for Refactor phase\n```\n\n### üîµ Refactor Phase: Improve the Code\n\n**Clean up code while maintaining passing tests.**\n\n1. **Identify** duplication, poor names, or structural issues\n2. **Refactor** incrementally, running tests after each change\n3. **Verify** all tests still pass\n4. **Repeat** until code is clean\n\n**Refactor Phase Principles**:\n- Never refactor with failing tests\n- Make small, safe changes\n- Run tests after each refactoring step\n- Improve both production code and test code\n- Apply design patterns and best practices\n\n**Example Flow**:\n```\n1. Identify: Duplicated tax calculation logic\n2. Extract: Move to _calculate_tax() method\n3. Run tests: All pass ‚úÖ\n4. Improve: Better variable names\n5. Run tests: All pass ‚úÖ\n6. ‚úÖ Commit and move to next feature\n```\n\n## TDD Workflow Integration\n\n### Before Starting Any Code Task\n\n**Step 1: Understand the Requirement**\n- Break down the task into small, testable behaviors\n- Identify the simplest test case to start with\n- State which TDD phase you're entering (Red)\n\n**Step 2: Plan the Test**\n- Describe what test you're about to write\n- Explain what behavior it will verify\n- Confirm test will fail before implementation\n\n### During Implementation\n\n**Always follow this sequence**:\n\n1. **üî¥ Red**: Write failing test ‚Üí Run ‚Üí Verify failure\n2. **üü¢ Green**: Write minimal code ‚Üí Run ‚Üí Verify pass\n3. **üîµ Refactor**: Improve code ‚Üí Run ‚Üí Verify still passes\n4. **Commit**: Save working, tested, clean code\n5. **Repeat**: Next test for next behavior\n\n**Never skip phases or reverse the order.**\n\n### Communicating TDD Progress\n\nIn every response involving code changes, explicitly state:\n- **Current phase**: Which phase you're in (Red/Green/Refactor)\n- **Test status**: Whether tests are passing or failing\n- **Next steps**: What comes next in the cycle\n\n**Example Communication**:\n```\nüî¥ RED PHASE: Writing a test for calculating order total with discounts.\n\nTest: test_should_apply_percentage_discount_to_order_total()\nExpected to fail because Order.apply_discount() doesn't exist yet.\n\n[Test code here]\n\nRunning test... ‚ùå Fails as expected: \"Order has no attribute 'apply_discount'\"\n\nüü¢ GREEN PHASE: Implementing minimal code to pass the test...\n\n[Implementation code here]\n\nRunning test... ‚úÖ Passes!\nRunning all tests... ‚úÖ All pass!\n\nüîµ REFACTOR PHASE: Improving the discount calculation structure...\n\n[Refactored code here]\n\nRunning all tests... ‚úÖ All pass!\nReady to commit this increment.\n```\n\n## Bundled Tools and Resources\n\n### Scripts\n\n#### check_tdd_compliance.py\n\nAnalyzes code to detect TDD compliance issues and code smells that indicate test-after development.\n\n**Usage**:\n```bash\npython scripts/check_tdd_compliance.py <path-to-code>\n```\n\n**What it checks**:\n- Nested conditionals (sign of poor TDD structure)\n- Long methods (TDD produces small, focused methods)\n- Complex boolean conditions (TDD encourages extraction)\n- Missing abstractions (type checking vs polymorphism)\n- Test coverage (presence of corresponding test files)\n\n**When to use**:\n- After completing a feature or module\n- Before committing code\n- When reviewing code quality\n- During refactoring sessions\n\n#### validate_tests.py\n\nValidates that tests exist, are properly structured, and follow TDD patterns.\n\n**Usage**:\n```bash\npython scripts/validate_tests.py <path-to-tests>\n```\n\n**What it checks**:\n- Test file existence and structure\n- Test case count and naming\n- Arrange-Act-Assert pattern adherence\n- Test size and complexity\n- Descriptive test names\n\n**When to use**:\n- Before committing new tests\n- When validating test quality\n- During code review\n- After writing a batch of tests\n\n#### setup_hooks.sh\n\nInstalls git hooks and Claude Code hooks to enforce TDD methodology automatically.\n\n**Usage**:\n```bash\nbash scripts/setup_hooks.sh <project-directory>\n```\n\n**What it installs**:\n- Git pre-commit hook: Validates TDD compliance before commits\n- Claude user-prompt-submit hook: Injects TDD reminders into every interaction\n- Updates CLAUDE.md to document TDD requirement\n\n**When to use**:\n- Once at project initialization\n- When onboarding new team members to TDD\n- When setting up TDD enforcement for the first time\n\n### References\n\nLoad these references when deeper understanding is needed:\n\n#### tdd-principles.md\n\nComprehensive guide to TDD methodology including:\n- The Red-Green-Refactor cycle in detail\n- TDD philosophy and benefits\n- Best practices and common mistakes\n- TDD in different contexts (unit, integration, acceptance)\n- Measuring TDD effectiveness\n\n**When to reference**: When explaining TDD concepts or resolving questions about methodology.\n\n#### code-smells.md\n\nCatalog of code smells that indicate test-after development:\n- High-severity smells (nested conditionals, long methods, god objects)\n- Medium-severity smells (type checking, duplication, primitive obsession)\n- Low-severity smells (magic numbers, long parameter lists)\n- Detection strategies and refactoring guidance\n\n**When to reference**: When analyzing code quality or identifying non-TDD patterns.\n\n**Grep patterns for searching**:\n- Nested conditionals: `if.*:\\s*\\n\\s+if`\n- Long methods: Count lines between function definitions\n- Type checking: `isinstance\\(|typeof `\n- God classes: Count methods per class\n\n#### testing-patterns.md\n\nLanguage-agnostic testing patterns and best practices:\n- Test structure patterns (AAA, Given-When-Then)\n- Test organization (fixtures, builders, object mothers)\n- Assertion patterns\n- Test doubles (stubs, mocks, fakes)\n- Parameterized testing\n- Exception testing\n- Test naming conventions\n\n**When to reference**: When writing tests or improving test structure.\n\n### Assets\n\n#### Hook Templates\n\nLocated in `assets/hook-templates/`:\n\n- **pre-commit.sh**: Git hook that runs TDD compliance checks before allowing commits\n- **user-prompt-submit.sh**: Claude Code hook that injects TDD reminders before every user prompt\n\nThese templates are used by `setup_hooks.sh` and can be customized for specific project needs.\n\n## Prompt-Based Validation\n\nUsers can invoke TDD validation scripts through natural language prompts instead of relying on git hooks. This provides flexibility for developers who prefer manual commits and on-demand validation.\n\n### Recognizing Validation Requests\n\nWhen the user requests TDD validation using phrases like:\n- \"Check the code for TDD compliance\"\n- \"Validate TDD adherence\"\n- \"Run TDD compliance check\"\n- \"Check if this code follows TDD\"\n- \"Analyze code for TDD smells\"\n- \"Check code quality\"\n- \"Run code smell detection\"\n\n**Immediately respond by**:\n\n1. **Identify target code**: Determine which files or directories to analyze\n   - If user specifies files/directories, use those\n   - If not specified, ask for clarification or analyze recently modified files\n   - Use `git diff --name-only` to find recently changed files if appropriate\n\n2. **Run compliance check**: Execute `check_tdd_compliance.py` on the target code\n   ```bash\n   python scripts/check_tdd_compliance.py <path-to-code>\n   ```\n\n3. **Parse and present results**:\n   - Report the TDD compliance score (0-100)\n   - List any code smells found with severity levels\n   - Highlight specific issues in the code\n   - Provide actionable recommendations for improvement\n\n4. **Validate tests** (if applicable): Run `validate_tests.py` on corresponding test files\n   ```bash\n   python scripts/validate_tests.py <path-to-tests>\n   ```\n\n5. **Provide context-aware guidance**:\n   - Reference specific code smells from `references/code-smells.md`\n   - Suggest refactoring patterns from `references/testing-patterns.md`\n   - Offer to refactor problematic code sections\n\n### Example Response Flow\n\n**User**: \"Check the code for TDD compliance\"\n\n**Claude Response**:\n```\nI'll analyze the code for TDD compliance. Let me identify the recently changed files and run the compliance check.\n\n[Runs check_tdd_compliance.py on relevant files]\n\nüìä TDD COMPLIANCE REPORT\n\nFile: src/order_processor.py\nTDD Score: 65/100 (Needs Improvement)\n\nIssues Found:\n‚ùå High Severity (3 issues):\n  - Line 45-68: Deeply nested conditionals (4 levels deep)\n  - Line 112-145: Long method 'process_order' (34 lines)\n  - Line 78-82: Complex boolean condition (5 logical operators)\n\n‚ö†Ô∏è Medium Severity (2 issues):\n  - Line 156: Type checking instead of polymorphism (isinstance)\n  - Line 203-215: Duplicate code block\n\nRecommendations:\n1. Extract nested conditionals into separate validation methods\n2. Break down 'process_order' into smaller, focused methods\n3. Extract complex boolean into named predicate method\n4. Use polymorphism instead of type checking\n5. Extract duplicate logic into reusable function\n\nWould you like me to refactor any of these issues?\n```\n\n### When NOT to Run Validation\n\nDo not automatically run validation scripts unless:\n- User explicitly requests validation/compliance check\n- User is about to commit and asks for pre-commit checks\n- User asks about code quality or TDD adherence\n\nAvoid running validation:\n- During normal TDD cycles (Red-Green-Refactor)\n- When writing initial test code\n- During exploratory coding or prototyping\n- When user hasn't requested it\n\n### Manual vs. Automated Validation\n\n**Manual (Prompt-Based)**:\n- User has full control over when checks run\n- Can validate specific files or directories\n- Immediate feedback and context-aware guidance\n- No interruption to commit workflow\n- Preferred for developers who commit manually\n\n**Automated (Git Hooks)**:\n- Runs automatically before commits (if hooks installed)\n- Ensures validation happens consistently\n- Blocks commits with poor TDD compliance\n- Can be bypassed with `--no-verify` flag\n- Optional setup via `setup_hooks.sh`\n\nBoth approaches are valid. Users can choose the workflow that fits their preferences.\n\n## Prompt-Based Setup\n\nUsers can request TDD setup for their project through natural language prompts. This provides a guided setup experience that respects user preferences.\n\n### Recognizing Setup Requests\n\nWhen the user requests TDD setup using phrases like:\n- \"Setup this project for TDD\"\n- \"Configure TDD for this project\"\n- \"Initialize TDD development\"\n- \"Set up TDD methodology\"\n- \"Enable TDD for this codebase\"\n- \"Install TDD tools\"\n\n**Immediately respond by**:\n\n1. **Confirm the request**: Acknowledge that you'll set up TDD for the project\n\n2. **Update CLAUDE.md**: Always add or update the TDD requirement\n   ```markdown\n   # Development Guidelines\n\n   ## Test-Driven Development (TDD)\n\n   This project follows strict Test-Driven Development methodology:\n   - Write tests before production code (Red-Green-Refactor cycle)\n   - All features must have corresponding unit tests\n   - Code quality is validated through TDD compliance checks\n\n   Use the `tdd-methodology-expert` skill for TDD guidance and validation.\n   ```\n\n3. **Install Claude Code hook**: Always install the user-prompt-submit hook\n   - Copy `assets/hook-templates/user-prompt-submit.sh` to `.claude/hooks/user-prompt-submit`\n   - Make executable: `chmod +x .claude/hooks/user-prompt-submit`\n   - This injects TDD reminders into every conversation\n\n4. **Offer pre-commit hook (optional)**: Proactively ask about git hook installation\n\n   **Prompt the user**:\n   ```\n   ‚úÖ TDD Setup Progress:\n   - ‚úì Updated CLAUDE.md with TDD requirements\n   - ‚úì Installed Claude Code hook for TDD reinforcement\n\n   üìã Optional Enhancement:\n\n   Would you like to install the git pre-commit hook for automated TDD compliance checking?\n\n   Benefits:\n   ‚úÖ Automatically validates TDD compliance before each commit\n   ‚úÖ Prevents commits with poor code quality (blocking enforcement)\n   ‚úÖ Provides immediate feedback on code smells\n\n   Trade-offs:\n   ‚ö†Ô∏è Adds ~2-5 seconds to commit time\n   ‚ö†Ô∏è Blocks commits that fail TDD compliance (can bypass with --no-verify)\n   ‚ö†Ô∏è Some developers prefer manual validation\n\n   You can always validate manually by saying \"Check the code for TDD compliance\"\n\n   Install pre-commit hook? (yes/no)\n   ```\n\n5. **Install pre-commit hook (if user agrees)**:\n   - Copy `assets/hook-templates/pre-commit.sh` to `.git/hooks/pre-commit`\n   - Make executable: `chmod +x .git/hooks/pre-commit`\n   - Confirm installation\n\n6. **Provide completion summary**:\n   ```\n   ‚úÖ TDD Setup Complete!\n\n   What was installed:\n   - ‚úì CLAUDE.md updated with TDD requirements\n   - ‚úì Claude Code hook (user-prompt-submit)\n   - ‚úì Git pre-commit hook (if user opted in)\n\n   Available validation scripts:\n   - check_tdd_compliance.py - Analyze code for TDD compliance\n   - validate_tests.py - Validate test quality and structure\n\n   How to use:\n   - Say \"Check the code for TDD compliance\" anytime\n   - All code development will follow Red-Green-Refactor cycle\n   - I'll provide TDD guidance and validation throughout\n\n   Ready to start TDD development!\n   ```\n\n### Example Setup Flow\n\n**User**: \"Please setup this project for TDD development\"\n\n**Claude**:\n```\nI'll set up TDD for your project. Let me configure the necessary files and hooks.\n\n[Updates CLAUDE.md with TDD requirements]\n[Installs Claude Code hook]\n\n‚úÖ TDD Setup Progress:\n- ‚úì Updated CLAUDE.md with TDD requirements\n- ‚úì Installed Claude Code hook for TDD reinforcement\n\nüìã Optional Enhancement:\n\nWould you like to install the git pre-commit hook for automated TDD compliance checking?\n\nBenefits:\n‚úÖ Automatically validates TDD compliance before each commit\n‚úÖ Prevents commits with poor code quality\n‚úÖ Provides immediate feedback on code smells\n\nTrade-offs:\n‚ö†Ô∏è Adds ~2-5 seconds to commit time\n‚ö†Ô∏è Blocks commits that fail TDD compliance (bypass with --no-verify)\n‚ö†Ô∏è Some developers prefer manual validation\n\nYou can always validate manually by saying \"Check the code for TDD compliance\"\n\nInstall pre-commit hook? (yes/no)\n```\n\n**User**: \"no thanks, I prefer manual validation\"\n\n**Claude**:\n```\n‚úÖ TDD Setup Complete!\n\nWhat was installed:\n- ‚úì CLAUDE.md updated with TDD requirements\n- ‚úì Claude Code hook (user-prompt-submit)\n- ‚úó Git pre-commit hook (skipped per user preference)\n\nAvailable validation scripts:\n- check_tdd_compliance.py - Analyze code for TDD compliance\n- validate_tests.py - Validate test quality and structure\n\nHow to use:\n- Say \"Check the code for TDD compliance\" anytime for manual validation\n- All code development will follow Red-Green-Refactor cycle\n- I'll provide TDD guidance throughout\n\nReady to start TDD development!\n```\n\n### Setup Components\n\n**Always Install**:\n- CLAUDE.md update (TDD documentation)\n- Claude Code user-prompt-submit hook (TDD reminders)\n\n**Optional Install** (ask user):\n- Git pre-commit hook (automated validation)\n\n**Never Install Without Asking**:\n- Git hooks that modify user's commit workflow\n\n### Handling Existing Setup\n\nIf TDD is already configured:\n- Check if CLAUDE.md mentions TDD\n- Check if `.claude/hooks/user-prompt-submit` exists\n- Check if `.git/hooks/pre-commit` exists\n- Report current status and offer to update or reinstall\n\n## TDD Enforcement Rules\n\n### Mandatory Requirements\n\n1. **Tests must be written before production code**\n   - Never implement features without failing tests first\n   - Never fix bugs without reproducing them in a test first\n\n2. **All tests must pass before committing**\n   - Red phase: Don't commit\n   - Green phase: Can commit, but prefer to refactor first\n   - Refactor phase: Commit here with clean, tested code\n\n3. **Refactoring is not optional**\n   - Every cycle must include the refactor phase\n   - Code quality must continuously improve\n   - Technical debt must be addressed immediately\n\n4. **Tests must follow TDD patterns**\n   - Descriptive, behavior-focused names\n   - Arrange-Act-Assert structure\n   - Single responsibility per test\n   - Independent and isolated\n\n### Validation and Feedback\n\n**Continuously validate TDD adherence by**:\n\n1. **Checking code structure**:\n   - Run `check_tdd_compliance.py` on changed files\n   - Report TDD score and any code smells found\n   - Provide specific guidance on improvements\n\n2. **Verifying test quality**:\n   - Run `validate_tests.py` on test files\n   - Ensure tests follow patterns from `testing-patterns.md`\n   - Check for descriptive names and proper structure\n\n3. **Monitoring the cycle**:\n   - Confirm each phase is completed in order\n   - Verify tests fail before implementation\n   - Ensure tests pass after implementation\n   - Validate refactoring maintains passing tests\n\n### User Reassurance\n\nThroughout the TDD process, continuously reassure the user that:\n\n- ‚úÖ TDD methodology is being strictly followed\n- ‚úÖ Red-Green-Refactor cycle is being respected\n- ‚úÖ Tests are written before code\n- ‚úÖ Code quality is being maintained\n- ‚úÖ Each phase is completed properly\n\n**Example Reassurance**:\n```\n‚úÖ TDD COMPLIANCE: Following strict Red-Green-Refactor methodology.\n\nCurrent status:\n- üî¥ Red: Test written and confirmed failing\n- üü¢ Green: Implementation passes test\n- üîµ Refactor: Code cleaned up, all tests pass\n- TDD Score: 95/100 (Excellent)\n\nThe code exhibits TDD characteristics:\n‚úì Small, focused functions (8-12 lines)\n‚úì Flat control flow (no deep nesting)\n‚úì Clear separation of concerns\n‚úì High testability\n\nReady to proceed with next feature.\n```\n\n## Common TDD Scenarios\n\n### Implementing a New Feature\n\n**Process**:\n1. Break feature into small, testable behaviors\n2. For each behavior:\n   - üî¥ Write failing test\n   - üü¢ Implement minimal code\n   - üîµ Refactor for quality\n3. Validate with `check_tdd_compliance.py`\n4. Commit clean, tested code\n\n### Fixing a Bug\n\n**Process**:\n1. üî¥ Write a test that reproduces the bug (should fail)\n2. Confirm test fails with current code\n3. üü¢ Fix the bug (test should now pass)\n4. üîµ Refactor if needed\n5. Validate no new code smells introduced\n6. Commit fix with test\n\n### Refactoring Existing Code\n\n**Process**:\n1. Ensure existing tests pass (or add characterization tests)\n2. For each refactoring increment:\n   - üîµ Make small structural improvement\n   - Run tests to verify behavior unchanged\n   - Repeat until code is clean\n3. Validate improvement with compliance check\n4. Commit refactored code\n\n### Adding Tests to Legacy Code\n\n**Process**:\n1. Identify functionality to test\n2. Write characterization tests (document current behavior)\n3. Use tests to enable safe refactoring\n4. Gradually improve structure following TDD\n5. Future changes follow strict TDD\n\n## Integration with Development Workflow\n\n### IDE Integration\n\nTests should be:\n- Easy to run (one command or hotkey)\n- Fast to execute (milliseconds for unit tests)\n- Clearly reported (pass/fail with details)\n\n### Continuous Integration\n\nEvery commit should:\n- Run all tests automatically\n- Report TDD compliance metrics\n- Block merge if tests fail\n- Track code quality trends\n\n### Code Review\n\nReviewers should verify:\n- Tests exist for all changes\n- Tests follow TDD patterns\n- Code exhibits TDD structure (small, flat, clean)\n- Red-Green-Refactor was followed\n\n## Troubleshooting TDD Issues\n\n### \"Tests are taking too long to write\"\n\n**Solution**: Tests are probably too big. Break into smaller behaviors.\n\n### \"Can't figure out what to test first\"\n\n**Solution**: Test the simplest case. Start with happy path, then edge cases.\n\n### \"Tests keep breaking during refactoring\"\n\n**Solution**: Tests are testing implementation, not behavior. Refactor tests too.\n\n### \"Code is getting messy\"\n\n**Solution**: Not refactoring enough. Spend more time in refactor phase.\n\n### \"Tests are hard to write\"\n\n**Solution**: Code design is poor. Let test difficulty guide design improvements.\n\n## Summary: TDD Mindset\n\nWhen using this skill, always remember:\n\n1. **Tests First**: Never write production code without a failing test\n2. **Small Steps**: Keep Red-Green-Refactor cycles very short (2-10 minutes)\n3. **Refactor Always**: Code quality is not optional\n4. **Trust the Process**: TDD produces better design through discipline\n5. **Verify Compliance**: Use bundled tools to validate adherence\n\n**The cycle is sacred: üî¥ Red ‚Üí üü¢ Green ‚Üí üîµ Refactor**\n\nNever skip phases. Never reverse the order. Always complete the cycle.\n\nTDD is not just about testing - it's a design methodology that produces higher-quality, more maintainable code through disciplined practice.\n",
        "threads-api/SKILL.md": "---\nname: threads-api\ndescription: Threads API Documentation\n---\n\n# Threads API Skill\n\nComprehensive assistance with Meta's Threads API development for building applications that integrate with the Threads social platform.\n\n## When to Use This Skill\n\nThis skill should be triggered when you are:\n- **Building Threads integrations** - Creating apps that post to or read from Threads\n- **Implementing authentication** - Setting up OAuth flows for Threads API access\n- **Working with media uploads** - Uploading images, videos, or carousel posts to Threads\n- **Managing user content** - Publishing, retrieving, or managing Threads posts\n- **Fetching analytics** - Retrieving insights and metrics for Threads content\n- **Handling webhooks** - Processing real-time updates from Threads\n- **Troubleshooting API errors** - Debugging authentication, rate limits, or API responses\n- **Reading Threads profiles** - Fetching user profile data and posts\n\n## Quick Reference\n\n### Authentication - Getting an Access Token\n\n```javascript\n// Step 1: Redirect user to authorization endpoint\nconst authUrl = `https://threads.net/oauth/authorize?client_id=${CLIENT_ID}&redirect_uri=${REDIRECT_URI}&scope=threads_basic,threads_content_publish&response_type=code`;\n\n// Step 2: Exchange authorization code for access token\nconst response = await fetch('https://graph.threads.net/oauth/access_token', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/x-www-form-urlencoded' },\n  body: new URLSearchParams({\n    client_id: CLIENT_ID,\n    client_secret: CLIENT_SECRET,\n    grant_type: 'authorization_code',\n    redirect_uri: REDIRECT_URI,\n    code: authorizationCode\n  })\n});\n\nconst { access_token } = await response.json();\n```\n\n### Publishing a Text Post\n\n```javascript\n// Create a simple text post\nconst response = await fetch(`https://graph.threads.net/v1.0/me/threads`, {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Authorization': `Bearer ${accessToken}`\n  },\n  body: JSON.stringify({\n    media_type: 'TEXT',\n    text: 'Hello from Threads API! üéâ'\n  })\n});\n\nconst data = await response.json();\nconsole.log('Post ID:', data.id);\n```\n\n### Publishing an Image Post\n\n```python\nimport requests\n\n# Upload and publish an image\nurl = \"https://graph.threads.net/v1.0/me/threads\"\nheaders = {\"Authorization\": f\"Bearer {access_token}\"}\n\ndata = {\n    \"media_type\": \"IMAGE\",\n    \"image_url\": \"https://example.com/image.jpg\",\n    \"text\": \"Check out this image! #API\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\npost_id = response.json()[\"id\"]\nprint(f\"Posted image with ID: {post_id}\")\n```\n\n### Publishing a Video Post\n\n```javascript\n// Step 1: Create a video container\nconst container = await fetch(`https://graph.threads.net/v1.0/me/threads`, {\n  method: 'POST',\n  headers: { 'Authorization': `Bearer ${accessToken}` },\n  body: JSON.stringify({\n    media_type: 'VIDEO',\n    video_url: 'https://example.com/video.mp4',\n    text: 'Check out this video!'\n  })\n});\n\nconst { id: containerId } = await container.json();\n\n// Step 2: Publish the container\nawait fetch(`https://graph.threads.net/v1.0/me/threads_publish`, {\n  method: 'POST',\n  headers: { 'Authorization': `Bearer ${accessToken}` },\n  body: JSON.stringify({ creation_id: containerId })\n});\n```\n\n### Fetching User Profile\n\n```python\nimport requests\n\n# Get authenticated user's profile\nurl = f\"https://graph.threads.net/v1.0/me\"\nheaders = {\"Authorization\": f\"Bearer {access_token}\"}\nparams = {\n    \"fields\": \"id,username,name,threads_profile_picture_url,threads_biography\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\nprofile = response.json()\n\nprint(f\"Username: {profile['username']}\")\nprint(f\"Bio: {profile['threads_biography']}\")\n```\n\n### Fetching User's Threads\n\n```javascript\n// Get user's recent threads with pagination\nconst response = await fetch(\n  `https://graph.threads.net/v1.0/me/threads?fields=id,text,timestamp,media_url&limit=25`,\n  {\n    headers: { 'Authorization': `Bearer ${accessToken}` }\n  }\n);\n\nconst { data, paging } = await response.json();\ndata.forEach(thread => {\n  console.log(`${thread.timestamp}: ${thread.text}`);\n});\n\n// Use paging.next for next page\n```\n\n### Publishing a Carousel Post\n\n```python\nimport requests\n\n# Create a carousel with multiple images\nurl = \"https://graph.threads.net/v1.0/me/threads\"\nheaders = {\"Authorization\": f\"Bearer {access_token}\"}\n\ndata = {\n    \"media_type\": \"CAROUSEL\",\n    \"children\": [\n        {\"media_type\": \"IMAGE\", \"image_url\": \"https://example.com/img1.jpg\"},\n        {\"media_type\": \"IMAGE\", \"image_url\": \"https://example.com/img2.jpg\"},\n        {\"media_type\": \"IMAGE\", \"image_url\": \"https://example.com/img3.jpg\"}\n    ],\n    \"text\": \"Swipe through these images! üì∏\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\ncarousel_id = response.json()[\"id\"]\n```\n\n### Retrieving Insights (Analytics)\n\n```javascript\n// Get insights for a specific thread\nconst threadId = '123456789';\nconst response = await fetch(\n  `https://graph.threads.net/v1.0/${threadId}/insights?metric=views,likes,replies,reposts`,\n  {\n    headers: { 'Authorization': `Bearer ${accessToken}` }\n  }\n);\n\nconst { data } = await response.json();\ndata.forEach(metric => {\n  console.log(`${metric.name}: ${metric.values[0].value}`);\n});\n```\n\n### Error Handling Pattern\n\n```python\nimport requests\n\ndef make_threads_request(url, access_token, method='GET', **kwargs):\n    \"\"\"Robust error handling for Threads API requests\"\"\"\n    headers = kwargs.pop('headers', {})\n    headers['Authorization'] = f\"Bearer {access_token}\"\n\n    try:\n        response = requests.request(method, url, headers=headers, **kwargs)\n        response.raise_for_status()\n        return response.json()\n\n    except requests.exceptions.HTTPError as e:\n        error_data = e.response.json()\n        error_code = error_data.get('error', {}).get('code')\n        error_msg = error_data.get('error', {}).get('message')\n\n        if error_code == 190:\n            raise Exception(f\"Invalid access token: {error_msg}\")\n        elif error_code == 32:\n            raise Exception(f\"Rate limit exceeded: {error_msg}\")\n        else:\n            raise Exception(f\"API Error {error_code}: {error_msg}\")\n\n    except requests.exceptions.RequestException as e:\n        raise Exception(f\"Network error: {str(e)}\")\n```\n\n## Key Concepts\n\n### Access Tokens and Permissions\n- **Access Tokens**: OAuth 2.0 tokens required for all API requests\n- **Scopes**: Define what your app can access (e.g., `threads_basic`, `threads_content_publish`, `threads_manage_insights`)\n- **Token Expiration**: Long-lived tokens (60 days) and refresh tokens for extended access\n\n### Media Types\n- **TEXT**: Simple text posts\n- **IMAGE**: Single image with optional caption\n- **VIDEO**: Single video with optional caption\n- **CAROUSEL**: Multiple images or videos in a swipeable format\n\n### Publishing Flow\n1. **Container Creation**: Create a media container with content\n2. **Publishing**: Publish the container to make it visible\n3. **Two-stage process**: Required for videos and carousels to allow processing time\n\n### Rate Limits\n- Rate limits vary by endpoint and access level\n- Standard rate limit: 200 calls per hour per user\n- Monitor `X-Business-Use-Case-Usage` header in responses\n- Implement exponential backoff for rate limit errors\n\n### Webhooks\n- Real-time notifications for events like mentions, replies, or new followers\n- Requires HTTPS endpoint for receiving notifications\n- Must validate webhook signatures for security\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **other.md** - Complete Threads API documentation including:\n  - Authentication and authorization flows\n  - API endpoints reference\n  - Request/response formats\n  - Error codes and troubleshooting\n  - Best practices and guidelines\n\nUse the skill's reference files when you need detailed information about specific API endpoints, parameters, or advanced features.\n\n## Working with This Skill\n\n### For Beginners\nStart by understanding the authentication flow - this is the foundation of all Threads API integrations. Focus on:\n1. Setting up your Meta developer account and app\n2. Implementing OAuth 2.0 authorization\n3. Making your first API request to fetch user profile\n4. Publishing a simple text post\n\n### For Intermediate Users\nBuild on the basics by exploring:\n1. Media uploads (images and videos)\n2. Carousel posts for multi-image content\n3. Webhook integration for real-time updates\n4. Error handling and retry logic\n5. Rate limit management\n\n### For Advanced Users\nOptimize your integration with:\n1. Insights and analytics data\n2. Batch operations for efficiency\n3. Advanced content scheduling\n4. Custom webhook event processing\n5. Multi-account management\n\n### Navigation Tips\n- **Quick Reference**: Use the code examples above for common tasks\n- **Reference Files**: Dive into `references/other.md` for complete API documentation\n- **Authentication First**: Always start with proper authentication setup\n- **Test in Sandbox**: Use Meta's test users and sandbox environment during development\n\n## Common Workflows\n\n### Complete Post Publishing Flow\n1. Obtain access token via OAuth flow\n2. Create media container (if using images/videos)\n3. Wait for container processing (for videos)\n4. Publish the container\n5. Retrieve post ID and insights\n\n### User Data Retrieval Flow\n1. Authenticate user\n2. Fetch user profile with required fields\n3. Retrieve user's threads with pagination\n4. Process and display content\n\n### Webhook Integration Flow\n1. Set up HTTPS endpoint\n2. Register webhook subscription\n3. Validate webhook signatures\n4. Process incoming events\n5. Respond with 200 OK status\n\n## Best Practices\n\n1. **Security**\n   - Never expose access tokens in client-side code\n   - Always validate webhook signatures\n   - Use environment variables for sensitive data\n   - Implement token refresh before expiration\n\n2. **Performance**\n   - Cache API responses when appropriate\n   - Use batch requests for multiple operations\n   - Implement pagination for large result sets\n   - Monitor and respect rate limits\n\n3. **User Experience**\n   - Provide clear error messages to users\n   - Show loading states during API calls\n   - Handle network failures gracefully\n   - Request only necessary permissions\n\n4. **Content Publishing**\n   - Validate media URLs before uploading\n   - Check media format requirements\n   - Add appropriate error handling for failed uploads\n   - Consider using alt text for accessibility\n\n## Resources\n\n### Official Documentation\n- Meta for Developers: https://developers.facebook.com/docs/threads\n- API Reference: Available in `references/other.md`\n\n### Developer Tools\n- Meta App Dashboard: Configure your app and manage permissions\n- Graph API Explorer: Test API calls interactively\n- Webhook Testing: Test webhook endpoints before production\n\n## Troubleshooting\n\n### Common Issues\n\n**Authentication Errors (Code 190)**\n- Check access token validity\n- Verify token hasn't expired\n- Ensure correct permissions/scopes\n\n**Rate Limit Errors (Code 32)**\n- Implement exponential backoff\n- Monitor API usage\n- Consider caching responses\n\n**Media Upload Failures**\n- Verify media URL is publicly accessible\n- Check file format and size requirements\n- Ensure proper media_type parameter\n\n**Webhook Not Receiving Events**\n- Verify endpoint is HTTPS\n- Check webhook signature validation\n- Ensure endpoint responds with 200 OK quickly\n\n## Notes\n\n- This skill was generated from Meta's official Threads API documentation\n- The Threads API is part of Meta's Graph API family\n- API features and endpoints may be updated by Meta - refer to official docs for latest changes\n- Some features may require additional app review or permissions from Meta\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Visit https://developers.facebook.com/docs/threads for the latest information\n2. Re-run the documentation scraper with updated configuration\n3. The skill will be rebuilt with current API information\n",
        "tumblr/SKILL.md": "---\nname: tumblr\ndescription: Tumblr API Development and Integration\n---\n\n# Tumblr API Skill\n\nComprehensive assistance with Tumblr API development, authentication, and integration. This skill provides practical guidance for building applications that interact with Tumblr's platform.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Integrating with the Tumblr API (any version)\n- Implementing OAuth 1.0a or OAuth 2.0 authentication for Tumblr\n- Working with Tumblr blog data, posts, likes, or followers\n- Building Tumblr clients, dashboard tools, or analytics applications\n- Debugging Tumblr API requests or responses\n- Understanding Tumblr's Neue Post Format (NPF) or legacy post types\n- Managing rate limits or API quotas\n- Handling Tumblr webhooks or real-time updates\n\n## Quick Reference\n\n### 1. Fetch Blog Information\n\nRetrieve basic blog metadata including title, description, and post count:\n\n```bash\ncurl -H 'User-Agent: MyApp/1.0' \\\n  'https://api.tumblr.com/v2/blog/staff.tumblr.com/info?api_key=YOUR_API_KEY'\n```\n\n**Response includes:** Blog title, URL, post count, description, avatar, theme settings.\n\n### 2. Get Recent Posts\n\nRetrieve the 5 most recent posts from a blog:\n\n```bash\ncurl -H 'Authorization: Bearer YOUR_ACCESS_TOKEN' \\\n  'https://api.tumblr.com/v2/blog/staff.tumblr.com/posts?limit=5'\n```\n\n**Query parameters:**\n- `limit`: 1-20 posts per request\n- `offset`: Pagination offset\n- `tag`: Filter by tag\n- `npf=true`: Request Neue Post Format\n\n### 3. OAuth 2.0 Token Exchange\n\nExchange authorization code for access token:\n\n```bash\ncurl -X POST https://api.tumblr.com/v2/oauth2/token \\\n  -F grant_type=authorization_code \\\n  -F code=YOUR_AUTH_CODE \\\n  -F client_id=YOUR_CONSUMER_KEY \\\n  -F client_secret=YOUR_CONSUMER_SECRET\n```\n\n**Scopes:** `basic`, `write`, `offline_access`\n\n### 4. Get Blog Avatar\n\nFetch blog avatar image URL:\n\n```bash\ncurl 'https://api.tumblr.com/v2/blog/staff.tumblr.com/avatar/128'\n```\n\n**Available sizes:** 16, 24, 30, 40, 48, 64, 96, 128, 512 (default: 64)\n\n### 5. Retrieve Liked Posts\n\nGet posts liked by a blog:\n\n```bash\ncurl -H 'Authorization: Bearer YOUR_ACCESS_TOKEN' \\\n  'https://api.tumblr.com/v2/blog/staff.tumblr.com/likes?limit=20&offset=0'\n```\n\n**Parameters:** `limit`, `offset`, `before` (timestamp), `after` (timestamp)\n\n### 6. Queue Management\n\nRetrieve queued posts:\n\n```bash\ncurl -H 'Authorization: Bearer YOUR_ACCESS_TOKEN' \\\n  'https://api.tumblr.com/v2/blog/myblog.tumblr.com/posts/queue'\n```\n\nReorder queue:\n\n```bash\ncurl -X POST https://api.tumblr.com/v2/blog/myblog.tumblr.com/posts/queue/reorder \\\n  -H 'Authorization: Bearer YOUR_ACCESS_TOKEN' \\\n  -d 'post_id=123456789'\n```\n\n### 7. Get Followers\n\nRetrieve blog followers:\n\n```bash\ncurl -H 'Authorization: Bearer YOUR_ACCESS_TOKEN' \\\n  'https://api.tumblr.com/v2/blog/myblog.tumblr.com/followers'\n```\n\n**Response includes:** Total follower count, follower blog objects with names and URLs.\n\n### 8. Filter Posts by Tag\n\nRetrieve posts with specific tag:\n\n```bash\ncurl -H 'User-Agent: MyApp/1.0' \\\n  'https://api.tumblr.com/v2/blog/staff.tumblr.com/posts?api_key=YOUR_KEY&tag=photography&limit=10'\n```\n\n### 9. Standard API Response Format\n\nAll Tumblr API responses follow this structure:\n\n```json\n{\n  \"meta\": {\n    \"status\": 200,\n    \"msg\": \"OK\"\n  },\n  \"response\": {\n    \"blog\": { },\n    \"posts\": [ ]\n  }\n}\n```\n\n### 10. Working with Blog Identifiers\n\nThree interchangeable identifier formats:\n\n```bash\n# Blog name\n/v2/blog/staff/info\n\n# Hostname\n/v2/blog/staff.tumblr.com/info\n\n# UUID (stable, persistent)\n/v2/blog/t:0aY0xL2Fi1OFJg4YxpmegQ/info\n```\n\n**Recommendation:** Use UUID for long-term stability (survives blog renames).\n\n## Key Concepts\n\n### Authentication Levels\n\n1. **None** - Public endpoints (blog info, public posts) require no authentication\n2. **API Key** - Use OAuth Consumer Key as `api_key` query parameter\n3. **OAuth** - Signed requests using OAuth 1.0a or OAuth 2.0 for user-specific data\n\n### Rate Limits\n\n**Per IP Address:**\n- 300 calls/minute\n- 18,000 calls/hour\n- 432,000 calls/day\n\n**Per Consumer Key:**\n- 1,000 calls/hour\n- 5,000 calls/day\n\n**Action Limits:**\n- 250 posts/day\n- 200 follows/day\n- 1,000 likes/day\n\n### Post Formats\n\n**Legacy Post Types:**\n- Text, Photo, Quote, Link, Chat, Audio, Video, Answer\n\n**Neue Post Format (NPF):**\n- Modern block-based format\n- Posts with `type: blocks` or `is_blocks_post_format: true`\n- Request with `npf=true` parameter\n- Contains `content` (blocks), `layout` (specifications), `trail` (reblog chain)\n\n### Post IDs\n\nPost IDs are 64-bit integers. **Important:** Use `id_string` field for JavaScript or languages with unsafe integer handling.\n\n### Required Headers\n\n**User-Agent:** Mandatory for all requests. Must be consistent. Format: `AppName/Version`\n\n**Content-Type:** Required for POST/PUT with body. Accepted:\n- `application/json`\n- `application/x-www-form-urlencoded`\n- `multipart/form-data`\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete Tumblr API documentation including:\n  - All authentication methods (OAuth 1.0a, OAuth 2.0, API key)\n  - Blog endpoints (info, posts, avatar, likes, following, followers)\n  - User endpoints (dashboard, likes, following)\n  - Post creation and management\n  - Queue and draft management\n  - Neue Post Format (NPF) specification\n  - Legacy post type fields\n  - Rate limits and best practices\n  - Response format documentation\n\nUse the `view` command to read specific reference files when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n\n1. **Start with public endpoints** - No authentication needed:\n   - Fetch blog info: `/v2/blog/{blog}/info?api_key={key}`\n   - Get public posts: `/v2/blog/{blog}/posts?api_key={key}`\n\n2. **Register your application:**\n   - Visit https://www.tumblr.com/oauth/apps\n   - Get OAuth Consumer Key and Secret\n   - Use Consumer Key as `api_key` for public endpoints\n\n3. **Test with API Console:**\n   - https://api.tumblr.com/console\n   - Interactive testing environment\n\n### For OAuth Implementation\n\n1. **Choose OAuth version:**\n   - OAuth 2.0: Modern, simpler, bearer tokens\n   - OAuth 1.0a: Legacy, more complex, signed requests\n\n2. **OAuth 2.0 flow:**\n   - Redirect user to authorization URL with scopes\n   - Exchange authorization code for access token\n   - Use token in `Authorization: Bearer {token}` header\n\n3. **OAuth 1.0a flow:**\n   - Request temporary credentials\n   - Redirect user to authorize\n   - Exchange verifier for access token\n   - Sign all requests with token\n\n### For Advanced Features\n\n1. **Neue Post Format (NPF):**\n   - Add `npf=true` to any post-returning endpoint\n   - Work with content blocks and layout objects\n   - Access full reblog trail\n\n2. **Pagination:**\n   - Use `offset` for numeric pagination\n   - Use `before`/`after` with timestamps for chronological navigation\n   - Check `_links` object for next/previous URLs\n\n3. **Partial responses:**\n   - Use `fields` parameter to specify blog object fields\n   - Reduces response size and improves performance\n\n4. **JSONP support:**\n   - Add `jsonp=callbackName` to GET requests\n   - Useful for client-side JavaScript\n\n## Common Patterns\n\n### Authentication Flow (OAuth 2.0)\n\n```bash\n# Step 1: Redirect user to authorization URL\nhttps://www.tumblr.com/oauth2/authorize?client_id={key}&response_type=code&scope=basic%20write&state={random}\n\n# Step 2: User authorizes, Tumblr redirects back with code\n# Your redirect URL receives: ?code={auth_code}\n\n# Step 3: Exchange code for access token\ncurl -X POST https://api.tumblr.com/v2/oauth2/token \\\n  -F grant_type=authorization_code \\\n  -F code={auth_code} \\\n  -F client_id={consumer_key} \\\n  -F client_secret={consumer_secret}\n\n# Step 4: Use access token in requests\ncurl -H 'Authorization: Bearer {access_token}' \\\n  'https://api.tumblr.com/v2/user/info'\n```\n\n### Error Handling\n\n```json\n{\n  \"meta\": {\n    \"status\": 401,\n    \"msg\": \"Unauthorized\"\n  },\n  \"response\": [ ],\n  \"errors\": [\n    {\n      \"title\": \"Unauthorized\",\n      \"code\": 401,\n      \"detail\": \"OAuth authentication required\"\n    }\n  ]\n}\n```\n\n**Common status codes:**\n- 200: Success\n- 401: Unauthorized (missing/invalid credentials)\n- 404: Not Found (blog or post doesn't exist)\n- 429: Rate Limit Exceeded\n- 503: Service Temporarily Unavailable\n\n### Handling Large Post Counts\n\n```bash\n# Fetch all posts using pagination\noffset=0\nlimit=20\n\nwhile true; do\n  curl \"https://api.tumblr.com/v2/blog/staff.tumblr.com/posts?api_key={key}&limit=${limit}&offset=${offset}\"\n  offset=$((offset + limit))\n  # Check if response contains fewer than 'limit' posts, then break\ndone\n```\n\n## Resources\n\n### Official Links\n\n- **API Console:** https://api.tumblr.com/console\n- **Developer Portal:** https://www.tumblr.com/docs/api/v2\n- **OAuth Apps:** https://www.tumblr.com/oauth/apps\n- **Support:** https://www.tumblr.com/support\n\n### Official Clients\n\n- JavaScript: `tumblr.js`\n- Ruby: `tumblr_client`\n- PHP: `tumblr/tumblr`\n- Python: `pytumblr`\n- Java: `jumblr`\n- Objective-C: `TMTumblrSDK`\n- Go: `tumblr/tumblr.go`\n\n### Best Practices\n\n1. **Always include User-Agent header** - Inconsistent or missing User-Agent may result in suspension\n2. **Respect rate limits** - Implement exponential backoff for 429 responses\n3. **Use UUIDs for blog identifiers** - More stable than blog names (survive renames)\n4. **Cache blog info** - Reduce API calls by caching static blog data\n5. **Use NPF for new integrations** - Legacy formats may be deprecated\n6. **Handle 64-bit integers carefully** - Use `id_string` for JavaScript\n7. **Validate responses** - Check `meta.status` before processing `response`\n\n## Notes\n\n- This skill was generated from official Tumblr API documentation\n- All endpoints use base URL: `https://api.tumblr.com`\n- API version is included in path: `/v2/`\n- HTTPS is required for all API requests\n- Reference files preserve structure and examples from source docs\n- Code examples include language detection for better syntax highlighting\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Re-run the scraper with the same configuration\n2. The skill will be rebuilt with the latest information from the official GitHub repository\n",
        "vastai-api/SKILL.md": "---\nname: vastai-api\ndescription: Vast.ai API Documentation - Affordable GPU Cloud Marketplace\n---\n\n# Vastai-Api Skill\n\nComprehensive assistance with the Vast.ai API for managing GPU instances, machine operations, and automating AI/ML workflows. This skill provides access to official documentation for programmatically controlling the Vast.ai platform.\n\n## When to Use This Skill\n\nThis skill should be triggered when working with:\n- **GPU Instance Management**: Creating, destroying, starting, stopping, or managing GPU instances\n- **Machine Operations**: Listing machines for rent, setting pricing, managing maintenance windows\n- **SSH & Authentication**: Managing SSH keys, API keys, and secure connections to instances\n- **Billing & Credits**: Viewing invoices, earnings, deposits, or transferring credits\n- **Network Volumes**: Creating, listing, or managing network storage volumes\n- **Serverless Endpoints**: Working with Vast.ai serverless workergroups and endpoints\n- **Data Transfer**: Copying data between instances or cloud services\n- **Account Management**: Managing subaccounts, environment variables, or team roles\n- **CLI Operations**: Using the `vastai` command-line tool\n- **API Integration**: Building applications that integrate with Vast.ai's REST API\n\n## Quick Reference\n\n### Creating and Managing Instances\n\n#### Create a New GPU Instance\n```bash\n# Create instance from an offer\nvastai create instance <offer_id> \\\n  --image pytorch/pytorch:latest \\\n  --disk 50 \\\n  --ssh\n```\n\n#### List Your Active Instances\n```bash\n# Show all instances\nvastai show instances\n\n# Show specific instance details\nvastai show instance <instance_id>\n```\n\n#### Manage Instance State\n```bash\n# Stop an instance (pause GPU billing, storage still charged)\nvastai stop instance <instance_id>\n\n# Start a stopped instance\nvastai start instance <instance_id>\n\n# Reboot instance without losing GPU priority\nvastai reboot instance <instance_id>\n\n# Destroy instance permanently (irreversible)\nvastai destroy instance <instance_id>\n```\n\n### SSH Key Management\n\n#### Add SSH Key to Account\n```bash\n# Add your public SSH key\nvastai create ssh-key \"ssh-rsa AAAAB3NzaC1yc2EA... user@host\"\n\n# List all SSH keys\nvastai show ssh-keys\n\n# Attach SSH key to specific instance\nvastai attach ssh <instance_id> <ssh_key>\n```\n\n### Search and Filter Offers\n\n#### Search for GPU Offers\n```bash\n# Search with filters\nvastai search offers \\\n  --gpu_name RTX_4090 \\\n  --num_gpus 2 \\\n  --disk_space 100\n\n# Order by price\nvastai search offers --order dph_total\n```\n\n### Environment Variables (Secrets)\n\n#### Manage Environment Variables\n```bash\n# Create encrypted environment variable\nvastai create env-var MY_API_KEY \"secret_value_here\"\n\n# List all environment variables\nvastai show env-vars\n\n# Update existing variable\nvastai update env-var MY_API_KEY \"new_secret_value\"\n\n# Delete environment variable\nvastai delete env-var MY_API_KEY\n```\n\n### Billing and Credits\n\n#### View Billing Information\n```bash\n# Show invoices\nvastai show invoices\n\n# Show earnings (for hosts)\nvastai show earnings\n\n# Show deposit for specific instance\nvastai show deposit <instance_id>\n\n# Transfer credits to another user\nvastai transfer credit recipient@email.com 25.00\n```\n\n### Instance Logs\n\n#### Retrieve Container Logs\n```bash\n# Get last 100 lines of logs\nvastai show logs <instance_id> --tail 100\n\n# Filter logs with grep pattern\nvastai show logs <instance_id> --filter \"error\"\n\n# Get daemon system logs\nvastai show logs <instance_id> --daemon-logs\n```\n\n### Data Transfer Operations\n\n#### Copy Between Instances\n```bash\n# Copy from one instance to another\nvastai copy <src_id> <dst_id> /source/path /destination/path\n\n# Cloud copy using rclone\nvastai cloud copy <instance_id> remote:bucket/path /local/path\n```\n\n### Machine Management (for Hosts)\n\n#### List Your Machine for Rent\n```bash\n# List machine with pricing\nvastai list machine <machine_id> \\\n  --price_gpu 0.50 \\\n  --price_disk 0.10\n\n# Unlist machine (stop renting)\nvastai unlist machine <machine_id>\n\n# Schedule maintenance window\nvastai schedule maint <machine_id> \\\n  --sdate \"2025-11-01T10:00:00\" \\\n  --duration 3600\n```\n\n## Key Concepts\n\n### Instance Types\n- **On-Demand Instances**: Pay-as-you-go GPU instances you create and manage\n- **Interruptible Instances**: Lower-cost instances that can be reclaimed by hosts\n- **Reserved Instances**: Pre-paid instances with usage discounts (up to 40%)\n\n### Pricing Model\n- **GPU Pricing**: Charged per hour while instance is running\n- **Storage Pricing**: Charged for disk space even when instance is stopped\n- **Network Transfer**: Upload/download bandwidth costs\n- **Discounts**: Available through prepayment on reserved instances\n\n### Instance States\n- `starting`: Instance is initializing\n- `running`: Instance is active and billable\n- `stopped`: Container stopped (storage still billable)\n- `exited`: Container exited or failed\n- `rebooting`: In process of restarting\n- `recycling`: Being destroyed and recreated from fresh image\n\n### Authentication\n- **API Keys**: Used for programmatic access via REST API\n- **SSH Keys**: For secure shell access to running instances\n- **Environment Variables**: Encrypted secrets injected into containers\n\n### Templates\nPre-configured setups containing:\n- Docker image specifications\n- Environment variables\n- Onstart scripts\n- Resource requirements\n- Port mappings\n\nPopular templates include PyTorch, TensorFlow, Jupyter, ComfyUI, and Stable Diffusion.\n\n### Network Volumes\nShared network storage that can be:\n- Attached to multiple instances\n- Persisted independently of instance lifecycle\n- Used for datasets and model weights\n- Scaled independently\n\n### Serverless Architecture\n- **Endpoints**: Top-level routing and configuration\n- **Workergroups**: Pools of GPU instances that autoscale\n- **Test Workers**: Exploration phase for performance profiling\n- **Target Utilization**: Controls scaling behavior\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n### llms-full.md\nComplete API reference with all endpoints organized by category:\n- **Accounts**: API keys, SSH keys, user management, subaccounts\n- **Billing**: Invoices, earnings, deposits, credit transfers\n- **Instances**: Create, manage, destroy, reboot, logs, SSH\n- **Machines**: List for rent, pricing, maintenance, default jobs\n- **Network Volumes**: Create, list, manage shared storage\n- **Search**: Find offers, benchmarks, filter GPU availability\n- **Serverless**: Endpoints, workergroups, autoscaling configuration\n\nEach endpoint includes:\n- HTTP method and path\n- Detailed description\n- CLI usage examples\n- Parameter specifications\n- Source documentation links\n\n### llms-txt.md\nFocused documentation covering:\n- Serverless workergroup parameters and configuration\n- Endpoint management\n- QuickStart guide with setup instructions\n- Common questions and answers\n- Schema.org structured data for better searchability\n\n### llms.md\nCurated list of all API operations with brief descriptions and CLI examples, organized by category for quick lookup.\n\n## Working with This Skill\n\n### For Beginners\n\n**Start here:**\n1. Review the QuickStart section in `llms-txt.md`\n2. Follow the 4-step setup process (signup, add credit, prepare SSH, create instance)\n3. Try the basic examples in Quick Reference above\n4. Learn about instance states and pricing model in Key Concepts\n\n**First tasks to try:**\n- Create an API key for authentication\n- Add your SSH public key to your account\n- Search for available GPU offers\n- Create your first instance with a template\n\n### For Intermediate Users\n\n**Focus on:**\n- Environment variable management for secrets\n- Data transfer between instances and cloud storage\n- Instance lifecycle management (stop/start/reboot vs destroy)\n- Billing optimization with reserved instances\n- Custom template creation for your workflows\n\n**Useful patterns:**\n- Set up auto-billing to avoid instance interruptions\n- Use environment variables for API keys and credentials\n- Schedule regular backups with copy commands\n- Monitor costs with invoice and earnings endpoints\n\n### For Advanced Users\n\n**Advanced topics:**\n- Serverless endpoint and workergroup configuration\n- Machine hosting and marketplace optimization\n- Network volume architecture for shared datasets\n- Team and subaccount management\n- API integration in custom applications\n- Automated scaling strategies\n\n**Power user tips:**\n- Use filter operators in search (eq, neq, gt, lt, gte, lte, in, nin)\n- Leverage launch_args for advanced instance customization\n- Implement monitoring and alerting via logs API\n- Optimize costs with bid price adjustments\n- Build workflows with cloud copy for data pipelines\n\n### Navigation Tips\n\n**Finding API endpoints:**\n- All endpoints documented in `llms-full.md` with full details\n- Organized by category (accounts, billing, instances, machines, etc.)\n- Each includes CLI usage examples\n\n**Quick lookups:**\n- `llms.md` provides condensed list of all operations\n- Use browser search (Ctrl+F) to find specific commands\n- Look for \"CLI Usage:\" sections for command syntax\n\n**Understanding concepts:**\n- Key Concepts section above for terminology\n- QuickStart in `llms-txt.md` for getting started\n- Workergroup Parameters section for serverless configuration\n\n## Common Workflows\n\n### Setting Up a New Development Environment\n1. Create API key with appropriate permissions\n2. Add SSH key to account for access\n3. Create environment variables for secrets\n4. Search for GPU offers matching requirements\n5. Create instance from template\n6. Connect via SSH and verify setup\n\n### Managing Long-Running Training Jobs\n1. Create instance with sufficient disk space\n2. Set up auto-billing to prevent interruptions\n3. Use reserved instance with prepayment for discounts\n4. Monitor with logs endpoint\n5. Copy model checkpoints to cloud storage\n6. Stop (not destroy) when paused to save costs\n\n### Hosting Machines for Profit\n1. Set machine pricing with list command\n2. Define minimum bid thresholds\n3. Configure default jobs for background work\n4. Schedule maintenance windows when needed\n5. Monitor earnings and clean up expired contracts\n6. Adjust pricing based on market conditions\n\n## Best Practices\n\n### Cost Management\n- **Destroy vs Stop**: Use stop for short pauses, destroy for long breaks\n- **Disk Space**: Choose carefully - cannot be changed later\n- **Reserved Instances**: Prepay for 40% discount on long-running work\n- **Auto-billing**: Set threshold above daily spend to prevent interruptions\n- **Low Balance Alerts**: Enable email notifications as backup\n\n### Security\n- **API Keys**: Use permission scoping, rotate regularly\n- **SSH Keys**: Use different keys for different purposes\n- **Environment Variables**: Store secrets as encrypted env vars\n- **Subaccounts**: Use for team members with restricted access\n\n### Performance\n- **Template Caching**: Pre-pulled images start much faster (seconds vs minutes)\n- **Network Volumes**: Use for large datasets shared across instances\n- **Bid Pricing**: Higher bids get better hardware availability\n- **Test Workers**: Let serverless explore before scaling\n\n### Reliability\n- **Logs**: Monitor regularly for errors\n- **Health Checks**: Implement in your applications\n- **Data Backup**: Copy critical data off instances regularly\n- **Redundancy**: For critical work, run on multiple instances\n\n## Resources\n\n### Official Links\n- **Console**: https://cloud.vast.ai/\n- **API Docs**: https://docs.vast.ai/\n- **Postman Collection**: https://www.postman.com/vast33/vast-ai-public-api-docs\n- **Templates**: https://cloud.vast.ai/templates/\n- **Search**: https://cloud.vast.ai/create/\n\n### Support\n- Minimum deposit: $5\n- Balance shown at top right of dashboard\n- Email verification required to rent or create teams\n- Auto-billing prevents interruptions when configured\n\n## Notes\n\n- This skill was automatically generated from official Vast.ai documentation\n- Reference files preserve structure and examples from source docs\n- CLI examples use the `vastai` command-line tool\n- API endpoints support both REST API and CLI access\n- All prices in USD, billed per hour for compute and storage\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Re-run the scraper with the same configuration\n2. The skill will be rebuilt with the latest API information\n3. Check for API version changes or deprecated endpoints\n",
        "vercel/SKILL.md": "---\nname: vercel\ndescription: Vercel Platform and API Documentation\n---\n\n# Vercel Skill\n\nComprehensive assistance with Vercel deployment, API integration, and platform features. This skill provides practical guidance for building and deploying modern web applications on Vercel's AI Cloud platform.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n\n- **Deployment & CI/CD**: Deploying applications, configuring continuous deployment, or setting up preview environments\n- **API Integration**: Working with Vercel REST API endpoints for programmatic deployments and management\n- **CLI Operations**: Using Vercel CLI commands for local development and deployment workflows\n- **Configuration**: Setting up `vercel.json` for build commands, routing, environment variables, or cron jobs\n- **Framework Setup**: Configuring Next.js, SvelteKit, Nuxt, or other supported frameworks\n- **Serverless Functions**: Creating and deploying serverless functions or Edge runtime code\n- **Domain Management**: Managing custom domains, SSL certificates, or DNS configuration\n- **Environment Variables**: Setting up secrets and environment variables for different environments\n- **Team Management**: Working with team resources, access tokens, or collaboration features\n- **AI Integration**: Deploying AI-powered applications, agents, or MCP servers\n\n## Quick Reference\n\n### Authentication with Access Token\n\n```bash\n# Using cURL with Vercel API\ncurl -X GET \"https://api.vercel.com/v9/projects\" \\\n  -H \"Authorization: Bearer YOUR_ACCESS_TOKEN\" \\\n  -H \"Content-Type: application/json\"\n```\n\n### Basic CLI Deployment\n\n```bash\n# Deploy to production\nvercel --prod\n\n# Deploy with environment variables\nvercel --env NEXT_PUBLIC_API_URL=https://api.example.com\n\n# Force new deployment without cache\nvercel --force\n\n# Deploy with build logs\nvercel --logs\n```\n\n### CI/CD Deployment Workflow\n\n```bash\n# Pull environment variables and project settings\nvercel pull --yes --environment=preview --token=$VERCEL_TOKEN\n\n# Build locally\nvercel build --token=$VERCEL_TOKEN\n\n# Deploy pre-built artifacts\nvercel deploy --prebuilt --token=$VERCEL_TOKEN\n```\n\n### vercel.json - Cron Jobs Configuration\n\n```json\n{\n  \"$schema\": \"https://openapi.vercel.sh/vercel.json\",\n  \"crons\": [\n    {\n      \"path\": \"/api/every-minute\",\n      \"schedule\": \"* * * * *\"\n    },\n    {\n      \"path\": \"/api/every-hour\",\n      \"schedule\": \"0 * * * *\"\n    },\n    {\n      \"path\": \"/api/daily-cleanup\",\n      \"schedule\": \"0 0 * * *\"\n    }\n  ]\n}\n```\n\n### vercel.json - Build Configuration\n\n```json\n{\n  \"buildCommand\": \"npm run build\",\n  \"outputDirectory\": \"dist\",\n  \"framework\": \"nextjs\",\n  \"installCommand\": \"npm install\"\n}\n```\n\n### Environment Variables Configuration\n\n```json\n{\n  \"env\": {\n    \"API_URL\": \"https://api.example.com\",\n    \"FEATURE_FLAG\": \"true\"\n  },\n  \"build\": {\n    \"env\": {\n      \"BUILD_TIME\": \"@now\"\n    }\n  }\n}\n```\n\n### Accessing Team Resources via API\n\n```bash\n# Get team deployments\ncurl -X GET \"https://api.vercel.com/v6/deployments?teamId=TEAM_ID\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n\n# Create deployment for team project\ncurl -X POST \"https://api.vercel.com/v13/deployments?teamId=TEAM_ID\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"my-project\", \"files\": []}'\n```\n\n### Bun Runtime Configuration\n\n```json\n{\n  \"bunVersion\": \"1.0.0\",\n  \"functions\": {\n    \"api/**/*.ts\": {\n      \"runtime\": \"bun\"\n    }\n  }\n}\n```\n\n### Serverless Function Example\n\n```javascript\n// api/hello.js\nexport default function handler(req, res) {\n  const { name = 'World' } = req.query;\n  res.status(200).json({\n    message: `Hello ${name}!`,\n    timestamp: new Date().toISOString()\n  });\n}\n```\n\n### Edge Function Example\n\n```javascript\n// middleware.js\nexport const config = {\n  matcher: '/api/:path*',\n};\n\nexport default function middleware(req) {\n  const response = NextResponse.next();\n  response.headers.set('x-custom-header', 'my-value');\n  return response;\n}\n```\n\n## Key Concepts\n\n### REST API Architecture\n\nThe Vercel REST API operates at `https://api.vercel.com` following REST principles. All requests require:\n- **Authentication**: Bearer token in Authorization header\n- **Content-Type**: `application/json` for all requests\n- **HTTP Versions**: Supports HTTP/1, 1.1, and 2 (HTTP/2 preferred)\n- **TLS**: Supports TLS 1.2 and 1.3 with resumption\n\n### Rate Limiting\n\nAPI responses include rate limit headers:\n- `X-RateLimit-Limit`: Maximum requests allowed\n- `X-RateLimit-Remaining`: Requests left in current window\n- `X-RateLimit-Reset`: Reset time (UTC epoch seconds)\n\nExceeding limits returns HTTP 429 with \"too_many_requests\" error.\n\n### Pagination\n\n- Default: 20 items per page\n- Maximum: 100 items per page\n- Navigate with `until` query parameter and `next`/`prev` timestamps\n\n### Token Security\n\n- Set expiration dates (1 day to 1 year)\n- Store tokens securely immediately after creation\n- Tokens display only once and cannot be retrieved later\n- Use team-scoped tokens for team resource access\n\n### Deployment Workflow\n\n1. **Preview Deployments**: Automatic deployments for every git push to non-production branches\n2. **Production Deployments**: Deployments to production domain from main branch or via `--prod` flag\n3. **Build Artifacts**: Local builds with `vercel build` upload only compiled output\n4. **Environment Variables**: Different values for development, preview, and production\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Vercel REST API endpoints, authentication, and integration patterns\n- **llms-full.md** - Complete Vercel documentation for comprehensive reference\n- **llms-small.md** - Condensed documentation for quick lookups\n\nUse `view` to read specific reference files when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n\nStart with basic deployment workflows:\n1. Install Vercel CLI: `npm i -g vercel`\n2. Authenticate: `vercel login`\n3. Deploy your first project: `vercel`\n4. Learn about `vercel.json` configuration basics\n\n### For Intermediate Users\n\nFocus on:\n- Custom build configurations in `vercel.json`\n- Environment variable management across environments\n- Setting up cron jobs for scheduled tasks\n- Working with serverless functions\n- Git integration and preview deployments\n\n### For Advanced Users\n\nExplore:\n- Vercel REST API for programmatic deployments\n- Custom CI/CD pipelines with `vercel build` and `vercel deploy --prebuilt`\n- Edge runtime and middleware configurations\n- Multi-tenant application patterns\n- Team management and access control\n- AI SDK integration and agent deployment\n\n### Navigation Tips\n\n- Use CLI commands for rapid iteration during development\n- Use REST API for automation and custom workflows\n- Reference `vercel.json` schema for configuration validation\n- Check rate limits when building high-volume integrations\n- Use team IDs for accessing shared resources\n\n## Platform Capabilities\n\n### Computing Infrastructure\n\n- **Serverless Functions**: Node.js, Python, Go, Ruby, Bun, Wasm runtimes\n- **Edge Runtime**: Low-latency edge computing\n- **Fluid Compute**: Active CPU allocation for optimal performance\n- **Streaming Support**: Real-time data streaming capabilities\n- **Cron Jobs**: Scheduled function execution\n\n### Development Features\n\n- **Framework Support**: Next.js, SvelteKit, Nuxt, Astro, and 30+ more\n- **Git Integration**: GitHub, GitLab, Bitbucket, Azure DevOps\n- **Automatic CI/CD**: Preview environments for every push\n- **Environment Variables**: Secure secrets management\n- **Deployment Protection**: Password protection and access control\n\n### AI Capabilities\n\n- **AI SDK**: Language model integration framework\n- **AI Gateway**: Multi-provider LLM routing\n- **Agent Building**: Frameworks for AI agents\n- **MCP Servers**: Model Context Protocol server deployment\n\n### Performance & Optimization\n\n- **CDN**: Global edge network\n- **Image Optimization**: Automatic image processing\n- **OG Image Generation**: Dynamic social media images\n- **Caching**: Intelligent caching strategies\n\n## Common Use Cases\n\n1. **Marketing Sites**: Rapid deployment with preview environments\n2. **E-commerce Platforms**: Composable commerce with serverless architecture\n3. **SaaS Applications**: Multi-tenant applications with edge computing\n4. **AI Applications**: AI-powered apps with intelligent infrastructure\n5. **API Backends**: Hosting RESTful APIs and GraphQL servers\n6. **Static Sites**: Optimized static site delivery\n7. **Jamstack Applications**: Modern web architectures\n\n## Resources\n\n### Official Documentation\n- **Main Docs**: https://vercel.com/docs\n- **REST API**: https://vercel.com/docs/rest-api\n- **CLI Reference**: https://vercel.com/docs/cli\n- **Framework Guides**: https://vercel.com/docs/frameworks\n\n### references/\nOrganized documentation extracted from official sources. These files contain:\n- Detailed API endpoint specifications\n- Complete configuration options\n- Framework-specific deployment guides\n- Code examples with best practices\n- Links to original documentation\n\n### scripts/\nAdd helper scripts here for common automation tasks such as:\n- Deployment automation scripts\n- Environment variable management\n- Team resource provisioning\n- Batch operations on projects\n\n### assets/\nAdd templates, boilerplate, or example projects here such as:\n- `vercel.json` templates for different use cases\n- Serverless function boilerplates\n- Edge middleware examples\n- CI/CD workflow templates\n\n## Best Practices\n\n1. **Security**\n   - Always set expiration dates on access tokens\n   - Use team-scoped tokens for shared resources\n   - Store tokens in secure environment variables\n   - Rotate tokens regularly\n\n2. **Performance**\n   - Use `--prebuilt` for faster deployments in CI/CD\n   - Enable caching for build dependencies\n   - Optimize images using Vercel's image optimization\n   - Use Edge runtime for low-latency operations\n\n3. **Configuration**\n   - Version control your `vercel.json` configuration\n   - Use environment-specific settings appropriately\n   - Document custom build commands\n   - Test configurations in preview environments first\n\n4. **API Integration**\n   - Implement retry logic for rate-limited requests\n   - Handle pagination for large result sets\n   - Monitor rate limit headers proactively\n   - Use team IDs consistently for team resources\n\n## Notes\n\n- This skill provides guidance based on Vercel's latest documentation (as of January 2025)\n- Reference files preserve structure and examples from official documentation\n- Code examples include proper language detection for syntax highlighting\n- Quick reference patterns are extracted from common usage scenarios\n\n## Updating\n\nTo refresh this skill with updated documentation:\n1. Re-run the documentation scraper with Vercel URLs\n2. Update reference files with latest API changes\n3. Verify code examples against current API versions\n4. Test configurations with latest CLI version\n",
        "word-count-checker/SKILL.md": "---\nname: word-count-checker\ndescription: Automatically checks word counts of documents when the user mentions word count in relation to a file. Triggers on phrases like \"Check the word count of X\", \"Stop when the word count is N\", or similar references to document word counts. Use this skill proactively whenever word count is mentioned with a document reference.\n---\n\n# Word Count Checker\n\n## Overview\n\nThis skill enables automatic word count checking when word count is mentioned in relation to a document. Instead of requiring explicit requests, trigger this skill whenever the user references word count alongside a document.\n\n## When to Use This Skill\n\nTrigger this skill whenever the user mentions word count in relation to a document, including phrases like:\n- \"Check the word count of [filename]\"\n- \"What's the word count of [filename]\"\n- \"Stop when the word count is [number]\"\n- \"Keep the word count under [number]\"\n- \"How many words are in [filename]\"\n- Any similar reference to word count with a document\n\n## How to Use\n\nWhen word count is mentioned with a document reference:\n\n1. **Identify the target file** from the user's message (e.g., `article.md`, `chapter1.md`)\n\n2. **Run the word count command** using Bash:\n   ```bash\n   wc -w <filename>\n   ```\n\n3. **Interpret the context**:\n   - **Checking**: If the user asks to check word count, report the current count\n   - **Monitoring**: If the user mentions a target word count (e.g., \"stop when word count is 4500\"), compare the current count to the target and inform the user whether the goal has been met\n   - **Writing**: If generating or editing content with a word count constraint, check periodically and adjust as needed\n\n4. **Report clearly**: Present the word count information in a natural, contextual way based on the user's request\n\n## Examples\n\n**User**: \"Check the word count of article.md\"\n**Action**: Run `wc -w article.md` and report: \"article.md has 3,245 words.\"\n\n**User**: \"Keep writing chapter1.md until it reaches 5000 words\"\n**Action**: Periodically run `wc -w chapter1.md` while writing, and stop when the count reaches or exceeds 5000 words.\n\n**User**: \"What's the word count of my draft.md?\"\n**Action**: Run `wc -w draft.md` and report the count naturally in response.\n",
        "writeas/SKILL.md": "---\nname: writeas\ndescription: Write.as API Documentation\n---\n\n# Write.as Skill\n\nComprehensive assistance with Write.as and WriteFreely API development, based on official API documentation. This skill provides practical guidance for building applications around the Write.as blogging platform and its open-source WriteFreely implementation.\n\n## When to Use This Skill\n\nThis skill should be triggered when:\n- Working with the Write.as REST API (`https://write.as/api/`)\n- Building applications that interact with Write.as or WriteFreely\n- Implementing blog post creation, updates, or management\n- Setting up user authentication for Write.as accounts\n- Creating or managing collections (blogs)\n- Implementing crossposting to Twitter, Medium, or Tumblr\n- Integrating Markdown rendering for blog posts\n- Debugging Write.as API calls or authentication issues\n- Working with anonymous posts and post claiming\n- Building self-hosted WriteFreely instances\n\n## Key Concepts\n\n### Core Terminology\n\n**Posts**: Markdown-based articles with metadata. Posts can be created anonymously or associated with a user account.\n\n**Collections**: Known as \"blogs\" in the UI. Container for multiple posts with customizable settings. Creating collections requires a Pro account.\n\n**Users**: Registered accounts with password, email, and resource access. Users can own multiple collections and posts.\n\n**Tokens**: Used for authentication and post management. Anonymous posts return a `token` for later modifications, while user operations use access tokens via `Authorization: Token {access_token}` header.\n\n### Authentication\n\n- **Anonymous**: No authentication required. Store the returned `token` for later updates/deletions.\n- **User-based**: Login via `/api/auth/login` to get an access token, then pass it in the `Authorization` header.\n\n## Quick Reference\n\n### Creating an Anonymous Post\n\n```json\nPOST https://write.as/api/posts\nContent-Type: application/json\n\n{\n  \"body\": \"This is a post.\",\n  \"title\": \"My First Post\"\n}\n```\n\n**Response:**\n```json\n{\n  \"code\": 201,\n  \"data\": {\n    \"id\": \"rf3t35fkax0aw\",\n    \"token\": \"ozPEuJWYK8L1QsysBUcTUKy9za7yqQ4M\",\n    \"title\": \"My First Post\",\n    \"body\": \"This is a post.\"\n  }\n}\n```\n\n**Note**: Save the `token` to update or delete this post later.\n\n### Updating a Post (Anonymous)\n\n```json\nPOST https://write.as/api/posts/{POST_ID}\nContent-Type: application/json\n\n{\n  \"token\": \"ozPEuJWYK8L1QsysBUcTUKy9za7yqQ4M\",\n  \"body\": \"This is an updated post.\"\n}\n```\n\n### User Authentication\n\n```json\nPOST https://write.as/api/auth/login\nContent-Type: application/json\n\n{\n  \"alias\": \"username\",\n  \"pass\": \"password\"\n}\n```\n\n**Response:**\n```json\n{\n  \"code\": 200,\n  \"data\": {\n    \"access_token\": \"00000000-0000-0000-0000-000000000000\",\n    \"user\": {\n      \"username\": \"username\"\n    }\n  }\n}\n```\n\n### Creating a Post as Authenticated User\n\n```json\nPOST https://write.as/api/posts\nAuthorization: Token 00000000-0000-0000-0000-000000000000\nContent-Type: application/json\n\n{\n  \"body\": \"# My authenticated post\\n\\nThis post is linked to my account.\",\n  \"title\": \"Authenticated Post\"\n}\n```\n\n### Styling Posts with Fonts\n\n```json\nPOST https://write.as/api/posts\nContent-Type: application/json\n\n{\n  \"body\": \"This is a monospace code post.\",\n  \"font\": \"code\"\n}\n```\n\n**Available fonts:**\n- `sans` - Sans-serif with word wrap\n- `serif` or `norm` - Serif with word wrap\n- `wrap` - Monospace with word wrap\n- `mono` - Monospace without wrap\n- `code` - Syntax-highlighted monospace\n\n### Crossposting to Social Media\n\n```json\nPOST https://write.as/api/posts\nAuthorization: Token 00000000-0000-0000-0000-000000000000\nContent-Type: application/json\n\n{\n  \"body\": \"Check out my new post!\",\n  \"title\": \"My Post\",\n  \"crosspost\": [\n    {\"twitter\": \"yourusername\"},\n    {\"medium\": \"yourusername\"}\n  ]\n}\n```\n\n**Supported services**: Twitter, Tumblr, Medium\n\n### Creating a Collection (Pro Feature)\n\n```json\nPOST https://write.as/api/collections\nAuthorization: Token 00000000-0000-0000-0000-000000000000\nContent-Type: application/json\n\n{\n  \"alias\": \"my-blog\",\n  \"title\": \"My Blog\"\n}\n```\n\n### Publishing to a Collection\n\n```json\nPOST https://write.as/api/collections/{ALIAS}/posts\nAuthorization: Token 00000000-0000-0000-0000-000000000000\nContent-Type: application/json\n\n{\n  \"body\": \"# First blog post\\n\\nWelcome to my blog!\",\n  \"title\": \"Hello World\"\n}\n```\n\n### Moving Anonymous Post to Collection\n\n```json\nPOST https://write.as/api/collections/{ALIAS}/collect\nAuthorization: Token 00000000-0000-0000-0000-000000000000\nContent-Type: application/json\n\n[\n  {\n    \"id\": \"rf3t35fkax0aw\",\n    \"token\": \"ozPEuJWYK8L1QsysBUcTUKy9za7yqQ4M\"\n  }\n]\n```\n\n### Rendering Markdown to HTML\n\n```json\nPOST https://write.as/api/markdown\nContent-Type: application/json\n\n{\n  \"raw_body\": \"# Hello\\n\\nThis is **Markdown**.\"\n}\n```\n\n**Response:**\n```json\n{\n  \"code\": 200,\n  \"data\": {\n    \"body\": \"<h1>Hello</h1>\\n<p>This is <strong>Markdown</strong>.</p>\"\n  }\n}\n```\n\n## Error Handling\n\nAll API responses follow this structure:\n\n```json\n{\n  \"code\": 200,\n  \"data\": {}\n}\n```\n\n**Common HTTP status codes:**\n- `200` - Success\n- `201` - Created successfully\n- `400` - Bad request or malformed data\n- `401` - Missing or invalid authentication\n- `403` - Insufficient permissions (e.g., creating collection without Pro)\n- `404` - Resource not found\n- `410` - Post unpublished (may return later)\n- `429` - Rate limited\n\n## Reference Files\n\nThis skill includes comprehensive documentation in `references/`:\n\n- **api.md** - Complete Write.as API documentation including:\n  - All available endpoints (posts, collections, users, formatting)\n  - Request/response examples\n  - Authentication methods\n  - Crossposting configuration\n  - Error codes and handling\n\nUse `view` to read the API reference file when detailed information is needed.\n\n## Working with This Skill\n\n### For Beginners\n\n1. **Start with anonymous posts**: No authentication required, perfect for testing\n2. **Save the token**: Always store the `token` returned when creating anonymous posts\n3. **Test with single posts**: Create, update, retrieve, and delete one post before scaling\n4. **Read error responses**: The API provides clear error messages in the response body\n\n### For Intermediate Users\n\n1. **Implement user authentication**: Use `/api/auth/login` to get access tokens\n2. **Work with collections**: Create blogs and organize posts into collections\n3. **Enable crossposting**: Automatically share posts to Twitter, Medium, or Tumblr\n4. **Claim anonymous posts**: Convert anonymous posts to user-owned posts with `/api/posts/claim`\n5. **Use post styling**: Apply different fonts (`code`, `sans`, `mono`) for various content types\n\n### For Advanced Users\n\n1. **Build full applications**: Leverage all endpoints for complete blog management\n2. **Self-host WriteFreely**: Deploy open-source WriteFreely instances\n3. **Implement rate limiting**: Respect API limits and handle 429 responses\n4. **Use client libraries**: Leverage official libraries (Go, Swift, Java) or community libraries (PHP, Python, JavaScript, .NET)\n5. **Handle edge cases**: Implement retry logic, token refresh, and error recovery\n\n### Navigation Tips\n\n- **Authentication flow**: See `api.md` ‚Üí \"Users\" section\n- **Post management**: See `api.md` ‚Üí \"Posts\" section\n- **Collection setup**: See `api.md` ‚Üí \"Collections\" section\n- **Crossposting**: See `api.md` ‚Üí \"Crossposting\" section\n- **Error handling**: See `api.md` ‚Üí \"Error Handling\" section\n\n## API Best Practices\n\n1. **Store tokens securely**: Never commit access tokens or post tokens to version control\n2. **Handle anonymous posts**: Always save the `token` field when creating anonymous posts\n3. **Respect rate limits**: Implement exponential backoff on 429 responses\n4. **Use HTTPS**: All API endpoints require HTTPS\n5. **Test with small datasets**: Verify your integration with a few posts before scaling\n6. **Check Pro status**: Collection creation requires a Pro account\n7. **Validate Markdown**: Test Markdown rendering with `/api/markdown` before posting\n8. **Handle 410 gracefully**: Unpublished posts may return with 410 status\n\n## Common Use Cases\n\n### Building a Blog Publishing Tool\nUse authenticated user endpoints to create collections, publish posts, and manage content.\n\n### Creating a Markdown Editor Integration\nImplement post creation with Markdown preview using `/api/markdown` endpoint.\n\n### Social Media Cross-Poster\nLeverage the `crosspost` parameter to automatically share posts to multiple platforms.\n\n### Anonymous Blogging Platform\nBuild an app using anonymous post creation, storing tokens locally for later management.\n\n### Content Migration Tool\nUse `/api/posts/claim` to import anonymous posts into a user account.\n\n## Client Libraries\n\n**Official:**\n- Go: https://github.com/writeas/go-writeas\n- Swift: https://github.com/writeas/writefreely-swift\n- Java: https://github.com/writeas/java-writeas\n\n**Community:**\n- PHP, Python, JavaScript, Vala, .NET Core (see Write.as documentation)\n\n## Resources\n\n### Official Documentation\n- API Docs: https://developers.write.as/docs/api/\n- WriteFreely: https://writefreely.org/ (open-source self-hosting)\n\n### Key Features\n- **Backwards compatibility**: Endpoints rarely removed; new features added alongside existing\n- **Flexible authentication**: Works anonymously or with user tokens\n- **Markdown-first**: All content uses Markdown formatting\n- **Self-hosting ready**: WriteFreely powers Write.as and independent instances\n\n## Notes\n\n- All API requests must use HTTPS\n- Anonymous posts can be claimed by authenticated users\n- Collections (blogs) require a Pro subscription on Write.as\n- Post IDs are permanent and unique\n- Tokens are sensitive credentials - protect them like passwords\n- The API maintains backwards compatibility - old integrations continue working\n\n## Updating\n\nThis skill is based on the official Write.as API documentation. For the latest updates, refer to:\n- https://developers.write.as/docs/api/\n"
      },
      "plugins": [
        {
          "name": "ai-summary-request",
          "description": "Creates llms.txt files for AI discoverability and AI Summary Request footer components with platform icons.",
          "source": "./",
          "strict": false,
          "skills": [
            "./ai-summary-request"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install ai-summary-request@skillsforge-marketplace"
          ]
        },
        {
          "name": "apify-js-sdk",
          "description": "Interacts with the Apify JS SDK. Allows you to work with Actors and other Apify features.",
          "source": "./",
          "strict": false,
          "skills": [
            "./apify-js-sdk"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install apify-js-sdk@skillsforge-marketplace"
          ]
        },
        {
          "name": "article-title-optimizer",
          "description": "Optimizes article titles for search engines.",
          "source": "./",
          "strict": false,
          "skills": [
            "./article-title-optimizer"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install article-title-optimizer@skillsforge-marketplace"
          ]
        },
        {
          "name": "cronjob-org",
          "description": "Interacts with the cronjob.org API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./cronjob-org"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install cronjob-org@skillsforge-marketplace"
          ]
        },
        {
          "name": "figlet-text-converter",
          "description": "Converts marked text in files to ASCII art using figlet tag syntax.",
          "source": "./",
          "strict": false,
          "skills": [
            "./figlet-text-converter"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install figlet-text-converter@skillsforge-marketplace"
          ]
        },
        {
          "name": "forem-api",
          "description": "Interacts with the Forem API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./forem-api"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install forem-api@skillsforge-marketplace"
          ]
        },
        {
          "name": "frankenphp",
          "description": "Interacts with the FrankenPHP App Server.",
          "source": "./",
          "strict": false,
          "skills": [
            "./frankenphp"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install frankenphp@skillsforge-marketplace"
          ]
        },
        {
          "name": "github-issue-fetcher",
          "description": "Fetches GitHub issues for a repository.",
          "source": "./",
          "strict": false,
          "skills": [
            "./github-issue-fetcher"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install github-issue-fetcher@skillsforge-marketplace"
          ]
        },
        {
          "name": "hashnode-api",
          "description": "Interacts with the Hashnode API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./hashnode-api"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install hashnode-api@skillsforge-marketplace"
          ]
        },
        {
          "name": "haveibeenpwned",
          "description": "Interacts with the HaveIBeenPwned API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./haveibeenpwned"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install haveibeenpwned@skillsforge-marketplace"
          ]
        },
        {
          "name": "laravel",
          "description": "Collection of skills used to work with Laravel",
          "source": "./",
          "strict": false,
          "skills": [
            "./laravel",
            "./laravel-cashier-paddle",
            "./laravel-cashier-stripe",
            "./laravel-dusk",
            "./laravel-mcp",
            "./laravel-prompts"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install laravel@skillsforge-marketplace"
          ]
        },
        {
          "name": "linode-api",
          "description": "Interacts with the Linode API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./linode-api"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install linode-api@skillsforge-marketplace"
          ]
        },
        {
          "name": "linode-cli",
          "description": "Interacts with the Linode CLI.",
          "source": "./",
          "strict": false,
          "skills": [
            "./linode-cli"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install linode-cli@skillsforge-marketplace"
          ]
        },
        {
          "name": "midjourney-replicate-flux",
          "description": "Interacts with the Replicate MCP server to create Midjourney-style prompts and images using Blackforest Labs Flux 1.1 Pro Model.",
          "source": "./",
          "strict": false,
          "skills": [
            "./midjourney-replicate-flux"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install midjourney-replicate-flux@skillsforge-marketplace"
          ]
        },
        {
          "name": "n8n",
          "description": "Interacts with the n8n API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./n8n"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install n8n@skillsforge-marketplace"
          ]
        },
        {
          "name": "ollama",
          "description": "Interacts with the Ollama API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./ollama"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install ollama@skillsforge-marketplace"
          ]
        },
        {
          "name": "openrouter",
          "description": "Interacts with the OpenRouter API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./openrouter"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install openrouter@skillsforge-marketplace"
          ]
        },
        {
          "name": "pinterest-api",
          "description": "Interacts with the Pinterest API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./pinterest-api"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install pinterest-api@skillsforge-marketplace"
          ]
        },
        {
          "name": "replicate-cli",
          "description": "Interacts with the Replicate CLI.",
          "source": "./",
          "strict": false,
          "skills": [
            "./replicate-cli"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install replicate-cli@skillsforge-marketplace"
          ]
        },
        {
          "name": "revenuecat",
          "description": "Interacts with the RevenueCat API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./revenuecat"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install revenuecat@skillsforge-marketplace"
          ]
        },
        {
          "name": "snapas",
          "description": "Interacts with the Snap.as API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./snapas"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install snapas@skillsforge-marketplace"
          ]
        },
        {
          "name": "tdd-methodology-expert",
          "description": "Expertise in Test-Driven Development (TDD) methodology.",
          "source": "./",
          "strict": false,
          "skills": [
            "./tdd-methodology-expert"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install tdd-methodology-expert@skillsforge-marketplace"
          ]
        },
        {
          "name": "threads-api",
          "description": "Interacts with the Threads API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./threads-api"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install threads-api@skillsforge-marketplace"
          ]
        },
        {
          "name": "tumblr",
          "description": "Interacts with the Tumblr API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./tumblr"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install tumblr@skillsforge-marketplace"
          ]
        },
        {
          "name": "vastai-api",
          "description": "Interacts with the VastAI API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./vastai-api"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install vastai-api@skillsforge-marketplace"
          ]
        },
        {
          "name": "vercel",
          "description": "Interacts with the Vercel API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./vercel"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install vercel@skillsforge-marketplace"
          ]
        },
        {
          "name": "word-count-checker",
          "description": "Checks the word count of a file.",
          "source": "./",
          "strict": false,
          "skills": [
            "./word-count-checker"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install word-count-checker@skillsforge-marketplace"
          ]
        },
        {
          "name": "writeas",
          "description": "Interacts with the Write.as API.",
          "source": "./",
          "strict": false,
          "skills": [
            "./writeas"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install writeas@skillsforge-marketplace"
          ]
        },
        {
          "name": "presumption-guard",
          "description": "Detects and flags presumptive actions after they occur - makes it clear when Claude has acted without explicit permission.",
          "source": "./presumption-guard",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add rawveg/skillsforge-marketplace",
            "/plugin install presumption-guard@skillsforge-marketplace"
          ]
        }
      ]
    }
  ]
}