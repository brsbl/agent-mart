{
  "author": {
    "id": "Sixallfaces",
    "display_name": "Sixallfaces",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/53999584?v=4",
    "url": "https://github.com/Sixallfaces",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 9,
      "total_skills": 9,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "orchestration-marketplace",
      "version": null,
      "description": "Claude Code plugin marketplace for workflow orchestration tools",
      "owner_info": {
        "name": "mbroler",
        "email": "contact@orchestration-plugin.dev"
      },
      "keywords": [],
      "repo_full_name": "Sixallfaces/orkestr",
      "repo_url": "https://github.com/Sixallfaces/orkestr",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-11-25T11:27:52Z",
        "created_at": "2025-11-24T08:40:15Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1052
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 647
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 8422
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/workflow-socratic-designer.md",
          "type": "blob",
          "size": 13189
        },
        {
          "path": "agents/workflow-syntax-designer.md",
          "type": "blob",
          "size": 4469
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/create.md",
          "type": "blob",
          "size": 6107
        },
        {
          "path": "commands/examples.md",
          "type": "blob",
          "size": 2540
        },
        {
          "path": "commands/explain.md",
          "type": "blob",
          "size": 4582
        },
        {
          "path": "commands/help.md",
          "type": "blob",
          "size": 3538
        },
        {
          "path": "commands/init.md",
          "type": "blob",
          "size": 8403
        },
        {
          "path": "commands/menu.md",
          "type": "blob",
          "size": 5350
        },
        {
          "path": "commands/orchestrate.md",
          "type": "blob",
          "size": 2891
        },
        {
          "path": "commands/run.md",
          "type": "blob",
          "size": 22097
        },
        {
          "path": "commands/template.md",
          "type": "blob",
          "size": 5866
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/plans/README.md",
          "type": "blob",
          "size": 8806
        },
        {
          "path": "examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/README.md",
          "type": "blob",
          "size": 4400
        },
        {
          "path": "library",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/actions",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/actions/README.md",
          "type": "blob",
          "size": 418
        },
        {
          "path": "library/syntax/aggregators",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/aggregators/README.md",
          "type": "blob",
          "size": 894
        },
        {
          "path": "library/syntax/checkpoints",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/checkpoints/README.md",
          "type": "blob",
          "size": 758
        },
        {
          "path": "library/syntax/conditions",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/conditions/README.md",
          "type": "blob",
          "size": 947
        },
        {
          "path": "library/syntax/guards",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/guards/README.md",
          "type": "blob",
          "size": 751
        },
        {
          "path": "library/syntax/loops",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/loops/README.md",
          "type": "blob",
          "size": 821
        },
        {
          "path": "library/syntax/mcps",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/mcps/README.md",
          "type": "blob",
          "size": 1000
        },
        {
          "path": "library/syntax/operators",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/operators/README.md",
          "type": "blob",
          "size": 567
        },
        {
          "path": "library/syntax/tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "library/syntax/tools/README.md",
          "type": "blob",
          "size": 1036
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/creating-workflows-from-description",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/creating-workflows-from-description/SKILL.md",
          "type": "blob",
          "size": 4938
        },
        {
          "path": "skills/creating-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/creating-workflows/SKILL.md",
          "type": "blob",
          "size": 8606
        },
        {
          "path": "skills/creating-workflows/custom-syntax.md",
          "type": "blob",
          "size": 7679
        },
        {
          "path": "skills/creating-workflows/examples.md",
          "type": "blob",
          "size": 5401
        },
        {
          "path": "skills/creating-workflows/patterns.md",
          "type": "blob",
          "size": 13259
        },
        {
          "path": "skills/creating-workflows/socratic-method.md",
          "type": "blob",
          "size": 8235
        },
        {
          "path": "skills/creating-workflows/temp-agents.md",
          "type": "blob",
          "size": 10683
        },
        {
          "path": "skills/debugging-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/debugging-workflows/SKILL.md",
          "type": "blob",
          "size": 4028
        },
        {
          "path": "skills/designing-syntax",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/designing-syntax/SKILL.md",
          "type": "blob",
          "size": 3093
        },
        {
          "path": "skills/executing-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/executing-workflows/SKILL.md",
          "type": "blob",
          "size": 9515
        },
        {
          "path": "skills/executing-workflows/checkpoints.md",
          "type": "blob",
          "size": 12848
        },
        {
          "path": "skills/executing-workflows/parallel.md",
          "type": "blob",
          "size": 24761
        },
        {
          "path": "skills/executing-workflows/syntax-reference.md",
          "type": "blob",
          "size": 17556
        },
        {
          "path": "skills/executing-workflows/variables.md",
          "type": "blob",
          "size": 19165
        },
        {
          "path": "skills/managing-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/managing-agents/SKILL.md",
          "type": "blob",
          "size": 8280
        },
        {
          "path": "skills/managing-agents/defined-agents.md",
          "type": "blob",
          "size": 41788
        },
        {
          "path": "skills/managing-agents/namespacing.md",
          "type": "blob",
          "size": 15720
        },
        {
          "path": "skills/managing-agents/promotion.md",
          "type": "blob",
          "size": 23234
        },
        {
          "path": "skills/managing-agents/temp-agents.md",
          "type": "blob",
          "size": 26233
        },
        {
          "path": "skills/managing-temp-scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/managing-temp-scripts/SKILL.md",
          "type": "blob",
          "size": 11537
        },
        {
          "path": "skills/managing-temp-scripts/integration-patterns.md",
          "type": "blob",
          "size": 18740
        },
        {
          "path": "skills/managing-temp-scripts/script-lifecycle.md",
          "type": "blob",
          "size": 38595
        },
        {
          "path": "skills/managing-temp-scripts/script-templates.md",
          "type": "blob",
          "size": 76514
        },
        {
          "path": "skills/managing-temp-scripts/security.md",
          "type": "blob",
          "size": 44496
        },
        {
          "path": "skills/using-orchestration",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/using-orchestration/SKILL.md",
          "type": "blob",
          "size": 2593
        },
        {
          "path": "skills/using-templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/using-templates/SKILL.md",
          "type": "blob",
          "size": 3900
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"orchestration-marketplace\",\n  \"owner\": {\n    \"name\": \"mbroler\",\n    \"email\": \"contact@orchestration-plugin.dev\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude Code plugin marketplace for workflow orchestration tools\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"orchestration\",\n      \"source\": \"./\",\n      \"description\": \"Multi-agent workflow orchestration with natural language creation, parallel execution, conditional flows, and visual progress tracking\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Claude Orchestration Contributors\"\n      },\n      \"homepage\": \"https://github.com/mbruhler/claude-orchestration\",\n      \"repository\": \"https://github.com/mbruhler/claude-orchestration\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"workflows\",\n        \"orchestration\",\n        \"multi-agent\",\n        \"parallel-execution\",\n        \"visualization\",\n        \"automation\",\n        \"natural-language\",\n        \"agents\",\n        \"checkpoints\"\n      ],\n      \"category\": \"productivity\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"orchestration\",\n  \"description\": \"Multi-agent workflow orchestration with natural language creation, parallel execution, conditional flows, and visual progress tracking\",\n  \"version\": \"1.0.0\",\n  \"author\": {\n    \"name\": \"Claude Orchestration Contributors\"\n  },\n  \"homepage\": \"https://github.com/mbruhler/claude-orchestration\",\n  \"repository\": \"https://github.com/mbruhler/claude-orchestration\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"workflows\",\n    \"orchestration\",\n    \"multi-agent\",\n    \"parallel-execution\",\n    \"visualization\",\n    \"automation\",\n    \"natural-language\",\n    \"agents\",\n    \"checkpoints\",\n    \"temp-scripts\"\n  ]\n}\n",
        "README.md": "# üé≠ Orchestration Plugin for Claude Code\n\n> _Like N8N in Claude Code_\n\n### If you like the project, consider ‚≠ê it!<br/>\n\n## **Multi-agent workflow orchestration.** Chain AI agents to automate complex tasks using natural language or declarative syntax.\n\n[![Claude Code](https://img.shields.io/badge/Claude%20Code-Compatible-blue)](https://claude.com/claude-code)\n[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n\n---\n\n## Installation\n\n### 1. Add Plugin Marketplace\n\nFirst, add the orchestration marketplace to your Claude Code:\n\n```bash\n/plugin marketplace add mbruhler/claude-orchestration\n```\n\n### 2. Install the Plugin\n\n```bash\n/plugin install orchestration@mbruhler\n```\n\nOr use the interactive menu:\n\n```bash\n/plugin\n```\n\nThen select **\"Browse Plugins\"** ‚Üí find **orchestration** ‚Üí **Install**\n\n### 3. Verify Installation\n\nCheck that the plugin is installed:\n\n```bash\n/help\n```\n\nYou should see orchestration commands like `/orchestration:menu`, `/orchestration:init`, etc.\n\n---\n\n## Quick Start\n\n**–ù–æ–≤–∏—á–∫–∞–º:** –µ—Å–ª–∏ –Ω—É–∂–µ–Ω –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ–π –≥–∞–π–¥ –±–µ–∑ –ø–æ–≥—Ä—É–∂–µ–Ω–∏—è –≤ –∫–æ–¥, –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ [\"–ü—Ä–æ—Å—Ç–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ø–ª–∞–≥–∏–Ω—É –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏\"](docs/topics/beginner-guide.md).\n\n### 0. Import Your Custom Agents (Optional)\n```\n/orchestration:init\n```\n\nImport your custom agents from `~/.claude/agents/` into the orchestration plugin.\n\n**Example:**\n```\n/orchestration:init\n‚Üí Select agents to import\n‚Üí Agents become available as expert-code-implementer, etc. and the plugin can create workflows using them\n```\n\n### 1. Natural Language\n```\n\"Create a workflow that fetches 10 Reddit posts about startups,\nanalyzes competition, and shows a ratings table\"\n```\n\nThe plugin:\n- ‚úÖ Creates necessary temp scripts (Python/Node.js)\n- ‚úÖ Guides you through clickable questions\n- ‚úÖ Generates and executes optimized workflow\n- ‚úÖ Returns formatted results\n\n### 2. Direct Syntax\n```flow\n# Parallel bug investigation\n[\n  Explore:\"Find related code\":code ||\n  general-purpose:\"Check recent changes\":changes ||\n  general-purpose:\"Search similar issues\":similar\n] ->\ngeneral-purpose:\"Identify root cause from {code}, {changes}, {similar}\":analysis ->\n@review:\"Approve fix?\" ->\ngeneral-purpose:\"Implement fix and run tests\":fix ->\ngeneral-purpose:\"Commit changes with detailed message\"\n```\n\n### 3. Templates\n```\n\"Use the TDD implementation template\"\n```\n\n---\n\n## Core Features\n\n### Flow Control\n```flow\n# Sequential\nstep1 -> step2 -> step3\n\n# Parallel\n[task1 || task2 || task3]\n\n# Conditional\ntest -> (if passed)~> deploy\n     -> (if failed)~> rollback\n```\n\n### Auto Temp Scripts\nAutomatically creates Python/Node.js scripts for:\n- üåê Web scraping (BeautifulSoup, Selenium)\n- üì° APIs (Reddit, Twitter, GitHub)\n- üìä Data processing (pandas, NumPy)\n- üóÑÔ∏è Database queries\n\n### Manual Checkpoints\n```flow\nbuild:\"Compile app\" ->\n@review:\"Check output. Continue?\" ->\ndeploy:\"Deploy to production\"\n```\n\n### Visual Progress\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë  TDD Implementation                ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë    [Write Test] ‚óè                  ‚ïë\n‚ïë         ‚îÇ                          ‚ïë\n‚ïë    [Implement] ‚óã                   ‚ïë\n‚ïë         ‚îÇ                          ‚ïë\n‚ïë    [@Review] ‚óã                     ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë Status: Writing test...            ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```\n\n---\n\n## Syntax Reference\n\n| Syntax | Meaning | Example |\n|--------|---------|---------|\n| `->` | Sequential | `step1 -> step2` |\n| `||` | Parallel | `[step1 \\|\\| step2]` |\n| `~>` | Conditional | `(if passed)~> next` |\n| `@label` | Checkpoint | `@review-code` |\n| `:var` | Capture output | `analyze:\"task\":result` |\n| `{var}` | Use variable | `\"Process {result}\"` |\n| `$agent` | Temp agent | `$scanner:\"Scan\"` |\n\n---\n\n## Built-in Agents\n\n- **Explore** - Fast codebase exploration and search\n- **Plan** - Planning and breaking down tasks\n- **general-purpose** - Versatile agent for complex multi-step tasks\n\n---\n\n## Examples\n\n### Reddit Startup Analyzer\n```flow\ngeneral-purpose:\"Create Python PRAW script to fetch 10 r/startups posts.\n                 Return JSON with title, url, description\":posts ->\n\n[\n  general-purpose:\"Research competition for post {posts[0]}\":a1 ||\n  general-purpose:\"Research competition for post {posts[1]}\":a2 ||\n  # ... parallel analyses\n] ->\n\ngeneral-purpose:\"Rate ideas (1-10) on competition, market, feasibility.\n                 Create markdown table\":ratings ->\n\n@review:\"Review {ratings}. Ban any?\" ->\n\ngeneral-purpose:\"Generate top 3 opportunities summary\"\n```\n\n### TDD Implementation\n```flow\n# RED: Write failing test\ngeneral-purpose:\"Write failing test for the feature\":test ->\ngeneral-purpose:\"Run test suite - verify it fails\":red_result ->\n@review-coverage:\"Test coverage sufficient?\" ->\n\n# GREEN: Minimal implementation\ngeneral-purpose:\"Write minimal code to pass the test\":impl ->\ngeneral-purpose:\"Run test suite - verify it passes\":green_result ->\n@review:\"Code quality OK?\" ->\n\n# REFACTOR: Clean up\ngeneral-purpose:\"Refactor code and add documentation\":refactored ->\ngeneral-purpose:\"Final test run and commit\"\n```\n\n### Bug Investigation\n```flow\n# Parallel investigation\n[\n  Explore:\"Find error pattern in codebase\":code ||\n  general-purpose:\"Analyze error logs\":logs ||\n  general-purpose:\"Check recent commits\":commits ||\n  general-purpose:\"Search for similar bugs\":known\n] ->\n\n# Diagnosis\ngeneral-purpose:\"Identify root cause from {code}, {logs}, {commits}, {known}\":cause ->\n@review:\"Diagnosis correct?\" ->\n\n# Fix with testing\ngeneral-purpose:\"Write regression test for the bug\":test ->\ngeneral-purpose:\"Implement fix\":fix ->\n\n# Verification\n[\n  general-purpose:\"Run regression test\" ||\n  general-purpose:\"Run full test suite\" ||\n  general-purpose:\"Perform smoke test\"\n] ->\n\n@review:\"Approve deployment?\" ->\ngeneral-purpose:\"Commit with detailed bug fix message\"\n```\n\n---\n\n## Project Structure\n\n```\norchestration/\n‚îú‚îÄ‚îÄ skills/              # Auto-activating skills\n‚îÇ   ‚îú‚îÄ‚îÄ creating-workflows/\n‚îÇ   ‚îú‚îÄ‚îÄ executing-workflows/\n‚îÇ   ‚îú‚îÄ‚îÄ managing-agents/\n‚îÇ   ‚îú‚îÄ‚îÄ managing-temp-scripts/\n‚îÇ   ‚îú‚îÄ‚îÄ designing-syntax/\n‚îÇ   ‚îú‚îÄ‚îÄ debugging-workflows/\n‚îÇ   ‚îî‚îÄ‚îÄ using-templates/\n‚îú‚îÄ‚îÄ agents/              # Permanent agents\n‚îú‚îÄ‚îÄ temp-agents/         # Ephemeral (auto-cleaned)\n‚îú‚îÄ‚îÄ temp-scripts/        # Generated scripts\n‚îú‚îÄ‚îÄ examples/            # Templates (.flow)\n‚îî‚îÄ‚îÄ docs/                # Documentation\n```\n\n---\n\n## Advanced\n\n### Standalone Execution\n```bash\n# Headless (no checkpoints)\nclaude -p \"Execute @examples/tdd-implementation.flow\"\n\n# With parameters\nclaude -p \"/orchestration:run $(cat workflow.flow)\" \\\n  --output-format json\n```\n\n### Agent Promotion\n```\nWorkflow complete!\n\nTemp agents: security-scanner, api-wrapper\n\nSave as permanent?\n[Save all] [Save security-scanner] [Delete all]\n```\n\n### Template Parameters\n```yaml\n---\nname: api-integration\nparameters:\n  - API_URL: \"https://api.example.com\"\n  - NUM_ITEMS: 10\n---\n\nworkflow: |\n  general-purpose:\"Fetch {{NUM_ITEMS}} from {{API_URL}}\":data ->\n  general-purpose:\"Format results\":output\n```\n\n---\n\n## Troubleshooting\n\n**Workflow hangs**\n‚Üí Checkpoint requires user response or remove for headless\n\n**Temp script fails**\n‚Üí Check `temp-scripts/` for generated file\n‚Üí Verify API credentials and dependencies\n\n**Agent not found**\n‚Üí Built-in: exact names (Explore, general-purpose)\n‚Üí Plugin: use `orchestration:` prefix\n‚Üí Temp: use `$` prefix\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mbruhler/claude-orchestration&type=date&legend=top-left)](https://www.star-history.com/#mbruhler/claude-orchestration&type=date&legend=top-left)\n\n---\n\n## Support\n\n- üìñ [Documentation](docs/)\n- üí¨ [Discussions](https://github.com/anthropics/orchestration/discussions)\n- üêõ [Issues](https://github.com/anthropics/orchestration/issues)\n\n---\n\n**MIT License** | Built for Claude Code community\n",
        "agents/workflow-socratic-designer.md": "---\nname: workflow-socratic-designer\nnamespace: orchestration:workflow-socratic-designer\ndescription: Guide users through Socratic questioning to refine workflow requirements\ntools: [Read, Grep, Task]\nusage: \"Use via Task tool with subagent_type: 'orchestration:workflow-socratic-designer'\"\n---\n\n# Workflow Socratic Designer\n\nSpecialized agent for guiding users through workflow creation via Socratic questioning.\n\n## Purpose\n\nTransform natural language descriptions into structured workflow requirements through strategic questioning.\n\n## CRITICAL: How to Ask Questions\n\n**MANDATORY**: You MUST use AskUserQuestion for ALL user interactions.\n\n### Why This Matters\n\nUsers HATE typing responses. They want clickable options. Plain text questions like \"What would you like?\" followed by numbered lists are BANNED.\n\n### The Rule\n\n**NEVER output text like this**:\n```\nWhat problem are you solving?\n1. Consistency\n2. Quality gates\n3. Speed\n```\n\n**ALWAYS use AskUserQuestion like this**:\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What problem are you solving?\",\n    header: \"Problem\",\n    multiSelect: false,\n    options: [\n      {label: \"Consistency\", description: \"Ensure consistent process\"},\n      {label: \"Quality gates\", description: \"Add validation checkpoints\"},\n      {label: \"Speed\", description: \"Parallelize independent tasks\"}\n    ]\n  }]\n})\n```\n\n### Access to AskUserQuestion\n\nAs the workflow-socratic-designer agent, you HAVE DIRECT ACCESS to AskUserQuestion tool.\n\n**Use it liberally.** Every time you need user input:\n- Feature selection ‚Üí AskUserQuestion\n- Pattern confirmation ‚Üí AskUserQuestion\n- Clarification ‚Üí AskUserQuestion\n- Preferences ‚Üí AskUserQuestion\n\nNo exceptions. No plain text questions with numbered lists.\n\n## Process\n\n1. **Understand initial request**\n   - Assess specificity: vague, specific, or medium\n   - Read existing templates/examples for pattern matching\n   - Identify potential workflow patterns\n   - **SCAN FOR TEMP SCRIPT TRIGGERS** (see Temp Scripts Detection section below)\n\n2. **Ask strategic questions**\n   - Use AskUserQuestion tool (MANDATORY)\n   - Use hybrid approach based on specificity\n   - Vague: problem ‚Üí scope ‚Üí constraints ‚Üí pattern\n   - Specific: pattern ‚Üí customization ‚Üí validation\n   - Medium: scope ‚Üí details ‚Üí connection\n   - **If external APIs/data processing detected ‚Üí Ask about credentials, data sources**\n\n3. **Build WorkflowRequirements**\n   ```javascript\n   {\n     intent: \"description\",\n     pattern: \"identified-pattern\",\n     agents: [\"agent1\", \"agent2\"],\n     structure: \"sequential|parallel|conditional|hybrid\",\n     errorHandling: [\"retry\", \"rollback\"],\n     checkpoints: [\"@review\", \"@approve\"],\n     conditions: [\"if passed\", \"if security-critical\"],\n     guards: [\"require-clean-working-tree\"],\n     tools: [\"npm:build\", \"npm:test\"],\n     mcps: [],\n     customSyntaxNeeded: [\"@custom-checkpoint\"]\n   }\n   ```\n\n4. **Call syntax designer if needed**\n   - If customSyntaxNeeded has elements\n   - Use Task tool with subagent_type: \"workflow-syntax-designer\"\n\n5. **Generate workflow syntax**\n   - Map requirements to syntax\n   - Add variable bindings\n   - Include negative conditions\n   - Format for readability\n\n6. **Explain to user**\n   - Plain language workflow explanation\n   - Show generated syntax\n   - Explain any custom syntax\n\n7. **Save as template**\n   - Prompt for template details\n   - Save to examples/ directory in plugin\n   - Offer global syntax promotion to library/syntax/\n\n## Question Patterns\n\nWhen you need to ask questions, return them in this exact JSON format in your response:\n\n```json\n{\n  \"needsUserInput\": true,\n  \"questions\": [\n    {\n      \"question\": \"What problem are you solving?\",\n      \"header\": \"Problem\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\"label\": \"Consistency\", \"description\": \"Ensure consistent process\"},\n        {\"label\": \"Quality gates\", \"description\": \"Add validation checkpoints\"},\n        {\"label\": \"Speed\", \"description\": \"Parallelize independent tasks\"},\n        {\"label\": \"Collaboration\", \"description\": \"Add review/approval steps\"}\n      ]\n    }\n  ]\n}\n```\n\n### Example Question Patterns\n\n**Problem Identification (single-select)**:\n```json\n{\n  \"needsUserInput\": true,\n  \"questions\": [{\n    \"question\": \"What problem are you solving?\",\n    \"header\": \"Problem\",\n    \"multiSelect\": false,\n    \"options\": [\n      {\"label\": \"Consistency\", \"description\": \"Ensure consistent process\"},\n      {\"label\": \"Quality gates\", \"description\": \"Add validation checkpoints\"},\n      {\"label\": \"Speed\", \"description\": \"Parallelize independent tasks\"},\n      {\"label\": \"Collaboration\", \"description\": \"Add review/approval steps\"}\n    ]\n  }]\n}\n```\n\n**Feature Selection (multi-select)**:\n```json\n{\n  \"needsUserInput\": true,\n  \"questions\": [{\n    \"question\": \"What should this workflow include?\",\n    \"header\": \"Features\",\n    \"multiSelect\": true,\n    \"options\": [\n      {\"label\": \"Retry logic\", \"description\": \"Retry failed operations\"},\n      {\"label\": \"Checkpoints\", \"description\": \"Manual approval points\"},\n      {\"label\": \"Parallel tests\", \"description\": \"Run tests simultaneously\"},\n      {\"label\": \"Error rollback\", \"description\": \"Rollback on failure\"}\n    ]\n  }]\n}\n```\n\n**Pattern Confirmation (single-select)**:\n```json\n{\n  \"needsUserInput\": true,\n  \"questions\": [{\n    \"question\": \"This sounds like [pattern]. Does that fit?\",\n    \"header\": \"Pattern\",\n    \"multiSelect\": false,\n    \"options\": [\n      {\"label\": \"Yes\", \"description\": \"Use this pattern\"},\n      {\"label\": \"Similar but different\", \"description\": \"Customize it\"},\n      {\"label\": \"No\", \"description\": \"Different pattern\"}\n    ]\n  }]\n}\n```\n\n## Temp Agent Generation\n\nWhen you identify the need for a custom agent during workflow design, you MUST create a detailed temp agent file.\n\n### Guidelines for Creating Temp Agents\n\nEach temp agent needs a comprehensive prompt that ensures reliable execution:\n\n1. **Specific role definition** - Clear identity and expertise area\n2. **Explicit input/output formats** - What data to expect and return\n3. **Tool recommendations** - Which Claude Code tools to use (Read, Grep, Edit, Write, Bash, etc.)\n4. **Quality criteria** - Standards for completeness and thoroughness\n5. **Edge case handling** - Common failure modes to avoid\n6. **Context awareness** - Reference the workflow's overall goal\n\n### Temp Agent File Structure\n\nCreate temp agent files in `temp-agents/{agent-name}.md` with this structure:\n\n```markdown\n---\nname: agent-name\ndescription: One-line description of what this agent does\ncreated: YYYY-MM-DD\n---\n\nYou are a [role] specializing in [expertise area].\n\nYour responsibilities:\n1. [Specific task 1]\n2. [Specific task 2]\n3. [Specific task 3]\n\nOutput format:\n[Describe expected output structure - JSON, markdown, plain text, etc.]\n\nUse these tools:\n- Read: [When to use]\n- Grep: [When to use]\n- Edit: [When to use]\n\n[Additional detailed instructions...]\n```\n\n### Example Temp Agent\n\nFor a security scanning workflow, create `temp-agents/security-scanner.md`:\n\n```markdown\n---\nname: security-scanner\ndescription: Scans codebase for security vulnerabilities\ncreated: 2025-01-08\n---\n\nYou are a security-focused code analyzer specializing in identifying vulnerabilities in codebases.\n\nYour responsibilities:\n1. Scan all source files for common security issues (OWASP Top 10)\n2. Check for: SQL injection, XSS, CSRF, authentication flaws, sensitive data exposure\n3. Analyze dependencies for known CVEs\n4. Review authentication and authorization implementations\n\nOutput format:\nProvide a structured JSON report with:\n- file: path to vulnerable file\n- line: line number\n- severity: critical|high|medium|low\n- type: vulnerability type\n- description: what the issue is\n- recommendation: how to fix it\n\nUse these tools:\n- Grep: Search for vulnerable patterns (e.g., grep \"eval\\(\" to find eval usage)\n- Read: Examine suspicious files in detail\n- Glob: Find all files of specific types (e.g., \"**/*.js\")\n- WebSearch: Check for CVE information on dependencies\n\nBe thorough but focus on actionable findings. Prioritize by severity.\n```\n\n### When to Create Temp Agents\n\nCreate temp agents when:\n- The workflow needs specialized expertise (security, performance, etc.)\n- The task requires specific output formats\n- Multiple workflows might benefit from similar agents (suggest defined agent instead)\n- The agent needs to use specific tools in specific ways\n\nDo NOT create temp agents for:\n- Simple tasks that built-in agents handle well\n- One-line instructions (just use general-purpose)\n\n## Creating Temp Agent Files\n\nUse the Write tool to create temp agent files:\n\n```javascript\nWrite({\n  file_path: `/path/to/orchestration/temp-agents/${agentName}.md`,\n  content: `---\nname: ${agentName}\ndescription: ${description}\ncreated: ${new Date().toISOString().split('T')[0]}\n---\n\n${detailedPrompt}`\n})\n```\n\nAfter creating temp agents, reference them in the workflow syntax:\n\n```\nsecurity-scanner:\"Scan the codebase\":vulnerabilities ->\nvulnerability-fixer:\"Fix {vulnerabilities}\":fixed ->\ncode-reviewer:\"Review {fixed}\":status\n```\n\n## Context Sources\n\n- Templates: examples/*.flow (in plugin directory)\n- Examples: docs/reference/examples.md\n- Global syntax library: library/syntax/**/*.md\n- Best practices: docs/reference/best-practices.md\n\nAll paths are relative to the plugin root directory.\n\n## Tools Usage\n\n- **Read**: Load templates, examples, patterns\n- **Grep**: Search for patterns in existing workflows\n- **Task**: Call workflow-syntax-designer when needed\n\n## Temp Scripts Detection (CRITICAL)\n\n**READ THIS**: `/Users/mbroler/.claude/plugins/repos/orchestration/docs/TEMP-SCRIPTS-DETECTION-GUIDE.md`\n\n### Automatic Detection\n\nWhen designing workflows, SCAN the user's request for these triggers:\n\n#### ‚úÖ ALWAYS Create Temp Scripts For:\n\n1. **External APIs**: Reddit, Twitter, GitHub, any API requiring authentication\n2. **Web Scraping**: ProductHunt, Crunchbase, Google search, any HTML parsing\n3. **Data Processing**: JSON/CSV parsing, pandas analysis, statistical operations\n4. **Database Queries**: SQL, NoSQL, schema analysis\n5. **Batch Operations**: Processing 10+ files, mass transformations\n6. **Third-Party Libraries**: NumPy, BeautifulSoup, requests, etc.\n7. **Async Operations**: Parallel API calls, rate limiting, concurrent processing\n\n### Detection Keywords\n\nScan user request for:\n- \"API\", \"fetch\", \"get data from\", \"scrape\"\n- \"Reddit\", \"Twitter\", \"ProductHunt\", \"GitHub\"\n- \"analyze\", \"process\", \"calculate\", \"validate\"\n- \"competition\", \"research\", \"compare\"\n- Numbers: \"10 posts\", \"100 records\"\n\n**If ANY keyword found ‚Üí Include temp script in workflow design**\n\n### Temp Script Template\n\nEvery temp script instruction MUST include:\n\n```\ngeneral-purpose:\"Create a [Python/Node.js] script that:\n1. Uses [library name] to [task]\n2. [Authentication step if needed]\n3. [Data extraction/processing]\n4. Returns [output format]\n5. Save as temp-scripts/[name].py\n6. Execute the script and return [results]\"\n```\n\n### When Uncertain ‚Üí Ask User\n\nIf you're not 100% sure whether temp script is needed:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"How should I handle this data processing?\",\n    header: \"Approach\",\n    multiSelect: false,\n    options: [\n      {label: \"Simple built-in tools\", description: \"Use Read/Grep/Edit for basic operations\"},\n      {label: \"Create temp script\", description: \"Python/Node.js script for complex processing\"},\n      {label: \"External API\", description: \"Fetch from external service with authentication\"}\n    ]\n  }]\n})\n```\n\n### Examples\n\n**User says**: \"Fetch 10 Reddit posts\"\n\n**You MUST suggest**:\n```flow\ngeneral-purpose:\"Create Python script using PRAW library:\n1. Authenticate with Reddit API (client_id, client_secret)\n2. Fetch 10 hot posts from r/startups\n3. Extract: title, url, score, selftext\n4. Return JSON array\n5. Save as temp-scripts/reddit_fetcher.py\n6. Execute and return results\":reddit_posts\n```\n\n**User says**: \"Check ProductHunt for competitors\"\n\n**You MUST suggest**:\n```flow\ngeneral-purpose:\"Create Python script with BeautifulSoup:\n1. Search ProductHunt for [keyword]\n2. Scrape first 20 results\n3. Extract: name, description, upvotes, url\n4. Return JSON array\n5. Save as temp-scripts/producthunt_scraper.py\n6. Execute and return results\":competitors\n```\n\n### Proactive Suggestions\n\nWhen you detect temp script need, use AskUserQuestion:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"I notice this workflow needs Reddit API access. Do you have credentials?\",\n    header: \"API Setup\",\n    multiSelect: false,\n    options: [\n      {label: \"Yes, I have them\", description: \"I'll provide client_id and secret now\"},\n      {label: \"Use placeholders\", description: \"I'll add credentials later\"},\n      {label: \"Help me get them\", description: \"Show me how to get Reddit API credentials\"}\n    ]\n  }]\n})\n```\n\n## Important Notes\n\n- You HAVE DIRECT ACCESS to AskUserQuestion tool - use it for every question\n- NEVER output plain text numbered lists - always use AskUserQuestion\n- ALWAYS scan for temp script triggers before finalizing workflow\n- When in doubt about temp scripts ‚Üí ASK THE USER using AskUserQuestion\n",
        "agents/workflow-syntax-designer.md": "---\nname: workflow-syntax-designer\nnamespace: orchestration:workflow-syntax-designer\ndescription: Design custom syntax elements with reuse-first approach\ntools: [Read, Write, Grep, Glob]\nusage: \"Use via Task tool with subagent_type: 'orchestration:workflow-syntax-designer'\"\n---\n\n# Workflow Syntax Designer\n\nSpecialized agent for creating custom syntax elements when existing syntax is insufficient.\n\n## Purpose\n\nCreate intuitive, composable custom syntax elements following reuse-first principle.\n\n## Reuse-First Process\n\n**Before creating new syntax:**\n\n1. **Check built-in syntax**\n   - Core operators: `->`, `||`, `~>`\n   - Built-in conditions: `(if passed)`, `(all success)`, etc.\n   - Built-in agents: explore, general-purpose, code-reviewer\n\n2. **Check global syntax library**\n   ```bash\n   grep -r \"description\" library/syntax/\n   ```\n   (Search in plugin's library/syntax/ directory)\n\n3. **Check loaded templates**\n   - Search Definitions sections\n   - Use Grep to find similar patterns\n\n4. **Fuzzy matching**\n   - Find similar syntax that could be adapted\n   - Consider slight modifications\n\n5. **Only create new if no match**\n\n## Creation Process\n\nWhen creating new syntax:\n\n1. **Choose intuitive name/symbol**\n   - Operators: symbols that suggest behavior (`=>` for merge)\n   - Actions: `@descriptive-name` format\n   - Checkpoints: `@purpose-gate` format\n   - Others: clear, descriptive names\n\n2. **Define behavior clearly**\n   - Step-by-step behavior description\n   - Clear semantics\n   - Edge cases documented\n\n3. **Create examples**\n   - Minimal working example\n   - Common use case example\n   - Integration with other syntax\n\n4. **Write definition file**\n   - Follow format for syntax type\n   - Include all required fields\n   - Add comprehensive documentation\n\n## Syntax Types\n\n### Operators\n```markdown\n---\nsymbol: =>\ndescription: Merge with deduplication\n---\n\n# Merge Operator (=>)\n\nExecutes left then right, deduplicating outputs.\n\n## Behavior\n- Execute left side\n- Execute right side\n- Merge results, removing duplicates\n- Pass merged result to next node\n\n## Example\nexplore => implement => test\n```\n\n### Actions\n```markdown\n---\nname: @deep-review\ntype: action\ndescription: Multi-stage code review\n---\n\n# Deep Review Action\n\nParallel security and style review with merge.\n\n## Expansion\n[code-reviewer:\"security\" || code-reviewer:\"style\"] -> merge\n\n## Usage\nexplore -> @deep-review -> implement\n```\n\n### Checkpoints\n```markdown\n---\nname: @security-gate\ntype: checkpoint\ndescription: Security approval checkpoint\n---\n\n# Security Gate\n\nPauses workflow for security review approval.\n\n## Prompt\nReview security findings. Verify no critical vulnerabilities before proceeding.\n\n## Usage\nscan -> @security-gate -> deploy\n```\n\n### Loops\n```markdown\n---\nname: retry-with-backoff\ntype: loop\nparams: [attempts]\ndescription: Retry with exponential backoff\n---\n\n# Retry with Backoff\n\nRetries operation N times with increasing delays.\n\n## Pattern\n@try -> {flow} (if failed)~> wait -> @try\n\n## Usage\nretry-with-backoff(3): deploy -> verify\n```\n\n### Conditions\n```markdown\n---\nname: if security-critical\ndescription: Check if changes affect security-critical code\nevaluation: Check if modified files in: auth/, crypto/, permissions/\n---\n```\n\n### Aggregators\n```markdown\n---\nname: merge-with-vote\ndescription: Combine parallel results using majority vote\nbehavior: Take most common result from parallel branches\n---\n```\n\n### Guards\n```markdown\n---\nname: require-clean-working-tree\ndescription: Ensure no uncommitted changes\ncheck: git status --porcelain returns empty\nerror: Uncommitted changes detected. Commit or stash first.\n---\n```\n\n### Tools\n```markdown\n---\nname: tool:npm:test\ntype: tool\ndescription: Run npm test suite\ncommand: npm test\noutput: test results\n---\n```\n\n### MCPs\n```markdown\n---\nname: mcp:supabase:execute_sql\ntype: mcp\ndescription: Execute SQL on Supabase\nserver: supabase\ntool: execute_sql\nparams: [query]\n---\n```\n\n## Design Principles\n\n1. **Intuitive**: Names/symbols hint at behavior\n2. **Composable**: Works with existing syntax\n3. **Self-documenting**: Clear from context\n4. **Minimal**: Only when truly needed\n\n## Output\n\nReturn to Socratic designer:\n```javascript\n{\n  type: \"action|operator|checkpoint|loop|condition|aggregator|guard|tool|mcp\",\n  name: \"syntax-element-name\",\n  definition: \"complete markdown content\",\n  path: \"library/syntax/<type>/<name>.md\"\n}\n```\n\nAll syntax files are stored in the plugin's library/syntax/ directory.\n",
        "commands/create.md": "---\ndescription: Create workflow from natural language description\ndeprecated: true\n---\n\n# ‚ö†Ô∏è DEPRECATED: Create Workflow from Description\n\n**This command is deprecated.** Use the **creating-workflows** skill instead for better auto-discovery and context compression.\n\nThe skill automatically activates when you describe workflows or mention automation.\n\n## Migration Guide\n\n**Instead of:** `/orchestration:create deploy with security validation`\n\n**Just say:** \"Create a workflow that deploys with security validation\"\n\nThe `creating-workflows` skill will automatically activate and guide you through workflow creation using Socratic questioning.\n\n---\n\n## Legacy Usage (Still Works)\n\nLaunch the Socratic workflow designer to create workflows from natural language.\n\n## Usage\n\n- `/orchestration:create` - Start with no context, ask what to build\n- `/orchestration:create <description>` - Start with initial description\n\n## Examples\n\n```\n/orchestration:create\n/orchestration:create deploy with security validation\n/orchestration:create implement auth feature with TDD\n```\n\n## Action\n\nParse arguments:\n```javascript\nconst description = args.trim() || null;\n```\n\nLaunch the workflow-socratic-designer agent and handle its response:\n\n**Step 1**: Call the subagent\n```javascript\nTask({\n  subagent_type: \"orchestration:workflow-socratic-designer\",\n  description: \"Create workflow from description\",\n  prompt: `Create an orchestration workflow from natural language description.\n\nInitial description: ${description || \"Ask user what they want to build\"}\n\nIMPORTANT: You are a subagent and do NOT have access to AskUserQuestion.\nWhen you need to ask the user questions, return them in JSON format with \"needsUserInput\": true.\nThe main agent will use AskUserQuestion to prompt the user and call you again with answers.\n\nFollow this process:\n\n1. **Understand Request**\n   ${description ?\n     \"- Assess specificity of provided description\\n   - Identify workflow pattern hints\" :\n     \"- Ask user what they want to build\\n   - Gather initial context\"}\n   - Read existing templates for pattern matching from: ~/.claude/plugins/repos/orchestration/examples/*.flow\n   - Reference agent registry for available agents: ~/.claude/plugins/repos/orchestration/agents/registry.json\n\n2. **Socratic Questioning**\n   Return questions in JSON format (you cannot use AskUserQuestion directly).\n\n   For vague requests:\n   - Problem identification (single-select)\n   - Scope clarification (multi-select)\n   - Constraints (multi-select)\n   - Pattern suggestion (single-select)\n\n   For specific requests:\n   - Pattern recognition\n   - Customization (multi-select)\n   - Validation (single-select)\n\n   For medium requests:\n   - Scope first (multi-select)\n   - Details drilling\n   - Connection logic\n\n3. **Build WorkflowRequirements**\n   Create structured object:\n   {\n     intent: \"user's goal\",\n     pattern: \"identified-pattern\",\n     agents: [\"list\", \"of\", \"agents\"],\n     structure: \"sequential|parallel|conditional|hybrid\",\n     errorHandling: [\"retry\", \"rollback\"],\n     checkpoints: [\"@review\"],\n     conditions: [\"if passed\"],\n     guards: [\"require-clean-working-tree\"],\n     tools: [\"npm:test\"],\n     mcps: [],\n     customSyntaxNeeded: []\n   }\n\n4. **Custom Syntax (if needed)**\n   If customSyntaxNeeded has elements:\n   - Call workflow-syntax-designer for each\n   - Use Task tool with subagent_type: \"orchestration:workflow-syntax-designer\"\n\n5. **Generate Workflow**\n   - Map requirements to orchestration syntax\n   - Add variable bindings: operation (condition):var~>\n   - Use negative conditions: (if !var)~>\n   - Format for readability\n\n6. **Explain to User**\n   - Plain language explanation of workflow\n   - Show generated syntax with highlighting\n   - Explain any custom syntax created\n\n7. **Save as Template**\n   Return JSON to request user input for:\n   - Ask if user wants to save as template\n   - Collect template name (suggest based on pattern)\n   - Confirm description\n   - Confirm parameters\n   - Save to ~/.claude/plugins/repos/orchestration/examples/<name>.flow\n   - Ask which custom syntax to promote to global library\n   - Copy promoted syntax to library/syntax/<type>/<name>.md\n\nContext files:\n- Templates: ~/.claude/plugins/repos/orchestration/examples/\n- Global syntax: ~/.claude/plugins/repos/orchestration/library/syntax/\n- Agent registry: ~/.claude/plugins/repos/orchestration/agents/registry.json\n- Temp agents: ~/.claude/plugins/repos/orchestration/temp-agents/\n- Natural language docs: ~/.claude/plugins/repos/orchestration/docs/features/natural-language.md\n- Best practices: ~/.claude/plugins/repos/orchestration/docs/reference/best-practices.md\n- Workflow syntax: ~/.claude/plugins/repos/orchestration/docs/topics/syntax.md\n\nRemember:\n- Use variable binding for explicit conditions\n- Support negative conditions with !\n- Follow reuse-first for custom syntax\n- Make workflow self-documenting with clear variable names\n`\n})\n```\n\n**Step 2**: Handle the subagent response\n\nAfter receiving the response from the subagent:\n\n1. **Check for needsUserInput**: Look for JSON with `\"needsUserInput\": true` in the response\n2. **If questions found**: Extract the questions array and use AskUserQuestion tool\n3. **Pass answers back**: Call the subagent again with user's answers included in the prompt\n4. **Repeat**: Continue this loop until the subagent returns a complete workflow (no needsUserInput)\n\nExample interaction flow:\n```\nSubagent returns: {\"needsUserInput\": true, \"questions\": [...]}\n  ‚Üì\nMain agent uses: AskUserQuestion({questions: [...]})\n  ‚Üì\nUser provides answers\n  ‚Üì\nMain agent calls subagent again with: \"User answered: {answers}\"\n  ‚Üì\nRepeat until workflow is complete\n```\n\n## Notes\n\nThis command is the primary entry point for natural language workflow creation.\n\n**Key responsibilities**:\n1. Delegate to the workflow-socratic-designer subagent\n2. Parse the subagent's JSON responses for questions\n3. Use AskUserQuestion tool to actually prompt the user (subagents can't do this directly)\n4. Pass user answers back to the subagent\n5. Continue the loop until the workflow is complete\n",
        "commands/examples.md": "---\ndescription: Display examples gallery for orchestration workflows\ndeprecated: true\n---\n\n# ‚ö†Ô∏è DEPRECATED: Orchestration Examples Gallery\n\n**This command is deprecated.** Examples are now integrated into skills with detailed explanations.\n\n## Migration Guide\n\nSee examples in skills:\n- **creating-workflows/examples.md** - Complete workflow examples\n- **creating-workflows/patterns.md** - Common patterns\n\nOr browse `examples/` directory for `.flow` files.\n\n---\n\n## Legacy Usage (Still Works)\n\nDisplay the examples gallery for the Workflow Orchestration System.\n\n## Arguments: {{ARGS}}\n\n## Load and Display Examples\n\n**Primary Source:** `~/.claude/plugins/repos/orchestration/docs/reference/examples.md` - Curated examples documentation\n\n**Template Source:** Use the Glob tool to list available example workflows:\n\n```\nGlob('~/.claude/plugins/repos/orchestration/examples/*.flow')\n```\n\nFor each template found, read the file to extract its name and description from the YAML frontmatter.\n\n**Template Documentation:** Reference `~/.claude/plugins/repos/orchestration/examples/README.md` for detailed template information.\n\nDisplay a formatted list combining both documentation examples and available templates to the user.\n\n## After Displaying Examples\n\nAsk the user what they'd like to do next:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What would you like to do with these examples?\",\n    header: \"Next\",\n    multiSelect: false,\n    options: [\n      {label: \"Try an example\", description: \"Execute one of these workflows\"},\n      {label: \"Learn more\", description: \"Get detailed docs on a topic\"},\n      {label: \"Create custom\", description: \"Build your own workflow\"},\n      {label: \"Return to menu\", description: \"Go back to main menu\"}\n    ]\n  }]\n})\n```\n\n**Handler Actions:**\n- **Try an example** ‚Üí Prompt user to paste/specify which example syntax, then execute `/orchestration:run <syntax>`\n- **Learn more** ‚Üí Execute `/orchestration:explain`\n- **Create custom** ‚Üí Prompt for syntax and execute `/orchestration:run <syntax>`\n- **Return to menu** ‚Üí Execute `/orchestration:menu`\n\n## Implementation Note\n\n**Documentation:**\n- Examples gallery: `~/.claude/plugins/repos/orchestration/docs/reference/examples.md`\n- Template documentation: `~/.claude/plugins/repos/orchestration/examples/README.md`\n\nIf the examples documentation doesn't exist, display a friendly message and offer to:\n1. Show inline examples (from help reference)\n2. List available templates from examples/ directory\n3. Return to menu\n",
        "commands/explain.md": "---\ndescription: Detailed topic documentation for orchestration features\ndeprecated: true\n---\n\n# ‚ö†Ô∏è DEPRECATED: Orchestration Topic Documentation\n\n**This command is deprecated.** Skills now contain embedded documentation with progressive disclosure.\n\n## Migration Guide\n\nDocumentation is now integrated into skills:\n- **creating-workflows** skill - Workflow creation docs\n- **executing-workflows** skill - Execution and syntax docs\n- **managing-agents** skill - Agent lifecycle docs\n- **designing-syntax** skill - Custom syntax docs\n- **debugging-workflows** skill - Debugging guides\n\n---\n\n## Legacy Usage (Still Works)\n\nProvide detailed documentation on specific orchestration topics.\n\n## Arguments: {{ARGS}}\n\n## Available Topics\n\n**Core Topics (docs/topics/):**\n- **syntax** - Complete syntax guide (operators, agents, patterns)\n- **custom-syntax** - Custom syntax elements and definitions\n\n**Features (docs/features/):**\n- **natural-language** - Natural language workflow creation\n- **templates** - Template system and parameter substitution\n- **error-handling** - Error recovery strategies\n- **defined-agents** - Reusable agent definitions\n- **temporary-agents** - Inline agent definitions ($agent syntax)\n- **agent-promotion** - Converting temp to defined agents\n- **custom-definitions** - Extension system\n\n**Reference (docs/reference/):**\n- **syntax** - Quick reference card\n- **examples** - Examples gallery\n- **best-practices** - Guidelines and patterns\n- **variable-binding** - Conditional variables\n- **temp-agents-syntax** - Temporary agent syntax reference\n\n## Handle Topic Selection\n\n### No Topic Specified\n\nIf {{ARGS}} is empty, present topic selection menu:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"Which topic would you like to learn about?\",\n    header: \"Topic\",\n    multiSelect: false,\n    options: [\n      {label: \"syntax\", description: \"Complete syntax guide\"},\n      {label: \"custom-syntax\", description: \"Custom syntax elements\"},\n      {label: \"natural-language\", description: \"Natural language creation\"},\n      {label: \"templates\", description: \"Template system\"},\n      {label: \"defined-agents\", description: \"Reusable agents\"},\n      {label: \"temporary-agents\", description: \"Inline agents ($agent)\"},\n      {label: \"agent-promotion\", description: \"Temp to defined agents\"},\n      {label: \"error-handling\", description: \"Error recovery\"},\n      {label: \"examples\", description: \"Examples gallery\"},\n      {label: \"best-practices\", description: \"Guidelines and patterns\"}\n    ]\n  }]\n})\n```\n\n### Topic Specified\n\nIf {{ARGS}} contains a topic name, load the corresponding documentation:\n\n**Available topic files:**\n- Core topics: `~/.claude/plugins/repos/orchestration/docs/topics/${topic}.md`\n- Features: `~/.claude/plugins/repos/orchestration/docs/features/${topic}.md`\n- Reference: `~/.claude/plugins/repos/orchestration/docs/reference/${topic}.md`\n\n```javascript\n// Try topics directory first\nRead(`~/.claude/plugins/repos/orchestration/docs/topics/${topic}.md`)\n\n// If not found, try features directory\n// If not found, try reference directory\n```\n\nDisplay the full content to the user.\n\n### File Not Found\n\nIf the topic file doesn't exist:\n1. Display friendly message: \"Documentation for '{topic}' is not available yet.\"\n2. Show list of available topics above\n3. Offer to explain what we know about the topic based on general knowledge\n4. Prompt to select another topic\n\n## After Displaying Topic\n\nAsk the user what they'd like to do next:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What would you like to do next?\",\n    header: \"Next\",\n    multiSelect: false,\n    options: [\n      {label: \"Learn another topic\", description: \"View different topic documentation\"},\n      {label: \"See examples\", description: \"View example workflows\"},\n      {label: \"Try it out\", description: \"Create a workflow using this concept\"},\n      {label: \"Return to menu\", description: \"Go back to main menu\"}\n    ]\n  }]\n})\n```\n\n**Handler Actions:**\n- **Learn another topic** ‚Üí Execute `/orchestration:explain` (without args to show menu)\n- **See examples** ‚Üí Execute `/orchestration:examples`\n- **Try it out** ‚Üí Prompt for syntax and execute `/orchestration:run <syntax>`\n- **Return to menu** ‚Üí Execute `/orchestration:menu`\n\n## Implementation Notes\n\n- Parse {{ARGS}} to extract topic name (handle variations like \"explain syntax\", \"syntax\", etc.)\n- Be flexible with topic names (case-insensitive, handle plurals)\n- If multiple topics match, ask for clarification\n- Keep documentation display clean and well-formatted\n",
        "commands/help.md": "---\ndescription: Quick reference guide for orchestration syntax\n---\n\n# Orchestration Help\n\nDisplay the quick reference guide for the Workflow Orchestration System.\n\n## Arguments: {{ARGS}}\n\n## Display Quick Reference\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë                Orchestration Quick Reference                 ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë                                                              ‚ïë\n‚ïë  OPERATORS                                                   ‚ïë\n‚ïë  step1 -> step2           Sequential                         ‚ïë\n‚ïë  step1 || step2           Parallel                           ‚ïë\n‚ïë  step (if cond)~> next    Conditional                        ‚ïë\n‚ïë  @label                   Checkpoint                         ‚ïë\n‚ïë  [...]                    Subgraph                           ‚ïë\n‚ïë                                                              ‚ïë\n‚ïë  AGENTS                                                      ‚ïë\n‚ïë  explore:\"task\"           Investigation                      ‚ïë\n‚ïë  general-purpose:\"task\"   Implementation                     ‚ïë\n‚ïë  code-reviewer:\"task\"     Quality check                      ‚ïë\n‚ïë                                                              ‚ïë\n‚ïë  EXAMPLES                                                    ‚ïë\n‚ïë  explore:\"find bugs\" -> review -> implement                  ‚ïë\n‚ïë  [test || lint] (all success)~> deploy                      ‚ïë\n‚ïë  @try -> fix -> test (if failed)~> @try                     ‚ïë\n‚ïë                                                              ‚ïë\n‚ïë  COMMANDS                                                    ‚ïë\n‚ïë  /orchestration:create            Natural language creation  ‚ïë\n‚ïë  /orchestration:orchestrate       Main orchestration menu    ‚ïë\n‚ïë  /orchestration:help              Quick reference            ‚ïë\n‚ïë  /orchestration:explain <topic>   Detailed docs              ‚ïë\n‚ïë  /orchestration:examples          Gallery                    ‚ïë\n‚ïë  /orchestration:run <syntax>      Execute workflow           ‚ïë\n‚ïë  /orchestration:template <name>   Load and run template      ‚ïë\n‚ïë                                                              ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```\n\n## Next Steps\n\nAsk the user what they'd like to do next:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What would you like to do next?\",\n    header: \"Next\",\n    multiSelect: false,\n    options: [\n      {label: \"View examples\", description: \"See example workflows\"},\n      {label: \"Explain topic\", description: \"Learn about specific features\"},\n      {label: \"Create workflow\", description: \"Start building a workflow\"},\n      {label: \"Return to menu\", description: \"Go back to main menu\"}\n    ]\n  }]\n})\n```\n\n**Handler Actions:**\n- **View examples** ‚Üí Execute `/orchestration:examples`\n- **Explain topic** ‚Üí Execute `/orchestration:explain`\n- **Create workflow** ‚Üí Prompt for syntax and execute `/orchestration:run <syntax>`\n- **Return to menu** ‚Üí Execute `/orchestration:menu`\n",
        "commands/init.md": "---\ndescription: Import agents from Claude Code environment to orchestration plugin context\n---\n\n# Initialize Orchestration Plugin\n\nImport custom agents from your Claude Code environment (`~/.claude/agents/`) into the orchestration plugin's **skills context**, making them available globally for all workflows without needing to copy files.\n\n## Usage\n\n```\n/orchestration:init\n```\n\nThis command will:\n1. Scan `~/.claude/agents/` for custom agent definitions\n2. Show you which agents are available to import\n3. Let you select which agents to register\n4. Add agent references to the orchestration skills context\n5. Make agents available for use in all workflows\n\n## How It Works\n\nThe command:\n- ‚úÖ Finds all `.md` files in `~/.claude/agents/`\n- ‚úÖ Excludes built-in Claude Code agents (Explore, Plan, general-purpose)\n- ‚úÖ Shows agent names and descriptions\n- ‚úÖ Lets you select individual agents or import all\n- ‚úÖ Registers agents in orchestration skills context (NOT copied, just referenced)\n- ‚úÖ Updates agent availability mapping\n- ‚úÖ Agents remain in original location but become usable in workflows\n\n## Example Flow\n\n```\nUser: /orchestration:init\n\nClaude: Found 5 custom agents in ~/.claude/agents/:\n\n1. expert-code-implementer\n   Description: Specialized agent for implementing code features\n\n2. code-optimizer\n   Description: Performance and code quality optimization\n\n3. implementation-architect\n   Description: System design and architecture planning\n\n4. jwt-keycloak-security-auditor\n   Description: Security auditing for JWT and Keycloak\n\n5. react-native-component-reviewer\n   Description: React Native component review and validation\n\nWhich agents would you like to import?\n- Import all\n- Select individual agents\n- Cancel\n\nUser: Select individual agents\n\nClaude: [Shows checkboxes for agents]\n‚òë expert-code-implementer\n‚òë code-optimizer\n‚òê implementation-architect\n‚òë jwt-keycloak-security-auditor\n‚òê react-native-component-reviewer\n\nUser: [Confirms selection]\n\nClaude: ‚úÖ Registered 3 agents in orchestration context:\n- expert-code-implementer (from ~/.claude/agents/expert-code-implementer.md)\n- code-optimizer (from ~/.claude/agents/code-optimizer.md)\n- jwt-keycloak-security-auditor (from ~/.claude/agents/jwt-keycloak-security-auditor.md)\n\nUpdated orchestration skills context.\n\nYou can now use these agents directly in workflows:\n- expert-code-implementer:\"task\"\n- code-optimizer:\"task\"\n- jwt-keycloak-security-auditor:\"task\"\n\nNo need for orchestration: prefix - they're available as if they were built-in!\n```\n\n## Action\n\n**Step 1**: Scan for custom agents\n\n1. Use Glob tool to find all `.md` files in `~/.claude/agents/`\n2. Filter out built-in agents: `explore`, `plan`, `general-purpose`\n3. For each custom agent file:\n   - Read the file using Read tool\n   - Extract description from frontmatter or first heading\n   - Store agent name and description\n4. If no custom agents found, inform user and exit\n\n**Step 2**: Present agents to user using AskUserQuestion\n\n**IMPORTANT:** MUST use AskUserQuestion tool for interactive selection!\n\n1. Create options array from discovered agents\n2. Each option should have:\n   - `label`: agent name (e.g., \"expert-code-implementer\")\n   - `description`: agent description or \"No description available\"\n3. Use AskUserQuestion tool:\n   - `question`: \"Select agents to register in orchestration context. These agents will become available for use in workflows.\"\n   - `header`: \"Import Agents\"\n   - `multiSelect`: true (allow multiple selections)\n   - `options`: the options array\n4. Parse the response to get list of selected agent names\n\n**Step 3**: Register selected agents in skills context\n\nFor each selected agent:\n\n1. Read the agent file from `~/.claude/agents/{agent-name}.md`\n2. Extract metadata (name, description)\n3. Create reference mapping (do NOT copy the file!)\n4. Store mapping with:\n   - Agent name\n   - Description\n   - Path to original file: `~/.claude/agents/{agent-name}.md`\n   - Type: \"external\"\n\n**Step 4**: Create or update agent registry for orchestration context\n\n**IMPORTANT:** Use `${CLAUDE_PLUGIN_ROOT}` for all plugin workspace paths!\n\n1. Create agent registry JSON object with:\n   - `externalAgents`: object containing all registered agents\n   - `lastUpdated`: current timestamp\n2. For each selected agent, add entry:\n   - Key: agent name\n   - Value object:\n     - `path`: `~/.claude/agents/{agent-name}.md` (external path, read-only)\n     - `description`: agent description\n     - `registered`: today's date\n     - `usageCount`: 0\n3. Save registry to plugin workspace using Write tool:\n   - Path: `${CLAUDE_PLUGIN_ROOT}/skills/managing-agents/external-agents.json`\n   - Format: Pretty-printed JSON with 2-space indentation\n\n**Step 5**: Update orchestration skills to recognize external agents\n\n1. Create available-agents.md document content with:\n   - Section: \"Built-in Claude Code Agents\"\n     - Explore - Fast codebase exploration\n     - Plan - Planning and task breakdown\n     - general-purpose - Versatile multi-step tasks\n   - Section: \"Registered External Agents\"\n     - List all agents from registry with their descriptions\n   - Section: \"Usage in Workflows\"\n     - Show example of using external agent directly\n     - Note that orchestration resolves agent from ~/.claude/agents/\n2. Write document to plugin workspace using Write tool:\n   - Path: `${CLAUDE_PLUGIN_ROOT}/skills/managing-agents/available-agents.md`\n\n**Step 6**: Confirm completion\n\nShow user:\n- Number of agents registered\n- Agent names and their source paths\n- How to use them in workflows (direct name, no namespace needed)\n- Confirmation that they're available in orchestration skills context\n\n## Implementation Details\n\n### Agent Metadata Extraction\n\nExtract from agent file:\n```markdown\n---\nname: expert-code-implementer\ndescription: Specialized agent for implementing code features\n---\n```\n\nOR from first heading:\n```markdown\n# Expert Code Implementer\n\nSpecialized agent for implementing code features\n```\n\n### Built-in Agents to Skip\n\nNever import these (they're built into Claude Code):\n- `explore.md` / `Explore`\n- `plan.md` / `Plan`\n- `general-purpose.md`\n\n### External Agents Registry Structure\n\nSaved to: `~/.claude/plugins/repos/orchestration/skills/managing-agents/external-agents.json`\n\n```json\n{\n  \"externalAgents\": {\n    \"expert-code-implementer\": {\n      \"path\": \"~/.claude/agents/expert-code-implementer.md\",\n      \"description\": \"Specialized agent for implementing code features\",\n      \"registered\": \"2025-01-08\",\n      \"usageCount\": 0\n    },\n    \"code-optimizer\": {\n      \"path\": \"~/.claude/agents/code-optimizer.md\",\n      \"description\": \"Performance and code quality optimization\",\n      \"registered\": \"2025-01-08\",\n      \"usageCount\": 0\n    }\n  },\n  \"lastUpdated\": \"2025-01-08T12:00:00.000Z\"\n}\n```\n\n### Available Agents Documentation\n\nSaved to: `~/.claude/plugins/repos/orchestration/skills/managing-agents/available-agents.md`\n\nThis file is automatically included in orchestration skills context, making all registered agents available to workflows.\n\n## Error Handling\n\n- **No agents found**: Inform user that ~/.claude/agents/ is empty or doesn't exist\n- **Agent already exists**: Ask if user wants to overwrite or skip\n- **Invalid agent file**: Warn about malformed files and skip them\n- **Registry update fails**: Show error and list which agents were copied\n\n## Notes\n\n- **No file copying**: Agents remain in `~/.claude/agents/`, orchestration just creates references\n- **Direct usage**: Use agents by name in workflows (e.g., `expert-code-implementer:\"task\"`)\n- **No namespace needed**: External agents work like built-in agents once registered\n- **Re-runnable**: Run `/orchestration:init` again to register new agents or update existing\n- **View registered agents**: Use `/orchestration:menu` to see all available agents\n- **Skills context**: Registration updates orchestration skills so agents are globally available\n\n## How Orchestration Resolves Agents\n\nWhen you use an agent in a workflow:\n\n```flow\nexpert-code-implementer:\"Implement feature X\"\n```\n\nThe orchestration system:\n1. Checks if it's a built-in agent (Explore, Plan, general-purpose)\n2. If not, looks in `external-agents.json` for the mapping\n3. Finds the path: `~/.claude/agents/expert-code-implementer.md`\n4. Uses that agent definition for the Task tool\n\nThis means **no duplication** - agents live in one place, available everywhere!",
        "commands/menu.md": "---\ndescription: Interactive menu for orchestration system\n---\n\n# Orchestration Menu\n\nYou are in **Menu Mode** of the Workflow Orchestration System. Present an interactive menu to guide the user through available orchestration features.\n\n## Arguments: {{ARGS}}\n\n## Display Menu\n\nUse AskUserQuestion to present the main menu:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What would you like to do?\",\n    header: \"Menu\",\n    multiSelect: false,\n    options: [\n      {label: \"Import agents\", description: \"Import custom agents from Claude Code\"},\n      {label: \"Create from description\", description: \"Natural language workflow creation\"},\n      {label: \"New workflow\", description: \"Create workflow from syntax\"},\n      {label: \"Load template\", description: \"Execute saved flow\"},\n      {label: \"List templates\", description: \"Show all templates\"},\n      {label: \"Manage syntax\", description: \"View/edit global syntax library\"},\n      {label: \"View docs\", description: \"Help, examples, or topic guides\"}\n    ]\n  }]\n})\n```\n\n## Handler Actions\n\n### Import agents\n- Execute `/orchestration:init`\n- Imports custom agents from ~/.claude/agents/ to orchestration plugin\n- Makes them available for use in workflows with orchestration: namespace\n\n### Create from description\n- Execute `/orchestration:create`\n- This launches the natural language workflow creation flow\n\n### New workflow\n- Prompt for workflow syntax\n- Execute `/orchestration:run <syntax>`\n\n### Load template\n- Show available templates from ~/.claude/plugins/repos/orchestration/examples/\n- Let user select template\n- Execute `/orchestration:template <template-name>`\n\n### List templates\n- Use Glob: `~/.claude/plugins/repos/orchestration/examples/*.flow`\n- Display table:\n  ```\n  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n  ‚ïë Name              | Description         | Parameters  ‚ïë\n  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n  ‚ïë tdd-feature       | TDD workflow        | feature     ‚ïë\n  ‚ïë debug-fix         | Debug and fix       | issue       ‚ïë\n  ‚ïë ...               | ...                 | ...         ‚ïë\n  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n  ```\n- Offer to execute or view any template\n\n### Manage syntax\nPresent submenu for global syntax management using AskUserQuestion:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"Manage global syntax library:\",\n    header: \"Syntax\",\n    multiSelect: false,\n    options: [\n      {label: \"List all syntax\", description: \"Show all global syntax elements\"},\n      {label: \"View by type\", description: \"Browse operators, actions, etc.\"},\n      {label: \"Search syntax\", description: \"Find specific syntax elements\"},\n      {label: \"Back to menu\", description: \"Return to main menu\"}\n    ]\n  }]\n})\n```\n\n#### List all syntax\n- Use Glob: `~/.claude/plugins/repos/orchestration/library/syntax/**/*.md`\n- Read frontmatter from each file\n- Display table:\n  ```\n  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n  ‚ïë Type      | Name     | Description         ‚ïë\n  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n  ‚ïë operator  | ->       | Sequential flow     ‚ïë\n  ‚ïë operator  | ||       | Parallel execution  ‚ïë\n  ‚ïë ...       | ...      | ...                 ‚ïë\n  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n  ```\n- Return to syntax submenu\n\n#### View by type\n- Ask which type to view (operators, actions, checkpoints, etc.)\n- List files in that directory\n- Show name and description for each\n- Allow viewing full content\n- Return to syntax submenu\n\n#### Search syntax\n- Ask for search term\n- Use Grep to search descriptions and content in `~/.claude/plugins/repos/orchestration/library/syntax/`\n- Display matching syntax elements\n- Allow viewing full content\n- Return to syntax submenu\n\n### View docs\nPresent documentation submenu using AskUserQuestion:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What documentation would you like to view?\",\n    header: \"Docs\",\n    multiSelect: false,\n    options: [\n      {label: \"Help\", description: \"Quick reference guide\"},\n      {label: \"Examples\", description: \"Examples gallery\"},\n      {label: \"Explain topic\", description: \"Detailed topic documentation\"},\n      {label: \"Back to menu\", description: \"Return to main menu\"}\n    ]\n  }]\n})\n```\n\n**Handler Actions:**\n- **Help** ‚Üí Execute `/orchestration:help`\n- **Examples** ‚Üí Execute `/orchestration:examples`\n- **Explain topic** ‚Üí Execute `/orchestration:explain`\n- **Back to menu** ‚Üí Redisplay main menu\n\n---\n\n## Notes\n\n- Always show clear navigation options\n- Allow returning to main menu from any submenu\n- Display content in formatted, readable boxes\n- Keep menu interactions conversational\n",
        "commands/orchestrate.md": "---\ndescription: Multi-agent workflow orchestration with visual feedback\n---\n\n# Workflow Orchestration System Router\n\nYou are the Workflow Orchestrator for Claude Code. This command routes to specialized subcommands based on the mode.\n\n## Quick Start\n\n```\n/orchestration:orchestrate                    Interactive menu\n/orchestration:orchestrate help               Quick reference\n/orchestration:orchestrate explain [topic]    Detailed docs\n/orchestration:orchestrate examples           Gallery\n/orchestration:orchestrate <template-name>    Execute template\n/orchestration:orchestrate <workflow-syntax>  Execute inline workflow\n```\n\n## Arguments: {{ARGS}}\n\n## Mode Detection\n\nAnalyze {{ARGS}} to determine the mode and route accordingly:\n\n1. **Empty or Menu** ‚Üí Route to `/orchestration:menu`\n   - No arguments provided\n   - User explicitly requested menu\n\n2. **Help Mode** ‚Üí Route to `/orchestration:help`\n   - Arguments are \"help\"\n\n3. **Documentation Mode** ‚Üí Route to `/orchestration:explain [topic]`\n   - Arguments start with \"explain\"\n   - Pass topic if specified\n\n4. **Examples Mode** ‚Üí Route to `/orchestration:examples`\n   - Arguments are \"examples\"\n\n5. **Template Mode** ‚Üí Route to `/orchestration:template <name>`\n   - Template file exists at `~/.claude/plugins/repos/orchestration/examples/{{ARGS}}.flow`\n   - Check with: Glob `~/.claude/plugins/repos/orchestration/examples/{{ARGS}}.flow`\n\n6. **Inline Mode** ‚Üí Route to `/orchestration:run <syntax>`\n   - Arguments contain workflow syntax (operators like `->`, `||`, `~>`, `@`, `[]`)\n   - This is the default if no other mode matches\n\n## Routing Logic\n\n```javascript\n// Pseudocode for routing\nconst args = {{ARGS}}.trim();\n\nif (!args || args === 'menu') {\n  execute('/orchestration:menu');\n}\nelse if (args === 'help') {\n  execute('/orchestration:help');\n}\nelse if (args.startsWith('explain')) {\n  const topic = args.replace('explain', '').trim();\n  execute(`/orchestration:explain ${topic}`);\n}\nelse if (args === 'examples') {\n  execute('/orchestration:examples');\n}\nelse if (templateExists(`~/.claude/plugins/repos/orchestration/examples/${args}.flow`)) {\n  execute(`/orchestration:template ${args}`);\n}\nelse {\n  // Contains workflow syntax\n  execute(`/orchestration:run ${args}`);\n}\n```\n\n## Implementation\n\n1. Parse {{ARGS}}\n2. Detect mode using logic above\n3. Execute appropriate subcommand with SlashCommand tool\n4. Let subcommand handle all logic\n\n## Subcommand Overview\n\n- **orchestration:menu** - Interactive menu system\n- **orchestration:help** - Quick reference guide\n- **orchestration:explain** - Topic documentation\n- **orchestration:examples** - Examples gallery\n- **orchestration:template** - Template execution with parameters\n- **orchestration:run** - Parse and execute workflow syntax\n\n---\n\n## Execute Router\n\n**Detected mode:** [Analyze {{ARGS}} and state mode, then route to appropriate subcommand]\n",
        "commands/run.md": "---\ndescription: Parse and execute inline workflow syntax\ndeprecated: true\n---\n\n# ‚ö†Ô∏è DEPRECATED: Orchestration Workflow Execution\n\n**This command is deprecated.** Use the **executing-workflows** skill instead for better visualization, error handling, and progress tracking.\n\nThe skill automatically activates when you provide workflow syntax or ask to run a workflow.\n\n## Migration Guide\n\n**Instead of:** `/orchestration:run step1 -> step2 -> step3`\n\n**Just provide syntax:**\n```flow\nstep1:\"task\" -> step2:\"task\" -> step3:\"task\"\n```\n\nThe `executing-workflows` skill will automatically activate and execute with full visualization and steering support.\n\n---\n\n## Legacy Usage (Still Works)\n\nParse and execute a workflow defined using orchestration syntax.\n\n## Arguments: {{ARGS}}\n\nThe workflow to execute. Can be provided in two formats:\n\n1. **Raw syntax** - Direct workflow operators (e.g., `step1 -> step2`)\n2. **Template format** - YAML frontmatter with `workflow` and optional `visualization` fields\n\n## Execution Phases\n\n### Phase -1: Template Detection (if applicable)\n\n**Check for YAML frontmatter:**\n\nIf input starts with `---`, it's a template with frontmatter:\n\n```javascript\nif (input.startsWith('---')) {\n  const { frontmatter, content } = parseYAMLFrontmatter(input)\n\n  // Extract fields\n  const visualization = frontmatter.visualization  // Static ASCII art\n  const workflow = frontmatter.workflow            // Raw workflow syntax\n\n  // Use workflow syntax from frontmatter, not content after ---\n  syntax = workflow\n\n  // Store visualization for Phase 2\n  staticVisualization = visualization\n}\n```\n\n**If no frontmatter detected, use input as-is for raw syntax.**\n\n---\n\n### Phase 0: Pre-Parse (Temporary Agents)\n\n**Reference:** `${CLAUDE_PLUGIN_ROOT}/docs/features/temporary-agents.md`\n**Registry:** `${CLAUDE_PLUGIN_ROOT}/temp-agents/`\n\nIf workflow contains temporary agent syntax (`$agent-name`):\n\n1. **Extract Definitions** - Find `$name := {...}` patterns\n   ```javascript\n   const { registry, cleanedSyntax } = extractTempAgentDefinitions(syntax)\n   ```\n\n2. **Expand Invocations** - Replace `$name:\"instruction\":var` with standard syntax\n   ```javascript\n   const { expanded, replacements } = expandTempAgentInvocations(cleanedSyntax, registry)\n   ```\n\n3. **Build Metadata** - Track temp agent info for executor\n   ```javascript\n   const metadata = {\n     tempAgents: [...],\n     nodeMetadata: [...],\n     variables: {}\n   }\n   ```\n\n**Example:**\n```\nInput:  $scanner := {base: \"general-purpose\", prompt: \"Security expert\", model: \"opus\"}\n        $scanner:\"Scan auth code\":results\n\nOutput: general-purpose:\"Security expert\\n\\nScan auth code\"\n        + metadata: {outputVar: \"results\", model: \"opus\"}\n```\n\n**Errors?**\n- Missing `base` or `prompt` field\n- Undefined temporary agent reference\n- Variable referenced but never produced\n\n**If no temp agents detected, skip to Phase 1.**\n\n---\n\n### Phase 1: Parse\n\n**Reference:** `${CLAUDE_PLUGIN_ROOT}/docs/core/parser.md`\n\n1. **Tokenize** - Split by operators: `->`, `||`, `~>`, `@`, `[...]`\n2. **Build AST** - Parse tokens into tree (precedence: `[]` > `||` > `->` > `~>`)\n3. **Create Graph** - Convert to directed graph with nodes and edges\n4. **Enhance Graph** - Add temp agent metadata if present\n   ```javascript\n   if (tempAgentMetadata) {\n     graph = enhanceGraphWithTempAgents(graph, tempAgentMetadata)\n   }\n   ```\n5. **Validate** - Check for:\n   - Unclosed subgraphs\n   - Unknown agents\n   - Orphaned nodes\n   - Circular dependencies\n   - Invalid conditions\n   - Variable dependencies (if temp agents used)\n\n**Output:**\n```javascript\n{\n  nodes: [{\n    id, type, agent, instruction, status: \"pending\",\n    outputVar?, model?, templateVars?, tempAgentName?\n  }],\n  edges: [{from, to, condition}],\n  variables: {},  // If temp agents used\n  tempAgents: {}  // If temp agents used\n}\n```\n\n**Errors?** Display clear message with context and abort.\n\n---\n\n### Phase 2: Visualize\n\n**Reference:** `${CLAUDE_PLUGIN_ROOT}/docs/core/visualizer.md`\n\n**Static Visualization Check:**\nBefore generating a dynamic visualization, check if a static visualization was provided:\n- Templates can include a `visualization` field in their YAML frontmatter\n- If present, display the static visualization directly without modification\n- Static visualizations ensure consistent display across all executions\n- Skip dynamic generation when static visualization is available\n\n**Dynamic Visualization:**\nIf no static visualization is provided, generate and display ASCII art visualization:\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë  Workflow: [name]                          ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë                                            ‚ïë\n‚ïë    [step-1] ‚óã                              ‚ïë\n‚ïë        ‚îÇ                                   ‚ïë\n‚ïë    ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê                               ‚ïë\n‚ïë  [step-2] [step-3] ‚óã ‚óã                     ‚ïë\n‚ïë    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò                               ‚ïë\n‚ïë    [merge] ‚óã                               ‚ïë\n‚ïë                                            ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë Status: Ready to execute                   ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë (c)ontinue  (e)dit  (q)uit                 ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```\n\n**Status Indicators:**\n- ‚óã Pending\n- ‚óè Executing\n- ‚úì Completed\n- ‚úó Failed\n- ‚äó Skipped\n\n**Confirm with user before execution.**\n\n---\n\n### Phase 3: Execute\n\n**Reference:** `${CLAUDE_PLUGIN_ROOT}/docs/core/executor.md`\n**Temp Agents:** `${CLAUDE_PLUGIN_ROOT}/temp-agents/`\n\n**Algorithm:**\n1. Initialize all nodes to ‚óã pending\n2. Initialize variables map if temp agents used: `graph.variables = {}`\n3. Loop until complete:\n   - Find executable nodes (dependencies satisfied)\n   - **If temp agents:** Check variable dependencies are satisfied\n   - **If temp agents:** Interpolate variables in instruction\n   - Launch agents via Task tool (parallel if multiple)\n   - Wait for completion\n   - **If temp agents:** Capture output to variable if node has `outputVar`\n   - Update status and visualization\n   - Evaluate conditionals\n   - Handle checkpoints\n   - Handle errors\n4. Display final results (including variable summary if temp agents used)\n\n**Agent Mapping:**\n\nPlugin agents MUST be prefixed with `orchestration:` namespace:\n- `explore` ‚Üí `Explore` subagent (built-in)\n- `general-purpose` ‚Üí `general-purpose` subagent (built-in)\n- `code-reviewer` ‚Üí `superpowers:code-reviewer` subagent (built-in)\n- `implementation-architect` ‚Üí `implementation-architect` subagent (built-in)\n- `expert-code-implementer` ‚Üí `expert-code-implementer` subagent (built-in)\n- `workflow-socratic-designer` ‚Üí `orchestration:workflow-socratic-designer` subagent (plugin)\n- `workflow-syntax-designer` ‚Üí `orchestration:workflow-syntax-designer` subagent (plugin)\n- Other defined agents from `agents/registry.json` ‚Üí `orchestration:{agent-name}` (plugin)\n- Temp agents (`$name`) ‚Üí `orchestration:{agent-name}` (plugin, ephemeral)\n\n**Namespace Rules:**\n1. **Built-in agents**: No prefix (Explore, general-purpose, code-reviewer, etc.)\n2. **Plugin agents**: Always prefix with `orchestration:`\n3. **Temp agents**: Automatically prefixed with `orchestration:` when loaded from temp-agents/\n4. **Agent resolution**: Check built-ins first, then try with `orchestration:` prefix\n\n**Example:**\n```javascript\n// In workflow syntax:\n$news-analyzer:\"Analyze news articles\"\n\n// At execution time:\nTask({\n  subagent_type: \"orchestration:news-analyzer\",  // Prefixed!\n  description: \"Temp agent: news-analyzer\",\n  prompt: \"...\"\n})\n```\n\n**Parallel Execution:**\nLaunch all parallel agents in single response using multiple Task calls.\n\n**Temporary Agent Execution:**\n```javascript\n// Before execution: interpolate variables\nconst instruction = prepareNodeInstruction(node, graph.variables)\n\n// Execute with model override if specified\nawait Task({\n  subagent_type: node.agent,\n  description: node.tempAgentName ? `Temp agent: ${node.tempAgentName}` : `Execute ${node.agent}`,\n  prompt: instruction,\n  model: node.model  // Override model if temp agent specified one\n})\n\n// After execution: capture output\nif (node.outputVar) {\n  captureNodeOutput(node, result, graph.variables)\n}\n```\n\n**Variable Interpolation:**\nReplace `{varname}` in instructions with actual values:\n```javascript\n\"Create report from {scan_results}\"\n‚Üí \"Create report from Found 3 vulnerabilities: ...\"\n```\n\n**Conditional Evaluation:**\n- `if passed` ‚Üí Check for success indicators\n- `if failed` ‚Üí Check for failure indicators\n- `if all success` ‚Üí All parallel branches succeeded\n- `if any success` ‚Üí At least one succeeded\n- Custom conditions ‚Üí Interpret from output\n\n**Checkpoints:**\nWhen reaching `@label`:\n1. Pause execution\n2. Show steering menu (see Phase 4)\n3. Wait for command\n4. Resume based on command\n\n---\n\n### Phase 4: Steering\n\n**Reference:** `${CLAUDE_PLUGIN_ROOT}/docs/core/steering.md`\n\nAt checkpoints and after errors, provide control:\n\n```\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë (c)ontinue  (j)ump  (r)epeat  (e)dit      ‚ïë\n‚ïë (v)iew-output  (q)uit                      ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```\n\nUse AskUserQuestion for steering:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What would you like to do?\",\n    header: \"Control\",\n    multiSelect: false,\n    options: [\n      {label: \"Continue\", description: \"Resume from current point\"},\n      {label: \"Jump\", description: \"Jump to specific node\"},\n      {label: \"Repeat\", description: \"Re-execute last node\"},\n      {label: \"Edit\", description: \"Modify workflow syntax\"},\n      {label: \"View output\", description: \"Display full node output\"},\n      {label: \"Quit\", description: \"Abort with summary\"}\n    ]\n  }]\n})\n```\n\n**Commands:**\n- **Continue** - Resume from current point\n- **Jump** - Ask which node, then jump to it\n- **Repeat** - Re-execute last node\n- **Edit** - Prompt for new syntax, reparse, and restart\n- **View** - Display full output from selected node\n- **Quit** - Abort and show summary\n\n---\n\n### Phase 5: Error Recovery\n\n**Reference:** `${CLAUDE_PLUGIN_ROOT}/docs/features/error-handling.md`\n\nWhen agent fails:\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë  ERROR: Agent Execution Failed             ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  Node: [failed-node] ‚úó                     ‚ïë\n‚ïë  Error: [message]                          ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  Recovery options:                         ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```\n\nUse AskUserQuestion for recovery:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"How would you like to recover?\",\n    header: \"Error\",\n    multiSelect: false,\n    options: [\n      {label: \"Retry\", description: \"Re-execute failed node\"},\n      {label: \"Edit\", description: \"Modify workflow\"},\n      {label: \"Skip\", description: \"Continue past failure\"},\n      {label: \"Debug\", description: \"Insert debug step\"},\n      {label: \"Fork\", description: \"Try parallel approaches\"},\n      {label: \"Quit\", description: \"Abort execution\"}\n    ]\n  }]\n})\n```\n\n**Context-aware suggestions** based on error type.\n\n---\n\n### Phase 6: Completion\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë  Workflow Complete                         ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  Total steps: 12                           ‚ïë\n‚ïë  Completed: 11 ‚úì                           ‚ïë\n‚ïë  Failed: 1 ‚úó                               ‚ïë\n‚ïë  Duration: 3m 45s                          ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  Next steps:                               ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```\n\nUse AskUserQuestion for completion:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"What would you like to do?\",\n    header: \"Complete\",\n    multiSelect: false,\n    options: [\n      {label: \"View results\", description: \"Display all node outputs\"},\n      {label: \"Save template\", description: \"Save workflow for reuse\"},\n      {label: \"Run again\", description: \"Execute workflow again\"},\n      {label: \"Return to menu\", description: \"Go back to main menu\"}\n    ]\n  }]\n})\n```\n\n---\n\n### Phase 7: Agent Promotion (if temp agents used)\n\nIf the workflow used temp agents and completed successfully, offer to promote them to defined agents.\n\n#### Step 1: Detect Temp Agent Usage\n\nCheck if any nodes used temp agents:\n```javascript\nconst tempAgentsUsed = nodes.filter(n => n.agentSource === 'temp');\nif (tempAgentsUsed.length === 0) {\n  // Skip promotion flow\n  continue to phase 6;\n}\n```\n\n#### Step 2: Generate Smart Suggestions\n\nAnalyze temp agents for reusability:\n```javascript\n// Analyze which temp agents are generic vs workflow-specific\nconst tempAgentNames = tempAgentsUsed.map(n => n.agentType);\nconst suggestions = analyzeAgentsForPromotion(tempAgentNames);\n\n// Generic agents should be promoted, workflow-specific ones should be deleted\n```\n\n#### Step 3: Present Batch Selection\n\nUse AskUserQuestion tool:\n```javascript\nconst options = suggestions.map(s => ({\n  label: s.name,\n  description: s.reason\n}));\n\nAskUserQuestion({\n  questions: [{\n    question: \"Select which temp agents to save as permanent defined agents:\",\n    header: \"Agent Promotion\",\n    multiSelect: true,\n    options: options\n  }]\n});\n```\n\nMark recommended agents as pre-selected in UI if possible.\n\n#### Step 4: Process Selections\n\n```javascript\nconst selectedNames = // from user response\nconst results = agentPromotion.processPromotions(selectedNames);\n\n// Show success message\nif (results.promoted.length > 0) {\n  console.log(`‚úì Saved ${results.promoted.length} agents:`);\n  results.promoted.forEach(name => {\n    console.log(`  - ${name} ‚Üí agents/${name}.md`);\n  });\n  console.log('These agents are now available for future workflows!');\n}\n\n// Show failures if any\nif (results.failed.length > 0) {\n  console.log('Failed to promote:');\n  results.failed.forEach(f => {\n    console.log(`  - ${f.name}: ${f.reason}`);\n  });\n}\n```\n\n#### Step 5: Cleanup Unselected Agents\n\n```javascript\nconst deleted = agentPromotion.cleanupTempAgents(tempAgentNames, selectedNames);\nconsole.log(`Cleaned up ${deleted.length} temp agent(s)`);\n```\n\n#### Edge Cases\n\n- No temp agents: Skip this phase entirely\n- All recommendations are \"not recommended\": Show message \"No reusable agents detected. All temp agents deleted.\"\n- User cancels: Delete all temp agents\n- Name conflicts: Handle in processPromotions (offer rename or skip)\n\n---\n\n### Phase 8: Cleanup Temporary Files\n\n**IMPORTANT**: After workflow completion (regardless of success/failure), clean up ALL temporary files.\n\n#### What to Clean\n\n1. **Temporary Agent Files** (if not promoted in Phase 7)\n   - Location: `${CLAUDE_PLUGIN_ROOT}/temp-agents/*.md`\n   - Delete ALL `.md` files that were created for this workflow\n   - Keep only pre-existing temp agents (if any)\n\n2. **Temporary JSON Files**\n   - Location: `${CLAUDE_PLUGIN_ROOT}/examples/*.json`\n   - Delete ALL `.json` files (these are intermediate data files)\n   - Keep only `.flow` workflow templates\n\n#### Implementation\n\n```javascript\n// After Phase 7 (Agent Promotion) or if no temp agents were used\n\nasync function cleanupTemporaryFiles() {\n  const cleanupTasks = [];\n\n  // IMPORTANT: Use ${CLAUDE_PLUGIN_ROOT} for plugin workspace paths!\n\n  // 1. Clean up temp-scripts (Python, JS, shell scripts created during workflow)\n  const tempScriptFiles = Glob({\n    pattern: \"**/*\",\n    path: \"${CLAUDE_PLUGIN_ROOT}/temp-scripts/\"\n  });\n\n  for (const file of tempScriptFiles) {\n    Bash({ command: `rm \"${file}\"` });\n    cleanupTasks.push(file);\n  }\n\n  // 2. Clean up temp agents markdown files (if not promoted)\n  const tempAgentFiles = Glob({\n    pattern: \"*.md\",\n    path: \"${CLAUDE_PLUGIN_ROOT}/temp-agents/\"\n  });\n\n  for (const file of tempAgentFiles) {\n    Bash({ command: `rm \"${file}\"` });\n    cleanupTasks.push(file);\n  }\n\n  // 3. Clean up temporary JSON files in examples/ (workflow state files)\n  const tempJsonFiles = Glob({\n    pattern: \"*.json\",\n    path: \"${CLAUDE_PLUGIN_ROOT}/examples/\"\n  });\n\n  for (const file of tempJsonFiles) {\n    Bash({ command: `rm \"${file}\"` });\n    cleanupTasks.push(file);\n  }\n\n  // 4. Report cleanup\n  if (cleanupTasks.length > 0) {\n    console.log(`\\nüßπ Cleaned up ${cleanupTasks.length} temporary file(s):`);\n    cleanupTasks.forEach(file => {\n      console.log(`   - ${file.replace('${CLAUDE_PLUGIN_ROOT}/', '')}`);\n    });\n  } else {\n    console.log(`\\n‚ú® No temporary files to clean up`);\n  }\n}\n\n// Execute cleanup - MANDATORY after every workflow\nawait cleanupTemporaryFiles();\n```\n\n#### When to Clean\n\n- **Always**: After workflow completion (success or failure)\n- **Exception**: Don't delete files if user explicitly requests to keep them\n- **Timing**: After agent promotion phase, before final completion message\n\n#### User Notification\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë  Workflow Complete                         ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  Total steps: 12                           ‚ïë\n‚ïë  Completed: 11 ‚úì                           ‚ïë\n‚ïë  Duration: 3m 45s                          ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  üßπ Cleanup: 3 temporary files removed     ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  Next steps:                               ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```\n\n---\n\n## State Management\n\nMaintain execution state throughout:\n```javascript\n{\n  workflow: \"original syntax\",\n  visualization: \"...\",   // Optional static ASCII art from template\n  graph: {\n    nodes,\n    edges,\n    variables: {},      // If temp agents: varName -> value\n    tempAgents: {}      // If temp agents: metadata\n  },\n  execution: {current, completed, failed, outputs},\n  steering: {paused, position, command}\n}\n```\n\n**Variables Map** (when temp agents used):\n- Stores outputs from agents with `outputVar` specified\n- Used for interpolating `{varname}` in subsequent instructions\n- Display summary at checkpoints and completion\n\n## Key Principles\n\n1. Parse first, execute later\n2. Show visualizations throughout\n3. Provide user control at checkpoints\n4. Fail gracefully with recovery options\n5. Context-aware error messages\n\n## Performance\n\n- Launch parallel agents in single response\n- Keep visualizations under 80 chars width\n- Limit parallel branches to 3-5 for clarity\n- Split large workflows (>50 nodes) into templates\n\n## Documentation References\n\n**Core Implementation:**\n- `${CLAUDE_PLUGIN_ROOT}/docs/core/parser.md` - Syntax parsing details\n- `${CLAUDE_PLUGIN_ROOT}/docs/core/executor.md` - Execution algorithm\n- `${CLAUDE_PLUGIN_ROOT}/docs/core/visualizer.md` - Rendering system\n- `${CLAUDE_PLUGIN_ROOT}/docs/core/steering.md` - Interactive control\n\n**Features:**\n- `${CLAUDE_PLUGIN_ROOT}/docs/features/temporary-agents.md` - Temporary agent system ($agent syntax)\n- `${CLAUDE_PLUGIN_ROOT}/docs/features/defined-agents.md` - Defined agent system\n- `${CLAUDE_PLUGIN_ROOT}/docs/features/agent-promotion.md` - Agent promotion workflow\n- `${CLAUDE_PLUGIN_ROOT}/docs/features/templates.md` - Template system\n- `${CLAUDE_PLUGIN_ROOT}/docs/features/error-handling.md` - Recovery strategies\n- `${CLAUDE_PLUGIN_ROOT}/docs/features/custom-definitions.md` - Extension system\n\n**Reference:**\n- `${CLAUDE_PLUGIN_ROOT}/docs/reference/syntax.md` - Complete syntax specification\n- `${CLAUDE_PLUGIN_ROOT}/docs/reference/temp-agents-syntax.md` - Temporary agent syntax\n- `${CLAUDE_PLUGIN_ROOT}/docs/reference/best-practices.md` - Guidelines and limitations\n\n**Examples and Templates:**\n- `${CLAUDE_PLUGIN_ROOT}/examples/` - Example workflows directory\n- `${CLAUDE_PLUGIN_ROOT}/examples/README.md` - Template documentation\n\n**Agent System:**\n- `${CLAUDE_PLUGIN_ROOT}/agents/registry.json` - Defined agents registry\n- `${CLAUDE_PLUGIN_ROOT}/agents/workflow-socratic-designer.md` - Socratic workflow designer\n- `${CLAUDE_PLUGIN_ROOT}/agents/workflow-syntax-designer.md` - Syntax designer\n- `${CLAUDE_PLUGIN_ROOT}/temp-agents/` - Temporary agent definitions\n",
        "commands/template.md": "---\ndescription: Load and execute saved workflow templates\ndeprecated: true\n---\n\n# ‚ö†Ô∏è DEPRECATED: Orchestration Template Execution\n\n**This command is deprecated.** Use the **using-templates** skill instead for better template discovery and customization.\n\n## Migration Guide\n\n**Instead of:** `/orchestration:template tdd-implementation`\n\n**Just say:** \"Use the TDD implementation template\"\n\nThe `using-templates` skill will automatically activate.\n\n---\n\n## Legacy Usage (Still Works)\n\nLoad and execute a saved workflow template with parameter substitution.\n\n## Arguments: {{ARGS}}\n\n## Template Location\n\nTemplates are stored at: `~/.claude/plugins/repos/orchestration/examples/{{ARGS}}.flow`\n\n## Template Format\n\n```yaml\n---\nname: template-name\ndescription: What this template does\nparams:\n  param1: Description (default: value)\n  param2: Another parameter (default: another value)\nvisualization: |\n  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n  ‚ïë  Workflow Name                                                             ‚ïë\n  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n  ‚ïë  [Static ASCII visualization of your workflow]                             ‚ïë\n  ‚ïë  This will be displayed consistently every time                            ‚ïë\n  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\nworkflow: |\n  step1:\"{{param1}}\" -> step2:\"{{param2}}\"\n---\n```\n\n**Notes:**\n- The `visualization` field is optional but recommended. If provided, this static ASCII art will be displayed instead of dynamically generating the visualization from the workflow syntax.\n- The `workflow` field contains the raw workflow syntax (with `->`, `[]`, `||`, etc.). Keep it compact without comments.\n- Both fields ensure consistent display and execution across all runs.\n\n## Execution Flow\n\n### 1. Check Template Exists\n\nRead template file:\n```javascript\nRead(`~/.claude/plugins/repos/orchestration/examples/${templateName}.flow`)\n```\n\nIf file doesn't exist:\n- Display friendly error message\n- List available templates from `~/.claude/plugins/repos/orchestration/examples/*.flow`\n- Offer to:\n  - Select another template\n  - Create new workflow from scratch\n  - Return to menu\n\n### 2. Parse Template\n\nExtract from template YAML frontmatter (between `---` delimiters):\n- **name** - Template identifier\n- **description** - What this template does\n- **params** - Parameters with descriptions and defaults\n- **visualization** - Optional static ASCII art (displayed consistently)\n- **workflow** - Raw workflow syntax with operators (`->`, `[]`, `||`, etc.)\n\n**Important:**\n- Both `visualization` and `workflow` are read from the YAML frontmatter\n- No dynamic generation occurs - the template is used exactly as written\n- This ensures 100% consistent display and execution every time\n\n### 3. Prompt for Parameters\n\nIf template has parameters, use AskUserQuestion to collect values:\n\nFor each parameter, show:\n- Parameter name\n- Description from template\n- Default value\n\nExample:\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"Enter value for 'feature' parameter\",\n    header: \"Parameters\",\n    multiSelect: false,\n    options: [\n      {label: \"Use default\", description: `Default value: ${defaultValue}`},\n      {label: \"Custom value\", description: \"Enter a custom value\"}\n    ]\n  }]\n})\n```\n\nIf user selects \"Custom value\", prompt for the actual value.\n\n### 4. Substitute Parameters\n\nReplace all `{{param}}` placeholders in the workflow with provided values.\n\nExample:\n- Template workflow: `implement:\"{{feature}}\" -> test:\"{{feature}}\"`\n- Values: `{feature: \"authentication\"}`\n- Result: `implement:\"authentication\" -> test:\"authentication\"`\n\n### 5. Execute Workflow\n\nPass the substituted workflow syntax from the frontmatter to `/orchestration:run`.\n\nThe static visualization (if present) is also passed along to ensure consistent display.\n\nThis will trigger the parse ‚Üí visualize ‚Üí execute flow using the exact syntax stored in the template.\n\n## After Execution\n\nWhen workflow completes, ask if user wants to:\n- Run template again with different parameters\n- Save current workflow as new template\n- Return to menu\n\n## Error Handling\n\n### Invalid Template Format\n- Display clear error message explaining what's wrong\n- Show example of correct format\n- Offer to fix template or choose another\n\n### Missing Parameters\n- Detect any unsubstituted `{{...}}` in workflow\n- Show which parameters are missing\n- Re-prompt for those specific values\n\n### Workflow Execution Errors\n- Let `/orchestration:run` handle execution errors\n- Its error recovery system will take over\n\n## Implementation Notes\n\n**Parameter Defaults:**\n- Always show default values to user\n- Allow empty input to use default\n- Validate parameter values before substitution\n\n**Template Discovery:**\n- Use Glob to find all `*.flow` files in ~/.claude/plugins/repos/orchestration/examples/\n- Parse frontmatter to get names and descriptions\n- Reference examples/README.md for template documentation\n- Cache for quick listing\n\n**Parameter Types:**\n- All parameters are strings\n- No type validation needed at template level\n- Let workflow execution validate usage\n\n**Nested Placeholders:**\n- Support `{{param}}` anywhere in workflow\n- Including in agent instructions, conditions, etc.\n- Multiple occurrences of same parameter are all replaced\n",
        "docs/plans/README.md": "# Orchestration Plugin Improvement Plans\n\nThis directory contains comprehensive implementation planning documentation for the orchestration plugin improvement initiative.\n\n---\n\n## Documents Overview\n\n### 1. [IMPROVEMENT-IMPLEMENTATION-PLAN.md](./IMPROVEMENT-IMPLEMENTATION-PLAN.md)\n\n**Primary comprehensive implementation plan** (50+ pages)\n\n**Contents:**\n- Executive summary and investment overview\n- Detailed implementation plans for all 5 priorities (P1-P5)\n- Technical architecture designs\n- Sprint-by-sprint breakdown with tasks, timelines, and deliverables\n- Integration strategy across priorities\n- Resource allocation guidance (sequential and parallel approaches)\n- Risk management framework\n- Success metrics and KPIs\n- Deployment strategy with gradual rollout\n- Monitoring and feedback loops\n- Comprehensive appendices (templates, checklists, playbooks)\n\n**Use for:**\n- Overall program planning and execution\n- Technical architecture reference\n- Detailed task planning and estimation\n- Risk assessment and mitigation\n- Stakeholder communication\n\n---\n\n### 2. [IMPROVEMENT-PLAN-QUICK-REF.md](./IMPROVEMENT-PLAN-QUICK-REF.md)\n\n**Quick reference guide** (8 pages)\n\n**Contents:**\n- At-a-glance timeline and priorities\n- Key goals and deliverables per priority\n- Success metrics dashboard\n- Sprint cadence and meeting structure\n- Risk summary with mitigations\n- Deployment approach summary\n- Communication templates\n- Decision framework\n- Quick links to all resources\n\n**Use for:**\n- Daily/weekly reference during execution\n- Quick status checks\n- Communication templates\n- Decision-making guidance\n- Sprint planning reference\n\n---\n\n### 3. [SPRINT-TEMPLATE.md](./SPRINT-TEMPLATE.md)\n\n**Reusable sprint planning template**\n\n**Contents:**\n- Sprint information and team structure\n- Sprint backlog with prioritization (P0/P1/P2)\n- Schedule and meeting cadence\n- Definition of Done checklist\n- Acceptance criteria template\n- Risk and dependency tracking\n- Success metrics framework\n- Testing strategy template\n- Documentation tracking\n- Communication plan\n- Retrospective format\n- Sprint planning checklist\n\n**Use for:**\n- Planning each individual sprint\n- Tracking sprint progress\n- Sprint retrospectives\n- Capturing lessons learned\n\n---\n\n## Related Documents\n\n### Technical Debt Documentation\n- [TECHNICAL-DEBT.md](../../TECHNICAL-DEBT.md) - Comprehensive technical debt inventory and ROI analysis\n\n### Existing Plans\n- [natural-language-workflow-creation-design.md](./2025-11-07-natural-language-workflow-creation-design.md)\n- [nl-workflow-creation-implementation.md](./2025-11-07-nl-workflow-creation-implementation.md)\n\n### Core Documentation\n- [README.md](../../README.md) - Plugin overview\n- [FEATURES.md](../FEATURES.md) - Feature index\n- [TESTING.md](../../tests/TESTING.md) - Testing protocol\n\n---\n\n## How to Use These Plans\n\n### For Technical Leads\n\n1. **Review** [IMPROVEMENT-IMPLEMENTATION-PLAN.md](./IMPROVEMENT-IMPLEMENTATION-PLAN.md) for complete context\n2. **Decide** sequential vs parallel approach based on team size\n3. **Plan** first sprint using [SPRINT-TEMPLATE.md](./SPRINT-TEMPLATE.md)\n4. **Track** progress using [IMPROVEMENT-PLAN-QUICK-REF.md](./IMPROVEMENT-PLAN-QUICK-REF.md)\n5. **Monitor** risks and metrics weekly\n6. **Communicate** to stakeholders monthly\n\n### For Developers\n\n1. **Read** your assigned priority section in the implementation plan\n2. **Reference** [IMPROVEMENT-PLAN-QUICK-REF.md](./IMPROVEMENT-PLAN-QUICK-REF.md) for goals and metrics\n3. **Use** [SPRINT-TEMPLATE.md](./SPRINT-TEMPLATE.md) for sprint execution\n4. **Update** sprint template with progress and retrospectives\n5. **Follow** Definition of Done for all tasks\n\n### For Product Owners\n\n1. **Review** executive summary and ROI analysis\n2. **Approve** priority order and resource allocation\n3. **Monitor** success metrics dashboard\n4. **Receive** monthly stakeholder updates\n5. **Provide** feedback and adjust priorities as needed\n\n### For QA Leads\n\n1. **Review** testing strategies for each priority\n2. **Plan** test infrastructure (P4) as critical foundation\n3. **Define** acceptance criteria for each sprint\n4. **Execute** validation and integration testing\n5. **Track** test coverage and quality metrics\n\n---\n\n## Improvement Timeline\n\n```\nTotal Duration: 16-21 weeks\nInvestment: $150k-$250k (estimated)\nExpected Return: $58k-$85k/year\nROI: 365%\nPayback Period: ~2 years\n```\n\n### Sequential Plan (Recommended for 1-2 developers)\n\n```\nWeek 1-3:   P1 - Path Handling Clarification\nWeek 4-8:   P4 - Testing & Validation Infrastructure\nWeek 9-12:  P2 - Error Handling Documentation\nWeek 13-17: P3 - Syntax Library Indexing\nWeek 18-21: P5 - Performance Optimization (Deferred if needed)\n```\n\n### Parallel Plan (For 3+ developers)\n\n```\nTrack A (Dev1): P1 (1-3) ‚Üí P2 (9-12)\nTrack B (Dev2): P4 (4-8) ‚Üí P3 (13-17) ‚Üí P5 (18-21)\nDuration: 17 weeks with coordination overhead\n```\n\n---\n\n## Key Priorities Rationale\n\n### Why This Order?\n\n**P1 First (Path Handling):**\n- Highest user pain point (30% of support issues)\n- Blocks template ecosystem growth\n- Quick win (2-3 weeks) builds momentum\n- No dependencies, can start immediately\n\n**P4 Second (Testing):**\n- Critical foundation for all future work\n- Enables confident development and refactoring\n- Protects against regressions\n- Provides infrastructure for validating P2, P3, P5\n\n**P2 Third (Error Handling):**\n- Leverages P1 path improvements\n- Benefits from P4 test coverage\n- Improves user confidence and reduces support burden\n\n**P3 Fourth (Syntax Indexing):**\n- Unlocks feature utilization and ecosystem growth\n- Leverages P4 test infrastructure\n- Feeds into P5 performance optimization\n\n**P5 Fifth (Performance):**\n- Lowest current priority (no active issues)\n- Benefits from all previous improvements\n- Can be deferred if needed\n\n---\n\n## Success Criteria\n\n### Program-Level Success\n\nThe improvement initiative is successful if:\n\n1. **All P1-P4 completed** with success metrics met (P5 optional)\n2. **User satisfaction** score >4/5\n3. **Support tickets** reduced by 50%+\n4. **Feature utilization** increased to 75%+\n5. **Test coverage** at 70%+\n6. **Development velocity** increased by 30%+\n7. **ROI targets** achieved ($58k-$85k annual benefit)\n\n### Priority-Level Success\n\nEach priority has specific success criteria documented in the implementation plan. See [Success Metrics & KPIs](./IMPROVEMENT-IMPLEMENTATION-PLAN.md#success-metrics--kpis) section.\n\n---\n\n## Risk Management\n\n### Top Risks\n\n1. **Path changes break workflows** (HIGH severity)\n   - Mitigation: Extensive testing, gradual rollout, quick rollback\n\n2. **Testing delays other priorities** (MEDIUM severity)\n   - Mitigation: Start early, accept incremental coverage\n\n3. **Resource availability changes** (MEDIUM severity)\n   - Mitigation: Document thoroughly, maintain continuity\n\n4. **Scope creep** (MEDIUM severity)\n   - Mitigation: Clear acceptance criteria, regular reviews\n\nSee [Risk Management](./IMPROVEMENT-IMPLEMENTATION-PLAN.md#risk-management) section for complete risk register.\n\n---\n\n## Communication\n\n### Weekly Updates\n\nUse template from [Quick Reference](./IMPROVEMENT-PLAN-QUICK-REF.md#communication-templates)\n\n**Format:**\n- Completed tasks\n- In-progress tasks\n- Blocked tasks\n- Key metrics\n- Next week's plan\n\n### Monthly Stakeholder Updates\n\n**Format:**\n- Executive summary\n- Completed priorities\n- In-progress priorities\n- Metrics dashboard\n- Budget and timeline status\n- Risks and issues\n- Next month's focus\n\n---\n\n## Next Steps\n\n1. **Review and Approve** the implementation plan\n2. **Allocate Resources** based on chosen approach (sequential/parallel)\n3. **Kick Off P1 Sprint 1** using the sprint template\n4. **Establish Monitoring** for success metrics\n5. **Set Up Communication** channels and cadence\n6. **Execute with Discipline** and adaptability\n\n---\n\n## Questions or Feedback?\n\n**For technical questions:** Tech Lead\n**For priority questions:** Product Owner\n**For process questions:** QA Lead\n**For escalations:** [Escalation process]\n\n---\n\n## Document Maintenance\n\n**Update Frequency:**\n- Implementation Plan: Monthly review, update as needed\n- Quick Reference: After each priority completion\n- Sprint Template: Per sprint (create new copy)\n\n**Review Schedule:**\n- After P1 completion (Week 3)\n- After P4 completion (Week 8)\n- After P2 completion (Week 12)\n- After P3 completion (Week 17)\n- After P5 completion (Week 21)\n\n**Version Control:**\n- All plans tracked in git\n- Major revisions documented in version history\n- Changes communicated to team\n\n---\n\n## Version History\n\n| Version | Date | Changes | Author |\n|---------|------|---------|--------|\n| 1.0 | 2025-11-07 | Initial improvement plans created | Technical Team |\n\n---\n\n**Status:** Active\n**Last Updated:** 2025-11-07\n**Next Review:** After P1 completion (Week 3)\n**Owner:** Technical Lead\n",
        "examples/README.md": "# Orchestration Workflow Templates\n\nThis directory contains static workflow templates that follow strict orchestration syntax for deterministic execution.\n\n## Template Structure\n\nAll templates in this directory follow these principles:\n\n1. **Static Execution**: Templates define a fixed execution graph with no dynamic behavior\n2. **Real Agents Only**: Use actual agent names (Explore, general-purpose, expert-code-implementer, etc.)\n3. **No Custom Actions**: No undefined actions like `find-jsx-strings` or `validate-structure`\n4. **No Parameters**: Templates execute the same way every time without parameter substitution\n5. **Clear Phases**: Each phase has a descriptive comment explaining its purpose\n\n## Available Templates\n\n### i18n-fix-hardcoded-strings.flow\nFinds and replaces hardcoded strings in JSX/TSX files with i18n translation calls.\n- Searches entire codebase for hardcoded user-facing text\n- Generates semantic translation keys\n- Updates all locale files\n- Creates git commit with changes\n\n### plugin-testing.flow\nComprehensive validation of Claude Code plugins.\n- Validates plugin structure and configuration\n- Security audit for vulnerabilities\n- Functionality testing\n- Documentation compliance check\n- Generates improvement plan\n\n### tdd-implementation.flow\nImplements new features using Test-Driven Development methodology.\n- Writes failing tests first (RED)\n- Implements minimal code to pass tests (GREEN)\n- Refactors for quality (REFACTOR)\n- Maintains test coverage throughout\n\n### debug-and-fix.flow\nSystematic approach to debugging and fixing issues.\n- Reproduces the problem\n- Investigates root cause\n- Writes regression test\n- Implements targeted fix\n- Verifies solution\n\n## Syntax Guide\n\n### Sequential Execution\n```\nagent1:\"instruction\":output1 -> agent2:\"instruction\":output2\n```\n\n### Parallel Execution\n```\n[\n  agent1:\"instruction\":output1 ||\n  agent2:\"instruction\":output2\n] ->\n```\n\n### Checkpoints (User Interaction)\n```\n@checkpoint-name ->\n```\n\n### Comments\n```\n# This is a comment explaining the phase\n```\n\n## Agent Types\n\nThe following agents are available for use in templates:\n\n- `Explore` - Fast codebase exploration and search\n- `Plan` - Planning and breaking down complex tasks\n- `general-purpose` - Versatile agent for complex multi-step tasks\n\n**Note:** Additional agents may be available through plugins installed in your environment.\n\n## Best Practices\n\n1. **Descriptive Instructions**: Each agent instruction should be self-contained and clear\n2. **Meaningful Output Names**: Use descriptive names like `:requirements_analyzed` not `:output1`\n3. **Logical Phases**: Group related operations into clear phases with comments\n4. **User Checkpoints**: Add `@checkpoint` at decision points for user review\n5. **Error Handling**: Include validation steps after critical operations\n6. **Parallel When Possible**: Use parallel execution `||` for independent operations\n7. **Atomic Commits**: Include git operations at the end of workflows\n\n## Running Templates\n\nTemplates are executed via the orchestration system:\n\n```\n/orchestration:template [template-name]\n```\n\nExample:\n```\n/orchestration:template i18n-fix-hardcoded-strings\n/orchestration:template debug-and-fix\n```\n\nTemplates can also be run directly:\n```\n/orchestration:run < [template-file]\n```\n\n## Creating New Templates\n\nWhen creating new templates:\n\n1. Start with a clear goal and break it into phases\n2. Use only real agents that exist in the system\n3. Write self-contained instructions for each agent\n4. Add checkpoints for user review at key decision points\n5. Include validation steps to ensure correctness\n6. End with a summary or commit phase\n7. Test the template thoroughly before committing\n\n## Template Validation\n\nBefore using a template, validate it follows these rules:\n\n- ‚úÖ Uses only real agent names (Explore, Plan, general-purpose, or plugin agents)\n- ‚úÖ No parameter placeholders like `{{param}}`\n- ‚úÖ No custom/undefined actions\n- ‚úÖ Clear phase structure with comments\n- ‚úÖ Deterministic execution path\n- ‚úÖ Meaningful output variable names\n- ‚úÖ Appropriate checkpoints for user control\n\n## Notes\n\n- Templates are version-controlled and should be treated as code\n- Changes to templates should be tested before committing\n- Templates should be idempotent when possible\n- Keep templates focused on a single workflow/goal\n- Document any prerequisites or assumptions in comments",
        "library/syntax/actions/README.md": "# Custom Actions\n\nCustom actions are reusable workflow fragments that expand to full workflow syntax.\n\n## Format\n\n```markdown\n---\nname: @action-name\ntype: action\ndescription: What this action does\n---\n\n# Action Name\n\nDetailed explanation.\n\n## Expansion\n[actual workflow syntax this expands to]\n\n## Usage\nnode -> @action-name -> next-node\n```\n\n## Examples\n\nSee `deep-review.md` for a multi-stage review action example.\n",
        "library/syntax/aggregators/README.md": "# Custom Aggregators\n\nCustom aggregators define how to combine results from parallel execution branches.\n\n## Format\n\n```markdown\n---\nname: aggregator-name\ndescription: How this aggregator combines results\nbehavior: Step-by-step aggregation behavior\n---\n\n# Aggregator Name\n\nDetailed explanation of the aggregation strategy.\n\n## Behavior\n1. Collect results from all parallel branches\n2. Apply aggregation logic\n3. Produce single output\n4. Handle edge cases (ties, conflicts, etc.)\n\n## Usage\n[branch1 || branch2 || branch3] aggregator-name next-step\n```\n\n## Built-in Aggregators\n\n- Default merge - Combines all outputs\n- First success - Takes first successful result\n\nCreate custom aggregators when you need:\n- Voting mechanisms\n- Weighted results\n- Conflict resolution\n- Custom merge logic\n- Deduplication strategies\n\n## Examples\n\nSee `merge-with-vote.md` for a majority-vote aggregator example.\n",
        "library/syntax/checkpoints/README.md": "# Custom Checkpoints\n\nCustom checkpoints are manual approval points with specific prompts for the user.\n\n## Format\n\n```markdown\n---\nname: @checkpoint-name\ntype: checkpoint\ndescription: What this checkpoint validates\n---\n\n# Checkpoint Name\n\nDetailed explanation of what should be checked at this point.\n\n## Prompt\nThe prompt text shown to the user when the checkpoint is reached.\nThis should clearly explain what needs to be reviewed or verified.\n\n## Usage\nprevious-step -> @checkpoint-name -> next-step\n```\n\n## When to Create\n\nCreate custom checkpoints when you need:\n- Specific prompt text for approval\n- Domain-specific validation instructions\n- Contextual review guidelines\n\n## Examples\n\nSee `security-gate.md` for a security approval checkpoint example.\n",
        "library/syntax/conditions/README.md": "# Custom Conditions\n\nCustom conditions enable domain-specific conditional logic in workflows.\n\n## Format\n\n```markdown\n---\nname: if condition-name\ndescription: What this condition checks\nevaluation: How the condition is evaluated\n---\n\n# Condition Name\n\nDetailed explanation of when this condition is true.\n\n## Evaluation\nSpecific criteria for evaluation:\n- Check 1\n- Check 2\n- Result determination\n\n## Usage\noperation (if condition-name):variable~>\n  (if variable)~> handle-true\n```\n\n## Built-in Conditions\n\n- `(if passed)` - Check if previous step succeeded\n- `(if failed)` - Check if previous step failed\n- `(all success)` - Check if all parallel branches succeeded\n- `(any failed)` - Check if any parallel branch failed\n\nCreate custom conditions when you need:\n- Domain-specific logic\n- File/directory checks\n- Environment validation\n- Business rule evaluation\n\n## Examples\n\nSee examples for file-based and environment-based condition patterns.\n",
        "library/syntax/guards/README.md": "# Custom Guards\n\nCustom guards are pre-conditions that must be met before workflow execution can proceed.\n\n## Format\n\n```markdown\n---\nname: guard-name\ntype: guard\ndescription: What this guard checks\n---\n\n# Guard Name\n\nDetailed explanation of the pre-condition.\n\n## Check\n```bash\ncommand to check condition\n```\nExpected output or exit code\n\n## Error\nError message shown when guard fails.\nShould explain what needs to be fixed.\n\n## Usage\nguard-name -> step1 -> step2\n```\n\n## Built-in Guards\n\n- None (create custom guards as needed)\n\nCreate guards when you need to:\n- Verify environment state\n- Check file/directory existence\n- Validate prerequisites\n- Ensure clean state\n\n## Examples\n\nSee `require-clean-working-tree.md` for a git status check example.\n",
        "library/syntax/loops/README.md": "# Custom Loops\n\nCustom loops are retry patterns with specific behavior beyond simple retry.\n\n## Format\n\n```markdown\n---\nname: loop-name\ntype: loop\nparams: [param1, param2]\ndescription: What retry behavior this provides\n---\n\n# Loop Name\n\nDetailed explanation of the retry pattern.\n\n## Pattern\nThe workflow pattern using {flow} placeholder:\n@try -> {flow} (if failed)~> retry-logic -> @try\n\n## Parameters\n- param1: Description of parameter\n- param2: Description of parameter\n\n## Usage\nloop-name(args): step1 -> step2\n```\n\n## Built-in Loops\n\n- `@try` - Simple retry loop\n- `@retry` - Retry with checkpoint\n\nCreate custom loops when you need:\n- Exponential backoff\n- Conditional retry logic\n- Complex retry patterns\n- Parameterized retry behavior\n\n## Examples\n\nSee `retry-with-backoff.md` for an exponential backoff example.\n",
        "library/syntax/mcps/README.md": "# Custom MCP Integrations\n\nCustom MCP integrations wrap MCP server tools for use in orchestration workflows.\n\n## Format\n\n```markdown\n---\nname: mcp:server:tool\ntype: mcp\ndescription: What this MCP tool does\nserver: server-name\ntool: tool-name\nparams: [param1, param2]\n---\n\n# MCP Tool Name\n\nDetailed explanation of the MCP tool.\n\n## Server\nThe MCP server that provides this tool\n\n## Tool\nThe specific tool from that server\n\n## Parameters\n- param1: Description and type\n- param2: Description and type\n\n## Usage\nprevious-step -> mcp:server:tool:\"param-value\" -> next-step\n```\n\n## Naming Convention\n\nFormat: `mcp:<server>:<tool>`\n\nExamples:\n- `mcp:supabase:execute_sql` - Execute SQL on Supabase\n- `mcp:github:create_pr` - Create GitHub PR\n- `mcp:slack:send_message` - Send Slack message\n\nCreate MCP wrappers when you need to:\n- Integrate MCP servers with workflows\n- Make MCP tools composable\n- Pass workflow data to MCP tools\n\n## Examples\n\nSee examples for Supabase, GitHub, and other MCP integrations.\n",
        "library/syntax/operators/README.md": "# Custom Operators\n\nCustom operators extend the orchestration syntax with new flow control mechanisms.\n\n## Format\n\n```markdown\n---\nsymbol: =>\ndescription: Brief description of what this operator does\n---\n\n# Operator Name\n\nDetailed explanation of the operator behavior.\n\n## Behavior\n- Step 1 of what it does\n- Step 2 of what it does\n\n## Example\nexample-usage => another-node\n```\n\n## Built-in Operators\n\n- `->` Sequential flow\n- `||` Parallel execution\n- `~>` Conditional flow\n\nAdd custom operators here only when built-in operators don't express your workflow intent.\n",
        "library/syntax/tools/README.md": "# Custom Tools\n\nCustom tools are wrappers for external command-line tools that can be invoked in workflows.\n\n## Format\n\n```markdown\n---\nname: tool:toolname:action\ntype: tool\ndescription: What this tool does\ncommand: command-line invocation\noutput: description of output\n---\n\n# Tool Name\n\nDetailed explanation of the tool and its usage.\n\n## Command\n```bash\nactual command-line invocation\n```\n\n## Output\nDescription of what the tool outputs:\n- Output format\n- Success/failure indicators\n- Useful data returned\n\n## Usage\nprevious-step -> tool:toolname:action (if passed):result~> next-step\n```\n\n## Naming Convention\n\nFormat: `tool:<tool>:<action>`\n\nExamples:\n- `tool:npm:test` - Run npm tests\n- `tool:docker:build` - Build docker image\n- `tool:git:status` - Check git status\n- `tool:pytest:run` - Run pytest suite\n\nCreate tool wrappers when you need to:\n- Invoke external commands in workflows\n- Capture and use command output\n- Make tools composable with workflow syntax\n\n## Examples\n\nSee examples for npm, docker, and git tool wrappers.\n",
        "skills/creating-workflows-from-description/SKILL.md": "---\nname: creating-workflows-from-description\ndescription: Use when user describes complex multi-step tasks that could benefit from orchestration - guides natural language workflow creation\n---\n\n# Creating Workflows from Description\n\n## When to Use\n\nProactively suggest orchestration when user describes tasks involving:\n\n- **Multiple sequential steps** with dependencies\n- **Parallel operations** that could run simultaneously\n- **Conditional logic** or branching (if/then scenarios)\n- **Error handling** or retry requirements\n- **Testing, review, and deployment** phases\n- **Complex multi-agent coordination**\n- **Quality gates** or approval checkpoints\n\n## Trigger Patterns\n\nWatch for these patterns in user messages:\n\n**Explicit workflow requests:**\n- \"I need to [multi-step task]\"\n- \"Help me build a pipeline for [process]\"\n- \"Create a workflow that [description]\"\n- \"Automate [complex task]\"\n\n**Implicit workflow descriptions:**\n- User describes 3+ sequential steps\n- User mentions temporal ordering: \"then\", \"after that\", \"once that's done\"\n- User mentions conditionals: \"if that works\", \"if tests pass\"\n- User mentions parallel work: \"at the same time\", \"in parallel\", \"simultaneously\"\n- User mentions reviews/approvals: \"needs review\", \"after approval\"\n- User mentions retry/error handling: \"if it fails\", \"retry\", \"rollback\"\n\n**Example phrases:**\n- \"run tests, then if they pass...\"\n- \"deploy to production after security review\"\n- \"implement with TDD workflow\"\n- \"check code quality before merging\"\n- \"parallel test execution\"\n\n## Action\n\nWhen triggers detected, suggest orchestration:\n\n```\nThis sounds like a perfect use case for orchestration! I can help you create a workflow that handles:\n\n[List 2-4 key aspects identified from description, e.g.:]\n- Sequential testing and deployment steps\n- Parallel validation (tests + security scan)\n- Conditional deployment based on test results\n- Automatic rollback on failure\n\nWould you like me to guide you through creating this workflow?\n```\n\n**If user says yes:**\n\nExecute the create command with their description:\n```\n/orchestration:create [initial description from user message]\n```\n\n**If user says no or wants to see example first:**\n\nShow relevant example from docs/reference/examples.md that matches their pattern.\n\n## Examples\n\n### Example 1: TDD Workflow\n\n**User:** \"I need to implement authentication using test-driven development\"\n\n**Assistant:** \"This sounds like a perfect use case for orchestration! I can help you create a TDD workflow that handles:\n- Writing tests first\n- Running tests and tracking results\n- Implementing features to pass tests\n- Automatic retry loop for failed tests\n\nWould you like me to guide you through creating this workflow?\"\n\n**If yes:** `/orchestration:create implement authentication with TDD`\n\n### Example 2: Deployment Pipeline\n\n**User:** \"Can you help me set up automated deployment that runs tests first, then if everything passes, does a security scan, and only deploys if both succeed?\"\n\n**Assistant:** \"This sounds like a perfect use case for orchestration! I can help you create a deployment pipeline that handles:\n- Parallel test and security validation\n- Quality gate before deployment (both must pass)\n- Automatic deployment when validation succeeds\n- Rollback capability if deployment fails\n\nWould you like me to guide you through creating this workflow?\"\n\n**If yes:** `/orchestration:create deploy with tests and security validation`\n\n### Example 3: Code Review Workflow\n\n**User:** \"I want to make sure all my changes go through code review and pass linting before merging\"\n\n**Assistant:** \"This sounds like a perfect use case for orchestration! I can help you create a review workflow that handles:\n- Parallel code review and linting\n- Quality gate (both must succeed)\n- Manual approval checkpoint\n- Automatic merge after approval\n\nWould you like me to guide you through creating this workflow?\"\n\n**If yes:** `/orchestration:create code review with linting and approval`\n\n## Don't Trigger For\n\n**Simple single-step tasks:**\n- \"Run the tests\" ‚Üê just run tests\n- \"Deploy to production\" ‚Üê single action\n- \"Review this code\" ‚Üê single agent\n\n**Already using orchestration syntax:**\n- User provides workflow syntax directly\n- User asks to modify existing workflow\n\n**Exploratory questions:**\n- \"What is orchestration?\"\n- \"How does the menu work?\"\n- \"Show me examples\"\n\n## Integration\n\nThis skill makes Claude proactive about suggesting orchestration when appropriate. It works alongside:\n\n- `/orchestration:create` - Command this skill triggers\n- `using-orchestration` - General guidance skill\n- `workflow-socratic-designer` - Agent this launches\n\n## Success Criteria\n\n‚úÖ Claude suggests orchestration for multi-step tasks\n‚úÖ Claude identifies parallel opportunities\n‚úÖ Claude recognizes conditional logic needs\n‚úÖ Claude explains workflow benefits before offering\n‚úÖ Claude uses /orchestration:create when user agrees\n",
        "skills/creating-workflows/SKILL.md": "---\nname: orchestration:creating-workflows\ndescription: Use when user says \"create workflow\", \"create a workflow\", \"design workflow\", \"orchestrate\", \"automate multiple steps\", \"coordinate agents\", \"multi-agent workflow\". Creates orchestration workflows from natural language using Socratic questioning to plan multi-agent workflows with visualization.\n---\n\n# Creating Orchestration Workflows\n\nI'll help you create powerful orchestration workflows that coordinate multiple Claude Code agents. I use Socratic questioning to understand your needs and generate optimal workflow syntax.\n\n## When I Activate\n\nI automatically activate when you:\n- Describe a multi-step process you want to automate\n- Mention \"workflow\", \"orchestration\", \"automate\", \"coordinate agents\"\n- Ask \"how do I create a workflow?\"\n- Want to connect multiple agents or tasks\n- Ask about automating repetitive processes\n\n## My Process\n\n### 1. Understanding Your Intent\n\n**CRITICAL**: I use AskUserQuestion tool for ALL questions. NO plain text numbered lists.\n\nI'll ask strategic questions to understand:\n- What problem you're solving\n- What your goal is\n- What scope you have in mind\n- **What external data sources you need** (APIs, web scraping, databases)\n\n### 2. Detecting Temp Script Needs\n\nI automatically scan for these triggers:\n- **External APIs**: Reddit, Twitter, GitHub, ProductHunt, etc.\n- **Web Scraping**: Extracting data from websites\n- **Data Processing**: Analyzing 10+ items, statistical analysis\n- **Authentication**: Any service requiring API keys\n\n**If detected ‚Üí I'll proactively create temp scripts for you**\n\n### 3. Identifying the Pattern\nI'll determine if your workflow is:\n- **Sequential**: One step after another (`->`)\n- **Parallel**: Multiple tasks at once (`||`)\n- **Conditional**: Based on results (`~>`)\n- **Hybrid**: Combination of above\n\n### 3. Designing the Workflow\nI'll help you define:\n- Which agents to use (built-in or custom)\n- How data flows between steps\n- Error handling strategy\n- Review checkpoints\n\n### 4. Generating Syntax\nI'll create clean, readable workflow syntax like:\n\n```flow\n# Simple sequential workflow\nexplore:\"Analyze codebase\" ->\nimplement:\"Add feature\" ->\ntest:\"Run tests\"\n```\n\n```flow\n# Parallel with merge\n[security-check || style-check || performance-check] ->\ngeneral-purpose:\"Consolidate findings\"\n```\n\n## Question Approach\n\nFor more details on my questioning strategy, see [socratic-method.md](socratic-method.md).\n\n**Quick overview:**\n- **Vague requests**: I ask about problem ‚Üí scope ‚Üí constraints\n- **Specific requests**: I confirm pattern ‚Üí ask about customization\n- **Medium requests**: I explore scope ‚Üí clarify details\n\n## Common Patterns\n\nI have templates for common scenarios. See [patterns.md](patterns.md) for complete catalog.\n\n**Popular patterns:**\n- Feature implementation (explore ‚Üí implement ‚Üí test ‚Üí review)\n- Bug fixing (investigate ‚Üí fix ‚Üí verify)\n- Security scanning (scan ‚Üí review ‚Üí fix ‚Üí verify)\n- Documentation (analyze ‚Üí write ‚Üí review)\n- Refactoring (analyze ‚Üí refactor ‚Üí test ‚Üí validate)\n\n## Custom Agents\n\nWhen your workflow needs specialized expertise, I can create **temp agents** for you.\n\n**Temp agents are:**\n- Created automatically during workflow design\n- Saved in `temp-agents/` directory\n- Auto-cleaned after workflow execution\n- Can be promoted to permanent agents if useful\n\n**When I create temp agents:**\n- You need domain-specific expertise (e.g., security scanner)\n- Task requires specific output formats\n- Multiple workflows might benefit (I'll suggest making it permanent)\n\nSee [temp-agents.md](temp-agents.md) for examples and guidelines.\n\n## Temp Scripts (CRITICAL)\n\n**Temp scripts** are Python/Node.js scripts I create for tasks that Claude Code tools can't handle directly.\n\n### When I Create Temp Scripts\n\nI **automatically** create temp scripts when you need:\n\n1. **External API calls** - Reddit, Twitter, GitHub, ProductHunt\n2. **Web scraping** - Extracting data from websites\n3. **Data processing** - Pandas analysis, JSON parsing at scale\n4. **Database queries** - SQL, NoSQL operations\n5. **Batch operations** - Processing 10+ files\n6. **Third-party libraries** - NumPy, BeautifulSoup, requests\n\n### How It Works\n\n**You say**: \"Fetch 10 Reddit posts about startups\"\n\n**I create**:\n```flow\ngeneral-purpose:\"Create Python script using PRAW library:\n1. Authenticate with Reddit API (client_id, client_secret)\n2. Fetch 10 hot posts from r/startups\n3. Extract: title, url, score, selftext\n4. Return JSON array\n5. Save as temp-scripts/reddit_fetcher.py\n6. Execute and return results\":reddit_posts\n```\n\n### Proactive Detection\n\nI scan your request for keywords:\n- \"API\", \"fetch\", \"scrape\", \"get data from\"\n- \"Reddit\", \"Twitter\", \"ProductHunt\", \"GitHub\"\n- \"analyze\", \"process\", \"calculate\"\n- Numbers like \"10 posts\", \"100 records\"\n\n**If found ‚Üí I'll suggest temp scripts and ask for your confirmation**\n\n### When Uncertain\n\nIf I'm not sure whether you need a temp script, I'll ask:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"How should I handle this data processing?\",\n    header: \"Approach\",\n    multiSelect: false,\n    options: [\n      {label: \"Built-in tools\", description: \"Use Read/Grep for simple operations\"},\n      {label: \"Create temp script\", description: \"Python script for complex processing\"},\n      {label: \"External API\", description: \"Fetch from service with authentication\"}\n    ]\n  }]\n})\n```\n\nFor complete guide, see: `docs/TEMP-SCRIPTS-DETECTION-GUIDE.md`\n\n## Custom Syntax\n\nSometimes you need syntax beyond the basics. I can design custom syntax elements like:\n- New operators (`=>` for merge-with-dedup)\n- Checkpoints (`@security-gate`)\n- Conditions (`if security-critical`)\n- Loops (`retry-with-backoff`)\n\nI follow a **reuse-first approach**: I check existing syntax before creating new.\n\nSee [custom-syntax.md](custom-syntax.md) for syntax design process.\n\n## Examples\n\nReal workflow examples to inspire you:\n\nSee [examples.md](examples.md) for complete catalog with explanations.\n\n**Quick examples:**\n\n**TDD Implementation:**\n```flow\n# Test-Driven Development workflow\ngeneral-purpose:\"Write failing test\":test_file ->\nimplement:\"Make test pass\":implementation ->\ncode-reviewer:\"Review {implementation}\":review ->\n(if review.approved)~> commit:\"Commit changes\" ~>\n(if review.needs_changes)~> implement:\"Fix issues\"\n```\n\n**Bug Investigation:**\n```flow\n# Parallel investigation with consolidation\n[\n  explore:\"Find related code\":related_files ||\n  general-purpose:\"Search for similar bugs\":similar_issues ||\n  general-purpose:\"Check recent changes\":recent_commits\n] ->\ngeneral-purpose:\"Consolidate findings into root cause analysis\":analysis ->\nimplement:\"Fix bug based on {analysis}\":fix ->\ngeneral-purpose:\"Run relevant tests\":test_results\n```\n\n**Security Audit:**\n```flow\n# Security scanning with manual gate\n$security-scanner:\"Scan codebase for vulnerabilities\":findings ->\n@security-review:\"Review {findings}. Approve if no critical issues.\" ->\n(if approved)~> deploy:\"Deploy to production\"\n```\n\n## Workflow Templates\n\nAfter creating your workflow, I'll offer to save it as a template for reuse.\n\nTemplates include:\n- Descriptive name and metadata\n- Parameter placeholders for customization\n- Complete workflow syntax\n- Usage instructions\n\nTemplates are saved in `examples/` directory as `.flow` files.\n\n## What Happens Next\n\nAfter I create your workflow:\n\n1. **Review**: I show you the generated syntax with explanation\n2. **Customize**: You can ask for modifications\n3. **Save**: I offer to save as template\n4. **Execute**: Use `/orchestration:run` to execute it\n\n## Tips for Best Results\n\n- **Be specific**: More details = better workflow\n- **Ask questions**: I'm here to help refine your ideas\n- **Start simple**: We can add complexity later\n- **Review examples**: Check [examples.md](examples.md) for inspiration\n\n## Technical Details\n\n- **Namespace**: All plugin agents use `orchestration:` prefix\n- **Temp agents**: Auto-prefixed with `orchestration:`\n- **Variable binding**: Use `:variable_name` to capture outputs\n- **Error handling**: Use `(if failed)~>` for error branches\n\nFor complete syntax reference, see executing-workflows skill or [syntax reference](../../docs/reference/syntax.md).\n\n## Related Skills\n\n- **executing-workflows**: Run workflows with visualization and steering\n- **managing-agents**: Create and manage custom agents\n- **designing-syntax**: Design custom syntax elements\n- **using-templates**: Use and customize workflow templates\n\n---\n\n**Ready to create a workflow? Just describe what you want to automate!**\n",
        "skills/creating-workflows/custom-syntax.md": "# Custom Syntax Design\n\nSometimes you need syntax beyond the built-in operators. I can help design custom syntax elements using a **reuse-first approach**.\n\n## Reuse-First Philosophy\n\nBefore creating new syntax, I check:\n\n1. **Built-in syntax** - Can existing operators do this?\n2. **Global syntax library** - Does a pattern already exist?\n3. **Template definitions** - Is this defined in a loaded template?\n4. **Similar patterns** - Can existing syntax be adapted?\n\nOnly if no match exists do I create new syntax.\n\n## When to Create Custom Syntax\n\nCreate custom syntax when:\n\n- **Common pattern repeats** - You keep writing the same sequence\n- **Domain-specific operations** - Industry-specific workflows\n- **Readability suffers** - Too verbose with basic syntax\n- **Abstraction helps** - Hide complexity behind clear name\n\n**Don't create** custom syntax for:\n- One-time use - Just use basic syntax\n- Already exists - Check library first\n- Overly specific - Won't be reusable\n\n## Custom Syntax Types\n\n### Actions (`@action-name`)\n\nReusable sub-workflows.\n\n**Example**: `@deep-review`\n```markdown\n---\nname: @deep-review\ntype: action\ndescription: Multi-stage code review\n---\n\n## Expansion\n[code-reviewer:\"security\" || code-reviewer:\"style\"] -> merge\n```\n\n**Usage**:\n```flow\nimplement:\"Write code\" -> @deep-review -> deploy\n```\n\n### Checkpoints (`@checkpoint-name`)\n\nManual approval gates with specific prompts.\n\n**Example**: `@security-gate`\n```markdown\n---\nname: @security-gate\ntype: checkpoint\ndescription: Security approval required\n---\n\n## Prompt\nReview security findings. Verify no critical vulnerabilities.\nOptions: Approve, Fix Issues, Abort\n```\n\n**Usage**:\n```flow\nscan:\"Security scan\" -> @security-gate -> deploy\n```\n\n### Operators (symbols)\n\nNew flow control operators.\n\n**Example**: `=>` (merge with dedup)\n```markdown\n---\nsymbol: =>\ndescription: Merge with deduplication\n---\n\nExecutes left then right, removing duplicates from combined output.\n```\n\n**Usage**:\n```flow\nfetch-primary => fetch-backup => process\n```\n\n### Conditions (`if condition-name`)\n\nCustom conditional logic.\n\n**Example**: `if security-critical`\n```markdown\n---\nname: if security-critical\ndescription: Check if changes affect security code\nevaluation: Modified files in: auth/, crypto/, permissions/\n---\n```\n\n**Usage**:\n```flow\nanalyze:\"Check changes\" ->\n(if security-critical)~> @security-review\n```\n\n### Loops\n\nReusable loop patterns.\n\n**Example**: `retry-with-backoff(n)`\n```markdown\n---\nname: retry-with-backoff\ntype: loop\nparams: [attempts]\ndescription: Retry N times with exponential backoff\n---\n\n## Pattern\n@try -> operation ->\n(if failed)~> wait:[exponential delay] -> @try ~>\n(if passed || attempts-exceeded)~> continue\n```\n\n**Usage**:\n```flow\nretry-with-backoff(3): deploy -> verify\n```\n\n## Design Process\n\nWhen you ask for custom syntax:\n\n### 1. I Verify Need\n\nI check if existing syntax can work:\n```\nYou want: \"retry 3 times with increasing delays\"\n\nExisting solution:\n@try -> op -> (if failed)~> wait -> @try ~> (if passed)~> next\n\nCustom syntax needed?\nOnly if this repeats frequently in your workflows.\n```\n\n### 2. I Propose Name\n\nI suggest an intuitive name:\n```\nFor: \"Deploy only if security scan is clean\"\nProposed: @security-gate or (if security-passed)\n```\n\n### 3. I Define Behavior\n\nI document exactly what it does:\n```markdown\n---\nname: @security-gate\ntype: checkpoint\n---\n\nBehavior:\n1. Pause workflow execution\n2. Show security scan results to user\n3. Prompt: \"Security scan complete. Approve deployment?\"\n4. Options: Approve / Fix Issues / Abort\n5. If Approve: Continue workflow\n6. If Fix Issues: Return to previous step\n7. If Abort: Stop workflow\n```\n\n### 4. I Create Examples\n\nI show how to use it:\n```flow\n# Before\nscan -> show-results -> ask-user -> (if approved)~> deploy\n\n# After with custom syntax\nscan -> @security-gate -> deploy\n```\n\n### 5. I Save Definition\n\nI save to library for reuse:\n```\nlibrary/syntax/checkpoints/security-gate.md\n```\n\n## Syntax Library Structure\n\n```\nlibrary/syntax/\n‚îú‚îÄ‚îÄ operators/          # Flow control operators\n‚îÇ   ‚îî‚îÄ‚îÄ merge-dedup.md\n‚îú‚îÄ‚îÄ actions/            # Reusable sub-workflows\n‚îÇ   ‚îî‚îÄ‚îÄ deep-review.md\n‚îú‚îÄ‚îÄ checkpoints/        # Approval gates\n‚îÇ   ‚îî‚îÄ‚îÄ security-gate.md\n‚îú‚îÄ‚îÄ conditions/         # Custom conditionals\n‚îÇ   ‚îî‚îÄ‚îÄ security-critical.md\n‚îú‚îÄ‚îÄ loops/              # Loop patterns\n‚îÇ   ‚îî‚îÄ‚îÄ retry-backoff.md\n‚îú‚îÄ‚îÄ aggregators/        # Result combination\n‚îÇ   ‚îî‚îÄ‚îÄ vote-majority.md\n‚îî‚îÄ‚îÄ guards/             # Pre-execution checks\n    ‚îî‚îÄ‚îÄ clean-working-tree.md\n```\n\n## Integration with Workflows\n\nCustom syntax is automatically loaded:\n\n```flow\n# This workflow uses custom syntax\nscan -> @security-gate -> deploy\n\n# I automatically:\n# 1. Check library/syntax/checkpoints/security-gate.md\n# 2. Load definition\n# 3. Expand during execution\n# 4. Execute as: scan -> [pause + prompt user] -> deploy\n```\n\n## Best Practices\n\n### DO:\n\n‚úÖ **Use descriptive names**\n- `@security-gate` not `@check`\n- `if security-critical` not `if important`\n\n‚úÖ **Document behavior clearly**\n- Exact steps\n- Edge cases\n- Expected inputs/outputs\n\n‚úÖ **Provide examples**\n- Show usage in workflows\n- Demonstrate with/without custom syntax\n\n‚úÖ **Keep composable**\n- Works with existing syntax\n- Can be nested\n- No surprising side effects\n\n### DON'T:\n\n‚ùå **Create for one-time use**\n‚ùå **Make too specific** (\"if tuesday-afternoon\")\n‚ùå **Hide too much complexity** (unclear what it does)\n‚ùå **Duplicate existing syntax**\n\n## Examples\n\n### Example 1: Adaptive Testing\n\n**Problem**: Different tests based on what changed.\n\n**Without custom syntax**:\n```flow\nanalyze:\"Check what changed\":changes ->\n(if changes.includes('api'))~> run:\"API tests\" ~>\n(if changes.includes('ui'))~> run:\"UI tests\" ~>\n(if changes.includes('db'))~> run:\"DB tests\"\n```\n\n**With custom syntax**: `@adaptive-tests`\n```markdown\n---\nname: @adaptive-tests\ntype: action\n---\n\nAnalyzes changes and runs relevant test suites:\n- API changes ‚Üí API + integration tests\n- UI changes ‚Üí UI + visual tests\n- DB changes ‚Üí DB migration tests\n```\n\n**Usage**:\n```flow\nanalyze:\"Check changes\" -> @adaptive-tests -> report\n```\n\n### Example 2: Canary Deployment\n\n**Problem**: Gradual rollout with health checks.\n\n**Custom syntax**: `=>canary(percent)`\n```markdown\n---\nname: =>canary\ntype: operator\nparams: [percent]\n---\n\nDeploys to X% of servers, monitors health, expands if healthy.\n```\n\n**Usage**:\n```flow\nbuild -> test -> deploy =>canary(10%) -> verify -> deploy =>canary(50%) -> deploy =>canary(100%)\n```\n\n### Example 3: Review Escalation\n\n**Problem**: Different approval levels based on risk.\n\n**Custom syntax**: `@escalating-review`\n```markdown\n---\nname: @escalating-review\ntype: checkpoint\n---\n\nReviews code with escalation:\n- Low risk: Auto-approve\n- Medium risk: Peer review\n- High risk: Senior + security review\n```\n\n**Usage**:\n```flow\nimplement -> assess-risk -> @escalating-review -> deploy\n```\n\n## Global vs Local Syntax\n\n**Global syntax** (in library/syntax/):\n- Available in all workflows\n- Well-tested and documented\n- Part of standard library\n\n**Local syntax** (in template Definitions):\n- Specific to one template/workflow\n- Not available globally\n- Can be promoted to global\n\n## Promoting Local to Global\n\nAfter using local syntax successfully:\n\n```\nI've noticed you use @security-gate in multiple workflows.\n\nWould you like to promote it to global syntax?\nThis will:\n- Save to library/syntax/checkpoints/security-gate.md\n- Make available in all future workflows\n- Add to syntax reference documentation\n```\n\n---\n\n**Want to create custom syntax? Describe the pattern you keep repeating!**\n",
        "skills/creating-workflows/examples.md": "# Workflow Examples\n\nReal-world workflow examples to inspire your automation.\n\n## Complete Examples\n\n### 1. TDD Feature Implementation\n\n**Use case**: Implement new feature using Test-Driven Development.\n\n**Workflow**: [examples/tdd-implementation.flow](../../../examples/tdd-implementation.flow)\n\n```flow\n# RED phase\nimplementation-architect:\"Analyze requirements, plan testable units\":spec ->\nexpert-code-implementer:\"Write comprehensive test suite (must fail)\":tests ->\ngeneral-purpose:\"Run tests, verify failures\":test_status ->\n\n@review-test-coverage ->\n\n# GREEN phase\nexpert-code-implementer:\"Write minimal code to pass tests\":implementation ->\ngeneral-purpose:\"Run tests, verify passes\":validation ->\n\n@review-implementation ->\n\n# REFACTOR phase\n[\n  code-optimizer:\"Refactor for quality\":refactored ||\n  expert-code-implementer:\"Add documentation\":docs\n] ->\n\ngeneral-purpose:\"Final test run\":final_validation ->\ngeneral-purpose:\"Commit changes\"\n```\n\n**Key features**:\n- RED-GREEN-REFACTOR cycle\n- Manual review checkpoints\n- Parallel refactoring and documentation\n- Comprehensive test validation\n\n### 2. Bug Investigation and Fix\n\n**Use case**: Systematic debugging of reported issues.\n\n**Workflow**: [examples/debug-and-fix.flow](../../../examples/debug-and-fix.flow)\n\n```flow\ngeneral-purpose:\"Reproduce issue, capture details\":issue_details ->\n\n# Parallel investigation\n[\n  Explore:\"Search codebase for error\":code_analysis ||\n  general-purpose:\"Analyze logs and traces\":log_analysis ||\n  general-purpose:\"Check environment and configs\":env_analysis\n] ->\n\ngeneral-purpose:\"Synthesize findings, identify root cause\":root_cause ->\n\n@review-root-cause ->\n\nexpert-code-implementer:\"Write regression test\":regression_test ->\nexpert-code-implementer:\"Implement fix\":fix ->\n\n# Parallel validation\n[\n  general-purpose:\"Run regression test\":regression_passed ||\n  general-purpose:\"Run full test suite\":suite_passed ||\n  general-purpose:\"Manual verification\":manual_verified\n] ->\n\n@review-fix ->\n\nexpert-code-implementer:\"Update docs, commit\"\n```\n\n**Key features**:\n- Parallel investigation paths\n- Regression test creation\n- Multi-level validation\n- Documentation updates\n\n### 3. Polish News Aggregation\n\n**Use case**: Aggregate and analyze Polish news from multiple sources.\n\n**Workflow**: [examples/polish-news-aggregation.flow](../../../examples/polish-news-aggregation.flow)\n\n```flow\n# Parallel data collection\n[\n  $rss-fetcher:\"Fetch RSS from Polish news sources\":rss ||\n  $web-scraper:\"Scrape fallback sites\":scraped\n] ->\n\ngeneral-purpose:\"Merge results\":all_articles ->\n$news-deduplicator:\"Remove duplicates\":unique ->\n$topic-clusterer:\"Group by topic\":clustered ->\n$graph-builder:\"Create visualization\":graph\n```\n\n**Key features**:\n- Multiple data sources\n- Custom temp agents for specialized tasks\n- Data deduplication\n- Visualization generation\n\n### 4. Security Audit Pipeline\n\n**Use case**: Comprehensive security scanning before deployment.\n\n```flow\n[\n  $security-scanner:\"OWASP Top 10 scan\":owasp ||\n  general-purpose:\"Dependency vulnerability check\":deps ||\n  $code-analyzer:\"Static analysis\":static\n] ->\n\ngeneral-purpose:\"Consolidate findings\":report ->\n\n@security-review:\"Review {report}. Critical issues?\" ->\n\n(if critical_issues)~> @emergency-halt:\"Stop deployment!\" ~>\n(if no_critical)~> general-purpose:\"Generate audit report\" ->\n                   general-purpose:\"Proceed with deployment\"\n```\n\n**Key features**:\n- Parallel security scans\n- Consolidated reporting\n- Manual security review gate\n- Conditional deployment stop\n\n### 5. CI/CD Pipeline\n\n**Use case**: Full continuous integration and deployment.\n\n```flow\ngeneral-purpose:\"Checkout code, install deps\":setup ->\n\n# Parallel quality checks\n[\n  general-purpose:\"Run linter\":lint ||\n  general-purpose:\"Run type checker\":types ||\n  general-purpose:\"Run unit tests\":units\n] ->\n\ngeneral-purpose:\"Build application\":build ->\n\n# Parallel integration checks\n[\n  general-purpose:\"Integration tests\":integration ||\n  $security-scanner:\"Security scan\":security ||\n  general-purpose:\"Performance benchmarks\":perf\n] ->\n\n@deployment-approval:\"Review results. Deploy?\" ->\n\ngeneral-purpose:\"Deploy to staging\":staging ->\ngeneral-purpose:\"Smoke tests on staging\":smoke ->\n\n@production-approval:\"Deploy to production?\" ->\n\ngeneral-purpose:\"Deploy to production\"\n```\n\n**Key features**:\n- Multi-stage validation\n- Parallel test execution\n- Manual approval gates\n- Staged deployment\n\n## Quick Patterns\n\n### Sequential Task Chain\n\n```flow\nstep1:\"First\" -> step2:\"Second\" -> step3:\"Third\"\n```\n\n### Parallel with Merge\n\n```flow\n[task1 || task2 || task3] -> general-purpose:\"Consolidate\"\n```\n\n### Conditional Branching\n\n```flow\ncheck:\"Evaluate\" ->\n(if condition)~> path-a:\"Do this\" ~>\n(if !condition)~> path-b:\"Do that\"\n```\n\n### Retry Loop\n\n```flow\n@attempt ->\noperation:\"Try task\" ->\n(if failed)~> wait:\"Wait\" -> @attempt ~>\n(if passed)~> next:\"Continue\"\n```\n\n### Review Checkpoint\n\n```flow\nwork:\"Do work\" ->\n@review:\"Review and approve\" ->\ncontinue:\"Proceed\"\n```\n\n## More Examples\n\nSee the [examples/](../../../examples/) directory for:\n- i18n-fix-hardcoded-strings.flow - Internationalization workflow\n- ui-component-refinement.flow - UI component improvement\n- plugin-testing.flow - Plugin testing workflow\n- agent-system-demo.flow - Agent system demonstration\n\n---\n\n**Want to see how a specific pattern works? Ask me to explain any workflow!**\n",
        "skills/creating-workflows/patterns.md": "# Common Workflow Patterns\n\nThis document catalogs proven workflow patterns for common scenarios. Use these as starting points for your workflows.\n\n## Sequential Patterns\n\n### Basic Sequential Flow\n\n**When to use**: Steps must happen in order, each depends on previous.\n\n```flow\nstep1:\"First task\" ->\nstep2:\"Second task\" ->\nstep3:\"Third task\"\n```\n\n**Example - Feature Implementation**:\n```flow\nimplementation-architect:\"Plan feature\":plan ->\nexpert-code-implementer:\"Implement {plan}\":code ->\ngeneral-purpose:\"Run tests\":results ->\ncode-reviewer:\"Review {code} and {results}\"\n```\n\n### Sequential with Error Handling\n\n**When to use**: Each step must succeed or workflow should stop.\n\n```flow\nstep1:\"Try operation\" ->\n(if failed)~> rollback:\"Undo changes\" ~>\n(if passed)~> step2:\"Continue\"\n```\n\n**Example - Deployment with Rollback**:\n```flow\ngeneral-purpose:\"Deploy new version\":deployment ->\ngeneral-purpose:\"Run smoke tests\":tests ->\n(if tests.failed)~> general-purpose:\"Rollback to previous version\" ~>\n(if tests.passed)~> general-purpose:\"Update monitoring dashboards\"\n```\n\n### Sequential with Retry\n\n**When to use**: Operations might fail temporarily but should retry.\n\n```flow\n@attempt ->\noperation:\"Try task\" ->\n(if failed)~> wait:\"Wait 5 seconds\" -> @attempt ~>\n(if passed)~> next:\"Continue\"\n```\n\n**Example - API Call with Retry**:\n```flow\n@try-api ->\ngeneral-purpose:\"Call external API\":response ->\n(if response.timeout)~> general-purpose:\"Wait 10 seconds\" -> @try-api ~>\n(if response.success)~> general-purpose:\"Process {response}\"\n```\n\n## Parallel Patterns\n\n### Basic Parallel Execution\n\n**When to use**: Multiple independent tasks can run simultaneously.\n\n```flow\n[task1 || task2 || task3] ->\nconsolidate:\"Merge results\"\n```\n\n**Example - Multi-Source Analysis**:\n```flow\n[\n  Explore:\"Analyze code structure\":structure ||\n  general-purpose:\"Check git history\":history ||\n  general-purpose:\"Review documentation\":docs\n] ->\ngeneral-purpose:\"Consolidate findings into comprehensive report\"\n```\n\n### Parallel with Individual Error Handling\n\n**When to use**: Some parallel tasks can fail without stopping others.\n\n```flow\n[\n  task1:\"First (continue on error)\" ||\n  task2:\"Second (continue on error)\" ||\n  task3:\"Third (continue on error)\"\n] ->\ngeneral-purpose:\"Process successful results, skip failed\"\n```\n\n**Example - Multi-Platform Testing**:\n```flow\n[\n  general-purpose:\"Run tests on Linux (continue on fail)\":linux_results ||\n  general-purpose:\"Run tests on macOS (continue on fail)\":mac_results ||\n  general-purpose:\"Run tests on Windows (continue on fail)\":win_results\n] ->\ngeneral-purpose:\"Generate cross-platform test report from {linux_results}, {mac_results}, {win_results}\"\n```\n\n### Parallel with Race Condition\n\n**When to use**: Multiple approaches, use first one that succeeds.\n\n```flow\n[approach1 || approach2 || approach3] ->\ngeneral-purpose:\"Use first successful result\"\n```\n\n**Example - Data Fetching Fallbacks**:\n```flow\n[\n  general-purpose:\"Try primary API\":primary ||\n  general-purpose:\"Try backup API\":backup ||\n  general-purpose:\"Try cache\":cached\n] ->\ngeneral-purpose:\"Use first available data source\"\n```\n\n## Conditional Patterns\n\n### If-Then-Else\n\n**When to use**: Different paths based on condition.\n\n```flow\ncheck:\"Evaluate condition\":result ->\n(if result.true)~> path-a:\"Do this\" ~>\n(if result.false)~> path-b:\"Do that\"\n```\n\n**Example - Security Check**:\n```flow\n$security-scanner:\"Scan for vulnerabilities\":findings ->\n(if findings.critical)~> @emergency-review:\"Critical issues found! Manual review required\" ->\n                         general-purpose:\"Stop deployment\" ~>\n(if findings.clean)~> general-purpose:\"Proceed with deployment\"\n```\n\n### Switch/Case Pattern\n\n**When to use**: Multiple mutually exclusive paths.\n\n```flow\nclassify:\"Determine type\":type ->\n(if type.A)~> handle-a:\"Process type A\" ~>\n(if type.B)~> handle-b:\"Process type B\" ~>\n(if type.C)~> handle-c:\"Process type C\"\n```\n\n**Example - Issue Triage**:\n```flow\nExplore:\"Analyze issue type\":issue_type ->\n(if issue_type.bug)~> $bug-fixer:\"Fix bug systematically\" ~>\n(if issue_type.feature)~> implementation-architect:\"Plan feature implementation\" ~>\n(if issue_type.docs)~> expert-code-implementer:\"Update documentation\" ~>\n(if issue_type.refactor)~> code-optimizer:\"Optimize code\"\n```\n\n## Review & Approval Patterns\n\n### Manual Checkpoint\n\n**When to use**: Human decision needed before proceeding.\n\n```flow\nprepare:\"Do work\" ->\n@review-checkpoint:\"Review and approve\" ->\ncontinue:\"Proceed after approval\"\n```\n\n**Example - PR Creation**:\n```flow\nexpert-code-implementer:\"Implement changes\":code ->\ngeneral-purpose:\"Run tests\":tests ->\n@review-changes:\"Review {code} and {tests}. Approve to create PR?\" ->\ngeneral-purpose:\"Create pull request with summary\"\n```\n\n### Multi-Stage Review\n\n**When to use**: Multiple approval stages required.\n\n```flow\nwork:\"Complete work\" ->\n@technical-review:\"Technical approval\" ->\n@security-review:\"Security approval\" ->\n@business-review:\"Business approval\" ->\ndeploy:\"Deploy\"\n```\n\n**Example - Production Deployment**:\n```flow\ngeneral-purpose:\"Build production artifacts\":build ->\n[general-purpose:\"Run integration tests\":tests || $security-scanner:\"Security scan\":scan] ->\n@tech-review:\"Review {build}, {tests}, {scan}. Technical approval?\" ->\n@product-review:\"Product approval for release?\" ->\ngeneral-purpose:\"Deploy to production\"\n```\n\n## Test-Driven Development Pattern\n\n**When to use**: Implementing new features with TDD methodology.\n\n```flow\n# RED\nwrite-test:\"Write failing test\":test ->\nverify-fails:\"Run test, verify it fails\":status ->\n\n# GREEN\nimplement:\"Write minimal code\":code ->\nverify-passes:\"Run test, verify it passes\":status ->\n\n# REFACTOR\nrefactor:\"Improve code quality\":improved ->\nverify-still-passes:\"Ensure tests still pass\"\n```\n\n**Complete TDD Example**:\n```flow\nimplementation-architect:\"Analyze requirements and plan testable units\":spec ->\n\nexpert-code-implementer:\"Write comprehensive test suite (must fail)\":tests ->\ngeneral-purpose:\"Run tests, verify they fail as expected\":test_status ->\n\n@review-test-coverage ->\n\nexpert-code-implementer:\"Write minimal code to pass tests\":implementation ->\ngeneral-purpose:\"Run tests, verify they now pass\":validation ->\n\n@review-implementation ->\n\n[\n  code-optimizer:\"Refactor for quality\":refactored ||\n  expert-code-implementer:\"Add documentation\":docs\n] ->\n\ngeneral-purpose:\"Final test run, ensure nothing broke\":final_validation ->\ngeneral-purpose:\"Commit changes with both tests and implementation\"\n```\n\n## Investigation & Debugging Pattern\n\n**When to use**: Diagnosing and fixing issues systematically.\n\n```flow\n# Reproduce\nreproduce:\"Document issue\" ->\n\n# Investigate (parallel)\n[investigate-code || analyze-logs || check-environment] ->\n\n# Diagnose\ndiagnose:\"Identify root cause\" ->\n@review-root-cause ->\n\n# Fix\nwrite-regression-test:\"Test that reproduces bug\" ->\nimplement-fix:\"Apply fix\" ->\n\n# Verify (parallel)\n[test-regression || test-suite || manual-test] ->\n\n# Complete\n@review-fix ->\ndocument:\"Update docs and commit\"\n```\n\n**Complete Debug Example**:\n```flow\ngeneral-purpose:\"Reproduce issue, capture error details\":issue_details ->\n\n[\n  Explore:\"Search for error in codebase\":code_analysis ||\n  general-purpose:\"Analyze logs and stack traces\":log_analysis ||\n  general-purpose:\"Check configs and environment\":env_analysis\n] ->\n\ngeneral-purpose:\"Synthesize findings, identify root cause\":root_cause ->\n\n@review-root-cause ->\n\nexpert-code-implementer:\"Write regression test (should fail)\":regression_test ->\nexpert-code-implementer:\"Implement targeted fix\":fix ->\n\n[\n  general-purpose:\"Run regression test (should pass)\":regression_passed ||\n  general-purpose:\"Run full test suite (all should pass)\":suite_passed ||\n  general-purpose:\"Manual verification of fix\":manual_verified\n] ->\n\n@review-fix ->\n\nexpert-code-implementer:\"Update docs, add fix notes\":docs_updated ->\ngeneral-purpose:\"Commit fix and test with descriptive message\"\n```\n\n## Data Processing Pattern\n\n**When to use**: Multi-stage data transformation.\n\n```flow\nfetch:\"Get data\" ->\nvalidate:\"Check data quality\" ->\ntransform:\"Process data\" ->\nanalyze:\"Extract insights\" ->\nreport:\"Generate report\"\n```\n\n**Example - News Aggregation**:\n```flow\n[\n  $rss-fetcher:\"Fetch from RSS feeds\":rss_articles ||\n  $web-scraper:\"Scrape news sites\":scraped_articles\n] ->\n\ngeneral-purpose:\"Merge and deduplicate {rss_articles} and {scraped_articles}\":all_articles ->\n\n$news-deduplicator:\"Remove duplicate articles from {all_articles}\":unique_articles ->\n\n$topic-clusterer:\"Group {unique_articles} by topic\":clustered ->\n\n$graph-builder:\"Create visualization of {clustered}\":graph ->\n\ngeneral-purpose:\"Generate summary report with {graph}\"\n```\n\n## Composite Patterns\n\n### Sequential with Parallel Sections\n\n**When to use**: Some stages must be sequential, but within stages tasks can be parallel.\n\n```flow\nsetup:\"Initial setup\" ->\n\n[parallel-work-1 || parallel-work-2 || parallel-work-3] ->\n\nintegration:\"Integrate results\" ->\n\n[parallel-validation-1 || parallel-validation-2] ->\n\nfinalize:\"Complete\"\n```\n\n**Example - Full CI/CD Pipeline**:\n```flow\ngeneral-purpose:\"Checkout code and install dependencies\":setup ->\n\n[\n  general-purpose:\"Run linter\":lint_results ||\n  general-purpose:\"Run type checker\":type_results ||\n  general-purpose:\"Run unit tests\":unit_results\n] ->\n\ngeneral-purpose:\"Build application if all checks pass\":build ->\n\n[\n  general-purpose:\"Run integration tests\":integration_results ||\n  $security-scanner:\"Security audit\":security_results ||\n  general-purpose:\"Performance benchmarks\":perf_results\n] ->\n\n@deployment-approval:\"Review all results. Approve deployment?\" ->\n\ngeneral-purpose:\"Deploy to staging\":staging ->\ngeneral-purpose:\"Run smoke tests on staging\":smoke_results ->\n\n@production-approval:\"Approve production deployment?\" ->\n\ngeneral-purpose:\"Deploy to production\"\n```\n\n### Conditional Parallel Execution\n\n**When to use**: Parallel execution depends on condition.\n\n```flow\ncheck:\"Evaluate\" ->\n(if condition)~> [parallel-a || parallel-b] -> merge ~>\n(if !condition)~> sequential:\"Do this\"\n```\n\n**Example - Adaptive Testing**:\n```flow\nExplore:\"Analyze changes\":changes ->\n\n(if changes.affects_api)~> [\n  general-purpose:\"Run API tests\":api_tests ||\n  general-purpose:\"Run integration tests\":integration_tests ||\n  general-purpose:\"Update API docs\":api_docs\n] -> general-purpose:\"Consolidate API test results\" ~>\n\n(if changes.affects_ui)~> [\n  general-purpose:\"Run UI tests\":ui_tests ||\n  general-purpose:\"Visual regression tests\":visual_tests ||\n  general-purpose:\"Accessibility tests\":a11y_tests\n] -> general-purpose:\"Consolidate UI test results\" ~>\n\n(if changes.affects_database)~> general-purpose:\"Run database migration tests\":db_tests ->\n\ngeneral-purpose:\"Create comprehensive test report\"\n```\n\n## Anti-Patterns to Avoid\n\n### ‚ùå Too Linear When Parallelization Possible\n\n**Don't do this**:\n```flow\ntask1 -> task2 -> task3 -> task4\n# When task1-4 are independent\n```\n\n**Do this instead**:\n```flow\n[task1 || task2 || task3 || task4] ->\nconsolidate:\"Merge results\"\n```\n\n### ‚ùå No Error Handling\n\n**Don't do this**:\n```flow\ndeploy:\"Deploy\" -> test:\"Test\"\n# What if deployment fails?\n```\n\n**Do this instead**:\n```flow\ndeploy:\"Deploy\":result ->\n(if result.failed)~> rollback:\"Rollback\" ~>\n(if result.success)~> test:\"Test\"\n```\n\n### ‚ùå Missing Review Checkpoints\n\n**Don't do this**:\n```flow\nimplement -> deploy\n# No human verification\n```\n\n**Do this instead**:\n```flow\nimplement ->\n@review:\"Review changes\" ->\ndeploy\n```\n\n### ‚ùå Overly Complex Single-Step\n\n**Don't do this**:\n```flow\ngeneral-purpose:\"Analyze code, find bugs, fix them, test fixes, deploy\"\n# Too much in one step\n```\n\n**Do this instead**:\n```flow\nExplore:\"Analyze code\":bugs ->\nimplement:\"Fix {bugs}\":fixes ->\ngeneral-purpose:\"Test {fixes}\":results ->\n(if results.passed)~> deploy:\"Deploy\"\n```\n\n## Pattern Selection Guide\n\n| Goal | Pattern | Example |\n|------|---------|---------|\n| Steps depend on each other | Sequential | plan ‚Üí implement ‚Üí test |\n| Independent tasks | Parallel | [test-linux \\|\\| test-mac \\|\\| test-win] |\n| Need human decision | Checkpoint | work ‚Üí @review ‚Üí continue |\n| Handle failures | Conditional | try ‚Üí (if failed)~> retry |\n| Prevent bugs | TDD | write-test ‚Üí implement ‚Üí refactor |\n| Fix issues | Debug | reproduce ‚Üí investigate ‚Üí fix ‚Üí verify |\n| Quality assurance | Multi-stage review | work ‚Üí @tech-review ‚Üí @security-review |\n| Data pipeline | Sequential transform | fetch ‚Üí validate ‚Üí transform ‚Üí analyze |\n| Fast feedback | Parallel validation | [lint \\|\\| test \\|\\| type-check] |\n| Adaptive behavior | Conditional parallel | if(api-change)~> [api-tests \\|\\| docs] |\n\n## Combining Patterns\n\nYou can nest and combine patterns:\n\n```flow\n# TDD + Parallel Testing + Review\nwrite-test ->\nimplement ->\n[unit-tests || integration-tests || e2e-tests] ->\n@review ->\nrefactor ->\n[unit-tests || integration-tests] ->\ncommit\n```\n\n```flow\n# Investigation + Conditional + Parallel\nreproduce ->\n[investigate-code || analyze-logs] ->\ndiagnose ->\n(if simple-fix)~> quick-fix ->\n(if complex-fix)~> [plan || write-test || implement] -> verify\n```\n\n---\n\n**Not finding the right pattern? Describe your use case and I'll help design a custom workflow!**\n",
        "skills/creating-workflows/socratic-method.md": "# Socratic Questioning Method\n\nThis document describes how I use strategic questioning to understand your workflow needs.\n\n## Philosophy\n\nRather than making assumptions, I ask targeted questions to:\n- Understand your true intent\n- Identify the right pattern\n- Uncover edge cases\n- Ensure the workflow fits your needs\n\n## Question Strategy by Request Type\n\n### Vague Requests\n\n**Example**: \"I need a workflow for my project\"\n\n**Strategy**: Problem ‚Üí Scope ‚Üí Constraints ‚Üí Pattern\n\n1. **Problem identification**\n   - \"What problem are you solving?\"\n   - Options: Consistency, Quality gates, Speed, Collaboration\n\n2. **Scope clarification**\n   - \"What's the scope of this workflow?\"\n   - Options: Single feature, Multiple features, Entire project, Specific task\n\n3. **Constraint exploration**\n   - \"Any constraints or requirements?\"\n   - Options: Must be fast, Must have approval, Must handle errors, Must be reversible\n\n4. **Pattern suggestion**\n   - Based on answers, suggest pattern\n   - Confirm fit or adjust\n\n### Specific Requests\n\n**Example**: \"Create a workflow that scans for security issues, reviews them, and fixes critical ones\"\n\n**Strategy**: Pattern confirmation ‚Üí Customization ‚Üí Validation\n\n1. **Pattern confirmation**\n   - \"This sounds like: scan ‚Üí review ‚Üí fix. Does that fit?\"\n   - Options: Yes, Similar but different, No\n\n2. **Customization questions**\n   - \"Should review be automatic or manual?\"\n   - \"What counts as critical?\"\n   - \"Should fixes be auto-applied or require approval?\"\n\n3. **Validation**\n   - Show proposed workflow\n   - Ask for confirmation or adjustments\n\n### Medium Specificity Requests\n\n**Example**: \"I want to automate testing and deployment\"\n\n**Strategy**: Scope ‚Üí Details ‚Üí Connection\n\n1. **Scope clarification**\n   - \"What should be tested?\"\n   - Options: Unit tests only, Integration tests, All tests, Specific test suites\n\n2. **Detail exploration**\n   - \"What happens if tests fail?\"\n   - \"Should deployment require approval?\"\n   - \"Any pre-deployment checks?\"\n\n3. **Connection questions**\n   - \"How are testing and deployment connected?\"\n   - \"Sequential or conditional?\"\n\n## Question Patterns\n\n### Problem Type Questions (Single-select)\n\nUsed to understand the core problem.\n\n```\nQuestion: \"What problem are you solving?\"\nOptions:\n- Consistency: Ensure consistent process execution\n- Quality gates: Add validation checkpoints\n- Speed: Parallelize independent tasks\n- Collaboration: Add review/approval steps\n```\n\n### Feature Selection (Multi-select)\n\nUsed to gather feature requirements.\n\n```\nQuestion: \"What features should this workflow have?\"\nOptions:\n- Retry logic: Retry failed operations\n- Checkpoints: Manual approval points\n- Parallel execution: Run tasks simultaneously\n- Error rollback: Rollback on failure\n```\n\n### Pattern Confirmation (Single-select)\n\nUsed to validate identified pattern.\n\n```\nQuestion: \"This sounds like [pattern name]. Does that fit?\"\nOptions:\n- Yes: Use this pattern as-is\n- Similar but different: Customize it\n- No: Different pattern needed\n```\n\n### Customization Questions (Varies)\n\nUsed to refine details.\n\n```\nQuestion: \"How should errors be handled?\"\nOptions:\n- Stop immediately: Fail fast\n- Continue with warnings: Best effort\n- Retry N times: Resilient\n- Ask user: Manual decision\n```\n\n## Workflow Requirements Building\n\nAs I ask questions, I build a WorkflowRequirements object:\n\n```javascript\n{\n  intent: \"User's goal in plain language\",\n  pattern: \"sequential|parallel|conditional|hybrid\",\n  agents: [\"agent1\", \"agent2\", \"agent3\"],\n  structure: \"Detailed structure description\",\n  errorHandling: [\"retry\", \"rollback\", \"continue\"],\n  checkpoints: [\"@review-point\", \"@approval-gate\"],\n  conditions: [\"if passed\", \"if critical\"],\n  guards: [\"require-clean-working-tree\"],\n  tools: [\"npm:test\", \"npm:build\"],\n  mcps: [\"supabase:execute_sql\"],\n  customSyntaxNeeded: [\"@custom-checkpoint\"]\n}\n```\n\n## Decision Tree\n\n```\nUser Request\n    ‚Üì\nIs it vague?\n    ‚îú‚îÄ Yes ‚Üí Ask problem question\n    ‚îÇ         ‚Üì\n    ‚îÇ       Ask scope question\n    ‚îÇ         ‚Üì\n    ‚îÇ       Ask constraints question\n    ‚îÇ         ‚Üì\n    ‚îÇ       Suggest pattern\n    ‚îÇ\n    ‚îî‚îÄ No ‚Üí Is it specific?\n            ‚îú‚îÄ Yes ‚Üí Identify pattern\n            ‚îÇ         ‚Üì\n            ‚îÇ       Confirm pattern\n            ‚îÇ         ‚Üì\n            ‚îÇ       Ask customization questions\n            ‚îÇ\n            ‚îî‚îÄ Medium ‚Üí Ask scope question\n                        ‚Üì\n                      Ask detail questions\n                        ‚Üì\n                      Ask connection questions\n                        ‚Üì\n                      Build workflow\n```\n\n## Question Limits\n\n- Ask minimum questions necessary\n- Group related questions together\n- Maximum 4 options per question\n- Maximum 4 questions at a time\n- Use multi-select when appropriate\n\n## Examples\n\n### Example 1: Vague Request\n\n**User**: \"I need automation\"\n\n**Question 1** (Problem):\n```\n\"What problem are you solving?\"\n- Consistency (Ensure repeatable process)\n- Quality (Add validation steps)\n- Speed (Parallelize work)\n- Collaboration (Add reviews)\n```\n\n**User selects**: Quality\n\n**Question 2** (Scope):\n```\n\"What needs quality checks?\"\n- Code changes (Review/test code)\n- Security (Scan for vulnerabilities)\n- Documentation (Verify docs)\n- Dependencies (Check for issues)\n```\n\n**User selects**: Code changes\n\n**Question 3** (Features):\n```\n\"What quality checks do you want?\"\n[Multi-select]\n- Linting (Code style)\n- Testing (Run test suite)\n- Type checking (Verify types)\n- Code review (Manual review)\n```\n\n**User selects**: Testing, Code review\n\n**Result**: Generate workflow:\n```flow\nimplement:\"Make changes\" ->\ngeneral-purpose:\"Run tests\":results ->\n@code-review:\"Review changes and {results}\" ->\n(if approved)~> commit:\"Commit and push\"\n```\n\n### Example 2: Specific Request\n\n**User**: \"Create workflow that explores codebase, implements feature, tests it, and creates PR\"\n\n**Question 1** (Confirmation):\n```\n\"This sounds like: explore ‚Üí implement ‚Üí test ‚Üí PR. Does that fit?\"\n- Yes (Use this flow)\n- Similar but different (Customize)\n- No (Different pattern)\n```\n\n**User selects**: Yes\n\n**Question 2** (Customization):\n```\n\"Any additional requirements?\"\n[Multi-select]\n- Code review before PR\n- Run linter\n- Update documentation\n- None\n```\n\n**User selects**: Code review before PR\n\n**Result**: Generate workflow:\n```flow\nExplore:\"Analyze codebase structure\":context ->\nimplementation-architect:\"Plan implementation using {context}\":plan ->\nexpert-code-implementer:\"Implement {plan}\":code ->\ngeneral-purpose:\"Run tests\":test_results ->\ncode-reviewer:\"Review {code} and {test_results}\":review ->\n(if review.approved)~> general-purpose:\"Create PR with summary\"\n```\n\n### Example 3: Medium Request\n\n**User**: \"I want to automate deployment with checks\"\n\n**Question 1** (Scope):\n```\n\"What checks before deployment?\"\n[Multi-select]\n- Tests pass\n- Build succeeds\n- Security scan clean\n- Manual approval\n```\n\n**User selects**: Tests pass, Security scan clean, Manual approval\n\n**Question 2** (Details):\n```\n\"Should checks run in parallel or sequential?\"\n- Parallel (Faster, all at once)\n- Sequential (Ordered, one by one)\n```\n\n**User selects**: Parallel\n\n**Result**: Generate workflow:\n```flow\n[general-purpose:\"Run test suite\":tests || $security-scanner:\"Scan for vulnerabilities\":scan] ->\ngeneral-purpose:\"Consolidate {tests} and {scan}\":report ->\n@deployment-approval:\"Review {report}. Approve deployment?\" ->\n(if approved)~> general-purpose:\"Deploy to production\":deployment\n```\n\n## Tips for Effective Questioning\n\n1. **Start broad, then narrow**: General questions first, specific details later\n2. **Group related questions**: Ask about related features together\n3. **Confirm understanding**: Repeat back what you heard\n4. **Offer alternatives**: Present options, don't assume\n5. **Progressive refinement**: Start with basic workflow, add complexity\n\n## When to Stop Asking\n\nStop asking questions when:\n- You have enough info to generate a complete workflow\n- User explicitly asks you to proceed\n- You've asked 3-4 rounds of questions\n- Pattern is clear and confirmed\n\nRemember: Better to ask one more clarifying question than generate wrong workflow.\n",
        "skills/creating-workflows/temp-agents.md": "# Temp Agents Guide\n\nTemp agents are ephemeral, workflow-specific agents that I create automatically when you need specialized functionality.\n\n## What Are Temp Agents?\n\n**Temp agents** are custom agents created for specific workflows:\n- Stored in `temp-agents/` directory\n- Automatically cleaned up after workflow execution\n- Can be promoted to permanent agents if useful\n- Namespaced with `orchestration:` prefix\n\n## When I Create Temp Agents\n\nI create temp agents when your workflow needs:\n\n1. **Domain-Specific Expertise**\n   - Security scanning\n   - Performance analysis\n   - Data processing\n   - Content generation\n\n2. **Specific Output Formats**\n   - Structured JSON reports\n   - Formatted markdown\n   - Standardized data schemas\n\n3. **Tool-Specific Operations**\n   - Complex grep patterns\n   - Multi-file analysis\n   - Specialized transformations\n\n4. **Reusable Logic**\n   - Common validation patterns\n   - Standard processing steps\n   - Consistent formatting\n\n## Temp Agent Structure\n\nEach temp agent is a markdown file with:\n\n```markdown\n---\nname: agent-name\ndescription: One-line description\ncreated: 2025-01-08\n---\n\n# Agent prompt with detailed instructions\n\nResponsibilities:\n1. Specific task 1\n2. Specific task 2\n\nOutput format:\n[Expected format description]\n\nTools to use:\n- Read: [When to use]\n- Grep: [When to use]\n```\n\n## Examples\n\n### Example 1: Security Scanner\n\n```markdown\n---\nname: security-scanner\ndescription: Scans codebase for security vulnerabilities\ncreated: 2025-01-08\n---\n\nYou are a security-focused code analyzer specializing in identifying vulnerabilities.\n\nYour responsibilities:\n1. Scan all source files for OWASP Top 10 issues\n2. Check for: SQL injection, XSS, CSRF, auth flaws, data exposure\n3. Analyze dependencies for known CVEs\n4. Review authentication and authorization implementations\n\nOutput format:\nJSON array with entries:\n{\n  \"file\": \"path/to/file.js\",\n  \"line\": 42,\n  \"severity\": \"critical|high|medium|low\",\n  \"type\": \"sql-injection\",\n  \"description\": \"User input directly in SQL query\",\n  \"recommendation\": \"Use parameterized queries\"\n}\n\nUse these tools:\n- Grep: Search for vulnerable patterns (e.g., grep \"eval\\\\(\" for eval usage)\n- Read: Examine suspicious files in detail\n- Glob: Find all files of specific types (e.g., \"**/*.js\")\n- WebSearch: Check CVE databases for dependency vulnerabilities\n\nPrioritize by severity. Focus on actionable findings.\n```\n\n**Usage in workflow**:\n```flow\n$security-scanner:\"Scan codebase\":vulnerabilities ->\ngeneral-purpose:\"Analyze {vulnerabilities}, prioritize critical\":priority ->\n@security-review:\"Review {priority}. Approve if acceptable?\" ->\n(if approved)~> continue:\"Proceed\"\n```\n\n### Example 2: API Documentation Generator\n\n```markdown\n---\nname: api-doc-generator\ndescription: Generates comprehensive API documentation from code\ncreated: 2025-01-08\n---\n\nYou are an API documentation specialist.\n\nYour responsibilities:\n1. Find all API endpoints in the codebase\n2. Extract route definitions, methods, parameters\n3. Generate OpenAPI/Swagger documentation\n4. Create usage examples for each endpoint\n\nOutput format:\nOpenAPI 3.0 YAML specification with:\n- All endpoints documented\n- Request/response schemas\n- Authentication requirements\n- Example requests and responses\n\nUse these tools:\n- Glob: Find API route files (e.g., \"**/*routes*.{js,ts}\")\n- Read: Parse route definitions\n- Grep: Search for endpoint patterns (@app.get, @app.post, etc.)\n\nInclude edge cases and error responses in documentation.\n```\n\n**Usage in workflow**:\n```flow\n$api-doc-generator:\"Generate API docs\":api_docs ->\nexpert-code-implementer:\"Format {api_docs} as README\":formatted_docs ->\n@review-docs:\"Review {formatted_docs}. Approve?\" ->\nexpert-code-implementer:\"Save to docs/API.md\"\n```\n\n### Example 3: Performance Profiler\n\n```markdown\n---\nname: performance-profiler\ndescription: Analyzes code for performance bottlenecks\ncreated: 2025-01-08\n---\n\nYou are a performance optimization specialist.\n\nYour responsibilities:\n1. Identify inefficient algorithms (O(n¬≤) or worse)\n2. Find unnecessary loops and redundant operations\n3. Detect memory leaks and excessive allocations\n4. Check for blocking I/O operations\n5. Analyze database query efficiency\n\nOutput format:\nMarkdown report with sections:\n\n## Critical Issues (P0)\n- Issue description\n- Location (file:line)\n- Current complexity\n- Recommendation\n\n## Optimizations (P1)\n[Same format]\n\n## Nice-to-Have (P2)\n[Same format]\n\nUse these tools:\n- Grep: Search for patterns like nested loops, .forEach().map()\n- Read: Analyze algorithm complexity\n- Glob: Find all source files for analysis\n\nFocus on issues with measurable impact. Provide concrete optimization suggestions.\n```\n\n**Usage in workflow**:\n```flow\n$performance-profiler:\"Analyze codebase\":perf_issues ->\n(if perf_issues.critical)~> @urgent-review:\"Critical performance issues found!\" ->\n                            code-optimizer:\"Fix critical {perf_issues}\":fixes ~>\n(if perf_issues.none)~> continue:\"No critical issues\"\n```\n\n### Example 4: Data Validator\n\n```markdown\n---\nname: data-validator\ndescription: Validates data against schema and business rules\ncreated: 2025-01-08\n---\n\nYou are a data validation specialist.\n\nYour responsibilities:\n1. Check data against provided JSON schema\n2. Validate business rules (e.g., dates in range, IDs exist)\n3. Identify missing required fields\n4. Check data types and formats\n5. Verify referential integrity\n\nOutput format:\nJSON report:\n{\n  \"valid\": true|false,\n  \"errors\": [\n    {\n      \"field\": \"user.email\",\n      \"error\": \"Invalid email format\",\n      \"value\": \"bad-email\",\n      \"rule\": \"Must match email regex\"\n    }\n  ],\n  \"warnings\": [...],\n  \"summary\": {\n    \"total_records\": 100,\n    \"valid_records\": 95,\n    \"error_count\": 5\n  }\n}\n\nUse these tools:\n- Read: Load data file and schema\n- Grep: Search for validation rule definitions\n\nReturn detailed error information for debugging.\n```\n\n**Usage in workflow**:\n```flow\ngeneral-purpose:\"Load data file\":data ->\n$data-validator:\"Validate {data} against schema\":validation ->\n(if validation.valid)~> process:\"Process data\" ~>\n(if validation.errors)~> @data-review:\"Review errors: {validation.errors}\" ->\n                         general-purpose:\"Fix data issues\" ->\n                         $data-validator:\"Re-validate\"\n```\n\n## Temp Agent Best Practices\n\n### DO:\n\n‚úÖ **Be specific about responsibilities**\n- List exactly what the agent should do\n- Include edge cases\n\n‚úÖ **Define clear output formats**\n- Specify JSON structure, markdown format, etc.\n- Include examples\n\n‚úÖ **Recommend appropriate tools**\n- List which Claude Code tools to use\n- Explain when to use each\n\n‚úÖ **Include quality criteria**\n- What makes output complete?\n- What level of detail is expected?\n\n‚úÖ **Handle edge cases**\n- What if input is invalid?\n- What if operation fails?\n\n### DON'T:\n\n‚ùå **Create for simple tasks**\n- Don't create temp agent for \"list files\"\n- Use general-purpose for simple operations\n\n‚ùå **Make too generic**\n- \"Do analysis\" is too vague\n- Be specific about what to analyze and how\n\n‚ùå **Forget error handling**\n- Always specify what to do if operation fails\n- Include validation steps\n\n‚ùå **Skip tool recommendations**\n- Agents work better when you suggest tools\n- Explain why each tool is useful\n\n## Workflow Integration\n\n### Defining Temp Agents in Workflow\n\nThere are two ways to use temp agents:\n\n**1. Reference existing temp agent**:\n```flow\n$security-scanner:\"Scan for vulnerabilities\":results\n```\n\n**2. Define inline** (I'll create the file):\n```flow\n# I'll create temp-agents/security-scanner.md during workflow execution\n$security-scanner:\"Scan for vulnerabilities\":results\n```\n\n### Variable Passing to Temp Agents\n\nPass data to temp agents using variable syntax:\n\n```flow\nExplore:\"Find API routes\":routes ->\n$api-doc-generator:\"Document {routes}\":docs\n```\n\nThe `{routes}` variable is automatically injected into the agent's prompt.\n\n### Error Handling with Temp Agents\n\n```flow\n$data-processor:\"Process data\":result ->\n(if result.failed)~> @error-review:\"Processing failed. Manual intervention?\" ->\n                     general-purpose:\"Fix data issues\" ->\n                     $data-processor:\"Retry processing\" ~>\n(if result.success)~> continue:\"Proceed\"\n```\n\n## Agent Promotion\n\nAfter workflow execution, I'll ask if you want to save temp agents:\n\n```\nWorkflow complete!\n\nTemp agents created:\n  - security-scanner\n  - performance-profiler\n\nWould you like to save any as permanent agents?\n```\n\n**If you save**, the agent moves to `agents/` directory and gets added to registry:\n- Available in all future workflows\n- No need to recreate\n- Can be updated and maintained\n\n**If you don't save**, the agent is deleted during cleanup:\n- Keeps plugin directory clean\n- Can recreate when needed\n\n## Temp Agent Lifecycle\n\n```\nWorkflow Design\n    ‚Üì\nI create temp-agents/agent-name.md\n    ‚Üì\nWorkflow Execution\n    ‚Üì\nAgent is used (with orchestration: namespace)\n    ‚Üì\nWorkflow Completes\n    ‚Üì\nAgent Promotion Prompt\n    ‚Üì\nUser chooses: Save or Discard\n    ‚Üì\nCleanup Phase\n    ‚Üì\nSaved: Moved to agents/\nDiscarded: Deleted\n```\n\n## Namespace Handling\n\nAll temp agents automatically get `orchestration:` prefix:\n\n**You write**:\n```flow\n$news-analyzer:\"Analyze news\"\n```\n\n**System executes**:\n```javascript\nTask({\n  subagent_type: \"orchestration:news-analyzer\",\n  prompt: /* loaded from temp-agents/news-analyzer.md */ + \"\\n\\n\" + \"Analyze news\"\n})\n```\n\nThis ensures no conflicts with built-in Claude Code agents.\n\n## Tips for Effective Temp Agents\n\n1. **Make prompts comprehensive** - Agent has no context beyond what you write\n2. **Include examples in prompt** - Shows agent what good output looks like\n3. **Specify tools explicitly** - Don't assume agent knows which tools to use\n4. **Define success criteria** - How does agent know when it's done?\n5. **Handle ambiguity** - What should agent do if input is unclear?\n\n## Common Use Cases\n\n| Use Case | Temp Agent | Benefits |\n|----------|-----------|----------|\n| Security audit | security-scanner | Consistent vulnerability checking |\n| Performance analysis | performance-profiler | Standardized bottleneck detection |\n| Data validation | data-validator | Schema compliance checking |\n| Documentation generation | doc-generator | Uniform doc format |\n| Code transformation | code-transformer | Repeatable refactoring patterns |\n| Test generation | test-generator | Comprehensive test coverage |\n| API client generation | client-generator | Consistent API wrappers |\n| Migration scripts | migration-helper | Safe data transformations |\n\n---\n\n**Want to see temp agents in action? Ask me to create a workflow that needs specialized functionality!**\n",
        "skills/debugging-workflows/SKILL.md": "---\nname: debugging-workflows\ndescription: Debug workflow execution issues including syntax errors, agent failures, variable problems, and execution errors. Use when workflows fail, produce unexpected results, or user asks for debugging help.\n---\n\n# Debugging Orchestration Workflows\n\nI help diagnose and fix workflow execution issues using systematic debugging techniques.\n\n## When I Activate\n\nI activate when you:\n- Experience workflow failures\n- Get syntax errors\n- Have agent execution issues\n- Variables not working as expected\n- Ask \"why isn't this working?\"\n\n## Common Issues\n\n### Syntax Errors\n\n**Problem**: Workflow won't parse\n\n**Symptoms**:\n- \"Unexpected token\" errors\n- \"Invalid syntax\" messages\n- Workflow won't start\n\n**Solutions**:\n1. Check operator syntax: `->`, `||`, `~>` (not `=>` or `&&`)\n2. Verify bracket matching: `[...]`\n3. Check quote matching: `\"instruction\"`\n4. Validate agent names (no typos)\n\n### Agent Not Found\n\n**Problem**: Agent reference doesn't resolve\n\n**Symptoms**:\n- \"Agent 'X' not found\"\n- Execution stops at agent invocation\n\n**Solutions**:\n1. Check spelling of agent name\n2. Verify temp agent file exists: `temp-agents/agent-name.md`\n3. Check defined agent in registry: `agents/registry.json`\n4. Ensure built-in agent name is correct\n\n### Variable Issues\n\n**Problem**: Variables not passing correctly\n\n**Symptoms**:\n- `{variable}` shows as literal text\n- \"Variable not found\" errors\n- Empty variable values\n\n**Solutions**:\n1. Verify capture syntax: `agent:\"task\":variable_name`\n2. Check interpolation: `\"Use {variable_name}\"`\n3. Ensure variable set before use\n4. Check variable name spelling\n\n### Parallel Execution Failures\n\n**Problem**: Parallel tasks failing or hanging\n\n**Symptoms**:\n- Only some parallel tasks complete\n- Workflow hangs at parallel section\n- Inconsistent results\n\n**Solutions**:\n1. Ensure tasks are independent (no shared state)\n2. Check syntax: `[task1 || task2 || task3]`\n3. Verify each task can run standalone\n4. Check for race conditions\n\n### Checkpoint Issues\n\n**Problem**: Checkpoints not triggering\n\n**Symptoms**:\n- Checkpoints skipped\n- No user prompt shown\n- Workflow continues without pause\n\n**Solutions**:\n1. Check checkpoint syntax: `@checkpoint-name`\n2. Verify not in auto-mode\n3. Ensure checkpoint is reachable in flow\n\n## Debugging Process\n\n### 1. Reproduce\n\nRun workflow with minimal changes to reproduce issue.\n\n### 2. Isolate\n\nSimplify workflow to find problematic section:\n\n```flow\n# If this fails:\nstep1 -> step2 -> step3 -> step4\n\n# Try:\nstep1 -> step2  # Works?\nstep3 -> step4  # Works?\n```\n\n### 3. Inspect\n\nCheck execution logs for error details.\n\n### 4. Fix\n\nApply targeted fix based on findings.\n\n### 5. Verify\n\nRun full workflow to ensure fix works.\n\n## Error Messages Guide\n\n| Error | Meaning | Fix |\n|-------|---------|-----|\n| \"Unexpected token\" | Syntax error | Check syntax around error location |\n| \"Agent not found\" | Missing agent | Verify agent exists and spelling |\n| \"Variable not found\" | Variable undefined | Check variable was captured |\n| \"Condition failed\" | Condition not met | Check condition logic |\n| \"Execution timeout\" | Task took too long | Add timeout handling or simplify task |\n\n## Best Practices\n\n‚úÖ **DO**:\n- Start with simple workflow, add complexity gradually\n- Test each section independently\n- Use meaningful variable names\n- Add error handling paths\n- Capture outputs for debugging\n\n‚ùå **DON'T**:\n- Create overly complex workflows initially\n- Skip testing individual steps\n- Use cryptic variable names\n- Ignore error messages\n- Remove error handling\n\n## Diagnostic Commands\n\n```bash\n# Check temp agents exist\nls temp-agents/\n\n# Verify agent registry\ncat agents/registry.json\n\n# Check workflow syntax file\ncat examples/workflow-name.flow\n```\n\n## Related Skills\n\n- **creating-workflows**: Create well-structured workflows\n- **executing-workflows**: Execute with better error visibility\n- **managing-agents**: Debug agent-related issues\n\n---\n\n**Workflow not working? Show me the error and I'll help debug!**\n",
        "skills/designing-syntax/SKILL.md": "---\nname: designing-syntax\ndescription: Design custom syntax elements with reuse-first approach for workflow orchestration. Use when user needs custom operators, checkpoints, or syntax patterns not available in core syntax.\n---\n\n# Designing Custom Workflow Syntax\n\nI design custom syntax elements following a reuse-first approach. Only create new syntax when existing patterns don't fit.\n\n## When I Activate\n\nI activate when you:\n- Need custom workflow operators\n- Want specialized checkpoints\n- Ask about extending syntax\n- Need domain-specific patterns\n- Say \"I need a custom syntax for...\"\n\n## Reuse-First Process\n\nBefore creating new syntax, I check:\n\n1. **Built-in syntax** - `->`, `||`, `~>`, `@`, `[...]`\n2. **Global syntax library** - `library/syntax/`\n3. **Template definitions** - Existing workflow definitions\n4. **Similar patterns** - Adaptable existing syntax\n\n**Only create new if no match exists.**\n\n## Syntax Types\n\n### Operators\n\nCustom flow control operators.\n\nExample: `=>` (merge with dedup)\n```markdown\n---\nsymbol: =>\ndescription: Merge with deduplication\n---\nExecutes left then right, removes duplicates from combined output.\n```\n\n### Actions\n\nReusable sub-workflows.\n\nExample: `@deep-review`\n```markdown\n---\nname: @deep-review\ntype: action\n---\nExpansion: [code-reviewer:\"security\" || code-reviewer:\"style\"] -> merge\n```\n\n### Checkpoints\n\nManual approval gates with prompts.\n\nExample: `@security-gate`\n```markdown\n---\nname: @security-gate\ntype: checkpoint\n---\nPrompt: Review security findings. Verify no critical vulnerabilities.\n```\n\n### Conditions\n\nCustom conditional logic.\n\nExample: `if security-critical`\n```markdown\n---\nname: if security-critical\ndescription: Check if changes affect security code\nevaluation: Modified files in: auth/, crypto/, permissions/\n---\n```\n\n### Loops\n\nReusable loop patterns.\n\nExample: `retry-with-backoff(n)`\n```markdown\n---\nname: retry-with-backoff\ntype: loop\nparams: [attempts]\n---\nPattern: @try -> operation -> (if failed)~> wait -> @try\n```\n\n## Design Principles\n\n1. **Intuitive** - Names/symbols hint at behavior\n2. **Composable** - Works with existing syntax\n3. **Self-documenting** - Clear from context\n4. **Minimal** - Only when truly needed\n\n## Best Practices\n\n‚úÖ **DO**:\n- Use descriptive names (`@security-gate` not `@check`)\n- Document behavior clearly\n- Provide examples\n- Keep composable\n\n‚ùå **DON'T**:\n- Create for one-time use\n- Make too specific\n- Hide too much complexity\n- Duplicate existing syntax\n\n## Library Structure\n\n```\nlibrary/syntax/\n‚îú‚îÄ‚îÄ operators/          # Flow control operators\n‚îú‚îÄ‚îÄ actions/            # Reusable sub-workflows\n‚îú‚îÄ‚îÄ checkpoints/        # Approval gates\n‚îú‚îÄ‚îÄ conditions/         # Custom conditionals\n‚îú‚îÄ‚îÄ loops/              # Loop patterns\n‚îú‚îÄ‚îÄ aggregators/        # Result combination\n‚îî‚îÄ‚îÄ guards/             # Pre-execution checks\n```\n\n## Related Skills\n\n- **creating-workflows**: Use custom syntax in workflows\n- **executing-workflows**: Execute workflows with custom syntax\n\n---\n\n**Need custom syntax? Describe the pattern you keep repeating!**\n",
        "skills/executing-workflows/SKILL.md": "---\nname: orchestration:executing-workflows\ndescription: Use when user provides workflow syntax with arrows (-> || ~>), says \"run workflow\", \"execute workflow\", \"run this\", mentions step1 -> step2 patterns. Executes orchestration workflows with real-time visualization, steering, and error recovery.\n---\n\n# Executing Orchestration Workflows\n\nI execute workflows with real-time visualization, progress tracking, and interactive steering at checkpoints.\n\n## When I Activate\n\nI automatically activate when you:\n- Provide workflow syntax to execute\n- Ask to \"run a workflow\"\n- Mention workflow execution\n- Want to execute a template\n- Ask \"how do I run this workflow?\"\n\n## Quick Start\n\nJust provide workflow syntax and I'll handle the rest:\n\n```flow\nExplore:\"Analyze codebase\":analysis ->\nimplement:\"Add feature based on {analysis}\":code ->\ngeneral-purpose:\"Run tests\":results\n```\n\nI automatically:\n1. Parse and validate syntax\n2. Show execution graph visualization\n3. Execute agents with progress updates\n4. Handle checkpoints and steering\n5. Manage errors gracefully\n6. Clean up temporary files\n\n## Execution Process\n\n### Phase 1: Parse & Validate\n\nI analyze your workflow:\n- Validate syntax correctness\n- Check agent references\n- Verify variable bindings\n- Identify checkpoints\n- Map execution graph\n\n### Phase 2: Visualize\n\nI show you the execution plan using ASCII art:\n\n```\nExecution Graph:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Explore         ‚îÇ\n‚îÇ (Analyze code)  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ\n         v\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ implement       ‚îÇ\n‚îÇ (Add feature)   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ\n         v\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ general-purpose ‚îÇ\n‚îÇ (Run tests)     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Phase 3: Execute\n\nI run agents sequentially or in parallel:\n\n**Sequential** (`->`):\n```\nRunning: Explore...  [In Progress]\nResult: ‚úì Analysis complete\nRunning: implement...  [In Progress]\nResult: ‚úì Feature added\n```\n\n**Parallel** (`||`):\n```\nRunning: task1...  [In Progress]\nRunning: task2...  [In Progress]\nRunning: task3...  [In Progress]\nAll complete! Merging results...\n```\n\n### Phase 4: Steering\n\nAt checkpoints (`@review`), you control flow:\n\n```\n@review-point reached\n\nOptions:\n  [C]ontinue - Proceed with workflow\n  [R]etry - Re-run previous step\n  [M]odify - Adjust and continue\n  [A]bort - Stop workflow\n\nYour choice?\n```\n\n### Phase 5: Error Recovery\n\nIf agent fails, I offer options:\n\n```\n‚ùå Agent 'implement' failed: Tests not passing\n\nOptions:\n  - Retry with same instruction\n  - Modify instruction and retry\n  - Skip this step (continue workflow)\n  - Abort workflow\n\nWhat would you like to do?\n```\n\n### Phase 6: Cleanup (MANDATORY)\n\n**CRITICAL:** After EVERY workflow execution, you MUST clean up temporary files!\n\n**Cleanup steps:**\n\n1. **Delete temp-scripts** - Remove all Python, JavaScript, shell scripts created during workflow\n   - Path: `${CLAUDE_PLUGIN_ROOT}/temp-scripts/`\n   - Delete ALL files (*.py, *.js, *.sh)\n\n2. **Delete temp-agents** - Remove temporary agent definitions (if not promoted)\n   - Path: `${CLAUDE_PLUGIN_ROOT}/temp-agents/`\n   - Delete all .md files\n\n3. **Delete temporary JSON** - Remove workflow state files\n   - Path: `${CLAUDE_PLUGIN_ROOT}/examples/`\n   - Delete *.json files only (keep .flow files!)\n\n4. **Report cleanup** - Tell user what was cleaned:\n   ```\n   üßπ Cleaned up 5 temporary files:\n   - temp-scripts/fetch_reddit.py\n   - temp-scripts/process_data.js\n   - temp-agents/scanner.md\n   - examples/workflow-state.json\n   ```\n\n5. **Verify cleanup** - Check that temp directories are empty\n\n**NEVER skip cleanup!** This prevents disk clutter and keeps plugin workspace clean.\n\n## Syntax Reference\n\nSee [syntax-reference.md](syntax-reference.md) for complete syntax documentation.\n\n**Quick reference**:\n\n| Syntax | Meaning | Example |\n|--------|---------|---------|\n| `->` | Sequential | `a -> b` |\n| `||` | Parallel | `[a \\|\\| b]` |\n| `~>` | Conditional | `(if passed)~> next` |\n| `@` | Checkpoint | `@review` |\n| `:var` | Output capture | `task:output` |\n| `{var}` | Variable interpolation | `\"Use {output}\"` |\n| `$agent` | Temp agent | `$scanner:\"Scan\"` |\n\n## Agent Types\n\n**Built-in Claude Code agents** (no prefix):\n- `Explore` - Fast codebase exploration and search\n- `Plan` - Planning and breaking down tasks\n- `general-purpose` - Versatile agent for complex multi-step tasks\n\n**Plugin agents** (orchestration: prefix):\n- `orchestration:workflow-socratic-designer` - Workflow creation via Socratic method\n- `orchestration:workflow-syntax-designer` - Custom syntax design\n\n**External agents** (registered via /orchestration:init):\n- Agents from `~/.claude/agents/` can be registered and used directly\n- Example: `expert-code-implementer`, `code-optimizer` (if registered)\n\n**Temp agents** ($name):\n- Created during workflow execution\n- Automatically cleaned up after workflow\n- Can be promoted to permanent agents if useful\n\n## Variable Passing\n\nSee [variables.md](variables.md) for advanced variable usage.\n\n**Capture output**:\n```flow\nExplore:\"Find routes\":routes ->\nanalyze:\"Check {routes}\":findings\n```\n\n**Conditional on variables**:\n```flow\ntest:\"Run tests\":results ->\n(if results.passed)~> deploy ->\n(if results.failed)~> debug\n```\n\n## Error Handling\n\nCommon error patterns:\n\n**Retry on failure**:\n```flow\n@attempt ->\noperation:\"Try task\" ->\n(if failed)~> wait:\"Wait 5s\" -> @attempt ~>\n(if passed)~> continue\n```\n\n**Fallback path**:\n```flow\nprimary:\"Try primary\" ->\n(if failed)~> backup:\"Use backup\" ~>\n(if passed)~> process\n```\n\n**Stop on critical error**:\n```flow\nsecurity-scan:\"Scan\" ->\n(if critical-issues)~> @emergency-stop -> abort ~>\n(if clean)~> deploy\n```\n\n## Checkpoints\n\nSee [checkpoints.md](checkpoints.md) for checkpoint details.\n\n**Basic checkpoint**:\n```flow\nimplement -> @review -> deploy\n```\n\n**Labeled checkpoint**:\n```flow\n@quality-gate:\"Review code quality. Approve?\"\n```\n\n**Conditional checkpoint**:\n```flow\n(if security-critical)~> @security-review\n```\n\n## Parallel Execution\n\nSee [parallel.md](parallel.md) for parallel execution patterns.\n\n**Basic parallel**:\n```flow\n[task1 || task2 || task3] -> merge\n```\n\n**Parallel with individual variables**:\n```flow\n[\n  task1:\"First\":result1 ||\n  task2:\"Second\":result2 ||\n  task3:\"Third\":result3\n] ->\ngeneral-purpose:\"Process {result1}, {result2}, {result3}\"\n```\n\n**Conditional parallel**:\n```flow\n(if needs-full-scan)~> [security || performance || style] ~>\n(if needs-quick-check)~> basic-lint\n```\n\n## Examples\n\nSee [examples/](examples/) for categorized workflow examples:\n\n- [sequential.md](examples/sequential.md) - Sequential workflows\n- [parallel.md](examples/parallel.md) - Parallel execution\n- [conditional.md](examples/conditional.md) - Conditional logic\n- [error-handling.md](examples/error-handling.md) - Error recovery\n- [checkpoints.md](examples/checkpoints.md) - Manual gates\n\n## Execution Modes\n\n**Normal mode** (default):\n- Full execution with all phases\n- Interactive checkpoints\n- Error recovery prompts\n\n**Dry-run mode**:\n- Parse and validate only\n- Show execution plan\n- No actual agent execution\n\n**Auto mode**:\n- Skip checkpoint prompts\n- Automatic error retry (up to 3 times)\n- Minimal user interaction\n\n## Progress Tracking\n\nDuring execution, I show:\n\n```\nWorkflow: TDD Implementation\nProgress: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 80%\n\nPhase 1: ‚úì Requirements analyzed\nPhase 2: ‚úì Tests written\nPhase 3: ‚úì Tests verified failing\nPhase 4: ‚è∏ Checkpoint: review-test-coverage\nPhase 5: ‚è≥ In Progress: Implementing code...\nPhase 6: ‚è∏ Pending\nPhase 7: ‚è∏ Pending\n```\n\n## Workflow Metadata\n\nTrack execution metadata:\n\n```\nWorkflow: debug-and-fix.flow\nStarted: 2025-01-08 14:32:10\nDuration: 5m 23s\nAgents used: 8\nCheckpoints: 2\nStatus: ‚úì Complete\n\nAgents executed:\n- Explore (√ó1)\n- general-purpose (√ó5)\n- expert-code-implementer (√ó2)\n\nResources:\n- Files read: 12\n- Files modified: 3\n- Tests run: 1\n```\n\n## Tips for Successful Execution\n\n1. **Start simple** - Test with small workflows first\n2. **Use checkpoints** - Add review points for critical steps\n3. **Capture outputs** - Use variables to pass data between agents\n4. **Handle errors** - Add fallback paths for critical operations\n5. **Monitor progress** - Watch execution visualization\n\n## Common Issues\n\n**Agent not found**:\n- Check agent name spelling\n- Verify temp agent exists in temp-agents/\n- Ensure namespace prefix for plugin agents\n\n**Variable not found**:\n- Verify variable was captured with `:varname`\n- Check variable name spelling in `{varname}`\n- Ensure variable set before use\n\n**Checkpoint skipped**:\n- Checkpoints only work in normal mode\n- Check checkpoint syntax: `@checkpoint-name`\n\n**Parallel execution failed**:\n- Ensure parallel tasks are independent\n- Check bracket syntax: `[a || b]`\n- Verify no shared state between parallel tasks\n\n## Related Skills\n\n- **creating-workflows**: Design and create workflows\n- **managing-agents**: Create and manage custom agents\n- **debugging-workflows**: Debug workflow issues\n- **using-templates**: Execute workflow templates\n\n## Commands\n\n- `/orchestration:run` - Execute workflow from file or inline\n- `/orchestration:template` - Execute saved template\n- `/orchestration:explain` - Explain workflow execution plan\n\n---\n\n**Ready to execute? Provide your workflow syntax or template name!**\n",
        "skills/executing-workflows/checkpoints.md": "# Checkpoints Guide\n\nManual approval gates that pause workflow execution for user review and decision-making.\n\n## What Are Checkpoints\n\nCheckpoints are explicit pause points in workflows where execution stops and waits for user approval before continuing. They serve as safety gates for critical operations, review points for quality assurance, and decision points for workflow branching.\n\n**Use Cases**:\n- Review generated code before committing\n- Approve deployments before execution\n- Verify test results before proceeding\n- Make decisions at workflow branching points\n- Confirm destructive operations\n- Validate AI-generated content\n\n## Basic Checkpoint Syntax\n\n### Simple Checkpoint\n```\n@checkpoint-name\n```\nUses the checkpoint name as the prompt text.\n\n### Checkpoint with Custom Prompt\n```\n@checkpoint-name:\"Custom prompt text for user\"\n```\nDisplays custom message to provide context about what's being reviewed.\n\n### Positioning in Workflows\n\nCheckpoints appear between workflow steps:\n\n```\nagent1~> \"First task\"\n@review-output:\"Review agent1 results before proceeding\"\nagent2~> \"Second task based on agent1\"\n@approval:\"Approve final changes\"\n(commit)~> \"git commit\"\n```\n\n## Checkpoint Behavior\n\n### When Checkpoint is Reached\n\n1. **Workflow Pauses**: Execution stops at the checkpoint\n2. **Prompt Displayed**: User sees the checkpoint message\n3. **Options Presented**: User chooses how to proceed\n\n### User Options\n\n- **Continue**: Proceed to next step (default action)\n- **Retry**: Re-run the previous step before checkpoint\n- **Modify**: Make changes to workflow or context\n- **Abort**: Stop workflow execution entirely\n\n### After User Choice\n\n- **Continue**: Next step executes immediately\n- **Retry**: Previous step re-executes, then returns to checkpoint\n- **Modify**: Workflow pauses for user input, then resumes\n- **Abort**: Workflow terminates with current state preserved\n\n## Common Checkpoint Types\n\n### Review Checkpoints\n\nFor examining outputs before proceeding:\n\n```\n@review:\"Review generated code\"\n@review-code:\"Check code quality and correctness\"\n@review-tests:\"Verify test coverage and results\"\n@review-docs:\"Review documentation for accuracy\"\n@review-changes:\"Examine all changes before commit\"\n```\n\n### Approval Gates\n\nFor authorizing critical operations:\n\n```\n@approval:\"Approve proceeding to next phase\"\n@security-approval:\"Security team approval required\"\n@deploy-approval:\"Authorize production deployment\"\n@merge-approval:\"Approve merging to main branch\"\n@budget-approval:\"Confirm resource allocation\"\n```\n\n### Decision Points\n\nFor workflow branching decisions:\n\n```\n@decide:\"Choose which path to take\"\n@choose-path:\"Select implementation approach\"\n@select-strategy:\"Pick optimization strategy\"\n@confirm-direction:\"Verify architectural direction\"\n```\n\n### Verification Checkpoints\n\nFor confirming states or conditions:\n\n```\n@verify:\"Verify system state before proceeding\"\n@confirm:\"Confirm operation parameters\"\n@validate:\"Validate input data\"\n@check-prerequisites:\"Ensure requirements are met\"\n```\n\n## Checkpoint Patterns\n\n### Pre-Deployment Gates\n\nMulti-stage approval before production:\n\n```\nagent1~> \"Run test suite\"\n@review-tests:\"Review test results - all passing?\"\n\nagent2~> \"Build production artifacts\"\n@verify-build:\"Verify build succeeded and artifacts are valid\"\n\nagent3~> \"Deploy to staging\"\n@staging-approval:\"Test in staging - approve prod deploy?\"\n\n(deploy-prod)~> \"Deploy to production\"\n```\n\n### Post-Test Reviews\n\nReview before committing changes:\n\n```\nagent1~> \"Implement feature\"\nagent2~> \"Write tests\"\nagent3~> \"Run test suite\"\n\n@review-implementation:\"Review code and test results\"\n\n(if approved)~> agent4~> \"Update docs\"\n@final-review:\"Final review before commit\"\n\n(commit)~> \"git commit and push\"\n```\n\n### Multi-Stage Approvals\n\nComplex workflows with multiple approval points:\n\n```\nagent1~> \"Design system architecture\"\n@architecture-approval:\"Approve architecture design\"\n\nagent2~> \"Implement core components\"\n@code-review:\"Review core implementation\"\n\nagent3~> \"Add security features\"\n@security-approval:\"Security team review\"\n\nagent4~> \"Performance optimization\"\n@performance-approval:\"Approve performance changes\"\n\n(deploy)~> \"Deploy to production\"\n```\n\n### Conditional Checkpoints\n\nCheckpoints that only trigger under certain conditions:\n\n```\nagent1~> \"Analyze code changes\"\n\n(if critical-path-changed)~> @security-review:\"Critical code changed - security review\"\n(if performance-impact)~> @performance-review:\"Performance impact detected\"\n(if breaking-change)~> @api-review:\"Breaking API change - stakeholder approval\"\n\nagent2~> \"Finalize changes\"\n```\n\n## Best Practices\n\n### When to Add Checkpoints\n\n**Always add checkpoints before**:\n- Irreversible operations (deployments, deletions, database migrations)\n- Production changes\n- Git commits and pushes\n- Security-related modifications\n- API changes that affect external users\n- Resource allocation or budget changes\n\n**Consider checkpoints for**:\n- Complex refactoring operations\n- AI-generated code that needs human review\n- Test results that may need interpretation\n- Documentation that represents the system\n- Configuration changes to critical systems\n\n### Naming Conventions\n\n**Good checkpoint names** (descriptive, purpose-based):\n```\n@review-security-changes\n@approve-database-migration\n@verify-backup-complete\n@confirm-deletion\n@review-api-contract\n```\n\n**Poor checkpoint names** (vague, generic):\n```\n@check\n@wait\n@pause\n@here\n@stop\n```\n\n### Checkpoint Frequency\n\n**Too Many Checkpoints**:\n```\nagent1~> \"Step 1\"\n@checkpoint1\nagent2~> \"Step 2\"\n@checkpoint2\nagent3~> \"Step 3\"\n@checkpoint3\n```\nResult: User fatigue, decreased attention to each checkpoint\n\n**Too Few Checkpoints**:\n```\nagent1~> \"Design, implement, test, and deploy\"\n@final-check\n(deploy-prod)\n```\nResult: No opportunity to catch issues early\n\n**Well-Balanced**:\n```\nagent1~> \"Design and implement feature\"\nagent2~> \"Write and run tests\"\n@review-implementation:\"Review code and tests\"\n\nagent3~> \"Build and deploy to staging\"\n@staging-verification:\"Test in staging environment\"\n\n(deploy-prod)~> \"Deploy to production\"\n```\nResult: Strategic checkpoints at natural workflow boundaries\n\n### Custom Prompts for Clarity\n\n**Provide context about what to review**:\n```\n@review:\"Review the following before proceeding:\n- Code follows style guidelines\n- Tests cover edge cases\n- Documentation is updated\n- No security vulnerabilities introduced\"\n```\n\n**Explain consequences of approval**:\n```\n@deploy-approval:\"Approving will:\n1. Deploy to production\n2. Notify users of new features\n3. Archive previous version\nProceed?\"\n```\n\n**Guide decision-making**:\n```\n@choose-implementation:\"Select approach:\nOption A: Fast but higher memory usage\nOption B: Slower but more memory efficient\nOption C: Balanced approach (recommended)\"\n```\n\n## Examples\n\n### Example 1: Feature Development with Reviews\n\n```\nworkflow: feature-with-reviews\n\nagent1~> \"Implement user authentication feature\"\nagent2~> \"Write unit and integration tests\"\nagent3~> \"Run complete test suite\"\n\n@review-code:\"Review implementation and test results:\n- Authentication logic secure?\n- Tests comprehensive?\n- Edge cases covered?\"\n\nagent4~> \"Update API documentation\"\nagent5~> \"Add user guide examples\"\n\n@review-docs:\"Review documentation for accuracy\"\n\n(commit)~> \"git add . && git commit -m 'Add user auth'\"\n```\n\n### Example 2: Database Migration\n\n```\nworkflow: safe-db-migration\n\nagent1~> \"Design database schema changes\"\n@schema-review:\"Review schema changes for:\n- Data integrity\n- Performance impact\n- Backward compatibility\"\n\nagent2~> \"Create migration scripts with rollback\"\nagent3~> \"Test migration on staging data\"\n\n@migration-test-review:\"Verify migration test results:\n- All data migrated correctly?\n- Performance acceptable?\n- Rollback tested?\"\n\nagent4~> \"Backup production database\"\n@backup-verify:\"Confirm backup completed successfully\"\n\nagent5~> \"Run migration on production\"\n@migration-complete:\"Verify production migration - check logs\"\n\n(notify)~> \"Send completion notification\"\n```\n\n### Example 3: Multi-Environment Deployment\n\n```\nworkflow: progressive-deployment\n\nagent1~> \"Build and test application\"\n@build-review:\"Review build artifacts and test results\"\n\nagent2~> \"Deploy to dev environment\"\nagent3~> \"Run smoke tests in dev\"\n\nagent4~> \"Deploy to staging\"\n@staging-approval:\"Test in staging - approve production deploy?\"\n\nagent5~> \"Deploy to production (canary 10%)\"\n@canary-check:\"Monitor canary metrics - proceed to full deploy?\"\n\nagent6~> \"Deploy to production (full 100%)\"\n@final-verification:\"Verify production deployment successful\"\n```\n\n### Example 4: Security-Focused Workflow\n\n```\nworkflow: security-hardening\n\nagent1~> \"Scan codebase for vulnerabilities\"\nagent2~> \"Analyze dependency security\"\n\n@security-findings:\"Review security scan results:\n- Critical vulnerabilities found?\n- Remediation plan clear?\n- Continue with fixes?\"\n\nagent3~> \"Apply security patches\"\nagent4~> \"Update dependencies to secure versions\"\n\n@verify-fixes:\"Verify all security issues resolved\"\n\nagent5~> \"Run security regression tests\"\n@security-approval:\"Security team final approval\"\n\n(commit)~> \"git commit -m 'Security hardening'\"\n(deploy)~> \"Deploy security updates\"\n```\n\n### Example 5: Content Generation Pipeline\n\n```\nworkflow: content-review-pipeline\n\nagent1~> \"Generate blog post content\"\n@content-review:\"Review AI-generated content for:\n- Accuracy and factual correctness\n- Tone and brand alignment\n- Technical accuracy\"\n\nagent2~> \"Optimize for SEO\"\nagent3~> \"Generate social media snippets\"\n\n@marketing-review:\"Review SEO and social content\"\n\nagent4~> \"Create images and graphics\"\n@visual-review:\"Review visual assets\"\n\nagent5~> \"Format and publish to CMS\"\n@final-preview:\"Preview in staging - approve publish?\"\n\n(publish)~> \"Publish to production\"\n```\n\n### Example 6: Data Processing with Quality Gates\n\n```\nworkflow: data-pipeline-with-checks\n\nagent1~> \"Extract data from sources\"\nagent2~> \"Validate data quality\"\n\n@data-quality-check:\"Review validation results:\n- Completeness: {{ completeness_pct }}%\n- Accuracy: {{ accuracy_score }}\n- Anomalies: {{ anomaly_count }}\nProceed with transformation?\"\n\nagent3~> \"Transform and normalize data\"\nagent4~> \"Run data quality checks\"\n\n@transformation-review:\"Verify transformation results\"\n\nagent5~> \"Load to data warehouse\"\n@load-verification:\"Confirm data loaded successfully:\n- Row count matches source\n- No duplicates\n- Indexes created\"\n\n(notify)~> \"Send pipeline completion report\"\n```\n\n### Example 7: Infrastructure Changes\n\n```\nworkflow: infrastructure-update\n\nagent1~> \"Plan infrastructure changes\"\nagent2~> \"Generate Terraform/IaC scripts\"\n\n@plan-review:\"Review infrastructure plan:\n- Resource changes appropriate?\n- Cost impact acceptable?\n- Security implications clear?\"\n\nagent3~> \"Apply changes to dev environment\"\n@dev-verification:\"Verify dev environment working correctly\"\n\nagent4~> \"Apply changes to staging\"\n@staging-verification:\"Test in staging - ready for production?\"\n\nagent5~> \"Create backup of current production state\"\n@backup-confirm:\"Backup complete - proceed with prod changes?\"\n\nagent6~> \"Apply changes to production\"\n@production-verification:\"Verify production infrastructure health\"\n\n(document)~> \"Update infrastructure documentation\"\n```\n\n## Tips\n\n### Checkpoint Limitations\n\n- **Only work in normal mode**: Checkpoints are ignored in auto-mode execution\n- **Cannot modify workflow structure**: User can modify context/files but not workflow definition\n- **No timeout**: Workflows wait indefinitely at checkpoints until user responds\n\n### Effective Checkpoint Usage\n\n- **Use before deployments**: Always checkpoint before production changes\n- **Add before commits**: Review code before committing to version control\n- **Gate destructive operations**: Checkpoint before deletes, drops, or irreversible changes\n- **Review AI outputs**: Checkpoint after AI-generated code or content\n- **Strategic placement**: Place at natural workflow boundaries (after logical phases)\n- **Informative prompts**: Always use custom prompts to explain what's being reviewed\n\n### Combining with Conditions\n\nCheckpoints work well with conditional execution:\n\n```\n(if high-risk)~> @security-review:\"High-risk changes detected\"\n(if tests-failed)~> @failure-analysis:\"Tests failed - review and decide\"\n(if breaking-change)~> @stakeholder-approval:\"Breaking change requires approval\"\n```\n\n### Emergency Abort\n\nAt any checkpoint, users can abort the workflow if:\n- Issues discovered that require significant rework\n- Requirements changed mid-execution\n- External dependencies unavailable\n- Critical errors detected\n\nAborting preserves current state, allowing resume or restart later.\n\n---\n\n**Key Takeaway**: Checkpoints transform automated workflows into collaborative processes, combining AI efficiency with human judgment at critical decision points.\n",
        "skills/executing-workflows/parallel.md": "# Parallel Execution Guide\n\nProgressive disclosure guide for parallel execution with the `||` operator in workflow orchestration.\n\n## Overview\n\nParallel execution allows multiple tasks to run simultaneously, significantly improving workflow performance when tasks are independent.\n\n**Benefits:**\n- **Speed**: Multiple agents execute concurrently instead of waiting sequentially\n- **Independence**: Tasks run without blocking each other\n- **Efficiency**: Optimal resource utilization for independent operations\n- **Scalability**: Handle multiple validations, tests, or analyses at once\n\n**Key Principle:** Parallel tasks must be independent - they cannot depend on each other's results or modify shared state.\n\n---\n\n## Basic Parallel Syntax\n\n### Simple Parallel Execution\n\nExecute multiple tasks simultaneously using the `||` operator:\n\n```flow\n[task1 || task2 || task3]\n```\n\n**Important:** Square brackets `[...]` are required to group parallel operations into a subgraph.\n\n### With Agents\n\nUse specific agents for parallel tasks:\n\n```flow\n[\n  Explore:\"Find authentication bugs\" ||\n  general-purpose:\"Run test suite\" ||\n  code-reviewer:\"Review security practices\"\n]\n```\n\n### Parallel Merge\n\nAll parallel branches complete before workflow continues:\n\n```flow\nstart -> [analyze || validate || test] -> merge-results -> deploy\n```\n\n**Execution flow:**\n1. `start` completes\n2. All three tasks (`analyze`, `validate`, `test`) launch simultaneously\n3. Workflow waits for all parallel tasks to complete\n4. `merge-results` executes with combined context\n5. `deploy` executes\n\n---\n\n## Variable Capture in Parallel\n\n### Individual Variable Capture\n\nEach parallel branch can capture its own output variable:\n\n```flow\n[\n  Explore:\"Find routes\":routes ||\n  Explore:\"Find middleware\":middleware ||\n  Explore:\"Find controllers\":controllers\n] ->\ngeneral-purpose:\"Analyze architecture using {routes}, {middleware}, {controllers}\"\n```\n\n**How it works:**\n1. Three parallel explorations execute simultaneously\n2. Each captures output to its own variable (`routes`, `middleware`, `controllers`)\n3. After all complete, the next step can reference all three variables\n4. Variables are interpolated into the instruction text\n\n### Using Captured Variables After Merge\n\nVariables from parallel branches are available in subsequent steps:\n\n```flow\n[\n  general-purpose:\"Run unit tests\":unit_results ||\n  general-purpose:\"Run integration tests\":integration_results ||\n  general-purpose:\"Run e2e tests\":e2e_results\n] ->\ngeneral-purpose:\"Generate test report combining {unit_results}, {integration_results}, {e2e_results}\" ->\n@review-test-results\n```\n\n### Referencing Parallel Results\n\nAccess individual results or combine them:\n\n```flow\n[\n  general-purpose:\"Security scan\":security_status ||\n  general-purpose:\"Performance benchmark\":performance_status ||\n  general-purpose:\"Code quality check\":quality_status\n] ->\n(if security_status)~> deploy ->\n(if !security_status)~> general-purpose:\"Address security issues from: {security_status}\"\n```\n\n---\n\n## Parallel Conditions\n\n### All Success Condition\n\nRequire all parallel branches to succeed:\n\n```flow\n[test || lint || security] (all success)~> deploy\n```\n\n**Semantics:**\n- All three tasks must complete successfully\n- If any task fails, the condition is false\n- Workflow continues to `deploy` only if all succeeded\n\n**Use case:** Quality gates where every check must pass\n\n### Any Success Condition\n\nProceed if at least one branch succeeds:\n\n```flow\n[primary-api || backup-api || fallback-api] (any success)~> process-data\n```\n\n**Semantics:**\n- At least one task must succeed\n- If all tasks fail, the condition is false\n- Workflow continues if any one succeeded\n\n**Use case:** Redundant data sources or fallback mechanisms\n\n### Specific Conditions After Parallel\n\nApply custom conditions to parallel results:\n\n```flow\n[\n  security-scan:\"Check vulnerabilities\":security ||\n  performance-test:\"Load testing\":performance\n] ->\n(if \"no critical issues\")~> deploy ->\n(if \"found critical issues\")~> @emergency-review\n```\n\n### Combining Parallel with Conditional Variables\n\n```flow\n[\n  test:\"Run tests\" (if passed):tests_ok ||\n  lint:\"Run linter\" (if passed):lint_ok ||\n  security:\"Security scan\" (if passed):security_ok\n]~>\n  (if tests_ok)~> (if lint_ok)~> (if security_ok)~> deploy ->\n  (if !tests_ok)~> debug-tests ->\n  (if !lint_ok)~> fix-lint ->\n  (if !security_ok)~> fix-security\n```\n\n---\n\n## Common Parallel Patterns\n\n### Multi-Platform Testing\n\nTest across different platforms simultaneously:\n\n```flow\n[\n  general-purpose:\"Run tests on Linux\":linux_test ||\n  general-purpose:\"Run tests on macOS\":mac_test ||\n  general-purpose:\"Run tests on Windows\":windows_test\n] (all success)~>\n  general-purpose:\"Generate cross-platform test report\"\n```\n\n### Parallel Validation\n\nRun multiple validation checks:\n\n```flow\nbuild ->\n[\n  general-purpose:\"Run unit tests\" ||\n  general-purpose:\"Run linter\" ||\n  general-purpose:\"Security vulnerability scan\" ||\n  general-purpose:\"Check documentation coverage\"\n] (all success)~> deploy\n```\n\n### Multi-Source Data Collection\n\nGather data from multiple sources in parallel:\n\n```flow\n[\n  Explore:\"Scan src/ for components\":components ||\n  Explore:\"Scan tests/ for test files\":tests ||\n  Explore:\"Scan docs/ for documentation\":docs ||\n  general-purpose:\"Read package.json dependencies\":deps\n] ->\nimplementation-architect:\"Create project architecture report using {components}, {tests}, {docs}, {deps}\"\n```\n\n### Parallel Investigation Paths\n\nInvestigate different aspects simultaneously:\n\n```flow\n[\n  Explore:\"Check recent commits for changes\":git_history ||\n  Explore:\"Search logs for error patterns\":log_analysis ||\n  Explore:\"Analyze configuration files\":config_review ||\n  general-purpose:\"Check environment variables\":env_check\n] ->\ngeneral-purpose:\"Synthesize findings from {git_history}, {log_analysis}, {config_review}, {env_check} to identify root cause\"\n```\n\n### Parallel Implementation with Review\n\nImplement multiple features, then review together:\n\n```flow\n[\n  expert-code-implementer:\"Implement authentication module\":auth_code ||\n  expert-code-implementer:\"Implement authorization module\":authz_code ||\n  expert-code-implementer:\"Implement session management\":session_code\n] ->\n@review-all-implementations ->\ncode-reviewer:\"Review {auth_code}, {authz_code}, {session_code} for security and consistency\"\n```\n\n### Parallel Refactoring\n\nRefactor multiple modules independently:\n\n```flow\n[\n  expert-code-implementer:\"Refactor user service\" ||\n  expert-code-implementer:\"Refactor auth service\" ||\n  expert-code-implementer:\"Refactor data service\"\n] ->\ngeneral-purpose:\"Run full integration test suite\" (if passed)~> commit\n```\n\n---\n\n## Requirements for Parallel Tasks\n\n### Tasks Must Be Independent\n\n**‚úì Good - Independent operations:**\n```flow\n[\n  Explore:\"Find all TODO comments\" ||\n  Explore:\"Find all FIXME comments\" ||\n  Explore:\"Find all deprecated code\"\n]\n```\n\n**‚úó Bad - Sequential dependency:**\n```flow\n[\n  general-purpose:\"Create user\" ||\n  general-purpose:\"Assign permissions to user\"  # Needs user from previous task!\n]\n```\n\n### No Dependencies Between Parallel Branches\n\nEach branch must be self-contained:\n\n**‚úì Good - Fully independent:**\n```flow\n[\n  general-purpose:\"Test authentication module\" ||\n  general-purpose:\"Test payment module\" ||\n  general-purpose:\"Test reporting module\"\n]\n```\n\n**‚úó Bad - Branch dependency:**\n```flow\n[\n  general-purpose:\"Create test database\":db ||\n  general-purpose:\"Run tests using {db}\"  # Can't reference db from parallel branch!\n]\n```\n\n### Read-Only Operations Are Safe\n\nParallel tasks can safely read the same files:\n\n**‚úì Safe - Multiple reads:**\n```flow\n[\n  Explore:\"Count lines in src/\" ||\n  Explore:\"Find patterns in src/\" ||\n  code-reviewer:\"Review code quality in src/\"\n]\n```\n\n### Avoid File Write Conflicts\n\nDon't write to the same files in parallel:\n\n**‚úó Dangerous - Write conflicts:**\n```flow\n[\n  general-purpose:\"Update config.json with feature A\" ||\n  general-purpose:\"Update config.json with feature B\"  # Race condition!\n]\n```\n\n**‚úì Safe - Different files:**\n```flow\n[\n  general-purpose:\"Update auth-config.json\" ||\n  general-purpose:\"Update db-config.json\" ||\n  general-purpose:\"Update api-config.json\"\n]\n```\n\n---\n\n## Error Handling in Parallel\n\n### Continue on Individual Failures\n\nBy default, parallel execution continues even if some branches fail:\n\n```flow\n[\n  general-purpose:\"Optional performance optimization\" ||\n  general-purpose:\"Optional documentation update\" ||\n  general-purpose:\"Optional style improvements\"\n] ->\ngeneral-purpose:\"Proceed with available improvements\"\n```\n\n**Behavior:**\n- All branches attempt to execute\n- Failures are logged but don't stop other branches\n- Next step receives context from all branches (including failures)\n\n### All-or-Nothing with `(all success)~>`\n\nRequire all branches to succeed:\n\n```flow\n[\n  general-purpose:\"Critical security validation\" ||\n  general-purpose:\"Critical data integrity check\" ||\n  general-purpose:\"Critical dependency verification\"\n] (all success)~> deploy ->\n(if failed)~> @rollback\n```\n\n**Behavior:**\n- All branches must complete successfully\n- If any fails, condition is false\n- Can route to error handling path\n\n### Partial Results Handling\n\nHandle mixed success/failure scenarios:\n\n```flow\n[\n  general-purpose:\"Primary data source\":primary ||\n  general-purpose:\"Secondary data source\":secondary ||\n  general-purpose:\"Tertiary data source\":tertiary\n] ->\ngeneral-purpose:\"Merge available data from: {primary} {secondary} {tertiary}\" ->\n(if \"sufficient data\")~> process ->\n(if \"insufficient data\")~> @data-collection-failed\n```\n\n### Retry Failed Branches\n\n```flow\n@parallel-attempt ->\n[\n  general-purpose:\"Flaky test suite\" ||\n  general-purpose:\"External API call\" ||\n  general-purpose:\"Network-dependent operation\"\n] (all success)~> continue ->\n(if failed)~> general-purpose:\"Wait 30 seconds\" -> @parallel-attempt\n```\n\n---\n\n## Best Practices\n\n### When to Use Parallel Execution\n\n**‚úì Use parallel when:**\n- Tasks are truly independent\n- No shared state or file modifications\n- Tasks can execute in any order\n- Read-only operations on same data\n- Speed improvement is valuable\n\n**Examples:**\n- Running different test suites\n- Scanning different directories\n- Validating different aspects\n- Gathering data from multiple sources\n- Multi-platform builds or tests\n\n### When NOT to Use Parallel\n\n**‚úó Avoid parallel when:**\n- Tasks have sequential dependencies\n- Tasks modify shared state\n- One task needs results from another\n- Tasks write to same files\n- Order of execution matters\n\n**Use sequential instead:**\n```flow\n# Bad (parallel with dependencies)\n[create-user || assign-permissions]\n\n# Good (sequential)\ncreate-user -> assign-permissions\n```\n\n### Optimal Number of Parallel Branches\n\n**Recommended:** 3-5 parallel branches per subgraph\n\n**‚úì Good - Manageable parallelism:**\n```flow\n[test || lint || security || docs]\n```\n\n**‚úó Problematic - Too many branches:**\n```flow\n[task1 || task2 || task3 || task4 || task5 || task6 || task7 || task8 || task9 || task10]\n```\n\n**Why limit branches:**\n- Easier to track and debug\n- Clearer visualization\n- Better resource management\n- More readable workflows\n\n**For many tasks, nest parallel groups:**\n```flow\n[\n  [frontend-test || backend-test] ||\n  [api-test || integration-test] ||\n  [security-scan || performance-test]\n] -> consolidate-results\n```\n\n### Design for Independence\n\nStructure tasks to be truly independent:\n\n**‚úì Good design:**\n```flow\n# Parallel data collection\n[\n  Explore:\"Scan authentication code\":auth_findings ||\n  Explore:\"Scan database code\":db_findings ||\n  Explore:\"Scan API code\":api_findings\n] ->\n# Sequential synthesis\ngeneral-purpose:\"Analyze {auth_findings}, {db_findings}, {api_findings}\"\n```\n\n### Use Descriptive Variable Names\n\nClear variable names help track parallel results:\n\n**‚úì Clear:**\n```flow\n[\n  scan:\"Frontend security\":frontend_security ||\n  scan:\"Backend security\":backend_security ||\n  scan:\"API security\":api_security\n]\n```\n\n**‚úó Unclear:**\n```flow\n[\n  scan:\"Frontend security\":s1 ||\n  scan:\"Backend security\":s2 ||\n  scan:\"API security\":s3\n]\n```\n\n### Add Checkpoints After Parallel\n\nReview parallel results before proceeding:\n\n```flow\n[\n  implement:\"Feature A\":feature_a ||\n  implement:\"Feature B\":feature_b ||\n  implement:\"Feature C\":feature_c\n] ->\n@review-implementations ->\ngeneral-purpose:\"Integration test all features\"\n```\n\n---\n\n## Performance Considerations\n\n### Actual Parallelism vs Sequential with Merge\n\n**How it works:**\n- Parallel branches execute simultaneously via separate agent invocations\n- Each branch runs in its own context\n- After all complete, results merge into shared context\n- Next step has access to all parallel outputs\n\n**Time savings example:**\n\nSequential:\n```flow\ntask1 (5 min) -> task2 (5 min) -> task3 (5 min)  # Total: 15 minutes\n```\n\nParallel:\n```flow\n[task1 (5 min) || task2 (5 min) || task3 (5 min)]  # Total: ~5 minutes\n```\n\n### Token Usage in Parallel Execution\n\n**Context passing:**\n- Each parallel branch receives the same input context\n- Each branch consumes tokens independently\n- Results combine for next step's context\n\n**Token efficiency:**\n```flow\n# Less efficient - sequential context growth\nstep1:output1 ->\nstep2:\"Process {output1}\":output2 ->\nstep3:\"Process {output1} {output2}\":output3\n# Context grows: output1 ‚Üí output1+output2 ‚Üí output1+output2+output3\n\n# More efficient - parallel then merge\n[\n  step1:output1 ||\n  step2:output2 ||\n  step3:output3\n] ->\nmerge:\"Process {output1}, {output2}, {output3}\"\n# Each branch independent, merge once at end\n```\n\n### Optimization Tips\n\n**Group related parallel tasks:**\n```flow\n# Optimization: group by stage\nbuild ->\n[unit-test || lint || type-check] ->\n[integration-test || e2e-test] ->\ndeploy\n```\n\n**Balance parallel branch complexity:**\n- Avoid one very slow branch with many fast branches\n- Try to keep parallel tasks similar in duration\n- Consider splitting slow tasks into parallel sub-tasks\n\n**Use parallel for I/O-bound tasks:**\n- File scanning across directories\n- External API calls\n- Database queries\n- Test execution\n\n---\n\n## Complete Examples\n\n### Example 1: Comprehensive Code Review\n\n```flow\n# Multi-aspect code review with parallel analysis\nExplore:\"Identify all modified files in last commit\":changed_files ->\n\n[\n  code-reviewer:\"Security review of {changed_files}\":security_review ||\n  code-reviewer:\"Performance analysis of {changed_files}\":performance_review ||\n  code-reviewer:\"Code style check of {changed_files}\":style_review ||\n  general-purpose:\"Check test coverage for {changed_files}\":coverage_review\n] ->\n\n@review-all-findings ->\n\ngeneral-purpose:\"Consolidate findings: {security_review}, {performance_review}, {style_review}, {coverage_review}\":consolidated_report (if \"critical issues\")~>\n  @block-merge ->\n  general-purpose:\"Create fix plan for critical issues\" ->\n(if \"no critical issues\")~>\n  general-purpose:\"Create optional improvement suggestions\"\n```\n\n### Example 2: Multi-Environment Deployment\n\n```flow\n# Build once, deploy to multiple environments in parallel\nimplementation-architect:\"Plan deployment strategy\":deploy_plan ->\nexpert-code-implementer:\"Build production artifacts\":artifacts ->\ngeneral-purpose:\"Run pre-deployment validation on {artifacts}\" (if passed)~>\n\n[\n  general-purpose:\"Deploy {artifacts} to staging\":staging_result ||\n  general-purpose:\"Deploy {artifacts} to qa\":qa_result ||\n  general-purpose:\"Deploy {artifacts} to demo\":demo_result\n] (all success)~>\n\n[\n  general-purpose:\"Run smoke tests on staging\" ||\n  general-purpose:\"Run smoke tests on qa\" ||\n  general-purpose:\"Run smoke tests on demo\"\n] (all success)~>\n\n@approve-production-deployment ->\ngeneral-purpose:\"Deploy {artifacts} to production\"\n```\n\n### Example 3: Parallel Bug Investigation\n\n```flow\n# Investigate bug from multiple angles simultaneously\ngeneral-purpose:\"Reproduce the reported bug\":reproduction_steps ->\n\n[\n  Explore:\"Search codebase for error message and related code\":code_investigation ||\n  general-purpose:\"Analyze error logs and stack traces\":log_analysis ||\n  general-purpose:\"Check configuration files and environment\":env_investigation ||\n  Explore:\"Review git history for recent changes to affected areas\":git_investigation\n] ->\n\ngeneral-purpose:\"Synthesize findings from {code_investigation}, {log_analysis}, {env_investigation}, {git_investigation} to identify root cause\":root_cause ->\n\n@review-root-cause ->\n\n[\n  expert-code-implementer:\"Write regression test for bug\":regression_test ||\n  expert-code-implementer:\"Implement fix based on {root_cause}\":bug_fix\n] ->\n\ngeneral-purpose:\"Verify {regression_test} fails with current code, passes with {bug_fix}\" (if passed)~>\n  @approve-fix ->\n  general-purpose:\"Commit fix and test together\"\n```\n\n### Example 4: Parallel Feature Implementation\n\n```flow\n# Implement multiple independent features in parallel\nimplementation-architect:\"Break down feature request into independent modules\":architecture ->\n\n[\n  expert-code-implementer:\"Implement user authentication module\":auth_impl ||\n  expert-code-implementer:\"Implement data validation module\":validation_impl ||\n  expert-code-implementer:\"Implement logging module\":logging_impl\n] ->\n\n[\n  general-purpose:\"Write tests for authentication: {auth_impl}\":auth_tests ||\n  general-purpose:\"Write tests for validation: {validation_impl}\":validation_tests ||\n  general-purpose:\"Write tests for logging: {logging_impl}\":logging_tests\n] ->\n\ngeneral-purpose:\"Run all tests: {auth_tests}, {validation_tests}, {logging_tests}\" (all success)~>\n  general-purpose:\"Integration test all modules together\" (if passed)~>\n    @final-review ->\n    general-purpose:\"Create commit with all modules and tests\"\n```\n\n### Example 5: Comprehensive Security Audit\n\n```flow\n# Multi-layered security audit with parallel scans\n[\n  Explore:\"Scan for authentication vulnerabilities\":auth_vulns ||\n  Explore:\"Scan for SQL injection risks\":sql_risks ||\n  Explore:\"Scan for XSS vulnerabilities\":xss_vulns ||\n  Explore:\"Check for exposed secrets and API keys\":exposed_secrets ||\n  general-purpose:\"Analyze dependency vulnerabilities\":dep_vulns\n] ->\n\ngeneral-purpose:\"Consolidate security findings: {auth_vulns}, {sql_risks}, {xss_vulns}, {exposed_secrets}, {dep_vulns}\":security_report ->\n\n(if \"critical vulnerabilities\")~>\n  @security-emergency ->\n  [\n    expert-code-implementer:\"Fix critical authentication issues from {security_report}\" ||\n    expert-code-implementer:\"Fix critical SQL injection issues from {security_report}\" ||\n    expert-code-implementer:\"Remove exposed secrets from {security_report}\"\n  ] (all success)~>\n    general-purpose:\"Re-run security audit to verify fixes\" ->\n\n(if \"no critical vulnerabilities\")~>\n  general-purpose:\"Create security improvement backlog from {security_report}\"\n```\n\n### Example 6: Data Migration with Validation\n\n```flow\n# Migrate data with parallel validation checks\ngeneral-purpose:\"Backup current production data\":backup_created ->\n\ngeneral-purpose:\"Run data migration script\":migration_complete ->\n\n[\n  general-purpose:\"Validate record counts match\":count_validation ||\n  general-purpose:\"Validate data integrity with checksums\":integrity_validation ||\n  general-purpose:\"Validate foreign key relationships\":relationship_validation ||\n  general-purpose:\"Validate business rules on sample data\":business_validation ||\n  general-purpose:\"Run performance tests on new schema\":performance_validation\n] (all success)~>\n  @approve-migration ->\n  general-purpose:\"Commit migration and remove backup\" ->\n\n(if failed)~>\n  @migration-failed ->\n  general-purpose:\"Rollback to {backup_created}\" ->\n  general-purpose:\"Analyze validation failures for migration fix\"\n```\n\n### Example 7: TDD with Parallel Test Categories\n\n```flow\n# Test-driven development with parallel test execution\nimplementation-architect:\"Analyze feature requirements\":requirements ->\n\n[\n  expert-code-implementer:\"Write unit tests for {requirements}\":unit_tests ||\n  expert-code-implementer:\"Write integration tests for {requirements}\":integration_tests ||\n  expert-code-implementer:\"Write e2e tests for {requirements}\":e2e_tests\n] ->\n\ngeneral-purpose:\"Verify all tests fail (RED phase)\" (if failed)~>\n\n  expert-code-implementer:\"Implement minimal code to pass tests\":implementation ->\n\n  [\n    general-purpose:\"Run unit tests\":unit_results ||\n    general-purpose:\"Run integration tests\":integration_results ||\n    general-purpose:\"Run e2e tests\":e2e_results\n  ] (all success)~>\n    @review-green-phase ->\n\n    [\n      code-reviewer:\"Refactor {implementation} for better design\" ||\n      expert-code-implementer:\"Add comprehensive documentation for {implementation}\"\n    ] ->\n\n    general-purpose:\"Run all tests again to ensure refactoring didn't break anything\" (if passed)~>\n      general-purpose:\"Commit implementation and tests together\"\n```\n\n### Example 8: Multi-Source Data Aggregation\n\n```flow\n# Collect and merge data from multiple sources\n[\n  general-purpose:\"Fetch data from primary API\":primary_data ||\n  general-purpose:\"Fetch data from secondary API\":secondary_data ||\n  general-purpose:\"Read data from local cache\":cached_data ||\n  general-purpose:\"Query database for historical data\":historical_data\n] (any success)~>\n\ngeneral-purpose:\"Merge and deduplicate: {primary_data}, {secondary_data}, {cached_data}, {historical_data}\":merged_data ->\n\n[\n  general-purpose:\"Validate data schema for {merged_data}\":schema_valid ||\n  general-purpose:\"Check data completeness of {merged_data}\":completeness_valid ||\n  general-purpose:\"Verify data freshness of {merged_data}\":freshness_valid\n] (all success)~>\n\ngeneral-purpose:\"Process and store {merged_data}\" ->\n\n@data-processing-complete\n```\n\n### Example 9: Parallel Refactoring with Safety Checks\n\n```flow\n# Refactor multiple modules with continuous validation\nExplore:\"Identify modules needing refactoring\":modules_to_refactor ->\n\n@approve-refactoring-plan ->\n\n[\n  expert-code-implementer:\"Refactor authentication module\":auth_refactored ||\n  expert-code-implementer:\"Refactor data access module\":data_refactored ||\n  expert-code-implementer:\"Refactor business logic module\":logic_refactored\n] ->\n\n# Parallel testing of refactored modules\n[\n  general-purpose:\"Test {auth_refactored} module\" ||\n  general-purpose:\"Test {data_refactored} module\" ||\n  general-purpose:\"Test {logic_refactored} module\"\n] (all success)~>\n\n# Integration testing\ngeneral-purpose:\"Run full integration test suite\" (if passed)~>\n\n# Parallel quality checks\n[\n  code-reviewer:\"Review code quality of refactored modules\" ||\n  general-purpose:\"Check performance metrics vs baseline\" ||\n  general-purpose:\"Verify no security regressions\"\n] (all success)~>\n\n@approve-refactoring-completion ->\ngeneral-purpose:\"Commit all refactored modules\"\n```\n\n### Example 10: Comprehensive Project Health Check\n\n```flow\n# Complete project audit with parallel analysis\n[\n  Explore:\"Analyze code quality metrics\":code_quality ||\n  Explore:\"Check test coverage and test health\":test_health ||\n  general-purpose:\"Audit dependencies for updates and vulnerabilities\":dependency_audit ||\n  general-purpose:\"Review documentation completeness\":docs_review ||\n  general-purpose:\"Analyze git commit patterns and velocity\":git_metrics ||\n  general-purpose:\"Check CI/CD pipeline health\":pipeline_health\n] ->\n\ngeneral-purpose:\"Generate comprehensive health report: {code_quality}, {test_health}, {dependency_audit}, {docs_review}, {git_metrics}, {pipeline_health}\":health_report ->\n\n@review-health-report ->\n\n(if \"critical issues\")~>\n  implementation-architect:\"Create improvement roadmap for critical issues from {health_report}\":improvement_plan ->\n  @prioritize-improvements ->\n\n(if \"no critical issues\")~>\n  general-purpose:\"Document project health status and optional improvements\"\n```\n\n---\n\n## Summary\n\nParallel execution with `||` is powerful for independent tasks:\n\n**Key Takeaways:**\n1. Use `[task1 || task2 || task3]` with square brackets\n2. Capture individual outputs with `:variable` syntax\n3. Apply conditions with `(all success)~>` or `(any success)~>`\n4. Ensure tasks are truly independent (no shared state)\n5. Optimize with 3-5 parallel branches per group\n6. Add checkpoints after parallel sections for review\n7. Handle errors gracefully with conditional routing\n\n**When in doubt:** Start with sequential execution, convert to parallel when independence is verified.\n\n---\n\n## Related Documentation\n\n- [Syntax Reference](syntax-reference.md) - Complete syntax guide\n- [Variables Guide](variables.md) - Variable capture and interpolation\n- [Conditional Execution](conditional.md) - Conditional flow patterns\n- [Checkpoints Guide](checkpoints.md) - Review and steering points\n- [Error Handling](error-handling.md) - Error recovery strategies\n",
        "skills/executing-workflows/syntax-reference.md": "# Workflow Syntax Reference\n\nComplete reference for workflow orchestration syntax used in the executing-workflows skill.\n\n## Table of Contents\n\n- [Operators](#operators)\n- [Agent Invocation](#agent-invocation)\n- [Conditions](#conditions)\n- [Variable Binding](#variable-binding)\n- [Temporary Agents](#temporary-agents)\n- [Complete Examples](#complete-examples)\n\n---\n\n## Operators\n\n### Sequential Operator: `->`\n\nExecutes agents in sequence, where each agent runs after the previous one completes.\n\n**Syntax:**\n```flow\nagent1:\"task1\" -> agent2:\"task2\" -> agent3:\"task3\"\n```\n\n**Example:**\n```flow\nimplementation-architect:\"Design user authentication\" ->\nexpert-code-implementer:\"Implement the design\" ->\ncode-reviewer:\"Review the implementation\"\n```\n\n**Behavior:**\n- Agents execute in left-to-right order\n- Each agent waits for the previous to complete\n- If an agent fails, execution stops unless conditional operators are used\n\n---\n\n### Parallel Operator: `||`\n\nExecutes multiple agents concurrently.\n\n**Syntax:**\n```flow\nagent1:\"task1\" || agent2:\"task2\" || agent3:\"task3\"\n```\n\n**Example:**\n```flow\nExplore:\"Find all API endpoints\" ||\nExplore:\"Find all database models\" ||\nExplore:\"Find all test files\"\n```\n\n**Behavior:**\n- All agents start simultaneously\n- Execution continues when all parallel agents complete\n- Variables from parallel agents are available to subsequent steps\n\n---\n\n### Conditional Operator: `~>`\n\nExecutes the next agent only if a condition is met.\n\n**Syntax:**\n```flow\nagent1:\"task1\" ~> (condition) agent2:\"task2\"\n```\n\n**Example:**\n```flow\ncode-reviewer:\"Review the code\":review ~>\n(if no issues) implementation-architect:\"Plan next feature\" ~>\n(if issues) expert-code-implementer:\"Fix the issues\"\n```\n\n**Behavior:**\n- Evaluates condition after agent completes\n- Only executes next agent if condition is true\n- Can chain multiple conditional branches\n\n---\n\n### Checkpoint Operator: `@`\n\nCreates a named checkpoint for workflow control and reporting.\n\n**Syntax:**\n```flow\n@ checkpoint-name\n```\n\n**Example:**\n```flow\nimplementation-architect:\"Design the feature\":design ->\n@ design-complete ->\nexpert-code-implementer:\"Implement {design}\" ->\n@ implementation-complete ->\ncode-reviewer:\"Review implementation\"\n```\n\n**Behavior:**\n- Marks a point in workflow execution\n- Useful for reporting progress\n- Helps with debugging workflow execution\n- Does not affect execution flow\n\n---\n\n### Grouping: `[...]`\n\nGroups multiple agents into a subgraph for organization or conditional execution.\n\n**Syntax:**\n```flow\n[\n  agent1:\"task1\" ->\n  agent2:\"task2\"\n]\n```\n\n**Example:**\n```flow\ncode-reviewer:\"Review code\":review ~>\n(if issues) [\n  implementation-architect:\"Analyze issues\":analysis ->\n  expert-code-implementer:\"Fix based on {analysis}\" ->\n  code-reviewer:\"Verify fixes\"\n]\n```\n\n**Behavior:**\n- Creates a logical grouping of agents\n- Can be used with conditional operators\n- Helps organize complex workflows\n- Entire subgraph executes as a unit\n\n---\n\n## Agent Invocation\n\n### Basic Invocation\n\n**Syntax:**\n```flow\nagent-name:\"instruction text\"\n```\n\n**Example:**\n```flow\nExplore:\"Find all authentication related files\"\n```\n\n### Invocation with Output Capture\n\n**Syntax:**\n```flow\nagent-name:\"instruction text\":variable_name\n```\n\n**Example:**\n```flow\nExplore:\"List all API endpoints\":endpoints\n```\n\n### Built-in Agents\n\n| Agent Name | Purpose | Typical Use Case |\n|------------|---------|------------------|\n| `Explore` | Search and discover code/files | Finding files, analyzing codebase structure |\n| `general-purpose` | General development tasks | Ad-hoc tasks, simple implementations |\n| `code-reviewer` | Review code quality | Code review, finding issues |\n| `implementation-architect` | Design solutions | Planning, architecture, design documents |\n| `expert-code-implementer` | Implement code | Writing production code, complex implementations |\n\n### Agent Invocation Examples\n\n**Simple exploration:**\n```flow\nExplore:\"Find all React components in src/\"\n```\n\n**Capture and reuse output:**\n```flow\nExplore:\"Find database schema files\":schema ->\nimplementation-architect:\"Design migration based on {schema}\"\n```\n\n**Multiple agents with different purposes:**\n```flow\nExplore:\"Find test files\":tests ||\nExplore:\"Find source files\":source ->\ncode-reviewer:\"Review {source} and {tests}\"\n```\n\n---\n\n## Conditions\n\n### Standard Conditions\n\n| Condition | Description | Use Case |\n|-----------|-------------|----------|\n| `(if passed)` | Agent completed successfully | Continue on success |\n| `(if failed)` | Agent encountered errors | Handle failures |\n| `(if no issues)` | Code review found no problems | Proceed after clean review |\n| `(if issues)` | Code review found problems | Fix issues |\n| `(if all success)` | All parallel agents succeeded | Proceed only if all passed |\n| `(if any success)` | At least one parallel agent succeeded | Proceed if any passed |\n\n### Negative Conditions\n\n**Syntax:**\n```flow\nagent:\"task\":var ~> (if !var) next-agent:\"handle empty result\"\n```\n\n**Example:**\n```flow\nExplore:\"Find configuration files\":config ~>\n(if !config) general-purpose:\"Create default configuration\"\n```\n\n**Behavior:**\n- `(if !variable)` checks if variable is empty, null, or false\n- Useful for handling missing data or failed searches\n\n### Custom Conditions\n\nWhile the standard conditions cover most cases, you can describe conditions in natural language:\n\n```flow\nagent:\"task\":result ~>\n(if result contains errors) handler:\"fix errors\"\n```\n\n**Note:** Custom conditions are interpreted based on context and variable content.\n\n### Condition Examples\n\n**Handle success/failure:**\n```flow\ncode-reviewer:\"Review implementation\":review ~>\n(if no issues) general-purpose:\"Deploy to staging\" ~>\n(if issues) expert-code-implementer:\"Fix issues from {review}\"\n```\n\n**Check variable content:**\n```flow\nExplore:\"Find deprecated code\":deprecated ~>\n(if !deprecated) general-purpose:\"No cleanup needed\" ~>\n(if deprecated) expert-code-implementer:\"Refactor {deprecated}\"\n```\n\n**Parallel execution with condition:**\n```flow\n[\n  expert-code-implementer:\"Implement feature A\" ||\n  expert-code-implementer:\"Implement feature B\" ||\n  expert-code-implementer:\"Implement feature C\"\n] ~>\n(if all success) code-reviewer:\"Review all features\" ~>\n(if any failed) general-purpose:\"Report failed features\"\n```\n\n---\n\n## Variable Binding\n\n### Capture Syntax\n\nCapture agent output to a variable for later use.\n\n**Syntax:**\n```flow\nagent:\"instruction\":variable_name\n```\n\n**Example:**\n```flow\nExplore:\"Find all API routes\":routes\n```\n\n**Rules:**\n- Variable names must be alphanumeric with underscores\n- Variables are scoped to the workflow\n- Variables from parallel agents are all available after the parallel block completes\n\n### Interpolation Syntax\n\nUse captured variables in subsequent instructions.\n\n**Syntax:**\n```flow\nagent:\"instruction with {variable_name}\"\n```\n\n**Example:**\n```flow\nExplore:\"Find authentication files\":auth_files ->\ncode-reviewer:\"Review {auth_files} for security issues\"\n```\n\n**Rules:**\n- Use curly braces `{variable_name}` to interpolate\n- Variables must be captured before use\n- Can use multiple variables in one instruction\n\n### Multiple Variables Example\n\n```flow\nExplore:\"Find API routes\":routes ->\nExplore:\"Find API tests\":tests ->\ncode-reviewer:\"Verify {routes} have corresponding {tests}\":coverage ->\nimplementation-architect:\"Design tests for uncovered routes in {coverage}\"\n```\n\n### Variable Scope in Parallel Execution\n\n```flow\n[\n  Explore:\"Find frontend files\":frontend ||\n  Explore:\"Find backend files\":backend ||\n  Explore:\"Find config files\":config\n] ->\nimplementation-architect:\"Design deployment strategy for {frontend}, {backend}, and {config}\"\n```\n\n**Behavior:**\n- All variables from parallel agents are available after the parallel block\n- Variables are merged into the workflow context\n- Can reference any variable in subsequent steps\n\n---\n\n## Temporary Agents\n\nTemporary agents (temp agents) are custom, single-use agents defined inline for specific workflow needs.\n\n### Definition Syntax\n\n**Syntax:**\n```flow\n$agent-name := {\n  base: \"agent-type\",\n  prompt: \"custom instructions\",\n  model: \"model-name\"\n}\n```\n\n**Parameters:**\n\n| Parameter | Required | Description | Options |\n|-----------|----------|-------------|---------|\n| `base` | Yes | Base agent type | `general-purpose`, `code-reviewer`, `implementation-architect`, `expert-code-implementer` |\n| `prompt` | Yes | Custom system prompt | Any text defining agent behavior |\n| `model` | No | Claude model to use | `sonnet` (default), `opus`, `haiku` |\n\n### Basic Temp Agent Example\n\n```flow\n$security-auditor := {\n  base: \"code-reviewer\",\n  prompt: \"You are a security specialist. Focus only on security vulnerabilities, authentication issues, and data exposure risks.\",\n  model: \"sonnet\"\n}\n\nExplore:\"Find authentication code\":auth ->\n$security-auditor:\"Audit {auth} for security vulnerabilities\"\n```\n\n### Temp Agent Invocation\n\nOnce defined, temp agents are used like built-in agents:\n\n**Syntax:**\n```flow\n$agent-name:\"instruction\"\n$agent-name:\"instruction\":output_variable\n```\n\n**Example:**\n```flow\n$api-designer := {\n  base: \"implementation-architect\",\n  prompt: \"You specialize in RESTful API design. Follow OpenAPI 3.0 standards and focus on resource-oriented design.\"\n}\n\n$api-designer:\"Design API for user management\":api_spec ->\nexpert-code-implementer:\"Implement {api_spec}\"\n```\n\n### Multiple Temp Agents Example\n\n```flow\n# Define specialized agents\n$frontend-reviewer := {\n  base: \"code-reviewer\",\n  prompt: \"Focus on React best practices, accessibility, and performance\"\n}\n\n$backend-reviewer := {\n  base: \"code-reviewer\",\n  prompt: \"Focus on API design, database queries, and error handling\"\n}\n\n$security-reviewer := {\n  base: \"code-reviewer\",\n  prompt: \"Focus exclusively on security vulnerabilities and auth issues\"\n}\n\n# Use in parallel\nExplore:\"Find React components\":frontend ->\nExplore:\"Find API endpoints\":backend ->\n[\n  $frontend-reviewer:\"Review {frontend}\" ||\n  $backend-reviewer:\"Review {backend}\" ||\n  $security-reviewer:\"Review {frontend} and {backend}\"\n]\n```\n\n### Temp Agent Best Practices\n\n1. **Specific Focus:** Define temp agents for specialized tasks that built-in agents don't cover\n2. **Clear Prompts:** Write detailed prompts that clearly define the agent's expertise and constraints\n3. **Appropriate Base:** Choose the base agent type that matches the task (reviewer for analysis, architect for design, implementer for coding)\n4. **Model Selection:** Use `opus` for complex reasoning, `sonnet` for balanced tasks (default), `haiku` for simple/fast tasks\n\n### Temp Agent with Model Selection\n\n```flow\n$quick-scanner := {\n  base: \"code-reviewer\",\n  prompt: \"Quickly scan for obvious syntax errors and missing imports\",\n  model: \"haiku\"\n}\n\n$deep-analyzer := {\n  base: \"code-reviewer\",\n  prompt: \"Perform deep analysis of architectural patterns and design decisions\",\n  model: \"opus\"\n}\n\n# Quick scan first, deep analysis if needed\n$quick-scanner:\"Scan codebase\":quick_results ~>\n(if issues) $deep-analyzer:\"Deep analysis of issues in {quick_results}\"\n```\n\n---\n\n## Complete Examples\n\n### Example 1: Feature Development Pipeline\n\n```flow\n# Plan the feature\nimplementation-architect:\"Design user profile feature\":design ->\n@ design-complete ->\n\n# Implement in parallel\n[\n  expert-code-implementer:\"Implement backend for {design}\" ||\n  expert-code-implementer:\"Implement frontend for {design}\" ||\n  expert-code-implementer:\"Write tests for {design}\"\n] ->\n@ implementation-complete ->\n\n# Review\ncode-reviewer:\"Review all implementation\":review ~>\n(if no issues) general-purpose:\"Feature ready for deployment\" ~>\n(if issues) expert-code-implementer:\"Fix issues: {review}\"\n```\n\n### Example 2: Codebase Audit with Temp Agents\n\n```flow\n# Define specialized auditors\n$security-auditor := {\n  base: \"code-reviewer\",\n  prompt: \"Security specialist focusing on vulnerabilities, auth, and data exposure\",\n  model: \"sonnet\"\n}\n\n$performance-auditor := {\n  base: \"code-reviewer\",\n  prompt: \"Performance specialist focusing on optimization, caching, and queries\",\n  model: \"sonnet\"\n}\n\n$accessibility-auditor := {\n  base: \"code-reviewer\",\n  prompt: \"Accessibility specialist focusing on WCAG compliance and screen readers\",\n  model: \"sonnet\"\n}\n\n# Discover codebase\nExplore:\"Find all source files\":source ->\n@ discovery-complete ->\n\n# Parallel audit\n[\n  $security-auditor:\"Audit {source}\":security_issues ||\n  $performance-auditor:\"Audit {source}\":performance_issues ||\n  $accessibility-auditor:\"Audit {source}\":a11y_issues\n] ->\n@ audit-complete ->\n\n# Generate report\nimplementation-architect:\"Create comprehensive audit report from {security_issues}, {performance_issues}, {a11y_issues}\"\n```\n\n### Example 3: Conditional Migration\n\n```flow\n# Find existing code\nExplore:\"Find database schema\":schema ->\nExplore:\"Find existing migrations\":migrations ->\n\n# Check if migration needed\ncode-reviewer:\"Compare {schema} with {migrations}\":analysis ~>\n(if !analysis) general-purpose:\"Schema is up to date\" ~>\n(if analysis) [\n  implementation-architect:\"Design migration for {analysis}\":migration_plan ->\n  expert-code-implementer:\"Create migration: {migration_plan}\":migration_file ->\n  code-reviewer:\"Verify {migration_file}\":verification ~>\n  (if no issues) general-purpose:\"Migration ready to apply\" ~>\n  (if issues) expert-code-implementer:\"Fix migration issues: {verification}\"\n]\n```\n\n### Example 4: Multi-Stage Refactoring\n\n```flow\n# Discovery phase\nExplore:\"Find deprecated patterns\":deprecated ->\n@ discovery-complete ->\n\n# Analysis phase\nimplementation-architect:\"Analyze {deprecated} and create refactoring strategy\":strategy ->\n@ analysis-complete ->\n\n# Implementation phase\nexpert-code-implementer:\"Refactor based on {strategy}\":refactored_code ->\n@ refactoring-complete ->\n\n# Verification phase\n[\n  code-reviewer:\"Review {refactored_code}\":review ||\n  general-purpose:\"Run tests on {refactored_code}\":test_results\n] ->\n@ verification-complete ->\n\n# Decision phase\n(if all success) general-purpose:\"Refactoring complete and verified\" ~>\n(if any failed) [\n  implementation-architect:\"Analyze failures in {review} and {test_results}\":fixes ->\n  expert-code-implementer:\"Apply fixes: {fixes}\"\n]\n```\n\n### Example 5: Parallel Feature Development\n\n```flow\n# Define specialized implementers\n$db-expert := {\n  base: \"expert-code-implementer\",\n  prompt: \"Database specialist. Expert in SQL, migrations, and query optimization.\",\n  model: \"sonnet\"\n}\n\n$api-expert := {\n  base: \"expert-code-implementer\",\n  prompt: \"API specialist. Expert in REST, GraphQL, and API design patterns.\",\n  model: \"sonnet\"\n}\n\n$ui-expert := {\n  base: \"expert-code-implementer\",\n  prompt: \"UI specialist. Expert in React, accessibility, and responsive design.\",\n  model: \"sonnet\"\n}\n\n# Plan feature\nimplementation-architect:\"Design multi-tier feature with DB, API, and UI layers\":plan ->\n\n# Parallel implementation by specialists\n[\n  $db-expert:\"Implement database layer from {plan}\":db_code ||\n  $api-expert:\"Implement API layer from {plan}\":api_code ||\n  $ui-expert:\"Implement UI layer from {plan}\":ui_code\n] ->\n\n# Integration review\ncode-reviewer:\"Review integration of {db_code}, {api_code}, and {ui_code}\":integration ~>\n(if no issues) general-purpose:\"Feature complete\" ~>\n(if issues) implementation-architect:\"Create fix plan for {integration}\":fix_plan ->\nexpert-code-implementer:\"Apply fixes: {fix_plan}\"\n```\n\n---\n\n## Syntax Quick Reference\n\n| Element | Syntax | Example |\n|---------|--------|---------|\n| Sequential | `->` | `agent1:\"task\" -> agent2:\"task\"` |\n| Parallel | `\\|\\|` | `agent1:\"task\" \\|\\| agent2:\"task\"` |\n| Conditional | `~>` | `agent:\"task\" ~> (if passed) next:\"task\"` |\n| Checkpoint | `@` | `@ checkpoint-name` |\n| Grouping | `[...]` | `[agent1:\"task\" -> agent2:\"task\"]` |\n| Agent call | `agent:\"instruction\"` | `Explore:\"Find files\"` |\n| Capture output | `:variable` | `agent:\"task\":result` |\n| Use variable | `{variable}` | `agent:\"Use {result}\"` |\n| Temp agent definition | `$name := {...}` | `$agent := {base: \"type\", prompt: \"text\"}` |\n| Temp agent call | `$name:\"instruction\"` | `$agent:\"Do task\"` |\n| Standard condition | `(if condition)` | `(if no issues)`, `(if passed)` |\n| Negative condition | `(if !var)` | `(if !result)` |\n\n---\n\n## Additional Notes\n\n### Workflow Execution Order\n\n1. **Definition Phase:** Temp agents are defined but not executed\n2. **Sequential Execution:** Agents execute left-to-right following `->`\n3. **Parallel Execution:** All agents in `||` block start simultaneously\n4. **Condition Evaluation:** Conditions evaluate after agent completes\n5. **Variable Availability:** Variables available immediately after capture\n\n### Error Handling\n\n- If an agent fails without a conditional, workflow stops\n- Use `~> (if failed)` to handle errors explicitly\n- Checkpoints help identify where failures occur\n- Parallel failures can be handled with `(if all success)` or `(if any success)`\n\n### Best Practices\n\n1. **Use checkpoints** for complex workflows to track progress\n2. **Capture variables** when output will be reused\n3. **Use parallel execution** for independent tasks\n4. **Define temp agents** for specialized, repeated tasks\n5. **Use conditionals** to handle different execution paths\n6. **Group related agents** with `[...]` for clarity\n7. **Choose appropriate base agents** for temp agents\n8. **Write clear instructions** that specify exact requirements\n\n---\n\n## See Also\n\n- Main skill documentation: `skills/executing-workflows/README.md`\n- Examples: `/commands/examples.md`\n- Workflow designer: `agents/workflow-socratic-designer.md`\n",
        "skills/executing-workflows/variables.md": "# Variables Guide\n\nProgressive disclosure guide to variable binding and interpolation in orchestration workflows.\n\n## Overview\n\nVariables in workflows serve two key purposes:\n\n1. **Capture outputs** from agents and operations for later use\n2. **Pass data** between different parts of your workflow\n\nVariables make workflows dynamic and data-driven, allowing agents to build on each other's work and make decisions based on previous results.\n\n**When to use variables:**\n- Passing data between sequential steps\n- Conditional branching based on agent outputs\n- Accumulating results from parallel operations\n- Making workflows self-documenting and traceable\n\n---\n\n## Capturing Output\n\n### Basic Capture Syntax\n\nCapture an agent's output by appending `:variable_name` after the instruction:\n\n```\nagent:\"instruction\":variable_name\n```\n\n**Example:**\n```\nExplore:\"Find all authentication files\":auth_files\n```\n\nThe variable `auth_files` now contains the output from the Explore agent.\n\n### Temporary Agent Outputs\n\nTemporary agents can also capture output:\n\n```\n$scanner:\"Analyze security vulnerabilities\":vulnerabilities\n```\n\n### What Gets Captured\n\nWhen you capture output, you get:\n- **Text output** from the agent's response\n- **Findings, analysis, and recommendations** the agent provides\n- **Any data** the agent generates or discovers\n\nThe captured content is the agent's final response text, which you can then reference in later steps.\n\n### Naming Conventions\n\n**Use snake_case for variable names:**\n- `auth_files` ‚úì\n- `security_issues` ‚úì\n- `test_results` ‚úì\n- `AuthFiles` ‚úó (use lowercase)\n- `security-issues` ‚úó (use underscores, not hyphens)\n\n**Be descriptive:**\n- `scan_results` ‚úì (clear what it contains)\n- `results` ‚úó (too vague)\n- `user_validation_status` ‚úì (specific)\n- `status` ‚úó (not specific enough)\n\n**Use noun phrases:**\n- `error_report` ‚úì\n- `fixed_code` ‚úì\n- `test_coverage_summary` ‚úì\n\n---\n\n## Variable Interpolation\n\n### Using Variables in Instructions\n\nReference captured variables in later instructions using curly braces `{variable_name}`:\n\n```\nExplore:\"Find authentication bugs\":bugs ->\nexpert-code-implementer:\"Fix these issues: {bugs}\"\n```\n\nThe `{bugs}` placeholder gets replaced with the actual content from the first agent's output.\n\n### Multiple Variables\n\nUse multiple variables in a single instruction:\n\n```\nExplore:\"Analyze authentication\":auth_analysis ->\nExplore:\"Analyze authorization\":authz_analysis ->\nexpert-code-implementer:\"Compare {auth_analysis} with {authz_analysis} and identify gaps\"\n```\n\n### Nested Workflows\n\nVariables work across workflow phases:\n\n```\n# Phase 1: Analysis\n$analyzer:\"Scan codebase\":findings ->\n\n# Phase 2: Planning\nimplementation-architect:\"Create fix plan for {findings}\":plan ->\n\n# Phase 3: Implementation\nexpert-code-implementer:\"Execute this plan: {plan}\":implementation ->\n\n# Phase 4: Verification\ncode-reviewer:\"Verify {implementation} addresses {findings}\"\n```\n\n### Interpolation in Temporary Agent Definitions\n\nYou can also interpolate variables within temporary agent prompts:\n\n```\n$custom_reviewer := {\n  base: \"code-reviewer\",\n  prompt: \"Focus review on issues found: {initial_scan}\",\n  model: \"sonnet\"\n}\n```\n\n**Note:** The variable must exist before the temporary agent is invoked.\n\n---\n\n## Variable Scope\n\n### Workflow-Wide Availability\n\nOnce a variable is captured, it's available throughout the entire workflow:\n\n```\nExplore:\"Find issues\":issues ->\n@checkpoint ->\nexpert-code-implementer:\"Fix {issues}\":fixes ->\n@review ->\ncode-reviewer:\"Verify {fixes} address {issues}\"\n```\n\nBoth `issues` and `fixes` remain accessible across checkpoints.\n\n### Variable Lifetime\n\nVariables persist for the entire workflow execution:\n- Created when the capturing node completes\n- Available to all subsequent nodes\n- Remain accessible even after checkpoints\n- Cleared only when workflow completes\n\n### Sequential Definition\n\nVariables must be defined before use:\n\n```\n# ‚úì Correct - bugs defined before use\nExplore:\"Find bugs\":bugs ->\ngeneral-purpose:\"Fix {bugs}\"\n\n# ‚úó Wrong - bugs used before definition\ngeneral-purpose:\"Fix {bugs}\" ->\nExplore:\"Find bugs\":bugs\n```\n\n### Parallel Branch Variables\n\nVariables captured in parallel branches are all available after the parallel block completes:\n\n```\n[\n  Explore:\"Find security issues\":security ||\n  Explore:\"Find performance issues\":performance ||\n  Explore:\"Find style issues\":style\n] ->\ngeneral-purpose:\"Address all issues: {security}, {performance}, {style}\"\n```\n\n**Important:** You cannot use a variable from one parallel branch in another parallel branch executing at the same time.\n\n```\n# ‚úó Wrong - parallel branches can't access each other's variables\n[\n  Explore:\"Find config\":config ||\n  general-purpose:\"Use {config}\"  # Error: config not yet available\n]\n\n# ‚úì Correct - use variables after parallel block\n[\n  Explore:\"Find config\":config ||\n  Explore:\"Find schema\":schema\n] ->\ngeneral-purpose:\"Compare {config} with {schema}\"\n```\n\n---\n\n## Conditional Variables\n\n### Binding from Conditions\n\nCapture boolean results from conditions:\n\n```\noperation (condition):variable_name~>\n```\n\nThis evaluates the condition and stores true/false in the variable.\n\n**Example:**\n```\ngeneral-purpose:\"Run tests\" (if passed):tests_passing~>\n  (if tests_passing)~> deploy\n```\n\n### Using in Conditionals\n\nReference boolean variables in conditional branches:\n\n```\nbuild ->\ntest (if passed):build_success~>\n  (if build_success)~> deploy ->\n  (if !build_success)~> notify_failure\n```\n\n### Negative Checks\n\nUse `!` prefix to check if a variable is false:\n\n```\nanalyze (if security-critical):is_critical~>\n  (if !is_critical)~> fast_deploy ->\n  (if is_critical)~> security_review -> careful_deploy\n```\n\n### Complex Conditional Flows\n\nCombine multiple conditional variables:\n\n```\n[test || lint] (all success):validation_passed~>\n  (if !validation_passed)~> fix -> @retry ->\n  (if validation_passed)~> analyze (if production-ready):ready~>\n    (if ready)~> deploy ->\n    (if !ready)~> @review -> manual_approval -> deploy\n```\n\n---\n\n## Common Patterns\n\n### Pattern 1: Data Passing Pipeline\n\nPass data through a series of transformations:\n\n```\nExplore:\"Extract user data from database\":raw_data ->\ngeneral-purpose:\"Clean and validate {raw_data}\":clean_data ->\ngeneral-purpose:\"Transform {clean_data} to new format\":transformed_data ->\ngeneral-purpose:\"Generate report from {transformed_data}\":final_report\n```\n\n### Pattern 2: Conditional Branching Based on Results\n\nMake decisions based on agent outputs:\n\n```\n$security_scanner:\"Scan for vulnerabilities\":issues ->\ngeneral-purpose:\"Count severity levels in {issues}\":severity_count ->\nanalyze (if critical-issues-found):has_critical~>\n  (if has_critical)~> @emergency_review -> priority_fix ->\n  (if !has_critical)~> standard_review -> scheduled_fix\n```\n\n### Pattern 3: Accumulating Results from Parallel Branches\n\nGather outputs from parallel operations:\n\n```\n[\n  Explore:\"Find TODO comments\":todos ||\n  Explore:\"Find FIXME comments\":fixmes ||\n  Explore:\"Find XXX comments\":xxx_notes ||\n  code-reviewer:\"Find undocumented public APIs\":missing_docs\n] ->\ngeneral-purpose:\"Create issue tracker entries for:\n  - TODOs: {todos}\n  - FIXMEs: {fixmes}\n  - XXX notes: {xxx_notes}\n  - Missing docs: {missing_docs}\n\":issue_tracker_report\n```\n\n### Pattern 4: Iterative Refinement\n\nUse outputs to refine subsequent steps:\n\n```\nimplementation-architect:\"Create initial plan\":plan ->\ncode-reviewer:\"Review {plan} for issues\":review ->\nimplementation-architect:\"Refine {plan} based on {review}\":refined_plan ->\nexpert-code-implementer:\"Implement {refined_plan}\":implementation\n```\n\n### Pattern 5: Analysis and Summary\n\nCollect detailed analysis and create summaries:\n\n```\n$analyzer:\"Deep analysis of authentication system\":auth_details ->\n$analyzer:\"Deep analysis of authorization system\":authz_details ->\n$analyzer:\"Deep analysis of session management\":session_details ->\ngeneral-purpose:\"Create executive summary of:\n  Authentication: {auth_details}\n  Authorization: {authz_details}\n  Sessions: {session_details}\n\":security_summary ->\n@review\n```\n\n### Pattern 6: Validation Gates\n\nValidate outputs before proceeding:\n\n```\nexpert-code-implementer:\"Implement feature X\":implementation ->\ncode-reviewer:\"Review {implementation}\":review_results ->\nanalyze (if approved):is_approved~>\n  (if !is_approved)~>\n    expert-code-implementer:\"Address issues: {review_results}\":fixes ->\n    @retry ->\n  (if is_approved)~> merge_to_main\n```\n\n### Pattern 7: Multi-Agent Collaboration\n\nHave specialized agents work together:\n\n```\n$backend_expert:\"Analyze API endpoints\":api_analysis ->\n$frontend_expert:\"Analyze UI components\":ui_analysis ->\n$integration_expert:\"Identify integration issues between {api_analysis} and {ui_analysis}\":integration_issues ->\n[\n  $backend_expert:\"Fix backend issues: {integration_issues}\":backend_fixes ||\n  $frontend_expert:\"Fix frontend issues: {integration_issues}\":frontend_fixes\n] ->\ngeneral-purpose:\"Verify {backend_fixes} and {frontend_fixes} work together\":verification\n```\n\n---\n\n## Best Practices\n\n### 1. Use Descriptive Names\n\n**Good:**\n```\nExplore:\"Find authentication vulnerabilities\":auth_vulnerabilities\n```\n\n**Bad:**\n```\nExplore:\"Find authentication vulnerabilities\":v\n```\n\nDescriptive names make workflows self-documenting and easier to maintain.\n\n### 2. Follow snake_case Convention\n\n**Consistent naming:**\n```\nsecurity_scan_results\ntest_coverage_report\nuser_validation_status\n```\n\n**Avoid:**\n```\nsecurityScanResults  # camelCase\nsecurity-scan-results  # kebab-case\nSecurityScanResults  # PascalCase\n```\n\n### 3. When to Use Variables vs Direct Flow\n\n**Use variables when:**\n- You need to reference output multiple times\n- The data flows to multiple branches\n- You want to make dependencies explicit\n- The output is important enough to name\n\n```\nExplore:\"Find all test files\":test_files ->\n[\n  general-purpose:\"Run tests in {test_files}\" ||\n  general-purpose:\"Check coverage for {test_files}\" ||\n  general-purpose:\"Generate report for {test_files}\"\n]\n```\n\n**Don't use variables when:**\n- Output flows to exactly one next step\n- The relationship is obvious from context\n- Variable wouldn't add clarity\n\n```\n# Direct flow is clearer here\nbuild -> test -> deploy\n\n# No need for:\nbuild:build_output ->\ntest:\"Test {build_output}\":test_output ->\ndeploy:\"Deploy {test_output}\"\n```\n\n### 4. Avoid Variable Name Conflicts\n\nEach variable should be defined only once:\n\n```\n# ‚úó Wrong - reusing variable name\nExplore:\"Find bugs\":issues ->\nfix_bugs ->\nExplore:\"Find more bugs\":issues  # Error: issues already defined\n\n# ‚úì Correct - unique names\nExplore:\"Find initial bugs\":initial_issues ->\nfix_bugs ->\nExplore:\"Find remaining bugs\":remaining_issues\n```\n\n### 5. Group Related Variables\n\nWhen capturing multiple related outputs, use consistent prefixes:\n\n```\n[\n  Explore:\"Analyze authentication\":auth_analysis ||\n  Explore:\"Analyze authorization\":auth_permissions ||\n  Explore:\"Analyze session handling\":auth_sessions\n] ->\ngeneral-purpose:\"Create security report from {auth_analysis}, {auth_permissions}, {auth_sessions}\"\n```\n\n### 6. Document Complex Interpolations\n\nFor workflows with many variables, add comments:\n\n```\n# Capture all analysis results\n$scanner:\"Security scan\":security_results ->\n$performance:\"Performance analysis\":perf_results ->\n$quality:\"Code quality check\":quality_results ->\n\n# Generate comprehensive report using all captured data\n$reporter:\"Create report including:\n  Security: {security_results}\n  Performance: {perf_results}\n  Quality: {quality_results}\n\":final_report\n```\n\n### 7. Balance Granularity\n\n**Too many variables (overly granular):**\n```\nbuild:b -> test:t -> lint:l -> format:f -> deploy:d\n```\n\n**Too few variables (missing important data):**\n```\nanalyze -> fix -> verify  # Lost context between steps\n```\n\n**Just right:**\n```\nanalyze:findings ->\nfix:\"Address {findings}\":implementation ->\nverify:\"Check {implementation} fixes {findings}\"\n```\n\n---\n\n## Examples\n\n### Example 1: Simple Data Pipeline\n\n```\n# Extract, transform, and report on database migration status\n\nExplore:\"Find all migration files and extract version numbers\":migration_list ->\ngeneral-purpose:\"Check which migrations in {migration_list} have been applied to production database\":applied_migrations ->\ngeneral-purpose:\"Compare {migration_list} with {applied_migrations} and identify pending migrations\":pending_migrations ->\ngeneral-purpose:\"Generate migration report showing {pending_migrations} with risk assessment\":migration_report ->\n@review\n```\n\n### Example 2: Conditional Code Analysis\n\n```\n# Analyze code with different paths for simple vs complex projects\n\nExplore:\"Count total lines of code and number of files\":project_size ->\nanalyze (if large-codebase):is_large~>\n  (if is_large)~>\n    $deep_analyzer:\"Perform comprehensive analysis of architecture, patterns, and dependencies\":detailed_analysis ->\n    @architect_review ->\n  (if !is_large)~>\n    general-purpose:\"Perform standard code review focusing on common issues\":standard_analysis ->\n\n# Both paths converge here\ngeneral-purpose:\"Create actionable recommendations based on analysis\"\n```\n\n### Example 3: Parallel Investigation and Synthesis\n\n```\n# Investigate multiple aspects of a security incident in parallel\n\n[\n  $log_analyzer:\"Analyze server logs for suspicious activity in last 24h\":log_findings ||\n  $code_scanner:\"Scan codebase for recently introduced vulnerabilities\":code_findings ||\n  $network_analyzer:\"Review network traffic patterns for anomalies\":network_findings ||\n  general-purpose:\"Check third-party dependencies for known CVEs\":dependency_findings\n] ->\n\n# Synthesize all findings\ngeneral-purpose:\"Correlate findings from multiple sources:\n  Logs: {log_findings}\n  Code: {code_findings}\n  Network: {network_findings}\n  Dependencies: {dependency_findings}\n\n  Identify root cause and attack vector\":root_cause_analysis ->\n\n# Create incident report\ngeneral-purpose:\"Generate incident report including {root_cause_analysis} with timeline, impact assessment, and remediation steps\":incident_report ->\n\n@security_review\n```\n\n### Example 4: Test-Driven Development Flow\n\n```\n# Implement feature using TDD with variable tracking\n\nimplementation-architect:\"Analyze requirements and create implementation plan\":implementation_plan ->\n\n# RED phase\nexpert-code-implementer:\"Write failing tests based on {implementation_plan}\":test_suite ->\ngeneral-purpose:\"Run tests and confirm they fail as expected\":test_results ->\n\n# GREEN phase\nexpert-code-implementer:\"Write minimal code to pass tests in {test_suite}\":implementation ->\ngeneral-purpose:\"Run tests again\":updated_test_results ->\n\n# Verify success\nanalyze (if all-tests-pass):tests_passing~>\n  (if !tests_passing)~>\n    @review ->\n    expert-code-implementer:\"Debug failing tests using {updated_test_results}\":debug_fixes ->\n    @retry ->\n  (if tests_passing)~>\n    # REFACTOR phase\n    code-reviewer:\"Refactor {implementation} while keeping {test_suite} passing\":refactored_code ->\n    general-purpose:\"Final test run to verify {refactored_code}\":final_test_results ->\n    @complete\n```\n\n### Example 5: Progressive Enhancement\n\n```\n# Build feature with progressive complexity based on validation\n\n# Stage 1: Minimal viable implementation\nexpert-code-implementer:\"Create basic implementation of user authentication\":basic_auth ->\ngeneral-purpose:\"Test {basic_auth} functionality\":basic_test_results ->\n\n# Stage 2: Add security\nanalyze (if basic-functional):stage1_complete~>\n  (if stage1_complete)~>\n    $security_expert:\"Add security hardening to {basic_auth}: rate limiting, password hashing, session management\":secure_auth ->\n    general-purpose:\"Security test {secure_auth}\":security_test_results ->\n\n# Stage 3: Add advanced features\nanalyze (if security-passing):stage2_complete~>\n  (if stage2_complete)~>\n    expert-code-implementer:\"Enhance {secure_auth} with: OAuth integration, 2FA, passwordless options\":advanced_auth ->\n    general-purpose:\"Run full test suite on {advanced_auth}\":final_test_results ->\n\n@production_review\n```\n\n### Example 6: Multi-Language Codebase Analysis\n\n```\n# Analyze polyglot codebase with specialized agents\n\n[\n  $js_expert:\"Analyze JavaScript/TypeScript code for issues\":js_findings ||\n  $python_expert:\"Analyze Python code for issues\":py_findings ||\n  $rust_expert:\"Analyze Rust code for issues\":rust_findings ||\n  general-purpose:\"Analyze build configuration and CI/CD\":build_findings\n] ->\n\n# Create per-language action items\n[\n  general-purpose:\"Create JavaScript action items from {js_findings}\":js_actions ||\n  general-purpose:\"Create Python action items from {py_findings}\":py_actions ||\n  general-purpose:\"Create Rust action items from {rust_findings}\":rust_actions\n] ->\n\n# Synthesize cross-language insights\ngeneral-purpose:\"Identify patterns across languages:\n  JavaScript: {js_findings}\n  Python: {py_findings}\n  Rust: {rust_findings}\n  Build: {build_findings}\n\n  Find architectural issues that span multiple languages\":cross_cutting_concerns ->\n\n# Generate comprehensive report\ngeneral-purpose:\"Create master report with:\n  - Per-language actions: {js_actions}, {py_actions}, {rust_actions}\n  - Cross-cutting concerns: {cross_cutting_concerns}\n  - Prioritized roadmap\n\":master_report\n```\n\n### Example 7: Iterative Code Review with Refinement\n\n```\n# Progressive code review with automated fixes\n\nexpert-code-implementer:\"Implement new payment processing feature\":initial_implementation ->\n\n# First review round\ncode-reviewer:\"Review {initial_implementation} for critical issues\":critical_review ->\nanalyze (if has-critical-issues):has_critical~>\n  (if has_critical)~>\n    expert-code-implementer:\"Fix critical issues: {critical_review}\":fixed_critical ->\n    @checkpoint ->\n  (if !has_critical)~>\n    fixed_critical := {initial_implementation} ->  # No critical issues, use original\n\n# Second review round - style and best practices\ncode-reviewer:\"Review {fixed_critical} for style and best practices\":style_review ->\nexpert-code-implementer:\"Apply style improvements: {style_review}\":improved_code ->\n\n# Security audit\n$security_auditor:\"Audit {improved_code} for security vulnerabilities\":security_audit ->\nanalyze (if security-approved):security_ok~>\n  (if !security_ok)~>\n    expert-code-implementer:\"Address security issues: {security_audit}\":security_hardened ->\n    final_code := {security_hardened} ->\n  (if security_ok)~>\n    final_code := {improved_code} ->\n\n# Performance check\n$performance_expert:\"Analyze {final_code} for performance issues\":perf_analysis ->\ngeneral-purpose:\"Generate final documentation and change summary\":documentation ->\n\n@ready_for_merge\n```\n\n---\n\n## Summary\n\nVariables are essential for creating dynamic, data-driven workflows:\n\n- **Capture outputs** with `:variable_name` syntax\n- **Interpolate values** using `{variable_name}` in instructions\n- **Use snake_case** for consistent naming\n- **Make dependencies explicit** by passing data through variables\n- **Leverage conditional variables** for dynamic branching\n- **Follow best practices** for maintainable workflows\n\nVariables transform static workflow graphs into intelligent, adaptive automation that builds on its own work.\n",
        "skills/managing-agents/SKILL.md": "---\nname: managing-agents\ndescription: Manages temporary and defined agents including creation, promotion, cleanup, and namespacing. Use when user creates custom agents, asks about agent lifecycle, temp agents, or agent management.\n---\n\n# Managing Orchestration Agents\n\nI manage the lifecycle of agents in the orchestration system: creation, execution, promotion, and cleanup.\n\n## When I Activate\n\nI automatically activate when you:\n- Create or define custom agents\n- Ask about agent lifecycle\n- Mention temp agents or agent promotion\n- Want to understand agent namespacing\n- Ask \"how do I create an agent?\"\n\n## Agent Types\n\n### Built-in Agents\n\n**No namespace prefix**, always available:\n- `Explore` - Codebase exploration\n- `general-purpose` - General-purpose tasks\n- `code-reviewer` - Code review\n- `implementation-architect` - Architecture planning\n- `expert-code-implementer` - Code implementation\n\n### Plugin Defined Agents\n\n**With `orchestration:` prefix**, permanent agents in this plugin:\n- `orchestration:workflow-socratic-designer`\n- `orchestration:workflow-syntax-designer`\n- Custom agents you promote\n\nLocated in: `agents/` directory\nRegistry: `agents/registry.json`\n\n### Temp Agents\n\n**With `orchestration:` prefix**, workflow-specific ephemeral agents:\n- Created during workflow design\n- Saved in `temp-agents/` directory\n- Auto-cleaned after workflow execution\n- Can be promoted to permanent\n\nReference in workflows: `$agent-name`\n\n## Temp Agent Lifecycle\n\nSee [temp-agents.md](temp-agents.md) for complete guide.\n\n### 1. Creation\n\nCreated automatically during workflow design:\n\n```markdown\n---\nname: security-scanner\ndescription: Scans for security vulnerabilities\ncreated: 2025-01-08\n---\n\nYou are a security expert specializing in vulnerability detection...\n```\n\nSaved to: `temp-agents/security-scanner.md`\n\n### 2. Execution\n\nReferenced in workflow with `$` prefix:\n\n```flow\n$security-scanner:\"Scan codebase\":findings ->\ngeneral-purpose:\"Analyze {findings}\"\n```\n\nExecuted with namespace: `orchestration:security-scanner`\n\n### 3. Promotion\n\nAfter workflow completion, you can save temp agents:\n\n```\nWorkflow complete!\n\nTemp agents created:\n  - security-scanner\n  - performance-profiler\n\nSave as permanent agents? [Y/n]\n```\n\nIf saved:\n- Moved from `temp-agents/` to `agents/`\n- Added to `agents/registry.json`\n- Available in all future workflows\n- No need to recreate\n\n### 4. Cleanup\n\nUnsaved temp agents are deleted:\n\n```\nüßπ Cleaned up 2 temporary file(s):\n   - temp-agents/security-scanner.md\n   - examples/workflow-data.json\n```\n\n## Creating Defined Agents\n\nSee [defined-agents.md](defined-agents.md) for detailed guide.\n\nTo create a permanent agent manually:\n\n### 1. Create Agent File\n\n`agents/custom-agent.md`:\n\n```markdown\n---\nname: custom-agent\nnamespace: orchestration:custom-agent\ndescription: One-line description of what this agent does\ntools: [Read, Grep, Edit]\nusage: \"Use via Task tool with subagent_type: 'orchestration:custom-agent'\"\n---\n\nYou are a specialized agent for [purpose].\n\nYour responsibilities:\n1. Task 1\n2. Task 2\n\nOutput format:\n[Expected output format]\n\nUse these tools:\n- Read: [When to use]\n- Grep: [When to use]\n```\n\n### 2. Register Agent\n\nAdd to `agents/registry.json`:\n\n```json\n{\n  \"custom-agent\": {\n    \"file\": \"custom-agent.md\",\n    \"description\": \"One-line description\",\n    \"namespace\": \"orchestration:custom-agent\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0\n  }\n}\n```\n\n### 3. Use in Workflows\n\nReference by name (system adds namespace automatically):\n\n```flow\ncustom-agent:\"Perform specialized task\":output\n```\n\n## Namespace Conventions\n\nSee [namespacing.md](namespacing.md) for complete reference.\n\n### Namespace Rules\n\n| Agent Type | User Writes | System Executes |\n|------------|-------------|-----------------|\n| Built-in | `Explore:\"task\"` | `Explore` |\n| Defined plugin | `workflow-socratic-designer` | `orchestration:workflow-socratic-designer` |\n| Temp | `$security-scanner` | `orchestration:security-scanner` |\n\n### Why Namespacing?\n\n1. **Avoid conflicts** - Plugin agents don't conflict with built-ins\n2. **Clear identification** - Know which plugin provides agent\n3. **Proper routing** - System knows where to find agent\n\n### Resolution Algorithm\n\n```javascript\nfunction resolveAgent(name) {\n  // 1. Check if built-in\n  if (isBuiltIn(name)) return name;\n\n  // 2. Check if other plugin (e.g., superpowers:)\n  if (name.includes(':')) return name;\n\n  // 3. Add orchestration namespace\n  return `orchestration:${name}`;\n}\n```\n\n## Agent Promotion Process\n\nSee [promotion.md](promotion.md) for details.\n\nAfter workflow execution with temp agents:\n\n### 1. Review Phase\n\n```\nTemp agents used in this workflow:\n\n1. security-scanner\n   Description: Scans for security vulnerabilities\n   Used: 1 time in workflow\n\n2. performance-profiler\n   Description: Analyzes code performance\n   Used: 1 time in workflow\n\nSelect agents to save (space-separated numbers, or 'none'):\n```\n\n### 2. Selection\n\n```\nYou selected: security-scanner\n\nPromotion options:\n[P]romote as-is - Save with current definition\n[E]dit first - Modify before saving\n[S]kip - Don't save this agent\n```\n\n### 3. Promotion\n\nIf promoted:\n1. File moved from `temp-agents/` to `agents/`\n2. Entry added to `agents/registry.json`\n3. Confirmation message shown\n\n### 4. Cleanup\n\nUnselected agents are deleted\n\n## Agent Maintenance\n\n### Updating Agents\n\nTo update a defined agent:\n\n1. Edit `agents/agent-name.md`\n2. Update description/responsibilities/tools\n3. Optionally update `agents/registry.json` metadata\n\nChanges take effect immediately in new workflows.\n\n### Deleting Agents\n\nTo remove a defined agent:\n\n1. Delete `agents/agent-name.md`\n2. Remove entry from `agents/registry.json`\n\nAgent will no longer be available in workflows.\n\n### Agent Usage Statistics\n\nTrack agent usage in `agents/registry.json`:\n\n```json\n{\n  \"security-scanner\": {\n    \"usageCount\": 15,\n    \"lastUsed\": \"2025-01-08T14:30:00Z\"\n  }\n}\n```\n\n## Best Practices\n\n### Creating Agents\n\n‚úÖ **DO**:\n- Make prompts comprehensive and specific\n- Include clear output format requirements\n- Recommend appropriate tools\n- Handle edge cases\n- Define success criteria\n\n‚ùå **DON'T**:\n- Create for simple one-line tasks\n- Make too generic (\"do analysis\")\n- Forget error handling\n- Skip tool recommendations\n\n### Promoting Agents\n\n‚úÖ **Promote when**:\n- Agent is reusable across workflows\n- Well-tested and reliable\n- Provides domain-specific expertise\n- Saves time in future workflows\n\n‚ùå **Don't promote when**:\n- One-time use only\n- Too specific to single workflow\n- Untested or unreliable\n- Duplicates existing agent\n\n### Naming Agents\n\n‚úÖ **Good names**:\n- `security-scanner` (clear purpose)\n- `api-doc-generator` (descriptive)\n- `performance-profiler` (specific)\n\n‚ùå **Bad names**:\n- `helper` (too generic)\n- `agent1` (meaningless)\n- `do-stuff` (vague)\n\n## Common Issues\n\n**\"Agent not found\" error**:\n- Check spelling of agent name\n- Verify temp agent file exists in `temp-agents/`\n- Ensure defined agent in `agents/` and registry\n- Check if agent was already cleaned up\n\n**Namespace conflict**:\n- Built-in agents don't need prefix\n- Plugin agents automatically prefixed\n- Don't manually add `orchestration:` in workflows\n\n**Temp agent disappeared**:\n- Temp agents auto-deleted after workflow\n- Save important agents during promotion phase\n- Check cleanup logs for what was deleted\n\n## Registry Structure\n\n`agents/registry.json`:\n\n```json\n{\n  \"$schema\": {\n    \"description\": \"Registry of defined agents\",\n    \"namespace\": \"orchestration:\",\n    \"usage\": \"All agents accessed via 'orchestration:{agent-name}'\"\n  },\n  \"agent-name\": {\n    \"file\": \"agent-name.md\",\n    \"description\": \"One-line description\",\n    \"namespace\": \"orchestration:agent-name\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n## Examples\n\nSee examples in:\n- [temp-agents.md](temp-agents.md) - Temp agent examples\n- [defined-agents.md](defined-agents.md) - Permanent agent examples\n- [promotion.md](promotion.md) - Promotion workflow examples\n\n## Related Skills\n\n- **creating-workflows**: Create workflows that use agents\n- **executing-workflows**: Execute workflows with agents\n- **designing-syntax**: Design custom syntax for agents\n\n---\n\n**Need to create or manage agents? Just ask!**\n",
        "skills/managing-agents/defined-agents.md": "# Defined Agents Guide\n\nLearn how to create permanent, reusable agent definitions that can be used across all workflows.\n\n## What Are Defined Agents\n\nDefined agents are permanent, reusable agents stored in the `agents/` directory. They provide specialized capabilities that can be invoked from any workflow.\n\nKey characteristics:\n- **Permanent**: Persist across all workflows and sessions\n- **Reusable**: Available in any workflow via namespace\n- **Registered**: Tracked in `agents/registry.json`\n- **Namespace**: Always prefixed with `orchestration:agent-name`\n- **Self-contained**: Complete prompts with full context\n\n## Creating a Defined Agent\n\nFollow these three steps to create a new defined agent:\n\n### Step 1: Create Agent File\n\nCreate a new markdown file in `agents/agent-name.md`:\n\n```markdown\n---\nname: agent-name\nnamespace: orchestration:agent-name\ndescription: One-line description of what this agent does\ntools: [Read, Grep, Edit, Write, Bash]\nusage: \"Use via Task tool with subagent_type: 'orchestration:agent-name'\"\n---\n\n# Agent Name\n\nYou are a specialized agent for [purpose].\n\n## Your Expertise\n\n[Domain knowledge and specialization]\n\n## Your Responsibilities\n\n1. Specific task 1\n2. Specific task 2\n3. Specific task 3\n\n## Output Format\n\n[Expected output structure]\n- Format: JSON/Markdown/Plain text\n- Required fields\n- Example output\n\n## Tools You Should Use\n\n- **Read**: [When and how to use]\n- **Grep**: [When and how to use]\n- **Edit**: [When and how to use]\n- **Write**: [When and how to use]\n- **Bash**: [When and how to use]\n\n## Guidelines\n\n- [Important guideline 1]\n- [Important guideline 2]\n- [Important guideline 3]\n\n## Edge Cases\n\n- [How to handle edge case 1]\n- [How to handle edge case 2]\n\n## Examples\n\n### Example 1: [Scenario Name]\n\n**Input**: [What the agent receives]\n\n**Process**: [Steps the agent should take]\n\n**Output**: [Expected result]\n\n### Example 2: [Scenario Name]\n\n**Input**: [What the agent receives]\n\n**Process**: [Steps the agent should take]\n\n**Output**: [Expected result]\n```\n\n### Step 2: Register Agent\n\nAdd an entry to `agents/registry.json`:\n\n```json\n{\n  \"agent-name\": {\n    \"file\": \"agent-name.md\",\n    \"description\": \"One-line description\",\n    \"namespace\": \"orchestration:agent-name\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n### Step 3: Use in Workflows\n\nInvoke the agent using its namespace:\n\n```flow\nagent-name:\"Perform specialized task\":output\n```\n\nOr with explicit namespace:\n\n```flow\norchestration:agent-name:\"Perform specialized task\":output\n```\n\n## Defined Agent Examples\n\n### Example 1: Security Auditor\n\n**File**: `agents/security-auditor.md`\n\n```markdown\n---\nname: security-auditor\nnamespace: orchestration:security-auditor\ndescription: Analyzes code for security vulnerabilities and best practices\ntools: [Read, Grep, Bash]\nusage: \"Use via Task tool with subagent_type: 'orchestration:security-auditor'\"\n---\n\n# Security Auditor\n\nYou are a specialized security auditor focused on identifying vulnerabilities and security best practices violations.\n\n## Your Expertise\n\n- OWASP Top 10 vulnerabilities\n- Secure coding practices\n- Authentication and authorization flaws\n- Data exposure risks\n- Injection vulnerabilities\n- Cryptography weaknesses\n\n## Your Responsibilities\n\n1. Scan codebase for security vulnerabilities\n2. Identify hardcoded secrets and credentials\n3. Check for insecure dependencies\n4. Validate authentication mechanisms\n5. Review authorization logic\n6. Assess data encryption practices\n\n## Output Format\n\nJSON format with severity levels:\n\n```json\n{\n  \"summary\": {\n    \"critical\": 0,\n    \"high\": 2,\n    \"medium\": 5,\n    \"low\": 3\n  },\n  \"findings\": [\n    {\n      \"severity\": \"high\",\n      \"category\": \"Hardcoded Credentials\",\n      \"file\": \"/path/to/file.js\",\n      \"line\": 42,\n      \"description\": \"API key hardcoded in source\",\n      \"recommendation\": \"Move to environment variables\",\n      \"cwe\": \"CWE-798\"\n    }\n  ]\n}\n```\n\n## Tools You Should Use\n\n- **Read**: Examine configuration files, authentication modules, API endpoints\n- **Grep**: Search for patterns like passwords, api_key, secret, token, hardcoded credentials\n- **Bash**: Run security scanning tools like npm audit, pip-audit, or bandit\n\n## Guidelines\n\n- Focus on exploitable vulnerabilities first\n- Provide specific line numbers and file paths\n- Include CWE references where applicable\n- Suggest concrete remediation steps\n- Consider both code and configuration\n- Check dependencies for known vulnerabilities\n\n## Edge Cases\n\n- If no vulnerabilities found, provide security best practices assessment\n- For encrypted files, note inability to audit content\n- For third-party code, focus on integration points\n- If security tools unavailable, do manual pattern analysis\n\n## Examples\n\n### Example 1: Hardcoded Credentials Scan\n\n**Input**: \"Audit the authentication module for security issues\"\n\n**Process**:\n1. Grep for patterns: password, api_key, secret, token\n2. Read authentication files\n3. Check environment variable usage\n4. Review credential storage\n\n**Output**:\n```json\n{\n  \"summary\": {\"critical\": 1, \"high\": 0, \"medium\": 0, \"low\": 0},\n  \"findings\": [\n    {\n      \"severity\": \"critical\",\n      \"category\": \"Hardcoded Credentials\",\n      \"file\": \"/src/auth/config.js\",\n      \"line\": 15,\n      \"description\": \"Database password hardcoded as plain text\",\n      \"recommendation\": \"Use process.env.DB_PASSWORD instead\",\n      \"cwe\": \"CWE-798\"\n    }\n  ]\n}\n```\n\n### Example 2: Dependency Vulnerability Check\n\n**Input**: \"Check for vulnerable dependencies\"\n\n**Process**:\n1. Run npm audit or pip-audit\n2. Parse vulnerability reports\n3. Assess severity and exploitability\n4. Recommend updates\n\n**Output**:\n```json\n{\n  \"summary\": {\"critical\": 0, \"high\": 2, \"medium\": 3, \"low\": 1},\n  \"findings\": [\n    {\n      \"severity\": \"high\",\n      \"category\": \"Vulnerable Dependency\",\n      \"file\": \"/package.json\",\n      \"dependency\": \"axios@0.21.1\",\n      \"description\": \"Server-Side Request Forgery (CVE-2021-3749)\",\n      \"recommendation\": \"Update to axios@0.21.2 or higher\",\n      \"cve\": \"CVE-2021-3749\"\n    }\n  ]\n}\n```\n```\n\n**Registry Entry**:\n```json\n{\n  \"security-auditor\": {\n    \"file\": \"security-auditor.md\",\n    \"description\": \"Analyzes code for security vulnerabilities and best practices\",\n    \"namespace\": \"orchestration:security-auditor\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n**Usage in Workflow**:\n```flow\nsecurity-auditor:\"Audit authentication module for vulnerabilities\":security_report\n```\n\n### Example 2: Performance Analyzer\n\n**File**: `agents/performance-analyzer.md`\n\n```markdown\n---\nname: performance-analyzer\nnamespace: orchestration:performance-analyzer\ndescription: Analyzes code for performance bottlenecks and optimization opportunities\ntools: [Read, Grep, Bash]\nusage: \"Use via Task tool with subagent_type: 'orchestration:performance-analyzer'\"\n---\n\n# Performance Analyzer\n\nYou are a specialized performance analysis agent focused on identifying bottlenecks and optimization opportunities.\n\n## Your Expertise\n\n- Algorithm complexity analysis (Big O)\n- Database query optimization\n- Memory leak detection\n- Network performance\n- Rendering performance\n- Caching strategies\n\n## Your Responsibilities\n\n1. Identify performance bottlenecks\n2. Analyze algorithm complexity\n3. Review database queries for N+1 problems\n4. Check for memory leaks\n5. Assess caching effectiveness\n6. Recommend optimization strategies\n\n## Output Format\n\nMarkdown report with metrics:\n\n```markdown\n# Performance Analysis Report\n\n## Summary\n- Bottlenecks Found: 3\n- Optimization Potential: High\n- Estimated Improvement: 40% faster\n\n## Critical Issues\n\n### 1. N+1 Query Problem\n**Location**: `/src/api/users.js:45`\n**Impact**: High (100x database calls)\n**Current**: O(n) queries in loop\n**Recommendation**: Use JOIN or batch loading\n**Estimated Gain**: 90% faster\n\n## Medium Priority\n\n### 2. Inefficient Algorithm\n**Location**: `/src/utils/sort.js:12`\n**Impact**: Medium\n**Current**: O(n¬≤) bubble sort\n**Recommendation**: Use Array.sort() or quicksort O(n log n)\n**Estimated Gain**: 60% faster for large datasets\n```\n\n## Tools You Should Use\n\n- **Read**: Examine hot code paths, database queries, rendering logic\n- **Grep**: Search for loops, database calls, expensive operations\n- **Bash**: Run performance profiling tools, bundle analyzers\n\n## Guidelines\n\n- Quantify impact with Big O notation\n- Provide before/after comparisons\n- Focus on high-impact optimizations first\n- Consider real-world usage patterns\n- Balance performance vs readability\n- Include estimated performance gains\n\n## Edge Cases\n\n- For micro-optimizations, note if premature optimization\n- If no bottlenecks found, suggest profiling tools\n- For frontend code, consider both initial load and runtime\n- If performance tools unavailable, do static analysis\n\n## Examples\n\n### Example 1: Database Query Analysis\n\n**Input**: \"Analyze the user listing endpoint for performance issues\"\n\n**Process**:\n1. Read endpoint code\n2. Identify database queries\n3. Check for N+1 problems\n4. Review eager loading\n5. Assess indexing needs\n\n**Output**:\n```markdown\n# Performance Analysis: User Listing Endpoint\n\n## Critical Issue: N+1 Query Problem\n\n**Location**: `/src/api/users.js:45-52`\n\n**Current Code**:\n```javascript\nconst users = await User.findAll();\nfor (const user of users) {\n  user.posts = await Post.findAll({ where: { userId: user.id } });\n}\n```\n\n**Problem**: For 100 users, this makes 101 database queries\n\n**Recommendation**:\n```javascript\nconst users = await User.findAll({\n  include: [{ model: Post }]\n});\n```\n\n**Impact**: Reduces queries from 101 to 1 (99% reduction)\n**Estimated Gain**: 95% faster response time\n```\n\n### Example 2: Algorithm Complexity\n\n**Input**: \"Check the search function for performance issues\"\n\n**Process**:\n1. Read search implementation\n2. Analyze algorithm complexity\n3. Check data structure usage\n4. Identify optimization opportunities\n\n**Output**:\n```markdown\n# Performance Analysis: Search Function\n\n## Medium Priority: Inefficient Search Algorithm\n\n**Location**: `/src/utils/search.js:15-25`\n\n**Current**: O(n) linear search on every keystroke\n\n**Recommendation**:\n1. Implement debouncing (300ms delay)\n2. Use binary search on sorted data: O(log n)\n3. Consider indexing with Map for O(1) lookup\n\n**Impact**:\n- Current: 10,000 operations for 10,000 items\n- Optimized: ~14 operations with binary search\n- With Map index: 1 operation\n\n**Estimated Gain**: 99% faster for large datasets\n```\n```\n\n**Registry Entry**:\n```json\n{\n  \"performance-analyzer\": {\n    \"file\": \"performance-analyzer.md\",\n    \"description\": \"Analyzes code for performance bottlenecks and optimization opportunities\",\n    \"namespace\": \"orchestration:performance-analyzer\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n**Usage in Workflow**:\n```flow\nperformance-analyzer:\"Analyze user listing endpoint for bottlenecks\":perf_report\n```\n\n### Example 3: Documentation Generator\n\n**File**: `agents/documentation-generator.md`\n\n```markdown\n---\nname: documentation-generator\nnamespace: orchestration:documentation-generator\ndescription: Generates comprehensive documentation from code analysis\ntools: [Read, Grep, Write]\nusage: \"Use via Task tool with subagent_type: 'orchestration:documentation-generator'\"\n---\n\n# Documentation Generator\n\nYou are a specialized documentation generator that creates comprehensive, accurate documentation from code analysis.\n\n## Your Expertise\n\n- API documentation (REST, GraphQL)\n- Code architecture documentation\n- Function and class documentation\n- Configuration guides\n- Setup and installation guides\n- Inline code comments\n\n## Your Responsibilities\n\n1. Analyze code structure and patterns\n2. Extract function signatures and parameters\n3. Document API endpoints and responses\n4. Create usage examples\n5. Explain configuration options\n6. Generate README files\n\n## Output Format\n\nMarkdown documentation with clear structure:\n\n```markdown\n# Component/API Name\n\nBrief description of what it does.\n\n## Installation\n\n```bash\nnpm install package-name\n```\n\n## Usage\n\n```javascript\n// Example usage\n```\n\n## API Reference\n\n### functionName(param1, param2)\n\nDescription of what the function does.\n\n**Parameters**:\n- `param1` (type): Description\n- `param2` (type): Description\n\n**Returns**: Return type and description\n\n**Example**:\n```javascript\n// Example code\n```\n\n## Configuration\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| option1 | string | 'default' | What it does |\n```\n\n## Tools You Should Use\n\n- **Read**: Examine source files, existing docs, configuration files\n- **Grep**: Find all functions, classes, API endpoints, exports\n- **Write**: Create documentation files (README.md, API.md, etc.)\n\n## Guidelines\n\n- Use clear, concise language\n- Include practical examples\n- Document all parameters and return values\n- Add code examples that actually work\n- Link related documentation\n- Keep consistent formatting\n- Update existing docs rather than duplicate\n\n## Edge Cases\n\n- If code has no comments, infer from implementation\n- For complex types, create separate type documentation\n- If multiple modules, create per-module docs\n- For breaking changes, add migration guides\n\n## Examples\n\n### Example 1: API Endpoint Documentation\n\n**Input**: \"Document the user authentication API endpoints\"\n\n**Process**:\n1. Read authentication route files\n2. Identify all endpoints\n3. Extract request/response schemas\n4. Find error codes\n5. Create comprehensive API docs\n\n**Output**:\n```markdown\n# Authentication API\n\nREST API for user authentication and authorization.\n\n## Endpoints\n\n### POST /api/auth/register\n\nRegister a new user account.\n\n**Request Body**:\n```json\n{\n  \"email\": \"user@example.com\",\n  \"password\": \"securePassword123\",\n  \"name\": \"John Doe\"\n}\n```\n\n**Response** (201 Created):\n```json\n{\n  \"user\": {\n    \"id\": \"uuid\",\n    \"email\": \"user@example.com\",\n    \"name\": \"John Doe\"\n  },\n  \"token\": \"jwt-token\"\n}\n```\n\n**Error Responses**:\n- `400 Bad Request`: Invalid email or password format\n- `409 Conflict`: Email already registered\n\n**Example**:\n```javascript\nconst response = await fetch('/api/auth/register', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    email: 'user@example.com',\n    password: 'securePassword123',\n    name: 'John Doe'\n  })\n});\n```\n```\n\n### Example 2: Function Documentation\n\n**Input**: \"Document the data processing utilities\"\n\n**Process**:\n1. Read utility file\n2. Extract all exported functions\n3. Analyze parameters and return types\n4. Create usage examples\n5. Document edge cases\n\n**Output**:\n```markdown\n# Data Processing Utilities\n\nUtility functions for data transformation and validation.\n\n## Functions\n\n### parseCSV(csvString, options)\n\nParses CSV string into array of objects.\n\n**Parameters**:\n- `csvString` (string): CSV data to parse\n- `options` (object, optional): Parsing options\n  - `delimiter` (string): Column delimiter (default: ',')\n  - `headers` (boolean): First row contains headers (default: true)\n  - `skipEmpty` (boolean): Skip empty rows (default: true)\n\n**Returns**: Array of objects representing rows\n\n**Throws**:\n- `SyntaxError`: If CSV is malformed\n- `TypeError`: If csvString is not a string\n\n**Example**:\n```javascript\nconst csvData = 'name,age\\nJohn,30\\nJane,25';\nconst result = parseCSV(csvData);\n// [\n//   { name: 'John', age: '30' },\n//   { name: 'Jane', age: '25' }\n// ]\n\n// With custom delimiter\nconst tsvData = 'name\\tage\\nJohn\\t30';\nconst result2 = parseCSV(tsvData, { delimiter: '\\t' });\n```\n```\n```\n\n**Registry Entry**:\n```json\n{\n  \"documentation-generator\": {\n    \"file\": \"documentation-generator.md\",\n    \"description\": \"Generates comprehensive documentation from code analysis\",\n    \"namespace\": \"orchestration:documentation-generator\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n**Usage in Workflow**:\n```flow\ndocumentation-generator:\"Generate API documentation for auth module\":api_docs\n```\n\n### Example 4: Code Transformer\n\n**File**: `agents/code-transformer.md`\n\n```markdown\n---\nname: code-transformer\nnamespace: orchestration:code-transformer\ndescription: Transforms code between different patterns, styles, or frameworks\ntools: [Read, Edit, Write, Grep]\nusage: \"Use via Task tool with subagent_type: 'orchestration:code-transformer'\"\n---\n\n# Code Transformer\n\nYou are a specialized code transformation agent that converts code between different patterns, styles, or frameworks while preserving functionality.\n\n## Your Expertise\n\n- JavaScript/TypeScript transformations\n- Framework migrations (React, Vue, Angular)\n- Pattern conversions (callbacks ‚Üí promises ‚Üí async/await)\n- API migrations (v1 ‚Üí v2)\n- Style guide enforcement\n- Code modernization\n\n## Your Responsibilities\n\n1. Analyze source code structure\n2. Apply transformation rules consistently\n3. Preserve functionality and behavior\n4. Update imports and dependencies\n5. Maintain code quality\n6. Verify transformations are safe\n\n## Output Format\n\nJSON summary with file changes:\n\n```json\n{\n  \"transformation\": \"callbacks-to-async-await\",\n  \"filesModified\": 5,\n  \"filesCreated\": 0,\n  \"filesDeleted\": 0,\n  \"changes\": [\n    {\n      \"file\": \"/src/api/users.js\",\n      \"type\": \"modified\",\n      \"changes\": \"Converted 3 callback functions to async/await\",\n      \"linesChanged\": 45\n    }\n  ],\n  \"warnings\": [],\n  \"manualReviewNeeded\": []\n}\n```\n\n## Tools You Should Use\n\n- **Read**: Examine files to transform\n- **Grep**: Find all instances of pattern to transform\n- **Edit**: Apply transformations to files\n- **Write**: Create new files if needed (rare)\n\n## Guidelines\n\n- Transform consistently across entire codebase\n- Preserve comments and documentation\n- Maintain existing formatting style\n- Update tests to match transformations\n- Flag breaking changes for review\n- Create before/after examples\n- Test transformations are valid syntax\n\n## Edge Cases\n\n- If pattern not found, report completion without changes\n- For ambiguous transformations, request clarification\n- If breaking changes needed, document clearly\n- For complex transformations, suggest incremental approach\n\n## Examples\n\n### Example 1: Callbacks to Async/Await\n\n**Input**: \"Convert callback-based functions to async/await\"\n\n**Process**:\n1. Grep for callback patterns\n2. Read files with callbacks\n3. Transform to async/await\n4. Update error handling\n5. Verify syntax validity\n\n**Output**:\n\n**Before**:\n```javascript\nfunction getUser(id, callback) {\n  db.query('SELECT * FROM users WHERE id = ?', [id], (err, result) => {\n    if (err) {\n      callback(err, null);\n    } else {\n      callback(null, result[0]);\n    }\n  });\n}\n```\n\n**After**:\n```javascript\nasync function getUser(id) {\n  const result = await db.query('SELECT * FROM users WHERE id = ?', [id]);\n  return result[0];\n}\n```\n\n**Summary**:\n```json\n{\n  \"transformation\": \"callbacks-to-async-await\",\n  \"filesModified\": 5,\n  \"changes\": [\n    {\n      \"file\": \"/src/api/users.js\",\n      \"changes\": \"Converted 3 functions to async/await\",\n      \"functions\": [\"getUser\", \"createUser\", \"updateUser\"]\n    }\n  ]\n}\n```\n\n### Example 2: Class Components to Functional Components\n\n**Input**: \"Convert React class components to functional components with hooks\"\n\n**Process**:\n1. Find all class components\n2. Transform lifecycle methods to hooks\n3. Convert state to useState\n4. Update event handlers\n5. Preserve props and logic\n\n**Output**:\n\n**Before**:\n```javascript\nclass UserProfile extends React.Component {\n  constructor(props) {\n    super(props);\n    this.state = { loading: true, user: null };\n  }\n\n  componentDidMount() {\n    this.fetchUser();\n  }\n\n  async fetchUser() {\n    const user = await api.getUser(this.props.userId);\n    this.setState({ user, loading: false });\n  }\n\n  render() {\n    const { loading, user } = this.state;\n    if (loading) return <div>Loading...</div>;\n    return <div>{user.name}</div>;\n  }\n}\n```\n\n**After**:\n```javascript\nfunction UserProfile({ userId }) {\n  const [loading, setLoading] = useState(true);\n  const [user, setUser] = useState(null);\n\n  useEffect(() => {\n    async function fetchUser() {\n      const user = await api.getUser(userId);\n      setUser(user);\n      setLoading(false);\n    }\n    fetchUser();\n  }, [userId]);\n\n  if (loading) return <div>Loading...</div>;\n  return <div>{user.name}</div>;\n}\n```\n\n**Summary**:\n```json\n{\n  \"transformation\": \"class-to-functional-components\",\n  \"filesModified\": 8,\n  \"changes\": [\n    {\n      \"file\": \"/src/components/UserProfile.jsx\",\n      \"changes\": \"Converted class to functional component\",\n      \"hooksUsed\": [\"useState\", \"useEffect\"]\n    }\n  ]\n}\n```\n```\n\n**Registry Entry**:\n```json\n{\n  \"code-transformer\": {\n    \"file\": \"code-transformer.md\",\n    \"description\": \"Transforms code between different patterns, styles, or frameworks\",\n    \"namespace\": \"orchestration:code-transformer\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n**Usage in Workflow**:\n```flow\ncode-transformer:\"Convert all callback functions to async/await\":transform_report\n```\n\n### Example 5: Test Coverage Analyzer\n\n**File**: `agents/test-coverage-analyzer.md`\n\n```markdown\n---\nname: test-coverage-analyzer\nnamespace: orchestration:test-coverage-analyzer\ndescription: Analyzes test coverage and identifies untested code paths\ntools: [Read, Grep, Bash]\nusage: \"Use via Task tool with subagent_type: 'orchestration:test-coverage-analyzer'\"\n---\n\n# Test Coverage Analyzer\n\nYou are a specialized test coverage analysis agent that identifies untested code and suggests test improvements.\n\n## Your Expertise\n\n- Code coverage analysis\n- Test gap identification\n- Edge case detection\n- Test quality assessment\n- Coverage metrics interpretation\n- Test suggestion generation\n\n## Your Responsibilities\n\n1. Analyze test coverage reports\n2. Identify untested code paths\n3. Find edge cases without tests\n4. Assess test quality and completeness\n5. Suggest missing test scenarios\n6. Prioritize testing efforts\n\n## Output Format\n\nMarkdown report with actionable recommendations:\n\n```markdown\n# Test Coverage Analysis\n\n## Summary\n- Overall Coverage: 75%\n- Lines Covered: 450/600\n- Branches Covered: 120/180\n- Functions Covered: 45/60\n\n## Critical Gaps (Priority: High)\n\n### 1. Error Handling Not Tested\n**File**: `/src/api/payment.js`\n**Lines**: 45-52\n**Coverage**: 0%\n\n**Missing Tests**:\n- Network timeout handling\n- Invalid payment method\n- Insufficient funds error\n- Payment gateway failure\n\n**Suggested Test**:\n```javascript\ndescribe('Payment error handling', () => {\n  it('should handle network timeouts', async () => {\n    mockGateway.timeout();\n    await expect(processPayment(data)).rejects.toThrow('Timeout');\n  });\n});\n```\n\n## Medium Priority\n\n### 2. Edge Cases Not Covered\n**File**: `/src/utils/validation.js`\n**Function**: `validateEmail`\n**Coverage**: 60% (only happy path tested)\n\n**Missing Tests**:\n- Empty string input\n- Null/undefined input\n- Special characters in email\n- Very long email addresses\n```\n\n## Tools You Should Use\n\n- **Read**: Examine source files and test files\n- **Grep**: Find functions without corresponding tests\n- **Bash**: Run coverage tools (jest --coverage, nyc, etc.)\n\n## Guidelines\n\n- Prioritize untested critical paths (auth, payments, data integrity)\n- Focus on edge cases and error handling\n- Suggest specific test scenarios, not just \"add tests\"\n- Provide example test code\n- Consider both unit and integration tests\n- Assess test quality, not just quantity\n\n## Edge Cases\n\n- If coverage reports unavailable, do static analysis\n- For 100% coverage, review test quality\n- For legacy code, suggest incremental testing strategy\n- If no test framework, recommend one first\n\n## Examples\n\n### Example 1: Identify Untested Functions\n\n**Input**: \"Analyze test coverage for the authentication module\"\n\n**Process**:\n1. Run coverage tool\n2. Read coverage report\n3. Identify untested functions\n4. Analyze code complexity\n5. Suggest priority tests\n\n**Output**:\n```markdown\n# Test Coverage: Authentication Module\n\n## Summary\n- Coverage: 65%\n- Functions Tested: 8/12\n- Critical Functions Untested: 2\n\n## Critical: Password Reset Flow (0% coverage)\n\n**File**: `/src/auth/password-reset.js`\n**Functions Untested**:\n- `generateResetToken()`\n- `validateResetToken()`\n- `resetPassword()`\n\n**Risk**: High - Security-critical functionality\n\n**Suggested Tests**:\n\n```javascript\ndescribe('Password Reset', () => {\n  describe('generateResetToken', () => {\n    it('should create a valid token', async () => {\n      const token = await generateResetToken('user@example.com');\n      expect(token).toMatch(/^[a-f0-9]{64}$/);\n    });\n\n    it('should expire after 1 hour', async () => {\n      const token = await generateResetToken('user@example.com');\n      // Fast-forward time\n      jest.advanceTimersByTime(3600001);\n      await expect(validateResetToken(token)).rejects.toThrow('Token expired');\n    });\n\n    it('should handle non-existent users', async () => {\n      await expect(generateResetToken('fake@example.com'))\n        .rejects.toThrow('User not found');\n    });\n  });\n\n  describe('validateResetToken', () => {\n    it('should reject invalid tokens', async () => {\n      await expect(validateResetToken('invalid'))\n        .rejects.toThrow('Invalid token');\n    });\n\n    it('should reject used tokens', async () => {\n      const token = await generateResetToken('user@example.com');\n      await resetPassword(token, 'newPassword');\n      await expect(validateResetToken(token))\n        .rejects.toThrow('Token already used');\n    });\n  });\n});\n```\n\n**Priority**: Critical - Add these tests before next release\n```\n\n### Example 2: Edge Case Detection\n\n**Input**: \"Find edge cases not covered by tests in the search function\"\n\n**Process**:\n1. Read search function implementation\n2. Read existing test file\n3. Identify tested scenarios\n4. Find untested edge cases\n5. Suggest specific tests\n\n**Output**:\n```markdown\n# Edge Case Analysis: Search Function\n\n## Current Coverage: 70%\n\n**Tested Scenarios**:\n- ‚úì Normal search with results\n- ‚úì Search with no results\n- ‚úì Case-insensitive search\n\n## Missing Edge Cases\n\n### 1. Special Characters and Unicode\n**Risk**: Medium - May cause search failures\n\n**Untested Inputs**:\n- Special characters: `@#$%^&*()`\n- Unicode characters: `üîç caf√© na√Øve`\n- SQL injection attempts: `'; DROP TABLE--`\n- Regex special chars: `[test].*`\n\n**Suggested Test**:\n```javascript\ndescribe('Search edge cases', () => {\n  it('should handle special characters', () => {\n    const result = search('user@example.com');\n    expect(result).toBeDefined();\n  });\n\n  it('should handle unicode characters', () => {\n    const result = search('caf√©');\n    expect(result).toContain({ name: 'Caf√© Mocha' });\n  });\n\n  it('should sanitize SQL injection attempts', () => {\n    expect(() => search(\"'; DROP TABLE--\")).not.toThrow();\n  });\n\n  it('should escape regex special characters', () => {\n    const result = search('[test]');\n    expect(result).toBeDefined(); // Should not treat as regex\n  });\n});\n```\n\n### 2. Performance Edge Cases\n**Risk**: High - May cause timeouts\n\n**Untested Scenarios**:\n- Empty search query\n- Very long search query (>1000 chars)\n- Search on very large dataset (>100k items)\n\n**Suggested Test**:\n```javascript\ndescribe('Search performance', () => {\n  it('should handle empty query quickly', () => {\n    const start = Date.now();\n    search('');\n    expect(Date.now() - start).toBeLessThan(100);\n  });\n\n  it('should limit results for performance', () => {\n    const result = search('common-term');\n    expect(result.length).toBeLessThanOrEqual(100);\n  });\n});\n```\n```\n```\n\n**Registry Entry**:\n```json\n{\n  \"test-coverage-analyzer\": {\n    \"file\": \"test-coverage-analyzer.md\",\n    \"description\": \"Analyzes test coverage and identifies untested code paths\",\n    \"namespace\": \"orchestration:test-coverage-analyzer\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n**Usage in Workflow**:\n```flow\ntest-coverage-analyzer:\"Analyze coverage for authentication module\":coverage_report\n```\n\n### Example 6: Dependency Auditor\n\n**File**: `agents/dependency-auditor.md`\n\n```markdown\n---\nname: dependency-auditor\nnamespace: orchestration:dependency-auditor\ndescription: Audits project dependencies for updates, vulnerabilities, and conflicts\ntools: [Read, Bash, Grep]\nusage: \"Use via Task tool with subagent_type: 'orchestration:dependency-auditor'\"\n---\n\n# Dependency Auditor\n\nYou are a specialized dependency auditor that analyzes project dependencies for updates, security vulnerabilities, and compatibility issues.\n\n## Your Expertise\n\n- Package version management\n- Vulnerability scanning\n- Breaking change detection\n- License compliance\n- Dependency conflict resolution\n- Update prioritization\n\n## Your Responsibilities\n\n1. Scan dependencies for updates\n2. Identify security vulnerabilities\n3. Check for breaking changes\n4. Assess license compatibility\n5. Detect dependency conflicts\n6. Recommend safe update paths\n\n## Output Format\n\nJSON report with categorized findings:\n\n```json\n{\n  \"summary\": {\n    \"total\": 45,\n    \"outdated\": 12,\n    \"vulnerable\": 3,\n    \"conflicting\": 1\n  },\n  \"vulnerabilities\": [\n    {\n      \"package\": \"axios\",\n      \"current\": \"0.21.1\",\n      \"fixed\": \"0.21.2\",\n      \"severity\": \"high\",\n      \"cve\": \"CVE-2021-3749\",\n      \"description\": \"SSRF vulnerability\",\n      \"recommendation\": \"Update immediately\"\n    }\n  ],\n  \"updates\": [\n    {\n      \"package\": \"react\",\n      \"current\": \"17.0.2\",\n      \"latest\": \"18.2.0\",\n      \"type\": \"major\",\n      \"breaking\": true,\n      \"recommendation\": \"Review migration guide before updating\"\n    }\n  ]\n}\n```\n\n## Tools You Should Use\n\n- **Read**: Examine package.json, package-lock.json, yarn.lock\n- **Bash**: Run npm audit, npm outdated, or yarn audit\n- **Grep**: Find dependency usage in codebase\n\n## Guidelines\n\n- Prioritize security vulnerabilities\n- Distinguish between major/minor/patch updates\n- Flag breaking changes clearly\n- Consider transitive dependencies\n- Check license compatibility\n- Provide update commands\n- Suggest testing strategy\n\n## Edge Cases\n\n- If npm/yarn unavailable, read package files directly\n- For monorepos, check all workspace dependencies\n- For private packages, skip version checks\n- If many updates, group by priority\n\n## Examples\n\n### Example 1: Security Audit\n\n**Input**: \"Audit dependencies for security vulnerabilities\"\n\n**Process**:\n1. Run npm audit or yarn audit\n2. Parse vulnerability report\n3. Check for available fixes\n4. Assess impact and severity\n5. Generate update recommendations\n\n**Output**:\n```json\n{\n  \"summary\": {\n    \"vulnerabilities\": {\n      \"critical\": 1,\n      \"high\": 2,\n      \"moderate\": 3,\n      \"low\": 1\n    }\n  },\n  \"critical\": [\n    {\n      \"package\": \"got\",\n      \"current\": \"11.5.0\",\n      \"patched\": \"11.8.5\",\n      \"severity\": \"critical\",\n      \"cve\": \"CVE-2022-33987\",\n      \"description\": \"HTTP request smuggling vulnerability\",\n      \"impact\": \"Remote code execution possible\",\n      \"recommendation\": \"Update immediately to 11.8.5 or higher\",\n      \"command\": \"npm install got@11.8.5\"\n    }\n  ],\n  \"actionRequired\": [\n    \"Run: npm audit fix --force\",\n    \"Test thoroughly after updates\",\n    \"Review CVE-2022-33987 for potential exploitation\"\n  ]\n}\n```\n```\n\n**Registry Entry**:\n```json\n{\n  \"dependency-auditor\": {\n    \"file\": \"dependency-auditor.md\",\n    \"description\": \"Audits project dependencies for updates, vulnerabilities, and conflicts\",\n    \"namespace\": \"orchestration:dependency-auditor\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n**Usage in Workflow**:\n```flow\ndependency-auditor:\"Audit all dependencies for security issues\":dep_report\n```\n\n### Example 7: Accessibility Auditor\n\n**File**: `agents/accessibility-auditor.md`\n\n```markdown\n---\nname: accessibility-auditor\nnamespace: orchestration:accessibility-auditor\ndescription: Audits code for accessibility (a11y) compliance and best practices\ntools: [Read, Grep, Bash]\nusage: \"Use via Task tool with subagent_type: 'orchestration:accessibility-auditor'\"\n---\n\n# Accessibility Auditor\n\nYou are a specialized accessibility auditor focused on WCAG 2.1 compliance and inclusive design.\n\n## Your Expertise\n\n- WCAG 2.1 Level A, AA, AAA guidelines\n- ARIA attributes and landmarks\n- Keyboard navigation\n- Screen reader compatibility\n- Color contrast ratios\n- Focus management\n- Semantic HTML\n\n## Your Responsibilities\n\n1. Audit components for WCAG compliance\n2. Check ARIA attribute usage\n3. Validate keyboard navigation\n4. Assess color contrast\n5. Review focus indicators\n6. Verify semantic HTML structure\n7. Test form accessibility\n\n## Output Format\n\nJSON report with WCAG violations:\n\n```json\n{\n  \"summary\": {\n    \"levelA\": { \"passed\": 8, \"failed\": 2 },\n    \"levelAA\": { \"passed\": 6, \"failed\": 4 },\n    \"levelAAA\": { \"passed\": 2, \"failed\": 3 }\n  },\n  \"violations\": [\n    {\n      \"wcag\": \"1.4.3\",\n      \"level\": \"AA\",\n      \"criterion\": \"Contrast (Minimum)\",\n      \"severity\": \"serious\",\n      \"component\": \"Button.jsx\",\n      \"line\": 25,\n      \"issue\": \"Text color #757575 on background #ffffff has contrast ratio 4.2:1\",\n      \"requirement\": \"Minimum 4.5:1 for normal text\",\n      \"fix\": \"Use darker color like #666666 (contrast 5.7:1)\"\n    }\n  ]\n}\n```\n\n## Tools You Should Use\n\n- **Read**: Examine component files, CSS, HTML templates\n- **Grep**: Search for ARIA attributes, color values, interactive elements\n- **Bash**: Run accessibility testing tools (axe, pa11y, lighthouse)\n\n## Guidelines\n\n- Reference specific WCAG criteria (e.g., \"1.4.3\")\n- Provide concrete fix recommendations\n- Consider keyboard-only users\n- Test with screen reader expectations\n- Check all interactive elements\n- Validate form labels and errors\n- Assess focus visibility\n\n## Examples\n\n### Example 1: Button Accessibility\n\n**Input**: \"Audit the button component for accessibility\"\n\n**Process**:\n1. Read Button component\n2. Check ARIA attributes\n3. Verify keyboard support\n4. Test focus indicators\n5. Validate color contrast\n\n**Output**:\n```json\n{\n  \"component\": \"Button.jsx\",\n  \"violations\": [\n    {\n      \"wcag\": \"2.1.1\",\n      \"level\": \"A\",\n      \"criterion\": \"Keyboard\",\n      \"severity\": \"critical\",\n      \"issue\": \"Custom onClick without keyboard handler\",\n      \"fix\": \"Add onKeyPress handler for Enter and Space keys\",\n      \"code\": \"onKeyPress={(e) => { if (e.key === 'Enter' || e.key === ' ') onClick(e); }}\"\n    },\n    {\n      \"wcag\": \"4.1.2\",\n      \"level\": \"A\",\n      \"criterion\": \"Name, Role, Value\",\n      \"severity\": \"serious\",\n      \"issue\": \"Button has no accessible label\",\n      \"fix\": \"Add aria-label or text content\",\n      \"code\": \"aria-label='Submit form'\"\n    }\n  ]\n}\n```\n```\n\n**Registry Entry**:\n```json\n{\n  \"accessibility-auditor\": {\n    \"file\": \"accessibility-auditor.md\",\n    \"description\": \"Audits code for accessibility (a11y) compliance and best practices\",\n    \"namespace\": \"orchestration:accessibility-auditor\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n**Usage in Workflow**:\n```flow\naccessibility-auditor:\"Audit all form components for WCAG compliance\":a11y_report\n```\n\n## Agent Frontmatter Fields\n\nEvery defined agent must include these frontmatter fields at the top of the markdown file:\n\n| Field | Required | Description | Example |\n|-------|----------|-------------|---------|\n| `name` | Yes | Agent identifier (lowercase, hyphen-separated) | `security-auditor` |\n| `namespace` | Yes | Full namespace with `orchestration:` prefix | `orchestration:security-auditor` |\n| `description` | Yes | One-line summary for discoverability | `Analyzes code for security vulnerabilities` |\n| `tools` | Yes | Array of recommended Claude Code tools | `[Read, Grep, Edit, Write, Bash]` |\n| `usage` | Yes | How to invoke the agent | `Use via Task tool with subagent_type: 'orchestration:security-auditor'` |\n\nExample frontmatter:\n```yaml\n---\nname: my-agent\nnamespace: orchestration:my-agent\ndescription: Does something specific and useful\ntools: [Read, Grep, Write]\nusage: \"Use via Task tool with subagent_type: 'orchestration:my-agent'\"\n---\n```\n\n## Best Practices for Agent Prompts\n\nFollow these principles when writing agent prompts:\n\n### 1. Be Comprehensive\nThe agent has no other context. Include everything needed:\n- Complete task description\n- Domain knowledge and terminology\n- Expected behavior and edge cases\n- Success criteria\n\n### 2. Define Clear Responsibilities\nList specific tasks, not vague goals:\n- ‚úì \"Identify N+1 database queries\"\n- ‚úó \"Improve performance\"\n\n### 3. Specify Exact Output Format\nProvide templates and examples:\n```json\n{\n  \"field\": \"value\",\n  \"required_field\": \"must be present\"\n}\n```\n\n### 4. Recommend Appropriate Tools\nTell the agent which tools to use and when:\n- **Read**: For examining specific files\n- **Grep**: For finding patterns across codebase\n- **Edit**: For modifying existing files\n- **Write**: For creating new files (rare)\n- **Bash**: For running commands and tools\n\n### 5. Include Edge Case Handling\nSpecify what to do when:\n- Input is invalid\n- Files are missing\n- Tools are unavailable\n- No issues found\n\n### 6. Add Usage Examples\nShow 2-3 realistic scenarios with:\n- Input the agent receives\n- Process the agent should follow\n- Expected output format\n\n### 7. Define Success Criteria\nMake it clear when the agent's job is done:\n- Specific deliverables\n- Quality standards\n- Validation steps\n\n## Updating Defined Agents\n\nAgents can be modified at any time:\n\n1. **Edit the agent file**: Make changes to `agents/agent-name.md`\n2. **Update registry if needed**: If description changes, update `agents/registry.json`\n3. **Changes are immediate**: No restart required\n4. **Version control**: Commit changes to track evolution\n\nExample update:\n```bash\n# Edit the agent\nvim agents/security-auditor.md\n\n# If description changed, update registry\nvim agents/registry.json\n\n# Commit changes\ngit add agents/\ngit commit -m \"feat: enhance security auditor with crypto checks\"\n```\n\n## Deleting Defined Agents\n\nTo remove an agent completely:\n\n1. **Delete agent file**: Remove `agents/agent-name.md`\n2. **Update registry**: Remove entry from `agents/registry.json`\n3. **Clean up workflows**: Update any workflows using the agent\n4. **Commit changes**: Track the removal\n\nExample deletion:\n```bash\n# Remove files\nrm agents/old-agent.md\n\n# Edit registry to remove entry\nvim agents/registry.json\n\n# Commit removal\ngit add agents/\ngit commit -m \"refactor: remove deprecated old-agent\"\n```\n\n## Agent Discovery\n\nFind and explore available agents:\n\n### List All Agents\n```bash\nls agents/*.md\n```\n\n### View Agent Registry\n```bash\ncat agents/registry.json\n```\n\n### Search by Description\n```bash\ngrep -i \"security\" agents/registry.json\n```\n\n### Read Agent Prompt\n```bash\ncat agents/security-auditor.md\n```\n\n### Count Agents\n```bash\nls agents/*.md | wc -l\n```\n\n## When to Create Defined Agents\n\nCreate a defined agent when:\n\n- **Task repeats** across multiple workflows\n- **Specialized expertise** needed (security, performance, accessibility)\n- **Complex multi-step** operations required\n- **Standardized output** format needed across workflows\n- **Domain knowledge** should be centralized\n- **Quality standards** must be enforced consistently\n\nExamples:\n- Security auditor (used in all PR workflows)\n- Performance analyzer (used in optimization workflows)\n- Documentation generator (used for multiple projects)\n- Code transformer (used for migrations and refactoring)\n\n## When NOT to Create Defined Agents\n\nUse other approaches when:\n\n### Use Temp Agent Instead\n- **One-time use**: Task only needed in single workflow\n- **Workflow-specific**: Logic tied to specific workflow context\n- **Experimental**: Still figuring out the approach\n\n### Use Built-in Agent Instead\n- **General capability**: workflow-socratic-designer, code-reviewer, etc.\n- **Standard operation**: Built-in agent already handles it well\n\n### Use Direct Instruction Instead\n- **Too simple**: Single tool call or straightforward operation\n- **No context needed**: Task is self-explanatory\n\nExamples of when NOT to create:\n- ‚úó One-off database migration (use temp agent)\n- ‚úó File reading (use Read tool directly)\n- ‚úó General code review (use code-reviewer)\n- ‚úó Simple grep operation (use Grep tool directly)\n\n## Defined vs Temp Agents\n\nUnderstanding when to use each:\n\n| Aspect | Defined Agents | Temp Agents |\n|--------|---------------|-------------|\n| **Location** | `agents/` directory | `temp-agents/` directory |\n| **Lifetime** | Permanent, across all workflows | Ephemeral, single workflow |\n| **Availability** | All workflows can use | Only defining workflow |\n| **Creation** | Manual or promoted from temp | Generated during workflow design |\n| **Cleanup** | Manual deletion | Automatic after workflow |\n| **Registry** | Tracked in `agents/registry.json` | Tracked in workflow metadata |\n| **Namespace** | `orchestration:agent-name` | `temp:agent-name` |\n| **Use Case** | Reusable specialized tasks | Workflow-specific tasks |\n| **Promotion** | N/A (already permanent) | Can be promoted to defined |\n\n### When to Promote Temp to Defined\n\nPromote a temp agent to defined when:\n- Used successfully in multiple workflows\n- Other team members need the capability\n- Task pattern emerges as common need\n- Quality standards should be enforced\n\nExample promotion workflow:\n```flow\n@agent-name:\"Analyze codebase\":analysis\n  -> promote-agent:\"Consider promotion to defined agent\":recommendation\n```\n\n## Related Documentation\n\n- [Temporary Agents](/docs/features/temporary-agents.md): Learn about ephemeral agents\n- [Agent Promotion](/docs/features/agent-promotion.md): Promote temp agents to defined\n- [Workflow Syntax](/docs/reference/syntax.md): Full workflow syntax reference\n- [Built-in Agents](/agents/README.md): Available built-in agents\n",
        "skills/managing-agents/namespacing.md": "# Agent Namespacing Reference\n\n## Why Namespacing?\n\nAgent namespacing is critical for the orchestration system to properly route agent invocations. Without namespacing:\n\n- **Conflicts with built-in agents**: Plugin agents could shadow Claude Code's built-in agents\n- **Ambiguous routing**: The system wouldn't know whether to use a plugin agent or built-in agent\n- **Cross-plugin conflicts**: Multiple plugins could define agents with the same name\n- **Task tool routing**: The Task tool needs to know which agent system to route to\n\nNamespacing ensures that every agent has a unique identifier and the system can correctly resolve and execute the right agent.\n\n## Namespace Rules\n\n| Agent Type | User Writes | System Executes | Example Use Case |\n|------------|-------------|-----------------|------------------|\n| Built-in | `Explore:\"task\"` | `Explore` | Code exploration and analysis |\n| Built-in | `general-purpose:\"task\"` | `general-purpose` | General purpose tasks |\n| Built-in | `code-reviewer:\"task\"` | `code-reviewer` | Code review |\n| Plugin defined | `workflow-socratic-designer` | `orchestration:workflow-socratic-designer` | Workflow creation |\n| Plugin defined | `workflow-executor` | `orchestration:workflow-executor` | Workflow execution |\n| Temp agent | `$security-scanner` | `orchestration:security-scanner` | One-off security scanning |\n| Temp agent | `$data-transformer` | `orchestration:data-transformer` | Workflow-specific data transformation |\n\n**Key takeaway**: Users write the short form, the system automatically adds the namespace prefix during execution.\n\n## Namespace Format\n\n### Plugin Agents\n- Format: `orchestration:agent-name`\n- Single colon (NOT `orchestration::` or `orchestration/`)\n- Lowercase with hyphens (kebab-case)\n- Examples:\n  - ‚úÖ `orchestration:workflow-socratic-designer`\n  - ‚úÖ `orchestration:validation-expert`\n  - ‚ùå `orchestration::workflow-designer` (double colon)\n  - ‚ùå `orchestration/workflow-designer` (slash)\n  - ‚ùå `orchestration:WorkflowDesigner` (camelCase)\n\n### Other Plugin Namespaces\n- Format: `plugin-name:agent-name`\n- Examples:\n  - `superpowers:brainstorming`\n  - `superpowers:code-reviewer`\n\n## Automatic Namespace Prefixing\n\nThe orchestration system automatically adds the `orchestration:` prefix to plugin and temp agents. Users never manually add the prefix in workflow syntax.\n\n**User writes**:\n```flow\nworkflow-socratic-designer:\"create a data processing workflow\"\n```\n\n**System transforms to**:\n```javascript\nTask({\n  subagent_type: \"orchestration:workflow-socratic-designer\",\n  instructions: \"create a data processing workflow\"\n})\n```\n\nThis automatic prefixing happens during the workflow parsing phase, before execution.\n\n## Agent Resolution Algorithm\n\nThe system uses a three-step algorithm to resolve agent names:\n\n```javascript\nfunction resolveAgent(name) {\n  // 1. Check if it's a built-in Claude Code agent\n  const builtIns = [\n    'Explore',\n    'general-purpose',\n    'code-reviewer',\n    'implementation-architect',\n    'expert-code-implementer'\n  ];\n\n  if (builtIns.includes(name)) {\n    return name; // Use as-is, no prefix\n  }\n\n  // 2. Check if it already has a namespace (from another plugin)\n  if (name.includes(':')) {\n    return name; // Already namespaced, use as-is\n  }\n\n  // 3. Add orchestration namespace\n  return `orchestration:${name}`;\n}\n```\n\n**Resolution examples**:\n- `Explore` ‚Üí `Explore` (built-in, no prefix)\n- `workflow-socratic-designer` ‚Üí `orchestration:workflow-socratic-designer` (plugin agent)\n- `$news-analyzer` ‚Üí `orchestration:news-analyzer` (temp agent, `$` stripped)\n- `superpowers:brainstorming` ‚Üí `superpowers:brainstorming` (other plugin, no change)\n\n## In Workflow Syntax\n\n### Example 1: Mixed Agent Types\n\n**User writes**:\n```flow\nExplore:\"analyze the codebase structure\" ->\nworkflow-socratic-designer:\"create a testing workflow\" ->\n$test-executor:\"run the generated tests\"\n```\n\n**System executes**:\n```javascript\n// Step 1: Built-in agent\nTask({\n  subagent_type: \"Explore\",\n  instructions: \"analyze the codebase structure\"\n})\n\n// Step 2: Plugin defined agent\nTask({\n  subagent_type: \"orchestration:workflow-socratic-designer\",\n  instructions: \"create a testing workflow\"\n})\n\n// Step 3: Temp agent\nTask({\n  subagent_type: \"orchestration:test-executor\",\n  instructions: \"run the generated tests\"\n})\n```\n\n### Example 2: Parallel Execution\n\n**User writes**:\n```flow\n{\n  Explore:\"find all API endpoints\",\n  workflow-socratic-designer:\"design API test workflow\",\n  $security-checker:\"check for vulnerabilities\"\n}\n```\n\n**System executes** (all in parallel):\n```javascript\n[\n  Task({ subagent_type: \"Explore\", ... }),\n  Task({ subagent_type: \"orchestration:workflow-socratic-designer\", ... }),\n  Task({ subagent_type: \"orchestration:security-checker\", ... })\n]\n```\n\n## Registry Structure\n\nAll defined plugin agents are registered in `agents/registry.json`:\n\n```json\n{\n  \"agents\": [\n    {\n      \"name\": \"workflow-socratic-designer\",\n      \"namespace\": \"orchestration\",\n      \"fullName\": \"orchestration:workflow-socratic-designer\",\n      \"file\": \"agents/workflow-socratic-designer.md\",\n      \"description\": \"Creates workflows through Socratic dialogue\"\n    },\n    {\n      \"name\": \"workflow-executor\",\n      \"namespace\": \"orchestration\",\n      \"fullName\": \"orchestration:workflow-executor\",\n      \"file\": \"agents/workflow-executor.md\",\n      \"description\": \"Executes workflow definitions\"\n    }\n  ]\n}\n```\n\nThe registry is used for:\n- Agent discovery and documentation\n- Validation (ensuring agent exists before execution)\n- Auto-completion suggestions\n- Error messages (\"Did you mean...?\")\n\n## Temp Agent Namespacing\n\nTemporary agents (defined inline in workflows) follow the same namespacing rules:\n\n1. **User defines with `$` prefix**:\n   ```flow\n   $news-analyzer:{\n     role: \"Analyze news articles\",\n     instructions: \"Extract key facts and sentiment\"\n   }\n   ```\n\n2. **System strips `$` and adds namespace**:\n   ```javascript\n   // Internal representation\n   {\n     name: \"news-analyzer\",\n     fullName: \"orchestration:news-analyzer\",\n     role: \"Analyze news articles\",\n     instructions: \"Extract key facts and sentiment\"\n   }\n   ```\n\n3. **Execution uses namespaced form**:\n   ```javascript\n   Task({\n     subagent_type: \"orchestration:news-analyzer\",\n     instructions: \"Analyze the latest tech news\"\n   })\n   ```\n\n4. **Cleanup after workflow**:\n   - Temp agent definition removed from memory\n   - Unless promoted to permanent agent (via promotion flow)\n\n## Common Issues and Solutions\n\n### Issue 1: Agent Not Found Error\n\n**Error message**:\n```\nError: Agent 'my-analyzer' not found\n```\n\n**Possible causes**:\n- Agent file doesn't exist in `agents/` or `temp-agents/`\n- Typo in agent name\n- Agent not registered in `registry.json` (for defined agents)\n\n**Solution**:\n1. Check spelling: `my-analyzer` vs `my-analizer`\n2. Verify file exists: `agents/my-analyzer.md`\n3. For defined agents, check `agents/registry.json`\n4. For temp agents, ensure definition appears before usage\n\n### Issue 2: Manually Adding Namespace\n\n**Wrong**:\n```flow\norchestration:workflow-socratic-designer:\"create workflow\"\n```\n\n**Right**:\n```flow\nworkflow-socratic-designer:\"create workflow\"\n```\n\nThe system adds the namespace automatically. Manual namespace addition will cause the agent to not be found (it will look for `orchestration:orchestration:workflow-socratic-designer`).\n\n### Issue 3: Incorrect Namespace Format\n\n**Wrong**:\n```javascript\n// In agent file or registry\n{\n  \"namespace\": \"orchestration::workflow-designer\" // Double colon\n}\n```\n\n**Right**:\n```javascript\n{\n  \"namespace\": \"orchestration:workflow-designer\" // Single colon\n}\n```\n\n### Issue 4: Case Sensitivity\n\n**Wrong**:\n```flow\nWorkflowSocraticDesigner:\"task\"\n```\n\n**Right**:\n```flow\nworkflow-socratic-designer:\"task\"\n```\n\nAgent names are case-sensitive and should always use kebab-case (lowercase with hyphens).\n\n## Complete Examples\n\n### Example 1: Simple Built-in Agent\n\n**Workflow**:\n```flow\nExplore:\"Find all configuration files in the project\"\n```\n\n**Execution**:\n```javascript\nTask({\n  subagent_type: \"Explore\",\n  instructions: \"Find all configuration files in the project\"\n})\n```\n\n**Result**: Uses Claude Code's built-in Explore agent directly.\n\n### Example 2: Plugin Agent Only\n\n**Workflow**:\n```flow\nworkflow-socratic-designer:\"Design a CI/CD workflow for testing\"\n```\n\n**Execution**:\n```javascript\nTask({\n  subagent_type: \"orchestration:workflow-socratic-designer\",\n  instructions: \"Design a CI/CD workflow for testing\"\n})\n```\n\n**Result**: Uses the orchestration plugin's workflow designer agent.\n\n### Example 3: Sequential with Mixed Types\n\n**Workflow**:\n```flow\nExplore:\"Analyze database schema\" ->\nworkflow-socratic-designer:\"Create data migration workflow\" ->\ngeneral-purpose:\"Validate the migration plan\"\n```\n\n**Execution**:\n```javascript\n// Step 1\nTask({ subagent_type: \"Explore\", instructions: \"Analyze database schema\" })\n\n// Step 2 (uses result from step 1 via context)\nTask({\n  subagent_type: \"orchestration:workflow-socratic-designer\",\n  instructions: \"Create data migration workflow\"\n})\n\n// Step 3 (uses results from steps 1 and 2)\nTask({\n  subagent_type: \"general-purpose\",\n  instructions: \"Validate the migration plan\"\n})\n```\n\n**Result**: Chains built-in agents with plugin agents seamlessly.\n\n### Example 4: Temp Agent Definition and Usage\n\n**Workflow**:\n```flow\n$i18n-scanner:{\n  role: \"Scan codebase for hardcoded strings that need internationalization\",\n  instructions: \"Find all user-facing strings not using i18n functions\"\n}\n\nExplore:\"List all React components\" ->\n$i18n-scanner:\"Scan components for hardcoded strings\" ->\ngeneral-purpose:\"Create a report of findings\"\n```\n\n**Execution**:\n```javascript\n// Temp agent registered as orchestration:i18n-scanner\n\n// Step 1\nTask({ subagent_type: \"Explore\", instructions: \"List all React components\" })\n\n// Step 2\nTask({\n  subagent_type: \"orchestration:i18n-scanner\",\n  instructions: \"Scan components for hardcoded strings\"\n})\n\n// Step 3\nTask({\n  subagent_type: \"general-purpose\",\n  instructions: \"Create a report of findings\"\n})\n```\n\n**Result**: Temp agent is created, used, and cleaned up after workflow completion.\n\n### Example 5: Parallel Execution with Multiple Namespaces\n\n**Workflow**:\n```flow\n{\n  Explore:\"Find all test files\",\n  workflow-socratic-designer:\"Design integration test workflow\",\n  $coverage-analyzer:\"Analyze current test coverage\"\n}\n```\n\n**Execution** (all parallel):\n```javascript\n[\n  Task({ subagent_type: \"Explore\", instructions: \"Find all test files\" }),\n  Task({\n    subagent_type: \"orchestration:workflow-socratic-designer\",\n    instructions: \"Design integration test workflow\"\n  }),\n  Task({\n    subagent_type: \"orchestration:coverage-analyzer\",\n    instructions: \"Analyze current test coverage\"\n  })\n]\n```\n\n**Result**: Three agents execute simultaneously, each properly namespaced.\n\n### Example 6: Cross-Plugin Agent Usage\n\n**Workflow**:\n```flow\nExplore:\"Analyze codebase\" ->\nsuperpowers:brainstorming:\"Brainstorm refactoring approaches\" ->\nworkflow-socratic-designer:\"Create refactoring workflow\"\n```\n\n**Execution**:\n```javascript\n// Step 1: Built-in\nTask({ subagent_type: \"Explore\", instructions: \"Analyze codebase\" })\n\n// Step 2: Superpowers plugin\nTask({\n  subagent_type: \"superpowers:brainstorming\",\n  instructions: \"Brainstorm refactoring approaches\"\n})\n\n// Step 3: Orchestration plugin\nTask({\n  subagent_type: \"orchestration:workflow-socratic-designer\",\n  instructions: \"Create refactoring workflow\"\n})\n```\n\n**Result**: Seamless integration across multiple plugin ecosystems.\n\n### Example 7: Complex Multi-Stage Workflow\n\n**Workflow**:\n```flow\n$requirements-analyzer:{\n  role: \"Analyze project requirements\",\n  instructions: \"Extract functional and non-functional requirements\"\n}\n\n$architecture-designer:{\n  role: \"Design system architecture\",\n  instructions: \"Create architecture based on requirements\"\n}\n\nExplore:\"Scan existing codebase\" ->\n$requirements-analyzer:\"Analyze requirements from docs\" ->\n{\n  $architecture-designer:\"Design new architecture\",\n  workflow-socratic-designer:\"Create implementation workflow\",\n  general-purpose:\"Identify potential risks\"\n} ->\ncode-reviewer:\"Review proposed changes\"\n```\n\n**Execution flow**:\n```javascript\n// Step 1: Built-in\nTask({ subagent_type: \"Explore\", ... })\n\n// Step 2: Temp agent\nTask({ subagent_type: \"orchestration:requirements-analyzer\", ... })\n\n// Step 3: Three parallel agents\n[\n  Task({ subagent_type: \"orchestration:architecture-designer\", ... }),\n  Task({ subagent_type: \"orchestration:workflow-socratic-designer\", ... }),\n  Task({ subagent_type: \"general-purpose\", ... })\n]\n\n// Step 4: Built-in (uses all previous results)\nTask({ subagent_type: \"code-reviewer\", ... })\n```\n\n**Result**: Complex workflow with temp agents, plugin agents, and built-in agents working together.\n\n## Best Practices\n\n### 1. Use Built-in Agents When Possible\n\nBuilt-in agents are well-tested and optimized for common tasks:\n\n```flow\n// Good: Use built-in for code exploration\nExplore:\"Find all API endpoints\"\n\n// Unnecessary: Creating temp agent for same task\n$code-explorer:{role: \"Find code\"} ->\n$code-explorer:\"Find all API endpoints\"\n```\n\n### 2. Create Plugin Agents for Specialized, Reusable Tasks\n\nDefine plugin agents for domain-specific work you'll use repeatedly:\n\n```javascript\n// Good: Specialized, reusable agent\n// agents/api-documentation-generator.md\n{\n  \"name\": \"api-documentation-generator\",\n  \"namespace\": \"orchestration\",\n  \"role\": \"Generate API documentation from code\"\n}\n```\n\n### 3. Use Temp Agents for Workflow-Specific Needs\n\nTemp agents are perfect for one-off, workflow-specific tasks:\n\n```flow\n// Good: Workflow-specific agent\n$stripe-webhook-validator:{\n  role: \"Validate Stripe webhook signatures and payloads\",\n  instructions: \"Check webhook authenticity and parse events\"\n}\n```\n\n### 4. Never Hardcode Namespace Prefixes\n\nLet the system handle namespacing:\n\n```flow\n// Wrong: Manual namespace\norchestration:workflow-socratic-designer:\"task\"\n\n// Right: System handles it\nworkflow-socratic-designer:\"task\"\n```\n\n### 5. Use Consistent Naming Conventions\n\nFollow kebab-case for all agent names:\n\n```flow\n// Good\nworkflow-socratic-designer\napi-test-generator\nsecurity-vulnerability-scanner\n\n// Avoid\nworkflowSocraticDesigner  // camelCase\nworkflow_socratic_designer // snake_case\nWorkflowSocraticDesigner   // PascalCase\n```\n\n### 6. Document Agent Purpose in Registry\n\nKeep `agents/registry.json` up-to-date with clear descriptions:\n\n```json\n{\n  \"name\": \"workflow-socratic-designer\",\n  \"description\": \"Creates workflows through Socratic dialogue, asking clarifying questions to understand user needs\"\n}\n```\n\n### 7. Validate Agent Existence Before Complex Workflows\n\nFor workflows with many agents, validate upfront:\n\n```flow\n// List available agents first\nExplore:\"Check agents/registry.json\" ->\nworkflow-socratic-designer:\"Create workflow using validated agents\"\n```\n\n### 8. Use Context Passing Between Namespaced Agents\n\nAgents automatically receive context from previous steps:\n\n```flow\nExplore:\"Find database models\" ->\nworkflow-socratic-designer:\"Create CRUD workflow for models\" ->\n// Designer receives model information from Explore automatically\n```\n\n## Summary\n\nNamespacing in the orchestration system is automatic and transparent to users:\n\n- **Write simple names**: `workflow-socratic-designer`, `$temp-agent`\n- **System adds namespace**: `orchestration:workflow-socratic-designer`, `orchestration:temp-agent`\n- **Built-ins stay unchanged**: `Explore`, `general-purpose`\n- **Other plugins respected**: `superpowers:brainstorming`\n\nThis design provides clarity, prevents conflicts, and enables seamless multi-agent orchestration across different agent systems.\n",
        "skills/managing-agents/promotion.md": "# Agent Promotion Guide\n\nProgressive disclosure guide for promoting temporary agents to permanent defined agents.\n\n## What Is Agent Promotion?\n\n**Agent promotion** is the process of converting a temporary agent (created inline in a workflow) into a permanent, reusable defined agent that can be used across multiple workflows.\n\n### Definition\n\n- **Temporary Agent**: Created inline with `$agent-name` syntax, exists only within a single workflow\n- **Permanent Agent**: Stored in `agents/` directory, registered in `agents/registry.json`, available system-wide\n- **Promotion**: Moving a temporary agent to permanent status with proper registration\n\n### Why Promote?\n\nPromotion provides several key benefits:\n\n- **Reusability**: Use the same agent across multiple workflows without redefining\n- **Discoverability**: Registered agents appear in system searches and documentation\n- **Maintenance**: Single source of truth, update once to affect all workflows\n- **Version Control**: Track changes to agent definitions over time\n- **Statistics**: Monitor usage patterns and performance metrics\n- **Quality**: Promotes review and refinement of successful agent patterns\n\n### When to Promote vs When to Discard\n\n**Promote when**:\n- Agent worked well and delivered expected results\n- Agent could be useful in future workflows\n- Agent provides specialized domain expertise\n- Agent represents a reusable pattern or capability\n\n**Discard when**:\n- Agent was one-time use only\n- Agent is too specific to a single workflow context\n- Agent didn't work well or needs major redesign\n- Agent duplicates existing permanent agent functionality\n\n## Promotion Process\n\nThe promotion process follows a structured, step-by-step flow:\n\n### Step 1: Workflow Completion\n\nAfter a workflow using temporary agents completes successfully, the system automatically detects all temporary agents that were defined.\n\n### Step 2: Review Phase\n\nThe system presents a list of all temporary agents used in the workflow:\n\n```\nWorkflow Complete!\n\nTemporary agents used in this workflow:\n1. $security-scanner - Analyzes code for security vulnerabilities\n2. $data-validator - Validates data against schema requirements\n3. $quick-formatter - One-off formatting task\n\nWould you like to review these agents for promotion?\n```\n\n### Step 3: Selection Phase\n\nUser selects which agents to promote:\n\n```\nSelect agents to promote (space to toggle, enter to confirm):\n[x] $security-scanner\n[x] $data-validator\n[ ] $quick-formatter\n\n2 agents selected for promotion\n```\n\n### Step 4: Options Phase\n\nFor each selected agent, choose how to promote:\n\n```\nPromoting: $security-scanner\n\nOptions:\n1. Save as-is (recommended if agent worked perfectly)\n2. Edit before saving (refine prompt, make more general)\n3. Skip this agent\n\nYour choice: _\n```\n\n### Step 5: Confirmation Phase\n\nReview and confirm all promotions:\n\n```\nReady to promote:\n- security-scanner ‚Üí agents/security-scanner.md\n- data-validator ‚Üí agents/data-validator.md\n\nConfirm promotion? (y/n): _\n```\n\n### Step 6: Completion\n\nSystem confirms successful promotion:\n\n```\nPromoted 2 agents successfully!\n\nNew agents available:\n- orchestration:security-scanner\n- orchestration:data-validator\n\nCleaned up temporary agents directory.\n```\n\n## Promotion Flow Diagram\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Workflow Completes  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n           ‚îÇ\n           ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Review Temp Agents  ‚îÇ\n‚îÇ (List all created)  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n           ‚îÇ\n           ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ User Selects Agents         ‚îÇ\n‚îÇ (Multi-select interface)    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n           ‚îÇ\n           ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ For Each Selected Agent:    ‚îÇ\n‚îÇ                             ‚îÇ\n‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ ‚îÇ Prompt: Action?     ‚îÇ    ‚îÇ\n‚îÇ ‚îÇ - Save as-is        ‚îÇ    ‚îÇ\n‚îÇ ‚îÇ - Edit first        ‚îÇ    ‚îÇ\n‚îÇ ‚îÇ - Skip              ‚îÇ    ‚îÇ\n‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îÇ           ‚îÇ                 ‚îÇ\n‚îÇ           ‚ñº                 ‚îÇ\n‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ ‚îÇ If Edit: Open file  ‚îÇ    ‚îÇ\n‚îÇ ‚îÇ for modifications   ‚îÇ    ‚îÇ\n‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îÇ           ‚îÇ                 ‚îÇ\n‚îÇ           ‚ñº                 ‚îÇ\n‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ ‚îÇ Move to agents/     ‚îÇ    ‚îÇ\n‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îÇ           ‚îÇ                 ‚îÇ\n‚îÇ           ‚ñº                 ‚îÇ\n‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ ‚îÇ Add to registry.json‚îÇ    ‚îÇ\n‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n           ‚îÇ\n           ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Cleanup Unselected Agents   ‚îÇ\n‚îÇ (Remove from temp-agents/)  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n           ‚îÇ\n           ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Confirmation Message        ‚îÇ\n‚îÇ (List newly available)      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## What Happens During Promotion\n\nWhen an agent is promoted, the system performs several automated steps:\n\n### 1. File Movement\n\nThe agent definition file is moved from the temporary location to the permanent location:\n\n```\nFROM: temp-agents/security-scanner.md\nTO:   agents/security-scanner.md\n```\n\n### 2. Registry Registration\n\nAn entry is added to `agents/registry.json`:\n\n```json\n{\n  \"security-scanner\": {\n    \"file\": \"security-scanner.md\",\n    \"description\": \"Analyzes code for security vulnerabilities\",\n    \"namespace\": \"orchestration:security-scanner\",\n    \"created\": \"2025-01-08\",\n    \"usageCount\": 0,\n    \"lastUsed\": null\n  }\n}\n```\n\n### 3. Namespace Assignment\n\nThe agent receives a formal namespace identifier:\n\n```\nNamespace: orchestration:security-scanner\n```\n\nThis namespace is used when invoking the agent in future workflows.\n\n### 4. Immediate Availability\n\nThe agent becomes immediately available for use in any workflow:\n\n```yaml\nagents:\n  - name: security-scanner  # No $ prefix, uses registered agent\n    type: defined\n```\n\n### 5. Statistics Initialization\n\nUsage tracking is initialized for the agent:\n\n- `usageCount`: Starts at 0\n- `lastUsed`: Set to null\n- `created`: Current timestamp\n\n## Registry Structure\n\nThe `agents/registry.json` file maintains metadata for all permanent agents.\n\n### Example Entry\n\n```json\n{\n  \"security-scanner\": {\n    \"file\": \"security-scanner.md\",\n    \"description\": \"Analyzes code for security vulnerabilities using industry best practices\",\n    \"namespace\": \"orchestration:security-scanner\",\n    \"created\": \"2025-01-08T10:30:00Z\",\n    \"usageCount\": 0,\n    \"lastUsed\": null,\n    \"tags\": [\"security\", \"analysis\", \"code-review\"],\n    \"version\": \"1.0.0\"\n  }\n}\n```\n\n### Field Descriptions\n\n- **file**: Filename of the agent definition (in `agents/` directory)\n- **description**: One-line summary of agent's purpose (used in discovery)\n- **namespace**: Fully qualified name for invoking the agent\n- **created**: ISO 8601 timestamp of when agent was created/promoted\n- **usageCount**: Number of times agent has been used in workflows\n- **lastUsed**: ISO 8601 timestamp of most recent usage (null if never used)\n- **tags**: (Optional) Keywords for categorization and search\n- **version**: (Optional) Semantic version for tracking changes\n\n### Multiple Agents Example\n\n```json\n{\n  \"security-scanner\": {\n    \"file\": \"security-scanner.md\",\n    \"description\": \"Analyzes code for security vulnerabilities\",\n    \"namespace\": \"orchestration:security-scanner\",\n    \"created\": \"2025-01-08T10:30:00Z\",\n    \"usageCount\": 15,\n    \"lastUsed\": \"2025-01-10T14:22:00Z\"\n  },\n  \"data-validator\": {\n    \"file\": \"data-validator.md\",\n    \"description\": \"Validates data against schema requirements\",\n    \"namespace\": \"orchestration:data-validator\",\n    \"created\": \"2025-01-08T10:31:00Z\",\n    \"usageCount\": 8,\n    \"lastUsed\": \"2025-01-09T16:45:00Z\"\n  },\n  \"api-documenter\": {\n    \"file\": \"api-documenter.md\",\n    \"description\": \"Generates comprehensive API documentation\",\n    \"namespace\": \"orchestration:api-documenter\",\n    \"created\": \"2025-01-07T09:15:00Z\",\n    \"usageCount\": 23,\n    \"lastUsed\": \"2025-01-10T11:30:00Z\"\n  }\n}\n```\n\n## Criteria for Promotion\n\nUse these criteria to decide whether an agent should be promoted:\n\n### Strong Promotion Candidates\n\n- **Proven Performance**: Agent successfully completed its tasks in the workflow\n- **Reusability Potential**: Similar tasks are likely to occur in future workflows\n- **Domain Expertise**: Agent encapsulates specialized knowledge or skills\n- **Well-Tested**: Agent's behavior is reliable and predictable\n- **Clear Purpose**: Agent has a focused, well-defined responsibility\n- **Good Prompt Quality**: Agent's prompt is comprehensive and well-structured\n\n### Example Scenarios\n\n**Promote**: A security scanner that analyzes code for vulnerabilities\n- Reason: Security analysis is needed regularly across projects\n\n**Promote**: A data validator that checks JSON schemas\n- Reason: Data validation is a common requirement\n\n**Promote**: A documentation generator for REST APIs\n- Reason: API documentation tasks occur frequently\n\n**Promote**: A code reviewer specialized in React best practices\n- Reason: React reviews are needed for ongoing development\n\n## When NOT to Promote\n\nRecognize situations where promotion isn't appropriate:\n\n### Poor Promotion Candidates\n\n- **One-Time Use**: Agent was created for a single, specific task\n- **Workflow-Specific**: Agent relies on context unique to one workflow\n- **Untested**: Agent didn't work well or needs significant refinement\n- **Duplicate Functionality**: Agent does what an existing permanent agent already does\n- **Overly Specific**: Agent is too narrowly focused to be useful elsewhere\n- **Poor Quality**: Agent's prompt is unclear or incomplete\n\n### Example Scenarios\n\n**Don't Promote**: A formatter that fixed a specific formatting issue in one file\n- Reason: Too specific, unlikely to be needed again\n\n**Don't Promote**: An agent that parsed a unique legacy data format\n- Reason: One-time migration task\n\n**Don't Promote**: An agent that didn't work correctly\n- Reason: Needs redesign, not ready for reuse\n\n**Don't Promote**: An agent that does the same thing as an existing permanent agent\n- Reason: Duplicate functionality, use existing agent instead\n\n**Don't Promote**: An agent that only works with specific hardcoded values from the workflow\n- Reason: Too coupled to workflow context\n\n## After Promotion\n\nOnce agents are promoted, here's how to work with them:\n\n### Using Promoted Agents\n\nReference promoted agents by name (without `$` prefix) in workflows:\n\n```yaml\nagents:\n  - name: security-scanner  # Uses permanent agent\n    type: defined\n\ntasks:\n  - agent: security-scanner\n    input: \"Analyze the authentication module\"\n```\n\nThe system automatically resolves the agent from the registry.\n\n### Updating Promoted Agents\n\nTo modify a permanent agent:\n\n1. Edit the file directly in the `agents/` directory\n2. Changes take effect immediately\n3. All workflows using the agent will use the updated version\n\n```bash\n# Edit the agent definition\nvim agents/security-scanner.md\n\n# Changes are live immediately\n# No need to update registry.json manually\n```\n\n### Tracking Usage Statistics\n\nThe registry automatically tracks usage:\n\n```json\n{\n  \"security-scanner\": {\n    \"usageCount\": 23,\n    \"lastUsed\": \"2025-01-10T14:22:00Z\"\n  }\n}\n```\n\nUse these statistics to:\n- Identify most valuable agents\n- Find unused agents that can be archived\n- Understand agent adoption patterns\n\n### Removing Promoted Agents\n\nIf a permanent agent is no longer needed:\n\n1. Remove the file from `agents/` directory\n2. Remove the entry from `agents/registry.json`\n3. Update any workflows that reference the agent\n\n## Examples\n\nReal-world scenarios illustrating the promotion decision process:\n\n### Example 1: Promoting a Security Scanner\n\n**Scenario**: Created a temporary agent to scan code for SQL injection vulnerabilities.\n\n**Workflow Definition**:\n```yaml\nagents:\n  - name: $sql-injection-scanner\n    prompt: |\n      You are a security expert specializing in SQL injection detection.\n      Analyze code for SQL injection vulnerabilities:\n      - Identify unsafe query construction\n      - Flag missing input sanitization\n      - Recommend parameterized queries\n      Provide severity ratings and fix recommendations.\n\ntasks:\n  - agent: $sql-injection-scanner\n    input: \"Scan the user authentication module\"\n```\n\n**Result**: Agent found 3 vulnerabilities with clear recommendations.\n\n**Decision**: **PROMOTE**\n\n**Reasoning**:\n- Security scanning is needed regularly\n- Agent performed well and found real issues\n- Applicable to any codebase with SQL queries\n- Well-defined scope and purpose\n\n**Action**: Promote as-is to `agents/sql-injection-scanner.md`\n\n**Registry Entry**:\n```json\n{\n  \"sql-injection-scanner\": {\n    \"file\": \"sql-injection-scanner.md\",\n    \"description\": \"Detects SQL injection vulnerabilities in code\",\n    \"namespace\": \"orchestration:sql-injection-scanner\",\n    \"created\": \"2025-01-08T15:30:00Z\",\n    \"usageCount\": 0,\n    \"lastUsed\": null,\n    \"tags\": [\"security\", \"sql\", \"vulnerability-scanning\"]\n  }\n}\n```\n\n### Example 2: Promoting a Data Validator\n\n**Scenario**: Created an agent to validate API responses against OpenAPI schemas.\n\n**Original Definition**:\n```yaml\nagents:\n  - name: $api-response-validator\n    prompt: |\n      Validate API responses against OpenAPI 3.0 schemas.\n      Check for:\n      - Required fields presence\n      - Data type correctness\n      - Format compliance\n      - Enum value validity\n      Report all violations with paths and expected values.\n```\n\n**Result**: Agent validated 15 endpoints, found 8 schema violations.\n\n**Decision**: **PROMOTE WITH EDITS**\n\n**Reasoning**:\n- API validation is a common need\n- Agent worked perfectly\n- Prompt could be more general to support JSON Schema too\n\n**Action**: Edit before promotion to support both OpenAPI and JSON Schema:\n\n```markdown\n# API Response Validator\n\nYou are a data validation expert specializing in API response validation.\n\n## Capabilities\n\nValidate API responses against schemas:\n- OpenAPI 3.0 specifications\n- JSON Schema definitions\n- Custom validation rules\n\n## Validation Checks\n\nFor each response:\n- Required fields presence\n- Data type correctness\n- Format compliance (email, uuid, date, etc.)\n- Enum value validity\n- Range constraints (min/max)\n- Pattern matching (regex)\n- Array constraints (minItems, maxItems, uniqueItems)\n\n## Output Format\n\nReport violations clearly:\n- Path to violating field (JSONPath notation)\n- Expected value/type/constraint\n- Actual value received\n- Severity level (error, warning)\n- Suggested fix\n```\n\n**Registry Entry**:\n```json\n{\n  \"api-response-validator\": {\n    \"file\": \"api-response-validator.md\",\n    \"description\": \"Validates API responses against OpenAPI and JSON schemas\",\n    \"namespace\": \"orchestration:api-response-validator\",\n    \"created\": \"2025-01-08T16:45:00Z\",\n    \"usageCount\": 0,\n    \"lastUsed\": null,\n    \"tags\": [\"validation\", \"api\", \"schema\", \"openapi\", \"json-schema\"]\n  }\n}\n```\n\n### Example 3: Deciding NOT to Promote\n\n**Scenario**: Created an agent to fix a specific legacy date format in one migration.\n\n**Definition**:\n```yaml\nagents:\n  - name: $legacy-date-fixer\n    prompt: |\n      Convert dates from legacy format \"DD/MM/YY HH:MM\" to ISO 8601.\n      Assume 20th century for years (97 = 1997).\n      Handle missing times by defaulting to 00:00.\n      Specific to the old CRM system export format.\n```\n\n**Result**: Agent successfully converted 1,200 dates in migration data.\n\n**Decision**: **DO NOT PROMOTE**\n\n**Reasoning**:\n- One-time migration task, won't be needed again\n- Too specific to legacy CRM format\n- Not applicable to other date conversion needs\n- If similar need arises, better to create a new, more general agent\n\n**Action**: Discard after workflow completion, keep workflow as documentation of migration process.\n\n### Example 4: Editing Before Promotion\n\n**Scenario**: Created an agent to review React components, but it was too opinionated.\n\n**Original Prompt** (too specific):\n```yaml\nagents:\n  - name: $react-reviewer\n    prompt: |\n      Review React components for our company standards:\n      - Must use hooks, no class components\n      - Must use TypeScript strict mode\n      - Must use our custom useAuth hook for auth\n      - Must follow our exact folder structure\n      - Must use Tailwind CSS, no styled-components\n```\n\n**Decision**: **EDIT BEFORE PROMOTION**\n\n**Revised Prompt** (more general):\n```markdown\n# React Component Reviewer\n\nYou are a React expert reviewing component code for best practices.\n\n## Review Criteria\n\n### Code Quality\n- Component structure and organization\n- Proper hook usage (dependencies, rules of hooks)\n- State management patterns\n- Error handling\n- Performance considerations (memoization, lazy loading)\n\n### Type Safety\n- TypeScript usage (if applicable)\n- Prop type definitions\n- Type inference optimization\n\n### Best Practices\n- Single responsibility principle\n- Proper component composition\n- Accessibility (a11y) compliance\n- Testability\n\n### Common Issues to Flag\n- Missing key props in lists\n- Unsafe lifecycle patterns\n- Memory leaks (missing cleanup)\n- Unnecessary re-renders\n- Missing error boundaries\n\n## Output Format\n\nProvide:\n- Overall assessment\n- Specific issues with line numbers\n- Severity levels (critical, warning, suggestion)\n- Recommended fixes\n- Code examples where helpful\n```\n\n**Reasoning**: Removed company-specific requirements, made it useful for any React project.\n\n### Example 5: Promoting Multiple Agents at Once\n\n**Scenario**: Completed a large workflow that used 5 temporary agents.\n\n**Agents Used**:\n1. `$code-analyzer` - Analyzes code complexity\n2. `$test-generator` - Generates unit tests\n3. `$doc-writer` - Writes JSDoc comments\n4. `$performance-checker` - Identifies performance issues\n5. `$quick-renamer` - Renamed variables for one refactoring\n\n**Review Process**:\n```\nSelect agents to promote:\n[x] $code-analyzer - Useful for ongoing code reviews\n[x] $test-generator - Always need test generation\n[x] $doc-writer - Documentation is continuous need\n[x] $performance-checker - Performance analysis needed regularly\n[ ] $quick-renamer - One-off task, too specific\n\n4 agents selected for promotion\n```\n\n**Batch Promotion**:\n```\nPromoting 4 agents:\n\n1. code-analyzer ‚Üí Save as-is? (y/e/s): y\n2. test-generator ‚Üí Save as-is? (y/e/s): e\n   [Opens editor for refinement]\n3. doc-writer ‚Üí Save as-is? (y/e/s): y\n4. performance-checker ‚Üí Save as-is? (y/e/s): y\n\nPromotion complete!\n\nNew agents available:\n- orchestration:code-analyzer\n- orchestration:test-generator\n- orchestration:doc-writer\n- orchestration:performance-checker\n```\n\n**Result**: 4 reusable agents added to permanent collection, 1 temporary agent discarded.\n\n## Best Practices\n\nFollow these guidelines for effective agent promotion:\n\n### 1. Review All Temporary Agents\n\nAfter every workflow, review all temporary agents:\n- Did each agent work as expected?\n- Which agents could be useful again?\n- Which agents need refinement?\n\nDon't skip the review step - it's where value is captured.\n\n### 2. Promote High-Value Agents\n\nPrioritize promoting agents that:\n- Saved significant time or effort\n- Solved complex problems effectively\n- Will likely be needed again soon\n- Represent specialized expertise\n\n### 3. Make Prompts More General\n\nBefore promotion, edit prompts to remove:\n- Hardcoded values specific to one workflow\n- References to specific files or paths\n- Overly narrow constraints\n- Company-specific assumptions\n\nMake agents reusable across different contexts.\n\n### 4. Add Good Descriptions\n\nWrite clear, searchable descriptions:\n\n**Bad**: \"Does stuff with code\"\n**Good**: \"Analyzes code complexity and suggests refactoring opportunities\"\n\n**Bad**: \"Validator\"\n**Good**: \"Validates JSON data against OpenAPI 3.0 and JSON Schema specifications\"\n\nDescriptions help with discovery and appropriate usage.\n\n### 5. Use Tags for Organization\n\nAdd tags to help categorize and find agents:\n\n```json\n{\n  \"security-scanner\": {\n    \"tags\": [\"security\", \"analysis\", \"code-review\", \"vulnerabilities\"]\n  },\n  \"api-validator\": {\n    \"tags\": [\"validation\", \"api\", \"testing\", \"schema\"]\n  }\n}\n```\n\n### 6. Test Before Promoting\n\nIf uncertain about an agent's quality:\n1. Use it in another workflow first\n2. Verify it works in different contexts\n3. Only promote after confirming reliability\n\nDon't promote untested agents.\n\n### 7. Archive Rather Than Delete\n\nInstead of deleting agents that might be useful later:\n- Create an `agents/archived/` directory\n- Move rarely used agents there\n- Keep them accessible for reference\n\n### 8. Document Agent Capabilities\n\nIn the agent file, clearly document:\n- What the agent does\n- What inputs it expects\n- What outputs it provides\n- Any limitations or constraints\n- Example use cases\n\n### 9. Version Complex Agents\n\nFor agents that will evolve over time:\n- Use semantic versioning in registry\n- Document breaking changes\n- Consider keeping old versions for compatibility\n\n### 10. Review Usage Statistics\n\nPeriodically check which promoted agents are actually being used:\n- High usage = valuable, keep improving\n- No usage = consider archiving or removing\n- Declining usage = may be obsolete\n\n---\n\n## Quick Reference\n\n### Promotion Checklist\n\nBefore promoting an agent, verify:\n\n- [ ] Agent worked correctly in workflow\n- [ ] Agent could be useful in future workflows\n- [ ] Prompt is clear and comprehensive\n- [ ] Removed workflow-specific hardcoded values\n- [ ] Added good description for discovery\n- [ ] Considered adding tags for categorization\n- [ ] Checked for duplicate functionality\n- [ ] Agent has focused, well-defined purpose\n\n### Common Promotion Patterns\n\n**Promote As-Is**: Agent is perfect, no changes needed\n**Edit First**: Agent works but needs generalization\n**Skip**: Agent is one-time use or needs major redesign\n\n### File Locations\n\n- **Temporary Agents**: `temp-agents/*.md`\n- **Permanent Agents**: `agents/*.md`\n- **Registry**: `agents/registry.json`\n- **Archive**: `agents/archived/*.md` (optional)\n\n---\n\nReady to promote your temporary agents? Review your recent workflow and identify valuable agents to preserve for future use!\n",
        "skills/managing-agents/temp-agents.md": "# Temporary Agents Guide\n\nA comprehensive guide to creating, using, and managing temporary agents in orchestration workflows.\n\n## What Are Temp Agents?\n\nTemporary agents are workflow-specific, ephemeral agents that exist only during a single workflow execution. They allow you to create specialized agents tailored to specific tasks without cluttering your permanent agent library.\n\n### Key Characteristics\n\n- **Workflow-scoped**: Created for and used within a single workflow\n- **Full agent definitions**: Complete markdown files with YAML frontmatter, not just prompt snippets\n- **Automatic cleanup**: Deleted after workflow execution unless promoted\n- **Promotion eligible**: Can be saved as permanent defined agents if valuable\n\n### When to Create Temp Agents\n\nCreate temporary agents when you need:\n\n1. **Specialized expertise** - Domain-specific knowledge (security, performance, data validation)\n2. **Workflow-specific context** - Custom instructions for this particular task\n3. **Experimentation** - Testing agent designs before committing to permanent agents\n4. **One-off tasks** - Agents that won't be reused across workflows\n\n### When NOT to Create Temp Agents\n\nDon't create temp agents when:\n\n- A built-in agent (`Explore`, `general-purpose`, etc.) can handle it\n- A permanent defined agent already exists for this purpose\n- The task is simple enough for a single instruction\n- You know you'll reuse this agent frequently (create a defined agent instead)\n\n## Lifecycle Overview\n\n```\n1. Creation        2. Execution       3. Promotion       4. Cleanup\n   (design)           (workflow)         (optional)        (automatic)\n\n[Designer] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> [Workflow] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> [User Choice] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> [Done]\ncreates temp       references $agent   save or discard     temp deleted\nagent files        in workflow steps   after completion    if not saved\n```\n\n## Temp Agent File Format\n\nTemp agents are markdown files stored in `temp-agents/` with YAML frontmatter.\n\n### Required Structure\n\n```markdown\n---\nname: agent-name\nbase: base-agent-type\nmodel: sonnet|opus|haiku\ndescription: One-line description of what this agent does\n---\n\nYou are a [role] specializing in [expertise].\n\nYour responsibilities:\n1. Primary task\n2. Secondary task\n3. Additional tasks\n\nInput format:\n[What the agent expects to receive]\n\nOutput format:\n[Expected output structure]\n\nBest practices:\n- Use [tool name]: [When and how to use it]\n- Handle [edge case]: [How to handle it]\n- Focus on [priority]: [Why it matters]\n```\n\n### Required Fields (YAML Frontmatter)\n\n| Field | Required | Description | Example |\n|-------|----------|-------------|---------|\n| `name` | Yes | Agent identifier (kebab-case) | `security-scanner` |\n| `base` | Yes | Base agent type to use | `general-purpose`, `Explore`, `code-reviewer` |\n| `model` | No | Model selection (default: sonnet) | `opus`, `sonnet`, `haiku` |\n| `description` | Yes | Brief one-line summary | `Scans for security vulnerabilities` |\n\n### Available Base Agents\n\n- **`general-purpose`** - Versatile agent for most tasks\n- **`Explore`** - Code exploration and codebase search\n- **`code-reviewer`** - Code review and quality checks\n- **`expert-code-implementer`** - Code implementation and editing\n- **`implementation-architect`** - Planning and architecture\n\n### Prompt Content Guidelines\n\nMake your agent prompts **comprehensive and specific**:\n\n1. **Define the role clearly** - \"You are a security expert specializing in...\"\n2. **List responsibilities** - Numbered list of what agent should do\n3. **Specify input/output formats** - JSON, markdown, specific structure\n4. **Include tool recommendations** - When to use Read, Grep, Edit, etc.\n5. **Handle edge cases** - Error handling, missing data, conflicts\n6. **Define success criteria** - What constitutes completion\n\n## Creating Temp Agents\n\nTemp agents are typically created automatically by the workflow designer when you use `/orchestration:create`. However, you can also create them manually.\n\n### Automatic Creation (Recommended)\n\nWhen designing workflows, the system creates temp agents for you:\n\n```\nUser: Create a workflow to scan for security issues and fix them\n\nDesigner: I'll create two temp agents:\n1. security-scanner - To find vulnerabilities\n2. vulnerability-fixer - To apply fixes\n```\n\nCreates files:\n- `temp-agents/security-scanner.md`\n- `temp-agents/vulnerability-fixer.md`\n\n### Manual Creation\n\nTo create a temp agent manually:\n\n1. Create file in `temp-agents/` directory\n2. Use kebab-case naming: `my-agent.md`\n3. Include YAML frontmatter with required fields\n4. Write comprehensive prompt\n5. Reference in workflow with `$agent-name` syntax\n\n## Using Temp Agents in Workflows\n\n### Reference Syntax\n\nUse the `$` prefix to reference temp agents in workflows:\n\n```flow\n$agent-name:\"instruction\"\n```\n\n**Example:**\n```flow\n$security-scanner:\"Scan the authentication module\"\n```\n\n### With Output Capture\n\nCapture agent output to a variable for use in subsequent steps:\n\n```flow\n$agent-name:\"instruction\":output_var\n```\n\n**Example:**\n```flow\n$security-scanner:\"Scan auth code\":vulnerabilities\n```\n\n### Variable Interpolation\n\nUse captured variables in subsequent agent instructions:\n\n```flow\n$agent1:\"First task\":result1 ->\n$agent2:\"Process {result1}\"\n```\n\n**Example:**\n```flow\n$security-scanner:\"Scan code\":issues ->\n$fixer:\"Fix these issues: {issues}\":fixes ->\ngeneral-purpose:\"Verify {fixes} resolved {issues}\"\n```\n\n### Complete Workflow Example\n\n```flow\n$security-scanner:\"Scan authentication and authorization\":issues ->\n@review ->\n$fixer:\"Fix issues: {issues}\":fixes ->\ngeneral-purpose:\"Verify fixes and run tests\"\n```\n\n## Temp Agent Examples\n\n### Example 1: Security Scanner\n\n**File:** `temp-agents/security-scanner.md`\n\n```markdown\n---\nname: security-scanner\nbase: general-purpose\nmodel: opus\ndescription: Scans codebase for security vulnerabilities using OWASP guidelines\n---\n\nYou are a security expert specializing in web application vulnerabilities.\n\nYour responsibilities:\n1. Scan code for OWASP Top 10 vulnerabilities\n2. Identify SQL injection, XSS, CSRF, and authentication flaws\n3. Provide specific file paths and line numbers\n4. Assess severity (critical, high, medium, low)\n\nInput format:\n- Natural language instruction specifying what to scan\n- May include specific modules or file patterns\n\nOutput format:\n```json\n{\n  \"vulnerabilities\": [\n    {\n      \"type\": \"SQL Injection\",\n      \"severity\": \"critical\",\n      \"file\": \"auth.js\",\n      \"line\": 42,\n      \"code\": \"const query = 'SELECT * FROM users WHERE id=' + userId\",\n      \"recommendation\": \"Use parameterized queries\"\n    }\n  ],\n  \"summary\": {\n    \"critical\": 2,\n    \"high\": 5,\n    \"medium\": 8,\n    \"low\": 3\n  }\n}\n```\n\nUse these tools:\n- Grep: Search for vulnerable patterns (eval, innerHTML, raw SQL)\n- Read: Examine suspicious files in detail\n- Glob: Find all files of specific types (*.js, *.php)\n\nBest practices:\n- Focus on user input handling, database queries, and authentication\n- Check both server-side and client-side code\n- Consider context-specific vulnerabilities (framework-specific issues)\n- Provide actionable, specific recommendations\n```\n\n**Usage in workflow:**\n\n```flow\n$security-scanner:\"Scan authentication module\":security_issues ->\ngeneral-purpose:\"Prioritize {security_issues} by severity\"\n```\n\n### Example 2: Performance Profiler\n\n**File:** `temp-agents/performance-profiler.md`\n\n```markdown\n---\nname: performance-profiler\nbase: Explore\nmodel: sonnet\ndescription: Analyzes code for performance bottlenecks and optimization opportunities\n---\n\nYou are a performance optimization expert specializing in identifying bottlenecks and inefficiencies.\n\nYour responsibilities:\n1. Identify performance issues (N+1 queries, memory leaks, inefficient algorithms)\n2. Measure complexity (time/space)\n3. Suggest specific optimizations\n4. Prioritize by impact\n\nInput format:\n- Module or component to analyze\n- Optional: performance budget or target metrics\n\nOutput format:\n```markdown\n## Performance Analysis\n\n### Critical Issues\n1. **N+1 Query in UserController.index** (auth/controllers/user.js:45)\n   - Impact: 500ms+ for 100 users\n   - Fix: Add eager loading `.includes(:posts)`\n\n### Optimization Opportunities\n1. **Memoization candidate** (utils/calculator.js:23)\n   - Function called 1000+ times with same inputs\n   - Potential savings: 200ms per request\n\n### Summary\n- Total potential improvement: 700ms (60% faster)\n- Estimated effort: 4 hours\n```\n\nUse these tools:\n- Grep: Find patterns (loops, queries, large data structures)\n- Read: Analyze algorithm complexity\n- Glob: Find all files in hot paths\n\nBest practices:\n- Focus on hot paths and frequently called code\n- Consider both time and space complexity\n- Provide before/after performance estimates\n- Suggest profiling tools if needed\n```\n\n**Usage in workflow:**\n\n```flow\n$performance-profiler:\"Analyze API request handlers\":bottlenecks ->\n@review ->\nexpert-code-implementer:\"Optimize based on {bottlenecks}\"\n```\n\n### Example 3: Data Validator\n\n**File:** `temp-agents/data-validator.md`\n\n```markdown\n---\nname: data-validator\nbase: general-purpose\nmodel: haiku\ndescription: Validates data integrity, schema compliance, and business rules\n---\n\nYou are a data validation specialist ensuring data quality and consistency.\n\nYour responsibilities:\n1. Validate data against schema/rules\n2. Check referential integrity\n3. Identify data quality issues (nulls, duplicates, outliers)\n4. Report statistics and violations\n\nInput format:\n- Data source (file path, database table, API response)\n- Validation rules or schema\n\nOutput format:\n```json\n{\n  \"valid\": false,\n  \"total_records\": 1000,\n  \"violations\": [\n    {\n      \"rule\": \"email_required\",\n      \"count\": 45,\n      \"examples\": [\"row 23\", \"row 67\", \"row 89\"]\n    },\n    {\n      \"rule\": \"age_range\",\n      \"count\": 12,\n      \"details\": \"Values outside 0-120 range\"\n    }\n  ],\n  \"statistics\": {\n    \"null_emails\": 45,\n    \"duplicate_ids\": 8,\n    \"invalid_dates\": 3\n  }\n}\n```\n\nUse these tools:\n- Read: Load data files\n- Bash: Run validation scripts or database queries\n\nBest practices:\n- Validate both structure and semantics\n- Provide specific row/record references\n- Suggest fixes for common violations\n- Report both errors and warnings\n```\n\n**Usage in workflow:**\n\n```flow\n$data-validator:\"Validate user import CSV against schema\":validation_report ->\ngeneral-purpose:\"Fix validation errors in {validation_report}\" ->\n$data-validator:\"Re-validate fixed data\":final_report\n```\n\n### Example 4: Documentation Generator\n\n**File:** `temp-agents/doc-generator.md`\n\n```markdown\n---\nname: doc-generator\nbase: general-purpose\nmodel: sonnet\ndescription: Generates comprehensive documentation from code analysis\n---\n\nYou are a technical writer specializing in creating clear, comprehensive documentation.\n\nYour responsibilities:\n1. Analyze code structure and functionality\n2. Generate API documentation\n3. Create usage examples\n4. Document edge cases and limitations\n\nInput format:\n- Code files or modules to document\n- Documentation format preference (Markdown, JSDoc, OpenAPI)\n\nOutput format:\n```markdown\n# Module Name\n\n## Overview\nBrief description of module purpose and functionality.\n\n## API Reference\n\n### `functionName(param1, param2)`\nDescription of what the function does.\n\n**Parameters:**\n- `param1` (type): Description\n- `param2` (type): Description\n\n**Returns:** Return type and description\n\n**Example:**\n\\`\\`\\`javascript\nconst result = functionName('value1', 'value2');\n\\`\\`\\`\n\n**Edge Cases:**\n- What happens if param1 is null\n- Behavior with empty arrays\n\n## Usage Guide\nStep-by-step guide for common use cases.\n```\n\nUse these tools:\n- Read: Examine source code\n- Grep: Find usage examples in tests\n- Glob: Discover related files\n\nBest practices:\n- Include practical examples\n- Document edge cases and error handling\n- Keep language clear and concise\n- Link to related documentation\n```\n\n**Usage in workflow:**\n\n```flow\n$doc-generator:\"Generate API docs for auth module\":api_docs ->\ncode-reviewer:\"Review {api_docs} for accuracy\" ->\ngeneral-purpose:\"Create getting-started guide using {api_docs}\"\n```\n\n### Example 5: Code Transformer\n\n**File:** `temp-agents/code-transformer.md`\n\n```markdown\n---\nname: code-transformer\nbase: expert-code-implementer\nmodel: sonnet\ndescription: Transforms code between patterns, frameworks, or styles\n---\n\nYou are a code refactoring expert specializing in transforming code while preserving functionality.\n\nYour responsibilities:\n1. Transform code to new patterns/frameworks\n2. Maintain functionality and tests\n3. Update imports and dependencies\n4. Preserve comments and documentation\n\nInput format:\n- Source code or files to transform\n- Target pattern/framework/style\n- Transformation rules\n\nOutput format:\n```markdown\n## Transformation Summary\n\n**Files transformed:** 12\n**Pattern:** Class components ‚Üí Functional components with hooks\n\n### Changes Made\n\n1. **UserProfile.jsx**\n   - Converted class component to function\n   - Replaced `componentDidMount` with `useEffect`\n   - Converted state to `useState` hooks\n\n2. **Dashboard.jsx**\n   - Similar transformations\n   - Added custom hook `useAuth` for auth logic\n\n### Breaking Changes\nNone - all tests passing\n\n### Manual Review Needed\n- Authentication.jsx: Complex lifecycle - review useEffect dependencies\n```\n\nUse these tools:\n- Read: Load source files\n- Edit: Apply transformations\n- Bash: Run tests after transformation\n\nBest practices:\n- Transform incrementally, test frequently\n- Preserve git history with meaningful commits\n- Document breaking changes\n- Maintain code style consistency\n```\n\n**Usage in workflow:**\n\n```flow\n$code-transformer:\"Convert class components to hooks\":transformation ->\ngeneral-purpose:\"Run tests and verify {transformation}\" ->\ncode-reviewer:\"Review transformed code quality\"\n```\n\n### Example 6: Test Generator\n\n**File:** `temp-agents/test-generator.md`\n\n```markdown\n---\nname: test-generator\nbase: general-purpose\nmodel: sonnet\ndescription: Generates comprehensive test suites from code analysis\n---\n\nYou are a testing expert specializing in creating thorough, maintainable test suites.\n\nYour responsibilities:\n1. Analyze code to identify test cases\n2. Generate unit, integration, and edge case tests\n3. Ensure high coverage of critical paths\n4. Follow testing best practices (AAA, no test interdependence)\n\nInput format:\n- Code files or modules to test\n- Testing framework (Jest, Mocha, pytest, etc.)\n- Coverage requirements\n\nOutput format:\n```javascript\n// UserService.test.js\n\ndescribe('UserService', () => {\n  describe('createUser', () => {\n    it('should create user with valid data', async () => {\n      // Arrange\n      const userData = { email: 'test@example.com', name: 'Test User' };\n\n      // Act\n      const user = await UserService.createUser(userData);\n\n      // Assert\n      expect(user).toBeDefined();\n      expect(user.email).toBe(userData.email);\n    });\n\n    it('should throw error with invalid email', async () => {\n      // Arrange\n      const userData = { email: 'invalid', name: 'Test' };\n\n      // Act & Assert\n      await expect(UserService.createUser(userData))\n        .rejects.toThrow('Invalid email format');\n    });\n\n    // Edge cases...\n  });\n});\n```\n\nUse these tools:\n- Read: Analyze source code\n- Grep: Find existing test patterns\n- Write: Create test files\n\nBest practices:\n- Test happy path, edge cases, and error conditions\n- Use descriptive test names\n- Follow AAA pattern (Arrange, Act, Assert)\n- Mock external dependencies\n- Aim for meaningful coverage, not just high percentage\n```\n\n**Usage in workflow:**\n\n```flow\n$test-generator:\"Generate tests for auth module\":test_suite ->\ngeneral-purpose:\"Run {test_suite} and report coverage\" ->\ncode-reviewer:\"Review test quality and completeness\"\n```\n\n### Example 7: API Client Generator\n\n**File:** `temp-agents/api-client-generator.md`\n\n```markdown\n---\nname: api-client-generator\nbase: expert-code-implementer\nmodel: sonnet\ndescription: Generates type-safe API client code from OpenAPI/Swagger specs\n---\n\nYou are an API integration expert specializing in generating robust client libraries.\n\nYour responsibilities:\n1. Parse API specifications (OpenAPI, Swagger)\n2. Generate type-safe client code\n3. Include error handling and retries\n4. Create usage documentation\n\nInput format:\n- OpenAPI/Swagger spec (URL or file)\n- Target language (TypeScript, Python, Go)\n- Client library preferences (axios, fetch, requests)\n\nOutput format:\n```typescript\n// Generated API Client\n\nexport interface User {\n  id: number;\n  email: string;\n  name: string;\n}\n\nexport interface CreateUserRequest {\n  email: string;\n  name: string;\n}\n\nexport class UserApiClient {\n  constructor(private baseUrl: string, private apiKey: string) {}\n\n  async getUser(userId: number): Promise<User> {\n    const response = await fetch(`${this.baseUrl}/users/${userId}`, {\n      headers: { 'Authorization': `Bearer ${this.apiKey}` }\n    });\n\n    if (!response.ok) {\n      throw new ApiError(response.status, await response.text());\n    }\n\n    return response.json();\n  }\n\n  async createUser(data: CreateUserRequest): Promise<User> {\n    // Implementation with validation, error handling, retries\n  }\n}\n\n// Usage example and documentation\n```\n\nUse these tools:\n- WebFetch: Retrieve OpenAPI specs from URLs\n- Read: Load local spec files\n- Write: Create generated client files\n\nBest practices:\n- Generate TypeScript interfaces from schemas\n- Include JSDoc comments with examples\n- Add request/response validation\n- Implement retry logic for transient failures\n- Provide clear error messages\n```\n\n**Usage in workflow:**\n\n```flow\n$api-client-generator:\"Generate TypeScript client from OpenAPI spec\":client_code ->\ngeneral-purpose:\"Create integration tests for {client_code}\" ->\ncode-reviewer:\"Review generated client quality\"\n```\n\n## Best Practices\n\n### Creating Effective Temp Agents\n\n#### Make Prompts Comprehensive\n\nAgents have **no context** beyond their prompt. Include everything they need:\n\n**Good prompt:**\n```markdown\nYou are a security expert specializing in OWASP vulnerabilities.\n\nScan for:\n- SQL injection (raw queries, string concatenation)\n- XSS (innerHTML, unescaped output)\n- CSRF (missing tokens on state-changing operations)\n\nProvide:\n- File paths and line numbers\n- Severity rating\n- Specific fix recommendations\n\nUse Grep to search for vulnerable patterns, Read to examine context.\n```\n\n**Bad prompt:**\n```markdown\nCheck for security issues.\n```\n\n#### Include Tool Recommendations\n\nTell agents **when and how** to use specific tools:\n\n```markdown\nUse these tools:\n- Read: Examine files you need detailed analysis of\n- Grep: Search codebase for patterns (*.js files, specific functions)\n- Glob: Find all files matching criteria (test files, config files)\n- Edit: Apply fixes to code\n- Bash: Run validation scripts or tests\n```\n\n#### Define Clear Output Formats\n\nSpecify **exactly** what format you expect:\n\n```markdown\nOutput format:\n```json\n{\n  \"issues\": [\n    {\"file\": \"path/to/file.js\", \"line\": 42, \"severity\": \"high\", \"description\": \"...\"}\n  ],\n  \"summary\": {\n    \"total\": 10,\n    \"critical\": 2,\n    \"high\": 5\n  }\n}\n```\n```\n\n#### Handle Edge Cases\n\nInclude guidance for common edge cases:\n\n```markdown\nEdge cases to handle:\n- If no issues found, return empty array\n- If file cannot be read, log error and continue\n- If pattern is ambiguous, ask for clarification\n- If multiple files match, process all of them\n```\n\n#### Specify Success Criteria\n\nDefine what \"done\" means:\n\n```markdown\nSuccess criteria:\n- All files in specified directory scanned\n- Issues categorized by severity\n- At least one example provided for each issue type\n- Recommendations include code snippets\n```\n\n### Naming Temp Agents\n\n#### Good Names\n\n- **Descriptive**: `security-scanner`, `performance-profiler`, `api-doc-generator`\n- **Domain-specific**: `sql-query-optimizer`, `react-hook-converter`\n- **Action-oriented**: `test-generator`, `schema-validator`\n\n#### Bad Names\n\n- **Generic**: `helper`, `agent1`, `analyzer`\n- **Vague**: `doer`, `processor`, `handler`\n- **Too long**: `comprehensive-security-vulnerability-scanner-and-reporter`\n\n### Model Selection\n\nChoose models based on task complexity:\n\n| Model | Use For | Characteristics |\n|-------|---------|----------------|\n| **Opus** | Complex analysis, security audits, architecture | Highest quality, slowest, most expensive |\n| **Sonnet** | General implementation, balanced tasks | Good quality, reasonable speed, moderate cost |\n| **Haiku** | Fast exploration, simple validation, parallel tasks | Fast, cheap, good for simple tasks |\n\n**Example:**\n```flow\n$security-scanner (opus):\"Deep vulnerability analysis\":issues ->\n$quick-validator (haiku):\"Validate fix syntax\":validation ->\n$implementer (sonnet):\"Apply fixes\"\n```\n\n### Variable Management\n\n#### Use Descriptive Variable Names\n\n**Good:**\n```flow\n:scan_results\n:vulnerabilities\n:performance_metrics\n:api_documentation\n```\n\n**Bad:**\n```flow\n:output\n:result\n:data\n:x\n```\n\n#### Track Variable Flow\n\nEnsure variables flow logically:\n\n```flow\n$analyzer:\"Scan code\":issues ->\n$fixer:\"Fix {issues}\":fixes ->\ngeneral-purpose:\"Verify {fixes} resolved {issues}\"\n```\n\nVariables should be:\n1. **Produced** before being consumed\n2. **Named** consistently throughout workflow\n3. **Scoped** to relevant parts of workflow\n\n## Agent Promotion\n\nAfter workflow completion, you can promote valuable temp agents to permanent defined agents.\n\n### When to Promote\n\nPromote agents that are:\n\n- **Reusable** - Useful across multiple workflows\n- **Well-tested** - Successfully completed workflow execution\n- **Generic** - Not tied to specific files or project context\n- **Valuable** - Provide domain expertise worth keeping\n\n### When NOT to Promote\n\nDon't promote agents that are:\n\n- **One-time use** - Created for single specific workflow\n- **Workflow-specific** - Reference specific files or project details\n- **Untested** - Haven't been validated in real workflow\n- **Duplicative** - Similar to existing defined agents\n\n### Promotion Process\n\nAfter workflow completion:\n\n1. **Review Phase** - System analyzes each temp agent for reusability\n2. **Recommendations** - AI suggests which agents to save\n3. **Selection** - Choose which agents to promote\n4. **Processing** - Selected agents moved to `agents/` and registered\n5. **Cleanup** - Unselected agents deleted\n\n**Example prompt:**\n\n```\nWorkflow complete!\n\nTemp agents used:\n‚úì [Recommended] security-scanner\n  Generic security analysis - reusable across projects\n\n‚úó [Not recommended] auth-fixer\n  Contains project-specific file references\n\nSelect agents to save: [1]\n\nSaved: security-scanner ‚Üí agents/security-scanner.md\nCleaned up: auth-fixer\n```\n\nFor complete promotion details, see [promotion.md](promotion.md).\n\n## Cleanup\n\n### Automatic Cleanup\n\nTemp agents are **automatically deleted** after workflow completion unless promoted.\n\nCleaned files:\n- `temp-agents/*.md` - Agent definition files\n- `examples/*-data.json` - Workflow-specific data files\n\n**Example:**\n```\nCleaned up 2 temporary file(s):\n  - temp-agents/security-scanner.md\n  - temp-agents/performance-profiler.md\n```\n\n### What Happens to Unsaved Agents\n\nUnsaved temp agents are permanently deleted:\n- Agent files removed from `temp-agents/`\n- No entry in `agents/registry.json`\n- Not available in future workflows\n- Must be recreated if needed again\n\n### Manual Cleanup\n\nTo manually clean up temp agents:\n\n```bash\n# Remove all temp agents\nrm -rf temp-agents/*.md\n\n# Remove specific temp agent\nrm temp-agents/my-agent.md\n```\n\nFor complete cleanup details, see the cleanup section in [SKILL.md](SKILL.md).\n\n## Common Issues\n\n### Agent Not Found\n\n**Error:** `Temporary agent '$scanner' not found`\n\n**Causes:**\n- Typo in agent name\n- Agent file doesn't exist in `temp-agents/`\n- Agent was already cleaned up\n- Wrong directory\n\n**Fix:**\n```bash\n# Check if agent file exists\nls temp-agents/scanner.md\n\n# Verify agent name matches file name\n# File: scanner.md, Reference: $scanner\n```\n\n### Missing Variable\n\n**Error:** `Variable 'results' referenced but not produced`\n\n**Cause:** No agent captures output to this variable\n\n**Fix:**\n```flow\n# Before (error)\n$agent1:\"Task\" ->\ngeneral-purpose:\"Use {results}\"\n\n# After (fixed)\n$agent1:\"Task\":results ->\ngeneral-purpose:\"Use {results}\"\n```\n\n### Variable Not Ready\n\n**Error:** `Cannot execute: missing variables: results`\n\n**Cause:** Agent tries to use variable before it's produced\n\n**Fix:**\n```flow\n# Ensure producer runs before consumer\n$producer:\"Generate data\":results ->\n$consumer:\"Process {results}\"\n```\n\n### Invalid Frontmatter\n\n**Error:** `Invalid agent definition: missing required field 'base'`\n\n**Cause:** YAML frontmatter incomplete\n\n**Fix:**\n```markdown\n---\nname: my-agent\nbase: general-purpose    # Required!\ndescription: What it does # Required!\n---\n```\n\n## Related Documentation\n\n- **[SKILL.md](SKILL.md)** - Complete agent management overview\n- **[promotion.md](promotion.md)** - Detailed promotion process *(to be created)*\n- **[defined-agents.md](defined-agents.md)** - Creating permanent agents *(to be created)*\n- **[namespacing.md](namespacing.md)** - Agent namespace conventions *(to be created)*\n- **[docs/features/temporary-agents.md](/Users/mbroler/.claude/plugins/repos/orchestration/docs/features/temporary-agents.md)** - Technical specification\n- **[docs/reference/temp-agents-syntax.md](/Users/mbroler/.claude/plugins/repos/orchestration/docs/reference/temp-agents-syntax.md)** - Syntax reference\n\n## Quick Reference\n\n### File Structure\n\n```\ntemp-agents/\n  my-agent.md          # Your temp agent definition\n\nagents/\n  promoted-agent.md    # Promoted permanent agents\n  registry.json        # Agent registry\n```\n\n### Workflow Syntax\n\n```flow\n# Reference temp agent\n$agent-name:\"instruction\"\n\n# With output capture\n$agent-name:\"instruction\":variable\n\n# With variable interpolation\n$agent:\"Use {previous_variable}\":new_variable\n```\n\n### YAML Frontmatter\n\n```yaml\n---\nname: agent-name        # Required: kebab-case identifier\nbase: general-purpose   # Required: base agent type\nmodel: sonnet          # Optional: opus|sonnet|haiku\ndescription: Brief summary  # Required: one-line description\n---\n```\n\n---\n\n**Ready to create temp agents? Start designing workflows with `/orchestration:create`!**\n",
        "skills/managing-temp-scripts/SKILL.md": "---\nname: managing-temp-scripts\ndescription: Create and execute temporary scripts (Python, Node.js, shell) during workflow execution for API integrations, data processing, and custom tools. Use when user needs to interact with external APIs, process data with specific libraries, or create temporary executable code.\n---\n\n# Managing Temporary Scripts\n\nI help you create and execute temporary scripts during workflow execution. Perfect for API integrations, data processing with specialized libraries, and creating temporary tools that execute and return results.\n\n## When I Activate\n\nI automatically activate when you:\n- Need to interact with external APIs (Reddit, Twitter, GitHub, etc.)\n- Want to use specific libraries not available in Claude Code\n- Need to process data with custom code\n- Ask \"how do I call an API in a workflow?\"\n- Mention \"temporary script\", \"execute code\", \"API client\"\n- Need credentials/API keys for external services\n\n## Key Concept\n\n**Temporary scripts are code files that:**\n1. Are created during workflow execution\n2. Execute via Bash tool\n3. Return results to workflow\n4. Are automatically cleaned up after workflow completion\n\n**Supported Languages:**\n- Python (with pip packages)\n- Node.js/JavaScript (with npm packages)\n- Shell/Bash scripts\n- Ruby, Go, or any executable language\n\n## Quick Example\n\n```flow\n# 1. Ask for API credentials\nAskUserQuestion:\"Reddit API key needed\":api_key ->\n\n# 2. Create Python script with embedded credentials\ngeneral-purpose:\"Create Python script: reddit_client.py with {api_key}\":script_path ->\n\n# 3. Execute script and capture output\nBash:\"python3 {script_path}\":reddit_data ->\n\n# 4. Process results in workflow\ngeneral-purpose:\"Analyze {reddit_data} and create summary\":analysis ->\n\n# 5. Cleanup happens automatically\n```\n\n## Script Lifecycle\n\nSee [script-lifecycle.md](script-lifecycle.md) for complete details.\n\n**Overview:**\n\n```\n1. Creation\n   ‚Üì\n   Write script to /tmp/workflow-scripts/\n\n2. Preparation\n   ‚Üì\n   Set permissions (chmod +x)\n   Install dependencies if needed\n\n3. Execution\n   ‚Üì\n   Run via Bash tool\n   Capture stdout/stderr\n\n4. Data Return\n   ‚Üì\n   Parse output (JSON, CSV, text)\n   Pass to next workflow step\n\n5. Cleanup\n   ‚Üì\n   Remove script files\n   Clean temp directories\n```\n\n## Common Use Cases\n\n### 1. API Integration\n\n**Reddit API Client:**\n```python\n# /tmp/workflow-scripts/reddit_client.py\nimport requests\nimport json\nimport sys\n\napi_key = sys.argv[1]\nsubreddit = sys.argv[2]\n\nheaders = {'Authorization': f'Bearer {api_key}'}\nresponse = requests.get(\n    f'https://oauth.reddit.com/r/{subreddit}/hot.json',\n    headers=headers\n)\n\nprint(json.dumps(response.json(), indent=2))\n```\n\n**In workflow:**\n```flow\n$script-creator:\"Create reddit_client.py\":script ->\nBash:\"python3 {script} {api_key} programming\":posts ->\ngeneral-purpose:\"Parse {posts} and extract top 10 titles\"\n```\n\n### 2. Data Processing\n\n**CSV Analysis:**\n```python\n# /tmp/workflow-scripts/analyze_data.py\nimport pandas as pd\nimport sys\n\ndf = pd.read_csv(sys.argv[1])\nsummary = df.describe().to_json()\nprint(summary)\n```\n\n**In workflow:**\n```flow\ngeneral-purpose:\"Create analyze_data.py script\":script ->\nBash:\"pip install pandas && python3 {script} data.csv\":analysis ->\ngeneral-purpose:\"Interpret {analysis} and create report\"\n```\n\n### 3. Web Scraping\n\n**Article Scraper:**\n```javascript\n// /tmp/workflow-scripts/scraper.js\nconst axios = require('axios');\nconst cheerio = require('cheerio');\n\nasync function scrapeArticles(url) {\n  const {data} = await axios.get(url);\n  const $ = cheerio.load(data);\n\n  const articles = [];\n  $('.article').each((i, el) => {\n    articles.push({\n      title: $(el).find('.title').text(),\n      url: $(el).find('a').attr('href')\n    });\n  });\n\n  console.log(JSON.stringify(articles));\n}\n\nscrapeArticles(process.argv[2]);\n```\n\n**In workflow:**\n```flow\ngeneral-purpose:\"Create scraper.js\":script ->\nBash:\"npm install axios cheerio && node {script} https://news.site\":articles ->\ngeneral-purpose:\"Process {articles}\"\n```\n\n## Script Templates\n\nSee [script-templates.md](script-templates.md) for complete library.\n\n**Quick templates:**\n\n- **API Client** (REST, GraphQL)\n- **Data Processing** (CSV, JSON, XML)\n- **Web Scraping** (HTML parsing)\n- **File Processing** (PDF, images, documents)\n- **Database Access** (PostgreSQL, MySQL, MongoDB)\n- **Message Queues** (RabbitMQ, Kafka)\n- **Cloud Services** (AWS S3, GCS, Azure)\n\n## Security Best Practices\n\nSee [security.md](security.md) for comprehensive guide.\n\n**Quick checklist:**\n\n‚úÖ **Credentials Management:**\n- Pass via command-line arguments (not hardcoded)\n- Use environment variables for sensitive data\n- Clean up after execution\n\n‚úÖ **File Permissions:**\n```bash\nchmod 700 /tmp/workflow-scripts/script.py  # Owner only\n```\n\n‚úÖ **Output Sanitization:**\n- Validate script output before using\n- Escape special characters\n- Limit output size\n\n‚úÖ **Dependency Management:**\n- Use virtual environments for Python\n- Specify exact package versions\n- Avoid running arbitrary code\n\n## Integration with Workflows\n\nSee [integration-patterns.md](integration-patterns.md) for detailed patterns.\n\n### Pattern 1: Simple Script Execution\n\n```flow\ngeneral-purpose:\"Create script.py that fetches data\":script ->\nBash:\"python3 {script}\":data ->\ngeneral-purpose:\"Process {data}\"\n```\n\n### Pattern 2: Script with User Input\n\n```flow\nAskUserQuestion:\"API credentials needed\":creds ->\ngeneral-purpose:\"Create api_client.py with {creds}\":script ->\nBash:\"python3 {script}\":results ->\ngeneral-purpose:\"Analyze {results}\"\n```\n\n### Pattern 3: Parallel Script Execution\n\n```flow\ngeneral-purpose:\"Create multiple API clients\":scripts ->\n[\n  Bash:\"python3 {scripts.reddit}\":reddit_data ||\n  Bash:\"python3 {scripts.twitter}\":twitter_data ||\n  Bash:\"python3 {scripts.github}\":github_data\n] ->\ngeneral-purpose:\"Merge all data sources\"\n```\n\n### Pattern 4: Iterative Processing\n\n```flow\n@process_batch ->\ngeneral-purpose:\"Create batch_processor.py\":script ->\nBash:\"python3 {script} batch_{n}\":results ->\n(if results.has_more)~> @process_batch ~>\n(if results.complete)~> general-purpose:\"Finalize\"\n```\n\n## Script Directory Structure\n\n```\n/tmp/workflow-scripts/\n‚îú‚îÄ‚îÄ {workflow-id}/              # Unique per workflow\n‚îÇ   ‚îú‚îÄ‚îÄ reddit_client.py\n‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py\n‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies\n‚îÇ   ‚îú‚îÄ‚îÄ package.json            # Node.js dependencies\n‚îÇ   ‚îî‚îÄ‚îÄ .env                    # Environment variables\n```\n\n**Automatic cleanup after workflow:**\n```bash\nrm -rf /tmp/workflow-scripts/{workflow-id}\n```\n\n## Creating Scripts in Workflows\n\n### Method 1: Inline Script Creation\n\n```flow\ngeneral-purpose:\"Create Python script:\n```python\nimport requests\nimport sys\n\napi_key = sys.argv[1]\nresponse = requests.get(\n    'https://api.example.com/data',\n    headers={'Authorization': f'Bearer {api_key}'}\n)\nprint(response.text)\n```\nSave to /tmp/workflow-scripts/api_client.py\":script_path ->\n\nBash:\"python3 {script_path} {api_key}\":data\n```\n\n### Method 2: Template-Based Creation\n\n```flow\ngeneral-purpose:\"Use template: api-rest-client\n- Language: Python\n- API: Reddit\n- Auth: Bearer token\n- Output: JSON\nCreate script in /tmp/workflow-scripts/\":script ->\n\nBash:\"python3 {script}\":data\n```\n\n### Method 3: Multi-File Scripts\n\n```flow\ngeneral-purpose:\"Create script package:\n- main.py (entry point)\n- utils.py (helper functions)\n- requirements.txt (dependencies)\nSave to /tmp/workflow-scripts/package/\":package_path ->\n\nBash:\"cd {package_path} && pip install -r requirements.txt && python3 main.py\":data\n```\n\n## Dependency Management\n\n### Python (pip)\n\n```flow\ngeneral-purpose:\"Create requirements.txt:\nrequests==2.31.0\npandas==2.0.0\nSave to /tmp/workflow-scripts/\":deps ->\n\ngeneral-purpose:\"Create script.py\":script ->\n\nBash:\"pip install -r {deps} && python3 {script}\":data\n```\n\n### Node.js (npm)\n\n```flow\ngeneral-purpose:\"Create package.json with dependencies\":package ->\n\ngeneral-purpose:\"Create script.js\":script ->\n\nBash:\"cd /tmp/workflow-scripts && npm install && node {script}\":data\n```\n\n### Virtual Environments\n\n```flow\nBash:\"python3 -m venv /tmp/workflow-scripts/venv\":venv ->\n\ngeneral-purpose:\"Create script in venv\":script ->\n\nBash:\"source /tmp/workflow-scripts/venv/bin/activate && python3 {script}\":data\n```\n\n## Error Handling\n\n### Capturing Errors\n\n```flow\nBash:\"python3 {script} 2>&1\":output ->\n\n(if output.contains('Error'))~>\n  general-purpose:\"Parse error: {output}\":error ->\n  @review-error:\"Script failed: {error}\" ~>\n\n(if output.success)~>\n  general-purpose:\"Process {output}\"\n```\n\n### Retry Logic\n\n```flow\n@retry ->\nBash:\"python3 {script}\":result ->\n\n(if result.failed)~>\n  general-purpose:\"Wait 5 seconds\" ->\n  @retry ~>\n\n(if result.success)~>\n  general-purpose:\"Process {result}\"\n```\n\n## Output Formats\n\nScripts can return data in various formats:\n\n### JSON (Recommended)\n\n```python\nimport json\nresult = {\"data\": [...], \"status\": \"success\"}\nprint(json.dumps(result))\n```\n\n### CSV\n\n```python\nimport csv\nimport sys\nwriter = csv.writer(sys.stdout)\nwriter.writerows(data)\n```\n\n### Plain Text\n\n```python\nfor item in results:\n    print(f\"{item['title']}: {item['url']}\")\n```\n\n## Cleanup\n\n### Automatic Cleanup\n\nCleanup happens automatically after workflow completion:\n\n```flow\n# At end of workflow execution:\ngeneral-purpose:\"Remove all scripts in /tmp/workflow-scripts/{workflow-id}\"\n```\n\n### Manual Cleanup\n\nFor long-running workflows:\n\n```flow\ngeneral-purpose:\"Create and execute script\":result ->\ngeneral-purpose:\"Process {result}\":output ->\nBash:\"rm -rf /tmp/workflow-scripts/{script-dir}\":cleanup\n```\n\n## Best Practices\n\n### DO:\n\n‚úÖ Use unique workflow IDs for script directories\n‚úÖ Pass credentials as arguments, not hardcoded\n‚úÖ Validate and sanitize script output\n‚úÖ Use virtual environments for Python\n‚úÖ Specify exact dependency versions\n‚úÖ Return structured data (JSON preferred)\n‚úÖ Clean up after workflow completion\n‚úÖ Set restrictive file permissions\n‚úÖ Use timeouts for script execution\n‚úÖ Log script output for debugging\n\n### DON'T:\n\n‚ùå Hardcode API keys in scripts\n‚ùå Execute untrusted code\n‚ùå Store sensitive data in script files\n‚ùå Leave scripts after workflow\n‚ùå Use global Python/Node packages\n‚ùå Ignore script errors\n‚ùå Return massive outputs (>1MB)\n‚ùå Use system-wide directories\n\n## Tips for Effective Script Management\n\n1. **Use Descriptive Names**: `reddit_api_client.py` not `script.py`\n\n2. **Return Structured Data**: Always use JSON when possible\n\n3. **Error Messages**: Include detailed error messages in output\n\n4. **Logging**: Add logging for debugging:\n```python\nimport logging\nlogging.basicConfig(level=logging.INFO)\nlogging.info(f\"Fetching data from {url}\")\n```\n\n5. **Validation**: Validate inputs before execution\n\n6. **Timeouts**: Set execution timeouts:\n```flow\nBash:\"timeout 30 python3 {script}\":data\n```\n\n## Related Skills\n\n- **creating-workflows**: Create workflows that use temp scripts\n- **executing-workflows**: Execute workflows with script steps\n- **managing-agents**: Temp agents vs temp scripts\n- **debugging-workflows**: Debug script execution issues\n\n## Advanced Topics\n\nSee detail files for:\n- [script-lifecycle.md](script-lifecycle.md) - Complete lifecycle management\n- [script-templates.md](script-templates.md) - 20+ ready-to-use templates\n- [security.md](security.md) - Security best practices\n- [integration-patterns.md](integration-patterns.md) - Workflow integration patterns\n\n---\n\n**Ready to use temporary scripts? Just describe what API or processing you need!**\n",
        "skills/managing-temp-scripts/integration-patterns.md": "# Workflow Integration Patterns for Temporary Scripts\n\nComplete patterns for integrating temporary scripts into orchestration workflows.\n\n## Pattern Categories\n\n1. [Basic Patterns](#basic-patterns) - Simple script execution\n2. [Data Collection Patterns](#data-collection-patterns) - API data fetching\n3. [Processing Patterns](#processing-patterns) - Data transformation pipelines\n4. [Integration Patterns](#integration-patterns) - Multi-service orchestration\n5. [Advanced Patterns](#advanced-patterns) - Complex workflow scenarios\n\n---\n\n## Basic Patterns\n\n### Pattern 1: Simple Script Execution\n\n**Use Case**: Execute a single script and process results\n\n**Workflow**:\n```flow\ngeneral-purpose:\"Create data_fetcher.py script\":script_path ->\nBash:\"python3 {script_path}\":data ->\ngeneral-purpose:\"Parse and analyze {data}\":results\n```\n\n**Script** (`data_fetcher.py`):\n```python\n#!/usr/bin/env python3\nimport json\nimport requests\n\nresponse = requests.get('https://api.example.com/data')\nprint(json.dumps(response.json()))\n```\n\n**Data Flow**:\n```\nworkflow ‚Üí create script ‚Üí execute ‚Üí capture output ‚Üí process results\n```\n\n**Error Handling**:\n```flow\nBash:\"python3 {script_path} 2>&1\":output ->\n(if output.contains('Error'))~>\n  @review-error:\"Script failed: {output}\" ~>\n(if output.success)~>\n  general-purpose:\"Process {output}\"\n```\n\n---\n\n### Pattern 2: Script with User Input\n\n**Use Case**: Script needs user-provided credentials or parameters\n\n**Workflow**:\n```flow\nAskUserQuestion:\"API credentials needed\":api_key ->\ngeneral-purpose:\"Create reddit_client.py with {api_key}\":script ->\nBash:\"python3 {script} programming 10\":posts ->\ngeneral-purpose:\"Extract titles from {posts}\":titles\n```\n\n**Script** (`reddit_client.py`):\n```python\n#!/usr/bin/env python3\nimport sys\nimport json\nimport requests\n\napi_key = sys.argv[1]\nsubreddit = sys.argv[2]\nlimit = sys.argv[3]\n\nheaders = {'Authorization': f'Bearer {api_key}'}\nresponse = requests.get(\n    f'https://oauth.reddit.com/r/{subreddit}/hot.json?limit={limit}',\n    headers=headers\n)\n\nprint(json.dumps(response.json()))\n```\n\n**Data Flow**:\n```\nuser input ‚Üí embed in script ‚Üí execute with args ‚Üí parse output ‚Üí use data\n```\n\n**Example Output**:\n```json\n{\n  \"data\": {\n    \"children\": [\n      {\"data\": {\"title\": \"Post 1\", \"url\": \"...\", \"score\": 100}},\n      {\"data\": {\"title\": \"Post 2\", \"url\": \"...\", \"score\": 85}}\n    ]\n  }\n}\n```\n\n---\n\n### Pattern 3: Script with Error Handling\n\n**Use Case**: Robust execution with retry logic\n\n**Workflow**:\n```flow\n@attempt ->\ngeneral-purpose:\"Create api_client.py\":script ->\nBash:\"python3 {script}\":result ->\n\n(if result.contains('RateLimit'))~>\n  general-purpose:\"Wait 60 seconds\" ->\n  @attempt ~>\n\n(if result.contains('Error') AND attempts < 3)~>\n  @attempt ~>\n\n(if result.success)~>\n  general-purpose:\"Process {result}\"\n```\n\n**Script** (`api_client.py`):\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\n\ntry:\n    # API call logic\n    result = fetch_data()\n    print(json.dumps({\"status\": \"success\", \"data\": result}))\nexcept RateLimitError as e:\n    print(json.dumps({\"status\": \"error\", \"type\": \"RateLimit\", \"message\": str(e)}))\n    sys.exit(1)\nexcept Exception as e:\n    print(json.dumps({\"status\": \"error\", \"type\": \"Unknown\", \"message\": str(e)}))\n    sys.exit(1)\n```\n\n---\n\n## Data Collection Patterns\n\n### Pattern 4: Single API Data Fetch\n\n**Use Case**: Fetch data from one API source\n\n**Workflow**:\n```flow\nAskUserQuestion:\"GitHub token needed\":token ->\n\ngeneral-purpose:\"Create github_fetcher.py with {token}\":script ->\n\nBash:\"python3 {script} anthropics claude-code\":repo_data ->\n\ngeneral-purpose:\"Parse {repo_data} and extract: stars, forks, issues\":stats ->\n\ngeneral-purpose:\"Create summary report of {stats}\":report\n```\n\n**Script** (`github_fetcher.py`):\n```python\n#!/usr/bin/env python3\nimport sys\nimport json\nimport requests\n\ntoken = sys.argv[1]\nowner = sys.argv[2]\nrepo = sys.argv[3]\n\nheaders = {'Authorization': f'token {token}'}\nresponse = requests.get(\n    f'https://api.github.com/repos/{owner}/{repo}',\n    headers=headers\n)\n\ndata = response.json()\nprint(json.dumps({\n    \"name\": data['name'],\n    \"stars\": data['stargazers_count'],\n    \"forks\": data['forks_count'],\n    \"issues\": data['open_issues_count'],\n    \"language\": data['language']\n}))\n```\n\n---\n\n### Pattern 5: Multiple API Parallel Fetching\n\n**Use Case**: Collect data from multiple sources simultaneously\n\n**Workflow**:\n```flow\nAskUserQuestion:\"API credentials\":creds ->\n\ngeneral-purpose:\"Create reddit_client.py\":reddit_script ->\ngeneral-purpose:\"Create twitter_client.py\":twitter_script ->\ngeneral-purpose:\"Create github_client.py\":github_script ->\n\n[\n  Bash:\"python3 {reddit_script} {creds.reddit}\":reddit_data ||\n  Bash:\"node {twitter_script} {creds.twitter}\":twitter_data ||\n  Bash:\"python3 {github_script} {creds.github}\":github_data\n] ->\n\ngeneral-purpose:\"Merge {reddit_data}, {twitter_data}, {github_data}\":combined ->\n\ngeneral-purpose:\"Analyze combined social metrics\":insights\n```\n\n**Data Flow**:\n```\ncredentials\n    ‚Üì\ncreate 3 scripts in parallel\n    ‚Üì\nexecute 3 scripts in parallel\n    ‚Üì\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\nreddit_data  twitter_data  github_data\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚Üì\n            merge all sources\n                    ‚Üì\n               analyze\n```\n\n---\n\n### Pattern 6: Paginated Data Collection\n\n**Use Case**: Fetch all pages of data from API\n\n**Workflow**:\n```flow\ngeneral-purpose:\"Create paginated_fetcher.py\":script ->\n\n@fetch_page ->\nBash:\"python3 {script} {page_num}\":page_data ->\n\ngeneral-purpose:\"Parse {page_data}\":parsed ->\n\n(if parsed.has_next_page)~>\n  general-purpose:\"Increment page number\":page_num ->\n  @fetch_page ~>\n\n(if parsed.is_last_page)~>\n  general-purpose:\"Combine all pages\":all_data ->\n  general-purpose:\"Process {all_data}\"\n```\n\n**Script** (`paginated_fetcher.py`):\n```python\n#!/usr/bin/env python3\nimport sys\nimport json\nimport requests\n\npage = int(sys.argv[1])\n\nresponse = requests.get(f'https://api.example.com/data?page={page}')\ndata = response.json()\n\nprint(json.dumps({\n    \"items\": data['items'],\n    \"page\": page,\n    \"has_next\": data.get('next') is not None,\n    \"total_pages\": data.get('total_pages', 1)\n}))\n```\n\n---\n\n## Processing Patterns\n\n### Pattern 7: Sequential Processing Pipeline\n\n**Use Case**: Multi-stage data transformation\n\n**Workflow**:\n```flow\n# Stage 1: Fetch raw data\ngeneral-purpose:\"Create data_fetcher.py\":fetcher ->\nBash:\"python3 {fetcher}\":raw_data ->\n\n# Stage 2: Clean data\ngeneral-purpose:\"Create data_cleaner.py\":cleaner ->\nBash:\"python3 {cleaner} <<< '{raw_data}'\":clean_data ->\n\n# Stage 3: Transform data\ngeneral-purpose:\"Create data_transformer.py\":transformer ->\nBash:\"python3 {transformer} <<< '{clean_data}'\":transformed ->\n\n# Stage 4: Aggregate results\ngeneral-purpose:\"Create aggregator.py\":aggregator ->\nBash:\"python3 {aggregator} <<< '{transformed}'\":final_report\n```\n\n**Data Flow**:\n```\nraw_data ‚Üí clean_data ‚Üí transformed ‚Üí final_report\n```\n\n---\n\n### Pattern 8: Parallel Data Processing\n\n**Use Case**: Process different data types simultaneously\n\n**Workflow**:\n```flow\ngeneral-purpose:\"Fetch dataset\":dataset ->\n\ngeneral-purpose:\"Create csv_processor.py\":csv_proc ->\ngeneral-purpose:\"Create json_processor.py\":json_proc ->\ngeneral-purpose:\"Create xml_processor.py\":xml_proc ->\n\n[\n  Bash:\"python3 {csv_proc} {dataset.csv}\":csv_results ||\n  Bash:\"python3 {json_proc} {dataset.json}\":json_results ||\n  Bash:\"python3 {xml_proc} {dataset.xml}\":xml_results\n] ->\n\ngeneral-purpose:\"Merge {csv_results}, {json_results}, {xml_results}\":combined ->\n\ngeneral-purpose:\"Generate unified report\":report\n```\n\n---\n\n### Pattern 9: Batch Processing with Iteration\n\n**Use Case**: Process large datasets in batches\n\n**Workflow**:\n```flow\ngeneral-purpose:\"Split dataset into batches\":batches ->\n\n@process_batch ->\ngeneral-purpose:\"Get next batch\":current_batch ->\n\ngeneral-purpose:\"Create batch_processor.py\":processor ->\nBash:\"python3 {processor} <<< '{current_batch}'\":batch_result ->\n\ngeneral-purpose:\"Store {batch_result}\":stored ->\n\n(if batches.has_more)~>\n  @process_batch ~>\n\n(if batches.complete)~>\n  general-purpose:\"Combine all batch results\":final_results\n```\n\n**Script** (`batch_processor.py`):\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\n\n# Read batch from stdin\nbatch = json.load(sys.stdin)\n\n# Process each item\nresults = []\nfor item in batch['items']:\n    processed = process_item(item)\n    results.append(processed)\n\nprint(json.dumps({\n    \"batch_id\": batch['id'],\n    \"processed_count\": len(results),\n    \"results\": results\n}))\n```\n\n---\n\n## Integration Patterns\n\n### Pattern 10: Multi-Service Orchestration\n\n**Use Case**: Coordinate multiple services in workflow\n\n**Workflow**:\n```flow\n# Collect from multiple sources\n[\n  Bash:\"python3 reddit_api.py\":reddit ||\n  Bash:\"python3 twitter_api.py\":twitter ||\n  Bash:\"python3 github_api.py\":github\n] ->\n\n# Process each source\ngeneral-purpose:\"Analyze {reddit}\":reddit_insights ->\ngeneral-purpose:\"Analyze {twitter}\":twitter_insights ->\ngeneral-purpose:\"Analyze {github}\":github_insights ->\n\n# Cross-reference data\ngeneral-purpose:\"Create cross_referencer.py\":cross_ref ->\nBash:\"python3 {cross_ref} {reddit_insights} {twitter_insights} {github_insights}\":connections ->\n\n# Store in database\ngeneral-purpose:\"Create db_writer.py\":db_writer ->\nBash:\"python3 {db_writer} <<< '{connections}'\":stored ->\n\n# Generate report\ngeneral-purpose:\"Create report_generator.py\":reporter ->\nBash:\"python3 {reporter} {stored}\":final_report\n```\n\n---\n\n### Pattern 11: ETL Pipeline\n\n**Use Case**: Extract, Transform, Load data pipeline\n\n**Workflow**:\n```flow\n# EXTRACT\ngeneral-purpose:\"Create extractors for multiple sources\":extractors ->\n\n[\n  Bash:\"python3 {extractors.postgres}\":pg_data ||\n  Bash:\"python3 {extractors.mongodb}\":mongo_data ||\n  Bash:\"python3 {extractors.api}\":api_data\n] ->\n\n# TRANSFORM\ngeneral-purpose:\"Create transformer.py\":transformer ->\nBash:\"python3 {transformer} {pg_data} {mongo_data} {api_data}\":transformed ->\n\n@review-transformation:\"Check {transformed} quality\" ->\n\n# LOAD\ngeneral-purpose:\"Create loader.py\":loader ->\nBash:\"python3 {loader} <<< '{transformed}'\":loaded ->\n\ngeneral-purpose:\"Verify {loaded} data integrity\":verification\n```\n\n**Transform Script** (`transformer.py`):\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\n\ndef transform_data(sources):\n    \"\"\"Transform data from multiple sources into unified format\"\"\"\n    transformed = []\n\n    for source in sources:\n        for item in source['data']:\n            transformed.append({\n                \"id\": generate_id(item),\n                \"source\": source['name'],\n                \"normalized_data\": normalize(item),\n                \"metadata\": extract_metadata(item)\n            })\n\n    return transformed\n\n# Read all sources\nsources = json.load(sys.stdin)\nresult = transform_data(sources)\nprint(json.dumps(result))\n```\n\n---\n\n### Pattern 12: Real-Time Data Streaming\n\n**Use Case**: Process streaming data with temp scripts\n\n**Workflow**:\n```flow\n# Start stream listener\ngeneral-purpose:\"Create stream_listener.py\":listener ->\nBash:\"python3 {listener} & echo $!\":listener_pid ->\n\n# Process stream in batches\n@process_stream ->\nBash:\"python3 read_stream_buffer.py\":batch ->\n\n(if batch.has_data)~>\n  general-purpose:\"Create batch_processor.py\":processor ->\n  Bash:\"python3 {processor} <<< '{batch}'\":processed ->\n  general-purpose:\"Store {processed}\":stored ->\n  @process_stream ~>\n\n(if batch.stream_ended)~>\n  Bash:\"kill {listener_pid}\":stopped ->\n  general-purpose:\"Generate final report\"\n```\n\n---\n\n## Advanced Patterns\n\n### Pattern 13: Conditional Script Execution\n\n**Use Case**: Execute different scripts based on workflow state\n\n**Workflow**:\n```flow\ngeneral-purpose:\"Analyze requirements\":reqs ->\n\n(if reqs.type == 'api')~>\n  general-purpose:\"Create api_client.py\":script ->\n  Bash:\"python3 {script} {reqs.params}\":data ~>\n\n(if reqs.type == 'scraping')~>\n  general-purpose:\"Create web_scraper.py\":script ->\n  Bash:\"python3 {script} {reqs.url}\":data ~>\n\n(if reqs.type == 'database')~>\n  general-purpose:\"Create db_query.py\":script ->\n  Bash:\"python3 {script} {reqs.query}\":data ->\n\ngeneral-purpose:\"Process {data} regardless of source\"\n```\n\n---\n\n### Pattern 14: Retry with Exponential Backoff\n\n**Use Case**: Resilient API calls with increasing wait times\n\n**Workflow**:\n```flow\ngeneral-purpose:\"Set attempt=1, delay=1\":state ->\n\n@retry ->\ngeneral-purpose:\"Create api_client.py\":script ->\nBash:\"python3 {script}\":result ->\n\n(if result.failed AND state.attempt < 5)~>\n  general-purpose:\"Calculate backoff: delay * 2\":new_delay ->\n  general-purpose:\"Wait {new_delay} seconds\" ->\n  general-purpose:\"Increment attempt, update delay\":state ->\n  @retry ~>\n\n(if result.failed AND state.attempt >= 5)~>\n  @max-retries-reached:\"Failed after 5 attempts\" ~>\n\n(if result.success)~>\n  general-purpose:\"Process {result}\"\n```\n\n**Script with Detailed Error Info**:\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\nimport requests\n\ntry:\n    response = requests.get('https://api.example.com/data', timeout=10)\n    response.raise_for_status()\n    print(json.dumps({\n        \"status\": \"success\",\n        \"data\": response.json()\n    }))\nexcept requests.exceptions.Timeout:\n    print(json.dumps({\n        \"status\": \"error\",\n        \"type\": \"timeout\",\n        \"retryable\": True\n    }))\n    sys.exit(1)\nexcept requests.exceptions.HTTPError as e:\n    print(json.dumps({\n        \"status\": \"error\",\n        \"type\": \"http_error\",\n        \"code\": e.response.status_code,\n        \"retryable\": e.response.status_code in [429, 500, 502, 503]\n    }))\n    sys.exit(1)\n```\n\n---\n\n### Pattern 15: Dynamic Script Generation\n\n**Use Case**: Generate scripts based on workflow state\n\n**Workflow**:\n```flow\ngeneral-purpose:\"Analyze user requirements\":requirements ->\n\ngeneral-purpose:\"Generate script template based on {requirements}\":template ->\n\ngeneral-purpose:\"Inject parameters into {template}\":custom_script ->\n\nBash:\"python3 {custom_script}\":result ->\n\ngeneral-purpose:\"Validate {result} meets {requirements}\":validation ->\n\n(if validation.passed)~>\n  general-purpose:\"Save {custom_script} as template for reuse\" ~>\n\n(if validation.failed)~>\n  general-purpose:\"Refine {template} based on errors\" ->\n  @retry-generation\n```\n\n**Template Generation Example**:\n```python\ndef generate_api_client(requirements):\n    \"\"\"Generate custom API client based on requirements\"\"\"\n\n    template = f'''#!/usr/bin/env python3\nimport requests\nimport json\nimport sys\n\ndef fetch_data():\n    response = requests.{requirements['method'].lower()}(\n        \"{requirements['endpoint']}\",\n        headers={requirements.get('headers', {})},\n        params={requirements.get('params', {})}\n    )\n    return response.json()\n\nif __name__ == \"__main__\":\n    try:\n        data = fetch_data()\n        print(json.dumps({{\"status\": \"success\", \"data\": data}}))\n    except Exception as e:\n        print(json.dumps({{\"status\": \"error\", \"message\": str(e)}}))\n        sys.exit(1)\n'''\n    return template\n```\n\n---\n\n## Pattern Comparison Matrix\n\n| Pattern | Complexity | Use Case | Scripts | Error Handling |\n|---------|-----------|----------|---------|----------------|\n| Simple Execution | Low | Single task | 1 | Basic |\n| User Input | Low | Needs credentials | 1 | Basic |\n| Error Handling | Medium | Production use | 1 | Advanced |\n| Single API Fetch | Low | One source | 1 | Medium |\n| Parallel Fetching | Medium | Multiple sources | 3+ | Medium |\n| Paginated Collection | Medium | Large datasets | 1 | Medium |\n| Sequential Pipeline | Medium | Multi-stage | 3-5 | Medium |\n| Parallel Processing | Medium | Different types | 3+ | Medium |\n| Batch Processing | High | Very large data | 1-2 | Advanced |\n| Multi-Service | High | Complex integration | 5+ | Advanced |\n| ETL Pipeline | High | Data warehouse | 3+ | Advanced |\n| Streaming | High | Real-time data | 2+ | Advanced |\n| Conditional | Medium | Dynamic flow | 2-3 | Medium |\n| Retry Backoff | Medium | Resilient calls | 1 | Advanced |\n| Dynamic Generation | High | Custom needs | Generated | Advanced |\n\n---\n\n## Real-World Example: Social Media Analytics\n\n**Complete workflow combining multiple patterns:**\n\n```flow\n# Phase 1: Credentials Collection\nAskUserQuestion:\"Social media API keys\":keys ->\n\n# Phase 2: Create Scripts\ngeneral-purpose:\"Create reddit_analyzer.py with {keys.reddit}\":reddit_script ->\ngeneral-purpose:\"Create twitter_analyzer.py with {keys.twitter}\":twitter_script ->\ngeneral-purpose:\"Create github_analyzer.py with {keys.github}\":github_script ->\n\n# Phase 3: Parallel Data Collection\n[\n  Bash:\"python3 {reddit_script} python programming 50\":reddit_data ||\n  Bash:\"python3 {twitter_script} #python #programming 50\":twitter_data ||\n  Bash:\"python3 {github_script} python topics/machine-learning\":github_data\n] ->\n\n# Phase 4: Data Cleaning (Sequential)\ngeneral-purpose:\"Create data_cleaner.py\":cleaner ->\nBash:\"python3 {cleaner} {reddit_data}\":clean_reddit ->\nBash:\"python3 {cleaner} {twitter_data}\":clean_twitter ->\nBash:\"python3 {cleaner} {github_data}\":clean_github ->\n\n# Phase 5: Analysis\ngeneral-purpose:\"Create sentiment_analyzer.py\":sentiment ->\n[\n  Bash:\"python3 {sentiment} <<< '{clean_reddit}'\":reddit_sentiment ||\n  Bash:\"python3 {sentiment} <<< '{clean_twitter}'\":twitter_sentiment ||\n  Bash:\"python3 {sentiment} <<< '{clean_github}'\":github_sentiment\n] ->\n\n# Phase 6: Cross-Platform Insights\ngeneral-purpose:\"Create cross_analyzer.py\":cross ->\nBash:\"python3 {cross} {reddit_sentiment} {twitter_sentiment} {github_sentiment}\":insights ->\n\n# Phase 7: Report Generation\ngeneral-purpose:\"Create report_generator.py\":reporter ->\nBash:\"python3 {reporter} <<< '{insights}'\":final_report ->\n\n# Phase 8: Review\n@review-report:\"Check {final_report}\" ->\n\n# Phase 9: Cleanup (automatic)\ngeneral-purpose:\"Remove all temp scripts\"\n```\n\n**This workflow demonstrates:**\n- User input collection\n- Parallel script execution\n- Sequential processing\n- Error handling at each stage\n- Automatic cleanup\n- Review checkpoints\n\n---\n\n## Best Practices Summary\n\n1. **Always validate script output** before using in workflow\n2. **Use JSON for structured data** exchange\n3. **Handle errors gracefully** with proper exit codes\n4. **Set timeouts** for long-running scripts\n5. **Clean up after workflow** completion\n6. **Use virtual environments** for Python\n7. **Pin dependency versions** exactly\n8. **Pass credentials securely** (args/env vars, never hardcoded)\n9. **Log script execution** for debugging\n10. **Test scripts independently** before workflow integration\n\n---\n\n**Need help implementing a pattern? Just describe your use case!**\n",
        "skills/managing-temp-scripts/script-lifecycle.md": "# Script Lifecycle Documentation\n\n## Overview\n\nThis document describes the complete lifecycle of temporary scripts used in orchestration workflows, from creation through execution to cleanup. Understanding this lifecycle is essential for building reliable workflows that use custom scripts for data processing, API integration, and automation tasks.\n\n**Complete Lifecycle Flow:**\n```\nCreation ‚Üí Dependencies ‚Üí Execution ‚Üí Output Processing ‚Üí Cleanup\n```\n\nEach phase has specific requirements, best practices, and potential failure points that must be handled properly.\n\n---\n\n## Phase 1: Script Creation\n\n### Storage Location\n\nAll temporary scripts are stored in `/tmp/workflow-scripts/` with subdirectories organized by workflow ID:\n\n```\n/tmp/workflow-scripts/\n‚îú‚îÄ‚îÄ workflow-12345/\n‚îÇ   ‚îú‚îÄ‚îÄ reddit_client.py\n‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt\n‚îÇ   ‚îî‚îÄ‚îÄ venv/\n‚îú‚îÄ‚îÄ workflow-67890/\n‚îÇ   ‚îú‚îÄ‚îÄ github_scraper.js\n‚îÇ   ‚îî‚îÄ‚îÄ package.json\n‚îî‚îÄ‚îÄ workflow-11111/\n    ‚îî‚îÄ‚îÄ data_processor.py\n```\n\n### Directory Structure Best Practices\n\n1. **One directory per workflow** - Isolates dependencies and prevents conflicts\n2. **Workflow ID in path** - Enables tracking and debugging\n3. **Group related scripts** - Keep helper files together\n4. **Clear naming** - Use descriptive names that indicate purpose\n\n### File Naming Conventions\n\n**Python Scripts:**\n```\nsnake_case_name.py\nreddit_api_client.py\ndata_processor.py\n```\n\n**Node.js Scripts:**\n```\ncamelCaseName.js or kebab-case-name.js\ngithubScraper.js or github-scraper.js\ndataProcessor.js\n```\n\n**Shell Scripts:**\n```\nkebab-case-name.sh\nprocess-data.sh\n```\n\n### Permission Setting\n\nAll scripts must be made executable immediately after creation:\n\n```bash\nchmod 700 /tmp/workflow-scripts/workflow-12345/script.py\n```\n\n**Permission Levels:**\n- `700` - Owner can read, write, execute (recommended for security)\n- `755` - Owner full, others read+execute (use if sharing needed)\n- Never use `777` - Security risk\n\n### Creation Example\n\n```python\n# Step 1: Create workflow directory\nimport os\nworkflow_id = \"workflow-12345\"\nscript_dir = f\"/tmp/workflow-scripts/{workflow_id}\"\nos.makedirs(script_dir, exist_ok=True)\n\n# Step 2: Write script file\nscript_path = f\"{script_dir}/reddit_client.py\"\nwith open(script_path, 'w') as f:\n    f.write(script_content)\n\n# Step 3: Set permissions\nos.chmod(script_path, 0o700)\n```\n\n---\n\n## Phase 2: Dependency Installation\n\n### Python Dependencies\n\n**Using pip with requirements.txt:**\n\n```bash\n# Create virtual environment\ncd /tmp/workflow-scripts/workflow-12345\npython3 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n**requirements.txt example:**\n```\npraw==7.7.1\npandas==2.1.3\nrequests==2.31.0\npython-dotenv==1.0.0\n```\n\n**Best Practices:**\n- Pin exact versions (`==`) for reproducibility\n- Use virtual environments to avoid system conflicts\n- Include all transitive dependencies\n- Test installation before execution\n\n### Node.js Dependencies\n\n**Using npm with package.json:**\n\n```bash\n# Navigate to script directory\ncd /tmp/workflow-scripts/workflow-67890\n\n# Install dependencies\nnpm install\n```\n\n**package.json example:**\n```json\n{\n  \"name\": \"github-scraper\",\n  \"version\": \"1.0.0\",\n  \"dependencies\": {\n    \"axios\": \"^1.6.2\",\n    \"cheerio\": \"^1.0.0-rc.12\",\n    \"dotenv\": \"^16.3.1\"\n  }\n}\n```\n\n**Best Practices:**\n- Use `package-lock.json` for version locking\n- Avoid global installations\n- Use `npm ci` for faster, reliable installs in production\n- Minimize dependency count\n\n### System Packages\n\n**macOS (Homebrew):**\n```bash\nbrew install jq curl imagemagick\n```\n\n**Ubuntu/Debian (apt):**\n```bash\napt-get update\napt-get install -y jq curl imagemagick\n```\n\n**Best Practices:**\n- Check if package already installed\n- Use non-interactive flags (`-y`)\n- Handle installation failures gracefully\n\n### Version Pinning Best Practices\n\n1. **Always pin major versions** - Prevents breaking changes\n2. **Test with pinned versions** - Ensures reproducibility\n3. **Document version requirements** - Include in comments\n4. **Update cautiously** - Test before updating pins\n\n---\n\n## Phase 3: Execution\n\n### Via Bash Tool\n\nScripts are executed using the Bash tool with proper environment setup:\n\n**Python execution:**\n```bash\ncd /tmp/workflow-scripts/workflow-12345\nsource venv/bin/activate\npython reddit_client.py --subreddit programming --limit 10\n```\n\n**Node.js execution:**\n```bash\ncd /tmp/workflow-scripts/workflow-67890\nnode github_scraper.js --repo \"microsoft/vscode\" --type issues\n```\n\n### Passing Arguments\n\n**Command-line arguments:**\n```bash\n# Python with argparse\npython script.py --api-key \"sk-xxx\" --output \"/tmp/results.json\"\n\n# Node.js with process.argv\nnode script.js --username \"octocat\" --format json\n```\n\n**Stdin input:**\n```bash\necho '{\"query\": \"python\", \"limit\": 100}' | python script.py\n```\n\n### Environment Variables\n\n**Setting variables:**\n```bash\n# Inline\nAPI_KEY=\"sk-xxx\" python script.py\n\n# Export for multiple commands\nexport REDDIT_CLIENT_ID=\"abc123\"\nexport REDDIT_CLIENT_SECRET=\"xyz789\"\npython reddit_client.py\n```\n\n**Loading from .env file:**\n```bash\n# Create .env file\ncat > /tmp/workflow-scripts/workflow-12345/.env <<EOF\nREDDIT_CLIENT_ID=abc123\nREDDIT_CLIENT_SECRET=xyz789\nEOF\n\n# Script loads with python-dotenv\npython reddit_client.py\n```\n\n### Timeout Handling\n\n**Bash tool timeout parameter:**\n```bash\n# 5 minute timeout (300000ms)\ntimeout 300000ms python long_running_script.py\n```\n\n**Script-level timeouts:**\n```python\nimport signal\n\ndef timeout_handler(signum, frame):\n    raise TimeoutError(\"Script exceeded time limit\")\n\nsignal.signal(signal.SIGALRM, timeout_handler)\nsignal.alarm(300)  # 5 minutes\n\ntry:\n    # Your code here\n    process_data()\nfinally:\n    signal.alarm(0)  # Cancel alarm\n```\n\n### Capturing stdout/stderr\n\n**Redirecting output:**\n```bash\n# Capture stdout only\npython script.py > /tmp/output.txt\n\n# Capture stderr only\npython script.py 2> /tmp/errors.txt\n\n# Capture both separately\npython script.py > /tmp/output.txt 2> /tmp/errors.txt\n\n# Capture both together\npython script.py > /tmp/combined.txt 2>&1\n\n# Capture and display\npython script.py 2>&1 | tee /tmp/output.txt\n```\n\n---\n\n## Phase 4: Output Processing\n\n### JSON Parsing\n\n**Python script output:**\n```python\n# reddit_client.py\nimport json\n\nresults = {\n    \"subreddit\": \"programming\",\n    \"posts\": [\n        {\"title\": \"Post 1\", \"score\": 100},\n        {\"title\": \"Post 2\", \"score\": 50}\n    ],\n    \"total\": 2\n}\n\nprint(json.dumps(results, indent=2))\n```\n\n**Processing in workflow:**\n```bash\n# Execute and parse\noutput=$(python reddit_client.py)\necho \"$output\" | jq '.posts[] | select(.score > 75)'\n```\n\n### CSV Parsing\n\n**Python script output:**\n```python\n# data_processor.py\nimport csv\nimport sys\n\ndata = [\n    [\"name\", \"age\", \"city\"],\n    [\"Alice\", \"30\", \"NYC\"],\n    [\"Bob\", \"25\", \"LA\"]\n]\n\nwriter = csv.writer(sys.stdout)\nwriter.writerows(data)\n```\n\n**Processing in workflow:**\n```bash\n# Execute and process\npython data_processor.py > /tmp/data.csv\n\n# Parse with Python\npython -c \"\nimport csv\nwith open('/tmp/data.csv') as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        print(f'{row[\\\"name\\\"]}: {row[\\\"age\\\"]}')\n\"\n```\n\n### Plain Text Processing\n\n**Script output:**\n```bash\n# Simple line-based output\npython script.py\n# Output:\n# Processing file 1...\n# Processing file 2...\n# Complete: 2 files processed\n```\n\n**Processing:**\n```bash\n# Extract specific lines\npython script.py | grep \"Complete\"\n\n# Count lines\npython script.py | wc -l\n\n# Filter and transform\npython script.py | grep \"Processing\" | sed 's/Processing //'\n```\n\n### Error Detection in Output\n\n**Structured error output:**\n```python\n# error_aware_script.py\nimport json\nimport sys\n\ntry:\n    result = perform_operation()\n    print(json.dumps({\"status\": \"success\", \"data\": result}))\nexcept Exception as e:\n    print(json.dumps({\"status\": \"error\", \"message\": str(e)}), file=sys.stderr)\n    sys.exit(1)\n```\n\n**Checking for errors:**\n```bash\n# Execute and check exit code\nif python error_aware_script.py > /tmp/output.json 2> /tmp/errors.txt; then\n    echo \"Success\"\n    cat /tmp/output.json\nelse\n    echo \"Failed\"\n    cat /tmp/errors.txt\n    exit 1\nfi\n```\n\n### Large Output Handling\n\n**Streaming output:**\n```python\n# stream_processor.py\nimport json\n\n# Process in chunks, output line by line\nfor chunk in process_large_dataset():\n    print(json.dumps(chunk))\n    sys.stdout.flush()  # Important for real-time output\n```\n\n**Processing large output:**\n```bash\n# Process line by line without loading all into memory\npython stream_processor.py | while read -r line; do\n    echo \"$line\" | jq -c '.id, .value'\ndone\n\n# Use files for very large output\npython stream_processor.py > /tmp/large_output.jsonl\ngrep \"important\" /tmp/large_output.jsonl > /tmp/filtered.jsonl\n```\n\n---\n\n## Phase 5: Cleanup\n\n### Automatic Cleanup After Workflow\n\n**At workflow end:**\n```bash\n# Remove entire workflow directory\nrm -rf /tmp/workflow-scripts/workflow-12345\n\n# Remove specific files\nrm -f /tmp/workflow-scripts/workflow-12345/*.json\nrm -f /tmp/output-*.csv\n```\n\n### Manual Cleanup for Long Workflows\n\n**Progressive cleanup:**\n```bash\n# Clean after each major step\npython step1.py > /tmp/step1_output.json\nprocess_results /tmp/step1_output.json\nrm /tmp/step1_output.json  # Clean immediately\n\npython step2.py > /tmp/step2_output.json\nprocess_results /tmp/step2_output.json\nrm /tmp/step2_output.json\n```\n\n### Cleanup on Error\n\n**Trap-based cleanup:**\n```bash\n#!/bin/bash\n\n# Set up cleanup trap\ncleanup() {\n    echo \"Cleaning up...\"\n    rm -rf /tmp/workflow-scripts/workflow-12345\n    rm -f /tmp/temp-*.json\n}\n\ntrap cleanup EXIT ERR\n\n# Your workflow code\npython script.py\nprocess_output\n# Cleanup runs automatically on exit or error\n```\n\n### Temporary File Removal\n\n**Best practices:**\n```bash\n# Use specific patterns\nrm -f /tmp/workflow-12345-*.tmp\nrm -f /tmp/processing-*.json\n\n# Avoid wildcards that could match too much\n# DON'T: rm -f /tmp/*\n# DO: rm -f /tmp/workflow-12345/*\n\n# Verify before removing\nif [ -d \"/tmp/workflow-scripts/workflow-12345\" ]; then\n    rm -rf /tmp/workflow-scripts/workflow-12345\nfi\n```\n\n---\n\n## Complete Examples\n\n### Example 1: Reddit API Client (Python)\n\n**Phase 1: Creation**\n```bash\n# Create directory\nmkdir -p /tmp/workflow-scripts/workflow-reddit-001\ncd /tmp/workflow-scripts/workflow-reddit-001\n\n# Create script\ncat > reddit_client.py <<'EOF'\nimport praw\nimport json\nimport sys\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef fetch_reddit_posts(subreddit, limit=10):\n    reddit = praw.Reddit(\n        client_id=os.getenv('REDDIT_CLIENT_ID'),\n        client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n        user_agent='workflow-script/1.0'\n    )\n\n    posts = []\n    for submission in reddit.subreddit(subreddit).hot(limit=limit):\n        posts.append({\n            'title': submission.title,\n            'score': submission.score,\n            'url': submission.url,\n            'created_utc': submission.created_utc,\n            'num_comments': submission.num_comments\n        })\n\n    return posts\n\nif __name__ == '__main__':\n    subreddit = sys.argv[1] if len(sys.argv) > 1 else 'programming'\n    limit = int(sys.argv[2]) if len(sys.argv) > 2 else 10\n\n    try:\n        results = fetch_reddit_posts(subreddit, limit)\n        output = {\n            'status': 'success',\n            'subreddit': subreddit,\n            'count': len(results),\n            'posts': results\n        }\n        print(json.dumps(output, indent=2))\n    except Exception as e:\n        error = {\n            'status': 'error',\n            'message': str(e)\n        }\n        print(json.dumps(error, indent=2), file=sys.stderr)\n        sys.exit(1)\nEOF\n\n# Set permissions\nchmod 700 reddit_client.py\n```\n\n**Phase 2: Dependencies**\n```bash\n# Create requirements.txt\ncat > requirements.txt <<EOF\npraw==7.7.1\npython-dotenv==1.0.0\nEOF\n\n# Create virtual environment\npython3 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n**Phase 3: Execution**\n```bash\n# Create .env file\ncat > .env <<EOF\nREDDIT_CLIENT_ID=your_client_id_here\nREDDIT_CLIENT_SECRET=your_client_secret_here\nEOF\n\n# Execute script\nsource venv/bin/activate\npython reddit_client.py programming 20 > /tmp/reddit_output.json 2> /tmp/reddit_errors.txt\n```\n\n**Phase 4: Output Processing**\n```bash\n# Check for errors\nif [ -s /tmp/reddit_errors.txt ]; then\n    echo \"Error occurred:\"\n    cat /tmp/reddit_errors.txt\n    exit 1\nfi\n\n# Parse and filter results\ncat /tmp/reddit_output.json | jq '.posts[] | select(.score > 100) | {title, score, url}'\n\n# Extract top post\ncat /tmp/reddit_output.json | jq '.posts[0]'\n\n# Count posts\ncat /tmp/reddit_output.json | jq '.count'\n```\n\n**Phase 5: Cleanup**\n```bash\n# Clean up output files\nrm -f /tmp/reddit_output.json /tmp/reddit_errors.txt\n\n# Clean up script directory (when workflow complete)\ndeactivate\nrm -rf /tmp/workflow-scripts/workflow-reddit-001\n```\n\n---\n\n### Example 2: GitHub API Client (Node.js)\n\n**Phase 1: Creation**\n```bash\n# Create directory\nmkdir -p /tmp/workflow-scripts/workflow-github-002\ncd /tmp/workflow-scripts/workflow-github-002\n\n# Create script\ncat > github_scraper.js <<'EOF'\nconst axios = require('axios');\nrequire('dotenv').config();\n\nasync function fetchGitHubIssues(owner, repo, state = 'open', limit = 30) {\n    try {\n        const response = await axios.get(\n            `https://api.github.com/repos/${owner}/${repo}/issues`,\n            {\n                headers: {\n                    'Authorization': `token ${process.env.GITHUB_TOKEN}`,\n                    'Accept': 'application/vnd.github.v3+json'\n                },\n                params: {\n                    state: state,\n                    per_page: limit,\n                    sort: 'created',\n                    direction: 'desc'\n                }\n            }\n        );\n\n        const issues = response.data.map(issue => ({\n            number: issue.number,\n            title: issue.title,\n            state: issue.state,\n            created_at: issue.created_at,\n            comments: issue.comments,\n            labels: issue.labels.map(l => l.name),\n            url: issue.html_url\n        }));\n\n        console.log(JSON.stringify({\n            status: 'success',\n            repo: `${owner}/${repo}`,\n            count: issues.length,\n            issues: issues\n        }, null, 2));\n\n    } catch (error) {\n        console.error(JSON.stringify({\n            status: 'error',\n            message: error.message,\n            code: error.code\n        }, null, 2));\n        process.exit(1);\n    }\n}\n\n// Parse command line arguments\nconst args = process.argv.slice(2);\nconst owner = args[0] || 'microsoft';\nconst repo = args[1] || 'vscode';\nconst state = args[2] || 'open';\nconst limit = parseInt(args[3]) || 30;\n\nfetchGitHubIssues(owner, repo, state, limit);\nEOF\n\n# Set permissions\nchmod 700 github_scraper.js\n```\n\n**Phase 2: Dependencies**\n```bash\n# Create package.json\ncat > package.json <<'EOF'\n{\n  \"name\": \"github-scraper\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Fetch GitHub issues\",\n  \"dependencies\": {\n    \"axios\": \"^1.6.2\",\n    \"dotenv\": \"^16.3.1\"\n  }\n}\nEOF\n\n# Install dependencies\nnpm install\n```\n\n**Phase 3: Execution**\n```bash\n# Create .env file\ncat > .env <<EOF\nGITHUB_TOKEN=ghp_your_token_here\nEOF\n\n# Execute script\nnode github_scraper.js microsoft vscode open 50 > /tmp/github_output.json 2> /tmp/github_errors.txt\n```\n\n**Phase 4: Output Processing**\n```bash\n# Check for errors\nif [ $? -ne 0 ]; then\n    echo \"Script failed:\"\n    cat /tmp/github_errors.txt\n    exit 1\nfi\n\n# Parse results\ncat /tmp/github_output.json | jq '.issues[] | select(.comments > 10) | {number, title, comments}'\n\n# Get issue numbers\ncat /tmp/github_output.json | jq '.issues[].number'\n\n# Filter by label\ncat /tmp/github_output.json | jq '.issues[] | select(.labels[] | contains(\"bug\"))'\n```\n\n**Phase 5: Cleanup**\n```bash\n# Remove output files\nrm -f /tmp/github_output.json /tmp/github_errors.txt\n\n# Remove script directory\nrm -rf /tmp/workflow-scripts/workflow-github-002\n```\n\n---\n\n### Example 3: Data Processing with Pandas\n\n**Phase 1: Creation**\n```bash\nmkdir -p /tmp/workflow-scripts/workflow-pandas-003\ncd /tmp/workflow-scripts/workflow-pandas-003\n\ncat > data_processor.py <<'EOF'\nimport pandas as pd\nimport json\nimport sys\n\ndef process_csv_data(input_file):\n    # Read CSV\n    df = pd.read_csv(input_file)\n\n    # Basic statistics\n    stats = {\n        'total_rows': len(df),\n        'columns': list(df.columns),\n        'numeric_summary': df.describe().to_dict(),\n        'missing_values': df.isnull().sum().to_dict()\n    }\n\n    # Group by analysis (example)\n    if 'category' in df.columns:\n        grouped = df.groupby('category').agg({\n            'value': ['sum', 'mean', 'count']\n        }).to_dict()\n        stats['grouped_analysis'] = grouped\n\n    # Top 10 rows by value (if column exists)\n    if 'value' in df.columns:\n        top_10 = df.nlargest(10, 'value')[['name', 'value']].to_dict('records')\n        stats['top_10'] = top_10\n\n    return stats\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print(json.dumps({\n            'status': 'error',\n            'message': 'Usage: python data_processor.py <input_file.csv>'\n        }), file=sys.stderr)\n        sys.exit(1)\n\n    input_file = sys.argv[1]\n\n    try:\n        results = process_csv_data(input_file)\n        output = {\n            'status': 'success',\n            'file': input_file,\n            'results': results\n        }\n        print(json.dumps(output, indent=2))\n    except Exception as e:\n        print(json.dumps({\n            'status': 'error',\n            'message': str(e)\n        }), file=sys.stderr)\n        sys.exit(1)\nEOF\n\nchmod 700 data_processor.py\n```\n\n**Phase 2: Dependencies**\n```bash\ncat > requirements.txt <<EOF\npandas==2.1.3\nnumpy==1.26.2\nEOF\n\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n**Phase 3: Execution**\n```bash\n# Create sample CSV for testing\ncat > /tmp/sample_data.csv <<EOF\nname,category,value\nProduct A,Electronics,1500\nProduct B,Electronics,2000\nProduct C,Furniture,800\nProduct D,Furniture,1200\nProduct E,Electronics,1800\nEOF\n\n# Execute\nsource venv/bin/activate\npython data_processor.py /tmp/sample_data.csv > /tmp/analysis.json\n```\n\n**Phase 4: Output Processing**\n```bash\n# Extract specific metrics\ncat /tmp/analysis.json | jq '.results.total_rows'\ncat /tmp/analysis.json | jq '.results.top_10'\ncat /tmp/analysis.json | jq '.results.numeric_summary.value.mean'\n\n# Process for further use\ncat /tmp/analysis.json | jq -r '.results.top_10[] | \"\\(.name): \\(.value)\"'\n```\n\n**Phase 5: Cleanup**\n```bash\nrm -f /tmp/sample_data.csv /tmp/analysis.json\ndeactivate\nrm -rf /tmp/workflow-scripts/workflow-pandas-003\n```\n\n---\n\n### Example 4: Web Scraping with Cheerio (Node.js)\n\n**Phase 1: Creation**\n```bash\nmkdir -p /tmp/workflow-scripts/workflow-scraper-004\ncd /tmp/workflow-scripts/workflow-scraper-004\n\ncat > web_scraper.js <<'EOF'\nconst axios = require('axios');\nconst cheerio = require('cheerio');\n\nasync function scrapePage(url, selector) {\n    try {\n        const response = await axios.get(url, {\n            headers: {\n                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'\n            }\n        });\n\n        const $ = cheerio.load(response.data);\n        const results = [];\n\n        $(selector).each((i, element) => {\n            results.push({\n                text: $(element).text().trim(),\n                html: $(element).html(),\n                href: $(element).attr('href')\n            });\n        });\n\n        console.log(JSON.stringify({\n            status: 'success',\n            url: url,\n            selector: selector,\n            count: results.length,\n            items: results\n        }, null, 2));\n\n    } catch (error) {\n        console.error(JSON.stringify({\n            status: 'error',\n            message: error.message\n        }));\n        process.exit(1);\n    }\n}\n\nconst url = process.argv[2];\nconst selector = process.argv[3] || 'a';\n\nif (!url) {\n    console.error('Usage: node web_scraper.js <url> [selector]');\n    process.exit(1);\n}\n\nscrapePage(url, selector);\nEOF\n\nchmod 700 web_scraper.js\n```\n\n**Phase 2: Dependencies**\n```bash\ncat > package.json <<'EOF'\n{\n  \"name\": \"web-scraper\",\n  \"version\": \"1.0.0\",\n  \"dependencies\": {\n    \"axios\": \"^1.6.2\",\n    \"cheerio\": \"^1.0.0-rc.12\"\n  }\n}\nEOF\n\nnpm install\n```\n\n**Phase 3: Execution**\n```bash\nnode web_scraper.js \"https://news.ycombinator.com\" \".titleline > a\" > /tmp/scrape_results.json\n```\n\n**Phase 4: Output Processing**\n```bash\n# Extract titles\ncat /tmp/scrape_results.json | jq -r '.items[].text'\n\n# Get URLs\ncat /tmp/scrape_results.json | jq -r '.items[] | select(.href != null) | .href'\n\n# Count items\ncat /tmp/scrape_results.json | jq '.count'\n```\n\n**Phase 5: Cleanup**\n```bash\nrm -f /tmp/scrape_results.json\nrm -rf /tmp/workflow-scripts/workflow-scraper-004\n```\n\n---\n\n### Example 5: Database Access with psycopg2 (Python)\n\n**Phase 1: Creation**\n```bash\nmkdir -p /tmp/workflow-scripts/workflow-db-005\ncd /tmp/workflow-scripts/workflow-db-005\n\ncat > db_query.py <<'EOF'\nimport psycopg2\nimport json\nimport sys\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef execute_query(query, params=None):\n    conn = None\n    try:\n        conn = psycopg2.connect(\n            host=os.getenv('DB_HOST'),\n            database=os.getenv('DB_NAME'),\n            user=os.getenv('DB_USER'),\n            password=os.getenv('DB_PASSWORD'),\n            port=os.getenv('DB_PORT', 5432)\n        )\n\n        cur = conn.cursor()\n        cur.execute(query, params)\n\n        # Fetch results if SELECT query\n        if cur.description:\n            columns = [desc[0] for desc in cur.description]\n            rows = cur.fetchall()\n            results = [dict(zip(columns, row)) for row in rows]\n        else:\n            # For INSERT/UPDATE/DELETE\n            conn.commit()\n            results = {'rows_affected': cur.rowcount}\n\n        cur.close()\n\n        return {\n            'status': 'success',\n            'query': query,\n            'results': results\n        }\n\n    except Exception as e:\n        return {\n            'status': 'error',\n            'message': str(e)\n        }\n    finally:\n        if conn:\n            conn.close()\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print(json.dumps({\n            'status': 'error',\n            'message': 'Usage: python db_query.py \"<query>\"'\n        }), file=sys.stderr)\n        sys.exit(1)\n\n    query = sys.argv[1]\n    result = execute_query(query)\n\n    print(json.dumps(result, indent=2, default=str))\n\n    if result['status'] == 'error':\n        sys.exit(1)\nEOF\n\nchmod 700 db_query.py\n```\n\n**Phase 2: Dependencies**\n```bash\ncat > requirements.txt <<EOF\npsycopg2-binary==2.9.9\npython-dotenv==1.0.0\nEOF\n\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n**Phase 3: Execution**\n```bash\n# Create .env\ncat > .env <<EOF\nDB_HOST=localhost\nDB_NAME=mydb\nDB_USER=myuser\nDB_PASSWORD=mypassword\nDB_PORT=5432\nEOF\n\n# Execute query\nsource venv/bin/activate\npython db_query.py \"SELECT * FROM users WHERE active = true LIMIT 10\" > /tmp/db_results.json\n```\n\n**Phase 4: Output Processing**\n```bash\n# Parse results\ncat /tmp/db_results.json | jq '.results[] | {id, username, email}'\n\n# Count rows\ncat /tmp/db_results.json | jq '.results | length'\n\n# Filter results\ncat /tmp/db_results.json | jq '.results[] | select(.role == \"admin\")'\n```\n\n**Phase 5: Cleanup**\n```bash\nrm -f /tmp/db_results.json\ndeactivate\nrm -rf /tmp/workflow-scripts/workflow-db-005\n```\n\n---\n\n### Example 6: API Rate-Limited Scraper (Python)\n\n**Phase 1: Creation**\n```bash\nmkdir -p /tmp/workflow-scripts/workflow-ratelimit-006\ncd /tmp/workflow-scripts/workflow-ratelimit-006\n\ncat > rate_limited_scraper.py <<'EOF'\nimport requests\nimport json\nimport time\nimport sys\nfrom datetime import datetime\n\nclass RateLimitedScraper:\n    def __init__(self, base_url, requests_per_second=1):\n        self.base_url = base_url\n        self.delay = 1.0 / requests_per_second\n        self.last_request_time = 0\n\n    def wait_if_needed(self):\n        elapsed = time.time() - self.last_request_time\n        if elapsed < self.delay:\n            time.sleep(self.delay - elapsed)\n\n    def fetch(self, endpoint, params=None):\n        self.wait_if_needed()\n\n        url = f\"{self.base_url}/{endpoint}\"\n        response = requests.get(url, params=params)\n\n        self.last_request_time = time.time()\n        response.raise_for_status()\n\n        return response.json()\n\n    def fetch_multiple(self, endpoints):\n        results = []\n\n        for i, endpoint in enumerate(endpoints):\n            try:\n                data = self.fetch(endpoint)\n                results.append({\n                    'endpoint': endpoint,\n                    'status': 'success',\n                    'data': data,\n                    'timestamp': datetime.now().isoformat()\n                })\n                print(f\"Progress: {i+1}/{len(endpoints)}\", file=sys.stderr)\n            except Exception as e:\n                results.append({\n                    'endpoint': endpoint,\n                    'status': 'error',\n                    'error': str(e)\n                })\n\n        return results\n\nif __name__ == '__main__':\n    if len(sys.argv) < 3:\n        print(\"Usage: python rate_limited_scraper.py <base_url> <endpoint1> [endpoint2] ...\",\n              file=sys.stderr)\n        sys.exit(1)\n\n    base_url = sys.argv[1]\n    endpoints = sys.argv[2:]\n\n    scraper = RateLimitedScraper(base_url, requests_per_second=2)\n    results = scraper.fetch_multiple(endpoints)\n\n    output = {\n        'status': 'success',\n        'base_url': base_url,\n        'total_endpoints': len(endpoints),\n        'successful': sum(1 for r in results if r['status'] == 'success'),\n        'failed': sum(1 for r in results if r['status'] == 'error'),\n        'results': results\n    }\n\n    print(json.dumps(output, indent=2))\nEOF\n\nchmod 700 rate_limited_scraper.py\n```\n\n**Phase 2: Dependencies**\n```bash\ncat > requirements.txt <<EOF\nrequests==2.31.0\nEOF\n\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n**Phase 3: Execution**\n```bash\nsource venv/bin/activate\npython rate_limited_scraper.py \\\n    \"https://api.github.com\" \\\n    \"users/octocat\" \\\n    \"users/torvalds\" \\\n    \"users/gvanrossum\" \\\n    > /tmp/scraper_output.json 2> /tmp/scraper_progress.txt\n```\n\n**Phase 4: Output Processing**\n```bash\n# Check progress\ntail -f /tmp/scraper_progress.txt\n\n# After completion, analyze results\ncat /tmp/scraper_output.json | jq '{total: .total_endpoints, successful: .successful, failed: .failed}'\n\n# Extract successful results\ncat /tmp/scraper_output.json | jq '.results[] | select(.status == \"success\") | .data.login'\n\n# Find errors\ncat /tmp/scraper_output.json | jq '.results[] | select(.status == \"error\")'\n```\n\n**Phase 5: Cleanup**\n```bash\nrm -f /tmp/scraper_output.json /tmp/scraper_progress.txt\ndeactivate\nrm -rf /tmp/workflow-scripts/workflow-ratelimit-006\n```\n\n---\n\n### Example 7: Multi-Format Data Converter (Python)\n\n**Phase 1: Creation**\n```bash\nmkdir -p /tmp/workflow-scripts/workflow-converter-007\ncd /tmp/workflow-scripts/workflow-converter-007\n\ncat > data_converter.py <<'EOF'\nimport pandas as pd\nimport json\nimport yaml\nimport xml.etree.ElementTree as ET\nimport sys\nfrom pathlib import Path\n\ndef csv_to_json(input_file, output_file):\n    df = pd.read_csv(input_file)\n    df.to_json(output_file, orient='records', indent=2)\n    return len(df)\n\ndef json_to_csv(input_file, output_file):\n    df = pd.read_json(input_file)\n    df.to_csv(output_file, index=False)\n    return len(df)\n\ndef json_to_yaml(input_file, output_file):\n    with open(input_file) as f:\n        data = json.load(f)\n    with open(output_file, 'w') as f:\n        yaml.dump(data, f, default_flow_style=False)\n    return len(data) if isinstance(data, list) else 1\n\ndef yaml_to_json(input_file, output_file):\n    with open(input_file) as f:\n        data = yaml.safe_load(f)\n    with open(output_file, 'w') as f:\n        json.dump(data, f, indent=2)\n    return len(data) if isinstance(data, list) else 1\n\ndef convert(input_file, output_file, conversion_type):\n    conversions = {\n        'csv_to_json': csv_to_json,\n        'json_to_csv': json_to_csv,\n        'json_to_yaml': json_to_yaml,\n        'yaml_to_json': yaml_to_json\n    }\n\n    if conversion_type not in conversions:\n        raise ValueError(f\"Unknown conversion type: {conversion_type}\")\n\n    rows = conversions[conversion_type](input_file, output_file)\n\n    return {\n        'status': 'success',\n        'conversion': conversion_type,\n        'input': input_file,\n        'output': output_file,\n        'rows_processed': rows,\n        'output_size': Path(output_file).stat().st_size\n    }\n\nif __name__ == '__main__':\n    if len(sys.argv) != 4:\n        print(\"Usage: python data_converter.py <input> <output> <conversion_type>\",\n              file=sys.stderr)\n        print(\"Types: csv_to_json, json_to_csv, json_to_yaml, yaml_to_json\",\n              file=sys.stderr)\n        sys.exit(1)\n\n    input_file = sys.argv[1]\n    output_file = sys.argv[2]\n    conversion_type = sys.argv[3]\n\n    try:\n        result = convert(input_file, output_file, conversion_type)\n        print(json.dumps(result, indent=2))\n    except Exception as e:\n        error = {\n            'status': 'error',\n            'message': str(e)\n        }\n        print(json.dumps(error, indent=2), file=sys.stderr)\n        sys.exit(1)\nEOF\n\nchmod 700 data_converter.py\n```\n\n**Phase 2: Dependencies**\n```bash\ncat > requirements.txt <<EOF\npandas==2.1.3\nPyYAML==6.0.1\nEOF\n\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n**Phase 3: Execution**\n```bash\n# Create sample CSV\ncat > /tmp/sample.csv <<EOF\nid,name,department,salary\n1,Alice,Engineering,90000\n2,Bob,Marketing,75000\n3,Carol,Engineering,95000\nEOF\n\n# Convert CSV to JSON\nsource venv/bin/activate\npython data_converter.py /tmp/sample.csv /tmp/output.json csv_to_json > /tmp/conversion_result.json\n\n# Convert JSON to YAML\npython data_converter.py /tmp/output.json /tmp/output.yaml json_to_yaml\n```\n\n**Phase 4: Output Processing**\n```bash\n# Check conversion result\ncat /tmp/conversion_result.json | jq '{status, rows: .rows_processed, size: .output_size}'\n\n# Verify output\ncat /tmp/output.json | jq '.'\ncat /tmp/output.yaml\n\n# Further processing\ncat /tmp/output.json | jq '.[] | select(.salary > 80000)'\n```\n\n**Phase 5: Cleanup**\n```bash\nrm -f /tmp/sample.csv /tmp/output.json /tmp/output.yaml /tmp/conversion_result.json\ndeactivate\nrm -rf /tmp/workflow-scripts/workflow-converter-007\n```\n\n---\n\n## Troubleshooting\n\n### Script Not Found Errors\n\n**Error:**\n```\nbash: /tmp/workflow-scripts/workflow-12345/script.py: No such file or directory\n```\n\n**Solutions:**\n\n1. **Verify directory exists:**\n```bash\nls -la /tmp/workflow-scripts/workflow-12345/\n```\n\n2. **Check script was created:**\n```bash\ncat /tmp/workflow-scripts/workflow-12345/script.py\n```\n\n3. **Verify correct path:**\n```bash\n# Use absolute path\n/tmp/workflow-scripts/workflow-12345/script.py\n\n# Or cd first\ncd /tmp/workflow-scripts/workflow-12345 && python script.py\n```\n\n4. **Check for typos:**\n```bash\n# List all files in directory\nfind /tmp/workflow-scripts/workflow-12345 -type f\n```\n\n---\n\n### Permission Denied\n\n**Error:**\n```\nbash: /tmp/workflow-scripts/workflow-12345/script.py: Permission denied\n```\n\n**Solutions:**\n\n1. **Make script executable:**\n```bash\nchmod +x /tmp/workflow-scripts/workflow-12345/script.py\n# or\nchmod 700 /tmp/workflow-scripts/workflow-12345/script.py\n```\n\n2. **Check current permissions:**\n```bash\nls -l /tmp/workflow-scripts/workflow-12345/script.py\n```\n\n3. **Run with interpreter explicitly:**\n```bash\n# Instead of: ./script.py\n# Use: python script.py or node script.js\npython /tmp/workflow-scripts/workflow-12345/script.py\n```\n\n4. **Check file ownership:**\n```bash\nls -l /tmp/workflow-scripts/workflow-12345/script.py\n# If needed, change ownership\nchown $USER /tmp/workflow-scripts/workflow-12345/script.py\n```\n\n---\n\n### Dependency Installation Failures\n\n**Error:**\n```\nERROR: Could not find a version that satisfies the requirement praw==7.7.1\n```\n\n**Solutions:**\n\n1. **Check internet connectivity:**\n```bash\nping pypi.org\ncurl -I https://pypi.org\n```\n\n2. **Update package manager:**\n```bash\n# Python\npip install --upgrade pip\n\n# Node.js\nnpm install -g npm@latest\n```\n\n3. **Use alternative package index:**\n```bash\n# Python with mirror\npip install -i https://pypi.org/simple -r requirements.txt\n\n# Node.js with different registry\nnpm install --registry=https://registry.npmjs.org/\n```\n\n4. **Install dependencies individually:**\n```bash\n# If requirements.txt fails, install one by one\npip install praw==7.7.1\npip install pandas==2.1.3\n```\n\n5. **Check Python/Node version:**\n```bash\npython --version  # Should be 3.8+\nnode --version    # Should be 16+\n\n# Use specific version if needed\npython3.11 -m pip install -r requirements.txt\n```\n\n6. **Clear cache:**\n```bash\n# Python\npip cache purge\n\n# Node.js\nnpm cache clean --force\n```\n\n---\n\n### Timeout Errors\n\n**Error:**\n```\nScript execution exceeded timeout of 120000ms\n```\n\n**Solutions:**\n\n1. **Increase timeout in Bash tool:**\n```bash\n# Use timeout parameter (in milliseconds)\npython long_script.py  # with timeout: 600000 (10 minutes)\n```\n\n2. **Add progress indicators:**\n```python\n# In your script\nimport sys\n\nfor i, item in enumerate(large_dataset):\n    process(item)\n    if i % 100 == 0:\n        print(f\"Processed {i} items...\", file=sys.stderr)\n        sys.stderr.flush()\n```\n\n3. **Optimize script:**\n```python\n# Use batch processing\ndef process_in_batches(items, batch_size=100):\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        process_batch(batch)\n\n# Use streaming instead of loading all data\nfor line in file:\n    process(line)  # Instead of: lines = file.readlines()\n```\n\n4. **Split into multiple scripts:**\n```bash\n# Instead of one long script\npython process_step1.py > /tmp/step1.json\npython process_step2.py /tmp/step1.json > /tmp/step2.json\n```\n\n---\n\n### Output Parsing Errors\n\n**Error:**\n```\njq: parse error: Invalid JSON\n```\n\n**Solutions:**\n\n1. **Validate JSON output:**\n```bash\n# Check if output is valid JSON\npython script.py > /tmp/output.txt\ncat /tmp/output.txt | jq '.' || echo \"Invalid JSON\"\n```\n\n2. **Fix script output:**\n```python\n# Ensure script only outputs JSON to stdout\nimport json\nimport sys\n\n# Debugging output goes to stderr\nprint(\"Debug info\", file=sys.stderr)\n\n# JSON output goes to stdout\nresult = {\"status\": \"success\"}\nprint(json.dumps(result))  # Only this to stdout\n```\n\n3. **Handle mixed output:**\n```bash\n# If script outputs text + JSON, extract JSON only\npython script.py > /tmp/full_output.txt\ngrep -A 9999 '{' /tmp/full_output.txt | jq '.'\n\n# Or use tail to get last line if JSON is at end\npython script.py | tail -n 1 | jq '.'\n```\n\n4. **Check for stderr contamination:**\n```bash\n# Separate stdout and stderr\npython script.py > /tmp/stdout.txt 2> /tmp/stderr.txt\ncat /tmp/stdout.txt | jq '.'\n```\n\n5. **Validate before parsing:**\n```bash\n# Check if file is empty\nif [ ! -s /tmp/output.json ]; then\n    echo \"Output file is empty\"\n    exit 1\nfi\n\n# Check if it's valid JSON\nif ! jq empty /tmp/output.json 2>/dev/null; then\n    echo \"Invalid JSON in output\"\n    cat /tmp/output.json\n    exit 1\nfi\n```\n\n---\n\n### Virtual Environment Issues\n\n**Error:**\n```\ncommand not found: python\nModuleNotFoundError: No module named 'praw'\n```\n\n**Solutions:**\n\n1. **Always activate venv:**\n```bash\ncd /tmp/workflow-scripts/workflow-12345\nsource venv/bin/activate\npython script.py\n```\n\n2. **Use absolute path to venv python:**\n```bash\n/tmp/workflow-scripts/workflow-12345/venv/bin/python script.py\n```\n\n3. **Verify venv exists:**\n```bash\nls -la /tmp/workflow-scripts/workflow-12345/venv/\n```\n\n4. **Recreate venv if corrupted:**\n```bash\nrm -rf /tmp/workflow-scripts/workflow-12345/venv\npython3 -m venv /tmp/workflow-scripts/workflow-12345/venv\nsource /tmp/workflow-scripts/workflow-12345/venv/bin/activate\npip install -r requirements.txt\n```\n\n---\n\n### Environment Variable Issues\n\n**Error:**\n```\nKeyError: 'REDDIT_CLIENT_ID'\nNone is not a valid value\n```\n\n**Solutions:**\n\n1. **Verify .env file exists:**\n```bash\ncat /tmp/workflow-scripts/workflow-12345/.env\n```\n\n2. **Check variable loading:**\n```python\n# Add debug output\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\nprint(f\"CLIENT_ID loaded: {os.getenv('REDDIT_CLIENT_ID') is not None}\", file=sys.stderr)\n```\n\n3. **Use explicit .env path:**\n```python\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nenv_path = Path('/tmp/workflow-scripts/workflow-12345/.env')\nload_dotenv(dotenv_path=env_path)\n```\n\n4. **Pass variables directly:**\n```bash\n# Instead of .env file\nREDDIT_CLIENT_ID=\"abc123\" REDDIT_CLIENT_SECRET=\"xyz789\" python script.py\n```\n\n---\n\n### Cleanup Failures\n\n**Error:**\n```\nrm: /tmp/workflow-scripts/workflow-12345: Directory not empty\n```\n\n**Solutions:**\n\n1. **Force recursive removal:**\n```bash\nrm -rf /tmp/workflow-scripts/workflow-12345\n```\n\n2. **Check for processes using files:**\n```bash\n# macOS\nlsof +D /tmp/workflow-scripts/workflow-12345\n\n# Linux\nfuser -v /tmp/workflow-scripts/workflow-12345\n```\n\n3. **Deactivate venv first:**\n```bash\ndeactivate\nrm -rf /tmp/workflow-scripts/workflow-12345\n```\n\n4. **Remove files individually:**\n```bash\nrm -f /tmp/workflow-scripts/workflow-12345/*\nrm -rf /tmp/workflow-scripts/workflow-12345/venv\nrmdir /tmp/workflow-scripts/workflow-12345\n```\n\n---\n\n## Best Practices Summary\n\n1. **Always use virtual environments** for Python scripts\n2. **Pin exact dependency versions** for reproducibility\n3. **Separate stdout and stderr** for clean output parsing\n4. **Use structured output** (JSON) for programmatic processing\n5. **Handle errors gracefully** with proper exit codes\n6. **Clean up temporary files** after workflow completion\n7. **Set appropriate timeouts** based on expected runtime\n8. **Use progress indicators** for long-running scripts\n9. **Validate output** before parsing\n10. **Test scripts independently** before integrating into workflows\n\n---\n\n## Quick Reference\n\n**Create script directory:**\n```bash\nmkdir -p /tmp/workflow-scripts/workflow-{id}\n```\n\n**Python virtual environment:**\n```bash\npython3 -m venv venv && source venv/bin/activate && pip install -r requirements.txt\n```\n\n**Execute with output capture:**\n```bash\npython script.py > /tmp/output.json 2> /tmp/errors.txt\n```\n\n**Parse JSON output:**\n```bash\ncat /tmp/output.json | jq '.results[] | {key1, key2}'\n```\n\n**Cleanup:**\n```bash\ndeactivate && rm -rf /tmp/workflow-scripts/workflow-{id}\n```\n",
        "skills/managing-temp-scripts/script-templates.md": "# Script Templates Library\n\nReady-to-use script templates for temporary agents in workflows.\n\n---\n\n## 1. API Clients\n\n### REST API Client (Generic)\n\n**Purpose**: Generic HTTP client for REST API interactions with authentication and error handling\n\n**Language**: Python\n\n**Dependencies**:\n```\nrequests==2.31.0\n```\n\n**Code**:\n```python\nimport requests\nimport json\nimport sys\n\ndef main():\n    # Read input from stdin\n    input_data = json.loads(sys.stdin.read())\n\n    url = input_data.get('url')\n    method = input_data.get('method', 'GET').upper()\n    headers = input_data.get('headers', {})\n    params = input_data.get('params', {})\n    body = input_data.get('body', None)\n    auth = input_data.get('auth', None)\n\n    try:\n        # Prepare authentication\n        auth_tuple = None\n        if auth and 'username' in auth and 'password' in auth:\n            auth_tuple = (auth['username'], auth['password'])\n\n        # Make request\n        response = requests.request(\n            method=method,\n            url=url,\n            headers=headers,\n            params=params,\n            json=body if body else None,\n            auth=auth_tuple,\n            timeout=30\n        )\n\n        response.raise_for_status()\n\n        # Output response\n        result = {\n            'status_code': response.status_code,\n            'headers': dict(response.headers),\n            'body': response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n        }\n\n        print(json.dumps(result))\n\n    except requests.exceptions.RequestException as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow api-integration\n  agent rest-api-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/rest-client.py\"\n    dependencies: [\"requests==2.31.0\"]\n  }\n\n  rest-api-client(\n    url=\"https://api.example.com/users\",\n    method=\"POST\",\n    headers={\"Content-Type\": \"application/json\"},\n    body={\"name\": \"John\", \"email\": \"john@example.com\"}\n  )\nend\n```\n\n**Input**:\n- `url` (string): API endpoint URL\n- `method` (string): HTTP method (GET, POST, PUT, DELETE, etc.)\n- `headers` (object): HTTP headers\n- `params` (object): Query parameters\n- `body` (object): Request body\n- `auth` (object): {username, password} for basic auth\n\n**Output**:\n```json\n{\n  \"status_code\": 200,\n  \"headers\": {\"content-type\": \"application/json\"},\n  \"body\": {\"id\": 123, \"name\": \"John\"}\n}\n```\n\n---\n\n### GraphQL Client\n\n**Purpose**: Execute GraphQL queries and mutations with variable support\n\n**Language**: Node.js\n\n**Dependencies**:\n```\ngraphql-request@6.1.0\n```\n\n**Code**:\n```javascript\nconst { GraphQLClient } = require('graphql-request');\n\nasync function main() {\n  let input = '';\n\n  process.stdin.on('data', chunk => input += chunk);\n\n  process.stdin.on('end', async () => {\n    try {\n      const { endpoint, query, variables = {}, headers = {} } = JSON.parse(input);\n\n      const client = new GraphQLClient(endpoint, { headers });\n      const data = await client.request(query, variables);\n\n      console.log(JSON.stringify({ success: true, data }));\n    } catch (error) {\n      console.error(JSON.stringify({\n        error: error.message,\n        details: error.response?.errors\n      }));\n      process.exit(1);\n    }\n  });\n}\n\nmain();\n```\n\n**Usage in Workflow**:\n```flow\nworkflow graphql-query\n  agent gql-client {\n    type: temp-script\n    language: node\n    script: \"./scripts/graphql-client.js\"\n    dependencies: [\"graphql-request@6.1.0\"]\n  }\n\n  gql-client(\n    endpoint=\"https://api.example.com/graphql\",\n    query=\"query GetUser($id: ID!) { user(id: $id) { name email } }\",\n    variables={\"id\": \"123\"},\n    headers={\"Authorization\": \"Bearer token\"}\n  )\nend\n```\n\n**Input**:\n- `endpoint` (string): GraphQL API endpoint\n- `query` (string): GraphQL query or mutation\n- `variables` (object): Query variables\n- `headers` (object): HTTP headers\n\n**Output**:\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"user\": {\"name\": \"John\", \"email\": \"john@example.com\"}\n  }\n}\n```\n\n---\n\n### Reddit API Client\n\n**Purpose**: Fetch posts, comments, and user data from Reddit\n\n**Language**: Python\n\n**Dependencies**:\n```\npraw==7.7.1\n```\n\n**Code**:\n```python\nimport praw\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    client_id = input_data['client_id']\n    client_secret = input_data['client_secret']\n    user_agent = input_data.get('user_agent', 'script:v1.0')\n    action = input_data['action']\n\n    try:\n        reddit = praw.Reddit(\n            client_id=client_id,\n            client_secret=client_secret,\n            user_agent=user_agent\n        )\n\n        result = {}\n\n        if action == 'get_subreddit_posts':\n            subreddit = reddit.subreddit(input_data['subreddit'])\n            limit = input_data.get('limit', 10)\n            sort = input_data.get('sort', 'hot')\n\n            posts = []\n            submission_list = getattr(subreddit, sort)(limit=limit)\n\n            for submission in submission_list:\n                posts.append({\n                    'id': submission.id,\n                    'title': submission.title,\n                    'author': str(submission.author),\n                    'score': submission.score,\n                    'url': submission.url,\n                    'created_utc': submission.created_utc,\n                    'num_comments': submission.num_comments,\n                    'selftext': submission.selftext\n                })\n\n            result = {'posts': posts}\n\n        elif action == 'get_comments':\n            submission = reddit.submission(id=input_data['submission_id'])\n            submission.comments.replace_more(limit=0)\n\n            comments = []\n            for comment in submission.comments.list():\n                comments.append({\n                    'id': comment.id,\n                    'author': str(comment.author),\n                    'body': comment.body,\n                    'score': comment.score,\n                    'created_utc': comment.created_utc\n                })\n\n            result = {'comments': comments}\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow reddit-scraper\n  agent reddit-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/reddit-client.py\"\n    dependencies: [\"praw==7.7.1\"]\n  }\n\n  reddit-client(\n    client_id=\"your_client_id\",\n    client_secret=\"your_secret\",\n    action=\"get_subreddit_posts\",\n    subreddit=\"python\",\n    sort=\"hot\",\n    limit=25\n  )\nend\n```\n\n**Input**:\n- `client_id` (string): Reddit API client ID\n- `client_secret` (string): Reddit API client secret\n- `user_agent` (string): User agent string\n- `action` (string): \"get_subreddit_posts\" or \"get_comments\"\n- `subreddit` (string): Subreddit name (for posts)\n- `submission_id` (string): Post ID (for comments)\n- `limit` (number): Number of items to fetch\n- `sort` (string): \"hot\", \"new\", \"top\", \"rising\"\n\n**Output**:\n```json\n{\n  \"posts\": [\n    {\n      \"id\": \"abc123\",\n      \"title\": \"Example Post\",\n      \"author\": \"username\",\n      \"score\": 1234,\n      \"url\": \"https://reddit.com/...\",\n      \"created_utc\": 1234567890,\n      \"num_comments\": 42,\n      \"selftext\": \"Post content...\"\n    }\n  ]\n}\n```\n\n---\n\n### Twitter/X API Client\n\n**Purpose**: Post tweets, fetch timeline, search tweets\n\n**Language**: Python\n\n**Dependencies**:\n```\ntweepy==4.14.0\n```\n\n**Code**:\n```python\nimport tweepy\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    api_key = input_data['api_key']\n    api_secret = input_data['api_secret']\n    access_token = input_data['access_token']\n    access_token_secret = input_data['access_token_secret']\n    action = input_data['action']\n\n    try:\n        client = tweepy.Client(\n            consumer_key=api_key,\n            consumer_secret=api_secret,\n            access_token=access_token,\n            access_token_secret=access_token_secret\n        )\n\n        result = {}\n\n        if action == 'post_tweet':\n            response = client.create_tweet(text=input_data['text'])\n            result = {'tweet_id': response.data['id']}\n\n        elif action == 'search_tweets':\n            query = input_data['query']\n            max_results = input_data.get('max_results', 10)\n\n            tweets = client.search_recent_tweets(\n                query=query,\n                max_results=max_results,\n                tweet_fields=['created_at', 'author_id', 'public_metrics']\n            )\n\n            result = {\n                'tweets': [\n                    {\n                        'id': tweet.id,\n                        'text': tweet.text,\n                        'created_at': str(tweet.created_at),\n                        'author_id': tweet.author_id,\n                        'metrics': tweet.public_metrics\n                    }\n                    for tweet in tweets.data\n                ]\n            }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow twitter-bot\n  agent twitter-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/twitter-client.py\"\n    dependencies: [\"tweepy==4.14.0\"]\n  }\n\n  twitter-client(\n    api_key=\"key\",\n    api_secret=\"secret\",\n    access_token=\"token\",\n    access_token_secret=\"token_secret\",\n    action=\"post_tweet\",\n    text=\"Hello from workflow!\"\n  )\nend\n```\n\n**Input**:\n- `api_key`, `api_secret`, `access_token`, `access_token_secret` (strings): Twitter API credentials\n- `action` (string): \"post_tweet\", \"search_tweets\"\n- `text` (string): Tweet text (for posting)\n- `query` (string): Search query (for search)\n- `max_results` (number): Max tweets to return\n\n**Output**:\n```json\n{\n  \"tweets\": [\n    {\n      \"id\": \"1234567890\",\n      \"text\": \"Tweet content\",\n      \"created_at\": \"2025-01-08T10:00:00\",\n      \"author_id\": \"9876543210\",\n      \"metrics\": {\"retweet_count\": 10, \"like_count\": 25}\n    }\n  ]\n}\n```\n\n---\n\n### GitHub API Client\n\n**Purpose**: Interact with GitHub repositories, issues, and pull requests\n\n**Language**: Node.js\n\n**Dependencies**:\n```\n@octokit/rest@20.0.2\n```\n\n**Code**:\n```javascript\nconst { Octokit } = require('@octokit/rest');\n\nasync function main() {\n  let input = '';\n\n  process.stdin.on('data', chunk => input += chunk);\n\n  process.stdin.on('end', async () => {\n    try {\n      const { token, action, owner, repo, ...params } = JSON.parse(input);\n\n      const octokit = new Octokit({ auth: token });\n\n      let result = {};\n\n      switch (action) {\n        case 'list_repos':\n          const repos = await octokit.rest.repos.listForAuthenticatedUser({\n            per_page: params.per_page || 30\n          });\n          result = { repositories: repos.data.map(r => ({\n            name: r.name,\n            full_name: r.full_name,\n            description: r.description,\n            stars: r.stargazers_count,\n            url: r.html_url\n          }))};\n          break;\n\n        case 'create_issue':\n          const issue = await octokit.rest.issues.create({\n            owner,\n            repo,\n            title: params.title,\n            body: params.body,\n            labels: params.labels || []\n          });\n          result = { issue_number: issue.data.number, url: issue.data.html_url };\n          break;\n\n        case 'list_issues':\n          const issues = await octokit.rest.issues.listForRepo({\n            owner,\n            repo,\n            state: params.state || 'open',\n            per_page: params.per_page || 30\n          });\n          result = { issues: issues.data.map(i => ({\n            number: i.number,\n            title: i.title,\n            state: i.state,\n            created_at: i.created_at,\n            url: i.html_url\n          }))};\n          break;\n\n        case 'get_file':\n          const file = await octokit.rest.repos.getContent({\n            owner,\n            repo,\n            path: params.path\n          });\n          result = {\n            name: file.data.name,\n            path: file.data.path,\n            content: Buffer.from(file.data.content, 'base64').toString('utf8')\n          };\n          break;\n      }\n\n      console.log(JSON.stringify(result));\n    } catch (error) {\n      console.error(JSON.stringify({ error: error.message }));\n      process.exit(1);\n    }\n  });\n}\n\nmain();\n```\n\n**Usage in Workflow**:\n```flow\nworkflow github-automation\n  agent github-client {\n    type: temp-script\n    language: node\n    script: \"./scripts/github-client.js\"\n    dependencies: [\"@octokit/rest@20.0.2\"]\n  }\n\n  github-client(\n    token=\"ghp_token\",\n    action=\"create_issue\",\n    owner=\"username\",\n    repo=\"repository\",\n    title=\"Bug report\",\n    body=\"Description of the issue\",\n    labels=[\"bug\", \"priority-high\"]\n  )\nend\n```\n\n**Input**:\n- `token` (string): GitHub personal access token\n- `action` (string): \"list_repos\", \"create_issue\", \"list_issues\", \"get_file\"\n- `owner` (string): Repository owner\n- `repo` (string): Repository name\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"issue_number\": 42,\n  \"url\": \"https://github.com/owner/repo/issues/42\"\n}\n```\n\n---\n\n### OpenAI API Client\n\n**Purpose**: Generate text, embeddings, and chat completions\n\n**Language**: Python\n\n**Dependencies**:\n```\nopenai==1.6.1\n```\n\n**Code**:\n```python\nimport openai\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    api_key = input_data['api_key']\n    action = input_data['action']\n\n    openai.api_key = api_key\n\n    try:\n        result = {}\n\n        if action == 'chat_completion':\n            response = openai.ChatCompletion.create(\n                model=input_data.get('model', 'gpt-4'),\n                messages=input_data['messages'],\n                temperature=input_data.get('temperature', 0.7),\n                max_tokens=input_data.get('max_tokens', 1000)\n            )\n            result = {\n                'content': response.choices[0].message.content,\n                'usage': dict(response.usage)\n            }\n\n        elif action == 'embeddings':\n            response = openai.Embedding.create(\n                model=input_data.get('model', 'text-embedding-ada-002'),\n                input=input_data['text']\n            )\n            result = {\n                'embedding': response.data[0].embedding,\n                'usage': dict(response.usage)\n            }\n\n        elif action == 'moderation':\n            response = openai.Moderation.create(\n                input=input_data['text']\n            )\n            result = {\n                'flagged': response.results[0].flagged,\n                'categories': dict(response.results[0].categories)\n            }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow ai-processor\n  agent openai-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/openai-client.py\"\n    dependencies: [\"openai==1.6.1\"]\n  }\n\n  openai-client(\n    api_key=\"sk-...\",\n    action=\"chat_completion\",\n    model=\"gpt-4\",\n    messages=[\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n      {\"role\": \"user\", \"content\": \"What is 2+2?\"}\n    ]\n  )\nend\n```\n\n**Input**:\n- `api_key` (string): OpenAI API key\n- `action` (string): \"chat_completion\", \"embeddings\", \"moderation\"\n- `model` (string): Model name\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"content\": \"2+2 equals 4.\",\n  \"usage\": {\"prompt_tokens\": 15, \"completion_tokens\": 8, \"total_tokens\": 23}\n}\n```\n\n---\n\n### Supabase Client\n\n**Purpose**: Query and manipulate data in Supabase database\n\n**Language**: Node.js\n\n**Dependencies**:\n```\n@supabase/supabase-js@2.39.0\n```\n\n**Code**:\n```javascript\nconst { createClient } = require('@supabase/supabase-js');\n\nasync function main() {\n  let input = '';\n\n  process.stdin.on('data', chunk => input += chunk);\n\n  process.stdin.on('end', async () => {\n    try {\n      const { url, key, action, table, ...params } = JSON.parse(input);\n\n      const supabase = createClient(url, key);\n\n      let result = {};\n\n      switch (action) {\n        case 'select':\n          const { data: selectData, error: selectError } = await supabase\n            .from(table)\n            .select(params.columns || '*')\n            .limit(params.limit || 100);\n\n          if (selectError) throw selectError;\n          result = { data: selectData };\n          break;\n\n        case 'insert':\n          const { data: insertData, error: insertError } = await supabase\n            .from(table)\n            .insert(params.records)\n            .select();\n\n          if (insertError) throw insertError;\n          result = { data: insertData };\n          break;\n\n        case 'update':\n          const { data: updateData, error: updateError } = await supabase\n            .from(table)\n            .update(params.updates)\n            .match(params.match)\n            .select();\n\n          if (updateError) throw updateError;\n          result = { data: updateData };\n          break;\n\n        case 'delete':\n          const { error: deleteError } = await supabase\n            .from(table)\n            .delete()\n            .match(params.match);\n\n          if (deleteError) throw deleteError;\n          result = { success: true };\n          break;\n      }\n\n      console.log(JSON.stringify(result));\n    } catch (error) {\n      console.error(JSON.stringify({ error: error.message }));\n      process.exit(1);\n    }\n  });\n}\n\nmain();\n```\n\n**Usage in Workflow**:\n```flow\nworkflow supabase-sync\n  agent supabase-client {\n    type: temp-script\n    language: node\n    script: \"./scripts/supabase-client.js\"\n    dependencies: [\"@supabase/supabase-js@2.39.0\"]\n  }\n\n  supabase-client(\n    url=\"https://your-project.supabase.co\",\n    key=\"your-anon-key\",\n    action=\"insert\",\n    table=\"users\",\n    records=[{\"name\": \"John\", \"email\": \"john@example.com\"}]\n  )\nend\n```\n\n**Input**:\n- `url` (string): Supabase project URL\n- `key` (string): Supabase anon/service key\n- `action` (string): \"select\", \"insert\", \"update\", \"delete\"\n- `table` (string): Table name\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"data\": [\n    {\"id\": 1, \"name\": \"John\", \"email\": \"john@example.com\"}\n  ]\n}\n```\n\n---\n\n## 2. Data Processing\n\n### CSV Processor\n\n**Purpose**: Read, transform, and analyze CSV files\n\n**Language**: Python\n\n**Dependencies**:\n```\npandas==2.1.4\n```\n\n**Code**:\n```python\nimport pandas as pd\nimport json\nimport sys\nimport io\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    action = input_data['action']\n\n    try:\n        result = {}\n\n        if action == 'read':\n            # Read from file or string\n            if 'file_path' in input_data:\n                df = pd.read_csv(input_data['file_path'])\n            else:\n                df = pd.read_csv(io.StringIO(input_data['csv_content']))\n\n            result = {\n                'rows': len(df),\n                'columns': list(df.columns),\n                'data': df.to_dict('records')\n            }\n\n        elif action == 'filter':\n            if 'file_path' in input_data:\n                df = pd.read_csv(input_data['file_path'])\n            else:\n                df = pd.read_csv(io.StringIO(input_data['csv_content']))\n\n            # Apply filters\n            for col, value in input_data.get('filters', {}).items():\n                df = df[df[col] == value]\n\n            result = {\n                'rows': len(df),\n                'data': df.to_dict('records')\n            }\n\n        elif action == 'aggregate':\n            if 'file_path' in input_data:\n                df = pd.read_csv(input_data['file_path'])\n            else:\n                df = pd.read_csv(io.StringIO(input_data['csv_content']))\n\n            group_by = input_data['group_by']\n            agg_func = input_data.get('function', 'sum')\n            agg_column = input_data['column']\n\n            grouped = df.groupby(group_by)[agg_column].agg(agg_func)\n\n            result = {\n                'aggregation': grouped.to_dict()\n            }\n\n        elif action == 'transform':\n            if 'file_path' in input_data:\n                df = pd.read_csv(input_data['file_path'])\n            else:\n                df = pd.read_csv(io.StringIO(input_data['csv_content']))\n\n            # Apply transformations\n            for col, operation in input_data.get('transformations', {}).items():\n                if operation['type'] == 'rename':\n                    df.rename(columns={col: operation['new_name']}, inplace=True)\n                elif operation['type'] == 'multiply':\n                    df[col] = df[col] * operation['factor']\n                elif operation['type'] == 'uppercase':\n                    df[col] = df[col].str.upper()\n\n            result = {\n                'data': df.to_dict('records')\n            }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow csv-analysis\n  agent csv-processor {\n    type: temp-script\n    language: python\n    script: \"./scripts/csv-processor.py\"\n    dependencies: [\"pandas==2.1.4\"]\n  }\n\n  csv-processor(\n    action=\"filter\",\n    file_path=\"/data/sales.csv\",\n    filters={\"region\": \"North\", \"year\": 2024}\n  )\nend\n```\n\n**Input**:\n- `action` (string): \"read\", \"filter\", \"aggregate\", \"transform\"\n- `file_path` (string) or `csv_content` (string): CSV source\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"rows\": 150,\n  \"data\": [\n    {\"name\": \"Product A\", \"sales\": 1000, \"region\": \"North\"}\n  ]\n}\n```\n\n---\n\n### JSON Transformer\n\n**Purpose**: Transform, validate, and manipulate JSON data\n\n**Language**: Node.js\n\n**Dependencies**:\n```\nlodash@4.17.21\najv@8.12.0\n```\n\n**Code**:\n```javascript\nconst _ = require('lodash');\nconst Ajv = require('ajv');\n\nasync function main() {\n  let input = '';\n\n  process.stdin.on('data', chunk => input += chunk);\n\n  process.stdin.on('end', async () => {\n    try {\n      const { action, data, ...params } = JSON.parse(input);\n\n      let result = {};\n\n      switch (action) {\n        case 'transform':\n          // Apply JSONPath-like transformations\n          const mappings = params.mappings || {};\n          result = {};\n\n          for (const [key, path] of Object.entries(mappings)) {\n            result[key] = _.get(data, path);\n          }\n          break;\n\n        case 'validate':\n          const ajv = new Ajv();\n          const validate = ajv.compile(params.schema);\n          const valid = validate(data);\n\n          result = {\n            valid,\n            errors: validate.errors || []\n          };\n          break;\n\n        case 'merge':\n          result = _.merge({}, ...params.objects);\n          break;\n\n        case 'filter':\n          // Filter array by predicate\n          result = {\n            filtered: _.filter(data, params.predicate)\n          };\n          break;\n\n        case 'group':\n          result = {\n            grouped: _.groupBy(data, params.key)\n          };\n          break;\n\n        case 'flatten':\n          result = {\n            flattened: _.flattenDeep(data)\n          };\n          break;\n      }\n\n      console.log(JSON.stringify(result));\n    } catch (error) {\n      console.error(JSON.stringify({ error: error.message }));\n      process.exit(1);\n    }\n  });\n}\n\nmain();\n```\n\n**Usage in Workflow**:\n```flow\nworkflow json-pipeline\n  agent json-transformer {\n    type: temp-script\n    language: node\n    script: \"./scripts/json-transformer.js\"\n    dependencies: [\"lodash@4.17.21\", \"ajv@8.12.0\"]\n  }\n\n  json-transformer(\n    action=\"transform\",\n    data={\"user\": {\"name\": \"John\", \"address\": {\"city\": \"NYC\"}}},\n    mappings={\"userName\": \"user.name\", \"city\": \"user.address.city\"}\n  )\nend\n```\n\n**Input**:\n- `action` (string): \"transform\", \"validate\", \"merge\", \"filter\", \"group\", \"flatten\"\n- `data` (any): Input JSON data\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"userName\": \"John\",\n  \"city\": \"NYC\"\n}\n```\n\n---\n\n### XML Parser\n\n**Purpose**: Parse and extract data from XML documents\n\n**Language**: Python\n\n**Dependencies**:\n```\nlxml==5.1.0\nxmltodict==0.13.0\n```\n\n**Code**:\n```python\nimport xml.etree.ElementTree as ET\nimport xmltodict\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    xml_content = input_data.get('xml_content')\n    file_path = input_data.get('file_path')\n    action = input_data['action']\n\n    try:\n        # Load XML\n        if file_path:\n            with open(file_path, 'r') as f:\n                xml_content = f.read()\n\n        result = {}\n\n        if action == 'to_json':\n            # Convert XML to JSON\n            data_dict = xmltodict.parse(xml_content)\n            result = {'data': data_dict}\n\n        elif action == 'xpath':\n            # Extract using XPath\n            root = ET.fromstring(xml_content)\n            xpath = input_data['xpath']\n\n            elements = []\n            for elem in root.findall(xpath):\n                elements.append({\n                    'tag': elem.tag,\n                    'text': elem.text,\n                    'attrib': elem.attrib\n                })\n\n            result = {'elements': elements}\n\n        elif action == 'extract':\n            # Extract specific fields\n            root = ET.fromstring(xml_content)\n            mappings = input_data['mappings']\n\n            extracted = {}\n            for key, xpath in mappings.items():\n                elem = root.find(xpath)\n                extracted[key] = elem.text if elem is not None else None\n\n            result = extracted\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow xml-parser\n  agent xml-processor {\n    type: temp-script\n    language: python\n    script: \"./scripts/xml-parser.py\"\n    dependencies: [\"lxml==5.1.0\", \"xmltodict==0.13.0\"]\n  }\n\n  xml-processor(\n    action=\"to_json\",\n    file_path=\"/data/config.xml\"\n  )\nend\n```\n\n**Input**:\n- `action` (string): \"to_json\", \"xpath\", \"extract\"\n- `xml_content` (string) or `file_path` (string): XML source\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"data\": {\n    \"config\": {\n      \"setting\": {\"@name\": \"value\"}\n    }\n  }\n}\n```\n\n---\n\n### Excel File Processor\n\n**Purpose**: Read and write Excel files with multiple sheets\n\n**Language**: Python\n\n**Dependencies**:\n```\nopenpyxl==3.1.2\npandas==2.1.4\n```\n\n**Code**:\n```python\nimport pandas as pd\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    action = input_data['action']\n    file_path = input_data.get('file_path')\n\n    try:\n        result = {}\n\n        if action == 'read':\n            # Read all sheets\n            excel_file = pd.ExcelFile(file_path)\n            sheets = {}\n\n            for sheet_name in excel_file.sheet_names:\n                df = pd.read_excel(file_path, sheet_name=sheet_name)\n                sheets[sheet_name] = {\n                    'rows': len(df),\n                    'columns': list(df.columns),\n                    'data': df.to_dict('records')\n                }\n\n            result = {'sheets': sheets}\n\n        elif action == 'read_sheet':\n            sheet_name = input_data.get('sheet_name', 0)\n            df = pd.read_excel(file_path, sheet_name=sheet_name)\n\n            result = {\n                'rows': len(df),\n                'columns': list(df.columns),\n                'data': df.to_dict('records')\n            }\n\n        elif action == 'write':\n            output_path = input_data['output_path']\n            sheets_data = input_data['sheets']\n\n            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n                for sheet_name, data in sheets_data.items():\n                    df = pd.DataFrame(data)\n                    df.to_excel(writer, sheet_name=sheet_name, index=False)\n\n            result = {'success': True, 'file': output_path}\n\n        elif action == 'append':\n            sheet_name = input_data.get('sheet_name', 'Sheet1')\n            new_data = input_data['data']\n\n            # Read existing\n            try:\n                df = pd.read_excel(file_path, sheet_name=sheet_name)\n            except:\n                df = pd.DataFrame()\n\n            # Append new data\n            new_df = pd.DataFrame(new_data)\n            df = pd.concat([df, new_df], ignore_index=True)\n\n            # Write back\n            with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n                df.to_excel(writer, sheet_name=sheet_name, index=False)\n\n            result = {'success': True, 'total_rows': len(df)}\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow excel-processor\n  agent excel-handler {\n    type: temp-script\n    language: python\n    script: \"./scripts/excel-processor.py\"\n    dependencies: [\"openpyxl==3.1.2\", \"pandas==2.1.4\"]\n  }\n\n  excel-handler(\n    action=\"read_sheet\",\n    file_path=\"/data/report.xlsx\",\n    sheet_name=\"Sales\"\n  )\nend\n```\n\n**Input**:\n- `action` (string): \"read\", \"read_sheet\", \"write\", \"append\"\n- `file_path` (string): Excel file path\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"rows\": 100,\n  \"columns\": [\"Name\", \"Sales\", \"Region\"],\n  \"data\": [{\"Name\": \"Product A\", \"Sales\": 1000, \"Region\": \"North\"}]\n}\n```\n\n---\n\n### PDF Text Extractor\n\n**Purpose**: Extract text and metadata from PDF files\n\n**Language**: Python\n\n**Dependencies**:\n```\nPyPDF2==3.0.1\npdfplumber==0.10.3\n```\n\n**Code**:\n```python\nimport PyPDF2\nimport pdfplumber\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    file_path = input_data['file_path']\n    method = input_data.get('method', 'pypdf2')\n\n    try:\n        result = {}\n\n        if method == 'pypdf2':\n            with open(file_path, 'rb') as f:\n                reader = PyPDF2.PdfReader(f)\n\n                pages = []\n                for i, page in enumerate(reader.pages):\n                    pages.append({\n                        'page_number': i + 1,\n                        'text': page.extract_text()\n                    })\n\n                result = {\n                    'num_pages': len(reader.pages),\n                    'metadata': dict(reader.metadata) if reader.metadata else {},\n                    'pages': pages\n                }\n\n        elif method == 'pdfplumber':\n            with pdfplumber.open(file_path) as pdf:\n                pages = []\n\n                for i, page in enumerate(pdf.pages):\n                    page_data = {\n                        'page_number': i + 1,\n                        'text': page.extract_text(),\n                        'width': page.width,\n                        'height': page.height\n                    }\n\n                    # Extract tables if requested\n                    if input_data.get('extract_tables', False):\n                        tables = page.extract_tables()\n                        page_data['tables'] = tables\n\n                    pages.append(page_data)\n\n                result = {\n                    'num_pages': len(pdf.pages),\n                    'metadata': pdf.metadata,\n                    'pages': pages\n                }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow pdf-extractor\n  agent pdf-reader {\n    type: temp-script\n    language: python\n    script: \"./scripts/pdf-extractor.py\"\n    dependencies: [\"PyPDF2==3.0.1\", \"pdfplumber==0.10.3\"]\n  }\n\n  pdf-reader(\n    file_path=\"/documents/report.pdf\",\n    method=\"pdfplumber\",\n    extract_tables=true\n  )\nend\n```\n\n**Input**:\n- `file_path` (string): PDF file path\n- `method` (string): \"pypdf2\" or \"pdfplumber\"\n- `extract_tables` (boolean): Extract tables (pdfplumber only)\n\n**Output**:\n```json\n{\n  \"num_pages\": 5,\n  \"metadata\": {\"Title\": \"Report\", \"Author\": \"John Doe\"},\n  \"pages\": [\n    {\n      \"page_number\": 1,\n      \"text\": \"Page content...\",\n      \"tables\": [[[\"Header1\", \"Header2\"], [\"Data1\", \"Data2\"]]]\n    }\n  ]\n}\n```\n\n---\n\n## 3. Web Scraping\n\n### HTML Scraper (BeautifulSoup)\n\n**Purpose**: Scrape and parse HTML content from web pages\n\n**Language**: Python\n\n**Dependencies**:\n```\nbeautifulsoup4==4.12.2\nrequests==2.31.0\nlxml==5.1.0\n```\n\n**Code**:\n```python\nfrom bs4 import BeautifulSoup\nimport requests\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    url = input_data.get('url')\n    html_content = input_data.get('html_content')\n\n    try:\n        # Get HTML content\n        if url:\n            headers = input_data.get('headers', {})\n            response = requests.get(url, headers=headers, timeout=30)\n            response.raise_for_status()\n            html_content = response.text\n\n        soup = BeautifulSoup(html_content, 'lxml')\n\n        action = input_data['action']\n        result = {}\n\n        if action == 'extract_text':\n            selector = input_data['selector']\n            elements = soup.select(selector)\n\n            result = {\n                'count': len(elements),\n                'items': [elem.get_text(strip=True) for elem in elements]\n            }\n\n        elif action == 'extract_attrs':\n            selector = input_data['selector']\n            attr = input_data['attribute']\n            elements = soup.select(selector)\n\n            result = {\n                'count': len(elements),\n                'items': [elem.get(attr) for elem in elements if elem.get(attr)]\n            }\n\n        elif action == 'extract_structured':\n            # Extract structured data using multiple selectors\n            items = []\n            container_selector = input_data['container']\n            field_selectors = input_data['fields']\n\n            for container in soup.select(container_selector):\n                item = {}\n                for field_name, selector in field_selectors.items():\n                    elem = container.select_one(selector)\n                    if elem:\n                        if 'attr' in selector:\n                            # Extract attribute\n                            attr_name = selector.split('@')[1]\n                            item[field_name] = elem.get(attr_name)\n                        else:\n                            item[field_name] = elem.get_text(strip=True)\n                items.append(item)\n\n            result = {\n                'count': len(items),\n                'items': items\n            }\n\n        elif action == 'get_links':\n            links = []\n            for a in soup.find_all('a', href=True):\n                links.append({\n                    'text': a.get_text(strip=True),\n                    'href': a['href']\n                })\n\n            result = {'links': links}\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow web-scraper\n  agent html-scraper {\n    type: temp-script\n    language: python\n    script: \"./scripts/html-scraper.py\"\n    dependencies: [\"beautifulsoup4==4.12.2\", \"requests==2.31.0\", \"lxml==5.1.0\"]\n  }\n\n  html-scraper(\n    url=\"https://news.ycombinator.com\",\n    action=\"extract_structured\",\n    container=\".athing\",\n    fields={\n      \"title\": \".titleline > a\",\n      \"url\": \".titleline > a@href\",\n      \"score\": \".score\"\n    }\n  )\nend\n```\n\n**Input**:\n- `url` (string) or `html_content` (string): HTML source\n- `action` (string): \"extract_text\", \"extract_attrs\", \"extract_structured\", \"get_links\"\n- CSS selectors and field mappings\n\n**Output**:\n```json\n{\n  \"count\": 30,\n  \"items\": [\n    {\n      \"title\": \"Article Title\",\n      \"url\": \"https://example.com/article\",\n      \"score\": \"123\"\n    }\n  ]\n}\n```\n\n---\n\n### Dynamic Page Scraper (Playwright)\n\n**Purpose**: Scrape JavaScript-rendered pages with browser automation\n\n**Language**: Node.js\n\n**Dependencies**:\n```\nplaywright@1.40.1\n```\n\n**Code**:\n```javascript\nconst { chromium } = require('playwright');\n\nasync function main() {\n  let input = '';\n\n  process.stdin.on('data', chunk => input += chunk);\n\n  process.stdin.on('end', async () => {\n    const browser = await chromium.launch({ headless: true });\n\n    try {\n      const { url, action, ...params } = JSON.parse(input);\n\n      const page = await browser.newPage();\n      await page.goto(url, { waitUntil: 'networkidle' });\n\n      let result = {};\n\n      switch (action) {\n        case 'screenshot':\n          const screenshot = await page.screenshot({\n            fullPage: params.fullPage || false,\n            type: params.format || 'png'\n          });\n          result = {\n            screenshot: screenshot.toString('base64'),\n            path: params.output_path\n          };\n          if (params.output_path) {\n            await page.screenshot({ path: params.output_path });\n          }\n          break;\n\n        case 'extract':\n          // Wait for selector if provided\n          if (params.wait_for) {\n            await page.waitForSelector(params.wait_for, { timeout: 10000 });\n          }\n\n          // Extract data using selectors\n          const data = await page.evaluate((selectors) => {\n            const results = [];\n            document.querySelectorAll(selectors.container).forEach(elem => {\n              const item = {};\n              for (const [key, selector] of Object.entries(selectors.fields)) {\n                const field = elem.querySelector(selector);\n                item[key] = field ? field.textContent.trim() : null;\n              }\n              results.push(item);\n            });\n            return results;\n          }, params);\n\n          result = { items: data };\n          break;\n\n        case 'interact':\n          // Click, type, and navigate\n          for (const step of params.steps) {\n            if (step.action === 'click') {\n              await page.click(step.selector);\n            } else if (step.action === 'type') {\n              await page.fill(step.selector, step.text);\n            } else if (step.action === 'wait') {\n              await page.waitForTimeout(step.ms);\n            }\n          }\n\n          // Get final page content or data\n          const content = await page.content();\n          result = { html: content };\n          break;\n\n        case 'pdf':\n          const pdf = await page.pdf({\n            format: params.format || 'A4',\n            path: params.output_path\n          });\n          result = { success: true, path: params.output_path };\n          break;\n      }\n\n      await browser.close();\n      console.log(JSON.stringify(result));\n\n    } catch (error) {\n      await browser.close();\n      console.error(JSON.stringify({ error: error.message }));\n      process.exit(1);\n    }\n  });\n}\n\nmain();\n```\n\n**Usage in Workflow**:\n```flow\nworkflow dynamic-scraper\n  agent playwright-scraper {\n    type: temp-script\n    language: node\n    script: \"./scripts/playwright-scraper.js\"\n    dependencies: [\"playwright@1.40.1\"]\n  }\n\n  playwright-scraper(\n    url=\"https://example.com\",\n    action=\"extract\",\n    wait_for=\".content\",\n    container=\".item\",\n    fields={\"title\": \"h2\", \"description\": \"p\"}\n  )\nend\n```\n\n**Input**:\n- `url` (string): Target URL\n- `action` (string): \"screenshot\", \"extract\", \"interact\", \"pdf\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"items\": [\n    {\"title\": \"Item 1\", \"description\": \"Description...\"}\n  ]\n}\n```\n\n---\n\n### Sitemap Crawler\n\n**Purpose**: Crawl website sitemaps and extract URLs\n\n**Language**: Python\n\n**Dependencies**:\n```\nrequests==2.31.0\nlxml==5.1.0\n```\n\n**Code**:\n```python\nimport requests\nimport xml.etree.ElementTree as ET\nimport json\nimport sys\nfrom urllib.parse import urljoin\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    sitemap_url = input_data['sitemap_url']\n    max_urls = input_data.get('max_urls', 1000)\n\n    try:\n        urls = []\n\n        def parse_sitemap(url, depth=0):\n            if len(urls) >= max_urls or depth > 3:\n                return\n\n            response = requests.get(url, timeout=30)\n            response.raise_for_status()\n\n            root = ET.fromstring(response.content)\n\n            # Handle namespace\n            ns = {'sm': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n\n            # Check for sitemap index\n            sitemaps = root.findall('.//sm:sitemap/sm:loc', ns)\n            if sitemaps:\n                # This is a sitemap index, recurse into child sitemaps\n                for sitemap in sitemaps:\n                    if len(urls) >= max_urls:\n                        break\n                    parse_sitemap(sitemap.text, depth + 1)\n            else:\n                # This is a URL set, extract URLs\n                for url_elem in root.findall('.//sm:url', ns):\n                    if len(urls) >= max_urls:\n                        break\n\n                    loc = url_elem.find('sm:loc', ns)\n                    lastmod = url_elem.find('sm:lastmod', ns)\n                    priority = url_elem.find('sm:priority', ns)\n\n                    url_data = {\n                        'url': loc.text if loc is not None else None,\n                        'lastmod': lastmod.text if lastmod is not None else None,\n                        'priority': priority.text if priority is not None else None\n                    }\n\n                    urls.append(url_data)\n\n        parse_sitemap(sitemap_url)\n\n        result = {\n            'total_urls': len(urls),\n            'urls': urls\n        }\n\n        # Filter by criteria if provided\n        if 'filter_pattern' in input_data:\n            import re\n            pattern = re.compile(input_data['filter_pattern'])\n            result['urls'] = [u for u in urls if pattern.search(u['url'])]\n            result['filtered_count'] = len(result['urls'])\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow sitemap-crawler\n  agent sitemap-parser {\n    type: temp-script\n    language: python\n    script: \"./scripts/sitemap-crawler.py\"\n    dependencies: [\"requests==2.31.0\", \"lxml==5.1.0\"]\n  }\n\n  sitemap-parser(\n    sitemap_url=\"https://example.com/sitemap.xml\",\n    max_urls=500,\n    filter_pattern=\"/blog/\"\n  )\nend\n```\n\n**Input**:\n- `sitemap_url` (string): Sitemap XML URL\n- `max_urls` (number): Maximum URLs to extract\n- `filter_pattern` (string): Regex pattern to filter URLs\n\n**Output**:\n```json\n{\n  \"total_urls\": 250,\n  \"urls\": [\n    {\n      \"url\": \"https://example.com/page1\",\n      \"lastmod\": \"2025-01-08\",\n      \"priority\": \"0.8\"\n    }\n  ]\n}\n```\n\n---\n\n## 4. Database Access\n\n### PostgreSQL Client\n\n**Purpose**: Execute queries and manage PostgreSQL databases\n\n**Language**: Python\n\n**Dependencies**:\n```\npsycopg2-binary==2.9.9\n```\n\n**Code**:\n```python\nimport psycopg2\nimport psycopg2.extras\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    # Connection parameters\n    conn_params = {\n        'host': input_data['host'],\n        'port': input_data.get('port', 5432),\n        'database': input_data['database'],\n        'user': input_data['user'],\n        'password': input_data['password']\n    }\n\n    action = input_data['action']\n\n    try:\n        conn = psycopg2.connect(**conn_params)\n        cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n\n        result = {}\n\n        if action == 'query':\n            query = input_data['query']\n            params = input_data.get('params', None)\n\n            cur.execute(query, params)\n\n            if query.strip().upper().startswith('SELECT'):\n                rows = cur.fetchall()\n                result = {\n                    'rows': [dict(row) for row in rows],\n                    'count': len(rows)\n                }\n            else:\n                conn.commit()\n                result = {\n                    'affected_rows': cur.rowcount,\n                    'success': True\n                }\n\n        elif action == 'batch_insert':\n            table = input_data['table']\n            records = input_data['records']\n\n            if records:\n                columns = records[0].keys()\n                values = [[r[col] for col in columns] for r in records]\n\n                query = f\"INSERT INTO {table} ({','.join(columns)}) VALUES ({','.join(['%s'] * len(columns))})\"\n                cur.executemany(query, values)\n                conn.commit()\n\n                result = {\n                    'inserted': cur.rowcount,\n                    'success': True\n                }\n\n        elif action == 'table_info':\n            table = input_data['table']\n\n            cur.execute(\"\"\"\n                SELECT column_name, data_type, is_nullable\n                FROM information_schema.columns\n                WHERE table_name = %s\n                ORDER BY ordinal_position\n            \"\"\", (table,))\n\n            columns = cur.fetchall()\n            result = {\n                'columns': [dict(col) for col in columns]\n            }\n\n        cur.close()\n        conn.close()\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow postgres-sync\n  agent pg-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/postgres-client.py\"\n    dependencies: [\"psycopg2-binary==2.9.9\"]\n  }\n\n  pg-client(\n    host=\"localhost\",\n    database=\"mydb\",\n    user=\"postgres\",\n    password=\"password\",\n    action=\"query\",\n    query=\"SELECT * FROM users WHERE active = %s\",\n    params=[true]\n  )\nend\n```\n\n**Input**:\n- `host`, `port`, `database`, `user`, `password` (strings): Connection details\n- `action` (string): \"query\", \"batch_insert\", \"table_info\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"rows\": [\n    {\"id\": 1, \"name\": \"John\", \"active\": true}\n  ],\n  \"count\": 1\n}\n```\n\n---\n\n### MongoDB Client\n\n**Purpose**: Interact with MongoDB collections\n\n**Language**: Node.js\n\n**Dependencies**:\n```\nmongodb@6.3.0\n```\n\n**Code**:\n```javascript\nconst { MongoClient } = require('mongodb');\n\nasync function main() {\n  let input = '';\n\n  process.stdin.on('data', chunk => input += chunk);\n\n  process.stdin.on('end', async () => {\n    let client;\n\n    try {\n      const { uri, database, collection, action, ...params } = JSON.parse(input);\n\n      client = new MongoClient(uri);\n      await client.connect();\n\n      const db = client.db(database);\n      const coll = db.collection(collection);\n\n      let result = {};\n\n      switch (action) {\n        case 'find':\n          const docs = await coll.find(params.filter || {})\n            .limit(params.limit || 100)\n            .toArray();\n          result = { documents: docs, count: docs.length };\n          break;\n\n        case 'insert':\n          const insertResult = await coll.insertMany(params.documents);\n          result = {\n            inserted: insertResult.insertedCount,\n            ids: Object.values(insertResult.insertedIds)\n          };\n          break;\n\n        case 'update':\n          const updateResult = await coll.updateMany(\n            params.filter,\n            params.update\n          );\n          result = {\n            matched: updateResult.matchedCount,\n            modified: updateResult.modifiedCount\n          };\n          break;\n\n        case 'delete':\n          const deleteResult = await coll.deleteMany(params.filter);\n          result = { deleted: deleteResult.deletedCount };\n          break;\n\n        case 'aggregate':\n          const aggResult = await coll.aggregate(params.pipeline).toArray();\n          result = { documents: aggResult };\n          break;\n      }\n\n      await client.close();\n      console.log(JSON.stringify(result));\n\n    } catch (error) {\n      if (client) await client.close();\n      console.error(JSON.stringify({ error: error.message }));\n      process.exit(1);\n    }\n  });\n}\n\nmain();\n```\n\n**Usage in Workflow**:\n```flow\nworkflow mongodb-sync\n  agent mongo-client {\n    type: temp-script\n    language: node\n    script: \"./scripts/mongodb-client.js\"\n    dependencies: [\"mongodb@6.3.0\"]\n  }\n\n  mongo-client(\n    uri=\"mongodb://localhost:27017\",\n    database=\"myapp\",\n    collection=\"users\",\n    action=\"find\",\n    filter={\"active\": true},\n    limit=50\n  )\nend\n```\n\n**Input**:\n- `uri` (string): MongoDB connection URI\n- `database` (string): Database name\n- `collection` (string): Collection name\n- `action` (string): \"find\", \"insert\", \"update\", \"delete\", \"aggregate\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"documents\": [\n    {\"_id\": \"507f1f77bcf86cd799439011\", \"name\": \"John\", \"active\": true}\n  ],\n  \"count\": 1\n}\n```\n\n---\n\n### SQLite Processor\n\n**Purpose**: Query and manage SQLite databases\n\n**Language**: Python\n\n**Dependencies**:\n```\n# No external dependencies - uses built-in sqlite3\n```\n\n**Code**:\n```python\nimport sqlite3\nimport json\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    db_path = input_data['db_path']\n    action = input_data['action']\n\n    try:\n        conn = sqlite3.connect(db_path)\n        conn.row_factory = sqlite3.Row\n        cur = conn.cursor()\n\n        result = {}\n\n        if action == 'query':\n            query = input_data['query']\n            params = input_data.get('params', [])\n\n            cur.execute(query, params)\n\n            if query.strip().upper().startswith('SELECT'):\n                rows = cur.fetchall()\n                result = {\n                    'rows': [dict(row) for row in rows],\n                    'count': len(rows)\n                }\n            else:\n                conn.commit()\n                result = {\n                    'affected_rows': cur.rowcount,\n                    'success': True\n                }\n\n        elif action == 'create_table':\n            table_name = input_data['table_name']\n            columns = input_data['columns']\n\n            column_defs = ', '.join([f\"{col['name']} {col['type']}\" for col in columns])\n            query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({column_defs})\"\n\n            cur.execute(query)\n            conn.commit()\n            result = {'success': True}\n\n        elif action == 'tables':\n            cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n            tables = [row['name'] for row in cur.fetchall()]\n            result = {'tables': tables}\n\n        elif action == 'schema':\n            table = input_data['table']\n            cur.execute(f\"PRAGMA table_info({table})\")\n            columns = cur.fetchall()\n            result = {\n                'columns': [dict(col) for col in columns]\n            }\n\n        cur.close()\n        conn.close()\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow sqlite-manager\n  agent sqlite-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/sqlite-client.py\"\n  }\n\n  sqlite-client(\n    db_path=\"/data/app.db\",\n    action=\"query\",\n    query=\"SELECT * FROM products WHERE price < ?\",\n    params=[100]\n  )\nend\n```\n\n**Input**:\n- `db_path` (string): SQLite database file path\n- `action` (string): \"query\", \"create_table\", \"tables\", \"schema\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"rows\": [\n    {\"id\": 1, \"name\": \"Product A\", \"price\": 50}\n  ],\n  \"count\": 1\n}\n```\n\n---\n\n## 5. File Operations\n\n### Image Processor\n\n**Purpose**: Resize, crop, convert, and manipulate images\n\n**Language**: Python\n\n**Dependencies**:\n```\nPillow==10.1.0\n```\n\n**Code**:\n```python\nfrom PIL import Image, ImageFilter, ImageEnhance\nimport json\nimport sys\nimport io\nimport base64\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    input_path = input_data.get('input_path')\n    output_path = input_data.get('output_path')\n    action = input_data['action']\n\n    try:\n        # Load image\n        img = Image.open(input_path)\n\n        result = {}\n\n        if action == 'resize':\n            width = input_data.get('width')\n            height = input_data.get('height')\n            maintain_aspect = input_data.get('maintain_aspect', True)\n\n            if maintain_aspect and width and height:\n                img.thumbnail((width, height), Image.Resampling.LANCZOS)\n            elif width and height:\n                img = img.resize((width, height), Image.Resampling.LANCZOS)\n            elif width:\n                aspect = img.height / img.width\n                img = img.resize((width, int(width * aspect)), Image.Resampling.LANCZOS)\n            elif height:\n                aspect = img.width / img.height\n                img = img.resize((int(height * aspect), height), Image.Resampling.LANCZOS)\n\n            result = {'width': img.width, 'height': img.height}\n\n        elif action == 'crop':\n            left = input_data.get('left', 0)\n            top = input_data.get('top', 0)\n            right = input_data.get('right', img.width)\n            bottom = input_data.get('bottom', img.height)\n\n            img = img.crop((left, top, right, bottom))\n            result = {'width': img.width, 'height': img.height}\n\n        elif action == 'filter':\n            filter_type = input_data['filter_type']\n\n            if filter_type == 'blur':\n                img = img.filter(ImageFilter.BLUR)\n            elif filter_type == 'sharpen':\n                img = img.filter(ImageFilter.SHARPEN)\n            elif filter_type == 'grayscale':\n                img = img.convert('L')\n\n            result = {'filter_applied': filter_type}\n\n        elif action == 'enhance':\n            enhance_type = input_data['enhance_type']\n            factor = input_data.get('factor', 1.5)\n\n            if enhance_type == 'brightness':\n                enhancer = ImageEnhance.Brightness(img)\n            elif enhance_type == 'contrast':\n                enhancer = ImageEnhance.Contrast(img)\n            elif enhance_type == 'sharpness':\n                enhancer = ImageEnhance.Sharpness(img)\n\n            img = enhancer.enhance(factor)\n            result = {'enhanced': enhance_type, 'factor': factor}\n\n        elif action == 'convert':\n            format_type = input_data['format'].upper()\n            if output_path:\n                img.save(output_path, format=format_type)\n                result = {'format': format_type, 'output': output_path}\n\n        elif action == 'info':\n            result = {\n                'format': img.format,\n                'mode': img.mode,\n                'width': img.width,\n                'height': img.height,\n                'size_bytes': img.size[0] * img.size[1] * len(img.getbands())\n            }\n\n        # Save output if path provided and not convert action\n        if output_path and action != 'convert' and action != 'info':\n            img.save(output_path)\n            result['output'] = output_path\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow image-pipeline\n  agent image-processor {\n    type: temp-script\n    language: python\n    script: \"./scripts/image-processor.py\"\n    dependencies: [\"Pillow==10.1.0\"]\n  }\n\n  image-processor(\n    input_path=\"/images/photo.jpg\",\n    output_path=\"/images/photo_resized.jpg\",\n    action=\"resize\",\n    width=800,\n    maintain_aspect=true\n  )\nend\n```\n\n**Input**:\n- `input_path` (string): Input image path\n- `output_path` (string): Output image path\n- `action` (string): \"resize\", \"crop\", \"filter\", \"enhance\", \"convert\", \"info\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"width\": 800,\n  \"height\": 600,\n  \"output\": \"/images/photo_resized.jpg\"\n}\n```\n\n---\n\n### Archive Creator\n\n**Purpose**: Create and extract ZIP and TAR archives\n\n**Language**: Python\n\n**Dependencies**:\n```\n# No external dependencies - uses built-in zipfile and tarfile\n```\n\n**Code**:\n```python\nimport zipfile\nimport tarfile\nimport json\nimport sys\nimport os\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    action = input_data['action']\n\n    try:\n        result = {}\n\n        if action == 'create_zip':\n            output_path = input_data['output_path']\n            files = input_data['files']\n\n            with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n                for file_info in files:\n                    source = file_info['source']\n                    arcname = file_info.get('arcname', os.path.basename(source))\n\n                    if os.path.isdir(source):\n                        for root, dirs, files_list in os.walk(source):\n                            for file in files_list:\n                                file_path = os.path.join(root, file)\n                                arc_path = os.path.join(arcname, os.path.relpath(file_path, source))\n                                zf.write(file_path, arc_path)\n                    else:\n                        zf.write(source, arcname)\n\n            result = {\n                'archive': output_path,\n                'size_bytes': os.path.getsize(output_path),\n                'success': True\n            }\n\n        elif action == 'extract_zip':\n            archive_path = input_data['archive_path']\n            extract_to = input_data['extract_to']\n\n            with zipfile.ZipFile(archive_path, 'r') as zf:\n                zf.extractall(extract_to)\n                members = zf.namelist()\n\n            result = {\n                'extracted_to': extract_to,\n                'files_count': len(members),\n                'files': members[:50]  # First 50 files\n            }\n\n        elif action == 'create_tar':\n            output_path = input_data['output_path']\n            files = input_data['files']\n            compression = input_data.get('compression', 'gz')\n\n            mode = f'w:{compression}' if compression else 'w'\n\n            with tarfile.open(output_path, mode) as tf:\n                for file_info in files:\n                    source = file_info['source']\n                    arcname = file_info.get('arcname', os.path.basename(source))\n                    tf.add(source, arcname=arcname)\n\n            result = {\n                'archive': output_path,\n                'size_bytes': os.path.getsize(output_path),\n                'compression': compression,\n                'success': True\n            }\n\n        elif action == 'extract_tar':\n            archive_path = input_data['archive_path']\n            extract_to = input_data['extract_to']\n\n            with tarfile.open(archive_path, 'r:*') as tf:\n                tf.extractall(extract_to)\n                members = tf.getnames()\n\n            result = {\n                'extracted_to': extract_to,\n                'files_count': len(members),\n                'files': members[:50]\n            }\n\n        elif action == 'list':\n            archive_path = input_data['archive_path']\n            archive_type = input_data.get('type', 'auto')\n\n            if archive_type == 'auto':\n                archive_type = 'zip' if archive_path.endswith('.zip') else 'tar'\n\n            if archive_type == 'zip':\n                with zipfile.ZipFile(archive_path, 'r') as zf:\n                    members = [{'name': info.filename, 'size': info.file_size}\n                              for info in zf.filelist]\n            else:\n                with tarfile.open(archive_path, 'r:*') as tf:\n                    members = [{'name': info.name, 'size': info.size}\n                              for info in tf.getmembers()]\n\n            result = {\n                'archive': archive_path,\n                'files_count': len(members),\n                'files': members\n            }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow archive-manager\n  agent archiver {\n    type: temp-script\n    language: python\n    script: \"./scripts/archive-creator.py\"\n  }\n\n  archiver(\n    action=\"create_zip\",\n    output_path=\"/backups/data.zip\",\n    files=[\n      {\"source\": \"/data/folder1\", \"arcname\": \"folder1\"},\n      {\"source\": \"/data/file.txt\", \"arcname\": \"file.txt\"}\n    ]\n  )\nend\n```\n\n**Input**:\n- `action` (string): \"create_zip\", \"extract_zip\", \"create_tar\", \"extract_tar\", \"list\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"archive\": \"/backups/data.zip\",\n  \"size_bytes\": 1048576,\n  \"success\": true\n}\n```\n\n---\n\n### File Converter\n\n**Purpose**: Convert between file formats (JSON, CSV, YAML, XML)\n\n**Language**: Python\n\n**Dependencies**:\n```\npyyaml==6.0.1\npandas==2.1.4\nxmltodict==0.13.0\n```\n\n**Code**:\n```python\nimport json\nimport csv\nimport yaml\nimport xmltodict\nimport pandas as pd\nimport sys\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    input_path = input_data.get('input_path')\n    output_path = input_data.get('output_path')\n    from_format = input_data['from_format']\n    to_format = input_data['to_format']\n\n    try:\n        # Read input data\n        data = None\n\n        if from_format == 'json':\n            with open(input_path, 'r') as f:\n                data = json.load(f)\n\n        elif from_format == 'csv':\n            df = pd.read_csv(input_path)\n            data = df.to_dict('records')\n\n        elif from_format == 'yaml':\n            with open(input_path, 'r') as f:\n                data = yaml.safe_load(f)\n\n        elif from_format == 'xml':\n            with open(input_path, 'r') as f:\n                data = xmltodict.parse(f.read())\n\n        # Write output data\n        result = {}\n\n        if to_format == 'json':\n            with open(output_path, 'w') as f:\n                json.dump(data, f, indent=2)\n            result = {'format': 'json', 'output': output_path}\n\n        elif to_format == 'csv':\n            df = pd.DataFrame(data)\n            df.to_csv(output_path, index=False)\n            result = {'format': 'csv', 'output': output_path, 'rows': len(df)}\n\n        elif to_format == 'yaml':\n            with open(output_path, 'w') as f:\n                yaml.dump(data, f, default_flow_style=False)\n            result = {'format': 'yaml', 'output': output_path}\n\n        elif to_format == 'xml':\n            with open(output_path, 'w') as f:\n                xml_str = xmltodict.unparse({'root': data}, pretty=True)\n                f.write(xml_str)\n            result = {'format': 'xml', 'output': output_path}\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow format-converter\n  agent file-converter {\n    type: temp-script\n    language: python\n    script: \"./scripts/file-converter.py\"\n    dependencies: [\"pyyaml==6.0.1\", \"pandas==2.1.4\", \"xmltodict==0.13.0\"]\n  }\n\n  file-converter(\n    input_path=\"/data/config.json\",\n    output_path=\"/data/config.yaml\",\n    from_format=\"json\",\n    to_format=\"yaml\"\n  )\nend\n```\n\n**Input**:\n- `input_path` (string): Input file path\n- `output_path` (string): Output file path\n- `from_format` (string): \"json\", \"csv\", \"yaml\", \"xml\"\n- `to_format` (string): \"json\", \"csv\", \"yaml\", \"xml\"\n\n**Output**:\n```json\n{\n  \"format\": \"yaml\",\n  \"output\": \"/data/config.yaml\"\n}\n```\n\n---\n\n## 6. Cloud Services\n\n### AWS S3 Uploader\n\n**Purpose**: Upload, download, and manage files in AWS S3\n\n**Language**: Python\n\n**Dependencies**:\n```\nboto3==1.34.19\n```\n\n**Code**:\n```python\nimport boto3\nimport json\nimport sys\nimport os\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    aws_access_key = input_data['aws_access_key_id']\n    aws_secret_key = input_data['aws_secret_access_key']\n    region = input_data.get('region', 'us-east-1')\n    bucket = input_data['bucket']\n    action = input_data['action']\n\n    try:\n        s3_client = boto3.client(\n            's3',\n            aws_access_key_id=aws_access_key,\n            aws_secret_access_key=aws_secret_key,\n            region_name=region\n        )\n\n        result = {}\n\n        if action == 'upload':\n            local_path = input_data['local_path']\n            s3_key = input_data['s3_key']\n\n            s3_client.upload_file(local_path, bucket, s3_key)\n\n            result = {\n                'uploaded': s3_key,\n                'bucket': bucket,\n                'size_bytes': os.path.getsize(local_path),\n                'url': f'https://{bucket}.s3.{region}.amazonaws.com/{s3_key}'\n            }\n\n        elif action == 'download':\n            s3_key = input_data['s3_key']\n            local_path = input_data['local_path']\n\n            s3_client.download_file(bucket, s3_key, local_path)\n\n            result = {\n                'downloaded': s3_key,\n                'local_path': local_path,\n                'size_bytes': os.path.getsize(local_path)\n            }\n\n        elif action == 'list':\n            prefix = input_data.get('prefix', '')\n            max_keys = input_data.get('max_keys', 1000)\n\n            response = s3_client.list_objects_v2(\n                Bucket=bucket,\n                Prefix=prefix,\n                MaxKeys=max_keys\n            )\n\n            files = []\n            if 'Contents' in response:\n                for obj in response['Contents']:\n                    files.append({\n                        'key': obj['Key'],\n                        'size': obj['Size'],\n                        'last_modified': obj['LastModified'].isoformat()\n                    })\n\n            result = {\n                'files': files,\n                'count': len(files)\n            }\n\n        elif action == 'delete':\n            s3_key = input_data['s3_key']\n\n            s3_client.delete_object(Bucket=bucket, Key=s3_key)\n\n            result = {\n                'deleted': s3_key,\n                'success': True\n            }\n\n        elif action == 'presigned_url':\n            s3_key = input_data['s3_key']\n            expiration = input_data.get('expiration', 3600)\n\n            url = s3_client.generate_presigned_url(\n                'get_object',\n                Params={'Bucket': bucket, 'Key': s3_key},\n                ExpiresIn=expiration\n            )\n\n            result = {\n                'url': url,\n                'expires_in': expiration\n            }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow s3-uploader\n  agent s3-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/s3-uploader.py\"\n    dependencies: [\"boto3==1.34.19\"]\n  }\n\n  s3-client(\n    aws_access_key_id=\"ACCESS_KEY\",\n    aws_secret_access_key=\"SECRET_KEY\",\n    bucket=\"my-bucket\",\n    action=\"upload\",\n    local_path=\"/data/file.pdf\",\n    s3_key=\"uploads/file.pdf\"\n  )\nend\n```\n\n**Input**:\n- `aws_access_key_id`, `aws_secret_access_key` (strings): AWS credentials\n- `bucket` (string): S3 bucket name\n- `region` (string): AWS region\n- `action` (string): \"upload\", \"download\", \"list\", \"delete\", \"presigned_url\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"uploaded\": \"uploads/file.pdf\",\n  \"bucket\": \"my-bucket\",\n  \"size_bytes\": 524288,\n  \"url\": \"https://my-bucket.s3.us-east-1.amazonaws.com/uploads/file.pdf\"\n}\n```\n\n---\n\n### Google Cloud Storage\n\n**Purpose**: Manage files in Google Cloud Storage buckets\n\n**Language**: Python\n\n**Dependencies**:\n```\ngoogle-cloud-storage==2.14.0\n```\n\n**Code**:\n```python\nfrom google.cloud import storage\nimport json\nimport sys\nimport os\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    # Set credentials from input\n    credentials_path = input_data.get('credentials_path')\n    if credentials_path:\n        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n\n    bucket_name = input_data['bucket']\n    action = input_data['action']\n\n    try:\n        client = storage.Client()\n        bucket = client.bucket(bucket_name)\n\n        result = {}\n\n        if action == 'upload':\n            local_path = input_data['local_path']\n            blob_name = input_data['blob_name']\n\n            blob = bucket.blob(blob_name)\n            blob.upload_from_filename(local_path)\n\n            result = {\n                'uploaded': blob_name,\n                'bucket': bucket_name,\n                'size_bytes': os.path.getsize(local_path),\n                'url': blob.public_url\n            }\n\n        elif action == 'download':\n            blob_name = input_data['blob_name']\n            local_path = input_data['local_path']\n\n            blob = bucket.blob(blob_name)\n            blob.download_to_filename(local_path)\n\n            result = {\n                'downloaded': blob_name,\n                'local_path': local_path,\n                'size_bytes': os.path.getsize(local_path)\n            }\n\n        elif action == 'list':\n            prefix = input_data.get('prefix', '')\n            max_results = input_data.get('max_results', 1000)\n\n            blobs = client.list_blobs(bucket_name, prefix=prefix, max_results=max_results)\n\n            files = []\n            for blob in blobs:\n                files.append({\n                    'name': blob.name,\n                    'size': blob.size,\n                    'updated': blob.updated.isoformat() if blob.updated else None\n                })\n\n            result = {\n                'files': files,\n                'count': len(files)\n            }\n\n        elif action == 'delete':\n            blob_name = input_data['blob_name']\n\n            blob = bucket.blob(blob_name)\n            blob.delete()\n\n            result = {\n                'deleted': blob_name,\n                'success': True\n            }\n\n        elif action == 'signed_url':\n            blob_name = input_data['blob_name']\n            expiration = input_data.get('expiration', 3600)\n\n            blob = bucket.blob(blob_name)\n            url = blob.generate_signed_url(expiration=expiration)\n\n            result = {\n                'url': url,\n                'expires_in': expiration\n            }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow gcs-uploader\n  agent gcs-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/gcs-client.py\"\n    dependencies: [\"google-cloud-storage==2.14.0\"]\n  }\n\n  gcs-client(\n    credentials_path=\"/path/to/credentials.json\",\n    bucket=\"my-bucket\",\n    action=\"upload\",\n    local_path=\"/data/file.pdf\",\n    blob_name=\"uploads/file.pdf\"\n  )\nend\n```\n\n**Input**:\n- `credentials_path` (string): Path to GCP credentials JSON\n- `bucket` (string): GCS bucket name\n- `action` (string): \"upload\", \"download\", \"list\", \"delete\", \"signed_url\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"uploaded\": \"uploads/file.pdf\",\n  \"bucket\": \"my-bucket\",\n  \"size_bytes\": 524288,\n  \"url\": \"https://storage.googleapis.com/my-bucket/uploads/file.pdf\"\n}\n```\n\n---\n\n### Azure Blob Storage\n\n**Purpose**: Manage files in Azure Blob Storage containers\n\n**Language**: Python\n\n**Dependencies**:\n```\nazure-storage-blob==12.19.0\n```\n\n**Code**:\n```python\nfrom azure.storage.blob import BlobServiceClient\nimport json\nimport sys\nimport os\n\ndef main():\n    input_data = json.loads(sys.stdin.read())\n\n    connection_string = input_data['connection_string']\n    container_name = input_data['container']\n    action = input_data['action']\n\n    try:\n        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n        container_client = blob_service_client.get_container_client(container_name)\n\n        result = {}\n\n        if action == 'upload':\n            local_path = input_data['local_path']\n            blob_name = input_data['blob_name']\n\n            blob_client = container_client.get_blob_client(blob_name)\n\n            with open(local_path, 'rb') as data:\n                blob_client.upload_blob(data, overwrite=True)\n\n            result = {\n                'uploaded': blob_name,\n                'container': container_name,\n                'size_bytes': os.path.getsize(local_path),\n                'url': blob_client.url\n            }\n\n        elif action == 'download':\n            blob_name = input_data['blob_name']\n            local_path = input_data['local_path']\n\n            blob_client = container_client.get_blob_client(blob_name)\n\n            with open(local_path, 'wb') as download_file:\n                download_file.write(blob_client.download_blob().readall())\n\n            result = {\n                'downloaded': blob_name,\n                'local_path': local_path,\n                'size_bytes': os.path.getsize(local_path)\n            }\n\n        elif action == 'list':\n            prefix = input_data.get('prefix', '')\n            max_results = input_data.get('max_results', 1000)\n\n            blobs = container_client.list_blobs(name_starts_with=prefix)\n\n            files = []\n            for i, blob in enumerate(blobs):\n                if i >= max_results:\n                    break\n                files.append({\n                    'name': blob.name,\n                    'size': blob.size,\n                    'last_modified': blob.last_modified.isoformat()\n                })\n\n            result = {\n                'files': files,\n                'count': len(files)\n            }\n\n        elif action == 'delete':\n            blob_name = input_data['blob_name']\n\n            blob_client = container_client.get_blob_client(blob_name)\n            blob_client.delete_blob()\n\n            result = {\n                'deleted': blob_name,\n                'success': True\n            }\n\n        print(json.dumps(result))\n\n    except Exception as e:\n        print(json.dumps({'error': str(e)}), file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage in Workflow**:\n```flow\nworkflow azure-uploader\n  agent azure-blob-client {\n    type: temp-script\n    language: python\n    script: \"./scripts/azure-blob-client.py\"\n    dependencies: [\"azure-storage-blob==12.19.0\"]\n  }\n\n  azure-blob-client(\n    connection_string=\"DefaultEndpointsProtocol=https;...\",\n    container=\"my-container\",\n    action=\"upload\",\n    local_path=\"/data/file.pdf\",\n    blob_name=\"uploads/file.pdf\"\n  )\nend\n```\n\n**Input**:\n- `connection_string` (string): Azure Storage connection string\n- `container` (string): Container name\n- `action` (string): \"upload\", \"download\", \"list\", \"delete\"\n- Action-specific parameters\n\n**Output**:\n```json\n{\n  \"uploaded\": \"uploads/file.pdf\",\n  \"container\": \"my-container\",\n  \"size_bytes\": 524288,\n  \"url\": \"https://account.blob.core.windows.net/my-container/uploads/file.pdf\"\n}\n```\n\n---\n\n## Usage Tips\n\n### Template Selection\n- Choose the appropriate language based on your environment and dependencies\n- Python templates are great for data processing and ML tasks\n- Node.js templates excel at API interactions and async operations\n\n### Error Handling\n- All templates include comprehensive error handling\n- Errors are returned as JSON to stderr with exit code 1\n- Check the `error` field in the output for troubleshooting\n\n### Customization\n- Templates are starting points - modify them for your needs\n- Add authentication, retries, rate limiting as needed\n- Combine multiple templates in a single workflow\n\n### Best Practices\n- Use environment variables for sensitive credentials\n- Implement proper timeout handling for long operations\n- Add logging for debugging complex workflows\n- Test scripts locally before using in workflows\n\n---\n\n## Contributing\n\nTo add new templates:\n1. Follow the same structure as existing templates\n2. Include complete working code with error handling\n3. Provide clear usage examples\n4. Document all input parameters and output formats\n5. Specify exact dependency versions\n",
        "skills/managing-temp-scripts/security.md": "# Security Best Practices for Temporary Scripts\n\n## Security Overview\n\nTemporary scripts pose unique security challenges because they:\n- Often handle sensitive data (API keys, credentials, user data)\n- Execute with the same privileges as the parent process\n- May be automatically deleted, making post-incident analysis difficult\n- Are frequently created on-the-fly, bypassing normal code review processes\n- Can introduce vulnerabilities if not properly secured\n\n**Key Principle**: Treat temporary scripts with the same security rigor as production code, even if they only run once.\n\n## Credential Management\n\n### Passing API Keys Safely\n\n**Never hardcode credentials in script files:**\n\n```python\n# BAD - Hardcoded credentials\nAPI_KEY = \"sk-1234567890abcdef\"\n\n# GOOD - Environment variable\nimport os\nAPI_KEY = os.environ.get('API_KEY')\nif not API_KEY:\n    raise ValueError(\"API_KEY environment variable required\")\n```\n\n**Preferred methods (from most to least secure):**\n\n1. **System Keychain** (most secure for local development)\n2. **Environment variables** (good for temporary use)\n3. **Encrypted files** (when persistence is needed)\n4. **Command-line arguments** (least secure, visible in process lists)\n\n### Using System Keychain\n\n```python\n# Secure credential storage using keyring\nimport keyring\n\n# Store credential (one-time setup)\nkeyring.set_password(\"my_service\", \"api_key\", \"sk-1234567890\")\n\n# Retrieve in script\napi_key = keyring.get_password(\"my_service\", \"api_key\")\nif not api_key:\n    raise ValueError(\"API key not found in keychain\")\n```\n\n### Encrypting Sensitive Data\n\n```python\nfrom cryptography.fernet import Fernet\nimport os\n\ndef encrypt_credential(credential, key_file=\".key\"):\n    \"\"\"Encrypt credential and save key\"\"\"\n    key = Fernet.generate_key()\n    f = Fernet(key)\n    encrypted = f.encrypt(credential.encode())\n\n    # Save key with restrictive permissions\n    with open(key_file, 'wb') as kf:\n        kf.write(key)\n    os.chmod(key_file, 0o600)\n\n    return encrypted\n\ndef decrypt_credential(encrypted, key_file=\".key\"):\n    \"\"\"Decrypt credential\"\"\"\n    with open(key_file, 'rb') as kf:\n        key = kf.read()\n    f = Fernet(key)\n    return f.decrypt(encrypted).decode()\n```\n\n### Avoiding Hardcoded Credentials\n\n**Bad practices:**\n```python\n# Visible in code\nPASSWORD = \"mysecret123\"\n\n# Visible in version control\nconfig = {\"api_key\": \"sk-1234\"}\n\n# Visible in logs\nprint(f\"Using API key: {api_key}\")\n```\n\n**Good practices:**\n```python\n# Load from secure source\nimport os\nPASSWORD = os.environ.get('PASSWORD')\n\n# Use configuration files with .gitignore\nimport json\nwith open('.credentials.json') as f:\n    config = json.load(f)\n\n# Redact in logs\nprint(f\"Using API key: {api_key[:8]}...\")\n```\n\n### Credential Cleanup\n\n```python\nimport os\nimport gc\n\ndef cleanup_credentials():\n    \"\"\"Securely cleanup credentials after use\"\"\"\n    # Clear environment variables\n    for var in ['API_KEY', 'PASSWORD', 'TOKEN']:\n        if var in os.environ:\n            os.environ[var] = ''\n            del os.environ[var]\n\n    # Force garbage collection\n    gc.collect()\n\n    # Delete credential files\n    for cred_file in ['.credentials.json', '.key']:\n        if os.path.exists(cred_file):\n            # Overwrite before deletion\n            with open(cred_file, 'wb') as f:\n                f.write(os.urandom(os.path.getsize(cred_file)))\n            os.remove(cred_file)\n```\n\n## File Permissions\n\n### Setting Restrictive Permissions\n\n```bash\n# Scripts should be executable only by owner\nchmod 700 script.py  # rwx------\n\n# Data files should be readable/writable only by owner\nchmod 600 data.json  # rw-------\n\n# Temporary directories\nchmod 700 temp_dir/  # rwx------\n```\n\n```python\nimport os\nimport stat\n\n# Set permissions when creating files\ndef create_secure_file(filepath, content):\n    \"\"\"Create file with secure permissions\"\"\"\n    # Create file\n    with open(filepath, 'w') as f:\n        f.write(content)\n\n    # Set restrictive permissions (owner read/write only)\n    os.chmod(filepath, stat.S_IRUSR | stat.S_IWUSR)  # 600\n\n# Set permissions when creating directories\ndef create_secure_dir(dirpath):\n    \"\"\"Create directory with secure permissions\"\"\"\n    os.makedirs(dirpath, mode=0o700, exist_ok=True)\n```\n\n### Temp Directory Security\n\n```python\nimport tempfile\nimport os\nimport shutil\n\ndef create_secure_temp_dir():\n    \"\"\"Create secure temporary directory\"\"\"\n    # Create with secure permissions\n    temp_dir = tempfile.mkdtemp(prefix='secure_')\n    os.chmod(temp_dir, 0o700)\n\n    return temp_dir\n\ndef secure_temp_file():\n    \"\"\"Create secure temporary file\"\"\"\n    # mkstemp creates file with 600 permissions by default\n    fd, path = tempfile.mkstemp(prefix='secure_', suffix='.dat')\n    os.close(fd)\n    return path\n```\n\n## Input Validation\n\n### Validating User Input\n\n```python\nimport re\nimport os.path\n\ndef validate_filename(filename):\n    \"\"\"Validate filename to prevent path traversal\"\"\"\n    # Check for path traversal attempts\n    if '..' in filename or filename.startswith('/'):\n        raise ValueError(\"Invalid filename: path traversal detected\")\n\n    # Allow only alphanumeric, dash, underscore, dot\n    if not re.match(r'^[a-zA-Z0-9._-]+$', filename):\n        raise ValueError(\"Invalid filename: contains illegal characters\")\n\n    return filename\n\ndef validate_email(email):\n    \"\"\"Validate email format\"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    if not re.match(pattern, email):\n        raise ValueError(\"Invalid email format\")\n    return email\n\ndef validate_number(value, min_val=None, max_val=None):\n    \"\"\"Validate numeric input with bounds\"\"\"\n    try:\n        num = float(value)\n    except (ValueError, TypeError):\n        raise ValueError(\"Invalid number format\")\n\n    if min_val is not None and num < min_val:\n        raise ValueError(f\"Value must be >= {min_val}\")\n    if max_val is not None and num > max_val:\n        raise ValueError(f\"Value must be <= {max_val}\")\n\n    return num\n```\n\n### Sanitizing Command-Line Arguments\n\n```python\nimport shlex\nimport subprocess\n\ndef safe_command_execution(user_input):\n    \"\"\"Safely execute command with user input\"\"\"\n    # BAD - Command injection vulnerability\n    # os.system(f\"process {user_input}\")\n\n    # GOOD - Use list form with validated input\n    allowed_commands = {'list', 'show', 'export'}\n    if user_input not in allowed_commands:\n        raise ValueError(f\"Invalid command: {user_input}\")\n\n    subprocess.run(['process', user_input], check=True)\n\ndef sanitize_shell_arg(arg):\n    \"\"\"Sanitize argument for shell command\"\"\"\n    # Use shlex.quote to escape special characters\n    return shlex.quote(str(arg))\n```\n\n### Preventing Injection Attacks\n\n```python\nimport sqlite3\n\ndef safe_database_query(user_id):\n    \"\"\"Safe database query preventing SQL injection\"\"\"\n    # BAD - SQL injection vulnerability\n    # cursor.execute(f\"SELECT * FROM users WHERE id = {user_id}\")\n\n    # GOOD - Use parameterized queries\n    conn = sqlite3.connect('database.db')\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,))\n    return cursor.fetchall()\n\ndef safe_template_rendering(template, user_data):\n    \"\"\"Safe template rendering preventing XSS\"\"\"\n    import html\n\n    # Escape all user data\n    safe_data = {k: html.escape(str(v)) for k, v in user_data.items()}\n\n    return template.format(**safe_data)\n```\n\n### Input Whitelisting\n\n```python\ndef validate_with_whitelist(value, allowed_values):\n    \"\"\"Validate input against whitelist\"\"\"\n    if value not in allowed_values:\n        raise ValueError(f\"Invalid value. Allowed: {allowed_values}\")\n    return value\n\n# Example usage\nALLOWED_FORMATS = {'json', 'csv', 'xml'}\noutput_format = validate_with_whitelist(user_input, ALLOWED_FORMATS)\n\nALLOWED_ACTIONS = {'create', 'read', 'update', 'delete'}\naction = validate_with_whitelist(user_action, ALLOWED_ACTIONS)\n```\n\n## Output Sanitization\n\n### Validating Script Output\n\n```python\nimport json\n\ndef validate_json_output(output):\n    \"\"\"Validate that output is valid JSON\"\"\"\n    try:\n        data = json.loads(output)\n        return data\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON output: {e}\")\n\ndef validate_output_structure(data, expected_keys):\n    \"\"\"Validate output has expected structure\"\"\"\n    if not isinstance(data, dict):\n        raise ValueError(\"Output must be a dictionary\")\n\n    missing_keys = set(expected_keys) - set(data.keys())\n    if missing_keys:\n        raise ValueError(f\"Missing required keys: {missing_keys}\")\n\n    return data\n```\n\n### Limiting Output Size\n\n```python\ndef limit_output_size(output, max_bytes=1_000_000):\n    \"\"\"Limit output size to prevent memory exhaustion\"\"\"\n    if len(output) > max_bytes:\n        raise ValueError(f\"Output exceeds {max_bytes} bytes\")\n    return output\n\ndef truncate_output(output, max_lines=1000):\n    \"\"\"Truncate output to maximum number of lines\"\"\"\n    lines = output.split('\\n')\n    if len(lines) > max_lines:\n        truncated = '\\n'.join(lines[:max_lines])\n        return truncated + f\"\\n... (truncated {len(lines) - max_lines} lines)\"\n    return output\n```\n\n### Escaping Special Characters\n\n```python\nimport html\nimport re\n\ndef escape_html(text):\n    \"\"\"Escape HTML special characters\"\"\"\n    return html.escape(text)\n\ndef escape_shell_output(text):\n    \"\"\"Remove potentially dangerous characters from shell output\"\"\"\n    # Remove control characters except newline and tab\n    return re.sub(r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]', '', text)\n\ndef sanitize_log_output(text):\n    \"\"\"Sanitize text for safe logging\"\"\"\n    # Remove ANSI escape codes\n    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n    return ansi_escape.sub('', text)\n```\n\n### Removing Sensitive Data from Output\n\n```python\nimport re\n\ndef redact_sensitive_data(text):\n    \"\"\"Redact sensitive data from output\"\"\"\n    # Redact email addresses\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n                  '[EMAIL REDACTED]', text)\n\n    # Redact API keys (common patterns)\n    text = re.sub(r'sk-[a-zA-Z0-9]{32,}', '[API_KEY REDACTED]', text)\n    text = re.sub(r'Bearer [a-zA-Z0-9._-]+', 'Bearer [TOKEN REDACTED]', text)\n\n    # Redact credit card numbers\n    text = re.sub(r'\\b\\d{4}[- ]?\\d{4}[- ]?\\d{4}[- ]?\\d{4}\\b',\n                  '[CARD REDACTED]', text)\n\n    # Redact IP addresses\n    text = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b',\n                  '[IP REDACTED]', text)\n\n    return text\n```\n\n## Dependency Security\n\n### Using Virtual Environments\n\n```bash\n# Always use virtual environments for isolation\npython -m venv .venv\nsource .venv/bin/activate  # Linux/Mac\n# .venv\\Scripts\\activate  # Windows\n\n# Install dependencies\npip install -r requirements.txt\n\n# Deactivate when done\ndeactivate\n```\n\n```python\n# Check if running in virtual environment\nimport sys\n\ndef ensure_virtualenv():\n    \"\"\"Ensure script runs in virtual environment\"\"\"\n    if not hasattr(sys, 'real_prefix') and not hasattr(sys, 'base_prefix'):\n        raise RuntimeError(\"Script must run in virtual environment\")\n\n    if sys.prefix == sys.base_prefix:\n        raise RuntimeError(\"Script must run in virtual environment\")\n```\n\n### Pinning Exact Versions\n\n```txt\n# requirements.txt - Pin exact versions\nrequests==2.31.0\ncryptography==41.0.7\nkeyring==24.3.0\n\n# NOT this - allows any version\n# requests\n# cryptography\n# keyring\n```\n\n```bash\n# Generate requirements.txt with pinned versions\npip freeze > requirements.txt\n\n# Install exact versions\npip install -r requirements.txt\n```\n\n### Checking for Vulnerabilities\n\n```bash\n# Python - Use pip-audit\npip install pip-audit\npip-audit\n\n# Or use safety\npip install safety\nsafety check\n\n# Node.js - Use npm audit\nnpm audit\n\n# Fix vulnerabilities automatically\nnpm audit fix\n```\n\n```python\n# Automate vulnerability checking in script\nimport subprocess\nimport sys\n\ndef check_dependencies():\n    \"\"\"Check dependencies for vulnerabilities before execution\"\"\"\n    try:\n        result = subprocess.run(\n            ['pip-audit', '--strict'],\n            capture_output=True,\n            text=True,\n            check=False\n        )\n\n        if result.returncode != 0:\n            print(\"WARNING: Vulnerabilities found in dependencies:\")\n            print(result.stdout)\n            response = input(\"Continue anyway? (yes/no): \")\n            if response.lower() != 'yes':\n                sys.exit(1)\n    except FileNotFoundError:\n        print(\"pip-audit not installed. Install with: pip install pip-audit\")\n```\n\n### Avoiding Global Package Installations\n\n```bash\n# BAD - Installs globally, affects system\npip install package\n\n# GOOD - Install in virtual environment\npython -m venv .venv\nsource .venv/bin/activate\npip install package\n\n# BETTER - Use pipx for CLI tools\npipx install package\n```\n\n## Execution Security\n\n### Running with Minimal Privileges\n\n```python\nimport os\nimport pwd\nimport grp\n\ndef drop_privileges(user='nobody', group='nogroup'):\n    \"\"\"Drop to lower privilege user (Unix only)\"\"\"\n    if os.getuid() != 0:\n        # Not running as root, no need to drop privileges\n        return\n\n    # Get the uid/gid from the name\n    running_uid = pwd.getpwnam(user).pw_uid\n    running_gid = grp.getgrnam(group).gr_gid\n\n    # Remove group privileges\n    os.setgroups([])\n\n    # Try setting the new uid/gid\n    os.setgid(running_gid)\n    os.setuid(running_uid)\n\n    # Ensure a reasonable umask\n    os.umask(0o077)\n```\n\n### Using Timeouts\n\n```python\nimport subprocess\nimport signal\nfrom contextlib import contextmanager\n\ndef run_with_timeout(command, timeout=30):\n    \"\"\"Execute command with timeout\"\"\"\n    try:\n        result = subprocess.run(\n            command,\n            timeout=timeout,\n            capture_output=True,\n            text=True,\n            check=True\n        )\n        return result.stdout\n    except subprocess.TimeoutExpired:\n        raise RuntimeError(f\"Command timed out after {timeout} seconds\")\n\n@contextmanager\ndef time_limit(seconds):\n    \"\"\"Context manager for time limits\"\"\"\n    def signal_handler(signum, frame):\n        raise TimeoutError(f\"Timed out after {seconds} seconds\")\n\n    signal.signal(signal.SIGALRM, signal_handler)\n    signal.alarm(seconds)\n    try:\n        yield\n    finally:\n        signal.alarm(0)\n\n# Usage\ntry:\n    with time_limit(10):\n        # Your code here\n        slow_operation()\nexcept TimeoutError as e:\n    print(f\"Operation timed out: {e}\")\n```\n\n### Sandboxing with Docker\n\n```dockerfile\n# Dockerfile for sandboxed script execution\nFROM python:3.11-slim\n\n# Create non-root user\nRUN useradd -m -u 1000 scriptuser\n\n# Set working directory\nWORKDIR /app\n\n# Copy requirements and install\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy script\nCOPY script.py .\n\n# Switch to non-root user\nUSER scriptuser\n\n# Set resource limits in docker-compose or run command\nCMD [\"python\", \"script.py\"]\n```\n\n```bash\n# Run with resource limits\ndocker run --rm \\\n  --memory=\"256m\" \\\n  --cpus=\"0.5\" \\\n  --network=\"none\" \\\n  --read-only \\\n  --tmpfs /tmp \\\n  my-script\n```\n\n### Resource Limits\n\n```python\nimport resource\n\ndef set_resource_limits():\n    \"\"\"Set resource limits for script execution\"\"\"\n    # Limit CPU time (seconds)\n    resource.setrlimit(resource.RLIMIT_CPU, (60, 60))\n\n    # Limit memory (bytes) - 256MB\n    resource.setrlimit(resource.RLIMIT_AS, (256 * 1024 * 1024, 256 * 1024 * 1024))\n\n    # Limit file size (bytes) - 10MB\n    resource.setrlimit(resource.RLIMIT_FSIZE, (10 * 1024 * 1024, 10 * 1024 * 1024))\n\n    # Limit number of open files\n    resource.setrlimit(resource.RLIMIT_NOFILE, (100, 100))\n```\n\n## Network Security\n\n### HTTPS Only for API Calls\n\n```python\nimport requests\nfrom urllib.parse import urlparse\n\ndef validate_https_url(url):\n    \"\"\"Ensure URL uses HTTPS\"\"\"\n    parsed = urlparse(url)\n    if parsed.scheme != 'https':\n        raise ValueError(f\"Only HTTPS URLs allowed, got: {parsed.scheme}\")\n    return url\n\ndef secure_api_call(url, **kwargs):\n    \"\"\"Make API call with security checks\"\"\"\n    # Validate HTTPS\n    validate_https_url(url)\n\n    # Enforce certificate verification\n    kwargs['verify'] = True\n\n    # Set timeout to prevent hanging\n    kwargs.setdefault('timeout', 30)\n\n    response = requests.get(url, **kwargs)\n    response.raise_for_status()\n\n    return response.json()\n```\n\n### Certificate Verification\n\n```python\nimport requests\nimport certifi\n\ndef api_call_with_cert_verification(url):\n    \"\"\"API call with explicit certificate verification\"\"\"\n    # Use certifi's certificate bundle\n    response = requests.get(\n        url,\n        verify=certifi.where(),  # Explicit cert bundle\n        timeout=30\n    )\n    return response\n\n# NEVER do this in production\ndef insecure_call(url):\n    \"\"\"Example of what NOT to do\"\"\"\n    # BAD - Disables certificate verification\n    # response = requests.get(url, verify=False)\n    pass\n```\n\n### Rate Limiting\n\n```python\nimport time\nfrom functools import wraps\nfrom collections import deque\n\nclass RateLimiter:\n    \"\"\"Simple rate limiter\"\"\"\n    def __init__(self, max_calls, period):\n        self.max_calls = max_calls\n        self.period = period\n        self.calls = deque()\n\n    def __call__(self, func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            now = time.time()\n\n            # Remove old calls outside the period\n            while self.calls and self.calls[0] < now - self.period:\n                self.calls.popleft()\n\n            # Check if we've exceeded rate limit\n            if len(self.calls) >= self.max_calls:\n                sleep_time = self.period - (now - self.calls[0])\n                if sleep_time > 0:\n                    time.sleep(sleep_time)\n                    self.calls.popleft()\n\n            # Record this call\n            self.calls.append(time.time())\n\n            return func(*args, **kwargs)\n        return wrapper\n\n# Usage: max 10 calls per minute\n@RateLimiter(max_calls=10, period=60)\ndef api_call(endpoint):\n    return requests.get(endpoint)\n```\n\n### Proxy Configuration\n\n```python\nimport os\nimport requests\n\ndef get_proxy_config():\n    \"\"\"Get proxy configuration from environment\"\"\"\n    proxies = {}\n\n    http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')\n    https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')\n\n    if http_proxy:\n        proxies['http'] = http_proxy\n    if https_proxy:\n        proxies['https'] = https_proxy\n\n    return proxies\n\ndef api_call_with_proxy(url):\n    \"\"\"Make API call respecting proxy settings\"\"\"\n    proxies = get_proxy_config()\n    response = requests.get(url, proxies=proxies, timeout=30)\n    return response\n```\n\n## Cleanup Security\n\n### Secure File Deletion\n\n```python\nimport os\nimport shutil\n\ndef secure_delete_file(filepath, passes=3):\n    \"\"\"Securely delete file by overwriting before removal\"\"\"\n    if not os.path.exists(filepath):\n        return\n\n    file_size = os.path.getsize(filepath)\n\n    # Overwrite file multiple times\n    with open(filepath, 'wb') as f:\n        for _ in range(passes):\n            f.seek(0)\n            f.write(os.urandom(file_size))\n            f.flush()\n            os.fsync(f.fileno())\n\n    # Finally remove the file\n    os.remove(filepath)\n\ndef secure_delete_directory(dirpath):\n    \"\"\"Securely delete directory and all contents\"\"\"\n    if not os.path.exists(dirpath):\n        return\n\n    # Walk through and securely delete all files\n    for root, dirs, files in os.walk(dirpath, topdown=False):\n        for name in files:\n            secure_delete_file(os.path.join(root, name))\n        for name in dirs:\n            os.rmdir(os.path.join(root, name))\n\n    # Remove the directory itself\n    os.rmdir(dirpath)\n```\n\n### Memory Cleanup\n\n```python\nimport gc\nimport ctypes\n\ndef secure_string_cleanup(sensitive_str):\n    \"\"\"Attempt to clear sensitive string from memory\"\"\"\n    # Python strings are immutable, but we can try to clear references\n    # This is not guaranteed to work in all cases\n\n    # Get the memory address\n    str_addr = id(sensitive_str)\n\n    # Overwrite the string object's data\n    # WARNING: This is CPython-specific and dangerous\n    try:\n        # Zero out the string data\n        ctypes.memset(str_addr, 0, len(sensitive_str))\n    except:\n        pass\n\n    # Delete reference and force garbage collection\n    del sensitive_str\n    gc.collect()\n\ndef cleanup_sensitive_variables(*var_names):\n    \"\"\"Cleanup sensitive variables from local scope\"\"\"\n    import sys\n\n    frame = sys._getframe(1)\n    for var_name in var_names:\n        if var_name in frame.f_locals:\n            del frame.f_locals[var_name]\n\n    gc.collect()\n```\n\n### Log Sanitization\n\n```python\nimport re\nimport logging\n\nclass SanitizingFormatter(logging.Formatter):\n    \"\"\"Custom formatter that sanitizes sensitive data\"\"\"\n\n    PATTERNS = [\n        (re.compile(r'sk-[a-zA-Z0-9]{32,}'), '[API_KEY]'),\n        (re.compile(r'Bearer [a-zA-Z0-9._-]+'), 'Bearer [TOKEN]'),\n        (re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'), '[EMAIL]'),\n        (re.compile(r'\\b\\d{4}[- ]?\\d{4}[- ]?\\d{4}[- ]?\\d{4}\\b'), '[CARD]'),\n    ]\n\n    def format(self, record):\n        # Format the message\n        msg = super().format(record)\n\n        # Apply sanitization patterns\n        for pattern, replacement in self.PATTERNS:\n            msg = pattern.sub(replacement, msg)\n\n        return msg\n\n# Setup sanitizing logger\ndef setup_secure_logging():\n    \"\"\"Setup logging with sanitization\"\"\"\n    handler = logging.StreamHandler()\n    handler.setFormatter(SanitizingFormatter('%(asctime)s - %(levelname)s - %(message)s'))\n\n    logger = logging.getLogger()\n    logger.addHandler(handler)\n    logger.setLevel(logging.INFO)\n\n    return logger\n```\n\n## Common Vulnerabilities\n\n### Command Injection\n\n**Vulnerability:**\n```python\n# UNSAFE - User input directly in shell command\nimport os\nuser_file = input(\"Enter filename: \")\nos.system(f\"cat {user_file}\")  # User can enter: \"file.txt; rm -rf /\"\n```\n\n**Prevention:**\n```python\n# SAFE - Use subprocess with list arguments\nimport subprocess\nuser_file = input(\"Enter filename: \")\n\n# Validate filename\nif '..' in user_file or '/' in user_file:\n    raise ValueError(\"Invalid filename\")\n\n# Use list form, not shell=True\nsubprocess.run(['cat', user_file], check=True)\n```\n\n### Path Traversal\n\n**Vulnerability:**\n```python\n# UNSAFE - User can access arbitrary files\nimport os\nfilename = input(\"Enter file: \")\nwith open(f\"/var/data/{filename}\") as f:  # User enters: \"../../etc/passwd\"\n    print(f.read())\n```\n\n**Prevention:**\n```python\n# SAFE - Validate and resolve path\nimport os\nfrom pathlib import Path\n\ndef safe_file_access(filename, base_dir=\"/var/data\"):\n    \"\"\"Safely access file within base directory\"\"\"\n    # Remove any path components\n    filename = os.path.basename(filename)\n\n    # Build full path\n    full_path = Path(base_dir) / filename\n\n    # Resolve to absolute path\n    resolved = full_path.resolve()\n\n    # Ensure it's within base directory\n    if not str(resolved).startswith(str(Path(base_dir).resolve())):\n        raise ValueError(\"Path traversal detected\")\n\n    return resolved\n```\n\n### Arbitrary Code Execution\n\n**Vulnerability:**\n```python\n# UNSAFE - Executing arbitrary code\nuser_code = input(\"Enter Python expression: \")\nresult = eval(user_code)  # User can enter: \"__import__('os').system('rm -rf /')\"\n```\n\n**Prevention:**\n```python\n# SAFE - Use ast.literal_eval for data only\nimport ast\n\nuser_code = input(\"Enter Python literal: \")\ntry:\n    # Only allows literals (strings, numbers, dicts, lists, etc.)\n    result = ast.literal_eval(user_code)\nexcept (ValueError, SyntaxError):\n    raise ValueError(\"Invalid literal expression\")\n\n# Or use a whitelist of safe operations\nSAFE_OPERATIONS = {'+', '-', '*', '/', '(', ')', ' ', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n\ndef is_safe_expression(expr):\n    \"\"\"Check if expression contains only safe characters\"\"\"\n    return all(c in SAFE_OPERATIONS for c in expr)\n```\n\n### Environment Variable Leakage\n\n**Vulnerability:**\n```python\n# UNSAFE - Exposing environment variables\nimport os\nprint(os.environ)  # Prints all environment variables including secrets\n\n# UNSAFE - Logging environment\nimport logging\nlogging.info(f\"Environment: {dict(os.environ)}\")\n```\n\n**Prevention:**\n```python\n# SAFE - Only access specific variables\nimport os\n\ndef get_safe_env_var(name, default=None):\n    \"\"\"Get environment variable safely\"\"\"\n    return os.environ.get(name, default)\n\n# SAFE - Sanitize environment before logging\nSAFE_ENV_VARS = {'PATH', 'HOME', 'USER', 'LANG'}\n\ndef get_safe_environment():\n    \"\"\"Get sanitized environment for logging\"\"\"\n    return {k: v for k, v in os.environ.items() if k in SAFE_ENV_VARS}\n\n# SAFE - Clear sensitive variables before subprocess\nimport subprocess\n\ndef run_subprocess_safely(command):\n    \"\"\"Run subprocess with sanitized environment\"\"\"\n    safe_env = get_safe_environment()\n    subprocess.run(command, env=safe_env, check=True)\n```\n\n## Security Checklist\n\n### Pre-Execution Checks\n\n```python\ndef pre_execution_security_check():\n    \"\"\"Run security checks before script execution\"\"\"\n    checks = []\n\n    # 1. Check file permissions\n    import os\n    import stat\n\n    script_path = __file__\n    st = os.stat(script_path)\n    if st.st_mode & stat.S_IWGRP or st.st_mode & stat.S_IWOTH:\n        checks.append(\"WARNING: Script is writable by group/others\")\n\n    # 2. Check for virtual environment\n    import sys\n    if sys.prefix == sys.base_prefix:\n        checks.append(\"WARNING: Not running in virtual environment\")\n\n    # 3. Check for required environment variables\n    required_vars = ['API_KEY']\n    for var in required_vars:\n        if var not in os.environ:\n            checks.append(f\"ERROR: Required environment variable {var} not set\")\n\n    # 4. Check dependencies for vulnerabilities (if pip-audit available)\n    try:\n        import subprocess\n        result = subprocess.run(['pip-audit', '--strict'],\n                              capture_output=True, check=False)\n        if result.returncode != 0:\n            checks.append(\"WARNING: Vulnerabilities found in dependencies\")\n    except FileNotFoundError:\n        checks.append(\"INFO: pip-audit not available for vulnerability check\")\n\n    # 5. Check write permissions on temp directory\n    import tempfile\n    temp_dir = tempfile.gettempdir()\n    if not os.access(temp_dir, os.W_OK):\n        checks.append(\"ERROR: No write permission on temp directory\")\n\n    return checks\n```\n\n### During Execution Monitoring\n\n```python\nimport time\nimport psutil\nimport os\n\nclass ExecutionMonitor:\n    \"\"\"Monitor script execution for security issues\"\"\"\n\n    def __init__(self, max_memory_mb=256, max_cpu_percent=50):\n        self.max_memory = max_memory_mb * 1024 * 1024\n        self.max_cpu = max_cpu_percent\n        self.start_time = time.time()\n        self.process = psutil.Process(os.getpid())\n\n    def check_resources(self):\n        \"\"\"Check if resource limits are exceeded\"\"\"\n        issues = []\n\n        # Check memory usage\n        mem_info = self.process.memory_info()\n        if mem_info.rss > self.max_memory:\n            issues.append(f\"Memory limit exceeded: {mem_info.rss / 1024 / 1024:.1f}MB\")\n\n        # Check CPU usage\n        cpu_percent = self.process.cpu_percent(interval=1)\n        if cpu_percent > self.max_cpu:\n            issues.append(f\"CPU limit exceeded: {cpu_percent:.1f}%\")\n\n        # Check for too many open files\n        num_fds = self.process.num_fds() if hasattr(self.process, 'num_fds') else 0\n        if num_fds > 100:\n            issues.append(f\"Too many open files: {num_fds}\")\n\n        return issues\n\n    def get_stats(self):\n        \"\"\"Get execution statistics\"\"\"\n        return {\n            'runtime': time.time() - self.start_time,\n            'memory_mb': self.process.memory_info().rss / 1024 / 1024,\n            'cpu_percent': self.process.cpu_percent(),\n        }\n```\n\n### Post-Execution Cleanup\n\n```python\ndef post_execution_cleanup():\n    \"\"\"Cleanup after script execution\"\"\"\n    import os\n    import tempfile\n    import shutil\n\n    cleanup_steps = []\n\n    # 1. Remove temporary files\n    temp_dir = tempfile.gettempdir()\n    temp_files = [f for f in os.listdir(temp_dir) if f.startswith('script_')]\n    for temp_file in temp_files:\n        try:\n            path = os.path.join(temp_dir, temp_file)\n            if os.path.isfile(path):\n                os.remove(path)\n            elif os.path.isdir(path):\n                shutil.rmtree(path)\n            cleanup_steps.append(f\"Removed: {temp_file}\")\n        except Exception as e:\n            cleanup_steps.append(f\"Failed to remove {temp_file}: {e}\")\n\n    # 2. Clear environment variables\n    sensitive_vars = ['API_KEY', 'PASSWORD', 'TOKEN']\n    for var in sensitive_vars:\n        if var in os.environ:\n            del os.environ[var]\n            cleanup_steps.append(f\"Cleared env var: {var}\")\n\n    # 3. Force garbage collection\n    import gc\n    gc.collect()\n    cleanup_steps.append(\"Forced garbage collection\")\n\n    # 4. Clear Python cache\n    import sys\n    if hasattr(sys, 'modules'):\n        # Remove imported modules (careful with this)\n        modules_to_remove = [m for m in sys.modules if m.startswith('temp_')]\n        for module in modules_to_remove:\n            del sys.modules[module]\n            cleanup_steps.append(f\"Removed module: {module}\")\n\n    return cleanup_steps\n```\n\n## Examples\n\n### Example 1: Secure API Client with Keyring\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nSecure API client using system keyring for credential storage\n\"\"\"\nimport keyring\nimport requests\nimport sys\nfrom urllib.parse import urlparse\n\nSERVICE_NAME = \"my_api_service\"\n\ndef get_api_key():\n    \"\"\"Retrieve API key from system keyring\"\"\"\n    api_key = keyring.get_password(SERVICE_NAME, \"api_key\")\n    if not api_key:\n        print(\"API key not found. Setting up...\")\n        api_key = input(\"Enter your API key: \")\n        keyring.set_password(SERVICE_NAME, \"api_key\", api_key)\n        print(\"API key stored securely in system keychain\")\n    return api_key\n\ndef validate_url(url):\n    \"\"\"Ensure URL is HTTPS\"\"\"\n    parsed = urlparse(url)\n    if parsed.scheme != 'https':\n        raise ValueError(\"Only HTTPS URLs are allowed\")\n    return url\n\ndef secure_api_call(endpoint, params=None):\n    \"\"\"Make secure API call\"\"\"\n    # Get credentials securely\n    api_key = get_api_key()\n\n    # Validate URL\n    url = validate_url(endpoint)\n\n    # Make request with security settings\n    headers = {'Authorization': f'Bearer {api_key}'}\n\n    try:\n        response = requests.get(\n            url,\n            headers=headers,\n            params=params,\n            timeout=30,\n            verify=True  # Enforce certificate verification\n        )\n        response.raise_for_status()\n        return response.json()\n    except requests.exceptions.RequestException as e:\n        print(f\"API call failed: {e}\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == '__main__':\n    try:\n        data = secure_api_call('https://api.example.com/data')\n        print(f\"Retrieved {len(data)} records\")\n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n```\n\n### Example 2: Sandboxed Data Processor\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nSandboxed data processor with resource limits\n\"\"\"\nimport os\nimport sys\nimport resource\nimport tempfile\nimport json\nfrom pathlib import Path\n\ndef set_resource_limits():\n    \"\"\"Set strict resource limits\"\"\"\n    # CPU time: 5 minutes\n    resource.setrlimit(resource.RLIMIT_CPU, (300, 300))\n\n    # Memory: 256MB\n    resource.setrlimit(resource.RLIMIT_AS, (256 * 1024 * 1024, 256 * 1024 * 1024))\n\n    # File size: 50MB\n    resource.setrlimit(resource.RLIMIT_FSIZE, (50 * 1024 * 1024, 50 * 1024 * 1024))\n\n    # Number of open files: 50\n    resource.setrlimit(resource.RLIMIT_NOFILE, (50, 50))\n\ndef validate_input_file(filepath, allowed_dir):\n    \"\"\"Validate input file is within allowed directory\"\"\"\n    # Resolve to absolute path\n    file_path = Path(filepath).resolve()\n    allowed_path = Path(allowed_dir).resolve()\n\n    # Check if file is within allowed directory\n    try:\n        file_path.relative_to(allowed_path)\n    except ValueError:\n        raise ValueError(f\"File must be within {allowed_dir}\")\n\n    # Check file size (max 10MB)\n    if file_path.stat().st_size > 10 * 1024 * 1024:\n        raise ValueError(\"File too large (max 10MB)\")\n\n    return file_path\n\ndef process_data(input_file, output_file):\n    \"\"\"Process data with security checks\"\"\"\n    # Validate input\n    safe_input = validate_input_file(input_file, '/tmp/safe_input')\n\n    # Read and validate JSON\n    with open(safe_input, 'r') as f:\n        data = json.load(f)\n\n    if not isinstance(data, list):\n        raise ValueError(\"Input must be a JSON array\")\n\n    # Process data (example: filter and transform)\n    processed = []\n    for item in data[:1000]:  # Limit to 1000 items\n        if isinstance(item, dict) and 'value' in item:\n            processed.append({\n                'value': item['value'],\n                'processed': True\n            })\n\n    # Write to secure temporary file\n    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:\n        json.dump(processed, f, indent=2)\n        temp_output = f.name\n\n    # Set secure permissions\n    os.chmod(temp_output, 0o600)\n\n    # Move to final location\n    os.rename(temp_output, output_file)\n\n    return len(processed)\n\nif __name__ == '__main__':\n    try:\n        # Set resource limits\n        set_resource_limits()\n\n        # Process data\n        if len(sys.argv) != 3:\n            print(\"Usage: processor.py <input.json> <output.json>\")\n            sys.exit(1)\n\n        count = process_data(sys.argv[1], sys.argv[2])\n        print(f\"Processed {count} items successfully\")\n\n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n```\n\n### Example 3: Secure Credential Passing\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nSecure credential passing using encrypted files\n\"\"\"\nimport os\nimport sys\nimport json\nfrom cryptography.fernet import Fernet\nfrom pathlib import Path\nimport stat\n\nclass SecureCredentials:\n    \"\"\"Manage encrypted credentials\"\"\"\n\n    def __init__(self, cred_dir='.credentials'):\n        self.cred_dir = Path(cred_dir)\n        self.key_file = self.cred_dir / '.key'\n        self.cred_file = self.cred_dir / 'credentials.enc'\n        self._ensure_directory()\n\n    def _ensure_directory(self):\n        \"\"\"Create credentials directory with secure permissions\"\"\"\n        self.cred_dir.mkdir(mode=0o700, exist_ok=True)\n\n    def _get_or_create_key(self):\n        \"\"\"Get encryption key or create new one\"\"\"\n        if self.key_file.exists():\n            with open(self.key_file, 'rb') as f:\n                return f.read()\n        else:\n            key = Fernet.generate_key()\n            with open(self.key_file, 'wb') as f:\n                f.write(key)\n            os.chmod(self.key_file, stat.S_IRUSR | stat.S_IWUSR)  # 600\n            return key\n\n    def store(self, credentials):\n        \"\"\"Store credentials encrypted\"\"\"\n        key = self._get_or_create_key()\n        f = Fernet(key)\n\n        # Encrypt credentials\n        data = json.dumps(credentials).encode()\n        encrypted = f.encrypt(data)\n\n        # Write encrypted data\n        with open(self.cred_file, 'wb') as file:\n            file.write(encrypted)\n        os.chmod(self.cred_file, stat.S_IRUSR | stat.S_IWUSR)  # 600\n\n    def retrieve(self):\n        \"\"\"Retrieve and decrypt credentials\"\"\"\n        if not self.cred_file.exists():\n            raise ValueError(\"No credentials stored\")\n\n        key = self._get_or_create_key()\n        f = Fernet(key)\n\n        # Read and decrypt\n        with open(self.cred_file, 'rb') as file:\n            encrypted = file.read()\n\n        decrypted = f.decrypt(encrypted)\n        return json.loads(decrypted.decode())\n\n    def cleanup(self):\n        \"\"\"Securely delete credentials\"\"\"\n        for file in [self.cred_file, self.key_file]:\n            if file.exists():\n                # Overwrite with random data\n                file_size = file.stat().st_size\n                with open(file, 'wb') as f:\n                    f.write(os.urandom(file_size))\n                file.unlink()\n\n# Usage example\nif __name__ == '__main__':\n    creds = SecureCredentials()\n\n    # Store credentials\n    creds.store({\n        'api_key': 'sk-1234567890',\n        'username': 'user@example.com'\n    })\n\n    # Retrieve credentials\n    retrieved = creds.retrieve()\n    print(f\"Retrieved credentials for: {retrieved['username']}\")\n\n    # Cleanup when done\n    creds.cleanup()\n```\n\n### Example 4: Safe Output Handling\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nSafe output handling with sanitization and size limits\n\"\"\"\nimport re\nimport sys\nfrom io import StringIO\n\nclass SafeOutput:\n    \"\"\"Handle output with security controls\"\"\"\n\n    def __init__(self, max_size=1_000_000, redact=True):\n        self.max_size = max_size\n        self.redact = redact\n        self.buffer = StringIO()\n        self.size = 0\n\n    def write(self, text):\n        \"\"\"Write text with size checking and sanitization\"\"\"\n        # Sanitize if enabled\n        if self.redact:\n            text = self._redact_sensitive(text)\n\n        # Check size limit\n        text_size = len(text.encode('utf-8'))\n        if self.size + text_size > self.max_size:\n            raise ValueError(f\"Output size limit ({self.max_size} bytes) exceeded\")\n\n        self.buffer.write(text)\n        self.size += text_size\n\n    def _redact_sensitive(self, text):\n        \"\"\"Redact sensitive information\"\"\"\n        # Redact email addresses\n        text = re.sub(\n            r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n            '[EMAIL]',\n            text\n        )\n\n        # Redact API keys\n        text = re.sub(r'sk-[a-zA-Z0-9]{32,}', '[API_KEY]', text)\n        text = re.sub(r'Bearer [a-zA-Z0-9._-]+', 'Bearer [TOKEN]', text)\n\n        # Redact IP addresses\n        text = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', '[IP]', text)\n\n        # Redact potential passwords (password= or pwd=)\n        text = re.sub(\n            r'(password|pwd|pass)\\s*=\\s*[^\\s&]+',\n            r'\\1=[REDACTED]',\n            text,\n            flags=re.IGNORECASE\n        )\n\n        return text\n\n    def get_output(self):\n        \"\"\"Get the buffered output\"\"\"\n        return self.buffer.getvalue()\n\n    def flush_to_file(self, filepath):\n        \"\"\"Write output to file with secure permissions\"\"\"\n        import os\n\n        with open(filepath, 'w') as f:\n            f.write(self.get_output())\n\n        # Set secure permissions\n        os.chmod(filepath, 0o600)\n\n# Usage example\nif __name__ == '__main__':\n    output = SafeOutput(max_size=10_000, redact=True)\n\n    try:\n        # Write various outputs\n        output.write(\"Processing user: user@example.com\\n\")\n        output.write(\"API Key: sk-1234567890abcdef\\n\")\n        output.write(\"Server IP: 192.168.1.1\\n\")\n        output.write(\"Password: secret123\\n\")\n\n        # Get sanitized output\n        print(\"=== Sanitized Output ===\")\n        print(output.get_output())\n\n    except ValueError as e:\n        print(f\"Output error: {e}\", file=sys.stderr)\n```\n\n### Example 5: Encrypted Storage\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nEncrypted storage for temporary data\n\"\"\"\nimport os\nimport json\nimport tempfile\nfrom pathlib import Path\nfrom cryptography.fernet import Fernet\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2\nfrom cryptography.hazmat.backends import default_backend\nimport getpass\n\nclass EncryptedStorage:\n    \"\"\"Encrypted file storage with password\"\"\"\n\n    def __init__(self, storage_dir=None):\n        if storage_dir is None:\n            storage_dir = tempfile.mkdtemp(prefix='secure_')\n\n        self.storage_dir = Path(storage_dir)\n        self.storage_dir.mkdir(mode=0o700, exist_ok=True)\n        self._password = None\n        self._fernet = None\n\n    def _derive_key(self, password, salt):\n        \"\"\"Derive encryption key from password\"\"\"\n        kdf = PBKDF2(\n            algorithm=hashes.SHA256(),\n            length=32,\n            salt=salt,\n            iterations=100000,\n            backend=default_backend()\n        )\n        return kdf.derive(password.encode())\n\n    def _get_fernet(self):\n        \"\"\"Get Fernet instance with derived key\"\"\"\n        if self._fernet is None:\n            if self._password is None:\n                self._password = getpass.getpass(\"Enter encryption password: \")\n\n            # Generate or load salt\n            salt_file = self.storage_dir / '.salt'\n            if salt_file.exists():\n                with open(salt_file, 'rb') as f:\n                    salt = f.read()\n            else:\n                salt = os.urandom(16)\n                with open(salt_file, 'wb') as f:\n                    f.write(salt)\n                os.chmod(salt_file, 0o600)\n\n            # Derive key\n            key = self._derive_key(self._password, salt)\n            self._fernet = Fernet(key)\n\n        return self._fernet\n\n    def store(self, name, data):\n        \"\"\"Store data encrypted\"\"\"\n        f = self._get_fernet()\n\n        # Convert data to JSON\n        json_data = json.dumps(data).encode()\n\n        # Encrypt\n        encrypted = f.encrypt(json_data)\n\n        # Write to file\n        file_path = self.storage_dir / f\"{name}.enc\"\n        with open(file_path, 'wb') as file:\n            file.write(encrypted)\n\n        # Set secure permissions\n        os.chmod(file_path, 0o600)\n\n    def retrieve(self, name):\n        \"\"\"Retrieve and decrypt data\"\"\"\n        f = self._get_fernet()\n\n        file_path = self.storage_dir / f\"{name}.enc\"\n        if not file_path.exists():\n            raise ValueError(f\"No data stored with name: {name}\")\n\n        # Read encrypted data\n        with open(file_path, 'rb') as file:\n            encrypted = file.read()\n\n        # Decrypt\n        try:\n            decrypted = f.decrypt(encrypted)\n            return json.loads(decrypted.decode())\n        except Exception as e:\n            raise ValueError(f\"Decryption failed. Wrong password? {e}\")\n\n    def list_items(self):\n        \"\"\"List stored items\"\"\"\n        return [f.stem for f in self.storage_dir.glob('*.enc')]\n\n    def delete(self, name):\n        \"\"\"Securely delete stored item\"\"\"\n        file_path = self.storage_dir / f\"{name}.enc\"\n        if file_path.exists():\n            # Overwrite with random data\n            file_size = file_path.stat().st_size\n            with open(file_path, 'wb') as f:\n                f.write(os.urandom(file_size))\n            file_path.unlink()\n\n    def cleanup(self):\n        \"\"\"Securely cleanup all stored data\"\"\"\n        for item in self.list_items():\n            self.delete(item)\n\n        # Delete salt file\n        salt_file = self.storage_dir / '.salt'\n        if salt_file.exists():\n            with open(salt_file, 'wb') as f:\n                f.write(os.urandom(16))\n            salt_file.unlink()\n\n        # Remove directory\n        self.storage_dir.rmdir()\n\n# Usage example\nif __name__ == '__main__':\n    storage = EncryptedStorage()\n\n    try:\n        # Store sensitive data\n        storage.store('api_config', {\n            'api_key': 'sk-1234567890',\n            'endpoint': 'https://api.example.com',\n            'timeout': 30\n        })\n\n        storage.store('user_data', {\n            'username': 'john.doe',\n            'email': 'john@example.com'\n        })\n\n        # List items\n        print(f\"Stored items: {storage.list_items()}\")\n\n        # Retrieve data\n        config = storage.retrieve('api_config')\n        print(f\"Retrieved config: {config['endpoint']}\")\n\n        # Cleanup when done\n        storage.cleanup()\n        print(\"All data securely deleted\")\n\n    except Exception as e:\n        print(f\"Error: {e}\")\n        storage.cleanup()\n```\n\n## Conclusion\n\nSecurity for temporary scripts requires the same diligence as production code. Key takeaways:\n\n1. **Never trust user input** - Always validate and sanitize\n2. **Protect credentials** - Use keyring, environment variables, or encryption\n3. **Limit privileges** - Run with minimum necessary permissions\n4. **Set resource limits** - Prevent resource exhaustion attacks\n5. **Use HTTPS** - Always verify certificates\n6. **Cleanup thoroughly** - Securely delete sensitive data\n7. **Monitor execution** - Watch for suspicious behavior\n8. **Use sandboxing** - Isolate untrusted code\n\nRemember: The temporary nature of scripts doesn't reduce their security requirements. A compromised temporary script can do just as much damage as a compromised production system.\n",
        "skills/using-orchestration/SKILL.md": "---\nname: using-orchestration\ndescription: Use when user has complex multi-agent workflows, needs to coordinate sequential or parallel agent execution, wants workflow visualization and control, or mentions automating repetitive multi-agent processes - guides discovery and usage of the orchestration system\n---\n\n# Using the Orchestration System\n\n## When to Suggest\n\nProactively suggest `/orchestrate` when user describes:\n\n**Clear Triggers:**\n- Multiple agents needed in sequence: \"explore then review then implement\"\n- Parallel operations: \"run tests and lint at the same time\"\n- Conditional workflows: \"if tests pass, deploy; if failed, fix and retry\"\n- Retry logic: \"keep trying until it works\"\n- Workflow automation: \"I do this same process often\"\n- Multiple checkpoints: \"I want to review before deploying\"\n\n**Specific Phrases:**\n- \"coordinate multiple agents\"\n- \"workflow\", \"pipeline\", \"orchestrate\"\n- \"run these in parallel\"\n- \"if X then Y\"\n- \"retry until success\"\n- \"automate this process\"\n\n## How to Introduce\n\nWhen triggers detected, suggest proactively:\n\n```\nThis workflow would benefit from orchestration. I can use `/orchestrate` to:\n- Visualize the workflow graph\n- Execute agents in parallel where possible\n- Handle retries and conditionals\n- Provide interactive control at checkpoints\n\nWould you like me to use `/orchestrate [workflow-syntax]` or create a reusable template?\n```\n\n**First-time setup reminder:**\n\nIf user mentions custom agents (like `expert-code-implementer`, `code-optimizer`, etc.) that aren't in the orchestration namespace:\n\n```\nI notice you have custom agents in your environment.\nWould you like to import them to orchestration first?\n\nRun: /orchestration:init\n\nThis will make your custom agents available in workflows as:\n- orchestration:expert-code-implementer\n- orchestration:code-optimizer\n- etc.\n```\n\n## Quick Syntax Reference\n\nShow relevant syntax based on user's needs:\n\n**Sequential:** `explore:\"task\" -> review -> implement`\n**Parallel:** `[test || lint || security]`\n**Conditional:** `test (if passed)~> deploy`\n**Retry:** `@try -> fix -> test (if failed)~> @try`\n\n## When NOT to Suggest\n\n- Single agent task (no coordination needed)\n- Simple sequential tasks (<3 steps, no conditionals)\n- User explicitly requests manual coordination\n- Task already in progress without orchestration\n\n## Integration Pattern\n\nWhen user agrees to orchestration:\n1. Parse their requirements into workflow syntax\n2. Invoke `/orchestrate [workflow-syntax]`\n3. Let the orchestration system handle execution\n4. Don't manually coordinate agents - let orchestrator do it\n",
        "skills/using-templates/SKILL.md": "---\nname: using-templates\ndescription: Use and customize workflow templates for common scenarios. Use when user wants to use a template, asks about available templates, or wants to customize existing workflows.\n---\n\n# Using Workflow Templates\n\nI help you use and customize workflow templates for common automation scenarios.\n\n## When I Activate\n\nI activate when you:\n- Ask about available templates\n- Want to use a workflow template\n- Need to customize a template\n- Ask \"what templates exist?\"\n- Say \"use the X template\"\n\n## Available Templates\n\nLocated in `examples/` directory:\n\n- **tdd-implementation.flow** - Test-Driven Development\n- **debug-and-fix.flow** - Bug investigation and fixing\n- **polish-news-aggregation.flow** - News data aggregation\n- **plugin-testing.flow** - Plugin testing workflow\n- **i18n-fix-hardcoded-strings.flow** - Internationalization\n- **ui-component-refinement.flow** - UI component improvement\n- **agent-system-demo.flow** - Agent system demonstration\n\n## Using Templates\n\n### 1. List Templates\n\n```bash\nls examples/*.flow\n```\n\n### 2. View Template\n\n```bash\ncat examples/tdd-implementation.flow\n```\n\n### 3. Execute Template\n\nUse `/orchestration:template` command:\n\n```\n/orchestration:template tdd-implementation\n```\n\nOr reference directly:\n\n```\nUse examples/tdd-implementation.flow\n```\n\n## Customizing Templates\n\n### Parameter Substitution\n\nSome templates have parameters:\n\n```flow\n# Template with parameter\n$scanner := {base: \"Explore\", prompt: \"{{SCAN_TYPE}}\", model: \"sonnet\"}\n```\n\n**Customize**:\n```flow\n# Your version\n$scanner := {base: \"Explore\", prompt: \"Security expert\", model: \"sonnet\"}\n```\n\n### Modify Steps\n\nAdd or remove workflow steps:\n\n```flow\n# Original\nstep1 -> step2 -> step3\n\n# Your version (added error handling)\nstep1 -> step2 ->\n(if failed)~> handle-error ~>\n(if passed)~> step3\n```\n\n### Add Checkpoints\n\nInsert review points:\n\n```flow\n# Original\nanalyze -> implement -> deploy\n\n# Your version\nanalyze -> implement -> @review-implementation -> deploy\n```\n\n## Template Structure\n\nTemplates typically have:\n\n```flow\n# Header with description\n# Template: TDD Implementation\n# Description: Implement features using Test-Driven Development\n# Parameters: None\n\n# Phase 1: RED\nstep1 -> step2\n\n# Phase 2: GREEN\nstep3 -> step4\n\n# Phase 3: REFACTOR\nstep5 -> step6\n```\n\n## Saving Custom Templates\n\nAfter customizing:\n\n1. Save to examples/ directory\n2. Use `.flow` extension\n3. Add descriptive header\n4. Include usage instructions\n\n```bash\n# Save your custom template\ncat > examples/my-custom-workflow.flow << 'EOF'\n# My Custom Workflow\n# Description: Custom automation for X\n...\nEOF\n```\n\n## Template Categories\n\n### Development Workflows\n\n- TDD implementation\n- Bug fixing\n- Refactoring\n- Code review\n\n### Testing Workflows\n\n- Test automation\n- Integration testing\n- Security scanning\n- Performance testing\n\n### Deployment Workflows\n\n- CI/CD pipelines\n- Staged deployment\n- Rollback procedures\n\n### Data Workflows\n\n- Data aggregation\n- Data validation\n- Data transformation\n- Report generation\n\n## Best Practices\n\n‚úÖ **DO**:\n- Start with existing template\n- Customize incrementally\n- Test modifications\n- Save successful customizations\n\n‚ùå **DON'T**:\n- Modify original templates (copy first)\n- Skip testing customizations\n- Over-complicate simple templates\n\n## Template Parameters\n\nCommon parameters in templates:\n\n| Parameter | Purpose | Example |\n|-----------|---------|---------|\n| `{{TARGET}}` | Target file/directory | `src/components` |\n| `{{SCAN_TYPE}}` | Type of scan | `security`, `performance` |\n| `{{ENV}}` | Environment | `staging`, `production` |\n| `{{BRANCH}}` | Git branch | `main`, `develop` |\n\n## Related Skills\n\n- **creating-workflows**: Create new templates\n- **executing-workflows**: Execute templates\n- **managing-agents**: Use agents in templates\n\n---\n\n**Want to use a template? Ask me to show available templates or execute one!**\n"
      },
      "plugins": [
        {
          "name": "orchestration",
          "source": "./",
          "description": "Multi-agent workflow orchestration with natural language creation, parallel execution, conditional flows, and visual progress tracking",
          "version": "1.0.0",
          "author": {
            "name": "Claude Orchestration Contributors"
          },
          "homepage": "https://github.com/mbruhler/claude-orchestration",
          "repository": "https://github.com/mbruhler/claude-orchestration",
          "license": "MIT",
          "keywords": [
            "workflows",
            "orchestration",
            "multi-agent",
            "parallel-execution",
            "visualization",
            "automation",
            "natural-language",
            "agents",
            "checkpoints"
          ],
          "category": "productivity",
          "categories": [
            "agents",
            "automation",
            "checkpoints",
            "multi-agent",
            "natural-language",
            "orchestration",
            "parallel-execution",
            "productivity",
            "visualization",
            "workflows"
          ],
          "install_commands": [
            "/plugin marketplace add Sixallfaces/orkestr",
            "/plugin install orchestration@orchestration-marketplace"
          ]
        }
      ]
    }
  ]
}