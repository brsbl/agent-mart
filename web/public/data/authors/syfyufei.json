{
  "author": {
    "id": "syfyufei",
    "display_name": "Yufei Sun (Adrian)",
    "avatar_url": "https://avatars.githubusercontent.com/u/58319029?u=bf502ce9cc90cb5205c96d7b546f4290552b49f2&v=4"
  },
  "marketplaces": [
    {
      "name": "research-memory-marketplace",
      "version": null,
      "description": "Research Memory skill marketplace for Claude Code",
      "repo_full_name": "syfyufei/research-memory",
      "repo_url": "https://github.com/syfyufei/research-memory",
      "repo_description": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2025-12-04T02:54:25Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"research-memory-marketplace\",\n  \"description\": \"Research Memory skill marketplace for Claude Code\",\n  \"owner\": {\n    \"name\": \"Adrian\",\n    \"email\": \"syfyufei@gmail.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"research-memory\",\n      \"description\": \"Academic research memory management skill for tracking project continuity, decisions, and experiments\",\n      \"version\": \"0.2.0\",\n      \"source\": \"./\",\n      \"author\": {\n        \"name\": \"Adrian\",\n        \"email\": \"syfyufei@gmail.com\"\n      }\n    }\n  ]\n}",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"research-memory\",\n  \"description\": \"Academic research memory management skill for tracking project continuity, decisions, and experiments\",\n  \"version\": \"0.2.0\",\n  \"author\": {\n    \"name\": \"Adrian\",\n    \"email\": \"syfyufei@gmail.com\"\n  },\n  \"homepage\": \"https://github.com/syfyufei/research-memory\",\n  \"repository\": \"https://github.com/syfyufei/research-memory\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"research\", \"memory\", \"academic\", \"logging\", \"context\", \"decision-tracking\"]\n}",
        "README.md": "[**English**](README.md) | [日本語](README.ja.md) | [简体中文](README.zh.md)\n\n<p align=\"center\">\n  <img src=\"https://maas-log-prod.cn-wlcb.ufileos.com/anthropic/c40838a3-d7bd-48b7-aa5c-ffc7e375eafa/361cbdc75b756c1a65f45153a2b60a0a.png?UCloudPublicKey=TOKEN_e15ba47a-d098-4fbd-9afc-a0dcf0e4e621&Expires=1764755166&Signature=j3dFWqiM%2BLqbBUWEMIR5C0jipSk%3D\" alt=\"Research Memory Banner\" width=\"100%\"/>\n</p>\n\nWe all know how academic research really works:\n\n1. **Your research cycles will inevitably stretch far beyond your initial timeline.**\n2. **You'll inevitably have more repositories open simultaneously than you intended.**\n3. **When you return to a project, you'll inevitably have forgotten where you left off.**\n\nIf you're a developer who works with AI assistants, this scenario probably feels all too familiar:\n\n> You open a repository that's been sitting untouched for three months,\n> Scroll through `git log` from top to bottom,\n> All your notebooks, scripts, and paper drafts are still there,\n> But only one question echoes in your mind:\n> **\"Where exactly did I leave things last time?\"**\n\nHere's what makes it even more frustrating:\n**You've forgotten, and so has your LLM assistant.**\nStarting a fresh conversation, the LLM only has access to \"the current few screens of context\",\nyet has absolutely no understanding of all the struggles, detours, and breakthroughs you've navigated through over the past few months.\n\n`research-memory` is designed to create a **truly \"long-term\" project-level memory layer** during your development process:\n\n- It doesn't try to be a general-purpose RAG system or help you memorize literature;\n- It faithfully records what you and your AI assistant accomplish in this project:\n  **what you did, how you did it, why you chose that approach, and what comes next**.\n\nIn other words:\n\n> Empower \"future you + your current AI assistant\"\n> to seamlessly continue where \"past you\" left off,\n> rather than starting from scratch with a blank conversation every single time.\n\n\n## Quick Overview (TL;DR)\n\n`research-memory` is a Claude Code Skill / Python tool specifically designed for academic research projects, providing three essential capabilities:\n\n1. **Session Bootstrap: `research_memory_bootstrap`**\n   - Pulls from your `memory/` directory:\n     - Project overview (research questions, hypotheses, data sources...)\n     - Recent N devlog entries\n     - Current TODO list\n   - Automatically generates \"recent progress + suggested work plan\"\n\n2. **Session Logging: `research_memory_log_session`**\n   - Structured recording of research work into:\n     - `devlog.md`: Organized by research phases (DGP / data_preprocess / data_analyse / modeling / robustness / writing / infra / notes)\n     - `experiments.csv`: One line per experiment (hypothesis/dataset/model/metrics/notes...)\n     - `decisions.md`: Key decisions and their rationale/alternatives\n     - `todos.md`: Add new items while marking completed ones as `[x]`\n\n3. **History Query: `research_memory_query_history`**\n   - Search using keywords + simple filters (date / phase / type) across:\n     - `devlog.md`\n     - `decisions.md`\n     - `experiments.csv`\n   - Returns summaries + key snippets.\n\n**Everything runs on local text files (Markdown + CSV), plays nicely with Git, is manually editable, and has zero external service dependencies.**\n\n---\n\n## Architecture Overview\n\nOverall structure:\n\n```text\nresearch-memory/\n├── handlers.py        # Skill's Python implementation & CLI entry point\n├── SKILL.md           # Claude Code Skill description (tool definitions)\n├── config/\n│   └── config.json    # Skill behavior configuration\n├── .claude/\n│   ├── CLAUDE.md      # Project-level instructions, telling Claude when to use this skill\n│   └── settings.local.json  # Claude Code local settings example\n└── memory/            # Actual \"project memory layer\" (auto-creatable)\n    ├── project-overview.md  # Long-term project information\n    ├── devlog.md            # Development/analysis log (by session + phase)\n    ├── decisions.md         # Key decision records\n    ├── experiments.csv      # Experiment table (structured)\n    └── todos.md             # TODO / open questions\n```\n\nCore components:\n\n* **Skill Layer**\n\n  * `SKILL.md` defines three tools:\n\n    * `research_memory_bootstrap`\n    * `research_memory_log_session`\n    * `research_memory_query_history`\n  * Called by Claude Code to corresponding functions in `handlers.py`.\n\n* **Backend Layer**\n\n  * `MemoryBackend` encapsulates all file I/O, configuration loading, and TODO processing logic:\n\n    * Currently local Markdown + CSV;\n    * Can be replaced with SQLite / vector database / MCP server in the future without changing the outer interface.\n\n---\n\n## Installation\n\nIn Claude Code, register the marketplace first:\n\n```bash\n/plugin marketplace add syfyufei/research-memory\n```\n\nThen install the plugin from this marketplace:\n\n```bash\n/plugin install research-memory@research-memory-marketplace\n```\n\n### Verify Installation\n\nCheck that commands appear:\n\n```bash\n/help\n```\n\n```\n# Should see 10 commands:\n# /research-memory:bootstrap - Restore project context and generate work plan\n# /research-memory:status - Quick project status overview\n# /research-memory:focus - Get focused daily work plan\n# /research-memory:remember - Remember current work session\n# /research-memory:query - Query research memory history\n# /research-memory:timeline - Visualize project timeline\n# /research-memory:summary - Generate comprehensive project summary\n# /research-memory:review - Review work in a specific time period\n# /research-memory:insights - Get AI-powered insights and suggestions\n# /research-memory:checkpoint - Create a named checkpoint of current state\n```\n\n### Quick Start\n\nResearch Memory can be used in two ways:\n\n**Option 1: Slash Commands**\n\nCore commands:\n```bash\n/research-memory:bootstrap    # Restore project context\n/research-memory:status       # Quick status overview\n/research-memory:focus        # Get today's focused work plan\n/research-memory:remember     # Remember current session\n/research-memory:query        # Search history\n```\n\nAnalysis & reporting:\n```bash\n/research-memory:timeline     # Show project timeline\n/research-memory:summary      # Generate full project summary\n/research-memory:review       # Review specific time period\n/research-memory:insights     # Get AI insights\n/research-memory:checkpoint   # Create state checkpoint\n```\n\n**Option 2: Natural Language**\n\n```\n\"Research Memory, help me get back up to speed with my project\"\n\"Show me a quick status of the project\"\n\"What should I focus on today?\"\n\"Remember this work session\"\n\"Search for our decisions about spatial lag models\"\n\"Generate a project summary for my weekly meeting\"\n```\n\nResearch Memory will automatically create the necessary `memory/` directory and files on first use.\n\n### Uninstallation\n\n**If installed via marketplace**:\n\n```bash\nclaude plugin uninstall research-memory\n```\n\n**If installed manually**:\n\n```bash\n# Remove the skill files from your project\nrm -f handlers.py config/config.json .claude/CLAUDE.md SKILL.md\nrm -rf config/ .claude/ memory/\n```\n\n---\n\n## Configuration: `config/config.json`\n\nAll behavior is controlled by one JSON configuration file, default configuration looks like this (excerpt):\n\n```jsonc\n{\n  \"memory_directory\": \"memory\",\n  \"encoding\": \"utf-8\",\n  \"csv_delimiter\": \",\",\n  \"timestamp_format\": \"ISO8601\",\n\n  \"bootstrap\": {\n    \"recent_entries_count\": 5,\n    \"include_todos\": true,\n    \"suggest_work_plan\": true\n  },\n\n  \"logging\": {\n    \"auto_timestamp\": true,\n    \"phase_sections\": [\n      \"DGP\",\n      \"data_preprocess\",\n      \"data_analyse\",\n      \"modeling\",\n      \"robustness\",\n      \"writing\",\n      \"infra\",\n      \"notes\"\n    ],\n    \"experiment_schema\": [\n      \"hypothesis\",\n      \"dataset\",\n      \"model\",\n      \"metrics\",\n      \"notes\"\n    ]\n  },\n\n  \"search\": {\n    \"max_results\": 10,\n    \"include_context\": true,\n    \"context_lines\": 3\n  }\n}\n```\n\nKey field descriptions:\n\n* `memory_directory`: Memory file directory (relative to project root);\n\n* `encoding`: File encoding (default `utf-8`, can also be changed to `gbk`, etc.);\n\n* `timestamp_format`:\n\n  * `\"ISO8601\"` → e.g., `2025-12-03T19:30:00+09:00`\n  * `\"YYYY-MM-DD_HH-MM-SS\"` → suitable for filenames / human reading\n  * `\"timestamp\"` → Unix timestamp (seconds);\n\n* `bootstrap.recent_entries_count`: How many recent devlog entries to show on startup;\n\n* `logging.phase_sections`: Supported research phase tags;\n\n* `logging.experiment_schema`: Required fields in `experiments.csv`;\n\n* `search.*`: Number of results returned on query and whether to include context.\n\nYou can modify `config.json` as needed, all configuration items are effective in `MemoryBackend`.\n\n---\n\n## Using with Claude Code\n\n### Typical Usage Patterns\n\n**1. Starting your day: Getting back up to speed**\n\n> \"Hey, help me get back up to speed with my research using research-memory, and suggest a plan for today.\"\n\nHere's what happens:\n\n* Calls `research_memory_bootstrap`:\n\n  * Reads `project-overview.md` (if it exists);\n  * Extracts recent N devlog entries (with timestamps + phase info);\n  * Summarizes current incomplete TODOs;\n  * Generates a \"today's work suggestion plan\".\n\n---\n\n**2. Completing a work session: Logging your progress**\n\n> \"Help me organize this work session into a research log, broken down by DGP / data_analyse / modeling phases, and save it to research-memory.\"\n\nClaude will:\n\n1. Based on current conversation content and what you just did, construct a payload, for example:\n\n   ```jsonc\n   {\n     \"session_goal\": \"Run spatial DiD on MCIB_v1.3 to verify H2\",\n     \"changes_summary\": [\n       \"Updated 01_clean_mcib.R, added treat_window_180 variable\",\n       \"Filtered municipalities with sample count < 100\"\n     ],\n     \"phases\": {\n       \"DGP\": \"Assume treatment effects gradually appear within 0-180 days, use distance threshold 50km to construct weight matrix.\",\n       \"data_analyse\": \"Plot baseline period cognitive mean comparison for treatment/control groups, no obvious pre-trend crossover observed.\",\n       \"modeling\": \"Estimate two specifications: TWFE + cluster by municipality; extended specification with provincial time trends.\",\n       \"robustness\": \"Simple placebo: shift treatment time by 1 year overall, results not significant.\"\n     },\n     \"experiments\": [\n       {\n         \"hypothesis\": \"H2\",\n         \"dataset\": \"MCIB_v1.3\",\n         \"model\": \"Spatial DiD with 50km binary contiguity W\",\n         \"metrics\": {\n           \"ATT\": 0.153,\n           \"p_value\": 0.021\n         },\n         \"notes\": \"Results sensitive to window setting, need further robustness checks.\"\n       }\n     ],\n     \"decisions\": [\n       {\n         \"title\": \"Tentatively adopt Model B as main specification\",\n         \"rationale\": \"Pre-trend smoother after adding provincial time trends, coefficients more stable.\",\n         \"alternatives\": [\n           \"Continue using simple TWFE as main specification\",\n           \"Try event-study form\"\n         ]\n       }\n     ],\n     \"todos\": [\n       \"Add k-nearest neighbors based spatial weight matrix comparison\",\n       \"Systematically organize placebo/alternative spec results into paper.qmd\"\n     ],\n     \"completed_todos\": [\n       \"Add spatial weight matrix construction explanation in Methods section\"\n     ]\n   }\n   ```\n\n2. Call `research_memory_log_session(payload)`, automatically:\n\n   * Append a timestamped session record to `devlog.md`;\n   * Insert a complete experiment information row to `experiments.csv`;\n   * Write decision block to `decisions.md`;\n   * Add new TODOs to `todos.md`, and mark items in `completed_todos` as completed.\n\nAfter that, you just need to naturally describe \"what you just did\", and the Skill will help you turn it into structured memory that can be long-term retrieved.\n\n---\n\n**3. Looking back: Reviewing past decisions and experiments**\n\n> \"Why did we abandon spatial lag models before?\"\n> \"Show me all experiments we ran for H2.\"\n> \"Look up changes related to hksarg_parser.R.\"\n\nClaude will call:\n\n```python\nquery_history(query, filters=None)\n```\n\nThe Skill will:\n\n* Perform keyword matching across `devlog.md` / `decisions.md` / `experiments.csv`;\n* Return up to `search.max_results` matches per your configuration;\n* Attach necessary context (a few lines before and after);\n* Generate a brief summary, telling you:\n\n  * What decisions were made at that time;\n  * Which experiments were conducted;\n  * Which alternative approaches/specifications were abandoned.\n\n---\n\n## Command Line Usage (Optional)\n\nBesides calling through Claude Code, you can also directly operate `handlers.py` from the command line—suitable for when you temporarily don't have Claude open, or want to use scripts for batch processing.\n\n### 1. Bootstrap\n\n```bash\npython handlers.py bootstrap\n```\n\nOutput a JSON, including:\n\n* `project_context`\n* `recent_progress`\n* `current_todos`\n* `work_plan_suggestions`\n* `timestamp`\n\n### 2. Record Session\n\n```bash\npython handlers.py log-session \\\n  --payload-json '{\n    \"session_goal\": \"Test CLI logging\",\n    \"changes_summary\": [\"Update README examples\"],\n    \"phases\": {\"notes\": \"First time using research-memory from command line\"},\n    \"todos\": [\"Reference this tool in paper.qmd\"]\n  }'\n```\n\n### 3. Query History\n\n```bash\n# Simplest: search by keywords\npython handlers.py query --question \"spatial lag model\"\n\n# With filters: time + phase + type\npython handlers.py query \\\n  --question \"H2\" \\\n  --from-date 2025-01-01 \\\n  --to-date 2025-12-31 \\\n  --phase modeling \\\n  --type experiments \\\n  --limit 5\n```\n\nCLI will output JSON, convenient for you to continue using in other scripts.\n\n---\n\n## File Format Examples\n\n### `memory/devlog.md`\n\n```markdown\n# Development Log\n\n## 2025-12-03 10:15\n\n**Session Goal**: Run spatial DiD on MCIB_v1.3 to verify H2\n\n**Changes Summary**:\n- Updated 01_clean_mcib.R, added treat_window_180 variable\n- Filtered out municipalities with sample count < 100\n\n### DGP\nAssume treatment effects gradually appear within 0-180 days, use 50km threshold to construct binary spatial weight matrix and row standardize.\n\n### data_analyse\nPlot baseline period cognitive mean comparison for treatment vs control groups, no obvious pre-trend crossover observed.\n\n### modeling\nEstimate two specifications: Model A (TWFE), Model B (TWFE + provincial time trends), H2 coefficients consistent in both directions.\n\n### robustness\nDid simple placebo test (shift treatment time by one year overall), effect not significant.\n\n### notes\nNeed to further try event-study and different spatial weight matrices.\n\n---\n\n```\n\n### `memory/experiments.csv` (header example)\n\n```csv\ntimestamp,experiment_id,hypothesis,dataset,model,metrics,notes,research_phase\n2025-12-03T10:15:00+09:00,exp_20251203_101500,H2,MCIB_v1.3,\"Spatial DiD, W=50km\",{\"ATT\":0.153,\"p_value\":0.021},\"placebo results unstable\",\"DGP,data_analyse,modeling,robustness\"\n```\n\n### `memory/todos.md`\n\n```markdown\n# Project TODOs\n\n- [ ] Add k-nearest neighbors based spatial weight matrix comparison\n- [x] Add spatial weight matrix construction explanation in Methods section (completed: 2025-12-03 - via log_session)\n```\n\n### `memory/decisions.md`\n\n```markdown\n# Key Decisions\n\n## 2025-12-03 10:20 — Tentatively adopt Model B as main specification\n\n**Decision**\nUse TWFE with provincial time trends as main specification.\n\n**Rationale**\nPre-trend smoother, estimation results more stable across different subsamples.\n\n**Alternatives**\n- Keep simple TWFE as main specification\n- Switch to event-study + group-specific trends\n```\n\n---\n\n## Design Principles\n\n* **Local-first**: Everything is local text files, Git-manageable, manually editable;\n* **Skill-first**: Claude Code calls through skill tools, you don't need to care about specific file paths;\n* **Extensible**: Through `MemoryBackend` abstraction layer, can seamlessly switch to database / MCP / remote services in the future;\n* **Semantically aligned with research workflow**:\n\n  * DGP / data_preprocess / data_analyse / modeling / robustness / writing / infra / notes\n  * Instead of just writing a few lines like \"changed some code today\".\n\n---\n\n## Roadmap\n\nCurrent version is **v0.x (file backend version)**, future considerations include:\n\n* Support SQLite / DuckDB as backend (stronger query capabilities, support aggregation analysis);\n* Add vector retrieval, provide fuzzy matching for long devlogs;\n* MCP / HTTP service mode, can be shared by multiple projects / Agents;\n* Locking and merge strategies for multi-user collaboration scenarios.\n\n---\n\n## License & Author\n\n* **License**: MIT\n* **Author**: Yufei Sun (Adrian) `<syfyufei@gmail.com>`\n* **Repo**: [https://github.com/syfyufei/research-memory](https://github.com/syfyufei/research-memory)\n\n---\n\nIf you frequently juggle multiple large projects\nand dread spending half a day each time \"remembering what yesterday's you was thinking\",\ntry installing `research-memory` into your research repositories—\nlet Claude Code become a partner that **truly remembers your entire project history**,\ninstead of just a chat interface that only remembers the current conversation.\n\n```\n::contentReference[oaicite:0]{index=0}\n```"
      },
      "plugins": [
        {
          "name": "research-memory",
          "description": "Academic research memory management skill for tracking project continuity, decisions, and experiments",
          "version": "0.2.0",
          "source": "./",
          "author": {
            "name": "Adrian",
            "email": "syfyufei@gmail.com"
          },
          "categories": [],
          "install_commands": [
            "/plugin marketplace add syfyufei/research-memory",
            "/plugin install research-memory@research-memory-marketplace"
          ]
        }
      ]
    }
  ]
}