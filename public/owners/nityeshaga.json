{
  "owner": {
    "id": "nityeshaga",
    "display_name": "Nityesh Agarwal",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/24698858?u=35e5c9d725754f341e750889cec4ed461998f738&v=4",
    "url": "https://github.com/nityeshaga",
    "bio": "Community Consultant ‚Ä¢ Podcaster ‚Ä¢ Indie Hacker",
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 13,
      "total_skills": 7,
      "total_stars": 42,
      "total_forks": 8
    }
  },
  "repos": [
    {
      "full_name": "nityeshaga/claude-code-essentials",
      "url": "https://github.com/nityeshaga/claude-code-essentials",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 42,
        "forks": 8,
        "pushed_at": "2026-01-12T11:41:05Z",
        "created_at": "2025-11-28T17:57:56Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 583
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 1289
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 2264
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 294
        },
        {
          "path": "plugins/basics/README.md",
          "type": "blob",
          "size": 1841
        },
        {
          "path": "plugins/basics/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/commands/cc.md",
          "type": "blob",
          "size": 14
        },
        {
          "path": "plugins/basics/commands/cleanup.md",
          "type": "blob",
          "size": 6086
        },
        {
          "path": "plugins/basics/commands/commit-push.md",
          "type": "blob",
          "size": 88
        },
        {
          "path": "plugins/basics/commands/compound.md",
          "type": "blob",
          "size": 1050
        },
        {
          "path": "plugins/basics/commands/create-developer-doc.md",
          "type": "blob",
          "size": 1504
        },
        {
          "path": "plugins/basics/commands/create-pitch.md",
          "type": "blob",
          "size": 6473
        },
        {
          "path": "plugins/basics/commands/depcheck.md",
          "type": "blob",
          "size": 204
        },
        {
          "path": "plugins/basics/commands/pinpoint.md",
          "type": "blob",
          "size": 510
        },
        {
          "path": "plugins/basics/commands/review.md",
          "type": "blob",
          "size": 760
        },
        {
          "path": "plugins/basics/commands/study.md",
          "type": "blob",
          "size": 221
        },
        {
          "path": "plugins/basics/commands/tailwind-upgrade.md",
          "type": "blob",
          "size": 428
        },
        {
          "path": "plugins/basics/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/hooks/hooks.json",
          "type": "blob",
          "size": 710
        },
        {
          "path": "plugins/basics/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/scripts/block-main-push.rb",
          "type": "blob",
          "size": 2442
        },
        {
          "path": "plugins/basics/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/ai-tool-designer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/ai-tool-designer/SKILL.md",
          "type": "blob",
          "size": 12667
        },
        {
          "path": "plugins/basics/skills/ai-tool-designer/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/ai-tool-designer/references/evaluation_guide.md",
          "type": "blob",
          "size": 18375
        },
        {
          "path": "plugins/basics/skills/ai-tool-designer/references/tool_design_patterns.md",
          "type": "blob",
          "size": 16627
        },
        {
          "path": "plugins/basics/skills/dhh-rails-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/dhh-rails-expert/SKILL.md",
          "type": "blob",
          "size": 1370
        },
        {
          "path": "plugins/basics/skills/dhh-rails-expert/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/dhh-rails-expert/references/style-guide.md",
          "type": "blob",
          "size": 83580
        },
        {
          "path": "plugins/basics/skills/kamal-deploy",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/kamal-deploy/SKILL.md",
          "type": "blob",
          "size": 8341
        },
        {
          "path": "plugins/basics/skills/kamal-deploy/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/kamal-deploy/references/configuration.md",
          "type": "blob",
          "size": 9496
        },
        {
          "path": "plugins/basics/skills/kamal-deploy/references/troubleshooting.md",
          "type": "blob",
          "size": 10257
        },
        {
          "path": "plugins/basics/skills/mcp-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/mcp-builder/.DS_Store",
          "type": "blob",
          "size": 6148
        },
        {
          "path": "plugins/basics/skills/mcp-builder/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/basics/skills/mcp-builder/SKILL.md",
          "type": "blob",
          "size": 13552
        },
        {
          "path": "plugins/basics/skills/mcp-builder/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/mcp-builder/reference/evaluation.md",
          "type": "blob",
          "size": 21663
        },
        {
          "path": "plugins/basics/skills/mcp-builder/reference/mcp_best_practices.md",
          "type": "blob",
          "size": 28910
        },
        {
          "path": "plugins/basics/skills/mcp-builder/reference/node_mcp_server.md",
          "type": "blob",
          "size": 26709
        },
        {
          "path": "plugins/basics/skills/mcp-builder/reference/python_mcp_server.md",
          "type": "blob",
          "size": 26182
        },
        {
          "path": "plugins/basics/skills/mcp-builder/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/mcp-builder/scripts/connections.py",
          "type": "blob",
          "size": 4875
        },
        {
          "path": "plugins/basics/skills/mcp-builder/scripts/evaluation.py",
          "type": "blob",
          "size": 12579
        },
        {
          "path": "plugins/basics/skills/mcp-builder/scripts/example_evaluation.xml",
          "type": "blob",
          "size": 1194
        },
        {
          "path": "plugins/basics/skills/mcp-builder/scripts/requirements.txt",
          "type": "blob",
          "size": 29
        },
        {
          "path": "plugins/basics/skills/prompt-engineer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/prompt-engineer/.DS_Store",
          "type": "blob",
          "size": 6148
        },
        {
          "path": "plugins/basics/skills/prompt-engineer/SKILL.md",
          "type": "blob",
          "size": 5154
        },
        {
          "path": "plugins/basics/skills/prompt-engineer/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/prompt-engineer/reference/.DS_Store",
          "type": "blob",
          "size": 6148
        },
        {
          "path": "plugins/basics/skills/prompt-engineer/reference/gpt5_prompting_guide.md",
          "type": "blob",
          "size": 7531
        },
        {
          "path": "plugins/basics/skills/prompt-engineer/reference/prompt_framework.md",
          "type": "blob",
          "size": 12638
        },
        {
          "path": "plugins/basics/skills/prompt-engineer/reference/writing_for_ai_teammates.md",
          "type": "blob",
          "size": 5040
        },
        {
          "path": "plugins/basics/skills/skill-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/skill-creator/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/basics/skills/skill-creator/SKILL.md",
          "type": "blob",
          "size": 11547
        },
        {
          "path": "plugins/basics/skills/skill-creator/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/basics/skills/skill-creator/scripts/init_skill.py",
          "type": "blob",
          "size": 10863
        },
        {
          "path": "plugins/basics/skills/skill-creator/scripts/package_skill.py",
          "type": "blob",
          "size": 3247
        },
        {
          "path": "plugins/basics/skills/skill-creator/scripts/quick_validate.py",
          "type": "blob",
          "size": 2165
        },
        {
          "path": "plugins/coding-tutor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 310
        },
        {
          "path": "plugins/coding-tutor/README.md",
          "type": "blob",
          "size": 3275
        },
        {
          "path": "plugins/coding-tutor/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/commands/quiz-me.md",
          "type": "blob",
          "size": 37
        },
        {
          "path": "plugins/coding-tutor/commands/teach-me.md",
          "type": "blob",
          "size": 48
        },
        {
          "path": "plugins/coding-tutor/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor/SKILL.md",
          "type": "blob",
          "size": 12389
        }
      ],
      "marketplace": {
        "name": "claude-code-essentials",
        "version": "1.7.0",
        "description": "Essential Claude Code plugins for developers",
        "owner_info": {
          "name": "Nityesh Agarwal"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "coding-tutor",
            "description": "Personalized coding tutorials with spaced repetition",
            "source": "./plugins/coding-tutor",
            "category": null,
            "version": "2.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add nityeshaga/claude-code-essentials",
              "/plugin install coding-tutor@claude-code-essentials"
            ],
            "signals": {
              "stars": 42,
              "forks": 8,
              "pushed_at": "2026-01-12T11:41:05Z",
              "created_at": "2025-11-28T17:57:56Z",
              "license": null
            },
            "commands": [
              {
                "name": "/quiz-me",
                "description": null,
                "path": "plugins/coding-tutor/commands/quiz-me.md",
                "frontmatter": null,
                "content": "Quiz me using the coding-tutor skill\n"
              },
              {
                "name": "/teach-me",
                "description": null,
                "path": "plugins/coding-tutor/commands/teach-me.md",
                "frontmatter": null,
                "content": "Teach me something using the coding-tutor skill\n"
              }
            ],
            "skills": [
              {
                "name": "coding-tutor",
                "description": "Personalized coding tutorials that build on your existing knowledge and use your actual codebase for examples. Creates a persistent learning trail that compounds over time using the power of AI, spaced repetition and quizzes. Uses cloud storage via MCP for tutorials and learner profiles.",
                "path": "plugins/coding-tutor/skills/coding-tutor/SKILL.md",
                "frontmatter": {
                  "name": "coding-tutor",
                  "description": "Personalized coding tutorials that build on your existing knowledge and use your actual codebase for examples. Creates a persistent learning trail that compounds over time using the power of AI, spaced repetition and quizzes. Uses cloud storage via MCP for tutorials and learner profiles."
                },
                "content": "This skill creates personalized coding tutorials that evolve with the learner. Each tutorial builds on previous ones, uses real examples from the current codebase, and maintains a persistent record of concepts mastered.\n\nThe user asks to learn something - either a specific concept or an open \"teach me something new\" request.\n\n## MCP Tools Available\n\nThis skill uses the `coding-tutor` MCP server for cloud storage. Available tools:\n\n- `mcp__coding-tutor__get_learner_profile` - Get profile with onboarding responses\n- `mcp__coding-tutor__update_learner_profile` - Create/update profile (key, question, answer, commentary)\n- `mcp__coding-tutor__list_tutorials` - List tutorials with optional filters\n- `mcp__coding-tutor__get_tutorial` - Get full tutorial by id or slug\n- `mcp__coding-tutor__create_tutorial` - Create a new tutorial\n- `mcp__coding-tutor__update_tutorial` - Update existing tutorial\n- `mcp__coding-tutor__delete_tutorial` - Delete a tutorial\n- `mcp__coding-tutor__create_quiz_session` - Record quiz results with questions asked\n- `mcp__coding-tutor__get_quiz_history` - Get quiz history for a tutorial\n- `mcp__coding-tutor__get_quiz_recommendations` - Get spaced repetition recommendations\n\n## Welcome New Learners\n\nCall `mcp__coding-tutor__get_learner_profile` to check if a profile exists. If the profile is incomplete (`complete: false` or no onboarding responses), this is a new learner. Introduce yourself:\n\n> I'm your personal coding tutor. I create tutorials tailored to you - using real code from your projects, building on what you already know, and tracking your progress over time.\n>\n> Your tutorials are stored in the cloud and sync across all your devices. Use `/teach-me` to learn something new, `/quiz-me` to test your retention with spaced repetition.\n\nThen proceed with onboarding.\n\n## First Step: Know Your Learner\n\n**Always start by calling `mcp__coding-tutor__get_learner_profile`** to get the learner's profile. This contains crucial context about who you're teaching - their background, goals, and personality. Use it to calibrate everything: what analogies will land, how fast to move, what examples resonate.\n\nIf the profile doesn't exist or is incomplete (`complete: false`), this is a brand new learner. Before teaching anything, you need to understand who you're teaching.\n\n**Onboarding Interview:**\n\nAsk these three questions, one at a time. Wait for each answer before asking the next.\n\n1. **Prior exposure**: What's your background with programming? - Understand if they've built anything before, followed tutorials, or if this is completely new territory.\n\n2. **Ambitious goal**: This is your private AI tutor whose goal is to make you a top 1% programmer. Where do you want this to take you? - Understand what success looks like for them: a million-dollar product, a job at a company they admire, or something else entirely.\n\n3. **Who are you**: Tell me a bit about yourself - imagine we just met at a coworking space. - Get context that shapes how to teach them.\n\n4. **Optional**: Based on the above answers, you may ask up to one optional 4th question if it will make your understanding of the learner richer.\n\nAfter gathering each response, save it along with your commentary using `mcp__coding-tutor__update_learner_profile`:\n\n```\nmcp__coding-tutor__update_learner_profile(\n  key: \"prior_exposure\",  # or \"ambitious_goal\", \"who_are_you\"\n  question: \"The question you asked\",\n  answer: \"Their response\",\n  commentary: \"Your internal commentary\"\n)\n```\n\n## Teaching Philosophy\n\nOur general goal is to take the user from newbie to a senior engineer in record time. One at par with engineers at companies like 37 Signals or Vercel.\n\nBefore creating a tutorial, make a plan by following these steps:\n\n- **Load learner context**: Call `mcp__coding-tutor__get_learner_profile` to understand who you're teaching - their background, goals, and personality.\n- **Survey existing knowledge**: Call `mcp__coding-tutor__list_tutorials` to see what concepts have been covered, at what depth, and how well they landed (understanding scores). Optionally, call `mcp__coding-tutor__get_tutorial` to read specific tutorials in detail.\n- **Identify the gap**: What's the next concept that would be most valuable? Consider both what they've asked for AND what naturally follows from their current knowledge. Think of a curriculum that would get them from their current point to Senior Engineer - what should be the next 3 topics they need to learn to advance their programming knowledge in this direction?\n- **Find the anchor**: Locate real examples in the codebase that demonstrate this concept. Learning from abstract examples is forgettable; learning from YOUR code is sticky.\n- **(Optional) Use ask-user-question tool**: Ask clarifying questions to the learner to understand their intent, goals or expectations if it'll help you make a better plan.\n\nThen show this curriculum plan of **next 3 TUTORIALS** to the user and proceed to the tutorial creation step only if the user approves. If the user rejects, create a new plan using steps mentioned above.\n\n## Tutorial Creation\n\nCreate tutorials using `mcp__coding-tutor__create_tutorial`:\n\n```\nmcp__coding-tutor__create_tutorial(\n  title: \"Tutorial Title\",\n  body: \"Full markdown content of the tutorial including cross-questions during learning\",\n  description: \"One-paragraph summary of what this tutorial covers\",\n  concepts: [\"primary_concept\", \"related_concept_1\", \"related_concept_2\"],\n  source_repo: \"my-app\",  # Which repo examples come from\n  prerequisite_ids: [1, 2, 3]  # Optional: IDs of prerequisite tutorials\n)\n```\n\nQualities of a great tutorial:\n\n- **Start with the \"why\"**: Not \"here's how callbacks work\" but \"here's the problem in your code that callbacks solve\"\n- **Use their code**: Every concept demonstrated with examples pulled from the actual codebase. Reference specific files and line numbers.\n- **Build mental models**: Diagrams, analogies, the underlying \"shape\" of the concept - not just syntax, ELI5\n- **Predict confusion**: Address the questions they're likely to ask before they ask them, don't skim over things, don't write in a notes style\n- **End with a challenge**: A small exercise they could try in this codebase to cement understanding\n\n### Tutorial Writing Style\n\nWrite personal tutorials like the best programming educators: Julia Evans, Dan Abramov. Not like study notes or documentation. There's a difference between a well-structured tutorial and one that truly teaches.\n\n- Show the struggle - \"Here's what you might try... here's why it doesn't work... here's the insight that unlocks it.\"\n- Fewer concepts, more depth - A tutorial that teaches 3 things deeply beats one that mentions 10 things.\n- Tell stories - a great tutorial is one coherent story, dives deep into a single concept, using storytelling techniques that engage readers\n\nWe should make the learner feel like Julia Evans or Dan Abramov is their private tutor.\n\nNote: If you're not sure about a fact or capability or new features/APIs, do web research, look at documentation to make sure you're teaching accurate up-to-date things. NEVER commit the sin of teaching something incorrect.\n\n## The Living Tutorial\n\nTutorials aren't static documents - they evolve:\n\n- **Q&A is mandatory**: When the learner asks ANY clarifying question about a tutorial, you MUST update the tutorial's `qa_section` using `mcp__coding-tutor__update_tutorial`. This is not optional - these exchanges are part of their personalized learning record and improve future teaching.\n- If the learner says they can't follow the tutorial or need you to take a different approach, update the tutorial like they ask\n- If a question reveals a gap in prerequisites, note it for future tutorial planning\n\nTo update a tutorial:\n```\nmcp__coding-tutor__update_tutorial(\n  id: 123,\n  qa_section: \"Updated Q&A content with new questions appended\"\n)\n```\n\nNote: `understanding_score` is only updated through Quiz Mode via `create_quiz_session`, not during teaching.\n\n## What Makes Great Teaching\n\n**DO**: Meet them where they are. Use their vocabulary. Reference their past struggles. Make connections to concepts they already own. Be encouraging but honest about complexity.\n\n**DON'T**: Assume knowledge not demonstrated in previous tutorials. Use generic blog-post examples when codebase examples exist. Overwhelm with every edge case upfront. Be condescending about gaps.\n\n**CALIBRATE**: A learner with 3 tutorials is different from one with 30. Early tutorials need more scaffolding and encouragement. Later tutorials can move faster and reference the shared history you've built.\n\nRemember: The goal isn't to teach programming in the abstract. It's to teach THIS person, using THEIR code, building on THEIR specific journey. Every tutorial should feel like it was written specifically for them - because it was.\n\n## Quiz Mode\n\nTutorials teach. Quizzes verify. The score should reflect what the learner actually retained, not what was presented to them.\n\n**Triggers:**\n- Explicit: \"Quiz me on React hooks\" - quiz that specific concept\n- Open: \"Quiz me on something\" - call `mcp__coding-tutor__get_quiz_recommendations` to get a prioritized list based on spaced repetition, then choose what to quiz\n\n**Spaced Repetition:**\n\nWhen the user requests an open quiz, call:\n```\nmcp__coding-tutor__get_quiz_recommendations(limit: 5)\n```\n\nThis returns tutorials prioritized by:\n- Never-quizzed tutorials (need baseline assessment)\n- Low-scored concepts that are overdue for review\n- High-scored concepts whose review interval has elapsed\n\nThe API uses Fibonacci-ish intervals: score 1 = review in 1 day, score 5 = 5 days, score 8 = 21 days, score 10 = 55 days. This means weak concepts get drilled frequently while mastered ones fade into long-term review.\n\nThe response includes `priority`, `days_overdue`, and `reason` for each recommendation. Use this to make an informed choice about what to quiz, and explain to the learner why you picked that concept (\"You learned callbacks 5 days ago but scored 4/10 - let's see if it's sticking better now\").\n\n**Philosophy:**\n\nA quiz isn't an exam - it's a conversation that reveals understanding. Ask questions that expose mental models, not just syntax recall. The goal is to find the edges of their knowledge: where does solid understanding fade into uncertainty?\n\n**Ask only 1 question at a time.** Wait for the learner's answer before asking the next question.\n\nMix question types based on what the concept demands:\n- Conceptual (\"when would you use X over Y?\")\n- Code reading (\"what does this code in your app do?\")\n- Code writing (\"write a scope that does X\")\n- Debugging (\"what's wrong here?\")\n\nUse their codebase for examples whenever possible. \"What does line 47 of `app/models/user.rb` do?\" is more valuable than abstract snippets.\n\n**Recording Quiz Results:**\n\nAfter the quiz, record the results with details of each question asked:\n```\nmcp__coding-tutor__create_quiz_session(\n  tutorial_id: 123,\n  score_after: 7,  # 1-10 based on quiz performance\n  questions_asked: [\n    {\n      question: \"question 1\",\n      response_summary: \"Brief summary of their response and what it revealed about understanding\"\n    }\n  ]\n)\n```\n\nThis automatically updates the tutorial's `understanding_score` and `last_quizzed` fields. The `questions_asked` array records each question with a brief summary of what the learner's response revealed about their understanding.\n\n**Reviewing Quiz History:**\n\nTo see past quiz performance and track progression over time:\n```\nmcp__coding-tutor__get_quiz_history(tutorial_id: 123, limit: 10)\n```\n\nUse this to:\n- Avoid repeating the same questions in future quizzes\n- Track how understanding has improved (or regressed) over time\n- Identify persistent gaps that keep appearing across sessions\n\n**Scoring Guidelines:**\n- **1-3**: Can't recall the concept, needs re-teaching\n- **4-5**: Vague memory, partial answers\n- **6-7**: Solid understanding, minor gaps\n- **8-9**: Strong grasp, handles edge cases\n- **10**: Could teach this to someone else"
              }
            ]
          },
          {
            "name": "basics",
            "description": "Essential commands, agents, hooks, and skills for everyday development workflows",
            "source": "./plugins/basics",
            "category": null,
            "version": "1.3.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add nityeshaga/claude-code-essentials",
              "/plugin install basics@claude-code-essentials"
            ],
            "signals": {
              "stars": 42,
              "forks": 8,
              "pushed_at": "2026-01-12T11:41:05Z",
              "created_at": "2025-11-28T17:57:56Z",
              "license": null
            },
            "commands": [
              {
                "name": "/cc",
                "description": null,
                "path": "plugins/basics/commands/cc.md",
                "frontmatter": null,
                "content": "Commit changes"
              },
              {
                "name": "/cleanup",
                "description": null,
                "path": "plugins/basics/commands/cleanup.md",
                "frontmatter": null,
                "content": "You are a senior Rails developer tasked with reviewing a branch of code with extreme attention to architectural and code quality issues. Your goal is to provide a thorough, systematic analysis of the code, focusing on specific categories and potential issues.\n\n- $ARGUMENTS\n\nStart multiple subagents in parallel - each doing a review across one or more of these following areas and then collect their reviews and present a unified report:\n\n## 1. CONTROLLER ARCHITECTURE SMELLS üéØ\n\n## PHILOSOPHY: Controllers as Business Logic Units\nControllers should represent business purposes, NOT database tables. Multiple controllers per model is GOOD. Ask yourself: \"What business problem does this controller solve?\" If a controller handles multiple business domains, it should be split.\n\n### CRITICAL: Complexity Rules\n\n- **Method Clarity**: \n  - üü° Flag methods that are hard to understand at a glance\n  - üî¥ Fail methods with multiple unrelated responsibilities\n  - Ask: \"Can I understand what this does without scrolling?\" and \"Does this method do one clear thing?\"\n- **Method Length Guidelines**: \n  - ~25-30 lines: Start asking if it could be cleaner\n  - ~40+ lines: Usually needs refactoring unless it's a cohesive, sequential process\n  - **Focus on cohesion over line count** - A 25-line method that does one clear thing is fine\n- **Controller Length**: \n  - üî¥ Controllers > 200 lines should be evaluated for splitting\n  - Prefer focused controllers over kitchen-sink controllers\n- **Business Logic Clarity**:\n  - Each controller should solve ONE clear business problem\n\n### NEW vs EXISTING Code Rules\n- **EXISTING CODE MODIFICATIONS**: Be VERY strict\n  - Any added complexity to existing files needs strong justification\n  - Prefer extracting to new controllers/services\n- **NEW CODE**: Be pragmatic\n  - If it's isolated and works, it's acceptable\n  - Still flag obvious improvements but don't block\n\n## 2. SPECIFIC STYLE VIOLATIONS üö®\n\n### Turbo Streams\n- **Rule**: Simple turbo streams MUST be inline arrays in controllers\n- **üî¥ FLAG**: Separate `.turbo_stream.erb` files for simple operations\n- **‚úÖ PASS**: `render turbo_stream: [turbo_stream.replace(...), turbo_stream.remove(...)]`\n\n### Testing as Quality Indicator\nAsk for EVERY complex method:\n1. \"How would I test this?\"\n2. \"If it's hard to test, what should be extracted?\"\nHard-to-test code = Poor structure\n\n## 3. CRITICAL DELETIONS & REGRESSIONS üî¥üî¥üî¥\n\n**For each deletion ask**:\n1. Was this intentional for THIS feature?\n2. Does removing this break an existing workflow?\n3. Are there tests that will fail?\n4. Is this logic moved elsewhere or completely removed?\n\n## 4. NAMING & CLARITY AUDIT\n\n### The \"5-Second Rule\"\nIf you can't understand what a view/component does in 5 seconds from its name:\n- üî¥ **FAIL**: `show_in_frame`, `process_stuff`\n- ‚úÖ **PASS**: `fact_check_modal`, `_fact_frame`\n\n### Missing Seeds\n- üü° **Flag**: Any manually created test data not in seeds.rb\n- Every new model/category/type needs seed data\n\n## 5. RAILS BEST PRACTICES & PERFORMANCE üöÄ\n\n### Controller Patterns\n- **RESTful by default**: Avoid custom actions when standard REST works\n- **No case statements for routing**: `case params[:id]` ‚Üí separate controllers\n- **No view logic**: Complex conditionals belong in helpers/presenters\n- **No N+1 queries**: Missing includes/joins\n\n### Query Performance Optimization\n- **Index Requirements**:\n  - \"Ordering without an index is slower\" - Flag ANY order clauses on unindexed columns\n  - Group by operations on large tables MUST have indexes\n  - Any query touching \"many rows\" (>1000) needs performance consideration\n- **Performance Red Flags**:\n  - Queries inside loops\n  - Multiple database calls that could be combined\n  - Missing counter caches for associations\n  - Heavy computations that could be cached\n\n### Service Extraction Smells\n\nConsider extracting to service when you have multiple of these signals:\n\n- **Complex business rules** (not just \"it's long\")\n- **Multiple models being orchestrated** together\n- **External API interactions** or complex I/O\n- **Logic you'd want to reuse** across controllers\n- **State machines or multi-step workflows**\n- **Genuinely hard to test** in the controller context\n\n## OUTPUT FORMAT:\n\nFor each issue, provide:\n\n**üî¥ CRITICAL** (Blocks merge - breaks functionality or violates core principles)\n**üü° MAJOR** (Must fix - hurts maintainability/readability)  \n**üü¢ MINOR** (Should fix - style/consistency)\n\n```\nIssue: [What's wrong]\nLocation: app/controllers/x_controller.rb:45 (method_name)\nCurrent: [Brief code snippet if helpful]\nProblem: [Why this matters]\nFix: [Specific solution]\nExample: [Show the refactored code if non-obvious]\n```\n\n## REFACTORING PRIORITIES:\n\n1. **Extract Controller** ‚Üí When handling multiple business domains\n2. **Extract Method** ‚Üí When too long or multiple responsibilities  \n3. **Extract Service** ‚Üí When complex business logic is in controller\n4. **Extract State Machine** ‚Üí When you see step/state progression logic\n5. **Inline Turbo Streams** ‚Üí When simple enough to be an array\n6. **Add Indexes** ‚Üí When ordering/grouping without proper indexes\n7. **Add Caching** ‚Üí When repeatedly computing expensive operations\n\n## PRAGMATIC BALANCE:\n\n- Don't over-engineer simple features\n- If new code is isolated and works, note improvements but don't block\n- Duplication > Complexity: \"I'd rather have four controllers with simple actions than three controllers that are all custom and have very complex things\"\n- Simple, duplicated code that's easy to understand is BETTER than complex DRY abstractions\n- \"Adding more controllers is never a bad thing. Making controllers very complex is a bad thing\"\n- Performance matters: Always consider \"What happens at scale?\"\n- Balance the indexing advice with the crucial reminder that indexes aren't free - they slow down writes\n\nRemember: Think ultrahard like a senior developer doing a REAL PR review. Be honest, specific, and always provide actionable solutions. Focus on what actually matters for maintainability and team velocity.\n"
              },
              {
                "name": "/commit-push",
                "description": null,
                "path": "plugins/basics/commands/commit-push.md",
                "frontmatter": null,
                "content": "Organize your work into commits so that it's easy for me to review. Then push to remote."
              },
              {
                "name": "/compound",
                "description": null,
                "path": "plugins/basics/commands/compound.md",
                "frontmatter": null,
                "content": "What should Claude learn from this session? \n\nThink ultrahard and reflect on this session, what just happened and how the experience of working could have been more frictionless for me. I want you to accumulate this tacit knowledge and share it with me.\n\n### Why we're doing this exercise?\n\nClaude Code can outperform a 10x engineer on raw capability, but lacks something even a first-week intern naturally does: accumulate context from friction. The moments where you say \"no, not like that\" or \"we tried that, it broke X\" or \"that's not how we do things here\" ‚Äî those are exactly the moments that would shape a human's mental model. They will extract that experience into a sentence or two that they remember for months if not years to help them steer away from the same problem.\n\nWe are trying to workaround that. What's that fuzzy feeling, heuristic, a \"wait, this reminds me of that time...\" that we should takeaway from this session?\n\nOh and if if you think there were no real learning moments this session, say so ‚Äî don't invent learnings."
              },
              {
                "name": "/create-developer-doc",
                "description": null,
                "path": "plugins/basics/commands/create-developer-doc.md",
                "frontmatter": null,
                "content": "I want you to deeply study the codebase to understand how this works:\n\n#$ARGUMENTS\n\nCreate a deeply researched research report and put it in a .md file that will function as the developer documentation for this part of the codebase. Study the structure of other docs in docs/developer-docs/ for reference. You will need to follow more or less the same logical structure as this doc.\n\nRemember, the document should read like a research report and not annotated source code. Lean towards making it more conversational and focused on the \"why\" and \"how it works\" rather than just showing code dumps. At the same time, we need code samples to illustrate important patterns and architecture. So you need to strike the right balance between adding meaningful code snippets that actually help understanding without drowning in implementation details.\n\nIn the final section of the doc when you provide a overview, feel free to create some critical pieces of feedback about each of the other parts. like maybe what they don't do right now - big or small or any blind sides that you've observed or any clearly missing features from a user standpoint. don't just write things there for the sake of writing critical feedback but rather use this as an invitation to share any critical feedback you truly have. You don't need to be sycophantic here but don't clutter the doc with needless criticisms either. A good rule of thumb is to not have more points of criticisms than the number of primary headings in the doc.\n"
              },
              {
                "name": "/create-pitch",
                "description": null,
                "path": "plugins/basics/commands/create-pitch.md",
                "frontmatter": null,
                "content": "Create a 37 signals style \"pitches\" for this new feature we wanna build in Cora:\n\n#$ARGUMENTS\n\nThey follow a specific format inspired by their \"Shape Up\" methodology. Here's the typical structure they use for pitches:\n\n## 37signals Pitch Structure\n\n1. Problem\n\nWhat's the current situation that's frustrating users?\nWhat job are people trying to do that they can't do well today?\nOften includes a brief story or example\n\n2. Appetite\n\nHow much time/resources are we willing to spend on this?\nIs this a 1-week, 6-week, or bigger project?\nWhat's the upper bound we're comfortable with?\n\n3. Solution\n\nHigh-level approach (not detailed specs)\nKey elements that make up the solution\nOften includes rough sketches or wireframes\nFocus on the core concept, not implementation details\n\n4. Rabbit Holes\n\nWhat could go wrong or spiral out of control?\nWhich parts might be trickier than they seem?\nScope creep risks to watch out for\n\n5. No-Gos\n\nWhat are we explicitly NOT doing?\nWhat features/complexity are we leaving out?\nHelps prevent scope creep during development\n\n6. Out of Bounds (sometimes combined with No-Gos)\n\nWhat's outside the scope of this particular pitch\nFuture considerations that aren't part of this cycle\n\nThe key principles:\n\n- Problem-focused (not solution-focused)\n- Concrete but not prescriptive (room for implementation creativity)\n- Bounded (clear limits and constraints)\n- Shaped (more than a raw idea, less than a detailed spec)\n\nNote: Unlike 37signals, we follow a 1-week cycle because we are ambitious about how fast you can code \nwith today's AI tools like Claude Code and Sonnet 4. Keep that in mind.\n\n### How to create a pitch:\n\n1. Explore our all docs in docs/ for a crash course on what exists today\n2. Dig into relevant pieces of code to understand related functionality\n3. Create the pitch\n4. Don't go too hard on Rabit holes or No-Gos or Out of Bounds. Make a good first suggestion but \ninterview me for refining it further based on my vision.\n5. Create a new github issue for the pitch with subject starting with \"Pitch: ...\"\n\nWhile creating this pitch, think like a Product Manager/CEO of the product. \n\nYou are a GREAT product manager!\n\n### Good Product Manager/Bad Product Manager\n\nGood product managers know the market, the product, the product line and the competition extremely well and operate from a strong basis of knowledge and confidence. A good product manager is the CEO of the product. A good product manager takes full responsibility and measures themselves in terms of the success of the product. The are responsible for right product/right time and all that entails. A good product manager knows the context going in (the company, our revenue funding, competition, etc.), and they take responsibility for devising and executing a winning plan (no excuses).\n\nBad product managers have lots of excuses. Not enough funding, the engineering manager is an idiot, Microsoft has 10 times as many engineers working on it, I‚Äôm overworked, I don‚Äôt get enough direction. Barksdale doesn‚Äôt make these kinds of excuses and neither should the CEO of a product.\n\nGood product managers don‚Äôt get all of their time sucked up by the various organizations that must work together to deliver right product right time. They don‚Äôt take all the product team minutes, they don‚Äôt project manage the various functions, they are not gophers for engineering. They are not part of the product team; they manage the product team. Engineering teams don‚Äôt consider Good Product Managers a ‚Äúmarketing resource.‚Äù Good product managers are the marketing counterpart of the engineering manager. Good product managers crisply define the target, the ‚Äúwhat‚Äù (as opposed to the how) and manage the delivery of the ‚Äúwhat.‚Äù Bad product managers feel best about themselves when they figure out ‚Äúhow‚Äù. Good product managers communicate crisply to engineering in writing as well as verbally. Good product managers don‚Äôt give direction informally. Good product managers gather information informally.\n\nGood product managers create leveragable collateral, FAQs, presentations, white papers. Bad product managers complain that they spend all day answering questions for the sales force and are swamped. Good product managers anticipate the serious product flaws and build real solutions. Bad product managers put out fires all day. Good product managers take written positions on important issues (competitive silver bullets, tough architectural choices, tough product decisions, markets to attack or yield). Bad product managers voice their opinion verbally and lament that the ‚Äúpowers that be‚Äù won‚Äôt let it happen. Once bad product managers fail, they point out that they predicted they would fail.\n\nGood product managers focus the team on revenue and customers. Bad product managers focus team on how many features Microsoft is building. Good product managers define good products that can be executed with a strong effort. Bad product managers define good products that can‚Äôt be executed or let engineering build whatever they want (i.e. solve the hardest problem).\n\nGood product managers think in terms of delivering superior value to the market place during inbound planning and achieving market share and revenue goals during outbound. Bad product managers get very confused about the differences amongst delivering value, matching competitive features, pricing, and ubiquity. Good product managers decompose problems. Bad product managers combine all problems into one.\n\nGood product managers think about the story they want written by the press. Bad product managers think about covering every feature and being really technically accurate with the press. Good product managers ask the press questions. Bad product managers answer any press question. Good product managers assume press and analyst people are really smart. Bad product managers assume that press and analysts are dumb because they don‚Äôt understand the difference between ‚Äúpush‚Äù and ‚Äúsimulated push.‚Äù\n\nGood product managers err on the side of clarity vs. explaining the obvious. Bad product managers never explain the obvious. Good product managers define their job and their success. Bad product managers constantly want to be told what to do.\n\nGood product managers send their status reports in on time every week, because they are disciplined. Bad product managers forget to send in their status reports on time, because they don‚Äôt value discipline. "
              },
              {
                "name": "/depcheck",
                "description": null,
                "path": "plugins/basics/commands/depcheck.md",
                "frontmatter": null,
                "content": "Please analyze pull request #$ARGUMENTS opened by\ndependabot. Check the release notes for any changes\nthat might break existing application. Basically\ndetermine if it's safe to merge Dependabot's changes."
              },
              {
                "name": "/pinpoint",
                "description": null,
                "path": "plugins/basics/commands/pinpoint.md",
                "frontmatter": null,
                "content": "Investigate the exact cause of this problem and pinpoint the issue to be before suggesting a solution:\n\n#$ARGUMENTS\n\nDon't guess. I need to identify the root cause here so we can make the surgically correct solution. Ultrathink until you know the exact cause. If you need more information or want me to check something on localhost feel free to ask me. You can use rails runner to use rails console for investigation. Don't edit code until you show me what the root cause problem is and i approve the solution."
              },
              {
                "name": "/review",
                "description": null,
                "path": "plugins/basics/commands/review.md",
                "frontmatter": null,
                "content": "Review this branch objectively and without any biases. Think ultrahard and do a detailed review across each of these parameters one by one.\n\n* Check for \"code smell\" - look for ruby conventions violations or non-efficient use of existing patterns in the codebase or architectural inconsistency\n* Do a git diff with all modified, added, and deleted files and see if there are any unintended changes or breaking stuff that shouldn't have been changed based on what this branch is trying to do\n* Clean up anything that might have been left over, simplify anything that is too complicated, Identify missing or outdated documentation\n* $ARGUMENTS\n\nIf you find a problem, surface it in your review and tell me the severity of the problem(/s). Always ultrathink hard."
              },
              {
                "name": "/study",
                "description": null,
                "path": "plugins/basics/commands/study.md",
                "frontmatter": null,
                "content": "Can you study the changes that have happened in this branch and deeply understand what we're working on currently? I'm asking because you'll need that knowledge to successfully work on the task i'm about to give you next."
              },
              {
                "name": "/tailwind-upgrade",
                "description": null,
                "path": "plugins/basics/commands/tailwind-upgrade.md",
                "frontmatter": null,
                "content": "I want to upgrade tailwindcss-rails from #$ARGUMENTS. I need you to check the release notes and commit to make a report on how it would affect my application, including what changes I should make before/after upgrading.\n\nFor release notes, go to https://github.com/rails/tailwindcss-rails/releases/tag/v<target-version>\nFor commits, go to https://github.com/rails/tailwindcss-rails/compare/v<current-version>...v<target-version>"
              }
            ],
            "skills": [
              {
                "name": "ai-tool-designer",
                "description": "Guide for designing effective tools for AI agents. Use when creating tools for custom agent systems or any AI tool interfaces. Provides principles for tool naming, input/output design, error handling, and evaluation methodologies that maximize agent effectiveness.",
                "path": "plugins/basics/skills/ai-tool-designer/SKILL.md",
                "frontmatter": {
                  "name": "ai-tool-designer",
                  "description": "Guide for designing effective tools for AI agents. Use when creating tools for custom agent systems or any AI tool interfaces. Provides principles for tool naming, input/output design, error handling, and evaluation methodologies that maximize agent effectiveness.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# AI Agent Tool Designer\n\n## Overview\n\nThis skill provides comprehensive guidance for designing tools that AI agents can use effectively. Whether building custom agent tools or any AI-accessible interfaces, these principles maximize agent success in accomplishing real-world tasks.\n\nNote: Use the more specific mcp-builder skill if you want to create an MCP server.\n\nThe quality of a tool system is measured not by how comprehensively it implements features, but by how well it enables AI agents to accomplish realistic, complex tasks using only the tools provided.\n\n---\n\n## Agent-Centric Design Principles\n\nBefore implementing any tool system, understand these foundational principles for designing tools that AI agents can use effectively:\n\n### 1. Build for Workflows, Not Just API Endpoints\n\n**Principle:** Design thoughtful, high-impact workflow tools rather than simply wrapping existing API endpoints.\n\n**Why it matters:** Agents need to accomplish complete tasks, not just make individual API calls. Tools that consolidate related operations reduce the number of steps agents must take and improve success rates.\n\n**How to apply:**\n- Consolidate related operations (e.g., `schedule_event` that both checks availability and creates the event)\n- Focus on tools that enable complete tasks, not just individual API calls\n- Consider what workflows agents actually need to accomplish, not just what the underlying API offers\n- Ask: \"What is the user trying to accomplish?\" rather than \"What does the API provide?\"\n\n**Examples:**\n- ‚ùå Bad: Separate tools `check_calendar_availability`, `create_calendar_event`, `send_event_notification`\n- ‚úÖ Good: Single tool `schedule_event` with parameters for checking conflicts and sending notifications\n\n### 2. Optimize for Limited Context\n\n**Principle:** Agents have constrained context windows - make every token count.\n\n**Why it matters:** When agents run out of context, they fail to complete tasks. Verbose tool outputs force agents to make difficult decisions about what information to keep or discard.\n\n**How to apply:**\n- Return high-signal information, not exhaustive data dumps\n- Provide \"concise\" vs \"detailed\" response format options (default to concise)\n- Default to human-readable identifiers over technical codes (names over IDs when possible)\n- Consider the agent's context budget as a scarce resource\n- Implement character limits and graceful truncation (typically 25,000 characters)\n- Use pagination with reasonable defaults (20-50 items)\n\n**Examples:**\n- ‚ùå Bad: Return all 50 fields from user object including metadata, internal IDs, timestamps in multiple formats\n- ‚úÖ Good: Return name, email, role, and key status fields; offer `detailed=true` parameter for full data\n\n### 3. Design Actionable Error Messages\n\n**Principle:** Error messages should guide agents toward correct usage patterns, not just report failures.\n\n**Why it matters:** Agents learn tool usage through feedback. Clear, educational errors help agents self-correct and succeed on retry.\n\n**How to apply:**\n- Suggest specific next steps in error messages\n- Make errors educational, not just diagnostic\n- Include examples of correct usage when parameters are invalid\n- Guide agents toward solutions: \"Try using filter='active_only' to reduce results\"\n- Avoid technical jargon; use natural language\n\n**Examples:**\n- ‚ùå Bad: \"Error 400: Invalid request\"\n- ‚úÖ Good: \"The limit parameter must be between 1-100. You provided 500. Try using limit=50 and pagination with offset to retrieve more results.\"\n\n### 4. Follow Natural Task Subdivisions\n\n**Principle:** Tool names and organization should reflect how humans think about tasks, not just API structure.\n\n**Why it matters:** Agents use tool names and descriptions to decide which tool to call. Natural naming improves tool discovery and reduces wrong tool selections.\n\n**How to apply:**\n- Tool names should reflect human mental models of tasks\n- Group related tools with consistent prefixes for discoverability\n- Design tools around natural workflows, not just API structure\n- Use action-oriented naming: `search_users`, `create_project`, `send_message`\n- Include service/system prefix to avoid conflicts: `slack_send_message` not just `send_message`\n\n**Examples:**\n- ‚ùå Bad: `api_endpoint_users_post`, `api_endpoint_users_get`, `api_endpoint_users_delete`\n- ‚úÖ Good: `create_user`, `search_users`, `delete_user`\n\n### 5. Use Evaluation-Driven Development\n\n**Principle:** Create realistic evaluation scenarios early and let agent feedback drive tool improvements.\n\n**Why it matters:** Only by testing tools with actual agents can you discover usability issues. Prototype quickly and iterate based on real agent performance.\n\n**How to apply:**\n- Create 10+ complex, realistic questions agents should answer using your tools\n- Test with actual AI agents attempting to solve these questions\n- Observe where agents struggle, make mistakes, or run out of context\n- Iterate on tool design based on agent feedback\n- Measure success by agent task completion rate, not feature completeness\n\n**Process:**\n1. Build initial tools based on these principles\n2. Create evaluation questions (see [Evaluation Guide](./references/evaluation_guide.md))\n3. Test with agents\n4. Identify failure patterns\n5. Refine tools\n6. Repeat\n\n---\n\n## Tool Design Framework\n\nFollow this systematic framework when designing any tool for AI agents:\n\n### Phase 1: Planning\n\n**1. Identify Core Workflows**\n- List the most valuable operations agents need to perform\n- Prioritize tools that enable the most common and important use cases\n- Consider which tools work together to enable complex workflows\n\n**2. Design Input Schemas**\n- Use strong validation (dry-validation for Ruby, JSON Schema)\n- Include proper constraints (min/max length, regex patterns, ranges)\n- Provide clear, descriptive field descriptions with examples\n- Set sensible defaults to reduce required parameters\n\n**3. Design Output Formats**\n- Support multiple formats (JSON for programmatic, Markdown for human-readable)\n- Define consistent response structures across similar tools\n- Plan for large-scale usage (thousands of users/resources)\n- Implement character limits and truncation strategies\n- Include pagination metadata (`has_more`, `next_offset`, `total_count`)\n\n**4. Plan Error Handling**\n- Design clear, actionable, agent-friendly error messages\n- Handle authentication and authorization errors gracefully\n- Consider rate limiting and timeout scenarios\n- Provide guidance on how to proceed after errors\n\n### Phase 2: Implementation\n\n**Tool Naming Conventions:**\n- Use snake_case: `search_users`, `create_project`\n- Include service prefix: `github_create_issue`, `slack_send_message`\n- Be action-oriented: start with verbs (get, list, search, create, update, delete)\n- Be specific: avoid generic names that could conflict\n\n**Tool Descriptions:**\nWrite comprehensive descriptions that include:\n- One-line summary of what the tool does\n- Detailed explanation of purpose and functionality\n- When to use this tool (and when NOT to use it)\n- Parameter descriptions with examples\n- Return value schema\n- Error handling guidance\n\n**Tool Annotations** (if supported by your system):\n- `readOnlyHint: true` for read-only operations\n- `destructiveHint: false` for non-destructive operations\n- `idempotentHint: true` if repeated calls have same effect\n- `openWorldHint: true` if interacting with external systems\n\n### Phase 3: Refinement\n\n**Code Quality Checklist:**\n- ‚úÖ No duplicated code between tools (DRY principle)\n- ‚úÖ Shared logic extracted into reusable functions\n- ‚úÖ Similar operations return similar formats (consistency)\n- ‚úÖ All external calls have error handling\n- ‚úÖ Full type coverage (type hints, TypeScript types)\n- ‚úÖ Every tool has comprehensive documentation\n\n**Testing:**\n- Test with valid and invalid inputs\n- Test error handling paths\n- Test with real AI agents using evaluation questions\n- Test pagination and large result sets\n- Test character limits and truncation\n\n---\n\n## Response Format Guidelines\n\nAll tools that return data should support multiple formats for flexibility:\n\n### JSON Format (`response_format=\"json\"`)\n**Purpose:** Machine-readable structured data for programmatic processing\n\n**Best practices:**\n- Include all available fields and metadata\n- Use consistent field names and types\n- Suitable for when agents need to process data further\n- Return IDs alongside names for precision\n\n**Example:**\n```json\n{\n  \"users\": [\n    {\n      \"id\": \"U123456\",\n      \"name\": \"John Doe\",\n      \"email\": \"john@example.com\",\n      \"role\": \"developer\",\n      \"active\": true\n    }\n  ],\n  \"total\": 150,\n  \"count\": 20,\n  \"has_more\": true,\n  \"next_offset\": 20\n}\n```\n\n### Markdown Format (`response_format=\"markdown\"`, typically default)\n**Purpose:** Human-readable formatted text for user presentation\n\n**Best practices:**\n- Use headers, lists, and formatting for clarity\n- Convert timestamps to readable format (\"2024-01-15 10:30 UTC\" vs epoch)\n- Show display names with IDs in parentheses (\"@john.doe (U123456)\")\n- Omit verbose metadata (show one profile image URL, not all sizes)\n- Group related information logically\n- Use when presenting information to end users\n\n**Example:**\n```markdown\n## Users (20 of 150)\n\n- **John Doe** (@john.doe)\n  - Email: john@example.com\n  - Role: Developer\n  - Status: Active\n\n- **Jane Smith** (@jane.smith)\n  - Email: jane@example.com\n  - Role: Designer\n  - Status: Active\n\n*Showing 20 results. Use offset=20 to see more.*\n```\n\n---\n\n## Pagination Best Practices\n\nFor tools that list resources:\n\n**Implementation requirements:**\n- Always respect the `limit` parameter (never load all results when limit specified)\n- Implement offset-based or cursor-based pagination\n- Return pagination metadata: `has_more`, `next_offset`/`next_cursor`, `total_count`\n- Never load all results into memory for large datasets\n- Default to reasonable limits (20-50 items typical)\n\n**Response structure:**\n```json\n{\n  \"items\": [...],\n  \"total\": 150,\n  \"count\": 20,\n  \"offset\": 0,\n  \"has_more\": true,\n  \"next_offset\": 20\n}\n```\n\n**Clear guidance in responses:**\nInclude instructions for getting more data:\n- \"Showing 20 of 150 results. Use offset=20 to see the next page.\"\n- \"Results truncated. Add filters to narrow the search.\"\n\n---\n\n## Character Limits and Truncation\n\nTo prevent overwhelming context windows:\n\n**Implementation:**\n- Define CHARACTER_LIMIT constant (typically 25,000 characters)\n- Check response size before returning\n- Truncate gracefully with clear indicators\n- Provide guidance on how to filter/paginate for complete results\n\n**Example handling:**\n```ruby\nCHARACTER_LIMIT = 25_000\n\nif result.length > CHARACTER_LIMIT\n  truncated_data = data[0...[1, data.length / 2].max]\n  response[:truncated] = true\n  response[:truncation_message] =\n    \"Response truncated from #{data.length} to #{truncated_data.length} items. \" \\\n    \"Use 'offset' parameter or add filters like status='active' to see more.\"\nend\n```\n\n---\n\n## Input Validation Best Practices\n\n**Security and usability:**\n- Validate all parameters against schema before processing\n- Sanitize file paths to prevent directory traversal\n- Validate URLs and external identifiers\n- Check parameter sizes and ranges\n- Prevent command injection in system calls\n- Return clear validation errors with examples of correct format\n\n**Schema design:**\n- Use strong validation (dry-validation, JSON Schema)\n- Include constraints (minLength, maxLength, pattern, minimum, maximum)\n- Provide detailed field descriptions with examples\n- Mark required vs optional parameters clearly\n- Set sensible defaults where possible\n\n---\n\n## Resources\n\nThis skill includes reference documentation for deeper exploration:\n\n### references/tool_design_patterns.md\nComprehensive patterns and anti-patterns for common tool design scenarios with detailed examples.\n\n### references/evaluation_guide.md\nComplete methodology for creating evaluation questions that test tool effectiveness with AI agents, including how to run evaluations and interpret results.\n\n---\n\n## Further Reading\n\nFor detailed examples and advanced patterns:\n- [Tool Design Patterns](./references/tool_design_patterns.md) - Comprehensive patterns and examples\n- [Evaluation Guide](./references/evaluation_guide.md) - Testing methodology and evaluation creation"
              },
              {
                "name": "dhh-rails-expert",
                "description": "Expert at writing and reviewing Rails code following DHH's style as practiced at 37signals. Use when writing new Rails code, reviewing Rails code, making architectural decisions in Rails apps.",
                "path": "plugins/basics/skills/dhh-rails-expert/SKILL.md",
                "frontmatter": {
                  "name": "dhh-rails-expert",
                  "description": "Expert at writing and reviewing Rails code following DHH's style as practiced at 37signals. Use when writing new Rails code, reviewing Rails code, making architectural decisions in Rails apps."
                },
                "content": "# DHH Rails Expert\n\n## Before You Do Anything\n\n**MANDATORY**: Read [references/style-guide.md](references/style-guide.md) in its entirety before writing or reviewing any code. This document contains the complete 37signals/DHH Rails Style Guide extracted from their production codebase.\n\nDo not proceed with any code changes until you have loaded and understood the style guide.\n\n## Respect Existing Conventions\n\nThe style guide represents DHH's ideal patterns, but real codebases have history. When working in an existing codebase:\n\n- **If the team uses Tailwind** - continue using Tailwind, don't push for vanilla CSS\n- **If the team has service objects** - work with them, don't push for removing them (although you may recommend using less of them)\n- **If the team uses RSpec** - write RSpec tests, don't suggest switching to Minitest\n- **If the team uses Devise** - work with Devise, don't rewrite authentication\n- **If the team uses Sidekiq/Redis** - work with those, don't push for Solid Queue\n\nThe goal is to apply DHH's principles where they naturally fit, not to convert an entire codebase to match 37signals' exact setup."
              },
              {
                "name": "kamal-deploy",
                "description": "Expert-level Kamal deployment guidance for deploying containerized applications to any server. Use this skill when users ask about Kamal, container deployment, zero-downtime deployments, deploying Rails/web apps to VPS/cloud servers, kamal setup, kamal deploy, Docker deployment without Kubernetes, or deploying to Hetzner/DigitalOcean/AWS with Kamal. Also use when users mention DHH's deployment tool, 37signals deployment, or want an alternative to Heroku/Render/Vercel with self-hosted infrastructure.",
                "path": "plugins/basics/skills/kamal-deploy/SKILL.md",
                "frontmatter": {
                  "name": "kamal-deploy",
                  "description": "Expert-level Kamal deployment guidance for deploying containerized applications to any server. Use this skill when users ask about Kamal, container deployment, zero-downtime deployments, deploying Rails/web apps to VPS/cloud servers, kamal setup, kamal deploy, Docker deployment without Kubernetes, or deploying to Hetzner/DigitalOcean/AWS with Kamal. Also use when users mention DHH's deployment tool, 37signals deployment, or want an alternative to Heroku/Render/Vercel with self-hosted infrastructure."
                },
                "content": "# Kamal Deploy Expert\n\nExpert guidance for deploying applications with Kamal - DHH's zero-downtime deployment tool from 37signals.\n\n## Step 1: Fetch Latest Documentation (MANDATORY)\n\n**BEFORE answering ANY Kamal question, you MUST use the WebFetch tool to get current documentation.** The docs below may be outdated - always fetch fresh docs first.\n\nExecute these WebFetch calls in parallel:\n\n1. `WebFetch(url: \"https://kamal-deploy.org/docs/installation/\", prompt: \"Extract complete installation and setup guide\")`\n\n2. `WebFetch(url: \"https://kamal-deploy.org/docs/configuration/overview/\", prompt: \"Extract all configuration options and deploy.yml structure\")`\n\n3. `WebFetch(url: \"https://kamal-deploy.org/docs/commands/view-all-commands/\", prompt: \"Extract all Kamal commands and usage\")`\n\n4. `WebFetch(url: \"https://kamal-deploy.org/docs/configuration/proxy/\", prompt: \"Extract proxy, SSL, and health check configuration\")`\n\nFetch these additional docs based on user's question:\n- Servers/roles: `https://kamal-deploy.org/docs/configuration/servers/`\n- Accessories (DB, Redis): `https://kamal-deploy.org/docs/configuration/accessories/`\n- Environment variables: `https://kamal-deploy.org/docs/configuration/environment-variables/`\n- Docker build options: `https://kamal-deploy.org/docs/configuration/builders/`\n- Deployment hooks: `https://kamal-deploy.org/docs/hooks/overview/`\n- Upgrading v1‚Üív2: `https://kamal-deploy.org/docs/upgrading/overview/`\n\n**Only after fetching fresh docs, use the reference material below as supplementary context.**\n\n## What is Kamal?\n\nKamal deploys containerized apps to any server via SSH + Docker. Created by 37signals (DHH's company) to deploy Basecamp, HEY, and other apps.\n\n**Core architecture:**\n- SSHs into servers, installs Docker automatically\n- Builds app into Docker container\n- Pushes to registry (Docker Hub, GHCR, etc.)\n- Pulls and runs on target servers\n- kamal-proxy handles routing, SSL (Let's Encrypt), zero-downtime\n\n**Mental model:** Hetzner/DigitalOcean = the computer, Kamal = deploys your app to it\n\n## Before You Start\n\n**Check these first to avoid common friction:**\n\n1. **Kamal version** - Run `kamal version`. If on 1.x, upgrade with `gem install kamal`. Config syntax changed significantly (1.x uses `traefik`, 2.x uses `proxy`).\n\n2. **Local Docker situation** - Ask the user if they have Docker working locally. If not (or if Docker Desktop is problematic on macOS), configure a remote builder:\n   ```yaml\n   builder:\n     arch: amd64\n     remote: ssh://root@SERVER_IP\n   ```\n   This builds on the target server and avoids local Docker entirely.\n\n3. **37signals open-source repos** - If deploying Campfire, HEY, or other 37signals apps, immediately delete `.env.erb` - it uses their internal 1Password setup and will fail with `op: command not found`.\n\n4. **Registry access** - Confirm the user has a container registry (Docker Hub, GHCR) and knows their credentials before writing config.\n\n## Quick Start\n\n```bash\n# Install (or upgrade)\ngem install kamal\n\n# Initialize in project\nkamal init\n\n# First deploy (installs Docker, proxy, deploys app)\nkamal setup\n\n# Subsequent deploys\nkamal deploy\n```\n\n## Essential Commands\n\n| Command | Purpose |\n|---------|---------|\n| `kamal setup` | First deploy - installs Docker, proxy, deploys |\n| `kamal deploy` | Deploy new version |\n| `kamal rollback` | Revert to previous version |\n| `kamal app logs` | View application logs |\n| `kamal app exec -i bash` | SSH into running container |\n| `kamal accessory boot <name>` | Start accessory (db, redis) |\n| `kamal proxy reboot` | Restart kamal-proxy |\n| `kamal remove` | Remove everything from servers |\n\n## Minimal config/deploy.yml\n\n```yaml\nservice: my-app\nimage: username/my-app\n\nservers:\n  - 123.45.67.89\n\nregistry:\n  username: username\n  password:\n    - KAMAL_REGISTRY_PASSWORD\n\nproxy:\n  ssl: true\n  host: myapp.com\n\nenv:\n  secret:\n    - RAILS_MASTER_KEY\n    - DATABASE_URL\n```\n\n## Secrets Management\n\nSecrets live in `.kamal/secrets`:\n\n```bash\n# .kamal/secrets\nKAMAL_REGISTRY_PASSWORD=ghp_xxxxxxxxxxxx\nRAILS_MASTER_KEY=abc123def456\nDATABASE_URL=postgres://user:pass@db:5432/app\n```\n\nReference in deploy.yml:\n```yaml\nenv:\n  clear:\n    RAILS_ENV: production\n  secret:\n    - RAILS_MASTER_KEY\n    - DATABASE_URL\n```\n\n## Multi-Server with Roles\n\n```yaml\nservers:\n  web:\n    hosts:\n      - 123.45.67.89\n      - 123.45.67.90\n  workers:\n    hosts:\n      - 123.45.67.91\n    cmd: bin/jobs\n    proxy: false  # Workers don't need proxy\n```\n\n## Accessories (Databases, Redis)\n\n```yaml\naccessories:\n  db:\n    image: postgres:16\n    host: 123.45.67.89\n    port: 5432\n    env:\n      clear:\n        POSTGRES_DB: app_production\n      secret:\n        - POSTGRES_PASSWORD\n    directories:\n      - data:/var/lib/postgresql/data\n\n  redis:\n    image: redis:7\n    host: 123.45.67.89\n    port: 6379\n    directories:\n      - data:/data\n```\n\n## SSL Configuration\n\n**Automatic (Let's Encrypt):**\n```yaml\nproxy:\n  ssl: true\n  host: myapp.com  # Must point to server IP\n```\n\n**Custom certificate:**\n```yaml\nproxy:\n  ssl:\n    certificate_pem:\n      - SSL_CERTIFICATE\n    private_key_pem:\n      - SSL_PRIVATE_KEY\n```\n\n## Health Checks\n\n```yaml\nproxy:\n  healthcheck:\n    interval: 3\n    path: /up\n    timeout: 3\n```\n\nApp must return 200 on `/up` (Rails default) or configured path.\n\n## Destinations (Staging/Production)\n\nCreate `config/deploy.staging.yml`:\n```yaml\nservers:\n  - staging.myapp.com\n\nproxy:\n  host: staging.myapp.com\n```\n\nDeploy: `kamal deploy -d staging`\n\nSecrets: `.kamal/secrets.staging`\n\n## Hooks\n\nPlace in `.kamal/hooks/` (no file extension):\n\nAvailable hooks:\n- `pre-connect`, `pre-build`, `pre-deploy`, `post-deploy`\n- `pre-app-boot`, `post-app-boot`\n- `pre-proxy-reboot`, `post-proxy-reboot`\n\nExample `.kamal/hooks/post-deploy`:\n```bash\n#!/bin/bash\ncurl -X POST \"https://api.honeybadger.io/v1/deploys\" \\\n  -d \"deploy[revision]=$KAMAL_VERSION\"\n```\n\n## Dockerfile Requirements\n\nKamal needs a Dockerfile. For Rails:\n\n```dockerfile\nFROM ruby:3.3-slim\n\nWORKDIR /app\n\n# Install dependencies\nRUN apt-get update -qq && apt-get install -y build-essential libpq-dev\n\nCOPY Gemfile* ./\nRUN bundle install\n\nCOPY . .\n\nRUN bundle exec rails assets:precompile\n\nEXPOSE 80\nCMD [\"bin/rails\", \"server\", \"-b\", \"0.0.0.0\", \"-p\", \"80\"]\n```\n\nNote: Kamal 2.x defaults to port 80 (not 3000).\n\n## Common Issues\n\n**\"Container not healthy\"**\n- Check `/up` endpoint returns 200\n- Increase `deploy_timeout` if app boots slowly\n- Check logs: `kamal app logs`\n\n**\"Permission denied\"**\n- Ensure SSH key is added: `ssh-add ~/.ssh/id_rsa`\n- Check SSH user has Docker access\n\n**Registry auth failed**\n- Verify `KAMAL_REGISTRY_PASSWORD` in `.kamal/secrets`\n- For GHCR: use personal access token with `write:packages`\n\n**\"Address already in use\"**\n- Another service on port 80/443\n- Run `kamal proxy reboot` or check `docker ps` on server\n\n## Kamal vs Alternatives\n\n| | Kamal | Kubernetes | Heroku |\n|---|---|---|---|\n| Complexity | Low | High | None |\n| Cost | VPS only | VPS + overhead | $$$ |\n| Control | Full | Full | Limited |\n| Zero-downtime | Yes | Yes | Yes |\n| SSL | Auto | Manual | Auto |\n| Learning curve | Hours | Weeks | Minutes |\n\n## Best Practices\n\n1. **Always test locally first**: `docker build . && docker run -p 3000:80 <image>`\n2. **Use staging destination** before production\n3. **Keep secrets out of git**: `.kamal/secrets` in `.gitignore`\n4. **Set up monitoring**: Use hooks to notify on deploy\n5. **Regular backups**: Especially accessory volumes\n6. **Use asset bridging** for Rails: `asset_path: /app/public/assets`\n\n## Reference Files\n\nFor detailed configuration options, see:\n- [references/configuration.md](references/configuration.md) - Complete deploy.yml reference\n- [references/troubleshooting.md](references/troubleshooting.md) - Common issues and solutions"
              },
              {
                "name": "mcp-builder",
                "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
                "path": "plugins/basics/skills/mcp-builder/SKILL.md",
                "frontmatter": {
                  "name": "mcp-builder",
                  "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# MCP Server Development Guide\n\n## Overview\n\nTo create high-quality MCP (Model Context Protocol) servers that enable LLMs to effectively interact with external services, use this skill. An MCP server provides tools that allow LLMs to access external services and APIs. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks using the tools provided.\n\n---\n\n# Process\n\n## üöÄ High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Agent-Centric Design Principles\n\nBefore diving into implementation, understand how to design tools for AI agents by reviewing these principles:\n\n**Build for Workflows, Not Just API Endpoints:**\n- Don't simply wrap existing API endpoints - build thoughtful, high-impact workflow tools\n- Consolidate related operations (e.g., `schedule_event` that both checks availability and creates event)\n- Focus on tools that enable complete tasks, not just individual API calls\n- Consider what workflows agents actually need to accomplish\n\n**Optimize for Limited Context:**\n- Agents have constrained context windows - make every token count\n- Return high-signal information, not exhaustive data dumps\n- Provide \"concise\" vs \"detailed\" response format options\n- Default to human-readable identifiers over technical codes (names over IDs)\n- Consider the agent's context budget as a scarce resource\n\n**Design Actionable Error Messages:**\n- Error messages should guide agents toward correct usage patterns\n- Suggest specific next steps: \"Try using filter='active_only' to reduce results\"\n- Make errors educational, not just diagnostic\n- Help agents learn proper tool usage through clear feedback\n\n**Follow Natural Task Subdivisions:**\n- Tool names should reflect how humans think about tasks\n- Group related tools with consistent prefixes for discoverability\n- Design tools around natural workflows, not just API structure\n\n**Use Evaluation-Driven Development:**\n- Create realistic evaluation scenarios early\n- Let agent feedback drive tool improvements\n- Prototype quickly and iterate based on actual agent performance\n\n#### 1.3 Study MCP Protocol Documentation\n\n**Fetch the latest MCP protocol documentation:**\n\nUse WebFetch to load: `https://modelcontextprotocol.io/llms-full.txt`\n\nThis comprehensive document contains the complete MCP specification and guidelines.\n\n#### 1.4 Study Framework Documentation\n\n**Load and read the following reference files:**\n\n- **MCP Best Practices**: [üìã View Best Practices](./reference/mcp_best_practices.md) - Core guidelines for all MCP servers\n\n**For Python implementations, also load:**\n- **Python SDK Documentation**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [üêç Python Implementation Guide](./reference/python_mcp_server.md) - Python-specific best practices and examples\n\n**For Node/TypeScript implementations, also load:**\n- **TypeScript SDK Documentation**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [‚ö° TypeScript Implementation Guide](./reference/node_mcp_server.md) - Node/TypeScript-specific best practices and examples\n\n#### 1.5 Exhaustively Study API Documentation\n\nTo integrate a service, read through **ALL** available API documentation:\n- Official API reference documentation\n- Authentication and authorization requirements\n- Rate limiting and pagination patterns\n- Error responses and status codes\n- Available endpoints and their parameters\n- Data models and schemas\n\n**To gather comprehensive information, use web search and the WebFetch tool as needed.**\n\n#### 1.6 Create a Comprehensive Implementation Plan\n\nBased on your research, create a detailed plan that includes:\n\n**Tool Selection:**\n- List the most valuable endpoints/operations to implement\n- Prioritize tools that enable the most common and important use cases\n- Consider which tools work together to enable complex workflows\n\n**Shared Utilities and Helpers:**\n- Identify common API request patterns\n- Plan pagination helpers\n- Design filtering and formatting utilities\n- Plan error handling strategies\n\n**Input/Output Design:**\n- Define input validation models (Pydantic for Python, Zod for TypeScript)\n- Design consistent response formats (e.g., JSON or Markdown), and configurable levels of detail (e.g., Detailed or Concise)\n- Plan for large-scale usage (thousands of users/resources)\n- Implement character limits and truncation strategies (e.g., 25,000 tokens)\n\n**Error Handling Strategy:**\n- Plan graceful failure modes\n- Design clear, actionable, LLM-friendly, natural language error messages which prompt further action\n- Consider rate limiting and timeout scenarios\n- Handle authentication and authorization errors\n\n---\n\n### Phase 2: Implementation\n\nNow that you have a comprehensive plan, begin implementation following language-specific best practices.\n\n#### 2.1 Set Up Project Structure\n\n**For Python:**\n- Create a single `.py` file or organize into modules if complex (see [üêç Python Guide](./reference/python_mcp_server.md))\n- Use the MCP Python SDK for tool registration\n- Define Pydantic models for input validation\n\n**For Node/TypeScript:**\n- Create proper project structure (see [‚ö° TypeScript Guide](./reference/node_mcp_server.md))\n- Set up `package.json` and `tsconfig.json`\n- Use MCP TypeScript SDK\n- Define Zod schemas for input validation\n\n#### 2.2 Implement Core Infrastructure First\n\n**To begin implementation, create shared utilities before implementing tools:**\n- API request helper functions\n- Error handling utilities\n- Response formatting functions (JSON and Markdown)\n- Pagination helpers\n- Authentication/token management\n\n#### 2.3 Implement Tools Systematically\n\nFor each tool in the plan:\n\n**Define Input Schema:**\n- Use Pydantic (Python) or Zod (TypeScript) for validation\n- Include proper constraints (min/max length, regex patterns, min/max values, ranges)\n- Provide clear, descriptive field descriptions\n- Include diverse examples in field descriptions\n\n**Write Comprehensive Docstrings/Descriptions:**\n- One-line summary of what the tool does\n- Detailed explanation of purpose and functionality\n- Explicit parameter types with examples\n- Complete return type schema\n- Usage examples (when to use, when not to use)\n- Error handling documentation, which outlines how to proceed given specific errors\n\n**Implement Tool Logic:**\n- Use shared utilities to avoid code duplication\n- Follow async/await patterns for all I/O\n- Implement proper error handling\n- Support multiple response formats (JSON and Markdown)\n- Respect pagination parameters\n- Check character limits and truncate appropriately\n\n**Add Tool Annotations:**\n- `readOnlyHint`: true (for read-only operations)\n- `destructiveHint`: false (for non-destructive operations)\n- `idempotentHint`: true (if repeated calls have same effect)\n- `openWorldHint`: true (if interacting with external systems)\n\n#### 2.4 Follow Language-Specific Best Practices\n\n**At this point, load the appropriate language guide:**\n\n**For Python: Load [üêç Python Implementation Guide](./reference/python_mcp_server.md) and ensure the following:**\n- Using MCP Python SDK with proper tool registration\n- Pydantic v2 models with `model_config`\n- Type hints throughout\n- Async/await for all I/O operations\n- Proper imports organization\n- Module-level constants (CHARACTER_LIMIT, API_BASE_URL)\n\n**For Node/TypeScript: Load [‚ö° TypeScript Implementation Guide](./reference/node_mcp_server.md) and ensure the following:**\n- Using `server.registerTool` properly\n- Zod schemas with `.strict()`\n- TypeScript strict mode enabled\n- No `any` types - use proper types\n- Explicit Promise<T> return types\n- Build process configured (`npm run build`)\n\n---\n\n### Phase 3: Review and Refine\n\nAfter initial implementation:\n\n#### 3.1 Code Quality Review\n\nTo ensure quality, review the code for:\n- **DRY Principle**: No duplicated code between tools\n- **Composability**: Shared logic extracted into functions\n- **Consistency**: Similar operations return similar formats\n- **Error Handling**: All external calls have error handling\n- **Type Safety**: Full type coverage (Python type hints, TypeScript types)\n- **Documentation**: Every tool has comprehensive docstrings/descriptions\n\n#### 3.2 Test and Build\n\n**Important:** MCP servers are long-running processes that wait for requests over stdio/stdin or sse/http. Running them directly in your main process (e.g., `python server.py` or `node dist/index.js`) will cause your process to hang indefinitely.\n\n**Safe ways to test the server:**\n- Use the evaluation harness (see Phase 4) - recommended approach\n- Run the server in tmux to keep it outside your main process\n- Use a timeout when testing: `timeout 5s python server.py`\n\n**For Python:**\n- Verify Python syntax: `python -m py_compile your_server.py`\n- Check imports work correctly by reviewing the file\n- To manually test: Run server in tmux, then test with evaluation harness in main process\n- Or use the evaluation harness directly (it manages the server for stdio transport)\n\n**For Node/TypeScript:**\n- Run `npm run build` and ensure it completes without errors\n- Verify dist/index.js is created\n- To manually test: Run server in tmux, then test with evaluation harness in main process\n- Or use the evaluation harness directly (it manages the server for stdio transport)\n\n#### 3.3 Use Quality Checklist\n\nTo verify implementation quality, load the appropriate checklist from the language-specific guide:\n- Python: see \"Quality Checklist\" in [üêç Python Guide](./reference/python_mcp_server.md)\n- Node/TypeScript: see \"Quality Checklist\" in [‚ö° TypeScript Guide](./reference/node_mcp_server.md)\n\n---\n\n### Phase 4: Create Evaluations\n\nAfter implementing your MCP server, create comprehensive evaluations to test its effectiveness.\n\n**Load [‚úÖ Evaluation Guide](./reference/evaluation.md) for complete evaluation guidelines.**\n\n#### 4.1 Understand Evaluation Purpose\n\nEvaluations test whether LLMs can effectively use your MCP server to answer realistic, complex questions.\n\n#### 4.2 Create 10 Evaluation Questions\n\nTo create effective evaluations, follow the process outlined in the evaluation guide:\n\n1. **Tool Inspection**: List available tools and understand their capabilities\n2. **Content Exploration**: Use READ-ONLY operations to explore available data\n3. **Question Generation**: Create 10 complex, realistic questions\n4. **Answer Verification**: Solve each question yourself to verify answers\n\n#### 4.3 Evaluation Requirements\n\nEach question must be:\n- **Independent**: Not dependent on other questions\n- **Read-only**: Only non-destructive operations required\n- **Complex**: Requiring multiple tool calls and deep exploration\n- **Realistic**: Based on real use cases humans would care about\n- **Verifiable**: Single, clear answer that can be verified by string comparison\n- **Stable**: Answer won't change over time\n\n#### 4.4 Output Format\n\nCreate an XML file with this structure:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find discussions about AI model launches with animal codenames. One model needed a specific safety designation that uses the format ASL-X. What number X was being determined for the model named after a spotted wild cat?</question>\n    <answer>3</answer>\n  </qa_pair>\n<!-- More qa_pairs... -->\n</evaluation>\n```\n\n---\n\n# Reference Files\n\n## üìö Documentation Library\n\nLoad these resources as needed during development:\n\n### Core MCP Documentation (Load First)\n- **MCP Protocol**: Fetch from `https://modelcontextprotocol.io/llms-full.txt` - Complete MCP specification\n- [üìã MCP Best Practices](./reference/mcp_best_practices.md) - Universal MCP guidelines including:\n  - Server and tool naming conventions\n  - Response format guidelines (JSON vs Markdown)\n  - Pagination best practices\n  - Character limits and truncation strategies\n  - Tool development guidelines\n  - Security and error handling standards\n\n### SDK Documentation (Load During Phase 1/2)\n- **Python SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- **TypeScript SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n\n### Language-Specific Implementation Guides (Load During Phase 2)\n- [üêç Python Implementation Guide](./reference/python_mcp_server.md) - Complete Python/FastMCP guide with:\n  - Server initialization patterns\n  - Pydantic model examples\n  - Tool registration with `@mcp.tool`\n  - Complete working examples\n  - Quality checklist\n\n- [‚ö° TypeScript Implementation Guide](./reference/node_mcp_server.md) - Complete TypeScript guide with:\n  - Project structure\n  - Zod schema patterns\n  - Tool registration with `server.registerTool`\n  - Complete working examples\n  - Quality checklist\n\n### Evaluation Guide (Load During Phase 4)\n- [‚úÖ Evaluation Guide](./reference/evaluation.md) - Complete evaluation creation guide with:\n  - Question creation guidelines\n  - Answer verification strategies\n  - XML format specifications\n  - Example questions and answers\n  - Running an evaluation with the provided scripts"
              },
              {
                "name": "prompt-engineer",
                "description": "Expert prompt engineering for AI systems. Use when the user wants to write or review prompts for AI, create instructions for AI systems, build system prompts, review or improve existing prompts, optimize AI instructions, or create any form of written communication intended for AI consumption (Claude, GPT, or other LLMs).",
                "path": "plugins/basics/skills/prompt-engineer/SKILL.md",
                "frontmatter": {
                  "name": "prompt-engineer",
                  "description": "Expert prompt engineering for AI systems. Use when the user wants to write or review prompts for AI, create instructions for AI systems, build system prompts, review or improve existing prompts, optimize AI instructions, or create any form of written communication intended for AI consumption (Claude, GPT, or other LLMs)."
                },
                "content": "# Prompt Engineer\n\nThis skill helps create high-quality prompts and instructions for AI systems by treating AI as a genius human teammate who needs clear, context-rich communication.\n\n## Core Philosophy\n\nThis skill is built on two foundational principles:\n\n1. **The Genius Intern Framework**: Treat AI like a brilliant generalist who can figure things out but needs context about what \"good\" looks like in your specific situation\n2. **Async Remote Teammate**: Write for AI the way you'd write for a smart remote colleague‚Äîclear, comprehensive, and decisively opinionated\n\nModern AI models have both high intelligence and high emotional intelligence. They don't need tricks or \"prompt engineering hacks\"‚Äîthey need what any smart remote teammate needs: clear written communication with sufficient context.\n\n## Reference Materials\n\nThis skill includes three core reference documents. Read them in full as needed:\n\n### Always Load First\n**[Writing for AI Teammates](./reference/writing_for_ai_teammates.md)** - Core philosophy covering:\n- Why \"prompt engineering\" is about clear writing, not tricks\n- The 37signals parallel (async remote culture)\n- Brevity-clarity balance\n- Progressive disclosure (\"inverted pyramid\")\n\nLoad this file at the start of every prompt creation task. It's your primary reference.\n\n### Then Load Prompt Framework\n**[Prompt Framework](./reference/prompt_framework.md)** - Comprehensive guide covering:\n- Three prompt types (Do This / Know How / Learn Domain)\n- Universal principles (examples with reasoning, decision frameworks, visual structure)\n- Type-specific patterns and structures\n- Anti-patterns to avoid\n\nAlways load read this detailed framework to understand best practices based on how Anthropic writes their prompts.\n\n### Load Only for GPT-5 Targets\n**[GPT-5 Prompting Guide](./reference/gpt5_prompting_guide.md)** - GPT-5-specific patterns:\n- Avoiding contradictory instructions (critical for GPT-5)\n- Calibrating autonomy vs asking questions\n- Tool preambles and progress updates\n- Self-reflection for quality\n- Planning protocols\n\nOnly load this file if the user explicitly mentions they're targeting GPT-5, OpenAI models, or asks for GPT-5 optimization after seeing the initial draft.\n\n## Workflow\n\n### 1. Understand the Request\n\nWhen the user asks for help with a prompt, quickly assess:\n\n**Type of prompt needed:**\n- **Do This** (single task execution)\n- **Know How** (reusable capability/tool)\n- **Learn Domain** (acquire knowledge then execute)\n\n**Available context:**\n- What's the AI being asked to do?\n- Who's the audience for the output?\n- What does success look like?\n- Are there examples of good/bad outputs?\n- What constraints exist?\n\n### 2. Gather Missing Info (Intelligently)\n\nBe smart about asking questions. Ask if:\n\n- You genuinely can't determine the prompt type\n- Critical context is completely missing (e.g., no idea what the AI should actually do)\n- Multiple valid interpretations exist with very different outcomes\n- Output format is not clear\n\n**Don't ask if:**\n- You have sufficient context to create a solid first draft\n- The user has been comprehensive in their initial request\n- Questions would be nitpicky rather than substantive\n\n### 3. Create the Prompt\n\n**Load the Prompt Framework reference first**, then:\n\n1. **Choose the right structure** based on prompt type:\n   - Do This: Purpose ‚Üí Success Criteria ‚Üí Examples ‚Üí Constraints\n   - Know How: Purpose ‚Üí When to Use ‚Üí Examples with Reasoning ‚Üí Mechanics\n   - Learn Domain: Foundation ‚Üí Study ‚Üí Synthesis ‚Üí Execution ‚Üí Validation\n\n2. **Apply universal principles:**\n   - Be decisively opinionated\n   - Show examples with reasoning (good AND bad)\n   - Provide clear decision frameworks\n   - Address common mistakes proactively\n   - Use visual structure for complex anatomy\n   - Scale complexity to judgment required\n\n3. **Avoid anti-patterns:**\n   - Don't explain basic concepts AI already knows\n   - Don't apologize or hedge\n   - Don't be excessively polite\n   - Don't list every edge case\n   - Don't add motivational statements\n   - Don't over-specify process\n   - Don't overfit on given examples by including said examples in the prompt\n\n### 4. Create as File\n\nAlways create the prompt as a markdown file.\n\n### 5. GPT-5 Optimization (if needed)\n\nAfter creating the prompt, ask: **\"Will this be used with GPT-5 or OpenAI models?\"**\n\nIf yes, you MUST load the GPT-5 Prompting Guide and perform a revision pass:\n\n[Official GPT-5 prompting guide](./reference/gpt5_prompting_guide.md)\n\n## Remember\n\nYou're not doing \"prompt engineering\"‚Äîyou're helping someone communicate clearly with an intelligent teammate. Focus on clarity, context, and decisiveness. Trust the AI to be smart; give them what they need to be effective in your specific context."
              },
              {
                "name": "skill-creator",
                "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
                "path": "plugins/basics/skills/skill-creator/SKILL.md",
                "frontmatter": {
                  "name": "skill-creator",
                  "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks‚Äîthey transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter metadata (required)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ name: (required)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ description: (required)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions (required)\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/          - Executable code (Python/Bash/etc.)\n    ‚îú‚îÄ‚îÄ references/       - Documentation intended to be loaded into context as needed\n    ‚îî‚îÄ‚îÄ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill‚Äîthis keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\nTo complete SKILL.md, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used?\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n### Step 5: Packaging a Skill\n\nOnce the skill is ready, it should be packaged into a distributable zip file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a zip file named after the skill (e.g., `my-skill.zip`) that includes all files and maintains the proper directory structure for distribution.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again"
              }
            ]
          }
        ]
      }
    }
  ]
}