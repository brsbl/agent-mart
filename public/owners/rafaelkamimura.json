{
  "owner": {
    "id": "rafaelkamimura",
    "display_name": "Rafael Kamimura",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/49506004?u=f8d1c490cc7d94694779a61d27e36b4a219c213a&v=4",
    "url": "https://github.com/rafaelkamimura",
    "bio": "Backend developer, but also a physicist.",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 5,
      "total_stars": 3,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "rafaelkamimura/claude-tools",
      "url": "https://github.com/rafaelkamimura/claude-tools",
      "description": "Comprehensive Claude Code toolkit with FastAPI skills, Brazilian financial integrations, workflow automation, and 46 specialized AI agents",
      "homepage": null,
      "signals": {
        "stars": 3,
        "forks": 0,
        "pushed_at": "2026-01-06T16:31:30Z",
        "created_at": "2026-01-06T16:31:27Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 528
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 629
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1072
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5390
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/accessibility-specialist.md",
          "type": "blob",
          "size": 1361
        },
        {
          "path": "agents/ai-engineer.md",
          "type": "blob",
          "size": 1254
        },
        {
          "path": "agents/api-documenter.md",
          "type": "blob",
          "size": 1084
        },
        {
          "path": "agents/arbitrage-bot.md",
          "type": "blob",
          "size": 1940
        },
        {
          "path": "agents/backend-architect.md",
          "type": "blob",
          "size": 1223
        },
        {
          "path": "agents/blockchain-developer.md",
          "type": "blob",
          "size": 1525
        },
        {
          "path": "agents/cloud-architect.md",
          "type": "blob",
          "size": 1239
        },
        {
          "path": "agents/code-architecture-reviewer.md",
          "type": "blob",
          "size": 11108
        },
        {
          "path": "agents/code-refactor-master.md",
          "type": "blob",
          "size": 14969
        },
        {
          "path": "agents/code-reviewer.md",
          "type": "blob",
          "size": 836
        },
        {
          "path": "agents/crypto-analyst.md",
          "type": "blob",
          "size": 1776
        },
        {
          "path": "agents/crypto-risk-manager.md",
          "type": "blob",
          "size": 1798
        },
        {
          "path": "agents/crypto-trader.md",
          "type": "blob",
          "size": 1791
        },
        {
          "path": "agents/data-engineer.md",
          "type": "blob",
          "size": 1137
        },
        {
          "path": "agents/data-scientist.md",
          "type": "blob",
          "size": 880
        },
        {
          "path": "agents/database-optimizer.md",
          "type": "blob",
          "size": 1188
        },
        {
          "path": "agents/debugger.md",
          "type": "blob",
          "size": 2016
        },
        {
          "path": "agents/defi-strategist.md",
          "type": "blob",
          "size": 1873
        },
        {
          "path": "agents/deployment-engineer.md",
          "type": "blob",
          "size": 1251
        },
        {
          "path": "agents/devops-troubleshooter.md",
          "type": "blob",
          "size": 1107
        },
        {
          "path": "agents/directus-developer.md",
          "type": "blob",
          "size": 2940
        },
        {
          "path": "agents/documentation-architect.md",
          "type": "blob",
          "size": 15497
        },
        {
          "path": "agents/drupal-developer.md",
          "type": "blob",
          "size": 3367
        },
        {
          "path": "agents/frontend-developer.md",
          "type": "blob",
          "size": 2396
        },
        {
          "path": "agents/frontend-qa-tester.md",
          "type": "blob",
          "size": 10575
        },
        {
          "path": "agents/game-developer.md",
          "type": "blob",
          "size": 1366
        },
        {
          "path": "agents/golang-pro.md",
          "type": "blob",
          "size": 1241
        },
        {
          "path": "agents/graphql-architect.md",
          "type": "blob",
          "size": 1096
        },
        {
          "path": "agents/laravel-vue-developer.md",
          "type": "blob",
          "size": 5291
        },
        {
          "path": "agents/legacy-modernizer.md",
          "type": "blob",
          "size": 1223
        },
        {
          "path": "agents/ml-engineer.md",
          "type": "blob",
          "size": 1056
        },
        {
          "path": "agents/mobile-developer.md",
          "type": "blob",
          "size": 1132
        },
        {
          "path": "agents/nextjs-app-router-developer.md",
          "type": "blob",
          "size": 3484
        },
        {
          "path": "agents/payment-integration.md",
          "type": "blob",
          "size": 1238
        },
        {
          "path": "agents/performance-engineer.md",
          "type": "blob",
          "size": 1090
        },
        {
          "path": "agents/php-developer.md",
          "type": "blob",
          "size": 2241
        },
        {
          "path": "agents/plan-reviewer.md",
          "type": "blob",
          "size": 11997
        },
        {
          "path": "agents/python-pro.md",
          "type": "blob",
          "size": 1304
        },
        {
          "path": "agents/quant-analyst.md",
          "type": "blob",
          "size": 1293
        },
        {
          "path": "agents/refactor-planner.md",
          "type": "blob",
          "size": 16235
        },
        {
          "path": "agents/rust-pro.md",
          "type": "blob",
          "size": 1335
        },
        {
          "path": "agents/security-auditor.md",
          "type": "blob",
          "size": 1202
        },
        {
          "path": "agents/test-automator.md",
          "type": "blob",
          "size": 1128
        },
        {
          "path": "agents/typescript-expert.md",
          "type": "blob",
          "size": 1367
        },
        {
          "path": "agents/ui-ux-designer.md",
          "type": "blob",
          "size": 3499
        },
        {
          "path": "agents/web-research-specialist.md",
          "type": "blob",
          "size": 10996
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/brainstorm.md",
          "type": "blob",
          "size": 11405
        },
        {
          "path": "commands/bslist.md",
          "type": "blob",
          "size": 12000
        },
        {
          "path": "commands/close-azure-task.md",
          "type": "blob",
          "size": 10564
        },
        {
          "path": "commands/commit.md",
          "type": "blob",
          "size": 6248
        },
        {
          "path": "commands/create-skill.md",
          "type": "blob",
          "size": 14354
        },
        {
          "path": "commands/debug-assistant.md",
          "type": "blob",
          "size": 9268
        },
        {
          "path": "commands/deploy.md",
          "type": "blob",
          "size": 10418
        },
        {
          "path": "commands/deps-update.md",
          "type": "blob",
          "size": 11336
        },
        {
          "path": "commands/dev-docs-update.md",
          "type": "blob",
          "size": 1843
        },
        {
          "path": "commands/dev-docs.md",
          "type": "blob",
          "size": 2251
        },
        {
          "path": "commands/env-sync.md",
          "type": "blob",
          "size": 10290
        },
        {
          "path": "commands/fetch-azure-task.md",
          "type": "blob",
          "size": 4249
        },
        {
          "path": "commands/generate-interview.md",
          "type": "blob",
          "size": 16645
        },
        {
          "path": "commands/handoff.md",
          "type": "blob",
          "size": 11732
        },
        {
          "path": "commands/interview-analysis-template.md",
          "type": "blob",
          "size": 2821
        },
        {
          "path": "commands/interview-context-storage.md",
          "type": "blob",
          "size": 6876
        },
        {
          "path": "commands/mr-draft.md",
          "type": "blob",
          "size": 12904
        },
        {
          "path": "commands/pdf-to-markdown.py",
          "type": "blob",
          "size": 6783
        },
        {
          "path": "commands/perf-check.md",
          "type": "blob",
          "size": 12390
        },
        {
          "path": "commands/read-specs.md",
          "type": "blob",
          "size": 17144
        },
        {
          "path": "commands/review-code.md",
          "type": "blob",
          "size": 11066
        },
        {
          "path": "commands/rollback.md",
          "type": "blob",
          "size": 10354
        },
        {
          "path": "commands/screen-resume.md",
          "type": "blob",
          "size": 10298
        },
        {
          "path": "commands/security-scan.md",
          "type": "blob",
          "size": 10103
        },
        {
          "path": "commands/standup.md",
          "type": "blob",
          "size": 10326
        },
        {
          "path": "commands/sync-config.md",
          "type": "blob",
          "size": 5309
        },
        {
          "path": "commands/task-init.md",
          "type": "blob",
          "size": 40444
        },
        {
          "path": "commands/tech-debt.md",
          "type": "blob",
          "size": 12014
        },
        {
          "path": "commands/test-suite.md",
          "type": "blob",
          "size": 9746
        },
        {
          "path": "commands/todo-worktree.md",
          "type": "blob",
          "size": 7652
        },
        {
          "path": "commands/update-azure-task.md",
          "type": "blob",
          "size": 8066
        },
        {
          "path": "commands/write-documentation.md",
          "type": "blob",
          "size": 16098
        },
        {
          "path": "hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/hooks.json",
          "type": "blob",
          "size": 251
        },
        {
          "path": "hooks/package.json",
          "type": "blob",
          "size": 419
        },
        {
          "path": "hooks/post-tool-use-tracker.sh",
          "type": "blob",
          "size": 5104
        },
        {
          "path": "hooks/skill-activation-prompt.sh",
          "type": "blob",
          "size": 211
        },
        {
          "path": "hooks/skill-activation-prompt.ts",
          "type": "blob",
          "size": 4591
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/README.md",
          "type": "blob",
          "size": 8679
        },
        {
          "path": "skills/async-testing-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/async-testing-expert/README.md",
          "type": "blob",
          "size": 8264
        },
        {
          "path": "skills/async-testing-expert/SKILL.md",
          "type": "blob",
          "size": 19881
        },
        {
          "path": "skills/async-testing-expert/generate_test_template.py",
          "type": "blob",
          "size": 11145
        },
        {
          "path": "skills/brazilian-financial-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/brazilian-financial-integration/SKILL.md",
          "type": "blob",
          "size": 36676
        },
        {
          "path": "skills/fastapi-clean-architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/fastapi-clean-architecture/SKILL.md",
          "type": "blob",
          "size": 27005
        },
        {
          "path": "skills/gitlab-cli-troubleshooter.md",
          "type": "blob",
          "size": 15382
        },
        {
          "path": "skills/mariadb-database-explorer.md",
          "type": "blob",
          "size": 11832
        },
        {
          "path": "skills/mcp-setup-wizard.md",
          "type": "blob",
          "size": 9255
        },
        {
          "path": "skills/multi-system-sso-authentication",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/multi-system-sso-authentication/SKILL.md",
          "type": "blob",
          "size": 35276
        },
        {
          "path": "skills/skill-developer",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/skill-developer/ADVANCED.md",
          "type": "blob",
          "size": 3979
        },
        {
          "path": "skills/skill-developer/HOOK_MECHANISMS.md",
          "type": "blob",
          "size": 7920
        },
        {
          "path": "skills/skill-developer/PATTERNS_LIBRARY.md",
          "type": "blob",
          "size": 3347
        },
        {
          "path": "skills/skill-developer/SKILL.md",
          "type": "blob",
          "size": 12278
        },
        {
          "path": "skills/skill-developer/SKILL_RULES_REFERENCE.md",
          "type": "blob",
          "size": 8692
        },
        {
          "path": "skills/skill-developer/TRIGGER_TYPES.md",
          "type": "blob",
          "size": 7709
        },
        {
          "path": "skills/skill-developer/TROUBLESHOOTING.md",
          "type": "blob",
          "size": 10080
        },
        {
          "path": "skills/skill-rules.json",
          "type": "blob",
          "size": 5646
        }
      ],
      "marketplace": {
        "name": "claude-tools",
        "version": null,
        "description": "Comprehensive Claude Code toolkit with FastAPI skills, Brazilian financial integrations, workflow automation, and 46 specialized AI agents",
        "owner_info": {
          "name": "Rafael Kamimura"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "claude-tools",
            "description": "Full toolkit with skills, commands, hooks, and 46 specialized agents for Python/FastAPI development, Brazilian financial integrations, and workflow automation",
            "source": "./",
            "category": null,
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add rafaelkamimura/claude-tools",
              "/plugin install claude-tools@claude-tools"
            ],
            "signals": {
              "stars": 3,
              "forks": 0,
              "pushed_at": "2026-01-06T16:31:30Z",
              "created_at": "2026-01-06T16:31:27Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "Async Testing Expert",
                "description": "Comprehensive pytest skill for async Python testing with proper mocking, fixtures, and patterns from production-ready test suites. Use when writing or improving async tests for Python applications, especially FastAPI backends with database interactions.",
                "path": "skills/async-testing-expert/SKILL.md",
                "frontmatter": {
                  "name": "Async Testing Expert",
                  "description": "Comprehensive pytest skill for async Python testing with proper mocking, fixtures, and patterns from production-ready test suites. Use when writing or improving async tests for Python applications, especially FastAPI backends with database interactions."
                },
                "content": "# Async Testing Expert\n\nExpert guidance for writing comprehensive async Python tests using pytest, based on production patterns from a 387-test FastAPI backend test suite.\n\n## When to Use This Skill\n\nActivate this skill when:\n- Writing async tests for FastAPI applications\n- Testing async database operations (PostgreSQL, MySQL, etc.)\n- Setting up pytest fixtures for async applications\n- Creating mock objects for database connections\n- Testing services with dependency injection\n- Writing DAO (Data Access Object) layer tests\n- Testing async API endpoints\n\n## Core Principles\n\n### 1. Test Organization\n```\ntests/\n├── conftest.py           # Shared fixtures (app, client, event_loop, faker)\n├── fakes.py              # Reusable mock objects (FakeConnection, FakeRecord)\n├── test_<module>_dao.py  # DAO layer tests\n├── test_<module>_service.py  # Service layer tests\n├── test_<module>_router.py   # API endpoint tests\n└── test_<module>_dto.py      # DTO validation tests\n```\n\n### 2. Naming Conventions\n- Test files: `test_<module>_<layer>.py`\n- Test functions: `test_<what>_<scenario>` (e.g., `test_create_calls_execute`, `test_fetch_by_id_error_maps_to_500`)\n- Be descriptive: readers should understand what's being tested without reading the code\n\n### 3. Always Use Type Hints\n```python\nasync def test_fetch_user_success(faker: Faker) -> None:\n    user_id: int = faker.random_int(1, 100)\n    conn: FakeConnection = FakeConnection()\n    # ...\n```\n\n## Essential Fixtures (conftest.py)\n\n### FastAPI Application Fixtures\n```python\nimport asyncio\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom httpx import AsyncClient, ASGITransport\nfrom faker import Faker\n\n@pytest.fixture(scope='session')\ndef app():\n    \"\"\"Create a FastAPI app instance for testing.\"\"\"\n    from src.config.factory import create_app\n    return create_app()\n\n@pytest.fixture(scope='session')\ndef client(app):\n    \"\"\"Provides a synchronous TestClient for FastAPI.\"\"\"\n    with TestClient(app) as c:\n        yield c\n\n@pytest.fixture\nasync def async_client(app):\n    \"\"\"Provides an asynchronous AsyncClient for FastAPI using ASGI transport.\"\"\"\n    transport = ASGITransport(app=app)\n    async with AsyncClient(transport=transport, base_url='http://test') as ac:\n        yield ac\n\n@pytest.fixture\ndef event_loop():\n    \"\"\"Create a new event loop for each test.\"\"\"\n    loop = asyncio.new_event_loop()\n    yield loop\n    loop.close()\n\n@pytest.fixture\ndef faker():\n    \"\"\"Provide a Faker instance configured for Brazilian Portuguese.\"\"\"\n    return Faker('pt_BR')  # Adjust locale as needed\n```\n\n## Mock Objects for Database Testing (fakes.py)\n\n### FakeRecord - Simulate Query Results\n```python\nclass FakeRecord:\n    \"\"\"Simulate a database record with a .result() method and optional rowcount.\"\"\"\n    def __init__(self, data, rowcount=None):\n        self._data = data\n        self.rowcount = rowcount if rowcount is not None else (\n            data if isinstance(data, int) else 1\n        )\n\n    def result(self):\n        return self._data\n```\n\n### FakeConnection - Full Database Mock\n```python\nclass FakeConnection:\n    \"\"\"Simulate a psqlpy/asyncpg Connection with execute, fetch, fetch_val, and fetch_row.\"\"\"\n    def __init__(self):\n        self.execute_return = None\n        self.fetch_return = None\n        self.fetch_row_return = None\n        self.fetch_val_return = None\n        self.execute_calls = []\n        self.fetch_calls = []\n        self.fetch_val_calls = []\n\n    def transaction(self):\n        return FakeTransactionContext(self)\n\n    async def __aenter__(self):\n        return self\n\n    async def __aexit__(self, exc_type, exc, tb):\n        return False\n\n    async def execute(self, stmt, parameters=None):\n        self.execute_calls.append((stmt, parameters))\n        if isinstance(self.execute_return, Exception):\n            raise self.execute_return\n\n        # Support list of return values for multiple execute calls\n        if (isinstance(self.execute_return, list) and\n            len(self.execute_return) > 0 and\n            all(isinstance(item, list) for item in self.execute_return)):\n            return FakeRecord(self.execute_return.pop(0))\n\n        return FakeRecord(self.execute_return)\n\n    async def execute_many(self, stmt, parameters_list=None):\n        \"\"\"Simulate execute_many for bulk operations.\"\"\"\n        if parameters_list is None:\n            parameters_list = []\n\n        self.execute_calls.append((stmt, parameters_list))\n\n        if isinstance(self.execute_return, Exception):\n            raise self.execute_return\n\n        total_rows = len(parameters_list) if parameters_list else 0\n        return FakeRecord(data=total_rows, rowcount=total_rows)\n\n    async def fetch(self, stmt, parameters=None):\n        self.fetch_calls.append((stmt, parameters))\n        return FakeRecord(self.fetch_return)\n\n    async def fetch_val(self, stmt, parameters=None):\n        self.fetch_val_calls.append((stmt, parameters))\n        if isinstance(self.fetch_val_return, Exception):\n            raise self.fetch_val_return\n        return self.fetch_val_return\n\n    async def fetch_row(self, stmt, parameters=None):\n        \"\"\"Simulate fetching a single row.\"\"\"\n        self.fetch_calls.append((stmt, parameters))\n\n        if isinstance(self.fetch_row_return, Exception):\n            raise self.fetch_row_return\n\n        if self.fetch_row_return is not None:\n            return self.fetch_row_return\n\n        if isinstance(self.fetch_return, list) and len(self.fetch_return) > 0:\n            return FakeRecord(self.fetch_return.pop(0))\n\n        return FakeRecord(self.fetch_return)\n```\n\n### FakeTransaction - Transaction Context Mock\n```python\nclass FakeTransaction:\n    \"\"\"Simulate a database transaction context.\"\"\"\n    def __init__(self, connection):\n        self.connection = connection\n\n    async def execute(self, stmt, parameters=None):\n        return await self.connection.execute(stmt, parameters)\n\n    async def execute_many(self, stmt, parameters_list=None, parameters=None):\n        \"\"\"Simulate execute_many - delegate to connection's execute_many if available.\"\"\"\n        params = parameters if parameters is not None else parameters_list\n        if hasattr(self.connection, 'execute_many'):\n            return await self.connection.execute_many(stmt, params)\n\n        # Fallback: simulate by calling execute for each parameter set\n        if params is None:\n            params = []\n\n        results = []\n        for param_set in params:\n            result = await self.connection.execute(stmt, param_set)\n            results.append(result)\n\n        if results:\n            total_rowcount = sum(getattr(r, 'rowcount', 0) for r in results)\n            return FakeRecord(data=total_rowcount, rowcount=total_rowcount)\n        else:\n            return FakeRecord(data=0, rowcount=0)\n\n    async def fetch(self, stmt, parameters=None):\n        return await self.connection.fetch(stmt, parameters)\n\n    async def fetch_row(self, stmt, parameters=None):\n        return await self.connection.fetch_row(stmt, parameters)\n\n    async def fetch_val(self, stmt, parameters=None):\n        return await self.connection.fetch_val(stmt, parameters)\n\nclass FakeTransactionContext:\n    \"\"\"Simulate the transaction context manager returned by conn.transaction().\"\"\"\n    def __init__(self, connection):\n        self.connection = connection\n        self.transaction = FakeTransaction(connection)\n\n    async def __aenter__(self):\n        return self.transaction\n\n    async def __aexit__(self, exc_type, exc, tb):\n        return False\n```\n\n## Testing Patterns\n\n### Pattern 1: DAO Layer Tests (Direct Method Testing)\n\n**Use `__wrapped__` to bypass connection decorators:**\n\n```python\n@pytest.mark.asyncio\nasync def test_create_calls_execute(faker):\n    \"\"\"Test that create method calls execute with correct SQL and parameters.\"\"\"\n    # Arrange: Prepare test data\n    create_dto = UserDTO.Create(\n        name=faker.name(),\n        email=faker.email(),\n        cpf=faker.ssn()\n    )\n    conn = FakeConnection()\n\n    # Act: Call DAO method directly with __wrapped__\n    await UserDAO.create.__wrapped__(conn, create_dto)\n\n    # Assert: Verify execute was called with correct SQL\n    assert len(conn.execute_calls) == 1\n    stmt, params = conn.execute_calls[0]\n    assert 'INSERT INTO users' in stmt\n    assert isinstance(params, list)\n    assert len(params) == len(create_dto.model_dump())\n```\n\n### Pattern 2: Testing Exception Handling\n\n```python\n@pytest.mark.asyncio\nasync def test_fetch_by_id_error_maps_to_500():\n    \"\"\"Test that database errors are properly mapped to DAOException.\"\"\"\n    conn = FakeConnection()\n\n    async def broken_fetch_row(stmt, parameters=None):\n        raise RustPSQLDriverPyBaseError('db fail')\n\n    conn.fetch_row = broken_fetch_row\n\n    with pytest.raises(DAOException) as exc:\n        await UserDAO.fetch_by_id.__wrapped__(conn, 1)\n\n    err = exc.value\n    assert err.status_code == 500\n    assert 'Erro ao buscar' in err.detail\n```\n\n### Pattern 3: Service Layer Tests with Dependency Injection\n\n**Create dummy dependencies for isolated testing:**\n\n```python\nclass DummyUserAdapter:\n    \"\"\"Mock adapter for testing service layer.\"\"\"\n    def __init__(self, users):\n        self.users = users\n        self.called = False\n\n    async def get_users_by_permission(self, _permission_id, _auth_header, _permission_scope):\n        self.called = True\n        return self.users\n\nclass DummyUserDAO:\n    \"\"\"Mock DAO for testing service layer.\"\"\"\n    def __init__(self):\n        self.fetch_called = False\n        self.create_called = False\n\n    async def fetch_all(self):\n        self.fetch_called = True\n        return [UserDTO.Read(id=1, name='Test User', email='test@example.com')]\n\n    async def create(self, dto):\n        self.create_called = (dto,)\n\n@pytest.mark.asyncio\nasync def test_service_coordinates_dao_and_adapter():\n    \"\"\"Test that service properly coordinates between DAO and adapter.\"\"\"\n    adapter = DummyUserAdapter([])\n    dao = DummyUserDAO()\n    service = UserService(user_adapter=adapter, user_dao=dao)\n\n    result = await service.get_all_users()\n\n    assert dao.fetch_called\n    assert isinstance(result[0], UserDTO.Read)\n```\n\n### Pattern 4: Monkeypatching for Connection Mocking\n\n```python\n@pytest.mark.asyncio\nasync def test_assign_with_dal_connection(monkeypatch, faker):\n    \"\"\"Test method that uses DAL connection wrapper.\"\"\"\n    from src.domain.dal import DAL\n\n    conn = FakeConnection()\n\n    # Monkeypatch connection acquisition\n    async def fake_get_connection(cls):\n        return conn\n\n    monkeypatch.setattr(DAL, '_DAL__get_connection', classmethod(fake_get_connection))\n\n    # Stub other dependencies\n    async def fake_verify_scope(id_, scope_type):\n        return None\n\n    monkeypatch.setattr(UserDAO, '_verify_scope', fake_verify_scope)\n\n    # Prepare test data\n    dto = UserDTO.Assign(user_id=1, role_id=2)\n\n    # Call the actual DAO method (not __wrapped__)\n    await UserDAO.assign(10, dto)\n\n    # Verify execution\n    assert len(conn.execute_calls) > 0\n```\n\n### Pattern 5: Testing Batch Operations\n\n```python\n@pytest.mark.asyncio\nasync def test_sync_calls_execute_many(faker):\n    \"\"\"Test that bulk sync uses execute_many for efficiency.\"\"\"\n    items = [\n        UserDTO.Create(name=faker.name(), email=faker.email())\n        for _ in range(3)\n    ]\n\n    conn = FakeConnection()\n    executed = []\n\n    async def fake_execute_many(stmt, parameters=None, **kwargs):\n        params = parameters if parameters is not None else kwargs.get('parameters_list')\n        executed.append((stmt, params))\n\n    # Patch transaction's execute_many\n    original_transaction = conn.transaction\n\n    async def patched_transaction():\n        t = await original_transaction().__aenter__()\n        t.execute_many = fake_execute_many\n        return t\n\n    class PatchedTransactionContext:\n        async def __aenter__(self):\n            return await patched_transaction()\n\n        async def __aexit__(self, exc_type, exc, tb):\n            return False\n\n    conn.transaction = lambda: PatchedTransactionContext()\n\n    await UserDAO.sync.__wrapped__(conn, items)\n\n    # Verify batch execution\n    assert len(executed) == 1\n    stmt, params = executed[0]\n    assert 'INSERT INTO users' in stmt\n    assert len(params[0]) == len(items)\n```\n\n### Pattern 6: FastAPI Endpoint Testing\n\n```python\n@pytest.mark.asyncio\nasync def test_get_users_endpoint(async_client, monkeypatch):\n    \"\"\"Test GET /users endpoint returns proper response.\"\"\"\n    # Mock the service layer\n    async def mock_get_users():\n        return [UserDTO.Read(id=1, name='Test', email='test@example.com')]\n\n    monkeypatch.setattr('src.api.path.users.UserService.get_all', mock_get_users)\n\n    # Make request\n    response = await async_client.get('/users')\n\n    # Assert response\n    assert response.status_code == 200\n    data = response.json()\n    assert len(data) == 1\n    assert data[0]['name'] == 'Test'\n```\n\n### Pattern 7: Testing with Multiple Return Values\n\n```python\n@pytest.mark.asyncio\nasync def test_multiple_queries_with_different_results(faker):\n    \"\"\"Test method that makes multiple queries with different expected results.\"\"\"\n    conn = FakeConnection()\n\n    # Set up multiple return values (will be popped in order)\n    conn.execute_return = [\n        [{'id': 1, 'status': 'pending'}],  # First query\n        [{'id': 2, 'status': 'approved'}]  # Second query\n    ]\n\n    # First call gets first result\n    result1 = await UserDAO.some_method.__wrapped__(conn, 1)\n    assert result1[0]['status'] == 'pending'\n\n    # Second call gets second result\n    result2 = await UserDAO.some_method.__wrapped__(conn, 2)\n    assert result2[0]['status'] == 'approved'\n```\n\n### Pattern 8: Parametrized Tests for Multiple Scenarios\n\n```python\n@pytest.mark.asyncio\n@pytest.mark.parametrize('status,expected_count', [\n    ('pending', 5),\n    ('approved', 3),\n    ('rejected', 2),\n])\nasync def test_count_by_status(status, expected_count):\n    \"\"\"Test counting users by different status values.\"\"\"\n    conn = FakeConnection()\n    conn.fetch_val_return = expected_count\n\n    result = await UserDAO.count_by_status.__wrapped__(conn, status)\n\n    assert result == expected_count\n    assert len(conn.fetch_val_calls) == 1\n```\n\n## Best Practices Checklist\n\n### Before Writing Tests\n- [ ] Identify the layer being tested (DAO/Service/Router/DTO)\n- [ ] Determine required fixtures (app, client, faker, etc.)\n- [ ] Plan mock objects needed (FakeConnection, dummy services, etc.)\n- [ ] Understand the happy path and error scenarios\n\n### During Test Writing\n- [ ] Use descriptive test names: `test_<action>_<scenario>`\n- [ ] Follow Arrange-Act-Assert pattern with clear sections\n- [ ] Add docstrings explaining what the test validates\n- [ ] Use type hints for all variables\n- [ ] Mock at the right level (connection for DAO, service for router)\n- [ ] Verify both success and failure paths\n- [ ] Check SQL statements, not just return values\n- [ ] Validate parameter counts and types\n\n### After Writing Tests\n- [ ] Run tests: `pytest tests/test_your_module.py -v`\n- [ ] Check coverage: `pytest --cov=src/domain/dao/your_module tests/test_your_module.py`\n- [ ] Verify all code paths are tested\n- [ ] Remove commented code and print statements\n- [ ] Ensure tests are isolated (no shared state)\n- [ ] Run tests multiple times to verify consistency\n\n## Common Pitfalls to Avoid\n\n1. **Forgetting @pytest.mark.asyncio**: All async tests need this decorator\n2. **Not using __wrapped__**: When testing DAO methods directly, bypass decorators\n3. **Sharing state between tests**: Each test should be independent\n4. **Over-mocking**: Mock at boundaries, not internal implementation details\n5. **Ignoring SQL validation**: Always verify the actual SQL being executed\n6. **Not testing exceptions**: Error paths are critical for robustness\n7. **Missing type hints**: Makes tests harder to understand and maintain\n8. **Vague test names**: Name should describe what and when\n\n## Performance Tips\n\n- Use `scope='session'` for expensive fixtures (app creation)\n- Use `scope='function'` (default) for mutable fixtures\n- Mock database connections rather than hitting real databases\n- Group related tests in same file for better context\n- Use `pytest -x` to stop on first failure during development\n- Run specific test files during development: `pytest tests/test_dao.py`\n\n## Integration with CI/CD\n\n```bash\n# Run all tests with coverage\npytest --cov=src --cov-report=html --cov-report=term\n\n# Run only unit tests (fast)\npytest tests/ -m \"not integration\"\n\n# Run with verbose output\npytest -v --tb=short\n\n# Run specific test file\npytest tests/test_user_dao.py -v\n\n# Run tests matching pattern\npytest -k \"test_create\" -v\n```\n\n## Example: Complete Test File\n\n```python\n\"\"\"Tests for UserDAO database access layer.\"\"\"\nfrom datetime import datetime\nimport pytest\nfrom src.domain.dal.dao.user import UserDAO\nfrom src.domain.dal.dao.exception import DAOException\nfrom src.domain.dto.user import UserDTO\nfrom tests.fakes import FakeConnection, FakeRecord\n\n\n@pytest.mark.asyncio\nasync def test_create_inserts_user(faker):\n    \"\"\"Test that create method inserts user with correct parameters.\"\"\"\n    create_dto = UserDTO.Create(\n        name=faker.name(),\n        email=faker.email(),\n        cpf=faker.ssn()\n    )\n    conn = FakeConnection()\n\n    await UserDAO.create.__wrapped__(conn, create_dto)\n\n    assert len(conn.execute_calls) == 1\n    stmt, params = conn.execute_calls[0]\n    assert 'INSERT INTO users' in stmt\n    assert params[0] == create_dto.name\n\n\n@pytest.mark.asyncio\nasync def test_fetch_by_id_returns_user(faker):\n    \"\"\"Test that fetch_by_id returns properly formatted UserDTO.\"\"\"\n    fake_row = {\n        'id': faker.random_int(1, 100),\n        'name': faker.name(),\n        'email': faker.email(),\n        'created_at': faker.date_time()\n    }\n    conn = FakeConnection()\n    conn.fetch_row_return = FakeRecord(fake_row)\n\n    result = await UserDAO.fetch_by_id.__wrapped__(conn, fake_row['id'])\n\n    assert result.id == fake_row['id']\n    assert result.name == fake_row['name']\n    assert isinstance(result, UserDTO.Read)\n\n\n@pytest.mark.asyncio\nasync def test_fetch_by_id_raises_on_db_error():\n    \"\"\"Test that database errors are properly handled and mapped.\"\"\"\n    conn = FakeConnection()\n\n    async def broken_fetch_row(stmt, parameters=None):\n        raise Exception('Connection lost')\n\n    conn.fetch_row = broken_fetch_row\n\n    with pytest.raises(DAOException) as exc:\n        await UserDAO.fetch_by_id.__wrapped__(conn, 1)\n\n    assert exc.value.status_code == 500\n```\n\n## Quick Reference Commands\n\n```bash\n# Run single test\npytest tests/test_user_dao.py::test_create_inserts_user -v\n\n# Run all tests in file\npytest tests/test_user_dao.py -v\n\n# Run with coverage for specific module\npytest --cov=src/domain/dao/user tests/test_user_dao.py\n\n# Stop on first failure\npytest -x tests/\n\n# Show local variables on failure\npytest --showlocals tests/\n\n# Run last failed tests\npytest --lf tests/\n```\n\n## Summary\n\nThis skill provides production-proven patterns for async Python testing:\n\n1. **Proper fixture setup** for FastAPI apps and async clients\n2. **Comprehensive mocking** with FakeConnection and related classes\n3. **Layer-specific testing** patterns (DAO, Service, Router)\n4. **Exception handling** and error path testing\n5. **Monkeypatching** for dependency injection\n6. **Batch operation** testing patterns\n7. **Best practices** for maintainable, robust tests\n\nWhen in doubt, follow the \"Arrange-Act-Assert\" pattern and always verify both the happy path and error scenarios."
              },
              {
                "name": "brazilian-financial-integration",
                "description": "Implement Brazilian financial system integrations including Boleto generation, PIX payments, parcelamento (installments), CPF/CNPJ validation, and Banco do Brasil API integration. Use this skill when building fintech applications, payment processing systems, or any system requiring Brazilian banking compliance.",
                "path": "skills/brazilian-financial-integration/SKILL.md",
                "frontmatter": {
                  "name": "brazilian-financial-integration",
                  "description": "Implement Brazilian financial system integrations including Boleto generation, PIX payments, parcelamento (installments), CPF/CNPJ validation, and Banco do Brasil API integration. Use this skill when building fintech applications, payment processing systems, or any system requiring Brazilian banking compliance."
                },
                "content": "# Brazilian Financial Integration Skill\n\n## Overview\n\nThis skill provides comprehensive patterns for integrating Brazilian financial systems and payment methods. It covers Boleto bank slip generation, PIX instant payments, installment plans (parcelamento), Brazilian tax ID validation, and banking API integrations.\n\n## When to Use This Skill\n\n- Building fintech or payment processing systems for Brazil\n- Implementing Boleto bank slip generation\n- Integrating PIX instant payment system\n- Creating installment payment plans (parcelamento)\n- Validating CPF/CNPJ tax identification numbers\n- Integrating with Brazilian banking APIs (Banco do Brasil, Itaú, etc.)\n- Handling Brazilian currency and date formats\n\n## Core Concepts\n\n### Brazilian Payment Methods\n\n1. **Boleto Bancário** (Bank Slip)\n   - Paper or digital payment slip\n   - Barcode for bank processing\n   - Payment deadline (vencimento)\n   - Widely used for bills and purchases\n\n2. **PIX** (Instant Payment)\n   - Real-time payment system\n   - QR Code or key-based\n   - 24/7 availability\n   - Transaction fees typically lower than boleto\n\n3. **Parcelamento** (Installments)\n   - Split payments over multiple months\n   - Fixed or variable amounts\n   - Interest calculations\n   - Payment schedules\n\n### Brazilian Tax IDs\n\n- **CPF** (Cadastro de Pessoas Físicas): Individual taxpayer ID (11 digits)\n- **CNPJ** (Cadastro Nacional da Pessoa Jurídica): Company taxpayer ID (14 digits)\n\n## Project Structure for Financial Module\n\n```\nsrc/\n├── domain/\n│   ├── modules/\n│   │   ├── boleto/\n│   │   │   ├── entity.py              # Boleto domain entity\n│   │   │   ├── generator.py           # IBoletoGenerator interface\n│   │   │   ├── barcode.py             # Barcode generation logic\n│   │   │   └── validator.py           # Boleto validation rules\n│   │   ├── pix/\n│   │   │   ├── entity.py              # CobrancaPix entity\n│   │   │   ├── payment_strategy.py    # IPixPaymentStrategy\n│   │   │   └── qrcode_generator.py    # QR code generation\n│   │   ├── parcelamento/\n│   │   │   ├── entity.py              # Parcelamento entity\n│   │   │   ├── calculator.py          # Interest/installment calculator\n│   │   │   └── strategy.py            # Payment strategies\n│   │   └── shared/\n│   │       ├── cpf_cnpj_validator.py  # Tax ID validation\n│   │       └── currency.py            # Brazilian currency helpers\n│   └── infra/\n│       ├── payment/\n│       │   ├── bb_api_adapter.py      # Banco do Brasil API\n│       │   ├── boleto_pdf_generator.py # PDF generation (reportlab)\n│       │   └── pix_api_client.py      # PIX API integration\n│       └── database/\n│           └── alchemist/\n│               └── modules/\n│                   ├── boleto/\n│                   ├── pix/\n│                   └── parcelamento/\n```\n\n## Implementation Patterns\n\n### 1. CPF/CNPJ Validation\n\n```python\n# src/domain/modules/shared/cpf_cnpj_validator.py\nimport re\nfrom typing import Literal\n\nclass CPFCNPJValidator:\n    \"\"\"Validator for Brazilian CPF and CNPJ tax IDs.\n\n    Implements official validation algorithms with check digits.\n    \"\"\"\n\n    @staticmethod\n    def clean(value: str) -> str:\n        \"\"\"Remove non-numeric characters from CPF/CNPJ.\"\"\"\n        return re.sub(r'\\D', '', value)\n\n    @staticmethod\n    def validate_cpf(cpf: str) -> bool:\n        \"\"\"Validate CPF using official algorithm.\n\n        Args:\n            cpf: CPF string (can contain formatting)\n\n        Returns:\n            True if valid, False otherwise\n        \"\"\"\n        cpf = CPFCNPJValidator.clean(cpf)\n\n        # Check length\n        if len(cpf) != 11:\n            return False\n\n        # Check for invalid patterns (all same digits)\n        if cpf == cpf[0] * 11:\n            return False\n\n        # Check for known invalid values\n        invalid_values = ['00000000000', '11111111111', '22222222222',\n                         '33333333333', '44444444444', '55555555555',\n                         '66666666666', '77777777777', '88888888888',\n                         '99999999999']\n        if cpf in invalid_values:\n            return False\n\n        # Calculate first check digit\n        sum_digits = sum(int(cpf[i]) * (10 - i) for i in range(9))\n        first_check = (sum_digits * 10) % 11\n        first_check = 0 if first_check == 10 else first_check\n\n        if int(cpf[9]) != first_check:\n            return False\n\n        # Calculate second check digit\n        sum_digits = sum(int(cpf[i]) * (11 - i) for i in range(10))\n        second_check = (sum_digits * 10) % 11\n        second_check = 0 if second_check == 10 else second_check\n\n        return int(cpf[10]) == second_check\n\n    @staticmethod\n    def validate_cnpj(cnpj: str) -> bool:\n        \"\"\"Validate CNPJ using official algorithm.\n\n        Args:\n            cnpj: CNPJ string (can contain formatting)\n\n        Returns:\n            True if valid, False otherwise\n        \"\"\"\n        cnpj = CPFCNPJValidator.clean(cnpj)\n\n        # Check length\n        if len(cnpj) != 14:\n            return False\n\n        # Check for invalid patterns\n        if cnpj == cnpj[0] * 14:\n            return False\n\n        # Calculate first check digit\n        weights_1 = [5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]\n        sum_digits = sum(int(cnpj[i]) * weights_1[i] for i in range(12))\n        first_check = sum_digits % 11\n        first_check = 0 if first_check < 2 else 11 - first_check\n\n        if int(cnpj[12]) != first_check:\n            return False\n\n        # Calculate second check digit\n        weights_2 = [6, 5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]\n        sum_digits = sum(int(cnpj[i]) * weights_2[i] for i in range(13))\n        second_check = sum_digits % 11\n        second_check = 0 if second_check < 2 else 11 - second_check\n\n        return int(cnpj[13]) == second_check\n\n    @staticmethod\n    def validate(value: str) -> tuple[bool, Literal[\"CPF\", \"CNPJ\", None]]:\n        \"\"\"Validate CPF or CNPJ automatically.\n\n        Args:\n            value: CPF or CNPJ string\n\n        Returns:\n            Tuple of (is_valid, document_type)\n        \"\"\"\n        cleaned = CPFCNPJValidator.clean(value)\n\n        if len(cleaned) == 11:\n            return CPFCNPJValidator.validate_cpf(cleaned), \"CPF\"\n        elif len(cleaned) == 14:\n            return CPFCNPJValidator.validate_cnpj(cleaned), \"CNPJ\"\n        else:\n            return False, None\n\n    @staticmethod\n    def format_cpf(cpf: str) -> str:\n        \"\"\"Format CPF as XXX.XXX.XXX-XX.\"\"\"\n        cleaned = CPFCNPJValidator.clean(cpf)\n        return f\"{cleaned[:3]}.{cleaned[3:6]}.{cleaned[6:9]}-{cleaned[9:]}\"\n\n    @staticmethod\n    def format_cnpj(cnpj: str) -> str:\n        \"\"\"Format CNPJ as XX.XXX.XXX/XXXX-XX.\"\"\"\n        cleaned = CPFCNPJValidator.clean(cnpj)\n        return f\"{cleaned[:2]}.{cleaned[2:5]}.{cleaned[5:8]}/{cleaned[8:12]}-{cleaned[12:]}\"\n```\n\n### 2. Boleto Entity and Generation\n\n```python\n# src/domain/modules/boleto/entity.py\nfrom dataclasses import dataclass\nfrom datetime import date, datetime\nfrom decimal import Decimal\n\n@dataclass\nclass Boleto:\n    \"\"\"Boleto bancário domain entity.\n\n    Represents a Brazilian bank slip payment.\n    \"\"\"\n    id: int | None\n    numero_documento: str  # Document number\n    valor_principal: Decimal  # Principal amount\n    valor_desconto: Decimal  # Discount amount\n    valor_multa: Decimal  # Late fee\n    valor_juros: Decimal  # Interest\n    data_vencimento: date  # Due date\n    data_emissao: date  # Issue date\n    nosso_numero: str  # Bank's reference number\n    codigo_barras: str  # Barcode number\n    linha_digitavel: str  # Typeable line\n    pagador_cpf_cnpj: str  # Payer tax ID\n    pagador_nome: str  # Payer name\n    pagador_endereco: str | None  # Payer address\n    beneficiario_nome: str  # Beneficiary name\n    beneficiario_cpf_cnpj: str  # Beneficiary tax ID\n    instrucoes: str | None  # Payment instructions\n    created_at: datetime\n    status: str = \"PENDENTE\"  # PENDENTE, PAGO, CANCELADO, VENCIDO\n\n    @property\n    def valor_total(self) -> Decimal:\n        \"\"\"Calculate total amount including fees.\"\"\"\n        return (\n            self.valor_principal\n            + self.valor_multa\n            + self.valor_juros\n            - self.valor_desconto\n        )\n\n    @property\n    def esta_vencido(self) -> bool:\n        \"\"\"Check if boleto is past due date.\"\"\"\n        return date.today() > self.data_vencimento\n\n    def aplicar_multa_juros(self, dias_atraso: int) -> None:\n        \"\"\"Apply late fees based on days overdue.\n\n        Business rule: 2% late fee + 0.033% daily interest.\n        \"\"\"\n        if dias_atraso > 0:\n            # 2% late fee\n            self.valor_multa = self.valor_principal * Decimal(\"0.02\")\n            # 0.033% daily interest (1% per month / 30 days)\n            self.valor_juros = (\n                self.valor_principal * Decimal(\"0.00033\") * dias_atraso\n            )\n\n\n# src/domain/modules/boleto/generator.py\nfrom abc import ABC, abstractmethod\nfrom src.domain.modules.boleto.entity import Boleto\n\nclass IBoletoGenerator(ABC):\n    \"\"\"Abstract interface for boleto generation.\"\"\"\n\n    @abstractmethod\n    async def generate_barcode(self, boleto: Boleto) -> str:\n        \"\"\"Generate barcode number for boleto.\"\"\"\n        pass\n\n    @abstractmethod\n    async def generate_linha_digitavel(self, codigo_barras: str) -> str:\n        \"\"\"Generate typeable line from barcode.\"\"\"\n        pass\n\n    @abstractmethod\n    async def generate_pdf(self, boleto: Boleto) -> bytes:\n        \"\"\"Generate PDF file for boleto.\"\"\"\n        pass\n```\n\n### 3. Boleto Barcode Generation\n\n```python\n# src/domain/modules/boleto/barcode.py\nfrom decimal import Decimal\nfrom datetime import date\n\nclass BoletoBarcode:\n    \"\"\"Generate boleto barcode using FEBRABAN standards.\n\n    Reference: FEBRABAN specification for bank slip barcodes.\n    \"\"\"\n\n    # Base date for boleto calculation (October 7, 1997)\n    BASE_DATE = date(1997, 10, 7)\n\n    @staticmethod\n    def calculate_fator_vencimento(data_vencimento: date) -> str:\n        \"\"\"Calculate fator de vencimento (due date factor).\n\n        Days between base date and due date.\n        \"\"\"\n        days = (data_vencimento - BoletoBarcode.BASE_DATE).days\n        return str(days).zfill(4)\n\n    @staticmethod\n    def format_valor(valor: Decimal) -> str:\n        \"\"\"Format amount for barcode (10 digits, no decimal point).\"\"\"\n        # Convert to cents and remove decimal\n        valor_cents = int(valor * 100)\n        return str(valor_cents).zfill(10)\n\n    @staticmethod\n    def calculate_dv_modulo11(codigo: str) -> int:\n        \"\"\"Calculate check digit using modulo 11 algorithm.\"\"\"\n        sequence = [2, 3, 4, 5, 6, 7, 8, 9]\n        total = 0\n        seq_idx = 0\n\n        # Sum from right to left\n        for digit in reversed(codigo):\n            total += int(digit) * sequence[seq_idx % len(sequence)]\n            seq_idx += 1\n\n        remainder = total % 11\n        dv = 11 - remainder\n\n        # Special cases\n        if dv == 0 or dv == 10 or dv == 11:\n            return 1\n        return dv\n\n    @classmethod\n    def generate(\n        cls,\n        banco: str,  # 3 digits\n        moeda: str,  # 1 digit (9 = Real)\n        data_vencimento: date,\n        valor: Decimal,\n        campo_livre: str,  # 25 digits (bank-specific)\n    ) -> str:\n        \"\"\"Generate 44-digit barcode.\n\n        Format: AAABC.CCCCDE.EEEEE.EEEEEE.FFFFF.FFFFFF.G.HHHH.IIIIIIIIII\n        - AAA: Bank code (3 digits)\n        - B: Currency code (1 digit, always 9 for BRL)\n        - G: Check digit (1 digit)\n        - HHHH: Due date factor (4 digits)\n        - IIIIIIIIII: Amount (10 digits)\n        - Campo livre: 25 digits (bank-specific)\n        \"\"\"\n        # Build barcode without check digit\n        fator_vencimento = cls.calculate_fator_vencimento(data_vencimento)\n        valor_formatado = cls.format_valor(valor)\n\n        # Initial code without DV\n        codigo_sem_dv = (\n            f\"{banco}{moeda}{fator_vencimento}{valor_formatado}{campo_livre}\"\n        )\n\n        # Calculate check digit\n        dv = cls.calculate_dv_modulo11(codigo_sem_dv)\n\n        # Final barcode with DV in position 5\n        codigo_barras = f\"{banco}{moeda}{dv}{fator_vencimento}{valor_formatado}{campo_livre}\"\n\n        return codigo_barras\n\n    @staticmethod\n    def generate_linha_digitavel(codigo_barras: str) -> str:\n        \"\"\"Generate typeable line from barcode.\n\n        Splits barcode into 5 fields with check digits.\n        Format: AAAAA.AAAAA BBBBB.BBBBBB CCCCC.CCCCCC D EEEEEEEEEEEEE\n        \"\"\"\n        # Extract parts from barcode\n        banco_moeda = codigo_barras[0:4]\n        dv_geral = codigo_barras[4]\n        campo_livre = codigo_barras[19:44]\n        fator_vencimento = codigo_barras[5:9]\n        valor = codigo_barras[9:19]\n\n        # Field 1: Bank + Currency + first 5 of campo livre\n        campo1 = banco_moeda + campo_livre[0:5]\n        dv1 = BoletoBarcode.calculate_dv_modulo10(campo1)\n        campo1_formatado = f\"{campo1[0:5]}.{campo1[5:]}{dv1}\"\n\n        # Field 2: Next 10 digits of campo livre\n        campo2 = campo_livre[5:15]\n        dv2 = BoletoBarcode.calculate_dv_modulo10(campo2)\n        campo2_formatado = f\"{campo2[0:5]}.{campo2[5:]}{dv2}\"\n\n        # Field 3: Last 10 digits of campo livre\n        campo3 = campo_livre[15:25]\n        dv3 = BoletoBarcode.calculate_dv_modulo10(campo3)\n        campo3_formatado = f\"{campo3[0:5]}.{campo3[5:]}{dv3}\"\n\n        # Field 4: General check digit\n        campo4 = dv_geral\n\n        # Field 5: Due date factor + amount\n        campo5 = fator_vencimento + valor\n\n        return f\"{campo1_formatado} {campo2_formatado} {campo3_formatado} {campo4} {campo5}\"\n\n    @staticmethod\n    def calculate_dv_modulo10(codigo: str) -> int:\n        \"\"\"Calculate check digit using modulo 10 algorithm.\"\"\"\n        sequence = [2, 1]\n        total = 0\n        seq_idx = 0\n\n        for digit in reversed(codigo):\n            produto = int(digit) * sequence[seq_idx % 2]\n            # If product > 9, sum digits\n            total += produto if produto < 10 else sum(int(d) for d in str(produto))\n            seq_idx += 1\n\n        remainder = total % 10\n        return 0 if remainder == 0 else 10 - remainder\n```\n\n### 4. PIX Payment Integration\n\n```python\n# src/domain/modules/pix/entity.py\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom decimal import Decimal\n\n@dataclass\nclass CobrancaPix:\n    \"\"\"PIX charge entity.\n\n    Represents a PIX instant payment charge.\n    \"\"\"\n    id: int | None\n    txid: str  # Transaction ID (26-35 characters)\n    chave_pix: str  # PIX key (CPF, CNPJ, email, phone, or random)\n    valor: Decimal\n    descricao: str | None\n    qrcode_texto: str  # QR code text (EMV format)\n    qrcode_imagem: str | None  # Base64 encoded image\n    expiracao: int  # Expiration in seconds\n    pagador_cpf_cnpj: str | None\n    status: str  # ATIVA, CONCLUIDA, REMOVIDA_PELO_USUARIO_RECEBEDOR\n    created_at: datetime\n    paid_at: datetime | None = None\n\n    @property\n    def is_expired(self) -> bool:\n        \"\"\"Check if PIX charge has expired.\"\"\"\n        if self.status != \"ATIVA\":\n            return False\n        elapsed = (datetime.now() - self.created_at).total_seconds()\n        return elapsed > self.expiracao\n\n\n# src/domain/modules/pix/payment_strategy.py\nfrom abc import ABC, abstractmethod\nfrom src.domain.modules.pix.entity import CobrancaPix\n\nclass IPixPaymentStrategy(ABC):\n    \"\"\"Abstract interface for PIX payment processing.\"\"\"\n\n    @abstractmethod\n    async def create_charge(\n        self,\n        valor: Decimal,\n        chave_pix: str,\n        descricao: str | None = None,\n        expiracao: int = 3600,\n    ) -> CobrancaPix:\n        \"\"\"Create PIX charge with QR code.\"\"\"\n        pass\n\n    @abstractmethod\n    async def check_payment_status(self, txid: str) -> str:\n        \"\"\"Check payment status by transaction ID.\"\"\"\n        pass\n\n    @abstractmethod\n    async def cancel_charge(self, txid: str) -> bool:\n        \"\"\"Cancel active PIX charge.\"\"\"\n        pass\n```\n\n### 5. Banco do Brasil PIX API Adapter\n\n```python\n# src/infra/payment/bb_pix_adapter.py\nimport base64\nimport httpx\nfrom decimal import Decimal\nfrom datetime import datetime\n\nfrom src.domain.modules.pix.entity import CobrancaPix\nfrom src.domain.modules.pix.payment_strategy import IPixPaymentStrategy\n\nclass BancoDoBrasilPixAdapter(IPixPaymentStrategy):\n    \"\"\"Banco do Brasil PIX API integration.\n\n    Implements PIX payment processing using BB's API.\n    Reference: https://developers.bb.com.br/\n    \"\"\"\n\n    def __init__(\n        self,\n        client_id: str,\n        client_secret: str,\n        developer_key: str,\n        gw_dev_app_key: str,\n        base_url: str = \"https://api.bb.com.br/pix/v2\",\n    ):\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.developer_key = developer_key\n        self.gw_dev_app_key = gw_dev_app_key\n        self.base_url = base_url\n        self._token: str | None = None\n        self._token_expires_at: datetime | None = None\n\n    async def _get_access_token(self) -> str:\n        \"\"\"Obtain OAuth2 access token from BB.\"\"\"\n        if self._token and self._token_expires_at > datetime.now():\n            return self._token\n\n        auth_url = \"https://oauth.bb.com.br/oauth/token\"\n        headers = {\n            \"Authorization\": f\"Basic {self._encode_credentials()}\",\n            \"Content-Type\": \"application/x-www-form-urlencoded\",\n        }\n        data = {\"grant_type\": \"client_credentials\", \"scope\": \"cob.read cob.write\"}\n\n        async with httpx.AsyncClient() as client:\n            response = await client.post(auth_url, headers=headers, data=data)\n            response.raise_for_status()\n            token_data = response.json()\n\n        self._token = token_data[\"access_token\"]\n        expires_in = token_data[\"expires_in\"]\n        self._token_expires_at = datetime.now() + timedelta(seconds=expires_in)\n\n        return self._token\n\n    def _encode_credentials(self) -> str:\n        \"\"\"Encode client credentials for Basic Auth.\"\"\"\n        credentials = f\"{self.client_id}:{self.client_secret}\"\n        return base64.b64encode(credentials.encode()).decode()\n\n    async def create_charge(\n        self,\n        valor: Decimal,\n        chave_pix: str,\n        descricao: str | None = None,\n        expiracao: int = 3600,\n    ) -> CobrancaPix:\n        \"\"\"Create PIX charge using BB API.\n\n        Returns CobrancaPix with QR code data.\n        \"\"\"\n        token = await self._get_access_token()\n        txid = self._generate_txid()\n\n        headers = {\n            \"Authorization\": f\"Bearer {token}\",\n            \"Content-Type\": \"application/json\",\n            \"X-Developer-Application-Key\": self.developer_key,\n            \"gw-dev-app-key\": self.gw_dev_app_key,\n        }\n\n        payload = {\n            \"calendario\": {\"expiracao\": expiracao},\n            \"devedor\": {},  # Optional payer info\n            \"valor\": {\"original\": f\"{valor:.2f}\"},\n            \"chave\": chave_pix,\n            \"solicitacaoPagador\": descricao or \"Pagamento via PIX\",\n        }\n\n        url = f\"{self.base_url}/cob/{txid}\"\n\n        async with httpx.AsyncClient() as client:\n            response = await client.put(url, headers=headers, json=payload)\n            response.raise_for_status()\n            data = response.json()\n\n        # Get QR code\n        qrcode_url = f\"{self.base_url}/cob/{txid}/qrcode\"\n        async with httpx.AsyncClient() as client:\n            qr_response = await client.get(qrcode_url, headers=headers)\n            qr_response.raise_for_status()\n            qr_data = qr_response.json()\n\n        return CobrancaPix(\n            id=None,\n            txid=txid,\n            chave_pix=chave_pix,\n            valor=valor,\n            descricao=descricao,\n            qrcode_texto=qr_data[\"qrcode\"],\n            qrcode_imagem=qr_data.get(\"imagemQrcode\"),\n            expiracao=expiracao,\n            pagador_cpf_cnpj=None,\n            status=data[\"status\"],\n            created_at=datetime.now(),\n        )\n\n    async def check_payment_status(self, txid: str) -> str:\n        \"\"\"Check PIX charge status.\"\"\"\n        token = await self._get_access_token()\n        headers = {\n            \"Authorization\": f\"Bearer {token}\",\n            \"X-Developer-Application-Key\": self.developer_key,\n            \"gw-dev-app-key\": self.gw_dev_app_key,\n        }\n\n        url = f\"{self.base_url}/cob/{txid}\"\n\n        async with httpx.AsyncClient() as client:\n            response = await client.get(url, headers=headers)\n            response.raise_for_status()\n            data = response.json()\n\n        return data[\"status\"]\n\n    async def cancel_charge(self, txid: str) -> bool:\n        \"\"\"Cancel PIX charge (not supported by BB, returns False).\"\"\"\n        # BB API doesn't support cancellation, charge expires automatically\n        return False\n\n    @staticmethod\n    def _generate_txid() -> str:\n        \"\"\"Generate unique transaction ID (26-35 characters alphanumeric).\"\"\"\n        import uuid\n        return str(uuid.uuid4()).replace(\"-\", \"\")[:35]\n```\n\n### 6. Parcelamento (Installment) Calculation\n\n```python\n# src/domain/modules/parcelamento/calculator.py\nfrom decimal import Decimal, ROUND_HALF_UP\nfrom datetime import date\nfrom dateutil.relativedelta import relativedelta\n\nclass ParcelamentoCalculator:\n    \"\"\"Calculate installment payments with interest.\n\n    Implements Brazilian installment payment calculations.\n    \"\"\"\n\n    @staticmethod\n    def calculate_parcelas(\n        valor_total: Decimal,\n        numero_parcelas: int,\n        taxa_juros_mensal: Decimal = Decimal(\"0\"),\n        data_primeira_parcela: date | None = None,\n    ) -> list[dict]:\n        \"\"\"Calculate installment schedule.\n\n        Args:\n            valor_total: Total amount to be split\n            numero_parcelas: Number of installments\n            taxa_juros_mensal: Monthly interest rate (0.05 = 5%)\n            data_primeira_parcela: First installment due date\n\n        Returns:\n            List of installment dictionaries with valor and vencimento\n        \"\"\"\n        if data_primeira_parcela is None:\n            data_primeira_parcela = date.today() + relativedelta(months=1)\n\n        parcelas = []\n\n        if taxa_juros_mensal == 0:\n            # Simple division without interest\n            valor_parcela = (valor_total / numero_parcelas).quantize(\n                Decimal(\"0.01\"), rounding=ROUND_HALF_UP\n            )\n            resto = valor_total - (valor_parcela * numero_parcelas)\n\n            for i in range(numero_parcelas):\n                vencimento = data_primeira_parcela + relativedelta(months=i)\n                valor = valor_parcela\n                # Add remaining cents to last installment\n                if i == numero_parcelas - 1:\n                    valor += resto\n\n                parcelas.append({\n                    \"numero\": i + 1,\n                    \"valor\": valor,\n                    \"vencimento\": vencimento,\n                })\n        else:\n            # Price table calculation (tabela price)\n            taxa = taxa_juros_mensal\n            fator = ((1 + taxa) ** numero_parcelas * taxa) / (\n                (1 + taxa) ** numero_parcelas - 1\n            )\n            valor_parcela = (valor_total * fator).quantize(\n                Decimal(\"0.01\"), rounding=ROUND_HALF_UP\n            )\n\n            saldo_devedor = valor_total\n\n            for i in range(numero_parcelas):\n                vencimento = data_primeira_parcela + relativedelta(months=i)\n                juros = (saldo_devedor * taxa).quantize(\n                    Decimal(\"0.01\"), rounding=ROUND_HALF_UP\n                )\n                amortizacao = valor_parcela - juros\n\n                # Last installment adjustment\n                if i == numero_parcelas - 1:\n                    amortizacao = saldo_devedor\n                    valor_parcela = amortizacao + juros\n\n                parcelas.append({\n                    \"numero\": i + 1,\n                    \"valor\": valor_parcela,\n                    \"valor_amortizacao\": amortizacao,\n                    \"valor_juros\": juros,\n                    \"saldo_devedor\": saldo_devedor,\n                    \"vencimento\": vencimento,\n                })\n\n                saldo_devedor -= amortizacao\n\n        return parcelas\n\n    @staticmethod\n    def calculate_discount_for_pix(\n        valor_total: Decimal,\n        percentual_desconto: Decimal = Decimal(\"0.025\"),  # 2.5%\n    ) -> tuple[Decimal, Decimal]:\n        \"\"\"Calculate PIX discount.\n\n        Args:\n            valor_total: Total amount\n            percentual_desconto: Discount percentage (default 2.5%)\n\n        Returns:\n            Tuple of (discounted_amount, discount_value)\n        \"\"\"\n        desconto = (valor_total * percentual_desconto).quantize(\n            Decimal(\"0.01\"), rounding=ROUND_HALF_UP\n        )\n        valor_com_desconto = valor_total - desconto\n        return valor_com_desconto, desconto\n```\n\n### 7. Brazilian Currency and Date Helpers\n\n```python\n# src/domain/modules/shared/currency.py\nfrom decimal import Decimal\nfrom datetime import date\n\nclass BrazilianCurrency:\n    \"\"\"Brazilian Real (BRL) formatting helpers.\"\"\"\n\n    @staticmethod\n    def format(valor: Decimal) -> str:\n        \"\"\"Format amount as Brazilian Real.\n\n        Example: Decimal(\"1234.56\") -> \"R$ 1.234,56\"\n        \"\"\"\n        valor_str = f\"{valor:,.2f}\"\n        # Swap , and . for Brazilian format\n        valor_br = valor_str.replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n        return f\"R$ {valor_br}\"\n\n    @staticmethod\n    def parse(valor_str: str) -> Decimal:\n        \"\"\"Parse Brazilian Real string to Decimal.\n\n        Example: \"R$ 1.234,56\" -> Decimal(\"1234.56\")\n        \"\"\"\n        # Remove currency symbol and spaces\n        cleaned = valor_str.replace(\"R$\", \"\").replace(\" \", \"\")\n        # Convert to standard format\n        standard = cleaned.replace(\".\", \"\").replace(\",\", \".\")\n        return Decimal(standard)\n\n\nclass BrazilianDate:\n    \"\"\"Brazilian date formatting helpers.\"\"\"\n\n    @staticmethod\n    def format(data: date) -> str:\n        \"\"\"Format date as DD/MM/YYYY.\"\"\"\n        return data.strftime(\"%d/%m/%Y\")\n\n    @staticmethod\n    def parse(data_str: str) -> date:\n        \"\"\"Parse DD/MM/YYYY string to date.\"\"\"\n        return datetime.strptime(data_str, \"%d/%m/%Y\").date()\n\n    @staticmethod\n    def extenso(data: date) -> str:\n        \"\"\"Format date in Brazilian Portuguese long form.\n\n        Example: date(2024, 1, 15) -> \"15 de janeiro de 2024\"\n        \"\"\"\n        meses = [\n            \"janeiro\", \"fevereiro\", \"março\", \"abril\", \"maio\", \"junho\",\n            \"julho\", \"agosto\", \"setembro\", \"outubro\", \"novembro\", \"dezembro\"\n        ]\n        dia = data.day\n        mes = meses[data.month - 1]\n        ano = data.year\n        return f\"{dia} de {mes} de {ano}\"\n```\n\n## Database Schema Patterns\n\n### Boleto Table (ptBR naming)\n\n```sql\nCREATE TABLE boleto (\n    id SERIAL PRIMARY KEY,\n    numero_documento VARCHAR(20) NOT NULL UNIQUE,\n    valor_principal DECIMAL(10, 2) NOT NULL,\n    valor_desconto DECIMAL(10, 2) DEFAULT 0,\n    valor_multa DECIMAL(10, 2) DEFAULT 0,\n    valor_juros DECIMAL(10, 2) DEFAULT 0,\n    data_vencimento DATE NOT NULL,\n    data_emissao DATE NOT NULL DEFAULT CURRENT_DATE,\n    nosso_numero VARCHAR(20) NOT NULL UNIQUE,\n    codigo_barras VARCHAR(44) NOT NULL,\n    linha_digitavel VARCHAR(54) NOT NULL,\n    pagador_cpf_cnpj VARCHAR(14) NOT NULL,\n    pagador_nome VARCHAR(100) NOT NULL,\n    pagador_endereco TEXT,\n    beneficiario_nome VARCHAR(100) NOT NULL,\n    beneficiario_cpf_cnpj VARCHAR(14) NOT NULL,\n    instrucoes TEXT,\n    status VARCHAR(20) DEFAULT 'PENDENTE',\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    CONSTRAINT chk_status CHECK (status IN ('PENDENTE', 'PAGO', 'CANCELADO', 'VENCIDO'))\n);\n\nCREATE INDEX idx_boleto_cpf_cnpj ON boleto(pagador_cpf_cnpj);\nCREATE INDEX idx_boleto_vencimento ON boleto(data_vencimento);\nCREATE INDEX idx_boleto_status ON boleto(status);\n```\n\n### PIX Table\n\n```sql\nCREATE TABLE cobranca_pix (\n    id SERIAL PRIMARY KEY,\n    txid VARCHAR(35) NOT NULL UNIQUE,\n    chave_pix VARCHAR(100) NOT NULL,\n    valor DECIMAL(10, 2) NOT NULL,\n    descricao TEXT,\n    qrcode_texto TEXT NOT NULL,\n    qrcode_imagem TEXT,\n    expiracao INTEGER NOT NULL DEFAULT 3600,\n    pagador_cpf_cnpj VARCHAR(14),\n    status VARCHAR(50) DEFAULT 'ATIVA',\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    paid_at TIMESTAMP,\n\n    CONSTRAINT chk_pix_status CHECK (status IN ('ATIVA', 'CONCLUIDA', 'REMOVIDA_PELO_USUARIO_RECEBEDOR'))\n);\n\nCREATE INDEX idx_pix_txid ON cobranca_pix(txid);\nCREATE INDEX idx_pix_status ON cobranca_pix(status);\n```\n\n### Parcelamento Table\n\n```sql\nCREATE TABLE parcelamento (\n    id SERIAL PRIMARY KEY,\n    tipo_cobranca_id INTEGER NOT NULL,\n    numero_parcelas INTEGER NOT NULL,\n    valor_total DECIMAL(10, 2) NOT NULL,\n    taxa_juros_mensal DECIMAL(5, 4) DEFAULT 0,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n\n    FOREIGN KEY (tipo_cobranca_id) REFERENCES tipo_cobranca(id)\n);\n\nCREATE TABLE parcela (\n    id SERIAL PRIMARY KEY,\n    parcelamento_id INTEGER,\n    boleto_id INTEGER,\n    pix_id INTEGER,\n    numero INTEGER NOT NULL,\n    valor DECIMAL(10, 2) NOT NULL,\n    valor_amortizacao DECIMAL(10, 2),\n    valor_juros DECIMAL(10, 2),\n    data_vencimento DATE NOT NULL,\n    status VARCHAR(20) DEFAULT 'PENDENTE',\n\n    FOREIGN KEY (parcelamento_id) REFERENCES parcelamento(id),\n    FOREIGN KEY (boleto_id) REFERENCES boleto(id),\n    FOREIGN KEY (pix_id) REFERENCES cobranca_pix(id),\n\n    -- Constraint: parcela must have either boleto_id OR pix_id, not both\n    CONSTRAINT chk_payment_method CHECK (\n        (boleto_id IS NOT NULL AND pix_id IS NULL) OR\n        (boleto_id IS NULL AND pix_id IS NOT NULL)\n    )\n);\n```\n\n## API Endpoint Examples\n\n### Boleto Endpoints\n\n```python\n# src/api/path/boleto.py\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom dependency_injector.wiring import inject, Provide\n\nfrom src.api.schemas.boleto import BoletoCreateRequest, BoletoResponse\nfrom src.domain.modules.boleto.service import IBoletoService\nfrom src.config.dependency import Container\n\nrouter = APIRouter(prefix=\"/v1/boletos\", tags=[\"boletos\"])\n\n@router.post(\"/\", response_model=BoletoResponse, status_code=status.HTTP_201_CREATED)\n@inject\nasync def create_boleto(\n    request: BoletoCreateRequest,\n    service: IBoletoService = Depends(Provide[Container.boleto_service]),\n):\n    \"\"\"Create new boleto bank slip.\"\"\"\n    boleto = await service.create_boleto(\n        valor_principal=request.valor_principal,\n        data_vencimento=request.data_vencimento,\n        pagador_cpf_cnpj=request.pagador_cpf_cnpj,\n        pagador_nome=request.pagador_nome,\n    )\n    return BoletoResponse.from_entity(boleto)\n\n@router.get(\"/{boleto_id}/pdf\")\n@inject\nasync def download_boleto_pdf(\n    boleto_id: int,\n    service: IBoletoService = Depends(Provide[Container.boleto_service]),\n):\n    \"\"\"Download boleto PDF file.\"\"\"\n    pdf_bytes = await service.generate_pdf(boleto_id)\n\n    return Response(\n        content=pdf_bytes,\n        media_type=\"application/pdf\",\n        headers={\"Content-Disposition\": f\"attachment; filename=boleto_{boleto_id}.pdf\"},\n    )\n```\n\n### PIX Endpoints\n\n```python\n# src/api/path/pix.py\n@router.post(\"/cobrancas\", response_model=PixCobrancaResponse)\n@inject\nasync def create_pix_charge(\n    request: PixCobrancaRequest,\n    service: IPixService = Depends(Provide[Container.pix_service]),\n):\n    \"\"\"Create PIX charge with QR code.\"\"\"\n    cobranca = await service.create_charge(\n        valor=request.valor,\n        chave_pix=request.chave_pix,\n        descricao=request.descricao,\n        expiracao=request.expiracao or 3600,\n    )\n    return PixCobrancaResponse.from_entity(cobranca)\n\n@router.get(\"/cobrancas/{txid}/status\")\n@inject\nasync def check_pix_status(\n    txid: str,\n    service: IPixService = Depends(Provide[Container.pix_service]),\n):\n    \"\"\"Check PIX payment status.\"\"\"\n    status = await service.check_payment_status(txid)\n    return {\"txid\": txid, \"status\": status}\n```\n\n## Best Practices\n\n### CPF/CNPJ Handling\n- ✅ Always validate before storing\n- ✅ Store in cleaned format (numbers only)\n- ✅ Format for display using helper functions\n- ✅ Index CPF/CNPJ columns for performance\n- ✅ Handle null values properly (not all entities require tax ID)\n\n### Boleto Generation\n- ✅ Use FEBRABAN standards for barcode\n- ✅ Validate all required fields before generation\n- ✅ Store nosso_numero (bank reference) for tracking\n- ✅ Generate PDF asynchronously for better performance\n- ✅ Implement proper late fee calculations\n\n### PIX Integration\n- ✅ Cache OAuth tokens to reduce API calls\n- ✅ Handle token expiration gracefully\n- ✅ Implement webhook for payment notifications\n- ✅ Set reasonable expiration times (default 1 hour)\n- ✅ Log all API interactions for debugging\n\n### Parcelamento\n- ✅ Use Decimal for all monetary calculations\n- ✅ Round using ROUND_HALF_UP for consistency\n- ✅ Adjust last installment for rounding differences\n- ✅ Support both simple and compound interest\n- ✅ Validate minimum installment amounts\n\n### Database\n- ✅ Use ptBR naming for Brazilian-specific fields\n- ✅ Add check constraints for status fields\n- ✅ Index frequently queried columns (CPF, status, dates)\n- ✅ Use DECIMAL(10,2) for currency values\n- ✅ Store dates without timezone for due dates\n\n## Testing Strategy\n\n```python\n# tests/domain/modules/shared/test_cpf_cnpj_validator.py\ndef test_validate_valid_cpf():\n    \"\"\"Test valid CPF validation.\"\"\"\n    assert CPFCNPJValidator.validate_cpf(\"12345678909\") is True\n    assert CPFCNPJValidator.validate_cpf(\"123.456.789-09\") is True\n\ndef test_validate_invalid_cpf():\n    \"\"\"Test invalid CPF validation.\"\"\"\n    assert CPFCNPJValidator.validate_cpf(\"11111111111\") is False\n    assert CPFCNPJValidator.validate_cpf(\"12345678900\") is False\n\ndef test_validate_valid_cnpj():\n    \"\"\"Test valid CNPJ validation.\"\"\"\n    assert CPFCNPJValidator.validate_cnpj(\"11222333000181\") is True\n\n# tests/domain/modules/boleto/test_barcode.py\ndef test_generate_barcode():\n    \"\"\"Test boleto barcode generation.\"\"\"\n    codigo = BoletoBarcode.generate(\n        banco=\"001\",\n        moeda=\"9\",\n        data_vencimento=date(2024, 12, 31),\n        valor=Decimal(\"100.00\"),\n        campo_livre=\"1234567890123456789012345\",\n    )\n    assert len(codigo) == 44\n    assert codigo[0:3] == \"001\"  # Bank code\n    assert codigo[3] == \"9\"  # Currency\n\n# tests/domain/modules/parcelamento/test_calculator.py\ndef test_calculate_parcelas_without_interest():\n    \"\"\"Test simple installment calculation.\"\"\"\n    parcelas = ParcelamentoCalculator.calculate_parcelas(\n        valor_total=Decimal(\"1000.00\"),\n        numero_parcelas=10,\n        taxa_juros_mensal=Decimal(\"0\"),\n    )\n    assert len(parcelas) == 10\n    assert all(p[\"valor\"] == Decimal(\"100.00\") for p in parcelas)\n```\n\n## Common Pitfalls\n\n1. **Floating Point for Currency**\n   - ❌ Never use `float` for money\n   - ✅ Always use `Decimal` type\n\n2. **CPF/CNPJ Formatting in Database**\n   - ❌ Don't store formatted values (with dots/dashes)\n   - ✅ Store cleaned numeric values, format on display\n\n3. **Timezone Issues**\n   - ❌ Don't use timezone-aware dates for vencimento\n   - ✅ Use plain `date` type for due dates\n\n4. **Rounding Errors**\n   - ❌ Don't ignore cents in installment calculations\n   - ✅ Adjust last installment for rounding differences\n\n5. **API Token Management**\n   - ❌ Don't request new token for every API call\n   - ✅ Cache tokens and refresh before expiration\n\n## References\n\n- [FEBRABAN Barcode Standard](https://portal.febraban.org.br/)\n- [Banco do Brasil PIX API](https://developers.bb.com.br/)\n- [CPF Validation Algorithm](http://www.receita.fazenda.gov.br/)\n- [CNPJ Validation Algorithm](http://www.receita.fazenda.gov.br/)\n- [Brazilian Central Bank - PIX](https://www.bcb.gov.br/estabilidadefinanceira/pix)\n\n## Production Examples\n\nBased on patterns from:\n- **GEFIN Backend**: Boleto, PIX, and parcelamento implementations\n- **Brazilian Banking Standards**: FEBRABAN compliance\n- **Banco do Brasil API**: Production-tested PIX integration"
              },
              {
                "name": "fastapi-clean-architecture",
                "description": "Build FastAPI applications using Clean Architecture principles with proper layer separation (Domain, Infrastructure, API), dependency injection, repository pattern, and comprehensive testing. Use this skill when designing or implementing Python backend services that require maintainability, testability, and scalability.",
                "path": "skills/fastapi-clean-architecture/SKILL.md",
                "frontmatter": {
                  "name": "fastapi-clean-architecture",
                  "description": "Build FastAPI applications using Clean Architecture principles with proper layer separation (Domain, Infrastructure, API), dependency injection, repository pattern, and comprehensive testing. Use this skill when designing or implementing Python backend services that require maintainability, testability, and scalability."
                },
                "content": "# FastAPI Clean Architecture Skill\n\n## Overview\n\nThis skill guides you in building FastAPI applications following Clean Architecture principles, based on production patterns from enterprise financial systems. It emphasizes proper layer separation, dependency injection, repository patterns, and comprehensive testing strategies.\n\n## When to Use This Skill\n\n- Starting a new FastAPI project requiring clean architecture\n- Refactoring existing FastAPI code for better maintainability\n- Implementing domain-driven design with FastAPI\n- Building testable, scalable backend services\n- Integrating multiple data sources (PostgreSQL, Redis, external APIs)\n\n## Core Architecture Principles\n\n### Three-Layer Architecture\n\n```\nsrc/\n├── api/              # API Layer (Controllers, Routes, DTOs)\n├── domain/           # Domain Layer (Business Logic, Entities, Services)\n└── infra/            # Infrastructure Layer (Database, External Services)\n```\n\n**Layer Responsibilities:**\n\n1. **API Layer** (`src/api/`)\n   - HTTP endpoints and routing\n   - Request/Response DTOs (Pydantic models)\n   - Input validation\n   - Authentication/Authorization middleware\n   - Error handling and HTTP status codes\n\n2. **Domain Layer** (`src/domain/`)\n   - Business entities and value objects\n   - Service interfaces (abstract classes)\n   - Business rules and validation\n   - Domain exceptions\n   - Pure business logic (framework-agnostic)\n\n3. **Infrastructure Layer** (`src/infra/`)\n   - Database repositories (SQLAlchemy)\n   - External API adapters\n   - Cache implementations (Redis)\n   - File storage adapters\n   - Concrete service implementations\n\n### Dependency Flow\n\n```\nAPI Layer → Domain Layer ← Infrastructure Layer\n```\n\n**Critical Rules:**\n- API depends on Domain (imports domain services/entities)\n- Infrastructure implements Domain interfaces\n- Domain NEVER imports from API or Infrastructure\n- Use dependency injection to wire everything together\n\n## Project Structure Template\n\n```\nproject-name/\n├── src/\n│   ├── api/\n│   │   ├── path/              # Route modules\n│   │   │   ├── users.py\n│   │   │   ├── auth.py\n│   │   │   └── financial.py\n│   │   ├── middlewares/       # Custom middleware\n│   │   │   ├── auth.py\n│   │   │   └── error_handler.py\n│   │   └── schemas/           # Request/Response DTOs\n│   │       ├── user.py\n│   │       └── financial.py\n│   ├── domain/\n│   │   ├── modules/           # Business modules\n│   │   │   ├── user/\n│   │   │   │   ├── entity.py       # User entity\n│   │   │   │   ├── service.py      # IUserService (abstract)\n│   │   │   │   ├── repository.py   # IUserRepository (abstract)\n│   │   │   │   └── exceptions.py   # Domain exceptions\n│   │   │   └── financial/\n│   │   │       ├── entity.py\n│   │   │       ├── service.py\n│   │   │       └── value_objects.py\n│   │   └── shared/            # Shared domain logic\n│   │       ├── base_entity.py\n│   │       └── exceptions.py\n│   ├── infra/\n│   │   ├── database/\n│   │   │   ├── alchemist/     # SQLAlchemy implementations\n│   │   │   │   ├── modules/\n│   │   │   │   │   ├── user/\n│   │   │   │   │   │   └── repository.py  # UserRepository\n│   │   │   │   │   └── financial/\n│   │   │   │   │       └── repository.py\n│   │   │   │   └── session.py\n│   │   │   └── migrations/    # Database migrations\n│   │   ├── adapters/          # External service adapters\n│   │   │   ├── auth/\n│   │   │   │   └── sso_adapter.py\n│   │   │   └── payment/\n│   │   │       └── payment_gateway.py\n│   │   ├── cache/             # Redis implementations\n│   │   │   └── redis_cache.py\n│   │   └── services/          # Service implementations\n│   │       ├── user_service.py\n│   │       └── financial_service.py\n│   ├── config/\n│   │   ├── settings.py        # Environment configuration\n│   │   ├── dependency.py      # DI Container\n│   │   └── database.py        # DB configuration\n│   └── main.py                # FastAPI app entry point\n├── tests/\n│   ├── api/                   # API integration tests\n│   ├── domain/                # Domain unit tests\n│   ├── infra/                 # Infrastructure tests\n│   └── conftest.py            # Pytest fixtures\n├── pyproject.toml\n├── Dockerfile\n├── docker-compose.yml\n└── README.md\n```\n\n## Implementation Patterns\n\n### 1. Domain Entity Pattern\n\n```python\n# src/domain/modules/user/entity.py\nfrom dataclasses import dataclass\nfrom datetime import datetime\n\n@dataclass\nclass User:\n    \"\"\"Domain entity representing a user.\n\n    Pure business logic with no framework dependencies.\n    \"\"\"\n    id: int | None\n    cpf: str\n    name: str\n    email: str\n    created_at: datetime\n    is_active: bool = True\n\n    def deactivate(self) -> None:\n        \"\"\"Business rule: Deactivate user account.\"\"\"\n        if not self.is_active:\n            raise UserAlreadyInactiveError(f\"User {self.cpf} is already inactive\")\n        self.is_active = False\n\n    def validate_cpf(self) -> bool:\n        \"\"\"Business rule: Validate CPF format.\"\"\"\n        cleaned = ''.join(filter(str.isdigit, self.cpf))\n        return len(cleaned) == 11 and not all(c == cleaned[0] for c in cleaned)\n```\n\n### 2. Repository Interface Pattern\n\n```python\n# src/domain/modules/user/repository.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nfrom src.domain.modules.user.entity import User\n\nclass IUserRepository(ABC):\n    \"\"\"Abstract repository interface in domain layer.\n\n    Defines contract without implementation details.\n    \"\"\"\n\n    @abstractmethod\n    async def get_by_id(self, user_id: int) -> User | None:\n        \"\"\"Retrieve user by ID.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_by_cpf(self, cpf: str) -> User | None:\n        \"\"\"Retrieve user by CPF.\"\"\"\n        pass\n\n    @abstractmethod\n    async def create(self, user: User) -> User:\n        \"\"\"Create new user.\"\"\"\n        pass\n\n    @abstractmethod\n    async def update(self, user: User) -> User:\n        \"\"\"Update existing user.\"\"\"\n        pass\n\n    @abstractmethod\n    async def list_active(self, limit: int = 100) -> List[User]:\n        \"\"\"List all active users.\"\"\"\n        pass\n```\n\n### 3. Service Interface Pattern\n\n```python\n# src/domain/modules/user/service.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n\nfrom src.domain.modules.user.entity import User\n\nclass IUserService(ABC):\n    \"\"\"Abstract service interface defining business operations.\"\"\"\n\n    @abstractmethod\n    async def register_user(self, cpf: str, name: str, email: str) -> User:\n        \"\"\"Register new user with validation.\"\"\"\n        pass\n\n    @abstractmethod\n    async def deactivate_user(self, cpf: str) -> User:\n        \"\"\"Deactivate user account.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_user_profile(self, cpf: str) -> User:\n        \"\"\"Get user profile by CPF.\"\"\"\n        pass\n```\n\n### 4. Concrete Repository Implementation\n\n```python\n# src/infra/database/alchemist/modules/user/repository.py\nfrom typing import List\nfrom sqlalchemy import select, text\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom src.domain.modules.user.entity import User\nfrom src.domain.modules.user.repository import IUserRepository\nfrom src.infra.database.alchemist.models import UserModel\n\nclass UserRepository(IUserRepository):\n    \"\"\"SQLAlchemy implementation of user repository.\n\n    Handles database operations and entity mapping.\n    \"\"\"\n\n    def __init__(self, session: AsyncSession):\n        self._session = session\n\n    async def get_by_id(self, user_id: int) -> User | None:\n        \"\"\"Retrieve user by ID.\"\"\"\n        result = await self._session.execute(\n            select(UserModel).where(UserModel.id == user_id)\n        )\n        model = result.scalar_one_or_none()\n        return self._to_entity(model) if model else None\n\n    async def get_by_cpf(self, cpf: str) -> User | None:\n        \"\"\"Retrieve user by CPF.\"\"\"\n        result = await self._session.execute(\n            select(UserModel).where(UserModel.cpf == cpf)\n        )\n        model = result.scalar_one_or_none()\n        return self._to_entity(model) if model else None\n\n    async def create(self, user: User) -> User:\n        \"\"\"Create new user.\"\"\"\n        model = UserModel(\n            cpf=user.cpf,\n            name=user.name,\n            email=user.email,\n            is_active=user.is_active,\n        )\n        self._session.add(model)\n        await self._session.flush()\n        await self._session.refresh(model)\n        return self._to_entity(model)\n\n    async def update(self, user: User) -> User:\n        \"\"\"Update existing user.\"\"\"\n        result = await self._session.execute(\n            select(UserModel).where(UserModel.id == user.id)\n        )\n        model = result.scalar_one()\n        model.name = user.name\n        model.email = user.email\n        model.is_active = user.is_active\n        await self._session.flush()\n        await self._session.refresh(model)\n        return self._to_entity(model)\n\n    async def list_active(self, limit: int = 100) -> List[User]:\n        \"\"\"List all active users.\"\"\"\n        result = await self._session.execute(\n            select(UserModel)\n            .where(UserModel.is_active == True)  # noqa: E712\n            .limit(limit)\n        )\n        models = result.scalars().all()\n        return [self._to_entity(model) for model in models]\n\n    def _to_entity(self, model: UserModel) -> User:\n        \"\"\"Convert database model to domain entity.\"\"\"\n        return User(\n            id=model.id,\n            cpf=model.cpf,\n            name=model.name,\n            email=model.email,\n            created_at=model.created_at,\n            is_active=model.is_active,\n        )\n```\n\n### 5. Concrete Service Implementation\n\n```python\n# src/infra/services/user_service.py\nfrom src.domain.modules.user.entity import User\nfrom src.domain.modules.user.service import IUserService\nfrom src.domain.modules.user.repository import IUserRepository\nfrom src.domain.modules.user.exceptions import (\n    UserAlreadyExistsError,\n    UserNotFoundError,\n    InvalidCPFError,\n)\n\nclass UserService(IUserService):\n    \"\"\"Concrete implementation of user service.\n\n    Orchestrates business logic using repository.\n    \"\"\"\n\n    def __init__(self, user_repository: IUserRepository):\n        self._repository = user_repository\n\n    async def register_user(self, cpf: str, name: str, email: str) -> User:\n        \"\"\"Register new user with validation.\"\"\"\n        # Check if user already exists\n        existing_user = await self._repository.get_by_cpf(cpf)\n        if existing_user:\n            raise UserAlreadyExistsError(f\"User with CPF {cpf} already exists\")\n\n        # Create and validate entity\n        user = User(\n            id=None,\n            cpf=cpf,\n            name=name,\n            email=email,\n            created_at=datetime.now(),\n            is_active=True,\n        )\n\n        if not user.validate_cpf():\n            raise InvalidCPFError(f\"Invalid CPF: {cpf}\")\n\n        # Persist\n        return await self._repository.create(user)\n\n    async def deactivate_user(self, cpf: str) -> User:\n        \"\"\"Deactivate user account.\"\"\"\n        user = await self._repository.get_by_cpf(cpf)\n        if not user:\n            raise UserNotFoundError(f\"User with CPF {cpf} not found\")\n\n        user.deactivate()  # Business logic in entity\n        return await self._repository.update(user)\n\n    async def get_user_profile(self, cpf: str) -> User:\n        \"\"\"Get user profile by CPF.\"\"\"\n        user = await self._repository.get_by_cpf(cpf)\n        if not user:\n            raise UserNotFoundError(f\"User with CPF {cpf} not found\")\n        return user\n```\n\n### 6. Dependency Injection Container\n\n```python\n# src/config/dependency.py\nfrom dependency_injector import containers, providers\nfrom dependency_injector.wiring import Provide, inject\n\nfrom src.infra.database.alchemist.session import get_session\nfrom src.infra.database.alchemist.modules.user.repository import UserRepository\nfrom src.infra.services.user_service import UserService\n\nclass Container(containers.DeclarativeContainer):\n    \"\"\"Dependency injection container.\n\n    Wires together all dependencies.\n    \"\"\"\n\n    wiring_config = containers.WiringConfiguration(\n        modules=[\n            \"src.api.path.users\",\n            \"src.api.path.auth\",\n        ]\n    )\n\n    # Database\n    db_session = providers.Resource(get_session)\n\n    # Repositories\n    user_repository = providers.Factory(\n        UserRepository,\n        session=db_session,\n    )\n\n    # Services\n    user_service = providers.Factory(\n        UserService,\n        user_repository=user_repository,\n    )\n```\n\n### 7. API Endpoint Implementation\n\n```python\n# src/api/path/users.py\nfrom fastapi import APIRouter, Depends, status\nfrom dependency_injector.wiring import inject, Provide\n\nfrom src.api.schemas.user import UserCreateRequest, UserResponse\nfrom src.domain.modules.user.service import IUserService\nfrom src.domain.modules.user.exceptions import UserAlreadyExistsError, InvalidCPFError\nfrom src.config.dependency import Container\n\nrouter = APIRouter(prefix=\"/v1/users\", tags=[\"users\"])\n\n@router.post(\n    \"/\",\n    response_model=UserResponse,\n    status_code=status.HTTP_201_CREATED,\n)\n@inject\nasync def create_user(\n    request: UserCreateRequest,\n    user_service: IUserService = Depends(Provide[Container.user_service]),\n):\n    \"\"\"Create new user endpoint.\n\n    Delegates to service layer for business logic.\n    \"\"\"\n    try:\n        user = await user_service.register_user(\n            cpf=request.cpf,\n            name=request.name,\n            email=request.email,\n        )\n        return UserResponse.from_entity(user)\n    except UserAlreadyExistsError as e:\n        raise HTTPException(status_code=409, detail=str(e))\n    except InvalidCPFError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@router.get(\"/{cpf}\", response_model=UserResponse)\n@inject\nasync def get_user(\n    cpf: str,\n    user_service: IUserService = Depends(Provide[Container.user_service]),\n):\n    \"\"\"Get user by CPF.\"\"\"\n    user = await user_service.get_user_profile(cpf)\n    return UserResponse.from_entity(user)\n```\n\n### 8. Pydantic DTOs (Request/Response)\n\n```python\n# src/api/schemas/user.py\nfrom datetime import datetime\nfrom pydantic import BaseModel, EmailStr, Field\n\nfrom src.domain.modules.user.entity import User\n\nclass UserCreateRequest(BaseModel):\n    \"\"\"Request DTO for user creation.\"\"\"\n    cpf: str = Field(..., min_length=11, max_length=14)\n    name: str = Field(..., min_length=3, max_length=100)\n    email: EmailStr\n\nclass UserResponse(BaseModel):\n    \"\"\"Response DTO for user data.\"\"\"\n    id: int\n    cpf: str\n    name: str\n    email: str\n    created_at: datetime\n    is_active: bool\n\n    @classmethod\n    def from_entity(cls, user: User) -> \"UserResponse\":\n        \"\"\"Convert domain entity to DTO.\"\"\"\n        return cls(\n            id=user.id,\n            cpf=user.cpf,\n            name=user.name,\n            email=user.email,\n            created_at=user.created_at,\n            is_active=user.is_active,\n        )\n```\n\n## Testing Strategy\n\n### Unit Tests (Domain Layer)\n\n```python\n# tests/domain/modules/user/test_entity.py\nimport pytest\nfrom src.domain.modules.user.entity import User\nfrom src.domain.modules.user.exceptions import UserAlreadyInactiveError\n\ndef test_user_deactivation():\n    \"\"\"Test user deactivation business rule.\"\"\"\n    user = User(\n        id=1,\n        cpf=\"12345678901\",\n        name=\"Test User\",\n        email=\"test@example.com\",\n        created_at=datetime.now(),\n        is_active=True,\n    )\n\n    user.deactivate()\n    assert user.is_active is False\n\ndef test_user_already_inactive_raises_error():\n    \"\"\"Test deactivating already inactive user raises error.\"\"\"\n    user = User(\n        id=1,\n        cpf=\"12345678901\",\n        name=\"Test User\",\n        email=\"test@example.com\",\n        created_at=datetime.now(),\n        is_active=False,\n    )\n\n    with pytest.raises(UserAlreadyInactiveError):\n        user.deactivate()\n\ndef test_cpf_validation():\n    \"\"\"Test CPF validation logic.\"\"\"\n    user = User(\n        id=1,\n        cpf=\"12345678901\",\n        name=\"Test User\",\n        email=\"test@example.com\",\n        created_at=datetime.now(),\n    )\n\n    assert user.validate_cpf() is True\n\n    user.cpf = \"11111111111\"  # All same digits\n    assert user.validate_cpf() is False\n```\n\n### Service Tests (Infrastructure Layer)\n\n```python\n# tests/infra/services/test_user_service.py\nimport pytest\nfrom unittest.mock import AsyncMock\n\nfrom src.infra.services.user_service import UserService\nfrom src.domain.modules.user.entity import User\nfrom src.domain.modules.user.exceptions import UserAlreadyExistsError\n\n@pytest.fixture\ndef mock_repository():\n    \"\"\"Mock user repository.\"\"\"\n    return AsyncMock()\n\n@pytest.fixture\ndef user_service(mock_repository):\n    \"\"\"User service with mocked repository.\"\"\"\n    return UserService(user_repository=mock_repository)\n\n@pytest.mark.asyncio\nasync def test_register_user_success(user_service, mock_repository):\n    \"\"\"Test successful user registration.\"\"\"\n    mock_repository.get_by_cpf.return_value = None\n    mock_repository.create.return_value = User(\n        id=1,\n        cpf=\"12345678901\",\n        name=\"Test User\",\n        email=\"test@example.com\",\n        created_at=datetime.now(),\n        is_active=True,\n    )\n\n    user = await user_service.register_user(\n        cpf=\"12345678901\",\n        name=\"Test User\",\n        email=\"test@example.com\",\n    )\n\n    assert user.id == 1\n    assert user.cpf == \"12345678901\"\n    mock_repository.create.assert_called_once()\n\n@pytest.mark.asyncio\nasync def test_register_user_already_exists(user_service, mock_repository):\n    \"\"\"Test registering existing user raises error.\"\"\"\n    mock_repository.get_by_cpf.return_value = User(\n        id=1,\n        cpf=\"12345678901\",\n        name=\"Existing User\",\n        email=\"existing@example.com\",\n        created_at=datetime.now(),\n        is_active=True,\n    )\n\n    with pytest.raises(UserAlreadyExistsError):\n        await user_service.register_user(\n            cpf=\"12345678901\",\n            name=\"Test User\",\n            email=\"test@example.com\",\n        )\n```\n\n### Integration Tests (API Layer)\n\n```python\n# tests/api/test_users.py\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.mark.asyncio\nasync def test_create_user_endpoint(client: AsyncClient):\n    \"\"\"Test user creation endpoint.\"\"\"\n    response = await client.post(\n        \"/v1/users/\",\n        json={\n            \"cpf\": \"12345678901\",\n            \"name\": \"Test User\",\n            \"email\": \"test@example.com\",\n        },\n    )\n\n    assert response.status_code == 201\n    data = response.json()\n    assert data[\"cpf\"] == \"12345678901\"\n    assert data[\"name\"] == \"Test User\"\n\n@pytest.mark.asyncio\nasync def test_create_duplicate_user_returns_409(client: AsyncClient):\n    \"\"\"Test creating duplicate user returns conflict.\"\"\"\n    user_data = {\n        \"cpf\": \"12345678901\",\n        \"name\": \"Test User\",\n        \"email\": \"test@example.com\",\n    }\n\n    # Create first user\n    await client.post(\"/v1/users/\", json=user_data)\n\n    # Try to create duplicate\n    response = await client.post(\"/v1/users/\", json=user_data)\n    assert response.status_code == 409\n```\n\n## Database Session Management\n\n```python\n# src/infra/database/alchemist/session.py\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import (\n    AsyncSession,\n    create_async_engine,\n    async_sessionmaker,\n)\n\nfrom src.config.settings import app_settings\n\n# Engine configuration\nengine = create_async_engine(\n    app_settings.DATABASE_URL,\n    echo=app_settings.DEBUG,\n    pool_size=10,\n    max_overflow=20,\n    pool_recycle=3600,\n)\n\n# Session factory\nAsyncSessionLocal = async_sessionmaker(\n    engine,\n    class_=AsyncSession,\n    expire_on_commit=False,\n    autocommit=False,\n    autoflush=False,\n)\n\n@asynccontextmanager\nasync def get_session() -> AsyncSession:\n    \"\"\"Get database session with automatic cleanup.\n\n    Usage with dependency injection:\n        session = Depends(get_session)\n    \"\"\"\n    async with AsyncSessionLocal() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n        finally:\n            await session.close()\n```\n\n## Configuration Management\n\n```python\n# src/config/settings.py\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\nclass AppSettings(BaseSettings):\n    \"\"\"Application configuration from environment variables.\"\"\"\n\n    model_config = SettingsConfigDict(\n        env_file=\".env\",\n        env_file_encoding=\"utf-8\",\n        case_sensitive=True,\n    )\n\n    # Application\n    APP_NAME: str = \"FastAPI Clean Architecture\"\n    DEBUG: bool = False\n    API_VERSION: str = \"v1\"\n\n    # Database\n    DATABASE_URL: str\n    DB_POOL_SIZE: int = 10\n    DB_MAX_OVERFLOW: int = 20\n\n    # Redis\n    REDIS_URL: str = \"redis://localhost:6379/0\"\n    REDIS_TTL: int = 3600\n\n    # Security\n    JWT_SECRET_KEY: str\n    JWT_ALGORITHM: str = \"RS256\"\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60\n\n    # CORS\n    CORS_ORIGINS: list[str] = [\"*\"]\n    CORS_CREDENTIALS: bool = True\n\napp_settings = AppSettings()\n```\n\n## Main Application Setup\n\n```python\n# src/main.py\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom src.config.settings import app_settings\nfrom src.config.dependency import Container\nfrom src.api.path import users, auth\n\ndef create_app() -> FastAPI:\n    \"\"\"Create and configure FastAPI application.\"\"\"\n\n    # Initialize DI container\n    container = Container()\n\n    # Create app\n    app = FastAPI(\n        title=app_settings.APP_NAME,\n        version=app_settings.API_VERSION,\n        debug=app_settings.DEBUG,\n    )\n\n    # Wire container\n    app.container = container\n\n    # CORS middleware\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=app_settings.CORS_ORIGINS,\n        allow_credentials=app_settings.CORS_CREDENTIALS,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Include routers\n    app.include_router(users.router)\n    app.include_router(auth.router)\n\n    return app\n\napp = create_app()\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\"}\n```\n\n## Best Practices Checklist\n\n### Architecture\n- ✅ Domain layer has NO dependencies on API or Infrastructure\n- ✅ All database logic encapsulated in repositories\n- ✅ Business logic lives in domain entities and services\n- ✅ Infrastructure implements domain interfaces\n- ✅ API layer only handles HTTP concerns\n\n### Dependency Injection\n- ✅ Use `dependency-injector` for IoC container\n- ✅ Wire all dependencies through container\n- ✅ Inject interfaces, not concrete implementations\n- ✅ Use `@inject` decorator on endpoints\n- ✅ Configure wiring for all API modules\n\n### Database\n- ✅ Use SQLAlchemy 2.0 async patterns\n- ✅ Separate ORM models from domain entities\n- ✅ Implement mapper methods (`_to_entity`)\n- ✅ Use connection pooling\n- ✅ Handle transactions properly (commit/rollback)\n\n### Testing\n- ✅ 100% coverage for domain layer (pure logic)\n- ✅ Mock repositories in service tests\n- ✅ Use AsyncMock for async methods\n- ✅ Integration tests for endpoints\n- ✅ Separate test database for integration tests\n\n### Naming Conventions\n- ✅ Entities: PascalCase (`User`, `Order`)\n- ✅ Services: `I{Name}Service` (interface), `{Name}Service` (implementation)\n- ✅ Repositories: `I{Name}Repository` (interface), `{Name}Repository` (implementation)\n- ✅ DTOs: `{Name}Request`, `{Name}Response`\n- ✅ Use ptBR names for database columns if applicable\n\n### Error Handling\n- ✅ Domain exceptions for business rule violations\n- ✅ HTTP exceptions at API layer only\n- ✅ Proper status codes (400, 404, 409, 500)\n- ✅ Meaningful error messages\n- ✅ Global exception handler\n\n## Common Pitfalls to Avoid\n\n1. **Importing Infrastructure in Domain**\n   - ❌ Never import SQLAlchemy models in domain layer\n   - ✅ Use mapper functions to convert between layers\n\n2. **Business Logic in API Layer**\n   - ❌ Never put validation or business rules in endpoints\n   - ✅ Move all logic to services or entities\n\n3. **Tight Coupling**\n   - ❌ Don't instantiate dependencies directly\n   - ✅ Use dependency injection everywhere\n\n4. **Anemic Entities**\n   - ❌ Don't use entities as plain data containers\n   - ✅ Put behavior and validation in entities\n\n5. **Repository Leakage**\n   - ❌ Don't expose SQLAlchemy queries outside repositories\n   - ✅ Return domain entities only\n\n6. **Improper Transaction Management**\n   - ❌ Don't commit/rollback in repositories\n   - ✅ Manage transactions at service or endpoint level\n\n## Migration Guide (Legacy → Clean Architecture)\n\n### Step 1: Create Domain Layer\n1. Extract business entities from database models\n2. Define repository interfaces\n3. Define service interfaces\n4. Move business logic to entities/services\n\n### Step 2: Create Infrastructure Layer\n1. Implement repositories with SQLAlchemy\n2. Create service implementations\n3. Keep database models separate from entities\n\n### Step 3: Refactor API Layer\n1. Create request/response DTOs\n2. Update endpoints to use services\n3. Remove direct database access\n4. Add dependency injection\n\n### Step 4: Testing\n1. Write unit tests for domain layer\n2. Add service tests with mocked repositories\n3. Create integration tests for endpoints\n4. Ensure 100% coverage\n\n## References\n\n- [Clean Architecture by Robert C. Martin](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)\n- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n- [Dependency Injector](https://python-dependency-injector.ets-labs.org/)\n- [SQLAlchemy 2.0](https://docs.sqlalchemy.org/en/20/)\n- [Pydantic](https://docs.pydantic.dev/)\n\n## Production Examples\n\nThis skill is based on patterns from:\n- **GEFIN Backend**: Financial management system with 595+ tests\n- **Clean Architecture**: Domain-driven design principles\n- **Enterprise Best Practices**: Scalability, maintainability, testability"
              },
              {
                "name": "multi-system-sso-authentication",
                "description": "Implement enterprise Single Sign-On (SSO) authentication supporting multiple identity providers with JWT RS256 tokens, backwards verification, session management, and cross-system permission mapping. Use this skill when building authentication systems that integrate with multiple enterprise SSO providers or when implementing secure token validation with session verification.",
                "path": "skills/multi-system-sso-authentication/SKILL.md",
                "frontmatter": {
                  "name": "multi-system-sso-authentication",
                  "description": "Implement enterprise Single Sign-On (SSO) authentication supporting multiple identity providers with JWT RS256 tokens, backwards verification, session management, and cross-system permission mapping. Use this skill when building authentication systems that integrate with multiple enterprise SSO providers or when implementing secure token validation with session verification."
                },
                "content": "# Multi-System SSO Authentication Skill\n\n## Overview\n\nThis skill provides comprehensive patterns for implementing enterprise SSO authentication that supports multiple identity providers. It covers JWT RS256 token validation, backwards verification with authoritative systems, Laravel session decryption, permission mapping, and Redis session management.\n\n## When to Use This Skill\n\n- Integrating with multiple enterprise SSO systems\n- Implementing secure JWT token validation with backwards verification\n- Supporting legacy session-based authentication alongside JWT\n- Building unified authentication adapters for microservices\n- Mapping permissions across different systems\n- Implementing token introspection and revocation\n- Handling OAuth2 flows with multiple providers\n\n## Core Concepts\n\n### Authentication Architecture\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                     Your Application                     │\n│  ┌────────────────────────────────────────────────────┐ │\n│  │          UnifiedAuthAdapter (Router)               │ │\n│  │  ┌──────────────────────────────────────────────┐ │ │\n│  │  │  Check token issuer (iss claim)              │ │ │\n│  │  │  Route to appropriate adapter                │ │ │\n│  │  └──────────────────────────────────────────────┘ │ │\n│  │         ▼          ▼          ▼          ▼        │ │\n│  │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ │ │\n│  │  │  CORP   │ │   SGF   │ │   GED   │ │ CARRINHO│ │ │\n│  │  │ Adapter │ │ Adapter │ │ Adapter │ │ Adapter │ │ │\n│  │  └─────────┘ └─────────┘ └─────────┘ └─────────┘ │ │\n│  └────────────────────────────────────────────────────┘ │\n└─────────────────────────────────────────────────────────┘\n         │             │             │             │\n         ▼             ▼             ▼             ▼\n  ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐\n  │ Corporativo│ │    SGF    │ │    GED    │ │ Carrinho  │\n  │    SSO    │ │    API    │ │    API    │ │    API    │\n  └───────────┘ └───────────┘ └───────────┘ └───────────┘\n```\n\n### Token Flow\n\n1. **User authenticates** with external SSO system\n2. **SSO system issues JWT** with issuer (iss) and audience (aud) claims\n3. **Your app receives token** from request headers\n4. **UnifiedAuthAdapter routes** to appropriate adapter based on issuer\n5. **Adapter validates** JWT signature with public key\n6. **Backwards verification** checks token validity with issuing system\n7. **Permissions mapped** from SSO format to your app's format\n8. **User session created** in Redis for future requests\n\n## Project Structure\n\n```\nsrc/\n├── api/\n│   ├── middlewares/\n│   │   └── auth.py              # AuthMiddleware\n│   └── path/\n│       └── auth.py              # Authentication endpoints\n├── domain/\n│   └── modules/\n│       └── auth/\n│           ├── entity.py        # User entity\n│           ├── session.py       # Session management\n│           └── permissions.py   # Permission definitions\n└── infra/\n    ├── adapters/\n    │   └── auth/\n    │       ├── unified_adapter.py      # Router for all adapters\n    │       ├── corporativo_adapter.py  # Corporativo SSO\n    │       ├── sgf_adapter.py          # SGF integration\n    │       ├── ged_adapter.py          # GED integration\n    │       └── carrinho_adapter.py     # Carrinho integration\n    ├── cache/\n    │   └── redis_session.py     # Redis session storage\n    └── services/\n        └── permission_mapper.py # Permission mapping\n```\n\n## Implementation Patterns\n\n### 1. Unified Authentication Adapter (Router)\n\n```python\n# src/infra/adapters/auth/unified_adapter.py\nfrom typing import Dict, Any\nfrom jose import jwt, JWTError\n\nfrom src.infra.adapters.auth.corporativo_adapter import CorporativoAuthAdapter\nfrom src.infra.adapters.auth.sgf_adapter import SGFAuthAdapter\nfrom src.infra.adapters.auth.ged_adapter import GEDAuthAdapter\nfrom src.infra.adapters.auth.carrinho_adapter import CarrinhoAuthAdapter\nfrom src.config.settings import app_settings\n\nclass UnifiedAuthAdapter:\n    \"\"\"Unified authentication adapter that routes tokens to appropriate SSO adapter.\n\n    Routes based on JWT issuer claim (iss).\n    \"\"\"\n\n    def __init__(\n        self,\n        corporativo_adapter: CorporativoAuthAdapter,\n        sgf_adapter: SGFAuthAdapter,\n        ged_adapter: GEDAuthAdapter,\n        carrinho_adapter: CarrinhoAuthAdapter,\n    ):\n        self.adapters = {\n            \"corporativo\": corporativo_adapter,\n            \"sgf\": sgf_adapter,\n            \"ged\": ged_adapter,\n            \"carrinho\": carrinho_adapter,\n        }\n\n        # Map issuer URLs to adapter names\n        self.issuer_map = {\n            app_settings.CORPORATIVO_API_URL: \"corporativo\",\n            app_settings.SGF_API_URL: \"sgf\",\n            app_settings.GED_API_URL: \"ged\",\n            app_settings.CARRINHO_API_URL: \"carrinho\",\n            \"gefin-backend\": \"corporativo\",  # Self-issued tokens\n        }\n\n    async def validate_token(self, token: str) -> Dict[str, Any]:\n        \"\"\"Validate token and route to appropriate adapter.\n\n        Args:\n            token: JWT token string\n\n        Returns:\n            User data dictionary with permissions\n\n        Raises:\n            JWTError: If token is invalid or from unknown issuer\n        \"\"\"\n        # Decode without verification to check issuer\n        try:\n            unverified = jwt.get_unverified_claims(token)\n            issuer = unverified.get(\"iss\")\n        except JWTError as e:\n            raise JWTError(f\"Invalid JWT format: {e}\")\n\n        # Map issuer to adapter\n        adapter_name = self.issuer_map.get(issuer)\n        if not adapter_name:\n            raise JWTError(f\"Unknown token issuer: {issuer}\")\n\n        # Check if adapter is enabled\n        enabled_systems = app_settings.ENABLED_AUTH_SYSTEMS\n        if adapter_name not in enabled_systems:\n            raise JWTError(f\"Authentication system '{adapter_name}' is disabled\")\n\n        # Route to appropriate adapter\n        adapter = self.adapters[adapter_name]\n        return await adapter.validate_token(token)\n\n    async def validate_session(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Validate session cookie (for legacy systems).\n\n        Routes to Corporativo adapter (primary session provider).\n        \"\"\"\n        return await self.adapters[\"corporativo\"].validate_session(session_id)\n```\n\n### 2. Base Auth Adapter Pattern\n\n```python\n# src/infra/adapters/auth/base_adapter.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any\n\nclass IAuthAdapter(ABC):\n    \"\"\"Abstract base class for authentication adapters.\n\n    All SSO adapters must implement this interface.\n    \"\"\"\n\n    @abstractmethod\n    async def validate_token(self, token: str) -> Dict[str, Any]:\n        \"\"\"Validate JWT token and return user data.\n\n        Args:\n            token: JWT token string\n\n        Returns:\n            User data with permissions\n\n        Raises:\n            JWTError: If token is invalid\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def validate_session(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Validate session ID and return user data.\n\n        Args:\n            session_id: Session identifier\n\n        Returns:\n            User data with permissions\n\n        Raises:\n            SessionError: If session is invalid\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_permissions(self, user_data: Dict[str, Any]) -> list[str]:\n        \"\"\"Extract and map permissions from user data.\n\n        Args:\n            user_data: User data from SSO system\n\n        Returns:\n            List of permission strings in app format\n        \"\"\"\n        pass\n```\n\n### 3. JWT RS256 Token Validation with Backwards Verification\n\n```python\n# src/infra/adapters/auth/corporativo_adapter.py\nimport httpx\nfrom datetime import datetime, timedelta\nfrom jose import jwt, JWTError\n\nfrom src.infra.adapters.auth.base_adapter import IAuthAdapter\nfrom src.infra.cache.redis_session import RedisSessionManager\n\nclass CorporativoAuthAdapter(IAuthAdapter):\n    \"\"\"Corporativo SSO authentication adapter.\n\n    Implements JWT RS256 validation with backwards verification.\n    \"\"\"\n\n    def __init__(\n        self,\n        public_key: str,\n        private_key: str,\n        api_url: str,\n        session_manager: RedisSessionManager,\n    ):\n        self.public_key = public_key\n        self.private_key = private_key\n        self.api_url = api_url\n        self.session_manager = session_manager\n        self._validation_cache: Dict[str, tuple[Dict, datetime]] = {}\n        self._cache_ttl = 30  # 30 seconds\n\n    async def validate_token(self, token: str) -> Dict[str, Any]:\n        \"\"\"Validate JWT token with backwards verification.\n\n        Steps:\n        1. Verify JWT signature with RSA public key\n        2. Check issuer and audience claims\n        3. Perform backwards verification with SSO system\n        4. Map permissions to app format\n        \"\"\"\n        try:\n            # Verify signature and decode token\n            payload = jwt.decode(\n                token,\n                self.public_key,\n                algorithms=[\"RS256\"],\n                options={\"verify_iss\": False, \"verify_aud\": False},  # Manual validation\n            )\n\n            # Manual issuer validation\n            accepted_issuers = [\"gefin-backend\", self.api_url]\n            if payload.get(\"iss\") not in accepted_issuers:\n                raise JWTError(f\"Invalid issuer: {payload.get('iss')}\")\n\n            # Manual audience validation\n            accepted_audiences = [\"gefin-api\", \"gefin\"]\n            aud = payload.get(\"aud\")\n            if isinstance(aud, list):\n                if not any(a in accepted_audiences for a in aud):\n                    raise JWTError(f\"Invalid audience: {aud}\")\n            elif aud not in accepted_audiences:\n                raise JWTError(f\"Invalid audience: {aud}\")\n\n            # Check expiration\n            exp = payload.get(\"exp\")\n            if exp and datetime.fromtimestamp(exp) < datetime.now():\n                raise JWTError(\"Token has expired\")\n\n            # Backwards verification (if not self-issued)\n            if payload.get(\"iss\") != \"gefin-backend\":\n                await self._verify_with_corporativo(token, payload)\n\n            return payload\n\n        except JWTError as e:\n            raise JWTError(f\"Token validation failed: {e}\")\n\n    async def _verify_with_corporativo(\n        self,\n        token: str,\n        payload: Dict[str, Any]\n    ) -> None:\n        \"\"\"Verify token validity with Corporativo SSO system.\n\n        Implements backwards verification with caching.\n        \"\"\"\n        # Check cache first\n        cache_key = payload.get(\"sub\")\n        if cache_key in self._validation_cache:\n            cached_data, cached_at = self._validation_cache[cache_key]\n            if datetime.now() - cached_at < timedelta(seconds=self._cache_ttl):\n                return  # Valid in cache\n\n        # Call Corporativo /api/me endpoint\n        headers = {\"Authorization\": f\"Bearer {token}\"}\n\n        try:\n            async with httpx.AsyncClient(timeout=5.0) as client:\n                response = await client.get(\n                    f\"{self.api_url}/api/me\",\n                    headers=headers,\n                )\n                response.raise_for_status()\n\n                # Cache validation result\n                self._validation_cache[cache_key] = (payload, datetime.now())\n\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 401:\n                raise JWTError(\"Token is not valid in Corporativo system\")\n            # Network error - extend cache if exists\n            if cache_key in self._validation_cache:\n                cached_data, cached_at = self._validation_cache[cache_key]\n                # Extend cache to 5 minutes on network failure\n                if datetime.now() - cached_at < timedelta(minutes=5):\n                    return\n            raise JWTError(\"Unable to verify token with Corporativo\")\n\n        except httpx.RequestError:\n            # Network error - graceful degradation\n            if cache_key in self._validation_cache:\n                return\n            raise JWTError(\"Network error verifying token\")\n\n    def get_permissions(self, user_data: Dict[str, Any]) -> list[str]:\n        \"\"\"Map Corporativo permissions to app format.\n\n        Example mapping:\n            \"Ver anuidade\" -> \"gefin.boleto.read\"\n            \"Editar anuidade\" -> \"gefin.boleto.write\"\n        \"\"\"\n        corporativo_permissions = user_data.get(\"permissions\", [])\n        permission_map = {\n            \"Ver anuidade\": \"gefin.boleto.read\",\n            \"Editar anuidade\": \"gefin.boleto.write\",\n            \"Ver parcelamento\": \"gefin.parcela.read\",\n            \"Editar parcelamento\": \"gefin.parcela.write\",\n            \"Ver publicações\": \"gefin.publicacao.read\",\n            \"Editar publicações\": \"gefin.publicacao.write\",\n            # ... more mappings\n        }\n\n        mapped_permissions = []\n        for corp_perm in corporativo_permissions:\n            if corp_perm == \"*\":  # Admin wildcard\n                return [\"*\"]\n            app_perm = permission_map.get(corp_perm)\n            if app_perm:\n                mapped_permissions.append(app_perm)\n\n        # Ensure at least read permission\n        if not any(p.endswith(\".read\") for p in mapped_permissions):\n            mapped_permissions.append(\"gefin.user.read\")\n\n        return mapped_permissions\n\n    async def validate_session(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Validate session from Redis.\n\n        Falls back to Laravel session decryption if Redis unavailable.\n        \"\"\"\n        # Try Redis first\n        session_data = await self.session_manager.get_session(session_id)\n        if session_data:\n            return session_data\n\n        # Fall back to Laravel session decryption\n        return await self._decrypt_laravel_session(session_id)\n\n    async def _decrypt_laravel_session(self, session_cookie: str) -> Dict[str, Any]:\n        \"\"\"Decrypt Laravel AES-256-CBC session cookie.\n\n        Laravel session format:\n        - base64(iv:encrypted_payload:mac)\n        - Encrypted with APP_KEY from .env\n        \"\"\"\n        # Implementation omitted for brevity\n        # See Laravel session decryption pattern below\n        pass\n```\n\n### 4. Laravel Session Decryption\n\n```python\n# src/infra/adapters/auth/laravel_session.py\nimport base64\nimport json\nimport hashlib\nimport hmac\nfrom Cryptodome.Cipher import AES\nfrom Cryptodome.Util.Padding import unpad\nimport phpserialize\n\nclass LaravelSessionDecryptor:\n    \"\"\"Decrypt Laravel AES-256-CBC encrypted sessions.\n\n    Handles Laravel's session encryption format.\n    \"\"\"\n\n    def __init__(self, app_key: str):\n        \"\"\"Initialize with Laravel APP_KEY.\n\n        Args:\n            app_key: Laravel APP_KEY from .env (base64: prefix)\n        \"\"\"\n        # Remove 'base64:' prefix if present\n        if app_key.startswith(\"base64:\"):\n            app_key = app_key[7:]\n\n        self.key = base64.b64decode(app_key)\n\n    def decrypt(self, encrypted_value: str) -> str:\n        \"\"\"Decrypt Laravel encrypted value.\n\n        Format: base64(json({\"iv\": \"...\", \"value\": \"...\", \"mac\": \"...\"}))\n        \"\"\"\n        # Decode base64\n        decoded = base64.b64decode(encrypted_value)\n        payload = json.loads(decoded)\n\n        # Verify MAC signature\n        if not self._valid_mac(payload):\n            raise ValueError(\"Invalid MAC signature\")\n\n        # Decrypt\n        iv = base64.b64decode(payload[\"iv\"])\n        encrypted = base64.b64decode(payload[\"value\"])\n\n        cipher = AES.new(self.key, AES.MODE_CBC, iv)\n        decrypted = unpad(cipher.decrypt(encrypted), AES.block_size)\n\n        return decrypted.decode(\"utf-8\")\n\n    def _valid_mac(self, payload: dict) -> bool:\n        \"\"\"Verify MAC signature.\"\"\"\n        mac = payload.get(\"mac\")\n        if not mac:\n            return False\n\n        # Calculate expected MAC\n        message = base64.b64encode(\n            json.dumps({\"iv\": payload[\"iv\"], \"value\": payload[\"value\"]}).encode()\n        )\n        expected_mac = hmac.new(\n            self.key,\n            message,\n            hashlib.sha256,\n        ).hexdigest()\n\n        return hmac.compare_digest(mac, expected_mac)\n\n    def decrypt_session(self, session_cookie: str) -> dict:\n        \"\"\"Decrypt Laravel session cookie and extract user data.\n\n        Args:\n            session_cookie: Laravel session cookie value\n\n        Returns:\n            Dictionary with user_id and other session data\n        \"\"\"\n        # Decrypt session\n        decrypted = self.decrypt(session_cookie)\n\n        # Unserialize PHP session data\n        session_data = phpserialize.loads(decrypted.encode())\n\n        # Extract user ID from various Laravel guard patterns\n        user_id = None\n\n        # Pattern 1: login_web_{guard}_*\n        for key in session_data:\n            if isinstance(key, bytes):\n                key_str = key.decode()\n                if key_str.startswith(\"login_web_\"):\n                    user_id = session_data[key]\n                    break\n\n        # Pattern 2: Direct user_id key\n        if not user_id and b\"user_id\" in session_data:\n            user_id = session_data[b\"user_id\"]\n\n        if not user_id:\n            raise ValueError(\"No user_id found in session\")\n\n        return {\n            \"user_id\": user_id.decode() if isinstance(user_id, bytes) else user_id,\n            \"session_data\": session_data,\n        }\n```\n\n### 5. Redis Session Management\n\n```python\n# src/infra/cache/redis_session.py\nimport json\nfrom datetime import timedelta\nfrom redis.asyncio import Redis\n\nclass RedisSessionManager:\n    \"\"\"Manage user sessions in Redis.\n\n    Stores session data with TTL for automatic expiration.\n    \"\"\"\n\n    def __init__(self, redis_client: Redis, ttl_seconds: int = 28800):\n        \"\"\"Initialize session manager.\n\n        Args:\n            redis_client: Async Redis client\n            ttl_seconds: Session TTL (default 8 hours)\n        \"\"\"\n        self.redis = redis_client\n        self.ttl = ttl_seconds\n\n    async def create_session(self, user_data: dict) -> str:\n        \"\"\"Create new session and return session ID.\n\n        Args:\n            user_data: User data to store\n\n        Returns:\n            Session ID (UUID)\n        \"\"\"\n        import uuid\n        session_id = str(uuid.uuid4())\n\n        # Store in Redis\n        session_key = f\"session:{session_id}\"\n        await self.redis.setex(\n            session_key,\n            self.ttl,\n            json.dumps(user_data),\n        )\n\n        return session_id\n\n    async def get_session(self, session_id: str) -> dict | None:\n        \"\"\"Retrieve session data.\n\n        Args:\n            session_id: Session identifier\n\n        Returns:\n            User data dictionary or None if not found\n        \"\"\"\n        session_key = f\"session:{session_id}\"\n        data = await self.redis.get(session_key)\n\n        if not data:\n            return None\n\n        # Refresh TTL on access\n        await self.redis.expire(session_key, self.ttl)\n\n        return json.loads(data)\n\n    async def delete_session(self, session_id: str) -> bool:\n        \"\"\"Delete session.\n\n        Args:\n            session_id: Session identifier\n\n        Returns:\n            True if deleted, False if not found\n        \"\"\"\n        session_key = f\"session:{session_id}\"\n        result = await self.redis.delete(session_key)\n        return result > 0\n\n    async def update_session(self, session_id: str, user_data: dict) -> bool:\n        \"\"\"Update existing session data.\n\n        Args:\n            session_id: Session identifier\n            user_data: Updated user data\n\n        Returns:\n            True if updated, False if session not found\n        \"\"\"\n        session_key = f\"session:{session_id}\"\n        exists = await self.redis.exists(session_key)\n\n        if not exists:\n            return False\n\n        await self.redis.setex(\n            session_key,\n            self.ttl,\n            json.dumps(user_data),\n        )\n        return True\n```\n\n### 6. Permission Checking Middleware\n\n```python\n# src/api/middlewares/auth.py\nfrom fastapi import Request, HTTPException, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n\nfrom src.infra.adapters.auth.unified_adapter import UnifiedAuthAdapter\n\nsecurity = HTTPBearer()\n\nclass ProtectedResource:\n    \"\"\"FastAPI dependency for protected endpoints.\n\n    Usage:\n        @app.get(\"/protected\", dependencies=[Depends(ProtectedResource.check)])\n    \"\"\"\n\n    def __init__(self, unified_adapter: UnifiedAuthAdapter):\n        self.unified_adapter = unified_adapter\n\n    async def check(\n        self,\n        credentials: HTTPAuthorizationCredentials = Depends(security),\n    ) -> dict:\n        \"\"\"Validate token and return user data.\n\n        Raises:\n            HTTPException: 401 if token invalid, 403 if insufficient permissions\n        \"\"\"\n        token = credentials.credentials\n\n        try:\n            user_data = await self.unified_adapter.validate_token(token)\n            return user_data\n        except JWTError as e:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=str(e),\n            )\n\n    async def check_permissions(\n        self,\n        credentials: HTTPAuthorizationCredentials,\n        required_permissions: list[str],\n    ) -> dict:\n        \"\"\"Validate token and check permissions.\n\n        Args:\n            credentials: Bearer token\n            required_permissions: List of required permissions\n\n        Returns:\n            User data if authorized\n\n        Raises:\n            HTTPException: 401 unauthorized, 403 forbidden\n        \"\"\"\n        user_data = await self.check(credentials)\n        user_permissions = user_data.get(\"permissions\", [])\n\n        # Check for admin wildcard\n        if \"*\" in user_permissions:\n            return user_data\n\n        # Check required permissions\n        has_permission = any(\n            perm in user_permissions for perm in required_permissions\n        )\n\n        if not has_permission:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=f\"Missing required permissions: {required_permissions}\",\n            )\n\n        return user_data\n```\n\n### 7. Multi-System Authentication Endpoints\n\n```python\n# src/api/path/auth.py\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom pydantic import BaseModel\n\nfrom src.infra.adapters.auth.unified_adapter import UnifiedAuthAdapter\nfrom src.infra.cache.redis_session import RedisSessionManager\n\nrouter = APIRouter(prefix=\"/v1/auth\", tags=[\"auth\"])\n\nclass LoginRequest(BaseModel):\n    username: str\n    password: str\n\nclass SSOLoginRequest(BaseModel):\n    corporativo_session: str  # Cookie from Corporativo\n\nclass TokenResponse(BaseModel):\n    access_token: str\n    token_type: str = \"bearer\"\n    expires_in: int\n\n@router.post(\"/login\", response_model=TokenResponse)\nasync def login(\n    request: LoginRequest,\n    adapter: UnifiedAuthAdapter = Depends(),\n):\n    \"\"\"Login with username/password (Corporativo).\n\n    Returns JWT access token.\n    \"\"\"\n    # Delegate to Corporativo adapter\n    result = await adapter.adapters[\"corporativo\"].authenticate_credentials(\n        username=request.username,\n        password=request.password,\n    )\n\n    return TokenResponse(\n        access_token=result[\"access_token\"],\n        expires_in=3600,\n    )\n\n@router.post(\"/sso-login\", response_model=TokenResponse)\nasync def sso_login(\n    request: SSOLoginRequest,\n    adapter: UnifiedAuthAdapter = Depends(),\n    session_manager: RedisSessionManager = Depends(),\n):\n    \"\"\"SSO login using Corporativo session cookie.\n\n    Validates session, creates local session, returns JWT.\n    \"\"\"\n    # Validate Corporativo session\n    user_data = await adapter.validate_session(request.corporativo_session)\n\n    # Create local session\n    session_id = await session_manager.create_session(user_data)\n\n    # Generate JWT\n    token = adapter.adapters[\"corporativo\"].generate_token(user_data)\n\n    return TokenResponse(\n        access_token=token,\n        expires_in=3600,\n    )\n\n@router.get(\"/me\")\nasync def get_current_user(\n    user_data: dict = Depends(ProtectedResource.check),\n):\n    \"\"\"Get current authenticated user info.\"\"\"\n    return {\n        \"cpf\": user_data.get(\"sub\"),\n        \"name\": user_data.get(\"name\"),\n        \"email\": user_data.get(\"email\"),\n        \"permissions\": user_data.get(\"permissions\"),\n        \"systems\": user_data.get(\"systems\", []),\n    }\n\n@router.post(\"/logout\")\nasync def logout(\n    session_id: str,\n    session_manager: RedisSessionManager = Depends(),\n):\n    \"\"\"Logout and invalidate session.\"\"\"\n    await session_manager.delete_session(session_id)\n    return {\"message\": \"Logged out successfully\"}\n```\n\n## Configuration\n\n### Environment Variables\n\n```python\n# src/config/settings.py\nfrom pydantic_settings import BaseSettings\n\nclass AppSettings(BaseSettings):\n    \"\"\"Multi-system authentication settings.\"\"\"\n\n    # Feature flags\n    ENABLE_MULTI_SYSTEM_AUTH: bool = True\n    ENABLED_AUTH_SYSTEMS: list[str] = [\"corporativo\", \"sgf\", \"ged\", \"carrinho\"]\n\n    # JWT configuration\n    JWT_ALGORITHM: str = \"RS256\"\n    JWT_PUBLIC_KEY_PATH: str = \"./keys/jwt_public.pem\"\n    JWT_PRIVATE_KEY_PATH: str = \"./keys/jwt_private.pem\"\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60\n    REFRESH_TOKEN_EXPIRE_HOURS: int = 8\n\n    # SSO systems\n    CORPORATIVO_API_URL: str\n    CORPORATIVO_APP_KEY: str  # Laravel APP_KEY for session decryption\n\n    SGF_API_URL: str\n    SGF_API_KEY: str\n\n    GED_API_URL: str\n    GED_API_KEY: str\n\n    CARRINHO_API_URL: str\n    CARRINHO_API_KEY: str\n\n    # Redis\n    REDIS_URL: str = \"redis://localhost:6379/0\"\n    SESSION_TTL_SECONDS: int = 28800  # 8 hours\n\n    # Backwards verification\n    ENABLE_BACKWARDS_VERIFICATION: bool = True\n    VERIFICATION_CACHE_TTL: int = 30  # seconds\n    VERIFICATION_TIMEOUT: int = 5  # seconds\n\napp_settings = AppSettings()\n```\n\n### RSA Key Pair Management\n\n```bash\n# Generate RSA key pair for JWT signing\nopenssl genrsa -out keys/jwt_private.pem 4096\nopenssl rsa -in keys/jwt_private.pem -pubout -out keys/jwt_public.pem\n\n# Set proper permissions\nchmod 600 keys/jwt_private.pem\nchmod 644 keys/jwt_public.pem\n\n# Add to .gitignore\necho \"keys/jwt_private.pem\" >> .gitignore\n```\n\n## Testing Strategy\n\n### Unit Tests (Token Validation)\n\n```python\n# tests/infra/adapters/auth/test_corporativo_adapter.py\nimport pytest\nfrom jose import jwt\nfrom datetime import datetime, timedelta\n\n@pytest.fixture\ndef valid_token(private_key):\n    \"\"\"Generate valid JWT token.\"\"\"\n    payload = {\n        \"sub\": \"12345678901\",\n        \"name\": \"Test User\",\n        \"email\": \"test@example.com\",\n        \"permissions\": [\"gefin.boleto.read\"],\n        \"iss\": \"gefin-backend\",\n        \"aud\": \"gefin-api\",\n        \"exp\": datetime.utcnow() + timedelta(hours=1),\n    }\n    return jwt.encode(payload, private_key, algorithm=\"RS256\")\n\n@pytest.mark.asyncio\nasync def test_validate_token_success(corporativo_adapter, valid_token):\n    \"\"\"Test successful token validation.\"\"\"\n    user_data = await corporativo_adapter.validate_token(valid_token)\n\n    assert user_data[\"sub\"] == \"12345678901\"\n    assert \"gefin.boleto.read\" in user_data[\"permissions\"]\n\n@pytest.mark.asyncio\nasync def test_validate_token_invalid_signature(corporativo_adapter):\n    \"\"\"Test token with invalid signature.\"\"\"\n    invalid_token = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.invalid.signature\"\n\n    with pytest.raises(JWTError):\n        await corporativo_adapter.validate_token(invalid_token)\n\n@pytest.mark.asyncio\nasync def test_validate_token_expired(corporativo_adapter, private_key):\n    \"\"\"Test expired token.\"\"\"\n    payload = {\n        \"sub\": \"12345678901\",\n        \"exp\": datetime.utcnow() - timedelta(hours=1),  # Expired\n        \"iss\": \"gefin-backend\",\n        \"aud\": \"gefin-api\",\n    }\n    expired_token = jwt.encode(payload, private_key, algorithm=\"RS256\")\n\n    with pytest.raises(JWTError, match=\"expired\"):\n        await corporativo_adapter.validate_token(expired_token)\n```\n\n### Integration Tests (Backwards Verification)\n\n```python\n# tests/integration/test_backwards_verification.py\n@pytest.mark.asyncio\nasync def test_backwards_verification_valid_token(\n    corporativo_adapter,\n    mock_corporativo_api,\n):\n    \"\"\"Test backwards verification with valid token.\"\"\"\n    # Mock Corporativo /api/me endpoint\n    mock_corporativo_api.get(\"/api/me\").returns(\n        status=200,\n        json={\"cpf\": \"12345678901\", \"name\": \"Test User\"},\n    )\n\n    token = generate_corporativo_token()\n    user_data = await corporativo_adapter.validate_token(token)\n\n    assert user_data[\"sub\"] == \"12345678901\"\n\n@pytest.mark.asyncio\nasync def test_backwards_verification_invalid_token(\n    corporativo_adapter,\n    mock_corporativo_api,\n):\n    \"\"\"Test backwards verification with invalid token.\"\"\"\n    mock_corporativo_api.get(\"/api/me\").returns(status=401)\n\n    token = generate_corporativo_token()\n\n    with pytest.raises(JWTError, match=\"not valid in Corporativo\"):\n        await corporativo_adapter.validate_token(token)\n```\n\n## Best Practices\n\n### Security\n- ✅ Always verify JWT signatures before trusting payload\n- ✅ Implement backwards verification for external tokens\n- ✅ Use RS256 (asymmetric) instead of HS256 for multi-service environments\n- ✅ Rotate keys periodically\n- ✅ Cache validation results with short TTL (30s)\n- ✅ Implement graceful degradation on network failures\n- ✅ Never log tokens or secrets\n\n### Performance\n- ✅ Cache token validation results\n- ✅ Use Redis for session storage\n- ✅ Set reasonable timeouts for backwards verification\n- ✅ Skip backwards verification for self-issued tokens\n- ✅ Use connection pooling for HTTP clients\n- ✅ Implement circuit breakers for external APIs\n\n### Permission Mapping\n- ✅ Define clear permission mapping tables\n- ✅ Support wildcard permissions for admins\n- ✅ Provide default read permissions for authenticated users\n- ✅ Map Portuguese permissions to English format\n- ✅ Log permission mapping failures\n\n### Session Management\n- ✅ Use UUIDs for session IDs\n- ✅ Set appropriate TTLs (8 hours default)\n- ✅ Refresh TTL on session access\n- ✅ Implement session cleanup on logout\n- ✅ Support both token and session authentication\n\n## Common Pitfalls\n\n1. **Not Verifying Issuer/Audience**\n   - ❌ Accepting any JWT without checking claims\n   - ✅ Manually verify iss and aud claims\n\n2. **Using HS256 in Multi-Service Environments**\n   - ❌ Symmetric keys shared across services\n   - ✅ Use RS256 with public/private key pairs\n\n3. **No Backwards Verification**\n   - ❌ Trusting JWT without checking with issuer\n   - ✅ Implement backwards verification for security\n\n4. **Hardcoded Permission Mappings**\n   - ❌ Magic strings in code\n   - ✅ Use configuration/database for mappings\n\n5. **Not Handling Network Failures**\n   - ❌ Failing all requests when SSO is down\n   - ✅ Implement graceful degradation with cache\n\n6. **Token Leakage in Logs**\n   - ❌ Logging full tokens in error messages\n   - ✅ Log only token metadata (sub, iss)\n\n## Architecture Decisions\n\n### Why Multi-Adapter Pattern?\n- **Separation of Concerns**: Each SSO system has its own adapter\n- **Extensibility**: Easy to add new SSO providers\n- **Testability**: Mock individual adapters independently\n- **Maintainability**: Changes to one SSO don't affect others\n\n### Why Backwards Verification?\n- **Security**: Prevent token replay attacks\n- **Session Validation**: Check if user is still active\n- **Revocation Support**: Detect revoked tokens\n- **Trust Verification**: Confirm token with authoritative system\n\n### Why RS256 Over HS256?\n- **Key Distribution**: Public key can be shared safely\n- **Trust Boundary**: Services verify without shared secret\n- **Rotation**: Easier key rotation strategy\n- **Industry Standard**: OAuth2/OIDC best practice\n\n## Production Deployment\n\n### Key Management\n```bash\n# Production key generation\nopenssl genrsa -out jwt_private.pem 4096\nopenssl rsa -in jwt_private.pem -pubout -out jwt_public.pem\n\n# Secure storage (AWS Secrets Manager, HashiCorp Vault, etc.)\naws secretsmanager create-secret \\\n    --name gefin/jwt-private-key \\\n    --secret-string file://jwt_private.pem\n```\n\n### Monitoring\n```python\n# Log authentication events\nimport structlog\n\nlogger = structlog.get_logger()\n\nasync def validate_token(self, token: str):\n    logger.info(\n        \"token_validation_started\",\n        issuer=self._get_issuer(token),\n    )\n\n    try:\n        user_data = await self._validate(token)\n        logger.info(\n            \"token_validation_success\",\n            user_id=user_data[\"sub\"],\n            issuer=user_data[\"iss\"],\n        )\n        return user_data\n    except JWTError as e:\n        logger.warning(\n            \"token_validation_failed\",\n            error=str(e),\n        )\n        raise\n```\n\n## References\n\n- [JWT Best Practices (RFC 8725)](https://datatracker.ietf.org/doc/html/rfc8725)\n- [OAuth 2.0 Token Introspection](https://datatracker.ietf.org/doc/html/rfc7662)\n- [FastAPI Security](https://fastapi.tiangolo.com/tutorial/security/)\n- [Python JOSE JWT](https://python-jose.readthedocs.io/)\n- [Laravel Encryption](https://laravel.com/docs/encryption)\n\n## Production Examples\n\nBased on patterns from:\n- **GEFIN Backend**: Multi-system SSO with Corporativo, SGF, GED, CARRINHO\n- **Enterprise SSO**: JWT RS256 with backwards verification\n- **Laravel Integration**: Session decryption for legacy systems"
              },
              {
                "name": "skill-developer",
                "description": "Create and manage Claude Code skills following Anthropic best practices. Use when creating new skills, modifying skill-rules.json, understanding trigger patterns, working with hooks, debugging skill activation, or implementing progressive disclosure. Covers skill structure, YAML frontmatter, trigger types (keywords, intent patterns, file paths, content patterns), enforcement levels (block, suggest, warn), hook mechanisms (UserPromptSubmit, PreToolUse), session tracking, and the 500-line rule.",
                "path": "skills/skill-developer/SKILL.md",
                "frontmatter": {
                  "name": "skill-developer",
                  "description": "Create and manage Claude Code skills following Anthropic best practices. Use when creating new skills, modifying skill-rules.json, understanding trigger patterns, working with hooks, debugging skill activation, or implementing progressive disclosure. Covers skill structure, YAML frontmatter, trigger types (keywords, intent patterns, file paths, content patterns), enforcement levels (block, suggest, warn), hook mechanisms (UserPromptSubmit, PreToolUse), session tracking, and the 500-line rule."
                },
                "content": "# Skill Developer Guide\n\n## Purpose\n\nComprehensive guide for creating and managing skills in Claude Code with auto-activation system, following Anthropic's official best practices including the 500-line rule and progressive disclosure pattern.\n\n## When to Use This Skill\n\nAutomatically activates when you mention:\n- Creating or adding skills\n- Modifying skill triggers or rules\n- Understanding how skill activation works\n- Debugging skill activation issues\n- Working with skill-rules.json\n- Hook system mechanics\n- Claude Code best practices\n- Progressive disclosure\n- YAML frontmatter\n- 500-line rule\n\n---\n\n## System Overview\n\n### Two-Hook Architecture\n\n**1. UserPromptSubmit Hook** (Proactive Suggestions)\n- **File**: `.claude/hooks/skill-activation-prompt.ts`\n- **Trigger**: BEFORE Claude sees user's prompt\n- **Purpose**: Suggest relevant skills based on keywords + intent patterns\n- **Method**: Injects formatted reminder as context (stdout → Claude's input)\n- **Use Cases**: Topic-based skills, implicit work detection\n\n**2. Stop Hook - Error Handling Reminder** (Gentle Reminders)\n- **File**: `.claude/hooks/error-handling-reminder.ts`\n- **Trigger**: AFTER Claude finishes responding\n- **Purpose**: Gentle reminder to self-assess error handling in code written\n- **Method**: Analyzes edited files for risky patterns, displays reminder if needed\n- **Use Cases**: Error handling awareness without blocking friction\n\n**Philosophy Change (2025-10-27):** We moved away from blocking PreToolUse for Sentry/error handling. Instead, use gentle post-response reminders that don't block workflow but maintain code quality awareness.\n\n### Configuration File\n\n**Location**: `.claude/skills/skill-rules.json`\n\nDefines:\n- All skills and their trigger conditions\n- Enforcement levels (block, suggest, warn)\n- File path patterns (glob)\n- Content detection patterns (regex)\n- Skip conditions (session tracking, file markers, env vars)\n\n---\n\n## Skill Types\n\n### 1. Guardrail Skills\n\n**Purpose:** Enforce critical best practices that prevent errors\n\n**Characteristics:**\n- Type: `\"guardrail\"`\n- Enforcement: `\"block\"`\n- Priority: `\"critical\"` or `\"high\"`\n- Block file edits until skill used\n- Prevent common mistakes (column names, critical errors)\n- Session-aware (don't repeat nag in same session)\n\n**Examples:**\n- `database-verification` - Verify table/column names before Prisma queries\n- `frontend-dev-guidelines` - Enforce React/TypeScript patterns\n\n**When to Use:**\n- Mistakes that cause runtime errors\n- Data integrity concerns\n- Critical compatibility issues\n\n### 2. Domain Skills\n\n**Purpose:** Provide comprehensive guidance for specific areas\n\n**Characteristics:**\n- Type: `\"domain\"`\n- Enforcement: `\"suggest\"`\n- Priority: `\"high\"` or `\"medium\"`\n- Advisory, not mandatory\n- Topic or domain-specific\n- Comprehensive documentation\n\n**Examples:**\n- `backend-dev-guidelines` - Node.js/Express/TypeScript patterns\n- `frontend-dev-guidelines` - React/TypeScript best practices\n- `error-tracking` - Sentry integration guidance\n\n**When to Use:**\n- Complex systems requiring deep knowledge\n- Best practices documentation\n- Architectural patterns\n- How-to guides\n\n---\n\n## Quick Start: Creating a New Skill\n\n### Step 1: Create Skill File\n\n**Location:** `.claude/skills/{skill-name}/SKILL.md`\n\n**Template:**\n```markdown\n---\nname: my-new-skill\ndescription: Brief description including keywords that trigger this skill. Mention topics, file types, and use cases. Be explicit about trigger terms.\n---\n\n# My New Skill\n\n## Purpose\nWhat this skill helps with\n\n## When to Use\nSpecific scenarios and conditions\n\n## Key Information\nThe actual guidance, documentation, patterns, examples\n```\n\n**Best Practices:**\n- ✅ **Name**: Lowercase, hyphens, gerund form (verb + -ing) preferred\n- ✅ **Description**: Include ALL trigger keywords/phrases (max 1024 chars)\n- ✅ **Content**: Under 500 lines - use reference files for details\n- ✅ **Examples**: Real code examples\n- ✅ **Structure**: Clear headings, lists, code blocks\n\n### Step 2: Add to skill-rules.json\n\nSee [SKILL_RULES_REFERENCE.md](SKILL_RULES_REFERENCE.md) for complete schema.\n\n**Basic Template:**\n```json\n{\n  \"my-new-skill\": {\n    \"type\": \"domain\",\n    \"enforcement\": \"suggest\",\n    \"priority\": \"medium\",\n    \"promptTriggers\": {\n      \"keywords\": [\"keyword1\", \"keyword2\"],\n      \"intentPatterns\": [\"(create|add).*?something\"]\n    }\n  }\n}\n```\n\n### Step 3: Test Triggers\n\n**Test UserPromptSubmit:**\n```bash\necho '{\"session_id\":\"test\",\"prompt\":\"your test prompt\"}' | \\\n  npx tsx .claude/hooks/skill-activation-prompt.ts\n```\n\n**Test PreToolUse:**\n```bash\ncat <<'EOF' | npx tsx .claude/hooks/skill-verification-guard.ts\n{\"session_id\":\"test\",\"tool_name\":\"Edit\",\"tool_input\":{\"file_path\":\"test.ts\"}}\nEOF\n```\n\n### Step 4: Refine Patterns\n\nBased on testing:\n- Add missing keywords\n- Refine intent patterns to reduce false positives\n- Adjust file path patterns\n- Test content patterns against actual files\n\n### Step 5: Follow Anthropic Best Practices\n\n✅ Keep SKILL.md under 500 lines\n✅ Use progressive disclosure with reference files\n✅ Add table of contents to reference files > 100 lines\n✅ Write detailed description with trigger keywords\n✅ Test with 3+ real scenarios before documenting\n✅ Iterate based on actual usage\n\n---\n\n## Enforcement Levels\n\n### BLOCK (Critical Guardrails)\n\n- Physically prevents Edit/Write tool execution\n- Exit code 2 from hook, stderr → Claude\n- Claude sees message and must use skill to proceed\n- **Use For**: Critical mistakes, data integrity, security issues\n\n**Example:** Database column name verification\n\n### SUGGEST (Recommended)\n\n- Reminder injected before Claude sees prompt\n- Claude is aware of relevant skills\n- Not enforced, just advisory\n- **Use For**: Domain guidance, best practices, how-to guides\n\n**Example:** Frontend development guidelines\n\n### WARN (Optional)\n\n- Low priority suggestions\n- Advisory only, minimal enforcement\n- **Use For**: Nice-to-have suggestions, informational reminders\n\n**Rarely used** - most skills are either BLOCK or SUGGEST.\n\n---\n\n## Skip Conditions & User Control\n\n### 1. Session Tracking\n\n**Purpose:** Don't nag repeatedly in same session\n\n**How it works:**\n- First edit → Hook blocks, updates session state\n- Second edit (same session) → Hook allows\n- Different session → Blocks again\n\n**State File:** `.claude/hooks/state/skills-used-{session_id}.json`\n\n### 2. File Markers\n\n**Purpose:** Permanent skip for verified files\n\n**Marker:** `// @skip-validation`\n\n**Usage:**\n```typescript\n// @skip-validation\nimport { PrismaService } from './prisma';\n// This file has been manually verified\n```\n\n**NOTE:** Use sparingly - defeats the purpose if overused\n\n### 3. Environment Variables\n\n**Purpose:** Emergency disable, temporary override\n\n**Global disable:**\n```bash\nexport SKIP_SKILL_GUARDRAILS=true  # Disables ALL PreToolUse blocks\n```\n\n**Skill-specific:**\n```bash\nexport SKIP_DB_VERIFICATION=true\nexport SKIP_ERROR_REMINDER=true\n```\n\n---\n\n## Testing Checklist\n\nWhen creating a new skill, verify:\n\n- [ ] Skill file created in `.claude/skills/{name}/SKILL.md`\n- [ ] Proper frontmatter with name and description\n- [ ] Entry added to `skill-rules.json`\n- [ ] Keywords tested with real prompts\n- [ ] Intent patterns tested with variations\n- [ ] File path patterns tested with actual files\n- [ ] Content patterns tested against file contents\n- [ ] Block message is clear and actionable (if guardrail)\n- [ ] Skip conditions configured appropriately\n- [ ] Priority level matches importance\n- [ ] No false positives in testing\n- [ ] No false negatives in testing\n- [ ] Performance is acceptable (<100ms or <200ms)\n- [ ] JSON syntax validated: `jq . skill-rules.json`\n- [ ] **SKILL.md under 500 lines** ⭐\n- [ ] Reference files created if needed\n- [ ] Table of contents added to files > 100 lines\n\n---\n\n## Reference Files\n\nFor detailed information on specific topics, see:\n\n### [TRIGGER_TYPES.md](TRIGGER_TYPES.md)\nComplete guide to all trigger types:\n- Keyword triggers (explicit topic matching)\n- Intent patterns (implicit action detection)\n- File path triggers (glob patterns)\n- Content patterns (regex in files)\n- Best practices and examples for each\n- Common pitfalls and testing strategies\n\n### [SKILL_RULES_REFERENCE.md](SKILL_RULES_REFERENCE.md)\nComplete skill-rules.json schema:\n- Full TypeScript interface definitions\n- Field-by-field explanations\n- Complete guardrail skill example\n- Complete domain skill example\n- Validation guide and common errors\n\n### [HOOK_MECHANISMS.md](HOOK_MECHANISMS.md)\nDeep dive into hook internals:\n- UserPromptSubmit flow (detailed)\n- PreToolUse flow (detailed)\n- Exit code behavior table (CRITICAL)\n- Session state management\n- Performance considerations\n\n### [TROUBLESHOOTING.md](TROUBLESHOOTING.md)\nComprehensive debugging guide:\n- Skill not triggering (UserPromptSubmit)\n- PreToolUse not blocking\n- False positives (too many triggers)\n- Hook not executing at all\n- Performance issues\n\n### [PATTERNS_LIBRARY.md](PATTERNS_LIBRARY.md)\nReady-to-use pattern collection:\n- Intent pattern library (regex)\n- File path pattern library (glob)\n- Content pattern library (regex)\n- Organized by use case\n- Copy-paste ready\n\n### [ADVANCED.md](ADVANCED.md)\nFuture enhancements and ideas:\n- Dynamic rule updates\n- Skill dependencies\n- Conditional enforcement\n- Skill analytics\n- Skill versioning\n\n---\n\n## Quick Reference Summary\n\n### Create New Skill (5 Steps)\n\n1. Create `.claude/skills/{name}/SKILL.md` with frontmatter\n2. Add entry to `.claude/skills/skill-rules.json`\n3. Test with `npx tsx` commands\n4. Refine patterns based on testing\n5. Keep SKILL.md under 500 lines\n\n### Trigger Types\n\n- **Keywords**: Explicit topic mentions\n- **Intent**: Implicit action detection\n- **File Paths**: Location-based activation\n- **Content**: Technology-specific detection\n\nSee [TRIGGER_TYPES.md](TRIGGER_TYPES.md) for complete details.\n\n### Enforcement\n\n- **BLOCK**: Exit code 2, critical only\n- **SUGGEST**: Inject context, most common\n- **WARN**: Advisory, rarely used\n\n### Skip Conditions\n\n- **Session tracking**: Automatic (prevents repeated nags)\n- **File markers**: `// @skip-validation` (permanent skip)\n- **Env vars**: `SKIP_SKILL_GUARDRAILS` (emergency disable)\n\n### Anthropic Best Practices\n\n✅ **500-line rule**: Keep SKILL.md under 500 lines\n✅ **Progressive disclosure**: Use reference files for details\n✅ **Table of contents**: Add to reference files > 100 lines\n✅ **One level deep**: Don't nest references deeply\n✅ **Rich descriptions**: Include all trigger keywords (max 1024 chars)\n✅ **Test first**: Build 3+ evaluations before extensive documentation\n✅ **Gerund naming**: Prefer verb + -ing (e.g., \"processing-pdfs\")\n\n### Troubleshoot\n\nTest hooks manually:\n```bash\n# UserPromptSubmit\necho '{\"prompt\":\"test\"}' | npx tsx .claude/hooks/skill-activation-prompt.ts\n\n# PreToolUse\ncat <<'EOF' | npx tsx .claude/hooks/skill-verification-guard.ts\n{\"tool_name\":\"Edit\",\"tool_input\":{\"file_path\":\"test.ts\"}}\nEOF\n```\n\nSee [TROUBLESHOOTING.md](TROUBLESHOOTING.md) for complete debugging guide.\n\n---\n\n## Related Files\n\n**Configuration:**\n- `.claude/skills/skill-rules.json` - Master configuration\n- `.claude/hooks/state/` - Session tracking\n- `.claude/settings.json` - Hook registration\n\n**Hooks:**\n- `.claude/hooks/skill-activation-prompt.ts` - UserPromptSubmit\n- `.claude/hooks/error-handling-reminder.ts` - Stop event (gentle reminders)\n\n**All Skills:**\n- `.claude/skills/*/SKILL.md` - Skill content files\n\n---\n\n**Skill Status**: COMPLETE - Restructured following Anthropic best practices ✅\n**Line Count**: < 500 (following 500-line rule) ✅\n**Progressive Disclosure**: Reference files for detailed information ✅\n\n**Next**: Create more skills, refine patterns based on usage"
              }
            ]
          }
        ]
      }
    }
  ]
}