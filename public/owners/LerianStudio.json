{
  "owner": {
    "id": "LerianStudio",
    "display_name": "Lerian Studio",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/148895005?v=4",
    "url": "https://github.com/LerianStudio",
    "bio": "Building Open-Source alternatives for the transactional world.",
    "stats": {
      "total_repos": 1,
      "total_plugins": 5,
      "total_commands": 24,
      "total_skills": 60,
      "total_stars": 39,
      "total_forks": 2
    }
  },
  "repos": [
    {
      "full_name": "LerianStudio/ring",
      "url": "https://github.com/LerianStudio/ring",
      "description": "Mandatory workflow system enforcing software engineering best practices and quality gates for AI agents.",
      "homepage": "",
      "signals": {
        "stars": 39,
        "forks": 2,
        "pushed_at": "2026-01-12T18:20:36Z",
        "created_at": "2025-10-30T20:18:13Z",
        "license": "Apache-2.0"
      },
      "file_tree": [
        {
          "path": ".archive",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/agents/accounting-specialist.md",
          "type": "blob",
          "size": 16536
        },
        {
          "path": ".archive/finance-team/agents/budget-planner.md",
          "type": "blob",
          "size": 14477
        },
        {
          "path": ".archive/finance-team/agents/financial-analyst.md",
          "type": "blob",
          "size": 14293
        },
        {
          "path": ".archive/finance-team/agents/financial-modeler.md",
          "type": "blob",
          "size": 15307
        },
        {
          "path": ".archive/finance-team/agents/metrics-analyst.md",
          "type": "blob",
          "size": 16849
        },
        {
          "path": ".archive/finance-team/agents/treasury-specialist.md",
          "type": "blob",
          "size": 16360
        },
        {
          "path": ".archive/finance-team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/commands/analyze-financials.md",
          "type": "blob",
          "size": 4202
        },
        {
          "path": ".archive/finance-team/commands/build-model.md",
          "type": "blob",
          "size": 4800
        },
        {
          "path": ".archive/finance-team/commands/create-budget.md",
          "type": "blob",
          "size": 4578
        },
        {
          "path": ".archive/finance-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": ".archive/finance-team/hooks/session-start.sh",
          "type": "blob",
          "size": 4328
        },
        {
          "path": ".archive/finance-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/budget-creation",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/budget-creation/SKILL.md",
          "type": "blob",
          "size": 7947
        },
        {
          "path": ".archive/finance-team/skills/cash-flow-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/cash-flow-analysis/SKILL.md",
          "type": "blob",
          "size": 7065
        },
        {
          "path": ".archive/finance-team/skills/financial-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/financial-analysis/SKILL.md",
          "type": "blob",
          "size": 7272
        },
        {
          "path": ".archive/finance-team/skills/financial-close",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/financial-close/SKILL.md",
          "type": "blob",
          "size": 7581
        },
        {
          "path": ".archive/finance-team/skills/financial-modeling",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/financial-modeling/SKILL.md",
          "type": "blob",
          "size": 8300
        },
        {
          "path": ".archive/finance-team/skills/financial-reporting",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/financial-reporting/SKILL.md",
          "type": "blob",
          "size": 7011
        },
        {
          "path": ".archive/finance-team/skills/metrics-dashboard",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/metrics-dashboard/SKILL.md",
          "type": "blob",
          "size": 7151
        },
        {
          "path": ".archive/finance-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/shared-patterns/anti-rationalization.md",
          "type": "blob",
          "size": 5668
        },
        {
          "path": ".archive/finance-team/skills/shared-patterns/execution-report.md",
          "type": "blob",
          "size": 3184
        },
        {
          "path": ".archive/finance-team/skills/shared-patterns/pressure-resistance.md",
          "type": "blob",
          "size": 4307
        },
        {
          "path": ".archive/finance-team/skills/shared-patterns/standards-coverage-table.md",
          "type": "blob",
          "size": 4326
        },
        {
          "path": ".archive/finance-team/skills/using-finance-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/finance-team/skills/using-finance-team/SKILL.md",
          "type": "blob",
          "size": 11359
        },
        {
          "path": ".archive/ops-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/agents/cloud-cost-optimizer.md",
          "type": "blob",
          "size": 12465
        },
        {
          "path": ".archive/ops-team/agents/incident-responder.md",
          "type": "blob",
          "size": 12029
        },
        {
          "path": ".archive/ops-team/agents/infrastructure-architect.md",
          "type": "blob",
          "size": 14996
        },
        {
          "path": ".archive/ops-team/agents/platform-engineer.md",
          "type": "blob",
          "size": 10515
        },
        {
          "path": ".archive/ops-team/agents/security-operations.md",
          "type": "blob",
          "size": 14525
        },
        {
          "path": ".archive/ops-team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/commands/capacity-review.md",
          "type": "blob",
          "size": 4569
        },
        {
          "path": ".archive/ops-team/commands/cost-analysis.md",
          "type": "blob",
          "size": 5572
        },
        {
          "path": ".archive/ops-team/commands/incident.md",
          "type": "blob",
          "size": 3613
        },
        {
          "path": ".archive/ops-team/commands/security-audit.md",
          "type": "blob",
          "size": 6719
        },
        {
          "path": ".archive/ops-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": ".archive/ops-team/hooks/session-start.sh",
          "type": "blob",
          "size": 3379
        },
        {
          "path": ".archive/ops-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-capacity-planning",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-capacity-planning/SKILL.md",
          "type": "blob",
          "size": 9373
        },
        {
          "path": ".archive/ops-team/skills/ops-cost-optimization",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-cost-optimization/SKILL.md",
          "type": "blob",
          "size": 9763
        },
        {
          "path": ".archive/ops-team/skills/ops-disaster-recovery",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-disaster-recovery/SKILL.md",
          "type": "blob",
          "size": 12355
        },
        {
          "path": ".archive/ops-team/skills/ops-incident-response",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-incident-response/SKILL.md",
          "type": "blob",
          "size": 8567
        },
        {
          "path": ".archive/ops-team/skills/ops-migration-planning",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-migration-planning/SKILL.md",
          "type": "blob",
          "size": 13984
        },
        {
          "path": ".archive/ops-team/skills/ops-platform-onboarding",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-platform-onboarding/SKILL.md",
          "type": "blob",
          "size": 11496
        },
        {
          "path": ".archive/ops-team/skills/ops-security-audit",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/ops-security-audit/SKILL.md",
          "type": "blob",
          "size": 10845
        },
        {
          "path": ".archive/ops-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/shared-patterns/anti-rationalization.md",
          "type": "blob",
          "size": 4590
        },
        {
          "path": ".archive/ops-team/skills/shared-patterns/execution-report.md",
          "type": "blob",
          "size": 3583
        },
        {
          "path": ".archive/ops-team/skills/shared-patterns/incident-severity.md",
          "type": "blob",
          "size": 4674
        },
        {
          "path": ".archive/ops-team/skills/shared-patterns/pressure-resistance.md",
          "type": "blob",
          "size": 3989
        },
        {
          "path": ".archive/ops-team/skills/shared-patterns/standards-workflow.md",
          "type": "blob",
          "size": 5835
        },
        {
          "path": ".archive/ops-team/skills/using-ops-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/ops-team/skills/using-ops-team/SKILL.md",
          "type": "blob",
          "size": 10597
        },
        {
          "path": ".archive/pmm-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/agents/gtm-planner.md",
          "type": "blob",
          "size": 10836
        },
        {
          "path": ".archive/pmm-team/agents/launch-coordinator.md",
          "type": "blob",
          "size": 11297
        },
        {
          "path": ".archive/pmm-team/agents/market-researcher.md",
          "type": "blob",
          "size": 10888
        },
        {
          "path": ".archive/pmm-team/agents/messaging-specialist.md",
          "type": "blob",
          "size": 10751
        },
        {
          "path": ".archive/pmm-team/agents/positioning-strategist.md",
          "type": "blob",
          "size": 10863
        },
        {
          "path": ".archive/pmm-team/agents/pricing-analyst.md",
          "type": "blob",
          "size": 11537
        },
        {
          "path": ".archive/pmm-team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/commands/competitive-intel.md",
          "type": "blob",
          "size": 6632
        },
        {
          "path": ".archive/pmm-team/commands/gtm-plan.md",
          "type": "blob",
          "size": 7123
        },
        {
          "path": ".archive/pmm-team/commands/market-analysis.md",
          "type": "blob",
          "size": 5487
        },
        {
          "path": ".archive/pmm-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": ".archive/pmm-team/hooks/session-start.sh",
          "type": "blob",
          "size": 3576
        },
        {
          "path": ".archive/pmm-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/competitive-intelligence",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/competitive-intelligence/SKILL.md",
          "type": "blob",
          "size": 9857
        },
        {
          "path": ".archive/pmm-team/skills/gtm-planning",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/gtm-planning/SKILL.md",
          "type": "blob",
          "size": 8835
        },
        {
          "path": ".archive/pmm-team/skills/launch-execution",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/launch-execution/SKILL.md",
          "type": "blob",
          "size": 10349
        },
        {
          "path": ".archive/pmm-team/skills/market-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/market-analysis/SKILL.md",
          "type": "blob",
          "size": 7097
        },
        {
          "path": ".archive/pmm-team/skills/messaging-creation",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/messaging-creation/SKILL.md",
          "type": "blob",
          "size": 8408
        },
        {
          "path": ".archive/pmm-team/skills/positioning-development",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/positioning-development/SKILL.md",
          "type": "blob",
          "size": 8170
        },
        {
          "path": ".archive/pmm-team/skills/pricing-strategy",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/pricing-strategy/SKILL.md",
          "type": "blob",
          "size": 9403
        },
        {
          "path": ".archive/pmm-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/shared-patterns/anti-rationalization.md",
          "type": "blob",
          "size": 4426
        },
        {
          "path": ".archive/pmm-team/skills/shared-patterns/execution-report.md",
          "type": "blob",
          "size": 1892
        },
        {
          "path": ".archive/pmm-team/skills/shared-patterns/pressure-resistance.md",
          "type": "blob",
          "size": 3249
        },
        {
          "path": ".archive/pmm-team/skills/using-pmm-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmm-team/skills/using-pmm-team/SKILL.md",
          "type": "blob",
          "size": 7110
        },
        {
          "path": ".archive/pmo-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/agents/executive-reporter.md",
          "type": "blob",
          "size": 12120
        },
        {
          "path": ".archive/pmo-team/agents/governance-specialist.md",
          "type": "blob",
          "size": 11663
        },
        {
          "path": ".archive/pmo-team/agents/portfolio-manager.md",
          "type": "blob",
          "size": 11526
        },
        {
          "path": ".archive/pmo-team/agents/resource-planner.md",
          "type": "blob",
          "size": 11331
        },
        {
          "path": ".archive/pmo-team/agents/risk-analyst.md",
          "type": "blob",
          "size": 11452
        },
        {
          "path": ".archive/pmo-team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/commands/dependency-analysis.md",
          "type": "blob",
          "size": 5854
        },
        {
          "path": ".archive/pmo-team/commands/executive-summary.md",
          "type": "blob",
          "size": 4778
        },
        {
          "path": ".archive/pmo-team/commands/portfolio-review.md",
          "type": "blob",
          "size": 3926
        },
        {
          "path": ".archive/pmo-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": ".archive/pmo-team/hooks/session-start.sh",
          "type": "blob",
          "size": 3305
        },
        {
          "path": ".archive/pmo-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/dependency-mapping",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/dependency-mapping/SKILL.md",
          "type": "blob",
          "size": 8943
        },
        {
          "path": ".archive/pmo-team/skills/executive-reporting",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/executive-reporting/SKILL.md",
          "type": "blob",
          "size": 8845
        },
        {
          "path": ".archive/pmo-team/skills/pmo-retrospective",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/pmo-retrospective/SKILL.md",
          "type": "blob",
          "size": 9206
        },
        {
          "path": ".archive/pmo-team/skills/portfolio-planning",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/portfolio-planning/SKILL.md",
          "type": "blob",
          "size": 7281
        },
        {
          "path": ".archive/pmo-team/skills/project-health-check",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/project-health-check/SKILL.md",
          "type": "blob",
          "size": 8827
        },
        {
          "path": ".archive/pmo-team/skills/resource-allocation",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/resource-allocation/SKILL.md",
          "type": "blob",
          "size": 7735
        },
        {
          "path": ".archive/pmo-team/skills/risk-management",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/risk-management/SKILL.md",
          "type": "blob",
          "size": 8219
        },
        {
          "path": ".archive/pmo-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/shared-patterns/anti-rationalization.md",
          "type": "blob",
          "size": 5964
        },
        {
          "path": ".archive/pmo-team/skills/shared-patterns/execution-report.md",
          "type": "blob",
          "size": 2986
        },
        {
          "path": ".archive/pmo-team/skills/shared-patterns/governance-gates.md",
          "type": "blob",
          "size": 5901
        },
        {
          "path": ".archive/pmo-team/skills/shared-patterns/pmo-metrics.md",
          "type": "blob",
          "size": 4930
        },
        {
          "path": ".archive/pmo-team/skills/shared-patterns/pressure-resistance.md",
          "type": "blob",
          "size": 4294
        },
        {
          "path": ".archive/pmo-team/skills/using-pmo-team",
          "type": "tree",
          "size": null
        },
        {
          "path": ".archive/pmo-team/skills/using-pmo-team/SKILL.md",
          "type": "blob",
          "size": 12295
        },
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 4566
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/version-bump.yml",
          "type": "blob",
          "size": 13037
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 292
        },
        {
          "path": "AGENTS.md",
          "type": "blob",
          "size": 9
        },
        {
          "path": "ARCHITECTURE.md",
          "type": "blob",
          "size": 27433
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 29842
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "MANUAL.md",
          "type": "blob",
          "size": 18427
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 24525
        },
        {
          "path": "default",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/agents/business-logic-reviewer.md",
          "type": "blob",
          "size": 11130
        },
        {
          "path": "default/agents/code-reviewer.md",
          "type": "blob",
          "size": 11747
        },
        {
          "path": "default/agents/codebase-explorer.md",
          "type": "blob",
          "size": 25874
        },
        {
          "path": "default/agents/nil-safety-reviewer.md",
          "type": "blob",
          "size": 16128
        },
        {
          "path": "default/agents/security-reviewer.md",
          "type": "blob",
          "size": 12538
        },
        {
          "path": "default/agents/test-reviewer.md",
          "type": "blob",
          "size": 19207
        },
        {
          "path": "default/agents/write-plan.md",
          "type": "blob",
          "size": 26882
        },
        {
          "path": "default/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/commands/brainstorm.md",
          "type": "blob",
          "size": 3947
        },
        {
          "path": "default/commands/codereview.md",
          "type": "blob",
          "size": 9938
        },
        {
          "path": "default/commands/commit.md",
          "type": "blob",
          "size": 16049
        },
        {
          "path": "default/commands/compound-learnings.md",
          "type": "blob",
          "size": 3555
        },
        {
          "path": "default/commands/create-handoff.md",
          "type": "blob",
          "size": 2730
        },
        {
          "path": "default/commands/execute-plan.md",
          "type": "blob",
          "size": 4845
        },
        {
          "path": "default/commands/explore-codebase.md",
          "type": "blob",
          "size": 13391
        },
        {
          "path": "default/commands/interview-me.md",
          "type": "blob",
          "size": 4034
        },
        {
          "path": "default/commands/lint.md",
          "type": "blob",
          "size": 2671
        },
        {
          "path": "default/commands/query-artifacts.md",
          "type": "blob",
          "size": 3961
        },
        {
          "path": "default/commands/release-guide.md",
          "type": "blob",
          "size": 1402
        },
        {
          "path": "default/commands/resume-handoff.md",
          "type": "blob",
          "size": 2826
        },
        {
          "path": "default/commands/worktree.md",
          "type": "blob",
          "size": 2932
        },
        {
          "path": "default/commands/write-plan.md",
          "type": "blob",
          "size": 4792
        },
        {
          "path": "default/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/docs/CONTEXT_WARNINGS.md",
          "type": "blob",
          "size": 4198
        },
        {
          "path": "default/docs/RAG_PLANNING.md",
          "type": "blob",
          "size": 5977
        },
        {
          "path": "default/docs/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/docs/hooks/user-message-contract.md",
          "type": "blob",
          "size": 6474
        },
        {
          "path": "default/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/hooks/artifact-index-write.sh",
          "type": "blob",
          "size": 2709
        },
        {
          "path": "default/hooks/claude-md-reminder.sh",
          "type": "blob",
          "size": 7160
        },
        {
          "path": "default/hooks/context-usage-check.sh",
          "type": "blob",
          "size": 8299
        },
        {
          "path": "default/hooks/generate-skills-ref.py",
          "type": "blob",
          "size": 11227
        },
        {
          "path": "default/hooks/generate-skills-ref.sh",
          "type": "blob",
          "size": 6741
        },
        {
          "path": "default/hooks/hooks.json",
          "type": "blob",
          "size": 2018
        },
        {
          "path": "default/hooks/learning-extract.py",
          "type": "blob",
          "size": 11489
        },
        {
          "path": "default/hooks/learning-extract.sh",
          "type": "blob",
          "size": 815
        },
        {
          "path": "default/hooks/ledger-save.sh",
          "type": "blob",
          "size": 3634
        },
        {
          "path": "default/hooks/outcome-inference.sh",
          "type": "blob",
          "size": 4340
        },
        {
          "path": "default/hooks/session-outcome.sh",
          "type": "blob",
          "size": 5389
        },
        {
          "path": "default/hooks/session-start.sh",
          "type": "blob",
          "size": 10887
        },
        {
          "path": "default/hooks/task-completion-check.sh",
          "type": "blob",
          "size": 4483
        },
        {
          "path": "default/hooks/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/hooks/tests/test-context-usage.sh",
          "type": "blob",
          "size": 8141
        },
        {
          "path": "default/lib",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/artifact-index",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/artifact-index/__init__.py",
          "type": "blob",
          "size": 492
        },
        {
          "path": "default/lib/artifact-index/artifact_index.py",
          "type": "blob",
          "size": 21006
        },
        {
          "path": "default/lib/artifact-index/artifact_mark.py",
          "type": "blob",
          "size": 5389
        },
        {
          "path": "default/lib/artifact-index/artifact_query.py",
          "type": "blob",
          "size": 20158
        },
        {
          "path": "default/lib/artifact-index/artifact_schema.sql",
          "type": "blob",
          "size": 12784
        },
        {
          "path": "default/lib/artifact-index/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/artifact-index/tests/__init__.py",
          "type": "blob",
          "size": 35
        },
        {
          "path": "default/lib/artifact-index/tests/test_artifact_index.py",
          "type": "blob",
          "size": 29600
        },
        {
          "path": "default/lib/artifact-index/utils.py",
          "type": "blob",
          "size": 1820
        },
        {
          "path": "default/lib/compound_learnings",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/compound_learnings/.gitkeep",
          "type": "blob",
          "size": null
        },
        {
          "path": "default/lib/compound_learnings/__init__.py",
          "type": "blob",
          "size": 1730
        },
        {
          "path": "default/lib/compound_learnings/learning_parser.py",
          "type": "blob",
          "size": 4891
        },
        {
          "path": "default/lib/compound_learnings/pattern_detector.py",
          "type": "blob",
          "size": 7796
        },
        {
          "path": "default/lib/compound_learnings/rule_generator.py",
          "type": "blob",
          "size": 10446
        },
        {
          "path": "default/lib/compound_learnings/test_learning_parser.py",
          "type": "blob",
          "size": 5249
        },
        {
          "path": "default/lib/compound_learnings/test_pattern_detector.py",
          "type": "blob",
          "size": 5931
        },
        {
          "path": "default/lib/compound_learnings/test_rule_generator.py",
          "type": "blob",
          "size": 7563
        },
        {
          "path": "default/lib/outcome-inference",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/outcome-inference/outcome_inference.py",
          "type": "blob",
          "size": 4435
        },
        {
          "path": "default/lib/shell",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/shell/context-check.sh",
          "type": "blob",
          "size": 7717
        },
        {
          "path": "default/lib/shell/hook-utils.sh",
          "type": "blob",
          "size": 6137
        },
        {
          "path": "default/lib/shell/json-escape.sh",
          "type": "blob",
          "size": 2087
        },
        {
          "path": "default/lib/shell/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/shell/tests/test_shell_utils.sh",
          "type": "blob",
          "size": 25820
        },
        {
          "path": "default/lib/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/lib/tests/test-rag-planning.sh",
          "type": "blob",
          "size": 6439
        },
        {
          "path": "default/lib/validate-plan-precedent.py",
          "type": "blob",
          "size": 11812
        },
        {
          "path": "default/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/artifact-query",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/artifact-query/SKILL.md",
          "type": "blob",
          "size": 5053
        },
        {
          "path": "default/skills/brainstorming",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/brainstorming/SKILL.md",
          "type": "blob",
          "size": 10145
        },
        {
          "path": "default/skills/compound-learnings",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/compound-learnings/SKILL.md",
          "type": "blob",
          "size": 7997
        },
        {
          "path": "default/skills/condition-based-waiting",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/condition-based-waiting/SKILL.md",
          "type": "blob",
          "size": 2862
        },
        {
          "path": "default/skills/condition-based-waiting/example.ts",
          "type": "blob",
          "size": 5054
        },
        {
          "path": "default/skills/continuity-ledger",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/continuity-ledger/SKILL.md",
          "type": "blob",
          "size": 7491
        },
        {
          "path": "default/skills/defense-in-depth",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/defense-in-depth/SKILL.md",
          "type": "blob",
          "size": 2772
        },
        {
          "path": "default/skills/dispatching-parallel-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/dispatching-parallel-agents/SKILL.md",
          "type": "blob",
          "size": 3594
        },
        {
          "path": "default/skills/executing-plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/executing-plans/SKILL.md",
          "type": "blob",
          "size": 5244
        },
        {
          "path": "default/skills/exploring-codebase",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/exploring-codebase/SKILL.md",
          "type": "blob",
          "size": 41014
        },
        {
          "path": "default/skills/exploring-codebase/STRESS_TEST_RESULTS.md",
          "type": "blob",
          "size": 10150
        },
        {
          "path": "default/skills/finishing-a-development-branch",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/finishing-a-development-branch/SKILL.md",
          "type": "blob",
          "size": 3564
        },
        {
          "path": "default/skills/handoff-tracking",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/handoff-tracking/SKILL.md",
          "type": "blob",
          "size": 6435
        },
        {
          "path": "default/skills/interviewing-user",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/interviewing-user/SKILL.md",
          "type": "blob",
          "size": 9208
        },
        {
          "path": "default/skills/linting-codebase",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/linting-codebase/SKILL.md",
          "type": "blob",
          "size": 5828
        },
        {
          "path": "default/skills/receiving-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/receiving-code-review/SKILL.md",
          "type": "blob",
          "size": 5506
        },
        {
          "path": "default/skills/release-guide-info",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/release-guide-info/SKILL.md",
          "type": "blob",
          "size": 22770
        },
        {
          "path": "default/skills/requesting-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/requesting-code-review/SKILL.md",
          "type": "blob",
          "size": 87719
        },
        {
          "path": "default/skills/root-cause-tracing",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/root-cause-tracing/SKILL.md",
          "type": "blob",
          "size": 4451
        },
        {
          "path": "default/skills/root-cause-tracing/find-polluter.sh",
          "type": "blob",
          "size": 2478
        },
        {
          "path": "default/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/shared-patterns/ai-slop-detection.md",
          "type": "blob",
          "size": 13362
        },
        {
          "path": "default/skills/shared-patterns/doubt-triggered-questions.md",
          "type": "blob",
          "size": 2996
        },
        {
          "path": "default/skills/shared-patterns/exit-criteria.md",
          "type": "blob",
          "size": 726
        },
        {
          "path": "default/skills/shared-patterns/failure-recovery.md",
          "type": "blob",
          "size": 1889
        },
        {
          "path": "default/skills/shared-patterns/orchestrator-direct-editing-anti-rationalization.md",
          "type": "blob",
          "size": 2857
        },
        {
          "path": "default/skills/shared-patterns/reviewer-anti-rationalization.md",
          "type": "blob",
          "size": 7335
        },
        {
          "path": "default/skills/shared-patterns/reviewer-blocker-criteria.md",
          "type": "blob",
          "size": 4138
        },
        {
          "path": "default/skills/shared-patterns/reviewer-model-requirement.md",
          "type": "blob",
          "size": 2386
        },
        {
          "path": "default/skills/shared-patterns/reviewer-orchestrator-boundary.md",
          "type": "blob",
          "size": 7977
        },
        {
          "path": "default/skills/shared-patterns/reviewer-output-schema-core.md",
          "type": "blob",
          "size": 3890
        },
        {
          "path": "default/skills/shared-patterns/reviewer-pressure-resistance.md",
          "type": "blob",
          "size": 5095
        },
        {
          "path": "default/skills/shared-patterns/reviewer-quality-feedback.md",
          "type": "blob",
          "size": 3465
        },
        {
          "path": "default/skills/shared-patterns/reviewer-severity-calibration.md",
          "type": "blob",
          "size": 4052
        },
        {
          "path": "default/skills/shared-patterns/reviewer-when-not-needed.md",
          "type": "blob",
          "size": 3899
        },
        {
          "path": "default/skills/shared-patterns/state-tracking.md",
          "type": "blob",
          "size": 669
        },
        {
          "path": "default/skills/shared-patterns/todowrite-integration.md",
          "type": "blob",
          "size": 1076
        },
        {
          "path": "default/skills/subagent-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/subagent-driven-development/SKILL.md",
          "type": "blob",
          "size": 5578
        },
        {
          "path": "default/skills/systematic-debugging",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/systematic-debugging/SKILL.md",
          "type": "blob",
          "size": 6231
        },
        {
          "path": "default/skills/test-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/test-driven-development/SKILL.md",
          "type": "blob",
          "size": 14360
        },
        {
          "path": "default/skills/testing-agents-with-subagents",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/testing-agents-with-subagents/SKILL.md",
          "type": "blob",
          "size": 15382
        },
        {
          "path": "default/skills/testing-anti-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/testing-anti-patterns/SKILL.md",
          "type": "blob",
          "size": 4200
        },
        {
          "path": "default/skills/testing-skills-with-subagents",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/testing-skills-with-subagents/SKILL.md",
          "type": "blob",
          "size": 10016
        },
        {
          "path": "default/skills/using-git-worktrees",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/using-git-worktrees/SKILL.md",
          "type": "blob",
          "size": 4470
        },
        {
          "path": "default/skills/using-ring",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/using-ring/SKILL.md",
          "type": "blob",
          "size": 16618
        },
        {
          "path": "default/skills/using-ring/STRESS-TEST.md",
          "type": "blob",
          "size": 14878
        },
        {
          "path": "default/skills/verification-before-completion",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/verification-before-completion/SKILL.md",
          "type": "blob",
          "size": 6669
        },
        {
          "path": "default/skills/writing-plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/writing-plans/SKILL.md",
          "type": "blob",
          "size": 5229
        },
        {
          "path": "default/skills/writing-skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/skills/writing-skills/SKILL.md",
          "type": "blob",
          "size": 15556
        },
        {
          "path": "default/skills/writing-skills/anthropic-best-practices.md",
          "type": "blob",
          "size": 45798
        },
        {
          "path": "default/skills/writing-skills/graphviz-conventions.dot",
          "type": "blob",
          "size": 5970
        },
        {
          "path": "default/skills/writing-skills/persuasion-principles.md",
          "type": "blob",
          "size": 5908
        },
        {
          "path": "default/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "default/templates/CONTINUITY-example.md",
          "type": "blob",
          "size": 1773
        },
        {
          "path": "default/templates/CONTINUITY-template.md",
          "type": "blob",
          "size": 1359
        },
        {
          "path": "dev-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/agents/backend-engineer-golang.md",
          "type": "blob",
          "size": 40206
        },
        {
          "path": "dev-team/agents/backend-engineer-typescript.md",
          "type": "blob",
          "size": 38563
        },
        {
          "path": "dev-team/agents/devops-engineer.md",
          "type": "blob",
          "size": 26772
        },
        {
          "path": "dev-team/agents/frontend-bff-engineer-typescript.md",
          "type": "blob",
          "size": 33781
        },
        {
          "path": "dev-team/agents/frontend-designer.md",
          "type": "blob",
          "size": 43231
        },
        {
          "path": "dev-team/agents/frontend-engineer.md",
          "type": "blob",
          "size": 38430
        },
        {
          "path": "dev-team/agents/prompt-quality-reviewer.md",
          "type": "blob",
          "size": 29114
        },
        {
          "path": "dev-team/agents/qa-analyst.md",
          "type": "blob",
          "size": 47193
        },
        {
          "path": "dev-team/agents/sre.md",
          "type": "blob",
          "size": 24973
        },
        {
          "path": "dev-team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/commands/dev-cancel.md",
          "type": "blob",
          "size": 1607
        },
        {
          "path": "dev-team/commands/dev-cycle.md",
          "type": "blob",
          "size": 4295
        },
        {
          "path": "dev-team/commands/dev-refactor.md",
          "type": "blob",
          "size": 7056
        },
        {
          "path": "dev-team/commands/dev-report.md",
          "type": "blob",
          "size": 2938
        },
        {
          "path": "dev-team/commands/dev-status.md",
          "type": "blob",
          "size": 1407
        },
        {
          "path": "dev-team/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/docs/standards",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/docs/standards/devops.md",
          "type": "blob",
          "size": 14754
        },
        {
          "path": "dev-team/docs/standards/frontend.md",
          "type": "blob",
          "size": 19979
        },
        {
          "path": "dev-team/docs/standards/golang.md",
          "type": "blob",
          "size": 106573
        },
        {
          "path": "dev-team/docs/standards/sre.md",
          "type": "blob",
          "size": 25826
        },
        {
          "path": "dev-team/docs/standards/typescript.md",
          "type": "blob",
          "size": 26683
        },
        {
          "path": "dev-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": "dev-team/hooks/session-start.sh",
          "type": "blob",
          "size": 3881
        },
        {
          "path": "dev-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-cycle",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-cycle/SKILL.md",
          "type": "blob",
          "size": 109753
        },
        {
          "path": "dev-team/skills/dev-devops",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-devops/SKILL.md",
          "type": "blob",
          "size": 14243
        },
        {
          "path": "dev-team/skills/dev-feedback-loop",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-feedback-loop/SKILL.md",
          "type": "blob",
          "size": 21333
        },
        {
          "path": "dev-team/skills/dev-implementation",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-implementation/SKILL.md",
          "type": "blob",
          "size": 18693
        },
        {
          "path": "dev-team/skills/dev-refactor",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-refactor/SKILL.md",
          "type": "blob",
          "size": 37109
        },
        {
          "path": "dev-team/skills/dev-sre",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-sre/SKILL.md",
          "type": "blob",
          "size": 18875
        },
        {
          "path": "dev-team/skills/dev-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-testing/SKILL.md",
          "type": "blob",
          "size": 14226
        },
        {
          "path": "dev-team/skills/dev-validation",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/dev-validation/SKILL.md",
          "type": "blob",
          "size": 13486
        },
        {
          "path": "dev-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/shared-patterns/output-execution-report.md",
          "type": "blob",
          "size": 1638
        },
        {
          "path": "dev-team/skills/shared-patterns/shared-anti-rationalization.md",
          "type": "blob",
          "size": 12984
        },
        {
          "path": "dev-team/skills/shared-patterns/shared-orchestrator-principle.md",
          "type": "blob",
          "size": 11044
        },
        {
          "path": "dev-team/skills/shared-patterns/shared-pressure-resistance.md",
          "type": "blob",
          "size": 4342
        },
        {
          "path": "dev-team/skills/shared-patterns/shared-red-flags.md",
          "type": "blob",
          "size": 3176
        },
        {
          "path": "dev-team/skills/shared-patterns/standards-boundary-enforcement.md",
          "type": "blob",
          "size": 7485
        },
        {
          "path": "dev-team/skills/shared-patterns/standards-compliance-detection.md",
          "type": "blob",
          "size": 10190
        },
        {
          "path": "dev-team/skills/shared-patterns/standards-coverage-table.md",
          "type": "blob",
          "size": 17583
        },
        {
          "path": "dev-team/skills/shared-patterns/standards-workflow.md",
          "type": "blob",
          "size": 18986
        },
        {
          "path": "dev-team/skills/shared-patterns/template-tdd-prompts.md",
          "type": "blob",
          "size": 19285
        },
        {
          "path": "dev-team/skills/using-dev-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "dev-team/skills/using-dev-team/SKILL.md",
          "type": "blob",
          "size": 10448
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/AGENT_DESIGN.md",
          "type": "blob",
          "size": 8141
        },
        {
          "path": "docs/PROJECT_RULES.md",
          "type": "blob",
          "size": 440
        },
        {
          "path": "docs/PROMPT_ENGINEERING.md",
          "type": "blob",
          "size": 16342
        },
        {
          "path": "docs/WORKFLOWS.md",
          "type": "blob",
          "size": 6328
        },
        {
          "path": "docs/handoffs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/handoffs/ring-namespace-refactor",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/handoffs/ring-namespace-refactor/2026-01-12_14-52-38_unified-ring-prefix.md",
          "type": "blob",
          "size": 6270
        },
        {
          "path": "finops-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/agents/finops-analyzer.md",
          "type": "blob",
          "size": 23333
        },
        {
          "path": "finops-team/agents/finops-automation.md",
          "type": "blob",
          "size": 23865
        },
        {
          "path": "finops-team/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/dictionaries",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/dictionaries/apix-001.yaml",
          "type": "blob",
          "size": 9924
        },
        {
          "path": "finops-team/docs/regulatory/dictionaries/cadoc-4010.yaml",
          "type": "blob",
          "size": 5560
        },
        {
          "path": "finops-team/docs/regulatory/dictionaries/cadoc-4016.yaml",
          "type": "blob",
          "size": 4167
        },
        {
          "path": "finops-team/docs/regulatory/dictionaries/efinanceira-evtCadDeclarante.yaml",
          "type": "blob",
          "size": 10075
        },
        {
          "path": "finops-team/docs/regulatory/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/APIX",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/APIX/001",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/APIX/001/APIX001_2-5.xsd",
          "type": "blob",
          "size": 14396
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/CADOC",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/CADOC/4010",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/CADOC/4010/generated",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/CADOC/4010/generated/cadoc4010_preview.tpl",
          "type": "blob",
          "size": 533
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/CADOC/4010/generated/cadoc4010_preview.tpl.docs",
          "type": "blob",
          "size": 5034
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/CADOC/cadoc-4010-4016.md",
          "type": "blob",
          "size": 9499
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/OpenBanking",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/OpenBanking/apix-reference.md",
          "type": "blob",
          "size": 9935
        },
        {
          "path": "finops-team/docs/regulatory/templates/BACEN/OpenBanking/open-banking-brasil.md",
          "type": "blob",
          "size": 11932
        },
        {
          "path": "finops-team/docs/regulatory/templates/RFB",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/RFB/DIMP",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/RFB/DIMP/dimp-v10-manual.md",
          "type": "blob",
          "size": 10172
        },
        {
          "path": "finops-team/docs/regulatory/templates/RFB/EFINANCEIRA",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/docs/regulatory/templates/RFB/EFINANCEIRA/efinanceira.md",
          "type": "blob",
          "size": 1406363
        },
        {
          "path": "finops-team/docs/regulatory/templates/registry.yaml",
          "type": "blob",
          "size": 9142
        },
        {
          "path": "finops-team/docs/regulatory/templates/reporter-guide.md",
          "type": "blob",
          "size": 12479
        },
        {
          "path": "finops-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": "finops-team/hooks/session-start.sh",
          "type": "blob",
          "size": 3414
        },
        {
          "path": "finops-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/regulatory-templates-gate1",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/regulatory-templates-gate1/SKILL.md",
          "type": "blob",
          "size": 22499
        },
        {
          "path": "finops-team/skills/regulatory-templates-gate2",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/regulatory-templates-gate2/SKILL.md",
          "type": "blob",
          "size": 12128
        },
        {
          "path": "finops-team/skills/regulatory-templates-gate3",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/regulatory-templates-gate3/SKILL.md",
          "type": "blob",
          "size": 9526
        },
        {
          "path": "finops-team/skills/regulatory-templates-setup",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/regulatory-templates-setup/SKILL.md",
          "type": "blob",
          "size": 9872
        },
        {
          "path": "finops-team/skills/regulatory-templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/regulatory-templates/SKILL.md",
          "type": "blob",
          "size": 12345
        },
        {
          "path": "finops-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/shared-patterns/anti-rationalization.md",
          "type": "blob",
          "size": 2875
        },
        {
          "path": "finops-team/skills/shared-patterns/pressure-resistance.md",
          "type": "blob",
          "size": 2273
        },
        {
          "path": "finops-team/skills/using-finops-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "finops-team/skills/using-finops-team/SKILL.md",
          "type": "blob",
          "size": 7440
        },
        {
          "path": "install-ring.ps1",
          "type": "blob",
          "size": 7138
        },
        {
          "path": "install-ring.sh",
          "type": "blob",
          "size": 7515
        },
        {
          "path": "installer",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/install-ring.ps1",
          "type": "blob",
          "size": 7944
        },
        {
          "path": "installer/install-ring.sh",
          "type": "blob",
          "size": 6278
        },
        {
          "path": "installer/pyproject.toml",
          "type": "blob",
          "size": 2062
        },
        {
          "path": "installer/requirements.txt",
          "type": "blob",
          "size": 216
        },
        {
          "path": "installer/ring_installer",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/ring_installer/__init__.py",
          "type": "blob",
          "size": 1357
        },
        {
          "path": "installer/ring_installer/__main__.py",
          "type": "blob",
          "size": 23791
        },
        {
          "path": "installer/ring_installer/adapters",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/ring_installer/adapters/__init__.py",
          "type": "blob",
          "size": 5926
        },
        {
          "path": "installer/ring_installer/adapters/base.py",
          "type": "blob",
          "size": 10113
        },
        {
          "path": "installer/ring_installer/adapters/claude.py",
          "type": "blob",
          "size": 6324
        },
        {
          "path": "installer/ring_installer/adapters/cline.py",
          "type": "blob",
          "size": 15384
        },
        {
          "path": "installer/ring_installer/adapters/cursor.py",
          "type": "blob",
          "size": 11950
        },
        {
          "path": "installer/ring_installer/adapters/factory.py",
          "type": "blob",
          "size": 30711
        },
        {
          "path": "installer/ring_installer/adapters/opencode.py",
          "type": "blob",
          "size": 27196
        },
        {
          "path": "installer/ring_installer/core.py",
          "type": "blob",
          "size": 54538
        },
        {
          "path": "installer/ring_installer/manifests",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/ring_installer/manifests/platforms.json",
          "type": "blob",
          "size": 7088
        },
        {
          "path": "installer/ring_installer/transformers",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/ring_installer/transformers/__init__.py",
          "type": "blob",
          "size": 10071
        },
        {
          "path": "installer/ring_installer/transformers/agent.py",
          "type": "blob",
          "size": 10540
        },
        {
          "path": "installer/ring_installer/transformers/base.py",
          "type": "blob",
          "size": 13006
        },
        {
          "path": "installer/ring_installer/transformers/cline_prompts.py",
          "type": "blob",
          "size": 14733
        },
        {
          "path": "installer/ring_installer/transformers/command.py",
          "type": "blob",
          "size": 9526
        },
        {
          "path": "installer/ring_installer/transformers/cursor_rules.py",
          "type": "blob",
          "size": 9107
        },
        {
          "path": "installer/ring_installer/transformers/hooks.py",
          "type": "blob",
          "size": 11504
        },
        {
          "path": "installer/ring_installer/transformers/skill.py",
          "type": "blob",
          "size": 10433
        },
        {
          "path": "installer/ring_installer/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/ring_installer/utils/__init__.py",
          "type": "blob",
          "size": 1097
        },
        {
          "path": "installer/ring_installer/utils/fs.py",
          "type": "blob",
          "size": 10825
        },
        {
          "path": "installer/ring_installer/utils/platform_detect.py",
          "type": "blob",
          "size": 17924
        },
        {
          "path": "installer/ring_installer/utils/version.py",
          "type": "blob",
          "size": 13344
        },
        {
          "path": "installer/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/tests/conftest.py",
          "type": "blob",
          "size": 18329
        },
        {
          "path": "installer/tests/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/tests/fixtures/README.md",
          "type": "blob",
          "size": 644
        },
        {
          "path": "installer/tests/fixtures/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/tests/fixtures/agents/sample-agent.md",
          "type": "blob",
          "size": 1434
        },
        {
          "path": "installer/tests/fixtures/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/tests/fixtures/commands/sample-command.md",
          "type": "blob",
          "size": 1077
        },
        {
          "path": "installer/tests/fixtures/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/tests/fixtures/hooks/hooks.json",
          "type": "blob",
          "size": 874
        },
        {
          "path": "installer/tests/fixtures/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/tests/fixtures/skills/sample-skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "installer/tests/fixtures/skills/sample-skill/SKILL.md",
          "type": "blob",
          "size": 1393
        },
        {
          "path": "installer/tests/test_adapters.py",
          "type": "blob",
          "size": 45374
        },
        {
          "path": "installer/tests/test_core.py",
          "type": "blob",
          "size": 51763
        },
        {
          "path": "installer/tests/test_transformers.py",
          "type": "blob",
          "size": 30568
        },
        {
          "path": "installer/tests/test_utils.py",
          "type": "blob",
          "size": 33738
        },
        {
          "path": "installer/uv.lock",
          "type": "blob",
          "size": 198956
        },
        {
          "path": "pm-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/agents/best-practices-researcher.md",
          "type": "blob",
          "size": 13050
        },
        {
          "path": "pm-team/agents/framework-docs-researcher.md",
          "type": "blob",
          "size": 14536
        },
        {
          "path": "pm-team/agents/repo-research-analyst.md",
          "type": "blob",
          "size": 12523
        },
        {
          "path": "pm-team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/commands/pre-dev-feature.md",
          "type": "blob",
          "size": 7469
        },
        {
          "path": "pm-team/commands/pre-dev-full.md",
          "type": "blob",
          "size": 11090
        },
        {
          "path": "pm-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": "pm-team/hooks/session-start.sh",
          "type": "blob",
          "size": 5556
        },
        {
          "path": "pm-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-api-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-api-design/SKILL.md",
          "type": "blob",
          "size": 9551
        },
        {
          "path": "pm-team/skills/pre-dev-data-model",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-data-model/SKILL.md",
          "type": "blob",
          "size": 9752
        },
        {
          "path": "pm-team/skills/pre-dev-dependency-map",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-dependency-map/SKILL.md",
          "type": "blob",
          "size": 14610
        },
        {
          "path": "pm-team/skills/pre-dev-feature-map",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-feature-map/SKILL.md",
          "type": "blob",
          "size": 8375
        },
        {
          "path": "pm-team/skills/pre-dev-prd-creation",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-prd-creation/SKILL.md",
          "type": "blob",
          "size": 9665
        },
        {
          "path": "pm-team/skills/pre-dev-research",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-research/SKILL.md",
          "type": "blob",
          "size": 5714
        },
        {
          "path": "pm-team/skills/pre-dev-subtask-creation",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-subtask-creation/SKILL.md",
          "type": "blob",
          "size": 7742
        },
        {
          "path": "pm-team/skills/pre-dev-task-breakdown",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-task-breakdown/SKILL.md",
          "type": "blob",
          "size": 8872
        },
        {
          "path": "pm-team/skills/pre-dev-trd-creation",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/pre-dev-trd-creation/SKILL.md",
          "type": "blob",
          "size": 14211
        },
        {
          "path": "pm-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/shared-patterns/anti-rationalization.md",
          "type": "blob",
          "size": 2497
        },
        {
          "path": "pm-team/skills/shared-patterns/pressure-resistance.md",
          "type": "blob",
          "size": 2206
        },
        {
          "path": "pm-team/skills/using-pm-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "pm-team/skills/using-pm-team/SKILL.md",
          "type": "blob",
          "size": 5980
        },
        {
          "path": "requirements.txt",
          "type": "blob",
          "size": 245
        },
        {
          "path": "shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "shared/lib",
          "type": "tree",
          "size": null
        },
        {
          "path": "shared/lib/context-check.sh",
          "type": "blob",
          "size": 5971
        },
        {
          "path": "shared/lib/generate-reference.py",
          "type": "blob",
          "size": 11527
        },
        {
          "path": "shared/lib/get-context-usage.sh",
          "type": "blob",
          "size": 3195
        },
        {
          "path": "shared/lib/json-escape.sh",
          "type": "blob",
          "size": 1340
        },
        {
          "path": "shared/lib/ledger-utils.sh",
          "type": "blob",
          "size": 1780
        },
        {
          "path": "shared/lib/session-utils.sh",
          "type": "blob",
          "size": 884
        },
        {
          "path": "tw-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/agents/api-writer.md",
          "type": "blob",
          "size": 15692
        },
        {
          "path": "tw-team/agents/docs-reviewer.md",
          "type": "blob",
          "size": 16448
        },
        {
          "path": "tw-team/agents/functional-writer.md",
          "type": "blob",
          "size": 14254
        },
        {
          "path": "tw-team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/commands/review-docs.md",
          "type": "blob",
          "size": 3404
        },
        {
          "path": "tw-team/commands/write-api.md",
          "type": "blob",
          "size": 3821
        },
        {
          "path": "tw-team/commands/write-guide.md",
          "type": "blob",
          "size": 2912
        },
        {
          "path": "tw-team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/hooks/hooks.json",
          "type": "blob",
          "size": 463
        },
        {
          "path": "tw-team/hooks/session-start.sh",
          "type": "blob",
          "size": 3894
        },
        {
          "path": "tw-team/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/api-field-descriptions",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/api-field-descriptions/SKILL.md",
          "type": "blob",
          "size": 3873
        },
        {
          "path": "tw-team/skills/documentation-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/documentation-review/SKILL.md",
          "type": "blob",
          "size": 4061
        },
        {
          "path": "tw-team/skills/documentation-structure",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/documentation-structure/SKILL.md",
          "type": "blob",
          "size": 4435
        },
        {
          "path": "tw-team/skills/shared-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/shared-patterns/anti-rationalization.md",
          "type": "blob",
          "size": 2856
        },
        {
          "path": "tw-team/skills/shared-patterns/pressure-resistance.md",
          "type": "blob",
          "size": 2225
        },
        {
          "path": "tw-team/skills/using-tw-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/using-tw-team/SKILL.md",
          "type": "blob",
          "size": 3842
        },
        {
          "path": "tw-team/skills/voice-and-tone",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/voice-and-tone/SKILL.md",
          "type": "blob",
          "size": 4502
        },
        {
          "path": "tw-team/skills/writing-api-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/writing-api-docs/SKILL.md",
          "type": "blob",
          "size": 5020
        },
        {
          "path": "tw-team/skills/writing-functional-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "tw-team/skills/writing-functional-docs/SKILL.md",
          "type": "blob",
          "size": 3386
        }
      ],
      "marketplace": {
        "name": "ring",
        "version": "0.186.0",
        "description": "Lerian Studio plugin marketplace: Core software engineering skills (TDD, debugging, code review), specialized developer agents (Backend, DevOps, Frontend, QA, SRE), product planning workflows (9-gate pre-dev system), FinOps/regulatory compliance for Brazilian financial systems (BACEN, RFB), and technical writing specialists for documentation.",
        "owner_info": {
          "name": "Fred Amaral",
          "email": "fred@fredamaral.com.br"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "ring-default",
            "description": "Core skills library for the Lerian Team: TDD, debugging, collaboration patterns, and proven techniques. Features parallel 3-reviewer code review system (Foundation, Correctness, Safety), systematic debugging, and workflow orchestration. 21 essential skills for software engineering excellence.",
            "source": "./default",
            "category": null,
            "version": "0.33.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add LerianStudio/ring",
              "/plugin install ring-default@ring"
            ],
            "signals": {
              "stars": 39,
              "forks": 2,
              "pushed_at": "2026-01-12T18:20:36Z",
              "created_at": "2025-10-30T20:18:13Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/brainstorm",
                "description": "Interactive design refinement using Socratic method",
                "path": "default/commands/brainstorm.md",
                "frontmatter": {
                  "name": "ring:brainstorm",
                  "description": "Interactive design refinement using Socratic method",
                  "argument-hint": "[topic]"
                },
                "content": "Transform rough ideas into fully-formed designs through structured questioning and alternative exploration. This command initiates an interactive design session using the Socratic method to refine your concept before implementation.\n\n## Usage\n\n```\n/brainstorm [topic]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `topic` | Yes | The feature, product, or system you want to design (e.g., \"user authentication\", \"payment processing\", \"notification system\") |\n\n## Examples\n\n### Starting a Feature Design\n```\n/brainstorm OAuth2 integration\n```\nInitiates a design session for adding OAuth2 authentication to your application.\n\n### Architectural Decision\n```\n/brainstorm microservices migration strategy\n```\nExplores approaches for migrating from monolith to microservices architecture.\n\n### New Product Concept\n```\n/brainstorm real-time collaboration feature\n```\nRefines requirements and design for a collaborative editing feature.\n\n## Process\n\nThe brainstorming session follows these phases:\n\n### 1. Autonomous Recon (Prep)\n- Inspects repository structure, documentation, and recent commits\n- Forms initial understanding of the codebase context\n- Shares findings before asking questions\n\n### 2. Understanding (Phase 1)\n- Shares synthesized understanding for validation\n- Asks targeted questions (max 3) to fill knowledge gaps\n- Gathers: purpose, constraints, success criteria\n\n### 3. Exploration (Phase 2)\n- Proposes 2-3 different architectural approaches\n- Presents trade-offs for each option\n- Recommends preferred approach with rationale\n- Uses `AskUserQuestion` for approach selection\n\n### 4. Design Presentation (Phase 3)\n- Presents design in 200-300 word sections\n- Covers: architecture, components, data flow, error handling, testing\n- Validates each section incrementally\n- Requires explicit approval (\"Approved\", \"Looks good\", \"Proceed\")\n\n### 5. Design Documentation (Phase 4)\n- Writes validated design to `docs/plans/YYYY-MM-DD-<topic>-design.md`\n- Commits the design document to git\n\n### 6. Worktree Setup (Phase 5, if implementing)\n- Sets up isolated git worktree for development\n- Prepares clean workspace for implementation\n\n### 7. Planning Handoff (Phase 6, if implementing)\n- Creates detailed implementation plan using `writing-plans` skill\n- Breaks design into bite-sized executable tasks\n\n## Related Commands/Skills\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `/write-plan` | Use after brainstorming when design is complete |\n| `/execute-plan` | Use after planning to implement the design |\n| `writing-plans` | Underlying skill for creating implementation plans |\n\n## Troubleshooting\n\n### \"Design not validated\"\nThe session requires explicit approval from you before proceeding. Responses like \"interesting\" or \"I see\" do not count as approval. Say \"approved\", \"looks good\", or \"proceed\" to advance.\n\n### \"Too many questions\"\nEach phase has a maximum of 3 questions. If you're being asked more, it indicates insufficient autonomous research. Request the agent to explore the codebase first.\n\n### \"Skipping phases\"\nThe process is phase-locked. You cannot skip ahead until the current phase is complete. If you need to go faster, provide explicit approval at each checkpoint.\n\n### When NOT to use this command\n- Design is already complete and validated - use `/write-plan`\n- Have a detailed plan ready to execute - use `/execute-plan`\n- Just need task breakdown from existing design - use `/write-plan`\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:brainstorming\n```\n\nThe skill contains the complete workflow with:\n- Socratic questioning framework\n- Design refinement phases\n- Challenge identification\n- Solution exploration\n- Decision documentation"
              },
              {
                "name": "/codereview",
                "description": "Run comprehensive parallel code review with all 5 specialized reviewers",
                "path": "default/commands/codereview.md",
                "frontmatter": {
                  "name": "ring:codereview",
                  "description": "Run comprehensive parallel code review with all 5 specialized reviewers",
                  "argument-hint": "[files-or-paths]"
                },
                "content": "Dispatch all 5 specialized code reviewers in parallel, collect their reports, and provide a consolidated analysis.\n\n## Review Process\n\n### Step 1: Dispatch All Five Reviewers in Parallel\n\n**CRITICAL: Use a single message with 5 Task tool calls to launch all reviewers simultaneously.**\n\nGather the required context first:\n- WHAT_WAS_IMPLEMENTED: Summary of changes made\n- PLAN_OR_REQUIREMENTS: Original plan or requirements (if available)\n- BASE_SHA: Base commit for comparison (if applicable)\n- HEAD_SHA: Head commit for comparison (if applicable)\n- DESCRIPTION: Additional context about the changes\n- LANGUAGES: Go, TypeScript, or both (for nil-safety-reviewer)\n\nThen dispatch all 5 reviewers:\n\n```\nTask tool #1 (code-reviewer):\n  subagent_type: \"ring:code-reviewer\"\n  model: \"opus\"\n  description: \"Review code quality and architecture\"\n  prompt: |\n    WHAT_WAS_IMPLEMENTED: [summary of changes]\n    PLAN_OR_REQUIREMENTS: [original plan/requirements]\n    BASE_SHA: [base commit if applicable]\n    HEAD_SHA: [head commit if applicable]\n    DESCRIPTION: [additional context]\n\nTask tool #2 (business-logic-reviewer):\n  subagent_type: \"ring:business-logic-reviewer\"\n  model: \"opus\"\n  description: \"Review business logic correctness\"\n  prompt: |\n    [Same parameters as above]\n\nTask tool #3 (security-reviewer):\n  subagent_type: \"ring:security-reviewer\"\n  model: \"opus\"\n  description: \"Review security vulnerabilities\"\n  prompt: |\n    [Same parameters as above]\n\nTask tool #4 (test-reviewer):\n  subagent_type: \"ring:test-reviewer\"\n  model: \"opus\"\n  description: \"Review test quality and coverage\"\n  prompt: |\n    [Same parameters as above]\n    Focus: Edge cases, error paths, test independence, assertion quality.\n\nTask tool #5 (nil-safety-reviewer):\n  subagent_type: \"ring:nil-safety-reviewer\"\n  model: \"opus\"\n  description: \"Review nil/null pointer safety\"\n  prompt: |\n    [Same parameters as above]\n    LANGUAGES: [Go|TypeScript|both]\n    Focus: Nil sources, propagation paths, missing guards.\n```\n\n**Wait for all five reviewers to complete their work.**\n\n### Step 2: Collect and Aggregate Reports\n\nEach reviewer returns:\n- **Verdict:** PASS/FAIL/NEEDS_DISCUSSION\n- **Strengths:** What was done well\n- **Issues:** Categorized by severity (Critical/High/Medium/Low/Cosmetic)\n- **Recommendations:** Specific actionable feedback\n\nConsolidate all issues by severity across all five reviewers.\n\n### Conflict Resolution\n\nWhen aggregating findings, detect and flag conflicting recommendations between reviewers:\n\n| Conflict Type | Resolution | Priority |\n|--------------|------------|----------|\n| Security vs Performance | Security recommendation wins | CRITICAL |\n| More tests vs Over-testing | Defer to test-reviewer for test scope | MEDIUM |\n| More mocks vs Less mocks | Evaluate based on test-reviewer guidance | MEDIUM |\n| Refactor vs Keep simple | Defer to code-reviewer for architecture decisions | MEDIUM |\n\n**Flagging Conflicts:**\nWhen reviewers provide contradictory guidance:\n1. Include BOTH recommendations in consolidated report\n2. Add a \" Conflict\" marker\n3. Present to user for final decision\n4. Do NOT automatically resolve conflicting recommendations\n\n**Example:**\n```\n Conflict Detected:\n- test-reviewer: \"Add more mock isolation for external services\"\n- code-reviewer: \"Current mocking approach is sufficient\"\n- Resolution: User decision required - see both perspectives above\n```\n\n### Step 3: Provide Consolidated Report\n\nReturn a consolidated report in this format:\n\n```markdown\n# Full Review Report\n\n## VERDICT: [PASS | FAIL | NEEDS_DISCUSSION]\n\n## Executive Summary\n\n[2-3 sentences about overall review across all gates]\n\n**Total Issues:**\n- Critical: [N across all gates]\n- High: [N across all gates]\n- Medium: [N across all gates]\n- Low: [N across all gates]\n\n---\n\n## Code Quality Review (Foundation)\n\n**Verdict:** [PASS | FAIL]\n**Issues:** Critical [N], High [N], Medium [N], Low [N]\n\n### Critical Issues\n[List all critical code quality issues]\n\n### High Issues\n[List all high code quality issues]\n\n[Medium/Low issues summary]\n\n---\n\n## Business Logic Review (Correctness)\n\n**Verdict:** [PASS | FAIL]\n**Issues:** Critical [N], High [N], Medium [N], Low [N]\n\n### Critical Issues\n[List all critical business logic issues]\n\n### High Issues\n[List all high business logic issues]\n\n[Medium/Low issues summary]\n\n---\n\n## Security Review (Safety)\n\n**Verdict:** [PASS | FAIL]\n**Issues:** Critical [N], High [N], Medium [N], Low [N]\n\n### Critical Vulnerabilities\n[List all critical security vulnerabilities]\n\n### High Vulnerabilities\n[List all high security vulnerabilities]\n\n[Medium/Low vulnerabilities summary]\n\n---\n\n## Test Quality Review (Coverage)\n\n**Verdict:** [PASS | FAIL]\n**Issues:** Critical [N], High [N], Medium [N], Low [N]\n\n### Critical Issues\n[Untested core logic, tests testing mock behavior]\n\n### High Issues\n[Missing edge cases, test anti-patterns]\n\n[Medium/Low issues summary]\n\n---\n\n## Nil-Safety Review (Pointer Safety)\n\n**Verdict:** [PASS | FAIL]\n**Issues:** Critical [N], High [N], Medium [N], Low [N]\n\n### Critical Issues\n[Direct panic paths, unguarded nil dereference]\n\n### High Issues\n[Conditional nil risks, missing ok checks]\n\n[Medium/Low issues summary]\n\n---\n\n## Consolidated Action Items\n\n**MUST FIX (Critical):**\n1. [Issue from any gate] - `file:line`\n2. [Issue from any gate] - `file:line`\n\n**SHOULD FIX (High):**\n1. [Issue from any gate] - `file:line`\n2. [Issue from any gate] - `file:line`\n\n**CONSIDER (Medium/Low):**\n[Brief list]\n\n---\n\n## Next Steps\n\n**If PASS:**\n-  All 5 reviewers passed\n-  Ready for next step (merge/production)\n\n**If FAIL:**\n-  Fix all Critical/High/Medium issues immediately\n-  Add TODO(review) comments for Low issues in code\n-  Add FIXME(nitpick) comments for Cosmetic/Nitpick issues in code\n-  Re-run all 5 reviewers in parallel after fixes\n\n**If NEEDS_DISCUSSION:**\n-  [Specific discussion points across gates]\n```\n\n## Severity-Based Action Guide\n\nAfter producing the consolidated report, provide clear guidance:\n\n**Critical/High/Medium Issues:**\n```\nThese issues MUST be fixed immediately:\n1. [Issue description] - file.ext:line - [Reviewer]\n2. [Issue description] - file.ext:line - [Reviewer]\n\nRecommended approach:\n- Dispatch fix subagent to address all Critical/High/Medium issues\n- After fixes complete, re-run all 5 reviewers in parallel to verify\n```\n\n**Low Issues:**\n```\nAdd TODO comments in the code for these issues:\n\n// TODO(review): [Issue description]\n// Reported by: [reviewer-name] on [date]\n// Severity: Low\n// Location: file.ext:line\n```\n\n**Cosmetic/Nitpick Issues:**\n```\nAdd FIXME comments in the code for these issues:\n\n// FIXME(nitpick): [Issue description]\n// Reported by: [reviewer-name] on [date]\n// Severity: Cosmetic\n// Location: file.ext:line\n```\n\n## Reviewer Failure Handling\n\nIf any reviewer fails during execution (timeout, error, incomplete output):\n\n### Single Reviewer Failure\n\n1. **Do NOT aggregate partial results** - Wait for all 5 reviewers\n2. **Retry the failed reviewer once:**\n   ```\n   Task tool (retry failed reviewer):\n     model: \"opus\"\n     description: \"Retry [reviewer-name] review\"\n     prompt: [same parameters as original]\n   ```\n3. **If retry fails:** Report which reviewer failed and why\n4. **Continue with available results** only if user explicitly approves\n\n### Multiple Reviewer Failures\n\n1. **Stop and report** - Do not provide partial review\n2. **Investigate root cause:**\n   - Large codebase? Consider chunking files\n   - Timeout? Increase timeout or reduce scope\n   - Error? Check file paths and permissions\n3. **Retry all failed reviewers** after addressing root cause\n\n### Incomplete Output Detection\n\nSigns that a reviewer produced incomplete output:\n\n| Pattern | Detection Method | Action |\n|---------|-----------------|--------|\n| Missing VERDICT | Output lacks \"## VERDICT:\" or \"**Verdict:**\" | Re-dispatch reviewer |\n| Empty Issues section | \"## Issues Found\" followed by no content or \"None\" only | Verify this is intentional (PASS case) |\n| Missing required sections | Check against output_schema in agent definition | Re-dispatch with explicit section reminder |\n| Truncated output | Ends mid-sentence or lacks closing sections | Re-dispatch with smaller scope |\n| Generic responses | Only contains boilerplate without file-specific analysis | Re-dispatch with explicit file list |\n\n**Validation Regex Patterns:**\n- Verdict present: `/^##?\\s*VERDICT:?\\s*(PASS|FAIL|NEEDS_DISCUSSION)/im`\n- Issues section: `/^##?\\s*Issues Found/im`\n- Summary present: `/^##?\\s*(Summary|Executive Summary)/im`\n\n**Action:** Re-dispatch the reviewer with explicit instruction to include all required sections.\n\n## Remember\n\n1. **All reviewers are independent** - They run in parallel, not sequentially\n2. **Dispatch all 5 reviewers in parallel** - Single message, 5 Task calls\n3. **Specify model: \"opus\"** - All reviewers need opus for comprehensive analysis\n4. **Wait for all to complete** - Don't aggregate until all reports received\n5. **Consolidate findings by severity** - Group all issues across reviewers\n6. **Provide clear action guidance** - Tell user exactly what to fix vs. document\n7. **Overall FAIL if any reviewer fails** - One failure means work needs fixes\n8. **Retry failed reviewers once** - Don't give up on first failure\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:requesting-code-review\n```\n\nThe skill contains the complete workflow with:\n- Auto-detection of git context (base_sha, head_sha, files)\n- Parallel dispatch of all 5 reviewers in single message\n- Issue aggregation by severity\n- Iteration loop with fix dispatching\n- Escalation handling at max iterations\n- Anti-rationalization tables\n- Pressure resistance scenarios"
              },
              {
                "name": "/commit",
                "description": "Organize and create atomic git commits with intelligent change grouping",
                "path": "default/commands/commit.md",
                "frontmatter": {
                  "name": "ring:commit",
                  "description": "Organize and create atomic git commits with intelligent change grouping",
                  "argument-hint": "[message]"
                },
                "content": "Analyze changes, group them into coherent atomic commits, and create signed commits following repository conventions. This command transforms a messy working directory into a clean, logical commit history.\n\n## Smart Commit Organization\n\n**This command does MORE than just commit.** It analyzes your changes and organizes them intelligently.\n\n### What It Does\n\n```\nWorking Directory State            Organized Commits\n\n- Modified: auth.ts                Commit 1: feat(auth): add OAuth2 support\n- Modified: auth.test.ts            (auth.ts + auth.test.ts)\n- Modified: package.json           Commit 2: chore(deps): update dependencies\n- Modified: README.md              Commit 3: docs: update authentication guide\n- New: logger.ts                   Commit 4: feat(logging): add structured logger\n- New: logger.test.ts               (logger.ts + logger.test.ts)\n```\n\n### Grouping Principles\n\n| Principle | Description |\n|-----------|-------------|\n| **Feature + Tests** | Implementation and its tests go together |\n| **Config Changes** | package.json, tsconfig, etc. grouped separately |\n| **Documentation** | README, docs/ changes grouped together |\n| **Refactoring** | Pure refactors (no behavior change) separate |\n| **Bug Fixes** | Each fix is atomic with its test |\n\n### Process Overview\n\n1. **Analyze** - Run `git status` and `git diff` to understand all changes\n2. **Group** - Cluster related changes into logical commits\n3. **Order** - Determine optimal commit sequence (deps before features, etc.)\n4. **Confirm** - Present grouping plan to user for approval\n5. **Execute** - Create signed commits in sequence\n\n### Single vs Multiple Commits\n\n**Single commit when:**\n- All changes are for one coherent feature/fix\n- User provides a specific message via argument\n- Changes are minimal and related\n\n**Multiple commits when:**\n- Changes span different concerns (feature + docs + deps)\n- Mix of features, fixes, and chores\n- Better git history benefits future archaeology\n\n### User Confirmation\n\nBefore creating commits, present the plan:\n\n```\nProposed Commit Plan:\n\n1. feat(auth): add OAuth2 refresh token support\n   - src/auth/oauth.ts (modified)\n   - src/auth/oauth.test.ts (modified)\n\n2. chore(deps): update authentication dependencies\n   - package.json (modified)\n   - package-lock.json (modified)\n\n3. docs: update OAuth2 setup guide\n   - docs/auth/oauth-setup.md (modified)\n\nProceed with this plan? [Yes / Modify / Single commit]\n```\n\nUse `AskUserQuestion` to confirm:\n- **Yes** - Execute the plan as proposed\n- **Modify** - User can adjust groupings\n- **Single commit** - Combine everything into one commit\n\n##  HARD STOP - TRAILER RULES \n\n**THE MOST COMMON MISTAKE:** Putting trailer text INSIDE the `-m` quotes.\n\n```bash\n#  WRONG - \"X-Lerian-Ref\" text is INSIDE the -m quotes\ngit commit -m \"feat: add feature\n\nX-Lerian-Ref: 0x1\"\n\n#  CORRECT - --trailer is a SEPARATE command-line argument OUTSIDE quotes\ngit commit -m \"feat: add feature\" --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n**BEFORE writing ANY git commit command, answer this checkpoint:**\n\n- [ ] Does my `-m \"...\"` contain ONLY the commit message? (NO trailer text inside)\n- [ ] Are `--trailer` flags OUTSIDE and AFTER the `-m` parameter?\n- [ ] Is my command structured as: `git commit -m \"msg\" --trailer \"key: value\"`?\n\n**If you answered NO to ANY question  STOP. Re-read the MANDATORY RULES below.**\n\n## Required Command Structure\n\n**EVERY git commit command you create MUST follow this exact structure:**\n\n```bash\ngit commit \\\n  -m \"commit message line 1\" \\\n  -m \"optional body line 2\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n**Visual breakdown - understand WHERE each piece goes:**\n\n```\ngit commit -m \"feat: add feature\" --trailer \"X-Lerian-Ref: 0x1\"\n                                                           \n            MESSAGE   SEPARATE FLAG (NOT inside -m) \n               (inside quotes)        (after the closing quote)\n```\n\n**The `--trailer` flag is NOT text. It's a command-line argument to git, like `-m` or `--amend`.**\n\n**Notice:**\n- `-m` parameters come FIRST\n- `-m` contains ONLY the commit message (no trailers, no signatures)\n- `--trailer` parameters come AFTER all `-m` parameters\n- `--trailer` is a SEPARATE command-line argument\n\n**If your command doesn't match this structure  YOU ARE DOING IT WRONG.**\n\n## MANDATORY RULES (NON-NEGOTIABLE)\n\n**These rules MUST be followed for EVERY commit:**\n\n1. **NEVER include visible markers or hashtags in commit message body:**\n   - NO ` Generated with [Claude Code](https://claude.com/claude-code)`\n   - NO `Co-Authored-By` lines of any kind\n   - NO emoji signatures or hashtags of any kind\n   - NO \"Generated by\" text in message body\n   - NO system references or internal codes in the message body\n   - **The `-m` parameter contains ONLY the commit message. PERIOD.**\n\n2. **ALWAYS use `--trailer` parameter for internal system tracing:**\n   - `--trailer \"X-Lerian-Ref: 0x1\"` - REQUIRED\n   - Trailer goes AFTER all `-m` parameters in the git command\n   - Trailer is a SEPARATE command-line argument, NOT part of message text\n\n3. **Commit message body must be clean and professional:**\n   - Only the actual commit description\n   - No metadata, signatures, hashtags, or internal references in the body\n   - If you see emoji, hashtags, or \"X-Lerian-Ref\" in your `-m` text  YOU ARE DOING IT WRONG\n\n## Commit Process\n\n### Step 1: Gather Context\n\nRun these commands in parallel to understand the current state:\n\n```bash\n# Check staged and unstaged changes\ngit status\n\n# View ALL changes (staged and unstaged)\ngit diff\ngit diff --cached\n\n# View recent commits for style reference\ngit log --oneline -10\n```\n\n### Step 2: Analyze and Group Changes\n\n**For each changed file, determine:**\n1. **Type**: feat, fix, chore, docs, refactor, test, style, perf, ci, build\n2. **Scope**: Component or area affected (auth, api, ui, etc.)\n3. **Logical group**: What other files belong with this change?\n\n**Grouping heuristics:**\n\n| File Pattern | Likely Group |\n|--------------|--------------|\n| `*.test.ts`, `*.spec.ts` | Group with implementation file |\n| `package.json`, `*-lock.json` | Dependency changes |\n| `*.md`, `docs/*` | Documentation |\n| `*.config.*`, `tsconfig.*` | Configuration |\n| Same directory/module | Often related |\n\n**Create a mental (or actual) grouping:**\n\n```\nGroup 1 (feat): auth changes\n  - src/auth/oauth.ts\n  - src/auth/oauth.test.ts\n\nGroup 2 (chore): dependencies\n  - package.json\n  - package-lock.json\n\nGroup 3 (docs): documentation\n  - README.md\n```\n\n### Step 3: Determine Commit Order\n\n**Order matters for bisectability:**\n\n1. **Dependencies first** - So subsequent commits can use them\n2. **Core changes** - Implementation before consumers\n3. **Tests with implementation** - Keep them atomic\n4. **Documentation last** - Documents the final state\n\n### Step 4: Present Plan and Confirm\n\n**MANDATORY: Get user confirmation before executing.**\n\nPresent the commit plan using `AskUserQuestion`:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"I've analyzed your changes and propose this commit plan. How should I proceed?\",\n    header: \"Commit Plan\",\n    multiSelect: false,\n    options: [\n      { label: \"Execute plan\", description: \"Create X commits as proposed\" },\n      { label: \"Single commit\", description: \"Combine all changes into one commit\" },\n      { label: \"Let me review\", description: \"Show details before proceeding\" }\n    ]\n  }]\n});\n```\n\nIf user selects \"Let me review\", show the full plan with files per commit.\n\n### Step 5: Draft Commit Messages\n\nFollow the repository's existing commit style. If Conventional Commits is used:\n\n```\n<type>(<scope>): <subject>\n\n<body - optional>\n```\n\n**Guidelines:**\n- Subject line: max 50 characters, imperative mood (\"add\" not \"added\")\n- Body: wrap at 72 characters, explain motivation/context\n- **DO NOT include** emoji signatures, hashtags, \"Generated by\", \"X-Lerian-Ref\", or any system markers in the message body\n\n### Step 6: Execute Commits (Signed)\n\n**For each commit group, in order:**\n\n1. **Stage only the files for this commit:**\n```bash\ngit add <file1> <file2> ...\n```\n\n2. **Create signed commit with trailers:**\n```bash\ngit commit -S \\\n  -m \"<type>(<scope>): <subject>\" \\\n  -m \"<body if needed>\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n**Required flags:**\n- `-S` - GPG sign the commit (REQUIRED for signed commits)\n- `--trailer \"X-Lerian-Ref: 0x1\"` - Internal system reference (REQUIRED)\n\n**If GPG signing fails:**\n- Check if GPG key is configured: `git config user.signingkey`\n- Check if GPG agent is running: `gpg --list-secret-keys`\n- If no key configured, proceed without `-S` and inform user\n\n3. **Repeat for each commit group**\n\n### Step 7: Verify Commits\n\nAfter all commits, verify the result:\n\n```bash\n# Show all new commits\ngit log --oneline -<number_of_commits>\n\n# Verify signatures (if signed)\ngit log --show-signature -1\n\n# Confirm clean state\ngit status\n```\n\n## Examples\n\n### Simple Feature (Signed)\n```bash\ngit commit -S \\\n  -m \"feat(auth): add OAuth2 refresh token support\" \\\n  -m \"Implements automatic token refresh when access token expires, preventing session interruptions for long-running operations.\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n### Bug Fix (Signed)\n```bash\ngit commit -S \\\n  -m \"fix(api): handle null response in user endpoint\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n### Chore/Refactor (Signed)\n```bash\ngit commit -S \\\n  -m \"chore: update dependencies to latest versions\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n### Multi-Commit Sequence (Organized)\n\nWhen changes span multiple concerns, execute in sequence:\n\n```bash\n# Commit 1: Dependencies first\ngit add package.json package-lock.json\ngit commit -S \\\n  -m \"chore(deps): update authentication dependencies\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n\n# Commit 2: Feature implementation with tests\ngit add src/auth/oauth.ts src/auth/oauth.test.ts\ngit commit -S \\\n  -m \"feat(auth): add OAuth2 refresh token support\" \\\n  -m \"Implements automatic token refresh when access token expires.\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n\n# Commit 3: Documentation last\ngit add docs/auth/oauth-setup.md README.md\ngit commit -S \\\n  -m \"docs: update OAuth2 setup guide\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n## Trailer Query Commands\n\nTrailers can be queried programmatically:\n\n**Note:** `git log --grep` searches commit message content only, not trailers. Use `--format` with `%(trailers)` to query trailer values.\n\n```bash\n# Find all commits with specific X-Lerian-Ref trailer value\ngit log --all --format=\"%H %s %(trailers:key=X-Lerian-Ref,valueonly)\" | grep \"0x1\"\n\n# Show all trailers for a commit\ngit log -1 --format=\"%(trailers)\"\n\n# Filter commits by trailer existence (any value)\ngit log --all --format=\"%H %s\" | while read hash msg; do\n  git log -1 --format=\"%(trailers:key=X-Lerian-Ref)\" $hash | grep -q \".\" && echo \"$hash $msg\"\ndone\n```\n\n## Important Notes\n\n1. **Smart grouping** - Analyzes changes and proposes atomic commits for clean history\n2. **GPG signing** - All commits are signed with `-S` flag (requires GPG key configured)\n3. **No visible markers** - The message body stays clean and professional\n4. **Trailers are standard** - Git trailers are a recognized convention (like Signed-off-by)\n5. **Machine-readable** - Easy to filter/query commits with internal system reference\n6. **Transparent** - System tracing is documented, just not prominently displayed\n7. **Do not use --no-verify** - Always run pre-commit hooks unless user explicitly requests\n8. **User confirmation** - Always present commit plan before executing\n\n## Anti-Patterns (NEVER DO THIS)\n\n** THESE PATTERNS ARE FORBIDDEN. DO NOT USE THEM. **\n\n```bash\n#  WRONG - emoji or hashtags in message body\ngit commit -m \"feat: add feature\n\n Generated with [Claude Code](https://claude.com/claude-code)\"\n\n#  WRONG - hashtags in message body\ngit commit -m \"feat: add feature #ai-generated #automated\"\n\n#  WRONG - Co-Authored-By in message body\ngit commit -m \"feat: add feature\n\nCo-Authored-By: System <noreply@example.com>\"\n\n#  WRONG - HEREDOC with markers in message body\ngit commit -m \"$(cat <<'EOF'\nfeat: add feature\n\n Generated with AI\nEOF\n)\"\n\n#  WRONG - Trailer text inside -m parameter\ngit commit -m \"feat: add feature\n\nX-Lerian-Ref: 0x1\"\n\n#  WRONG - System reference as hashtag in message body\ngit commit -m \"feat: add feature #0x1\"\n\n#  WRONG - ANY attempt to include trailers, hashtags, or system markers in message body\n# The message body (-m parameter) must ONLY contain the commit description\n# NO trailers, NO signatures, NO emoji, NO hashtags, NO system markers of any kind\n```\n\n**Why these are wrong:** They put visible markers in the commit message body, making them visible in `git log --oneline` and polluting the commit history.\n\n```bash\n#  CORRECT - signed commit with trailer via --trailer parameter\ngit commit -S \\\n  -m \"feat: add feature\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n**Why this is correct:** Trailers are separate from the message body and only visible in `git log --format=full` or `git log --format=\"%(trailers)\"`. The commit message stays completely clean. The `-S` flag signs the commit with GPG.\n\n## Anti-Rationalization Table\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I'll commit everything at once\" | Mixed changes = messy history, hard to bisect/revert. | **Analyze and group changes first** |\n| \"Grouping takes too long\" | Clean history saves hours of debugging later. | **Always propose commit plan** |\n| \"I'll skip GPG signing\" | Unsigned commits can't be verified. | **Use `-S` flag (skip only if no GPG key)** |\n| \"I'll put the trailer text in the message body\" | `--trailer` is a GIT FLAG, not text. Text in `-m` is NOT a trailer. | **Use `--trailer \"X-Lerian-Ref: 0x1\"` as separate argument** |\n| \"The trailers need to be in the commit message\" | NO. Trailers go via `--trailer` flag OUTSIDE the `-m` quotes. | **Structure: `git commit -S -m \"msg\" --trailer \"X-Lerian-Ref: 0x1\"` ** |\n| \"I'll format it nicely in the message body\" | That's NOT a trailer - that's polluting the message body. | **NEVER put \"X-Lerian-Ref\" text inside `-m` quotes** |\n| \"HEREDOC will format the trailers correctly\" | HEREDOC puts everything in the message body. That's WRONG. | **Use `--trailer` flag, NOT HEREDOC** |\n| \"The example shows trailer text in the message\" | Look again. `--trailer` is OUTSIDE the `-m \"...\"` quotes. | **Copy the structure exactly: `-S -m \"msg\" --trailer \"X-Lerian-Ref: 0x1\"` ** |\n| \"I'll add a hashtag #0x1 for tracking\" | Hashtags pollute the message body. Use --trailer instead. | **NEVER use hashtags. Use `--trailer \"X-Lerian-Ref: 0x1\"`** |\n\n## When User Provides Message\n\nIf the user provides a commit message as argument:\n1. **Single commit mode** - Skip grouping analysis, use provided message\n2. Use their message as the subject/body\n3. Ensure proper formatting (50 char subject, etc.)\n4. Create signed commit with trailer\n\n```bash\n# User says: /commit \"fix login bug\"\ngit commit -S \\\n  -m \"fix: fix login bug\" \\\n  --trailer \"X-Lerian-Ref: 0x1\"\n```\n\n## Step 8: Offer Push (Optional)\n\nAfter successful commit, ask the user if they want to push:\n\n```javascript\nAskUserQuestion({\n  questions: [{\n    question: \"Push commit to remote?\",\n    header: \"Push\",\n    multiSelect: false,\n    options: [\n      { label: \"Yes\", description: \"Push to current branch\" },\n      { label: \"No\", description: \"Keep local only\" }\n    ]\n  }]\n});\n```\n\nIf user selects \"Yes\":\n```bash\ngit push\n```\n\nIf branch has no upstream, use:\n```bash\ngit push -u origin <current-branch>\n```"
              },
              {
                "name": "/compound-learnings",
                "description": "Analyze session learnings and propose new rules/skills",
                "path": "default/commands/compound-learnings.md",
                "frontmatter": {
                  "name": "ring:compound-learnings",
                  "description": "Analyze session learnings and propose new rules/skills",
                  "argument-hint": "[--approve <id>] [--reject <id>] [--list]"
                },
                "content": "Analyze accumulated session learnings to detect recurring patterns and propose new rules, skills, or hooks. Requires user approval before creating any permanent artifacts.\n\n## Usage\n\n```\n/compound-learnings [options]\n```\n\n## Options\n\n| Option | Description |\n|--------|-------------|\n| (none) | Analyze learnings and generate new proposals |\n| `--list` | List pending proposals without analyzing |\n| `--approve <id>` | Approve a specific proposal (e.g., `--approve proposal-1`) |\n| `--reject <id>` | Reject a specific proposal with optional reason |\n| `--history` | Show history of approved/rejected proposals |\n\n## Examples\n\n### Analyze Learnings (Default)\n```\n/compound-learnings\n```\nAnalyzes all session learnings, detects patterns appearing 3+ times, and presents proposals.\n\n### List Pending Proposals\n```\n/compound-learnings --list\n```\nShows proposals waiting for approval without re-analyzing.\n\n### Approve a Proposal\n```\n/compound-learnings --approve proposal-1\n```\nCreates the rule/skill from the approved proposal.\n\n### Reject a Proposal\n```\n/compound-learnings --reject proposal-2 \"Too project-specific\"\n```\nMarks proposal as rejected with reason.\n\n### View History\n```\n/compound-learnings --history\n```\nShows all past approvals and rejections.\n\n## Process\n\nThe command follows this workflow:\n\n### 1. Gather (Automatic)\n- Reads `.ring/cache/learnings/*.md` files\n- Counts total sessions available\n\n### 2. Analyze (Automatic)\n- Extracts patterns from What Worked, What Failed, Key Decisions\n- Consolidates similar patterns using fuzzy matching\n- Detects patterns appearing in 3+ sessions\n\n### 3. Categorize (Automatic)\n- Classifies patterns as rule, skill, or hook candidates\n- Generates preview content for each\n\n### 4. Propose (Interactive)\n- Presents each qualifying pattern\n- Shows draft content\n- Waits for your decision\n\n### 5. Create (On Approval)\n- Creates rule/skill/hook in appropriate location\n- Updates proposal history\n- Archives processed learnings\n\n## Output Example\n\n```markdown\n## Compound Learnings Analysis\n\n**Sessions Analyzed:** 12\n**Patterns Detected:** 8\n**Qualifying (3+ sessions):** 3\n\n---\n\n### Proposal 1: Always use explicit file paths\n\n**Signal:** 5 sessions (abc, def, ghi, jkl, mno)\n**Category:** Rule\n**Sources:** patterns, what_worked\n\n**Preview:**\n# Always use explicit file paths\n## Pattern\nNever use relative paths like \"./file\" - always use absolute paths.\n...\n\n**Action Required:** Type `approve`, `reject`, or `modify`\n\n---\n```\n\n## Related Commands/Skills\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `compound-learnings` skill | Underlying skill with full process details |\n| `handoff-tracking` | Provides source data (what_worked, what_failed) |\n| `artifact-query` | Search past handoffs for context |\n\n## Troubleshooting\n\n### \"No learnings found\"\nNo `.ring/cache/learnings/*.md` files exist. Complete some sessions with outcome tracking enabled.\n\n### \"Insufficient data for patterns\"\nFewer than 3 learning files. Continue working - patterns emerge after multiple sessions.\n\n### \"Pattern already exists\"\nCheck `.ring/generated/rules/` and `.ring/generated/skills/` in your project, or `default/rules/` and `default/skills/` in the plugin - a similar rule or skill may already exist.\n\n### \"Proposal not found\"\nThe proposal ID doesn't exist in pending.json. Run `/compound-learnings --list` to see current proposals."
              },
              {
                "name": "/create-handoff",
                "description": "Create a handoff document capturing current session state for future resumption",
                "path": "default/commands/create-handoff.md",
                "frontmatter": {
                  "name": "ring:create-handoff",
                  "description": "Create a handoff document capturing current session state for future resumption",
                  "argument-hint": "[session-name] [description]"
                },
                "content": "Create a detailed handoff document that preserves the current session's context, learnings, and next steps for future sessions.\n\n## Usage\n\n```\n/create-handoff [session-name] [description]\n```\n\n**Arguments:**\n- `session-name` (optional): Work stream name (e.g., `auth-feature`, `context-management`)\n- `description` (optional): Brief description of the handoff\n\nIf arguments not provided, infer from:\n1. Recent plan files in `docs/plans/`\n2. Current git branch name\n3. Ask user if unclear\n\n## Process\n\n### Step 1: Determine Handoff Location\n\n```bash\n# Get session context\nSESSION_NAME=\"${1:-$(git branch --show-current | sed 's/^feature\\///')}\"\nTIMESTAMP=$(date +\"%Y-%m-%d_%H-%M-%S\")\nDESC=\"${2:-session-handoff}\"\n\n# Create directory\nmkdir -p \"docs/handoffs/${SESSION_NAME}\"\n\n# File path\necho \"docs/handoffs/${SESSION_NAME}/${TIMESTAMP}_${DESC}.md\"\n```\n\n### Step 2: Gather Metadata\n\nRun these commands to gather required metadata:\n\n```bash\n# Git state\ngit rev-parse HEAD\ngit branch --show-current\ngit remote get-url origin 2>/dev/null || echo \"local\"\n\n# Timestamp\ndate -u +\"%Y-%m-%dT%H:%M:%SZ\"\n```\n\n### Step 3: Write Handoff Document\n\nUse the handoff-tracking skill template. Fill in:\n\n1. **Task Summary**: What were you working on? What's the status?\n2. **Critical References**: What files MUST be read to continue?\n3. **Recent Changes**: What files did you modify (with line numbers)?\n4. **Learnings**: What worked? What failed? What decisions were made?\n5. **Action Items**: What's next?\n\n### Step 4: Confirm Creation\n\nAfter writing the handoff, respond:\n\n```\nHandoff created: docs/handoffs/{session-name}/{timestamp}_{desc}.md\n\nThe handoff has been automatically indexed and will be searchable.\n\nResume in a new session with:\n/resume-handoff docs/handoffs/{session-name}/{timestamp}_{desc}.md\n```\n\n## Example\n\n```\nUser: /create-handoff context-management artifact-index-complete\nAssistant: Creating handoff for context-management session...\n\n[Gathers metadata, writes handoff document]\n\nHandoff created: docs/handoffs/context-management/2025-12-27_15-45-00_artifact-index-complete.md\n\nResume in a new session with:\n/resume-handoff docs/handoffs/context-management/2025-12-27_15-45-00_artifact-index-complete.md\n```\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:handoff-tracking\n```\n\nThe skill contains the complete workflow with:\n- Handoff document template\n- Metadata gathering process\n- Automatic indexing integration\n- Outcome tracking\n- Session trace correlation"
              },
              {
                "name": "/execute-plan",
                "description": "Execute plan in batches with review checkpoints",
                "path": "default/commands/execute-plan.md",
                "frontmatter": {
                  "name": "ring:execute-plan",
                  "description": "Execute plan in batches with review checkpoints",
                  "argument-hint": "[plan-file-path]"
                },
                "content": "Execute an existing implementation plan with controlled checkpoints and code review between batches. Supports autonomous one-go execution or batch mode with human review at each checkpoint.\n\n## Usage\n\n```\n/execute-plan [plan-file-path]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `plan-file-path` | Yes | Path to the plan file (e.g., `docs/plans/2024-01-15-auth-feature.md`) |\n\n## Examples\n\n### Execute a Feature Plan\n```\n/execute-plan docs/plans/2024-01-15-oauth-integration.md\n```\nLoads and executes the OAuth integration plan with review checkpoints.\n\n### Execute from Absolute Path\n```\n/execute-plan /Users/dev/project/docs/plans/2024-01-15-api-refactor.md\n```\nExecutes a plan using its full path.\n\n### Execute Latest Plan\n```\n/execute-plan docs/plans/2024-01-20-notification-system.md\n```\nExecutes the most recent plan for the notification system feature.\n\n## Process\n\n### Step 1: Load and Review Plan\n- Reads the plan file\n- Critically reviews for any questions or concerns\n- Raises issues with you before starting\n- Creates TodoWrite to track progress\n\n### Step 2: Choose Execution Mode (MANDATORY)\nYou will be asked to choose between:\n\n| Mode | Behavior |\n|------|----------|\n| **One-go (autonomous)** | Executes all batches continuously with code review between each; no human review until completion |\n| **Batch (with review)** | Executes one batch, pauses for human feedback after code review, then continues |\n\n### Step 3: Execute Batch\n- Default batch size: first 3 tasks\n- Each task is marked in_progress, executed, then completed\n- Dispatches to specialized agents when available:\n  - Backend Go: `backend-engineer-golang`\n  - Backend TypeScript: `backend-engineer-typescript`\n  - Frontend React/Next.js/BFF: `frontend-bff-engineer-typescript`\n  - Infrastructure: `devops-engineer`\n  - Testing: `qa-analyst`\n  - Reliability: `sre`\n\n### Step 4: Run Code Review\nAfter each batch, all 3 reviewers run in parallel:\n- `code-reviewer` - Architecture and patterns\n- `business-logic-reviewer` - Requirements and edge cases\n- `security-reviewer` - OWASP and auth validation\n\n**Issue handling by severity:**\n| Severity | Action |\n|----------|--------|\n| Critical/High/Medium | Fix immediately, re-run all reviewers |\n| Low | Add `TODO(review):` comment in code |\n| Cosmetic/Nitpick | Add `FIXME(nitpick):` comment in code |\n\n### Step 5: Report and Continue\n**One-go mode:** Continues to next batch automatically, reports only at final completion.\n\n**Batch mode:** Shows implementation summary, verification output, and code review results. Waits for your feedback before proceeding.\n\n### Step 6: Complete Development\nAfter all tasks complete:\n- Uses `finishing-a-development-branch` skill\n- Verifies tests pass\n- Presents options for branch completion\n\n## Related Commands/Skills\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `/write-plan` | Use first to create the plan file |\n| `/brainstorm` | Use before writing-plans if design unclear |\n| `writing-plans` | Creates the plan files this command executes |\n| `requesting-code-review` | Called automatically after each batch |\n| `finishing-a-development-branch` | Called at completion |\n\n## Troubleshooting\n\n### \"No plan file found\"\nEnsure the path is correct. Plans are typically stored in `docs/plans/`. Use `ls docs/plans/` to list available plans.\n\n### \"Plan has critical gaps\"\nThe plan was reviewed and found to have issues preventing execution. You'll be asked to clarify or revise the plan before proceeding.\n\n### \"Verification failed repeatedly\"\nExecution stops when a verification step fails multiple times. Review the output to determine if the plan needs revision or if there's an environmental issue.\n\n### \"Code review finds Critical issues\"\nAll Critical, High, and Medium issues must be fixed before proceeding. The reviewers will re-run after fixes until the batch passes.\n\n### Execution mode was not asked\nIf you're not prompted for execution mode, this is a violation of the skill protocol. The mode selection is mandatory regardless of any \"just execute\" or \"don't wait\" instructions.\n\n### When NOT to use this command\n- No plan exists - use `/write-plan` first\n- Plan needs revision - use `/brainstorm` to refine the design\n- Working on independent tasks in current session - use `subagent-driven-development` skill directly\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:executing-plans\n```\n\nThe skill contains the complete workflow with:\n- Batch execution with review checkpoints\n- Task state management\n- Failure recovery procedures\n- Progress tracking\n- Code review integration"
              },
              {
                "name": "/explore-codebase",
                "description": "Autonomous two-phase codebase exploration with adaptive agents",
                "path": "default/commands/explore-codebase.md",
                "frontmatter": {
                  "name": "ring:explore-codebase",
                  "description": "Autonomous two-phase codebase exploration with adaptive agents",
                  "argument-hint": "[target]"
                },
                "content": "Autonomously discover codebase structure, then explore deeply with adaptive agents. The system first learns the architecture, then dispatches targeted explorers based on what it found.\n\n## Usage\n\n```\n/explore-codebase [target]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `target` | Yes | Feature, component, or system to explore (e.g., \"account creation\", \"transaction processing\", \"authentication system\") |\n\n## What This Command Does\n\n**Two-Phase Autonomous Exploration:**\n\n### Phase 1: Discovery (Meta-Exploration)\n1. **Discovers structure** - Launches 3-4 agents to understand the codebase\n2. **Identifies perspectives** - Finds architecture, components, layers, organization\n3. **Creates structural map** - Documents what was discovered with evidence\n\n### Phase 2: Deep Dive (Adaptive Exploration)\n4. **Adapts to structure** - Generates N explorers based on Phase 1 discoveries\n5. **Explores target** - Each agent investigates target in their assigned area\n6. **Synthesizes findings** - Integrates discovery + deep dives into unified understanding\n7. **Provides guidance** - Recommends next steps based on your goal\n\n## The Autonomous Flow\n\n```\nTarget: \"account creation\"\n           \n           \n    \n      Phase 1:      Launch 4 discovery agents in parallel:\n      Discovery      Architecture pattern?\n                     Components/modules?\n                     Layers/boundaries?\n       Organization principle?\n           \n             Discovered: 3 components, hexagonal architecture, 4 layers each\n           \n           \n    \n      Phase 2:      Launch 3 deep-dive agents (adapted to discoveries):\n      Deep Dive      Onboarding component\n                     Transaction component\n                     CRM component\n      Each explores \"account creation\" in their area\n           \n           \n    \n      Synthesis      Integrate discoveries + deep dives\n                     Cross-cutting insights\n                     Implementation guidance\n    \n```\n\n## Process Details\n\nThis command invokes the `exploring-codebase` skill which handles:\n\n### Phase 1: Discovery Pass (3-4 parallel agents)\n\n**Architecture Discovery Agent:**\n- Identifies architecture pattern (hexagonal, layered, microservices, etc.)\n- Documents evidence (directory structure, naming, separation)\n- Provides confidence level\n\n**Component Discovery Agent:**\n- Enumerates major components/modules/services\n- Maps dependencies between components\n- Identifies shared libraries\n\n**Layer Discovery Agent:**\n- Discovers layers within components\n- Documents layer communication patterns\n- Identifies violations or cross-cutting concerns\n\n**Organization Discovery Agent:**\n- Understands organizing principle (by layer, by feature, by domain)\n- Documents file naming conventions\n- Maps test and config organization\n\n### Phase 2: Adaptive Deep Dive (N agents based on discoveries)\n\nThe number and focus of agents adapts to Phase 1 findings:\n\n| What Phase 1 Found | Phase 2 Strategy |\n|--------------------|------------------|\n| 3 components  4 layers | Launch 3 agents (one per component) |\n| Single component, clear layers | Launch 4 agents (one per layer) |\n| 5 microservices | Launch 5 agents (one per service) |\n| 6 features (feature-organized) | Launch 6 agents (one per feature) |\n\n**Each deep dive agent receives:**\n- Context from Phase 1 discoveries\n- Focused scope (specific component/layer/service)\n- Target to explore within that scope\n- Boundaries to respect\n\n**Each deep dive agent produces:**\n- How target is implemented in their area\n- Execution flow with file:line references\n- Patterns observed\n- Integration points with other areas\n\n### Phase 3: Synthesis\n\n- Integrates Phase 1 structural map with Phase 2 deep dives\n- Identifies cross-cutting insights\n- Documents consistent patterns\n- Highlights variations between areas\n- Provides actionable implementation guidance\n\n## Examples\n\n### Example 1: Exploring Account Creation\n\n```bash\n/explore-codebase account creation\n```\n\n**Phase 1 might discover:**\n- Hexagonal architecture\n- 3 components (onboarding, transaction, crm)\n- 4 layers per component (HTTP, UseCase, Repository, Domain)\n\n**Phase 2 adapts with 3 agents:**\n- Agent 1: Explore account creation in onboarding component\n- Agent 2: Check for account references in transaction component\n- Agent 3: Check for account references in CRM component\n\n**Result:** Comprehensive understanding of how account creation works across all components\n\n### Example 2: Exploring Transaction Processing\n\n```bash\n/explore-codebase transaction processing\n```\n\n**Phase 1 might discover:**\n- Microservices architecture\n- 5 services (auth, user, order, payment, notification)\n- Event-driven communication\n\n**Phase 2 adapts with 5 agents:**\n- One agent per service exploring transaction handling\n- Focus on event publishing/subscribing\n- Document inter-service data flow\n\n**Result:** End-to-end understanding of transactions across services\n\n### Example 3: Exploring Authentication\n\n```bash\n/explore-codebase authentication system\n```\n\n**Phase 1 might discover:**\n- Monolithic layered architecture\n- MVC pattern with 3 layers\n\n**Phase 2 adapts with 3 agents:**\n- Agent 1: Auth in Controller layer\n- Agent 2: Auth in Service layer\n- Agent 3: Auth in Data Access layer\n\n**Result:** Vertical slice of authentication through all layers\n\n## Output\n\nThe command produces a **comprehensive synthesis document** with:\n\n### Executive Summary\n2-3 sentences about architecture + how target works\n\n### Phase 1: Discovery Findings\n- Architecture pattern (with evidence)\n- Component structure (with responsibilities)\n- Layer organization (with boundaries)\n- Technology stack\n- Structural diagram\n\n### Phase 2: Deep Dive Findings\nFor each discovered area:\n- Scope explored\n- Target implementation (with file:line)\n- Execution flow\n- Patterns observed\n- Integration points\n\n### Cross-Cutting Insights\n- Pattern consistency across areas\n- Pattern variations and why\n- Integration points between areas\n- Data flow across boundaries\n- Key design decisions\n\n### Implementation Guidance\nContext-aware recommendations for:\n- **Adding functionality:** Where to put code, patterns to follow\n- **Modifying functionality:** Files to change, ripple effects\n- **Debugging:** Where to start, what to inspect\n\n### Next Steps\nRecommendations based on your goal (implementation, debugging, or learning)\n\n## When to Use\n\n**Use this command when:**\n- You need end-to-end understanding of a feature\n- Starting work on unfamiliar codebase\n- Planning changes spanning multiple components\n- Need architecture context before implementation\n- Exploring complex system interactions\n\n**Don't use when:**\n- Looking for specific file/function (use grep/find)\n- Already familiar with the structure\n- Simple single-file change needed\n- Just viewing an error location (use read)\n\n## Key Advantages of Two-Phase Approach\n\n### 1. Adaptive to Any Architecture\n- Discovers structure rather than assuming it\n- Works with hexagonal, microservices, MVC, monoliths, etc.\n- Handles mixed patterns (e.g., hexagonal within each microservice)\n\n### 2. Efficient Parallelization\n- Phase 1: 3-4 discovery agents run in parallel\n- Phase 2: N deep-dive agents run in parallel (N adapts)\n- Faster than sequential exploration\n\n### 3. Thorough Understanding\n- Structural context (Phase 1) + Implementation details (Phase 2)\n- No blind spots from single-lens exploration\n- Cross-cutting insights from synthesis\n\n### 4. Actionable Guidance\n- Not just \"what exists\" but \"where to make changes\"\n- Pattern recommendations based on actual codebase\n- Integration points clearly documented\n\n## Related Commands/Skills\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `/brainstorm` | Use explore-codebase in Phase 1 for context |\n| `/write-plan` | Use explore-codebase before planning implementation |\n| `/execute-plan` | Use if plan execution reveals gaps in understanding |\n| `exploring-codebase` | Underlying skill with full logic and prompts |\n| `dispatching-parallel-agents` | Pattern used twice (discovery + deep dive) |\n| `systematic-debugging` | Use explore-codebase before debugging |\n\n## Troubleshooting\n\n### \"Discovery phase found unclear structure\"\n**Cause:** Codebase may have inconsistent or legacy patterns\n**Solution:** Review discovery agent outputs, may need manual interpretation\n\n### \"Deep dive agents didn't find the target\"\n**Cause:** Target may not exist in that area (valid finding) OR target named differently\n**Solution:** Check if agents noted \"not found in this area\" - may be expected\n\n### \"Contradictions between agents\"\n**Cause:** Different parts of codebase use different patterns (common in legacy code)\n**Solution:** Synthesis phase should document variations - may indicate refactoring opportunities\n\n### \"Too many deep dive agents (long exploration)\"\n**Cause:** Phase 1 discovered many components/layers\n**Solution:** Refine target to be more specific, or use a subset scope\n\n### \"Not enough detail in results\"\n**Cause:** Target may be too broad or vague\n**Solution:** Be more specific: \"account creation API endpoint\" vs \"accounts\"\n\n## Advanced Usage\n\n### Narrow Scope\nFocus discovery on specific area:\n```bash\n/explore-codebase transaction processing in payment service only\n```\n\n### Deep Exploration\nRequest comprehensive analysis:\n```bash\n/explore-codebase authentication (include all integrations and edge cases)\n```\n\n### Comparative Analysis\nRun twice to understand changes:\n```bash\n# Before refactoring\n/explore-codebase user management\n\n# After refactoring\n/explore-codebase user management\n# Compare the two synthesis documents\n```\n\n## Performance & Cost\n\n- **Discovery Phase:** 3-4 agents  ~2-3 min each = ~3-5 minutes total (parallel)\n- **Deep Dive Phase:** N agents  ~3-5 min each = ~3-5 minutes total (parallel)\n- **Total Time:** ~6-10 minutes for comprehensive exploration\n- **Model Used:** Haiku (cost-effective for exploration)\n- **Cost:** Minimal - optimized for efficiency\n\n## What Makes This Different\n\n### vs. Traditional Exploration:\n- Traditional: Assume structure  explore sequentially\n- This command: **Discover structure  adapt exploration**\n\n### vs. Fixed-Perspective Exploration:\n- Fixed: Always use same 4 perspectives (feature flow, patterns, components, data)\n- This command: **Perspectives adapt to what Phase 1 discovers**\n\n### vs. Manual Navigation:\n- Manual: Guess where to look, follow imports, repeat\n- This command: **Systematic discovery + targeted deep dives + synthesis**\n\n## Example Discoveries\n\n### Microservices Codebase\n**Phase 1:** \"Found 8 microservices with event-driven architecture\"\n**Phase 2:** 8 deep-dive agents, one per service\n**Synthesis:** Event flow diagram + service responsibilities + integration points\n\n### Hexagonal Monolith\n**Phase 1:** \"Found single app with hexagonal architecture, 4 layers\"\n**Phase 2:** 4 deep-dive agents, one per layer\n**Synthesis:** Dependency inversion patterns + layer boundaries + adapter implementations\n\n### Feature-Organized Codebase\n**Phase 1:** \"Found 12 features, each self-contained with own layers\"\n**Phase 2:** 12 deep-dive agents, one per feature\n**Synthesis:** Shared code patterns + feature independence + cross-feature integration\n\n## Next Steps After Exploration\n\nThe command suggests appropriate follow-up:\n\n**If you're implementing something:**\n```\nReady to create implementation plan? Use /write-plan\n```\n\n**If you're setting up workspace:**\n```\nReady for isolated workspace? Use /worktree\n```\n\n**If you're debugging:**\n```\nReady to investigate? Use systematic-debugging skill\n```\n\n**If you're designing:**\n```\nReady to refine design? Use /brainstorm\n```\n\n## Real-World Workflow\n\n```bash\n# 1. Understand the codebase\n/explore-codebase payment processing\n\n# 2. Review synthesis document (architecture + implementation)\n\n# 3. Based on findings, plan your changes\n/write-plan add-refund-support\n\n# 4. Set up isolated workspace\n/worktree feature/add-refund-support\n\n# 5. Execute the plan\n/execute-plan <plan-file>\n```\n\n## Key Takeaways\n\n **Autonomous** - Discovers structure, doesn't assume it\n **Adaptive** - Deep dive agents match discovered architecture\n **Efficient** - Parallel exploration in both phases\n **Thorough** - Structural context + implementation details\n **Actionable** - Synthesis provides implementation guidance\n **Universal** - Works with any codebase architecture\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:exploring-codebase\n```\n\nThe skill contains the complete workflow with:\n- Two-phase autonomous exploration (Discovery + Deep Dive)\n- Red flag detection table\n- Violation consequences documentation\n- Discovery agent prompt templates\n- Deep dive adaptive prompts\n- Synthesis document format"
              },
              {
                "name": "/interview-me",
                "description": "Proactive requirements gathering through structured user interview",
                "path": "default/commands/interview-me.md",
                "frontmatter": {
                  "name": "ring:interview-me",
                  "description": "Proactive requirements gathering through structured user interview",
                  "argument-hint": "[topic]"
                },
                "content": "Surface ambiguities and gather requirements BEFORE implementation begins. This command inverts the typical flow: instead of you anticipating what Claude might misunderstand, Claude proactively interviews you to build a complete picture.\n\n## Usage\n\n```\n/interview-me [topic]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `topic` | No | The feature, task, or area to gather requirements for. If omitted, Claude analyzes current context. |\n\n## Examples\n\n### Before Starting a Feature\n```\n/interview-me user notifications\n```\nClaude interviews you about notification types, delivery channels, preferences, etc.\n\n### When Claude Seems Confused\n```\n/interview-me\n```\nClaude analyzes the current conversation and surfaces its uncertainties.\n\n### Before Architecture Decisions\n```\n/interview-me database migration strategy\n```\nClaude gathers constraints, timelines, compatibility requirements, etc.\n\n## What Happens\n\n1. **Context Analysis** - Claude analyzes the task/topic and identifies ambiguities\n2. **Question Clustering** - Questions are grouped by priority (blocking  architecture  behavior  preference)\n3. **Structured Interview** - Claude asks questions using structured choices (2-4 options each)\n4. **Understanding Summary** - Claude presents a \"Validated Understanding\" document\n5. **Confirmation** - You confirm or correct, then Claude proceeds with implementation\n\n## Question Budget\n\n- **Maximum 4 questions per round** (AskUserQuestion tool limit)\n- **Maximum 3 rounds** (respects your time)\n- **Fewer is better** - Claude should explore before asking\n\n## Output: Validated Understanding\n\nAfter the interview, Claude presents:\n\n```markdown\n## Validated Understanding\n\n### What We're Building\n[1-2 sentence summary]\n\n### Key Decisions Made\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n\n### Constraints Confirmed\n- [List of constraints]\n\n### Out of Scope (Explicit)\n- [Things we're NOT doing]\n```\n\nYou must explicitly confirm this before Claude proceeds.\n\n## When to Use This Command\n\n| Scenario | Use /interview-me? |\n|----------|-------------------|\n| Starting a new feature with vague requirements |  Yes |\n| Claude made wrong assumptions previously |  Yes |\n| Multiple valid approaches, unclear which to pick |  Yes |\n| Architecture decisions without clear direction |  Yes |\n| Simple bug fix with clear reproduction |  No |\n| Following an existing detailed plan |  No |\n| Single clarifying question needed |  No (just ask) |\n\n## Related Commands/Skills\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `doubt-triggered-questions` pattern | For single questions during work |\n| `/brainstorm` | Use AFTER interview to explore solutions |\n| `/write-plan` | Use AFTER interview to create implementation plan |\n\n## Troubleshooting\n\n### \"Too many questions\"\nClaude should explore the codebase before asking. If you're being bombarded with questions, tell Claude to \"explore first, then ask only what you can't figure out.\"\n\n### \"Questions are too vague\"\nGood questions have 2-4 concrete options with descriptions. If you're getting open-ended questions, ask Claude to \"provide specific options.\"\n\n### \"Claude keeps asking about things I already said\"\nRemind Claude to re-read the conversation. The interview should build on what's already known, not repeat it.\n\n### \"I want Claude to just decide\"\nSay \"use your judgment\" or \"pick whatever fits best.\" Claude will make a choice and document the assumption.\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:interviewing-user\n```\n\nThe skill contains the complete workflow with:\n- Context analysis methodology\n- Question clustering by priority\n- Structured interview patterns\n- Validated Understanding template\n- Auto-trigger conditions"
              },
              {
                "name": "/lint",
                "description": "Run lint checks and dispatch parallel agents to fix all issues",
                "path": "default/commands/lint.md",
                "frontmatter": {
                  "name": "ring:lint",
                  "description": "Run lint checks and dispatch parallel agents to fix all issues",
                  "argument-hint": "[path]"
                },
                "content": "Run linting tools, analyze results, and dispatch parallel AI agents to fix all issues until the codebase is clean.\n\n## Usage\n\n```\n/lint [path]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `path` | No | Specific path to lint (defaults to entire codebase) |\n\n## What This Command Does\n\n1. **Runs lint checks** - Executes `make lint` or appropriate linting tools\n2. **Analyzes results** - Groups issues into independent fix streams\n3. **Dispatches agents** - Launches parallel agents (one per stream)\n4. **Iterates until clean** - Continues until all lint issues are resolved\n\n## Process\n\nThis command invokes the `linting-codebase` skill which handles:\n\n### Phase 1: Lint Execution\n- Runs `make lint` (or detects appropriate lint command)\n- Captures all output and exit codes\n- Parses errors, warnings, and their locations\n\n### Phase 2: Stream Analysis\n- Groups issues by file or logical component\n- Identifies independent streams that can be fixed in parallel\n- Creates fix assignments for each stream\n\n### Phase 3: Parallel Agent Dispatch\n- Launches N agents simultaneously (one per stream)\n- Each agent fixes issues in their assigned scope\n- Agents work independently without conflicts\n\n### Phase 4: Verification Loop\n- Re-runs lint after all agents complete\n- If issues remain, analyzes and dispatches new agents\n- Continues until lint passes completely\n\n## Important Constraints\n\n **NO AUTOMATED SCRIPTS** - Agents fix code directly, never create automation scripts\n **NO DOCUMENTATION** - Agents fix lint issues only, don't add docs/comments\n **DIRECT FIXES ONLY** - Each issue is fixed manually by editing the source\n\n## Examples\n\n### Lint Entire Codebase\n```\n/lint\n```\nRuns full lint, dispatches agents to fix everything.\n\n### Lint Specific Path\n```\n/lint src/services/\n```\nLints only the services directory.\n\n## Related\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `linting-codebase` | Underlying skill with full logic |\n| `dispatching-parallel-agents` | Pattern used for parallel fixes |\n| `/codereview` | Use after lint passes for deeper review |\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:linting-codebase\n```\n\nThe skill contains the complete workflow with:\n- Parallel lint fixing pattern\n- Stream analysis for independent fix groups\n- Agent dispatch rules\n- Verification loop with max iterations\n- Critical constraints (no scripts, direct fixes only)"
              },
              {
                "name": "/query-artifacts",
                "description": "Search the Artifact Index for relevant historical context",
                "path": "default/commands/query-artifacts.md",
                "frontmatter": {
                  "name": "ring:query-artifacts",
                  "description": "Search the Artifact Index for relevant historical context",
                  "argument-hint": "<search-terms> [--type TYPE] [--outcome OUTCOME]"
                },
                "content": "Search the Artifact Index for relevant handoffs, plans, and continuity ledgers using FTS5 full-text search with BM25 ranking.\n\n## Usage\n\n```\n/query-artifacts <search-terms> [options]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `search-terms` | Yes | Keywords to search for (e.g., \"authentication OAuth\", \"error handling\") |\n| `--mode` | No | Query mode: `search` (default) or `planning` (structured precedent) |\n| `--type` | No | Filter by type: `handoffs`, `plans`, `continuity`, `all` (default: all) |\n| `--outcome` | No | Filter handoffs: `SUCCEEDED`, `PARTIAL_PLUS`, `PARTIAL_MINUS`, `FAILED` |\n| `--limit` | No | Maximum results per category (1-100, default: 5) |\n\n## Examples\n\n### Search for Authentication Work\n\n```\n/query-artifacts authentication OAuth JWT\n```\n\nReturns handoffs, plans, and continuity ledgers related to authentication.\n\n### Find Successful Implementations\n\n```\n/query-artifacts API design --outcome SUCCEEDED\n```\n\nReturns only handoffs that were marked as successful.\n\n### Search Plans Only\n\n```\n/query-artifacts context management --type plans\n```\n\nReturns only matching plan documents.\n\n### Limit Results\n\n```\n/query-artifacts testing --limit 3\n```\n\nReturns at most 3 results per category.\n\n### Planning Mode (Structured Precedent)\n\n```\n/query-artifacts api rate limiting --mode planning\n```\n\nReturns structured precedent for creating implementation plans:\n- **Successful Implementations** - What worked (reference these)\n- **Failed Implementations** - What failed (AVOID these patterns)\n- **Relevant Past Plans** - Similar approaches\n\nThis mode is used automatically by `/write-plan` to inform new plans with historical context.\n\n## Output\n\nResults are displayed in markdown format:\n\n```markdown\n## Relevant Handoffs\n### [OK] session-name/task-01\n**Summary:** Implemented OAuth2 authentication...\n**What worked:** Token refresh mechanism...\n**What failed:** Initial PKCE implementation...\n**File:** `/path/to/handoff.md`\n\n## Relevant Plans\n### OAuth2 Integration Plan\n**Overview:** Implement OAuth2 with PKCE flow...\n**File:** `/path/to/plan.md`\n\n## Related Sessions\n### Session: auth-implementation\n**Goal:** Add authentication to the API...\n**Key learnings:** Use refresh tokens...\n**File:** `/path/to/ledger.md`\n```\n\n## Index Management\n\n### Check Index Statistics\n\n```\n/query-artifacts --stats\n```\n\nShows counts of indexed artifacts.\n\n### Initialize/Rebuild Index\n\nIf the index is empty or out of date:\n\n```bash\npython3 default/lib/artifact-index/artifact_index.py --all\n```\n\n## Related Commands/Skills\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `/write-plan` | Query before planning to inform decisions |\n| `/create-handoff` | Creates handoffs that get indexed |\n| `artifact-query` | The underlying skill |\n| `writing-plans` | Uses query results for RAG-enhanced planning |\n\n## Troubleshooting\n\n### \"Database not found\"\n\nThe artifact index hasn't been initialized. Run:\n\n```bash\npython3 default/lib/artifact-index/artifact_index.py --all\n```\n\n### \"No results found\"\n\n1. Check that artifacts exist: `ls docs/handoffs/ docs/plans/`\n2. Re-index: `python3 default/lib/artifact-index/artifact_index.py --all`\n3. Try broader search terms\n\n### Slow queries\n\nQueries should complete in < 100ms. If slow:\n\n1. Check database size: `ls -la .ring/cache/artifact-index/`\n2. Rebuild indexes: `python3 default/lib/artifact-index/artifact_index.py --all`\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:artifact-query\n```\n\nThe skill contains the complete workflow with:\n- Query formulation guidance\n- Mode selection (search, planning)\n- Result interpretation\n- Learnings application\n- Index initialization"
              },
              {
                "name": "/release-guide",
                "description": "Generate an Ops Update Guide from git diff between two refs",
                "path": "default/commands/release-guide.md",
                "frontmatter": {
                  "name": "ring:release-guide",
                  "description": "Generate an Ops Update Guide from git diff between two refs"
                },
                "content": "Generate an internal Operations-facing update/migration guide based on git diff analysis.\n\n## Usage\n\n```\n/release-guide\n```\n\nThis command invokes the `release-guide-info` skill, which will interactively collect all required information:\n- Base ref (starting point)\n- Target ref (ending point)\n- Version (optional, auto-detected from tags)\n- Language (en, pt-br, or both)\n- Execution mode\n\n## Output\n\nThe skill generates:\n1. **Preview summary** - Shows configuration and change counts\n2. **User confirmation** - Waits for approval before writing\n3. **Release guide file(s)** - Written to `notes/releases/`\n\n## Related\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `release-guide-info` skill | Full workflow with all options |\n| `/commit` | Use after release guide to commit changes |\n| `finishing-a-development-branch` | Complementary workflow for branch completion |\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:release-guide-info\n```\n\nThe skill contains the complete workflow with:\n- Tag auto-detection and version resolution\n- Commit log analysis for context\n- Dual language support (English/Portuguese)\n- Preview step before saving\n- Anti-rationalization table\n- Quality checklist"
              },
              {
                "name": "/resume-handoff",
                "description": "Resume work from a handoff document with context analysis and validation",
                "path": "default/commands/resume-handoff.md",
                "frontmatter": {
                  "name": "ring:resume-handoff",
                  "description": "Resume work from a handoff document with context analysis and validation",
                  "argument-hint": "<path-to-handoff.md>"
                },
                "content": "Resume work from a handoff document through an interactive process. Handoffs contain critical context, learnings, and next steps from previous sessions.\n\n## Usage\n\n```\n/resume-handoff <path-to-handoff.md>\n/resume-handoff <session-name>\n```\n\n**Arguments:**\n- `path-to-handoff.md`: Direct path to handoff file\n- `session-name`: Session folder name (will find most recent handoff)\n\n## Process\n\n### Step 1: Locate Handoff\n\n**If path provided:** Read the handoff file directly.\n\n**If session-name provided:**\n```bash\n# Find most recent handoff for session\nls -t docs/handoffs/{session-name}/*.md | head -1\n```\n\n**If nothing provided:** List available handoffs:\n```bash\nfind docs/handoffs -name \"*.md\" -type f | head -10\n```\n\n### Step 2: Read and Analyze Handoff\n\n1. Read handoff document completely\n2. Extract key sections:\n   - Task(s) and their statuses\n   - Recent changes\n   - Learnings (what worked, what failed)\n   - Critical references\n   - Action items and next steps\n\n### Step 3: Verify Current State\n\nCheck if changes from handoff still exist:\n\n```bash\n# Check files mentioned in handoff exist\nls -la {files-from-handoff}\n\n# Check git state\ngit log --oneline -5\ngit status\n```\n\n### Step 4: Present Analysis\n\nPresent to user:\n```\nI have analyzed the handoff from {date}.\n\n**Original Tasks:**\n- [Task 1]: {Status from handoff} -> {Current verification}\n\n**Key Learnings:**\n- {Learning} - {Still valid / Changed}\n\n**Recommended Next Actions:**\n1. {Most logical next step}\n2. {Second priority}\n\nShall I proceed with {recommended action}?\n```\n\n### Step 5: Create Action Plan\n\nUse TodoWrite to create task list from action items.\n\n### Step 6: Begin Implementation\n\nStart with first approved task, referencing learnings from handoff.\n\n## Guidelines\n\n1. **Read entire handoff first** - Do not start work until fully analyzed\n2. **Verify current state** - Handoff state may not match current state\n3. **Apply learnings** - Use documented patterns and avoid documented failures\n4. **Be interactive** - Get user buy-in before starting work\n\n## Common Scenarios\n\n| Scenario | Action |\n|----------|--------|\n| All changes present | Proceed with next steps |\n| Some changes missing | Reconcile differences first |\n| Tasks in_progress | Complete unfinished work first |\n| Stale handoff | Re-evaluate strategy with user |\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:handoff-tracking\n```\n\nThe skill contains the complete workflow with:\n- Handoff location and reading process\n- State verification procedures\n- Action plan creation\n- Learnings application\n- Interactive resumption guidelines"
              },
              {
                "name": "/worktree",
                "description": "Create isolated git worktree with interactive setup",
                "path": "default/commands/worktree.md",
                "frontmatter": {
                  "name": "ring:worktree",
                  "description": "Create isolated git worktree with interactive setup",
                  "argument-hint": "[branch-name]"
                },
                "content": "I'm using the using-git-worktrees skill to set up an isolated workspace for your feature work.\n\n**This command will:**\n1. Ask you for the feature/branch name\n2. Auto-detect or ask about worktree directory location\n3. Create the isolated worktree\n4. Set up dependencies\n5. Verify baseline tests pass\n\n**The skill will systematically:**\n- Check for existing `.worktrees/` or `worktrees/` directories\n- Check CLAUDE.md for location preferences\n- Verify .gitignore (for project-local directories)\n- Auto-detect and run project setup (npm install, cargo build, etc.)\n- Run baseline tests to ensure clean starting point\n\n**First, let me ask you about your feature:**\n\nPlease use the AskUserQuestion tool to gather:\n\n**Question 1:** \"What is the name of your feature/branch?\"\n- Header: \"Feature Name\"\n- This will be used for both the branch name and worktree directory name\n- Examples: \"auth-system\", \"user-profiles\", \"payment-integration\"\n\nAfter getting the feature name, follow the complete using-git-worktrees skill process:\n\n1. **Check for existing directories** (priority order):\n   - `.worktrees/` (preferred)\n   - `worktrees/` (alternative)\n   - If both exist, use `.worktrees/`\n\n2. **Check CLAUDE.md** for worktree directory preferences\n\n3. **If no directory exists and no CLAUDE.md preference**, ask user:\n   - Option 1: `.worktrees/` (project-local, hidden)\n   - Option 2: `~/.config/ring/worktrees/<project-name>/` (global location)\n\n4. **Verify .gitignore** (if project-local directory):\n   - MUST check if directory is in .gitignore\n   - If NOT: Add to .gitignore immediately and commit\n   - Per Jesse's rule: \"Fix broken things immediately\"\n\n5. **Create worktree**:\n   - Detect project name: `basename \"$(git rev-parse --show-toplevel)\"`\n   - Create: `git worktree add <path> -b <branch-name>`\n   - Navigate: `cd <path>`\n\n6. **Run project setup** (auto-detect):\n   - Node.js: `npm install` (if package.json exists)\n   - Rust: `cargo build` (if Cargo.toml exists)\n   - Python: `pip install -r requirements.txt` or `poetry install`\n   - Go: `go mod download` (if go.mod exists)\n\n7. **Verify clean baseline**:\n   - Run appropriate test command for the project\n   - If tests fail: Report failures and ask whether to proceed\n   - If tests pass: Report ready\n\n8. **Report completion**:\n   ```\n   Worktree ready at <full-path>\n   Tests passing (N tests, 0 failures)\n   Ready to implement <feature-name>\n   ```\n\nFollow the complete process defined in `skills/using-git-worktrees/SKILL.md`.\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:using-git-worktrees\n```\n\nThe skill contains the complete workflow with:\n- Worktree naming conventions\n- Branch isolation patterns\n- Cleanup procedures\n- Integration with Ring workflows"
              },
              {
                "name": "/write-plan",
                "description": "Create detailed implementation plan with bite-sized tasks",
                "path": "default/commands/write-plan.md",
                "frontmatter": {
                  "name": "ring:write-plan",
                  "description": "Create detailed implementation plan with bite-sized tasks",
                  "argument-hint": "[feature-name]"
                },
                "content": "Create a comprehensive implementation plan for a feature, with exact file paths, complete code examples, and verification steps. Plans are designed to be executable by engineers with zero codebase context.\n\n## Usage\n\n```\n/write-plan [feature-name]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `feature-name` | Yes | Descriptive name for the feature (e.g., \"user-authentication\", \"payment-webhooks\", \"api-rate-limiting\") |\n\n## Examples\n\n### Create a Feature Plan\n```\n/write-plan oauth2-integration\n```\nCreates a detailed plan for implementing OAuth2 authentication.\n\n### Create an API Plan\n```\n/write-plan rest-api-versioning\n```\nPlans the implementation of API versioning with migration path.\n\n### Create a Refactoring Plan\n```\n/write-plan database-connection-pooling\n```\nCreates a step-by-step plan for implementing connection pooling.\n\n## Process\n\n### Step 1: Dispatch Planning Agent\nA specialized planning agent (running on Opus model) is dispatched to:\n- Explore the codebase to understand architecture\n- Identify all files that need modification\n- Break the feature into bite-sized tasks (2-5 minutes each)\n\n### Step 2: Agent Creates Plan\nThe agent writes a comprehensive plan including:\n- Header with goal, architecture, tech stack, prerequisites\n- Bite-sized tasks with exact file paths\n- Complete, copy-paste ready code for each task\n- Exact verification commands with expected output\n- Code review checkpoints after task batches\n- Recommended agents for each task type\n- Failure recovery steps\n\n### Step 3: Save Plan\nPlan is saved to: `docs/plans/YYYY-MM-DD-<feature-name>.md`\n\n### Step 4: Choose Execution Mode\nAfter the plan is ready, you'll be asked:\n\n| Option | Description |\n|--------|-------------|\n| **Execute now** | Start implementation immediately using subagent-driven development |\n| **Execute in parallel session** | Open a new agent session in the worktree for batch execution |\n| **Save for later** | Keep the plan for manual review before execution |\n\n## Plan Requirements (Zero-Context Test)\n\nEvery plan passes the \"Zero-Context Test\" - executable with only the document:\n\n- **Exact file paths** - Never \"somewhere in src\"\n- **Complete code** - Never \"add validation here\"\n- **Verification commands** - With expected output\n- **Failure recovery** - What to do when things go wrong\n- **Code review checkpoints** - Severity-based handling\n- **Agent recommendations** - Which specialized agent for each task\n\n## Agent Selection in Plans\n\nPlans specify recommended agents for execution:\n\n| Task Type | Recommended Agent |\n|-----------|-------------------|\n| Backend (Go) | `backend-engineer-golang` |\n| Backend (TypeScript) | `backend-engineer-typescript` |\n| Frontend (BFF/API Routes) | `frontend-bff-engineer-typescript` |\n| Infrastructure | `devops-engineer` |\n| Testing | `qa-analyst` |\n| Reliability | `sre` |\n| Fallback | `general-purpose` (built-in) |\n\n## Related Commands/Skills\n\n| Command/Skill | Relationship |\n|---------------|--------------|\n| `/brainstorm` | Use first if design is not yet validated |\n| `/execute-plan` | Use after to execute the created plan |\n| `brainstorming` | Design validation before planning |\n| `executing-plans` | Batch execution with review checkpoints |\n| `subagent-driven-development` | Alternative execution for current session |\n\n## Troubleshooting\n\n### \"Design not validated\"\nPlanning requires a validated design. Use `/brainstorm` first to refine your concept before creating the implementation plan.\n\n### \"Plan is too vague\"\nIf the generated plan contains phrases like \"implement the logic\" or \"add appropriate handling\", the plan doesn't meet quality standards. Request revision with specific code examples.\n\n### \"Worktree not set up\"\nThis command is best run in a dedicated worktree created by the brainstorming skill. You can still run it in main, but isolation is recommended.\n\n### \"Agent selection unavailable\"\nIf `ring-dev-team` plugin is not installed, execution falls back to `general-purpose` agents automatically. Plans remain valid regardless.\n\n### When NOT to use this command\n- Design is not validated - use `/brainstorm` first\n- Requirements still unclear - use pre-dev PRD/TRD workflow first\n- Already have a plan - use `/execute-plan` instead\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:writing-plans\n```\n\nThe skill contains the complete workflow with:\n- Plan document structure\n- Task granularity requirements (2-5 min per task)\n- Zero-context test criteria\n- Historical precedent integration\n- Code review checkpoint requirements"
              }
            ],
            "skills": [
              {
                "name": "ring:artifact-query",
                "description": "Search the Artifact Index for relevant historical context using semantic\nfull-text search. Returns handoffs, plans, and continuity ledgers ranked\nby relevance using BM25.\n",
                "path": "default/skills/artifact-query/SKILL.md",
                "frontmatter": {
                  "name": "ring:artifact-query",
                  "description": "Search the Artifact Index for relevant historical context using semantic\nfull-text search. Returns handoffs, plans, and continuity ledgers ranked\nby relevance using BM25.\n",
                  "trigger": "- Need to find similar past work before starting a task\n- Want to learn from previous successes or failures\n- Looking for historical context on a topic\n- Planning a feature and want precedent\n",
                  "skip_when": "- Working on completely novel functionality\n- Simple task that doesn't benefit from historical context\n- Artifact index not initialized (run artifact_index.py --all first)\n",
                  "sequence": {
                    "before": [
                      "writing-plans",
                      "executing-plans"
                    ]
                  },
                  "related": {
                    "similar": [
                      "exploring-codebase"
                    ]
                  }
                },
                "content": "# Artifact Query\n\n## Overview\n\nSearch Ring's Artifact Index for relevant historical context. Uses SQLite FTS5 full-text search with BM25 ranking to find:\n\n- **Handoffs** - Completed task records with what worked/failed\n- **Plans** - Implementation design documents\n- **Continuity** - Session state snapshots with learnings\n\n**Query response time:** < 100ms for typical searches\n\n**Announce at start:** \"I'm searching the artifact index for relevant precedent.\"\n\n## When to Use\n\n| Scenario | Use This Skill |\n|----------|---------------|\n| Starting a new feature | Yes - find similar implementations |\n| Debugging a recurring issue | Yes - find past resolutions |\n| Writing a plan | Yes - learn from past approaches |\n| Simple one-liner fix | No - overhead not worth it |\n| First time using Ring | No - index is empty |\n\n## The Process\n\n### Step 1: Formulate Query\n\nChoose relevant keywords that describe what you're looking for:\n- Feature names: \"authentication\", \"OAuth\", \"API\"\n- Problem types: \"error handling\", \"performance\", \"testing\"\n- Components: \"database\", \"frontend\", \"hook\"\n\n### Step 2: Run Query\n\n```bash\npython3 default/lib/artifact-index/artifact_query.py \"<keywords>\" [options]\n```\n\n**Options:**\n- `--mode search|planning` - Query mode (planning for structured precedent)\n- `--type handoffs|plans|continuity|all` - Filter by artifact type\n- `--outcome SUCCEEDED|FAILED|...` - Filter handoffs by outcome\n- `--limit N` - Maximum results (1-100, default: 5)\n- `--json` - Output as JSON for programmatic use\n- `--stats` - Show index statistics\n- `--no-save` - Disable automatic query saving (saving enabled by default)\n\n### Planning Mode (Recommended for write-plan)\n\nFor structured precedent when creating implementation plans:\n\n```bash\npython3 default/lib/artifact-index/artifact_query.py --mode planning \"feature topic\" --json\n```\n\nReturns:\n- **successful_handoffs**: Past implementations that worked (reference these)\n- **failed_handoffs**: Past implementations that failed (avoid these patterns)\n- **relevant_plans**: Similar past plans for reference\n- **query_time_ms**: Performance metric (target <200ms)\n- **is_empty_index**: True if no historical data available\n\nEmpty index returns:\n```json\n{\n  \"is_empty_index\": true,\n  \"message\": \"No artifact index found. This is normal for new projects.\"\n}\n```\nThis is NOT an error - proceed with standard planning.\n\n### Step 3: Interpret Results\n\nResults are ranked by relevance (BM25 score). For each result:\n\n1. **Check outcome** - Learn from successes, avoid failures\n2. **Read what_worked** - Reuse successful approaches\n3. **Read what_failed** - Don't repeat mistakes\n4. **Note file paths** - Can read full artifact if needed\n\n### Step 4: Apply Learnings\n\nUse historical context to inform current work:\n- Reference successful patterns in your implementation\n- Avoid approaches that failed previously\n- Cite the precedent in your plan or handoff\n\n## Examples\n\n### Find Authentication Implementations\n\n```bash\npython3 default/lib/artifact-index/artifact_query.py \"authentication OAuth JWT\" --type handoffs\n```\n\n### Find Successful API Designs\n\n```bash\npython3 default/lib/artifact-index/artifact_query.py \"API design REST\" --outcome SUCCEEDED\n```\n\n### Get Index Statistics\n\n```bash\npython3 default/lib/artifact-index/artifact_query.py --stats\n```\n\n### Search Plans Only\n\n```bash\npython3 default/lib/artifact-index/artifact_query.py \"context management\" --type plans --json\n```\n\n## Integration with Planning\n\nWhen creating plans (writing-plans skill), query the artifact index first:\n\n1. Search for similar past implementations\n2. Note which approaches succeeded vs failed\n3. Include historical context in your plan\n4. Reference specific handoffs that inform decisions\n\nThis enables RAG-enhanced planning where new plans learn from past experience.\n\n## Initialization\n\nIf the index is empty, initialize it:\n\n```bash\npython3 default/lib/artifact-index/artifact_index.py --all\n```\n\nThis indexes:\n- `docs/handoffs/**/*.md` - Handoff documents\n- `docs/plans/*.md` - Plan documents\n- `.ring/ledgers/*.md` and `CONTINUITY*.md` - Continuity ledgers\n\n## Remember\n\n- Query before starting significant work\n- Learn from both successes AND failures\n- Cite historical precedent in your work\n- Keep the index updated (hooks do this automatically)\n- Response time target: < 100ms"
              },
              {
                "name": "ring:brainstorming",
                "description": "Socratic design refinement - transforms rough ideas into validated designs through\nstructured questioning, alternative exploration, and incremental validation.\n",
                "path": "default/skills/brainstorming/SKILL.md",
                "frontmatter": {
                  "name": "ring:brainstorming",
                  "description": "Socratic design refinement - transforms rough ideas into validated designs through\nstructured questioning, alternative exploration, and incremental validation.\n",
                  "trigger": "- New feature or product idea (requirements unclear)\n- User says \"plan\", \"design\", or \"architect\" something\n- Multiple approaches seem possible\n- Design hasn't been validated by user\n",
                  "skip_when": "- Design already complete and validated  use writing-plans\n- Have detailed plan ready to execute  use executing-plans\n- Just need task breakdown from existing design  use writing-plans\n",
                  "sequence": {
                    "before": [
                      "writing-plans",
                      "using-git-worktrees"
                    ]
                  },
                  "related": {
                    "similar": [
                      "writing-plans"
                    ]
                  }
                },
                "content": "# Brainstorming Ideas Into Designs\n\n## Overview\n\nTransform rough ideas into fully-formed designs through structured questioning and alternative exploration.\n\n**Core principle:** Research first, ask targeted questions to fill gaps, explore alternatives, present design incrementally for validation.\n\n**Announce at start:** \"I'm using the brainstorming skill to refine your idea into a design.\"\n\n## Quick Reference\n\n| Phase | Key Activities | Tool Usage | Output |\n|-------|---------------|------------|--------|\n| **Prep: Autonomous Recon** | Inspect repo/docs/commits, form initial model | Native tools (ls, cat, git log, etc.) | Draft understanding to confirm |\n| **1. Understanding** | Share findings, ask only for missing context | AskUserQuestion for real decisions | Purpose, constraints, criteria (confirmed) |\n| **2. Exploration** | Propose 2-3 approaches | AskUserQuestion for approach selection | Architecture options with trade-offs |\n| **3. Design Presentation** | Present in 200-300 word sections | Open-ended questions | Complete design with validation |\n| **4. Design Documentation** | Write design document | writing-clearly-and-concisely skill | Design doc in docs/plans/ |\n| **5. Worktree Setup** | Set up isolated workspace | using-git-worktrees skill | Ready development environment |\n| **6. Planning Handoff** | Create implementation plan | writing-plans skill | Detailed task breakdown |\n\n## The Process\n\nCopy this checklist to track progress:\n\n```\nBrainstorming Progress:\n- [ ] Prep: Autonomous Recon (repo/docs/commits reviewed, initial model shared)\n- [ ] Phase 1: Understanding (purpose, constraints, criteria gathered)\n- [ ] Phase 2: Exploration (2-3 approaches proposed and evaluated)\n- [ ] Phase 3: Design Presentation (design validated in sections)\n- [ ] Phase 4: Design Documentation (design written to docs/plans/)\n- [ ] Phase 5: Worktree Setup (if implementing)\n- [ ] Phase 6: Planning Handoff (if implementing)\n```\n\n### Prep: Autonomous Recon\n\n**MANDATORY evidence (paste ALL):** `ls -la`, `git log --oneline -10`, `head -50 README.md`, `find . -name \"*test*\" | wc -l`, check package.json/requirements.txt/go.mod.\n\n**Only after ALL evidence pasted:** Form your model and share findings. **Skip any = not following skill.**\n\n### Question Budget\n\n**Maximum 3 questions per phase.** More = insufficient research.\n\nQuestion count:\n- Phase 1: ___/3\n- Phase 2: ___/3\n- Phase 3: ___/3\n\nHit limit? Do research instead of asking.\n\n### Phase 1: Understanding\n- Share your synthesized understanding first, then invite corrections or additions.\n- Ask one focused question at a time, only for gaps you cannot close yourself.\n- **Use AskUserQuestion tool** only when you need the human to make a decision among real alternatives.\n- Gather: Purpose, constraints, success criteria (confirmed or amended by your partner)\n\n**Example summary + targeted question:**\n```\nBased on the README and yesterday's commit, we're expanding localization to dashboard and billing emails; admin console is still untouched. Only gap I see is whether support responses need localization in this iteration. Did I miss anything important?\n```\n\n### Phase Lock Rules\n\n**CRITICAL:** Once you enter a phase, you CANNOT skip ahead.\n\n- Asked a question?  WAIT for answer before solutions\n- Proposed approaches?  WAIT for selection before design\n- Started design?  COMPLETE before documentation\n\n**Violations:**\n- \"While you consider that, here's my design...\"  WRONG\n- \"I'll proceed with option 1 unless...\"  WRONG\n- \"Moving forward with the assumption...\"  WRONG\n\n**WAIT means WAIT. No assumptions.**\n\n### Phase 2: Exploration\n- Propose 2-3 different approaches\n- For each: Core architecture, trade-offs, complexity assessment, and your recommendation\n- **Use AskUserQuestion tool** to present approaches when you truly need a judgement call\n- Lead with the option you prefer and explain why; invite disagreement if your partner sees it differently\n- Own prioritization: if the repo makes priorities clear, state them and proceed rather than asking\n\n**Example using AskUserQuestion:**\n```\nQuestion: \"Which architectural approach should we use?\"\nOptions:\n  - \"Direct API calls with retry logic\" (simple, synchronous, easier to debug)  recommended for current scope\n  - \"Event-driven with message queue\" (scalable, complex setup, eventual consistency)\n  - \"Hybrid with background jobs\" (balanced, moderate complexity, best of both)\n\nI recommend the direct API approach because it matches existing patterns and minimizes new infrastructure. Let me know if you see a blocker that pushes us toward the other options.\n```\n\n### Phase 3: Design Presentation\n- Present in coherent sections; use ~200-300 words when introducing new material, shorter summaries once alignment is obvious\n- Cover: Architecture, components, data flow, error handling, testing\n- Check in at natural breakpoints rather than after every paragraph: \"Stop me if this diverges from what you expect.\"\n- Use open-ended questions to allow freeform feedback\n- Assume ownership and proceed unless your partner redirects you\n\n**Design Acceptance Gate:**\n\nDesign is NOT approved until human EXPLICITLY says one of:\n- \"Approved\" / \"Looks good\" / \"Proceed\"\n- \"Let's implement that\" / \"Ship it\"\n- \"Yes\" (in response to \"Shall I proceed?\")\n\n**These do NOT mean approval:**\n- Silence / No response\n- \"Interesting\" / \"I see\" / \"Hmm\"\n- Questions about the design\n- \"What about X?\" (that's requesting changes)\n\n**No explicit approval = keep refining**\n\n### Phase 4: Design Documentation\nAfter validating the design, write it to a permanent document:\n- **File location:** `docs/plans/YYYY-MM-DD-<topic>-design.md` (use actual date and descriptive topic)\n- **RECOMMENDED SUB-SKILL:** Use elements-of-style:writing-clearly-and-concisely (if available) for documentation quality\n- **Content:** Capture the design as discussed and validated in Phase 3, organized into sections that emerged from the conversation\n- Commit the design document to git before proceeding\n\n### Phase 5: Worktree Setup (for implementation)\nWhen design is approved and implementation will follow:\n- Announce: \"I'm using the using-git-worktrees skill to set up an isolated workspace.\"\n- **REQUIRED SUB-SKILL:** Use using-git-worktrees\n- Follow that skill's process for directory selection, safety verification, and setup\n- Return here when worktree ready\n\n### Phase 6: Planning Handoff\nAsk: \"Ready to create the implementation plan?\"\n\nWhen your human partner confirms (any affirmative response):\n- Announce: \"I'm using the writing-plans skill to create the implementation plan.\"\n- **REQUIRED SUB-SKILL:** Use writing-plans\n- Create detailed plan in the worktree\n\n## Question Patterns\n\n### When to Use AskUserQuestion Tool\n\n**Use AskUserQuestion when:**\n- You need your partner to make a judgement call among real alternatives\n- You have a recommendation and can explain why its your preference\n- Prioritization is ambiguous and cannot be inferred from existing materials\n\n**Best practices:**\n- State your preferred option and rationale inside the question so your partner can agree or redirect\n- If you know the answer from repo/docs, state it as fact and proceedno question needed\n- When priorities are spelled out, acknowledge them and proceed rather than delegating the choice back to your partner\n\n### When to Use Open-Ended Questions\n\n**Use open-ended questions for:**\n- Phase 3: Design validation (\"Does this look right so far?\")\n- When you need detailed feedback or explanation\n- When partner should describe their own requirements\n- When structured options would limit creative input\n\nFrame them to confirm or expand your current understanding rather than reopening settled topics.\n\n**Example decision flow:**\n- \"What authentication method?\"  Use AskUserQuestion (2-4 options)\n- \"Does this design handle your use case?\"  Open-ended (validation)\n\n## When to Revisit Earlier Phases\n\n| Trigger | Action |\n|---------|--------|\n| New constraint revealed |  Return to Phase 1 |\n| Partner questions approach |  Return to Phase 2 |\n| Requirements unclear |  Return to Phase 1 |\n| Something doesn't make sense |  Go back and clarify |\n\n**Avoid forcing forward linearly** when going backward would give better results.\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **Exit Criteria:** See `skills/shared-patterns/exit-criteria.md`\n- **TodoWrite:** See `skills/shared-patterns/todowrite-integration.md`\n\nApply ALL patterns when using this skill.\n\n## Key Principles\n\n| Principle | Application |\n|-----------|-------------|\n| **One question at a time** | Phase 1: Single targeted question only for gaps you cant close yourself |\n| **Structured choices** | Use AskUserQuestion tool for 2-4 options with trade-offs |\n| **YAGNI ruthlessly** | Remove unnecessary features from all designs |\n| **Explore alternatives** | Always propose 2-3 approaches before settling |\n| **Incremental validation** | Present design in sections, validate each |\n| **Flexible progression** | Go backward when needed - flexibility > rigidity |\n| **Own the initiative** | Recommend priorities and next steps; ask if you should proceed only when requirements conflict |\n| **Announce usage** | State skill usage at start of session |"
              },
              {
                "name": "ring:compound-learnings",
                "description": "Use when asked to \"analyze learnings\", \"find patterns\", \"what should become rules\",\n\"compound my learnings\", or after accumulating 5+ session learnings. Analyzes\nsession learnings to detect recurring patterns (3+ occurrences), categorizes them\nas rule/skill/hook candidates, and generates proposals for user approval.\n",
                "path": "default/skills/compound-learnings/SKILL.md",
                "frontmatter": {
                  "name": "ring:compound-learnings",
                  "description": "Use when asked to \"analyze learnings\", \"find patterns\", \"what should become rules\",\n\"compound my learnings\", or after accumulating 5+ session learnings. Analyzes\nsession learnings to detect recurring patterns (3+ occurrences), categorizes them\nas rule/skill/hook candidates, and generates proposals for user approval.\n",
                  "trigger": "- \"What patterns should become permanent?\"\n- \"Analyze my learnings\"\n- \"Compound learnings\"\n- \"Turn learnings into rules\"\n- After completing a feature with multiple sessions\n",
                  "skip_when": "- Fewer than 3 learning files exist\n- Just completed first session (no patterns to detect yet)\n- Looking for specific past learning (use artifact search instead)\n",
                  "related": {
                    "complementary": [
                      "handoff-tracking",
                      "artifact-query"
                    ]
                  }
                },
                "content": "# Compound Learnings\n\nTransform ephemeral session learnings into permanent, compounding capabilities.\n\n## Overview\n\nThis skill analyzes accumulated learnings from past sessions, detects recurring patterns (appearing in 3+ sessions), and generates proposals for new rules, skills, or hooks. User approval is REQUIRED before creating any permanent artifacts.\n\n**Core Principle:** The system improves itself over time by learning from successes and failures.\n\n## When to Use\n\n- \"What should I learn from recent sessions?\"\n- \"Improve my setup based on recent work\"\n- \"Turn learnings into skills/rules\"\n- \"What patterns should become permanent?\"\n- \"Compound my learnings\"\n- After completing a multi-session feature\n\n## When NOT to Use\n\n- Fewer than 3 learning files exist (insufficient data)\n- Looking for a specific past learning (use artifact search)\n- First session on a new project (no history yet)\n\n## Process\n\n### Step 1: Gather Learnings\n\n```bash\n# List learnings (most recent first)\nls -t $PROJECT_ROOT/.ring/cache/learnings/*.md 2>/dev/null | head -20\n\n# Count total learnings\nls $PROJECT_ROOT/.ring/cache/learnings/*.md 2>/dev/null | wc -l\n```\n\n**If fewer than 3 files:** STOP. Insufficient data for pattern detection.\n\nRead the most recent 5-10 files for analysis.\n\n### Step 2: Extract and Consolidate Patterns\n\nFor each learnings file, extract entries from:\n\n| Section Header | What to Extract |\n|----------------|-----------------|\n| `## What Worked` | Success patterns |\n| `## What Failed` | Anti-patterns (invert to rules) |\n| `## Key Decisions` | Design principles |\n| `## Patterns` | Direct pattern candidates |\n\n**Consolidate similar patterns before counting:**\n\n| Raw Patterns | Consolidated To |\n|--------------|-----------------|\n| \"Check artifacts before editing\", \"Verify outputs first\", \"Look before editing\" | \"Observe outputs before editing code\" |\n| \"TDD approach\", \"Test-driven development\", \"Write tests first\" | \"Use TDD workflow\" |\n\nUse the most general formulation.\n\n### Step 3: Detect Recurring Patterns\n\n**Signal thresholds:**\n\n| Occurrences | Action |\n|-------------|--------|\n| 1 | Skip (insufficient signal) |\n| 2 | Consider - present to user for information only |\n| 3+ | Strong signal - recommend creating permanent artifact |\n| 4+ | Definitely create |\n\n**Only patterns appearing in 3+ DIFFERENT sessions qualify for proposals.**\n\n### Step 4: Categorize Patterns\n\nFor each qualifying pattern, determine artifact type:\n\n```\nIs it a sequence of commands/steps?\n   YES  SKILL (executable process)\n   NO \n\nShould it run automatically on an event?\n   YES  HOOK (SessionEnd, PostToolUse, etc.)\n   NO \n\nIs it \"when X, do Y\" or \"never do X\"?\n   YES  RULE (behavioral heuristic)\n   NO  Skip (not worth capturing)\n```\n\n**Examples:**\n\n| Pattern | Type | Why |\n|---------|------|-----|\n| \"Run tests before committing\" | Hook (PreCommit) | Automatic gate |\n| \"Step-by-step debugging process\" | Skill | Manual sequence |\n| \"Always use explicit file paths\" | Rule | Behavioral heuristic |\n\n### Step 5: Generate Proposals\n\nPresent each proposal in this format:\n\n```markdown\n---\n## Pattern: [Generalized Name]\n\n**Signal:** [N] sessions ([list session IDs])\n\n**Category:** [rule / skill / hook]\n\n**Rationale:** [Why this artifact type, why worth creating]\n\n**Draft Content:**\n[Preview of what would be created]\n\n**Target Location:** `.ring/generated/rules/[name].md` or `.ring/generated/skills/[name]/SKILL.md`\n\n**Your Action:** [APPROVE] / [REJECT] / [MODIFY]\n\n---\n```\n\n### Step 6: WAIT FOR USER APPROVAL\n\n**CRITICAL: DO NOT create any files without explicit user approval.**\n\nUser must explicitly say:\n- \"Approve\" or \"Create it\"  Proceed to create\n- \"Reject\" or \"Skip\"  Mark as rejected, do not create\n- \"Modify\"  User provides changes, then re-propose\n\n**NEVER assume approval. NEVER create without explicit consent.**\n\n### Step 7: Create Approved Artifacts\n\n#### Before Creating Any Artifact:\nEnsure the target directories exist:\n```bash\nmkdir -p $PROJECT_ROOT/.ring/generated/rules\nmkdir -p $PROJECT_ROOT/.ring/generated/skills\nmkdir -p $PROJECT_ROOT/.ring/generated/hooks\n```\n\n#### For Rules:\n\nCreate file at `.ring/generated/rules/<slug>.md` with:\n- Rule name and context\n- Pattern description\n- DO / DON'T sections\n- Source sessions\n\n#### For Skills:\n\nCreate directory `.ring/generated/skills/<slug>/` with `SKILL.md` containing:\n- YAML frontmatter (name, description)\n- Overview (what it does)\n- When to Use (triggers)\n- When NOT to Use\n- Step-by-step process\n- Source sessions\n\n**Note:** Generated skills are project-local. To make them discoverable, add to your project's `CLAUDE.md`:\n```markdown\n## Project-Specific Skills\nSee `.ring/generated/skills/` for learnings-based skills.\n```\n\n#### For Hooks:\n\nCreate in `.ring/generated/hooks/<name>.sh` following Ring's hook patterns.\nRegister in project's `.claude/hooks.json` (not plugin's hooks.json).\n\n### Step 8: Archive Processed Learnings\n\nAfter creating artifacts, move processed learnings:\n\n```bash\n# Create archive directory\nmkdir -p $PROJECT_ROOT/.ring/cache/learnings/archived\n\n# Move processed files (preserving them for reference)\nmv $PROJECT_ROOT/.ring/cache/learnings/2025-*.md $PROJECT_ROOT/.ring/cache/learnings/archived/\n```\n\n### Step 9: Summary Report\n\n```markdown\n## Compounding Complete\n\n**Learnings Analyzed:** [N] sessions\n**Patterns Found:** [M]\n**Artifacts Created:** [K]\n\n### Created:\n- Rule: `explicit-paths.md` - Always use explicit file paths\n- Skill: `systematic-debugging` - Step-by-step debugging workflow\n\n### Skipped (insufficient signal):\n- \"Pattern X\" (2 occurrences - below threshold)\n\n### Rejected by User:\n- \"Pattern Y\" - User chose not to create\n\n**Your setup is now permanently improved.**\n```\n\n## Quality Checks\n\nBefore creating any artifact:\n\n1. **Is it general enough?** Would it apply in other projects?\n2. **Is it specific enough?** Does it give concrete guidance?\n3. **Does it already exist?** Check `.ring/generated/rules/` and `.ring/generated/skills/` first\n4. **Is it the right type?** Sequences  skills, heuristics  rules\n\n## Common Mistakes\n\n| Mistake | Why It's Wrong | Correct Approach |\n|---------|----------------|------------------|\n| Creating without approval | Violates user consent | ALWAYS wait for explicit approval |\n| Low-signal patterns | 1-2 occurrences is noise | Require 3+ session occurrences |\n| Too specific | Won't apply elsewhere | Generalize to broader principle |\n| Too vague | No actionable guidance | Include concrete DO/DON'T |\n| Duplicate artifacts | Wastes space, confuses | Check existing rules/skills first |\n\n## Files Reference\n\n**Project-local data (per-project):**\n- Learnings input: `.ring/cache/learnings/*.md`\n- Proposals: `.ring/cache/proposals/pending.json`\n- History: `.ring/cache/proposals/history.json`\n- Generated rules: `.ring/generated/rules/<name>.md`\n- Generated skills: `.ring/generated/skills/<name>/SKILL.md`\n- Generated hooks: `.ring/generated/hooks/<name>.sh`\n\n**Plugin code (shared, read-only):**\n- Library: `default/lib/compound_learnings/`\n- Skill: `default/skills/compound-learnings/SKILL.md`\n- Command: `default/commands/compound-learnings.md`"
              },
              {
                "name": "ring:condition-based-waiting",
                "description": "Flaky test fix pattern - replaces arbitrary timeouts with condition polling\nthat waits for actual state changes.\n",
                "path": "default/skills/condition-based-waiting/SKILL.md",
                "frontmatter": {
                  "name": "ring:condition-based-waiting",
                  "description": "Flaky test fix pattern - replaces arbitrary timeouts with condition polling\nthat waits for actual state changes.\n",
                  "trigger": "- Tests use setTimeout/sleep with arbitrary values\n- Tests are flaky (pass sometimes, fail under load)\n- Tests timeout when run in parallel\n- Waiting for async operations in tests\n",
                  "skip_when": "- Testing actual timing behavior (debounce, throttle)  timeout is correct\n- Synchronous tests  no waiting needed\n"
                },
                "content": "# Condition-Based Waiting\n\n## Overview\n\nFlaky tests often guess at timing with arbitrary delays. This creates race conditions where tests pass on fast machines but fail under load or in CI.\n\n**Core principle:** Wait for the actual condition you care about, not a guess about how long it takes.\n\n## When to Use\n\n**Decision flow:** Test uses setTimeout/sleep?  Testing actual timing behavior?  (yes: document WHY timeout needed) | (no: **use condition-based waiting**)\n\n**Use when:** Arbitrary delays (`setTimeout`, `sleep`) | Flaky tests (pass sometimes, fail under load) | Timeouts in parallel runs | Async operation waits\n\n**Don't use when:** Testing actual timing behavior (debounce, throttle) - document WHY if using arbitrary timeout\n\n## Core Pattern\n\n```typescript\n//  BEFORE: Guessing at timing\nawait new Promise(r => setTimeout(r, 50));\nconst result = getResult();\nexpect(result).toBeDefined();\n\n//  AFTER: Waiting for condition\nawait waitFor(() => getResult() !== undefined);\nconst result = getResult();\nexpect(result).toBeDefined();\n```\n\n## Quick Patterns\n\n| Scenario | Pattern |\n|----------|---------|\n| Wait for event | `waitFor(() => events.find(e => e.type === 'DONE'))` |\n| Wait for state | `waitFor(() => machine.state === 'ready')` |\n| Wait for count | `waitFor(() => items.length >= 5)` |\n| Wait for file | `waitFor(() => fs.existsSync(path))` |\n| Complex condition | `waitFor(() => obj.ready && obj.value > 10)` |\n\n## Implementation\n\n**Generic polling:** `waitFor(condition, description, timeoutMs=5000)` - poll every 10ms, throw on timeout with clear message. See @example.ts for domain-specific helpers (`waitForEvent`, `waitForEventCount`, `waitForEventMatch`).\n\n## Common Mistakes\n\n|  Bad |  Fix |\n|--------|--------|\n| Polling too fast (`setTimeout(check, 1)`) | Poll every 10ms |\n| No timeout (loop forever) | Always include timeout with clear error |\n| Stale data (cache before loop) | Call getter inside loop for fresh data |\n\n## When Arbitrary Timeout IS Correct\n\n`await waitForEvent(...); await setTimeout(200)` - OK when: (1) First wait for triggering condition (2) Based on known timing, not guessing (3) Comment explaining WHY (e.g., \"200ms = 2 ticks at 100ms intervals\")\n\n## Real-World Impact\n\nFixed 15 flaky tests across 3 files: 60%  100% pass rate, 40% faster execution, zero race conditions."
              },
              {
                "name": "ring:continuity-ledger",
                "description": "Create or update continuity ledger for state preservation across /clear operations.\nLedgers maintain session state externally, surviving context resets with full fidelity.\n",
                "path": "default/skills/continuity-ledger/SKILL.md",
                "frontmatter": {
                  "name": "ring:continuity-ledger",
                  "description": "Create or update continuity ledger for state preservation across /clear operations.\nLedgers maintain session state externally, surviving context resets with full fidelity.\n",
                  "trigger": "- Before running /clear\n- Context usage approaching 70%+\n- Multi-phase implementations (3+ phases)\n- Complex refactors spanning multiple sessions\n- Any session expected to hit 85%+ context\n",
                  "skip_when": "- Quick tasks (< 30 min estimated)\n- Simple single-file bug fixes\n- Already using handoffs for cross-session transfer\n- No multi-phase work in progress\n"
                },
                "content": "# Continuity Ledger\n\nMaintain a ledger file that survives `/clear` for long-running sessions. Unlike handoffs (cross-session), ledgers preserve state within a session.\n\n**Why clear instead of compact?** Each compaction is lossy compression - after several compactions, you're working with degraded context. Clearing + loading the ledger gives you fresh context with full signal.\n\n## When to Use\n\n- Before running `/clear`\n- Context usage approaching 70%+\n- Multi-day implementations\n- Complex refactors you pick up/put down\n- Any session expected to hit 85%+ context\n\n## When NOT to Use\n\n- Quick tasks (< 30 min)\n- Simple bug fixes\n- Single-file changes\n- Already using handoffs for cross-session transfer\n\n## Ledger Location\n\nLedgers are stored in: `$PROJECT_ROOT/.ring/ledgers/`\nFormat: `CONTINUITY-<session-name>.md`\n\n**Use kebab-case for session name** (e.g., `auth-refactor`, `api-migration`)\n\n## Process\n\n### 1. Determine Ledger File\n\nCheck if a ledger already exists:\n```bash\nls \"$PROJECT_ROOT/.ring/ledgers/CONTINUITY-\"*.md 2>/dev/null\n```\n\n- **If exists**: Update the existing ledger\n- **If not**: Create new file with the template below\n\n### 2. Create/Update Ledger\n\n**REQUIRED SECTIONS (all must be present):**\n\n```markdown\n# Session: <name>\nUpdated: <ISO timestamp>\n\n## Goal\n<Success criteria - what does \"done\" look like?>\n\n## Constraints\n<Tech requirements, patterns to follow, things to avoid>\n\n## Key Decisions\n<Choices made with brief rationale>\n- Decision 1: Chose X over Y because...\n- Decision 2: ...\n\n## State\n- Done:\n  - [x] Phase 1: <completed phase>\n  - [x] Phase 2: <completed phase>\n- Now: [->] Phase 3: <current focus - ONE thing only>\n- Next:\n  - [ ] Phase 4: <queued item>\n  - [ ] Phase 5: <queued item>\n\n## Open Questions\n- UNCONFIRMED: <things needing verification after clear>\n- UNCONFIRMED: <assumptions that should be validated>\n\n## Working Set\n<Active files, branch, test commands>\n- Branch: `feature/xyz`\n- Key files: `src/auth/`, `tests/auth/`\n- Test cmd: `npm test -- --grep auth`\n- Build cmd: `npm run build`\n```\n\n### 3. Checkbox States\n\n| Symbol | Meaning |\n|--------|---------|\n| `[x]` | Completed |\n| `[->]` | In progress (current) |\n| `[ ]` | Pending |\n\n**Why checkboxes in files:** TodoWrite survives compaction, but the *understanding* around those todos degrades each time context is compressed. File-based checkboxes are never compressed - full fidelity preserved.\n\n### 4. Real-Time Update Rule (MANDATORY)\n\n** HARD GATE: Update ledger IMMEDIATELY after completing ANY phase.**\n\nYou (the AI) are the one doing the work. You know exactly when:\n- A phase is complete\n- A decision is made\n- An open question is resolved\n\n**There is NO excuse to wait for the user to ask.** This is the same discipline as `TodoWrite` - update in real-time.\n\n| After This Event | MUST Do This | Before |\n|------------------|--------------|--------|\n| Complete a phase | Mark `[x]`, move `[->]` to next | Proceeding to next phase |\n| All phases done | Add `Status: COMPLETED` | Telling user \"done\" |\n| Make key decision | Add to Key Decisions section | Moving on |\n| Resolve open question | Change UNCONFIRMED  CONFIRMED | Proceeding |\n\n**Anti-Rationalization:**\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I'll update after I finish\" | You'll forget. State drifts. User asks why ledger is stale. | **Update NOW** |\n| \"It's just one phase\" | One phase becomes three. Ledger shows Phase 2 when you're on Phase 5. | **Update NOW** |\n| \"User will ask me to update\" | User shouldn't have to. You're the AI doing the work. You know. | **Update NOW** |\n| \"I'm in the flow, don't want to stop\" | 10 seconds to update vs. explaining why ledger is wrong later. | **Update NOW** |\n\n### 5. Update Guidelines\n\n**When to update the ledger:**\n- **IMMEDIATELY after completing a phase** (MANDATORY - see above)\n- Session start: Read and refresh\n- After major decisions\n- Before `/clear`\n- At natural breakpoints\n- When context usage >70%\n\n**What to update:**\n- Move completed items from \"Now\" to \"Done\" (change `[->]` to `[x]`)\n- Update \"Now\" with current focus\n- Add new decisions as they're made\n- Mark items as UNCONFIRMED if uncertain\n- Add `Status: COMPLETED` when all phases done\n\n### 6. After Clear Recovery\n\nWhen resuming after `/clear`:\n\n1. **Ledger loads automatically** (SessionStart hook)\n2. **Find `[->]` marker** to see current phase\n3. **Review UNCONFIRMED items**\n4. **Ask 1-3 targeted questions** to validate assumptions\n5. **Update ledger** with clarifications\n6. **Continue work** with fresh context\n\n## Template Response\n\nAfter creating/updating the ledger, respond:\n\n```\nContinuity ledger updated: .ring/ledgers/CONTINUITY-<name>.md\n\nCurrent state:\n- Done: <summary of completed phases>\n- Now: <current focus>\n- Next: <upcoming phases>\n\nReady for /clear - ledger will reload on resume.\n```\n\n## UNCONFIRMED Prefix\n\nMark uncertain items explicitly:\n\n```markdown\n## Open Questions\n- UNCONFIRMED: Does the auth middleware need updating?\n- UNCONFIRMED: Are we using v2 or v3 of the API?\n```\n\nAfter `/clear`, these prompt you to verify before proceeding.\n\n## Comparison with Other Tools\n\n| Tool | Scope | Fidelity |\n|------|-------|----------|\n| CLAUDE.md | Project | Always fresh, stable patterns |\n| TodoWrite | Turn | Survives compaction, but understanding degrades |\n| CONTINUITY-*.md | Session | External file - never compressed, full fidelity |\n| Handoffs | Cross-session | External file - detailed context for new session |\n\n## Example\n\n```markdown\n# Session: auth-refactor\nUpdated: 2025-01-15T14:30:00Z\n\n## Goal\nReplace JWT auth with session-based auth. Done when all tests pass and no JWT imports remain.\n\n## Constraints\n- Must maintain backward compat for 2 weeks (migration period)\n- Use existing Redis for session storage\n- No new dependencies\n\n## Key Decisions\n- Session tokens: UUID v4 (simpler than signed tokens for our use case)\n- Storage: Redis with 24h TTL (matches current JWT expiry)\n- Migration: Dual-auth period, feature flag controlled\n\n## State\n- Done:\n  - [x] Phase 1: Session model\n  - [x] Phase 2: Redis integration\n  - [x] Phase 3: Login endpoint\n- Now: [->] Phase 4: Logout endpoint and session invalidation\n- Next:\n  - [ ] Phase 5: Middleware swap\n  - [ ] Phase 6: Remove JWT\n  - [ ] Phase 7: Update tests\n\n## Open Questions\n- UNCONFIRMED: Does rate limiter need session awareness?\n\n## Working Set\n- Branch: `feature/session-auth`\n- Key files: `src/auth/session.ts`, `src/middleware/auth.ts`\n- Test cmd: `npm test -- --grep session`\n```\n\n## Additional Notes\n\n- **Keep it concise** - Brevity matters for context\n- **One \"Now\" item** - Forces focus, prevents sprawl\n- **UNCONFIRMED prefix** - Signals what to verify after clear\n- **Update frequently** - Stale ledgers lose value quickly\n- **Clear > compact** - Fresh context beats degraded context"
              },
              {
                "name": "ring:defense-in-depth",
                "description": "Multi-layer validation pattern - validates data at EVERY layer it passes through\nto make bugs structurally impossible, not just caught.\n",
                "path": "default/skills/defense-in-depth/SKILL.md",
                "frontmatter": {
                  "name": "ring:defense-in-depth",
                  "description": "Multi-layer validation pattern - validates data at EVERY layer it passes through\nto make bugs structurally impossible, not just caught.\n",
                  "trigger": "- Bug caused by invalid data reaching deep layers\n- Single validation point can be bypassed\n- Need to prevent bug category, not just instance\n",
                  "skip_when": "- Validation already exists at all layers  check other issues\n- Simple input validation sufficient  add single check\n",
                  "related": {
                    "complementary": [
                      "root-cause-tracing"
                    ]
                  }
                },
                "content": "# Defense-in-Depth Validation\n\n## Overview\n\nWhen you fix a bug caused by invalid data, adding validation at one place feels sufficient. But that single check can be bypassed by different code paths, refactoring, or mocks.\n\n**Core principle:** Validate at EVERY layer data passes through. Make the bug structurally impossible.\n\n## Why Multiple Layers\n\nSingle validation: \"We fixed the bug\"\nMultiple layers: \"We made the bug impossible\"\n\nDifferent layers catch different cases:\n- Entry validation catches most bugs\n- Business logic catches edge cases\n- Environment guards prevent context-specific dangers\n- Debug logging helps when other layers fail\n\n## The Four Layers\n\n| Layer | Purpose | Example |\n|-------|---------|---------|\n| **1. Entry Point** | Reject invalid input at API boundary | `if (!workingDir \\|\\| !existsSync(workingDir)) throw new Error(...)` |\n| **2. Business Logic** | Ensure data makes sense for operation | `if (!projectDir) throw new Error('projectDir required')` |\n| **3. Environment Guards** | Prevent dangerous ops in contexts | `if (NODE_ENV === 'test' && !path.startsWith(tmpdir())) throw...` |\n| **4. Debug Instrumentation** | Capture context for forensics | `logger.debug('About to git init', { directory, cwd, stack })` |\n\n## Applying the Pattern\n\n**Steps:** (1) Trace data flow (origin  error) (2) Map all checkpoints (3) Add validation at each layer (4) Test each layer (try to bypass layer 1, verify layer 2 catches it)\n\n## Example\n\n**Bug:** Empty `projectDir` caused `git init` in source code\n\n**Flow:** Test setup (`''`)  `Project.create(name, '')`  `WorkspaceManager.createWorkspace('')`  `git init` in `process.cwd()`\n\n**Layers added:** L1: `Project.create()` validates not empty/exists/writable | L2: `WorkspaceManager` validates not empty | L3: Refuse git init outside tmpdir in tests | L4: Stack trace logging\n\n**Result:** 1847 tests passed, bug impossible to reproduce\n\n## Key Insight\n\nAll four layers necessary - each caught bugs others missed: different code paths bypassed entry validation | mocks bypassed business logic | edge cases needed environment guards | debug logging identified structural misuse.\n\n**Don't stop at one validation point.** Add checks at every layer."
              },
              {
                "name": "ring:dispatching-parallel-agents",
                "description": "Concurrent investigation pattern - dispatches multiple AI agents to investigate\nand fix independent problems simultaneously.\n",
                "path": "default/skills/dispatching-parallel-agents/SKILL.md",
                "frontmatter": {
                  "name": "ring:dispatching-parallel-agents",
                  "description": "Concurrent investigation pattern - dispatches multiple AI agents to investigate\nand fix independent problems simultaneously.\n",
                  "trigger": "- 3+ failures in different test files/subsystems\n- Problems are independent (no shared state)\n- Each can be investigated without context from others\n",
                  "skip_when": "- Failures are related/connected  single investigation\n- Shared state between problems  sequential investigation\n- <3 failures  investigate directly\n"
                },
                "content": "# Dispatching Parallel Agents\n\n## Overview\n\nWhen you have multiple unrelated failures (different test files, different subsystems, different bugs), investigating them sequentially wastes time. Each investigation is independent and can happen in parallel.\n\n**Core principle:** Dispatch one agent per independent problem domain. Let them work concurrently.\n\n## When to Use\n\n**Decision flow:** Multiple failures?  Are they independent? (No  single agent) | Independent?  Can work in parallel? (No/shared state  sequential) | Yes  **Parallel dispatch**\n\n**Use when:** 3+ test files with different root causes | Multiple subsystems broken independently | Each problem understood without others | No shared state\n\n**Don't use when:** Failures related (fix one might fix others) | Need full system state | Agents would interfere\n\n## The Pattern\n\n**1. Identify Independent Domains:** Group failures by what's broken (File A: approval flow, File B: batch behavior, File C: abort). Each domain independent.\n\n**2. Create Focused Agent Tasks:** Each agent gets: specific scope (one file/subsystem), clear goal (make tests pass), constraints (don't change other code), expected output (summary of findings/fixes).\n\n**3. Dispatch in Parallel:** `Task(\"Fix agent-tool-abort.test.ts\")` + `Task(\"Fix batch-completion.test.ts\")` + `Task(\"Fix tool-approval-races.test.ts\")` - all concurrent.\n\n**4. Review and Integrate:** Read summaries  verify no conflicts  run full test suite  integrate all changes.\n\n## Agent Prompt Structure\n\nGood prompts are: **Focused** (one problem domain), **Self-contained** (all context included), **Specific output** (what to return).\n\n**Example:** \"Fix 3 failing tests in agent-tool-abort.test.ts: [list tests + expected behavior]. Timing/race issues. Read tests  identify root cause  fix (event-based waiting, not timeout increases). Return: Summary of findings and fixes.\"\n\n## Common Mistakes\n\n|  Bad |  Good |\n|--------|---------|\n| Too broad: \"Fix all tests\" | Specific: \"Fix agent-tool-abort.test.ts\" |\n| No context: \"Fix race condition\" | Context: Paste error messages + test names |\n| No constraints: Agent refactors everything | Constraints: \"Do NOT change production code\" |\n| Vague output: \"Fix it\" | Specific: \"Return summary of root cause and changes\" |\n\n## When NOT to Use\n\nRelated failures (fix one might fix others) | Need full context | Exploratory debugging | Shared state (same files/resources)\n\n## Real Example\n\n**Scenario:** 6 failures across 3 files after refactoring.\n**Decision:** Independent domains  parallel dispatch.\n**Results:** Agent 1 (timeouts  events), Agent 2 (event structure bug), Agent 3 (async wait). All independent, no conflicts, suite green. **3 problems solved in time of 1.**\n\n## Key Benefits\n\n**Parallelization** (simultaneous) | **Focus** (narrow scope) | **Independence** (no interference) | **Speed** (3  1 time unit)\n\n## Verification\n\nAfter agents return: Review summaries  check for conflicts  run full suite  spot check for systematic errors."
              },
              {
                "name": "ring:executing-plans",
                "description": "Controlled plan execution with human review checkpoints - loads plan, executes\nin batches, pauses for feedback. Supports one-go (autonomous) or batch modes.\n",
                "path": "default/skills/executing-plans/SKILL.md",
                "frontmatter": {
                  "name": "ring:executing-plans",
                  "description": "Controlled plan execution with human review checkpoints - loads plan, executes\nin batches, pauses for feedback. Supports one-go (autonomous) or batch modes.\n",
                  "trigger": "- Have a plan file ready to execute\n- Want human review between task batches\n- Need structured checkpoints during implementation\n",
                  "skip_when": "- Same session with independent tasks  use subagent-driven-development\n- No plan exists  use writing-plans first\n- Plan needs revision  use brainstorming first\n",
                  "sequence": {
                    "after": [
                      "writing-plans",
                      "pre-dev-task-breakdown"
                    ]
                  },
                  "related": {
                    "similar": [
                      "subagent-driven-development"
                    ]
                  }
                },
                "content": "# Executing Plans\n\n## Overview\n\nLoad plan, review critically, choose execution mode, execute tasks with code review.\n\n**Core principle:** User chooses between autonomous execution or batch execution with human review checkpoints.\n\n**Two execution modes:**\n- **One-go (autonomous):** Execute all batches continuously with code review, report only at completion\n- **Batch (with review):** Execute one batch, code review, pause for human feedback, repeat\n\n**Announce at start:** \"I'm using the executing-plans skill to implement this plan.\"\n\n## The Process\n\n### Step 1: Load and Review Plan\n1. Read plan file\n2. Review critically - identify any questions or concerns about the plan\n3. If concerns: Raise them with your human partner before starting\n4. If no concerns: Create TodoWrite and proceed to Step 2\n\n### Step 2: Choose Execution Mode (MANDATORY)\n\n** THIS STEP IS NON-NEGOTIABLE. You MUST use `AskUserQuestion` before executing ANY tasks.**\n\nAsk: \"How would you like to execute this plan?\" Options: (1) **One-go (autonomous)** - all batches with code review, no human review until completion (2) **Batch (with review)** - pause for human review after each batch\n\n**Based on response:** One-go  Steps 3-4 loop until done | Batch  Steps 3-5 loop\n\n### Why AskUserQuestion is Mandatory (Not \"Contextual Guidance\")\n\n**This is a structural checkpoint, not optional UX polish.**\n\nUser saying \"don't wait\", \"don't ask questions\", or \"just execute\" does NOT skip this step because:\n\n1. **Execution mode affects architecture** - One-go vs batch determines review checkpoints, error recovery paths, and rollback points\n2. **Implicit intent  explicit choice** - \"Don't wait\" might mean \"use one-go\" OR \"ask quickly and proceed\"\n3. **AskUserQuestion takes 3 seconds** - It's not an interruption, it's a confirmation\n4. **Emergency pressure is exactly when mistakes happen** - Structural gates exist FOR high-pressure moments\n\n**Common Rationalizations That Mean You're About to Violate This Rule:**\n\n| Rationalization | Reality |\n|-----------------|---------|\n| \"User intent is crystal clear\" | Intent is not the same as explicit selection. Ask anyway. |\n| \"This is contextual guidance, not absolute law\" | Wrong. It says MANDATORY. That means mandatory. |\n| \"Asking would violate their 'don't ask' instruction\" | AskUserQuestion is a 3-second structural gate, not a conversation. |\n| \"Skills are tools, not bureaucratic checklists\" | This skill IS the checklist. Follow it. |\n| \"Interpreting spirit over letter\" | The spirit IS the letter. Use AskUserQuestion. |\n| \"User already chose by saying 'just execute'\" | Verbal shorthand  structured mode selection. Ask. |\n\n**If you catch yourself thinking any of these  STOP  Use AskUserQuestion anyway.**\n\n### Step 3: Execute Batch\n**Default: First 3 tasks**\n\n**Agent Selection:** Backend Go  `backend-engineer-golang` | Backend TS  `backend-engineer-typescript` | Frontend  `frontend-bff-engineer-typescript` | Infra  `devops-engineer` | Testing  `qa-analyst` | Reliability  `sre`\n\nFor each task: Mark in_progress  Dispatch to agent  Follow plan steps exactly  Run verifications  Mark completed\n\n### Step 4: Run Code Review\n**After each batch, REQUIRED:** Use requesting-code-review (all 3 reviewers in parallel)\n\n**Handle by severity:**\n- **Critical/High/Medium:** Fix immediately (no TODO)  re-run all 3 reviewers  repeat until resolved\n- **Low:** Add `TODO(review): [Issue] ([reviewer], [date], Low)`\n- **Cosmetic:** Add `FIXME(nitpick): [Issue] ([reviewer], [date], Cosmetic)`\n\n**Proceed when:** Zero Critical/High/Medium remain + all Low/Cosmetic have comments\n\n### Step 5: Report and Continue\n\n**One-go mode:** Log internally  proceed to next batch  report only at completion\n**Batch mode:** Show implementation + verification + review results  \"Ready for feedback.\"  wait  apply changes  proceed\n\n### Step 6: Complete Development\n\nUse finishing-a-development-branch to verify tests, present options, execute choice.\n\n## When to Stop\n\n**STOP immediately:** Blocker mid-batch | Critical gaps | Unclear instruction | Verification fails repeatedly. **Ask rather than guess.**\n\n## Remember\n\n- **MANDATORY:** `AskUserQuestion` for execution mode - NO exceptions\n- Use `*` agents over `general-purpose` when available\n- Run code review after each batch (all 3 parallel)\n- Fix Critical/High/Medium immediately (no TODO)\n- Low  TODO, Cosmetic  FIXME\n- Stop when blocked, don't guess\n- **If rationalizing why to skip AskUserQuestion  You're wrong  Ask anyway**"
              },
              {
                "name": "ring:exploring-codebase",
                "description": "Autonomous two-phase codebase exploration - first discovers natural perspectives\n(layers, components, boundaries), then dispatches adaptive deep-dive explorers\nbased on what was discovered. Synthesizes findings into actionable insights.\n",
                "path": "default/skills/exploring-codebase/SKILL.md",
                "frontmatter": {
                  "name": "ring:exploring-codebase",
                  "description": "Autonomous two-phase codebase exploration - first discovers natural perspectives\n(layers, components, boundaries), then dispatches adaptive deep-dive explorers\nbased on what was discovered. Synthesizes findings into actionable insights.\n",
                  "trigger": "- Need to understand how a feature/system works across the codebase\n- Starting work on unfamiliar codebase or component\n- Planning changes that span multiple layers/components\n- User asks \"how does X work?\" for non-trivial X\n- Need architecture understanding before implementation\n",
                  "skip_when": "- Pure reference lookup (function signature, type definition)\n- Checking if specific file exists (yes/no question)\n- Reading error message from known file location\n\nWARNING: These are NOT valid skip reasons:\n- \"I already know the architecture\"  Prior knowledge is incomplete\n- \"Simple question about location\"  Location without context is incomplete\n- \"Production emergency, no time\"  High stakes demand MORE rigor\n- \"Colleague told me structure\"  High-level  implementation details\n",
                  "related": {
                    "similar": [
                      "dispatching-parallel-agents",
                      "systematic-debugging"
                    ],
                    "sequence_after": [
                      "brainstorming"
                    ],
                    "sequence_before": [
                      "writing-plans",
                      "executing-plans"
                    ]
                  }
                },
                "content": "# Autonomous Two-Phase Codebase Exploration\n\n## Overview\n\nTraditional exploration assumes structure upfront or explores sequentially. This skill takes an autonomous two-phase approach: **discover** the natural perspectives of the codebase first, then **deep dive** into each discovered perspective with targeted explorers.\n\n**Core principle:** Let the codebase reveal its own structure, then explore each structure element thoroughly with adaptive parallel agents.\n\n**MANDATORY ANNOUNCEMENT at start:**\n\n\"I'm using the exploring-codebase skill to autonomously discover and explore the codebase structure.\n\nBefore proceeding, I've checked the Red Flags table and confirmed:\n- [X] Production pressure makes me WANT to skip discovery  Using skill anyway\n- [X] I think I 'already know' the structure  Discovery will validate assumptions\n- [X] This seems like a simple question  Location without context is incomplete\n- [X] Colleague gave me high-level info  Discovery finds what they forgot\n\nThe skill's core principle: **When pressure is highest, systematic approach matters most.**\"\n\n##  Red Flags: When You're About to Make a Mistake\n\n**STOP and use this skill if you catch yourself thinking:**\n\n| Red Flag Thought | What It Means | Do This Instead |\n|------------------|---------------|-----------------|\n| \"I already know this architecture\" |  Dunning-Kruger | Run discovery to validate assumptions |\n| \"Grep is faster for this simple question\" |  Optimizing for feeling productive | One exploration > multiple follow-ups |\n| \"Production is down, no time for process\" |  Panic mode | High stakes demand MORE rigor |\n| \"Colleague told me the structure\" |  Trusting abstractions | Discovery finds what they forgot |\n| \"Being pragmatic means skipping this\" |  Conflating speed with value | Real pragmatism = doing it right |\n| \"This is overkill for...\" |  Underestimating complexity | Incomplete understanding compounds |\n| \"I'll explore progressively if I get stuck\" |  Reactive vs proactive | Discovery prevents getting stuck |\n| \"Let me just quickly check...\" |  Ad-hoc investigation trap | Systematic > ad-hoc |\n\n**If 2+ red flags triggered: YOU NEED THIS SKILL.**\n\n##  Violation Consequences: Real Costs of Skipping\n\n**\"What's the worst that could happen if I skip discovery?\"**\n\n### Consequence 1: The Cascade Effect\n**Scenario:** Skip discovery  Fix in wrong component  Break integration  New production issue\n\n**Example:**\n- Bug: \"Account creation failing\"\n- Assumption: \"It's in onboarding component\"\n- Reality: Transaction component has new validation that breaks onboarding\n- Your fix: Modify onboarding (wrong component)\n- Result: Original bug persists, NEW bug in onboarding, 2 issues instead of 1\n\n**Discovery would have revealed:** Transaction component owns the validation now.\n\n### Consequence 2: The Multiple Round-Trip Effect\n**Scenario:** Grep for location  Answer question  User asks follow-up  Grep again  Another follow-up\n\n**Example:**\n- Q1: \"Where is validation?\"  Grep  Answer: `validation.go:45`\n- Q2: \"How does it integrate?\"  Read files  Answer: \"Called from use case\"\n- Q3: \"What else validates?\"  Grep again  Answer: \"Assert package + HTTP layer\"\n- **Total: 3 round trips, 15 minutes, incomplete mental model**\n\n**Exploration would have provided:** All answers in one comprehensive document, 10 minutes total.\n\n### Consequence 3: The Stale Knowledge Effect\n**Scenario:** \"I already know\"  Work based on old mental model  Code has changed  Wrong implementation\n\n**Example:**\n- Your knowledge: \"3 components (onboarding, transaction, crm)\"\n- Reality: New `audit` component added last month for compliance\n- Your fix: Modify account creation in onboarding\n- Missing: Audit component now logs all account operations\n- Result: Account created but not audited, compliance violation\n\n**Discovery would have revealed:** 4 components now, audit is mandatory.\n\n### Consequence 4: The Hidden Dependencies Effect\n**Scenario:** Skip discovery  Miss shared libraries  Duplicate code  Technical debt\n\n**Example:**\n- Task: Add account validation rule\n- Grep finds: `create-account.go` has validation\n- You add: New validation in same file\n- Discovery would reveal: `pkg/validator/account.go` has shared validation library\n- Result: Duplicate logic, inconsistent validation across codebase\n\n**Discovery would have revealed:** Centralized validation library for reuse.\n\n### Cost Summary Table\n\n| Skip Reason | Time \"Saved\" | Actual Cost | Net Loss |\n|-------------|--------------|-------------|----------|\n| \"I already know\" | 6-10 min | 2+ hours debugging stale knowledge | -110 to -114 min |\n| \"Simple question\" | 6-10 min | 3 round trips  5 min each = 15 min | -5 to -9 min |\n| \"Production emergency\" | 6-10 min | Wrong fix + cascade = 2+ hours | -110 to -114 min |\n| \"Colleague told me\" | 6-10 min | Missing component/library = 1+ hour rework | -50 to -54 min |\n\n**Pattern:** Every \"time-saving\" skip costs more time than it saves.**\n\n## The Two-Phase Flow\n\n### Phase 1: Discovery Pass (Meta-Exploration)\n**Goal:** Understand \"What IS this codebase?\"\n\nLaunch 3-4 **discovery agents** to identify:\n- Architecture pattern (hexagonal, layered, microservices, etc.)\n- Major components/modules\n- Natural boundaries and layers\n- Organization principles\n- Key technologies and frameworks\n\n**Output:** Structural map of the codebase\n\n### Phase 2: Deep Dive Pass (Adaptive Exploration)\n**Goal:** Understand \"How does [target] work in each discovered area?\"\n\nBased on Phase 1 discoveries, launch **N targeted explorers** (where N adapts):\n- One explorer per discovered perspective/component/layer\n- Each explorer focuses on the target within their scope\n- Number and type of explorers match codebase structure\n\n**Output:** Comprehensive understanding of target across all perspectives\n\n## When to Use\n\n**Decision flow:**\n- Need codebase understanding?  Is it trivial (single file/function)?  Yes = Use Read/Grep directly\n- No  Is it unfamiliar territory or spans multiple areas?  Yes = **Two-phase exploration**\n- Are you about to make changes spanning multiple components?  Yes = **Two-phase exploration**\n\n**Use when:**\n- Understanding how a feature works in an unfamiliar codebase\n- Starting work on new component/service\n- Planning architectural changes\n- Need to find where to implement new functionality\n- User asks \"how does X work?\" for complex X in unknown codebase\n\n**Don't use when:**\n- Pure reference lookup: \"What's the signature of function X?\"\n- File existence check: \"Does utils.go exist?\"\n- Reading known error location: \"Show me line 45 of errors.go\"\n\n**COMMON TRAPS - These SEEM like valid skip reasons but are NOT:**\n\n###  Trap 1: \"Simple Question About Location\"\n**Rationalization:** \"User just asked 'where is X?' - grep is faster\"\n\n**Reality:** Location questions lead to \"how does X work?\" next\n- Question: \"Where is validation logic?\"\n- Grep answer: `validation.go:45`\n- Follow-up: \"How does it integrate with the system?\"\n- Follow-up: \"What else validates this?\"\n- **Result:** 3 questions, incomplete picture, wasted time\n\n**Counter:** Run exploration once, answer current + future questions.\n\n###  Trap 2: \"I Already Know the Architecture\"\n**Rationalization:** \"I worked here before, discovery is redundant\"\n\n**Reality:** Prior knowledge is dangerously incomplete\n- You know high-level (components exist)\n- You don't know details (how they're wired, what changed)\n- Assumptions about \"known\" code cause most bugs\n\n**Counter:** Discovery validates assumptions and reveals what changed.\n\n###  Trap 3: \"Production Emergency, No Time\"\n**Rationalization:** \"Production is down, skip the process\"\n\n**Reality:** High stakes demand MORE rigor, not less\n- 6-10 min discovery prevents hours of wrong assumptions\n- Production bugs from incomplete context cost >> discovery time\n- \"I know where to look\" under stress = peak Dunning-Kruger\n\n**Counter:** See \"When Pressure is Highest\" section below.\n\n###  Trap 4: \"Colleague Told Me Structure\"\n**Rationalization:** \"They said '3 microservices', why rediscover?\"\n\n**Reality:** High-level descriptions miss critical details\n- \"3 microservices\" doesn't mention shared libraries, background jobs, API gateways\n- Mental models are abstractions, not complete maps\n- People forget to mention \"obvious\" infrastructure\n\n**Counter:** Use colleague info as validation context, not replacement for discovery.\n\n## When Pressure is Highest, Use Skill Most\n\n**CRITICAL INSIGHT: Production emergencies DEMAND systematic understanding.**\n\n### The Emergency Trap\n\n**False logic:** \"Production down  Skip process  Fix faster\"\n**True logic:** \"Production down  Need accuracy  Use systematic approach\"\n\n### Why Discovery Matters MORE Under Pressure\n\n| Shortcut Path | Systematic Path |\n|---------------|-----------------|\n| Grep \"CreateAccount\" (30 sec) | Run two-phase exploration (6-10 min) |\n| Read 2-3 files (2 min) | Get complete architecture + target impl |\n| Make assumption-based fix (10 min) | Fix with full context (5 min) |\n| Fix breaks something else (2 hours) | Fix correct first time |\n| **Total: 2+ hours + new bugs** | **Total: 15-20 minutes, done right** |\n\n### The \"Surgeon Textbook\" Analogy is Wrong\n\n**Bad analogy:** \"Surgeon doesn't read textbook while patient bleeds\"\n**Correct analogy:** \"Surgeon checks vitals before operating\"\n\nDiscovery is NOT reading theory - it's gathering critical context:\n-  Discovery = Checking patient vitals (essential context)\n-  Reading textbooks = Reading unnecessary theory\n\n**You wouldn't skip vitals because \"emergency\" - same principle applies here.**\n\n### Production Emergency Protocol\n\nWhen production is down:\n\n1. **Acknowledge the pressure** - \"This is urgent, I feel pressure to skip discovery\"\n2. **Recognize the trap** - \"That pressure is EXACTLY when I need systematic approach\"\n3. **Invest 6-10 minutes** - Run two-phase exploration\n4. **Fix with confidence** - Full context prevents cascading failures\n\n**Reality check:** If you don't have 6-10 minutes for discovery, you don't have 2+ hours to undo wrong fixes.\n\n## Real vs False Pragmatism\n\n### False Pragmatism (Shortcuts that Backfire)\n\n| Shortcut | Seems Pragmatic | Actual Result |\n|----------|-----------------|---------------|\n| \"Skip discovery, I already know\" | Saves 6-10 min | Hours debugging wrong assumptions |\n| \"Grep for simple questions\" | Faster than exploration | Multiple follow-up questions, incomplete picture |\n| \"Production emergency, no process\" | Fixes faster | Wrong fix, breaks more things |\n| \"Colleague told me structure\" | Use existing knowledge | Miss shared libs, background jobs, actual impl |\n\n### Real Pragmatism (Invest to Save)\n\n| Systematic Approach | Costs | Saves |\n|---------------------|-------|-------|\n| 6-10 min two-phase exploration | 6-10 minutes | Hours of debugging wrong assumptions |\n| Complete understanding first | Discovery time | Multiple follow-up questions |\n| Systematic under pressure | Feeling \"slow\" | Fixing wrong thing, cascading failures |\n| Validate colleague's mental model | Discovery vs assumption | Missing critical infrastructure |\n\n**Real pragmatism = Doing it right when stakes are high.**\n\n**False pragmatism = Taking shortcuts that create bigger problems.**\n\n### When Pragmatism Tells You to Skip...\n\nIf you think \"being pragmatic means skipping this,\" ask:\n\n1. **Am I conflating \"fast\" with \"good\"?** Speed without accuracy is just fast failure.\n2. **Am I optimizing for feeling productive?** Grep gives quick dopamine, but incomplete understanding.\n3. **Am I making excuses under pressure?** High stakes demand MORE rigor, not less.\n4. **Am I assuming I know more than I do?** Dunning-Kruger peaks under stress.\n\n**If you answered yes to any: Use the skill anyway.**\n\n## Rationalization Table\n\nWhen you're tempted to skip the skill, check this table:\n\n| Rationalization | Why It Feels Right | Why It's Wrong | Counter |\n|-----------------|--------------------|-----------------|---------|\n| **\"I already know the architecture\"** | You worked here before | Prior knowledge is high-level abstractions | Discovery reveals what you don't know to ask |\n| **\"Simple question, grep is faster\"** | Just need a file location | Leads to follow-ups, incomplete picture | One exploration answers current + future questions |\n| **\"Production emergency, no time\"** | Every second counts | Wrong fix wastes hours, creates new bugs | 6-10 min discovery prevents hours of wrong assumptions |\n| **\"Colleague told me the structure\"** | They work here, they'd know | Mental models miss details (shared libs, jobs) | Use as validation context, not replacement |\n| **\"Being pragmatic not dogmatic\"** | Process shouldn't be rigid | Shortcuts under pressure cause bigger problems | Real pragmatism = right approach when stakes high |\n| **\"Match tool to scope\"** | Simple task = simple tool | Context-free answer requires follow-ups | Comprehensive once > multiple partial searches |\n| **\"Skip discovery to save time\"** | 3-5 min vs 6-10 min | Saving 5 min, losing hours on wrong assumptions | False economy - incomplete understanding compounds |\n| **\"Progressive investigation works\"** | Start narrow, expand if stuck | Ad-hoc misses systematic patterns | Discovery first prevents getting stuck |\n\n## Process\n\nCopy this checklist to track progress:\n\n```\nTwo-Phase Exploration Progress:\n- [ ] Phase 0: Scope Definition (exploration target identified)\n- [ ] Phase 1: Discovery Pass (structure discovered - 3-4 agents)\n- [ ] Phase 2: Deep Dive Pass (N adaptive explorers launched)\n- [ ] Phase 3: Result Collection (all agents completed)\n- [ ] Phase 4: Synthesis (discovery + deep dive integrated)\n- [ ] Phase 5: Action Recommendations (next steps identified)\n```\n\n## Phase 0: Scope Definition\n\n**Step 0.1: Identify Exploration Target**\n\nFrom user request, extract:\n- **Core subject:** What feature/system/component to explore?\n- **Context clue:** Why are they asking? (planning change, debugging, learning)\n- **Depth needed:** Surface understanding or comprehensive dive?\n\n**Step 0.2: Set Exploration Boundaries**\n\nDefine scope to keep agents focused:\n- **Include:** Directories/components relevant to target\n- **Exclude:** Build config, vendor code, generated files (unless specifically needed)\n- **Target specificity:** \"account creation\" vs \"entire onboarding service\"\n\n## Phase 1: Discovery Pass (Meta-Exploration)\n\n**Goal:** Discover the natural structure of THIS codebase\n\n**Step 1.1: Launch Discovery Agents in Parallel**\n\n**CRITICAL: Single message with 3-4 Task tool calls**\n\nDispatch discovery agents simultaneously:\n\n```\nTask(subagent_type=\"Explore\", description=\"Architecture discovery\",\n     prompt=\"[Architecture Discovery prompt]\")\n\nTask(subagent_type=\"Explore\", description=\"Component discovery\",\n     prompt=\"[Component Discovery prompt]\")\n\nTask(subagent_type=\"Explore\", description=\"Layer discovery\",\n     prompt=\"[Layer Discovery prompt]\")\n\nTask(subagent_type=\"Explore\", description=\"Organization discovery\",\n     prompt=\"[Organization Discovery prompt]\")\n```\n\nSee **Discovery Agent Prompts** section below for templates.\n\n**Step 1.2: Collect Discovery Results**\n\nWait for all discovery agents to complete. Extract from results:\n\n**Structural Elements:**\n- Architecture pattern(s) used\n- List of major components/services\n- Layers within components (if applicable)\n- Directory organization principle\n- Technology stack per component\n\n**Perspective Matrix:**\nCreate a matrix of discovered perspectives:\n```\nComponents: [A, B, C]\nLayers (per component): [HTTP, UseCase, Repository, Domain]\nBoundaries: [Component boundaries, Layer boundaries]\nOrganization: [By feature, By layer, By domain]\n```\n\n**Step 1.3: Determine Deep Dive Strategy**\n\nBased on discoveries, decide exploration approach:\n\n| Discovery Result | Deep Dive Strategy |\n|------------------|-------------------|\n| 3 components  4 layers | Launch 3 explorers (one per component) |\n| Single component, clear layers | Launch 4 explorers (one per layer) |\n| Microservices architecture | Launch N explorers (one per service) |\n| Monolith by feature | Launch explorers per major feature |\n| Mix of patterns | Adaptive: explore each unique area |\n\n**Step 1.4: Validate Discovery Quality**\n\n **Quality checks:**\n- [ ] Architecture pattern clearly identified\n- [ ] Major components/modules enumerated\n- [ ] Boundaries and layers documented\n- [ ] File paths provided as evidence\n- [ ] No major \"unknown\" areas remaining\n\nIf quality insufficient: Re-run specific discovery agents with refined prompts.\n\n## Phase 2: Deep Dive Pass (Adaptive Exploration)\n\n**Goal:** Explore target within each discovered perspective\n\n**Step 2.1: Generate Adaptive Prompts**\n\nFor each discovered perspective, create a targeted prompt:\n\n**Template structure:**\n```\nExplore [TARGET] in [DISCOVERED_COMPONENT/LAYER].\n\nContext from discovery:\n- This is the [COMPONENT_NAME] which handles [RESPONSIBILITY]\n- Architecture: [PATTERN]\n- Location: [DIRECTORY_PATHS]\n- Related components: [DEPENDENCIES]\n\nTask:\n1. Find how [TARGET] is implemented in this area\n2. Trace execution flow within this scope\n3. Identify key files and functions (with file:line references)\n4. Document patterns and conventions used\n5. Note integration points with other areas\n\nBoundaries:\n- Stay within [DIRECTORY_SCOPE]\n- Maximum depth: [BASED_ON_LAYER]\n- Focus on [TARGET] specifically\n\nOutput format: [Structured report with file:line references]\n```\n\n**Step 2.2: Dispatch Adaptive Explorers in Parallel**\n\n**CRITICAL: Single message with N Task tool calls** (N = number of discovered perspectives)\n\nExample for 3-component system:\n```\nTask(subagent_type=\"Explore\", description=\"Explore target in Component A\",\n     prompt=\"[Adaptive prompt for Component A]\")\n\nTask(subagent_type=\"Explore\", description=\"Explore target in Component B\",\n     prompt=\"[Adaptive prompt for Component B]\")\n\nTask(subagent_type=\"Explore\", description=\"Explore target in Component C\",\n     prompt=\"[Adaptive prompt for Component C]\")\n```\n\n**Agent Configuration:**\n- **subagent_type:** `Explore` (fast agent specialized for codebase exploration)\n- **model:** `haiku` (fast, cost-effective)\n- **run_in_background:** No (await results for synthesis)\n\n**Step 2.3: Await All Deep Dive Agents**\n\nBlock until all N agents complete. Do not proceed with partial results.\n\n## Phase 3: Result Collection\n\n**Step 3.1: Organize Findings**\n\nSeparate results into two buckets:\n\n**Discovery Results (from Phase 1):**\n- Architecture map\n- Component catalog\n- Layer definitions\n- Organization principles\n\n**Deep Dive Results (from Phase 2):**\n- Per-perspective exploration reports\n- File:line references for target\n- Patterns observed in each area\n- Integration points discovered\n\n**Step 3.2: Quality Check Deep Dives**\n\nFor each deep dive agent result:\n-  Check completeness (did it find the target?)\n-  Verify file:line references provided\n-  Confirm it stayed within scope\n-  Note gaps (\"target not found in this area\" is valid)\n-  Identify conflicts between areas\n\n**Step 3.3: Cross-Reference Discovery vs Deep Dive**\n\nValidate that deep dives align with discovered structure:\n- Do findings match the architecture pattern?\n- Are all discovered components covered?\n- Are there surprises (things not in discovery)?\n\nIf major misalignment: Investigation needed (discovery was incomplete or incorrect).\n\n## Phase 4: Synthesis\n\n**Step 4.1: Integrate Discovery + Deep Dive**\n\nCreate unified understanding by layering deep dives onto discovery:\n\n**Integration process:**\n1. Start with structural map (from Phase 1)\n2. Overlay target implementation (from Phase 2 per area)\n3. Identify how target flows across discovered boundaries\n4. Document patterns consistent across areas\n5. Highlight variations between areas\n\n**Step 4.2: Create Synthesis Document**\n\n**Output format:**\n\n```markdown\n# Autonomous Codebase Exploration: [Target]\n\n## Executive Summary\n[2-3 sentences: architecture + how target works]\n\n---\n\n## Phase 1: Discovery Findings\n\n### Architecture Pattern\n[Pattern name with evidence]\n\n### Component Structure\n[Components discovered with responsibilities]\n\n### Layer Organization\n[Layers identified with boundaries]\n\n### Technology Stack\n[Key technologies per area]\n\n### Structural Diagram\n[ASCII/markdown diagram of discovered structure]\n\n---\n\n## Phase 2: Deep Dive Findings\n\n### [Discovered Area 1 - e.g., \"Onboarding Component\"]\n**Scope:** `components/onboarding/`\n**Target Implementation:**\n- Entry point: `path/to/file.ext:line`\n- Flow: [step-by-step with file:line references]\n- Patterns: [patterns observed]\n- Integration: [how it connects to other areas]\n\n### [Discovered Area 2 - e.g., \"Transaction Component\"]\n**Scope:** `components/transaction/`\n**Target Implementation:**\n- Entry point: `path/to/file.ext:line`\n- Flow: [step-by-step with file:line references]\n- Patterns: [patterns observed]\n- Integration: [how it connects to other areas]\n\n[... repeat for each discovered area ...]\n\n---\n\n## Cross-Cutting Insights\n\n### Pattern Consistency\n[Where patterns are consistent across areas]\n\n### Pattern Variations\n[Where implementation differs and why]\n\n### Integration Points\n[How discovered areas interact for target]\n\n### Data Flow\n[How data flows across boundaries]\n\n### Key Design Decisions\n[Architectural choices evident from exploration]\n\n---\n\n## Implementation Guidance\n\n### For Adding New Functionality\n**Where to add code:**\n- In [Component]: `path/to/directory/`\n- In [Layer]: Follow pattern from `example/file.ext:line`\n\n**Patterns to follow:**\n- [Pattern 1] as seen in `file.ext:line`\n- [Pattern 2] as seen in `file.ext:line`\n\n**Integration requirements:**\n- Connect to [Component A] via [interface]\n- Update [Component B] to handle [scenario]\n\n### For Modifying Existing Functionality\n**Files to change:**\n- Primary: `path/file.ext:line`\n- Secondary impacts: `path/file2.ext:line`\n\n**Ripple effects:**\n- Changes in [Component A] require updates in [Component B]\n\n### For Debugging\n**Start investigation in:**\n- [Component/Layer]: `path/file.ext:line`\n\n**Data inspection points:**\n- [Layer 1]: `file.ext:line` - [what to check]\n- [Layer 2]: `file.ext:line` - [what to check]\n\n**Common failure points:**\n- [Area identified from cross-cutting analysis]\n\n---\n\n## Appendix: Discovery Evidence\n\n[File:line references supporting structural discoveries]\n```\n\n**Step 4.3: Validate Synthesis**\n\n **Completeness check:**\n- [ ] Both Phase 1 and Phase 2 integrated\n- [ ] All discovered areas covered in deep dive\n- [ ] Cross-cutting insights identified\n- [ ] Implementation guidance specific and actionable\n\n## Phase 5: Action Recommendations\n\nBased on synthesis, provide context-aware next steps:\n\n**If user's goal is implementation:**\n```\nBased on autonomous exploration:\n\n**Codebase Structure:**\n- Architecture: [Discovered pattern]\n- Components: [List with responsibilities]\n\n**To implement [TARGET]:**\n1. Add new code in: [Component/Layer] at `path/`\n2. Follow pattern: [Pattern name] from `file.ext:line`\n3. Integrate with: [Other components] via [mechanism]\n4. Test using: [Test pattern discovered]\n\n**Critical files to understand:**\n- `file1.ext:line` - [why important]\n- `file2.ext:line` - [why important]\n\nReady to create implementation plan? (Use /write-plan)\n```\n\n**If user's goal is debugging:**\n```\nBased on autonomous exploration:\n\n**Investigation starting points:**\n- [Component A]: `file.ext:line` - [what to check]\n- [Component B]: `file.ext:line` - [what to check]\n\n**Data flow for [TARGET]:**\n[Origin]  [Transform 1]  [Validation]  [Destination]\n\n**Common failure modes:**\n- [Pattern from cross-cutting analysis]\n\nReady to investigate systematically? (Use systematic-debugging)\n```\n\n**If user's goal is learning:**\n```\nBased on autonomous exploration:\n\n**Codebase organization:**\n- [Discovered architecture pattern]\n- [N components] with [responsibilities]\n\n**Reading path for [TARGET]:**\n1. Start: `file1.ext:line` - [entry point]\n2. Then: `file2.ext:line` - [core logic]\n3. Finally: `file3.ext:line` - [persistence/output]\n\n**Key patterns to understand:**\n- [Pattern 1]: Explained in `file.ext:line`\n- [Pattern 2]: Explained in `file.ext:line`\n\n**Related areas to explore next:**\n- [Connection found during exploration]\n```\n\n## Discovery Agent Prompts\n\n### Template: Architecture Discovery Agent\n\n```markdown\n**Goal:** Discover the architecture pattern(s) used in this codebase.\n\n**Scope:** Entire codebase (focus on [TARGET_AREA if specified])\n\n**Task:**\n1. Examine directory structure at top level\n2. Identify architectural pattern(s):\n   - Hexagonal (Ports & Adapters)?\n   - Layered (N-tier)?\n   - Microservices?\n   - Monolith (modular or big ball)?\n   - Clean Architecture?\n   - MVC/MVVM?\n   - Event-driven?\n   - Other or mixed?\n3. Document evidence for pattern identification:\n   - Directory names suggesting layers/boundaries\n   - Presence of \"adapters\", \"ports\", \"domain\", \"infrastructure\"\n   - Service separation or monolithic structure\n4. Note if multiple patterns coexist (e.g., hexagonal within each microservice)\n\n**Evidence to collect:**\n- Directory structure (top 2-3 levels)\n- Key directory names that indicate architecture\n- Example file paths showing layer separation\n- README or docs mentioning architecture\n\n**Output format:**\n```\n## Architecture Discovery\n\n### Primary Pattern: [Pattern Name]\n**Evidence:**\n- Directory structure shows: [what indicates this pattern]\n- Example paths:\n  - `path/to/adapter/` - [adapter layer]\n  - `path/to/domain/` - [domain layer]\n  - `path/to/infrastructure/` - [infrastructure layer]\n\n### Confidence: [High/Medium/Low]\n[Explain confidence level]\n\n### Secondary Patterns: [If any]\n[Any mixed or nested patterns]\n\n### Architectural Diagram:\n```\n[ASCII diagram of discovered architecture]\n```\n\n### Key Insights:\n- [Any notable architectural decisions or trade-offs visible]\n```\n```\n\n### Template: Component Discovery Agent\n\n```markdown\n**Goal:** Identify all major components/modules/services in the codebase.\n\n**Scope:** Entire codebase (focus on [TARGET_AREA if specified])\n\n**Task:**\n1. Identify major components:\n   - By directory (e.g., `services/`, `components/`, `modules/`)\n   - By responsibility (what each component does)\n   - By deployment unit (if microservices)\n2. For each component, document:\n   - Name and location (directory path)\n   - Primary responsibility (one sentence)\n   - Key technologies used (language, framework)\n   - Size/scope (small, medium, large)\n3. Map dependencies between components:\n   - Which components depend on which?\n   - Are dependencies clean or tangled?\n4. Identify shared libraries or common code\n\n**Evidence to collect:**\n- List of top-level directories\n- README files describing components\n- Import/dependency patterns\n- Package.json, go.mod, or similar dependency files\n\n**Output format:**\n```\n## Component Discovery\n\n### Components Identified: [N]\n\n#### Component 1: [Name]\n- **Location:** `path/to/component/`\n- **Responsibility:** [One sentence]\n- **Technology:** [Language + framework]\n- **Size:** [Lines of code or file count]\n- **Key entry points:**\n  - `file1.ext` - [purpose]\n  - `file2.ext` - [purpose]\n\n#### Component 2: [Name]\n[... same structure ...]\n\n### Dependency Map:\n```\n[Component A]  [Component B]\n               [Shared Lib]\n[Component B]  [Shared Lib]\n[Component C]  [Component A]\n               [Shared Lib]\n```\n\n### Shared Libraries:\n- `lib/common/` - [what it provides]\n- `pkg/utils/` - [what it provides]\n\n### Dependency Health:\n Clean: [Examples]\n Tangled: [Examples of circular or unclear dependencies]\n```\n```\n\n### Template: Layer Discovery Agent\n\n```markdown\n**Goal:** Discover layers/boundaries within components.\n\n**Scope:** [Specific component if multi-component, else entire codebase]\n\n**Task:**\n1. Within each component, identify layers:\n   - Presentation/API layer (HTTP handlers, controllers, etc.)\n   - Business logic layer (use cases, services, domain)\n   - Data access layer (repositories, database)\n   - Infrastructure layer (external integrations)\n2. Document how layers are separated:\n   - By directory?\n   - By naming convention?\n   - By file organization?\n3. Check for layer violations:\n   - Does presentation layer directly access database?\n   - Does business logic depend on infrastructure?\n4. Identify patterns used for layer communication:\n   - Dependency injection?\n   - Interfaces/abstractions?\n   - Direct coupling?\n\n**Evidence to collect:**\n- Directory structure showing layer separation\n- File naming conventions indicating layer\n- Import patterns (what imports what)\n- Interface/abstraction usage\n\n**Output format:**\n```\n## Layer Discovery\n\n### Component: [Name]\n\n#### Layers Identified:\n\n##### Layer 1: [Name - e.g., \"HTTP/API Layer\"]\n- **Location:** `path/to/layer/`\n- **Responsibility:** [What it does]\n- **Key files:**\n  - `file1.ext` - [purpose]\n  - `file2.ext` - [purpose]\n- **Dependencies:** [What it depends on]\n\n##### Layer 2: [Name - e.g., \"Business Logic\"]\n[... same structure ...]\n\n##### Layer 3: [Name - e.g., \"Data Access\"]\n[... same structure ...]\n\n### Layer Communication Pattern:\n[How layers interact - interfaces, DI, direct calls, etc.]\n\n### Layer Diagram:\n```\n\n   HTTP/API Layer    \n\n          \n\n   Business Logic    \n\n          \n\n   Data Access       \n\n```\n\n### Layer Health:\n Clean separation: [Evidence]\n Violations found: [Examples with file:line]\n\n### Repeat for other components if multi-component system\n```\n```\n\n### Template: Organization Discovery Agent\n\n```markdown\n**Goal:** Understand the organizing principle of this codebase.\n\n**Scope:** Entire codebase\n\n**Task:**\n1. Identify primary organization principle:\n   - By layer (all controllers together, all models together)\n   - By feature (each feature has its own directory with all layers)\n   - By domain (organized around business domains)\n   - By component type (frontend, backend, shared)\n   - Mixed or unclear\n2. Document file naming conventions:\n   - kebab-case, snake_case, camelCase?\n   - Suffixes or prefixes? (e.g., `UserController`, `user.controller.ts`)\n3. Identify test organization:\n   - Co-located with source?\n   - Separate test directory?\n   - Naming convention for tests?\n4. Note configuration and build setup:\n   - Where are config files?\n   - Build tool used?\n   - Environment-specific configs?\n\n**Evidence to collect:**\n- Directory structure examples\n- File naming examples\n- Test file locations\n- Config file locations\n\n**Output format:**\n```\n## Organization Discovery\n\n### Primary Organization: [Principle Name]\n**Evidence:**\n- Feature X has all its files in: `path/to/feature/`\n- OR: Controllers are all in: `path/controllers/`, Models in: `path/models/`\n\n**Example structure:**\n```\n[Show representative directory tree]\n```\n\n### File Naming Convention:\n- **Style:** [kebab-case, snake_case, camelCase, etc.]\n- **Pattern:** [Describe pattern]\n- **Examples:**\n  - `example-file-1.ext`\n  - `example-file-2.ext`\n\n### Test Organization:\n- **Location:** [Co-located or separate]\n- **Pattern:** `*.test.ext`, `*_test.ext`, `test/*`, etc.\n- **Examples:**\n  - Source: `src/service.ts`\n  - Test: `src/service.test.ts`\n\n### Configuration:\n- **Location:** `path/to/configs/`\n- **Environment handling:** [How envs are managed]\n- **Build tool:** [Make, npm, cargo, etc.]\n\n### Key Insights:\n- [Notable organizational choices]\n- [Any inconsistencies or legacy patterns]\n```\n```\n\n## Deep Dive Agent Prompts\n\n### Template: Adaptive Deep Dive Agent\n\n```markdown\n**Goal:** Explore [TARGET] within [DISCOVERED_PERSPECTIVE].\n\n**Context from Discovery Phase:**\n- **Architecture:** [Discovered pattern]\n- **This area is:** [Component/Layer/Module name]\n- **Responsibility:** [What this area handles]\n- **Location:** [Directory paths]\n- **Technologies:** [Stack for this area]\n- **Related areas:** [Dependencies/connections]\n\n**Task:**\n1. **Find [TARGET] in this area:**\n   - Search for relevant files containing [TARGET] implementation\n   - Identify entry points (APIs, handlers, functions)\n   - Document with file:line references\n\n2. **Trace execution flow:**\n   - Follow [TARGET] through this area's layers/components\n   - Document each step with file:line\n   - Note data transformations\n   - Identify validation/error handling\n\n3. **Document patterns:**\n   - What patterns are used in this area for [TARGET]?\n   - Error handling approach\n   - Testing approach\n   - Integration approach with other areas\n\n4. **Identify integration points:**\n   - How does this area connect to others for [TARGET]?\n   - What interfaces/APIs are used?\n   - What data is passed between areas?\n\n**Boundaries:**\n- **Stay within:** [Directory scope for this perspective]\n- **Maximum depth:** [Based on layer - don't trace into frameworks]\n- **Focus:** [TARGET] specifically (don't document unrelated code)\n\n**Output Format:**\n```\n## Deep Dive: [TARGET] in [PERSPECTIVE_NAME]\n\n### Overview\n[2-3 sentences about how [TARGET] works in this area]\n\n### Entry Points\n**File:** `path/to/file.ext:line`\n**Function/Handler:** `functionName`\n**Triggered by:** [API call, event, function call, etc.]\n\n### Execution Flow\n\n#### Step 1: [Layer/Stage Name]\n- **File:** `path/to/file.ext:line`\n- **What happens:** [Description]\n- **Key code:**\n  ```[language]\n  [Relevant snippet if helpful]\n  ```\n\n#### Step 2: [Next Layer/Stage]\n[... same structure ...]\n\n[... repeat for all steps ...]\n\n### Data Transformations\n- **Input format:** [Describe]\n- **Transform 1:** At `file.ext:line` - [what changes]\n- **Transform 2:** At `file.ext:line` - [what changes]\n- **Output format:** [Describe]\n\n### Patterns Observed\n- **Error handling:** [Approach with example]\n- **Validation:** [Where and how]\n- **Testing:** [Test patterns if visible]\n- **Integration:** [How it connects to other areas]\n\n### Integration Points\n\n#### Outbound: Calls to Other Areas\n- **To [Area X]:** Via `interface/api` at `file.ext:line`\n  - Purpose: [Why]\n  - Data passed: [What]\n\n#### Inbound: Called by Other Areas\n- **From [Area Y]:** Via `interface/api` at `file.ext:line`\n  - Purpose: [Why]\n  - Data received: [What]\n\n### Key Files for [TARGET]\n1. `path/file1.ext:line` - [Primary implementation]\n2. `path/file2.ext:line` - [Secondary/helper]\n3. `path/file3.ext:line` - [Integration point]\n\n### Notes\n- [Any discoveries not fitting above categories]\n- [Gaps: \"Could not find X in this area\"]\n- [Surprises: \"Unexpected implementation choice\"]\n```\n```\n\n## Common Mistakes\n\n|  Bad |  Good |\n|--------|---------|\n| Skip discovery, assume structure | Always run Phase 1 discovery first |\n| Use same deep dive agents for all codebases | Adapt Phase 2 agents based on Phase 1 |\n| Accept vague discoveries | Require file:line evidence |\n| Run explorers sequentially | Dispatch all in parallel (per phase) |\n| Skip synthesis step | Always integrate discovery + deep dive |\n| Provide raw dumps | Synthesize into actionable guidance |\n| Use for single file lookup | Use Read/Grep instead |\n\n## Integration with Other Skills\n\n| Skill | When to use together |\n|-------|----------------------|\n| **brainstorming** | Use exploring-codebase in Phase 1 (Understanding) to gather context |\n| **writing-plans** | Use exploring-codebase before creating implementation plans |\n| **executing-plans** | Use exploring-codebase if plan execution reveals gaps |\n| **systematic-debugging** | Use exploring-codebase to understand system before debugging |\n| **dispatching-parallel-agents** | This skill is built on that pattern (twice!) |\n\n## Output Format\n\nWhen skill completes, provide:\n\n### 1. Synthesis Document\n[As defined in Phase 4.2 - includes both discovery and deep dive]\n\n### 2. Structural Insights\n```\n**Discovered Architecture:**\n- Pattern: [Name]\n- Components: [List]\n- Layers: [List]\n- Organization: [Principle]\n\n**[TARGET] Implementation:**\n- Present in: [N components/layers]\n- Entry points: [List with file:line]\n- Integration: [How areas connect]\n- Patterns: [Consistent patterns observed]\n```\n\n### 3. Next Step Recommendations\n[As defined in Phase 5 - context-aware based on user goal]\n\n## Verification\n\nAfter completing exploration:\n\n **Phase 1 (Discovery) completeness:**\n- [ ] Architecture pattern identified with evidence\n- [ ] All major components/modules enumerated\n- [ ] Layers/boundaries documented\n- [ ] Organization principle clear\n- [ ] File:line references for structural elements\n\n **Phase 2 (Deep Dive) completeness:**\n- [ ] All discovered perspectives explored\n- [ ] [TARGET] found and documented in each area\n- [ ] Execution flows traced with file:line\n- [ ] Integration points identified\n- [ ] Patterns documented per area\n\n **Synthesis quality:**\n- [ ] Discovery and deep dive integrated\n- [ ] Cross-cutting insights identified\n- [ ] Inconsistencies explained\n- [ ] Implementation guidance specific\n- [ ] Next steps clear and actionable\n\n## Adaptive Examples\n\n### Example 1: Microservices Architecture\n\n**Phase 1 Discovery finds:**\n- 5 microservices (Auth, User, Order, Payment, Notification)\n- Each service is independent\n- Event-driven communication via message bus\n\n**Phase 2 adapts:**\n- Launch 5 deep dive agents (one per service)\n- Each explores target within their service\n- Focus on event publishing/subscribing for integration\n\n### Example 2: Monolithic Hexagonal Architecture\n\n**Phase 1 Discovery finds:**\n- Single application\n- Hexagonal architecture (adapters + domain)\n- 4 layers: HTTP  Application  Domain  Infrastructure\n\n**Phase 2 adapts:**\n- Launch 4 deep dive agents (one per layer)\n- Each explores target within their layer\n- Focus on dependency inversion at boundaries\n\n### Example 3: Feature-Organized Monolith\n\n**Phase 1 Discovery finds:**\n- Features organized in separate directories\n- Each feature has its own layers\n- 6 major features identified\n\n**Phase 2 adapts:**\n- Launch 6 deep dive agents (one per feature)\n- Each explores target within their feature\n- Focus on shared code and cross-feature integration\n\n## Key Principles\n\n| Principle | Application |\n|-----------|-------------|\n| **Discover, then dive** | Phase 1 discovery informs Phase 2 exploration |\n| **Adaptive parallelization** | Number and type of agents matches structure |\n| **Evidence-based** | All discoveries backed by file:line references |\n| **Autonomous** | Codebase reveals its own structure |\n| **Synthesis required** | Raw outputs must be integrated |\n| **Action-oriented** | Always end with next steps |\n| **Quality gates** | Verify each phase before proceeding |\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **TodoWrite:** See `skills/shared-patterns/todowrite-integration.md`\n\nApply ALL patterns when using this skill.\n\n## Notes\n\n- **Performance:** Two phases complete faster than naive sequential exploration\n- **Cost:** Uses `haiku` model (cost-effective for exploration)\n- **Adaptability:** Works for any architecture (hexagonal, microservices, MVC, etc.)\n- **Scalability:** Handles codebases from small (2-3 components) to large (10+ services)\n- **Reusability:** Synthesis documents serve as permanent reference"
              },
              {
                "name": "ring:finishing-a-development-branch",
                "description": "Branch completion workflow - guides merge/PR/cleanup decisions after implementation\nis verified complete.\n",
                "path": "default/skills/finishing-a-development-branch/SKILL.md",
                "frontmatter": {
                  "name": "ring:finishing-a-development-branch",
                  "description": "Branch completion workflow - guides merge/PR/cleanup decisions after implementation\nis verified complete.\n",
                  "trigger": "- Implementation complete (tests passing)\n- Ready to integrate work to main branch\n- Need to decide: merge, PR, or more work\n",
                  "skip_when": "- Tests not passing  fix first\n- Implementation incomplete  continue development\n- Already merged  proceed to next task\n",
                  "sequence": {
                    "after": [
                      "verification-before-completion",
                      "requesting-code-review"
                    ]
                  }
                },
                "content": "# Finishing a Development Branch\n\n## Overview\n\nGuide completion of development work by presenting clear options and handling chosen workflow.\n\n**Core principle:** Verify tests  Present options  Execute choice  Clean up.\n\n**Announce at start:** \"I'm using the finishing-a-development-branch skill to complete this work.\"\n\n## The Process\n\n### Step 1: Verify Tests\n\nRun `npm test / cargo test / pytest / go test ./...` **If tests fail:** Show failures, stop. Cannot proceed until tests pass.\n\n### Step 2: Determine Base Branch\n\n```bash\ngit merge-base HEAD main 2>/dev/null || git merge-base HEAD master 2>/dev/null\n```\n\n### Step 3: Present Options\n\nPresent exactly these 4 options (no explanation):\n1. Merge back to <base-branch> locally\n2. Push and create a Pull Request\n3. Keep the branch as-is (I'll handle it later)\n4. Discard this work\n\n### Step 4: Execute Choice\n\n| Option | Commands |\n|--------|----------|\n| **1. Merge Locally** | `git checkout <base>`  `git pull`  `git merge <feature>`  verify tests  `git branch -d <feature>`  Cleanup worktree |\n| **2. Create PR** | `git push -u origin <feature>`  `gh pr create --title \"...\" --body \"## Summary...\"`  Cleanup worktree |\n| **3. Keep As-Is** | Report: \"Keeping branch <name>. Worktree preserved at <path>.\" **Don't cleanup.** |\n| **4. Discard** | **Confirm first:** \"Type 'discard' to confirm.\"  `git checkout <base>`  `git branch -D <feature>`  Cleanup worktree |\n\n### Step 5: Cleanup Worktree\n\n**Options 1, 2, 4:** `git worktree list | grep $(git branch --show-current)`  if in worktree: `git worktree remove <path>`\n**Option 3:** Keep worktree.\n\n## Quick Reference\n\n| Option | Merge | Push | Keep Worktree | Cleanup Branch |\n|--------|-------|------|---------------|----------------|\n| 1. Merge locally |  | - | - |  |\n| 2. Create PR | - |  |  | - |\n| 3. Keep as-is | - | - |  | - |\n| 4. Discard | - | - | - |  (force) |\n\n## Common Mistakes\n\n| Mistake | Problem | Fix |\n|---------|---------|-----|\n| Skipping test verification | Merge broken code, create failing PR | Always verify tests before offering options |\n| Open-ended questions | \"What should I do next?\"  ambiguous | Present exactly 4 structured options |\n| Automatic worktree cleanup | Remove worktree when might need it | Only cleanup for Options 1 and 4 |\n| No confirmation for discard | Accidentally delete work | Require typed \"discard\" confirmation |\n\n## Red Flags\n\n**Never:**\n- Proceed with failing tests\n- Merge without verifying tests on result\n- Delete work without confirmation\n- Force-push without explicit request\n\n**Always:**\n- Verify tests before offering options\n- Present exactly 4 options\n- Get typed confirmation for Option 4\n- Clean up worktree for Options 1 & 4 only\n\n## Integration\n\n**Called by:**\n- **subagent-driven-development** (Step 7) - After all tasks complete\n- **executing-plans** (Step 5) - After all batches complete\n\n**Pairs with:**\n- **using-git-worktrees** - Cleans up worktree created by that skill"
              },
              {
                "name": "ring:handoff-tracking",
                "description": "Create detailed handoff documents for session transitions. Captures task status,\nlearnings, decisions, and next steps in a structured format that gets indexed\nfor future retrieval.\n",
                "path": "default/skills/handoff-tracking/SKILL.md",
                "frontmatter": {
                  "name": "ring:handoff-tracking",
                  "description": "Create detailed handoff documents for session transitions. Captures task status,\nlearnings, decisions, and next steps in a structured format that gets indexed\nfor future retrieval.\n",
                  "trigger": "- Session ending or transitioning\n- User runs /create-handoff command\n- Context pressure requiring /clear\n- Completing a major milestone\n",
                  "skip_when": "- Quick Q&A session with no implementation\n- No meaningful work to document\n- Session was exploratory with no decisions\n",
                  "related": {
                    "before": [
                      "executing-plans",
                      "subagent-driven-development"
                    ],
                    "after": [
                      "artifact-query"
                    ]
                  }
                },
                "content": "# Handoff Tracking\n\n## Overview\n\nCreate structured handoff documents that preserve session context for future sessions. Handoffs capture what was done, what worked, what failed, key decisions, and next steps.\n\n**Core principle:** Handoffs are indexed immediately on creation, making them searchable before the session ends.\n\n**Announce at start:** \"I'm creating a handoff document to preserve this session's context.\"\n\n## When to Create Handoffs\n\n| Situation | Action |\n|-----------|--------|\n| Session ending | ALWAYS create handoff |\n| Running /clear | Create handoff BEFORE clear |\n| Major milestone complete | Create handoff to checkpoint progress |\n| Context at 70%+ | Create handoff, then /clear |\n| Blocked and need help | Create handoff with blockers documented |\n\n## Handoff File Location\n\n**Path:** `docs/handoffs/{session-name}/YYYY-MM-DD_HH-MM-SS_{description}.md`\n\nWhere:\n- `{session-name}` - From active work context (e.g., `context-management`, `auth-feature`)\n- `YYYY-MM-DD_HH-MM-SS` - Current timestamp in 24-hour format\n- `{description}` - Brief kebab-case description of work done\n\n**Example:** `docs/handoffs/context-management/2025-12-27_14-30-00_handoff-tracking-skill.md`\n\nIf no clear session context, use `general/` as the folder name.\n\n## Handoff Document Template\n\nUse this exact structure for all handoff documents:\n\n~~~markdown\n---\ndate: {ISO timestamp with timezone}\nsession_name: {session-name}\ngit_commit: {current commit hash}\nbranch: {current branch}\nrepository: {repository name}\ntopic: \"{Feature/Task} Implementation\"\ntags: [implementation, {relevant-tags}]\nstatus: {complete|in_progress|blocked}\noutcome: UNKNOWN\nroot_span_id: {trace ID if available, empty otherwise}\nturn_span_id: {turn span ID if available, empty otherwise}\n---\n\n# Handoff: {concise description}\n\n## Task Summary\n{Description of task(s) worked on and their status: completed, in_progress, blocked.\nIf following a plan, reference the plan document and current phase.}\n\n## Critical References\n{2-3 most important file paths that must be read to continue this work.\nLeave blank if none.}\n- `path/to/critical/file.md`\n\n## Recent Changes\n{Files modified in this session with line references}\n- `src/path/to/file.py:45-67` - Added validation logic\n- `tests/path/to/test.py:10-30` - New test cases\n\n## Learnings\n\n### What Worked\n{Specific approaches that succeeded - these get indexed for future sessions}\n- Approach: {description} - worked because {reason}\n- Pattern: {pattern name} was effective for {use case}\n\n### What Failed\n{Attempted approaches that didn't work - helps future sessions avoid same mistakes}\n- Tried: {approach} -> Failed because: {reason}\n- Error: {error type} when {action} -> Fixed by: {solution}\n\n### Key Decisions\n{Important choices made and WHY - future sessions reference these}\n- Decision: {choice made}\n  - Alternatives: {other options considered}\n  - Reason: {why this choice}\n\n## Files Modified\n{Exhaustive list of files created or modified}\n- `path/to/new/file.py` - NEW: Description\n- `path/to/existing/file.py:100-150` - MODIFIED: Description\n\n## Action Items & Next Steps\n{Prioritized list for the next session}\n1. {Most important next action}\n2. {Second priority}\n3. {Additional items}\n\n## Other Notes\n{Anything else relevant: codebase locations, useful commands, gotchas}\n~~~\n\n## The Process\n\n### Step 1: Gather Session Metadata\n\n```bash\n# Get current git state\ngit rev-parse HEAD        # Commit hash\ngit branch --show-current # Branch name\ngit remote get-url origin # Repository\n\n# Get timestamp\ndate -u +\"%Y-%m-%dT%H:%M:%SZ\"\n```\n\n### Step 2: Determine Session Name\n\nCheck for active work context:\n1. Recent plan files in `docs/plans/` - extract feature name\n2. Recent branch name - use as session context\n3. If unclear, use `general`\n\n### Step 3: Write Handoff Document\n\n1. Create handoff directory if needed: `mkdir -p docs/handoffs/{session-name}/`\n2. Write handoff file with template structure\n3. Fill in all sections with session details\n4. Be thorough in learnings - these feed compound learning\n\n### Step 4: Verify Indexing\n\nAfter writing the handoff, verify it was indexed:\n\n```bash\n# Check artifact index updated (if database exists)\nsqlite3 .ring/cache/artifact-index/context.db \\\n  \"SELECT id, session_name FROM handoffs ORDER BY indexed_at DESC LIMIT 1\"\n```\n\nThe PostToolUse hook automatically indexes handoffs on Write.\n\n## Integration with Ring\n\n### Execution Reports\nWhen working within dev-team cycles, the handoff's \"Recent Changes\" and \"Files Modified\" sections should mirror the execution report format:\n\n| Metric | Include |\n|--------|---------|\n| Duration | Time spent on session |\n| Tasks Completed | X/Y from plan |\n| Files Created | N |\n| Files Modified | N |\n| Tests Added | N |\n\n### Session Traces\nIf session tracing is enabled (Braintrust, etc.), include:\n- `root_span_id` - Main trace ID\n- `turn_span_id` - Current turn span\n\nThese enable correlation between handoffs and detailed session logs.\n\n## Outcome Tracking\n\nOutcomes are marked AFTER the handoff is created, either:\n1. User responds to Stop hook prompt\n2. User runs outcome marking command later\n\n**Valid outcomes:**\n| Outcome | Meaning |\n|---------|---------|\n| SUCCEEDED | Task completed successfully |\n| PARTIAL_PLUS | Mostly done, minor issues remain |\n| PARTIAL_MINUS | Some progress, major issues remain |\n| FAILED | Task abandoned or blocked |\n\nHandoffs start with `outcome: UNKNOWN` and get updated when marked.\n\n## Remember\n\n- **Be thorough in Learnings** - These feed the compound learning system\n- **Include file:line references** - Makes resumption faster\n- **Document WHY not just WHAT** - Decisions without rationale are useless\n- **Index happens automatically** - PostToolUse hook handles it\n- **Outcome is separate** - Don't try to guess outcome, leave as UNKNOWN"
              },
              {
                "name": "ring:interviewing-user",
                "description": "Proactive requirements gathering - systematically interviews the user to uncover\nambiguities, preferences, and constraints BEFORE implementation begins.\n",
                "path": "default/skills/interviewing-user/SKILL.md",
                "frontmatter": {
                  "name": "ring:interviewing-user",
                  "description": "Proactive requirements gathering - systematically interviews the user to uncover\nambiguities, preferences, and constraints BEFORE implementation begins.\n",
                  "trigger": "- User invokes /interview-me command\n- Claude detects significant ambiguity in requirements\n- Multiple valid implementation paths exist with no clear winner\n- User says \"interview me\", \"ask me questions\", \"clarify with me\"\n- Task involves architecture decisions without clear direction\n",
                  "skip_when": "- Requirements are already crystal clear\n- User has provided detailed specifications\n- Following an existing plan with explicit instructions\n- Doubt can be resolved via doubt-triggered-questions (single question)\n",
                  "sequence": {
                    "before": [
                      "brainstorming",
                      "writing-plans"
                    ],
                    "after": []
                  },
                  "related": {
                    "similar": [
                      "brainstorming"
                    ],
                    "uses": [
                      "doubt-triggered-questions"
                    ]
                  }
                },
                "content": "# Interviewing User for Requirements\n\n## Overview\n\nProactively surface and resolve ambiguities by systematically interviewing the user BEFORE implementation begins. This prevents wasted effort from incorrect assumptions.\n\n**Core principle:** It's better to ask 5 questions upfront than to rewrite code 3 times.\n\n**Announce at start:** \"I'm using the interviewing-user skill to gather requirements before we begin.\"\n\n## Quick Reference\n\n| Phase | Key Activities | Tool | Output |\n|-------|---------------|------|--------|\n| **1. Context Analysis** | Analyze task, identify ambiguities | Internal | Ambiguity inventory |\n| **2. Question Clustering** | Group questions by category | Internal | Prioritized question list |\n| **3. Structured Interview** | Ask questions using AskUserQuestion | AskUserQuestion | User responses |\n| **4. Understanding Summary** | Synthesize and confirm | Text output | Validated Understanding |\n| **5. Proceed or Iterate** | User confirms or clarifies | User input | Green light to proceed |\n\n## The Process\n\nCopy this checklist to track progress:\n\n```\nInterview Progress:\n- [ ] Phase 1: Context Analysis (ambiguities identified)\n- [ ] Phase 2: Question Clustering (questions prioritized)\n- [ ] Phase 3: Structured Interview (questions asked and answered)\n- [ ] Phase 4: Understanding Summary (presented to user)\n- [ ] Phase 5: Proceed or Iterate (user confirmed)\n```\n\n### Phase 1: Context Analysis\n\n**BEFORE asking any questions**, analyze:\n\n1. **What the user explicitly stated** - Extract concrete requirements\n2. **What the codebase implies** - Patterns, conventions, existing solutions\n3. **What remains ambiguous** - Gaps between stated and implied\n4. **What decisions I must make** - Architecture, behavior, constraints\n\n**Create an Ambiguity Inventory:**\n\n```\nAmbiguity Inventory:\n- Architecture: [list unclear architectural decisions]\n- Behavior: [list unclear behavioral requirements]\n- Constraints: [list unclear constraints or limitations]\n- Preferences: [list unclear user preferences]\n- Integration: [list unclear integration points]\n```\n\n### Phase 2: Question Clustering\n\nGroup questions by category and prioritize:\n\n| Priority | Category | Criteria |\n|----------|----------|----------|\n| **P0** | Blocking | Cannot proceed without answer |\n| **P1** | Architecture | Affects overall structure |\n| **P2** | Behavior | Affects user-facing functionality |\n| **P3** | Preferences | Affects style, not correctness |\n\n**Question Budget:**\n- **Maximum 4 questions per AskUserQuestion call** (tool limitation)\n- **Maximum 3 rounds of questions** (respect user's time)\n- **Prefer fewer, higher-quality questions**\n\n### Phase 3: Structured Interview\n\nUse `AskUserQuestion` tool with well-structured options:\n\n**Question Quality Checklist:**\n- [ ] Shows what I already know (evidence of exploration)\n- [ ] Explains why I'm uncertain (the genuine conflict)\n- [ ] Provides 2-4 concrete options with descriptions\n- [ ] Options are mutually exclusive or clearly labeled as multi-select\n\n**Example - Good Question:**\n```\nheader: \"Auth Method\"\nquestion: \"The codebase has both session-based auth (UserService) and JWT (APIService). Which should this new endpoint use?\"\noptions:\n  - label: \"Session-based (Recommended)\"\n    description: \"Matches existing user-facing endpoints, simpler cookie handling\"\n  - label: \"JWT tokens\"\n    description: \"Matches API patterns, better for external integrations\"\n  - label: \"Support both\"\n    description: \"Maximum flexibility, more implementation complexity\"\n```\n\n**Example - Bad Question:**\n```\nquestion: \"What authentication should I use?\"\noptions:\n  - label: \"Option 1\"\n  - label: \"Option 2\"\n```\n\n### Phase 4: Understanding Summary\n\nAfter gathering responses, synthesize into a **Validated Understanding**:\n\n```markdown\n## Validated Understanding\n\n### What We're Building\n[1-2 sentence summary of the goal]\n\n### Key Decisions Made\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| [Topic] | [Selected option] | [Why this was chosen] |\n\n### Constraints Confirmed\n- [Constraint 1]\n- [Constraint 2]\n\n### Out of Scope (Explicit)\n- [Thing we're NOT doing]\n\n### Assumptions (If Any)\n- [Assumption]: [What would invalidate this]\n```\n\n**Present this to the user for confirmation.**\n\n### Phase 5: Proceed or Iterate\n\n**Confirmation Gate:**\n\nUnderstanding is NOT confirmed until user explicitly says:\n- \"Confirmed\" / \"Correct\" / \"That's right\"\n- \"Proceed\" / \"Let's do it\" / \"Go ahead\"\n- \"Yes\" (in response to \"Is this correct?\")\n\n**These do NOT mean confirmation:**\n- Silence\n- \"Interesting\" / \"I see\"\n- Questions about the summary\n- \"What about X?\" (that's requesting changes)\n\n**If not confirmed:** Return to Phase 3 with targeted follow-up questions.\n\n## Question Categories\n\n### Architecture Questions\n- \"Which pattern should this follow: [A] or [B]?\"\n- \"Where should this logic live: [Service A], [Service B], or new service?\"\n- \"Should this be synchronous or asynchronous?\"\n\n### Behavior Questions\n- \"When [edge case], should the system [A] or [B]?\"\n- \"What should happen if [failure scenario]?\"\n- \"Should users be able to [optional capability]?\"\n\n### Constraint Questions\n- \"Is there a performance requirement for this?\"\n- \"Does this need to support [specific scenario]?\"\n- \"Are there backward compatibility requirements?\"\n\n### Preference Questions\n- \"Do you prefer [verbose but explicit] or [concise but implicit]?\"\n- \"Should I prioritize [speed] or [maintainability]?\"\n- \"Any naming conventions I should follow?\"\n\n## When to Auto-Trigger This Skill\n\nClaude SHOULD invoke this skill automatically when:\n\n1. **Ambiguity count > 3** - More than 3 unclear decisions\n2. **Architecture choice unclear** - Multiple valid patterns, no codebase precedent\n3. **User request is high-level** - \"Build me X\" without specifics\n4. **Previous implementation was rejected** - Indicates misunderstanding\n5. **Task spans multiple domains** - Frontend + backend + infrastructure\n\nClaude should NOT auto-trigger when:\n- Task is a simple bug fix with clear reproduction\n- User provided detailed specifications\n- Following an existing plan\n- Single question would suffice (use doubt-triggered-questions instead)\n\n## Anti-Patterns\n\n| Anti-Pattern | Why It's Wrong | Correct Approach |\n|--------------|----------------|------------------|\n| Asking without exploring first | Wastes user's time | Explore codebase THEN ask |\n| Open-ended questions only | Hard to answer, vague responses | Provide concrete options |\n| Too many questions at once | Overwhelming | Max 4 per round, max 3 rounds |\n| Asking about things user already said | Shows you weren't listening | Re-read conversation first |\n| Asking preferences when conventions exist | CLAUDE.md/codebase already answers | Follow existing patterns |\n| Skipping summary phase | User can't correct misunderstandings | Always present Validated Understanding |\n\n## Integration with Other Skills\n\n| Skill | Relationship |\n|-------|--------------|\n| `doubt-triggered-questions` | Use for single questions during work; use interviewing-user for systematic upfront gathering |\n| `brainstorming` | Interview first to gather requirements, THEN brainstorm solutions |\n| `writing-plans` | Interview first to clarify scope, THEN create plan |\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **Exit Criteria:** See `skills/shared-patterns/exit-criteria.md`\n\n## Exit Criteria\n\nInterview is complete when ALL of these are true:\n\n- [ ] All P0 (blocking) questions answered\n- [ ] All P1 (architecture) questions answered\n- [ ] Validated Understanding presented\n- [ ] User explicitly confirmed understanding\n- [ ] No remaining ambiguities that affect correctness\n\n## Key Principles\n\n| Principle | Application |\n|-----------|-------------|\n| **Explore before asking** | 30 seconds of exploration can save a question |\n| **Structured choices** | Use AskUserQuestion with 2-4 concrete options |\n| **Show your work** | Include what you found and why you're uncertain |\n| **Respect time** | Max 3 rounds, max 4 questions per round |\n| **Confirm understanding** | Always present summary for validation |\n| **Iterate if needed** | Unclear confirmation = ask follow-up |"
              },
              {
                "name": "ring:linting-codebase",
                "description": "Parallel lint fixing pattern - runs lint checks, groups issues into independent\nstreams, and dispatches AI agents to fix all issues until the codebase is clean.\n",
                "path": "default/skills/linting-codebase/SKILL.md",
                "frontmatter": {
                  "name": "ring:linting-codebase",
                  "description": "Parallel lint fixing pattern - runs lint checks, groups issues into independent\nstreams, and dispatches AI agents to fix all issues until the codebase is clean.\n",
                  "trigger": "- User runs /lint command\n- Codebase has lint issues that need fixing\n- Multiple lint errors across different files/components\n",
                  "skip_when": "- Single lint error  fix directly without agent dispatch\n- Lint already passes  nothing to do\n- User only wants to see lint output, not fix\n"
                },
                "content": "# Linting Codebase\n\n## Overview\n\nThis skill runs lint checks on the codebase, analyzes the results to identify independent fix streams, and dispatches parallel AI agents to fix all issues. The process iterates until the codebase passes all lint checks.\n\n**Core principle:** Group lint issues by file/component, dispatch one agent per independent stream, iterate until clean.\n\n##  CRITICAL CONSTRAINTS\n\nThese constraints are NON-NEGOTIABLE and must be communicated to ALL dispatched agents:\n\n```\n\n   DO NOT CREATE AUTOMATED SCRIPTS TO FIX LINT ISSUES         \n   DO NOT CREATE DOCUMENTATION OR README FILES                 \n   DO NOT ADD COMMENTS EXPLAINING THE FIXES                   \n   FIX EACH ISSUE DIRECTLY BY EDITING THE SOURCE CODE         \n   MAKE MINIMAL CHANGES - ONLY WHAT'S NEEDED FOR LINT         \n\n```\n\n## Phase 1: Lint Execution\n\n### Step 1.1: Detect Lint Command\n\nPriority: `make lint`  `npm run lint`  `yarn lint`  `pnpm lint`  `golangci-lint run`  `cargo clippy`  `ruff check .`  `eslint .`\n\n### Step 1.2: Run Lint\n\n`<lint_command> 2>&1 | tee /tmp/lint-output.txt && echo \"EXIT_CODE: $?\"`\n\n### Step 1.3: Parse Results\n\nExtract: file path, line:column, error code/rule, message, severity (error/warning).\n\n## Phase 2: Stream Analysis\n\n### Step 2.1: Group Issues\n\nGroup lint issues into independent streams that can be fixed in parallel:\n\n**Grouping strategies (choose based on issue count):**\n\n| Issue Count | Grouping Strategy |\n|-------------|-------------------|\n| < 10 issues | Group by file |\n| 10-50 issues | Group by directory |\n| 50-100 issues | Group by error type/rule |\n| > 100 issues | Group by component/module |\n\n### Step 2.2: Identify Independence\n\nA stream is independent if: files don't import/depend on each other, fixes won't conflict, agents can work without knowledge of other streams.\n\n### Step 2.3: Create Stream Summary\n\nOutput format: Total issues, Streams (path, issue types, count, independence status), Recommended agents (one per stream).\n\n## Phase 3: Parallel Agent Dispatch\n\n### Step 3.1: Prepare Agent Prompts\n\nEach agent receives: **Scope** (files/directories), **Issues** (file:line:col + message), **Constraints** (from Critical Constraints above), **Output** (files modified, issues fixed, issues unable to fix with reasons).\n\n### Step 3.2: Dispatch Agents in Parallel\n\n**CRITICAL: Single message with multiple Task tool calls** - one `general-purpose` agent per stream.\n\n### Step 3.3: Await All Agents\n\nWait for all dispatched agents to complete before proceeding.\n\n## Phase 4: Verification Loop\n\n### Step 4.1: Re-run Lint\n\nAfter all agents complete, run `<lint_command> 2>&1`.\n\n### Step 4.2: Evaluate Results\n\n| Result | Action |\n|--------|--------|\n| **Lint passes** |  Done |\n| **Same issues remain** |  Investigate why fixes failed |\n| **New issues appeared** |  Analyze + dispatch new agents |\n| **Fewer issues remain** |  Create new streams, repeat |\n\n### Step 4.3: Iterate If Needed\n\n**Maximum iterations:** 5. If issues persist: report remaining, ask user, investigate (lint conflicts, auto-fix impossible).\n\n## Agent Dispatch Rules\n\n### DO dispatch when:\n- 3+ files have lint issues\n- Issues are in independent areas\n- Fixes are mechanical (unused vars, formatting, etc.)\n\n### DO NOT dispatch when:\n- Single file has issues  fix directly\n- Issues require architectural decisions\n- Fixes would cause breaking changes\n\n### Agent selection:\n\n| Issue Type | Agent Type |\n|------------|------------|\n| TypeScript/JavaScript | `general-purpose` |\n| Go | `general-purpose` or `backend-engineer-golang` |\n| Security lints | `security-reviewer` for analysis first |\n| Style/formatting | `general-purpose` |\n\n## Output Format\n\n**Success:** Initial issues, Streams processed, Agents dispatched, Iterations, Final status (all pass), Changes by stream (files, issues fixed).\n\n**Partial:** Initial/fixed/remaining issues, Iterations (max reached), Remaining issues with reasons (e.g., requires external types, intentional usage), Recommended actions (manual review, lint exceptions, type definitions).\n\n## Error Handling\n\n| Error | Response |\n|-------|----------|\n| **Lint command not found** | Ask user to specify command |\n| **Agent failure** | Options: retry stream, skip, investigate manually |\n| **Conflicting changes** | Report file + lines, ask user to merge manually |\n\n## Integration with Other Skills\n\n| Skill | When to use |\n|-------|-------------|\n| `dispatching-parallel-agents` | Pattern basis for this skill |\n| `systematic-debugging` | If lint errors indicate deeper issues |\n| `requesting-code-review` | After lint passes, before merge |\n\n## Example Session\n\n`/lint`  Run lint  16 issues in 3 areas  Analyze streams (API: 5, Services: 8, Utils: 3)  Dispatch 3 parallel agents  All complete  Re-run lint   All pass."
              },
              {
                "name": "ring:receiving-code-review",
                "description": "Review reception protocol - requires technical verification before implementing\nsuggestions. Prevents performative agreement and blind implementation.\n",
                "path": "default/skills/receiving-code-review/SKILL.md",
                "frontmatter": {
                  "name": "ring:receiving-code-review",
                  "description": "Review reception protocol - requires technical verification before implementing\nsuggestions. Prevents performative agreement and blind implementation.\n",
                  "trigger": "- Received code review feedback\n- About to implement reviewer suggestions\n- Feedback seems unclear or technically questionable\n",
                  "skip_when": "- Feedback is clear and obviously correct  implement directly\n- No feedback received  continue working\n"
                },
                "content": "# Code Review Reception\n\n## Overview\n\nCode review requires technical evaluation, not emotional performance.\n\n**Core principle:** Verify before implementing. Ask before assuming. Technical correctness over social comfort.\n\n## The Response Pattern\n\n**WHEN receiving feedback:** READ (complete, no reaction)  UNDERSTAND (restate or ask)  VERIFY (check codebase reality)  EVALUATE (technically sound for THIS codebase?)  RESPOND (technical acknowledgment or pushback)  IMPLEMENT (one at a time, test each)\n\n## Forbidden Responses\n\n**NEVER:**\n- \"You're absolutely right!\" (explicit CLAUDE.md violation)\n- \"Great point!\" / \"Excellent feedback!\" (performative)\n- \"Let me implement that now\" (before verification)\n\n**INSTEAD:**\n- Restate the technical requirement\n- Ask clarifying questions\n- Push back with technical reasoning if wrong\n- Just start working (actions > words)\n\n## Handling Unclear Feedback\n\n**IF any item is unclear:** STOP - do not implement anything yet. ASK for clarification. Items may be related - partial understanding = wrong implementation.\n\n**Example:** \"Fix 1-6\" - You understand 1,2,3,6, unclear on 4,5.  Implement 1,2,3,6 now.  \"Understand 1,2,3,6. Need clarification on 4 and 5 before proceeding.\"\n\n## Source-Specific Handling\n\n### From your human partner\n- **Trusted** - implement after understanding\n- **Still ask** if scope unclear\n- **No performative agreement**\n- **Skip to action** or technical acknowledgment\n\n### From External Reviewers\n\n**BEFORE implementing:** (1) Technically correct for THIS codebase? (2) Breaks existing functionality? (3) Reason for current implementation? (4) Works on all platforms/versions? (5) Does reviewer understand full context?\n\n- **If suggestion seems wrong:** Push back with technical reasoning\n- **If can't easily verify:** \"I can't verify this without [X]. Should I [investigate/ask/proceed]?\"\n- **If conflicts with your human partner's prior decisions:** Stop and discuss first\n\n**your human partner's rule:** \"External feedback - be skeptical, but check carefully\"\n\n## YAGNI Check for \"Professional\" Features\n\n**IF reviewer suggests \"implementing properly\":** grep codebase for actual usage. Unused? \"This endpoint isn't called. Remove it (YAGNI)?\" Used? Then implement properly.\n\n**your human partner's rule:** \"You and reviewer both report to me. If we don't need this feature, don't add it.\"\n\n## Implementation Order\n\n**FOR multi-item feedback:** (1) Clarify anything unclear FIRST (2) Implement: Blocking issues  Simple fixes  Complex fixes (3) Test each fix individually (4) Verify no regressions\n\n## When To Push Back\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Legacy/compatibility reasons exist\n- Conflicts with your human partner's architectural decisions\n\n**How to push back:**\n- Use technical reasoning, not defensiveness\n- Ask specific questions\n- Reference working tests/code\n- Involve your human partner if architectural\n\n**Signal if uncomfortable pushing back out loud:** \"Strange things are afoot at the Circle K\"\n\n## Acknowledging Correct Feedback\n\n \"Fixed. [Brief description]\" |  \"Good catch - [issue]. Fixed in [location].\" |  [Just fix it and show in code]\n \"You're absolutely right!\" |  \"Great point!\" |  \"Thanks for [anything]\" |  ANY gratitude expression\n\n**Why no thanks:** Actions speak. Just fix it. The code shows you heard the feedback. About to write \"Thanks\"? DELETE IT. State the fix instead.\n\n## Gracefully Correcting Your Pushback\n\nIf you pushed back and were wrong:  \"You were right - I checked [X] and it does [Y]. Implementing now.\"  Long apology, defending why you pushed back, over-explaining. State the correction factually and move on.\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Performative agreement | State requirement or just act |\n| Blind implementation | Verify against codebase first |\n| Batch without testing | One at a time, test each |\n| Assuming reviewer is right | Check if breaks things |\n| Avoiding pushback | Technical correctness > comfort |\n| Partial implementation | Clarify all items first |\n| Can't verify, proceed anyway | State limitation, ask for direction |\n\n## Real Examples\n\n| Type | Response |\n|------|----------|\n| **Performative (Bad)** | \"Remove legacy code\"   \"You're absolutely right! Let me remove that...\" |\n| **Technical (Good)** | \"Remove legacy code\"   \"Checking... build target is 10.15+, this API needs 13+. Need legacy for backward compat.\" |\n| **YAGNI (Good)** | \"Implement proper metrics\"   \"Grepped codebase - nothing calls this endpoint. Remove it (YAGNI)?\" |\n| **Unclear (Good)** | \"Fix items 1-6\"   \"Understand 1,2,3,6. Need clarification on 4 and 5 before implementing.\" |\n\n## The Bottom Line\n\n**External feedback = suggestions to evaluate, not orders to follow.**\n\nVerify. Question. Then implement.\n\nNo performative agreement. Technical rigor always."
              },
              {
                "name": "ring:release-guide-info",
                "description": "Generate Ops Update Guide from Git Diff. Produces internal Operations-facing\nupdate/migration guides based on git diff analysis. Supports STRICT_NO_TOUCH (default)\nand TEMP_CLONE_FOR_FRESH_REFS modes. Includes tag auto-detection and commit log analysis.\n",
                "path": "default/skills/release-guide-info/SKILL.md",
                "frontmatter": {
                  "name": "ring:release-guide-info",
                  "version": "1.2.0",
                  "description": "Generate Ops Update Guide from Git Diff. Produces internal Operations-facing\nupdate/migration guides based on git diff analysis. Supports STRICT_NO_TOUCH (default)\nand TEMP_CLONE_FOR_FRESH_REFS modes. Includes tag auto-detection and commit log analysis.\n",
                  "trigger": "- Preparing to release a new version\n- Need to document what changed between refs\n- Creating operational update guide\n- Communicating version updates to Ops team\n- \"Generate ops guide from main to HEAD\"\n- \"Generate release guide for <version>\"\n",
                  "skip_when": "- No git repository available\n- Single file change (too small for formal guide)\n- Customer-facing release notes only (use simpler template)\n",
                  "input_schema": {
                    "BASE_REF": {
                      "type": "string",
                      "required": true,
                      "description": "Starting point (branch, tag, or SHA)",
                      "examples": [
                        "main",
                        "release/v3.4.x",
                        "v1.0.0"
                      ]
                    },
                    "TARGET_REF": {
                      "type": "string",
                      "required": true,
                      "description": "Ending point (branch, tag, or SHA)",
                      "examples": [
                        "HEAD",
                        "feature/foo",
                        "v1.1.0"
                      ]
                    },
                    "VERSION": {
                      "type": "string",
                      "required": false,
                      "description": "Version number for the release (auto-detected from tags if not provided)",
                      "examples": [
                        "v2.0.0",
                        "1.5.0",
                        "2025.01"
                      ]
                    },
                    "LANGUAGE": {
                      "type": "enum",
                      "required": false,
                      "default": "en",
                      "values": [
                        "en",
                        "pt-br",
                        "both"
                      ],
                      "description": "Output language(s) for the guide"
                    },
                    "MODE": {
                      "type": "enum",
                      "required": false,
                      "default": "STRICT_NO_TOUCH",
                      "values": [
                        "STRICT_NO_TOUCH",
                        "TEMP_CLONE_FOR_FRESH_REFS"
                      ],
                      "description": "Git execution mode"
                    }
                  },
                  "output_schema": {
                    "files": {
                      "type": "array",
                      "description": "List of generated guide files",
                      "items": {
                        "path": "string",
                        "language": "string"
                      }
                    },
                    "summary": {
                      "type": "object",
                      "description": "Quick summary of changes",
                      "properties": {
                        "features": "number",
                        "bug_fixes": "number",
                        "improvements": "number",
                        "breaking_changes": "number"
                      }
                    },
                    "version": {
                      "type": "string",
                      "description": "Version number (provided or auto-detected)"
                    },
                    "refs": {
                      "type": "object",
                      "properties": {
                        "base": "string",
                        "target": "string",
                        "base_sha": "string",
                        "target_sha": "string"
                      }
                    }
                  },
                  "related": {
                    "complementary": [
                      "finishing-a-development-branch",
                      "handoff-tracking"
                    ]
                  }
                },
                "content": "# Release Guide Info  Ops Update Guide Generator\n\n## Overview\n\nYou are a code-aware documentation agent. Produce an **internal** Operations-facing update/migration guide.\n\n## Runtime Inputs (REQUIRED)\n\n| Input | Description | Example |\n|-------|-------------|---------|\n| `BASE_REF` | Starting point (branch, tag, or SHA) | `main`, `release/v3.4.x`, `v1.0.0` |\n| `TARGET_REF` | Ending point (branch, tag, or SHA) | `feature/foo`, `HEAD`, `v1.1.0` |\n| `VERSION` (optional) | Version number (auto-detected from tags if not provided) | `v2.0.0`, `1.5.0` |\n| `LANGUAGE` (optional) | Output language | `en` (default), `pt-br`, `both` |\n| `MODE` (optional) | Execution mode | `STRICT_NO_TOUCH` (default), `TEMP_CLONE_FOR_FRESH_REFS` |\n\n**Language options:**\n- `en`  English only (default)\n- `pt-br`  Portuguese (Brazil) only\n- `both`  Generate two files, one in each language\n\n**Version handling:**\n- If `VERSION` provided  Use it directly\n- If `TARGET_REF` is a tag  Auto-extract version from tag name\n- If neither  Omit version from output\n\n**Comparison range:** Always use triple-dot `BASE_REF...TARGET_REF`\n\n## Safety Invariants\n\n### STRICT_NO_TOUCH (default)\n\n**Hard requirement:** Do NOT alter anything in the current local repo.\n\n**FORBIDDEN commands:**\n- `git fetch`, `git pull`, `git push`\n- `git checkout`, `git switch`, `git reset`, `git clean`\n- `git commit`, `git merge`, `git rebase`, `git cherry-pick`\n- `git worktree`, `git gc`, `git repack`, `git prune`\n- Any write operation to `.git/` files\n\n**ALLOWED commands (read-only):**\n- `git rev-parse`, `git diff`, `git show`, `git log`, `git remote get-url`\n\n**If ref does not exist locally:** STOP and report:\n- Which ref failed to resolve\n- That STRICT_NO_TOUCH forbids fetching\n- Suggest alternative: TEMP_CLONE_FOR_FRESH_REFS\n\n### TEMP_CLONE_FOR_FRESH_REFS (optional)\n\nGoal: Do NOT touch current repo, but allow obtaining up-to-date remote refs in an isolated temporary clone.\n\n**Process:**\n```bash\n# 1. Get remote URL\nREMOTE_URL=$(git remote get-url origin)\n\n# 2. Create isolated temp clone\nTMP_DIR=$(mktemp -d) || { echo \"Failed to create temp directory\"; exit 1; }\ngit clone --no-checkout \"$REMOTE_URL\" \"$TMP_DIR\"\n\n# 3. Fetch refs in temp clone\ncd \"$TMP_DIR\"\ngit fetch origin --prune --tags\n\n# 4. Continue steps inside temp clone only\n\n# 5. Cleanup after guide is generated\ncd - >/dev/null\nrm -rf \"$TMP_DIR\"\n```\n\n## The Process\n\n### Step 0  Determine Execution Location\n\n**If MODE=STRICT_NO_TOUCH:** Operate in current repo with read-only commands only.\n\n**If MODE=TEMP_CLONE_FOR_FRESH_REFS:** Create temp clone, operate there, cleanup after.\n\n### Step 1  Resolve Refs and Metadata\n\n```bash\n# Verify refs exist\ngit rev-parse --verify BASE_REF^{commit}\ngit rev-parse --verify TARGET_REF^{commit}\n\n# Capture SHAs\nBASE_SHA=$(git rev-parse --short BASE_REF)\nTARGET_SHA=$(git rev-parse --short TARGET_REF)\n\n# Get repo/service name\norigin_url=\"$(git remote get-url origin 2>/dev/null)\"\n[ -n \"$origin_url\" ] && printf '%s\\n' \"$origin_url\" | sed 's|.*[:/]||;s|\\.git$||' || basename \"$(pwd)\"\n```\n\n**If verification fails:**\n- STRICT_NO_TOUCH: STOP + suggest TEMP_CLONE_FOR_FRESH_REFS\n- TEMP_CLONE: STOP (refs truly not found)\n\n### Step 1.5  Tag Auto-Detection and Version Resolution\n\n**Detect if refs are tags and extract version:**\n\n```bash\n# Check if TARGET_REF is a tag\nif git tag -l \"$TARGET_REF\" | grep -q .; then\n    IS_TAG=true\n    # Extract version from tag (handles v1.0.0, 1.0.0, release-1.0.0, etc.)\n    AUTO_VERSION=$(echo \"$TARGET_REF\" | sed -E 's/^(v|release[-_]?|version[-_]?)?//i')\nelse\n    IS_TAG=false\n    AUTO_VERSION=\"\"\nfi\n\n# Check if BASE_REF is a tag\nif git tag -l \"$BASE_REF\" | grep -q .; then\n    BASE_IS_TAG=true\nelse\n    BASE_IS_TAG=false\nfi\n\n# Resolve final VERSION\nif [ -n \"$VERSION\" ]; then\n    FINAL_VERSION=\"$VERSION\"\nelif [ -n \"$AUTO_VERSION\" ]; then\n    FINAL_VERSION=\"$AUTO_VERSION\"\nelse\n    FINAL_VERSION=\"\"\nfi\n```\n\n**Version detection output:**\n\n| Scenario | Result |\n|----------|--------|\n| `VERSION` provided | Use provided version |\n| `TARGET_REF` is tag `v2.0.0` | Auto-detect: `2.0.0` |\n| `TARGET_REF` is tag `release-1.5.0` | Auto-detect: `1.5.0` |\n| `TARGET_REF` is branch/SHA | No version (omit from title) |\n\n### Step 1.6  Commit Log Analysis\n\n**Extract context from commit messages:**\n\n```bash\n# Get commit messages between refs\ngit log --oneline --no-merges BASE_REF...TARGET_REF\n\n# Get detailed commit messages for context\ngit log --pretty=format:\"%h %s%n%b\" --no-merges BASE_REF...TARGET_REF\n```\n\n**Parse commit messages for:**\n\n| Pattern | Category | Example |\n|---------|----------|---------|\n| `feat:`, `feature:` | Feature | `feat: add user authentication` |\n| `fix:`, `bugfix:` | Bug Fix | `fix: resolve null pointer exception` |\n| `refactor:` | Improvement | `refactor: optimize database queries` |\n| `breaking:`, `BREAKING CHANGE:` | Breaking | `breaking: remove deprecated API` |\n| `perf:` | Performance | `perf: improve response time` |\n| `docs:` | Documentation | `docs: update API documentation` |\n| `chore:`, `build:`, `ci:` | Infrastructure | `chore: update dependencies` |\n\n**Use commit messages to:**\n1. Supplement diff analysis with intent/context\n2. Identify breaking changes explicitly marked\n3. Group related changes by commit scope\n4. Extract ticket/issue references (e.g., `#123`, `JIRA-456`)\n\n### Step 2  Produce the Diff\n\n```bash\n# Stats view\ngit diff --find-renames --find-copies --stat BASE_REF...TARGET_REF\n\n# Full diff\ngit diff --find-renames --find-copies BASE_REF...TARGET_REF\n```\n\n### Step 3  Build Change Inventory\n\nFrom the diff, identify:\n\n| Category | What to Look For |\n|----------|------------------|\n| **Endpoints** | New/changed/removed (method/path/request/response/status codes) |\n| **DB Schema** | Migrations, backfills, indexes, constraints |\n| **Messaging** | Topics, payloads, headers, idempotency, ordering |\n| **Config/Env** | New vars, changed defaults |\n| **Auth** | Permissions, roles, tokens |\n| **Performance** | Rate-limits, timeouts, retries |\n| **Dependencies** | Bumps with runtime behavior impact |\n| **Observability** | Logging, metrics, tracing changes |\n| **Operations** | Scripts, cron, job schedules |\n\n### Step 4  Write the Ops Update Guide\n\n**Use the appropriate template based on LANGUAGE parameter.**\n\n---\n\n## Language Templates\n\n### Template Selection\n\n| LANGUAGE | Use Template |\n|----------|--------------|\n| `en` | English Template |\n| `pt-br` | Portuguese Template |\n| `both` | Generate BOTH templates as separate files |\n\n---\n\n###  English Template (LANGUAGE=en)\n\n**Title Format (with version):**\n```markdown\n# Ops Update Guide  <repo/service>  <VERSION>  <TARGET_SHA>\n```\n\n**Title Format (without version):**\n```markdown\n# Ops Update Guide  <repo/service>  BASE_REF  TARGET_REF  <TARGET_SHA>\n```\n\n**Header Block:**\n```markdown\n| Field | Value |\n|-------|-------|\n| **Mode** | `STRICT_NO_TOUCH` or `TEMP_CLONE_FOR_FRESH_REFS` |\n| **Comparison** | `BASE_REF...TARGET_REF` |\n| **Base SHA** | `<BASE_SHA>` |\n| **Target SHA** | `<TARGET_SHA>` |\n| **Date** | YYYY-MM-DD |\n| **Source** | based on git diff |\n```\n\n**Section Format:**\n```markdown\n## <N>. <Descriptive Title> [<Category> <Emoji>]\n```\n\n**Category Mapping (English):**\n\n| Category | Emoji |\n|----------|-------|\n| Feature |  |\n| Bug Fix |  |\n| Improvement |  |\n| Breaking |  |\n| Infrastructure |  |\n| Observability |  |\n| Data |  |\n\n**Section Labels (English):**\n- **What Changed**  Bullet list with concrete changes\n- **Why It Changed**  Infer from code/comments/tests\n- **Client Impact**  Risk level: Low/Medium/High\n- **Required Client Action**  \"None\" or exact steps\n- **Deploy/Upgrade Notes**  Order of operations, compatibility\n- **Post-Deploy Monitoring**  Logs, metrics, signals\n- **Rollback**  Safety: Safe/Conditional/Not recommended\n\n**Uncertain Info Markers (English):**\n- Mark as **ASSUMPTION** + **HOW TO VALIDATE**\n\n---\n\n###  Portuguese Template (LANGUAGE=pt-br)\n\n**Title Format (with version):**\n```markdown\n# Guia de Atualizao (Ops)  <repo/servio>  <VERSION>  <TARGET_SHA>\n```\n\n**Title Format (without version):**\n```markdown\n# Guia de Atualizao (Ops)  <repo/servio>  BASE_REF  TARGET_REF  <TARGET_SHA>\n```\n\n**Header Block:**\n```markdown\n| Campo | Valor |\n|-------|-------|\n| **Mode** | `STRICT_NO_TOUCH` ou `TEMP_CLONE_FOR_FRESH_REFS` |\n| **Comparao** | `BASE_REF...TARGET_REF` |\n| **Base SHA** | `<BASE_SHA>` |\n| **Target SHA** | `<TARGET_SHA>` |\n| **Data** | YYYY-MM-DD |\n| **Fonte** | baseado em git diff |\n```\n\n**Section Format:**\n```markdown\n## <N>. <Ttulo descritivo> [<Categoria> <Emoji>]\n```\n\n**Category Mapping (Portuguese):**\n\n| Categoria | Emoji |\n|-----------|-------|\n| Funcionalidade |  |\n| Correo |  |\n| Melhoria |  |\n| Breaking |  |\n| Infra |  |\n| Observabilidade |  |\n| Dados |  |\n\n**Section Labels (Portuguese):**\n- **O que mudou**  Bullet list with concrete changes\n- **Por que mudou**  Infer from code/comments/tests\n- **Impacto para clientes**  Risk level: Baixo/Mdio/Alto\n- **Ao necessria do cliente**  \"Nenhuma\" or exact steps\n- **Notas de deploy/upgrade**  Order of operations, compatibility\n- **O que monitorar ps-deploy**  Logs, metrics, signals\n- **Rollback**  Safety: Seguro/Condicional/No recomendado\n\n**Uncertain Info Markers (Portuguese):**\n- Mark as **ASSUNO** + **COMO VALIDAR**\n\n---\n\n## Section Structure (applies to both languages)\n\n**1) Contextual Narrative (REQUIRED - comes FIRST)**\n- 1-3 paragraphs explaining business/operational context\n- Problem being solved or scenario that triggered change\n- Concrete examples (anonymized if needed)\n\n**2) What Changed / O que mudou**\n- Bullet list with concrete changes\n- Include `file:line` references (e.g., `pkg/mmodel/balance.go:332-335`)\n- Show key code snippets if they clarify behavior\n\n**3) Why It Changed / Por que mudou**\n- Infer from code/comments/tests if possible\n- If not derivable, use the appropriate uncertainty marker for the language\n\n**4) Client Impact / Impacto para clientes**\n- Who/what is impacted\n- Risk level with justification\n- Expected behavior differences\n\n**5) Required Client Action / Ao necessria do cliente**\n- \"None\"/\"Nenhuma\" if none\n- If yes: exact steps (API fields, headers, retries, config updates)\n\n**6) Deploy/Upgrade Notes / Notas de deploy/upgrade**\n- Order of operations, compatibility concerns\n- Rolling deploy safety\n- Flags/canary recommendations\n\n**7) Post-Deploy Monitoring / O que monitorar ps-deploy**\n\nFor log messages:\n```markdown\n| Level/Nvel | Message/Mensagem | Meaning/Significado |\n|-------------|------------------|---------------------|\n| `INFO` | `Message text` | Explanation |\n| `WARN` | `Warning text` | What this indicates |\n```\n\nFor tracing spans:\n```markdown\n#### Tracing Span: `span.name.here`\n\n| Scenario/Cenrio | Span Status | Description |\n|------------------|-------------|-------------|\n| Success/Sucesso |  OK | Description |\n| Error/Erro |  Error | Description with error details |\n```\n\nInclude:\n- **Where/Onde**: Log sources, dashboards, metric names\n- **Suggested threshold/Threshold sugerido**: If not derivable, label as \"Suggestion\"/\"Sugesto\"\n- **Success signals/Sinais de sucesso**: Expected positive indicators\n- **Failure signals/Sinais de falha**: Warning signs\n\n**8) Rollback**\n- **Safety/Segurana**: Safe/Conditional/Not recommended (or Portuguese equivalent)\n- **Steps/Passos**: Specific steps (revert image, wait for TTL, etc.)\n- **Concerns/Preocupaes**: Data/compat concerns\n\n#### Special Sections\n\n** Attention Point / Ponto de Ateno (when applicable)**\n\nEnglish:\n```markdown\n###  Attention Point\n\n**The client may observe [specific change] after this deploy.**\n\nThis is expected because:\n- [Reason 1]\n- [Reason 2]\n\n**Upside**: [Benefit]\n**Required action**: [What to do]\n```\n\nPortuguese:\n```markdown\n###  Ponto de Ateno\n\n**O cliente pode observar [mudana especfica] aps este deploy.**\n\nIsso  esperado porque:\n- [Razo 1]\n- [Razo 2]\n\n**Lado positivo**: [Benefcio]\n**Ao necessria**: [O que fazer]\n```\n\n**Compatibility Tables (when applicable)**\n\nEnglish:\n```markdown\n### Backward Compatibility\n\n **100% compatible** with existing data:\n\n| Scenario | Handling | Location |\n|----------|----------|----------|\n| Scenario 1 | How handled | `file:line` |\n```\n\nPortuguese:\n```markdown\n### Compatibilidade retroativa\n\n **100% compatvel** com dados existentes:\n\n| Cenrio | Tratamento | Local |\n|---------|------------|-------|\n| Cenrio 1 | Como tratado | `arquivo:linha` |\n```\n\n### Step 5  Write Summary Section\n\n**English Summary:**\n```markdown\n## Summary\n\n| Category | Count |\n|----------|-------|\n| Features  | N |\n| Bug Fixes  | N |\n| Improvements  | N |\n| Data/Migrations  | N |\n\n## Rollback Compatibility Analysis\n\n/ **[Overall assessment]**\n\n| Item | Rollback | Justification |\n|------|----------|---------------|\n| 1. [Item name] |  Safe | [Brief reason] |\n| 2. [Item name] |  Conditional | [Brief reason] |\n```\n\n**Portuguese Summary:**\n```markdown\n## Resumo\n\n| Categoria | Quantidade |\n|-----------|------------|\n| Funcionalidades  | N |\n| Correes  | N |\n| Melhorias  | N |\n| Dados/Migraes  | N |\n\n## Anlise de Compatibilidade de Rollback\n\n/ **[Avaliao geral]**\n\n| Item | Rollback | Justificativa |\n|------|----------|---------------|\n| 1. [Nome do item] |  Seguro | [Razo breve] |\n| 2. [Nome do item] |  Condicional | [Razo breve] |\n```\n\nEnd with:\n- Schema changes\n- Incompatible serialization changes\n- Data that old version cannot read\n- Irreversible migrations\n\n### Step 6  Preview Before Saving\n\n**MANDATORY: Show preview summary before writing to disk.**\n\nPresent to user for confirmation:\n\n```markdown\n##  Release Guide Preview\n\n**Configuration:**\n| Setting | Value |\n|---------|-------|\n| Repository | <repo-name> |\n| Comparison | `BASE_REF...TARGET_REF` |\n| Version | <VERSION or \"Not detected\"> |\n| Language(s) | <en/pt-br/both> |\n| Mode | <STRICT_NO_TOUCH/TEMP_CLONE_FOR_FRESH_REFS> |\n\n**Change Summary:**\n| Category | Count |\n|----------|-------|\n| Features  | N |\n| Bug Fixes  | N |\n| Improvements  | N |\n| Breaking Changes  | N |\n| Infrastructure  | N |\n| Data/Migrations  | N |\n\n**Key Changes (top 5):**\n1. [Brief description of most significant change]\n2. [Second most significant]\n3. [Third]\n4. [Fourth]\n5. [Fifth]\n\n**Output File(s):**\n- `notes/releases/{filename}.md`\n\n---\n**Proceed with saving?** [Yes/No]\n```\n\n**Wait for user confirmation before Step 7.**\n\n### Step 7  Persist Guide to Disk\n\n**File naming convention:**\n\n| Has Version? | LANGUAGE | Filename Pattern |\n|--------------|----------|------------------|\n| Yes | `en` | `{DATE}_{REPO}-{VERSION}.md` |\n| Yes | `pt-br` | `{DATE}_{REPO}-{VERSION}_pt-br.md` |\n| No | `en` | `{DATE}_{REPO}-{BASE}-to-{TARGET}.md` |\n| No | `pt-br` | `{DATE}_{REPO}-{BASE}-to-{TARGET}_pt-br.md` |\n| Any | `both` | Generate BOTH files above |\n\n```bash\n# Output directory\nOUT_DIR=\"notes/releases\"\nmkdir -p \"$OUT_DIR\"\n\n# Base filename components\nDATE=$(date +%Y-%m-%d)\nREPO_SLUG=<repo-kebab-case>\nVERSION_SLUG=<version-sanitized>  # e.g., v2.0.0 -> v2-0-0\nBASE_SLUG=<base-ref-sanitized>\nTARGET_SLUG=<target-ref-sanitized>\n\n# Determine filename based on version availability\nif [ -n \"$FINAL_VERSION\" ]; then\n    BASE_FILENAME=\"${DATE}_${REPO_SLUG}-${VERSION_SLUG}\"\nelse\n    BASE_FILENAME=\"${DATE}_${REPO_SLUG}-${BASE_SLUG}-to-${TARGET_SLUG}\"\nfi\n\n# Generate files based on LANGUAGE\ncase \"$LANGUAGE\" in\n  en)\n    FILE=\"$OUT_DIR/${BASE_FILENAME}.md\"\n    # Write English guide\n    ;;\n  pt-br)\n    FILE=\"$OUT_DIR/${BASE_FILENAME}_pt-br.md\"\n    # Write Portuguese guide\n    ;;\n  both)\n    FILE_EN=\"$OUT_DIR/${BASE_FILENAME}.md\"\n    FILE_PT=\"$OUT_DIR/${BASE_FILENAME}_pt-br.md\"\n    # Write BOTH guides\n    ;;\nesac\n```\n\n**After saving, confirm:**\n- Path(s) of saved file(s)\n- `BASE_REF...TARGET_REF` used\n- SHAs used\n- Version (if detected/provided)\n- Language(s) generated\n\n## Hard Rules (Content)\n\n| Rule | Enforcement |\n|------|-------------|\n| No invented changes | Everything MUST be supported by diff |\n| Uncertain info | Mark as **ASSUMPTION** + **HOW TO VALIDATE** |\n| Operational language | Audience is Ops, not customers |\n| External changes | API, events, DB, auth, timeouts MUST be called out |\n| Preview required | MUST show preview before saving |\n| User confirmation | MUST wait for user approval before writing files |\n\n## Anti-Rationalization Table\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"The diff is too large, I'll summarize\" | Summarizing loses critical details. Ops needs specifics. | **Document ALL significant changes** |\n| \"This change is obvious, no need to explain\" | Obvious to you  obvious to Ops. Context is required. | **Add contextual narrative** |\n| \"I'll skip the preview, user is in a hurry\" | Preview prevents errors. Skipping risks wrong output. | **ALWAYS show preview first** |\n| \"No breaking changes detected\" | Did you check commit messages for BREAKING CHANGE? | **Verify commit messages AND diff** |\n| \"Version not important for this guide\" | Version helps Ops track releases. Auto-detect or ask. | **Include version when available** |\n| \"Rollback analysis not needed, changes are safe\" | ALL changes need rollback assessment. No exceptions. | **Include rollback section** |\n| \"I'll invent a likely reason for this change\" | Invented reasons mislead Ops. Mark as ASSUMPTION. | **Mark uncertain info clearly** |\n| \"This file change isn't relevant to Ops\" | You don't decide relevance. Document it, Ops decides. | **Document ALL changes** |\n| \"Skip commit log, diff is enough\" | Commit messages contain intent not visible in diff. | **Analyze commit messages** |\n| \"User didn't ask for Portuguese, skip it\" | Check LANGUAGE parameter. If `both`, generate both. | **Respect LANGUAGE parameter** |\n\n## Quality Checklist\n\nBefore output, self-validate:\n\n- [ ] Every section starts with contextual narrative\n- [ ] All log messages in table format (Level | Message | Meaning)\n- [ ] All tracing spans in table format when applicable\n- [ ] Emojis used consistently for category tags\n- [ ] Rollback analysis consolidated as matrix at end\n- [ ] No invented changes - everything traceable to diff\n- [ ] File:line references included for key code changes\n- [ ] \" Attention Point\" used for confusing expected behaviors\n\n## Special Handling Rules\n\n| Change Type | Required Info |\n|-------------|---------------|\n| **DB migrations** | Forward steps, rollback steps, irreversibility, compat matrix |\n| **Breaking API/events** | Explicit contract diffs + mitigation/versioning |\n| **Feature flags** | Name, default, operational toggling guidance |\n| **Security/auth** | Privilege/role changes, operational checks |\n| **Log level changes** | Document what was ERRORINFO, etc. |\n\n## Example Invocations\n\n**With version (from tag):**\n```\nUser: Generate release guide from <base-tag> to <target-tag>\nAssistant: [Detects tags, auto-extracts version from <target-tag>]\nAssistant: [Shows preview summary]\nUser: Yes, proceed\nAssistant: [Writes guide]\nOutput: notes/releases/{DATE}_{REPO}-{VERSION}.md\n```\n\n**With explicit version:**\n```\nUser: Generate release guide from <base-ref> to <target-ref>, version <version>\nAssistant: [Uses provided version]\nAssistant: [Shows preview summary]\nUser: Yes, proceed\nOutput: notes/releases/{DATE}_{REPO}-{VERSION}.md\n```\n\n**Without version (branch to branch):**\n```\nUser: Generate ops guide from <base-branch> to <target-branch>\nAssistant: [No version detected]\nAssistant: [Shows preview summary]\nUser: Yes, proceed\nOutput: notes/releases/{DATE}_{REPO}-{BASE}-to-{TARGET}.md\n```\n\n**Portuguese only:**\n```\nUser: Generate ops guide from <base-ref> to <target-ref> in Portuguese\nAssistant: [Shows preview summary]\nUser: Yes, proceed\nOutput: notes/releases/{DATE}_{REPO}-{BASE}-to-{TARGET}_pt-br.md\n```\n\n**Both languages:**\n```\nUser: Generate release guide for <version> in both English and Portuguese\nAssistant: [Shows preview summary]\nUser: Yes, proceed\nOutput:\n  - notes/releases/{DATE}_{REPO}-{VERSION}.md (English)\n  - notes/releases/{DATE}_{REPO}-{VERSION}_pt-br.md (Portuguese)\n```\n\n**Via slash command:**\n```\nUser: /release-guide <base-ref> <target-ref>\nAssistant: [Executes skill with BASE_REF and TARGET_REF]\n```"
              },
              {
                "name": "ring:requesting-code-review",
                "description": "Gate 4 of development cycle - dispatches 5 specialized reviewers (code, business-logic,\nsecurity, test, nil-safety) in parallel for comprehensive code review feedback.\n",
                "path": "default/skills/requesting-code-review/SKILL.md",
                "frontmatter": {
                  "name": "ring:requesting-code-review",
                  "description": "Gate 4 of development cycle - dispatches 5 specialized reviewers (code, business-logic,\nsecurity, test, nil-safety) in parallel for comprehensive code review feedback.\n",
                  "trigger": "- Gate 4 of development cycle\n- After completing major feature implementation\n- Before merge to main branch\n- After fixing complex bug\n",
                  "NOT_skip_when": "- \"Code is simple\"  Simple code can have security issues. Review required.\n- \"Just refactoring\"  Refactoring may expose vulnerabilities. Review required.\n- \"Already reviewed similar code\"  Each change needs fresh review.\n",
                  "sequence": {
                    "after": [
                      "dev-testing"
                    ],
                    "before": [
                      "dev-validation"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "dev-cycle",
                      "dev-implementation",
                      "dev-testing"
                    ]
                  },
                  "input_schema": {
                    "required": [],
                    "optional": [
                      {
                        "name": "unit_id",
                        "type": "string",
                        "description": "Task or subtask identifier (auto-generated if not provided)"
                      },
                      {
                        "name": "base_sha",
                        "type": "string",
                        "description": "Git SHA before implementation (auto-detected via git merge-base HEAD main)"
                      },
                      {
                        "name": "head_sha",
                        "type": "string",
                        "description": "Git SHA after implementation (auto-detected via git rev-parse HEAD)"
                      },
                      {
                        "name": "implementation_summary",
                        "type": "string",
                        "description": "Summary of what was implemented (auto-generated from git log if not provided)"
                      },
                      {
                        "name": "requirements",
                        "type": "string",
                        "description": "Requirements or acceptance criteria (reviewers will infer from code if not provided)"
                      },
                      {
                        "name": "implementation_files",
                        "type": "array",
                        "items": "string",
                        "description": "List of files changed (auto-detected via git diff if not provided)"
                      },
                      {
                        "name": "gate0_handoff",
                        "type": "object",
                        "description": "Full handoff from Gate 0 (only when called from dev-cycle)"
                      },
                      {
                        "name": "skip_reviewers",
                        "type": "array",
                        "items": "string",
                        "enum": [
                          "code-reviewer",
                          "business-logic-reviewer",
                          "security-reviewer",
                          "test-reviewer",
                          "nil-safety-reviewer"
                        ],
                        "description": "Reviewers to skip (use sparingly)"
                      }
                    ]
                  },
                  "output_schema": {
                    "format": "markdown",
                    "required_sections": [
                      {
                        "name": "Review Summary",
                        "pattern": "^## Review Summary",
                        "required": true
                      },
                      {
                        "name": "Issues by Severity",
                        "pattern": "^## Issues by Severity",
                        "required": true
                      },
                      {
                        "name": "Reviewer Verdicts",
                        "pattern": "^## Reviewer Verdicts",
                        "required": true
                      },
                      {
                        "name": "CodeRabbit External Review",
                        "pattern": "^## CodeRabbit External Review",
                        "required": false
                      },
                      {
                        "name": "Handoff to Next Gate",
                        "pattern": "^## Handoff to Next Gate",
                        "required": true
                      }
                    ],
                    "metrics": [
                      {
                        "name": "result",
                        "type": "enum",
                        "values": [
                          "PASS",
                          "FAIL",
                          "NEEDS_FIXES"
                        ]
                      },
                      {
                        "name": "reviewers_passed",
                        "type": "string",
                        "description": "X/5 format"
                      },
                      {
                        "name": "issues_critical",
                        "type": "integer"
                      },
                      {
                        "name": "issues_high",
                        "type": "integer"
                      },
                      {
                        "name": "issues_medium",
                        "type": "integer"
                      },
                      {
                        "name": "issues_low",
                        "type": "integer"
                      },
                      {
                        "name": "iterations",
                        "type": "integer"
                      },
                      {
                        "name": "coderabbit_status",
                        "type": "enum",
                        "values": [
                          "PASS",
                          "ISSUES_FOUND",
                          "SKIPPED",
                          "NOT_INSTALLED"
                        ]
                      },
                      {
                        "name": "coderabbit_validation_mode",
                        "type": "enum",
                        "values": [
                          "SUBTASK_LEVEL",
                          "TASK_LEVEL"
                        ],
                        "description": "Granularity of CodeRabbit validation"
                      },
                      {
                        "name": "coderabbit_units_validated",
                        "type": "integer",
                        "description": "Number of units (subtasks or tasks) validated by CodeRabbit"
                      },
                      {
                        "name": "coderabbit_units_passed",
                        "type": "integer",
                        "description": "Number of units that passed CodeRabbit validation"
                      },
                      {
                        "name": "coderabbit_issues",
                        "type": "integer",
                        "description": "Total number of issues found by CodeRabbit across all units (0 if skipped)"
                      }
                    ]
                  },
                  "examples": [
                    {
                      "name": "Feature review",
                      "input": {
                        "unit_id": "task-001",
                        "base_sha": "abc123",
                        "head_sha": "def456",
                        "implementation_summary": "Added user authentication with JWT",
                        "requirements": "AC-1: User can login, AC-2: Invalid password returns error"
                      },
                      "expected_output": "## Review Summary\n**Status:** PASS\n**Reviewers:** 5/5 PASS\n\n## Issues by Severity\n| Severity | Count |\n|----------|-------|\n| Critical | 0 |\n| High | 0 |\n| Medium | 0 |\n| Low | 2 |\n\n## Reviewer Verdicts\n| Reviewer | Verdict |\n|----------|---------|\n| code-reviewer |  PASS |\n| business-logic-reviewer |  PASS |\n| security-reviewer |  PASS |\n| test-reviewer |  PASS |\n| nil-safety-reviewer |  PASS |\n\n## Handoff to Next Gate\n- Ready for Gate 5: YES\n"
                    }
                  ]
                },
                "content": "# Code Review (Gate 4)\n\n## Overview\n\nDispatch all five reviewer subagents in **parallel** for fast, comprehensive feedback:\n\n1. **code-reviewer** - Architecture, design patterns, code quality\n2. **business-logic-reviewer** - Domain correctness, business rules, edge cases\n3. **security-reviewer** - Vulnerabilities, authentication, OWASP risks\n4. **test-reviewer** - Test quality, coverage, edge cases, anti-patterns\n5. **nil-safety-reviewer** - Nil/null pointer safety for Go and TypeScript\n\n**Core principle:** All 5 reviewers run simultaneously in a single message with 5 Task tool calls.\n\n## CRITICAL: Role Clarification\n\n**This skill ORCHESTRATES. Reviewer Agents REVIEW.**\n\n| Who | Responsibility |\n|-----|----------------|\n| **This Skill** | Dispatch reviewers, aggregate findings, track iterations |\n| **Reviewer Agents** | Analyze code, report issues with severity |\n| **Implementation Agent** | Fix issues found by reviewers |\n\n---\n\n## Step 1: Gather Context (Auto-Detect if Not Provided)\n\n```text\nThis skill supports TWO modes:\n1. WITH INPUTS: Called by any skill/user that provides structured inputs (unit_id, base_sha, etc.)\n2. STANDALONE: Called directly without inputs - auto-detects everything from git\n\nFOR EACH INPUT, check if provided OR auto-detect:\n\n1. unit_id:\n   IF provided  use it\n   ELSE  generate: \"review-\" + timestamp (e.g., \"review-20241222-143052\")\n\n2. base_sha:\n   IF provided  use it\n   ELSE  Execute: git merge-base HEAD main\n   IF git fails  Execute: git rev-parse HEAD~10 (fallback to last 10 commits)\n\n3. head_sha:\n   IF provided  use it\n   ELSE  Execute: git rev-parse HEAD\n\n4. implementation_files:\n   IF provided  use it\n   ELSE  Execute: git diff --name-only [base_sha] [head_sha]\n\n5. implementation_summary:\n   IF provided  use it\n   ELSE  Execute: git log --oneline [base_sha]..[head_sha]\n   Format as: \"Changes: [list of commit messages]\"\n\n6. requirements:\n   IF provided  use it\n   ELSE  Set to: \"Infer requirements from code changes and commit messages\"\n   (Reviewers will analyze code to understand intent)\n\nAFTER AUTO-DETECTION, display context:\n\n  CODE REVIEW CONTEXT                                          \n\n Unit ID: [unit_id]                                              \n Base SHA: [base_sha]                                            \n Head SHA: [head_sha]                                            \n Files Changed: [count] files                                    \n Commits: [count] commits                                        \n                                                                 \n Dispatching 5 reviewers in parallel...                          \n\n```\n\n## Step 2: Initialize Review State\n\n```text\nreview_state = {\n  unit_id: [from input],\n  base_sha: [from input],\n  head_sha: [from input],\n  reviewers: {\n    code_reviewer: {verdict: null, issues: []},\n    business_logic_reviewer: {verdict: null, issues: []},\n    security_reviewer: {verdict: null, issues: []},\n    test_reviewer: {verdict: null, issues: []},\n    nil_safety_reviewer: {verdict: null, issues: []}\n  },\n  aggregated_issues: {\n    critical: [],\n    high: [],\n    medium: [],\n    low: [],\n    cosmetic: []\n  },\n  iterations: 0,\n  max_iterations: 3\n}\n```\n\n## Step 3: Dispatch All 5 Reviewers in Parallel\n\n** CRITICAL: All 5 reviewers MUST be dispatched in a SINGLE message with 5 Task calls.**\n\n```yaml\n# Task 1: Code Reviewer\nTask:\n  subagent_type: \"ring:code-reviewer\"\n  model: \"opus\"\n  description: \"Code review for [unit_id]\"\n  prompt: |\n    ## Code Review Request\n    \n    **Unit ID:** [unit_id]\n    **Base SHA:** [base_sha]\n    **Head SHA:** [head_sha]\n    \n    ## What Was Implemented\n    [implementation_summary]\n    \n    ## Requirements\n    [requirements]\n    \n    ## Files Changed\n    [implementation_files or \"Use git diff\"]\n    \n    ## Your Focus\n    - Architecture and design patterns\n    - Code quality and maintainability\n    - Naming conventions\n    - Error handling patterns\n    - Performance concerns\n    \n    ## Required Output\n    ### VERDICT: PASS / FAIL\n    \n    ### Issues Found\n    | Severity | Description | File:Line | Recommendation |\n    |----------|-------------|-----------|----------------|\n    | [CRITICAL/HIGH/MEDIUM/LOW/COSMETIC] | [issue] | [location] | [fix] |\n    \n    ### What Was Done Well\n    [positive observations]\n\n# Task 2: Business Logic Reviewer\nTask:\n  subagent_type: \"ring:business-logic-reviewer\"\n  model: \"opus\"\n  description: \"Business logic review for [unit_id]\"\n  prompt: |\n    ## Business Logic Review Request\n    \n    **Unit ID:** [unit_id]\n    **Base SHA:** [base_sha]\n    **Head SHA:** [head_sha]\n    \n    ## What Was Implemented\n    [implementation_summary]\n    \n    ## Requirements\n    [requirements]\n    \n    ## Your Focus\n    - Domain correctness\n    - Business rules implementation\n    - Edge cases handling\n    - Requirements coverage\n    - Data validation\n    \n    ## Required Output\n    ### VERDICT: PASS / FAIL\n    \n    ### Issues Found\n    | Severity | Description | File:Line | Recommendation |\n    |----------|-------------|-----------|----------------|\n    | [CRITICAL/HIGH/MEDIUM/LOW/COSMETIC] | [issue] | [location] | [fix] |\n    \n    ### Requirements Traceability\n    | Requirement | Status | Evidence |\n    |-------------|--------|----------|\n    | [req] | / | [file:line] |\n\n# Task 3: Security Reviewer\nTask:\n  subagent_type: \"ring:security-reviewer\"\n  model: \"opus\"\n  description: \"Security review for [unit_id]\"\n  prompt: |\n    ## Security Review Request\n\n    **Unit ID:** [unit_id]\n    **Base SHA:** [base_sha]\n    **Head SHA:** [head_sha]\n\n    ## What Was Implemented\n    [implementation_summary]\n\n    ## Requirements\n    [requirements]\n\n    ## Your Focus\n    - Authentication and authorization\n    - Input validation\n    - SQL injection, XSS, CSRF\n    - Sensitive data handling\n    - OWASP Top 10 risks\n\n    ## Required Output\n    ### VERDICT: PASS / FAIL\n\n    ### Issues Found\n    | Severity | Description | File:Line | OWASP Category | Recommendation |\n    |----------|-------------|-----------|----------------|----------------|\n    | [CRITICAL/HIGH/MEDIUM/LOW] | [issue] | [location] | [A01-A10] | [fix] |\n\n    ### Security Checklist\n    | Check | Status |\n    |-------|--------|\n    | Input validation | / |\n    | Auth checks | / |\n    | No hardcoded secrets | / |\n\n# Task 4: Test Reviewer\nTask:\n  subagent_type: \"ring:test-reviewer\"\n  model: \"opus\"\n  description: \"Test quality review for [unit_id]\"\n  prompt: |\n    ## Test Quality Review Request\n\n    **Unit ID:** [unit_id]\n    **Base SHA:** [base_sha]\n    **Head SHA:** [head_sha]\n\n    ## What Was Implemented\n    [implementation_summary]\n\n    ## Requirements\n    [requirements]\n\n    ## Your Focus\n    - Test coverage for business logic\n    - Edge case testing (empty, null, boundary)\n    - Error path coverage\n    - Test independence and isolation\n    - Assertion quality (not just \"no error\")\n    - Test anti-patterns (testing mock behavior)\n\n    ## Required Output\n    ### VERDICT: PASS / FAIL\n\n    ### Issues Found\n    | Severity | Description | File:Line | Recommendation |\n    |----------|-------------|-----------|----------------|\n    | [CRITICAL/HIGH/MEDIUM/LOW] | [issue] | [location] | [fix] |\n\n    ### Test Coverage Analysis\n    | Test Type | Count | Coverage |\n    |-----------|-------|----------|\n    | Unit | [N] | [areas] |\n    | Integration | [N] | [areas] |\n    | E2E | [N] | [areas] |\n\n# Task 5: Nil-Safety Reviewer\nTask:\n  subagent_type: \"ring:nil-safety-reviewer\"\n  model: \"opus\"\n  description: \"Nil/null safety review for [unit_id]\"\n  prompt: |\n    ## Nil-Safety Review Request\n\n    **Unit ID:** [unit_id]\n    **Base SHA:** [base_sha]\n    **Head SHA:** [head_sha]\n    **Languages:** [Go|TypeScript|both - detect from files]\n\n    ## What Was Implemented\n    [implementation_summary]\n\n    ## Requirements\n    [requirements]\n\n    ## Your Focus\n    - Nil/null pointer risks in changed code\n    - Missing nil guards before dereference\n    - Map access without ok check (Go)\n    - Type assertions without ok check (Go)\n    - Optional chaining misuse (TypeScript)\n    - Error-then-use patterns\n\n    ## Required Output\n    ### VERDICT: PASS / FAIL\n\n    ### Issues Found\n    | Severity | Description | File:Line | Recommendation |\n    |----------|-------------|-----------|----------------|\n    | [CRITICAL/HIGH/MEDIUM/LOW] | [issue] | [location] | [fix] |\n\n    ### Nil Risk Trace\n    [For each risk: Source  Propagation  Dereference point]\n```\n\n## Step 4: Wait for All Reviewers and Parse Output\n\n```text\nWait for all 5 Task calls to complete.\n\nFor each reviewer:\n1. Extract VERDICT (PASS/FAIL)\n2. Extract Issues Found table\n3. Categorize issues by severity\n\nreview_state.reviewers.code_reviewer = {\n  verdict: [PASS/FAIL],\n  issues: [parsed issues]\n}\n// ... same for other reviewers\n\nAggregate all issues by severity:\nreview_state.aggregated_issues.critical = [all critical from all reviewers]\nreview_state.aggregated_issues.high = [all high from all reviewers]\n// ... etc\n```\n\n## Step 5: Handle Results by Severity\n\n```text\nCount blocking issues:\nblocking_count = critical.length + high.length + medium.length\n\nIF blocking_count == 0:\n   All reviewers PASS\n   Proceed to Step 8 (Success)\n\nIF blocking_count > 0:\n   review_state.iterations += 1\n   IF iterations >= max_iterations: Go to Step 9 (Escalate)\n   Go to Step 6 (Dispatch Fixes)\n```\n\n## Step 6: Dispatch Fixes to Implementation Agent\n\n** CRITICAL: You are an ORCHESTRATOR. You CANNOT edit source files directly.**\n**You MUST dispatch the implementation agent to fix ALL review issues.**\n\n### Orchestrator Boundaries (HARD GATE)\n\n**See [dev-team/skills/shared-patterns/standards-boundary-enforcement.md](../../dev-team/skills/shared-patterns/standards-boundary-enforcement.md) for core enforcement rules.**\n\n**Key prohibition:** Edit/Write/Create on source files is FORBIDDEN. Always dispatch agent.\n\n**If you catch yourself about to use Edit/Write/Create on source files  STOP. Dispatch agent.**\n\n### Dispatch Implementation Agent\n\n```yaml\nTask:\n  subagent_type: \"[implementation_agent from Gate 0]\"\n  model: \"opus\"\n  description: \"Fix review issues for [unit_id]\"\n  prompt: |\n     FIX REQUIRED - Code Review Issues Found\n\n    ## Context\n    - **Unit ID:** [unit_id]\n    - **Iteration:** [iterations] of [max_iterations]\n\n    ## Critical Issues (MUST FIX)\n    [list critical issues with file:line and recommendation]\n\n    ## High Issues (MUST FIX)\n    [list high issues]\n\n    ## Medium Issues (MUST FIX)\n    [list medium issues]\n\n    ## Requirements\n    1. Fix ALL Critical, High, and Medium issues\n    2. Run tests to verify fixes\n    3. Commit fixes with descriptive message\n    4. Return list of fixed issues with evidence\n\n    ## For Low/Cosmetic Issues\n    Add TODO/FIXME comments:\n    - Low: `// TODO(review): [Issue] - [reviewer] on [date]`\n    - Cosmetic: `// FIXME(nitpick): [Issue] - [reviewer] on [date]`\n```\n\n### Anti-Rationalization for Direct Editing\n\n**See [shared-patterns/orchestrator-direct-editing-anti-rationalization.md](../shared-patterns/orchestrator-direct-editing-anti-rationalization.md) for complete anti-rationalization table.**\n\n*Applies to: Step 6 (Fix dispatch after Ring reviewers) & Step 7.5.3 (Fix dispatch after CodeRabbit)*\n\n## Step 7: Re-Run All Reviewers After Fixes\n\n```text\nAfter fixes committed:\n1. Get new HEAD_SHA\n2. Go back to Step 3 (dispatch all 5 reviewers again)\n\n CRITICAL: Always re-run ALL 5 reviewers after fixes.\nDo NOT cherry-pick reviewers.\n```\n\n## Step 7.5: CodeRabbit CLI Validation (Per-Subtask/Task)\n\n** NEW APPROACH: CodeRabbit validates EACH subtask/task as it completes, accumulating findings to a file.**\n\n### CodeRabbit Integration Overview\n\n```text\n\n CODERABBIT PER-UNIT VALIDATION FLOW                             \n\n                                                                 \n DURING REVIEW (after each subtask/task Ring reviewers pass):   \n   1. Run CodeRabbit for that unit's files                      \n   2. Append findings to .coderabbit-findings.md                \n   3. Continue to next unit                                     \n                                                                 \n BEFORE COMMIT (Step 8):                                        \n   1. Display accumulated .coderabbit-findings.md               \n   2. User decides: fix issues OR acknowledge and proceed       \n                                                                 \n BENEFITS:                                                      \n    Catches issues close to when code was written              \n    Smaller scope = faster reviews (7-30 min per unit)         \n    Issues isolated to specific units, easier to fix           \n    Accumulated file provides audit trail                      \n                                                                 \n\n```\n\n### Rate Limits (Official - per developer per repository per hour)\n\n| Limit Type | Value | Notes |\n|------------|-------|-------|\n| Files reviewed | 200 files/hour | Per review |\n| Reviews | 3 back-to-back, then 4/hour | **7 reviews possible in first hour** |\n| Conversations | 25 back-to-back, then 50/hour | For follow-up questions |\n\n** TIMING:** Each CodeRabbit review takes **7-30+ minutes** depending on scope.\nRun in background and check periodically for completion.\n\n### Common Commands Reference\n\n<a id=\"coderabbit-install-check\"></a>\n**CodeRabbit Installation Check:**\n```bash\nwhich coderabbit || which cr\n```\n> Used in Step 7.5.1 and after installation to verify CLI availability.\n\n---\n\n###  PREREQUISITES & ENVIRONMENT REQUIREMENTS\n\n**Before attempting Step 7.5, verify your environment supports the required operations:**\n\n| Requirement | Local Dev | CI/CD | Containerized | Remote/SSH |\n|-------------|-----------|-------|---------------|------------|\n| `curl \\| sh` install |  Yes |  May require elevated permissions |  Often blocked |  Depends on config |\n| Browser auth (`coderabbit auth login`) |  Yes |  No browser |  No browser |  No browser |\n| Write to `$HOME/.coderabbit/` |  Yes |  Ephemeral |  Ephemeral |  Usually |\n| Internet access to `cli.coderabbit.ai` |  Yes |  Check firewall |  Check firewall |  Check firewall |\n\n** HARD STOP CONDITIONS - Skip Step 7.5 if ANY apply:**\n- Running in containerized environment without persistent storage\n- CI/CD pipeline without pre-installed CodeRabbit CLI\n- Non-interactive environment (no TTY for browser auth)\n- Network restrictions blocking `cli.coderabbit.ai`\n- Read-only filesystem\n\n### Environment-Specific Guidance\n\n#### Local Development (RECOMMENDED)\nStandard flow works: `curl | sh` install + browser authentication.\n\n#### CI/CD Pipelines\n**Option A: Pre-install in CI image**\n```dockerfile\n# Add to your CI Dockerfile\nRUN curl -fsSL https://cli.coderabbit.ai/install.sh | sh\n```\n\n**Option B: Use API token authentication (headless)**\n```bash\n# Set token via environment variable (add to CI secrets)\nexport CODERABBIT_API_TOKEN=\"your-api-token\"\ncoderabbit auth login --token \"$CODERABBIT_API_TOKEN\"\n```\n\n**Option C: Skip CodeRabbit in CI, run locally**\n```bash\n# In CI config, set env var to auto-skip\nexport SKIP_CODERABBIT_REVIEW=true\n```\n\n#### Containerized/Docker Environments\n```bash\n# Option 1: Mount credentials from host\ndocker run -v ~/.coderabbit:/root/.coderabbit ...\n\n# Option 2: Pass token as env var\ndocker run -e CODERABBIT_API_TOKEN=\"...\" ...\n\n# Option 3: Pre-bake into image (not recommended for tokens)\n```\n\n#### Non-Interactive/Headless Authentication\n```bash\n# Generate API token at: https://app.coderabbit.ai/settings/api-tokens\n# Then authenticate without browser:\ncoderabbit auth login --token \"cr_xxxxxxxxxxxxx\"\n```\n\n---\n\n### Step 7.5 Flow Logic\n\n```text\n\n  ALL 3 RING REVIEWERS PASSED                                  \n\n                                                                 \n Checking CodeRabbit CLI availability...                         \n                                                                 \n CodeRabbit provides additional AI-powered code review that      \n catches race conditions, memory leaks, security vulnerabilities,\n and edge cases that may complement Ring reviewers.              \n                                                                 \n\n```\n\n** HARD GATE: CodeRabbit Execution Rules (NON-NEGOTIABLE)**\n\n| Scenario | Rule | Action |\n|----------|------|--------|\n| **Installed & authenticated** | **MANDATORY** - CANNOT skip | Run CodeRabbit review, no prompt |\n| **Not installed** | **MUST ask** user about installation | Present installation option |\n| **User declines installation** | Optional - can proceed | Skip and continue to Step 8 |\n\n**Why this distinction:**\n- If CodeRabbit IS installed  User has committed to using it  MUST run\n- If CodeRabbit is NOT installed  User choice to add it  MUST ask, but can decline\n\n```text\nFLOW:\n1. Run CodeRabbit Installation Check\n2. IF installed AND authenticated  Run CodeRabbit (MANDATORY, NO prompt, CANNOT skip)\n3. IF installed BUT NOT authenticated  Guide authentication (REQUIRED before proceeding)\n4. IF NOT installed  MUST ask user about installation (REQUIRED prompt)\n5. IF user declines installation  Skip CodeRabbit, proceed to Step 8 (only valid skip path)\n```\n\n### Anti-Rationalization for CodeRabbit Execution\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"CodeRabbit is optional, I'll skip it\" | If installed, it's MANDATORY. Optional only means installation is optional. | **Run CodeRabbit if installed** |\n| \"Ring reviewers passed, that's enough\" | Different tools catch different issues. CodeRabbit complements Ring. | **Run CodeRabbit if installed** |\n| \"User didn't ask for CodeRabbit\" | User installed it. Installation = consent to mandatory execution. | **Run CodeRabbit if installed** |\n| \"Takes too long, skip this time\" | Time is irrelevant. Installed = mandatory. | **Run CodeRabbit if installed** |\n| \"I'll just proceed without asking about install\" | MUST ask every user if they want to install. No silent skips. | **Ask user about installation** |\n\n#### Step 7.5.1: Check CodeRabbit Installation\n\nRun the [CodeRabbit Installation Check](#coderabbit-install-check) command.\n\n**IF INSTALLED AND AUTHENTICATED  MANDATORY EXECUTION (CANNOT SKIP):**\n```text\n\n  CodeRabbit CLI detected - MANDATORY EXECUTION                \n\n                                                                 \n CodeRabbit CLI is installed and authenticated.                  \n                                                                 \n  CodeRabbit review is MANDATORY when installed.               \n    This step CANNOT be skipped. Proceeding automatically...     \n                                                                 \n\n```\n Proceed directly to Step 7.5.2 (Run CodeRabbit Review) - **NO user prompt, NO skip option**\n\n**IF NOT INSTALLED  MUST ASK USER (REQUIRED PROMPT):**\n\n** You MUST present this prompt to the user. Silent skips are FORBIDDEN.**\n\n```text\n\n   CodeRabbit CLI not found - INSTALLATION PROMPT REQUIRED     \n\n                                                                 \n CodeRabbit CLI is not installed on your system.                 \n                                                                 \n CodeRabbit provides additional AI-powered review that catches:  \n    Race conditions and concurrency issues                      \n    Memory leaks and resource management                        \n    Security vulnerabilities                                    \n    Edge cases missed by other reviewers                        \n                                                                 \n  You MUST choose one of the following options:                \n                                                                 \n   (a) Yes, install CodeRabbit CLI (I'll guide you)              \n   (b) No, skip CodeRabbit and proceed to Gate 5                 \n                                                                 \n   ENVIRONMENT CHECK:                                          \n      Interactive terminal with browser?  Standard install     \n      CI/headless?  Requires API token auth                    \n      Container?  See Environment-Specific Guidance above      \n                                                                 \n\n```\n\n**If user selects (a) Yes, install:**\n Proceed to Installation Flow below\n\n**If user selects (b) No, skip:**\n```text\n Record: \"CodeRabbit review: SKIPPED (not installed, user declined installation)\"\n Proceed to Step 8 (Success Output)\n This is the ONLY valid path to skip CodeRabbit\n```\n\n#### Step 7.5.1a: CodeRabbit Installation Flow\n\n```text\n\n  INSTALLING CODERABBIT CLI                                    \n\n                                                                 \n   ENVIRONMENT CHECK FIRST:                                    \n                                                                 \n This installation requires:                                     \n    curl command available                                      \n    Write access to $HOME or /usr/local/bin                     \n    Internet access to cli.coderabbit.ai                        \n    Non-containerized environment (or persistent storage)       \n                                                                 \n If in CI/container, see \"Environment-Specific Guidance\" above.  \n                                                                 \n\n```\n\n**Check environment before proceeding:**\n```bash\n# Verify prerequisites\ncurl --version && echo \"curl: OK\" || echo \"curl: MISSING\"\ntest -w \"$HOME\" && echo \"HOME writable: OK\" || echo \"HOME writable: NO\"\ncurl -sI https://cli.coderabbit.ai | head -1 | grep -q \"200\\|301\\|302\" && echo \"Network: OK\" || echo \"Network: BLOCKED\"\n```\n\n**If prerequisites pass, install:**\n```text\n\n  Step 1: Installing CodeRabbit CLI...                         \n\n```\n\n```bash\n# Step 1: Download and install CodeRabbit CLI\ncurl -fsSL https://cli.coderabbit.ai/install.sh | sh\n```\n\n**After installation, verify:** Run the [CodeRabbit Installation Check](#coderabbit-install-check) command.\n\n**If installation successful:**\n```text\n\n  CodeRabbit CLI installed successfully!                       \n\n                                                                 \n Step 2: Authentication required                                 \n                                                                 \n Choose your authentication method:                              \n                                                                 \n   (a) Browser login (interactive - opens browser)               \n        Best for: Local development with GUI                    \n        Command: coderabbit auth login                          \n                                                                 \n   (b) API token (headless - no browser needed)                  \n        Best for: CI/CD, containers, SSH sessions               \n        Get token: https://app.coderabbit.ai/settings/api-tokens\n        Command: coderabbit auth login --token \"cr_xxx\"         \n                                                                 \n   (c) Skip authentication and CodeRabbit review                 \n                                                                 \n Note: Free tier allows 1 review/hour.                           \n       Paid plans get enhanced reviews + higher limits.          \n                                                                 \n\n```\n\n**If user selects (a) Browser login:**\n```bash\n# Step 2a: Authenticate with CodeRabbit (opens browser)\n#  Requires: GUI environment with default browser\ncoderabbit auth login\n```\n\n**If user selects (b) API token:**\n```bash\n# Step 2b: Authenticate with API token (headless)\n# Get your token from: https://app.coderabbit.ai/settings/api-tokens\ncoderabbit auth login --token \"cr_xxxxxxxxxxxxx\"\n```\n\n**After authentication:**\n```text\n\n  CodeRabbit CLI ready!                                        \n\n                                                                 \n Installation: Complete                                          \n Authentication: Complete                                        \n                                                                 \n Proceeding to CodeRabbit review...                              \n                                                                 \n\n```\n\n Proceed to Step 7.5.2 (Run CodeRabbit Review)\n\n**If installation failed:**\n```text\n\n  CodeRabbit CLI installation failed                           \n\n                                                                 \n Error: [error message from curl/sh]                             \n                                                                 \n Troubleshooting:                                                \n    Check internet connection                                   \n    Try manual install: https://docs.coderabbit.ai/cli/overview \n    macOS/Linux only (Windows not supported yet)                \n                                                                 \n Would you like to:                                              \n   (a) Retry installation                                        \n   (b) Skip CodeRabbit and proceed to Gate 5                     \n                                                                 \n\n```\n\n#### Step 7.5.2: Run CodeRabbit Review\n\n** GRANULAR VALIDATION: CodeRabbit MUST validate at the most granular level available.**\n\n```text\nDETERMINE VALIDATION SCOPE:\n1. Check if current work has subtasks (from gate0_handoff or implementation context)\n2. IF subtasks exist  Validate EACH SUBTASK separately\n3. IF no subtasks  Validate the TASK as a whole\n\nWHY GRANULAR VALIDATION:\n- Subtask-level validation catches issues early\n- Easier to pinpoint which subtask introduced problems\n- Prevents \"works for task A, breaks task B\" scenarios\n- Enables incremental fixes without re-running entire review\n```\n\n**Step 7.5.2a: Determine Validation Scope**\n\n```text\nvalidation_scope = {\n  mode: null,  // \"subtask\" or \"task\"\n  units: [],   // list of {id, files, commits} to validate\n  current_index: 0\n}\n\nIF gate0_handoff.subtasks exists AND gate0_handoff.subtasks.length > 0:\n   validation_scope.mode = \"subtask\"\n   FOR EACH subtask in gate0_handoff.subtasks:\n       Get files changed by this subtask (from commits or file mapping)\n       Add to validation_scope.units: {\n          id: subtask.id,\n          name: subtask.name,\n          files: [files touched by this subtask],\n          base_sha: [sha before subtask],\n          head_sha: [sha after subtask]\n        }\n  \n  Display:\n  \n    CODERABBIT VALIDATION MODE: SUBTASK-LEVEL                    \n  \n                                                                   \n   Detected [N] subtasks. Will validate each separately:          \n                                                                   \n     1. [subtask-1-id]: [subtask-1-name]                          \n        Files: [file1.go, file2.go]                               \n                                                                   \n     2. [subtask-2-id]: [subtask-2-name]                          \n        Files: [file3.go, file4.go]                               \n                                                                   \n     ... (up to N subtasks)                                       \n                                                                   \n  \n\nELSE:\n   validation_scope.mode = \"task\"\n   Add single unit: {\n      id: unit_id,\n      name: implementation_summary,\n      files: implementation_files,\n      base_sha: base_sha,\n      head_sha: head_sha\n    }\n  \n  Display:\n  \n    CODERABBIT VALIDATION MODE: TASK-LEVEL                       \n  \n                                                                   \n   No subtasks detected. Validating entire task:                  \n                                                                   \n     Task: [unit_id]                                              \n     Files: [N] files changed                                     \n                                                                   \n  \n```\n\n**Step 7.5.2b: Run CodeRabbit for Each Validation Unit**\n\n```text\ncoderabbit_results = {\n  overall_status: \"PASS\",  // PASS only if ALL units pass\n  units: []\n}\n\nFOR EACH unit IN validation_scope.units:\n  Display:\n  \n    VALIDATING: [unit.id] ([current]/[total])                    \n  \n   Name: [unit.name]                                              \n   Files: [unit.files.join(\", \")]                                 \n  \n```\n\n```bash\n# Run CodeRabbit review\n#  TIMING: 7-30+ minutes per review. Run in background if possible.\n\n# Compare against base branch\ncoderabbit --prompt-only --type uncommitted --base [base_branch]\n\n# Compare against specific commit on current branch\ncoderabbit --prompt-only --type uncommitted --base-commit [unit.base_sha]\n\n# The command is synchronous - it completes when output is returned\n```\n\n```text\n  Parse output and record:\n  unit_result = {\n    id: unit.id,\n    status: \"PASS\" | \"ISSUES_FOUND\",\n    issues: {\n      critical: [list],\n      high: [list],\n      medium: [list],\n      low: [list]\n    }\n  }\n  \n  coderabbit_results.units.push(unit_result)\n  \n  IF unit_result.issues.critical.length > 0 OR unit_result.issues.high.length > 0:\n     coderabbit_results.overall_status = \"ISSUES_FOUND\"\n  \n  \n   MANDATORY: APPEND FINDINGS TO .coderabbit-findings.md\n  \n  \n  After EACH unit validation, append results to findings file:\n  \n  IF .coderabbit-findings.md does NOT exist:\n     Create file with header (see \"Findings File Format\" below)\n  \n  APPEND to .coderabbit-findings.md:\n  ```\n  ## Unit: [unit.id] - [unit.name]\n  **Validated:** [timestamp]\n  **Status:** [PASS | ISSUES_FOUND]\n  **Files:** [unit.files.join(\", \")]\n  \n  ### Issues Found\n  | # | Severity | Description | File:Line | Recommendation |\n  |---|----------|-------------|-----------|----------------|\n  | 1 | [severity] | [description] | [file:line] | [recommendation] |\n  | ... | ... | ... | ... | ... |\n  \n  ---\n  ```\n  \n  This ensures ALL findings are accumulated for review before commit.\n\nAFTER ALL UNITS VALIDATED:\n  Display summary:\n  \n    CODERABBIT VALIDATION SUMMARY                                \n  \n   Mode: [SUBTASK-LEVEL | TASK-LEVEL]                             \n   Units Validated: [N]                                           \n   Overall Status: [PASS | ISSUES_FOUND]                          \n                                                                   \n   Per-Unit Results:                                              \n        \n    Unit ID       Status      Crit  High  Medium  Low      \n        \n    [subtask-1]    PASS      0     0      0      1       \n    [subtask-2]    ISSUES    1     2      0      0       \n        \n                                                                   \n  \n```\n\n**Parse CodeRabbit output for:**\n- Critical issues\n- High severity issues\n- Security vulnerabilities\n- Performance concerns\n\n### Findings File Format (.coderabbit-findings.md)\n\n**This file accumulates ALL CodeRabbit findings across all validated units.**\n\n```markdown\n# CodeRabbit Findings\n\n**Generated:** [initial timestamp]\n**Last Updated:** [latest timestamp]\n**Total Units Validated:** [N]\n**Overall Status:** [PASS | ISSUES_FOUND]\n\n## Summary\n\n| Severity | Count | Status |\n|----------|-------|--------|\n| Critical | [N] | [N pending / N fixed] |\n| High | [N] | [N pending / N fixed] |\n| Medium | [N] | [N pending / N fixed] |\n| Low | [N] | [N pending / N fixed] |\n\n---\n\n## Unit: [subtask-1-id] - [subtask-1-name]\n**Validated:** [timestamp]\n**Status:** [PASS | ISSUES_FOUND]\n**Files:** [file1.go, file2.go]\n\n### Issues Found\n| # | Severity | Description | File:Line | Recommendation | Status |\n|---|----------|-------------|-----------|----------------|--------|\n| 1 | CRITICAL | Race condition in handler | handler.go:45 | Use sync.Mutex | PENDING |\n| 2 | HIGH | Unchecked error return | repo.go:123 | Handle error | PENDING |\n\n---\n\n## Unit: [subtask-2-id] - [subtask-2-name]\n**Validated:** [timestamp]\n**Status:** PASS\n**Files:** [file3.go]\n\n### Issues Found\n_No issues found._\n\n---\n\n[... additional units ...]\n```\n\n**File Location:** Project root (`.coderabbit-findings.md`)\n\n**Lifecycle:**\n1. Created when first CodeRabbit validation runs\n2. Appended after each unit validation\n3. Displayed before commit (Step 8)\n4. User decides: fix issues or acknowledge and proceed\n5. After commit, file can be deleted or kept for audit\n\n#### Step 7.5.3: Handle CodeRabbit Findings\n\n** CRITICAL: You are an ORCHESTRATOR. You CANNOT edit source files directly.**\n**You MUST dispatch the implementation agent to fix issues.**\n\n** GRANULAR FIX DISPATCH: Fixes MUST be dispatched per-unit (subtask or task).**\n\n```text\nIF coderabbit_results.overall_status == \"ISSUES_FOUND\":\n  \n   FIRST: Display EACH issue in detail (REQUIRED before any action):\n  \n     CODERABBIT ISSUES FOUND - DETAILED DESCRIPTION               \n  \n                                                                   \n   UNIT: [subtask-1] - [subtask name]                             \n   \n   Issue #1 [CRITICAL]                                            \n     Description: Race condition in concurrent request handler    \n     File: src/handler.go:45                                      \n     Code Context:                                                \n       43 | func (h *Handler) Process(ctx context.Context) {      \n       44 |     h.counter++  //  NOT THREAD-SAFE                 \n       45 |     data := h.sharedMap[key]                          \n     Why it matters: Multiple goroutines can corrupt shared state \n     Recommendation: Use sync.Mutex or atomic operations          \n                                                                   \n   Issue #2 [HIGH]                                                \n     Description: Unchecked error return from database query      \n     File: src/repo.go:123                                        \n     Code Context:                                                \n       121 | func (r *Repo) GetUser(id string) (*User, error) {   \n       122 |     result, _ := r.db.Query(query, id)  //  IGNORED \n       123 |     return parseUser(result), nil                    \n     Why it matters: Silent failures can cause data corruption    \n     Recommendation: Check and handle the error properly          \n                                                                   \n   UNIT: [subtask-2] - [subtask name]                             \n   \n   Issue #3 [HIGH]                                                \n     Description: SQL injection vulnerability                     \n     File: src/query.go:89                                        \n     Code Context:                                                \n       87 | func BuildQuery(userInput string) string {            \n       88 |     return fmt.Sprintf(\"SELECT * FROM users WHERE     \n       89 |            name = '%s'\", userInput)  //  INJECTABLE  \n     Why it matters: Attacker can execute arbitrary SQL           \n     Recommendation: Use parameterized queries                    \n                                                                   \n  \n  \n   THEN: Ask user for action:\n  \"CodeRabbit found [N] issues in [M] units. What would you like to do?\"\n    (a) Fix all issues - dispatch implementation agent per unit\n    (b) Proceed to Gate 5 (acknowledge risk)\n    (c) Review findings in detail (show code context)\n\n  IF user selects (a) Fix issues:\n      DO NOT edit files directly\n     FOR EACH unit WITH issues (validation_scope.units where status == \"ISSUES_FOUND\"):\n    \n        Display:\n        \n          DISPATCHING FIX: [unit.id] ([current]/[total with issues])   \n        \n         Unit: [unit.name]                                              \n         Critical Issues: [N]                                           \n         High Issues: [N]                                               \n        \n        \n         DISPATCH implementation agent with unit-specific findings:\n        \n        Task:\n          subagent_type: \"[same agent used in Gate 0]\"\n          model: \"opus\"\n          description: \"Fix CodeRabbit issues for [unit.id]\"\n          prompt: |\n            ## CodeRabbit Issues to Fix - [unit.id]\n            \n            **Scope:** This fix is for [subtask/task]: [unit.name]\n            **Files in Scope:** [unit.files.join(\", \")]\n            \n            The following issues were found by CodeRabbit CLI external review\n            for THIS SPECIFIC [subtask/task].\n            \n             IMPORTANT: Only fix issues in files belonging to this unit:\n            [unit.files list]\n            \n            ### Critical Issues\n            [list from unit.issues.critical]\n            \n            ### High Issues  \n            [list from unit.issues.high]\n            \n            ## Requirements\n            1. Fix each issue following Ring Standards\n            2. Only modify files in scope: [unit.files]\n            3. Run tests to verify fixes don't break functionality\n            4. Commit fixes with message referencing unit: \"fix([unit.id]): [description]\"\n        \n         Wait for agent to complete\n         Record fix result for this unit\n        \n         VALIDATE EACH ISSUE INDIVIDUALLY:\n        \n          VALIDATING FIXES FOR: [unit.id]                              \n        \n                                                                         \n         Each issue MUST be validated individually:                      \n                                                                         \n         Issue #1: [issue description]                                   \n           File: [file:line]                                            \n           Severity: CRITICAL                                           \n           Fix Applied: [description of fix]                            \n           Validation:  RESOLVED /  NOT RESOLVED                     \n           Evidence: [code snippet or test result]                      \n                                                                         \n         Issue #2: [issue description]                                   \n           File: [file:line]                                            \n           Severity: HIGH                                               \n           Fix Applied: [description of fix]                            \n           Validation:  RESOLVED /  NOT RESOLVED                     \n           Evidence: [code snippet or test result]                      \n                                                                         \n         ... (repeat for ALL issues)                                    \n                                                                         \n        \n        \n         IF any issue NOT RESOLVED:\n             Identify the correct agent for re-dispatch:\n              - Check gate0_handoff.implementation_agent (if available)\n              - OR infer from file type:\n                - *.go files  ring:backend-engineer-golang\n                - *.ts files (backend)  ring:backend-engineer-typescript\n                - *.ts/*.tsx files (frontend)  ring:frontend-engineer\n                - *.yaml/*.yml (infra)  ring:devops-engineer\n            \n             Re-dispatch ONLY unresolved issues to the correct agent:\n            \n            Task:\n              subagent_type: \"[correct agent based on file type or gate0_handoff]\"\n              model: \"opus\"\n              description: \"Retry fix for unresolved issues in [unit.id]\"\n              prompt: |\n                ## RETRY: Unresolved CodeRabbit Issues - [unit.id]\n                \n                Previous fix attempt did NOT resolve these issues.\n                This is attempt [N] of 2 maximum.\n                \n                ### Unresolved Issues (MUST FIX)\n                | # | Severity | Description | File:Line | Previous Attempt | Why It Failed |\n                |---|----------|-------------|-----------|------------------|---------------|\n                | [issue.id] | [severity] | [description] | [file:line] | [what was tried] | [why not resolved] |\n                \n                ### Requirements\n                1. Review the previous fix attempt and understand why it failed\n                2. Apply a different/better solution\n                3. Verify the fix resolves the issue\n                4. Run relevant tests\n                5. Commit with message: \"fix([unit.id]): retry [issue description]\"\n            \n             Max 2 fix attempts per issue\n             IF issue still NOT RESOLVED after 2 attempts:\n                 Mark as UNRESOLVED_ESCALATE\n                 Add to escalation report for manual review\n        \n         Record per-issue validation results:\n        unit_validation = {\n          id: unit.id,\n          issues_validated: [\n            {\n              issue_id: 1,\n              description: \"[issue]\",\n              severity: \"CRITICAL\",\n              file: \"[file:line]\",\n              fix_applied: \"[description]\",\n              status: \"RESOLVED\" | \"NOT_RESOLVED\",\n              evidence: \"[snippet or test]\",\n              attempts: 1\n            },\n            ...\n          ],\n          all_resolved: true | false\n        }\n    \n     AFTER ALL UNITS FIXED:\n        Display:\n        \n          FIX DISPATCH COMPLETE                                        \n        \n         Units Fixed: [N] / [total with issues]                         \n         Total Issues Validated: [N]                                    \n         Issues Resolved: [N] / [N]                                     \n                                                                         \n         Per-Unit Fix Status:                                           \n                   \n          Unit ID       Status      Commit                          \n                   \n          [subtask-1]    FIXED    abc123                          \n          [subtask-2]    FIXED    def456                          \n                   \n                                                                         \n         Issue-Level Validation Details:                                \n            \n          UNIT: [subtask-1]                                           \n            \n          #1 [CRITICAL] Race condition in handler                     \n             File: src/handler.go:45                                  \n             Fix: Added mutex lock                                    \n             Status:  RESOLVED                                      \n             Evidence: Test race_test.go passes                       \n            \n          #2 [HIGH] Unchecked error return                            \n             File: src/handler.go:67                                  \n             Fix: Added error check with proper handling              \n             Status:  RESOLVED                                      \n             Evidence: Error path verified in unit test               \n            \n                                                                         \n        \n\nLEGACY FLOW (when validation_scope.mode == \"task\"):\n  IF CodeRabbit found CRITICAL or HIGH issues:\n     Display findings to user\n     Ask: \"CodeRabbit found [N] critical/high issues. Fix now or proceed anyway?\"\n      (a) Fix issues - dispatch to implementation agent\n      (b) Proceed to Gate 5 (acknowledge risk)\n      (c) Review findings in detail\n\n    IF user selects (a) Fix issues:\n        DO NOT edit files directly\n       DISPATCH implementation agent with CodeRabbit findings:\n      \n      Task:\n        subagent_type: \"[same agent used in Gate 0]\"\n        model: \"opus\"\n        description: \"Fix CodeRabbit issues for [unit_id]\"\n        prompt: |\n          ## CodeRabbit Issues to Fix\n          \n          The following issues were found by CodeRabbit CLI external review.\n          Fix ALL Critical and High severity issues.\n          \n          ### Critical Issues\n          [list from CodeRabbit output]\n          \n          ### High Issues\n          [list from CodeRabbit output]\n          \n          ## Requirements\n          1. Fix each issue following Ring Standards\n          2. Run tests to verify fixes don't break functionality\n          3. Commit fixes with descriptive message\n    \n     After agent completes, re-run CodeRabbit: `coderabbit --prompt-only`\n     If CodeRabbit issues remain, repeat fix cycle (max 2 iterations for CodeRabbit)\n    \n      AFTER CodeRabbit passes, MUST re-run Ring reviewers:\n    \n    \n      RE-RUNNING RING REVIEWERS AFTER CODERABBIT FIXES             \n    \n                                                                     \n     CodeRabbit fixes may have introduced new issues detectable by   \n     Ring reviewers. Re-validation is MANDATORY before Gate 5.       \n                                                                     \n    \n    \n    Step 7.5.3a: Re-Run All 5 Ring Reviewers\n    \n    1. Get new HEAD_SHA after CodeRabbit fixes\n    2. Dispatch all 5 reviewers in parallel (per Step 3):\n       - code-reviewer\n       - business-logic-reviewer\n       - security-reviewer\n       - test-reviewer\n       - nil-safety-reviewer\n    3. Wait for all 5 to complete\n    \n    Step 7.5.3b: Handle Ring Reviewer Results\n    \n    IF all 5 Ring reviewers PASS:\n       Proceed to Step 8 (Success Output)\n    \n    IF any Ring reviewer finds CRITICAL/HIGH/MEDIUM issues:\n       Increment ring_revalidation_iterations counter\n       IF ring_revalidation_iterations >= 2:\n           ESCALATE: \"Max iterations reached after CodeRabbit fixes\"\n           Go to Step 9 (Escalate)\n       DISPATCH implementation agent to fix Ring reviewer issues\n       After fixes committed:\n           Re-run CodeRabbit: `coderabbit --prompt-only`\n           IF CodeRabbit passes:\n               Re-run all 5 Ring reviewers (loop back to Step 7.5.3a)\n           IF CodeRabbit finds issues:\n               Fix CodeRabbit issues first, then re-run Ring reviewers\n    \n    State tracking for CodeRabbit fix cycle:\n    ```\n    coderabbit_fix_state = {\n      coderabbit_iterations: 0,      // max 2 for CodeRabbit-only fixes\n      ring_revalidation_iterations: 0,  // max 2 for Ring reviewer re-runs\n      total_max_iterations: 4        // absolute cap: 2 CR + 2 Ring\n    }\n    ```\n\nIF CodeRabbit found only MEDIUM/LOW issues:\n   Display summary\n    DO NOT edit files directly to add TODOs\n   DISPATCH implementation agent to add TODO comments:\n  \n  Task:\n    subagent_type: \"[same agent used in Gate 0]\"\n    description: \"Add TODO comments for CodeRabbit findings\"\n    prompt: |\n      Add TODO comments for these CodeRabbit findings:\n      [list MEDIUM/LOW issues with file:line]\n      \n      Format: // TODO(coderabbit): [issue description]\n  \n   After TODO comments added (code changed):\n       Re-run all 5 Ring reviewers (per Step 7.5.3a above)\n       IF Ring reviewers PASS: Proceed to Step 8\n       IF Ring reviewers find issues: Fix and re-run (max 2 iterations)\n\nIF CodeRabbit found no issues:\n   Display: \" CodeRabbit review passed - no additional issues found\"\n   No code changes made by CodeRabbit flow\n   Proceed directly to Step 8 (no Ring re-run needed)\n```\n\n### Anti-Rationalization for Direct Editing\n\n**See [shared-patterns/orchestrator-direct-editing-anti-rationalization.md](../shared-patterns/orchestrator-direct-editing-anti-rationalization.md) - same table applies here.**\n\n*Applies to: Step 6 (Fix dispatch after Ring reviewers) & Step 7.5.3 (Fix dispatch after CodeRabbit)*\n\n#### Step 7.5.4: CodeRabbit Results Summary\n\n```markdown\n## CodeRabbit External Review\n**Status:** [PASS|ISSUES_FOUND|SKIPPED]\n**Validation Mode:** [SUBTASK-LEVEL|TASK-LEVEL]\n**Units Validated:** [N]\n**Total Issues Found:** [N]\n**Issues Resolved:** [N]/[N]\n\n### Per-Unit Validation Results\n| Unit ID | Unit Name | Status | Critical | High | Medium | Low |\n|---------|-----------|--------|----------|------|--------|-----|\n| [subtask-1] | [name] |  PASS | 0 | 0 | 0 | 1 |\n| [subtask-2] | [name] |  FIXED | 10 | 20 | 0 | 0 |\n| [task-id] | [name] |  PASS | 0 | 0 | 0 | 0 |\n\n### Issues Found - Detailed Description (ALWAYS shown when issues exist)\n\n#### Unit: [subtask-2]\n| # | Severity | Description | File:Line | Code Context | Why It Matters | Recommendation |\n|---|----------|-------------|-----------|--------------|----------------|----------------|\n| 1 | CRITICAL | Race condition | handler.go:45 | `h.counter++` not thread-safe | Corrupts shared state | Use sync.Mutex |\n| 2 | HIGH | Unchecked error | repo.go:123 | `result, _ := r.db.Query()` | Silent failures | Handle error |\n| 3 | HIGH | SQL injection | query.go:89 | `fmt.Sprintf(\"...%s\", input)` | Security breach | Parameterized query |\n\n### Issue-Level Validation (REQUIRED after fixes are applied)\n\n#### Unit: [subtask-2]\n| # | Severity | Description | File:Line | Fix Applied | Status | Evidence |\n|---|----------|-------------|-----------|-------------|--------|----------|\n| 1 | CRITICAL | Race condition in concurrent handler | handler.go:45 | Added mutex lock around shared state |  RESOLVED | race_test.go passes |\n| 2 | HIGH | Unchecked error from DB query | repo.go:123 | Added error check with rollback |  RESOLVED | Error path tested |\n| 3 | HIGH | SQL injection vulnerability | query.go:89 | Used parameterized query |  RESOLVED | Security test added |\n\n#### Unit: [subtask-3] (if applicable)\n| # | Severity | Description | File:Line | Fix Applied | Status | Evidence |\n|---|----------|-------------|-----------|-------------|--------|----------|\n| 1 | HIGH | Missing input validation | api.go:34 | Added validation middleware |  RESOLVED | Fuzz test passes |\n\n### Overall Summary by Severity\n| Severity | Found | Resolved | Remaining | Action |\n|----------|-------|----------|-----------|--------|\n| Critical | [N] | [N] | 0 | Fixed |\n| High | [N] | [N] | 0 | Fixed |\n| Medium | [N] | [N] | 0 | TODO added |\n| Low | [N] | - | [N] | TODO added |\n```\n\n### CodeRabbit Skip Scenarios (ONLY VALID PATHS)\n\n** CodeRabbit can ONLY be skipped in these specific scenarios. Any other skip is a VIOLATION.**\n\n| Scenario | Record As | Next Step | Why Valid |\n|----------|-----------|-----------|-----------|\n| CLI not installed, user **explicitly** declines install | `SKIPPED (not installed, user declined)` | Step 8 | User was asked and chose not to install |\n| Installation failed after attempt, user skips | `SKIPPED (installation failed)` | Step 8 | Technical failure, user informed |\n| Authentication failed after attempt, user skips | `SKIPPED (auth failed)` | Step 8 | Technical failure, user informed |\n| Environment doesn't support (CI/container) | `SKIPPED (unsupported environment)` | Step 8 | Technical limitation |\n\n** INVALID SKIP SCENARIOS (FORBIDDEN):**\n\n| Invalid Scenario | Why FORBIDDEN | Required Action |\n|------------------|---------------|-----------------|\n| CLI installed but \"skipped for speed\" | Installed = MANDATORY | **Run CodeRabbit** |\n| CLI installed but \"Ring reviewers passed\" | Complementary tools, both required | **Run CodeRabbit** |\n| CLI not installed, no prompt shown | MUST ask user about installation | **Show installation prompt** |\n| Silent skip without user interaction | All skips require explicit user choice | **Ask user** |\n\n** NON-NEGOTIABLE:** When CodeRabbit CLI IS installed and authenticated, execution is **MANDATORY** - it CANNOT be skipped under any circumstance.\n\n---\n\n## Step 8: Display Accumulated Findings & Prepare Success Output\n\n** BEFORE generating success output, MUST display accumulated CodeRabbit findings.**\n\n### Step 8.1: Display Accumulated CodeRabbit Findings\n\n```text\nIF .coderabbit-findings.md exists:\n  \n  \n    CODERABBIT FINDINGS - ACCUMULATED DURING REVIEW              \n  \n                                                                   \n   The following issues were identified by CodeRabbit during the  \n   review process. Review before proceeding to commit.            \n                                                                   \n  \n  \n   Display contents of .coderabbit-findings.md\n   Show summary table:\n  \n  \n    CODERABBIT FINDINGS SUMMARY                                  \n  \n                                                                   \n   | Severity | Count | Status |                                  \n   |----------|-------|--------|                                  \n   | Critical | [N]   | [pending/fixed] |                         \n   | High     | [N]   | [pending/fixed] |                         \n   | Medium   | [N]   | [pending/fixed] |                         \n   | Low      | [N]   | [pending/fixed] |                         \n                                                                   \n   Total Issues: [N] | Fixed: [N] | Pending: [N]                  \n                                                                   \n  \n  \n   Ask user:\n  \n    ACTION REQUIRED                                              \n  \n                                                                   \n   [N] CodeRabbit issues are pending. What would you like to do?  \n                                                                   \n     (a) Fix all pending issues now (dispatch implementation agent)\n     (b) Review and fix issues one-by-one (interactive mode)      \n     (c) Acknowledge and proceed to commit (issues documented)    \n                                                                   \n   Note: Choosing (c) will include findings file in commit for    \n         tracking. Issues remain documented for future fixing.    \n                                                                   \n  \n  \n  IF user selects (a) Fix all issues:\n     Dispatch implementation agent with ALL pending issues from findings file\n     After fixes, update .coderabbit-findings.md (mark issues as FIXED)\n     Re-run CodeRabbit validation for affected files\n     Loop back to Step 8.1 to display updated findings\n  \n  IF user selects (b) Interactive mode (one-by-one):\n     Go to Step 8.1.1 (Interactive Issue Review)\n  \n  IF user selects (c) Acknowledge and proceed:\n     Record: \"CodeRabbit issues acknowledged by user\"\n     Include .coderabbit-findings.md in commit (for audit trail)\n     Proceed to Step 8.2 (Success Output)\n\n\nStep 8.1.1: Interactive Issue Review (One-by-One)\n\n\nissues_to_fix = []\nissues_to_skip = []\n\nFOR EACH issue IN pending_issues (ordered by severity: CRITICAL  HIGH  MEDIUM  LOW):\n  \n  Display:\n  \n    ISSUE [current]/[total] - [SEVERITY]                         \n  \n                                                                   \n   Unit: [unit.id] - [unit.name]                                  \n   File: [file:line]                                              \n                                                                   \n   Description:                                                   \n     [issue description]                                          \n                                                                   \n   Code Context:                                                  \n     [code snippet around the issue]                              \n                                                                   \n   Why it matters:                                                \n     [explanation of impact]                                      \n                                                                   \n   Recommendation:                                                \n     [suggested fix]                                              \n                                                                   \n  \n   What would you like to do with this issue?                     \n                                                                   \n     (f) Fix this issue                                           \n     (s) Skip this issue (acknowledge)                            \n     (a) Fix ALL remaining issues                                 \n     (k) Skip ALL remaining issues                                \n                                                                   \n  \n  \n  IF user selects (f) Fix:\n     Add to issues_to_fix list\n     Continue to next issue\n  \n  IF user selects (s) Skip:\n     Add to issues_to_skip list\n     Continue to next issue\n  \n  IF user selects (a) Fix ALL remaining:\n     Add current + all remaining to issues_to_fix list\n     Break loop\n  \n  IF user selects (k) Skip ALL remaining:\n     Add current + all remaining to issues_to_skip list\n     Break loop\n\nAFTER loop completes:\n  Display summary:\n  \n    INTERACTIVE REVIEW COMPLETE                                  \n  \n                                                                   \n   Issues to fix: [N]                                             \n     [list of issues selected for fixing]                         \n                                                                   \n   Issues to skip: [N]                                            \n     [list of issues selected to skip]                            \n                                                                   \n   Proceed with this selection? (y/n)                             \n                                                                   \n  \n  \n  IF user confirms (y):\n    IF issues_to_fix.length > 0:\n       Dispatch implementation agent with ONLY issues_to_fix\n       After fixes, update .coderabbit-findings.md:\n        - Mark fixed issues as FIXED\n        - Mark skipped issues as ACKNOWLEDGED\n       Re-run CodeRabbit validation for affected files\n       Loop back to Step 8.1\n    ELSE:\n       All issues skipped/acknowledged\n       Proceed to Step 8.2 (Success Output)\n  \n  IF user cancels (n):\n     Return to Step 8.1 main prompt\n\nELSE (no findings file exists):\n   CodeRabbit was skipped or found no issues\n   Proceed directly to Step 8.2 (Success Output)\n```\n\n### Step 8.2: Generate Success Output\n\n```text\nGenerate skill output:\n\n## Review Summary\n**Status:** PASS\n**Unit ID:** [unit_id]\n**Iterations:** [review_state.iterations]\n\n## Issues by Severity\n| Severity | Count |\n|----------|-------|\n| Critical | 0 |\n| High | 0 |\n| Medium | 0 |\n| Low | [count] |\n| Cosmetic | [count] |\n\n## Reviewer Verdicts\n| Reviewer | Verdict | Issues |\n|----------|---------|--------|\n| code-reviewer |  PASS | [count] |\n| business-logic-reviewer |  PASS | [count] |\n| security-reviewer |  PASS | [count] |\n| test-reviewer |  PASS | [count] |\n| nil-safety-reviewer |  PASS | [count] |\n\n## Low/Cosmetic Issues (TODO/FIXME added)\n[list with file locations]\n\n## CodeRabbit Findings\n**Findings File:** .coderabbit-findings.md\n**Total Issues Found:** [N]\n**Issues Fixed:** [N]\n**Issues Acknowledged:** [N]\n**Status:** [ALL_FIXED | ACKNOWLEDGED | NO_ISSUES]\n\n## Handoff to Next Gate\n- Review status: COMPLETE\n- All blocking issues: RESOLVED\n- Reviewers passed: 5/5\n- CodeRabbit findings: [status]\n- Ready for Gate 5 (Validation): YES\n```\n\n## Step 9: Escalate - Max Iterations Reached\n\n```text\nGenerate skill output:\n\n## Review Summary\n**Status:** FAIL\n**Unit ID:** [unit_id]\n**Iterations:** [max_iterations] (MAX REACHED)\n\n## Issues by Severity\n| Severity | Count |\n|----------|-------|\n| Critical | [count] |\n| High | [count] |\n| Medium | [count] |\n\n## Unresolved Issues\n[list all Critical/High/Medium still open]\n\n## Reviewer Verdicts\n| Reviewer | Verdict |\n|----------|---------|\n| code-reviewer | [PASS/FAIL] |\n| business-logic-reviewer | [PASS/FAIL] |\n| security-reviewer | [PASS/FAIL] |\n\n## Handoff to Next Gate\n- Review status: FAILED\n- Unresolved blocking issues: [count]\n- Ready for Gate 5: NO\n- **Action Required:** User must manually resolve issues\n\n ESCALATION: Max iterations (3) reached. Blocking issues remain.\n```\n\n---\n\n## Pressure Resistance\n\nSee [dev-team/skills/shared-patterns/shared-pressure-resistance.md](../../dev-team/skills/shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Skip review, code is simple\" | \"Simple code can have security issues. Dispatching all 5 reviewers.\" |\n| \"Just run code-reviewer\" | \"All 5 reviewers run in parallel. No time saved by skipping.\" |\n| \"Fix later, merge now\" | \"Blocking issues (Critical/High/Medium) MUST be fixed before Gate 5.\" |\n\n## Anti-Rationalization Table\n\nSee [dev-team/skills/shared-patterns/shared-anti-rationalization.md](../../dev-team/skills/shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations.\n\n### Gate 4-Specific Anti-Rationalizations\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Run reviewers one at a time\" | Sequential = slow. Parallel = 5x faster. | **Dispatch all 5 in single message** |\n| \"Skip security for internal code\" | Internal code can have vulnerabilities. | **Include security-reviewer** |\n| \"Critical issue is false positive\" | Prove it with evidence, don't assume. | **Fix or provide evidence** |\n| \"Low issues don't need TODO\" | TODOs ensure issues aren't forgotten. | **Add TODO comments** |\n| \"4 of 5 reviewers passed\" | Gate 4 requires ALL 5. 4/5 = 0/5. | **Re-run ALL 5 reviewers** |\n| \"MEDIUM is not blocking\" | MEDIUM = MUST FIX. Same as CRITICAL/HIGH. | **Fix MEDIUM issues NOW** |\n\n---\n\n## Execution Report Format\n\n```markdown\n## Review Summary\n**Status:** [PASS|FAIL|NEEDS_FIXES]\n**Unit ID:** [unit_id]\n**Duration:** [Xm Ys]\n**Iterations:** [N]\n\n## Issues by Severity\n| Severity | Count |\n|----------|-------|\n| Critical | [N] |\n| High | [N] |\n| Medium | [N] |\n| Low | [N] |\n\n## Reviewer Verdicts\n| Reviewer | Verdict |\n|----------|---------|\n| code-reviewer | / |\n| business-logic-reviewer | / |\n| security-reviewer | / |\n| test-reviewer | / |\n| nil-safety-reviewer | / |\n\n## CodeRabbit External Review (MANDATORY if installed, Optional to install)\n**Status:** [PASS|ISSUES_FOUND|SKIPPED|NOT_INSTALLED]\n**Validation Mode:** [SUBTASK-LEVEL|TASK-LEVEL]\n**Units Validated:** [N]\n**Units Passed:** [N]/[N]\n**Issues Found:** [N]\n**Issues Resolved:** [N]/[N]\n\n### Per-Unit Results (if subtask-level)\n| Unit ID | Status | Critical | High | Medium | Low |\n|---------|--------|----------|------|--------|-----|\n| [subtask-1] |  PASS | 0 | 0 | 0 | 1 |\n| [subtask-2] |  FIXED | 0 | 0 | 0 | 0 |\n\n### Issue-Level Validation (REQUIRED when issues were fixed)\n| Unit | # | Severity | Description | Fix Applied | Status | Evidence |\n|------|---|----------|-------------|-------------|--------|----------|\n| subtask-2 | 1 | CRITICAL | Race condition | Mutex added |  RESOLVED | Test passes |\n| subtask-2 | 2 | HIGH | Unchecked error | Error handling added |  RESOLVED | Test passes |\n\n## Handoff to Next Gate\n- Review status: [COMPLETE|FAILED]\n- Blocking issues: [resolved|N remaining]\n- CodeRabbit: [PASS|SKIPPED|N issues acknowledged]\n- CodeRabbit validation: [N]/[N] units passed\n- Ready for Gate 5: [YES|NO]\n```"
              },
              {
                "name": "ring:root-cause-tracing",
                "description": "Backward call-chain tracing - systematically trace bugs from error location back\nthrough call stack to original trigger. Adds instrumentation when needed.\n",
                "path": "default/skills/root-cause-tracing/SKILL.md",
                "frontmatter": {
                  "name": "ring:root-cause-tracing",
                  "description": "Backward call-chain tracing - systematically trace bugs from error location back\nthrough call stack to original trigger. Adds instrumentation when needed.\n",
                  "trigger": "- Error happens deep in execution (not at entry point)\n- Stack trace shows long call chain\n- Unclear where invalid data originated\n- systematic-debugging Phase 1 leads you here\n",
                  "skip_when": "- Bug at entry point  use systematic-debugging directly\n- Haven't started investigation  use systematic-debugging first\n- Root cause is obvious  just fix it\n",
                  "sequence": {
                    "after": [
                      "systematic-debugging"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "systematic-debugging"
                    ]
                  }
                },
                "content": "# Root Cause Tracing\n\n## Overview\n\nBugs often manifest deep in the call stack (git init in wrong directory, file created in wrong location, database opened with wrong path). Your instinct is to fix where the error appears, but that's treating a symptom.\n\n**Core principle:** Trace backward through the call chain until you find the original trigger, then fix at the source.\n\n## When to Use\n\n**Use root-cause-tracing when:**\n- Error happens deep in execution (not at entry point)\n- Stack trace shows long call chain\n- Unclear where invalid data originated\n- systematic-debugging Phase 1 leads you here\n\n**Relationship with systematic-debugging:**\n- root-cause-tracing is a **SUB-SKILL** of systematic-debugging\n- Use during **systematic-debugging Phase 1, Step 5** (Trace Data Flow)\n- Can also use standalone if you KNOW bug is deep-stack issue\n- After tracing to source, **return to systematic-debugging Phase 2**\n\n**When NOT to use:**\n- Bug appears at entry point  Use systematic-debugging Phase 1 directly\n- You haven't started systematic-debugging yet  Start there first\n- Root cause is obvious  Just fix it\n- Still gathering evidence  Continue systematic-debugging Phase 1\n\n## The Tracing Process\n\n1. **Observe Symptom:** `Error: git init failed in /Users/jesse/project/packages/core`\n2. **Find Immediate Cause:** `await execFileAsync('git', ['init'], { cwd: projectDir })`\n3. **Ask: What Called This?** `WorktreeManager.createSessionWorktree(projectDir)`  `Session.initializeWorkspace()`  `Session.create()`  test at `Project.create()`\n4. **Keep Tracing Up:** `projectDir = ''` (empty!)  resolves to `process.cwd()`  source code directory!\n5. **Find Original Trigger:** `const context = setupCoreTest()` returns `{ tempDir: '' }`  accessed before beforeEach!\n\n## Adding Stack Traces\n\nWhen you can't trace manually, add instrumentation before the problematic operation:\n```typescript\nconsole.error('DEBUG git init:', { directory, cwd: process.cwd(), stack: new Error().stack });\n```\n\n**Critical:** Use `console.error()` in tests (logger may not show). Run: `npm test 2>&1 | grep 'DEBUG'`\n\n**Analyze:** Look for test file names, line numbers, patterns (same test? same parameter?).\n\n## Finding Which Test Causes Pollution\n\nIf something appears during tests but you don't know which test:\n\nUse the bisection script: @find-polluter.sh\n\n```bash\n./find-polluter.sh '.git' 'src/**/*.test.ts'\n```\n\nRuns tests one-by-one, stops at first polluter. See script for usage.\n\n## Real Example: Empty projectDir\n\n**Symptom:** `.git` in `packages/core/` (source code)\n**Trace chain:** `git init` in `process.cwd()`  empty cwd  WorktreeManager  Session.create()  test accessed `context.tempDir` before beforeEach  `setupCoreTest()` returns `{ tempDir: '' }`\n**Root cause:** Top-level variable initialization accessing empty value\n**Fix:** Made tempDir a getter that throws if accessed before beforeEach\n**Defense-in-depth:** (1) Project.create() validates (2) WorkspaceManager validates (3) NODE_ENV guard (4) Stack trace logging\n\n## Key Principle\n\n**Flow:** Found immediate cause  Can trace up? (yes  trace backwards)  Is this source? (no  keep tracing | yes  fix at source)  Add validation at each layer  Bug impossible\n\n**NEVER fix just where the error appears.** Trace back to find the original trigger.\n\n## Stack Trace Tips\n\n- **In tests:** `console.error()` not logger (may be suppressed)\n- **Before operation:** Log before dangerous op, not after fail\n- **Include context:** Directory, cwd, env vars, timestamps\n- **Capture stack:** `new Error().stack` shows complete chain\n\n## Real-World Impact\n\n5-level trace  fixed at source (getter validation)  4 layers defense  1847 tests, zero pollution"
              },
              {
                "name": "ring:subagent-driven-development",
                "description": "Autonomous plan execution - fresh subagent per task with automated code review\nbetween tasks. No human-in-loop, high throughput with quality gates.\n",
                "path": "default/skills/subagent-driven-development/SKILL.md",
                "frontmatter": {
                  "name": "ring:subagent-driven-development",
                  "description": "Autonomous plan execution - fresh subagent per task with automated code review\nbetween tasks. No human-in-loop, high throughput with quality gates.\n",
                  "trigger": "- Staying in current session (no worktree switch)\n- Tasks are independent (can be executed in isolation)\n- Want continuous progress without human pause points\n",
                  "skip_when": "- Need human review between tasks  use executing-plans\n- Tasks are tightly coupled  execute manually\n- Plan needs revision  use brainstorming first\n",
                  "sequence": {
                    "after": [
                      "writing-plans",
                      "pre-dev-task-breakdown"
                    ]
                  },
                  "related": {
                    "similar": [
                      "executing-plans"
                    ]
                  }
                },
                "content": "# Subagent-Driven Development\n\nExecute plan by dispatching fresh subagent per task, with code review after each.\n\n**Core principle:** Fresh subagent per task + review between tasks = high quality, fast iteration\n\n## Overview\n\n**vs. Executing Plans (parallel session):**\n- Same session (no context switch)\n- Fresh subagent per task (no context pollution)\n- Code review after each task (catch issues early)\n- Faster iteration (no human-in-loop between tasks)\n\n**When to use:**\n- Staying in this session\n- Tasks are mostly independent\n- Want continuous progress with quality gates\n\n**When NOT to use:**\n- Need to review plan first (use executing-plans)\n- Tasks are tightly coupled (manual execution better)\n- Plan needs revision (brainstorm first)\n\n## The Process\n\n### 1. Load Plan\n\nRead plan file, create TodoWrite with all tasks.\n\n### 2. Execute Task with Subagent\n\n**Dispatch:** `Task tool (general-purpose)` with: Task N from [plan-file], instructions (implement, test with TDD, verify, commit, report back), working directory. Subagent reports summary.\n\n### 3. Review Subagent's Work (Parallel Execution)\n\n**CRITICAL: Single message with 3 Task tool calls** - all reviewers execute simultaneously.\n\n| Reviewer | Model | Context |\n|----------|-------|---------|\n| `code-reviewer` | opus | WHAT_WAS_IMPLEMENTED, PLAN, BASE_SHA, HEAD_SHA |\n| `business-logic-reviewer` | opus | Same context |\n| `security-reviewer` | opus | Same context |\n\n**Each returns:** Strengths, Issues (Critical/High/Medium/Low/Cosmetic), Assessment (PASS/FAIL)\n\n### 4. Aggregate and Handle Review Feedback\n\n**Aggregate** all issues by severity across all 3 reviewers.\n\n| Severity | Action |\n|----------|--------|\n| **Critical/High/Medium** | Dispatch fix subagent  Re-run all 3 reviewers  Repeat until clear |\n| **Low** | Add `# TODO(review): [issue] - reviewer, date, Severity: Low` |\n| **Cosmetic** | Add `# FIXME(nitpick): [issue] - reviewer, date, Severity: Cosmetic` |\n\nCommit TODO/FIXME comments with fixes.\n\n### 5. Mark Complete, Next Task\n\nAfter all Critical/High/Medium issues resolved for current task:\n- Mark task as completed in TodoWrite\n- Commit all changes (including TODO/FIXME comments)\n- Move to next task\n- Repeat steps 2-5\n\n### 6. Final Review (After All Tasks)\n\n**Same pattern as Step 3** but reviewing entire implementation (all tasks, full BASE_SHAHEAD_SHA range). Aggregate, fix, re-run until all 3 PASS.\n\n### 7. Complete Development\n\nAfter final review passes:\n- Announce: \"I'm using the finishing-a-development-branch skill to complete this work.\"\n- **REQUIRED SUB-SKILL:** Use finishing-a-development-branch\n- Follow that skill to verify tests, present options, execute choice\n\n## Example Workflow\n\n**Task 1:** Implement  All 3 reviewers PASS  Mark complete.\n\n**Task 2:** Implement  Review finds: Critical (hardcoded secret), High (missing password reset, no rate limiting), Low (extract token logic)  Dispatch fix subagent  Re-run reviewers  All PASS  Add TODO for Low  Mark complete.\n\n**Final:** All 3 reviewers PASS entire implementation  Done.\n\n**Why parallel:** 3x faster, all feedback at once, TODO/FIXME tracks tech debt.\n\n## Advantages\n\n| vs. | Benefits |\n|-----|----------|\n| **Manual execution** | Fresh context per task, TDD enforced, parallel-safe |\n| **Executing Plans** | Same session (no handoff), continuous progress, automatic review |\n\n**Cost:** More invocations, but catches issues early (cheaper than debugging later).\n\n## Red Flags\n\n**Never:**\n- Skip code review between tasks\n- Proceed with unfixed Critical/High/Medium issues\n- Dispatch reviewers sequentially (use parallel - 3x faster!)\n- Dispatch multiple implementation subagents in parallel (conflicts)\n- Implement without reading plan task\n- Forget to add TODO/FIXME comments for Low/Cosmetic issues\n\n**Always:**\n- Launch all 3 reviewers in single message with 3 Task calls\n- Specify `model: \"opus\"` for each reviewer\n- Wait for all reviewers before aggregating findings\n- Fix Critical/High/Medium immediately\n- Add TODO for Low, FIXME for Cosmetic\n- Re-run all 3 reviewers after fixes\n\n**If subagent fails task:**\n- Dispatch fix subagent with specific instructions\n- Don't try to fix manually (context pollution)\n\n## Integration\n\n**Required workflow skills:**\n- **writing-plans** - REQUIRED: Creates the plan that this skill executes\n- **requesting-code-review** - REQUIRED: Review after each task (see Step 3)\n- **finishing-a-development-branch** - REQUIRED: Complete development after all tasks (see Step 7)\n\n**Subagents must use:**\n- **test-driven-development** - Subagents follow TDD for each task\n\n**Alternative workflow:**\n- **executing-plans** - Use for parallel session instead of same-session execution\n\nSee reviewer agent definitions: code-reviewer (agents/code-reviewer.md), security-reviewer (agents/security-reviewer.md), business-logic-reviewer (agents/business-logic-reviewer.md)"
              },
              {
                "name": "ring:systematic-debugging",
                "description": "Four-phase debugging framework - root cause investigation, pattern analysis,\nhypothesis testing, implementation. Ensures understanding before attempting fixes.\n",
                "path": "default/skills/systematic-debugging/SKILL.md",
                "frontmatter": {
                  "name": "ring:systematic-debugging",
                  "description": "Four-phase debugging framework - root cause investigation, pattern analysis,\nhypothesis testing, implementation. Ensures understanding before attempting fixes.\n",
                  "trigger": "- Bug reported or test failure observed\n- Unexpected behavior or error message\n- Root cause unknown\n- Previous fix attempt didn't work\n",
                  "skip_when": "- Root cause already known  just fix it\n- Error deep in call stack, need to trace backward  use root-cause-tracing\n- Issue obviously caused by your last change  quick verification first\n",
                  "related": {
                    "complementary": [
                      "root-cause-tracing"
                    ]
                  }
                },
                "content": "# Systematic Debugging\n\n**Core principle:** NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST.\n\n## When to Use\n\nUse for ANY technical issue: test failures, bugs, unexpected behavior, performance problems, build failures, integration issues.\n\n**Especially when:**\n- Under time pressure (emergencies make guessing tempting)\n- \"Just one quick fix\" seems obvious\n- Previous fix didn't work\n- You don't fully understand the issue\n\n## The Four Phases\n\nComplete each phase before proceeding to the next.\n\n### Phase 1: Root Cause Investigation\n\n**MUST complete ALL before Phase 2 (copy to TodoWrite):**\n Error message copied verbatim |  Reproduction confirmed |  Recent changes reviewed (`git diff`) |  Evidence from ALL components |  Data flow traced (origin  error)\n\n1. **Read Error Messages** - Stack traces completely, line numbers, file paths, error codes. Don't skip warnings.\n2. **Reproduce Consistently** - Exact steps to trigger. Intermittent  gather more data.\n3. **Check Recent Changes** - `git diff`, recent commits, new dependencies, config changes.\n4. **Multi-Component Systems** - Log at each boundary: what enters, what exits, env/config state. Run once, analyze, identify failing layer.\n5. **Trace Data Flow** - Error deep in stack? **Use root-cause-tracing skill.** Quick: Where does bad value originate? Trace up call stack, fix at source not symptom.\n\n**Phase 1 Summary:** Error: [exact] | Reproduces: [steps] | Recent changes: [commits] | Component evidence: [each] | Data origin: [source]\n\n### Phase 2: Pattern Analysis\n\n1. **Find Working Examples** - Similar working code in codebase. What works that's similar to what's broken?\n2. **Compare Against References** - Read reference implementation COMPLETELY. Don't skim - understand fully.\n3. **Identify Differences** - List EVERY difference (working vs broken). Don't assume \"that can't matter.\"\n4. **Understand Dependencies** - What components, config, environment needed? What assumptions does it make?\n\n### Phase 3: Hypothesis Testing\n\n1. **Form Single Hypothesis** - \"I think X is root cause because Y\" - Be specific.\n2. **Test Minimally** - SMALLEST possible change. One variable at a time.\n3. **Verify and Track** - `H#1: [what]  [result] | H#2: [what]  [result] | H#3: [what]  [STOP if fails]`\n   **If 3 hypotheses fail:** STOP immediately  \"3 hypotheses failed, architecture review required\"  Discuss with partner before more attempts.\n4. **When You Don't Know** - Say \"I don't understand X.\" Ask for help. Research more.\n\n### Phase 4: Implementation\n\n**Fix root cause, not symptom:**\n\n1. **Create Failing Test** - Simplest reproduction. **Use test-driven-development skill.**\n2. **Implement Single Fix** - Address root cause only. ONE change at a time. No \"while I'm here\" improvements.\n3. **Verify Fix** - Test passes? No other tests broken? Issue resolved?\n4. **If Fix Doesn't Work** - Count fixes. If < 3: Return to Phase 1. **If  3: STOP  Architecture review required.**\n5. **After Fix Verified** - Test passes and issue resolved? Move to post-completion review.\n6. **If 3+ Fixes Failed** - Pattern: each fix reveals new problem elsewhere, requires massive refactoring, creates new symptoms. **STOP and discuss:** Is architecture sound? Should we refactor vs. fix?\n\n## Time Limits\n\n**Debugging time boxes:**\n- 30 min without root cause  Escalate\n- 3 failed fixes  Architecture review\n- 1 hour total  Stop, document, ask for guidance\n\n## Red Flags\n\n**STOP and return to Phase 1 if thinking:**\n- \"Quick fix for now, investigate later\"\n- \"Just try changing X and see if it works\"\n- \"Add multiple changes, run tests\"\n- \"Skip the test, I'll manually verify\"\n- \"It's probably X, let me fix that\"\n- \"I don't fully understand but this might work\"\n- \"One more fix attempt\" (when already tried 2+)\n- \"Each fix reveals new problem\" (architecture issue)\n\n**User signals you're wrong:**\n- \"Is that not happening?\"  You assumed without verifying\n- \"Stop guessing\"  You're proposing fixes without understanding\n- \"We're stuck?\"  Your approach isn't working\n\n**When you see these: STOP. Return to Phase 1.**\n\n## Quick Reference\n\n| Phase | Key Activities | Success Criteria |\n|-------|---------------|------------------|\n| **1. Root Cause** | Read errors, reproduce, check changes, gather evidence, trace data flow | Understand WHAT and WHY |\n| **2. Pattern** | Find working examples, compare differences, understand dependencies | Identify what's different |\n| **3. Hypothesis** | Form theory, test minimally, verify one at a time | Confirmed or new hypothesis |\n| **4. Implementation** | Create test, fix root cause, verify | Bug resolved, tests pass |\n\n**Circuit breakers:**\n- 3 hypotheses fail  STOP, architecture review\n- 3 fixes fail  STOP, question fundamentals\n- 30 min no root cause  Escalate\n\n## Integration with Other Skills\n\n**Required sub-skills:**\n- **root-cause-tracing** - When error is deep in call stack (Phase 1, Step 5)\n- **test-driven-development** - For failing test case (Phase 4, Step 1)\n\n**Complementary:**\n- **defense-in-depth** - Add validation after finding root cause\n- **verification-before-completion** - Verify fix worked before claiming success\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **Exit Criteria:** See `skills/shared-patterns/exit-criteria.md`\n- **TodoWrite:** See `skills/shared-patterns/todowrite-integration.md`\n\nApply ALL patterns when using this skill."
              },
              {
                "name": "ring:test-driven-development",
                "description": "RED-GREEN-REFACTOR implementation methodology - write failing test first,\nminimal implementation to pass, then refactor. Ensures tests verify behavior.\n",
                "path": "default/skills/test-driven-development/SKILL.md",
                "frontmatter": {
                  "name": "ring:test-driven-development",
                  "description": "RED-GREEN-REFACTOR implementation methodology - write failing test first,\nminimal implementation to pass, then refactor. Ensures tests verify behavior.\n",
                  "trigger": "- Starting implementation of new feature\n- Starting implementation of bugfix\n- Writing new production code\n",
                  "skip_when": "- Reviewing/modifying existing tests  use testing-anti-patterns\n- Code already exists without tests  add tests first, then TDD for new code\n- Exploratory/spike work  consider brainstorming first\n",
                  "related": {
                    "complementary": [
                      "testing-anti-patterns",
                      "verification-before-completion"
                    ]
                  },
                  "compliance_rules": [
                    {
                      "id": "test_file_exists",
                      "description": "Test file must exist before implementation file",
                      "check_type": "file_exists",
                      "pattern": "**/*.test.{ts,js,go,py}",
                      "severity": "blocking",
                      "failure_message": "No test file found. Write test first (RED phase)."
                    },
                    {
                      "id": "test_must_fail_first",
                      "description": "Test must produce failure output before implementation",
                      "check_type": "command_output_contains",
                      "command": "npm test 2>&1 || pytest 2>&1 || go test ./... 2>&1",
                      "pattern": "FAIL|Error|failed",
                      "severity": "blocking",
                      "failure_message": "Test does not fail. Write a failing test first (RED phase)."
                    }
                  ],
                  "prerequisites": [
                    {
                      "name": "test_framework_installed",
                      "check": "npm list jest 2>/dev/null || npm list vitest 2>/dev/null || which pytest 2>/dev/null || go list ./... 2>&1 | grep -q testing",
                      "failure_message": "No test framework found. Install jest/vitest (JS), pytest (Python), or use Go's built-in testing.",
                      "severity": "blocking"
                    },
                    {
                      "name": "can_run_tests",
                      "check": "npm test -- --version 2>/dev/null || pytest --version 2>/dev/null || go test -v 2>&1 | grep -q 'testing:'",
                      "failure_message": "Cannot run tests. Fix test configuration.",
                      "severity": "warning"
                    }
                  ],
                  "composition": {
                    "works_well_with": [
                      {
                        "skill": "ring:systematic-debugging",
                        "when": "test reveals unexpected behavior or bug",
                        "transition": "Pause TDD at current phase, use systematic-debugging to find root cause, return to TDD after fix"
                      },
                      {
                        "skill": "ring:verification-before-completion",
                        "when": "before marking test suite or feature complete",
                        "transition": "Run verification to ensure all tests pass, return to TDD if issues found"
                      },
                      {
                        "skill": "ring:requesting-code-review",
                        "when": "after completing RED-GREEN-REFACTOR cycle for feature",
                        "transition": "Request review before merging, address feedback, mark complete"
                      }
                    ],
                    "conflicts_with": [],
                    "typical_workflow": "1. Write failing test (RED)\n2. If test reveals unexpected behavior  switch to systematic-debugging\n3. Fix root cause\n4. Return to TDD: minimal implementation (GREEN)\n5. Refactor (REFACTOR)\n6. Run verification-before-completion\n7. Request code review\n"
                  }
                },
                "content": "# Test-Driven Development (TDD)\n\n## Overview\n\nWrite the test first. Watch it fail. Write minimal code to pass.\n\n**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.\n\n**Violating the letter of the rules is violating the spirit of the rules.**\n\n## When to Use\n\n**Always:**\n- New features\n- Bug fixes\n- Refactoring\n- Behavior changes\n\n**Exceptions (ask your human partner):**\n- Throwaway prototypes\n- Generated code\n- Configuration files\n\nThinking \"skip TDD just this once\"? Stop. That's rationalization.\n\n## The Iron Law\n\n```\nNO PRODUCTION CODE WITHOUT A FAILING TEST FIRST\n```\n\nWrite code before the test? You have ONLY two options:\n\n## Violation Handling (Mandatory)\n\n**If you wrote code before test:**\n\n### DELETE IT. IMMEDIATELY.\n\n```bash\nrm [files]  # or git reset --hard\n```\n\n**Not tomorrow. Not after asking. NOW.**\n\n**Delete means DELETE:**\n- `rm -rf the_file.py` \n- `git reset --hard` \n- Physically delete \n\n**These are NOT deleting (violations):**\n- `git stash` - That's hiding, not deleting\n- `mv file.py file.py.bak` - That's keeping\n- Copy to clipboard - That's keeping\n- Comment out - That's keeping\n- \"Mental note\" - That's keeping\n- Asking permission - That's delaying\n\nDelete means gone forever. No recovery possible.\n\nThen start over with TDD.\n\n### NO ASKING. NO PERMISSION. NO EXCEPTIONS.\n\n**You CANNOT:**\n-  Ask \"should I delete this?\"\n-  Ask \"may I proceed with tests-after?\"\n-  Request permission due to [any reason]\n-  Explain why deleting is hard\n-  Decide \"I'll be pragmatic and test after\"\n-  Claim \"spirit not letter\"\n-  Rationalize \"damage already done\"\n-  Argue \"skill is guide not suicide pact\"\n-  Create \"pragmatic compliance\" category\n-  Mention sunk cost, time pressure, personal plans\n-  Commit anything\n\n**If you think you have a legitimate reason to skip deletion:**\n- You don't.\n- Delete it.\n- Every excuse is rationalization.\n- Anniversary? Delete code, go to dinner, start fresh tomorrow.\n- Deadline? Delete code, communicate delay, do it right.\n- 4 hours of work? Sunk cost fallacy. Delete it.\n- Manager pressure? Delete it, explain TDD prevents bugs.\n- \"But this is different because...\" No. Delete it.\n\n**The rule has ZERO exceptions. ZERO.**\n\n### Consequences of NOT Deleting\n\nUntested code WILL cause production incidents. These are CERTAINTIES:\n\n- **Trust:** Partner loses confidence permanently. PRs rejected. Assigned bug duty.\n- **Production:** Incident within 30 days. Worst timing (holiday, 3am). Postmortem responsibility.\n- **Career:** Reputation as \"cuts corners\" follows you. Promotion blocked.\n- **Personal:** Anniversary debugging. Technical debt haunts for years.\n\n \"This time is different\"  Every developer who thought this experienced these consequences.\n\n### The ONLY Acceptable Action\n\n**DELETE THE CODE. NOW.**\n\n```bash\nrm /tmp/auth-feature/src/auth.ts\nrm /tmp/auth-feature/src/middleware.ts\nrm /tmp/auth-feature/src/utils.ts\n# or: git reset --hard\n```\n\n**Then:**\n- Go to anniversary dinner\n- Sleep well\n- Tomorrow morning: Start fresh with TDD\n- Implement in 2-3 hours with tests (faster second time)\n- Code review passes\n- No production incidents\n- Career intact\n\n**ZERO exceptions. Anniversary, deadline, manager pressure, sunk cost - NONE of these override deletion.**\n\n### Prohibited Rationalizations\n\n**You CANNOT create alternatives:**\n-  \"Commit with WIP message\" - NO. Delete.\n-  \"Commit with 'NO TESTS' warning\" - NO. Delete.\n-  \"Mark as technical debt\" - NO. Delete.\n-  \"Email team about violation\" - NO. Delete first, communicate after.\n-  \"Come early tomorrow to decide\" - NO. Delete now, decide nothing.\n-  \"Let team decide\" - NO. You decide: Delete.\n-  \"Write tests tonight after dinner\" - NO. Delete, start fresh tomorrow with TDD.\n-  \"Commit honestly labeled code\" - NO. Honesty is deleting it.\n-  \"Present options to partner\" - NO. Only one option: Delete.\n\n**The skill doesn't offer choices. It commands: DELETE.**\n\n**If you create ANY alternative to deletion, you violated the skill.**\n\n**DELETE IT. NOW. NO ALTERNATIVES.**\n\n## Red-Green-Refactor\n\n**Cycle:** RED (write failing test)  verify fails  GREEN (minimal code)  verify passes  REFACTOR (clean up)  verify still green  repeat\n\n### RED - Write Failing Test\n\nWrite one minimal test showing what should happen.\n\n**GOOD:** `test('retries failed operations 3 times', ...)` - clear name, tests real behavior, one thing.\n\n**BAD:** `test('retry works', ...)` with mocks - vague name, tests mock not code.\n\n**Time limit:** <5 minutes. Complex mocks  testing wrong thing. Lots of setup  design too complex. Multiple assertions  split tests.\n\n**Requirements:**\n- One behavior\n- Clear name\n- Real code (no mocks unless unavoidable)\n\n### Verify RED - Watch It Fail\n\n**MANDATORY. Never skip.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\n**Paste the ACTUAL failure output in your response:**\n```\n[PASTE EXACT OUTPUT HERE]\n[NO OUTPUT = VIOLATION]\n```\n\nIf you can't paste output, you didn't run the test.\n\n### Required Failure Patterns\n\n| Test Type | Must See This Failure | Wrong Failure = Wrong Test |\n|-----------|----------------------|---------------------------|\n| New feature | `NameError: function not defined` or `AttributeError` | Test passing = testing existing behavior |\n| Bug fix | Actual wrong output/behavior | Test passing = not testing the bug |\n| Refactor | Tests pass before and after | Tests fail after = broke something |\n\n**No failure output = didn't run = violation**\n\nConfirm:\n- Test fails (not errors)\n- Failure message is expected\n- Fails because feature missing (not typos)\n\n**Test passes?** You're testing existing behavior. Fix test.\n\n**Test errors?** Fix error, re-run until it fails correctly.\n\n### GREEN - Minimal Code\n\nWrite simplest code to pass the test.\n\n**GOOD:** Simple loop with try/catch, just enough to pass. **BAD:** Adding options, backoff, callbacks (YAGNI).\n\nDon't add features, refactor other code, or \"improve\" beyond the test.\n\n### Verify GREEN - Watch It Pass\n\n**MANDATORY.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\nConfirm:\n- Test passes\n- Other tests still pass\n- Output pristine (no errors, warnings)\n\n**Test fails?** Fix code, not test.\n\n**Other tests fail?** Fix now.\n\n### REFACTOR - Clean Up\n\nAfter green only:\n- Remove duplication\n- Improve names\n- Extract helpers\n\nKeep tests green. Don't add behavior.\n\n### Repeat\n\nNext failing test for next feature.\n\n## Good Tests\n\n| Quality | Good | Bad |\n|---------|------|-----|\n| **Minimal** | One thing. \"and\" in name? Split it. | `test('validates email and domain and whitespace')` |\n| **Clear** | Name describes behavior | `test('test1')` |\n| **Shows intent** | Demonstrates desired API | Obscures what code should do |\n\n## Why Order Matters\n\n| Argument | Reality |\n|----------|---------|\n| \"Tests after verify it works\" | Tests-after pass immediately  proves nothing. Test-first forces failure  proves test works. |\n| \"Already manually tested\" | Ad-hoc  systematic. No record, can't re-run, easy to forget under pressure. |\n| \"Deleting X hours is wasteful\" | Sunk cost fallacy. Keeping unverified code = tech debt. Delete  rewrite with confidence. |\n| \"TDD is dogmatic\" | TDD IS pragmatic: catches bugs pre-commit, prevents regressions, documents behavior, enables refactoring. |\n| \"Spirit not ritual\" | Tests-after = \"what does this do?\" Tests-first = \"what should this do?\" Different questions. |\n\n## Common Rationalizations\n\n| Excuse | Reality |\n|--------|---------|\n| \"Too simple to test\" | Simple code breaks. Test takes 30 seconds. |\n| \"I'll test after\" | Tests passing immediately prove nothing. |\n| \"Tests after achieve same goals\" | Tests-after = \"what does this do?\" Tests-first = \"what should this do?\" |\n| \"Already manually tested\" | Ad-hoc  systematic. No record, can't re-run. |\n| \"Deleting X hours is wasteful\" | Sunk cost fallacy. Keeping unverified code is technical debt. |\n| \"Keep as reference, write tests first\" | You'll adapt it. That's testing after. Delete means delete. |\n| \"Need to explore first\" | Fine. Throw away exploration, start with TDD. |\n| \"Test hard = design unclear\" | Listen to test. Hard to test = hard to use. |\n| \"TDD will slow me down\" | TDD faster than debugging. Pragmatic = test-first. |\n| \"Manual test faster\" | Manual doesn't prove edge cases. You'll re-test every change. |\n| \"Existing code has no tests\" | You're improving it. Add tests for existing code. |\n\n## Red Flags - STOP and Start Over\n\n- Code before test\n- Test after implementation\n- Test passes immediately\n- Can't explain why test failed\n- Tests added \"later\"\n- Rationalizing \"just this once\"\n- \"I already manually tested it\"\n- \"Tests after achieve the same purpose\"\n- \"It's about spirit not ritual\"\n- \"Keep as reference\" or \"adapt existing code\"\n- \"Already spent X hours, deleting is wasteful\"\n- \"TDD is dogmatic, I'm being pragmatic\"\n- \"This is different because...\"\n\n**All of these mean: Delete code. Start over with TDD.**\n\n## Example: Bug Fix\n\n**Bug:** Empty email accepted  **RED:** `test('rejects empty email', ...)`  **Verify RED:** `FAIL: expected 'Email required', got undefined`  **GREEN:** Add `if (!data.email?.trim()) return { error: 'Email required' }`  **Verify GREEN:** `PASS`  **REFACTOR:** Extract validation if needed.\n\n## Verification Checklist\n\nBefore marking work complete:\n\n- [ ] Every new function/method has a test\n- [ ] Watched each test fail before implementing\n- [ ] Each test failed for expected reason (feature missing, not typo)\n- [ ] Wrote minimal code to pass each test\n- [ ] All tests pass\n- [ ] Output pristine (no errors, warnings)\n- [ ] Tests use real code (mocks only if unavoidable)\n- [ ] Edge cases and errors covered\n\nCan't check all boxes? You skipped TDD. Start over.\n\n## When Stuck\n\n| Problem | Solution |\n|---------|----------|\n| Don't know how to test | Write wished-for API. Write assertion first. Ask your human partner. |\n| Test too complicated | Design too complicated. Simplify interface. |\n| Must mock everything | Code too coupled. Use dependency injection. |\n| Test setup huge | Extract helpers. Still complex? Simplify design. |\n\n## Debugging Integration\n\nBug found? Write failing test reproducing it. Follow TDD cycle. Test proves fix and prevents regression.\n\nNever fix bugs without a test.\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **Exit Criteria:** See `skills/shared-patterns/exit-criteria.md`\n- **TodoWrite:** See `skills/shared-patterns/todowrite-integration.md`\n\nApply ALL patterns when using this skill.\n\n---\n\n## Violation Recovery Quick Reference\n\n| Violation | Detection | Recovery |\n|-----------|-----------|----------|\n| **Code before test** | Implementation exists, no test file | DELETE code (`rm`), write test, verify RED, reimplement |\n| **FALSE GREEN** | Test passes immediately, no implementation | Test is broken - make stricter until it fails correctly |\n| **Kept \"reference\"** | Stash/backup/clipboard exists | Delete permanently (`git stash drop`, `rm`), start fresh |\n\n**Why recovery matters:** Test must fail first to prove it tests something. Keeping code means you'll adapt it instead of implementing from tests.\n\n---\n\n## Final Rule\n\n```\nProduction code  test exists and failed first\nOtherwise  not TDD\n```\n\nNo exceptions without your human partner's permission."
              },
              {
                "name": "ring:testing-agents-with-subagents",
                "description": "Agent testing methodology - run agents with test inputs, observe outputs,\niterate until outputs are accurate and well-structured.\n",
                "path": "default/skills/testing-agents-with-subagents/SKILL.md",
                "frontmatter": {
                  "name": "ring:testing-agents-with-subagents",
                  "description": "Agent testing methodology - run agents with test inputs, observe outputs,\niterate until outputs are accurate and well-structured.\n",
                  "trigger": "- Before deploying a new agent\n- After editing an existing agent\n- Agent produces structured outputs that must be accurate\n",
                  "skip_when": "- Agent is simple passthrough  minimal testing needed\n- Agent already tested for this use case\n",
                  "related": {
                    "complementary": [
                      "test-driven-development"
                    ]
                  }
                },
                "content": "# Testing Agents With Subagents\n\n## Overview\n\n**Testing agents is TDD applied to AI worker definitions.**\n\nYou run agents with known test inputs (RED - observe incorrect outputs), fix the agent definition (GREEN - outputs now correct), then handle edge cases (REFACTOR - robust under all conditions).\n\n**Core principle:** If you didn't run an agent with test inputs and verify its outputs, you don't know if the agent works correctly.\n\n**REQUIRED BACKGROUND:** You MUST understand `test-driven-development` before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill provides agent-specific test formats (test inputs, output verification, accuracy metrics).\n\n**Key difference from testing-skills-with-subagents:**\n- **Skills** = instructions that guide behavior; test if agent follows rules under pressure\n- **Agents** = separate Claude instances via Task tool; test if they produce correct outputs\n\n## The Iron Law\n\n```\nNO AGENT DEPLOYMENT WITHOUT RED-GREEN-REFACTOR TESTING FIRST\n```\n\nAbout to deploy an agent without completing the test cycle? You have ONLY one option:\n\n### STOP. TEST FIRST. THEN DEPLOY.\n\n**You CANNOT:**\n-  \"Deploy and monitor for issues\"\n-  \"Test with first real usage\"\n-  \"Quick smoke test is enough\"\n-  \"Tested manually in Claude UI\"\n-  \"One test case passed\"\n-  \"Agent prompt looks correct\"\n-  \"Based on working template\"\n-  \"Deploy now, test in parallel\"\n-  \"Production is down, no time to test\"\n\n**ZERO exceptions. Simple agent, expert confidence, time pressure, production outage - NONE override testing.**\n\n**Why this is absolute:** Untested agents fail in production. Every time. The question is not IF but WHEN and HOW BADLY. A 20-minute test suite prevents hours of debugging and lost trust.\n\n## When to Use\n\nTest agents that:\n- Analyze code/designs and produce findings (reviewers)\n- Generate structured outputs (planners, analyzers)\n- Make decisions or categorizations (severity, priority)\n- Have defined output schemas that must be followed\n- Are used in parallel workflows where consistency matters\n\n**Test exemptions require explicit human partner approval:**\n- Simple pass-through agents (just reformatting) - **only if human partner confirms**\n- Agents without structured outputs - **only if human partner confirms**\n- **You CANNOT self-determine test exemption**\n- **When in doubt  TEST**\n\n## TDD Mapping for Agent Testing\n\n| TDD Phase | Agent Testing | What You Do |\n|-----------|---------------|-------------|\n| **RED** | Run with test inputs | Dispatch agent, observe incorrect/incomplete outputs |\n| **Verify RED** | Document failures | Capture exact output issues verbatim |\n| **GREEN** | Fix agent definition | Update prompt/schema to address failures |\n| **Verify GREEN** | Re-run tests | Agent now produces correct outputs |\n| **REFACTOR** | Test edge cases | Ambiguous inputs, empty inputs, complex scenarios |\n| **Stay GREEN** | Re-verify all | Previous tests still pass after changes |\n\nSame cycle as code TDD, different test format.\n\n## RED Phase: Baseline Testing (Observe Failures)\n\n**Goal:** Run agent with known test inputs - observe what's wrong, document exact failures.\n\nThis is identical to TDD's \"write failing test first\" - you MUST see what the agent actually produces before fixing the definition.\n\n**Process:**\n\n- [ ] **Create test inputs** (known issues, edge cases, clean inputs)\n- [ ] **Run agent** - dispatch via Task tool with test inputs\n- [ ] **Compare outputs** - expected vs actual\n- [ ] **Document failures** - missing findings, wrong severity, bad format\n- [ ] **Identify patterns** - which input types cause failures?\n\n### Test Input Categories\n\n| Category | Purpose | Example |\n|----------|---------|---------|\n| **Known Issues** | Verify agent finds real problems | Code with SQL injection, hardcoded secrets |\n| **Clean Inputs** | Verify no false positives | Well-written code with no issues |\n| **Edge Cases** | Verify robustness | Empty files, huge files, unusual patterns |\n| **Ambiguous Cases** | Verify judgment | Code that could go either way |\n| **Severity Calibration** | Verify severity accuracy | Mix of critical, high, medium, low issues |\n\n### Minimum Test Suite Requirements\n\nBefore deploying ANY agent, you MUST have:\n\n| Agent Type | Minimum Test Cases | Required Coverage |\n|------------|-------------------|-------------------|\n| **Reviewer agents** | 6 tests | 2 known issues, 2 clean, 1 edge case, 1 ambiguous |\n| **Analyzer agents** | 5 tests | 2 typical, 1 empty, 1 large, 1 malformed |\n| **Decision agents** | 4 tests | 2 clear cases, 2 boundary cases |\n| **Planning agents** | 5 tests | 2 standard, 1 complex, 1 minimal, 1 edge case |\n\n**Fewer tests = incomplete testing = DO NOT DEPLOY.**\n\nOne test case proves nothing. Three tests are suspicious. Six tests are minimum for confidence.\n\n### Example Test Suite for Code Reviewer\n\n| Test | Input | Expected |\n|------|-------|----------|\n| SQL Injection | String concatenation in SQL | CRITICAL, OWASP A03:2021 |\n| Clean Auth | Proper JWT validation | No findings or LOW only |\n| Ambiguous Error | Caught but only logged | MEDIUM silent failure |\n| Empty File | Empty source | Graceful handling |\n\n### Running the Test\n\nDispatch via Task tool with test input  **Document exact output verbatim** (don't summarize).\n\n## GREEN Phase: Fix Agent Definition (Make Tests Pass)\n\nWrite/update agent definition addressing specific failures documented in RED phase.\n\n**Common fixes:**\n\n| Failure Type | Fix Approach |\n|--------------|--------------|\n| Missing findings | Add explicit instructions to check for X |\n| Wrong severity | Add severity calibration examples |\n| Bad output format | Add output schema with examples |\n| False positives | Add \"don't flag X when Y\" instructions |\n| Incomplete analysis | Add \"always check A, B, C\" checklist |\n\n### Example Fix: Severity Calibration\n\n**RED Failure:** Agent marked hardcoded password as MEDIUM instead of CRITICAL\n\n**GREEN Fix:** Add severity calibration: CRITICAL (hardcoded secrets, SQL injection, auth bypass), HIGH (missing validation, error exposure), MEDIUM (rate limiting, verbose errors), LOW (headers, deps)\n\n### Re-run Tests\n\nAfter fixing, re-run ALL test cases. If any fail  continue fixing, re-test.\n\n## VERIFY GREEN: Output Verification\n\n**Goal:** Confirm agent produces correct, well-structured outputs consistently.\n\n### Accuracy Metrics\n\n| Metric | Target |\n|--------|--------|\n| True Positives | 100% |\n| False Positives | <10% |\n| False Negatives | <5% |\n| Severity Accuracy | >90% |\n| Schema Compliance | 100% |\n\n### Consistency Testing\n\nRun same input 3 times  outputs should be identical. Inconsistency indicates ambiguous agent definition.\n\n## REFACTOR Phase: Edge Cases and Robustness\n\nAgent passes basic tests? Now test edge cases.\n\n### Edge Case Categories\n\n| Category | Test Cases |\n|----------|------------|\n| **Empty/Null** | Empty file, null input, whitespace only |\n| **Large** | 10K line file, deeply nested code |\n| **Unusual** | Minified code, generated code, config files |\n| **Multi-language** | Mixed JS/TS, embedded SQL, templates |\n| **Ambiguous** | Code that could be good or bad depending on context |\n\n### Stress Testing\n\nTest edge cases: Large file (5000 lines, 20 issues), Complex nesting (15-level deep). Verify all issues found with reasonable response time.\n\n### Ambiguity Testing\n\nTest context-dependent cases (e.g., hardcoded password with \"local dev\" comment). Agent should flag but acknowledge context.\n\n### Plugging Holes\n\nFor each edge case failure, add explicit handling to agent definition:\n- Empty files: Return \"No code to review\" with PASS\n- Large files: Focus on high-risk patterns first\n- Minified code: Note limitations\n- Context comments: Consider but don't use to dismiss issues\n## Testing Parallel Agent Workflows\n\nWhen agents run in parallel (like 3 reviewers), test combined workflow:\n- **Parallel Consistency**: Same input to all reviewers  check findings overlap appropriately, no contradictions\n- **Aggregation Testing**: Same issue found by multiple reviewers  severity should be consistent; fix misalignments\n\n## Agent Testing Checklist\n\n**RED Phase:** Create test inputs (known issues, clean, edge cases)  Run agent  Document failures verbatim\n\n**GREEN Phase:** Update agent definition  Re-run tests  All pass\n\n**REFACTOR Phase:** Test edge cases  Test stress scenarios  Add explicit handling  Verify consistency (3+ runs)  Test parallel integration (if applicable)  Re-run ALL tests after each change\n\n**Metrics (reviewer agents):** True positive >95%, False positive <10%, False negative <5%, Severity accuracy >90%, Schema compliance 100%, Consistency >95%\n\n## Prohibited Testing Shortcuts\n\n**You CANNOT substitute proper testing with:**\n\n| Shortcut | Why It Fails |\n|----------|--------------|\n| Reading agent definition carefully | Reading  executing. Must run agent with inputs. |\n| Manual testing in Claude UI | Ad-hoc  reproducible. No baseline documented. |\n| \"Looks good to me\" review | Visual inspection misses runtime failures. |\n| Basing on proven template | Templates need validation for YOUR use case. |\n| Expert prompt engineering knowledge | Expertise doesn't prevent bugs. Tests do. |\n| Testing after first production use | Production is not QA. Test before deployment. |\n| Monitoring production for issues | Reactive  proactive. Catch issues before users do. |\n| Deploy now, test in parallel | Parallel testing still means untested code in production. |\n\n**ALL require running agent with documented test inputs and comparing outputs.**\n\n## Testing Agent Modifications\n\n**EVERY agent edit requires re-running the FULL test suite:**\n\n| Change Type | Required Action |\n|-------------|-----------------|\n| Prompt wording changes | Full re-test |\n| Severity calibration updates | Full re-test |\n| Output schema modifications | Full re-test |\n| Adding edge case handling | Full re-test |\n| \"Small\" one-line changes | Full re-test |\n| Typo fixes in prompt | Full re-test |\n\n**\"Small change\" is not an exception.** One-line prompt changes can completely alter LLM behavior. Re-test always.\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Testing only \"happy path\" inputs | Include ambiguous + edge cases |\n| Not documenting exact outputs | Capture verbatim, compare to expected |\n| Fixing without re-running all tests | Re-run entire suite after each change |\n| Testing single agent in isolation (parallel workflow) | Test parallel dispatch + aggregation |\n| Not testing consistency | Run same input 3+ times |\n| Skipping severity calibration | Add explicit severity examples |\n| Not testing edge cases | Test empty, large, unusual, ambiguous |\n| Single test case validation | Minimum 4-6 test cases per agent type |\n| Manual UI testing as substitute | Document all test inputs and expected outputs |\n| Skipping re-test for \"small\" changes | Re-run full suite after ANY modification |\n\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"Agent prompt is obviously correct\" | Obvious prompts fail in practice. Test proves correctness. |\n| \"Tested manually in Claude UI\" | Ad-hoc  reproducible. No baseline documented. |\n| \"One test case passed\" | Sample size = 1 proves nothing. Need 4-6 cases minimum. |\n| \"Will test after first production use\" | Production is not QA. Test before deployment. Always. |\n| \"Reading prompt is sufficient review\" | Reading  executing. Must run agent with inputs. |\n| \"Changes are small, re-test unnecessary\" | Small changes cause big failures. Re-run full suite. |\n| \"Based agent on proven template\" | Templates need validation for your use case. Test anyway. |\n| \"Expert in prompt engineering\" | Expertise doesn't prevent bugs. Tests do. |\n| \"Production is down, no time to test\" | Deploying untested fix may make outage worse. Test first. |\n| \"Deploy now, test in parallel\" | Untested code in production = unknown behavior. Unacceptable. |\n| \"Quick smoke test is enough\" | Smoke test misses edge cases. Full suite required. |\n| \"Simple pass-through agent\" | You cannot self-determine exemptions. Get human approval. |\n\n## Red Flags - STOP and Test Now\n\nIf you catch yourself thinking ANY of these, STOP. You're about to violate the Iron Law:\n\n- Agent edited but tests not re-run\n- \"Looks good\" without execution\n- Single test case only\n- No documented baseline\n- No edge case testing\n- Manual verification only\n- \"Will test in production\"\n- \"Based on template, should work\"\n- \"Just a small prompt change\"\n- \"No time to test properly\"\n- \"One quick test is enough\"\n- \"Agent is simple, obviously works\"\n- \"Expert intuition says it's fine\"\n- \"Production is down, skip testing\"\n- \"Deploy now, test in parallel\"\n\n**All of these mean: STOP. Run full RED-GREEN-REFACTOR cycle NOW.**\n\n## Quick Reference (TDD Cycle for Agents)\n\n| TDD Phase | Agent Testing | Success Criteria |\n|-----------|---------------|------------------|\n| **RED** | Run with test inputs | Document exact output failures |\n| **Verify RED** | Capture verbatim | Have specific issues to fix |\n| **GREEN** | Fix agent definition | All basic tests pass |\n| **Verify GREEN** | Re-run all tests | No regressions |\n| **REFACTOR** | Test edge cases | Robust under all conditions |\n| **Stay GREEN** | Full test suite | All tests pass, metrics met |\n\n## Example: Testing a New Reviewer Agent\n\n### Step 1: Create Test Suite\n\n| Test | Input | Expected |\n|------|-------|----------|\n| SQL Injection | `\"SELECT * FROM users WHERE id = \" + user_id` | CRITICAL, OWASP A03:2021 |\n| Parameterized (Clean) | `db.execute(query, [user_id])` | No findings |\n| Hardcoded Secret | `API_KEY = \"sk-1234...\"` | CRITICAL |\n| Env Variable (Clean) | `os.environ.get(\"API_KEY\")` | No findings |\n| Empty File | (empty) | Graceful handling |\n| Ambiguous | `password = \"dev123\"  # Local dev` | Flag with context |\n\n**Step 2: RED Phase** - Run tests, document failures: Test 1 marked HIGH not CRITICAL, Test 3 missed, Test 5 errored, Test 6 dismissed.\n\n**Step 3: GREEN Phase** - Fix definition: Add severity calibration (SQL=CRITICAL), hardcoded secrets pattern, empty file handling, \"context comments dont dismiss issues\".\n\n**Step 4: Re-run** - All tests pass with correct severities and handling.\n\n**Step 5: REFACTOR** - Add edge cases: minified code, 10K line file, mixed languages, nested vulnerabilities. Run, fix, repeat.\n\n\n## The Bottom Line\n\n**Agent testing IS TDD. Same principles, same cycle, same benefits.**\n\nIf you wouldn't deploy code without tests, don't deploy agents without testing them.\n\nRED-GREEN-REFACTOR for agents works exactly like RED-GREEN-REFACTOR for code:\n1. **RED:** See what's wrong (run with test inputs)\n2. **GREEN:** Fix it (update agent definition)\n3. **REFACTOR:** Make it robust (edge cases, consistency)\n\n**Evidence before deployment. Always.**"
              },
              {
                "name": "ring:testing-anti-patterns",
                "description": "Test quality guard - prevents testing mock behavior, production pollution with\ntest-only methods, and mocking without understanding dependencies.\n",
                "path": "default/skills/testing-anti-patterns/SKILL.md",
                "frontmatter": {
                  "name": "ring:testing-anti-patterns",
                  "description": "Test quality guard - prevents testing mock behavior, production pollution with\ntest-only methods, and mocking without understanding dependencies.\n",
                  "trigger": "- Reviewing or modifying existing tests\n- Adding mocks to tests\n- Tempted to add test-only methods to production code\n- Tests passing but seem to test the wrong things\n",
                  "skip_when": "- Writing new tests via TDD  TDD prevents these patterns\n- Pure unit tests without mocks  check other quality concerns\n",
                  "related": {
                    "complementary": [
                      "test-driven-development"
                    ]
                  }
                },
                "content": "# Testing Anti-Patterns\n\n## Overview\n\nTests must verify real behavior, not mock behavior. Mocks are a means to isolate, not the thing being tested.\n\n**Core principle:** Test what the code does, not what the mocks do.\n\n**Following strict TDD prevents these anti-patterns.**\n\n## The Iron Laws\n\n```\n1. NEVER test mock behavior\n2. NEVER add test-only methods to production classes\n3. NEVER mock without understanding dependencies\n```\n\n## Anti-Pattern 1: Testing Mock Behavior\n\n**BAD:** `expect(screen.getByTestId('sidebar-mock')).toBeInTheDocument()` - testing mock exists, not real behavior.\n\n**GOOD:** `expect(screen.getByRole('navigation')).toBeInTheDocument()` - test real component or don't mock.\n\n**Gate:** Before asserting on mock element  \"Am I testing real behavior or mock existence?\" If mock  delete assertion or unmock.\n\n## Anti-Pattern 2: Test-Only Methods in Production\n\n**BAD:** `session.destroy()` method only used in tests - pollutes production, dangerous if called.\n\n**GOOD:** `cleanupSession(session)` in test-utils/ - keeps production clean.\n\n**Gate:** \"Is this method only used by tests?\"  Put in test utilities. \"Does this class own this lifecycle?\"  If no, wrong class.\n\n## Anti-Pattern 3: Mocking Without Understanding\n\n**BAD:** Mocking `discoverAndCacheTools` breaks config write test depends on - test passes for wrong reason.\n\n**GOOD:** Mock only the slow part (`MCPServerManager`), preserve behavior test needs.\n\n**Gate:** Before mocking  (1) What side effects does real method have? (2) Does test depend on them? If yes  mock at lower level. **Red flags:** \"Mock to be safe\", \"might be slow\", mocking without understanding.\n\n## Anti-Pattern 4: Incomplete Mocks\n\n**BAD:** Partial mock missing `metadata` field - breaks when downstream code accesses `response.metadata.requestId`.\n\n**GOOD:** Complete mock mirroring real API - ALL fields real API returns.\n\n**Iron Rule:** Mock COMPLETE data structure, not just fields your test uses. Partial mocks fail silently.\n\n**Gate:** Before mock  Check real API response, include ALL fields. If uncertain  include all documented fields.\n\n## Anti-Pattern 5: Integration Tests as Afterthought\n\n**BAD:** \"Implementation complete\" without tests. **FIX:** TDD cycle: write test  implement  refactor  claim complete.\n\n## When Mocks Become Too Complex\n\n**Warning signs:** Mock setup longer than test logic, mocking everything, mocks missing methods real components have. **Consider:** Integration tests with real components often simpler than complex mocks.\n\n## TDD Prevents These Anti-Patterns\n\nTDD forces: (1) Think about what you're testing, (2) Watch fail confirms real behavior not mocks, (3) See what test needs before mocking. **If testing mock behavior, you violated TDD.**\n\n## Quick Reference\n\n| Anti-Pattern | Fix |\n|--------------|-----|\n| Assert on mock elements | Test real component or unmock it |\n| Test-only methods in production | Move to test utilities |\n| Mock without understanding | Understand dependencies first, mock minimally |\n| Incomplete mocks | Mirror real API completely |\n| Tests as afterthought | TDD - tests first |\n| Over-complex mocks | Consider integration tests |\n\n## Red Flags\n\n- Assertion checks for `*-mock` test IDs\n- Methods only called in test files\n- Mock setup is >50% of test\n- Test fails when you remove mock\n- Can't explain why mock is needed\n- Mocking \"just to be safe\"\n\n## The Bottom Line\n\n**Mocks are tools to isolate, not things to test.**\n\nIf TDD reveals you're testing mock behavior, you've gone wrong.\n\nFix: Test real behavior or question why you're mocking at all."
              },
              {
                "name": "ring:testing-skills-with-subagents",
                "description": "Skill testing methodology - run scenarios without skill (RED), observe failures,\nwrite skill (GREEN), close loopholes (REFACTOR).\n",
                "path": "default/skills/testing-skills-with-subagents/SKILL.md",
                "frontmatter": {
                  "name": "ring:testing-skills-with-subagents",
                  "description": "Skill testing methodology - run scenarios without skill (RED), observe failures,\nwrite skill (GREEN), close loopholes (REFACTOR).\n",
                  "trigger": "- Before deploying a new skill\n- After editing an existing skill\n- Skill enforces discipline that could be rationalized away\n",
                  "skip_when": "- Pure reference skill  no behavior to test\n- No rules that agents have incentive to bypass\n",
                  "related": {
                    "complementary": [
                      "writing-skills",
                      "test-driven-development"
                    ]
                  }
                },
                "content": "# Testing Skills With Subagents\n\n## Overview\n\n**Testing skills is just TDD applied to process documentation.**\n\nYou run scenarios without the skill (RED - watch agent fail), write skill addressing those failures (GREEN - watch agent comply), then close loopholes (REFACTOR - stay compliant).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill prevents the right failures.\n\n**REQUIRED BACKGROUND:** You MUST understand test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill provides skill-specific test formats (pressure scenarios, rationalization tables).\n\n**Complete worked example:** See examples/CLAUDE_MD_TESTING.md for a full test campaign testing CLAUDE.md documentation variants.\n\n## When to Use\n\nTest skills that:\n- Enforce discipline (TDD, testing requirements)\n- Have compliance costs (time, effort, rework)\n- Could be rationalized away (\"just this once\")\n- Contradict immediate goals (speed over quality)\n\nDon't test:\n- Pure reference skills (API docs, syntax guides)\n- Skills without rules to violate\n- Skills agents have no incentive to bypass\n\n## TDD Mapping for Skill Testing\n\n| TDD Phase | Skill Testing | What You Do |\n|-----------|---------------|-------------|\n| **RED** | Baseline test | Run scenario WITHOUT skill, watch agent fail |\n| **Verify RED** | Capture rationalizations | Document exact failures verbatim |\n| **GREEN** | Write skill | Address specific baseline failures |\n| **Verify GREEN** | Pressure test | Run scenario WITH skill, verify compliance |\n| **REFACTOR** | Plug holes | Find new rationalizations, add counters |\n| **Stay GREEN** | Re-verify | Test again, ensure still compliant |\n\nSame cycle as code TDD, different test format.\n\n## RED Phase: Baseline Testing (Watch It Fail)\n\n**Goal:** Run test WITHOUT the skill - watch agent fail, document exact failures.\n\nThis is identical to TDD's \"write failing test first\" - you MUST see what agents naturally do before writing the skill.\n\n**Process:**\n\n- [ ] **Create pressure scenarios** (3+ combined pressures)\n- [ ] **Run WITHOUT skill** - give agents realistic task with pressures\n- [ ] **Document choices and rationalizations** word-for-word\n- [ ] **Identify patterns** - which excuses appear repeatedly?\n- [ ] **Note effective pressures** - which scenarios trigger violations?\n\n**Example:** Scenario: \"4 hours implementing, manually tested, 6pm, dinner 6:30pm, forgot TDD. Options: A) Delete+TDD tomorrow, B) Commit now, C) Write tests now.\"\n\nRun WITHOUT skill  Agent chooses B/C with rationalizations: \"manually tested\", \"tests after same goals\", \"deleting wasteful\", \"pragmatic not dogmatic\".\n\n**NOW you know exactly what the skill must prevent.**\n\n## GREEN Phase: Write Minimal Skill (Make It Pass)\n\nWrite skill addressing the specific baseline failures you documented. Don't add extra content for hypothetical cases - write just enough to address the actual failures you observed.\n\nRun same scenarios WITH skill. Agent should now comply.\n\nIf agent still fails: skill is unclear or incomplete. Revise and re-test.\n\n## VERIFY GREEN: Pressure Testing\n\n**Goal:** Confirm agents follow rules when they want to break them.\n\n**Method:** Realistic scenarios with multiple pressures.\n\n### Writing Pressure Scenarios\n\n| Quality | Example | Why |\n|---------|---------|-----|\n| **Bad** | \"What does the skill say?\" | Too academic, agent recites |\n| **Good** | \"Production down, $10k/min, 5 min window\" | Single pressure (time+authority) |\n| **Great** | \"3hr/200 lines done, 6pm, dinner plans, forgot TDD. A) Delete B) Commit C) Tests now\" | Multiple pressures + forced choice |\n\n### Pressure Types\n\n| Pressure | Example |\n|----------|---------|\n| **Time** | Emergency, deadline, deploy window closing |\n| **Sunk cost** | Hours of work, \"waste\" to delete |\n| **Authority** | Senior says skip it, manager overrides |\n| **Economic** | Job, promotion, company survival at stake |\n| **Exhaustion** | End of day, already tired, want to go home |\n| **Social** | Looking dogmatic, seeming inflexible |\n| **Pragmatic** | \"Being pragmatic vs dogmatic\" |\n\n**Best tests combine 3+ pressures.**\n\n**Why this works:** See persuasion-principles.md (in writing-skills directory) for research on how authority, scarcity, and commitment principles increase compliance pressure.\n\n### Key Elements\n\nConcrete A/B/C options, real constraints (times, consequences), real file paths, \"What do you do?\" (not \"should\"), no easy outs.\n\n**Setup:** \"IMPORTANT: Real scenario. Choose and act. You have access to: [skill-being-tested]\"\n\n## REFACTOR Phase: Close Loopholes (Stay Green)\n\nAgent violated rule despite having the skill? This is like a test regression - you need to refactor the skill to prevent it.\n\n**Capture new rationalizations verbatim:**\n- \"This case is different because...\"\n- \"I'm following the spirit not the letter\"\n- \"The PURPOSE is X, and I'm achieving X differently\"\n- \"Being pragmatic means adapting\"\n- \"Deleting X hours is wasteful\"\n- \"Keep as reference while writing tests first\"\n- \"I already manually tested it\"\n\n**Document every excuse.** These become your rationalization table.\n\n### Plugging Each Hole\n\nFor each rationalization, add:\n\n| Component | Add |\n|-----------|-----|\n| **Rules** | Explicit negation: \"Delete means delete. No reference, no adapt, no look.\" |\n| **Rationalization Table** | `\"Keep as reference\"  \"You'll adapt it. That's testing after.\"` |\n| **Red Flags** | Entry: \"Keep as reference\", \"spirit not letter\" |\n| **Description** | Symptoms: \"when tempted to test after, when manually testing seems faster\" |\n\n### Re-verify After Refactoring\n\n**Re-test same scenarios with updated skill.**\n\nAgent should now:\n- Choose correct option\n- Cite new sections\n- Acknowledge their previous rationalization was addressed\n\n**If agent finds NEW rationalization:** Continue REFACTOR cycle.\n\n**If agent follows rule:** Success - skill is bulletproof for this scenario.\n\n## Meta-Testing (When GREEN Isn't Working)\n\n**Ask agent:** \"You read the skill and chose C anyway. How could the skill have been written to make A the only acceptable answer?\"\n\n| Response | Diagnosis | Fix |\n|----------|-----------|-----|\n| \"Skill WAS clear, I chose to ignore\" | Need stronger principle | Add \"Violating letter is violating spirit\" |\n| \"Skill should have said X\" | Documentation problem | Add their suggestion verbatim |\n| \"I didn't see section Y\" | Organization problem | Make key points more prominent |\n\n## When Skill is Bulletproof\n\n**Signs of bulletproof skill:**\n\n1. **Agent chooses correct option** under maximum pressure\n2. **Agent cites skill sections** as justification\n3. **Agent acknowledges temptation** but follows rule anyway\n4. **Meta-testing reveals** \"skill was clear, I should follow it\"\n\n**Not bulletproof if:**\n- Agent finds new rationalizations\n- Agent argues skill is wrong\n- Agent creates \"hybrid approaches\"\n- Agent asks permission but argues strongly for violation\n\n## Example: TDD Skill Bulletproofing\n\n| Iteration | Action | Result |\n|-----------|--------|--------|\n| Initial | Scenario: 200 lines, forgot TDD | Agent chose C, rationalized \"tests after same goals\" |\n| 1 | Added \"Why Order Matters\" | Still chose C, new rationalization \"spirit not letter\" |\n| 2 | Added \"Violating letter IS violating spirit\" | Agent chose A (delete), cited principle. **Bulletproof.** |\n\n## Testing Checklist\n\n| Phase | Verify |\n|-------|--------|\n| **RED** | Created 3+ pressure scenarios, ran WITHOUT skill, documented failures verbatim |\n| **GREEN** | Wrote skill addressing failures, ran WITH skill, agent complies |\n| **REFACTOR** | Found new rationalizations, added counters, updated table/flags/description, re-tested, meta-tested |\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Writing skill before testing (skip RED) | Always run baseline scenarios first |\n| Academic tests only (no pressure) | Use scenarios that make agent WANT to violate |\n| Single pressure | Combine 3+ pressures (time + sunk cost + exhaustion) |\n| Not capturing exact failures | Document rationalizations verbatim |\n| Vague fixes (\"don't cheat\") | Add explicit negations (\"don't keep as reference\") |\n| Stopping after first pass | Continue REFACTOR until no new rationalizations |\n\n## Quick Reference (TDD Cycle)\n\n| TDD Phase | Skill Testing | Success Criteria |\n|-----------|---------------|------------------|\n| **RED** | Run scenario without skill | Agent fails, document rationalizations |\n| **Verify RED** | Capture exact wording | Verbatim documentation of failures |\n| **GREEN** | Write skill addressing failures | Agent now complies with skill |\n| **Verify GREEN** | Re-test scenarios | Agent follows rule under pressure |\n| **REFACTOR** | Close loopholes | Add counters for new rationalizations |\n| **Stay GREEN** | Re-verify | Agent still complies after refactoring |\n\n## The Bottom Line\n\n**Skill creation IS TDD. Same principles, same cycle, same benefits.**\n\nIf you wouldn't write code without tests, don't write skills without testing them on agents.\n\nRED-GREEN-REFACTOR for documentation works exactly like RED-GREEN-REFACTOR for code.\n\n## Real-World Impact\n\nFrom applying TDD to TDD skill itself (2025-10-03):\n- 6 RED-GREEN-REFACTOR iterations to bulletproof\n- Baseline testing revealed 10+ unique rationalizations\n- Each REFACTOR closed specific loopholes\n- Final VERIFY GREEN: 100% compliance under maximum pressure\n- Same process works for any discipline-enforcing skill"
              },
              {
                "name": "ring:using-git-worktrees",
                "description": "Isolated workspace creation - creates git worktrees with smart directory selection\nand safety verification for parallel feature development.\n",
                "path": "default/skills/using-git-worktrees/SKILL.md",
                "frontmatter": {
                  "name": "ring:using-git-worktrees",
                  "description": "Isolated workspace creation - creates git worktrees with smart directory selection\nand safety verification for parallel feature development.\n",
                  "trigger": "- Starting feature that needs isolation from main workspace\n- Before executing implementation plan\n- Working on multiple features simultaneously\n",
                  "skip_when": "- Quick fix in current branch  stay in place\n- Already in isolated worktree for this feature  continue\n- Repository doesn't use worktrees  use standard branch workflow\n",
                  "sequence": {
                    "after": [
                      "brainstorming"
                    ],
                    "before": [
                      "writing-plans",
                      "executing-plans"
                    ]
                  }
                },
                "content": "# Using Git Worktrees\n\n## Overview\n\nGit worktrees create isolated workspaces sharing the same repository, allowing work on multiple branches simultaneously without switching.\n\n**Core principle:** Systematic directory selection + safety verification = reliable isolation.\n\n**Announce at start:** \"I'm using the using-git-worktrees skill to set up an isolated workspace.\"\n\n## Directory Selection Process\n\n**Priority order:** (1) Existing `.worktrees/` or `worktrees/` (2) CLAUDE.md preference (3) Ask user\n\n```bash\nls -d .worktrees worktrees 2>/dev/null   # Check existing (prefer .worktrees)\ngrep -i \"worktree.*director\" CLAUDE.md    # Check project preference\n```\n\n**If none found, ask:** `.worktrees/` (project-local, hidden) OR `~/.config/ring/worktrees/<project>/` (global)\n\n## Safety Verification\n\n**Project-local directories:** MUST verify .gitignore before creating: `grep -q \"^\\.worktrees/$\\|^worktrees/$\" .gitignore`\n- If NOT in .gitignore: Add it  commit  proceed (fix broken things immediately)\n- **Why critical:** Prevents accidentally committing worktree contents\n\n**Global directory (~/.config/ring/worktrees):** No verification needed - outside project.\n\n## Creation Steps\n\n```bash\n# 1. Detect project\nproject=$(basename \"$(git rev-parse --show-toplevel)\")\n\n# 2. Create worktree (path = $LOCATION/$BRANCH or ~/.config/ring/worktrees/$project/$BRANCH)\ngit worktree add \"$path\" -b \"$BRANCH_NAME\" && cd \"$path\"\n\n# 3. Auto-detect and run setup\n[ -f package.json ] && npm install\n[ -f Cargo.toml ] && cargo build\n[ -f requirements.txt ] && pip install -r requirements.txt\n[ -f pyproject.toml ] && poetry install\n[ -f go.mod ] && go mod download\n\n# 4. Verify clean baseline (npm test / cargo test / pytest / go test ./...)\n```\n\n**If tests fail:** Report failures, ask whether to proceed or investigate.\n**If tests pass:** Report: `Worktree ready at <path> | Tests passing (<N> tests) | Ready to implement <feature>`\n\n## Quick Reference\n\n| Situation | Action |\n|-----------|--------|\n| `.worktrees/` exists | Use it (verify .gitignore) |\n| `worktrees/` exists | Use it (verify .gitignore) |\n| Both exist | Use `.worktrees/` |\n| Neither exists | Check CLAUDE.md  Ask user |\n| Directory not in .gitignore | Add it immediately + commit |\n| Tests fail during baseline | Report failures + ask |\n| No package.json/Cargo.toml | Skip dependency install |\n\n## Common Mistakes\n\n| Mistake | Problem | Fix |\n|---------|---------|-----|\n| Skip .gitignore verification | Worktree contents tracked, pollute git status | Always grep .gitignore first |\n| Assuming directory location | Inconsistency, violates conventions | Follow priority: existing > CLAUDE.md > ask |\n| Proceeding with failing tests | Can't distinguish new vs pre-existing bugs | Report failures, get permission |\n| Hardcoding setup commands | Breaks on different tools | Auto-detect from project files |\n\n## Example Workflow\n\nAnnounce  Check `.worktrees/` exists  Verify .gitignore  `git worktree add .worktrees/auth -b feature/auth`  `npm install`  `npm test` (47 passing)  Report ready\n\n## Red Flags\n\n**Never:**\n- Create worktree without .gitignore verification (project-local)\n- Skip baseline test verification\n- Proceed with failing tests without asking\n- Assume directory location when ambiguous\n- Skip CLAUDE.md check\n\n**Always:**\n- Follow directory priority: existing > CLAUDE.md > ask\n- Verify .gitignore for project-local\n- Auto-detect and run project setup\n- Verify clean test baseline\n\n## Integration\n\n**Called by:**\n- **brainstorming** (Phase 4) - REQUIRED when design is approved and implementation follows\n- Any skill needing isolated workspace\n\n**Pairs with:**\n- **finishing-a-development-branch** - REQUIRED for cleanup after work complete\n- **executing-plans** or **subagent-driven-development** - Work happens in this worktree"
              },
              {
                "name": "ring:using-ring",
                "description": "Mandatory orchestrator protocol - establishes ORCHESTRATOR principle (dispatch agents,\ndon't operate directly) and skill discovery workflow for every conversation.\n",
                "path": "default/skills/using-ring/SKILL.md",
                "frontmatter": {
                  "name": "ring:using-ring",
                  "description": "Mandatory orchestrator protocol - establishes ORCHESTRATOR principle (dispatch agents,\ndon't operate directly) and skill discovery workflow for every conversation.\n",
                  "trigger": "- Every conversation start (automatic via SessionStart hook)\n- Before ANY task (check for applicable skills)\n- When tempted to operate tools directly instead of delegating\n",
                  "skip_when": "- Never skip - this skill is always mandatory\n"
                },
                "content": "<EXTREMELY-IMPORTANT>\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST read the skill.\n\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\n\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\n</EXTREMELY-IMPORTANT>\n\n##  3-FILE RULE: HARD GATE (NON-NEGOTIABLE)\n\n**DO NOT read/edit >3 files directly. PROHIBITION, not guidance.**\n\n```\n3 files  Direct OK (if user requested)\n>3 files  STOP. Launch agent. VIOLATION = 15x context waste.\n```\n\n**Applies to:** Read, Grep/Glob (>3 matches to inspect), Edit, or any combination >3.\n\n**Already at 3 files?** STOP. Dispatch agent NOW with what you've learned.\n\n**Why 3?** 3 files  6-15k tokens. Agent dispatch = ~2k tokens with focused results. Math: >3 = agent is 5-15x more efficient.\n\n##  AUTO-TRIGGER PHRASES: MANDATORY AGENT DISPATCH\n\n**When user says ANY of these, DEFAULT to launching specialist agent:**\n\n| User Phrase Pattern | Mandatory Action |\n|---------------------|------------------|\n| \"fix issues\", \"fix remaining\", \"address findings\" | Launch specialist agent (NOT manual edits) |\n| \"apply fixes\", \"fix the X issues\" | Launch specialist agent |\n| \"fix errors\", \"fix warnings\", \"fix linting\" | Launch specialist agent |\n| \"update across\", \"change all\", \"refactor\" | Launch specialist agent |\n| \"find where\", \"search for\", \"locate\" | Launch Explore agent |\n| \"understand how\", \"how does X work\" | Launch Explore agent |\n\n**Why?** These phrases imply multi-file operations. You WILL exceed 3 files. Pre-empt the violation.\n\n## MANDATORY PRE-ACTION CHECKPOINT\n\n**Before EVERY tool use (Read/Grep/Glob/Bash), complete this. No exceptions.**\n\n```\n STOP. COMPLETE BEFORE PROCEEDING.\n\n1. FILES: ___  >3?  Agent.  Already 3?  Agent now.\n\n2. USER PHRASE:\n    \"fix issues/remaining/findings\"  Agent\n    \"find/search/locate/understand\"  Explore agent\n\n3. DECISION:\n    Investigation  Explore agent\n    Multi-file  Specialist agent\n    User named ONE specific file  Direct OK (rare)\n\nRESULT: [Agent: ___] or [Direct: why]\n\n```\n\n**Skipping = violation. Document decision in TodoWrite.**\n\n# Getting Started with Skills\n\n## MANDATORY FIRST RESPONSE PROTOCOL\n\nBefore responding to ANY user message, you MUST complete this checklist IN ORDER:\n\n1.  **Check for MANDATORY-USER-MESSAGE** - If additionalContext contains `<MANDATORY-USER-MESSAGE>` tags, display the message FIRST, verbatim, at the start of your response\n2.  **ORCHESTRATION DECISION** - Determine which agent handles this task\n   - Create TodoWrite: \"Orchestration decision: [agent-name] with Opus\"\n   - Default model: **Opus** (use unless user specifies otherwise)\n   - If considering direct tools, document why the exception applies (user explicitly requested specific file read)\n   - Mark todo complete only after documenting decision\n3.  **Skill Check** - List available skills in your mind, ask: \"Does ANY skill match this request?\"\n4.  **If yes**  Use the Skill tool to read and run the skill file\n5.  **Announce** - State which skill/agent you're using (when non-obvious)\n6.  **Execute** - Dispatch agent OR follow skill exactly\n\n**Responding WITHOUT completing this checklist = automatic failure.**\n\n### MANDATORY-USER-MESSAGE Contract\n\nIf additionalContext contains `<MANDATORY-USER-MESSAGE>` tags:\n- Display verbatim at message start, no exceptions\n- No paraphrasing, no \"will mention later\" rationalizations\n\n## Critical Rules\n\n1. **Follow mandatory workflows.** Brainstorming before coding. Check for relevant skills before ANY task.\n\n2. Execute skills with the Skill tool\n\n## Common Rationalizations That Mean You're About To Fail\n\nIf you catch yourself thinking ANY of these thoughts, STOP. You are rationalizing. Check for and use the skill. Also check: are you being an OPERATOR instead of ORCHESTRATOR?\n\n**Skill Checks:**\n- \"This is just a simple question\"  WRONG. Questions are tasks. Check for skills.\n- \"This doesn't need a formal skill\"  WRONG. If a skill exists for it, use it.\n- \"I remember this skill\"  WRONG. Skills evolve. Run the current version.\n- \"This doesn't count as a task\"  WRONG. If you're taking action, it's a task. Check for skills.\n- \"The skill is overkill for this\"  WRONG. Skills exist because simple things become complex. Use it.\n- \"I'll just do this one thing first\"  WRONG. Check for skills BEFORE doing anything.\n- \"I need context before checking skills\"  WRONG. Gathering context IS a task. Check for skills first.\n\n**Orchestrator Breaks (Direct Tool Usage):**\n- \"I can check git/files quickly\"  WRONG. Use agents, stay ORCHESTRATOR.\n- \"Let me gather information first\"  WRONG. Dispatch agent to gather it.\n- \"Just a quick look at files\"  WRONG. That \"quick\" becomes 20k tokens. Use agent.\n- \"I'll scan the codebase manually\"  WRONG. That's operator behavior. Use Explore.\n- \"This exploration is too simple for an agent\"  WRONG. Simplicity makes agents more efficient.\n- \"I already started reading files\"  WRONG. Stop. Dispatch agent instead.\n- \"It's faster to do it myself\"  WRONG. You're burning context. Agents are 15x faster contextually.\n\n**3-File Rule Rationalizations (YOU WILL TRY THESE):**\n- \"This task is small\"  WRONG. Count files. >3 = agent. Task size is irrelevant.\n- \"It's only 5 fixes across 5 files, I can handle it\"  WRONG. 5 files > 3 files. Agent mandatory.\n- \"User said 'here' so they want me to do it in this conversation\"  WRONG. \"Here\" means get it done, not manually.\n- \"TodoWrite took priority so I'll execute sequentially\"  WRONG. TodoWrite plans WHAT. Orchestrator decides HOW.\n- \"The 3-file rule is guidance, not a gate\"  WRONG. It's a PROHIBITION. You DO NOT proceed past 3 files.\n- \"User didn't explicitly call an agent so I shouldn't\"  WRONG. Agent dispatch is YOUR decision.\n- \"I'm confident I know where the files are\"  WRONG. Confidence doesn't reduce context cost.\n- \"Let me finish these medium/low fixes here\"  WRONG. \"Fix issues\" phrase = auto-trigger for agent.\n\n**Why:** Skills document proven techniques. Agents preserve context. Not using them means repeating mistakes and wasting tokens.\n\n**Both matter:** Skills check is mandatory. ORCHESTRATOR approach is mandatory.\n\nIf a skill exists or if you're about to use tools directly, you must use the proper approach or you will fail.\n\n## The Cost of Skipping Skills\n\nEvery time you skip checking for skills:\n- You fail your task (skills contain critical patterns)\n- You waste time (rediscovering solved problems)\n- You make known errors (skills prevent common mistakes)\n- You lose trust (not following mandatory workflows)\n\n**This is not optional. Check for skills or fail.**\n\n## ORCHESTRATOR Principle: Agent-First Always\n\n**Your role is ORCHESTRATOR, not operator.**\n\nYou don't read files, run grep chains, or manually explore  you **dispatch agents** to do the work and return results. This is not optional. This is mandatory for context efficiency.\n\n**The Problem with Direct Tool Usage:**\n- Manual exploration chains: ~30-100k tokens in main context\n- Each file read adds context bloat\n- Grep/Glob chains multiply the problem\n- User sees work happening but context explodes\n\n**The Solution: Orchestration:**\n- Dispatch agents to handle complexity\n- Agents return only essential findings (~2-5k tokens)\n- Main context stays lean for reasoning\n- **15x more efficient** than direct file operations\n\n### Your Role: ORCHESTRATOR (No Exceptions)\n\n**You dispatch agents. You do not operate tools directly.**\n\n**Default answer for ANY exploration/search/investigation:** Use one of the three built-in agents (Explore, Plan, or general-purpose) with Opus model.\n\n**Which agent?**\n- **Explore** - Fast codebase navigation, finding files/code, understanding architecture\n- **Plan** - Implementation planning, breaking down features into tasks\n- **general-purpose** - Multi-step research, complex investigations, anything not fitting Explore/Plan\n\n**Model Selection:** Always use **Opus** for agent dispatching unless user explicitly specifies otherwise (e.g., \"use Haiku\", \"use Sonnet\").\n\n**Exceptions to default agents:**\n1. User explicitly provides a file path AND explicitly requests you read it (e.g., \"read src/foo.ts\")\n2. **A skill has its own specialized agents** - Some skills (e.g., `dev-refactor`) define their own agents that MUST be used instead of Explore/Plan/general-purpose. When a skill specifies \"OVERRIDE\" or \"FORBIDDEN agents\", follow the skill's agent requirements, not the defaults above.\n\n**All these are STILL orchestration tasks:**\n-  \"I need to understand the codebase structure first\"  Explore agent\n-  \"Let me check what files handle X\"  Explore agent\n-  \"I'll grep for the function definition\"  Explore agent\n-  \"User mentioned component Y, let me find it\"  Explore agent\n-  \"I'm confident it's in src/foo/\"  Explore agent\n-  \"Just checking one file to confirm\"  Explore agent\n-  \"This search premise seems invalid, won't find anything\"  Explore agent (you're not the validator)\n\n**You don't validate search premises.** Dispatch the agent, let the agent report back if search yields nothing.\n\n**If you're about to use Read, Grep, Glob, or Bash for investigation:**\nYou are breaking ORCHESTRATOR. Use an agent instead.\n\n### Available Agents\n\n**Built-in (Opus):** `Explore` (navigation), `Plan` (implementation), `general-purpose` (research), `claude-code-guide` (docs).\n\n**Ring:** `code-reviewer`, `business-logic-reviewer`, `security-reviewer`, `write-plan`.\n\n### Decision: Which Agent?\n\n| Task Type | Agent (Opus default) |\n|-----------|---------------------|\n| Explore/find/understand/search | **Explore** |\n| Plan implementation, break down features | **Plan** |\n| Multi-step research, complex investigation | **general-purpose** |\n| Code review | ALL THREE in parallel (code, business-logic, security reviewers) |\n| Implementation plan document | write-plan |\n| Claude Code questions | claude-code-guide |\n| User explicitly said \"read [file]\" | Direct (ONLY exception) |\n\n**WRONG  RIGHT:** \"Let me read files\"  Explore. \"I'll grep\"  Explore. \"Already read 3 files\"  STOP, dispatch now.\n\n### Ring Reviewers: ALWAYS Parallel\n\nWhen dispatching code reviewers, **single message with 3 Task calls:**\n\n```\n CORRECT: One message with 3 Task calls (all in parallel)\n WRONG: Three separate messages (sequential, 3x slower)\n```\n\n### Context Efficiency: Orchestrator Wins\n\n| Approach | Context Cost | Your Role |\n|----------|--------------|-----------|\n| Manual file reading (5 files) | ~25k tokens | Operator |\n| Manual grep chains (10 searches) | ~50k tokens | Operator |\n| Explore agent dispatch | ~2-3k tokens | Orchestrator |\n| **Savings** | **15-25x more efficient** | **Orchestrator always wins** |\n\n## TodoWrite Requirements\n\n**First two todos for ANY task:**\n1. \"Orchestration decision: [agent-name] with Opus\" (or exception justification)\n2. \"Check for relevant skills\"\n\n**If skill has checklist:** Create TodoWrite todo for EACH item. No mental checklists.\n\n## Announcing Skill Usage\n\n- **Always announce meta-skills:** brainstorming, writing-plans, systematic-debugging (methodology change)\n- **Skip when obvious:** User says \"write tests first\"  no need to announce TDD\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **Exit Criteria:** See `skills/shared-patterns/exit-criteria.md`\n- **TodoWrite:** See `skills/shared-patterns/todowrite-integration.md`\n\nApply ALL patterns when using this skill.\n\n# About these skills\n\n**Many skills contain rigid rules (TDD, debugging, verification).** Follow them exactly. Don't adapt away the discipline.\n\n**Some skills are flexible patterns (architecture, naming).** Adapt core principles to your context.\n\nThe skill itself tells you which type it is.\n\n## Instructions  Permission to Skip Workflows\n\nYour human partner's specific instructions describe WHAT to do, not HOW.\n\n\"Add X\", \"Fix Y\" = the goal, NOT permission to skip brainstorming, TDD, or RED-GREEN-REFACTOR.\n\n**Red flags:** \"Instruction was specific\"  \"Seems simple\"  \"Workflow is overkill\"\n\n**Why:** Specific instructions mean clear requirements, which is when workflows matter MOST. Skipping process on \"simple\" tasks is how simple tasks become complex problems.\n\n## Context Management & Self-Improvement\n\nRing includes skills for managing context and enabling self-improvement:\n\n| Skill | Use When | Trigger |\n|-------|----------|---------|\n| `continuity-ledger` | Save session state for future resumption | At 70%+ context OR task completion |\n| `create-handoff` | Full handoff document with all context | At 85%+ context OR session end |\n| `artifact-query` | Search past handoffs, plans, or outcomes by keywords | Need historical context |\n| `handoff-tracking` | Mark task completion with what_worked/what_failed/key_decisions | Task complete |\n| `compound-learnings` | Analyze learnings from multiple sessions, detect patterns | After 3+ sessions |\n\n**Compound Learnings workflow:** Session ends  Hook extracts learnings  After 3+ sessions, patterns emerge  User approves  Permanent rules/skills created.\n\n### MANDATORY Context Preservation (NON-NEGOTIABLE)\n\n**Context warnings are BEHAVIORAL TRIGGERS, not informational messages.**\n\n| Context Level | Warning Type | MANDATORY Action |\n|---------------|--------------|------------------|\n| 50-69% (info) | `<context-warning>` | Acknowledge, plan for handoff |\n| 70-84% (warning) | `<MANDATORY-USER-MESSAGE>` | **CREATE ledger NOW** - No exceptions |\n| 85%+ (critical) | `<MANDATORY-USER-MESSAGE>` | **STOP + handoff + /clear** - Immediate |\n\n**When you receive a MANDATORY-USER-MESSAGE about context:**\n1. Display the message verbatim at start of response (per MANDATORY-USER-MESSAGE contract)\n2. Execute the required action BEFORE continuing other work\n3. Do NOT rationalize delaying action\n\n**Anti-Rationalization for Context Management:**\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I'll create handoff after this task\" | Context may truncate mid-task, losing everything | **Create handoff NOW** |\n| \"70% is just a warning, not urgent\" | 70% = MANDATORY action, not suggestion | **Create ledger immediately** |\n| \"The message is informational\" | MANDATORY-USER-MESSAGE = behavioral trigger | **Execute required action** |\n| \"User didn't ask for handoff\" | System requires it for context safety | **Create handoff anyway** |\n| \"I'm almost done, can finish first\" | \"Almost done\" at 85% = high truncation risk | **STOP and handoff NOW** |\n| \"Small task, won't use much more context\" | Every response adds ~2500 tokens | **Follow threshold rules** |\n\n**Verification Checklist:**\n- [ ] At 70%+: Did I create a continuity-ledger?\n- [ ] At 85%+: Did I STOP, create handoff, and recommend /clear?\n- [ ] Did I display MANDATORY-USER-MESSAGE verbatim?\n- [ ] Did I execute required action BEFORE other work?\n\n## Summary\n\n**Starting any task:**\n1. **Orchestration decision**  Which agent handles this? Use **Opus** model by default (TodoWrite required)\n2. **Skill check**  If relevant skill exists, use it\n3. **Announce**  State which skill/agent you're using\n4. **Execute**  Dispatch agent with Opus OR follow skill exactly\n\n**Before ANY tool use (Read/Grep/Glob/Bash):** Complete PRE-ACTION CHECKPOINT.\n\n**Skill has checklist?** TodoWrite for every item.\n\n**Default answer: Use an agent with Opus. Exception is rare (user explicitly requests specific file read).**\n\n**Model default: Opus** (unless user specifies Haiku/Sonnet explicitly).\n\n**Finding a relevant skill = mandatory to read and use it. Not optional.**"
              },
              {
                "name": "ring:verification-before-completion",
                "description": "Evidence-first completion gate - requires running verification commands and\nconfirming output before making any success claims.\n",
                "path": "default/skills/verification-before-completion/SKILL.md",
                "frontmatter": {
                  "name": "ring:verification-before-completion",
                  "description": "Evidence-first completion gate - requires running verification commands and\nconfirming output before making any success claims.\n",
                  "trigger": "- About to claim \"work is complete\"\n- About to claim \"tests pass\"\n- About to claim \"bug is fixed\"\n- Before committing or creating PRs\n",
                  "skip_when": "- Just ran verification command with passing output  proceed\n- Still in development (not claiming completion)  continue working\n",
                  "sequence": {
                    "before": [
                      "finishing-a-development-branch",
                      "requesting-code-review"
                    ]
                  }
                },
                "content": "# Verification Before Completion\n\n## Overview\n\nClaiming work is complete without verification is dishonesty, not efficiency.\n\n**Core principle:** Evidence before claims, always.\n\n**Violating the letter of this rule is violating the spirit of this rule.**\n\n## The Iron Law\n\n```\nNO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE\n```\n\nIf you haven't run the verification command in this message, you cannot claim it passes.\n\n## The Gate Function\n\n```\nBEFORE claiming any status or expressing satisfaction:\n\n1. IDENTIFY: What command proves this claim?\n2. RUN: Execute the FULL command (fresh, complete)\n3. READ: Full output, check exit code, count failures\n4. VERIFY: Does output confirm the claim?\n   - If NO: State actual status with evidence\n   - If YES: State claim WITH evidence\n5. ONLY THEN: Make the claim\n\nSkip any step = lying, not verifying\n```\n\n## The Command-First Rule\n\n**EVERY completion message structure:**\n\n1. FIRST: Run verification command\n2. SECOND: Paste complete output\n3. THIRD: State what output proves\n4. ONLY THEN: Make your claim\n\n**Example structure:**\n```\nLet me verify the implementation:\n\n$ npm test\n[PASTE FULL OUTPUT]\n\nThe tests show 15/15 passing. Implementation is complete.\n```\n\n**Wrong structure (violation):**\n```\nImplementation is complete! Let me verify:\n[This is backwards - claimed before verifying]\n```\n\n## Common Failures\n\n| Claim | Requires | Not Sufficient |\n|-------|----------|----------------|\n| Tests pass | Test command output: 0 failures | Previous run, \"should pass\" |\n| Linter clean | Linter output: 0 errors | Partial check, extrapolation |\n| Build succeeds | Build command: exit 0 | Linter passing, logs look good |\n| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |\n| Regression test works | Red-green cycle verified | Test passes once |\n| Agent completed | VCS diff shows changes | Agent reports \"success\" |\n| Requirements met | Line-by-line checklist | Tests passing |\n\n## Red Flags - STOP\n\n- Using \"should\", \"probably\", \"seems to\"\n- Expressing satisfaction before verification (\"Great!\", \"Perfect!\", \"Done!\", etc.)\n- About to commit/push/PR without verification\n- Trusting agent success reports\n- Relying on partial verification\n- Thinking \"just this once\"\n- Tired and wanting work over\n- **ANY wording implying success without having run verification**\n\n## Banned Phrases (Automatic Violation)\n\n**NEVER use these without evidence:**\n- \"appears to\" / \"seems to\" / \"looks like\"\n- \"should be working\" / \"is now working\"\n- \"implementation complete\" (without test output)\n- \"successfully\" (without command output)\n- \"properly\" / \"correctly\" (without verification)\n- \"all good\" / \"works great\" (without evidence)\n- ANY positive adjective before verification\n\n**Using these = lying, not verifying**\n\n## The False Positive Trap\n\n**About to say \"all tests pass\"?**\n\nCheck:\n- Did you run tests THIS message? (Not last message)\n- Did you paste the output? (Not just claim)\n- Does output show 0 failures? (Not assumed)\n\n**No to any = you're lying**\n\n\"I ran them earlier\" = NOT verification\n\"They should pass now\" = NOT verification\n\"The previous output showed\" = NOT verification\n\n**Run. Paste. Then claim.**\n\n## Rationalization Prevention\n\n| Excuse | Reality |\n|--------|---------|\n| \"Should work now\" | RUN the verification |\n| \"I'm confident\" | Confidence  evidence |\n| \"Just this once\" | No exceptions |\n| \"Linter passed\" | Linter  compiler |\n| \"Agent said success\" | Verify independently |\n| \"I'm tired\" | Exhaustion  excuse |\n| \"Partial check is enough\" | Partial proves nothing |\n| \"Different words so rule doesn't apply\" | Spirit over letter |\n\n## Key Patterns\n\n| Type |  CORRECT |  WRONG |\n|------|-----------|---------|\n| Tests | Run command, see \"34/34 pass\", then claim | \"Should pass now\" |\n| Regression (TDD) | Write  pass  revert  MUST FAIL  restore  pass | \"Written regression test\" (no red-green) |\n| Build | Run build, see exit 0, then claim | \"Linter passed\" (linter  compiler) |\n| Requirements | Re-read plan  checklist  verify each | \"Tests pass, phase complete\" |\n| Agent delegation | Check VCS diff  verify changes | Trust agent report |\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **Exit Criteria:** See `skills/shared-patterns/exit-criteria.md`\n- **TodoWrite:** See `skills/shared-patterns/todowrite-integration.md`\n\nApply ALL patterns when using this skill.\n\n---\n\n## Violation Recovery\n\n| Violation | Detection | Recovery |\n|-----------|-----------|----------|\n| Claimed complete without verification | \"complete\" with no command output, \"should work\" | Run verification  paste output  then claim |\n| Ran command but didn't paste | Mentioned running tests, no output shown | Re-run  copy FULL output  paste  then claim |\n| Used banned phrases | \"appears to work\", \"Great!\", \"Done!\" before evidence | Stop  run verification  paste output  evidence-based claim |\n\n**Why recovery matters:** Claims without evidence = false confidence. Silent failures go undetected until production.\n\n---\n\n## Why This Matters\n\nFrom 24 failure memories:\n- your human partner said \"I don't believe you\" - trust broken\n- Undefined functions shipped - would crash\n- Missing requirements shipped - incomplete features\n- Time wasted on false completion  redirect  rework\n- Violates: \"Honesty is a core value. If you lie, you'll be replaced.\"\n\n## When To Apply\n\n**ALWAYS before:**\n- ANY variation of success/completion claims\n- ANY expression of satisfaction\n- ANY positive statement about work state\n- Committing, PR creation, task completion\n- Moving to next task\n- Delegating to agents\n\n**Rule applies to:**\n- Exact phrases\n- Paraphrases and synonyms\n- Implications of success\n- ANY communication suggesting completion/correctness\n\n## The Bottom Line\n\n**No shortcuts for verification.**\n\nRun the command. Read the output. THEN claim the result.\n\nThis is non-negotiable."
              },
              {
                "name": "ring:writing-plans",
                "description": "Creates comprehensive implementation plans with exact file paths, complete code\nexamples, and verification steps for engineers with zero codebase context.\n",
                "path": "default/skills/writing-plans/SKILL.md",
                "frontmatter": {
                  "name": "ring:writing-plans",
                  "description": "Creates comprehensive implementation plans with exact file paths, complete code\nexamples, and verification steps for engineers with zero codebase context.\n",
                  "trigger": "- Design phase complete (brainstorming/PRD/TRD validated)\n- Need to create executable task breakdown\n- Creating work for other engineers or AI agents\n",
                  "skip_when": "- Design not validated  use brainstorming first\n- Requirements still unclear  use pre-dev-prd-creation first\n- Already have a plan  use executing-plans\n",
                  "sequence": {
                    "after": [
                      "brainstorming",
                      "pre-dev-trd-creation"
                    ],
                    "before": [
                      "executing-plans",
                      "subagent-driven-development"
                    ]
                  },
                  "related": {
                    "similar": [
                      "brainstorming"
                    ]
                  }
                },
                "content": "# Writing Plans\n\n## Overview\n\nThis skill dispatches a specialized agent to write comprehensive implementation plans for engineers with zero codebase context.\n\n**Announce at start:** \"I'm using the writing-plans skill to create the implementation plan.\"\n\n**Context:** This should be run in a dedicated worktree (created by brainstorming skill).\n\n## The Process\n\n**Step 1: Query Historical Precedent (MANDATORY)**\n\nBefore planning, query the artifact index for historical context:\n\n```bash\n# Keywords MUST be alphanumeric with spaces only (sanitize before use)\npython3 default/lib/artifact-index/artifact_query.py --mode planning \"keywords\" --json\n```\n\n**Keyword Extraction (MANDATORY):**\n1. Extract topic keywords from the planning request\n2. Sanitize keywords: Keep only alphanumeric characters, hyphens, and spaces\n3. Example: \"Implement OAuth2 authentication!\"  keywords: \"oauth2 authentication\"\n\n**Safety:** Never include shell metacharacters (`;`, `$`, `` ` ``, `|`, `&`) in keywords.\n\nResults inform the plan:\n- `successful_handoffs`  Reference patterns that worked\n- `failed_handoffs`  WARN in plan, design to avoid\n- `relevant_plans`  Review for approach ideas\n\nIf `is_empty_index: true`  Proceed without precedent (normal for new projects).\n\n**Step 2: Dispatch Write-Plan Agent**\n\nDispatch via `Task(subagent_type: \"ring:write-plan\", model: \"opus\")` with:\n- Instructions to create bite-sized tasks (2-5 min each)\n- Include exact file paths, complete code, verification steps\n- **Include Historical Precedent section** in plan with query results\n- Save to `docs/plans/YYYY-MM-DD-<feature-name>.md`\n\n**Step 3: Validate Plan Against Failure Patterns**\n\nAfter the plan is saved, validate it against known failures:\n\n```bash\npython3 default/lib/validate-plan-precedent.py docs/plans/YYYY-MM-DD-<feature>.md\n```\n\n**Interpretation:**\n- `PASS`  Plan is safe to execute\n- `WARNING`  Plan has >30% keyword overlap with past failures\n  - Review the warnings in the output\n  - Update plan to address the failure patterns\n  - Re-run validation until PASS\n\n**Note:** If artifact index is unavailable, validation passes automatically (nothing to check against).\n\n**Step 4: Ask User About Execution**\n\nAsk via `AskUserQuestion`: \"Execute now?\" Options:\n1. Execute now  `subagent-driven-development`\n2. Parallel session  user opens new session with `executing-plans`\n3. Save for later  report location and end\n\n## Why Use an Agent?\n\n**Context preservation** (reading many files keeps supervisor clean) | **Model power** (Opus for comprehensive planning) | **Separation of concerns** (supervisor orchestrates, agent plans)\n\n## What the Agent Does\n\n**Query precedent**  Explore codebase  identify files  break into bite-sized tasks (2-5 min)  write complete code  include exact commands  add review checkpoints  **include Historical Precedent section**  verify Zero-Context Test  save to `docs/plans/YYYY-MM-DD-<feature>.md`  report back\n\n## Requirements for Plans\n\nEvery plan: **Historical Precedent section** | Header (goal, architecture, tech stack) | Verification commands with expected output | Exact file paths (never \"somewhere in src\") | Complete code (never \"add validation here\") | Bite-sized steps with verification | Failure recovery | Review checkpoints | Zero-Context Test | **Recommended agents per task** | **Avoids known failure patterns**\n\n## Agent Selection\n\n| Task Type | Agent |\n|-----------|-------|\n| Backend API/services | `backend-engineer-{golang,typescript}` |\n| Frontend/BFF | `frontend-bff-engineer-typescript` |\n| Infra/CI/CD | `devops-engineer` |\n| Testing | `qa-analyst` |\n| Reliability | `sre` |\n| Fallback | `general-purpose` (built-in, no prefix) |\n\n## Execution Options Reference\n\n| Option | Description |\n|--------|-------------|\n| **Execute now** | Fresh subagent per task, code review between tasks  `subagent-driven-development` |\n| **Parallel session** | User opens new session, batch execution with human review  `executing-plans` |\n| **Save for later** | Plan at `docs/plans/YYYY-MM-DD-<feature>.md`, manual review before execution |\n\n## Required Patterns\n\nThis skill uses these universal patterns:\n- **State Tracking:** See `skills/shared-patterns/state-tracking.md`\n- **Failure Recovery:** See `skills/shared-patterns/failure-recovery.md`\n- **Exit Criteria:** See `skills/shared-patterns/exit-criteria.md`\n- **TodoWrite:** See `skills/shared-patterns/todowrite-integration.md`\n\nApply ALL patterns when using this skill."
              },
              {
                "name": "ring:writing-skills",
                "description": "TDD for process documentation - write test cases (pressure scenarios), watch\nbaseline fail, write skill, iterate until bulletproof against rationalization.\n",
                "path": "default/skills/writing-skills/SKILL.md",
                "frontmatter": {
                  "name": "ring:writing-skills",
                  "description": "TDD for process documentation - write test cases (pressure scenarios), watch\nbaseline fail, write skill, iterate until bulletproof against rationalization.\n",
                  "trigger": "- Creating a new skill\n- Editing an existing skill\n- Skill needs to resist rationalization under pressure\n",
                  "skip_when": "- Writing pure reference skill (API docs)  no rules to test\n- Skill has no compliance costs  no rationalization risk\n",
                  "related": {
                    "complementary": [
                      "testing-skills-with-subagents"
                    ]
                  }
                },
                "content": "# Writing Skills\n\n## Overview\n\n**Writing skills IS Test-Driven Development applied to process documentation.**\n\n**Personal skills live in agent-specific directories (e.g., `~/.claude/skills` for Claude Code, `~/.codex/skills` for Codex, or custom agent directories)** \n\nYou write test cases (pressure scenarios with subagents), watch them fail (baseline behavior), write the skill (documentation), watch tests pass (agents comply), and refactor (close loopholes).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill teaches the right thing.\n\n**REQUIRED BACKGROUND:** You MUST understand test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill adapts TDD to documentation.\n\n**Official guidance:** For Anthropic's official skill authoring best practices, see anthropic-best-practices.md. This document provides additional patterns and guidelines that complement the TDD-focused approach in this skill.\n\n## What is a Skill?\n\nA **skill** is a reference guide for proven techniques, patterns, or tools. Skills help future agent instances find and apply effective approaches.\n\n**Skills are:** Reusable techniques, patterns, tools, reference guides\n\n**Skills are NOT:** Narratives about how you solved a problem once\n\n## TDD Mapping for Skills\n\n| TDD Concept | Skill Creation |\n|-------------|----------------|\n| **Test case** | Pressure scenario with subagent |\n| **Production code** | Skill document (SKILL.md) |\n| **Test fails (RED)** | Agent violates rule without skill (baseline) |\n| **Test passes (GREEN)** | Agent complies with skill present |\n| **Refactor** | Close loopholes while maintaining compliance |\n| **Write test first** | Run baseline scenario BEFORE writing skill |\n| **Watch it fail** | Document exact rationalizations agent uses |\n| **Minimal code** | Write skill addressing those specific violations |\n| **Watch it pass** | Verify agent now complies |\n| **Refactor cycle** | Find new rationalizations  plug  re-verify |\n\nThe entire skill creation process follows RED-GREEN-REFACTOR.\n\n## When to Create a Skill\n\n**Create when:**\n- Technique wasn't intuitively obvious to you\n- You'd reference this again across projects\n- Pattern applies broadly (not project-specific)\n- Others would benefit\n\n**Don't create for:**\n- One-off solutions\n- Standard practices well-documented elsewhere\n- Project-specific conventions (put in CLAUDE.md)\n\n## Skill Types\n\n### Technique\nConcrete method with steps to follow (condition-based-waiting, root-cause-tracing)\n\n### Pattern\nWay of thinking about problems (flatten-with-flags, test-invariants)\n\n### Reference\nAPI docs, syntax guides, tool documentation (office docs)\n\n## Directory Structure\n\n`skills/skill-name/SKILL.md` (required) + optional supporting files. Flat namespace.\n\n**Separate files for:** Heavy reference (100+ lines), reusable tools. **Keep inline:** Principles, code patterns (<50 lines).\n\n## SKILL.md Structure\n\n**Frontmatter (YAML):**\n- Only two fields supported: `name` and `description`\n- Max 1024 characters total\n- `name`: Use letters, numbers, and hyphens only (no parentheses, special chars)\n- `description`: Third-person, includes BOTH what it does AND when to use it\n  - Start with \"Use when...\" to focus on triggering conditions\n  - Include specific symptoms, situations, and contexts\n  - Keep under 500 characters if possible\n\n```markdown\n---\nname: ring:Skill-Name-With-Hyphens\ndescription: Use when [triggers/symptoms] - [what it does, third person]\n---\n# Skill Name\n## Overview (1-2 sentences), ## When to Use (symptoms, NOT to use)\n## Core Pattern (before/after code), ## Quick Reference (table for scanning)\n## Implementation (inline or link), ## Common Mistakes, ## Real-World Impact (optional)\n```\n\n\n## Agent Search Optimization (ASO)\n\n**Critical for discovery:** Future agents need to FIND your skill\n\n### 1. Rich Description Field\n\n**Purpose:** Agents read description to decide which skills to load for a given task. Make it answer: \"Should I read this skill right now?\"\n\n**Format:** Start with \"Use when...\" to focus on triggering conditions, then explain what it does\n\n**Content:**\n- Use concrete triggers, symptoms, and situations that signal this skill applies\n- Describe the *problem* (race conditions, inconsistent behavior) not *language-specific symptoms* (setTimeout, sleep)\n- Keep triggers technology-agnostic unless the skill itself is technology-specific\n- If skill is technology-specific, make that explicit in the trigger\n- Write in third person (injected into system prompt)\n\n| Quality | Example |\n|---------|---------|\n| **BAD** | `For async testing` (vague), `I can help...` (first person), `setTimeout/sleep` (tech-specific but skill isn't) |\n| **GOOD** | `Use when tests have race conditions... - replaces timeouts with condition polling` (problem + solution) |\n\n### 2. Keyword Coverage\n\nUse words agents would search for:\n- Error messages: \"Hook timed out\", \"ENOTEMPTY\", \"race condition\"\n- Symptoms: \"flaky\", \"hanging\", \"zombie\", \"pollution\"\n- Synonyms: \"timeout/hang/freeze\", \"cleanup/teardown/afterEach\"\n- Tools: Actual commands, library names, file types\n\n### 3. Descriptive Naming\n\n**Use active voice, verb-first:**\n-  `creating-skills` not `skill-creation`\n-  `testing-skills-with-subagents` not `subagent-skill-testing`\n\n### 4. Token Efficiency (Critical)\n\n**Problem:** getting-started and frequently-referenced skills load into EVERY conversation. Every token counts.\n\n**Target word counts by skill type:**\n- **Bootstrap/Getting-started**: <150 words each (loads in every session)\n- **Simple technique skills**: <500 words (procedures, patterns, single concept)\n- **Discipline-enforcing skills**: <2,000 words (TDD, verification, systematic debugging - need rationalization tables)\n- **Process/workflow skills**: <4,000 words (multi-phase workflows with comprehensive templates)\n\n**Rationale:** Complex skills need extensive rationalization prevention and complete templates. Don't artificially compress at the cost of effectiveness.\n\n**Techniques:** Reference `--help` instead of documenting flags. Cross-reference other skills instead of repeating. Compress examples (42 words  20 words). Don't repeat cross-referenced content.\n\n**Verify:** `wc -w skills/path/SKILL.md` (check against word counts above)\n\n**Name by what you DO or core insight:**\n-  `condition-based-waiting` > `async-test-helpers`\n-  `using-skills` not `skill-usage`\n-  `flatten-with-flags` > `data-structure-refactoring`\n-  `root-cause-tracing` > `debugging-techniques`\n\n**Gerunds (-ing) work well for processes:**\n- `creating-skills`, `testing-skills`, `debugging-with-logs`\n- Active, describes the action you're taking\n\n### 4. Cross-Referencing Other Skills\n\n**When writing documentation that references other skills:**\n\nUse skill name only, with explicit requirement markers:\n-  Good: `**REQUIRED SUB-SKILL:** Use test-driven-development`\n-  Good: `**REQUIRED BACKGROUND:** You MUST understand systematic-debugging`\n-  Bad: `See skills/testing/test-driven-development` (unclear if required)\n-  Bad: `@skills/testing/test-driven-development/SKILL.md` (force-loads, burns context)\n\n**Why no @ links:** `@` syntax force-loads files immediately, consuming 200k+ context before you need them.\n\n## Flowchart Usage\n\n**Only for:** Non-obvious decisions, process loops, \"A vs B\" choices. **Never for:** Reference (tables), code (blocks), linear steps (lists). See graphviz-conventions.dot for conventions.\n\n## Code Examples\n\n**One excellent example in most relevant language.** Complete, well-commented WHY, real scenario, ready to adapt. Don't: multi-language, fill-in-blank templates, contrived examples.\n\n## File Organization\n\n| Type | Structure | When |\n|------|-----------|------|\n| **Self-Contained** | `skill/SKILL.md` only | All content fits inline |\n| **With Tool** | `SKILL.md` + `example.ts` | Reusable code, not narrative |\n| **Heavy Reference** | `SKILL.md` + `*.md` refs + `scripts/` | Reference >100 lines |\n\n## The Iron Law (Same as TDD)\n\n```\nNO SKILL WITHOUT A FAILING TEST FIRST\n```\n\nThis applies to NEW skills AND EDITS to existing skills.\n\nWrite skill before testing? Delete it. Start over.\nEdit skill without testing? Same violation.\n\n**No exceptions:**\n- Not for \"simple additions\"\n- Not for \"just adding a section\"\n- Not for \"documentation updates\"\n- Don't keep untested changes as \"reference\"\n- Don't \"adapt\" while running tests\n- Delete means delete\n\n**REQUIRED BACKGROUND:** The test-driven-development skill explains why this matters. Same principles apply to documentation.\n\n## Testing All Skill Types\n\n| Skill Type | Examples | Test With | Success Criteria |\n|------------|----------|-----------|------------------|\n| **Discipline** (rules) | TDD, verification | Pressure scenarios (time + sunk cost + exhaustion), academic questions | Agent follows rule under maximum pressure |\n| **Technique** (how-to) | condition-based-waiting, root-cause-tracing | Application + variation + gap testing | Agent applies technique to new scenario |\n| **Pattern** (mental model) | reducing-complexity | Recognition + application + counter-examples | Agent identifies when/how to apply |\n| **Reference** (docs/APIs) | API docs, command refs | Retrieval + application + gap testing | Agent finds and applies info correctly |\n\n## Common Rationalizations for Skipping Testing\n\n| Excuse | Reality |\n|--------|---------|\n| \"Skill is obviously clear\" | Clear to you  clear to other agents. Test it. |\n| \"It's just a reference\" | References can have gaps, unclear sections. Test retrieval. |\n| \"Testing is overkill\" | Untested skills have issues. Always. 15 min testing saves hours. |\n| \"I'll test if problems emerge\" | Problems = agents can't use skill. Test BEFORE deploying. |\n| \"Too tedious to test\" | Testing is less tedious than debugging bad skill in production. |\n| \"I'm confident it's good\" | Overconfidence guarantees issues. Test anyway. |\n| \"Academic review is enough\" | Reading  using. Test application scenarios. |\n| \"No time to test\" | Deploying untested skill wastes more time fixing it later. |\n\n**All of these mean: Test before deploying. No exceptions.**\n\n## Bulletproofing Skills Against Rationalization\n\nSkills that enforce discipline (like TDD) need to resist rationalization. Agents are smart and will find loopholes when under pressure.\n\n**Psychology note:** Understanding WHY persuasion techniques work helps you apply them systematically. See persuasion-principles.md for research foundation (Cialdini, 2021; Meincke et al., 2025) on authority, commitment, scarcity, social proof, and unity principles.\n\n### Close Every Loophole Explicitly\n\nDon't just state rule - forbid specific workarounds:\n- **BAD:** `Write code before test? Delete it.`\n- **GOOD:** Add `Delete it. Start over.` + explicit `No exceptions:` list (don't keep as reference, don't adapt, don't look, delete means delete)\n\n### Address \"Spirit vs Letter\" Arguments\n\nAdd foundational principle early:\n\n```markdown\n**Violating the letter of the rules is violating the spirit of the rules.**\n```\n\nThis cuts off entire class of \"I'm following the spirit\" rationalizations.\n\n### Build Rationalization Table\n\nCapture rationalizations from baseline testing (see Testing section below). Every excuse agents make goes in the table:\n\n```markdown\n| Excuse | Reality |\n|--------|---------|\n| \"Too simple to test\" | Simple code breaks. Test takes 30 seconds. |\n| \"I'll test after\" | Tests passing immediately prove nothing. |\n| \"Tests after achieve same goals\" | Tests-after = \"what does this do?\" Tests-first = \"what should this do?\" |\n```\n\n### Create Red Flags List\n\nMake it easy for agents to self-check when rationalizing:\n\n```markdown\n## Red Flags - STOP and Start Over\n\n- Code before test\n- \"I already manually tested it\"\n- \"Tests after achieve the same purpose\"\n- \"It's about spirit not ritual\"\n- \"This is different because...\"\n\n**All of these mean: Delete code. Start over with TDD.**\n```\n\n### Update CSO for Violation Symptoms\n\nAdd to description: symptoms of when you're ABOUT to violate the rule:\n\n```yaml\ndescription: use when implementing any feature or bugfix, before writing implementation code\n```\n\n## RED-GREEN-REFACTOR for Skills\n\n| Phase | Action |\n|-------|--------|\n| **RED** | Run pressure scenario WITHOUT skill  document choices/rationalizations verbatim |\n| **GREEN** | Write skill addressing specific failures  verify agent complies |\n| **REFACTOR** | Find new rationalizations  add counters  re-test until bulletproof |\n\n**REQUIRED SUB-SKILL:** Use testing-skills-with-subagents for pressure scenarios, pressure types, hole-plugging, meta-testing.\n\n## Anti-Patterns\n\n| Pattern | Example | Why Bad |\n|---------|---------|---------|\n| **Narrative** | \"In session 2025-10-03, we found...\" | Too specific, not reusable |\n| **Multi-language** | example-js.js, example-py.py | Mediocre quality, maintenance burden |\n| **Code in flowcharts** | `step1 [label=\"import fs\"]` | Can't copy-paste, hard to read |\n| **Generic labels** | helper1, step3, pattern4 | Labels need semantic meaning |\n\n## STOP: Before Moving to Next Skill\n\n**After writing ANY skill, you MUST STOP and complete the deployment process.**\n\n**Do NOT:**\n- Create multiple skills in batch without testing each\n- Move to next skill before current one is verified\n- Skip testing because \"batching is more efficient\"\n\n**The deployment checklist below is MANDATORY for EACH skill.**\n\nDeploying untested skills = deploying untested code. It's a violation of quality standards.\n\n## Skill Creation Checklist (TDD Adapted)\n\n**Use TodoWrite for each phase.**\n\n| Phase | Requirements |\n|-------|--------------|\n| **RED** | 3+ pressure scenarios, run WITHOUT skill, document rationalizations verbatim |\n| **GREEN** | Name (letters/numbers/hyphens), YAML frontmatter (<1024 chars), description starts \"Use when...\", third person, keywords, address baseline failures, one excellent example, verify compliance |\n| **REFACTOR** | New rationalizations  add counters, build rationalization table, create red flags, re-test |\n| **Quality** | Flowchart only if non-obvious, quick ref table, common mistakes, no narrative |\n| **Deploy** | Commit and push, consider contributing PR |\n\n## Discovery Workflow\n\nHow future agents find your skill:\n\n1. **Encounters problem** (\"tests are flaky\")\n3. **Finds SKILL** (description matches)\n4. **Scans overview** (is this relevant?)\n5. **Reads patterns** (quick reference table)\n6. **Loads example** (only when implementing)\n\n**Optimize for this flow** - put searchable terms early and often.\n\n## The Bottom Line\n\n**Creating skills IS TDD for process documentation.**\n\nSame Iron Law: No skill without failing test first.\nSame cycle: RED (baseline)  GREEN (write skill)  REFACTOR (close loopholes).\nSame benefits: Better quality, fewer surprises, bulletproof results.\n\nIf you follow TDD for code, follow it for skills. It's the same discipline applied to documentation."
              }
            ]
          },
          {
            "name": "ring-dev-team",
            "description": "7 specialized developer agents + 10 development skills + 5 slash commands: 6-gate development cycle (implementation->devops->SRE->testing->review->validation), integrated with PM team output. Go/TypeScript Backend specialists, DevOps Engineer, Frontend TypeScript specialist, Frontend Designer, QA Analyst, and SRE. Complete development team coverage with TDD, observability, and security best practices.",
            "source": "./dev-team",
            "category": null,
            "version": "0.45.7",
            "author": null,
            "install_commands": [
              "/plugin marketplace add LerianStudio/ring",
              "/plugin install ring-dev-team@ring"
            ],
            "signals": {
              "stars": 39,
              "forks": 2,
              "pushed_at": "2026-01-12T18:20:36Z",
              "created_at": "2025-10-30T20:18:13Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/dev-cancel",
                "description": "Cancel the current development cycle",
                "path": "dev-team/commands/dev-cancel.md",
                "frontmatter": {
                  "name": "ring:dev-cancel",
                  "description": "Cancel the current development cycle",
                  "argument-hint": "[--force]"
                },
                "content": "Cancel the current development cycle.\n\n## Usage\n\n```\n/dev-cancel [--force]\n```\n\n## Options\n\n| Option | Description |\n|--------|-------------|\n| `--force` | Cancel without confirmation |\n\n## Behavior\n\n1. **Confirmation**: Asks for confirmation before canceling (unless `--force`)\n2. **State preservation**: Saves current state for potential resume\n3. **Cleanup**: Marks cycle as `cancelled` in state file\n4. **Report**: Generates partial feedback report with completed tasks\n\n## Example\n\n```\n Cancel Development Cycle?\n\nCycle ID: 2024-01-15-143000\nProgress: 3/5 tasks completed\n\nThis will:\n- Stop the current cycle\n- Save state for potential resume\n- Generate partial feedback report\n\n[Confirm Cancel] [Keep Running]\n```\n\nAfter confirmation:\n\n```\n Cycle Cancelled\n\nCycle ID: 2024-01-15-143000\nStatus: cancelled\nCompleted: 3/5 tasks\n\nState saved to: docs/dev-cycle/current-cycle.json (or docs/dev-refactor/current-cycle.json)\nPartial report: .ring/dev-team/feedback/cycle-2024-01-15-partial.md\n\nTo resume later:\n  /dev-cycle --resume\n```\n\n## When No Cycle is Running\n\n```\n No development cycle to cancel.\n\nCheck status with:\n  /dev-status\n```\n\n## Related Commands\n\n| Command | Description |\n|---------|-------------|\n| `/dev-cycle` | Start or resume cycle |\n| `/dev-status` | Check current status |\n| `/dev-report` | View feedback report |\n\n---\n\nNow checking for active cycle to cancel...\n\nRead state from: `docs/dev-cycle/current-cycle.json` or `docs/dev-refactor/current-cycle.json`"
              },
              {
                "name": "/dev-cycle",
                "description": "Execute the development cycle for tasks in a markdown file",
                "path": "dev-team/commands/dev-cycle.md",
                "frontmatter": {
                  "name": "ring:dev-cycle",
                  "description": "Execute the development cycle for tasks in a markdown file",
                  "argument-hint": "[tasks-file] [options]"
                },
                "content": "Execute the development cycle for tasks in a markdown file.\n\n## Usage\n\n```\n/dev-cycle [tasks-file] [options]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `tasks-file` | Yes* | Path to markdown file with tasks (e.g., `docs/tasks/sprint-001.md`) |\n\n*Can be omitted if `docs/tasks/current.md` exists.\n\n## Options\n\n| Option | Description | Example |\n|--------|-------------|---------|\n| `--task ID` | Execute only specific task | `--task PROJ-123` |\n| `--skip-gates` | Skip specific gates | `--skip-gates devops,review` |\n| `--dry-run` | Validate tasks without executing | `--dry-run` |\n| `--resume` | Resume interrupted cycle | `--resume` |\n\n## Examples\n\n```bash\n# Execute all tasks from a file\n/dev-cycle docs/tasks/sprint-001.md\n\n# Execute single task\n/dev-cycle docs/tasks/sprint-001.md --task AUTH-001\n\n# Skip DevOps setup (infrastructure already exists)\n/dev-cycle docs/tasks/sprint-001.md --skip-gates devops\n\n# Validate tasks without executing\n/dev-cycle docs/tasks/sprint-001.md --dry-run\n\n# Resume interrupted cycle\n/dev-cycle --resume\n```\n\n## Prerequisites\n\n1. **Task file**: Markdown file generated by `/pre-dev-*` or `/dev-refactor`\n2. **Project standards** (optional but recommended): `docs/PROJECT_RULES.md` with project conventions\n3. **PRD/TRD** (optional): If exists in `docs/pre-dev/{feature}/`, will be used in design phase\n\n## Gates Executed\n\n| Gate | Skill | Description |\n|------|-------|-------------|\n| 0 | `dev-implementation` | Implement code (TDD) |\n| 1 | `dev-devops` | Create Docker/compose |\n| 2 | `dev-sre` | Observability (health checks, logging, tracing) |\n| 3 | `dev-testing` | Write and run tests |\n| 4 | `requesting-code-review` | Code review (3 reviewers in parallel) |\n| 5 | `dev-validation` | Final validation |\n\n**Note:** Tasks are loaded at initialization, not as a separate gate.\n\nAfter all tasks: `dev-feedback-loop` generates metrics report.\n\n## Output\n\n- **State file**: `docs/dev-cycle/current-cycle.json` (feature) or `docs/dev-refactor/current-cycle.json` (refactor)\n- **Feedback report**: `.ring/dev-team/feedback/cycle-YYYY-MM-DD.md`\n\n## Related Commands\n\n| Command | Description |\n|---------|-------------|\n| `/dev-status` | Check current cycle status |\n| `/dev-cancel` | Cancel running cycle |\n| `/dev-report` | View feedback report |\n\n---\n\n##  MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:dev-cycle\n```\n\nThe skill contains the complete 6-gate workflow with:\n- Anti-rationalization tables\n- Pressure resistance scenarios\n- TDD sub-phases (Gate 0.1 RED  Gate 0.2 GREEN)\n- Gate completion definitions\n- Incremental compromise prevention\n- State management schema\n\n## Execution Context\n\nPass the following context to the skill:\n\n| Parameter | Value |\n|-----------|-------|\n| `tasks-file` | `$1` (first argument, e.g., `docs/tasks/sprint-001.md`) |\n| `--task` | If provided, filter to specific task ID |\n| `--skip-gates` | If provided, list of gates to skip |\n| `--dry-run` | If provided, validate only |\n| `--resume` | If provided, resume from existing state file (dev-cycle or dev-refactor) |\n\n## Step 1: ASK EXECUTION MODE (MANDATORY)\n\n**After loading skill and before executing gates, you MUST ask:**\n\n```yaml\nAskUserQuestion:\n  questions:\n    - question: \"Select execution mode for this cycle\"\n      header: \"Mode\"\n      options:\n        - label: \"Manual per subtask\"\n          description: \"Checkpoint after each subtask\"\n        - label: \"Manual per task\"\n          description: \"Checkpoint after each task\"\n        - label: \"Automatic\"\n          description: \"No checkpoints, run all gates\"\n```\n\n**Do not skip this.** User hints  mode selection. Only explicit selection is valid.\n\n## Quick Reference\n\nSee skill `dev-cycle` for full details. Key rules:\n\n- **all 6 gates execute** - Checkpoints affect pauses, not gates\n- **Gates execute in order** - 0  1  2  3  4  5\n- **Gate 4 requires all 3 reviewers** - 2/3 = FAIL\n- **Coverage threshold** - 85% minimum, no exceptions\n- **State persisted** - Can resume with `--resume` after any interruption"
              },
              {
                "name": "/dev-refactor",
                "description": "Analyze existing codebase against standards and execute refactoring through dev-cycle",
                "path": "dev-team/commands/dev-refactor.md",
                "frontmatter": {
                  "name": "ring:dev-refactor",
                  "description": "Analyze existing codebase against standards and execute refactoring through dev-cycle",
                  "argument-hint": "[path]"
                },
                "content": "Analyze existing codebase against standards and execute refactoring through dev-cycle.\n\n##  PRE-EXECUTION CHECK (EXECUTE FIRST)\n\n**Before loading the skill, you MUST check:**\n\n```\nDoes docs/PROJECT_RULES.md exist in the target project?\n YES  Load skill: dev-refactor\n no   Output blocker below and STOP\n```\n\n**If file does not exist, output this EXACT response:**\n\n```markdown\n##  HARD BLOCK: PROJECT_RULES.md Not Found\n\n**Status:** BLOCKED - Cannot proceed\n\n### Required Action\nCreate `docs/PROJECT_RULES.md` with your project's:\n- Architecture patterns\n- Code conventions\n- Testing requirements\n- DevOps standards\n\nThen re-run `/dev-refactor`.\n```\n\n**DO not:**\n- Use \"default\" or \"industry\" standards\n- Infer standards from existing code\n- Proceed with partial analysis\n- Offer to create the file\n\n---\n\n## Usage\n\n```\n/dev-refactor [path] [options]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `path` | No | Directory to analyze (default: current project root) |\n\n## Options\n\n| Option | Description | Example |\n|--------|-------------|---------|\n| `--standards PATH` | Custom standards file | `--standards docs/MY_PROJECT_RULES.md` |\n| `--analyze-only` | Generate report without executing | `--analyze-only` |\n| `--critical-only` | Only Critical and High priority issues | `--critical-only` |\n| `--dry-run` | Show what would be analyzed | `--dry-run` |\n\n## Examples\n\n```bash\n# Analyze entire project and refactor\n/dev-refactor\n\n# Analyze specific directory\n/dev-refactor src/domain\n\n# Analysis only (no execution)\n/dev-refactor --analyze-only\n\n# Only fix critical issues\n/dev-refactor --critical-only\n\n# Use custom standards\n/dev-refactor --standards docs/team-standards.md\n```\n\n## Workflow\n\n**See skill `dev-refactor` for the complete 13-step workflow with TodoWrite template.**\n\nThe skill defines all steps including: stack detection, codebase-explorer dispatch, individual agent reports, finding mapping, and artifact generation.\n\n## Analysis Dimensions\n\n| Dimension | What's Checked | Standards Reference |\n|-----------|----------------|---------------------|\n| **Architecture** | DDD patterns, layer separation, dependency direction, directory structure | `golang.md`  Architecture |\n| **Code Quality** | Naming conventions, error handling, forbidden practices, security | `golang.md`  Error Handling |\n| **Instrumentation** | Service method tracing, span naming, error classification, context propagation | `golang.md`  Distributed Tracing |\n| **Testing** | Coverage percentage, test patterns, naming, missing tests | `golang.md`  Testing |\n| **DevOps** | Dockerfile, docker-compose, env management, Helm charts | `golang.md`  DevOps |\n\n### Instrumentation Checklist (Quick Reference)\n\nWhen analyzing services for instrumentation compliance, verify:\n\n1. **Context extraction**: `libCommons.NewTrackingFromContext(ctx)` at method start\n2. **Child span creation**: `tracer.Start(ctx, \"layer.entity.operation\")` with proper naming\n3. **Span cleanup**: `defer span.End()` immediately after span creation\n4. **Error classification**:\n   - Business errors  `HandleSpanBusinessErrorEvent` (span stays OK)\n   - Technical errors  `HandleSpanError` (span marked ERROR)\n5. **Structured logging**: Use logger from context, not `log.Printf`\n\n**Full details and code templates**: See `docs/standards/golang.md`  \"Distributed Tracing Architecture\"\n\n## Output\n\n**Analysis Report** (`docs/refactor/{timestamp}/analysis-report.md`):\n- Summary table with issue counts by severity\n- Detailed findings grouped by dimension\n- Specific file locations and line numbers\n\n**Tasks File** (`docs/refactor/{timestamp}/tasks.md`):\n- Grouped refactoring tasks (REFACTOR-001, REFACTOR-002, etc.)\n- Same format as PM Team output\n- Compatible with dev-cycle execution\n\n## Severity Levels (all ARE MANDATORY)\n\n| Level | Description | Priority | Tracking |\n|-------|-------------|----------|----------|\n| **Critical** | Security vulnerabilities, data loss risk | Fix immediately | **MANDATORY** |\n| **High** | Architecture violations, major code smells | Fix in current sprint | **MANDATORY** |\n| **Medium** | Convention violations, moderate gaps | Fix in next sprint | **MANDATORY** |\n| **Low** | Style issues, minor gaps | Fix when capacity | **MANDATORY** |\n\n** all severities are MANDATORY to track and fix. Low  Optional. Low = Lower priority, still required.**\n\n## Prerequisites\n\n1. ** PROJECT_RULES.md (MANDATORY)**: `docs/PROJECT_RULES.md` MUST exist - no defaults, no fallback\n2. **Git repository**: Project should be under version control\n3. **Readable codebase**: Access to source files\n\n**If PROJECT_RULES.md does not exist:** This command will output a blocker message and terminate. The project owner must create the file first.\n\n## Related Commands\n\n| Command | Description |\n|---------|-------------|\n| `/dev-cycle` | Execute development cycle (used after analysis) |\n| `/pre-dev-feature` | Plan new features (use instead for greenfield) |\n| `/codereview` | Manual code review (dev-cycle includes this) |\n\n---\n\n##  MANDATORY: Load Full Skill\n\n**After PROJECT_RULES.md check passes, load the skill:**\n\n```\nUse Skill tool: ring:dev-refactor\n```\n\nThe skill contains the complete analysis workflow with:\n- Anti-rationalization tables for codebase exploration\n- Mandatory use of `codebase-explorer` (not Bash/Explore)\n- Standards coverage table requirements\n- Finding  Task mapping gates\n- Full agent dispatch prompts with `**MODE: ANALYSIS only**`\n\n## Execution Context\n\nPass the following context to the skill:\n\n| Parameter | Value |\n|-----------|-------|\n| `path` | `$1` (first argument, default: project root) |\n| `--standards` | If provided, custom standards file path |\n| `--analyze-only` | If provided, skip dev-cycle execution |\n| `--critical-only` | If provided, filter to Critical/High only |\n| `--dry-run` | If provided, show what would be analyzed |\n\n## User Approval (MANDATORY)\n\n**Before executing dev-cycle, you MUST ask:**\n\n```yaml\nAskUserQuestion:\n  questions:\n    - question: \"Review refactoring plan. How to proceed?\"\n      header: \"Approval\"\n      options:\n        - label: \"Approve all\"\n          description: \"Proceed to dev-cycle execution\"\n        - label: \"Critical only\"\n          description: \"Execute only Critical/High tasks\"\n        - label: \"Cancel\"\n          description: \"Keep analysis, skip execution\"\n```\n\n## Quick Reference\n\nSee skill `dev-refactor` for full details. Key rules:\n\n- **All agents dispatch in parallel** - Single message, multiple Task calls\n- **Specify model: \"opus\"** - All agents need opus for comprehensive analysis\n- **MODE: ANALYSIS only** - Agents analyze, they DO NOT implement\n- **Save artifacts** to `docs/refactor/{timestamp}/`\n- **Get user approval** before executing dev-cycle\n- **Handoff**: `/dev-cycle docs/refactor/{timestamp}/tasks.md`"
              },
              {
                "name": "/dev-report",
                "description": "View the feedback report from the last development cycle",
                "path": "dev-team/commands/dev-report.md",
                "frontmatter": {
                  "name": "ring:dev-report",
                  "description": "View the feedback report from the last development cycle",
                  "argument-hint": "[cycle-date]"
                },
                "content": "View the feedback report from the last development cycle.\n\n## Usage\n\n```\n/dev-report [cycle-date]\n```\n\n## Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `cycle-date` | No | Date of the cycle (YYYY-MM-DD). Defaults to most recent. |\n\n## Examples\n\n```bash\n# View most recent report\n/dev-report\n\n# View specific date\n/dev-report 2024-01-15\n```\n\n## Report Contents\n\nThe feedback report includes:\n\n### Summary\n- Total tasks processed\n- Success/partial/failed counts\n- Average assertiveness score\n- Total cycle duration\n\n### Per-Task Metrics\n- Assertiveness score\n- Duration per gate\n- Iteration counts\n- Issues encountered\n\n### Analysis\n- Gates with most retrabalho\n- Recurring failure patterns\n- Improvement suggestions\n\n### Recommendations\n- Suggested skill improvements\n- Suggested agent adjustments\n- Process optimizations\n\n## Example Output\n\n```\n Development Cycle Report\n\nDate: 2024-01-15\nDuration: 2h 45m\n\n\n Summary                                   \n\n Tasks: 5 total                           \n    SUCCESS: 4 (80%)                    \n    PARTIAL: 1 (20%)                    \n    FAILED: 0 (0%)                      \n                                          \n Assertiveness: 87.4% (target: 85%)       \n\n\nTop Issues:\n1. Gate 5 (testing): 3 tasks needed extra iterations\n2. Gate 6 (review): Security findings in 2 tasks\n\nRecommendations:\n Skill dev-testing: Add test planning phase\n Agent backend-*: Reinforce input validation\n\nFull report: .ring/dev-team/feedback/cycle-2024-01-15.md\n```\n\n## Report Location\n\nReports are saved to: `.ring/dev-team/feedback/cycle-YYYY-MM-DD.md`\n\n## Available Reports\n\nList all reports:\n```bash\nls .ring/dev-team/feedback/\n```\n\n## Related Commands\n\n| Command | Description |\n|---------|-------------|\n| `/dev-cycle` | Start new cycle |\n| `/dev-status` | Check current status |\n| `/dev-cancel` | Cancel running cycle |\n\n---\n\nNow loading the most recent feedback report...\n\nSearch for reports in: `.ring/dev-team/feedback/cycle-*.md`\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:dev-feedback-loop\n```\n\nThe skill contains the complete workflow with:\n- Metrics collection from dev-cycle\n- Pattern analysis\n- Improvement recommendations\n- Report generation format\n- Historical comparison"
              },
              {
                "name": "/dev-status",
                "description": "Check the status of the current development cycle",
                "path": "dev-team/commands/dev-status.md",
                "frontmatter": {
                  "name": "ring:dev-status",
                  "description": "Check the status of the current development cycle",
                  "argument-hint": ""
                },
                "content": "Check the status of the current development cycle.\n\n## Usage\n\n```\n/dev-status\n```\n\n## Output\n\nDisplays:\n- Current cycle ID and start time\n- Tasks: total, completed, in progress, pending\n- Current task and gate being executed\n- Assertiveness score (if tasks completed)\n- Elapsed time\n\n## Example Output\n\n```\n Development Cycle Status\n\nCycle ID: 2024-01-15-143000\nStarted: 2024-01-15 14:30:00\nStatus: in_progress\n\nTasks:\n   Completed: 2/5\n   In Progress: 1/5 (AUTH-003)\n   Pending: 2/5\n\nCurrent:\n  Task: AUTH-003 - Implementar refresh token\n  Gate: 5/8 (dev-testing)\n  Iterations: 1\n\nMetrics (completed tasks):\n  Average Assertiveness: 89%\n  Total Duration: 1h 45m\n\nState file: docs/dev-cycle/current-cycle.json (or docs/dev-refactor/current-cycle.json)\n```\n\n## When No Cycle is Running\n\n```\n No development cycle in progress.\n\nStart a new cycle with:\n  /dev-cycle docs/tasks/your-tasks.md\n\nOr resume an interrupted cycle:\n  /dev-cycle --resume\n```\n\n## Related Commands\n\n| Command | Description |\n|---------|-------------|\n| `/dev-cycle` | Start or resume cycle |\n| `/dev-cancel` | Cancel running cycle |\n| `/dev-report` | View feedback report |\n\n---\n\nNow checking cycle status...\n\nRead state from: `docs/dev-cycle/current-cycle.json` or `docs/dev-refactor/current-cycle.json`"
              }
            ],
            "skills": [
              {
                "name": "ring:dev-cycle",
                "description": "Main orchestrator for the 6-gate development cycle system. Loads tasks/subtasks\nfrom PM team output and executes through implementation, devops, SRE, testing, review,\nand validation gates with state persistence and metrics collection.\n",
                "path": "dev-team/skills/dev-cycle/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-cycle",
                  "description": "Main orchestrator for the 6-gate development cycle system. Loads tasks/subtasks\nfrom PM team output and executes through implementation, devops, SRE, testing, review,\nand validation gates with state persistence and metrics collection.\n",
                  "trigger": "- Starting a new development cycle with a task file\n- Resuming an interrupted development cycle (--resume flag)\n- Need structured, gate-based task execution with quality checkpoints\n",
                  "prerequisite": "- Tasks file exists with structured subtasks\n- Not already in a specific gate skill execution\n- Human has not explicitly requested manual workflow\n",
                  "NOT_skip_when": "- \"Task is simple\"  Simple  risk-free. Execute gates.\n- \"Tests already pass\"  Tests  review. Different concerns.\n- \"Time pressure\"  Pressure  permission. Document and proceed.\n- \"Already did N gates\"  Sunk cost is irrelevant. Complete all gates.\n",
                  "sequence": {
                    "before": [
                      "dev-feedback-loop"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "dev-implementation",
                      "dev-devops",
                      "dev-sre",
                      "dev-testing",
                      "ring:requesting-code-review",
                      "dev-validation",
                      "dev-feedback-loop"
                    ]
                  },
                  "verification": {
                    "automated": [
                      {
                        "command": "test -f docs/dev-cycle/current-cycle.json || test -f docs/dev-refactor/current-cycle.json",
                        "description": "State file exists (dev-cycle or dev-refactor)",
                        "success_pattern": "exit 0"
                      },
                      {
                        "command": "cat docs/dev-cycle/current-cycle.json 2>/dev/null || cat docs/dev-refactor/current-cycle.json | jq '.current_gate'",
                        "description": "Current gate is valid",
                        "success_pattern": "[0-5]"
                      }
                    ],
                    "manual": [
                      "All gates for current task show PASS in state file",
                      "No tasks have status 'blocked' for more than 3 iterations"
                    ]
                  },
                  "examples": [
                    {
                      "name": "New feature from PM workflow",
                      "invocation": "/dev-cycle docs/pre-dev/auth/tasks.md",
                      "expected_flow": "1. Load tasks with subtasks from tasks.md\n2. Ask user for checkpoint mode (per-task/per-gate/continuous)\n3. Execute Gate 0-5 for each task sequentially\n4. Generate feedback report after completion\n"
                    },
                    {
                      "name": "Resume interrupted cycle",
                      "invocation": "/dev-cycle --resume",
                      "expected_state": "Continues from last saved gate in current-cycle.json"
                    },
                    {
                      "name": "Execute with per-gate checkpoints",
                      "invocation": "/dev-cycle tasks.md --checkpoint per-gate",
                      "expected_flow": "1. Execute Gate 0, pause for approval\n2. User approves, execute Gate 1, pause\n3. Continue until all gates complete\n"
                    }
                  ]
                },
                "content": "# Development Cycle Orchestrator\n\n## Standards Loading (MANDATORY)\n\n**Before any gate execution, you MUST load Ring standards:**\n\n<fetch_required>\nhttps://raw.githubusercontent.com/LerianStudio/ring/main/CLAUDE.md\n</fetch_required>\n\nFetch URL above and extract: Agent Modification Verification requirements, Anti-Rationalization Tables requirements, and Critical Rules.\n\n<block_condition>\n- WebFetch fails or returns empty\n- CLAUDE.md not accessible\n</block_condition>\n\nIf any condition is true, STOP and report blocker. Cannot proceed without Ring standards.\n\n## Overview\n\nThe development cycle orchestrator loads tasks/subtasks from PM team output (or manual task files) and executes through 6 quality gates. Tasks are loaded at initialization - no separate import gate.\n\n**Announce at start:** \"I'm using the dev-cycle skill to orchestrate task execution through 6 gates.\"\n\n##  CRITICAL: Specialized Agents Perform All Tasks\n\nSee [shared-patterns/shared-orchestrator-principle.md](../shared-patterns/shared-orchestrator-principle.md) for full ORCHESTRATOR principle, role separation, forbidden/required actions, gate-to-agent mapping, and anti-rationalization table.\n\n**Summary:** You orchestrate. Agents execute. If using Read/Write/Edit/Bash on source code  STOP. Dispatch agent.\n\n---\n\n##  ORCHESTRATOR BOUNDARIES (HARD GATE)\n\n**This section defines exactly what the orchestrator CAN and CANNOT do.**\n\n### What Orchestrator CAN Do (PERMITTED)\n\n| Action | Tool | Purpose |\n|--------|------|---------|\n| Read task files | `Read` | Load task definitions from `docs/pre-dev/*/tasks.md` or `docs/refactor/*/tasks.md` |\n| Read state files | `Read` | Load/verify `docs/dev-cycle/current-cycle.json` or `docs/dev-refactor/current-cycle.json` |\n| Read PROJECT_RULES.md | `Read` | Load project-specific rules |\n| Write state files | `Write` | Persist cycle state to JSON |\n| Track progress | `TodoWrite` | Maintain task list |\n| Dispatch agents | `Task` | Send work to specialist agents |\n| Ask user questions | `AskUserQuestion` | Get execution mode, approvals |\n| WebFetch standards | `WebFetch` | Load Ring standards |\n\n### What Orchestrator CANNOT Do (FORBIDDEN)\n\n<forbidden>\n- Read source code (`Read` on `*.go`, `*.ts`, `*.tsx`) - Agent reads code, not orchestrator\n- Write source code (`Write`/`Create` on `*.go`, `*.ts`) - Agent writes code, not orchestrator\n- Edit source code (`Edit` on `*.go`, `*.ts`, `*.tsx`) - Agent edits code, not orchestrator\n- Run tests (`Execute` with `go test`, `npm test`) - Agent runs tests in TDD cycle\n- Analyze code (Direct pattern analysis) - `codebase-explorer` analyzes\n- Make architectural decisions (Choosing patterns/libraries) - User decides, agent implements\n</forbidden>\n\nAny of these actions by orchestrator = IMMEDIATE VIOLATION. Dispatch agent instead.\n\n---\n\n### The 3-FILE RULE\n\n**If a task requires editing MORE than 3 files  MUST dispatch specialist agent.**\n\nThis is not negotiable:\n- 1-3 files of non-source content (markdown, json, yaml)  Orchestrator MAY edit directly\n- 1+ source code files (`*.go`, `*.ts`, `*.tsx`)  MUST dispatch agent\n- 4+ files of any type  MUST dispatch agent\n\n### Orchestrator Workflow Order (MANDATORY)\n\n```text\n\n  CORRECT WORKFLOW ORDER                                         \n\n                                                                 \n  1. Load task file (Read docs/pre-dev/*/tasks.md or docs/refactor/*/tasks.md) \n  2. Ask execution mode (AskUserQuestion)                        \n  3. Determine state path + Check/Load state (see State Path Selection) \n  4. WebFetch Ring Standards                                     \n  5.  LOAD SUB-SKILL for current gate (Skill tool)            \n  6. Execute sub-skill instructions (dispatch agent via Task)    \n  7. Wait for agent completion                                   \n  8. Verify agent output (Standards Coverage Table)              \n  9. Update state (Write to JSON)                               \n  10. Proceed to next gate                                       \n                                                                 \n     \n   WRONG: Load  Mode  Standards  Task(agent) directly       \n   RIGHT: Load  Mode  Standards  Skill(sub)  Task(agent)   \n     \n\n```\n\n###  SUB-SKILL LOADING IS MANDATORY (HARD GATE)\n\n**Before dispatching any agent, you MUST load the corresponding sub-skill first.**\n\n<cannot_skip>\n- Gate 0: `Skill(\"ring:dev-implementation\")`  then `Task(subagent_type=\"ring:backend-engineer-*\", ...)`\n- Gate 1: `Skill(\"ring:dev-devops\")`  then `Task(subagent_type=\"ring:devops-engineer\", ...)`\n- Gate 2: `Skill(\"ring:dev-sre\")`  then `Task(subagent_type=\"ring:sre\", ...)`\n- Gate 3: `Skill(\"ring:dev-testing\")`  then `Task(subagent_type=\"ring:qa-analyst\", ...)`\n- Gate 4: `Skill(\"ring:requesting-code-review\")`  then 3x `Task(...)` in parallel\n- Gate 5: `Skill(\"ring:dev-validation\")`  N/A (verification only)\n</cannot_skip>\n\nBetween \"WebFetch standards\" and \"Task(agent)\" there MUST be \"Skill(sub-skill)\".\n\n**The workflow for each gate is:**\n```text\n1. Skill(\"[sub-skill-name]\")      Load sub-skill instructions\n2. Follow sub-skill instructions   Sub-skill tells you HOW to dispatch\n3. Task(subagent_type=...)        Dispatch agent as sub-skill instructs\n4. Validate agent output           Per sub-skill validation rules\n5. Update state                    Record results\n```\n\n### Anti-Rationalization for Skipping Sub-Skills\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I know what the sub-skill does\" | Knowledge  execution. Sub-skill has iteration logic. | **Load Skill() first** |\n| \"Task() directly is faster\" | Faster  correct. Sub-skill has validation rules. | **Load Skill() first** |\n| \"Sub-skill just wraps Task()\" | Sub-skills have retry logic, fix dispatch, validation. | **Load Skill() first** |\n| \"I'll follow the pattern manually\" | Manual = error-prone. Sub-skill is the pattern. | **Load Skill() first** |\n\n**Between \"WebFetch standards\" and \"Task(agent)\" there MUST be \"Skill(sub-skill)\".**\n\n---\n\n### Anti-Rationalization for Direct Coding\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"It's just one small file\" | File count doesn't determine agent need. Language does. | **DISPATCH specialist agent** |\n| \"I already loaded the standards\" | Loading standards  permission to implement. Standards are for AGENTS. | **DISPATCH specialist agent** |\n| \"Agent dispatch adds overhead\" | Overhead ensures compliance. Skip = skip verification. | **DISPATCH specialist agent** |\n| \"I can write Go/TypeScript\" | Knowing language  having Ring standards loaded. Agent has them. | **DISPATCH specialist agent** |\n| \"Just a quick fix\" | \"Quick\" is irrelevant. all source changes require specialist. | **DISPATCH specialist agent** |\n| \"I'll read the file first to understand\" | Reading source  temptation to edit. Agent reads for you. | **DISPATCH specialist agent** |\n| \"Let me check if tests pass first\" | Agent runs tests in TDD cycle. You don't run tests. | **DISPATCH specialist agent** |\n\n### Red Flags - Orchestrator Violation in Progress\n\n**If you catch yourself doing any of these, STOP IMMEDIATELY:**\n\n```text\n RED FLAG: About to Read *.go or *.ts file\n    STOP. Dispatch agent instead.\n\n RED FLAG: About to Write/Create source code\n    STOP. Dispatch agent instead.\n\n RED FLAG: About to Edit source code\n    STOP. Dispatch agent instead.\n\n RED FLAG: About to run \"go test\" or \"npm test\"\n    STOP. Agent runs tests, not you.\n\n RED FLAG: Thinking \"I'll just...\"\n    STOP. \"Just\" is the warning word. Dispatch agent.\n\n RED FLAG: Thinking \"This is simple enough...\"\n    STOP. Simplicity is irrelevant. Dispatch agent.\n\n RED FLAG: Standards loaded, but next action is not Task tool\n    STOP. After standards, IMMEDIATELY dispatch agent.\n```\n\n### Recovery from Orchestrator Violation\n\nIf you violated orchestrator boundaries:\n\n1. **STOP** current execution immediately\n2. **DISCARD** any direct changes (`git checkout -- .`)\n3. **DISPATCH** the correct specialist agent\n4. **Agent implements** from scratch following TDD\n5. **Document** the violation for feedback loop\n\n**Sunk cost of direct work is IRRELEVANT. Agent dispatch is MANDATORY.**\n\n---\n\n## Blocker Criteria - STOP and Report\n\n<block_condition>\n- Gate Failure: Tests not passing, review failed  STOP, cannot proceed to next gate\n- Missing Standards: No PROJECT_RULES.md  STOP, report blocker and wait\n- Agent Failure: Specialist agent returned errors  STOP, diagnose and report\n- User Decision Required: Architecture choice, framework selection  STOP, present options\n</block_condition>\n\nYou CANNOT proceed when blocked. Report and wait for resolution.\n\n### Cannot Be Overridden\n\n<cannot_skip>\n- All 6 gates must execute - Each gate catches different issues\n- Gates execute in order (05) - Dependencies exist between gates\n- Gate 4 requires all 3 reviewers - Different review perspectives are complementary\n- Coverage threshold  85% - Industry standard for quality code\n- PROJECT_RULES.md must exist - Cannot verify standards without target\n</cannot_skip>\n\nNo exceptions. User cannot override. Time pressure cannot override.\n\n---\n\n## Severity Calibration\n\n| Severity | Criteria | Examples |\n|----------|----------|----------|\n| **CRITICAL** | Blocks deployment, security risk, data loss | Gate violation, skipped mandatory step |\n| **HIGH** | Major functionality broken, standards violation | Missing tests, wrong agent dispatched |\n| **MEDIUM** | Code quality, maintainability issues | Incomplete documentation, minor gaps |\n| **LOW** | Best practices, optimization | Style improvements, minor refactoring |\n\nReport all severities. Let user prioritize.\n\n### Reviewer Verdicts Are Final\n\n**MEDIUM issues found in Gate 4 MUST be fixed. No exceptions.**\n\n| Request | Why It's WRONG | Required Action |\n|---------|----------------|-----------------|\n| \"Can reviewer clarify if MEDIUM can defer?\" | Reviewer already decided. MEDIUM means FIX. | **Fix the issue, re-run reviewers** |\n| \"Ask if this specific case is different\" | Reviewer verdict accounts for context already. | **Fix the issue, re-run reviewers** |\n| \"Request exception for business reasons\" | Reviewers know business context. Verdict is final. | **Fix the issue, re-run reviewers** |\n\n**Severity mapping is absolute:**\n- CRITICAL/HIGH/MEDIUM  Fix NOW, re-run all 3 reviewers\n- LOW  Add TODO(review): comment\n- Cosmetic  Add FIXME(nitpick): comment\n\nNo negotiation. No exceptions. No \"special cases\".\n\n---\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n**Gate-specific note:** Execution mode selection affects CHECKPOINTS (user approval pauses), not GATES (quality checks). all gates execute regardless of mode.\n\n---\n\n## Common Rationalizations - REJECTED\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations.\n\n**Gate-specific rationalizations:**\n\n| Excuse | Reality |\n|--------|---------|\n| \"Automatic mode means faster\" | Automatic mode skips CHECKPOINTS, not GATES. Same quality, less interruption. |\n| \"Automatic mode will skip review\" | Automatic mode affects user approval pauses, not quality gates. all gates execute regardless. |\n| \"Defense in depth exists (frontend validates)\" | Frontend can be bypassed. Backend is the last line. Fix at source. |\n| \"Backlog the Medium issue, it's documented\" | Documented risk  mitigated risk. Medium in Gate 4 = fix NOW, not later. |\n| \"Risk-based prioritization allows deferral\" | Gates ARE the risk-based system. Reviewers define severity, not you. |\n\n---\n\n## Red Flags - STOP\n\nSee [shared-patterns/shared-red-flags.md](../shared-patterns/shared-red-flags.md) for universal red flags.\n\nIf you catch yourself thinking any of those patterns, STOP immediately and return to gate execution.\n\n---\n\n## Incremental Compromise Prevention\n\n**The \"just this once\" pattern leads to complete gate erosion:**\n\n```text\nDay 1: \"Skip review just this once\"  Approved (precedent set)\nDay 2: \"Skip testing, we did it last time\"  Approved (precedent extended)\nDay 3: \"Skip implementation checks, pattern established\"  Approved (gates meaningless)\nDay 4: Production incident from Day 1 code\n```\n\n**Prevention rules:**\n1. **No incremental exceptions** - Each exception becomes the new baseline\n2. **Document every pressure** - Log who requested, why, outcome\n3. **Escalate patterns** - If same pressure repeats, escalate to team lead\n4. **Gates are binary** - Complete or incomplete. No \"mostly done\".\n\n---\n\n## Gate Completion Definition (HARD GATE)\n\n**A gate is COMPLETE only when all components finish successfully:**\n\n| Gate | Components Required | Partial = FAIL |\n|------|---------------------|----------------|\n| 0.1 | TDD-RED: Failing test written + failure output captured | Test exists but no failure output = FAIL |\n| 0.2 | TDD-GREEN: Implementation passes test | Code exists but test fails = FAIL |\n| 0 | Both 0.1 and 0.2 complete | 0.1 done without 0.2 = FAIL |\n| 1 | Dockerfile + docker-compose + .env.example | Missing any = FAIL |\n| 2 | Structured JSON logs with trace correlation | Partial structured logs = FAIL |\n| 3 | Coverage  85% + all AC tested | 84% = FAIL |\n| 4 | **all 3 reviewers PASS** | 2/3 reviewers = FAIL |\n| 5 | Explicit \"APPROVED\" from user | \"Looks good\" = not approved |\n\n**CRITICAL for Gate 4:** Running 2 of 3 reviewers is not a partial pass - it's a FAIL. Re-run all 3 reviewers.\n\n**Anti-Rationalization for Partial Gates:**\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"2 of 3 reviewers passed\" | Gate 4 requires all 3. 2/3 = 0/3. | **Re-run all 3 reviewers** |\n| \"Gate mostly complete\" | Mostly  complete. Binary: done or not done. | **Complete all components** |\n| \"Can finish remaining in next cycle\" | Gates don't carry over. Complete NOW. | **Finish current gate** |\n| \"Core components done, optional can wait\" | No component is optional within a gate. | **Complete all components** |\n\n---\n\n## Gate Order Enforcement (HARD GATE)\n\n**Gates MUST execute in order: 0  1  2  3  4  5. No exceptions.**\n\n| Violation | Why It's WRONG | Consequence |\n|-----------|----------------|-------------|\n| Skip Gate 1 (DevOps) | \"No infra changes\" | Code without container = works on my machine only |\n| Skip Gate 2 (SRE) | \"Observability later\" | Blind production = debugging nightmare |\n| Reorder Gates | \"Review before test\" | Reviewing untested code wastes reviewer time |\n| Parallel Gates | \"Run 2 and 3 together\" | Dependencies exist. Order is intentional. |\n\n**Gates are not parallelizable across different gates. Sequential execution is MANDATORY.**\n\n## The 6 Gates\n\n| Gate | Skill | Purpose | Agent |\n|------|-------|---------|-------|\n| 0 | dev-implementation | Write code following TDD | Based on task language/domain |\n| 1 | dev-devops | Infrastructure and deployment | devops-engineer |\n| 2 | dev-sre | Observability (health, logging, tracing) | sre |\n| 3 | dev-testing | Unit tests for acceptance criteria | qa-analyst |\n| 4 | ring:requesting-code-review | Parallel code review | code-reviewer, business-logic-reviewer, security-reviewer (3x parallel) |\n| 5 | dev-validation | Final acceptance validation | N/A (verification) |\n\n## Integrated PM  Dev Workflow\n\n**PM Team Output**  **Dev Team Execution** (`/dev-cycle`)\n\n| Input Type | Path | Structure |\n|------------|------|-----------|\n| **Tasks only** | `docs/pre-dev/{feature}/tasks.md` | T-001, T-002, T-003 with requirements + acceptance criteria |\n| **Tasks + Subtasks** | `docs/pre-dev/{feature}/` | tasks.md + `subtasks/{task-id}/ST-XXX-01.md, ST-XXX-02.md...` |\n\n## Execution Order\n\n**Core Principle:** Each execution unit (task or subtask) passes through **all 6 gates** before the next unit.\n\n**Flow:** Unit  Gate 0-5   Unit Checkpoint (Step 7.1)   Task Checkpoint (Step 7.2)  Next Unit\n\n| Scenario | Execution Unit | Gates Per Unit |\n|----------|----------------|----------------|\n| Task without subtasks | Task itself | 6 gates |\n| Task with subtasks | Each subtask | 6 gates per subtask |\n\n## Commit Timing\n\n**User selects when commits happen (Step 7 of initialization).**\n\n| Option | When Commit Happens | Use Case |\n|--------|---------------------|----------|\n| **(a) Per subtask** | After each subtask passes Gate 5 | Fine-grained history, easy rollback per subtask |\n| **(b) Per task** | After all subtasks of a task complete | Logical grouping, one commit per feature chunk |\n| **(c) At the end** | After entire cycle completes | Single commit with all changes, clean history |\n\n### Commit Message Format\n\n| Timing | Message Format | Example |\n|--------|----------------|---------|\n| Per subtask | `feat({subtask_id}): {subtask_title}` | `feat(ST-001-02): implement user authentication handler` |\n| Per task | `feat({task_id}): {task_title}` | `feat(T-001): implement user authentication` |\n| At the end | `feat({cycle_id}): complete dev cycle for {feature}` | `feat(cycle-abc123): complete dev cycle for auth-system` |\n\n### Commit Timing vs Execution Mode\n\n| Execution Mode | Commit Timing | Behavior |\n|----------------|---------------|----------|\n| Manual per subtask | Per subtask | Commit + checkpoint after each subtask |\n| Manual per subtask | Per task | Checkpoint after subtask, commit after task |\n| Manual per subtask | At end | Checkpoint after subtask, commit at cycle end |\n| Manual per task | Per subtask | Commit after subtask, checkpoint after task |\n| Manual per task | Per task | Commit + checkpoint after task |\n| Manual per task | At end | Checkpoint after task, commit at cycle end |\n| Automatic | Per subtask | Commit after each subtask, no checkpoints |\n| Automatic | Per task | Commit after task, no checkpoints |\n| Automatic | At end | Single commit at cycle end, no checkpoints |\n\n**Note:** Checkpoints (user approval pauses) are controlled by `execution_mode`. Commits are controlled by `commit_timing`. They are independent settings.\n\n## State Management\n\n### State Path Selection (MANDATORY)\n\nThe state file path depends on the **source of tasks**:\n\n| Task Source | State Path | Use Case |\n|-------------|------------|----------|\n| `docs/refactor/*/tasks.md` | `docs/dev-refactor/current-cycle.json` | Refactoring existing code |\n| `docs/pre-dev/*/tasks.md` | `docs/dev-cycle/current-cycle.json` | New feature development |\n| Any other path | `docs/dev-cycle/current-cycle.json` | Default for manual tasks |\n\n**Detection Logic:**\n```text\nif source_file contains \"docs/refactor/\" THEN\n  state_path = \"docs/dev-refactor/current-cycle.json\"\nelse\n  state_path = \"docs/dev-cycle/current-cycle.json\"\n```\n\n**Store state_path in the state object itself** so resume knows where to look.\n\n### State File Structure\n\nState is persisted to `{state_path}` (either `docs/dev-cycle/current-cycle.json` or `docs/dev-refactor/current-cycle.json`):\n\n```json\n{\n  \"version\": \"1.0.0\",\n  \"cycle_id\": \"uuid\",\n  \"started_at\": \"ISO timestamp\",\n  \"updated_at\": \"ISO timestamp\",\n  \"source_file\": \"path/to/tasks.md\",\n  \"state_path\": \"docs/dev-cycle/current-cycle.json | docs/dev-refactor/current-cycle.json\",\n  \"cycle_type\": \"feature | refactor\",\n  \"execution_mode\": \"manual_per_subtask|manual_per_task|automatic\",\n  \"commit_timing\": \"per_subtask|per_task|at_end\",\n  \"status\": \"in_progress|completed|failed|paused|paused_for_approval|paused_for_testing|paused_for_task_approval|paused_for_integration_testing\",\n  \"feedback_loop_completed\": false,\n  \"current_task_index\": 0,\n  \"current_gate\": 0,\n  \"current_subtask_index\": 0,\n  \"tasks\": [\n    {\n      \"id\": \"T-001\",\n      \"title\": \"Task title\",\n      \"status\": \"pending|in_progress|completed|failed|blocked\",\n      \"feedback_loop_completed\": false,\n      \"subtasks\": [\n        {\n          \"id\": \"ST-001-01\",\n          \"file\": \"subtasks/T-001/ST-001-01.md\",\n          \"status\": \"pending|completed\"\n        }\n      ],\n      \"gate_progress\": {\n        \"implementation\": {\n          \"status\": \"in_progress\",\n          \"started_at\": \"...\",\n          \"tdd_red\": {\n            \"status\": \"pending|in_progress|completed\",\n            \"test_file\": \"path/to/test_file.go\",\n            \"failure_output\": \"FAIL: TestFoo - expected X got nil\",\n            \"completed_at\": \"ISO timestamp\"\n          },\n          \"tdd_green\": {\n            \"status\": \"pending|in_progress|completed\",\n            \"implementation_file\": \"path/to/impl.go\",\n            \"test_pass_output\": \"PASS: TestFoo (0.003s)\",\n            \"completed_at\": \"ISO timestamp\"\n          }\n        },\n        \"devops\": {\"status\": \"pending\"},\n        \"sre\": {\"status\": \"pending\"},\n        \"testing\": {\"status\": \"pending\"},\n        \"review\": {\"status\": \"pending\"},\n        \"validation\": {\"status\": \"pending\"}\n      },\n      \"artifacts\": {},\n      \"agent_outputs\": {\n        \"implementation\": {\n          \"agent\": \"backend-engineer-golang\",\n          \"output\": \"## Summary\\n...\",\n          \"timestamp\": \"ISO timestamp\",\n          \"duration_ms\": 0,\n          \"iterations\": 1,\n          \"standards_compliance\": {\n            \"total_sections\": 15,\n            \"compliant\": 14,\n            \"not_applicable\": 1,\n            \"non_compliant\": 0,\n            \"gaps\": []\n          }\n        },\n        \"devops\": {\n          \"agent\": \"devops-engineer\",\n          \"output\": \"## Summary\\n...\",\n          \"timestamp\": \"ISO timestamp\",\n          \"duration_ms\": 0,\n          \"iterations\": 1,\n          \"artifacts_created\": [\"Dockerfile\", \"docker-compose.yml\", \".env.example\"],\n          \"verification_errors\": [],\n          \"standards_compliance\": {\n            \"total_sections\": 8,\n            \"compliant\": 8,\n            \"not_applicable\": 0,\n            \"non_compliant\": 0,\n            \"gaps\": []\n          }\n        },\n        \"sre\": {\n          \"agent\": \"sre\",\n          \"output\": \"## Summary\\n...\",\n          \"timestamp\": \"ISO timestamp\",\n          \"duration_ms\": 0,\n          \"iterations\": 1,\n          \"instrumentation_coverage\": \"92%\",\n          \"validation_errors\": [],\n          \"standards_compliance\": {\n            \"total_sections\": 10,\n            \"compliant\": 10,\n            \"not_applicable\": 0,\n            \"non_compliant\": 0,\n            \"gaps\": []\n          }\n        },\n        \"testing\": {\n          \"agent\": \"qa-analyst\",\n          \"output\": \"## Summary\\n...\",\n          \"verdict\": \"PASS\",\n          \"coverage_actual\": 87.5,\n          \"coverage_threshold\": 85,\n          \"iterations\": 1,\n          \"timestamp\": \"ISO timestamp\",\n          \"duration_ms\": 0,\n          \"failures\": [],\n          \"uncovered_criteria\": [],\n          \"standards_compliance\": {\n            \"total_sections\": 6,\n            \"compliant\": 6,\n            \"not_applicable\": 0,\n            \"non_compliant\": 0,\n            \"gaps\": []\n          }\n        },\n        \"review\": {\n          \"iterations\": 1,\n          \"timestamp\": \"ISO timestamp\",\n          \"duration_ms\": 0,\n          \"code_reviewer\": {\n            \"agent\": \"code-reviewer\",\n            \"output\": \"...\",\n            \"verdict\": \"PASS\",\n            \"timestamp\": \"...\",\n            \"issues\": [],\n            \"standards_compliance\": {\n              \"total_sections\": 12,\n              \"compliant\": 12,\n              \"not_applicable\": 0,\n              \"non_compliant\": 0,\n              \"gaps\": []\n            }\n          },\n          \"business_logic_reviewer\": {\n            \"agent\": \"business-logic-reviewer\",\n            \"output\": \"...\",\n            \"verdict\": \"PASS\",\n            \"timestamp\": \"...\",\n            \"issues\": [],\n            \"standards_compliance\": {\n              \"total_sections\": 8,\n              \"compliant\": 8,\n              \"not_applicable\": 0,\n              \"non_compliant\": 0,\n              \"gaps\": []\n            }\n          },\n          \"security_reviewer\": {\n            \"agent\": \"security-reviewer\",\n            \"output\": \"...\",\n            \"verdict\": \"PASS\",\n            \"timestamp\": \"...\",\n            \"issues\": [],\n            \"standards_compliance\": {\n              \"total_sections\": 10,\n              \"compliant\": 10,\n              \"not_applicable\": 0,\n              \"non_compliant\": 0,\n              \"gaps\": []\n            }\n          }\n        },\n        \"validation\": {\n          \"result\": \"approved|rejected\",\n          \"timestamp\": \"ISO timestamp\"\n        }\n      }\n    }\n  ],\n  \"metrics\": {\n    \"total_duration_ms\": 0,\n    \"gate_durations\": {},\n    \"review_iterations\": 0,\n    \"testing_iterations\": 0\n  }\n}\n```\n\n### Structured Error/Issue Schemas\n\n**These schemas enable `dev-feedback-loop` to analyze issues without parsing raw output.**\n\n#### Standards Compliance Gap Schema\n\n```json\n{\n  \"section\": \"Error Handling (MANDATORY)\",\n  \"status\": \"\",\n  \"reason\": \"Missing error wrapping with context\",\n  \"file\": \"internal/handler/user.go\",\n  \"line\": 45,\n  \"evidence\": \"return err // should wrap with additional context\"\n}\n```\n\n#### Test Failure Schema\n\n```json\n{\n  \"test_name\": \"TestUserCreate_InvalidEmail\",\n  \"test_file\": \"internal/handler/user_test.go\",\n  \"error_type\": \"assertion\",\n  \"expected\": \"ErrInvalidEmail\",\n  \"actual\": \"nil\",\n  \"message\": \"Expected validation error for invalid email format\",\n  \"stack_trace\": \"user_test.go:42  user.go:28\"\n}\n```\n\n#### Review Issue Schema\n\n```json\n{\n  \"severity\": \"MEDIUM\",\n  \"category\": \"error-handling\",\n  \"description\": \"Error not wrapped with context before returning\",\n  \"file\": \"internal/handler/user.go\",\n  \"line\": 45,\n  \"suggestion\": \"Use fmt.Errorf(\\\"failed to create user: %w\\\", err)\",\n  \"fixed\": false,\n  \"fixed_in_iteration\": null\n}\n```\n\n#### DevOps Verification Error Schema\n\n```json\n{\n  \"check\": \"docker_build\",\n  \"status\": \"FAIL\",\n  \"error\": \"COPY failed: file not found in build context: go.sum\",\n  \"suggestion\": \"Ensure go.sum exists and is not in .dockerignore\"\n}\n```\n\n#### SRE Validation Error Schema\n\n```json\n{\n  \"check\": \"structured_logging\",\n  \"status\": \"FAIL\",\n  \"file\": \"internal/handler/user.go\",\n  \"line\": 32,\n  \"error\": \"Using fmt.Printf instead of structured logger\",\n  \"suggestion\": \"Use logger.Info().Str(\\\"user_id\\\", id).Msg(\\\"user created\\\")\"\n}\n```\n\n### Populating Structured Data\n\n**Each gate MUST populate its structured fields when saving to state:**\n\n| Gate | Fields to Populate |\n|------|-------------------|\n| Gate 0 (Implementation) | `standards_compliance` (total, compliant, gaps[]) |\n| Gate 1 (DevOps) | `standards_compliance` + `verification_errors[]` |\n| Gate 2 (SRE) | `standards_compliance` + `validation_errors[]` |\n| Gate 3 (Testing) | `standards_compliance` + `failures[]` + `uncovered_criteria[]` |\n| Gate 4 (Review) | `standards_compliance` per reviewer + `issues[]` per reviewer |\n\n**All gates track `standards_compliance`:**\n- `total_sections`: Count from agent's standards file (via standards-coverage-table.md)\n- `compliant`: Sections marked  in Standards Coverage Table\n- `not_applicable`: Sections marked N/A\n- `non_compliant`: Sections marked  (MUST be 0 to pass gate)\n- `gaps[]`: Detailed info for each  section (even if later fixed)\n\n**Empty arrays `[]` indicate no issues found - this is valid data for feedback-loop.**\n\n##  State Persistence Rule (MANDATORY)\n\n**\"Update state\" means BOTH update the object and write to file. Not just in-memory.**\n\n### After every Gate Transition\n\nYou MUST execute these steps after completing any gate (0, 1, 2, 3, 4, or 5):\n\n```yaml\n# Step 1: Update state object with gate results\nstate.tasks[current_task_index].gate_progress.[gate_name].status = \"completed\"\nstate.tasks[current_task_index].gate_progress.[gate_name].completed_at = \"[ISO timestamp]\"\nstate.current_gate = [next_gate_number]\nstate.updated_at = \"[ISO timestamp]\"\n\n# Step 2: Write to file (MANDATORY - use Write tool)\nWrite tool:\n  file_path: [state.state_path]  # Use state_path from state object\n  content: [full JSON state]\n\n# Step 3: Verify persistence (MANDATORY - use Read tool)\nRead tool:\n  file_path: [state.state_path]  # Use state_path from state object\n# Confirm current_gate and gate_progress match expected values\n```\n\n### State Persistence Checkpoints\n\n| After | MUST Update | MUST Write File |\n|-------|-------------|-----------------|\n| Gate 0.1 (TDD-RED) | `tdd_red.status`, `tdd_red.failure_output` |  YES |\n| Gate 0.2 (TDD-GREEN) | `tdd_green.status`, `implementation.status` |  YES |\n| Gate 1 (DevOps) | `devops.status`, `agent_outputs.devops` |  YES |\n| Gate 2 (SRE) | `sre.status`, `agent_outputs.sre` |  YES |\n| Gate 3 (Testing) | `testing.status`, `agent_outputs.testing` |  YES |\n| Gate 4 (Review) | `review.status`, `agent_outputs.review` |  YES |\n| Gate 5 (Validation) | `validation.status`, task `status` |  YES |\n| Step 7.1 (Unit Approval) | `status = \"paused_for_approval\"` |  YES |\n| Step 7.2 (Task Approval) | `status = \"paused_for_task_approval\"` |  YES |\n\n### Anti-Rationalization for State Persistence\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I'll save state at the end\" | Crash/timeout loses all progress | **Save after each gate** |\n| \"State is in memory, that's updated\" | Memory is volatile. File is persistent. | **Write to JSON file** |\n| \"Only save on checkpoints\" | Gates without saves = unrecoverable on resume | **Save after every gate** |\n| \"Write tool is slow\" | Write takes <100ms. Lost progress takes hours. | **Write after every gate** |\n| \"I updated the state variable\" | Variable  file. Without Write tool, nothing persists. | **Use Write tool explicitly** |\n\n### Verification Command\n\nAfter each gate, the state file MUST reflect:\n- `current_gate` = next gate number\n- `updated_at` = recent timestamp\n- Previous gate `status` = \"completed\"\n\n**If verification fails  State was not persisted. Re-execute Write tool.**\n\n---\n\n## Step 0: Verify PROJECT_RULES.md Exists (HARD GATE)\n\n**NON-NEGOTIABLE. Cycle CANNOT proceed without project standards.**\n\n### Step 0 Flow\n\n```text\n\n  Check: Does docs/PROJECT_RULES.md exist?                                   \n                                                                             \n   YES  Proceed to Step 1 (Initialize or Resume)                        \n                                                                            \n   no  ASK: \"Is this a LEGACY project (created without PM workflow)?\"   \n                                                                            \n        YES (legacy project)  LEGACY PROJECT ANALYSIS:                   \n          Step 1: Dispatch codebase-explorer (technical info only)          \n          Step 2: Ask 3 questions (what agent can't determine):             \n            1. What do you need help with?                                  \n            2. Any external APIs not visible in code?                       \n            3. Any specific technology not in Ring Standards?               \n          Step 3: Generate PROJECT_RULES.md (deduplicated from Ring)        \n          Note: Business rules belong in PRD, not in PROJECT_RULES          \n           Proceed to Step 1                                               \n                                                                            \n        no (new project)  ASK: \"Do you have PRD, TRD, or Feature Map?\"  \n                                                                            \n            YES (has PM docs)  \"Please provide the file path(s)\"        \n               Read PRD/TRD/Feature Map  Extract info                    \n               Generate PROJECT_RULES.md                                  \n               Ask supplementary questions if info is incomplete          \n               Save and proceed to Step 1                                 \n                                                                            \n            no (no PM docs)   HARD BLOCK:                              \n               \"PM documents are REQUIRED for new projects.                  \n                Run /pre-dev-full or /pre-dev-feature first.\"               \n                STOP (cycle cannot proceed)                                 \n\n```\n\n### Step 0.1: Check for PROJECT_RULES.md\n\n```yaml\n# Check if file exists\nRead tool:\n  file_path: \"docs/PROJECT_RULES.md\"\n\n# If file exists and has content  Proceed to Step 1\n# If file does not exist or is empty  Continue to Step 0.2\n```\n\n### Step 0.2: Check if Legacy Project\n\n#### Ask the User\n\nUse AskUserQuestion:\n\n```text\n\n  PROJECT_RULES.md not FOUND                                   \n\n                                                                 \n I need to create docs/PROJECT_RULES.md to understand your       \n project's specific conventions and domain.                      \n                                                                 \n First, I need to know: Is this a LEGACY project?                \n                                                                 \n A legacy project is one that was created WITHOUT using the      \n PM team workflow (no PRD, TRD, or Feature Map documents).       \n                                                                 \n\n```\n\n#### Question\n\n\"Is this a legacy project (created without PM team workflow)?\"\n\n#### Options\n\n(a) Yes, this is a legacy project (b) No, this is a new project following Ring workflow\n\n#### If YES (legacy)\n\nGo to Step 0.2.1 (Legacy Project Analysis)\n\n#### If no (new project)\n\nGo to Step 0.3 (Check for PM Documents)\n\n### Step 0.2.1: Legacy Project Analysis (Technical Only)\n\n#### Overview\n\nFor legacy projects, analyze codebase for TECHNICAL information only:\n\n```text\n\n  LEGACY PROJECT ANALYSIS                                      \n\n                                                                 \n Since this is a legacy project, I'll analyze the codebase       \n for TECHNICAL information (not business rules).                 \n                                                                 \n Step 1: Automated analysis (codebase-explorer)                  \n Step 2: Ask for project-specific tech not in Ring Standards     \n Step 3: Generate PROJECT_RULES.md (deduplicated)                \n                                                                 \n Note: Business rules belong in PRD/product docs, not here.      \n                                                                 \n\n```\n\n#### Step 0.2.1a: Automated Codebase Analysis (MANDATORY)\n\n** You MUST use the Task tool to dispatch codebase-explorer. This is not implicit.**\n\n#### Dispatch Agent\n\nDispatch codebase-explorer to analyze the legacy project for TECHNICAL information:\n\n```text\nAction: Use Task tool with EXACTLY these parameters:\n\n\n   If Task tool not used  Analysis does not happen  PROJECT_RULES.md INVALID \n\n```\n\n```yaml\n# Agent 1: Codebase Explorer - Technical Analysis\nTask tool:\n  subagent_type: \"ring:codebase-explorer\"\n  model: \"opus\"\n  description: \"Analyze legacy project for PROJECT_RULES.md\"\n  prompt: |\n    Analyze this LEGACY codebase to extract technical information for PROJECT_RULES.md.\n    \n    This is an existing project created without PM documentation.\n    Your job is to understand what exists in the code.\n    \n    **Extract:**\n    1. **Project Structure:** Directory layout, module organization\n    2. **Technical Stack:** Languages, frameworks, databases, external services\n    3. **Architecture Patterns:** Clean Architecture, MVC, microservices, etc.\n    4. **Existing Features:** Main modules, endpoints, capabilities\n    5. **Internal Libraries:** Shared packages, utilities\n    6. **Configuration:** Environment variables, config patterns\n    7. **Database:** Schema patterns, migrations, ORM usage\n    8. **External Integrations:** APIs consumed, message queues\n    \n    **Output format:**\n    ## Technical Analysis (Legacy Project)\n    \n    ### Project Overview\n    [What this project appears to do based on code analysis]\n    \n    ### Technical Stack\n    - Language: [detected]\n    - Framework: [detected]\n    - Database: [detected]\n    - External Services: [detected]\n    \n    ### Architecture Patterns\n    [Detected patterns]\n    \n    ### Existing Features\n    [List of features/modules found]\n    \n    ### Project Structure\n    [Directory layout explanation]\n    \n    ### Configuration\n    [Env vars, config files found]\n    \n    ### External Integrations\n    [APIs, services detected]\n\n```\n\n**Note:** Business logic analysis is not needed for PROJECT_RULES.md. Business rules belong in PRD/product docs, not technical project rules.\n\n#### Verification (MANDATORY)\n\nAfter agent completes, confirm:\n- [ ] `codebase-explorer` returned \"## Technical Analysis (Legacy Project)\" section\n- [ ] Output contains non-empty content for: Tech Stack, External Integrations, Configuration\n\n**If agent failed or returned empty output  Re-dispatch. Cannot proceed without technical analysis.**\n\n#### Step 0.2.1b: Supplementary Questions (Only What Agents Can't Determine)\n\n#### Post-Analysis Questions\n\nAfter agents complete, ask only what they couldn't determine from code:\n\n```text\n\n  Codebase Analysis Complete                                    \n\n                                                                 \n I've analyzed your codebase. Now I need a few details that      \n only you can provide (not visible in the code).                 \n                                                                 \n\n```\n\n#### Questions to Ask\n\nUse AskUserQuestion for each:\n\n| # | Question | Why Agents Can't Determine This |\n|---|----------|--------------------------------|\n| 1 | **What do you need help with?** (Current task/feature/fix) | Future intent, not in code |\n| 2 | **Any external APIs or services not visible in code?** (Third-party integrations planned) | Planned integrations, not yet in code |\n| 3 | **Any specific technology not in Ring Standards?** (Message broker, cache, etc.) | Project-specific tech not in Ring |\n\n**Note:** Business rules belong in PRD/product docs, not in PROJECT_RULES.md.\n\n#### Step 0.2.1c: Generate PROJECT_RULES.md\n\n#### Combine Agent Outputs and User Answers\n\n```yaml\nCreate tool:\n  file_path: \"docs/PROJECT_RULES.md\"\n  content: |\n    # Project Rules\n    \n    > Ring Standards apply automatically. This file documents only what Ring does not cover.\n    > For error handling, logging, testing, architecture, lib-commons  See Ring Standards (auto-loaded by agents)\n    > Generated from legacy project analysis.\n    \n    ## What Ring Standards Already Cover (DO not ADD HERE)\n    \n    The following are defined in Ring Standards and MUST not be duplicated:\n    - Error handling patterns (no panic, wrap errors)\n    - Logging standards (structured JSON, zerolog/zap)\n    - Testing patterns (table-driven tests, mocks)\n    - Architecture patterns (Hexagonal, Clean Architecture)\n    - Observability (OpenTelemetry, trace correlation)\n    - lib-commons usage and patterns\n    - API directory structure\n    \n    ---\n    \n    ## Tech Stack (Not in Ring Standards)\n    \n    [From codebase-explorer: Technologies not covered by Ring Standards]\n    [e.g., specific message broker, specific cache, DB if not PostgreSQL]\n    \n    | Technology | Purpose | Notes |\n    |------------|---------|-------|\n    | [detected] | [purpose] | [notes] |\n    \n    ## Non-Standard Directory Structure\n    \n    [From codebase-explorer: Directories that deviate from Ring's standard API structure]\n    [e.g., workers/, consumers/, polling/]\n    \n    | Directory | Purpose | Pattern |\n    |-----------|---------|---------|\n    | [detected] | [purpose] | [pattern] |\n    \n    ## External Integrations\n    \n    [From codebase-explorer: Third-party services specific to this project]\n    \n    | Service | Purpose | Docs |\n    |---------|---------|------|\n    | [detected] | [purpose] | [link] |\n    \n    ## Environment Configuration\n    \n    [From codebase-explorer: Project-specific env vars not covered by Ring]\n    \n    | Variable | Purpose | Example |\n    |----------|---------|---------|\n    | [detected] | [purpose] | [example] |\n    \n    ## Domain Terminology\n    \n    [From codebase analysis: Technical names used in this codebase]\n    \n    | Term | Definition | Used In |\n    |------|------------|---------|\n    | [detected] | [definition] | [location] |\n    \n    ---\n    \n    *Generated: [ISO timestamp]*\n    *Source: Legacy project analysis (codebase-explorer)*\n    *Ring Standards Version: [version from WebFetch]*\n```\n\n#### Present to User\n\n```text\n\n  PROJECT_RULES.md Generated for Legacy Project                 \n\n                                                                 \n I analyzed your codebase using:                                 \n    codebase-explorer (technical patterns, stack, structure)    \n                                                                 \n Combined with your input on:                                    \n    Current development goal                                    \n    External integrations                                       \n    Project-specific technology                                 \n                                                                 \n Generated: docs/PROJECT_RULES.md                                \n                                                                 \n Note: Ring Standards (error handling, logging, testing, etc.)   \n are not duplicated - agents load them automatically via WebFetch\n                                                                 \n Please review the file and make any corrections needed.         \n                                                                 \n\n```\n\n#### Ask for Approval\n\nUse AskUserQuestion:\n- Question: \"PROJECT_RULES.md has been generated. Would you like to review it before proceeding?\"\n- Options: (a) Proceed (b) Open for editing first\n\n#### After Approval\n\nProceed to Step 1\n\n### Step 0.3: Check for PM Documents (PRD/TRD/Feature Map)\n\n#### Check for PM Documents\n\nFor NEW projects (not legacy), ask about PM documents:\n\n```text\n\n  NEW PROJECT - PM DOCUMENTS CHECK                             \n\n                                                                 \n Since this is a new project following Ring workflow, you        \n should have PM documents from the pre-dev workflow.             \n                                                                 \n Do you have any of these PM documents?                          \n    PRD (Product Requirements Document)                         \n    TRD (Technical Requirements Document)                       \n    Feature Map (from pre-dev-feature-map skill)                \n                                                                 \n\n```\n\n#### Question\n\n\"Do you have PRD, TRD, or Feature Map documents for this project?\"\n\n#### Options\n\n(a) Yes, I have PM documents (b) No, I don't have these documents\n\n#### If YES - Ask for File Paths\n\n```text\n\"Please provide the file path(s) to your PM documents:\n - PRD path (or 'skip' if none): \n - TRD path (or 'skip' if none): \n - Feature Map path (or 'skip' if none): \"\n```\n\n#### Example Paths\n\nTypical PM team output structure:\n\n```text\ndocs/pre-dev/{feature-name}/\n prd.md               PRD path: docs/pre-dev/auth-system/prd.md\n trd.md               TRD path: docs/pre-dev/auth-system/trd.md\n feature-map.md       Feature Map path: docs/pre-dev/auth-system/feature-map.md\n api-design.md\n data-model.md\n tasks.md\n```\n\n#### Common Patterns\n\n- `/pre-dev-full` output: `docs/pre-dev/{feature}/prd.md`, `trd.md`, `feature-map.md`\n- `/pre-dev-feature` output: `docs/pre-dev/{feature}/prd.md`, `feature-map.md`\n- Custom locations: User may have docs in different paths (e.g., `requirements/`, `specs/`)\n\n#### Then\n\nGo to Step 0.3.1 (Generate from PM Documents)\n\n#### If no\n\nHARD BLOCK (Step 0.3.2)\n\n### Step 0.3.1: Generate from PM Documents (PRD/TRD/Feature Map)\n\n#### Read the Provided Documents\n\n```yaml\n# Read PRD if provided\nRead tool:\n  file_path: \"[user-provided PRD path]\"\n\n# Read TRD if provided  \nRead tool:\n  file_path: \"[user-provided TRD path]\"\n\n# Read Feature Map if provided\nRead tool:\n  file_path: \"[user-provided Feature Map path]\"\n```\n\n#### Extract PROJECT_RULES.md Content from PM Documents\n\n** DEDUPLICATION RULE:** Extract only what Ring Standards DO NOT cover.\n\n| From PRD | Extract For PROJECT_RULES.md | Note |\n|----------|------------------------------|------|\n| Domain terms, entities | Domain Terminology | Technical names only |\n| External service mentions | External Integrations | Third-party APIs |\n| ~~Business rules~~ | ~~N/A~~ |  Stays in PRD, not PROJECT_RULES |\n| ~~Architecture~~ | ~~N/A~~ |  Ring Standards covers this |\n\n| From TRD | Extract For PROJECT_RULES.md | Note |\n|----------|------------------------------|------|\n| Tech stack not in Ring | Tech Stack (Not in Ring) | Only non-standard tech |\n| External APIs | External Integrations | Third-party services |\n| Non-standard directories | Non-Standard Directory Structure | Workers, consumers, etc. |\n| ~~Architecture decisions~~ | ~~N/A~~ |  Ring Standards covers this |\n| ~~Database patterns~~ | ~~N/A~~ |  Ring Standards covers this |\n\n| From Feature Map | Extract For PROJECT_RULES.md | Note |\n|------------------|------------------------------|------|\n| Technology choices not in Ring | Tech Stack (Not in Ring) | Only if not in Ring |\n| External dependencies | External Integrations | Third-party services |\n| ~~Architecture~~ | ~~N/A~~ |  Ring Standards covers this |\n\n#### Generate PROJECT_RULES.md\n\n```yaml\nCreate tool:\n  file_path: \"docs/PROJECT_RULES.md\"\n  content: |\n    # Project Rules\n    \n    >  IMPORTANT: Ring Standards are not automatic. Agents MUST WebFetch them before implementation.\n    > This file documents only project-specific information not covered by Ring Standards.\n    > Generated from PM documents (PRD/TRD/Feature Map).\n    >\n    > Ring Standards URLs:\n    > - Go: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md\n    > - TypeScript: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/typescript.md\n    \n    ## What Ring Standards Cover (DO not DUPLICATE HERE)\n    \n    The following are defined in Ring Standards and MUST not be duplicated in this file:\n    - Error handling patterns (no panic, wrap errors)\n    - Logging standards (structured JSON via lib-commons)\n    - Testing patterns (table-driven tests, mocks)\n    - Architecture patterns (Hexagonal, Clean Architecture)\n    - Observability (OpenTelemetry via lib-commons)\n    - lib-commons / lib-common-js usage and patterns\n    - API directory structure (Lerian pattern)\n    - Database connections (PostgreSQL, MongoDB, Redis via lib-commons)\n    - Bootstrap pattern (config.go, service.go, server.go)\n    \n    **Agents MUST WebFetch Ring Standards and output Standards Coverage Table.**\n    \n    ---\n    \n    ## Tech Stack (Not in Ring Standards)\n    \n    [From TRD/Feature Map: only technologies not covered by Ring Standards]\n    \n    | Technology | Purpose | Notes |\n    |------------|---------|-------|\n    | [detected] | [purpose] | [notes] |\n    \n    ## Non-Standard Directory Structure\n    \n    [From TRD: Directories that deviate from Ring's standard API structure]\n    \n    | Directory | Purpose | Pattern |\n    |-----------|---------|---------|\n    | [detected] | [purpose] | [pattern] |\n    \n    ## External Integrations\n    \n    [From TRD/PRD: Third-party services specific to this project]\n    \n    | Service | Purpose | Docs |\n    |---------|---------|------|\n    | [detected] | [purpose] | [link] |\n    \n    ## Environment Configuration\n    \n    [From TRD: Project-specific env vars not covered by Ring]\n    \n    | Variable | Purpose | Example |\n    |----------|---------|---------|\n    | [detected] | [purpose] | [example] |\n    \n    ## Domain Terminology\n    \n    [From PRD: Technical names used in this codebase]\n    \n    | Term | Definition | Used In |\n    |------|------------|---------|\n    | [detected] | [definition] | [location] |\n    \n    ---\n    \n    *Generated from: [PRD path], [TRD path], [Feature Map path]*\n    *Ring Standards Version: [version from WebFetch]*\n    *Generated: [ISO timestamp]*\n```\n\n#### Check for Missing Information\n\nIf any section is empty or incomplete, ask supplementary questions:\n\n| Missing Section | Supplementary Question |\n|-----------------|------------------------|\n| Tech Stack (Not in Ring) | \"Any technology not covered by Ring Standards (message broker, cache, etc.)?\" |\n| External Integrations | \"Any third-party APIs or external services?\" |\n| Domain Terminology | \"What are the main entities/classes in this codebase?\" |\n| Non-Standard Directories | \"Any directories that don't follow standard API structure (workers, consumers)?\" |\n\n**Note:** Do not ask about architecture, error handling, logging, testing - Ring Standards covers these.\n\n#### After Generation\n\nPresent to user for review, then proceed to Step 1.\n\n### Step 0.3.2: HARD BLOCK - No PM Documents (New Projects Only)\n\n#### When User Has No PM Documents\n\n```text\n\n  CANNOT PROCEED - PM DOCUMENTS REQUIRED                       \n\n                                                                 \n Development cannot start without PM documents.                  \n                                                                 \n You MUST create PRD, TRD, and/or Feature Map documents first    \n using PM team skills:                                           \n                                                                 \n   /pre-dev-full      For features 2 days (9 gates)           \n   /pre-dev-feature   For features <2 days (4 gates)           \n                                                                 \n These commands will guide you through creating:                 \n    PRD (Product Requirements Document)                         \n    TRD (Technical Requirements Document)                       \n    Feature Map (technology choices, feature relationships)     \n                                                                 \n After completing pre-dev workflow, run /dev-cycle again.        \n                                                                 \n\n```\n\n#### Action\n\nSTOP EXECUTION. Do not proceed to Step 1.\n\n### Step 0 Anti-Rationalization\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Skip PM docs, I'll add them later\" | Later = never. No PM docs = no project context = agents guessing. | **Run /pre-dev-full or /pre-dev-feature NOW** |\n| \"Project is simple, doesn't need PM docs\" | Simple projects still need domain context defined upfront. | **Create PM documents first** |\n| \"I know what I want to build\" | Your knowledge  documented knowledge agents can use. | **Document in PRD/TRD/Feature Map** |\n| \"PM workflow takes too long\" | PM workflow takes 30-60 min. Rework from unclear requirements takes days. | **Invest time upfront** |\n| \"Just let me start coding\" | Coding without requirements = building the wrong thing. | **Requirements first, code second** |\n| \"It's legacy but I don't want to answer questions\" | Legacy analysis takes ~5 min. Without it, agents have zero context. | **Answer the 4 questions** |\n| \"Legacy project is too complex to explain\" | Start with high-level answers. PROJECT_RULES.md can be refined later. | **Provide what you know NOW** |\n\n### Pressure Resistance\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Just skip this, I'll create PM docs later\" | \"PM documents are REQUIRED for new projects. Without them, agents cannot understand your project's domain context or technical requirements. Run `/pre-dev-full` or `/pre-dev-feature` first.\" |\n| \"I don't need formal documents\" | \"PM documents are the source of truth for PROJECT_RULES.md. Development cannot start without documented requirements.\" |\n| \"This is just a quick prototype\" | \"Even prototypes need clear requirements. `/pre-dev-feature` takes ~30 minutes and prevents hours of rework.\" |\n| \"I already explained what I want verbally\" | \"Verbal explanations cannot be used by agents. Requirements MUST be documented in PRD/TRD/Feature Map files.\" |\n| \"It's a legacy project but skip the questions\" | \"The legacy analysis (codebase-explorer + 3 questions) is the only way I can understand your project. It takes ~5 minutes and enables me to help you effectively.\" |\n| \"I'll fill in PROJECT_RULES.md myself\" | \"That works! Create `docs/PROJECT_RULES.md` with: Tech Stack (not in Ring), External Integrations, Domain Terminology. Do not duplicate Ring Standards content. Then run `/dev-cycle` again.\" |\n\n---\n\n## Step 1: Initialize or Resume\n\n### New Cycle (with task file path)\n\n**Input:** `path/to/tasks.md` or `path/to/pre-dev/{feature}/`\n\n1. **Detect input:** File  Load directly | Directory  Load tasks.md + discover subtasks/\n2. **Build order:** Read tasks, check for subtasks (ST-XXX-01, 02...) or TDD autonomous mode\n3. **Determine state path:**\n   - if source_file contains `docs/refactor/`  `state_path = \"docs/dev-refactor/current-cycle.json\"`, `cycle_type = \"refactor\"`\n   - else  `state_path = \"docs/dev-cycle/current-cycle.json\"`, `cycle_type = \"feature\"`\n4. **Initialize state:** Generate cycle_id, create state file at `{state_path}`, set indices to 0\n5. **Display plan:** \"Loaded X tasks with Y subtasks\"\n6. **ASK EXECUTION MODE (MANDATORY - AskUserQuestion):**\n   - Options: (a) Manual per subtask (b) Manual per task (c) Automatic\n   - **Do not skip:** User hints  mode selection. Only explicit a/b/c is valid.\n7. **ASK COMMIT TIMING (MANDATORY - AskUserQuestion):**\n   - Options: (a) Per subtask (b) Per task (c) At the end\n   - Store in `commit_timing` field in state\n8. **Start:** Display mode + commit timing, proceed to Gate 0\n\n### Resume Cycle (--resume flag)\n\n1. **Find existing state file:**\n   - Check `docs/dev-cycle/current-cycle.json` first\n   - If not found, check `docs/dev-refactor/current-cycle.json`\n   - If neither exists  Error: \"No cycle to resume\"\n2. Load found state file, validate (state_path is stored in the state object)\n3. Display: cycle started, tasks completed/total, current task/subtask/gate, paused reason\n4. **Handle paused states:**\n\n| Status | Action |\n|--------|--------|\n| `paused_for_approval` | Re-present Step 7.1 checkpoint |\n| `paused_for_testing` | Ask if testing complete  continue or keep paused |\n| `paused_for_task_approval` | Re-present Step 7.2 checkpoint |\n| `paused_for_integration_testing` | Ask if integration testing complete |\n| `paused` (generic) | Ask user to confirm resume |\n| `in_progress` | Resume from current gate |\n\n## Input Validation\n\nTask files are generated by `/pre-dev-*` or `/dev-refactor`, which handle content validation. The dev-cycle performs basic format checks:\n\n### Format Checks\n\n| Check | Validation | Action |\n|-------|------------|--------|\n| File exists | Task file path is readable | Error: abort |\n| Task headers | At least one `## Task:` found | Error: abort |\n| Task ID format | `## Task: {ID} - {Title}` | Warning: use line number as ID |\n| Acceptance criteria | At least one `- [ ]` per task | Warning: task may fail validation gate |\n\n## Step 2: Gate 0 - Implementation (Per Execution Unit)\n\n**REQUIRED SUB-SKILL:** Use dev-implementation\n\n**Execution Unit:** Task (if no subtasks) or Subtask (if task has subtasks)\n\n###  MANDATORY: Agent Dispatch Required\n\nSee [shared-patterns/shared-orchestrator-principle.md](../shared-patterns/shared-orchestrator-principle.md) for full details.\n\n**Gate 0 has TWO explicit sub-phases with a HARD GATE between them:**\n\n```text\n\n  GATE 0.1: TDD-RED                                              \n                                                \n  Write failing test  Run test  Capture FAILURE output         \n                                                                 \n   HARD GATE   \n  CANNOT proceed to 0.2 until failure output is captured         \n     \n                                                                 \n  GATE 0.2: TDD-GREEN                                            \n                                               \n  Implement minimal code  Run test  Verify PASS                \n\n```\n\n### Step 2.1: Gate 0.1 - TDD-RED (Write Failing Test)\n\n1. Record gate start timestamp\n2. Set `gate_progress.implementation.tdd_red.status = \"in_progress\"`\n\n3. Determine appropriate agent based on content:\n   - Go files/go.mod  backend-engineer-golang\n   - TypeScript backend  backend-engineer-typescript\n   - React/Frontend  frontend-engineer-typescript\n   - Infrastructure  devops-engineer\n\n4. Dispatch to selected agent for TDD-RED only:\n\n   See [shared-patterns/template-tdd-prompts.md](../shared-patterns/template-tdd-prompts.md) for the TDD-RED prompt template.\n\n   Include: unit_id, title, requirements, acceptance_criteria in the prompt.\n\n5. Receive TDD-RED report from agent\n6. **VERIFY FAILURE OUTPUT EXISTS (HARD GATE):** See shared-patterns/template-tdd-prompts.md for verification rules.\n\n7. Update state:\n   ```json\n   gate_progress.implementation.tdd_red = {\n     \"status\": \"completed\",\n     \"test_file\": \"[path from agent]\",\n     \"failure_output\": \"[actual failure output from agent]\",\n     \"completed_at\": \"[ISO timestamp]\"\n   }\n   ```\n\n8. **Display to user:**\n   ```text\n   \n     TDD-RED COMPLETE                              \n   \n    Test: [test_file]:[test_function]               \n    Failure: [first line of failure output]         \n                                                    \n    Proceeding to TDD-GREEN...                      \n   \n   ```\n\n9. Proceed to Gate 0.2\n\n### Step 2.2: Gate 0.2 - TDD-GREEN (Implementation)\n\n**PREREQUISITE:** `gate_progress.implementation.tdd_red.status == \"completed\"`\n\n1. Set `gate_progress.implementation.tdd_green.status = \"in_progress\"`\n\n2. Dispatch to same agent for TDD-GREEN:\n\n   See [shared-patterns/template-tdd-prompts.md](../shared-patterns/template-tdd-prompts.md) for the TDD-GREEN prompt template (includes observability requirements).\n\n   Include: unit_id, title, tdd_red.test_file, tdd_red.failure_output in the prompt.\n\n3. Receive TDD-GREEN report from agent\n4. **VERIFY PASS OUTPUT EXISTS (HARD GATE):** See shared-patterns/template-tdd-prompts.md for verification rules.\n\n5. Update state:\n   ```json\n   gate_progress.implementation.tdd_green = {\n     \"status\": \"completed\",\n     \"implementation_file\": \"[path from agent]\",\n     \"test_pass_output\": \"[actual pass output from agent]\",\n     \"completed_at\": \"[ISO timestamp]\"\n   }\n   gate_progress.implementation.status = \"completed\"\n   artifacts.implementation = {files_changed, commit_sha}\n   agent_outputs.implementation = {\n     agent: \"[selected_agent]\",\n     output: \"[full agent output for feedback analysis]\",\n     timestamp: \"[ISO timestamp]\",\n     duration_ms: [execution time],\n     iterations: [standards_compliance_iterations from Step 2.3],\n     standards_compliance: {\n       total_sections: [N from final verification],\n       compliant: [N sections with ],\n       not_applicable: [N sections with N/A],\n       non_compliant: 0,\n       gaps: []  // Empty when gate passes; populated during iterations\n     }\n   }\n   ```\n   \n   **If iterations > 1, populate `gaps[]` with issues found in previous iterations:**\n   ```json\n   gaps: [\n     {\n       \"section\": \"[section name from  row]\",\n       \"status\": \"\",\n       \"reason\": \"[why it failed]\",\n       \"file\": \"[file path if available]\",\n       \"line\": [line number if available],\n       \"evidence\": \"[code snippet or description]\",\n       \"fixed_in_iteration\": [iteration number when fixed]\n     }\n   ]\n   ```\n\n6. **Display to user:**\n   ```text\n   \n     GATE 0 COMPLETE (TDD-RED  TDD-GREEN)        \n   \n    RED:   [test_file] - FAIL captured            \n    GREEN: [impl_file] - PASS verified            \n                                                    \n    Proceeding to Gate 1 (DevOps)...               \n   \n   ```\n\n7. **Proceed to Step 2.3 (Standards Compliance Verification)**\n\n### Step 2.3: Standards Compliance Verification (HARD GATE)\n\n**PREREQUISITE:** `gate_progress.implementation.tdd_green.status == \"completed\"`\n\n**Purpose:** Verify implementation follows all standards defined in agent's standards file.\n\nSee [shared-patterns/template-tdd-prompts.md](../shared-patterns/template-tdd-prompts.md)  \"Orchestrator Enforcement\" section for full verification process.\n\n**Process:**\n\n### Step 2.3.1: Initialize Iteration Counter\n\n```text\nSet standards_compliance_iterations = 0\nSet MAX_ITERATIONS = 3\n```\n\n### Step 2.3.2: Verification Loop\n\n```text\nLOOP while standards_compliance_iterations < MAX_ITERATIONS:\n  \n  1. INCREMENT counter FIRST (before any verification):\n     standards_compliance_iterations += 1\n  \n  2. PARSE agent output for \"## Standards Coverage Table\":\n     if not FOUND:\n        Output INCOMPLETE\n        Log: \"Iteration [N]: Standards Coverage Table missing\"\n        Re-dispatch agent (see Step 2.3.3)\n        CONTINUE loop\n  \n  3. PARSE \"all STANDARDS MET:\" value:\n     if not FOUND:\n        Output INCOMPLETE\n        Log: \"Iteration [N]: Compliance Summary missing\"\n        Re-dispatch agent (see Step 2.3.3)\n        CONTINUE loop\n  \n  4. COUNT sections from Standards Coverage Table:\n     total_sections = count all rows\n     compliant = count rows with \n     not_applicable = count rows with N/A\n     non_compliant = count rows with \n  \n  5. VERIFY compliance:\n     if \"all STANDARDS MET:  YES\" and non_compliant == 0:\n        Gate 0 PASSED\n        BREAK loop (proceed to Step 2.3.4)\n     \n     if \"all STANDARDS MET:  no\" or non_compliant > 0:\n        Gate 0 BLOCKED\n        Extract  sections\n        Log: \"Iteration [N]: [non_compliant] sections non-compliant\"\n        Re-dispatch agent (see Step 2.3.3)\n        CONTINUE loop\n\nEND LOOP\n\nif standards_compliance_iterations >= MAX_ITERATIONS and non_compliant > 0:\n   HARD BLOCK\n   Update state with failure info\n   Report to user: \"Standards compliance failed after 3 attempts\"\n   STOP execution\n```\n\n### Step 2.3.3: Re-dispatch Agent for Compliance Fix\n\n```yaml\nTask tool:\n  subagent_type: \"[same agent from TDD-GREEN]\"\n  model: \"opus\"\n  description: \"Fix missing Ring Standards for [unit_id] (attempt [N]/3)\"\n  prompt: |\n     STANDARDS not MET - Fix Required (Attempt [standards_compliance_iterations] of 3)\n    \n    Your Standards Coverage Table shows these sections as :\n    [list  sections extracted from table]\n    \n    WebFetch your standards file:\n    [URL for agent's standards - golang.md, typescript.md, etc.]\n    \n    Implement all missing sections.\n    Return updated Standards Coverage Table with all  or N/A.\n    \n    Previous attempt summary:\n    - Total sections: [total_sections]\n    - Compliant: [compliant]\n    - Not applicable: [not_applicable]\n    - Non-compliant: [non_compliant]\n```\n\n### Step 2.3.4: Update State with Compliance Metrics\n\n```json\ngate_progress.implementation = {\n  \"status\": \"completed\",\n  \"tdd_red\": {...},\n  \"tdd_green\": {...},\n  \"standards_verified\": true,\n  \"standards_compliance_iterations\": [final count - e.g., 1, 2, or 3],\n  \"standards_coverage\": {\n    \"total_sections\": [N - from final successful verification],\n    \"compliant\": [N - sections with ],\n    \"not_applicable\": [N - sections with N/A],\n    \"non_compliant\": 0\n  }\n}\n```\n\n**Note:** `non_compliant` MUST be 0 when gate passes. If non-zero after 3 iterations, gate is BLOCKED.\n\n5. **Display to user:**\n   ```text\n   \n     GATE 0 COMPLETE                              \n   \n    TDD-RED:   [test_file] - FAIL captured        \n    TDD-GREEN: [impl_file] - PASS verified        \n    STANDARDS: [N]/[N] sections compliant         \n    ITERATIONS: [standards_compliance_iterations]   \n                                                    \n    Proceeding to Gate 1 (DevOps)...               \n   \n   ```\n\n6. ** SAVE STATE TO FILE (MANDATORY):**\n   ```yaml\n   Write tool:\n     file_path: [state.state_path]  # \"docs/dev-cycle/current-cycle.json\" or \"docs/dev-refactor/current-cycle.json\"\n     content: [full updated state JSON]\n   ```\n   See \"State Persistence Rule\" section. State MUST be written to file after Gate 0.\n\n7. **Proceed to Gate 1**\n\n### Standards Compliance Anti-Rationalization\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Agent said implementation is complete\" | Agent completion  Standards compliance. Verify table. | **Parse and verify Standards Coverage Table** |\n| \"Table wasn't in agent output\" | Missing table = Incomplete output = Re-dispatch | **Re-dispatch agent to output table** |\n| \"Only 1-2 sections are \" | any  = BLOCKED. Count is irrelevant. | **Re-dispatch to fix all  sections** |\n| \"lib-commons is the main thing\" | all sections are equally required. No prioritization. | **Verify all sections from standards-coverage-table.md** |\n| \"Agent knows the standards\" | Knowledge  implementation. Evidence required. | **Check file:line evidence in table** |\n| \"Standards verification is slow\" | Verification prevents rework. 30 seconds vs hours. | **Always verify before proceeding** |\n\n### TDD Sub-Phase Anti-Rationalization\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Test passes on first run, skip RED\" | Passing test  TDD. Test MUST fail first. | **Delete test, rewrite to fail first** |\n| \"I'll capture failure output later\" | Later = never. Failure output is the gate. | **Capture NOW or cannot proceed** |\n| \"Failure output is in the logs somewhere\" | \"Somewhere\"  captured. Must be in state. | **Extract and store in tdd_red.failure_output** |\n| \"GREEN passed, RED doesn't matter now\" | RED proves test validity. Skip = invalid test. | **Re-run RED phase, capture failure** |\n| \"Agent already did TDD internally\" | Internal  verified. State must show evidence. | **Agent must output failure explicitly** |\n\n## Step 3: Gate 1 - DevOps (Per Execution Unit)\n\n**REQUIRED SUB-SKILL:** Use dev-devops\n\n###  HARD GATE: Required Artifacts MUST Be Created\n\n**Gate 1 is a BLOCKING gate.** DevOps agent MUST create all required artifacts. If any artifact is missing:\n- You CANNOT proceed to Gate 2\n- You MUST re-dispatch to devops-engineer to create missing artifacts\n- You MUST verify all artifacts exist before proceeding\n\n### Required Artifacts\n\n**See [shared-patterns/standards-coverage-table.md](../skills/shared-patterns/standards-coverage-table.md)  \"devops-engineer  devops.md\" for all required sections.**\n\n**Key artifacts from devops.md:**\n- Containers (Dockerfile + Docker Compose)\n- Makefile Standards (all required commands)\n- Infrastructure as Code (if applicable)\n- Helm charts (if K8s deployment)\n\n### Step 3.1: Prepare Input for dev-devops Skill\n\n```text\nGather from previous gates:\n\ndevops_input = {\n  // REQUIRED - from current execution unit\n  unit_id: state.current_unit.id,\n  \n  // REQUIRED - from Gate 0 context\n  language: state.current_unit.language,  // \"go\" | \"typescript\" | \"python\"\n  service_type: state.current_unit.service_type,  // \"api\" | \"worker\" | \"batch\" | \"cli\"\n  implementation_files: agent_outputs.implementation.files_changed,  // list of files from Gate 0\n  \n  // OPTIONAL - additional context\n  gate0_handoff: agent_outputs.implementation,  // full Gate 0 output\n  new_dependencies: state.current_unit.new_deps || [],  // new deps added in Gate 0\n  new_env_vars: state.current_unit.env_vars || [],  // env vars needed\n  new_services: state.current_unit.services || [],  // postgres, redis, etc.\n  existing_dockerfile: [check if Dockerfile exists],\n  existing_compose: [check if docker-compose.yml exists]\n}\n```\n\n### Step 3.2: Invoke dev-devops Skill\n\n```text\n1. Record gate start timestamp\n\n2. Invoke dev-devops skill with structured input:\n\n   Skill(\"ring:dev-devops\") with input:\n     unit_id: devops_input.unit_id\n     language: devops_input.language\n     service_type: devops_input.service_type\n     implementation_files: devops_input.implementation_files\n     gate0_handoff: devops_input.gate0_handoff\n     new_dependencies: devops_input.new_dependencies\n     new_env_vars: devops_input.new_env_vars\n     new_services: devops_input.new_services\n     existing_dockerfile: devops_input.existing_dockerfile\n     existing_compose: devops_input.existing_compose\n\n   The skill handles:\n   - Dispatching devops-engineer agent\n   - Dockerfile creation/update\n   - docker-compose.yml configuration\n   - .env.example documentation\n   - Verification commands execution\n   - Fix iteration loop (max 3 attempts)\n\n3. Parse skill output for results:\n   \n   Expected output sections:\n   - \"## DevOps Summary\"  status, iterations\n   - \"## Files Changed\"  Dockerfile, docker-compose, .env.example actions\n   - \"## Verification Results\"  build, startup, health checks\n   - \"## Handoff to Next Gate\"  ready_for_sre: YES/no\n   \n   if skill output contains \"Status: PASS\" and \"Ready for Gate 2: YES\":\n      Gate 1 PASSED. Proceed to Step 3.3.\n   \n   if skill output contains \"Status: FAIL\" or \"Ready for Gate 2: no\":\n      Gate 1 BLOCKED.\n      Skill already dispatched fixes to devops-engineer\n      Skill already re-ran verification\n      If \"ESCALATION\" in output: STOP and report to user\n\n4. ** SAVE STATE TO FILE (MANDATORY):**\n   Write tool  [state.state_path]\n```\n\n### Step 3.3: Gate 1 Complete\n\n```text\n5. When dev-devops skill returns PASS:\n   \n   Parse from skill output:\n   - status: extract from \"## DevOps Summary\"\n   - dockerfile_action: extract from \"## Files Changed\" table\n   - compose_action: extract from \"## Files Changed\" table\n   - verification_passed: extract from \"## Verification Results\"\n   \n   - agent_outputs.devops = {\n       skill: \"ring:dev-devops\",\n       output: \"[full skill output]\",\n       artifacts_created: [\"Dockerfile\", \"docker-compose.yml\", \".env.example\"],\n       verification_passed: true,\n       timestamp: \"[ISO timestamp]\",\n       duration_ms: [execution time]\n     }\n\n6. Update state:\n   - gate_progress.devops.status = \"completed\"\n   - gate_progress.devops.artifacts = [list from skill output]\n\n7. Proceed to Gate 2\n```\n\n### Gate 1 Anti-Rationalization Table\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Dockerfile exists, skip other artifacts\" | all artifacts required. 1/4  complete. | **Create all artifacts** |\n| \"docker-compose not needed locally\" | docker-compose is MANDATORY for local dev. | **Create docker-compose.yml** |\n| \"Makefile is optional\" | Makefile is MANDATORY for standardized commands. | **Create Makefile** |\n| \".env.example can be added later\" | .env.example documents required config NOW. | **Create .env.example** |\n| \"Small service doesn't need all this\" | Size is irrelevant. Standards apply uniformly. | **Create all artifacts** |\n\n## Step 4: Gate 2 - SRE (Per Execution Unit)\n\n**REQUIRED SUB-SKILL:** Use `dev-sre`\n\n### Step 4.1: Prepare Input for dev-sre Skill\n\n```text\nGather from previous gates:\n\nsre_input = {\n  // REQUIRED - from current execution unit\n  unit_id: state.current_unit.id,\n  \n  // REQUIRED - from Gate 0 context\n  language: state.current_unit.language,  // \"go\" | \"typescript\" | \"python\"\n  service_type: state.current_unit.service_type,  // \"api\" | \"worker\" | \"batch\" | \"cli\"\n  implementation_agent: agent_outputs.implementation.agent,  // e.g., \"ring:backend-engineer-golang\"\n  implementation_files: agent_outputs.implementation.files_changed,  // list of files from Gate 0\n  \n  // OPTIONAL - additional context\n  external_dependencies: state.current_unit.external_deps || [],  // HTTP clients, gRPC, queues\n  gate0_handoff: agent_outputs.implementation,  // full Gate 0 output\n  gate1_handoff: agent_outputs.devops  // full Gate 1 output\n}\n```\n\n### Step 4.2: Invoke dev-sre Skill\n\n```text\n1. Record gate start timestamp\n\n2. Invoke dev-sre skill with structured input:\n\n   Skill(\"ring:dev-sre\") with input:\n     unit_id: sre_input.unit_id\n     language: sre_input.language\n     service_type: sre_input.service_type\n     implementation_agent: sre_input.implementation_agent\n     implementation_files: sre_input.implementation_files\n     external_dependencies: sre_input.external_dependencies\n     gate0_handoff: sre_input.gate0_handoff\n     gate1_handoff: sre_input.gate1_handoff\n\n   The skill handles:\n   - Dispatching SRE agent for validation\n   - Structured logging validation\n   - Distributed tracing validation\n   - Code instrumentation coverage (90%+ required)\n   - Context propagation validation (InjectHTTPContext/InjectGRPCContext)\n   - Dispatching fixes to implementation agent if needed\n   - Re-validation loop (max 3 iterations)\n\n3. Parse skill output for validation results:\n   \n   Expected output sections:\n   - \"## Validation Result\"  status, iterations, coverage\n   - \"## Instrumentation Coverage\"  table with per-layer coverage\n   - \"## Issues Found\"  list or \"None\"\n   - \"## Handoff to Next Gate\"  ready_for_testing: YES/no\n   \n   if skill output contains \"Status: PASS\" and \"Ready for Gate 3: YES\":\n      Gate 2 PASSED. Proceed to Step 4.3.\n   \n   if skill output contains \"Status: FAIL\" or \"Ready for Gate 3: no\":\n      Gate 2 BLOCKED. \n      Skill already dispatched fixes to implementation agent\n      Skill already re-ran validation\n      If \"ESCALATION\" in output: STOP and report to user\n\n4. ** SAVE STATE TO FILE (MANDATORY):**\n   Write tool  [state.state_path]\n```\n\n### Step 4.3: Gate 2 Complete\n\n```text\n5. When dev-sre skill returns PASS:\n   \n   Parse from skill output:\n   - status: extract from \"## Validation Result\"\n   - instrumentation_coverage: extract percentage from coverage table\n   - iterations: extract from \"Iterations:\" line\n   \n   - agent_outputs.sre = {\n       skill: \"ring:dev-sre\",\n       output: \"[full skill output]\",\n       validation_result: \"PASS\",\n       instrumentation_coverage: \"[X%]\",\n       iterations: [count],\n       timestamp: \"[ISO timestamp]\",\n       duration_ms: [execution time]\n     }\n\n6. Update state:\n   - gate_progress.sre.status = \"completed\"\n   - gate_progress.sre.observability_validated = true\n   - gate_progress.sre.instrumentation_coverage = \"[X%]\"\n\n7. Proceed to Gate 3\n```\n\n### Gate 2 Anti-Rationalization Table\n\nSee [dev-sre/SKILL.md](../dev-sre/SKILL.md) for complete anti-rationalization tables covering:\n- Observability deferral rationalizations\n- Instrumentation coverage rationalizations\n- Context propagation rationalizations\n\n### Gate 2 Pressure Resistance\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Skip SRE validation, we'll add observability later\" | \"Observability is MANDATORY for Gate 2. Invoking dev-sre skill now.\" |\n| \"SRE found issues but let's continue\" | \"Gate 2 is a HARD GATE. dev-sre skill handles fix dispatch and re-validation.\" |\n| \"Instrumentation coverage is low but code works\" | \"90%+ instrumentation coverage is REQUIRED. dev-sre skill will not pass until met.\" |\n\n## Step 5: Gate 3 - Testing (Per Execution Unit)\n\n**REQUIRED SUB-SKILL:** Use `dev-testing`\n\n### Step 5.1: Prepare Input for dev-testing Skill\n\n```text\nGather from previous gates:\n\ntesting_input = {\n  // REQUIRED - from current execution unit\n  unit_id: state.current_unit.id,\n  acceptance_criteria: state.current_unit.acceptance_criteria,  // list of ACs to test\n  implementation_files: agent_outputs.implementation.files_changed,\n  language: state.current_unit.language,  // \"go\" | \"typescript\" | \"python\"\n  \n  // OPTIONAL - additional context\n  coverage_threshold: 85,  // Ring minimum, PROJECT_RULES.md can raise\n  gate0_handoff: agent_outputs.implementation,  // full Gate 0 output\n  existing_tests: [check for existing test files]\n}\n```\n\n### Step 5.2: Invoke dev-testing Skill\n\n```text\n1. Record gate start timestamp\n\n2. Invoke dev-testing skill with structured input:\n\n   Skill(\"ring:dev-testing\") with input:\n     unit_id: testing_input.unit_id\n     acceptance_criteria: testing_input.acceptance_criteria\n     implementation_files: testing_input.implementation_files\n     language: testing_input.language\n     coverage_threshold: testing_input.coverage_threshold\n     gate0_handoff: testing_input.gate0_handoff\n     existing_tests: testing_input.existing_tests\n\n   The skill handles:\n   - Dispatching qa-analyst agent\n   - Test creation following TDD methodology\n   - Coverage measurement and validation (85%+ required)\n   - Traceability matrix (AC  Test mapping)\n   - Dispatching fixes to implementation agent if coverage < threshold\n   - Re-validation loop (max 3 iterations)\n\n3. Parse skill output for results:\n   \n   Expected output sections:\n   - \"## Testing Summary\"  status, iterations\n   - \"## Coverage Report\"  threshold vs actual\n   - \"## Traceability Matrix\"  AC-to-test mapping\n   - \"## Handoff to Next Gate\"  ready_for_review: YES/no\n   \n   if skill output contains \"Status: PASS\" and \"Ready for Gate 4: YES\":\n      Gate 3 PASSED. Proceed to Step 5.3.\n   \n   if skill output contains \"Status: FAIL\" or \"Ready for Gate 4: no\":\n      Gate 3 BLOCKED.\n      Skill already dispatched fixes to implementation agent\n      Skill already re-ran coverage check\n      If \"ESCALATION\" in output: STOP and report to user\n\n4. ** SAVE STATE TO FILE (MANDATORY):**\n   Write tool  [state.state_path]\n```\n\n### Step 5.3: Gate 3 Complete\n\n```text\n5. When dev-testing skill returns PASS:\n   \n   Parse from skill output:\n   - coverage_actual: extract percentage from \"## Coverage Report\"\n   - coverage_threshold: extract from \"## Coverage Report\"\n   - criteria_covered: extract from \"## Traceability Matrix\"\n   - iterations: extract from \"Iterations:\" line\n   \n   - agent_outputs.testing = {\n       skill: \"ring:dev-testing\",\n       output: \"[full skill output]\",\n       verdict: \"PASS\",\n       coverage_actual: [X%],\n       coverage_threshold: [85%],\n       criteria_covered: \"[X/Y]\",\n       iterations: [count],\n       timestamp: \"[ISO timestamp]\",\n       duration_ms: [execution time],\n       failures: [],  // Empty when PASS; see schema below for FAIL\n       uncovered_criteria: []  // Empty when all ACs covered\n     }\n   \n   **If iterations > 1 (tests failed before passing), populate `failures[]`:**\n   ```json\n   failures: [\n     {\n       \"test_name\": \"TestUserCreate_InvalidEmail\",\n       \"test_file\": \"internal/handler/user_test.go\",\n       \"error_type\": \"assertion|panic|timeout|compilation\",\n       \"expected\": \"[expected value]\",\n       \"actual\": \"[actual value]\",\n       \"message\": \"[error message from test output]\",\n       \"stack_trace\": \"[relevant stack trace]\",\n       \"fixed_in_iteration\": [iteration number when fixed]\n     }\n   ]\n   ```\n   \n   **If coverage < 100% of acceptance criteria, populate `uncovered_criteria[]`:**\n   ```json\n   uncovered_criteria: [\n     {\n       \"criterion_id\": \"AC-001\",\n       \"description\": \"User should receive email confirmation\",\n       \"reason\": \"No test found for email sending functionality\"\n     }\n   ]\n   ```\n\n6. Update state:\n   - gate_progress.testing.status = \"completed\"\n   - gate_progress.testing.coverage = [coverage_actual]\n\n7. Proceed to Gate 4\n```\n\n### Gate 3 Thresholds\n\n- **Minimum:** 85% (Ring standard - CANNOT be lowered)\n- **Project-specific:** Can be higher if defined in `docs/PROJECT_RULES.md`\n- **Validation:** Threshold < 85%  Use 85%\n\n### Gate 3 Pressure Resistance\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"84% is close enough\" | \"85% is Ring minimum. dev-testing skill enforces this.\" |\n| \"Skip testing, deadline\" | \"Testing is MANDATORY. dev-testing skill handles iterations.\" |\n| \"Manual testing covers it\" | \"Gate 3 requires executable unit tests. Invoking dev-testing now.\" |\n\n## Step 6: Gate 4 - Review (Per Execution Unit)\n\n**REQUIRED SUB-SKILL:** Use `ring:requesting-code-review`\n\n### Step 6.1: Prepare Input for ring:requesting-code-review Skill\n\n```text\nGather from previous gates:\n\nreview_input = {\n  // REQUIRED - from current execution unit\n  unit_id: state.current_unit.id,\n  base_sha: state.current_unit.base_sha,  // SHA before implementation\n  head_sha: [current HEAD],  // SHA after all gates\n  implementation_summary: state.current_unit.title + requirements,\n  requirements: state.current_unit.acceptance_criteria,\n  \n  // OPTIONAL - additional context\n  implementation_files: agent_outputs.implementation.files_changed,\n  gate0_handoff: agent_outputs.implementation  // full Gate 0 output\n}\n```\n\n### Step 6.2: Invoke ring:requesting-code-review Skill\n\n```text\n1. Record gate start timestamp\n\n2. Invoke ring:requesting-code-review skill with structured input:\n\n   Skill(\"ring:requesting-code-review\") with input:\n     unit_id: review_input.unit_id\n     base_sha: review_input.base_sha\n     head_sha: review_input.head_sha\n     implementation_summary: review_input.implementation_summary\n     requirements: review_input.requirements\n     implementation_files: review_input.implementation_files\n     gate0_handoff: review_input.gate0_handoff\n\n   The skill handles:\n   - Dispatching all 3 reviewers in PARALLEL (single message with 3 Task calls)\n   - Aggregating issues by severity (CRITICAL/HIGH/MEDIUM/LOW/COSMETIC)\n   - Dispatching fixes to implementation agent for blocking issues\n   - Re-running all 3 reviewers after fixes\n   - Iteration tracking (max 3 attempts)\n   - Adding TODO/FIXME comments for non-blocking issues\n\n3. Parse skill output for results:\n   \n   Expected output sections:\n   - \"## Review Summary\"  status, iterations\n   - \"## Issues by Severity\"  counts per severity level\n   - \"## Reviewer Verdicts\"  code-reviewer, business-logic-reviewer, security-reviewer\n   - \"## Handoff to Next Gate\"  ready_for_validation: YES/no\n   \n   if skill output contains \"Status: PASS\" and \"Ready for Gate 5: YES\":\n      Gate 4 PASSED. Proceed to Step 6.3.\n   \n   if skill output contains \"Status: FAIL\" or \"Ready for Gate 5: no\":\n      Gate 4 BLOCKED.\n      Skill already dispatched fixes to implementation agent\n      Skill already re-ran all 3 reviewers\n      If \"ESCALATION\" in output: STOP and report to user\n\n4. ** SAVE STATE TO FILE (MANDATORY):**\n   Write tool  [state.state_path]\n```\n\n### Step 6.3: Gate 4 Complete\n\n```text\n5. When ring:requesting-code-review skill returns PASS:\n   \n   Parse from skill output:\n   - reviewers_passed: extract from \"## Reviewer Verdicts\" (should be \"3/3\")\n   - issues_critical: extract count from \"## Issues by Severity\"\n   - issues_high: extract count from \"## Issues by Severity\"\n   - issues_medium: extract count from \"## Issues by Severity\"\n   - iterations: extract from \"Iterations:\" line\n   \n   - agent_outputs.review = {\n       skill: \"ring:requesting-code-review\",\n       output: \"[full skill output]\",\n       iterations: [count],\n       timestamp: \"[ISO timestamp]\",\n       duration_ms: [execution time],\n       reviewers_passed: \"3/3\",\n       code_reviewer: {\n         verdict: \"PASS\",\n         issues_count: N,\n         issues: []  // Structured issues - see schema below\n       },\n       business_logic_reviewer: {\n         verdict: \"PASS\",\n         issues_count: N,\n         issues: []\n       },\n       security_reviewer: {\n         verdict: \"PASS\",\n         issues_count: N,\n         issues: []\n       }\n     }\n   \n   **Populate `issues[]` for each reviewer with all issues found (even if fixed):**\n   ```json\n   issues: [\n     {\n       \"severity\": \"CRITICAL|HIGH|MEDIUM|LOW|COSMETIC\",\n       \"category\": \"error-handling|security|performance|maintainability|business-logic|...\",\n       \"description\": \"[detailed description of the issue]\",\n       \"file\": \"internal/handler/user.go\",\n       \"line\": 45,\n       \"code_snippet\": \"return err\",\n       \"suggestion\": \"Use fmt.Errorf(\\\"failed to create user: %w\\\", err)\",\n       \"fixed\": true|false,\n       \"fixed_in_iteration\": [iteration number when fixed, null if not fixed]\n     }\n   ]\n   ```\n   \n   **Issue tracking rules:**\n   - all issues found across all iterations MUST be recorded\n   - `fixed: true` + `fixed_in_iteration: N` for issues resolved during review\n   - `fixed: false` + `fixed_in_iteration: null` for LOW/COSMETIC (TODO/FIXME added)\n   - This enables feedback-loop to analyze recurring issue patterns\n\n6. Update state:\n   - gate_progress.review.status = \"completed\"\n   - gate_progress.review.reviewers_passed = \"3/3\"\n\n7. Proceed to Gate 5\n```\n\n### Gate 4 Anti-Rationalization Table\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Only 1 MEDIUM issue, can proceed\" | MEDIUM = MUST FIX. Quantity is irrelevant. | **Fix the issue, re-run all reviewers** |\n| \"Issue is cosmetic, not really MEDIUM\" | Reviewer decided severity. Accept their judgment. | **Fix the issue, re-run all reviewers** |\n| \"Will fix in next sprint\" | Deferred fixes = technical debt = production bugs. | **Fix NOW before Gate 5** |\n| \"User approved, can skip fix\" | User approval  reviewer override. Fixes are mandatory. | **Fix the issue, re-run all reviewers** |\n| \"Same issue keeps appearing, skip it\" | Recurring issue = fix is wrong. Debug properly. | **Root cause analysis, then fix** |\n| \"Only security reviewer found it\" | One reviewer = valid finding. All findings matter. | **Fix the issue, re-run all reviewers** |\n| \"Iteration limit reached, just proceed\" | Limit = escalate, not bypass. Quality is non-negotiable. | **Escalate to user, DO NOT proceed** |\n| \"Tests pass, review issues don't matter\" | Tests  review. Different quality dimensions. | **Fix the issue, re-run all reviewers** |\n\n### Gate 4 Pressure Resistance\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Just skip this MEDIUM issue\" | \"MEDIUM severity issues are blocking by definition. I MUST dispatch a fix to the appropriate agent before proceeding. This protects code quality.\" |\n| \"I'll fix it later, let's continue\" | \"Gate 4 is a HARD GATE. All CRITICAL/HIGH/MEDIUM issues must be resolved NOW. I'm dispatching the fix to [agent] and will re-run reviewers after.\" |\n| \"We're running out of time\" | \"Proceeding with known issues creates larger problems later. The fix dispatch is automated and typically takes 2-5 minutes. Quality gates exist to save time overall.\" |\n| \"Override the gate, I approve\" | \"User approval cannot override reviewer findings. The gate ensures code quality. I'll dispatch the fix now.\" |\n| \"It's just a style issue\" | \"If it's truly cosmetic, reviewers would mark it COSMETIC (non-blocking). MEDIUM means it affects maintainability or correctness. Fixing now.\" |\n\n## Step 7: Gate 5 - Validation (Per Execution Unit)\n\n```text\nFor current execution unit:\n\n1. Record gate start timestamp\n2. Verify acceptance criteria:\n   For each criterion in acceptance_criteria:\n     - Check if implemented\n     - Check if tested\n     - Mark as PASS/FAIL\n\n3. Run final verification:\n   - All tests pass?\n   - No Critical/High/Medium review issues?\n   - All acceptance criteria met?\n\n4. If validation fails:\n   - Log failure reasons\n   - Determine which gate to revisit\n   - Loop back to appropriate gate\n\n5. If validation passes:\n   - Set unit status = \"completed\"\n   - Record gate end timestamp\n   - agent_outputs.validation = {\n       result: \"approved\",\n       timestamp: \"[ISO timestamp]\",\n       criteria_results: [{criterion, status}]\n     }\n   - Proceed to Step 7.1 (Execution Unit Approval)\n```\n\n## Step 7.1: Execution Unit Approval (Conditional)\n\n**Checkpoint depends on `execution_mode`:** `manual_per_subtask`  Execute | `manual_per_task` / `automatic`  Skip\n\n0. **COMMIT CHECK (before checkpoint):**\n   - if `commit_timing == \"per_subtask\"`:\n     - Execute `/commit` command with message: `feat({unit_id}): {unit_title}`\n     - Include all changed files from this subtask\n   - else: Skip commit (will happen at task or cycle end)\n\n1. Set `status = \"paused_for_approval\"`, save state\n2. Present summary: Unit ID, Parent Task, Gates 0-5 status, Criteria X/X, Duration, Files Changed, Commit Status\n3. **AskUserQuestion:** \"Ready to proceed?\" Options: (a) Continue (b) Test First (c) Stop Here\n4. **Handle response:**\n\n| Response | Action |\n|----------|--------|\n| Continue | Set in_progress, move to next unit (or Step 7.2 if last) |\n| Test First | Set `paused_for_testing`, STOP, output resume command |\n| Stop Here | Set `paused`, STOP, output resume command |\n\n## Step 7.2: Task Approval Checkpoint (Conditional)\n\n**Checkpoint depends on `execution_mode`:** `manual_per_subtask` / `manual_per_task`  Execute | `automatic`  Skip\n\n0. **COMMIT CHECK (before task checkpoint):**\n   - if `commit_timing == \"per_task\"`:\n     - Execute `/commit` command with message: `feat({task_id}): {task_title}`\n     - Include all changed files from this task (all subtasks combined)\n   - else if `commit_timing == \"per_subtask\"`: Already committed per subtask\n   - else: Skip commit (will happen at cycle end)\n\n1. Set task `status = \"completed\"`, cycle `status = \"paused_for_task_approval\"`, save state\n2. Present summary: Task ID, Subtasks X/X, Total Duration, Review Iterations, Files Changed, Commit Status\n3. **AskUserQuestion:** \"Task complete. Ready for next?\" Options: (a) Continue (b) Integration Test (c) Stop Here\n4. **Handle response:**\n\n```text\nAfter completing all subtasks of a task:\n\n0. Check execution_mode from state:\n   - If \"automatic\": Still run feedback, then skip to next task\n   - If \"manual_per_subtask\" or \"manual_per_task\": Continue with checkpoint below\n\n1. Set task status = \"completed\"\n\n2. ** MANDATORY: Run dev-feedback-loop skill**\n\n   ```yaml\n   Skill tool:\n     skill: \"ring:dev-feedback-loop\"\n   ```\n\n   **Note:** dev-feedback-loop manages its own TodoWrite tracking internally.\n   \n   The skill will:\n   - Add its own todo item for tracking\n   - Calculate assertiveness score for the task\n   - Dispatch prompt-quality-reviewer agent with agent_outputs from state\n   - Generate improvement suggestions\n   - Write feedback to docs/feedbacks/cycle-{date}/{agent}.md\n   - Mark its todo as completed\n\n   **After feedback-loop completes, update state:**\n   - Set `tasks[current].feedback_loop_completed = true` in state file\n\n   **Anti-Rationalization for Feedback Loop:**\n\n   | Rationalization | Why It's WRONG | Required Action |\n   |-----------------|----------------|-----------------|\n   | \"Task was simple, skip feedback\" | Simple tasks still contribute to patterns | **Execute Skill tool** |\n   | \"Already at 100% score\" | High scores need tracking for replication | **Execute Skill tool** |\n   | \"User approved, feedback unnecessary\" | Approval  process quality metrics | **Execute Skill tool** |\n   | \"No issues found, nothing to report\" | Absence of issues IS data | **Execute Skill tool** |\n   | \"Time pressure, skip metrics\" | Metrics take <2 min, prevent future issues | **Execute Skill tool** |\n\n   ** HARD GATE: You CANNOT proceed to step 3 without executing the Skill tool above.**\n\n3. Set cycle status = \"paused_for_task_approval\"\n4. Save state\n\n5. Present task completion summary (with feedback metrics):\n   \n     TASK COMPLETED                                \n   \n    Task: [task_id] - [task_title]                  \n                                                     \n    Subtasks Completed: X/X                         \n       ST-001-01: [title]                          \n       ST-001-02: [title]                          \n       ST-001-03: [title]                          \n                                                     \n    Total Duration: Xh Xm                           \n    Total Review Iterations: N                      \n                                                     \n     \n    FEEDBACK METRICS                                \n     \n                                                     \n    Assertiveness Score: XX% (Rating)               \n                                                     \n    Prompt Quality by Agent:                        \n      backend-engineer-golang: 90% (Excellent)     \n      qa-analyst: 75% (Acceptable)                 \n      code-reviewer: 88% (Good)                    \n                                                     \n    Improvements Suggested: N                       \n    Feedback Location:                              \n      docs/feedbacks/cycle-YYYY-MM-DD/             \n                                                     \n     \n                                                     \n    All Files Changed This Task:                    \n      - file1.go                                    \n      - file2.go                                    \n      - ...                                         \n                                                     \n    Next Task: [next_task_id] - [next_task_title]   \n               Subtasks: N (or \"TDD autonomous\")    \n               or \"No more tasks - cycle complete\"  \n   \n\n6. **ASK FOR EXPLICIT APPROVAL using AskUserQuestion tool:**\n\n   Question: \"Task [task_id] complete. Ready to start the next task?\"\n   Options:\n     a) \"Continue\" - Proceed to next task\n     b) \"Integration Test\" - User wants to test the full task integration\n     c) \"Stop Here\" - Pause cycle\n\n7. Handle user response:\n\n   If \"Continue\":\n     - Set status = \"in_progress\"\n     - Move to next task\n     - Set current_task_index += 1\n     - Set current_subtask_index = 0\n     - Reset to Gate 0\n     - Continue execution\n\n   If \"Integration Test\":\n     - Set status = \"paused_for_integration_testing\"\n     - Save state\n     - Output: \"Cycle paused for integration testing.\n                Test task [task_id] integration and run:\n                /dev-cycle --resume\n                when ready to continue.\"\n     - STOP execution\n\n   If \"Stop Here\":\n     - Set status = \"paused\"\n     - Save state\n     - Output: \"Cycle paused after task [task_id]. Resume with:\n                /dev-cycle --resume\"\n     - STOP execution\n```\n\n**Note:** Tasks without subtasks execute both 7.1 and 7.2 in sequence.\n\n## Step 8: Cycle Completion\n\n0. **FINAL COMMIT CHECK (before completion):**\n   - if `commit_timing == \"at_end\"`:\n     - Execute `/commit` command with message: `feat({cycle_id}): complete dev cycle for {feature_name}`\n     - Include all changed files from the entire cycle\n   - else: Already committed per subtask or per task\n\n1. **Calculate metrics:** total_duration_ms, average gate durations, review iterations, pass/fail ratio\n2. **Update state:** `status = \"completed\"`, `completed_at = timestamp`\n3. **Generate report:** Task | Subtasks | Duration | Review Iterations | Status | Commit Status\n\n4. ** MANDATORY: Run dev-feedback-loop skill for cycle metrics**\n\n   ```yaml\n   Skill tool:\n     skill: \"ring:dev-feedback-loop\"\n   ```\n\n   **Note:** dev-feedback-loop manages its own TodoWrite tracking internally.\n\n   **After feedback-loop completes, update state:**\n   - Set `feedback_loop_completed = true` at cycle level in state file\n\n   ** HARD GATE: Cycle incomplete until feedback-loop executes.**\n\n   | Rationalization | Why It's WRONG | Required Action |\n   |-----------------|----------------|-----------------|\n   | \"Cycle done, feedback is extra\" | Feedback IS part of cycle completion | **Execute Skill tool** |\n   | \"Will run feedback next session\" | Next session = never. Run NOW. | **Execute Skill tool** |\n   | \"All tasks passed, no insights\" | Pass patterns need documentation too | **Execute Skill tool** |\n\n5. **Report:** \"Cycle completed. Tasks X/X, Subtasks Y, Time Xh Xm, Review iterations X\"\n\n## Quick Commands\n\n```bash\n# Full PM workflow then dev execution\n/pre-dev-full my-feature\n/dev-cycle docs/pre-dev/my-feature/\n\n# Simple PM workflow then dev execution\n/pre-dev-feature my-feature\n/dev-cycle docs/pre-dev/my-feature/tasks.md\n\n# Manual task file\n/dev-cycle docs/tasks/sprint-001.md\n\n# Resume interrupted cycle\n/dev-cycle --resume\n```\n\n## Error Recovery\n\n| Type | Condition | Action |\n|------|-----------|--------|\n| **Recoverable** | Network timeout | Retry with exponential backoff |\n| **Recoverable** | Agent failure | Retry once, then pause for user |\n| **Recoverable** | Test flakiness | Re-run tests up to 2 times |\n| **Non-Recoverable** | Missing required files | Stop and report |\n| **Non-Recoverable** | Invalid state file | Must restart (cannot resume) |\n| **Non-Recoverable** | Max review iterations | Pause for user |\n\n**On any error:** Update state  Set status (failed/paused)  Save immediately  Report (what failed, why, how to recover, resume command)\n\n## Execution Report\n\nBase metrics per [shared-patterns/output-execution-report.md](../shared-patterns/output-execution-report.md).\n\n| Metric | Value |\n|--------|-------|\n| Duration | Xh Xm Ys |\n| Tasks Processed | N/M |\n| Current Gate | Gate X - [name] |\n| Review Iterations | N |\n| Result | PASS/FAIL/IN_PROGRESS |\n\n### Gate Timings\n| Gate | Duration | Status |\n|------|----------|--------|\n| Implementation | Xm Ys | in_progress |\n| DevOps | - | pending |\n| SRE | - | pending |\n| Testing | - | pending |\n| Review | - | pending |\n| Validation | - | pending |\n\n### State File Location\n`docs/dev-cycle/current-cycle.json` (feature) or `docs/dev-refactor/current-cycle.json` (refactor)"
              },
              {
                "name": "ring:dev-devops",
                "description": "Gate 1 of the development cycle. Creates/updates Docker configuration,\ndocker-compose setup, and environment variables for local development\nand deployment readiness.\n",
                "path": "dev-team/skills/dev-devops/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-devops",
                  "description": "Gate 1 of the development cycle. Creates/updates Docker configuration,\ndocker-compose setup, and environment variables for local development\nand deployment readiness.\n",
                  "trigger": "- Gate 1 of development cycle\n- Implementation complete from Gate 0\n- Need containerization or environment setup\n",
                  "NOT_skip_when": "- \"Application runs fine locally\"  Docker ensures consistency across environments.\n- \"Docker is overkill\"  Docker is baseline, not overkill.\n- \"We'll containerize before production\"  Containerize NOW or never.\n",
                  "sequence": {
                    "after": [
                      "dev-implementation"
                    ],
                    "before": [
                      "dev-sre"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "dev-implementation",
                      "dev-testing"
                    ]
                  },
                  "input_schema": {
                    "required": [
                      {
                        "name": "unit_id",
                        "type": "string",
                        "description": "Task or subtask identifier"
                      },
                      {
                        "name": "language",
                        "type": "string",
                        "enum": [
                          "go",
                          "typescript",
                          "python"
                        ],
                        "description": "Programming language of the implementation"
                      },
                      {
                        "name": "service_type",
                        "type": "string",
                        "enum": [
                          "api",
                          "worker",
                          "batch",
                          "cli"
                        ],
                        "description": "Type of service being containerized"
                      },
                      {
                        "name": "implementation_files",
                        "type": "array",
                        "items": "string",
                        "description": "List of files from Gate 0 implementation"
                      }
                    ],
                    "optional": [
                      {
                        "name": "gate0_handoff",
                        "type": "object",
                        "description": "Full handoff from Gate 0"
                      },
                      {
                        "name": "new_dependencies",
                        "type": "array",
                        "items": "string",
                        "description": "New dependencies added in Gate 0"
                      },
                      {
                        "name": "new_env_vars",
                        "type": "array",
                        "items": "string",
                        "description": "New environment variables needed"
                      },
                      {
                        "name": "new_services",
                        "type": "array",
                        "items": "string",
                        "description": "New services needed (postgres, redis, etc.)"
                      },
                      {
                        "name": "existing_dockerfile",
                        "type": "boolean",
                        "default": false,
                        "description": "Whether Dockerfile already exists"
                      },
                      {
                        "name": "existing_compose",
                        "type": "boolean",
                        "default": false,
                        "description": "Whether docker-compose.yml already exists"
                      }
                    ]
                  },
                  "output_schema": {
                    "format": "markdown",
                    "required_sections": [
                      {
                        "name": "DevOps Summary",
                        "pattern": "^## DevOps Summary",
                        "required": true
                      },
                      {
                        "name": "Files Changed",
                        "pattern": "^## Files Changed",
                        "required": true
                      },
                      {
                        "name": "Verification Results",
                        "pattern": "^## Verification Results",
                        "required": true
                      },
                      {
                        "name": "Handoff to Next Gate",
                        "pattern": "^## Handoff to Next Gate",
                        "required": true
                      }
                    ],
                    "metrics": [
                      {
                        "name": "result",
                        "type": "enum",
                        "values": [
                          "PASS",
                          "FAIL",
                          "PARTIAL"
                        ]
                      },
                      {
                        "name": "dockerfile_action",
                        "type": "enum",
                        "values": [
                          "CREATED",
                          "UPDATED",
                          "UNCHANGED"
                        ]
                      },
                      {
                        "name": "compose_action",
                        "type": "enum",
                        "values": [
                          "CREATED",
                          "UPDATED",
                          "UNCHANGED"
                        ]
                      },
                      {
                        "name": "env_example_action",
                        "type": "enum",
                        "values": [
                          "CREATED",
                          "UPDATED",
                          "UNCHANGED"
                        ]
                      },
                      {
                        "name": "services_configured",
                        "type": "integer"
                      },
                      {
                        "name": "verification_passed",
                        "type": "boolean"
                      }
                    ]
                  },
                  "verification": {
                    "automated": [
                      {
                        "command": "docker-compose build",
                        "description": "Docker images build successfully",
                        "success_pattern": "Successfully built|successfully"
                      },
                      {
                        "command": "docker-compose up -d && sleep 10 && docker-compose ps",
                        "description": "All services start and are healthy",
                        "success_pattern": "Up|running|healthy"
                      },
                      {
                        "command": "docker-compose logs app | head -5 | jq -e '.level'",
                        "description": "Structured JSON logging works",
                        "success_pattern": "info|debug|warn|error"
                      }
                    ],
                    "manual": [
                      "Verify docker-compose ps shows all services as 'Up (healthy)'",
                      "Verify .env.example documents all required environment variables"
                    ]
                  },
                  "examples": [
                    {
                      "name": "New Go service",
                      "input": {
                        "unit_id": "task-001",
                        "language": "go",
                        "service_type": "api",
                        "implementation_files": [
                          "cmd/api/main.go",
                          "internal/handler/user.go"
                        ],
                        "new_services": [
                          "postgres",
                          "redis"
                        ]
                      },
                      "expected_output": "## DevOps Summary\n**Status:** PASS\n\n## Files Changed\n| File | Action |\n|------|--------|\n| Dockerfile | Created |\n| docker-compose.yml | Created |\n| .env.example | Created |\n\n## Verification Results\n| Check | Status |\n|-------|--------|\n| Build |  PASS |\n| Services Start |  PASS |\n| Health Checks |  PASS |\n\n## Handoff to Next Gate\n- Ready for Gate 2: YES\n"
                    }
                  ]
                },
                "content": "# DevOps Setup (Gate 1)\n\n## Overview\n\nThis skill configures the development and deployment infrastructure:\n- Creates or updates Dockerfile for the application\n- Configures docker-compose.yml for local development\n- Documents environment variables in .env.example\n- Verifies the containerized application works\n\n## CRITICAL: Role Clarification\n\n**This skill ORCHESTRATES. DevOps Agent IMPLEMENTS.**\n\n| Who | Responsibility |\n|-----|----------------|\n| **This Skill** | Gather requirements, prepare prompts, validate outputs |\n| **DevOps Agent** | Create Dockerfile, docker-compose, .env.example, verify |\n\n---\n\n## Step 1: Validate Input\n\n<verify_before_proceed>\n- unit_id exists\n- language is valid (go|typescript|python)\n- service_type is valid (api|worker|batch|cli)\n- implementation_files is not empty\n</verify_before_proceed>\n\n```text\nREQUIRED INPUT (from dev-cycle orchestrator):\n- unit_id: [task/subtask being containerized]\n- language: [go|typescript|python]\n- service_type: [api|worker|batch|cli]\n- implementation_files: [files from Gate 0]\n\nOPTIONAL INPUT:\n- gate0_handoff: [full Gate 0 output]\n- new_dependencies: [deps added in Gate 0]\n- new_env_vars: [env vars needed]\n- new_services: [postgres, redis, etc.]\n- existing_dockerfile: [true/false]\n- existing_compose: [true/false]\n\nif any REQUIRED input is missing:\n   STOP and report: \"Missing required input: [field]\"\n   Return to orchestrator with error\n```\n\n## Step 2: Analyze DevOps Requirements\n\n```text\n1. Check existing files:\n   - Dockerfile: [EXISTS/MISSING]\n   - docker-compose.yml: [EXISTS/MISSING]\n   - .env.example: [EXISTS/MISSING]\n\n2. Determine actions needed:\n   - Dockerfile: CREATE / UPDATE / NONE\n   - docker-compose.yml: CREATE / UPDATE / NONE\n   - .env.example: CREATE / UPDATE / NONE\n\n3. Identify services needed:\n   - From new_services input\n   - From language (Go  alpine base, TS  node base)\n   - From service_type (api  expose port, worker  no port)\n```\n\n## Step 3: Initialize DevOps State\n\n```text\ndevops_state = {\n  unit_id: [from input],\n  dockerfile_action: \"pending\",\n  compose_action: \"pending\",\n  env_action: \"pending\",\n  services: [],\n  verification: {\n    build: null,\n    startup: null,\n    health: null\n  },\n  iterations: 0,\n  max_iterations: 3\n}\n```\n\n## Step 4: Dispatch DevOps Agent\n\n<dispatch_required agent=\"ring:devops-engineer\" model=\"opus\">\nCreate/update Dockerfile, docker-compose.yml, and .env.example for containerization.\n</dispatch_required>\n\n```yaml\nTask:\n  subagent_type: \"ring:devops-engineer\"\n  model: \"opus\"\n  description: \"Create/update DevOps artifacts for [unit_id]\"\n  prompt: |\n     MANDATORY: Create all DevOps Artifacts\n\n    ## Input Context\n    - **Unit ID:** [unit_id]\n    - **Language:** [language]\n    - **Service Type:** [service_type]\n    - **Implementation Files:** [implementation_files]\n    - **New Dependencies:** [new_dependencies or \"None\"]\n    - **New Environment Variables:** [new_env_vars or \"None\"]\n    - **New Services Needed:** [new_services or \"None\"]\n\n    ## Existing Files\n    - Dockerfile: [EXISTS/MISSING]\n    - docker-compose.yml: [EXISTS/MISSING]\n    - .env.example: [EXISTS/MISSING]\n\n    ## Standards Reference\n    WebFetch: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/devops.md\n\n    You MUST implement all sections from devops.md.\n\n    ## Requirements\n\n    ### Dockerfile\n    - Multi-stage build (builder  production)\n    - Non-root USER (appuser)\n    - Specific versions (no :latest)\n    - HEALTHCHECK instruction\n    - Layer caching optimization\n\n    ### docker-compose.yml\n    - Version: 3.8\n    - App service with build context\n    - Database/cache services as needed\n    - Named volumes for persistence\n    - Health checks with depends_on conditions\n    - Network: app-network (bridge)\n\n    ### .env.example\n    - all variables with placeholders\n    - Comments explaining each\n    - Grouped by service\n    - Required vs optional marked\n\n    ## Required Output Format\n\n    ### Standards Coverage Table\n    | # | Section (from devops.md) | Status | Evidence |\n    |---|--------------------------|--------|----------|\n    | 1 | Containers | / | Dockerfile:[line] |\n    | 2 | Docker Compose | / | docker-compose.yml:[line] |\n    | 3 | Environment | / | .env.example:[line] |\n    | 4 | Health Checks | / | [file:line] |\n\n    ### Files Created/Updated\n    | File | Action | Key Changes |\n    |------|--------|-------------|\n    | Dockerfile | Created/Updated | [summary] |\n    | docker-compose.yml | Created/Updated | [summary] |\n    | .env.example | Created/Updated | [summary] |\n\n    ### Verification Commands\n\n    <verify_before_proceed>\n    - docker-compose build succeeds\n    - docker-compose up -d starts all services\n    - docker-compose ps shows healthy status\n    - docker-compose logs shows JSON format\n    </verify_before_proceed>\n\n    Execute these and report results:\n    1. `docker-compose build`  [PASS/FAIL]\n    2. `docker-compose up -d`  [PASS/FAIL]\n    3. `docker-compose ps`  [all healthy?]\n    4. `docker-compose logs app | head -5`  [JSON logs?]\n\n    ### Compliance Summary\n    - **all STANDARDS MET:**  YES /  no\n    - **If no, what's missing:** [list sections]\n```\n\n## Step 5: Validate Agent Output\n\n```text\nParse agent output:\n\n1. Extract Standards Coverage Table\n2. Extract Files Created/Updated\n3. Extract Verification results\n\nif \"all STANDARDS MET:  YES\" and all verifications PASS:\n   devops_state.dockerfile_action = [from table]\n   devops_state.compose_action = [from table]\n   devops_state.env_action = [from table]\n   devops_state.verification = {build: PASS, startup: PASS, health: PASS}\n   Proceed to Step 7\n\nif any section has  or any verification FAIL:\n   devops_state.iterations += 1\n   if iterations >= max_iterations: Go to Step 8 (Escalate)\n   Re-dispatch agent with specific failures\n```\n\n## Step 6: Re-Dispatch for Fixes (if needed)\n\n```yaml\nTask:\n  subagent_type: \"ring:devops-engineer\"\n  model: \"opus\"\n  description: \"Fix DevOps issues for [unit_id]\"\n  prompt: |\n     FIX REQUIRED - DevOps Standards Not Met\n\n    ## Issues Found\n    [list  sections and FAIL verifications]\n\n    ## Standards Reference\n    WebFetch: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/devops.md\n\n    Fix all issues and re-run verification commands.\n    Return updated Standards Coverage Table with all .\n```\n\nAfter fix  Go back to Step 5\n\n## Step 7: Prepare Success Output\n\n```text\nGenerate skill output:\n\n## DevOps Summary\n**Status:** PASS\n**Unit ID:** [unit_id]\n**Iterations:** [devops_state.iterations]\n\n## Files Changed\n| File | Action | Summary |\n|------|--------|---------|\n| Dockerfile | [CREATED/UPDATED/UNCHANGED] | [summary] |\n| docker-compose.yml | [CREATED/UPDATED/UNCHANGED] | [summary] |\n| .env.example | [CREATED/UPDATED/UNCHANGED] | [summary] |\n\n## Services Configured\n| Service | Image | Port | Health Check |\n|---------|-------|------|--------------|\n| app | [built] | [port] | [healthcheck] |\n| [db] | [image] | [port] | [healthcheck] |\n| [cache] | [image] | [port] | [healthcheck] |\n\n## Verification Results\n| Check | Status | Output |\n|-------|--------|--------|\n| Build |  PASS | Successfully built |\n| Startup |  PASS | All services Up |\n| Health |  PASS | All healthy |\n| Logging |  PASS | JSON structured |\n\n## Handoff to Next Gate\n- DevOps status: COMPLETE\n- Services: [list]\n- Env vars: [count] documented\n- Verification: all PASS\n- Ready for Gate 2 (SRE): YES\n```\n\n## Step 8: Escalate - Max Iterations Reached\n\n```text\nGenerate skill output:\n\n## DevOps Summary\n**Status:** FAIL\n**Unit ID:** [unit_id]\n**Iterations:** [max_iterations] (MAX REACHED)\n\n## Files Changed\n[list what was created/updated]\n\n## Issues Remaining\n[list unresolved issues]\n\n## Verification Results\n[list PASS/FAIL for each check]\n\n## Handoff to Next Gate\n- DevOps status: FAILED\n- Ready for Gate 2: no\n- **Action Required:** User must manually resolve issues\n\n ESCALATION: Max iterations (3) reached. User intervention required.\n```\n\n---\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Skip Docker, runs fine locally\" | \"Docker ensures consistency. Dispatching devops-engineer now.\" |\n| \"Demo tomorrow, no time\" | \"Docker takes 30 min. Better than environment crash during demo.\" |\n| \"We'll containerize later\" | \"Later = never. Containerizing now.\" |\n\n---\n\n## Anti-Rationalization Table\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations.\n\n### Gate 1-Specific Anti-Rationalizations\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Works fine locally\" | Your machine  production | **Containerize for consistency** |\n| \"Docker is overkill\" | Docker is baseline, not overkill | **Create Dockerfile** |\n| \"Just need docker run\" | docker-compose is reproducible | **Use docker-compose** |\n| \"Lambda doesn't need Docker\" | SAM uses Docker locally | **Use SAM containers** |\n\n---\n\n## Execution Report Format\n\n```markdown\n## DevOps Summary\n**Status:** [PASS|FAIL|PARTIAL]\n**Unit ID:** [unit_id]\n**Duration:** [Xm Ys]\n**Iterations:** [N]\n\n## Files Changed\n| File | Action |\n|------|--------|\n| Dockerfile | [CREATED/UPDATED/UNCHANGED] |\n| docker-compose.yml | [CREATED/UPDATED/UNCHANGED] |\n| .env.example | [CREATED/UPDATED/UNCHANGED] |\n\n## Services Configured\n| Service | Image | Port |\n|---------|-------|------|\n| [name] | [image] | [port] |\n\n## Verification Results\n| Check | Status |\n|-------|--------|\n| Build | / |\n| Startup | / |\n| Health | / |\n| Logging | / |\n\n## Handoff to Next Gate\n- DevOps status: [COMPLETE|PARTIAL|FAILED]\n- Ready for Gate 2: [YES|no]\n```"
              },
              {
                "name": "ring:dev-feedback-loop",
                "description": "Development cycle feedback system - calculates assertiveness scores, analyzes prompt\nquality for all agents executed, aggregates cycle metrics, performs root cause analysis\non failures, and generates improvement reports to docs/feedbacks/cycle-{date}/.\n",
                "path": "dev-team/skills/dev-feedback-loop/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-feedback-loop",
                  "description": "Development cycle feedback system - calculates assertiveness scores, analyzes prompt\nquality for all agents executed, aggregates cycle metrics, performs root cause analysis\non failures, and generates improvement reports to docs/feedbacks/cycle-{date}/.\n",
                  "trigger": "- After task completion (any gate outcome)\n- After validation approval or rejection\n- At end of development cycle\n- When assertiveness drops below threshold\n",
                  "skip_when": "- Task still in progress -> wait for completion\n- Feedback already recorded for this task -> proceed\n",
                  "NOT_skip_when": "- \"Exploratory/spike work\"  all work produces learnings. Track metrics for spikes too.\n- \"Just experimenting\"  Experiments need metrics to measure success. No exceptions.\n",
                  "sequence": {
                    "after": [
                      "dev-validation"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "dev-cycle",
                      "dev-validation"
                    ]
                  }
                },
                "content": "# Dev Feedback Loop\n\n## Overview\n\nSee [CLAUDE.md](https://raw.githubusercontent.com/LerianStudio/ring/main/CLAUDE.md) for canonical validation and gate requirements. This skill collects metrics and generates improvement reports.\n\nContinuous improvement system that tracks development cycle effectiveness through assertiveness scores, identifies recurring failure patterns, and generates actionable improvement suggestions.\n\n**Core principle:** What gets measured gets improved. Track every gate transition to identify systemic issues.\n\n## Step 0: TodoWrite Tracking (MANDATORY FIRST ACTION)\n\n<cannot_skip>\n- MUST add feedback-loop to todo list before any other action\n- MUST execute TodoWrite IMMEDIATELY when skill starts\n- CANNOT proceed to Step 1 without TodoWrite execution\n</cannot_skip>\n\n** HARD GATE: Before any other action, you MUST add feedback-loop to todo list.**\n\n**Execute this TodoWrite call IMMEDIATELY when this skill starts:**\n\n```yaml\nTodoWrite tool:\n  todos:\n    - id: \"feedback-loop-execution\"\n      content: \"Execute dev-feedback-loop: collect metrics, calculate scores, write report\"\n      status: \"in_progress\"\n      priority: \"high\"\n```\n\n**Why this is mandatory:**\n- TodoWrite creates visible tracking of feedback-loop execution\n- Prevents skill from being \"forgotten\" mid-execution\n- Creates audit trail that feedback was collected\n- Hook enforcer checks for this todo item\n\n**After completing all feedback-loop steps, mark as completed:**\n\n```yaml\nTodoWrite tool:\n  todos:\n    - id: \"feedback-loop-execution\"\n      content: \"Execute dev-feedback-loop: collect metrics, calculate scores, write report\"\n      status: \"completed\"\n      priority: \"high\"\n```\n\n**Anti-Rationalization:**\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"TodoWrite slows things down\" | 1 tool call = 2 seconds. Not an excuse. | **Execute TodoWrite NOW** |\n| \"I'll remember to complete it\" | Memory is unreliable. Todo is proof. | **Execute TodoWrite NOW** |\n| \"Skill is simple, no tracking needed\" | Simple  optional. all skills get tracked. | **Execute TodoWrite NOW** |\n\n**You CANNOT proceed to Step 1 without executing TodoWrite above.**\n\n---\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n**Feedback-specific note:** Feedback MUST be collected for every completed task, regardless of outcome or complexity. \"Simple tasks\" and \"perfect scores\" still need tracking.\n\n## Common Rationalizations - REJECTED\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations.\n\n**Feedback-specific rationalizations:**\n\n| Excuse | Reality |\n|--------|---------|\n| \"It was just a spike/experiment\" | Spikes produce learnings. Track what worked and what didn't. |\n| \"Perfect score, no insights\" | Perfect scores reveal what works. Document for replication. |\n| \"Reporting my own failures reflects badly\" | Unreported failures compound. Self-reporting is professional. |\n| \"Round up to passing threshold\" | Rounding is falsification. Report exact score. |\n\n## Red Flags - STOP\n\nSee [shared-patterns/shared-red-flags.md](../shared-patterns/shared-red-flags.md) for universal red flags.\n\nIf you catch yourself thinking any of those patterns, STOP immediately. Collect metrics for every task.\n\n---\n\n## Self-Preservation Bias Prevention\n\n**Agents must report accurately, even when scores are low:**\n\n| Bias Pattern | Why It's Wrong | Correct Behavior |\n|-------------|----------------|------------------|\n| \"Round up score\" | Falsifies data, masks trends | Report exact: 68, not 70 |\n| \"Skip failed task\" | Selection bias, incomplete picture | Report all tasks |\n| \"Blame external factors\" | Avoids actionable insights | Document factors + still log score |\n| \"Report only successes\" | Survivorship bias | Success and failure needed |\n\n**Reporting protocol:**\n1. Calculate score using exact formula (no rounding)\n2. Report score regardless of value\n3. If score < 70, mandatory root cause analysis\n4. Document honestly - \"I made this mistake\" not \"mistake was made\"\n5. Patterns in low scores = improvement opportunities, not blame\n\n**Self-interest check:** If you're tempted to adjust a score, ask: \"Would I report this score if someone else achieved it?\" If yes, report as-is.\n\n## Mandatory Feedback Collection\n\n<cannot_skip>\n- Feedback collection for EVERY completed task\n- No exemptions for task complexity, outcome, or time pressure\n- \"Nothing to report\" is still data that must be recorded\n</cannot_skip>\n\n**Non-negotiable:** Feedback MUST be collected for every completed task, regardless of:\n\n| Factor | Still Collect? | Reason |\n|--------|---------------|--------|\n| Task complexity |  YES | Simple tasks reveal patterns |\n| Outcome quality |  YES | 100-score tasks need tracking |\n| User satisfaction |  YES | Approval  process quality |\n| Time pressure |  YES | Metrics take <5 min |\n| \"Nothing to report\" |  YES | Absence of issues is data |\n\n**Consequence:** Skipping feedback breaks continuous improvement loop and masks systemic issues.\n\n---\n\n## Repeated Feedback Detection\n\n**When the same feedback appears multiple times:**\n\n| Repetition | Classification | Action |\n|------------|----------------|--------|\n| 2nd occurrence | RECURRING | Flag as recurring issue. Add to patterns. |\n| 3rd occurrence | UNRESOLVED | Escalate. Stop current work. Report blocker. |\n\n**Recurring feedback indicates systemic issue not being addressed.**\n\n**Escalation format:**\n```markdown\n## RECURRING ISSUE - Escalation Required\n\n**Issue:** [Description]\n**Occurrences:** [Count] times across [N] tasks\n**Pattern:** [What triggers this issue]\n**Previous Responses:** [What was tried]\n\n**Recommendation:** [Systemic fix needed]\n**Awaiting:** User decision on root cause resolution\n```\n\n---\n\n## Threshold Alerts - MANDATORY RESPONSE\n\n<block_condition>\n- Task score < 70  Root cause analysis required\n- Gate iterations > 3  STOP, request human intervention\n- Cycle average < 80  Deep analysis required\n</block_condition>\n\n**When thresholds are breached, response is REQUIRED:**\n\n| Alert | Threshold | Required Action |\n|-------|-----------|-----------------|\n| Task score | < 70 | Document what went wrong. Identify root cause. |\n| Gate iterations | > 3 | STOP. Request human intervention. Document blocker. |\n| Cycle average | < 80 | Deep analysis required. Pattern identification mandatory. |\n\n**You CANNOT proceed past threshold without documented response.**\n\n## Blocker Criteria - STOP and Report\n\n**always pause and report blocker for:**\n\n| Decision Type | Examples | Action |\n|--------------|----------|--------|\n| **Score interpretation** | \"Is 65 acceptable?\" | STOP. Follow interpretation table. |\n| **Threshold override** | \"Skip analysis for this task\" | STOP. Analysis is MANDATORY for low scores. |\n| **Pattern judgment** | \"Is this pattern significant?\" | STOP. Document pattern, let user decide significance. |\n| **Improvement priority** | \"Which fix first?\" | STOP. Report all findings, let user prioritize. |\n\n**Before skipping any feedback collection:**\n1. Check if task is complete (feedback required for all completed tasks)\n2. Check threshold status (alerts are mandatory)\n3. If in doubt  STOP and report blocker\n\n**You CANNOT skip feedback collection. Period.**\n\n---\n\n## Assertiveness Score Calculation\n\nBase score of 100 points, with deductions for inefficiencies:\n\n### Penalty Matrix\n\n| Event | Penalty | Max Penalty | Rationale |\n|-------|---------|-------------|-----------|\n| Extra iteration (beyond 1) | -10 per iteration | -30 | Each iteration = rework |\n| Review FAIL verdict | -20 | -20 | Critical/High issues found |\n| Review NEEDS_DISCUSSION | -10 | -10 | Uncertainty in implementation |\n| Unmet criterion at validation | -10 per criterion | -40 | Requirements gap |\n| User REJECTED validation | -100 (score = 0) | -100 | Complete failure |\n\n### Score Calculation Formula\n\n`score = 100 - min(30, extra_iterations*10) - review_fail*20 - needs_discussion*10 - min(40, unmet_criteria*10)` | User rejected  score = 0\n\n### Score Interpretation\n\n| Score Range | Rating | Action Required |\n|-------------|--------|-----------------|\n| 90-100 | Excellent | No action needed |\n| 80-89 | Good | Minor improvements possible |\n| 70-79 | Acceptable | Review patterns, optimize |\n| 60-69 | Needs Improvement | Root cause analysis required |\n| < 60 | Poor | Mandatory deep analysis |\n| 0 | Failed | Full post-mortem required |\n\n## Step 1: Collect Cycle Metrics\n\n**MANDATORY: Execute this step for all tasks, regardless of:**\n- Score value (even 100%)\n- User satisfaction (even immediate approval)\n- Outcome quality (even perfect)\n\n**Anti-exemption check:**\nIf you're thinking \"perfect outcome, skip metrics\"  STOP. This is Red Flag at line 75 (\"Perfect outcome, skip the metrics\").\n\n**After task completion, gather from `agent_outputs` in state file:**\n\n### Structured Data Fields (NEW)\n\nThe state file now contains structured error/issue data for direct analysis:\n\n| Gate | Structured Fields | Use For |\n|------|-------------------|---------|\n| Gate 0 | `implementation.standards_compliance`, `implementation.iterations` | Implementation standards patterns |\n| Gate 1 | `devops.standards_compliance`, `devops.verification_errors[]` | DevOps standards + build/deploy failures |\n| Gate 2 | `sre.standards_compliance`, `sre.validation_errors[]` | SRE standards + observability gaps |\n| Gate 3 | `testing.standards_compliance`, `testing.failures[]`, `testing.uncovered_criteria[]` | Testing standards + test failures + coverage |\n| Gate 4 | `review.{reviewer}.standards_compliance`, `review.{reviewer}.issues[]` | Review standards + issues by category/severity |\n\n**All gates have `standards_compliance` with:**\n- `total_sections`, `compliant`, `not_applicable`, `non_compliant`\n- `gaps[]` - array of non-compliant sections with details\n\n### Reading Structured Data\n\n```yaml\n# From state file, extract standards compliance from all gates:\nall_standards_gaps = [\n  ...agent_outputs.implementation.standards_compliance.gaps,\n  ...agent_outputs.devops.standards_compliance.gaps,\n  ...agent_outputs.sre.standards_compliance.gaps,\n  ...agent_outputs.testing.standards_compliance.gaps,\n  ...agent_outputs.review.code_reviewer.standards_compliance.gaps,\n  ...agent_outputs.review.business_logic_reviewer.standards_compliance.gaps,\n  ...agent_outputs.review.security_reviewer.standards_compliance.gaps\n]\n\n# Gate-specific errors/issues:\ndevops_errors = agent_outputs.devops.verification_errors\nsre_errors = agent_outputs.sre.validation_errors\ntest_failures = agent_outputs.testing.failures\nuncovered_acs = agent_outputs.testing.uncovered_criteria\nreview_issues = [\n  ...agent_outputs.review.code_reviewer.issues,\n  ...agent_outputs.review.business_logic_reviewer.issues,\n  ...agent_outputs.review.security_reviewer.issues\n]\n\n# Aggregate standards compliance metrics:\ntotal_standards_sections = sum(all_gates.standards_compliance.total_sections)\ntotal_compliant = sum(all_gates.standards_compliance.compliant)\noverall_compliance_rate = total_compliant / total_standards_sections * 100\n```\n\n### Iteration Penalty Calculation\n\n```yaml\n# Total extra iterations across all gates:\nextra_iterations = (\n  max(0, implementation.iterations - 1) +\n  max(0, devops.iterations - 1) +\n  max(0, sre.iterations - 1) +\n  max(0, testing.iterations - 1) +\n  max(0, review.iterations - 1)\n)\n```\n\n## Step 2: Calculate Assertiveness Score\n\n**Apply formula:** Base 100 - deductions (extra iterations, review failures, unmet criteria) = Final Score / 100. Map to rating per interpretation table.\n\n## Step 3: Analyze Prompt Quality (Agents Only)\n\nAfter calculating assertiveness, analyze prompt quality for all **agents** that executed in the task.\n\n### 3.1 Load Agent Outputs\n\nRead `agent_outputs` from state file (`docs/dev-cycle/current-cycle.json` or `docs/dev-refactor/current-cycle.json`):\n\n```text\nAgents to analyze (if executed, not null):\n  - implementation: backend-engineer-golang | backend-engineer-typescript\n  - devops: devops-engineer\n  - sre: sre\n  - testing: qa-analyst\n  - review: code-reviewer, business-logic-reviewer, security-reviewer\n```\n\n### 3.2 Dispatch Prompt Quality Reviewer\n\n<dispatch_required agent=\"prompt-quality-reviewer\" model=\"opus\">\nAnalyze prompt quality for all agents executed in this task.\n</dispatch_required>\n\n```text\nTask tool:\n  subagent_type: \"ring:prompt-quality-reviewer\"\n  prompt: |\n    Analyze prompt quality for agents in task [task_id].\n\n    Agent outputs from state:\n    [agent_outputs]\n\n    For each agent:\n    1. Load definition from dev-team/agents/ or default/agents/\n    2. Extract rules: MUST, MUST not, ask_when, output_schema\n    3. Compare output vs rules\n    4. Calculate score\n    5. Identify gaps with evidence\n    6. Generate improvements\n\n    Return structured analysis per agent.\n```\n\n### 3.3 Write Feedback Files\n\n**Directory:** `docs/feedbacks/cycle-YYYY-MM-DD/`\n\n**One file per agent**, accumulating all tasks that used that agent.\n\n**File:** `docs/feedbacks/cycle-YYYY-MM-DD/{agent-name}.md`\n\n```markdown\n# Prompt Feedback: {agent-name}\n\n**Cycle:** YYYY-MM-DD\n**Total Executions:** N\n**Average Score:** XX%\n\n---\n\n## Task T-001 (Gate X)\n\n**Score:** XX/100\n**Rating:** {rating}\n\n### Gaps Found\n\n| Category | Rule | Evidence | Impact |\n|----------|------|----------|--------|\n| MUST | [rule text] | [quote from output] | -X |\n\n### What Went Well\n\n- [positive observation]\n\n---\n\n## Task T-002 (Gate X)\n\n**Score:** XX/100\n...\n\n---\n\n## Consolidated Improvements\n\n### Priority 1: [Title]\n\n**Occurrences:** X/Y tasks\n**Impact:** +X points expected\n**File:** dev-team/agents/{agent}.md\n\n**Current text (line ~N):**\n```\n[existing prompt]\n```\n\n**Suggested addition:**\n```markdown\n[new prompt text]\n```\n\n### Priority 2: [Title]\n...\n```\n\n### 3.4 Append to Existing File\n\nIf file already exists (from previous task in same cycle), **append** the new task section before \"## Consolidated Improvements\" and update:\n- Total Executions count\n- Average Score\n- Consolidated Improvements (re-analyze patterns)\n\n## Step 3.5: Pattern Analysis from Structured Data (NEW)\n\n**Analyze structured error/issue data to identify recurring patterns:**\n\n### 3.5.1 Standards Compliance Patterns\n\n```yaml\n# Group gaps by section name\nstandards_gaps_by_section = group(all_implementation_gaps, by: \"section\")\n\n# Identify recurring gaps (same section fails across tasks)\nrecurring_standards_gaps = filter(standards_gaps_by_section, count >= 2)\n\n# Output pattern\nFor each recurring gap:\n  - Section: [section name]\n  - Occurrences: [N] tasks\n  - Common reason: [most frequent reason]\n  - Recommendation: [agent prompt improvement]\n```\n\n### 3.5.2 Review Issue Patterns\n\n```yaml\n# Group review issues by category\nissues_by_category = group(all_review_issues, by: \"category\")\n\n# Group by severity for prioritization\nissues_by_severity = group(all_review_issues, by: \"severity\")\n\n# Identify top recurring categories\ntop_categories = sort(issues_by_category, by: count, descending).take(5)\n\n# Output pattern\nFor each top category:\n  - Category: [category name]\n  - Occurrences: [N] issues across [M] tasks\n  - Severity breakdown: [CRITICAL: X, HIGH: Y, MEDIUM: Z]\n  - Most common: [most frequent description pattern]\n  - Fix rate: [fixed_count / total_count]%\n```\n\n### 3.5.3 Test Failure Patterns\n\n```yaml\n# Group failures by error_type\nfailures_by_type = group(all_test_failures, by: \"error_type\")\n\n# Identify flaky tests (same test fails multiple times)\nflaky_tests = filter(all_test_failures, count_by_test_name >= 2)\n\n# Output pattern\nFor each error type:\n  - Type: [assertion|panic|timeout|compilation]\n  - Occurrences: [N] failures\n  - Fix iterations: avg [X] iterations to fix\n```\n\n### 3.5.4 Cross-Gate Pattern Correlation\n\n```yaml\n# Correlate: Do standards gaps predict review issues?\ncorrelation_standards_review = correlate(\n  implementation.standards_compliance.gaps[].section,\n  review.*.issues[].category\n)\n\n# Output insight\nIf correlation > 0.5:\n  \"Standards gap in [section] correlates with review issues in [category]\"\n   Recommendation: Strengthen agent prompt for [section]\n```\n\n## Step 4: Threshold Alerts\n\n| Alert | Trigger | Action | Report Contents |\n|-------|---------|--------|-----------------|\n| **Score < 70** | Individual task assertiveness < 70 | Mandatory root cause analysis | Failure events, \"5 Whys\" per event, Corrective actions, Prevention measures |\n| **Iterations > 3** | Any gate exceeds 3 iterations | STOP + human intervention | Iteration history, Recurring issue, Options: [Continue/Reassign/Descope/Cancel] |\n| **Avg < 80** | Cycle average below 80 | Deep analysis report | Score distribution, Failure patterns (freq/cause/fix), Improvement plan |\n| **Recurring Pattern** | Same issue category in 3+ tasks | Pattern alert | Category, frequency, suggested prompt fix |\n\n**Report formats:** RCA = Score  Failure Events  5 Whys  Root cause  Corrective action | Gate Blocked = History  Issue  BLOCKED UNTIL human decision | Deep Analysis = Distribution  Patterns  Improvement Plan\n\n## Step 5: Write Feedback Report\n\n**Location:** `.ring/dev-team/feedback/cycle-YYYY-MM-DD.md`\n\n**Required sections:**\n\n| Section | Content |\n|---------|---------|\n| **Header** | Date, Tasks Completed, Average Assertiveness |\n| **Task Summary** | Table: Task ID, Score, Rating, Key Issue |\n| **By Gate** | Table: Gate, Avg Iterations, Avg Duration, Pass Rate |\n| **By Penalty** | Table: Penalty type, Occurrences, Points Lost |\n| **Patterns** | Positive patterns (what works) + Negative patterns (what needs improvement) |\n| **Recommendations** | Immediate (this sprint), Short-term (this month), Long-term (this quarter) |\n| **Next Review** | Date, Target assertiveness, Focus areas |\n\n## Step 6: Generate Improvement Suggestions\n\n**Improvement types based on pattern analysis:**\n\n| Target | When to Suggest | Format |\n|--------|-----------------|--------|\n| **Agents** | Same issue type recurring in reviews | Agent name  Issue  Suggestion  Specific addition to prompt |\n| **Skills** | Gate consistently needs iterations | Skill name  Issue  Suggestion  Specific change to skill |\n| **Process** | Pattern spans multiple tasks | Process area  Issue  Suggestion  Implementation |\n\n## Step 7: Complete TodoWrite Tracking (MANDATORY FINAL ACTION)\n\n** HARD GATE: After all steps complete, you MUST mark feedback-loop todo as completed.**\n\n**Execute this TodoWrite call to finalize:**\n\n```yaml\nTodoWrite tool:\n  todos:\n    - id: \"feedback-loop-execution\"\n      content: \"Execute dev-feedback-loop: collect metrics, calculate scores, write report\"\n      status: \"completed\"\n      priority: \"high\"\n```\n\n**Verification before marking complete:**\n- [ ] Step 1: Metrics collected from state file\n- [ ] Step 2: Assertiveness score calculated\n- [ ] Step 3: Prompt quality analyzed (if agents executed)\n- [ ] Step 4: Threshold alerts checked\n- [ ] Step 5: Feedback report written to `.ring/dev-team/feedback/`\n- [ ] Step 6: Improvement suggestions generated\n\n**You CANNOT mark todo as completed until all steps above are done.**\n\n---\n\n## Execution Report\n\nBase metrics per [shared-patterns/output-execution-report.md](../shared-patterns/output-execution-report.md).\n\n| Metric | Value |\n|--------|-------|\n| Tasks Analyzed | N |\n| Average Assertiveness | XX.X% |\n| Threshold Alerts | X |\n| Root Cause Analyses | Y |\n| Improvement Suggestions | Z |\n| Report Location | .ring/dev-team/feedback/cycle-YYYY-MM-DD.md |\n\n## Anti-Patterns\n\n**Never:**\n- Skip feedback collection for \"simple\" tasks\n- Ignore threshold alerts\n- Accept low scores without analysis\n- Generate suggestions without data\n- Blame individuals instead of process\n\n**Always:**\n- Track every gate transition\n- Calculate score for every task\n- Investigate scores < 70\n- Document root causes\n- Generate actionable improvements\n- Review trends over time\n\n## Feedback Loop Integration\n\n| Integration | Process |\n|-------------|---------|\n| **Retrospectives** | Share metrics  Discuss trends  Prioritize improvements  Assign actions |\n| **Skill Updates** | Document gap  Update skill  Track improvement  Iterate |\n| **Agent Updates** | Identify behavior  Update prompt  Track change  Validate |"
              },
              {
                "name": "ring:dev-implementation",
                "description": "Gate 0 of the development cycle. Executes code implementation using the appropriate\nspecialized agent based on task content and project language. Handles TDD workflow\nwith RED-GREEN phases. Follows project standards defined in docs/PROJECT_RULES.md.\n",
                "path": "dev-team/skills/dev-implementation/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-implementation",
                  "description": "Gate 0 of the development cycle. Executes code implementation using the appropriate\nspecialized agent based on task content and project language. Handles TDD workflow\nwith RED-GREEN phases. Follows project standards defined in docs/PROJECT_RULES.md.\n",
                  "trigger": "- Gate 0 of development cycle\n- Tasks loaded at initialization\n- Ready to write code\n",
                  "NOT_skip_when": "- \"Code already exists\"  DELETE it. TDD is test-first.\n- \"Simple feature\"  Simple  exempt. TDD for all.\n- \"Time pressure\"  TDD saves time. No shortcuts.\n- \"PROJECT_RULES.md doesn't require\"  Ring always requires TDD.\n",
                  "sequence": {
                    "before": [
                      "dev-devops"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "dev-cycle",
                      "test-driven-development",
                      "requesting-code-review"
                    ]
                  },
                  "input_schema": {
                    "required": [
                      {
                        "name": "unit_id",
                        "type": "string",
                        "description": "Task or subtask identifier being implemented"
                      },
                      {
                        "name": "requirements",
                        "type": "string",
                        "description": "Task requirements or acceptance criteria"
                      },
                      {
                        "name": "language",
                        "type": "string",
                        "enum": [
                          "go",
                          "typescript",
                          "python"
                        ],
                        "description": "Programming language for implementation"
                      },
                      {
                        "name": "service_type",
                        "type": "string",
                        "enum": [
                          "api",
                          "worker",
                          "batch",
                          "cli",
                          "frontend",
                          "bff"
                        ],
                        "description": "Type of service being implemented"
                      }
                    ],
                    "optional": [
                      {
                        "name": "technical_design",
                        "type": "string",
                        "description": "Path to technical design document"
                      },
                      {
                        "name": "existing_patterns",
                        "type": "array",
                        "items": "string",
                        "description": "Existing code patterns to follow"
                      },
                      {
                        "name": "project_rules_path",
                        "type": "string",
                        "default": "docs/PROJECT_RULES.md",
                        "description": "Path to project rules file"
                      }
                    ]
                  },
                  "output_schema": {
                    "format": "markdown",
                    "required_sections": [
                      {
                        "name": "Implementation Summary",
                        "pattern": "^## Implementation Summary",
                        "required": true
                      },
                      {
                        "name": "TDD Results",
                        "pattern": "^## TDD Results",
                        "required": true
                      },
                      {
                        "name": "Files Changed",
                        "pattern": "^## Files Changed",
                        "required": true
                      },
                      {
                        "name": "Handoff to Next Gate",
                        "pattern": "^## Handoff to Next Gate",
                        "required": true
                      }
                    ],
                    "metrics": [
                      {
                        "name": "result",
                        "type": "enum",
                        "values": [
                          "PASS",
                          "FAIL",
                          "PARTIAL"
                        ]
                      },
                      {
                        "name": "agent_used",
                        "type": "string"
                      },
                      {
                        "name": "tdd_red_status",
                        "type": "enum",
                        "values": [
                          "completed",
                          "failed"
                        ]
                      },
                      {
                        "name": "tdd_green_status",
                        "type": "enum",
                        "values": [
                          "completed",
                          "failed"
                        ]
                      },
                      {
                        "name": "files_created",
                        "type": "integer"
                      },
                      {
                        "name": "files_modified",
                        "type": "integer"
                      },
                      {
                        "name": "tests_added",
                        "type": "integer"
                      }
                    ]
                  },
                  "agent_selection": {
                    "criteria": [
                      {
                        "pattern": "*.go",
                        "keywords": [
                          "go.mod",
                          "golang",
                          "Go"
                        ],
                        "agent": "backend-engineer-golang"
                      },
                      {
                        "pattern": "*.ts",
                        "keywords": [
                          "express",
                          "fastify",
                          "nestjs",
                          "backend",
                          "api",
                          "server"
                        ],
                        "agent": "backend-engineer-typescript"
                      },
                      {
                        "pattern": "*.tsx",
                        "keywords": [
                          "react",
                          "next",
                          "frontend",
                          "component",
                          "page"
                        ],
                        "agent": "frontend-bff-engineer-typescript"
                      },
                      {
                        "pattern": "*.css|*.scss",
                        "keywords": [
                          "design",
                          "visual",
                          "aesthetic",
                          "styling",
                          "ui"
                        ],
                        "agent": "frontend-designer"
                      }
                    ],
                    "fallback": "ASK_USER"
                  },
                  "verification": {
                    "automated": [
                      {
                        "command": "go build ./... 2>&1 | grep -c 'error'",
                        "description": "Go code compiles",
                        "success_pattern": "^0$"
                      },
                      {
                        "command": "npm run build 2>&1 | grep -c 'error'",
                        "description": "TypeScript compiles",
                        "success_pattern": "^0$"
                      }
                    ],
                    "manual": [
                      "TDD RED phase failure output captured before implementation",
                      "Implementation follows project standards from PROJECT_RULES.md"
                    ]
                  },
                  "examples": [
                    {
                      "name": "Go backend implementation",
                      "input": {
                        "unit_id": "task-001",
                        "requirements": "Add user authentication endpoint with JWT",
                        "language": "go",
                        "service_type": "api"
                      },
                      "expected_output": "## Implementation Summary\n**Status:** PASS\n**Agent:** backend-engineer-golang\n\n## TDD Results\n| Phase | Status | Output |\n|-------|--------|--------|\n| RED |  | FAIL: TestUserAuth - expected token, got nil |\n| GREEN |  | PASS: TestUserAuth (0.003s) |\n\n## Files Changed\n| File | Action | Lines |\n|------|--------|-------|\n| internal/handler/auth.go | Created | +85 |\n| internal/handler/auth_test.go | Created | +120 |\n\n## Handoff to Next Gate\n- Ready for Gate 1: YES\n"
                    }
                  ]
                },
                "content": "# Code Implementation (Gate 0)\n\n## Overview\n\nThis skill executes the implementation phase of the development cycle:\n- Selects the appropriate specialized agent based on task content\n- Applies project standards from docs/PROJECT_RULES.md\n- Follows TDD methodology (RED  GREEN  REFACTOR)\n- Documents implementation decisions\n\n## CRITICAL: Role Clarification\n\n**This skill ORCHESTRATES. Agents IMPLEMENT.**\n\n| Who | Responsibility |\n|-----|----------------|\n| **This Skill** | Select agent, prepare prompts, track state, validate outputs |\n| **Implementation Agent** | Write tests, write code, follow standards |\n\n---\n\n## Step 1: Validate Input\n\n<verify_before_proceed>\n- unit_id exists\n- requirements exists\n- language is valid (go|typescript|python)\n- service_type is valid (api|worker|batch|cli|frontend|bff)\n</verify_before_proceed>\n\n```text\nREQUIRED INPUT (from dev-cycle orchestrator):\n- unit_id: [task/subtask being implemented]\n- requirements: [acceptance criteria or task description]\n- language: [go|typescript|python]\n- service_type: [api|worker|batch|cli|frontend|bff]\n\nOPTIONAL INPUT:\n- technical_design: [path to design doc]\n- existing_patterns: [patterns to follow]\n- project_rules_path: [default: docs/PROJECT_RULES.md]\n\nif any REQUIRED input is missing:\n   STOP and report: \"Missing required input: [field]\"\n   Return to orchestrator with error\n```\n\n## Step 2: Validate Prerequisites\n\n<block_condition>\n- PROJECT_RULES.md does not exist at project_rules_path\n</block_condition>\n\nIf condition is true, STOP and return error to orchestrator.\n\n```text\n1. Check PROJECT_RULES.md exists:\n   Read tool  project_rules_path (default: docs/PROJECT_RULES.md)\n   \n   if not found:\n      STOP with blocker: \"Cannot implement without project standards\"\n      Return error to orchestrator\n\n2. Select implementation agent based on language:\n   \n   | Language | Service Type | Agent |\n   |----------|--------------|-------|\n   | go | api, worker, batch, cli | backend-engineer-golang |\n   | typescript | api, worker | backend-engineer-typescript |\n   | typescript | frontend, bff | frontend-bff-engineer-typescript |\n   \n   Store: selected_agent = [agent name]\n```\n\n## Step 3: Initialize Implementation State\n\n```text\nimplementation_state = {\n  unit_id: [from input],\n  agent: selected_agent,\n  tdd_red: {\n    status: \"pending\",\n    test_file: null,\n    failure_output: null\n  },\n  tdd_green: {\n    status: \"pending\",\n    implementation_files: [],\n    pass_output: null\n  },\n  files_created: [],\n  files_modified: [],\n  commit_sha: null\n}\n```\n\n## Step 4: Gate 0.1 - TDD-RED (Write Failing Test)\n\n<dispatch_required agent=\"[selected_agent]\" model=\"opus\">\nWrite failing test for unit_id following TDD-RED methodology.\n</dispatch_required>\n\n```yaml\nTask:\n  subagent_type: \"[selected_agent]\"  # e.g., \"ring:backend-engineer-golang\"\n  model: \"opus\"\n  description: \"TDD-RED: Write failing test for [unit_id]\"\n  prompt: |\n     TDD-RED PHASE: Write a FAILING Test\n\n    ## Input Context\n    - **Unit ID:** [unit_id]\n    - **Requirements:** [requirements]\n    - **Language:** [language]\n    - **Service Type:** [service_type]\n\n    ## Project Standards\n    Read and follow: [project_rules_path]\n\n    ## Ring Standards Reference\n    For Go: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md\n    For TS: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/typescript.md\n\n    ## Your Task\n    1. Write a test that captures the expected behavior\n    2. The test MUST FAIL (no implementation exists yet)\n    3. Run the test and capture the FAILURE output\n\n    ## Requirements for Test\n    - Follow project naming conventions from PROJECT_RULES.md\n    - Use table-driven tests (Go) or describe/it blocks (TS)\n    - Test the happy path and edge cases\n    - Include meaningful assertion messages\n\n    ## Required Output Format\n\n    ### Test File\n    **Path:** [path/to/test_file]\n    \n    ```[language]\n    [test code]\n    ```\n\n    ### Test Execution\n    **Command:** [test command]\n    **Result:** FAIL (expected)\n\n    ### Failure Output (MANDATORY)\n    ```\n    [paste actual test failure output here]\n    ```\n\n     HARD GATE: You MUST include actual failure output.\n    Without failure output, TDD-RED is not complete.\n```\n\n## Step 5: Validate TDD-RED Output\n\n<block_condition>\n- failure_output is missing\n- failure_output does not contain \"FAIL\"\n</block_condition>\n\nIf any condition is true, re-dispatch agent with clarification.\n\n```text\nParse agent output:\n\n1. Extract test file path\n2. Extract failure output\n\nif failure_output is missing or does not contain \"FAIL\":\n   STOP: \"TDD-RED incomplete - no failure output captured\"\n   Re-dispatch agent with clarification\n\nif failure_output contains \"FAIL\":\n   implementation_state.tdd_red = {\n      status: \"completed\",\n      test_file: [extracted path],\n      failure_output: [extracted output]\n    }\n   Proceed to Step 6\n```\n\n## Step 6: Gate 0.2 - TDD-GREEN (Implementation)\n\n**PREREQUISITE:** `implementation_state.tdd_red.status == \"completed\"`\n\n<dispatch_required agent=\"[selected_agent]\" model=\"opus\">\nImplement code to make test pass following TDD-GREEN methodology.\n</dispatch_required>\n\n```yaml\nTask:\n  subagent_type: \"[selected_agent]\"\n  model: \"opus\"\n  description: \"TDD-GREEN: Implement code to pass test for [unit_id]\"\n  prompt: |\n     TDD-GREEN PHASE: Make the Test PASS\n\n    ## Input Context\n    - **Unit ID:** [unit_id]\n    - **Requirements:** [requirements]\n    - **Language:** [language]\n    - **Service Type:** [service_type]\n\n    ## TDD-RED Results (from previous phase)\n    - **Test File:** [implementation_state.tdd_red.test_file]\n    - **Failure Output:**\n    ```\n    [implementation_state.tdd_red.failure_output]\n    ```\n\n    ## Project Standards\n    Read and follow: [project_rules_path]\n\n    ## Ring Standards Reference\n    For Go: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md\n    For TS: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/typescript.md\n\n    ##  CRITICAL: all Ring Standards Apply (no DEFERRAL)\n    See Ring Standards for mandatory requirements:\n    - Structured JSON logging with trace_id correlation\n    - OpenTelemetry instrumentation (spans in every function)\n    - Error handling (no panic, wrap with context)\n    - Context propagation\n\n    ** HARD GATE:** If you output \"DEFERRED\" for any Ring Standard  Implementation is INCOMPLETE.\n\n    ## Your Task\n    1. Write MINIMAL code to make the test pass\n    2. Follow all Ring Standards (logging, tracing, error handling)\n    3. **Instrument all code with telemetry** (100% of handlers, services, repositories)\n    4. Run the test and capture the PASS output\n\n    ##  MANDATORY: Telemetry Instrumentation (NON-NEGOTIABLE)\n\n    <cannot_skip>\n    - 90%+ instrumentation coverage required\n    - WebFetch standards file before implementation\n    - Follow exact patterns from standards\n    - Output Standards Coverage Table with evidence\n    </cannot_skip>\n\n    **every function that does work MUST be instrumented with telemetry.**\n    This is not optional. This is not \"nice to have\". This is REQUIRED.\n\n    ### What \"Instrumented\" Means\n    1. **Extract logger/tracer from context** (not create new ones)\n    2. **Create a child span** for the operation\n    3. **Defer span.End()** immediately\n    4. **Use structured logging** correlated with trace\n    5. **Handle errors with span attribution** (business vs technical)\n\n    ### Language-Specific Patterns (MANDATORY)\n\n    ** HARD GATE: Agent MUST WebFetch standards file BEFORE writing any code.**\n\n    | Language | Standards File | REQUIRED Sections to WebFetch |\n    |----------|----------------|-------------------------------|\n    | **Go** | `golang.md` | \"Telemetry & Observability (MANDATORY)\", \"Child Spans\", \"Context Propagation\", \"Anti-Patterns\" |\n    | **TypeScript** | `typescript.md` | \"Observability\", \"Telemetry Patterns\", \"Context Propagation\", \"Anti-Patterns\" |\n\n    ** NON-NEGOTIABLE: Agent MUST implement EXACTLY the patterns from standards. no deviations. no shortcuts.**\n\n    | Requirement | Enforcement |\n    |-------------|-------------|\n    | WebFetch standards file | MANDATORY before implementation |\n    | Follow exact patterns | REQUIRED - copy structure from standards |\n    | Output Standards Coverage Table | REQUIRED - with file:line evidence |\n    | 90%+ instrumentation coverage | HARD GATE - implementation REJECTED if below |\n\n    ###  FORBIDDEN Patterns (HARD BLOCK)\n    \n    **Agent MUST WebFetch standards and check Anti-Patterns table. Violations = REJECTED.**\n\n    - **Go:** `golang.md`  \"Anti-Patterns\" table - MUST check all rows\n    - **TypeScript:** `typescript.md`  \"Anti-Patterns\" table - MUST check all rows\n\n    **If agent uses any forbidden pattern  Implementation is INVALID. Start over.**\n\n    ### Verification (MANDATORY)\n    \n    **Agent MUST output Standards Coverage Table per `standards-coverage-table.md`.**\n    \n    - all sections MUST show  or N/A\n    - any  = Implementation REJECTED\n    - Missing table = Implementation INCOMPLETE\n\n    ## Required Output Format\n\n    ### Implementation Files\n    | File | Action | Lines |\n    |------|--------|-------|\n    | [path] | Created/Modified | +/-N |\n\n    ### Code\n    **Path:** [path/to/implementation_file]\n    \n    ```[language]\n    [implementation code]\n    ```\n\n    ### Test Execution\n    **Command:** [test command]\n    **Result:** PASS\n\n    ### Pass Output (MANDATORY)\n    ```\n    [paste actual test pass output here]\n    ```\n\n    ### Standards Compliance\n    - Structured Logging: /\n    - OpenTelemetry Spans: /\n    - Error Handling: /\n    - Context Propagation: /\n\n    ### Commit\n    **SHA:** [commit hash after implementation]\n```\n\n## Step 7: Validate TDD-GREEN Output\n\n```text\nParse agent output:\n\n1. Extract implementation files\n2. Extract pass output\n3. Extract standards compliance\n4. Extract commit SHA\n\nif pass_output is missing or does not contain \"PASS\":\n   STOP: \"TDD-GREEN incomplete - test not passing\"\n   Re-dispatch agent with error details\n\nif any standards compliance is :\n   STOP: \"Standards not met - [list failing standards]\"\n   Re-dispatch agent to fix\n\nif pass_output contains \"PASS\" and all standards :\n   implementation_state.tdd_green = {\n      status: \"completed\",\n      implementation_files: [extracted files],\n      pass_output: [extracted output],\n      commit_sha: [extracted SHA]\n    }\n   Proceed to Step 8\n```\n\n## Step 8: Prepare Output\n\n```text\nGenerate skill output:\n\n## Implementation Summary\n**Status:** PASS\n**Unit ID:** [unit_id]\n**Agent:** [selected_agent]\n**Commit:** [commit_sha]\n\n## TDD Results\n| Phase | Status | Output |\n|-------|--------|--------|\n| RED |  | [first line of failure_output] |\n| GREEN |  | [first line of pass_output] |\n\n## Files Changed\n| File | Action | Lines |\n|------|--------|-------|\n[table from implementation_files]\n\n**Files Created:** [count]\n**Files Modified:** [count]\n**Tests Added:** [count]\n\n## Standards Compliance\n- Structured Logging: \n- OpenTelemetry Spans: \n- Error Handling: \n- Context Propagation: \n\n## Handoff to Next Gate\n- Implementation status: COMPLETE\n- Code compiles: \n- Tests pass: \n- Standards met: \n- Ready for Gate 1 (DevOps): YES\n- Environment needs: [list any new deps, env vars, services]\n```\n\n---\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Skip TDD, just implement\" | \"TDD is MANDATORY. Dispatching agent for RED phase.\" |\n| \"Code exists, just add tests\" | \"DELETE existing code. TDD requires test-first.\" |\n| \"Add observability later\" | \"Observability is part of implementation. Agent MUST add it now.\" |\n\n---\n\n## Anti-Rationalization Table\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations.\n\n### Gate 0-Specific Anti-Rationalizations\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Test passes on first run\" | Passing test  TDD. Test MUST fail first. | **Rewrite test to fail first** |\n| \"Skip RED, go straight to GREEN\" | RED proves test validity | **Execute RED phase first** |\n| \"I'll add observability later\" | Later = never. Observability is part of GREEN. | **Add logging + tracing NOW** |\n| \"Minimal code = no logging\" | Minimal = pass test. Logging is a standard, not extra. | **Include observability** |\n| \"DEFERRED to later tasks\" | DEFERRED = FAILED. Standards are not deferrable. | **Implement all standards NOW** |\n| \"Using raw OTel is fine\" | lib-commons wrappers are MANDATORY for consistency | **Use libCommons.NewTrackingFromContext** |\n| \"c.JSON() works the same\" | Direct Fiber breaks response standardization | **Use libHTTP.OK(), libHTTP.WithError()** |\n| \"This function is too simple for spans\" | Simple  exempt. all functions need spans. | **Add span to every function** |\n| \"Telemetry adds overhead\" | Observability is non-negotiable for production | **Instrument 100% of code paths** |\n\n## Agent Selection Guide\n\n| Language | Service Type | Agent |\n|----------|--------------|-------|\n| Go | API, Worker, Batch, CLI | `backend-engineer-golang` |\n| TypeScript | API, Worker | `backend-engineer-typescript` |\n| TypeScript | Frontend, BFF | `frontend-bff-engineer-typescript` |\n| React/CSS | Design, Styling | `frontend-designer` |\n\n---\n\n## Execution Report Format\n\n```markdown\n## Implementation Summary\n**Status:** [PASS|FAIL|PARTIAL]\n**Unit ID:** [unit_id]\n**Agent:** [agent]\n**Duration:** [Xm Ys]\n\n## TDD Results\n| Phase | Status | Output |\n|-------|--------|--------|\n| RED | / | [summary] |\n| GREEN | / | [summary] |\n\n## Files Changed\n| File | Action | Lines |\n|------|--------|-------|\n| [path] | [Created/Modified] | [+/-N] |\n\n## Standards Compliance\n- Structured Logging: /\n- OpenTelemetry Spans: /\n- Error Handling: /\n- Context Propagation: /\n\n## Handoff to Next Gate\n- Implementation status: [COMPLETE|PARTIAL]\n- Ready for Gate 1: [YES|no]\n- Environment needs: [list]\n```"
              },
              {
                "name": "ring:dev-refactor",
                "description": "Analyzes codebase against standards and generates refactoring tasks for dev-cycle.",
                "path": "dev-team/skills/dev-refactor/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-refactor",
                  "description": "Analyzes codebase against standards and generates refactoring tasks for dev-cycle.",
                  "trigger": "- User wants to refactor existing project to follow standards\n- Legacy codebase needs modernization\n- Project audit requested\n",
                  "skip_when": "- Greenfield project  Use /pre-dev-* instead\n- Single file fix  Use dev-cycle directly\n"
                },
                "content": "# Dev Refactor Skill\n\nAnalyzes existing codebase against Ring/Lerian standards and generates refactoring tasks compatible with dev-cycle.\n\n---\n\n##  MANDATORY GAP PRINCIPLE (NON-NEGOTIABLE)\n\n**any divergence from Ring standards = MANDATORY gap to implement.**\n\n<cannot_skip>\n- All divergences are gaps - Every difference MUST be tracked as FINDING-XXX\n- Severity affects PRIORITY, not TRACKING - Low severity = lower priority, not \"optional\"\n- No filtering allowed - You CANNOT decide which divergences \"matter\"\n- No alternative patterns accepted - Different approach = STILL A GAP\n- No cosmetic exceptions - Naming, formatting, structure differences = GAPS\n</cannot_skip>\n\nNon-negotiable, not open to interpretationa HARD RULE.\n\n### Anti-Rationalization: Mandatory Gap Principle\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for:\n- **Refactor Gap Tracking** section (mandatory gap principle rationalizations)\n- **Gate Execution** section (workflow skip rationalizations)\n- **TDD** section (test-first rationalizations)\n- **Universal** section (general anti-patterns)\n\n### Verification Rule\n\n```\nCOUNT(non- items in all Standards Coverage Tables) == COUNT(FINDING-XXX entries)\n\nIf counts don't match  SKILL FAILURE. Go back and add missing findings.\n```\n\n---\n\n##  Architecture Pattern Applicability\n\n**Not all architecture patterns apply to all services.** Before flagging gaps, verify the pattern is applicable.\n\n| Service Type | Hexagonal/Clean Architecture | Directory Structure |\n|--------------|------------------------------|---------------------|\n| CRUD API (with services, adapters) |  APPLY |  APPLY (Lerian pattern) |\n| Complex business logic |  APPLY |  APPLY |\n| Multiple bounded contexts |  APPLY |  APPLY |\n| Event-driven systems |  APPLY |  APPLY |\n| Simple scripts/utilities |  not APPLICABLE |  not APPLICABLE |\n| CLI tools |  not APPLICABLE |  not APPLICABLE |\n| Workers/background jobs |  not APPLICABLE |  not APPLICABLE |\n| Simple lambda/functions |  not APPLICABLE |  not APPLICABLE |\n\n### Detection Criteria\n\n**CRUD API (Hexagonal/Lerian Pattern APPLICABLE):**\n- Service exposes API endpoints (REST, gRPC, GraphQL)\n- Contains business logic and models\n- Has CRUD operations (Create, Read, Update, Delete)\n- Uses repositories for data access\n-  **MUST follow Hexagonal Architecture and Lerian directory pattern**\n\n**Simple Service (Hexagonal/Lerian not applicable):**\n- CLI tools and scripts\n- Workers and background jobs\n- Simple utility functions\n- Lambda functions with single responsibility\n- No business logic layer\n\n### Agent Instruction\n\nWhen dispatching specialist agents, include:\n\n```\n ARCHITECTURE APPLICABILITY CHECK:\n1. If service is an API with CRUD operations  APPLY Hexagonal/Lerian standards\n2. If service is CLI tool, script, or simple utility  Do not flag Hexagonal/Lerian gaps\n\nCRUD APIs MUST follow Hexagonal Architecture (ports/adapters) and Lerian directory pattern.\n```\n\n---\n\n##  MANDATORY: Initialize Todo List FIRST\n\n**Before any other action, create the todo list with all steps:**\n\n```yaml\nTodoWrite:\n  todos:\n    - content: \"Validate PROJECT_RULES.md exists\"\n      status: \"pending\"\n      activeForm: \"Validating PROJECT_RULES.md exists\"\n    - content: \"Detect project stack (Go/TypeScript/Frontend)\"\n      status: \"pending\"\n      activeForm: \"Detecting project stack\"\n    - content: \"Read PROJECT_RULES.md for context\"\n      status: \"pending\"\n      activeForm: \"Reading PROJECT_RULES.md\"\n    - content: \"Generate codebase report via codebase-explorer\"\n      status: \"pending\"\n      activeForm: \"Generating codebase report\"\n    - content: \"Dispatch specialist agents in parallel\"\n      status: \"pending\"\n      activeForm: \"Dispatching specialist agents\"\n    - content: \"Save individual agent reports\"\n      status: \"pending\"\n      activeForm: \"Saving agent reports\"\n    - content: \"Map agent findings to FINDING-XXX entries\"\n      status: \"pending\"\n      activeForm: \"Mapping agent findings\"\n    - content: \"Generate findings.md\"\n      status: \"pending\"\n      activeForm: \"Generating findings.md\"\n    - content: \"Group findings into REFACTOR-XXX tasks\"\n      status: \"pending\"\n      activeForm: \"Grouping findings into tasks\"\n    - content: \"Generate tasks.md\"\n      status: \"pending\"\n      activeForm: \"Generating tasks.md\"\n    - content: \"Get user approval\"\n      status: \"pending\"\n      activeForm: \"Getting user approval\"\n    - content: \"Save all artifacts\"\n      status: \"pending\"\n      activeForm: \"Saving artifacts\"\n    - content: \"Handoff to dev-cycle\"\n      status: \"pending\"\n      activeForm: \"Handing off to dev-cycle\"\n```\n\n**This is NON-NEGOTIABLE. Do not skip creating the todo list.**\n\n---\n\n##  CRITICAL: Specialized Agents Perform All Tasks\n\nSee [shared-patterns/shared-orchestrator-principle.md](../shared-patterns/shared-orchestrator-principle.md) for full ORCHESTRATOR principle, role separation, forbidden/required actions, step-to-agent mapping, and anti-rationalization table.\n\n**Summary:** You orchestrate. Agents execute. If using Bash/Grep/Read to analyze code  STOP. Dispatch agent.\n\n---\n\n## Step 0: Validate PROJECT_RULES.md\n\n**TodoWrite:** Mark \"Validate PROJECT_RULES.md exists\" as `in_progress`\n\n<block_condition>\n- docs/PROJECT_RULES.md does not exist\n</block_condition>\n\nIf condition is true, output blocker and TERMINATE. Otherwise continue to Step 1.\n\n**Check:** Does `docs/PROJECT_RULES.md` exist?\n\n- **YES**  Mark todo as `completed`, continue to Step 1\n- **no**  Output blocker and TERMINATE:\n\n```markdown\n## BLOCKED: PROJECT_RULES.md Not Found\n\nCannot proceed without project standards baseline.\n\n**Required Action:** Create `docs/PROJECT_RULES.md` with:\n- Architecture patterns\n- Code conventions\n- Testing requirements\n- Technology stack decisions\n\nRe-run after file exists.\n```\n\n---\n\n## Step 1: Detect Project Stack\n\n**TodoWrite:** Mark \"Detect project stack (Go/TypeScript/Frontend)\" as `in_progress`\n\nCheck for manifest files and frontend indicators:\n\n| File/Pattern | Stack | Agent |\n|--------------|-------|-------|\n| `go.mod` | Go Backend | backend-engineer-golang |\n| `package.json` + `src/` (no React) | TypeScript Backend | backend-engineer-typescript |\n| `package.json` + React/Next.js | Frontend | frontend-engineer |\n| `package.json` + BFF pattern | TypeScript BFF | frontend-bff-engineer-typescript |\n\n**Detection Logic:**\n- `go.mod` exists  Add Go backend agent\n- `package.json` exists + `next.config.*` or React in dependencies  Add frontend agent\n- `package.json` exists + `/api/` routes or Express/Fastify  Add TypeScript backend agent\n- `package.json` exists + BFF indicators (`/bff/`, gateway patterns)  Add BFF agent\n\nIf multiple stacks detected, dispatch agents for all.\n\n**TodoWrite:** Mark \"Detect project stack (Go/TypeScript/Frontend)\" as `completed`\n\n---\n\n## Step 2: Read PROJECT_RULES.md\n\n**TodoWrite:** Mark \"Read PROJECT_RULES.md for context\" as `in_progress`\n\n```\nRead tool: docs/PROJECT_RULES.md\n```\n\nExtract project-specific conventions for agent context.\n\n**TodoWrite:** Mark \"Read PROJECT_RULES.md for context\" as `completed`\n\n---\n\n## Step 3: Generate Codebase Report\n\n**TodoWrite:** Mark \"Generate codebase report via codebase-explorer\" as `in_progress`\n\n###  MANDATORY: Use Task Tool with codebase-explorer\n\n<dispatch_required agent=\"codebase-explorer\" model=\"opus\">\nGenerate a comprehensive codebase report describing WHAT EXISTS.\n\nInclude:\n- Project structure and directory layout\n- Architecture pattern (hexagonal, clean, etc.)\n- Technology stack from manifests\n- Code patterns: config, database, handlers, errors, telemetry, testing\n- Key files inventory with file:line references\n- Code snippets showing current implementation patterns\n</dispatch_required>\n\n<output_required>\n## EXPLORATION SUMMARY\n[Your summary here]\n\n## KEY FINDINGS\n[Your findings here]\n\n## ARCHITECTURE INSIGHTS\n[Your insights here]\n\n## RELEVANT FILES\n[Your file inventory here]\n\n## RECOMMENDATIONS\n[Your recommendations here]\n</output_required>\n\nDo not complete without outputting full report in the format above.\n\n### Anti-Rationalization Table for Step 3\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I'll use Bash find/ls to quickly explore\" | Bash cannot analyze patterns, just lists files. codebase-explorer provides architectural analysis. | **Use Task with subagent_type=\"ring:codebase-explorer\"** |\n| \"The Explore agent is faster\" | \"Explore\" subagent_type  \"codebase-explorer\". Different agents. | **Use exact string: \"codebase-explorer\"** |\n| \"I already know the structure from find output\" | Knowing file paths  understanding architecture. Agent provides analysis. | **Use Task with subagent_type=\"ring:codebase-explorer\"** |\n| \"This is a small codebase, Bash is enough\" | Size is irrelevant. The agent provides standardized output format required by Step 4. | **Use Task with subagent_type=\"ring:codebase-explorer\"** |\n| \"I'll explore manually then dispatch agents\" | Manual exploration skips the codebase-report.md artifact required for Step 4 gate. | **Use Task with subagent_type=\"ring:codebase-explorer\"** |\n\n### FORBIDDEN Actions for Step 3\n\n<forbidden>\n- Bash(command=\"find ... -name '*.go'\")  SKILL FAILURE\n- Bash(command=\"ls -la ...\")  SKILL FAILURE\n- Bash(command=\"tree ...\")  SKILL FAILURE\n- Task(subagent_type=\"Explore\", ...)  SKILL FAILURE\n- Task(subagent_type=\"general-purpose\", ...)  SKILL FAILURE\n- Task(subagent_type=\"Plan\", ...)  SKILL FAILURE\n</forbidden>\n\nAny of these = IMMEDIATE SKILL FAILURE.\n\n### REQUIRED Action for Step 3\n\n```\n Task(subagent_type=\"ring:codebase-explorer\", model=\"opus\", ...)\n```\n\n**After Task completes, save with Write tool:**\n\n```\nWrite tool:\n  file_path: \"docs/refactor/{timestamp}/codebase-report.md\"\n  content: [Task output]\n```\n\n**TodoWrite:** Mark \"Generate codebase report via codebase-explorer\" as `completed`\n\n---\n\n## Step 4: Dispatch Specialist Agents\n\n**TodoWrite:** Mark \"Dispatch specialist agents in parallel\" as `in_progress`\n\n###  HARD GATE: Verify codebase-report.md Exists\n\n**BEFORE dispatching any specialist agent, verify:**\n\n```\nCheck 1: Does docs/refactor/{timestamp}/codebase-report.md exist?\n  - YES  Continue to dispatch agents\n  - no   STOP. Go back to Step 3.\n\nCheck 2: Was codebase-report.md created by codebase-explorer?\n  - YES  Continue\n  - no (created by Bash output)  DELETE IT. Go back to Step 3. Use correct agent.\n```\n\n**If you skipped Step 3 or used Bash instead of Task tool  You MUST go back and redo Step 3 correctly.**\n\n**Dispatch all applicable agents in ONE message (parallel):**\n\n###  MANDATORY: Reference Standards Coverage Table\n\n**All agents MUST follow [shared-patterns/standards-coverage-table.md](../shared-patterns/standards-coverage-table.md) which defines:**\n- all sections to check per agent (including DDD)\n- Required output format (Standards Coverage Table)\n- Anti-rationalization rules\n- Completeness verification\n\n**Section indexes are pre-defined in shared-patterns. Agents MUST check all sections listed.**\n\n---\n\n### For Go projects:\n\n<parallel_dispatch agents=\"backend-engineer-golang, qa-analyst, devops-engineer, sre\" model=\"opus\">\nAll four agents MUST be dispatched in parallel via Task tool.\nInput: codebase-report.md, PROJECT_RULES.md\n</parallel_dispatch>\n\n```yaml\nTask tool 1:\n  subagent_type: \"ring:backend-engineer-golang\"\n  model: \"opus\"\n  description: \"Go standards analysis\"\n  prompt: |\n    **MODE: ANALYSIS only**\n\n     MANDATORY: Check all sections in golang.md per shared-patterns/standards-coverage-table.md\n\n     FRAMEWORKS & LIBRARIES DETECTION (MANDATORY):\n    1. Read go.mod to extract all dependencies used in codebase\n    2. Load golang.md standards via WebFetch  extract all listed frameworks/libraries\n    3. For each category in standards (HTTP, Database, Validation, Testing, etc.):\n       - Compare codebase dependency vs standards requirement\n       - If codebase uses DIFFERENT library than standards  ISSUE-XXX\n       - If codebase is MISSING required library  ISSUE-XXX\n    4. any library not in standards that serves same purpose = ISSUE-XXX\n\n    Input:\n    - Ring Standards: Load via WebFetch (golang.md)\n    - Section Index: See shared-patterns/standards-coverage-table.md  \"backend-engineer-golang\"\n    - Codebase Report: docs/refactor/{timestamp}/codebase-report.md\n    - Project Rules: docs/PROJECT_RULES.md\n\n    Output:\n    1. Standards Coverage Table (per shared-patterns format)\n    2. ISSUE-XXX for each / finding with: Pattern name, Severity, file:line, Current Code, Expected Code\n\nTask tool 2:\n  subagent_type: \"ring:qa-analyst\"\n  model: \"opus\"\n  description: \"Test coverage analysis\"\n  prompt: |\n    **MODE: ANALYSIS only**\n    Check all testing sections per shared-patterns/standards-coverage-table.md  \"qa-analyst\"\n    Input: codebase-report.md, PROJECT_RULES.md\n    Output: Standards Coverage Table + ISSUE-XXX for gaps\n\nTask tool 3:\n  subagent_type: \"ring:devops-engineer\"\n  model: \"opus\"\n  description: \"DevOps analysis\"\n  prompt: |\n    **MODE: ANALYSIS only**\n    Check all 7 sections per shared-patterns/standards-coverage-table.md  \"devops-engineer\"\n     \"Containers\" means BOTH Dockerfile and Docker Compose\n     \"Makefile Standards\" means all required commands: build, lint, test, cover, up, down, etc.\n    Input: codebase-report.md, PROJECT_RULES.md\n    Output: Standards Coverage Table + ISSUE-XXX for gaps\n\nTask tool 4:\n  subagent_type: \"ring:sre\"\n  model: \"opus\"\n  description: \"Observability analysis\"\n  prompt: |\n    **MODE: ANALYSIS only**\n    Check all 6 sections per shared-patterns/standards-coverage-table.md  \"sre\"\n    Input: codebase-report.md, PROJECT_RULES.md\n    Output: Standards Coverage Table + ISSUE-XXX for gaps\n```\n\n### For TypeScript Backend projects:\n\n<parallel_dispatch agents=\"backend-engineer-typescript, qa-analyst, devops-engineer, sre\" model=\"opus\">\nAll four agents MUST be dispatched in parallel via Task tool.\nInput: codebase-report.md, PROJECT_RULES.md\n</parallel_dispatch>\n\n```yaml\nTask tool 1:\n  subagent_type: \"ring:backend-engineer-typescript\"\n  model: \"opus\"\n  description: \"TypeScript backend standards analysis\"\n  prompt: |\n    **MODE: ANALYSIS only**\n\n     MANDATORY: Check all sections in typescript.md per shared-patterns/standards-coverage-table.md\n\n     FRAMEWORKS & LIBRARIES DETECTION (MANDATORY):\n    1. Read package.json to extract all dependencies used in codebase\n    2. Load typescript.md standards via WebFetch  extract all listed frameworks/libraries\n    3. For each category in standards (Backend Framework, ORM, Validation, Testing, etc.):\n       - Compare codebase dependency vs standards requirement\n       - If codebase uses DIFFERENT library than standards  ISSUE-XXX\n       - If codebase is MISSING required library  ISSUE-XXX\n    4. any library not in standards that serves same purpose = ISSUE-XXX\n\n    Input:\n    - Ring Standards: Load via WebFetch (typescript.md)\n    - Section Index: See shared-patterns/standards-coverage-table.md  \"backend-engineer-typescript\"\n    - Codebase Report: docs/refactor/{timestamp}/codebase-report.md\n    - Project Rules: docs/PROJECT_RULES.md\n\n    Output:\n    1. Standards Coverage Table (per shared-patterns format)\n    2. ISSUE-XXX for each / finding with: Pattern name, Severity, file:line, Current Code, Expected Code\n```\n\n### For Frontend projects (React/Next.js):\n\n<parallel_dispatch agents=\"frontend-engineer, qa-analyst, devops-engineer, sre\" model=\"opus\">\nAll four agents MUST be dispatched in parallel via Task tool.\nInput: codebase-report.md, PROJECT_RULES.md\n</parallel_dispatch>\n\n```yaml\nTask tool 5:\n  subagent_type: \"ring:frontend-engineer\"\n  model: \"opus\"\n  description: \"Frontend standards analysis\"\n  prompt: |\n    **MODE: ANALYSIS only**\n\n     MANDATORY: Check all 13 sections in frontend.md per shared-patterns/standards-coverage-table.md\n\n    Input:\n    - Ring Standards: Load via WebFetch (frontend.md)\n    - Section Index: See shared-patterns/standards-coverage-table.md  \"frontend-engineer\"\n    - Codebase Report: docs/refactor/{timestamp}/codebase-report.md\n    - Project Rules: docs/PROJECT_RULES.md\n\n    Output:\n    1. Standards Coverage Table (per shared-patterns format)\n    2. ISSUE-XXX for each / finding with: Pattern name, Severity, file:line, Current Code, Expected Code\n```\n\n### For BFF (Backend-for-Frontend) projects:\n\n<parallel_dispatch agents=\"frontend-bff-engineer-typescript, qa-analyst, devops-engineer, sre\" model=\"opus\">\nAll four agents MUST be dispatched in parallel via Task tool.\nInput: codebase-report.md, PROJECT_RULES.md\n</parallel_dispatch>\n\n```yaml\nTask tool 6:\n  subagent_type: \"ring:frontend-bff-engineer-typescript\"\n  model: \"opus\"\n  description: \"BFF TypeScript standards analysis\"\n  prompt: |\n    **MODE: ANALYSIS only**\n\n     MANDATORY: Check all sections in typescript.md per shared-patterns/standards-coverage-table.md\n\n     FRAMEWORKS & LIBRARIES DETECTION (MANDATORY):\n    1. Read package.json to extract all dependencies used in codebase\n    2. Load typescript.md standards via WebFetch  extract all listed frameworks/libraries\n    3. For each category in standards (Backend Framework, ORM, Validation, Testing, etc.):\n       - Compare codebase dependency vs standards requirement\n       - If codebase uses DIFFERENT library than standards  ISSUE-XXX\n       - If codebase is MISSING required library  ISSUE-XXX\n    4. any library not in standards that serves same purpose = ISSUE-XXX\n\n    Input:\n    - Ring Standards: Load via WebFetch (typescript.md)\n    - Section Index: See shared-patterns/standards-coverage-table.md  \"frontend-bff-engineer-typescript\"\n    - Codebase Report: docs/refactor/{timestamp}/codebase-report.md\n    - Project Rules: docs/PROJECT_RULES.md\n\n    Output:\n    1. Standards Coverage Table (per shared-patterns format)\n    2. ISSUE-XXX for each / finding with: Pattern name, Severity, file:line, Current Code, Expected Code\n```\n\n### Agent Dispatch Summary\n\n| Stack Detected | Agents to Dispatch |\n|----------------|-------------------|\n| Go only | Task 1 (Go) + Task 2-4 |\n| TypeScript Backend only | Task 1 (TS Backend) + Task 2-4 |\n| Frontend only | Task 5 (Frontend) + Task 2-4 |\n| Go + Frontend | Task 1 (Go) + Task 5 (Frontend) + Task 2-4 |\n| TypeScript Backend + Frontend | Task 1 (TS Backend) + Task 5 (Frontend) + Task 2-4 |\n| BFF detected | Add Task 6 (BFF) to above |\n\n**TodoWrite:** Mark \"Dispatch specialist agents in parallel\" as `completed`\n\n---\n\n## Step 4.5: Save Individual Agent Reports\n\n**TodoWrite:** Mark \"Save individual agent reports\" as `in_progress`\n\n** MANDATORY: Each agent's output MUST be saved as an individual report file.**\n\nAfter all parallel agent tasks complete, save each agent's output to a separate file:\n\n```\ndocs/refactor/{timestamp}/reports/\n backend-engineer-golang-report.md     (if Go project)\n backend-engineer-typescript-report.md (if TypeScript Backend)\n frontend-engineer-report.md           (if Frontend)\n frontend-bff-engineer-report.md       (if BFF)\n qa-analyst-report.md                  (always)\n devops-engineer-report.md             (always)\n sre-report.md                         (always)\n```\n\n### Report File Format\n\n**Use Write tool for each agent report:**\n\n```markdown\n# {Agent Name} Analysis Report\n\n**Generated:** {timestamp}\n**Agent:** {agent-name}\n**Mode:** ANALYSIS only\n\n## Standards Coverage Table\n\n{Copy agent's Standards Coverage Table output here}\n\n## Issues Found\n\n{Copy all ISSUE-XXX entries from agent output}\n\n## Summary\n\n- **Total Issues:** {count}\n- **Critical:** {count}\n- **High:** {count}\n- **Medium:** {count}\n- **Low:** {count}\n\n---\n*Report generated by dev-refactor skill*\n```\n\n### Agent Report Mapping\n\n| Agent Dispatched | Report File Name |\n|------------------|------------------|\n| backend-engineer-golang | `backend-engineer-golang-report.md` |\n| backend-engineer-typescript | `backend-engineer-typescript-report.md` |\n| frontend-engineer | `frontend-engineer-report.md` |\n| frontend-bff-engineer-typescript | `frontend-bff-engineer-report.md` |\n| qa-analyst | `qa-analyst-report.md` |\n| devops-engineer | `devops-engineer-report.md` |\n| sre | `sre-report.md` |\n\n### Anti-Rationalization Table for Step 4.5\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I'll combine all reports into one file\" | Individual reports enable targeted re-runs and tracking | **Save each agent to SEPARATE file** |\n| \"Agent output is already visible in chat\" | Chat history is ephemeral; files are artifacts | **MUST persist as files** |\n| \"Only saving reports with issues\" | Empty reports prove compliance was checked | **Save all dispatched agent reports** |\n| \"findings.md already captures everything\" | findings.md is processed; reports are raw agent output | **Save BOTH raw reports and findings.md** |\n\n### REQUIRED Action for Step 4.5\n\n```\nWrite tool:\n  file_path: \"docs/refactor/{timestamp}/reports/{agent-name}-report.md\"\n  content: [Agent Task output formatted per template above]\n```\n\n**Repeat for each agent dispatched in Step 4.**\n\n**TodoWrite:** Mark \"Save individual agent reports\" as `completed`\n\n---\n\n## Step 4.1: Agent Report  Findings Mapping (HARD GATE)\n\n**TodoWrite:** Mark \"Map agent findings to FINDING-XXX entries\" as `in_progress`\n\n** MANDATORY: all agent-reported issues MUST become findings.**\n\n| Agent Report | Action |\n|--------------|--------|\n| Any difference between current code and Ring standard |  Create FINDING-XXX |\n| Any missing pattern from Ring standards |  Create FINDING-XXX |\n| Any deprecated pattern usage |  Create FINDING-XXX |\n| Any observability gap |  Create FINDING-XXX |\n\n### FORBIDDEN Actions for Step 4.1\n\n```\n Ignoring agent-reported issues because they seem \"minor\"   SKILL FAILURE\n Filtering out issues based on personal judgment            SKILL FAILURE\n Summarizing multiple issues into one finding               SKILL FAILURE\n Skipping issues without ISSUE-XXX format from agent        SKILL FAILURE\n Creating findings only for \"interesting\" gaps              SKILL FAILURE\n```\n\n### REQUIRED Actions for Step 4.1\n\n```\n Every line item from agent reports becomes a FINDING-XXX entry\n Preserve agent's severity assessment exactly as reported\n Include exact file:line references from agent report\n Every non- item in Standards Coverage Table = one FINDING-XXX\n Count findings in Step 5 MUST equal total issues from all agent reports\n```\n\n---\n\n### Anti-Rationalization Table for Step 4.1\n\n** See also: \"Anti-Rationalization: Mandatory Gap Principle\" at top of this skill.**\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Multiple similar issues can be one finding\" | Distinct file:line = distinct finding. Merging loses traceability. | **One issue = One FINDING-XXX** |\n| \"Agent report didn't use ISSUE-XXX format\" | Format varies; presence matters. Every gap = one finding. | **Extract all gaps into findings** |\n| \"I'll consolidate to reduce noise\" | Consolidation = data loss. Noise is signal. | **Preserve all individual issues** |\n| \"Some findings are duplicates across agents\" | Different agents = different perspectives. Keep both. | **Create separate findings per agent** |\n| \"Team has approved this deviation\" | Team approval  standards compliance. Document the gap. | **Create FINDING-XXX, note team decision** |\n| \"Fixing this would break existing code\" | Breaking risk = implementation concern, not tracking concern. | **Create FINDING-XXX, note risk in description** |\n\n###  MANDATORY GAP RULE FOR STEP 4.1\n\n**Per the Mandatory Gap Principle (see top of skill): any divergence from Ring standards = FINDING-XXX.**\n\nThis means:\n-  items in Standards Coverage Table = No finding needed\n-  items = MUST create FINDING-XXX (partial compliance is a gap)\n-  items = MUST create FINDING-XXX (non-compliance is a gap)\n- Different pattern = MUST create FINDING-XXX (alternative is still a gap)\n\n**Verification:** Use formula from \"Mandatory Gap Principle  Verification Rule\" section.\n\n###  Gate Escape Detection (Anti-Duplication)\n\n**When mapping findings, identify which gate SHOULD have caught the issue:**\n\n| Finding Category | Should Be Caught In | Flag |\n|------------------|---------------------|------|\n| Missing edge case tests | Gate 3 (Testing) | ` GATE 3 ESCAPE` |\n| Test isolation issues | Gate 3 (Testing) | ` GATE 3 ESCAPE` |\n| Skipped/assertion-less tests | Gate 3 (Testing) | ` GATE 3 ESCAPE` |\n| Test naming convention | Gate 3 (Testing) | ` GATE 3 ESCAPE` |\n| Missing test coverage | Gate 3 (Testing) | ` GATE 3 ESCAPE` |\n| TDD RED phase missing | Gate 3 (Testing) | ` GATE 3 ESCAPE` |\n| Implementation pattern gaps | Gate 0 (Implementation) | Normal finding |\n| Standards compliance gaps | Gate 0 (Implementation) | Normal finding |\n| Observability gaps | Gate 2 (SRE) | ` GATE 2 ESCAPE` |\n| Docker/DevOps gaps | Gate 1 (DevOps) | ` GATE 1 ESCAPE` |\n\n**Gate Escape Output Format:**\n\n```markdown\n### FINDING-XXX: [Issue Title]  GATE 3 ESCAPE\n\n**Escaped From:** Gate 3 (Testing)\n**Why It Escaped:** [Quality Gate check that should have caught this]\n**Prevention:** [Specific check to add to Gate 3 exit criteria]\n\n[Rest of finding format...]\n```\n\n**Purpose:** Track which issues escape which gates. If many `GATE 3 ESCAPE` findings occur, the Quality Gate checks need strengthening.\n\n---\n\n**Summary Table (MANDATORY at end of findings.md):**\n\n```markdown\n## Gate Escape Summary\n\n| Gate | Escaped Issues | Most Common Type |\n|------|----------------|------------------|\n| Gate 0 (Implementation) | N | [type] |\n| Gate 1 (DevOps) | N | [type] |\n| Gate 2 (SRE) | N | [type] |\n| Gate 3 (Testing) | N | [type] |\n\n**Action Required:** If any gate has >2 escapes, review that gate's exit criteria.\n```\n\n**TodoWrite:** Mark \"Map agent findings to FINDING-XXX entries\" as `completed`\n\n---\n\n## Step 5: Generate findings.md\n\n**TodoWrite:** Mark \"Generate findings.md\" as `in_progress`\n\n###  HARD GATE: Verify All Issues Are Mapped\n\n**BEFORE creating findings.md, apply the Verification Rule from \"Mandatory Gap Principle\" section.**\n\nIf counts don't match  STOP. Go back to Step 4.1. Map missing issues.\n\n### FORBIDDEN Actions for Step 5\n\n```\n Creating findings.md with fewer entries than agent issues   SKILL FAILURE\n Omitting file:line references from findings                 SKILL FAILURE\n Using vague descriptions instead of specific code excerpts  SKILL FAILURE\n Skipping \"Why This Matters\" section for any finding         SKILL FAILURE\n Generating findings.md without reading all agent reports    SKILL FAILURE\n```\n\n### REQUIRED Actions for Step 5\n\n```\n Every FINDING-XXX includes: Severity, Category, Agent, Standard reference\n Every FINDING-XXX includes: Current Code with exact file:line\n Every FINDING-XXX includes: Ring Standard Reference with URL\n Every FINDING-XXX includes: Required Changes as numbered actions\n Every FINDING-XXX includes: Why This Matters with Problem/Standard/Impact\n Total finding count MUST match total issues from Step 4.1\n```\n\n### Anti-Rationalization Table for Step 5\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"I'll add details later during implementation\" | findings.md is the source of truth. Incomplete = useless. | **Complete all sections for every finding** |\n| \"Code snippet is too long to include\" | Truncate to relevant lines, but never omit. Context is required. | **Include code with file:line reference** |\n| \"Standard URL is obvious, skip it\" | Agents and humans need direct links. Nothing is obvious. | **Include full URL for every standard** |\n| \"Why This Matters is redundant\" | It explains business impact. Standards alone don't convey urgency. | **Write Problem/Standard/Impact for all** |\n| \"Some findings are self-explanatory\" | Self-explanatory to you  clear to implementer. | **Complete all sections without exception** |\n| \"I'll group small findings together\" | Grouping happens in Step 6 (tasks). findings.md = atomic issues. | **One finding = one FINDING-XXX entry** |\n\n**Use Write tool to create findings.md:**\n\n** CRITICAL: Every issue reported by agents in Step 4 MUST appear here as a FINDING-XXX entry.**\n\n```markdown\n# Findings: {project-name}\n\n**Generated:** {timestamp}\n**Total Findings:** {count}\n\n##  Mandatory Gap Principle Applied\n\n**all divergences from Ring standards are tracked below. No filtering applied.**\n\n| Metric | Count |\n|--------|-------|\n| Total non- items from agent reports | {X} |\n| Total FINDING-XXX entries below | {X} |\n| **Counts match?** |  YES (REQUIRED) |\n\n**Severity does not affect tracking - all gaps are mandatory:**\n| Severity | Count | Priority | Tracking |\n|----------|-------|----------|----------|\n| Critical | {N} | Execute first | **MANDATORY** |\n| High | {N} | Execute in current sprint | **MANDATORY** |\n| Medium | {N} | Execute in next sprint | **MANDATORY** |\n| Low | {N} | Execute when capacity | **MANDATORY** |\n\n---\n\n## FINDING-001: {Pattern Name}\n\n**Severity:** Critical | High | Medium | Low (all MANDATORY)\n**Category:** {lib-commons | architecture | testing | devops}\n**Agent:** {agent-name}\n**Standard:** {file}.md:{section}\n\n### Current Code\n```{lang}\n// file: {path}:{lines}\n{actual code}\n```\n\n### Ring Standard Reference\n**Standard:** {standards-file}.md  Section: {section-name}\n**Pattern:** {pattern-name}\n**URL:** https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/{file}.md\n\n### Required Changes\n1. {action item 1 - what to change}\n2. {action item 2 - what to add/remove}\n3. {action item 3 - pattern to follow}\n\n### Why This Matters\n- **Problem:** {what is wrong with current code}\n- **Standard Violated:** {specific section from Ring standards}\n- **Impact:** {business/technical impact if not fixed}\n\n---\n\n## FINDING-002: ...\n```\n\n**TodoWrite:** Mark \"Generate findings.md\" as `completed`\n\n---\n\n## Step 6: Group Findings into Tasks\n\n**TodoWrite:** Mark \"Group findings into REFACTOR-XXX tasks\" as `in_progress`\n\n** HARD GATE: Every FINDING-XXX MUST appear in at least one REFACTOR-XXX task.**\n\nGroup related findings by:\n1. Module/bounded context (same file/package = same task)\n2. Dependency order (foundational changes first)\n3. Severity (critical first)\n\n**Mapping Verification:**\n```\nBefore proceeding to Step 7, verify:\n- Total findings in findings.md: X\n- Total findings referenced in tasks: X (MUST MATCH)\n- Orphan findings (not in any task): 0 (MUST BE ZERO)\n```\n\n**If any finding is not mapped to a task  STOP. Add missing findings to tasks.**\n\n**TodoWrite:** Mark \"Group findings into REFACTOR-XXX tasks\" as `completed`\n\n---\n\n## Step 7: Generate tasks.md\n\n**TodoWrite:** Mark \"Generate tasks.md\" as `in_progress`\n\n**Use Write tool to create tasks.md:**\n\n```markdown\n# Refactoring Tasks: {project-name}\n\n**Source:** findings.md\n**Total Tasks:** {count}\n\n##  Mandatory Gap Verification\n\n**all findings from findings.md MUST be addressed in tasks below.**\n\n| Metric | Count |\n|--------|-------|\n| Total FINDING-XXX in findings.md | {X} |\n| Total FINDING-XXX referenced in tasks | {X} |\n| Orphan findings (not in any task) | 0 (REQUIRED) |\n| **All findings mapped?** |  YES (REQUIRED) |\n\n**Priority affects execution order, not whether to include:**\n- Critical/High tasks: Execute first\n- Medium tasks: Execute in current cycle\n- Low tasks: Execute when capacity - STILL MANDATORY TO COMPLETE\n\n---\n\n## REFACTOR-001: {Task Name}\n\n**Priority:** Critical | High | Medium | Low (all ARE MANDATORY)\n**Effort:** {hours}h\n**Dependencies:** {other tasks or none}\n\n### Findings Addressed\n| Finding | Pattern | Severity | File:Line |\n|---------|---------|----------|-----------|\n| FINDING-001 | {name} | Critical | src/handler.go:45 |\n| FINDING-003 | {name} | High | src/service.go:112 |\n\n### Ring Standards to Follow\n| Standard File | Section | URL |\n|---------------|---------|-----|\n| golang.md | Error Handling | [Link](https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md) |\n| sre.md | Structured Logging | [Link](https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/sre.md) |\n\n### Required Actions\n1. [ ] {action from FINDING-001 - specific change to make}\n2. [ ] {action from FINDING-001 - pattern to implement}\n3. [ ] {action from FINDING-003 - specific change to make}\n\n### Acceptance Criteria\n- [ ] Code follows {standard}.md  {section} pattern\n- [ ] No {anti-pattern} usage remains\n- [ ] Tests pass after refactoring\n- [ ] {additional criteria from findings}\n```\n\n**TodoWrite:** Mark \"Generate tasks.md\" as `completed`\n\n---\n\n## Step 8: User Approval\n\n**TodoWrite:** Mark \"Get user approval\" as `in_progress`\n\n<user_decision>\nMUST wait for explicit user response before proceeding.\nOptions: Approve all | Critical only | Cancel\n</user_decision>\n\n```yaml\nAskUserQuestion:\n  questions:\n    - question: \"Review refactoring plan. How to proceed?\"\n      header: \"Approval\"\n      options:\n        - label: \"Approve all\"\n          description: \"Proceed to dev-cycle execution\"\n        - label: \"Critical only\"\n          description: \"Execute only Critical/High tasks\"\n        - label: \"Cancel\"\n          description: \"Keep analysis, skip execution\"\n```\n\nCANNOT proceed without explicit user selection.\n\n**TodoWrite:** Mark \"Get user approval\" as `completed`\n\n---\n\n## Step 9: Save Artifacts\n\n**TodoWrite:** Mark \"Save all artifacts\" as `in_progress`\n\n```\ndocs/refactor/{timestamp}/\n codebase-report.md  (Step 3)\n reports/            (Step 4.5)\n    backend-engineer-golang-report.md\n    qa-analyst-report.md\n    devops-engineer-report.md\n    sre-report.md\n findings.md         (Step 5)\n tasks.md           (Step 7)\n```\n\n**TodoWrite:** Mark \"Save all artifacts\" as `completed`\n\n---\n\n## Step 10: Handoff to dev-cycle\n\n**TodoWrite:** Mark \"Handoff to dev-cycle\" as `in_progress`\n\n**If user approved, use Skill tool to invoke dev-cycle directly:**\n\n```yaml\nSkill tool:\n  skill: \"ring:dev-cycle\"\n```\n\n** CRITICAL: Pass tasks file path in context:**\nAfter invoking the skill, provide the tasks file location:\n- Tasks file: `docs/refactor/{timestamp}/tasks.md`\n\nWhere `{timestamp}` is the same timestamp used in Step 9 artifacts.\n\n### Anti-Rationalization: Skill Invocation\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"SlashCommand is equivalent to Skill tool\" | SlashCommand is a hint; Skill tool guarantees skill loading | **Use Skill tool, not SlashCommand** |\n| \"User can run /dev-cycle manually\" | Manual run risks skill not being loaded | **Invoke Skill tool directly** |\n| \"dev-cycle will auto-discover tasks\" | Explicit path ensures correct file is used | **Pass explicit tasks path** |\n| \"User approved, I can skip dev-cycle\" | Approval = permission to proceed, not skip execution | **Invoke Skill tool** |\n| \"Tasks are saved, job is done\" | Saved tasks without execution = incomplete workflow | **Invoke Skill tool** |\n\n** HARD GATE: You CANNOT complete dev-refactor without invoking `Skill tool: ring:dev-cycle`.**\n\nIf user approved execution, you MUST:\n1. Invoke `Skill tool: ring:dev-cycle`\n2. Pass tasks file path: `docs/refactor/{timestamp}/tasks.md`\n3. Wait for dev-cycle to complete all 6 gates\n\n**Skipping this step = SKILL FAILURE.**\n\ndev-cycle executes each REFACTOR-XXX task through 6-gate process.\n\n**TodoWrite:** Mark \"Handoff to dev-cycle\" as `completed`\n\n---\n\n## Execution Report\n\nBase metrics per [shared-patterns/output-execution-report.md](../shared-patterns/output-execution-report.md).\n\n| Metric | Value |\n|--------|-------|\n| Duration | Xm Ys |\n| Iterations | N |\n| Result | PASS/FAIL/PARTIAL |\n\n### Refactor-Specific Metrics\n| Metric | Value |\n|--------|-------|\n| Agents Dispatched | N |\n| Findings Generated | N |\n| Tasks Created | N |\n| Artifacts Location | docs/refactors/{date}/ |\n\n## Output Schema\n\n```yaml\nartifacts:\n  - codebase-report.md (Step 3)\n  - reports/{agent-name}-report.md (Step 4.5)\n  - findings.md (Step 5)\n  - tasks.md (Step 7)\n\ntraceability:\n  Ring Standard  Agent Report  FINDING-XXX  REFACTOR-XXX  Implementation\n```"
              },
              {
                "name": "ring:dev-sre",
                "description": "Gate 2 of the development cycle. VALIDATES that observability was correctly implemented\nby developers. Does not implement observability code - only validates it.\n",
                "path": "dev-team/skills/dev-sre/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-sre",
                  "description": "Gate 2 of the development cycle. VALIDATES that observability was correctly implemented\nby developers. Does not implement observability code - only validates it.\n",
                  "trigger": "- Gate 2 of development cycle\n- Gate 0 (Implementation) complete with observability code\n- Gate 1 (DevOps) setup complete\n- Service needs observability validation (logging, tracing)\n",
                  "NOT_skip_when": "- \"Task says observability not required\"  AI cannot self-exempt. all services need observability.\n- \"Pure frontend\"  If it calls any API, backend needs observability. Frontend-only = static HTML.\n- \"MVP doesn't need observability\"  MVP without observability = blind MVP. No exceptions.\n",
                  "sequence": {
                    "after": [
                      "dev-devops"
                    ],
                    "before": [
                      "dev-testing"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "dev-cycle",
                      "dev-devops",
                      "dev-testing"
                    ]
                  },
                  "input_schema": {
                    "required": [
                      {
                        "name": "unit_id",
                        "type": "string",
                        "description": "Task or subtask identifier being validated"
                      },
                      {
                        "name": "language",
                        "type": "string",
                        "enum": [
                          "go",
                          "typescript",
                          "python"
                        ],
                        "description": "Programming language of the implementation"
                      },
                      {
                        "name": "service_type",
                        "type": "string",
                        "enum": [
                          "api",
                          "worker",
                          "batch",
                          "cli",
                          "library"
                        ],
                        "description": "Type of service being validated"
                      },
                      {
                        "name": "implementation_agent",
                        "type": "string",
                        "description": "Agent that performed Gate 0 (e.g., ring:backend-engineer-golang)"
                      },
                      {
                        "name": "implementation_files",
                        "type": "array",
                        "items": "string",
                        "description": "List of files created/modified in Gate 0"
                      }
                    ],
                    "optional": [
                      {
                        "name": "external_dependencies",
                        "type": "array",
                        "items": "string",
                        "description": "External services called (HTTP, gRPC, queues)"
                      },
                      {
                        "name": "gate0_handoff",
                        "type": "object",
                        "description": "Summary from Gate 0 implementation"
                      },
                      {
                        "name": "gate1_handoff",
                        "type": "object",
                        "description": "Summary from Gate 1 DevOps setup"
                      }
                    ]
                  },
                  "output_schema": {
                    "format": "markdown",
                    "required_sections": [
                      {
                        "name": "Validation Result",
                        "pattern": "^## Validation Result",
                        "required": true
                      },
                      {
                        "name": "Instrumentation Coverage",
                        "pattern": "^## Instrumentation Coverage",
                        "required": true
                      },
                      {
                        "name": "Issues Found",
                        "pattern": "^## Issues Found",
                        "required": true
                      },
                      {
                        "name": "Handoff to Next Gate",
                        "pattern": "^## Handoff to Next Gate",
                        "required": true
                      }
                    ],
                    "metrics": [
                      {
                        "name": "result",
                        "type": "enum",
                        "values": [
                          "PASS",
                          "FAIL",
                          "NEEDS_FIXES"
                        ]
                      },
                      {
                        "name": "instrumentation_coverage_percent",
                        "type": "float"
                      },
                      {
                        "name": "iterations",
                        "type": "integer"
                      },
                      {
                        "name": "issues_critical",
                        "type": "integer"
                      },
                      {
                        "name": "issues_high",
                        "type": "integer"
                      },
                      {
                        "name": "issues_medium",
                        "type": "integer"
                      },
                      {
                        "name": "issues_low",
                        "type": "integer"
                      }
                    ]
                  },
                  "verification": {
                    "automated": [
                      {
                        "command": "docker-compose logs app 2>&1 | head -5 | jq -e '.level'",
                        "description": "Logs are JSON structured",
                        "success_pattern": "info|debug|warn|error"
                      }
                    ],
                    "manual": [
                      "Verify logs include trace_id when tracing is enabled"
                    ]
                  },
                  "examples": [
                    {
                      "name": "API service observability validation",
                      "input": {
                        "unit_id": "task-001",
                        "language": "go",
                        "service_type": "api",
                        "implementation_agent": "backend-engineer-golang",
                        "implementation_files": [
                          "internal/handler/user.go",
                          "internal/service/user.go"
                        ]
                      },
                      "expected_output": "## Validation Result\n**Status:** PASS\n**Iterations:** 1\n\n## Instrumentation Coverage\n| Layer | Instrumented | Total | Coverage |\n|-------|--------------|-------|----------|\n| Handlers | 5 | 5 | 100% |\n| Services | 8 | 8 | 100% |\n| Repositories | 4 | 4 | 100% |\n| **TOTAL** | 17 | 17 | **100%** |\n\n## Issues Found\nNone\n\n## Handoff to Next Gate\n- Ready for Gate 3: YES\n"
                    }
                  ]
                },
                "content": "# SRE Validation (Gate 2)\n\n## Overview\n\nThis skill VALIDATES that observability was correctly implemented by developers:\n- Structured logging with trace correlation\n- OpenTelemetry tracing instrumentation\n- Code instrumentation coverage (90%+ required)\n- Context propagation for distributed tracing\n\n## CRITICAL: Role Clarification\n\n**Developers IMPLEMENT observability. SRE VALIDATES it.**\n\n| Who | Responsibility |\n|-----|----------------|\n| **Developers** (Gate 0) | IMPLEMENT observability following Ring Standards |\n| **SRE Agent** (Gate 2) | VALIDATE that observability is correctly implemented |\n| **Implementation Agent** | FIX issues found by SRE (if any) |\n\n**If observability is missing or incorrect:**\n1. SRE reports issues with severity levels\n2. This skill dispatches fixes to the implementation agent\n3. SRE re-validates after fixes\n4. Max 3 iterations, then escalate to user\n\n---\n\n## Step 1: Validate Input\n\n<verify_before_proceed>\n- unit_id exists\n- language is valid (go|typescript|python)\n- service_type is valid (api|worker|batch|cli|library)\n- implementation_agent exists\n- implementation_files is not empty\n</verify_before_proceed>\n\n```text\nREQUIRED INPUT (from dev-cycle orchestrator):\n- unit_id: [task/subtask being validated]\n- language: [go|typescript|python]\n- service_type: [api|worker|batch|cli|library]\n- implementation_agent: [agent that did Gate 0]\n- implementation_files: [list of files from Gate 0]\n\nOPTIONAL INPUT:\n- external_dependencies: [HTTP clients, gRPC clients, queues]\n- gate0_handoff: [summary from Gate 0]\n- gate1_handoff: [summary from Gate 1]\n\nif any REQUIRED input is missing:\n   STOP and report: \"Missing required input: [field]\"\n   Return to orchestrator with error\n```\n\n## Step 2: Initialize Validation State\n\n```text\nvalidation_state = {\n  iteration: 1,\n  max_iterations: 3,\n  sre_result: null,\n  issues: [],\n  instrumentation_coverage: null\n}\n```\n\n## Step 3: Dispatch SRE Agent for Validation\n\n<dispatch_required agent=\"sre\" model=\"opus\">\nValidate observability implementation for unit_id.\n</dispatch_required>\n\n```yaml\nTask:\n  subagent_type: \"ring:sre\"\n  model: \"opus\"\n  description: \"Validate observability for [unit_id]\"\n  prompt: |\n     VALIDATE Observability Implementation\n\n    ## Input Context\n    - **Unit ID:** [unit_id]\n    - **Language:** [language]\n    - **Service Type:** [service_type]\n    - **Implementation Agent:** [implementation_agent]\n    - **Files to Validate:** [implementation_files]\n    - **External Dependencies:** [external_dependencies or \"None\"]\n\n    ## Standards Reference\n    WebFetch: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/sre.md\n\n    ## Your Role\n    - VALIDATE that observability is implemented correctly\n    - Do not implement - only verify and report\n    - Check structured JSON logging\n    - Check OpenTelemetry instrumentation coverage\n    - Check context propagation for external calls\n\n    ## Validation Checklist\n\n    ### 0. FORBIDDEN Logging Patterns (CRITICAL - Check FIRST)\n\n    Any occurrence = CRITICAL severity, automatic FAIL verdict.\n\n    <forbidden>\n    - fmt.Println() in Go code\n    - fmt.Printf() in Go code\n    - log.Println() in Go code\n    - log.Printf() in Go code\n    - log.Fatal() in Go code\n    - println() in Go code\n    - console.log() in TypeScript\n    - console.error() in TypeScript\n    - console.warn() in TypeScript\n    </forbidden>\n    \n    **MUST search for and report all occurrences of FORBIDDEN patterns:**\n    \n    | Language | FORBIDDEN Pattern | Search For |\n    |----------|-------------------|------------|\n    | Go | `fmt.Println()` | `fmt.Println` in *.go files |\n    | Go | `fmt.Printf()` | `fmt.Printf` in *.go files |\n    | Go | `log.Println()` | `log.Println` in *.go files |\n    | Go | `log.Printf()` | `log.Printf` in *.go files |\n    | Go | `log.Fatal()` | `log.Fatal` in *.go files |\n    | Go | `println()` | `println(` in *.go files |\n    | TypeScript | `console.log()` | `console.log` in *.ts files |\n    | TypeScript | `console.error()` | `console.error` in *.ts files |\n    | TypeScript | `console.warn()` | `console.warn` in *.ts files |\n    \n    **If any FORBIDDEN pattern found:**\n    - Severity: **CRITICAL**\n    - Verdict: **FAIL** (automatic, no exceptions)\n    - Each occurrence MUST be listed with file:line\n    \n    ### 1. Structured Logging (lib-commons)\n    - [ ] Uses `libCommons.NewTrackingFromContext(ctx)` for logger (Go)\n    - [ ] Uses `initializeLogger()` from lib-common-js (TypeScript)\n    - [ ] JSON format with timestamp, level, message, service\n    - [ ] trace_id correlation in logs\n    - [ ] **no FORBIDDEN patterns** (see check 0 above)\n\n    ### 2. Instrumentation Coverage (90%+ required)\n    For [language], check these patterns:\n\n    **Go (lib-commons):**\n    ```go\n    logger, tracer, _, _ := libCommons.NewTrackingFromContext(ctx)\n    ctx, span := tracer.Start(ctx, \"layer.operation\")\n    defer span.End()\n    ```\n\n    **TypeScript:**\n    ```typescript\n    const span = tracer.startSpan('layer.operation');\n    try { /* work */ } finally { span.end(); }\n    ```\n\n    Count spans in:\n    - Handlers: grep \"tracer.Start\" in *handler*.go or *controller*.ts\n    - Services: grep \"tracer.Start\" in *service*.go or *service*.ts\n    - Repositories: grep \"tracer.Start\" in *repo*.go or *repository*.ts\n\n    ### 3. Context Propagation\n    For external calls, verify:\n    - HTTP: InjectHTTPContext (Go) or equivalent\n    - gRPC: InjectGRPCContext (Go) or equivalent\n    - Queues: PrepareQueueHeaders (Go) or equivalent\n\n    ## Required Output Format\n\n    ### Validation Summary\n    | Check | Status | Evidence |\n    |-------|--------|----------|\n    | Structured Logging | / | [file:line or \"not FOUND\"] |\n    | Tracing Enabled | / | [file:line or \"not FOUND\"] |\n    | Instrumentation 90% | / | [X%] |\n    | Context Propagation | //N/A | [file:line or \"N/A\"] |\n\n    ### Instrumentation Coverage Table\n    | Layer | Instrumented | Total | Coverage |\n    |-------|--------------|-------|----------|\n    | Handlers | X | Y | Z% |\n    | Services | X | Y | Z% |\n    | Repositories | X | Y | Z% |\n    | HTTP Clients | X | Y | Z% |\n    | gRPC Clients | X | Y | Z% |\n    | **TOTAL** | X | Y | **Z%** |\n\n    ### Issues Found (if any)\n    For each issue:\n    - **Severity:** CRITICAL/HIGH/MEDIUM/LOW\n    - **Category:** [Logging|Tracing|Instrumentation|Propagation]\n    - **Description:** [what's wrong]\n    - **File:** [path:line]\n    - **Expected:** [what should exist]\n    - **Fix Required By:** [implementation_agent]\n\n    ### Verdict\n    - **all CHECKS PASSED:**  YES /  no\n    - **Instrumentation Coverage:** [X%]\n    - **If no, blocking issues:** [list]\n```\n\n## Step 4: Parse SRE Agent Output\n\n```text\nParse agent output:\n\n1. Extract Validation Summary table\n2. Extract Instrumentation Coverage table\n3. Extract Issues Found list\n4. Extract Verdict\n\nvalidation_state.sre_result = {\n  logging_ok: [true/false],\n  tracing_ok: [true/false],\n  instrumentation_coverage: [percentage],\n  context_propagation_ok: [true/false/na],\n  issues: [list of issues],\n  verdict: [PASS/FAIL]\n}\n```\n\n## Step 5: Handle Validation Result\n\n```text\nif validation_state.sre_result.verdict == \"PASS\" \n   and validation_state.sre_result.instrumentation_coverage >= 90:\n   Go to Step 8 (Success)\n\nif validation_state.sre_result.verdict == \"FAIL\"\n   or validation_state.sre_result.instrumentation_coverage < 90:\n   Go to Step 6 (Dispatch Fix)\n\nif validation_state.iteration >= validation_state.max_iterations:\n   Go to Step 9 (Escalate)\n```\n\n## Step 6: Dispatch Fix to Implementation Agent\n\n```yaml\nTask:\n  subagent_type: \"[implementation_agent from input]\"  # e.g., \"ring:backend-engineer-golang\"\n  model: \"opus\"\n  description: \"Fix observability issues for [unit_id]\"\n  prompt: |\n     FIX REQUIRED - Observability Issues Found\n\n    ## Context\n    - **Unit ID:** [unit_id]\n    - **Iteration:** [validation_state.iteration] of [validation_state.max_iterations]\n    - **Your Previous Implementation:** [implementation_files]\n\n    ## Issues to Fix (from SRE Validation)\n    [paste issues from validation_state.sre_result.issues]\n\n    ## Current Instrumentation Coverage\n    [paste Instrumentation Coverage table from SRE output]\n    **Required:** 90%\n    **Current:** [validation_state.sre_result.instrumentation_coverage]%\n\n    ## Standards Reference\n    For Go: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md\n    For TS: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/typescript.md\n\n    Focus on: Telemetry & Observability section\n\n    ## Required Fixes\n\n    ### If Logging Issues:\n    - Replace fmt.Println/console.log with structured logger\n    - Add trace_id to log context\n    - Use JSON format\n\n    ### If Instrumentation Coverage < 90%:\n    - Add spans to all handlers: `tracer.Start(ctx, \"handler.name\")`\n    - Add spans to all services: `tracer.Start(ctx, \"service.domain.operation\")`\n    - Add spans to all repositories: `tracer.Start(ctx, \"db.operation\")`\n    - Add `defer span.End()` after each span creation\n\n    ### If Context Propagation Issues:\n    - Add InjectHTTPContext for outgoing HTTP calls\n    - Add InjectGRPCContext for outgoing gRPC calls\n    - Add PrepareQueueHeaders for queue publishing\n\n    ## Required Output\n    - Files modified with fixes\n    - New Instrumentation Coverage calculation\n    - Confirmation all issues addressed\n```\n\n## Step 7: Re-Validate After Fix\n\n```text\nvalidation_state.iteration += 1\n\nif validation_state.iteration > validation_state.max_iterations:\n   Go to Step 9 (Escalate)\n\n Go back to Step 3 (Dispatch SRE Agent)\n```\n\n## Step 8: Success - Prepare Output\n\n```text\nGenerate skill output:\n\n## Validation Result\n**Status:** PASS\n**Iterations:** [validation_state.iteration]\n**Instrumentation Coverage:** [validation_state.sre_result.instrumentation_coverage]%\n\n## Instrumentation Coverage\n[paste final Instrumentation Coverage table]\n\n## Issues Found\nNone (all resolved)\n\n## Handoff to Next Gate\n- SRE validation: COMPLETE\n- Logging:  Structured JSON with trace_id\n- Tracing:  OpenTelemetry instrumented\n- Instrumentation:  [X]% coverage\n- Ready for Gate 3 (Testing): YES\n```\n\n## Step 9: Escalate - Max Iterations Reached\n\n```text\nGenerate skill output:\n\n## Validation Result\n**Status:** FAIL\n**Iterations:** [validation_state.iteration] (MAX REACHED)\n**Instrumentation Coverage:** [validation_state.sre_result.instrumentation_coverage]%\n\n## Instrumentation Coverage\n[paste final Instrumentation Coverage table]\n\n## Issues Found\n[list remaining unresolved issues]\n\n## Handoff to Next Gate\n- SRE validation: FAILED\n- Remaining issues: [count]\n- Ready for Gate 3 (Testing): no\n- **Action Required:** User must manually resolve remaining issues\n\n ESCALATION: Max iterations (3) reached. User intervention required.\n```\n\n---\n\n## Severity Calibration\n\n| Severity | Scenario | Gate 2 Status | Action |\n|----------|----------|---------------|--------|\n| **CRITICAL** | Missing all observability (no structured logs) | FAIL |  Return to Gate 0 |\n| **CRITICAL** | fmt.Println/echo instead of JSON logs | FAIL |  Return to Gate 0 |\n| **CRITICAL** | Instrumentation coverage < 50% | FAIL |  Return to Gate 0 |\n| **CRITICAL** | \"DEFERRED\" appears in validation output | FAIL |  Return to Gate 0 |\n| **HIGH** | Instrumentation coverage 50-89% | NEEDS_FIXES |  Fix and re-validate |\n| **MEDIUM** | Missing context propagation | NEEDS_FIXES |  Fix and re-validate |\n| **LOW** | Minor logging improvements | PASS |  Note for future |\n\n---\n\n## Blocker Criteria - STOP and Report\n\n<block_condition>\nIf any condition is true, STOP and dispatch fix or escalate to user.\n- Service lacks JSON-structured logs\n- Instrumentation coverage < 50%\n- Max iterations (3) reached\n</block_condition>\n\n| Decision Type | Examples | Action |\n|---------------|----------|--------|\n| **HARD BLOCK** | Service lacks JSON structured logs | **STOP** - Dispatch fix to implementation agent |\n| **HARD BLOCK** | Instrumentation coverage < 50% | **STOP** - Dispatch fix to implementation agent |\n| **HARD BLOCK** | Max iterations reached | **STOP** - Escalate to user |\n\n---\n\n### Cannot Be Overridden\n\n<cannot_skip>\n- Gate 2 execution (no MVP exemptions)\n- 90% instrumentation coverage minimum\n- JSON structured logs requirement\n</cannot_skip>\n\n| Requirement | Cannot Be Waived By | Rationale |\n|-------------|---------------------|-----------|\n| Gate 2 execution | CTO, PM, \"MVP\" arguments | Observability prevents production blindness |\n| 90% instrumentation coverage | \"We'll add spans later\" | Later = never. Instrument during implementation. |\n| JSON structured logs | \"Plain text is enough\" | Plain text is unsearchable in production |\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Skip SRE validation\" | \"Observability is MANDATORY. Dispatching SRE agent now.\" |\n| \"90% coverage is too high\" | \"90% is the Ring Standard minimum. Cannot lower.\" |\n| \"Will add instrumentation later\" | \"Instrumentation is part of implementation. Fix now.\" |\n\n---\n\n## Anti-Rationalization Table\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations.\n\n### Gate 2-Specific Anti-Rationalizations\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"OpenTelemetry library is installed\" | Installation  Instrumentation | **Verify spans exist in code** |\n| \"Middleware handles tracing\" | Middleware = root span only | **Add child spans in all layers** |\n| \"Small function doesn't need span\" | Size is irrelevant | **Add span to every function** |\n| \"Only external calls need tracing\" | Internal ops need tracing too | **Instrument all layers** |\n| \"Feature complete, observability later\" | Observability IS completion | **Fix NOW before Gate 3** |\n\n## Component Type Requirements\n\n| Type | JSON Logs | Tracing | Instrumentation |\n|------|-----------|---------|-----------------|\n| **API Service** | REQUIRED | REQUIRED | 90%+ |\n| **Background Worker** | REQUIRED | REQUIRED | 90%+ |\n| **CLI Tool** | REQUIRED | N/A | N/A |\n| **Library** | N/A | N/A | N/A |\n\n---\n\n## Execution Report Format\n\n```markdown\n## Validation Result\n**Status:** [PASS|FAIL|NEEDS_FIXES]\n**Iterations:** [N]\n**Duration:** [Xm Ys]\n\n## Instrumentation Coverage\n| Layer | Instrumented | Total | Coverage |\n|-------|--------------|-------|----------|\n| Handlers | X | Y | Z% |\n| Services | X | Y | Z% |\n| Repositories | X | Y | Z% |\n| HTTP Clients | X | Y | Z% |\n| gRPC Clients | X | Y | Z% |\n| **TOTAL** | X | Y | **Z%** |\n\n**Coverage Status:** [PASS (90%) | NEEDS_FIXES (50-89%) | FAIL (<50%)]\n\n## Issues Found\n- [List by severity or \"None\"]\n\n## Handoff to Next Gate\n- SRE validation status: [complete|needs_fixes|failed]\n- Instrumentation coverage: [X%]\n- Ready for testing: [YES|no]\n```"
              },
              {
                "name": "ring:dev-testing",
                "description": "Gate 3 of development cycle - ensures unit test coverage meets threshold (85%+)\nfor all acceptance criteria using TDD methodology.\n",
                "path": "dev-team/skills/dev-testing/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-testing",
                  "description": "Gate 3 of development cycle - ensures unit test coverage meets threshold (85%+)\nfor all acceptance criteria using TDD methodology.\n",
                  "trigger": "- After implementation and SRE complete (Gate 0/1/2)\n- Task has acceptance criteria requiring test coverage\n- Need to verify implementation meets requirements\n",
                  "NOT_skip_when": "- \"Manual testing validates all criteria\"  Manual tests are not executable. Gate 3 requires unit tests.\n- \"Integration tests are better\"  Gate 3 scope is unit tests only.\n- \"Coverage is close to 85%\"  Close enough is not passing. Meet exact threshold.\n",
                  "sequence": {
                    "after": [
                      "dev-implementation",
                      "dev-devops",
                      "dev-sre"
                    ],
                    "before": [
                      "requesting-code-review"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "test-driven-development",
                      "qa-analyst"
                    ]
                  },
                  "input_schema": {
                    "required": [
                      {
                        "name": "unit_id",
                        "type": "string",
                        "description": "Task or subtask identifier"
                      },
                      {
                        "name": "acceptance_criteria",
                        "type": "array",
                        "items": "string",
                        "description": "List of acceptance criteria to test"
                      },
                      {
                        "name": "implementation_files",
                        "type": "array",
                        "items": "string",
                        "description": "Files from Gate 0 implementation"
                      },
                      {
                        "name": "language",
                        "type": "string",
                        "enum": [
                          "go",
                          "typescript",
                          "python"
                        ],
                        "description": "Programming language"
                      }
                    ],
                    "optional": [
                      {
                        "name": "coverage_threshold",
                        "type": "float",
                        "default": 85,
                        "description": "Minimum coverage percentage (cannot be below 85)"
                      },
                      {
                        "name": "gate0_handoff",
                        "type": "object",
                        "description": "Full handoff from Gate 0"
                      },
                      {
                        "name": "existing_tests",
                        "type": "array",
                        "items": "string",
                        "description": "Existing test files"
                      }
                    ]
                  },
                  "output_schema": {
                    "format": "markdown",
                    "required_sections": [
                      {
                        "name": "Testing Summary",
                        "pattern": "^## Testing Summary",
                        "required": true
                      },
                      {
                        "name": "Coverage Report",
                        "pattern": "^## Coverage Report",
                        "required": true
                      },
                      {
                        "name": "Traceability Matrix",
                        "pattern": "^## Traceability Matrix",
                        "required": true
                      },
                      {
                        "name": "Handoff to Next Gate",
                        "pattern": "^## Handoff to Next Gate",
                        "required": true
                      }
                    ],
                    "metrics": [
                      {
                        "name": "result",
                        "type": "enum",
                        "values": [
                          "PASS",
                          "FAIL"
                        ]
                      },
                      {
                        "name": "coverage_actual",
                        "type": "float"
                      },
                      {
                        "name": "coverage_threshold",
                        "type": "float"
                      },
                      {
                        "name": "tests_written",
                        "type": "integer"
                      },
                      {
                        "name": "criteria_covered",
                        "type": "string",
                        "description": "X/Y format"
                      },
                      {
                        "name": "iterations",
                        "type": "integer"
                      }
                    ]
                  },
                  "verification": {
                    "automated": [
                      {
                        "command": "go test ./... -covermode=atomic -coverprofile=coverage.out && go tool cover -func=coverage.out | grep total",
                        "description": "Go tests pass with coverage",
                        "success_pattern": "total:.*[8-9][0-9]|100"
                      },
                      {
                        "command": "npm test -- --coverage | grep -E 'All files|Statements'",
                        "description": "TypeScript tests pass with coverage",
                        "success_pattern": "[8-9][0-9]|100"
                      }
                    ],
                    "manual": [
                      "Every acceptance criterion has at least one test",
                      "No skipped or pending tests"
                    ]
                  },
                  "examples": [
                    {
                      "name": "TDD for auth service",
                      "input": {
                        "unit_id": "task-001",
                        "acceptance_criteria": [
                          "User can login with valid credentials",
                          "Invalid password returns error"
                        ],
                        "implementation_files": [
                          "internal/service/auth.go"
                        ],
                        "language": "go"
                      },
                      "expected_output": "## Testing Summary\n**Status:** PASS\n**Coverage:** 89.5%\n\n## Coverage Report\n| Package | Coverage |\n|---------|----------|\n| internal/service | 89.5% |\n\n## Traceability Matrix\n| AC | Test | Status |\n|----|------|--------|\n| AC-1 | TestAuthService_Login_ValidCredentials |  |\n| AC-2 | TestAuthService_Login_InvalidPassword |  |\n\n## Handoff to Next Gate\n- Ready for Gate 4: YES\n"
                    }
                  ]
                },
                "content": "# Dev Testing (Gate 3)\n\n## Overview\n\nEnsure every acceptance criterion has at least one **unit test** proving it works. Follow TDD methodology: RED (failing test) -> GREEN (implementation) -> REFACTOR.\n\n**Core principle:** Untested acceptance criteria are unverified claims. Each criterion MUST map to at least one executable unit test.\n\n<block_condition>\n- Coverage below 85% = FAIL\n- Any acceptance criterion without test = FAIL\n</block_condition>\n\n**Coverage threshold:** 85% minimum (Ring standard). PROJECT_RULES.md can raise, not lower.\n\n## CRITICAL: Role Clarification\n\n**This skill ORCHESTRATES. QA Analyst Agent EXECUTES.**\n\n| Who | Responsibility |\n|-----|----------------|\n| **This Skill** | Gather requirements, dispatch agent, track iterations |\n| **QA Analyst Agent** | Write tests, run coverage, report results |\n\n---\n\n## Step 1: Validate Input\n\n```text\nREQUIRED INPUT (from dev-cycle orchestrator):\n<verify_before_proceed>\n- unit_id exists\n- acceptance_criteria is not empty\n- implementation_files is not empty\n- language is valid (go|typescript|python)\n</verify_before_proceed>\n\n```text\n- unit_id: [task/subtask being tested]\n- acceptance_criteria: [list of ACs to test]\n- implementation_files: [files from Gate 0]\n- language: [go|typescript|python]\n\nOPTIONAL INPUT:\n- coverage_threshold: [default 85.0, cannot be lower]\n- gate0_handoff: [full Gate 0 output]\n- existing_tests: [existing test files]\n\nif any REQUIRED input is missing:\n   STOP and report: \"Missing required input: [field]\"\n   Return to orchestrator with error\n\nif coverage_threshold < 85:\n   STOP and report: \"Coverage threshold cannot be below Ring minimum (85%)\"\n   Use 85% as threshold\n```\n\n## Step 2: Initialize Testing State\n\n```text\ntesting_state = {\n  unit_id: [from input],\n  coverage_threshold: max(85, [from input]),\n  coverage_actual: null,\n  verdict: null,\n  iterations: 0,\n  max_iterations: 3,\n  traceability_matrix: [],\n  tests_written: 0\n}\n```\n\n## Step 3: Dispatch QA Analyst Agent\n\n<dispatch_required agent=\"qa-analyst\" model=\"opus\">\nWrite unit tests for all acceptance criteria with 85%+ coverage.\n</dispatch_required>\n\n```yaml\nTask:\n  subagent_type: \"ring:qa-analyst\"\n  model: \"opus\"\n  description: \"Write unit tests for [unit_id]\"\n  prompt: |\n     WRITE UNIT TESTS for All Acceptance Criteria\n\n    ## Input Context\n    - **Unit ID:** [unit_id]\n    - **Language:** [language]\n    - **Coverage Threshold:** [coverage_threshold]%\n\n    ## Acceptance Criteria to Test\n    [list acceptance_criteria with AC-1, AC-2, etc.]\n\n    ## Implementation Files to Test\n    [list implementation_files]\n\n    ## Standards Reference\n    For Go: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md\n    For TS: https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/typescript.md\n\n    Focus on: Testing Patterns section\n\n    ## Requirements\n\n    ### Test Coverage\n    - Minimum: [coverage_threshold]% branch coverage\n    - Every AC MUST have at least one test\n    - Edge cases REQUIRED (null, empty, boundary, error conditions)\n\n    ### Test Naming\n    - Go: `Test{Unit}_{Method}_{Scenario}`\n    - TS: `describe('{Unit}', () => { it('should {scenario}', ...) })`\n\n    ### Test Structure\n    - One behavior per test\n    - Arrange-Act-Assert pattern\n    - Mock all external dependencies\n    - no database/API calls (unit tests only)\n\n    ### Edge Cases Required per AC Type\n\n    <cannot_skip>\n    - Minimum 3 edge cases per AC type\n    - null, empty, boundary conditions required\n    - Error conditions required\n    </cannot_skip>\n\n    | AC Type | Required Edge Cases | Minimum |\n    |---------|---------------------|---------|\n    | Input validation | null, empty, boundary, invalid format | 3+ |\n    | CRUD operations | not found, duplicate, concurrent | 3+ |\n    | Business logic | zero, negative, overflow, boundary | 3+ |\n    | Error handling | timeout, connection failure, retry | 2+ |\n\n    ## Required Output Format\n\n    ### Test Files Created\n    | File | Tests | Lines |\n    |------|-------|-------|\n    | [path] | [count] | +N |\n\n    ### Coverage Report\n    **Command:** [coverage command]\n    **Result:**\n    ```\n    [paste actual coverage output]\n    ```\n\n    | Package/File | Coverage |\n    |--------------|----------|\n    | [name] | [X%] |\n    | **TOTAL** | **[X%]** |\n\n    ### Traceability Matrix\n    | AC ID | Criterion | Test File | Test Function | Status |\n    |-------|-----------|-----------|---------------|--------|\n    | AC-1 | [criterion text] | [file] | [function] | / |\n    | AC-2 | [criterion text] | [file] | [function] | / |\n\n    ### Quality Checks\n    | Check | Status |\n    |-------|--------|\n    | No skipped tests | / |\n    | No assertion-less tests | / |\n    | Edge cases per AC | / |\n    | Test isolation | / |\n\n    ### VERDICT\n    **Coverage:** [X%] vs Threshold [Y%]\n    **VERDICT:** PASS / FAIL\n    \n    If FAIL:\n    - **Gap Analysis:** [what needs more tests]\n    - **Files needing coverage:** [list with line numbers]\n```\n\n## Step 4: Parse QA Analyst Output\n\n```text\nParse agent output:\n\n1. Extract coverage percentage from Coverage Report\n2. Extract traceability matrix\n3. Extract verdict\n\ntesting_state.coverage_actual = [extracted coverage]\ntesting_state.traceability_matrix = [extracted matrix]\ntesting_state.tests_written = [count from Test Files Created]\n\nif verdict == \"PASS\" and coverage_actual >= coverage_threshold:\n   testing_state.verdict = \"PASS\"\n   Proceed to Step 6\n\nif verdict == \"FAIL\" or coverage_actual < coverage_threshold:\n   testing_state.verdict = \"FAIL\"\n   testing_state.iterations += 1\n   if iterations >= max_iterations: Go to Step 7 (Escalate)\n   Go to Step 5 (Dispatch Fix)\n```\n\n## Step 5: Dispatch Fix to Implementation Agent\n\n**Coverage below threshold  Return to Gate 0 for more tests**\n\n```yaml\nTask:\n  subagent_type: \"[implementation_agent from Gate 0]\"  # e.g., \"ring:backend-engineer-golang\"\n  model: \"opus\"\n  description: \"Add tests to meet coverage threshold for [unit_id]\"\n  prompt: |\n     COVERAGE BELOW THRESHOLD - Add More Tests\n\n    ## Current Status\n    - **Coverage Actual:** [coverage_actual]%\n    - **Coverage Threshold:** [coverage_threshold]%\n    - **Gap:** [threshold - actual]%\n    - **Iteration:** [iterations] of [max_iterations]\n\n    ## Gap Analysis (from QA)\n    [paste gap analysis from QA output]\n\n    ## Files Needing Coverage\n    [paste files list from QA output]\n\n    ## Requirements\n    1. Add tests to cover the identified gaps\n    2. Focus on edge cases and error paths\n    3. Run coverage after each addition\n    4. Stop when coverage >= [threshold]%\n\n    ## Required Output\n    - Tests added: [list]\n    - New coverage: [X%]\n    - Coverage command output\n```\n\nAfter fix  Go back to Step 3 (Re-dispatch QA Analyst)\n\n## Step 6: Prepare Success Output\n\n```text\nGenerate skill output:\n\n## Testing Summary\n**Status:** PASS\n**Unit ID:** [unit_id]\n**Iterations:** [testing_state.iterations]\n\n## Coverage Report\n**Threshold:** [coverage_threshold]%\n**Actual:** [coverage_actual]%\n**Status:**  PASS\n\n| Package/File | Coverage |\n|--------------|----------|\n[from QA output]\n| **TOTAL** | **[coverage_actual]%** |\n\n## Traceability Matrix\n| AC ID | Criterion | Test | Status |\n|-------|-----------|------|--------|\n[from testing_state.traceability_matrix]\n\n**Criteria Covered:** [X]/[Y] (100%)\n\n## Quality Checks\n| Check | Status |\n|-------|--------|\n| Coverage  threshold |  |\n| All ACs tested |  |\n| No skipped tests |  |\n| Edge cases present |  |\n\n## Handoff to Next Gate\n- Testing status: COMPLETE\n- Coverage: [coverage_actual]% (threshold: [coverage_threshold]%)\n- All criteria tested: \n- Ready for Gate 4 (Review): YES\n```\n\n## Step 7: Escalate - Max Iterations Reached\n\n```text\nGenerate skill output:\n\n## Testing Summary\n**Status:** FAIL\n**Unit ID:** [unit_id]\n**Iterations:** [max_iterations] (MAX REACHED)\n\n## Coverage Report\n**Threshold:** [coverage_threshold]%\n**Actual:** [coverage_actual]%\n**Gap:** [threshold - actual]%\n**Status:**  FAIL\n\n## Gap Analysis\n[from last QA output]\n\n## Files Still Needing Coverage\n[from last QA output]\n\n## Handoff to Next Gate\n- Testing status: FAILED\n- Ready for Gate 4: no\n- **Action Required:** User must manually add tests or adjust scope\n\n ESCALATION: Max iterations (3) reached. Coverage still below threshold.\nUser intervention required.\n```\n\n---\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"84% is close enough\" | \"85% is minimum threshold. 84% = FAIL. Adding more tests.\" |\n| \"Manual testing covers it\" | \"Gate 3 requires executable unit tests. Dispatching QA analyst.\" |\n| \"Skip testing, deadline\" | \"Testing is MANDATORY. Untested code = unverified claims.\" |\n\n---\n\n## Anti-Rationalization Table\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations.\n\n### Gate 3-Specific Anti-Rationalizations\n\n| Rationalization | Why It's WRONG | Required Action |\n|-----------------|----------------|-----------------|\n| \"Tool shows 83% but real is 90%\" | Tool output IS real. Your belief is not. | **Fix issue, re-measure** |\n| \"Excluding dead code gets us to 85%\" | Delete dead code, don't exclude it. | **Delete dead code** |\n| \"84.5% rounds to 85%\" | Rounding is not allowed. 84.5% < 85%. | **Write more tests** |\n| \"Close enough with all AC tested\" | \"Close enough\" is not passing. | **Meet exact threshold** |\n| \"Integration tests cover this\" | Gate 3 = unit tests only. Different scope. | **Write unit tests** |\n\n## Unit Test vs Integration Test\n\n| Type | Characteristics | Gate 3? |\n|------|----------------|---------|\n| **Unit**  | Mocks all external deps, tests single function | YES |\n| **Integration**  | Hits real database/API/filesystem | no |\n\n---\n\n## Execution Report Format\n\n```markdown\n## Testing Summary\n**Status:** [PASS|FAIL]\n**Unit ID:** [unit_id]\n**Duration:** [Xm Ys]\n**Iterations:** [N]\n\n## Coverage Report\n**Threshold:** [X%]\n**Actual:** [Y%]\n**Status:** [ PASS |  FAIL]\n\n## Traceability Matrix\n| AC ID | Criterion | Test | Status |\n|-------|-----------|------|--------|\n| AC-1 | [text] | [test] | / |\n\n**Criteria Covered:** [X/Y]\n\n## Handoff to Next Gate\n- Testing status: [COMPLETE|FAILED]\n- Coverage: [X%]\n- Ready for Gate 4: [YES|no]\n```"
              },
              {
                "name": "ring:dev-validation",
                "description": "Development cycle validation gate (Gate 5) - validates all acceptance criteria are met\nand requires explicit user approval before completion.\n",
                "path": "dev-team/skills/dev-validation/SKILL.md",
                "frontmatter": {
                  "name": "ring:dev-validation",
                  "description": "Development cycle validation gate (Gate 5) - validates all acceptance criteria are met\nand requires explicit user approval before completion.\n",
                  "trigger": "- After review gate passes (Gate 4)\n- Implementation and tests complete\n- Need user sign-off on acceptance criteria\n",
                  "NOT_skip_when": "- \"Already validated\"  Each iteration needs fresh validation.\n- \"User will validate manually\"  Gate 5 IS user validation. Cannot skip.\n",
                  "sequence": {
                    "after": [
                      "requesting-code-review"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "verification-before-completion"
                    ]
                  },
                  "verification": {
                    "automated": [
                      {
                        "command": "go test ./... 2>&1 | grep -c PASS",
                        "description": "All tests pass",
                        "success_pattern": "[1-9][0-9]*"
                      },
                      {
                        "command": "cat docs/dev-cycle/current-cycle.json 2>/dev/null || cat docs/dev-refactor/current-cycle.json | jq '.gates[4].verdict'",
                        "description": "Review gate passed",
                        "success_pattern": "PASS"
                      }
                    ],
                    "manual": [
                      "User has provided explicit APPROVED or REJECTED decision",
                      "All acceptance criteria have verified evidence",
                      "Validation checklist presented to user"
                    ]
                  },
                  "examples": [
                    {
                      "name": "Successful validation",
                      "context": "4 acceptance criteria, all tests pass",
                      "expected_flow": "1. Gather evidence for each criterion\n2. Build validation checklist with evidence types\n3. Present to user with APPROVED/REJECTED options\n4. User selects APPROVED\n5. Document approval, proceed to feedback loop\n"
                    },
                    {
                      "name": "Validation rejection",
                      "context": "AC-3 not met (response time too slow)",
                      "expected_flow": "1. Present validation checklist\n2. User identifies AC-3 failure\n3. User selects REJECTED with reason\n4. Create remediation task\n5. Return to Gate 0 for fixes\n"
                    }
                  ]
                },
                "content": "# Dev Validation (Gate 5)\n\n## Overview\n\nFinal validation gate requiring explicit user approval. Present evidence that each acceptance criterion is met and obtain APPROVED or REJECTED decision.\n\n**Core principle:** Passing tests and code review DO NOT guarantee requirements are met. User validation confirms implementation matches intent.\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios.\n\n**Gate 5-specific note:** User MUST respond with \"APPROVED\" or \"REJECTED: [reason]\". No other responses accepted. Silence  approval.\n\n## Self-Approval Prohibition\n\n<forbidden>\n- Same agent approving code it implemented\n- Role switching to self-approve (e.g., ring:backend-engineer  ring:code-reviewer)\n- Interpreting silence as approval\n- Proceeding without explicit APPROVED/REJECTED\n</forbidden>\n\n**HARD GATE:** The agent that implemented code CANNOT approve validation for that same code.\n\n| Scenario | Allowed? | Action |\n|----------|----------|--------|\n| Different agent/human approves | YES | Proceed with approval |\n| Same agent self-approves | no | STOP - requires external approval |\n| User explicitly approves | YES | User approval always valid |\n\n**If you implemented the code, you CANNOT approve it. Wait for user or different reviewer.**\n\n**Important:** \"Different agent\" means different human/entity. The same human using different agent roles (backend-engineer  code-reviewer) is STILL self-approval and PROHIBITED.\n\nSee [CLAUDE.md](https://raw.githubusercontent.com/LerianStudio/ring/main/CLAUDE.md) for the canonical validation policy.\n\n---\n\n## Severity Calibration\n\n**When presenting validation results to user, issues are categorized by severity:**\n\n| Severity | Criteria | Examples | Action Required |\n|----------|----------|----------|-----------------|\n| **CRITICAL** | Acceptance criterion completely unmet | AC-1: \"User can login\" but login doesn't work at all | MUST fix before approval. Return to Gate 0. |\n| **HIGH** | Acceptance criterion partially met or degraded | AC-2: \"Response < 200ms\" but actually 800ms | MUST fix before approval. Return to Gate 0. |\n| **MEDIUM** | Edge case or non-critical requirement gap | AC-3 met for happy path, fails for empty input | SHOULD fix before approval. User decides. |\n| **LOW** | Quality issue, requirement technically met | Code works but is hard to understand/maintain | MAY fix or document. User decides. |\n\n**Severity Assignment Rules:**\n- Unmet acceptance criterion = CRITICAL (requirement not satisfied)\n- Degraded performance/quality vs criterion = HIGH (requirement barely met)\n- Edge case failures = MEDIUM (main path works, edges don't)\n- Quality/maintainability with working code = LOW (works but suboptimal)\n\n**Why This Matters:**\n- User needs to understand impact severity when deciding APPROVED vs REJECTED\n- CRITICAL/HIGH = automatic REJECTED recommendation\n- MEDIUM/LOW = user judgment call with context\n\n**Example Validation Checklist with Severity:**\n```markdown\n## Validation Results\n\n| AC # | Criterion | Evidence | Status | Severity |\n|------|-----------|----------|--------|----------|\n| AC-1 | User can login |  Tests pass, manual verification | MET | - |\n| AC-2 | Response < 200ms |  Measured 350ms average | not MET | HIGH |\n| AC-3 | Input validation |  Works for valid input, crashes on empty | PARTIAL | MEDIUM |\n| AC-4 | Error messages clear |  All errors have user-friendly messages | MET | - |\n\n**Overall Validation:** REJECTED (1 HIGH issue: AC-2 response time)\n\n**Recommendation:** Fix AC-2 (HIGH) before approval. AC-3 (MEDIUM) user can decide.\n```\n\n---\n\n## Common Rationalizations - REJECTED\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations (including Validation section).\n\n**Gate 5-specific rationalizations:**\n\n| Excuse | Reality |\n|--------|---------|\n| \"Async over sync - work in parallel\" | Validation is a GATE, not async task. STOP means STOP. |\n| \"Continue other tasks while waiting\" | Other tasks may conflict. Validation blocks all related work. |\n| \"User delegated approval to X\" | Delegation  stakeholder approval. Only original requester can approve. |\n| \"I implemented it, I know requirements\" | Knowledge  approval authority. Implementer CANNOT self-approve. |\n| \"I'll switch to QA role to approve\" | Role switching is STILL self-approval. PROHIBITED. |\n\n## Red Flags - STOP\n\nSee [shared-patterns/shared-red-flags.md](../shared-patterns/shared-red-flags.md) for universal red flags (including Validation section).\n\nIf you catch yourself thinking any of those patterns, STOP immediately. Wait for explicit \"APPROVED\" or \"REJECTED\".\n\n---\n\n## Ambiguous Response Handling\n\n<block_condition>\n- Response is \"Looks good\", \"Sure\", \"Ok\", \"Fine\"\n- Response is emoji only (, )\n- Response is \"Go ahead\", \"Ship it\"\n- Response contains conditional (\"APPROVED if X\", \"APPROVED with caveats\")\n</block_condition>\n\nIf any condition matches, ask for explicit APPROVED or REJECTED.\n\n**User responses that are not valid approvals:**\n\n| Response | Status | Action Required |\n|----------|--------|-----------------|\n| \"Looks good\" |  AMBIGUOUS | \"To confirm, please respond with APPROVED or REJECTED: [reason]\" |\n| \"Sure\" / \"Ok\" / \"Fine\" |  AMBIGUOUS | Ask for explicit APPROVED |\n| \"\" / \"\" |  AMBIGUOUS | Emojis are not formal approval. Ask for APPROVED. |\n| \"Go ahead\" |  AMBIGUOUS | Ask for explicit APPROVED |\n| \"Ship it\" |  AMBIGUOUS | Ask for explicit APPROVED |\n| \"APPROVED\" |  VALID | Proceed to next gate |\n| \"REJECTED: [reason]\" |  VALID | Document reason, return to Gate 0 |\n| \"APPROVED if X\" |  CONDITIONAL | Not approved until X is verified. Status = PENDING. |\n| \"APPROVED with caveats\" |  CONDITIONAL | Not approved. List caveats, verify each, then re-ask. |\n| \"APPROVED but fix Y later\" |  CONDITIONAL | Not approved. Y must be addressed first. |\n\n**When user gives ambiguous response:**\n```\n\"Thank you for the feedback. For formal validation, please confirm with:\n- APPROVED - to proceed with completion\n- REJECTED: [reason] - to return for fixes\n\nWhich is your decision?\"\n```\n\n**Never interpret intent. Require explicit keyword.**\n\n---\n\n## Awaiting Approval - STOP all WORK\n\n<cannot_skip>\n- STOP all work when validation request is presented\n- Wait for explicit APPROVED or REJECTED\n- Do not proceed with any \"quick fixes\" while waiting\n</cannot_skip>\n\n**When validation request is presented:**\n\n1. **STOP all WORK** on this feature, module, and related code\n2. **DO not** proceed to documentation, refactoring, or \"quick fixes\"\n3. **DO not** work on \"unrelated\" tasks in the same codebase\n4. **WAIT** for explicit user response\n\n**User unavailability is not permission to:**\n- Assume approval\n- Work on \"low-risk\" next steps\n- Redefine criteria as \"already met\"\n- Proceed with \"we'll fix issues later\"\n\n**Document pending status and WAIT.**\n\n## Approval Format - MANDATORY\n\n<user_decision>\nValid responses:\n- \"APPROVED\"  Proceed to next gate\n- \"REJECTED: [reason]\"  Return for fixes\n</user_decision>\n\n**User MUST respond with exactly one of:**\n\n **\"APPROVED\"** - All criteria verified, proceed to next gate\n **\"REJECTED: [specific reason]\"** - Issues found, fix and revalidate\n\n**not acceptable:**\n-  \"Looks good\" (vague)\n-  \"\" (ambiguous)\n-  Silence (not a response)\n-  \"Approved with minor issues\" (partial = REJECTED)\n\n**If user provides ambiguous response, ask for explicit APPROVED or REJECTED.**\n\n---\n\n## Prerequisites\n\nBefore starting this gate:\n- All tests pass (Gate 3 verified)\n- Code review passed (Gate 4 VERDICT: PASS)\n- Implementation is complete and stable\n\n## Steps 1-4: Evidence Collection and Validation\n\n| Step | Action | Output |\n|------|--------|--------|\n| **1. Gather Evidence** | Collect proof per criterion | Table: Criterion, Evidence Type (Test/Demo/Log/Manual/Metric), Location, Status |\n| **2. Verify** | Execute verification (automated: `npm test --grep \"AC-X\"`, manual: documented steps with Result + Screenshot) | VERIFIED/FAILED per criterion |\n| **3. Build Checklist** | For each AC: Status + Evidence list + Verification method | Validation Checklist |\n| **4. Present Request** | Task Summary + Validation Table + Test Results + Review Summary + Artifacts | USER DECISION block with APPROVED/REJECTED options |\n\n**Validation Request format:**\n```\nVALIDATION REQUEST - [TASK-ID]\nTask: [title], [description], [date]\nCriteria: Table (Criterion | Status | Evidence)\nTests: Total/Passed/Failed/Coverage\nReview: VERDICT + issue counts\nArtifacts: Code, Tests, Docs links\n\nUSER DECISION REQUIRED:\n[ ] APPROVED - proceed\n[ ] REJECTED - specify: which criterion, what's missing, what's wrong\n```\n\n## Steps 5-6: Handle Decision and Document\n\n| Decision | Actions | Documentation |\n|----------|---------|---------------|\n| **APPROVED** | 1. Document (Task, Approver, Date, Notes)  2. Update status  3. Proceed to feedback loop | Validation Approved record |\n| **REJECTED** | 1. Document (Task, Rejector, Date, Criterion failed, Issue, Expected vs Actual)  2. Create remediation task  3. Return to Gate 0  4. After fix: restart from Gate 3  5. Track in feedback loop | Validation Rejected + Remediation Required records |\n\n**Validation Record format:** Date, Validator, Decision, Criteria Summary (X/Y), Evidence Summary (tests/manual/perf), Decision Details, Next Steps\n\n## Validation Best Practices\n\n| Category | Strong Evidence | Weak Evidence (avoid) |\n|----------|-----------------|----------------------|\n| **Evidence Quality** | Automated test + assertion, Screenshot/recording, Log with exact values, Metrics within threshold | \"Works on my machine\", \"Tested manually\" (no details), \"Should be fine\", Indirect evidence |\n| **Verifiable Criteria** | \"User can login\"  test login + verify session | \"System is fast\"  needs specific metric |\n| | \"Page loads <2s\"  measure + show metric | \"UX is good\"  needs measurable criteria |\n\n## Handling Partial Validation\n\nIf some criteria pass but others fail:\n\n1. **Do not partially approve**\n2. Mark entire validation as REJECTED\n3. Document which criteria passed (won't need re-verification)\n4. Document which criteria failed (need fixes)\n5. After fixes, re-verify only failed criteria\n6. Present updated checklist for approval\n\n## Anti-Patterns\n\n**Never:**\n- Skip validation because \"tests pass\"\n- Auto-approve without user decision\n- Assume criterion is met without evidence\n- Accept vague approval (\"looks good\")\n- Proceed while awaiting decision\n- Reuse old evidence for new changes\n\n**Always:**\n- Present evidence for every criterion\n- Require explicit APPROVED/REJECTED decision\n- Document rejection reason in detail\n- Track validation metrics\n- Re-verify after any changes\n\n## Execution Report\n\nBase metrics per [shared-patterns/output-execution-report.md](../shared-patterns/output-execution-report.md).\n\n| Metric | Value |\n|--------|-------|\n| Duration | Xm Ys |\n| Criteria Validated | X/Y |\n| Evidence Collected | X automated, Y manual |\n| User Decision | APPROVED/REJECTED |\n| Rejection Reason | [if applicable] |\n| Result | Gate passed / Returned to Gate 0 |\n\n## Edge Cases\n\n| Scenario | Action |\n|----------|--------|\n| **User Unavailable** | Document pending  Do not proceed  Set escalation  Block task completion |\n| **Criterion Ambiguity** | STOP  Ask user to clarify  Update AC  Re-verify with new understanding |\n| **New Requirements** | Document as new req  Complete current validation on original AC  Create new task  no scope creep |"
              },
              {
                "name": "ring:using-dev-team",
                "description": "7 specialist developer agents for backend (Go/TypeScript), DevOps, frontend,\ndesign, QA, and SRE. Dispatch when you need deep technology expertise.\n",
                "path": "dev-team/skills/using-dev-team/SKILL.md",
                "frontmatter": {
                  "name": "ring:using-dev-team",
                  "description": "7 specialist developer agents for backend (Go/TypeScript), DevOps, frontend,\ndesign, QA, and SRE. Dispatch when you need deep technology expertise.\n",
                  "trigger": "- Need deep expertise for specific technology (Go, TypeScript)\n- Building infrastructure/CI-CD  devops-engineer\n- Frontend with design focus  frontend-designer\n- Test strategy needed  qa-analyst\n- Reliability/monitoring  sre\n",
                  "skip_when": "- General code review  use default plugin reviewers\n- Planning/design  use brainstorming\n- Debugging  use systematic-debugging\n",
                  "related": {
                    "similar": [
                      "using-ring"
                    ]
                  }
                },
                "content": "# Using Ring Developer Specialists\n\nThe ring-dev-team plugin provides 7 specialized developer agents. Use them via `Task tool with subagent_type:`.\n\nSee [CLAUDE.md](https://raw.githubusercontent.com/LerianStudio/ring/main/CLAUDE.md) and [using-ring](https://raw.githubusercontent.com/LerianStudio/ring/main/default/skills/using-ring/SKILL.md) for canonical workflow requirements and ORCHESTRATOR principle. This skill introduces dev-team-specific agents.\n\n**Remember:** Follow the **ORCHESTRATOR principle** from `using-ring`. Dispatch agents to handle complexity; don't operate tools directly.\n\n---\n\n## Blocker Criteria - STOP and Report\n\n<block_condition>\n- Technology Stack decision needed (Go vs TypeScript)\n- Architecture decision needed (monolith vs microservices)\n- Infrastructure decision needed (cloud provider)\n- Testing strategy decision needed (unit vs E2E)\n</block_condition>\n\nIf any condition applies, STOP and ask user.\n\n**always pause and report blocker for:**\n\n| Decision Type | Examples | Action |\n|--------------|----------|--------|\n| **Technology Stack** | Go vs TypeScript for new service | STOP. Check existing patterns. Ask user. |\n| **Architecture** | Monolith vs microservices | STOP. This is a business decision. Ask user. |\n| **Infrastructure** | Cloud provider choice | STOP. Check existing infrastructure. Ask user. |\n| **Testing Strategy** | Unit vs E2E vs both | STOP. Check QA requirements. Ask user. |\n\n**You CANNOT make technology decisions autonomously. STOP and ask.**\n\n---\n\n## Common Misconceptions - REJECTED\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations (including Specialist Dispatch section).\n\n**Self-sufficiency bias check:** If you're tempted to implement directly, ask:\n1. Is there a specialist for this? (Check the 7 specialists below)\n2. Would a specialist follow standards I might miss?\n3. Am I avoiding dispatch because it feels like \"overhead\"?\n\n**If any answer is yes  You MUST DISPATCH the specialist. This is NON-NEGOTIABLE.**\n\n---\n\n## Anti-Rationalization Table\n\nSee [shared-patterns/shared-anti-rationalization.md](../shared-patterns/shared-anti-rationalization.md) for universal anti-rationalizations (including Specialist Dispatch section and Universal section).\n\n---\n\n### Cannot Be Overridden\n\n<cannot_skip>\n- Dispatch to specialist (standards loading required)\n- 6-gate development cycle (quality gates)\n- Parallel reviewer dispatch (not sequential)\n- TDD in Gate 0 (test-first)\n- User approval in Gate 5\n</cannot_skip>\n\n**These requirements are NON-NEGOTIABLE:**\n\n| Requirement | Why It Cannot Be Waived |\n|-------------|------------------------|\n| **Dispatch to specialist** | Specialists have standards loading, you don't |\n| **6-gate development cycle** | Gates prevent quality regressions |\n| **Parallel reviewer dispatch** | Sequential review = 3x slower, same cost |\n| **TDD in Gate 0** | Test-first ensures testability |\n| **User approval in Gate 5** | Only users can approve completion |\n\n**User cannot override these. Time pressure cannot override these. \"Simple task\" cannot override these.**\n\n---\n\n## Pressure Resistance\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md) for universal pressure scenarios (including Combined Pressure Scenarios and Emergency Response).\n\n**Critical Reminder:**\n- **Urgency  Permission to bypass** - Emergencies require MORE care, not less\n- **Authority  Permission to bypass** - Ring standards override human preferences\n- **Sunk Cost  Permission to bypass** - Wrong approach stays wrong at 80% completion\n\n---\n\n## Emergency Response Protocol\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md)  Emergency Response section for the complete protocol.\n\n**Emergency Dispatch Template:**\n```\nTask tool:\n  subagent_type: \"ring:backend-engineer-golang\"\n  model: \"opus\"\n  prompt: \"URGENT PRODUCTION INCIDENT: [brief context]. [Your specific request]\"\n```\n\n**IMPORTANT:** Specialist dispatch takes 5-10 minutes, not hours. This is NON-NEGOTIABLE even under CEO pressure.\n\n---\n\n## Combined Pressure Scenarios\n\nSee [shared-patterns/shared-pressure-resistance.md](../shared-patterns/shared-pressure-resistance.md)  Combined Pressure Scenarios section.\n\n---\n\n## 7 Developer Specialists\n\n<dispatch_required agent=\"{specialist}\" model=\"opus\">\nUse Task tool to dispatch appropriate specialist based on technology need.\n</dispatch_required>\n\n| Agent | Specializations | Use When |\n|-------|-----------------|----------|\n| **`backend-engineer-golang`** | Go microservices, PostgreSQL/MongoDB, Kafka/RabbitMQ, OAuth2/JWT, gRPC, concurrency | Go services, DB optimization, auth/authz, concurrency issues |\n| **`backend-engineer-typescript`** | TypeScript/Node.js, Express/Fastify/NestJS, Prisma/TypeORM, async patterns, Jest/Vitest | TS backends, JSTS migration, NestJS design, full-stack TS |\n| **`devops-engineer`** | Docker/Compose, Terraform/Helm, cloud infra, secrets management | Containerization, local dev setup, IaC provisioning, Helm charts |\n| **`frontend-bff-engineer-typescript`** | Next.js API Routes BFF, Clean/Hexagonal Architecture, DDD patterns, Inversify DI, repository pattern | BFF layer, Clean Architecture, DDD domains, API orchestration |\n| **`frontend-designer`** | Bold typography, color systems, animations, unexpected layouts, textures/gradients | Landing pages, portfolios, distinctive dashboards, design systems |\n| **`qa-analyst`** | Test strategy, Cypress/Playwright E2E, coverage analysis, API testing, performance | Test planning, E2E suites, coverage gaps, quality gates |\n| **`sre`** | Structured logging, tracing, health checks, observability | Logging validation, tracing setup, health endpoint verification |\n\n**Dispatch template:**\n```\nTask tool:\n  subagent_type: \"ring:{agent-name}\"\n  model: \"opus\"\n  prompt: \"{Your specific request with context}\"\n```\n\n**Note:** `frontend-designer` = visual aesthetics. `frontend-bff-engineer-typescript` = business logic/architecture.\n\n---\n\n## When to Use Developer Specialists vs General Review\n\n### Use Developer Specialists for:\n-  **Deep technical expertise needed**  Architecture decisions, complex implementations\n-  **Technology-specific guidance**  \"How do I optimize this Go service?\"\n-  **Specialized domains**  Infrastructure, SRE, testing strategy\n-  **Building from scratch**  New service, new pipeline, new testing framework\n\n### Use General Review Agents for:\n-  **Code quality assessment**  Architecture, patterns, maintainability\n-  **Correctness & edge cases**  Business logic verification\n-  **Security review**  OWASP, auth, validation\n-  **Post-implementation**  Before merging existing code\n\n**Both can be used together:** Get developer specialist guidance during design, then run general reviewers before merge.\n\n---\n\n## Dispatching Multiple Specialists\n\nIf you need multiple specialists (e.g., backend engineer + DevOps engineer), dispatch in **parallel** (single message, multiple Task calls):\n\n```\n CORRECT:\nTask #1: backend-engineer-golang\nTask #2: devops-engineer\n(Both run in parallel)\n\n WRONG:\nTask #1: backend-engineer-golang\n(Wait for response)\nTask #2: devops-engineer\n(Sequential = 2x slower)\n```\n\n---\n\n## ORCHESTRATOR Principle\n\nRemember:\n- **You're the orchestrator**  Dispatch specialists, don't implement directly\n- **Don't read specialist docs yourself**  Dispatch to specialist, they know their domain\n- **Combine with using-ring principle**  Skills + Specialists = complete workflow\n\n### Good Example (ORCHESTRATOR):\n> \"I need a Go service. Let me dispatch `backend-engineer-golang` to design it.\"\n\n### Bad Example (OPERATOR):\n> \"I'll manually read Go best practices and design the service myself.\"\n\n---\n\n## Available in This Plugin\n\n**Agents:** See \"7 Developer Specialists\" table above.\n\n**Skills:** `using-dev-team` (this), `dev-cycle` (6-gate workflow), `dev-refactor` (codebase analysis)\n\n**Commands:** `/dev-cycle` (execute tasks), `/dev-refactor` (analyze codebase)\n\n**Note:** Missing agents? Check `.claude-plugin/marketplace.json` for ring-dev-team plugin.\n\n---\n\n## Development Workflows\n\nAll workflows converge to the 6-gate development cycle:\n\n| Workflow | Entry Point | Output | Then |\n|----------|-------------|--------|------|\n| **New Feature** | `/pre-dev-feature \"description\"` | `docs/pre-dev/{feature}/tasks.md` |  `/dev-cycle tasks.md` |\n| **Direct Tasks** | `/dev-cycle tasks.md` |  | Execute 6 gates directly |\n| **Refactoring** | `/dev-refactor` | `docs/refactor/{timestamp}/tasks.md` |  `/dev-cycle tasks.md` |\n\n**6-Gate Development Cycle:**\n\n| Gate | Focus | Agent(s) |\n|------|-------|----------|\n| **0: Implementation** | TDD: REDGREENREFACTOR | `backend-engineer-*`, `frontend-bff-engineer-typescript` |\n| **1: DevOps** | Dockerfile, docker-compose, .env | `devops-engineer` |\n| **2: SRE** | Health checks, logging, tracing | `sre` |\n| **3: Testing** | Unit tests, coverage 85% | `qa-analyst` |\n| **4: Review** | 3 reviewers IN PARALLEL | `code-reviewer`, `business-logic`, `security` |\n| **5: Validation** | User approval: APPROVED/REJECTED | User decision |\n\n**Key Principle:** All development follows the same 6-gate process.\n\n---\n\n## Integration with Other Plugins\n\n- **using-ring** (default)  ORCHESTRATOR principle for all agents\n- **using-pm-team**  Pre-dev workflow agents\n- **using-finops-team**  Financial/regulatory agents\n\nDispatch based on your need:\n- General code review  default plugin agents\n- Specific domain expertise  ring-dev-team agents\n- Feature planning  ring-pm-team agents\n- Regulatory compliance  ring-finops-team agents"
              }
            ]
          },
          {
            "name": "ring-pm-team",
            "description": "Product team pre-development workflow: 10 skills + 3 research agents. 9-gate planning system with research-first approach (Gate 0) before PRD creation. Includes parallel research agents (repo-research-analyst, best-practices-researcher, framework-docs-researcher) and full planning gates (PRD, feature map, TRD, API, data model, dependencies, tasks, subtasks).",
            "source": "./pm-team",
            "category": null,
            "version": "0.9.3",
            "author": null,
            "install_commands": [
              "/plugin marketplace add LerianStudio/ring",
              "/plugin install ring-pm-team@ring"
            ],
            "signals": {
              "stars": 39,
              "forks": 2,
              "pushed_at": "2026-01-12T18:20:36Z",
              "created_at": "2025-10-30T20:18:13Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/pre-dev-feature",
                "description": "Lightweight 4-gate pre-dev workflow for small features (<2 days)",
                "path": "pm-team/commands/pre-dev-feature.md",
                "frontmatter": {
                  "name": "ring:pre-dev-feature",
                  "description": "Lightweight 4-gate pre-dev workflow for small features (<2 days)",
                  "argument-hint": "[feature-name]"
                },
                "content": "I'm running the **Small Track** pre-development workflow (4 gates) for your feature.\n\n**This track is for features that:**\n-  Take <2 days to implement\n-  Use existing architecture patterns\n-  Don't add new external dependencies\n-  Don't create new data models/entities\n-  Don't require multi-service integration\n-  Can be completed by a single developer\n\n**If any of the above are false, use `/pre-dev-full` instead.**\n\n## Document Organization\n\nAll artifacts will be saved to: `docs/pre-dev/<feature-name>/`\n\n**First, let me ask you about your feature:**\n\nUse the AskUserQuestion tool to gather:\n\n**Question 1:** \"What is the name of your feature?\"\n- Header: \"Feature Name\"\n- This will be used for the directory name\n- Use kebab-case (e.g., \"user-logout\", \"email-validation\", \"rate-limiting\")\n\n**Question 2 (CONDITIONAL):** \"Does this feature require authentication or authorization?\"\n- **Auto-detection:** Before asking, check if `go.mod` contains `github.com/LerianStudio/lib-auth`\n  - If **found**  Skip this question. Auth is already integrated at project level.\n  - If **not found**  Ask this question (new project or project without auth)\n- Header: \"Auth Requirements\"\n- Options:\n  - \"None\" - No authentication needed\n  - \"User authentication only\" - Users must log in but no permission checks\n  - \"User + permissions\" - Full user auth with role-based access control\n  - \"Service-to-service auth\" - Machine-to-machine authentication only\n  - \"Full (user + service-to-service)\" - Both user and service auth\n- **Note:** For Go services requiring auth, reference `golang.md`  Access Manager Integration section during TRD creation (Gate 2)\n\n**Question 3 (CONDITIONAL):** \"Is this a licensed product/plugin?\"\n- **Auto-detection:** Before asking, check if `go.mod` contains `github.com/LerianStudio/lib-license-go`\n  - If **found**  Skip this question. Licensing is already integrated at project level.\n  - If **not found**  Ask this question (new project or project without licensing)\n- Header: \"License Requirements\"\n- Options:\n  - \"No\" - Not a licensed product (open source, internal tool, etc.)\n  - \"Yes\" - Licensed product that requires License Manager integration\n- **Note:** For Go services requiring license validation, reference `golang.md`  License Manager Integration section during TRD creation (Gate 2)\n\n**Why auto-detection?** Access Manager and License Manager are project-level infrastructure decisions, not feature-level. Once integrated, all features in the project inherit them.\n\nAfter getting the feature name (and auth/license requirements if applicable), create the directory structure and run the 4-gate workflow:\n\n```bash\nmkdir -p docs/pre-dev/<feature-name>\n```\n\n## Gate 0: Research Phase (Lightweight)\n\n**Skill:** pre-dev-research\n\nEven small features benefit from quick research:\n\n1. Determine research mode (usually **modification** for small features)\n2. Dispatch 3 research agents in PARALLEL (quick mode)\n3. Save to: `docs/pre-dev/<feature-name>/research.md`\n4. Get human approval before proceeding\n\n**Gate 0 Pass Criteria (Small Track):**\n- [ ] Research mode determined\n- [ ] Existing patterns identified (if any)\n- [ ] No conflicting implementations found\n\n**Note:** For very simple changes, Gate 0 can be abbreviated - focus on checking for existing patterns.\n\n## Gate 1: PRD Creation\n\n**Skill:** pre-dev-prd-creation\n\n1. Ask user to describe the feature (what problem does it solve, who are the users, what's the business value)\n2. Create PRD document with:\n   - Problem statement\n   - User stories\n   - Acceptance criteria\n   - Success metrics\n   - Out of scope\n3. Save to: `docs/pre-dev/<feature-name>/prd.md`\n4. Run Gate 1 validation checklist\n5. Get human approval before proceeding\n\n**Gate 1 Pass Criteria:**\n- [ ] Problem is clearly defined\n- [ ] User value is measurable\n- [ ] Acceptance criteria are testable\n- [ ] Scope is explicitly bounded\n\n## Gate 2: TRD Creation (Skipping Feature Map)\n\n**Skill:** pre-dev-trd-creation\n\n1. Load PRD from `docs/pre-dev/<feature-name>/prd.md`\n2. Note: No Feature Map exists (small track) - map PRD features directly to components\n3. Create TRD document with:\n   - Architecture style (pattern names, not products)\n   - Component design (technology-agnostic)\n   - Data architecture (conceptual)\n   - Integration patterns\n   - Security architecture\n   - **NO specific tech products** (use \"Relational Database\" not \"PostgreSQL\")\n4. Save to: `docs/pre-dev/<feature-name>/trd.md`\n5. Run Gate 2 validation checklist\n6. Get human approval before proceeding\n\n**Gate 2 Pass Criteria:**\n- [ ] All PRD features mapped to components\n- [ ] Component boundaries are clear\n- [ ] Interfaces are technology-agnostic\n- [ ] No specific products named\n\n## Gate 3: Task Breakdown (Skipping API/Data/Deps)\n\n**Skill:** pre-dev-task-breakdown\n\n1. Load PRD from `docs/pre-dev/<feature-name>/prd.md`\n2. Load TRD from `docs/pre-dev/<feature-name>/trd.md`\n3. Note: No Feature Map, API Design, Data Model, or Dependency Map exist (small track)\n4. Create task breakdown document with:\n   - Value-driven decomposition\n   - Each task delivers working software\n   - Maximum task size: 2 weeks\n   - Dependencies mapped\n   - Testing strategy per task\n5. Save to: `docs/pre-dev/<feature-name>/tasks.md`\n6. Run Gate 3 validation checklist\n7. Get human approval\n\n**Gate 3 Pass Criteria:**\n- [ ] Every task delivers user value\n- [ ] No task larger than 2 weeks\n- [ ] Dependencies are clear\n- [ ] Testing approach defined\n\n## After Completion\n\nReport to human:\n\n```\n Small Track (4 gates) complete for <feature-name>\n\nArtifacts created:\n- docs/pre-dev/<feature-name>/research.md (Gate 0)  NEW\n- docs/pre-dev/<feature-name>/prd.md (Gate 1)\n- docs/pre-dev/<feature-name>/trd.md (Gate 2)\n- docs/pre-dev/<feature-name>/tasks.md (Gate 3)\n\nSkipped from full workflow:\n- Feature Map (features simple enough to map directly)\n- API Design (no new APIs)\n- Data Model (no new data structures)\n- Dependency Map (no new dependencies)\n- Subtask Creation (tasks small enough already)\n\nNext steps:\n1. Review artifacts in docs/pre-dev/<feature-name>/\n2. Use /worktree to create isolated workspace\n3. Use /write-plan to create implementation plan\n4. Execute the plan\n```\n\n## Remember\n\n- This is the **Small Track** - lightweight and fast\n- **Gate 0 (Research) checks for existing patterns** even for small features\n- If feature grows during planning, switch to `/pre-dev-full`\n- All documents saved to `docs/pre-dev/<feature-name>/`\n- Get human approval at each gate\n- Technology decisions happen later in Dependency Map (not in this track)\n\n---\n\n## MANDATORY: Skills Orchestration\n\n**This command orchestrates multiple skills in a 4-gate workflow.**\n\n### Gate Sequence\n\n| Gate | Skill | Purpose |\n|------|-------|---------|\n| 0 | `pre-dev-research` | Domain and technical research |\n| 1 | `pre-dev-prd-creation` | Product requirements |\n| 2 | `pre-dev-trd-creation` | Technical requirements |\n| 3 | `pre-dev-task-breakdown` | Task decomposition |\n\n### Execution Pattern\n\n```\nFor each gate:\n  Use Skill tool: [gate-skill]\n  Wait for human approval\n  Proceed to next gate\n```\n\nEach skill contains its own:\n- Anti-rationalization tables\n- Gate pass criteria\n- Output format requirements\n\n**Do NOT skip gates.** Each gate builds on the previous gate's output."
              },
              {
                "name": "/pre-dev-full",
                "description": "Complete 9-gate pre-dev workflow for large features (2 days)",
                "path": "pm-team/commands/pre-dev-full.md",
                "frontmatter": {
                  "name": "ring:pre-dev-full",
                  "description": "Complete 9-gate pre-dev workflow for large features (2 days)",
                  "argument-hint": "[feature-name]"
                },
                "content": "I'm running the **Full Track** pre-development workflow (9 gates) for your feature.\n\n**This track is for features that have ANY of:**\n-  Take 2 days to implement\n-  Add new external dependencies (APIs, databases, libraries)\n-  Create new data models or entities\n-  Require multi-service integration\n-  Use new architecture patterns\n-  Require team collaboration\n\n**If feature is simple (<2 days, existing patterns), use `/pre-dev-feature` instead.**\n\n## Document Organization\n\nAll artifacts will be saved to: `docs/pre-dev/<feature-name>/`\n\n**First, let me ask you about your feature:**\n\nUse the AskUserQuestion tool to gather:\n\n**Question 1:** \"What is the name of your feature?\"\n- Header: \"Feature Name\"\n- This will be used for the directory name\n- Use kebab-case (e.g., \"auth-system\", \"payment-processing\", \"file-upload\")\n\n**Question 2 (CONDITIONAL):** \"Does this feature require authentication or authorization?\"\n- **Auto-detection:** Before asking, check if `go.mod` contains `github.com/LerianStudio/lib-auth`\n  - If **found**  Skip this question. Auth is already integrated at project level.\n  - If **not found**  Ask this question (new project or project without auth)\n- Header: \"Auth Requirements\"\n- Options:\n  - \"None\" - No authentication needed\n  - \"User authentication only\" - Users must log in but no permission checks\n  - \"User + permissions\" - Full user auth with role-based access control\n  - \"Service-to-service auth\" - Machine-to-machine authentication only\n  - \"Full (user + service-to-service)\" - Both user and service auth\n- **Note:** For Go services requiring auth, reference `golang.md`  Access Manager Integration section during TRD creation (Gate 3) and Dependency Map (Gate 6)\n\n**Question 3 (CONDITIONAL):** \"Is this a licensed product/plugin?\"\n- **Auto-detection:** Before asking, check if `go.mod` contains `github.com/LerianStudio/lib-license-go`\n  - If **found**  Skip this question. Licensing is already integrated at project level.\n  - If **not found**  Ask this question (new project or project without licensing)\n- Header: \"License Requirements\"\n- Options:\n  - \"No\" - Not a licensed product (open source, internal tool, etc.)\n  - \"Yes\" - Licensed product that requires License Manager integration\n- **Note:** For Go services requiring license validation, reference `golang.md`  License Manager Integration section during TRD creation (Gate 3) and Dependency Map (Gate 6)\n\n**Why auto-detection?** Access Manager and License Manager are project-level infrastructure decisions, not feature-level. Once integrated, all features in the project inherit them.\n\nAfter getting the feature name (and auth/license requirements if applicable), create the directory structure and run the 9-gate workflow:\n\n```bash\nmkdir -p docs/pre-dev/<feature-name>\n```\n\n## Gate 0: Research Phase (NEW)\n\n**Skill:** pre-dev-research\n\n1. Determine research mode by asking user or inferring from context:\n   - **greenfield**: New capability, no existing patterns\n   - **modification**: Extending existing functionality\n   - **integration**: Connecting external systems\n\n2. Dispatch 3 research agents in PARALLEL:\n   - repo-research-analyst (codebase patterns, file:line refs)\n   - best-practices-researcher (web search, Context7)\n   - framework-docs-researcher (tech stack, versions)\n\n3. Aggregate findings into research document\n4. Save to: `docs/pre-dev/<feature-name>/research.md`\n5. Run Gate 0 validation checklist\n6. Get human approval before proceeding\n\n**Gate 0 Pass Criteria:**\n- [ ] Research mode determined and documented\n- [ ] All 3 agents dispatched and returned\n- [ ] At least one file:line reference (if modification mode)\n- [ ] At least one external URL (if greenfield mode)\n- [ ] docs/solutions/ knowledge base searched\n- [ ] Tech stack versions documented\n\n## Gate 1: PRD Creation\n\n**Skill:** pre-dev-prd-creation\n\n1. Ask user to describe the feature (problem, users, business value)\n2. Create PRD document with:\n   - Problem statement\n   - User stories\n   - Acceptance criteria\n   - Success metrics\n   - Out of scope\n3. Save to: `docs/pre-dev/<feature-name>/prd.md`\n4. Run Gate 1 validation checklist\n5. Get human approval before proceeding\n\n**Gate 1 Pass Criteria:**\n- [ ] Problem is clearly defined\n- [ ] User value is measurable\n- [ ] Acceptance criteria are testable\n- [ ] Scope is explicitly bounded\n\n## Gate 2: Feature Map Creation\n\n**Skill:** pre-dev-feature-map\n\n1. Load PRD from `docs/pre-dev/<feature-name>/prd.md`\n2. Create feature map document with:\n   - Feature relationships and dependencies\n   - Domain boundaries\n   - Integration points\n   - Scope visualization\n3. Save to: `docs/pre-dev/<feature-name>/feature-map.md`\n4. Run Gate 2 validation checklist\n5. Get human approval before proceeding\n\n**Gate 2 Pass Criteria:**\n- [ ] All features from PRD mapped\n- [ ] Relationships are clear\n- [ ] Domain boundaries defined\n- [ ] Feature interactions documented\n\n## Gate 3: TRD Creation\n\n**Skill:** pre-dev-trd-creation\n\n1. Load PRD from `docs/pre-dev/<feature-name>/prd.md`\n2. Load Feature Map from `docs/pre-dev/<feature-name>/feature-map.md`\n3. Map Feature Map domains to architectural components\n4. Create TRD document with:\n   - Architecture style (pattern names, not products)\n   - Component design (technology-agnostic)\n   - Data architecture (conceptual)\n   - Integration patterns\n   - Security architecture\n   - **NO specific tech products**\n5. Save to: `docs/pre-dev/<feature-name>/trd.md`\n6. Run Gate 3 validation checklist\n7. Get human approval before proceeding\n\n**Gate 3 Pass Criteria:**\n- [ ] All Feature Map domains mapped to components\n- [ ] All PRD features mapped to components\n- [ ] Component boundaries are clear\n- [ ] Interfaces are technology-agnostic\n- [ ] No specific products named\n\n## Gate 4: API Design\n\n**Skill:** pre-dev-api-design\n\n1. Load previous artifacts (PRD, Feature Map, TRD)\n2. Create API design document with:\n   - Component contracts and interfaces\n   - Request/response formats\n   - Error handling patterns\n   - Integration specifications\n3. Save to: `docs/pre-dev/<feature-name>/api-design.md`\n4. Run Gate 4 validation checklist\n5. Get human approval before proceeding\n\n**Gate 4 Pass Criteria:**\n- [ ] All component interfaces defined\n- [ ] Contracts are clear and complete\n- [ ] Error cases covered\n- [ ] Protocol-agnostic (no REST/gRPC specifics yet)\n\n## Gate 5: Data Model\n\n**Skill:** pre-dev-data-model\n\n1. Load previous artifacts\n2. Create data model document with:\n   - Entity relationships and schemas\n   - Data ownership boundaries\n   - Access patterns\n   - Migration strategy\n3. Save to: `docs/pre-dev/<feature-name>/data-model.md`\n4. Run Gate 5 validation checklist\n5. Get human approval before proceeding\n\n**Gate 5 Pass Criteria:**\n- [ ] All entities defined with relationships\n- [ ] Data ownership is clear\n- [ ] Access patterns documented\n- [ ] Database-agnostic (no PostgreSQL/MongoDB specifics yet)\n\n## Gate 6: Dependency Map\n\n**Skill:** pre-dev-dependency-map\n\n1. Load previous artifacts\n2. Create dependency map document with:\n   - **NOW we select specific technologies**\n   - Concrete versions and packages\n   - Rationale for each choice\n   - Alternative evaluations\n3. Save to: `docs/pre-dev/<feature-name>/dependency-map.md`\n4. Run Gate 6 validation checklist\n5. Get human approval before proceeding\n\n**Gate 6 Pass Criteria:**\n- [ ] All technologies selected with rationale\n- [ ] Versions pinned (no \"latest\")\n- [ ] Alternatives evaluated\n- [ ] Tech stack is complete\n\n## Gate 7: Task Breakdown\n\n**Skill:** pre-dev-task-breakdown\n\n1. Load all previous artifacts (PRD, Feature Map, TRD, API Design, Data Model, Dependency Map)\n2. Create task breakdown document with:\n   - Value-driven decomposition\n   - Each task delivers working software\n   - Maximum task size: 2 weeks\n   - Dependencies mapped\n   - Testing strategy per task\n3. Save to: `docs/pre-dev/<feature-name>/tasks.md`\n4. Run Gate 7 validation checklist\n5. Get human approval before proceeding\n\n**Gate 7 Pass Criteria:**\n- [ ] Every task delivers user value\n- [ ] No task larger than 2 weeks\n- [ ] Dependencies are clear\n- [ ] Testing approach defined\n\n## Gate 8: Subtask Creation\n\n**Skill:** pre-dev-subtask-creation\n\n1. Load tasks from `docs/pre-dev/<feature-name>/tasks.md`\n2. Create subtask breakdown document with:\n   - Bite-sized steps (2-5 minutes each)\n   - TDD-based implementation steps\n   - Complete code (no placeholders)\n   - Zero-context executable\n3. Save to: `docs/pre-dev/<feature-name>/subtasks.md`\n4. Run Gate 8 validation checklist\n5. Get human approval\n\n**Gate 8 Pass Criteria:**\n- [ ] Every subtask is 2-5 minutes\n- [ ] TDD cycle enforced (test first)\n- [ ] Complete code provided\n- [ ] Zero-context test passes\n\n## After Completion\n\nReport to human:\n\n```\n Full Track (9 gates) complete for <feature-name>\n\nArtifacts created:\n- docs/pre-dev/<feature-name>/research.md (Gate 0)  NEW\n- docs/pre-dev/<feature-name>/prd.md (Gate 1)\n- docs/pre-dev/<feature-name>/feature-map.md (Gate 2)\n- docs/pre-dev/<feature-name>/trd.md (Gate 3)\n- docs/pre-dev/<feature-name>/api-design.md (Gate 4)\n- docs/pre-dev/<feature-name>/data-model.md (Gate 5)\n- docs/pre-dev/<feature-name>/dependency-map.md (Gate 6)\n- docs/pre-dev/<feature-name>/tasks.md (Gate 7)\n- docs/pre-dev/<feature-name>/subtasks.md (Gate 8)\n\nPlanning time: 2-4 hours (comprehensive)\n\nNext steps:\n1. Review artifacts in docs/pre-dev/<feature-name>/\n2. Use /worktree to create isolated workspace\n3. Use /write-plan to create implementation plan\n4. Execute the plan\n```\n\n## Remember\n\n- This is the **Full Track** - comprehensive and thorough\n- All 9 gates provide maximum planning depth\n- **Gate 0 (Research) runs 3 agents in parallel** for codebase, best practices, and framework docs\n- Technology decisions happen at Gate 6 (Dependency Map)\n- All documents saved to `docs/pre-dev/<feature-name>/`\n- Get human approval at each gate before proceeding\n- Planning investment (2-4 hours) pays off during implementation\n\n---\n\n## MANDATORY: Skills Orchestration\n\n**This command orchestrates multiple skills in a 9-gate workflow.**\n\n### Gate Sequence\n\n| Gate | Skill | Purpose |\n|------|-------|---------|\n| 0 | `pre-dev-research` | Domain/technical research |\n| 1 | `pre-dev-prd-creation` | Product requirements |\n| 2 | `pre-dev-feature-map` | Feature scope |\n| 3 | `pre-dev-trd-creation` | Technical requirements |\n| 4 | `pre-dev-api-design` | API contracts |\n| 5 | `pre-dev-data-model` | Data architecture |\n| 6 | `pre-dev-dependency-map` | Technology selection |\n| 7 | `pre-dev-task-breakdown` | Task decomposition |\n| 8 | `pre-dev-subtask-creation` | Implementation steps |\n\n### Execution Pattern\n\n```\nFor each gate:\n  Use Skill tool: [gate-skill]\n  Wait for human approval\n  Proceed to next gate\n```\n\nEach skill contains its own:\n- Anti-rationalization tables\n- Gate pass criteria\n- Output format requirements\n\n**Do NOT skip gates.** Each gate builds on the previous gate's output."
              }
            ],
            "skills": [
              {
                "name": "ring:pre-dev-api-design",
                "description": "Gate 4: API contracts document - defines component interfaces and data contracts\nbefore protocol/technology selection. Large Track only.\n",
                "path": "pm-team/skills/pre-dev-api-design/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-api-design",
                  "description": "Gate 4: API contracts document - defines component interfaces and data contracts\nbefore protocol/technology selection. Large Track only.\n",
                  "trigger": "- TRD passed Gate 3 validation\n- System has multiple components that need to integrate\n- Building APIs (internal or external)\n- Large Track workflow (2+ day features)\n",
                  "skip_when": "- Small Track workflow  skip to Task Breakdown\n- Single component system  skip to Data Model\n- TRD not validated  complete Gate 3 first\n",
                  "sequence": {
                    "after": [
                      "pre-dev-trd-creation"
                    ],
                    "before": [
                      "pre-dev-data-model"
                    ]
                  }
                },
                "content": "# API/Contract Design - Defining Component Interfaces\n\n## Foundational Principle\n\n**Component contracts and interfaces must be defined before technology/protocol selection.**\n\nJumping to implementation without contract definition creates:\n- Integration failures discovered during development\n- Inconsistent data structures across components\n- Teams blocked waiting for interface clarity\n- Rework when assumptions about contracts differ\n\n**The API Design answers**: WHAT data/operations components expose and consume?\n**The API Design never answers**: HOW those are implemented (protocols, serialization, specific tech).\n\n## Mandatory Workflow\n\n| Phase | Activities |\n|-------|------------|\n| **1. Contract Analysis** | Load approved TRD (Gate 3), Feature Map (Gate 2), PRD (Gate 1); identify integration points from TRD component diagram; extract data flows |\n| **2. Contract Definition** | Per interface: define operations, specify inputs/outputs, define errors, document events, set constraints (validation, rate limits), version contracts |\n| **3. Gate 4 Validation** | Verify all checkboxes in validation checklist before proceeding to Data Modeling |\n\n## Explicit Rules\n\n###  DO Include\nOperation names/descriptions, input parameters (name, type, required/optional, constraints), output structure (fields, types, nullable), error codes/descriptions, event types/payloads, validation rules, rate limits/quotas, idempotency requirements, auth/authz needs (abstract), versioning strategy\n\n###  NEVER Include\nHTTP verbs (GET/POST/PUT), gRPC/GraphQL/WebSocket details, URL paths/routes, serialization formats (JSON/Protobuf), framework code, database queries, infrastructure, specific auth libraries\n\n### Abstraction Rules\n\n| Element | Abstract () | Protocol-Specific () |\n|---------|--------------|----------------------|\n| Operation | \"CreateUser\" | \"POST /api/v1/users\" |\n| Data Type | \"EmailAddress (validated)\" | \"string with regex\" |\n| Error | \"UserAlreadyExists\" | \"HTTP 409 Conflict\" |\n| Auth | \"Requires authenticated user\" | \"JWT Bearer token\" |\n| Format | \"ISO8601 timestamp\" | \"time.RFC3339\" |\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"REST is obvious, just document endpoints\" | Protocol choice goes in Dependency Map. Define contracts abstractly. |\n| \"We need HTTP codes for errors\" | Error semantics matter; HTTP codes are protocol. Abstract the errors. |\n| \"Teams need to see JSON examples\" | JSON is serialization. Define structure; format comes later. |\n| \"The contract IS the OpenAPI spec\" | OpenAPI is protocol-specific. Design contracts first, generate specs later. |\n| \"gRPC/GraphQL affects the contract\" | Protocols deliver contracts. Design protocol-agnostic contracts first. |\n| \"We already know it's REST\" | Knowing doesn't mean documenting prematurely. Stay abstract. |\n| \"Framework validates inputs\" | Validation logic is universal. Document rules; implementation comes later. |\n| \"This feels redundant with TRD\" | TRD = components exist. API = how they talk. Different concerns. |\n| \"URL structure matters for APIs\" | URLs are HTTP-specific. Focus on operations and data. |\n| \"But API Design means REST API\" | API = interface. Could be REST, gRPC, events, or in-process. Stay abstract. |\n\n## Red Flags - STOP\n\nIf you catch yourself writing any of these in API Design, **STOP**:\n\n- HTTP methods (GET, POST, PUT, DELETE, PATCH)\n- URL paths (/api/v1/users, /users/{id})\n- Protocol names (REST, GraphQL, gRPC, WebSocket)\n- Status codes (200, 404, 500)\n- Serialization formats (JSON, XML, Protobuf)\n- Authentication tokens (JWT, OAuth2 tokens, API keys)\n- Framework code (Express routes, gRPC service definitions)\n- Transport mechanisms (HTTP/2, TCP, UDP)\n\n**When you catch yourself**: Replace protocol detail with abstract contract. \"POST /users\"  \"CreateUser operation\"\n\n## Gate 4 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Contract Completeness** | All component-to-component interactions have contracts; all external integrations covered; all event/message contracts defined; client-facing APIs specified |\n| **Operation Clarity** | Each operation has clear purpose/description; consistent naming convention; idempotency documented; batch operations identified |\n| **Data Specification** | All inputs typed and documented; required vs optional explicit; outputs complete; null/empty cases handled |\n| **Error Handling** | All scenarios identified; error codes/types defined; actionable messages; retry/recovery documented |\n| **Event Contracts** | All events named/described; payloads specified; ordering/delivery semantics documented; versioning defined |\n| **Constraints & Policies** | Validation rules explicit; rate limits defined; timeouts specified; backward compatibility exists |\n| **Technology Agnostic** | No protocol specifics; no serialization formats; no framework names; implementable in any protocol |\n\n**Gate Result:**  PASS (all checked)  Data Modeling |  CONDITIONAL (remove protocol details) |  FAIL (incomplete)\n\n## Contract Template Structure\n\nOutput to `docs/pre-dev/{feature-name}/api-design.md` with these sections:\n\n| Section | Content |\n|---------|---------|\n| **Overview** | TRD/Feature Map/PRD references, status, last updated |\n| **Versioning Strategy** | Approach (semantic/date-based), backward compatibility policy, deprecation process |\n| **Component Contracts** | Per component: purpose, integration points (inbound/outbound), operations |\n\n### Per-Operation Structure\n\n| Field | Content |\n|-------|---------|\n| **Purpose** | What the operation does |\n| **Inputs** | Table: Parameter, Type, Required, Constraints, Description |\n| **Validation Rules** | Format patterns, business rules |\n| **Outputs (Success)** | Table: Field, Type, Nullable, Description + abstract structure |\n| **Errors** | Table: Error Code, Condition, Description, Retry? |\n| **Idempotency** | Behavior on duplicate calls |\n| **Authorization** | Required permissions (abstract) |\n| **Related Operations** | Events triggered, downstream calls |\n\n### Event Contract Structure\n\n| Field | Content |\n|-------|---------|\n| **Purpose/When Emitted** | Trigger conditions |\n| **Payload** | Table: Field, Type, Nullable, Description |\n| **Consumers** | Services that consume this event |\n| **Delivery Semantics** | At-least-once, at-most-once, exactly-once |\n| **Ordering/Retention** | Ordering guarantees, retention period |\n\n### Additional Sections\n\n| Section | Content |\n|---------|---------|\n| **Cross-Component Integration** | Per integration: purpose, operations used, data flow diagram (abstract), error handling |\n| **External System Contracts** | Operations exposed to us, operations we expose, per-operation details |\n| **Custom Type Definitions** | Per type: base type, format, constraints, example |\n| **Naming Conventions** | Operations (verb+noun), parameters (camelCase), events (past tense), errors (noun+condition) |\n| **Rate Limiting & Quotas** | Per-operation limits table, quota policies, exceeded limit behavior |\n| **Backward Compatibility** | Breaking vs non-breaking changes, deprecation timeline |\n| **Testing Contracts** | Contract testing strategy, example test scenarios |\n| **Gate 4 Validation** | Date, validator, checklist, approval status |\n\n## Common Violations\n\n| Violation | Wrong | Correct |\n|-----------|-------|---------|\n| **Protocol Details** | \"Endpoint: POST /api/v1/users, Status: 201 Created, 409 Conflict\" | \"Operation: CreateUser, Errors: EmailAlreadyExists, InvalidInput\" |\n| **Implementation Code** | JavaScript regex validation code | \"email must match RFC 5322 format, max 254 chars\" |\n| **Technology Types** | JSON example with \"uuid\", \"Date\", \"Map<String,Any>\" | Table with abstract types: Identifier (UUID format), Timestamp (ISO8601), ProfileObject |\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Contract Completeness | 0-30 | All ops: 30, Most: 20, Gaps: 10 |\n| Interface Clarity | 0-25 | Clear/unambiguous: 25, Some interpretation: 15, Vague: 5 |\n| Integration Complexity | 0-25 | Simple point-to-point: 25, Moderate deps: 15, Complex orchestration: 5 |\n| Error Handling | 0-20 | All scenarios: 20, Common cases: 12, Minimal: 5 |\n\n**Action:** 80+ autonomous generation | 50-79 present options | <50 ask clarifying questions\n\n## After Approval\n\n1.  Lock contracts - interfaces are now implementation reference\n2.  Use contracts as input for Data Modeling (`pre-dev-data-model`)\n3.  Never add protocol specifics retroactively\n4.  Keep technology-agnostic until Dependency Map\n\n## The Bottom Line\n\n**If you wrote API contracts with HTTP endpoints or gRPC services, remove them.**\n\nContracts are protocol-agnostic. Period. No REST. No GraphQL. No HTTP codes.\n\nProtocol choices go in Dependency Map. That's a later phase. Wait for it.\n\n**Define the contract. Stay abstract. Choose protocol later.**"
              },
              {
                "name": "ring:pre-dev-data-model",
                "description": "Gate 5: Data structures document - defines entities, relationships, and ownership\nbefore database technology selection. Large Track only.\n",
                "path": "pm-team/skills/pre-dev-data-model/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-data-model",
                  "description": "Gate 5: Data structures document - defines entities, relationships, and ownership\nbefore database technology selection. Large Track only.\n",
                  "trigger": "- API Design passed Gate 4 validation\n- System stores persistent data\n- Multiple entities with relationships\n- Large Track workflow (2+ day features)\n",
                  "skip_when": "- Small Track workflow  skip to Task Breakdown\n- No persistent data  skip to Dependency Map\n- API Design not validated  complete Gate 4 first\n",
                  "sequence": {
                    "after": [
                      "pre-dev-api-design"
                    ],
                    "before": [
                      "pre-dev-dependency-map"
                    ]
                  }
                },
                "content": "# Data Modeling - Defining Data Structures\n\n## Foundational Principle\n\n**Data structures, relationships, and ownership must be defined before database technology selection.**\n\nJumping to database-specific schemas without modeling creates:\n- Inconsistent data structures across services\n- Unclear data ownership and authority\n- Schema conflicts discovered during development\n- Migration nightmares when requirements change\n\n**The Data Model answers**: WHAT data exists, HOW entities relate, WHO owns what data?\n**The Data Model never answers**: WHICH database technology or HOW to implement storage.\n\n## Mandatory Workflow\n\n| Phase | Activities |\n|-------|------------|\n| **1. Data Analysis** | Load approved API Design (Gate 4), TRD (Gate 3), Feature Map (Gate 2), PRD (Gate 1); extract entities from contracts; identify relationships |\n| **2. Data Modeling** | Define entities, specify attributes, model relationships, assign ownership, define constraints, plan lifecycle, design access patterns, consider data quality |\n| **3. Gate 5 Validation** | Verify all checkboxes before proceeding to Dependency Map |\n\n## Explicit Rules\n\n###  DO Include\nEntity definitions (conceptual data objects), attributes with types, constraints (required, unique, ranges), relationships (1:1, 1:N, M:N), data ownership (authoritative component), primary identifiers, lifecycle rules (soft delete, archival), access patterns, data quality rules, referential integrity\n\n###  NEVER Include\nDatabase products (PostgreSQL, MongoDB, Redis), table/collection names, index definitions, SQL/query language, ORM frameworks (Prisma, TypeORM), storage engines, partitioning/sharding, replication/backup, database-specific types (JSONB, BIGSERIAL)\n\n### Abstraction Rules\n\n| Element | Abstract () | Database-Specific () |\n|---------|--------------|----------------------|\n| Entity | \"User\" | \"users table\" |\n| Attribute | \"emailAddress: String (email format)\" | \"email VARCHAR(255)\" |\n| Relationship | \"User has many Orders\" | \"foreign key user_id\" |\n| Identifier | \"Unique identifier\" | \"UUID primary key\" |\n| Constraint | \"Must be unique\" | \"UNIQUE INDEX\" |\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"We know it's PostgreSQL, just use PG types\" | Database choice comes later. Model abstractly now. |\n| \"Table design is data modeling\" | Tables are implementation. Entities are concepts. Stay conceptual. |\n| \"We need indexes for performance\" | Indexes are optimization. Model data first, optimize later. |\n| \"ORMs require specific schemas\" | ORMs adapt to models. Don't let tooling drive design. |\n| \"Foreign keys define relationships\" | Relationships exist conceptually. FKs are implementation. |\n| \"SQL examples help clarity\" | Abstract models are clearer. SQL is implementation detail. |\n| \"NoSQL doesn't need relationships\" | All systems have data relationships. Model them regardless of DB type. |\n| \"This is just ERD\" | ERD is visualization tool. Data model is broader (ownership, lifecycle, etc). |\n| \"We can skip this for simple CRUD\" | Even CRUD needs clear entity design. Don't skip. |\n| \"Microservices mean no relationships\" | Services interact via data. Model entities per service. |\n\n## Red Flags - STOP\n\nIf you catch yourself writing any of these in Data Model, **STOP**:\n\n- Database product names (Postgres, MySQL, Mongo, Redis)\n- SQL keywords (CREATE TABLE, ALTER TABLE, SELECT, JOIN)\n- Database-specific types (SERIAL, JSONB, VARCHAR, TEXT)\n- Index commands (CREATE INDEX, UNIQUE INDEX)\n- ORM code (Prisma schema, TypeORM decorators)\n- Storage details (partitioning, sharding, replication)\n- Query optimization (EXPLAIN plans, index hints)\n- Backup/recovery strategies\n\n**When you catch yourself**: Replace DB detail with abstract concept. \"users table\"  \"User entity\"\n\n## Gate 5 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Entity Completeness** | All entities from PRD/Feature Map modeled; clear consistent names; defined purpose; boundaries align with TRD components |\n| **Attribute Specification** | All types specified; required vs optional explicit; constraints documented; defaults where relevant; computed fields identified |\n| **Relationship Modeling** | All relationships documented; cardinality specified (1:1, 1:N, M:N); optional vs required clear; referential integrity to be documented; circular deps resolved |\n| **Data Ownership** | Each entity owned by exactly one component; read/write permissions documented; cross-component access via APIs only; no shared database anti-pattern |\n| **Data Quality** | Validation rules specified; normalization level appropriate; denormalization justified; consistency strategy defined |\n| **Lifecycle Management** | Creation rules; update patterns; deletion strategy (hard/soft); archival/retention policies; audit trail needs |\n| **Access Patterns** | Primary patterns documented; query needs identified; write patterns documented; consistency requirements specified |\n| **Technology Agnostic** | No database products; no SQL/NoSQL specifics; no table/index definitions; implementable in any DB |\n\n**Gate Result:**  PASS (all checked)  Dependency Map |  CONDITIONAL (remove DB specifics) |  FAIL (incomplete/poor ownership)\n\n## Data Model Template Structure\n\nOutput to `docs/pre-dev/{feature-name}/data-model.md` with these sections:\n\n| Section | Content |\n|---------|---------|\n| **Overview** | API Design/TRD/Feature Map references, status, last updated |\n| **Data Ownership Map** | Table: Entity, Owning Component, Read Access, Write Access |\n\n### Per-Entity Structure\n\n| Field | Content |\n|-------|---------|\n| **Purpose** | What this entity represents |\n| **Owned By** | Component from TRD |\n| **Primary Identifier** | Unique identifier field and format |\n| **Attributes** | Table: Attribute, Type, Required, Unique, Constraints, Description |\n| **Nested Types** | Embedded types (e.g., OrderItem within Order, Address value object) |\n| **Relationships** | Cardinality notation: Entity (1) < has many > (*) OtherEntity |\n| **Constraints** | Business rules, status transitions, referential integrity |\n| **Lifecycle** | Creation (via which API), updates, deletion strategy, archival |\n| **Access Patterns** | Lookup patterns by frequency (primary, secondary, rare) |\n| **Data Quality** | Normalization rules, validation |\n\n### Additional Sections\n\n| Section | Content |\n|---------|---------|\n| **Relationship Diagram** | ASCII/text diagram showing entity relationships with cardinality legend |\n| **Cross-Component Access** | Per scenario: data flow steps, rules (no direct DB access, API only) |\n| **Consistency Strategy** | Strong consistency (immediate): auth, payments, inventory; Eventual (delay OK): analytics, search |\n| **Validation Rules** | Per-entity and cross-entity validation |\n| **Lifecycle Policies** | Retention periods table, soft delete strategy, audit trail requirements |\n| **Privacy & Compliance** | PII fields table with handling, GDPR compliance, encryption needs (algorithm TBD) |\n| **Access Pattern Analysis** | High/medium/low frequency patterns with req/sec estimates, optimization notes for later |\n| **Data Quality Standards** | Normalization rules, validation approach, integrity enforcement |\n| **Migration Strategy** | Schema evolution (additive, non-breaking, breaking), versioning approach |\n| **Gate 5 Validation** | Date, validator, checklist, approval status |\n\n## Common Violations\n\n| Violation | Wrong | Correct |\n|-----------|-------|---------|\n| **Database Schema** | `CREATE TABLE users (id UUID PRIMARY KEY, email VARCHAR(255) UNIQUE)` | Entity User with attributes table: userId (Identifier, Unique), email (EmailAddress, Unique) |\n| **ORM Code** | TypeScript with @Entity(), @PrimaryGeneratedColumn('uuid'), @Column decorators | Entity User with primary identifier, attributes list, constraints description |\n| **Technology in Relationships** | \"Foreign key user_id references users.id; Join table user_roles\" | \"User (1:N) Order; User (M:N) Role\" with cardinality descriptions |\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Entity Coverage | 0-30 | All entities: 30, Most: 20, Gaps: 10 |\n| Relationship Clarity | 0-25 | All documented: 25, Most clear: 15, Ambiguous: 5 |\n| Data Ownership | 0-25 | Clear boundaries: 25, Minor overlaps: 15, Unclear: 5 |\n| Constraint Completeness | 0-20 | All rules: 20, Common cases: 12, Minimal: 5 |\n\n**Action:** 80+ autonomous generation | 50-79 present options | <50 ask clarifying questions\n\n## After Approval\n\n1.  Lock data model - entity structure is now reference\n2.  Use model as input for Dependency Map (`pre-dev-dependency-map`)\n3.  Never add database specifics retroactively\n4.  Keep technology-agnostic until Dependency Map\n\n## The Bottom Line\n\n**If you wrote SQL schemas or ORM code, delete it and model abstractly.**\n\nData modeling is conceptual. Period. No database products. No SQL. No ORMs.\n\nDatabase technology goes in Dependency Map. That's the next phase. Wait for it.\n\n**Model the data. Stay abstract. Choose database later.**"
              },
              {
                "name": "ring:pre-dev-dependency-map",
                "description": "Gate 6: Technology choices document - explicit, versioned, validated technology\nselections with justifications. Large Track only. HARD BLOCK: Must load Ring Standards\nand PROJECT_RULES.md before proceeding.\n",
                "path": "pm-team/skills/pre-dev-dependency-map/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-dependency-map",
                  "description": "Gate 6: Technology choices document - explicit, versioned, validated technology\nselections with justifications. Large Track only. HARD BLOCK: Must load Ring Standards\nand PROJECT_RULES.md before proceeding.\n",
                  "trigger": "- Data Model passed Gate 5 validation\n- About to select specific technologies\n- Tempted to write \"@latest\" or \"newest version\"\n- Large Track workflow (2+ day features)\n",
                  "skip_when": "- Small Track workflow  skip to Task Breakdown\n- Technologies already locked  skip to Task Breakdown\n- Data Model not validated  complete Gate 5 first\n",
                  "sequence": {
                    "after": [
                      "pre-dev-data-model"
                    ],
                    "before": [
                      "pre-dev-task-breakdown"
                    ]
                  }
                },
                "content": "# Dependency Map - Explicit Technology Choices\n\n## Foundational Principle\n\n**Every technology choice must be explicit, versioned, validated against Ring Standards, and justified.**\n\nUsing vague or \"latest\" dependencies creates:\n- Unreproducible builds across environments\n- Hidden incompatibilities discovered during implementation\n- Security vulnerabilities from unvetted versions\n\n**The Dependency Map answers**: WHAT specific products, versions, packages, and infrastructure we'll use.\n**The Dependency Map never answers**: HOW to implement features (that's Tasks/Subtasks).\n\n---\n\n##  HARD BLOCK: Standards Loading (Step 0)\n\n**This is a HARD GATE. Do NOT proceed without loading Ring Standards and TRD decisions.**\n\n### Step 0.1: Read Technology Decisions from TRD\n\nRead `docs/pre-dev/{feature-name}/trd.md` and extract: `deployment.model`, `tech_stack.primary`, `project_technologies[]`\n\n**If TRD metadata missing:** BLOCKER  Go back to TRD (Gate 3) and complete Step 0.4\n\n### Step 0.2: Load Ring Standards via WebFetch\n\n| Standard | URL | Purpose |\n|----------|-----|---------|\n| **golang.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md` | Go coding patterns |\n| **typescript.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/typescript.md` | TypeScript patterns |\n| **frontend.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/frontend.md` | Frontend patterns |\n| **devops.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/devops.md` | DevOps patterns |\n| **sre.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/sre.md` | Observability, logging |\n\n**Ring Standards** = coding patterns, observability, logging, error handling (shared across ALL projects)\n**PROJECT_RULES.md** = specific technologies, versions, database choices (specific to THIS project)\n\n### Step 0.3: Generate PROJECT_RULES.md (OUTPUT)\n\nUsing TRD `project_technologies[]`, create `docs/PROJECT_RULES.md` with: deployment model, tech stack, per-category decisions (PRD requirement, technology, version, rationale, cloud service, on-premise alternative), version matrix, security/compliance.\n\n### Pressure Resistance for Step 0\n\n| Pressure | Response |\n|----------|----------|\n| \"TRD doesn't have technology decisions\" | \"Go back to TRD (Gate 3) and complete Step 0.4 (PRD analysis).\" |\n| \"Ring Standards are optional\" | \"Ring Standards define coding patterns. PROJECT_RULES.md defines technologies. Both needed.\" |\n| \"Just use defaults\" | \"Defaults come from PRD analysis in TRD. Read TRD first.\" |\n| \"Skip to save time\" | \"PROJECT_RULES.md is the output. Cannot skip the output.\" |\n\n---\n\n## Mandatory Workflow\n\n| Phase | Activities |\n|-------|------------|\n| **1. Evaluation** | Ring Standards loaded (Step 0); PROJECT_RULES.md loaded; Data Model (Gate 5), API Design (Gate 4), TRD (Gate 3) passed; map TRD components to tech candidates; validate against Ring Standards; map Data Model to storage; map API contracts to protocols; check team expertise; estimate costs |\n| **2. Selection** | Per technology: check Ring Standards (mandatory/prohibited), check PROJECT_RULES.md overrides, specify exact version, list alternatives with trade-offs, verify compatibility, check security (CVEs), validate licenses, calculate costs |\n| **3. Gate 6 Validation** | All dependencies explicit, no conflicts, no critical CVEs, licenses compliant, team expertise, costs documented, all components mapped |\n\n## Explicit Rules\n\n###  DO Include\nExact package names with versions (`go.uber.org/zap@v1.27.0`), tech stack with constraints (`Go 1.24+, PostgreSQL 16`), infrastructure specs (`Valkey 8, MinIO`), external SDKs, dev tools, security deps, monitoring tools, compatibility matrices, license summary, cost analysis\n\n###  NEVER Include\nImplementation code, how to use dependencies, task breakdowns, setup instructions, architectural patterns (TRD), business requirements (PRD)\n\n### Version Rules\n1. **Explicit**: `@v1.27.0` not `@latest` or `^1.0.0`\n2. **Justified ranges**: If using `>=`, document why\n3. **Lock file referenced**: `go.mod`, `package-lock.json`, etc.\n4. **Upgrade constraints**: Document why locked/capped\n5. **Compatibility**: Document known conflicts\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"Latest version is always best\" | Latest is untested in your context. Pick specific, validate. |\n| \"I'll use flexible version ranges\" | Ranges cause non-reproducible builds. Lock versions. |\n| \"Version numbers don't matter much\" | They matter critically. Specify or face build failures. |\n| \"We can update versions later\" | Document constraints now. Future you needs context. |\n| \"The team knows the stack already\" | Document it anyway. Teams change, memories fade. |\n| \"Security scanning can happen in CI\" | Security analysis must happen before committing. Do it now. |\n| \"We'll figure out costs in production\" | Costs must be estimated before building. Calculate now. |\n| \"Compatibility issues will surface in tests\" | Validate compatibility NOW. Don't wait for failures. |\n| \"License compliance is legal's problem\" | You're responsible for your dependencies. Check licenses. |\n| \"I'll just use what the project template has\" | Templates may be outdated/insecure. Validate explicitly. |\n\n## Red Flags - STOP\n\nIf you catch yourself writing any of these in a Dependency Map, **STOP**:\n\n- Version placeholders: `@latest`, `@next`, `^X.Y.Z` without justification\n- Vague descriptions: \"latest stable\", \"current version\", \"newest\"\n- Missing version numbers: Just package names without versions\n- Unchecked compatibility: Not verifying version conflicts\n- Unvetted security: Not checking vulnerability databases\n- Unknown licenses: Not documenting license types\n- Estimated costs as \"TBD\" or \"unknown\"\n- \"We'll use whatever is default\" (no default without analysis)\n\n**When you catch yourself**: Stop and specify the exact version after proper analysis.\n\n## Gate 6 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Standards Compliance (HARD BLOCK)** | Ring Standards loaded; PROJECT_RULES.md loaded; mandatory deps included (or justified); no prohibited choices (or justified); version constraints respected; deviations documented |\n| **Compatibility** | All deps have explicit versions; version matrix complete; no known conflicts; runtime requirements specified; upgrade path documented |\n| **Security** | All deps scanned for vulnerabilities; no critical (9.0+) or high (7.0-8.9) CVEs; security update policy documented; supply chain verified |\n| **Feasibility** | Team has expertise or learning path; tools available; licensing allows commercial use; costs fit budget |\n| **Completeness** | Every TRD component mapped; dev environment specified; CI/CD deps documented; monitoring stack complete |\n| **Documentation** | License summary; cost analysis; known constraints; alternatives with rationale |\n\n**Gate Result:**  PASS (all checked)  Task Breakdown |  CONDITIONAL (standards not loaded)  Complete Step 0 |  FAIL (critical CVEs, incompatibilities, standards not loaded)\n\n## Common Violations\n\n| Violation | Wrong | Correct |\n|-----------|-------|---------|\n| **Vague Versions** | `Fiber (latest), PostgreSQL (current), Zap (newest stable)` | `gofiber/fiber/v2@v2.52.0` with purpose, alternatives considered, trade-offs; `lib/pq@v1.10.9` with constraint; `go.uber.org/zap@v1.27.0` with rationale |\n| **Missing Security** | `JWT Library: golang-jwt/jwt@v5.0.0` (no analysis) | Package + purpose + security (CVE check date, OWASP compliance, update history) + alternatives |\n| **Undefined Infrastructure** | `Some database (probably Postgres), Cache (Redis or Valkey), Storage for files` | Per component: product + version + rationale + configuration + cost (managed vs self-hosted) |\n\n## Dependency Resolution Patterns\n\n### Standards-Driven Validation\n\nIf language cannot be auto-detected, use AskUserQuestion with tech stack options (Go Backend, TypeScript Backend, TypeScript Frontend, Full-Stack TypeScript).\n\n| Selection | Standards to Load |\n|-----------|-------------------|\n| Go Backend | golang.md + devops.md + sre.md |\n| TypeScript Backend | typescript.md + devops.md + sre.md |\n| TypeScript Frontend | frontend.md + devops.md |\n| Full-Stack TypeScript | typescript.md + frontend.md + devops.md + sre.md |\n\n**Validation Flow:** Standards loaded  Extract mandatory/prohibited/constraints  Check PROJECT_RULES.md  Validate each selection  Document compliance or justified deviations\n\n### Best Practices\n\n**Prefer:** Semantic versioned packages, well-maintained (commits within 6 months), minimal dependency trees, standard library when sufficient\n**Avoid:** Deprecated packages (>1 year unmaintained), single-maintainer critical deps, >100 transitive deps, GPL unless compliance certain\n\n### Authentication Dependencies (Mandatory for Auth Features)\n\n**If TRD specifies authentication/authorization requirements, include these dependencies:**\n\n| Tech Stack | Auth Requirement | Mandatory Dependency | Reference |\n|------------|------------------|---------------------|-----------|\n| Go Backend | User authentication | `github.com/LerianStudio/lib-auth/v2` | `golang.md`  Access Manager Integration |\n| Go Backend | Service-to-service auth | `github.com/LerianStudio/lib-auth/v2` | `golang.md`  Access Manager Integration |\n| Go Backend | User + permissions (RBAC) | `github.com/LerianStudio/lib-auth/v2` | `golang.md`  Access Manager Integration |\n\n**For Go services, the dependency entry MUST include:**\n\n```markdown\n### Authentication\n\n**Package:** `github.com/LerianStudio/lib-auth/v2@vX.Y.Z`\n**Purpose:** Integration with Lerian Access Manager (plugin-auth + identity)\n**Rationale:** Standard authentication library for all Lerian Go services\n**Environment Variables:** PLUGIN_AUTH_ADDRESS, PLUGIN_AUTH_ENABLED\n**Additional (if S2S):** CLIENT_ID, CLIENT_SECRET\n**Reference:** See `golang.md`  Access Manager Integration for implementation patterns\n```\n\n**CRITICAL:** Go services MUST use lib-auth for authentication. Direct integration with plugin-auth is FORBIDDEN.\n\n**Implementation Requirement (from TRD):**\n- Every protected endpoint MUST have route middleware: `auth.Authorize(applicationName, resource, action)`\n- Middleware is applied per-route, not globally\n- See `golang.md`  Access Manager Integration  Router Setup for patterns\n\n### Licensing Dependencies (Mandatory for Licensed Products)\n\n**If TRD specifies this is a licensed product/plugin, include these dependencies:**\n\n| Tech Stack | License Requirement | Mandatory Dependency | Reference |\n|------------|---------------------|---------------------|-----------|\n| Go Backend | Single-org (global) license | `github.com/LerianStudio/lib-license-go/v2` | `golang.md`  License Manager Integration |\n| Go Backend | Multi-org license | `github.com/LerianStudio/lib-license-go/v2` | `golang.md`  License Manager Integration |\n\n**For Go services, the dependency entry MUST include:**\n\n```markdown\n### Licensing\n\n**Package:** `github.com/LerianStudio/lib-license-go/v2/middleware@vX.Y.Z`\n**Purpose:** Integration with Lerian License Manager for product licensing\n**Rationale:** Standard licensing library for all Lerian licensed Go services\n**Environment Variables:** LICENSE_KEY, ORGANIZATION_IDS\n**Mode:** Global (ORGANIZATION_IDS=global) or Multi-org (comma-separated org IDs)\n**Reference:** See `golang.md`  License Manager Integration for implementation patterns\n```\n\n**CRITICAL:** Go services MUST use lib-license-go for licensing. Custom license validation is FORBIDDEN.\n\n**Implementation Requirement (from TRD):**\n- License middleware applied GLOBALLY: `f.Use(lc.Middleware())`\n- Middleware applied early in chain (first after Fiber creation)\n- Graceful shutdown MUST include: `licenseClient.GetLicenseManagerShutdown()`\n- See `golang.md`  License Manager Integration  Router Setup for patterns\n\n## License & Cost Templates\n\n**License Summary:** Document count by type (MIT, Apache 2.0, BSD-3-Clause, Commercial), compliance actions (attribution file, legal notification, GPL verification)\n\n**Cost Analysis:** Monthly breakdown by category (Compute: containers  cost, Storage: managed DB + cache + object, Network: transfer + load balancer, Third-Party: auth + email + monitoring), grand total, scaling cost per additional users, budget validation\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Technology Familiarity | 0-30 | Used before: 30, Similar: 20, Novel: 10 |\n| Compatibility Verification | 0-25 | All verified: 25, Most checked: 15, Limited: 5 |\n| Security Assessment | 0-25 | Full CVE scan: 25, Basic check: 15, No review: 5 |\n| Cost Analysis | 0-20 | Detailed breakdown: 20, Rough estimates: 12, None: 5 |\n\n**Action:** 80+ autonomous generation | 50-79 present alternatives | <50 ask about expertise/constraints\n\n## Output & After Approval\n\n**Output to:** `docs/pre-dev/{feature-name}/dependency-map.md`\n\n1.  Lock all versions - update only with documented justification\n2.  Create lock files (go.mod, package-lock.json, etc.)\n3.  Set up Dependabot or equivalent for security updates\n4.  Proceed to task breakdown with full stack context\n\n## The Bottom Line\n\n**If you skipped loading Ring Standards, STOP and go back to Step 0.**\n\n**If you wrote a Dependency Map without explicit versions, add them now or start over.**\n\nTwo non-negotiable requirements:\n1. **Ring Standards MUST be loaded** - Technology choices validated against organizational baseline\n2. **Every dependency MUST be explicit** - No @latest, no vague versions, no \"we'll figure it out\"\n\n**Load standards first. Be explicit. Be specific. Lock your versions.**"
              },
              {
                "name": "ring:pre-dev-feature-map",
                "description": "Gate 2: Feature relationship map - visualizes feature landscape, groupings,\nand interactions at business level before technical architecture.\n",
                "path": "pm-team/skills/pre-dev-feature-map/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-feature-map",
                  "description": "Gate 2: Feature relationship map - visualizes feature landscape, groupings,\nand interactions at business level before technical architecture.\n",
                  "trigger": "- PRD passed Gate 1 validation\n- Multiple features with complex interactions\n- Need to understand feature scope and relationships\n- Large Track workflow (2+ day features)\n",
                  "skip_when": "- Small Track workflow (<2 days)  skip to TRD\n- Single simple feature  TRD directly\n- PRD not validated  complete Gate 1 first\n",
                  "sequence": {
                    "after": [
                      "pre-dev-prd-creation"
                    ],
                    "before": [
                      "pre-dev-trd-creation"
                    ]
                  }
                },
                "content": "# Feature Map Creation - Understanding the Feature Landscape\n\n## Foundational Principle\n\n**Feature relationships and boundaries must be mapped before architectural decisions.**\n\nJumping from PRD to TRD without mapping creates:\n- Architectures that don't match feature interaction patterns\n- Missing integration points discovered late\n- Poor module boundaries that cross feature concerns\n\n**The Feature Map answers**: How do features relate, group, and interact at a business level?\n**The Feature Map never answers**: How we'll technically implement those features (that's TRD).\n\n## Mandatory Workflow\n\n| Phase | Activities |\n|-------|------------|\n| **1. Feature Analysis** | Load approved PRD (Gate 1); extract all features; identify user journeys; map feature interactions and dependencies |\n| **2. Feature Mapping** | Categorize (Core/Supporting/Enhancement/Integration); group into domains; map user journeys; identify integration points; define boundaries; visualize relationships; prioritize by value |\n| **3. Gate 2 Validation** | All PRD features mapped; categories defined; domains logical; journeys complete; integration points identified; boundaries clear; priorities support phased delivery; no technical details |\n\n## Explicit Rules\n\n###  DO Include\nFeature list (from PRD), categories (Core/Supporting/Enhancement/Integration), domain groupings (business areas), user journey maps, feature interactions, integration points, feature boundaries, priority levels, scope visualization\n\n###  NEVER Include\nTechnical architecture/components, technology choices/frameworks, database schemas/API specs, implementation approaches, infrastructure/deployment, code structure, protocols/data formats\n\n### Categorization Rules\n- **Core**: Must have for MVP, blocks other features\n- **Supporting**: Enables core features, medium priority\n- **Enhancement**: Improves existing features, nice-to-have\n- **Integration**: Connects to external systems\n\n### Domain Grouping Rules\n- Group by business capability (not technical layer)\n- Each domain = cohesive related features\n- Minimize cross-domain dependencies\n- Name by business function (User Management, Payment Processing)\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"Feature relationships are obvious\" | Obvious to you  documented for team. Map them. |\n| \"We can figure out groupings during TRD\" | TRD architecture follows feature structure. Define it first. |\n| \"This feels like extra work\" | Skipping this causes rework when architecture mismatches features. |\n| \"The PRD already has this info\" | PRD lists features; map shows relationships. Different views. |\n| \"I'll just mention the components\" | Components are technical (TRD). This is business groupings only. |\n| \"User journeys are in the PRD\" | PRD has stories; map shows cross-feature flows. Different levels. |\n| \"Integration points are technical\" | Points WHERE features interact = business. HOW = technical (TRD). |\n| \"Priorities can be set later\" | Priority affects architecture decisions. Set them before TRD. |\n| \"Boundaries will be clear in code\" | Code structure follows feature boundaries. Define them first. |\n| \"This is just a simple feature\" | Even simple features have interactions. Map them. |\n\n## Red Flags - STOP\n\nIf you catch yourself writing any of these in a Feature Map, **STOP**:\n\n- Technology names (APIs, databases, frameworks)\n- Component names (AuthService, PaymentProcessor)\n- Technical terms (microservices, endpoints, schemas)\n- Implementation details (how data flows technically)\n- Architecture diagrams (system components)\n- Code organization (packages, modules, files)\n- Protocol specifications (REST, GraphQL, gRPC)\n\n**When you catch yourself**: Remove the technical detail. Focus on WHAT features do and HOW they relate at a business level.\n\n## Gate 2 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Feature Completeness** | All PRD features included; clear descriptions; categories assigned; none missing |\n| **Grouping Clarity** | Domains logically cohesive; clear boundaries; cross-domain deps minimized; business function names |\n| **Journey Mapping** | Primary journeys documented (start to finish); features touched shown; happy/error paths; handoffs identified |\n| **Integration Points** | All interactions identified; data/event exchange points marked; directional deps clear; circular deps resolved |\n| **Priority & Phasing** | MVP features identified; rationale documented; incremental value delivery; deps don't block MVP |\n\n**Gate Result:**  PASS  TRD |  CONDITIONAL (clarify boundaries) |  FAIL (poor groupings/missing features)\n\n## Feature Map Template Structure\n\nOutput to `docs/pre-dev/{feature-name}/feature-map.md` with these sections:\n\n| Section | Content |\n|---------|---------|\n| **Overview** | PRD reference, status, last updated |\n| **Feature Inventory** | Tables by category (Core/Supporting/Enhancement/Integration): Feature ID, Name, Description, User Value, Dependencies |\n| **Domain Groupings** | Per domain: Purpose, Features list, Boundaries (Owns/Consumes/Provides), Integration Points (/) |\n| **User Journeys** | Per journey: User Type, Goal, Path (steps with features, integrations, success/failure), Cross-Domain Interactions |\n| **Feature Interaction Map** | ASCII/text diagram with relationships, Dependency Matrix table (Feature, Depends On, Blocks, Optional) |\n| **Phasing Strategy** | Per phase: Goal, Timeline, Features, User Value, Success Criteria, Triggers for next phase |\n| **Scope Boundaries** | In Scope, Out of Scope (with rationale), Assumptions, Constraints |\n| **Risk Assessment** | Feature Complexity Risks table, Integration Risks table |\n| **Gate 2 Validation** | Date, validator, checklist, approval, next step |\n\n## Common Violations\n\n| Violation | Wrong | Correct |\n|-----------|-------|---------|\n| **Tech in Features** | `F-001: JWT-based auth with PostgreSQL sessions, Deps: Database, Redis cache` | `F-001: Users can create accounts and log in, User Value: Access personalized features, Deps: None (foundational), Blocks: F-002, F-003` |\n| **Tech in Domains** | `Domain: Auth Services with AuthService, TokenValidator, SessionManager components` | `Domain: User Identity - Purpose: Managing user accounts and sessions. Features: Registration, Login, Session Mgmt, Password Recovery. Owns: credentials, session state. Provides: identity verification` |\n| **Tech in Integration** | `User Auth  Profile: REST API call to /api/profile with JWT` | `User Auth  Profile: Provides verified user identity` |\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Feature Coverage | 0-25 | All mapped: 25, Most: 15, Some missing: 5 |\n| Relationship Clarity | 0-25 | All documented: 25, Most clear: 15, Unclear: 5 |\n| Domain Cohesion | 0-25 | Logically cohesive: 25, Mostly: 15, Poor boundaries: 5 |\n| Journey Completeness | 0-25 | All paths: 25, Primary: 15, Incomplete: 5 |\n\n**Action:** 80+ proceed to TRD | 50-79 address gaps | <50 rework groupings\n\n## Output & After Approval\n\n**Output to:** `docs/pre-dev/{feature-name}/feature-map.md`\n\n1.  Lock Feature Map - scope and relationships are now reference\n2.  Use as input for TRD (next phase)\n3.  Never add technical architecture retroactively\n4.  Keep business features separate from technical components\n\n## The Bottom Line\n\n**If you wrote a Feature Map with technical architecture details, remove them.**\n\nThe Feature Map is business-level feature relationships only. Period. No components. No APIs. No databases.\n\nTechnical architecture goes in TRD. That's the next phase. Wait for it.\n\n**Map the features. Understand relationships. Then architect in TRD.**"
              },
              {
                "name": "ring:pre-dev-prd-creation",
                "description": "Gate 1: Business requirements document - defines WHAT/WHY before HOW.\nCreates PRD with problem definition, user stories, success metrics.\n",
                "path": "pm-team/skills/pre-dev-prd-creation/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-prd-creation",
                  "description": "Gate 1: Business requirements document - defines WHAT/WHY before HOW.\nCreates PRD with problem definition, user stories, success metrics.\n",
                  "trigger": "- Starting new product or major feature\n- User asks to \"plan\", \"design\", or \"architect\"\n- About to write code without documented requirements\n- Asked to create PRD or requirements document\n",
                  "skip_when": "- PRD already exists and validated  proceed to Gate 2\n- Pure technical task without business impact  TRD directly\n- Bug fix  systematic-debugging\n",
                  "sequence": {
                    "before": [
                      "pre-dev-feature-map",
                      "pre-dev-trd-creation"
                    ]
                  }
                },
                "content": "# PRD Creation - Business Before Technical\n\n## Foundational Principle\n\n**Business requirements (WHAT/WHY) must be fully defined before technical decisions (HOW/WHERE).**\n\nMixing business and technical concerns creates:\n- Requirements that serve implementation convenience, not user needs\n- Technical constraints that limit product vision\n- Inability to evaluate alternatives objectively\n- Cascade failures when requirements change\n\n**The PRD answers**: WHAT we're building and WHY it matters to users and business.\n**The PRD never answers**: HOW we'll build it or WHERE components will live.\n\n## Mandatory Workflow\n\n| Phase | Activities |\n|-------|------------|\n| **0. Load Research** | Check `docs/pre-dev/{feature}/research.md`; review codebase patterns, best practices, framework constraints; reference findings with `file:line` notation |\n| **1. Problem Discovery** | Define problem without solution bias; identify specific users; quantify pain with metrics/evidence |\n| **2. Business Requirements** | Executive summary (3 sentences); user personas (goals, frustrations); user stories (As/I want/So that); success metrics (measurable); scope boundaries (in/out) |\n| **3. Gate 1 Validation** | Problem articulated; impact quantified; users identified; features address problem; metrics measurable; scope explicit |\n\n## Explicit Rules\n\n###  DO Include in PRD\nProblem definition and user pain points, user personas (demographics, goals, frustrations), user stories with acceptance criteria, feature requirements (WHAT not HOW), success metrics (adoption, satisfaction, KPIs), scope boundaries (in/out explicitly), go-to-market considerations\n\n###  NEVER Include in PRD\nArchitecture diagrams or component design, technology choices (languages, frameworks, databases), implementation approaches or algorithms, database schemas or API specifications, code examples or package dependencies, infrastructure needs or deployment strategies, system integration patterns\n\n### Separation Rules\n1. **If it's a technology name**  Not in PRD (goes in Dependency Map)\n2. **If it's a \"how to build\"**  Not in PRD (goes in TRD)\n3. **If it's implementation**  Not in PRD (goes in Tasks/Subtasks)\n4. **If it describes system behavior**  Not in PRD (goes in TRD)\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"Just a quick technical note won't hurt\" | Technical details constrain business thinking. Keep them separate. |\n| \"Stakeholders need to know it's feasible\" | Feasibility comes in TRD after business requirements are locked. |\n| \"The implementation is obvious\" | Obvious to you  obvious to everyone. Separate concerns. |\n| \"I'll save time by combining PRD and TRD\" | You'll waste time rewriting when requirements change. |\n| \"This is a simple feature, no need for formality\" | Simple features still need clear requirements. Follow the process. |\n| \"I can skip Gate 1, I know it's good\" | Gates exist because humans are overconfident. Validate. |\n| \"The problem is obvious, no need for personas\" | Obvious to you  validated with users. Document it. |\n| \"Success metrics can be defined later\" | Defining metrics later means building without targets. Do it now. |\n| \"I'll just add this one API endpoint detail\" | API design is technical architecture. Stop. Keep it in TRD. |\n| \"But we already decided on PostgreSQL\" | Technology decisions come after business requirements. Wait. |\n| \"CEO/CTO says it's a business constraint\" | Authority doesn't change what's technical. Abstract it anyway. |\n| \"Investors need to see specific vendors/tech\" | Show phasing and constraints abstractly. Vendors go in TRD. |\n| \"This is product scoping, not technical design\" | Scope = capabilities. Technology = implementation. Different things. |\n| \"Mentioning Stripe shows we're being practical\" | Mentioning \"payment processor\" shows the same. Stay abstract. |\n| \"PRDs can mention tech when it's a constraint\" | PRDs mention capabilities needed. TRD maps capabilities to tech. |\n| \"Context matters - this is for exec review\" | Context doesn't override principles. Executives get abstracted version. |\n\n## Security Requirements Discovery (Business Level)\n\n**During PRD creation, identify if the feature requires access control:**\n\n| Business Question | If Yes  Document |\n|-------------------|-------------------|\n| Does this feature handle user-specific data? | \"Users can only access their own [data type]\" |\n| Are there different user roles with different permissions? | \"Admins can [X], regular users can [Y]\" |\n| Does this feature need to identify who performed an action? | \"Audit trail required for [action type]\" |\n| Does this integrate with other internal services? | \"Service must authenticate to [service name]\" |\n| Are there regulatory requirements (GDPR, PCI-DSS, HIPAA)? | \"Must comply with [regulation] for [data type]\" |\n\n**What to include in PRD:**\n-  \"Only authenticated users can access this feature\"\n-  \"Users can only view/edit their own records\"\n-  \"Admin approval required for [action]\"\n-  \"Must track who performed each action\"\n\n**What NOT to include in PRD:**\n-  \"Use JWT tokens\" (technology choice  TRD)\n-  \"Integrate with Access Manager\" (architecture  TRD)\n-  \"OAuth2 flow\" (protocol choice  TRD)\n\n**Note:** The TRD (Gate 3) will translate these business requirements into authentication/authorization architecture patterns. For Go services, refer to `golang.md`  Access Manager Integration section during TRD creation.\n\n---\n\n## Red Flags - STOP\n\nIf you catch yourself writing or thinking any of these in a PRD, **STOP**:\n\n- Technology product names (PostgreSQL, Redis, Kafka, AWS, etc.)\n- Framework or library names (React, Fiber, Express, etc.)\n- Words like: \"architecture\", \"component\", \"service\", \"endpoint\", \"schema\"\n- Phrases like: \"we'll use X to do Y\" or \"the system will store data in Z\"\n- Code examples or API specifications\n- \"How we'll implement\" or \"Technical approach\"\n- Database table designs or data models\n- Integration patterns or protocols\n\n**When you catch yourself**: Move that content to a \"technical notes\" section to transfer to TRD later. Keep PRD pure business.\n\n## Gate 1 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Problem Definition** | Problem articulated (1-2 sentences); impact quantified/qualified; users specifically identified; current workarounds documented |\n| **Solution Value** | Features address core problem; success metrics measurable; ROI case documented; user value clear per feature |\n| **Scope Clarity** | In-scope items explicit; out-of-scope with rationale; assumptions documented; business dependencies identified |\n| **Market Fit** | Differentiation clear; value proposition validated; business case sound; go-to-market outlined |\n\n**Gate Result:**  PASS  Feature Map |  CONDITIONAL (address gaps) |  FAIL (return to discovery)\n\n## Common Violations\n\n| Violation | Wrong | Correct |\n|-----------|-------|---------|\n| **Tech in Features** | \"FR-001: Use JWT tokens for session, bcrypt for passwords, OAuth2 with Google\" | \"FR-001: Users can create accounts and securely log in. Value: Access personalized content. Success: 95% authenticate first attempt\" |\n| **Implementation in Stories** | \"As user, I want to store data in PostgreSQL so queries are fast\" | \"As user, I want dashboard to load in <2 seconds so I can quickly access information\" |\n| **Architecture in Problem** | \"Our microservices architecture doesn't support real-time notifications\" | \"Users miss important updates because they must manually refresh. 78% report missing time-sensitive info\" |\n| **Authority-Based Bypass** | \"MVP: Stripe for payments, PostgreSQL (we already use it)\" | \"Phase 1: Integrate with existing payment vendor (2-week timeline); leverage existing database infrastructure. TRD will document specific vendor selection\" |\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Market Validation | 0-25 | Direct user feedback: 25, Market research: 15, Assumptions: 5 |\n| Problem Clarity | 0-25 | Quantified pain: 25, Qualitative evidence: 15, Hypothetical: 5 |\n| Solution Fit | 0-25 | Proven pattern: 25, Adjacent pattern: 15, Novel: 5 |\n| Business Value | 0-25 | Clear ROI: 25, Indirect value: 15, Uncertain: 5 |\n\n**Action:** 80+ autonomous | 50-79 present options | <50 ask discovery questions\n\n## Output & After Approval\n\n**Output to:** `docs/pre-dev/{feature-name}/prd.md`\n\n1.  Lock the PRD - no changes without formal amendment\n2.  Use as input for Feature Map (`pre-dev-feature-map`)\n3.  Never add technical details retroactively\n4.  Keep business/technical strictly separated\n\n## The Bottom Line\n\n**If you wrote a PRD with technical details, delete it and start over.**\n\nThe PRD is business-only. Period. No exceptions. No \"just this once\". No \"but it's relevant\".\n\nTechnical details go in TRD. That's the next phase. Wait for it.\n\n**Follow the separation. Your future self will thank you.**"
              },
              {
                "name": "ring:pre-dev-research",
                "description": "Gate 0 research phase for pre-dev workflow. Dispatches 3 parallel research agents\nto gather codebase patterns, external best practices, and framework documentation\nBEFORE creating PRD/TRD. Outputs research.md with file:line references.\n",
                "path": "pm-team/skills/pre-dev-research/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-research",
                  "description": "Gate 0 research phase for pre-dev workflow. Dispatches 3 parallel research agents\nto gather codebase patterns, external best practices, and framework documentation\nBEFORE creating PRD/TRD. Outputs research.md with file:line references.\n",
                  "trigger": "- Before any pre-dev workflow (Gate 0)\n- When planning new features or modifications\n- Invoked by /pre-dev-full and /pre-dev-feature\n",
                  "skip_when": "- Trivial changes that don't need planning\n- Research already completed (research.md exists and is recent)\n",
                  "sequence": {
                    "before": [
                      "pre-dev-prd-creation",
                      "pre-dev-feature-map"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "pre-dev-prd-creation",
                      "pre-dev-trd-creation"
                    ]
                  },
                  "research_modes": {
                    "greenfield": {
                      "description": "New feature with no existing patterns to follow",
                      "primary_agents": [
                        "best-practices-researcher",
                        "framework-docs-researcher"
                      ],
                      "focus": "External best practices and framework patterns"
                    },
                    "modification": {
                      "description": "Changing or extending existing functionality",
                      "primary_agents": [
                        "repo-research-analyst"
                      ],
                      "focus": "Existing codebase patterns and conventions"
                    },
                    "integration": {
                      "description": "Connecting systems or adding external dependencies",
                      "primary_agents": [
                        "framework-docs-researcher",
                        "best-practices-researcher",
                        "repo-research-analyst"
                      ],
                      "focus": "API documentation and integration patterns"
                    }
                  }
                },
                "content": "# Pre-Dev Research Skill (Gate 0)\n\n**Purpose:** Gather comprehensive research BEFORE writing planning documents, ensuring PRDs and TRDs are grounded in codebase reality and industry best practices.\n\n## The Research-First Principle\n\n```\nTraditional:  Request  PRD  Discover problems during implementation\nResearch-First:  Request  Research  Informed PRD  Smoother implementation\n\nResearch prevents: Reinventing existing patterns, ignoring conventions, missing framework constraints, repeating solved problems\n```\n\n## Step 1: Determine Research Mode\n\n**BLOCKING GATE:** Before dispatching agents, determine the research mode.\n\n| Mode | When to Use | Example |\n|------|-------------|---------|\n| **greenfield** | No existing patterns | \"Add GraphQL API\" (when project has none) |\n| **modification** | Extending existing functionality | \"Add pagination to user list API\" |\n| **integration** | Connecting external systems | \"Integrate Stripe payments\" |\n\n**If unclear, ask:**\n> Before starting research: Is this (1) Greenfield - new capability, (2) Modification - extends existing, or (3) Integration - connects external systems?\n\n**Mode affects agent priority:**\n- Greenfield  Web research primary (best-practices, framework-docs)\n- Modification  Codebase research primary (repo-research)\n- Integration  All agents equally weighted\n\n## Step 2: Dispatch Research Agents\n\n**Run 3 agents in PARALLEL** (single message, 3 Task calls):\n\n| Agent | Prompt Focus |\n|-------|--------------|\n| `repo-research-analyst` | Codebase patterns for [feature]. Search docs/solutions/ knowledge base. Return file:line references. If modification mode: PRIMARY focus. |\n| `best-practices-researcher` | External best practices for [feature]. Use Context7 + WebSearch. Return URLs. If greenfield mode: PRIMARY focus. |\n| `framework-docs-researcher` | Tech stack docs for [feature]. Detect versions from manifests. Use Context7. Return version constraints. If integration mode: focus on SDK/API docs. |\n\n## Step 3: Aggregate Research Findings\n\n**Output:** `docs/pre-dev/{feature-name}/research.md`\n\n| Section | Content |\n|---------|---------|\n| **Metadata** | date, feature, research_mode, agents_dispatched |\n| **Executive Summary** | 2-3 sentences synthesizing key findings |\n| **Research Mode** | Why selected, what it means for focus |\n| **Codebase Research** | Agent output (file:line references) |\n| **Best Practices Research** | Agent output (URLs) |\n| **Framework Documentation** | Agent output (version constraints) |\n| **Synthesis** | Key patterns to follow (file:line, URL, doc ref); Constraints identified; Prior solutions from docs/solutions/; Open questions for PRD |\n\n## Step 4: Gate 0 Validation\n\n**BLOCKING CHECKLIST:**\n\n| Check | Required For |\n|-------|--------------|\n| Research mode documented | All modes |\n| All 3 agents returned | All modes |\n| research.md created | All modes |\n| At least one file:line reference | modification, integration |\n| At least one external URL | greenfield, integration |\n| docs/solutions/ searched | All modes |\n| Tech stack versions documented | All modes |\n| Synthesis section complete | All modes |\n\n**If validation fails:**\n- Missing agent output  Re-run that agent\n- No codebase patterns (modification)  May need mode change\n- No external docs (greenfield)  Try different search terms\n\n## Integration with Pre-Dev Workflow\n\n**pre-dev-full (9-gate):** Gate 0 Research  Gate 1 PRD (reads research.md)  ...  Gate 3 TRD (reads research.md)\n\n**pre-dev-feature (4-gate):** Gate 0 Research  Gate 1 PRD  Gate 2 TRD  Gate 3 Tasks\n\n## Research Document Usage\n\n**In Gate 1 (PRD):** Reference existing patterns with file:line; cite docs/solutions/; include external URLs; note framework constraints\n\n**In Gate 3 (TRD):** Reference implementation patterns; use version constraints; cite similar implementations\n\n## Anti-Patterns\n\n1. **Skipping research for \"simple\" features** - Even simple features benefit from convention checks\n2. **Wrong research mode** - Greenfield with heavy codebase research wastes time; modification without codebase research misses patterns\n3. **Ignoring docs/solutions/** - Prior solutions are gold; prevents repeating mistakes\n4. **Vague references without file:line** - \"There's a pattern somewhere\" is not useful; exact locations enable quick reference"
              },
              {
                "name": "ring:pre-dev-subtask-creation",
                "description": "Gate 8: Zero-context implementation steps - 2-5 minute atomic subtasks with\ncomplete code, exact commands, TDD pattern. Large Track only.\n",
                "path": "pm-team/skills/pre-dev-subtask-creation/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-subtask-creation",
                  "description": "Gate 8: Zero-context implementation steps - 2-5 minute atomic subtasks with\ncomplete code, exact commands, TDD pattern. Large Track only.\n",
                  "trigger": "- Tasks passed Gate 7 validation\n- Need absolute implementation clarity\n- Creating work for engineers with zero codebase context\n- Large Track workflow (2+ day features)\n",
                  "skip_when": "- Small Track workflow  execute tasks directly\n- Tasks simple enough without breakdown\n- Tasks not validated  complete Gate 7 first\n",
                  "sequence": {
                    "after": [
                      "pre-dev-task-breakdown"
                    ],
                    "before": [
                      "executing-plans",
                      "subagent-driven-development"
                    ]
                  }
                },
                "content": "# Subtask Creation - Bite-Sized, Zero-Context Steps\n\n## Overview\n\nWrite comprehensive implementation subtasks assuming the engineer has zero context for our codebase. Each subtask breaks down into 2-5 minute steps following RED-GREEN-REFACTOR. Complete code, exact commands, explicit verification. **DRY. YAGNI. TDD. Frequent commits.**\n\n**Save subtasks to:** `docs/pre-dev/{feature-name}/subtasks/T-[task-id]/ST-[task-id]-[number]-[description].md`\n\n## Foundational Principle\n\n**Every subtask must be completable by anyone with zero context about the system.**\n\nRequiring context creates bottlenecks, onboarding friction, and integration failures.\n\n**Subtasks answer**: Exactly what to create/modify, with complete code and verification.\n**Subtasks never answer**: Why the system works this way (context is removed).\n\n## Bite-Sized Step Granularity\n\n**Each step is one action (2-5 minutes):**\n- \"Write the failing test\" - step\n- \"Run it to make sure it fails\" - step\n- \"Implement the minimal code to make the test pass\" - step\n- \"Run the tests and make sure they pass\" - step\n- \"Commit\" - step\n\n## Subtask Document Structure\n\n**Header (required):**\n\n| Field | Content |\n|-------|---------|\n| Title | `# ST-[task-id]-[number]: [Subtask Name]` |\n| Agent Note | `> **For Agents:** REQUIRED SUB-SKILL: Use executing-plans` |\n| Goal | One sentence describing what this builds |\n| Prerequisites | Verification commands with expected output |\n| Files | Create: `exact/path`, Modify: `exact/path:lines`, Test: `tests/path` |\n\n**Step Structure (TDD Cycle):**\n\n| Step | Content |\n|------|---------|\n| Step 1: Write failing test | Complete test file with imports |\n| Step 2: Run test to verify fail | Command + expected failure output |\n| Step 3: Write minimal implementation | Complete implementation file |\n| Step 4: Run test to verify pass | Command + expected success output |\n| Step 5: Update exports (if needed) | Exact modification to index files |\n| Step 6: Verify type checking | Command + expected output |\n| Step 7: Commit | Exact git commands with message |\n| Rollback | Exact commands to undo if issues |\n\n## Explicit Rules\n\n###  DO Include in Subtasks\nExact file paths (absolute or from root), complete file contents (if creating), complete code snippets (if modifying), all imports and dependencies, step-by-step TDD cycle (numbered), verification commands (copy-pasteable), expected output (exact), rollback procedures (exact commands), prerequisites (what must exist first)\n\n###  NEVER Include in Subtasks\nPlaceholders: \"...\", \"TODO\", \"implement here\"; vague instructions: \"update the service\", \"add validation\"; assumptions: \"assuming setup is done\"; context requirements: \"you need to understand X first\"; incomplete code: \"add the rest yourself\"; missing imports: \"import necessary packages\"; undefined success: \"make sure it works\"; no verification: \"test it manually\"\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"The developer will figure out imports\" | Imports are context. Provide them explicitly. |\n| \"TODO comments are fine for simple parts\" | TODOs require decisions. Make them now. |\n| \"They'll know which service to update\" | They won't. Specify the exact file path. |\n| \"The verification steps are obvious\" | Obvious  documented. Write exact commands. |\n| \"Rollback isn't needed for simple changes\" | Simple changes fail too. Always provide rollback. |\n| \"This needs system understanding\" | Then you haven't removed context. Simplify more. |\n| \"I'll provide the template, they fill it\" | Templates are incomplete. Provide full code. |\n| \"The subtask description explains it\" | Descriptions need interpretation. Give exact steps. |\n| \"They can look at similar code for reference\" | That's context. Make subtask self-contained. |\n| \"This is too detailed, we're not that formal\" | Detailed = parallelizable = faster. Be detailed. |\n| \"Steps are too small, feels like hand-holding\" | Small steps = verifiable progress. Stay small. |\n\n## Red Flags - STOP\n\nIf you catch yourself writing any of these in a subtask, **STOP and rewrite**:\n\n- Code placeholders: `...`, `// TODO`, `// implement X here`\n- Vague file references: \"the user service\", \"the auth module\"\n- Assumption phrases: \"assuming you have\", \"make sure you\"\n- Incomplete imports: \"import required packages\"\n- Missing paths: Not specifying where files go\n- Undefined verification: \"test that it works\"\n- Steps longer than 5 minutes\n- Context dependencies: \"you need to understand X\"\n- No TDD cycle in implementation steps\n\n**When you catch yourself**: Expand the subtask until it's completely self-contained.\n\n## Gate 8 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Atomicity** | Each step 2-5 minutes; no system architecture understanding required; assignable to anyone |\n| **Completeness** | All code provided in full; all file paths explicit; all imports listed; all prerequisites documented; TDD cycle followed |\n| **Verifiability** | Test commands copy-pasteable; expected output exact; commands run from project root |\n| **Reversibility** | Rollback commands provided; rollback doesn't require system knowledge |\n\n**Gate Result:**  PASS  Ready for implementation |  CONDITIONAL (add details) |  FAIL (decompose further)\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Step Atomicity | 0-30 | All 2-5 minutes: 30, Most sized right: 20, Too large/vague: 10 |\n| Code Completeness | 0-30 | Zero placeholders: 30, Mostly complete: 15, Significant TODOs: 5 |\n| Context Independence | 0-25 | Anyone can execute: 25, Minor context: 15, Significant knowledge: 5 |\n| TDD Coverage | 0-15 | All RED-GREEN-REFACTOR: 15, Most have tests: 10, Limited: 5 |\n\n**Action:** 80+ autonomous | 50-79 present options | <50 ask about structure\n\n## Execution Handoff\n\nAfter creating subtasks, offer execution choice:\n\n**\"Subtasks complete. Two execution options:**\n1. **Subagent-Driven** - Fresh subagent per subtask, review between, fast iteration  Use `subagent-driven-development`\n2. **Parallel Session** - New session with executing-plans, batch with checkpoints  Use `executing-plans`\n\n**Which approach?\"**\n\n## The Bottom Line\n\n**If you wrote a subtask with \"TODO\" or \"...\" or \"add necessary imports\", delete it and rewrite with complete code.**\n\nSubtasks are not instructions. Subtasks are complete, copy-pasteable implementations following TDD.\n\n- \"Add validation\" is not a step. [Complete validation code with test] is a step.\n- \"Update the service\" is not a step. [Exact file path + exact code changes with test] is a step.\n- \"Import necessary packages\" is not a step. [Complete list of imports] is a step.\n\nEvery subtask must be completable by someone who:\n- Just joined the team yesterday\n- Has never seen the codebase before\n- Doesn't know the business domain\n- Won't ask questions (you're unavailable)\n- Follows TDD religiously\n\nIf they can't complete it with zero questions while following RED-GREEN-REFACTOR, **it's not atomic enough.**\n\n**Remember: DRY. YAGNI. TDD. Frequent commits.**"
              },
              {
                "name": "ring:pre-dev-task-breakdown",
                "description": "Gate 7: Implementation tasks - value-driven decomposition into working increments\nthat deliver measurable user value.\n",
                "path": "pm-team/skills/pre-dev-task-breakdown/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-task-breakdown",
                  "description": "Gate 7: Implementation tasks - value-driven decomposition into working increments\nthat deliver measurable user value.\n",
                  "trigger": "- PRD passed Gate 1 (required)\n- TRD passed Gate 3 (required)\n- All Large Track gates passed (if applicable)\n- Ready to create sprint/iteration tasks\n",
                  "skip_when": "- PRD or TRD not validated  complete earlier gates\n- Tasks already exist  proceed to Subtask Creation\n- Trivial change  direct implementation\n",
                  "sequence": {
                    "after": [
                      "pre-dev-trd-creation",
                      "pre-dev-dependency-map"
                    ],
                    "before": [
                      "pre-dev-subtask-creation",
                      "executing-plans"
                    ]
                  }
                },
                "content": "# Task Breakdown - Value-Driven Decomposition\n\n## Foundational Principle\n\n**Every task must deliver working software that provides measurable user value.**\n\nCreating technical-only or oversized tasks creates:\n- Work that doesn't ship until \"everything is done\"\n- Teams working on pieces that don't integrate\n- No early validation of value or technical approach\n- Waterfall development disguised as iterative process\n\n**Tasks answer**: What working increment will be delivered?\n**Tasks never answer**: How to implement that increment (that's Subtasks).\n\n## Mandatory Workflow\n\n| Phase | Activities |\n|-------|------------|\n| **1. Task Identification** | Load PRD (Gate 1, required), TRD (Gate 3, required); optional: Feature Map, API Design, Data Model, Dependency Map; identify value streams |\n| **2. Decomposition** | Per component/feature: define deliverable, set success criteria, map dependencies, estimate effort (S/M/L/XL max=2 weeks), plan testing, identify risks |\n| **3. Gate 7 Validation** | All TRD components covered; every task delivers working software; measurable success criteria; correct dependencies; no task >2 weeks; testing strategy defined; risks with mitigations; delivery sequence optimizes value |\n\n## Explicit Rules\n\n###  DO Include in Tasks\nTask ID, title, type (Foundation/Feature/Integration/Polish), deliverable (what ships), user value (what users can do), technical value (what it enables), success criteria (testable/measurable), dependencies (blocks/requires/optional), effort estimate (S/M/L/XL with points), testing strategy, risk identification with mitigations, Definition of Done checklist\n\n###  NEVER Include in Tasks\nImplementation details (file paths, code examples), step-by-step instructions (those go in subtasks), technical-only tasks with no user value, tasks exceeding 2 weeks (break them down), vague success criteria (\"improve performance\"), missing dependency information, undefined testing approach\n\n### Task Sizing Rules\n\n| Size | Points | Duration | Scope |\n|------|--------|----------|-------|\n| Small (S) | 1-3 | 1-3 days | Single component |\n| Medium (M) | 5-8 | 3-5 days | Few dependencies |\n| Large (L) | 13 | 1-2 weeks | Multiple components |\n| XL (>2 weeks) | BREAK IT DOWN | Too large | Not atomic |\n\n### Value Delivery Rules\n- **Foundation**: Enables other work (database setup, core services)\n- **Feature**: Delivers user-facing capabilities\n- **Integration**: Connects to external systems\n- **Polish**: Optimizes or enhances (nice-to-have)\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"This 3-week task is fine\" | Tasks >2 weeks hide complexity. Break it down. |\n| \"Setup tasks don't need value\" | Setup enables value. Define what it enables. |\n| \"Success criteria are obvious\" | Obvious to you  testable. Document explicitly. |\n| \"Dependencies will be clear later\" | Later is too late. Map them now. |\n| \"We don't need detailed estimates\" | Without estimates, no planning possible. Size them. |\n| \"Technical tasks can skip user value\" | Even infrastructure enables users. Define the connection. |\n| \"Testing strategy can be decided during\" | Testing affects design. Plan it upfront. |\n| \"Risks aren't relevant at task level\" | Risks compound across tasks. Identify them early. |\n| \"DoD is the same for all tasks\" | Different tasks need different criteria. Specify. |\n| \"We can combine multiple features\" | Combining hides value delivery. Keep tasks focused. |\n\n## Red Flags - STOP\n\nIf you catch yourself writing any of these in a task, **STOP**:\n\n- Task estimates over 2 weeks\n- Tasks named \"Setup X\" without defining what X enables\n- Success criteria like \"works\" or \"complete\" (not measurable)\n- No dependencies listed (every task depends on something)\n- No testing strategy (how will you verify?)\n- \"Technical debt\" as a task type (debt reduction must deliver value)\n- Vague deliverables (\"improve\", \"optimize\", \"refactor\")\n- Missing Definition of Done\n\n**When you catch yourself**: Refine the task until it's concrete, valuable, and testable.\n\n## Gate 7 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Task Completeness** | All TRD components have tasks; all PRD features have tasks; each task appropriately sized (no XL+); task boundaries clear |\n| **Delivery Value** | Every task delivers working software; user value explicit; technical value clear; sequence optimizes value |\n| **Technical Clarity** | Success criteria measurable/testable; dependencies correctly mapped; testing approach defined; DoD comprehensive |\n| **Team Readiness** | Skills match capabilities; estimates realistic; capacity available; handoffs minimized |\n| **Risk Management** | Risks identified per task; mitigations defined; high-risk tasks scheduled early; fallback plans exist |\n\n**Gate Result:**  PASS  Subtasks |  CONDITIONAL (refine oversized/vague) |  FAIL (re-decompose)\n\n## Task Template Structure\n\nOutput to `docs/pre-dev/{feature-name}/tasks.md`. Each task includes:\n\n| Section | Content |\n|---------|---------|\n| **Header** | T-[XXX]: [Task Title - What It Delivers] |\n| **Deliverable** | One sentence: what working software ships |\n| **Scope** | Includes (specific capabilities), Excludes (future tasks with IDs) |\n| **Success Criteria** | Testable items: Functional, Technical, Operational, Quality |\n| **User/Technical Value** | What users can do; what this enables |\n| **Technical Components** | From TRD, From Dependencies |\n| **Dependencies** | Blocks (T-AAA), Requires (T-BBB), Optional (T-CCC) |\n| **Effort Estimate** | Size (S/M/L/XL), Points, Duration, Team type |\n| **Risks** | Per risk: Impact, Probability, Mitigation, Fallback |\n| **Testing Strategy** | Unit, Integration, E2E, Performance, Security |\n| **Definition of Done** | Code reviewed, tests passing, docs updated, security clean, performance met, deployed to staging, PO acceptance, monitoring configured |\n\n## Common Violations\n\n| Violation | Wrong | Correct |\n|-----------|-------|---------|\n| **Technical-Only Tasks** | \"Setup PostgreSQL Database\" with install/configure steps | \"User Data Persistence Foundation\" with deliverable (working DB layer <100ms), user value (enables T-002/T-003), success criteria (users table, pooling, migrations) |\n| **Oversized Tasks** | \"Complete User Management System\" (6 weeks) with all auth features combined | Split into: T-005 Basic Auth (L), T-006 Password Mgmt (M), T-007 2FA (M), T-008 Permissions (L) |\n| **Vague Success Criteria** | \"Feature works, Tests pass, Code reviewed\" | Functional (upload 100MB, formats), Technical (<2s response), Operational (99.5% success rate), Quality (90% coverage) |\n\n## Delivery Sequencing\n\nOptimize task order by sprint/phase with goals, critical path identification, and parallel work opportunities.\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Task Decomposition | 0-30 | All appropriately sized: 30, Most well-scoped: 20, Too large/vague: 10 |\n| Value Clarity | 0-25 | Every task delivers working software: 25, Most clear: 15, Unclear: 5 |\n| Dependency Mapping | 0-25 | All documented: 25, Most clear: 15, Ambiguous: 5 |\n| Estimation Quality | 0-20 | Based on past work: 20, Educated guesses: 12, Speculation: 5 |\n\n**Action:** 80+ autonomous | 50-79 present options | <50 ask about velocity\n\n## Output & After Approval\n\n**Output to:** `docs/pre-dev/{feature-name}/tasks.md`\n\n1.  Tasks become sprint backlog\n2.  Use as input for subtasks (`pre-dev-subtask-creation`)\n3.  Track progress per task (not per subtask)\n4.  No implementation yet - that's in subtasks\n\n## The Bottom Line\n\n**If you created tasks that don't deliver working software, rewrite them.**\n\nTasks are not technical activities. Tasks are working increments.\n\n\"Setup database\" is not a task. \"User data persists correctly\" is a task.\n\"Implement OAuth\" is not a task. \"Users can log in with Google\" is a task.\n\"Write tests\" is not a task. Tests are part of Definition of Done for other tasks.\n\nEvery task must answer: **\"What working software can I demo to users?\"**\n\nIf you can't demo it, it's not a task. It's subtask implementation detail.\n\n**Deliver value. Ship working software. Make tasks demoable.**"
              },
              {
                "name": "ring:pre-dev-trd-creation",
                "description": "Gate 3: Technical architecture document - defines HOW/WHERE with technology-agnostic\npatterns before concrete implementation choices.\n",
                "path": "pm-team/skills/pre-dev-trd-creation/SKILL.md",
                "frontmatter": {
                  "name": "ring:pre-dev-trd-creation",
                  "description": "Gate 3: Technical architecture document - defines HOW/WHERE with technology-agnostic\npatterns before concrete implementation choices.\n",
                  "trigger": "- PRD passed Gate 1 (required)\n- Feature Map passed Gate 2 (if Large Track)\n- About to design technical architecture\n- Tempted to specify \"PostgreSQL\" instead of \"Relational Database\"\n",
                  "skip_when": "- PRD not validated  complete Gate 1 first\n- Architecture already documented  proceed to API Design\n- Pure business requirement change  update PRD\n",
                  "sequence": {
                    "after": [
                      "pre-dev-prd-creation",
                      "pre-dev-feature-map"
                    ],
                    "before": [
                      "pre-dev-api-design",
                      "pre-dev-task-breakdown"
                    ]
                  }
                },
                "content": "# TRD Creation - Architecture Before Implementation\n\n## Foundational Principle\n\n**Architecture decisions (HOW/WHERE) must be technology-agnostic patterns before concrete implementation choices.**\n\nSpecifying technologies in TRD creates:\n- Vendor lock-in before evaluating alternatives\n- Architecture coupled to specific products\n- Technology decisions made without full dependency analysis\n\n**The TRD answers**: HOW we'll architect the solution and WHERE components will live.\n**The TRD never answers**: WHAT specific products, frameworks, versions, or packages we'll use.\n\n---\n\n##  HARD BLOCK: Tech Stack Definition (Step 0)\n\n**This is a HARD GATE. Do NOT proceed without defining the tech stack.**\n\n### Step 0.1: Auto-Detect or Ask User\n\n**Auto-detection:** `go.mod` exists  Go | `package.json` with react/next  Frontend TS | `package.json` with express/fastify/nestjs  Backend TS\n\n**If ambiguous, AskUserQuestion:** \"What is the primary technology stack?\" Options: Go (Backend), TypeScript (Backend), TypeScript (Frontend), Full-Stack TypeScript\n\n### Step 0.2: Load Ring Standards via WebFetch\n\n| Standard | URL | Purpose |\n|----------|-----|---------|\n| **golang.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/golang.md` | Go patterns, DDD |\n| **typescript.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/typescript.md` | TS patterns, async |\n| **frontend.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/frontend.md` | React, Next.js, a11y |\n| **devops.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/devops.md` | Docker, CI/CD |\n| **sre.md** | `https://raw.githubusercontent.com/LerianStudio/ring/main/dev-team/docs/standards/sre.md` | Health checks, logging |\n\n| Tech Stack | Load |\n|------------|------|\n| Go Backend | golang.md + devops.md + sre.md |\n| TypeScript Backend | typescript.md + devops.md + sre.md |\n| TypeScript Frontend | frontend.md + devops.md |\n| Full-Stack TypeScript | typescript.md + frontend.md + devops.md + sre.md |\n\n### Step 0.3: Read PROJECT_RULES.md\n\nCheck: `docs/PROJECT_RULES.md`  `docs/STANDARDS.md` (legacy)  STOP if not found\n\n### Step 0.4: Analyze PRD and Suggest Technologies\n\nRead PRD, extract requirements, suggest technologies that address each, present to user for confirmation. Document in TRD metadata for Gate 6 to create PROJECT_RULES.md.\n\n**AskUserQuestion:** \"What deployment model?\" Options: Cloud, On-Premise, Hybrid\n\n### Step 0.5: Document in TRD Metadata\n\nTRD header must include: `feature`, `gate: 3`, `deployment.model`, `tech_stack.primary`, `tech_stack.standards_loaded[]`, `project_technologies[]` (category, prd_requirement, choice, rationale per technology decision)\n\nThis metadata flows to Gates 4-6.\n\n### Pressure Resistance for Step 0\n\n| Pressure | Response |\n|----------|----------|\n| \"Tech stack doesn't matter for architecture\" | \"Architecture patterns vary by language. Go patterns  TypeScript patterns. Define stack first.\" |\n| \"We'll decide tech stack later\" | \"Later = Dependency Map. But architecture NOW needs to know capabilities. Define stack.\" |\n| \"Just use generic patterns\" | \"Generic patterns miss stack-specific best practices. 5 min to define saves rework.\" |\n| \"Skip to save time\" | \"Skipping causes Gates 4-6 to ask again. Define once here, inherit everywhere.\" |\n\n---\n\n## Mandatory Workflow\n\n| Phase | Activities |\n|-------|------------|\n| **1. Analysis (After Step 0)** | PRD (Gate 1) required; Feature Map (Gate 2) optional; identify NFRs (performance, security, scalability); map domains to components |\n| **2. Architecture Definition** | Choose style (Microservices, Modular Monolith, Serverless); design components with boundaries; define interfaces; model data architecture; plan integration patterns; design security |\n| **3. Gate 3 Validation** | All domains mapped; component boundaries clear; interfaces technology-agnostic; data ownership explicit; quality attributes achievable; no specific products named |\n\n## Explicit Rules\n\n###  DO Include\nSystem architecture style (patterns, not products), component design with responsibilities, data architecture (ownership, flows - conceptual), API design (contracts, not protocols), security architecture (layers, threat model), integration patterns (sync/async, not tools), performance targets, deployment topology (logical)\n\n###  NEVER Include\nTechnology products (PostgreSQL, Redis, Kafka), framework versions (Fiber v2, React 18), language specifics (Go 1.24, Node.js 20), cloud services (AWS RDS, Azure Functions), packages (bcrypt, zod, prisma), container orchestration (Kubernetes, ECS), CI/CD details, IaC specifics\n\n### Technology Abstraction Rules\n\n| Element | Say This () | Not This () |\n|---------|--------------|---------------|\n| Database | \"Relational Database\" | \"PostgreSQL 16\" |\n| Cache | \"In-Memory Cache\" | \"Redis\" or \"Valkey\" |\n| Message Queue | \"Message Broker\" | \"RabbitMQ\" |\n| Object Storage | \"Blob Storage\" | \"MinIO\" or \"S3\" |\n| Web Framework | \"HTTP Router\" | \"Fiber\" or \"Express\" |\n| Auth | \"JWT-based Authentication\" | \"specific library\" |\n\n## Rationalization Table\n\n| Excuse | Reality |\n|--------|---------|\n| \"Everyone knows we use PostgreSQL\" | Assumptions prevent proper evaluation. Stay abstract. |\n| \"Just mentioning the tech stack for context\" | Context belongs in Dependency Map. Keep TRD abstract. |\n| \"The team needs to know what we're using\" | They'll know in Dependency Map. TRD is patterns only. |\n| \"It's obvious we need Redis here\" | Obvious  documented. Abstract to \"cache\", decide later. |\n| \"I'll save time by specifying frameworks now\" | You'll waste time when better options emerge. Wait. |\n| \"But our project template requires X\" | Templates are implementation. TRD is architecture. Separate. |\n| \"The dependency is critical to the design\" | Then describe the *capability* needed, not the product. |\n| \"Stakeholders expect to see technology choices\" | Stakeholders see them in Dependency Map. Not here. |\n| \"Architecture decisions depend on technology X\" | Then your architecture is too coupled. Redesign abstractly. |\n| \"We already decided on the tech stack\" | Decisions without analysis are assumptions. Validate later. |\n\n## Red Flags - STOP\n\nIf you catch yourself writing any of these in a TRD, **STOP**:\n\n- Specific product names with version numbers\n- Package manager commands (npm install, go get, pip install)\n- Cloud provider service names (RDS, Lambda, Cloud Run, etc.)\n- Framework-specific terms (Fiber middleware, React hooks, Express routers)\n- Container/orchestration specifics (Docker, K8s, ECS)\n- Programming language version constraints\n- Infrastructure service names (CloudFront, Cloudflare, Fastly)\n- CI/CD tool names (GitHub Actions, CircleCI, Jenkins)\n\n**When you catch yourself**: Replace the product name with the capability it provides. \"PostgreSQL 16\"  \"Relational Database with ACID guarantees\"\n\n## Gate 3 Validation Checklist\n\n| Category | Requirements |\n|----------|--------------|\n| **Architecture Completeness** | All PRD features mapped; DDD boundaries; single clear responsibilities; stable interfaces |\n| **Data Design** | Ownership explicit; models support PRD; consistency strategy defined; flows documented |\n| **Quality Attributes** | Performance targets set; security addressed; scalability path clear; reliability defined |\n| **Integration Readiness** | External deps identified (by capability); patterns selected (not tools); errors considered; versioning strategy exists |\n| **Technology Agnostic** | Zero product names; capabilities abstract; patterns named not implementations; can swap tech without redesign |\n\n**Gate Result:**  PASS  API Design |  CONDITIONAL (remove product names) |  FAIL (too coupled)\n\n## Common Violations\n\n| Violation | Wrong | Correct |\n|-----------|-------|---------|\n| **Tech in Architecture** | `Language: Go 1.24+, Framework: Fiber v2.52+, Database: PostgreSQL 16` | `Style: Modular Monolith, Pattern: Hexagonal, Data Tier: Relational DB, Key-value store, Object storage` |\n| **Framework in Components** | `Fiber middleware for JWT, bcrypt for passwords, passport.js for OAuth2` | `Auth Component: Purpose, Inbound (HTTP endpoints), Outbound (persistence, notifications), Security (token-based, industry-standard hashing)` |\n| **Cloud Services in Deployment** | `Compute: AWS ECS Fargate, Database: AWS RDS, Cache: ElastiCache` | `Compute: Container-based stateless, Data Tier: Managed DB with backup, Performance: Distributed caching, Traffic: Load balanced with health checks` |\n\n## Pagination Strategy (Required for List Endpoints)\n\nIf feature includes list/browse, decide during TRD:\n\n| Strategy | Best For | Trade-off | Performance |\n|----------|----------|-----------|-------------|\n| **Cursor-Based** | >10k records, infinite scroll, real-time | Can't jump pages | O(1) |\n| **Page-Based (Offset)** | <10k records, admin interfaces | Degrades with large offsets | O(n) |\n| **Page-Based + Total Count** | \"Page X of Y\" UI | Additional COUNT query | 2 queries |\n| **No Pagination** | Very small bounded datasets (<100) | All data at once | - |\n\nDocument in TRD: `API Patterns  Pagination  Strategy + Rationale`\n\n## Authentication/Authorization Architecture (If Required)\n\nIf feature requires authentication or authorization (as determined in Question 2 of pre-dev command):\n\n| Auth Type | TRD Description (Abstract) | Implementation Reference |\n|-----------|---------------------------|-------------------------|\n| User authentication only | \"Token-based authentication with stateless validation\" | For Go: `golang.md`  Access Manager Integration |\n| User + permissions | \"Token-based authentication with role-based access control (RBAC)\" | For Go: `golang.md`  Access Manager Integration |\n| Service-to-service | \"Machine-to-machine authentication with client credentials\" | For Go: `golang.md`  Access Manager Integration (GetApplicationToken) |\n| Full (user + S2S) | \"Dual-layer authentication: user tokens for end-users, client credentials for services\" | For Go: `golang.md`  Access Manager Integration |\n\n**Document in TRD:** `Security Architecture  Authentication/Authorization  Strategy + Implementation Reference`\n\n**Key Implementation Pattern (for TRD reference):**\n- Every protected endpoint requires middleware authorization\n- Pattern: `auth.Authorize(applicationName, resource, action)` on each route\n- Engineers will implement per-route protection following the referenced standard\n\n**Note for Go Services:** Lerian's Access Manager (plugin-auth + identity + lib-auth) is the standard authentication system. Reference `golang.md`  Access Manager Integration section in the TRD so engineers know where to find implementation patterns including route middleware protection.\n\n## License Manager Architecture (If Required)\n\nIf feature is a licensed product/plugin (as determined in Question 3 of pre-dev command):\n\n| License Type | TRD Description (Abstract) | Implementation Reference |\n|--------------|---------------------------|-------------------------|\n| Single-org (global) | \"Global license validation at service startup with fail-fast behavior\" | For Go: `golang.md`  License Manager Integration |\n| Multi-org | \"Per-request license validation with organization context\" | For Go: `golang.md`  License Manager Integration |\n\n**Document in TRD:** `Security Architecture  Licensing  Strategy + Implementation Reference`\n\n**Key Architecture Pattern (for TRD reference):**\n- License validation as global middleware (applied early in chain)\n- Fail-fast on startup: service refuses to start without valid license\n- Graceful shutdown integration for license manager resources\n- Built-in skip paths for health/readiness endpoints\n\n**Note for Go Services:** Lerian's License Manager (lib-license-go) is the standard licensing system. Reference `golang.md`  License Manager Integration section in the TRD so engineers know where to find implementation patterns including global middleware and graceful shutdown.\n\n## ADR Template\n\n```markdown\n**ADR-00X: [Pattern Name]**\n- **Context**: [Problem needing solution]\n- **Options**: [List with trade-offs - no products]\n- **Decision**: [Selected pattern]\n- **Rationale**: [Why this pattern]\n- **Consequences**: [Impact of decision]\n```\n\n## Confidence Scoring\n\n| Factor | Points | Criteria |\n|--------|--------|----------|\n| Pattern Match | 0-40 | Exact before: 40, Similar: 25, Novel: 10 |\n| Complexity Management | 0-30 | Simple proven: 30, Moderate: 20, High: 10 |\n| Risk Level | 0-30 | Low proven: 30, Moderate mitigated: 20, High accepted: 10 |\n\n**Action:** 80+ present autonomously | 50-79 present options | <50 request clarification\n\n## Output & After Approval\n\n**Output to:** `docs/pre-dev/{feature-name}/trd.md`\n\n1.  Lock TRD - architecture patterns are now reference\n2.  Use as input for API Design (`pre-dev-api-design`)\n3.  Never add technologies retroactively\n4.  Keep architecture/implementation strictly separated\n\n## The Bottom Line\n\n**If you wrote a TRD with specific technology products, delete those sections and rewrite abstractly.**\n\nThe TRD is architecture patterns only. Period. No product names. No versions. No frameworks.\n\nTechnology choices go in Dependency Map. That's the next phase. Wait for it.\n\n**Stay abstract. Stay flexible. Make technology decisions in the next phase with full analysis.**"
              },
              {
                "name": "ring:using-pm-team",
                "description": "10 pre-dev workflow skills + 3 research agents organized into Small Track (4 gates, <2 days) and\nLarge Track (9 gates, 2+ days) for systematic feature planning with research-first approach.\n",
                "path": "pm-team/skills/using-pm-team/SKILL.md",
                "frontmatter": {
                  "name": "ring:using-pm-team",
                  "description": "10 pre-dev workflow skills + 3 research agents organized into Small Track (4 gates, <2 days) and\nLarge Track (9 gates, 2+ days) for systematic feature planning with research-first approach.\n",
                  "trigger": "- Starting any feature implementation\n- Need systematic planning before coding\n- User requests \"plan a feature\"\n",
                  "skip_when": "- Quick exploratory work  brainstorming may suffice\n- Bug fix with known solution  direct implementation\n- Trivial change (<1 hour)  skip formal planning\n"
                },
                "content": "# Using Ring Team-Product: Pre-Dev Workflow\n\nThe ring-pm-team plugin provides 10 pre-development planning skills and 3 research agents. Use them via `Skill tool: \"ring:gate-name\"` or via slash commands.\n\n**Remember:** Follow the **ORCHESTRATOR principle** from `using-ring`. Dispatch pre-dev workflow to handle planning; plan thoroughly before coding.\n\n## Pre-Dev Philosophy\n\n**Before you code, you plan. Every time.**\n\nPre-dev workflow ensures:\n-  Requirements are clear (WHAT/WHY)\n-  Architecture is sound (HOW)\n-  APIs are contracts (boundaries)\n-  Data models are explicit (entities)\n-  Dependencies are known (tech choices)\n-  Tasks are atomic (2-5 min each)\n-  Implementation is execution, not design\n\n## Two Tracks: Choose Your Path\n\n### Small Track (4 Gates)  <2 Day Features\n\n**Use when ALL criteria met:**\n-  Implementation <2 days\n-  No new external dependencies\n-  No new data models\n-  No multi-service integration\n-  Uses existing architecture\n-  Single developer\n\n| Gate | Skill | Output |\n|------|-------|--------|\n| 0 | pre-dev-research | research.md |\n| 1 | pre-dev-prd-creation | PRD.md |\n| 2 | pre-dev-trd-creation | TRD.md |\n| 3 | pre-dev-task-breakdown | tasks.md |\n\n**Planning time:** 45-75 minutes\n\n### Large Track (9 Gates)  2 Day Features\n\n**Use when ANY criteria met:**\n-  Implementation 2 days\n-  New external dependencies\n-  New data models/entities\n-  Multi-service integration\n-  New architecture patterns\n-  Team collaboration needed\n\n| Gate | Skill | Output |\n|------|-------|--------|\n| 0 | pre-dev-research | research.md |\n| 1 | pre-dev-prd-creation | PRD.md |\n| 2 | pre-dev-feature-map | feature-map.md |\n| 3 | pre-dev-trd-creation | TRD.md |\n| 4 | pre-dev-api-design | API.md |\n| 5 | pre-dev-data-model | data-model.md |\n| 6 | pre-dev-dependency-map | dependencies.md |\n| 7 | pre-dev-task-breakdown | tasks.md |\n| 8 | pre-dev-subtask-creation | subtasks/ |\n\n**Planning time:** 2.5-4.5 hours\n\n## Gate Summaries\n\n| Gate | Skill | What It Does |\n|------|-------|--------------|\n| 0 | pre-dev-research | Parallel research: codebase patterns, best practices, framework docs |\n| 1 | pre-dev-prd-creation | Business requirements (WHAT/WHY), user stories, success metrics |\n| 2 | pre-dev-feature-map | Feature relationships, dependencies, deployment order (Large only) |\n| 3 | pre-dev-trd-creation | Technical architecture, technology-agnostic patterns |\n| 4 | pre-dev-api-design | API contracts, operations, error handling (Large only) |\n| 5 | pre-dev-data-model | Entities, relationships, ownership (Large only) |\n| 6 | pre-dev-dependency-map | Explicit tech choices, versions, licenses (Large only) |\n| 7 | pre-dev-task-breakdown | Value-driven tasks with success criteria |\n| 8 | pre-dev-subtask-creation | Zero-context 2-5 min implementation steps (Large only) |\n\n## Research Agents (Gate 0)\n\n| Agent | Focus |\n|-------|-------|\n| `repo-research-analyst` | Codebase patterns, docs/solutions/ knowledge base |\n| `best-practices-researcher` | Web search, Context7 for best practices |\n| `framework-docs-researcher` | Tech stack versions, official patterns |\n\n**Research Modes:**\n- **greenfield**: Web research primary (new capability)\n- **modification**: Codebase research primary (extending existing)\n- **integration**: All agents equally weighted (connecting systems)\n\n## Using Pre-Dev Workflow\n\n### Via Slash Commands\n\n```\n/pre-dev-feature logout-button    # Small track (4 gates)\n/pre-dev-full payment-system      # Large track (9 gates)\n```\n\n### Via Skills (Manual)\n\n```\nSkill tool: \"ring:pre-dev-prd-creation\"\n(Review output)\nSkill tool: \"ring:pre-dev-trd-creation\"\n(Review output)\n```\n\n## Output Structure\n\n```\ndocs/pre-dev/{feature}/\n research.md        # Gate 0\n prd.md             # Gate 1\n feature-map.md     # Gate 2 (large only)\n trd.md             # Gate 3\n api-design.md      # Gate 4 (large only)\n data-model.md      # Gate 5 (large only)\n dependency-map.md  # Gate 6 (large only)\n tasks.md           # Gate 7\n subtasks/          # Gate 8 (large only)\n```\n\n## Decision: Small or Large Track?\n\n**When in doubt: Use Large Track.** Better to over-plan than discover mid-implementation that feature is larger.\n\n**You can switch:** If Small Track feature grows, pause and complete Large Track gates.\n\n## Integration with Other Plugins\n\n| Plugin | Use For |\n|--------|---------|\n| using-ring (default) | ORCHESTRATOR principle for ALL tasks |\n| using-dev-team | Developer specialists for reviewing designs |\n| using-finops-team | Regulatory compliance planning |\n| using-tw-team | Documentation for features |\n\n**Combined with:**\n- `execute-plan`  Run tasks in batches\n- `write-plan`  Generate plan from scratch\n- `*-engineer`  Specialist review of design\n- `requesting-code-review`  Post-implementation review\n\n## ORCHESTRATOR Principle\n\n- **You're the orchestrator**  Dispatch pre-dev skills, don't plan manually\n- **Don't skip gates**  Each gate adds clarity\n- **Don't code without planning**  Plan first, code second\n- **Use agents for specialist review**  Dispatch engineers to review TRD\n\n### Good (ORCHESTRATOR):\n> \"I need to plan payment system. Let me run /pre-dev-full, then dispatch backend-engineer-golang to review the architecture.\"\n\n### Bad (OPERATOR):\n> \"I'll start coding and plan as I go.\""
              }
            ]
          },
          {
            "name": "ring-finops-team",
            "description": "FinOps and Brazilian regulatory compliance skills for financial systems",
            "source": "./finops-team",
            "category": null,
            "version": "0.6.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add LerianStudio/ring",
              "/plugin install ring-finops-team@ring"
            ],
            "signals": {
              "stars": 39,
              "forks": 2,
              "pushed_at": "2026-01-12T18:20:36Z",
              "created_at": "2025-10-30T20:18:13Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "ring:regulatory-templates-gate1",
                "description": "Gate 1 sub-skill - performs regulatory compliance analysis and field mapping\nfrom template specifications.\n",
                "path": "finops-team/skills/regulatory-templates-gate1/SKILL.md",
                "frontmatter": {
                  "name": "ring:regulatory-templates-gate1",
                  "description": "Gate 1 sub-skill - performs regulatory compliance analysis and field mapping\nfrom template specifications.\n",
                  "trigger": "- regulatory-templates-setup completed\n- Need to analyze regulatory specification and map fields\n",
                  "skip_when": "- Setup not complete  run setup first\n- Gate 1 already passed  proceed to Gate 2\n",
                  "sequence": {
                    "after": [
                      "regulatory-templates-setup"
                    ],
                    "before": [
                      "regulatory-templates-gate2"
                    ]
                  }
                },
                "content": "# Regulatory Templates - Gate 1: Placeholder Mapping (Post Gate 0)\n\n## Overview\n\n**UPDATED: Gate 1 now maps placeholders from Gate 0 template to data sources. NO structure creation, NO logic addition.**\n\n**Parent skill:** `regulatory-templates`\n\n**Prerequisites:**\n- Context from `regulatory-templates-setup`\n- Template base from `regulatory-templates-setup`\n\n**Output:** Mapping of placeholders to backend data sources\n\n---\n\n## Foundational Principle\n\n**Field mapping errors compound through Gates 2-3 and into production.**\n\nGate 1 is the foundation of regulatory template accuracy:\n- **snake_case conversion**: Python/Django ecosystem standard (PEP 8) - mixed conventions cause maintenance nightmares\n- **Data source prefixes**: BACEN audits require data lineage traceability - \"where did this value come from?\"\n- **Interactive validation**: No dictionary = no ground truth - user approval prevents assumption errors\n- **Confidence thresholds**: Quality gates prevent low-confidence mappings from reaching production\n- **Dictionary checks**: Consistency across team, audit trail for regulatory reviews\n\n**Every \"shortcut\" in Gate 1 multiplies through downstream gates:**\n- Skip snake_case  Gate 3 templates have mixed conventions  maintenance debt\n- Skip prefixes  Gate 2 cannot trace data sources  debugging nightmares\n- Auto-approve mappings  Gate 2 validates wrong assumptions  compliance violations\n- Skip optional fields  Gate 1 fails confidence threshold  rework loops\n- Lower thresholds  Low-confidence fields reach Gate 3  production errors\n\n**Technical correctness in Gate 1 = foundation for compliance in production.**\n\n---\n\n## When to Use\n\n**Called by:** `regulatory-templates` skill after Gate 0 template structure copy\n\n**Purpose:** Map each placeholder to its data source - structure already defined in Gate 0\n\n---\n\n## NO EXCEPTIONS - Technical Requirements Are Mandatory\n\n**Gate 1 field mapping requirements have ZERO exceptions.** Every requirement exists to prevent specific failure modes.\n\n### Common Pressures You Must Resist\n\n| Pressure | Your Thought | Reality |\n|----------|--------------|---------|\n| **Speed** | \"camelCase works, skip conversion\" | PEP 8 violation creates maintenance debt. 30 min now vs 75+ min debugging later |\n| **Simplicity** | \"Prefix is verbose, omit it\" | BACEN audits require data lineage. Implicit resolution = debugging nightmares |\n| **Efficiency** | \"AUTO-approve obvious mappings\" | No dictionary = no ground truth. \"Obvious\" assumptions cause compliance violations |\n| **Pragmatism** | \"Skip optional fields\" | Confidence calculated across ALL fields. 64% coverage = FAIL |\n| **Authority** | \"75% confidence is enough\" | Threshold erosion: 75%  70%  60%. LOW confidence fields = high-risk mappings |\n| **Experience** | \"I memorized these, skip dictionary\" | Memory is fallible. 1-min check prevents 20-40 min error correction |\n\n### Technical Requirements (Non-Negotiable)\n\n**snake_case Conversion:**\n-  REQUIRED: Convert ALL field names to snake_case\n-  FORBIDDEN: Use camelCase, PascalCase, or mixed conventions\n- Why: Python/Django PEP 8 standard, grep-able patterns, maintenance\n\n**Data Source Prefixes:**\n-  REQUIRED: `{{ midaz_onboarding.organization.0.legal_document }}`\n-  FORBIDDEN: `{{ organization.legal_document }}`\n- Why: Data lineage traceability, multi-source disambiguation, audit compliance\n\n**Interactive Validation:**\n-  REQUIRED: AskUserQuestion for EACH field mapping\n-  FORBIDDEN: Auto-approve HIGH confidence fields\n- Why: No dictionary = no ground truth, user provides domain knowledge\n\n**Confidence Threshold:**\n-  REQUIRED: Overall confidence  80%\n-  FORBIDDEN: Lower threshold or skip fields\n- Why: Quality gate for Gate 2/3, prevents low-confidence mappings in production\n\n**Dictionary Check:**\n-  REQUIRED: Check `~/.claude/docs/regulatory/dictionaries/` first\n-  FORBIDDEN: Skip check and use memory\n- Why: Consistency, audit trail, error prevention\n\n### The Bottom Line\n\n**Shortcuts in field mapping = errors in production regulatory submissions.**\n\nGate 1 creates the foundation for Gates 2-3. Technical correctness here prevents compliance violations downstream.\n\n**If you're tempted to skip ANY requirement, ask yourself: Am I willing to debug production BACEN submission failures caused by this shortcut?**\n\n---\n\n## Rationalization Table - Know the Excuses\n\nEvery rationalization below has been used to justify skipping requirements. **ALL are invalid.**\n\n| Excuse | Why It's Wrong | Correct Response |\n|--------|---------------|------------------|\n| \"camelCase works fine in Django\" | PEP 8 violation, maintenance debt, inconsistent conventions | Convert ALL to snake_case |\n| \"Prefix is verbose and ugly\" | Audit trail required, multi-source disambiguation critical | Prefix ALL fields |\n| \"HIGH confidence = obvious, no approval needed\" | No dictionary = no ground truth, assumptions fail | Ask approval for EACH field |\n| \"Optional fields don't affect compliance\" | Confidence calculated across ALL fields, 64% = FAIL | Map ALL fields |\n| \"75% is close to 80%, good enough\" | Threshold erosion, LOW confidence = high risk | Research to 80% |\n| \"I know these mappings by heart\" | Memory fallible, experience creates overconfidence | Check dictionary first |\n| \"Everyone knows where organization comes from\" | Implicit tribal knowledge, new team members lost | Explicit beats implicit |\n| \"User approval wastes their time\" | User provides domain knowledge we lack | Interactive validation mandatory |\n| \"Conversion is unnecessary busywork\" | Dismissing requirements without understanding cost | Technical correctness prevents debt |\n| \"This is simple, process is overkill\" | Simple tasks accumulate into complex problems | Follow workflow completely |\n\n### If You Find Yourself Making These Excuses\n\n**STOP. You are rationalizing.**\n\nThe requirements exist to prevent these exact thoughts from causing errors. If a requirement seems \"unnecessary,\" that's evidence it's working - preventing shortcuts that seem reasonable but create risk.\n\n---\n\n## CRITICAL CHANGE\n\n###  OLD Gate 1 (Over-engineering)\n- Created complex field mappings\n- Added transformation logic\n- Built nested structures\n- Result: 90+ line templates\n\n###  NEW Gate 1 (Simple)\n- Takes template from Gate 0\n- Maps placeholders to single data source\n- NO structural changes\n- Result: <20 line templates\n\n###  CRITICAL: NAMING CONVENTION - SNAKE_CASE STANDARD\n**ALL field names MUST be converted to snake_case:**\n-  If API returns `legalDocument`  convert to `legal_document`\n-  If API returns `taxId`  convert to `tax_id`\n-  If API returns `openingDate`  convert to `opening_date`\n-  If API returns `naturalPerson`  convert to `natural_person`\n-  If API returns `tax_id`  keep as `tax_id` (already snake_case)\n\n**ALWAYS convert camelCase, PascalCase, or any other convention to snake_case.**\n\n###  CRITICAL: DATA SOURCES - ALWAYS USE CORRECT DOMAIN PREFIX\n\n**REFERENCE:** See `/docs/regulatory/DATA_SOURCES.md` for complete documentation.\n\n**Available Data Sources (Reporter Platform):**\n\n| Data Source | Descrio | Entidades Principais |\n|-------------|-----------|---------------------|\n| `midaz_onboarding` | Dados cadastrais | organization, account |\n| `midaz_transaction` | Dados transacionais | operation_route, balance, operation |\n| `midaz_onboarding_metadata` | Metadados cadastro | custom fields |\n| `midaz_transaction_metadata` | Metadados transaes | custom fields |\n\n**Field Path Format:** `{data_source}.{entity}.{index?}.{field}`\n\n**Examples:** `{{ midaz_onboarding.organization.0.legal_document }}` | `{{ midaz_transaction.operation_route.code }}` | `{{ midaz_transaction.balance.available }}`\n\n**Common Mappings:** CNPJ`organization.0.legal_document`, COSIF`operation_route.code`, Saldo`balance.available`\n\n**RULE:** Always prefix with data source!  `{{ organization.legal_document }}`   `{{ midaz_onboarding.organization.0.legal_document }}`\n\n---\n\n## Gate 1 Process\n\n### STEP 1: Check for Data Dictionary (FROM/TO Mappings)\n\n**HIERARCHICAL SEARCH - Dictionary first, Interactive Validation second:**\n\n**Dictionary Path:** `~/.claude/docs/regulatory/dictionaries/{category}-{code}.yaml`\n\n| Step | If Dictionary EXISTS | If Dictionary NOT EXISTS |\n|------|---------------------|--------------------------|\n| 1 | Load YAML, use field_mappings | Query MCP: `mcp__apidog_midaz/crm__read_project_oas()` |\n| 2 | Apply transformations | Analyze schemas, SUGGEST mappings (preserve casing) |\n| 3 | Use existing mappings | **AskUserQuestion** for EACH field (user approval required) |\n| 4 | Return | Create dictionary with APPROVED mappings only |\n| 5 |  | Save to dictionary path for future use |\n\n**Dictionary contains:** field_mappings (FROMTO), transformations, pitfalls, validation_rules\n\n---\n\n##  CRITICAL: INTERACTIVE VALIDATION FOR TEMPLATES WITHOUT DICTIONARY\n\n### Data Dictionaries Location\n\n**Dicionrios de dados disponveis em:** `~/.claude/docs/regulatory/dictionaries/`\n\nConsulte os dicionrios existentes antes de iniciar o mapeamento de campos.\n\n---\n\n### Interactive Validation Process (MANDATORY for templates without dictionary)\n\n| Step | Action | Details |\n|------|--------|---------|\n| **A** | Discover Fields | Read regulatory spec (XSD/PDF)  Extract ALL required fields + types + formats |\n| **B** | Query API Schemas | `mcp__apidog-midaz/crm__read_project_oas()`  Extract available fields from both systems |\n| **C** | Interactive Validation | For EACH field: AskUserQuestion with top 3-4 suggestions + \"Skip\" + \"Other\" (custom path) |\n| **D** | Validate Transformations | If field needs transform: AskUserQuestion with options (e.g., `slice:':8'`, \"No transformation\") |\n| **E** | Generate Dictionary | Create YAML with APPROVED mappings only  Save to `DICTIONARY_BASE_PATH/[template].yaml`\n\n---\n\n### AskUserQuestion Implementation for Field Mapping\n\n**CRITICAL: Use AskUserQuestion tool with these patterns:**\n\n| Pattern | Question Format | Options |\n|---------|----------------|---------|\n| **Field Source** | `Map '${field.name}' (${type}, ${required})?` | Top 3 suggestions (with confidence %) + \"Skip for now\" + \"Other\" (auto) |\n| **Transformation** | `Transformation for '${field.name}'?` | Suggested filters (with examples) + \"No transformation\" + \"Other\" (auto) |\n| **Batch Approval** | `Approve mapping for '${name}'? Suggested: ${path}, Confidence: ${%}` | \"Approve \" / \"Reject \" (max 4 questions per batch) |\n\n**Note:** \"Other\" option automatically added by AskUserQuestion for custom input.\n\n---\n\n### Complete Interactive Validation Flow\n\n**Process:** Read spec  Query MCP schemas  For EACH field: AskUserQuestion  Process response  Track approved/skipped\n\n| Response Type | Action |\n|--------------|--------|\n| \"Skip\" | Add to skippedFields (resolve in Gate 2) |\n| Custom input (\"Other\") | Add with `approved_by: \"user_custom_input\"`, confidence: 100 |\n| Suggested option | If needs transformation: ask for filter (slice, floatformat, etc.)  Add with `approved_by: \"user_selection\"` |\n\n**Output:** `{ approvedMappings: [...], skippedFields: [...] }`\n\n---\n\n### Validation Rules for User Input\n\n**Valid path patterns for custom input:**\n\n| Source | Pattern | Example |\n|--------|---------|---------|\n| `midaz_onboarding` | `midaz_onboarding.(organization\\|account).N.field` | `midaz_onboarding.organization.0.legal_document` |\n| `midaz_transaction` | `midaz_transaction.(operation_route\\|balance\\|operation).field` | `midaz_transaction.balance.available` |\n| `crm` | `crm.(holder\\|alias).field` | `crm.holder.document` |\n| `metadata` | `(midaz\\|crm).entity.metadata.field` | `midaz.account.metadata.branch` |\n\n**Validation:** If path doesn't match patterns  warn user but allow (may be valid custom path).\n\n### NAMING CONVENTION IN FIELD DISCOVERY\n\n**CRITICAL: ALWAYS CONVERT TO SNAKE_CASE!**\n\n| API Returns | Map As | / |\n|-------------|--------|------|\n| `legalDocument` | `organization.legal_document` |  |\n| `taxId` / `TaxID` | `organization.tax_id` |  |\n| `openingDate` | `organization.opening_date` |  |\n| `legalDocument` | `organization.legalDocument` |  NEVER |\n\n**Search patterns help FIND fields. Once found, CONVERT TO SNAKE_CASE!**\n\n### Hierarchical Search Strategy\n\n**CRITICAL: Convert ALL discovered fields to snake_case!**\n\n| Step | Action | Priority Paths |\n|------|--------|----------------|\n| **1** | Query MCP schemas | `mcp__apidog_crm/midaz__read_project_oas()` |\n| **2** | Search CRM first | holder.document, holder.name, holder.type, holder.addresses.*, holder.contact.*, holder.naturalPerson.*, holder.legalPerson.*, alias.bankingDetails.*, alias.metadata.* |\n| **3** | Search Midaz second | account.name, account.alias, account.metadata.*, account.status, transaction.metadata.*, balance.amount, organization.legalDocument |\n| **4** | Check metadata | crm.holder/alias.metadata.*, midaz.account/transaction.metadata.* |\n| **5** | Mark as uncertain | If not found  document searched locations + suggest closest matches + indicate confidence |\n\n### Confidence Scoring System\n\n| Level | Score | Criteria |\n|-------|-------|----------|\n| **HIGH** (90-100%) | Base(30) + Name(25) + System(25) + Type(20) + Validation(20) | Exact name match, type matches, primary system, validation passes, simple/no transform |\n| **MEDIUM** (60-89%) | Base(30) + partial matches | Partial name or pattern match, compatible type needs transform, secondary system, some uncertainty |\n| **LOW** (30-59%) | Base(30) only | Synonym/fuzzy match, significant transform, metadata only, cannot validate |\n\n**Formula:** `Score = Base(30) + NameMatch(0-25) + SystemMatch(0-25) + TypeMatch(0-20) + ValidationMatch(0-20)`\n\n| Component | Values |\n|-----------|--------|\n| NameMatch | exact=25, partial=15, pattern=5 |\n| SystemMatch | primary=25, secondary=15, metadata=5 |\n| TypeMatch | exact=20, compatible=10, needs_transform=5 |\n| ValidationMatch | validated=20, partial=10, cannot_validate=0 |\n\n### Validation with Examples\n\n**Process:** Fetch sample  Apply transformation  Validate format\n\n| Pattern | Regex |\n|---------|-------|\n| CPF | `/^\\d{11}$/` |\n| CNPJ | `/^\\d{14}$/` |\n| CNPJ_BASE | `/^\\d{8}$/` |\n| DATE_BR | `/^\\d{2}\\/\\d{2}\\/\\d{4}$/` |\n| DATE_ISO | `/^\\d{4}-\\d{2}-\\d{2}$/` |\n| PHONE_BR | `/^\\+?55?\\s?\\(?\\d{2}\\)?\\s?\\d{4,5}-?\\d{4}$/` |\n| CEP | `/^\\d{5}-?\\d{3}$/` |\n\n**Example:** CNPJ Base: `\"12345678000190\"`  `slice:':8'`  `\"12345678\"`  `/^\\d{8}$/`   valid (+20 confidence)\n\n### Agent Dispatch\n\n**Dispatch:** `Task(subagent_type: \"ring:finops-analyzer\", model: \"opus\")`\n\n**Pre-dispatch:** Check dictionary at `~/.claude/docs/regulatory/dictionaries/{category}-{code}.yaml`\n\n| Mode | Condition | Instructions |\n|------|-----------|--------------|\n| **Dictionary Mode** | File exists | USE dictionary data ONLY. NO MCP calls. Validate mappings. |\n| **MCP Discovery Mode** | File missing | Query MCP APIs  Suggest mappings  AskUserQuestion for EACH  Create dictionary with APPROVED only |\n\n**Prompt includes:** Template info, dictionary status/content (if exists), snake_case requirement, validation steps, output format\n\n**CRITICAL REQUIREMENTS:**\n\n|  DO |  NEVER |\n|-------|---------|\n| Check dictionary FIRST | Skip dictionary check |\n| MCP only if no dictionary | Call MCP when dictionary exists |\n| AskUserQuestion for ALL mappings | Auto-approve without asking |\n| Save APPROVED mappings only | Save unapproved guesses |\n| Validate all transformations | Guess field mappings |\n\n**Report Output:** dictionary_status, field_mappings (code, name, required, source, transformation, confidence, validated, examples), validation_summary (total, mapped, coverage%, avg_confidence)\n\n**COMPLETION STATUS:** COMPLETE, INCOMPLETE, or NEEDS_DISCUSSION\n\n---\n\n## Capture Gate 1 Response\n\n**Response structure:**\n\n| Section | Fields |\n|---------|--------|\n| **Template Info** | template_name, regulatory_standard, authority, submission_frequency, submission_deadline |\n| **Field Counts** | total_fields, mandatory_fields, optional_fields |\n| **Discovery Summary** | crm_fields_available, midaz_fields_available, metadata_fields_used, unmapped_fields |\n| **Field Mappings** (per field) | field_code, field_name, required, type, format, mappings_found[], selected_mapping, confidence_score, confidence_level, reasoning, transformation, validation_passed, status |\n| **Uncertainties** (per field) | field_code, field_name, mappings_attempted[], best_match, doubt, suggested_resolution |\n| **Confidence Summary** | high/medium/low_confidence_fields, overall_confidence |\n| **Compliance Risk** | LOW/MEDIUM/HIGH (based on confidence levels) |\n| **Documentation Used** | official_regulatory URL, implementation_reference URL, regulatory_framework |\n\n---\n\n## Documentation Sources\n\n### Official Regulatory Sources (SOURCE OF TRUTH)\n\n---\n\n## Red Flags - STOP Immediately\n\nIf you catch yourself thinking ANY of these, STOP and re-read the NO EXCEPTIONS section:\n\n### Skip Patterns\n- \"Skip snake_case conversion for...\"\n- \"Omit prefix for obvious fields\"\n- \"Use camelCase this time\"\n- \"Mixed conventions are fine\"\n- \"Dictionary check is ceremony\"\n\n### Partial Compliance\n- \"Convert only mandatory fields\"\n- \"Prefix only ambiguous fields\"\n- \"Auto-approve HIGH confidence\"\n- \"Map only mandatory fields\"\n- \"75% is close enough to 80%\"\n\n### Experience-Based Shortcuts\n- \"I memorized these mappings\"\n- \"I know where this comes from\"\n- \"We've done this 50 times\"\n- \"The pattern is obvious\"\n- \"Dictionary won't exist anyway\"\n\n### Justification Language\n- \"Unnecessary busywork\"\n- \"Verbose and ugly\"\n- \"Wasting user time\"\n- \"Process over outcome\"\n- \"Being pragmatic\"\n- \"Close enough\"\n- \"Everyone knows\"\n\n### If You See These Red Flags\n\n1. **Acknowledge the rationalization** (\"I'm trying to skip snake_case\")\n2. **Read the NO EXCEPTIONS section** (understand why it's required)\n3. **Read the Rationalization Table** (see your exact excuse refuted)\n4. **Follow the requirement completely** (no modifications)\n\n**Technical requirements are not negotiable. Field mapping errors compound through Gates 2-3.**\n\n---\n\n## Pass/Fail Criteria\n\n### PASS Criteria\n-  `COMPLETION STATUS: COMPLETE`\n-  0 Critical gaps (unmapped mandatory fields)\n-  Overall confidence score  80%\n-  All mandatory fields mapped (even if LOW confidence)\n-  < 10% of fields with LOW confidence\n-  Dynamic discovery via MCP executed\n-  Documentation was consulted (both official and implementation)\n-  CRM checked first for banking/personal data\n\n### FAIL Criteria\n-  `COMPLETION STATUS: INCOMPLETE`\n-  Critical gaps exist (mandatory fields unmapped)\n-  Overall confidence score < 60%\n-  > 20% fields with LOW confidence\n-  Documentation not consulted\n-  MCP discovery not performed\n-  Only checked one system (didn't check CRM + Midaz)\n\n---\n\n## State Tracking\n\n| Status | Output Fields |\n|--------|--------------|\n| **PASS** | STATUS: PASSED, FIELDS: total/mandatory, UNCERTAINTIES: count, COMPLIANCE_RISK, NEXT: Gate 2, EVIDENCE: docs consulted + all mandatory mapped |\n| **FAIL** | STATUS: FAILED, CRITICAL_GAPS: count, HIGH_UNCERTAINTIES: count, NEXT: Fix gaps, BLOCKERS: Critical mapping gaps |\n\n---\n\n## Critical Validations\n\nEnsure these patterns are followed:\n- Use EXACT patterns from Lerian documentation\n- Apply filters like `slice`, `floatformat` as shown in docs\n- Follow tipoRemessa rules: \"I\" for new/rejected, \"S\" for approved only\n- Date formats must match regulatory requirements (YYYY/MM, YYYY-MM-DD)\n- CNPJ/CPF formatting rules must be exact\n\n---\n\n## Output to Parent Skill\n\n**Return to `regulatory-templates`:** `{ gate1_passed: bool, gate1_context: {...}, uncertainties_count: N, critical_gaps: [], next_action: \"proceed_to_gate2\" | \"fix_gaps_and_retry\" }`\n\n---\n\n## Common Issues and Solutions\n\n| Issue | Solution |\n|-------|----------|\n| Documentation not accessible | Try alternative URLs or cached versions |\n| Field names don't match Midaz | Mark as uncertain for Gate 2 validation |\n| Missing mandatory fields | Mark as Critical gap, must resolve |\n| Format specifications unclear | Consult both Lerian docs and government specs |\n\n---\n\n## Dynamic Discovery Example\n\n**Finding \"Agncia\" field for CADOC 4010:**\n\n| Step | Action | Result |\n|------|--------|--------|\n| 1 | Pattern search | `[\"branch\", \"agency\", \"agencia\", \"branch_code\"]` |\n| 2 | Query CRM first | `crm.alias.bankingDetails.branch`  (exact, 95%) |\n| 3 | Query Midaz fallback | `midaz.account.metadata.branch_code`  (metadata, 45%) |\n| 4 | Select highest | `crm.alias.bankingDetails.branch` (HIGH confidence) |\n\n## Remember\n\n1. **CONVERT TO SNAKE_CASE** - All fields must be snake_case (legal_document not legalDocument)\n2. **Use MCP for dynamic discovery** - Never hardcode field paths\n3. **CRM first for banking/personal data** - It has the most complete holder info\n4. **Official specs are SOURCE OF TRUTH** - Regulatory requirements from government\n5. **Lerian docs show IMPLEMENTATION** - How to create templates in their system\n6. **Template-specific knowledge is valuable** - Always check for existing sub-skills\n7. **Confidence scoring is key** - Always calculate and document confidence\n8. **Be conservative with mappings** - Mark uncertain rather than guess\n9. **Capture everything** - Gate 2 needs complete context with all attempted mappings\n10. **Reference both sources** - Note official specs AND implementation examples\n11. **Risk assessment based on confidence** - Low confidence = higher compliance risk\n\n## Important Distinction\n\n **Regulatory Compliance vs Implementation**\n- **WHAT** (Requirements) = Official government documentation\n- **HOW** (Implementation) = Lerian documentation examples\n- When validating compliance  Use official specs\n- When creating templates  Use Lerian patterns\n- Never confuse implementation examples with regulatory requirements"
              },
              {
                "name": "ring:regulatory-templates-gate2",
                "description": "Gate 2 sub-skill - validates uncertain mappings from Gate 1 and confirms\nall field specifications through testing.\n",
                "path": "finops-team/skills/regulatory-templates-gate2/SKILL.md",
                "frontmatter": {
                  "name": "ring:regulatory-templates-gate2",
                  "description": "Gate 2 sub-skill - validates uncertain mappings from Gate 1 and confirms\nall field specifications through testing.\n",
                  "trigger": "- Gate 1 PASSED\n- Need to validate mappings before template generation\n",
                  "skip_when": "- Gate 1 not passed  complete Gate 1 first\n- Gate 2 already passed  proceed to Gate 3\n",
                  "sequence": {
                    "after": [
                      "regulatory-templates-gate1"
                    ],
                    "before": [
                      "regulatory-templates-gate3"
                    ]
                  }
                },
                "content": "# Regulatory Templates - Gate 2: Technical Validation\n\n## Overview\n\n**This sub-skill executes Gate 2 of the regulatory template workflow: validating uncertain mappings from Gate 1 and confirming all field specifications through testing.**\n\n**Parent skill:** `regulatory-templates`\n\n**Prerequisites:**\n- Gate 1 PASSED\n- Context object with Gate 1 results\n\n**Output:** Validated mappings with test results and validation rules\n\n---\n\n## Foundational Principle\n\n**Validation is the checkpoint that prevents incorrect mappings from reaching production.**\n\nGate 2 is the quality gate between analysis (Gate 1) and implementation (Gate 3):\n- **All uncertainties resolved**: Gate 1 analysis  Gate 2 validation. MEDIUM/LOW uncertainties often hide critical issues\n- **100% mandatory validation**: 95% = 5% of mandatory data could be wrong in BACEN submission\n- **>90% test pass rate**: Test data reveals transformation bugs, data type mismatches, edge cases\n- **Confirmed mappings**: Prevents Gate 3 from generating templates based on assumptions\n- **Validation rules defined**: Gate 3 needs explicit validation logic for template generation\n\n**Skipping validation in Gate 2 means:**\n- Gate 1 assumptions become Gate 3 implementation (no verification layer)\n- Uncertainties propagate to production (BACEN submission failures)\n- Low-confidence mappings generate incorrect templates (compliance violations)\n- No test data validation = edge cases break in production\n\n**Gate 2 is not redundant - it's the firewall between analysis and implementation.**\n\n---\n\n## When to Use\n\n**Called by:** `regulatory-templates` skill after Gate 1 passes\n\n**Purpose:** Resolve uncertainties, validate field mappings, test transformations, define validation rules\n\n---\n\n## NO EXCEPTIONS - Validation Requirements Are Mandatory\n\n**Gate 2 validation requirements have ZERO exceptions.** This is the quality firewall before template generation.\n\n### Common Pressures You Must Resist\n\n| Pressure | Your Thought | Reality |\n|----------|--------------|---------|\n| **Pragmatism** | \"Critical uncertainties only, skip MEDIUM/LOW\" | PASS criteria: ALL uncertainties resolved. MEDIUM/LOW cascade to mandatory failures |\n| **Efficiency** | \"88% test pass rate is excellent\" | Threshold is >90%. 12% failure = edge cases that break in production |\n| **Complexity** | \"Validation dashboard is redundant\" | Mandatory validation = 100% required. Dashboard catches missing validations |\n| **Confidence** | \"Mappings look correct, skip testing\" | Visual inspection  test validation. Test data reveals hidden bugs |\n| **Authority** | \"95% mandatory validation is outstanding\" | 100% is non-negotiable. 5% gap = 5% of mandatory data wrong in BACEN |\n| **Frustration** | \"Use workarounds for rejected fields\" | FAIL criteria: Cannot find alternatives. Workarounds bypass validation |\n\n### Validation Requirements (Non-Negotiable)\n\n**All Uncertainties Resolved:**\n-  REQUIRED: Resolve ALL Gate 1 uncertainties (CRITICAL + MEDIUM + LOW)\n-  FORBIDDEN: \"Fix critical only\", \"Skip low-priority items\"\n- Why: MEDIUM/LOW uncertainties often reveal systemic issues, cascade to mandatory failures\n\n**Test Data Validation:**\n-  REQUIRED: Test pass rate >90%\n-  FORBIDDEN: \"88% is close enough\", \"Skip testing, looks correct\"\n- Why: Test data reveals transformation bugs, data type mismatches, edge cases\n\n**Mandatory Field Validation:**\n-  REQUIRED: 100% mandatory fields validated\n-  FORBIDDEN: \"95% is outstanding\", \"Edge cases don't matter\"\n- Why: Each 1% gap = potential BACEN submission failure on mandatory data\n\n**Alternative Mappings:**\n-  REQUIRED: Find alternatives for ALL rejected fields\n-  FORBIDDEN: \"Use workarounds\", \"Keep original with patches\"\n- Why: Rejected mappings fail validation for a reason - workarounds bypass the firewall\n\n### The Bottom Line\n\n**Partial validation = no validation.**\n\nGate 2 exists to catch what Gate 1 missed. Lowering thresholds or skipping validation defeats the purpose. Every PASS criterion exists because production incidents occurred without it.\n\n**If you're tempted to skip ANY validation, ask yourself: Am I willing to defend this shortcut during a BACEN audit?**\n\n---\n\n## Rationalization Table - Know the Excuses\n\nEvery rationalization below has been used to justify skipping validation. **ALL are invalid.**\n\n| Excuse | Why It's Wrong | Correct Response |\n|--------|---------------|------------------|\n| \"Critical uncertainties only, MEDIUM/LOW can wait\" | ALL uncertainties = all 8. MEDIUM cascade to mandatory failures | Resolve ALL uncertainties |\n| \"88% is excellent, 2% gap is edge cases\" | >90% threshold exists for production edge cases | Fix to reach >90% |\n| \"Validation dashboard is redundant with Gate 1\" | Gate 1 = mapping, Gate 2 = validation. Different purposes | Run dashboard, ensure 100% |\n| \"Mappings look correct, testing is busywork\" | Visual inspection missed bugs testing would catch | Run test data validation |\n| \"95% is outstanding, 5% isn't worth 2 hours\" | 100% is binary requirement. 95%  100% | Fix to reach 100% |\n| \"Rejected fields can use workarounds\" | Workarounds bypass validation layer | Find valid alternatives |\n| \"Gate 2 rarely finds issues after 50 templates\" | Experience doesn't exempt from validation | Run full validation |\n| \"Following spirit not letter\" | Validation thresholds ARE the spirit | Meet all thresholds |\n| \"Being pragmatic vs dogmatic\" | Thresholds prevent regulatory incidents | Rigor is pragmatism |\n| \"Fix in next sprint if issues arise\" | Regulatory submissions are final, can't patch | Fix now before Gate 3 |\n\n### If You Find Yourself Making These Excuses\n\n**STOP. You are rationalizing.**\n\nThe validation exists to prevent these exact thoughts from allowing errors into production. If validation seems \"redundant,\" that's evidence it's working - catching what analysis missed.\n\n---\n\n## Gate 2 Process\n\n### Check for Template-Specific Validation Rules\n\nCheck for template-specific sub-skill at `skills/regulatory-{template}/SKILL.md` containing:\n- Validation rules (VR001, VR002...), business rules (BR001, BR002...)\n- Format rules, test data with expected outputs\n\n### Agent Dispatch with Gate 1 Context\n\n**Dispatch:** `Task(subagent_type: \"ring:finops-analyzer\", model: \"opus\")`\n\n**CRITICAL:**  DO NOT MAKE MCP API CALLS - use Gate 1 context ONLY\n\n**Prompt structure:**\n\n| Section | Content |\n|---------|---------|\n| Context | Full Gate 1 context (field mappings, uncertainties) |\n| Uncertain Mappings | For each: field_code, current_mapping, doubt, confidence, action_needed |\n| Validation Tasks | 1. Use Gate 1 mapping 2. Validate transformations 3. Check business logic 4. Confirm data types 5. Mark CONFIRMED/REJECTED |\n| Output | Per field: code, resolution, alternative (if rejected), test_result |\n\n**Output:** Field resolutions + validation rules + cross-field logic + test data\n\n---\n\n## Validation Process\n\n** All validation uses Gate 1 context ONLY - no MCP API calls.**\n\n### 1. Field Validation\n\nPer uncertain field: field_code, original_doubt, validation_steps (5), resolution (confirmed/rejected), transformation, test_data (input/expected/actual/status)\n\n### 2. Validation Rules Definition\n\n| Rule Type | Example | Formula |\n|-----------|---------|---------|\n| field_format | CNPJ 8 digits | `length(field_001) == 8` |\n| cross_field | CPF/CNPJ check | `length(field_001) IN (11, 14)` |\n| date_range | Within period | `field_020 >= period_start AND field_020 <= period_end` |\n\n### 3. Test Results Documentation\n\nPer test: field, test_name, input, transformation, output, expected, passed (true/false)\n\n**Example:** Field 001 CNPJ extraction: `\"12345678000190\"`  `slice:':8'`  `\"12345678\"` \n\n---\n\n## Capture Gate 2 Response\n\n**Merge with Gate 1:** `validated_mappings[]`, `validation_rules[]`, `all_uncertainties_resolved`, `test_summary` (total/passed/failed/success_rate)\n\n---\n\n## Red Flags - STOP Immediately\n\nIf you catch yourself thinking ANY of these, STOP and re-read the NO EXCEPTIONS section:\n\n### Partial Resolution\n- \"Resolve critical only, skip MEDIUM/LOW\"\n- \"Fix most uncertainties, good enough\"\n- \"ALL is unrealistic, most is pragmatic\"\n\n### Threshold Degradation\n- \"88% is close to 90%\"\n- \"95% mandatory validation is outstanding\"\n- \"Close enough to pass\"\n- \"The gap isn't material\"\n\n### Skip Validation Steps\n- \"Validation dashboard is redundant\"\n- \"Mappings look correct visually\"\n- \"Testing is busywork\"\n- \"We'll catch issues in Gate 3\"\n\n### Workaround Thinking\n- \"Use workarounds for rejected fields\"\n- \"Patch it in Gate 3\"\n- \"Fix in next sprint\"\n- \"This is an edge case\"\n\n### Justification Language\n- \"Being pragmatic\"\n- \"Following spirit not letter\"\n- \"Outstanding is good enough\"\n- \"Rarely finds issues anyway\"\n- \"Experience says this is fine\"\n\n### If You See These Red Flags\n\n1. **Acknowledge the rationalization** (\"I'm trying to skip LOW uncertainties\")\n2. **Read the NO EXCEPTIONS section** (understand why ALL means ALL)\n3. **Read the Rationalization Table** (see your exact excuse refuted)\n4. **Meet the threshold completely** (100%, >90%, ALL)\n\n**Validation thresholds are binary gates, not aspirational goals.**\n\n---\n\n## Pass/Fail Criteria\n\n### PASS Criteria\n-  All Gate 1 uncertainties resolved (confirmed or alternatives found)\n-  Test data validates successfully (>90% pass rate)\n-  No new Critical/High issues\n-  All mandatory fields have confirmed mappings\n-  Validation rules defined for all critical fields\n\n### FAIL Criteria\n-  Uncertainties remain unresolved\n-  Test failures on mandatory fields\n-  Cannot find alternative mappings for rejected fields\n-  Data type mismatches that can't be transformed\n-  **Mandatory fields validation < 100%**\n\n---\n\n## Mandatory Fields Final Validation\n\n**CRITICAL:** Execute before Gate 2 completion\n\n**Per mandatory field, check:**\n- mapped (in gate1.field_mappings)\n- confidence_ok (80%)\n- validated (in gate2.validated_mappings)\n- tested (in gate2.test_results)\n- transformation_ok (works correctly)\n\n**Status:** All checks PASS  field PASS; any FAIL  field FAIL\n\n**Gate 2 Pass Condition:** `all_mandatory_fields_valid == true` required. Coverage must be 100%.\n\n---\n\n## State Tracking\n\n**PASS:** `SKILL: regulatory-templates-gate2 | GATE: 2 | STATUS: PASSED | RESOLVED: {n} uncertainties | RULES: {n} defined | TESTS: {passed}/{total} | NEXT:  Gate 3`\n\n**FAIL:** `SKILL: regulatory-templates-gate2 | GATE: 2 | STATUS: FAILED | UNRESOLVED: {n} | TEST_FAILURES: {n} | BLOCKERS: {description}`\n\n---\n\n## Technical Validation Checklist\n\n| Category | Validations |\n|----------|-------------|\n| Field Naming | snake_case (not camelCase), check MCP API Dog naming |\n| Data Types | String (length, UTF-8), Number (precision), Date (format), Boolean, Enum |\n| Transformations | CNPJ/CPF slice, date timezone, decimal format, string trim/uppercase/padding, null defaults |\n| Cross-Field | Dependent consistency, date ranges, calculated fields, conditional logic |\n\n## Common Validation Patterns\n\n| Pattern | Input  Transformation  Output |\n|---------|--------------------------------|\n| CNPJ extraction | `\"12345678000190\"`  `slice:':8'`  `\"12345678\"` |\n| Date format | `\"2025-01-15T10:30:00Z\"`  `date_format:'%Y/%m'`  `\"2025/01\"` |\n| Decimal precision | `1234.5678`  `floatformat:2`  `\"1234.57\"` |\n| Conditional | `tipoRemessa == \"I\"`  include all; `\"S\"`  approved only |\n\n---\n\n## Output to Parent Skill\n\nReturn: `gate2_passed`, `gate2_context` (merged), `all_uncertainties_resolved`, `validation_rules_count`, `test_success_rate`, `next_action` (proceed_to_gate3 | fix_validations_and_retry)"
              },
              {
                "name": "ring:regulatory-templates-gate3",
                "description": "Gate 3 sub-skill - generates complete .tpl template file with all validated\nmappings from Gates 1-2.\n",
                "path": "finops-team/skills/regulatory-templates-gate3/SKILL.md",
                "frontmatter": {
                  "name": "ring:regulatory-templates-gate3",
                  "description": "Gate 3 sub-skill - generates complete .tpl template file with all validated\nmappings from Gates 1-2.\n",
                  "trigger": "- Gate 2 PASSED\n- Ready to generate production template file\n",
                  "skip_when": "- Gate 2 not passed  complete Gate 2 first\n- Template already generated  verify or regenerate\n",
                  "sequence": {
                    "after": [
                      "regulatory-templates-gate2"
                    ]
                  }
                },
                "content": "# Regulatory Templates - Gate 3: Template File Generation\n\n## Overview\n\n**This sub-skill executes Gate 3 of the regulatory template workflow: generating the complete .tpl template file with all validated mappings and transformations from Gates 1-2.**\n\n**Parent skill:** `regulatory-templates`\n\n**Prerequisites:**\n- Gate 1 PASSED (field mappings complete)\n- Gate 2 PASSED (validations confirmed)\n- Context object with Gates 1-2 results\n\n**Output:** Generated .tpl template file ready for use\n\n---\n\n## Foundational Principle\n\n**Template generation is the final quality gate before production deployment.**\n\nGate 3 transforms validated specifications into production artifacts:\n- **Agent-based generation**: finops-automation applies validated mappings consistently - manual creation introduces human error\n- **Two-file separation**: Clean .tpl (production code) + .tpl.docs (documentation) - inline comments bloat production artifacts\n- **All mandatory fields**: 100% inclusion required - 95% = 5% of regulatory data missing in BACEN submission\n- **Correct transformations**: Django filters applied per Gates 1-2 validation - errors here multiply in every submission\n- **Valid syntax**: Template must execute without errors - syntax failures block Reporter deployment\n\n**Skipping requirements in Gate 3 means:**\n- Manual creation bypasses systematic validation (fatigue errors, missed transformations)\n- Single-file output mixes production code with documentation (maintenance nightmare)\n- Missing fields cause BACEN submission failures (compliance violations)\n- Invalid syntax blocks deployment (emergency fixes under pressure)\n\n**Gate 3 is not automation for convenience - it's the final verification layer.**\n\n---\n\n## When to Use\n\n**Called by:** `regulatory-templates` skill after Gate 2 passes\n\n**Purpose:** Create the final Django/Jinja2 template file with all field mappings, transformations, and validation logic\n\n---\n\n## NO EXCEPTIONS - Generation Requirements Are Mandatory\n\n**Gate 3 template generation requirements have ZERO exceptions.** This is the final artifact that goes to production.\n\n### Common Pressures You Must Resist\n\n| Pressure | Your Thought | Reality |\n|----------|--------------|---------|\n| **Fatigue** | \"Manual creation is faster when tired\" | Fatigue increases error rate. Agent doesn't get tired. 10 min manual < 15 min validated |\n| **Simplicity** | \"One file easier than two\" | Production artifacts must be clean. Documentation bloats .tpl files |\n| **Confidence** | \"45/47 fields works for 99% cases\" | 100% mandatory required. 95% = BACEN submission failures on edge cases |\n| **Experience** | \"I can optimize agent output\" | Agent applies validated mappings systematically. Manual edits introduce drift |\n\n### Generation Requirements (Non-Negotiable)\n\n**Agent-Based Generation:**\n-  REQUIRED: Use finops-automation agent for all template generation\n-  FORBIDDEN: Manual .tpl creation, editing agent output\n- Why: Agent applies Gates 1-2 validations consistently, prevents fatigue errors\n\n**Two-File Output:**\n-  REQUIRED: Generate .tpl (clean code) + .tpl.docs (documentation)\n-  FORBIDDEN: Single file with inline comments, merged documentation\n- Why: Production artifacts stay clean, documentation separate for maintenance\n\n**All Mandatory Fields:**\n-  REQUIRED: 100% mandatory fields in template (47/47)\n-  FORBIDDEN: \"45/47 is good enough\", placeholder comments for missing\n- Why: Each missing field = potential regulatory compliance failure\n\n**Validated Output:**\n-  REQUIRED: Use exact agent output without manual \"improvements\"\n-  FORBIDDEN: Refactoring for optimization, rewriting for clarity\n- Why: Agent output validated against Gates 1-2, edits create drift\n\n### The Bottom Line\n\n**Manual shortcuts in final artifact = production regulatory failures.**\n\nGate 3 is the last checkpoint. All previous gates' work culminates here. Bypassing agent generation defeats the entire 3-gate validation process.\n\n**If you're tempted to skip agent generation, ask yourself: Am I willing to debug production BACEN submission failures from manual template errors?**\n\n---\n\n## Rationalization Table - Know the Excuses\n\n| Excuse | Why It's Wrong | Correct Response |\n|--------|---------------|------------------|\n| \"Manual creation same output, faster\" | Agent validates systematically, manual risks errors | Use agent completely |\n| \"10 min vs 15 min, I'm tired\" | Fatigue increases manual error rate | Let agent work |\n| \"Two files is over-engineering\" | Production code must be clean, no doc bloat | Generate TWO files |\n| \"One file easier to maintain\" | Mixing code and docs creates maintenance burden | Separate concerns |\n| \"45/47 works for 99% cases\" | 100% mandatory required, edge cases matter | Include ALL fields |\n| \"I can optimize agent output\" | Optimization creates drift from validated spec | Use exact output |\n| \"Agent code is verbose\" | Verbose but validated > concise but wrong | Trust validation |\n| \"Skip for now, add fields later\" | Template is final artifact, can't patch BACEN | Complete now |\n\n### If You Find Yourself Making These Excuses\n\n**STOP. You are rationalizing.**\n\nGate 3 is where 5+ hours of Gates 1-2 work becomes a production artifact. Shortcuts here waste all previous validation effort.\n\n---\n\n## Gate 3 Process\n\n### Agent Dispatch\n\n**Dispatch:** `Task(subagent_type: \"ring:finops-automation\", model: \"sonnet\")`\n\n**Prompt includes:**\n\n| Section | Content |\n|---------|---------|\n| Context | template_name, template_code, authority, field_mappings.length, validation_rules.length |\n| Field Mappings | Per field: code, name, source, transformation, confidence%, required |\n| Validation Rules | Per rule: rule_id, description, formula |\n| Tasks | 1. Generate clean .tpl 2. Include all mappings 3. Apply Django syntax 4. Structure per regulatory spec 5. Conditional logic 6. Minimal comments |\n\n**CRITICAL - Naming Convention:**\n- ALL fields in snake_case (already converted by Gate 1)\n- Examples: `legal_document`, `operation_route`, `opening_date`, `natural_person`\n\n**CRITICAL - Data Sources:**\n- `midaz_onboarding`: organization, account (cadastral)\n- `midaz_transaction`: operation_route, balance, operation (transactional)\n- Format: `{{ data_source.entity.index.field|filter }}`\n- Example: `{{ midaz_onboarding.organization.0.legal_document|slice:':8' }}`\n\n---\n\n## Expected Output\n\n| File | Content |\n|------|---------|\n| `{code}_preview.tpl` | Clean Django/Jinja2 template code, production-ready, minimal comments |\n| `{code}_preview.tpl.docs` | Full documentation: field mappings, transformations, troubleshooting |\n\n---\n\n## Red Flags - STOP Immediately\n\nIf you catch yourself thinking ANY of these, STOP and re-read the NO EXCEPTIONS section:\n\n### Manual Shortcuts\n- \"Create .tpl manually, faster\"\n- \"Edit agent output for optimization\"\n- \"I can write cleaner code\"\n- \"Agent is too verbose\"\n\n### File Structure Violations\n- \"One file easier to maintain\"\n- \"Inline comments instead of .docs\"\n- \"Merge documentation into .tpl\"\n- \"Two files is over-engineering\"\n\n### Partial Completion\n- \"45/47 fields works for most cases\"\n- \"Skip edge case fields\"\n- \"Add missing fields later\"\n- \"99% is good enough\"\n\n### Justification Language\n- \"Being pragmatic\"\n- \"I'm too tired for agent wait\"\n- \"Manual is faster\"\n- \"Over-engineering\"\n- \"Optimization is better\"\n\n### If You See These Red Flags\n\n1. **Acknowledge rationalization** (\"I'm trying to skip agent generation\")\n2. **Read NO EXCEPTIONS** (understand why agent is required)\n3. **Read Rationalization Table** (see excuse refuted)\n4. **Use agent completely** (no manual shortcuts)\n\n**Template generation shortcuts waste all Gates 1-2 validation work.**\n\n---\n\n## Pass/Fail Criteria\n\n### PASS Criteria\n-  Template file generated successfully\n-  All mandatory fields included\n-  Transformations correctly applied\n-  Django/Jinja2 syntax valid\n-  Output format matches specification\n-  File saved with correct extension\n\n### FAIL Criteria\n-  Missing mandatory fields\n-  Invalid template syntax\n-  Transformation errors\n-  File generation failed\n\n---\n\n## State Tracking\n\n**PASS:** `SKILL: regulatory-templates-gate3 | GATE: 3 | STATUS: PASSED  | FILE: {filename} | FIELDS: {n}/{total} | NEXT: Template ready for use`\n\n**FAIL:** `SKILL: regulatory-templates-gate3 | GATE: 3 | STATUS: FAILED  | ERROR: {error} | BLOCKERS: {description}`\n\n---\n\n## Output to Parent Skill\n\nReturn: `gate3_passed`, `template_file` (filename, path, size_bytes, fields_included), `ready_for_use`, `next_action` (template_complete | fix_and_regenerate)\n\n---\n\n## Common Template Patterns\n\n| Pattern | Syntax |\n|---------|--------|\n| Field access | `{{ organization.legal_document }}` (snake_case) |\n| Collection loop | `{% for item in collection %}{{ item.field }}{% endfor %}` |\n| Conditional | `{% if condition %}<field>{{ value }}</field>{% endif %}` |\n| Nested | `{{ parent.child.grandchild }}` |\n| Filter chain | `{{ value\\|slice:':8'\\|upper }}` |\n\n**Remember:** Use exact Gate 1 paths, snake_case only, apply Gate 2 transformations, follow regulatory format exactly."
              },
              {
                "name": "ring:regulatory-templates-setup",
                "description": "Initial setup sub-skill - handles template selection and context initialization\nfor the 3-gate regulatory workflow.\n",
                "path": "finops-team/skills/regulatory-templates-setup/SKILL.md",
                "frontmatter": {
                  "name": "ring:regulatory-templates-setup",
                  "description": "Initial setup sub-skill - handles template selection and context initialization\nfor the 3-gate regulatory workflow.\n",
                  "trigger": "- Called by regulatory-templates orchestrator at workflow start\n- Need to select template type and initialize context\n",
                  "skip_when": "- Not in regulatory-templates workflow\n- Setup already completed for current template\n",
                  "sequence": {
                    "after": [
                      "regulatory-templates"
                    ],
                    "before": [
                      "regulatory-templates-gate1"
                    ]
                  }
                },
                "content": "# Regulatory Templates - Initial Setup\n\n## Overview\n\n**This sub-skill handles the initial setup phase for regulatory template creation, including template selection and context initialization.**\n\n**Parent skill:** `regulatory-templates`\n\n**Output:** Complete initial context object with all selections and configurations\n\n---\n\n## Foundational Principle\n\n**Setup initializes the foundation - errors here propagate through all 3 gates.**\n\nSetup is not \"just configuration\" - it's critical validation:\n- **Template selection**: Wrong template = entire workflow on wrong regulatory spec (hours wasted)\n- **Context initialization**: Incomplete context = gates fail mysteriously downstream\n- **Dictionary status check**: Skipped check = lost automation, unnecessary interactive validation\n- **User awareness**: No alert about validation mode = poor UX, blocked progress\n\n**Skipping setup steps means:**\n- Hard-coded context bypasses validation (typos, wrong versions)\n- Missing values cause gate failures (debugging waste)\n- Silent dictionary check = user unprepared for interactive validation\n- No audit trail of selections (compliance gap)\n\n**Setup is the contract between user intent and gate execution. Get it wrong = everything downstream breaks.**\n\n---\n\n## When to Use\n\n**Called by:** `regulatory-templates` skill at the beginning of the workflow\n\n**Purpose:** Gather all user selections and initialize the context object that will flow through all gates\n\n---\n\n## NO EXCEPTIONS - Setup Requirements Are Mandatory\n\n**Setup requirements have ZERO exceptions.** Foundation errors compound through all gates.\n\n### Common Pressures You Must Resist\n\n| Pressure | Your Thought | Reality |\n|----------|--------------|---------|\n| **Ceremony** | \"User said CADOC 4010, skip selection\" | Validation confirms, prevents typos, initializes full context |\n| **Speed** | \"Hard-code context, skip AskUserQuestion\" | Bypasses validation, loses audit trail, breaks contract |\n| **Simplicity** | \"Dictionary check is file I/O ceremony\" | Check determines validation mode (auto vs interactive 40 min difference) |\n| **Efficiency** | \"Skip user alert, they'll see validation later\" | Poor UX, unprepared user, blocked progress |\n\n### Setup Requirements (Non-Negotiable)\n\n**Template Selection:**\n-  REQUIRED: Use AskUserQuestion for authority and template selection\n-  FORBIDDEN: Hard-code based on user message, skip selection dialog\n- Why: Validation confirms correct template, prevents typos, establishes audit trail\n\n**Dictionary Status Check:**\n-  REQUIRED: Check ~/.claude/docs/regulatory/dictionaries/ for template dictionary\n-  FORBIDDEN: Skip check, assume no dictionary exists\n- Why: Determines validation mode (automatic vs interactive = 40 min time difference)\n\n**User Alert:**\n-  REQUIRED: Alert user if interactive validation required (no dictionary)\n-  FORBIDDEN: \"They'll figure it out in Gate 1\"\n- Why: User preparedness, UX, informed consent for 40-min validation process\n\n**Complete Context:**\n-  REQUIRED: Initialize ALL context fields (authority, template_code, template_name, dictionary_status, documentation_path)\n-  FORBIDDEN: Minimal context, \"gates will add details later\"\n- Why: Incomplete context causes mysterious gate failures\n\n### The Bottom Line\n\n**Setup shortcuts = silent failures in all downstream gates.**\n\nSetup is foundation. Wrong template selection wastes hours on wrong spec. Missing context breaks gates mysteriously. Skipped checks lose automation.\n\n**If tempted to skip setup, ask: Am I willing to debug gate failures from incomplete initialization?**\n\n---\n\n## Rationalization Table\n\n| Excuse | Why It's Wrong | Correct Response |\n|--------|---------------|------------------|\n| \"User already said CADOC 4010\" | Validation confirms, prevents typos (4010 vs 4020) | Run selection |\n| \"Hard-code context is faster\" | Bypasses validation, loses audit trail | Use AskUserQuestion |\n| \"Dictionary check is ceremony\" | Determines 40-min validation mode difference | Check dictionary |\n| \"They'll see validation in Gate 1\" | Poor UX, unprepared user | Alert if interactive |\n| \"Just pass minimal context\" | Incomplete causes mysterious gate failures | Initialize ALL fields |\n| \"Setup is just config\" | Foundation errors compound through 3 gates | Setup is validation |\n\n### If You Find Yourself Making These Excuses\n\n**STOP. You are rationalizing.**\n\nSetup appears simple but errors propagate through 4-6 hours of gate execution. Foundation correctness prevents downstream waste.\n\n---\n\n## Setup Steps\n\n### Step 1: Regulatory Authority Selection\n\n**AskUserQuestion:** \"Which regulatory authority template?\"\n\n| Option | Description |\n|--------|-------------|\n| CADOC | BACEN - Cadastro de Clientes do SFN |\n| e-Financeira | RFB - SPED e-Financeira |\n| DIMP | RFB - Declarao de Informaes sobre Movimentao Patrimonial |\n| APIX | BACEN - Open Banking API |\n\n---\n\n### Step 1.1: Template Selection (Conditional by Authority)\n\n**AskUserQuestion:** Show template options based on authority selected:\n\n| Authority | Question | Options |\n|-----------|----------|---------|\n| **CADOC** | \"Which CADOC document?\" | 4010 (Cadastro), 4016 (Crdito), 4111 (Cmbio) |\n| **e-Financeira** | \"Which event?\" | evtCadDeclarante, evtAbertura, evtFechamento, evtMovOpFin, evtMovPP, evtMovOpFinAnual |\n| **DIMP** | \"Which version?\" | v10 (current) |\n| **APIX** | \"Which API?\" | 001 (Cadastrais), 002 (Contas/Transaes) |\n\n**Template Registry:**\n\n| Category | Code | Name | Frequency | Format | FATCA/CRS |\n|----------|------|------|-----------|--------|-----------|\n| CADOC | 4010 | Informaes de Cadastro | Monthly | XML | N/A |\n| CADOC | 4016 | Operaes de Crdito | Monthly | XML | N/A |\n| CADOC | 4111 | Operaes de Cmbio | Daily | XML | N/A |\n| e-Financeira | evtCadDeclarante | Cadastro do Declarante | Per Period | XML | Yes/Yes |\n| e-Financeira | evtAberturaeFinanceira | Abertura e-Financeira | Semestral | XML | No/No |\n| e-Financeira | evtFechamentoeFinanceira | Fechamento e-Financeira | Semestral | XML | Yes/Yes |\n| e-Financeira | evtMovOpFin | Mov. Operaes Financeiras | Semestral | XML | Yes/Yes |\n| e-Financeira | evtMovPP | Mov. Previdncia Privada | Semestral | XML | No/No |\n| e-Financeira | evtMovOpFinAnual | Mov. Operaes Fin. Anual | Annual | XML | Yes/Yes |\n| DIMP | v10 | DIMP Verso 10 | Annual | XML | N/A |\n| APIX | 001 | Dados Cadastrais | REST API | JSON | N/A |\n| APIX | 002 | Contas e Transaes | REST API | JSON | N/A |\n\n**Capture:** Authority (BACEN/RFB), category, code, name, metadata\n\n### Step 2: Optional Deadline Input\n\nIf not provided by user, use standard deadline for the template type.\n\n### Step 3: Check Dictionary Status and Alert User\n\n**CRITICAL:** Check dictionary BEFORE initializing context. Path: `~/.claude/docs/regulatory/dictionaries/{category}-{code}.yaml`\n\n| Template | Has Dictionary | Validation Mode |\n|----------|----------------|-----------------|\n| CADOC_4010 |  Yes | Automatic |\n| CADOC_4016 |  Yes | Automatic |\n| APIX_001 |  Yes | Automatic |\n| EFINANCEIRA_evtCadDeclarante |  Yes | Automatic |\n| All others |  No | Interactive |\n\n**If NO dictionary exists  AskUserQuestion:**\n- Question: \"Template has no pre-configured dictionary. Interactive validation required (~40 min). Proceed?\"\n- Options: \"Proceed with interactive validation\" | \"Choose different template\"\n- Alert user: Query APIs  Suggest mappings  User approval each  Save as new dictionary\n\n---\n\n### Step 4: Initialize Context Object\n\n**Base context structure (ALL fields required):**\n\n| Field | Source | Example |\n|-------|--------|---------|\n| `authority` | Step 1 | \"BACEN\" or \"RFB\" |\n| `template_category` | Step 1 | \"CADOC\", \"e-Financeira\", \"DIMP\", \"APIX\" |\n| `template_code` | Step 1.1 | \"4010\", \"evtMovOpFin\", \"v10\", \"001\" |\n| `template_name` | Registry | \"Informaes de Cadastro\" |\n| `template_selected` | Computed | \"CADOC 4010\" |\n| `dictionary_status` | Step 3 | `{has_dictionary, dictionary_path, validation_mode}` |\n| `documentation_path` | Registry | \".claude/docs/regulatory/templates/...\" |\n| `deadline` | User/Default | \"2025-12-31\" |\n| `gate1/gate2/gate3` | Initialize | null (populated by subsequent gates) |\n\n**Template-Specific Extensions:**\n\n| Category | Extra Fields |\n|----------|--------------|\n| CADOC | `format: \"XML\"`, `frequency: \"monthly\"/\"daily\"` |\n| e-Financeira | `format: \"XML\"`, `event_module`, `event_category`, `event_frequency`, `fatca_applicable`, `crs_applicable` |\n| DIMP | `format: \"XML\"`, `frequency: \"annual\"` |\n| APIX | `format: \"JSON\"`, `api_type: \"REST\"` |\n\n**Documentation Paths:**\n- CADOC: `.claude/docs/regulatory/templates/BACEN/CADOC/cadoc-4010-4016.md`\n- e-Financeira: `.claude/docs/regulatory/templates/RFB/EFINANCEIRA/efinanceira.md`\n- DIMP: `.claude/docs/regulatory/templates/RFB/DIMP/dimp-v10-manual.md`\n- APIX: `.claude/docs/regulatory/templates/BACEN/APIX/{code}/`\n\n---\n\n## State Tracking Output\n\nOutput on completion: `SKILL: regulatory-templates-setup | STATUS: COMPLETE | TEMPLATE: {template_selected} | DEADLINE: {deadline} | NEXT:  Gate 1`\n\n## Success Criteria\n\n-  Template selected and validated\n-  Deadline established (input or default)\n-  Context object initialized with ALL fields\n-  Dictionary status checked\n\n**Output:** Return complete `context` object to parent skill."
              },
              {
                "name": "ring:regulatory-templates",
                "description": "3-gate regulatory template orchestrator - manages setup, Gate 1 (analysis),\nGate 2 (validation), Gate 3 (generation) for BACEN/RFB compliance.\n",
                "path": "finops-team/skills/regulatory-templates/SKILL.md",
                "frontmatter": {
                  "name": "ring:regulatory-templates",
                  "description": "3-gate regulatory template orchestrator - manages setup, Gate 1 (analysis),\nGate 2 (validation), Gate 3 (generation) for BACEN/RFB compliance.\n",
                  "trigger": "- Creating BACEN CADOCs (4010, 4016, 4111)\n- Mapping e-Financeira, DIMP, APIX templates\n- Full automation from analysis to template creation\n",
                  "skip_when": "- Non-Brazilian regulations  not applicable\n- Analysis-only without template  use finops-analyzer directly\n- Template already exists, just needs updates  modify directly\n",
                  "sequence": {
                    "before": [
                      "regulatory-templates-setup"
                    ]
                  }
                },
                "content": "# Regulatory Templates - Orchestrator\n\n## Overview\n\n**This skill orchestrates the regulatory template creation workflow through modular sub-skills, managing a 3-gate sequential validation process with dynamic context passing between gates.**\n\n**Architecture:** Modular design with dedicated sub-skills for each phase:\n- `regulatory-templates-setup` - Initial configuration and selection\n- `regulatory-templates-gate1` - Regulatory compliance analysis and field mapping\n- `regulatory-templates-gate2` - Technical validation of mappings\n- `regulatory-templates-gate3` - Template file generation (.tpl)\n\n**Template Specifications:** All template specifications are dynamically loaded within gates from centralized configurations. Templates are organized by regulatory authority with cascading selection:\n\n**BACEN (Banco Central):**\n- **CADOC:** 4010 (Cadastro), 4016 (Crdito), 4111 (Cmbio)\n- **APIX:** 001 (Dados Cadastrais), 002 (Contas e Transaes)\n\n**RFB (Receita Federal):**\n- **e-Financeira:** evtCadDeclarante, evtAberturaeFinanceira, evtFechamentoeFinanceira, evtMovOpFin, evtMovPP, evtMovOpFinAnual\n- **DIMP:** v10 (Movimentao Patrimonial)\n\n**REQUIRED AGENTS:** The sub-skills dispatch specialized agents:\n- `finops-analyzer` - For Gates 1-2 and Discussion (regulatory analysis and validation)\n- `finops-automation` - For Gate 3 (template file generation)\n\n---\n\n## Foundational Principle\n\n**Brazilian regulatory compliance (BACEN, RFB) has zero margin for error.**\n\nThis isn't hyperbole:\n- BACEN penalties for incorrect submissions: R$10,000 - R$500,000 + license sanctions\n- RFB penalties for e-Financeira errors: Criminal liability for false declarations\n- Template errors are discovered during audits, often months after submission\n- \"We'll fix it later\" is impossible - submissions are final\n\n**This workflow exists because:**\n1. Human confidence without validation = optimism bias (proven by TDD research)\n2. \"Mostly correct\" regulatory submissions = rejected submissions + penalties\n3. Shortcuts under pressure = exactly when errors are most likely\n4. Each gate prevents specific failure modes discovered in production\n\n**The 3-gate architecture is not bureaucracy - it's risk management.**\n\nEvery section that seems \"rigid\" or \"redundant\" exists because someone, somewhere, cut that corner and caused a regulatory incident.\n\n**Follow this workflow exactly. Your professional reputation depends on it.**\n\n---\n\n## When to Use\n\n**Use this skill when:**\n- User requests mapping and creation of Brazilian regulatory templates\n- BACEN CADOCs (4010, 4016, 4111), e-Financeira, DIMP, APIX\n- Full automation from analysis to template creation\n\n**Symptoms triggering this skill:**\n- \"Create CADOC 4010 template\"\n- \"Map e-Financeira to Midaz and set up in Reporter\"\n- \"Automate DIMP template creation\"\n\n**When NOT to use:**\n- Non-Brazilian regulations\n- Analysis-only without template creation\n- Templates already exist and just need updates\n\n---\n\n## NO EXCEPTIONS - Read This First\n\n**This workflow has ZERO exceptions.** Brazilian regulatory compliance (BACEN, RFB) has zero margin for error.\n\n### Common Pressures You Must Resist\n\n| Pressure | Your Thought | Reality |\n|----------|--------------|---------|\n| **Deadline** | \"Skip Gate 2, we're confident\" | Gate 1 analysis  Gate 2 validation. Confidence without verification = optimism bias |\n| **Authority** | \"Manager says skip it\" | Manager authority doesn't override regulatory requirements. Workflow protects both of you |\n| **Fatigue** | \"Manual creation is faster\" | Fatigue makes errors MORE likely. Automation doesn't get tired |\n| **Economic** | \"Optional fields have no fines\" | Template is reusable. Skipping fields = technical debt + future rework |\n| **Sunk Cost** | \"Reuse existing template\" | 70% overlap = 30% different. Regulatory work doesn't tolerate \"mostly correct\" |\n| **Pragmatism** | \"Setup is ceremony\" | Setup initializes context. Skipping = silent assumptions |\n| **Efficiency** | \"Fix critical only\" | Gate 2 PASS criteria: ALL uncertainties resolved, not just critical |\n\n### Emergency Scenarios\n\n**\"Production is down, need template NOW\"**\n Production issues don't override regulatory compliance. Fix production differently.\n\n**\"CEO directive to ship immediately\"**\n CEO authority doesn't override BACEN requirements. Escalate risk in writing.\n\n**\"Client contract requires delivery today\"**\n Contract penalties < regulatory penalties. Renegotiate delivery, don't skip validation.\n\n**\"Tool/agent is unavailable\"**\n Wait for tools or escalate. Manual workarounds bypass validation layers.\n\n### The Bottom Line\n\n**Shortcuts in regulatory templates = career-ending mistakes.**\n\nBACEN and RFB submissions are final. You cannot \"patch next sprint.\" Every gate exists because regulatory compliance has zero tolerance for \"mostly correct.\"\n\n**If you're tempted to skip ANY part of this workflow, stop and ask yourself: Am I willing to stake my professional reputation on this shortcut?**\n\n---\n\n## Rationalization Table - Know the Excuses\n\nEvery rationalization below has been used to justify skipping workflow steps. **ALL are invalid.**\n\n| Excuse | Why It's Wrong | Correct Response |\n|--------|---------------|------------------|\n| \"Gate 2 is redundant when Gate 1 is complete\" | Gate 1 = analysis, Gate 2 = validation. Different purposes. Validation catches analysis errors | Run Gate 2 completely |\n| \"Manual creation is pragmatic\" | Manual bypasses validation layer. Gate 3 agent validates against Gate 2 report | Use automation agent |\n| \"Optional fields don't affect compliance\" | Overall confidence includes all fields. Skipping 36% fails PASS criteria | Map all fields |\n| \"70% overlap means we can copy\" | 30% difference contains critical regulatory fields. Similarity  simplicity | Run full workflow |\n| \"Setup is bureaucratic ceremony\" | Setup initializes context for Gates 1-3. Skipping creates silent assumptions | Run setup completely |\n| \"Fix critical issues only\" | Gate 2 PASS: ALL uncertainties resolved. Medium/low issues cascade to mandatory failures | Resolve all uncertainties |\n| \"We're experienced, simplified workflow\" | Experience doesn't exempt you from validation. Regulatory work requires process | Follow full workflow |\n| \"Following spirit not letter\" | Regulatory compliance requires BOTH. Skipping steps violates spirit AND letter | Process IS the spirit |\n| \"Being pragmatic vs dogmatic\" | Process exists because pragmatism failed. Brazilian regulatory penalties are severe | Rigor is pragmatism |\n| \"Tool is too rigid for real-world\" | Rigidity prevents errors. Real-world includes regulatory audits and penalties | Rigidity is protection |\n\n### If You Find Yourself Making These Excuses\n\n**STOP. You are rationalizing.**\n\nThe workflow exists specifically to prevent these exact thoughts from leading to errors. If the workflow seems \"too rigid,\" that's evidence it's working - preventing you from shortcuts that seem reasonable but create risk.\n\n---\n\n## Workflow Overview\n\n**Flow:** Setup  Gate 1  Gate 2  Gate 3  Template Created \n\n| Phase | Sub-skill | Purpose | Agent |\n|-------|-----------|---------|-------|\n| Setup | `regulatory-templates-setup` | Template selection, context init |  |\n| Gate 1 | `regulatory-templates-gate1` | Regulatory analysis, field mapping | `finops-analyzer` (opus) |\n| Gate 2 | `regulatory-templates-gate2` | Validate mappings, test transformations | `finops-analyzer` (opus) |\n| Gate 3 | `regulatory-templates-gate3` | Generate .tpl template file | `finops-automation` (sonnet) |\n\n---\n\n## Orchestration Process\n\n**Step 1:** Initialize TodoWrite with 5 tasks (setup, gate1, gate2, gate3, verify)\n\n**Step 2-5:** Execute each sub-skill using Skill tool:\n\n| Step | Skill | On PASS | On FAIL |\n|------|-------|---------|---------|\n| 2 | `regulatory-templates-setup` | Store context  Gate 1 | Fix selection issues |\n| 3 | `regulatory-templates-gate1` | Store spec report  Gate 2 | Address critical gaps, retry |\n| 4 | `regulatory-templates-gate2` | Store finalized report  Gate 3 | Resolve uncertainties, retry |\n| 5 | `regulatory-templates-gate3` | Template complete | 401=refresh token, 500/503=wait+retry |\n\n**Context flows in memory** - no intermediate files created\n\n---\n\n## Context Management - Report-Driven Flow\n\n**Context accumulates through gates (each adds, never overwrites):**\n\n| After | Context Additions |\n|-------|-------------------|\n| Setup | `template_selected`, `template_code`, `authority`, `deadline` |\n| Gate 1 | `specification_report` (template_info, fields, transformations, validations, structure) |\n| Gate 2 | `finalized_report` (validated, uncertainties_resolved, all_fields_mapped, ready_for_implementation) |\n| Gate 3 | `gate3` (template_file, filename, path, ready_for_use, report_compliance: 100%) |\n\n---\n\n## Template Specifications Management\n\n- Gates load specs dynamically from centralized config\n- Add new templates by adding specifications only (no new skills)\n- Pattern: `loadTemplateSpecifications(templateName)` for field mappings, validation rules, format specs\n\n---\n\n## State Tracking\n\nOutput after EACH sub-skill: `SKILL: regulatory-templates | PHASE: {phase} | TEMPLATE: {template} | GATES: {n}/3 | CURRENT: {action} | NEXT: {next} | BLOCKERS: {blockers}`\n\n---\n\n## Error Handling\n\n| Error | Action |\n|-------|--------|\n| Gate failure (retriable) | Fix issues  retry gate |\n| Gate failure (non-retriable) | Escalate to user |\n| Gate 3: 401 | Refresh token  retry |\n| Gate 3: 500/503 | Wait 2 min  retry |\n\n---\n\n## Coordination Rules\n\n1. Sequential execution (123)\n2. Context accumulates (never overwrites)\n3. Failure stops progress\n4. State tracking after each sub-skill\n5. TodoWrite updates immediately\n6. NO intermediate files (memory only)\n7. SINGLE output file (.tpl in Gate 3)\n\n---\n\n## Red Flags - STOP Immediately\n\nIf you catch yourself thinking ANY of these, STOP and re-read the NO EXCEPTIONS section:\n\n### Skip Patterns\n- \"Skip Gate X\" (any variation)\n- \"Run Gates out of order\"\n- \"Parallel gates for speed\"\n- \"Simplified workflow for experienced teams\"\n- \"Emergency override protocol\"\n\n### Manual Workarounds\n- \"Create template manually\"\n- \"Copy existing template\"\n- \"Manual validation is sufficient\"\n- \"I'll verify it myself\"\n\n### Partial Compliance\n- \"Fix critical only\"\n- \"Map mandatory fields only\"\n- \"Skip setup, we already know\"\n- \"Lower pass threshold\"\n\n### Justification Language\n- \"Being pragmatic\"\n- \"Following spirit not letter\"\n- \"Real-world flexibility\"\n- \"Process over outcome\"\n- \"Dogmatic adherence\"\n- \"We're confident\"\n- \"Manager approved\"\n\n### If You See These Red Flags\n\n1. **Acknowledge the rationalization** (\"I'm trying to skip Gate 2\")\n2. **Read the NO EXCEPTIONS section** (understand why it's required)\n3. **Follow the workflow completely** (no modifications)\n4. **Document the pressure** (for future skill improvement)\n\n**The workflow is non-negotiable. Regulatory compliance doesn't have \"reasonable exceptions.\"**\n\n---\n\n## Quick Reference\n\n| Sub-skill | Purpose | Input | Output |\n|-----------|---------|-------|--------|\n| regulatory-templates-setup | Initial configuration | User selections | Base context |\n| regulatory-templates-gate1 | Regulatory analysis | Base context | Field mappings, spec report |\n| regulatory-templates-gate2 | Technical validation | Context + Gate 1 | Validated mappings, rules |\n| regulatory-templates-gate3 | Template creation | Context + Gates 1-2 | .tpl file |\n\n## Checklist\n\n**Before:** Sub-skills exist, agents available, template selected, URLs configured\n**After each gate:** Result captured, context updated, TodoWrite updated, state tracked\n**After completion:** Template created, verified, user notified"
              },
              {
                "name": "ring:using-finops-team",
                "description": "2 FinOps agents for Brazilian financial regulatory compliance (BACEN, RFB,\nOpen Banking). Dispatch for compliance analysis or template generation.\n",
                "path": "finops-team/skills/using-finops-team/SKILL.md",
                "frontmatter": {
                  "name": "ring:using-finops-team",
                  "description": "2 FinOps agents for Brazilian financial regulatory compliance (BACEN, RFB,\nOpen Banking). Dispatch for compliance analysis or template generation.\n",
                  "trigger": "- Brazilian regulatory reporting (BACEN, RFB)\n- Financial compliance requirements\n- Open Banking specifications\n- Template generation for Reporter platform\n",
                  "skip_when": "- Non-Brazilian regulations  use appropriate resources\n- General financial analysis  use other tools\n"
                },
                "content": "# Using Ring FinOps & Regulatory Agents\n\nThe ring-finops-team plugin provides 2 specialized FinOps agents for Brazilian financial compliance. Use them via `Task tool with subagent_type:`.\n\n**Remember:** Follow the **ORCHESTRATOR principle** from `using-ring`. Dispatch agents to handle regulatory complexity; don't implement compliance manually.\n\n---\n\n## 2 FinOps Specialists\n\n### 1. FinOps Analyzer (Compliance Analysis)\n**`finops-analyzer`**\n\n**Specializations:**\n- Brazilian regulatory compliance analysis\n- BACEN (Central Bank) requirements:\n  - COSIF (accounting chart of accounts)\n  - CADOCs (financial instruments catalog)\n- RFB (Federal Revenue) requirements:\n  - e-Financeira (financial reporting)\n  - SPED (electronic data exchange)\n- Open Banking specifications\n- Field mapping & validation\n\n**Use When:**\n- Analyzing regulatory requirements (Gate 1-2)\n- Validating field mappings for compliance\n- Understanding BACEN/RFB specifications\n- Planning compliance architecture\n- Determining required data structures\n\n**Output:** Compliance analysis, field mappings, validation rules\n\n**Example dispatch:**\n```\nTask tool:\n  subagent_type: \"ring:finops-analyzer\"\n  model: \"opus\"\n  prompt: \"Analyze BACEN COSIF requirements for corporate account reporting\"\n```\n\n---\n\n### 2. FinOps Automation (Template Generation)\n**`finops-automation`**\n\n**Specializations:**\n- Template generation from specifications\n- .tpl file creation for Reporter platform\n- XML template generation\n- HTML template generation\n- TXT template generation\n- Reporter platform integration\n\n**Use When:**\n- Generating regulatory report templates (Gate 3)\n- Creating BACEN/RFB compliant templates\n- Building Reporter platform files\n- Converting specifications to executable templates\n- Finalizing compliance implementation\n\n**Output:** Complete .tpl template files, ready for Reporter platform\n\n**Example dispatch:**\n```\nTask tool:\n  subagent_type: \"ring:finops-automation\"\n  model: \"opus\"\n  prompt: \"Generate BACEN COSIF template from analyzed requirements\"\n```\n\n---\n\n## Regulatory Workflow: 3-Gate Process\n\nBrazilian regulatory compliance follows a 3-gate workflow:\n\n### Gate 1: Compliance Analysis\n**Agent:** finops-analyzer\n**Purpose:** Understand requirements, identify fields, validate mappings\n**Output:** compliance analysis document\n\n**Dispatch when:**\n- Starting regulatory feature\n- Need to understand BACEN/RFB specs\n- Planning field mappings\n\n---\n\n### Gate 2: Validation & Confirmation\n**Agent:** finops-analyzer (again)\n**Purpose:** Confirm mappings are correct, validate against specs\n**Output:** validated specification document\n\n**Dispatch when:**\n- Ready to confirm compliance understanding\n- Need secondary validation\n- Before moving to template generation\n\n---\n\n### Gate 3: Template Generation\n**Agent:** finops-automation\n**Purpose:** Generate executable .tpl templates from validated specifications\n**Output:** complete .tpl files for Reporter platform\n\n**Dispatch when:**\n- Specifications are finalized & validated\n- Ready to create Reporter templates\n- Need production-ready compliance files\n\n---\n\n## Supported Regulatory Standards\n\n### BACEN (Central Bank of Brazil)\n- **COSIF**  Chart of accounts and accounting rules\n- **CADOCs**  Financial instruments and derivatives catalog\n- **Manual de Normas**  Regulatory requirements\n\n### RFB (Brazilian Federal Revenue)\n- **e-Financeira**  Electronic financial reporting\n- **SPED**  Electronic data exchange system\n- **ECF**  Financial institutions data\n\n### Open Banking\n- **API specifications**  Data sharing standards\n- **Security requirements**  Auth and encryption\n- **Integration patterns**  System interoperability\n\n---\n\n## Decision: Which Agent?\n\n| Phase | Agent | Use Case |\n|-------|-------|----------|\n| Understanding requirements | finops-analyzer | Analyze specs, identify fields |\n| Validating mappings | finops-analyzer | Confirm correctness, validate |\n| Generating templates | finops-automation | Create .tpl files, finalize |\n\n---\n\n## When to Use FinOps Agents\n\n### Use finops-analyzer for:\n-  **Understanding regulations**  What does BACEN require?\n-  **Compliance research**  How do we map our data?\n-  **Requirement analysis**  Which fields are required?\n-  **Validation**  Does our mapping match the spec?\n\n### Use finops-automation for:\n-  **Template creation**  Build .tpl files\n-  **Specification execution**  Convert analysis to templates\n-  **Reporter platform prep**  Generate deployment files\n-  **Production readiness**  Finalize compliance implementation\n\n---\n\n## Dispatching Multiple FinOps Agents\n\nIf you need both analysis and template generation, **dispatch sequentially** (analyze first, then automate):\n\n```\nWorkflow:\nStep 1: Dispatch finops-analyzer\n   Returns: compliance analysis\nStep 2: Dispatch finops-automation\n   Returns: .tpl templates\n\nNote: These must run sequentially because automation depends on analysis.\n```\n\n---\n\n## ORCHESTRATOR Principle\n\nRemember:\n- **You're the orchestrator**  Dispatch agents, don't implement compliance manually\n- **Don't write BACEN specs yourself**  Dispatch analyzer to understand\n- **Don't generate templates by hand**  Dispatch automation agent\n- **Combine with using-ring principle**  Skills + Agents = complete workflow\n\n### Good Example (ORCHESTRATOR):\n> \"I need BACEN compliance. Let me dispatch finops-analyzer to understand requirements, then finops-automation to generate templates.\"\n\n### Bad Example (OPERATOR):\n> \"I'll manually read BACEN documentation and write templates myself.\"\n\n---\n\n## Reporter Platform Integration\n\nGenerated .tpl files integrate directly with Reporter platform:\n- **Input:** Validated specifications from finops-analyzer\n- **Output:** .tpl files (XML, HTML, TXT formats)\n- **Deployment:** Direct integration with Reporter\n- **Validation:** Compliance verified by template structure\n\n---\n\n## Available in This Plugin\n\n**Agents:**\n- finops-analyzer (Gate 1-2)\n- finops-automation (Gate 3)\n\n**Skills:**\n- using-finops-team (this skill - plugin introduction)\n- regulatory-templates (overview/index skill)\n- regulatory-templates-setup (Gate 0: Setup & initialization)\n- regulatory-templates-gate1 (Gate 1: Compliance analysis)\n- regulatory-templates-gate2 (Gate 2: Field mapping & validation)\n- regulatory-templates-gate3 (Gate 3: Template generation)\n\n**Note:** If agents are unavailable, check if ring-finops-team is enabled in `.claude-plugin/marketplace.json`.\n\n---\n\n## Integration with Other Plugins\n\n- **using-ring** (default)  ORCHESTRATOR principle for ALL agents\n- **using-dev-team**  Developer specialists\n- **using-pm-team**  Pre-dev workflow agents\n\nDispatch based on your need:\n- General code review  default plugin agents\n- Regulatory compliance  ring-finops-team agents\n- Developer expertise  ring-dev-team agents\n- Feature planning  ring-pm-team agents"
              }
            ]
          },
          {
            "name": "ring-tw-team",
            "description": "Technical writing specialists for functional and API documentation. 3 specialized agents (functional-writer, api-writer, docs-reviewer) and 7 documentation skills covering voice/tone, structure, API field descriptions, and quality review. Enforces clear, consistent documentation standards.",
            "source": "./tw-team",
            "category": null,
            "version": "0.3.6",
            "author": null,
            "install_commands": [
              "/plugin marketplace add LerianStudio/ring",
              "/plugin install ring-tw-team@ring"
            ],
            "signals": {
              "stars": 39,
              "forks": 2,
              "pushed_at": "2026-01-12T18:20:36Z",
              "created_at": "2025-10-30T20:18:13Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/review-docs",
                "description": "Review existing documentation for quality, voice, tone, and completeness",
                "path": "tw-team/commands/review-docs.md",
                "frontmatter": {
                  "name": "ring:review-docs",
                  "description": "Review existing documentation for quality, voice, tone, and completeness",
                  "argument-hint": "[file]",
                  "arguments": [
                    {
                      "name": "file",
                      "description": "Path to the documentation file to review",
                      "required": false
                    }
                  ]
                },
                "content": "# Review Documentation Command\n\nYou're reviewing documentation quality. This command dispatches the docs-reviewer agent.\n\n## Review Process\n\nThe review covers five dimensions:\n\n### 1. Voice and Tone\n- Uses \"you\" not \"users\"\n- Present tense for current behavior\n- Active voice (subject does action)\n- Assertive but not arrogant\n- Sounds like helping a colleague\n\n### 2. Structure\n- Sentence case headings\n- Section dividers between major topics\n- Scannable (bullets, tables, headings)\n- Logical hierarchy\n\n### 3. Completeness\n- All sections present\n- Examples included\n- Links work\n- Next steps provided\n\n### 4. Clarity\n- Short sentences (one idea)\n- Short paragraphs (2-3 sentences)\n- Jargon explained\n- Realistic examples\n\n### 5. Technical Accuracy\n- Facts are correct\n- Code examples work\n- Links valid\n- Version info current\n\n## Dispatch Review Agent\n\n```\nTask tool:\n  subagent_type: \"ring:docs-reviewer\"\n  model: \"opus\"\n  prompt: \"Review this documentation for quality. Check:\n          1. Voice and tone (second person, active voice, present tense)\n          2. Structure (sentence case, dividers, scannable)\n          3. Completeness (examples, links, next steps)\n          4. Clarity (short sentences, no jargon)\n          5. Accuracy (facts, code, links)\n\n          Provide:\n          - VERDICT: PASS / NEEDS_REVISION / MAJOR_ISSUES\n          - Prioritized issues with locations and fixes\n          - What was done well\n\n          Documentation to review:\n          [paste or reference file content]\"\n```\n\n## Quick Checklist\n\n### Voice (scan for these)\n- [ ] No \"users\" or \"one\" (should be \"you\")\n- [ ] No \"will\" for current behavior (should be present tense)\n- [ ] No \"is created by\" (should be active: \"creates\")\n\n### Structure (scan for these)\n- [ ] Headings are sentence case\n- [ ] `---` dividers present\n- [ ] Content is scannable\n\n### Completeness (check for)\n- [ ] Examples present\n- [ ] Links work\n- [ ] Next steps at end\n\n## Verdict Criteria\n\n**PASS:** No critical issues, 2 high-priority issues, consistent voice/tone\n\n**NEEDS_REVISION:** Has high-priority issues, some inconsistencies, minor gaps\n\n**MAJOR_ISSUES:** Critical issues, significant problems, poor structure\n\n## Common Issues Reference\n\n| Issue | Example | Fix |\n|-------|---------|-----|\n| Third person | \"Users can...\" | \"You can...\" |\n| Passive voice | \"...is returned\" | \"...returns\" |\n| Title case | \"Getting Started\" | \"Getting started\" |\n| Missing prereqs | Steps without context | Add prerequisites |\n| No examples | API without code | Add examples |\n| Long sentences | 40+ words | Split into multiple |\n\n## Proceed\n\n**Documentation to review:** $ARGUMENTS.file\n\nIf no file path was provided, paste the documentation content or specify a file path now.\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:documentation-review\n```\n\nThe skill contains the complete workflow with:\n- Five-dimension review (voice, structure, completeness, clarity, accuracy)\n- Verdict criteria (PASS, NEEDS_REVISION, MAJOR_ISSUES)\n- Common issues reference\n- Quick checklist\n- docs-reviewer agent dispatch"
              },
              {
                "name": "/write-api",
                "description": "Start writing API reference documentation for an endpoint",
                "path": "tw-team/commands/write-api.md",
                "frontmatter": {
                  "name": "ring:write-api",
                  "description": "Start writing API reference documentation for an endpoint",
                  "argument-hint": "[endpoint]",
                  "arguments": [
                    {
                      "name": "endpoint",
                      "description": "The API endpoint to document (e.g., POST /accounts)",
                      "required": true
                    }
                  ]
                },
                "content": "# Write API Reference Command\n\nYou're starting API reference documentation. Follow these steps:\n\n## 1. Understand the Endpoint\n\n**Endpoint to document:** $ARGUMENTS.endpoint\n\nGather information about:\n- HTTP method and path\n- Path parameters\n- Query parameters\n- Request body schema\n- Response schema\n- Error conditions\n\n## 2. Required Sections\n\nEvery endpoint must include:\n\n### HTTP Method and Path\n```markdown\n`POST /v1/organizations/{organizationId}/ledgers/{ledgerId}/accounts`\n```\n\n### Path Parameters\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n\n### Query Parameters (if applicable)\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n\n### Request Body\n```json\n{\n  \"field\": \"value\"\n}\n```\n\n### Request Body Fields\n| Field | Type | Required | Description |\n|-------|------|----------|-------------|\n\n### Response\n```json\n{\n  \"field\": \"value\"\n}\n```\n\n### Response Fields\n| Field | Type | Description |\n|-------|------|-------------|\n\n### Errors\n| Status Code | Error Code | Description |\n|-------------|------------|-------------|\n\n## 3. Field Description Patterns\n\n**UUID:** \"The unique identifier of the [Entity]\"\n\n**String with constraints:** \"[Purpose] (max N chars, format)\"\n\n**Enum:** \"[Purpose]: `value1`, `value2`, `value3`\"\n\n**Boolean:** \"If `true`, [behavior]. Default: `value`\"\n\n**Timestamp:** \"Timestamp of [event] (UTC)\"\n\n**Deprecated:** \"**[Deprecated]** Use `newField` instead\"\n\n**Read-only:** \"**Read-only.** Generated by the system\"\n\n## 4. Example Quality\n\n### Request examples must:\n- Use realistic data (not \"foo\", \"bar\")\n- Include all required fields\n- Be valid JSON\n\n### Response examples must:\n- Show complete structure\n- Include all fields\n- Use realistic UUIDs and timestamps\n\n## 5. Dispatch Agent\n\nFor complex API documentation, dispatch the api-writer agent:\n\n```\nTask tool:\n  subagent_type: \"ring:api-writer\"\n  model: \"opus\"\n  prompt: \"Document the [endpoint] endpoint. Include:\n          - All path/query parameters\n          - Complete request body schema\n          - Complete response schema\n          - All error codes\n          - Realistic examples\"\n```\n\n## 6. Review Before Publishing\n\nAfter writing, use the docs-reviewer agent:\n\n```\nTask tool:\n  subagent_type: \"ring:docs-reviewer\"\n  model: \"opus\"\n  prompt: \"Review this API documentation for completeness and accuracy:\n          [paste documentation]\"\n```\n\n## Data Types Reference\n\n| Type | Description | Example |\n|------|-------------|---------|\n| `uuid` | UUID v4 | `3172933b-50d2-4b17-96aa-9b378d6a6eac` |\n| `string` | Text | `\"Customer Account\"` |\n| `integer` | Whole number | `42` |\n| `boolean` | True/false | `true` |\n| `timestamptz` | ISO 8601 (UTC) | `2024-01-15T10:30:00Z` |\n| `jsonb` | JSON object | `{\"key\": \"value\"}` |\n| `array` | List | `[\"item1\", \"item2\"]` |\n| `enum` | Predefined values | `currency`, `crypto` |\n\n## HTTP Status Codes\n\n**Success:** 200 (GET/PUT), 201 (POST), 204 (DELETE)\n\n**Errors:** 400 (Bad Request), 401 (Unauthorized), 403 (Forbidden), 404 (Not Found), 409 (Conflict), 422 (Invalid), 429 (Rate Limited), 500 (Server Error)\n\n## Proceed\n\n**Endpoint to document:** $ARGUMENTS.endpoint\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:writing-api-docs\n```\n\nThe skill contains the complete workflow with:\n- Required sections (method, parameters, request/response, errors)\n- Field description patterns\n- Example quality requirements\n- Data types reference\n- HTTP status codes mapping"
              },
              {
                "name": "/write-guide",
                "description": "Start writing a functional guide with voice, tone, and structure guidance",
                "path": "tw-team/commands/write-guide.md",
                "frontmatter": {
                  "name": "ring:write-guide",
                  "description": "Start writing a functional guide with voice, tone, and structure guidance",
                  "argument-hint": "[topic]",
                  "arguments": [
                    {
                      "name": "topic",
                      "description": "The topic or feature to document",
                      "required": true
                    }
                  ]
                },
                "content": "# Write Guide Command\n\nYou're starting a functional documentation task. Follow these steps:\n\n## 1. Understand the Topic\n\n**Topic to document:** $ARGUMENTS.topic\n\nFirst, gather context about this topic:\n- What is it and why does it matter?\n- Who is the target audience?\n- What should readers be able to do after reading?\n\n## 2. Choose Document Type\n\nSelect the appropriate structure:\n\n### Conceptual Documentation\nFor explaining what something is and how it works.\n\n### Getting Started Guide\nFor helping users accomplish their first task.\n\n### How-To Guide\nFor task-focused instructions with specific goals.\n\n### Best Practices\nFor guidance on optimal usage patterns.\n\n## 3. Apply Writing Standards\n\n### Voice and Tone\n- Write like you're helping a smart colleague who just joined\n- Use \"you\" not \"users\"\n- Use present tense\n- Use active voice\n- Be assertive but not arrogant\n\n### Structure\n- Sentence case for headings\n- Short sentences (one idea each)\n- Short paragraphs (2-3 sentences)\n- Use `---` dividers between major sections\n- Include examples\n\n### Must Include\n- Clear value statement at the start\n- Key characteristics or steps\n- Working examples\n- Links to related content\n- Next steps at the end\n\n## 4. Dispatch Agent\n\nFor complex documentation, dispatch the functional-writer agent:\n\n```\nTask tool:\n  subagent_type: \"ring:functional-writer\"\n  model: \"opus\"\n  prompt: \"Write a [document type] for [topic]. Target audience: [audience].\n          The reader should be able to [goal] after reading.\"\n```\n\n## 5. Review Before Publishing\n\nAfter writing, use the docs-reviewer agent:\n\n```\nTask tool:\n  subagent_type: \"ring:docs-reviewer\"\n  model: \"opus\"\n  prompt: \"Review this documentation for voice, tone, structure, and completeness:\n          [paste documentation]\"\n```\n\n## Quick Reference\n\n### Document Structures\n\n**Conceptual:**\n```\n# Concept\nDefinition paragraph\n## Key characteristics\n## How it works\n---\n## Related concepts\n```\n\n**Getting Started:**\n```\n# Getting started with X\n## Prerequisites\n---\n## Step 1\n## Step 2\n---\n## Next steps\n```\n\n**How-To:**\n```\n# How to X\n## Before you begin\n## Steps\n## Verification\n```\n\n**Best Practices:**\n```\n# Best practices for X\n## Practice 1\n- Mistake:\n- Best practice:\n## Summary\n```\n\n## Proceed\n\n**Topic to document:** $ARGUMENTS.topic\n\n---\n\n## MANDATORY: Load Full Skill\n\n**This command MUST load the skill for complete workflow execution.**\n\n```\nUse Skill tool: ring:writing-functional-docs\n```\n\nThe skill contains the complete workflow with:\n- Document type selection (conceptual, getting-started, how-to, best-practices)\n- Voice and tone guidelines\n- Structure templates\n- Review integration\n- Quality checklist"
              }
            ],
            "skills": [
              {
                "name": "ring:api-field-descriptions",
                "description": "Patterns for writing clear, consistent API field descriptions including\ntypes, constraints, examples, and edge cases.\n",
                "path": "tw-team/skills/api-field-descriptions/SKILL.md",
                "frontmatter": {
                  "name": "ring:api-field-descriptions",
                  "description": "Patterns for writing clear, consistent API field descriptions including\ntypes, constraints, examples, and edge cases.\n",
                  "trigger": "- Writing API field documentation\n- Documenting request/response schemas\n- Creating data model documentation\n",
                  "skip_when": "- Writing conceptual docs  use writing-functional-docs\n- Full API endpoint docs  use writing-api-docs\n",
                  "related": {
                    "complementary": [
                      "writing-api-docs"
                    ]
                  }
                },
                "content": "# API Field Descriptions\n\nField descriptions are the most-read part of API documentation. Users scan for specific fields and need clear, consistent information.\n\n## Field Description Structure\n\nEvery field description answers: **What is it?** (purpose), **What type?** (data type), **Required?** (mandatory), **Constraints?** (limits/validations), **Example?** (valid data)\n\n## Table Format (Preferred)\n\n```markdown\n| Field | Type | Required | Description |\n|-------|------|----------|-------------|\n| id | uuid |  | The unique identifier of the Account |\n| name | string | Yes | The display name of the Account (max 255 chars) |\n| status | enum |  | Account status: `ACTIVE`, `INACTIVE`, `BLOCKED` |\n```\n\n**Note:** Use `` for response-only fields (not applicable for requests).\n\nFor nested objects: `status.code`, `status.description`\n\n---\n\n## Description Patterns by Type\n\n| Type | Pattern | Example |\n|------|---------|---------|\n| UUID | \"The unique identifier of the [Entity]\" | `id: uuid  The unique identifier of the Account` |\n| String | \"[Purpose] (constraints)\" | `code: string  The asset code (max 10 chars, uppercase, e.g., \"BRL\")` |\n| String (format) | \"[Purpose] (format example)\" | `email: string  Email address (e.g., \"user@example.com\")` |\n| Enum | \"[Purpose]: `val1`, `val2`, `val3`\" | `type: enum  Asset type: \\`currency\\`, \\`crypto\\`, \\`commodity\\`` |\n| Boolean | \"If `true`, [what happens]. Default: `[value]`\" | `allowSending: boolean  If \\`true\\`, sending permitted. Default: \\`true\\`` |\n| Integer | \"[Purpose] (range)\" | `scale: integer  Decimal places (0-18)` |\n| Timestamp | \"Timestamp of [event] (UTC)\" | `createdAt: timestamptz  Timestamp of creation (UTC)` |\n| Object (jsonb) | \"[Purpose] including [fields]\" | `status: jsonb  Status information including code and description` |\n| Array | \"List of [what it contains]\" | `operations: array  List of operations in the transaction` |\n\n---\n\n## Required vs Optional\n\n**In Requests:**\n- `Yes` = Must be provided\n- `No` = Optional\n- `Conditional` = Required in specific scenarios (explain in description)\n\n**In Responses:** Use `` (response fields are always returned or null)\n\n---\n\n## Special Field Documentation\n\n| Pattern | Format |\n|---------|--------|\n| Default values | \"Results per page. Default: 10\" |\n| Nullable fields | \"Soft deletion timestamp, or `null` if not deleted\" |\n| Deprecated fields | \"**[Deprecated]** Use `route` instead\" |\n| Read-only fields | \"**Read-only.** Generated by the system\" |\n| Relationships | \"References an Asset code. Must exist in the Ledger\" |\n\n---\n\n## Writing Good Descriptions\n\n| Don't | Do |\n|-------|-----|\n| \"The name\" | \"The display name of the Account\" |\n| \"Status info\" | \"Account status: `ACTIVE`, `INACTIVE`, `BLOCKED`\" |\n| \"A number\" | \"Balance version, incremented with each transaction\" |\n| \"The code\" | \"The asset code (max 10 chars, uppercase)\" |\n| \"The timestamp\" | \"Timestamp of creation (UTC)\" |\n\n---\n\n## Quality Checklist\n\n- [ ] Description explains the field's purpose\n- [ ] Data type is accurate\n- [ ] Required/optional status is clear\n- [ ] Constraints documented (max length, valid values)\n- [ ] Default value noted (if optional)\n- [ ] Nullable behavior explained (if applicable)\n- [ ] Deprecated fields marked\n- [ ] Read-only fields indicated\n- [ ] Relationships to other entities clear\n- [ ] Example values realistic"
              },
              {
                "name": "ring:documentation-review",
                "description": "Comprehensive checklist and process for reviewing documentation quality\nincluding voice, tone, structure, completeness, and technical accuracy.\n",
                "path": "tw-team/skills/documentation-review/SKILL.md",
                "frontmatter": {
                  "name": "ring:documentation-review",
                  "description": "Comprehensive checklist and process for reviewing documentation quality\nincluding voice, tone, structure, completeness, and technical accuracy.\n",
                  "trigger": "- Reviewing draft documentation\n- Pre-publication quality check\n- Documentation audit\n- Ensuring style guide compliance\n",
                  "skip_when": "- Writing new documentation  use writing-functional-docs or writing-api-docs\n- Only checking voice  use voice-and-tone\n",
                  "sequence": {
                    "after": [
                      "writing-functional-docs",
                      "writing-api-docs"
                    ]
                  },
                  "related": {
                    "complementary": [
                      "voice-and-tone",
                      "documentation-structure"
                    ]
                  }
                },
                "content": "# Documentation Review Process\n\nReview documentation systematically across multiple dimensions. A thorough review catches issues before they reach users.\n\n## Review Dimensions\n\n1. **Voice and Tone**  Does it sound right?\n2. **Structure**  Is it organized effectively?\n3. **Completeness**  Is everything covered?\n4. **Clarity**  Is it easy to understand?\n5. **Technical Accuracy**  Is it correct?\n\n---\n\n## Voice and Tone Review\n\n| Check | Flag If |\n|-------|---------|\n| Second person | \"Users can...\" instead of \"You can...\" |\n| Present tense | \"will return\" instead of \"returns\" |\n| Active voice | \"is returned by the API\" instead of \"The API returns\" |\n| Tone | Arrogant (\"Obviously...\") or condescending |\n\n---\n\n## Structure Review\n\n| Check | Flag If |\n|-------|---------|\n| Hierarchy | Deep nesting (H4+), unclear parent-child |\n| Headings | Title Case instead of sentence case |\n| Section dividers | Missing `---` between major topics |\n| Navigation | Missing links to related content |\n\n---\n\n## Completeness Review\n\n**Conceptual docs:** Definition, characteristics, how it works, related concepts, next steps\n\n**How-to guides:** Prerequisites, all steps, verification, troubleshooting, next steps\n\n**API docs:** HTTP method/path, all parameters, all fields, required vs optional, examples, error codes\n\n---\n\n## Clarity Review\n\n| Check | Flag If |\n|-------|---------|\n| Sentence length | >25 words per sentence |\n| Paragraph length | >3 sentences per paragraph |\n| Jargon | Technical terms not explained on first use |\n| Examples | Abstract data (\"foo\", \"bar\") instead of realistic |\n\n---\n\n## Technical Accuracy Review\n\n**Conceptual:** Facts correct, behavior matches description, links work\n\n**API docs:** Paths correct, methods correct, field names match API, types accurate, examples valid JSON\n\n**Code examples:** Compiles/runs, output matches description, no syntax errors\n\n---\n\n## Common Issues to Flag\n\n| Category | Issue | Fix |\n|----------|-------|-----|\n| Voice | Third person (\"Users can...\") | \"You can...\" |\n| Voice | Passive (\"...is returned\") | \"...returns\" |\n| Voice | Future tense (\"will provide\") | \"provides\" |\n| Structure | Title case heading | Sentence case |\n| Structure | Wall of text | Add `---` dividers |\n| Completeness | Missing prereqs | Add prerequisites |\n| Completeness | No examples | Add code examples |\n| Clarity | Long sentences (40+ words) | Split into multiple |\n| Clarity | Undefined jargon | Define on first use |\n\n---\n\n## Review Output Format\n\n> **Note:** Documentation reviews use `PASS/NEEDS_REVISION/MAJOR_ISSUES` verdicts (graduated), which differ from code review verdicts (`PASS/FAIL/NEEDS_DISCUSSION`).\n\n```markdown\n## Review Summary\n\n**Overall Assessment:** [PASS | NEEDS_REVISION | MAJOR_ISSUES]\n\n### Issues Found\n\n#### High Priority\n1. **Line 45:** Passive voice \"is created by\"  \"creates\"\n\n#### Medium Priority\n1. **Line 23:** Title case in heading  sentence case\n\n#### Low Priority\n1. **Line 12:** Could add example for clarity\n\n### Recommendations\n1. Fix passive voice instances (3 found)\n2. Add missing API field documentation\n```\n\n---\n\n## Quick Review Checklist\n\n**Voice (30s):** \"You\" not \"users\", present tense, active voice\n\n**Structure (30s):** Sentence case headings, section dividers, scannable (bullets/tables)\n\n**Completeness (1m):** Examples present, links work, next steps included\n\n**Accuracy (varies):** Technical facts correct, code examples work"
              },
              {
                "name": "ring:documentation-structure",
                "description": "Patterns for organizing and structuring documentation including hierarchy,\nnavigation, and information architecture.\n",
                "path": "tw-team/skills/documentation-structure/SKILL.md",
                "frontmatter": {
                  "name": "ring:documentation-structure",
                  "description": "Patterns for organizing and structuring documentation including hierarchy,\nnavigation, and information architecture.\n",
                  "trigger": "- Planning documentation structure\n- Organizing content hierarchy\n- Deciding how to split content across pages\n- Creating navigation patterns\n",
                  "skip_when": "- Writing content  use writing-functional-docs or writing-api-docs\n- Checking voice  use voice-and-tone\n",
                  "related": {
                    "complementary": [
                      "writing-functional-docs",
                      "writing-api-docs"
                    ]
                  }
                },
                "content": "# Documentation Structure\n\nGood structure helps users find what they need quickly. Organize content by user tasks and mental models, not by internal system organization.\n\n## Content Hierarchy\n\n```\nDocumentation/\n Welcome/              # Entry point, product overview\n Getting Started/      # First steps, quick wins\n Guides/              # Task-oriented documentation\n    Understanding X   # Conceptual\n    Use Cases        # Real-world scenarios\n    Best Practices   # Recommendations\n API Reference/       # Technical reference\n    Introduction     # API overview\n    Endpoints/       # Per-resource documentation\n Updates/             # Changelog, versioning\n```\n\n---\n\n## Page Structure Patterns\n\n| Page Type | Structure |\n|-----------|-----------|\n| **Overview** | Brief description  \"In this section you will find:\"  Linked list of child pages |\n| **Conceptual** | Lead paragraph  Key characteristics (bullets)  How it works  Subtopics with `---` dividers  Related concepts |\n| **Task-Oriented** | Brief context  Prerequisites  Numbered steps  Verification  Next steps |\n\n---\n\n## Section Dividers\n\nUse `---` between major sections for visual separation.\n\n**When to use:**\n- Between major topic changes\n- Before \"Related\" or \"Next steps\" sections\n- After introductory content\n- Before prerequisites in guides\n\n**Don't overuse:** Not every heading needs a divider.\n\n---\n\n## Navigation Patterns\n\n| Pattern | Usage |\n|---------|-------|\n| Breadcrumb | Show hierarchy: `Guides > Core Entities > Accounts` |\n| Prev/Next | Connect sequential content: `[Previous: Assets] \\| [Next: Portfolios]` |\n| On-this-page | For long pages, show section links at top |\n\n---\n\n## Information Density\n\n**Scannable content:**\n1. Lead with key point in each section\n2. Use bullet points for 3+ items\n3. Use tables for comparing options\n4. Use headings every 2-3 paragraphs\n5. Bold key terms on first use\n\n**Progressive disclosure:**\n- Essential info (80% of users need) first\n- Advanced configuration in separate section\n- Edge cases and rare scenarios last\n\n---\n\n## Tables vs Lists\n\n**Use tables when:** Comparing items across same attributes, showing structured data (API fields), displaying options with consistent properties\n\n**Use lists when:** Items don't have comparable attributes, sequence matters (steps), items have varying detail levels\n\n---\n\n## Code Examples Placement\n\n| Type | When |\n|------|------|\n| Inline code | Short references: \"Set the `assetCode` field...\" |\n| Code blocks | Complete, runnable examples |\n\n**Rules:**\n1. Show example immediately after explaining it\n2. Keep examples minimal but complete\n3. Use realistic data (not \"foo\", \"bar\")\n4. Show both request and response for API docs\n\n---\n\n## Cross-Linking Strategy\n\n- **Link first mention** of a concept in each section\n- **Don't over-link**  once per section is enough\n- **Link destinations:** Concept  conceptual docs, API action  endpoint, \"Learn more\"  deeper dive\n\n---\n\n## Page Length Guidelines\n\n| Page Type | Target | Reasoning |\n|-----------|--------|-----------|\n| Overview | 1-2 screens | Quick orientation |\n| Concept | 2-4 screens | Thorough explanation |\n| How-to | 1-3 screens | Task completion |\n| API endpoint | 2-3 screens | Complete reference |\n| Best practices | 3-5 screens | Multiple recommendations |\n\nIf >5 screens, consider splitting.\n\n---\n\n## Quality Checklist\n\n- [ ] Content organized by user task, not system structure\n- [ ] Overview pages link to all child content\n- [ ] Section dividers separate major topics\n- [ ] Headings create scannable structure\n- [ ] Tables used for comparable items\n- [ ] Code examples follow explanations\n- [ ] Cross-links connect related content\n- [ ] Page length appropriate for type\n- [ ] Navigation connects sequential content"
              },
              {
                "name": "ring:using-tw-team",
                "description": "Technical writing specialists for functional and API documentation. Dispatch when\nyou need to create guides, conceptual docs, or API references following established\ndocumentation standards.\n",
                "path": "tw-team/skills/using-tw-team/SKILL.md",
                "frontmatter": {
                  "name": "ring:using-tw-team",
                  "description": "Technical writing specialists for functional and API documentation. Dispatch when\nyou need to create guides, conceptual docs, or API references following established\ndocumentation standards.\n",
                  "trigger": "- Need to write functional documentation (guides, conceptual docs, tutorials)\n- Need to write API reference documentation\n- Need to review existing documentation quality\n- Writing or updating product documentation\n",
                  "skip_when": "- Writing code  use dev-team agents\n- Writing plans  use pm-team agents\n- General code review  use default plugin reviewers\n",
                  "related": {
                    "similar": [
                      "using-ring",
                      "using-dev-team"
                    ]
                  }
                },
                "content": "# Using Ring Technical Writing Specialists\n\nThe ring-tw-team plugin provides specialized agents for technical documentation. Use them via `Task tool with subagent_type:`.\n\n**Remember:** Follow the **ORCHESTRATOR principle** from `using-ring`. Dispatch agents to handle documentation tasks; don't write complex documentation directly.\n\n## 3 Documentation Specialists\n\n| Agent | Specialization | Use When |\n|-------|---------------|----------|\n| `functional-writer` | Conceptual docs, guides, tutorials, best practices, workflows | Writing product guides, tutorials, \"how to\" content |\n| `api-writer` | REST API reference, endpoints, schemas, errors, field descriptions | Documenting API endpoints, request/response examples |\n| `docs-reviewer` | Voice/tone, structure, completeness, clarity, accuracy | Reviewing drafts, pre-publication quality check |\n\n---\n\n## Documentation Standards Summary\n\n### Voice and Tone\n- **Assertive, but never arrogant**  Say what needs to be said, clearly\n- **Encouraging and empowering**  Guide users through complexity\n- **Tech-savvy, but human**  Use technical terms when needed, prioritize clarity\n- **Humble and open**  Confident but always learning\n\n### Capitalization\n- **Sentence case** for all headings and titles\n- Only first letter and proper nouns capitalized\n-  \"Getting started with the API\"\n-  \"Getting Started With The API\"\n\n### Structure Patterns\n1. Lead with clear definition paragraph\n2. Use bullet points for key characteristics\n3. Separate sections with `---` dividers\n4. Include info boxes and warnings where needed\n5. Link to related API reference\n6. Add code examples for technical topics\n\n---\n\n## Dispatching Specialists\n\n**Parallel dispatch** for comprehensive documentation (single message, multiple Tasks):\n\n```\nTask #1: functional-writer (write the guide)\nTask #2: api-writer (write API reference)\n(Both run in parallel)\n\nThen:\nTask #3: docs-reviewer (review both)\n```\n\n---\n\n## Available in This Plugin\n\n**Agents:** functional-writer, api-writer, docs-reviewer\n\n**Skills:**\n- using-tw-team: Plugin introduction\n- writing-functional-docs: Functional doc patterns\n- writing-api-docs: API reference patterns\n- documentation-structure: Hierarchy and organization\n- voice-and-tone: Voice guidelines\n- documentation-review: Quality checklist\n- api-field-descriptions: Field description patterns\n\n**Commands:**\n- /write-guide: Start functional guide\n- /write-api: Start API documentation\n- /review-docs: Review existing docs\n\n---\n\n## Integration with Other Plugins\n\n| Plugin | Use For |\n|--------|---------|\n| using-ring (default) | ORCHESTRATOR principle |\n| using-dev-team | Developer agents for technical accuracy |\n| using-pm-team | Pre-dev planning before documentation |\n\n---\n\n## ORCHESTRATOR Principle\n\n- **You're the orchestrator**  Dispatch specialists, don't write directly\n- **Let specialists apply standards**  They know voice, tone, structure\n- **Combine with other plugins**  API writers + backend engineers for accuracy\n\n>  \"I need documentation for the new feature. Let me dispatch functional-writer.\"\n>\n>  \"I'll manually write all the documentation myself.\""
              },
              {
                "name": "ring:voice-and-tone",
                "description": "Voice and tone guidelines for technical documentation. Ensures consistent,\nclear, and human writing across all documentation.\n",
                "path": "tw-team/skills/voice-and-tone/SKILL.md",
                "frontmatter": {
                  "name": "ring:voice-and-tone",
                  "description": "Voice and tone guidelines for technical documentation. Ensures consistent,\nclear, and human writing across all documentation.\n",
                  "trigger": "- Need to check voice and tone compliance\n- Writing new documentation\n- Reviewing existing documentation for style\n",
                  "skip_when": "- Only checking structure  use documentation-structure\n- Only checking technical accuracy  use docs-reviewer agent\n",
                  "related": {
                    "complementary": [
                      "writing-functional-docs",
                      "writing-api-docs",
                      "documentation-review"
                    ]
                  }
                },
                "content": "# Voice and Tone Guidelines\n\nWrite the way you work: with confidence, clarity, and care. Good documentation sounds like a knowledgeable colleague helping you solve a problem.\n\n## Core Tone Principles\n\n### Assertive, But Never Arrogant\nSay what needs to be said, clearly and without overexplaining.\n\n>  Midaz uses a microservices architecture, which allows each component to be self-sufficient and easily scalable.\n>\n>  Midaz might use what some people call a microservices architecture, which could potentially allow components to be somewhat self-sufficient.\n\n### Encouraging and Empowering\nGuide users to make progress, especially when things get complex.\n\n>  This setup isn't just technically solid; it's built for real-world use. You can add new components as needed without disrupting what's already in place.\n>\n>  This complex setup requires careful understanding of multiple systems before you can safely make changes.\n\n### Tech-Savvy, But Human\nTalk to developers, not at them. Use technical terms when needed, but prioritize clarity.\n\n>  Each Account is linked to exactly one Asset type.\n>\n>  The Account entity maintains a mandatory one-to-one cardinality with the Asset entity.\n\n### Humble and Open\nBe confident in your solutions but always assume there's more to learn.\n\n>  As Midaz evolves, new fields and tables may be added.\n>\n>  The system is complete and requires no further development.\n\n---\n\n## The Golden Rule\n\n> Write like you're helping a smart colleague who just joined the team.\n\nThis colleague is: Technical and can handle complexity, new to this system, busy and appreciates efficiency, capable of learning quickly with guidance.\n\n---\n\n## Writing Mechanics\n\n| Rule | Use | Avoid |\n|------|-----|-------|\n| Second person | \"You can create...\" | \"Users can create...\" |\n| Present tense | \"The system returns...\" | \"The system will return...\" |\n| Active voice | \"The API returns a JSON response\" | \"A JSON response is returned by the API\" |\n| Short sentences | Two sentences, one idea each | One long sentence with multiple clauses |\n\n---\n\n## Capitalization\n\n**Sentence case for all headings**  Only capitalize first letter and proper nouns.\n\n|  Correct |  Avoid |\n|-----------|---------|\n| Getting started with the API | Getting Started With The API |\n| Using the transaction builder | Using The Transaction Builder |\n| Managing account types | Managing Account Types |\n\nApplies to: Page titles, section headings, card titles, navigation labels, table headers\n\n---\n\n## Terminology\n\n**Product names:** Always capitalize (Midaz, Console, Reporter, Matcher, Flowker)\n\n**Entity names:** Capitalize when referring to specific concept (Account, Ledger, Asset, Portfolio, Segment, Transaction, Operation, Balance)\n\n> Each Account is linked to a single Asset.\n\nLowercase for general references:\n> You can create multiple accounts within a ledger.\n\n---\n\n## Contractions\n\nUse naturally to make writing conversational:\n\n| Natural | Stiff |\n|---------|-------|\n| You'll find... | You will find... |\n| It's important... | It is important... |\n| Don't delete... | Do not delete... |\n\n---\n\n## Emphasis\n\n**Bold** for UI elements and key terms: Click **Create Account**, the **metadata** field\n\n`Code formatting` for technical terms: `POST /accounts`, `allowSending`\n\n**Don't overuse**  if everything is emphasized, nothing stands out.\n\n---\n\n## Info Boxes\n\n| Type | When |\n|------|------|\n| **Tip:** | Helpful information |\n| **Note:** | Important context |\n| **Warning:** | Potential issues |\n| **Deprecated:** | Removal notices |\n\n---\n\n## Quality Checklist\n\n- [ ] Uses \"you\" consistently (not \"users\")\n- [ ] Uses present tense for current behavior\n- [ ] Uses active voice (subject does action)\n- [ ] Sentences are short (one idea each)\n- [ ] Headings use sentence case\n- [ ] Technical terms used appropriately\n- [ ] Contractions used naturally\n- [ ] Emphasis used sparingly\n- [ ] Sounds like helping a colleague"
              },
              {
                "name": "ring:writing-api-docs",
                "description": "Patterns and structure for writing API reference documentation including\nendpoint descriptions, request/response schemas, and error documentation.\n",
                "path": "tw-team/skills/writing-api-docs/SKILL.md",
                "frontmatter": {
                  "name": "ring:writing-api-docs",
                  "description": "Patterns and structure for writing API reference documentation including\nendpoint descriptions, request/response schemas, and error documentation.\n",
                  "trigger": "- Documenting REST API endpoints\n- Writing request/response examples\n- Documenting error codes\n- Creating API field descriptions\n",
                  "skip_when": "- Writing conceptual guides  use writing-functional-docs\n- Reviewing documentation  use documentation-review\n- Writing code  use dev-team agents\n",
                  "sequence": {
                    "before": [
                      "documentation-review"
                    ]
                  },
                  "related": {
                    "similar": [
                      "writing-functional-docs"
                    ],
                    "complementary": [
                      "api-field-descriptions",
                      "documentation-structure"
                    ]
                  }
                },
                "content": "# Writing API Reference Documentation\n\nAPI reference documentation describes what each endpoint does, its parameters, request/response formats, and error conditions. It focuses on the \"what\" rather than the \"why.\"\n\n## API Reference Principles\n\n- **RESTful and Predictable:** Standard HTTP methods, consistent URL patterns, document idempotency\n- **Consistent Formats:** JSON requests/responses, clear typing, standard error format\n- **Explicit Versioning:** Version in URL path, backward compatibility notes, deprecated fields marked\n\n---\n\n## Endpoint Documentation Structure\n\n| Section | Content |\n|---------|---------|\n| **Title** | Endpoint name |\n| **Description** | Brief description of what the endpoint does |\n| **HTTP Method + Path** | `POST /v1/organizations/{orgId}/ledgers/{ledgerId}/accounts` |\n| **Path Parameters** | Table: Parameter, Type, Required, Description |\n| **Query Parameters** | Table: Parameter, Type, Default, Description |\n| **Request Body** | JSON example + fields table |\n| **Success Response** | Status code + JSON example + fields table |\n| **Errors** | Table: Status Code, Error Code, Description |\n\n---\n\n## Field Description Patterns\n\n| Type | Pattern |\n|------|---------|\n| Basic | `name: string  The name of the Account` |\n| With constraints | `code: string  The asset code (max 10 chars, uppercase)` |\n| With example | `email: string  Email address (e.g., \"user@example.com\")` |\n| Deprecated | `chartOfAccountsGroupName: string  **[Deprecated]** Use \\`route\\` instead` |\n\n---\n\n## Data Types Reference\n\n| Type | Description | Example |\n|------|-------------|---------|\n| `uuid` | UUID v4 identifier | `3172933b-50d2-4b17-96aa-9b378d6a6eac` |\n| `string` | Text value | `\"Customer Account\"` |\n| `integer` | Whole number | `42` |\n| `boolean` | True/false | `true` |\n| `timestamptz` | ISO 8601 (UTC) | `2024-01-15T10:30:00Z` |\n| `jsonb` | JSON object | `{\"key\": \"value\"}` |\n| `array` | List of values | `[\"item1\", \"item2\"]` |\n| `enum` | Predefined values | `currency`, `crypto` |\n\n---\n\n## Request/Response Examples\n\n**Rules:**\n- Show realistic, working examples (not \"foo\", \"bar\")\n- Show all fields that would be returned\n- Use actual UUIDs, timestamps, realistic data\n\n---\n\n## Error Documentation\n\n**Standard error format:**\n```json\n{\n  \"code\": \"ACCOUNT_NOT_FOUND\",\n  \"message\": \"The specified account does not exist\",\n  \"details\": { \"accountId\": \"invalid-uuid\" }\n}\n```\n\n**Error table:**\n\n| Status | Code | Description | Resolution |\n|--------|------|-------------|------------|\n| 400 | INVALID_REQUEST | Validation failed | Check request format |\n| 401 | UNAUTHORIZED | Missing/invalid auth | Provide valid API key |\n| 403 | FORBIDDEN | Insufficient permissions | Contact admin |\n| 404 | NOT_FOUND | Resource doesn't exist | Verify resource ID |\n| 409 | CONFLICT | Resource already exists | Use different identifier |\n| 422 | UNPROCESSABLE_ENTITY | Business rule violation | Check constraints |\n| 429 | TOO_MANY_REQUESTS | Rate limit exceeded | Retry after delay |\n| 500 | INTERNAL_ERROR | Server error | Retry or contact support |\n\n---\n\n## HTTP Status Codes\n\n**Success:** 200 (GET/PUT/PATCH), 201 (POST creates), 204 (DELETE)\n\n**Client errors:** 400 (malformed), 401 (no auth), 403 (no permission), 404 (not found), 409 (conflict), 422 (invalid semantics), 429 (rate limit)\n\n**Server errors:** 500 (internal)\n\n---\n\n## Pagination Documentation\n\nFor paginated endpoints, document query parameters:\n\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n| limit | integer | 10 | Results per page (max 100) |\n| page | integer | 1 | Page number |\n\nResponse includes: `items`, `page`, `limit`, `totalItems`, `totalPages`\n\n---\n\n## Versioning Notes\n\n> **Note:** You're viewing documentation for the **current version** (v3).\n\nFor deprecated: `> **Deprecated:** This endpoint will be removed in v4. Use [/v3/accounts](link) instead.`\n\n---\n\n## Quality Checklist\n\n- [ ] HTTP method and path correct\n- [ ] All path parameters documented\n- [ ] All query parameters documented\n- [ ] All request body fields documented with types\n- [ ] All response fields documented with types\n- [ ] Required vs optional clear\n- [ ] Realistic request/response examples included\n- [ ] All error codes documented\n- [ ] Deprecated fields marked\n- [ ] Links to related endpoints included"
              },
              {
                "name": "ring:writing-functional-docs",
                "description": "Patterns and structure for writing functional documentation including guides,\nconceptual explanations, tutorials, and best practices documentation.\n",
                "path": "tw-team/skills/writing-functional-docs/SKILL.md",
                "frontmatter": {
                  "name": "ring:writing-functional-docs",
                  "description": "Patterns and structure for writing functional documentation including guides,\nconceptual explanations, tutorials, and best practices documentation.\n",
                  "trigger": "- Writing a new guide or tutorial\n- Creating conceptual documentation\n- Documenting best practices\n- Writing \"how to\" content\n",
                  "skip_when": "- Writing API reference  use writing-api-docs\n- Reviewing documentation  use documentation-review\n- Writing code  use dev-team agents\n",
                  "sequence": {
                    "before": [
                      "documentation-review"
                    ]
                  },
                  "related": {
                    "similar": [
                      "writing-api-docs"
                    ],
                    "complementary": [
                      "voice-and-tone",
                      "documentation-structure"
                    ]
                  }
                },
                "content": "# Writing Functional Documentation\n\nFunctional documentation explains concepts, guides users through workflows, and helps them understand \"why\" and \"how\" things work. This differs from API reference, which documents \"what\" each endpoint does.\n\n## Document Types\n\n| Type | Purpose | Key Sections |\n|------|---------|--------------|\n| **Conceptual** | Explains core concepts and how things work | Definition  Key characteristics  How it works  Related concepts |\n| **Getting Started** | First task with the product | Intro  Prerequisites  Numbered steps  Next steps |\n| **How-To** | Task-focused for specific goals | Context  Before you begin  Steps  Verification  Troubleshooting |\n| **Best Practices** | Optimal usage patterns | Intro  Practice sections (Mistake/Best practice)  Summary |\n\n---\n\n## Writing Patterns\n\n### Lead with Value\nStart every document with what the reader will learn or accomplish.\n\n>  This guide shows you how to create your first transaction in under 5 minutes.\n>\n>  In this document, we will discuss the various aspects of transaction creation.\n\n### Use Second Person\nAddress the reader directly.\n\n>  You can create as many accounts as your structure demands.\n>\n>  Users can create as many accounts as their structure demands.\n\n### Present Tense\nUse for current behavior.\n\n>  Midaz uses a microservices architecture.\n>\n>  Midaz will use a microservices architecture.\n\n### Action-Oriented Headings\nIndicate what the section covers or what users will do.\n\n>  Creating your first account\n>\n>  Account creation process overview\n\n### Short Paragraphs\n2-3 sentences maximum. Use bullets for lists.\n\n---\n\n## Visual Elements\n\n| Element | Usage |\n|---------|-------|\n| **Info box** | `> **Tip:** Helpful additional context` |\n| **Warning box** | `> **Warning:** Important caution` |\n| **Code examples** | Always include working examples for technical concepts |\n| **Tables** | For comparing options or structured data |\n\n---\n\n## Section Dividers\n\nUse `---` to separate major sections. Improves scannability.\n\n---\n\n## Linking Patterns\n\n- **Internal links:** Link concepts when first mentioned: \"Each Account is linked to a single [Asset](link)\"\n- **API reference links:** Connect to API docs: \"Manage via [API](link) or [Console](link)\"\n- **Next steps:** End guides with clear next steps\n\n---\n\n## Quality Checklist\n\n- [ ] Leads with clear value statement\n- [ ] Uses second person (\"you\")\n- [ ] Uses present tense\n- [ ] Headings are action-oriented (sentence case)\n- [ ] Paragraphs are short (2-3 sentences)\n- [ ] Includes working code examples\n- [ ] Links to related documentation\n- [ ] Ends with next steps\n- [ ] Follows voice and tone guidelines"
              }
            ]
          }
        ]
      }
    }
  ]
}