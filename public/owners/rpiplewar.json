{
  "owner": {
    "id": "rpiplewar",
    "display_name": "rpiplewar",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/115534607?v=4",
    "url": "https://github.com/rpiplewar",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 21,
      "total_skills": 0,
      "total_stars": 7,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "rpiplewar/shipfaster",
      "url": "https://github.com/rpiplewar/shipfaster",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 7,
        "forks": 0,
        "pushed_at": "2025-10-30T18:27:06Z",
        "created_at": "2025-10-13T14:36:48Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 322
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 16
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5901
        },
        {
          "path": "content-gen",
          "type": "tree",
          "size": null
        },
        {
          "path": "content-gen/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "content-gen/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 212
        },
        {
          "path": "content-gen/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "content-gen/agents/critic.md",
          "type": "blob",
          "size": 8222
        },
        {
          "path": "content-gen/agents/draft-generator.md",
          "type": "blob",
          "size": 12369
        },
        {
          "path": "content-gen/agents/performance-tracker.md",
          "type": "blob",
          "size": 10778
        },
        {
          "path": "content-gen/agents/scorer.md",
          "type": "blob",
          "size": 13950
        },
        {
          "path": "content-gen/agents/selector.md",
          "type": "blob",
          "size": 8061
        },
        {
          "path": "content-gen/agents/story-extractor.md",
          "type": "blob",
          "size": 7276
        },
        {
          "path": "content-gen/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "content-gen/commands/content-critic-review.md",
          "type": "blob",
          "size": 4792
        },
        {
          "path": "content-gen/commands/content-extract-stories.md",
          "type": "blob",
          "size": 3764
        },
        {
          "path": "content-gen/commands/content-full-pipeline.md",
          "type": "blob",
          "size": 15053
        },
        {
          "path": "content-gen/commands/content-generate-drafts.md",
          "type": "blob",
          "size": 4385
        },
        {
          "path": "content-gen/commands/content-score-all.md",
          "type": "blob",
          "size": 4048
        },
        {
          "path": "content-gen/commands/content-select-best.md",
          "type": "blob",
          "size": 7004
        },
        {
          "path": "content-gen/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "content-gen/templates/content-prp-base.md",
          "type": "blob",
          "size": 16483
        },
        {
          "path": "content-gen/templates/scoring-rubric.md",
          "type": "blob",
          "size": 22084
        },
        {
          "path": "prp",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 152
        },
        {
          "path": "prp/PRPs",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/PRPs/README.md",
          "type": "blob",
          "size": 2567
        },
        {
          "path": "prp/PRPs/STORY_WORKFLOW_GUIDE.md",
          "type": "blob",
          "size": 5441
        },
        {
          "path": "prp/PRPs/ai_docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/PRPs/ai_docs/build_with_claude_code.md",
          "type": "blob",
          "size": 21380
        },
        {
          "path": "prp/PRPs/ai_docs/cc_administration.md",
          "type": "blob",
          "size": 21051
        },
        {
          "path": "prp/PRPs/ai_docs/cc_cli.md",
          "type": "blob",
          "size": 11047
        },
        {
          "path": "prp/PRPs/ai_docs/cc_commands.md",
          "type": "blob",
          "size": 8998
        },
        {
          "path": "prp/PRPs/ai_docs/cc_containers.md",
          "type": "blob",
          "size": 4281
        },
        {
          "path": "prp/PRPs/ai_docs/cc_deployment.md",
          "type": "blob",
          "size": 46231
        },
        {
          "path": "prp/PRPs/ai_docs/cc_hooks.md",
          "type": "blob",
          "size": 37467
        },
        {
          "path": "prp/PRPs/ai_docs/cc_mcp.md",
          "type": "blob",
          "size": 15149
        },
        {
          "path": "prp/PRPs/ai_docs/cc_monitoring.md",
          "type": "blob",
          "size": 61793
        },
        {
          "path": "prp/PRPs/ai_docs/cc_settings.md",
          "type": "blob",
          "size": 33924
        },
        {
          "path": "prp/PRPs/ai_docs/cc_troubleshoot.md",
          "type": "blob",
          "size": 5360
        },
        {
          "path": "prp/PRPs/ai_docs/getting_started.md",
          "type": "blob",
          "size": 34126
        },
        {
          "path": "prp/PRPs/ai_docs/github_actions.md",
          "type": "blob",
          "size": 22526
        },
        {
          "path": "prp/PRPs/ai_docs/hooks.md",
          "type": "blob",
          "size": 5927
        },
        {
          "path": "prp/PRPs/ai_docs/subagents.md",
          "type": "blob",
          "size": 11814
        },
        {
          "path": "prp/PRPs/example-from-workshop-mcp-crawl4ai-refactor-1.md",
          "type": "blob",
          "size": 15294
        },
        {
          "path": "prp/PRPs/pydantic-ai-prp-creation-agent-parallel.md",
          "type": "blob",
          "size": 24573
        },
        {
          "path": "prp/PRPs/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/PRPs/scripts/prp_runner.py",
          "type": "blob",
          "size": 10223
        },
        {
          "path": "prp/PRPs/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/PRPs/templates/prp_base.md",
          "type": "blob",
          "size": 10161
        },
        {
          "path": "prp/PRPs/templates/prp_base_typescript.md",
          "type": "blob",
          "size": 11514
        },
        {
          "path": "prp/PRPs/templates/prp_planning.md",
          "type": "blob",
          "size": 7678
        },
        {
          "path": "prp/PRPs/templates/prp_poc_react.md",
          "type": "blob",
          "size": 12941
        },
        {
          "path": "prp/PRPs/templates/prp_spec.md",
          "type": "blob",
          "size": 1850
        },
        {
          "path": "prp/PRPs/templates/prp_story_task.md",
          "type": "blob",
          "size": 5492
        },
        {
          "path": "prp/PRPs/templates/prp_task.md",
          "type": "blob",
          "size": 4254
        },
        {
          "path": "prp/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/agents/codebase-analyst.md",
          "type": "blob",
          "size": 3411
        },
        {
          "path": "prp/agents/library-researcher.md",
          "type": "blob",
          "size": 3004
        },
        {
          "path": "prp/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "prp/commands/api-contract-define.md",
          "type": "blob",
          "size": 3062
        },
        {
          "path": "prp/commands/prp-base-create.md",
          "type": "blob",
          "size": 4963
        },
        {
          "path": "prp/commands/prp-base-execute.md",
          "type": "blob",
          "size": 2529
        },
        {
          "path": "prp/commands/prp-planning-create.md",
          "type": "blob",
          "size": 3139
        },
        {
          "path": "prp/commands/prp-poc-create-parallel.md",
          "type": "blob",
          "size": 10980
        },
        {
          "path": "prp/commands/prp-poc-execute-parallel.md",
          "type": "blob",
          "size": 13013
        },
        {
          "path": "prp/commands/prp-spec-create.md",
          "type": "blob",
          "size": 2790
        },
        {
          "path": "prp/commands/prp-spec-execute.md",
          "type": "blob",
          "size": 847
        },
        {
          "path": "prp/commands/prp-story-create.md",
          "type": "blob",
          "size": 5402
        },
        {
          "path": "prp/commands/prp-story-execute.md",
          "type": "blob",
          "size": 2317
        },
        {
          "path": "prp/commands/prp-task-create.md",
          "type": "blob",
          "size": 2202
        },
        {
          "path": "prp/commands/prp-task-execute.md",
          "type": "blob",
          "size": 426
        },
        {
          "path": "prp/commands/prp-ts-create.md",
          "type": "blob",
          "size": 6443
        },
        {
          "path": "prp/commands/prp-ts-execute.md",
          "type": "blob",
          "size": 3710
        },
        {
          "path": "prp/commands/task-list-init.md",
          "type": "blob",
          "size": 1064
        }
      ],
      "marketplace": {
        "name": "rapid-shipping",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "rpiplewar"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "prp",
            "description": "prp commands to ship products at rapid speed",
            "source": "./prp",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add rpiplewar/shipfaster",
              "/plugin install prp@rapid-shipping"
            ],
            "signals": {
              "stars": 7,
              "forks": 0,
              "pushed_at": "2025-10-30T18:27:06Z",
              "created_at": "2025-10-13T14:36:48Z",
              "license": null
            },
            "commands": [
              {
                "name": "/api-contract-define",
                "description": null,
                "path": "prp/commands/api-contract-define.md",
                "frontmatter": null,
                "content": "# Define API Contract Between Backend and Frontend\n\nFeature: $ARGUMENTS\n\n## Task: Create detailed API contract specification for backend/frontend coordination\n\n1. **Define RESTful endpoints**:\n\n   ```yaml\n   Base URL: /api/v1/{feature}\n\n   Endpoints:\n   - GET /api/v1/{features}\n     Query params: page, size, sort, filter\n     Response: Page<{Feature}Response>\n\n   - GET /api/v1/{features}/{id}\n     Path param: id (Long)\n     Response: {Feature}Response\n\n   - POST /api/v1/{features}\n     Body: {Feature}Request\n     Response: {Feature}Response (201 Created)\n\n   - PUT /api/v1/{features}/{id}\n     Path param: id (Long)\n     Body: {Feature}Request\n     Response: {Feature}Response\n\n   - DELETE /api/v1/{features}/{id}\n     Path param: id (Long)\n     Response: 204 No Content\n   ```\n\n2. **Define request/response DTOs**:\n\n   ```typescript\n   // Request DTO (for POST/PUT)\n   interface {Feature}Request {\n     name: string;        // min: 2, max: 100\n     description?: string; // max: 1000\n     // Add domain-specific fields\n   }\n\n   // Response DTO (for GET)\n   interface {Feature}Response {\n     id: number;\n     name: string;\n     description?: string;\n     createdAt: string;   // ISO 8601\n     updatedAt: string;   // ISO 8601\n     // Add computed fields\n   }\n\n   // Page response wrapper\n   interface Page<T> {\n     content: T[];\n     totalElements: number;\n     totalPages: number;\n     size: number;\n     number: number;\n   }\n   ```\n\n3. **Define error responses**:\n\n   ```json\n   {\n     \"timestamp\": \"2024-01-20T10:30:00Z\",\n     \"status\": 400,\n     \"error\": \"Bad Request\",\n     \"message\": \"Validation failed\",\n     \"path\": \"/api/v1/{features}\",\n     \"errors\": [\n       {\n         \"field\": \"name\",\n         \"message\": \"Name is required\"\n       }\n     ]\n   }\n   ```\n\n4. **Define validation rules**:\n   - Backend: Bean Validation annotations\n   - Frontend: Matching Zod schemas\n\n   ```\n   name: required, 2-100 chars\n   description: optional, max 1000 chars\n   email: valid email format\n   date: ISO 8601 format\n   ```\n\n5. **Define status codes**:\n   - 200: OK (GET, PUT)\n   - 201: Created (POST)\n   - 204: No Content (DELETE)\n   - 400: Bad Request (validation)\n   - 404: Not Found\n   - 409: Conflict (duplicate)\n   - 500: Internal Server Error\n\n6. **Integration requirements**:\n   - CORS: Allow frontend origin\n   - Content-Type: application/json\n   - Authentication: Bearer token (if needed)\n   - Pagination: Spring Pageable format\n   - Sorting: field,direction (e.g., \"name,asc\")\n\n7. **Backend implementation notes**:\n\n   ```java\n   // Entity fields match response DTO\n   // Use MapStruct for DTO mapping\n   // Repository method naming conventions\n   // Service layer validation\n   ```\n\n8. **Frontend implementation notes**:\n   ```typescript\n   // Zod schemas match validation rules\n   // API client with base configuration\n   // TanStack Query hooks\n   // Error handling utilities\n   ```\n\nSave this contract as: `PRPs/working-memory/{feature-name}/contracts/{feature}-api-contract.md`\n\nShare this file between backend and frontend teams for alignment.\n"
              },
              {
                "name": "/prp-base-create",
                "description": null,
                "path": "prp/commands/prp-base-create.md",
                "frontmatter": null,
                "content": "# Create BASE PRP\n\n## Feature: $ARGUMENTS\n\n## PRP Creation Mission\n\nCreate a comprehensive PRP that enables **one-pass implementation success** through systematic research and context curation.\n\n**Critical Understanding**: The executing AI agent only receives:\n\n- Start by reading and understanding the prp concepts PRPs/README.md\n- The PRP content you create\n- Its training data knowledge\n- Access to codebase files (but needs guidance on which ones)\n\n**Therefore**: Your research and context curation directly determines implementation success. Incomplete context = implementation failure.\n\n## Research Process\n\n> During the research process, create clear tasks and spawn as many agents and subagents as needed using the batch tools. The deeper research we do here the better the PRP will be. we optminize for chance of success and not for speed.\n\n1. **User Clarification**\n   - Breakdown the ask into clear steps\n   - List all assumptions as you make them\n   - Clarify your assumptions from user before proceeding\n\n2. **Codebase Analysis in depth**\n   - Create clear todos and spawn subagents to search the codebase for similar features/patterns Think hard and plan your approach\n   - Identify all the necessary files to reference in the PRP\n   - Note all existing conventions to follow\n   - Check existing test patterns for validation approach\n   - Use the batch tools to spawn subagents to search the codebase for similar features/patterns\n\n3. **External Research at scale**\n   - Create clear todos and spawn with instructions subagents to do deep research for similar features/patterns online and include urls to documentation and examples\n   - Library documentation (include specific URLs)\n   - For critical pieces of documentation add a .md file to PRPs/ai_docs and reference it in the PRP with clear reasoning and instructions\n   - Implementation examples (GitHub/StackOverflow/blogs)\n   - Best practices and common pitfalls found during research\n   - Use the batch tools to spawn subagents to search for similar features/patterns online and include urls to documentation and examples\n\n3. **User Clarification**\n   - Ask for clarification if you need it\n\n## PRP Generation Process\n\n### Step 1: Choose Template\n\nUse `PRPs/templates/prp_base.md` as your template structure - it contains all necessary sections and formatting.\n\n### Step 2: Context Completeness Validation\n\nBefore writing, apply the **\"No Prior Knowledge\" test** from the template:\n_\"If someone knew nothing about this codebase, would they have everything needed to implement this successfully?\"_\n\n### Step 3: Research Integration\n\nTransform your research findings into the template sections:\n\n**Goal Section**: Use research to define specific, measurable Feature Goal and concrete Deliverable\n**Context Section**: Populate YAML structure with your research findings - specific URLs, file patterns, gotchas\n**Implementation Tasks**: Create dependency-ordered tasks using information-dense keywords from codebase analysis\n**Validation Gates**: Use project-specific validation commands that you've verified work in this codebase\n\n### Step 4: Information Density Standards\n\nEnsure every reference is **specific and actionable**:\n\n- URLs include section anchors, not just domain names\n- File references include specific patterns to follow, not generic mentions\n- Task specifications include exact naming conventions and placement\n- Validation commands are project-specific and executable\n\n### Step 5: ULTRATHINK Before Writing\n\nAfter research completion, create comprehensive PRP writing plan using TodoWrite tool:\n\n- Plan how to structure each template section with your research findings\n- Identify gaps that need additional research\n- Create systematic approach to filling template with actionable context\n\n## Output\n\nSave as: `PRPs/working-memory/{feature-name}/.plan`\n\n## PRP Quality Gates\n\n### Context Completeness Check\n\n- [ ] Passes \"No Prior Knowledge\" test from template\n- [ ] All YAML references are specific and accessible\n- [ ] Implementation tasks include exact naming and placement guidance\n- [ ] Validation commands are project-specific and verified working\n\n### Template Structure Compliance\n\n- [ ] All required template sections completed\n- [ ] Goal section has specific Feature Goal, Deliverable, Success Definition\n- [ ] Implementation Tasks follow dependency ordering\n- [ ] Final Validation Checklist is comprehensive\n\n### Information Density Standards\n\n- [ ] No generic references - all are specific and actionable\n- [ ] File patterns point at specific examples to follow\n- [ ] URLs include section anchors for exact guidance\n- [ ] Task specifications use information-dense keywords from codebase\n\n## Success Metrics\n\n**Confidence Score**: Rate 1-10 for one-pass implementation success likelihood\n\n**Validation**: The completed PRP should enable an AI agent unfamiliar with the codebase to implement the feature successfully using only the PRP content and codebase access.\n"
              },
              {
                "name": "/prp-base-execute",
                "description": null,
                "path": "prp/commands/prp-base-execute.md",
                "frontmatter": null,
                "content": "# Execute BASE PRP\n\n## PRP File: $ARGUMENTS\n\n## Mission: One-Pass Implementation Success\n\nPRPs enable working code on the first attempt through:\n\n- **Context Completeness**: Everything needed, nothing guessed\n- **Progressive Validation**: 4-level gates catch errors early\n- **Pattern Consistency**: Follow existing codebase approaches\n- Read PRPs/README.md to understand PRP concepts\n\n**Your Goal**: Transform the PRP into working code that passes all validation gates.\n\n## Execution Process\n\n1. **Load PRP**\n   - Read the specified PRP file completely\n   - Absorb all context, patterns, requirements and gather codebase intelligence\n   - Use the provided documentation references and file patterns, consume the right documentation before the appropriate todo/task\n   - Trust the PRP's context and guidance - it's designed for one-pass success\n   - If needed do additional codebase exploration and research as needed\n\n2. **ULTRATHINK & Plan**\n   - Create comprehensive implementation plan following the PRP's task order\n   - Break down into clear todos using TodoWrite tool\n   - Use subagents for parallel work when beneficial (always create prp inspired prompts for subagents when used)\n   - Follow the patterns referenced in the PRP\n   - Use specific file paths, class names, and method signatures from PRP context\n   - Never guess - always verify the codebase patterns and examples referenced in the PRP yourself\n\n3. **Execute Implementation**\n   - Follow the PRP's Implementation Tasks sequence, add more detail as needed, especially when using subagents\n   - Use the patterns and examples referenced in the PRP\n   - Create files in locations specified by the desired codebase tree\n   - Apply naming conventions from the task specifications and CLAUDE.md\n\n4. **Progressive Validation**\n\n   **Execute the level validation system from the PRP:**\n   - **Level 1**: Run syntax & style validation commands from PRP\n   - **Level 2**: Execute unit test validation from PRP\n   - **Level 3**: Run integration testing commands from PRP\n   - **Level 4**: Execute specified validation from PRP\n\n   **Each level must pass before proceeding to the next.**\n\n5. **Completion Verification**\n   - Work through the Final Validation Checklist in the PRP\n   - Verify all Success Criteria from the \"What\" section are met\n   - Confirm all Anti-Patterns were avoided\n   - Implementation is ready and working\n\n**Failure Protocol**: When validation fails, use the patterns and gotchas from the PRP to fix issues, then re-run validation until passing.\n"
              },
              {
                "name": "/prp-planning-create",
                "description": null,
                "path": "prp/commands/prp-planning-create.md",
                "frontmatter": null,
                "content": "# Create PLANNING PRP (Advanced)\n\nTransform rough ideas into comprehensive PRDs with rich visual documentation.\n\n## Idea: $ARGUMENTS\n\n## Discovery Process\n\n1. **Concept Expansion**\n   - Break down the core idea\n   - Define success criteria\n   - Map to business goals if provided\n\n2. **Market & Technical Research**\n   - Do deep web search for the following:\n     - Market analysis\n     - Competitor analysis\n     - Technical feasibility study\n     - Best practice examples\n     - Integration possibilities\n\n3. **User Research & Clarification**\n     - Ask user for the following if not provided:\n     - Target user personas?\n     - Key pain points?\n     - Success metrics?\n     - Constraints/requirements?\n\n## PRD Generation\n\nUsing /PRPs/templates/prp_planning_base.md:\n\n### Visual Documentation Plan\n```yaml\ndiagrams_needed:\n  user_flows:\n    - Happy path journey\n    - Error scenarios\n    - Edge cases\n  \n  architecture:\n    - System components\n    - Data flow\n    - Integration points\n  \n  sequences:\n    - API interactions\n    - Event flows\n    - State changes\n  \n  data_models:\n    - Entity relationships\n    - Schema design\n    - State machines\n```\n\n### Research Integration\n- **Market Analysis**: Include findings in PRD\n- **Technical Options**: Compare approaches\n- **Risk Assessment**: With mitigation strategies\n- **Success Metrics**: Specific, measurable\n\n### User Story Development\n```markdown\n## Epic: [High-level feature]\n\n### Story 1: [User need]\n**As a** [user type]\n**I want** [capability]\n**So that** [benefit]\n\n**Acceptance Criteria:**\n- [ ] Specific behavior\n- [ ] Edge case handling\n- [ ] Performance requirement\n\n**Technical Notes:**\n- Implementation approach\n- API implications\n- Data requirements\n```\n\n### Implementation Strategy\n- Phases with dependencies (no dates)\n- Priority ordering\n- MVP vs enhanced features\n- Technical prerequisites\n\n## User Interaction Points\n\n1. **Idea Validation**\n   - Confirm understanding\n   - Clarify ambiguities\n   - Set boundaries\n\n2. **Research Review**\n   - Share findings\n   - Validate assumptions\n   - Adjust direction\n\n3. **PRD Draft Review**\n   - Architecture approval\n   - Risk acknowledgment\n   - Success metric agreement\n\n## Diagram Guidelines\n- Use Mermaid for all diagrams\n- Include legends where needed\n- Show error paths\n- Annotate complex flows\n\n## Output Structure\n```markdown\n1. Executive Summary\n2. Problem & Solution\n3. User Stories (with diagrams)\n4. Technical Architecture (with diagrams)\n5. API Specifications\n6. Data Models\n7. Implementation Phases\n8. Risks & Mitigations\n9. Success Metrics\n10. Appendices\n```\n\nSave as: `PRPs/working-memory/{feature-name}/{feature-name}-prd.md`\n\n## Quality Checklist\n- [ ] Problem clearly articulated\n- [ ] Solution addresses problem\n- [ ] All user flows diagrammed\n- [ ] Wireframes included if needed\n- [ ] Architecture visualized\n- [ ] APIs fully specified with examples\n- [ ] Data models included\n- [ ] Dependencies identified\n- [ ] Risks identified and mitigated\n- [ ] Success metrics measurable\n- [ ] Implementation phases logical\n- [ ] Ready for implementation PRP\n\nRemember: Great PRDs prevent implementation confusion."
              },
              {
                "name": "/prp-poc-create-parallel",
                "description": null,
                "path": "prp/commands/prp-poc-create-parallel.md",
                "frontmatter": null,
                "content": "# Create Parallel React POCs\n\n## Request: $ARGUMENTS\n\nUsage: `/prp-poc-create-parallel [number_of_demos] \"[problem_statement]\"`\nExample: `/prp-poc-create-parallel 5 \"create a dashboard for tracking team productivity with real-time metrics\"`\n\n## Parallel POC Creation Mission\n\nCreate multiple React POC variations simultaneously to **maximize concept validation** through diverse implementation approaches. This command generates PRPs for parallel execution using specialized UI/UX and User Journey agents.\n\n**Critical Understanding**: Each POC targets different aspects of the same problem:\n- Different UI/UX approaches (minimal, polished, experimental)\n- Different user journey focuses (power user, casual user, admin)\n- Different technical approaches (component-heavy, page-based, single-file)\n- Different fidelity levels (wireframe, demo, MVP)\n\n## Parallel Creation Strategy\n\n### Agent Specialization Pattern\n\nFor **N demos** requested, create **N pairs** of specialized agents:\n- **N UI-UX Agents**: Each focusing on different design approaches\n- **N User Journey Agents**: Each targeting different user personas/flows\n\n**Agent Assignment Matrix:**\n```yaml\nDemo 1: @ui-ux-agent (Minimal/Clean) + @user-journey-agent (Power User)\nDemo 2: @ui-ux-agent (Polished/Professional) + @user-journey-agent (Casual User) \nDemo 3: @ui-ux-agent (Experimental/Modern) + @user-journey-agent (Admin User)\nDemo 4: @ui-ux-agent (Dashboard-Heavy) + @user-journey-agent (Mobile-First)\nDemo 5: @ui-ux-agent (Component-Library) + @user-journey-agent (Accessibility-First)\n```\n\n### POC Variation Strategy\n\nEach POC should explore different aspects:\n\n**Design Variations:**\n- **Minimal**: Clean, simple, content-focused\n- **Polished**: Professional, brand-aligned, stakeholder-ready\n- **Experimental**: Modern patterns, micro-interactions, innovative UI\n- **Dashboard-Heavy**: Data visualization focused, charts/graphs\n- **Component-Library**: Showcases reusable design system components\n\n**User Journey Variations:**\n- **Power User**: Feature-rich, keyboard shortcuts, advanced workflows\n- **Casual User**: Simplified navigation, guided experiences, fewer options\n- **Admin User**: Management interfaces, bulk actions, system controls\n- **Mobile-First**: Touch-optimized, responsive, gesture-based\n- **Accessibility-First**: Screen reader optimized, keyboard navigation, high contrast\n\n## Implementation Process\n\n### Step 1: Problem Analysis & POC Strategy\n\nAnalyze the problem statement and create a **parallel execution plan**:\n\n1. **Parse Request Arguments**\n   - Extract number of demos requested (default: 5)\n   - Analyze problem statement for key concepts and requirements\n   - Identify core user personas and interaction patterns\n\n2. **Design POC Matrix**\n   - Create unique combination of UI approach + User journey for each demo\n   - Ensure each POC validates different aspects of the problem\n   - Plan directory structure: `poc-{problem-slug}-{variant-number}`\n\n### Step 2: Parallel Agent Research\n\n**Execute all research agents in PARALLEL using Task tool:**\n\n```yaml\n# Spawn N pairs of agents simultaneously\nTask 1 - @ui-ux-agent for Demo 1:\n\"Analyze the problem: '{problem_statement}' and design a MINIMAL/CLEAN UI approach.\nFocus on: Clean typography, generous whitespace, content-first design.\nResearch component patterns and create UI specifications for a React POC.\nTarget: Stakeholder presentations requiring clear concept demonstration.\nReturn: UI component architecture, styling approach, and design specifications.\"\n\nTask 2 - @user-journey-agent for Demo 1:\n\"Analyze the problem: '{problem_statement}' and design a POWER USER journey.\nFocus on: Advanced features, keyboard shortcuts, efficient workflows.\nResearch user patterns and create journey specifications for React POC.\nTarget: Users who need maximum functionality and control.\nReturn: User flow architecture, interaction patterns, and journey specifications.\"\n\nTask 3 - @ui-ux-agent for Demo 2:\n\"Analyze the problem: '{problem_statement}' and design a POLISHED/PROFESSIONAL UI approach.\nFocus on: Brand alignment, professional aesthetics, stakeholder-ready presentation.\nResearch premium component patterns and create UI specifications for React POC.\nTarget: Executive demos and client presentations.\nReturn: UI component architecture, styling approach, and design specifications.\"\n\nTask 4 - @user-journey-agent for Demo 2:\n\"Analyze the problem: '{problem_statement}' and design a CASUAL USER journey.\nFocus on: Simplified navigation, guided experiences, progressive disclosure.\nResearch beginner-friendly patterns and create journey specifications for React POC.\nTarget: Users new to the system who need guidance and simplicity.\nReturn: User flow architecture, interaction patterns, and journey specifications.\"\n\n# Continue pattern for remaining demos...\n```\n\n### Step 3: PRP Generation from Research\n\nAfter all research agents complete, **synthesize results into POC PRPs**:\n\n1. **Use prp_poc_react.md template** for each POC\n2. **Incorporate agent research** into context sections\n3. **Customize each PRP** based on UI/UX + User Journey specifications\n4. **Create unique identifiers** for parallel development\n\n### Step 4: POC Specification Matrix\n\nGenerate **N PRPs** with these variations:\n\n**POC 1: Minimal Power User**\n```yaml\npoc_name: \"poc-{problem-slug}-minimal-power\"\nui_approach: \"Clean, typography-focused, content-first design\"\nuser_journey: \"Advanced features, keyboard shortcuts, efficient workflows\"\nfidelity: \"Demo\"\nunique_aspects: \"Focuses on functionality over aesthetics, rapid interaction patterns\"\n```\n\n**POC 2: Polished Casual User**\n```yaml\npoc_name: \"poc-{problem-slug}-polished-casual\"\nui_approach: \"Professional aesthetics, brand-aligned, premium components\"\nuser_journey: \"Guided experience, progressive disclosure, help tooltips\"\nfidelity: \"MVP\"\nunique_aspects: \"Executive-ready presentation with beginner-friendly flows\"\n```\n\n**POC 3: Experimental Admin**\n```yaml\npoc_name: \"poc-{problem-slug}-experimental-admin\"\nui_approach: \"Modern patterns, micro-interactions, innovative UI elements\"\nuser_journey: \"Management interfaces, bulk actions, system administration\"\nfidelity: \"Demo\"\nunique_aspects: \"Cutting-edge design patterns with administrative power features\"\n```\n\n**POC 4: Dashboard Mobile-First**\n```yaml\npoc_name: \"poc-{problem-slug}-dashboard-mobile\"\nui_approach: \"Data visualization heavy, charts and metrics focused\"\nuser_journey: \"Touch-optimized interactions, responsive design, gesture-based\"\nfidelity: \"Demo\"\nunique_aspects: \"Analytics dashboard optimized for mobile devices\"\n```\n\n**POC 5: Component-Library Accessible**\n```yaml\npoc_name: \"poc-{problem-slug}-components-a11y\"\nui_approach: \"Design system showcase, reusable component patterns\"\nuser_journey: \"Screen reader optimized, keyboard navigation, inclusive design\"\nfidelity: \"MVP\"\nunique_aspects: \"Accessibility-first design with component library demonstration\"\n```\n\n## PRP Output Structure\n\nFor each POC, generate a complete PRP file:\n\n**File:** `PRPs/working-memory/{feature-name}/poc-{problem-slug}-{variant}.md`\n\n**Content Structure:**\n1. **Goal Section**: Specific to UI approach + User journey combination\n2. **POC Scope**: Tailored to the variation's unique focus\n3. **Context**: Incorporates both UI-UX and User Journey agent research\n4. **Implementation Blueprint**: Customized task sequence for the variant\n5. **Validation Loop**: POC-appropriate validation for the specific approach\n\n## Parallel Execution Preparation\n\n### Project Structure Setup\n\n```\nreact-poc-project/\n├── public/\n├── src/\n│   ├── poc-{problem-slug}-minimal-power/\n│   ├── poc-{problem-slug}-polished-casual/\n│   ├── poc-{problem-slug}-experimental-admin/\n│   ├── poc-{problem-slug}-dashboard-mobile/\n│   ├── poc-{problem-slug}-components-a11y/\n│   └── App.tsx  # Main navigation between POCs\n├── package.json\n└── README.md\n```\n\n### Main App Navigation\n\nEach POC should be accessible from a main navigation page:\n\n```tsx\n// App.tsx structure\nfunction App() {\n  return (\n    <Router>\n      <Routes>\n        <Route path=\"/\" element={<POCNavigationHub />} />\n        <Route path=\"/minimal-power\" element={<POCMinimalPower />} />\n        <Route path=\"/polished-casual\" element={<POCPolishedCasual />} />\n        <Route path=\"/experimental-admin\" element={<POCExperimentalAdmin />} />\n        <Route path=\"/dashboard-mobile\" element={<POCDashboardMobile />} />\n        <Route path=\"/components-a11y\" element={<POCComponentsA11y />} />\n      </Routes>\n    </Router>\n  )\n}\n```\n\n## Success Criteria\n\n### Research Quality\n- [ ] **All agent pairs completed**: N UI-UX + N User Journey agents finished successfully\n- [ ] **Diverse approaches identified**: Each POC targets different aspects of problem\n- [ ] **Research synthesis complete**: Agent findings incorporated into PRP context\n- [ ] **Unique value propositions**: Each POC validates different assumptions\n\n### PRP Quality\n- [ ] **N complete PRPs generated**: One for each POC variation\n- [ ] **Context completeness**: Each PRP enables one-pass implementation\n- [ ] **Validation approaches**: POC-appropriate testing for each variant\n- [ ] **Implementation clarity**: Clear task sequences for parallel development\n\n### Parallel Readiness\n- [ ] **Unique naming**: All POCs have distinct identifiers and directories\n- [ ] **Isolated development**: POCs can be developed simultaneously without conflicts\n- [ ] **Shared infrastructure**: Common mock data and routing setup defined\n- [ ] **Execution ready**: All PRPs ready for parallel execution command\n\n## Anti-Patterns\n\n### Research Anti-Patterns\n- ❌ **Don't create identical approaches**: Ensure each POC explores different aspects\n- ❌ **Don't skip agent specialization**: Each agent should have distinct focus\n- ❌ **Don't generalize findings**: Customize context for each POC's unique approach\n- ❌ **Don't rush parallel research**: Let all agents complete before synthesis\n\n### PRP Generation Anti-Patterns\n- ❌ **Don't copy-paste PRPs**: Each should be tailored to its unique approach\n- ❌ **Don't ignore agent research**: Incorporate all findings into appropriate PRPs\n- ❌ **Don't create conflicting requirements**: Ensure POCs can coexist in same project\n- ❌ **Don't skip validation customization**: Each POC needs appropriate testing approach\n\n### DO Focus On\n- ✅ **Maximum concept coverage**: Each POC validates different aspects of the problem\n- ✅ **Specialized agent research**: Leverage UI-UX and User Journey expertise fully\n- ✅ **Parallel development readiness**: Structure for simultaneous implementation\n- ✅ **Stakeholder value**: Each POC provides unique insights for decision making\n\n---\n\n**Remember**: The goal is **comprehensive concept validation** through **diverse parallel approaches**. Each POC should explore the problem from a different angle, maximizing the insights available to stakeholders for informed decision-making."
              },
              {
                "name": "/prp-poc-execute-parallel",
                "description": null,
                "path": "prp/commands/prp-poc-execute-parallel.md",
                "frontmatter": null,
                "content": "# Execute Parallel React POCs\n\n## POC Directory: $ARGUMENTS\n\nUsage: `/prp-poc-execute-parallel [poc_directory_pattern]`\nExample: `/prp-poc-execute-parallel \"PRPs/poc-dashboard-*\"`\n\n## Mission: Parallel POC Implementation Success\n\nTransform multiple React POC PRPs into working demonstrations simultaneously through **coordinated parallel execution** using specialized UI/UX and User Journey agents.\n\n**Critical Understanding**: Each POC requires specialized execution:\n- **UI-focused implementation** leveraging @ui-ux-agent expertise\n- **User journey validation** using @user-journey-agent insights  \n- **Parallel development** without interference between POCs\n- **Coordinated validation** ensuring all POCs demonstrate successfully\n\n## Parallel Execution Strategy\n\n### Agent Orchestration Pattern\n\nFor **N POCs** discovered, create **N execution pairs**:\n- **N UI-UX Implementation Agents**: Each building the specific UI approach\n- **N User Journey Validation Agents**: Each ensuring journey flows work correctly\n\n**Execution Agent Assignment:**\n```yaml\nPOC 1: @ui-ux-agent (Build minimal/clean interface) + @user-journey-agent (Validate power user flows)\nPOC 2: @ui-ux-agent (Build polished/professional interface) + @user-journey-agent (Validate casual user flows)\nPOC 3: @ui-ux-agent (Build experimental/modern interface) + @user-journey-agent (Validate admin user flows)\nPOC 4: @ui-ux-agent (Build dashboard/data-heavy interface) + @user-journey-agent (Validate mobile-first flows)\nPOC 5: @ui-ux-agent (Build component-library interface) + @user-journey-agent (Validate accessibility flows)\n```\n\n## Pre-Execution Setup\n\n### Step 1: Environment Preparation\n\n1. **Create Fresh React Project**\n   ```bash\n   npx create-react-app react-poc-demos --template typescript\n   cd react-poc-demos\n   npm install react-router-dom @faker-js/faker msw\n   npm install -D @types/react-router-dom\n   ```\n\n2. **Discover POC PRPs**\n   - Scan for POC PRP files matching the pattern\n   - Extract POC specifications and requirements\n   - Plan directory structure and routing\n\n3. **Setup Project Structure**\n   ```\n   src/\n   ├── components/\n   │   └── shared/        # Shared components across POCs\n   ├── data/\n   │   └── mocks/         # Shared mock data\n   ├── poc-{name}-{variant}/\n   │   ├── components/    # POC-specific components\n   │   ├── pages/         # POC-specific pages\n   │   ├── hooks/         # POC-specific hooks\n   │   └── styles/        # POC-specific styles\n   └── App.tsx           # Main navigation hub\n   ```\n\n## Parallel Implementation Process\n\n### Step 2: Simultaneous POC Development\n\n**Execute all implementation pairs in PARALLEL using Task tool:**\n\n```yaml\n# For each discovered POC, spawn specialized agent pair\nTask 1 - @ui-ux-agent Implementation for POC 1:\n\"Read and implement PRP: 'PRPs/working-memory/{feature-name}/poc-{name}-{variant1}.md'\nFocus on: Building the UI components and styling specified in the PRP.\nRequirements:\n- Follow the UI approach defined in the PRP context\n- Implement all components with TypeScript interfaces\n- Apply the styling approach (minimal/clean as specified)\n- Create responsive layouts following the PRP requirements\n- Use mock data integration as specified\nDirectory: src/poc-{name}-{variant1}/\nReturn: Complete UI implementation with all components functional\"\n\nTask 2 - @user-journey-agent Validation for POC 1:\n\"Read and validate PRP implementation: 'PRPs/working-memory/{feature-name}/poc-{name}-{variant1}.md'\nFocus on: Ensuring user journey flows work as specified in the PRP.\nRequirements:\n- Test all user interactions defined in the PRP\n- Validate navigation flows and state management\n- Ensure mock data scenarios cover user journey requirements\n- Test user flow completion from start to finish\n- Document any journey friction points discovered\nDirectory: src/poc-{name}-{variant1}/\nReturn: Journey validation report and any flow improvements needed\"\n\nTask 3 - @ui-ux-agent Implementation for POC 2:\n\"Read and implement PRP: 'PRPs/working-memory/{feature-name}/poc-{name}-{variant2}.md'\nFocus on: Building the UI components and styling specified in the PRP.\nRequirements:\n- Follow the UI approach defined in the PRP context (polished/professional)\n- Implement all components with premium aesthetics\n- Create brand-aligned styling and professional presentation\n- Build stakeholder-ready demonstration interface\n- Integrate realistic mock data for presentations\nDirectory: src/poc-{name}-{variant2}/\nReturn: Complete UI implementation with professional polish\"\n\nTask 4 - @user-journey-agent Validation for POC 2:\n\"Read and validate PRP implementation: 'PRPs/working-memory/{feature-name}/poc-{name}-{variant2}.md'\nFocus on: Ensuring casual user journey flows work intuitively.\nRequirements:\n- Test simplified navigation and guided experiences\n- Validate progressive disclosure and help systems\n- Ensure beginner-friendly interaction patterns work\n- Test complete user onboarding and guidance flows\n- Document usability for non-expert users\nDirectory: src/poc-{name}-{variant2}/\nReturn: Casual user validation report and usability assessment\"\n\n# Continue pattern for all discovered POCs...\n```\n\n### Step 3: Main Navigation Implementation\n\n**After all POCs are built, create navigation hub:**\n\n```typescript\n// App.tsx - Main navigation between POCs\nimport React from 'react'\nimport { BrowserRouter as Router, Routes, Route } from 'react-router-dom'\nimport POCNavigationHub from './components/POCNavigationHub'\n\n// Import all POC entry points (generated dynamically based on discovered POCs)\nconst pocRoutes = [\n  { path: '/poc-1', component: lazy(() => import('./poc-{name}-{variant1}/pages/Demo')), title: 'Minimal Power User' },\n  { path: '/poc-2', component: lazy(() => import('./poc-{name}-{variant2}/pages/Demo')), title: 'Polished Casual User' },\n  // ... additional routes for all POCs\n]\n\nfunction App() {\n  return (\n    <Router>\n      <Routes>\n        <Route path=\"/\" element={<POCNavigationHub pocs={pocRoutes} />} />\n        {pocRoutes.map(({ path, component: Component }) => (\n          <Route key={path} path={path} element={<Suspense><Component /></Suspense>} />\n        ))}\n      </Routes>\n    </Router>\n  )\n}\n```\n\n### Step 4: Coordinated Validation\n\n**Execute validation for all POCs simultaneously:**\n\n1. **Technical Validation (All POCs)**\n   ```bash\n   npm run lint          # All POCs pass linting\n   npm run type-check    # All TypeScript errors resolved\n   npm run build         # Production build succeeds\n   npm run test          # All POC smoke tests pass\n   ```\n\n2. **Functional Validation (Per POC)**\n   - Each POC loads without errors\n   - Core user journeys navigable in each POC\n   - Mock data displays correctly in all variations\n   - Navigation between POCs works seamlessly\n\n3. **User Journey Validation (Agent-Specific)**\n   - Power user flows efficient and feature-complete\n   - Casual user flows intuitive and guided\n   - Admin flows comprehensive and control-focused  \n   - Mobile flows touch-optimized and responsive\n   - Accessibility flows screen reader compatible\n\n## Coordination & Conflict Resolution\n\n### Step 5: Integration Management\n\n1. **Shared Resource Coordination**\n   - Merge shared mock data without conflicts\n   - Resolve common component naming conflicts\n   - Integrate shared utilities and hooks\n   - Coordinate routing and navigation structure\n\n2. **Style Isolation**\n   - Ensure POC-specific styles don't interfere\n   - Use CSS modules or styled-components for isolation\n   - Coordinate shared design system tokens\n   - Resolve competing global styles\n\n3. **Dependency Management**\n   - Consolidate common dependencies\n   - Resolve version conflicts between POC requirements\n   - Optimize bundle size across all POCs\n   - Manage shared vs POC-specific packages\n\n## Final Validation & Demo Preparation\n\n### Step 6: Comprehensive Testing\n\n**Multi-POC Validation Checklist:**\n\n**Technical Completeness:**\n- [ ] **All POCs Build Successfully**: No TypeScript or build errors across any POC\n- [ ] **Shared Infrastructure Works**: Navigation, routing, shared components functional\n- [ ] **Isolated Functionality**: Each POC operates independently without interference\n- [ ] **Performance Acceptable**: All POCs load and perform adequately for demos\n\n**Feature Completeness:**\n- [ ] **All User Journeys Complete**: Each POC's primary user flow works end-to-end\n- [ ] **Specialized Approaches Visible**: Unique value propositions clear in each POC\n- [ ] **Mock Data Realistic**: All POCs display meaningful, realistic data scenarios\n- [ ] **Cross-POC Navigation**: Users can move between different POC approaches easily\n\n**Business Validation:**\n- [ ] **Concept Differentiation Clear**: Each POC explores different aspects of the problem\n- [ ] **Stakeholder Demo Ready**: All POCs ready for comparative evaluation\n- [ ] **Findings Documentation**: Each POC's insights and limitations documented\n- [ ] **Next Steps Identified**: Production recommendations available for each approach\n\n### Step 7: Demo Script Preparation\n\n**Create demonstration script for stakeholder presentations:**\n\n```markdown\n# POC Demonstration Script\n\n## Introduction (2 minutes)\n- Problem statement overview\n- POC approach explanation\n- Navigation between different solutions\n\n## POC 1: Minimal Power User (3 minutes)\n- Target audience: Expert users needing efficiency\n- Key features demonstration\n- Performance and workflow benefits\n\n## POC 2: Polished Casual User (3 minutes)\n- Target audience: General users needing guidance\n- Guided experience demonstration\n- Ease of use and accessibility benefits\n\n## POC 3: Experimental Admin (3 minutes)\n- Target audience: System administrators\n- Advanced controls demonstration\n- Management and oversight capabilities\n\n## POC 4: Dashboard Mobile-First (3 minutes)\n- Target audience: Mobile-centric users\n- Data visualization demonstration\n- Touch interaction and responsive benefits\n\n## POC 5: Component-Library Accessible (3 minutes)\n- Target audience: Inclusive design requirements\n- Accessibility features demonstration\n- Design system and consistency benefits\n\n## Comparison & Recommendations (5 minutes)\n- Side-by-side feature comparison\n- User feedback integration\n- Production implementation recommendations\n```\n\n## Success Metrics\n\n### Implementation Success\n- [ ] **All POCs Functional**: Every discovered PRP implemented successfully\n- [ ] **Agent Specialization Effective**: UI-UX and User Journey agents delivered specialized results\n- [ ] **Parallel Development Efficient**: No conflicts or interference between concurrent implementations  \n- [ ] **Validation Complete**: All POCs pass technical and functional validation\n\n### Business Value Delivery\n- [ ] **Comprehensive Concept Coverage**: Problem explored from multiple angles successfully\n- [ ] **Clear Differentiation**: Each POC's unique value proposition demonstrated\n- [ ] **Stakeholder Ready**: All POCs ready for evaluation and feedback gathering\n- [ ] **Decision Support**: Sufficient information available for production approach selection\n\n## Error Handling & Recovery\n\n### Common Issues & Solutions\n\n**Build Conflicts:**\n- Isolate POC-specific dependencies\n- Use namespace prefixes for shared utilities\n- Implement CSS-in-JS for style isolation\n\n**Agent Coordination Issues:**\n- Re-assign failed implementations to backup agents\n- Merge partial implementations when agents complete successfully\n- Prioritize critical POCs if time constraints emerge\n\n**Performance Issues:**\n- Lazy load POC components to improve initial page load\n- Optimize shared mock data generation\n- Implement code splitting at POC boundaries\n\n## Anti-Patterns\n\n### Execution Anti-Patterns\n- ❌ **Don't execute POCs sequentially**: Use parallel agent execution always\n- ❌ **Don't ignore agent specialization**: UI-UX and User Journey agents have distinct roles\n- ❌ **Don't rush validation**: Each POC needs proper testing and verification\n- ❌ **Don't skip integration testing**: Cross-POC navigation and shared resources need validation\n\n### Coordination Anti-Patterns  \n- ❌ **Don't allow POC interference**: Maintain isolation between implementations\n- ❌ **Don't duplicate shared logic**: Coordinate common utilities and mock data\n- ❌ **Don't ignore conflicts**: Resolve dependency and styling conflicts early\n- ❌ **Don't skip demo preparation**: Stakeholder presentation needs coordination\n\n### DO Focus On\n- ✅ **Specialized agent utilization**: Leverage UI-UX and User Journey expertise fully\n- ✅ **Parallel execution efficiency**: Maximum development speed through coordination\n- ✅ **Cross-POC consistency**: Shared infrastructure and navigation experience\n- ✅ **Business value delivery**: Each POC provides unique insights for decision making\n\n---\n\n**Remember**: The goal is **successful parallel implementation** of multiple POC approaches that collectively provide **comprehensive concept validation** for stakeholder decision-making."
              },
              {
                "name": "/prp-spec-create",
                "description": null,
                "path": "prp/commands/prp-spec-create.md",
                "frontmatter": null,
                "content": "# Create SPEC PRP (Advanced)\n\nGenerate a comprehensive specification-driven PRP with clear transformation goals.\n\n## Specification: $ARGUMENTS\n\n## Analysis Process\n\n1. **Current State Assessment**\n   - Map existing implementation\n   - Identify pain points\n   - Document technical debt\n   - Note integration points\n\n2. **Desired State Research**\n   - Best practices for target state\n   - Implementation examples\n   - Migration strategies\n   - Risk assessment\n   - Dependency mapping\n\n3. **User Clarification**\n   - Confirm transformation goals\n   - Priority of objectives\n   - Acceptable trade-offs\n\n## PRP Generation\n\nUsing /PRPs/templates/prp_spec.md:\n\n### State Documentation\n\n```yaml\ncurrent_state:\n  files: [list affected files]\n  behavior: [how it works now]\n  issues: [specific problems]\n\ndesired_state:\n  files: [expected structure]\n  behavior: [target functionality]\n  benefits: [improvements gained]\n```\n\n### Hierarchical Objectives\n\n1. **High-Level**: Overall transformation goal\n2. **Mid-Level**: Major milestones\n3. **Low-Level**: Specific tasks with validation\n\n### Task Specification with information dense keywords\n\n#### Information dense keywords:\n\n- MIRROR: Mirror the state of existing code to be mirrored to another use case\n- COPY: Copy the state of existing code to be copied to another use case\n- ADD: Add new code to the codebase\n- MODIFY: Modify existing code\n- DELETE: Delete existing code\n- RENAME: Rename existing code\n- MOVE: Move existing code\n- REPLACE: Replace existing code\n- CREATE: Create new code\n\n#### Example:\n\n```yaml\ntask_name:\n  action: MODIFY/CREATE\n  file: path/to/file\n  changes: |\n    - Specific modifications\n    - Implementation details\n    - With clear markers\n  validation:\n    - command: \"test command\"\n    - expect: \"success criteria\"\n```\n\n### Implementation Strategy\n\n- Identify dependencies\n- Order tasks by priority and implementation order and dependencies logic\n- Include rollback plans\n- Progressive enhancement\n\n## User Interaction Points\n\n1. **Objective Validation**\n   - Review hierarchical breakdown\n   - Confirm priorities\n   - Identify missing pieces\n\n2. **Risk Review**\n   - Document identified risks\n   - Find mitigations\n   - Set go/no-go criteria\n\n## Context Requirements\n\n- Current implementation details\n- Target architecture examples\n- Migration best practices\n- Testing strategies\n\n## Output\n\nSave as: `SPEC_PRP/PRPs/{spec-name}.md`\n\n## Quality Checklist\n\n- [ ] Current state fully documented\n- [ ] Desired state clearly defined\n- [ ] All objectives measurable\n- [ ] Tasks ordered by dependency\n- [ ] Each task has validation that AI can run\n- [ ] Risks identified with mitigations\n- [ ] Rollback strategy included\n- [ ] Integration points noted\n\nRemember: Focus on the transformation journey, not just the destination.\n"
              },
              {
                "name": "/prp-spec-execute",
                "description": null,
                "path": "prp/commands/prp-spec-execute.md",
                "frontmatter": null,
                "content": "# Execute SPEC PRP\n\nImplement a specification using an existing SPEC PRP.\n\n## PRP File: $ARGUMENTS\n\n## Execution Process\n\n1. **Understand Spec**\n   - Current state analysis\n   - Desired state goals\n   - Task dependencies\n\n2. **ULTRATHINK**\n   - Think hard before you execute the plan. Create a comprehensive plan addressing all requirements.\n   - Break down complex tasks into smaller, manageable steps using your todos tools.\n   - Use the TodoWrite tool to create and track your implementation plan.\n   - Identify implementation patterns from existing code to follow.\n\n3. **Execute Tasks**\n   - Follow task order\n   - Run validation after each\n   - Fix failures before proceeding\n\n4. **Verify Transformation**\n   - Confirm desired state achieved\n   - Run all validation gates\n   - Test integration\n\nProgress through each objective systematically."
              },
              {
                "name": "/prp-story-create",
                "description": "Convert user story/task into executable PRP with deep codebase analysis",
                "path": "prp/commands/prp-story-create.md",
                "frontmatter": {
                  "description": "Convert user story/task into executable PRP with deep codebase analysis"
                },
                "content": "# Create Story PRP from User Story/Task\n\n## Story/Task: $ARGUMENTS\n\n## Mission\n\nTransform a user story or task into a **tactical implementation PRP** through systematic codebase analysis and task decomposition.\n\nWe do not write any code in this step, the goal is to create a detailed context engineered implementation plan for the implementation agent.\n\n**Key Principle**: We must first gather the context about the story/task before proceeding with the analysis.\n\nWhen we understand the story/task, we can proceed with the codebase analysis. We systematically dig deep into the codebase to gather intelligence and identify patterns and implementation points. We then use this information to create a PRP that can be executed by a coding agent.\n\nThe contents of the created PRP should encapsulate all the information the agent needs to complete the story/task in one pass.\n\nRemember that subagents will only receive their details from you, the user has no way of interacting with the subagents. so you need to share all the relevant context to the subagent in the subagent prompt and in the TODO that is shared with the particular agent.\n\nCreate detailed todos and spawn parallel subagents to analyze (Use specialized subagents when apropriate):\n\n## Analysis Process\n\n### Phase 1: Story Decomposition\n\nAnalyze the story to determine:\n\n- **Story/Task Type**: Feature/Bug/Enhancement/Refactor\n- **Complexity**: Low, Medium, High\n- **Affected Systems**: Which components/services need changes\n\nGet a deep understanding about the story/task before proceeding so that you can effectively guide the rest of the process.\n\n### Phase 2: Codebase Intelligence Gathering\n\n**1. Project Structure Analysis**\n\n- Detect primary language(s) and frameworks\n- Map directory structure and conventions to identify integration points for the story/task\n- Identify service/component boundaries\n- Find configuration files and environment setup\n\n**2. Pattern Recognition**\n\n- Search for similar implementations in codebase\n- Identify coding conventions (naming, structure, error handling) start in CLAUDE.md AGENTS.md or relevant rules files such as .cursorrules\n- Extract common patterns for the story's domain that should be added to the PRP as context for the implementation agent.\n- Note anti-patterns to avoid\n\n**3. Dependency Analysis**\n\n- Catalog external libraries used if relevant to the story/task (check package.json, pyproject.toml, go.mod, etc.)\n- Understand how libraries are integrated\n- Find relevant documentation in PRPs/ai_docs/ if shared, ai_docs directory is used by the user to paste in relevant additional context that may be relevant to our story/task\n\n**4. Testing Patterns**\n\n- Identify test framework and structure\n- Find similar test examples and test setup\n- Suggest test cases and scenarios\n\n**5. Integration Points**\n\n- Identify files that will need updates\n- Identify if new files needs to be created and where to create them\n- Find router/API registration patterns\n- Understand database/model patterns if relevant\n\n### Phase 3: Think harder about the story and its components.\n\nReally think hard about everything you just learned during the research phases.\n\n### Phase 4: PRP Task Generation\n\nTransform analysis into concrete tasks:\n\nRead and understand the template @PRPs/templates/prp_story_task.md\n\n**Task Rules**:\n\n1. Each task is atomic and independently testable\n2. Tasks are ordered by dependency\n3. Use action verbs that are information dense: CREATE, UPDATE, ADD, REMOVE, REFACTOR, MIRROR\n4. Include specific implementation details from codebase analysis\n5. Every task has an executable validation command\n\n**Task Action Types**:\n\nWe use the concept of information dense keywords to describe the action to be taken, below is a guidance.\nBut you can use your own words to describe the action to be taken as long as you follow this same principle.\n\nExamples:\n\n- **CREATE**: New files/components\n- **UPDATE**: Modify existing files\n- **ADD**: Insert new functionality into existing code\n- **REMOVE**: Delete deprecated code\n- **REFACTOR**: Restructure without changing behavior\n- **MIRROR**: Mirror existing pattern or functionality that exists elsewhere in the codebase\n\n### Phase 5: Validation Design\n\nFor each task, design validation that:\n\n- Can run immediately after task completion\n- Provides clear pass/fail feedback\n- Uses project-specific commands discovered in analysis\n\n## Quality Criteria\n\n### Task Clarity\n\n- [ ] The PRP is clear and concise and follows KISS principle\n- [ ] Each task has clear action and target\n- [ ] Implementation details reference specific patterns\n- [ ] Validation commands are executable\n\n### Context Completeness\n\n- [ ] All necessary patterns identified\n- [ ] External library usage documented\n- [ ] Integration points mapped\n- [ ] External context references populated\n\n### Story Coverage\n\n- [ ] All acceptance criteria addressed\n- [ ] Edge cases considered\n- [ ] Error handling included where needed\n\n## Output\n\nSave as: `PRPs/working-memory/{feature-name}/story_{kebab-case-summary}.md`\n\n## Success Metrics\n\n**Implementation Ready**: Another developer could execute these tasks without additional context\n**Validation Complete**: Every task has atleast one working validation command\n**Pattern Consistent**: Tasks follow existing codebase conventions"
              },
              {
                "name": "/prp-story-execute",
                "description": "Execute a Story PRP with focused task implementation",
                "path": "prp/commands/prp-story-execute.md",
                "frontmatter": {
                  "description": "Execute a Story PRP with focused task implementation"
                },
                "content": "# Execute Story PRP\n\n## PRP File: $ARGUMENTS\n\n## Mission\n\nExecute a story/task PRP through **sequential task completion** with immediate validation.\n\n**Execution Philosophy**: Complete one task, validate it, then move to the next. No task left behind.\n\n## Execution Process\n\n### 1. Load Story PRP\n\n- Read the specified story PRP file\n- Understand the original story intent\n- Review all context references\n- Note validation commands for each task\n\n### 2. Pre-Implementation Check\n\n- Ultrathink about the story intent and task requirements\n- Verify all referenced files exist\n- Check that patterns mentioned are accessible\n- Ensure development environment is ready\n- Run any pre-requisite setup commands\n\n### 3. Task-by-Task Implementation\n\nFor each task in the PRP:\n\n**a) Understand Task**\n\n- Read task requirements completely\n- Review referenced patterns\n- Check gotchas and constraints\n\n**b) Implement Task**\n\n- Follow the specified pattern\n- Use the indicated naming conventions\n- Apply the documented approach\n- Handle edge cases mentioned\n\n**c) Validate Immediately**\n\n- Run the task's validation command\n- If validation fails, fix and re-validate\n- Don't proceed until current task passes\n\n**d) Mark Complete**\n\n- Update todo list to track progress\n- Document any deviations if necessary\n\n### 4. Full Validation\n\nAfter all tasks complete:\n\n- Run the validation gates from PRP\n- Execute comprehensive test suite\n- Verify all acceptance criteria met\n\n### 5. Completion\n\n- Work through completion checklist\n- Ensure story requirements satisfied\n- Move completed PRP to PRPs/completed/{feature-name}/ create the folder if it does not exist\n\n## Execution Rules\n\n**Validation Gates**: Each task must pass validation, iterate until passed\n**Pattern Adherence**: Follow existing patterns, don't create new ones\n**No Shortcuts**: Complete all validation steps\n\n## Failure Handling\n\nWhen a task fails validation:\n\n1. Read the error message carefully\n2. Check the pattern reference again\n3. Validate it by investigating the codebase\n4. Fix and re-validate\n5. If stuck, check similar implementations\n\n## Success Criteria\n\n- Every validation command passes\n- Full test suite green\n- Story acceptance criteria met\n- Code follows project conventions"
              },
              {
                "name": "/prp-task-create",
                "description": null,
                "path": "prp/commands/prp-task-create.md",
                "frontmatter": null,
                "content": "# Create TASK PRP (Advanced)\n\nGenerate a comprehensive task list for focused changes with validation.\n\n## Task: $ARGUMENTS\n\n## Analysis Process\n\n1. **Scope Definition**\n   - Identify all affected files\n   - Map dependencies\n   - Check for side effects\n   - Note test coverage\n\n2. **Pattern Research**\n   - Find similar changes in history\n   - Identify conventions to follow\n   - Check for helper functions\n   - Review test patterns\n\n3. **User Clarification**\n   - Confirm change scope\n   - Verify acceptance criteria\n   - Check deployment considerations\n   - Identify blockers\n\n## PRP Generation\n\n**READ**\nUsing TASK_PRP/PRPs/prp_task.md format:\n\n### Context Section\n\n```yaml\ncontext:\n  docs:\n    - url: [API documentation]\n      focus: [specific methods]\n\n  patterns:\n    - file: existing/example.py\n      copy: [pattern to follow]\n\n  gotchas:\n    - issue: \"Library requires X\"\n      fix: \"Always do Y first\"\n```\n\n### Task Structure\n\n```\nACTION path/to/file:\n  - OPERATION: [specific change]\n  - VALIDATE: [test command]\n  - IF_FAIL: [debug strategy]\n  - ROLLBACK: [undo approach]\n```\n\n### Task Sequencing\n\n1. **Setup Tasks**: Prerequisites\n2. **Core Changes**: Main modifications\n3. **Integration**: Connect components\n4. **Validation**: Comprehensive tests\n5. **Cleanup**: Remove temp code\n\n### Validation Strategy\n\n- Unit test after each change\n- Integration test after groups\n- Performance check if relevant\n- Security scan for sensitive areas\n\n## User Interaction Points\n\n1. **Task Review**\n   - Confirm task breakdown\n   - Validate sequencing\n   - Check completeness\n\n2. **Risk Assessment**\n   - Review potential impacts\n   - Confirm rollback approach\n   - Set success criteria\n\n## Critical Elements\n\n- Include debug patterns\n- Add performance checks\n- Note security concerns\n- Document assumptions\n\n## Output\n\nSave as: `TASK_PRP/PRPs/working-memory/{feature-name}/{task-name}.md`\n\n## Quality Checklist\n\n- [ ] All changes identified\n- [ ] Dependencies mapped\n- [ ] Each task has validation\n- [ ] Rollback steps included\n- [ ] Debug strategies provided\n- [ ] Performance impact noted\n- [ ] Security checked\n- [ ] No missing edge cases\n\nRemember: Small, focused changes with immediate validation.\n"
              },
              {
                "name": "/prp-task-execute",
                "description": null,
                "path": "prp/commands/prp-task-execute.md",
                "frontmatter": null,
                "content": "# Execute TASK PRP\n\nRun through a task list from an existing TASK PRP.\n\n## PRP File: $ARGUMENTS\n\n## Execution Process\n\n1. **Load Tasks**\n   - Read task list\n   - Understand context\n\n2. **Execute Each Task**\n   - Perform ACTION\n   - Run VALIDATE\n   - Fix IF_FAIL issues\n\n3. **Complete Checklist**\n   - Verify all tasks done\n   - Run final validation\n   - Check no regressions\n\nWork through tasks sequentially, validating each.\n"
              },
              {
                "name": "/prp-ts-create",
                "description": null,
                "path": "prp/commands/prp-ts-create.md",
                "frontmatter": null,
                "content": "# Create TypeScript PRP\n\n## Feature: $ARGUMENTS\n\n## PRP Creation Mission\n\nCreate a comprehensive TypeScript PRP that enables **one-pass implementation success** through systematic research and context curation.\n\n**Critical Understanding**: The executing AI agent only receives:\n\n- Start by reading and understanding the prp concepts PRPs/README.md\n- The PRP content you create\n- Its training data knowledge\n- Access to codebase files (but needs guidance on which ones)\n\n**Therefore**: Your research and context curation directly determines implementation success. Incomplete context = implementation failure.\n\n## Research Process\n\n> During the research process, create clear tasks and spawn as many agents and subagents as needed using the batch tools. The deeper research we do here the better the PRP will be. we optminize for chance of success and not for speed.\n\n1. **TypeScript/React Codebase Analysis in depth**\n   - Create clear todos and spawn subagents to search the codebase for similar features/patterns Think hard and plan your approach\n   - Identify all the necessary TypeScript files to reference in the PRP\n   - Note all existing TypeScript/React conventions to follow\n   - Check existing component patterns, hook patterns, and API route patterns\n   - Analyze TypeScript interface definitions and type usage patterns\n   - Check existing test patterns for React components and TypeScript code validation approach\n   - Use the batch tools to spawn subagents to search the codebase for similar features/patterns\n\n2. **TypeScript/React External Research at scale**\n   - Create clear todos and spawn with instructions subagents to do deep research for similar features/patterns online and include urls to documentation and examples\n   - TypeScript documentation (include specific URLs with version compatibility)\n   - React/Next.js documentation (include specific URLs for App Router, Server Components, etc.)\n   - For critical pieces of documentation add a .md file to PRPs/ai_docs and reference it in the PRP with clear reasoning and instructions\n   - Implementation examples (GitHub/StackOverflow/blogs) specific to TypeScript/React/Next.js\n   - Best practices and common pitfalls found during research (TypeScript compilation issues, React hydration, Next.js gotchas)\n   - Use the batch tools to spawn subagents to search for similar features/patterns online and include urls to documentation and examples\n\n3. **User Clarification**\n   - Ask for clarification if you need it\n\n## PRP Generation Process\n\n### Step 1: Choose Template\n\nUse `PRPs/templates/prp_base_typescript.md` as your template structure - it contains all necessary sections and formatting specific to TypeScript/React development.\n\n### Step 2: Context Completeness Validation\n\nBefore writing, apply the **\"No Prior Knowledge\" test** from the template:\n_\"If someone knew nothing about this TypeScript/React codebase, would they have everything needed to implement this successfully?\"_\n\n### Step 3: Research Integration\n\nTransform your research findings into the template sections:\n\n**Goal Section**: Use research to define specific, measurable Feature Goal and concrete Deliverable (component, API route, integration, etc.)\n**Context Section**: Populate YAML structure with your research findings - specific TypeScript/React URLs, file patterns, gotchas\n**Implementation Tasks**: Create dependency-ordered tasks using information-dense keywords from TypeScript/React codebase analysis\n**Validation Gates**: Use TypeScript/React-specific validation commands that you've verified work in this codebase\n\n### Step 4: TypeScript/React Information Density Standards\n\nEnsure every reference is **specific and actionable** for TypeScript development:\n\n- URLs include section anchors, not just domain names (React docs, TypeScript handbook, Next.js docs)\n- File references include specific TypeScript patterns to follow (interfaces, component props, hook patterns)\n- Task specifications include exact TypeScript naming conventions and placement (PascalCase components, camelCase props, etc.)\n- Validation commands are TypeScript/React-specific and executable (tsc, eslint with TypeScript rules, React Testing Library)\n\n### Step 5: ULTRATHINK Before Writing\n\nAfter research completion, create comprehensive PRP writing plan using TodoWrite tool:\n\n- Plan how to structure each template section with your TypeScript/React research findings\n- Identify gaps that need additional TypeScript/React research\n- Create systematic approach to filling template with actionable TypeScript context\n- Consider TypeScript compilation dependencies and React component hierarchies\n\n## Output\n\nSave as: `PRPs/{feature-name}.md`\n\n## TypeScript PRP Quality Gates\n\n### Context Completeness Check\n\n- [ ] Passes \"No Prior Knowledge\" test from TypeScript template\n- [ ] All YAML references are specific and accessible (TypeScript/React docs, component examples)\n- [ ] Implementation tasks include exact TypeScript naming and placement guidance\n- [ ] Validation commands are TypeScript/React-specific and verified working\n- [ ] TypeScript interface definitions and component prop types are specified\n\n### Template Structure Compliance\n\n- [ ] All required TypeScript template sections completed\n- [ ] Goal section has specific Feature Goal, Deliverable, Success Definition\n- [ ] Implementation Tasks follow TypeScript dependency ordering (types → components → pages → tests)\n- [ ] Final Validation Checklist includes TypeScript/React-specific validation\n\n### TypeScript/React Information Density Standards\n\n- [ ] No generic references - all are specific to TypeScript/React patterns\n- [ ] File patterns include specific TypeScript examples to follow (interfaces, components, hooks)\n- [ ] URLs include section anchors for exact TypeScript/React guidance\n- [ ] Task specifications use information-dense keywords from TypeScript/React codebase\n- [ ] Component patterns specify Server vs Client component usage\n- [ ] Type definitions are comprehensive and follow existing patterns\n\n## Success Metrics\n\n**Confidence Score**: Rate 1-10 for one-pass TypeScript implementation success likelihood\n\n**Quality Standard**: Minimum 8/10 required before PRP approval\n\n**Validation**: The completed PRP should enable an AI agent unfamiliar with the TypeScript/React codebase to implement the feature successfully using only the PRP content and codebase access, with full type safety and React best practices.\n"
              },
              {
                "name": "/prp-ts-execute",
                "description": null,
                "path": "prp/commands/prp-ts-execute.md",
                "frontmatter": null,
                "content": "# Execute TypeScript PRP\n\n## PRP File: $ARGUMENTS\n\n## Mission: One-Pass TypeScript Implementation Success\n\nPRPs enable working TypeScript/React code on the first attempt through:\n\n- **Context Completeness**: Everything needed, nothing guessed\n- **Progressive Validation**: 4-level gates catch errors early\n- **Pattern Consistency**: Follow existing TypeScript/React codebase approaches\n- **Type Safety**: Leverage TypeScript's compile-time error detection\n- Read PRPs/README.md to understand PRP concepts\n\n**Your Goal**: Transform the PRP into working TypeScript code that passes all validation gates and maintains type safety.\n\n## Execution Process\n\n1. **Load PRP**\n   - Read the specified TypeScript PRP file completely\n   - Absorb all context, patterns, requirements and gather codebase intelligence\n   - Use the provided documentation references and file patterns, consume the right documentation before the appropriate todo/task\n   - Trust the PRP's context and guidance - it's designed for one-pass success\n   - If needed do additional codebase exploration and research as needed\n   - Pay special attention to TypeScript interfaces, component patterns, and Next.js App Router structure\n\n2. **ULTRATHINK & Plan**\n   - Create comprehensive implementation plan following the PRP's task order\n   - Break down into clear todos using TodoWrite tool\n   - Use subagents for parallel work when beneficial (always create prp inspired prompts for subagents when used)\n   - Follow the TypeScript/React patterns referenced in the PRP\n   - Use specific file paths, interface names, component names, and type definitions from PRP context\n   - Never guess - always verify the codebase patterns and examples referenced in the PRP yourself\n   - Consider TypeScript compilation dependencies (types before components, components before pages)\n\n3. **Execute Implementation**\n   - Follow the PRP's Implementation Tasks sequence, add more detail as needed, especially when using subagents\n   - Use the TypeScript/React patterns and examples referenced in the PRP\n   - Create files in locations specified by the desired codebase tree\n   - Apply TypeScript naming conventions from the task specifications and CLAUDE.md\n   - Ensure proper TypeScript typing throughout (interfaces, props, return types)\n   - Follow Next.js App Router patterns for file-based routing\n\n4. **Progressive Validation**\n\n   **Execute the 4-level validation system from the TypeScript PRP:**\n   - **Level 1**: Run TypeScript syntax & style validation commands from PRP (ESLint, tsc, Prettier)\n   - **Level 2**: Execute component and hook unit test validation from PRP\n   - **Level 3**: Run Next.js integration testing commands from PRP (dev server, API routes, production build)\n   - **Level 4**: Execute TypeScript/React-specific validation from PRP (E2E, performance, accessibility)\n\n   **Each level must pass before proceeding to the next.**\n\n5. **Completion Verification**\n   - Work through the Final Validation Checklist in the PRP\n   - Verify all Success Criteria from the \"What\" section are met\n   - Confirm all Anti-Patterns were avoided (especially TypeScript/React-specific ones)\n   - Verify TypeScript compilation is successful with no errors\n   - Ensure proper Server/Client component separation if using Next.js\n   - Implementation is ready and working with full type safety\n\n**Failure Protocol**: When validation fails, use the TypeScript/React patterns and gotchas from the PRP to fix issues, then re-run validation until passing. Pay special attention to:\n- TypeScript compilation errors and type mismatches\n- React hydration issues between server and client\n- Next.js App Router specific requirements\n- Component prop interface violations"
              },
              {
                "name": "/task-list-init",
                "description": null,
                "path": "prp/commands/task-list-init.md",
                "frontmatter": null,
                "content": "claude\n\\*\\* Create a comprehensive task list in PRPs/checklist.md for PRP $ARGIMENTS\n\nIngest the infomration then dig deep into our existing codebase and PRP, When done ->\n\nULTRATHINK about the PRP task and create the plan based adhering to claude.md and extract and refine detailed tasks following this principle:\n\n### list of tasks to be completed to fullfill the PRP in the order they should be completed using infomration dense keywords\n\n- Infomration dense keyword examples:\n  ADD, CREATE, MODIFY, MIRROR, FIND, EXECUTE, KEEP, PRESERVE etc\n\nMark done tasks with: STATUS [DONE], if not done leave empty\n\n```yaml\nTask 1:\nSTATUS [ ]\nMODIFY src/existing_module.py:\n  - FIND pattern: \"class OldImplementation\"\n  - INJECT after line containing \"def __init__\"\n  - PRESERVE existing method signatures\n\nSTATUS [ ]\nCREATE src/new_feature.py:\n  - MIRROR pattern from: src/similar_feature.py\n  - MODIFY class name and core logic\n  - KEEP error handling pattern identical\n\n...(...)\n\nTask N:\n...\n\n```\n\nEach task should have unit test coverage, make tests pass on each task\n"
              }
            ],
            "skills": []
          },
          {
            "name": "content-gen",
            "description": "Automated multi-agent content generation system with framework-based scoring",
            "source": "./content-gen",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add rpiplewar/shipfaster",
              "/plugin install content-gen@rapid-shipping"
            ],
            "signals": {
              "stars": 7,
              "forks": 0,
              "pushed_at": "2025-10-30T18:27:06Z",
              "created_at": "2025-10-13T14:36:48Z",
              "license": null
            },
            "commands": [
              {
                "name": "/content-critic-review",
                "description": "Review scored content and provide improvement suggestions",
                "path": "content-gen/commands/content-critic-review.md",
                "frontmatter": {
                  "description": "Review scored content and provide improvement suggestions"
                },
                "content": "# Critic Review\n\n## Mission\n\nReview all scored content variations, provide specific improvement suggestions for pieces scoring 15-25/30, and filter out content below quality threshold (<20/30).\n\n## Process\n\nFollow the Critic agent instructions (`agents/critic.md`) to:\n\n1. **Read scored content** from content-drafts.md\n2. **Evaluate quality** (factual accuracy, framework alignment, engagement potential)\n3. **Generate critiques** with strengths, weaknesses, and specific suggestions\n4. **Apply Pass/Fail verdicts** (< 20 = FAIL, ≥ 20 = PASS)\n5. **Update content-drafts.md** with critique sections\n\n## Execution Steps\n\n### Step 1: Read Scored Content\n\n**Input Source**: `content-drafts.md` with complete scores\n\n**Focus On**:\n- Content scoring 15-25/30 (improvement candidates)\n- Content scoring < 20/30 (automatic FAIL)\n- Content scoring 20+/30 (PASS but optimize)\n\n### Step 2: Quality Evaluation\n\nFor each piece, assess:\n\n#### Factual Accuracy (Non-Negotiable)\n- [ ] All claims verifiable against themes-memory.md source stories\n- [ ] No hallucinated examples or fictional scenarios\n- [ ] Numbers, dates, names match source material\n\n**If Inaccurate**: Mark FAIL regardless of score\n\n#### Framework Alignment\n- [ ] Gap Selling: Problem clear, emotional stakes present, solution evident\n- [ ] Biases: Claimed biases actually activated\n- [ ] Decision Framework: Hook strong, value clear, CTA present\n\n#### Engagement Potential\n- [ ] First line grabs attention\n- [ ] Logical flow\n- [ ] Emotional resonance\n- [ ] Actionable insight\n- [ ] Platform-appropriate style\n\n### Step 3: Generate Structured Critique\n\nFor each piece:\n\n```markdown\n**Critic Notes:**\n\n**Strengths:**\n- {Specific element that works, with reference}\n- {Second strength}\n- {Third strength}\n\n**Weaknesses:**\n- {Specific issue with explanation}\n- {Second weakness and why it matters}\n- {Third weakness}\n\n**Suggestions:**\n- {Concrete edit: \"Change X to Y because...\"}\n- {Second suggestion with specific line reference}\n- {Third suggestion}\n\n**Verdict:** {✅ PASS or ❌ FAIL}\n```\n\n### Step 4: Apply Pass/Fail Logic\n\n**FAIL if ANY of these true**:\n- Total score < 20/30\n- Factually inaccurate\n- Hallucinated information\n- Gap Selling < 6/10 (problem unclear)\n- Decision Framework < 6/10 (weak hook or no value)\n\n**PASS if ALL of these true**:\n- Total score ≥ 20/30\n- Factually accurate\n- All frameworks adequately addressed\n- Engagement potential present\n\n### Step 5: Update content-drafts.md\n\nAdd critique section after scores for each variation.\n\n## Validation Checklist\n\nBefore marking review complete:\n\n- [ ] All scored content reviewed\n- [ ] Factual accuracy verified for each piece\n- [ ] Specific strengths identified (3 per piece)\n- [ ] Specific weaknesses identified (3 per piece)\n- [ ] Actionable suggestions provided (3 per piece)\n- [ ] Pass/Fail verdicts assigned\n- [ ] content-drafts.md updated with critiques\n\n## Common Improvement Patterns\n\n**If Gap Selling Low** (< 6/10):\n- Make problem more explicit\n- Increase emotional stakes\n- Strengthen future-state value\n\n**If Bias Score Low** (< 5):\n- Add before/after structure (Contrast)\n- Include numbers/credentials (Authority)\n- Reference crowd behavior (Social Proof)\n- Give free value (Reciprocation)\n\n**If Decision Framework Low** (< 6/10):\n- Strengthen opening hook\n- Add actionable insight\n- Make CTA explicit and low-friction\n\n## Example Output\n\n```\n✅ Critic Review Complete\n\nVariations Reviewed: 25\n\nPass/Fail Distribution:\n- PASS: 21 pieces (84%)\n- FAIL: 4 pieces (16%)\n\nCommon Strengths:\n- Strong vulnerability/authenticity (18/25 pieces)\n- Effective contrast before/after structure (15/25 pieces)\n- Clear problem statements (20/25 pieces)\n\nCommon Weaknesses:\n- CTAs often philosophical rather than actionable (12/25 pieces)\n- Emotional stakes could be more vivid (8/25 pieces)\n- Some hooks predictable (6/25 pieces)\n\nTop Recommendations:\n1. Convert philosophical CTAs to specific actions\n2. Amplify stakes language for emotional impact\n3. Test open-loop questions vs bold statements for hooks\n\nOutput File: content-drafts.md (updated with critiques)\n\nNext Step: Run /content-select-best to choose top piece\n```\n\n## Error Handling\n\n**If critique seems subjective**:\n- Reference specific lines and concrete issues\n- Justify suggestions with framework principles\n- Avoid \"I think\" or \"I feel\" language\n\n**If uncertain about factual accuracy**:\n- Cross-check against themes-memory.md source stories\n- Flag for user verification\n- Mark as uncertain rather than guessing\n\n## Next Steps\n\nAfter successful review:\n\n1. Review critiques in content-drafts.md\n2. Run `/content-select-best` to select top piece\n3. Or continue with full pipeline if running `/content-full-pipeline`"
              },
              {
                "name": "/content-extract-stories",
                "description": "Extract stories from Linear tasks and identify themes for content generation",
                "path": "content-gen/commands/content-extract-stories.md",
                "frontmatter": {
                  "description": "Extract stories from Linear tasks and identify themes for content generation"
                },
                "content": "# Extract Stories from Linear\n\n## Mission\n\nConnect to Linear, extract stories from as specified by user, identify recurring themes, and output structured theme data to `themes-memory.md`.\n\n## Process\n\nFollow the Story Extractor agent instructions (`agents/story-extractor.md`) to systematically:\n\n1. **Connect to Linear MCP** and fetch task details\n2. **Analyze story content** for problems, insights, and emotional hooks\n3. **Identify recurring themes** (minimum 5)\n4. **Structure theme extraction** with all required sections\n5. **Write to themes-memory.md** in poasting repository\n6. **Update Linear tasks** with extraction confirmation\n\n## Execution Steps\n\n### Step 1: Verify Prerequisites\n\nCheck that required tools are available:\n\n- [ ] Linear MCP installed and configured\n- [ ] LINEAR_API_KEY set in .env file\n- [ ] themes-memory.md path accessible: `./poasting/themes-memory.md`\n\n### Step 2: Fetch Stories from Linear\n\nUse Linear MCP commands to retrieve tasks POA-5 through POA-14:\n\n```javascript\n// List all target issues\nmcp__linear__list_issues({\n  \"team\": \"YOUR_TEAM_ID\",\n  \"filter\": {\n    \"id\": {\n      \"in\": [\"POA-{X}\", \"POA-{Y}\"]\n    }\n  }\n})\n\n// For each task, get full details including comments\nmcp__linear__get_issue({\n  \"id\": \"POA-X\",\n  \"include_comments\": true\n})\n```\n\n**Rate Limit**: 100 requests/minute. Batch requests when possible.\n\n### Step 3: Extract and Structure Themes\n\nFor each identified theme, create structured output with:\n\n- Theme name\n- Source task IDs\n- Problem statement\n- Emotional hook\n- Key insight\n- 5 content angles (Bold, Story, Problem-Solution, Data, Emotional)\n- Source story excerpt\n\n**Minimum Output**: 5 distinct themes\n\n### Step 4: Write to themes-memory.md\n\n**Location**: `./poasting/themes-memory.md`\n\n**Action**:\n- If file doesn't exist, create with header\n- If file exists, APPEND new themes (preserve existing)\n- Add extraction metadata timestamp\n\n### Step 5: Update Linear Tasks\n\nAdd confirmation comment to each processed task:\n\n```\n✅ Theme extracted: {Theme Name}\nExtracted to themes-memory.md on {YYYY-MM-DD}\n```\n\n## Validation Checklist\n\nBefore marking extraction complete:\n\n- [ ] Minimum 5 themes extracted\n- [ ] Each theme has all required sections\n- [ ] Themes are distinct (>70% different)\n- [ ] Source stories quoted accurately\n- [ ] themes-memory.md written successfully\n- [ ] Linear tasks updated with confirmations\n- [ ] No hallucinated information\n- [ ] Emotional authenticity preserved\n\n## Example Output\n\n```\n✅ Story Extraction Complete\n\nThemes Extracted: n\nSource Tasks: POA-X to POA-Y\nOutput File: themes-memory.md\n\nThemes Identified:\n1. First Money From Code (POA-5, POA-8)\n2. Personal Pain → Product (POA-6, POA-9, POA-12)\n3. Learning Intensity vs Environment (POA-7, POA-10)\n4. Affordable Loss Decision Making (POA-5, POA-11)\n5. The Quit Day (POA-5, POA-13)\n6. Family-Influenced Products (POA-6, POA-14)\n7. Creative Reactivation After Engineering (POA-8, POA-10)\n\nLinear tasks updated with extraction confirmations.\nReady for content generation: /content-generate-drafts {theme}\n```\n\n## Error Handling\n\n**If Linear MCP fails**:\n- Check .env for LINEAR_API_KEY\n- Verify Linear MCP installation\n- Confirm team ID is correct\n\n**If rate limit hit**:\n- Batch remaining requests\n- Wait 60 seconds before retry\n\n**If stories are sparse**:\n- Extract what's available\n- Flag for user follow-up in Linear comment\n\n## Next Steps\n\nAfter successful extraction:\n\n1. Review themes in themes-memory.md\n2. Select theme for content generation\n3. Run `/content-generate-drafts {theme-name}` to create variations\n\n**Or run full pipeline**: `/content-full-pipeline` to execute all stages end-to-end"
              },
              {
                "name": "/content-full-pipeline",
                "description": "Execute end-to-end content generation pipeline from Linear stories to ready-to-post content",
                "path": "content-gen/commands/content-full-pipeline.md",
                "frontmatter": {
                  "description": "Execute end-to-end content generation pipeline from Linear stories to ready-to-post content"
                },
                "content": "# Full Content Generation Pipeline\n\n## Mission\n\nExecute the complete content generation workflow end-to-end: Extract stories from Linear → Generate variations → Score all → Critic review → Select best → Output ONE ready-to-post piece.\n\n## Overview\n\nThis command orchestrates all 5 stages of the content generation system:\n\n1. **Story Extraction** (`/content-extract-stories`)\n2. **Draft Generation** (`/content-generate-drafts` for each theme)\n3. **Automated Scoring** (`/content-score-all`)\n4. **Critic Review** (`/content-critic-review`)\n5. **Best Selection** (`/content-select-best`)\n\n**Expected Output**: ONE piece in `content-ready.md` scoring 25+/30, ready for human approval and posting.\n\n**Expected Duration**: < 3 minutes for 5 themes → 25 variations → 1 selected piece\n\n## Process\n\n### Stage 1: Story Extraction\n\n**Command**: `/content-extract-stories`\n\n**Actions**:\n- Connect to Linear MCP\n- Fetch tasks POA-X through POA-Y\n- Analyze story content and identify themes\n- Extract minimum 5 distinct themes\n- Write to `themes-memory.md`\n- Update Linear tasks with extraction confirmations\n\n**Success Criteria**:\n- [ ] Minimum 5 themes extracted\n- [ ] themes-memory.md populated with structured themes\n- [ ] Linear tasks updated with confirmation comments\n- [ ] No hallucinated information\n\n**Failure Handling**:\n- If Linear MCP fails: Check .env for LINEAR_API_KEY, verify MCP installation\n- If < 5 themes: Alert user, proceed with available themes\n- If rate limit hit: Batch requests, wait 60s, retry\n\n**Stage Output**: `themes-memory.md` with 5+ themes\n\n---\n\n### Stage 2: Draft Generation\n\n**Command**: `/content-generate-drafts {theme}` for EACH theme\n\n**Actions**:\n- For each theme in themes-memory.md:\n  - Spawn 5 parallel Draft Generator sub-agents\n  - Each sub-agent targets DIFFERENT bias combinations:\n    - Bold Statement (Contrast, Authority)\n    - Story Hook (Curiosity, Liking)\n    - Problem-Solution (Social Proof, Reciprocation)\n    - Data-Driven (Authority, Reason-Respecting)\n    - Emotional (Liking, Stress-Influence, Lollapalooza)\n  - Generate 5 unique variations per theme\n  - Write to `content-drafts.md`\n\n**Success Criteria**:\n- [ ] 5 variations per theme (25 total for 5 themes)\n- [ ] Each variation >70% different from others\n- [ ] All variations follow Hook-Content-CTA structure\n- [ ] Bias targeting explicit and diverse\n\n**Failure Handling**:\n- If variation count < 5 per theme: Regenerate missing variations\n- If similarity > 30% between variations: Regenerate duplicates\n- If bias targeting unclear: Review draft-generator.md specs\n\n**Stage Output**: `content-drafts.md` with 25 variations (5 themes × 5 variations)\n\n---\n\n### Stage 3: Automated Scoring\n\n**Command**: `/content-score-all`\n\n**Actions**:\n- Read all variations from content-drafts.md\n- Apply 3-framework scoring to each:\n  - **Gap Selling** (0-10): Problem clarity + Impact + Solution value\n  - **Cognitive Biases** (count): Activated biases + Lollapalooza bonus\n  - **Decision Framework** (0-10): Hook strength + Content value + CTA clarity\n- Calculate total score (Gap + Biases + Decision = XX/30)\n- Update content-drafts.md with complete score breakdowns\n\n**Success Criteria**:\n- [ ] All 25 variations scored\n- [ ] Score breakdowns complete (subscore details)\n- [ ] Minimum 80% of content scores 20+/30\n- [ ] Total scores calculated correctly\n\n**Failure Handling**:\n- If < 50% score 20+/30: Alert quality issue, consider regenerating\n- If scoring formulas inconsistent: Review scorer.md rubrics\n- If subscore missing: Re-run scoring for affected variations\n\n**Stage Output**: `content-drafts.md` with complete scores for all variations\n\n---\n\n### Stage 4: Critic Review\n\n**Command**: `/content-critic-review`\n\n**Actions**:\n- Review all variations scoring 15+/30\n- Provide specific improvement suggestions\n- Verify factual accuracy against Linear stories\n- Assign ✅ PASS or ❌ FAIL verdict\n- Filter out < 20/30 pieces\n- Update content-drafts.md with critic notes\n\n**Success Criteria**:\n- [ ] All 20+/30 variations reviewed\n- [ ] Critic notes complete (Strengths, Weaknesses, Suggestions)\n- [ ] PASS/FAIL verdicts assigned\n- [ ] Factual accuracy verified (no hallucinations)\n\n**Failure Handling**:\n- If no PASS content: Alert pipeline failure, regenerate with constraints\n- If factual inaccuracies found: Flag for correction, re-verify\n- If critic notes missing: Re-run review for affected variations\n\n**Stage Output**: `content-drafts.md` with critic verdicts and notes\n\n---\n\n### Stage 5: Best Selection\n\n**Command**: `/content-select-best`\n\n**Actions**:\n- Filter for PASS content (20+/30 scores)\n- Rank by total score (descending)\n- Apply tie-breaker rules if needed:\n  1. Gap Selling subscore\n  2. Hook strength\n  3. Lollapalooza effect (5+ biases)\n  4. Bias diversity\n  5. Theme novelty\n  6. Human judgment flag\n- Validate selection against quality gates\n- Format for content-ready.md with posting instructions\n- Document top 3 runner-ups\n\n**Success Criteria**:\n- [ ] ONE piece selected (not zero, not multiple)\n- [ ] Selected piece scores 20+/30 (ideally 25+/30)\n- [ ] content-ready.md overwritten with formatted output\n- [ ] Posting instructions included\n- [ ] Runner-ups documented\n\n**Failure Handling**:\n- If no PASS content: STOP pipeline, alert user\n- If tie-breakers don't resolve: Flag for human decision\n- If content-ready.md already full: Prompt to archive or overwrite\n\n**Stage Output**: `content-ready.md` with ONE ready-to-post piece\n\n---\n\n## Execution Flow\n\n```\nSTART\n  ↓\n[Stage 1: Extract Stories]\n  ├─ Linear MCP → POA-5 to POA-14\n  ├─ Identify themes (min 5)\n  └─ Output: themes-memory.md\n  ↓\n[Stage 2: Generate Drafts]\n  ├─ For each theme (5 themes):\n  │   ├─ Spawn 5 parallel sub-agents\n  │   ├─ Generate 5 variations (different bias combos)\n  │   └─ Total: 25 variations\n  └─ Output: content-drafts.md\n  ↓\n[Stage 3: Score All]\n  ├─ Apply Gap Selling (0-10)\n  ├─ Count Cognitive Biases\n  ├─ Apply Decision Framework (0-10)\n  └─ Output: content-drafts.md with scores\n  ↓\n[Stage 4: Critic Review]\n  ├─ Review 20+/30 content\n  ├─ Provide improvement suggestions\n  ├─ Assign PASS/FAIL verdicts\n  └─ Output: content-drafts.md with critic notes\n  ↓\n[Stage 5: Select Best]\n  ├─ Rank PASS content\n  ├─ Apply tie-breakers\n  ├─ Validate selection\n  └─ Output: content-ready.md (ONE piece)\n  ↓\n[Human Approval Required]\n  ├─ Review content-ready.md\n  ├─ Post to Twitter/X\n  └─ Capture metrics after 48 hours\n  ↓\nEND\n```\n\n## Pre-Execution Checklist\n\nBefore running full pipeline, verify:\n\n**Infrastructure**:\n- [ ] Linear MCP installed and configured\n- [ ] LINEAR_API_KEY set in .env file\n- [ ] All framework docs accessible (gap_selling.md, bias_checklist_munger.md, effective-decision-making-framework.md)\n- [ ] File paths correct (themes-memory.md, content-drafts.md, content-ready.md)\n\n**Content Readiness**:\n- [ ] Linear tasks POA-5 to POA-14 have story content\n- [ ] Stories contain sufficient detail for theme extraction\n- [ ] content-ready.md is clear (or content archived to content-posted.md)\n\n**System Resources**:\n- [ ] Network connectivity stable (for Linear API calls)\n- [ ] Sufficient API quota (Linear rate limit: 100 req/min)\n- [ ] Execution environment ready (no blocking processes)\n\n## Validation Checkpoints\n\n### After Stage 1 (Story Extraction)\n```bash\n# Verify themes extracted\ngrep -c \"## Theme:\" /home/rpiplewar/fast_dot_ai/poasting/themes-memory.md\n# Should be >= 5\n```\n\n### After Stage 2 (Draft Generation)\n```bash\n# Verify variations generated\ngrep -c \"### Variation\" /home/rpiplewar/fast_dot_ai/poasting/content-drafts.md\n# Should be >= 25 (5 themes × 5 variations)\n```\n\n### After Stage 3 (Automated Scoring)\n```bash\n# Verify scores added\ngrep -c \"TOTAL:\" /home/rpiplewar/fast_dot_ai/poasting/content-drafts.md\n# Should match variation count\n```\n\n### After Stage 4 (Critic Review)\n```bash\n# Verify verdicts assigned\ngrep -c \"Verdict: PASS\\|FAIL\" /home/rpiplewar/fast_dot_ai/poasting/content-drafts.md\n# Should match variations with 15+/30 scores\n```\n\n### After Stage 5 (Best Selection)\n```bash\n# Verify single piece selected\ngrep -c \"# Content Ready to Post\" /home/rpiplewar/fast_dot_ai/poasting/content-ready.md\n# Should be exactly 1\n```\n\n## Error Handling & Recovery\n\n### Pipeline Failure Scenarios\n\n**Stage 1 Failure (Story Extraction)**:\n```\n❌ Stage 1 Failed: Could not extract stories from Linear\n\nPossible Causes:\n- Linear MCP not configured\n- LINEAR_API_KEY missing or invalid\n- Network connectivity issues\n- Tasks POA-5 to POA-14 not accessible\n\nRecovery:\n1. Check .env file for LINEAR_API_KEY\n2. Verify Linear MCP installation: mcp__linear__list_issues test\n3. Confirm network connectivity\n4. Retry: /content-extract-stories\n\nPipeline STOPPED at Stage 1. Fix issues before retrying full pipeline.\n```\n\n**Stage 2 Failure (Draft Generation)**:\n```\n❌ Stage 2 Failed: Insufficient variations generated\n\nPossible Causes:\n- Theme quality low (not enough content generation potential)\n- Draft generator specs unclear\n- Agent spawning failed\n\nRecovery:\n1. Review themes in themes-memory.md for clarity\n2. Manually run: /content-generate-drafts {theme} for each theme\n3. Verify draft-generator.md agent specs\n4. Check for variation diversity (>70% different)\n\nPipeline STOPPED at Stage 2. Complete draft generation before continuing.\n```\n\n**Stage 3 Failure (Automated Scoring)**:\n```\n❌ Stage 3 Failed: Scoring incomplete or inconsistent\n\nPossible Causes:\n- Framework docs inaccessible\n- Scoring formulas incorrect\n- Subscore calculation errors\n\nRecovery:\n1. Verify framework docs accessible (gap_selling.md, bias_checklist_munger.md, effective-decision-making-framework.md)\n2. Review scorer.md agent specs\n3. Manually run: /content-score-all\n4. Compare sample scores vs manual evaluation\n\nPipeline STOPPED at Stage 3. Complete scoring before continuing.\n```\n\n**Stage 4 Failure (Critic Review)**:\n```\n❌ Stage 4 Failed: No PASS content after critic review\n\nPossible Causes:\n- Content quality below 20/30 threshold\n- Critic too harsh (scoring too low)\n- Theme selection poor\n\nRecovery:\n1. Review content-drafts.md scores (check if consistently low)\n2. If scores 15-19/30: Adjust scoring weights in scorer.md\n3. If scores < 15/30: Regenerate content with stronger constraints\n4. Consider revising themes for better content potential\n\nPipeline STOPPED at Stage 4. Fix quality issues before continuing.\n```\n\n**Stage 5 Failure (Best Selection)**:\n```\n❌ Stage 5 Failed: No content available for selection\n\nPossible Causes:\n- No PASS content from Stage 4\n- All content < 20/30 threshold\n- Selection criteria too strict\n\nRecovery:\n1. Review Critic verdicts in content-drafts.md\n2. If close to threshold (18-19/30): Consider relaxing to 18+/30 minimum\n3. If far below threshold: Regenerate content from Stage 2\n4. Review theme quality and bias targeting\n\nPipeline STOPPED at Stage 5. Fix quality issues or regenerate content.\n```\n\n### Partial Pipeline Recovery\n\n**If pipeline stopped at Stage X**, resume from that stage:\n\n```bash\n# Resume from Stage 2 (Draft Generation)\n/content-generate-drafts {theme}  # For each remaining theme\n\n# Resume from Stage 3 (Automated Scoring)\n/content-score-all\n\n# Resume from Stage 4 (Critic Review)\n/content-critic-review\n\n# Resume from Stage 5 (Best Selection)\n/content-select-best\n```\n\n**No need to re-run completed stages** - pipeline is idempotent at each stage.\n\n## Success Output\n\n```\n✅ Full Content Generation Pipeline Complete\n\n⏱️ Execution Time: 2m 34s\n\n📊 Pipeline Stats:\n- Themes Extracted: 7\n- Variations Generated: 35 (7 themes × 5 variations)\n- Content Scored: 35/35\n- PASS Content: 24/35 (68.6%)\n- FAIL Content: 11/35 (31.4%)\n\n🏆 Best Content Selected:\n- Theme: First Money From Code\n- Variation: Bold Statement\n- Score: 28/30 (EXCELLENT)\n- Ranking: #1 of 24 PASS pieces\n\n📁 Output Files Updated:\n✓ themes-memory.md (7 themes)\n✓ content-drafts.md (35 variations with scores)\n✓ content-ready.md (1 ready-to-post piece)\n\n📋 Next Steps:\n1. Review content-ready.md\n2. Perform final quality check\n3. Post to Twitter/X at optimal time (8:30 AM or 5:30 PM IST)\n4. Capture metrics after 48 hours\n5. Move to content-posted.md with metrics\n\n🚀 Ready for human review and posting!\n```\n\n## Performance Metrics\n\n**Target Benchmarks**:\n- Execution Time: < 3 minutes\n- Themes Extracted: ≥ 5\n- Variations Generated: ≥ 25 (5 themes × 5 variations)\n- PASS Content: ≥ 80% (20/25)\n- Selected Score: ≥ 25/30 (ideally 27+/30)\n\n**Quality Thresholds**:\n- < 50% PASS content: Quality issue, regenerate with constraints\n- Selected score < 23/30: Consider regenerating or improving themes\n- Selected score ≥ 28/30: Excellent, high viral potential\n\n## Integration Notes\n\nThis command represents the complete automated content generation system. It requires:\n- All 6 agent instruction documents (agents/*.md)\n- All 5 individual stage commands (commands/content-*.md)\n- Linear MCP integration\n- All 3 framework docs (docs/frameworks/*.md)\n\nAfter execution, human approval is required before posting. Performance tracking begins after posting to content-posted.md.\n\n## Advanced Options\n\n**Regenerate Pipeline with Filters**:\n```bash\n# Regenerate specific theme only\n/content-generate-drafts \"First Money From Code\"\n/content-score-all\n/content-critic-review\n/content-select-best\n\n# Regenerate with stronger bias constraints\n# (Modify draft-generator.md to require 5+ biases per variation)\n/content-full-pipeline\n\n# Test pipeline without Linear extraction (use existing themes)\n# Skip Stage 1, start from Stage 2\n```\n\n**Performance Optimization**:\n- Parallel theme processing: Spawn all theme agents simultaneously\n- Batch Linear API calls: Group requests to avoid rate limits\n- Cache framework docs: Load once, reuse across agents\n- Incremental updates: Only re-score modified variations\n\n## CRITICAL RULES\n\n1. **No File Proliferation**: Use ONLY 4 pipeline files (themes-memory.md, content-drafts.md, content-ready.md, content-posted.md)\n2. **ONE Piece in content-ready.md**: Always exactly ONE, never zero or multiple\n3. **Minimum Score Threshold**: 20+/30 to PASS, ideally 25+/30 for selection\n4. **No Hallucination**: All content must be traceable to Linear stories\n5. **Framework Completeness**: All 3 frameworks applied to every variation\n6. **Human Approval Required**: Never auto-post, always require review\n\n## Validation Checklist\n\nBefore marking pipeline complete:\n\n- [ ] All 5 stages completed successfully\n- [ ] themes-memory.md has ≥5 themes\n- [ ] content-drafts.md has ≥25 variations with complete scores\n- [ ] content-ready.md has EXACTLY ONE piece scoring 20+/30\n- [ ] Execution time < 3 minutes\n- [ ] No file proliferation (only 4 pipeline files used)\n- [ ] Linear tasks updated with extraction confirmations\n- [ ] No hallucinated information in any stage\n- [ ] Human approval workflow clear"
              },
              {
                "name": "/content-generate-drafts",
                "description": "Generate 5 content variations for a theme using parallel multi-agent approach",
                "path": "content-gen/commands/content-generate-drafts.md",
                "frontmatter": {
                  "description": "Generate 5 content variations for a theme using parallel multi-agent approach"
                },
                "content": "# Generate Content Drafts\n\n## Arguments\n\n`$ARGUMENTS` - Theme name from themes-memory.md\n\n## Mission\n\nGenerate 5 unique content variations for the specified theme by spawning 5 parallel sub-agents, each targeting different cognitive bias combinations and content structures.\n\n## Process\n\nFollow the Draft Generator agent instructions (`agents/draft-generator.md`) to:\n\n1. **Read theme details** from themes-memory.md\n2. **Spawn 5 parallel sub-agents** (CRITICAL: simultaneous, not sequential)\n3. **Collect sub-agent outputs** (5 variations)\n4. **Write to content-drafts.md** with proper formatting\n\n## Execution Steps\n\n### Step 1: Read Theme from themes-memory.md\n\n**Target Theme**: $ARGUMENTS\n\n**Extract**:\n- Theme name and problem statement\n- Emotional hook and key insight\n- All 5 content angles\n- Source story excerpts\n\n**If theme not found**: List available themes and ask user to retry with correct name.\n\n### Step 2: Spawn 5 Parallel Sub-Agents\n\n**CRITICAL**: Use single message with 5 Task tool calls to spawn all sub-agents simultaneously.\n\nEach sub-agent receives self-contained prompt with:\n- Full theme details\n- Specific bias activation strategy\n- Content structure requirements\n- Hook-Content-CTA framework\n- Character limits (280 single or 4-6 tweet thread)\n\n**Sub-Agent Assignments**:\n\n1. **Bold Statement Generator**\n   - Biases: Contrast-Misreaction + Authority-Misinfluence\n   - Structure: Shocking opening → Contrast → Authority evidence → CTA\n\n2. **Story Hook Generator**\n   - Biases: Curiosity Tendency + Liking/Loving Tendency\n   - Structure: Open-loop question → Personal story → Vulnerability → Resolution\n\n3. **Problem-Solution Generator**\n   - Biases: Social-Proof + Reciprocation + Reward/Punishment\n   - Structure: Problem statement → Social proof → Solution value → Free insight\n\n4. **Data-Driven Generator**\n   - Biases: Authority + Reason-Respecting + Availability-Misweighing\n   - Structure: Surprising stat → Reasoning → Concrete example → Implication\n\n5. **Emotional Lollapalooza Generator**\n   - Biases: Liking + Stress-Influence + 5+ biases converging\n   - Structure: Emotional hook → Stress creation → Relief → Multi-bias activation\n\n### Step 3: Quality Check Each Variation\n\nVerify:\n- [ ] Content factually accurate (matches source stories)\n- [ ] Target biases clearly activated\n- [ ] Structure follows assigned format\n- [ ] Character limits respected\n- [ ] No meta-commentary (pure content)\n\n### Step 4: Write to content-drafts.md\n\n**Location**: `/home/rpiplewar/fast_dot_ai/poasting/content-drafts.md`\n\n**Format**:\n```markdown\n## Theme: {Theme Name}\n**Source:** {Linear Task ID}\n\n### Variation 1: Bold Statement\n**Content:**\n{Generated content}\n\n**Biases Targeted:** Contrast-Misreaction, Authority-Misinfluence\n\n**Scores:**\n[To be filled by Scorer agent]\n\n---\n\n### Variation 2: Story Hook\n...\n```\n\n**Action**: APPEND to file (don't overwrite existing content from other themes)\n\n## Validation Checklist\n\nBefore marking generation complete:\n\n- [ ] All 5 variations generated\n- [ ] Each variation targets DIFFERENT bias combinations\n- [ ] All content factually accurate\n- [ ] Variations >70% structurally different\n- [ ] content-drafts.md updated successfully\n- [ ] No meta-commentary in output\n- [ ] Character limits respected\n- [ ] Hook-Content-CTA structure followed\n\n## Example Output\n\n```\n✅ Draft Generation Complete\n\nTheme: First Money From Code\nVariations Generated: 5\n\n1. Bold Statement (Contrast + Authority)\n2. Story Hook (Curiosity + Liking)\n3. Problem-Solution (Social Proof + Reciprocation)\n4. Data-Driven (Authority + Reason-Respecting)\n5. Emotional Lollapalooza (6 biases)\n\nOutput File: content-drafts.md\n\nNext Step: Run /content-score-all to apply framework scoring\n```\n\n## Error Handling\n\n**If theme not found**:\n- List available themes from themes-memory.md\n- Ask user to specify correct theme name\n\n**If sub-agent fails**:\n- Retry that specific sub-agent only\n- Don't re-run all 5\n\n**If variations too similar**:\n- Regenerate similar variation with stronger bias differentiation\n\n## Next Steps\n\nAfter successful generation:\n\n1. Review variations in content-drafts.md\n2. Run `/content-score-all` to apply automated scoring\n3. Or continue with full pipeline if running `/content-full-pipeline`"
              },
              {
                "name": "/content-score-all",
                "description": "Apply automated 3-framework scoring to all content variations",
                "path": "content-gen/commands/content-score-all.md",
                "frontmatter": {
                  "description": "Apply automated 3-framework scoring to all content variations"
                },
                "content": "# Score All Content Variations\n\n## Mission\n\nApply automated framework-based scoring (Gap Selling + Munger Biases + Decision Framework) to all content variations in content-drafts.md, calculating total scores with detailed breakdowns.\n\n## Process\n\nFollow the Scorer agent instructions (`agents/scorer.md`) to:\n\n1. **Read all content variations** from content-drafts.md\n2. **Apply 3-framework scoring** with mathematical formulas\n3. **Calculate total scores** (out of 30)\n4. **Update content-drafts.md** with complete score breakdowns\n\n## Execution Steps\n\n### Step 1: Read Content from content-drafts.md\n\n**Location**: `/home/rpiplewar/fast_dot_ai/poasting/content-drafts.md`\n\n**Identify**:\n- All content variations awaiting scoring\n- Look for `[To be filled by Scorer agent]` placeholders\n- Extract content text and bias targeting info\n\n### Step 2: Score Each Variation\n\n**For each content piece, calculate**:\n\n#### Framework 1: Gap Selling (0-10 points)\n- **Problem Clarity** (0-3): Is problem explicit and relatable?\n- **Emotional Impact** (0-3): Is pain point vivid and resonant?\n- **Solution Value** (0-4): Is future state compelling and actionable?\n\n#### Framework 2: Cognitive Biases (0-10+ points)\n- **Count activated biases** from Munger's 25\n- **Lollapalooza bonus**: +2 if 5+ biases converge\n- **List specific biases** detected\n\n#### Framework 3: Decision Framework (0-10 points)\n- **Hook Strength** (0-3): Does first line grab attention?\n- **Content Value** (0-4): Are insights actionable and transferable?\n- **CTA Clarity** (0-3): Is next step crystal clear?\n\n**Total Score = Gap (0-10) + Biases (0-10+) + Decision (0-10)**\n\n### Step 3: Assign Pass/Fail Verdict\n\n**Quality Thresholds**:\n- **< 20**: ❌ FAIL (filter out)\n- **20-24**: ✅ PASS (needs improvement)\n- **25-27**: ✅ PASS (GOOD)\n- **28-30**: ✅ PASS (EXCELLENT)\n\n### Step 4: Update content-drafts.md\n\n**Replace** `[To be filled by Scorer agent]` with:\n\n```markdown\n**Scores:**\n- Gap Selling: X/10 (Problem: X/3, Impact: X/3, Solution: X/4)\n- Biases Activated: Y (List: Bias1, Bias2, Bias3...)\n- Decision Framework: Z/10 (Hook: X/3, Value: X/4, CTA: X/3)\n- **TOTAL: XX/30** {✅ PASS or ❌ FAIL}\n```\n\n## Validation Checklist\n\nBefore marking scoring complete:\n\n- [ ] All variations scored\n- [ ] All subscores documented with reasoning\n- [ ] Bias lists include specific bias names (not just count)\n- [ ] Lollapalooza bonus applied where applicable (5+ biases)\n- [ ] Pass/Fail verdicts assigned (< 20 = FAIL, ≥ 20 = PASS)\n- [ ] content-drafts.md updated with complete scores\n- [ ] Scoring formulas followed exactly per scorer.md\n\n## Example Output\n\n```\n✅ Scoring Complete\n\nVariations Scored: 25 (5 themes × 5 variations)\n\nScore Distribution:\n- EXCELLENT (28-30): 3 pieces\n- GOOD (25-27): 8 pieces\n- PASS (20-24): 10 pieces\n- FAIL (< 20): 4 pieces\n\nPass Rate: 84% (21/25)\n\nHighest Scoring:\n1. Theme: First Money From Code, Variation 1 (Bold Statement) - 28/30\n2. Theme: The Quit Day, Variation 5 (Lollapalooza) - 27/30\n3. Theme: Personal Pain → Product, Variation 2 (Story Hook) - 26/30\n\nOutput File: content-drafts.md (updated with all scores)\n\nNext Step: Run /content-critic-review for quality feedback\n```\n\n## Error Handling\n\n**If scoring logic unclear**:\n- Refer to detailed rubrics in `agents/scorer.md`\n- Use examples as reference\n- Document edge cases for future refinement\n\n**If scores seem inaccurate**:\n- Cross-check against manual evaluation\n- Verify detection patterns\n- Adjust formulas if systematic drift detected\n\n## Accuracy Targets\n\n**Goal**: Within ±2 points (10% margin) of manual expert evaluation\n\n**If accuracy drifts**:\n- Review scoring logic against actual performance\n- Adjust detection patterns\n- Document refinements in scorer.md\n\n## Next Steps\n\nAfter successful scoring:\n\n1. Review score distribution in content-drafts.md\n2. Run `/content-critic-review` to get improvement suggestions\n3. Or continue with full pipeline if running `/content-full-pipeline`"
              },
              {
                "name": "/content-select-best",
                "description": "Select the best content piece from scored variations and format for content-ready.md",
                "path": "content-gen/commands/content-select-best.md",
                "frontmatter": {
                  "description": "Select the best content piece from scored variations and format for content-ready.md"
                },
                "content": "# Select Best Content for Posting\n\n## Mission\n\nRank all PASS content (20+/30 scores), apply tie-breaker rules, and select EXACTLY ONE best piece for human review in `content-ready.md`.\n\n## Process\n\nFollow the Selector agent instructions (`agents/selector.md`) to systematically:\n\n1. **Filter for PASS content** (20+/30 scores with ✅ PASS verdict)\n2. **Rank by total score** (descending order)\n3. **Apply tie-breaker rules** if multiple pieces tied for first\n4. **Validate selection** against quality gates\n5. **Format for content-ready.md** with posting instructions\n6. **Document runner-ups** (top 3 alternatives)\n\n## Execution Steps\n\n### Step 1: Read Scored Content\n\n**Input Source**: `content-drafts.md` with completed scores and critic verdicts\n\n**Required Data**:\n- Total scores (Gap + Biases + Decision = XX/30)\n- Critic verdict (✅ PASS or ❌ FAIL)\n- Subscore breakdowns (Gap subscore, Hook subscore, Bias count)\n- Content text and theme information\n\n### Step 2: Filter and Rank\n\n**Filter Criteria**:\n- Total score ≥ 20/30\n- Critic verdict: ✅ PASS\n- Factually accurate (verified by Critic)\n\n**Ranking**:\n- Primary: Sort by total score (descending)\n- Expected: 12-20 PASS pieces from 25 total variations\n\n**Quality Alert**:\n- If < 5 PASS pieces: Alert user that quality is below threshold\n- Consider regenerating content with stronger constraints\n\n### Step 3: Apply Tie-Breaker Rules\n\n**If multiple pieces have same total score**, apply tie-breakers in order:\n\n1. **Gap Selling Subscore**: Higher Gap score wins (problem clarity most important)\n2. **Hook Strength**: Higher Hook subscore wins (first line = 80% of engagement)\n3. **Lollapalooza Effect**: Content with 5+ biases wins (exponential persuasive power)\n4. **Bias Diversity**: More unique biases wins (broader psychological appeal)\n5. **Theme Novelty**: Less-used theme wins (prevents theme fatigue)\n6. **Human Judgment**: If still tied, flag for manual decision\n\n### Step 4: Validate Selection\n\nBefore finalizing, verify:\n\n**Quality Gates**:\n- [ ] Selected piece scores 20+/30 (ideally 25+/30)\n- [ ] All three frameworks adequately addressed (no subscore < 5)\n- [ ] Factually accurate (verified by Critic)\n- [ ] High engagement potential (hook + emotional resonance)\n\n**Platform Appropriateness**:\n- [ ] Twitter/X character limits respected (280 single or thread)\n- [ ] Tone matches platform (conversational, punchy)\n- [ ] Format clean (line breaks, readability)\n\n**Strategic Fit**:\n- [ ] Theme aligns with user's positioning\n- [ ] Message supports broader narrative\n- [ ] Timing appropriate (seasonally relevant)\n\n### Step 5: Write to content-ready.md\n\n**Location**: `/home/rpiplewar/fast_dot_ai/poasting/content-ready.md`\n\n**Action**: OVERWRITE file (only ONE piece should exist)\n\n**Format**:\n```markdown\n# Content Ready to Post\n\n**Date Generated:** {ISO Timestamp}\n**Theme:** {Theme Name}\n**Source:** {Linear Task ID}\n**Total Score:** {XX/30}\n\n---\n\n## Content\n\n{Content exactly as it should be posted}\n\n---\n\n## Scoring Breakdown\n\n**Gap Selling:** X/10 (Problem: X/3, Impact: X/3, Solution: X/4)\n**Cognitive Biases:** Y (List: Bias1, Bias2, Bias3...)\n**Decision Framework:** Z/10 (Hook: X/3, Value: X/4, CTA: X/3)\n**TOTAL: XX/30**\n\n---\n\n## Why This Piece?\n\n**Ranking Position:** #1 of {total_pass_count} PASS pieces\n\n**Key Strengths:**\n- {Strength from Critic notes}\n- {Strength from Critic notes}\n- {Strength from Critic notes}\n\n**Winning Elements:**\n- {Why this beat other contenders}\n- {Specific tie-breaker if applicable}\n- {Strategic fit reasoning}\n\n---\n\n## Posting Instructions\n\n**Optimal Timing:**\n- **Best Times (IST)**: 8:30 AM or 5:30 PM (high engagement windows)\n- **Avoid**: Late night (11 PM - 6 AM) or midday lull (12 PM - 2 PM)\n\n**Format Check:**\n- [ ] Character count: {count} (within 280 for single, or thread format)\n- [ ] Line breaks clean\n- [ ] No typos or formatting issues\n\n**Pre-Post Checklist:**\n- [ ] Read aloud for flow\n- [ ] Verify factual accuracy one final time\n- [ ] Check for unintended meanings or misinterpretations\n- [ ] Confirm tone matches brand voice\n\n**After Posting:**\n1. Copy final posted version to content-posted.md\n2. Add posting timestamp\n3. Set reminder to capture metrics after 48 hours\n4. Monitor engagement in first 2 hours for immediate feedback\n\n---\n\n## Alternatives (Top 3 Runner-Ups)\n\n### Runner-Up #2: {Score}\n**Theme:** {Theme Name}\n**Content Preview:** {First 50 characters}...\n**Why Not Selected:** {Reasoning}\n\n### Runner-Up #3: {Score}\n**Theme:** {Theme Name}\n**Content Preview:** {First 50 characters}...\n**Why Not Selected:** {Reasoning}\n\n### Runner-Up #4: {Score}\n**Theme:** {Theme Name}\n**Content Preview:** {First 50 characters}...\n**Why Not Selected:** {Reasoning}\n\n---\n\n**Generated by:** content-gen plugin v1.0\n**Selection Criteria:** Highest total score + tie-breaker rules\n**Human Approval Required:** YES (review before posting)\n```\n\n## Validation Checklist\n\nBefore marking selection complete:\n\n- [ ] ONE piece selected (not zero, not multiple)\n- [ ] Selected piece scores 20+/30 (ideally 25+/30)\n- [ ] All tie-breakers applied correctly if needed\n- [ ] content-ready.md overwritten with formatted output\n- [ ] Posting instructions included\n- [ ] Top 3 runner-ups documented\n- [ ] Selection reasoning documented\n\n## Example Output\n\n```\n✅ Best Content Selected\n\nSelected: Theme A, Variation 1\nScore: 28/30 (EXCELLENT)\nRanking: #1 of 18 PASS pieces\n\nKey Strengths:\n- Exceptional problem clarity (Gap: 9/10)\n- Strong emotional hook activating 6 biases\n- Clear, actionable CTA\n\nOutput: content-ready.md\nStatus: Ready for human review and approval\n\nRunner-Ups:\n#2: Theme C, Var 5 (27/30)\n#3: Theme B, Var 2 (26/30)\n#4: Theme A, Var 3 (25/30)\n\nNext Step: Review content-ready.md and post when ready\n```\n\n## Error Handling\n\n**If no PASS content**:\n```\n❌ Selection Failed: No content scored 20+/30\n\nAction Required:\n1. Review scorer settings (may be too harsh)\n2. Regenerate content with stronger constraints\n3. Review theme quality (may lack content generation potential)\n\nPipeline STOPPED at selection phase.\n```\n\n**If tie-breakers don't resolve**:\n```\n⚠️ Human Decision Required\n\nTwo pieces tied after all 6 automated tie-breakers.\nBoth pieces displayed in content-ready.md.\nUser must manually select.\n```\n\n**If content-ready.md already has content**:\n```\n⚠️ Warning: content-ready.md already contains content\n\nOptions:\n1. Archive existing content to content-posted.md first\n2. Overwrite with new selection (confirm Y/N)\n3. Cancel selection\n\nCurrent content in content-ready.md should be posted or archived before generating new content.\n```\n\n## Next Steps\n\nAfter successful selection:\n\n1. Review content-ready.md\n2. Perform final quality check\n3. Post to Twitter/X at optimal time\n4. Capture metrics after 48 hours\n5. Move to content-posted.md with metrics\n\n**Or run full pipeline**: `/content-full-pipeline` to execute all stages end-to-end"
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}