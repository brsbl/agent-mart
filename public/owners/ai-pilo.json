{
  "owner": {
    "id": "ai-pilo",
    "display_name": "Pilo",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/237793937?u=9de0365f5ff3dfc552dabfc951d153a77c8a1662&v=4",
    "url": "https://github.com/ai-pilo",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 8,
      "total_commands": 6,
      "total_skills": 9,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "ai-pilo/agents-backend-architecture",
      "url": "https://github.com/ai-pilo/agents-backend-architecture",
      "description": "Backend development, API design, and architecture",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-10-20T23:03:39Z",
        "created_at": "2025-10-20T19:59:40Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1170
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 83
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1056
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 955
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/agents.md",
          "type": "blob",
          "size": null
        },
        {
          "path": "docs/plugins.md",
          "type": "blob",
          "size": null
        },
        {
          "path": "docs/usage.md",
          "type": "blob",
          "size": null
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-scaffolding",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-scaffolding/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-scaffolding/agents/backend-architect.md",
          "type": "blob",
          "size": 18150
        },
        {
          "path": "plugins/api-scaffolding/agents/django-pro.md",
          "type": "blob",
          "size": 6496
        },
        {
          "path": "plugins/api-scaffolding/agents/fastapi-pro.md",
          "type": "blob",
          "size": 5945
        },
        {
          "path": "plugins/api-scaffolding/agents/graphql-architect.md",
          "type": "blob",
          "size": 6786
        },
        {
          "path": "plugins/api-scaffolding/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-scaffolding/skills/fastapi-templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-scaffolding/skills/fastapi-templates/SKILL.md",
          "type": "blob",
          "size": 16291
        },
        {
          "path": "plugins/api-testing-observability",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-testing-observability/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-testing-observability/agents/api-documenter.md",
          "type": "blob",
          "size": 7429
        },
        {
          "path": "plugins/api-testing-observability/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/api-testing-observability/commands/api-mock.md",
          "type": "blob",
          "size": 43517
        },
        {
          "path": "plugins/backend-api-security",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-api-security/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-api-security/agents/backend-architect.md",
          "type": "blob",
          "size": 18150
        },
        {
          "path": "plugins/backend-api-security/agents/backend-security-coder.md",
          "type": "blob",
          "size": 9291
        },
        {
          "path": "plugins/backend-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/agents/backend-architect.md",
          "type": "blob",
          "size": 18150
        },
        {
          "path": "plugins/backend-development/agents/graphql-architect.md",
          "type": "blob",
          "size": 6786
        },
        {
          "path": "plugins/backend-development/agents/tdd-orchestrator.md",
          "type": "blob",
          "size": 9826
        },
        {
          "path": "plugins/backend-development/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/commands/feature-development.md",
          "type": "blob",
          "size": 10055
        },
        {
          "path": "plugins/backend-development/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles/SKILL.md",
          "type": "blob",
          "size": 13741
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles/assets/api-design-checklist.md",
          "type": "blob",
          "size": 3865
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles/assets/rest-api-template.py",
          "type": "blob",
          "size": 4638
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles/references/graphql-schema-design.md",
          "type": "blob",
          "size": 9029
        },
        {
          "path": "plugins/backend-development/skills/api-design-principles/references/rest-best-practices.md",
          "type": "blob",
          "size": 7548
        },
        {
          "path": "plugins/backend-development/skills/architecture-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/skills/architecture-patterns/SKILL.md",
          "type": "blob",
          "size": 15157
        },
        {
          "path": "plugins/backend-development/skills/microservices-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend-development/skills/microservices-patterns/SKILL.md",
          "type": "blob",
          "size": 17652
        },
        {
          "path": "plugins/data-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/data-engineering/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/data-engineering/agents/backend-architect.md",
          "type": "blob",
          "size": 18150
        },
        {
          "path": "plugins/data-engineering/agents/data-engineer.md",
          "type": "blob",
          "size": 10713
        },
        {
          "path": "plugins/data-engineering/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/data-engineering/commands/data-driven-feature.md",
          "type": "blob",
          "size": 11251
        },
        {
          "path": "plugins/data-engineering/commands/data-pipeline.md",
          "type": "blob",
          "size": 6398
        },
        {
          "path": "plugins/data-validation-suite",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/data-validation-suite/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/data-validation-suite/agents/backend-security-coder.md",
          "type": "blob",
          "size": 9291
        },
        {
          "path": "plugins/database-cloud-optimization",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/database-cloud-optimization/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/database-cloud-optimization/agents/backend-architect.md",
          "type": "blob",
          "size": 18150
        },
        {
          "path": "plugins/database-cloud-optimization/agents/cloud-architect.md",
          "type": "blob",
          "size": 7383
        },
        {
          "path": "plugins/database-cloud-optimization/agents/database-architect.md",
          "type": "blob",
          "size": 16550
        },
        {
          "path": "plugins/database-cloud-optimization/agents/database-optimizer.md",
          "type": "blob",
          "size": 9760
        },
        {
          "path": "plugins/database-cloud-optimization/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/database-cloud-optimization/commands/cost-optimize.md",
          "type": "blob",
          "size": 50747
        },
        {
          "path": "plugins/python-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/agents/django-pro.md",
          "type": "blob",
          "size": 6496
        },
        {
          "path": "plugins/python-development/agents/fastapi-pro.md",
          "type": "blob",
          "size": 5945
        },
        {
          "path": "plugins/python-development/agents/python-pro.md",
          "type": "blob",
          "size": 6728
        },
        {
          "path": "plugins/python-development/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/commands/python-scaffold.md",
          "type": "blob",
          "size": 7261
        },
        {
          "path": "plugins/python-development/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/skills/async-python-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/skills/async-python-patterns/SKILL.md",
          "type": "blob",
          "size": 18730
        },
        {
          "path": "plugins/python-development/skills/python-packaging",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/skills/python-packaging/SKILL.md",
          "type": "blob",
          "size": 18248
        },
        {
          "path": "plugins/python-development/skills/python-performance-optimization",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/skills/python-performance-optimization/SKILL.md",
          "type": "blob",
          "size": 21268
        },
        {
          "path": "plugins/python-development/skills/python-testing-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/skills/python-testing-patterns/SKILL.md",
          "type": "blob",
          "size": 21664
        },
        {
          "path": "plugins/python-development/skills/uv-package-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-development/skills/uv-package-manager/SKILL.md",
          "type": "blob",
          "size": 16048
        }
      ],
      "marketplace": {
        "name": "agents-backend-architecture",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "ai-pilo",
          "email": "",
          "url": "https://github.com/ai-pilo"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "api-scaffolding",
            "description": null,
            "source": "./plugins/api-scaffolding",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install api-scaffolding@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "fastapi-templates",
                "description": "Create production-ready FastAPI projects with async patterns, dependency injection, and comprehensive error handling. Use when building new FastAPI applications or setting up backend API projects.",
                "path": "plugins/api-scaffolding/skills/fastapi-templates/SKILL.md",
                "frontmatter": {
                  "name": "fastapi-templates",
                  "description": "Create production-ready FastAPI projects with async patterns, dependency injection, and comprehensive error handling. Use when building new FastAPI applications or setting up backend API projects."
                },
                "content": "# FastAPI Project Templates\n\nProduction-ready FastAPI project structures with async patterns, dependency injection, middleware, and best practices for building high-performance APIs.\n\n## When to Use This Skill\n\n- Starting new FastAPI projects from scratch\n- Implementing async REST APIs with Python\n- Building high-performance web services and microservices\n- Creating async applications with PostgreSQL, MongoDB\n- Setting up API projects with proper structure and testing\n\n## Core Concepts\n\n### 1. Project Structure\n\n**Recommended Layout:**\n```\napp/\n├── api/                    # API routes\n│   ├── v1/\n│   │   ├── endpoints/\n│   │   │   ├── users.py\n│   │   │   ├── auth.py\n│   │   │   └── items.py\n│   │   └── router.py\n│   └── dependencies.py     # Shared dependencies\n├── core/                   # Core configuration\n│   ├── config.py\n│   ├── security.py\n│   └── database.py\n├── models/                 # Database models\n│   ├── user.py\n│   └── item.py\n├── schemas/                # Pydantic schemas\n│   ├── user.py\n│   └── item.py\n├── services/               # Business logic\n│   ├── user_service.py\n│   └── auth_service.py\n├── repositories/           # Data access\n│   ├── user_repository.py\n│   └── item_repository.py\n└── main.py                 # Application entry\n```\n\n### 2. Dependency Injection\n\nFastAPI's built-in DI system using `Depends`:\n- Database session management\n- Authentication/authorization\n- Shared business logic\n- Configuration injection\n\n### 3. Async Patterns\n\nProper async/await usage:\n- Async route handlers\n- Async database operations\n- Async background tasks\n- Async middleware\n\n## Implementation Patterns\n\n### Pattern 1: Complete FastAPI Application\n\n```python\n# main.py\nfrom fastapi import FastAPI, Depends\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan events.\"\"\"\n    # Startup\n    await database.connect()\n    yield\n    # Shutdown\n    await database.disconnect()\n\napp = FastAPI(\n    title=\"API Template\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n# CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\nfrom app.api.v1.router import api_router\napp.include_router(api_router, prefix=\"/api/v1\")\n\n# core/config.py\nfrom pydantic_settings import BaseSettings\nfrom functools import lru_cache\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings.\"\"\"\n    DATABASE_URL: str\n    SECRET_KEY: str\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n    API_V1_STR: str = \"/api/v1\"\n\n    class Config:\n        env_file = \".env\"\n\n@lru_cache()\ndef get_settings() -> Settings:\n    return Settings()\n\n# core/database.py\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom app.core.config import get_settings\n\nsettings = get_settings()\n\nengine = create_async_engine(\n    settings.DATABASE_URL,\n    echo=True,\n    future=True\n)\n\nAsyncSessionLocal = sessionmaker(\n    engine,\n    class_=AsyncSession,\n    expire_on_commit=False\n)\n\nBase = declarative_base()\n\nasync def get_db() -> AsyncSession:\n    \"\"\"Dependency for database session.\"\"\"\n    async with AsyncSessionLocal() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n        finally:\n            await session.close()\n```\n\n### Pattern 2: CRUD Repository Pattern\n\n```python\n# repositories/base_repository.py\nfrom typing import Generic, TypeVar, Type, Optional, List\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import select\nfrom pydantic import BaseModel\n\nModelType = TypeVar(\"ModelType\")\nCreateSchemaType = TypeVar(\"CreateSchemaType\", bound=BaseModel)\nUpdateSchemaType = TypeVar(\"UpdateSchemaType\", bound=BaseModel)\n\nclass BaseRepository(Generic[ModelType, CreateSchemaType, UpdateSchemaType]):\n    \"\"\"Base repository for CRUD operations.\"\"\"\n\n    def __init__(self, model: Type[ModelType]):\n        self.model = model\n\n    async def get(self, db: AsyncSession, id: int) -> Optional[ModelType]:\n        \"\"\"Get by ID.\"\"\"\n        result = await db.execute(\n            select(self.model).where(self.model.id == id)\n        )\n        return result.scalars().first()\n\n    async def get_multi(\n        self,\n        db: AsyncSession,\n        skip: int = 0,\n        limit: int = 100\n    ) -> List[ModelType]:\n        \"\"\"Get multiple records.\"\"\"\n        result = await db.execute(\n            select(self.model).offset(skip).limit(limit)\n        )\n        return result.scalars().all()\n\n    async def create(\n        self,\n        db: AsyncSession,\n        obj_in: CreateSchemaType\n    ) -> ModelType:\n        \"\"\"Create new record.\"\"\"\n        db_obj = self.model(**obj_in.dict())\n        db.add(db_obj)\n        await db.flush()\n        await db.refresh(db_obj)\n        return db_obj\n\n    async def update(\n        self,\n        db: AsyncSession,\n        db_obj: ModelType,\n        obj_in: UpdateSchemaType\n    ) -> ModelType:\n        \"\"\"Update record.\"\"\"\n        update_data = obj_in.dict(exclude_unset=True)\n        for field, value in update_data.items():\n            setattr(db_obj, field, value)\n        await db.flush()\n        await db.refresh(db_obj)\n        return db_obj\n\n    async def delete(self, db: AsyncSession, id: int) -> bool:\n        \"\"\"Delete record.\"\"\"\n        obj = await self.get(db, id)\n        if obj:\n            await db.delete(obj)\n            return True\n        return False\n\n# repositories/user_repository.py\nfrom app.repositories.base_repository import BaseRepository\nfrom app.models.user import User\nfrom app.schemas.user import UserCreate, UserUpdate\n\nclass UserRepository(BaseRepository[User, UserCreate, UserUpdate]):\n    \"\"\"User-specific repository.\"\"\"\n\n    async def get_by_email(self, db: AsyncSession, email: str) -> Optional[User]:\n        \"\"\"Get user by email.\"\"\"\n        result = await db.execute(\n            select(User).where(User.email == email)\n        )\n        return result.scalars().first()\n\n    async def is_active(self, db: AsyncSession, user_id: int) -> bool:\n        \"\"\"Check if user is active.\"\"\"\n        user = await self.get(db, user_id)\n        return user.is_active if user else False\n\nuser_repository = UserRepository(User)\n```\n\n### Pattern 3: Service Layer\n\n```python\n# services/user_service.py\nfrom typing import Optional\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom app.repositories.user_repository import user_repository\nfrom app.schemas.user import UserCreate, UserUpdate, User\nfrom app.core.security import get_password_hash, verify_password\n\nclass UserService:\n    \"\"\"Business logic for users.\"\"\"\n\n    def __init__(self):\n        self.repository = user_repository\n\n    async def create_user(\n        self,\n        db: AsyncSession,\n        user_in: UserCreate\n    ) -> User:\n        \"\"\"Create new user with hashed password.\"\"\"\n        # Check if email exists\n        existing = await self.repository.get_by_email(db, user_in.email)\n        if existing:\n            raise ValueError(\"Email already registered\")\n\n        # Hash password\n        user_in_dict = user_in.dict()\n        user_in_dict[\"hashed_password\"] = get_password_hash(user_in_dict.pop(\"password\"))\n\n        # Create user\n        user = await self.repository.create(db, UserCreate(**user_in_dict))\n        return user\n\n    async def authenticate(\n        self,\n        db: AsyncSession,\n        email: str,\n        password: str\n    ) -> Optional[User]:\n        \"\"\"Authenticate user.\"\"\"\n        user = await self.repository.get_by_email(db, email)\n        if not user:\n            return None\n        if not verify_password(password, user.hashed_password):\n            return None\n        return user\n\n    async def update_user(\n        self,\n        db: AsyncSession,\n        user_id: int,\n        user_in: UserUpdate\n    ) -> Optional[User]:\n        \"\"\"Update user.\"\"\"\n        user = await self.repository.get(db, user_id)\n        if not user:\n            return None\n\n        if user_in.password:\n            user_in_dict = user_in.dict(exclude_unset=True)\n            user_in_dict[\"hashed_password\"] = get_password_hash(\n                user_in_dict.pop(\"password\")\n            )\n            user_in = UserUpdate(**user_in_dict)\n\n        return await self.repository.update(db, user, user_in)\n\nuser_service = UserService()\n```\n\n### Pattern 4: API Endpoints with Dependencies\n\n```python\n# api/v1/endpoints/users.py\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom typing import List\n\nfrom app.core.database import get_db\nfrom app.schemas.user import User, UserCreate, UserUpdate\nfrom app.services.user_service import user_service\nfrom app.api.dependencies import get_current_user\n\nrouter = APIRouter()\n\n@router.post(\"/\", response_model=User, status_code=status.HTTP_201_CREATED)\nasync def create_user(\n    user_in: UserCreate,\n    db: AsyncSession = Depends(get_db)\n):\n    \"\"\"Create new user.\"\"\"\n    try:\n        user = await user_service.create_user(db, user_in)\n        return user\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@router.get(\"/me\", response_model=User)\nasync def read_current_user(\n    current_user: User = Depends(get_current_user)\n):\n    \"\"\"Get current user.\"\"\"\n    return current_user\n\n@router.get(\"/{user_id}\", response_model=User)\nasync def read_user(\n    user_id: int,\n    db: AsyncSession = Depends(get_db),\n    current_user: User = Depends(get_current_user)\n):\n    \"\"\"Get user by ID.\"\"\"\n    user = await user_service.repository.get(db, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@router.patch(\"/{user_id}\", response_model=User)\nasync def update_user(\n    user_id: int,\n    user_in: UserUpdate,\n    db: AsyncSession = Depends(get_db),\n    current_user: User = Depends(get_current_user)\n):\n    \"\"\"Update user.\"\"\"\n    if current_user.id != user_id:\n        raise HTTPException(status_code=403, detail=\"Not authorized\")\n\n    user = await user_service.update_user(db, user_id, user_in)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return user\n\n@router.delete(\"/{user_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_user(\n    user_id: int,\n    db: AsyncSession = Depends(get_db),\n    current_user: User = Depends(get_current_user)\n):\n    \"\"\"Delete user.\"\"\"\n    if current_user.id != user_id:\n        raise HTTPException(status_code=403, detail=\"Not authorized\")\n\n    deleted = await user_service.repository.delete(db, user_id)\n    if not deleted:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n```\n\n### Pattern 5: Authentication & Authorization\n\n```python\n# core/security.py\nfrom datetime import datetime, timedelta\nfrom typing import Optional\nfrom jose import JWTError, jwt\nfrom passlib.context import CryptContext\nfrom app.core.config import get_settings\n\nsettings = get_settings()\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n\nALGORITHM = \"HS256\"\n\ndef create_access_token(data: dict, expires_delta: Optional[timedelta] = None):\n    \"\"\"Create JWT access token.\"\"\"\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.utcnow() + expires_delta\n    else:\n        expire = datetime.utcnow() + timedelta(minutes=15)\n    to_encode.update({\"exp\": expire})\n    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=ALGORITHM)\n    return encoded_jwt\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    \"\"\"Verify password against hash.\"\"\"\n    return pwd_context.verify(plain_password, hashed_password)\n\ndef get_password_hash(password: str) -> str:\n    \"\"\"Hash password.\"\"\"\n    return pwd_context.hash(password)\n\n# api/dependencies.py\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordBearer\nfrom jose import JWTError, jwt\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.database import get_db\nfrom app.core.security import ALGORITHM\nfrom app.core.config import get_settings\nfrom app.repositories.user_repository import user_repository\n\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=f\"{settings.API_V1_STR}/auth/login\")\n\nasync def get_current_user(\n    db: AsyncSession = Depends(get_db),\n    token: str = Depends(oauth2_scheme)\n):\n    \"\"\"Get current authenticated user.\"\"\"\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n\n    try:\n        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[ALGORITHM])\n        user_id: int = payload.get(\"sub\")\n        if user_id is None:\n            raise credentials_exception\n    except JWTError:\n        raise credentials_exception\n\n    user = await user_repository.get(db, user_id)\n    if user is None:\n        raise credentials_exception\n\n    return user\n```\n\n## Testing\n\n```python\n# tests/conftest.py\nimport pytest\nimport asyncio\nfrom httpx import AsyncClient\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import sessionmaker\n\nfrom app.main import app\nfrom app.core.database import get_db, Base\n\nTEST_DATABASE_URL = \"sqlite+aiosqlite:///:memory:\"\n\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    loop = asyncio.get_event_loop_policy().new_event_loop()\n    yield loop\n    loop.close()\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL, echo=True)\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    AsyncSessionLocal = sessionmaker(\n        engine, class_=AsyncSession, expire_on_commit=False\n    )\n\n    async with AsyncSessionLocal() as session:\n        yield session\n\n@pytest.fixture\nasync def client(db_session):\n    async def override_get_db():\n        yield db_session\n\n    app.dependency_overrides[get_db] = override_get_db\n\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        yield client\n\n# tests/test_users.py\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_create_user(client):\n    response = await client.post(\n        \"/api/v1/users/\",\n        json={\n            \"email\": \"test@example.com\",\n            \"password\": \"testpass123\",\n            \"name\": \"Test User\"\n        }\n    )\n    assert response.status_code == 201\n    data = response.json()\n    assert data[\"email\"] == \"test@example.com\"\n    assert \"id\" in data\n```\n\n## Resources\n\n- **references/fastapi-architecture.md**: Detailed architecture guide\n- **references/async-best-practices.md**: Async/await patterns\n- **references/testing-strategies.md**: Comprehensive testing guide\n- **assets/project-template/**: Complete FastAPI project\n- **assets/docker-compose.yml**: Development environment setup\n\n## Best Practices\n\n1. **Async All The Way**: Use async for database, external APIs\n2. **Dependency Injection**: Leverage FastAPI's DI system\n3. **Repository Pattern**: Separate data access from business logic\n4. **Service Layer**: Keep business logic out of routes\n5. **Pydantic Schemas**: Strong typing for request/response\n6. **Error Handling**: Consistent error responses\n7. **Testing**: Test all layers independently\n\n## Common Pitfalls\n\n- **Blocking Code in Async**: Using synchronous database drivers\n- **No Service Layer**: Business logic in route handlers\n- **Missing Type Hints**: Loses FastAPI's benefits\n- **Ignoring Sessions**: Not properly managing database sessions\n- **No Testing**: Skipping integration tests\n- **Tight Coupling**: Direct database access in routes"
              }
            ]
          },
          {
            "name": "backend-api-security",
            "description": null,
            "source": "./plugins/backend-api-security",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install backend-api-security@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "backend-development",
            "description": null,
            "source": "./plugins/backend-development",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install backend-development@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/feature-development",
                "description": null,
                "path": "plugins/backend-development/commands/feature-development.md",
                "frontmatter": null,
                "content": "Orchestrate end-to-end feature development from requirements to production deployment:\n\n[Extended thinking: This workflow orchestrates specialized agents through comprehensive feature development phases - from discovery and planning through implementation, testing, and deployment. Each phase builds on previous outputs, ensuring coherent feature delivery. The workflow supports multiple development methodologies (traditional, TDD/BDD, DDD), feature complexity levels, and modern deployment strategies including feature flags, gradual rollouts, and observability-first development. Agents receive detailed context from previous phases to maintain consistency and quality throughout the development lifecycle.]\n\n## Configuration Options\n\n### Development Methodology\n- **traditional**: Sequential development with testing after implementation\n- **tdd**: Test-Driven Development with red-green-refactor cycles\n- **bdd**: Behavior-Driven Development with scenario-based testing\n- **ddd**: Domain-Driven Design with bounded contexts and aggregates\n\n### Feature Complexity\n- **simple**: Single service, minimal integration (1-2 days)\n- **medium**: Multiple services, moderate integration (3-5 days)\n- **complex**: Cross-domain, extensive integration (1-2 weeks)\n- **epic**: Major architectural changes, multiple teams (2+ weeks)\n\n### Deployment Strategy\n- **direct**: Immediate rollout to all users\n- **canary**: Gradual rollout starting with 5% of traffic\n- **feature-flag**: Controlled activation via feature toggles\n- **blue-green**: Zero-downtime deployment with instant rollback\n- **a-b-test**: Split traffic for experimentation and metrics\n\n## Phase 1: Discovery & Requirements Planning\n\n1. **Business Analysis & Requirements**\n   - Use Task tool with subagent_type=\"business-analytics::business-analyst\"\n   - Prompt: \"Analyze feature requirements for: $ARGUMENTS. Define user stories, acceptance criteria, success metrics, and business value. Identify stakeholders, dependencies, and risks. Create feature specification document with clear scope boundaries.\"\n   - Expected output: Requirements document with user stories, success metrics, risk assessment\n   - Context: Initial feature request and business context\n\n2. **Technical Architecture Design**\n   - Use Task tool with subagent_type=\"comprehensive-review::architect-review\"\n   - Prompt: \"Design technical architecture for feature: $ARGUMENTS. Using requirements: [include business analysis from step 1]. Define service boundaries, API contracts, data models, integration points, and technology stack. Consider scalability, performance, and security requirements.\"\n   - Expected output: Technical design document with architecture diagrams, API specifications, data models\n   - Context: Business requirements, existing system architecture\n\n3. **Feasibility & Risk Assessment**\n   - Use Task tool with subagent_type=\"security-scanning::security-auditor\"\n   - Prompt: \"Assess security implications and risks for feature: $ARGUMENTS. Review architecture: [include technical design from step 2]. Identify security requirements, compliance needs, data privacy concerns, and potential vulnerabilities.\"\n   - Expected output: Security assessment with risk matrix, compliance checklist, mitigation strategies\n   - Context: Technical design, regulatory requirements\n\n## Phase 2: Implementation & Development\n\n4. **Backend Services Implementation**\n   - Use Task tool with subagent_type=\"backend-architect\"\n   - Prompt: \"Implement backend services for: $ARGUMENTS. Follow technical design: [include architecture from step 2]. Build RESTful/GraphQL APIs, implement business logic, integrate with data layer, add resilience patterns (circuit breakers, retries), implement caching strategies. Include feature flags for gradual rollout.\"\n   - Expected output: Backend services with APIs, business logic, database integration, feature flags\n   - Context: Technical design, API contracts, data models\n\n5. **Frontend Implementation**\n   - Use Task tool with subagent_type=\"frontend-mobile-development::frontend-developer\"\n   - Prompt: \"Build frontend components for: $ARGUMENTS. Integrate with backend APIs: [include API endpoints from step 4]. Implement responsive UI, state management, error handling, loading states, and analytics tracking. Add feature flag integration for A/B testing capabilities.\"\n   - Expected output: Frontend components with API integration, state management, analytics\n   - Context: Backend APIs, UI/UX designs, user stories\n\n6. **Data Pipeline & Integration**\n   - Use Task tool with subagent_type=\"data-engineering::data-engineer\"\n   - Prompt: \"Build data pipelines for: $ARGUMENTS. Design ETL/ELT processes, implement data validation, create analytics events, set up data quality monitoring. Integrate with product analytics platforms for feature usage tracking.\"\n   - Expected output: Data pipelines, analytics events, data quality checks\n   - Context: Data requirements, analytics needs, existing data infrastructure\n\n## Phase 3: Testing & Quality Assurance\n\n7. **Automated Test Suite**\n   - Use Task tool with subagent_type=\"unit-testing::test-automator\"\n   - Prompt: \"Create comprehensive test suite for: $ARGUMENTS. Write unit tests for backend: [from step 4] and frontend: [from step 5]. Add integration tests for API endpoints, E2E tests for critical user journeys, performance tests for scalability validation. Ensure minimum 80% code coverage.\"\n   - Expected output: Test suites with unit, integration, E2E, and performance tests\n   - Context: Implementation code, acceptance criteria, test requirements\n\n8. **Security Validation**\n   - Use Task tool with subagent_type=\"security-scanning::security-auditor\"\n   - Prompt: \"Perform security testing for: $ARGUMENTS. Review implementation: [include backend and frontend from steps 4-5]. Run OWASP checks, penetration testing, dependency scanning, and compliance validation. Verify data encryption, authentication, and authorization.\"\n   - Expected output: Security test results, vulnerability report, remediation actions\n   - Context: Implementation code, security requirements\n\n9. **Performance Optimization**\n   - Use Task tool with subagent_type=\"application-performance::performance-engineer\"\n   - Prompt: \"Optimize performance for: $ARGUMENTS. Analyze backend services: [from step 4] and frontend: [from step 5]. Profile code, optimize queries, implement caching, reduce bundle sizes, improve load times. Set up performance budgets and monitoring.\"\n   - Expected output: Performance improvements, optimization report, performance metrics\n   - Context: Implementation code, performance requirements\n\n## Phase 4: Deployment & Monitoring\n\n10. **Deployment Strategy & Pipeline**\n    - Use Task tool with subagent_type=\"deployment-strategies::deployment-engineer\"\n    - Prompt: \"Prepare deployment for: $ARGUMENTS. Create CI/CD pipeline with automated tests: [from step 7]. Configure feature flags for gradual rollout, implement blue-green deployment, set up rollback procedures. Create deployment runbook and rollback plan.\"\n    - Expected output: CI/CD pipeline, deployment configuration, rollback procedures\n    - Context: Test suites, infrastructure requirements, deployment strategy\n\n11. **Observability & Monitoring**\n    - Use Task tool with subagent_type=\"observability-monitoring::observability-engineer\"\n    - Prompt: \"Set up observability for: $ARGUMENTS. Implement distributed tracing, custom metrics, error tracking, and alerting. Create dashboards for feature usage, performance metrics, error rates, and business KPIs. Set up SLOs/SLIs with automated alerts.\"\n    - Expected output: Monitoring dashboards, alerts, SLO definitions, observability infrastructure\n    - Context: Feature implementation, success metrics, operational requirements\n\n12. **Documentation & Knowledge Transfer**\n    - Use Task tool with subagent_type=\"documentation-generation::docs-architect\"\n    - Prompt: \"Generate comprehensive documentation for: $ARGUMENTS. Create API documentation, user guides, deployment guides, troubleshooting runbooks. Include architecture diagrams, data flow diagrams, and integration guides. Generate automated changelog from commits.\"\n    - Expected output: API docs, user guides, runbooks, architecture documentation\n    - Context: All previous phases' outputs\n\n## Execution Parameters\n\n### Required Parameters\n- **--feature**: Feature name and description\n- **--methodology**: Development approach (traditional|tdd|bdd|ddd)\n- **--complexity**: Feature complexity level (simple|medium|complex|epic)\n\n### Optional Parameters\n- **--deployment-strategy**: Deployment approach (direct|canary|feature-flag|blue-green|a-b-test)\n- **--test-coverage-min**: Minimum test coverage threshold (default: 80%)\n- **--performance-budget**: Performance requirements (e.g., <200ms response time)\n- **--rollout-percentage**: Initial rollout percentage for gradual deployment (default: 5%)\n- **--feature-flag-service**: Feature flag provider (launchdarkly|split|unleash|custom)\n- **--analytics-platform**: Analytics integration (segment|amplitude|mixpanel|custom)\n- **--monitoring-stack**: Observability tools (datadog|newrelic|grafana|custom)\n\n## Success Criteria\n\n- All acceptance criteria from business requirements are met\n- Test coverage exceeds minimum threshold (80% default)\n- Security scan shows no critical vulnerabilities\n- Performance meets defined budgets and SLOs\n- Feature flags configured for controlled rollout\n- Monitoring and alerting fully operational\n- Documentation complete and approved\n- Successful deployment to production with rollback capability\n- Product analytics tracking feature usage\n- A/B test metrics configured (if applicable)\n\n## Rollback Strategy\n\nIf issues arise during or after deployment:\n1. Immediate feature flag disable (< 1 minute)\n2. Blue-green traffic switch (< 5 minutes)\n3. Full deployment rollback via CI/CD (< 15 minutes)\n4. Database migration rollback if needed (coordinate with data team)\n5. Incident post-mortem and fixes before re-deployment\n\nFeature description: $ARGUMENTS"
              }
            ],
            "skills": [
              {
                "name": "api-design-principles",
                "description": "Master REST and GraphQL API design principles to build intuitive, scalable, and maintainable APIs that delight developers. Use when designing new APIs, reviewing API specifications, or establishing API design standards.",
                "path": "plugins/backend-development/skills/api-design-principles/SKILL.md",
                "frontmatter": {
                  "name": "api-design-principles",
                  "description": "Master REST and GraphQL API design principles to build intuitive, scalable, and maintainable APIs that delight developers. Use when designing new APIs, reviewing API specifications, or establishing API design standards."
                },
                "content": "# API Design Principles\n\nMaster REST and GraphQL API design principles to build intuitive, scalable, and maintainable APIs that delight developers and stand the test of time.\n\n## When to Use This Skill\n\n- Designing new REST or GraphQL APIs\n- Refactoring existing APIs for better usability\n- Establishing API design standards for your team\n- Reviewing API specifications before implementation\n- Migrating between API paradigms (REST to GraphQL, etc.)\n- Creating developer-friendly API documentation\n- Optimizing APIs for specific use cases (mobile, third-party integrations)\n\n## Core Concepts\n\n### 1. RESTful Design Principles\n\n**Resource-Oriented Architecture**\n- Resources are nouns (users, orders, products), not verbs\n- Use HTTP methods for actions (GET, POST, PUT, PATCH, DELETE)\n- URLs represent resource hierarchies\n- Consistent naming conventions\n\n**HTTP Methods Semantics:**\n- `GET`: Retrieve resources (idempotent, safe)\n- `POST`: Create new resources\n- `PUT`: Replace entire resource (idempotent)\n- `PATCH`: Partial resource updates\n- `DELETE`: Remove resources (idempotent)\n\n### 2. GraphQL Design Principles\n\n**Schema-First Development**\n- Types define your domain model\n- Queries for reading data\n- Mutations for modifying data\n- Subscriptions for real-time updates\n\n**Query Structure:**\n- Clients request exactly what they need\n- Single endpoint, multiple operations\n- Strongly typed schema\n- Introspection built-in\n\n### 3. API Versioning Strategies\n\n**URL Versioning:**\n```\n/api/v1/users\n/api/v2/users\n```\n\n**Header Versioning:**\n```\nAccept: application/vnd.api+json; version=1\n```\n\n**Query Parameter Versioning:**\n```\n/api/users?version=1\n```\n\n## REST API Design Patterns\n\n### Pattern 1: Resource Collection Design\n\n```python\n# Good: Resource-oriented endpoints\nGET    /api/users              # List users (with pagination)\nPOST   /api/users              # Create user\nGET    /api/users/{id}         # Get specific user\nPUT    /api/users/{id}         # Replace user\nPATCH  /api/users/{id}         # Update user fields\nDELETE /api/users/{id}         # Delete user\n\n# Nested resources\nGET    /api/users/{id}/orders  # Get user's orders\nPOST   /api/users/{id}/orders  # Create order for user\n\n# Bad: Action-oriented endpoints (avoid)\nPOST   /api/createUser\nPOST   /api/getUserById\nPOST   /api/deleteUser\n```\n\n### Pattern 2: Pagination and Filtering\n\n```python\nfrom typing import List, Optional\nfrom pydantic import BaseModel, Field\n\nclass PaginationParams(BaseModel):\n    page: int = Field(1, ge=1, description=\"Page number\")\n    page_size: int = Field(20, ge=1, le=100, description=\"Items per page\")\n\nclass FilterParams(BaseModel):\n    status: Optional[str] = None\n    created_after: Optional[str] = None\n    search: Optional[str] = None\n\nclass PaginatedResponse(BaseModel):\n    items: List[dict]\n    total: int\n    page: int\n    page_size: int\n    pages: int\n\n    @property\n    def has_next(self) -> bool:\n        return self.page < self.pages\n\n    @property\n    def has_prev(self) -> bool:\n        return self.page > 1\n\n# FastAPI endpoint example\nfrom fastapi import FastAPI, Query, Depends\n\napp = FastAPI()\n\n@app.get(\"/api/users\", response_model=PaginatedResponse)\nasync def list_users(\n    page: int = Query(1, ge=1),\n    page_size: int = Query(20, ge=1, le=100),\n    status: Optional[str] = Query(None),\n    search: Optional[str] = Query(None)\n):\n    # Apply filters\n    query = build_query(status=status, search=search)\n\n    # Count total\n    total = await count_users(query)\n\n    # Fetch page\n    offset = (page - 1) * page_size\n    users = await fetch_users(query, limit=page_size, offset=offset)\n\n    return PaginatedResponse(\n        items=users,\n        total=total,\n        page=page,\n        page_size=page_size,\n        pages=(total + page_size - 1) // page_size\n    )\n```\n\n### Pattern 3: Error Handling and Status Codes\n\n```python\nfrom fastapi import HTTPException, status\nfrom pydantic import BaseModel\n\nclass ErrorResponse(BaseModel):\n    error: str\n    message: str\n    details: Optional[dict] = None\n    timestamp: str\n    path: str\n\nclass ValidationErrorDetail(BaseModel):\n    field: str\n    message: str\n    value: Any\n\n# Consistent error responses\nSTATUS_CODES = {\n    \"success\": 200,\n    \"created\": 201,\n    \"no_content\": 204,\n    \"bad_request\": 400,\n    \"unauthorized\": 401,\n    \"forbidden\": 403,\n    \"not_found\": 404,\n    \"conflict\": 409,\n    \"unprocessable\": 422,\n    \"internal_error\": 500\n}\n\ndef raise_not_found(resource: str, id: str):\n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail={\n            \"error\": \"NotFound\",\n            \"message\": f\"{resource} not found\",\n            \"details\": {\"id\": id}\n        }\n    )\n\ndef raise_validation_error(errors: List[ValidationErrorDetail]):\n    raise HTTPException(\n        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n        detail={\n            \"error\": \"ValidationError\",\n            \"message\": \"Request validation failed\",\n            \"details\": {\"errors\": [e.dict() for e in errors]}\n        }\n    )\n\n# Example usage\n@app.get(\"/api/users/{user_id}\")\nasync def get_user(user_id: str):\n    user = await fetch_user(user_id)\n    if not user:\n        raise_not_found(\"User\", user_id)\n    return user\n```\n\n### Pattern 4: HATEOAS (Hypermedia as the Engine of Application State)\n\n```python\nclass UserResponse(BaseModel):\n    id: str\n    name: str\n    email: str\n    _links: dict\n\n    @classmethod\n    def from_user(cls, user: User, base_url: str):\n        return cls(\n            id=user.id,\n            name=user.name,\n            email=user.email,\n            _links={\n                \"self\": {\"href\": f\"{base_url}/api/users/{user.id}\"},\n                \"orders\": {\"href\": f\"{base_url}/api/users/{user.id}/orders\"},\n                \"update\": {\n                    \"href\": f\"{base_url}/api/users/{user.id}\",\n                    \"method\": \"PATCH\"\n                },\n                \"delete\": {\n                    \"href\": f\"{base_url}/api/users/{user.id}\",\n                    \"method\": \"DELETE\"\n                }\n            }\n        )\n```\n\n## GraphQL Design Patterns\n\n### Pattern 1: Schema Design\n\n```graphql\n# schema.graphql\n\n# Clear type definitions\ntype User {\n  id: ID!\n  email: String!\n  name: String!\n  createdAt: DateTime!\n\n  # Relationships\n  orders(\n    first: Int = 20\n    after: String\n    status: OrderStatus\n  ): OrderConnection!\n\n  profile: UserProfile\n}\n\ntype Order {\n  id: ID!\n  status: OrderStatus!\n  total: Money!\n  items: [OrderItem!]!\n  createdAt: DateTime!\n\n  # Back-reference\n  user: User!\n}\n\n# Pagination pattern (Relay-style)\ntype OrderConnection {\n  edges: [OrderEdge!]!\n  pageInfo: PageInfo!\n  totalCount: Int!\n}\n\ntype OrderEdge {\n  node: Order!\n  cursor: String!\n}\n\ntype PageInfo {\n  hasNextPage: Boolean!\n  hasPreviousPage: Boolean!\n  startCursor: String\n  endCursor: String\n}\n\n# Enums for type safety\nenum OrderStatus {\n  PENDING\n  CONFIRMED\n  SHIPPED\n  DELIVERED\n  CANCELLED\n}\n\n# Custom scalars\nscalar DateTime\nscalar Money\n\n# Query root\ntype Query {\n  user(id: ID!): User\n  users(\n    first: Int = 20\n    after: String\n    search: String\n  ): UserConnection!\n\n  order(id: ID!): Order\n}\n\n# Mutation root\ntype Mutation {\n  createUser(input: CreateUserInput!): CreateUserPayload!\n  updateUser(input: UpdateUserInput!): UpdateUserPayload!\n  deleteUser(id: ID!): DeleteUserPayload!\n\n  createOrder(input: CreateOrderInput!): CreateOrderPayload!\n}\n\n# Input types for mutations\ninput CreateUserInput {\n  email: String!\n  name: String!\n  password: String!\n}\n\n# Payload types for mutations\ntype CreateUserPayload {\n  user: User\n  errors: [Error!]\n}\n\ntype Error {\n  field: String\n  message: String!\n}\n```\n\n### Pattern 2: Resolver Design\n\n```python\nfrom typing import Optional, List\nfrom ariadne import QueryType, MutationType, ObjectType\nfrom dataclasses import dataclass\n\nquery = QueryType()\nmutation = MutationType()\nuser_type = ObjectType(\"User\")\n\n@query.field(\"user\")\nasync def resolve_user(obj, info, id: str) -> Optional[dict]:\n    \"\"\"Resolve single user by ID.\"\"\"\n    return await fetch_user_by_id(id)\n\n@query.field(\"users\")\nasync def resolve_users(\n    obj,\n    info,\n    first: int = 20,\n    after: Optional[str] = None,\n    search: Optional[str] = None\n) -> dict:\n    \"\"\"Resolve paginated user list.\"\"\"\n    # Decode cursor\n    offset = decode_cursor(after) if after else 0\n\n    # Fetch users\n    users = await fetch_users(\n        limit=first + 1,  # Fetch one extra to check hasNextPage\n        offset=offset,\n        search=search\n    )\n\n    # Pagination\n    has_next = len(users) > first\n    if has_next:\n        users = users[:first]\n\n    edges = [\n        {\n            \"node\": user,\n            \"cursor\": encode_cursor(offset + i)\n        }\n        for i, user in enumerate(users)\n    ]\n\n    return {\n        \"edges\": edges,\n        \"pageInfo\": {\n            \"hasNextPage\": has_next,\n            \"hasPreviousPage\": offset > 0,\n            \"startCursor\": edges[0][\"cursor\"] if edges else None,\n            \"endCursor\": edges[-1][\"cursor\"] if edges else None\n        },\n        \"totalCount\": await count_users(search=search)\n    }\n\n@user_type.field(\"orders\")\nasync def resolve_user_orders(user: dict, info, first: int = 20) -> dict:\n    \"\"\"Resolve user's orders (N+1 prevention with DataLoader).\"\"\"\n    # Use DataLoader to batch requests\n    loader = info.context[\"loaders\"][\"orders_by_user\"]\n    orders = await loader.load(user[\"id\"])\n\n    return paginate_orders(orders, first)\n\n@mutation.field(\"createUser\")\nasync def resolve_create_user(obj, info, input: dict) -> dict:\n    \"\"\"Create new user.\"\"\"\n    try:\n        # Validate input\n        validate_user_input(input)\n\n        # Create user\n        user = await create_user(\n            email=input[\"email\"],\n            name=input[\"name\"],\n            password=hash_password(input[\"password\"])\n        )\n\n        return {\n            \"user\": user,\n            \"errors\": []\n        }\n    except ValidationError as e:\n        return {\n            \"user\": None,\n            \"errors\": [{\"field\": e.field, \"message\": e.message}]\n        }\n```\n\n### Pattern 3: DataLoader (N+1 Problem Prevention)\n\n```python\nfrom aiodataloader import DataLoader\nfrom typing import List, Optional\n\nclass UserLoader(DataLoader):\n    \"\"\"Batch load users by ID.\"\"\"\n\n    async def batch_load_fn(self, user_ids: List[str]) -> List[Optional[dict]]:\n        \"\"\"Load multiple users in single query.\"\"\"\n        users = await fetch_users_by_ids(user_ids)\n\n        # Map results back to input order\n        user_map = {user[\"id\"]: user for user in users}\n        return [user_map.get(user_id) for user_id in user_ids]\n\nclass OrdersByUserLoader(DataLoader):\n    \"\"\"Batch load orders by user ID.\"\"\"\n\n    async def batch_load_fn(self, user_ids: List[str]) -> List[List[dict]]:\n        \"\"\"Load orders for multiple users in single query.\"\"\"\n        orders = await fetch_orders_by_user_ids(user_ids)\n\n        # Group orders by user_id\n        orders_by_user = {}\n        for order in orders:\n            user_id = order[\"user_id\"]\n            if user_id not in orders_by_user:\n                orders_by_user[user_id] = []\n            orders_by_user[user_id].append(order)\n\n        # Return in input order\n        return [orders_by_user.get(user_id, []) for user_id in user_ids]\n\n# Context setup\ndef create_context():\n    return {\n        \"loaders\": {\n            \"user\": UserLoader(),\n            \"orders_by_user\": OrdersByUserLoader()\n        }\n    }\n```\n\n## Best Practices\n\n### REST APIs\n1. **Consistent Naming**: Use plural nouns for collections (`/users`, not `/user`)\n2. **Stateless**: Each request contains all necessary information\n3. **Use HTTP Status Codes Correctly**: 2xx success, 4xx client errors, 5xx server errors\n4. **Version Your API**: Plan for breaking changes from day one\n5. **Pagination**: Always paginate large collections\n6. **Rate Limiting**: Protect your API with rate limits\n7. **Documentation**: Use OpenAPI/Swagger for interactive docs\n\n### GraphQL APIs\n1. **Schema First**: Design schema before writing resolvers\n2. **Avoid N+1**: Use DataLoaders for efficient data fetching\n3. **Input Validation**: Validate at schema and resolver levels\n4. **Error Handling**: Return structured errors in mutation payloads\n5. **Pagination**: Use cursor-based pagination (Relay spec)\n6. **Deprecation**: Use `@deprecated` directive for gradual migration\n7. **Monitoring**: Track query complexity and execution time\n\n## Common Pitfalls\n\n- **Over-fetching/Under-fetching (REST)**: Fixed in GraphQL but requires DataLoaders\n- **Breaking Changes**: Version APIs or use deprecation strategies\n- **Inconsistent Error Formats**: Standardize error responses\n- **Missing Rate Limits**: APIs without limits are vulnerable to abuse\n- **Poor Documentation**: Undocumented APIs frustrate developers\n- **Ignoring HTTP Semantics**: POST for idempotent operations breaks expectations\n- **Tight Coupling**: API structure shouldn't mirror database schema\n\n## Resources\n\n- **references/rest-best-practices.md**: Comprehensive REST API design guide\n- **references/graphql-schema-design.md**: GraphQL schema patterns and anti-patterns\n- **references/api-versioning-strategies.md**: Versioning approaches and migration paths\n- **assets/rest-api-template.py**: FastAPI REST API template\n- **assets/graphql-schema-template.graphql**: Complete GraphQL schema example\n- **assets/api-design-checklist.md**: Pre-implementation review checklist\n- **scripts/openapi-generator.py**: Generate OpenAPI specs from code"
              },
              {
                "name": "architecture-patterns",
                "description": "Implement proven backend architecture patterns including Clean Architecture, Hexagonal Architecture, and Domain-Driven Design. Use when architecting complex backend systems or refactoring existing applications for better maintainability.",
                "path": "plugins/backend-development/skills/architecture-patterns/SKILL.md",
                "frontmatter": {
                  "name": "architecture-patterns",
                  "description": "Implement proven backend architecture patterns including Clean Architecture, Hexagonal Architecture, and Domain-Driven Design. Use when architecting complex backend systems or refactoring existing applications for better maintainability."
                },
                "content": "# Architecture Patterns\n\nMaster proven backend architecture patterns including Clean Architecture, Hexagonal Architecture, and Domain-Driven Design to build maintainable, testable, and scalable systems.\n\n## When to Use This Skill\n\n- Designing new backend systems from scratch\n- Refactoring monolithic applications for better maintainability\n- Establishing architecture standards for your team\n- Migrating from tightly coupled to loosely coupled architectures\n- Implementing domain-driven design principles\n- Creating testable and mockable codebases\n- Planning microservices decomposition\n\n## Core Concepts\n\n### 1. Clean Architecture (Uncle Bob)\n\n**Layers (dependency flows inward):**\n- **Entities**: Core business models\n- **Use Cases**: Application business rules\n- **Interface Adapters**: Controllers, presenters, gateways\n- **Frameworks & Drivers**: UI, database, external services\n\n**Key Principles:**\n- Dependencies point inward\n- Inner layers know nothing about outer layers\n- Business logic independent of frameworks\n- Testable without UI, database, or external services\n\n### 2. Hexagonal Architecture (Ports and Adapters)\n\n**Components:**\n- **Domain Core**: Business logic\n- **Ports**: Interfaces defining interactions\n- **Adapters**: Implementations of ports (database, REST, message queue)\n\n**Benefits:**\n- Swap implementations easily (mock for testing)\n- Technology-agnostic core\n- Clear separation of concerns\n\n### 3. Domain-Driven Design (DDD)\n\n**Strategic Patterns:**\n- **Bounded Contexts**: Separate models for different domains\n- **Context Mapping**: How contexts relate\n- **Ubiquitous Language**: Shared terminology\n\n**Tactical Patterns:**\n- **Entities**: Objects with identity\n- **Value Objects**: Immutable objects defined by attributes\n- **Aggregates**: Consistency boundaries\n- **Repositories**: Data access abstraction\n- **Domain Events**: Things that happened\n\n## Clean Architecture Pattern\n\n### Directory Structure\n```\napp/\n├── domain/           # Entities & business rules\n│   ├── entities/\n│   │   ├── user.py\n│   │   └── order.py\n│   ├── value_objects/\n│   │   ├── email.py\n│   │   └── money.py\n│   └── interfaces/   # Abstract interfaces\n│       ├── user_repository.py\n│       └── payment_gateway.py\n├── use_cases/        # Application business rules\n│   ├── create_user.py\n│   ├── process_order.py\n│   └── send_notification.py\n├── adapters/         # Interface implementations\n│   ├── repositories/\n│   │   ├── postgres_user_repository.py\n│   │   └── redis_cache_repository.py\n│   ├── controllers/\n│   │   └── user_controller.py\n│   └── gateways/\n│       ├── stripe_payment_gateway.py\n│       └── sendgrid_email_gateway.py\n└── infrastructure/   # Framework & external concerns\n    ├── database.py\n    ├── config.py\n    └── logging.py\n```\n\n### Implementation Example\n\n```python\n# domain/entities/user.py\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional\n\n@dataclass\nclass User:\n    \"\"\"Core user entity - no framework dependencies.\"\"\"\n    id: str\n    email: str\n    name: str\n    created_at: datetime\n    is_active: bool = True\n\n    def deactivate(self):\n        \"\"\"Business rule: deactivating user.\"\"\"\n        self.is_active = False\n\n    def can_place_order(self) -> bool:\n        \"\"\"Business rule: active users can order.\"\"\"\n        return self.is_active\n\n# domain/interfaces/user_repository.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, List\nfrom domain.entities.user import User\n\nclass IUserRepository(ABC):\n    \"\"\"Port: defines contract, no implementation.\"\"\"\n\n    @abstractmethod\n    async def find_by_id(self, user_id: str) -> Optional[User]:\n        pass\n\n    @abstractmethod\n    async def find_by_email(self, email: str) -> Optional[User]:\n        pass\n\n    @abstractmethod\n    async def save(self, user: User) -> User:\n        pass\n\n    @abstractmethod\n    async def delete(self, user_id: str) -> bool:\n        pass\n\n# use_cases/create_user.py\nfrom domain.entities.user import User\nfrom domain.interfaces.user_repository import IUserRepository\nfrom dataclasses import dataclass\nfrom datetime import datetime\nimport uuid\n\n@dataclass\nclass CreateUserRequest:\n    email: str\n    name: str\n\n@dataclass\nclass CreateUserResponse:\n    user: User\n    success: bool\n    error: Optional[str] = None\n\nclass CreateUserUseCase:\n    \"\"\"Use case: orchestrates business logic.\"\"\"\n\n    def __init__(self, user_repository: IUserRepository):\n        self.user_repository = user_repository\n\n    async def execute(self, request: CreateUserRequest) -> CreateUserResponse:\n        # Business validation\n        existing = await self.user_repository.find_by_email(request.email)\n        if existing:\n            return CreateUserResponse(\n                user=None,\n                success=False,\n                error=\"Email already exists\"\n            )\n\n        # Create entity\n        user = User(\n            id=str(uuid.uuid4()),\n            email=request.email,\n            name=request.name,\n            created_at=datetime.now(),\n            is_active=True\n        )\n\n        # Persist\n        saved_user = await self.user_repository.save(user)\n\n        return CreateUserResponse(\n            user=saved_user,\n            success=True\n        )\n\n# adapters/repositories/postgres_user_repository.py\nfrom domain.interfaces.user_repository import IUserRepository\nfrom domain.entities.user import User\nfrom typing import Optional\nimport asyncpg\n\nclass PostgresUserRepository(IUserRepository):\n    \"\"\"Adapter: PostgreSQL implementation.\"\"\"\n\n    def __init__(self, pool: asyncpg.Pool):\n        self.pool = pool\n\n    async def find_by_id(self, user_id: str) -> Optional[User]:\n        async with self.pool.acquire() as conn:\n            row = await conn.fetchrow(\n                \"SELECT * FROM users WHERE id = $1\", user_id\n            )\n            return self._to_entity(row) if row else None\n\n    async def find_by_email(self, email: str) -> Optional[User]:\n        async with self.pool.acquire() as conn:\n            row = await conn.fetchrow(\n                \"SELECT * FROM users WHERE email = $1\", email\n            )\n            return self._to_entity(row) if row else None\n\n    async def save(self, user: User) -> User:\n        async with self.pool.acquire() as conn:\n            await conn.execute(\n                \"\"\"\n                INSERT INTO users (id, email, name, created_at, is_active)\n                VALUES ($1, $2, $3, $4, $5)\n                ON CONFLICT (id) DO UPDATE\n                SET email = $2, name = $3, is_active = $5\n                \"\"\",\n                user.id, user.email, user.name, user.created_at, user.is_active\n            )\n            return user\n\n    async def delete(self, user_id: str) -> bool:\n        async with self.pool.acquire() as conn:\n            result = await conn.execute(\n                \"DELETE FROM users WHERE id = $1\", user_id\n            )\n            return result == \"DELETE 1\"\n\n    def _to_entity(self, row) -> User:\n        \"\"\"Map database row to entity.\"\"\"\n        return User(\n            id=row[\"id\"],\n            email=row[\"email\"],\n            name=row[\"name\"],\n            created_at=row[\"created_at\"],\n            is_active=row[\"is_active\"]\n        )\n\n# adapters/controllers/user_controller.py\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom use_cases.create_user import CreateUserUseCase, CreateUserRequest\nfrom pydantic import BaseModel\n\nrouter = APIRouter()\n\nclass CreateUserDTO(BaseModel):\n    email: str\n    name: str\n\n@router.post(\"/users\")\nasync def create_user(\n    dto: CreateUserDTO,\n    use_case: CreateUserUseCase = Depends(get_create_user_use_case)\n):\n    \"\"\"Controller: handles HTTP concerns only.\"\"\"\n    request = CreateUserRequest(email=dto.email, name=dto.name)\n    response = await use_case.execute(request)\n\n    if not response.success:\n        raise HTTPException(status_code=400, detail=response.error)\n\n    return {\"user\": response.user}\n```\n\n## Hexagonal Architecture Pattern\n\n```python\n# Core domain (hexagon center)\nclass OrderService:\n    \"\"\"Domain service - no infrastructure dependencies.\"\"\"\n\n    def __init__(\n        self,\n        order_repository: OrderRepositoryPort,\n        payment_gateway: PaymentGatewayPort,\n        notification_service: NotificationPort\n    ):\n        self.orders = order_repository\n        self.payments = payment_gateway\n        self.notifications = notification_service\n\n    async def place_order(self, order: Order) -> OrderResult:\n        # Business logic\n        if not order.is_valid():\n            return OrderResult(success=False, error=\"Invalid order\")\n\n        # Use ports (interfaces)\n        payment = await self.payments.charge(\n            amount=order.total,\n            customer=order.customer_id\n        )\n\n        if not payment.success:\n            return OrderResult(success=False, error=\"Payment failed\")\n\n        order.mark_as_paid()\n        saved_order = await self.orders.save(order)\n\n        await self.notifications.send(\n            to=order.customer_email,\n            subject=\"Order confirmed\",\n            body=f\"Order {order.id} confirmed\"\n        )\n\n        return OrderResult(success=True, order=saved_order)\n\n# Ports (interfaces)\nclass OrderRepositoryPort(ABC):\n    @abstractmethod\n    async def save(self, order: Order) -> Order:\n        pass\n\nclass PaymentGatewayPort(ABC):\n    @abstractmethod\n    async def charge(self, amount: Money, customer: str) -> PaymentResult:\n        pass\n\nclass NotificationPort(ABC):\n    @abstractmethod\n    async def send(self, to: str, subject: str, body: str):\n        pass\n\n# Adapters (implementations)\nclass StripePaymentAdapter(PaymentGatewayPort):\n    \"\"\"Primary adapter: connects to Stripe API.\"\"\"\n\n    def __init__(self, api_key: str):\n        self.stripe = stripe\n        self.stripe.api_key = api_key\n\n    async def charge(self, amount: Money, customer: str) -> PaymentResult:\n        try:\n            charge = self.stripe.Charge.create(\n                amount=amount.cents,\n                currency=amount.currency,\n                customer=customer\n            )\n            return PaymentResult(success=True, transaction_id=charge.id)\n        except stripe.error.CardError as e:\n            return PaymentResult(success=False, error=str(e))\n\nclass MockPaymentAdapter(PaymentGatewayPort):\n    \"\"\"Test adapter: no external dependencies.\"\"\"\n\n    async def charge(self, amount: Money, customer: str) -> PaymentResult:\n        return PaymentResult(success=True, transaction_id=\"mock-123\")\n```\n\n## Domain-Driven Design Pattern\n\n```python\n# Value Objects (immutable)\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass(frozen=True)\nclass Email:\n    \"\"\"Value object: validated email.\"\"\"\n    value: str\n\n    def __post_init__(self):\n        if \"@\" not in self.value:\n            raise ValueError(\"Invalid email\")\n\n@dataclass(frozen=True)\nclass Money:\n    \"\"\"Value object: amount with currency.\"\"\"\n    amount: int  # cents\n    currency: str\n\n    def add(self, other: \"Money\") -> \"Money\":\n        if self.currency != other.currency:\n            raise ValueError(\"Currency mismatch\")\n        return Money(self.amount + other.amount, self.currency)\n\n# Entities (with identity)\nclass Order:\n    \"\"\"Entity: has identity, mutable state.\"\"\"\n\n    def __init__(self, id: str, customer: Customer):\n        self.id = id\n        self.customer = customer\n        self.items: List[OrderItem] = []\n        self.status = OrderStatus.PENDING\n        self._events: List[DomainEvent] = []\n\n    def add_item(self, product: Product, quantity: int):\n        \"\"\"Business logic in entity.\"\"\"\n        item = OrderItem(product, quantity)\n        self.items.append(item)\n        self._events.append(ItemAddedEvent(self.id, item))\n\n    def total(self) -> Money:\n        \"\"\"Calculated property.\"\"\"\n        return sum(item.subtotal() for item in self.items)\n\n    def submit(self):\n        \"\"\"State transition with business rules.\"\"\"\n        if not self.items:\n            raise ValueError(\"Cannot submit empty order\")\n        if self.status != OrderStatus.PENDING:\n            raise ValueError(\"Order already submitted\")\n\n        self.status = OrderStatus.SUBMITTED\n        self._events.append(OrderSubmittedEvent(self.id))\n\n# Aggregates (consistency boundary)\nclass Customer:\n    \"\"\"Aggregate root: controls access to entities.\"\"\"\n\n    def __init__(self, id: str, email: Email):\n        self.id = id\n        self.email = email\n        self._addresses: List[Address] = []\n        self._orders: List[str] = []  # Order IDs, not full objects\n\n    def add_address(self, address: Address):\n        \"\"\"Aggregate enforces invariants.\"\"\"\n        if len(self._addresses) >= 5:\n            raise ValueError(\"Maximum 5 addresses allowed\")\n        self._addresses.append(address)\n\n    @property\n    def primary_address(self) -> Optional[Address]:\n        return next((a for a in self._addresses if a.is_primary), None)\n\n# Domain Events\n@dataclass\nclass OrderSubmittedEvent:\n    order_id: str\n    occurred_at: datetime = field(default_factory=datetime.now)\n\n# Repository (aggregate persistence)\nclass OrderRepository:\n    \"\"\"Repository: persist/retrieve aggregates.\"\"\"\n\n    async def find_by_id(self, order_id: str) -> Optional[Order]:\n        \"\"\"Reconstitute aggregate from storage.\"\"\"\n        pass\n\n    async def save(self, order: Order):\n        \"\"\"Persist aggregate and publish events.\"\"\"\n        await self._persist(order)\n        await self._publish_events(order._events)\n        order._events.clear()\n```\n\n## Resources\n\n- **references/clean-architecture-guide.md**: Detailed layer breakdown\n- **references/hexagonal-architecture-guide.md**: Ports and adapters patterns\n- **references/ddd-tactical-patterns.md**: Entities, value objects, aggregates\n- **assets/clean-architecture-template/**: Complete project structure\n- **assets/ddd-examples/**: Domain modeling examples\n\n## Best Practices\n\n1. **Dependency Rule**: Dependencies always point inward\n2. **Interface Segregation**: Small, focused interfaces\n3. **Business Logic in Domain**: Keep frameworks out of core\n4. **Test Independence**: Core testable without infrastructure\n5. **Bounded Contexts**: Clear domain boundaries\n6. **Ubiquitous Language**: Consistent terminology\n7. **Thin Controllers**: Delegate to use cases\n8. **Rich Domain Models**: Behavior with data\n\n## Common Pitfalls\n\n- **Anemic Domain**: Entities with only data, no behavior\n- **Framework Coupling**: Business logic depends on frameworks\n- **Fat Controllers**: Business logic in controllers\n- **Repository Leakage**: Exposing ORM objects\n- **Missing Abstractions**: Concrete dependencies in core\n- **Over-Engineering**: Clean architecture for simple CRUD"
              },
              {
                "name": "microservices-patterns",
                "description": "Design microservices architectures with service boundaries, event-driven communication, and resilience patterns. Use when building distributed systems, decomposing monoliths, or implementing microservices.",
                "path": "plugins/backend-development/skills/microservices-patterns/SKILL.md",
                "frontmatter": {
                  "name": "microservices-patterns",
                  "description": "Design microservices architectures with service boundaries, event-driven communication, and resilience patterns. Use when building distributed systems, decomposing monoliths, or implementing microservices."
                },
                "content": "# Microservices Patterns\n\nMaster microservices architecture patterns including service boundaries, inter-service communication, data management, and resilience patterns for building distributed systems.\n\n## When to Use This Skill\n\n- Decomposing monoliths into microservices\n- Designing service boundaries and contracts\n- Implementing inter-service communication\n- Managing distributed data and transactions\n- Building resilient distributed systems\n- Implementing service discovery and load balancing\n- Designing event-driven architectures\n\n## Core Concepts\n\n### 1. Service Decomposition Strategies\n\n**By Business Capability**\n- Organize services around business functions\n- Each service owns its domain\n- Example: OrderService, PaymentService, InventoryService\n\n**By Subdomain (DDD)**\n- Core domain, supporting subdomains\n- Bounded contexts map to services\n- Clear ownership and responsibility\n\n**Strangler Fig Pattern**\n- Gradually extract from monolith\n- New functionality as microservices\n- Proxy routes to old/new systems\n\n### 2. Communication Patterns\n\n**Synchronous (Request/Response)**\n- REST APIs\n- gRPC\n- GraphQL\n\n**Asynchronous (Events/Messages)**\n- Event streaming (Kafka)\n- Message queues (RabbitMQ, SQS)\n- Pub/Sub patterns\n\n### 3. Data Management\n\n**Database Per Service**\n- Each service owns its data\n- No shared databases\n- Loose coupling\n\n**Saga Pattern**\n- Distributed transactions\n- Compensating actions\n- Eventual consistency\n\n### 4. Resilience Patterns\n\n**Circuit Breaker**\n- Fail fast on repeated errors\n- Prevent cascade failures\n\n**Retry with Backoff**\n- Transient fault handling\n- Exponential backoff\n\n**Bulkhead**\n- Isolate resources\n- Limit impact of failures\n\n## Service Decomposition Patterns\n\n### Pattern 1: By Business Capability\n\n```python\n# E-commerce example\n\n# Order Service\nclass OrderService:\n    \"\"\"Handles order lifecycle.\"\"\"\n\n    async def create_order(self, order_data: dict) -> Order:\n        order = Order.create(order_data)\n\n        # Publish event for other services\n        await self.event_bus.publish(\n            OrderCreatedEvent(\n                order_id=order.id,\n                customer_id=order.customer_id,\n                items=order.items,\n                total=order.total\n            )\n        )\n\n        return order\n\n# Payment Service (separate service)\nclass PaymentService:\n    \"\"\"Handles payment processing.\"\"\"\n\n    async def process_payment(self, payment_request: PaymentRequest) -> PaymentResult:\n        # Process payment\n        result = await self.payment_gateway.charge(\n            amount=payment_request.amount,\n            customer=payment_request.customer_id\n        )\n\n        if result.success:\n            await self.event_bus.publish(\n                PaymentCompletedEvent(\n                    order_id=payment_request.order_id,\n                    transaction_id=result.transaction_id\n                )\n            )\n\n        return result\n\n# Inventory Service (separate service)\nclass InventoryService:\n    \"\"\"Handles inventory management.\"\"\"\n\n    async def reserve_items(self, order_id: str, items: List[OrderItem]) -> ReservationResult:\n        # Check availability\n        for item in items:\n            available = await self.inventory_repo.get_available(item.product_id)\n            if available < item.quantity:\n                return ReservationResult(\n                    success=False,\n                    error=f\"Insufficient inventory for {item.product_id}\"\n                )\n\n        # Reserve items\n        reservation = await self.create_reservation(order_id, items)\n\n        await self.event_bus.publish(\n            InventoryReservedEvent(\n                order_id=order_id,\n                reservation_id=reservation.id\n            )\n        )\n\n        return ReservationResult(success=True, reservation=reservation)\n```\n\n### Pattern 2: API Gateway\n\n```python\nfrom fastapi import FastAPI, HTTPException, Depends\nimport httpx\nfrom circuitbreaker import circuit\n\napp = FastAPI()\n\nclass APIGateway:\n    \"\"\"Central entry point for all client requests.\"\"\"\n\n    def __init__(self):\n        self.order_service_url = \"http://order-service:8000\"\n        self.payment_service_url = \"http://payment-service:8001\"\n        self.inventory_service_url = \"http://inventory-service:8002\"\n        self.http_client = httpx.AsyncClient(timeout=5.0)\n\n    @circuit(failure_threshold=5, recovery_timeout=30)\n    async def call_order_service(self, path: str, method: str = \"GET\", **kwargs):\n        \"\"\"Call order service with circuit breaker.\"\"\"\n        response = await self.http_client.request(\n            method,\n            f\"{self.order_service_url}{path}\",\n            **kwargs\n        )\n        response.raise_for_status()\n        return response.json()\n\n    async def create_order_aggregate(self, order_id: str) -> dict:\n        \"\"\"Aggregate data from multiple services.\"\"\"\n        # Parallel requests\n        order, payment, inventory = await asyncio.gather(\n            self.call_order_service(f\"/orders/{order_id}\"),\n            self.call_payment_service(f\"/payments/order/{order_id}\"),\n            self.call_inventory_service(f\"/reservations/order/{order_id}\"),\n            return_exceptions=True\n        )\n\n        # Handle partial failures\n        result = {\"order\": order}\n        if not isinstance(payment, Exception):\n            result[\"payment\"] = payment\n        if not isinstance(inventory, Exception):\n            result[\"inventory\"] = inventory\n\n        return result\n\n@app.post(\"/api/orders\")\nasync def create_order(\n    order_data: dict,\n    gateway: APIGateway = Depends()\n):\n    \"\"\"API Gateway endpoint.\"\"\"\n    try:\n        # Route to order service\n        order = await gateway.call_order_service(\n            \"/orders\",\n            method=\"POST\",\n            json=order_data\n        )\n        return {\"order\": order}\n    except httpx.HTTPError as e:\n        raise HTTPException(status_code=503, detail=\"Order service unavailable\")\n```\n\n## Communication Patterns\n\n### Pattern 1: Synchronous REST Communication\n\n```python\n# Service A calls Service B\nimport httpx\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nclass ServiceClient:\n    \"\"\"HTTP client with retries and timeout.\"\"\"\n\n    def __init__(self, base_url: str):\n        self.base_url = base_url\n        self.client = httpx.AsyncClient(\n            timeout=httpx.Timeout(5.0, connect=2.0),\n            limits=httpx.Limits(max_keepalive_connections=20)\n        )\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=2, max=10)\n    )\n    async def get(self, path: str, **kwargs):\n        \"\"\"GET with automatic retries.\"\"\"\n        response = await self.client.get(f\"{self.base_url}{path}\", **kwargs)\n        response.raise_for_status()\n        return response.json()\n\n    async def post(self, path: str, **kwargs):\n        \"\"\"POST request.\"\"\"\n        response = await self.client.post(f\"{self.base_url}{path}\", **kwargs)\n        response.raise_for_status()\n        return response.json()\n\n# Usage\npayment_client = ServiceClient(\"http://payment-service:8001\")\nresult = await payment_client.post(\"/payments\", json=payment_data)\n```\n\n### Pattern 2: Asynchronous Event-Driven\n\n```python\n# Event-driven communication with Kafka\nfrom aiokafka import AIOKafkaProducer, AIOKafkaConsumer\nimport json\nfrom dataclasses import dataclass, asdict\nfrom datetime import datetime\n\n@dataclass\nclass DomainEvent:\n    event_id: str\n    event_type: str\n    aggregate_id: str\n    occurred_at: datetime\n    data: dict\n\nclass EventBus:\n    \"\"\"Event publishing and subscription.\"\"\"\n\n    def __init__(self, bootstrap_servers: List[str]):\n        self.bootstrap_servers = bootstrap_servers\n        self.producer = None\n\n    async def start(self):\n        self.producer = AIOKafkaProducer(\n            bootstrap_servers=self.bootstrap_servers,\n            value_serializer=lambda v: json.dumps(v).encode()\n        )\n        await self.producer.start()\n\n    async def publish(self, event: DomainEvent):\n        \"\"\"Publish event to Kafka topic.\"\"\"\n        topic = event.event_type\n        await self.producer.send_and_wait(\n            topic,\n            value=asdict(event),\n            key=event.aggregate_id.encode()\n        )\n\n    async def subscribe(self, topic: str, handler: callable):\n        \"\"\"Subscribe to events.\"\"\"\n        consumer = AIOKafkaConsumer(\n            topic,\n            bootstrap_servers=self.bootstrap_servers,\n            value_deserializer=lambda v: json.loads(v.decode()),\n            group_id=\"my-service\"\n        )\n        await consumer.start()\n\n        try:\n            async for message in consumer:\n                event_data = message.value\n                await handler(event_data)\n        finally:\n            await consumer.stop()\n\n# Order Service publishes event\nasync def create_order(order_data: dict):\n    order = await save_order(order_data)\n\n    event = DomainEvent(\n        event_id=str(uuid.uuid4()),\n        event_type=\"OrderCreated\",\n        aggregate_id=order.id,\n        occurred_at=datetime.now(),\n        data={\n            \"order_id\": order.id,\n            \"customer_id\": order.customer_id,\n            \"total\": order.total\n        }\n    )\n\n    await event_bus.publish(event)\n\n# Inventory Service listens for OrderCreated\nasync def handle_order_created(event_data: dict):\n    \"\"\"React to order creation.\"\"\"\n    order_id = event_data[\"data\"][\"order_id\"]\n    items = event_data[\"data\"][\"items\"]\n\n    # Reserve inventory\n    await reserve_inventory(order_id, items)\n```\n\n### Pattern 3: Saga Pattern (Distributed Transactions)\n\n```python\n# Saga orchestration for order fulfillment\nfrom enum import Enum\nfrom typing import List, Callable\n\nclass SagaStep:\n    \"\"\"Single step in saga.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        action: Callable,\n        compensation: Callable\n    ):\n        self.name = name\n        self.action = action\n        self.compensation = compensation\n\nclass SagaStatus(Enum):\n    PENDING = \"pending\"\n    COMPLETED = \"completed\"\n    COMPENSATING = \"compensating\"\n    FAILED = \"failed\"\n\nclass OrderFulfillmentSaga:\n    \"\"\"Orchestrated saga for order fulfillment.\"\"\"\n\n    def __init__(self):\n        self.steps: List[SagaStep] = [\n            SagaStep(\n                \"create_order\",\n                action=self.create_order,\n                compensation=self.cancel_order\n            ),\n            SagaStep(\n                \"reserve_inventory\",\n                action=self.reserve_inventory,\n                compensation=self.release_inventory\n            ),\n            SagaStep(\n                \"process_payment\",\n                action=self.process_payment,\n                compensation=self.refund_payment\n            ),\n            SagaStep(\n                \"confirm_order\",\n                action=self.confirm_order,\n                compensation=self.cancel_order_confirmation\n            )\n        ]\n\n    async def execute(self, order_data: dict) -> SagaResult:\n        \"\"\"Execute saga steps.\"\"\"\n        completed_steps = []\n        context = {\"order_data\": order_data}\n\n        try:\n            for step in self.steps:\n                # Execute step\n                result = await step.action(context)\n                if not result.success:\n                    # Compensate\n                    await self.compensate(completed_steps, context)\n                    return SagaResult(\n                        status=SagaStatus.FAILED,\n                        error=result.error\n                    )\n\n                completed_steps.append(step)\n                context.update(result.data)\n\n            return SagaResult(status=SagaStatus.COMPLETED, data=context)\n\n        except Exception as e:\n            # Compensate on error\n            await self.compensate(completed_steps, context)\n            return SagaResult(status=SagaStatus.FAILED, error=str(e))\n\n    async def compensate(self, completed_steps: List[SagaStep], context: dict):\n        \"\"\"Execute compensating actions in reverse order.\"\"\"\n        for step in reversed(completed_steps):\n            try:\n                await step.compensation(context)\n            except Exception as e:\n                # Log compensation failure\n                print(f\"Compensation failed for {step.name}: {e}\")\n\n    # Step implementations\n    async def create_order(self, context: dict) -> StepResult:\n        order = await order_service.create(context[\"order_data\"])\n        return StepResult(success=True, data={\"order_id\": order.id})\n\n    async def cancel_order(self, context: dict):\n        await order_service.cancel(context[\"order_id\"])\n\n    async def reserve_inventory(self, context: dict) -> StepResult:\n        result = await inventory_service.reserve(\n            context[\"order_id\"],\n            context[\"order_data\"][\"items\"]\n        )\n        return StepResult(\n            success=result.success,\n            data={\"reservation_id\": result.reservation_id}\n        )\n\n    async def release_inventory(self, context: dict):\n        await inventory_service.release(context[\"reservation_id\"])\n\n    async def process_payment(self, context: dict) -> StepResult:\n        result = await payment_service.charge(\n            context[\"order_id\"],\n            context[\"order_data\"][\"total\"]\n        )\n        return StepResult(\n            success=result.success,\n            data={\"transaction_id\": result.transaction_id},\n            error=result.error\n        )\n\n    async def refund_payment(self, context: dict):\n        await payment_service.refund(context[\"transaction_id\"])\n```\n\n## Resilience Patterns\n\n### Circuit Breaker Pattern\n\n```python\nfrom enum import Enum\nfrom datetime import datetime, timedelta\nfrom typing import Callable, Any\n\nclass CircuitState(Enum):\n    CLOSED = \"closed\"  # Normal operation\n    OPEN = \"open\"      # Failing, reject requests\n    HALF_OPEN = \"half_open\"  # Testing if recovered\n\nclass CircuitBreaker:\n    \"\"\"Circuit breaker for service calls.\"\"\"\n\n    def __init__(\n        self,\n        failure_threshold: int = 5,\n        recovery_timeout: int = 30,\n        success_threshold: int = 2\n    ):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.success_threshold = success_threshold\n\n        self.failure_count = 0\n        self.success_count = 0\n        self.state = CircuitState.CLOSED\n        self.opened_at = None\n\n    async def call(self, func: Callable, *args, **kwargs) -> Any:\n        \"\"\"Execute function with circuit breaker.\"\"\"\n\n        if self.state == CircuitState.OPEN:\n            if self._should_attempt_reset():\n                self.state = CircuitState.HALF_OPEN\n            else:\n                raise CircuitBreakerOpenError(\"Circuit breaker is open\")\n\n        try:\n            result = await func(*args, **kwargs)\n            self._on_success()\n            return result\n\n        except Exception as e:\n            self._on_failure()\n            raise\n\n    def _on_success(self):\n        \"\"\"Handle successful call.\"\"\"\n        self.failure_count = 0\n\n        if self.state == CircuitState.HALF_OPEN:\n            self.success_count += 1\n            if self.success_count >= self.success_threshold:\n                self.state = CircuitState.CLOSED\n                self.success_count = 0\n\n    def _on_failure(self):\n        \"\"\"Handle failed call.\"\"\"\n        self.failure_count += 1\n\n        if self.failure_count >= self.failure_threshold:\n            self.state = CircuitState.OPEN\n            self.opened_at = datetime.now()\n\n        if self.state == CircuitState.HALF_OPEN:\n            self.state = CircuitState.OPEN\n            self.opened_at = datetime.now()\n\n    def _should_attempt_reset(self) -> bool:\n        \"\"\"Check if enough time passed to try again.\"\"\"\n        return (\n            datetime.now() - self.opened_at\n            > timedelta(seconds=self.recovery_timeout)\n        )\n\n# Usage\nbreaker = CircuitBreaker(failure_threshold=5, recovery_timeout=30)\n\nasync def call_payment_service(payment_data: dict):\n    return await breaker.call(\n        payment_client.process_payment,\n        payment_data\n    )\n```\n\n## Resources\n\n- **references/service-decomposition-guide.md**: Breaking down monoliths\n- **references/communication-patterns.md**: Sync vs async patterns\n- **references/saga-implementation.md**: Distributed transactions\n- **assets/circuit-breaker.py**: Production circuit breaker\n- **assets/event-bus-template.py**: Kafka event bus implementation\n- **assets/api-gateway-template.py**: Complete API gateway\n\n## Best Practices\n\n1. **Service Boundaries**: Align with business capabilities\n2. **Database Per Service**: No shared databases\n3. **API Contracts**: Versioned, backward compatible\n4. **Async When Possible**: Events over direct calls\n5. **Circuit Breakers**: Fail fast on service failures\n6. **Distributed Tracing**: Track requests across services\n7. **Service Registry**: Dynamic service discovery\n8. **Health Checks**: Liveness and readiness probes\n\n## Common Pitfalls\n\n- **Distributed Monolith**: Tightly coupled services\n- **Chatty Services**: Too many inter-service calls\n- **Shared Databases**: Tight coupling through data\n- **No Circuit Breakers**: Cascade failures\n- **Synchronous Everything**: Tight coupling, poor resilience\n- **Premature Microservices**: Starting with microservices\n- **Ignoring Network Failures**: Assuming reliable network\n- **No Compensation Logic**: Can't undo failed transactions"
              }
            ]
          },
          {
            "name": "data-engineering",
            "description": null,
            "source": "./plugins/data-engineering",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install data-engineering@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/data-driven-feature",
                "description": null,
                "path": "plugins/data-engineering/commands/data-driven-feature.md",
                "frontmatter": null,
                "content": "# Data-Driven Feature Development\n\nBuild features guided by data insights, A/B testing, and continuous measurement using specialized agents for analysis, implementation, and experimentation.\n\n[Extended thinking: This workflow orchestrates a comprehensive data-driven development process from initial data analysis and hypothesis formulation through feature implementation with integrated analytics, A/B testing infrastructure, and post-launch analysis. Each phase leverages specialized agents to ensure features are built based on data insights, properly instrumented for measurement, and validated through controlled experiments. The workflow emphasizes modern product analytics practices, statistical rigor in testing, and continuous learning from user behavior.]\n\n## Phase 1: Data Analysis and Hypothesis Formation\n\n### 1. Exploratory Data Analysis\n- Use Task tool with subagent_type=\"machine-learning-ops::data-scientist\"\n- Prompt: \"Perform exploratory data analysis for feature: $ARGUMENTS. Analyze existing user behavior data, identify patterns and opportunities, segment users by behavior, and calculate baseline metrics. Use modern analytics tools (Amplitude, Mixpanel, Segment) to understand current user journeys, conversion funnels, and engagement patterns.\"\n- Output: EDA report with visualizations, user segments, behavioral patterns, baseline metrics\n\n### 2. Business Hypothesis Development\n- Use Task tool with subagent_type=\"business-analytics::business-analyst\"\n- Context: Data scientist's EDA findings and behavioral patterns\n- Prompt: \"Formulate business hypotheses for feature: $ARGUMENTS based on data analysis. Define clear success metrics, expected impact on key business KPIs, target user segments, and minimum detectable effects. Create measurable hypotheses using frameworks like ICE scoring or RICE prioritization.\"\n- Output: Hypothesis document, success metrics definition, expected ROI calculations\n\n### 3. Statistical Experiment Design\n- Use Task tool with subagent_type=\"machine-learning-ops::data-scientist\"\n- Context: Business hypotheses and success metrics\n- Prompt: \"Design statistical experiment for feature: $ARGUMENTS. Calculate required sample size for statistical power, define control and treatment groups, specify randomization strategy, and plan for multiple testing corrections. Consider Bayesian A/B testing approaches for faster decision making. Design for both primary and guardrail metrics.\"\n- Output: Experiment design document, power analysis, statistical test plan\n\n## Phase 2: Feature Architecture and Analytics Design\n\n### 4. Feature Architecture Planning\n- Use Task tool with subagent_type=\"data-engineering::backend-architect\"\n- Context: Business requirements and experiment design\n- Prompt: \"Design feature architecture for: $ARGUMENTS with A/B testing capability. Include feature flag integration (LaunchDarkly, Split.io, or Optimizely), gradual rollout strategy, circuit breakers for safety, and clean separation between control and treatment logic. Ensure architecture supports real-time configuration updates.\"\n- Output: Architecture diagrams, feature flag schema, rollout strategy\n\n### 5. Analytics Instrumentation Design\n- Use Task tool with subagent_type=\"data-engineering::data-engineer\"\n- Context: Feature architecture and success metrics\n- Prompt: \"Design comprehensive analytics instrumentation for: $ARGUMENTS. Define event schemas for user interactions, specify properties for segmentation and analysis, design funnel tracking and conversion events, plan cohort analysis capabilities. Implement using modern SDKs (Segment, Amplitude, Mixpanel) with proper event taxonomy.\"\n- Output: Event tracking plan, analytics schema, instrumentation guide\n\n### 6. Data Pipeline Architecture\n- Use Task tool with subagent_type=\"data-engineering::data-engineer\"\n- Context: Analytics requirements and existing data infrastructure\n- Prompt: \"Design data pipelines for feature: $ARGUMENTS. Include real-time streaming for live metrics (Kafka, Kinesis), batch processing for detailed analysis, data warehouse integration (Snowflake, BigQuery), and feature store for ML if applicable. Ensure proper data governance and GDPR compliance.\"\n- Output: Pipeline architecture, ETL/ELT specifications, data flow diagrams\n\n## Phase 3: Implementation with Instrumentation\n\n### 7. Backend Implementation\n- Use Task tool with subagent_type=\"backend-development::backend-architect\"\n- Context: Architecture design and feature requirements\n- Prompt: \"Implement backend for feature: $ARGUMENTS with full instrumentation. Include feature flag checks at decision points, comprehensive event tracking for all user actions, performance metrics collection, error tracking and monitoring. Implement proper logging for experiment analysis.\"\n- Output: Backend code with analytics, feature flag integration, monitoring setup\n\n### 8. Frontend Implementation\n- Use Task tool with subagent_type=\"frontend-mobile-development::frontend-developer\"\n- Context: Backend APIs and analytics requirements\n- Prompt: \"Build frontend for feature: $ARGUMENTS with analytics tracking. Implement event tracking for all user interactions, session recording integration if applicable, performance metrics (Core Web Vitals), and proper error boundaries. Ensure consistent experience between control and treatment groups.\"\n- Output: Frontend code with analytics, A/B test variants, performance monitoring\n\n### 9. ML Model Integration (if applicable)\n- Use Task tool with subagent_type=\"machine-learning-ops::ml-engineer\"\n- Context: Feature requirements and data pipelines\n- Prompt: \"Integrate ML models for feature: $ARGUMENTS if needed. Implement online inference with low latency, A/B testing between model versions, model performance tracking, and automatic fallback mechanisms. Set up model monitoring for drift detection.\"\n- Output: ML pipeline, model serving infrastructure, monitoring setup\n\n## Phase 4: Pre-Launch Validation\n\n### 10. Analytics Validation\n- Use Task tool with subagent_type=\"data-engineering::data-engineer\"\n- Context: Implemented tracking and event schemas\n- Prompt: \"Validate analytics implementation for: $ARGUMENTS. Test all event tracking in staging, verify data quality and completeness, validate funnel definitions, ensure proper user identification and session tracking. Run end-to-end tests for data pipeline.\"\n- Output: Validation report, data quality metrics, tracking coverage analysis\n\n### 11. Experiment Setup\n- Use Task tool with subagent_type=\"cloud-infrastructure::deployment-engineer\"\n- Context: Feature flags and experiment design\n- Prompt: \"Configure experiment infrastructure for: $ARGUMENTS. Set up feature flags with proper targeting rules, configure traffic allocation (start with 5-10%), implement kill switches, set up monitoring alerts for key metrics. Test randomization and assignment logic.\"\n- Output: Experiment configuration, monitoring dashboards, rollout plan\n\n## Phase 5: Launch and Experimentation\n\n### 12. Gradual Rollout\n- Use Task tool with subagent_type=\"cloud-infrastructure::deployment-engineer\"\n- Context: Experiment configuration and monitoring setup\n- Prompt: \"Execute gradual rollout for feature: $ARGUMENTS. Start with internal dogfooding, then beta users (1-5%), gradually increase to target traffic. Monitor error rates, performance metrics, and early indicators. Implement automated rollback on anomalies.\"\n- Output: Rollout execution, monitoring alerts, health metrics\n\n### 13. Real-time Monitoring\n- Use Task tool with subagent_type=\"observability-monitoring::observability-engineer\"\n- Context: Deployed feature and success metrics\n- Prompt: \"Set up comprehensive monitoring for: $ARGUMENTS. Create real-time dashboards for experiment metrics, configure alerts for statistical significance, monitor guardrail metrics for negative impacts, track system performance and error rates. Use tools like Datadog, New Relic, or custom dashboards.\"\n- Output: Monitoring dashboards, alert configurations, SLO definitions\n\n## Phase 6: Analysis and Decision Making\n\n### 14. Statistical Analysis\n- Use Task tool with subagent_type=\"machine-learning-ops::data-scientist\"\n- Context: Experiment data and original hypotheses\n- Prompt: \"Analyze A/B test results for: $ARGUMENTS. Calculate statistical significance with confidence intervals, check for segment-level effects, analyze secondary metrics impact, investigate any unexpected patterns. Use both frequentist and Bayesian approaches. Account for multiple testing if applicable.\"\n- Output: Statistical analysis report, significance tests, segment analysis\n\n### 15. Business Impact Assessment\n- Use Task tool with subagent_type=\"business-analytics::business-analyst\"\n- Context: Statistical analysis and business metrics\n- Prompt: \"Assess business impact of feature: $ARGUMENTS. Calculate actual vs expected ROI, analyze impact on key business metrics, evaluate cost-benefit including operational overhead, project long-term value. Make recommendation on full rollout, iteration, or rollback.\"\n- Output: Business impact report, ROI analysis, recommendation document\n\n### 16. Post-Launch Optimization\n- Use Task tool with subagent_type=\"machine-learning-ops::data-scientist\"\n- Context: Launch results and user feedback\n- Prompt: \"Identify optimization opportunities for: $ARGUMENTS based on data. Analyze user behavior patterns in treatment group, identify friction points in user journey, suggest improvements based on data, plan follow-up experiments. Use cohort analysis for long-term impact.\"\n- Output: Optimization recommendations, follow-up experiment plans\n\n## Configuration Options\n\n```yaml\nexperiment_config:\n  min_sample_size: 10000\n  confidence_level: 0.95\n  runtime_days: 14\n  traffic_allocation: \"gradual\"  # gradual, fixed, or adaptive\n\nanalytics_platforms:\n  - amplitude\n  - segment\n  - mixpanel\n\nfeature_flags:\n  provider: \"launchdarkly\"  # launchdarkly, split, optimizely, unleash\n\nstatistical_methods:\n  - frequentist\n  - bayesian\n\nmonitoring:\n  - real_time_metrics: true\n  - anomaly_detection: true\n  - automatic_rollback: true\n```\n\n## Success Criteria\n\n- **Data Coverage**: 100% of user interactions tracked with proper event schema\n- **Experiment Validity**: Proper randomization, sufficient statistical power, no sample ratio mismatch\n- **Statistical Rigor**: Clear significance testing, proper confidence intervals, multiple testing corrections\n- **Business Impact**: Measurable improvement in target metrics without degrading guardrail metrics\n- **Technical Performance**: No degradation in p95 latency, error rates below 0.1%\n- **Decision Speed**: Clear go/no-go decision within planned experiment runtime\n- **Learning Outcomes**: Documented insights for future feature development\n\n## Coordination Notes\n\n- Data scientists and business analysts collaborate on hypothesis formation\n- Engineers implement with analytics as first-class requirement, not afterthought\n- Feature flags enable safe experimentation without full deployments\n- Real-time monitoring allows for quick iteration and rollback if needed\n- Statistical rigor balanced with business practicality and speed to market\n- Continuous learning loop feeds back into next feature development cycle\n\nFeature to develop with data-driven approach: $ARGUMENTS"
              },
              {
                "name": "/data-pipeline",
                "description": null,
                "path": "plugins/data-engineering/commands/data-pipeline.md",
                "frontmatter": null,
                "content": "# Data Pipeline Architecture\n\nYou are a data pipeline architecture expert specializing in scalable, reliable, and cost-effective data pipelines for batch and streaming data processing.\n\n## Requirements\n\n$ARGUMENTS\n\n## Core Capabilities\n\n- Design ETL/ELT, Lambda, Kappa, and Lakehouse architectures\n- Implement batch and streaming data ingestion\n- Build workflow orchestration with Airflow/Prefect\n- Transform data using dbt and Spark\n- Manage Delta Lake/Iceberg storage with ACID transactions\n- Implement data quality frameworks (Great Expectations, dbt tests)\n- Monitor pipelines with CloudWatch/Prometheus/Grafana\n- Optimize costs through partitioning, lifecycle policies, and compute optimization\n\n## Instructions\n\n### 1. Architecture Design\n- Assess: sources, volume, latency requirements, targets\n- Select pattern: ETL (transform before load), ELT (load then transform), Lambda (batch + speed layers), Kappa (stream-only), Lakehouse (unified)\n- Design flow: sources → ingestion → processing → storage → serving\n- Add observability touchpoints\n\n### 2. Ingestion Implementation\n**Batch**\n- Incremental loading with watermark columns\n- Retry logic with exponential backoff\n- Schema validation and dead letter queue for invalid records\n- Metadata tracking (_extracted_at, _source)\n\n**Streaming**\n- Kafka consumers with exactly-once semantics\n- Manual offset commits within transactions\n- Windowing for time-based aggregations\n- Error handling and replay capability\n\n### 3. Orchestration\n**Airflow**\n- Task groups for logical organization\n- XCom for inter-task communication\n- SLA monitoring and email alerts\n- Incremental execution with execution_date\n- Retry with exponential backoff\n\n**Prefect**\n- Task caching for idempotency\n- Parallel execution with .submit()\n- Artifacts for visibility\n- Automatic retries with configurable delays\n\n### 4. Transformation with dbt\n- Staging layer: incremental materialization, deduplication, late-arriving data handling\n- Marts layer: dimensional models, aggregations, business logic\n- Tests: unique, not_null, relationships, accepted_values, custom data quality tests\n- Sources: freshness checks, loaded_at_field tracking\n- Incremental strategy: merge or delete+insert\n\n### 5. Data Quality Framework\n**Great Expectations**\n- Table-level: row count, column count\n- Column-level: uniqueness, nullability, type validation, value sets, ranges\n- Checkpoints for validation execution\n- Data docs for documentation\n- Failure notifications\n\n**dbt Tests**\n- Schema tests in YAML\n- Custom data quality tests with dbt-expectations\n- Test results tracked in metadata\n\n### 6. Storage Strategy\n**Delta Lake**\n- ACID transactions with append/overwrite/merge modes\n- Upsert with predicate-based matching\n- Time travel for historical queries\n- Optimize: compact small files, Z-order clustering\n- Vacuum to remove old files\n\n**Apache Iceberg**\n- Partitioning and sort order optimization\n- MERGE INTO for upserts\n- Snapshot isolation and time travel\n- File compaction with binpack strategy\n- Snapshot expiration for cleanup\n\n### 7. Monitoring & Cost Optimization\n**Monitoring**\n- Track: records processed/failed, data size, execution time, success/failure rates\n- CloudWatch metrics and custom namespaces\n- SNS alerts for critical/warning/info events\n- Data freshness checks\n- Performance trend analysis\n\n**Cost Optimization**\n- Partitioning: date/entity-based, avoid over-partitioning (keep >1GB)\n- File sizes: 512MB-1GB for Parquet\n- Lifecycle policies: hot (Standard) → warm (IA) → cold (Glacier)\n- Compute: spot instances for batch, on-demand for streaming, serverless for adhoc\n- Query optimization: partition pruning, clustering, predicate pushdown\n\n## Example: Minimal Batch Pipeline\n\n```python\n# Batch ingestion with validation\nfrom batch_ingestion import BatchDataIngester\nfrom storage.delta_lake_manager import DeltaLakeManager\nfrom data_quality.expectations_suite import DataQualityFramework\n\ningester = BatchDataIngester(config={})\n\n# Extract with incremental loading\ndf = ingester.extract_from_database(\n    connection_string='postgresql://host:5432/db',\n    query='SELECT * FROM orders',\n    watermark_column='updated_at',\n    last_watermark=last_run_timestamp\n)\n\n# Validate\nschema = {'required_fields': ['id', 'user_id'], 'dtypes': {'id': 'int64'}}\ndf = ingester.validate_and_clean(df, schema)\n\n# Data quality checks\ndq = DataQualityFramework()\nresult = dq.validate_dataframe(df, suite_name='orders_suite', data_asset_name='orders')\n\n# Write to Delta Lake\ndelta_mgr = DeltaLakeManager(storage_path='s3://lake')\ndelta_mgr.create_or_update_table(\n    df=df,\n    table_name='orders',\n    partition_columns=['order_date'],\n    mode='append'\n)\n\n# Save failed records\ningester.save_dead_letter_queue('s3://lake/dlq/orders')\n```\n\n## Output Deliverables\n\n### 1. Architecture Documentation\n- Architecture diagram with data flow\n- Technology stack with justification\n- Scalability analysis and growth patterns\n- Failure modes and recovery strategies\n\n### 2. Implementation Code\n- Ingestion: batch/streaming with error handling\n- Transformation: dbt models (staging → marts) or Spark jobs\n- Orchestration: Airflow/Prefect DAGs with dependencies\n- Storage: Delta/Iceberg table management\n- Data quality: Great Expectations suites and dbt tests\n\n### 3. Configuration Files\n- Orchestration: DAG definitions, schedules, retry policies\n- dbt: models, sources, tests, project config\n- Infrastructure: Docker Compose, K8s manifests, Terraform\n- Environment: dev/staging/prod configs\n\n### 4. Monitoring & Observability\n- Metrics: execution time, records processed, quality scores\n- Alerts: failures, performance degradation, data freshness\n- Dashboards: Grafana/CloudWatch for pipeline health\n- Logging: structured logs with correlation IDs\n\n### 5. Operations Guide\n- Deployment procedures and rollback strategy\n- Troubleshooting guide for common issues\n- Scaling guide for increased volume\n- Cost optimization strategies and savings\n- Disaster recovery and backup procedures\n\n## Success Criteria\n- Pipeline meets defined SLA (latency, throughput)\n- Data quality checks pass with >99% success rate\n- Automatic retry and alerting on failures\n- Comprehensive monitoring shows health and performance\n- Documentation enables team maintenance\n- Cost optimization reduces infrastructure costs by 30-50%\n- Schema evolution without downtime\n- End-to-end data lineage tracked\n"
              }
            ],
            "skills": []
          },
          {
            "name": "database-cloud-optimization",
            "description": null,
            "source": "./plugins/database-cloud-optimization",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install database-cloud-optimization@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/cost-optimize",
                "description": null,
                "path": "plugins/database-cloud-optimization/commands/cost-optimize.md",
                "frontmatter": null,
                "content": "# Cloud Cost Optimization\n\nYou are a cloud cost optimization expert specializing in reducing infrastructure expenses while maintaining performance and reliability. Analyze cloud spending, identify savings opportunities, and implement cost-effective architectures across AWS, Azure, and GCP.\n\n## Context\nThe user needs to optimize cloud infrastructure costs without compromising performance or reliability. Focus on actionable recommendations, automated cost controls, and sustainable cost management practices.\n\n## Requirements\n$ARGUMENTS\n\n## Instructions\n\n### 1. Cost Analysis and Visibility\n\nImplement comprehensive cost analysis:\n\n**Cost Analysis Framework**\n```python\nimport boto3\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any\nimport json\n\nclass CloudCostAnalyzer:\n    def __init__(self, cloud_provider: str):\n        self.provider = cloud_provider\n        self.client = self._initialize_client()\n        self.cost_data = None\n        \n    def analyze_costs(self, time_period: int = 30):\n        \"\"\"Comprehensive cost analysis\"\"\"\n        analysis = {\n            'total_cost': self._get_total_cost(time_period),\n            'cost_by_service': self._analyze_by_service(time_period),\n            'cost_by_resource': self._analyze_by_resource(time_period),\n            'cost_trends': self._analyze_trends(time_period),\n            'anomalies': self._detect_anomalies(time_period),\n            'waste_analysis': self._identify_waste(),\n            'optimization_opportunities': self._find_opportunities()\n        }\n        \n        return self._generate_report(analysis)\n    \n    def _analyze_by_service(self, days: int):\n        \"\"\"Analyze costs by service\"\"\"\n        if self.provider == 'aws':\n            ce = boto3.client('ce')\n            \n            response = ce.get_cost_and_usage(\n                TimePeriod={\n                    'Start': (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d'),\n                    'End': datetime.now().strftime('%Y-%m-%d')\n                },\n                Granularity='DAILY',\n                Metrics=['UnblendedCost'],\n                GroupBy=[\n                    {'Type': 'DIMENSION', 'Key': 'SERVICE'}\n                ]\n            )\n            \n            # Process response\n            service_costs = {}\n            for result in response['ResultsByTime']:\n                for group in result['Groups']:\n                    service = group['Keys'][0]\n                    cost = float(group['Metrics']['UnblendedCost']['Amount'])\n                    \n                    if service not in service_costs:\n                        service_costs[service] = []\n                    service_costs[service].append(cost)\n            \n            # Calculate totals and trends\n            analysis = {}\n            for service, costs in service_costs.items():\n                analysis[service] = {\n                    'total': sum(costs),\n                    'average_daily': sum(costs) / len(costs),\n                    'trend': self._calculate_trend(costs),\n                    'percentage': (sum(costs) / self._get_total_cost(days)) * 100\n                }\n            \n            return analysis\n    \n    def _identify_waste(self):\n        \"\"\"Identify wasted resources\"\"\"\n        waste_analysis = {\n            'unused_resources': self._find_unused_resources(),\n            'oversized_resources': self._find_oversized_resources(),\n            'unattached_storage': self._find_unattached_storage(),\n            'idle_load_balancers': self._find_idle_load_balancers(),\n            'old_snapshots': self._find_old_snapshots(),\n            'untagged_resources': self._find_untagged_resources()\n        }\n        \n        total_waste = sum(item['estimated_savings'] \n                         for category in waste_analysis.values() \n                         for item in category)\n        \n        waste_analysis['total_potential_savings'] = total_waste\n        \n        return waste_analysis\n    \n    def _find_unused_resources(self):\n        \"\"\"Find resources with no usage\"\"\"\n        unused = []\n        \n        if self.provider == 'aws':\n            # Check EC2 instances\n            ec2 = boto3.client('ec2')\n            cloudwatch = boto3.client('cloudwatch')\n            \n            instances = ec2.describe_instances(\n                Filters=[{'Name': 'instance-state-name', 'Values': ['running']}]\n            )\n            \n            for reservation in instances['Reservations']:\n                for instance in reservation['Instances']:\n                    # Check CPU utilization\n                    metrics = cloudwatch.get_metric_statistics(\n                        Namespace='AWS/EC2',\n                        MetricName='CPUUtilization',\n                        Dimensions=[\n                            {'Name': 'InstanceId', 'Value': instance['InstanceId']}\n                        ],\n                        StartTime=datetime.now() - timedelta(days=7),\n                        EndTime=datetime.now(),\n                        Period=3600,\n                        Statistics=['Average']\n                    )\n                    \n                    if metrics['Datapoints']:\n                        avg_cpu = sum(d['Average'] for d in metrics['Datapoints']) / len(metrics['Datapoints'])\n                        \n                        if avg_cpu < 5:  # Less than 5% CPU usage\n                            unused.append({\n                                'resource_type': 'EC2 Instance',\n                                'resource_id': instance['InstanceId'],\n                                'reason': f'Average CPU: {avg_cpu:.2f}%',\n                                'estimated_savings': self._calculate_instance_cost(instance)\n                            })\n        \n        return unused\n```\n\n### 2. Resource Rightsizing\n\nImplement intelligent rightsizing:\n\n**Rightsizing Engine**\n```python\nclass ResourceRightsizer:\n    def __init__(self):\n        self.utilization_thresholds = {\n            'cpu_low': 20,\n            'cpu_high': 80,\n            'memory_low': 30,\n            'memory_high': 85,\n            'network_low': 10,\n            'network_high': 70\n        }\n    \n    def analyze_rightsizing_opportunities(self):\n        \"\"\"Find rightsizing opportunities\"\"\"\n        opportunities = {\n            'ec2_instances': self._rightsize_ec2(),\n            'rds_instances': self._rightsize_rds(),\n            'containers': self._rightsize_containers(),\n            'lambda_functions': self._rightsize_lambda(),\n            'storage_volumes': self._rightsize_storage()\n        }\n        \n        return self._prioritize_opportunities(opportunities)\n    \n    def _rightsize_ec2(self):\n        \"\"\"Rightsize EC2 instances\"\"\"\n        recommendations = []\n        \n        instances = self._get_running_instances()\n        \n        for instance in instances:\n            # Get utilization metrics\n            utilization = self._get_instance_utilization(instance['InstanceId'])\n            \n            # Determine if oversized or undersized\n            current_type = instance['InstanceType']\n            recommended_type = self._recommend_instance_type(\n                current_type, \n                utilization\n            )\n            \n            if recommended_type != current_type:\n                current_cost = self._get_instance_cost(current_type)\n                new_cost = self._get_instance_cost(recommended_type)\n                \n                recommendations.append({\n                    'resource_id': instance['InstanceId'],\n                    'current_type': current_type,\n                    'recommended_type': recommended_type,\n                    'reason': self._generate_reason(utilization),\n                    'current_cost': current_cost,\n                    'new_cost': new_cost,\n                    'monthly_savings': (current_cost - new_cost) * 730,\n                    'effort': 'medium',\n                    'risk': 'low' if 'downsize' in self._generate_reason(utilization) else 'medium'\n                })\n        \n        return recommendations\n    \n    def _recommend_instance_type(self, current_type: str, utilization: Dict):\n        \"\"\"Recommend optimal instance type\"\"\"\n        # Parse current instance family and size\n        family, size = self._parse_instance_type(current_type)\n        \n        # Calculate required resources\n        required_cpu = self._calculate_required_cpu(utilization['cpu'])\n        required_memory = self._calculate_required_memory(utilization['memory'])\n        \n        # Find best matching instance\n        instance_catalog = self._get_instance_catalog()\n        \n        candidates = []\n        for instance_type, specs in instance_catalog.items():\n            if (specs['vcpu'] >= required_cpu and \n                specs['memory'] >= required_memory):\n                candidates.append({\n                    'type': instance_type,\n                    'cost': specs['cost'],\n                    'vcpu': specs['vcpu'],\n                    'memory': specs['memory'],\n                    'efficiency_score': self._calculate_efficiency_score(\n                        specs, required_cpu, required_memory\n                    )\n                })\n        \n        # Select best candidate\n        if candidates:\n            best = sorted(candidates, \n                         key=lambda x: (x['efficiency_score'], x['cost']))[0]\n            return best['type']\n        \n        return current_type\n    \n    def create_rightsizing_automation(self):\n        \"\"\"Automated rightsizing implementation\"\"\"\n        return '''\nimport boto3\nfrom datetime import datetime\nimport logging\n\nclass AutomatedRightsizer:\n    def __init__(self):\n        self.ec2 = boto3.client('ec2')\n        self.cloudwatch = boto3.client('cloudwatch')\n        self.logger = logging.getLogger(__name__)\n        \n    def execute_rightsizing(self, recommendations: List[Dict], dry_run: bool = True):\n        \"\"\"Execute rightsizing recommendations\"\"\"\n        results = []\n        \n        for recommendation in recommendations:\n            try:\n                if recommendation['risk'] == 'low' or self._get_approval(recommendation):\n                    result = self._resize_instance(\n                        recommendation['resource_id'],\n                        recommendation['recommended_type'],\n                        dry_run=dry_run\n                    )\n                    results.append(result)\n            except Exception as e:\n                self.logger.error(f\"Failed to resize {recommendation['resource_id']}: {e}\")\n                \n        return results\n    \n    def _resize_instance(self, instance_id: str, new_type: str, dry_run: bool):\n        \"\"\"Resize an EC2 instance\"\"\"\n        # Create snapshot for rollback\n        snapshot_id = self._create_snapshot(instance_id)\n        \n        try:\n            # Stop instance\n            if not dry_run:\n                self.ec2.stop_instances(InstanceIds=[instance_id])\n                self._wait_for_state(instance_id, 'stopped')\n            \n            # Change instance type\n            self.ec2.modify_instance_attribute(\n                InstanceId=instance_id,\n                InstanceType={'Value': new_type},\n                DryRun=dry_run\n            )\n            \n            # Start instance\n            if not dry_run:\n                self.ec2.start_instances(InstanceIds=[instance_id])\n                self._wait_for_state(instance_id, 'running')\n            \n            return {\n                'instance_id': instance_id,\n                'status': 'success',\n                'new_type': new_type,\n                'snapshot_id': snapshot_id\n            }\n            \n        except Exception as e:\n            # Rollback on failure\n            if not dry_run:\n                self._rollback_instance(instance_id, snapshot_id)\n            raise\n'''\n```\n\n### 3. Reserved Instances and Savings Plans\n\nOptimize commitment-based discounts:\n\n**Reservation Optimizer**\n```python\nclass ReservationOptimizer:\n    def __init__(self):\n        self.usage_history = None\n        self.existing_reservations = None\n        \n    def analyze_reservation_opportunities(self):\n        \"\"\"Analyze opportunities for reservations\"\"\"\n        analysis = {\n            'current_coverage': self._analyze_current_coverage(),\n            'usage_patterns': self._analyze_usage_patterns(),\n            'recommendations': self._generate_recommendations(),\n            'roi_analysis': self._calculate_roi(),\n            'risk_assessment': self._assess_commitment_risk()\n        }\n        \n        return analysis\n    \n    def _analyze_usage_patterns(self):\n        \"\"\"Analyze historical usage patterns\"\"\"\n        # Get 12 months of usage data\n        usage_data = self._get_historical_usage(months=12)\n        \n        patterns = {\n            'stable_workloads': [],\n            'variable_workloads': [],\n            'seasonal_patterns': [],\n            'growth_trends': []\n        }\n        \n        # Analyze each instance family\n        for family in self._get_instance_families(usage_data):\n            family_usage = self._filter_by_family(usage_data, family)\n            \n            # Calculate stability metrics\n            stability = self._calculate_stability(family_usage)\n            \n            if stability['coefficient_of_variation'] < 0.1:\n                patterns['stable_workloads'].append({\n                    'family': family,\n                    'average_usage': stability['mean'],\n                    'min_usage': stability['min'],\n                    'recommendation': 'reserved_instance',\n                    'term': '3_year',\n                    'payment': 'all_upfront'\n                })\n            elif stability['coefficient_of_variation'] < 0.3:\n                patterns['variable_workloads'].append({\n                    'family': family,\n                    'average_usage': stability['mean'],\n                    'baseline': stability['percentile_25'],\n                    'recommendation': 'savings_plan',\n                    'commitment': stability['percentile_25']\n                })\n            \n            # Check for seasonal patterns\n            if self._has_seasonal_pattern(family_usage):\n                patterns['seasonal_patterns'].append({\n                    'family': family,\n                    'pattern': self._identify_seasonal_pattern(family_usage),\n                    'recommendation': 'spot_with_savings_plan_baseline'\n                })\n        \n        return patterns\n    \n    def _generate_recommendations(self):\n        \"\"\"Generate reservation recommendations\"\"\"\n        recommendations = []\n        \n        patterns = self._analyze_usage_patterns()\n        current_costs = self._calculate_current_costs()\n        \n        # Reserved Instance recommendations\n        for workload in patterns['stable_workloads']:\n            ri_options = self._calculate_ri_options(workload)\n            \n            for option in ri_options:\n                savings = current_costs[workload['family']] - option['total_cost']\n                \n                if savings > 0:\n                    recommendations.append({\n                        'type': 'reserved_instance',\n                        'family': workload['family'],\n                        'quantity': option['quantity'],\n                        'term': option['term'],\n                        'payment': option['payment_option'],\n                        'upfront_cost': option['upfront_cost'],\n                        'monthly_cost': option['monthly_cost'],\n                        'total_savings': savings,\n                        'break_even_months': option['upfront_cost'] / (savings / 36),\n                        'confidence': 'high'\n                    })\n        \n        # Savings Plan recommendations\n        for workload in patterns['variable_workloads']:\n            sp_options = self._calculate_savings_plan_options(workload)\n            \n            for option in sp_options:\n                recommendations.append({\n                    'type': 'savings_plan',\n                    'commitment_type': option['type'],\n                    'hourly_commitment': option['commitment'],\n                    'term': option['term'],\n                    'estimated_savings': option['savings'],\n                    'flexibility': option['flexibility_score'],\n                    'confidence': 'medium'\n                })\n        \n        return sorted(recommendations, key=lambda x: x.get('total_savings', 0), reverse=True)\n    \n    def create_reservation_dashboard(self):\n        \"\"\"Create reservation tracking dashboard\"\"\"\n        return '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Reservation & Savings Dashboard</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n</head>\n<body>\n    <div class=\"dashboard\">\n        <div class=\"summary-cards\">\n            <div class=\"card\">\n                <h3>Current Coverage</h3>\n                <div class=\"metric\">{coverage_percentage}%</div>\n                <div class=\"sub-metric\">On-Demand: ${on_demand_cost}</div>\n                <div class=\"sub-metric\">Reserved: ${reserved_cost}</div>\n            </div>\n            \n            <div class=\"card\">\n                <h3>Potential Savings</h3>\n                <div class=\"metric\">${potential_savings}/month</div>\n                <div class=\"sub-metric\">{recommendations_count} opportunities</div>\n            </div>\n            \n            <div class=\"card\">\n                <h3>Expiring Soon</h3>\n                <div class=\"metric\">{expiring_count} RIs</div>\n                <div class=\"sub-metric\">Next 30 days</div>\n            </div>\n        </div>\n        \n        <div class=\"charts\">\n            <canvas id=\"coverageChart\"></canvas>\n            <canvas id=\"savingsChart\"></canvas>\n        </div>\n        \n        <div class=\"recommendations-table\">\n            <h3>Top Recommendations</h3>\n            <table>\n                <tr>\n                    <th>Type</th>\n                    <th>Resource</th>\n                    <th>Term</th>\n                    <th>Upfront</th>\n                    <th>Monthly Savings</th>\n                    <th>ROI</th>\n                    <th>Action</th>\n                </tr>\n                {recommendation_rows}\n            </table>\n        </div>\n    </div>\n</body>\n</html>\n'''\n```\n\n### 4. Spot Instance Optimization\n\nLeverage spot instances effectively:\n\n**Spot Instance Manager**\n```python\nclass SpotInstanceOptimizer:\n    def __init__(self):\n        self.spot_advisor = self._init_spot_advisor()\n        self.interruption_handler = None\n        \n    def identify_spot_opportunities(self):\n        \"\"\"Identify workloads suitable for spot\"\"\"\n        workloads = self._analyze_workloads()\n        \n        spot_candidates = {\n            'batch_processing': [],\n            'dev_test': [],\n            'stateless_apps': [],\n            'ci_cd': [],\n            'data_processing': []\n        }\n        \n        for workload in workloads:\n            suitability = self._assess_spot_suitability(workload)\n            \n            if suitability['score'] > 0.7:\n                spot_candidates[workload['type']].append({\n                    'workload': workload['name'],\n                    'current_cost': workload['cost'],\n                    'spot_savings': workload['cost'] * 0.7,  # ~70% savings\n                    'interruption_tolerance': suitability['interruption_tolerance'],\n                    'recommended_strategy': self._recommend_spot_strategy(workload)\n                })\n        \n        return spot_candidates\n    \n    def _recommend_spot_strategy(self, workload):\n        \"\"\"Recommend spot instance strategy\"\"\"\n        if workload['interruption_tolerance'] == 'high':\n            return {\n                'strategy': 'spot_fleet_diverse',\n                'instance_pools': 10,\n                'allocation_strategy': 'capacity-optimized',\n                'on_demand_base': 0,\n                'spot_percentage': 100\n            }\n        elif workload['interruption_tolerance'] == 'medium':\n            return {\n                'strategy': 'mixed_instances',\n                'on_demand_base': 25,\n                'spot_percentage': 75,\n                'spot_allocation': 'lowest-price'\n            }\n        else:\n            return {\n                'strategy': 'spot_with_fallback',\n                'primary': 'spot',\n                'fallback': 'on-demand',\n                'checkpointing': True\n            }\n    \n    def create_spot_configuration(self):\n        \"\"\"Create spot instance configuration\"\"\"\n        return '''\n# Terraform configuration for Spot instances\nresource \"aws_spot_fleet_request\" \"processing_fleet\" {\n  iam_fleet_role = aws_iam_role.spot_fleet.arn\n  \n  allocation_strategy = \"diversified\"\n  target_capacity     = 100\n  valid_until        = timeadd(timestamp(), \"168h\")\n  \n  # Define multiple launch specifications for diversity\n  dynamic \"launch_specification\" {\n    for_each = var.spot_instance_types\n    \n    content {\n      instance_type     = launch_specification.value\n      ami              = var.ami_id\n      key_name         = var.key_name\n      subnet_id        = var.subnet_ids[launch_specification.key % length(var.subnet_ids)]\n      \n      weighted_capacity = var.instance_weights[launch_specification.value]\n      spot_price       = var.max_spot_prices[launch_specification.value]\n      \n      user_data = base64encode(templatefile(\"${path.module}/spot-init.sh\", {\n        interruption_handler = true\n        checkpoint_s3_bucket = var.checkpoint_bucket\n      }))\n      \n      tags = {\n        Name = \"spot-processing-${launch_specification.key}\"\n        Type = \"spot\"\n      }\n    }\n  }\n  \n  # Interruption handling\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# Spot interruption handler\nresource \"aws_lambda_function\" \"spot_interruption_handler\" {\n  filename         = \"spot-handler.zip\"\n  function_name    = \"spot-interruption-handler\"\n  role            = aws_iam_role.lambda_role.arn\n  handler         = \"handler.main\"\n  runtime         = \"python3.9\"\n  \n  environment {\n    variables = {\n      CHECKPOINT_BUCKET = var.checkpoint_bucket\n      SNS_TOPIC_ARN    = aws_sns_topic.spot_interruptions.arn\n    }\n  }\n}\n'''\n```\n\n### 5. Storage Optimization\n\nOptimize storage costs:\n\n**Storage Optimizer**\n```python\nclass StorageOptimizer:\n    def analyze_storage_costs(self):\n        \"\"\"Comprehensive storage analysis\"\"\"\n        analysis = {\n            'ebs_volumes': self._analyze_ebs_volumes(),\n            's3_buckets': self._analyze_s3_buckets(),\n            'snapshots': self._analyze_snapshots(),\n            'lifecycle_opportunities': self._find_lifecycle_opportunities(),\n            'compression_opportunities': self._find_compression_opportunities()\n        }\n        \n        return analysis\n    \n    def _analyze_s3_buckets(self):\n        \"\"\"Analyze S3 bucket costs and optimization\"\"\"\n        s3 = boto3.client('s3')\n        cloudwatch = boto3.client('cloudwatch')\n        \n        buckets = s3.list_buckets()['Buckets']\n        bucket_analysis = []\n        \n        for bucket in buckets:\n            bucket_name = bucket['Name']\n            \n            # Get storage metrics\n            metrics = self._get_s3_metrics(bucket_name)\n            \n            # Analyze storage classes\n            storage_class_distribution = self._get_storage_class_distribution(bucket_name)\n            \n            # Calculate optimization potential\n            optimization = self._calculate_s3_optimization(\n                bucket_name,\n                metrics,\n                storage_class_distribution\n            )\n            \n            bucket_analysis.append({\n                'bucket_name': bucket_name,\n                'total_size_gb': metrics['size_gb'],\n                'total_objects': metrics['object_count'],\n                'current_cost': metrics['monthly_cost'],\n                'storage_classes': storage_class_distribution,\n                'optimization_recommendations': optimization['recommendations'],\n                'potential_savings': optimization['savings']\n            })\n        \n        return bucket_analysis\n    \n    def create_lifecycle_policies(self):\n        \"\"\"Create S3 lifecycle policies\"\"\"\n        return '''\nimport boto3\nfrom datetime import datetime\n\nclass S3LifecycleManager:\n    def __init__(self):\n        self.s3 = boto3.client('s3')\n        \n    def create_intelligent_lifecycle(self, bucket_name: str, access_patterns: Dict):\n        \"\"\"Create lifecycle policy based on access patterns\"\"\"\n        \n        rules = []\n        \n        # Intelligent tiering for unknown access patterns\n        if access_patterns.get('unpredictable'):\n            rules.append({\n                'ID': 'intelligent-tiering',\n                'Status': 'Enabled',\n                'Transitions': [{\n                    'Days': 1,\n                    'StorageClass': 'INTELLIGENT_TIERING'\n                }]\n            })\n        \n        # Standard lifecycle for predictable patterns\n        if access_patterns.get('predictable'):\n            rules.append({\n                'ID': 'standard-lifecycle',\n                'Status': 'Enabled',\n                'Transitions': [\n                    {\n                        'Days': 30,\n                        'StorageClass': 'STANDARD_IA'\n                    },\n                    {\n                        'Days': 90,\n                        'StorageClass': 'GLACIER'\n                    },\n                    {\n                        'Days': 180,\n                        'StorageClass': 'DEEP_ARCHIVE'\n                    }\n                ]\n            })\n        \n        # Delete old versions\n        rules.append({\n            'ID': 'delete-old-versions',\n            'Status': 'Enabled',\n            'NoncurrentVersionTransitions': [\n                {\n                    'NoncurrentDays': 30,\n                    'StorageClass': 'GLACIER'\n                }\n            ],\n            'NoncurrentVersionExpiration': {\n                'NoncurrentDays': 90\n            }\n        })\n        \n        # Apply lifecycle configuration\n        self.s3.put_bucket_lifecycle_configuration(\n            Bucket=bucket_name,\n            LifecycleConfiguration={'Rules': rules}\n        )\n        \n        return rules\n    \n    def optimize_ebs_volumes(self):\n        \"\"\"Optimize EBS volume types and sizes\"\"\"\n        ec2 = boto3.client('ec2')\n        \n        volumes = ec2.describe_volumes()['Volumes']\n        optimizations = []\n        \n        for volume in volumes:\n            # Analyze volume metrics\n            iops_usage = self._get_volume_iops_usage(volume['VolumeId'])\n            throughput_usage = self._get_volume_throughput_usage(volume['VolumeId'])\n            \n            current_type = volume['VolumeType']\n            recommended_type = self._recommend_volume_type(\n                iops_usage,\n                throughput_usage,\n                volume['Size']\n            )\n            \n            if recommended_type != current_type:\n                optimizations.append({\n                    'volume_id': volume['VolumeId'],\n                    'current_type': current_type,\n                    'recommended_type': recommended_type,\n                    'reason': self._get_optimization_reason(\n                        current_type,\n                        recommended_type,\n                        iops_usage,\n                        throughput_usage\n                    ),\n                    'monthly_savings': self._calculate_volume_savings(\n                        volume,\n                        recommended_type\n                    )\n                })\n        \n        return optimizations\n'''\n```\n\n### 6. Network Cost Optimization\n\nReduce network transfer costs:\n\n**Network Cost Optimizer**\n```python\nclass NetworkCostOptimizer:\n    def analyze_network_costs(self):\n        \"\"\"Analyze network transfer costs\"\"\"\n        analysis = {\n            'data_transfer_costs': self._analyze_data_transfer(),\n            'nat_gateway_costs': self._analyze_nat_gateways(),\n            'load_balancer_costs': self._analyze_load_balancers(),\n            'vpc_endpoint_opportunities': self._find_vpc_endpoint_opportunities(),\n            'cdn_optimization': self._analyze_cdn_usage()\n        }\n        \n        return analysis\n    \n    def _analyze_data_transfer(self):\n        \"\"\"Analyze data transfer patterns and costs\"\"\"\n        transfers = {\n            'inter_region': self._get_inter_region_transfers(),\n            'internet_egress': self._get_internet_egress(),\n            'inter_az': self._get_inter_az_transfers(),\n            'vpc_peering': self._get_vpc_peering_transfers()\n        }\n        \n        recommendations = []\n        \n        # Analyze inter-region transfers\n        if transfers['inter_region']['monthly_gb'] > 1000:\n            recommendations.append({\n                'type': 'region_consolidation',\n                'description': 'Consider consolidating resources in fewer regions',\n                'current_cost': transfers['inter_region']['monthly_cost'],\n                'potential_savings': transfers['inter_region']['monthly_cost'] * 0.8\n            })\n        \n        # Analyze internet egress\n        if transfers['internet_egress']['monthly_gb'] > 10000:\n            recommendations.append({\n                'type': 'cdn_implementation',\n                'description': 'Implement CDN to reduce origin egress',\n                'current_cost': transfers['internet_egress']['monthly_cost'],\n                'potential_savings': transfers['internet_egress']['monthly_cost'] * 0.6\n            })\n        \n        return {\n            'current_costs': transfers,\n            'recommendations': recommendations\n        }\n    \n    def create_network_optimization_script(self):\n        \"\"\"Script to implement network optimizations\"\"\"\n        return '''\n#!/usr/bin/env python3\nimport boto3\nfrom collections import defaultdict\n\nclass NetworkOptimizer:\n    def __init__(self):\n        self.ec2 = boto3.client('ec2')\n        self.cloudwatch = boto3.client('cloudwatch')\n        \n    def optimize_nat_gateways(self):\n        \"\"\"Consolidate and optimize NAT gateways\"\"\"\n        # Get all NAT gateways\n        nat_gateways = self.ec2.describe_nat_gateways()['NatGateways']\n        \n        # Group by VPC\n        vpc_nat_gateways = defaultdict(list)\n        for nat in nat_gateways:\n            if nat['State'] == 'available':\n                vpc_nat_gateways[nat['VpcId']].append(nat)\n        \n        optimizations = []\n        \n        for vpc_id, nats in vpc_nat_gateways.items():\n            if len(nats) > 1:\n                # Check if consolidation is possible\n                traffic_analysis = self._analyze_nat_traffic(nats)\n                \n                if traffic_analysis['can_consolidate']:\n                    optimizations.append({\n                        'vpc_id': vpc_id,\n                        'action': 'consolidate_nat',\n                        'current_count': len(nats),\n                        'recommended_count': traffic_analysis['recommended_count'],\n                        'monthly_savings': (len(nats) - traffic_analysis['recommended_count']) * 45\n                    })\n        \n        return optimizations\n    \n    def implement_vpc_endpoints(self):\n        \"\"\"Implement VPC endpoints for AWS services\"\"\"\n        services_to_check = ['s3', 'dynamodb', 'ec2', 'sns', 'sqs']\n        vpc_list = self.ec2.describe_vpcs()['Vpcs']\n        \n        implementations = []\n        \n        for vpc in vpc_list:\n            vpc_id = vpc['VpcId']\n            \n            # Check existing endpoints\n            existing = self._get_existing_endpoints(vpc_id)\n            \n            for service in services_to_check:\n                if service not in existing:\n                    # Check if service is being used\n                    if self._is_service_used(vpc_id, service):\n                        # Create VPC endpoint\n                        endpoint = self._create_vpc_endpoint(vpc_id, service)\n                        \n                        implementations.append({\n                            'vpc_id': vpc_id,\n                            'service': service,\n                            'endpoint_id': endpoint['VpcEndpointId'],\n                            'estimated_savings': self._estimate_endpoint_savings(vpc_id, service)\n                        })\n        \n        return implementations\n    \n    def optimize_cloudfront_distribution(self):\n        \"\"\"Optimize CloudFront for cost reduction\"\"\"\n        cloudfront = boto3.client('cloudfront')\n        \n        distributions = cloudfront.list_distributions()\n        optimizations = []\n        \n        for dist in distributions.get('DistributionList', {}).get('Items', []):\n            # Analyze distribution patterns\n            analysis = self._analyze_distribution(dist['Id'])\n            \n            if analysis['optimization_potential']:\n                optimizations.append({\n                    'distribution_id': dist['Id'],\n                    'recommendations': [\n                        {\n                            'action': 'adjust_price_class',\n                            'current': dist['PriceClass'],\n                            'recommended': analysis['recommended_price_class'],\n                            'savings': analysis['price_class_savings']\n                        },\n                        {\n                            'action': 'optimize_cache_behaviors',\n                            'cache_improvements': analysis['cache_improvements'],\n                            'savings': analysis['cache_savings']\n                        }\n                    ]\n                })\n        \n        return optimizations\n'''\n```\n\n### 7. Container Cost Optimization\n\nOptimize container workloads:\n\n**Container Cost Optimizer**\n```python\nclass ContainerCostOptimizer:\n    def optimize_ecs_costs(self):\n        \"\"\"Optimize ECS/Fargate costs\"\"\"\n        return {\n            'cluster_optimization': self._optimize_clusters(),\n            'task_rightsizing': self._rightsize_tasks(),\n            'scheduling_optimization': self._optimize_scheduling(),\n            'fargate_spot': self._implement_fargate_spot()\n        }\n    \n    def _rightsize_tasks(self):\n        \"\"\"Rightsize ECS tasks\"\"\"\n        ecs = boto3.client('ecs')\n        cloudwatch = boto3.client('cloudwatch')\n        \n        clusters = ecs.list_clusters()['clusterArns']\n        recommendations = []\n        \n        for cluster in clusters:\n            # Get services\n            services = ecs.list_services(cluster=cluster)['serviceArns']\n            \n            for service in services:\n                # Get task definition\n                service_detail = ecs.describe_services(\n                    cluster=cluster,\n                    services=[service]\n                )['services'][0]\n                \n                task_def = service_detail['taskDefinition']\n                \n                # Analyze resource utilization\n                utilization = self._analyze_task_utilization(cluster, service)\n                \n                # Generate recommendations\n                if utilization['cpu']['average'] < 30 or utilization['memory']['average'] < 40:\n                    recommendations.append({\n                        'cluster': cluster,\n                        'service': service,\n                        'current_cpu': service_detail['cpu'],\n                        'current_memory': service_detail['memory'],\n                        'recommended_cpu': int(service_detail['cpu'] * 0.7),\n                        'recommended_memory': int(service_detail['memory'] * 0.8),\n                        'monthly_savings': self._calculate_task_savings(\n                            service_detail,\n                            utilization\n                        )\n                    })\n        \n        return recommendations\n    \n    def create_k8s_cost_optimization(self):\n        \"\"\"Kubernetes cost optimization\"\"\"\n        return '''\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: cost-optimization-config\ndata:\n  vertical-pod-autoscaler.yaml: |\n    apiVersion: autoscaling.k8s.io/v1\n    kind: VerticalPodAutoscaler\n    metadata:\n      name: app-vpa\n    spec:\n      targetRef:\n        apiVersion: apps/v1\n        kind: Deployment\n        name: app-deployment\n      updatePolicy:\n        updateMode: \"Auto\"\n      resourcePolicy:\n        containerPolicies:\n        - containerName: app\n          minAllowed:\n            cpu: 100m\n            memory: 128Mi\n          maxAllowed:\n            cpu: 2\n            memory: 2Gi\n  \n  cluster-autoscaler-config.yaml: |\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: cluster-autoscaler\n    spec:\n      template:\n        spec:\n          containers:\n          - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.21.0\n            name: cluster-autoscaler\n            command:\n            - ./cluster-autoscaler\n            - --v=4\n            - --stderrthreshold=info\n            - --cloud-provider=aws\n            - --skip-nodes-with-local-storage=false\n            - --expander=priority\n            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/cluster-name\n            - --scale-down-enabled=true\n            - --scale-down-unneeded-time=10m\n            - --scale-down-utilization-threshold=0.5\n  \n  spot-instance-handler.yaml: |\n    apiVersion: apps/v1\n    kind: DaemonSet\n    metadata:\n      name: aws-node-termination-handler\n    spec:\n      selector:\n        matchLabels:\n          app: aws-node-termination-handler\n      template:\n        spec:\n          containers:\n          - name: aws-node-termination-handler\n            image: amazon/aws-node-termination-handler:v1.13.0\n            env:\n            - name: NODE_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            - name: ENABLE_SPOT_INTERRUPTION_DRAINING\n              value: \"true\"\n            - name: ENABLE_SCHEDULED_EVENT_DRAINING\n              value: \"true\"\n'''\n```\n\n### 8. Serverless Cost Optimization\n\nOptimize serverless workloads:\n\n**Serverless Optimizer**\n```python\nclass ServerlessOptimizer:\n    def optimize_lambda_costs(self):\n        \"\"\"Optimize Lambda function costs\"\"\"\n        lambda_client = boto3.client('lambda')\n        cloudwatch = boto3.client('cloudwatch')\n        \n        functions = lambda_client.list_functions()['Functions']\n        optimizations = []\n        \n        for function in functions:\n            # Analyze function performance\n            analysis = self._analyze_lambda_function(function)\n            \n            # Memory optimization\n            if analysis['memory_optimization_possible']:\n                optimizations.append({\n                    'function_name': function['FunctionName'],\n                    'type': 'memory_optimization',\n                    'current_memory': function['MemorySize'],\n                    'recommended_memory': analysis['optimal_memory'],\n                    'estimated_savings': analysis['memory_savings']\n                })\n            \n            # Timeout optimization\n            if analysis['timeout_optimization_possible']:\n                optimizations.append({\n                    'function_name': function['FunctionName'],\n                    'type': 'timeout_optimization',\n                    'current_timeout': function['Timeout'],\n                    'recommended_timeout': analysis['optimal_timeout'],\n                    'risk_reduction': 'prevents unnecessary charges from hanging functions'\n                })\n        \n        return optimizations\n    \n    def implement_lambda_cost_controls(self):\n        \"\"\"Implement Lambda cost controls\"\"\"\n        return '''\nimport json\nimport boto3\nfrom datetime import datetime\n\ndef lambda_cost_controller(event, context):\n    \"\"\"Lambda function to monitor and control Lambda costs\"\"\"\n    \n    cloudwatch = boto3.client('cloudwatch')\n    lambda_client = boto3.client('lambda')\n    \n    # Get current month costs\n    costs = get_current_month_lambda_costs()\n    \n    # Check against budget\n    budget_limit = float(os.environ.get('MONTHLY_BUDGET', '1000'))\n    \n    if costs > budget_limit * 0.8:  # 80% of budget\n        # Implement cost controls\n        high_cost_functions = identify_high_cost_functions()\n        \n        for func in high_cost_functions:\n            # Reduce concurrency\n            lambda_client.put_function_concurrency(\n                FunctionName=func['FunctionName'],\n                ReservedConcurrentExecutions=max(\n                    1, \n                    int(func['CurrentConcurrency'] * 0.5)\n                )\n            )\n            \n            # Alert\n            send_cost_alert(func, costs, budget_limit)\n    \n    # Implement provisioned concurrency optimization\n    optimize_provisioned_concurrency()\n    \n    return {\n        'statusCode': 200,\n        'body': json.dumps({\n            'current_costs': costs,\n            'budget_limit': budget_limit,\n            'actions_taken': len(high_cost_functions)\n        })\n    }\n\ndef optimize_provisioned_concurrency():\n    \"\"\"Optimize provisioned concurrency based on usage patterns\"\"\"\n    functions = get_functions_with_provisioned_concurrency()\n    \n    for func in functions:\n        # Analyze invocation patterns\n        patterns = analyze_invocation_patterns(func['FunctionName'])\n        \n        if patterns['predictable']:\n            # Schedule provisioned concurrency\n            create_scheduled_scaling(\n                func['FunctionName'],\n                patterns['peak_hours'],\n                patterns['peak_concurrency']\n            )\n        else:\n            # Consider removing provisioned concurrency\n            if patterns['avg_cold_starts'] < 10:  # per minute\n                remove_provisioned_concurrency(func['FunctionName'])\n'''\n```\n\n### 9. Cost Allocation and Tagging\n\nImplement cost allocation strategies:\n\n**Cost Allocation Manager**\n```python\nclass CostAllocationManager:\n    def implement_tagging_strategy(self):\n        \"\"\"Implement comprehensive tagging strategy\"\"\"\n        return {\n            'required_tags': [\n                {'key': 'Environment', 'values': ['prod', 'staging', 'dev', 'test']},\n                {'key': 'CostCenter', 'values': 'dynamic'},\n                {'key': 'Project', 'values': 'dynamic'},\n                {'key': 'Owner', 'values': 'dynamic'},\n                {'key': 'Department', 'values': 'dynamic'}\n            ],\n            'automation': self._create_tagging_automation(),\n            'enforcement': self._create_tag_enforcement(),\n            'reporting': self._create_cost_allocation_reports()\n        }\n    \n    def _create_tagging_automation(self):\n        \"\"\"Automate resource tagging\"\"\"\n        return '''\nimport boto3\nfrom datetime import datetime\n\nclass AutoTagger:\n    def __init__(self):\n        self.tag_policies = self.load_tag_policies()\n        \n    def auto_tag_resources(self, event, context):\n        \"\"\"Auto-tag resources on creation\"\"\"\n        \n        # Parse CloudTrail event\n        detail = event['detail']\n        event_name = detail['eventName']\n        \n        # Map events to resource types\n        if event_name.startswith('Create'):\n            resource_arn = self.extract_resource_arn(detail)\n            \n            if resource_arn:\n                # Determine tags\n                tags = self.determine_tags(detail)\n                \n                # Apply tags\n                self.apply_tags(resource_arn, tags)\n                \n                # Log tagging action\n                self.log_tagging(resource_arn, tags)\n    \n    def determine_tags(self, event_detail):\n        \"\"\"Determine tags based on context\"\"\"\n        tags = []\n        \n        # User-based tags\n        user_identity = event_detail.get('userIdentity', {})\n        if 'userName' in user_identity:\n            tags.append({\n                'Key': 'Creator',\n                'Value': user_identity['userName']\n            })\n        \n        # Time-based tags\n        tags.append({\n            'Key': 'CreatedDate',\n            'Value': datetime.now().strftime('%Y-%m-%d')\n        })\n        \n        # Environment inference\n        if 'prod' in event_detail.get('sourceIPAddress', ''):\n            env = 'prod'\n        elif 'dev' in event_detail.get('sourceIPAddress', ''):\n            env = 'dev'\n        else:\n            env = 'unknown'\n            \n        tags.append({\n            'Key': 'Environment',\n            'Value': env\n        })\n        \n        return tags\n    \n    def create_cost_allocation_dashboard(self):\n        \"\"\"Create cost allocation dashboard\"\"\"\n        return \"\"\"\n        SELECT \n            tags.environment,\n            tags.department,\n            tags.project,\n            SUM(costs.amount) as total_cost,\n            SUM(costs.amount) / SUM(SUM(costs.amount)) OVER () * 100 as percentage\n        FROM \n            aws_costs costs\n        JOIN \n            resource_tags tags ON costs.resource_id = tags.resource_id\n        WHERE \n            costs.date >= DATE_TRUNC('month', CURRENT_DATE)\n        GROUP BY \n            tags.environment,\n            tags.department,\n            tags.project\n        ORDER BY \n            total_cost DESC\n        \"\"\"\n'''\n```\n\n### 10. Cost Monitoring and Alerts\n\nImplement proactive cost monitoring:\n\n**Cost Monitoring System**\n```python\nclass CostMonitoringSystem:\n    def setup_cost_alerts(self):\n        \"\"\"Setup comprehensive cost alerting\"\"\"\n        alerts = []\n        \n        # Budget alerts\n        alerts.extend(self._create_budget_alerts())\n        \n        # Anomaly detection\n        alerts.extend(self._create_anomaly_alerts())\n        \n        # Threshold alerts\n        alerts.extend(self._create_threshold_alerts())\n        \n        # Forecast alerts\n        alerts.extend(self._create_forecast_alerts())\n        \n        return alerts\n    \n    def _create_anomaly_alerts(self):\n        \"\"\"Create anomaly detection alerts\"\"\"\n        ce = boto3.client('ce')\n        \n        # Create anomaly monitor\n        monitor = ce.create_anomaly_monitor(\n            AnomalyMonitor={\n                'MonitorName': 'ServiceCostMonitor',\n                'MonitorType': 'DIMENSIONAL',\n                'MonitorDimension': 'SERVICE'\n            }\n        )\n        \n        # Create anomaly subscription\n        subscription = ce.create_anomaly_subscription(\n            AnomalySubscription={\n                'SubscriptionName': 'CostAnomalyAlerts',\n                'Threshold': 100.0,  # Alert on anomalies > $100\n                'Frequency': 'DAILY',\n                'MonitorArnList': [monitor['MonitorArn']],\n                'Subscribers': [\n                    {\n                        'Type': 'EMAIL',\n                        'Address': 'team@company.com'\n                    },\n                    {\n                        'Type': 'SNS',\n                        'Address': 'arn:aws:sns:us-east-1:123456789012:cost-alerts'\n                    }\n                ]\n            }\n        )\n        \n        return [monitor, subscription]\n    \n    def create_cost_dashboard(self):\n        \"\"\"Create executive cost dashboard\"\"\"\n        return '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Cloud Cost Dashboard</title>\n    <script src=\"https://d3js.org/d3.v7.min.js\"></script>\n    <style>\n        .metric-card {\n            background: #f5f5f5;\n            padding: 20px;\n            margin: 10px;\n            border-radius: 8px;\n            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n        }\n        .alert { color: #d32f2f; }\n        .warning { color: #f57c00; }\n        .success { color: #388e3c; }\n    </style>\n</head>\n<body>\n    <div id=\"dashboard\">\n        <h1>Cloud Cost Optimization Dashboard</h1>\n        \n        <div class=\"summary-row\">\n            <div class=\"metric-card\">\n                <h3>Current Month Spend</h3>\n                <div class=\"metric\">${current_spend}</div>\n                <div class=\"trend ${spend_trend_class}\">${spend_trend}% vs last month</div>\n            </div>\n            \n            <div class=\"metric-card\">\n                <h3>Projected Month End</h3>\n                <div class=\"metric\">${projected_spend}</div>\n                <div class=\"budget-status\">Budget: ${budget}</div>\n            </div>\n            \n            <div class=\"metric-card\">\n                <h3>Optimization Opportunities</h3>\n                <div class=\"metric\">${total_savings_identified}</div>\n                <div class=\"count\">{opportunity_count} recommendations</div>\n            </div>\n            \n            <div class=\"metric-card\">\n                <h3>Realized Savings</h3>\n                <div class=\"metric\">${realized_savings_mtd}</div>\n                <div class=\"count\">YTD: ${realized_savings_ytd}</div>\n            </div>\n        </div>\n        \n        <div class=\"charts-row\">\n            <div id=\"spend-trend-chart\"></div>\n            <div id=\"service-breakdown-chart\"></div>\n            <div id=\"optimization-progress-chart\"></div>\n        </div>\n        \n        <div class=\"recommendations-section\">\n            <h2>Top Optimization Recommendations</h2>\n            <table id=\"recommendations-table\">\n                <thead>\n                    <tr>\n                        <th>Priority</th>\n                        <th>Service</th>\n                        <th>Recommendation</th>\n                        <th>Monthly Savings</th>\n                        <th>Effort</th>\n                        <th>Action</th>\n                    </tr>\n                </thead>\n                <tbody>\n                    ${recommendation_rows}\n                </tbody>\n            </table>\n        </div>\n    </div>\n    \n    <script>\n        // Real-time updates\n        setInterval(updateDashboard, 60000);\n        \n        // Initialize charts\n        initializeCharts();\n    </script>\n</body>\n</html>\n'''\n```\n\n## Output Format\n\n1. **Cost Analysis Report**: Comprehensive breakdown of current cloud costs\n2. **Optimization Recommendations**: Prioritized list of cost-saving opportunities\n3. **Implementation Scripts**: Automated scripts for implementing optimizations\n4. **Monitoring Dashboards**: Real-time cost tracking and alerting\n5. **ROI Calculations**: Detailed savings projections and payback periods\n6. **Risk Assessment**: Analysis of risks associated with each optimization\n7. **Implementation Roadmap**: Phased approach to cost optimization\n8. **Best Practices Guide**: Long-term cost management strategies\n\nFocus on delivering immediate cost savings while establishing sustainable cost optimization practices that maintain performance and reliability standards."
              }
            ],
            "skills": []
          },
          {
            "name": "data-validation-suite",
            "description": null,
            "source": "./plugins/data-validation-suite",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install data-validation-suite@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "python-development",
            "description": null,
            "source": "./plugins/python-development",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install python-development@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/python-scaffold",
                "description": null,
                "path": "plugins/python-development/commands/python-scaffold.md",
                "frontmatter": null,
                "content": "# Python Project Scaffolding\n\nYou are a Python project architecture expert specializing in scaffolding production-ready Python applications. Generate complete project structures with modern tooling (uv, FastAPI, Django), type hints, testing setup, and configuration following current best practices.\n\n## Context\n\nThe user needs automated Python project scaffolding that creates consistent, type-safe applications with proper structure, dependency management, testing, and tooling. Focus on modern Python patterns and scalable architecture.\n\n## Requirements\n\n$ARGUMENTS\n\n## Instructions\n\n### 1. Analyze Project Type\n\nDetermine the project type from user requirements:\n- **FastAPI**: REST APIs, microservices, async applications\n- **Django**: Full-stack web applications, admin panels, ORM-heavy projects\n- **Library**: Reusable packages, utilities, tools\n- **CLI**: Command-line tools, automation scripts\n- **Generic**: Standard Python applications\n\n### 2. Initialize Project with uv\n\n```bash\n# Create new project with uv\nuv init <project-name>\ncd <project-name>\n\n# Initialize git repository\ngit init\necho \".venv/\" >> .gitignore\necho \"*.pyc\" >> .gitignore\necho \"__pycache__/\" >> .gitignore\necho \".pytest_cache/\" >> .gitignore\necho \".ruff_cache/\" >> .gitignore\n\n# Create virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n```\n\n### 3. Generate FastAPI Project Structure\n\n```\nfastapi-project/\n├── pyproject.toml\n├── README.md\n├── .gitignore\n├── .env.example\n├── src/\n│   └── project_name/\n│       ├── __init__.py\n│       ├── main.py\n│       ├── config.py\n│       ├── api/\n│       │   ├── __init__.py\n│       │   ├── deps.py\n│       │   ├── v1/\n│       │   │   ├── __init__.py\n│       │   │   ├── endpoints/\n│       │   │   │   ├── __init__.py\n│       │   │   │   ├── users.py\n│       │   │   │   └── health.py\n│       │   │   └── router.py\n│       ├── core/\n│       │   ├── __init__.py\n│       │   ├── security.py\n│       │   └── database.py\n│       ├── models/\n│       │   ├── __init__.py\n│       │   └── user.py\n│       ├── schemas/\n│       │   ├── __init__.py\n│       │   └── user.py\n│       └── services/\n│           ├── __init__.py\n│           └── user_service.py\n└── tests/\n    ├── __init__.py\n    ├── conftest.py\n    └── api/\n        ├── __init__.py\n        └── test_users.py\n```\n\n**pyproject.toml**:\n```toml\n[project]\nname = \"project-name\"\nversion = \"0.1.0\"\ndescription = \"FastAPI project description\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"fastapi>=0.110.0\",\n    \"uvicorn[standard]>=0.27.0\",\n    \"pydantic>=2.6.0\",\n    \"pydantic-settings>=2.1.0\",\n    \"sqlalchemy>=2.0.0\",\n    \"alembic>=1.13.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=8.0.0\",\n    \"pytest-asyncio>=0.23.0\",\n    \"httpx>=0.26.0\",\n    \"ruff>=0.2.0\",\n]\n\n[tool.ruff]\nline-length = 100\ntarget-version = \"py311\"\n\n[tool.ruff.lint]\nselect = [\"E\", \"F\", \"I\", \"N\", \"W\", \"UP\"]\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\nasyncio_mode = \"auto\"\n```\n\n**src/project_name/main.py**:\n```python\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom .api.v1.router import api_router\nfrom .config import settings\n\napp = FastAPI(\n    title=settings.PROJECT_NAME,\n    version=settings.VERSION,\n    openapi_url=f\"{settings.API_V1_PREFIX}/openapi.json\",\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=settings.ALLOWED_ORIGINS,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\napp.include_router(api_router, prefix=settings.API_V1_PREFIX)\n\n@app.get(\"/health\")\nasync def health_check() -> dict[str, str]:\n    return {\"status\": \"healthy\"}\n```\n\n### 4. Generate Django Project Structure\n\n```bash\n# Install Django with uv\nuv add django django-environ django-debug-toolbar\n\n# Create Django project\ndjango-admin startproject config .\npython manage.py startapp core\n```\n\n**pyproject.toml for Django**:\n```toml\n[project]\nname = \"django-project\"\nversion = \"0.1.0\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"django>=5.0.0\",\n    \"django-environ>=0.11.0\",\n    \"psycopg[binary]>=3.1.0\",\n    \"gunicorn>=21.2.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"django-debug-toolbar>=4.3.0\",\n    \"pytest-django>=4.8.0\",\n    \"ruff>=0.2.0\",\n]\n```\n\n### 5. Generate Python Library Structure\n\n```\nlibrary-name/\n├── pyproject.toml\n├── README.md\n├── LICENSE\n├── src/\n│   └── library_name/\n│       ├── __init__.py\n│       ├── py.typed\n│       └── core.py\n└── tests/\n    ├── __init__.py\n    └── test_core.py\n```\n\n**pyproject.toml for Library**:\n```toml\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"library-name\"\nversion = \"0.1.0\"\ndescription = \"Library description\"\nreadme = \"README.md\"\nrequires-python = \">=3.11\"\nlicense = {text = \"MIT\"}\nauthors = [\n    {name = \"Your Name\", email = \"email@example.com\"}\n]\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n]\ndependencies = []\n\n[project.optional-dependencies]\ndev = [\"pytest>=8.0.0\", \"ruff>=0.2.0\", \"mypy>=1.8.0\"]\n\n[tool.hatch.build.targets.wheel]\npackages = [\"src/library_name\"]\n```\n\n### 6. Generate CLI Tool Structure\n\n```python\n# pyproject.toml\n[project.scripts]\ncli-name = \"project_name.cli:main\"\n\n[project]\ndependencies = [\n    \"typer>=0.9.0\",\n    \"rich>=13.7.0\",\n]\n```\n\n**src/project_name/cli.py**:\n```python\nimport typer\nfrom rich.console import Console\n\napp = typer.Typer()\nconsole = Console()\n\n@app.command()\ndef hello(name: str = typer.Option(..., \"--name\", \"-n\", help=\"Your name\")):\n    \"\"\"Greet someone\"\"\"\n    console.print(f\"[bold green]Hello {name}![/bold green]\")\n\ndef main():\n    app()\n```\n\n### 7. Configure Development Tools\n\n**.env.example**:\n```env\n# Application\nPROJECT_NAME=\"Project Name\"\nVERSION=\"0.1.0\"\nDEBUG=True\n\n# API\nAPI_V1_PREFIX=\"/api/v1\"\nALLOWED_ORIGINS=[\"http://localhost:3000\"]\n\n# Database\nDATABASE_URL=\"postgresql://user:pass@localhost:5432/dbname\"\n\n# Security\nSECRET_KEY=\"your-secret-key-here\"\n```\n\n**Makefile**:\n```makefile\n.PHONY: install dev test lint format clean\n\ninstall:\n\tuv sync\n\ndev:\n\tuv run uvicorn src.project_name.main:app --reload\n\ntest:\n\tuv run pytest -v\n\nlint:\n\tuv run ruff check .\n\nformat:\n\tuv run ruff format .\n\nclean:\n\tfind . -type d -name __pycache__ -exec rm -rf {} +\n\tfind . -type f -name \"*.pyc\" -delete\n\trm -rf .pytest_cache .ruff_cache\n```\n\n## Output Format\n\n1. **Project Structure**: Complete directory tree with all necessary files\n2. **Configuration**: pyproject.toml with dependencies and tool settings\n3. **Entry Point**: Main application file (main.py, cli.py, etc.)\n4. **Tests**: Test structure with pytest configuration\n5. **Documentation**: README with setup and usage instructions\n6. **Development Tools**: Makefile, .env.example, .gitignore\n\nFocus on creating production-ready Python projects with modern tooling, type safety, and comprehensive testing setup.\n"
              }
            ],
            "skills": [
              {
                "name": "async-python-patterns",
                "description": "Master Python asyncio, concurrent programming, and async/await patterns for high-performance applications. Use when building async APIs, concurrent systems, or I/O-bound applications requiring non-blocking operations.",
                "path": "plugins/python-development/skills/async-python-patterns/SKILL.md",
                "frontmatter": {
                  "name": "async-python-patterns",
                  "description": "Master Python asyncio, concurrent programming, and async/await patterns for high-performance applications. Use when building async APIs, concurrent systems, or I/O-bound applications requiring non-blocking operations."
                },
                "content": "# Async Python Patterns\n\nComprehensive guidance for implementing asynchronous Python applications using asyncio, concurrent programming patterns, and async/await for building high-performance, non-blocking systems.\n\n## When to Use This Skill\n\n- Building async web APIs (FastAPI, aiohttp, Sanic)\n- Implementing concurrent I/O operations (database, file, network)\n- Creating web scrapers with concurrent requests\n- Developing real-time applications (WebSocket servers, chat systems)\n- Processing multiple independent tasks simultaneously\n- Building microservices with async communication\n- Optimizing I/O-bound workloads\n- Implementing async background tasks and queues\n\n## Core Concepts\n\n### 1. Event Loop\nThe event loop is the heart of asyncio, managing and scheduling asynchronous tasks.\n\n**Key characteristics:**\n- Single-threaded cooperative multitasking\n- Schedules coroutines for execution\n- Handles I/O operations without blocking\n- Manages callbacks and futures\n\n### 2. Coroutines\nFunctions defined with `async def` that can be paused and resumed.\n\n**Syntax:**\n```python\nasync def my_coroutine():\n    result = await some_async_operation()\n    return result\n```\n\n### 3. Tasks\nScheduled coroutines that run concurrently on the event loop.\n\n### 4. Futures\nLow-level objects representing eventual results of async operations.\n\n### 5. Async Context Managers\nResources that support `async with` for proper cleanup.\n\n### 6. Async Iterators\nObjects that support `async for` for iterating over async data sources.\n\n## Quick Start\n\n```python\nimport asyncio\n\nasync def main():\n    print(\"Hello\")\n    await asyncio.sleep(1)\n    print(\"World\")\n\n# Python 3.7+\nasyncio.run(main())\n```\n\n## Fundamental Patterns\n\n### Pattern 1: Basic Async/Await\n\n```python\nimport asyncio\n\nasync def fetch_data(url: str) -> dict:\n    \"\"\"Fetch data from URL asynchronously.\"\"\"\n    await asyncio.sleep(1)  # Simulate I/O\n    return {\"url\": url, \"data\": \"result\"}\n\nasync def main():\n    result = await fetch_data(\"https://api.example.com\")\n    print(result)\n\nasyncio.run(main())\n```\n\n### Pattern 2: Concurrent Execution with gather()\n\n```python\nimport asyncio\nfrom typing import List\n\nasync def fetch_user(user_id: int) -> dict:\n    \"\"\"Fetch user data.\"\"\"\n    await asyncio.sleep(0.5)\n    return {\"id\": user_id, \"name\": f\"User {user_id}\"}\n\nasync def fetch_all_users(user_ids: List[int]) -> List[dict]:\n    \"\"\"Fetch multiple users concurrently.\"\"\"\n    tasks = [fetch_user(uid) for uid in user_ids]\n    results = await asyncio.gather(*tasks)\n    return results\n\nasync def main():\n    user_ids = [1, 2, 3, 4, 5]\n    users = await fetch_all_users(user_ids)\n    print(f\"Fetched {len(users)} users\")\n\nasyncio.run(main())\n```\n\n### Pattern 3: Task Creation and Management\n\n```python\nimport asyncio\n\nasync def background_task(name: str, delay: int):\n    \"\"\"Long-running background task.\"\"\"\n    print(f\"{name} started\")\n    await asyncio.sleep(delay)\n    print(f\"{name} completed\")\n    return f\"Result from {name}\"\n\nasync def main():\n    # Create tasks\n    task1 = asyncio.create_task(background_task(\"Task 1\", 2))\n    task2 = asyncio.create_task(background_task(\"Task 2\", 1))\n\n    # Do other work\n    print(\"Main: doing other work\")\n    await asyncio.sleep(0.5)\n\n    # Wait for tasks\n    result1 = await task1\n    result2 = await task2\n\n    print(f\"Results: {result1}, {result2}\")\n\nasyncio.run(main())\n```\n\n### Pattern 4: Error Handling in Async Code\n\n```python\nimport asyncio\nfrom typing import List, Optional\n\nasync def risky_operation(item_id: int) -> dict:\n    \"\"\"Operation that might fail.\"\"\"\n    await asyncio.sleep(0.1)\n    if item_id % 3 == 0:\n        raise ValueError(f\"Item {item_id} failed\")\n    return {\"id\": item_id, \"status\": \"success\"}\n\nasync def safe_operation(item_id: int) -> Optional[dict]:\n    \"\"\"Wrapper with error handling.\"\"\"\n    try:\n        return await risky_operation(item_id)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return None\n\nasync def process_items(item_ids: List[int]):\n    \"\"\"Process multiple items with error handling.\"\"\"\n    tasks = [safe_operation(iid) for iid in item_ids]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Filter out failures\n    successful = [r for r in results if r is not None and not isinstance(r, Exception)]\n    failed = [r for r in results if isinstance(r, Exception)]\n\n    print(f\"Success: {len(successful)}, Failed: {len(failed)}\")\n    return successful\n\nasyncio.run(process_items([1, 2, 3, 4, 5, 6]))\n```\n\n### Pattern 5: Timeout Handling\n\n```python\nimport asyncio\n\nasync def slow_operation(delay: int) -> str:\n    \"\"\"Operation that takes time.\"\"\"\n    await asyncio.sleep(delay)\n    return f\"Completed after {delay}s\"\n\nasync def with_timeout():\n    \"\"\"Execute operation with timeout.\"\"\"\n    try:\n        result = await asyncio.wait_for(slow_operation(5), timeout=2.0)\n        print(result)\n    except asyncio.TimeoutError:\n        print(\"Operation timed out\")\n\nasyncio.run(with_timeout())\n```\n\n## Advanced Patterns\n\n### Pattern 6: Async Context Managers\n\n```python\nimport asyncio\nfrom typing import Optional\n\nclass AsyncDatabaseConnection:\n    \"\"\"Async database connection context manager.\"\"\"\n\n    def __init__(self, dsn: str):\n        self.dsn = dsn\n        self.connection: Optional[object] = None\n\n    async def __aenter__(self):\n        print(\"Opening connection\")\n        await asyncio.sleep(0.1)  # Simulate connection\n        self.connection = {\"dsn\": self.dsn, \"connected\": True}\n        return self.connection\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        print(\"Closing connection\")\n        await asyncio.sleep(0.1)  # Simulate cleanup\n        self.connection = None\n\nasync def query_database():\n    \"\"\"Use async context manager.\"\"\"\n    async with AsyncDatabaseConnection(\"postgresql://localhost\") as conn:\n        print(f\"Using connection: {conn}\")\n        await asyncio.sleep(0.2)  # Simulate query\n        return {\"rows\": 10}\n\nasyncio.run(query_database())\n```\n\n### Pattern 7: Async Iterators and Generators\n\n```python\nimport asyncio\nfrom typing import AsyncIterator\n\nasync def async_range(start: int, end: int, delay: float = 0.1) -> AsyncIterator[int]:\n    \"\"\"Async generator that yields numbers with delay.\"\"\"\n    for i in range(start, end):\n        await asyncio.sleep(delay)\n        yield i\n\nasync def fetch_pages(url: str, max_pages: int) -> AsyncIterator[dict]:\n    \"\"\"Fetch paginated data asynchronously.\"\"\"\n    for page in range(1, max_pages + 1):\n        await asyncio.sleep(0.2)  # Simulate API call\n        yield {\n            \"page\": page,\n            \"url\": f\"{url}?page={page}\",\n            \"data\": [f\"item_{page}_{i}\" for i in range(5)]\n        }\n\nasync def consume_async_iterator():\n    \"\"\"Consume async iterator.\"\"\"\n    async for number in async_range(1, 5):\n        print(f\"Number: {number}\")\n\n    print(\"\\nFetching pages:\")\n    async for page_data in fetch_pages(\"https://api.example.com/items\", 3):\n        print(f\"Page {page_data['page']}: {len(page_data['data'])} items\")\n\nasyncio.run(consume_async_iterator())\n```\n\n### Pattern 8: Producer-Consumer Pattern\n\n```python\nimport asyncio\nfrom asyncio import Queue\nfrom typing import Optional\n\nasync def producer(queue: Queue, producer_id: int, num_items: int):\n    \"\"\"Produce items and put them in queue.\"\"\"\n    for i in range(num_items):\n        item = f\"Item-{producer_id}-{i}\"\n        await queue.put(item)\n        print(f\"Producer {producer_id} produced: {item}\")\n        await asyncio.sleep(0.1)\n    await queue.put(None)  # Signal completion\n\nasync def consumer(queue: Queue, consumer_id: int):\n    \"\"\"Consume items from queue.\"\"\"\n    while True:\n        item = await queue.get()\n        if item is None:\n            queue.task_done()\n            break\n\n        print(f\"Consumer {consumer_id} processing: {item}\")\n        await asyncio.sleep(0.2)  # Simulate work\n        queue.task_done()\n\nasync def producer_consumer_example():\n    \"\"\"Run producer-consumer pattern.\"\"\"\n    queue = Queue(maxsize=10)\n\n    # Create tasks\n    producers = [\n        asyncio.create_task(producer(queue, i, 5))\n        for i in range(2)\n    ]\n\n    consumers = [\n        asyncio.create_task(consumer(queue, i))\n        for i in range(3)\n    ]\n\n    # Wait for producers\n    await asyncio.gather(*producers)\n\n    # Wait for queue to be empty\n    await queue.join()\n\n    # Cancel consumers\n    for c in consumers:\n        c.cancel()\n\nasyncio.run(producer_consumer_example())\n```\n\n### Pattern 9: Semaphore for Rate Limiting\n\n```python\nimport asyncio\nfrom typing import List\n\nasync def api_call(url: str, semaphore: asyncio.Semaphore) -> dict:\n    \"\"\"Make API call with rate limiting.\"\"\"\n    async with semaphore:\n        print(f\"Calling {url}\")\n        await asyncio.sleep(0.5)  # Simulate API call\n        return {\"url\": url, \"status\": 200}\n\nasync def rate_limited_requests(urls: List[str], max_concurrent: int = 5):\n    \"\"\"Make multiple requests with rate limiting.\"\"\"\n    semaphore = asyncio.Semaphore(max_concurrent)\n    tasks = [api_call(url, semaphore) for url in urls]\n    results = await asyncio.gather(*tasks)\n    return results\n\nasync def main():\n    urls = [f\"https://api.example.com/item/{i}\" for i in range(20)]\n    results = await rate_limited_requests(urls, max_concurrent=3)\n    print(f\"Completed {len(results)} requests\")\n\nasyncio.run(main())\n```\n\n### Pattern 10: Async Locks and Synchronization\n\n```python\nimport asyncio\n\nclass AsyncCounter:\n    \"\"\"Thread-safe async counter.\"\"\"\n\n    def __init__(self):\n        self.value = 0\n        self.lock = asyncio.Lock()\n\n    async def increment(self):\n        \"\"\"Safely increment counter.\"\"\"\n        async with self.lock:\n            current = self.value\n            await asyncio.sleep(0.01)  # Simulate work\n            self.value = current + 1\n\n    async def get_value(self) -> int:\n        \"\"\"Get current value.\"\"\"\n        async with self.lock:\n            return self.value\n\nasync def worker(counter: AsyncCounter, worker_id: int):\n    \"\"\"Worker that increments counter.\"\"\"\n    for _ in range(10):\n        await counter.increment()\n        print(f\"Worker {worker_id} incremented\")\n\nasync def test_counter():\n    \"\"\"Test concurrent counter.\"\"\"\n    counter = AsyncCounter()\n\n    workers = [asyncio.create_task(worker(counter, i)) for i in range(5)]\n    await asyncio.gather(*workers)\n\n    final_value = await counter.get_value()\n    print(f\"Final counter value: {final_value}\")\n\nasyncio.run(test_counter())\n```\n\n## Real-World Applications\n\n### Web Scraping with aiohttp\n\n```python\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict\n\nasync def fetch_url(session: aiohttp.ClientSession, url: str) -> Dict:\n    \"\"\"Fetch single URL.\"\"\"\n    try:\n        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:\n            text = await response.text()\n            return {\n                \"url\": url,\n                \"status\": response.status,\n                \"length\": len(text)\n            }\n    except Exception as e:\n        return {\"url\": url, \"error\": str(e)}\n\nasync def scrape_urls(urls: List[str]) -> List[Dict]:\n    \"\"\"Scrape multiple URLs concurrently.\"\"\"\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_url(session, url) for url in urls]\n        results = await asyncio.gather(*tasks)\n        return results\n\nasync def main():\n    urls = [\n        \"https://httpbin.org/delay/1\",\n        \"https://httpbin.org/delay/2\",\n        \"https://httpbin.org/status/404\",\n    ]\n\n    results = await scrape_urls(urls)\n    for result in results:\n        print(result)\n\nasyncio.run(main())\n```\n\n### Async Database Operations\n\n```python\nimport asyncio\nfrom typing import List, Optional\n\n# Simulated async database client\nclass AsyncDB:\n    \"\"\"Simulated async database.\"\"\"\n\n    async def execute(self, query: str) -> List[dict]:\n        \"\"\"Execute query.\"\"\"\n        await asyncio.sleep(0.1)\n        return [{\"id\": 1, \"name\": \"Example\"}]\n\n    async def fetch_one(self, query: str) -> Optional[dict]:\n        \"\"\"Fetch single row.\"\"\"\n        await asyncio.sleep(0.1)\n        return {\"id\": 1, \"name\": \"Example\"}\n\nasync def get_user_data(db: AsyncDB, user_id: int) -> dict:\n    \"\"\"Fetch user and related data concurrently.\"\"\"\n    user_task = db.fetch_one(f\"SELECT * FROM users WHERE id = {user_id}\")\n    orders_task = db.execute(f\"SELECT * FROM orders WHERE user_id = {user_id}\")\n    profile_task = db.fetch_one(f\"SELECT * FROM profiles WHERE user_id = {user_id}\")\n\n    user, orders, profile = await asyncio.gather(user_task, orders_task, profile_task)\n\n    return {\n        \"user\": user,\n        \"orders\": orders,\n        \"profile\": profile\n    }\n\nasync def main():\n    db = AsyncDB()\n    user_data = await get_user_data(db, 1)\n    print(user_data)\n\nasyncio.run(main())\n```\n\n### WebSocket Server\n\n```python\nimport asyncio\nfrom typing import Set\n\n# Simulated WebSocket connection\nclass WebSocket:\n    \"\"\"Simulated WebSocket.\"\"\"\n\n    def __init__(self, client_id: str):\n        self.client_id = client_id\n\n    async def send(self, message: str):\n        \"\"\"Send message.\"\"\"\n        print(f\"Sending to {self.client_id}: {message}\")\n        await asyncio.sleep(0.01)\n\n    async def recv(self) -> str:\n        \"\"\"Receive message.\"\"\"\n        await asyncio.sleep(1)\n        return f\"Message from {self.client_id}\"\n\nclass WebSocketServer:\n    \"\"\"Simple WebSocket server.\"\"\"\n\n    def __init__(self):\n        self.clients: Set[WebSocket] = set()\n\n    async def register(self, websocket: WebSocket):\n        \"\"\"Register new client.\"\"\"\n        self.clients.add(websocket)\n        print(f\"Client {websocket.client_id} connected\")\n\n    async def unregister(self, websocket: WebSocket):\n        \"\"\"Unregister client.\"\"\"\n        self.clients.remove(websocket)\n        print(f\"Client {websocket.client_id} disconnected\")\n\n    async def broadcast(self, message: str):\n        \"\"\"Broadcast message to all clients.\"\"\"\n        if self.clients:\n            tasks = [client.send(message) for client in self.clients]\n            await asyncio.gather(*tasks)\n\n    async def handle_client(self, websocket: WebSocket):\n        \"\"\"Handle individual client connection.\"\"\"\n        await self.register(websocket)\n        try:\n            async for message in self.message_iterator(websocket):\n                await self.broadcast(f\"{websocket.client_id}: {message}\")\n        finally:\n            await self.unregister(websocket)\n\n    async def message_iterator(self, websocket: WebSocket):\n        \"\"\"Iterate over messages from client.\"\"\"\n        for _ in range(3):  # Simulate 3 messages\n            yield await websocket.recv()\n```\n\n## Performance Best Practices\n\n### 1. Use Connection Pools\n\n```python\nimport asyncio\nimport aiohttp\n\nasync def with_connection_pool():\n    \"\"\"Use connection pool for efficiency.\"\"\"\n    connector = aiohttp.TCPConnector(limit=100, limit_per_host=10)\n\n    async with aiohttp.ClientSession(connector=connector) as session:\n        tasks = [session.get(f\"https://api.example.com/item/{i}\") for i in range(50)]\n        responses = await asyncio.gather(*tasks)\n        return responses\n```\n\n### 2. Batch Operations\n\n```python\nasync def batch_process(items: List[str], batch_size: int = 10):\n    \"\"\"Process items in batches.\"\"\"\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i + batch_size]\n        tasks = [process_item(item) for item in batch]\n        await asyncio.gather(*tasks)\n        print(f\"Processed batch {i // batch_size + 1}\")\n\nasync def process_item(item: str):\n    \"\"\"Process single item.\"\"\"\n    await asyncio.sleep(0.1)\n    return f\"Processed: {item}\"\n```\n\n### 3. Avoid Blocking Operations\n\n```python\nimport asyncio\nimport concurrent.futures\nfrom typing import Any\n\ndef blocking_operation(data: Any) -> Any:\n    \"\"\"CPU-intensive blocking operation.\"\"\"\n    import time\n    time.sleep(1)\n    return data * 2\n\nasync def run_in_executor(data: Any) -> Any:\n    \"\"\"Run blocking operation in thread pool.\"\"\"\n    loop = asyncio.get_event_loop()\n    with concurrent.futures.ThreadPoolExecutor() as pool:\n        result = await loop.run_in_executor(pool, blocking_operation, data)\n        return result\n\nasync def main():\n    results = await asyncio.gather(*[run_in_executor(i) for i in range(5)])\n    print(results)\n\nasyncio.run(main())\n```\n\n## Common Pitfalls\n\n### 1. Forgetting await\n\n```python\n# Wrong - returns coroutine object, doesn't execute\nresult = async_function()\n\n# Correct\nresult = await async_function()\n```\n\n### 2. Blocking the Event Loop\n\n```python\n# Wrong - blocks event loop\nimport time\nasync def bad():\n    time.sleep(1)  # Blocks!\n\n# Correct\nasync def good():\n    await asyncio.sleep(1)  # Non-blocking\n```\n\n### 3. Not Handling Cancellation\n\n```python\nasync def cancelable_task():\n    \"\"\"Task that handles cancellation.\"\"\"\n    try:\n        while True:\n            await asyncio.sleep(1)\n            print(\"Working...\")\n    except asyncio.CancelledError:\n        print(\"Task cancelled, cleaning up...\")\n        # Perform cleanup\n        raise  # Re-raise to propagate cancellation\n```\n\n### 4. Mixing Sync and Async Code\n\n```python\n# Wrong - can't call async from sync directly\ndef sync_function():\n    result = await async_function()  # SyntaxError!\n\n# Correct\ndef sync_function():\n    result = asyncio.run(async_function())\n```\n\n## Testing Async Code\n\n```python\nimport asyncio\nimport pytest\n\n# Using pytest-asyncio\n@pytest.mark.asyncio\nasync def test_async_function():\n    \"\"\"Test async function.\"\"\"\n    result = await fetch_data(\"https://api.example.com\")\n    assert result is not None\n\n@pytest.mark.asyncio\nasync def test_with_timeout():\n    \"\"\"Test with timeout.\"\"\"\n    with pytest.raises(asyncio.TimeoutError):\n        await asyncio.wait_for(slow_operation(5), timeout=1.0)\n```\n\n## Resources\n\n- **Python asyncio documentation**: https://docs.python.org/3/library/asyncio.html\n- **aiohttp**: Async HTTP client/server\n- **FastAPI**: Modern async web framework\n- **asyncpg**: Async PostgreSQL driver\n- **motor**: Async MongoDB driver\n\n## Best Practices Summary\n\n1. **Use asyncio.run()** for entry point (Python 3.7+)\n2. **Always await coroutines** to execute them\n3. **Use gather() for concurrent execution** of multiple tasks\n4. **Implement proper error handling** with try/except\n5. **Use timeouts** to prevent hanging operations\n6. **Pool connections** for better performance\n7. **Avoid blocking operations** in async code\n8. **Use semaphores** for rate limiting\n9. **Handle task cancellation** properly\n10. **Test async code** with pytest-asyncio"
              },
              {
                "name": "python-packaging",
                "description": "Create distributable Python packages with proper project structure, setup.py/pyproject.toml, and publishing to PyPI. Use when packaging Python libraries, creating CLI tools, or distributing Python code.",
                "path": "plugins/python-development/skills/python-packaging/SKILL.md",
                "frontmatter": {
                  "name": "python-packaging",
                  "description": "Create distributable Python packages with proper project structure, setup.py/pyproject.toml, and publishing to PyPI. Use when packaging Python libraries, creating CLI tools, or distributing Python code."
                },
                "content": "# Python Packaging\n\nComprehensive guide to creating, structuring, and distributing Python packages using modern packaging tools, pyproject.toml, and publishing to PyPI.\n\n## When to Use This Skill\n\n- Creating Python libraries for distribution\n- Building command-line tools with entry points\n- Publishing packages to PyPI or private repositories\n- Setting up Python project structure\n- Creating installable packages with dependencies\n- Building wheels and source distributions\n- Versioning and releasing Python packages\n- Creating namespace packages\n- Implementing package metadata and classifiers\n\n## Core Concepts\n\n### 1. Package Structure\n- **Source layout**: `src/package_name/` (recommended)\n- **Flat layout**: `package_name/` (simpler but less flexible)\n- **Package metadata**: pyproject.toml, setup.py, or setup.cfg\n- **Distribution formats**: wheel (.whl) and source distribution (.tar.gz)\n\n### 2. Modern Packaging Standards\n- **PEP 517/518**: Build system requirements\n- **PEP 621**: Metadata in pyproject.toml\n- **PEP 660**: Editable installs\n- **pyproject.toml**: Single source of configuration\n\n### 3. Build Backends\n- **setuptools**: Traditional, widely used\n- **hatchling**: Modern, opinionated\n- **flit**: Lightweight, for pure Python\n- **poetry**: Dependency management + packaging\n\n### 4. Distribution\n- **PyPI**: Python Package Index (public)\n- **TestPyPI**: Testing before production\n- **Private repositories**: JFrog, AWS CodeArtifact, etc.\n\n## Quick Start\n\n### Minimal Package Structure\n\n```\nmy-package/\n├── pyproject.toml\n├── README.md\n├── LICENSE\n├── src/\n│   └── my_package/\n│       ├── __init__.py\n│       └── module.py\n└── tests/\n    └── test_module.py\n```\n\n### Minimal pyproject.toml\n\n```toml\n[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"my-package\"\nversion = \"0.1.0\"\ndescription = \"A short description\"\nauthors = [{name = \"Your Name\", email = \"you@example.com\"}]\nreadme = \"README.md\"\nrequires-python = \">=3.8\"\ndependencies = [\n    \"requests>=2.28.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=7.0\",\n    \"black>=22.0\",\n]\n```\n\n## Package Structure Patterns\n\n### Pattern 1: Source Layout (Recommended)\n\n```\nmy-package/\n├── pyproject.toml\n├── README.md\n├── LICENSE\n├── .gitignore\n├── src/\n│   └── my_package/\n│       ├── __init__.py\n│       ├── core.py\n│       ├── utils.py\n│       └── py.typed          # For type hints\n├── tests/\n│   ├── __init__.py\n│   ├── test_core.py\n│   └── test_utils.py\n└── docs/\n    └── index.md\n```\n\n**Advantages:**\n- Prevents accidentally importing from source\n- Cleaner test imports\n- Better isolation\n\n**pyproject.toml for source layout:**\n```toml\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n```\n\n### Pattern 2: Flat Layout\n\n```\nmy-package/\n├── pyproject.toml\n├── README.md\n├── my_package/\n│   ├── __init__.py\n│   └── module.py\n└── tests/\n    └── test_module.py\n```\n\n**Simpler but:**\n- Can import package without installing\n- Less professional for libraries\n\n### Pattern 3: Multi-Package Project\n\n```\nproject/\n├── pyproject.toml\n├── packages/\n│   ├── package-a/\n│   │   └── src/\n│   │       └── package_a/\n│   └── package-b/\n│       └── src/\n│           └── package_b/\n└── tests/\n```\n\n## Complete pyproject.toml Examples\n\n### Pattern 4: Full-Featured pyproject.toml\n\n```toml\n[build-system]\nrequires = [\"setuptools>=61.0\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"my-awesome-package\"\nversion = \"1.0.0\"\ndescription = \"An awesome Python package\"\nreadme = \"README.md\"\nrequires-python = \">=3.8\"\nlicense = {text = \"MIT\"}\nauthors = [\n    {name = \"Your Name\", email = \"you@example.com\"},\n]\nmaintainers = [\n    {name = \"Maintainer Name\", email = \"maintainer@example.com\"},\n]\nkeywords = [\"example\", \"package\", \"awesome\"]\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n]\n\ndependencies = [\n    \"requests>=2.28.0,<3.0.0\",\n    \"click>=8.0.0\",\n    \"pydantic>=2.0.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=7.0.0\",\n    \"pytest-cov>=4.0.0\",\n    \"black>=23.0.0\",\n    \"ruff>=0.1.0\",\n    \"mypy>=1.0.0\",\n]\ndocs = [\n    \"sphinx>=5.0.0\",\n    \"sphinx-rtd-theme>=1.0.0\",\n]\nall = [\n    \"my-awesome-package[dev,docs]\",\n]\n\n[project.urls]\nHomepage = \"https://github.com/username/my-awesome-package\"\nDocumentation = \"https://my-awesome-package.readthedocs.io\"\nRepository = \"https://github.com/username/my-awesome-package\"\n\"Bug Tracker\" = \"https://github.com/username/my-awesome-package/issues\"\nChangelog = \"https://github.com/username/my-awesome-package/blob/main/CHANGELOG.md\"\n\n[project.scripts]\nmy-cli = \"my_package.cli:main\"\nawesome-tool = \"my_package.tools:run\"\n\n[project.entry-points.\"my_package.plugins\"]\nplugin1 = \"my_package.plugins:plugin1\"\n\n[tool.setuptools]\npackage-dir = {\"\" = \"src\"}\nzip-safe = false\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\ninclude = [\"my_package*\"]\nexclude = [\"tests*\"]\n\n[tool.setuptools.package-data]\nmy_package = [\"py.typed\", \"*.pyi\", \"data/*.json\"]\n\n# Black configuration\n[tool.black]\nline-length = 100\ntarget-version = [\"py38\", \"py39\", \"py310\", \"py311\"]\ninclude = '\\.pyi?$'\n\n# Ruff configuration\n[tool.ruff]\nline-length = 100\ntarget-version = \"py38\"\n\n[tool.ruff.lint]\nselect = [\"E\", \"F\", \"I\", \"N\", \"W\", \"UP\"]\n\n# MyPy configuration\n[tool.mypy]\npython_version = \"3.8\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\n\n# Pytest configuration\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\naddopts = \"-v --cov=my_package --cov-report=term-missing\"\n\n# Coverage configuration\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"*/tests/*\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n]\n```\n\n### Pattern 5: Dynamic Versioning\n\n```toml\n[build-system]\nrequires = [\"setuptools>=61.0\", \"setuptools-scm>=8.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"my-package\"\ndynamic = [\"version\"]\ndescription = \"Package with dynamic version\"\n\n[tool.setuptools.dynamic]\nversion = {attr = \"my_package.__version__\"}\n\n# Or use setuptools-scm for git-based versioning\n[tool.setuptools_scm]\nwrite_to = \"src/my_package/_version.py\"\n```\n\n**In __init__.py:**\n```python\n# src/my_package/__init__.py\n__version__ = \"1.0.0\"\n\n# Or with setuptools-scm\nfrom importlib.metadata import version\n__version__ = version(\"my-package\")\n```\n\n## Command-Line Interface (CLI) Patterns\n\n### Pattern 6: CLI with Click\n\n```python\n# src/my_package/cli.py\nimport click\n\n@click.group()\n@click.version_option()\ndef cli():\n    \"\"\"My awesome CLI tool.\"\"\"\n    pass\n\n@cli.command()\n@click.argument(\"name\")\n@click.option(\"--greeting\", default=\"Hello\", help=\"Greeting to use\")\ndef greet(name: str, greeting: str):\n    \"\"\"Greet someone.\"\"\"\n    click.echo(f\"{greeting}, {name}!\")\n\n@cli.command()\n@click.option(\"--count\", default=1, help=\"Number of times to repeat\")\ndef repeat(count: int):\n    \"\"\"Repeat a message.\"\"\"\n    for i in range(count):\n        click.echo(f\"Message {i + 1}\")\n\ndef main():\n    \"\"\"Entry point for CLI.\"\"\"\n    cli()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n**Register in pyproject.toml:**\n```toml\n[project.scripts]\nmy-tool = \"my_package.cli:main\"\n```\n\n**Usage:**\n```bash\npip install -e .\nmy-tool greet World\nmy-tool greet Alice --greeting=\"Hi\"\nmy-tool repeat --count=3\n```\n\n### Pattern 7: CLI with argparse\n\n```python\n# src/my_package/cli.py\nimport argparse\nimport sys\n\ndef main():\n    \"\"\"Main CLI entry point.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"My awesome tool\",\n        prog=\"my-tool\"\n    )\n\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=\"%(prog)s 1.0.0\"\n    )\n\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Commands\")\n\n    # Add subcommand\n    process_parser = subparsers.add_parser(\"process\", help=\"Process data\")\n    process_parser.add_argument(\"input_file\", help=\"Input file path\")\n    process_parser.add_argument(\n        \"--output\", \"-o\",\n        default=\"output.txt\",\n        help=\"Output file path\"\n    )\n\n    args = parser.parse_args()\n\n    if args.command == \"process\":\n        process_data(args.input_file, args.output)\n    else:\n        parser.print_help()\n        sys.exit(1)\n\ndef process_data(input_file: str, output_file: str):\n    \"\"\"Process data from input to output.\"\"\"\n    print(f\"Processing {input_file} -> {output_file}\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Building and Publishing\n\n### Pattern 8: Build Package Locally\n\n```bash\n# Install build tools\npip install build twine\n\n# Build distribution\npython -m build\n\n# This creates:\n# dist/\n#   my-package-1.0.0.tar.gz (source distribution)\n#   my_package-1.0.0-py3-none-any.whl (wheel)\n\n# Check the distribution\ntwine check dist/*\n```\n\n### Pattern 9: Publishing to PyPI\n\n```bash\n# Install publishing tools\npip install twine\n\n# Test on TestPyPI first\ntwine upload --repository testpypi dist/*\n\n# Install from TestPyPI to test\npip install --index-url https://test.pypi.org/simple/ my-package\n\n# If all good, publish to PyPI\ntwine upload dist/*\n```\n\n**Using API tokens (recommended):**\n```bash\n# Create ~/.pypirc\n[distutils]\nindex-servers =\n    pypi\n    testpypi\n\n[pypi]\nusername = __token__\npassword = pypi-...your-token...\n\n[testpypi]\nusername = __token__\npassword = pypi-...your-test-token...\n```\n\n### Pattern 10: Automated Publishing with GitHub Actions\n\n```yaml\n# .github/workflows/publish.yml\nname: Publish to PyPI\n\non:\n  release:\n    types: [created]\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.11\"\n\n      - name: Install dependencies\n        run: |\n          pip install build twine\n\n      - name: Build package\n        run: python -m build\n\n      - name: Check package\n        run: twine check dist/*\n\n      - name: Publish to PyPI\n        env:\n          TWINE_USERNAME: __token__\n          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}\n        run: twine upload dist/*\n```\n\n## Advanced Patterns\n\n### Pattern 11: Including Data Files\n\n```toml\n[tool.setuptools.package-data]\nmy_package = [\n    \"data/*.json\",\n    \"templates/*.html\",\n    \"static/css/*.css\",\n    \"py.typed\",\n]\n```\n\n**Accessing data files:**\n```python\n# src/my_package/loader.py\nfrom importlib.resources import files\nimport json\n\ndef load_config():\n    \"\"\"Load configuration from package data.\"\"\"\n    config_file = files(\"my_package\").joinpath(\"data/config.json\")\n    with config_file.open() as f:\n        return json.load(f)\n\n# Python 3.9+\nfrom importlib.resources import files\n\ndata = files(\"my_package\").joinpath(\"data/file.txt\").read_text()\n```\n\n### Pattern 12: Namespace Packages\n\n**For large projects split across multiple repositories:**\n\n```\n# Package 1: company-core\ncompany/\n└── core/\n    ├── __init__.py\n    └── models.py\n\n# Package 2: company-api\ncompany/\n└── api/\n    ├── __init__.py\n    └── routes.py\n```\n\n**Do NOT include __init__.py in the namespace directory (company/):**\n\n```toml\n# company-core/pyproject.toml\n[project]\nname = \"company-core\"\n\n[tool.setuptools.packages.find]\nwhere = [\".\"]\ninclude = [\"company.core*\"]\n\n# company-api/pyproject.toml\n[project]\nname = \"company-api\"\n\n[tool.setuptools.packages.find]\nwhere = [\".\"]\ninclude = [\"company.api*\"]\n```\n\n**Usage:**\n```python\n# Both packages can be imported under same namespace\nfrom company.core import models\nfrom company.api import routes\n```\n\n### Pattern 13: C Extensions\n\n```toml\n[build-system]\nrequires = [\"setuptools>=61.0\", \"wheel\", \"Cython>=0.29\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.setuptools]\next-modules = [\n    {name = \"my_package.fast_module\", sources = [\"src/fast_module.c\"]},\n]\n```\n\n**Or with setup.py:**\n```python\n# setup.py\nfrom setuptools import setup, Extension\n\nsetup(\n    ext_modules=[\n        Extension(\n            \"my_package.fast_module\",\n            sources=[\"src/fast_module.c\"],\n            include_dirs=[\"src/include\"],\n        )\n    ]\n)\n```\n\n## Version Management\n\n### Pattern 14: Semantic Versioning\n\n```python\n# src/my_package/__init__.py\n__version__ = \"1.2.3\"\n\n# Semantic versioning: MAJOR.MINOR.PATCH\n# MAJOR: Breaking changes\n# MINOR: New features (backward compatible)\n# PATCH: Bug fixes\n```\n\n**Version constraints in dependencies:**\n```toml\ndependencies = [\n    \"requests>=2.28.0,<3.0.0\",  # Compatible range\n    \"click~=8.1.0\",              # Compatible release (~= 8.1.0 means >=8.1.0,<8.2.0)\n    \"pydantic>=2.0\",             # Minimum version\n    \"numpy==1.24.3\",             # Exact version (avoid if possible)\n]\n```\n\n### Pattern 15: Git-Based Versioning\n\n```toml\n[build-system]\nrequires = [\"setuptools>=61.0\", \"setuptools-scm>=8.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"my-package\"\ndynamic = [\"version\"]\n\n[tool.setuptools_scm]\nwrite_to = \"src/my_package/_version.py\"\nversion_scheme = \"post-release\"\nlocal_scheme = \"dirty-tag\"\n```\n\n**Creates versions like:**\n- `1.0.0` (from git tag)\n- `1.0.1.dev3+g1234567` (3 commits after tag)\n\n## Testing Installation\n\n### Pattern 16: Editable Install\n\n```bash\n# Install in development mode\npip install -e .\n\n# With optional dependencies\npip install -e \".[dev]\"\npip install -e \".[dev,docs]\"\n\n# Now changes to source code are immediately reflected\n```\n\n### Pattern 17: Testing in Isolated Environment\n\n```bash\n# Create virtual environment\npython -m venv test-env\nsource test-env/bin/activate  # Linux/Mac\n# test-env\\Scripts\\activate  # Windows\n\n# Install package\npip install dist/my_package-1.0.0-py3-none-any.whl\n\n# Test it works\npython -c \"import my_package; print(my_package.__version__)\"\n\n# Test CLI\nmy-tool --help\n\n# Cleanup\ndeactivate\nrm -rf test-env\n```\n\n## Documentation\n\n### Pattern 18: README.md Template\n\n```markdown\n# My Package\n\n[![PyPI version](https://badge.fury.io/py/my-package.svg)](https://pypi.org/project/my-package/)\n[![Python versions](https://img.shields.io/pypi/pyversions/my-package.svg)](https://pypi.org/project/my-package/)\n[![Tests](https://github.com/username/my-package/workflows/Tests/badge.svg)](https://github.com/username/my-package/actions)\n\nBrief description of your package.\n\n## Installation\n\n```bash\npip install my-package\n```\n\n## Quick Start\n\n```python\nfrom my_package import something\n\nresult = something.do_stuff()\n```\n\n## Features\n\n- Feature 1\n- Feature 2\n- Feature 3\n\n## Documentation\n\nFull documentation: https://my-package.readthedocs.io\n\n## Development\n\n```bash\ngit clone https://github.com/username/my-package.git\ncd my-package\npip install -e \".[dev]\"\npytest\n```\n\n## License\n\nMIT\n```\n\n## Common Patterns\n\n### Pattern 19: Multi-Architecture Wheels\n\n```yaml\n# .github/workflows/wheels.yml\nname: Build wheels\n\non: [push, pull_request]\n\njobs:\n  build_wheels:\n    name: Build wheels on ${{ matrix.os }}\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build wheels\n        uses: pypa/cibuildwheel@v2.16.2\n\n      - uses: actions/upload-artifact@v3\n        with:\n          path: ./wheelhouse/*.whl\n```\n\n### Pattern 20: Private Package Index\n\n```bash\n# Install from private index\npip install my-package --index-url https://private.pypi.org/simple/\n\n# Or add to pip.conf\n[global]\nindex-url = https://private.pypi.org/simple/\nextra-index-url = https://pypi.org/simple/\n\n# Upload to private index\ntwine upload --repository-url https://private.pypi.org/ dist/*\n```\n\n## File Templates\n\n### .gitignore for Python Packages\n\n```gitignore\n# Build artifacts\nbuild/\ndist/\n*.egg-info/\n*.egg\n.eggs/\n\n# Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n\n# Virtual environments\nvenv/\nenv/\nENV/\n\n# IDE\n.vscode/\n.idea/\n*.swp\n\n# Testing\n.pytest_cache/\n.coverage\nhtmlcov/\n\n# Distribution\n*.whl\n*.tar.gz\n```\n\n### MANIFEST.in\n\n```\n# MANIFEST.in\ninclude README.md\ninclude LICENSE\ninclude pyproject.toml\n\nrecursive-include src/my_package/data *.json\nrecursive-include src/my_package/templates *.html\nrecursive-exclude * __pycache__\nrecursive-exclude * *.py[co]\n```\n\n## Checklist for Publishing\n\n- [ ] Code is tested (pytest passing)\n- [ ] Documentation is complete (README, docstrings)\n- [ ] Version number updated\n- [ ] CHANGELOG.md updated\n- [ ] License file included\n- [ ] pyproject.toml is complete\n- [ ] Package builds without errors\n- [ ] Installation tested in clean environment\n- [ ] CLI tools work (if applicable)\n- [ ] PyPI metadata is correct (classifiers, keywords)\n- [ ] GitHub repository linked\n- [ ] Tested on TestPyPI first\n- [ ] Git tag created for release\n\n## Resources\n\n- **Python Packaging Guide**: https://packaging.python.org/\n- **PyPI**: https://pypi.org/\n- **TestPyPI**: https://test.pypi.org/\n- **setuptools documentation**: https://setuptools.pypa.io/\n- **build**: https://pypa-build.readthedocs.io/\n- **twine**: https://twine.readthedocs.io/\n\n## Best Practices Summary\n\n1. **Use src/ layout** for cleaner package structure\n2. **Use pyproject.toml** for modern packaging\n3. **Pin build dependencies** in build-system.requires\n4. **Version appropriately** with semantic versioning\n5. **Include all metadata** (classifiers, URLs, etc.)\n6. **Test installation** in clean environments\n7. **Use TestPyPI** before publishing to PyPI\n8. **Document thoroughly** with README and docstrings\n9. **Include LICENSE** file\n10. **Automate publishing** with CI/CD"
              },
              {
                "name": "python-performance-optimization",
                "description": "Profile and optimize Python code using cProfile, memory profilers, and performance best practices. Use when debugging slow Python code, optimizing bottlenecks, or improving application performance.",
                "path": "plugins/python-development/skills/python-performance-optimization/SKILL.md",
                "frontmatter": {
                  "name": "python-performance-optimization",
                  "description": "Profile and optimize Python code using cProfile, memory profilers, and performance best practices. Use when debugging slow Python code, optimizing bottlenecks, or improving application performance."
                },
                "content": "# Python Performance Optimization\n\nComprehensive guide to profiling, analyzing, and optimizing Python code for better performance, including CPU profiling, memory optimization, and implementation best practices.\n\n## When to Use This Skill\n\n- Identifying performance bottlenecks in Python applications\n- Reducing application latency and response times\n- Optimizing CPU-intensive operations\n- Reducing memory consumption and memory leaks\n- Improving database query performance\n- Optimizing I/O operations\n- Speeding up data processing pipelines\n- Implementing high-performance algorithms\n- Profiling production applications\n\n## Core Concepts\n\n### 1. Profiling Types\n- **CPU Profiling**: Identify time-consuming functions\n- **Memory Profiling**: Track memory allocation and leaks\n- **Line Profiling**: Profile at line-by-line granularity\n- **Call Graph**: Visualize function call relationships\n\n### 2. Performance Metrics\n- **Execution Time**: How long operations take\n- **Memory Usage**: Peak and average memory consumption\n- **CPU Utilization**: Processor usage patterns\n- **I/O Wait**: Time spent on I/O operations\n\n### 3. Optimization Strategies\n- **Algorithmic**: Better algorithms and data structures\n- **Implementation**: More efficient code patterns\n- **Parallelization**: Multi-threading/processing\n- **Caching**: Avoid redundant computation\n- **Native Extensions**: C/Rust for critical paths\n\n## Quick Start\n\n### Basic Timing\n\n```python\nimport time\n\ndef measure_time():\n    \"\"\"Simple timing measurement.\"\"\"\n    start = time.time()\n\n    # Your code here\n    result = sum(range(1000000))\n\n    elapsed = time.time() - start\n    print(f\"Execution time: {elapsed:.4f} seconds\")\n    return result\n\n# Better: use timeit for accurate measurements\nimport timeit\n\nexecution_time = timeit.timeit(\n    \"sum(range(1000000))\",\n    number=100\n)\nprint(f\"Average time: {execution_time/100:.6f} seconds\")\n```\n\n## Profiling Tools\n\n### Pattern 1: cProfile - CPU Profiling\n\n```python\nimport cProfile\nimport pstats\nfrom pstats import SortKey\n\ndef slow_function():\n    \"\"\"Function to profile.\"\"\"\n    total = 0\n    for i in range(1000000):\n        total += i\n    return total\n\ndef another_function():\n    \"\"\"Another function.\"\"\"\n    return [i**2 for i in range(100000)]\n\ndef main():\n    \"\"\"Main function to profile.\"\"\"\n    result1 = slow_function()\n    result2 = another_function()\n    return result1, result2\n\n# Profile the code\nif __name__ == \"__main__\":\n    profiler = cProfile.Profile()\n    profiler.enable()\n\n    main()\n\n    profiler.disable()\n\n    # Print stats\n    stats = pstats.Stats(profiler)\n    stats.sort_stats(SortKey.CUMULATIVE)\n    stats.print_stats(10)  # Top 10 functions\n\n    # Save to file for later analysis\n    stats.dump_stats(\"profile_output.prof\")\n```\n\n**Command-line profiling:**\n```bash\n# Profile a script\npython -m cProfile -o output.prof script.py\n\n# View results\npython -m pstats output.prof\n# In pstats:\n# sort cumtime\n# stats 10\n```\n\n### Pattern 2: line_profiler - Line-by-Line Profiling\n\n```python\n# Install: pip install line-profiler\n\n# Add @profile decorator (line_profiler provides this)\n@profile\ndef process_data(data):\n    \"\"\"Process data with line profiling.\"\"\"\n    result = []\n    for item in data:\n        processed = item * 2\n        result.append(processed)\n    return result\n\n# Run with:\n# kernprof -l -v script.py\n```\n\n**Manual line profiling:**\n```python\nfrom line_profiler import LineProfiler\n\ndef process_data(data):\n    \"\"\"Function to profile.\"\"\"\n    result = []\n    for item in data:\n        processed = item * 2\n        result.append(processed)\n    return result\n\nif __name__ == \"__main__\":\n    lp = LineProfiler()\n    lp.add_function(process_data)\n\n    data = list(range(100000))\n\n    lp_wrapper = lp(process_data)\n    lp_wrapper(data)\n\n    lp.print_stats()\n```\n\n### Pattern 3: memory_profiler - Memory Usage\n\n```python\n# Install: pip install memory-profiler\n\nfrom memory_profiler import profile\n\n@profile\ndef memory_intensive():\n    \"\"\"Function that uses lots of memory.\"\"\"\n    # Create large list\n    big_list = [i for i in range(1000000)]\n\n    # Create large dict\n    big_dict = {i: i**2 for i in range(100000)}\n\n    # Process data\n    result = sum(big_list)\n\n    return result\n\nif __name__ == \"__main__\":\n    memory_intensive()\n\n# Run with:\n# python -m memory_profiler script.py\n```\n\n### Pattern 4: py-spy - Production Profiling\n\n```bash\n# Install: pip install py-spy\n\n# Profile a running Python process\npy-spy top --pid 12345\n\n# Generate flamegraph\npy-spy record -o profile.svg --pid 12345\n\n# Profile a script\npy-spy record -o profile.svg -- python script.py\n\n# Dump current call stack\npy-spy dump --pid 12345\n```\n\n## Optimization Patterns\n\n### Pattern 5: List Comprehensions vs Loops\n\n```python\nimport timeit\n\n# Slow: Traditional loop\ndef slow_squares(n):\n    \"\"\"Create list of squares using loop.\"\"\"\n    result = []\n    for i in range(n):\n        result.append(i**2)\n    return result\n\n# Fast: List comprehension\ndef fast_squares(n):\n    \"\"\"Create list of squares using comprehension.\"\"\"\n    return [i**2 for i in range(n)]\n\n# Benchmark\nn = 100000\n\nslow_time = timeit.timeit(lambda: slow_squares(n), number=100)\nfast_time = timeit.timeit(lambda: fast_squares(n), number=100)\n\nprint(f\"Loop: {slow_time:.4f}s\")\nprint(f\"Comprehension: {fast_time:.4f}s\")\nprint(f\"Speedup: {slow_time/fast_time:.2f}x\")\n\n# Even faster for simple operations: map\ndef faster_squares(n):\n    \"\"\"Use map for even better performance.\"\"\"\n    return list(map(lambda x: x**2, range(n)))\n```\n\n### Pattern 6: Generator Expressions for Memory\n\n```python\nimport sys\n\ndef list_approach():\n    \"\"\"Memory-intensive list.\"\"\"\n    data = [i**2 for i in range(1000000)]\n    return sum(data)\n\ndef generator_approach():\n    \"\"\"Memory-efficient generator.\"\"\"\n    data = (i**2 for i in range(1000000))\n    return sum(data)\n\n# Memory comparison\nlist_data = [i for i in range(1000000)]\ngen_data = (i for i in range(1000000))\n\nprint(f\"List size: {sys.getsizeof(list_data)} bytes\")\nprint(f\"Generator size: {sys.getsizeof(gen_data)} bytes\")\n\n# Generators use constant memory regardless of size\n```\n\n### Pattern 7: String Concatenation\n\n```python\nimport timeit\n\ndef slow_concat(items):\n    \"\"\"Slow string concatenation.\"\"\"\n    result = \"\"\n    for item in items:\n        result += str(item)\n    return result\n\ndef fast_concat(items):\n    \"\"\"Fast string concatenation with join.\"\"\"\n    return \"\".join(str(item) for item in items)\n\ndef faster_concat(items):\n    \"\"\"Even faster with list.\"\"\"\n    parts = [str(item) for item in items]\n    return \"\".join(parts)\n\nitems = list(range(10000))\n\n# Benchmark\nslow = timeit.timeit(lambda: slow_concat(items), number=100)\nfast = timeit.timeit(lambda: fast_concat(items), number=100)\nfaster = timeit.timeit(lambda: faster_concat(items), number=100)\n\nprint(f\"Concatenation (+): {slow:.4f}s\")\nprint(f\"Join (generator): {fast:.4f}s\")\nprint(f\"Join (list): {faster:.4f}s\")\n```\n\n### Pattern 8: Dictionary Lookups vs List Searches\n\n```python\nimport timeit\n\n# Create test data\nsize = 10000\nitems = list(range(size))\nlookup_dict = {i: i for i in range(size)}\n\ndef list_search(items, target):\n    \"\"\"O(n) search in list.\"\"\"\n    return target in items\n\ndef dict_search(lookup_dict, target):\n    \"\"\"O(1) search in dict.\"\"\"\n    return target in lookup_dict\n\ntarget = size - 1  # Worst case for list\n\n# Benchmark\nlist_time = timeit.timeit(\n    lambda: list_search(items, target),\n    number=1000\n)\ndict_time = timeit.timeit(\n    lambda: dict_search(lookup_dict, target),\n    number=1000\n)\n\nprint(f\"List search: {list_time:.6f}s\")\nprint(f\"Dict search: {dict_time:.6f}s\")\nprint(f\"Speedup: {list_time/dict_time:.0f}x\")\n```\n\n### Pattern 9: Local Variable Access\n\n```python\nimport timeit\n\n# Global variable (slow)\nGLOBAL_VALUE = 100\n\ndef use_global():\n    \"\"\"Access global variable.\"\"\"\n    total = 0\n    for i in range(10000):\n        total += GLOBAL_VALUE\n    return total\n\ndef use_local():\n    \"\"\"Use local variable.\"\"\"\n    local_value = 100\n    total = 0\n    for i in range(10000):\n        total += local_value\n    return total\n\n# Local is faster\nglobal_time = timeit.timeit(use_global, number=1000)\nlocal_time = timeit.timeit(use_local, number=1000)\n\nprint(f\"Global access: {global_time:.4f}s\")\nprint(f\"Local access: {local_time:.4f}s\")\nprint(f\"Speedup: {global_time/local_time:.2f}x\")\n```\n\n### Pattern 10: Function Call Overhead\n\n```python\nimport timeit\n\ndef calculate_inline():\n    \"\"\"Inline calculation.\"\"\"\n    total = 0\n    for i in range(10000):\n        total += i * 2 + 1\n    return total\n\ndef helper_function(x):\n    \"\"\"Helper function.\"\"\"\n    return x * 2 + 1\n\ndef calculate_with_function():\n    \"\"\"Calculation with function calls.\"\"\"\n    total = 0\n    for i in range(10000):\n        total += helper_function(i)\n    return total\n\n# Inline is faster due to no call overhead\ninline_time = timeit.timeit(calculate_inline, number=1000)\nfunction_time = timeit.timeit(calculate_with_function, number=1000)\n\nprint(f\"Inline: {inline_time:.4f}s\")\nprint(f\"Function calls: {function_time:.4f}s\")\n```\n\n## Advanced Optimization\n\n### Pattern 11: NumPy for Numerical Operations\n\n```python\nimport timeit\nimport numpy as np\n\ndef python_sum(n):\n    \"\"\"Sum using pure Python.\"\"\"\n    return sum(range(n))\n\ndef numpy_sum(n):\n    \"\"\"Sum using NumPy.\"\"\"\n    return np.arange(n).sum()\n\nn = 1000000\n\npython_time = timeit.timeit(lambda: python_sum(n), number=100)\nnumpy_time = timeit.timeit(lambda: numpy_sum(n), number=100)\n\nprint(f\"Python: {python_time:.4f}s\")\nprint(f\"NumPy: {numpy_time:.4f}s\")\nprint(f\"Speedup: {python_time/numpy_time:.2f}x\")\n\n# Vectorized operations\ndef python_multiply():\n    \"\"\"Element-wise multiplication in Python.\"\"\"\n    a = list(range(100000))\n    b = list(range(100000))\n    return [x * y for x, y in zip(a, b)]\n\ndef numpy_multiply():\n    \"\"\"Vectorized multiplication in NumPy.\"\"\"\n    a = np.arange(100000)\n    b = np.arange(100000)\n    return a * b\n\npy_time = timeit.timeit(python_multiply, number=100)\nnp_time = timeit.timeit(numpy_multiply, number=100)\n\nprint(f\"\\nPython multiply: {py_time:.4f}s\")\nprint(f\"NumPy multiply: {np_time:.4f}s\")\nprint(f\"Speedup: {py_time/np_time:.2f}x\")\n```\n\n### Pattern 12: Caching with functools.lru_cache\n\n```python\nfrom functools import lru_cache\nimport timeit\n\ndef fibonacci_slow(n):\n    \"\"\"Recursive fibonacci without caching.\"\"\"\n    if n < 2:\n        return n\n    return fibonacci_slow(n-1) + fibonacci_slow(n-2)\n\n@lru_cache(maxsize=None)\ndef fibonacci_fast(n):\n    \"\"\"Recursive fibonacci with caching.\"\"\"\n    if n < 2:\n        return n\n    return fibonacci_fast(n-1) + fibonacci_fast(n-2)\n\n# Massive speedup for recursive algorithms\nn = 30\n\nslow_time = timeit.timeit(lambda: fibonacci_slow(n), number=1)\nfast_time = timeit.timeit(lambda: fibonacci_fast(n), number=1000)\n\nprint(f\"Without cache (1 run): {slow_time:.4f}s\")\nprint(f\"With cache (1000 runs): {fast_time:.4f}s\")\n\n# Cache info\nprint(f\"Cache info: {fibonacci_fast.cache_info()}\")\n```\n\n### Pattern 13: Using __slots__ for Memory\n\n```python\nimport sys\n\nclass RegularClass:\n    \"\"\"Regular class with __dict__.\"\"\"\n    def __init__(self, x, y, z):\n        self.x = x\n        self.y = y\n        self.z = z\n\nclass SlottedClass:\n    \"\"\"Class with __slots__ for memory efficiency.\"\"\"\n    __slots__ = ['x', 'y', 'z']\n\n    def __init__(self, x, y, z):\n        self.x = x\n        self.y = y\n        self.z = z\n\n# Memory comparison\nregular = RegularClass(1, 2, 3)\nslotted = SlottedClass(1, 2, 3)\n\nprint(f\"Regular class size: {sys.getsizeof(regular)} bytes\")\nprint(f\"Slotted class size: {sys.getsizeof(slotted)} bytes\")\n\n# Significant savings with many instances\nregular_objects = [RegularClass(i, i+1, i+2) for i in range(10000)]\nslotted_objects = [SlottedClass(i, i+1, i+2) for i in range(10000)]\n\nprint(f\"\\nMemory for 10000 regular objects: ~{sys.getsizeof(regular) * 10000} bytes\")\nprint(f\"Memory for 10000 slotted objects: ~{sys.getsizeof(slotted) * 10000} bytes\")\n```\n\n### Pattern 14: Multiprocessing for CPU-Bound Tasks\n\n```python\nimport multiprocessing as mp\nimport time\n\ndef cpu_intensive_task(n):\n    \"\"\"CPU-intensive calculation.\"\"\"\n    return sum(i**2 for i in range(n))\n\ndef sequential_processing():\n    \"\"\"Process tasks sequentially.\"\"\"\n    start = time.time()\n    results = [cpu_intensive_task(1000000) for _ in range(4)]\n    elapsed = time.time() - start\n    return elapsed, results\n\ndef parallel_processing():\n    \"\"\"Process tasks in parallel.\"\"\"\n    start = time.time()\n    with mp.Pool(processes=4) as pool:\n        results = pool.map(cpu_intensive_task, [1000000] * 4)\n    elapsed = time.time() - start\n    return elapsed, results\n\nif __name__ == \"__main__\":\n    seq_time, seq_results = sequential_processing()\n    par_time, par_results = parallel_processing()\n\n    print(f\"Sequential: {seq_time:.2f}s\")\n    print(f\"Parallel: {par_time:.2f}s\")\n    print(f\"Speedup: {seq_time/par_time:.2f}x\")\n```\n\n### Pattern 15: Async I/O for I/O-Bound Tasks\n\n```python\nimport asyncio\nimport aiohttp\nimport time\nimport requests\n\nurls = [\n    \"https://httpbin.org/delay/1\",\n    \"https://httpbin.org/delay/1\",\n    \"https://httpbin.org/delay/1\",\n    \"https://httpbin.org/delay/1\",\n]\n\ndef synchronous_requests():\n    \"\"\"Synchronous HTTP requests.\"\"\"\n    start = time.time()\n    results = []\n    for url in urls:\n        response = requests.get(url)\n        results.append(response.status_code)\n    elapsed = time.time() - start\n    return elapsed, results\n\nasync def async_fetch(session, url):\n    \"\"\"Async HTTP request.\"\"\"\n    async with session.get(url) as response:\n        return response.status\n\nasync def asynchronous_requests():\n    \"\"\"Asynchronous HTTP requests.\"\"\"\n    start = time.time()\n    async with aiohttp.ClientSession() as session:\n        tasks = [async_fetch(session, url) for url in urls]\n        results = await asyncio.gather(*tasks)\n    elapsed = time.time() - start\n    return elapsed, results\n\n# Async is much faster for I/O-bound work\nsync_time, sync_results = synchronous_requests()\nasync_time, async_results = asyncio.run(asynchronous_requests())\n\nprint(f\"Synchronous: {sync_time:.2f}s\")\nprint(f\"Asynchronous: {async_time:.2f}s\")\nprint(f\"Speedup: {sync_time/async_time:.2f}x\")\n```\n\n## Database Optimization\n\n### Pattern 16: Batch Database Operations\n\n```python\nimport sqlite3\nimport time\n\ndef create_db():\n    \"\"\"Create test database.\"\"\"\n    conn = sqlite3.connect(\":memory:\")\n    conn.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT)\")\n    return conn\n\ndef slow_inserts(conn, count):\n    \"\"\"Insert records one at a time.\"\"\"\n    start = time.time()\n    cursor = conn.cursor()\n    for i in range(count):\n        cursor.execute(\"INSERT INTO users (name) VALUES (?)\", (f\"User {i}\",))\n        conn.commit()  # Commit each insert\n    elapsed = time.time() - start\n    return elapsed\n\ndef fast_inserts(conn, count):\n    \"\"\"Batch insert with single commit.\"\"\"\n    start = time.time()\n    cursor = conn.cursor()\n    data = [(f\"User {i}\",) for i in range(count)]\n    cursor.executemany(\"INSERT INTO users (name) VALUES (?)\", data)\n    conn.commit()  # Single commit\n    elapsed = time.time() - start\n    return elapsed\n\n# Benchmark\nconn1 = create_db()\nslow_time = slow_inserts(conn1, 1000)\n\nconn2 = create_db()\nfast_time = fast_inserts(conn2, 1000)\n\nprint(f\"Individual inserts: {slow_time:.4f}s\")\nprint(f\"Batch insert: {fast_time:.4f}s\")\nprint(f\"Speedup: {slow_time/fast_time:.2f}x\")\n```\n\n### Pattern 17: Query Optimization\n\n```python\n# Use indexes for frequently queried columns\n\"\"\"\n-- Slow: No index\nSELECT * FROM users WHERE email = 'user@example.com';\n\n-- Fast: With index\nCREATE INDEX idx_users_email ON users(email);\nSELECT * FROM users WHERE email = 'user@example.com';\n\"\"\"\n\n# Use query planning\nimport sqlite3\n\nconn = sqlite3.connect(\"example.db\")\ncursor = conn.cursor()\n\n# Analyze query performance\ncursor.execute(\"EXPLAIN QUERY PLAN SELECT * FROM users WHERE email = ?\", (\"test@example.com\",))\nprint(cursor.fetchall())\n\n# Use SELECT only needed columns\n# Slow: SELECT *\n# Fast: SELECT id, name\n```\n\n## Memory Optimization\n\n### Pattern 18: Detecting Memory Leaks\n\n```python\nimport tracemalloc\nimport gc\n\ndef memory_leak_example():\n    \"\"\"Example that leaks memory.\"\"\"\n    leaked_objects = []\n\n    for i in range(100000):\n        # Objects added but never removed\n        leaked_objects.append([i] * 100)\n\n    # In real code, this would be an unintended reference\n\ndef track_memory_usage():\n    \"\"\"Track memory allocations.\"\"\"\n    tracemalloc.start()\n\n    # Take snapshot before\n    snapshot1 = tracemalloc.take_snapshot()\n\n    # Run code\n    memory_leak_example()\n\n    # Take snapshot after\n    snapshot2 = tracemalloc.take_snapshot()\n\n    # Compare\n    top_stats = snapshot2.compare_to(snapshot1, 'lineno')\n\n    print(\"Top 10 memory allocations:\")\n    for stat in top_stats[:10]:\n        print(stat)\n\n    tracemalloc.stop()\n\n# Monitor memory\ntrack_memory_usage()\n\n# Force garbage collection\ngc.collect()\n```\n\n### Pattern 19: Iterators vs Lists\n\n```python\nimport sys\n\ndef process_file_list(filename):\n    \"\"\"Load entire file into memory.\"\"\"\n    with open(filename) as f:\n        lines = f.readlines()  # Loads all lines\n        return sum(1 for line in lines if line.strip())\n\ndef process_file_iterator(filename):\n    \"\"\"Process file line by line.\"\"\"\n    with open(filename) as f:\n        return sum(1 for line in f if line.strip())\n\n# Iterator uses constant memory\n# List loads entire file into memory\n```\n\n### Pattern 20: Weakref for Caches\n\n```python\nimport weakref\n\nclass CachedResource:\n    \"\"\"Resource that can be garbage collected.\"\"\"\n    def __init__(self, data):\n        self.data = data\n\n# Regular cache prevents garbage collection\nregular_cache = {}\n\ndef get_resource_regular(key):\n    \"\"\"Get resource from regular cache.\"\"\"\n    if key not in regular_cache:\n        regular_cache[key] = CachedResource(f\"Data for {key}\")\n    return regular_cache[key]\n\n# Weak reference cache allows garbage collection\nweak_cache = weakref.WeakValueDictionary()\n\ndef get_resource_weak(key):\n    \"\"\"Get resource from weak cache.\"\"\"\n    resource = weak_cache.get(key)\n    if resource is None:\n        resource = CachedResource(f\"Data for {key}\")\n        weak_cache[key] = resource\n    return resource\n\n# When no strong references exist, objects can be GC'd\n```\n\n## Benchmarking Tools\n\n### Custom Benchmark Decorator\n\n```python\nimport time\nfrom functools import wraps\n\ndef benchmark(func):\n    \"\"\"Decorator to benchmark function execution.\"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start = time.perf_counter()\n        result = func(*args, **kwargs)\n        elapsed = time.perf_counter() - start\n        print(f\"{func.__name__} took {elapsed:.6f} seconds\")\n        return result\n    return wrapper\n\n@benchmark\ndef slow_function():\n    \"\"\"Function to benchmark.\"\"\"\n    time.sleep(0.5)\n    return sum(range(1000000))\n\nresult = slow_function()\n```\n\n### Performance Testing with pytest-benchmark\n\n```python\n# Install: pip install pytest-benchmark\n\ndef test_list_comprehension(benchmark):\n    \"\"\"Benchmark list comprehension.\"\"\"\n    result = benchmark(lambda: [i**2 for i in range(10000)])\n    assert len(result) == 10000\n\ndef test_map_function(benchmark):\n    \"\"\"Benchmark map function.\"\"\"\n    result = benchmark(lambda: list(map(lambda x: x**2, range(10000))))\n    assert len(result) == 10000\n\n# Run with: pytest test_performance.py --benchmark-compare\n```\n\n## Best Practices\n\n1. **Profile before optimizing** - Measure to find real bottlenecks\n2. **Focus on hot paths** - Optimize code that runs most frequently\n3. **Use appropriate data structures** - Dict for lookups, set for membership\n4. **Avoid premature optimization** - Clarity first, then optimize\n5. **Use built-in functions** - They're implemented in C\n6. **Cache expensive computations** - Use lru_cache\n7. **Batch I/O operations** - Reduce system calls\n8. **Use generators** for large datasets\n9. **Consider NumPy** for numerical operations\n10. **Profile production code** - Use py-spy for live systems\n\n## Common Pitfalls\n\n- Optimizing without profiling\n- Using global variables unnecessarily\n- Not using appropriate data structures\n- Creating unnecessary copies of data\n- Not using connection pooling for databases\n- Ignoring algorithmic complexity\n- Over-optimizing rare code paths\n- Not considering memory usage\n\n## Resources\n\n- **cProfile**: Built-in CPU profiler\n- **memory_profiler**: Memory usage profiling\n- **line_profiler**: Line-by-line profiling\n- **py-spy**: Sampling profiler for production\n- **NumPy**: High-performance numerical computing\n- **Cython**: Compile Python to C\n- **PyPy**: Alternative Python interpreter with JIT\n\n## Performance Checklist\n\n- [ ] Profiled code to identify bottlenecks\n- [ ] Used appropriate data structures\n- [ ] Implemented caching where beneficial\n- [ ] Optimized database queries\n- [ ] Used generators for large datasets\n- [ ] Considered multiprocessing for CPU-bound tasks\n- [ ] Used async I/O for I/O-bound tasks\n- [ ] Minimized function call overhead in hot loops\n- [ ] Checked for memory leaks\n- [ ] Benchmarked before and after optimization"
              },
              {
                "name": "python-testing-patterns",
                "description": "Implement comprehensive testing strategies with pytest, fixtures, mocking, and test-driven development. Use when writing Python tests, setting up test suites, or implementing testing best practices.",
                "path": "plugins/python-development/skills/python-testing-patterns/SKILL.md",
                "frontmatter": {
                  "name": "python-testing-patterns",
                  "description": "Implement comprehensive testing strategies with pytest, fixtures, mocking, and test-driven development. Use when writing Python tests, setting up test suites, or implementing testing best practices."
                },
                "content": "# Python Testing Patterns\n\nComprehensive guide to implementing robust testing strategies in Python using pytest, fixtures, mocking, parameterization, and test-driven development practices.\n\n## When to Use This Skill\n\n- Writing unit tests for Python code\n- Setting up test suites and test infrastructure\n- Implementing test-driven development (TDD)\n- Creating integration tests for APIs and services\n- Mocking external dependencies and services\n- Testing async code and concurrent operations\n- Setting up continuous testing in CI/CD\n- Implementing property-based testing\n- Testing database operations\n- Debugging failing tests\n\n## Core Concepts\n\n### 1. Test Types\n- **Unit Tests**: Test individual functions/classes in isolation\n- **Integration Tests**: Test interaction between components\n- **Functional Tests**: Test complete features end-to-end\n- **Performance Tests**: Measure speed and resource usage\n\n### 2. Test Structure (AAA Pattern)\n- **Arrange**: Set up test data and preconditions\n- **Act**: Execute the code under test\n- **Assert**: Verify the results\n\n### 3. Test Coverage\n- Measure what code is exercised by tests\n- Identify untested code paths\n- Aim for meaningful coverage, not just high percentages\n\n### 4. Test Isolation\n- Tests should be independent\n- No shared state between tests\n- Each test should clean up after itself\n\n## Quick Start\n\n```python\n# test_example.py\ndef add(a, b):\n    return a + b\n\ndef test_add():\n    \"\"\"Basic test example.\"\"\"\n    result = add(2, 3)\n    assert result == 5\n\ndef test_add_negative():\n    \"\"\"Test with negative numbers.\"\"\"\n    assert add(-1, 1) == 0\n\n# Run with: pytest test_example.py\n```\n\n## Fundamental Patterns\n\n### Pattern 1: Basic pytest Tests\n\n```python\n# test_calculator.py\nimport pytest\n\nclass Calculator:\n    \"\"\"Simple calculator for testing.\"\"\"\n\n    def add(self, a: float, b: float) -> float:\n        return a + b\n\n    def subtract(self, a: float, b: float) -> float:\n        return a - b\n\n    def multiply(self, a: float, b: float) -> float:\n        return a * b\n\n    def divide(self, a: float, b: float) -> float:\n        if b == 0:\n            raise ValueError(\"Cannot divide by zero\")\n        return a / b\n\n\ndef test_addition():\n    \"\"\"Test addition.\"\"\"\n    calc = Calculator()\n    assert calc.add(2, 3) == 5\n    assert calc.add(-1, 1) == 0\n    assert calc.add(0, 0) == 0\n\n\ndef test_subtraction():\n    \"\"\"Test subtraction.\"\"\"\n    calc = Calculator()\n    assert calc.subtract(5, 3) == 2\n    assert calc.subtract(0, 5) == -5\n\n\ndef test_multiplication():\n    \"\"\"Test multiplication.\"\"\"\n    calc = Calculator()\n    assert calc.multiply(3, 4) == 12\n    assert calc.multiply(0, 5) == 0\n\n\ndef test_division():\n    \"\"\"Test division.\"\"\"\n    calc = Calculator()\n    assert calc.divide(6, 3) == 2\n    assert calc.divide(5, 2) == 2.5\n\n\ndef test_division_by_zero():\n    \"\"\"Test division by zero raises error.\"\"\"\n    calc = Calculator()\n    with pytest.raises(ValueError, match=\"Cannot divide by zero\"):\n        calc.divide(5, 0)\n```\n\n### Pattern 2: Fixtures for Setup and Teardown\n\n```python\n# test_database.py\nimport pytest\nfrom typing import Generator\n\nclass Database:\n    \"\"\"Simple database class.\"\"\"\n\n    def __init__(self, connection_string: str):\n        self.connection_string = connection_string\n        self.connected = False\n\n    def connect(self):\n        \"\"\"Connect to database.\"\"\"\n        self.connected = True\n\n    def disconnect(self):\n        \"\"\"Disconnect from database.\"\"\"\n        self.connected = False\n\n    def query(self, sql: str) -> list:\n        \"\"\"Execute query.\"\"\"\n        if not self.connected:\n            raise RuntimeError(\"Not connected\")\n        return [{\"id\": 1, \"name\": \"Test\"}]\n\n\n@pytest.fixture\ndef db() -> Generator[Database, None, None]:\n    \"\"\"Fixture that provides connected database.\"\"\"\n    # Setup\n    database = Database(\"sqlite:///:memory:\")\n    database.connect()\n\n    # Provide to test\n    yield database\n\n    # Teardown\n    database.disconnect()\n\n\ndef test_database_query(db):\n    \"\"\"Test database query with fixture.\"\"\"\n    results = db.query(\"SELECT * FROM users\")\n    assert len(results) == 1\n    assert results[0][\"name\"] == \"Test\"\n\n\n@pytest.fixture(scope=\"session\")\ndef app_config():\n    \"\"\"Session-scoped fixture - created once per test session.\"\"\"\n    return {\n        \"database_url\": \"postgresql://localhost/test\",\n        \"api_key\": \"test-key\",\n        \"debug\": True\n    }\n\n\n@pytest.fixture(scope=\"module\")\ndef api_client(app_config):\n    \"\"\"Module-scoped fixture - created once per test module.\"\"\"\n    # Setup expensive resource\n    client = {\"config\": app_config, \"session\": \"active\"}\n    yield client\n    # Cleanup\n    client[\"session\"] = \"closed\"\n\n\ndef test_api_client(api_client):\n    \"\"\"Test using api client fixture.\"\"\"\n    assert api_client[\"session\"] == \"active\"\n    assert api_client[\"config\"][\"debug\"] is True\n```\n\n### Pattern 3: Parameterized Tests\n\n```python\n# test_validation.py\nimport pytest\n\ndef is_valid_email(email: str) -> bool:\n    \"\"\"Check if email is valid.\"\"\"\n    return \"@\" in email and \".\" in email.split(\"@\")[1]\n\n\n@pytest.mark.parametrize(\"email,expected\", [\n    (\"user@example.com\", True),\n    (\"test.user@domain.co.uk\", True),\n    (\"invalid.email\", False),\n    (\"@example.com\", False),\n    (\"user@domain\", False),\n    (\"\", False),\n])\ndef test_email_validation(email, expected):\n    \"\"\"Test email validation with various inputs.\"\"\"\n    assert is_valid_email(email) == expected\n\n\n@pytest.mark.parametrize(\"a,b,expected\", [\n    (2, 3, 5),\n    (0, 0, 0),\n    (-1, 1, 0),\n    (100, 200, 300),\n    (-5, -5, -10),\n])\ndef test_addition_parameterized(a, b, expected):\n    \"\"\"Test addition with multiple parameter sets.\"\"\"\n    from test_calculator import Calculator\n    calc = Calculator()\n    assert calc.add(a, b) == expected\n\n\n# Using pytest.param for special cases\n@pytest.mark.parametrize(\"value,expected\", [\n    pytest.param(1, True, id=\"positive\"),\n    pytest.param(0, False, id=\"zero\"),\n    pytest.param(-1, False, id=\"negative\"),\n])\ndef test_is_positive(value, expected):\n    \"\"\"Test with custom test IDs.\"\"\"\n    assert (value > 0) == expected\n```\n\n### Pattern 4: Mocking with unittest.mock\n\n```python\n# test_api_client.py\nimport pytest\nfrom unittest.mock import Mock, patch, MagicMock\nimport requests\n\nclass APIClient:\n    \"\"\"Simple API client.\"\"\"\n\n    def __init__(self, base_url: str):\n        self.base_url = base_url\n\n    def get_user(self, user_id: int) -> dict:\n        \"\"\"Fetch user from API.\"\"\"\n        response = requests.get(f\"{self.base_url}/users/{user_id}\")\n        response.raise_for_status()\n        return response.json()\n\n    def create_user(self, data: dict) -> dict:\n        \"\"\"Create new user.\"\"\"\n        response = requests.post(f\"{self.base_url}/users\", json=data)\n        response.raise_for_status()\n        return response.json()\n\n\ndef test_get_user_success():\n    \"\"\"Test successful API call with mock.\"\"\"\n    client = APIClient(\"https://api.example.com\")\n\n    mock_response = Mock()\n    mock_response.json.return_value = {\"id\": 1, \"name\": \"John Doe\"}\n    mock_response.raise_for_status.return_value = None\n\n    with patch(\"requests.get\", return_value=mock_response) as mock_get:\n        user = client.get_user(1)\n\n        assert user[\"id\"] == 1\n        assert user[\"name\"] == \"John Doe\"\n        mock_get.assert_called_once_with(\"https://api.example.com/users/1\")\n\n\ndef test_get_user_not_found():\n    \"\"\"Test API call with 404 error.\"\"\"\n    client = APIClient(\"https://api.example.com\")\n\n    mock_response = Mock()\n    mock_response.raise_for_status.side_effect = requests.HTTPError(\"404 Not Found\")\n\n    with patch(\"requests.get\", return_value=mock_response):\n        with pytest.raises(requests.HTTPError):\n            client.get_user(999)\n\n\n@patch(\"requests.post\")\ndef test_create_user(mock_post):\n    \"\"\"Test user creation with decorator syntax.\"\"\"\n    client = APIClient(\"https://api.example.com\")\n\n    mock_post.return_value.json.return_value = {\"id\": 2, \"name\": \"Jane Doe\"}\n    mock_post.return_value.raise_for_status.return_value = None\n\n    user_data = {\"name\": \"Jane Doe\", \"email\": \"jane@example.com\"}\n    result = client.create_user(user_data)\n\n    assert result[\"id\"] == 2\n    mock_post.assert_called_once()\n    call_args = mock_post.call_args\n    assert call_args.kwargs[\"json\"] == user_data\n```\n\n### Pattern 5: Testing Exceptions\n\n```python\n# test_exceptions.py\nimport pytest\n\ndef divide(a: float, b: float) -> float:\n    \"\"\"Divide a by b.\"\"\"\n    if b == 0:\n        raise ZeroDivisionError(\"Division by zero\")\n    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\n        raise TypeError(\"Arguments must be numbers\")\n    return a / b\n\n\ndef test_zero_division():\n    \"\"\"Test exception is raised for division by zero.\"\"\"\n    with pytest.raises(ZeroDivisionError):\n        divide(10, 0)\n\n\ndef test_zero_division_with_message():\n    \"\"\"Test exception message.\"\"\"\n    with pytest.raises(ZeroDivisionError, match=\"Division by zero\"):\n        divide(5, 0)\n\n\ndef test_type_error():\n    \"\"\"Test type error exception.\"\"\"\n    with pytest.raises(TypeError, match=\"must be numbers\"):\n        divide(\"10\", 5)\n\n\ndef test_exception_info():\n    \"\"\"Test accessing exception info.\"\"\"\n    with pytest.raises(ValueError) as exc_info:\n        int(\"not a number\")\n\n    assert \"invalid literal\" in str(exc_info.value)\n```\n\n## Advanced Patterns\n\n### Pattern 6: Testing Async Code\n\n```python\n# test_async.py\nimport pytest\nimport asyncio\n\nasync def fetch_data(url: str) -> dict:\n    \"\"\"Fetch data asynchronously.\"\"\"\n    await asyncio.sleep(0.1)\n    return {\"url\": url, \"data\": \"result\"}\n\n\n@pytest.mark.asyncio\nasync def test_fetch_data():\n    \"\"\"Test async function.\"\"\"\n    result = await fetch_data(\"https://api.example.com\")\n    assert result[\"url\"] == \"https://api.example.com\"\n    assert \"data\" in result\n\n\n@pytest.mark.asyncio\nasync def test_concurrent_fetches():\n    \"\"\"Test concurrent async operations.\"\"\"\n    urls = [\"url1\", \"url2\", \"url3\"]\n    tasks = [fetch_data(url) for url in urls]\n    results = await asyncio.gather(*tasks)\n\n    assert len(results) == 3\n    assert all(\"data\" in r for r in results)\n\n\n@pytest.fixture\nasync def async_client():\n    \"\"\"Async fixture.\"\"\"\n    client = {\"connected\": True}\n    yield client\n    client[\"connected\"] = False\n\n\n@pytest.mark.asyncio\nasync def test_with_async_fixture(async_client):\n    \"\"\"Test using async fixture.\"\"\"\n    assert async_client[\"connected\"] is True\n```\n\n### Pattern 7: Monkeypatch for Testing\n\n```python\n# test_environment.py\nimport os\nimport pytest\n\ndef get_database_url() -> str:\n    \"\"\"Get database URL from environment.\"\"\"\n    return os.environ.get(\"DATABASE_URL\", \"sqlite:///:memory:\")\n\n\ndef test_database_url_default():\n    \"\"\"Test default database URL.\"\"\"\n    # Will use actual environment variable if set\n    url = get_database_url()\n    assert url\n\n\ndef test_database_url_custom(monkeypatch):\n    \"\"\"Test custom database URL with monkeypatch.\"\"\"\n    monkeypatch.setenv(\"DATABASE_URL\", \"postgresql://localhost/test\")\n    assert get_database_url() == \"postgresql://localhost/test\"\n\n\ndef test_database_url_not_set(monkeypatch):\n    \"\"\"Test when env var is not set.\"\"\"\n    monkeypatch.delenv(\"DATABASE_URL\", raising=False)\n    assert get_database_url() == \"sqlite:///:memory:\"\n\n\nclass Config:\n    \"\"\"Configuration class.\"\"\"\n\n    def __init__(self):\n        self.api_key = \"production-key\"\n\n    def get_api_key(self):\n        return self.api_key\n\n\ndef test_monkeypatch_attribute(monkeypatch):\n    \"\"\"Test monkeypatching object attributes.\"\"\"\n    config = Config()\n    monkeypatch.setattr(config, \"api_key\", \"test-key\")\n    assert config.get_api_key() == \"test-key\"\n```\n\n### Pattern 8: Temporary Files and Directories\n\n```python\n# test_file_operations.py\nimport pytest\nfrom pathlib import Path\n\ndef save_data(filepath: Path, data: str):\n    \"\"\"Save data to file.\"\"\"\n    filepath.write_text(data)\n\n\ndef load_data(filepath: Path) -> str:\n    \"\"\"Load data from file.\"\"\"\n    return filepath.read_text()\n\n\ndef test_file_operations(tmp_path):\n    \"\"\"Test file operations with temporary directory.\"\"\"\n    # tmp_path is a pathlib.Path object\n    test_file = tmp_path / \"test_data.txt\"\n\n    # Save data\n    save_data(test_file, \"Hello, World!\")\n\n    # Verify file exists\n    assert test_file.exists()\n\n    # Load and verify data\n    data = load_data(test_file)\n    assert data == \"Hello, World!\"\n\n\ndef test_multiple_files(tmp_path):\n    \"\"\"Test with multiple temporary files.\"\"\"\n    files = {\n        \"file1.txt\": \"Content 1\",\n        \"file2.txt\": \"Content 2\",\n        \"file3.txt\": \"Content 3\"\n    }\n\n    for filename, content in files.items():\n        filepath = tmp_path / filename\n        save_data(filepath, content)\n\n    # Verify all files created\n    assert len(list(tmp_path.iterdir())) == 3\n\n    # Verify contents\n    for filename, expected_content in files.items():\n        filepath = tmp_path / filename\n        assert load_data(filepath) == expected_content\n```\n\n### Pattern 9: Custom Fixtures and Conftest\n\n```python\n# conftest.py\n\"\"\"Shared fixtures for all tests.\"\"\"\nimport pytest\n\n@pytest.fixture(scope=\"session\")\ndef database_url():\n    \"\"\"Provide database URL for all tests.\"\"\"\n    return \"postgresql://localhost/test_db\"\n\n\n@pytest.fixture(autouse=True)\ndef reset_database(database_url):\n    \"\"\"Auto-use fixture that runs before each test.\"\"\"\n    # Setup: Clear database\n    print(f\"Clearing database: {database_url}\")\n    yield\n    # Teardown: Clean up\n    print(\"Test completed\")\n\n\n@pytest.fixture\ndef sample_user():\n    \"\"\"Provide sample user data.\"\"\"\n    return {\n        \"id\": 1,\n        \"name\": \"Test User\",\n        \"email\": \"test@example.com\"\n    }\n\n\n@pytest.fixture\ndef sample_users():\n    \"\"\"Provide list of sample users.\"\"\"\n    return [\n        {\"id\": 1, \"name\": \"User 1\"},\n        {\"id\": 2, \"name\": \"User 2\"},\n        {\"id\": 3, \"name\": \"User 3\"},\n    ]\n\n\n# Parametrized fixture\n@pytest.fixture(params=[\"sqlite\", \"postgresql\", \"mysql\"])\ndef db_backend(request):\n    \"\"\"Fixture that runs tests with different database backends.\"\"\"\n    return request.param\n\n\ndef test_with_db_backend(db_backend):\n    \"\"\"This test will run 3 times with different backends.\"\"\"\n    print(f\"Testing with {db_backend}\")\n    assert db_backend in [\"sqlite\", \"postgresql\", \"mysql\"]\n```\n\n### Pattern 10: Property-Based Testing\n\n```python\n# test_properties.py\nfrom hypothesis import given, strategies as st\nimport pytest\n\ndef reverse_string(s: str) -> str:\n    \"\"\"Reverse a string.\"\"\"\n    return s[::-1]\n\n\n@given(st.text())\ndef test_reverse_twice_is_original(s):\n    \"\"\"Property: reversing twice returns original.\"\"\"\n    assert reverse_string(reverse_string(s)) == s\n\n\n@given(st.text())\ndef test_reverse_length(s):\n    \"\"\"Property: reversed string has same length.\"\"\"\n    assert len(reverse_string(s)) == len(s)\n\n\n@given(st.integers(), st.integers())\ndef test_addition_commutative(a, b):\n    \"\"\"Property: addition is commutative.\"\"\"\n    assert a + b == b + a\n\n\n@given(st.lists(st.integers()))\ndef test_sorted_list_properties(lst):\n    \"\"\"Property: sorted list is ordered.\"\"\"\n    sorted_lst = sorted(lst)\n\n    # Same length\n    assert len(sorted_lst) == len(lst)\n\n    # All elements present\n    assert set(sorted_lst) == set(lst)\n\n    # Is ordered\n    for i in range(len(sorted_lst) - 1):\n        assert sorted_lst[i] <= sorted_lst[i + 1]\n```\n\n## Testing Best Practices\n\n### Test Organization\n\n```python\n# tests/\n#   __init__.py\n#   conftest.py           # Shared fixtures\n#   test_unit/            # Unit tests\n#     test_models.py\n#     test_utils.py\n#   test_integration/     # Integration tests\n#     test_api.py\n#     test_database.py\n#   test_e2e/            # End-to-end tests\n#     test_workflows.py\n```\n\n### Test Naming\n\n```python\n# Good test names\ndef test_user_creation_with_valid_data():\n    \"\"\"Clear name describes what is being tested.\"\"\"\n    pass\n\n\ndef test_login_fails_with_invalid_password():\n    \"\"\"Name describes expected behavior.\"\"\"\n    pass\n\n\ndef test_api_returns_404_for_missing_resource():\n    \"\"\"Specific about inputs and expected outcomes.\"\"\"\n    pass\n\n\n# Bad test names\ndef test_1():  # Not descriptive\n    pass\n\n\ndef test_user():  # Too vague\n    pass\n\n\ndef test_function():  # Doesn't explain what's tested\n    pass\n```\n\n### Test Markers\n\n```python\n# test_markers.py\nimport pytest\n\n@pytest.mark.slow\ndef test_slow_operation():\n    \"\"\"Mark slow tests.\"\"\"\n    import time\n    time.sleep(2)\n\n\n@pytest.mark.integration\ndef test_database_integration():\n    \"\"\"Mark integration tests.\"\"\"\n    pass\n\n\n@pytest.mark.skip(reason=\"Feature not implemented yet\")\ndef test_future_feature():\n    \"\"\"Skip tests temporarily.\"\"\"\n    pass\n\n\n@pytest.mark.skipif(os.name == \"nt\", reason=\"Unix only test\")\ndef test_unix_specific():\n    \"\"\"Conditional skip.\"\"\"\n    pass\n\n\n@pytest.mark.xfail(reason=\"Known bug #123\")\ndef test_known_bug():\n    \"\"\"Mark expected failures.\"\"\"\n    assert False\n\n\n# Run with:\n# pytest -m slow          # Run only slow tests\n# pytest -m \"not slow\"    # Skip slow tests\n# pytest -m integration   # Run integration tests\n```\n\n### Coverage Reporting\n\n```bash\n# Install coverage\npip install pytest-cov\n\n# Run tests with coverage\npytest --cov=myapp tests/\n\n# Generate HTML report\npytest --cov=myapp --cov-report=html tests/\n\n# Fail if coverage below threshold\npytest --cov=myapp --cov-fail-under=80 tests/\n\n# Show missing lines\npytest --cov=myapp --cov-report=term-missing tests/\n```\n\n## Testing Database Code\n\n```python\n# test_database_models.py\nimport pytest\nfrom sqlalchemy import create_engine, Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session\n\nBase = declarative_base()\n\n\nclass User(Base):\n    \"\"\"User model.\"\"\"\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True)\n    name = Column(String(50))\n    email = Column(String(100), unique=True)\n\n\n@pytest.fixture(scope=\"function\")\ndef db_session() -> Session:\n    \"\"\"Create in-memory database for testing.\"\"\"\n    engine = create_engine(\"sqlite:///:memory:\")\n    Base.metadata.create_all(engine)\n\n    SessionLocal = sessionmaker(bind=engine)\n    session = SessionLocal()\n\n    yield session\n\n    session.close()\n\n\ndef test_create_user(db_session):\n    \"\"\"Test creating a user.\"\"\"\n    user = User(name=\"Test User\", email=\"test@example.com\")\n    db_session.add(user)\n    db_session.commit()\n\n    assert user.id is not None\n    assert user.name == \"Test User\"\n\n\ndef test_query_user(db_session):\n    \"\"\"Test querying users.\"\"\"\n    user1 = User(name=\"User 1\", email=\"user1@example.com\")\n    user2 = User(name=\"User 2\", email=\"user2@example.com\")\n\n    db_session.add_all([user1, user2])\n    db_session.commit()\n\n    users = db_session.query(User).all()\n    assert len(users) == 2\n\n\ndef test_unique_email_constraint(db_session):\n    \"\"\"Test unique email constraint.\"\"\"\n    from sqlalchemy.exc import IntegrityError\n\n    user1 = User(name=\"User 1\", email=\"same@example.com\")\n    user2 = User(name=\"User 2\", email=\"same@example.com\")\n\n    db_session.add(user1)\n    db_session.commit()\n\n    db_session.add(user2)\n\n    with pytest.raises(IntegrityError):\n        db_session.commit()\n```\n\n## CI/CD Integration\n\n```yaml\n# .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        python-version: [\"3.9\", \"3.10\", \"3.11\", \"3.12\"]\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Install dependencies\n        run: |\n          pip install -e \".[dev]\"\n          pip install pytest pytest-cov\n\n      - name: Run tests\n        run: |\n          pytest --cov=myapp --cov-report=xml\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml\n```\n\n## Configuration Files\n\n```ini\n# pytest.ini\n[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts =\n    -v\n    --strict-markers\n    --tb=short\n    --cov=myapp\n    --cov-report=term-missing\nmarkers =\n    slow: marks tests as slow\n    integration: marks integration tests\n    unit: marks unit tests\n    e2e: marks end-to-end tests\n```\n\n```toml\n# pyproject.toml\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\naddopts = [\n    \"-v\",\n    \"--cov=myapp\",\n    \"--cov-report=term-missing\",\n]\n\n[tool.coverage.run]\nsource = [\"myapp\"]\nomit = [\"*/tests/*\", \"*/migrations/*\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n]\n```\n\n## Resources\n\n- **pytest documentation**: https://docs.pytest.org/\n- **unittest.mock**: https://docs.python.org/3/library/unittest.mock.html\n- **hypothesis**: Property-based testing\n- **pytest-asyncio**: Testing async code\n- **pytest-cov**: Coverage reporting\n- **pytest-mock**: pytest wrapper for mock\n\n## Best Practices Summary\n\n1. **Write tests first** (TDD) or alongside code\n2. **One assertion per test** when possible\n3. **Use descriptive test names** that explain behavior\n4. **Keep tests independent** and isolated\n5. **Use fixtures** for setup and teardown\n6. **Mock external dependencies** appropriately\n7. **Parametrize tests** to reduce duplication\n8. **Test edge cases** and error conditions\n9. **Measure coverage** but focus on quality\n10. **Run tests in CI/CD** on every commit"
              },
              {
                "name": "uv-package-manager",
                "description": "Master the uv package manager for fast Python dependency management, virtual environments, and modern Python project workflows. Use when setting up Python projects, managing dependencies, or optimizing Python development workflows with uv.",
                "path": "plugins/python-development/skills/uv-package-manager/SKILL.md",
                "frontmatter": {
                  "name": "uv-package-manager",
                  "description": "Master the uv package manager for fast Python dependency management, virtual environments, and modern Python project workflows. Use when setting up Python projects, managing dependencies, or optimizing Python development workflows with uv."
                },
                "content": "# UV Package Manager\n\nComprehensive guide to using uv, an extremely fast Python package installer and resolver written in Rust, for modern Python project management and dependency workflows.\n\n## When to Use This Skill\n\n- Setting up new Python projects quickly\n- Managing Python dependencies faster than pip\n- Creating and managing virtual environments\n- Installing Python interpreters\n- Resolving dependency conflicts efficiently\n- Migrating from pip/pip-tools/poetry\n- Speeding up CI/CD pipelines\n- Managing monorepo Python projects\n- Working with lockfiles for reproducible builds\n- Optimizing Docker builds with Python dependencies\n\n## Core Concepts\n\n### 1. What is uv?\n- **Ultra-fast package installer**: 10-100x faster than pip\n- **Written in Rust**: Leverages Rust's performance\n- **Drop-in pip replacement**: Compatible with pip workflows\n- **Virtual environment manager**: Create and manage venvs\n- **Python installer**: Download and manage Python versions\n- **Resolver**: Advanced dependency resolution\n- **Lockfile support**: Reproducible installations\n\n### 2. Key Features\n- Blazing fast installation speeds\n- Disk space efficient with global cache\n- Compatible with pip, pip-tools, poetry\n- Comprehensive dependency resolution\n- Cross-platform support (Linux, macOS, Windows)\n- No Python required for installation\n- Built-in virtual environment support\n\n### 3. UV vs Traditional Tools\n- **vs pip**: 10-100x faster, better resolver\n- **vs pip-tools**: Faster, simpler, better UX\n- **vs poetry**: Faster, less opinionated, lighter\n- **vs conda**: Faster, Python-focused\n\n## Installation\n\n### Quick Install\n\n```bash\n# macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows (PowerShell)\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Using pip (if you already have Python)\npip install uv\n\n# Using Homebrew (macOS)\nbrew install uv\n\n# Using cargo (if you have Rust)\ncargo install --git https://github.com/astral-sh/uv uv\n```\n\n### Verify Installation\n\n```bash\nuv --version\n# uv 0.x.x\n```\n\n## Quick Start\n\n### Create a New Project\n\n```bash\n# Create new project with virtual environment\nuv init my-project\ncd my-project\n\n# Or create in current directory\nuv init .\n\n# Initialize creates:\n# - .python-version (Python version)\n# - pyproject.toml (project config)\n# - README.md\n# - .gitignore\n```\n\n### Install Dependencies\n\n```bash\n# Install packages (creates venv if needed)\nuv add requests pandas\n\n# Install dev dependencies\nuv add --dev pytest black ruff\n\n# Install from requirements.txt\nuv pip install -r requirements.txt\n\n# Install from pyproject.toml\nuv sync\n```\n\n## Virtual Environment Management\n\n### Pattern 1: Creating Virtual Environments\n\n```bash\n# Create virtual environment with uv\nuv venv\n\n# Create with specific Python version\nuv venv --python 3.12\n\n# Create with custom name\nuv venv my-env\n\n# Create with system site packages\nuv venv --system-site-packages\n\n# Specify location\nuv venv /path/to/venv\n```\n\n### Pattern 2: Activating Virtual Environments\n\n```bash\n# Linux/macOS\nsource .venv/bin/activate\n\n# Windows (Command Prompt)\n.venv\\Scripts\\activate.bat\n\n# Windows (PowerShell)\n.venv\\Scripts\\Activate.ps1\n\n# Or use uv run (no activation needed)\nuv run python script.py\nuv run pytest\n```\n\n### Pattern 3: Using uv run\n\n```bash\n# Run Python script (auto-activates venv)\nuv run python app.py\n\n# Run installed CLI tool\nuv run black .\nuv run pytest\n\n# Run with specific Python version\nuv run --python 3.11 python script.py\n\n# Pass arguments\nuv run python script.py --arg value\n```\n\n## Package Management\n\n### Pattern 4: Adding Dependencies\n\n```bash\n# Add package (adds to pyproject.toml)\nuv add requests\n\n# Add with version constraint\nuv add \"django>=4.0,<5.0\"\n\n# Add multiple packages\nuv add numpy pandas matplotlib\n\n# Add dev dependency\nuv add --dev pytest pytest-cov\n\n# Add optional dependency group\nuv add --optional docs sphinx\n\n# Add from git\nuv add git+https://github.com/user/repo.git\n\n# Add from git with specific ref\nuv add git+https://github.com/user/repo.git@v1.0.0\n\n# Add from local path\nuv add ./local-package\n\n# Add editable local package\nuv add -e ./local-package\n```\n\n### Pattern 5: Removing Dependencies\n\n```bash\n# Remove package\nuv remove requests\n\n# Remove dev dependency\nuv remove --dev pytest\n\n# Remove multiple packages\nuv remove numpy pandas matplotlib\n```\n\n### Pattern 6: Upgrading Dependencies\n\n```bash\n# Upgrade specific package\nuv add --upgrade requests\n\n# Upgrade all packages\nuv sync --upgrade\n\n# Upgrade package to latest\nuv add --upgrade requests\n\n# Show what would be upgraded\nuv tree --outdated\n```\n\n### Pattern 7: Locking Dependencies\n\n```bash\n# Generate uv.lock file\nuv lock\n\n# Update lock file\nuv lock --upgrade\n\n# Lock without installing\nuv lock --no-install\n\n# Lock specific package\nuv lock --upgrade-package requests\n```\n\n## Python Version Management\n\n### Pattern 8: Installing Python Versions\n\n```bash\n# Install Python version\nuv python install 3.12\n\n# Install multiple versions\nuv python install 3.11 3.12 3.13\n\n# Install latest version\nuv python install\n\n# List installed versions\nuv python list\n\n# Find available versions\nuv python list --all-versions\n```\n\n### Pattern 9: Setting Python Version\n\n```bash\n# Set Python version for project\nuv python pin 3.12\n\n# This creates/updates .python-version file\n\n# Use specific Python version for command\nuv --python 3.11 run python script.py\n\n# Create venv with specific version\nuv venv --python 3.12\n```\n\n## Project Configuration\n\n### Pattern 10: pyproject.toml with uv\n\n```toml\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"My awesome project\"\nreadme = \"README.md\"\nrequires-python = \">=3.8\"\ndependencies = [\n    \"requests>=2.31.0\",\n    \"pydantic>=2.0.0\",\n    \"click>=8.1.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=7.4.0\",\n    \"pytest-cov>=4.1.0\",\n    \"black>=23.0.0\",\n    \"ruff>=0.1.0\",\n    \"mypy>=1.5.0\",\n]\ndocs = [\n    \"sphinx>=7.0.0\",\n    \"sphinx-rtd-theme>=1.3.0\",\n]\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.uv]\ndev-dependencies = [\n    # Additional dev dependencies managed by uv\n]\n\n[tool.uv.sources]\n# Custom package sources\nmy-package = { git = \"https://github.com/user/repo.git\" }\n```\n\n### Pattern 11: Using uv with Existing Projects\n\n```bash\n# Migrate from requirements.txt\nuv add -r requirements.txt\n\n# Migrate from poetry\n# Already have pyproject.toml, just use:\nuv sync\n\n# Export to requirements.txt\nuv pip freeze > requirements.txt\n\n# Export with hashes\nuv pip freeze --require-hashes > requirements.txt\n```\n\n## Advanced Workflows\n\n### Pattern 12: Monorepo Support\n\n```bash\n# Project structure\n# monorepo/\n#   packages/\n#     package-a/\n#       pyproject.toml\n#     package-b/\n#       pyproject.toml\n#   pyproject.toml (root)\n\n# Root pyproject.toml\n[tool.uv.workspace]\nmembers = [\"packages/*\"]\n\n# Install all workspace packages\nuv sync\n\n# Add workspace dependency\nuv add --path ./packages/package-a\n```\n\n### Pattern 13: CI/CD Integration\n\n```yaml\n# .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v2\n        with:\n          enable-cache: true\n\n      - name: Set up Python\n        run: uv python install 3.12\n\n      - name: Install dependencies\n        run: uv sync --all-extras --dev\n\n      - name: Run tests\n        run: uv run pytest\n\n      - name: Run linting\n        run: |\n          uv run ruff check .\n          uv run black --check .\n```\n\n### Pattern 14: Docker Integration\n\n```dockerfile\n# Dockerfile\nFROM python:3.12-slim\n\n# Install uv\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n\n# Set working directory\nWORKDIR /app\n\n# Copy dependency files\nCOPY pyproject.toml uv.lock ./\n\n# Install dependencies\nRUN uv sync --frozen --no-dev\n\n# Copy application code\nCOPY . .\n\n# Run application\nCMD [\"uv\", \"run\", \"python\", \"app.py\"]\n```\n\n**Optimized multi-stage build:**\n\n```dockerfile\n# Multi-stage Dockerfile\nFROM python:3.12-slim AS builder\n\n# Install uv\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n\nWORKDIR /app\n\n# Install dependencies to venv\nCOPY pyproject.toml uv.lock ./\nRUN uv sync --frozen --no-dev --no-editable\n\n# Runtime stage\nFROM python:3.12-slim\n\nWORKDIR /app\n\n# Copy venv from builder\nCOPY --from=builder /app/.venv .venv\nCOPY . .\n\n# Use venv\nENV PATH=\"/app/.venv/bin:$PATH\"\n\nCMD [\"python\", \"app.py\"]\n```\n\n### Pattern 15: Lockfile Workflows\n\n```bash\n# Create lockfile (uv.lock)\nuv lock\n\n# Install from lockfile (exact versions)\nuv sync --frozen\n\n# Update lockfile without installing\nuv lock --no-install\n\n# Upgrade specific package in lock\nuv lock --upgrade-package requests\n\n# Check if lockfile is up to date\nuv lock --check\n\n# Export lockfile to requirements.txt\nuv export --format requirements-txt > requirements.txt\n\n# Export with hashes for security\nuv export --format requirements-txt --hash > requirements.txt\n```\n\n## Performance Optimization\n\n### Pattern 16: Using Global Cache\n\n```bash\n# UV automatically uses global cache at:\n# Linux: ~/.cache/uv\n# macOS: ~/Library/Caches/uv\n# Windows: %LOCALAPPDATA%\\uv\\cache\n\n# Clear cache\nuv cache clean\n\n# Check cache size\nuv cache dir\n```\n\n### Pattern 17: Parallel Installation\n\n```bash\n# UV installs packages in parallel by default\n\n# Control parallelism\nuv pip install --jobs 4 package1 package2\n\n# No parallel (sequential)\nuv pip install --jobs 1 package\n```\n\n### Pattern 18: Offline Mode\n\n```bash\n# Install from cache only (no network)\nuv pip install --offline package\n\n# Sync from lockfile offline\nuv sync --frozen --offline\n```\n\n## Comparison with Other Tools\n\n### uv vs pip\n\n```bash\n# pip\npython -m venv .venv\nsource .venv/bin/activate\npip install requests pandas numpy\n# ~30 seconds\n\n# uv\nuv venv\nuv add requests pandas numpy\n# ~2 seconds (10-15x faster)\n```\n\n### uv vs poetry\n\n```bash\n# poetry\npoetry init\npoetry add requests pandas\npoetry install\n# ~20 seconds\n\n# uv\nuv init\nuv add requests pandas\nuv sync\n# ~3 seconds (6-7x faster)\n```\n\n### uv vs pip-tools\n\n```bash\n# pip-tools\npip-compile requirements.in\npip-sync requirements.txt\n# ~15 seconds\n\n# uv\nuv lock\nuv sync --frozen\n# ~2 seconds (7-8x faster)\n```\n\n## Common Workflows\n\n### Pattern 19: Starting a New Project\n\n```bash\n# Complete workflow\nuv init my-project\ncd my-project\n\n# Set Python version\nuv python pin 3.12\n\n# Add dependencies\nuv add fastapi uvicorn pydantic\n\n# Add dev dependencies\nuv add --dev pytest black ruff mypy\n\n# Create structure\nmkdir -p src/my_project tests\n\n# Run tests\nuv run pytest\n\n# Format code\nuv run black .\nuv run ruff check .\n```\n\n### Pattern 20: Maintaining Existing Project\n\n```bash\n# Clone repository\ngit clone https://github.com/user/project.git\ncd project\n\n# Install dependencies (creates venv automatically)\nuv sync\n\n# Install with dev dependencies\nuv sync --all-extras\n\n# Update dependencies\nuv lock --upgrade\n\n# Run application\nuv run python app.py\n\n# Run tests\nuv run pytest\n\n# Add new dependency\nuv add new-package\n\n# Commit updated files\ngit add pyproject.toml uv.lock\ngit commit -m \"Add new-package dependency\"\n```\n\n## Tool Integration\n\n### Pattern 21: Pre-commit Hooks\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: uv-lock\n        name: uv lock\n        entry: uv lock\n        language: system\n        pass_filenames: false\n\n      - id: ruff\n        name: ruff\n        entry: uv run ruff check --fix\n        language: system\n        types: [python]\n\n      - id: black\n        name: black\n        entry: uv run black\n        language: system\n        types: [python]\n```\n\n### Pattern 22: VS Code Integration\n\n```json\n// .vscode/settings.json\n{\n  \"python.defaultInterpreterPath\": \"${workspaceFolder}/.venv/bin/python\",\n  \"python.terminal.activateEnvironment\": true,\n  \"python.testing.pytestEnabled\": true,\n  \"python.testing.pytestArgs\": [\"-v\"],\n  \"python.linting.enabled\": true,\n  \"python.formatting.provider\": \"black\",\n  \"[python]\": {\n    \"editor.defaultFormatter\": \"ms-python.black-formatter\",\n    \"editor.formatOnSave\": true\n  }\n}\n```\n\n## Troubleshooting\n\n### Common Issues\n\n```bash\n# Issue: uv not found\n# Solution: Add to PATH or reinstall\necho 'export PATH=\"$HOME/.cargo/bin:$PATH\"' >> ~/.bashrc\n\n# Issue: Wrong Python version\n# Solution: Pin version explicitly\nuv python pin 3.12\nuv venv --python 3.12\n\n# Issue: Dependency conflict\n# Solution: Check resolution\nuv lock --verbose\n\n# Issue: Cache issues\n# Solution: Clear cache\nuv cache clean\n\n# Issue: Lockfile out of sync\n# Solution: Regenerate\nuv lock --upgrade\n```\n\n## Best Practices\n\n### Project Setup\n\n1. **Always use lockfiles** for reproducibility\n2. **Pin Python version** with .python-version\n3. **Separate dev dependencies** from production\n4. **Use uv run** instead of activating venv\n5. **Commit uv.lock** to version control\n6. **Use --frozen in CI** for consistent builds\n7. **Leverage global cache** for speed\n8. **Use workspace** for monorepos\n9. **Export requirements.txt** for compatibility\n10. **Keep uv updated** for latest features\n\n### Performance Tips\n\n```bash\n# Use frozen installs in CI\nuv sync --frozen\n\n# Use offline mode when possible\nuv sync --offline\n\n# Parallel operations (automatic)\n# uv does this by default\n\n# Reuse cache across environments\n# uv shares cache globally\n\n# Use lockfiles to skip resolution\nuv sync --frozen  # skips resolution\n```\n\n## Migration Guide\n\n### From pip + requirements.txt\n\n```bash\n# Before\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n\n# After\nuv venv\nuv pip install -r requirements.txt\n# Or better:\nuv init\nuv add -r requirements.txt\n```\n\n### From Poetry\n\n```bash\n# Before\npoetry install\npoetry add requests\n\n# After\nuv sync\nuv add requests\n\n# Keep existing pyproject.toml\n# uv reads [project] and [tool.poetry] sections\n```\n\n### From pip-tools\n\n```bash\n# Before\npip-compile requirements.in\npip-sync requirements.txt\n\n# After\nuv lock\nuv sync --frozen\n```\n\n## Command Reference\n\n### Essential Commands\n\n```bash\n# Project management\nuv init [PATH]              # Initialize project\nuv add PACKAGE              # Add dependency\nuv remove PACKAGE           # Remove dependency\nuv sync                     # Install dependencies\nuv lock                     # Create/update lockfile\n\n# Virtual environments\nuv venv [PATH]              # Create venv\nuv run COMMAND              # Run in venv\n\n# Python management\nuv python install VERSION   # Install Python\nuv python list              # List installed Pythons\nuv python pin VERSION       # Pin Python version\n\n# Package installation (pip-compatible)\nuv pip install PACKAGE      # Install package\nuv pip uninstall PACKAGE    # Uninstall package\nuv pip freeze               # List installed\nuv pip list                 # List packages\n\n# Utility\nuv cache clean              # Clear cache\nuv cache dir                # Show cache location\nuv --version                # Show version\n```\n\n## Resources\n\n- **Official documentation**: https://docs.astral.sh/uv/\n- **GitHub repository**: https://github.com/astral-sh/uv\n- **Astral blog**: https://astral.sh/blog\n- **Migration guides**: https://docs.astral.sh/uv/guides/\n- **Comparison with other tools**: https://docs.astral.sh/uv/pip/compatibility/\n\n## Best Practices Summary\n\n1. **Use uv for all new projects** - Start with `uv init`\n2. **Commit lockfiles** - Ensure reproducible builds\n3. **Pin Python versions** - Use .python-version\n4. **Use uv run** - Avoid manual venv activation\n5. **Leverage caching** - Let uv manage global cache\n6. **Use --frozen in CI** - Exact reproduction\n7. **Keep uv updated** - Fast-moving project\n8. **Use workspaces** - For monorepo projects\n9. **Export for compatibility** - Generate requirements.txt when needed\n10. **Read the docs** - uv is feature-rich and evolving"
              }
            ]
          },
          {
            "name": "api-testing-observability",
            "description": null,
            "source": "./plugins/api-testing-observability",
            "category": null,
            "version": "1.2.2",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ai-pilo/agents-backend-architecture",
              "/plugin install api-testing-observability@agents-backend-architecture"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-10-20T23:03:39Z",
              "created_at": "2025-10-20T19:59:40Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/api-mock",
                "description": null,
                "path": "plugins/api-testing-observability/commands/api-mock.md",
                "frontmatter": null,
                "content": "# API Mocking Framework\n\nYou are an API mocking expert specializing in creating realistic mock services for development, testing, and demonstration purposes. Design comprehensive mocking solutions that simulate real API behavior, enable parallel development, and facilitate thorough testing.\n\n## Context\nThe user needs to create mock APIs for development, testing, or demonstration purposes. Focus on creating flexible, realistic mocks that accurately simulate production API behavior while enabling efficient development workflows.\n\n## Requirements\n$ARGUMENTS\n\n## Instructions\n\n### 1. Mock Server Setup\n\nCreate comprehensive mock server infrastructure:\n\n**Mock Server Framework**\n```python\nfrom typing import Dict, List, Any, Optional\nimport json\nimport asyncio\nfrom datetime import datetime\nfrom fastapi import FastAPI, Request, Response\nimport uvicorn\n\nclass MockAPIServer:\n    def __init__(self, config: Dict[str, Any]):\n        self.app = FastAPI(title=\"Mock API Server\")\n        self.routes = {}\n        self.middleware = []\n        self.state_manager = StateManager()\n        self.scenario_manager = ScenarioManager()\n        \n    def setup_mock_server(self):\n        \"\"\"Setup comprehensive mock server\"\"\"\n        # Configure middleware\n        self._setup_middleware()\n        \n        # Load mock definitions\n        self._load_mock_definitions()\n        \n        # Setup dynamic routes\n        self._setup_dynamic_routes()\n        \n        # Initialize scenarios\n        self._initialize_scenarios()\n        \n        return self.app\n    \n    def _setup_middleware(self):\n        \"\"\"Configure server middleware\"\"\"\n        @self.app.middleware(\"http\")\n        async def add_mock_headers(request: Request, call_next):\n            response = await call_next(request)\n            response.headers[\"X-Mock-Server\"] = \"true\"\n            response.headers[\"X-Mock-Scenario\"] = self.scenario_manager.current_scenario\n            return response\n        \n        @self.app.middleware(\"http\")\n        async def simulate_latency(request: Request, call_next):\n            # Simulate network latency\n            latency = self._calculate_latency(request.url.path)\n            await asyncio.sleep(latency / 1000)  # Convert to seconds\n            response = await call_next(request)\n            return response\n        \n        @self.app.middleware(\"http\")\n        async def track_requests(request: Request, call_next):\n            # Track request for verification\n            self.state_manager.track_request({\n                'method': request.method,\n                'path': str(request.url.path),\n                'headers': dict(request.headers),\n                'timestamp': datetime.now()\n            })\n            response = await call_next(request)\n            return response\n    \n    def _setup_dynamic_routes(self):\n        \"\"\"Setup dynamic route handling\"\"\"\n        @self.app.api_route(\"/{path:path}\", methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"])\n        async def handle_mock_request(path: str, request: Request):\n            # Find matching mock\n            mock = self._find_matching_mock(request.method, path, request)\n            \n            if not mock:\n                return Response(\n                    content=json.dumps({\"error\": \"No mock found for this endpoint\"}),\n                    status_code=404,\n                    media_type=\"application/json\"\n                )\n            \n            # Process mock response\n            response_data = await self._process_mock_response(mock, request)\n            \n            return Response(\n                content=json.dumps(response_data['body']),\n                status_code=response_data['status'],\n                headers=response_data['headers'],\n                media_type=\"application/json\"\n            )\n    \n    async def _process_mock_response(self, mock: Dict[str, Any], request: Request):\n        \"\"\"Process and generate mock response\"\"\"\n        # Check for conditional responses\n        if mock.get('conditions'):\n            for condition in mock['conditions']:\n                if self._evaluate_condition(condition, request):\n                    return await self._generate_response(condition['response'], request)\n        \n        # Use default response\n        return await self._generate_response(mock['response'], request)\n    \n    def _generate_response(self, response_template: Dict[str, Any], request: Request):\n        \"\"\"Generate response from template\"\"\"\n        response = {\n            'status': response_template.get('status', 200),\n            'headers': response_template.get('headers', {}),\n            'body': self._process_response_body(response_template['body'], request)\n        }\n        \n        # Apply response transformations\n        if response_template.get('transformations'):\n            response = self._apply_transformations(response, response_template['transformations'])\n        \n        return response\n```\n\n### 2. Request/Response Stubbing\n\nImplement flexible stubbing system:\n\n**Stubbing Engine**\n```python\nclass StubbingEngine:\n    def __init__(self):\n        self.stubs = {}\n        self.matchers = self._initialize_matchers()\n        \n    def create_stub(self, method: str, path: str, **kwargs):\n        \"\"\"Create a new stub\"\"\"\n        stub_id = self._generate_stub_id()\n        \n        stub = {\n            'id': stub_id,\n            'method': method,\n            'path': path,\n            'matchers': self._build_matchers(kwargs),\n            'response': kwargs.get('response', {}),\n            'priority': kwargs.get('priority', 0),\n            'times': kwargs.get('times', -1),  # -1 for unlimited\n            'delay': kwargs.get('delay', 0),\n            'scenario': kwargs.get('scenario', 'default')\n        }\n        \n        self.stubs[stub_id] = stub\n        return stub_id\n    \n    def _build_matchers(self, kwargs):\n        \"\"\"Build request matchers\"\"\"\n        matchers = []\n        \n        # Path parameter matching\n        if 'path_params' in kwargs:\n            matchers.append({\n                'type': 'path_params',\n                'params': kwargs['path_params']\n            })\n        \n        # Query parameter matching\n        if 'query_params' in kwargs:\n            matchers.append({\n                'type': 'query_params',\n                'params': kwargs['query_params']\n            })\n        \n        # Header matching\n        if 'headers' in kwargs:\n            matchers.append({\n                'type': 'headers',\n                'headers': kwargs['headers']\n            })\n        \n        # Body matching\n        if 'body' in kwargs:\n            matchers.append({\n                'type': 'body',\n                'body': kwargs['body'],\n                'match_type': kwargs.get('body_match_type', 'exact')\n            })\n        \n        return matchers\n    \n    def match_request(self, request: Dict[str, Any]):\n        \"\"\"Find matching stub for request\"\"\"\n        candidates = []\n        \n        for stub in self.stubs.values():\n            if self._matches_stub(request, stub):\n                candidates.append(stub)\n        \n        # Sort by priority and return best match\n        if candidates:\n            return sorted(candidates, key=lambda x: x['priority'], reverse=True)[0]\n        \n        return None\n    \n    def _matches_stub(self, request: Dict[str, Any], stub: Dict[str, Any]):\n        \"\"\"Check if request matches stub\"\"\"\n        # Check method\n        if request['method'] != stub['method']:\n            return False\n        \n        # Check path\n        if not self._matches_path(request['path'], stub['path']):\n            return False\n        \n        # Check all matchers\n        for matcher in stub['matchers']:\n            if not self._evaluate_matcher(request, matcher):\n                return False\n        \n        # Check if stub is still valid\n        if stub['times'] == 0:\n            return False\n        \n        return True\n    \n    def create_dynamic_stub(self):\n        \"\"\"Create dynamic stub with callbacks\"\"\"\n        return '''\nclass DynamicStub:\n    def __init__(self, path_pattern: str):\n        self.path_pattern = path_pattern\n        self.response_generator = None\n        self.state_modifier = None\n        \n    def with_response_generator(self, generator):\n        \"\"\"Set dynamic response generator\"\"\"\n        self.response_generator = generator\n        return self\n    \n    def with_state_modifier(self, modifier):\n        \"\"\"Set state modification callback\"\"\"\n        self.state_modifier = modifier\n        return self\n    \n    async def process_request(self, request: Request, state: Dict[str, Any]):\n        \"\"\"Process request dynamically\"\"\"\n        # Extract request data\n        request_data = {\n            'method': request.method,\n            'path': request.url.path,\n            'headers': dict(request.headers),\n            'query_params': dict(request.query_params),\n            'body': await request.json() if request.method in ['POST', 'PUT'] else None\n        }\n        \n        # Modify state if needed\n        if self.state_modifier:\n            state = self.state_modifier(state, request_data)\n        \n        # Generate response\n        if self.response_generator:\n            response = self.response_generator(request_data, state)\n        else:\n            response = {'status': 200, 'body': {}}\n        \n        return response, state\n\n# Usage example\ndynamic_stub = DynamicStub('/api/users/{user_id}')\ndynamic_stub.with_response_generator(lambda req, state: {\n    'status': 200,\n    'body': {\n        'id': req['path_params']['user_id'],\n        'name': state.get('users', {}).get(req['path_params']['user_id'], 'Unknown'),\n        'request_count': state.get('request_count', 0)\n    }\n}).with_state_modifier(lambda state, req: {\n    **state,\n    'request_count': state.get('request_count', 0) + 1\n})\n'''\n```\n\n### 3. Dynamic Data Generation\n\nGenerate realistic mock data:\n\n**Mock Data Generator**\n```python\nfrom faker import Faker\nimport random\nfrom datetime import datetime, timedelta\n\nclass MockDataGenerator:\n    def __init__(self):\n        self.faker = Faker()\n        self.templates = {}\n        self.generators = self._init_generators()\n        \n    def generate_data(self, schema: Dict[str, Any]):\n        \"\"\"Generate data based on schema\"\"\"\n        if isinstance(schema, dict):\n            if '$ref' in schema:\n                # Reference to another schema\n                return self.generate_data(self.resolve_ref(schema['$ref']))\n            \n            result = {}\n            for key, value in schema.items():\n                if key.startswith('$'):\n                    continue\n                result[key] = self._generate_field(value)\n            return result\n        \n        elif isinstance(schema, list):\n            # Generate array\n            count = random.randint(1, 10)\n            return [self.generate_data(schema[0]) for _ in range(count)]\n        \n        else:\n            return schema\n    \n    def _generate_field(self, field_schema: Dict[str, Any]):\n        \"\"\"Generate field value based on schema\"\"\"\n        field_type = field_schema.get('type', 'string')\n        \n        # Check for custom generator\n        if 'generator' in field_schema:\n            return self._use_custom_generator(field_schema['generator'])\n        \n        # Check for enum\n        if 'enum' in field_schema:\n            return random.choice(field_schema['enum'])\n        \n        # Generate based on type\n        generators = {\n            'string': self._generate_string,\n            'number': self._generate_number,\n            'integer': self._generate_integer,\n            'boolean': self._generate_boolean,\n            'array': self._generate_array,\n            'object': lambda s: self.generate_data(s)\n        }\n        \n        generator = generators.get(field_type, self._generate_string)\n        return generator(field_schema)\n    \n    def _generate_string(self, schema: Dict[str, Any]):\n        \"\"\"Generate string value\"\"\"\n        # Check for format\n        format_type = schema.get('format', '')\n        \n        format_generators = {\n            'email': self.faker.email,\n            'name': self.faker.name,\n            'first_name': self.faker.first_name,\n            'last_name': self.faker.last_name,\n            'phone': self.faker.phone_number,\n            'address': self.faker.address,\n            'url': self.faker.url,\n            'uuid': self.faker.uuid4,\n            'date': lambda: self.faker.date().isoformat(),\n            'datetime': lambda: self.faker.date_time().isoformat(),\n            'password': lambda: self.faker.password()\n        }\n        \n        if format_type in format_generators:\n            return format_generators[format_type]()\n        \n        # Check for pattern\n        if 'pattern' in schema:\n            return self._generate_from_pattern(schema['pattern'])\n        \n        # Default string generation\n        min_length = schema.get('minLength', 5)\n        max_length = schema.get('maxLength', 20)\n        return self.faker.text(max_nb_chars=random.randint(min_length, max_length))\n    \n    def create_data_templates(self):\n        \"\"\"Create reusable data templates\"\"\"\n        return {\n            'user': {\n                'id': {'type': 'string', 'format': 'uuid'},\n                'username': {'type': 'string', 'generator': 'username'},\n                'email': {'type': 'string', 'format': 'email'},\n                'profile': {\n                    'type': 'object',\n                    'properties': {\n                        'firstName': {'type': 'string', 'format': 'first_name'},\n                        'lastName': {'type': 'string', 'format': 'last_name'},\n                        'avatar': {'type': 'string', 'format': 'url'},\n                        'bio': {'type': 'string', 'maxLength': 200}\n                    }\n                },\n                'createdAt': {'type': 'string', 'format': 'datetime'},\n                'status': {'type': 'string', 'enum': ['active', 'inactive', 'suspended']}\n            },\n            'product': {\n                'id': {'type': 'string', 'format': 'uuid'},\n                'name': {'type': 'string', 'generator': 'product_name'},\n                'description': {'type': 'string', 'maxLength': 500},\n                'price': {'type': 'number', 'minimum': 0.01, 'maximum': 9999.99},\n                'category': {'type': 'string', 'enum': ['electronics', 'clothing', 'food', 'books']},\n                'inStock': {'type': 'boolean'},\n                'rating': {'type': 'number', 'minimum': 0, 'maximum': 5}\n            }\n        }\n    \n    def generate_relational_data(self):\n        \"\"\"Generate data with relationships\"\"\"\n        return '''\nclass RelationalDataGenerator:\n    def generate_related_entities(self, schema: Dict[str, Any], count: int):\n        \"\"\"Generate related entities maintaining referential integrity\"\"\"\n        entities = {}\n        \n        # First pass: generate primary entities\n        for entity_name, entity_schema in schema['entities'].items():\n            entities[entity_name] = []\n            for i in range(count):\n                entity = self.generate_entity(entity_schema)\n                entity['id'] = f\"{entity_name}_{i}\"\n                entities[entity_name].append(entity)\n        \n        # Second pass: establish relationships\n        for relationship in schema.get('relationships', []):\n            self.establish_relationship(entities, relationship)\n        \n        return entities\n    \n    def establish_relationship(self, entities: Dict[str, List], relationship: Dict):\n        \"\"\"Establish relationships between entities\"\"\"\n        source = relationship['source']\n        target = relationship['target']\n        rel_type = relationship['type']\n        \n        if rel_type == 'one-to-many':\n            for source_entity in entities[source['entity']]:\n                # Select random targets\n                num_targets = random.randint(1, 5)\n                target_refs = random.sample(\n                    entities[target['entity']], \n                    min(num_targets, len(entities[target['entity']]))\n                )\n                source_entity[source['field']] = [t['id'] for t in target_refs]\n        \n        elif rel_type == 'many-to-one':\n            for target_entity in entities[target['entity']]:\n                # Select one source\n                source_ref = random.choice(entities[source['entity']])\n                target_entity[target['field']] = source_ref['id']\n'''\n```\n\n### 4. Mock Scenarios\n\nImplement scenario-based mocking:\n\n**Scenario Manager**\n```python\nclass ScenarioManager:\n    def __init__(self):\n        self.scenarios = {}\n        self.current_scenario = 'default'\n        self.scenario_states = {}\n        \n    def define_scenario(self, name: str, definition: Dict[str, Any]):\n        \"\"\"Define a mock scenario\"\"\"\n        self.scenarios[name] = {\n            'name': name,\n            'description': definition.get('description', ''),\n            'initial_state': definition.get('initial_state', {}),\n            'stubs': definition.get('stubs', []),\n            'sequences': definition.get('sequences', []),\n            'conditions': definition.get('conditions', [])\n        }\n    \n    def create_test_scenarios(self):\n        \"\"\"Create common test scenarios\"\"\"\n        return {\n            'happy_path': {\n                'description': 'All operations succeed',\n                'stubs': [\n                    {\n                        'path': '/api/auth/login',\n                        'response': {\n                            'status': 200,\n                            'body': {\n                                'token': 'valid_token',\n                                'user': {'id': '123', 'name': 'Test User'}\n                            }\n                        }\n                    },\n                    {\n                        'path': '/api/users/{id}',\n                        'response': {\n                            'status': 200,\n                            'body': {\n                                'id': '{id}',\n                                'name': 'Test User',\n                                'email': 'test@example.com'\n                            }\n                        }\n                    }\n                ]\n            },\n            'error_scenario': {\n                'description': 'Various error conditions',\n                'sequences': [\n                    {\n                        'name': 'rate_limiting',\n                        'steps': [\n                            {'repeat': 5, 'response': {'status': 200}},\n                            {'repeat': 10, 'response': {'status': 429, 'body': {'error': 'Rate limit exceeded'}}}\n                        ]\n                    }\n                ],\n                'stubs': [\n                    {\n                        'path': '/api/auth/login',\n                        'conditions': [\n                            {\n                                'match': {'body': {'username': 'locked_user'}},\n                                'response': {'status': 423, 'body': {'error': 'Account locked'}}\n                            }\n                        ]\n                    }\n                ]\n            },\n            'degraded_performance': {\n                'description': 'Slow responses and timeouts',\n                'stubs': [\n                    {\n                        'path': '/api/*',\n                        'delay': 5000,  # 5 second delay\n                        'response': {'status': 200}\n                    }\n                ]\n            }\n        }\n    \n    def execute_scenario_sequence(self):\n        \"\"\"Execute scenario sequences\"\"\"\n        return '''\nclass SequenceExecutor:\n    def __init__(self):\n        self.sequence_states = {}\n        \n    def get_sequence_response(self, sequence_name: str, request: Dict):\n        \"\"\"Get response based on sequence state\"\"\"\n        if sequence_name not in self.sequence_states:\n            self.sequence_states[sequence_name] = {'step': 0, 'count': 0}\n        \n        state = self.sequence_states[sequence_name]\n        sequence = self.get_sequence_definition(sequence_name)\n        \n        # Get current step\n        current_step = sequence['steps'][state['step']]\n        \n        # Check if we should advance to next step\n        state['count'] += 1\n        if state['count'] >= current_step.get('repeat', 1):\n            state['step'] = (state['step'] + 1) % len(sequence['steps'])\n            state['count'] = 0\n        \n        return current_step['response']\n    \n    def create_stateful_scenario(self):\n        \"\"\"Create scenario with stateful behavior\"\"\"\n        return {\n            'shopping_cart': {\n                'initial_state': {\n                    'cart': {},\n                    'total': 0\n                },\n                'stubs': [\n                    {\n                        'method': 'POST',\n                        'path': '/api/cart/items',\n                        'handler': 'add_to_cart',\n                        'modifies_state': True\n                    },\n                    {\n                        'method': 'GET',\n                        'path': '/api/cart',\n                        'handler': 'get_cart',\n                        'uses_state': True\n                    }\n                ],\n                'handlers': {\n                    'add_to_cart': lambda state, request: {\n                        'state': {\n                            **state,\n                            'cart': {\n                                **state['cart'],\n                                request['body']['product_id']: request['body']['quantity']\n                            },\n                            'total': state['total'] + request['body']['price']\n                        },\n                        'response': {\n                            'status': 201,\n                            'body': {'message': 'Item added to cart'}\n                        }\n                    },\n                    'get_cart': lambda state, request: {\n                        'response': {\n                            'status': 200,\n                            'body': {\n                                'items': state['cart'],\n                                'total': state['total']\n                            }\n                        }\n                    }\n                }\n            }\n        }\n'''\n```\n\n### 5. Contract Testing\n\nImplement contract-based mocking:\n\n**Contract Testing Framework**\n```python\nclass ContractMockServer:\n    def __init__(self):\n        self.contracts = {}\n        self.validators = self._init_validators()\n        \n    def load_contract(self, contract_path: str):\n        \"\"\"Load API contract (OpenAPI, AsyncAPI, etc.)\"\"\"\n        with open(contract_path, 'r') as f:\n            contract = yaml.safe_load(f)\n        \n        # Parse contract\n        self.contracts[contract['info']['title']] = {\n            'spec': contract,\n            'endpoints': self._parse_endpoints(contract),\n            'schemas': self._parse_schemas(contract)\n        }\n    \n    def generate_mocks_from_contract(self, contract_name: str):\n        \"\"\"Generate mocks from contract specification\"\"\"\n        contract = self.contracts[contract_name]\n        mocks = []\n        \n        for path, methods in contract['endpoints'].items():\n            for method, spec in methods.items():\n                mock = self._create_mock_from_spec(path, method, spec)\n                mocks.append(mock)\n        \n        return mocks\n    \n    def _create_mock_from_spec(self, path: str, method: str, spec: Dict):\n        \"\"\"Create mock from endpoint specification\"\"\"\n        mock = {\n            'method': method.upper(),\n            'path': self._convert_path_to_pattern(path),\n            'responses': {}\n        }\n        \n        # Generate responses for each status code\n        for status_code, response_spec in spec.get('responses', {}).items():\n            mock['responses'][status_code] = {\n                'status': int(status_code),\n                'headers': self._get_response_headers(response_spec),\n                'body': self._generate_response_body(response_spec)\n            }\n        \n        # Add request validation\n        if 'requestBody' in spec:\n            mock['request_validation'] = self._create_request_validator(spec['requestBody'])\n        \n        return mock\n    \n    def validate_against_contract(self):\n        \"\"\"Validate mock responses against contract\"\"\"\n        return '''\nclass ContractValidator:\n    def validate_response(self, contract_spec, actual_response):\n        \"\"\"Validate response against contract\"\"\"\n        validation_results = {\n            'valid': True,\n            'errors': []\n        }\n        \n        # Find response spec for status code\n        response_spec = contract_spec['responses'].get(\n            str(actual_response['status']),\n            contract_spec['responses'].get('default')\n        )\n        \n        if not response_spec:\n            validation_results['errors'].append({\n                'type': 'unexpected_status',\n                'message': f\"Status {actual_response['status']} not defined in contract\"\n            })\n            validation_results['valid'] = False\n            return validation_results\n        \n        # Validate headers\n        if 'headers' in response_spec:\n            header_errors = self.validate_headers(\n                response_spec['headers'],\n                actual_response['headers']\n            )\n            validation_results['errors'].extend(header_errors)\n        \n        # Validate body schema\n        if 'content' in response_spec:\n            body_errors = self.validate_body(\n                response_spec['content'],\n                actual_response['body']\n            )\n            validation_results['errors'].extend(body_errors)\n        \n        validation_results['valid'] = len(validation_results['errors']) == 0\n        return validation_results\n    \n    def validate_body(self, content_spec, actual_body):\n        \"\"\"Validate response body against schema\"\"\"\n        errors = []\n        \n        # Get schema for content type\n        schema = content_spec.get('application/json', {}).get('schema')\n        if not schema:\n            return errors\n        \n        # Validate against JSON schema\n        try:\n            validate(instance=actual_body, schema=schema)\n        except ValidationError as e:\n            errors.append({\n                'type': 'schema_validation',\n                'path': e.json_path,\n                'message': e.message\n            })\n        \n        return errors\n'''\n```\n\n### 6. Performance Testing\n\nCreate performance testing mocks:\n\n**Performance Mock Server**\n```python\nclass PerformanceMockServer:\n    def __init__(self):\n        self.performance_profiles = {}\n        self.metrics_collector = MetricsCollector()\n        \n    def create_performance_profile(self, name: str, config: Dict):\n        \"\"\"Create performance testing profile\"\"\"\n        self.performance_profiles[name] = {\n            'latency': config.get('latency', {'min': 10, 'max': 100}),\n            'throughput': config.get('throughput', 1000),  # requests per second\n            'error_rate': config.get('error_rate', 0.01),  # 1% errors\n            'response_size': config.get('response_size', {'min': 100, 'max': 10000})\n        }\n    \n    async def simulate_performance(self, profile_name: str, request: Request):\n        \"\"\"Simulate performance characteristics\"\"\"\n        profile = self.performance_profiles[profile_name]\n        \n        # Simulate latency\n        latency = random.uniform(profile['latency']['min'], profile['latency']['max'])\n        await asyncio.sleep(latency / 1000)\n        \n        # Simulate errors\n        if random.random() < profile['error_rate']:\n            return self._generate_error_response()\n        \n        # Generate response with specified size\n        response_size = random.randint(\n            profile['response_size']['min'],\n            profile['response_size']['max']\n        )\n        \n        response_data = self._generate_data_of_size(response_size)\n        \n        # Track metrics\n        self.metrics_collector.record({\n            'latency': latency,\n            'response_size': response_size,\n            'timestamp': datetime.now()\n        })\n        \n        return response_data\n    \n    def create_load_test_scenarios(self):\n        \"\"\"Create load testing scenarios\"\"\"\n        return {\n            'gradual_load': {\n                'description': 'Gradually increase load',\n                'stages': [\n                    {'duration': 60, 'target_rps': 100},\n                    {'duration': 120, 'target_rps': 500},\n                    {'duration': 180, 'target_rps': 1000},\n                    {'duration': 60, 'target_rps': 100}\n                ]\n            },\n            'spike_test': {\n                'description': 'Sudden spike in traffic',\n                'stages': [\n                    {'duration': 60, 'target_rps': 100},\n                    {'duration': 10, 'target_rps': 5000},\n                    {'duration': 60, 'target_rps': 100}\n                ]\n            },\n            'stress_test': {\n                'description': 'Find breaking point',\n                'stages': [\n                    {'duration': 60, 'target_rps': 100},\n                    {'duration': 60, 'target_rps': 500},\n                    {'duration': 60, 'target_rps': 1000},\n                    {'duration': 60, 'target_rps': 2000},\n                    {'duration': 60, 'target_rps': 5000},\n                    {'duration': 60, 'target_rps': 10000}\n                ]\n            }\n        }\n    \n    def implement_throttling(self):\n        \"\"\"Implement request throttling\"\"\"\n        return '''\nclass ThrottlingMiddleware:\n    def __init__(self, max_rps: int):\n        self.max_rps = max_rps\n        self.request_times = deque()\n        \n    async def __call__(self, request: Request, call_next):\n        current_time = time.time()\n        \n        # Remove old requests\n        while self.request_times and self.request_times[0] < current_time - 1:\n            self.request_times.popleft()\n        \n        # Check if we're over limit\n        if len(self.request_times) >= self.max_rps:\n            return Response(\n                content=json.dumps({\n                    'error': 'Rate limit exceeded',\n                    'retry_after': 1\n                }),\n                status_code=429,\n                headers={'Retry-After': '1'}\n            )\n        \n        # Record this request\n        self.request_times.append(current_time)\n        \n        # Process request\n        response = await call_next(request)\n        return response\n'''\n```\n\n### 7. Mock Data Management\n\nManage mock data effectively:\n\n**Mock Data Store**\n```python\nclass MockDataStore:\n    def __init__(self):\n        self.collections = {}\n        self.indexes = {}\n        \n    def create_collection(self, name: str, schema: Dict = None):\n        \"\"\"Create a new data collection\"\"\"\n        self.collections[name] = {\n            'data': {},\n            'schema': schema,\n            'counter': 0\n        }\n        \n        # Create default index on 'id'\n        self.create_index(name, 'id')\n    \n    def insert(self, collection: str, data: Dict):\n        \"\"\"Insert data into collection\"\"\"\n        collection_data = self.collections[collection]\n        \n        # Validate against schema if exists\n        if collection_data['schema']:\n            self._validate_data(data, collection_data['schema'])\n        \n        # Generate ID if not provided\n        if 'id' not in data:\n            collection_data['counter'] += 1\n            data['id'] = str(collection_data['counter'])\n        \n        # Store data\n        collection_data['data'][data['id']] = data\n        \n        # Update indexes\n        self._update_indexes(collection, data)\n        \n        return data['id']\n    \n    def query(self, collection: str, filters: Dict = None):\n        \"\"\"Query collection with filters\"\"\"\n        collection_data = self.collections[collection]['data']\n        \n        if not filters:\n            return list(collection_data.values())\n        \n        # Use indexes if available\n        if self._can_use_index(collection, filters):\n            return self._query_with_index(collection, filters)\n        \n        # Full scan\n        results = []\n        for item in collection_data.values():\n            if self._matches_filters(item, filters):\n                results.append(item)\n        \n        return results\n    \n    def create_relationships(self):\n        \"\"\"Define relationships between collections\"\"\"\n        return '''\nclass RelationshipManager:\n    def __init__(self, data_store: MockDataStore):\n        self.store = data_store\n        self.relationships = {}\n        \n    def define_relationship(self, \n                          source_collection: str,\n                          target_collection: str,\n                          relationship_type: str,\n                          foreign_key: str):\n        \"\"\"Define relationship between collections\"\"\"\n        self.relationships[f\"{source_collection}->{target_collection}\"] = {\n            'type': relationship_type,\n            'source': source_collection,\n            'target': target_collection,\n            'foreign_key': foreign_key\n        }\n    \n    def populate_related_data(self, entity: Dict, collection: str, depth: int = 1):\n        \"\"\"Populate related data for entity\"\"\"\n        if depth <= 0:\n            return entity\n        \n        # Find relationships for this collection\n        for rel_key, rel in self.relationships.items():\n            if rel['source'] == collection:\n                # Get related data\n                foreign_id = entity.get(rel['foreign_key'])\n                if foreign_id:\n                    related = self.store.get(rel['target'], foreign_id)\n                    if related:\n                        # Recursively populate\n                        related = self.populate_related_data(\n                            related, \n                            rel['target'], \n                            depth - 1\n                        )\n                        entity[rel['target']] = related\n        \n        return entity\n    \n    def cascade_operations(self, operation: str, collection: str, entity_id: str):\n        \"\"\"Handle cascade operations\"\"\"\n        if operation == 'delete':\n            # Find dependent relationships\n            for rel in self.relationships.values():\n                if rel['target'] == collection:\n                    # Delete dependent entities\n                    dependents = self.store.query(\n                        rel['source'],\n                        {rel['foreign_key']: entity_id}\n                    )\n                    for dep in dependents:\n                        self.store.delete(rel['source'], dep['id'])\n'''\n```\n\n### 8. Testing Framework Integration\n\nIntegrate with popular testing frameworks:\n\n**Testing Integration**\n```python\nclass TestingFrameworkIntegration:\n    def create_jest_integration(self):\n        \"\"\"Jest testing integration\"\"\"\n        return '''\n// jest.mock.config.js\nimport { MockServer } from './mockServer';\n\nconst mockServer = new MockServer();\n\nbeforeAll(async () => {\n    await mockServer.start({ port: 3001 });\n    \n    // Load mock definitions\n    await mockServer.loadMocks('./mocks/*.json');\n    \n    // Set default scenario\n    await mockServer.setScenario('test');\n});\n\nafterAll(async () => {\n    await mockServer.stop();\n});\n\nbeforeEach(async () => {\n    // Reset mock state\n    await mockServer.reset();\n});\n\n// Test helper functions\nexport const setupMock = async (stub) => {\n    return await mockServer.addStub(stub);\n};\n\nexport const verifyRequests = async (matcher) => {\n    const requests = await mockServer.getRequests(matcher);\n    return requests;\n};\n\n// Example test\ndescribe('User API', () => {\n    it('should fetch user details', async () => {\n        // Setup mock\n        await setupMock({\n            method: 'GET',\n            path: '/api/users/123',\n            response: {\n                status: 200,\n                body: { id: '123', name: 'Test User' }\n            }\n        });\n        \n        // Make request\n        const response = await fetch('http://localhost:3001/api/users/123');\n        const user = await response.json();\n        \n        // Verify\n        expect(user.name).toBe('Test User');\n        \n        // Verify mock was called\n        const requests = await verifyRequests({ path: '/api/users/123' });\n        expect(requests).toHaveLength(1);\n    });\n});\n'''\n    \n    def create_pytest_integration(self):\n        \"\"\"Pytest integration\"\"\"\n        return '''\n# conftest.py\nimport pytest\nfrom mock_server import MockServer\nimport asyncio\n\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    loop = asyncio.get_event_loop_policy().new_event_loop()\n    yield loop\n    loop.close()\n\n@pytest.fixture(scope=\"session\")\nasync def mock_server(event_loop):\n    server = MockServer()\n    await server.start(port=3001)\n    yield server\n    await server.stop()\n\n@pytest.fixture(autouse=True)\nasync def reset_mocks(mock_server):\n    await mock_server.reset()\n    yield\n    # Verify no unexpected calls\n    unmatched = await mock_server.get_unmatched_requests()\n    assert len(unmatched) == 0, f\"Unmatched requests: {unmatched}\"\n\n# Test utilities\nclass MockBuilder:\n    def __init__(self, mock_server):\n        self.server = mock_server\n        self.stubs = []\n    \n    def when(self, method, path):\n        self.current_stub = {\n            'method': method,\n            'path': path\n        }\n        return self\n    \n    def with_body(self, body):\n        self.current_stub['body'] = body\n        return self\n    \n    def then_return(self, status, body=None, headers=None):\n        self.current_stub['response'] = {\n            'status': status,\n            'body': body,\n            'headers': headers or {}\n        }\n        self.stubs.append(self.current_stub)\n        return self\n    \n    async def setup(self):\n        for stub in self.stubs:\n            await self.server.add_stub(stub)\n\n# Example test\n@pytest.mark.asyncio\nasync def test_user_creation(mock_server):\n    # Setup mocks\n    mock = MockBuilder(mock_server)\n    mock.when('POST', '/api/users') \\\n        .with_body({'name': 'New User'}) \\\n        .then_return(201, {'id': '456', 'name': 'New User'})\n    \n    await mock.setup()\n    \n    # Test code here\n    response = await create_user({'name': 'New User'})\n    assert response['id'] == '456'\n'''\n```\n\n### 9. Mock Server Deployment\n\nDeploy mock servers:\n\n**Deployment Configuration**\n```yaml\n# docker-compose.yml for mock services\nversion: '3.8'\n\nservices:\n  mock-api:\n    build:\n      context: .\n      dockerfile: Dockerfile.mock\n    ports:\n      - \"3001:3001\"\n    environment:\n      - MOCK_SCENARIO=production\n      - MOCK_DATA_PATH=/data/mocks\n    volumes:\n      - ./mocks:/data/mocks\n      - ./scenarios:/data/scenarios\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3001/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  mock-admin:\n    build:\n      context: .\n      dockerfile: Dockerfile.admin\n    ports:\n      - \"3002:3002\"\n    environment:\n      - MOCK_SERVER_URL=http://mock-api:3001\n    depends_on:\n      - mock-api\n\n# Kubernetes deployment\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mock-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: mock-server\n  template:\n    metadata:\n      labels:\n        app: mock-server\n    spec:\n      containers:\n      - name: mock-server\n        image: mock-server:latest\n        ports:\n        - containerPort: 3001\n        env:\n        - name: MOCK_SCENARIO\n          valueFrom:\n            configMapKeyRef:\n              name: mock-config\n              key: scenario\n        volumeMounts:\n        - name: mock-definitions\n          mountPath: /data/mocks\n      volumes:\n      - name: mock-definitions\n        configMap:\n          name: mock-definitions\n```\n\n### 10. Mock Documentation\n\nGenerate mock API documentation:\n\n**Documentation Generator**\n```python\nclass MockDocumentationGenerator:\n    def generate_documentation(self, mock_server):\n        \"\"\"Generate comprehensive mock documentation\"\"\"\n        return f\"\"\"\n# Mock API Documentation\n\n## Overview\n{self._generate_overview(mock_server)}\n\n## Available Endpoints\n{self._generate_endpoints_doc(mock_server)}\n\n## Scenarios\n{self._generate_scenarios_doc(mock_server)}\n\n## Data Models\n{self._generate_models_doc(mock_server)}\n\n## Usage Examples\n{self._generate_examples(mock_server)}\n\n## Configuration\n{self._generate_config_doc(mock_server)}\n\"\"\"\n    \n    def _generate_endpoints_doc(self, mock_server):\n        \"\"\"Generate endpoint documentation\"\"\"\n        doc = \"\"\n        for endpoint in mock_server.get_endpoints():\n            doc += f\"\"\"\n### {endpoint['method']} {endpoint['path']}\n\n**Description**: {endpoint.get('description', 'No description')}\n\n**Request**:\n```json\n{json.dumps(endpoint.get('request_example', {}), indent=2)}\n```\n\n**Response**:\n```json\n{json.dumps(endpoint.get('response_example', {}), indent=2)}\n```\n\n**Scenarios**:\n{self._format_endpoint_scenarios(endpoint)}\n\"\"\"\n        return doc\n    \n    def create_interactive_docs(self):\n        \"\"\"Create interactive API documentation\"\"\"\n        return '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Mock API Interactive Documentation</title>\n    <script src=\"https://unpkg.com/swagger-ui-dist/swagger-ui-bundle.js\"></script>\n    <link rel=\"stylesheet\" href=\"https://unpkg.com/swagger-ui-dist/swagger-ui.css\">\n</head>\n<body>\n    <div id=\"swagger-ui\"></div>\n    <script>\n        window.onload = function() {\n            const ui = SwaggerUIBundle({\n                url: \"/api/mock/openapi.json\",\n                dom_id: '#swagger-ui',\n                presets: [\n                    SwaggerUIBundle.presets.apis,\n                    SwaggerUIBundle.SwaggerUIStandalonePreset\n                ],\n                layout: \"BaseLayout\",\n                tryItOutEnabled: true,\n                requestInterceptor: (request) => {\n                    request.headers['X-Mock-Scenario'] = \n                        document.getElementById('scenario-select').value;\n                    return request;\n                }\n            });\n        }\n    </script>\n    \n    <div class=\"scenario-selector\">\n        <label>Scenario:</label>\n        <select id=\"scenario-select\">\n            <option value=\"default\">Default</option>\n            <option value=\"error\">Error Conditions</option>\n            <option value=\"slow\">Slow Responses</option>\n        </select>\n    </div>\n</body>\n</html>\n'''\n```\n\n## Output Format\n\n1. **Mock Server Setup**: Complete mock server implementation\n2. **Stubbing Configuration**: Flexible request/response stubbing\n3. **Data Generation**: Realistic mock data generation\n4. **Scenario Definitions**: Comprehensive test scenarios\n5. **Contract Testing**: Contract-based mock validation\n6. **Performance Simulation**: Performance testing capabilities\n7. **Data Management**: Mock data storage and relationships\n8. **Testing Integration**: Framework integration examples\n9. **Deployment Guide**: Mock server deployment configurations\n10. **Documentation**: Auto-generated mock API documentation\n\nFocus on creating flexible, realistic mock services that enable efficient development, thorough testing, and reliable API simulation for all stages of the development lifecycle."
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}