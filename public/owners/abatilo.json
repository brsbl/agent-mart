{
  "owner": {
    "id": "abatilo",
    "display_name": "Aaron Batilo",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/1634746?u=f13168335a7914b873617ea8e0f53b9c4306419a&v=4",
    "url": "https://github.com/abatilo",
    "bio": "If I don't have to do it, I won't. If I have to do it, I'll do it as quickly as possible.",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 6,
      "total_skills": 6,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "abatilo/vimrc",
      "url": "https://github.com/abatilo/vimrc",
      "description": "My personal vim settings",
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-12T21:18:04Z",
        "created_at": "2015-09-28T13:46:32Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 290
        },
        {
          "path": ".editorconfig_global",
          "type": "blob",
          "size": 399
        },
        {
          "path": ".gitconfig_global",
          "type": "blob",
          "size": 858
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 35
        },
        {
          "path": ".gitignore_global",
          "type": "blob",
          "size": 501
        },
        {
          "path": ".mise.toml",
          "type": "blob",
          "size": 30
        },
        {
          "path": ".tmux.conf",
          "type": "blob",
          "size": 868
        },
        {
          "path": ".vsnip",
          "type": "tree",
          "size": null
        },
        {
          "path": ".vsnip/yaml.json",
          "type": "blob",
          "size": 1619
        },
        {
          "path": "AGENTS_global.md",
          "type": "blob",
          "size": null
        },
        {
          "path": "CLAUDE_global.md",
          "type": "blob",
          "size": 117
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 1248
        },
        {
          "path": "claude_settings.json",
          "type": "blob",
          "size": 1798
        },
        {
          "path": "codex_config.toml",
          "type": "blob",
          "size": 559
        },
        {
          "path": "gh-dash-config.yml",
          "type": "blob",
          "size": 1428
        },
        {
          "path": "ghostty_config",
          "type": "blob",
          "size": 161
        },
        {
          "path": "install.sh",
          "type": "blob",
          "size": 3483
        },
        {
          "path": "mcps.json",
          "type": "blob",
          "size": 23
        },
        {
          "path": "nvim",
          "type": "tree",
          "size": null
        },
        {
          "path": "nvim/init.lua",
          "type": "blob",
          "size": 14371
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 136
        },
        {
          "path": "plugins/abatilo-core/CLAUDE.md",
          "type": "blob",
          "size": 1102
        },
        {
          "path": "plugins/abatilo-core/README-epic-drain.md",
          "type": "blob",
          "size": 3022
        },
        {
          "path": "plugins/abatilo-core/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/commands/CLAUDE.md",
          "type": "blob",
          "size": 327
        },
        {
          "path": "plugins/abatilo-core/commands/bd-drain.md",
          "type": "blob",
          "size": 1419
        },
        {
          "path": "plugins/abatilo-core/commands/bd-plan.md",
          "type": "blob",
          "size": 11576
        },
        {
          "path": "plugins/abatilo-core/commands/bd-sequence.md",
          "type": "blob",
          "size": 6161
        },
        {
          "path": "plugins/abatilo-core/commands/commit.md",
          "type": "blob",
          "size": 452
        },
        {
          "path": "plugins/abatilo-core/commands/interview.md",
          "type": "blob",
          "size": 727
        },
        {
          "path": "plugins/abatilo-core/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/hooks/CLAUDE.md",
          "type": "blob",
          "size": 881
        },
        {
          "path": "plugins/abatilo-core/hooks/hooks.json",
          "type": "blob",
          "size": 230
        },
        {
          "path": "plugins/abatilo-core/hooks/stop-hook.sh",
          "type": "blob",
          "size": 3092
        },
        {
          "path": "plugins/abatilo-core/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/CLAUDE.md",
          "type": "blob",
          "size": 403
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/README.md",
          "type": "blob",
          "size": 5703
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/SKILL.md",
          "type": "blob",
          "size": 3076
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references/BOUNDARIES.md",
          "type": "blob",
          "size": 17033
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references/CLI_REFERENCE.md",
          "type": "blob",
          "size": 16832
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references/DEPENDENCIES.md",
          "type": "blob",
          "size": 19670
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references/ISSUE_CREATION.md",
          "type": "blob",
          "size": 5081
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references/RESUMABILITY.md",
          "type": "blob",
          "size": 5419
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references/STATIC_DATA.md",
          "type": "blob",
          "size": 2013
        },
        {
          "path": "plugins/abatilo-core/skills/bd-issue-tracking/references/WORKFLOWS.md",
          "type": "blob",
          "size": 17123
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/SKILL.md",
          "type": "blob",
          "size": 8142
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/explanation.md",
          "type": "blob",
          "size": 19004
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/framework-overview.md",
          "type": "blob",
          "size": 11058
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/how-to-guides.md",
          "type": "blob",
          "size": 13765
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/reference.md",
          "type": "blob",
          "size": 14675
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/tutorials.md",
          "type": "blob",
          "size": 11407
        },
        {
          "path": "plugins/abatilo-core/skills/git-commit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/git-commit/SKILL.md",
          "type": "blob",
          "size": 6383
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/SKILL.md",
          "type": "blob",
          "size": 7510
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/reference/commands.md",
          "type": "blob",
          "size": 9125
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/reference/workflows.md",
          "type": "blob",
          "size": 8736
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/SKILL.md",
          "type": "blob",
          "size": 6689
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/best_practices.md",
          "type": "blob",
          "size": 16335
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/helm_reference.md",
          "type": "blob",
          "size": 14692
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/kubectl_reference.md",
          "type": "blob",
          "size": 14668
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/workflows.md",
          "type": "blob",
          "size": 14734
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore/SKILL.md",
          "type": "blob",
          "size": 4675
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore/update-reference.md",
          "type": "blob",
          "size": 5254
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore/version-detection.md",
          "type": "blob",
          "size": 5846
        },
        {
          "path": "rules",
          "type": "tree",
          "size": null
        },
        {
          "path": "rules/issue-tracking.md",
          "type": "blob",
          "size": 1148
        },
        {
          "path": "tmux.sh",
          "type": "blob",
          "size": 344
        }
      ],
      "marketplace": {
        "name": "abatilo-plugins",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "abatilo"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "abatilo-core",
            "description": "Core commands, skills, and hooks for abatilo's Claude Code setup",
            "source": "./plugins/abatilo-core",
            "category": null,
            "version": "0.2.3",
            "author": null,
            "install_commands": [
              "/plugin marketplace add abatilo/vimrc",
              "/plugin install abatilo-core@abatilo-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T21:18:04Z",
              "created_at": "2015-09-28T13:46:32Z",
              "license": null
            },
            "commands": [
              {
                "name": "/CLAUDE",
                "description": null,
                "path": "plugins/abatilo-core/commands/CLAUDE.md",
                "frontmatter": null,
                "content": "# Commands Directory\n\nFiles here define slash commands (e.g., `/bd-plan`, `/git-commit`).\n\n## Before committing changes\n\n**Bump the plugin version.** See `../CLAUDE.md` for the checklist.\n\nQuick reminder:\n- Adding a command → bump MINOR\n- Modifying a command → bump PATCH\n- Update both `plugin.json` and `marketplace.json`\n"
              },
              {
                "name": "/bd-drain",
                "description": "Start draining all ready bd epics",
                "path": "plugins/abatilo-core/commands/bd-drain.md",
                "frontmatter": {
                  "description": "Start draining all ready bd epics"
                },
                "content": "# BD-Drain\n\nStart an automated loop to drain all ready bd epics. Uses bd as the single source of truth - no local state files.\n\n## Startup\n\nFirst, check for an already in-progress epic:\n\n```bash\nbd list --status=in_progress --type=epic --json\n```\n\n**If an epic is already in_progress:** Resume working on it.\n\n**If no epic is in_progress:** Check for ready epics:\n\n```bash\nbd ready --type=epic --json\n```\n\n## Logic\n\n**If no epics ready and none in_progress:** Inform the user that there are no epics to drain.\n\n**If epics ready:**\n\n1. Get the first ready epic ID from the JSON output\n2. Mark it as in_progress:\n\n```bash\nbd update <epic_id> --status=in_progress\n```\n\n3. Create a marker commit for session recovery:\n\n```bash\ngit add -A && git commit --allow-empty -m \"bd-drain-start: $(date +%Y%m%d-%H%M%S)\"\n```\n\n4. Output the prompt to start working:\n\n```\nWork on epic <epic_id>. Run 'bd show <epic_id>' to see all issues. Complete each issue in priority order: implement, test, and close. Use 'bd update <id> --status=in_progress' before starting, 'bd close <id> --reason=\"...\"' when done. Create new bd issues for any discovered bugs. Use /commit for atomic commits.\n```\n\nThe Stop hook controls the drain loop:\n- Blocks exit while issues remain open\n- Closes completed epics automatically\n- Chains to next ready epic\n- Allows exit when no more epics\n\n$ARGUMENTS"
              },
              {
                "name": "/bd-plan",
                "description": "Plan complex work with collaborative AI debate, create bd issues with dependencies",
                "path": "plugins/abatilo-core/commands/bd-plan.md",
                "frontmatter": {
                  "description": "Plan complex work with collaborative AI debate, create bd issues with dependencies",
                  "argument-hint": [
                    "optional focus area"
                  ]
                },
                "content": "# Planning Bd Issues\n\nReview the conversation history above to identify work that needs planning. Extract requirements, decisions, and context discussed—these inform the bd issues you create. If the user provided additional instructions below, incorporate those as well.\n\nThis is a two-phase process: discovery first, then planning with collaborative debate.\n\n## Phase 1: Discovery\n\nGather context from the conversation history and find verification commands.\n\n### Step 1: Verification Commands\nRun a focused Explore query to find exact development commands:\n```\nFind the ACTUAL commands used in this project for verification. Search in order:\n1. mise.toml / .mise.toml (mise task runner - https://github.com/jdx/mise)\n2. package.json scripts / pyproject.toml / Makefile / Justfile\n3. .github/workflows (CI jobs are authoritative)\n4. docs/CONTRIBUTING.md or README.md\n\nFor each category, report the EXACT command string:\n- Linting/formatting (e.g., `mise run lint`, `go fmt ./...`)\n- Static analysis / type checking (e.g., `mise run check`, `staticcheck ./...`, `golangci-lint run`)\n- Unit tests (e.g., `mise run test`, `go test ./...`)\n- Scoped E2E tests - run specific tests (e.g., `mise run test:e2e -- -run TestAuth`, `go test ./e2e/... -run TestAuth`)\n- Full E2E tests - run entire suite (e.g., `mise run test:e2e`, `go test ./e2e/...`)\n\nOutput format: \"CATEGORY: [exact command]\"\nStop searching a category once you find an authoritative source.\n```\n\n### Step 2: Discovery Synthesis\nConsolidate findings from conversation history into planning input:\n- **Architecture overview**: Patterns, conventions, and constraints discussed\n- **Testing setup**: Where tests live, how to run them, what coverage exists\n- **Verification commands**: From Step 1\n- **Known risks**: Edge cases and caveats identified\n\nThis synthesis becomes the input for Phase 2.\n\n## Phase 2: Planning with Collaborative Debate\n\nUse multi-round refinement for thorough planning.\n\n### Guiding Principles: Speed-of-Light Implementation\n\n**Treat planning as a minimization problem.** The goal is not to design a comprehensive solution—it's to find the smallest, fastest path to the desired outcome.\n\n- **Minimize changes**: What is the absolute minimum number of lines, files, and touch points needed? Every additional change is a potential bug, a review burden, and merge conflict risk.\n- **Minimize complexity**: Prefer boring, obvious solutions over clever ones. If two approaches work, choose the one a junior developer could understand in 5 minutes.\n- **Minimize scope**: Ruthlessly cut anything that isn't strictly required. \"Nice to have\" belongs in a separate future issue, not this plan.\n- **Minimize risk**: Favor incremental changes over big-bang rewrites. Ship something small that works over something ambitious that might not.\n\n**Ask at every decision point**: \"Is there a simpler way?\" If the answer is yes, take it.\n\n### Step 1: Initial Plan\nUse the Plan subagent with **model: \"opus\"** to design the minimum viable implementation based on discovery synthesis. The plan should answer: \"What is the smallest change that achieves the goal?\"\n\n### Step 2: Collaborative Debate (1-5 rounds, until feedback converges)\nClaude (Opus) and Codex (gpt-5.2-codex) debate back-and-forth to refine the plan. The number of rounds depends on complexity and whether feedback converges:\n\n- **Simple/straightforward plans**: 1 round may suffice if both models agree\n- **Moderate complexity**: 2-3 rounds typical\n- **Complex or contentious plans**: Up to 5 rounds if feedback doesn't converge\n\n**Round 1 - Dual Critique**:\n- **Claude (Opus)**: Review the plan through a minimization lens. For each concern: (1) Is this change actually necessary? (2) Is there a simpler alternative? (3) What can be cut or deferred? Also flag genuine gaps or risks.\n- **Codex**: Use `mcp__codex__codex` with model \"gpt-5.2-codex\":\n  ```\n  prompt: \"Review this implementation plan with a minimization mindset: [plan]. The goal is the smallest, simplest path to the outcome. For each part of the plan: (1) Is this necessary or can it be cut? (2) Is there a simpler approach? (3) What's the minimum viable version? Also list any genuine gaps or risks, with concrete mitigations.\"\n  ```\n- Synthesize both critiques. Prioritize simplification opportunities alongside risk fixes.\n- **Exit condition**: If both models agree the plan is minimal and sound, proceed to issue creation.\n\n**Round 2+ - Address & Counter** (repeat until convergence or Round 5):\n- **Claude (Opus)**: Propose revisions that make the plan simpler, not more complex. For each concern: accept and simplify, reject with rationale, or defer to a future issue. Resist adding complexity to \"fix\" problems.\n- **Codex**: Use `mcp__codex__codex` with model \"gpt-5.2-codex\":\n  ```\n  prompt: \"Claude proposes these revisions: [revisions]. Evaluate with a bias toward simplicity: (1) Does this revision add or remove complexity? (2) Is there an even simpler fix? (3) Should this concern be deferred rather than addressed now? Flag any revision that makes the plan bigger rather than smaller.\"\n  ```\n- Integrate valid counterpoints. If a fix adds more complexity than the problem warrants, defer it.\n- **Exit condition**: Feedback converges (plan is minimal, both models agree on approach).\n\n**Final Round - Consensus Check** (when exiting):\n- **Claude (Opus)**: Present the refined plan. Confirm it represents the minimum viable implementation. List what was intentionally deferred.\n- **Codex**: Use `mcp__codex__codex` with model \"gpt-5.2-codex\":\n  ```\n  prompt: \"Final minimization check: [plan]. Verify: (1) Is this the smallest possible implementation? (2) Can anything else be cut or deferred? (3) Are there any 'nice to haves' hiding as requirements? (4) Is the testing strategy proportional (not over-tested)? Approve only if the plan is truly minimal.\"\n  ```\n- If consensus: Proceed to issue creation.\n- If minor disagreement: Choose the simpler option, defer the rest.\n- If still unresolved after Round 5: Choose the approach with fewer moving parts. Document what was deferred and why.\n\n### Quality Gate\nBefore creating issues, confirm:\n- [ ] All discovered edge cases addressed or explicitly deferred with rationale\n- [ ] Error paths defined (what happens when X fails?)\n- [ ] Testing strategy covers new code\n- [ ] Trade-offs documented with reasoning\n\n### Step 3: Create Issues\n\nCreate bd issues using the bd-issue-tracking skill. Each issue must:\n1. Have clear acceptance criteria (what success looks like)\n2. Be scoped to complete in one session\n3. End with verification notes using **discovered commands** (not generic phrases):\n   ```\n   ## Verification\n   - [ ] `[discovered lint command]` passes\n   - [ ] `[discovered static analysis command]` passes\n   - [ ] `[discovered test command]` passes\n   - [ ] `[discovered scoped e2e command]` passes (if applicable)\n   ```\n   Use exact commands from Phase 1 discovery. Omit categories if no command exists.\n4. Include note: \"If implementation reveals new issues, create separate bd issues for investigation\"\n\n### Step 4: Final Verification Issue\n\nAfter creating all implementation issues, create one final bd issue to run the full test suite:\n\n1. **Create the issue**:\n   - Title: \"Run full E2E/integration test suite\"\n   - Description: Verify all changes work together by running the complete test suite\n   - Include the discovered **full E2E** command from Phase 1\n   - Acceptance criteria: All tests pass, no regressions introduced. If any tests fail, create new issues for each failure and link them to the same epic before closing this verification issue.\n\n2. **Set up dependencies**:\n   Use `bd dep add <final-issue> <implementation-issue> --type blocks` for EACH implementation issue.\n   This ensures the final verification runs only after all implementation work is complete.\n\nExample:\n```bash\n# If implementation issues are bd-001, bd-002, bd-003 and final is bd-004:\nbd dep add bd-004 bd-001 --type blocks\nbd dep add bd-004 bd-002 --type blocks\nbd dep add bd-004 bd-003 --type blocks\n```\n\n### Step 5: Create Epics\n\n**IMPORTANT**: Every planned task MUST have an epic, even simple single-issue tasks. Workflow automation depends on epic completion tracking. A simple task = one epic with one issue under it.\n\n**Goal**: Create the smallest shippable units of work. Prefer many small epics over few large ones.\n\n#### The Smallest Shippable Unit Test\nAn epic is the right size when:\n- Removing any issue would make it unshippable\n- Adding any issue would make it do two things instead of one\n- You can describe what it ships in one sentence without \"and\"\n\n#### Decomposition Checklist\nBefore finalizing epics, ask these questions:\n\n1. **File overlap test**: Do any two issues modify the same files?\n   - If YES and they're in different epics → merge epics or resequence\n   - If YES and epic is large → they belong together, but look for other splits\n\n2. **Ship independently test**: Can this epic be merged to main without the others?\n   - If NO → it's not self-contained, find the true boundary\n\n3. **Value test**: Does this epic deliver user-visible value or enable future work?\n   - If NO → it might be too granular, consider merging with dependent epic\n\n4. **Parallel work test**: Could two developers work on different epics simultaneously without conflicts?\n   - If NO → file overlap exists, resequence or merge\n\n#### Split Signals (create separate epics when you see these)\n- Different subsystems (API vs UI vs database)\n- Different risk profiles (safe refactor vs risky behavior change)\n- Natural phases (setup/infrastructure → core feature → polish)\n- Optional enhancements vs core functionality\n\n#### Anti-patterns to Avoid\n- ❌ One mega-epic containing all work\n- ❌ Epics that \"prepare\" for other epics without delivering value\n- ❌ Splitting by arbitrary issue count rather than logical boundaries\n- ❌ Epics where issues have no dependency relationship\n\nFor each epic:\n\n```bash\nbd create \"[epic name]\" --type epic --description \"$(cat <<'EOF'\n# Overview\n[Brief description of this epic's scope]\n\n# Why This Is One Epic\n[Explain the boundary: what makes this atomic and self-contained?\nWhy can't it be split further? Why doesn't it need other epics to ship?]\n\n# Implementation Issues\n- bd-xxx: [issue title]\n- bd-xxx: [issue title]\n- bd-xxx: Run verification for this epic\n\n# Files Modified\n[List primary files this epic touches—used for conflict detection]\n\n# Verification Commands\n- Lint: `[discovered lint command]`\n- Static analysis: `[discovered static analysis command]`\n- Tests: `[discovered test command]`\n- Scoped E2E: `[discovered scoped e2e command]`\n- Full E2E: `[discovered full e2e command]`\n\n# Success Criteria\n[What \"done\" looks like for this epic]\nEOF\n)\" --json\n```\n\nLink issues to their epic:\n```bash\nbd dep add bd-xxx <epic-id> --type parent-child\n# ... repeat for each issue in this epic\n```\n\nCheck progress: `bd epic status`\n\n## Handling Failures\n\nWhen discovery or planning reveals blocking issues:\n1. Create a P0 meta issue titled: \"Create plan for [blocker-topic]\"\n2. Description must include:\n   - What was blocking and why it matters\n   - Instruction to use Explore subagent for discovery\n   - Instruction to use Plan subagent to design fix\n   - Instruction to create implementation bd issues via bd-issue-tracking skill\n3. Any implementation issues spawned from meta issues are also P0\n\n$ARGUMENTS"
              },
              {
                "name": "/bd-sequence",
                "description": "Sequence bd epics to minimize merge conflicts and reduce refactor risk",
                "path": "plugins/abatilo-core/commands/bd-sequence.md",
                "frontmatter": {
                  "description": "Sequence bd epics to minimize merge conflicts and reduce refactor risk",
                  "argument-hint": [
                    "optional epic filter"
                  ]
                },
                "content": "# Sequencing Bd Epics\n\n## Overview\n\nDetermine the optimal execution order for epics to minimize merge conflicts and reduce refactor risk across the project.\n\n### Key Insight: Epic-Level Blocking Is Sufficient\n\n**When Epic A blocks Epic B, all tasks within Epic B are automatically blocked.** This transitive blocking through parent-child relationships means:\n- You only need to sequence epics, not individual tasks\n- Tasks within a blocked epic cannot be worked on until the blocking epic completes\n- Intra-epic task dependencies are assumed to already exist\n\n### Three-Phase Process\n\n1. **Discovery**: Collect all epics and map module-level dependencies.\n2. **Sequencing with Debate**: Use 2 rounds of collaborative debate to determine epic order.\n3. **Application**: Create bd dependency links between epics.\n\n---\n\n## Prerequisites\n\nBefore starting, ensure:\n- All epics have a title and description.\n- The project has a clear module structure.\n- You have access to both Claude (Haiku model) and Codex (gpt-5.1-codex-mini) for collaborative debate.\n\n---\n\n## Phase 1: Epic Discovery\n\n### Step 1.1: Gather All Epics\n\nRun these commands to collect the epic inventory:\n\n```bash\nbd epic status --json     # All epics with progress\nbd blocked --json         # Show blocked issues and their blockers\n```\n\nFor each epic, check its dependency tree:\n```bash\nbd dep tree <epic-id> --direction=both --json   # See what blocks/is blocked by this epic\n```\n\n**What you'll need for Phase 2:**\n- Complete list of epic IDs, titles, and descriptions\n- Current epic-to-epic dependency graph (from dep tree output)\n- Which modules/areas each epic touches\n\n### Step 1.2: Map Epic Module Ownership\n\nUse Explore subagent (haiku) to predict module impacts for each epic.\n\nOutput two things:\n1. **Impact Matrix**: Table with Epic ID | Affected Modules | Module Dependencies\n2. **Overlap Analysis**: Which epic pairs touch the same modules (e.g., \"OVERLAP: epic-001 and epic-002 both affect [core]\")\n\nUse existing codebase module granularity.\n\n### Step 1.3: Cross-Validate with Codex\n\nUse `mcp__codex__codex` (gpt-5.1-codex-mini) to independently verify module predictions:\n- Run `bd epic status --json` and `bd show <epic-id>` to understand epics\n- Explore codebase to predict which modules each epic modifies\n- Output: Epic ID → modules affected, plus overlaps\n\n### Step 1.4: Build the Epic Conflict Matrix\n\nConsolidate findings into a reference document:\n\n```\n**Epic Inventory:**\n\n| Epic ID   | Title              | Priority | Affected Modules |\n|-----------|--------------------|----------|------------------|\n| epic-001  | Auth Refactor      | P1       | auth, core       |\n| epic-002  | API Client         | P2       | api, core        |\n\n**Overlap Map:**\n- epic-001 + epic-002: both affect [core]\n\n**Existing Dependencies:**\n- epic-001 blocks epic-003 (from bd dep tree / bd blocked)\n\n**Consensus Points:**\n- Epics with zero overlaps can be sequenced in any order\n- Foundational epics (those with dependents) must come first\n```\n\n---\n\n## Phase 2: Sequencing with Collaborative Debate\n\n### Overview\n\nTwo rounds of debate between Claude and Codex to determine optimal epic order.\n\n### Step 2.1: Generate Initial Proposal\n\nUse Plan subagent (haiku) to propose epic sequence.\n\n**Constraints (priority order):**\n1. Honor existing `blocks` dependencies\n2. Foundational epics before dependents\n3. Same-module epics adjacent (minimize context switching)\n4. Higher priority first when constraints 1-3 allow\n\n**Output:** Numbered sequence with modules listed, plus rationale for key decisions.\n\n### Step 2.2: Debate Round 1 - Dual Critique\n\n**Claude (Haiku) Critique:**\nIdentify up to 5 concerns. For each:\n- Which epics and modules overlap\n- Risk type: hidden dependency, module conflict, priority inversion, or separation inefficiency\n- Current positions in sequence\n\n**Codex Critique:**\nUse `mcp__codex__codex` to analyze adjacent pairs:\n- Could changes in epic N+1 conflict with epic N?\n- Would reordering reduce risk?\n- Identify top 3 weakest links with reordering suggestions\n\n**Synthesis:** If 2+ suggestions propose same reordering, mark as high-priority fix.\n\n### Step 2.3: Debate Round 2 - Revise & Validate\n\n**Claude (Haiku) Revision:**\nAddress top 3 concerns only. For each move:\n- Movement: \"epic-XXX: position N → M\"\n- Which concern addressed\n- Validate: blocks dependencies still hold? modules still grouped?\n\n**Codex Validation:**\nUse `mcp__codex__codex` to verify:\n1. Module-overlap epics adjacent (PASS/FAIL)\n2. Priority order respected (PASS/FAIL)\n3. No circular dependencies (PASS/FAIL)\n\n**Synthesis:**\n- If all PASS → proceed to Phase 3\n- If FAIL → use fallback order: foundational → shared-module → feature → polish epics\n\n### Quality Gate\n\nBefore proceeding to Phase 3:\n\n- [ ] No circular dependencies in the proposed sequence\n- [ ] All existing `blocks` dependencies are respected\n- [ ] Epics with module overlaps are adjacent\n- [ ] Codex validation passed or fallback order applied\n\n---\n\n## Phase 3: Apply Epic Dependencies\n\n### Step 3.1: Create Epic Blocking Chain\n\nFor the final epic sequence, create `blocks` dependencies:\n\n```bash\n# Example: If final sequence is epic-A → epic-B → epic-C\n\nbd dep add epic-A epic-B --type blocks  # epic-A blocks epic-B\nbd dep add epic-B epic-C --type blocks  # epic-B blocks epic-C\n```\n\n**Critical reminder:** In `bd dep add A B --type blocks`, A blocks B (A must complete before B starts).\n\n**What happens automatically:**\n- All tasks in epic-B become blocked until epic-A closes\n- All tasks in epic-C become blocked until epic-B closes\n- No need to create task-level dependencies across epics\n\n---\n\n### Step 3.2: Verification\n\n```bash\nbd ready --json           # Show ready work\nbd blocked --json         # Show blocked issues\nbd epic status --json     # Show epic blocking relationships\n```\n\n**Expected result:**\n- Tasks from the FIRST epic show as ready\n- All tasks in subsequent epics show as blocked\n- When an epic closes, tasks from the next epic become ready\n\n$ARGUMENTS"
              },
              {
                "name": "/commit",
                "description": null,
                "path": "plugins/abatilo-core/commands/commit.md",
                "frontmatter": null,
                "content": "## Context\n\n- Current git status: !`git status`\n- Current git diff (staged and unstaged changes): !`git diff HEAD`\n- Current branch: !`git branch --show-current`\n- Recent commits: !`git log --oneline -10`\n\n## Task\n\nCreate logically grouped, atomic commits based on the above context.\nUse the git-commit skill for commit message formatting and best practices.\nUse partial adds (`git add -p`) when a file contains multiple unrelated changes.\n\n$ARGUMENTS\n"
              },
              {
                "name": "/interview",
                "description": "Interview users in-depth about their plans using probing, non-obvious questions.",
                "path": "plugins/abatilo-core/commands/interview.md",
                "frontmatter": {
                  "description": "Interview users in-depth about their plans using probing, non-obvious questions."
                },
                "content": "# Plan Interview\n\nFirst, review the entire conversation to understand what plan is being discussed.\n\nInterview me about this plan in detail using the AskUserQuestion tool. Ask about literally anything: technical implementation, UI & UX, concerns, tradeoffs, edge cases, assumptions, risks, dependencies, etc.\n\nMake sure the questions are not obvious - probe deeper into things I might not have considered. Challenge assumptions. Ask about the hard parts.\n\nBe very in-depth and continue interviewing me continually until the plan is fully fleshed out, then re-iterate the complete plan incorporating everything we discussed."
              }
            ],
            "skills": [
              {
                "name": "bd-issue-tracking",
                "description": "Track and manage work with bd issue tracker for persistent context across sessions and compaction events. Use for work needing dependencies, recovery after compaction, or multi-session tracking.",
                "path": "plugins/abatilo-core/skills/bd-issue-tracking/SKILL.md",
                "frontmatter": {
                  "name": "bd-issue-tracking",
                  "description": "Track and manage work with bd issue tracker for persistent context across sessions and compaction events. Use for work needing dependencies, recovery after compaction, or multi-session tracking."
                },
                "content": "# bd Issue Tracking\n\nbd is a graph-based issue tracker providing persistent memory across sessions. Use for multi-session work; use TodoWrite for simple single-session tasks.\n\n## When to Use bd vs TodoWrite\n\n| Use bd | Use TodoWrite |\n|--------|---------------|\n| Multi-session work (days/weeks) | Single-session tasks (this hour) |\n| Complex dependencies/blockers | Linear step-by-step execution |\n| Need context after compaction | All context in conversation |\n| Fuzzy/exploratory work | Simple checklist |\n\n**Decision rule**: \"If I need this context in 2 weeks after compaction, use bd\"\n\n## Session Start\n\n```bash\nbd ready --json                              # Find available work\nbd list --status in_progress --json          # Check active work\nbd show <issue-id>                           # Read notes from previous session\n```\n\nReport to user: \"X items ready. Issue Y in_progress: [summary from notes]\"\n\n## Core Operations\n\n```bash\n# Create issue\nbd create \"Title\" -d \"Description\" -p 2 -t task --json\n\n# Start work\nbd update bd-xxx --status in_progress --json\n\n# Checkpoint progress (at 70% tokens, milestones, blockers)\nbd update bd-xxx --notes \"COMPLETED: ...\\nIN_PROGRESS: ...\\nNEXT: ...\" --json\n\n# Complete work\nbd close bd-xxx --reason \"What was done and how verified\" --json\n\n# Manage dependencies\nbd dep add bd-setup bd-impl --type blocks    # A blocks B\nbd dep tree bd-xxx                           # View dependency tree\n```\n\n## Notes Format\n\nWrite for post-compaction recovery (no conversation context):\n\n```\nCOMPLETED: Specific deliverables done\nKEY DECISION: Important choices with rationale\nIN PROGRESS: Current state + immediate next step\nBLOCKERS: What's preventing progress\nNEXT: What to do when unblocked\n```\n\n## Priority Levels\n\n0=critical, 1=high, 2=normal (default), 3=low, 4=backlog\n\n## Description Template\n\n```bash\nbd create --title \"$TITLE\" --description \"$(cat <<'EOF'\n# Description\n1-4 sentences: what and why.\n\n# Relevant files and snippets\nFiles identified during discovery with code snippets.\n\n# Additional sources\nRepos explored, web searches performed.\nEOF\n)\" --json\n```\n\n## Reference Documentation\n\nFor detailed guidance, read these files:\n\n| Topic | Reference |\n|-------|-----------|\n| bd vs TodoWrite decisions | [references/BOUNDARIES.md](references/BOUNDARIES.md) |\n| Complete CLI reference | [references/CLI_REFERENCE.md](references/CLI_REFERENCE.md) |\n| Session workflows & checklists | [references/WORKFLOWS.md](references/WORKFLOWS.md) |\n| Dependency types & patterns | [references/DEPENDENCIES.md](references/DEPENDENCIES.md) |\n| Issue creation guidance | [references/ISSUE_CREATION.md](references/ISSUE_CREATION.md) |\n| Context recovery patterns | [references/RESUMABILITY.md](references/RESUMABILITY.md) |\n| Static data usage | [references/STATIC_DATA.md](references/STATIC_DATA.md) |"
              },
              {
                "name": "diataxis-documentation",
                "description": "Write comprehensive, user-focused documentation following the Diataxis framework. Use this skill when creating or improving tutorials, how-to guides, reference documentation, or explanatory content. Helps identify the right documentation type and apply best practices for each.",
                "path": "plugins/abatilo-core/skills/diataxis-documentation/SKILL.md",
                "frontmatter": {
                  "name": "diataxis-documentation",
                  "description": "Write comprehensive, user-focused documentation following the Diataxis framework. Use this skill when creating or improving tutorials, how-to guides, reference documentation, or explanatory content. Helps identify the right documentation type and apply best practices for each.",
                  "allowed-tools": [
                    "Read",
                    "Write",
                    "Edit"
                  ]
                },
                "content": "# Diataxis Documentation Skill\n\nThis skill helps you create high-quality, user-focused documentation following the Diataxis framework, which organizes documentation into four distinct types based on user needs.\n\n## When to Use This Skill\n\nUse this skill when:\n- Creating new documentation of any kind\n- Improving existing documentation\n- Organizing documentation for a project or codebase\n- Writing tutorials, how-to guides, reference material, or explanations\n- Unsure which type of documentation is needed\n- Documentation feels unclear or serves multiple purposes poorly\n\n## The Diataxis Framework Overview\n\nDiataxis organizes documentation along two dimensions:\n\n**User Context:**\n- **Study** (Skill Acquisition): User is learning\n- **Work** (Skill Application): User is doing\n\n**Content Nature:**\n- **Action** (Practical Steps): How to do things\n- **Cognition** (Theoretical Knowledge): Understanding concepts\n\nThis creates four distinct documentation types:\n\n```\n                Study          |          Work\n           (Learning)          |         (Doing)\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━\n                                |\n    TUTORIALS                   |    HOW-TO GUIDES\n    Learning-oriented           |    Goal-oriented\n    Guided lessons              |    Practical directions\n    \"Learn by doing\"            |    \"Achieve a goal\"\n                                |\nAction ━━━━━━━━━━━━━━━━━━━━━━━━┼━━━━━━━━━━━━━━━━━━━━━━━━━━ Action\n                                |\n    EXPLANATION                 |    REFERENCE\n    Understanding-oriented      |    Information-oriented\n    Background & context        |    Technical description\n    \"Why & how it works\"        |    \"Facts about machinery\"\n                                |\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━\nCognition                       |                    Cognition\n```\n\n## How to Use This Skill\n\n### 1. Identify the Documentation Type Needed\n\n**Ask these two questions:**\n1. **Action or Cognition?** Does the user need to DO something or UNDERSTAND something?\n2. **Study or Work?** Is the user learning something new or applying existing knowledge?\n\n**Decision Tree:**\n- Action + Study = **Tutorial** (learning by doing)\n- Action + Work = **How-to Guide** (solving a problem)\n- Cognition + Work = **Reference** (looking up facts)\n- Cognition + Study = **Explanation** (understanding concepts)\n\n### 2. Load the Appropriate Reference File\n\nBased on the documentation type identified, load the relevant reference for detailed guidance:\n\n**For Tutorials:**\nLoad [Tutorials Reference](./references/tutorials.md) when you need to:\n- Guide a learner through a complete, practical lesson\n- Teach basic skills and concepts through hands-on experience\n- Create a learning-oriented \"first steps\" experience\n- Help someone gain confidence with a new tool or technology\n\n**For How-to Guides:**\nLoad [How-to Guides Reference](./references/how-to-guides.md) when you need to:\n- Provide step-by-step instructions to achieve a specific goal\n- Help solve a particular real-world problem\n- Write task-oriented documentation for competent users\n- Address a \"How do I...\" question\n\n**For Reference Documentation:**\nLoad [Reference Documentation Reference](./references/reference.md) when you need to:\n- Document APIs, functions, classes, or configuration options\n- Provide accurate technical descriptions\n- Create lookup material for factual information\n- Write information-oriented content structured like the product\n\n**For Explanations:**\nLoad [Explanations Reference](./references/explanation.md) when you need to:\n- Explain concepts, design decisions, or architectural choices\n- Provide background and context\n- Discuss alternatives and trade-offs\n- Answer \"why\" questions about how things work\n\n**For Framework Overview:**\nLoad [Framework Overview Reference](./references/framework-overview.md) when you need:\n- Detailed understanding of Diataxis principles\n- Guidance on maintaining distinctness between types\n- Common mistakes to avoid\n- The iterative improvement workflow\n\n### 3. Follow the Iterative Improvement Process\n\nDiataxis emphasizes continuous, incremental improvement:\n\n1. **Choose**: Select a small piece of documentation (page, paragraph, or sentence)\n2. **Assess**: Evaluate it against Diataxis standards:\n   - What user need does it serve?\n   - How well does it serve that need?\n   - Does it belong in the right documentation type?\n   - Is it using the right style and approach?\n3. **Decide**: Determine one specific improvement that aligns with Diataxis\n4. **Do**: Complete that single improvement and publish immediately\n\n**Important:** Focus on small, immediate improvements rather than large restructuring efforts.\n\n## Key Principles\n\n### Maintain Distinctness\n- Each documentation type has a specific purpose - don't blur them\n- Tutorials teach through doing, not explaining\n- How-to guides solve problems, not teach concepts\n- Reference describes facts, not guide users through tasks\n- Explanations provide context, not instructions\n\n### User-Centered Approach\n- Always consider: What does the user need right now?\n- Match the documentation type to the user's context (study vs. work)\n- Match the content to the user's need (action vs. cognition)\n\n### Organic Structure\n- Don't create empty documentation structures upfront\n- Let structure emerge from content improvements\n- Create documentation types only when content demands it\n\n### Link Between Types\n- Tutorials can link to explanations for deeper understanding\n- How-to guides can reference relevant reference material\n- Keep each type focused; use links for cross-cutting needs\n\n## Quick Documentation Type Selector\n\n**User says \"How do I...\"**\n- If they're learning → Tutorial\n- If they're working → How-to Guide\n\n**User needs facts about something**\n→ Reference\n\n**User asks \"Why...\" or \"What is...\"**\n→ Explanation\n\n**User is frustrated or stuck**\n- Check recent tasks → How-to Guide\n- Check understanding → Explanation\n- Check syntax/parameters → Reference\n\n**Creating first-time user content**\n→ Tutorial\n\n## Common Patterns\n\n### Tutorial Example Scenarios\n- \"Build your first web app\"\n- \"Getting started with X\"\n- \"Introduction to Y\"\n- \"Your first Z project\"\n\n### How-to Guide Example Scenarios\n- \"How to deploy to production\"\n- \"Implementing authentication\"\n- \"Optimizing database queries\"\n- \"Troubleshooting connection errors\"\n\n### Reference Example Scenarios\n- API documentation\n- Configuration file reference\n- Command-line options\n- Class/function documentation\n\n### Explanation Example Scenarios\n- \"Understanding the architecture\"\n- \"Why we chose X over Y\"\n- \"How the authentication system works\"\n- \"Database design decisions\"\n\n## Important Notes\n\n- Load specific reference files only when needed to keep context manageable\n- Each documentation type requires different writing styles and structures\n- Avoid mixing purposes - if documentation tries to do multiple things, split it\n- The framework is descriptive, not prescriptive - adapt to your project's needs\n- Iterate continuously rather than attempting complete restructuring\n- Quality comes from alignment with user needs, not from following rigid templates\n\n---\n\n**Remember:** The goal is to serve user needs effectively. Use the Diataxis compass to identify what users need, then load the appropriate reference file for detailed guidance on creating that documentation type."
              },
              {
                "name": "git-commit",
                "description": "Create logically grouped, atomic git commits with well-formatted commit messages following best practices. Use this skill when you need to commit changes to a git repository with proper message formatting and atomic grouping.",
                "path": "plugins/abatilo-core/skills/git-commit/SKILL.md",
                "frontmatter": {
                  "name": "git-commit",
                  "description": "Create logically grouped, atomic git commits with well-formatted commit messages following best practices. Use this skill when you need to commit changes to a git repository with proper message formatting and atomic grouping.",
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Edit"
                  ]
                },
                "content": "# Git Commit Skill\n\nThis skill helps you create well-structured, atomic git commits with properly formatted commit messages.\n\n## When to Use This Skill\n\nUse this skill when:\n- You need to commit changes to a git repository\n- You want to create atomic, logically grouped commits\n- You need to follow commit message best practices\n- You have multiple changes that should be split into separate commits\n- You need to use git partial adds (git add -p) for fine-grained control\n\n## Task Overview\n\nBased on the current git status and changes, create a set of logically grouped, atomic commits.\nBe specific with each grouping, and keep scope minimal. Leverage partial adds to\nmake sure that multiple changes within a single file aren't batched into\ncommits with unrelated changes.\n\n## Process\n\n1. **Analyze Current State**\n   - Check git status to see staged and unstaged changes\n   - Review git diff to understand what has changed\n   - Check recent commits (`git log --oneline -20`) to understand:\n     - Whether the project uses conventional commits (e.g., `feat:`, `fix:`, `docs:`)\n     - The project's commit message style and conventions\n     - Typical subject line length and formatting patterns\n\n2. **Group Changes Logically**\n   - Identify related changes that should be committed together\n   - Separate unrelated changes into different commits\n   - Use `git add -p` for partial adds when a file contains multiple logical changes\n\n3. **Create Commits**\n   - Stage the appropriate changes for each commit\n   - Write commit messages following the best practices below\n   - Verify each commit is atomic and complete\n\n## Commit Message Format Detection\n\n**IMPORTANT**: Before writing any commits, analyze the recent git history to determine the project's commit style:\n\n- **Check for Conventional Commits**: Look for patterns like `feat:`, `fix:`, `docs:`, `chore:`, `refactor:`, `test:`, `style:`, `perf:`, `ci:`, `build:`\n- **Match the existing style**: If 80% or more of recent commits follow conventional commits, use that format\n- **Be consistent**: Match the capitalization, punctuation, and structure of existing commits\n\n### Conventional Commits Format\n\nIf the project uses conventional commits, follow this structure:\n\n```\n<type>[(optional scope)]: <description>\n\n[optional body]\n\n[optional footer(s)]\n```\n\n**Common types:**\n- `feat`: A new feature\n- `fix`: A bug fix\n- `docs`: Documentation changes\n- `style`: Code style changes (formatting, missing semicolons, etc.)\n- `refactor`: Code changes that neither fix bugs nor add features\n- `perf`: Performance improvements\n- `test`: Adding or updating tests\n- `build`: Changes to build system or dependencies\n- `ci`: Changes to CI configuration\n- `chore`: Other changes that don't modify src or test files\n\n**Examples:**\n- `feat: add user authentication`\n- `fix: resolve null pointer in login handler`\n- `docs: update API documentation`\n- `refactor(auth): simplify token validation logic`\n\n## Git Commit Message Best Practices\n\nFollow these seven rules for excellent commit messages (adjust for conventional commits if used):\n\n1. **Separate subject from body with a blank line** - Critical for readability\n2. **Limit subject line to 50 characters** - Forces concise summaries\n3. **Capitalize the subject line** - Consistent formatting\n4. **Do not end subject line with a period** - It's a title, not a sentence\n5. **Use imperative mood in subject** - \"Add feature\" not \"Added feature\"\n   - Test: Subject should complete \"If applied, this commit will _____\"\n6. **Wrap body at 72 characters** - Ensures readability in terminals\n7. **Use body to explain what and why vs. how** - Code shows how, commit explains why\n\n### Message Structure\n\n```\n<subject: concise summary, imperative, capitalized, no period>\n\n<body: explain the motivation for the change and contrast with previous behavior>\n\n<footer: references to issues, breaking changes, etc.>\n```\n\n### Key Principles\n\n- **Atomic commits**: Each commit should represent one logical change\n- **Context is king**: Explain WHY the change was made, not just what\n- **Future-proof**: Write for someone (including future you) reading this months later\n- **Consistency**: Maintain uniform style across the project\n\n### Examples\n\n**Good Examples (Traditional Style):**\n- `Refactor subsystem X for readability`\n- `Remove deprecated methods from UserService`\n- `Fix null pointer exception in login handler`\n- `Add user authentication middleware`\n\n**Good Examples (Conventional Commits):**\n- `feat: add user authentication middleware`\n- `fix: resolve null pointer exception in login handler`\n- `refactor: improve subsystem X readability`\n- `chore: remove deprecated methods from UserService`\n\n**Bad Examples:**\n- `fixed stuff`\n- `Changes`\n- `wip`\n- `Update file.js`\n- `feat added new feature` (incorrect format - missing colon)\n\n## Implementation Steps\n\n1. Run `git status` to see current state\n2. Run `git diff HEAD` to see all changes\n3. Run `git log --oneline -20` to analyze recent commit style\n   - **Determine if conventional commits are used** (look for `type:` prefix patterns)\n   - Note the typical capitalization and formatting style\n   - Identify any project-specific conventions\n4. Identify logical groupings of changes\n5. For each logical group:\n   - Stage the relevant changes (use `git add -p` if needed)\n   - Create a commit with a well-formatted message **matching the project's style**\n   - Verify the commit with `git show`\n6. After all commits, run `git status` to verify nothing important was missed\n\n## Notes\n\n- **ALWAYS check recent git history first** to determine if conventional commits are used\n- **Match the project's existing style** - consistency is more important than personal preference\n- DO NOT push to remote unless explicitly asked\n- Always verify authorship and commit details before amending\n- Use `git add -p` for interactive staging when files contain multiple unrelated changes\n- Keep commits focused and atomic - one logical change per commit\n- If in doubt about whether to use conventional commits, look at the last 20-30 commits for patterns"
              },
              {
                "name": "git-spice",
                "description": "Manage stacked Git branches and create multiple pull requests using git-spice (gs). Use when organizing feature branches into stacks, rebasing changes across branches, creating PR chains, navigating branch stacks, or managing dependent branches on GitHub/GitLab. Handles stacked PRs, branch restacking, and stack submission workflows.",
                "path": "plugins/abatilo-core/skills/git-spice/SKILL.md",
                "frontmatter": {
                  "name": "git-spice",
                  "description": "Manage stacked Git branches and create multiple pull requests using git-spice (gs). Use when organizing feature branches into stacks, rebasing changes across branches, creating PR chains, navigating branch stacks, or managing dependent branches on GitHub/GitLab. Handles stacked PRs, branch restacking, and stack submission workflows.",
                  "context": "fork",
                  "allowed-tools": [
                    "Bash(gs:*)",
                    "Bash(git:*)",
                    "Read",
                    "Edit"
                  ]
                },
                "content": "# Git Spice Skill\n\nThis skill helps you manage stacked Git branches using git-spice (`gs`), a CLI tool for creating, navigating, and submitting branch stacks as pull requests.\n\n## When to Use This Skill\n\nUse this skill when:\n- Creating stacked branches for large features broken into reviewable chunks\n- Navigating up/down through branch stacks\n- Submitting multiple related PRs as a stack\n- Rebasing and restacking branches after upstream changes\n- Managing branch dependencies and PR chains on GitHub/GitLab\n\n## Core Concepts\n\n**Stacked Branches**: A series of branches where each branch is based on the previous one, forming a dependency chain rooted at trunk (main/master).\n\n```\n    ┌── feat3 (#3)    <- top of stack\n  ┌─┴ feat2 (#2)\n┌─┴ feat1 (#1)        <- bottom of stack\nmain                  <- trunk\n```\n\n**Trunk**: The main development branch (main, master, or configured trunk).\n\n**Upstack/Downstack**: Branches above/below the current branch in the stack.\n\n## Quick Start\n\n### 1. Initialize Repository\n\n```bash\ngs repo init\n```\n\nThis sets up git-spice tracking in your repository. You'll be prompted to select the trunk branch and remote.\n\n### 2. Create a Branch Stack\n\n```bash\n# Start from trunk\ngit checkout main\n\n# Create first branch in stack\ngs branch create feat1 -m \"Add user model\"\n\n# Create second branch stacked on feat1\ngs branch create feat2 -m \"Add user API\"\n\n# Create third branch stacked on feat2\ngs branch create feat3 -m \"Add user tests\"\n```\n\n### 3. Navigate the Stack\n\n```bash\ngs up        # Move up one branch (u)\ngs down      # Move down one branch (d)\ngs top       # Jump to top of stack (U)\ngs bottom    # Jump to bottom of stack (D)\ngs trunk     # Return to trunk branch\n```\n\n### 4. View Your Stack\n\n```bash\ngs log short    # List all tracked branches (ls)\ngs log long     # Show branches with commits (ll)\n```\n\n### 5. Submit PRs\n\n```bash\ngs stack submit     # Submit entire stack as PRs (ss)\ngs branch submit    # Submit current branch only (bs)\ngs upstack submit   # Submit current and all above (uss)\ngs downstack submit # Submit current and all below (dss)\n```\n\n### 6. Sync and Restack\n\n```bash\ngs repo sync       # Pull latest, delete merged branches (rs)\ngs stack restack   # Rebase all branches onto latest (sr)\n```\n\n## Command Reference (Shorthands)\n\n| Command | Shorthand | Description |\n|---------|-----------|-------------|\n| `gs branch create` | `gs bc` | Create new branch |\n| `gs branch checkout` | `gs bco` | Switch to branch |\n| `gs branch submit` | `gs bs` | Submit branch as PR |\n| `gs branch restack` | `gs br` | Rebase branch on base |\n| `gs branch delete` | `gs bd` | Delete branch |\n| `gs branch onto` | `gs bon` | Move branch onto another |\n| `gs branch edit` | `gs be` | Interactive rebase |\n| `gs stack submit` | `gs ss` | Submit entire stack |\n| `gs stack restack` | `gs sr` | Restack entire stack |\n| `gs upstack submit` | `gs uss` | Submit upstack |\n| `gs upstack restack` | `gs usr` | Restack upstack |\n| `gs downstack submit` | `gs dss` | Submit downstack |\n| `gs repo sync` | `gs rs` | Sync with remote |\n| `gs repo init` | `gs ri` | Initialize repo |\n| `gs commit create` | `gs cc` | Create commit |\n| `gs commit amend` | `gs ca` | Amend commit |\n| `gs log short` | `gs ls` | List branches |\n| `gs log long` | `gs ll` | List with commits |\n\n## Common Workflows\n\n### Creating a Feature Stack\n\n```bash\n# Start from updated trunk\ngs trunk\ngit pull\n\n# Create logical branches for each reviewable piece\ngs bc api-models -m \"Add data models for new API\"\ngs bc api-handlers -m \"Implement API handlers\"\ngs bc api-tests -m \"Add API integration tests\"\n\n# View your stack\ngs ll\n```\n\n### Updating After Review Feedback\n\n```bash\n# Navigate to branch that needs changes\ngs bco api-handlers\n\n# Make changes, then amend or create new commit\ngs ca  # amend current commit\n# or\ngs cc -m \"Address review feedback\"\n\n# Restack all branches above to incorporate changes\ngs usr  # upstack restack\n```\n\n### Syncing with Upstream Changes\n\n```bash\n# Sync repo - pulls trunk, deletes merged branches\ngs rs\n\n# Restack all tracked branches onto new trunk\ngs repo restack\n# or for just current stack:\ngs sr\n```\n\n### Moving a Branch\n\n```bash\n# Move current branch onto a different base\ngs bon main           # Move onto main directly\ngs bon other-feature  # Move onto another branch\n\n# Insert a new branch in the middle of a stack\ngs bc new-branch --insert  # Restacks upstack onto new branch\n```\n\n### Handling Conflicts\n\nWhen restacking encounters conflicts:\n\n```bash\n# Resolve conflicts in your editor\ngit status  # See conflicted files\n# ... fix conflicts ...\ngit add <resolved-files>\n\n# Continue the restack operation\ngs rebase continue  # (gs rbc)\n\n# Or abort if needed\ngs rebase abort     # (gs rba)\n```\n\n### Submitting PRs\n\n```bash\n# Submit all branches in stack as linked PRs\ngs ss\n\n# Submit with draft PRs\ngs ss --draft\n\n# Submit only current branch\ngs bs\n\n# Update PR after changes\ngs bs  # Re-run submit updates existing PR\n```\n\n## Branch Operations\n\n### Track Existing Branches\n\n```bash\n# Track a single branch\ngs branch track feature-branch --base main\n\n# Track all branches in a downstack\ngs downstack track\n```\n\n### Split and Squash\n\n```bash\n# Split current branch into multiple commits\ngs branch split\n\n# Squash branch into single commit\ngs branch squash\n```\n\n### Delete Branches\n\n```bash\n# Delete a single branch\ngs bd feature-branch\n\n# Delete entire upstack\ngs upstack delete\n\n# Delete entire stack\ngs stack delete\n```\n\n## Authentication\n\n```bash\ngs auth login   # Authenticate with GitHub/GitLab\ngs auth status  # Check current auth status\ngs auth logout  # Clear credentials\n```\n\n## Configuration\n\nGit-spice uses git config for settings:\n\n```bash\n# Set branch name prefix\ngit config spice.branchCreate.prefix \"username/\"\n\n# Configure navigation comment style\ngit config spice.submit.navigationComment multiple\n\n# View all spice config\ngit config --get-regexp spice\n```\n\n## Troubleshooting\n\n### Branch Not Tracked\n\n```bash\n# Track an existing branch\ngs branch track my-branch --base main\n```\n\n### Rebase Conflicts\n\n```bash\n# After resolving conflicts\ngs rebase continue\n\n# To abort and try different approach\ngs rebase abort\n```\n\n### Out of Sync with Remote\n\n```bash\ngs repo sync    # Fetch and sync\ngs repo restack # Restack all branches\n```\n\n### Force Push After Restack\n\nAfter restacking, branches need force push:\n```bash\ngs bs --force  # Submit handles force push\n# or manually:\ngit push --force-with-lease\n```\n\n## Reference Documentation\n\nFor detailed information on specific topics, see:\n- [Command Reference](reference/commands.md) - Complete command documentation\n- [Workflows](reference/workflows.md) - Advanced workflow patterns\n\n## Key Principles\n\n1. **Atomic branches**: Each branch should be one logical, reviewable change\n2. **Stack from trunk**: Build stacks starting from main/master\n3. **Restack often**: Keep branches rebased on latest changes\n4. **Submit together**: Use `gs ss` to create linked PRs\n5. **Sync regularly**: Use `gs rs` to stay current with upstream"
              },
              {
                "name": "kubernetes",
                "description": "Comprehensive Kubernetes cluster management skill. Use this skill when working with Kubernetes resources, kubectl operations, Helm charts, container orchestration, debugging pods, managing deployments, or any Kubernetes-related infrastructure tasks.",
                "path": "plugins/abatilo-core/skills/kubernetes/SKILL.md",
                "frontmatter": {
                  "name": "kubernetes",
                  "description": "Comprehensive Kubernetes cluster management skill. Use this skill when working with Kubernetes resources, kubectl operations, Helm charts, container orchestration, debugging pods, managing deployments, or any Kubernetes-related infrastructure tasks.",
                  "context": "fork",
                  "allowed-tools": [
                    "Bash(kubectl:*)",
                    "Bash(helm:*)",
                    "Bash(kustomize:*)"
                  ]
                },
                "content": "# Kubernetes Management Skill\n\nThis skill provides comprehensive capabilities for managing Kubernetes clusters, resources, and workloads using kubectl, Helm, and Kustomize.\n\n## When to Use This Skill\n\nUse this skill when working with:\n- Kubernetes resources (pods, deployments, services, configmaps, secrets, etc.)\n- Debugging containerized applications and troubleshooting cluster issues\n- Helm chart installation, upgrades, and management\n- kubectl operations (get, describe, apply, create, delete, logs, exec, scale, rollout)\n- Context and namespace management\n- Deployment strategies (rolling updates, blue-green, canary)\n- Configuration management and resource optimization\n\n## How to Use This Skill\n\n### 1. Verify Context and Namespace\n\n**Always start by verifying your current context and namespace:**\n```bash\nkubectl config current-context\nkubectl config view --minify\n```\n\nSet namespace if needed:\n```bash\nkubectl config set-context --current --namespace=<namespace>\n```\n\n### 2. Load Appropriate Reference Files\n\nBased on the task at hand, load the relevant reference documentation:\n\n**For kubectl Operations:**\nLoad [kubectl Reference](./references/kubectl_reference.md) when you need detailed information about:\n- Getting, describing, creating, updating, or deleting resources\n- Viewing logs or executing commands in containers\n- Port forwarding and debugging\n- Scaling deployments\n- Managing rollouts and rollbacks\n- Context and namespace operations\n- Output formats and filtering\n\n**For Helm Operations:**\nLoad [Helm Reference](./references/helm_reference.md) when you need detailed information about:\n- Installing or upgrading Helm charts\n- Managing releases (list, status, uninstall, rollback)\n- Repository management\n- Chart development and inspection\n- Values configuration and overrides\n- Troubleshooting Helm issues\n\n**For Common Workflows:**\nLoad [Workflows Reference](./references/workflows.md) when you need guidance on:\n- Debugging failing pods or services\n- Deploying applications\n- Updating deployments with different strategies\n- Blue-green and canary deployments\n- Configuration management (ConfigMaps and Secrets)\n- Maintenance operations (draining nodes, backup/restore)\n- Cluster inspection and cleanup\n\n**For Best Practices:**\nLoad [Best Practices Reference](./references/best_practices.md) when you need guidance on:\n- Safety and validation before operations\n- Efficiency and optimization\n- Debugging approaches\n- YAML and manifest management\n- High availability patterns\n- Error handling and troubleshooting\n- Integration with other tools\n- Environment-specific practices\n\n### 3. General Workflow\n\n**For Resource Management:**\n1. Verify context and namespace\n2. Use `kubectl get` to list resources\n3. Use `kubectl describe` for detailed information\n4. Apply changes with `kubectl apply` or `kubectl patch`\n5. Monitor with `kubectl rollout status` or `kubectl get events`\n\n**For Debugging:**\n1. Check pod status with `kubectl get pods`\n2. Describe the resource with `kubectl describe`\n3. View logs with `kubectl logs`\n4. Check events with `kubectl get events`\n5. Exec into container if needed with `kubectl exec -it`\n\n**For Deployments:**\n1. Validate manifests with `--dry-run`\n2. Apply manifests with `kubectl apply`\n3. Monitor rollout with `kubectl rollout status`\n4. Verify with `kubectl get` and `kubectl logs`\n5. Rollback if needed with `kubectl rollout undo`\n\n## Key Principles\n\n### Safety First\n- Always verify context and namespace before operations\n- Use `--dry-run=client` or `--dry-run=server` to validate changes\n- Use `kubectl diff` to preview changes before applying\n- Be cautious with destructive operations (delete, force, drain)\n\n### Declarative Over Imperative\n- Prefer `kubectl apply -f file.yaml` over imperative commands\n- Store manifests in version control\n- Use Kustomize for environment-specific overlays\n- Make infrastructure reproducible and auditable\n\n### Efficient Resource Usage\n- Use label selectors to operate on groups of resources\n- Use output formats (`-o json|yaml`) for automation and parsing\n- Filter with `--field-selector` and sort with `--sort-by`\n- Watch resources in real-time with `-w` flag\n\n### Systematic Debugging\n- Follow the debugging workflow: status → describe → logs → events → exec\n- Use timestamps in logs for correlation\n- Check recent events with `kubectl get events --sort-by='.lastTimestamp'`\n- Test connectivity with temporary debug pods\n\n## Quick Command Reference\n\n**Most Common Operations:**\n```bash\n# Get resources\nkubectl get pods\nkubectl get pods -o wide\nkubectl get pods -l app=myapp\n\n# Describe for details\nkubectl describe pod <pod-name>\n\n# View logs\nkubectl logs <pod-name>\nkubectl logs <pod-name> -f\nkubectl logs <pod-name> --previous\n\n# Exec into pod\nkubectl exec -it <pod-name> -- /bin/sh\n\n# Apply manifests\nkubectl apply -f deployment.yaml\nkubectl apply -f ./manifests/\n\n# Scale deployment\nkubectl scale deployment/<name> --replicas=3\n\n# Check rollout\nkubectl rollout status deployment/<name>\nkubectl rollout undo deployment/<name>\n\n# Port forward\nkubectl port-forward service/<name> 8080:80\n\n# Helm operations\nhelm install <release> <chart>\nhelm upgrade <release> <chart>\nhelm list\nhelm uninstall <release>\n```\n\n## Important Notes\n\n- Reference files contain comprehensive details - load them as needed to avoid context overhead\n- Always validate configurations before applying to production\n- Use namespaces for resource isolation\n- Set resource requests and limits for all containers\n- Implement health checks (liveness, readiness, startup probes)\n- Use PodDisruptionBudgets for high availability\n- Store sensitive data in Secrets, not ConfigMaps\n- Tag images with specific versions, avoid `:latest` in production\n\n## Integration Points\n\nThis skill works well with:\n- **Docker** for container image management\n- **Git** for manifest version control (GitOps)\n- **Terraform** for infrastructure provisioning\n- **CI/CD pipelines** for automated deployments\n- **Monitoring tools** (Prometheus, Grafana) for observability\n- **Logging systems** (EFK stack) for centralized logging\n\n---\n\n**Remember:** Load the specific reference files only when you need detailed information about kubectl commands, Helm operations, specific workflows, or best practices. This keeps the context manageable and efficient."
              },
              {
                "name": "repo-explore",
                "description": "Clone and explore external GitHub repositories to understand how libraries, frameworks, or dependencies work. Use when user provides a GitHub URL (github.com/owner/repo), asks \"how does X library work\", wants to look at source code for a dependency, asks about implementation details of an external package, or says \"explore\", \"look at\", or \"check out\" a repository. Automatically checks out the matching version tag when the repo is a dependency in the current project.",
                "path": "plugins/abatilo-core/skills/repo-explore/SKILL.md",
                "frontmatter": {
                  "name": "repo-explore",
                  "description": "Clone and explore external GitHub repositories to understand how libraries, frameworks, or dependencies work. Use when user provides a GitHub URL (github.com/owner/repo), asks \"how does X library work\", wants to look at source code for a dependency, asks about implementation details of an external package, or says \"explore\", \"look at\", or \"check out\" a repository. Automatically checks out the matching version tag when the repo is a dependency in the current project.",
                  "context": "fork"
                },
                "content": "# Repo Explore Skill\n\nExplore external GitHub repositories by cloning them locally and using the Explore agent for comprehensive codebase analysis.\n\n## Cache Location\n\n```\n~/.cache/claude/repos/<owner>/<repo>/\n```\n\n## Workflow\n\n### 1. Parse Repository URL\n\nExtract owner and repo from various formats:\n- `https://github.com/owner/repo`\n- `git@github.com:owner/repo.git`\n- `owner/repo` (shorthand)\n- `github.com/owner/repo`\n\n### 2. Check Cache\n\n```bash\nls ~/.cache/claude/repos/<owner>/<repo>/\n```\n\n- **If exists**: Check if update needed (see `update-reference.md`)\n- **If not exists**: Proceed to clone\n\n### 3. Clone Repository\n\n```bash\nmkdir -p ~/.cache/claude/repos/<owner>\ngit clone https://github.com/<owner>/<repo>.git ~/.cache/claude/repos/<owner>/<repo>\n```\n\n### 4. Version Detection (CRITICAL)\n\n**Before exploring, check if this repo is a dependency in the current working directory.**\n\nConsult `version-detection.md` for:\n- Which dependency files to check\n- How to extract versions from each format\n- How to map versions to git tags\n\nIf a matching version is found:\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\ngit fetch --all --tags\ngit checkout <tag>\n```\n\nCommon tag formats to try:\n- `v1.2.3`\n- `1.2.3`\n- `release-1.2.3`\n- `release/1.2.3`\n\n### 5. Explore with Explore Agent\n\n**ALWAYS use the Task tool with `subagent_type=Explore` for answering questions about the repository.**\n\nDo NOT manually browse files when the Explore agent can do it. The Explore agent is optimized for:\n- Finding files by patterns\n- Searching code for keywords\n- Understanding codebase architecture\n- Answering questions about how code works\n\nExample:\n```\nTask(\n  subagent_type=\"Explore\",\n  prompt=\"\"\"In ~/.cache/claude/repos/owner/repo/, find how authentication is implemented.\n\nRequirements for your response:\n- Include code snippets with file paths and line numbers\n- Show key type definitions and function signatures\n- End with a 'Key Files for Further Exploration' table with columns: File, Purpose, Start Here If...\n\"\"\"\n)\n```\n\n### 6. Response Format Requirements\n\n**When answering questions about the repository, responses MUST include:**\n\n#### Code Snippets\n- Include relevant code snippets that directly support the answer\n- Show actual type definitions, function signatures, and key logic\n- Use proper syntax highlighting with language identifier\n- Include file path and line numbers for each snippet:\n  ```go\n  // File: pkg/controller/foo.go:42-58\n  func (r *Reconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n      // ... relevant code\n  }\n  ```\n\n#### File Recommendations for Further Reading\nAt the end of every response, include a **\"Key Files for Further Exploration\"** section:\n\n```markdown\n## Key Files for Further Exploration\n\n| File | Purpose | Start Here If... |\n|------|---------|------------------|\n| `pkg/apis/v1/types.go` | Core type definitions | You want to understand the data model |\n| `pkg/controller/main_controller.go` | Main reconciliation logic | You want to understand the control flow |\n| `docs/design.md` | Architecture decisions | You want high-level understanding |\n```\n\n**Guidelines for file recommendations:**\n- Prioritize files by relevance to the question asked\n- Include 3-7 files (not too few, not overwhelming)\n- Add context on WHY each file is useful\n- Include \"Start Here If...\" guidance to help with future exploration\n- Order from most fundamental to most specific\n\n#### Response Structure Template\n```\n1. Brief answer summary (2-3 sentences)\n2. Detailed explanation with inline code snippets\n3. Architecture/flow diagrams if helpful (ASCII or description)\n4. Key Files for Further Exploration table\n5. Optional: Related topics the user might want to explore next\n```\n\n### 7. Updates\n\nFor refreshing the repository or switching versions, consult `update-reference.md`.\n\n## Important Notes\n\n- Always verify the checkout succeeded before exploring\n- If the user asks about a specific version, checkout that version even if not a dependency\n- For private repos, the clone will work if the user has git credentials configured\n- Large repos may take time to clone; inform the user"
              }
            ]
          }
        ]
      }
    }
  ]
}