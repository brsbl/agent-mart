{
  "owner": {
    "id": "AojdevStudio",
    "display_name": "Ossie Irondi",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/180108913?u=f0e5862e159bc0f269c111203f24f14f68456c89&v=4",
    "url": "https://github.com/AojdevStudio",
    "bio": "ðŸ¦· Dentalpreneur by day, tech tinkerer by night. I build SaaS tools to streamline dental workflows, automate the boring stuff, and make life a bit smarter. ",
    "stats": {
      "total_repos": 1,
      "total_plugins": 46,
      "total_commands": 75,
      "total_skills": 0,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "AojdevStudio/dev-utils-marketplace",
      "url": "https://github.com/AojdevStudio/dev-utils-marketplace",
      "description": "Modular Claude Code plugin marketplace with 15 focused, independently installable plugins for enhanced development workflows",
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2025-10-14T17:41:35Z",
        "created_at": "2025-10-11T13:48:44Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 13499
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 156
        },
        {
          "path": "CHANGELOG.md",
          "type": "blob",
          "size": 6175
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 9977
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 19925
        },
        {
          "path": "auth-security-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 539
        },
        {
          "path": "auth-security-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security-agents/agents/auth-systems-expert.md",
          "type": "blob",
          "size": 4562
        },
        {
          "path": "auth-security-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security-hooks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security-hooks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 552
        },
        {
          "path": "auth-security-hooks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security-hooks/hooks/hooks.json",
          "type": "blob",
          "size": 338
        },
        {
          "path": "auth-security-hooks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security-hooks/hooks/scripts/api-standards-checker.py",
          "type": "blob",
          "size": 21724
        },
        {
          "path": "auth-security",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 743
        },
        {
          "path": "auth-security/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security/agents/auth-systems-expert.md",
          "type": "blob",
          "size": 4562
        },
        {
          "path": "auth-security/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security/hooks/hooks.json",
          "type": "blob",
          "size": 338
        },
        {
          "path": "auth-security/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "auth-security/hooks/scripts/api-standards-checker.py",
          "type": "blob",
          "size": 21724
        },
        {
          "path": "cicd-automation-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 543
        },
        {
          "path": "cicd-automation-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation-agents/agents/devops-troubleshooter.md",
          "type": "blob",
          "size": 1170
        },
        {
          "path": "cicd-automation-agents/agents/github-actions-specialist.md",
          "type": "blob",
          "size": 4993
        },
        {
          "path": "cicd-automation-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 548
        },
        {
          "path": "cicd-automation-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation-commands/commands/gh-actions-monitor.md",
          "type": "blob",
          "size": 5623
        },
        {
          "path": "cicd-automation-commands/commands/husky.md",
          "type": "blob",
          "size": 1047
        },
        {
          "path": "cicd-automation",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 764
        },
        {
          "path": "cicd-automation/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation/agents/devops-troubleshooter.md",
          "type": "blob",
          "size": 1170
        },
        {
          "path": "cicd-automation/agents/github-actions-specialist.md",
          "type": "blob",
          "size": 4993
        },
        {
          "path": "cicd-automation/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "cicd-automation/commands/gh-actions-monitor.md",
          "type": "blob",
          "size": 5623
        },
        {
          "path": "cicd-automation/commands/husky.md",
          "type": "blob",
          "size": 1047
        },
        {
          "path": "code-quality-enforcement-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 561
        },
        {
          "path": "code-quality-enforcement-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-agents/agents/tech-debt-reviewer.md",
          "type": "blob",
          "size": 13056
        },
        {
          "path": "code-quality-enforcement-agents/agents/test-automator.md",
          "type": "blob",
          "size": 4099
        },
        {
          "path": "code-quality-enforcement-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 566
        },
        {
          "path": "code-quality-enforcement-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-commands/commands/enforce-logging-discipline.md",
          "type": "blob",
          "size": 2477
        },
        {
          "path": "code-quality-enforcement-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-hooks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-hooks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 574
        },
        {
          "path": "code-quality-enforcement-hooks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-hooks/hooks/hooks.json",
          "type": "blob",
          "size": 781
        },
        {
          "path": "code-quality-enforcement-hooks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement-hooks/hooks/scripts/code-quality-reporter.py",
          "type": "blob",
          "size": 13293
        },
        {
          "path": "code-quality-enforcement-hooks/hooks/scripts/pnpm-enforcer.py",
          "type": "blob",
          "size": 6867
        },
        {
          "path": "code-quality-enforcement-hooks/hooks/scripts/universal-linter.py",
          "type": "blob",
          "size": 16682
        },
        {
          "path": "code-quality-enforcement",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 897
        },
        {
          "path": "code-quality-enforcement/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement/agents/tech-debt-reviewer.md",
          "type": "blob",
          "size": 13056
        },
        {
          "path": "code-quality-enforcement/agents/test-automator.md",
          "type": "blob",
          "size": 4099
        },
        {
          "path": "code-quality-enforcement/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement/commands/enforce-logging-discipline.md",
          "type": "blob",
          "size": 2477
        },
        {
          "path": "code-quality-enforcement/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement/hooks/hooks.json",
          "type": "blob",
          "size": 781
        },
        {
          "path": "code-quality-enforcement/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-enforcement/hooks/scripts/code-quality-reporter.py",
          "type": "blob",
          "size": 13293
        },
        {
          "path": "code-quality-enforcement/hooks/scripts/pnpm-enforcer.py",
          "type": "blob",
          "size": 6867
        },
        {
          "path": "code-quality-enforcement/hooks/scripts/universal-linter.py",
          "type": "blob",
          "size": 16682
        },
        {
          "path": "core-essentials-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 543
        },
        {
          "path": "core-essentials-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-agents/agents/code-reviewer.md",
          "type": "blob",
          "size": 1021
        },
        {
          "path": "core-essentials-agents/agents/doc-curator.md",
          "type": "blob",
          "size": 5234
        },
        {
          "path": "core-essentials-agents/agents/git-flow-manager.md",
          "type": "blob",
          "size": 8784
        },
        {
          "path": "core-essentials-agents/agents/quality-guardian.md",
          "type": "blob",
          "size": 4378
        },
        {
          "path": "core-essentials-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 548
        },
        {
          "path": "core-essentials-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-commands/commands/analyze-codebase.md",
          "type": "blob",
          "size": 7366
        },
        {
          "path": "core-essentials-commands/commands/build.md",
          "type": "blob",
          "size": 794
        },
        {
          "path": "core-essentials-commands/commands/code-review.md",
          "type": "blob",
          "size": 2924
        },
        {
          "path": "core-essentials-commands/commands/commit.md",
          "type": "blob",
          "size": 3007
        },
        {
          "path": "core-essentials-commands/commands/git-status.md",
          "type": "blob",
          "size": 431
        },
        {
          "path": "core-essentials-commands/commands/go.md",
          "type": "blob",
          "size": 2636
        },
        {
          "path": "core-essentials-commands/commands/quick-plan.md",
          "type": "blob",
          "size": 2593
        },
        {
          "path": "core-essentials-commands/commands/quick-search.md",
          "type": "blob",
          "size": 423
        },
        {
          "path": "core-essentials-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-hooks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-hooks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 556
        },
        {
          "path": "core-essentials-hooks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-hooks/hooks/hooks.json",
          "type": "blob",
          "size": 1362
        },
        {
          "path": "core-essentials-hooks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-hooks/hooks/scripts/notification.py",
          "type": "blob",
          "size": 4007
        },
        {
          "path": "core-essentials-hooks/hooks/scripts/post_tool_use.py",
          "type": "blob",
          "size": 2633
        },
        {
          "path": "core-essentials-hooks/hooks/scripts/pre_tool_use.py",
          "type": "blob",
          "size": 20423
        },
        {
          "path": "core-essentials-hooks/hooks/scripts/session_start.py",
          "type": "blob",
          "size": 6602
        },
        {
          "path": "core-essentials-hooks/hooks/scripts/stop.py",
          "type": "blob",
          "size": 6623
        },
        {
          "path": "core-essentials-hooks/hooks/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-hooks/hooks/utils/README.md",
          "type": "blob",
          "size": 703
        },
        {
          "path": "core-essentials-hooks/hooks/utils/llm",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-hooks/hooks/utils/llm/anth.py",
          "type": "blob",
          "size": 3234
        },
        {
          "path": "core-essentials-hooks/hooks/utils/llm/oai.py",
          "type": "blob",
          "size": 3218
        },
        {
          "path": "core-essentials-hooks/hooks/utils/tts",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials-hooks/hooks/utils/tts/elevenlabs_tts.py",
          "type": "blob",
          "size": 2513
        },
        {
          "path": "core-essentials-hooks/hooks/utils/tts/openai_tts.py",
          "type": "blob",
          "size": 3273
        },
        {
          "path": "core-essentials-hooks/hooks/utils/tts/pyttsx3_tts.py",
          "type": "blob",
          "size": 1919
        },
        {
          "path": "core-essentials",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 825
        },
        {
          "path": "core-essentials/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/agents/code-reviewer.md",
          "type": "blob",
          "size": 1021
        },
        {
          "path": "core-essentials/agents/doc-curator.md",
          "type": "blob",
          "size": 5234
        },
        {
          "path": "core-essentials/agents/git-flow-manager.md",
          "type": "blob",
          "size": 8784
        },
        {
          "path": "core-essentials/agents/quality-guardian.md",
          "type": "blob",
          "size": 4378
        },
        {
          "path": "core-essentials/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/commands/analyze-codebase.md",
          "type": "blob",
          "size": 7366
        },
        {
          "path": "core-essentials/commands/build.md",
          "type": "blob",
          "size": 794
        },
        {
          "path": "core-essentials/commands/code-review.md",
          "type": "blob",
          "size": 2924
        },
        {
          "path": "core-essentials/commands/commit.md",
          "type": "blob",
          "size": 3007
        },
        {
          "path": "core-essentials/commands/git-status.md",
          "type": "blob",
          "size": 431
        },
        {
          "path": "core-essentials/commands/go.md",
          "type": "blob",
          "size": 2636
        },
        {
          "path": "core-essentials/commands/quick-plan.md",
          "type": "blob",
          "size": 2593
        },
        {
          "path": "core-essentials/commands/quick-search.md",
          "type": "blob",
          "size": 423
        },
        {
          "path": "core-essentials/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/hooks/hooks.json",
          "type": "blob",
          "size": 1362
        },
        {
          "path": "core-essentials/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/hooks/scripts/notification.py",
          "type": "blob",
          "size": 4007
        },
        {
          "path": "core-essentials/hooks/scripts/post_tool_use.py",
          "type": "blob",
          "size": 2633
        },
        {
          "path": "core-essentials/hooks/scripts/pre_tool_use.py",
          "type": "blob",
          "size": 20423
        },
        {
          "path": "core-essentials/hooks/scripts/session_start.py",
          "type": "blob",
          "size": 6602
        },
        {
          "path": "core-essentials/hooks/scripts/stop.py",
          "type": "blob",
          "size": 6623
        },
        {
          "path": "core-essentials/hooks/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/hooks/utils/README.md",
          "type": "blob",
          "size": 703
        },
        {
          "path": "core-essentials/hooks/utils/llm",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/hooks/utils/llm/anth.py",
          "type": "blob",
          "size": 3234
        },
        {
          "path": "core-essentials/hooks/utils/llm/oai.py",
          "type": "blob",
          "size": 3218
        },
        {
          "path": "core-essentials/hooks/utils/tts",
          "type": "tree",
          "size": null
        },
        {
          "path": "core-essentials/hooks/utils/tts/elevenlabs_tts.py",
          "type": "blob",
          "size": 2513
        },
        {
          "path": "core-essentials/hooks/utils/tts/openai_tts.py",
          "type": "blob",
          "size": 3273
        },
        {
          "path": "core-essentials/hooks/utils/tts/pyttsx3_tts.py",
          "type": "blob",
          "size": 1919
        },
        {
          "path": "data-science-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 537
        },
        {
          "path": "data-science-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science-agents/agents/data-analyst.md",
          "type": "blob",
          "size": 4772
        },
        {
          "path": "data-science-agents/agents/data-engineer.md",
          "type": "blob",
          "size": 1190
        },
        {
          "path": "data-science-agents/agents/data-scientist.md",
          "type": "blob",
          "size": 11013
        },
        {
          "path": "data-science-agents/agents/quant-analyst.md",
          "type": "blob",
          "size": 1309
        },
        {
          "path": "data-science-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 542
        },
        {
          "path": "data-science-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science-commands/commands/data-commander.md",
          "type": "blob",
          "size": 2948
        },
        {
          "path": "data-science",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 746
        },
        {
          "path": "data-science/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science/agents/data-analyst.md",
          "type": "blob",
          "size": 4772
        },
        {
          "path": "data-science/agents/data-engineer.md",
          "type": "blob",
          "size": 1190
        },
        {
          "path": "data-science/agents/data-scientist.md",
          "type": "blob",
          "size": 11013
        },
        {
          "path": "data-science/agents/quant-analyst.md",
          "type": "blob",
          "size": 1309
        },
        {
          "path": "data-science/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "data-science/commands/data-commander.md",
          "type": "blob",
          "size": 2948
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/migration",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/migration/v2-to-v3.md",
          "type": "blob",
          "size": 9127
        },
        {
          "path": "documentation-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 539
        },
        {
          "path": "documentation-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-agents/agents/auto-documenter.md",
          "type": "blob",
          "size": 4516
        },
        {
          "path": "documentation-agents/agents/changelog-writer.md",
          "type": "blob",
          "size": 2079
        },
        {
          "path": "documentation-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 544
        },
        {
          "path": "documentation-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-commands/commands/generate-readme.md",
          "type": "blob",
          "size": 1431
        },
        {
          "path": "documentation-commands/commands/update-changelog.md",
          "type": "blob",
          "size": 468
        },
        {
          "path": "documentation-commands/commands/update-claude.md",
          "type": "blob",
          "size": 3175
        },
        {
          "path": "documentation-commands/commands/update-docs.md",
          "type": "blob",
          "size": 4960
        },
        {
          "path": "documentation-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-hooks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-hooks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 552
        },
        {
          "path": "documentation-hooks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-hooks/hooks/hooks.json",
          "type": "blob",
          "size": 335
        },
        {
          "path": "documentation-hooks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-hooks/hooks/scripts/auto-changelog-updater.py",
          "type": "blob",
          "size": 3046
        },
        {
          "path": "documentation",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 809
        },
        {
          "path": "documentation/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation/agents/auto-documenter.md",
          "type": "blob",
          "size": 4516
        },
        {
          "path": "documentation/agents/changelog-writer.md",
          "type": "blob",
          "size": 2079
        },
        {
          "path": "documentation/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation/commands/generate-readme.md",
          "type": "blob",
          "size": 1431
        },
        {
          "path": "documentation/commands/update-changelog.md",
          "type": "blob",
          "size": 468
        },
        {
          "path": "documentation/commands/update-claude.md",
          "type": "blob",
          "size": 3175
        },
        {
          "path": "documentation/commands/update-docs.md",
          "type": "blob",
          "size": 4960
        },
        {
          "path": "documentation/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation/hooks/hooks.json",
          "type": "blob",
          "size": 335
        },
        {
          "path": "documentation/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation/hooks/scripts/auto-changelog-updater.py",
          "type": "blob",
          "size": 3046
        },
        {
          "path": "git-workflow-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 537
        },
        {
          "path": "git-workflow-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-agents/agents/coderabbit-review-extractor.md",
          "type": "blob",
          "size": 4529
        },
        {
          "path": "git-workflow-agents/agents/pr-specialist.md",
          "type": "blob",
          "size": 5204
        },
        {
          "path": "git-workflow-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 542
        },
        {
          "path": "git-workflow-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-commands/commands/create-pr.md",
          "type": "blob",
          "size": 617
        },
        {
          "path": "git-workflow-commands/commands/review-merge.md",
          "type": "blob",
          "size": 646
        },
        {
          "path": "git-workflow-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-hooks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-hooks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 550
        },
        {
          "path": "git-workflow-hooks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-hooks/hooks/hooks.json",
          "type": "blob",
          "size": 831
        },
        {
          "path": "git-workflow-hooks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow-hooks/hooks/scripts/auto-changelog-updater.py",
          "type": "blob",
          "size": 3046
        },
        {
          "path": "git-workflow-hooks/hooks/scripts/auto_commit_on_changes.py",
          "type": "blob",
          "size": 3630
        },
        {
          "path": "git-workflow-hooks/hooks/scripts/commit-message-validator.py",
          "type": "blob",
          "size": 8592
        },
        {
          "path": "git-workflow-hooks/hooks/scripts/prevent-direct-push.py",
          "type": "blob",
          "size": 2163
        },
        {
          "path": "git-workflow-hooks/hooks/scripts/validate-branch-name.py",
          "type": "blob",
          "size": 2518
        },
        {
          "path": "git-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 801
        },
        {
          "path": "git-workflow/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow/agents/coderabbit-review-extractor.md",
          "type": "blob",
          "size": 4529
        },
        {
          "path": "git-workflow/agents/pr-specialist.md",
          "type": "blob",
          "size": 5204
        },
        {
          "path": "git-workflow/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow/commands/create-pr.md",
          "type": "blob",
          "size": 617
        },
        {
          "path": "git-workflow/commands/review-merge.md",
          "type": "blob",
          "size": 646
        },
        {
          "path": "git-workflow/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow/hooks/hooks.json",
          "type": "blob",
          "size": 831
        },
        {
          "path": "git-workflow/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-workflow/hooks/scripts/auto-changelog-updater.py",
          "type": "blob",
          "size": 3046
        },
        {
          "path": "git-workflow/hooks/scripts/auto_commit_on_changes.py",
          "type": "blob",
          "size": 3630
        },
        {
          "path": "git-workflow/hooks/scripts/commit-message-validator.py",
          "type": "blob",
          "size": 8592
        },
        {
          "path": "git-workflow/hooks/scripts/prevent-direct-push.py",
          "type": "blob",
          "size": 2163
        },
        {
          "path": "git-workflow/hooks/scripts/validate-branch-name.py",
          "type": "blob",
          "size": 2518
        },
        {
          "path": "lang-apps-script-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-apps-script-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-apps-script-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 545
        },
        {
          "path": "lang-apps-script-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-apps-script-agents/agents/apps-script-developer.md",
          "type": "blob",
          "size": 8853
        },
        {
          "path": "lang-apps-script-agents/agents/apps-script-requirements-planner.md",
          "type": "blob",
          "size": 13658
        },
        {
          "path": "lang-apps-script",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-apps-script/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-apps-script/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 698
        },
        {
          "path": "lang-apps-script/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-apps-script/agents/apps-script-developer.md",
          "type": "blob",
          "size": 8853
        },
        {
          "path": "lang-apps-script/agents/apps-script-requirements-planner.md",
          "type": "blob",
          "size": 13658
        },
        {
          "path": "lang-fullstack-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-fullstack-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-fullstack-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 541
        },
        {
          "path": "lang-fullstack-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-fullstack-agents/agents/backend-architect.md",
          "type": "blob",
          "size": 1273
        },
        {
          "path": "lang-fullstack-agents/agents/devops-engineer.md",
          "type": "blob",
          "size": 24039
        },
        {
          "path": "lang-fullstack-agents/agents/fullstack-developer.md",
          "type": "blob",
          "size": 32283
        },
        {
          "path": "lang-fullstack",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-fullstack/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-fullstack/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 690
        },
        {
          "path": "lang-fullstack/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-fullstack/agents/backend-architect.md",
          "type": "blob",
          "size": 1273
        },
        {
          "path": "lang-fullstack/agents/devops-engineer.md",
          "type": "blob",
          "size": 24039
        },
        {
          "path": "lang-fullstack/agents/fullstack-developer.md",
          "type": "blob",
          "size": 32283
        },
        {
          "path": "lang-javascript-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 543
        },
        {
          "path": "lang-javascript-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript-agents/agents/javascript-craftsman.md",
          "type": "blob",
          "size": 13403
        },
        {
          "path": "lang-javascript-agents/agents/v2-typescript-expert.md",
          "type": "blob",
          "size": 6703
        },
        {
          "path": "lang-javascript-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript-hooks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript-hooks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 556
        },
        {
          "path": "lang-javascript-hooks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript-hooks/hooks/hooks.json",
          "type": "blob",
          "size": 529
        },
        {
          "path": "lang-javascript-hooks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript-hooks/hooks/scripts/import-organizer.py",
          "type": "blob",
          "size": 11025
        },
        {
          "path": "lang-javascript-hooks/hooks/scripts/typescript-validator.py",
          "type": "blob",
          "size": 23456
        },
        {
          "path": "lang-javascript",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 755
        },
        {
          "path": "lang-javascript/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript/agents/javascript-craftsman.md",
          "type": "blob",
          "size": 13403
        },
        {
          "path": "lang-javascript/agents/v2-typescript-expert.md",
          "type": "blob",
          "size": 6703
        },
        {
          "path": "lang-javascript/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript/hooks/hooks.json",
          "type": "blob",
          "size": 529
        },
        {
          "path": "lang-javascript/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-javascript/hooks/scripts/import-organizer.py",
          "type": "blob",
          "size": 11025
        },
        {
          "path": "lang-javascript/hooks/scripts/typescript-validator.py",
          "type": "blob",
          "size": 23456
        },
        {
          "path": "lang-python-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-python-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-python-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 535
        },
        {
          "path": "lang-python-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-python-agents/agents/python-pro.md",
          "type": "blob",
          "size": 13843
        },
        {
          "path": "lang-python",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-python/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-python/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 678
        },
        {
          "path": "lang-python/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "lang-python/agents/python-pro.md",
          "type": "blob",
          "size": 13843
        },
        {
          "path": "logs",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/pre_tool_use.json",
          "type": "blob",
          "size": 3982
        },
        {
          "path": "logs/session_start.json",
          "type": "blob",
          "size": 427
        },
        {
          "path": "logs/stop.json",
          "type": "blob",
          "size": 916
        },
        {
          "path": "logs/subagent_stop.json",
          "type": "blob",
          "size": 467
        },
        {
          "path": "logs/task_completion_enforcer.json",
          "type": "blob",
          "size": 553
        },
        {
          "path": "logs/user_prompt_submit.json",
          "type": "blob",
          "size": 482
        },
        {
          "path": "research-intelligence-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 556
        },
        {
          "path": "research-intelligence-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence-agents/agents/competitive-intelligence-analyst.md",
          "type": "blob",
          "size": 19098
        },
        {
          "path": "research-intelligence-agents/agents/deep-searcher.md",
          "type": "blob",
          "size": 10424
        },
        {
          "path": "research-intelligence-agents/agents/doc-curator.md",
          "type": "blob",
          "size": 5234
        },
        {
          "path": "research-intelligence-agents/agents/docs-hunter.md",
          "type": "blob",
          "size": 3976
        },
        {
          "path": "research-intelligence-agents/agents/fact-checker.md",
          "type": "blob",
          "size": 21474
        },
        {
          "path": "research-intelligence-agents/agents/podcast-content-analyzer.md",
          "type": "blob",
          "size": 2843
        },
        {
          "path": "research-intelligence-agents/agents/podcast-metadata-specialist.md",
          "type": "blob",
          "size": 3023
        },
        {
          "path": "research-intelligence-agents/agents/podcast-transcriber.md",
          "type": "blob",
          "size": 3338
        },
        {
          "path": "research-intelligence-agents/agents/product-strategist.md",
          "type": "blob",
          "size": 7992
        },
        {
          "path": "research-intelligence-agents/agents/report-generator.md",
          "type": "blob",
          "size": 5372
        },
        {
          "path": "research-intelligence-agents/agents/risk-manager.md",
          "type": "blob",
          "size": 1417
        },
        {
          "path": "research-intelligence-agents/agents/youtube-transcript-analyzer.md",
          "type": "blob",
          "size": 7299
        },
        {
          "path": "research-intelligence-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 560
        },
        {
          "path": "research-intelligence-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence-commands/commands/scrape-site.md",
          "type": "blob",
          "size": 1913
        },
        {
          "path": "research-intelligence",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 800
        },
        {
          "path": "research-intelligence/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence/agents/competitive-intelligence-analyst.md",
          "type": "blob",
          "size": 19098
        },
        {
          "path": "research-intelligence/agents/deep-searcher.md",
          "type": "blob",
          "size": 10424
        },
        {
          "path": "research-intelligence/agents/doc-curator.md",
          "type": "blob",
          "size": 5234
        },
        {
          "path": "research-intelligence/agents/docs-hunter.md",
          "type": "blob",
          "size": 3976
        },
        {
          "path": "research-intelligence/agents/fact-checker.md",
          "type": "blob",
          "size": 21474
        },
        {
          "path": "research-intelligence/agents/podcast-content-analyzer.md",
          "type": "blob",
          "size": 2843
        },
        {
          "path": "research-intelligence/agents/podcast-metadata-specialist.md",
          "type": "blob",
          "size": 3023
        },
        {
          "path": "research-intelligence/agents/podcast-transcriber.md",
          "type": "blob",
          "size": 3338
        },
        {
          "path": "research-intelligence/agents/product-strategist.md",
          "type": "blob",
          "size": 7992
        },
        {
          "path": "research-intelligence/agents/report-generator.md",
          "type": "blob",
          "size": 5372
        },
        {
          "path": "research-intelligence/agents/risk-manager.md",
          "type": "blob",
          "size": 1417
        },
        {
          "path": "research-intelligence/agents/youtube-transcript-analyzer.md",
          "type": "blob",
          "size": 7299
        },
        {
          "path": "research-intelligence/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "research-intelligence/commands/scrape-site.md",
          "type": "blob",
          "size": 1913
        },
        {
          "path": "shell-config-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 537
        },
        {
          "path": "shell-config-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config-agents/agents/shell-config-expert.md",
          "type": "blob",
          "size": 3835
        },
        {
          "path": "shell-config-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 542
        },
        {
          "path": "shell-config-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config-commands/commands/enforce-structure.md",
          "type": "blob",
          "size": 926
        },
        {
          "path": "shell-config",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 746
        },
        {
          "path": "shell-config/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config/agents/shell-config-expert.md",
          "type": "blob",
          "size": 3835
        },
        {
          "path": "shell-config/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "shell-config/commands/enforce-structure.md",
          "type": "blob",
          "size": 926
        },
        {
          "path": "task-orchestration-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 549
        },
        {
          "path": "task-orchestration-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-agents/agents/agent-coordinator.md",
          "type": "blob",
          "size": 7214
        },
        {
          "path": "task-orchestration-agents/agents/agent-expert.md",
          "type": "blob",
          "size": 16281
        },
        {
          "path": "task-orchestration-agents/agents/ai-engineer.md",
          "type": "blob",
          "size": 1292
        },
        {
          "path": "task-orchestration-agents/agents/gpt5.md",
          "type": "blob",
          "size": 743
        },
        {
          "path": "task-orchestration-agents/agents/meta-agent.md",
          "type": "blob",
          "size": 7752
        },
        {
          "path": "task-orchestration-agents/agents/prd-writer.md",
          "type": "blob",
          "size": 8767
        },
        {
          "path": "task-orchestration-agents/agents/prompt-engineer.md",
          "type": "blob",
          "size": 12175
        },
        {
          "path": "task-orchestration-agents/agents/task-orchestrator.md",
          "type": "blob",
          "size": 8602
        },
        {
          "path": "task-orchestration-agents/agents/validation-gate.md",
          "type": "blob",
          "size": 4593
        },
        {
          "path": "task-orchestration-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-commands/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-commands/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 554
        },
        {
          "path": "task-orchestration-commands/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-commands/commands/analyze-issue.md",
          "type": "blob",
          "size": 947
        },
        {
          "path": "task-orchestration-commands/commands/build-roadmap.md",
          "type": "blob",
          "size": 476
        },
        {
          "path": "task-orchestration-commands/commands/create-coordination-files.md",
          "type": "blob",
          "size": 442
        },
        {
          "path": "task-orchestration-commands/commands/use-agent.md",
          "type": "blob",
          "size": 1160
        },
        {
          "path": "task-orchestration-commands/commands/write-linear-issue.md",
          "type": "blob",
          "size": 897
        },
        {
          "path": "task-orchestration-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-hooks/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-hooks/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 562
        },
        {
          "path": "task-orchestration-hooks/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-hooks/hooks/hooks.json",
          "type": "blob",
          "size": 1007
        },
        {
          "path": "task-orchestration-hooks/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration-hooks/hooks/scripts/pre_compact.py",
          "type": "blob",
          "size": 3872
        },
        {
          "path": "task-orchestration-hooks/hooks/scripts/subagent_stop.py",
          "type": "blob",
          "size": 4680
        },
        {
          "path": "task-orchestration-hooks/hooks/scripts/task-completion-enforcer.py",
          "type": "blob",
          "size": 14691
        },
        {
          "path": "task-orchestration-hooks/hooks/scripts/user_prompt_sumbit.py",
          "type": "blob",
          "size": 6296
        },
        {
          "path": "task-orchestration",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 849
        },
        {
          "path": "task-orchestration/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration/agents/agent-coordinator.md",
          "type": "blob",
          "size": 7214
        },
        {
          "path": "task-orchestration/agents/agent-expert.md",
          "type": "blob",
          "size": 16281
        },
        {
          "path": "task-orchestration/agents/ai-engineer.md",
          "type": "blob",
          "size": 1292
        },
        {
          "path": "task-orchestration/agents/gpt5.md",
          "type": "blob",
          "size": 743
        },
        {
          "path": "task-orchestration/agents/meta-agent.md",
          "type": "blob",
          "size": 7752
        },
        {
          "path": "task-orchestration/agents/prd-writer.md",
          "type": "blob",
          "size": 8767
        },
        {
          "path": "task-orchestration/agents/prompt-engineer.md",
          "type": "blob",
          "size": 12175
        },
        {
          "path": "task-orchestration/agents/task-orchestrator.md",
          "type": "blob",
          "size": 8602
        },
        {
          "path": "task-orchestration/agents/validation-gate.md",
          "type": "blob",
          "size": 4593
        },
        {
          "path": "task-orchestration/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration/commands/analyze-issue.md",
          "type": "blob",
          "size": 947
        },
        {
          "path": "task-orchestration/commands/build-roadmap.md",
          "type": "blob",
          "size": 476
        },
        {
          "path": "task-orchestration/commands/create-coordination-files.md",
          "type": "blob",
          "size": 442
        },
        {
          "path": "task-orchestration/commands/use-agent.md",
          "type": "blob",
          "size": 1160
        },
        {
          "path": "task-orchestration/commands/write-linear-issue.md",
          "type": "blob",
          "size": 897
        },
        {
          "path": "task-orchestration/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration/hooks/hooks.json",
          "type": "blob",
          "size": 1007
        },
        {
          "path": "task-orchestration/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "task-orchestration/hooks/scripts/pre_compact.py",
          "type": "blob",
          "size": 3872
        },
        {
          "path": "task-orchestration/hooks/scripts/subagent_stop.py",
          "type": "blob",
          "size": 4680
        },
        {
          "path": "task-orchestration/hooks/scripts/task-completion-enforcer.py",
          "type": "blob",
          "size": 14691
        },
        {
          "path": "task-orchestration/hooks/scripts/user_prompt_sumbit.py",
          "type": "blob",
          "size": 6296
        },
        {
          "path": "ui-design-system-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui-design-system-agents/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui-design-system-agents/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 545
        },
        {
          "path": "ui-design-system-agents/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui-design-system-agents/agents/cli-ui-designer.md",
          "type": "blob",
          "size": 10399
        },
        {
          "path": "ui-design-system-agents/agents/frontend-developer.md",
          "type": "blob",
          "size": 1616
        },
        {
          "path": "ui-design-system-agents/agents/frontend-verifier.md",
          "type": "blob",
          "size": 5115
        },
        {
          "path": "ui-design-system-agents/agents/interface-designer.md",
          "type": "blob",
          "size": 7938
        },
        {
          "path": "ui-design-system-agents/agents/senior-frontend-designer.md",
          "type": "blob",
          "size": 14794
        },
        {
          "path": "ui-design-system-agents/agents/ui-ux-designer.md",
          "type": "blob",
          "size": 1616
        },
        {
          "path": "ui-design-system",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui-design-system/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui-design-system/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 698
        },
        {
          "path": "ui-design-system/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "ui-design-system/agents/cli-ui-designer.md",
          "type": "blob",
          "size": 10399
        },
        {
          "path": "ui-design-system/agents/frontend-developer.md",
          "type": "blob",
          "size": 1616
        },
        {
          "path": "ui-design-system/agents/frontend-verifier.md",
          "type": "blob",
          "size": 5115
        },
        {
          "path": "ui-design-system/agents/interface-designer.md",
          "type": "blob",
          "size": 7938
        },
        {
          "path": "ui-design-system/agents/senior-frontend-designer.md",
          "type": "blob",
          "size": 14794
        },
        {
          "path": "ui-design-system/agents/ui-ux-designer.md",
          "type": "blob",
          "size": 1616
        }
      ],
      "marketplace": {
        "name": "dev-utils-marketplace",
        "version": "3.0.0",
        "description": "Modular development utilities for Claude Code - now with granular component packages (commands, agents, hooks)",
        "owner_info": {
          "name": "Ossie Irondi",
          "email": "admin@kamdental.com",
          "url": "https://github.com/AojdevStudio"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "auth-security-agents",
            "description": "auth-security AI agents for specialized tasks (1 agents)",
            "source": "./auth-security-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install auth-security-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "auth-security-hooks",
            "description": "auth-security automation hooks for development workflow",
            "source": "./auth-security-hooks",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install auth-security-hooks@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "auth-security",
            "description": "Meta-package: Installs all auth-security components (agents + hooks)",
            "source": "./auth-security",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install auth-security@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "cicd-automation-agents",
            "description": "cicd-automation AI agents for specialized tasks (2 agents)",
            "source": "./cicd-automation-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install cicd-automation-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "cicd-automation-commands",
            "description": "cicd-automation slash commands for Claude Code (2 commands)",
            "source": "./cicd-automation-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install cicd-automation-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/gh-actions-monitor",
                "description": "Monitor GitHub Actions workflow runs and delegate failures to appropriate sub-agents",
                "path": "cicd-automation-commands/commands/gh-actions-monitor.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Task",
                  "description": "Monitor GitHub Actions workflow runs and delegate failures to appropriate sub-agents",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# GitHub Actions Monitor\n\nMonitor GitHub Actions workflow runs and automatically delegate failed workflows to specialized sub-agents for resolution.\n\n**variables:**\nRunLimit: $ARGUMENTS\n\n**Usage Examples:**\n\n- `/gh-actions-monitor` - Show last 10 workflow runs\n- `/gh-actions-monitor 20` - Show last 20 workflow runs\n- `/gh-actions-monitor fix` - Analyze failures and delegate fixes\n\n```yaml\ngh_actions_monitor_protocol:\n  instructions:\n    - step: 1\n      action: \"Fetch recent workflow runs using GitHub CLI\"\n      details: \"Use `gh run list --limit ${RunLimit:-10}` to get recent runs\"\n\n    - step: 2\n      action: \"Identify failed or cancelled workflows\"\n      details: \"Filter runs with failure or cancelled status\"\n\n    - step: 3\n      action: \"Analyze failure patterns\"\n      details: \"For each failed run, use `gh run view <run-id>` to get details\"\n\n    - step: 4\n      action: \"Categorize failures by type\"\n      details: |\n        - Test failures â†’ test-automator\n        - Build/compilation errors â†’ language-specific agents\n        - Linting issues â†’ code-reviewer\n        - CI configuration â†’ github-actions-specialist\n        - Security scans â†’ quality-guardian\n\n    - step: 5\n      action: \"Delegate to appropriate sub-agents\"\n      details: \"Use the Task tool to spawn specialized agents for each failure type\"\n\n  workflow_analysis:\n    failure_categories:\n      test_failures:\n        patterns: [\"Test failed\", \"test suite\", \"FAIL\", \"assertion error\"]\n        agent: \"test-automator\"\n        action: \"Fix failing tests and update test suites\"\n\n      build_errors:\n        patterns: [\"build failed\", \"compilation error\", \"module not found\"]\n        agent: \"javascript-craftsman or typescript-expert or python-pro\"\n        action: \"Resolve build/compilation issues\"\n\n      lint_violations:\n        patterns: [\"ESLint\", \"Prettier\", \"linting\", \"code style\"]\n        agent: \"code-reviewer\"\n        action: \"Fix linting violations and code style issues\"\n\n      ci_config_issues:\n        patterns: [\"workflow syntax\", \"invalid workflow\", \"action not found\"]\n        agent: \"github-actions-specialist\"\n        action: \"Fix GitHub Actions workflow configuration\"\n\n      security_issues:\n        patterns: [\"security\", \"vulnerability\", \"audit\", \"CVE\"]\n        agent: \"quality-guardian\"\n        action: \"Address security vulnerabilities\"\n\n  commands:\n    list_runs: \"gh run list --limit ${RunLimit:-10}\"\n    view_run: \"gh run view <run-id>\"\n    view_logs: \"gh run view <run-id> --log\"\n    list_failed: \"gh run list --status failed --limit ${RunLimit:-10}\"\n    download_logs: \"gh run download <run-id>\"\n\n  delegation_templates:\n    - trigger: \"test failures detected\"\n      action: |\n        Use the test-automator sub-agent to analyze and fix the failing tests.\n        Provide the workflow logs and failure details.\n\n    - trigger: \"build errors detected\"\n      action: |\n        Use the appropriate language agent (javascript-craftsman, typescript-expert, or python-pro)\n        to resolve compilation and build issues.\n\n    - trigger: \"workflow configuration issues\"\n      action: |\n        Use the github-actions-specialist sub-agent to fix the GitHub Actions workflow files.\n        Include the error messages and current workflow configuration.\n\n  output_format:\n    dashboard:\n      - \"Workflow run summary with status indicators\"\n      - \"Failed runs grouped by failure type\"\n      - \"Recommended actions for each failure\"\n\n    delegation_report:\n      - \"Agents spawned for each issue\"\n      - \"Expected resolution time\"\n      - \"Follow-up actions required\"\n```\n\n## Instructions\n\n- Run `gh run list --limit ${RunLimit:-10}` to fetch recent workflow runs\n- Identify failed or cancelled workflows from the output\n- For each failed workflow, run `gh run view <run-id>` to get detailed failure information\n- Analyze the failure logs to categorize the type of issue\n- Based on the failure type, use the Task tool to spawn the appropriate sub-agent:\n  - **Test failures**: Use the test-automator sub-agent to fix failing tests\n  - **Build errors**: Use the javascript-craftsman, typescript-expert, or python-pro sub-agent based on the language\n  - **Linting issues**: Use the code-reviewer sub-agent to fix code style violations\n  - **CI configuration**: Use the github-actions-specialist sub-agent to fix workflow files\n  - **Security issues**: Use the quality-guardian sub-agent to address vulnerabilities\n- Provide each sub-agent with the specific failure context and logs\n- Track which issues have been delegated for fixing\n\n## Context\n\nGitHub Actions workflows can fail for various reasons. This command helps identify failures and automatically delegates them to specialized agents who can fix the specific type of issue. The command uses the GitHub CLI which must be authenticated:\n\n```bash\n# Check GitHub CLI authentication\ngh auth status\n\n# Common workflow commands\ngh run list --limit 10           # List recent runs\ngh run view <run-id>            # View run details\ngh run view <run-id> --log      # View full logs\ngh run list --status failed     # List only failed runs\n```\n\n## Output\n\n- **Workflow Dashboard**: Summary of recent runs with status indicators (âœ“ success, âœ— failed, â—‹ cancelled)\n- **Failure Analysis**: Categorized list of failures with recommended fixes\n- **Delegation Report**: List of sub-agents spawned to address each issue\n- **Resolution Tracking**: Status of fixes being implemented by sub-agents"
              },
              {
                "name": "/husky",
                "description": null,
                "path": "cicd-automation-commands/commands/husky.md",
                "frontmatter": null,
                "content": "# Repository Health Verification Protocol\n\nThis command outlines a comprehensive protocol for verifying and maintaining a repository's health.\n\n## Key Goals\n- Verify repo is in a working state\n- Run CI checks\n- Fix any identified issues\n- Prepare files for staging\n\n## Main Steps\n1. Update dependencies (detect package manager by lockfile: package-lock.json â†’ npm, pnpm-lock.yaml â†’ pnpm, yarn.lock â†’ yarn, bun.lockb â†’ bun)\n2. Run linter checks\n3. Verify builds and types\n4. Run test coverage\n5. Sort package.json\n6. Lint packages\n7. Double-check all previous steps\n8. Stage files (avoiding git submodules)\n\n## Error Handling Protocol\n1. Explain why something broke\n2. Propose and implement a fix\n3. Check for similar issues elsewhere\n4. Clean up debugging code\n\n## Important Guidelines\n- Never commit, only stage files\n- Run tests package-by-package\n- Be willing to make necessary fixes\n- Use typescript and tests as safeguards\n\nThe document emphasizes a methodical approach to maintaining code quality and resolving issues systematically."
              }
            ],
            "skills": []
          },
          {
            "name": "cicd-automation",
            "description": "Meta-package: Installs all cicd-automation components (commands + agents)",
            "source": "./cicd-automation",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install cicd-automation@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/gh-actions-monitor",
                "description": "Monitor GitHub Actions workflow runs and delegate failures to appropriate sub-agents",
                "path": "cicd-automation-commands/commands/gh-actions-monitor.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Task",
                  "description": "Monitor GitHub Actions workflow runs and delegate failures to appropriate sub-agents",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# GitHub Actions Monitor\n\nMonitor GitHub Actions workflow runs and automatically delegate failed workflows to specialized sub-agents for resolution.\n\n**variables:**\nRunLimit: $ARGUMENTS\n\n**Usage Examples:**\n\n- `/gh-actions-monitor` - Show last 10 workflow runs\n- `/gh-actions-monitor 20` - Show last 20 workflow runs\n- `/gh-actions-monitor fix` - Analyze failures and delegate fixes\n\n```yaml\ngh_actions_monitor_protocol:\n  instructions:\n    - step: 1\n      action: \"Fetch recent workflow runs using GitHub CLI\"\n      details: \"Use `gh run list --limit ${RunLimit:-10}` to get recent runs\"\n\n    - step: 2\n      action: \"Identify failed or cancelled workflows\"\n      details: \"Filter runs with failure or cancelled status\"\n\n    - step: 3\n      action: \"Analyze failure patterns\"\n      details: \"For each failed run, use `gh run view <run-id>` to get details\"\n\n    - step: 4\n      action: \"Categorize failures by type\"\n      details: |\n        - Test failures â†’ test-automator\n        - Build/compilation errors â†’ language-specific agents\n        - Linting issues â†’ code-reviewer\n        - CI configuration â†’ github-actions-specialist\n        - Security scans â†’ quality-guardian\n\n    - step: 5\n      action: \"Delegate to appropriate sub-agents\"\n      details: \"Use the Task tool to spawn specialized agents for each failure type\"\n\n  workflow_analysis:\n    failure_categories:\n      test_failures:\n        patterns: [\"Test failed\", \"test suite\", \"FAIL\", \"assertion error\"]\n        agent: \"test-automator\"\n        action: \"Fix failing tests and update test suites\"\n\n      build_errors:\n        patterns: [\"build failed\", \"compilation error\", \"module not found\"]\n        agent: \"javascript-craftsman or typescript-expert or python-pro\"\n        action: \"Resolve build/compilation issues\"\n\n      lint_violations:\n        patterns: [\"ESLint\", \"Prettier\", \"linting\", \"code style\"]\n        agent: \"code-reviewer\"\n        action: \"Fix linting violations and code style issues\"\n\n      ci_config_issues:\n        patterns: [\"workflow syntax\", \"invalid workflow\", \"action not found\"]\n        agent: \"github-actions-specialist\"\n        action: \"Fix GitHub Actions workflow configuration\"\n\n      security_issues:\n        patterns: [\"security\", \"vulnerability\", \"audit\", \"CVE\"]\n        agent: \"quality-guardian\"\n        action: \"Address security vulnerabilities\"\n\n  commands:\n    list_runs: \"gh run list --limit ${RunLimit:-10}\"\n    view_run: \"gh run view <run-id>\"\n    view_logs: \"gh run view <run-id> --log\"\n    list_failed: \"gh run list --status failed --limit ${RunLimit:-10}\"\n    download_logs: \"gh run download <run-id>\"\n\n  delegation_templates:\n    - trigger: \"test failures detected\"\n      action: |\n        Use the test-automator sub-agent to analyze and fix the failing tests.\n        Provide the workflow logs and failure details.\n\n    - trigger: \"build errors detected\"\n      action: |\n        Use the appropriate language agent (javascript-craftsman, typescript-expert, or python-pro)\n        to resolve compilation and build issues.\n\n    - trigger: \"workflow configuration issues\"\n      action: |\n        Use the github-actions-specialist sub-agent to fix the GitHub Actions workflow files.\n        Include the error messages and current workflow configuration.\n\n  output_format:\n    dashboard:\n      - \"Workflow run summary with status indicators\"\n      - \"Failed runs grouped by failure type\"\n      - \"Recommended actions for each failure\"\n\n    delegation_report:\n      - \"Agents spawned for each issue\"\n      - \"Expected resolution time\"\n      - \"Follow-up actions required\"\n```\n\n## Instructions\n\n- Run `gh run list --limit ${RunLimit:-10}` to fetch recent workflow runs\n- Identify failed or cancelled workflows from the output\n- For each failed workflow, run `gh run view <run-id>` to get detailed failure information\n- Analyze the failure logs to categorize the type of issue\n- Based on the failure type, use the Task tool to spawn the appropriate sub-agent:\n  - **Test failures**: Use the test-automator sub-agent to fix failing tests\n  - **Build errors**: Use the javascript-craftsman, typescript-expert, or python-pro sub-agent based on the language\n  - **Linting issues**: Use the code-reviewer sub-agent to fix code style violations\n  - **CI configuration**: Use the github-actions-specialist sub-agent to fix workflow files\n  - **Security issues**: Use the quality-guardian sub-agent to address vulnerabilities\n- Provide each sub-agent with the specific failure context and logs\n- Track which issues have been delegated for fixing\n\n## Context\n\nGitHub Actions workflows can fail for various reasons. This command helps identify failures and automatically delegates them to specialized agents who can fix the specific type of issue. The command uses the GitHub CLI which must be authenticated:\n\n```bash\n# Check GitHub CLI authentication\ngh auth status\n\n# Common workflow commands\ngh run list --limit 10           # List recent runs\ngh run view <run-id>            # View run details\ngh run view <run-id> --log      # View full logs\ngh run list --status failed     # List only failed runs\n```\n\n## Output\n\n- **Workflow Dashboard**: Summary of recent runs with status indicators (âœ“ success, âœ— failed, â—‹ cancelled)\n- **Failure Analysis**: Categorized list of failures with recommended fixes\n- **Delegation Report**: List of sub-agents spawned to address each issue\n- **Resolution Tracking**: Status of fixes being implemented by sub-agents"
              },
              {
                "name": "/husky",
                "description": null,
                "path": "cicd-automation-commands/commands/husky.md",
                "frontmatter": null,
                "content": "# Repository Health Verification Protocol\n\nThis command outlines a comprehensive protocol for verifying and maintaining a repository's health.\n\n## Key Goals\n- Verify repo is in a working state\n- Run CI checks\n- Fix any identified issues\n- Prepare files for staging\n\n## Main Steps\n1. Update dependencies (detect package manager by lockfile: package-lock.json â†’ npm, pnpm-lock.yaml â†’ pnpm, yarn.lock â†’ yarn, bun.lockb â†’ bun)\n2. Run linter checks\n3. Verify builds and types\n4. Run test coverage\n5. Sort package.json\n6. Lint packages\n7. Double-check all previous steps\n8. Stage files (avoiding git submodules)\n\n## Error Handling Protocol\n1. Explain why something broke\n2. Propose and implement a fix\n3. Check for similar issues elsewhere\n4. Clean up debugging code\n\n## Important Guidelines\n- Never commit, only stage files\n- Run tests package-by-package\n- Be willing to make necessary fixes\n- Use typescript and tests as safeguards\n\nThe document emphasizes a methodical approach to maintaining code quality and resolving issues systematically."
              },
              {
                "name": "/gh-actions-monitor",
                "description": "Monitor GitHub Actions workflow runs and delegate failures to appropriate sub-agents",
                "path": "cicd-automation/commands/gh-actions-monitor.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Task",
                  "description": "Monitor GitHub Actions workflow runs and delegate failures to appropriate sub-agents",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# GitHub Actions Monitor\n\nMonitor GitHub Actions workflow runs and automatically delegate failed workflows to specialized sub-agents for resolution.\n\n**variables:**\nRunLimit: $ARGUMENTS\n\n**Usage Examples:**\n\n- `/gh-actions-monitor` - Show last 10 workflow runs\n- `/gh-actions-monitor 20` - Show last 20 workflow runs\n- `/gh-actions-monitor fix` - Analyze failures and delegate fixes\n\n```yaml\ngh_actions_monitor_protocol:\n  instructions:\n    - step: 1\n      action: \"Fetch recent workflow runs using GitHub CLI\"\n      details: \"Use `gh run list --limit ${RunLimit:-10}` to get recent runs\"\n\n    - step: 2\n      action: \"Identify failed or cancelled workflows\"\n      details: \"Filter runs with failure or cancelled status\"\n\n    - step: 3\n      action: \"Analyze failure patterns\"\n      details: \"For each failed run, use `gh run view <run-id>` to get details\"\n\n    - step: 4\n      action: \"Categorize failures by type\"\n      details: |\n        - Test failures â†’ test-automator\n        - Build/compilation errors â†’ language-specific agents\n        - Linting issues â†’ code-reviewer\n        - CI configuration â†’ github-actions-specialist\n        - Security scans â†’ quality-guardian\n\n    - step: 5\n      action: \"Delegate to appropriate sub-agents\"\n      details: \"Use the Task tool to spawn specialized agents for each failure type\"\n\n  workflow_analysis:\n    failure_categories:\n      test_failures:\n        patterns: [\"Test failed\", \"test suite\", \"FAIL\", \"assertion error\"]\n        agent: \"test-automator\"\n        action: \"Fix failing tests and update test suites\"\n\n      build_errors:\n        patterns: [\"build failed\", \"compilation error\", \"module not found\"]\n        agent: \"javascript-craftsman or typescript-expert or python-pro\"\n        action: \"Resolve build/compilation issues\"\n\n      lint_violations:\n        patterns: [\"ESLint\", \"Prettier\", \"linting\", \"code style\"]\n        agent: \"code-reviewer\"\n        action: \"Fix linting violations and code style issues\"\n\n      ci_config_issues:\n        patterns: [\"workflow syntax\", \"invalid workflow\", \"action not found\"]\n        agent: \"github-actions-specialist\"\n        action: \"Fix GitHub Actions workflow configuration\"\n\n      security_issues:\n        patterns: [\"security\", \"vulnerability\", \"audit\", \"CVE\"]\n        agent: \"quality-guardian\"\n        action: \"Address security vulnerabilities\"\n\n  commands:\n    list_runs: \"gh run list --limit ${RunLimit:-10}\"\n    view_run: \"gh run view <run-id>\"\n    view_logs: \"gh run view <run-id> --log\"\n    list_failed: \"gh run list --status failed --limit ${RunLimit:-10}\"\n    download_logs: \"gh run download <run-id>\"\n\n  delegation_templates:\n    - trigger: \"test failures detected\"\n      action: |\n        Use the test-automator sub-agent to analyze and fix the failing tests.\n        Provide the workflow logs and failure details.\n\n    - trigger: \"build errors detected\"\n      action: |\n        Use the appropriate language agent (javascript-craftsman, typescript-expert, or python-pro)\n        to resolve compilation and build issues.\n\n    - trigger: \"workflow configuration issues\"\n      action: |\n        Use the github-actions-specialist sub-agent to fix the GitHub Actions workflow files.\n        Include the error messages and current workflow configuration.\n\n  output_format:\n    dashboard:\n      - \"Workflow run summary with status indicators\"\n      - \"Failed runs grouped by failure type\"\n      - \"Recommended actions for each failure\"\n\n    delegation_report:\n      - \"Agents spawned for each issue\"\n      - \"Expected resolution time\"\n      - \"Follow-up actions required\"\n```\n\n## Instructions\n\n- Run `gh run list --limit ${RunLimit:-10}` to fetch recent workflow runs\n- Identify failed or cancelled workflows from the output\n- For each failed workflow, run `gh run view <run-id>` to get detailed failure information\n- Analyze the failure logs to categorize the type of issue\n- Based on the failure type, use the Task tool to spawn the appropriate sub-agent:\n  - **Test failures**: Use the test-automator sub-agent to fix failing tests\n  - **Build errors**: Use the javascript-craftsman, typescript-expert, or python-pro sub-agent based on the language\n  - **Linting issues**: Use the code-reviewer sub-agent to fix code style violations\n  - **CI configuration**: Use the github-actions-specialist sub-agent to fix workflow files\n  - **Security issues**: Use the quality-guardian sub-agent to address vulnerabilities\n- Provide each sub-agent with the specific failure context and logs\n- Track which issues have been delegated for fixing\n\n## Context\n\nGitHub Actions workflows can fail for various reasons. This command helps identify failures and automatically delegates them to specialized agents who can fix the specific type of issue. The command uses the GitHub CLI which must be authenticated:\n\n```bash\n# Check GitHub CLI authentication\ngh auth status\n\n# Common workflow commands\ngh run list --limit 10           # List recent runs\ngh run view <run-id>            # View run details\ngh run view <run-id> --log      # View full logs\ngh run list --status failed     # List only failed runs\n```\n\n## Output\n\n- **Workflow Dashboard**: Summary of recent runs with status indicators (âœ“ success, âœ— failed, â—‹ cancelled)\n- **Failure Analysis**: Categorized list of failures with recommended fixes\n- **Delegation Report**: List of sub-agents spawned to address each issue\n- **Resolution Tracking**: Status of fixes being implemented by sub-agents"
              },
              {
                "name": "/husky",
                "description": null,
                "path": "cicd-automation/commands/husky.md",
                "frontmatter": null,
                "content": "# Repository Health Verification Protocol\n\nThis command outlines a comprehensive protocol for verifying and maintaining a repository's health.\n\n## Key Goals\n- Verify repo is in a working state\n- Run CI checks\n- Fix any identified issues\n- Prepare files for staging\n\n## Main Steps\n1. Update dependencies (detect package manager by lockfile: package-lock.json â†’ npm, pnpm-lock.yaml â†’ pnpm, yarn.lock â†’ yarn, bun.lockb â†’ bun)\n2. Run linter checks\n3. Verify builds and types\n4. Run test coverage\n5. Sort package.json\n6. Lint packages\n7. Double-check all previous steps\n8. Stage files (avoiding git submodules)\n\n## Error Handling Protocol\n1. Explain why something broke\n2. Propose and implement a fix\n3. Check for similar issues elsewhere\n4. Clean up debugging code\n\n## Important Guidelines\n- Never commit, only stage files\n- Run tests package-by-package\n- Be willing to make necessary fixes\n- Use typescript and tests as safeguards\n\nThe document emphasizes a methodical approach to maintaining code quality and resolving issues systematically."
              }
            ],
            "skills": []
          },
          {
            "name": "code-quality-enforcement-agents",
            "description": "code-quality-enforcement AI agents for specialized tasks (2 agents)",
            "source": "./code-quality-enforcement-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install code-quality-enforcement-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "code-quality-enforcement-commands",
            "description": "code-quality-enforcement slash commands for Claude Code (1 commands)",
            "source": "./code-quality-enforcement-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install code-quality-enforcement-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/enforce-logging-discipline",
                "description": null,
                "path": "code-quality-enforcement-commands/commands/enforce-logging-discipline.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Read, Write, Edit, MultiEdit, Grep, Glob, Bash\ndescription: Enforce logging discipline protocol - eliminate console statements and implement structured logging\nargument-hint: [TARGET_DIRECTORY] [LANGUAGE] [CHECK_ONLY]\n---\n\n# Enforce Logging Discipline\n\nScan `TARGET_DIRECTORY` for logging violations, eliminate all console statements, and implement structured logging following the discipline protocol. Save enforcement report to `OUTPUT_DIRECTORY` with violations found and fixes applied.\n\n## Variables:\n\nTARGET_DIRECTORY: $1\nLANGUAGE: $2\nCHECK_ONLY: $3\nOUTPUT_DIRECTORY: .claude/data/\nPROTOCOL_FILE: ai-docs/logging-discipline.md\n\n## Instructions:\n\n- Read `PROTOCOL_FILE` to understand the complete logging discipline requirements\n- Scan `TARGET_DIRECTORY` for console.*, print(), and other logging violations\n- For `LANGUAGE` JavaScript/TypeScript: configure ESLint no-console rule and implement Pino logger\n- For `LANGUAGE` Python: configure Ruff rules and implement structlog\n- If `CHECK_ONLY` is true, report violations without making changes\n- Apply all fixes following the protocol's structured logging patterns\n- Generate enforcement report with before/after comparison\n\n## Workflow:\n\n1. Read `PROTOCOL_FILE` to understand logging discipline requirements\n2. Use Grep to scan `TARGET_DIRECTORY` for console.log, console.error, print() violations\n3. Identify `LANGUAGE` from file extensions (.js, .ts, .py) if not specified\n4. Check existing logger configuration (ESLint, Pino, structlog)\n5. If `CHECK_ONLY` is false, configure appropriate linting rules for `LANGUAGE`\n6. Install and configure structured logging library (Pino for JS/TS, structlog for Python)\n7. Use MultiEdit to replace all console.* statements with structured logger calls\n8. Ensure stdout/stderr separation follows protocol requirements\n9. Add correlation IDs and redaction configuration\n10. Run linting validation to confirm no violations remain\n11. Generate enforcement report with violations count and fixes applied\n12. Save report to `OUTPUT_DIRECTORY`/logging-discipline-report.md\n\n## Report:\n\nLogging Discipline Enforced\n\nFile: `OUTPUT_DIRECTORY`/logging-discipline-report.md\nTarget: `TARGET_DIRECTORY` (`LANGUAGE` files)\nViolations Fixed:\n- Console statements eliminated: [count]\n- Structured logging implemented: [yes/no]\n- ESLint/Ruff rules configured: [yes/no]\nProtocol Compliance: [compliant/violations remaining]\n\n## Relevant Files:\n\n- [@ai-docs/logging-discipline.md]\n"
              }
            ],
            "skills": []
          },
          {
            "name": "code-quality-enforcement-hooks",
            "description": "code-quality-enforcement automation hooks for development workflow",
            "source": "./code-quality-enforcement-hooks",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install code-quality-enforcement-hooks@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "code-quality-enforcement",
            "description": "Meta-package: Installs all code-quality-enforcement components (commands + agents + hooks)",
            "source": "./code-quality-enforcement",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install code-quality-enforcement@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/enforce-logging-discipline",
                "description": null,
                "path": "code-quality-enforcement-commands/commands/enforce-logging-discipline.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Read, Write, Edit, MultiEdit, Grep, Glob, Bash\ndescription: Enforce logging discipline protocol - eliminate console statements and implement structured logging\nargument-hint: [TARGET_DIRECTORY] [LANGUAGE] [CHECK_ONLY]\n---\n\n# Enforce Logging Discipline\n\nScan `TARGET_DIRECTORY` for logging violations, eliminate all console statements, and implement structured logging following the discipline protocol. Save enforcement report to `OUTPUT_DIRECTORY` with violations found and fixes applied.\n\n## Variables:\n\nTARGET_DIRECTORY: $1\nLANGUAGE: $2\nCHECK_ONLY: $3\nOUTPUT_DIRECTORY: .claude/data/\nPROTOCOL_FILE: ai-docs/logging-discipline.md\n\n## Instructions:\n\n- Read `PROTOCOL_FILE` to understand the complete logging discipline requirements\n- Scan `TARGET_DIRECTORY` for console.*, print(), and other logging violations\n- For `LANGUAGE` JavaScript/TypeScript: configure ESLint no-console rule and implement Pino logger\n- For `LANGUAGE` Python: configure Ruff rules and implement structlog\n- If `CHECK_ONLY` is true, report violations without making changes\n- Apply all fixes following the protocol's structured logging patterns\n- Generate enforcement report with before/after comparison\n\n## Workflow:\n\n1. Read `PROTOCOL_FILE` to understand logging discipline requirements\n2. Use Grep to scan `TARGET_DIRECTORY` for console.log, console.error, print() violations\n3. Identify `LANGUAGE` from file extensions (.js, .ts, .py) if not specified\n4. Check existing logger configuration (ESLint, Pino, structlog)\n5. If `CHECK_ONLY` is false, configure appropriate linting rules for `LANGUAGE`\n6. Install and configure structured logging library (Pino for JS/TS, structlog for Python)\n7. Use MultiEdit to replace all console.* statements with structured logger calls\n8. Ensure stdout/stderr separation follows protocol requirements\n9. Add correlation IDs and redaction configuration\n10. Run linting validation to confirm no violations remain\n11. Generate enforcement report with violations count and fixes applied\n12. Save report to `OUTPUT_DIRECTORY`/logging-discipline-report.md\n\n## Report:\n\nLogging Discipline Enforced\n\nFile: `OUTPUT_DIRECTORY`/logging-discipline-report.md\nTarget: `TARGET_DIRECTORY` (`LANGUAGE` files)\nViolations Fixed:\n- Console statements eliminated: [count]\n- Structured logging implemented: [yes/no]\n- ESLint/Ruff rules configured: [yes/no]\nProtocol Compliance: [compliant/violations remaining]\n\n## Relevant Files:\n\n- [@ai-docs/logging-discipline.md]\n"
              },
              {
                "name": "/enforce-logging-discipline",
                "description": null,
                "path": "code-quality-enforcement/commands/enforce-logging-discipline.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Read, Write, Edit, MultiEdit, Grep, Glob, Bash\ndescription: Enforce logging discipline protocol - eliminate console statements and implement structured logging\nargument-hint: [TARGET_DIRECTORY] [LANGUAGE] [CHECK_ONLY]\n---\n\n# Enforce Logging Discipline\n\nScan `TARGET_DIRECTORY` for logging violations, eliminate all console statements, and implement structured logging following the discipline protocol. Save enforcement report to `OUTPUT_DIRECTORY` with violations found and fixes applied.\n\n## Variables:\n\nTARGET_DIRECTORY: $1\nLANGUAGE: $2\nCHECK_ONLY: $3\nOUTPUT_DIRECTORY: .claude/data/\nPROTOCOL_FILE: ai-docs/logging-discipline.md\n\n## Instructions:\n\n- Read `PROTOCOL_FILE` to understand the complete logging discipline requirements\n- Scan `TARGET_DIRECTORY` for console.*, print(), and other logging violations\n- For `LANGUAGE` JavaScript/TypeScript: configure ESLint no-console rule and implement Pino logger\n- For `LANGUAGE` Python: configure Ruff rules and implement structlog\n- If `CHECK_ONLY` is true, report violations without making changes\n- Apply all fixes following the protocol's structured logging patterns\n- Generate enforcement report with before/after comparison\n\n## Workflow:\n\n1. Read `PROTOCOL_FILE` to understand logging discipline requirements\n2. Use Grep to scan `TARGET_DIRECTORY` for console.log, console.error, print() violations\n3. Identify `LANGUAGE` from file extensions (.js, .ts, .py) if not specified\n4. Check existing logger configuration (ESLint, Pino, structlog)\n5. If `CHECK_ONLY` is false, configure appropriate linting rules for `LANGUAGE`\n6. Install and configure structured logging library (Pino for JS/TS, structlog for Python)\n7. Use MultiEdit to replace all console.* statements with structured logger calls\n8. Ensure stdout/stderr separation follows protocol requirements\n9. Add correlation IDs and redaction configuration\n10. Run linting validation to confirm no violations remain\n11. Generate enforcement report with violations count and fixes applied\n12. Save report to `OUTPUT_DIRECTORY`/logging-discipline-report.md\n\n## Report:\n\nLogging Discipline Enforced\n\nFile: `OUTPUT_DIRECTORY`/logging-discipline-report.md\nTarget: `TARGET_DIRECTORY` (`LANGUAGE` files)\nViolations Fixed:\n- Console statements eliminated: [count]\n- Structured logging implemented: [yes/no]\n- ESLint/Ruff rules configured: [yes/no]\nProtocol Compliance: [compliant/violations remaining]\n\n## Relevant Files:\n\n- [@ai-docs/logging-discipline.md]\n"
              }
            ],
            "skills": []
          },
          {
            "name": "core-essentials-agents",
            "description": "core-essentials AI agents for specialized tasks (4 agents)",
            "source": "./core-essentials-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install core-essentials-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "core-essentials-commands",
            "description": "core-essentials slash commands for Claude Code (8 commands)",
            "source": "./core-essentials-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install core-essentials-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/analyze-codebase",
                "description": "Generate comprehensive analysis and documentation of entire codebase",
                "path": "core-essentials-commands/commands/analyze-codebase.md",
                "frontmatter": {
                  "allowed-tools": "Bash(find:*), Bash(ls:*), Bash(tree:*), Bash(grep:*), Bash(wc:*), Bash(du:*), Bash(head:*), Bash(tail:*), Bash(cat:*), Bash(touch:*)",
                  "description": "Generate comprehensive analysis and documentation of entire codebase"
                },
                "content": "# Comprehensive Codebase Analysis\n\n## Project Discovery Phase\n\n### Directory Structure\n!`find . -type d -not -path \"./node_modules/*\" -not -path \"./.git/*\" -not -path \"./dist/*\" -not -path \"./build/*\" -not -path \"./.next/*\" -not -path \"./coverage/*\" | sort`\n\n### Complete File Tree\n!`eza --tree --all --level=4 --ignore-glob='node_modules|.git|dist|build|.next|coverage|*.log'`\n\n### File Count and Size Analysis\n- Total files: !`find . -type f -not -path \"./node_modules/*\" -not -path \"./.git/*\" | wc -l`\n- Code files: !`find . -name \"*.js\" -o -name \"*.ts\" -o -name \"*.jsx\" -o -name \"*.tsx\" -o -name \"*.py\" -o -name \"*.java\" -o -name \"*.php\" -o -name \"*.rb\" -o -name \"*.go\" -o -name \"*.rs\" -o -name \"*.cpp\" -o -name \"*.c\" | grep -v node_modules | wc -l`\n- Project size: !`find . -type f -not -path \"./node_modules/*\" -not -path \"./.git/*\" -not -path \"./dist/*\" -not -path \"./build/*\" -not -path \"./.next/*\" -not -path \"./coverage/*\" -exec du -ch {} + 2>/dev/null | grep total$ | cut -f1`\n\n## Configuration Files Analysis\n\n### Package Management\n- Package.json: @package.json\n- Package-lock.json exists: !`ls package-lock.json 2>/dev/null || echo \"Not found\"`\n- Yarn.lock exists: !`ls yarn.lock 2>/dev/null || echo \"Not found\"`\n- Requirements.txt: @requirements.txt\n- Gemfile: @Gemfile\n- Cargo.toml: @Cargo.toml\n- Go.mod: @go.mod\n- Composer.json: @composer.json\n\n### Build & Dev Tools\n- Webpack config: @webpack.config.js\n- Vite config: @vite.config.js\n- Rollup config: @rollup.config.js\n- Babel config: @.babelrc\n- ESLint config: @.eslintrc.js\n- Prettier config: @.prettierrc\n- TypeScript config: @tsconfig.json\n- Tailwind config: @tailwind.config.js\n- Next.js config: @next.config.js\n\n### Environment & Docker\n- .env files: !`find . -name \".env*\" -type f 2>/dev/null || echo \"No .env files found\"`\n- Docker files: !`find . -name \"Dockerfile*\" -o -name \"docker-compose*\" 2>/dev/null || echo \"No Docker files found\"`\n- Kubernetes files: !`find . -name \"*.yaml\" -o -name \"*.yml\" 2>/dev/null | grep -E \"(k8s|kubernetes|deployment|service)\" || echo \"No Kubernetes files found\"`\n\n### CI/CD Configuration\n- GitHub Actions: !`find .github -name \"*.yml\" -o -name \"*.yaml\" 2>/dev/null || echo \"No GitHub Actions\"`\n- GitLab CI: @.gitlab-ci.yml\n- Travis CI: @.travis.yml\n- Circle CI: @.circleci/config.yml\n\n## Source Code Analysis\n\n### Main Application Files\n- Main entry points: !`find . -name \"main.*\" -o -name \"index.*\" -o -name \"app.*\" -o -name \"server.*\" | grep -v node_modules | head -10`\n- Routes/Controllers: !`find . -path \"*/routes/*\" -o -path \"*/controllers/*\" -o -path \"*/api/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No routes/controllers found\"`\n- Models/Schemas: !`find . -path \"*/models/*\" -o -path \"*/schemas/*\" -o -path \"*/entities/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No models/schemas found\"`\n- Components: !`find . -path \"*/components/*\" -o -path \"*/views/*\" -o -path \"*/pages/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No components/views/pages found\"`\n\n### Database & Storage\n- Database configs: !`find . -name \"*database*\" -o -name \"*db*\" -o -name \"*connection*\" | grep -v node_modules | head -10`\n- Migration files: !`find . -path \"*/migrations/*\" -o -path \"*/migrate/*\" 2>/dev/null | head -10 || echo \"No migration files found\"`\n- Seed files: !`find . -path \"*/seeds/*\" -o -path \"*/seeders/*\" 2>/dev/null | head -10 || echo \"No seed files found\"`\n\n### Testing Files\n- Test files: !`find . -name \"*test*\" -o -name \"*spec*\" | grep -v node_modules | head -15`\n- Test config: @jest.config.js\n\n### API Documentation\n- API docs: !`find . \\( -name \"*api*\" -a -name \"*.md\" \\) -o -name \"swagger*\" -o -name \"openapi*\" 2>/dev/null | head -10 || echo \"No API documentation found\"`\n\n## Key Files Content Analysis\n\n### Root Configuration Files\n@README.md\n@LICENSE\n@.gitignore\n\n### Main Application Entry Points\n!`find . -name \"index.js\" -o -name \"index.ts\" -o -name \"main.js\" -o -name \"main.ts\" -o -name \"app.js\" -o -name \"app.ts\" -o -name \"server.js\" -o -name \"server.ts\" 2>/dev/null | grep -v node_modules | head -5 | while read file; do echo \"=== $file ===\"; head -50 \"$file\" 2>/dev/null || echo \"Could not read $file\"; echo; done || echo \"No main entry point files found\"`\n\n## Your Task\n\nBased on all the discovered information above, create a comprehensive analysis that includes:\n\n## 1. Project Overview\n- Project type (web app, API, library, etc.)\n- Tech stack and frameworks\n- Architecture pattern (MVC, microservices, etc.)\n- Language(s) and versions\n\n## 2. Detailed Directory Structure Analysis\nFor each major directory, explain:\n- Purpose and role in the application\n- Key files and their functions\n- How it connects to other parts\n\n## 3. File-by-File Breakdown\nOrganize by category:\n- **Core Application Files**: Main entry points, routing, business logic\n- **Configuration Files**: Build tools, environment, deployment\n- **Data Layer**: Models, database connections, migrations\n- **Frontend/UI**: Components, pages, styles, assets  \n- **Testing**: Test files, mocks, fixtures\n- **Documentation**: README, API docs, guides\n- **DevOps**: CI/CD, Docker, deployment scripts\n\n## 4. API Endpoints Analysis\nIf applicable, document:\n- All discovered endpoints and their methods\n- Authentication/authorization patterns\n- Request/response formats\n- API versioning strategy\n\n## 5. Architecture Deep Dive\nExplain:\n- Overall application architecture\n- Data flow and request lifecycle\n- Key design patterns used\n- Dependencies between modules\n\n## 6. Environment & Setup Analysis\nDocument:\n- Required environment variables\n- Installation and setup process\n- Development workflow\n- Production deployment strategy\n\n## 7. Technology Stack Breakdown\nList and explain:\n- Runtime environment\n- Frameworks and libraries\n- Database technologies\n- Build tools and bundlers\n- Testing frameworks\n- Deployment technologies\n\n## 8. Visual Architecture Diagram\nCreate a comprehensive diagram showing:\n- High-level system architecture\n- Component relationships\n- Data flow\n- External integrations\n- File structure hierarchy\n\nUse ASCII art, mermaid syntax, or detailed text representation to show:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Frontend    â”‚â”€â”€â”€â”€â–¶â”‚      API        â”‚â”€â”€â”€â”€â–¶â”‚    Database     â”‚\nâ”‚   (React/Vue)   â”‚     â”‚   (Node/Flask)  â”‚     â”‚ (Postgres/Mongo)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n## 9. Key Insights & Recommendations\nProvide:\n- Code quality assessment\n- Potential improvements\n- Security considerations\n- Performance optimization opportunities\n- Maintainability suggestions\n\nThink deeply about the codebase structure and provide comprehensive insights that would be valuable for new developers joining the project or for architectural decision-making.\n\nAt the end, write all of the output into a file called \"codebase_analysis.md\""
              },
              {
                "name": "/build",
                "description": "Build the codebase based on a plan using structured approach",
                "path": "core-essentials-commands/commands/build.md",
                "frontmatter": {
                  "description": "Build the codebase based on a plan using structured approach",
                  "arguement-hint": [
                    "path-to-plan"
                  ],
                  "allowed-tools": "Bash, Read, Write, Glob, Grep, Task"
                },
                "content": "# Build\n\nFollow the `Workflow` to implement the `PATH_TO_PLAN` then `Report` the completed work.\n\n## Variables\n\nPATH_TO_PLAN: $ARGUMENTS\n\n## Workflow\n\n### 1. Initial Setup\n- If no `PATH_TO_PLAN` is provided, STOP immediately and ask the user to provide it\n\n### 2. Plan Analysis \n- Read the plan at `PATH_TO_PLAN`. Think hard about the plan and write the code to implement it into the codebase. \n\n### 3. Memory Management\n- Document any architectural decisions or patterns discovered\n\n## Report\n\n- Summarize the work you've just done in a concise bullet point list\n- Report the files and total lines changed with `git diff --stat`"
              },
              {
                "name": "/code-review",
                "description": "Perform comprehensive code review analysis of recent changes with semantic code understanding",
                "path": "core-essentials-commands/commands/code-review.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(git branch:*), mcp__serena__get_symbols_overview, mcp__serena__find_symbol, mcp__serena__find_referencing_symbols, mcp__serena__search_for_pattern, mcp__serena__list_dir",
                  "description": "Perform comprehensive code review analysis of recent changes with semantic code understanding",
                  "argument-hint": [
                    {
                      "Optional": "specify file paths or commit range for focused review"
                    }
                  ]
                },
                "content": "# Code Review Analysis\n\nAnalyze `RECENT_CHANGES` using semantic code understanding to perform comprehensive code review covering quality, security, performance, testing, and documentation with specific actionable feedback saved to `REVIEW_OUTPUT`.\n\n## Variables:\nTARGET_SCOPE: $1 (optional - specific files, commit range, or \"recent\" for latest changes)\nGIT_CONTEXT: recent changes and commit history\nREVIEW_CRITERIA: code quality, security, performance, testing, documentation\nANALYSIS_DEPTH: semantic symbol analysis with cross-references\nREVIEW_OUTPUT: logs/code-review-analysis.md\n\n## Workflow:\n\n1. Gather git context using `git status`, `git diff HEAD~1`, `git log --oneline -5`, and `git branch --show-current`\n2. Identify changed files from git diff output for semantic analysis scope\n3. Use `mcp__serena__list_dir` to understand project structure and identify key directories\n4. For each modified file, use `mcp__serena__get_symbols_overview` to understand code structure and symbols\n5. Use `mcp__serena__find_symbol` with `include_body=true` for detailed analysis of modified functions/classes\n6. Apply `mcp__serena__find_referencing_symbols` to understand impact of changes on dependent code\n7. Use `mcp__serena__search_for_pattern` to identify potential security patterns, anti-patterns, or code smells\n8. Analyze code quality: readability, maintainability, adherence to project conventions and best practices\n9. Evaluate security: scan for vulnerabilities, input validation, authentication, authorization issues\n10. Assess performance: identify bottlenecks, inefficient algorithms, resource usage patterns\n11. Review testing: evaluate test coverage, test quality, missing test scenarios for changed code\n12. Verify documentation: check inline comments, README updates, API documentation completeness\n13. Generate specific, actionable feedback with file:line references and suggested improvements\n14. Save comprehensive review analysis to `REVIEW_OUTPUT` with prioritized recommendations\n\n## Report:\n\nCode Review Analysis Complete\n\nFile: `REVIEW_OUTPUT`\nTopic: Comprehensive semantic code review of `TARGET_SCOPE` with actionable recommendations\nKey Components:\n- Git context analysis with change scope identification\n- Semantic symbol analysis using serena-mcp tools for deep code understanding\n- Multi-dimensional review covering quality, security, performance, testing, documentation\n- Specific actionable feedback with file:line references and improvement suggestions"
              },
              {
                "name": "/commit",
                "description": "Intelligent commits with hook-aware strategy detection",
                "path": "core-essentials-commands/commands/commit.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Write, Task",
                  "description": "Intelligent commits with hook-aware strategy detection",
                  "argument-hint": [
                    {
                      "Optional": "--no-verify or custom message"
                    }
                  ]
                },
                "content": "# Commit\n\nUse the git-flow-manager sub-agent to intelligently analyze staging area and project formatting hooks, then execute optimal commit strategy (PARALLEL/COORDINATED/HYBRID) to prevent conflicts while maintaining commit organization. Parse `$ARGUMENTS` for commit options, run pre-commit checks, analyze changes for atomic splitting, and execute commits with conventional messages.\n\n## Variables:\nCOMMIT_OPTIONS: $ARGUMENTS\nSTRATEGY_MODE: auto-detected\nCOMMIT_COUNT: auto-calculated\nHOOK_ANALYSIS: auto-performed\n\n## Instructions:\n\n- Parse `COMMIT_OPTIONS` to extract flags like `--no-verify` or custom messages\n- Use the git-flow-manager sub-agent for comprehensive workflow management with automatic strategy detection\n- Auto-detect formatting hook aggressiveness and choose optimal commit strategy\n- Run pre-commit checks unless `--no-verify` flag is present\n- Validate `.gitignore` configuration and alert for large files (>1MB)\n- Auto-stage modified files if none staged, analyze changes for atomic splitting\n- Execute commits using detected strategy with conventional messages and emoji\n- Include issue references for GitHub/Linear integration when applicable\n\n## Workflow:\n\n1. Deploy git-flow-manager sub-agent with strategy detection capabilities\n2. Run `!git status --porcelain` to analyze current repository state\n3. Execute formatting hook analysis to determine optimal commit strategy\n4. Check for `--no-verify` flag in `COMMIT_OPTIONS`, skip pre-commit checks if present\n5. Run pre-commit validation: `!pnpm lint`, `!pnpm build`, `!pnpm generate:docs`\n6. Validate `.gitignore` configuration and check for large files\n7. Auto-stage files with `!git add .` if no files currently staged\n8. Execute `!git diff --staged --name-status` to analyze staged changes\n9. Analyze changes for atomic commit splitting opportunities\n10. Execute commits using detected strategy (PARALLEL/COORDINATED/HYBRID)\n11. Generate conventional commit messages with appropriate emoji from @ai-docs/emoji-commit-ref.yaml\n12. Include issue references in commit body for automatic linking\n13. Execute `!git commit` with generated messages\n14. Display commit summary using `!git log --oneline -1`\n\n## Report:\n\nIntelligent Commit Complete\n\nStrategy: `STRATEGY_MODE` (auto-detected based on formatting hook analysis)\nFiles: `COMMIT_COUNT` commits created and executed\nTopic: Hook-aware commit processing with adaptive strategy selection\nKey Components:\n- Automatic strategy detection preventing formatting hook conflicts\n- Conventional commit messages with appropriate emoji\n- Pre-commit validation and quality gates\n- Atomic commit splitting for logical organization\n- GitHub/Linear issue integration\n- Clean working directory achieved without conflicts\n\n## Relevant Files:\n\n- @~/.claude/agents/git-flow-manager.md\n- @ai-docs/emoji-commit-ref.yaml"
              },
              {
                "name": "/git-status",
                "description": "Analyze current git repository state and differences from remote",
                "path": "core-essentials-commands/commands/git-status.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read",
                  "description": "Analyze current git repository state and differences from remote"
                },
                "content": "# Git Status\n\nAnalyze current git repository state including status, branch information, differences from remote, and recent commits. Use $ARGUMENTS for specific branch or filter options, provide actionable summary with next steps recommendations highlighting any uncommitted changes or divergence from remote branch."
              },
              {
                "name": "/go",
                "description": "Advanced code analysis and development using semantic tools, documentation, and structured decision making",
                "path": "core-essentials-commands/commands/go.md",
                "frontmatter": {
                  "allowed-tools": "mcp__serena__list_dir, mcp__serena__find_file, mcp__serena__search_for_pattern, mcp__serena__get_symbols_overview, mcp__serena__find_symbol, mcp__serena__find_referencing_symbols, mcp__serena__replace_symbol_body, mcp__serena__insert_after_symbol, mcp__serena__insert_before_symbol, mcp__context7__resolve-library-id, mcp__context7__get-library-docs, mcp__sequential-thinking__process_thought, mcp__sequential-thinking__generate_summary, Read",
                  "description": "Advanced code analysis and development using semantic tools, documentation, and structured decision making",
                  "argument-hint": [
                    "task description or development requirement"
                  ],
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Go\n\nAdvanced code analysis, development, and decision-making command that uses `USER_TASK` to analyze requirements through semantic code tools, up-to-date documentation, and structured thinking processes.\n\n## Variables:\n\nUSER_TASK: $1\nPROJECT_ROOT: .\nCLAUDE_CONFIG: CLAUDE.md\n\n## Instructions:\n\n- Read `CLAUDE_CONFIG` to understand project context and requirements\n- Use `USER_TASK` to determine specific analysis or development needs\n- Apply serena tools for semantic code retrieval and precise editing operations\n- Leverage context7 for current third-party library documentation and examples\n- Use sequential thinking for all decision-making processes and complex analysis\n- Maintain structured approach with clear reasoning for all actions taken\n\n## Workflow:\n\n1. Read `CLAUDE_CONFIG` file to understand project structure and context\n2. Use sequential thinking to process and break down `USER_TASK` requirements\n3. Use serena semantic tools to explore relevant codebase sections and symbols\n4. Retrieve up-to-date documentation using context7 for any third-party dependencies\n5. Apply structured decision-making through sequential thinking for implementation approach\n6. Execute precise code analysis or modifications using serena's semantic editing tools\n7. Document reasoning and decisions made throughout the process\n8. Generate summary of actions taken and results achieved\n9. Provide clear recommendations for next steps or follow-up actions\n\n## Report:\n\nAdvanced Analysis Complete\n\nTask: `USER_TASK` processed using semantic tools and structured thinking\nKey Components:\n\n- Project context analysis from `CLAUDE_CONFIG`\n- Semantic code exploration and analysis using serena tools\n- Third-party documentation retrieval via context7\n- Structured decision-making through sequential thinking process\n- Precise code modifications or analysis results\n- Clear reasoning documentation and next step recommendations\n\n## Relevant Files:\n\n- [@CLAUDE.md]"
              },
              {
                "name": "/quick-plan",
                "description": "Creates a concise engineering implementation plan based on user requirements and saves it to specs directory",
                "path": "core-essentials-commands/commands/quick-plan.md",
                "frontmatter": {
                  "description": "Creates a concise engineering implementation plan based on user requirements and saves it to specs directory",
                  "argument-hint": [
                    "user prompt"
                  ],
                  "allowed-tools": "Read, Write, Edit, Grep, Glob, MultiEdit",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Quick Plan\n\nCreate a detailed implementation plan based on the user's requirements provided thought the `USER_PROMPT` variable. Analyze the request, think through the implementation approach, and save a comprehensive specification document to the `PLAN_OUTPUT_DIRECTORY/<name-of-plan>.md` that can be used as a blueprint for actual development work.\n\n## Variables\n\nUSER_PROMPT: $ARGUMENTS\nPLAN_OUTPUT_DIRECTORY: `specs/`\n\n## Instructions\n\n- Carefully analyze the user's requirements provided in the `USER_PROMPT` variable.\n- Think deeply about the best approach to implement the requested functionality or solve the problem.\n- Create a concise implementation plan that includes:\n  - Clear problem statement and objectives\n  - Technical approach and architecture decisions\n  - Step-by-step implementation guide\n  - Potential challenges and solutions\n  - Testing strategy\n  - Success criteria\n- Generate a descriptive, kebab-case filename based on the main topic of the plan\n- Save the complete implementation plan to the `PLAN_OUTPUT_DIRECTORY/<descriptive-name.md>` directory\n- Ensure the plan is detailed enough that another developer could follow it to implement the solution\n- Include code examples or pseudo-code where appropriate to clarify complex concepts\n- Consider edge cases, error handling, and scalability concerns to the tune of 10-20 users\n- Structure the document with clear sections and proper markdown formatting\n\n## Workflow\n\n1. Analyze Requirements - THINK HARD and parse the `USER_PROMPT` to understand the core problem and desired outcome\n2. Design solution - Develop technical approach including architecture decisions and implementation strategy\n3. Document Plan - Structure a comprehensive markdown document with problem statement, implementation steps, and testing approach\n4. Generate Filename - Create a descriptive, kebab-case filename based on the plan's main topic\n5. Save & Report - Write the plan to the `PLAN_OUTPUT_DIRECTORY/<filename.md>` and provide a summary of key components\n\n## Report\n\nAfter creating and saving the implemetaion plan, provide a concise report with the following format:\n\n```\nImplementation Plan Created\n\nFile: PLAN_OUTPUT_DIRECTORY/<filename.md>\nTopic: <brief description of the what the plan covers>\nKey Components:\n- <main component 1>\n- <main component 2>\n- <main component 3>\n```"
              },
              {
                "name": "/quick-search",
                "description": "Search for patterns across project logs and files",
                "path": "core-essentials-commands/commands/quick-search.md",
                "frontmatter": {
                  "allowed-tools": "Grep, Read, Task",
                  "description": "Search for patterns across project logs and files",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Quick Search\n\nSearch for $ARGUMENTS pattern across project logs and files using intelligent strategy. Scan logs/ directory for .json and .log files, extract relevant context around matches, present results with file location and line numbers, and suggest refined searches if needed."
              }
            ],
            "skills": []
          },
          {
            "name": "core-essentials-hooks",
            "description": "core-essentials automation hooks for development workflow",
            "source": "./core-essentials-hooks",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install core-essentials-hooks@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "core-essentials",
            "description": "Meta-package: Installs all core-essentials components (commands + agents + hooks)",
            "source": "./core-essentials",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install core-essentials@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/analyze-codebase",
                "description": "Generate comprehensive analysis and documentation of entire codebase",
                "path": "core-essentials-commands/commands/analyze-codebase.md",
                "frontmatter": {
                  "allowed-tools": "Bash(find:*), Bash(ls:*), Bash(tree:*), Bash(grep:*), Bash(wc:*), Bash(du:*), Bash(head:*), Bash(tail:*), Bash(cat:*), Bash(touch:*)",
                  "description": "Generate comprehensive analysis and documentation of entire codebase"
                },
                "content": "# Comprehensive Codebase Analysis\n\n## Project Discovery Phase\n\n### Directory Structure\n!`find . -type d -not -path \"./node_modules/*\" -not -path \"./.git/*\" -not -path \"./dist/*\" -not -path \"./build/*\" -not -path \"./.next/*\" -not -path \"./coverage/*\" | sort`\n\n### Complete File Tree\n!`eza --tree --all --level=4 --ignore-glob='node_modules|.git|dist|build|.next|coverage|*.log'`\n\n### File Count and Size Analysis\n- Total files: !`find . -type f -not -path \"./node_modules/*\" -not -path \"./.git/*\" | wc -l`\n- Code files: !`find . -name \"*.js\" -o -name \"*.ts\" -o -name \"*.jsx\" -o -name \"*.tsx\" -o -name \"*.py\" -o -name \"*.java\" -o -name \"*.php\" -o -name \"*.rb\" -o -name \"*.go\" -o -name \"*.rs\" -o -name \"*.cpp\" -o -name \"*.c\" | grep -v node_modules | wc -l`\n- Project size: !`find . -type f -not -path \"./node_modules/*\" -not -path \"./.git/*\" -not -path \"./dist/*\" -not -path \"./build/*\" -not -path \"./.next/*\" -not -path \"./coverage/*\" -exec du -ch {} + 2>/dev/null | grep total$ | cut -f1`\n\n## Configuration Files Analysis\n\n### Package Management\n- Package.json: @package.json\n- Package-lock.json exists: !`ls package-lock.json 2>/dev/null || echo \"Not found\"`\n- Yarn.lock exists: !`ls yarn.lock 2>/dev/null || echo \"Not found\"`\n- Requirements.txt: @requirements.txt\n- Gemfile: @Gemfile\n- Cargo.toml: @Cargo.toml\n- Go.mod: @go.mod\n- Composer.json: @composer.json\n\n### Build & Dev Tools\n- Webpack config: @webpack.config.js\n- Vite config: @vite.config.js\n- Rollup config: @rollup.config.js\n- Babel config: @.babelrc\n- ESLint config: @.eslintrc.js\n- Prettier config: @.prettierrc\n- TypeScript config: @tsconfig.json\n- Tailwind config: @tailwind.config.js\n- Next.js config: @next.config.js\n\n### Environment & Docker\n- .env files: !`find . -name \".env*\" -type f 2>/dev/null || echo \"No .env files found\"`\n- Docker files: !`find . -name \"Dockerfile*\" -o -name \"docker-compose*\" 2>/dev/null || echo \"No Docker files found\"`\n- Kubernetes files: !`find . -name \"*.yaml\" -o -name \"*.yml\" 2>/dev/null | grep -E \"(k8s|kubernetes|deployment|service)\" || echo \"No Kubernetes files found\"`\n\n### CI/CD Configuration\n- GitHub Actions: !`find .github -name \"*.yml\" -o -name \"*.yaml\" 2>/dev/null || echo \"No GitHub Actions\"`\n- GitLab CI: @.gitlab-ci.yml\n- Travis CI: @.travis.yml\n- Circle CI: @.circleci/config.yml\n\n## Source Code Analysis\n\n### Main Application Files\n- Main entry points: !`find . -name \"main.*\" -o -name \"index.*\" -o -name \"app.*\" -o -name \"server.*\" | grep -v node_modules | head -10`\n- Routes/Controllers: !`find . -path \"*/routes/*\" -o -path \"*/controllers/*\" -o -path \"*/api/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No routes/controllers found\"`\n- Models/Schemas: !`find . -path \"*/models/*\" -o -path \"*/schemas/*\" -o -path \"*/entities/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No models/schemas found\"`\n- Components: !`find . -path \"*/components/*\" -o -path \"*/views/*\" -o -path \"*/pages/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No components/views/pages found\"`\n\n### Database & Storage\n- Database configs: !`find . -name \"*database*\" -o -name \"*db*\" -o -name \"*connection*\" | grep -v node_modules | head -10`\n- Migration files: !`find . -path \"*/migrations/*\" -o -path \"*/migrate/*\" 2>/dev/null | head -10 || echo \"No migration files found\"`\n- Seed files: !`find . -path \"*/seeds/*\" -o -path \"*/seeders/*\" 2>/dev/null | head -10 || echo \"No seed files found\"`\n\n### Testing Files\n- Test files: !`find . -name \"*test*\" -o -name \"*spec*\" | grep -v node_modules | head -15`\n- Test config: @jest.config.js\n\n### API Documentation\n- API docs: !`find . \\( -name \"*api*\" -a -name \"*.md\" \\) -o -name \"swagger*\" -o -name \"openapi*\" 2>/dev/null | head -10 || echo \"No API documentation found\"`\n\n## Key Files Content Analysis\n\n### Root Configuration Files\n@README.md\n@LICENSE\n@.gitignore\n\n### Main Application Entry Points\n!`find . -name \"index.js\" -o -name \"index.ts\" -o -name \"main.js\" -o -name \"main.ts\" -o -name \"app.js\" -o -name \"app.ts\" -o -name \"server.js\" -o -name \"server.ts\" 2>/dev/null | grep -v node_modules | head -5 | while read file; do echo \"=== $file ===\"; head -50 \"$file\" 2>/dev/null || echo \"Could not read $file\"; echo; done || echo \"No main entry point files found\"`\n\n## Your Task\n\nBased on all the discovered information above, create a comprehensive analysis that includes:\n\n## 1. Project Overview\n- Project type (web app, API, library, etc.)\n- Tech stack and frameworks\n- Architecture pattern (MVC, microservices, etc.)\n- Language(s) and versions\n\n## 2. Detailed Directory Structure Analysis\nFor each major directory, explain:\n- Purpose and role in the application\n- Key files and their functions\n- How it connects to other parts\n\n## 3. File-by-File Breakdown\nOrganize by category:\n- **Core Application Files**: Main entry points, routing, business logic\n- **Configuration Files**: Build tools, environment, deployment\n- **Data Layer**: Models, database connections, migrations\n- **Frontend/UI**: Components, pages, styles, assets  \n- **Testing**: Test files, mocks, fixtures\n- **Documentation**: README, API docs, guides\n- **DevOps**: CI/CD, Docker, deployment scripts\n\n## 4. API Endpoints Analysis\nIf applicable, document:\n- All discovered endpoints and their methods\n- Authentication/authorization patterns\n- Request/response formats\n- API versioning strategy\n\n## 5. Architecture Deep Dive\nExplain:\n- Overall application architecture\n- Data flow and request lifecycle\n- Key design patterns used\n- Dependencies between modules\n\n## 6. Environment & Setup Analysis\nDocument:\n- Required environment variables\n- Installation and setup process\n- Development workflow\n- Production deployment strategy\n\n## 7. Technology Stack Breakdown\nList and explain:\n- Runtime environment\n- Frameworks and libraries\n- Database technologies\n- Build tools and bundlers\n- Testing frameworks\n- Deployment technologies\n\n## 8. Visual Architecture Diagram\nCreate a comprehensive diagram showing:\n- High-level system architecture\n- Component relationships\n- Data flow\n- External integrations\n- File structure hierarchy\n\nUse ASCII art, mermaid syntax, or detailed text representation to show:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Frontend    â”‚â”€â”€â”€â”€â–¶â”‚      API        â”‚â”€â”€â”€â”€â–¶â”‚    Database     â”‚\nâ”‚   (React/Vue)   â”‚     â”‚   (Node/Flask)  â”‚     â”‚ (Postgres/Mongo)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n## 9. Key Insights & Recommendations\nProvide:\n- Code quality assessment\n- Potential improvements\n- Security considerations\n- Performance optimization opportunities\n- Maintainability suggestions\n\nThink deeply about the codebase structure and provide comprehensive insights that would be valuable for new developers joining the project or for architectural decision-making.\n\nAt the end, write all of the output into a file called \"codebase_analysis.md\""
              },
              {
                "name": "/build",
                "description": "Build the codebase based on a plan using structured approach",
                "path": "core-essentials-commands/commands/build.md",
                "frontmatter": {
                  "description": "Build the codebase based on a plan using structured approach",
                  "arguement-hint": [
                    "path-to-plan"
                  ],
                  "allowed-tools": "Bash, Read, Write, Glob, Grep, Task"
                },
                "content": "# Build\n\nFollow the `Workflow` to implement the `PATH_TO_PLAN` then `Report` the completed work.\n\n## Variables\n\nPATH_TO_PLAN: $ARGUMENTS\n\n## Workflow\n\n### 1. Initial Setup\n- If no `PATH_TO_PLAN` is provided, STOP immediately and ask the user to provide it\n\n### 2. Plan Analysis \n- Read the plan at `PATH_TO_PLAN`. Think hard about the plan and write the code to implement it into the codebase. \n\n### 3. Memory Management\n- Document any architectural decisions or patterns discovered\n\n## Report\n\n- Summarize the work you've just done in a concise bullet point list\n- Report the files and total lines changed with `git diff --stat`"
              },
              {
                "name": "/code-review",
                "description": "Perform comprehensive code review analysis of recent changes with semantic code understanding",
                "path": "core-essentials-commands/commands/code-review.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(git branch:*), mcp__serena__get_symbols_overview, mcp__serena__find_symbol, mcp__serena__find_referencing_symbols, mcp__serena__search_for_pattern, mcp__serena__list_dir",
                  "description": "Perform comprehensive code review analysis of recent changes with semantic code understanding",
                  "argument-hint": [
                    {
                      "Optional": "specify file paths or commit range for focused review"
                    }
                  ]
                },
                "content": "# Code Review Analysis\n\nAnalyze `RECENT_CHANGES` using semantic code understanding to perform comprehensive code review covering quality, security, performance, testing, and documentation with specific actionable feedback saved to `REVIEW_OUTPUT`.\n\n## Variables:\nTARGET_SCOPE: $1 (optional - specific files, commit range, or \"recent\" for latest changes)\nGIT_CONTEXT: recent changes and commit history\nREVIEW_CRITERIA: code quality, security, performance, testing, documentation\nANALYSIS_DEPTH: semantic symbol analysis with cross-references\nREVIEW_OUTPUT: logs/code-review-analysis.md\n\n## Workflow:\n\n1. Gather git context using `git status`, `git diff HEAD~1`, `git log --oneline -5`, and `git branch --show-current`\n2. Identify changed files from git diff output for semantic analysis scope\n3. Use `mcp__serena__list_dir` to understand project structure and identify key directories\n4. For each modified file, use `mcp__serena__get_symbols_overview` to understand code structure and symbols\n5. Use `mcp__serena__find_symbol` with `include_body=true` for detailed analysis of modified functions/classes\n6. Apply `mcp__serena__find_referencing_symbols` to understand impact of changes on dependent code\n7. Use `mcp__serena__search_for_pattern` to identify potential security patterns, anti-patterns, or code smells\n8. Analyze code quality: readability, maintainability, adherence to project conventions and best practices\n9. Evaluate security: scan for vulnerabilities, input validation, authentication, authorization issues\n10. Assess performance: identify bottlenecks, inefficient algorithms, resource usage patterns\n11. Review testing: evaluate test coverage, test quality, missing test scenarios for changed code\n12. Verify documentation: check inline comments, README updates, API documentation completeness\n13. Generate specific, actionable feedback with file:line references and suggested improvements\n14. Save comprehensive review analysis to `REVIEW_OUTPUT` with prioritized recommendations\n\n## Report:\n\nCode Review Analysis Complete\n\nFile: `REVIEW_OUTPUT`\nTopic: Comprehensive semantic code review of `TARGET_SCOPE` with actionable recommendations\nKey Components:\n- Git context analysis with change scope identification\n- Semantic symbol analysis using serena-mcp tools for deep code understanding\n- Multi-dimensional review covering quality, security, performance, testing, documentation\n- Specific actionable feedback with file:line references and improvement suggestions"
              },
              {
                "name": "/commit",
                "description": "Intelligent commits with hook-aware strategy detection",
                "path": "core-essentials-commands/commands/commit.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Write, Task",
                  "description": "Intelligent commits with hook-aware strategy detection",
                  "argument-hint": [
                    {
                      "Optional": "--no-verify or custom message"
                    }
                  ]
                },
                "content": "# Commit\n\nUse the git-flow-manager sub-agent to intelligently analyze staging area and project formatting hooks, then execute optimal commit strategy (PARALLEL/COORDINATED/HYBRID) to prevent conflicts while maintaining commit organization. Parse `$ARGUMENTS` for commit options, run pre-commit checks, analyze changes for atomic splitting, and execute commits with conventional messages.\n\n## Variables:\nCOMMIT_OPTIONS: $ARGUMENTS\nSTRATEGY_MODE: auto-detected\nCOMMIT_COUNT: auto-calculated\nHOOK_ANALYSIS: auto-performed\n\n## Instructions:\n\n- Parse `COMMIT_OPTIONS` to extract flags like `--no-verify` or custom messages\n- Use the git-flow-manager sub-agent for comprehensive workflow management with automatic strategy detection\n- Auto-detect formatting hook aggressiveness and choose optimal commit strategy\n- Run pre-commit checks unless `--no-verify` flag is present\n- Validate `.gitignore` configuration and alert for large files (>1MB)\n- Auto-stage modified files if none staged, analyze changes for atomic splitting\n- Execute commits using detected strategy with conventional messages and emoji\n- Include issue references for GitHub/Linear integration when applicable\n\n## Workflow:\n\n1. Deploy git-flow-manager sub-agent with strategy detection capabilities\n2. Run `!git status --porcelain` to analyze current repository state\n3. Execute formatting hook analysis to determine optimal commit strategy\n4. Check for `--no-verify` flag in `COMMIT_OPTIONS`, skip pre-commit checks if present\n5. Run pre-commit validation: `!pnpm lint`, `!pnpm build`, `!pnpm generate:docs`\n6. Validate `.gitignore` configuration and check for large files\n7. Auto-stage files with `!git add .` if no files currently staged\n8. Execute `!git diff --staged --name-status` to analyze staged changes\n9. Analyze changes for atomic commit splitting opportunities\n10. Execute commits using detected strategy (PARALLEL/COORDINATED/HYBRID)\n11. Generate conventional commit messages with appropriate emoji from @ai-docs/emoji-commit-ref.yaml\n12. Include issue references in commit body for automatic linking\n13. Execute `!git commit` with generated messages\n14. Display commit summary using `!git log --oneline -1`\n\n## Report:\n\nIntelligent Commit Complete\n\nStrategy: `STRATEGY_MODE` (auto-detected based on formatting hook analysis)\nFiles: `COMMIT_COUNT` commits created and executed\nTopic: Hook-aware commit processing with adaptive strategy selection\nKey Components:\n- Automatic strategy detection preventing formatting hook conflicts\n- Conventional commit messages with appropriate emoji\n- Pre-commit validation and quality gates\n- Atomic commit splitting for logical organization\n- GitHub/Linear issue integration\n- Clean working directory achieved without conflicts\n\n## Relevant Files:\n\n- @~/.claude/agents/git-flow-manager.md\n- @ai-docs/emoji-commit-ref.yaml"
              },
              {
                "name": "/git-status",
                "description": "Analyze current git repository state and differences from remote",
                "path": "core-essentials-commands/commands/git-status.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read",
                  "description": "Analyze current git repository state and differences from remote"
                },
                "content": "# Git Status\n\nAnalyze current git repository state including status, branch information, differences from remote, and recent commits. Use $ARGUMENTS for specific branch or filter options, provide actionable summary with next steps recommendations highlighting any uncommitted changes or divergence from remote branch."
              },
              {
                "name": "/go",
                "description": "Advanced code analysis and development using semantic tools, documentation, and structured decision making",
                "path": "core-essentials-commands/commands/go.md",
                "frontmatter": {
                  "allowed-tools": "mcp__serena__list_dir, mcp__serena__find_file, mcp__serena__search_for_pattern, mcp__serena__get_symbols_overview, mcp__serena__find_symbol, mcp__serena__find_referencing_symbols, mcp__serena__replace_symbol_body, mcp__serena__insert_after_symbol, mcp__serena__insert_before_symbol, mcp__context7__resolve-library-id, mcp__context7__get-library-docs, mcp__sequential-thinking__process_thought, mcp__sequential-thinking__generate_summary, Read",
                  "description": "Advanced code analysis and development using semantic tools, documentation, and structured decision making",
                  "argument-hint": [
                    "task description or development requirement"
                  ],
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Go\n\nAdvanced code analysis, development, and decision-making command that uses `USER_TASK` to analyze requirements through semantic code tools, up-to-date documentation, and structured thinking processes.\n\n## Variables:\n\nUSER_TASK: $1\nPROJECT_ROOT: .\nCLAUDE_CONFIG: CLAUDE.md\n\n## Instructions:\n\n- Read `CLAUDE_CONFIG` to understand project context and requirements\n- Use `USER_TASK` to determine specific analysis or development needs\n- Apply serena tools for semantic code retrieval and precise editing operations\n- Leverage context7 for current third-party library documentation and examples\n- Use sequential thinking for all decision-making processes and complex analysis\n- Maintain structured approach with clear reasoning for all actions taken\n\n## Workflow:\n\n1. Read `CLAUDE_CONFIG` file to understand project structure and context\n2. Use sequential thinking to process and break down `USER_TASK` requirements\n3. Use serena semantic tools to explore relevant codebase sections and symbols\n4. Retrieve up-to-date documentation using context7 for any third-party dependencies\n5. Apply structured decision-making through sequential thinking for implementation approach\n6. Execute precise code analysis or modifications using serena's semantic editing tools\n7. Document reasoning and decisions made throughout the process\n8. Generate summary of actions taken and results achieved\n9. Provide clear recommendations for next steps or follow-up actions\n\n## Report:\n\nAdvanced Analysis Complete\n\nTask: `USER_TASK` processed using semantic tools and structured thinking\nKey Components:\n\n- Project context analysis from `CLAUDE_CONFIG`\n- Semantic code exploration and analysis using serena tools\n- Third-party documentation retrieval via context7\n- Structured decision-making through sequential thinking process\n- Precise code modifications or analysis results\n- Clear reasoning documentation and next step recommendations\n\n## Relevant Files:\n\n- [@CLAUDE.md]"
              },
              {
                "name": "/quick-plan",
                "description": "Creates a concise engineering implementation plan based on user requirements and saves it to specs directory",
                "path": "core-essentials-commands/commands/quick-plan.md",
                "frontmatter": {
                  "description": "Creates a concise engineering implementation plan based on user requirements and saves it to specs directory",
                  "argument-hint": [
                    "user prompt"
                  ],
                  "allowed-tools": "Read, Write, Edit, Grep, Glob, MultiEdit",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Quick Plan\n\nCreate a detailed implementation plan based on the user's requirements provided thought the `USER_PROMPT` variable. Analyze the request, think through the implementation approach, and save a comprehensive specification document to the `PLAN_OUTPUT_DIRECTORY/<name-of-plan>.md` that can be used as a blueprint for actual development work.\n\n## Variables\n\nUSER_PROMPT: $ARGUMENTS\nPLAN_OUTPUT_DIRECTORY: `specs/`\n\n## Instructions\n\n- Carefully analyze the user's requirements provided in the `USER_PROMPT` variable.\n- Think deeply about the best approach to implement the requested functionality or solve the problem.\n- Create a concise implementation plan that includes:\n  - Clear problem statement and objectives\n  - Technical approach and architecture decisions\n  - Step-by-step implementation guide\n  - Potential challenges and solutions\n  - Testing strategy\n  - Success criteria\n- Generate a descriptive, kebab-case filename based on the main topic of the plan\n- Save the complete implementation plan to the `PLAN_OUTPUT_DIRECTORY/<descriptive-name.md>` directory\n- Ensure the plan is detailed enough that another developer could follow it to implement the solution\n- Include code examples or pseudo-code where appropriate to clarify complex concepts\n- Consider edge cases, error handling, and scalability concerns to the tune of 10-20 users\n- Structure the document with clear sections and proper markdown formatting\n\n## Workflow\n\n1. Analyze Requirements - THINK HARD and parse the `USER_PROMPT` to understand the core problem and desired outcome\n2. Design solution - Develop technical approach including architecture decisions and implementation strategy\n3. Document Plan - Structure a comprehensive markdown document with problem statement, implementation steps, and testing approach\n4. Generate Filename - Create a descriptive, kebab-case filename based on the plan's main topic\n5. Save & Report - Write the plan to the `PLAN_OUTPUT_DIRECTORY/<filename.md>` and provide a summary of key components\n\n## Report\n\nAfter creating and saving the implemetaion plan, provide a concise report with the following format:\n\n```\nImplementation Plan Created\n\nFile: PLAN_OUTPUT_DIRECTORY/<filename.md>\nTopic: <brief description of the what the plan covers>\nKey Components:\n- <main component 1>\n- <main component 2>\n- <main component 3>\n```"
              },
              {
                "name": "/quick-search",
                "description": "Search for patterns across project logs and files",
                "path": "core-essentials-commands/commands/quick-search.md",
                "frontmatter": {
                  "allowed-tools": "Grep, Read, Task",
                  "description": "Search for patterns across project logs and files",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Quick Search\n\nSearch for $ARGUMENTS pattern across project logs and files using intelligent strategy. Scan logs/ directory for .json and .log files, extract relevant context around matches, present results with file location and line numbers, and suggest refined searches if needed."
              },
              {
                "name": "/analyze-codebase",
                "description": "Generate comprehensive analysis and documentation of entire codebase",
                "path": "core-essentials/commands/analyze-codebase.md",
                "frontmatter": {
                  "allowed-tools": "Bash(find:*), Bash(ls:*), Bash(tree:*), Bash(grep:*), Bash(wc:*), Bash(du:*), Bash(head:*), Bash(tail:*), Bash(cat:*), Bash(touch:*)",
                  "description": "Generate comprehensive analysis and documentation of entire codebase"
                },
                "content": "# Comprehensive Codebase Analysis\n\n## Project Discovery Phase\n\n### Directory Structure\n!`find . -type d -not -path \"./node_modules/*\" -not -path \"./.git/*\" -not -path \"./dist/*\" -not -path \"./build/*\" -not -path \"./.next/*\" -not -path \"./coverage/*\" | sort`\n\n### Complete File Tree\n!`eza --tree --all --level=4 --ignore-glob='node_modules|.git|dist|build|.next|coverage|*.log'`\n\n### File Count and Size Analysis\n- Total files: !`find . -type f -not -path \"./node_modules/*\" -not -path \"./.git/*\" | wc -l`\n- Code files: !`find . -name \"*.js\" -o -name \"*.ts\" -o -name \"*.jsx\" -o -name \"*.tsx\" -o -name \"*.py\" -o -name \"*.java\" -o -name \"*.php\" -o -name \"*.rb\" -o -name \"*.go\" -o -name \"*.rs\" -o -name \"*.cpp\" -o -name \"*.c\" | grep -v node_modules | wc -l`\n- Project size: !`find . -type f -not -path \"./node_modules/*\" -not -path \"./.git/*\" -not -path \"./dist/*\" -not -path \"./build/*\" -not -path \"./.next/*\" -not -path \"./coverage/*\" -exec du -ch {} + 2>/dev/null | grep total$ | cut -f1`\n\n## Configuration Files Analysis\n\n### Package Management\n- Package.json: @package.json\n- Package-lock.json exists: !`ls package-lock.json 2>/dev/null || echo \"Not found\"`\n- Yarn.lock exists: !`ls yarn.lock 2>/dev/null || echo \"Not found\"`\n- Requirements.txt: @requirements.txt\n- Gemfile: @Gemfile\n- Cargo.toml: @Cargo.toml\n- Go.mod: @go.mod\n- Composer.json: @composer.json\n\n### Build & Dev Tools\n- Webpack config: @webpack.config.js\n- Vite config: @vite.config.js\n- Rollup config: @rollup.config.js\n- Babel config: @.babelrc\n- ESLint config: @.eslintrc.js\n- Prettier config: @.prettierrc\n- TypeScript config: @tsconfig.json\n- Tailwind config: @tailwind.config.js\n- Next.js config: @next.config.js\n\n### Environment & Docker\n- .env files: !`find . -name \".env*\" -type f 2>/dev/null || echo \"No .env files found\"`\n- Docker files: !`find . -name \"Dockerfile*\" -o -name \"docker-compose*\" 2>/dev/null || echo \"No Docker files found\"`\n- Kubernetes files: !`find . -name \"*.yaml\" -o -name \"*.yml\" 2>/dev/null | grep -E \"(k8s|kubernetes|deployment|service)\" || echo \"No Kubernetes files found\"`\n\n### CI/CD Configuration\n- GitHub Actions: !`find .github -name \"*.yml\" -o -name \"*.yaml\" 2>/dev/null || echo \"No GitHub Actions\"`\n- GitLab CI: @.gitlab-ci.yml\n- Travis CI: @.travis.yml\n- Circle CI: @.circleci/config.yml\n\n## Source Code Analysis\n\n### Main Application Files\n- Main entry points: !`find . -name \"main.*\" -o -name \"index.*\" -o -name \"app.*\" -o -name \"server.*\" | grep -v node_modules | head -10`\n- Routes/Controllers: !`find . -path \"*/routes/*\" -o -path \"*/controllers/*\" -o -path \"*/api/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No routes/controllers found\"`\n- Models/Schemas: !`find . -path \"*/models/*\" -o -path \"*/schemas/*\" -o -path \"*/entities/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No models/schemas found\"`\n- Components: !`find . -path \"*/components/*\" -o -path \"*/views/*\" -o -path \"*/pages/*\" 2>/dev/null | grep -v node_modules | head -20 || echo \"No components/views/pages found\"`\n\n### Database & Storage\n- Database configs: !`find . -name \"*database*\" -o -name \"*db*\" -o -name \"*connection*\" | grep -v node_modules | head -10`\n- Migration files: !`find . -path \"*/migrations/*\" -o -path \"*/migrate/*\" 2>/dev/null | head -10 || echo \"No migration files found\"`\n- Seed files: !`find . -path \"*/seeds/*\" -o -path \"*/seeders/*\" 2>/dev/null | head -10 || echo \"No seed files found\"`\n\n### Testing Files\n- Test files: !`find . -name \"*test*\" -o -name \"*spec*\" | grep -v node_modules | head -15`\n- Test config: @jest.config.js\n\n### API Documentation\n- API docs: !`find . \\( -name \"*api*\" -a -name \"*.md\" \\) -o -name \"swagger*\" -o -name \"openapi*\" 2>/dev/null | head -10 || echo \"No API documentation found\"`\n\n## Key Files Content Analysis\n\n### Root Configuration Files\n@README.md\n@LICENSE\n@.gitignore\n\n### Main Application Entry Points\n!`find . -name \"index.js\" -o -name \"index.ts\" -o -name \"main.js\" -o -name \"main.ts\" -o -name \"app.js\" -o -name \"app.ts\" -o -name \"server.js\" -o -name \"server.ts\" 2>/dev/null | grep -v node_modules | head -5 | while read file; do echo \"=== $file ===\"; head -50 \"$file\" 2>/dev/null || echo \"Could not read $file\"; echo; done || echo \"No main entry point files found\"`\n\n## Your Task\n\nBased on all the discovered information above, create a comprehensive analysis that includes:\n\n## 1. Project Overview\n- Project type (web app, API, library, etc.)\n- Tech stack and frameworks\n- Architecture pattern (MVC, microservices, etc.)\n- Language(s) and versions\n\n## 2. Detailed Directory Structure Analysis\nFor each major directory, explain:\n- Purpose and role in the application\n- Key files and their functions\n- How it connects to other parts\n\n## 3. File-by-File Breakdown\nOrganize by category:\n- **Core Application Files**: Main entry points, routing, business logic\n- **Configuration Files**: Build tools, environment, deployment\n- **Data Layer**: Models, database connections, migrations\n- **Frontend/UI**: Components, pages, styles, assets  \n- **Testing**: Test files, mocks, fixtures\n- **Documentation**: README, API docs, guides\n- **DevOps**: CI/CD, Docker, deployment scripts\n\n## 4. API Endpoints Analysis\nIf applicable, document:\n- All discovered endpoints and their methods\n- Authentication/authorization patterns\n- Request/response formats\n- API versioning strategy\n\n## 5. Architecture Deep Dive\nExplain:\n- Overall application architecture\n- Data flow and request lifecycle\n- Key design patterns used\n- Dependencies between modules\n\n## 6. Environment & Setup Analysis\nDocument:\n- Required environment variables\n- Installation and setup process\n- Development workflow\n- Production deployment strategy\n\n## 7. Technology Stack Breakdown\nList and explain:\n- Runtime environment\n- Frameworks and libraries\n- Database technologies\n- Build tools and bundlers\n- Testing frameworks\n- Deployment technologies\n\n## 8. Visual Architecture Diagram\nCreate a comprehensive diagram showing:\n- High-level system architecture\n- Component relationships\n- Data flow\n- External integrations\n- File structure hierarchy\n\nUse ASCII art, mermaid syntax, or detailed text representation to show:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Frontend    â”‚â”€â”€â”€â”€â–¶â”‚      API        â”‚â”€â”€â”€â”€â–¶â”‚    Database     â”‚\nâ”‚   (React/Vue)   â”‚     â”‚   (Node/Flask)  â”‚     â”‚ (Postgres/Mongo)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n## 9. Key Insights & Recommendations\nProvide:\n- Code quality assessment\n- Potential improvements\n- Security considerations\n- Performance optimization opportunities\n- Maintainability suggestions\n\nThink deeply about the codebase structure and provide comprehensive insights that would be valuable for new developers joining the project or for architectural decision-making.\n\nAt the end, write all of the output into a file called \"codebase_analysis.md\""
              },
              {
                "name": "/build",
                "description": "Build the codebase based on a plan using structured approach",
                "path": "core-essentials/commands/build.md",
                "frontmatter": {
                  "description": "Build the codebase based on a plan using structured approach",
                  "arguement-hint": [
                    "path-to-plan"
                  ],
                  "allowed-tools": "Bash, Read, Write, Glob, Grep, Task"
                },
                "content": "# Build\n\nFollow the `Workflow` to implement the `PATH_TO_PLAN` then `Report` the completed work.\n\n## Variables\n\nPATH_TO_PLAN: $ARGUMENTS\n\n## Workflow\n\n### 1. Initial Setup\n- If no `PATH_TO_PLAN` is provided, STOP immediately and ask the user to provide it\n\n### 2. Plan Analysis \n- Read the plan at `PATH_TO_PLAN`. Think hard about the plan and write the code to implement it into the codebase. \n\n### 3. Memory Management\n- Document any architectural decisions or patterns discovered\n\n## Report\n\n- Summarize the work you've just done in a concise bullet point list\n- Report the files and total lines changed with `git diff --stat`"
              },
              {
                "name": "/code-review",
                "description": "Perform comprehensive code review analysis of recent changes with semantic code understanding",
                "path": "core-essentials/commands/code-review.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(git branch:*), mcp__serena__get_symbols_overview, mcp__serena__find_symbol, mcp__serena__find_referencing_symbols, mcp__serena__search_for_pattern, mcp__serena__list_dir",
                  "description": "Perform comprehensive code review analysis of recent changes with semantic code understanding",
                  "argument-hint": [
                    {
                      "Optional": "specify file paths or commit range for focused review"
                    }
                  ]
                },
                "content": "# Code Review Analysis\n\nAnalyze `RECENT_CHANGES` using semantic code understanding to perform comprehensive code review covering quality, security, performance, testing, and documentation with specific actionable feedback saved to `REVIEW_OUTPUT`.\n\n## Variables:\nTARGET_SCOPE: $1 (optional - specific files, commit range, or \"recent\" for latest changes)\nGIT_CONTEXT: recent changes and commit history\nREVIEW_CRITERIA: code quality, security, performance, testing, documentation\nANALYSIS_DEPTH: semantic symbol analysis with cross-references\nREVIEW_OUTPUT: logs/code-review-analysis.md\n\n## Workflow:\n\n1. Gather git context using `git status`, `git diff HEAD~1`, `git log --oneline -5`, and `git branch --show-current`\n2. Identify changed files from git diff output for semantic analysis scope\n3. Use `mcp__serena__list_dir` to understand project structure and identify key directories\n4. For each modified file, use `mcp__serena__get_symbols_overview` to understand code structure and symbols\n5. Use `mcp__serena__find_symbol` with `include_body=true` for detailed analysis of modified functions/classes\n6. Apply `mcp__serena__find_referencing_symbols` to understand impact of changes on dependent code\n7. Use `mcp__serena__search_for_pattern` to identify potential security patterns, anti-patterns, or code smells\n8. Analyze code quality: readability, maintainability, adherence to project conventions and best practices\n9. Evaluate security: scan for vulnerabilities, input validation, authentication, authorization issues\n10. Assess performance: identify bottlenecks, inefficient algorithms, resource usage patterns\n11. Review testing: evaluate test coverage, test quality, missing test scenarios for changed code\n12. Verify documentation: check inline comments, README updates, API documentation completeness\n13. Generate specific, actionable feedback with file:line references and suggested improvements\n14. Save comprehensive review analysis to `REVIEW_OUTPUT` with prioritized recommendations\n\n## Report:\n\nCode Review Analysis Complete\n\nFile: `REVIEW_OUTPUT`\nTopic: Comprehensive semantic code review of `TARGET_SCOPE` with actionable recommendations\nKey Components:\n- Git context analysis with change scope identification\n- Semantic symbol analysis using serena-mcp tools for deep code understanding\n- Multi-dimensional review covering quality, security, performance, testing, documentation\n- Specific actionable feedback with file:line references and improvement suggestions"
              },
              {
                "name": "/commit",
                "description": "Intelligent commits with hook-aware strategy detection",
                "path": "core-essentials/commands/commit.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Write, Task",
                  "description": "Intelligent commits with hook-aware strategy detection",
                  "argument-hint": [
                    {
                      "Optional": "--no-verify or custom message"
                    }
                  ]
                },
                "content": "# Commit\n\nUse the git-flow-manager sub-agent to intelligently analyze staging area and project formatting hooks, then execute optimal commit strategy (PARALLEL/COORDINATED/HYBRID) to prevent conflicts while maintaining commit organization. Parse `$ARGUMENTS` for commit options, run pre-commit checks, analyze changes for atomic splitting, and execute commits with conventional messages.\n\n## Variables:\nCOMMIT_OPTIONS: $ARGUMENTS\nSTRATEGY_MODE: auto-detected\nCOMMIT_COUNT: auto-calculated\nHOOK_ANALYSIS: auto-performed\n\n## Instructions:\n\n- Parse `COMMIT_OPTIONS` to extract flags like `--no-verify` or custom messages\n- Use the git-flow-manager sub-agent for comprehensive workflow management with automatic strategy detection\n- Auto-detect formatting hook aggressiveness and choose optimal commit strategy\n- Run pre-commit checks unless `--no-verify` flag is present\n- Validate `.gitignore` configuration and alert for large files (>1MB)\n- Auto-stage modified files if none staged, analyze changes for atomic splitting\n- Execute commits using detected strategy with conventional messages and emoji\n- Include issue references for GitHub/Linear integration when applicable\n\n## Workflow:\n\n1. Deploy git-flow-manager sub-agent with strategy detection capabilities\n2. Run `!git status --porcelain` to analyze current repository state\n3. Execute formatting hook analysis to determine optimal commit strategy\n4. Check for `--no-verify` flag in `COMMIT_OPTIONS`, skip pre-commit checks if present\n5. Run pre-commit validation: `!pnpm lint`, `!pnpm build`, `!pnpm generate:docs`\n6. Validate `.gitignore` configuration and check for large files\n7. Auto-stage files with `!git add .` if no files currently staged\n8. Execute `!git diff --staged --name-status` to analyze staged changes\n9. Analyze changes for atomic commit splitting opportunities\n10. Execute commits using detected strategy (PARALLEL/COORDINATED/HYBRID)\n11. Generate conventional commit messages with appropriate emoji from @ai-docs/emoji-commit-ref.yaml\n12. Include issue references in commit body for automatic linking\n13. Execute `!git commit` with generated messages\n14. Display commit summary using `!git log --oneline -1`\n\n## Report:\n\nIntelligent Commit Complete\n\nStrategy: `STRATEGY_MODE` (auto-detected based on formatting hook analysis)\nFiles: `COMMIT_COUNT` commits created and executed\nTopic: Hook-aware commit processing with adaptive strategy selection\nKey Components:\n- Automatic strategy detection preventing formatting hook conflicts\n- Conventional commit messages with appropriate emoji\n- Pre-commit validation and quality gates\n- Atomic commit splitting for logical organization\n- GitHub/Linear issue integration\n- Clean working directory achieved without conflicts\n\n## Relevant Files:\n\n- @~/.claude/agents/git-flow-manager.md\n- @ai-docs/emoji-commit-ref.yaml"
              },
              {
                "name": "/git-status",
                "description": "Analyze current git repository state and differences from remote",
                "path": "core-essentials/commands/git-status.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read",
                  "description": "Analyze current git repository state and differences from remote"
                },
                "content": "# Git Status\n\nAnalyze current git repository state including status, branch information, differences from remote, and recent commits. Use $ARGUMENTS for specific branch or filter options, provide actionable summary with next steps recommendations highlighting any uncommitted changes or divergence from remote branch."
              },
              {
                "name": "/go",
                "description": "Advanced code analysis and development using semantic tools, documentation, and structured decision making",
                "path": "core-essentials/commands/go.md",
                "frontmatter": {
                  "allowed-tools": "mcp__serena__list_dir, mcp__serena__find_file, mcp__serena__search_for_pattern, mcp__serena__get_symbols_overview, mcp__serena__find_symbol, mcp__serena__find_referencing_symbols, mcp__serena__replace_symbol_body, mcp__serena__insert_after_symbol, mcp__serena__insert_before_symbol, mcp__context7__resolve-library-id, mcp__context7__get-library-docs, mcp__sequential-thinking__process_thought, mcp__sequential-thinking__generate_summary, Read",
                  "description": "Advanced code analysis and development using semantic tools, documentation, and structured decision making",
                  "argument-hint": [
                    "task description or development requirement"
                  ],
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Go\n\nAdvanced code analysis, development, and decision-making command that uses `USER_TASK` to analyze requirements through semantic code tools, up-to-date documentation, and structured thinking processes.\n\n## Variables:\n\nUSER_TASK: $1\nPROJECT_ROOT: .\nCLAUDE_CONFIG: CLAUDE.md\n\n## Instructions:\n\n- Read `CLAUDE_CONFIG` to understand project context and requirements\n- Use `USER_TASK` to determine specific analysis or development needs\n- Apply serena tools for semantic code retrieval and precise editing operations\n- Leverage context7 for current third-party library documentation and examples\n- Use sequential thinking for all decision-making processes and complex analysis\n- Maintain structured approach with clear reasoning for all actions taken\n\n## Workflow:\n\n1. Read `CLAUDE_CONFIG` file to understand project structure and context\n2. Use sequential thinking to process and break down `USER_TASK` requirements\n3. Use serena semantic tools to explore relevant codebase sections and symbols\n4. Retrieve up-to-date documentation using context7 for any third-party dependencies\n5. Apply structured decision-making through sequential thinking for implementation approach\n6. Execute precise code analysis or modifications using serena's semantic editing tools\n7. Document reasoning and decisions made throughout the process\n8. Generate summary of actions taken and results achieved\n9. Provide clear recommendations for next steps or follow-up actions\n\n## Report:\n\nAdvanced Analysis Complete\n\nTask: `USER_TASK` processed using semantic tools and structured thinking\nKey Components:\n\n- Project context analysis from `CLAUDE_CONFIG`\n- Semantic code exploration and analysis using serena tools\n- Third-party documentation retrieval via context7\n- Structured decision-making through sequential thinking process\n- Precise code modifications or analysis results\n- Clear reasoning documentation and next step recommendations\n\n## Relevant Files:\n\n- [@CLAUDE.md]"
              },
              {
                "name": "/quick-plan",
                "description": "Creates a concise engineering implementation plan based on user requirements and saves it to specs directory",
                "path": "core-essentials/commands/quick-plan.md",
                "frontmatter": {
                  "description": "Creates a concise engineering implementation plan based on user requirements and saves it to specs directory",
                  "argument-hint": [
                    "user prompt"
                  ],
                  "allowed-tools": "Read, Write, Edit, Grep, Glob, MultiEdit",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Quick Plan\n\nCreate a detailed implementation plan based on the user's requirements provided thought the `USER_PROMPT` variable. Analyze the request, think through the implementation approach, and save a comprehensive specification document to the `PLAN_OUTPUT_DIRECTORY/<name-of-plan>.md` that can be used as a blueprint for actual development work.\n\n## Variables\n\nUSER_PROMPT: $ARGUMENTS\nPLAN_OUTPUT_DIRECTORY: `specs/`\n\n## Instructions\n\n- Carefully analyze the user's requirements provided in the `USER_PROMPT` variable.\n- Think deeply about the best approach to implement the requested functionality or solve the problem.\n- Create a concise implementation plan that includes:\n  - Clear problem statement and objectives\n  - Technical approach and architecture decisions\n  - Step-by-step implementation guide\n  - Potential challenges and solutions\n  - Testing strategy\n  - Success criteria\n- Generate a descriptive, kebab-case filename based on the main topic of the plan\n- Save the complete implementation plan to the `PLAN_OUTPUT_DIRECTORY/<descriptive-name.md>` directory\n- Ensure the plan is detailed enough that another developer could follow it to implement the solution\n- Include code examples or pseudo-code where appropriate to clarify complex concepts\n- Consider edge cases, error handling, and scalability concerns to the tune of 10-20 users\n- Structure the document with clear sections and proper markdown formatting\n\n## Workflow\n\n1. Analyze Requirements - THINK HARD and parse the `USER_PROMPT` to understand the core problem and desired outcome\n2. Design solution - Develop technical approach including architecture decisions and implementation strategy\n3. Document Plan - Structure a comprehensive markdown document with problem statement, implementation steps, and testing approach\n4. Generate Filename - Create a descriptive, kebab-case filename based on the plan's main topic\n5. Save & Report - Write the plan to the `PLAN_OUTPUT_DIRECTORY/<filename.md>` and provide a summary of key components\n\n## Report\n\nAfter creating and saving the implemetaion plan, provide a concise report with the following format:\n\n```\nImplementation Plan Created\n\nFile: PLAN_OUTPUT_DIRECTORY/<filename.md>\nTopic: <brief description of the what the plan covers>\nKey Components:\n- <main component 1>\n- <main component 2>\n- <main component 3>\n```"
              },
              {
                "name": "/quick-search",
                "description": "Search for patterns across project logs and files",
                "path": "core-essentials/commands/quick-search.md",
                "frontmatter": {
                  "allowed-tools": "Grep, Read, Task",
                  "description": "Search for patterns across project logs and files",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Quick Search\n\nSearch for $ARGUMENTS pattern across project logs and files using intelligent strategy. Scan logs/ directory for .json and .log files, extract relevant context around matches, present results with file location and line numbers, and suggest refined searches if needed."
              }
            ],
            "skills": []
          },
          {
            "name": "data-science-agents",
            "description": "data-science AI agents for specialized tasks (4 agents)",
            "source": "./data-science-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install data-science-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "data-science-commands",
            "description": "data-science slash commands for Claude Code (1 commands)",
            "source": "./data-science-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install data-science-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/data-commander",
                "description": null,
                "path": "data-science-commands/commands/data-commander.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Bash, Read, Write, WebFetch, Grep, Glob\ndescription: Analyze GitHub issues and generate technical specifications for implementation\nargument-hint: [issue_url_or_number] [repository_name] [output_format]\nmodel: claude-sonnet-4-5-20250929\n---\n\n# Data Commander\n\nAnalyze GitHub {issue_reference} in {repository_context} and generate {specification_format} technical specification that provides implementation-ready requirements and codebase integration guidance.\n\n## Variables:\n\n[IssueReference]: $ARGUMENTS \"GitHub issue URL, issue number, or search criteria\"\n[RepositoryContext]: $ARGUMENTS \"GitHub repository name or URL for context\"\n[SpecificationFormat]: $ARGUMENTS \"technical specification output format: detailed, summary, or implementation-focused\"\n[OutputLocation]: $ARGUMENTS \"file path for generated specification\"\n\n## Instructions:\n\n- Use GitHub CLI to fetch {IssueReference} details from {RepositoryContext}\n- Analyze issue description, comments, and related pull requests\n- Examine codebase structure to understand implementation context\n- Generate {SpecificationFormat} technical specification with clear requirements\n- Include implementation guidance based on existing codebase patterns\n- Validate specification completeness against issue requirements\n\n## Workflow:\n\n1. Authenticate GitHub CLI access and verify repository permissions\n2. Fetch issue details using `gh issue view {IssueReference} --repo {RepositoryContext} --json title,body,comments,assignees,labels,milestone`\n3. Extract core requirements, acceptance criteria, and technical constraints from issue content\n4. Analyze codebase structure using `find` and `grep` commands to identify relevant modules and patterns\n5. Review existing implementation patterns in related files and directories\n6. Cross-reference issue labels and milestone to understand project context and priority\n7. Generate technical specification document with sections: Overview, Requirements, Implementation Plan, Dependencies, Testing Strategy\n8. Include specific file paths, function signatures, and integration points based on codebase analysis\n9. Validate specification against issue acceptance criteria and technical feasibility\n10. Save specification to {OutputLocation} with structured format for development team review\n\n## Report:\n\nTechnical Specification Generated\n\nFile: {OutputLocation}\nSource Issue: {IssueReference} from {RepositoryContext}\nSpecification Type: {SpecificationFormat}\nKey Components:\n\n- Requirements analysis with acceptance criteria mapping\n- Implementation plan with specific code integration points\n- Dependencies and technical constraints identification\n- Testing strategy aligned with existing codebase patterns\n- Development timeline estimation based on complexity analysis\n\n## Relevant Files:\n\n- [GitHub issue and related discussions]\n- [Existing codebase files and modules identified during analysis]\n- [Project documentation and README files]\n"
              }
            ],
            "skills": []
          },
          {
            "name": "data-science",
            "description": "Meta-package: Installs all data-science components (commands + agents)",
            "source": "./data-science",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install data-science@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/data-commander",
                "description": null,
                "path": "data-science-commands/commands/data-commander.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Bash, Read, Write, WebFetch, Grep, Glob\ndescription: Analyze GitHub issues and generate technical specifications for implementation\nargument-hint: [issue_url_or_number] [repository_name] [output_format]\nmodel: claude-sonnet-4-5-20250929\n---\n\n# Data Commander\n\nAnalyze GitHub {issue_reference} in {repository_context} and generate {specification_format} technical specification that provides implementation-ready requirements and codebase integration guidance.\n\n## Variables:\n\n[IssueReference]: $ARGUMENTS \"GitHub issue URL, issue number, or search criteria\"\n[RepositoryContext]: $ARGUMENTS \"GitHub repository name or URL for context\"\n[SpecificationFormat]: $ARGUMENTS \"technical specification output format: detailed, summary, or implementation-focused\"\n[OutputLocation]: $ARGUMENTS \"file path for generated specification\"\n\n## Instructions:\n\n- Use GitHub CLI to fetch {IssueReference} details from {RepositoryContext}\n- Analyze issue description, comments, and related pull requests\n- Examine codebase structure to understand implementation context\n- Generate {SpecificationFormat} technical specification with clear requirements\n- Include implementation guidance based on existing codebase patterns\n- Validate specification completeness against issue requirements\n\n## Workflow:\n\n1. Authenticate GitHub CLI access and verify repository permissions\n2. Fetch issue details using `gh issue view {IssueReference} --repo {RepositoryContext} --json title,body,comments,assignees,labels,milestone`\n3. Extract core requirements, acceptance criteria, and technical constraints from issue content\n4. Analyze codebase structure using `find` and `grep` commands to identify relevant modules and patterns\n5. Review existing implementation patterns in related files and directories\n6. Cross-reference issue labels and milestone to understand project context and priority\n7. Generate technical specification document with sections: Overview, Requirements, Implementation Plan, Dependencies, Testing Strategy\n8. Include specific file paths, function signatures, and integration points based on codebase analysis\n9. Validate specification against issue acceptance criteria and technical feasibility\n10. Save specification to {OutputLocation} with structured format for development team review\n\n## Report:\n\nTechnical Specification Generated\n\nFile: {OutputLocation}\nSource Issue: {IssueReference} from {RepositoryContext}\nSpecification Type: {SpecificationFormat}\nKey Components:\n\n- Requirements analysis with acceptance criteria mapping\n- Implementation plan with specific code integration points\n- Dependencies and technical constraints identification\n- Testing strategy aligned with existing codebase patterns\n- Development timeline estimation based on complexity analysis\n\n## Relevant Files:\n\n- [GitHub issue and related discussions]\n- [Existing codebase files and modules identified during analysis]\n- [Project documentation and README files]\n"
              },
              {
                "name": "/data-commander",
                "description": null,
                "path": "data-science/commands/data-commander.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Bash, Read, Write, WebFetch, Grep, Glob\ndescription: Analyze GitHub issues and generate technical specifications for implementation\nargument-hint: [issue_url_or_number] [repository_name] [output_format]\nmodel: claude-sonnet-4-5-20250929\n---\n\n# Data Commander\n\nAnalyze GitHub {issue_reference} in {repository_context} and generate {specification_format} technical specification that provides implementation-ready requirements and codebase integration guidance.\n\n## Variables:\n\n[IssueReference]: $ARGUMENTS \"GitHub issue URL, issue number, or search criteria\"\n[RepositoryContext]: $ARGUMENTS \"GitHub repository name or URL for context\"\n[SpecificationFormat]: $ARGUMENTS \"technical specification output format: detailed, summary, or implementation-focused\"\n[OutputLocation]: $ARGUMENTS \"file path for generated specification\"\n\n## Instructions:\n\n- Use GitHub CLI to fetch {IssueReference} details from {RepositoryContext}\n- Analyze issue description, comments, and related pull requests\n- Examine codebase structure to understand implementation context\n- Generate {SpecificationFormat} technical specification with clear requirements\n- Include implementation guidance based on existing codebase patterns\n- Validate specification completeness against issue requirements\n\n## Workflow:\n\n1. Authenticate GitHub CLI access and verify repository permissions\n2. Fetch issue details using `gh issue view {IssueReference} --repo {RepositoryContext} --json title,body,comments,assignees,labels,milestone`\n3. Extract core requirements, acceptance criteria, and technical constraints from issue content\n4. Analyze codebase structure using `find` and `grep` commands to identify relevant modules and patterns\n5. Review existing implementation patterns in related files and directories\n6. Cross-reference issue labels and milestone to understand project context and priority\n7. Generate technical specification document with sections: Overview, Requirements, Implementation Plan, Dependencies, Testing Strategy\n8. Include specific file paths, function signatures, and integration points based on codebase analysis\n9. Validate specification against issue acceptance criteria and technical feasibility\n10. Save specification to {OutputLocation} with structured format for development team review\n\n## Report:\n\nTechnical Specification Generated\n\nFile: {OutputLocation}\nSource Issue: {IssueReference} from {RepositoryContext}\nSpecification Type: {SpecificationFormat}\nKey Components:\n\n- Requirements analysis with acceptance criteria mapping\n- Implementation plan with specific code integration points\n- Dependencies and technical constraints identification\n- Testing strategy aligned with existing codebase patterns\n- Development timeline estimation based on complexity analysis\n\n## Relevant Files:\n\n- [GitHub issue and related discussions]\n- [Existing codebase files and modules identified during analysis]\n- [Project documentation and README files]\n"
              }
            ],
            "skills": []
          },
          {
            "name": "documentation-agents",
            "description": "documentation AI agents for specialized tasks (2 agents)",
            "source": "./documentation-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install documentation-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "documentation-commands",
            "description": "documentation slash commands for Claude Code (4 commands)",
            "source": "./documentation-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install documentation-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/generate-readme",
                "description": null,
                "path": "documentation-commands/commands/generate-readme.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Task\ndescription: Use doc-curator agent to generate README following template standards\nargument-hint: [target-file] [template-mode]\nmodel: claude-3-5-haiku-20241022\n---\n\n# Generate README\n\nUse the doc-curator sub-agent to generate comprehensive `README.md` following `TEMPLATE_MODE` standards from `TARGET_FILE` template, ensuring no business-specific references or credentials are included.\n\n## Variables\n\nTARGET_FILE: $1 (default: README.md)\nTEMPLATE_MODE: $2 (default: ai-docs/readme-template.yaml)\nOUTPUT_DIRECTORY: current project root\nTEMPLATE_NAME: structured YAML template format\n\n## Workflow\n\n1. Use the doc-curator sub-agent to analyze current project structure\n2. Load template from `@ai-docs/readme-template.yaml`\n3. Extract metadata from configuration files (package.json, setup.py)\n4. Apply security filtering to remove business references and credentials\n5. Substitute template variables with sanitized project-specific content\n6. Generate navigation structure and setup instructions\n7. Write final README.md with comprehensive documentation\n\n## Report\n\nREADME Generation Complete\n\nFile: `TARGET_FILE`\nTemplate: `TEMPLATE_MODE` format applied\nKey Components:\n- Project metadata and description\n- Installation and setup instructions\n- Navigation structure\n- Security-sanitized content (no credentials/business refs)\n\n## Relevant Files\n\n- @ai-docs/readme-template.yaml\n- @package.json\n- @CLAUDE.md\n"
              },
              {
                "name": "/update-changelog",
                "description": "Update project CHANGELOG.md automatically from git commits",
                "path": "documentation-commands/commands/update-changelog.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Edit",
                  "description": "Update project CHANGELOG.md automatically from git commits",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Update Changelog\n\nRun `npm run changelog:force` to automatically update CHANGELOG.md from git commits. Review generated entry for $ARGUMENTS version, edit to follow conventions in ai-docs/changelog-conventions.md (proper categorization, clear descriptions, technical context), and commit the updated CHANGELOG.md file."
              },
              {
                "name": "/update-claude",
                "description": "Update CLAUDE.md using Serena-first analysis of recent code changes",
                "path": "documentation-commands/commands/update-claude.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(grep:*), Bash(wc:*), Bash(ls:*), mcp__serena__*",
                  "description": "Update CLAUDE.md using Serena-first analysis of recent code changes",
                  "argument-hint": [
                    "--directory target-dir"
                  ],
                  "flags": {
                    "--directory": "Create/update CLAUDE.md for a specific directory instead of project root"
                  },
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Update Claude.md\n\nUse Serena-first analysis to update CLAUDE.md based on recent code changes and git history.\n\n## Variables\n\nTARGET_DIRECTORY: {{if flags.directory}}{{flags.directory}}{{else}}.{{endif}}\nCLAUDE_FILE: {{if flags.directory}}{{flags.directory}}/CLAUDE.md{{else}}CLAUDE.md{{endif}}\nANALYSIS_SCOPE: {{if flags.directory}}directory-specific{{else}}project-wide{{endif}}\n\n## Workflow\n\n### 1. Initial Setup\n\n- Check Serena onboarding: `mcp__serena__check_onboarding_performed`\n- If not onboarded, complete onboarding process first\n- Use `mcp__serena__think_about_task_adherence` to validate update scope\n\n### 2. Git Analysis\n\n- Get current status: !`git status --porcelain`\n- Review recent commits: !`git log --oneline -10`\n- Analyze changed files: !`git diff HEAD~5 --name-only | head -20`\n- Check key file modifications: !`git diff --name-status HEAD~10 | grep \"^M\" | head -10`\n- Store git insights: `mcp__serena__write_memory --memory_name=\"git_analysis\"`\n\n### 3. Serena Codebase Analysis\n\n- Analyze directory structure: `mcp__serena__list_dir --relative_path=\"TARGET_DIRECTORY\" --recursive=true`\n- For each modified file from git analysis:\n  - Get symbol overview: `mcp__serena__get_symbols_overview --relative_path=\"<FILE>\"`\n  - Find new symbols: `mcp__serena__find_symbol --name_path=\"<NEW_SYMBOLS>\"`\n  - Check symbol impact: `mcp__serena__find_referencing_symbols --name_path=\"<KEY_SYMBOLS>\"`\n- Store symbol analysis: `mcp__serena__write_memory --memory_name=\"symbol_changes\"`\n\n### 4. Content Integration\n\n- Read existing CLAUDE.md file: @CLAUDE_FILE\n- Use `mcp__serena__think_about_collected_information` to validate analysis\n- Update CLAUDE.md based on @ai-docs/serena-enhanced-claude-template.md:\n  - Project overview with new architecture patterns\n- Save updated CLAUDE.md to CLAUDE_FILE location\n\n### 5. Validation\n\n- Use `mcp__serena__think_about_whether_you_are_done` to verify completeness\n- Store update insights: `mcp__serena__write_memory --memory_name=\"claude_update_ANALYSIS_SCOPE\"`\n\n## Report\n\nCLAUDE.md Update Complete\n\nFile: `CLAUDE_FILE`\nAnalysis Scope: ANALYSIS_SCOPE\nKey Updates:\n\n- Symbol-level changes documented in serena memory\n- Architecture patterns updated\n- Development workflow enhanced\n- Integration points clarified\n  Memory Stored: claude_update_ANALYSIS_SCOPE\n\n## Template Reference\n\nUse the comprehensive template from: @ai-docs/serena-enhanced-claude-template.md\n\n### Template Selection Logic\n\n{{if flags.directory}}\n\n- Apply directory-specific template sections from the referenced file\n- Focus on symbol-based architecture and development workflow patterns\n  {{else}}\n- Apply full project root template structure from the referenced file\n- Include all Serena-first development patterns and core command references\n  {{endif}}"
              },
              {
                "name": "/update-docs",
                "description": null,
                "path": "documentation-commands/commands/update-docs.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Task, Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(ls:*)\ndescription: Update existing documentation in docs/ directory based on uncommitted or recent code changes\nargument-hint: [--depth 5|10|20] [--focus api|config|usage|architecture] [--uncommitted]\nflags:\n  --depth: Number of commits to analyze for changes (default: 10)\n  --focus: Specific documentation area to prioritize (default: all)\n  --uncommitted: Only analyze uncommitted changes (working directory and staged)\nmodel: claude-sonnet-4-5-20250929\n---\n\n# Update Docs\n\nUse the doc-curator subagent to surgically update existing documentation in the `docs/` directory based on recent code changes. This command focuses on intelligent, incremental updates to keep documentation synchronized with code changes.\n\n## Variables\n\nDOCS_DIR: docs\nCOMMIT_DEPTH: {{if flags.depth}}{{flags.depth}}{{else}}10{{endif}}\nFOCUS_AREA: {{if flags.focus}}{{flags.focus}}{{else}}all{{endif}}\nANALYZE_MODE: {{if flags.uncommitted}}uncommitted{{else}}all{{endif}}\n\n## Workflow\n\n### 1. Quick Documentation Inventory\n\n- Check docs directory exists: !`ls docs/ 2>/dev/null | head -5`\n- List existing documentation files: !`find docs/ -type f -name \"*.md\" -o -name \"*.rst\" -o -name \"*.txt\" | sort`\n\n### 2. Identify What Changed\n\n#### Check for uncommitted changes first:\n\n- Working directory changes: !`git status --short | head -20`\n- Unstaged modifications: !`git diff --stat | head -15`\n- Staged changes: !`git diff --cached --stat | head -15`\n- Show uncommitted function changes: !`git diff --function-context | grep -E \"^@@|^\\+\\+\\+|function|class|def|interface\" | head -30`\n\n#### If no uncommitted changes, analyze recent commits:\n\n- Get recent commits: !`git log --oneline -COMMIT_DEPTH --name-status | grep -E \"^[AM]\" | head -20`\n- Show committed changes: !`git diff HEAD~COMMIT_DEPTH --stat | head -15`\n- Identify committed function changes: !`git diff HEAD~COMMIT_DEPTH --function-context | grep -E \"^@@|^\\+\\+\\+|function|class|def|interface\" | head -30`\n\n### 3. Launch Doc-Curator for Surgical Updates\n\nUse the doc-curator subagent with specific instructions based on FOCUS_AREA:\n\n```\nAnalyze these code changes (both uncommitted and recent commits) and update ONLY the affected sections in existing documentation:\n\nUncommitted changes:\n- [Output from git diff for working directory]\n- [Output from git diff --cached for staged changes]\n\nRecent committed changes (if analyzing history):\n- [Output from git diff HEAD~COMMIT_DEPTH]\n- [Specific functions/APIs that changed]\n\nDocumentation focus: FOCUS_AREA\nTarget directory: docs/\n\nInstructions:\n1. Read existing documentation files in docs/\n2. Identify which docs reference the changed code\n3. Make surgical updates ONLY where needed:\n   - Update function signatures if they changed\n   - Update configuration options if modified\n   - Update API endpoints if altered\n   - Update example code if it's now incorrect\n   - Add brief notes for new features\n   - Mark deprecated features\n4. Preserve all other content exactly as is\n5. Do NOT rewrite entire sections unless absolutely necessary\n6. Focus on accuracy over comprehensive rewrites\n```\n\n### 4. Types of Surgical Updates\n\n#### For API Changes (focus: api)\n\n- Update endpoint paths if renamed\n- Update request/response formats if changed\n- Update parameter descriptions if modified\n- Add new endpoints to existing lists\n- Mark deprecated endpoints\n\n#### For Configuration Changes (focus: config)\n\n- Update environment variable names\n- Update default values if changed\n- Add new configuration options\n- Remove obsolete settings\n- Update example configurations\n\n#### For Usage Changes (focus: usage)\n\n- Update command-line examples\n- Fix code snippets that no longer work\n- Update import statements if paths changed\n- Adjust setup instructions if process changed\n\n#### For Architecture Changes (focus: architecture)\n\n- Update component diagrams if structure changed\n- Revise data flow descriptions\n- Update dependency lists\n- Adjust system requirements\n\n## Report\n\nDocumentation Synchronization Complete\n\nDirectory: `DOCS_DIR`\nCommits Analyzed: COMMIT_DEPTH\nFocus Area: FOCUS_AREA\n\nSurgical Updates Applied:\n\n- [List of specific sections updated]\n- [Line-by-line changes made]\n- [New content added where needed]\n\nUpdate Summary:\n\n- Files Modified: [count and list]\n- Sections Updated: [specific sections touched]\n- Code Examples Fixed: [count]\n- Configuration Updates: [count]\n- API Changes Reflected: [count]\n\n## Examples of Surgical Updates\n\n**Function Signature Change:**\n\n```diff\n- `processData(input: string): void`\n+ `processData(input: string, options?: ProcessOptions): Promise<void>`\n```\n\n**Configuration Update:**\n\n```diff\n- `API_TIMEOUT`: 5000 (milliseconds)\n+ `API_TIMEOUT`: 10000 (milliseconds, increased for stability)\n```\n\n**Deprecated Feature:**\n\n```diff\n+ **Deprecated:** The `oldMethod()` function is deprecated as of v2.0. Use `newMethod()` instead.\n```\n"
              }
            ],
            "skills": []
          },
          {
            "name": "documentation-hooks",
            "description": "documentation automation hooks for development workflow",
            "source": "./documentation-hooks",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install documentation-hooks@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "documentation",
            "description": "Meta-package: Installs all documentation components (commands + agents + hooks)",
            "source": "./documentation",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install documentation@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/generate-readme",
                "description": null,
                "path": "documentation-commands/commands/generate-readme.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Task\ndescription: Use doc-curator agent to generate README following template standards\nargument-hint: [target-file] [template-mode]\nmodel: claude-3-5-haiku-20241022\n---\n\n# Generate README\n\nUse the doc-curator sub-agent to generate comprehensive `README.md` following `TEMPLATE_MODE` standards from `TARGET_FILE` template, ensuring no business-specific references or credentials are included.\n\n## Variables\n\nTARGET_FILE: $1 (default: README.md)\nTEMPLATE_MODE: $2 (default: ai-docs/readme-template.yaml)\nOUTPUT_DIRECTORY: current project root\nTEMPLATE_NAME: structured YAML template format\n\n## Workflow\n\n1. Use the doc-curator sub-agent to analyze current project structure\n2. Load template from `@ai-docs/readme-template.yaml`\n3. Extract metadata from configuration files (package.json, setup.py)\n4. Apply security filtering to remove business references and credentials\n5. Substitute template variables with sanitized project-specific content\n6. Generate navigation structure and setup instructions\n7. Write final README.md with comprehensive documentation\n\n## Report\n\nREADME Generation Complete\n\nFile: `TARGET_FILE`\nTemplate: `TEMPLATE_MODE` format applied\nKey Components:\n- Project metadata and description\n- Installation and setup instructions\n- Navigation structure\n- Security-sanitized content (no credentials/business refs)\n\n## Relevant Files\n\n- @ai-docs/readme-template.yaml\n- @package.json\n- @CLAUDE.md\n"
              },
              {
                "name": "/update-changelog",
                "description": "Update project CHANGELOG.md automatically from git commits",
                "path": "documentation-commands/commands/update-changelog.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Edit",
                  "description": "Update project CHANGELOG.md automatically from git commits",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Update Changelog\n\nRun `npm run changelog:force` to automatically update CHANGELOG.md from git commits. Review generated entry for $ARGUMENTS version, edit to follow conventions in ai-docs/changelog-conventions.md (proper categorization, clear descriptions, technical context), and commit the updated CHANGELOG.md file."
              },
              {
                "name": "/update-claude",
                "description": "Update CLAUDE.md using Serena-first analysis of recent code changes",
                "path": "documentation-commands/commands/update-claude.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(grep:*), Bash(wc:*), Bash(ls:*), mcp__serena__*",
                  "description": "Update CLAUDE.md using Serena-first analysis of recent code changes",
                  "argument-hint": [
                    "--directory target-dir"
                  ],
                  "flags": {
                    "--directory": "Create/update CLAUDE.md for a specific directory instead of project root"
                  },
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Update Claude.md\n\nUse Serena-first analysis to update CLAUDE.md based on recent code changes and git history.\n\n## Variables\n\nTARGET_DIRECTORY: {{if flags.directory}}{{flags.directory}}{{else}}.{{endif}}\nCLAUDE_FILE: {{if flags.directory}}{{flags.directory}}/CLAUDE.md{{else}}CLAUDE.md{{endif}}\nANALYSIS_SCOPE: {{if flags.directory}}directory-specific{{else}}project-wide{{endif}}\n\n## Workflow\n\n### 1. Initial Setup\n\n- Check Serena onboarding: `mcp__serena__check_onboarding_performed`\n- If not onboarded, complete onboarding process first\n- Use `mcp__serena__think_about_task_adherence` to validate update scope\n\n### 2. Git Analysis\n\n- Get current status: !`git status --porcelain`\n- Review recent commits: !`git log --oneline -10`\n- Analyze changed files: !`git diff HEAD~5 --name-only | head -20`\n- Check key file modifications: !`git diff --name-status HEAD~10 | grep \"^M\" | head -10`\n- Store git insights: `mcp__serena__write_memory --memory_name=\"git_analysis\"`\n\n### 3. Serena Codebase Analysis\n\n- Analyze directory structure: `mcp__serena__list_dir --relative_path=\"TARGET_DIRECTORY\" --recursive=true`\n- For each modified file from git analysis:\n  - Get symbol overview: `mcp__serena__get_symbols_overview --relative_path=\"<FILE>\"`\n  - Find new symbols: `mcp__serena__find_symbol --name_path=\"<NEW_SYMBOLS>\"`\n  - Check symbol impact: `mcp__serena__find_referencing_symbols --name_path=\"<KEY_SYMBOLS>\"`\n- Store symbol analysis: `mcp__serena__write_memory --memory_name=\"symbol_changes\"`\n\n### 4. Content Integration\n\n- Read existing CLAUDE.md file: @CLAUDE_FILE\n- Use `mcp__serena__think_about_collected_information` to validate analysis\n- Update CLAUDE.md based on @ai-docs/serena-enhanced-claude-template.md:\n  - Project overview with new architecture patterns\n- Save updated CLAUDE.md to CLAUDE_FILE location\n\n### 5. Validation\n\n- Use `mcp__serena__think_about_whether_you_are_done` to verify completeness\n- Store update insights: `mcp__serena__write_memory --memory_name=\"claude_update_ANALYSIS_SCOPE\"`\n\n## Report\n\nCLAUDE.md Update Complete\n\nFile: `CLAUDE_FILE`\nAnalysis Scope: ANALYSIS_SCOPE\nKey Updates:\n\n- Symbol-level changes documented in serena memory\n- Architecture patterns updated\n- Development workflow enhanced\n- Integration points clarified\n  Memory Stored: claude_update_ANALYSIS_SCOPE\n\n## Template Reference\n\nUse the comprehensive template from: @ai-docs/serena-enhanced-claude-template.md\n\n### Template Selection Logic\n\n{{if flags.directory}}\n\n- Apply directory-specific template sections from the referenced file\n- Focus on symbol-based architecture and development workflow patterns\n  {{else}}\n- Apply full project root template structure from the referenced file\n- Include all Serena-first development patterns and core command references\n  {{endif}}"
              },
              {
                "name": "/update-docs",
                "description": null,
                "path": "documentation-commands/commands/update-docs.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Task, Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(ls:*)\ndescription: Update existing documentation in docs/ directory based on uncommitted or recent code changes\nargument-hint: [--depth 5|10|20] [--focus api|config|usage|architecture] [--uncommitted]\nflags:\n  --depth: Number of commits to analyze for changes (default: 10)\n  --focus: Specific documentation area to prioritize (default: all)\n  --uncommitted: Only analyze uncommitted changes (working directory and staged)\nmodel: claude-sonnet-4-5-20250929\n---\n\n# Update Docs\n\nUse the doc-curator subagent to surgically update existing documentation in the `docs/` directory based on recent code changes. This command focuses on intelligent, incremental updates to keep documentation synchronized with code changes.\n\n## Variables\n\nDOCS_DIR: docs\nCOMMIT_DEPTH: {{if flags.depth}}{{flags.depth}}{{else}}10{{endif}}\nFOCUS_AREA: {{if flags.focus}}{{flags.focus}}{{else}}all{{endif}}\nANALYZE_MODE: {{if flags.uncommitted}}uncommitted{{else}}all{{endif}}\n\n## Workflow\n\n### 1. Quick Documentation Inventory\n\n- Check docs directory exists: !`ls docs/ 2>/dev/null | head -5`\n- List existing documentation files: !`find docs/ -type f -name \"*.md\" -o -name \"*.rst\" -o -name \"*.txt\" | sort`\n\n### 2. Identify What Changed\n\n#### Check for uncommitted changes first:\n\n- Working directory changes: !`git status --short | head -20`\n- Unstaged modifications: !`git diff --stat | head -15`\n- Staged changes: !`git diff --cached --stat | head -15`\n- Show uncommitted function changes: !`git diff --function-context | grep -E \"^@@|^\\+\\+\\+|function|class|def|interface\" | head -30`\n\n#### If no uncommitted changes, analyze recent commits:\n\n- Get recent commits: !`git log --oneline -COMMIT_DEPTH --name-status | grep -E \"^[AM]\" | head -20`\n- Show committed changes: !`git diff HEAD~COMMIT_DEPTH --stat | head -15`\n- Identify committed function changes: !`git diff HEAD~COMMIT_DEPTH --function-context | grep -E \"^@@|^\\+\\+\\+|function|class|def|interface\" | head -30`\n\n### 3. Launch Doc-Curator for Surgical Updates\n\nUse the doc-curator subagent with specific instructions based on FOCUS_AREA:\n\n```\nAnalyze these code changes (both uncommitted and recent commits) and update ONLY the affected sections in existing documentation:\n\nUncommitted changes:\n- [Output from git diff for working directory]\n- [Output from git diff --cached for staged changes]\n\nRecent committed changes (if analyzing history):\n- [Output from git diff HEAD~COMMIT_DEPTH]\n- [Specific functions/APIs that changed]\n\nDocumentation focus: FOCUS_AREA\nTarget directory: docs/\n\nInstructions:\n1. Read existing documentation files in docs/\n2. Identify which docs reference the changed code\n3. Make surgical updates ONLY where needed:\n   - Update function signatures if they changed\n   - Update configuration options if modified\n   - Update API endpoints if altered\n   - Update example code if it's now incorrect\n   - Add brief notes for new features\n   - Mark deprecated features\n4. Preserve all other content exactly as is\n5. Do NOT rewrite entire sections unless absolutely necessary\n6. Focus on accuracy over comprehensive rewrites\n```\n\n### 4. Types of Surgical Updates\n\n#### For API Changes (focus: api)\n\n- Update endpoint paths if renamed\n- Update request/response formats if changed\n- Update parameter descriptions if modified\n- Add new endpoints to existing lists\n- Mark deprecated endpoints\n\n#### For Configuration Changes (focus: config)\n\n- Update environment variable names\n- Update default values if changed\n- Add new configuration options\n- Remove obsolete settings\n- Update example configurations\n\n#### For Usage Changes (focus: usage)\n\n- Update command-line examples\n- Fix code snippets that no longer work\n- Update import statements if paths changed\n- Adjust setup instructions if process changed\n\n#### For Architecture Changes (focus: architecture)\n\n- Update component diagrams if structure changed\n- Revise data flow descriptions\n- Update dependency lists\n- Adjust system requirements\n\n## Report\n\nDocumentation Synchronization Complete\n\nDirectory: `DOCS_DIR`\nCommits Analyzed: COMMIT_DEPTH\nFocus Area: FOCUS_AREA\n\nSurgical Updates Applied:\n\n- [List of specific sections updated]\n- [Line-by-line changes made]\n- [New content added where needed]\n\nUpdate Summary:\n\n- Files Modified: [count and list]\n- Sections Updated: [specific sections touched]\n- Code Examples Fixed: [count]\n- Configuration Updates: [count]\n- API Changes Reflected: [count]\n\n## Examples of Surgical Updates\n\n**Function Signature Change:**\n\n```diff\n- `processData(input: string): void`\n+ `processData(input: string, options?: ProcessOptions): Promise<void>`\n```\n\n**Configuration Update:**\n\n```diff\n- `API_TIMEOUT`: 5000 (milliseconds)\n+ `API_TIMEOUT`: 10000 (milliseconds, increased for stability)\n```\n\n**Deprecated Feature:**\n\n```diff\n+ **Deprecated:** The `oldMethod()` function is deprecated as of v2.0. Use `newMethod()` instead.\n```\n"
              },
              {
                "name": "/generate-readme",
                "description": null,
                "path": "documentation/commands/generate-readme.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Task\ndescription: Use doc-curator agent to generate README following template standards\nargument-hint: [target-file] [template-mode]\nmodel: claude-3-5-haiku-20241022\n---\n\n# Generate README\n\nUse the doc-curator sub-agent to generate comprehensive `README.md` following `TEMPLATE_MODE` standards from `TARGET_FILE` template, ensuring no business-specific references or credentials are included.\n\n## Variables\n\nTARGET_FILE: $1 (default: README.md)\nTEMPLATE_MODE: $2 (default: ai-docs/readme-template.yaml)\nOUTPUT_DIRECTORY: current project root\nTEMPLATE_NAME: structured YAML template format\n\n## Workflow\n\n1. Use the doc-curator sub-agent to analyze current project structure\n2. Load template from `@ai-docs/readme-template.yaml`\n3. Extract metadata from configuration files (package.json, setup.py)\n4. Apply security filtering to remove business references and credentials\n5. Substitute template variables with sanitized project-specific content\n6. Generate navigation structure and setup instructions\n7. Write final README.md with comprehensive documentation\n\n## Report\n\nREADME Generation Complete\n\nFile: `TARGET_FILE`\nTemplate: `TEMPLATE_MODE` format applied\nKey Components:\n- Project metadata and description\n- Installation and setup instructions\n- Navigation structure\n- Security-sanitized content (no credentials/business refs)\n\n## Relevant Files\n\n- @ai-docs/readme-template.yaml\n- @package.json\n- @CLAUDE.md\n"
              },
              {
                "name": "/update-changelog",
                "description": "Update project CHANGELOG.md automatically from git commits",
                "path": "documentation/commands/update-changelog.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Edit",
                  "description": "Update project CHANGELOG.md automatically from git commits",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Update Changelog\n\nRun `npm run changelog:force` to automatically update CHANGELOG.md from git commits. Review generated entry for $ARGUMENTS version, edit to follow conventions in ai-docs/changelog-conventions.md (proper categorization, clear descriptions, technical context), and commit the updated CHANGELOG.md file."
              },
              {
                "name": "/update-claude",
                "description": "Update CLAUDE.md using Serena-first analysis of recent code changes",
                "path": "documentation/commands/update-claude.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(grep:*), Bash(wc:*), Bash(ls:*), mcp__serena__*",
                  "description": "Update CLAUDE.md using Serena-first analysis of recent code changes",
                  "argument-hint": [
                    "--directory target-dir"
                  ],
                  "flags": {
                    "--directory": "Create/update CLAUDE.md for a specific directory instead of project root"
                  },
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Update Claude.md\n\nUse Serena-first analysis to update CLAUDE.md based on recent code changes and git history.\n\n## Variables\n\nTARGET_DIRECTORY: {{if flags.directory}}{{flags.directory}}{{else}}.{{endif}}\nCLAUDE_FILE: {{if flags.directory}}{{flags.directory}}/CLAUDE.md{{else}}CLAUDE.md{{endif}}\nANALYSIS_SCOPE: {{if flags.directory}}directory-specific{{else}}project-wide{{endif}}\n\n## Workflow\n\n### 1. Initial Setup\n\n- Check Serena onboarding: `mcp__serena__check_onboarding_performed`\n- If not onboarded, complete onboarding process first\n- Use `mcp__serena__think_about_task_adherence` to validate update scope\n\n### 2. Git Analysis\n\n- Get current status: !`git status --porcelain`\n- Review recent commits: !`git log --oneline -10`\n- Analyze changed files: !`git diff HEAD~5 --name-only | head -20`\n- Check key file modifications: !`git diff --name-status HEAD~10 | grep \"^M\" | head -10`\n- Store git insights: `mcp__serena__write_memory --memory_name=\"git_analysis\"`\n\n### 3. Serena Codebase Analysis\n\n- Analyze directory structure: `mcp__serena__list_dir --relative_path=\"TARGET_DIRECTORY\" --recursive=true`\n- For each modified file from git analysis:\n  - Get symbol overview: `mcp__serena__get_symbols_overview --relative_path=\"<FILE>\"`\n  - Find new symbols: `mcp__serena__find_symbol --name_path=\"<NEW_SYMBOLS>\"`\n  - Check symbol impact: `mcp__serena__find_referencing_symbols --name_path=\"<KEY_SYMBOLS>\"`\n- Store symbol analysis: `mcp__serena__write_memory --memory_name=\"symbol_changes\"`\n\n### 4. Content Integration\n\n- Read existing CLAUDE.md file: @CLAUDE_FILE\n- Use `mcp__serena__think_about_collected_information` to validate analysis\n- Update CLAUDE.md based on @ai-docs/serena-enhanced-claude-template.md:\n  - Project overview with new architecture patterns\n- Save updated CLAUDE.md to CLAUDE_FILE location\n\n### 5. Validation\n\n- Use `mcp__serena__think_about_whether_you_are_done` to verify completeness\n- Store update insights: `mcp__serena__write_memory --memory_name=\"claude_update_ANALYSIS_SCOPE\"`\n\n## Report\n\nCLAUDE.md Update Complete\n\nFile: `CLAUDE_FILE`\nAnalysis Scope: ANALYSIS_SCOPE\nKey Updates:\n\n- Symbol-level changes documented in serena memory\n- Architecture patterns updated\n- Development workflow enhanced\n- Integration points clarified\n  Memory Stored: claude_update_ANALYSIS_SCOPE\n\n## Template Reference\n\nUse the comprehensive template from: @ai-docs/serena-enhanced-claude-template.md\n\n### Template Selection Logic\n\n{{if flags.directory}}\n\n- Apply directory-specific template sections from the referenced file\n- Focus on symbol-based architecture and development workflow patterns\n  {{else}}\n- Apply full project root template structure from the referenced file\n- Include all Serena-first development patterns and core command references\n  {{endif}}"
              },
              {
                "name": "/update-docs",
                "description": null,
                "path": "documentation/commands/update-docs.md",
                "frontmatter": null,
                "content": "---\nallowed-tools: Task, Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(ls:*)\ndescription: Update existing documentation in docs/ directory based on uncommitted or recent code changes\nargument-hint: [--depth 5|10|20] [--focus api|config|usage|architecture] [--uncommitted]\nflags:\n  --depth: Number of commits to analyze for changes (default: 10)\n  --focus: Specific documentation area to prioritize (default: all)\n  --uncommitted: Only analyze uncommitted changes (working directory and staged)\nmodel: claude-sonnet-4-5-20250929\n---\n\n# Update Docs\n\nUse the doc-curator subagent to surgically update existing documentation in the `docs/` directory based on recent code changes. This command focuses on intelligent, incremental updates to keep documentation synchronized with code changes.\n\n## Variables\n\nDOCS_DIR: docs\nCOMMIT_DEPTH: {{if flags.depth}}{{flags.depth}}{{else}}10{{endif}}\nFOCUS_AREA: {{if flags.focus}}{{flags.focus}}{{else}}all{{endif}}\nANALYZE_MODE: {{if flags.uncommitted}}uncommitted{{else}}all{{endif}}\n\n## Workflow\n\n### 1. Quick Documentation Inventory\n\n- Check docs directory exists: !`ls docs/ 2>/dev/null | head -5`\n- List existing documentation files: !`find docs/ -type f -name \"*.md\" -o -name \"*.rst\" -o -name \"*.txt\" | sort`\n\n### 2. Identify What Changed\n\n#### Check for uncommitted changes first:\n\n- Working directory changes: !`git status --short | head -20`\n- Unstaged modifications: !`git diff --stat | head -15`\n- Staged changes: !`git diff --cached --stat | head -15`\n- Show uncommitted function changes: !`git diff --function-context | grep -E \"^@@|^\\+\\+\\+|function|class|def|interface\" | head -30`\n\n#### If no uncommitted changes, analyze recent commits:\n\n- Get recent commits: !`git log --oneline -COMMIT_DEPTH --name-status | grep -E \"^[AM]\" | head -20`\n- Show committed changes: !`git diff HEAD~COMMIT_DEPTH --stat | head -15`\n- Identify committed function changes: !`git diff HEAD~COMMIT_DEPTH --function-context | grep -E \"^@@|^\\+\\+\\+|function|class|def|interface\" | head -30`\n\n### 3. Launch Doc-Curator for Surgical Updates\n\nUse the doc-curator subagent with specific instructions based on FOCUS_AREA:\n\n```\nAnalyze these code changes (both uncommitted and recent commits) and update ONLY the affected sections in existing documentation:\n\nUncommitted changes:\n- [Output from git diff for working directory]\n- [Output from git diff --cached for staged changes]\n\nRecent committed changes (if analyzing history):\n- [Output from git diff HEAD~COMMIT_DEPTH]\n- [Specific functions/APIs that changed]\n\nDocumentation focus: FOCUS_AREA\nTarget directory: docs/\n\nInstructions:\n1. Read existing documentation files in docs/\n2. Identify which docs reference the changed code\n3. Make surgical updates ONLY where needed:\n   - Update function signatures if they changed\n   - Update configuration options if modified\n   - Update API endpoints if altered\n   - Update example code if it's now incorrect\n   - Add brief notes for new features\n   - Mark deprecated features\n4. Preserve all other content exactly as is\n5. Do NOT rewrite entire sections unless absolutely necessary\n6. Focus on accuracy over comprehensive rewrites\n```\n\n### 4. Types of Surgical Updates\n\n#### For API Changes (focus: api)\n\n- Update endpoint paths if renamed\n- Update request/response formats if changed\n- Update parameter descriptions if modified\n- Add new endpoints to existing lists\n- Mark deprecated endpoints\n\n#### For Configuration Changes (focus: config)\n\n- Update environment variable names\n- Update default values if changed\n- Add new configuration options\n- Remove obsolete settings\n- Update example configurations\n\n#### For Usage Changes (focus: usage)\n\n- Update command-line examples\n- Fix code snippets that no longer work\n- Update import statements if paths changed\n- Adjust setup instructions if process changed\n\n#### For Architecture Changes (focus: architecture)\n\n- Update component diagrams if structure changed\n- Revise data flow descriptions\n- Update dependency lists\n- Adjust system requirements\n\n## Report\n\nDocumentation Synchronization Complete\n\nDirectory: `DOCS_DIR`\nCommits Analyzed: COMMIT_DEPTH\nFocus Area: FOCUS_AREA\n\nSurgical Updates Applied:\n\n- [List of specific sections updated]\n- [Line-by-line changes made]\n- [New content added where needed]\n\nUpdate Summary:\n\n- Files Modified: [count and list]\n- Sections Updated: [specific sections touched]\n- Code Examples Fixed: [count]\n- Configuration Updates: [count]\n- API Changes Reflected: [count]\n\n## Examples of Surgical Updates\n\n**Function Signature Change:**\n\n```diff\n- `processData(input: string): void`\n+ `processData(input: string, options?: ProcessOptions): Promise<void>`\n```\n\n**Configuration Update:**\n\n```diff\n- `API_TIMEOUT`: 5000 (milliseconds)\n+ `API_TIMEOUT`: 10000 (milliseconds, increased for stability)\n```\n\n**Deprecated Feature:**\n\n```diff\n+ **Deprecated:** The `oldMethod()` function is deprecated as of v2.0. Use `newMethod()` instead.\n```\n"
              }
            ],
            "skills": []
          },
          {
            "name": "git-workflow-agents",
            "description": "git-workflow AI agents for specialized tasks (2 agents)",
            "source": "./git-workflow-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install git-workflow-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "git-workflow-commands",
            "description": "git-workflow slash commands for Claude Code (2 commands)",
            "source": "./git-workflow-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install git-workflow-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/create-pr",
                "description": "Create pull requests for completed work with automatic context gathering",
                "path": "git-workflow-commands/commands/create-pr.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Grep, MultiEdit, Read, TodoWrite, WebFetch, Write",
                  "description": "Create pull requests for completed work with automatic context gathering"
                },
                "content": "# Create PR\n\nUse the pr-specialist sub-agent to create comprehensive pull requests for completed work with automatic context gathering. Parse $ARGUMENTS for title, branches, and Linear task ID, gather context from git history and changed files, validate readiness (commits, tests, linting), generate structured PR content with conventional format and checklist, create PR via gh CLI with labels and reviewers, and provide PR URL and next steps."
              },
              {
                "name": "/review-merge",
                "description": "Review and merge pull requests with comprehensive validation and safety checks",
                "path": "git-workflow-commands/commands/review-merge.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Grep, MultiEdit, Read, TodoWrite, WebFetch, Write",
                  "description": "Review and merge pull requests with comprehensive validation and safety checks",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Review Merge\n\nReview and merge pull requests with comprehensive validation and safety checks. Parse $ARGUMENTS for PR number and merge strategy (merge/squash/rebase), fetch PR details via gh commands, validate CI checks and reviews, verify test coverage and security scans, perform interactive review of changes, execute merge with selected strategy, and handle post-merge cleanup including branch deletion and Linear task updates."
              }
            ],
            "skills": []
          },
          {
            "name": "git-workflow-hooks",
            "description": "git-workflow automation hooks for development workflow",
            "source": "./git-workflow-hooks",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install git-workflow-hooks@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "git-workflow",
            "description": "Meta-package: Installs all git-workflow components (commands + agents + hooks)",
            "source": "./git-workflow",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install git-workflow@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/create-pr",
                "description": "Create pull requests for completed work with automatic context gathering",
                "path": "git-workflow-commands/commands/create-pr.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Grep, MultiEdit, Read, TodoWrite, WebFetch, Write",
                  "description": "Create pull requests for completed work with automatic context gathering"
                },
                "content": "# Create PR\n\nUse the pr-specialist sub-agent to create comprehensive pull requests for completed work with automatic context gathering. Parse $ARGUMENTS for title, branches, and Linear task ID, gather context from git history and changed files, validate readiness (commits, tests, linting), generate structured PR content with conventional format and checklist, create PR via gh CLI with labels and reviewers, and provide PR URL and next steps."
              },
              {
                "name": "/review-merge",
                "description": "Review and merge pull requests with comprehensive validation and safety checks",
                "path": "git-workflow-commands/commands/review-merge.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Grep, MultiEdit, Read, TodoWrite, WebFetch, Write",
                  "description": "Review and merge pull requests with comprehensive validation and safety checks",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Review Merge\n\nReview and merge pull requests with comprehensive validation and safety checks. Parse $ARGUMENTS for PR number and merge strategy (merge/squash/rebase), fetch PR details via gh commands, validate CI checks and reviews, verify test coverage and security scans, perform interactive review of changes, execute merge with selected strategy, and handle post-merge cleanup including branch deletion and Linear task updates."
              },
              {
                "name": "/create-pr",
                "description": "Create pull requests for completed work with automatic context gathering",
                "path": "git-workflow/commands/create-pr.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Grep, MultiEdit, Read, TodoWrite, WebFetch, Write",
                  "description": "Create pull requests for completed work with automatic context gathering"
                },
                "content": "# Create PR\n\nUse the pr-specialist sub-agent to create comprehensive pull requests for completed work with automatic context gathering. Parse $ARGUMENTS for title, branches, and Linear task ID, gather context from git history and changed files, validate readiness (commits, tests, linting), generate structured PR content with conventional format and checklist, create PR via gh CLI with labels and reviewers, and provide PR URL and next steps."
              },
              {
                "name": "/review-merge",
                "description": "Review and merge pull requests with comprehensive validation and safety checks",
                "path": "git-workflow/commands/review-merge.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Grep, MultiEdit, Read, TodoWrite, WebFetch, Write",
                  "description": "Review and merge pull requests with comprehensive validation and safety checks",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Review Merge\n\nReview and merge pull requests with comprehensive validation and safety checks. Parse $ARGUMENTS for PR number and merge strategy (merge/squash/rebase), fetch PR details via gh commands, validate CI checks and reviews, verify test coverage and security scans, perform interactive review of changes, execute merge with selected strategy, and handle post-merge cleanup including branch deletion and Linear task updates."
              }
            ],
            "skills": []
          },
          {
            "name": "lang-apps-script-agents",
            "description": "lang-apps-script AI agents for specialized tasks (2 agents)",
            "source": "./lang-apps-script-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-apps-script-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-apps-script",
            "description": "Meta-package: Installs all lang-apps-script components (agents)",
            "source": "./lang-apps-script",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-apps-script@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-fullstack-agents",
            "description": "lang-fullstack AI agents for specialized tasks (3 agents)",
            "source": "./lang-fullstack-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-fullstack-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-fullstack",
            "description": "Meta-package: Installs all lang-fullstack components (agents)",
            "source": "./lang-fullstack",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-fullstack@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-javascript-agents",
            "description": "lang-javascript AI agents for specialized tasks (2 agents)",
            "source": "./lang-javascript-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-javascript-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-javascript-hooks",
            "description": "lang-javascript automation hooks for development workflow",
            "source": "./lang-javascript-hooks",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-javascript-hooks@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-javascript",
            "description": "Meta-package: Installs all lang-javascript components (agents + hooks)",
            "source": "./lang-javascript",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-javascript@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-python-agents",
            "description": "lang-python AI agents for specialized tasks (1 agents)",
            "source": "./lang-python-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-python-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "lang-python",
            "description": "Meta-package: Installs all lang-python components (agents)",
            "source": "./lang-python",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install lang-python@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "research-intelligence-agents",
            "description": "research-intelligence AI agents for specialized tasks (12 agents)",
            "source": "./research-intelligence-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install research-intelligence-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "research-intelligence-commands",
            "description": "research-intelligence slash commands for Claude Code (1 commands)",
            "source": "./research-intelligence-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install research-intelligence-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/scrape-site",
                "description": "Scrape websites using Firecrawl MCP and save content to research folders",
                "path": "research-intelligence-commands/commands/scrape-site.md",
                "frontmatter": {
                  "allowed-tools": "mcp__mcp-server-firecrawl__firecrawl_scrape, Write, Bash",
                  "description": "Scrape websites using Firecrawl MCP and save content to research folders",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Scrape Site\n\nThis command scrapes websites using the Firecrawl MCP and intelligently saves the content to organized research folders within the desktop-commander documentation system.\n\n$ARGUMENTS\n\n**Usage Examples:**\n\n- `/scrape-site https://docs.anthropic.com/claude/guide` - Scrape and auto-organize in research folder\n- `/scrape-site https://example.com/api \"api-docs\"` - Scrape and save to specific subfolder\n- `/scrape-site https://github.com/owner/repo/wiki \"github-wiki\"` - Save with custom folder name\n\n## Instructions\n\n- Extract the URL from `$ARGUMENTS` (first argument is always the URL to scrape)\n- If second argument provided, use it as the subfolder name; otherwise auto-generate from URL domain\n- Use Firecrawl MCP to scrape the site with markdown format and main content extraction\n- Create organized folder structure in `docs/research/[domain-or-subfolder]/`\n- Generate descriptive filename based on URL path or page title\n- Save scraped content as markdown file with metadata header (URL, date, source)\n- Create or update an index file in the research folder listing all scraped content\n- Provide summary of scraped content and file location\n\n## Context\n\n- Research folder structure: `docs/research/` (organized by domain/topic)\n- Existing research: !`ls -la docs/context7-research/ docs/research/ 2>/dev/null | head -10`\n- Firecrawl MCP status: Available for web scraping with markdown output\n- Current date: !`date \"+%Y-%m-%d\"`\n- Content organization: domain-based folders (anthropic, github, etc.) or custom subfolder names\n- File naming: descriptive names based on URL path, avoiding special characters\n- Metadata format: YAML frontmatter with url, scraped_date, domain, and title fields"
              }
            ],
            "skills": []
          },
          {
            "name": "research-intelligence",
            "description": "Meta-package: Installs all research-intelligence components (commands + agents)",
            "source": "./research-intelligence",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install research-intelligence@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/scrape-site",
                "description": "Scrape websites using Firecrawl MCP and save content to research folders",
                "path": "research-intelligence-commands/commands/scrape-site.md",
                "frontmatter": {
                  "allowed-tools": "mcp__mcp-server-firecrawl__firecrawl_scrape, Write, Bash",
                  "description": "Scrape websites using Firecrawl MCP and save content to research folders",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Scrape Site\n\nThis command scrapes websites using the Firecrawl MCP and intelligently saves the content to organized research folders within the desktop-commander documentation system.\n\n$ARGUMENTS\n\n**Usage Examples:**\n\n- `/scrape-site https://docs.anthropic.com/claude/guide` - Scrape and auto-organize in research folder\n- `/scrape-site https://example.com/api \"api-docs\"` - Scrape and save to specific subfolder\n- `/scrape-site https://github.com/owner/repo/wiki \"github-wiki\"` - Save with custom folder name\n\n## Instructions\n\n- Extract the URL from `$ARGUMENTS` (first argument is always the URL to scrape)\n- If second argument provided, use it as the subfolder name; otherwise auto-generate from URL domain\n- Use Firecrawl MCP to scrape the site with markdown format and main content extraction\n- Create organized folder structure in `docs/research/[domain-or-subfolder]/`\n- Generate descriptive filename based on URL path or page title\n- Save scraped content as markdown file with metadata header (URL, date, source)\n- Create or update an index file in the research folder listing all scraped content\n- Provide summary of scraped content and file location\n\n## Context\n\n- Research folder structure: `docs/research/` (organized by domain/topic)\n- Existing research: !`ls -la docs/context7-research/ docs/research/ 2>/dev/null | head -10`\n- Firecrawl MCP status: Available for web scraping with markdown output\n- Current date: !`date \"+%Y-%m-%d\"`\n- Content organization: domain-based folders (anthropic, github, etc.) or custom subfolder names\n- File naming: descriptive names based on URL path, avoiding special characters\n- Metadata format: YAML frontmatter with url, scraped_date, domain, and title fields"
              },
              {
                "name": "/scrape-site",
                "description": "Scrape websites using Firecrawl MCP and save content to research folders",
                "path": "research-intelligence/commands/scrape-site.md",
                "frontmatter": {
                  "allowed-tools": "mcp__mcp-server-firecrawl__firecrawl_scrape, Write, Bash",
                  "description": "Scrape websites using Firecrawl MCP and save content to research folders",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Scrape Site\n\nThis command scrapes websites using the Firecrawl MCP and intelligently saves the content to organized research folders within the desktop-commander documentation system.\n\n$ARGUMENTS\n\n**Usage Examples:**\n\n- `/scrape-site https://docs.anthropic.com/claude/guide` - Scrape and auto-organize in research folder\n- `/scrape-site https://example.com/api \"api-docs\"` - Scrape and save to specific subfolder\n- `/scrape-site https://github.com/owner/repo/wiki \"github-wiki\"` - Save with custom folder name\n\n## Instructions\n\n- Extract the URL from `$ARGUMENTS` (first argument is always the URL to scrape)\n- If second argument provided, use it as the subfolder name; otherwise auto-generate from URL domain\n- Use Firecrawl MCP to scrape the site with markdown format and main content extraction\n- Create organized folder structure in `docs/research/[domain-or-subfolder]/`\n- Generate descriptive filename based on URL path or page title\n- Save scraped content as markdown file with metadata header (URL, date, source)\n- Create or update an index file in the research folder listing all scraped content\n- Provide summary of scraped content and file location\n\n## Context\n\n- Research folder structure: `docs/research/` (organized by domain/topic)\n- Existing research: !`ls -la docs/context7-research/ docs/research/ 2>/dev/null | head -10`\n- Firecrawl MCP status: Available for web scraping with markdown output\n- Current date: !`date \"+%Y-%m-%d\"`\n- Content organization: domain-based folders (anthropic, github, etc.) or custom subfolder names\n- File naming: descriptive names based on URL path, avoiding special characters\n- Metadata format: YAML frontmatter with url, scraped_date, domain, and title fields"
              }
            ],
            "skills": []
          },
          {
            "name": "shell-config-agents",
            "description": "shell-config AI agents for specialized tasks (1 agents)",
            "source": "./shell-config-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install shell-config-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "shell-config-commands",
            "description": "shell-config slash commands for Claude Code (1 commands)",
            "source": "./shell-config-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install shell-config-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/enforce-structure",
                "description": "Validates and enforcts clean root directory structure with automatic file organization",
                "path": "shell-config-commands/commands/enforce-structure.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Glob, LS, Read, Write",
                  "description": "Validates and enforcts clean root directory structure with automatic file organization",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Enforce Structure\n\nThis command is used to enforce the structure of the root directory.\n\n##Instructions\n\n- Use the structure-enforcer sub-agent to validate and enforce clean root directory structure with automatic file organization.\n- Parse $ARGUMENTS for operation mode (default: fix, --dry-run: preview, --report: detailed), deploy parallel scanning for misplaced files using coordinated root_scanner and deep_scanner agents, move files to appropriate directories (config/, scripts/, docs/, archive/) based on patterns, clean up temporary files and cache, and validate final state compliance with structure rules.\n\n##Context\n\n- Codebase structure all: !`eza . --tree`\n- Documentation:\n  - @ai-docs/structure-enforcement-system.md"
              }
            ],
            "skills": []
          },
          {
            "name": "shell-config",
            "description": "Meta-package: Installs all shell-config components (commands + agents)",
            "source": "./shell-config",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install shell-config@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/enforce-structure",
                "description": "Validates and enforcts clean root directory structure with automatic file organization",
                "path": "shell-config-commands/commands/enforce-structure.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Glob, LS, Read, Write",
                  "description": "Validates and enforcts clean root directory structure with automatic file organization",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Enforce Structure\n\nThis command is used to enforce the structure of the root directory.\n\n##Instructions\n\n- Use the structure-enforcer sub-agent to validate and enforce clean root directory structure with automatic file organization.\n- Parse $ARGUMENTS for operation mode (default: fix, --dry-run: preview, --report: detailed), deploy parallel scanning for misplaced files using coordinated root_scanner and deep_scanner agents, move files to appropriate directories (config/, scripts/, docs/, archive/) based on patterns, clean up temporary files and cache, and validate final state compliance with structure rules.\n\n##Context\n\n- Codebase structure all: !`eza . --tree`\n- Documentation:\n  - @ai-docs/structure-enforcement-system.md"
              },
              {
                "name": "/enforce-structure",
                "description": "Validates and enforcts clean root directory structure with automatic file organization",
                "path": "shell-config/commands/enforce-structure.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Edit, Glob, LS, Read, Write",
                  "description": "Validates and enforcts clean root directory structure with automatic file organization",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Enforce Structure\n\nThis command is used to enforce the structure of the root directory.\n\n##Instructions\n\n- Use the structure-enforcer sub-agent to validate and enforce clean root directory structure with automatic file organization.\n- Parse $ARGUMENTS for operation mode (default: fix, --dry-run: preview, --report: detailed), deploy parallel scanning for misplaced files using coordinated root_scanner and deep_scanner agents, move files to appropriate directories (config/, scripts/, docs/, archive/) based on patterns, clean up temporary files and cache, and validate final state compliance with structure rules.\n\n##Context\n\n- Codebase structure all: !`eza . --tree`\n- Documentation:\n  - @ai-docs/structure-enforcement-system.md"
              }
            ],
            "skills": []
          },
          {
            "name": "task-orchestration-agents",
            "description": "task-orchestration AI agents for specialized tasks (9 agents)",
            "source": "./task-orchestration-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install task-orchestration-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "task-orchestration-commands",
            "description": "task-orchestration slash commands for Claude Code (5 commands)",
            "source": "./task-orchestration-commands",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install task-orchestration-commands@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/analyze-issue",
                "description": "Analyze GitHub issue and generate technical specification",
                "path": "task-orchestration-commands/commands/analyze-issue.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(grep:*), Bash(wc:*), Bash(ls:*), Write, Read, MultiEdit,",
                  "description": "Analyze GitHub issue and generate technical specification"
                },
                "content": "# GitHub Issue Analysis and Technical Specification Generator\n\nThis template/script generates a technical specification for a GitHub issue with the following components:\n\n## Key Components\n1. A bash script to fetch GitHub issue details\n2. A structured technical specification template with sections:\n   - Issue Summary\n   - Problem Statement\n   - Technical Approach\n   - Implementation Plan\n   - Test Plan\n   - Files to Modify/Create\n   - Success Criteria\n   - Out of Scope\n\n## Principles\n- Test-Driven Development (TDD)\n- KISS (Keep It Simple, Stupid) approach\n- 300-line file size limit\n\nThe template is designed to provide a comprehensive, structured approach to analyzing and documenting technical issues from GitHub."
              },
              {
                "name": "/build-roadmap",
                "description": null,
                "path": "task-orchestration-commands/commands/build-roadmap.md",
                "frontmatter": null,
                "content": "Use the roadmap-architect sub-agent to build comprehensive project roadmaps with strategic planning and timeline visualization. Parse $ARGUMENTS for scope and focus areas, analyze current project state from git history and documentation, define vision and strategic objectives, create structured roadmap with phases and dependencies, generate timeline visualization with Mermaid diagrams, document assumptions and risks, and create tracking mechanisms for progress monitoring."
              },
              {
                "name": "/create-coordination-files",
                "description": "Generate coordination files for parallel workflow integration",
                "path": "task-orchestration-commands/commands/create-coordination-files.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Write, Edit",
                  "description": "Generate coordination files for parallel workflow integration"
                },
                "content": "# Create Coordination Files\n\nGenerate coordination files for parallel workflow integration in agent workspace $ARGUMENTS. Read agent_context.yaml and validation_checklist.txt, calculate completion percentage, create status files and deployment plans in shared/coordination/ directory for seamless workflow integration."
              },
              {
                "name": "/use-agent",
                "description": "Intelligently select and use appropriate sub-agent based on task requirements",
                "path": "task-orchestration-commands/commands/use-agent.md",
                "frontmatter": {
                  "allowed-tools": "Task, Read, Glob, Bash",
                  "description": "Intelligently select and use appropriate sub-agent based on task requirements",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Use Agent\n\nAnalyze $ARGUMENTS to determine the most appropriate sub-agent from the .claude/agents directory and use it to handle the specified task.\n\n$ARGUMENTS: [task description or agent:task format]\n\n## Instructions - IMPORTANT: YOU MUST FOLLOW THESE INSTRUCTIONS EXACTLY IN THIS ORDER\n\n1. Run !`ls -l ~/.claude/agents` to see available sub-agents.\n2. Parse $ARGUMENTS to identify task type, domain, and requirements\n3. If sub-agent is specified â†’ Use specified sub-agent directly\n4. If format is \"youtube-url\", IMPORTANT: you must immediately send task to youtube-transcript-analyzer sub-agent.\n5. Otherwise, analyze task keywords to select appropriate sub-agent from the list of available sub-agents.\n6. Use the Task tool to spawn the selected sub-agent with appropriate parameters\n\n## Context\n\nAvailable sub-agents in @~/.claude/agents/:\n\n## Output\n\n- Selected sub-agent name and rationale\n- Task execution through the chosen sub-agent\n- Results from the sub-agent's processing"
              },
              {
                "name": "/write-linear-issue",
                "description": "Create well-structured Linear issues for parallel development workflow",
                "path": "task-orchestration-commands/commands/write-linear-issue.md",
                "frontmatter": {
                  "allowed-tools": "Read, mcp__linear__create_issue, mcp__linear__get_project, mcp__linear__get_team, mcp__linear__get_user, mcp__linear__list_issue_labels, mcp__linear__list_issue_statuses, mcp__linear__list_projects, mcp__linear__list_teams, mcp__linear__list_users, mcp__linear__update_issue",
                  "description": "Create well-structured Linear issues for parallel development workflow",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Write Linear Issue\n\nCreate well-structured Linear issues optimized for parallel development workflow using Linear MCP tools. Use $ARGUMENTS for feature description and team identifier, fetch team and project context via mcp**linear**list_teams and related tools, structure issue with numbered tasks, acceptance criteria, and technical constraints following ai-docs/linear-issue-template.yaml format, then create issue via mcp**linear**create_issue and provide issue ID and URL."
              }
            ],
            "skills": []
          },
          {
            "name": "task-orchestration-hooks",
            "description": "task-orchestration automation hooks for development workflow",
            "source": "./task-orchestration-hooks",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install task-orchestration-hooks@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "task-orchestration",
            "description": "Meta-package: Installs all task-orchestration components (commands + agents + hooks)",
            "source": "./task-orchestration",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install task-orchestration@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/analyze-issue",
                "description": "Analyze GitHub issue and generate technical specification",
                "path": "task-orchestration-commands/commands/analyze-issue.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(grep:*), Bash(wc:*), Bash(ls:*), Write, Read, MultiEdit,",
                  "description": "Analyze GitHub issue and generate technical specification"
                },
                "content": "# GitHub Issue Analysis and Technical Specification Generator\n\nThis template/script generates a technical specification for a GitHub issue with the following components:\n\n## Key Components\n1. A bash script to fetch GitHub issue details\n2. A structured technical specification template with sections:\n   - Issue Summary\n   - Problem Statement\n   - Technical Approach\n   - Implementation Plan\n   - Test Plan\n   - Files to Modify/Create\n   - Success Criteria\n   - Out of Scope\n\n## Principles\n- Test-Driven Development (TDD)\n- KISS (Keep It Simple, Stupid) approach\n- 300-line file size limit\n\nThe template is designed to provide a comprehensive, structured approach to analyzing and documenting technical issues from GitHub."
              },
              {
                "name": "/build-roadmap",
                "description": null,
                "path": "task-orchestration-commands/commands/build-roadmap.md",
                "frontmatter": null,
                "content": "Use the roadmap-architect sub-agent to build comprehensive project roadmaps with strategic planning and timeline visualization. Parse $ARGUMENTS for scope and focus areas, analyze current project state from git history and documentation, define vision and strategic objectives, create structured roadmap with phases and dependencies, generate timeline visualization with Mermaid diagrams, document assumptions and risks, and create tracking mechanisms for progress monitoring."
              },
              {
                "name": "/create-coordination-files",
                "description": "Generate coordination files for parallel workflow integration",
                "path": "task-orchestration-commands/commands/create-coordination-files.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Write, Edit",
                  "description": "Generate coordination files for parallel workflow integration"
                },
                "content": "# Create Coordination Files\n\nGenerate coordination files for parallel workflow integration in agent workspace $ARGUMENTS. Read agent_context.yaml and validation_checklist.txt, calculate completion percentage, create status files and deployment plans in shared/coordination/ directory for seamless workflow integration."
              },
              {
                "name": "/use-agent",
                "description": "Intelligently select and use appropriate sub-agent based on task requirements",
                "path": "task-orchestration-commands/commands/use-agent.md",
                "frontmatter": {
                  "allowed-tools": "Task, Read, Glob, Bash",
                  "description": "Intelligently select and use appropriate sub-agent based on task requirements",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Use Agent\n\nAnalyze $ARGUMENTS to determine the most appropriate sub-agent from the .claude/agents directory and use it to handle the specified task.\n\n$ARGUMENTS: [task description or agent:task format]\n\n## Instructions - IMPORTANT: YOU MUST FOLLOW THESE INSTRUCTIONS EXACTLY IN THIS ORDER\n\n1. Run !`ls -l ~/.claude/agents` to see available sub-agents.\n2. Parse $ARGUMENTS to identify task type, domain, and requirements\n3. If sub-agent is specified â†’ Use specified sub-agent directly\n4. If format is \"youtube-url\", IMPORTANT: you must immediately send task to youtube-transcript-analyzer sub-agent.\n5. Otherwise, analyze task keywords to select appropriate sub-agent from the list of available sub-agents.\n6. Use the Task tool to spawn the selected sub-agent with appropriate parameters\n\n## Context\n\nAvailable sub-agents in @~/.claude/agents/:\n\n## Output\n\n- Selected sub-agent name and rationale\n- Task execution through the chosen sub-agent\n- Results from the sub-agent's processing"
              },
              {
                "name": "/write-linear-issue",
                "description": "Create well-structured Linear issues for parallel development workflow",
                "path": "task-orchestration-commands/commands/write-linear-issue.md",
                "frontmatter": {
                  "allowed-tools": "Read, mcp__linear__create_issue, mcp__linear__get_project, mcp__linear__get_team, mcp__linear__get_user, mcp__linear__list_issue_labels, mcp__linear__list_issue_statuses, mcp__linear__list_projects, mcp__linear__list_teams, mcp__linear__list_users, mcp__linear__update_issue",
                  "description": "Create well-structured Linear issues for parallel development workflow",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Write Linear Issue\n\nCreate well-structured Linear issues optimized for parallel development workflow using Linear MCP tools. Use $ARGUMENTS for feature description and team identifier, fetch team and project context via mcp**linear**list_teams and related tools, structure issue with numbered tasks, acceptance criteria, and technical constraints following ai-docs/linear-issue-template.yaml format, then create issue via mcp**linear**create_issue and provide issue ID and URL."
              },
              {
                "name": "/analyze-issue",
                "description": "Analyze GitHub issue and generate technical specification",
                "path": "task-orchestration/commands/analyze-issue.md",
                "frontmatter": {
                  "allowed-tools": "Bash(git diff:*), Bash(git log:*), Bash(git status:*), Bash(find:*), Bash(grep:*), Bash(wc:*), Bash(ls:*), Write, Read, MultiEdit,",
                  "description": "Analyze GitHub issue and generate technical specification"
                },
                "content": "# GitHub Issue Analysis and Technical Specification Generator\n\nThis template/script generates a technical specification for a GitHub issue with the following components:\n\n## Key Components\n1. A bash script to fetch GitHub issue details\n2. A structured technical specification template with sections:\n   - Issue Summary\n   - Problem Statement\n   - Technical Approach\n   - Implementation Plan\n   - Test Plan\n   - Files to Modify/Create\n   - Success Criteria\n   - Out of Scope\n\n## Principles\n- Test-Driven Development (TDD)\n- KISS (Keep It Simple, Stupid) approach\n- 300-line file size limit\n\nThe template is designed to provide a comprehensive, structured approach to analyzing and documenting technical issues from GitHub."
              },
              {
                "name": "/build-roadmap",
                "description": null,
                "path": "task-orchestration/commands/build-roadmap.md",
                "frontmatter": null,
                "content": "Use the roadmap-architect sub-agent to build comprehensive project roadmaps with strategic planning and timeline visualization. Parse $ARGUMENTS for scope and focus areas, analyze current project state from git history and documentation, define vision and strategic objectives, create structured roadmap with phases and dependencies, generate timeline visualization with Mermaid diagrams, document assumptions and risks, and create tracking mechanisms for progress monitoring."
              },
              {
                "name": "/create-coordination-files",
                "description": "Generate coordination files for parallel workflow integration",
                "path": "task-orchestration/commands/create-coordination-files.md",
                "frontmatter": {
                  "allowed-tools": "Bash, Read, Write, Edit",
                  "description": "Generate coordination files for parallel workflow integration"
                },
                "content": "# Create Coordination Files\n\nGenerate coordination files for parallel workflow integration in agent workspace $ARGUMENTS. Read agent_context.yaml and validation_checklist.txt, calculate completion percentage, create status files and deployment plans in shared/coordination/ directory for seamless workflow integration."
              },
              {
                "name": "/use-agent",
                "description": "Intelligently select and use appropriate sub-agent based on task requirements",
                "path": "task-orchestration/commands/use-agent.md",
                "frontmatter": {
                  "allowed-tools": "Task, Read, Glob, Bash",
                  "description": "Intelligently select and use appropriate sub-agent based on task requirements",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Use Agent\n\nAnalyze $ARGUMENTS to determine the most appropriate sub-agent from the .claude/agents directory and use it to handle the specified task.\n\n$ARGUMENTS: [task description or agent:task format]\n\n## Instructions - IMPORTANT: YOU MUST FOLLOW THESE INSTRUCTIONS EXACTLY IN THIS ORDER\n\n1. Run !`ls -l ~/.claude/agents` to see available sub-agents.\n2. Parse $ARGUMENTS to identify task type, domain, and requirements\n3. If sub-agent is specified â†’ Use specified sub-agent directly\n4. If format is \"youtube-url\", IMPORTANT: you must immediately send task to youtube-transcript-analyzer sub-agent.\n5. Otherwise, analyze task keywords to select appropriate sub-agent from the list of available sub-agents.\n6. Use the Task tool to spawn the selected sub-agent with appropriate parameters\n\n## Context\n\nAvailable sub-agents in @~/.claude/agents/:\n\n## Output\n\n- Selected sub-agent name and rationale\n- Task execution through the chosen sub-agent\n- Results from the sub-agent's processing"
              },
              {
                "name": "/write-linear-issue",
                "description": "Create well-structured Linear issues for parallel development workflow",
                "path": "task-orchestration/commands/write-linear-issue.md",
                "frontmatter": {
                  "allowed-tools": "Read, mcp__linear__create_issue, mcp__linear__get_project, mcp__linear__get_team, mcp__linear__get_user, mcp__linear__list_issue_labels, mcp__linear__list_issue_statuses, mcp__linear__list_projects, mcp__linear__list_teams, mcp__linear__list_users, mcp__linear__update_issue",
                  "description": "Create well-structured Linear issues for parallel development workflow",
                  "model": "claude-sonnet-4-5-20250929"
                },
                "content": "# Write Linear Issue\n\nCreate well-structured Linear issues optimized for parallel development workflow using Linear MCP tools. Use $ARGUMENTS for feature description and team identifier, fetch team and project context via mcp**linear**list_teams and related tools, structure issue with numbered tasks, acceptance criteria, and technical constraints following ai-docs/linear-issue-template.yaml format, then create issue via mcp**linear**create_issue and provide issue ID and URL."
              }
            ],
            "skills": []
          },
          {
            "name": "ui-design-system-agents",
            "description": "ui-design-system AI agents for specialized tasks (6 agents)",
            "source": "./ui-design-system-agents",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install ui-design-system-agents@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "ui-design-system",
            "description": "Meta-package: Installs all ui-design-system components (agents)",
            "source": "./ui-design-system",
            "category": null,
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add AojdevStudio/dev-utils-marketplace",
              "/plugin install ui-design-system@dev-utils-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-10-14T17:41:35Z",
              "created_at": "2025-10-11T13:48:44Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": []
          }
        ]
      }
    }
  ]
}