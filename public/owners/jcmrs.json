{
  "owner": {
    "id": "jcmrs",
    "display_name": "JCMRS",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/19489577?u=ce7368e4df40da22f3df64219a5ba44c34b2ad86&v=4",
    "url": "https://github.com/jcmrs",
    "bio": "Managed by Claude Code",
    "stats": {
      "total_repos": 1,
      "total_plugins": 6,
      "total_commands": 17,
      "total_skills": 4,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "jcmrs/jcmrs-plugins",
      "url": "https://github.com/jcmrs/jcmrs-plugins",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-04T21:15:59Z",
        "created_at": "2025-12-21T13:19:03Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1643
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 578
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 6828
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 710
        },
        {
          "path": "plugins/claude-pms/.gitignore",
          "type": "blob",
          "size": 247
        },
        {
          "path": "plugins/claude-pms/ARCHITECTURE.md",
          "type": "blob",
          "size": 25221
        },
        {
          "path": "plugins/claude-pms/CHANGELOG.md",
          "type": "blob",
          "size": 9591
        },
        {
          "path": "plugins/claude-pms/README.md",
          "type": "blob",
          "size": 7966
        },
        {
          "path": "plugins/claude-pms/SKILL.md",
          "type": "blob",
          "size": 9237
        },
        {
          "path": "plugins/claude-pms/VALIDATION_GUIDE.md",
          "type": "blob",
          "size": 15691
        },
        {
          "path": "plugins/claude-pms/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/commands/.gitkeep",
          "type": "blob",
          "size": 110
        },
        {
          "path": "plugins/claude-pms/commands/config.md",
          "type": "blob",
          "size": 4481
        },
        {
          "path": "plugins/claude-pms/commands/encode.md",
          "type": "blob",
          "size": 1515
        },
        {
          "path": "plugins/claude-pms/commands/extract.md",
          "type": "blob",
          "size": 2392
        },
        {
          "path": "plugins/claude-pms/commands/reflect.md",
          "type": "blob",
          "size": 3020
        },
        {
          "path": "plugins/claude-pms/commands/status.md",
          "type": "blob",
          "size": 7855
        },
        {
          "path": "plugins/claude-pms/commands/synthesize.md",
          "type": "blob",
          "size": 3035
        },
        {
          "path": "plugins/claude-pms/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/examples/USAGE_EXAMPLES.md",
          "type": "blob",
          "size": 13659
        },
        {
          "path": "plugins/claude-pms/examples/pms.local.md",
          "type": "blob",
          "size": 3931
        },
        {
          "path": "plugins/claude-pms/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/hooks/.gitkeep",
          "type": "blob",
          "size": 99
        },
        {
          "path": "plugins/claude-pms/hooks/hooks.json",
          "type": "blob",
          "size": 1119
        },
        {
          "path": "plugins/claude-pms/hooks/precompact.sh",
          "type": "blob",
          "size": 1130
        },
        {
          "path": "plugins/claude-pms/hooks/session-end.sh",
          "type": "blob",
          "size": 1071
        },
        {
          "path": "plugins/claude-pms/hooks/session-start.sh",
          "type": "blob",
          "size": 1391
        },
        {
          "path": "plugins/claude-pms/hooks/stop.sh",
          "type": "blob",
          "size": 1095
        },
        {
          "path": "plugins/claude-pms/prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/prompts/.gitkeep",
          "type": "blob",
          "size": 125
        },
        {
          "path": "plugins/claude-pms/prompts/analyze-session.txt",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "plugins/claude-pms/prompts/detect-patterns.txt",
          "type": "blob",
          "size": 7126
        },
        {
          "path": "plugins/claude-pms/prompts/generate-rules.txt",
          "type": "blob",
          "size": 6375
        },
        {
          "path": "plugins/claude-pms/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/scripts/.gitkeep",
          "type": "blob",
          "size": 109
        },
        {
          "path": "plugins/claude-pms/scripts/config.py",
          "type": "blob",
          "size": 5352
        },
        {
          "path": "plugins/claude-pms/scripts/encode.py",
          "type": "blob",
          "size": 15353
        },
        {
          "path": "plugins/claude-pms/scripts/extract.py",
          "type": "blob",
          "size": 16468
        },
        {
          "path": "plugins/claude-pms/scripts/json_handler.py",
          "type": "blob",
          "size": 7317
        },
        {
          "path": "plugins/claude-pms/scripts/load-config.sh",
          "type": "blob",
          "size": 4041
        },
        {
          "path": "plugins/claude-pms/scripts/recovery.py",
          "type": "blob",
          "size": 11924
        },
        {
          "path": "plugins/claude-pms/scripts/redaction.py",
          "type": "blob",
          "size": 4238
        },
        {
          "path": "plugins/claude-pms/scripts/synthesize.py",
          "type": "blob",
          "size": 12171
        },
        {
          "path": "plugins/claude-pms/scripts/utils.py",
          "type": "blob",
          "size": 2834
        },
        {
          "path": "plugins/claude-pms/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/tests/.gitkeep",
          "type": "blob",
          "size": 108
        },
        {
          "path": "plugins/claude-pms/tests/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/tests/fixtures/sample-config.yaml",
          "type": "blob",
          "size": 517
        },
        {
          "path": "plugins/claude-pms/tests/fixtures/sample-episodic-record.json",
          "type": "blob",
          "size": 1378
        },
        {
          "path": "plugins/claude-pms/tests/fixtures/sample-semantic-patterns.json",
          "type": "blob",
          "size": 1729
        },
        {
          "path": "plugins/claude-pms/tests/fixtures/sample-transcript.jsonl",
          "type": "blob",
          "size": 1227
        },
        {
          "path": "plugins/claude-pms/tests/integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-pms/tests/integration/test_full_pipeline.sh",
          "type": "blob",
          "size": 10903
        },
        {
          "path": "plugins/claude-pms/tests/test_config.py",
          "type": "blob",
          "size": 5715
        },
        {
          "path": "plugins/claude-pms/tests/test_encode.py",
          "type": "blob",
          "size": 6696
        },
        {
          "path": "plugins/claude-pms/tests/test_extract.py",
          "type": "blob",
          "size": 13087
        },
        {
          "path": "plugins/claude-pms/tests/test_json_handler.py",
          "type": "blob",
          "size": 7768
        },
        {
          "path": "plugins/claude-pms/tests/test_recovery.py",
          "type": "blob",
          "size": 8386
        },
        {
          "path": "plugins/claude-pms/tests/test_redaction.py",
          "type": "blob",
          "size": 7558
        },
        {
          "path": "plugins/claude-pms/tests/test_synthesize.py",
          "type": "blob",
          "size": 13914
        },
        {
          "path": "plugins/docs-reader",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs-reader/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs-reader/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 482
        },
        {
          "path": "plugins/docs-reader/LICENSE",
          "type": "blob",
          "size": 1492
        },
        {
          "path": "plugins/docs-reader/README.md",
          "type": "blob",
          "size": 4611
        },
        {
          "path": "plugins/docs-reader/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs-reader/commands/docs.md",
          "type": "blob",
          "size": 1961
        },
        {
          "path": "plugins/docs-reader/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs-reader/skills/documentation-query",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs-reader/skills/documentation-query/LICENSE",
          "type": "blob",
          "size": 1492
        },
        {
          "path": "plugins/docs-reader/skills/documentation-query/SKILL.md",
          "type": "blob",
          "size": 5932
        },
        {
          "path": "plugins/docs-reader/skills/documentation-query/resources",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs-reader/skills/documentation-query/resources/tutorials-index.md",
          "type": "blob",
          "size": 1336
        },
        {
          "path": "plugins/docs-reader/skills/documentation-query/resources/wiki-index.md",
          "type": "blob",
          "size": 1618
        },
        {
          "path": "plugins/gemini-consult",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini-consult/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini-consult/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 206
        },
        {
          "path": "plugins/gemini-consult/README.md",
          "type": "blob",
          "size": 14620
        },
        {
          "path": "plugins/gemini-consult/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini-consult/commands/gemini-check.md",
          "type": "blob",
          "size": 5105
        },
        {
          "path": "plugins/gemini-consult/commands/gemini-consult.md",
          "type": "blob",
          "size": 5073
        },
        {
          "path": "plugins/gemini-consult/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini-consult/hooks/hooks.json",
          "type": "blob",
          "size": 2659
        },
        {
          "path": "plugins/gemini-consult/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini-consult/skills/gemini-consult",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini-consult/skills/gemini-consult/SKILL.md",
          "type": "blob",
          "size": 16095
        },
        {
          "path": "plugins/profile-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 446
        },
        {
          "path": "plugins/profile-creator/EXAMPLES_README.md",
          "type": "blob",
          "size": 13760
        },
        {
          "path": "plugins/profile-creator/README.md",
          "type": "blob",
          "size": 3110
        },
        {
          "path": "plugins/profile-creator/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/commands/create-profile.md",
          "type": "blob",
          "size": 4789
        },
        {
          "path": "plugins/profile-creator/commands/validate-profile.md",
          "type": "blob",
          "size": 4827
        },
        {
          "path": "plugins/profile-creator/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/examples/composite",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/examples/composite/research-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/examples/composite/research-team/CLAUDE.md",
          "type": "blob",
          "size": 11403
        },
        {
          "path": "plugins/profile-creator/examples/composite/research-team/Domain_Linguist.md",
          "type": "blob",
          "size": 13527
        },
        {
          "path": "plugins/profile-creator/examples/composite/research-team/metadata.json",
          "type": "blob",
          "size": 3432
        },
        {
          "path": "plugins/profile-creator/examples/singular",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/examples/singular/researcher-crewai",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/examples/singular/researcher-crewai/CLAUDE.md",
          "type": "blob",
          "size": 23788
        },
        {
          "path": "plugins/profile-creator/examples/singular/researcher-crewai/README.md",
          "type": "blob",
          "size": 10746
        },
        {
          "path": "plugins/profile-creator/examples/singular/researcher-crewai/metadata.json",
          "type": "blob",
          "size": 1794
        },
        {
          "path": "plugins/profile-creator/examples/singular/system-architect",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/examples/singular/system-architect/CLAUDE.md",
          "type": "blob",
          "size": 21877
        },
        {
          "path": "plugins/profile-creator/examples/singular/system-architect/README.md",
          "type": "blob",
          "size": 9698
        },
        {
          "path": "plugins/profile-creator/examples/singular/system-architect/metadata.json",
          "type": "blob",
          "size": 1825
        },
        {
          "path": "plugins/profile-creator/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/skills/profile-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/skills/profile-creator/SKILL.md",
          "type": "blob",
          "size": 14132
        },
        {
          "path": "plugins/profile-creator/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/templates/composite",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/templates/composite/specialist-template.md",
          "type": "blob",
          "size": 31044
        },
        {
          "path": "plugins/profile-creator/templates/composite/system-owner-template.md",
          "type": "blob",
          "size": 27169
        },
        {
          "path": "plugins/profile-creator/templates/singular",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/profile-creator/templates/singular/profile-template.md",
          "type": "blob",
          "size": 27331
        },
        {
          "path": "plugins/running-log",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/running-log/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/running-log/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 422
        },
        {
          "path": "plugins/running-log/README.md",
          "type": "blob",
          "size": 11842
        },
        {
          "path": "plugins/running-log/README_v1_backup.md",
          "type": "blob",
          "size": 6681
        },
        {
          "path": "plugins/running-log/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/running-log/commands/idea.md",
          "type": "blob",
          "size": 4923
        },
        {
          "path": "plugins/running-log/commands/review-backlog.md",
          "type": "blob",
          "size": 9498
        },
        {
          "path": "plugins/running-log/commands/running-log.md",
          "type": "blob",
          "size": 3590
        },
        {
          "path": "plugins/running-log/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/running-log/skills/running-log",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/running-log/skills/running-log/SKILL.md",
          "type": "blob",
          "size": 11226
        },
        {
          "path": "plugins/semantic-linguist",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 858
        },
        {
          "path": "plugins/semantic-linguist/.gitignore",
          "type": "blob",
          "size": 479
        },
        {
          "path": "plugins/semantic-linguist/IMPLEMENTATION_COMPLETE.md",
          "type": "blob",
          "size": 19983
        },
        {
          "path": "plugins/semantic-linguist/README.md",
          "type": "blob",
          "size": 10344
        },
        {
          "path": "plugins/semantic-linguist/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/commands/map-domain.md",
          "type": "blob",
          "size": 6922
        },
        {
          "path": "plugins/semantic-linguist/commands/semantic-config.md",
          "type": "blob",
          "size": 9643
        },
        {
          "path": "plugins/semantic-linguist/commands/validate-terminology.md",
          "type": "blob",
          "size": 5190
        },
        {
          "path": "plugins/semantic-linguist/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/hooks/hooks.json",
          "type": "blob",
          "size": 5983
        },
        {
          "path": "plugins/semantic-linguist/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/scripts/detect-ambiguity.py",
          "type": "blob",
          "size": 6576
        },
        {
          "path": "plugins/semantic-linguist/scripts/domain-mapper.py",
          "type": "blob",
          "size": 9005
        },
        {
          "path": "plugins/semantic-linguist/scripts/knowledge-query.py",
          "type": "blob",
          "size": 11439
        },
        {
          "path": "plugins/semantic-linguist/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/AI-DOMAIN-ADDITION-GUIDE.md",
          "type": "blob",
          "size": 36617
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/SKILL.md",
          "type": "blob",
          "size": 21152
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/autogen-mappings.md",
          "type": "blob",
          "size": 13765
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/common-ambiguities.md",
          "type": "blob",
          "size": 7972
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/fastapi-mappings.md",
          "type": "blob",
          "size": 24808
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/git-gitflow-mappings.md",
          "type": "blob",
          "size": 20391
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/langroid-mappings.md",
          "type": "blob",
          "size": 4383
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/mcp-mappings.md",
          "type": "blob",
          "size": 22190
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/memory-graphs-mappings.md",
          "type": "blob",
          "size": 35774
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/sre-mappings.md",
          "type": "blob",
          "size": 27538
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/examples/utcp-mappings.md",
          "type": "blob",
          "size": 24837
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/knowledge",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/knowledge/ambiguous-terms.json",
          "type": "blob",
          "size": 17919
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/knowledge/ontology-graph.json",
          "type": "blob",
          "size": 31015
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/knowledge/technical-mappings.json",
          "type": "blob",
          "size": 34258
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/references/cognitive-framework.md",
          "type": "blob",
          "size": 21053
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/references/decision-trees.md",
          "type": "blob",
          "size": 30455
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/references/domain-ontologies.md",
          "type": "blob",
          "size": 16490
        },
        {
          "path": "plugins/semantic-linguist/skills/semantic-translation/references/translation-patterns.md",
          "type": "blob",
          "size": 17747
        }
      ],
      "marketplace": {
        "name": "jcmrs-plugins",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "JCMRS"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "profile-creator",
            "description": "Transforms messy human intent and repository analysis into living operational domain profiles through 6-phase knowledge engineering pipeline",
            "source": "./plugins/profile-creator",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add jcmrs/jcmrs-plugins",
              "/plugin install profile-creator@jcmrs-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-04T21:15:59Z",
              "created_at": "2025-12-21T13:19:03Z",
              "license": null
            },
            "commands": [
              {
                "name": "/create-profile",
                "description": "Create operational domain profile through 6-phase knowledge engineering pipeline",
                "path": "plugins/profile-creator/commands/create-profile.md",
                "frontmatter": {
                  "name": "create-profile",
                  "description": "Create operational domain profile through 6-phase knowledge engineering pipeline",
                  "argument-hint": "[intent] [repository_url]"
                },
                "content": "Create a living operational domain profile through conversational knowledge engineering pipeline.\n\n## Usage\n\n```bash\n/create-profile [intent] [repository_url]\n```\n\n## Arguments\n\n- `intent` (optional): Quick description like \"research team\" or \"system architect\"\n- `repository_url` (optional): GitHub/GitLab repository URL to analyze\n\n## Behavior\n\nLaunches the **6-Phase Knowledge Engineering Pipeline**:\n\n### Phase 1: Intent Structuring (Conversational)\n\nIf no arguments provided, begins guided conversation with educational context:\n\n1. \"What's the primary role or archetype for this profile?\"\n   - Context: Examples like 'Researcher', 'System Architect', 'Domain Linguist'\n\n2. \"What's the domain focus?\"\n   - Context: Specific area like 'CrewAI codebase', 'API documentation'\n\n3. \"Single profile or multi-role structure?\"\n   - Context: Single = one profile, Multi-role = System Owner + backroom specialists\n\n4. \"Any critical behavioral constraints?\"\n   - Context: Must-haves like 'hallucination prevention', 'peer review'\n\n5. \"Repository URL?\" (if analyzing codebase)\n\n6. \"Additional study links?\" (optional framework docs)\n\nProduces **Structured Intent Object** for validation.\n\nIf arguments provided, constructs structured intent automatically and confirms with user.\n\n### Phase 2: Repository Analysis (Automated)\n\n- Uses Glob/Read/Grep to extract technical patterns (no MCP - preserves session time)\n- Identifies frameworks, architecture, tools\n- Analyzes package manifests, documentation, configuration\n\n### Phase 3: Ontology Mapping (Validated)\n\n- Maps to Domain Knowledge Graphs (CrewAI, LangChain, Autogen, Semantic Kernel)\n- Validates against actual frameworks (prevents hallucinations)\n- **User validation checkpoint** - confirms mappings are accurate\n\n### Phase 4: Behavioral Synthesis (Automated)\n\n- Generates 50+ observations from 8 universal categories\n- Creates execution_protocol with autonomy/monitoring constraints\n- Injects inheritance from COLLABORATION base\n- Produces methodology_techniques (4+ per domain)\n\n### Phase 5: Profile Validation (AUTOMATED QUALITY GATE)\n\n**The Killer Phase** - catches 95% of issues before user sees them.\n\nChecklist enforcement:\n- ✅ 8+ execution_protocol.autonomy observations\n- ✅ Inheritance relations exist (COLLABORATION base)\n- ✅ 4+ methodology_techniques per domain\n- ✅ Hallucination prevention constraints present\n- ✅ Reporting hierarchy complete (for HMAS)\n\nIF FAIL → Auto-regenerate Phase 4 (max 3 attempts with diagnostic feedback)\nIF PASS → Continue to Phase 6\n\n### Phase 6: Profile Generation (Output)\n\nWrites operational profile file(s):\n\n**Singular:** `CLAUDE.md`\n\n**Composite (HMAS):**\n- `CLAUDE.md` (System Owner)\n- `{PrimaryRole}.md` (e.g., Researcher.md)\n- `{Specialist}.md` (backroom profiles)\n\nUser reviews final output with option to iterate.\n\n## Examples\n\n```bash\n# Guided conversation (recommended for first use)\n/create-profile\n\n# Quick creation with defaults\n/create-profile \"research team\" \"https://github.com/joaomdmoura/crewai\"\n\n# Documentation project\n/create-profile \"documentation architect\" \"https://github.com/facebook/docusaurus\"\n```\n\n## Iteration Support\n\nAt validation checkpoints:\n- **Phase 1:** Review structured intent → [Confirm / Adjust]\n- **Phase 3:** Review ontology mappings → [Confirm / Adjust / Add Links]\n- **Phase 6:** Review generated profile → [Accept / Refine Sections / Regenerate]\n\n## Error Handling\n\n- Invalid repo URL → Validate and retry with suggestion\n- Inaccessible repo → Fallback to study_links only\n- Unknown framework → Graceful degradation with warning\n- Phase 5 validation failure (3x) → Surface diagnostic with suggestions\n\n## Output Format\n\nLiving operational profiles with 6 layers:\n1. Constitutional (Identity, Prime Directive, Focus Areas)\n2. Knowledge (Domain Graphs, Blind Spots)\n3. Activation (Triggers, Prerequisites)\n4. Operational (Methodology, Tools, Artifacts)\n5. Social (Reporting Lines for HMAS)\n6. Behavioral (Execution Protocol, Observations, Inheritance)\n\nProfiles have agency: activation triggers, self-monitoring, rejection protocols, transformation logic.\n\n## Current Implementation Status\n\n**Phase 1:** In Development - Basic conversational flow\n**Phases 2-6:** Not Yet Implemented - See design in conversation log\n\n## Related Commands\n\n- `/validate-profile [path]` - Run Phase 5 validation on existing profile\n- `/adjust-phase [N]` - (Future) Backward iteration to specific phase\n- `/regenerate-phase [N]` - (Future) Manual retry of phase\n\n## Design Reference\n\nComplete architecture in: `.claude/conversations/2024/12/21-profile-creator-skill-design.md`"
              },
              {
                "name": "/validate-profile",
                "description": "Validate operational domain profile quality and completeness using Phase 5 checklist",
                "path": "plugins/profile-creator/commands/validate-profile.md",
                "frontmatter": {
                  "name": "validate-profile",
                  "description": "Validate operational domain profile quality and completeness using Phase 5 checklist",
                  "argument-hint": "<path-to-profile>"
                },
                "content": "Run Phase 5 validation checklist on an existing profile to verify quality and completeness.\n\n## Usage\n\n```bash\n/validate-profile <path-to-profile>\n```\n\n## Arguments\n\n- `path` (required): Path to profile file (CLAUDE.md, AGENTS.md, etc.)\n\n## Behavior\n\nLoads the specified profile and runs the **Phase 5 Validation Checklist** to verify:\n\n### Quality Checklist\n\n**Execution Protocol:**\n- ✅ 8+ autonomy observations (self-assertion, expertise claiming)\n- ✅ Monitoring observations present (bias detection, drift monitoring)\n\n**Behavioral Programming:**\n- ✅ Inheritance relations exist (COLLABORATION base or equivalent)\n- ✅ 4+ methodology techniques per domain area\n- ✅ Observations structured by category (4-5 per category)\n\n**Structural Completeness:**\n- ✅ Identity section present (archetype, prime directive)\n- ✅ Focus areas defined (3-5 domains with clear boundaries)\n- ✅ Domain knowledge graphs listed (5+ sources)\n- ✅ Operational methodology defined (process steps)\n- ✅ Tooling interface specified (authorized tools)\n- ✅ Artifacts section complete (inputs and outputs)\n\n**Living Profile Indicators:**\n- ✅ Activation triggers present (condition-specific patterns)\n- ✅ Self-monitoring mechanisms defined\n- ✅ Rejection protocols exist (blocks invalid requests)\n- ✅ Transformation logic present (adapts behavior based on context)\n\n**Constraints Validation (if specified):**\n- ✅ Hallucination prevention measures present\n- ✅ Peer review requirements defined (if applicable)\n- ✅ Security-first constraints applied (if applicable)\n- ✅ Systematic validation enforced (if applicable)\n\n**Multi-Role Profiles (HMAS only):**\n- ✅ System Owner reporting hierarchy complete\n- ✅ Backroom profiles have clear specialization\n- ✅ Delegation protocols defined\n- ✅ Expertise boundaries clear between roles\n\n## Output Format\n\n**Validation Passed:**\n```\n✅ Profile validation PASSED\n\nQuality Score: X/Y checks passed\n\nStrengths:\n- [Identified strong areas]\n\nRecommendations:\n- [Optional improvements]\n```\n\n**Validation Failed:**\n```\n❌ Profile validation FAILED\n\nFailed Checks:\n- [ ] Check 1: [Specific issue]\n- [ ] Check 2: [Specific issue]\n\nDiagnostic:\n[Detailed explanation of what's missing or insufficient]\n\nSuggestions:\n1. [Specific fix for issue 1]\n2. [Specific fix for issue 2]\n\nManual Fix:\nEdit [file:line] to address [specific issue]\n```\n\n## When to Use\n\n**Recommended scenarios:**\n- After manually editing an existing profile\n- Before deploying profile to production environment\n- When profile behavior seems inconsistent or shallow\n- Periodic quality audits of domain profiles\n- After extending profile with new capabilities\n\n## Validation Philosophy\n\nThe validator enforces the distinction between **living operational profiles** and **dead documentation**:\n\n**Will FAIL if profile lacks:**\n- Activation triggers (just describes without triggering)\n- Self-monitoring (no bias/drift detection)\n- Rejection protocols (accepts everything)\n- Transformation logic (static, doesn't adapt)\n- Behavioral observations (just procedures, no constraints)\n\n**Will PASS profiles with:**\n- Auto-active patterns based on conditions\n- Explicit monitoring for problematic patterns\n- Clear boundaries and rejection criteria\n- Context-aware behavior adaptation\n- Rich observation layers guiding formulation\n\n## Integration with /create-profile\n\nThe same validation logic runs automatically in `/create-profile` Phase 5 with auto-regeneration (max 3 attempts). Using `/validate-profile` manually allows you to:\n- Validate profiles created outside the pipeline\n- Re-validate profiles after manual edits\n- Audit quality without regeneration attempts\n\n## Examples\n\n```bash\n# Validate singular profile\n/validate-profile CLAUDE.md\n\n# Validate System Owner in HMAS\n/validate-profile CLAUDE.md\n\n# Validate backroom specialist\n/validate-profile Researcher.md\n\n# Validate after manual edits\n/validate-profile docs/profiles/custom-profile.md\n```\n\n## Current Implementation Status\n\n**Status:** Not Yet Implemented\n\nThis command definition exists but validation logic is not implemented. Implementation requires:\n- Profile parsing and structure detection\n- Checklist evaluation logic\n- Diagnostic message generation\n- Suggestion synthesis based on failures\n\n## Related Commands\n\n- `/create-profile` - Generate new profile with built-in Phase 5 validation\n- Future: `/enhance-profile [path] [aspect]` - Add missing elements to existing profile\n- Future: `/audit-profiles [directory]` - Batch validate multiple profiles\n\n## Design Reference\n\nComplete validation checklist specification: `.claude/conversations/2024/12/21-profile-creator-skill-design.md`"
              }
            ],
            "skills": [
              {
                "name": "Profile Creator",
                "description": "Knowledge engineering pipeline that transforms messy human intent and repository analysis into living operational domain profiles",
                "path": "plugins/profile-creator/skills/profile-creator/SKILL.md",
                "frontmatter": {
                  "name": "Profile Creator",
                  "description": "Knowledge engineering pipeline that transforms messy human intent and repository analysis into living operational domain profiles",
                  "version": "0.1.0"
                },
                "content": "Transforms messy human intent and repository analysis into living operational domain profiles through collaborative knowledge engineering.\n\n## Core Purpose\n\nBridge the semantic gap between non-technical user vision and AI-specific behavioral constraints by operationalizing collaboration:\n\n**Humans contribute:** Vision, domain intuition, user stories, conceptual relationships (the \"why\" and \"what\")\n**AI contributes:** Ontological validation, role taxonomy mapping, framework alignment, behavioral observation structuring (the \"how\" and \"structure\")\n\n**Neither can do this well alone.** Profile Creator enables the synergy.\n\n## The 6-Phase Pipeline\n\n```\nPhase 1: Intent Structuring (conversational)\n    ↓ [User validates structured intent]\n\nPhase 2: Repository Analysis (automated)\n    ↓\n\nPhase 3: Ontology Mapping (domain knowledge graphs)\n    ↓ [User validates framework mappings]\n\nPhase 4: Behavioral Synthesis (50+ observations)\n    ↓\n\nPhase 5: Profile Validation (AUTOMATED QUALITY GATE)\n    ├─ Checklist: 8+ autonomy, inheritance, methodology depth\n    ├─ IF FAIL → Regenerate Phase 4 (max 3 attempts)\n    └─ IF PASS → Continue\n\nPhase 6: Profile Generation (CLAUDE.md / AGENTS.md)\n    ↓ [User reviews operational profile]\n```\n\n## Phase 1: Intent Structuring\n\n**Objective:** Transform messy human input into structured intent object through conversational discovery.\n\n**Interaction Model:** Guided questions (ONE at a time) with educational context. Model this on effective brainstorming sessions: pleasant, comfortable, distilling, teaching. No questionnaires (produce garbage). No free-form (too costly in tokens).\n\n**Conversational Flow:**\n\n**Question 1:** \"What's the primary role or archetype for this profile?\"\n\n*Educational context:* \"This becomes the identity - examples: 'Researcher', 'System Architect', 'Domain Linguist', 'Security Analyst'. Think about the main function this profile will perform.\"\n\nWait for response.\n\n**Question 2:** \"What's the domain focus - the specific area this profile operates in?\"\n\n*Educational context:* \"Examples: 'CrewAI codebase analysis', 'API documentation', 'Infrastructure orchestration', 'User authentication flows'. This sets the boundaries for where expertise applies.\"\n\nWait for response.\n\n**Question 3:** \"Single profile or multi-role structure?\"\n\n*Educational context:* \"Single = one operational profile doing everything. Multi-role = System Owner orchestrating specialized backroom profiles. Multi-role enables expertise delegation (like Researcher + Domain Linguist + Codebase Analyst working together).\"\n\nWait for response.\n\n**Question 4:** \"Any critical behavioral constraints - must-have behaviors?\"\n\n*Educational context:* \"Examples: 'hallucination prevention', 'peer review required', 'security-first', 'systematic validation'. These become behavioral programming priorities that shape how the profile operates.\"\n\nWait for response.\n\n**Question 5:** \"Repository URL (if analyzing existing codebase)?\"\n\n*Context:* \"GitHub/GitLab URL we'll analyze for technical patterns, frameworks, architecture. Leave empty if creating profile without repo analysis.\"\n\nWait for response.\n\n**Question 6:** \"Any additional study links?\"\n\n*Context:* \"Framework documentation, domain resources, or specific files that provide context. Optional but helpful for accuracy.\"\n\nWait for response.\n\n**Produce Structured Intent:**\n\n```javascript\nintent: {\n  primary_role: \"Researcher\",           // From Q1\n  domain_focus: \"CrewAI codebase\",      // From Q2\n  team_structure: \"multi-role\",         // From Q3: \"single\" or \"multi-role\"\n  key_constraints: [\"hallucination prevention\", \"systematic methodology\"] // From Q4\n}\n\nrepository: \"https://github.com/joaomdmoura/crewai\" // From Q5 (optional)\nstudy_links: [\"...\"] // From Q6 (optional)\n```\n\n**Validation Checkpoint:** Present structured intent to user:\n\n\"Here's the structured intent I've captured: [display intent object]. Does this capture your vision? [Confirm / Adjust]\"\n\nIf Adjust → Iterate on specific fields. If Confirm → Proceed to Phase 2.\n\n## Phase 2: Repository Analysis\n\n**Objective:** Extract technical patterns, frameworks, architecture, tools from repository.\n\n**Implementation:** Use direct file system tools (Glob/Read/Grep) - NO MCP to preserve session time.\n\n**Analysis Steps:**\n\n1. **Framework Detection:**\n   - Glob for `package.json`, `requirements.txt`, `Cargo.toml`, `go.mod`\n   - Read manifests → Identify frameworks (CrewAI, LangChain, Autogen, etc.)\n\n2. **Architecture Patterns:**\n   - Glob for directory structure (`src/`, `plugins/`, `skills/`, etc.)\n   - Identify architectural patterns (plugin system, agent framework, etc.)\n\n3. **Technical Patterns:**\n   - Grep for key patterns: `Agent`, `Task`, `Crew`, API signatures\n   - Extract methodology hints from code structure\n\n4. **Documentation Analysis:**\n   - Read `README.md`, `docs/` directory\n   - Extract domain context and usage patterns\n\n**Output:** `repository_analysis` object with frameworks, architecture, tools, patterns.\n\n## Phase 3: Ontology Mapping\n\n**Objective:** Map user intent and repository patterns to domain knowledge graphs.\n\n**Domain Knowledge Sources:**\n- Framework documentation (CrewAI, LangChain, Autogen, Semantic Kernel, LangGraph)\n- Role taxonomies (Researcher, Architect, Engineer, etc.)\n- Behavioral programming patterns (from Axivo collaboration platform)\n- Study links provided by user\n\n**Mapping Process:**\n\n1. **Role Definition:** Map `primary_role` to known role patterns and methodologies\n2. **Framework Mapping:** Match detected frameworks to their ontologies (Agent.goal(), Crew.kickoff(), etc.)\n3. **Domain Validation:** Verify mappings against study_links to prevent hallucinations\n4. **Constraint Translation:** Convert `key_constraints` to specific behavioral observations\n\n**Validation Checkpoint:** \"I'm mapping to these frameworks and patterns: [display mappings]. Does this match your understanding? Any additional resources I should reference?\"\n\nUser can confirm, add study links, or correct mappings. Critical for preventing hallucinated framework features.\n\n## Phase 4: Behavioral Synthesis\n\n**Objective:** Generate 50+ behavioral observations with execution protocol, methodology, and inheritance.\n\n**Synthesis Components:**\n\n1. **Execution Protocol:**\n   - **Autonomy:** 8+ observations for self-assertion (e.g., \"Assert research expertise\", \"Challenge flawed assumptions\")\n   - **Monitoring:** Bias detection, drift monitoring (e.g., \"Detect confirmation bias\", \"Verify source credibility\")\n\n2. **Methodology Techniques:**\n   - 4+ per domain from framework patterns\n   - Process steps, decision heuristics, validation approaches\n\n3. **Inheritance:**\n   - Inject COLLABORATION base behaviors\n   - Add domain-specific inheritance chains\n\n4. **Observations:**\n   - 4-5 per methodology category\n   - Behavioral constraints that guide formulation\n   - Monitoring observations for problematic patterns\n\n**Template-Based Enrichment:** Use universal templates + framework-specific patterns + user constraints to generate observations systematically.\n\n**Output:** `behavioral_synthesis` object with observations, execution_protocol, methodology_techniques.\n\n## Phase 5: Profile Validation (THE KILLER GATE)\n\n**Objective:** Automated quality enforcement - catches 95% of issues before user sees them.\n\n**Quality Checklist:**\n\n```javascript\nvalidation_checklist = {\n  autonomy_observations: count >= 8,\n  inheritance_relations: exists && includes(\"COLLABORATION\"),\n  methodology_techniques: count >= 4 per domain,\n  hallucination_prevention: constraints.includes(\"hallucination prevention\") || similar,\n  reporting_hierarchy: if HMAS then complete else N/A,\n\n  // Structural completeness\n  has_identity: true,\n  has_prime_directive: true,\n  has_focus_areas: count >= 3 && count <= 5,\n  has_domain_knowledge_graphs: sources.length >= 5,\n  has_operational_methodology: process.length > 0\n}\n```\n\n**Validation Logic:**\n\n```javascript\nif (all_checklist_passed) {\n  proceed_to_phase_6();\n} else {\n  attempt_count++;\n\n  if (attempt_count <= 3) {\n    diagnostic = generate_diagnostic(failed_items);\n    regenerate_phase_4_with_enrichment(diagnostic);\n  } else {\n    surface_diagnostic_to_user({\n      error: \"Validation failed after 3 attempts\",\n      diagnostic: failed_items_details,\n      suggestion: \"/adjust-phase 3 'add missing constraint categories'\",\n      manual_path: \"/regenerate-phase 4\"\n    });\n  }\n}\n```\n\n**Enrichment Strategy:**\n- Attempt 1: Add missing observations from templates\n- Attempt 2: Inject inheritance more aggressively\n- Attempt 3: Use maximum constraints + framework patterns\n\n**This gate prevents shallow LLM garbage from reaching the user.**\n\n## Phase 6: Profile Generation\n\n**Objective:** Write living operational profile file(s) with 6-layer structure.\n\n**Profile Structure (Complete):**\n\n### 1. Constitutional Layer\n```markdown\n## 1. Identity\n- **Archetype**: {archetype}\n- **Prime Directive**: {single sentence mission / safety-critical constraint}\n\n## 2. Ontology & Scope\n- **Focus Area**: {3-5 core domains for precise boundaries}\n- **Domain Knowledge Graphs**: {5-7 sources: frameworks, repos, docs}\n- **Blind Spots**: {explicit limitations - what it cannot do}\n```\n\n### 2. Activation Layer (if not System Owner)\n```markdown\n## 3. Activation Protocol\n- **Triggers**: {condition-specific, auto-active patterns}\n- **Prerequisites**: {required context/files/tools}\n```\n\n### 3. Operational Layer\n```markdown\n## 4. Operational Methodology\n- **Process**: {numbered steps or directive workflow}\n- **Decision Heuristics**: {IF/THEN rules + behavioral constraints}\n\n## 5. Tooling Interface\n- **Authorized Tools**: {exact list, no more no less}\n- **Task Profiles**: {specialized tool configurations}\n\n## 6. Artifacts\n- **Inputs**: {precise sources}\n- **Outputs**: {transformed deliverables / value creation}\n```\n\n### 4. Social Layer (for HMAS)\n```markdown\n## 7. Reporting Line\n- **Relationship to System Owner**: {first line of defense, specialist, etc.}\n- **Peer Relationships**: {other backroom profiles}\n```\n\n### 5. Behavioral Layer\n```markdown\n## 8. Execution Protocol\n### Autonomy\n{8+ observations for self-assertion}\n\n### Monitoring\n{observations for bias/drift detection}\n\n## 9. Behavioral Programming\n### Observations\n{4-5 per methodology category}\n\n### Inheritance\n{base profiles leveraged}\n```\n\n**Output Format:**\n\n**Singular:**\n```javascript\n{\n  profile_type: \"singular\",\n  files: [\"CLAUDE.md\"],\n  metadata: { archetype, domain, validation_passed: true }\n}\n```\n\n**Composite (HMAS):**\n```javascript\n{\n  profile_type: \"composite\",\n  files: [\n    \"CLAUDE.md\",           // System Owner\n    \"Researcher.md\",       // Primary role\n    \"Domain_Linguist.md\",  // Backroom specialist\n    \"Codebase_Analyst.md\"  // Backroom specialist\n  ],\n  hierarchy: {\n    system_owner: \"CLAUDE.md\",\n    primary: \"Researcher.md\",\n    backroom: [\"Domain_Linguist.md\", \"Codebase_Analyst.md\"]\n  }\n}\n```\n\n**File Writing:** Atomic commits - all files written or none. Use Write tool for each file.\n\n**User Review:** Present generated profile(s) for final review with iteration options.\n\n## Living vs Dead Profiles\n\n**Critical Distinction:**\n\n**Dead Documentation:**\n- Describes what something does\n- No activation triggers\n- No self-monitoring\n- No rejection protocols\n- No transformation logic\n\n**Living Operational Profile:**\n- **Triggers:** Auto-active on conditions\n- **Execution Protocol:** Self-asserts expertise, detects bias/drift\n- **Rejection:** Blocks invalid requests\n- **Transformation:** Adapts behavior based on context\n- **Observations:** Guide formulation with behavioral constraints\n\n**Profile Creator MUST generate living systems, not documentation.**\n\n## Error Handling\n\n**Phase-Specific:**\n- Phase 1: Empty input → prompt, ambiguous role → clarify\n- Phase 2: Invalid repo → validate/retry, inaccessible → fallback to study_links\n- Phase 3: Unmapped framework → warn, hallucinated features → validate against study_links\n- Phase 4: Insufficient observations → auto-enrich from templates\n- Phase 5: Validation failure → regenerate with enrichment (3 attempts)\n\n**Edge Cases:**\n- Non-code repositories (documentation projects) → Skip technical patterns, focus on domain knowledge\n- Private repositories (no access) → Fallback to study_links + manual domain description\n- Multi-framework repositories → Map to all frameworks, composite knowledge graphs\n- Existing CLAUDE.md (enhancement) → Load existing, merge with new synthesis, enhance\n\n## State Management\n\n**sessionState Structure:**\n```javascript\n{\n  structured_intent: {...},      // Phase 1 output\n  repository_analysis: {...},    // Phase 2 output\n  ontology_mapping: {...},       // Phase 3 output\n  behavioral_synthesis: {...},   // Phase 4 output\n  validation_results: {...}      // Phase 5 output\n}\n```\n\n**Persistence:** Write JSON artifacts per phase for restart recovery.\n\n**Iteration:** User can iterate backward - reload phase state, regenerate forward.\n\n## Key Principles\n\n1. **Conversation is Educational:** Teach along the way, explain ontology concepts, help user learn\n2. **One Question at a Time:** No barrage, no overwhelm, pleasant rhythm\n3. **Validation Checkpoints Matter:** Phases 1, 3, 6 require user confirmation\n4. **Phase 5 is Non-Negotiable:** Quality gate prevents garbage output\n5. **Living Not Dead:** Profiles must have agency (triggers, monitoring, rejection, transformation)\n6. **Synergy is Non-Reducible:** Need all 6 layers for emergent properties\n7. **Hallucination Prevention:** Validate against actual frameworks, reject invented features\n\n## Implementation Status\n\n**Current:** Basic structure and methodology documented\n**Next:** Implement Phase 1 conversational flow\n**Future:** Complete Phases 2-6, workflow commands, testing suite\n\n## Design Reference\n\nComplete architectural design: `.claude/conversations/2024/12/21-profile-creator-skill-design.md`"
              }
            ]
          },
          {
            "name": "running-log",
            "description": "Persistent schema-driven running log capturing ideas, consultations, and Claude's reasoning patterns for cross-session learning and process memory",
            "source": "./plugins/running-log",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add jcmrs/jcmrs-plugins",
              "/plugin install running-log@jcmrs-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-04T21:15:59Z",
              "created_at": "2025-12-21T13:19:03Z",
              "license": null
            },
            "commands": [
              {
                "name": "/idea",
                "description": "Quick idea capture with AI-filled defaults (description only, zero friction)",
                "path": "plugins/running-log/commands/idea.md",
                "frontmatter": {
                  "name": "idea",
                  "description": "Quick idea capture with AI-filled defaults (description only, zero friction)",
                  "argument-hint": "[DESCRIPTION]"
                },
                "content": "Ultra-minimal idea capture while working. AI fills all defaults.\n\n## Usage\n\n```\n/idea Local copies of Anthropic docs in AI-optimized format\n```\n\n## Execution\n\n### Step 1: Parse Description\n\nExtract description from `$ARGUMENTS`:\n- If empty or no arguments: Display usage and exit\n- Otherwise: Description = `$ARGUMENTS`\n\n### Step 2: Generate Entry ID\n\n1. Read `.claude/RUNNING_LOG.md` to find highest entry number for today\n2. Generate ID: `#ID-YYYYMMDD-NNN` where:\n   - YYYY = current year (2025)\n   - MM = current month (zero-padded)\n   - DD = current day (zero-padded)\n   - NNN = next sequence number (001, 002, etc.)\n\nExample: `#ID-20251222-003`\n\n### Step 3: Generate AI Tags\n\nAnalyze description and generate 2-4 relevant tags based on:\n- Existing tags in RUNNING_LOG.md (for consistency)\n- Domain keywords (documentation, api, framework, tooling, etc.)\n- Technology mentions (anthropic, claude, python, etc.)\n\n**Tag Guidelines**:\n- Lowercase, hyphenated (e.g., `api-design`, `local-tooling`)\n- Prefer existing tags over creating new ones\n- Max 4 tags per entry\n\n### Step 4: Create Entry\n\nFormat entry with AI-filled defaults:\n\n```markdown\n## Idea/Note | [Entry ID] | [ISO 8601 Timestamp]\n\n**Description**: [User-provided description from $ARGUMENTS]\n**Confidence/Priority**: TBD\n**Status**: Backlog\n**Type**: Idea/Note\n**Profile**: DEVELOPER\n**Tags**: [AI-generated tags]\n\n---\n```\n\n**ISO 8601 Timestamp Format**: `YYYY-MM-DDTHH:MM:SS+TZ`\nExample: `2025-12-22T15:30:00+01:00`\n\n### Step 5: Append to RUNNING_LOG.md\n\n1. Read `.claude/RUNNING_LOG.md`\n2. Find the `## Entry Backlog` section\n3. Insert new entry at the TOP of the backlog (reverse chronological order)\n4. Update `**Last Updated**` timestamp in header\n5. Write file using Edit tool\n\n### Step 6: Update LAST_ENTRIES.md\n\n1. Read `.claude/LAST_ENTRIES.md`\n2. Add new entry to top of table:\n   ```\n   | [Entry ID] | Idea/Note | [Description (truncated to 60 chars)] | TBD | Backlog | [Tags] |\n   ```\n3. Keep only last 20 entries (remove oldest if > 20)\n4. Update `**Last Updated**` timestamp\n5. Increment `**Total Entries**` count\n6. Write file using Edit tool\n\n### Step 7: Confirm\n\nDisplay:\n```\n✅ Idea logged: [Entry ID]\n📝 [First 60 chars of description...]\n🏷️  Tags: [tag1, tag2, tag3]\n```\n\n## File Initialization\n\nIf `.claude/RUNNING_LOG.md` doesn't exist, create it:\n\n```markdown\n# Running Log - DEVELOPER Profile\n\n**Created**: [ISO 8601 timestamp]\n**Last Updated**: [ISO 8601 timestamp]\n\n---\n\n## Auto-Generated Sections\n\n### 🔥 High-Priority Ideas\n[Auto-populated from entries tagged High/Critical]\n\n### ⚠️ Open Risks / Low-Confidence Items\n[Auto-populated from entries with confidence < 60%]\n\n### 🔗 Linked Process Insights\n[Auto-populated from Process Memory entries with Linked To]\n\n---\n\n## Entry Backlog\n\n[Entries will appear here in reverse chronological order]\n\n---\n```\n\nIf `.claude/LAST_ENTRIES.md` doesn't exist, create it:\n\n```markdown\n# Last Entries - Quick Access Cache\n\n**Last Updated**: [ISO 8601 timestamp]\n**Profile**: DEVELOPER@75%\n\n---\n\n## Recent Entries (Last 20)\n\n| ID | Type | Description | Confidence | Status | Tags |\n|----|------|-------------|------------|--------|------|\n\n---\n\n**Total Entries**: 0\n**Session**: [Current date]\n```\n\n## Important Notes\n\n- Use Read tool to read files\n- Use Edit tool to update existing files\n- Use Write tool only if file doesn't exist\n- Entry IDs must be unique and sequential per day\n- Always update both RUNNING_LOG.md and LAST_ENTRIES.md\n- Keep LAST_ENTRIES.md at max 20 entries\n- Tags should be consistent with existing tags in the log\n\n## Examples\n\n### Example 1: First Idea of Day\n\n```\nUser: /idea Add plugin permission system for marketplace\n\nAI generates:\n- Entry ID: #ID-20251222-001\n- Tags: plugin-system, marketplace, permissions, security\n- Timestamp: 2025-12-22T10:15:00+01:00\n\nOutput:\n✅ Idea logged: #ID-20251222-001\n📝 Add plugin permission system for marketplace\n🏷️  Tags: plugin-system, marketplace, permissions, security\n```\n\n### Example 2: Second Idea (Same Day)\n\n```\nUser: /idea Local AI-optimized Anthropic docs\n\nAI generates:\n- Entry ID: #ID-20251222-002 (incremented)\n- Tags: documentation, anthropic, ai-optimization, local-tooling\n- Timestamp: 2025-12-22T15:30:00+01:00\n\nOutput:\n✅ Idea logged: #ID-20251222-002\n📝 Local AI-optimized Anthropic docs\n🏷️  Tags: documentation, anthropic, ai-optimization, local-tooling\n```\n\n## Error Handling\n\n**No description provided:**\n```\nUsage: /idea [DESCRIPTION]\n\nExample: /idea Add dark mode toggle to settings\n```\n\n**File errors:**\n- If RUNNING_LOG.md unreadable → Initialize new file\n- If LAST_ENTRIES.md unreadable → Initialize new file\n- If Edit fails → Show error, ask user to check file permissions\n\n---\n\nExecute the command based on `$ARGUMENTS`."
              },
              {
                "name": "/review-backlog",
                "description": "Post-process running log entries - prioritize, link, harmonize tags, regenerate auto-sections",
                "path": "plugins/running-log/commands/review-backlog.md",
                "frontmatter": {
                  "name": "review-backlog",
                  "description": "Post-process running log entries - prioritize, link, harmonize tags, regenerate auto-sections",
                  "argument-hint": "[--ideas|--risks|--link ID|--tags]"
                },
                "content": "Post-process running log entries: prioritize, link, harmonize tags, regenerate auto-sections.\n\n## Usage\n\n```\n/review-backlog                 # Full review with all suggestions\n/review-backlog --ideas         # Review only ideas (prioritize TBD items)\n/review-backlog --risks         # Review low-confidence Process Memory items\n/review-backlog --link #ID-XXX  # Find and link entries related to specific ID\n/review-backlog --tags          # Harmonize tags only\n```\n\n## Execution\n\n### Step 1: Parse Arguments\n\nCheck `$ARGUMENTS` for mode:\n- No arguments or empty: **Full Review Mode**\n- `--ideas`: **Ideas Review Mode**\n- `--risks`: **Risks Review Mode**\n- `--link #ID-XXX`: **Link Discovery Mode**\n- `--tags`: **Tag Harmonization Mode**\n\n### Step 2: Load All Entries\n\n1. Read `.claude/RUNNING_LOG.md`\n2. Parse all entries from `## Entry Backlog` section\n3. Extract for each entry:\n   - Entry ID\n   - Type (Idea/Note, Consultation, Process Memory)\n   - Description\n   - Confidence/Priority\n   - Status\n   - Tags\n   - Linked To (if present)\n\nStore in memory for analysis.\n\n---\n\n## Mode 1: Full Review (No Arguments)\n\nPerform all analyses and present comprehensive review.\n\n### Analysis 1: Prioritization\n\n**Find Ideas with Priority = TBD:**\n\nFor each TBD idea:\n1. Analyze description keywords\n2. Check if related to recent Process Memory entries (decisions, critical items)\n3. Look for domain alignment (documentation, api, tooling, etc.)\n4. Suggest priority: High/Med/Low with brief rationale\n\n**Output Format:**\n```\n💡 Ideas Requiring Prioritization (N):\n\n- #ID-20251222-001: Local AI-optimized docs\n  → Suggested: High\n  → Rationale: Aligns with knowledge-base work, mentioned in #ID-20251221-005\n\n- #ID-20251221-003: Plugin permission system\n  → Suggested: Med\n  → Rationale: Dependent on architecture decisions, no immediate blockers\n```\n\n### Analysis 2: Relationship Discovery\n\n**Find Related Entries:**\n\nFor each entry, identify potential links based on:\n- Shared keywords in descriptions\n- Similar tags\n- Temporal proximity (entries from same session)\n- Causal relationships (decision → idea, consultation → implementation)\n\n**Output Format:**\n```\n🔗 Suggested Links (N):\n\n- #ID-20251222-001 ← #ID-20251221-008\n  Reason: Both reference documentation workflows\n\n- #ID-20251221-005 → #ID-20251221-003\n  Reason: Decision in 005 impacts idea in 003\n\n- #ID-20251220-012 ↔ #ID-20251220-015\n  Reason: Both discuss marketplace architecture\n```\n\n### Analysis 3: Tag Harmonization\n\n**Find Tag Inconsistencies:**\n\n1. Identify similar tags:\n   - `docs` vs `documentation`\n   - `api` vs `api-design`\n   - `anthropic` vs `anthropic-api`\n\n2. Count usage frequency\n3. Suggest consolidation to most common variant\n\n**Output Format:**\n```\n🏷️  Tag Harmonization Suggestions:\n\n- Rename \"docs\" → \"documentation\" (4 entries affected)\n- Merge \"api\" + \"api-design\" → \"api-design\" (3 entries)\n- Merge \"anthropic\" + \"anthropic-api\" → \"anthropic\" (5 entries)\n```\n\n### Analysis 4: Risk Highlighting\n\n**Find Low-Confidence Items:**\n\n- Process Memory entries with Confidence < 70%\n- Status = Assumed (not yet validated)\n- Critical signals (blocker, must-verify, etc.)\n\n**Output Format:**\n```\n⚠️  Open Risks / Low-Confidence Items (N):\n\n- #ID-20251221-004: Confidence 65%\n  → Low confidence on validation approach\n  → Status: Todo\n  → Linked to: #ID-20251221-005\n\n- #ID-20251220-010: Confidence 60%\n  → Assumption about API behavior not yet validated\n  → Status: Assumed\n```\n\n### Step 3: Display Summary\n\n```\n🔍 Backlog Review Results\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n[Analysis 1: Prioritization]\n[Analysis 2: Relationship Discovery]\n[Analysis 3: Tag Harmonization]\n[Analysis 4: Risk Highlighting]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nApply changes? [Y/n]\n```\n\n### Step 4: Apply Changes (If User Confirms)\n\nIf user types \"Y\" or \"yes\":\n\n1. **Update Priorities**: Edit entries to change TBD → High/Med/Low\n2. **Add Links**: Add \"Linked To\" fields to suggested entries\n3. **Harmonize Tags**: Rename/merge tags across affected entries\n4. **Regenerate Auto-Sections**: Update High-Priority Ideas, Open Risks, Linked Insights sections\n5. **Update Last Updated timestamp** in header\n\nConfirm:\n```\n✅ Applied N changes to running log\n   - Updated 5 priorities\n   - Added 3 links\n   - Harmonized 12 tag occurrences\n   - Regenerated auto-sections\n```\n\n---\n\n## Mode 2: Ideas Review (`--ideas`)\n\nFocus only on prioritizing TBD ideas.\n\n### Execution\n\n1. Load all entries\n2. Filter: Type = Idea/Note AND Priority = TBD\n3. For each TBD idea:\n   - Analyze description\n   - Suggest priority with rationale\n   - Identify potential links\n\n**Output:**\n```\n💡 Ideas Review (N ideas with TBD priority)\n\n#ID-20251222-001: Local AI-optimized docs\n→ Suggested: High\n→ Rationale: Aligns with knowledge-base goals\n→ Potential Links: #ID-20251221-008 (documentation workflow)\n\n#ID-20251221-003: Plugin permission system\n→ Suggested: Med\n→ Rationale: Dependent on architecture, no immediate need\n\nApply priority suggestions? [Y/n]\n```\n\n---\n\n## Mode 3: Risks Review (`--risks`)\n\nFocus only on low-confidence Process Memory items.\n\n### Execution\n\n1. Load all entries\n2. Filter: Type = Process Memory AND (Confidence < 70% OR Status = Assumed)\n3. For each risk item:\n   - Display confidence level\n   - Show status\n   - Highlight if linked to ideas or consultations\n   - Suggest validation steps\n\n**Output:**\n```\n⚠️  Open Risks Review (N items)\n\n#ID-20251221-004: Confidence 65%\n→ Low confidence on validation approach\n→ Status: Todo\n→ Linked to: #ID-20251221-005 (decision fork)\n→ Suggested Action: Test manual stub approach vs auto-detection\n\n#ID-20251220-010: Confidence 60%\n→ Assumption about API pagination\n→ Status: Assumed\n→ Suggested Action: Verify with actual API test\n```\n\n---\n\n## Mode 4: Link Discovery (`--link #ID-XXX`)\n\nFind entries related to a specific entry ID.\n\n### Execution\n\n1. Load all entries\n2. Find target entry by ID\n3. Analyze target entry:\n   - Extract keywords from description\n   - Extract tags\n   - Note type and timestamp\n\n4. Search all other entries for:\n   - Shared keywords (≥ 2 words in common)\n   - Shared tags (≥ 1 tag)\n   - Temporal proximity (same day or adjacent days)\n   - Causal language (\"because of\", \"led to\", \"resulted in\")\n\n5. Rank by relevance score:\n   - Shared keywords: +2 per keyword\n   - Shared tags: +3 per tag\n   - Same type: +1\n   - Temporal proximity: +1\n   - Causal language: +5\n\n**Output:**\n```\n🔗 Entries Related to #ID-20251222-001\n\nHigh Relevance (Score ≥ 7):\n- #ID-20251221-008 (Score: 9)\n  → Shares 3 keywords, 2 tags\n  → Same day, both reference documentation\n\nMedium Relevance (Score 4-6):\n- #ID-20251220-015 (Score: 5)\n  → Shares 2 tags, temporal proximity\n\nLow Relevance (Score 1-3):\n- #ID-20251219-003 (Score: 2)\n  → Shares 1 keyword\n\nAdd \"Linked To\" field to #ID-20251222-001 with suggested links? [Y/n]\n```\n\n---\n\n## Mode 5: Tag Harmonization (`--tags`)\n\nFocus only on tag consistency.\n\n### Execution\n\n1. Load all entries\n2. Extract all unique tags\n3. Group similar tags:\n   - Levenshtein distance < 3 edits\n   - Common prefixes/suffixes\n   - Semantic similarity (e.g., \"doc\" vs \"documentation\")\n\n4. For each group:\n   - Count usage frequency\n   - Suggest consolidation to most common variant\n\n**Output:**\n```\n🏷️  Tag Harmonization Report\n\nGroup 1: Documentation Tags\n- \"documentation\" (8 uses) ← KEEP\n- \"docs\" (4 uses) → Rename to \"documentation\"\n- \"doc\" (1 use) → Rename to \"documentation\"\n\nGroup 2: API Tags\n- \"api-design\" (5 uses) ← KEEP\n- \"api\" (3 uses) → Rename to \"api-design\"\n\nGroup 3: Anthropic Tags\n- \"anthropic\" (6 uses) ← KEEP\n- \"anthropic-api\" (2 uses) → Rename to \"anthropic\"\n\nApply harmonization? [Y/n]\n\nChanges: 13 tag occurrences across 10 entries\n```\n\n---\n\n## Auto-Section Regeneration\n\nAfter any changes applied, regenerate auto-sections in RUNNING_LOG.md:\n\n### High-Priority Ideas\n\n```markdown\n### 🔥 High-Priority Ideas\n\n- #ID-20251222-001: Local AI-optimized docs (Backlog)\n- #ID-20251221-012: Add WebSocket support (In Progress)\n```\n\n**Criteria**: Type = Idea/Note + Priority = High + Status ≠ Done\n\n### Open Risks / Low-Confidence Items\n\n```markdown\n### ⚠️ Open Risks / Low-Confidence Items\n\n- #ID-20251221-004: Validation approach uncertainty (65%)\n- #ID-20251220-010: API pagination assumption (60%)\n```\n\n**Criteria**: Type = Process Memory + (Confidence < 60% OR Status = Assumed)\n\n### Linked Process Insights\n\n```markdown\n### 🔗 Linked Process Insights\n\n- #ID-20251221-005 → #ID-20251221-003 (Decision impacts plugin idea)\n- #ID-20251220-012 ↔ #ID-20251220-015 (Marketplace architecture discussion)\n```\n\n**Criteria**: Any entry with \"Linked To\" field populated\n\n---\n\n## Important Notes\n\n- All analysis is AI-driven (relationship detection, priority suggestion, tag harmonization)\n- Changes require user confirmation (Y/n prompt)\n- Original entries never deleted, only enhanced\n- Backup tip: User can check git diff before confirming changes\n- Tag harmonization preserves semantic meaning while improving consistency\n\n---\n\nExecute the appropriate mode based on `$ARGUMENTS`."
              },
              {
                "name": "/running-log",
                "description": "Display running log entries - show recent entries or debug details",
                "path": "plugins/running-log/commands/running-log.md",
                "frontmatter": {
                  "name": "running-log",
                  "description": "Display running log entries - show recent entries or debug details",
                  "argument-hint": "[--show N|--debug]"
                },
                "content": "Display running log entries. For adding ideas, use `/idea`. For post-processing, use `/review-backlog`.\n\n## Usage\n\n```\n/running-log --show [N]    # Show last N entries (default: 10)\n/running-log --debug       # Show last 5 entries with full details\n```\n\n## Parse Arguments\n\nCheck `$ARGUMENTS` for flags:\n- `--show` or `--show N`: **Display mode** (show last N entries, default 10)\n- `--debug`: **Debug mode** (show last 5 entries with regex details)\n- No arguments or empty: Display usage help\n\n## File Paths\n\n- **Main log**: `.claude/RUNNING_LOG.md`\n- **Cache**: `.claude/LAST_ENTRIES.md`\n\nCheck if files exist. If not, initialize them.\n\n---\n\n## Mode 1: Display (`--show [N]`)\n\n1. Read `.claude/LAST_ENTRIES.md`\n2. Parse the entry table\n3. Extract last N entries (default: 10, or use number from `$ARGUMENTS`)\n4. Display in compact format:\n   ```\n   Last N entries:\n\n   #ID-YYYYMMDD-NNN | Type | Description | Status\n   #ID-YYYYMMDD-NNN | Type | Description | Status\n   ```\n\n---\n\n## Mode 2: Debug (`--debug`)\n\n1. Read `.claude/RUNNING_LOG.md`\n2. Extract last 5 entries from Entry Backlog section\n3. Display full entry content including:\n   - All fields (Description, Confidence, Status, Type, Profile, Tags)\n   - Extended Context\n   - Pattern Detected (if present)\n   - Raw Output (if present)\n   - Detection Method\n\nFormat each entry with full markdown, separated by `---`\n\n---\n\n## Mode 3: Usage Help (no arguments)\n\nDisplay usage information:\n\n```\nRunning Log v2.0 - Display & Quick-Capture\n\nDisplay Modes:\n  /running-log --show [N]    Show last N entries (default: 10)\n  /running-log --debug       Show last 5 entries with full details\n\nQuick-Capture:\n  /idea [DESCRIPTION]        Add idea to backlog (one-line, AI fills defaults)\n\nPost-Processing:\n  /review-backlog            Prioritize, link, organize entries\n\nExamples:\n  /running-log --show 5              Show last 5 entries\n  /running-log --debug               Show debugging details\n  /idea Local AI-optimized docs      Add quick idea\n  /review-backlog                    Review and organize backlog\n```\n\n---\n\n## File Initialization\n\nIf `.claude/RUNNING_LOG.md` doesn't exist, create it:\n\n```markdown\n# Running Log - DEVELOPER Profile\n\n**Created**: [ISO 8601 timestamp]\n**Last Updated**: [ISO 8601 timestamp]\n\n---\n\n## Auto-Generated Sections\n\n### 🔥 High-Priority Ideas\n[Auto-populated from entries tagged High/Critical]\n\n### ⚠️ Open Risks / Low-Confidence Items\n[Auto-populated from entries with confidence < 60%]\n\n### 🔗 Linked Process Insights\n[Auto-populated from Process Memory entries with Linked To]\n\n---\n\n## Entry Backlog\n\n[Entries will appear here in reverse chronological order]\n\n---\n```\n\nIf `.claude/LAST_ENTRIES.md` doesn't exist, create it:\n\n```markdown\n# Last Entries - Quick Access Cache\n\n**Last Updated**: [ISO 8601 timestamp]\n**Profile**: DEVELOPER@75%\n\n---\n\n## Recent Entries (Last 20)\n\n| ID | Type | Description | Confidence | Status | Tags |\n|----|------|-------------|------------|--------|------|\n\n---\n\n**Total Entries**: 0\n**Session**: [Current date]\n```\n\n---\n\n## Important Notes\n\n- Use Read tool to read files\n- Use Edit tool to update existing files\n- Use Write tool only if file doesn't exist\n- Generate ISO 8601 timestamps: `YYYY-MM-DDTHH:MM:SS+TZ`\n- Entry IDs must be unique and sequential per day\n- Always update both RUNNING_LOG.md and LAST_ENTRIES.md\n- Keep LAST_ENTRIES.md at max 20 entries\n\nExecute the appropriate mode based on `$ARGUMENTS`."
              }
            ],
            "skills": [
              {
                "name": "Running Log",
                "description": "Persistent schema-driven running log with three-component architecture - quick-capture ideas, AI auto-detection, and backlog review librarian",
                "path": "plugins/running-log/skills/running-log/SKILL.md",
                "frontmatter": {
                  "name": "Running Log",
                  "description": "Persistent schema-driven running log with three-component architecture - quick-capture ideas, AI auto-detection, and backlog review librarian",
                  "version": "2.0.0"
                },
                "content": "**Name**: running-log\n**Version**: 2.0\n**Domain**: Process Memory, Decision Tracking, Cross-Session Learning\n**Status**: Redesigned based on Phase 2 validation findings\n\n---\n\n## Purpose\n\nMaintain a persistent, schema-driven running log that captures:\n- **Ideas** (human quick-capture backlog)\n- **Consultations** (AI-detected external sources)\n- **Process Memory** (AI-detected reasoning patterns)\n\nCreates searchable, auto-organized entry backlog across sessions through **three distinct workflows**:\n1. Human quick-capture (`/idea`)\n2. AI auto-detection (Consultation, Process Memory)\n3. Post-processing librarian (`/review-backlog`)\n\n**Critical Design Insight**: Human entry workflows differ fundamentally from AI auto-detection workflows. v2.0 separates these cleanly.\n\n---\n\n## Architecture: Three-Component System\n\n### Component 1: `/idea` Command (Human Territory)\n\n**Purpose**: Ultra-minimal quick capture while working\n\n**Workflow**:\n```\nUser: /idea Local copies of Anthropic docs in AI-optimized format\n→ Entry created immediately with defaults\n→ User continues work\n```\n\n**What AI fills automatically**:\n- Entry ID: `#ID-YYYYMMDD-NNN` (auto-incremented)\n- Timestamp: ISO 8601\n- Confidence/Priority: `TBD` (To Be Determined - evaluated during backlog review)\n- Status: `Backlog` (default for all ideas)\n- Tags: AI-generated from description + existing tag taxonomy\n- Type: `Idea/Note`\n- Profile: Active profile (e.g., `DEVELOPER`)\n\n**Entry Schema (Ideas)**:\n```markdown\n## Idea/Note | #ID-YYYYMMDD-NNN | [ISO 8601 Timestamp]\n\n**Description**: [User-provided 1-line description]\n**Confidence/Priority**: TBD\n**Status**: Backlog\n**Type**: Idea/Note\n**Profile**: [Active Profile]\n**Tags**: [AI-generated tags]\n\n---\n```\n\n**Why this works**:\n- Zero friction: User types one line, gets back to work\n- No nonsensical prompts for confidence (ideas are captured, not evaluated)\n- No status guessing (all ideas start as backlog)\n- Consistent tags (AI prevents million inconsistent human tags)\n- Evaluation happens later during `/review-backlog`\n\n---\n\n### Component 2: AI Auto-Detection (AI Territory)\n\n**Purpose**: Monitor Claude's responses for reasoning patterns worth capturing\n\n**Entry Types**:\n\n#### Consultation (External Sources)\nAI detects when referencing external knowledge:\n- Documentation lookups\n- Perplexity/research queries\n- User-provided references\n- Framework/library citations\n\n**Auto-generates**:\n```markdown\n## Consultation | #ID-YYYYMMDD-NNN | [Timestamp]\n\n**Description**: [What was consulted]\n**Source**: [Citation/URL]\n**Confidence**: [AI's confidence in source quality: High/Med/Low]\n**Status**: Reviewed\n**Type**: Consultation\n**Profile**: [Active Profile]\n**Tags**: [domain, source-type, framework]\n\n---\n```\n\n#### Process Memory (AI Reasoning Patterns)\nAI detects loggable reasoning patterns in its own responses:\n\n**Pattern 1: Uncertainty**\n```regex\n/uncertainty\\s+(on|about|regarding|around)\\s+([^.!?]+)/i\n```\n→ Logs: What's uncertain, confidence level\n\n**Pattern 2: Assumption**\n```regex\n/assum(e|ing|ption)\\s+(that|about|the)\\s+([^.!?]+)/i\n```\n→ Logs: Assumption made, validation status\n\n**Pattern 3: Confidence Threshold**\n```regex\n/confidence\\s+(less\\s+than|below|<)\\s*(\\d+)%?/i\n```\n→ Logs: Low-confidence item needing validation\n\n**Pattern 4: Decision/Fork**\n```regex\n/(fork|branch|decision\\s+point|chose|decided|rejected)\\s+(in|on)?\\s*([^.!?]+)/i\n```\n→ Logs: Decision made, alternatives considered, rationale\n\n**Pattern 5: Critical Signal**\n```regex\n/critical|blocker|blocking|must\\s+(clarify|understand|verify)/i\n```\n→ Logs: Critical issue flagged, requires attention\n\n**Auto-generates**:\n```markdown\n## Process Memory | #ID-YYYYMMDD-NNN | [Timestamp]\n\n**Description**: [Reasoning pattern detected]\n**Confidence**: [AI's certainty about this pattern: 0-100%]\n**Status**: [Assumed/Validated/Rejected]\n**Type**: Process Memory\n**Profile**: [Active Profile]\n**Tags**: [pattern-type, domain, criticality]\n**Pattern Detected**: [Which regex matched]\n**Raw Output**: [Exact phrase from Claude's response]\n\n**Extended Context**:\n[Why this pattern matters, implications, next steps]\n\n---\n```\n\n**Cadence**: 3 automatic checks per session\n1. **Session Start**: Continuity from previous session\n2. **Mid-Toolchain**: After `floor(tool_count / 3)` tools executed\n3. **Session End**: Archive session learnings\n\n**Confidence Thresholds** (Auto-log only if >= threshold):\n- DEVELOPER: 75%\n- RESEARCHER: 60%\n- ENGINEER: 70%\n- DEFAULT: 70%\n\n**Noise Filtering**:\n1. Confidence threshold (above)\n2. Entry cap per session (DEVELOPER: 8, RESEARCHER: 12, ENGINEER: 10)\n3. Deduplication (Levenshtein 85% similarity suppresses duplicates)\n\n---\n\n### Component 3: `/review-backlog` Command (Librarian Function)\n\n**Purpose**: Post-process entries to organize, prioritize, and link\n\n**What it does**:\n1. **Relationship Identification**: AI analyzes all entries and identifies connections\n2. **Tag Refinement**: Harmonizes tags across entries, suggests taxonomy improvements\n3. **Prioritization**: Reviews `TBD` priorities, suggests High/Med/Low based on context\n4. **Linking**: Populates `Linked To` field by finding related entries\n5. **Auto-Section Generation**: Regenerates High-Priority Ideas, Open Risks, Linked Insights\n\n**Usage**:\n```\n/review-backlog                 # Review all entries, suggest actions\n/review-backlog --ideas         # Review only ideas (prioritize, link)\n/review-backlog --risks         # Review low-confidence items\n/review-backlog --link #ID-001  # Find and link entries related to #ID-001\n```\n\n**Example Output**:\n```\n🔍 Backlog Review Results\n\nIdeas Requiring Prioritization (5):\n- #ID-20251222-001: Local AI-optimized docs → Suggested: High (aligns with knowledge-base work)\n- #ID-20251221-003: Plugin permission system → Suggested: Med (dependent on architecture)\n\nSuggested Links (3):\n- #ID-20251222-001 ← #ID-20251221-008 (both reference documentation workflows)\n- #ID-20251221-005 → #ID-20251221-003 (decision impacts idea)\n\nTag Harmonization:\n- Rename \"docs\" → \"documentation\" (4 entries)\n- Merge \"anthropic-api\" + \"anthropic\" (2 entries)\n\nApply changes? [Y/n]\n```\n\n**Why separate from capture**:\n- Humans can't know relationships while capturing ideas mid-work\n- Requires full-backlog context to identify patterns\n- Deliberate activity, not real-time capture\n- AI analyzes relationships humans can't see\n\n---\n\n## File Structure\n\n```\nproject/\n├── .claude/\n│   ├── RUNNING_LOG.md              # Main log (auto-sections + chronological)\n│   ├── LAST_ENTRIES.md             # Dedup tracking (20 most recent)\n│   └── skills/\n│       └── running-log/\n│           └── SKILL.md            # This specification\n└── [project files]\n```\n\n### RUNNING_LOG.md Structure\n\n```markdown\n# Running Log - DEVELOPER Profile\n\n**Created**: [ISO 8601]\n**Last Updated**: [ISO 8601]\n\n---\n\n## Auto-Generated Sections\n\n### 🔥 High-Priority Ideas\n[Auto-populated from ideas tagged High, status ≠ Done]\n\n### ⚠️ Open Risks / Low-Confidence Items\n[Auto-populated from Process Memory with confidence < 60%]\n\n### 🔗 Linked Process Insights\n[Auto-populated from entries with Linked To populated]\n\n---\n\n## Entry Backlog\n\n[Entries in reverse chronological order]\n\n---\n```\n\n---\n\n## Commands Summary\n\n### `/idea [DESCRIPTION]`\nQuick-capture idea while working. AI fills all other fields with defaults.\n\n```\n/idea Local copies of Anthropic docs in AI-optimized format\n```\n\n### `/review-backlog [OPTIONS]`\nPost-process entries: prioritize, link, harmonize tags.\n\n```\n/review-backlog                 # Full review\n/review-backlog --ideas         # Ideas only\n/review-backlog --risks         # Low-confidence items\n/review-backlog --link #ID-001  # Link related entries\n```\n\n### `/running-log --show [N]`\nDisplay last N entries (default: 10).\n\n```\n/running-log --show 5\n```\n\n### `/running-log --debug`\nShow last 5 entries with full details including regex detection.\n\n```\n/running-log --debug\n```\n\n---\n\n## Configuration\n\n```yaml\nrunning_log:\n  enabled: true\n  file_path: \".claude/RUNNING_LOG.md\"\n  state_file: \".claude/LAST_ENTRIES.md\"\n\n  profiles:\n    DEVELOPER:\n      threshold: 75\n      entry_cap: 8\n    RESEARCHER:\n      threshold: 60\n      entry_cap: 12\n    ENGINEER:\n      threshold: 70\n      entry_cap: 10\n    DEFAULT:\n      threshold: 70\n      entry_cap: 8\n\n  deduplication:\n    enabled: true\n    levenshtein_threshold: 0.85\n    cross_session: true\n\n  idea_defaults:\n    confidence: \"TBD\"\n    status: \"Backlog\"\n    auto_tag: true  # AI generates tags from description\n```\n\n---\n\n## Migration from v1.0\n\n**Changes**:\n1. **`/log` command removed** → Use `/idea [description]` instead\n2. **Interactive prompting removed** → `/idea` is one-line only\n3. **Confidence/Status for ideas** → Now defaults (TBD/Backlog)\n4. **Tags** → AI-generated, not human-entered\n5. **Linked To** → Post-processing via `/review-backlog`, not capture-time\n6. **`/review` command** → Renamed to `/review-backlog` with expanded functions\n\n**Existing logs compatible**: v1.0 entries remain valid, new entries use v2.0 schema\n\n---\n\n## Design Rationale (Phase 2 Learnings)\n\n### Problem 1: Nonsensical Fields for Ideas\n**v1.0**: Asked humans for confidence/priority when capturing ideas\n**Issue**: Ideas are captured for later evaluation, not evaluated at capture time\n**v2.0 Fix**: Defaults to TBD/Backlog, evaluation happens during `/review-backlog`\n\n### Problem 2: Inconsistent Human Tags\n**v1.0**: Asked humans to enter free-form tags\n**Issue**: Million inconsistent tags, none relevant\n**v2.0 Fix**: AI auto-generates tags from description + existing taxonomy\n\n### Problem 3: Impossible \"Linked To\" Field\n**v1.0**: Asked humans to provide entry IDs while capturing\n**Issue**: Humans don't memorize IDs mid-work\n**v2.0 Fix**: AI identifies relationships during `/review-backlog` post-processing\n\n### Problem 4: Monolithic Command\n**v1.0**: Single `/log` command tried to handle all entry types\n**Issue**: Human quick-capture ≠ AI auto-detection workflows\n**v2.0 Fix**: Split into `/idea` (human), auto-detection (AI), `/review-backlog` (librarian)\n\n---\n\n## Version & Maintenance\n\n**Current**: v2.0 (Redesigned based on Phase 2 validation)\n**Previous**: v1.0 (Phase 1 spec-only)\n\n**Expected Updates**:\n- v2.1: Post-deployment tuning based on real usage\n- v3.0: Multi-repository support, cross-project insights\n\n**Schema Stability**: Core schema stable. Thresholds may adjust based on empirical data.\n\n---\n\n## Next Steps\n\n1. Implement `/idea` command (minimal quick-capture)\n2. Implement `/review-backlog` command (librarian functions)\n3. Update existing `/running-log` command for display-only modes\n4. Test with real workflows across 5+ sessions\n5. Collect usage data, tune thresholds\n\n---\n\n**End of SKILL.md Specification v2.0**\n\n*This specification reflects critical design learnings from Phase 2 validation. The three-component architecture (quick-capture, auto-detection, post-processing) separates human and AI workflows appropriately.*"
              }
            ]
          },
          {
            "name": "gemini-consult",
            "description": "Leverage Google Gemini's CLI for analyzing large codebases beyond typical context limits using @ syntax for file/directory inclusion",
            "source": "./plugins/gemini-consult",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add jcmrs/jcmrs-plugins",
              "/plugin install gemini-consult@jcmrs-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-04T21:15:59Z",
              "created_at": "2025-12-21T13:19:03Z",
              "license": null
            },
            "commands": [
              {
                "name": "/gemini-check",
                "description": "Verify Google Gemini CLI installation and readiness",
                "path": "plugins/gemini-consult/commands/gemini-check.md",
                "frontmatter": {
                  "name": "jcmrs:gemini-check",
                  "description": "Verify Google Gemini CLI installation and readiness",
                  "allowed-tools": [
                    "Bash"
                  ]
                },
                "content": "# Gemini Check Command\n\nDiagnose Google Gemini CLI installation and configuration status.\n\n## Purpose\n\nQuickly verify that:\n- Gemini CLI is installed\n- Command is in PATH\n- Version information is available\n- System is ready for `/jcmrs:gemini-consult` usage\n\n## Execution Protocol\n\n### 1. Check CLI Availability\n\nTest if `gemini` command exists:\n\n```bash\nwhich gemini || echo \"NOT_FOUND\"\n```\n\n**On Windows** (if which fails):\n```bash\nwhere gemini || echo \"NOT_FOUND\"\n```\n\n### 2. Get Version Information\n\nIf gemini is found, retrieve version:\n\n```bash\ngemini --version\n```\n\n**Expected output**: Version number (e.g., \"1.0.0\" or similar)\n\n### 3. Test Basic Functionality\n\nRun a minimal test query to verify gemini works:\n\n```bash\ngemini -p \"test query\" --help\n```\n\n**Purpose**: Verify gemini responds to commands without actually executing a query\n\n### 4. Format Diagnostic Report\n\nPresent results in clear status format:\n\n**If everything works**:\n\n```markdown\n✅ Gemini CLI Status: Ready\n\n**Installation**\n- Command: gemini\n- Location: [path from which/where]\n- Version: [version number]\n\n**Functionality**\n- Basic commands: ✅ Working\n- Ready for queries: ✅ Yes\n\n**Next Steps**\n- Run queries with: /jcmrs:gemini-consult\n- Example: /jcmrs:gemini-consult @src/ Analyze architecture\n```\n\n**If gemini not found**:\n\n```markdown\n❌ Gemini CLI Status: Not Installed\n\n**Problem**\n- gemini command not found in PATH\n\n**Solution**\nInstall Google Gemini CLI:\n\n1. Using npm:\n   ```bash\n   npm install -g @google/generative-ai\n   ```\n\n2. Verify installation:\n   ```bash\n   gemini --version\n   ```\n\n3. Authenticate (if needed):\n   ```bash\n   gemini auth login\n   ```\n\n4. Test with:\n   ```bash\n   /jcmrs:gemini-check\n   ```\n\n**Documentation**\n- Installation guide: https://ai.google.dev/gemini-api/docs/cli\n```\n\n**If gemini found but errors**:\n\n```markdown\n⚠️ Gemini CLI Status: Installed but Issues Detected\n\n**Installation**\n- Command: gemini\n- Location: [path]\n- Version: [version or error]\n\n**Issues**\n- [Specific error from version check]\n\n**Troubleshooting**\n1. Verify installation:\n   ```bash\n   npm list -g @google/generative-ai\n   ```\n\n2. Reinstall if needed:\n   ```bash\n   npm install -g @google/generative-ai\n   ```\n\n3. Check authentication:\n   ```bash\n   gemini auth status\n   ```\n\n4. Test query:\n   ```bash\n   gemini -p \"@README.md Summarize this file\"\n   ```\n\n**Need Help?**\n- Run diagnostics: /jcmrs:gemini-check\n- Check installation docs: https://ai.google.dev/gemini-api/docs/cli\n```\n\n## Diagnostic Details\n\n### PATH Check\n\nVerify gemini is in system PATH:\n- **macOS/Linux**: `which gemini`\n- **Windows**: `where gemini`\n\n**Expected**: Full path to gemini executable\n\n### Version Verification\n\nCheck installed version:\n```bash\ngemini --version\n```\n\n**Purpose**: Confirms not only installation but that gemini binary works\n\n### Authentication Status\n\nOptionally check authentication (if gemini supports it):\n```bash\ngemini auth status\n```\n\n**Note**: Some gemini installations may not require auth or may handle it differently\n\n## Common Issues & Solutions\n\n### Issue: Command Not Found\n\n**Symptom**: `gemini: command not found`\n\n**Solutions**:\n1. Install globally: `npm install -g @google/generative-ai`\n2. Check npm global bin in PATH: `npm config get prefix`\n3. Restart terminal after installation\n\n### Issue: Permission Denied\n\n**Symptom**: `Permission denied` when running gemini\n\n**Solutions**:\n1. Fix permissions: `chmod +x [gemini path]`\n2. Reinstall with proper permissions: `sudo npm install -g @google/generative-ai`\n3. Use npm without sudo: Configure npm prefix to user directory\n\n### Issue: Wrong Version\n\n**Symptom**: Old version installed\n\n**Solutions**:\n1. Update: `npm update -g @google/generative-ai`\n2. Check version: `gemini --version`\n3. Uninstall and reinstall if update fails\n\n### Issue: Authentication Required\n\n**Symptom**: Gemini asks for auth when running queries\n\n**Solutions**:\n1. Login: `gemini auth login`\n2. Follow authentication prompts\n3. Verify: `gemini auth status`\n\n## Integration with Plugin\n\nThis diagnostic command helps troubleshoot:\n- `/jcmrs:gemini-consult` failures\n- Hook suggestion errors\n- Setup verification for new users\n\n**Recommended workflow**:\n1. User installs plugin\n2. Run `/jcmrs:gemini-check` to verify setup\n3. Fix any issues identified\n4. Proceed with `/jcmrs:gemini-consult` queries\n\n## Quick Reference\n\n```bash\n# Check status\n/jcmrs:gemini-check\n\n# If issues, install\nnpm install -g @google/generative-ai\n\n# Verify\ngemini --version\n\n# Test query\ngemini -p \"@README.md Summarize\"\n\n# Recheck\n/jcmrs:gemini-check\n```\n\n## Exit Conditions\n\nCommand completes successfully when:\n- ✅ Status report generated\n- ✅ Installation state determined\n- ✅ Clear next steps provided (if issues found)\n- ✅ User knows whether they can use `/jcmrs:gemini-consult`\n\n**Do not**:\n- Attempt to install gemini automatically\n- Modify user's PATH\n- Change system configuration\n\n**Only**: Report status and provide clear instructions"
              },
              {
                "name": "/gemini-consult",
                "description": "Execute Google Gemini CLI for large codebase analysis using @ syntax",
                "path": "plugins/gemini-consult/commands/gemini-consult.md",
                "frontmatter": {
                  "name": "jcmrs:gemini-consult",
                  "description": "Execute Google Gemini CLI for large codebase analysis using @ syntax",
                  "argument-hint": "[scope-pattern] [query]",
                  "allowed-tools": [
                    "Bash",
                    "mcp__cipher__ask_cipher"
                  ]
                },
                "content": "# Gemini Consult Command\n\nExecute Google Gemini CLI for analyzing large codebases that exceed Claude Code's context limits.\n\n## Command Format\n\nThe command accepts free-form arguments combining scope patterns and queries:\n\n```bash\n/jcmrs:gemini-consult @src/main.py Explain this file's purpose and structure\n/jcmrs:gemini-consult @package.json @src/index.js Analyze dependencies\n/jcmrs:gemini-consult @src/ Summarize the architecture\n/jcmrs:gemini-consult @src/ @tests/ Analyze test coverage\n/jcmrs:gemini-consult @./ Give me an overview of this project\n/jcmrs:gemini-consult --all_files Analyze project structure and dependencies\n```\n\n## Execution Protocol\n\n### 1. Parse Arguments\n\nExtract the complete query from user input:\n- Everything after `/jcmrs:gemini-consult` is the query\n- Query includes both scope patterns (@...) and question text\n- Preserve exact formatting and spacing\n\n### 2. Construct Gemini Command\n\nBuild the Gemini CLI command:\n\n```bash\ngemini -p \"[complete user query]\"\n```\n\n**Important**:\n- Use double quotes around the entire prompt\n- Escape any internal quotes if present\n- Preserve @ syntax exactly as provided\n- Include --all_files flag if present\n\n### 3. Execute Query\n\nRun the Gemini command via Bash tool:\n\n```bash\ngemini -p \"[query]\"\n```\n\n**Timeout**: Set to 120 seconds (Gemini queries can take time for large scopes)\n\n**Error handling**:\n- If gemini command not found: Direct user to run `/jcmrs:gemini-check`\n- If timeout: Suggest reducing scope or splitting into multiple queries\n- If other errors: Display error message and suggest diagnostics\n\n### 4. Process Results\n\nWhen Gemini returns output:\n\n**A. Synthesize Summary**\n\nExtract key insights:\n- Main findings (3-5 bullet points)\n- File references mentioned (with paths)\n- Critical recommendations\n- Confidence level or uncertainties noted\n\n**B. Validate Output**\n\nQuick validation checks:\n- File paths mentioned: Note if they exist in current repo\n- Specific claims: Flag any that seem uncertain\n- Completeness: Check if query was fully addressed\n\n**C. Format Response**\n\nPresent in this structure:\n\n```markdown\n## Gemini Analysis Results\n\n**Query**: [original query]\n**Scope**: [scope patterns used]\n\n### Key Findings\n\n1. [Finding 1 with file references]\n2. [Finding 2 with implications]\n3. [Finding 3 with recommendations]\n\n### Recommendations\n\n- [Actionable item 1]\n- [Actionable item 2]\n\n### Full Gemini Output\n\n<details>\n<summary>Click to expand complete response</summary>\n\n[Complete Gemini output here]\n\n</details>\n\n---\n\n*Analysis stored in Cipher for future reference*\n```\n\n### 5. Store in Cipher\n\nAutomatically store the consultation in Cipher:\n\n```\nmcp__cipher__ask_cipher(\"Store: Gemini Consultation - [Topic from query]\n\nQuery: [original query]\nScope: [scope patterns]\nDate: [timestamp]\n\nKey Findings:\n- [Finding 1]\n- [Finding 2]\n\nRecommendations:\n- [Recommendation 1]\n- [Recommendation 2]\n\nComplete output archived for reference.\")\n```\n\n**Storage benefits**:\n- Future queries can reference past analyses\n- User can ask \"What did Gemini say about X?\"\n- Builds knowledge base over time\n\n## Usage Tips\n\n**Single file analysis**:\n```bash\n/jcmrs:gemini-consult @src/auth/login.js Explain authentication flow\n```\n\n**Comparative analysis**:\n```bash\n/jcmrs:gemini-consult @src/api/v1/ @src/api/v2/ Compare API versions\n```\n\n**Security audit**:\n```bash\n/jcmrs:gemini-consult @src/ Find SQL injection vulnerabilities\n```\n\n**Architecture review**:\n```bash\n/jcmrs:gemini-consult --all_files Analyze project architecture and dependencies\n```\n\n**Feature verification**:\n```bash\n/jcmrs:gemini-consult @src/ @tests/ Verify dark mode implementation\n```\n\n## Important Notes\n\n- **Paths are relative**: @ patterns are relative to current working directory\n- **Large scopes take time**: --all_files can take 30-60 seconds\n- **Gemini required**: User must have `gemini` CLI installed and in PATH\n- **No API key needed**: Assumes gemini is already authenticated\n- **Results cached**: Gemini may cache results for identical queries\n\n## Error Recovery\n\n**Command not found**:\n```\nError: 'gemini' command not found\n→ Run /jcmrs:gemini-check to diagnose\n→ Install: npm install -g @google/generative-ai\n```\n\n**Timeout**:\n```\nError: Query timeout (>120s)\n→ Reduce scope: Use specific directories instead of --all_files\n→ Split query: Analyze frontend and backend separately\n```\n\n**Empty response**:\n```\nError: Gemini returned no output\n→ Check query syntax (@ patterns correct?)\n→ Verify files exist at specified paths\n→ Try simpler query first\n```\n\n## Integration with Skill\n\nThis command complements the gemini-consult skill:\n- **Skill**: Provides knowledge about when/how to use Gemini\n- **Command**: Executes the actual Gemini query\n- **Both**: Store results in Cipher for continuity\n\nUsers can invoke this command directly or let the skill suggest it when appropriate."
              }
            ],
            "skills": []
          },
          {
            "name": "semantic-linguist",
            "description": "Semantic translation between natural language and technical precision across 8 domains: Autogen, Langroid, MCP, UTCP, FastAPI, Git/Gitflow, SRE, and Memory Graphs",
            "source": "./plugins/semantic-linguist",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add jcmrs/jcmrs-plugins",
              "/plugin install semantic-linguist@jcmrs-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-04T21:15:59Z",
              "created_at": "2025-12-21T13:19:03Z",
              "license": null
            },
            "commands": [
              {
                "name": "/map-domain",
                "description": "Provide conversational complete reference of domain mappings between Autogen, Langroid, and general concepts with cross-domain translations",
                "path": "plugins/semantic-linguist/commands/map-domain.md",
                "frontmatter": {
                  "name": "map-domain",
                  "description": "Provide conversational complete reference of domain mappings between Autogen, Langroid, and general concepts with cross-domain translations"
                },
                "content": "# Map Domain Command\n\nProvide comprehensive domain mapping reference to translate between Autogen, Langroid, and general AI agent concepts.\n\n## Process\n\n1. **Identify User's Context**\n   - Detect current domain from conversation (Autogen, Langroid, or general)\n   - Identify target domain (if user is switching or learning new framework)\n   - Determine user's experience level (technical vs non-technical)\n\n2. **Load Domain Knowledge**\n   - Read `skills/semantic-validation/knowledge/ontology-graph.json`\n   - Read `skills/semantic-validation/knowledge/technical-mappings.json`\n   - Load cross-domain equivalents\n\n3. **Present Conversational Complete Reference**\n\n   Start with overview:\n   ```\n   # Domain Mapping Reference\n\n   I'll show you how concepts translate between frameworks.\n\n   **Current context**: [detected domain]\n   **Available domains**: Autogen, Langroid, General AI concepts\n\n   Let me know if you want:\n   1. Complete reference (all mappings)\n   2. Specific concept mapping (e.g., \"how does Autogen's ConversableAgent map to Langroid?\")\n   3. Domain-specific deep dive (all Autogen patterns)\n   4. Cross-framework comparison (same concept across all domains)\n   ```\n\n4. **Provide Requested Mapping Type**\n\n   **Option 1: Complete Reference**\n   ```markdown\n   ## Core Concepts Across Frameworks\n\n   ### Agent Types\n\n   | Concept | Autogen | Langroid | General |\n   |---------|---------|----------|---------|\n   | Basic agent | ConversableAgent | ChatAgent | AI conversational agent |\n   | Tool-enabled agent | AssistantAgent | ToolAgent pattern | Function-calling agent |\n   | Human proxy | UserProxyAgent | Task with interactive=True | Human-in-loop agent |\n   | Orchestrator | GroupChatManager | Parent Task | Multi-agent coordinator |\n\n   ### Communication Patterns\n\n   | Pattern | Autogen | Langroid | General |\n   |---------|---------|----------|---------|\n   | One-to-one | send() / initiate_chat() | Task.run() | Direct messaging |\n   | Multi-party | GroupChat + GroupChatManager | Task hierarchy | Multi-agent system |\n\n   ### Tool/Function Calling\n\n   | Aspect | Autogen | Langroid | General |\n   |--------|---------|----------|---------|\n   | Definition | Function with type hints | ToolMessage subclass | Tool schema |\n   | Registration | @register_for_llm() | Auto-detection | Tool registry |\n   | Execution | @register_for_execution() | ToolMessage.handle() | Tool executor |\n\n   [Continue with comprehensive mappings...]\n\n   **Want to dive deeper into any concept? Just ask!**\n   ```\n\n   **Option 2: Specific Concept**\n   ```markdown\n   ## Mapping: [Concept Name]\n\n   ### What it is (General)\n   [Plain language explanation]\n\n   ### Autogen Implementation\n   - **Class/Method**: [name]\n   - **Purpose**: [what it does]\n   - **Use cases**: [when to use]\n   - **Key methods**: [list]\n   - **Example**:\n     ```python\n     [code example]\n     ```\n\n   ### Langroid Implementation\n   - **Class/Pattern**: [name]\n   - **Purpose**: [what it does]\n   - **Use cases**: [when to use]\n   - **Key methods**: [list]\n   - **Example**:\n     ```python\n     [code example]\n     ```\n\n   ### Conceptual Relationship\n   - Both solve: [problem]\n   - Key difference: [how they differ]\n   - Choose Autogen if: [scenario]\n   - Choose Langroid if: [scenario]\n\n   ### Cross-Domain Translation\n   If you're moving from [framework A] to [framework B]:\n   - Instead of [A concept], use [B equivalent]\n   - Pattern changes from [A pattern] to [B pattern]\n   ```\n\n   **Option 3: Domain-Specific Deep Dive**\n   ```markdown\n   ## [Framework] Complete Patterns\n\n   ### Agent Hierarchy\n   [Detailed class hierarchy with relationships]\n\n   ### Communication Patterns\n   [All messaging patterns with code examples]\n\n   ### Tool Integration\n   [Complete tool calling workflow]\n\n   ### Orchestration\n   [Multi-agent coordination patterns]\n\n   [Include ontology graph visualization as markdown tree]\n   ```\n\n   **Option 4: Cross-Framework Comparison**\n   ```markdown\n   ## [Concept] Across All Frameworks\n\n   ### Problem Statement\n   [What problem this solves]\n\n   ### Autogen Approach\n   - Philosophy: [design philosophy]\n   - Implementation: [how it works]\n   - Code pattern: [example]\n   - Pros: [benefits]\n   - Cons: [limitations]\n\n   ### Langroid Approach\n   - Philosophy: [design philosophy]\n   - Implementation: [how it works]\n   - Code pattern: [example]\n   - Pros: [benefits]\n   - Cons: [limitations]\n\n   ### General Pattern\n   - Abstract concept: [explanation]\n   - When to use: [scenarios]\n   - Alternatives: [other approaches]\n\n   ### Migration Guide\n   From Autogen to Langroid:\n   1. [Step 1]\n   2. [Step 2]\n\n   From Langroid to Autogen:\n   1. [Step 1]\n   2. [Step 2]\n   ```\n\n5. **Interactive Follow-Up**\n\n   After presenting information, offer:\n   ```\n   What would you like to explore next?\n   - Dive deeper into [related concept]\n   - See code examples for [specific pattern]\n   - Compare with [alternative framework]\n   - Get clarification on [ambiguous term]\n   - Continue with current understanding\n   ```\n\n## Usage Examples\n\n**Basic usage (presents options):**\n```\n/map-domain\n```\n\n**Specific concept:**\n```\n/map-domain ConversableAgent\n```\n\n**Framework comparison:**\n```\n/map-domain autogen vs langroid\n```\n\n**After command, user can request:**\n```\nshow me tool calling patterns\n```\nor\n```\nhow do I migrate from Autogen to Langroid?\n```\nor\n```\nexplain GroupChat in simple terms\n```\n\n## Data Sources\n\n- **ontology-graph.json**: Conceptual hierarchies and relationships\n- **technical-mappings.json**: Precise technical translations\n- **ambiguous-terms.json**: User phrase to technical term mappings\n- **references/domain-ontologies.md**: Detailed relationship graphs\n- **references/translation-patterns.md**: Common translation patterns\n\n## Output Format\n\n- **Conversational introduction**: Detect context, present options\n- **Structured reference**: Tables, hierarchies, code examples\n- **Interactive navigation**: User can drill down or switch topics\n- **Always contextual**: Adapt to user's current framework and goals\n\n## Important Principles\n\n- **User-directed**: Present complete reference, user chooses depth\n- **Conversational**: Not a dry reference dump, but guided exploration\n- **Multi-modal**: Tables, code, explanations, visualizations\n- **Cross-linkable**: Connect related concepts naturally\n- **No assumptions**: If unclear which framework user wants, ask\n- **Practical focus**: Include code examples and use cases\n- **Jargon translation**: Always explain technical terms\n\n## Integration\n\n- Works standalone or after semantic validation\n- Can be triggered from `/validate-terminology` findings\n- References same knowledge base as validation workflow\n- Complements clarification process with comprehensive mappings"
              },
              {
                "name": "/semantic-config",
                "description": "Configure semantic validation sensitivity, interaction style, enabled domains, and custom user trigger words or phrases for personalized ambiguity detection",
                "path": "plugins/semantic-linguist/commands/semantic-config.md",
                "frontmatter": {
                  "name": "semantic-config",
                  "description": "Configure semantic validation sensitivity, interaction style, enabled domains, and custom user trigger words or phrases for personalized ambiguity detection"
                },
                "content": "# Semantic Configuration Command\n\nConfigure semantic validation behavior, detection sensitivity, and custom user trigger phrases.\n\n## Process\n\n1. **Check for Existing Configuration**\n   - Look for `.claude/semantic-linguist.local.md` in project\n   - If exists, read current settings from YAML frontmatter\n   - If not exists, use defaults\n\n2. **Present Current Configuration**\n   ```\n   # Semantic Linguist Configuration\n\n   **Current Settings:**\n\n   ## Detection Sensitivity\n   - **Threshold**: [current] (Options: low=50, medium=60, high=80)\n   - **Meta-questions**: [enabled/disabled]\n   - **Domain confusion**: [enabled/disabled]\n\n   ## Interaction Style\n   - **Mode**: [current] (conversational | explicit | minimal)\n   - **Auto-validate**: [yes/no]\n\n   ## Enabled Domains\n   - **Autogen**: [✓/✗]\n   - **Langroid**: [✓/✗]\n   - **General**: [✓/✗]\n\n   ## Custom User Triggers\n   - [list of custom phrases]\n   - (These are phrases unique to you that should trigger validation)\n\n   ---\n\n   What would you like to configure?\n   1. Adjust sensitivity\n   2. Change interaction style\n   3. Enable/disable domains\n   4. Add custom trigger phrases\n   5. Reset to defaults\n   6. View all settings\n   ```\n\n3. **Interactive Configuration**\n\n   **Option 1: Adjust Sensitivity**\n   ```\n   ## Detection Sensitivity Settings\n\n   **Confidence Threshold**:\n   - Low (50): More detections, may include minor ambiguities\n   - Medium (60): Balanced - catches significant ambiguities (default)\n   - High (80): Only very ambiguous terms or meta-questions\n\n   Current: [X]\n\n   **Detection Categories** (enable/disable):\n   - [ ] Meta-questions (\"am I making sense?\")\n   - [ ] High-ambiguity terms (\"make it talk\", \"we need an api\")\n   - [ ] Vague action verbs (\"make it X\", \"do the thing\")\n   - [ ] Generic terms (\"component\", \"service\", \"module\")\n   - [ ] Domain confusion (mixing framework terms)\n   - [ ] Unclear references (\"that\", \"it\", \"the thing\")\n\n   Which would you like to change?\n   ```\n\n   **Option 2: Interaction Style**\n   ```\n   ## Interaction Style\n\n   **Conversational** (default):\n   - Friendly, helpful tone\n   - Presents options naturally\n   - Minimal technical jargon\n   - Good for: All users, especially non-technical\n\n   **Explicit**:\n   - Direct, structured responses\n   - Clear numbered options\n   - More technical precision\n   - Good for: Technical users, rapid clarification\n\n   **Minimal**:\n   - Brief summaries only\n   - Only triggers on high-confidence ambiguities\n   - Assumes user prefers autonomy\n   - Good for: Experienced users who know what they want\n\n   Current: [X]\n\n   **Auto-validate**: [yes/no]\n   - If yes: Automatically analyze and clarify when ambiguity detected\n   - If no: Detect but wait for user to request validation\n\n   Select new style or keep current?\n   ```\n\n   **Option 3: Domain Selection**\n   ```\n   ## Enabled Domains\n\n   Configure which frameworks to provide mappings for:\n\n   - [ ] **Autogen** (multi-agent conversations, GroupChat, AssistantAgent)\n   - [ ] **Langroid** (Task orchestration, ToolMessage, ChatAgent)\n   - [ ] **General** (Cross-framework concepts, general AI patterns)\n\n   Current selection: [X, Y]\n\n   **Why disable a domain?**\n   - Reduces noise if you only work with specific framework\n   - Faster validation (fewer mappings to check)\n   - Cleaner clarification suggestions\n\n   **Recommendation**: Keep all enabled unless you exclusively use one framework.\n\n   Which domains should be active?\n   ```\n\n   **Option 4: Custom Trigger Phrases**\n   ```\n   ## Custom User Triggers\n\n   Add phrases that are unique to your communication style that should trigger validation.\n\n   **Current custom triggers**:\n   [list existing]\n\n   **Why add custom triggers?**\n   Different users have different quirks - phrases you use that might be ambiguous but aren't in the standard knowledge base.\n\n   **Examples of good custom triggers**:\n   - \"hook it up\" (could mean: connect systems, add event handler, integrate API)\n   - \"plug it in\" (could mean: dependency injection, module import, literal plugin)\n   - \"wire everything together\" (could mean: dependency wiring, event connections, integration)\n   - Your unique jargon or shorthand\n\n   **Add new trigger phrase**:\n   Format: \"phrase\" → ambiguity_score (0.5-1.0) → categories → possible meanings\n\n   Example:\n   ```yaml\n   \"hook it up\":\n     score: 0.85\n     categories: [\"vague_action\", \"integration\"]\n     meanings:\n       autogen: [\"register_for_llm\", \"message routing\"]\n       langroid: [\"Task connection\", \"agent chaining\"]\n       general: [\"API integration\", \"event handler\"]\n   ```\n\n   Enter custom phrase to add:\n   ```\n\n   **Option 5: Reset to Defaults**\n   ```\n   ## Reset to Defaults\n\n   This will restore all settings to default values:\n   - Threshold: 60 (medium)\n   - Interaction: conversational\n   - Domains: all enabled\n   - Custom triggers: cleared\n\n   **Your current custom triggers will be lost.**\n\n   Are you sure? (yes/no)\n   ```\n\n   **Option 6: View All Settings**\n   ```\n   # Complete Semantic Linguist Configuration\n\n   ## Detection\n   - **Threshold**: [value]\n   - **Meta-questions**: ✓\n   - **High-ambiguity terms**: ✓\n   - **Vague verbs**: ✓\n   - **Generic terms**: ✓\n   - **Domain confusion**: ✓\n   - **Unclear references**: ✓\n\n   ## Interaction\n   - **Style**: conversational\n   - **Auto-validate**: yes\n\n   ## Domains\n   - **Autogen**: ✓\n   - **Langroid**: ✓\n   - **General**: ✓\n\n   ## Custom Triggers ([count])\n   [detailed list with scores and meanings]\n\n   ## Storage Location\n   `.claude/semantic-linguist.local.md`\n\n   (This file is git-ignored by default)\n   ```\n\n4. **Save Configuration**\n\n   Write settings to `.claude/semantic-linguist.local.md`:\n   ```markdown\n   ---\n   # Semantic Linguist Configuration\n   # Do not commit this file - it contains user-specific settings\n\n   detection:\n     threshold: 60\n     categories:\n       meta_questions: true\n       high_ambiguity: true\n       vague_verbs: true\n       generic_terms: true\n       domain_confusion: true\n       unclear_refs: true\n\n   interaction:\n     style: conversational  # conversational | explicit | minimal\n     auto_validate: true\n\n   domains:\n     autogen: true\n     langroid: true\n     general: true\n\n   custom_triggers:\n     \"hook it up\":\n       score: 0.85\n       categories: [\"vague_action\", \"integration\"]\n       meanings:\n         autogen: [\"register_for_llm\", \"message routing\"]\n         langroid: [\"Task connection\", \"agent chaining\"]\n         general: [\"API integration\", \"event handler\"]\n   ---\n\n   # Semantic Linguist User Configuration\n\n   This file stores your personal semantic validation preferences.\n\n   ## How to Edit\n\n   1. Run `/semantic-config` to use interactive configuration\n   2. Or edit YAML frontmatter directly above\n   3. Changes take effect immediately\n\n   ## Custom Triggers Format\n\n   Add your unique phrases that should trigger validation:\n\n   ```yaml\n   \"your phrase here\":\n     score: 0.5-1.0  # How ambiguous (0.5=moderate, 1.0=very ambiguous)\n     categories: [list of categories]\n     meanings:\n       framework: [list of possible meanings]\n   ```\n\n   ## Need Help?\n\n   Run `/validate-terminology` to see how current settings affect detection.\n   ```\n\n5. **Confirm Changes**\n   ```\n   ✅ Configuration saved to `.claude/semantic-linguist.local.md`\n\n   **New settings**:\n   - [summary of changes]\n\n   Changes are active immediately. Run `/validate-terminology` to test new settings.\n\n   **Next steps**:\n   - Test with recent conversation: `/validate-terminology`\n   - View domain mappings: `/map-domain`\n   - Continue working with new validation settings\n   ```\n\n## Usage Examples\n\n**Interactive configuration:**\n```\n/semantic-config\n```\n\n**Quick threshold adjustment:**\n```\n/semantic-config threshold high\n```\n\n**Add custom trigger:**\n```\n/semantic-config add-trigger \"wire it up\"\n```\n\n**View current settings:**\n```\n/semantic-config show\n```\n\n**Reset to defaults:**\n```\n/semantic-config reset\n```\n\n## Configuration File\n\nSettings stored in: `.claude/semantic-linguist.local.md`\n\n**Format**: Markdown with YAML frontmatter\n**Scope**: Project-specific (each project can have different settings)\n**Version control**: Automatically added to `.gitignore`\n\n## Default Values\n\n```yaml\ndetection:\n  threshold: 60\n  categories:\n    meta_questions: true\n    high_ambiguity: true\n    vague_verbs: true\n    generic_terms: true\n    domain_confusion: true\n    unclear_refs: true\n\ninteraction:\n  style: conversational\n  auto_validate: true\n\ndomains:\n  autogen: true\n  langroid: true\n  general: true\n\ncustom_triggers: {}\n```\n\n## Important Principles\n\n- **User-specific**: Each user has unique communication patterns\n- **Project-scoped**: Different projects may need different settings\n- **Git-safe**: Configuration file is git-ignored by default\n- **Immediately active**: No restart required\n- **Reversible**: Can always reset to defaults\n- **Transparent**: View all settings at any time\n\n## Integration\n\n- UserPromptSubmit hook reads these settings\n- Detection threshold affects confidence scoring\n- Custom triggers added to ambiguous-terms.json logic\n- Domain selection filters mapping results\n- Interaction style affects response formatting\n\n## Advanced: Direct Editing\n\nPower users can edit `.claude/semantic-linguist.local.md` directly:\n\n1. Open file in editor\n2. Modify YAML frontmatter\n3. Save file\n4. Changes apply immediately\n\nValidate syntax with `/semantic-config validate`."
              },
              {
                "name": "/validate-terminology",
                "description": "Analyze recent conversation messages for ambiguous terminology and provide semantic validation with conversational summary and optional detailed report",
                "path": "plugins/semantic-linguist/commands/validate-terminology.md",
                "frontmatter": {
                  "name": "validate-terminology",
                  "description": "Analyze recent conversation messages for ambiguous terminology and provide semantic validation with conversational summary and optional detailed report"
                },
                "content": "# Validate Terminology Command\n\nAnalyze the last 5-10 messages in the conversation for semantic ambiguities and provide validation feedback.\n\n## Process\n\n1. **Retrieve Recent Messages**\n   - Extract last 5-10 user messages from conversation history\n   - Include Claude's responses for context\n\n2. **Load Knowledge Base**\n   - Read `skills/semantic-validation/knowledge/ambiguous-terms.json`\n   - Read `skills/semantic-validation/knowledge/technical-mappings.json`\n   - Read `skills/semantic-validation/knowledge/ontology-graph.json`\n\n3. **Detect Ambiguities**\n   - Scan for known ambiguous terms from knowledge base\n   - Identify meta-questions (\"am I making sense?\", \"does this make sense?\")\n   - Detect vague action verbs (\"make it X\", \"do the thing\")\n   - Check for generic technical terms without context\n   - Look for unclear references (\"that\", \"it\", \"the thing\")\n   - Identify domain confusion (mixing framework-specific terms)\n\n4. **Calculate Confidence Scores**\n   - Meta-question detected: +100 (auto-trigger)\n   - Known high-ambiguity term: +40\n   - Vague action verb: +30\n   - Generic term without context: +25\n   - Domain confusion: +35\n   - Unclear reference: +20\n   - Recent conversation provides context: -20\n   - Specific technical term used: -30\n\n5. **Provide Conversational Summary**\n   - **If no ambiguities found (score < 60):**\n     ```\n     ✅ Terminology looks clear! I didn't detect any significant ambiguities in the last [N] messages.\n\n     The conversation has been using specific technical terms and clear references.\n     ```\n\n   - **If minor ambiguities (score 60-79):**\n     ```\n     ⚠️ Found some potentially ambiguous terms:\n\n     - \"[term]\" could mean:\n       • [Option 1] (most likely based on context)\n       • [Option 2]\n\n     Current context suggests [interpretation], but let me know if that's not what you meant.\n\n     Want a detailed report? Just ask!\n     ```\n\n   - **If significant ambiguities (score ≥ 80):**\n     ```\n     🔍 Detected several ambiguous terms that might benefit from clarification:\n\n     **High-priority:**\n     - \"[term 1]\" (score: [X]) - Could mean:\n       • [Domain 1]: [precise meaning]\n       • [Domain 2]: [precise meaning]\n       • [General]: [precise meaning]\n\n     **Moderate-priority:**\n     - \"[term 2]\" (score: [Y]) - Possible interpretations...\n\n     Would you like me to:\n     1. Clarify these terms now\n     2. See a detailed analysis report\n     3. Continue with my best understanding\n\n     (Type \"detailed report\" for comprehensive analysis)\n     ```\n\n6. **Generate Detailed Report (if requested)**\n   When user requests detailed report, provide:\n\n   ```markdown\n   # Semantic Validation Report\n\n   ## Analysis Summary\n   - **Messages analyzed**: [N]\n   - **Ambiguities detected**: [count]\n   - **Confidence scores**: [range]\n   - **Domains detected**: [list]\n\n   ## Detected Ambiguities\n\n   ### 1. \"[ambiguous term]\" (Score: [X])\n\n   **Category**: [vague_action_verb | unclear_scope | generic_term | meta_question | domain_confusion]\n\n   **Possible meanings**:\n   - **Autogen**: [precise translation]\n     - Methods: [list]\n     - Use cases: [list]\n   - **Langroid**: [precise translation]\n     - Methods: [list]\n     - Use cases: [list]\n   - **General**: [precise translation]\n\n   **Context clues**:\n   - [Relevant context from conversation]\n\n   **Recommended clarification**:\n   > \"[Specific question to ask user]\"\n\n   **Why this matters**:\n   [Explanation of why ambiguity is problematic]\n\n   ---\n\n   ### 2. [Next ambiguity]...\n\n   ## Cross-Domain Equivalents\n\n   If user is working across frameworks:\n   - **Autogen term** → **Langroid equivalent** → **General concept**\n   - [mappings from ontology-graph.json]\n\n   ## Recommendations\n\n   1. **Immediate clarifications needed**: [list]\n   2. **Context-dependent terms**: [list]\n   3. **Suggested terminology**: [precise alternatives]\n\n   ## Next Steps\n\n   Would you like me to:\n   - Clarify specific terms now\n   - Map to your target domain\n   - Continue with validated understanding\n   ```\n\n## Usage Examples\n\n**Basic usage:**\n```\n/validate-terminology\n```\n\n**After validation, user can request:**\n```\ndetailed report\n```\nor\n```\nclarify [specific term]\n```\n\n## Integration\n\n- Loads semantic-validation skill automatically\n- Uses knowledge files for detection\n- References ontology-graph.json for cross-domain mappings\n- Conversational and non-blocking\n- Always offers options, never assumes\n\n## Output Format\n\n- **Conversational summary** (default): 3-5 sentences with key findings\n- **Detailed report** (on request): Comprehensive markdown analysis\n- **Interactive follow-up**: User can ask for clarifications or mappings\n\n## Important Principles\n\n- **Never assume**: Present options, verify with user\n- **Conversational tone**: Friendly and helpful, not prescriptive\n- **Context-aware**: Consider recent conversation flow\n- **Actionable**: Provide clear next steps\n- **Optional detail**: Summary first, detailed report on request"
              }
            ],
            "skills": [
              {
                "name": "Semantic Translation",
                "description": "This skill should be used when the user uses ambiguous terminology like \"make it talk\", \"we need an api\", \"make it portable\", \"check for gaps\", asks meta-questions like \"am I making sense?\", \"does this make sense?\", mentions being a \"non-technical user\", uses vague action verbs (\"make it work\", \"do the thing\"), mixes domain languages, uses invented terms, or when detecting semantic drift between human natural language and technical precision. Provides semantic translation, disambiguation, and domain knowledge mapping across Autogen, Langroid, MCP (Model Context Protocol), UTCP (Universal Tool Calling Protocol), FastAPI, Git/Gitflow, SRE (Site Reliability Engineering), and Memory Graphs domains. Bridges the gap between user intent and technical specificity through ontological translation.",
                "path": "plugins/semantic-linguist/skills/semantic-translation/SKILL.md",
                "frontmatter": {
                  "name": "Semantic Translation",
                  "description": "This skill should be used when the user uses ambiguous terminology like \"make it talk\", \"we need an api\", \"make it portable\", \"check for gaps\", asks meta-questions like \"am I making sense?\", \"does this make sense?\", mentions being a \"non-technical user\", uses vague action verbs (\"make it work\", \"do the thing\"), mixes domain languages, uses invented terms, or when detecting semantic drift between human natural language and technical precision. Provides semantic translation, disambiguation, and domain knowledge mapping across Autogen, Langroid, MCP (Model Context Protocol), UTCP (Universal Tool Calling Protocol), FastAPI, Git/Gitflow, SRE (Site Reliability Engineering), and Memory Graphs domains. Bridges the gap between user intent and technical specificity through ontological translation.",
                  "version": "1.0.0"
                },
                "content": "# Semantic Translation & Ontological Mapping\n\n## Purpose\n\nPrevent miscommunication, assumptions, and hallucinations by translating ambiguous user terminology into precise technical concepts across multiple domains. Act as a semantic bridge between human natural language and technical specificity, mapping concepts across Autogen, Langroid, MCP, UTCP, FastAPI, Git/Gitflow, SRE, and Memory Graphs ecosystems.\n\n## Supported Domains\n\nThis skill provides semantic translation and disambiguation across 8 technical domains:\n\n1. **Autogen** - Multi-agent orchestration (ConversableAgent, AssistantAgent, UserProxyAgent, GroupChat)\n2. **Langroid** - Agent framework (ChatAgent, ToolAgent, Task orchestration)\n3. **MCP (Model Context Protocol)** - Server types (SSE, stdio, HTTP, WebSocket), tools, resources, prompts, sampling\n4. **UTCP (Universal Tool Calling Protocol)** - Framework-agnostic tool schemas, adapters, universal tool definitions\n5. **FastAPI** - Python web framework (path operations, dependency injection with Depends(), Pydantic models, APIRouter)\n6. **Git/Gitflow** - Version control workflows (feature/release/hotfix branches, merge strategies, collaboration patterns)\n7. **SRE (Site Reliability Engineering)** - Observability pillars (logs/metrics/traces), SLO/SLI/SLA, incident management\n8. **Memory Graphs** - Knowledge graph structures (entities, relationships, embeddings, episodic/semantic/procedural memory)\n\n## The Core Problem\n\nUsers frequently encounter the \"abyss\" between natural language intent and technical precision:\n\n- **Vague terminology**: \"make it talk\", \"we need an api\", \"make it work\"\n- **Unclear scope**: \"check for gaps\", \"make it portable\"\n- **Meta-questions**: \"am I making sense?\", \"does this make sense?\"\n- **Domain confusion**: Mixing business and technical terminology\n- **Invented terms**: User-created words not in domain vocabulary\n\nWithout intervention, these ambiguities lead to:\n- AI assumptions and hallucinations\n- Misaligned implementations\n- Wasted development time\n- Project failures from misunderstood requirements\n\n## When to Use This Skill\n\nTrigger semantic validation when detecting:\n\n1. **Ambiguous Action Verbs**\n   - \"make it [X]\" → Multiple technical interpretations possible\n   - \"do the thing\" → No clear referent\n   - \"fix it\" → Unclear what or how\n\n2. **Meta-Questions (User Seeking Validation)**\n   - \"am I making sense?\" → User uncertain about their explanation\n   - \"does this make sense?\" → User seeking confirmation\n   - \"is this right?\" → User wants validation\n   - \"non-technical user\" → User self-identifies as potentially ambiguous\n\n3. **Domain-Crossing Language**\n   - Mixing business and technical terms\n   - Unclear which framework/library intended\n   - Generic terms with multiple technical meanings\n\n4. **Unclear References**\n   - \"that\", \"the previous thing\", \"like before\"\n   - References without clear antecedents\n\n5. **Scope Ambiguity**\n   - \"portable\" → Docker? Cross-platform? Vendoring? Executable?\n   - \"api\" → HTTP server? API client? API design? Internal interface?\n   - \"gaps\" → Code coverage? Documentation? Features? Security?\n\n## Core Workflow\n\n### Step 1: Detect Ambiguity\n\nAnalyze the user's message for ambiguity signals. Use pattern matching from `scripts/detect-ambiguity.py` or manual analysis.\n\n**High-confidence triggers (always validate):**\n- Explicit meta-questions: \"am I making sense?\"\n- Vague action verbs with unclear objects: \"make it talk\"\n- Domain confusion: mixing incompatible terminology\n- User self-identification: \"I'm a non-technical user\"\n\n**Moderate-confidence triggers (validate if >80% confidence):**\n- Generic technical terms: \"api\", \"agent\", \"portable\"\n- Unclear scope: \"check for gaps\", \"add validation\"\n- Invented terminology: words not in domain vocabulary\n\n### Step 2: Query Knowledge Sources (In Order)\n\nQuery knowledge sources in this specific order for efficiency:\n\n**1. Static Domain Knowledge (First - Fastest)**\n- Query `knowledge/ambiguous-terms.json` for known ambiguous phrases\n- Check `knowledge/technical-mappings.json` for domain-specific translations\n- Review `knowledge/ontology-graph.json` for conceptual relationships\n\n**2. External Documentation (Second - Authoritative)**\n- Query official documentation (Autogen, Langroid, etc.) via available tools\n- Use WebFetch, context7, or deepwiki MCP for current API references\n- Validate against authoritative sources when static knowledge insufficient\n\n**3. Codebase Validation (Third - Context-Specific)**\n- Use LSP to query symbol definitions in user's project\n- Use Grep to search for actual usage patterns\n- Identify project-specific terminology and conventions\n\n### Step 3: Translate Ambiguous → Precise\n\nMap ambiguous terminology to precise technical concepts using domain knowledge.\n\n**Translation process:**\n1. Identify all possible technical interpretations\n2. Rank by confidence score (from knowledge files)\n3. Consider user's context (recent conversation, project domain)\n4. Present options if multiple interpretations viable\n\n**Example translation:**\n```\nAmbiguous: \"make it talk\"\nDomain: Autogen\nPossible translations:\n- ConversableAgent.send() (confidence: 0.8, context: single message)\n- register ConversableAgent (confidence: 0.7, context: enable conversation)\n- GroupChat setup (confidence: 0.5, context: multi-agent conversation)\n```\n\n### Step 4: Engage Conversational Clarification\n\n**Never assume.** Always verify understanding with the user.\n\nPresent options conversationally:\n```\nI notice \"[ambiguous term]\" could mean different things:\n\n1. [Precise interpretation 1] - [Brief context]\n2. [Precise interpretation 2] - [Brief context]\n3. [Precise interpretation 3] - [Brief context]\n\n[Ask clarifying question based on context]\n```\n\n**Tone guidelines:**\n- Conversational, not clinical\n- Helpful, not pedantic\n- Transparent about uncertainty\n- Frame as collaboration, not correction\n\n**Wait for confirmation** before proceeding with implementation.\n\n## Decision Trees\n\n### Primary Decision Tree\n\n```\nUser message received\n├── Contains meta-question? (\"am I making sense?\")\n│   ├── Yes → HIGH confidence, validate immediately\n│   └── No → Continue analysis\n├── Contains ambiguous action verb? (\"make it talk\")\n│   ├── Yes → Check domain context\n│   │   ├── Clear domain → Query knowledge, translate\n│   │   └── Unclear domain → Ask which framework/library\n│   └── No → Continue analysis\n├── Contains vague scope? (\"check for gaps\", \"make it portable\")\n│   ├── Yes → Query knowledge for common interpretations\n│   │   ├── Multiple viable → Present options\n│   │   └── One clear match → Confirm with user\n│   └── No → Continue analysis\n├── Contains domain-crossing language?\n│   ├── Yes → Identify conflicting domains, ask clarification\n│   └── No → Proceed normally (low ambiguity)\n```\n\n### Clarification Decision Tree\n\n```\nAmbiguity detected\n├── Confidence score > 80%?\n│   ├── Yes → Trigger validation\n│   └── No → Monitor, don't interrupt\n├── Query knowledge sources (static → external → codebase)\n├── Translation mappings found?\n│   ├── Yes, single mapping → Confirm with user\n│   ├── Yes, multiple mappings → Present options\n│   └── No mappings found → Ask open-ended clarification\n└── User confirms → Proceed with precise terminology\n```\n\n## Domain Quick Reference\n\nKey ambiguous terms across all 8 supported domains with precise translations:\n\n### Autogen Domain\n\n**\"make it talk\"** → ConversableAgent.send() (single message) vs initiate_chat() (conversation) vs GroupChat setup (multi-agent)\n**\"agent\"** → ConversableAgent (base) vs AssistantAgent (LLM-powered) vs UserProxyAgent (human proxy)\n\n### Langroid Domain\n\n**\"agent\"** → ChatAgent (conversation) vs ToolAgent (function-calling)\n**\"task\"** → Langroid Task object (orchestration) vs general task concept\n\n### MCP Domain\n\n**\"mcp server\"** → SSE server (web-based) vs stdio server (process-based) vs HTTP server vs WebSocket server\n**\"resource\"** → MCP resource (data/content exposed by server) vs system resource (CPU/memory)\n**\"prompt\"** → MCP prompt template (structured prompts) vs LLM prompt (text input)\n\n### UTCP Domain\n\n**\"tool calling\"** → UTCP universal calling (framework-agnostic) vs framework-specific (OpenAI tools, Anthropic tools)\n**\"tool schema\"** → UTCP universal schema vs framework-specific schema\n\n### FastAPI Domain\n\n**\"dependency\"** → FastAPI Depends() (dependency injection) vs pip dependency (package) vs architectural dependency (service)\n**\"endpoint\"** → Path operation decorator (@app.get) vs external API endpoint\n**\"model\"** → Pydantic model (validation) vs database model (ORM) vs ML model\n\n### Git/Gitflow Domain\n\n**\"merge\"** → Merge commit (preserves history) vs squash merge (single commit) vs rebase (linear history)\n**\"branch\"** → Gitflow branch type (feature/release/hotfix/develop/main) vs general branch name\n\n### SRE Domain\n\n**\"observability\"** → Logs (events) vs metrics (measurements) vs traces (request paths) - three pillars\n**\"sli\"** → Availability SLI (uptime %) vs latency SLI (response time) vs error rate SLI (failure %)\n**\"incident\"** → SEV-1 incident (critical outage) vs alert (automated notification) vs degradation (partial failure)\n\n### Memory Graphs Domain\n\n**\"memory\"** → Knowledge graph (structured entities/relationships) vs vector memory (embeddings) vs episodic memory (temporal context) vs system RAM\n**\"retrieval\"** → Semantic search (embedding similarity) vs graph traversal (relationship following) vs hybrid approach\n\n### Meta-Questions (Cross-Domain)\n\n**\"am I making sense?\"** → Trigger explicit semantic validation across all domains\n- Summarize recent conversation\n- Identify detected ambiguities\n- Ask domain-specific clarifying questions\n- Confirm shared understanding with precise terminology\n\n## Domain-Specific Validation\n\n### Autogen Domain\n\n**Key concepts to validate:**\n- Agent types: ConversableAgent, AssistantAgent, UserProxyAgent\n- Multi-agent: GroupChat, GroupChatManager\n- Communication: send(), register_reply(), initiate_chat()\n- Tools: register_for_execution(), register_for_llm()\n\n**Common ambiguities:**\n- \"agent\" → Which type? (ConversableAgent vs AssistantAgent vs UserProxyAgent)\n- \"group chat\" → GroupChat object vs general multi-agent conversation\n- \"tools\" → Function calling vs external tool integration\n\n### Langroid Domain\n\n**Key concepts to validate:**\n- Agent types: ChatAgent, ToolAgent\n- Tasks: Task orchestration and delegation\n- Tools: ToolMessage, tool decorators\n- Multi-agent: Agent collaboration patterns\n\n**Common ambiguities:**\n- \"agent\" → ChatAgent vs ToolAgent\n- \"task\" → Langroid Task object vs general task concept\n- \"tools\" → Langroid tool system vs general utilities\n\n### MCP Domain\n\n**Key concepts to validate:**\n- Server types: SSE (Server-Sent Events), stdio, HTTP, WebSocket\n- Components: tools, resources, prompts, sampling\n- Integration: local server, remote server, managed server\n\n**Common ambiguities:**\n- \"mcp server\" → Which type? (SSE vs stdio vs HTTP vs WebSocket)\n- \"resource\" → MCP resource (data/content) vs system resource\n- \"prompt\" → MCP prompt template vs LLM prompt\n- \"tool\" → MCP tool definition vs general function\n\n### UTCP Domain\n\n**Key concepts to validate:**\n- Universal tool schemas: Framework-agnostic tool definitions\n- Adapters: UTCP framework adapters for different AI frameworks\n- Tool calling patterns: Universal invocation vs framework-specific\n\n**Common ambiguities:**\n- \"tool calling\" → UTCP universal calling vs framework-specific calling (OpenAI tools, Anthropic tools)\n- \"tool schema\" → UTCP universal schema vs framework-specific schema\n- \"adapter\" → UTCP framework adapter vs general adapter pattern\n- \"invocation\" → UTCP tool invocation vs direct function call\n\n### FastAPI Domain\n\n**Key concepts to validate:**\n- Path operations: Endpoint decorators (@app.get, @app.post)\n- Dependency injection: Depends() mechanism\n- Pydantic models: Request/response validation\n- APIRouter: Endpoint organization and grouping\n\n**Common ambiguities:**\n- \"dependency\" → FastAPI Depends() vs pip package dependency vs architectural dependency\n- \"endpoint\" → Path operation decorator vs external API endpoint\n- \"model\" → Pydantic model vs database model vs ML model\n- \"route\" → Path operation vs APIRouter vs URL routing\n- \"validation\" → Pydantic automatic validation vs business logic validation\n\n### Git/Gitflow Domain\n\n**Key concepts to validate:**\n- Branch types: feature/, release/, hotfix/, develop, main\n- Merge strategies: merge commit, squash merge, rebase\n- Workflows: Gitflow vs GitHub flow vs GitLab flow\n- Operations: commit, push, pull, merge, rebase\n\n**Common ambiguities:**\n- \"merge\" → Merge commit vs squash merge vs rebase\n- \"branch\" → Gitflow branch type (feature/release/hotfix) vs general branch\n- \"rebase\" → Interactive rebase vs standard rebase vs rebase merge\n- \"commit\" → Commit operation vs commit message vs specific commit SHA\n- \"workflow\" → Gitflow workflow vs GitHub flow vs custom workflow\n\n### SRE Domain\n\n**Key concepts to validate:**\n- Observability pillars: logs, metrics, traces\n- SLI/SLO/SLA: Service Level Indicator/Objective/Agreement\n- Incident management: SEV levels, on-call, postmortems\n- Reliability patterns: error budgets, canary deployments, circuit breakers\n\n**Common ambiguities:**\n- \"observability\" → Which pillar? (logs vs metrics vs traces)\n- \"sli\" → Which metric? (availability vs latency vs throughput vs error rate)\n- \"incident\" → SEV-1 incident vs alert vs outage vs degradation\n- \"monitoring\" → Monitoring (passive data collection) vs observability (active understanding)\n- \"on-call\" → On-call rotation vs on-call engineer vs escalation policy\n\n### Memory Graphs Domain\n\n**Key concepts to validate:**\n- Graph types: knowledge graph, memory graph, dependency graph\n- Memory types: episodic, semantic, procedural\n- Components: entities (nodes), relationships (edges), embeddings\n- Operations: retrieval (semantic search, graph traversal), storage\n\n**Common ambiguities:**\n- \"memory\" → Knowledge graph vs vector memory vs episodic memory vs system RAM\n- \"graph\" → Knowledge graph vs visualization graph vs dependency graph\n- \"embedding\" → Vector embedding for semantic search vs embedding layer in neural networks\n- \"retrieval\" → Semantic search via embeddings vs graph traversal vs hybrid\n- \"node\" → Memory node (entity) vs graph node vs system node\n\n### Generic/Framework-Agnostic\n\n**When domain unclear:**\n1. Don't assume framework\n2. Ask explicitly: \"Which framework/library are you using?\"\n3. Once identified, load domain-specific knowledge\n4. Translate with domain context\n\n## Confidence Scoring\n\nUse confidence scores to determine intervention:\n\n**High confidence (>80%):** Always validate\n- Explicit meta-questions\n- Known highly ambiguous terms (from knowledge files)\n- Domain confusion detected\n- User self-identifies ambiguity\n\n**Medium confidence (50-80%):** Validate if multiple interpretations\n- Generic technical terms with context clues\n- Unclear scope with partial context\n- Vague references with some antecedents\n\n**Low confidence (<50%):** Monitor but don't interrupt\n- Technical terms with clear context\n- Conventional usage patterns\n- Recent clarification provided\n\n## Integration with Knowledge Files\n\n### ambiguous-terms.json\n\nContains user phrases mapped to ambiguity scores and contexts.\n\n**Query pattern:**\n```python\nterm = extract_key_phrase(user_message)\nentry = load_json(\"knowledge/ambiguous-terms.json\").get(term)\nif entry and entry[\"ambiguity_score\"] > 0.8:\n    trigger_validation(term, entry[\"contexts\"])\n```\n\n### technical-mappings.json\n\nContains precise technical translations organized by domain.\n\n**Query pattern:**\n```python\nmappings = load_json(\"knowledge/technical-mappings.json\")\ndomain_mappings = mappings.get(domain, {})\ntranslations = domain_mappings.get(ambiguous_term, [])\npresent_options(translations)\n```\n\n### ontology-graph.json\n\nContains conceptual relationships between terms across domains.\n\n**Query pattern:**\n```python\ngraph = load_json(\"knowledge/ontology-graph.json\")\nrelated_concepts = graph.get(concept, {}).get(\"related\", [])\ncross_domain = graph.get(concept, {}).get(\"cross_domain_equivalents\", {})\n```\n\n## Working with Scripts\n\n### scripts/detect-ambiguity.py\n\nPattern matching utility for ambiguity detection.\n\n**Usage:**\n```bash\npython scripts/detect-ambiguity.py --message \"user message here\"\n# Returns: confidence score, detected patterns, suggested validation\n```\n\n**When to use:**\n- Programmatic ambiguity detection in hooks\n- Batch analysis of conversation history\n- Testing new ambiguity patterns\n\n### scripts/domain-mapper.py\n\nTerm translation utility using knowledge files.\n\n**Usage:**\n```bash\npython scripts/domain-mapper.py --term \"make it talk\" --domain autogen\n# Returns: ranked translations with confidence scores\n```\n\n**When to use:**\n- Translate specific terms\n- Generate clarification options\n- Validate translations against knowledge\n\n### scripts/knowledge-query.py\n\nUnified interface to all knowledge sources.\n\n**Usage:**\n```bash\npython scripts/knowledge-query.py --term \"api\" --sources static,external,codebase\n# Returns: results from each source in order\n```\n\n**When to use:**\n- Query all knowledge sources in one call\n- Implement the three-tier query workflow\n- Aggregate results from multiple sources\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed domain knowledge and advanced patterns:\n- **`references/cognitive-framework.md`** - Complete AGENTS.md framework adapted for Claude Code\n- **`references/decision-trees.md`** - Detailed decision trees and flowcharts\n- **`references/domain-ontologies.md`** - Comprehensive domain knowledge graphs (Autogen, Langroid)\n- **`references/translation-patterns.md`** - Extensive ambiguous→precise mappings\n\n### Example Files\n\nWorking examples of semantic validation:\n- **`examples/autogen-mappings.md`** - Autogen-specific ambiguity resolutions\n- **`examples/langroid-mappings.md`** - Langroid-specific examples\n- **`examples/common-ambiguities.md`** - Cross-domain frequent patterns\n\n### Knowledge Files\n\nDomain knowledge JSON files:\n- **`knowledge/ambiguous-terms.json`** - User phrases with ambiguity scores\n- **`knowledge/technical-mappings.json`** - Domain-specific translations\n- **`knowledge/ontology-graph.json`** - Conceptual relationships\n\n## Best Practices\n\n### Always Verify, Never Assume\n\n\"Never ASSUME - it makes an ass out of u and me.\"\n\n- Present options when ambiguity detected\n- Ask clarifying questions before proceeding\n- Confirm understanding with user\n- Never proceed with interpretation alone\n\n### Maintain Conversational Tone\n\n- Avoid clinical language: \"Ambiguity detected at 87% confidence\"\n- Use helpful framing: \"I notice [term] could mean a few different things...\"\n- Frame as collaboration: \"Let me make sure I understand...\"\n- Be transparent about uncertainty\n\n### Respect User Triggers\n\nUsers have different patterns for expressing uncertainty. Learn from settings:\n- Default triggers: \"am I making sense?\", \"does this make sense?\"\n- Custom triggers from `.claude/semantic-linguist.local.md`\n- Adapt to user's communication style\n\n### Progressive Validation\n\nNot every message needs validation:\n- Start with high-confidence triggers only\n- Expand to moderate-confidence as needed\n- Don't interrupt clear, unambiguous requests\n- Balance helpfulness with intrusiveness\n\n## Configuration\n\nUsers can customize via `.claude/semantic-linguist.local.md`:\n\n- **Sensitivity**: low, medium (default), high\n- **Interaction style**: explicit (default), guided, silent\n- **User trigger phrases**: Custom patterns to trigger validation\n- **Custom terminology mappings**: Project-specific translations\n- **Enabled domains**: Which domains to validate against\n\nRespect user configuration when determining whether to trigger validation.\n\n---\n\n**Core principle**: Bridge the gap between human natural language and AI technical precision through systematic semantic validation and conversational clarification."
              }
            ]
          },
          {
            "name": "claude-pms",
            "description": "Procedural Memory System - Learns procedures, processes, and workflows from conversational history through three-tier architecture (Episodic → Semantic → Procedural). Shame on you.",
            "source": "./plugins/claude-pms",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add jcmrs/jcmrs-plugins",
              "/plugin install claude-pms@jcmrs-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-04T21:15:59Z",
              "created_at": "2025-12-21T13:19:03Z",
              "license": null
            },
            "commands": [
              {
                "name": "/config",
                "description": "Open or view PMS configuration file",
                "path": "plugins/claude-pms/commands/config.md",
                "frontmatter": {
                  "name": "pms:config",
                  "description": "Open or view PMS configuration file"
                },
                "content": "# PMS Configuration Management\n\nManage Claude PMS configuration settings.\n\n## Configuration Location\n\n```\n$CLAUDE_PROJECT_DIR/.claude/pms.local.md\n```\n\nYAML frontmatter format with markdown documentation.\n\n## Usage\n\n### Open in Editor (if available)\n\n```bash\nCONFIG_FILE=\"$CLAUDE_PROJECT_DIR/.claude/pms.local.md\"\n\n# Try common editors\nif command -v code >/dev/null 2>&1; then\n  code \"$CONFIG_FILE\"\nelif command -v nano >/dev/null 2>&1; then\n  nano \"$CONFIG_FILE\"\nelif command -v vim >/dev/null 2>&1; then\n  vim \"$CONFIG_FILE\"\nelse\n  echo \"No editor found. View config manually:\"\n  echo \"$CONFIG_FILE\"\nfi\n```\n\n### View Current Configuration\n\n```bash\nCONFIG_FILE=\"$CLAUDE_PROJECT_DIR/.claude/pms.local.md\"\n\nif [ -f \"$CONFIG_FILE\" ]; then\n  echo \"=== Current Configuration ===\"\n  echo \"\"\n  cat \"$CONFIG_FILE\"\n  echo \"\"\n  echo \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n  echo \"To edit: Open $CONFIG_FILE in your editor\"\n  echo \"After changes: Restart Claude Code session\"\nelse\n  echo \"Config not found. Creating default...\"\n  mkdir -p \"$(dirname \"$CONFIG_FILE\")\"\n  cp \"$CLAUDE_PLUGIN_ROOT/examples/pms.local.md\" \"$CONFIG_FILE\"\n  echo \"✓ Created default config at:\"\n  echo \"  $CONFIG_FILE\"\n  echo \"\"\n  echo \"Edit this file to customize PMS behavior\"\nfi\n```\n\n## Configuration Options\n\n### Triggers (When to capture sessions)\n```yaml\ntriggers:\n  precompact: true      # Before context compaction\n  session_end: true     # When session ends\n  stop: false           # When Claude stops (optional)\n```\n\n### Processing Modes\n```yaml\nprocessing:\n  continuous_mode: true      # Auto-extract after encoding\n  auto_synthesize: false     # Require approval for rules\n```\n\n**continuous_mode:**\n- `true`: Automatically run extraction after each encoding\n- `false`: Manual control with `/pms:extract`\n\n**auto_synthesize:**\n- `true`: Automatically generate rules without approval\n- `false`: User approval required (recommended)\n\n### Thresholds\n```yaml\nthresholds:\n  min_sessions: 10           # Minimum before extraction\n  emerging_pattern: 2        # 2+ occurrences\n  strong_pattern: 3          # 3+ occurrences (rule-worthy)\n  critical_pattern: 5        # 5+ occurrences (high priority)\n```\n\n### Privacy Settings\n```yaml\nprivacy:\n  redact_sensitive: true     # Auto-redact API keys, passwords\n  custom_redaction_patterns:\n    - \"custom_secret_pattern\"\n```\n\n### Encoding Preferences\n```yaml\nencoding:\n  prefer_context: true       # Use conversation history first\n  fallback_jsonl: true       # Fall back to JSONL if needed\n```\n\n### Timeouts (seconds)\n```yaml\ntimeouts:\n  encode: 30                 # Max encoding time\n  extract: 60                # Max extraction time\n  synthesize: 45             # Max synthesis time\n```\n\n## Applying Changes\n\n**After editing configuration:**\n\n1. Save the file\n2. Exit Claude Code: `exit` or Ctrl+D\n3. Restart: `claude` or `cc`\n4. Changes take effect\n\n**Configuration is loaded at session start** - changes mid-session won't apply.\n\n## Example Configurations\n\n### Minimal (Auto-everything)\n```yaml\n---\ntriggers:\n  precompact: true\nprocessing:\n  continuous_mode: true\n  auto_synthesize: true\n---\n```\n\n**Use when:** Trust the system, want hands-off operation\n\n### Conservative (Manual control)\n```yaml\n---\ntriggers:\n  precompact: false\n  session_end: false\nprocessing:\n  continuous_mode: false\n  auto_synthesize: false\n---\n```\n\n**Use when:** Want explicit control over all operations\n\n### Recommended (Balanced)\n```yaml\n---\ntriggers:\n  precompact: true\n  session_end: true\nprocessing:\n  continuous_mode: true\n  auto_synthesize: false      # Manual approval for rules\nthresholds:\n  min_sessions: 10\n  strong_pattern: 3\n---\n```\n\n**Use when:** Want automatic capture but manual rule approval\n\n## Troubleshooting\n\n**\"Config not loading\"**: Check YAML syntax with online validator.\n\n**\"Thresholds ignored\"**: Values clamped to valid ranges:\n- `min_sessions`: 5-50\n- `emerging_pattern`: 2-10\n- `strong_pattern` ≥ `emerging_pattern`\n- `critical_pattern` ≥ `strong_pattern`\n\n**\"Changes not applying\"**: Restart Claude Code session.\n\n**\"Default config restored\"**: Invalid YAML causes fallback to defaults. Check syntax.\n\n## Configuration File Location\n\n```bash\necho \"$CLAUDE_PROJECT_DIR/.claude/pms.local.md\"\n```\n\n## Verify Configuration Loaded\n\nCheck with `/pms:status` - shows current thresholds and triggers."
              },
              {
                "name": "/encode",
                "description": "Manually encode current session as episodic memory record",
                "path": "plugins/claude-pms/commands/encode.md",
                "frontmatter": {
                  "name": "pms:encode",
                  "description": "Manually encode current session as episodic memory record"
                },
                "content": "# Manual Episodic Encoding\n\nCapture the current session's work as an episodic memory record.\n\n## What This Does\n\n1. Analyzes the current conversation history\n2. Extracts structured information (tasks, decisions, patterns, preferences)\n3. Applies privacy redaction (API keys, passwords, etc.)\n4. Saves episodic record to `.claude/pms/episodic/sessions-YYYY-MM.json`\n\n## Usage\n\nSimply invoke this command at any point during a session to manually capture the session state.\n\n**When to use:**\n- After completing significant work\n- Before taking a break\n- When you want to preserve learning without waiting for auto-triggers\n\n## Execution\n\nExecute the episodic encoding script:\n\n```bash\npython \"$CLAUDE_PLUGIN_ROOT/scripts/encode.py\" \\\n  --project-path \"$CLAUDE_PROJECT_DIR\" \\\n  --trigger manual\n```\n\n## Expected Output\n\n```\nEpisodic record saved: sessions-2025-12.json\nSession ID: abc-123-def-456\nTimestamp: 2025-12-31T02:30:00Z\n```\n\n## What Happens Next\n\n- **Continuous mode enabled**: Semantic extraction runs automatically if threshold met\n- **Continuous mode disabled**: Run `/pms:reflect` or `/pms:extract` when ready\n\n## Troubleshooting\n\n**\"Context unavailable\"**: Falls back to JSONL transcript parsing (best effort).\n\n**\"Privacy redaction failed\"**: Over-redacts suspicious patterns for safety.\n\n**\"Encoding timeout\"**: Saves partial record. Run again if needed.\n\nCheck `.claude/pms/episodic/` for saved records."
              },
              {
                "name": "/extract",
                "description": "Extract semantic patterns from episodic records (without generating rules)",
                "path": "plugins/claude-pms/commands/extract.md",
                "frontmatter": {
                  "name": "pms:extract",
                  "description": "Extract semantic patterns from episodic records (without generating rules)"
                },
                "content": "# Semantic Pattern Extraction\n\nAnalyze episodic records to detect patterns without generating rules yet.\n\n## What This Does\n\n1. Load all episodic records from `.claude/pms/episodic/`\n2. Detect recurring patterns across sessions\n3. Categorize patterns (preferences, code patterns, anti-patterns)\n4. Assess strength (emerging/strong/critical)\n5. Save to `.claude/pms/semantic/`\n\n**Does NOT generate rules** - use `/pms:synthesize` afterward if desired.\n\n## When to Use\n\n- **Preview patterns** before rule generation\n- **Verify pattern detection** is working correctly\n- **Inspect evidence** for detected patterns\n- **Separate extraction from synthesis** (manual control)\n\n## Usage\n\n```bash\npython \"$CLAUDE_PLUGIN_ROOT/scripts/extract.py\" \\\n  --project-path \"$CLAUDE_PROJECT_DIR\"\n```\n\n## Expected Output\n\n```\nAnalyzing 25 episodic records...\nDetected 12 patterns\n  - 4 preferences\n  - 6 code patterns\n  - 2 anti-patterns\n\nSemantic knowledge saved to .claude/pms/semantic/\n```\n\n## Review Patterns\n\nAfter extraction, inspect the detected patterns:\n\n```bash\n# View all patterns\ncat \"$CLAUDE_PROJECT_DIR/.claude/pms/semantic/patterns.json\" | jq .\n\n# View just preferences\ncat \"$CLAUDE_PROJECT_DIR/.claude/pms/semantic/preferences.json\" | jq .\n\n# Count strong patterns (candidates for rules)\ncat \"$CLAUDE_PROJECT_DIR/.claude/pms/semantic/patterns.json\" | \\\n  jq '[.patterns[] | select(.strength == \"strong\" or .strength == \"critical\")] | length'\n```\n\n## Pattern Structure\n\nEach pattern includes:\n```json\n{\n  \"pattern_id\": \"pref_123456\",\n  \"description\": \"Always run tests before commits\",\n  \"category\": \"preference\",\n  \"strength\": \"critical\",\n  \"occurrences\": 8,\n  \"evidence\": [\"session-1\", \"session-2\", ...],\n  \"detected_at\": \"2025-12-31T02:00:00Z\"\n}\n```\n\n## Next Steps\n\n**If strong patterns detected:**\n```\nRun /pms:synthesize to generate rules from strong patterns\n```\n\n**If only emerging patterns:**\n```\nContinue working - patterns need 3+ occurrences to become strong\n```\n\n## Troubleshooting\n\n**\"Insufficient sessions (X/10)\"**: Need at least 10 episodic records.\n\n**\"No patterns found\"**: Sessions lack sufficient recurrence. Continue accumulating data.\n\n**\"Pattern detection timeout\"**: Falls back to frequency-only detection.\n\nUse `/pms:status` to check episodic record count."
              },
              {
                "name": "/reflect",
                "description": "Run full PMS pipeline - extract patterns and generate rules from episodic memory",
                "path": "plugins/claude-pms/commands/reflect.md",
                "frontmatter": {
                  "name": "pms:reflect",
                  "description": "Run full PMS pipeline - extract patterns and generate rules from episodic memory"
                },
                "content": "# PMS Reflection - Full Pipeline\n\nAnalyze accumulated episodic records, extract patterns, and generate procedural rules.\n\n## What This Does\n\n**Full pipeline execution:**\n\n1. **Semantic Extraction** (`scripts/extract.py`):\n   - Load all episodic records from `.claude/pms/episodic/`\n   - Detect recurring patterns (preferences, code patterns, anti-patterns)\n   - Categorize by strength (emerging/strong/critical)\n   - Save to `.claude/pms/semantic/`\n\n2. **Procedural Synthesis** (`scripts/synthesize.py`):\n   - Filter strong patterns (≥3 occurrences)\n   - Generate actionable rules\n   - User approval workflow\n   - Save to `.claude/rules/pms/`\n\n## Prerequisites\n\n- At least 10 episodic records (default threshold)\n- Check with `/pms:status` first\n\n## Usage\n\nRun the full reflection pipeline:\n\n```bash\n# Step 1: Semantic Extraction\necho \"Running semantic extraction...\"\npython \"$CLAUDE_PLUGIN_ROOT/scripts/extract.py\" \\\n  --project-path \"$CLAUDE_PROJECT_DIR\"\n\n# Step 2: Procedural Synthesis (if patterns detected)\nif [ $? -eq 0 ]; then\n  echo \"\"\n  echo \"Running procedural synthesis...\"\n  python \"$CLAUDE_PLUGIN_ROOT/scripts/synthesize.py\" \\\n    --project-path \"$CLAUDE_PROJECT_DIR\"\n\n  echo \"\"\n  echo \"✓ PMS reflection complete!\"\n  echo \"✓ Restart Claude Code session to load new rules\"\nelse\n  echo \"Semantic extraction completed with no actionable patterns.\"\n  echo \"Continue working to accumulate more data.\"\nfi\n```\n\n## Expected Output\n\n```\nRunning semantic extraction...\nAnalyzing 25 episodic records...\nDetected 12 patterns\n  - 4 preferences\n  - 6 code patterns\n  - 2 anti-patterns\nSemantic knowledge saved to .claude/pms/semantic/\n\nRunning procedural synthesis...\nFound 8 strong patterns for rule generation\n  - 4 user preferences\n  - 3 code patterns\n  - 1 anti-patterns\nGenerated: user-preferences.md\nGenerated: code-patterns.md\nGenerated: anti-patterns.md\n\n✓ Generated 3 rule files in .claude/rules/pms/\n✓ Restart Claude Code session to load new rules\n```\n\n## User Approval\n\nThe synthesis step includes approval workflow (unless `auto_synthesize: true`):\n\n1. Proposed rules displayed\n2. Review patterns and evidence\n3. Approve all / approve selected / reject all\n4. Only approved rules are saved\n\n## What Happens Next\n\n**After successful reflection:**\n1. Rule files generated in `.claude/rules/pms/`\n2. Restart Claude Code: `exit` then `claude` (or `cc`)\n3. New rules activate automatically\n\n**If insufficient data:**\n- Continue working to accumulate more sessions\n- Check thresholds in `.claude/pms.local.md`\n\n## Troubleshooting\n\n**\"Insufficient sessions (X/10)\"**: Need more episodic records. Use `/pms:encode` or wait for auto-triggers.\n\n**\"No strong patterns found\"**: Patterns exist but none meet threshold (≥3 occurrences). Continue working.\n\n**\"Permission denied\"**: Check file permissions on `.claude/rules/pms/` directory.\n\nRun `/pms:status` to check current memory state."
              },
              {
                "name": "/status",
                "description": "Display current PMS memory state and configuration",
                "path": "plugins/claude-pms/commands/status.md",
                "frontmatter": {
                  "name": "pms:status",
                  "description": "Display current PMS memory state and configuration"
                },
                "content": "# PMS Memory Status\n\nView the current state of procedural memory across all tiers.\n\n## What This Shows\n\n1. **Episodic Memory**: Session records captured\n2. **Semantic Memory**: Patterns detected and categorized\n3. **Procedural Memory**: Rules generated and active\n4. **Configuration**: Current thresholds and triggers\n5. **Timeline**: Last encoding, extraction, synthesis timestamps\n\n## Usage\n\n```bash\n#!/bin/bash\n\n# Configuration\nPROJECT_DIR=\"${CLAUDE_PROJECT_DIR}\"\nPMS_DIR=\"$PROJECT_DIR/.claude/pms\"\n\necho \"=== Claude PMS - Procedural Memory System ===\"\necho \"\"\n\n# 1. Episodic Memory Status\necho \"📝 Episodic Memory (Sessions Recorded)\"\necho \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n\nEPISODIC_DIR=\"$PMS_DIR/episodic\"\nif [ -d \"$EPISODIC_DIR\" ]; then\n  SESSION_COUNT=$(find \"$EPISODIC_DIR\" -name \"sessions-*.json\" -exec jq '.sessions | length' {} + | awk '{s+=$1} END {print s}')\n  MONTHLY_FILES=$(find \"$EPISODIC_DIR\" -name \"sessions-*.json\" | wc -l)\n\n  echo \"Total Sessions: ${SESSION_COUNT:-0}\"\n  echo \"Monthly Files: ${MONTHLY_FILES:-0}\"\n\n  # Last encoded\n  if [ -f \"$EPISODIC_DIR/index.json\" ]; then\n    LAST_SESSION=$(jq -r 'to_entries | max_by(.key) | .key' \"$EPISODIC_DIR/index.json\" 2>/dev/null || echo \"Unknown\")\n    echo \"Last Encoded: $LAST_SESSION\"\n  fi\nelse\n  echo \"Status: Not initialized\"\nfi\n\necho \"\"\n\n# 2. Semantic Memory Status\necho \"🧠 Semantic Memory (Patterns Detected)\"\necho \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n\nSEMANTIC_DIR=\"$PMS_DIR/semantic\"\nif [ -f \"$SEMANTIC_DIR/patterns.json\" ]; then\n  TOTAL_PATTERNS=$(jq -r '.count // 0' \"$SEMANTIC_DIR/patterns.json\")\n  EMERGING=$(jq '[.patterns[] | select(.strength == \"emerging\")] | length' \"$SEMANTIC_DIR/patterns.json\")\n  STRONG=$(jq '[.patterns[] | select(.strength == \"strong\")] | length' \"$SEMANTIC_DIR/patterns.json\")\n  CRITICAL=$(jq '[.patterns[] | select(.strength == \"critical\")] | length' \"$SEMANTIC_DIR/patterns.json\")\n\n  echo \"Total Patterns: $TOTAL_PATTERNS\"\n  echo \"  • Emerging (2+ occurrences): $EMERGING\"\n  echo \"  • Strong (3+ occurrences): $STRONG\"\n  echo \"  • Critical (5+ occurrences): $CRITICAL\"\n\n  # Breakdown by category\n  PREFERENCES=$(jq -r '.count // 0' \"$SEMANTIC_DIR/preferences.json\" 2>/dev/null || echo \"0\")\n  CODE_PATTERNS=$(jq -r '.count // 0' \"$SEMANTIC_DIR/code-patterns.json\" 2>/dev/null || echo \"0\")\n  ANTI_PATTERNS=$(jq -r '.count // 0' \"$SEMANTIC_DIR/anti-patterns.json\" 2>/dev/null || echo \"0\")\n\n  echo \"\"\n  echo \"By Category:\"\n  echo \"  • User Preferences: $PREFERENCES\"\n  echo \"  • Code Patterns: $CODE_PATTERNS\"\n  echo \"  • Anti-Patterns: $ANTI_PATTERNS\"\n\n  LAST_EXTRACTION=$(jq -r '.last_updated // \"Unknown\"' \"$SEMANTIC_DIR/patterns.json\")\n  echo \"\"\n  echo \"Last Extraction: $LAST_EXTRACTION\"\nelse\n  echo \"Status: Not extracted\"\n  echo \"Run: /pms:extract\"\nfi\n\necho \"\"\n\n# 3. Procedural Memory Status\necho \"⚙️  Procedural Memory (Active Rules)\"\necho \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n\nRULES_DIR=\"$PROJECT_DIR/.claude/rules/pms\"\nPROCEDURAL_METADATA=\"$PMS_DIR/procedural/rules-metadata.json\"\n\nif [ -d \"$RULES_DIR\" ] && [ \"$(ls -A \"$RULES_DIR\" 2>/dev/null)\" ]; then\n  RULE_FILES=$(ls \"$RULES_DIR\"/*.md 2>/dev/null | wc -l)\n  echo \"Rule Files: $RULE_FILES\"\n\n  # List files\n  if [ $RULE_FILES -gt 0 ]; then\n    echo \"Files:\"\n    ls \"$RULES_DIR\"/*.md 2>/dev/null | while read file; do\n      basename \"$file\"\n    done | sed 's/^/  • /'\n  fi\n\n  # Last synthesis\n  if [ -f \"$PROCEDURAL_METADATA\" ]; then\n    LAST_SYNTHESIS=$(jq -r '.last_synthesis // \"Unknown\"' \"$PROCEDURAL_METADATA\")\n    PATTERN_COUNT=$(jq -r '.pattern_count // 0' \"$PROCEDURAL_METADATA\")\n    echo \"\"\n    echo \"Last Synthesis: $LAST_SYNTHESIS\"\n    echo \"Patterns Converted: $PATTERN_COUNT\"\n  fi\nelse\n  echo \"Status: No rules generated\"\n  echo \"Run: /pms:synthesize\"\nfi\n\necho \"\"\n\n# 4. Configuration Summary\necho \"⚙️  Configuration\"\necho \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n\nCONFIG_FILE=\"$PROJECT_DIR/.claude/pms.local.md\"\nif [ -f \"$CONFIG_FILE\" ]; then\n  # Parse YAML frontmatter (basic extraction)\n  TRIGGER_PRECOMPACT=$(grep -A 20 \"^triggers:\" \"$CONFIG_FILE\" | grep \"precompact:\" | awk '{print $2}' || echo \"true\")\n  CONTINUOUS_MODE=$(grep -A 20 \"^processing:\" \"$CONFIG_FILE\" | grep \"continuous_mode:\" | awk '{print $2}' || echo \"true\")\n  MIN_SESSIONS=$(grep -A 20 \"^thresholds:\" \"$CONFIG_FILE\" | grep \"min_sessions:\" | awk '{print $2}' || echo \"10\")\n  STRONG_THRESHOLD=$(grep -A 20 \"^thresholds:\" \"$CONFIG_FILE\" | grep \"strong_pattern:\" | awk '{print $2}' || echo \"3\")\n\n  echo \"Triggers:\"\n  echo \"  • PreCompact: $TRIGGER_PRECOMPACT\"\n  echo \"\"\n  echo \"Processing:\"\n  echo \"  • Continuous Mode: $CONTINUOUS_MODE\"\n  echo \"\"\n  echo \"Thresholds:\"\n  echo \"  • Min Sessions: $MIN_SESSIONS\"\n  echo \"  • Strong Pattern: $STRONG_THRESHOLD occurrences\"\nelse\n  echo \"Status: Using defaults\"\n  echo \"Create: .claude/pms.local.md\"\nfi\n\necho \"\"\necho \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\necho \"\"\n\n# Readiness check\nif [ \"${SESSION_COUNT:-0}\" -ge \"${MIN_SESSIONS:-10}\" ]; then\n  if [ \"$STRONG\" -gt 0 ] 2>/dev/null; then\n    echo \"✓ Ready for rule generation!\"\n    echo \"  Run: /pms:synthesize\"\n  else\n    echo \"⚠ Data sufficient but no strong patterns yet\"\n    echo \"  Continue working to strengthen patterns\"\n  fi\nelif [ \"${SESSION_COUNT:-0}\" -gt 0 ]; then\n  NEEDED=$((${MIN_SESSIONS:-10} - ${SESSION_COUNT:-0}))\n  echo \"⏳ Need $NEEDED more sessions before extraction\"\n  echo \"  Current: ${SESSION_COUNT:-0} / ${MIN_SESSIONS:-10}\"\nelse\n  echo \"👋 No data yet - system will capture sessions automatically\"\n  echo \"  Or run: /pms:encode\"\nfi\n\necho \"\"\n```\n\n## Example Output\n\n```\n=== Claude PMS - Procedural Memory System ===\n\n📝 Episodic Memory (Sessions Recorded)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nTotal Sessions: 25\nMonthly Files: 2\nLast Encoded: session-abc-123-def-456\n\n🧠 Semantic Memory (Patterns Detected)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nTotal Patterns: 12\n  • Emerging (2+ occurrences): 4\n  • Strong (3+ occurrences): 6\n  • Critical (5+ occurrences): 2\n\nBy Category:\n  • User Preferences: 4\n  • Code Patterns: 6\n  • Anti-Patterns: 2\n\nLast Extraction: 2025-12-31T01:30:00Z\n\n⚙️  Procedural Memory (Active Rules)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nRule Files: 3\nFiles:\n  • user-preferences.md\n  • code-patterns.md\n  • anti-patterns.md\n\nLast Synthesis: 2025-12-31T02:00:00Z\nPatterns Converted: 8\n\n⚙️  Configuration\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nTriggers:\n  • PreCompact: true\n\nProcessing:\n  • Continuous Mode: true\n\nThresholds:\n  • Min Sessions: 10\n  • Strong Pattern: 3 occurrences\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n✓ Ready for rule generation!\n  Run: /pms:synthesize\n```\n\n## Troubleshooting\n\n**\"Not initialized\"**: No `.claude/pms/` directory. Run `/pms:encode` to initialize.\n\n**\"jq: command not found\"**: Install jq for JSON parsing: `brew install jq` (macOS) or equivalent.\n\n**Inaccurate counts**: Check for corrupted JSON files in `.claude/pms/`."
              },
              {
                "name": "/synthesize",
                "description": "Generate procedural rules from existing semantic patterns",
                "path": "plugins/claude-pms/commands/synthesize.md",
                "frontmatter": {
                  "name": "pms:synthesize",
                  "description": "Generate procedural rules from existing semantic patterns"
                },
                "content": "# Procedural Rule Synthesis\n\nConvert confirmed semantic patterns into actionable Claude Code rules.\n\n## What This Does\n\n1. Load semantic knowledge from `.claude/pms/semantic/patterns.json`\n2. Filter strong patterns (strength = \"strong\" or \"critical\")\n3. Generate markdown rule files\n4. User approval workflow (unless `auto_synthesize: true`)\n5. Save to `.claude/rules/pms/`\n\n**Requires semantic extraction first** - run `/pms:extract` if needed.\n\n## Prerequisites\n\n- Semantic patterns exist (`.claude/pms/semantic/patterns.json`)\n- At least one strong pattern (≥3 occurrences)\n\n## Usage\n\n```bash\npython \"$CLAUDE_PLUGIN_ROOT/scripts/synthesize.py\" \\\n  --project-path \"$CLAUDE_PROJECT_DIR\"\n```\n\n## User Approval Workflow\n\n**Unless `auto_synthesize: true` in config:**\n\n1. **Review proposed rules**:\n   ```\n   === Proposed Rules ===\n\n   user-preferences.md:\n   # User Preferences\n\n   **Always run tests before committing code**\n   - Observed 8 times (critical pattern)\n   - Evidence: session-1, session-2, session-3...\n   ```\n\n2. **Approve or reject**:\n   - Approve all → Rules generated\n   - Reject all → Stored in metadata (won't re-propose)\n   - Select specific rules → Only approved ones saved\n\n3. **Rules saved to `.claude/rules/pms/`**\n\n## Expected Output\n\n```\nFound 8 strong patterns for rule generation\n  - 4 user preferences\n  - 3 code patterns\n  - 1 anti-patterns\n\nGenerated: user-preferences.md\nGenerated: code-patterns.md\nGenerated: anti-patterns.md\n\n✓ Generated 3 rule files in .claude/rules/pms/\n✓ Restart Claude Code session to load new rules\n```\n\n## Rule File Categories\n\n**user-preferences.md**:\n- Testing requirements\n- Commit practices\n- Code review expectations\n- Documentation standards\n\n**code-patterns.md**:\n- Language/framework conventions\n- Testing strategies\n- Error handling patterns\n- Architectural patterns\n\n**anti-patterns.md**:\n- Common mistakes to avoid\n- Discouraged practices\n- Known bug sources\n\n## Activate New Rules\n\n**After synthesis succeeds:**\n\n1. Exit Claude Code: `exit` or Ctrl+D\n2. Restart: `claude` or `cc`\n3. Rules load automatically from `.claude/rules/pms/`\n\n## Troubleshooting\n\n**\"No semantic knowledge found\"**: Run `/pms:extract` first.\n\n**\"No strong patterns found\"**: All patterns are emerging (< 3 occurrences). Continue working.\n\n**\"Permission denied\"**: Check write permissions on `.claude/rules/pms/`\n\n**\"Auto-synthesize enabled but still prompted\"**: Command overrides config - use hook triggers for auto mode.\n\n## Auto-Approve Mode\n\nSkip approval prompts (use cautiously):\n\n```bash\npython \"$CLAUDE_PLUGIN_ROOT/scripts/synthesize.py\" \\\n  --project-path \"$CLAUDE_PROJECT_DIR\" \\\n  --auto-approve\n```\n\nOr enable in config:\n```yaml\nprocessing:\n  auto_synthesize: true\n```\n\n## Review Generated Rules\n\n```bash\n# View user preferences\ncat \"$CLAUDE_PROJECT_DIR/.claude/rules/pms/user-preferences.md\"\n\n# View all rule files\nls -la \"$CLAUDE_PROJECT_DIR/.claude/rules/pms/\"\n```"
              }
            ],
            "skills": []
          },
          {
            "name": "docs-reader",
            "description": "Documentation Reader for Axivo Claude Collaboration Platform, providing access through components, protocols, and competencies",
            "source": "./plugins/docs-reader",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add jcmrs/jcmrs-plugins",
              "/plugin install docs-reader@jcmrs-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-04T21:15:59Z",
              "created_at": "2025-12-21T13:19:03Z",
              "license": null
            },
            "commands": [
              {
                "name": "/docs",
                "description": "Search official Claude collaboration platform documentation",
                "path": "plugins/docs-reader/commands/docs.md",
                "frontmatter": {
                  "name": "jcmrs:docs",
                  "argument-hint": "[search query]",
                  "description": "Search official Claude collaboration platform documentation",
                  "allowed-tools": [
                    "WebFetch",
                    "Read",
                    "Skill"
                  ]
                },
                "content": "# Documentation Search\n\nSearch and retrieve content from official collaboration platform documentation.\n\n## Reference Documentation\n\nBefore starting, load the documentation-query skill:\n\n1. **Load the documentation-query skill** which provides the methodology\n2. The skill guides you through Understand → Locate → Present workflow\n\n## Establish Query\n\nIf `$ARGUMENTS` is provided, use that as the search query. Otherwise, ask:\n\n\"What would you like to search in the documentation?\"\n\nWait for the user's response before continuing.\n\n## Query Workflow\n\nFollow the documentation-query skill methodology:\n\n1. **Understand** - Clarify what information is needed\n2. **Locate** - Identify which documentation source has the answer (Components, Protocols, or Competencies)\n3. **Present** - Fetch and present the relevant content with architectural context\n\n## Documentation Architecture\n\n**Wiki** (Platform architecture and reference):\n- Base: `https://raw.githubusercontent.com/axivo/website/main/claude/content/wiki/`\n- **Components**: Plugins, Documentation, Instructions, Memory\n- **Protocols**: Equilibrium, Initialization, Response\n- **Getting Started**: Configuration and setup\n\n**Tutorials** (Practical competency development):\n- Base: `https://raw.githubusercontent.com/axivo/website/main/claude/content/tutorials/`\n- **Core Competencies**: Session structuring, Communication, Continuity, Customization, Measurement\n\n## Query Type Mapping\n\nMap user questions to documentation structure:\n\n- \"Can Claude Code do X?\" → Wiki → Components\n- \"How does the framework work?\" → Wiki → Protocols\n- \"How do I configure X?\" → Wiki → Getting Started\n- \"Show me how to do X\" → Tutorials → Competencies\n\nBegin by understanding what the user wants to find in the documentation."
              }
            ],
            "skills": [
              {
                "name": "documentation-query",
                "description": "Access official collaboration platform documentation organized by platform components, protocols, and core competencies. Use when user asks about platform capabilities, how the framework works, or when Claude Code needs to reference architecture, implementation patterns, or best practices to answer questions accurately.",
                "path": "plugins/docs-reader/skills/documentation-query/SKILL.md",
                "frontmatter": {
                  "name": "documentation-query",
                  "description": "Access official collaboration platform documentation organized by platform components, protocols, and core competencies. Use when user asks about platform capabilities, how the framework works, or when Claude Code needs to reference architecture, implementation patterns, or best practices to answer questions accurately.",
                  "license": "LICENSE",
                  "metadata": {
                    "documentation": "https://axivo.com/claude/",
                    "profile": "DEVELOPER, ENGINEER, RESEARCHER",
                    "project": "Claude Collaboration Platform",
                    "repository": "https://github.com/axivo/claude"
                  }
                },
                "content": "# Documentation Query\n\nSystematic access to official platform documentation through understanding-focused architecture.\n\n## Skill Methodology\n\nDocumentation access through platform architecture understanding. Extends all profiles with structured reference to components, protocols, and competencies.\n\n> [!IMPORTANT]\n> The skill embodies Understand Architecture → Locate Precisely → Present Systematically\n>\n> - Understand platform architecture (Components, Protocols, Competencies)\n> - Locate documentation based on query type\n> - Present information that builds understanding\n\n### Documentation Architecture\n\nThe platform documentation is organized for systematic understanding:\n\n**Wiki** - Platform architecture and reference:\n- **Components** (4 subsystems): Plugins, Documentation, Instructions, Memory\n- **Protocols** (3 operational sequences): Equilibrium, Initialization, Response\n\n**Tutorials** - Practical competency development:\n- **Core Competencies** (5 skills): Session structuring, Communication, Continuity, Customization, Measurement\n\n> [!IMPORTANT]\n> Documentation structure reflects platform architecture - understanding the structure reveals how the platform works.\n\n## Query Type Mapping\n\n### User-Initiated Queries\n\nWhen users ask questions, map to documentation structure:\n\n| User Question | Documentation Source | Specific Section |\n|---------------|---------------------|------------------|\n| \"Can Claude Code do X?\" | Wiki → Components | Plugins, Documentation, Instructions, or Memory |\n| \"How does the framework work?\" | Wiki → Protocols | Equilibrium, Initialization, or Response |\n| \"How do I configure X?\" | Wiki → Getting Started | Configuration section |\n| \"Show me how to do X\" | Tutorials → Competencies | Relevant competency (1-5) |\n| \"What are profiles?\" | Wiki → Components | Memory System |\n| \"How do skills work?\" | Wiki → Components | Plugins System |\n| \"What is the response protocol?\" | Wiki → Protocols | Response Protocol |\n\n### Agent-Initiated Queries\n\nWhen Claude Code needs reference documentation:\n\n| Claude Code Need | Documentation Source | Purpose |\n|------------------|---------------------|---------|\n| Explaining platform capabilities | Wiki → Components | Accurate capability description |\n| Understanding framework behavior | Wiki → Protocols | Correct protocol application |\n| Implementing plugin features | Wiki → Components → Plugins | Pattern reference |\n| Teaching collaboration techniques | Tutorials → Competencies | Best practices |\n| Troubleshooting framework issues | Wiki → Protocols | Diagnostic understanding |\n| Profile customization guidance | Wiki → Components → Memory | Profile system reference |\n\n> [!IMPORTANT]\n> Agent queries are proactive - Claude Code should reference documentation to provide accurate, platform-aligned guidance.\n\n## Understanding Stage\n\nClarify what type of understanding is needed.\n\n### For User Queries\n\nAsk focused questions to map to architecture:\n\n- \"Are you asking what the platform can do?\" → Components\n- \"Are you asking how something works?\" → Protocols\n- \"Are you asking how to do something?\" → Competencies (Tutorials)\n\n### For Agent Queries\n\nDetermine information need:\n\n- Answering \"Can it...?\" → Components (verify capability)\n- Explaining \"How does...?\" → Protocols (explain mechanism)\n- Guiding \"How to...?\" → Competencies (teach technique)\n\n## Location Stage\n\nUse architecture understanding to locate documentation.\n\n### Wiki Structure\n\nConsult [wiki-index.md](./resources/wiki-index.md) for:\n\n**Components Section:**\n- Plugins System\n- Documentation System\n- Instructions System\n- Memory System\n\n**Protocols Section:**\n- Equilibrium Protocol\n- Initialization Protocol\n- Response Protocol\n\n**Getting Started:**\n- Configuration and setup\n\n### Tutorials Structure\n\nConsult [tutorials-index.md](./resources/tutorials-index.md) for:\n\n**Core Competencies:**\n1. Session structuring\n2. Effective communication\n3. Cross-session continuity\n4. Profile customization\n5. Effectiveness measurement\n\n## Presentation Stage\n\nFetch and present with architectural context.\n\n### Building Understanding\n\nWhen presenting documentation:\n1. **Provide architectural context** - \"This is in the Memory System component because...\"\n2. **Show relationships** - \"This protocol uses these components...\"\n3. **Connect to use cases** - \"This helps you accomplish X by...\"\n\n### For Agent Reference\n\nWhen Claude Code queries internally:\n1. **Quick reference** - Extract specific pattern or capability\n2. **Verify accuracy** - Confirm platform behavior before stating it\n3. **Update understanding** - Learn from official docs, not assumptions\n\n## Session Guidelines\n\n### User Documentation Queries\n\n- Ask clarifying questions to understand the need\n- Map to Components, Protocols, or Competencies\n- Present with architectural context\n- Offer related documentation if relevant\n\n### Agent Self-Reference\n\n- Query proactively when uncertain about platform behavior\n- Verify capabilities before claiming them\n- Reference protocols when explaining framework operations\n- Use components documentation for implementation patterns\n\n### DON'T\n\n- Guess at platform capabilities - check Components\n- Explain protocols from memory - fetch actual documentation\n- Assume competency patterns - reference tutorials\n- Mix up component responsibilities"
              }
            ]
          }
        ]
      }
    }
  ]
}