{
  "owner": {
    "id": "EveryInc",
    "display_name": "Every",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/76073155?v=4",
    "url": "https://github.com/EveryInc",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 21,
      "total_skills": 14,
      "total_stars": 4576,
      "total_forks": 386
    }
  },
  "repos": [
    {
      "full_name": "EveryInc/compound-engineering-plugin",
      "url": "https://github.com/EveryInc/compound-engineering-plugin",
      "description": "Official Claude Code compound engineering plugin",
      "homepage": "",
      "signals": {
        "stars": 4576,
        "forks": 386,
        "pushed_at": "2026-01-09T16:07:41Z",
        "created_at": "2025-10-09T19:43:46Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1541
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/deploy-docs.yml",
          "type": "blob",
          "size": 796
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 30
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 11464
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1062
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 1633
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/css",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/css/docs.css",
          "type": "blob",
          "size": 13021
        },
        {
          "path": "docs/css/style.css",
          "type": "blob",
          "size": 63963
        },
        {
          "path": "docs/index.html",
          "type": "blob",
          "size": 52534
        },
        {
          "path": "docs/js",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/js/main.js",
          "type": "blob",
          "size": 6410
        },
        {
          "path": "docs/pages",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/pages/agents.html",
          "type": "blob",
          "size": 34067
        },
        {
          "path": "docs/pages/changelog.html",
          "type": "blob",
          "size": 20531
        },
        {
          "path": "docs/pages/commands.html",
          "type": "blob",
          "size": 24745
        },
        {
          "path": "docs/pages/getting-started.html",
          "type": "blob",
          "size": 22033
        },
        {
          "path": "docs/pages/mcp-servers.html",
          "type": "blob",
          "size": 14578
        },
        {
          "path": "docs/pages/skills.html",
          "type": "blob",
          "size": 28493
        },
        {
          "path": "docs/solutions",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/solutions/plugin-versioning-requirements.md",
          "type": "blob",
          "size": 2582
        },
        {
          "path": "plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "plans/grow-your-own-garden-plugin-architecture.md",
          "type": "blob",
          "size": 3387
        },
        {
          "path": "plans/landing-page-launchkit-refresh.md",
          "type": "blob",
          "size": 8839
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 310
        },
        {
          "path": "plugins/coding-tutor/README.md",
          "type": "blob",
          "size": 1810
        },
        {
          "path": "plugins/coding-tutor/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/commands/quiz-me.md",
          "type": "blob",
          "size": 37
        },
        {
          "path": "plugins/coding-tutor/commands/sync-tutorials.md",
          "type": "blob",
          "size": 910
        },
        {
          "path": "plugins/coding-tutor/commands/teach-me.md",
          "type": "blob",
          "size": 48
        },
        {
          "path": "plugins/coding-tutor/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor/SKILL.md",
          "type": "blob",
          "size": 12017
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor/scripts/create_tutorial.py",
          "type": "blob",
          "size": 6392
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor/scripts/index_tutorials.py",
          "type": "blob",
          "size": 6398
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor/scripts/quiz_priority.py",
          "type": "blob",
          "size": 5536
        },
        {
          "path": "plugins/coding-tutor/skills/coding-tutor/scripts/setup_tutorials.py",
          "type": "blob",
          "size": 3660
        },
        {
          "path": "plugins/compound-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 1036
        },
        {
          "path": "plugins/compound-engineering/CHANGELOG.md",
          "type": "blob",
          "size": 11811
        },
        {
          "path": "plugins/compound-engineering/CLAUDE.md",
          "type": "blob",
          "size": 3252
        },
        {
          "path": "plugins/compound-engineering/LICENSE",
          "type": "blob",
          "size": 1072
        },
        {
          "path": "plugins/compound-engineering/README.md",
          "type": "blob",
          "size": 7349
        },
        {
          "path": "plugins/compound-engineering/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/agents/design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/agents/design/design-implementation-reviewer.md",
          "type": "blob",
          "size": 5218
        },
        {
          "path": "plugins/compound-engineering/agents/design/design-iterator.md",
          "type": "blob",
          "size": 10946
        },
        {
          "path": "plugins/compound-engineering/agents/design/figma-design-sync.md",
          "type": "blob",
          "size": 9837
        },
        {
          "path": "plugins/compound-engineering/agents/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/agents/docs/ankane-readme-writer.md",
          "type": "blob",
          "size": 3689
        },
        {
          "path": "plugins/compound-engineering/agents/research",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/agents/research/best-practices-researcher.md",
          "type": "blob",
          "size": 4611
        },
        {
          "path": "plugins/compound-engineering/agents/research/framework-docs-researcher.md",
          "type": "blob",
          "size": 5300
        },
        {
          "path": "plugins/compound-engineering/agents/research/git-history-analyzer.md",
          "type": "blob",
          "size": 4034
        },
        {
          "path": "plugins/compound-engineering/agents/research/repo-research-analyst.md",
          "type": "blob",
          "size": 6080
        },
        {
          "path": "plugins/compound-engineering/agents/review",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/agents/review/agent-native-reviewer.md",
          "type": "blob",
          "size": 8571
        },
        {
          "path": "plugins/compound-engineering/agents/review/architecture-strategist.md",
          "type": "blob",
          "size": 4652
        },
        {
          "path": "plugins/compound-engineering/agents/review/code-simplicity-reviewer.md",
          "type": "blob",
          "size": 4159
        },
        {
          "path": "plugins/compound-engineering/agents/review/data-integrity-guardian.md",
          "type": "blob",
          "size": 4308
        },
        {
          "path": "plugins/compound-engineering/agents/review/data-migration-expert.md",
          "type": "blob",
          "size": 5179
        },
        {
          "path": "plugins/compound-engineering/agents/review/deployment-verification-agent.md",
          "type": "blob",
          "size": 5845
        },
        {
          "path": "plugins/compound-engineering/agents/review/dhh-rails-reviewer.md",
          "type": "blob",
          "size": 4402
        },
        {
          "path": "plugins/compound-engineering/agents/review/julik-frontend-races-reviewer.md",
          "type": "blob",
          "size": 11360
        },
        {
          "path": "plugins/compound-engineering/agents/review/kieran-python-reviewer.md",
          "type": "blob",
          "size": 5831
        },
        {
          "path": "plugins/compound-engineering/agents/review/kieran-rails-reviewer.md",
          "type": "blob",
          "size": 5252
        },
        {
          "path": "plugins/compound-engineering/agents/review/kieran-typescript-reviewer.md",
          "type": "blob",
          "size": 5719
        },
        {
          "path": "plugins/compound-engineering/agents/review/pattern-recognition-specialist.md",
          "type": "blob",
          "size": 4607
        },
        {
          "path": "plugins/compound-engineering/agents/review/performance-oracle.md",
          "type": "blob",
          "size": 6001
        },
        {
          "path": "plugins/compound-engineering/agents/review/security-sentinel.md",
          "type": "blob",
          "size": 5825
        },
        {
          "path": "plugins/compound-engineering/agents/workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/agents/workflow/bug-reproduction-validator.md",
          "type": "blob",
          "size": 4974
        },
        {
          "path": "plugins/compound-engineering/agents/workflow/every-style-editor.md",
          "type": "blob",
          "size": 3807
        },
        {
          "path": "plugins/compound-engineering/agents/workflow/lint.md",
          "type": "blob",
          "size": 796
        },
        {
          "path": "plugins/compound-engineering/agents/workflow/pr-comment-resolver.md",
          "type": "blob",
          "size": 3976
        },
        {
          "path": "plugins/compound-engineering/agents/workflow/spec-flow-analyzer.md",
          "type": "blob",
          "size": 6903
        },
        {
          "path": "plugins/compound-engineering/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/commands/agent-native-audit.md",
          "type": "blob",
          "size": 8206
        },
        {
          "path": "plugins/compound-engineering/commands/changelog.md",
          "type": "blob",
          "size": 4671
        },
        {
          "path": "plugins/compound-engineering/commands/create-agent-skill.md",
          "type": "blob",
          "size": 280
        },
        {
          "path": "plugins/compound-engineering/commands/deepen-plan.md",
          "type": "blob",
          "size": 17953
        },
        {
          "path": "plugins/compound-engineering/commands/deploy-docs.md",
          "type": "blob",
          "size": 2778
        },
        {
          "path": "plugins/compound-engineering/commands/feature-video.md",
          "type": "blob",
          "size": 9227
        },
        {
          "path": "plugins/compound-engineering/commands/generate_command.md",
          "type": "blob",
          "size": 4091
        },
        {
          "path": "plugins/compound-engineering/commands/heal-skill.md",
          "type": "blob",
          "size": 3966
        },
        {
          "path": "plugins/compound-engineering/commands/plan_review.md",
          "type": "blob",
          "size": 271
        },
        {
          "path": "plugins/compound-engineering/commands/playwright-test.md",
          "type": "blob",
          "size": 5491
        },
        {
          "path": "plugins/compound-engineering/commands/release-docs.md",
          "type": "blob",
          "size": 6111
        },
        {
          "path": "plugins/compound-engineering/commands/report-bug.md",
          "type": "blob",
          "size": 3882
        },
        {
          "path": "plugins/compound-engineering/commands/reproduce-bug.md",
          "type": "blob",
          "size": 2995
        },
        {
          "path": "plugins/compound-engineering/commands/resolve_parallel.md",
          "type": "blob",
          "size": 1208
        },
        {
          "path": "plugins/compound-engineering/commands/resolve_pr_parallel.md",
          "type": "blob",
          "size": 1236
        },
        {
          "path": "plugins/compound-engineering/commands/resolve_todo_parallel.md",
          "type": "blob",
          "size": 1295
        },
        {
          "path": "plugins/compound-engineering/commands/triage.md",
          "type": "blob",
          "size": 7776
        },
        {
          "path": "plugins/compound-engineering/commands/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/commands/workflows/compound.md",
          "type": "blob",
          "size": 7271
        },
        {
          "path": "plugins/compound-engineering/commands/workflows/plan.md",
          "type": "blob",
          "size": 11864
        },
        {
          "path": "plugins/compound-engineering/commands/workflows/review.md",
          "type": "blob",
          "size": 16340
        },
        {
          "path": "plugins/compound-engineering/commands/workflows/work.md",
          "type": "blob",
          "size": 9138
        },
        {
          "path": "plugins/compound-engineering/commands/xcode-test.md",
          "type": "blob",
          "size": 6612
        },
        {
          "path": "plugins/compound-engineering/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/SKILL.md",
          "type": "blob",
          "size": 23253
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/action-parity-discipline.md",
          "type": "blob",
          "size": 11128
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/agent-execution-patterns.md",
          "type": "blob",
          "size": 13317
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/agent-native-testing.md",
          "type": "blob",
          "size": 16749
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/architecture-patterns.md",
          "type": "blob",
          "size": 17241
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/dynamic-context-injection.md",
          "type": "blob",
          "size": 9612
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/files-universal-interface.md",
          "type": "blob",
          "size": 10092
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/from-primitives-to-domain-tools.md",
          "type": "blob",
          "size": 11788
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/mcp-tool-design.md",
          "type": "blob",
          "size": 15658
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/mobile-patterns.md",
          "type": "blob",
          "size": 25629
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/product-implications.md",
          "type": "blob",
          "size": 12976
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/refactoring-to-prompt-native.md",
          "type": "blob",
          "size": 8560
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/self-modification.md",
          "type": "blob",
          "size": 7866
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/shared-workspace-architecture.md",
          "type": "blob",
          "size": 20874
        },
        {
          "path": "plugins/compound-engineering/skills/agent-native-architecture/references/system-prompt-design.md",
          "type": "blob",
          "size": 6522
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/SKILL.md",
          "type": "blob",
          "size": 4867
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/references/database-adapters.md",
          "type": "blob",
          "size": 4348
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/references/module-organization.md",
          "type": "blob",
          "size": 2250
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/references/rails-integration.md",
          "type": "blob",
          "size": 3792
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/references/resources.md",
          "type": "blob",
          "size": 5382
        },
        {
          "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/references/testing-patterns.md",
          "type": "blob",
          "size": 4766
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs/SKILL.md",
          "type": "blob",
          "size": 14629
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs/assets/critical-pattern-template.md",
          "type": "blob",
          "size": 880
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs/assets/resolution-template.md",
          "type": "blob",
          "size": 3165
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs/references/yaml-schema.md",
          "type": "blob",
          "size": 3102
        },
        {
          "path": "plugins/compound-engineering/skills/compound-docs/schema.yaml",
          "type": "blob",
          "size": 6902
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/SKILL.md",
          "type": "blob",
          "size": 6790
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/api-security.md",
          "type": "blob",
          "size": 6193
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/be-clear-and-direct.md",
          "type": "blob",
          "size": 13030
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/best-practices.md",
          "type": "blob",
          "size": 9282
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/common-patterns.md",
          "type": "blob",
          "size": 14431
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/core-principles.md",
          "type": "blob",
          "size": 12695
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/executable-code.md",
          "type": "blob",
          "size": 4378
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/iteration-and-testing.md",
          "type": "blob",
          "size": 13496
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/official-spec.md",
          "type": "blob",
          "size": 5499
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/recommended-structure.md",
          "type": "blob",
          "size": 4006
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/skill-structure.md",
          "type": "blob",
          "size": 11177
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/using-scripts.md",
          "type": "blob",
          "size": 3023
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/using-templates.md",
          "type": "blob",
          "size": 2924
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/references/workflows-and-validation.md",
          "type": "blob",
          "size": 11845
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/templates/router-skill.md",
          "type": "blob",
          "size": 1494
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/templates/simple-skill.md",
          "type": "blob",
          "size": 636
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/add-reference.md",
          "type": "blob",
          "size": 2272
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/add-script.md",
          "type": "blob",
          "size": 2155
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/add-template.md",
          "type": "blob",
          "size": 1926
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/add-workflow.md",
          "type": "blob",
          "size": 2921
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/audit-skill.md",
          "type": "blob",
          "size": 3559
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/create-domain-expertise-skill.md",
          "type": "blob",
          "size": 18098
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/create-new-skill.md",
          "type": "blob",
          "size": 5673
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/get-guidance.md",
          "type": "blob",
          "size": 3098
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/upgrade-to-router.md",
          "type": "blob",
          "size": 3785
        },
        {
          "path": "plugins/compound-engineering/skills/create-agent-skills/workflows/verify-skill.md",
          "type": "blob",
          "size": 5194
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/SKILL.md",
          "type": "blob",
          "size": 6858
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/references/architecture.md",
          "type": "blob",
          "size": 13122
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/references/controllers.md",
          "type": "blob",
          "size": 6395
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/references/frontend.md",
          "type": "blob",
          "size": 10691
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/references/gems.md",
          "type": "blob",
          "size": 5696
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/references/models.md",
          "type": "blob",
          "size": 7504
        },
        {
          "path": "plugins/compound-engineering/skills/dhh-rails-style/references/testing.md",
          "type": "blob",
          "size": 7061
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/SKILL.md",
          "type": "blob",
          "size": 15563
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/assets/config-template.rb",
          "type": "blob",
          "size": 10321
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/assets/module-template.rb",
          "type": "blob",
          "size": 7664
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/assets/signature-template.rb",
          "type": "blob",
          "size": 4838
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/references/core-concepts.md",
          "type": "blob",
          "size": 6301
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/references/optimization.md",
          "type": "blob",
          "size": 14272
        },
        {
          "path": "plugins/compound-engineering/skills/dspy-ruby/references/providers.md",
          "type": "blob",
          "size": 8229
        },
        {
          "path": "plugins/compound-engineering/skills/every-style-editor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/every-style-editor/SKILL.md",
          "type": "blob",
          "size": 4885
        },
        {
          "path": "plugins/compound-engineering/skills/every-style-editor/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/every-style-editor/references/EVERY_WRITE_STYLE.md",
          "type": "blob",
          "size": 29236
        },
        {
          "path": "plugins/compound-engineering/skills/file-todos",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/file-todos/SKILL.md",
          "type": "blob",
          "size": 7623
        },
        {
          "path": "plugins/compound-engineering/skills/file-todos/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/file-todos/assets/todo-template.md",
          "type": "blob",
          "size": 3735
        },
        {
          "path": "plugins/compound-engineering/skills/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/frontend-design/SKILL.md",
          "type": "blob",
          "size": 4304
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/SKILL.md",
          "type": "blob",
          "size": 6490
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/requirements.txt",
          "type": "blob",
          "size": 35
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/scripts/compose_images.py",
          "type": "blob",
          "size": 4723
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/scripts/edit_image.py",
          "type": "blob",
          "size": 4173
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/scripts/gemini_images.py",
          "type": "blob",
          "size": 8069
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/scripts/generate_image.py",
          "type": "blob",
          "size": 3889
        },
        {
          "path": "plugins/compound-engineering/skills/gemini-imagegen/scripts/multi_turn_chat.py",
          "type": "blob",
          "size": 6487
        },
        {
          "path": "plugins/compound-engineering/skills/git-worktree",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/git-worktree/SKILL.md",
          "type": "blob",
          "size": 8611
        },
        {
          "path": "plugins/compound-engineering/skills/git-worktree/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/git-worktree/scripts/worktree-manager.sh",
          "type": "blob",
          "size": 8950
        },
        {
          "path": "plugins/compound-engineering/skills/rclone",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/rclone/SKILL.md",
          "type": "blob",
          "size": 3844
        },
        {
          "path": "plugins/compound-engineering/skills/rclone/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/rclone/scripts/check_setup.sh",
          "type": "blob",
          "size": 1584
        },
        {
          "path": "plugins/compound-engineering/skills/skill-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/skill-creator/SKILL.md",
          "type": "blob",
          "size": 11547
        },
        {
          "path": "plugins/compound-engineering/skills/skill-creator/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/compound-engineering/skills/skill-creator/scripts/init_skill.py",
          "type": "blob",
          "size": 10863
        },
        {
          "path": "plugins/compound-engineering/skills/skill-creator/scripts/package_skill.py",
          "type": "blob",
          "size": 3247
        },
        {
          "path": "plugins/compound-engineering/skills/skill-creator/scripts/quick_validate.py",
          "type": "blob",
          "size": 2165
        }
      ],
      "marketplace": {
        "name": "every-marketplace",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Every Inc.",
          "url": "https://github.com/EveryInc"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "compound-engineering",
            "description": "AI-powered development tools that get smarter with every use. Make each unit of engineering work easier than the last. Includes 27 specialized agents, 20 commands, and 12 skills.",
            "source": "./plugins/compound-engineering",
            "category": null,
            "version": "2.21.0",
            "author": {
              "name": "Kieran Klaassen",
              "url": "https://github.com/kieranklaassen",
              "email": "kieran@every.to"
            },
            "install_commands": [
              "/plugin marketplace add EveryInc/compound-engineering-plugin",
              "/plugin install compound-engineering@every-marketplace"
            ],
            "signals": {
              "stars": 4576,
              "forks": 386,
              "pushed_at": "2026-01-09T16:07:41Z",
              "created_at": "2025-10-09T19:43:46Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/agent-native-audit",
                "description": "Run comprehensive agent-native architecture review with scored principles",
                "path": "plugins/compound-engineering/commands/agent-native-audit.md",
                "frontmatter": {
                  "name": "agent-native-audit",
                  "description": "Run comprehensive agent-native architecture review with scored principles",
                  "argument-hint": "[optional: specific principle to audit]"
                },
                "content": "# Agent-Native Architecture Audit\n\nConduct a comprehensive review of the codebase against agent-native architecture principles, launching parallel sub-agents for each principle and producing a scored report.\n\n## Core Principles to Audit\n\n1. **Action Parity** - \"Whatever the user can do, the agent can do\"\n2. **Tools as Primitives** - \"Tools provide capability, not behavior\"\n3. **Context Injection** - \"System prompt includes dynamic context about app state\"\n4. **Shared Workspace** - \"Agent and user work in the same data space\"\n5. **CRUD Completeness** - \"Every entity has full CRUD (Create, Read, Update, Delete)\"\n6. **UI Integration** - \"Agent actions immediately reflected in UI\"\n7. **Capability Discovery** - \"Users can discover what the agent can do\"\n8. **Prompt-Native Features** - \"Features are prompts defining outcomes, not code\"\n\n## Workflow\n\n### Step 1: Load the Agent-Native Skill\n\nFirst, invoke the agent-native-architecture skill to understand all principles:\n\n```\n/compound-engineering:agent-native-architecture\n```\n\nSelect option 7 (action parity) to load the full reference material.\n\n### Step 2: Launch Parallel Sub-Agents\n\nLaunch 8 parallel sub-agents using the Task tool with `subagent_type: Explore`, one for each principle. Each agent should:\n\n1. Enumerate ALL instances in the codebase (user actions, tools, contexts, data stores, etc.)\n2. Check compliance against the principle\n3. Provide a SPECIFIC SCORE like \"X out of Y (percentage%)\"\n4. List specific gaps and recommendations\n\n<sub-agents>\n\n**Agent 1: Action Parity**\n```\nAudit for ACTION PARITY - \"Whatever the user can do, the agent can do.\"\n\nTasks:\n1. Enumerate ALL user actions in frontend (API calls, button clicks, form submissions)\n   - Search for API service files, fetch calls, form handlers\n   - Check routes and components for user interactions\n2. Check which have corresponding agent tools\n   - Search for agent tool definitions\n   - Map user actions to agent capabilities\n3. Score: \"Agent can do X out of Y user actions\"\n\nFormat:\n## Action Parity Audit\n### User Actions Found\n| Action | Location | Agent Tool | Status |\n### Score: X/Y (percentage%)\n### Missing Agent Tools\n### Recommendations\n```\n\n**Agent 2: Tools as Primitives**\n```\nAudit for TOOLS AS PRIMITIVES - \"Tools provide capability, not behavior.\"\n\nTasks:\n1. Find and read ALL agent tool files\n2. Classify each as:\n   - PRIMITIVE (good): read, write, store, list - enables capability without business logic\n   - WORKFLOW (bad): encodes business logic, makes decisions, orchestrates steps\n3. Score: \"X out of Y tools are proper primitives\"\n\nFormat:\n## Tools as Primitives Audit\n### Tool Analysis\n| Tool | File | Type | Reasoning |\n### Score: X/Y (percentage%)\n### Problematic Tools (workflows that should be primitives)\n### Recommendations\n```\n\n**Agent 3: Context Injection**\n```\nAudit for CONTEXT INJECTION - \"System prompt includes dynamic context about app state\"\n\nTasks:\n1. Find context injection code (search for \"context\", \"system prompt\", \"inject\")\n2. Read agent prompts and system messages\n3. Enumerate what IS injected vs what SHOULD be:\n   - Available resources (files, drafts, documents)\n   - User preferences/settings\n   - Recent activity\n   - Available capabilities listed\n   - Session history\n   - Workspace state\n\nFormat:\n## Context Injection Audit\n### Context Types Analysis\n| Context Type | Injected? | Location | Notes |\n### Score: X/Y (percentage%)\n### Missing Context\n### Recommendations\n```\n\n**Agent 4: Shared Workspace**\n```\nAudit for SHARED WORKSPACE - \"Agent and user work in the same data space\"\n\nTasks:\n1. Identify all data stores/tables/models\n2. Check if agents read/write to SAME tables or separate ones\n3. Look for sandbox isolation anti-pattern (agent has separate data space)\n\nFormat:\n## Shared Workspace Audit\n### Data Store Analysis\n| Data Store | User Access | Agent Access | Shared? |\n### Score: X/Y (percentage%)\n### Isolated Data (anti-pattern)\n### Recommendations\n```\n\n**Agent 5: CRUD Completeness**\n```\nAudit for CRUD COMPLETENESS - \"Every entity has full CRUD\"\n\nTasks:\n1. Identify all entities/models in the codebase\n2. For each entity, check if agent tools exist for:\n   - Create\n   - Read\n   - Update\n   - Delete\n3. Score per entity and overall\n\nFormat:\n## CRUD Completeness Audit\n### Entity CRUD Analysis\n| Entity | Create | Read | Update | Delete | Score |\n### Overall Score: X/Y entities with full CRUD (percentage%)\n### Incomplete Entities (list missing operations)\n### Recommendations\n```\n\n**Agent 6: UI Integration**\n```\nAudit for UI INTEGRATION - \"Agent actions immediately reflected in UI\"\n\nTasks:\n1. Check how agent writes/changes propagate to frontend\n2. Look for:\n   - Streaming updates (SSE, WebSocket)\n   - Polling mechanisms\n   - Shared state/services\n   - Event buses\n   - File watching\n3. Identify \"silent actions\" anti-pattern (agent changes state but UI doesn't update)\n\nFormat:\n## UI Integration Audit\n### Agent Action ‚Üí UI Update Analysis\n| Agent Action | UI Mechanism | Immediate? | Notes |\n### Score: X/Y (percentage%)\n### Silent Actions (anti-pattern)\n### Recommendations\n```\n\n**Agent 7: Capability Discovery**\n```\nAudit for CAPABILITY DISCOVERY - \"Users can discover what the agent can do\"\n\nTasks:\n1. Check for these 7 discovery mechanisms:\n   - Onboarding flow showing agent capabilities\n   - Help documentation\n   - Capability hints in UI\n   - Agent self-describes in responses\n   - Suggested prompts/actions\n   - Empty state guidance\n   - Slash commands (/help, /tools)\n2. Score against 7 mechanisms\n\nFormat:\n## Capability Discovery Audit\n### Discovery Mechanism Analysis\n| Mechanism | Exists? | Location | Quality |\n### Score: X/7 (percentage%)\n### Missing Discovery\n### Recommendations\n```\n\n**Agent 8: Prompt-Native Features**\n```\nAudit for PROMPT-NATIVE FEATURES - \"Features are prompts defining outcomes, not code\"\n\nTasks:\n1. Read all agent prompts\n2. Classify each feature/behavior as defined in:\n   - PROMPT (good): outcomes defined in natural language\n   - CODE (bad): business logic hardcoded\n3. Check if behavior changes require prompt edit vs code change\n\nFormat:\n## Prompt-Native Features Audit\n### Feature Definition Analysis\n| Feature | Defined In | Type | Notes |\n### Score: X/Y (percentage%)\n### Code-Defined Features (anti-pattern)\n### Recommendations\n```\n\n</sub-agents>\n\n### Step 3: Compile Summary Report\n\nAfter all agents complete, compile a summary with:\n\n```markdown\n## Agent-Native Architecture Review: [Project Name]\n\n### Overall Score Summary\n\n| Core Principle | Score | Percentage | Status |\n|----------------|-------|------------|--------|\n| Action Parity | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n| Tools as Primitives | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n| Context Injection | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n| Shared Workspace | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n| CRUD Completeness | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n| UI Integration | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n| Capability Discovery | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n| Prompt-Native Features | X/Y | Z% | ‚úÖ/‚ö†Ô∏è/‚ùå |\n\n**Overall Agent-Native Score: X%**\n\n### Status Legend\n- ‚úÖ Excellent (80%+)\n- ‚ö†Ô∏è Partial (50-79%)\n- ‚ùå Needs Work (<50%)\n\n### Top 10 Recommendations by Impact\n\n| Priority | Action | Principle | Effort |\n|----------|--------|-----------|--------|\n\n### What's Working Excellently\n\n[List top 5 strengths]\n```\n\n## Success Criteria\n\n- [ ] All 8 sub-agents complete their audits\n- [ ] Each principle has a specific numeric score (X/Y format)\n- [ ] Summary table shows all scores and status indicators\n- [ ] Top 10 recommendations are prioritized by impact\n- [ ] Report identifies both strengths and gaps\n\n## Optional: Single Principle Audit\n\nIf $ARGUMENTS specifies a single principle (e.g., \"action parity\"), only run that sub-agent and provide detailed findings for that principle alone.\n\nValid arguments:\n- `action parity` or `1`\n- `tools` or `primitives` or `2`\n- `context` or `injection` or `3`\n- `shared` or `workspace` or `4`\n- `crud` or `5`\n- `ui` or `integration` or `6`\n- `discovery` or `7`\n- `prompt` or `features` or `8`"
              },
              {
                "name": "/changelog",
                "description": "Create engaging changelogs for recent merges to main branch",
                "path": "plugins/compound-engineering/commands/changelog.md",
                "frontmatter": {
                  "name": "changelog",
                  "description": "Create engaging changelogs for recent merges to main branch",
                  "argument-hint": "[optional: daily|weekly, or time period in days]"
                },
                "content": "You are a witty and enthusiastic product marketer tasked with creating a fun, engaging change log for an internal development team. Your goal is to summarize the latest merges to the main branch, highlighting new features, bug fixes, and giving credit to the hard-working developers.\n\n## Time Period\n\n- For daily changelogs: Look at PRs merged in the last 24 hours\n- For weekly summaries: Look at PRs merged in the last 7 days\n- Always specify the time period in the title (e.g., \"Daily\" vs \"Weekly\")\n- Default: Get the latest changes from the last day from the main branch of the repository\n\n## PR Analysis\n\nAnalyze the provided GitHub changes and related issues. Look for:\n\n1. New features that have been added\n2. Bug fixes that have been implemented\n3. Any other significant changes or improvements\n4. References to specific issues and their details\n5. Names of contributors who made the changes\n6. Use gh cli to lookup the PRs as well and the description of the PRs\n7. Check PR labels to identify feature type (feature, bug, chore, etc.)\n8. Look for breaking changes and highlight them prominently\n9. Include PR numbers for traceability\n10. Check if PRs are linked to issues and include issue context\n\n## Content Priorities\n\n1. Breaking changes (if any) - MUST be at the top\n2. User-facing features\n3. Critical bug fixes\n4. Performance improvements\n5. Developer experience improvements\n6. Documentation updates\n\n## Formatting Guidelines\n\nNow, create a change log summary with the following guidelines:\n\n1. Keep it concise and to the point\n2. Highlight the most important changes first\n3. Group similar changes together (e.g., all new features, all bug fixes)\n4. Include issue references where applicable\n5. Mention the names of contributors, giving them credit for their work\n6. Add a touch of humor or playfulness to make it engaging\n7. Use emojis sparingly to add visual interest\n8. Keep total message under 2000 characters for Discord\n9. Use consistent emoji for each section\n10. Format code/technical terms in backticks\n11. Include PR numbers in parentheses (e.g., \"Fixed login bug (#123)\")\n\n## Deployment Notes\n\nWhen relevant, include:\n\n- Database migrations required\n- Environment variable updates needed\n- Manual intervention steps post-deploy\n- Dependencies that need updating\n\nYour final output should be formatted as follows:\n\n<change_log>\n\n# üöÄ [Daily/Weekly] Change Log: [Current Date]\n\n## üö® Breaking Changes (if any)\n\n[List any breaking changes that require immediate attention]\n\n## üåü New Features\n\n[List new features here with PR numbers]\n\n## üêõ Bug Fixes\n\n[List bug fixes here with PR numbers]\n\n## üõ†Ô∏è Other Improvements\n\n[List other significant changes or improvements]\n\n## üôå Shoutouts\n\n[Mention contributors and their contributions]\n\n## üéâ Fun Fact of the Day\n\n[Include a brief, work-related fun fact or joke]\n\n</change_log>\n\n## Style Guide Review\n\nNow review the changelog using the EVERY_WRITE_STYLE.md file and go one by one to make sure you are following the style guide. Use multiple agents, run in parallel to make it faster.\n\nRemember, your final output should only include the content within the <change_log> tags. Do not include any of your thought process or the original data in the output.\n\n## Discord Posting (Optional)\n\nYou can post changelogs to Discord by adding your own webhook URL:\n\n```\n# Set your Discord webhook URL\nDISCORD_WEBHOOK_URL=\"https://discord.com/api/webhooks/YOUR_WEBHOOK_ID/YOUR_WEBHOOK_TOKEN\"\n\n# Post using curl\ncurl -H \"Content-Type: application/json\" \\\n  -d \"{\\\"content\\\": \\\"{{CHANGELOG}}\\\"}\" \\\n  $DISCORD_WEBHOOK_URL\n```\n\nTo get a webhook URL, go to your Discord server ‚Üí Server Settings ‚Üí Integrations ‚Üí Webhooks ‚Üí New Webhook.\n\n## Error Handling\n\n- If no changes in the time period, post a \"quiet day\" message: \"üå§Ô∏è Quiet day! No new changes merged.\"\n- If unable to fetch PR details, list the PR numbers for manual review\n- Always validate message length before posting to Discord (max 2000 chars)\n\n## Schedule Recommendations\n\n- Run daily at 6 AM NY time for previous day's changes\n- Run weekly summary on Mondays for the previous week\n- Special runs after major releases or deployments\n\n## Audience Considerations\n\nAdjust the tone and detail level based on the channel:\n\n- **Dev team channels**: Include technical details, performance metrics, code snippets\n- **Product team channels**: Focus on user-facing changes and business impact\n- **Leadership channels**: Highlight progress on key initiatives and blockers"
              },
              {
                "name": "/create-agent-skill",
                "description": "Create or edit Claude Code skills with expert guidance on structure and best practices",
                "path": "plugins/compound-engineering/commands/create-agent-skill.md",
                "frontmatter": {
                  "name": "create-agent-skill",
                  "description": "Create or edit Claude Code skills with expert guidance on structure and best practices",
                  "allowed-tools": "Skill(create-agent-skills)",
                  "argument-hint": [
                    "skill description or requirements"
                  ]
                },
                "content": "Invoke the create-agent-skills skill for: $ARGUMENTS"
              },
              {
                "name": "/deepen-plan",
                "description": "Enhance a plan with parallel research agents for each section to add depth, best practices, and implementation details",
                "path": "plugins/compound-engineering/commands/deepen-plan.md",
                "frontmatter": {
                  "name": "deepen-plan",
                  "description": "Enhance a plan with parallel research agents for each section to add depth, best practices, and implementation details",
                  "argument-hint": "[path to plan file]"
                },
                "content": "# Deepen Plan - Power Enhancement Mode\n\n## Introduction\n\n**Note: The current year is 2025.** Use this when searching for recent documentation and best practices.\n\nThis command takes an existing plan (from `/workflows:plan`) and enhances each section with parallel research agents. Each major element gets its own dedicated research sub-agent to find:\n- Best practices and industry patterns\n- Performance optimizations\n- UI/UX improvements (if applicable)\n- Quality enhancements and edge cases\n- Real-world implementation examples\n\nThe result is a deeply grounded, production-ready plan with concrete implementation details.\n\n## Plan File\n\n<plan_path> #$ARGUMENTS </plan_path>\n\n**If the plan path above is empty:**\n1. Check for recent plans: `ls -la plans/`\n2. Ask the user: \"Which plan would you like to deepen? Please provide the path (e.g., `plans/my-feature.md`).\"\n\nDo not proceed until you have a valid plan file path.\n\n## Main Tasks\n\n### 1. Parse and Analyze Plan Structure\n\n<thinking>\nFirst, read and parse the plan to identify each major section that can be enhanced with research.\n</thinking>\n\n**Read the plan file and extract:**\n- [ ] Overview/Problem Statement\n- [ ] Proposed Solution sections\n- [ ] Technical Approach/Architecture\n- [ ] Implementation phases/steps\n- [ ] Code examples and file references\n- [ ] Acceptance criteria\n- [ ] Any UI/UX components mentioned\n- [ ] Technologies/frameworks mentioned (Rails, React, Python, TypeScript, etc.)\n- [ ] Domain areas (data models, APIs, UI, security, performance, etc.)\n\n**Create a section manifest:**\n```\nSection 1: [Title] - [Brief description of what to research]\nSection 2: [Title] - [Brief description of what to research]\n...\n```\n\n### 2. Discover and Apply Available Skills\n\n<thinking>\nDynamically discover all available skills and match them to plan sections. Don't assume what skills exist - discover them at runtime.\n</thinking>\n\n**Step 1: Discover ALL available skills from ALL sources**\n\n```bash\n# 1. Project-local skills (highest priority - project-specific)\nls .claude/skills/\n\n# 2. User's global skills (~/.claude/)\nls ~/.claude/skills/\n\n# 3. compound-engineering plugin skills\nls ~/.claude/plugins/cache/*/compound-engineering/*/skills/\n\n# 4. ALL other installed plugins - check every plugin for skills\nfind ~/.claude/plugins/cache -type d -name \"skills\" 2>/dev/null\n\n# 5. Also check installed_plugins.json for all plugin locations\ncat ~/.claude/plugins/installed_plugins.json\n```\n\n**Important:** Check EVERY source. Don't assume compound-engineering is the only plugin. Use skills from ANY installed plugin that's relevant.\n\n**Step 2: For each discovered skill, read its SKILL.md to understand what it does**\n\n```bash\n# For each skill directory found, read its documentation\ncat [skill-path]/SKILL.md\n```\n\n**Step 3: Match skills to plan content**\n\nFor each skill discovered:\n- Read its SKILL.md description\n- Check if any plan sections match the skill's domain\n- If there's a match, spawn a sub-agent to apply that skill's knowledge\n\n**Step 4: Spawn a sub-agent for EVERY matched skill**\n\n**CRITICAL: For EACH skill that matches, spawn a separate sub-agent and instruct it to USE that skill.**\n\nFor each matched skill:\n```\nTask general-purpose: \"You have the [skill-name] skill available at [skill-path].\n\nYOUR JOB: Use this skill on the plan.\n\n1. Read the skill: cat [skill-path]/SKILL.md\n2. Follow the skill's instructions exactly\n3. Apply the skill to this content:\n\n[relevant plan section or full plan]\n\n4. Return the skill's full output\n\nThe skill tells you what to do - follow it. Execute the skill completely.\"\n```\n\n**Spawn ALL skill sub-agents in PARALLEL:**\n- 1 sub-agent per matched skill\n- Each sub-agent reads and uses its assigned skill\n- All run simultaneously\n- 10, 20, 30 skill sub-agents is fine\n\n**Each sub-agent:**\n1. Reads its skill's SKILL.md\n2. Follows the skill's workflow/instructions\n3. Applies the skill to the plan\n4. Returns whatever the skill produces (code, recommendations, patterns, reviews, etc.)\n\n**Example spawns:**\n```\nTask general-purpose: \"Use the dhh-rails-style skill at ~/.claude/plugins/.../dhh-rails-style. Read SKILL.md and apply it to: [Rails sections of plan]\"\n\nTask general-purpose: \"Use the frontend-design skill at ~/.claude/plugins/.../frontend-design. Read SKILL.md and apply it to: [UI sections of plan]\"\n\nTask general-purpose: \"Use the agent-native-architecture skill at ~/.claude/plugins/.../agent-native-architecture. Read SKILL.md and apply it to: [agent/tool sections of plan]\"\n\nTask general-purpose: \"Use the security-patterns skill at ~/.claude/skills/security-patterns. Read SKILL.md and apply it to: [full plan]\"\n```\n\n**No limit on skill sub-agents. Spawn one for every skill that could possibly be relevant.**\n\n### 3. Discover and Apply Learnings/Solutions\n\n<thinking>\nCheck for documented learnings from /workflows:compound. These are solved problems stored as markdown files. Spawn a sub-agent for each learning to check if it's relevant.\n</thinking>\n\n**LEARNINGS LOCATION - Check these exact folders:**\n\n```\ndocs/solutions/           <-- PRIMARY: Project-level learnings (created by /workflows:compound)\n‚îú‚îÄ‚îÄ performance-issues/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ debugging-patterns/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ configuration-fixes/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ integration-issues/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ deployment-issues/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îî‚îÄ‚îÄ [other-categories]/\n    ‚îî‚îÄ‚îÄ *.md\n```\n\n**Step 1: Find ALL learning markdown files**\n\nRun these commands to get every learning file:\n\n```bash\n# PRIMARY LOCATION - Project learnings\nfind docs/solutions -name \"*.md\" -type f 2>/dev/null\n\n# If docs/solutions doesn't exist, check alternate locations:\nfind .claude/docs -name \"*.md\" -type f 2>/dev/null\nfind ~/.claude/docs -name \"*.md\" -type f 2>/dev/null\n```\n\n**Step 2: Read frontmatter of each learning to filter**\n\nEach learning file has YAML frontmatter with metadata. Read the first ~20 lines of each file to get:\n\n```yaml\n---\ntitle: \"N+1 Query Fix for Briefs\"\ncategory: performance-issues\ntags: [activerecord, n-plus-one, includes, eager-loading]\nmodule: Briefs\nsymptom: \"Slow page load, multiple queries in logs\"\nroot_cause: \"Missing includes on association\"\n---\n```\n\n**For each .md file, quickly scan its frontmatter:**\n\n```bash\n# Read first 20 lines of each learning (frontmatter + summary)\nhead -20 docs/solutions/**/*.md\n```\n\n**Step 3: Filter - only spawn sub-agents for LIKELY relevant learnings**\n\nCompare each learning's frontmatter against the plan:\n- `tags:` - Do any tags match technologies/patterns in the plan?\n- `category:` - Is this category relevant? (e.g., skip deployment-issues if plan is UI-only)\n- `module:` - Does the plan touch this module?\n- `symptom:` / `root_cause:` - Could this problem occur with the plan?\n\n**SKIP learnings that are clearly not applicable:**\n- Plan is frontend-only ‚Üí skip `database-migrations/` learnings\n- Plan is Python ‚Üí skip `rails-specific/` learnings\n- Plan has no auth ‚Üí skip `authentication-issues/` learnings\n\n**SPAWN sub-agents for learnings that MIGHT apply:**\n- Any tag overlap with plan technologies\n- Same category as plan domain\n- Similar patterns or concerns\n\n**Step 4: Spawn sub-agents for filtered learnings**\n\nFor each learning that passes the filter:\n\n```\nTask general-purpose: \"\nLEARNING FILE: [full path to .md file]\n\n1. Read this learning file completely\n2. This learning documents a previously solved problem\n\nCheck if this learning applies to this plan:\n\n---\n[full plan content]\n---\n\nIf relevant:\n- Explain specifically how it applies\n- Quote the key insight or solution\n- Suggest where/how to incorporate it\n\nIf NOT relevant after deeper analysis:\n- Say 'Not applicable: [reason]'\n\"\n```\n\n**Example filtering:**\n```\n# Found 15 learning files, plan is about \"Rails API caching\"\n\n# SPAWN (likely relevant):\ndocs/solutions/performance-issues/n-plus-one-queries.md      # tags: [activerecord] ‚úì\ndocs/solutions/performance-issues/redis-cache-stampede.md    # tags: [caching, redis] ‚úì\ndocs/solutions/configuration-fixes/redis-connection-pool.md  # tags: [redis] ‚úì\n\n# SKIP (clearly not applicable):\ndocs/solutions/deployment-issues/heroku-memory-quota.md      # not about caching\ndocs/solutions/frontend-issues/stimulus-race-condition.md    # plan is API, not frontend\ndocs/solutions/authentication-issues/jwt-expiry.md           # plan has no auth\n```\n\n**Spawn sub-agents in PARALLEL for all filtered learnings.**\n\n**These learnings are institutional knowledge - applying them prevents repeating past mistakes.**\n\n### 4. Launch Per-Section Research Agents\n\n<thinking>\nFor each major section in the plan, spawn dedicated sub-agents to research improvements. Use the Explore agent type for open-ended research.\n</thinking>\n\n**For each identified section, launch parallel research:**\n\n```\nTask Explore: \"Research best practices, patterns, and real-world examples for: [section topic].\nFind:\n- Industry standards and conventions\n- Performance considerations\n- Common pitfalls and how to avoid them\n- Documentation and tutorials\nReturn concrete, actionable recommendations.\"\n```\n\n**Also use Context7 MCP for framework documentation:**\n\nFor any technologies/frameworks mentioned in the plan, query Context7:\n```\nmcp__plugin_compound-engineering_context7__resolve-library-id: Find library ID for [framework]\nmcp__plugin_compound-engineering_context7__query-docs: Query documentation for specific patterns\n```\n\n**Use WebSearch for current best practices:**\n\nSearch for recent (2024-2025) articles, blog posts, and documentation on topics in the plan.\n\n### 5. Discover and Run ALL Review Agents\n\n<thinking>\nDynamically discover every available agent and run them ALL against the plan. Don't filter, don't skip, don't assume relevance. 40+ parallel agents is fine. Use everything available.\n</thinking>\n\n**Step 1: Discover ALL available agents from ALL sources**\n\n```bash\n# 1. Project-local agents (highest priority - project-specific)\nfind .claude/agents -name \"*.md\" 2>/dev/null\n\n# 2. User's global agents (~/.claude/)\nfind ~/.claude/agents -name \"*.md\" 2>/dev/null\n\n# 3. compound-engineering plugin agents (all subdirectories)\nfind ~/.claude/plugins/cache/*/compound-engineering/*/agents -name \"*.md\" 2>/dev/null\n\n# 4. ALL other installed plugins - check every plugin for agents\nfind ~/.claude/plugins/cache -path \"*/agents/*.md\" 2>/dev/null\n\n# 5. Check installed_plugins.json to find all plugin locations\ncat ~/.claude/plugins/installed_plugins.json\n\n# 6. For local plugins (isLocal: true), check their source directories\n# Parse installed_plugins.json and find local plugin paths\n```\n\n**Important:** Check EVERY source. Include agents from:\n- Project `.claude/agents/`\n- User's `~/.claude/agents/`\n- compound-engineering plugin (but SKIP workflow/ agents - only use review/, research/, design/, docs/)\n- ALL other installed plugins (agent-sdk-dev, frontend-design, etc.)\n- Any local plugins\n\n**For compound-engineering plugin specifically:**\n- USE: `agents/review/*` (all reviewers)\n- USE: `agents/research/*` (all researchers)\n- USE: `agents/design/*` (design agents)\n- USE: `agents/docs/*` (documentation agents)\n- SKIP: `agents/workflow/*` (these are workflow orchestrators, not reviewers)\n\n**Step 2: For each discovered agent, read its description**\n\nRead the first few lines of each agent file to understand what it reviews/analyzes.\n\n**Step 3: Launch ALL agents in parallel**\n\nFor EVERY agent discovered, launch a Task in parallel:\n\n```\nTask [agent-name]: \"Review this plan using your expertise. Apply all your checks and patterns. Plan content: [full plan content]\"\n```\n\n**CRITICAL RULES:**\n- Do NOT filter agents by \"relevance\" - run them ALL\n- Do NOT skip agents because they \"might not apply\" - let them decide\n- Launch ALL agents in a SINGLE message with multiple Task tool calls\n- 20, 30, 40 parallel agents is fine - use everything\n- Each agent may catch something others miss\n- The goal is MAXIMUM coverage, not efficiency\n\n**Step 4: Also discover and run research agents**\n\nResearch agents (like `best-practices-researcher`, `framework-docs-researcher`, `git-history-analyzer`, `repo-research-analyst`) should also be run for relevant plan sections.\n\n### 6. Wait for ALL Agents and Synthesize Everything\n\n<thinking>\nWait for ALL parallel agents to complete - skills, research agents, review agents, everything. Then synthesize all findings into a comprehensive enhancement.\n</thinking>\n\n**Collect outputs from ALL sources:**\n\n1. **Skill-based sub-agents** - Each skill's full output (code examples, patterns, recommendations)\n2. **Learnings/Solutions sub-agents** - Relevant documented learnings from /workflows:compound\n3. **Research agents** - Best practices, documentation, real-world examples\n4. **Review agents** - All feedback from every reviewer (architecture, security, performance, simplicity, etc.)\n5. **Context7 queries** - Framework documentation and patterns\n6. **Web searches** - Current best practices and articles\n\n**For each agent's findings, extract:**\n- [ ] Concrete recommendations (actionable items)\n- [ ] Code patterns and examples (copy-paste ready)\n- [ ] Anti-patterns to avoid (warnings)\n- [ ] Performance considerations (metrics, benchmarks)\n- [ ] Security considerations (vulnerabilities, mitigations)\n- [ ] Edge cases discovered (handling strategies)\n- [ ] Documentation links (references)\n- [ ] Skill-specific patterns (from matched skills)\n- [ ] Relevant learnings (past solutions that apply - prevent repeating mistakes)\n\n**Deduplicate and prioritize:**\n- Merge similar recommendations from multiple agents\n- Prioritize by impact (high-value improvements first)\n- Flag conflicting advice for human review\n- Group by plan section\n\n### 7. Enhance Plan Sections\n\n<thinking>\nMerge research findings back into the plan, adding depth without changing the original structure.\n</thinking>\n\n**Enhancement format for each section:**\n\n```markdown\n## [Original Section Title]\n\n[Original content preserved]\n\n### Research Insights\n\n**Best Practices:**\n- [Concrete recommendation 1]\n- [Concrete recommendation 2]\n\n**Performance Considerations:**\n- [Optimization opportunity]\n- [Benchmark or metric to target]\n\n**Implementation Details:**\n```[language]\n// Concrete code example from research\n```\n\n**Edge Cases:**\n- [Edge case 1 and how to handle]\n- [Edge case 2 and how to handle]\n\n**References:**\n- [Documentation URL 1]\n- [Documentation URL 2]\n```\n\n### 8. Add Enhancement Summary\n\nAt the top of the plan, add a summary section:\n\n```markdown\n## Enhancement Summary\n\n**Deepened on:** [Date]\n**Sections enhanced:** [Count]\n**Research agents used:** [List]\n\n### Key Improvements\n1. [Major improvement 1]\n2. [Major improvement 2]\n3. [Major improvement 3]\n\n### New Considerations Discovered\n- [Important finding 1]\n- [Important finding 2]\n```\n\n### 9. Update Plan File\n\n**Write the enhanced plan:**\n- Preserve original filename\n- Add `-deepened` suffix if user prefers a new file\n- Update any timestamps or metadata\n\n## Output Format\n\nUpdate the plan file in place (or create `plans/<original-name>-deepened.md` if requested).\n\n## Quality Checks\n\nBefore finalizing:\n- [ ] All original content preserved\n- [ ] Research insights clearly marked and attributed\n- [ ] Code examples are syntactically correct\n- [ ] Links are valid and relevant\n- [ ] No contradictions between sections\n- [ ] Enhancement summary accurately reflects changes\n\n## Post-Enhancement Options\n\nAfter writing the enhanced plan, use the **AskUserQuestion tool** to present these options:\n\n**Question:** \"Plan deepened at `[plan_path]`. What would you like to do next?\"\n\n**Options:**\n1. **View diff** - Show what was added/changed\n2. **Run `/plan_review`** - Get feedback from reviewers on enhanced plan\n3. **Start `/workflows:work`** - Begin implementing this enhanced plan\n4. **Deepen further** - Run another round of research on specific sections\n5. **Revert** - Restore original plan (if backup exists)\n\nBased on selection:\n- **View diff** ‚Üí Run `git diff [plan_path]` or show before/after\n- **`/plan_review`** ‚Üí Call the /plan_review command with the plan file path\n- **`/workflows:work`** ‚Üí Call the /workflows:work command with the plan file path\n- **Deepen further** ‚Üí Ask which sections need more research, then re-run those agents\n- **Revert** ‚Üí Restore from git or backup\n\n## Example Enhancement\n\n**Before (from /workflows:plan):**\n```markdown\n## Technical Approach\n\nUse React Query for data fetching with optimistic updates.\n```\n\n**After (from /workflows:deepen-plan):**\n```markdown\n## Technical Approach\n\nUse React Query for data fetching with optimistic updates.\n\n### Research Insights\n\n**Best Practices:**\n- Configure `staleTime` and `cacheTime` based on data freshness requirements\n- Use `queryKey` factories for consistent cache invalidation\n- Implement error boundaries around query-dependent components\n\n**Performance Considerations:**\n- Enable `refetchOnWindowFocus: false` for stable data to reduce unnecessary requests\n- Use `select` option to transform and memoize data at query level\n- Consider `placeholderData` for instant perceived loading\n\n**Implementation Details:**\n```typescript\n// Recommended query configuration\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      staleTime: 5 * 60 * 1000, // 5 minutes\n      retry: 2,\n      refetchOnWindowFocus: false,\n    },\n  },\n});\n```\n\n**Edge Cases:**\n- Handle race conditions with `cancelQueries` on component unmount\n- Implement retry logic for transient network failures\n- Consider offline support with `persistQueryClient`\n\n**References:**\n- https://tanstack.com/query/latest/docs/react/guides/optimistic-updates\n- https://tkdodo.eu/blog/practical-react-query\n```\n\nNEVER CODE! Just research and enhance the plan."
              },
              {
                "name": "/deploy-docs",
                "description": "Validate and prepare documentation for GitHub Pages deployment",
                "path": "plugins/compound-engineering/commands/deploy-docs.md",
                "frontmatter": {
                  "name": "deploy-docs",
                  "description": "Validate and prepare documentation for GitHub Pages deployment"
                },
                "content": "# Deploy Documentation Command\n\nValidate the documentation site and prepare it for GitHub Pages deployment.\n\n## Step 1: Validate Documentation\n\nRun these checks:\n\n```bash\n# Count components\necho \"Agents: $(ls plugins/compound-engineering/agents/*.md | wc -l)\"\necho \"Commands: $(ls plugins/compound-engineering/commands/*.md | wc -l)\"\necho \"Skills: $(ls -d plugins/compound-engineering/skills/*/ 2>/dev/null | wc -l)\"\n\n# Validate JSON\ncat .claude-plugin/marketplace.json | jq . > /dev/null && echo \"‚úì marketplace.json valid\"\ncat plugins/compound-engineering/.claude-plugin/plugin.json | jq . > /dev/null && echo \"‚úì plugin.json valid\"\n\n# Check all HTML files exist\nfor page in index agents commands skills mcp-servers changelog getting-started; do\n  if [ -f \"plugins/compound-engineering/docs/pages/${page}.html\" ] || [ -f \"plugins/compound-engineering/docs/${page}.html\" ]; then\n    echo \"‚úì ${page}.html exists\"\n  else\n    echo \"‚úó ${page}.html MISSING\"\n  fi\ndone\n```\n\n## Step 2: Check for Uncommitted Changes\n\n```bash\ngit status --porcelain plugins/compound-engineering/docs/\n```\n\nIf there are uncommitted changes, warn the user to commit first.\n\n## Step 3: Deployment Instructions\n\nSince GitHub Pages deployment requires a workflow file with special permissions, provide these instructions:\n\n### First-time Setup\n\n1. Create `.github/workflows/deploy-docs.yml` with the GitHub Pages workflow\n2. Go to repository Settings > Pages\n3. Set Source to \"GitHub Actions\"\n\n### Deploying\n\nAfter merging to `main`, the docs will auto-deploy. Or:\n\n1. Go to Actions tab\n2. Select \"Deploy Documentation to GitHub Pages\"\n3. Click \"Run workflow\"\n\n### Workflow File Content\n\n```yaml\nname: Deploy Documentation to GitHub Pages\n\non:\n  push:\n    branches: [main]\n    paths:\n      - 'plugins/compound-engineering/docs/**'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/configure-pages@v4\n      - uses: actions/upload-pages-artifact@v3\n        with:\n          path: 'plugins/compound-engineering/docs'\n      - uses: actions/deploy-pages@v4\n```\n\n## Step 4: Report Status\n\nProvide a summary:\n\n```\n## Deployment Readiness\n\n‚úì All HTML pages present\n‚úì JSON files valid\n‚úì Component counts match\n\n### Next Steps\n- [ ] Commit any pending changes\n- [ ] Push to main branch\n- [ ] Verify GitHub Pages workflow exists\n- [ ] Check deployment at https://everyinc.github.io/every-marketplace/\n```"
              },
              {
                "name": "/feature-video",
                "description": "Record a video walkthrough of a feature and add it to the PR description",
                "path": "plugins/compound-engineering/commands/feature-video.md",
                "frontmatter": {
                  "name": "feature-video",
                  "description": "Record a video walkthrough of a feature and add it to the PR description",
                  "argument-hint": "[PR number or 'current'] [optional: base URL, default localhost:3000]"
                },
                "content": "# Feature Video Walkthrough\n\n<command_purpose>Record a video walkthrough demonstrating a feature, upload it, and add it to the PR description.</command_purpose>\n\n## Introduction\n\n<role>Developer Relations Engineer creating feature demo videos</role>\n\nThis command creates professional video walkthroughs of features for PR documentation:\n- Records browser interactions using Playwright video capture\n- Demonstrates the complete user flow\n- Uploads the video for easy sharing\n- Updates the PR description with an embedded video\n\n## Prerequisites\n\n<requirements>\n- Local development server running (e.g., `bin/dev`, `rails server`)\n- Playwright MCP server connected\n- Git repository with a PR to document\n- `ffmpeg` installed (for video conversion)\n- `rclone` configured (optional, for cloud upload - see rclone skill)\n</requirements>\n\n## Main Tasks\n\n### 1. Parse Arguments\n\n<parse_args>\n\n**Arguments:** $ARGUMENTS\n\nParse the input:\n- First argument: PR number or \"current\" (defaults to current branch's PR)\n- Second argument: Base URL (defaults to `http://localhost:3000`)\n\n```bash\n# Get PR number for current branch if needed\ngh pr view --json number -q '.number'\n```\n\n</parse_args>\n\n### 2. Gather Feature Context\n\n<gather_context>\n\n**Get PR details:**\n```bash\ngh pr view [number] --json title,body,files,headRefName -q '.'\n```\n\n**Get changed files:**\n```bash\ngh pr view [number] --json files -q '.files[].path'\n```\n\n**Map files to testable routes** (same as playwright-test):\n\n| File Pattern | Route(s) |\n|-------------|----------|\n| `app/views/users/*` | `/users`, `/users/:id`, `/users/new` |\n| `app/controllers/settings_controller.rb` | `/settings` |\n| `app/javascript/controllers/*_controller.js` | Pages using that Stimulus controller |\n| `app/components/*_component.rb` | Pages rendering that component |\n\n</gather_context>\n\n### 3. Plan the Video Flow\n\n<plan_flow>\n\nBefore recording, create a shot list:\n\n1. **Opening shot**: Homepage or starting point (2-3 seconds)\n2. **Navigation**: How user gets to the feature\n3. **Feature demonstration**: Core functionality (main focus)\n4. **Edge cases**: Error states, validation, etc. (if applicable)\n5. **Success state**: Completed action/result\n\nAsk user to confirm or adjust the flow:\n\n```markdown\n**Proposed Video Flow**\n\nBased on PR #[number]: [title]\n\n1. Start at: /[starting-route]\n2. Navigate to: /[feature-route]\n3. Demonstrate:\n   - [Action 1]\n   - [Action 2]\n   - [Action 3]\n4. Show result: [success state]\n\nEstimated duration: ~[X] seconds\n\nDoes this look right?\n1. Yes, start recording\n2. Modify the flow (describe changes)\n3. Add specific interactions to demonstrate\n```\n\n</plan_flow>\n\n### 4. Setup Video Recording\n\n<setup_recording>\n\n**Create videos directory:**\n```bash\nmkdir -p tmp/videos\n```\n\n**Start browser with video recording using Playwright MCP:**\n\nNote: Playwright MCP's browser_navigate will be used, and we'll use browser_run_code to enable video recording:\n\n```javascript\n// Enable video recording context\nmcp__plugin_compound-engineering_pw__browser_run_code({\n  code: `async (page) => {\n    // Video recording is enabled at context level\n    // The MCP server handles this automatically\n    return 'Video recording active';\n  }`\n})\n```\n\n**Alternative: Use browser screenshots as frames**\n\nIf video recording isn't available via MCP, fall back to:\n1. Take screenshots at key moments\n2. Combine into a GIF using ffmpeg\n\n```bash\nffmpeg -framerate 2 -pattern_type glob -i 'tmp/screenshots/*.png' -vf \"scale=1280:-1\" tmp/videos/feature-demo.gif\n```\n\n</setup_recording>\n\n### 5. Record the Walkthrough\n\n<record_walkthrough>\n\nExecute the planned flow, capturing each step:\n\n**Step 1: Navigate to starting point**\n```\nmcp__plugin_compound-engineering_pw__browser_navigate({ url: \"[base-url]/[start-route]\" })\nmcp__plugin_compound-engineering_pw__browser_wait_for({ time: 2 })\nmcp__plugin_compound-engineering_pw__browser_take_screenshot({ filename: \"tmp/screenshots/01-start.png\" })\n```\n\n**Step 2: Perform navigation/interactions**\n```\nmcp__plugin_compound-engineering_pw__browser_click({ element: \"[description]\", ref: \"[ref]\" })\nmcp__plugin_compound-engineering_pw__browser_wait_for({ time: 1 })\nmcp__plugin_compound-engineering_pw__browser_take_screenshot({ filename: \"tmp/screenshots/02-navigate.png\" })\n```\n\n**Step 3: Demonstrate feature**\n```\nmcp__plugin_compound-engineering_pw__browser_snapshot({})\n// Identify interactive elements\nmcp__plugin_compound-engineering_pw__browser_click({ element: \"[feature element]\", ref: \"[ref]\" })\nmcp__plugin_compound-engineering_pw__browser_wait_for({ time: 1 })\nmcp__plugin_compound-engineering_pw__browser_take_screenshot({ filename: \"tmp/screenshots/03-feature.png\" })\n```\n\n**Step 4: Capture result**\n```\nmcp__plugin_compound-engineering_pw__browser_wait_for({ time: 2 })\nmcp__plugin_compound-engineering_pw__browser_take_screenshot({ filename: \"tmp/screenshots/04-result.png\" })\n```\n\n**Create video/GIF from screenshots:**\n\n```bash\n# Create directories\nmkdir -p tmp/videos tmp/screenshots\n\n# Create MP4 video (RECOMMENDED - better quality, smaller size)\n# -framerate 0.5 = 2 seconds per frame (slower playback)\n# -framerate 1 = 1 second per frame\nffmpeg -y -framerate 0.5 -pattern_type glob -i '.playwright-mcp/tmp/screenshots/*.png' \\\n  -c:v libx264 -pix_fmt yuv420p -vf \"scale=1280:-2\" \\\n  tmp/videos/feature-demo.mp4\n\n# Create low-quality GIF for preview (small file, for GitHub embed)\nffmpeg -y -framerate 0.5 -pattern_type glob -i '.playwright-mcp/tmp/screenshots/*.png' \\\n  -vf \"scale=640:-1:flags=lanczos,split[s0][s1];[s0]palettegen=max_colors=128[p];[s1][p]paletteuse\" \\\n  -loop 0 tmp/videos/feature-demo-preview.gif\n\n# Copy screenshots to project folder for easy access\ncp -r .playwright-mcp/tmp/screenshots tmp/\n```\n\n**Note:**\n- The `-2` in MP4 scale ensures height is divisible by 2 (required for H.264)\n- Preview GIF uses 640px width and 128 colors to keep file size small (~100-200KB)\n\n</record_walkthrough>\n\n### 6. Upload the Video\n\n<upload_video>\n\n**Upload with rclone:**\n\n```bash\n# Check rclone is configured\nrclone listremotes\n\n# Upload video, preview GIF, and screenshots to cloud storage\n# Use --s3-no-check-bucket to avoid permission errors\nrclone copy tmp/videos/ r2:kieran-claude/pr-videos/pr-[number]/ --s3-no-check-bucket --progress\nrclone copy tmp/screenshots/ r2:kieran-claude/pr-videos/pr-[number]/screenshots/ --s3-no-check-bucket --progress\n\n# List uploaded files\nrclone ls r2:kieran-claude/pr-videos/pr-[number]/\n```\n\nPublic URLs (R2 with public access):\n```\nVideo: https://pub-4047722ebb1b4b09853f24d3b61467f1.r2.dev/pr-videos/pr-[number]/feature-demo.mp4\nPreview: https://pub-4047722ebb1b4b09853f24d3b61467f1.r2.dev/pr-videos/pr-[number]/feature-demo-preview.gif\n```\n\n</upload_video>\n\n### 7. Update PR Description\n\n<update_pr>\n\n**Get current PR body:**\n```bash\ngh pr view [number] --json body -q '.body'\n```\n\n**Add video section to PR description:**\n\nIf the PR already has a video section, replace it. Otherwise, append:\n\n**IMPORTANT:** GitHub cannot embed external MP4s directly. Use a clickable GIF that links to the video:\n\n```markdown\n## Demo\n\n[![Feature Demo]([preview-gif-url])]([video-mp4-url])\n\n*Click to view full video*\n```\n\nExample:\n```markdown\n[![Feature Demo](https://pub-4047722ebb1b4b09853f24d3b61467f1.r2.dev/pr-videos/pr-137/feature-demo-preview.gif)](https://pub-4047722ebb1b4b09853f24d3b61467f1.r2.dev/pr-videos/pr-137/feature-demo.mp4)\n```\n\n**Update the PR:**\n```bash\ngh pr edit [number] --body \"[updated body with video section]\"\n```\n\n**Or add as a comment if preferred:**\n```bash\ngh pr comment [number] --body \"## Feature Demo\n\n![Demo]([video-url])\n\n_Automated walkthrough of the changes in this PR_\"\n```\n\n</update_pr>\n\n### 8. Cleanup\n\n<cleanup>\n\n```bash\n# Optional: Clean up screenshots\nrm -rf tmp/screenshots\n\n# Keep videos for reference\necho \"Video retained at: tmp/videos/feature-demo.gif\"\n```\n\n</cleanup>\n\n### 9. Summary\n\n<summary>\n\nPresent completion summary:\n\n```markdown\n## Feature Video Complete\n\n**PR:** #[number] - [title]\n**Video:** [url or local path]\n**Duration:** ~[X] seconds\n**Format:** [GIF/MP4]\n\n### Shots Captured\n1. [Starting point] - [description]\n2. [Navigation] - [description]\n3. [Feature demo] - [description]\n4. [Result] - [description]\n\n### PR Updated\n- [x] Video section added to PR description\n- [ ] Ready for review\n\n**Next steps:**\n- Review the video to ensure it accurately demonstrates the feature\n- Share with reviewers for context\n```\n\n</summary>\n\n## Quick Usage Examples\n\n```bash\n# Record video for current branch's PR\n/feature-video\n\n# Record video for specific PR\n/feature-video 847\n\n# Record with custom base URL\n/feature-video 847 http://localhost:5000\n\n# Record for staging environment\n/feature-video current https://staging.example.com\n```\n\n## Tips\n\n- **Keep it short**: 10-30 seconds is ideal for PR demos\n- **Focus on the change**: Don't include unrelated UI\n- **Show before/after**: If fixing a bug, show the broken state first (if possible)\n- **Annotate if needed**: Add text overlays for complex features"
              },
              {
                "name": "/generate_command",
                "description": "Create a new custom slash command following conventions and best practices",
                "path": "plugins/compound-engineering/commands/generate_command.md",
                "frontmatter": {
                  "name": "generate_command",
                  "description": "Create a new custom slash command following conventions and best practices",
                  "argument-hint": "[command purpose and requirements]"
                },
                "content": "# Create a Custom Claude Code Command\n\nCreate a new slash command in `.claude/commands/` for the requested task.\n\n## Goal\n\n#$ARGUMENTS\n\n## Key Capabilities to Leverage\n\n**File Operations:**\n- Read, Edit, Write - modify files precisely\n- Glob, Grep - search codebase\n- MultiEdit - atomic multi-part changes\n\n**Development:**\n- Bash - run commands (git, tests, linters)\n- Task - launch specialized agents for complex tasks\n- TodoWrite - track progress with todo lists\n\n**Web & APIs:**\n- WebFetch, WebSearch - research documentation\n- GitHub (gh cli) - PRs, issues, reviews\n- Playwright - browser automation, screenshots\n\n**Integrations:**\n- AppSignal - logs and monitoring\n- Context7 - framework docs\n- Stripe, Todoist, Featurebase (if relevant)\n\n## Best Practices\n\n1. **Be specific and clear** - detailed instructions yield better results\n2. **Break down complex tasks** - use step-by-step plans\n3. **Use examples** - reference existing code patterns\n4. **Include success criteria** - tests pass, linting clean, etc.\n5. **Think first** - use \"think hard\" or \"plan\" keywords for complex problems\n6. **Iterate** - guide the process step by step\n\n## Required: YAML Frontmatter\n\n**EVERY command MUST start with YAML frontmatter:**\n\n```yaml\n---\nname: command-name\ndescription: Brief description of what this command does (max 100 chars)\nargument-hint: \"[what arguments the command accepts]\"\n---\n```\n\n**Fields:**\n- `name`: Lowercase command identifier (used internally)\n- `description`: Clear, concise summary of command purpose\n- `argument-hint`: Shows user what arguments are expected (e.g., `[file path]`, `[PR number]`, `[optional: format]`)\n\n## Structure Your Command\n\n```markdown\n# [Command Name]\n\n[Brief description of what this command does]\n\n## Steps\n\n1. [First step with specific details]\n   - Include file paths, patterns, or constraints\n   - Reference existing code if applicable\n\n2. [Second step]\n   - Use parallel tool calls when possible\n   - Check/verify results\n\n3. [Final steps]\n   - Run tests\n   - Lint code\n   - Commit changes (if appropriate)\n\n## Success Criteria\n\n- [ ] Tests pass\n- [ ] Code follows style guide\n- [ ] Documentation updated (if needed)\n```\n\n## Tips for Effective Commands\n\n- **Use $ARGUMENTS** placeholder for dynamic inputs\n- **Reference CLAUDE.md** patterns and conventions\n- **Include verification steps** - tests, linting, visual checks\n- **Be explicit about constraints** - don't modify X, use pattern Y\n- **Use XML tags** for structured prompts: `<task>`, `<requirements>`, `<constraints>`\n\n## Example Pattern\n\n```markdown\nImplement #$ARGUMENTS following these steps:\n\n1. Research existing patterns\n   - Search for similar code using Grep\n   - Read relevant files to understand approach\n\n2. Plan the implementation\n   - Think through edge cases and requirements\n   - Consider test cases needed\n\n3. Implement\n   - Follow existing code patterns (reference specific files)\n   - Write tests first if doing TDD\n   - Ensure code follows CLAUDE.md conventions\n\n4. Verify\n   - Run tests: `bin/rails test`\n   - Run linter: `bundle exec standardrb`\n   - Check changes with git diff\n\n5. Commit (optional)\n   - Stage changes\n   - Write clear commit message\n```\n\n## Creating the Command File\n\n1. **Create the file** at `.claude/commands/[name].md` (subdirectories like `workflows/` supported)\n2. **Start with YAML frontmatter** (see section above)\n3. **Structure the command** using the template above\n4. **Test the command** by using it with appropriate arguments\n\n## Command File Template\n\n```markdown\n---\nname: command-name\ndescription: What this command does\nargument-hint: \"[expected arguments]\"\n---\n\n# Command Title\n\nBrief introduction of what the command does and when to use it.\n\n## Workflow\n\n### Step 1: [First Major Step]\n\nDetails about what to do.\n\n### Step 2: [Second Major Step]\n\nDetails about what to do.\n\n## Success Criteria\n\n- [ ] Expected outcome 1\n- [ ] Expected outcome 2\n```"
              },
              {
                "name": "/heal-skill",
                "description": "Fix incorrect SKILL.md files when a skill has wrong instructions or outdated API references",
                "path": "plugins/compound-engineering/commands/heal-skill.md",
                "frontmatter": {
                  "name": "heal-skill",
                  "description": "Fix incorrect SKILL.md files when a skill has wrong instructions or outdated API references",
                  "argument-hint": [
                    {
                      "optional": "specific issue to fix"
                    }
                  ],
                  "allowed-tools": [
                    "Read",
                    "Edit",
                    "Bash(ls:*)",
                    "Bash(git:*)"
                  ]
                },
                "content": "<objective>\nUpdate a skill's SKILL.md and related files based on corrections discovered during execution.\n\nAnalyze the conversation to detect which skill is running, reflect on what went wrong, propose specific fixes, get user approval, then apply changes with optional commit.\n</objective>\n\n<context>\nSkill detection: !`ls -1 ./skills/*/SKILL.md | head -5`\n</context>\n\n<quick_start>\n<workflow>\n1. **Detect skill** from conversation context (invocation messages, recent SKILL.md references)\n2. **Reflect** on what went wrong and how you discovered the fix\n3. **Present** proposed changes with before/after diffs\n4. **Get approval** before making any edits\n5. **Apply** changes and optionally commit\n</workflow>\n</quick_start>\n\n<process>\n<step_1 name=\"detect_skill\">\nIdentify the skill from conversation context:\n\n- Look for skill invocation messages\n- Check which SKILL.md was recently referenced\n- Examine current task context\n\nSet: `SKILL_NAME=[skill-name]` and `SKILL_DIR=./skills/$SKILL_NAME`\n\nIf unclear, ask the user.\n</step_1>\n\n<step_2 name=\"reflection_and_analysis\">\nFocus on $ARGUMENTS if provided, otherwise analyze broader context.\n\nDetermine:\n- **What was wrong**: Quote specific sections from SKILL.md that are incorrect\n- **Discovery method**: Context7, error messages, trial and error, documentation lookup\n- **Root cause**: Outdated API, incorrect parameters, wrong endpoint, missing context\n- **Scope of impact**: Single section or multiple? Related files affected?\n- **Proposed fix**: Which files, which sections, before/after for each\n</step_2>\n\n<step_3 name=\"scan_affected_files\">\n```bash\nls -la $SKILL_DIR/\nls -la $SKILL_DIR/references/ 2>/dev/null\nls -la $SKILL_DIR/scripts/ 2>/dev/null\n```\n</step_3>\n\n<step_4 name=\"present_proposed_changes\">\nPresent changes in this format:\n\n```\n**Skill being healed:** [skill-name]\n**Issue discovered:** [1-2 sentence summary]\n**Root cause:** [brief explanation]\n\n**Files to be modified:**\n- [ ] SKILL.md\n- [ ] references/[file].md\n- [ ] scripts/[file].py\n\n**Proposed changes:**\n\n### Change 1: SKILL.md - [Section name]\n**Location:** Line [X] in SKILL.md\n\n**Current (incorrect):**\n```\n[exact text from current file]\n```\n\n**Corrected:**\n```\n[new text]\n```\n\n**Reason:** [why this fixes the issue]\n\n[repeat for each change across all files]\n\n**Impact assessment:**\n- Affects: [authentication/API endpoints/parameters/examples/etc.]\n\n**Verification:**\nThese changes will prevent: [specific error that prompted this]\n```\n</step_4>\n\n<step_5 name=\"request_approval\">\n```\nShould I apply these changes?\n\n1. Yes, apply and commit all changes\n2. Apply but don't commit (let me review first)\n3. Revise the changes (I'll provide feedback)\n4. Cancel (don't make changes)\n\nChoose (1-4):\n```\n\n**Wait for user response. Do not proceed without approval.**\n</step_5>\n\n<step_6 name=\"apply_changes\">\nOnly after approval (option 1 or 2):\n\n1. Use Edit tool for each correction across all files\n2. Read back modified sections to verify\n3. If option 1, commit with structured message showing what was healed\n4. Confirm completion with file list\n</step_6>\n</process>\n\n<success_criteria>\n- Skill correctly detected from conversation context\n- All incorrect sections identified with before/after\n- User approved changes before application\n- All edits applied across SKILL.md and related files\n- Changes verified by reading back\n- Commit created if user chose option 1\n- Completion confirmed with file list\n</success_criteria>\n\n<verification>\nBefore completing:\n\n- Read back each modified section to confirm changes applied\n- Ensure cross-file consistency (SKILL.md examples match references/)\n- Verify git commit created if option 1 was selected\n- Check no unintended files were modified\n</verification>"
              },
              {
                "name": "/plan_review",
                "description": "Have multiple specialized agents review a plan in parallel",
                "path": "plugins/compound-engineering/commands/plan_review.md",
                "frontmatter": {
                  "name": "plan_review",
                  "description": "Have multiple specialized agents review a plan in parallel",
                  "argument-hint": "[plan file path or plan content]"
                },
                "content": "Have @agent-dhh-rails-reviewer @agent-kieran-rails-reviewer @agent-code-simplicity-reviewer review this plan in parallel."
              },
              {
                "name": "/playwright-test",
                "description": "Run Playwright browser tests on pages affected by current PR or branch",
                "path": "plugins/compound-engineering/commands/playwright-test.md",
                "frontmatter": {
                  "name": "playwright-test",
                  "description": "Run Playwright browser tests on pages affected by current PR or branch",
                  "argument-hint": "[PR number, branch name, or 'current' for current branch]"
                },
                "content": "# Playwright Test Command\n\n<command_purpose>Run end-to-end browser tests on pages affected by a PR or branch changes using Playwright MCP.</command_purpose>\n\n## Introduction\n\n<role>QA Engineer specializing in browser-based end-to-end testing</role>\n\nThis command tests affected pages in a real browser, catching issues that unit tests miss:\n- JavaScript integration bugs\n- CSS/layout regressions\n- User workflow breakages\n- Console errors\n\n## Prerequisites\n\n<requirements>\n- Local development server running (e.g., `bin/dev`, `rails server`)\n- Playwright MCP server connected\n- Git repository with changes to test\n</requirements>\n\n## Main Tasks\n\n### 1. Determine Test Scope\n\n<test_target> $ARGUMENTS </test_target>\n\n<determine_scope>\n\n**If PR number provided:**\n```bash\ngh pr view [number] --json files -q '.files[].path'\n```\n\n**If 'current' or empty:**\n```bash\ngit diff --name-only main...HEAD\n```\n\n**If branch name provided:**\n```bash\ngit diff --name-only main...[branch]\n```\n\n</determine_scope>\n\n### 2. Map Files to Routes\n\n<file_to_route_mapping>\n\nMap changed files to testable routes:\n\n| File Pattern | Route(s) |\n|-------------|----------|\n| `app/views/users/*` | `/users`, `/users/:id`, `/users/new` |\n| `app/controllers/settings_controller.rb` | `/settings` |\n| `app/javascript/controllers/*_controller.js` | Pages using that Stimulus controller |\n| `app/components/*_component.rb` | Pages rendering that component |\n| `app/views/layouts/*` | All pages (test homepage at minimum) |\n| `app/assets/stylesheets/*` | Visual regression on key pages |\n| `app/helpers/*_helper.rb` | Pages using that helper |\n\nBuild a list of URLs to test based on the mapping.\n\n</file_to_route_mapping>\n\n### 3. Verify Server is Running\n\n<check_server>\n\nBefore testing, verify the local server is accessible:\n\n```\nmcp__playwright__browser_navigate({ url: \"http://localhost:3000\" })\nmcp__playwright__browser_snapshot({})\n```\n\nIf server is not running, inform user:\n```markdown\n**Server not running**\n\nPlease start your development server:\n- Rails: `bin/dev` or `rails server`\n- Node: `npm run dev`\n\nThen run `/playwright-test` again.\n```\n\n</check_server>\n\n### 4. Test Each Affected Page\n\n<test_pages>\n\nFor each affected route:\n\n**Step 1: Navigate and capture snapshot**\n```\nmcp__playwright__browser_navigate({ url: \"http://localhost:3000/[route]\" })\nmcp__playwright__browser_snapshot({})\n```\n\n**Step 2: Check for errors**\n```\nmcp__playwright__browser_console_messages({ level: \"error\" })\n```\n\n**Step 3: Verify key elements**\n- Page title/heading present\n- Primary content rendered\n- No error messages visible\n- Forms have expected fields\n\n**Step 4: Test critical interactions (if applicable)**\n```\nmcp__playwright__browser_click({ element: \"[description]\", ref: \"[ref]\" })\nmcp__playwright__browser_snapshot({})\n```\n\n</test_pages>\n\n### 5. Human Verification (When Required)\n\n<human_verification>\n\nPause for human input when testing touches:\n\n| Flow Type | What to Ask |\n|-----------|-------------|\n| OAuth | \"Please sign in with [provider] and confirm it works\" |\n| Email | \"Check your inbox for the test email and confirm receipt\" |\n| Payments | \"Complete a test purchase in sandbox mode\" |\n| SMS | \"Verify you received the SMS code\" |\n| External APIs | \"Confirm the [service] integration is working\" |\n\nUse AskUserQuestion:\n```markdown\n**Human Verification Needed**\n\nThis test touches the [flow type]. Please:\n1. [Action to take]\n2. [What to verify]\n\nDid it work correctly?\n1. Yes - continue testing\n2. No - describe the issue\n```\n\n</human_verification>\n\n### 6. Handle Failures\n\n<failure_handling>\n\nWhen a test fails:\n\n1. **Document the failure:**\n   - Screenshot the error state\n   - Capture console errors\n   - Note the exact reproduction steps\n\n2. **Ask user how to proceed:**\n   ```markdown\n   **Test Failed: [route]**\n\n   Issue: [description]\n   Console errors: [if any]\n\n   How to proceed?\n   1. Fix now - I'll help debug and fix\n   2. Create todo - Add to todos/ for later\n   3. Skip - Continue testing other pages\n   ```\n\n3. **If \"Fix now\":**\n   - Investigate the issue\n   - Propose a fix\n   - Apply fix\n   - Re-run the failing test\n\n4. **If \"Create todo\":**\n   - Create `{id}-pending-p1-playwright-{description}.md`\n   - Continue testing\n\n5. **If \"Skip\":**\n   - Log as skipped\n   - Continue testing\n\n</failure_handling>\n\n### 7. Test Summary\n\n<test_summary>\n\nAfter all tests complete, present summary:\n\n```markdown\n## üé≠ Playwright Test Results\n\n**Test Scope:** PR #[number] / [branch name]\n**Server:** http://localhost:3000\n\n### Pages Tested: [count]\n\n| Route | Status | Notes |\n|-------|--------|-------|\n| `/users` | ‚úÖ Pass | |\n| `/settings` | ‚úÖ Pass | |\n| `/dashboard` | ‚ùå Fail | Console error: [msg] |\n| `/checkout` | ‚è≠Ô∏è Skip | Requires payment credentials |\n\n### Console Errors: [count]\n- [List any errors found]\n\n### Human Verifications: [count]\n- OAuth flow: ‚úÖ Confirmed\n- Email delivery: ‚úÖ Confirmed\n\n### Failures: [count]\n- `/dashboard` - [issue description]\n\n### Created Todos: [count]\n- `005-pending-p1-playwright-dashboard-error.md`\n\n### Result: [PASS / FAIL / PARTIAL]\n```\n\n</test_summary>\n\n## Quick Usage Examples\n\n```bash\n# Test current branch changes\n/playwright-test\n\n# Test specific PR\n/playwright-test 847\n\n# Test specific branch\n/playwright-test feature/new-dashboard\n```"
              },
              {
                "name": "/release-docs",
                "description": "Build and update the documentation site with current plugin components",
                "path": "plugins/compound-engineering/commands/release-docs.md",
                "frontmatter": {
                  "name": "release-docs",
                  "description": "Build and update the documentation site with current plugin components",
                  "argument-hint": "[optional: --dry-run to preview changes without writing]"
                },
                "content": "# Release Documentation Command\n\nYou are a documentation generator for the compound-engineering plugin. Your job is to ensure the documentation site at `plugins/compound-engineering/docs/` is always up-to-date with the actual plugin components.\n\n## Overview\n\nThe documentation site is a static HTML/CSS/JS site based on the Evil Martians LaunchKit template. It needs to be regenerated whenever:\n\n- Agents are added, removed, or modified\n- Commands are added, removed, or modified\n- Skills are added, removed, or modified\n- MCP servers are added, removed, or modified\n\n## Step 1: Inventory Current Components\n\nFirst, count and list all current components:\n\n```bash\n# Count agents\nls plugins/compound-engineering/agents/*.md | wc -l\n\n# Count commands\nls plugins/compound-engineering/commands/*.md | wc -l\n\n# Count skills\nls -d plugins/compound-engineering/skills/*/ 2>/dev/null | wc -l\n\n# Count MCP servers\nls -d plugins/compound-engineering/mcp-servers/*/ 2>/dev/null | wc -l\n```\n\nRead all component files to get their metadata:\n\n### Agents\nFor each agent file in `plugins/compound-engineering/agents/*.md`:\n- Extract the frontmatter (name, description)\n- Note the category (Review, Research, Workflow, Design, Docs)\n- Get key responsibilities from the content\n\n### Commands\nFor each command file in `plugins/compound-engineering/commands/*.md`:\n- Extract the frontmatter (name, description, argument-hint)\n- Categorize as Workflow or Utility command\n\n### Skills\nFor each skill directory in `plugins/compound-engineering/skills/*/`:\n- Read the SKILL.md file for frontmatter (name, description)\n- Note any scripts or supporting files\n\n### MCP Servers\nFor each MCP server in `plugins/compound-engineering/mcp-servers/*/`:\n- Read the configuration and README\n- List the tools provided\n\n## Step 2: Update Documentation Pages\n\n### 2a. Update `docs/index.html`\n\nUpdate the stats section with accurate counts:\n```html\n<div class=\"stats-grid\">\n  <div class=\"stat-card\">\n    <span class=\"stat-number\">[AGENT_COUNT]</span>\n    <span class=\"stat-label\">Specialized Agents</span>\n  </div>\n  <!-- Update all stat cards -->\n</div>\n```\n\nEnsure the component summary sections list key components accurately.\n\n### 2b. Update `docs/pages/agents.html`\n\nRegenerate the complete agents reference page:\n- Group agents by category (Review, Research, Workflow, Design, Docs)\n- Include for each agent:\n  - Name and description\n  - Key responsibilities (bullet list)\n  - Usage example: `claude agent [agent-name] \"your message\"`\n  - Use cases\n\n### 2c. Update `docs/pages/commands.html`\n\nRegenerate the complete commands reference page:\n- Group commands by type (Workflow, Utility)\n- Include for each command:\n  - Name and description\n  - Arguments (if any)\n  - Process/workflow steps\n  - Example usage\n\n### 2d. Update `docs/pages/skills.html`\n\nRegenerate the complete skills reference page:\n- Group skills by category (Development Tools, Content & Workflow, Image Generation)\n- Include for each skill:\n  - Name and description\n  - Usage: `claude skill [skill-name]`\n  - Features and capabilities\n\n### 2e. Update `docs/pages/mcp-servers.html`\n\nRegenerate the MCP servers reference page:\n- For each server:\n  - Name and purpose\n  - Tools provided\n  - Configuration details\n  - Supported frameworks/services\n\n## Step 3: Update Metadata Files\n\nEnsure counts are consistent across:\n\n1. **`plugins/compound-engineering/.claude-plugin/plugin.json`**\n   - Update `description` with correct counts\n   - Update `components` object with counts\n   - Update `agents`, `commands` arrays with current items\n\n2. **`.claude-plugin/marketplace.json`**\n   - Update plugin `description` with correct counts\n\n3. **`plugins/compound-engineering/README.md`**\n   - Update intro paragraph with counts\n   - Update component lists\n\n## Step 4: Validate\n\nRun validation checks:\n\n```bash\n# Validate JSON files\ncat .claude-plugin/marketplace.json | jq .\ncat plugins/compound-engineering/.claude-plugin/plugin.json | jq .\n\n# Verify counts match\necho \"Agents in files: $(ls plugins/compound-engineering/agents/*.md | wc -l)\"\ngrep -o \"[0-9]* specialized agents\" plugins/compound-engineering/docs/index.html\n\necho \"Commands in files: $(ls plugins/compound-engineering/commands/*.md | wc -l)\"\ngrep -o \"[0-9]* slash commands\" plugins/compound-engineering/docs/index.html\n```\n\n## Step 5: Report Changes\n\nProvide a summary of what was updated:\n\n```\n## Documentation Release Summary\n\n### Component Counts\n- Agents: X (previously Y)\n- Commands: X (previously Y)\n- Skills: X (previously Y)\n- MCP Servers: X (previously Y)\n\n### Files Updated\n- docs/index.html - Updated stats and component summaries\n- docs/pages/agents.html - Regenerated with X agents\n- docs/pages/commands.html - Regenerated with X commands\n- docs/pages/skills.html - Regenerated with X skills\n- docs/pages/mcp-servers.html - Regenerated with X servers\n- plugin.json - Updated counts and component lists\n- marketplace.json - Updated description\n- README.md - Updated component lists\n\n### New Components Added\n- [List any new agents/commands/skills]\n\n### Components Removed\n- [List any removed agents/commands/skills]\n```\n\n## Dry Run Mode\n\nIf `--dry-run` is specified:\n- Perform all inventory and validation steps\n- Report what WOULD be updated\n- Do NOT write any files\n- Show diff previews of proposed changes\n\n## Error Handling\n\n- If component files have invalid frontmatter, report the error and skip\n- If JSON validation fails, report and abort\n- Always maintain a valid state - don't partially update\n\n## Post-Release\n\nAfter successful release:\n1. Suggest updating CHANGELOG.md with documentation changes\n2. Remind to commit with message: `docs: Update documentation site to match plugin components`\n3. Remind to push changes\n\n## Usage Examples\n\n```bash\n# Full documentation release\nclaude /release-docs\n\n# Preview changes without writing\nclaude /release-docs --dry-run\n\n# After adding new agents\nclaude /release-docs\n```"
              },
              {
                "name": "/report-bug",
                "description": "Report a bug in the compound-engineering plugin",
                "path": "plugins/compound-engineering/commands/report-bug.md",
                "frontmatter": {
                  "name": "report-bug",
                  "description": "Report a bug in the compound-engineering plugin",
                  "argument-hint": "[optional: brief description of the bug]"
                },
                "content": "# Report a Compounding Engineering Plugin Bug\n\nReport bugs encountered while using the compound-engineering plugin. This command gathers structured information and creates a GitHub issue for the maintainer.\n\n## Step 1: Gather Bug Information\n\nUse the AskUserQuestion tool to collect the following information:\n\n**Question 1: Bug Category**\n- What type of issue are you experiencing?\n- Options: Agent not working, Command not working, Skill not working, MCP server issue, Installation problem, Other\n\n**Question 2: Specific Component**\n- Which specific component is affected?\n- Ask for the name of the agent, command, skill, or MCP server\n\n**Question 3: What Happened (Actual Behavior)**\n- Ask: \"What happened when you used this component?\"\n- Get a clear description of the actual behavior\n\n**Question 4: What Should Have Happened (Expected Behavior)**\n- Ask: \"What did you expect to happen instead?\"\n- Get a clear description of expected behavior\n\n**Question 5: Steps to Reproduce**\n- Ask: \"What steps did you take before the bug occurred?\"\n- Get reproduction steps\n\n**Question 6: Error Messages**\n- Ask: \"Did you see any error messages? If so, please share them.\"\n- Capture any error output\n\n## Step 2: Collect Environment Information\n\nAutomatically gather:\n```bash\n# Get plugin version\ncat ~/.claude/plugins/installed_plugins.json 2>/dev/null | grep -A5 \"compound-engineering\" | head -10 || echo \"Plugin info not found\"\n\n# Get Claude Code version\nclaude --version 2>/dev/null || echo \"Claude CLI version unknown\"\n\n# Get OS info\nuname -a\n```\n\n## Step 3: Format the Bug Report\n\nCreate a well-structured bug report with:\n\n```markdown\n## Bug Description\n\n**Component:** [Type] - [Name]\n**Summary:** [Brief description from argument or collected info]\n\n## Environment\n\n- **Plugin Version:** [from installed_plugins.json]\n- **Claude Code Version:** [from claude --version]\n- **OS:** [from uname]\n\n## What Happened\n\n[Actual behavior description]\n\n## Expected Behavior\n\n[Expected behavior description]\n\n## Steps to Reproduce\n\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\n## Error Messages\n\n```\n[Any error output]\n```\n\n## Additional Context\n\n[Any other relevant information]\n\n---\n*Reported via `/report-bug` command*\n```\n\n## Step 4: Create GitHub Issue\n\nUse the GitHub CLI to create the issue:\n\n```bash\ngh issue create \\\n  --repo EveryInc/every-marketplace \\\n  --title \"[compound-engineering] Bug: [Brief description]\" \\\n  --body \"[Formatted bug report from Step 3]\" \\\n  --label \"bug,compound-engineering\"\n```\n\n**Note:** If labels don't exist, create without labels:\n```bash\ngh issue create \\\n  --repo EveryInc/every-marketplace \\\n  --title \"[compound-engineering] Bug: [Brief description]\" \\\n  --body \"[Formatted bug report]\"\n```\n\n## Step 5: Confirm Submission\n\nAfter the issue is created:\n1. Display the issue URL to the user\n2. Thank them for reporting the bug\n3. Let them know the maintainer (Kieran Klaassen) will be notified\n\n## Output Format\n\n```\n‚úÖ Bug report submitted successfully!\n\nIssue: https://github.com/EveryInc/every-marketplace/issues/[NUMBER]\nTitle: [compound-engineering] Bug: [description]\n\nThank you for helping improve the compound-engineering plugin!\nThe maintainer will review your report and respond as soon as possible.\n```\n\n## Error Handling\n\n- If `gh` CLI is not authenticated: Prompt user to run `gh auth login` first\n- If issue creation fails: Display the formatted report so user can manually create the issue\n- If required information is missing: Re-prompt for that specific field\n\n## Privacy Notice\n\nThis command does NOT collect:\n- Personal information\n- API keys or credentials\n- Private code from your projects\n- File paths beyond basic OS info\n\nOnly technical information about the bug is included in the report."
              },
              {
                "name": "/reproduce-bug",
                "description": "Reproduce and investigate a bug using logs, console inspection, and browser screenshots",
                "path": "plugins/compound-engineering/commands/reproduce-bug.md",
                "frontmatter": {
                  "name": "reproduce-bug",
                  "description": "Reproduce and investigate a bug using logs, console inspection, and browser screenshots",
                  "argument-hint": "[GitHub issue number]"
                },
                "content": "# Reproduce Bug Command\n\nLook at github issue #$ARGUMENTS and read the issue description and comments.\n\n## Phase 1: Log Investigation\n\nRun the following agents in parallel to investigate the bug:\n\n1. Task rails-console-explorer(issue_description)\n2. Task appsignal-log-investigator(issue_description)\n\nThink about the places it could go wrong looking at the codebase. Look for logging output we can look for.\n\nRun the agents again to find any logs that could help us reproduce the bug.\n\nKeep running these agents until you have a good idea of what is going on.\n\n## Phase 2: Visual Reproduction with Playwright\n\nIf the bug is UI-related or involves user flows, use Playwright to visually reproduce it:\n\n### Step 1: Verify Server is Running\n\n```\nmcp__plugin_compound-engineering_pw__browser_navigate({ url: \"http://localhost:3000\" })\nmcp__plugin_compound-engineering_pw__browser_snapshot({})\n```\n\nIf server not running, inform user to start `bin/dev`.\n\n### Step 2: Navigate to Affected Area\n\nBased on the issue description, navigate to the relevant page:\n\n```\nmcp__plugin_compound-engineering_pw__browser_navigate({ url: \"http://localhost:3000/[affected_route]\" })\nmcp__plugin_compound-engineering_pw__browser_snapshot({})\n```\n\n### Step 3: Capture Screenshots\n\nTake screenshots at each step of reproducing the bug:\n\n```\nmcp__plugin_compound-engineering_pw__browser_take_screenshot({ filename: \"bug-[issue]-step-1.png\" })\n```\n\n### Step 4: Follow User Flow\n\nReproduce the exact steps from the issue:\n\n1. **Read the issue's reproduction steps**\n2. **Execute each step using Playwright:**\n   - `browser_click` for clicking elements\n   - `browser_type` for filling forms\n   - `browser_snapshot` to see the current state\n   - `browser_take_screenshot` to capture evidence\n\n3. **Check for console errors:**\n   ```\n   mcp__plugin_compound-engineering_pw__browser_console_messages({ level: \"error\" })\n   ```\n\n### Step 5: Capture Bug State\n\nWhen you reproduce the bug:\n\n1. Take a screenshot of the bug state\n2. Capture console errors\n3. Document the exact steps that triggered it\n\n```\nmcp__plugin_compound-engineering_pw__browser_take_screenshot({ filename: \"bug-[issue]-reproduced.png\" })\n```\n\n## Phase 3: Document Findings\n\n**Reference Collection:**\n\n- [ ] Document all research findings with specific file paths (e.g., `app/services/example_service.rb:42`)\n- [ ] Include screenshots showing the bug reproduction\n- [ ] List console errors if any\n- [ ] Document the exact reproduction steps\n\n## Phase 4: Report Back\n\nAdd a comment to the issue with:\n\n1. **Findings** - What you discovered about the cause\n2. **Reproduction Steps** - Exact steps to reproduce (verified)\n3. **Screenshots** - Visual evidence of the bug (upload captured screenshots)\n4. **Relevant Code** - File paths and line numbers\n5. **Suggested Fix** - If you have one"
              },
              {
                "name": "/resolve_parallel",
                "description": "Resolve all TODO comments using parallel processing",
                "path": "plugins/compound-engineering/commands/resolve_parallel.md",
                "frontmatter": {
                  "name": "resolve_parallel",
                  "description": "Resolve all TODO comments using parallel processing",
                  "argument-hint": "[optional: specific TODO pattern or file]"
                },
                "content": "Resolve all TODO comments using parallel processing.\n\n## Workflow\n\n### 1. Analyze\n\nGather the things todo from above.\n\n### 2. Plan\n\nCreate a TodoWrite list of all unresolved items grouped by type.Make sure to look at dependencies that might occur and prioritize the ones needed by others. For example, if you need to change a name, you must wait to do the others. Output a mermaid flow diagram showing how we can do this. Can we do everything in parallel? Do we need to do one first that leads to others in parallel? I'll put the to-dos in the mermaid diagram flow‚Äëwise so the agent knows how to proceed in order.\n\n### 3. Implement (PARALLEL)\n\nSpawn a pr-comment-resolver agent for each unresolved item in parallel.\n\nSo if there are 3 comments, it will spawn 3 pr-comment-resolver agents in parallel. liek this\n\n1. Task pr-comment-resolver(comment1)\n2. Task pr-comment-resolver(comment2)\n3. Task pr-comment-resolver(comment3)\n\nAlways run all in parallel subagents/Tasks for each Todo item.\n\n### 4. Commit & Resolve\n\n- Commit changes\n- Push to remote"
              },
              {
                "name": "/resolve_pr_parallel",
                "description": "Resolve all PR comments using parallel processing",
                "path": "plugins/compound-engineering/commands/resolve_pr_parallel.md",
                "frontmatter": {
                  "name": "resolve_pr_parallel",
                  "description": "Resolve all PR comments using parallel processing",
                  "argument-hint": "[optional: PR number or current PR]"
                },
                "content": "Resolve all PR comments using parallel processing.\n\nClaude Code automatically detects and understands your git context:\n\n- Current branch detection\n- Associated PR context\n- All PR comments and review threads\n- Can work with any PR by specifying the PR number, or ask it.\n\n## Workflow\n\n### 1. Analyze\n\nGet all unresolved comments for PR\n\n```bash\ngh pr status\nbin/get-pr-comments PR_NUMBER\n```\n\n### 2. Plan\n\nCreate a TodoWrite list of all unresolved items grouped by type.\n\n### 3. Implement (PARALLEL)\n\nSpawn a pr-comment-resolver agent for each unresolved item in parallel.\n\nSo if there are 3 comments, it will spawn 3 pr-comment-resolver agents in parallel. liek this\n\n1. Task pr-comment-resolver(comment1)\n2. Task pr-comment-resolver(comment2)\n3. Task pr-comment-resolver(comment3)\n\nAlways run all in parallel subagents/Tasks for each Todo item.\n\n### 4. Commit & Resolve\n\n- Commit changes\n- Run bin/resolve-pr-thread THREAD_ID_1\n- Push to remote\n\nLast, check bin/get-pr-comments PR_NUMBER again to see if all comments are resolved. They should be, if not, repeat the process from 1."
              },
              {
                "name": "/resolve_todo_parallel",
                "description": "Resolve all pending CLI todos using parallel processing",
                "path": "plugins/compound-engineering/commands/resolve_todo_parallel.md",
                "frontmatter": {
                  "name": "resolve_todo_parallel",
                  "description": "Resolve all pending CLI todos using parallel processing",
                  "argument-hint": "[optional: specific todo ID or pattern]"
                },
                "content": "Resolve all TODO comments using parallel processing.\n\n## Workflow\n\n### 1. Analyze\n\nGet all unresolved TODOs from the /todos/\\*.md directory\n\n### 2. Plan\n\nCreate a TodoWrite list of all unresolved items grouped by type.Make sure to look at dependencies that might occur and prioritize the ones needed by others. For example, if you need to change a name, you must wait to do the others. Output a mermaid flow diagram showing how we can do this. Can we do everything in parallel? Do we need to do one first that leads to others in parallel? I'll put the to-dos in the mermaid diagram flow‚Äëwise so the agent knows how to proceed in order.\n\n### 3. Implement (PARALLEL)\n\nSpawn a pr-comment-resolver agent for each unresolved item in parallel.\n\nSo if there are 3 comments, it will spawn 3 pr-comment-resolver agents in parallel. liek this\n\n1. Task pr-comment-resolver(comment1)\n2. Task pr-comment-resolver(comment2)\n3. Task pr-comment-resolver(comment3)\n\nAlways run all in parallel subagents/Tasks for each Todo item.\n\n### 4. Commit & Resolve\n\n- Commit changes\n- Remove the TODO from the file, and mark it as resolved.\n- Push to remote"
              },
              {
                "name": "/triage",
                "description": "Triage and categorize findings for the CLI todo system",
                "path": "plugins/compound-engineering/commands/triage.md",
                "frontmatter": {
                  "name": "triage",
                  "description": "Triage and categorize findings for the CLI todo system",
                  "argument-hint": "[findings list or source type]"
                },
                "content": "- First set the /model to Haiku\n- Then read all pending todos in the todos/ directory\n\nPresent all findings, decisions, or issues here one by one for triage. The goal is to go through each item and decide whether to add it to the CLI todo system.\n\n**IMPORTANT: DO NOT CODE ANYTHING DURING TRIAGE!**\n\nThis command is for:\n\n- Triaging code review findings\n- Processing security audit results\n- Reviewing performance analysis\n- Handling any other categorized findings that need tracking\n\n## Workflow\n\n### Step 1: Present Each Finding\n\nFor each finding, present in this format:\n\n```\n---\nIssue #X: [Brief Title]\n\nSeverity: üî¥ P1 (CRITICAL) / üü° P2 (IMPORTANT) / üîµ P3 (NICE-TO-HAVE)\n\nCategory: [Security/Performance/Architecture/Bug/Feature/etc.]\n\nDescription:\n[Detailed explanation of the issue or improvement]\n\nLocation: [file_path:line_number]\n\nProblem Scenario:\n[Step by step what's wrong or could happen]\n\nProposed Solution:\n[How to fix it]\n\nEstimated Effort: [Small (< 2 hours) / Medium (2-8 hours) / Large (> 8 hours)]\n\n---\nDo you want to add this to the todo list?\n1. yes - create todo file\n2. next - skip this item\n3. custom - modify before creating\n```\n\n### Step 2: Handle User Decision\n\n**When user says \"yes\":**\n\n1. **Update existing todo file** (if it exists) or **Create new filename:**\n\n   If todo already exists (from code review):\n\n   - Rename file from `{id}-pending-{priority}-{desc}.md` ‚Üí `{id}-ready-{priority}-{desc}.md`\n   - Update YAML frontmatter: `status: pending` ‚Üí `status: ready`\n   - Keep issue_id, priority, and description unchanged\n\n   If creating new todo:\n\n   ```\n   {next_id}-ready-{priority}-{brief-description}.md\n   ```\n\n   Priority mapping:\n\n   - üî¥ P1 (CRITICAL) ‚Üí `p1`\n   - üü° P2 (IMPORTANT) ‚Üí `p2`\n   - üîµ P3 (NICE-TO-HAVE) ‚Üí `p3`\n\n   Example: `042-ready-p1-transaction-boundaries.md`\n\n2. **Update YAML frontmatter:**\n\n   ```yaml\n   ---\n   status: ready # IMPORTANT: Change from \"pending\" to \"ready\"\n   priority: p1 # or p2, p3 based on severity\n   issue_id: \"042\"\n   tags: [category, relevant-tags]\n   dependencies: []\n   ---\n   ```\n\n3. **Populate or update the file:**\n\n   ```yaml\n   # [Issue Title]\n\n   ## Problem Statement\n   [Description from finding]\n\n   ## Findings\n   - [Key discoveries]\n   - Location: [file_path:line_number]\n   - [Scenario details]\n\n   ## Proposed Solutions\n\n   ### Option 1: [Primary solution]\n   - **Pros**: [Benefits]\n   - **Cons**: [Drawbacks if any]\n   - **Effort**: [Small/Medium/Large]\n   - **Risk**: [Low/Medium/High]\n\n   ## Recommended Action\n   [Filled during triage - specific action plan]\n\n   ## Technical Details\n   - **Affected Files**: [List files]\n   - **Related Components**: [Components affected]\n   - **Database Changes**: [Yes/No - describe if yes]\n\n   ## Resources\n   - Original finding: [Source of this issue]\n   - Related issues: [If any]\n\n   ## Acceptance Criteria\n   - [ ] [Specific success criteria]\n   - [ ] Tests pass\n   - [ ] Code reviewed\n\n   ## Work Log\n\n   ### {date} - Approved for Work\n   **By:** Claude Triage System\n   **Actions:**\n   - Issue approved during triage session\n   - Status changed from pending ‚Üí ready\n   - Ready to be picked up and worked on\n\n   **Learnings:**\n   - [Context and insights]\n\n   ## Notes\n   Source: Triage session on {date}\n   ```\n\n4. **Confirm approval:** \"‚úÖ Approved: `{new_filename}` (Issue #{issue_id}) - Status: **ready** ‚Üí Ready to work on\"\n\n**When user says \"next\":**\n\n- **Delete the todo file** - Remove it from todos/ directory since it's not relevant\n- Skip to the next item\n- Track skipped items for summary\n\n**When user says \"custom\":**\n\n- Ask what to modify (priority, description, details)\n- Update the information\n- Present revised version\n- Ask again: yes/next/custom\n\n### Step 3: Continue Until All Processed\n\n- Process all items one by one\n- Track using TodoWrite for visibility\n- Don't wait for approval between items - keep moving\n\n### Step 4: Final Summary\n\nAfter all items processed:\n\n````markdown\n## Triage Complete\n\n**Total Items:** [X] **Todos Approved (ready):** [Y] **Skipped:** [Z]\n\n### Approved Todos (Ready for Work):\n\n- `042-ready-p1-transaction-boundaries.md` - Transaction boundary issue\n- `043-ready-p2-cache-optimization.md` - Cache performance improvement ...\n\n### Skipped Items (Deleted):\n\n- Item #5: [reason] - Removed from todos/\n- Item #12: [reason] - Removed from todos/\n\n### Summary of Changes Made:\n\nDuring triage, the following status updates occurred:\n\n- **Pending ‚Üí Ready:** Filenames and frontmatter updated to reflect approved status\n- **Deleted:** Todo files for skipped findings removed from todos/ directory\n- Each approved file now has `status: ready` in YAML frontmatter\n\n### Next Steps:\n\n1. View approved todos ready for work:\n   ```bash\n   ls todos/*-ready-*.md\n   ```\n````\n\n2. Start work on approved items:\n\n   ```bash\n   /resolve_todo_parallel  # Work on multiple approved items efficiently\n   ```\n\n3. Or pick individual items to work on\n\n4. As you work, update todo status:\n   - Ready ‚Üí In Progress (in your local context as you work)\n   - In Progress ‚Üí Complete (rename file: ready ‚Üí complete, update frontmatter)\n\n```\n\n## Example Response Format\n\n```\n\n---\n\nIssue #5: Missing Transaction Boundaries for Multi-Step Operations\n\nSeverity: üî¥ P1 (CRITICAL)\n\nCategory: Data Integrity / Security\n\nDescription: The google_oauth2_connected callback in GoogleOauthCallbacks concern performs multiple database operations without transaction protection. If any step fails midway, the database is left in an inconsistent state.\n\nLocation: app/controllers/concerns/google_oauth_callbacks.rb:13-50\n\nProblem Scenario:\n\n1. User.update succeeds (email changed)\n2. Account.save! fails (validation error)\n3. Result: User has changed email but no associated Account\n4. Next login attempt fails completely\n\nOperations Without Transaction:\n\n- User confirmation (line 13)\n- Waitlist removal (line 14)\n- User profile update (line 21-23)\n- Account creation (line 28-37)\n- Avatar attachment (line 39-45)\n- Journey creation (line 47)\n\nProposed Solution: Wrap all operations in ApplicationRecord.transaction do ... end block\n\nEstimated Effort: Small (30 minutes)\n\n---\n\nDo you want to add this to the todo list?\n\n1. yes - create todo file\n2. next - skip this item\n3. custom - modify before creating\n\n```\n\n## Important Implementation Details\n\n### Status Transitions During Triage\n\n**When \"yes\" is selected:**\n1. Rename file: `{id}-pending-{priority}-{desc}.md` ‚Üí `{id}-ready-{priority}-{desc}.md`\n2. Update YAML frontmatter: `status: pending` ‚Üí `status: ready`\n3. Update Work Log with triage approval entry\n4. Confirm: \"‚úÖ Approved: `{filename}` (Issue #{issue_id}) - Status: **ready**\"\n\n**When \"next\" is selected:**\n1. Delete the todo file from todos/ directory\n2. Skip to next item\n3. No file remains in the system\n\n### Progress Tracking\n\nEvery time you present a todo as a header, include:\n- **Progress:** X/Y completed (e.g., \"3/10 completed\")\n- **Estimated time remaining:** Based on how quickly you're progressing\n- **Pacing:** Monitor time per finding and adjust estimate accordingly\n\nExample:\n```\n\nProgress: 3/10 completed | Estimated time: ~2 minutes remaining\n\n```\n\n### Do Not Code During Triage\n\n- ‚úÖ Present findings\n- ‚úÖ Make yes/next/custom decisions\n- ‚úÖ Update todo files (rename, frontmatter, work log)\n- ‚ùå Do NOT implement fixes or write code\n- ‚ùå Do NOT add detailed implementation details\n- ‚ùå That's for /resolve_todo_parallel phase\n```\n\nWhen done give these options\n\n```markdown\nWhat would you like to do next?\n\n1. run /resolve_todo_parallel to resolve the todos\n2. commit the todos\n3. nothing, go chill\n```"
              },
              {
                "name": "/xcode-test",
                "description": "Build and test iOS apps on simulator using XcodeBuildMCP",
                "path": "plugins/compound-engineering/commands/xcode-test.md",
                "frontmatter": {
                  "name": "xcode-test",
                  "description": "Build and test iOS apps on simulator using XcodeBuildMCP",
                  "argument-hint": "[scheme name or 'current' to use default]"
                },
                "content": "# Xcode Test Command\n\n<command_purpose>Build, install, and test iOS apps on the simulator using XcodeBuildMCP. Captures screenshots, logs, and verifies app behavior.</command_purpose>\n\n## Introduction\n\n<role>iOS QA Engineer specializing in simulator-based testing</role>\n\nThis command tests iOS/macOS apps by:\n- Building for simulator\n- Installing and launching the app\n- Taking screenshots of key screens\n- Capturing console logs for errors\n- Supporting human verification for external flows\n\n## Prerequisites\n\n<requirements>\n- Xcode installed with command-line tools\n- XcodeBuildMCP server connected\n- Valid Xcode project or workspace\n- At least one iOS Simulator available\n</requirements>\n\n## Main Tasks\n\n### 0. Verify XcodeBuildMCP is Installed\n\n<check_mcp_installed>\n\n**First, check if XcodeBuildMCP tools are available.**\n\nTry calling:\n```\nmcp__xcodebuildmcp__list_simulators({})\n```\n\n**If the tool is not found or errors:**\n\nTell the user:\n```markdown\n**XcodeBuildMCP not installed**\n\nPlease install the XcodeBuildMCP server first:\n\n\\`\\`\\`bash\nclaude mcp add XcodeBuildMCP -- npx xcodebuildmcp@latest\n\\`\\`\\`\n\nThen restart Claude Code and run `/xcode-test` again.\n```\n\n**Do NOT proceed** until XcodeBuildMCP is confirmed working.\n\n</check_mcp_installed>\n\n### 1. Discover Project and Scheme\n\n<discover_project>\n\n**Find available projects:**\n```\nmcp__xcodebuildmcp__discover_projs({})\n```\n\n**List schemes for the project:**\n```\nmcp__xcodebuildmcp__list_schemes({ project_path: \"/path/to/Project.xcodeproj\" })\n```\n\n**If argument provided:**\n- Use the specified scheme name\n- Or \"current\" to use the default/last-used scheme\n\n</discover_project>\n\n### 2. Boot Simulator\n\n<boot_simulator>\n\n**List available simulators:**\n```\nmcp__xcodebuildmcp__list_simulators({})\n```\n\n**Boot preferred simulator (iPhone 15 Pro recommended):**\n```\nmcp__xcodebuildmcp__boot_simulator({ simulator_id: \"[uuid]\" })\n```\n\n**Wait for simulator to be ready:**\nCheck simulator state before proceeding with installation.\n\n</boot_simulator>\n\n### 3. Build the App\n\n<build_app>\n\n**Build for iOS Simulator:**\n```\nmcp__xcodebuildmcp__build_ios_sim_app({\n  project_path: \"/path/to/Project.xcodeproj\",\n  scheme: \"[scheme_name]\"\n})\n```\n\n**Handle build failures:**\n- Capture build errors\n- Create P1 todo for each build error\n- Report to user with specific error details\n\n**On success:**\n- Note the built app path for installation\n- Proceed to installation step\n\n</build_app>\n\n### 4. Install and Launch\n\n<install_launch>\n\n**Install app on simulator:**\n```\nmcp__xcodebuildmcp__install_app_on_simulator({\n  app_path: \"/path/to/built/App.app\",\n  simulator_id: \"[uuid]\"\n})\n```\n\n**Launch the app:**\n```\nmcp__xcodebuildmcp__launch_app_on_simulator({\n  bundle_id: \"[app.bundle.id]\",\n  simulator_id: \"[uuid]\"\n})\n```\n\n**Start capturing logs:**\n```\nmcp__xcodebuildmcp__capture_sim_logs({\n  simulator_id: \"[uuid]\",\n  bundle_id: \"[app.bundle.id]\"\n})\n```\n\n</install_launch>\n\n### 5. Test Key Screens\n\n<test_screens>\n\nFor each key screen in the app:\n\n**Take screenshot:**\n```\nmcp__xcodebuildmcp__take_screenshot({\n  simulator_id: \"[uuid]\",\n  filename: \"screen-[name].png\"\n})\n```\n\n**Review screenshot for:**\n- UI elements rendered correctly\n- No error messages visible\n- Expected content displayed\n- Layout looks correct\n\n**Check logs for errors:**\n```\nmcp__xcodebuildmcp__get_sim_logs({ simulator_id: \"[uuid]\" })\n```\n\nLook for:\n- Crashes\n- Exceptions\n- Error-level log messages\n- Failed network requests\n\n</test_screens>\n\n### 6. Human Verification (When Required)\n\n<human_verification>\n\nPause for human input when testing touches:\n\n| Flow Type | What to Ask |\n|-----------|-------------|\n| Sign in with Apple | \"Please complete Sign in with Apple on the simulator\" |\n| Push notifications | \"Send a test push and confirm it appears\" |\n| In-app purchases | \"Complete a sandbox purchase\" |\n| Camera/Photos | \"Grant permissions and verify camera works\" |\n| Location | \"Allow location access and verify map updates\" |\n\nUse AskUserQuestion:\n```markdown\n**Human Verification Needed**\n\nThis test requires [flow type]. Please:\n1. [Action to take on simulator]\n2. [What to verify]\n\nDid it work correctly?\n1. Yes - continue testing\n2. No - describe the issue\n```\n\n</human_verification>\n\n### 7. Handle Failures\n\n<failure_handling>\n\nWhen a test fails:\n\n1. **Document the failure:**\n   - Take screenshot of error state\n   - Capture console logs\n   - Note reproduction steps\n\n2. **Ask user how to proceed:**\n   ```markdown\n   **Test Failed: [screen/feature]**\n\n   Issue: [description]\n   Logs: [relevant error messages]\n\n   How to proceed?\n   1. Fix now - I'll help debug and fix\n   2. Create todo - Add to todos/ for later\n   3. Skip - Continue testing other screens\n   ```\n\n3. **If \"Fix now\":**\n   - Investigate the issue in code\n   - Propose a fix\n   - Rebuild and retest\n\n4. **If \"Create todo\":**\n   - Create `{id}-pending-p1-xcode-{description}.md`\n   - Continue testing\n\n</failure_handling>\n\n### 8. Test Summary\n\n<test_summary>\n\nAfter all tests complete, present summary:\n\n```markdown\n## üì± Xcode Test Results\n\n**Project:** [project name]\n**Scheme:** [scheme name]\n**Simulator:** [simulator name]\n\n### Build: ‚úÖ Success / ‚ùå Failed\n\n### Screens Tested: [count]\n\n| Screen | Status | Notes |\n|--------|--------|-------|\n| Launch | ‚úÖ Pass | |\n| Home | ‚úÖ Pass | |\n| Settings | ‚ùå Fail | Crash on tap |\n| Profile | ‚è≠Ô∏è Skip | Requires login |\n\n### Console Errors: [count]\n- [List any errors found]\n\n### Human Verifications: [count]\n- Sign in with Apple: ‚úÖ Confirmed\n- Push notifications: ‚úÖ Confirmed\n\n### Failures: [count]\n- Settings screen - crash on navigation\n\n### Created Todos: [count]\n- `006-pending-p1-xcode-settings-crash.md`\n\n### Result: [PASS / FAIL / PARTIAL]\n```\n\n</test_summary>\n\n### 9. Cleanup\n\n<cleanup>\n\nAfter testing:\n\n**Stop log capture:**\n```\nmcp__xcodebuildmcp__stop_log_capture({ simulator_id: \"[uuid]\" })\n```\n\n**Optionally shut down simulator:**\n```\nmcp__xcodebuildmcp__shutdown_simulator({ simulator_id: \"[uuid]\" })\n```\n\n</cleanup>\n\n## Quick Usage Examples\n\n```bash\n# Test with default scheme\n/xcode-test\n\n# Test specific scheme\n/xcode-test MyApp-Debug\n\n# Test after making changes\n/xcode-test current\n```\n\n## Integration with /workflows:review\n\nWhen reviewing PRs that touch iOS code, the `/workflows:review` command can spawn this as a subagent:\n\n```\nTask general-purpose(\"Run /xcode-test for scheme [name]. Build, install on simulator, test key screens, check for crashes.\")\n```"
              }
            ],
            "skills": [
              {
                "name": "agent-native-architecture",
                "description": "Build applications where agents are first-class citizens. Use this skill when designing autonomous agents, creating MCP tools, implementing self-modifying systems, or building apps where features are outcomes achieved by agents operating in a loop.",
                "path": "plugins/compound-engineering/skills/agent-native-architecture/SKILL.md",
                "frontmatter": {
                  "name": "agent-native-architecture",
                  "description": "Build applications where agents are first-class citizens. Use this skill when designing autonomous agents, creating MCP tools, implementing self-modifying systems, or building apps where features are outcomes achieved by agents operating in a loop."
                },
                "content": "<why_now>\n## Why Now\n\nSoftware agents work reliably now. Claude Code demonstrated that an LLM with access to bash and file tools, operating in a loop until an objective is achieved, can accomplish complex multi-step tasks autonomously.\n\nThe surprising discovery: **a really good coding agent is actually a really good general-purpose agent.** The same architecture that lets Claude Code refactor a codebase can let an agent organize your files, manage your reading list, or automate your workflows.\n\nThe Claude Code SDK makes this accessible. You can build applications where features aren't code you write‚Äîthey're outcomes you describe, achieved by an agent with tools, operating in a loop until the outcome is reached.\n\nThis opens up a new field: software that works the way Claude Code works, applied to categories far beyond coding.\n</why_now>\n\n<core_principles>\n## Core Principles\n\n### 1. Parity\n\n**Whatever the user can do through the UI, the agent should be able to achieve through tools.**\n\nThis is the foundational principle. Without it, nothing else matters.\n\nImagine you build a notes app with a beautiful interface for creating, organizing, and tagging notes. A user asks the agent: \"Create a note summarizing my meeting and tag it as urgent.\"\n\nIf you built UI for creating notes but no agent capability to do the same, the agent is stuck. It might apologize or ask clarifying questions, but it can't help‚Äîeven though the action is trivial for a human using the interface.\n\n**The fix:** Ensure the agent has tools (or combinations of tools) that can accomplish anything the UI can do.\n\nThis isn't about creating a 1:1 mapping of UI buttons to tools. It's about ensuring the agent can **achieve the same outcomes**. Sometimes that's a single tool (`create_note`). Sometimes it's composing primitives (`write_file` to a notes directory with proper formatting).\n\n**The discipline:** When adding any UI capability, ask: can the agent achieve this outcome? If not, add the necessary tools or primitives.\n\nA capability map helps:\n\n| User Action | How Agent Achieves It |\n|-------------|----------------------|\n| Create a note | `write_file` to notes directory, or `create_note` tool |\n| Tag a note as urgent | `update_file` metadata, or `tag_note` tool |\n| Search notes | `search_files` or `search_notes` tool |\n| Delete a note | `delete_file` or `delete_note` tool |\n\n**The test:** Pick any action a user can take in your UI. Describe it to the agent. Can it accomplish the outcome?\n\n---\n\n### 2. Granularity\n\n**Prefer atomic primitives. Features are outcomes achieved by an agent operating in a loop.**\n\nA tool is a primitive capability: read a file, write a file, run a bash command, store a record, send a notification.\n\nA **feature** is not a function you write. It's an outcome you describe in a prompt, achieved by an agent that has tools and operates in a loop until the outcome is reached.\n\n**Less granular (limits the agent):**\n```\nTool: classify_and_organize_files(files)\n‚Üí You wrote the decision logic\n‚Üí Agent executes your code\n‚Üí To change behavior, you refactor\n```\n\n**More granular (empowers the agent):**\n```\nTools: read_file, write_file, move_file, list_directory, bash\nPrompt: \"Organize the user's downloads folder. Analyze each file,\n        determine appropriate locations based on content and recency,\n        and move them there.\"\nAgent: Operates in a loop‚Äîreads files, makes judgments, moves things,\n       checks results‚Äîuntil the folder is organized.\n‚Üí Agent makes the decisions\n‚Üí To change behavior, you edit the prompt\n```\n\n**The key shift:** The agent is pursuing an outcome with judgment, not executing a choreographed sequence. It might encounter unexpected file types, adjust its approach, or ask clarifying questions. The loop continues until the outcome is achieved.\n\nThe more atomic your tools, the more flexibly the agent can use them. If you bundle decision logic into tools, you've moved judgment back into code.\n\n**The test:** To change how a feature behaves, do you edit prose or refactor code?\n\n---\n\n### 3. Composability\n\n**With atomic tools and parity, you can create new features just by writing new prompts.**\n\nThis is the payoff of the first two principles. When your tools are atomic and the agent can do anything users can do, new features are just new prompts.\n\nWant a \"weekly review\" feature that summarizes activity and suggests priorities? That's a prompt:\n\n```\n\"Review files modified this week. Summarize key changes. Based on\nincomplete items and approaching deadlines, suggest three priorities\nfor next week.\"\n```\n\nThe agent uses `list_files`, `read_file`, and its judgment to accomplish this. You didn't write weekly-review code. You described an outcome, and the agent operates in a loop until it's achieved.\n\n**This works for developers and users.** You can ship new features by adding prompts. Users can customize behavior by modifying prompts or creating their own. \"When I say 'file this,' always move it to my Action folder and tag it urgent\" becomes a user-level prompt that extends the application.\n\n**The constraint:** This only works if tools are atomic enough to be composed in ways you didn't anticipate, and if the agent has parity with users. If tools encode too much logic, or the agent can't access key capabilities, composition breaks down.\n\n**The test:** Can you add a new feature by writing a new prompt section, without adding new code?\n\n---\n\n### 4. Emergent Capability\n\n**The agent can accomplish things you didn't explicitly design for.**\n\nWhen tools are atomic, parity is maintained, and prompts are composable, users will ask the agent for things you never anticipated. And often, the agent can figure it out.\n\n*\"Cross-reference my meeting notes with my task list and tell me what I've committed to but haven't scheduled.\"*\n\nYou didn't build a \"commitment tracker\" feature. But if the agent can read notes, read tasks, and reason about them‚Äîoperating in a loop until it has an answer‚Äîit can accomplish this.\n\n**This reveals latent demand.** Instead of guessing what features users want, you observe what they're asking the agent to do. When patterns emerge, you can optimize them with domain-specific tools or dedicated prompts. But you didn't have to anticipate them‚Äîyou discovered them.\n\n**The flywheel:**\n1. Build with atomic tools and parity\n2. Users ask for things you didn't anticipate\n3. Agent composes tools to accomplish them (or fails, revealing a gap)\n4. You observe patterns in what's being requested\n5. Add domain tools or prompts to make common patterns efficient\n6. Repeat\n\nThis changes how you build products. You're not trying to imagine every feature upfront. You're creating a capable foundation and learning from what emerges.\n\n**The test:** Give the agent an open-ended request relevant to your domain. Can it figure out a reasonable approach, operating in a loop until it succeeds? If it just says \"I don't have a feature for that,\" your architecture is too constrained.\n\n---\n\n### 5. Improvement Over Time\n\n**Agent-native applications get better through accumulated context and prompt refinement.**\n\nUnlike traditional software, agent-native applications can improve without shipping code:\n\n**Accumulated context:** The agent can maintain state across sessions‚Äîwhat exists, what the user has done, what worked, what didn't. A `context.md` file the agent reads and updates is layer one. More sophisticated approaches involve structured memory and learned preferences.\n\n**Prompt refinement at multiple levels:**\n- **Developer level:** You ship updated prompts that change agent behavior for all users\n- **User level:** Users customize prompts for their workflow\n- **Agent level:** The agent modifies its own prompts based on feedback (advanced)\n\n**Self-modification (advanced):** Agents that can edit their own prompts or even their own code. For production use cases, consider adding safety rails‚Äîapproval gates, automatic checkpoints for rollback, health checks. This is where things are heading.\n\nThe improvement mechanisms are still being discovered. Context and prompt refinement are proven. Self-modification is emerging. What's clear: the architecture supports getting better in ways traditional software doesn't.\n\n**The test:** Does the application work better after a month of use than on day one, even without code changes?\n</core_principles>\n\n<intake>\n## What aspect of agent-native architecture do you need help with?\n\n1. **Design architecture** - Plan a new agent-native system from scratch\n2. **Files & workspace** - Use files as the universal interface, shared workspace patterns\n3. **Tool design** - Build primitive tools, dynamic capability discovery, CRUD completeness\n4. **Domain tools** - Know when to add domain tools vs stay with primitives\n5. **Execution patterns** - Completion signals, partial completion, context limits\n6. **System prompts** - Define agent behavior in prompts, judgment criteria\n7. **Context injection** - Inject runtime app state into agent prompts\n8. **Action parity** - Ensure agents can do everything users can do\n9. **Self-modification** - Enable agents to safely evolve themselves\n10. **Product design** - Progressive disclosure, latent demand, approval patterns\n11. **Mobile patterns** - iOS storage, background execution, checkpoint/resume\n12. **Testing** - Test agent-native apps for capability and parity\n13. **Refactoring** - Make existing code more agent-native\n\n**Wait for response before proceeding.**\n</intake>\n\n<routing>\n| Response | Action |\n|----------|--------|\n| 1, \"design\", \"architecture\", \"plan\" | Read [architecture-patterns.md](./references/architecture-patterns.md), then apply Architecture Checklist below |\n| 2, \"files\", \"workspace\", \"filesystem\" | Read [files-universal-interface.md](./references/files-universal-interface.md) and [shared-workspace-architecture.md](./references/shared-workspace-architecture.md) |\n| 3, \"tool\", \"mcp\", \"primitive\", \"crud\" | Read [mcp-tool-design.md](./references/mcp-tool-design.md) |\n| 4, \"domain tool\", \"when to add\" | Read [from-primitives-to-domain-tools.md](./references/from-primitives-to-domain-tools.md) |\n| 5, \"execution\", \"completion\", \"loop\" | Read [agent-execution-patterns.md](./references/agent-execution-patterns.md) |\n| 6, \"prompt\", \"system prompt\", \"behavior\" | Read [system-prompt-design.md](./references/system-prompt-design.md) |\n| 7, \"context\", \"inject\", \"runtime\", \"dynamic\" | Read [dynamic-context-injection.md](./references/dynamic-context-injection.md) |\n| 8, \"parity\", \"ui action\", \"capability map\" | Read [action-parity-discipline.md](./references/action-parity-discipline.md) |\n| 9, \"self-modify\", \"evolve\", \"git\" | Read [self-modification.md](./references/self-modification.md) |\n| 10, \"product\", \"progressive\", \"approval\", \"latent demand\" | Read [product-implications.md](./references/product-implications.md) |\n| 11, \"mobile\", \"ios\", \"android\", \"background\", \"checkpoint\" | Read [mobile-patterns.md](./references/mobile-patterns.md) |\n| 12, \"test\", \"testing\", \"verify\", \"validate\" | Read [agent-native-testing.md](./references/agent-native-testing.md) |\n| 13, \"review\", \"refactor\", \"existing\" | Read [refactoring-to-prompt-native.md](./references/refactoring-to-prompt-native.md) |\n\n**After reading the reference, apply those patterns to the user's specific context.**\n</routing>\n\n<architecture_checklist>\n## Architecture Review Checklist\n\nWhen designing an agent-native system, verify these **before implementation**:\n\n### Core Principles\n- [ ] **Parity:** Every UI action has a corresponding agent capability\n- [ ] **Granularity:** Tools are primitives; features are prompt-defined outcomes\n- [ ] **Composability:** New features can be added via prompts alone\n- [ ] **Emergent Capability:** Agent can handle open-ended requests in your domain\n\n### Tool Design\n- [ ] **Dynamic vs Static:** For external APIs where agent should have full access, use Dynamic Capability Discovery\n- [ ] **CRUD Completeness:** Every entity has create, read, update, AND delete\n- [ ] **Primitives not Workflows:** Tools enable capability, don't encode business logic\n- [ ] **API as Validator:** Use `z.string()` inputs when the API validates, not `z.enum()`\n\n### Files & Workspace\n- [ ] **Shared Workspace:** Agent and user work in same data space\n- [ ] **context.md Pattern:** Agent reads/updates context file for accumulated knowledge\n- [ ] **File Organization:** Entity-scoped directories with consistent naming\n\n### Agent Execution\n- [ ] **Completion Signals:** Agent has explicit `complete_task` tool (not heuristic detection)\n- [ ] **Partial Completion:** Multi-step tasks track progress for resume\n- [ ] **Context Limits:** Designed for bounded context from the start\n\n### Context Injection\n- [ ] **Available Resources:** System prompt includes what exists (files, data, types)\n- [ ] **Available Capabilities:** System prompt documents tools with user vocabulary\n- [ ] **Dynamic Context:** Context refreshes for long sessions (or provide `refresh_context` tool)\n\n### UI Integration\n- [ ] **Agent ‚Üí UI:** Agent changes reflect in UI (shared service, file watching, or event bus)\n- [ ] **No Silent Actions:** Agent writes trigger UI updates immediately\n- [ ] **Capability Discovery:** Users can learn what agent can do\n\n### Mobile (if applicable)\n- [ ] **Checkpoint/Resume:** Handle iOS app suspension gracefully\n- [ ] **iCloud Storage:** iCloud-first with local fallback for multi-device sync\n- [ ] **Cost Awareness:** Model tier selection (Haiku/Sonnet/Opus)\n\n**When designing architecture, explicitly address each checkbox in your plan.**\n</architecture_checklist>\n\n<quick_start>\n## Quick Start: Build an Agent-Native Feature\n\n**Step 1: Define atomic tools**\n```typescript\nconst tools = [\n  tool(\"read_file\", \"Read any file\", { path: z.string() }, ...),\n  tool(\"write_file\", \"Write any file\", { path: z.string(), content: z.string() }, ...),\n  tool(\"list_files\", \"List directory\", { path: z.string() }, ...),\n  tool(\"complete_task\", \"Signal task completion\", { summary: z.string() }, ...),\n];\n```\n\n**Step 2: Write behavior in the system prompt**\n```markdown\n## Your Responsibilities\nWhen asked to organize content, you should:\n1. Read existing files to understand the structure\n2. Analyze what organization makes sense\n3. Create/move files using your tools\n4. Use your judgment about layout and formatting\n5. Call complete_task when you're done\n\nYou decide the structure. Make it good.\n```\n\n**Step 3: Let the agent work in a loop**\n```typescript\nconst result = await agent.run({\n  prompt: userMessage,\n  tools: tools,\n  systemPrompt: systemPrompt,\n  // Agent loops until it calls complete_task\n});\n```\n</quick_start>\n\n<reference_index>\n## Reference Files\n\nAll references in `references/`:\n\n**Core Patterns:**\n- [architecture-patterns.md](./references/architecture-patterns.md) - Event-driven, unified orchestrator, agent-to-UI\n- [files-universal-interface.md](./references/files-universal-interface.md) - Why files, organization patterns, context.md\n- [mcp-tool-design.md](./references/mcp-tool-design.md) - Tool design, dynamic capability discovery, CRUD\n- [from-primitives-to-domain-tools.md](./references/from-primitives-to-domain-tools.md) - When to add domain tools, graduating to code\n- [agent-execution-patterns.md](./references/agent-execution-patterns.md) - Completion signals, partial completion, context limits\n- [system-prompt-design.md](./references/system-prompt-design.md) - Features as prompts, judgment criteria\n\n**Agent-Native Disciplines:**\n- [dynamic-context-injection.md](./references/dynamic-context-injection.md) - Runtime context, what to inject\n- [action-parity-discipline.md](./references/action-parity-discipline.md) - Capability mapping, parity workflow\n- [shared-workspace-architecture.md](./references/shared-workspace-architecture.md) - Shared data space, UI integration\n- [product-implications.md](./references/product-implications.md) - Progressive disclosure, latent demand, approval\n- [agent-native-testing.md](./references/agent-native-testing.md) - Testing outcomes, parity tests\n\n**Platform-Specific:**\n- [mobile-patterns.md](./references/mobile-patterns.md) - iOS storage, checkpoint/resume, cost awareness\n- [self-modification.md](./references/self-modification.md) - Git-based evolution, guardrails\n- [refactoring-to-prompt-native.md](./references/refactoring-to-prompt-native.md) - Migrating existing code\n</reference_index>\n\n<anti_patterns>\n## Anti-Patterns\n\n### Common Approaches That Aren't Fully Agent-Native\n\nThese aren't necessarily wrong‚Äîthey may be appropriate for your use case. But they're worth recognizing as different from the architecture this document describes.\n\n**Agent as router** ‚Äî The agent figures out what the user wants, then calls the right function. The agent's intelligence is used to route, not to act. This can work, but you're using a fraction of what agents can do.\n\n**Build the app, then add agent** ‚Äî You build features the traditional way (as code), then expose them to an agent. The agent can only do what your features already do. You won't get emergent capability.\n\n**Request/response thinking** ‚Äî Agent gets input, does one thing, returns output. This misses the loop: agent gets an outcome to achieve, operates until it's done, handles unexpected situations along the way.\n\n**Defensive tool design** ‚Äî You over-constrain tool inputs because you're used to defensive programming. Strict enums, validation at every layer. This is safe, but it prevents the agent from doing things you didn't anticipate.\n\n**Happy path in code, agent just executes** ‚Äî Traditional software handles edge cases in code‚Äîyou write the logic for what happens when X goes wrong. Agent-native lets the agent handle edge cases with judgment. If your code handles all the edge cases, the agent is just a caller.\n\n---\n\n### Specific Anti-Patterns\n\n**THE CARDINAL SIN: Agent executes your code instead of figuring things out**\n\n```typescript\n// WRONG - You wrote the workflow, agent just executes it\ntool(\"process_feedback\", async ({ message }) => {\n  const category = categorize(message);      // Your code decides\n  const priority = calculatePriority(message); // Your code decides\n  await store(message, category, priority);   // Your code orchestrates\n  if (priority > 3) await notify();           // Your code decides\n});\n\n// RIGHT - Agent figures out how to process feedback\ntools: store_item, send_message  // Primitives\nprompt: \"Rate importance 1-5 based on actionability, store feedback, notify if >= 4\"\n```\n\n**Workflow-shaped tools** ‚Äî `analyze_and_organize` bundles judgment into the tool. Break it into primitives and let the agent compose them.\n\n**Context starvation** ‚Äî Agent doesn't know what resources exist in the app.\n```\nUser: \"Write something about Catherine the Great in my feed\"\nAgent: \"What feed? I don't understand what system you're referring to.\"\n```\nFix: Inject available resources, capabilities, and vocabulary into system prompt.\n\n**Orphan UI actions** ‚Äî User can do something through the UI that the agent can't achieve. Fix: maintain parity.\n\n**Silent actions** ‚Äî Agent changes state but UI doesn't update. Fix: Use shared data stores with reactive binding, or file system observation.\n\n**Heuristic completion detection** ‚Äî Detecting agent completion through heuristics (consecutive iterations without tool calls, checking for expected output files). This is fragile. Fix: Require agents to explicitly signal completion through a `complete_task` tool.\n\n**Static tool mapping for dynamic APIs** ‚Äî Building 50 tools for 50 API endpoints when a `discover` + `access` pattern would give more flexibility.\n```typescript\n// WRONG - Every API type needs a hardcoded tool\ntool(\"read_steps\", ...)\ntool(\"read_heart_rate\", ...)\ntool(\"read_sleep\", ...)\n// When glucose tracking is added... code change required\n\n// RIGHT - Dynamic capability discovery\ntool(\"list_available_types\", ...)  // Discover what's available\ntool(\"read_health_data\", { dataType: z.string() }, ...)  // Access any type\n```\n\n**Incomplete CRUD** ‚Äî Agent can create but not update or delete.\n```typescript\n// User: \"Delete that journal entry\"\n// Agent: \"I don't have a tool for that\"\ntool(\"create_journal_entry\", ...)  // Missing: update, delete\n```\nFix: Every entity needs full CRUD.\n\n**Sandbox isolation** ‚Äî Agent works in separate data space from user.\n```\nDocuments/\n‚îú‚îÄ‚îÄ user_files/        ‚Üê User's space\n‚îî‚îÄ‚îÄ agent_output/      ‚Üê Agent's space (isolated)\n```\nFix: Use shared workspace where both operate on same files.\n\n**Gates without reason** ‚Äî Domain tool is the only way to do something, and you didn't intend to restrict access. The default is open. Keep primitives available unless there's a specific reason to gate.\n\n**Artificial capability limits** ‚Äî Restricting what the agent can do out of vague safety concerns rather than specific risks. Be thoughtful about restricting capabilities. The agent should generally be able to do what users can do.\n</anti_patterns>\n\n<success_criteria>\n## Success Criteria\n\nYou've built an agent-native application when:\n\n### Architecture\n- [ ] The agent can achieve anything users can achieve through the UI (parity)\n- [ ] Tools are atomic primitives; domain tools are shortcuts, not gates (granularity)\n- [ ] New features can be added by writing new prompts (composability)\n- [ ] The agent can accomplish tasks you didn't explicitly design for (emergent capability)\n- [ ] Changing behavior means editing prompts, not refactoring code\n\n### Implementation\n- [ ] System prompt includes dynamic context about app state\n- [ ] Every UI action has a corresponding agent tool (action parity)\n- [ ] Agent tools are documented in system prompt with user vocabulary\n- [ ] Agent and user work in the same data space (shared workspace)\n- [ ] Agent actions are immediately reflected in the UI\n- [ ] Every entity has full CRUD (Create, Read, Update, Delete)\n- [ ] Agents explicitly signal completion (no heuristic detection)\n- [ ] context.md or equivalent for accumulated knowledge\n\n### Product\n- [ ] Simple requests work immediately with no learning curve\n- [ ] Power users can push the system in unexpected directions\n- [ ] You're learning what users want by observing what they ask the agent to do\n- [ ] Approval requirements match stakes and reversibility\n\n### Mobile (if applicable)\n- [ ] Checkpoint/resume handles app interruption\n- [ ] iCloud-first storage with local fallback\n- [ ] Background execution uses available time wisely\n- [ ] Model tier matched to task complexity\n\n---\n\n### The Ultimate Test\n\n**Describe an outcome to the agent that's within your application's domain but that you didn't build a specific feature for.**\n\nCan it figure out how to accomplish it, operating in a loop until it succeeds?\n\nIf yes, you've built something agent-native.\n\nIf it says \"I don't have a feature for that\"‚Äîyour architecture is still too constrained.\n</success_criteria>"
              },
              {
                "name": "andrew-kane-gem-writer",
                "description": "This skill should be used when writing Ruby gems following Andrew Kane's proven patterns and philosophy. It applies when creating new Ruby gems, refactoring existing gems, designing gem APIs, or when clean, minimal, production-ready Ruby library code is needed. Triggers on requests like \"create a gem\", \"write a Ruby library\", \"design a gem API\", or mentions of Andrew Kane's style.",
                "path": "plugins/compound-engineering/skills/andrew-kane-gem-writer/SKILL.md",
                "frontmatter": {
                  "name": "andrew-kane-gem-writer",
                  "description": "This skill should be used when writing Ruby gems following Andrew Kane's proven patterns and philosophy. It applies when creating new Ruby gems, refactoring existing gems, designing gem APIs, or when clean, minimal, production-ready Ruby library code is needed. Triggers on requests like \"create a gem\", \"write a Ruby library\", \"design a gem API\", or mentions of Andrew Kane's style."
                },
                "content": "# Andrew Kane Gem Writer\n\nWrite Ruby gems following Andrew Kane's battle-tested patterns from 100+ gems with 374M+ downloads (Searchkick, PgHero, Chartkick, Strong Migrations, Lockbox, Ahoy, Blazer, Groupdate, Neighbor, Blind Index).\n\n## Core Philosophy\n\n**Simplicity over cleverness.** Zero or minimal dependencies. Explicit code over metaprogramming. Rails integration without Rails coupling. Every pattern serves production use cases.\n\n## Entry Point Structure\n\nEvery gem follows this exact pattern in `lib/gemname.rb`:\n\n```ruby\n# 1. Dependencies (stdlib preferred)\nrequire \"forwardable\"\n\n# 2. Internal modules\nrequire_relative \"gemname/model\"\nrequire_relative \"gemname/version\"\n\n# 3. Conditional Rails (CRITICAL - never require Rails directly)\nrequire_relative \"gemname/railtie\" if defined?(Rails)\n\n# 4. Module with config and errors\nmodule GemName\n  class Error < StandardError; end\n  class InvalidConfigError < Error; end\n\n  class << self\n    attr_accessor :timeout, :logger\n    attr_writer :client\n  end\n\n  self.timeout = 10  # Defaults set immediately\nend\n```\n\n## Class Macro DSL Pattern\n\nThe signature Kane pattern‚Äîsingle method call configures everything:\n\n```ruby\n# Usage\nclass Product < ApplicationRecord\n  searchkick word_start: [:name]\nend\n\n# Implementation\nmodule GemName\n  module Model\n    def gemname(**options)\n      unknown = options.keys - KNOWN_KEYWORDS\n      raise ArgumentError, \"unknown keywords: #{unknown.join(\", \")}\" if unknown.any?\n\n      mod = Module.new\n      mod.module_eval do\n        define_method :some_method do\n          # implementation\n        end unless method_defined?(:some_method)\n      end\n      include mod\n\n      class_eval do\n        cattr_reader :gemname_options, instance_reader: false\n        class_variable_set :@@gemname_options, options.dup\n      end\n    end\n  end\nend\n```\n\n## Rails Integration\n\n**Always use `ActiveSupport.on_load`‚Äînever require Rails gems directly:**\n\n```ruby\n# WRONG\nrequire \"active_record\"\nActiveRecord::Base.include(MyGem::Model)\n\n# CORRECT\nActiveSupport.on_load(:active_record) do\n  extend GemName::Model\nend\n\n# Use prepend for behavior modification\nActiveSupport.on_load(:active_record) do\n  ActiveRecord::Migration.prepend(GemName::Migration)\nend\n```\n\n## Configuration Pattern\n\nUse `class << self` with `attr_accessor`, not Configuration objects:\n\n```ruby\nmodule GemName\n  class << self\n    attr_accessor :timeout, :logger\n    attr_writer :master_key\n  end\n\n  def self.master_key\n    @master_key ||= ENV[\"GEMNAME_MASTER_KEY\"]\n  end\n\n  self.timeout = 10\n  self.logger = nil\nend\n```\n\n## Error Handling\n\nSimple hierarchy with informative messages:\n\n```ruby\nmodule GemName\n  class Error < StandardError; end\n  class ConfigError < Error; end\n  class ValidationError < Error; end\nend\n\n# Validate early with ArgumentError\ndef initialize(key:)\n  raise ArgumentError, \"Key must be 32 bytes\" unless key&.bytesize == 32\nend\n```\n\n## Testing (Minitest Only)\n\n```ruby\n# test/test_helper.rb\nrequire \"bundler/setup\"\nBundler.require(:default)\nrequire \"minitest/autorun\"\nrequire \"minitest/pride\"\n\n# test/model_test.rb\nclass ModelTest < Minitest::Test\n  def test_basic_functionality\n    assert_equal expected, actual\n  end\nend\n```\n\n## Gemspec Pattern\n\nZero runtime dependencies when possible:\n\n```ruby\nGem::Specification.new do |spec|\n  spec.name = \"gemname\"\n  spec.version = GemName::VERSION\n  spec.required_ruby_version = \">= 3.1\"\n  spec.files = Dir[\"*.{md,txt}\", \"{lib}/**/*\"]\n  spec.require_path = \"lib\"\n  # NO add_dependency lines - dev deps go in Gemfile\nend\n```\n\n## Anti-Patterns to Avoid\n\n- `method_missing` (use `define_method` instead)\n- Configuration objects (use class accessors)\n- `@@class_variables` (use `class << self`)\n- Requiring Rails gems directly\n- Many runtime dependencies\n- Committing Gemfile.lock in gems\n- RSpec (use Minitest)\n- Heavy DSLs (prefer explicit Ruby)\n\n## Reference Files\n\nFor deeper patterns, see:\n- **[references/module-organization.md](references/module-organization.md)** - Directory layouts, method decomposition\n- **[references/rails-integration.md](references/rails-integration.md)** - Railtie, Engine, on_load patterns\n- **[references/database-adapters.md](references/database-adapters.md)** - Multi-database support patterns\n- **[references/testing-patterns.md](references/testing-patterns.md)** - Multi-version testing, CI setup\n- **[references/resources.md](references/resources.md)** - Links to Kane's repos and articles"
              },
              {
                "name": "compound-docs",
                "description": "Capture solved problems as categorized documentation with YAML frontmatter for fast lookup",
                "path": "plugins/compound-engineering/skills/compound-docs/SKILL.md",
                "frontmatter": {
                  "name": "compound-docs",
                  "description": "Capture solved problems as categorized documentation with YAML frontmatter for fast lookup",
                  "allowed-tools": [
                    "Read",
                    "Write",
                    "Bash",
                    "Grep"
                  ],
                  "preconditions": [
                    "Problem has been solved (not in-progress)",
                    "Solution has been verified working"
                  ]
                },
                "content": "# compound-docs Skill\n\n**Purpose:** Automatically document solved problems to build searchable institutional knowledge with category-based organization (enum-validated problem types).\n\n## Overview\n\nThis skill captures problem solutions immediately after confirmation, creating structured documentation that serves as a searchable knowledge base for future sessions.\n\n**Organization:** Single-file architecture - each problem documented as one markdown file in its symptom category directory (e.g., `docs/solutions/performance-issues/n-plus-one-briefs.md`). Files use YAML frontmatter for metadata and searchability.\n\n---\n\n<critical_sequence name=\"documentation-capture\" enforce_order=\"strict\">\n\n## 7-Step Process\n\n<step number=\"1\" required=\"true\">\n### Step 1: Detect Confirmation\n\n**Auto-invoke after phrases:**\n\n- \"that worked\"\n- \"it's fixed\"\n- \"working now\"\n- \"problem solved\"\n- \"that did it\"\n\n**OR manual:** `/doc-fix` command\n\n**Non-trivial problems only:**\n\n- Multiple investigation attempts needed\n- Tricky debugging that took time\n- Non-obvious solution\n- Future sessions would benefit\n\n**Skip documentation for:**\n\n- Simple typos\n- Obvious syntax errors\n- Trivial fixes immediately corrected\n</step>\n\n<step number=\"2\" required=\"true\" depends_on=\"1\">\n### Step 2: Gather Context\n\nExtract from conversation history:\n\n**Required information:**\n\n- **Module name**: Which CORA module had the problem\n- **Symptom**: Observable error/behavior (exact error messages)\n- **Investigation attempts**: What didn't work and why\n- **Root cause**: Technical explanation of actual problem\n- **Solution**: What fixed it (code/config changes)\n- **Prevention**: How to avoid in future\n\n**Environment details:**\n\n- Rails version\n- Stage (0-6 or post-implementation)\n- OS version\n- File/line references\n\n**BLOCKING REQUIREMENT:** If critical context is missing (module name, exact error, stage, or resolution steps), ask user and WAIT for response before proceeding to Step 3:\n\n```\nI need a few details to document this properly:\n\n1. Which module had this issue? [ModuleName]\n2. What was the exact error message or symptom?\n3. What stage were you in? (0-6 or post-implementation)\n\n[Continue after user provides details]\n```\n</step>\n\n<step number=\"3\" required=\"false\" depends_on=\"2\">\n### Step 3: Check Existing Docs\n\nSearch docs/solutions/ for similar issues:\n\n```bash\n# Search by error message keywords\ngrep -r \"exact error phrase\" docs/solutions/\n\n# Search by symptom category\nls docs/solutions/[category]/\n```\n\n**IF similar issue found:**\n\nTHEN present decision options:\n\n```\nFound similar issue: docs/solutions/[path]\n\nWhat's next?\n1. Create new doc with cross-reference (recommended)\n2. Update existing doc (only if same root cause)\n3. Other\n\nChoose (1-3): _\n```\n\nWAIT for user response, then execute chosen action.\n\n**ELSE** (no similar issue found):\n\nProceed directly to Step 4 (no user interaction needed).\n</step>\n\n<step number=\"4\" required=\"true\" depends_on=\"2\">\n### Step 4: Generate Filename\n\nFormat: `[sanitized-symptom]-[module]-[YYYYMMDD].md`\n\n**Sanitization rules:**\n\n- Lowercase\n- Replace spaces with hyphens\n- Remove special characters except hyphens\n- Truncate to reasonable length (< 80 chars)\n\n**Examples:**\n\n- `missing-include-BriefSystem-20251110.md`\n- `parameter-not-saving-state-EmailProcessing-20251110.md`\n- `webview-crash-on-resize-Assistant-20251110.md`\n</step>\n\n<step number=\"5\" required=\"true\" depends_on=\"4\" blocking=\"true\">\n### Step 5: Validate YAML Schema\n\n**CRITICAL:** All docs require validated YAML frontmatter with enum validation.\n\n<validation_gate name=\"yaml-schema\" blocking=\"true\">\n\n**Validate against schema:**\nLoad `schema.yaml` and classify the problem against the enum values defined in [yaml-schema.md](./references/yaml-schema.md). Ensure all required fields are present and match allowed values exactly.\n\n**BLOCK if validation fails:**\n\n```\n‚ùå YAML validation failed\n\nErrors:\n- problem_type: must be one of schema enums, got \"compilation_error\"\n- severity: must be one of [critical, moderate, minor], got \"high\"\n- symptoms: must be array with 1-5 items, got string\n\nPlease provide corrected values.\n```\n\n**GATE ENFORCEMENT:** Do NOT proceed to Step 6 (Create Documentation) until YAML frontmatter passes all validation rules defined in `schema.yaml`.\n\n</validation_gate>\n</step>\n\n<step number=\"6\" required=\"true\" depends_on=\"5\">\n### Step 6: Create Documentation\n\n**Determine category from problem_type:** Use the category mapping defined in [yaml-schema.md](./references/yaml-schema.md) (lines 49-61).\n\n**Create documentation file:**\n\n```bash\nPROBLEM_TYPE=\"[from validated YAML]\"\nCATEGORY=\"[mapped from problem_type]\"\nFILENAME=\"[generated-filename].md\"\nDOC_PATH=\"docs/solutions/${CATEGORY}/${FILENAME}\"\n\n# Create directory if needed\nmkdir -p \"docs/solutions/${CATEGORY}\"\n\n# Write documentation using template from assets/resolution-template.md\n# (Content populated with Step 2 context and validated YAML frontmatter)\n```\n\n**Result:**\n- Single file in category directory\n- Enum validation ensures consistent categorization\n\n**Create documentation:** Populate the structure from `assets/resolution-template.md` with context gathered in Step 2 and validated YAML frontmatter from Step 5.\n</step>\n\n<step number=\"7\" required=\"false\" depends_on=\"6\">\n### Step 7: Cross-Reference & Critical Pattern Detection\n\nIf similar issues found in Step 3:\n\n**Update existing doc:**\n\n```bash\n# Add Related Issues link to similar doc\necho \"- See also: [$FILENAME]($REAL_FILE)\" >> [similar-doc.md]\n```\n\n**Update new doc:**\nAlready includes cross-reference from Step 6.\n\n**Update patterns if applicable:**\n\nIf this represents a common pattern (3+ similar issues):\n\n```bash\n# Add to docs/solutions/patterns/common-solutions.md\ncat >> docs/solutions/patterns/common-solutions.md << 'EOF'\n\n## [Pattern Name]\n\n**Common symptom:** [Description]\n**Root cause:** [Technical explanation]\n**Solution pattern:** [General approach]\n\n**Examples:**\n- [Link to doc 1]\n- [Link to doc 2]\n- [Link to doc 3]\nEOF\n```\n\n**Critical Pattern Detection (Optional Proactive Suggestion):**\n\nIf this issue has automatic indicators suggesting it might be critical:\n- Severity: `critical` in YAML\n- Affects multiple modules OR foundational stage (Stage 2 or 3)\n- Non-obvious solution\n\nThen in the decision menu (Step 8), add a note:\n```\nüí° This might be worth adding to Required Reading (Option 2)\n```\n\nBut **NEVER auto-promote**. User decides via decision menu (Option 2).\n\n**Template for critical pattern addition:**\n\nWhen user selects Option 2 (Add to Required Reading), use the template from `assets/critical-pattern-template.md` to structure the pattern entry. Number it sequentially based on existing patterns in `docs/solutions/patterns/cora-critical-patterns.md`.\n</step>\n\n</critical_sequence>\n\n---\n\n<decision_gate name=\"post-documentation\" wait_for_user=\"true\">\n\n## Decision Menu After Capture\n\nAfter successful documentation, present options and WAIT for user response:\n\n```\n‚úì Solution documented\n\nFile created:\n- docs/solutions/[category]/[filename].md\n\nWhat's next?\n1. Continue workflow (recommended)\n2. Add to Required Reading - Promote to critical patterns (cora-critical-patterns.md)\n3. Link related issues - Connect to similar problems\n4. Add to existing skill - Add to a learning skill (e.g., hotwire-native)\n5. Create new skill - Extract into new learning skill\n6. View documentation - See what was captured\n7. Other\n```\n\n**Handle responses:**\n\n**Option 1: Continue workflow**\n\n- Return to calling skill/workflow\n- Documentation is complete\n\n**Option 2: Add to Required Reading** ‚≠ê PRIMARY PATH FOR CRITICAL PATTERNS\n\nUser selects this when:\n- System made this mistake multiple times across different modules\n- Solution is non-obvious but must be followed every time\n- Foundational requirement (Rails, Rails API, threading, etc.)\n\nAction:\n1. Extract pattern from the documentation\n2. Format as ‚ùå WRONG vs ‚úÖ CORRECT with code examples\n3. Add to `docs/solutions/patterns/cora-critical-patterns.md`\n4. Add cross-reference back to this doc\n5. Confirm: \"‚úì Added to Required Reading. All subagents will see this pattern before code generation.\"\n\n**Option 3: Link related issues**\n\n- Prompt: \"Which doc to link? (provide filename or describe)\"\n- Search docs/solutions/ for the doc\n- Add cross-reference to both docs\n- Confirm: \"‚úì Cross-reference added\"\n\n**Option 4: Add to existing skill**\n\nUser selects this when the documented solution relates to an existing learning skill:\n\nAction:\n1. Prompt: \"Which skill? (hotwire-native, etc.)\"\n2. Determine which reference file to update (resources.md, patterns.md, or examples.md)\n3. Add link and brief description to appropriate section\n4. Confirm: \"‚úì Added to [skill-name] skill in [file]\"\n\nExample: For Hotwire Native Tailwind variants solution:\n- Add to `hotwire-native/references/resources.md` under \"CORA-Specific Resources\"\n- Add to `hotwire-native/references/examples.md` with link to solution doc\n\n**Option 5: Create new skill**\n\nUser selects this when the solution represents the start of a new learning domain:\n\nAction:\n1. Prompt: \"What should the new skill be called? (e.g., stripe-billing, email-processing)\"\n2. Run `python3 .claude/skills/skill-creator/scripts/init_skill.py [skill-name]`\n3. Create initial reference files with this solution as first example\n4. Confirm: \"‚úì Created new [skill-name] skill with this solution as first example\"\n\n**Option 6: View documentation**\n\n- Display the created documentation\n- Present decision menu again\n\n**Option 7: Other**\n\n- Ask what they'd like to do\n\n</decision_gate>\n\n---\n\n<integration_protocol>\n\n## Integration Points\n\n**Invoked by:**\n- /compound command (primary interface)\n- Manual invocation in conversation after solution confirmed\n- Can be triggered by detecting confirmation phrases like \"that worked\", \"it's fixed\", etc.\n\n**Invokes:**\n- None (terminal skill - does not delegate to other skills)\n\n**Handoff expectations:**\nAll context needed for documentation should be present in conversation history before invocation.\n\n</integration_protocol>\n\n---\n\n<success_criteria>\n\n## Success Criteria\n\nDocumentation is successful when ALL of the following are true:\n\n- ‚úÖ YAML frontmatter validated (all required fields, correct formats)\n- ‚úÖ File created in docs/solutions/[category]/[filename].md\n- ‚úÖ Enum values match schema.yaml exactly\n- ‚úÖ Code examples included in solution section\n- ‚úÖ Cross-references added if related issues found\n- ‚úÖ User presented with decision menu and action confirmed\n\n</success_criteria>\n\n---\n\n## Error Handling\n\n**Missing context:**\n\n- Ask user for missing details\n- Don't proceed until critical info provided\n\n**YAML validation failure:**\n\n- Show specific errors\n- Present retry with corrected values\n- BLOCK until valid\n\n**Similar issue ambiguity:**\n\n- Present multiple matches\n- Let user choose: new doc, update existing, or link as duplicate\n\n**Module not in CORA-MODULES.md:**\n\n- Warn but don't block\n- Proceed with documentation\n- Suggest: \"Add [Module] to CORA-MODULES.md if not there\"\n\n---\n\n## Execution Guidelines\n\n**MUST do:**\n- Validate YAML frontmatter (BLOCK if invalid per Step 5 validation gate)\n- Extract exact error messages from conversation\n- Include code examples in solution section\n- Create directories before writing files (`mkdir -p`)\n- Ask user and WAIT if critical context missing\n\n**MUST NOT do:**\n- Skip YAML validation (validation gate is blocking)\n- Use vague descriptions (not searchable)\n- Omit code examples or cross-references\n\n---\n\n## Quality Guidelines\n\n**Good documentation has:**\n\n- ‚úÖ Exact error messages (copy-paste from output)\n- ‚úÖ Specific file:line references\n- ‚úÖ Observable symptoms (what you saw, not interpretations)\n- ‚úÖ Failed attempts documented (helps avoid wrong paths)\n- ‚úÖ Technical explanation (not just \"what\" but \"why\")\n- ‚úÖ Code examples (before/after if applicable)\n- ‚úÖ Prevention guidance (how to catch early)\n- ‚úÖ Cross-references (related issues)\n\n**Avoid:**\n\n- ‚ùå Vague descriptions (\"something was wrong\")\n- ‚ùå Missing technical details (\"fixed the code\")\n- ‚ùå No context (which version? which file?)\n- ‚ùå Just code dumps (explain why it works)\n- ‚ùå No prevention guidance\n- ‚ùå No cross-references\n\n---\n\n## Example Scenario\n\n**User:** \"That worked! The N+1 query is fixed.\"\n\n**Skill activates:**\n\n1. **Detect confirmation:** \"That worked!\" triggers auto-invoke\n2. **Gather context:**\n   - Module: Brief System\n   - Symptom: Brief generation taking >5 seconds, N+1 query when loading email threads\n   - Failed attempts: Added pagination (didn't help), checked background job performance\n   - Solution: Added eager loading with `includes(:emails)` on Brief model\n   - Root cause: Missing eager loading causing separate database query per email thread\n3. **Check existing:** No similar issue found\n4. **Generate filename:** `n-plus-one-brief-generation-BriefSystem-20251110.md`\n5. **Validate YAML:**\n   ```yaml\n   module: Brief System\n   date: 2025-11-10\n   problem_type: performance_issue\n   component: rails_model\n   symptoms:\n     - \"N+1 query when loading email threads\"\n     - \"Brief generation taking >5 seconds\"\n   root_cause: missing_include\n   severity: high\n   tags: [n-plus-one, eager-loading, performance]\n   ```\n   ‚úÖ Valid\n6. **Create documentation:**\n   - `docs/solutions/performance-issues/n-plus-one-brief-generation-BriefSystem-20251110.md`\n7. **Cross-reference:** None needed (no similar issues)\n\n**Output:**\n\n```\n‚úì Solution documented\n\nFile created:\n- docs/solutions/performance-issues/n-plus-one-brief-generation-BriefSystem-20251110.md\n\nWhat's next?\n1. Continue workflow (recommended)\n2. Add to Required Reading - Promote to critical patterns (cora-critical-patterns.md)\n3. Link related issues - Connect to similar problems\n4. Add to existing skill - Add to a learning skill (e.g., hotwire-native)\n5. Create new skill - Extract into new learning skill\n6. View documentation - See what was captured\n7. Other\n```\n\n---\n\n## Future Enhancements\n\n**Not in Phase 7 scope, but potential:**\n\n- Search by date range\n- Filter by severity\n- Tag-based search interface\n- Metrics (most common issues, resolution time)\n- Export to shareable format (community knowledge sharing)\n- Import community solutions"
              },
              {
                "name": "creating-agent-skills",
                "description": "Expert guidance for creating, writing, and refining Claude Code Skills. Use when working with SKILL.md files, authoring new skills, improving existing skills, or understanding skill structure and best practices.",
                "path": "plugins/compound-engineering/skills/create-agent-skills/SKILL.md",
                "frontmatter": {
                  "name": "creating-agent-skills",
                  "description": "Expert guidance for creating, writing, and refining Claude Code Skills. Use when working with SKILL.md files, authoring new skills, improving existing skills, or understanding skill structure and best practices."
                },
                "content": "# Creating Agent Skills\n\nThis skill teaches how to create effective Claude Code Skills following Anthropic's official specification.\n\n## Core Principles\n\n### 1. Skills Are Prompts\n\nAll prompting best practices apply. Be clear, be direct. Assume Claude is smart - only add context Claude doesn't have.\n\n### 2. Standard Markdown Format\n\nUse YAML frontmatter + markdown body. **No XML tags** - use standard markdown headings.\n\n```markdown\n---\nname: my-skill-name\ndescription: What it does and when to use it\n---\n\n# My Skill Name\n\n## Quick Start\nImmediate actionable guidance...\n\n## Instructions\nStep-by-step procedures...\n\n## Examples\nConcrete usage examples...\n```\n\n### 3. Progressive Disclosure\n\nKeep SKILL.md under 500 lines. Split detailed content into reference files. Load only what's needed.\n\n```\nmy-skill/\n‚îú‚îÄ‚îÄ SKILL.md              # Entry point (required)\n‚îú‚îÄ‚îÄ reference.md          # Detailed docs (loaded when needed)\n‚îú‚îÄ‚îÄ examples.md           # Usage examples\n‚îî‚îÄ‚îÄ scripts/              # Utility scripts (executed, not loaded)\n```\n\n### 4. Effective Descriptions\n\nThe description field enables skill discovery. Include both what the skill does AND when to use it. Write in third person.\n\n**Good:**\n```yaml\ndescription: Extracts text and tables from PDF files, fills forms, merges documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n```\n\n**Bad:**\n```yaml\ndescription: Helps with documents\n```\n\n## Skill Structure\n\n### Required Frontmatter\n\n| Field | Required | Max Length | Description |\n|-------|----------|------------|-------------|\n| `name` | Yes | 64 chars | Lowercase letters, numbers, hyphens only |\n| `description` | Yes | 1024 chars | What it does AND when to use it |\n| `allowed-tools` | No | - | Tools Claude can use without asking |\n| `model` | No | - | Specific model to use |\n\n### Naming Conventions\n\nUse **gerund form** (verb + -ing) for skill names:\n\n- `processing-pdfs`\n- `analyzing-spreadsheets`\n- `generating-commit-messages`\n- `reviewing-code`\n\nAvoid: `helper`, `utils`, `tools`, `anthropic-*`, `claude-*`\n\n### Body Structure\n\nUse standard markdown headings:\n\n```markdown\n# Skill Name\n\n## Quick Start\nFastest path to value...\n\n## Instructions\nCore guidance Claude follows...\n\n## Examples\nInput/output pairs showing expected behavior...\n\n## Advanced Features\nAdditional capabilities (link to reference files)...\n\n## Guidelines\nRules and constraints...\n```\n\n## What Would You Like To Do?\n\n1. **Create new skill** - Build from scratch\n2. **Audit existing skill** - Check against best practices\n3. **Add component** - Add workflow/reference/example\n4. **Get guidance** - Understand skill design\n\n## Creating a New Skill\n\n### Step 1: Choose Type\n\n**Simple skill (single file):**\n- Under 500 lines\n- Self-contained guidance\n- No complex workflows\n\n**Progressive disclosure skill (multiple files):**\n- SKILL.md as overview\n- Reference files for detailed docs\n- Scripts for utilities\n\n### Step 2: Create SKILL.md\n\n```markdown\n---\nname: your-skill-name\ndescription: [What it does]. Use when [trigger conditions].\n---\n\n# Your Skill Name\n\n## Quick Start\n\n[Immediate actionable example]\n\n```[language]\n[Code example]\n```\n\n## Instructions\n\n[Core guidance]\n\n## Examples\n\n**Example 1:**\nInput: [description]\nOutput:\n```\n[result]\n```\n\n## Guidelines\n\n- [Constraint 1]\n- [Constraint 2]\n```\n\n### Step 3: Add Reference Files (If Needed)\n\nLink from SKILL.md to detailed content:\n\n```markdown\nFor API reference, see [REFERENCE.md](REFERENCE.md).\nFor form filling guide, see [FORMS.md](FORMS.md).\n```\n\nKeep references **one level deep** from SKILL.md.\n\n### Step 4: Add Scripts (If Needed)\n\nScripts execute without loading into context:\n\n```markdown\n## Utility Scripts\n\nExtract fields:\n```bash\npython scripts/analyze.py input.pdf > fields.json\n```\n```\n\n### Step 5: Test With Real Usage\n\n1. Test with actual tasks, not test scenarios\n2. Observe where Claude struggles\n3. Refine based on real behavior\n4. Test with Haiku, Sonnet, and Opus\n\n## Auditing Existing Skills\n\nCheck against this rubric:\n\n- [ ] Valid YAML frontmatter (name + description)\n- [ ] Description includes trigger keywords\n- [ ] Uses standard markdown headings (not XML tags)\n- [ ] SKILL.md under 500 lines\n- [ ] References one level deep\n- [ ] Examples are concrete, not abstract\n- [ ] Consistent terminology\n- [ ] No time-sensitive information\n- [ ] Scripts handle errors explicitly\n\n## Common Patterns\n\n### Template Pattern\n\nProvide output templates for consistent results:\n\n```markdown\n## Report Template\n\n```markdown\n# [Analysis Title]\n\n## Executive Summary\n[One paragraph overview]\n\n## Key Findings\n- Finding 1\n- Finding 2\n\n## Recommendations\n1. [Action item]\n2. [Action item]\n```\n```\n\n### Workflow Pattern\n\nFor complex multi-step tasks:\n\n```markdown\n## Migration Workflow\n\nCopy this checklist:\n\n```\n- [ ] Step 1: Backup database\n- [ ] Step 2: Run migration script\n- [ ] Step 3: Validate output\n- [ ] Step 4: Update configuration\n```\n\n**Step 1: Backup database**\nRun: `./scripts/backup.sh`\n...\n```\n\n### Conditional Pattern\n\nGuide through decision points:\n\n```markdown\n## Choose Your Approach\n\n**Creating new content?** Follow \"Creation workflow\" below.\n**Editing existing?** Follow \"Editing workflow\" below.\n```\n\n## Anti-Patterns to Avoid\n\n- **XML tags in body** - Use markdown headings instead\n- **Vague descriptions** - Be specific with trigger keywords\n- **Deep nesting** - Keep references one level from SKILL.md\n- **Too many options** - Provide a default with escape hatch\n- **Windows paths** - Always use forward slashes\n- **Punting to Claude** - Scripts should handle errors\n- **Time-sensitive info** - Use \"old patterns\" section instead\n\n## Reference Files\n\nFor detailed guidance, see:\n\n- [official-spec.md](references/official-spec.md) - Anthropic's official skill specification\n- [best-practices.md](references/best-practices.md) - Skill authoring best practices\n\n## Success Criteria\n\nA well-structured skill:\n- Has valid YAML frontmatter with descriptive name and description\n- Uses standard markdown headings (not XML tags)\n- Keeps SKILL.md under 500 lines\n- Links to reference files for detailed content\n- Includes concrete examples with input/output pairs\n- Has been tested with real usage\n\nSources:\n- [Agent Skills - Claude Code Docs](https://code.claude.com/docs/en/skills)\n- [Skill authoring best practices](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices)\n- [GitHub - anthropics/skills](https://github.com/anthropics/skills)"
              },
              {
                "name": "dhh-rails-style",
                "description": "This skill should be used when writing Ruby and Rails code in DHH's distinctive 37signals style. It applies when writing Ruby code, Rails applications, creating models, controllers, or any Ruby file. Triggers on Ruby/Rails code generation, refactoring requests, code review, or when the user mentions DHH, 37signals, Basecamp, HEY, or Campfire style. Embodies REST purity, fat models, thin controllers, Current attributes, Hotwire patterns, and the \"clarity over cleverness\" philosophy.",
                "path": "plugins/compound-engineering/skills/dhh-rails-style/SKILL.md",
                "frontmatter": {
                  "name": "dhh-rails-style",
                  "description": "This skill should be used when writing Ruby and Rails code in DHH's distinctive 37signals style. It applies when writing Ruby code, Rails applications, creating models, controllers, or any Ruby file. Triggers on Ruby/Rails code generation, refactoring requests, code review, or when the user mentions DHH, 37signals, Basecamp, HEY, or Campfire style. Embodies REST purity, fat models, thin controllers, Current attributes, Hotwire patterns, and the \"clarity over cleverness\" philosophy."
                },
                "content": "<objective>\nApply 37signals/DHH Rails conventions to Ruby and Rails code. This skill provides comprehensive domain expertise extracted from analyzing production 37signals codebases (Fizzy/Campfire) and DHH's code review patterns.\n</objective>\n\n<essential_principles>\n## Core Philosophy\n\n\"The best code is the code you don't write. The second best is the code that's obviously correct.\"\n\n**Vanilla Rails is plenty:**\n- Rich domain models over service objects\n- CRUD controllers over custom actions\n- Concerns for horizontal code sharing\n- Records as state instead of boolean columns\n- Database-backed everything (no Redis)\n- Build solutions before reaching for gems\n\n**What they deliberately avoid:**\n- devise (custom ~150-line auth instead)\n- pundit/cancancan (simple role checks in models)\n- sidekiq (Solid Queue uses database)\n- redis (database for everything)\n- view_component (partials work fine)\n- GraphQL (REST with Turbo sufficient)\n- factory_bot (fixtures are simpler)\n- rspec (Minitest ships with Rails)\n- Tailwind (native CSS with layers)\n\n**Development Philosophy:**\n- Ship, Validate, Refine - prototype-quality code to production to learn\n- Fix root causes, not symptoms\n- Write-time operations over read-time computations\n- Database constraints over ActiveRecord validations\n</essential_principles>\n\n<intake>\nWhat are you working on?\n\n1. **Controllers** - REST mapping, concerns, Turbo responses, API patterns\n2. **Models** - Concerns, state records, callbacks, scopes, POROs\n3. **Views & Frontend** - Turbo, Stimulus, CSS, partials\n4. **Architecture** - Routing, multi-tenancy, authentication, jobs, caching\n5. **Testing** - Minitest, fixtures, integration tests\n6. **Gems & Dependencies** - What to use vs avoid\n7. **Code Review** - Review code against DHH style\n8. **General Guidance** - Philosophy and conventions\n\n**Specify a number or describe your task.**\n</intake>\n\n<routing>\n| Response | Reference to Read |\n|----------|-------------------|\n| 1, \"controller\" | [controllers.md](./references/controllers.md) |\n| 2, \"model\" | [models.md](./references/models.md) |\n| 3, \"view\", \"frontend\", \"turbo\", \"stimulus\", \"css\" | [frontend.md](./references/frontend.md) |\n| 4, \"architecture\", \"routing\", \"auth\", \"job\", \"cache\" | [architecture.md](./references/architecture.md) |\n| 5, \"test\", \"testing\", \"minitest\", \"fixture\" | [testing.md](./references/testing.md) |\n| 6, \"gem\", \"dependency\", \"library\" | [gems.md](./references/gems.md) |\n| 7, \"review\" | Read all references, then review code |\n| 8, general task | Read relevant references based on context |\n\n**After reading relevant references, apply patterns to the user's code.**\n</routing>\n\n<quick_reference>\n## Naming Conventions\n\n**Verbs:** `card.close`, `card.gild`, `board.publish` (not `set_style` methods)\n\n**Predicates:** `card.closed?`, `card.golden?` (derived from presence of related record)\n\n**Concerns:** Adjectives describing capability (`Closeable`, `Publishable`, `Watchable`)\n\n**Controllers:** Nouns matching resources (`Cards::ClosuresController`)\n\n**Scopes:**\n- `chronologically`, `reverse_chronologically`, `alphabetically`, `latest`\n- `preloaded` (standard eager loading name)\n- `indexed_by`, `sorted_by` (parameterized)\n- `active`, `unassigned` (business terms, not SQL-ish)\n\n## REST Mapping\n\nInstead of custom actions, create new resources:\n\n```\nPOST /cards/:id/close    ‚Üí POST /cards/:id/closure\nDELETE /cards/:id/close  ‚Üí DELETE /cards/:id/closure\nPOST /cards/:id/archive  ‚Üí POST /cards/:id/archival\n```\n\n## Ruby Syntax Preferences\n\n```ruby\n# Symbol arrays with spaces inside brackets\nbefore_action :set_message, only: %i[ show edit update destroy ]\n\n# Private method indentation\n  private\n    def set_message\n      @message = Message.find(params[:id])\n    end\n\n# Expression-less case for conditionals\ncase\nwhen params[:before].present?\n  messages.page_before(params[:before])\nelse\n  messages.last_page\nend\n\n# Bang methods for fail-fast\n@message = Message.create!(params)\n\n# Ternaries for simple conditionals\n@room.direct? ? @room.users : @message.mentionees\n```\n\n## Key Patterns\n\n**State as Records:**\n```ruby\nCard.joins(:closure)         # closed cards\nCard.where.missing(:closure) # open cards\n```\n\n**Current Attributes:**\n```ruby\nbelongs_to :creator, default: -> { Current.user }\n```\n\n**Authorization on Models:**\n```ruby\nclass User < ApplicationRecord\n  def can_administer?(message)\n    message.creator == self || admin?\n  end\nend\n```\n</quick_reference>\n\n<reference_index>\n## Domain Knowledge\n\nAll detailed patterns in `references/`:\n\n| File | Topics |\n|------|--------|\n| [controllers.md](./references/controllers.md) | REST mapping, concerns, Turbo responses, API patterns, HTTP caching |\n| [models.md](./references/models.md) | Concerns, state records, callbacks, scopes, POROs, authorization, broadcasting |\n| [frontend.md](./references/frontend.md) | Turbo Streams, Stimulus controllers, CSS layers, OKLCH colors, partials |\n| [architecture.md](./references/architecture.md) | Routing, authentication, jobs, Current attributes, caching, database patterns |\n| [testing.md](./references/testing.md) | Minitest, fixtures, unit/integration/system tests, testing patterns |\n| [gems.md](./references/gems.md) | What they use vs avoid, decision framework, Gemfile examples |\n</reference_index>\n\n<success_criteria>\nCode follows DHH style when:\n- Controllers map to CRUD verbs on resources\n- Models use concerns for horizontal behavior\n- State is tracked via records, not booleans\n- No unnecessary service objects or abstractions\n- Database-backed solutions preferred over external services\n- Tests use Minitest with fixtures\n- Turbo/Stimulus for interactivity (no heavy JS frameworks)\n- Native CSS with modern features (layers, OKLCH, nesting)\n- Authorization logic lives on User model\n- Jobs are shallow wrappers calling model methods\n</success_criteria>\n\n<credits>\nBased on [The Unofficial 37signals/DHH Rails Style Guide](https://github.com/marckohlbrugge/unofficial-37signals-coding-style-guide) by [Marc K√∂hlbrugge](https://x.com/marckohlbrugge), generated through deep analysis of 265 pull requests from the Fizzy codebase.\n\n**Important Disclaimers:**\n- LLM-generated guide - may contain inaccuracies\n- Code examples from Fizzy are licensed under the O'Saasy License\n- Not affiliated with or endorsed by 37signals\n</credits>"
              },
              {
                "name": "dspy-ruby",
                "description": "This skill should be used when working with DSPy.rb, a Ruby framework for building type-safe, composable LLM applications. Use this when implementing predictable AI features, creating LLM signatures and modules, configuring language model providers (OpenAI, Anthropic, Gemini, Ollama), building agent systems with tools, optimizing prompts, or testing LLM-powered functionality in Ruby applications.",
                "path": "plugins/compound-engineering/skills/dspy-ruby/SKILL.md",
                "frontmatter": {
                  "name": "dspy-ruby",
                  "description": "This skill should be used when working with DSPy.rb, a Ruby framework for building type-safe, composable LLM applications. Use this when implementing predictable AI features, creating LLM signatures and modules, configuring language model providers (OpenAI, Anthropic, Gemini, Ollama), building agent systems with tools, optimizing prompts, or testing LLM-powered functionality in Ruby applications."
                },
                "content": "# DSPy.rb Expert\n\n## Overview\n\nDSPy.rb is a Ruby framework that enables developers to **program LLMs, not prompt them**. Instead of manually crafting prompts, define application requirements through type-safe, composable modules that can be tested, optimized, and version-controlled like regular code.\n\nThis skill provides comprehensive guidance on:\n- Creating type-safe signatures for LLM operations\n- Building composable modules and workflows\n- Configuring multiple LLM providers\n- Implementing agents with tools\n- Testing and optimizing LLM applications\n- Production deployment patterns\n\n## Core Capabilities\n\n### 1. Type-Safe Signatures\n\nCreate input/output contracts for LLM operations with runtime type checking.\n\n**When to use**: Defining any LLM task, from simple classification to complex analysis.\n\n**Quick reference**:\n```ruby\nclass EmailClassificationSignature < DSPy::Signature\n  description \"Classify customer support emails\"\n\n  input do\n    const :email_subject, String\n    const :email_body, String\n  end\n\n  output do\n    const :category, T.enum([\"Technical\", \"Billing\", \"General\"])\n    const :priority, T.enum([\"Low\", \"Medium\", \"High\"])\n  end\nend\n```\n\n**Templates**: See `assets/signature-template.rb` for comprehensive examples including:\n- Basic signatures with multiple field types\n- Vision signatures for multimodal tasks\n- Sentiment analysis signatures\n- Code generation signatures\n\n**Best practices**:\n- Always provide clear, specific descriptions\n- Use enums for constrained outputs\n- Include field descriptions with `desc:` parameter\n- Prefer specific types over generic String when possible\n\n**Full documentation**: See `references/core-concepts.md` sections on Signatures and Type Safety.\n\n### 2. Composable Modules\n\nBuild reusable, chainable modules that encapsulate LLM operations.\n\n**When to use**: Implementing any LLM-powered feature, especially complex multi-step workflows.\n\n**Quick reference**:\n```ruby\nclass EmailProcessor < DSPy::Module\n  def initialize\n    super\n    @classifier = DSPy::Predict.new(EmailClassificationSignature)\n  end\n\n  def forward(email_subject:, email_body:)\n    @classifier.forward(\n      email_subject: email_subject,\n      email_body: email_body\n    )\n  end\nend\n```\n\n**Templates**: See `assets/module-template.rb` for comprehensive examples including:\n- Basic modules with single predictors\n- Multi-step pipelines that chain modules\n- Modules with conditional logic\n- Error handling and retry patterns\n- Stateful modules with history\n- Caching implementations\n\n**Module composition**: Chain modules together to create complex workflows:\n```ruby\nclass Pipeline < DSPy::Module\n  def initialize\n    super\n    @step1 = Classifier.new\n    @step2 = Analyzer.new\n    @step3 = Responder.new\n  end\n\n  def forward(input)\n    result1 = @step1.forward(input)\n    result2 = @step2.forward(result1)\n    @step3.forward(result2)\n  end\nend\n```\n\n**Full documentation**: See `references/core-concepts.md` sections on Modules and Module Composition.\n\n### 3. Multiple Predictor Types\n\nChoose the right predictor for your task:\n\n**Predict**: Basic LLM inference with type-safe inputs/outputs\n```ruby\npredictor = DSPy::Predict.new(TaskSignature)\nresult = predictor.forward(input: \"data\")\n```\n\n**ChainOfThought**: Adds automatic reasoning for improved accuracy\n```ruby\npredictor = DSPy::ChainOfThought.new(TaskSignature)\nresult = predictor.forward(input: \"data\")\n# Returns: { reasoning: \"...\", output: \"...\" }\n```\n\n**ReAct**: Tool-using agents with iterative reasoning\n```ruby\npredictor = DSPy::ReAct.new(\n  TaskSignature,\n  tools: [SearchTool.new, CalculatorTool.new],\n  max_iterations: 5\n)\n```\n\n**CodeAct**: Dynamic code generation (requires `dspy-code_act` gem)\n```ruby\npredictor = DSPy::CodeAct.new(TaskSignature)\nresult = predictor.forward(task: \"Calculate factorial of 5\")\n```\n\n**When to use each**:\n- **Predict**: Simple tasks, classification, extraction\n- **ChainOfThought**: Complex reasoning, analysis, multi-step thinking\n- **ReAct**: Tasks requiring external tools (search, calculation, API calls)\n- **CodeAct**: Tasks best solved with generated code\n\n**Full documentation**: See `references/core-concepts.md` section on Predictors.\n\n### 4. LLM Provider Configuration\n\nSupport for OpenAI, Anthropic Claude, Google Gemini, Ollama, and OpenRouter.\n\n**Quick configuration examples**:\n```ruby\n# OpenAI\nDSPy.configure do |c|\n  c.lm = DSPy::LM.new('openai/gpt-4o-mini',\n    api_key: ENV['OPENAI_API_KEY'])\nend\n\n# Anthropic Claude\nDSPy.configure do |c|\n  c.lm = DSPy::LM.new('anthropic/claude-3-5-sonnet-20241022',\n    api_key: ENV['ANTHROPIC_API_KEY'])\nend\n\n# Google Gemini\nDSPy.configure do |c|\n  c.lm = DSPy::LM.new('gemini/gemini-1.5-pro',\n    api_key: ENV['GOOGLE_API_KEY'])\nend\n\n# Local Ollama (free, private)\nDSPy.configure do |c|\n  c.lm = DSPy::LM.new('ollama/llama3.1')\nend\n```\n\n**Templates**: See `assets/config-template.rb` for comprehensive examples including:\n- Environment-based configuration\n- Multi-model setups for different tasks\n- Configuration with observability (OpenTelemetry, Langfuse)\n- Retry logic and fallback strategies\n- Budget tracking\n- Rails initializer patterns\n\n**Provider compatibility matrix**:\n\n| Feature | OpenAI | Anthropic | Gemini | Ollama |\n|---------|--------|-----------|--------|--------|\n| Structured Output | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n| Vision (Images) | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è Limited |\n| Image URLs | ‚úÖ | ‚ùå | ‚ùå | ‚ùå |\n| Tool Calling | ‚úÖ | ‚úÖ | ‚úÖ | Varies |\n\n**Cost optimization strategy**:\n- Development: Ollama (free) or gpt-4o-mini (cheap)\n- Testing: gpt-4o-mini with temperature=0.0\n- Production simple tasks: gpt-4o-mini, claude-3-haiku, gemini-1.5-flash\n- Production complex tasks: gpt-4o, claude-3-5-sonnet, gemini-1.5-pro\n\n**Full documentation**: See `references/providers.md` for all configuration options, provider-specific features, and troubleshooting.\n\n### 5. Multimodal & Vision Support\n\nProcess images alongside text using the unified `DSPy::Image` interface.\n\n**Quick reference**:\n```ruby\nclass VisionSignature < DSPy::Signature\n  description \"Analyze image and answer questions\"\n\n  input do\n    const :image, DSPy::Image\n    const :question, String\n  end\n\n  output do\n    const :answer, String\n  end\nend\n\npredictor = DSPy::Predict.new(VisionSignature)\nresult = predictor.forward(\n  image: DSPy::Image.from_file(\"path/to/image.jpg\"),\n  question: \"What objects are visible?\"\n)\n```\n\n**Image loading methods**:\n```ruby\n# From file\nDSPy::Image.from_file(\"path/to/image.jpg\")\n\n# From URL (OpenAI only)\nDSPy::Image.from_url(\"https://example.com/image.jpg\")\n\n# From base64\nDSPy::Image.from_base64(base64_data, mime_type: \"image/jpeg\")\n```\n\n**Provider support**:\n- OpenAI: Full support including URLs\n- Anthropic, Gemini: Base64 or file loading only\n- Ollama: Limited multimodal depending on model\n\n**Full documentation**: See `references/core-concepts.md` section on Multimodal Support.\n\n### 6. Testing LLM Applications\n\nWrite standard RSpec tests for LLM logic.\n\n**Quick reference**:\n```ruby\nRSpec.describe EmailClassifier do\n  before do\n    DSPy.configure do |c|\n      c.lm = DSPy::LM.new('openai/gpt-4o-mini',\n        api_key: ENV['OPENAI_API_KEY'])\n    end\n  end\n\n  it 'classifies technical emails correctly' do\n    classifier = EmailClassifier.new\n    result = classifier.forward(\n      email_subject: \"Can't log in\",\n      email_body: \"Unable to access account\"\n    )\n\n    expect(result[:category]).to eq('Technical')\n    expect(result[:priority]).to be_in(['High', 'Medium', 'Low'])\n  end\nend\n```\n\n**Testing patterns**:\n- Mock LLM responses for unit tests\n- Use VCR for deterministic API testing\n- Test type safety and validation\n- Test edge cases (empty inputs, special characters, long texts)\n- Integration test complete workflows\n\n**Full documentation**: See `references/optimization.md` section on Testing.\n\n### 7. Optimization & Improvement\n\nAutomatically improve prompts and modules using optimization techniques.\n\n**MIPROv2 optimization**:\n```ruby\nrequire 'dspy/mipro'\n\n# Define evaluation metric\ndef accuracy_metric(example, prediction)\n  example[:expected_output][:category] == prediction[:category] ? 1.0 : 0.0\nend\n\n# Prepare training data\ntraining_examples = [\n  {\n    input: { email_subject: \"...\", email_body: \"...\" },\n    expected_output: { category: 'Technical' }\n  },\n  # More examples...\n]\n\n# Run optimization\noptimizer = DSPy::MIPROv2.new(\n  metric: method(:accuracy_metric),\n  num_candidates: 10\n)\n\noptimized_module = optimizer.compile(\n  EmailClassifier.new,\n  trainset: training_examples\n)\n```\n\n**A/B testing different approaches**:\n```ruby\n# Test ChainOfThought vs ReAct\napproach_a_score = evaluate_approach(ChainOfThoughtModule, test_set)\napproach_b_score = evaluate_approach(ReActModule, test_set)\n```\n\n**Full documentation**: See `references/optimization.md` section on Optimization.\n\n### 8. Observability & Monitoring\n\nTrack performance, token usage, and behavior in production.\n\n**OpenTelemetry integration**:\n```ruby\nrequire 'opentelemetry/sdk'\n\nOpenTelemetry::SDK.configure do |c|\n  c.service_name = 'my-dspy-app'\n  c.use_all\nend\n\n# DSPy automatically creates traces\n```\n\n**Langfuse tracing**:\n```ruby\nDSPy.configure do |c|\n  c.lm = DSPy::LM.new('openai/gpt-4o-mini',\n    api_key: ENV['OPENAI_API_KEY'])\n\n  c.langfuse = {\n    public_key: ENV['LANGFUSE_PUBLIC_KEY'],\n    secret_key: ENV['LANGFUSE_SECRET_KEY']\n  }\nend\n```\n\n**Custom monitoring**:\n- Token tracking\n- Performance monitoring\n- Error rate tracking\n- Custom logging\n\n**Full documentation**: See `references/optimization.md` section on Observability.\n\n## Quick Start Workflow\n\n### For New Projects\n\n1. **Install DSPy.rb and provider gems**:\n```bash\ngem install dspy dspy-openai  # or dspy-anthropic, dspy-gemini\n```\n\n2. **Configure LLM provider** (see `assets/config-template.rb`):\n```ruby\nrequire 'dspy'\n\nDSPy.configure do |c|\n  c.lm = DSPy::LM.new('openai/gpt-4o-mini',\n    api_key: ENV['OPENAI_API_KEY'])\nend\n```\n\n3. **Create a signature** (see `assets/signature-template.rb`):\n```ruby\nclass MySignature < DSPy::Signature\n  description \"Clear description of task\"\n\n  input do\n    const :input_field, String, desc: \"Description\"\n  end\n\n  output do\n    const :output_field, String, desc: \"Description\"\n  end\nend\n```\n\n4. **Create a module** (see `assets/module-template.rb`):\n```ruby\nclass MyModule < DSPy::Module\n  def initialize\n    super\n    @predictor = DSPy::Predict.new(MySignature)\n  end\n\n  def forward(input_field:)\n    @predictor.forward(input_field: input_field)\n  end\nend\n```\n\n5. **Use the module**:\n```ruby\nmodule_instance = MyModule.new\nresult = module_instance.forward(input_field: \"test\")\nputs result[:output_field]\n```\n\n6. **Add tests** (see `references/optimization.md`):\n```ruby\nRSpec.describe MyModule do\n  it 'produces expected output' do\n    result = MyModule.new.forward(input_field: \"test\")\n    expect(result[:output_field]).to be_a(String)\n  end\nend\n```\n\n### For Rails Applications\n\n1. **Add to Gemfile**:\n```ruby\ngem 'dspy'\ngem 'dspy-openai'  # or other provider\n```\n\n2. **Create initializer** at `config/initializers/dspy.rb` (see `assets/config-template.rb` for full example):\n```ruby\nrequire 'dspy'\n\nDSPy.configure do |c|\n  c.lm = DSPy::LM.new('openai/gpt-4o-mini',\n    api_key: ENV['OPENAI_API_KEY'])\nend\n```\n\n3. **Create modules in** `app/llm/` directory:\n```ruby\n# app/llm/email_classifier.rb\nclass EmailClassifier < DSPy::Module\n  # Implementation here\nend\n```\n\n4. **Use in controllers/services**:\n```ruby\nclass EmailsController < ApplicationController\n  def classify\n    classifier = EmailClassifier.new\n    result = classifier.forward(\n      email_subject: params[:subject],\n      email_body: params[:body]\n    )\n    render json: result\n  end\nend\n```\n\n## Common Patterns\n\n### Pattern: Multi-Step Analysis Pipeline\n\n```ruby\nclass AnalysisPipeline < DSPy::Module\n  def initialize\n    super\n    @extract = DSPy::Predict.new(ExtractSignature)\n    @analyze = DSPy::ChainOfThought.new(AnalyzeSignature)\n    @summarize = DSPy::Predict.new(SummarizeSignature)\n  end\n\n  def forward(text:)\n    extracted = @extract.forward(text: text)\n    analyzed = @analyze.forward(data: extracted[:data])\n    @summarize.forward(analysis: analyzed[:result])\n  end\nend\n```\n\n### Pattern: Agent with Tools\n\n```ruby\nclass ResearchAgent < DSPy::Module\n  def initialize\n    super\n    @agent = DSPy::ReAct.new(\n      ResearchSignature,\n      tools: [\n        WebSearchTool.new,\n        DatabaseQueryTool.new,\n        SummarizerTool.new\n      ],\n      max_iterations: 10\n    )\n  end\n\n  def forward(question:)\n    @agent.forward(question: question)\n  end\nend\n\nclass WebSearchTool < DSPy::Tool\n  def call(query:)\n    results = perform_search(query)\n    { results: results }\n  end\nend\n```\n\n### Pattern: Conditional Routing\n\n```ruby\nclass SmartRouter < DSPy::Module\n  def initialize\n    super\n    @classifier = DSPy::Predict.new(ClassifySignature)\n    @simple_handler = SimpleModule.new\n    @complex_handler = ComplexModule.new\n  end\n\n  def forward(input:)\n    classification = @classifier.forward(text: input)\n\n    if classification[:complexity] == 'Simple'\n      @simple_handler.forward(input: input)\n    else\n      @complex_handler.forward(input: input)\n    end\n  end\nend\n```\n\n### Pattern: Retry with Fallback\n\n```ruby\nclass RobustModule < DSPy::Module\n  MAX_RETRIES = 3\n\n  def forward(input, retry_count: 0)\n    begin\n      @predictor.forward(input)\n    rescue DSPy::ValidationError => e\n      if retry_count < MAX_RETRIES\n        sleep(2 ** retry_count)\n        forward(input, retry_count: retry_count + 1)\n      else\n        # Fallback to default or raise\n        raise\n      end\n    end\n  end\nend\n```\n\n## Resources\n\nThis skill includes comprehensive reference materials and templates:\n\n### References (load as needed for detailed information)\n\n- [core-concepts.md](./references/core-concepts.md): Complete guide to signatures, modules, predictors, multimodal support, and best practices\n- [providers.md](./references/providers.md): All LLM provider configurations, compatibility matrix, cost optimization, and troubleshooting\n- [optimization.md](./references/optimization.md): Testing patterns, optimization techniques, observability setup, and monitoring\n\n### Assets (templates for quick starts)\n\n- [signature-template.rb](./assets/signature-template.rb): Examples of signatures including basic, vision, sentiment analysis, and code generation\n- [module-template.rb](./assets/module-template.rb): Module patterns including pipelines, agents, error handling, caching, and state management\n- [config-template.rb](./assets/config-template.rb): Configuration examples for all providers, environments, observability, and production patterns\n\n## When to Use This Skill\n\nTrigger this skill when:\n- Implementing LLM-powered features in Ruby applications\n- Creating type-safe interfaces for AI operations\n- Building agent systems with tool usage\n- Setting up or troubleshooting LLM providers\n- Optimizing prompts and improving accuracy\n- Testing LLM functionality\n- Adding observability to AI applications\n- Converting from manual prompt engineering to programmatic approach\n- Debugging DSPy.rb code or configuration issues"
              },
              {
                "name": "every-style-editor",
                "description": "This skill should be used when reviewing or editing copy to ensure adherence to Every's style guide. It provides a systematic line-by-line review process for grammar, punctuation, mechanics, and style guide compliance.",
                "path": "plugins/compound-engineering/skills/every-style-editor/SKILL.md",
                "frontmatter": {
                  "name": "every-style-editor",
                  "description": "This skill should be used when reviewing or editing copy to ensure adherence to Every's style guide. It provides a systematic line-by-line review process for grammar, punctuation, mechanics, and style guide compliance."
                },
                "content": "# Every Style Editor\n\nThis skill provides a systematic approach to reviewing copy against Every's comprehensive style guide. It transforms Claude into a meticulous line editor and proofreader specializing in grammar, mechanics, and style guide compliance.\n\n## When to Use This Skill\n\nUse this skill when:\n- Reviewing articles, blog posts, newsletters, or any written content\n- Ensuring copy follows Every's specific style conventions\n- Providing feedback on grammar, punctuation, and mechanics\n- Flagging deviations from the Every style guide\n- Preparing clean copy for human editorial review\n\n## Skill Overview\n\nThis skill enables performing a comprehensive review of written content in four phases:\n\n1. **Initial Assessment** - Understanding context and document type\n2. **Detailed Line Edit** - Checking every sentence for compliance\n3. **Mechanical Review** - Verifying formatting and consistency\n4. **Recommendations** - Providing actionable improvement suggestions\n\n## How to Use This Skill\n\n### Step 1: Initial Assessment\n\nBegin by reading the entire piece to understand:\n- Document type (article, knowledge base entry, social post, etc.)\n- Target audience\n- Overall tone and voice\n- Content context\n\n### Step 2: Detailed Line Edit\n\nReview each paragraph systematically, checking for:\n- Sentence structure and grammar correctness\n- Punctuation usage (commas, semicolons, em dashes, etc.)\n- Capitalization rules (especially job titles, headlines)\n- Word choice and usage (overused words, passive voice)\n- Adherence to Every style guide rules\n\nReference the complete [EVERY_WRITE_STYLE.md](./references/EVERY_WRITE_STYLE.md) for specific rules when in doubt.\n\n### Step 3: Mechanical Review\n\nVerify:\n- Spacing and formatting consistency\n- Style choices applied uniformly throughout\n- Special elements (lists, quotes, citations)\n- Proper use of italics and formatting\n- Number formatting (numerals vs. spelled out)\n- Link formatting and descriptions\n\n### Step 4: Output Results\n\nPresent findings using this structure:\n\n```\nDOCUMENT REVIEW SUMMARY\n=====================\nDocument Type: [type]\nWord Count: [approximate]\nOverall Assessment: [brief overview]\n\nERRORS FOUND: [total number]\n\nDETAILED CORRECTIONS\n===================\n\n[For each error found:]\n\n**Location**: [Paragraph #, Sentence #]\n**Issue Type**: [Grammar/Punctuation/Mechanics/Style Guide]\n**Original**: \"[exact text with error]\"\n**Correction**: \"[corrected text]\"\n**Rule Reference**: [Specific style guide rule violated]\n**Explanation**: [Brief explanation of why this is an error]\n\n---\n\nRECURRING ISSUES\n===============\n[List patterns of errors that appear multiple times]\n\nSTYLE GUIDE COMPLIANCE CHECKLIST\n==============================\n‚úì [Rule followed correctly]\n‚úó [Rule violated - with count of violations]\n\nFINAL RECOMMENDATIONS\n===================\n[2-3 actionable suggestions for improving the draft]\n```\n\n## Style Guide Reference\n\nThe complete Every style guide is included in [EVERY_WRITE_STYLE.md](./references/EVERY_WRITE_STYLE.md). Key areas to focus on:\n\n- **Quick Rules**: Title case for headlines, sentence case elsewhere\n- **Tone**: Active voice, avoid overused words (actually, very, just), be specific\n- **Numbers**: Spell out one through nine; use numerals for 10+\n- **Punctuation**: Oxford commas, em dashes without spaces, proper quotation mark usage\n- **Capitalization**: Lowercase job titles, company as singular (it), teams as plural (they)\n- **Emphasis**: Italics only (no bold for emphasis)\n- **Links**: 2-4 words, don't say \"click here\"\n\n## Key Principles\n\n- **Be specific**: Always quote the exact text with the error\n- **Reference rules**: Cite the specific style guide rule for each correction\n- **Maintain voice**: Preserve the author's voice while correcting errors\n- **Prioritize clarity**: Focus on changes that improve readability\n- **Be constructive**: Frame feedback to help writers improve\n- **Flag ambiguous cases**: When style guide doesn't address an issue, explain options and recommend the clearest choice\n\n## Common Areas to Focus On\n\nBased on Every's style guide, pay special attention to:\n\n- Punctuation (comma usage, semicolons, apostrophes, quotation marks)\n- Capitalization (proper nouns, titles, sentence starts)\n- Numbers (when to spell out vs. use numerals)\n- Passive voice (replace with active whenever possible)\n- Overused words (actually, very, just)\n- Lists (parallel structure, punctuation, capitalization)\n- Hyphenation (compound adjectives, except adverbs)\n- Word usage (fewer vs. less, they vs. them)\n- Company references (singular \"it\", teams as plural \"they\")\n- Job title capitalization"
              },
              {
                "name": "file-todos",
                "description": "This skill should be used when managing the file-based todo tracking system in the todos/ directory. It provides workflows for creating todos, managing status and dependencies, conducting triage, and integrating with slash commands and code review processes.",
                "path": "plugins/compound-engineering/skills/file-todos/SKILL.md",
                "frontmatter": {
                  "name": "file-todos",
                  "description": "This skill should be used when managing the file-based todo tracking system in the todos/ directory. It provides workflows for creating todos, managing status and dependencies, conducting triage, and integrating with slash commands and code review processes."
                },
                "content": "# File-Based Todo Tracking Skill\n\n## Overview\n\nThe `todos/` directory contains a file-based tracking system for managing code review feedback, technical debt, feature requests, and work items. Each todo is a markdown file with YAML frontmatter and structured sections.\n\nThis skill should be used when:\n- Creating new todos from findings or feedback\n- Managing todo lifecycle (pending ‚Üí ready ‚Üí complete)\n- Triaging pending items for approval\n- Checking or managing dependencies\n- Converting PR comments or code findings into tracked work\n- Updating work logs during todo execution\n\n## File Naming Convention\n\nTodo files follow this naming pattern:\n\n```\n{issue_id}-{status}-{priority}-{description}.md\n```\n\n**Components:**\n- **issue_id**: Sequential number (001, 002, 003...) - never reused\n- **status**: `pending` (needs triage), `ready` (approved), `complete` (done)\n- **priority**: `p1` (critical), `p2` (important), `p3` (nice-to-have)\n- **description**: kebab-case, brief description\n\n**Examples:**\n```\n001-pending-p1-mailer-test.md\n002-ready-p1-fix-n-plus-1.md\n005-complete-p2-refactor-csv.md\n```\n\n## File Structure\n\nEach todo is a markdown file with YAML frontmatter and structured sections. Use the template at [todo-template.md](./assets/todo-template.md) as a starting point when creating new todos.\n\n**Required sections:**\n- **Problem Statement** - What is broken, missing, or needs improvement?\n- **Findings** - Investigation results, root cause, key discoveries\n- **Proposed Solutions** - Multiple options with pros/cons, effort, risk\n- **Recommended Action** - Clear plan (filled during triage)\n- **Acceptance Criteria** - Testable checklist items\n- **Work Log** - Chronological record with date, actions, learnings\n\n**Optional sections:**\n- **Technical Details** - Affected files, related components, DB changes\n- **Resources** - Links to errors, tests, PRs, documentation\n- **Notes** - Additional context or decisions\n\n**YAML frontmatter fields:**\n```yaml\n---\nstatus: ready              # pending | ready | complete\npriority: p1              # p1 | p2 | p3\nissue_id: \"002\"\ntags: [rails, performance, database]\ndependencies: [\"001\"]     # Issue IDs this is blocked by\n---\n```\n\n## Common Workflows\n\n### Creating a New Todo\n\n**To create a new todo from findings or feedback:**\n\n1. Determine next issue ID: `ls todos/ | grep -o '^[0-9]\\+' | sort -n | tail -1`\n2. Copy template: `cp assets/todo-template.md todos/{NEXT_ID}-pending-{priority}-{description}.md`\n3. Edit and fill required sections:\n   - Problem Statement\n   - Findings (if from investigation)\n   - Proposed Solutions (multiple options)\n   - Acceptance Criteria\n   - Add initial Work Log entry\n4. Determine status: `pending` (needs triage) or `ready` (pre-approved)\n5. Add relevant tags for filtering\n\n**When to create a todo:**\n- Requires more than 15-20 minutes of work\n- Needs research, planning, or multiple approaches considered\n- Has dependencies on other work\n- Requires manager approval or prioritization\n- Part of larger feature or refactor\n- Technical debt needing documentation\n\n**When to act immediately instead:**\n- Issue is trivial (< 15 minutes)\n- Complete context available now\n- No planning needed\n- User explicitly requests immediate action\n- Simple bug fix with obvious solution\n\n### Triaging Pending Items\n\n**To triage pending todos:**\n\n1. List pending items: `ls todos/*-pending-*.md`\n2. For each todo:\n   - Read Problem Statement and Findings\n   - Review Proposed Solutions\n   - Make decision: approve, defer, or modify priority\n3. Update approved todos:\n   - Rename file: `mv {file}-pending-{pri}-{desc}.md {file}-ready-{pri}-{desc}.md`\n   - Update frontmatter: `status: pending` ‚Üí `status: ready`\n   - Fill \"Recommended Action\" section with clear plan\n   - Adjust priority if different from initial assessment\n4. Deferred todos stay in `pending` status\n\n**Use slash command:** `/triage` for interactive approval workflow\n\n### Managing Dependencies\n\n**To track dependencies:**\n\n```yaml\ndependencies: [\"002\", \"005\"]  # This todo blocked by issues 002 and 005\ndependencies: []               # No blockers - can work immediately\n```\n\n**To check what blocks a todo:**\n```bash\ngrep \"^dependencies:\" todos/003-*.md\n```\n\n**To find what a todo blocks:**\n```bash\ngrep -l 'dependencies:.*\"002\"' todos/*.md\n```\n\n**To verify blockers are complete before starting:**\n```bash\nfor dep in 001 002 003; do\n  [ -f \"todos/${dep}-complete-*.md\" ] || echo \"Issue $dep not complete\"\ndone\n```\n\n### Updating Work Logs\n\n**When working on a todo, always add a work log entry:**\n\n```markdown\n### YYYY-MM-DD - Session Title\n\n**By:** Claude Code / Developer Name\n\n**Actions:**\n- Specific changes made (include file:line references)\n- Commands executed\n- Tests run\n- Results of investigation\n\n**Learnings:**\n- What worked / what didn't\n- Patterns discovered\n- Key insights for future work\n```\n\nWork logs serve as:\n- Historical record of investigation\n- Documentation of approaches attempted\n- Knowledge sharing for team\n- Context for future similar work\n\n### Completing a Todo\n\n**To mark a todo as complete:**\n\n1. Verify all acceptance criteria checked off\n2. Update Work Log with final session and results\n3. Rename file: `mv {file}-ready-{pri}-{desc}.md {file}-complete-{pri}-{desc}.md`\n4. Update frontmatter: `status: ready` ‚Üí `status: complete`\n5. Check for unblocked work: `grep -l 'dependencies:.*\"002\"' todos/*-ready-*.md`\n6. Commit with issue reference: `feat: resolve issue 002`\n\n## Integration with Development Workflows\n\n| Trigger | Flow | Tool |\n|---------|------|------|\n| Code review | `/workflows:review` ‚Üí Findings ‚Üí `/triage` ‚Üí Todos | Review agent + skill |\n| PR comments | `/resolve_pr_parallel` ‚Üí Individual fixes ‚Üí Todos | gh CLI + skill |\n| Code TODOs | `/resolve_todo_parallel` ‚Üí Fixes + Complex todos | Agent + skill |\n| Planning | Brainstorm ‚Üí Create todo ‚Üí Work ‚Üí Complete | Skill |\n| Feedback | Discussion ‚Üí Create todo ‚Üí Triage ‚Üí Work | Skill + slash |\n\n## Quick Reference Commands\n\n**Finding work:**\n```bash\n# List highest priority unblocked work\ngrep -l 'dependencies: \\[\\]' todos/*-ready-p1-*.md\n\n# List all pending items needing triage\nls todos/*-pending-*.md\n\n# Find next issue ID\nls todos/ | grep -o '^[0-9]\\+' | sort -n | tail -1 | awk '{printf \"%03d\", $1+1}'\n\n# Count by status\nfor status in pending ready complete; do\n  echo \"$status: $(ls -1 todos/*-$status-*.md 2>/dev/null | wc -l)\"\ndone\n```\n\n**Dependency management:**\n```bash\n# What blocks this todo?\ngrep \"^dependencies:\" todos/003-*.md\n\n# What does this todo block?\ngrep -l 'dependencies:.*\"002\"' todos/*.md\n```\n\n**Searching:**\n```bash\n# Search by tag\ngrep -l \"tags:.*rails\" todos/*.md\n\n# Search by priority\nls todos/*-p1-*.md\n\n# Full-text search\ngrep -r \"payment\" todos/\n```\n\n## Key Distinctions\n\n**File-todos system (this skill):**\n- Markdown files in `todos/` directory\n- Development/project tracking\n- Standalone markdown files with YAML frontmatter\n- Used by humans and agents\n\n**Rails Todo model:**\n- Database model in `app/models/todo.rb`\n- User-facing feature in the application\n- Active Record CRUD operations\n- Different from this file-based system\n\n**TodoWrite tool:**\n- In-memory task tracking during agent sessions\n- Temporary tracking for single conversation\n- Not persisted to disk\n- Different from both systems above"
              },
              {
                "name": "frontend-design",
                "description": "This skill should be used when creating distinctive, production-grade frontend interfaces with high design quality. It applies when the user asks to build web components, pages, or applications. Generates creative, polished code that avoids generic AI aesthetics.",
                "path": "plugins/compound-engineering/skills/frontend-design/SKILL.md",
                "frontmatter": {
                  "name": "frontend-design",
                  "description": "This skill should be used when creating distinctive, production-grade frontend interfaces with high design quality. It applies when the user asks to build web components, pages, or applications. Generates creative, polished code that avoids generic AI aesthetics.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision."
              },
              {
                "name": "gemini-imagegen",
                "description": "This skill should be used when generating and editing images using the Gemini API (Nano Banana Pro). It applies when creating images from text prompts, editing existing images, applying style transfers, generating logos with text, creating stickers, product mockups, or any image generation/manipulation task. Supports text-to-image, image editing, multi-turn refinement, and composition from multiple reference images.",
                "path": "plugins/compound-engineering/skills/gemini-imagegen/SKILL.md",
                "frontmatter": {
                  "name": "gemini-imagegen",
                  "description": "This skill should be used when generating and editing images using the Gemini API (Nano Banana Pro). It applies when creating images from text prompts, editing existing images, applying style transfers, generating logos with text, creating stickers, product mockups, or any image generation/manipulation task. Supports text-to-image, image editing, multi-turn refinement, and composition from multiple reference images."
                },
                "content": "# Gemini Image Generation (Nano Banana Pro)\n\nGenerate and edit images using Google's Gemini API. The environment variable `GEMINI_API_KEY` must be set.\n\n## Default Model\n\n| Model | Resolution | Best For |\n|-------|------------|----------|\n| `gemini-3-pro-image-preview` | 1K-4K | All image generation (default) |\n\n**Note:** Always use this Pro model. Only use a different model if explicitly requested.\n\n## Quick Reference\n\n### Default Settings\n- **Model:** `gemini-3-pro-image-preview`\n- **Resolution:** 1K (default, options: 1K, 2K, 4K)\n- **Aspect Ratio:** 1:1 (default)\n\n### Available Aspect Ratios\n`1:1`, `2:3`, `3:2`, `3:4`, `4:3`, `4:5`, `5:4`, `9:16`, `16:9`, `21:9`\n\n### Available Resolutions\n`1K` (default), `2K`, `4K`\n\n## Core API Pattern\n\n```python\nimport os\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n\n# Basic generation (1K, 1:1 - defaults)\nresponse = client.models.generate_content(\n    model=\"gemini-3-pro-image-preview\",\n    contents=[\"Your prompt here\"],\n    config=types.GenerateContentConfig(\n        response_modalities=['TEXT', 'IMAGE'],\n    ),\n)\n\nfor part in response.parts:\n    if part.text:\n        print(part.text)\n    elif part.inline_data:\n        image = part.as_image()\n        image.save(\"output.png\")\n```\n\n## Custom Resolution & Aspect Ratio\n\n```python\nfrom google.genai import types\n\nresponse = client.models.generate_content(\n    model=\"gemini-3-pro-image-preview\",\n    contents=[prompt],\n    config=types.GenerateContentConfig(\n        response_modalities=['TEXT', 'IMAGE'],\n        image_config=types.ImageConfig(\n            aspect_ratio=\"16:9\",  # Wide format\n            image_size=\"2K\"       # Higher resolution\n        ),\n    )\n)\n```\n\n### Resolution Examples\n\n```python\n# 1K (default) - Fast, good for previews\nimage_config=types.ImageConfig(image_size=\"1K\")\n\n# 2K - Balanced quality/speed\nimage_config=types.ImageConfig(image_size=\"2K\")\n\n# 4K - Maximum quality, slower\nimage_config=types.ImageConfig(image_size=\"4K\")\n```\n\n### Aspect Ratio Examples\n\n```python\n# Square (default)\nimage_config=types.ImageConfig(aspect_ratio=\"1:1\")\n\n# Landscape wide\nimage_config=types.ImageConfig(aspect_ratio=\"16:9\")\n\n# Ultra-wide panoramic\nimage_config=types.ImageConfig(aspect_ratio=\"21:9\")\n\n# Portrait\nimage_config=types.ImageConfig(aspect_ratio=\"9:16\")\n\n# Photo standard\nimage_config=types.ImageConfig(aspect_ratio=\"4:3\")\n```\n\n## Editing Images\n\nPass existing images with text prompts:\n\n```python\nfrom PIL import Image\n\nimg = Image.open(\"input.png\")\nresponse = client.models.generate_content(\n    model=\"gemini-3-pro-image-preview\",\n    contents=[\"Add a sunset to this scene\", img],\n    config=types.GenerateContentConfig(\n        response_modalities=['TEXT', 'IMAGE'],\n    ),\n)\n```\n\n## Multi-Turn Refinement\n\nUse chat for iterative editing:\n\n```python\nfrom google.genai import types\n\nchat = client.chats.create(\n    model=\"gemini-3-pro-image-preview\",\n    config=types.GenerateContentConfig(response_modalities=['TEXT', 'IMAGE'])\n)\n\nresponse = chat.send_message(\"Create a logo for 'Acme Corp'\")\n# Save first image...\n\nresponse = chat.send_message(\"Make the text bolder and add a blue gradient\")\n# Save refined image...\n```\n\n## Prompting Best Practices\n\n### Photorealistic Scenes\nInclude camera details: lens type, lighting, angle, mood.\n> \"A photorealistic close-up portrait, 85mm lens, soft golden hour light, shallow depth of field\"\n\n### Stylized Art\nSpecify style explicitly:\n> \"A kawaii-style sticker of a happy red panda, bold outlines, cel-shading, white background\"\n\n### Text in Images\nBe explicit about font style and placement:\n> \"Create a logo with text 'Daily Grind' in clean sans-serif, black and white, coffee bean motif\"\n\n### Product Mockups\nDescribe lighting setup and surface:\n> \"Studio-lit product photo on polished concrete, three-point softbox setup, 45-degree angle\"\n\n## Advanced Features\n\n### Google Search Grounding\nGenerate images based on real-time data:\n\n```python\nresponse = client.models.generate_content(\n    model=\"gemini-3-pro-image-preview\",\n    contents=[\"Visualize today's weather in Tokyo as an infographic\"],\n    config=types.GenerateContentConfig(\n        response_modalities=['TEXT', 'IMAGE'],\n        tools=[{\"google_search\": {}}]\n    )\n)\n```\n\n### Multiple Reference Images (Up to 14)\nCombine elements from multiple sources:\n\n```python\nresponse = client.models.generate_content(\n    model=\"gemini-3-pro-image-preview\",\n    contents=[\n        \"Create a group photo of these people in an office\",\n        Image.open(\"person1.png\"),\n        Image.open(\"person2.png\"),\n        Image.open(\"person3.png\"),\n    ],\n    config=types.GenerateContentConfig(\n        response_modalities=['TEXT', 'IMAGE'],\n    ),\n)\n```\n\n## Important: File Format & Media Type\n\n**CRITICAL:** The Gemini API returns images in JPEG format by default. When saving, always use `.jpg` extension to avoid media type mismatches.\n\n```python\n# CORRECT - Use .jpg extension (Gemini returns JPEG)\nimage.save(\"output.jpg\")\n\n# WRONG - Will cause \"Image does not match media type\" errors\nimage.save(\"output.png\")  # Creates JPEG with PNG extension!\n```\n\n### Converting to PNG (if needed)\n\nIf you specifically need PNG format:\n\n```python\nfrom PIL import Image\n\n# Generate with Gemini\nfor part in response.parts:\n    if part.inline_data:\n        img = part.as_image()\n        # Convert to PNG by saving with explicit format\n        img.save(\"output.png\", format=\"PNG\")\n```\n\n### Verifying Image Format\n\nCheck actual format vs extension with the `file` command:\n\n```bash\nfile image.png\n# If output shows \"JPEG image data\" - rename to .jpg!\n```\n\n## Notes\n\n- All generated images include SynthID watermarks\n- Gemini returns **JPEG format by default** - always use `.jpg` extension\n- Image-only mode (`responseModalities: [\"IMAGE\"]`) won't work with Google Search grounding\n- For editing, describe changes conversationally‚Äîthe model understands semantic masking\n- Default to 1K resolution for speed; use 2K/4K when quality is critical"
              },
              {
                "name": "git-worktree",
                "description": "This skill manages Git worktrees for isolated parallel development. It handles creating, listing, switching, and cleaning up worktrees with a simple interactive interface, following KISS principles.",
                "path": "plugins/compound-engineering/skills/git-worktree/SKILL.md",
                "frontmatter": {
                  "name": "git-worktree",
                  "description": "This skill manages Git worktrees for isolated parallel development. It handles creating, listing, switching, and cleaning up worktrees with a simple interactive interface, following KISS principles."
                },
                "content": "# Git Worktree Manager\n\nThis skill provides a unified interface for managing Git worktrees across your development workflow. Whether you're reviewing PRs in isolation or working on features in parallel, this skill handles all the complexity.\n\n## What This Skill Does\n\n- **Create worktrees** from main branch with clear branch names\n- **List worktrees** with current status\n- **Switch between worktrees** for parallel work\n- **Clean up completed worktrees** automatically\n- **Interactive confirmations** at each step\n- **Automatic .gitignore management** for worktree directory\n- **Automatic .env file copying** from main repo to new worktrees\n\n## CRITICAL: Always Use the Manager Script\n\n**NEVER call `git worktree add` directly.** Always use the `worktree-manager.sh` script.\n\nThe script handles critical setup that raw git commands don't:\n1. Copies `.env`, `.env.local`, `.env.test`, etc. from main repo\n2. Ensures `.worktrees` is in `.gitignore`\n3. Creates consistent directory structure\n\n```bash\n# ‚úÖ CORRECT - Always use the script\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh create feature-name\n\n# ‚ùå WRONG - Never do this directly\ngit worktree add .worktrees/feature-name -b feature-name main\n```\n\n## When to Use This Skill\n\nUse this skill in these scenarios:\n\n1. **Code Review (`/workflows:review`)**: If NOT already on the PR branch, offer worktree for isolated review\n2. **Feature Work (`/workflows:work`)**: Always ask if user wants parallel worktree or live branch work\n3. **Parallel Development**: When working on multiple features simultaneously\n4. **Cleanup**: After completing work in a worktree\n\n## How to Use\n\n### In Claude Code Workflows\n\nThe skill is automatically called from `/workflows:review` and `/workflows:work` commands:\n\n```\n# For review: offers worktree if not on PR branch\n# For work: always asks - new branch or worktree?\n```\n\n### Manual Usage\n\nYou can also invoke the skill directly from bash:\n\n```bash\n# Create a new worktree (copies .env files automatically)\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh create feature-login\n\n# List all worktrees\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh list\n\n# Switch to a worktree\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh switch feature-login\n\n# Copy .env files to an existing worktree (if they weren't copied)\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh copy-env feature-login\n\n# Clean up completed worktrees\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh cleanup\n```\n\n## Commands\n\n### `create <branch-name> [from-branch]`\n\nCreates a new worktree with the given branch name.\n\n**Options:**\n- `branch-name` (required): The name for the new branch and worktree\n- `from-branch` (optional): Base branch to create from (defaults to `main`)\n\n**Example:**\n```bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh create feature-login\n```\n\n**What happens:**\n1. Checks if worktree already exists\n2. Updates the base branch from remote\n3. Creates new worktree and branch\n4. **Copies all .env files from main repo** (.env, .env.local, .env.test, etc.)\n5. Shows path for cd-ing to the worktree\n\n### `list` or `ls`\n\nLists all available worktrees with their branches and current status.\n\n**Example:**\n```bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh list\n```\n\n**Output shows:**\n- Worktree name\n- Branch name\n- Which is current (marked with ‚úì)\n- Main repo status\n\n### `switch <name>` or `go <name>`\n\nSwitches to an existing worktree and cd's into it.\n\n**Example:**\n```bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh switch feature-login\n```\n\n**Optional:**\n- If name not provided, lists available worktrees and prompts for selection\n\n### `cleanup` or `clean`\n\nInteractively cleans up inactive worktrees with confirmation.\n\n**Example:**\n```bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh cleanup\n```\n\n**What happens:**\n1. Lists all inactive worktrees\n2. Asks for confirmation\n3. Removes selected worktrees\n4. Cleans up empty directories\n\n## Workflow Examples\n\n### Code Review with Worktree\n\n```bash\n# Claude Code recognizes you're not on the PR branch\n# Offers: \"Use worktree for isolated review? (y/n)\"\n\n# You respond: yes\n# Script runs (copies .env files automatically):\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh create pr-123-feature-name\n\n# You're now in isolated worktree for review with all env vars\ncd .worktrees/pr-123-feature-name\n\n# After review, return to main:\ncd ../..\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh cleanup\n```\n\n### Parallel Feature Development\n\n```bash\n# For first feature (copies .env files):\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh create feature-login\n\n# Later, start second feature (also copies .env files):\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh create feature-notifications\n\n# List what you have:\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh list\n\n# Switch between them as needed:\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh switch feature-login\n\n# Return to main and cleanup when done:\ncd .\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh cleanup\n```\n\n## Key Design Principles\n\n### KISS (Keep It Simple, Stupid)\n\n- **One manager script** handles all worktree operations\n- **Simple commands** with sensible defaults\n- **Interactive prompts** prevent accidental operations\n- **Clear naming** using branch names directly\n\n### Opinionated Defaults\n\n- Worktrees always created from **main** (unless specified)\n- Worktrees stored in **.worktrees/** directory\n- Branch name becomes worktree name\n- **.gitignore** automatically managed\n\n### Safety First\n\n- **Confirms before creating** worktrees\n- **Confirms before cleanup** to prevent accidental removal\n- **Won't remove current worktree**\n- **Clear error messages** for issues\n\n## Integration with Workflows\n\n### `/workflows:review`\n\nInstead of always creating a worktree:\n\n```\n1. Check current branch\n2. If ALREADY on PR branch ‚Üí stay there, no worktree needed\n3. If DIFFERENT branch ‚Üí offer worktree:\n   \"Use worktree for isolated review? (y/n)\"\n   - yes ‚Üí call git-worktree skill\n   - no ‚Üí proceed with PR diff on current branch\n```\n\n### `/workflows:work`\n\nAlways offer choice:\n\n```\n1. Ask: \"How do you want to work?\n   1. New branch on current worktree (live work)\n   2. Worktree (parallel work)\"\n\n2. If choice 1 ‚Üí create new branch normally\n3. If choice 2 ‚Üí call git-worktree skill to create from main\n```\n\n## Troubleshooting\n\n### \"Worktree already exists\"\n\nIf you see this, the script will ask if you want to switch to it instead.\n\n### \"Cannot remove worktree: it is the current worktree\"\n\nSwitch out of the worktree first (to main repo), then cleanup:\n\n```bash\ncd $(git rev-parse --show-toplevel)\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh cleanup\n```\n\n### Lost in a worktree?\n\nSee where you are:\n\n```bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh list\n```\n\n### .env files missing in worktree?\n\nIf a worktree was created without .env files (e.g., via raw `git worktree add`), copy them:\n\n```bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/git-worktree/scripts/worktree-manager.sh copy-env feature-name\n```\n\nNavigate back to main:\n\n```bash\ncd $(git rev-parse --show-toplevel)\n```\n\n## Technical Details\n\n### Directory Structure\n\n```\n.worktrees/\n‚îú‚îÄ‚îÄ feature-login/          # Worktree 1\n‚îÇ   ‚îú‚îÄ‚îÄ .git\n‚îÇ   ‚îú‚îÄ‚îÄ app/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ feature-notifications/  # Worktree 2\n‚îÇ   ‚îú‚îÄ‚îÄ .git\n‚îÇ   ‚îú‚îÄ‚îÄ app/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ ...\n\n.gitignore (updated to include .worktrees)\n```\n\n### How It Works\n\n- Uses `git worktree add` for isolated environments\n- Each worktree has its own branch\n- Changes in one worktree don't affect others\n- Share git history with main repo\n- Can push from any worktree\n\n### Performance\n\n- Worktrees are lightweight (just file system links)\n- No repository duplication\n- Shared git objects for efficiency\n- Much faster than cloning or stashing/switching"
              },
              {
                "name": "rclone",
                "description": "Upload, sync, and manage files across cloud storage providers using rclone. Use when uploading files (images, videos, documents) to S3, Cloudflare R2, Backblaze B2, Google Drive, Dropbox, or any S3-compatible storage. Triggers on \"upload to S3\", \"sync to cloud\", \"rclone\", \"backup files\", \"upload video/image to bucket\", or requests to transfer files to remote storage.",
                "path": "plugins/compound-engineering/skills/rclone/SKILL.md",
                "frontmatter": {
                  "name": "rclone",
                  "description": "Upload, sync, and manage files across cloud storage providers using rclone. Use when uploading files (images, videos, documents) to S3, Cloudflare R2, Backblaze B2, Google Drive, Dropbox, or any S3-compatible storage. Triggers on \"upload to S3\", \"sync to cloud\", \"rclone\", \"backup files\", \"upload video/image to bucket\", or requests to transfer files to remote storage."
                },
                "content": "# rclone File Transfer Skill\n\n## Setup Check (Always Run First)\n\nBefore any rclone operation, verify installation and configuration:\n\n```bash\n# Check if rclone is installed\ncommand -v rclone >/dev/null 2>&1 && echo \"rclone installed: $(rclone version | head -1)\" || echo \"NOT INSTALLED\"\n\n# List configured remotes\nrclone listremotes 2>/dev/null || echo \"NO REMOTES CONFIGURED\"\n```\n\n### If rclone is NOT installed\n\nGuide the user to install:\n\n```bash\n# macOS\nbrew install rclone\n\n# Linux (script install)\ncurl https://rclone.org/install.sh | sudo bash\n\n# Or via package manager\nsudo apt install rclone  # Debian/Ubuntu\nsudo dnf install rclone  # Fedora\n```\n\n### If NO remotes are configured\n\nWalk the user through interactive configuration:\n\n```bash\nrclone config\n```\n\n**Common provider setup quick reference:**\n\n| Provider | Type | Key Settings |\n|----------|------|--------------|\n| AWS S3 | `s3` | access_key_id, secret_access_key, region |\n| Cloudflare R2 | `s3` | access_key_id, secret_access_key, endpoint (account_id.r2.cloudflarestorage.com) |\n| Backblaze B2 | `b2` | account (keyID), key (applicationKey) |\n| DigitalOcean Spaces | `s3` | access_key_id, secret_access_key, endpoint (region.digitaloceanspaces.com) |\n| Google Drive | `drive` | OAuth flow (opens browser) |\n| Dropbox | `dropbox` | OAuth flow (opens browser) |\n\n**Example: Configure Cloudflare R2**\n```bash\nrclone config create r2 s3 \\\n  provider=Cloudflare \\\n  access_key_id=YOUR_ACCESS_KEY \\\n  secret_access_key=YOUR_SECRET_KEY \\\n  endpoint=ACCOUNT_ID.r2.cloudflarestorage.com \\\n  acl=private\n```\n\n**Example: Configure AWS S3**\n```bash\nrclone config create aws s3 \\\n  provider=AWS \\\n  access_key_id=YOUR_ACCESS_KEY \\\n  secret_access_key=YOUR_SECRET_KEY \\\n  region=us-east-1\n```\n\n## Common Operations\n\n### Upload single file\n```bash\nrclone copy /path/to/file.mp4 remote:bucket/path/ --progress\n```\n\n### Upload directory\n```bash\nrclone copy /path/to/folder remote:bucket/folder/ --progress\n```\n\n### Sync directory (mirror, deletes removed files)\n```bash\nrclone sync /local/path remote:bucket/path/ --progress\n```\n\n### List remote contents\n```bash\nrclone ls remote:bucket/\nrclone lsd remote:bucket/  # directories only\n```\n\n### Check what would be transferred (dry run)\n```bash\nrclone copy /path remote:bucket/ --dry-run\n```\n\n## Useful Flags\n\n| Flag | Purpose |\n|------|---------|\n| `--progress` | Show transfer progress |\n| `--dry-run` | Preview without transferring |\n| `-v` | Verbose output |\n| `--transfers=N` | Parallel transfers (default 4) |\n| `--bwlimit=RATE` | Bandwidth limit (e.g., `10M`) |\n| `--checksum` | Compare by checksum, not size/time |\n| `--exclude=\"*.tmp\"` | Exclude patterns |\n| `--include=\"*.mp4\"` | Include only matching |\n| `--min-size=SIZE` | Skip files smaller than SIZE |\n| `--max-size=SIZE` | Skip files larger than SIZE |\n\n## Large File Uploads\n\nFor videos and large files, use chunked uploads:\n\n```bash\n# S3 multipart upload (automatic for >200MB)\nrclone copy large_video.mp4 remote:bucket/ --s3-chunk-size=64M --progress\n\n# Resume interrupted transfers\nrclone copy /path remote:bucket/ --progress --retries=5\n```\n\n## Verify Upload\n\n```bash\n# Check file exists and matches\nrclone check /local/file remote:bucket/file\n\n# Get file info\nrclone lsl remote:bucket/path/to/file\n```\n\n## Troubleshooting\n\n```bash\n# Test connection\nrclone lsd remote:\n\n# Debug connection issues\nrclone lsd remote: -vv\n\n# Check config\nrclone config show remote\n```"
              },
              {
                "name": "skill-creator",
                "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
                "path": "plugins/compound-engineering/skills/skill-creator/SKILL.md",
                "frontmatter": {
                  "name": "skill-creator",
                  "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks‚Äîthey transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter metadata (required)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ name: (required)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ description: (required)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions (required)\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/          - Executable code (Python/Bash/etc.)\n    ‚îú‚îÄ‚îÄ references/       - Documentation intended to be loaded into context as needed\n    ‚îî‚îÄ‚îÄ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill‚Äîthis keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\nTo complete SKILL.md, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used?\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n### Step 5: Packaging a Skill\n\nOnce the skill is ready, it should be packaged into a distributable zip file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a zip file named after the skill (e.g., `my-skill.zip`) that includes all files and maintains the proper directory structure for distribution.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again"
              }
            ]
          },
          {
            "name": "coding-tutor",
            "description": "Personalized coding tutorials that build on your existing knowledge and use your actual codebase for examples. Includes spaced repetition quizzes to reinforce learning. Includes 3 commands and 1 skill.",
            "source": "./plugins/coding-tutor",
            "category": null,
            "version": "1.2.1",
            "author": {
              "name": "Nityesh Agarwal"
            },
            "install_commands": [
              "/plugin marketplace add EveryInc/compound-engineering-plugin",
              "/plugin install coding-tutor@every-marketplace"
            ],
            "signals": {
              "stars": 4576,
              "forks": 386,
              "pushed_at": "2026-01-09T16:07:41Z",
              "created_at": "2025-10-09T19:43:46Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/quiz-me",
                "description": null,
                "path": "plugins/coding-tutor/commands/quiz-me.md",
                "frontmatter": null,
                "content": "Quiz me using the coding-tutor skill\n"
              },
              {
                "name": "/sync-tutorials",
                "description": null,
                "path": "plugins/coding-tutor/commands/sync-tutorials.md",
                "frontmatter": null,
                "content": "# Sync Coding Tutor Tutorials\n\nCommit and push your tutorials to the GitHub repository for backup and mobile reading.\n\n## Instructions\n\n1. **Go to the tutorials repo**: `cd ~/coding-tutor-tutorials`\n\n2. **Check for changes**: Run `git status` to see what's new or modified\n\n3. **If there are changes**:\n   - Stage all changes: `git add -A`\n   - Create a commit with a message summarizing what was added/updated (e.g., \"Add tutorial on React hooks\" or \"Update quiz scores\")\n   - Push to origin: `git push`\n\n4. **If no GitHub remote exists**:\n   - Create the repo: `gh repo create coding-tutor-tutorials --private --source=. --push`\n\n5. **Report results**: Tell the user what was synced or that everything is already up to date\n\n## Notes\n\n- The tutorials repo is at: `~/coding-tutor-tutorials/`\n- Always use `--private` when creating the GitHub repo\n- This is your personal learning journey - keep it backed up!\n"
              },
              {
                "name": "/teach-me",
                "description": null,
                "path": "plugins/coding-tutor/commands/teach-me.md",
                "frontmatter": null,
                "content": "Teach me something using the coding-tutor skill\n"
              }
            ],
            "skills": [
              {
                "name": "coding-tutor",
                "description": "Personalized coding tutorials that build on your existing knowledge and use your actual codebase for examples. Creates a persistent learning trail that compounds over time using the power of AI, spaced repetition and quizes.",
                "path": "plugins/coding-tutor/skills/coding-tutor/SKILL.md",
                "frontmatter": {
                  "name": "coding-tutor",
                  "description": "Personalized coding tutorials that build on your existing knowledge and use your actual codebase for examples. Creates a persistent learning trail that compounds over time using the power of AI, spaced repetition and quizes."
                },
                "content": "This skill creates personalized coding tutorials that evolve with the learner. Each tutorial builds on previous ones, uses real examples from the current codebase, and maintains a persistent record of concepts mastered.\n\nThe user asks to learn something - either a specific concept or an open \"teach me something new\" request.\n\n## Welcome New Learners\n\nIf `~/coding-tutor-tutorials/` does not exist, this is a new learner. Before running setup, introduce yourself:\n\n> I'm your personal coding tutor. I create tutorials tailored to you - using real code from your projects, building on what you already know, and tracking your progress over time.\n>\n> All your tutorials live in one central library (`~/coding-tutor-tutorials/`) that works across all your projects. Use `/teach-me` to learn something new, `/quiz-me` to test your retention with spaced repetition.\n\nThen proceed with setup and onboarding.\n\n## Setup: Ensure Tutorials Repo Exists\n\n**Before doing anything else**, run the setup script to ensure the central tutorials repository exists:\n\n```bash\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/coding-tutor/scripts/setup_tutorials.py\n```\n\nThis creates `~/coding-tutor-tutorials/` if it doesn't exist. All tutorials and the learner profile are stored there, shared across all your projects.\n\n## First Step: Know Your Learner\n\n**Always start by reading `~/coding-tutor-tutorials/learner_profile.md` if it exists.** This profile contains crucial context about who you're teaching - their background, goals, and personality. Use it to calibrate everything: what analogies will land, how fast to move, what examples resonate.\n\nIf no tutorials exist in `~/coding-tutor-tutorials/` AND no learner profile exists at `~/coding-tutor-tutorials/learner_profile.md`, this is a brand new learner. Before teaching anything, you need to understand who you're teaching.\n\n**Onboarding Interview:**\n\nAsk these three questions, one at a time. Wait for each answer before asking the next.\n\n1. **Prior exposure**: What's your background with programming? - Understand if they've built anything before, followed tutorials, or if this is completely new territory.\n\n2. **Ambitious goal**: This is your private AI tutor whose goal is to make you a top 1% programmer. Where do you want this to take you? - Understand what success looks like for them: a million-dollar product, a job at a company they admire, or something else entirely.\n\n3. **Who are you**: Tell me a bit about yourself - imagine we just met at a coworking space. - Get context that shapes how to teach them.\n\n4. **Optional**: Based on the above answers, you may ask upto one optional 4th question if it will make your understanding of the learner richer.\n\nAfter gathering responses, create `~/coding-tutor-tutorials/learner_profile.md` and put the interview Q&A there (along with your commentary):\n\n```yaml\n---\ncreated: DD-MM-YYYY\nlast_updated: DD-MM-YYYY\n---\n\n**Q1. <insert question you asked>**\n**Answer**. <insert user's answer>\n**your internal commentary**\n\n**Q2. <insert question you asked>**\n**Answer**. <insert user's answer>\n**your internal commentary**\n\n**Q3. <insert question you asked>**\n**Answer**. <insert user's answer>\n**your internal commentary**\n\n**Q4. <optional>\n```\n\n## Teaching Philosophy\n\nOur general goal is to take the user from newbie to a senior engineer in record time. One at par with engineers at companies like 37 Signals or Vercel.\n\nBefore creating a tutorial, make a plan by following these steps:\n\n- **Load learner context**: Read `~/coding-tutor-tutorials/learner_profile.md` to understand who you're teaching - their background, goals, and personality.\n- **Survey existing knowledge**: Run `python3 ${CLAUDE_PLUGIN_ROOT}/skills/coding-tutor/scripts/index_tutorials.py` to understand what concepts have been covered, at what depth, and how well they landed (understanding scores). Optionally, dive into particular tutorials in `~/coding-tutor-tutorials/` to read them.\n- **Identify the gap**: What's the next concept that would be most valuable? Consider both what they've asked for AND what naturally follows from their current knowledge. Think of a curriculum that would get them from their current point to Senior Engineer - what should be the next 3 topics they need to learn to advance their programming knowledge in this direction?\n- **Find the anchor**: Locate real examples in the codebase that demonstrate this concept. Learning from abstract examples is forgettable; learning from YOUR code is sticky.\n- **(Optional) Use ask-user-question tool**: Ask clarifying questions to the learner to understand their intent, goals or expectations if it'll help you make a better plan.\n\nThen show this curriculum plan of **next 3 TUTORIALS** to the user and proceed to the tutorial creation step only if the user approves. If the user rejects, create a new plan using steps mentioned above.\n\n## Tutorial Creation\n\nEach tutorial is a markdown file in `~/coding-tutor-tutorials/` with this structure:\n```yaml\n---\nconcepts: [primary_concept, related_concept_1, related_concept_2]\nsource_repo: my-app  # Auto-detected: which repo this tutorial's examples come from\ndescription: One-paragraph summary of what this tutorial covers\nunderstanding_score: null  # null until quizzed, then 1-10 based on quiz performance\nlast_quizzed: null  # null until first quiz, then DD-MM-YYYY\nprerequisites: [~/coding-tutor-tutorials/tutorial_1_name.md, ~/coding-tutor-tutorials/tutorial_2_name.md, (upto 3 other existing tutorials)]\ncreated: DD-MM-YYYY\nlast_updated: DD-MM-YYYY\n---\n\nFull contents of tutorial go here\n\n---\n\n## Q&A\n\nCross-questions during learning go here.\n\n## Quiz History\n\nQuiz sessions recorded here.\n```\n\nRun `scripts/create_tutorial.py` like this to create a new tutorial with template:\n\n```bash\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/coding-tutor/scripts/create_tutorial.py \"Topic Name\" --concepts \"Concept1,Concept2\"\n```\n\nThis creates an empty template of the tutorial. Then you should edit the newly created file to write in the actual tutorial.\nQualities of a great tutorial should:\n\n- **Start with the \"why\"**: Not \"here's how callbacks work\" but \"here's the problem in your code that callbacks solve\"\n- **Use their code**: Every concept demonstrated with examples pulled from the actual codebase. Reference specific files and line numbers.\n- **Build mental models**: Diagrams, analogies, the underlying \"shape\" of the concept - not just syntax, ELI5\n- **Predict confusion**: Address the questions they're likely to ask before they ask them, don't skim over things, don't write in a notes style\n- **End with a challenge**: A small exercise they could try in this codebase to cement understanding\n\n### Tutorial Writing Style\n\nWrite personal tutorials like the best programming educators: Julia Evans, Dan Abramov. Not like study notes or documentation. There's a difference between a well-structured tutorial and one that truly teaches.\n\n- Show the struggle - \"Here's what you might try... here's why it doesn't work... here's the insight that unlocks it.\"\n- Fewer concepts, more depth - A tutorial that teaches 3 things deeply beats one that mentions 10 things.\n- Tell stories - a great tutorial is one coherent story, dives deep into a single concept, using storytelling techniques that engage readers\n\nWe should make the learner feel like Julia Evans or Dan Abramov is their private tutor.\n\nNote: If you're not sure about a fact or capability or new features/APIs, do web research, look at documentation to make sure you're teaching accurate up-to-date things. NEVER commit the sin of teaching something incorrect.\n\n## The Living Tutorial\n\nTutorials aren't static documents - they evolve:\n\n- **Q&A is mandatory**: When the learner asks ANY clarifying question about a tutorial, you MUST append it to the tutorial's `## Q&A` section. This is not optional - these exchanges are part of their personalized learning record and improve future teaching.\n- If the learner says they can't follow the tutorial or need you to take a different approach, update the tutorial like they ask\n- Update `last_updated` timestamp\n- If a question reveals a gap in prerequisites, note it for future tutorial planning\n\nNote: `understanding_score` is only updated through Quiz Mode, not during teaching.\n\n## What Makes Great Teaching\n**DO**: Meet them where they are. Use their vocabulary. Reference their past struggles. Make connections to concepts they already own. Be encouraging but honest about complexity.\n\n**DON'T**: Assume knowledge not demonstrated in previous tutorials. Use generic blog-post examples when codebase examples exist. Overwhelm with every edge case upfront. Be condescending about gaps.\n\n**CALIBRATE**: A learner with 3 tutorials is different from one with 30. Early tutorials need more scaffolding and encouragement. Later tutorials can move faster and reference the shared history you've built.\n\nRemember: The goal isn't to teach programming in the abstract. It's to teach THIS person, using THEIR code, building on THEIR specific journey. Every tutorial should feel like it was written specifically for them - because it was.\n\n## Quiz Mode\n\nTutorials teach. Quizzes verify. The score should reflect what the learner actually retained, not what was presented to them.\n\n**Triggers:**\n- Explicit: \"Quiz me on React hooks\" ‚Üí quiz that specific concept\n- Open: \"Quiz me on something\" ‚Üí run `python3 ${CLAUDE_PLUGIN_ROOT}/skills/coding-tutor/scripts/quiz_priority.py` to get a prioritized list based on spaced repetition, then choose what to quiz\n\n**Spaced Repetition:**\n\nWhen the user requests an open quiz, the priority script uses spaced repetition intervals to surface:\n- Never-quizzed tutorials (need baseline assessment)\n- Low-scored concepts that are overdue for review\n- High-scored concepts whose review interval has elapsed\n\nThe script uses Fibonacci-ish intervals: score 1 = review in 2 days, score 5 = 13 days, score 8 = 55 days, score 10 = 144 days. This means weak concepts get drilled frequently while mastered ones fade into long-term review.\n\nThe script gives you an ordered list with `understanding_score` and `last_quizzed` for each tutorial. Use this to make an informed choice about what to quiz, and explain to the learner why you picked that concept (\"You learned callbacks 5 days ago but scored 4/10 - let's see if it's sticking better now\").\n\n**Philosophy:**\n\nA quiz isn't an exam - it's a conversation that reveals understanding. Ask questions that expose mental models, not just syntax recall. The goal is to find the edges of their knowledge: where does solid understanding fade into uncertainty?\n\n**Ask only 1 question at a time.** Wait for the learner's answer before asking the next question.\n\nMix question types based on what the concept demands:\n- Conceptual (\"when would you use X over Y?\")\n- Code reading (\"what does this code in your app do?\")\n- Code writing (\"write a scope that does X\")\n- Debugging (\"what's wrong here?\")\n\nUse their codebase for examples whenever possible. \"What does line 47 of `app/models/user.rb` do?\" is more valuable than abstract snippets.\n\n**Scoring:**\n\nAfter the quiz, update `understanding_score` honestly:\n- **1-3**: Can't recall the concept, needs re-teaching\n- **4-5**: Vague memory, partial answers\n- **6-7**: Solid understanding, minor gaps\n- **8-9**: Strong grasp, handles edge cases\n- **10**: Could teach this to someone else\n\nAlso update `last_quizzed: DD-MM-YYYY` in the frontmatter.\n\n**Recording:**\n\nAppend to the tutorial's `## Quiz History` section:\n```\n### Quiz - DD-MM-YYYY\n**Q:** [Question asked]\n**A:** [Brief summary of their response and what it revealed about understanding]\nScore updated: 5 ‚Üí 7\n```\n\nThis history helps future quizzes avoid repetition and track progression over time."
              }
            ]
          }
        ]
      }
    }
  ]
}