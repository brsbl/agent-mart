{
  "owner": {
    "id": "outfitter-dev",
    "display_name": "Outfitter",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/206289526?v=4",
    "url": "https://github.com/outfitter-dev",
    "bio": "Making things to help agents & devs make things.",
    "stats": {
      "total_repos": 1,
      "total_plugins": 4,
      "total_commands": 8,
      "total_skills": 39,
      "total_stars": 15,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "outfitter-dev/agents",
      "url": "https://github.com/outfitter-dev/agents",
      "description": "Rules files & configurations for agents",
      "homepage": null,
      "signals": {
        "stars": 15,
        "forks": 0,
        "pushed_at": "2026-01-11T17:32:42Z",
        "created_at": "2025-08-30T16:37:06Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/notes",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/notes/202511281355-consolidation-from-agentish.md",
          "type": "blob",
          "size": 5066
        },
        {
          "path": ".agents/notes/202511281430-config-claude-inventory.md",
          "type": "blob",
          "size": 5998
        },
        {
          "path": ".agents/notes/202512221158-skill-naming-standardization.md",
          "type": "blob",
          "size": 2002
        },
        {
          "path": ".agents/notes/202512311635-agent-authoring-skill-gaps.md",
          "type": "blob",
          "size": 13595
        },
        {
          "path": ".agents/notes/superpowers-subagent-patterns.md",
          "type": "blob",
          "size": 4895
        },
        {
          "path": ".agents/plans",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/plans/ast-grep",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/plans/ast-grep/PLAN.md",
          "type": "blob",
          "size": 26343
        },
        {
          "path": ".agents/plans/guardrails",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/plans/guardrails/PLAN.md",
          "type": "blob",
          "size": 25277
        },
        {
          "path": ".agents/plans/patternify",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/plans/patternify/CHECKLIST.md",
          "type": "blob",
          "size": 3974
        },
        {
          "path": ".agents/plans/patternify/COMPONENTS.md",
          "type": "blob",
          "size": 12294
        },
        {
          "path": ".agents/plans/patternify/PLAN.md",
          "type": "blob",
          "size": 18420
        },
        {
          "path": ".agents/plans/skills-suite",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/plans/skills-suite/ANALYSIS.md",
          "type": "blob",
          "size": 19435
        },
        {
          "path": ".agents/plans/skills-suite/INTEGRATION-PLAN.md",
          "type": "blob",
          "size": 28302
        },
        {
          "path": ".agents/plans/skills-suite/SPEC.md",
          "type": "blob",
          "size": 61600
        },
        {
          "path": ".beads",
          "type": "tree",
          "size": null
        },
        {
          "path": ".beads/.gitignore",
          "type": "blob",
          "size": 464
        },
        {
          "path": ".beads/README.md",
          "type": "blob",
          "size": 2250
        },
        {
          "path": ".beads/config.yaml",
          "type": "blob",
          "size": 2260
        },
        {
          "path": ".beads/deletions.jsonl",
          "type": "blob",
          "size": 140
        },
        {
          "path": ".beads/issues.jsonl",
          "type": "blob",
          "size": 13218
        },
        {
          "path": ".beads/metadata.json",
          "type": "blob",
          "size": 93
        },
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1756
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/rules",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/rules/COMMANDS.md",
          "type": "blob",
          "size": 1998
        },
        {
          "path": ".claude/rules/FORMATTING.md",
          "type": "blob",
          "size": 72
        },
        {
          "path": ".claude/rules/PLUGINS.md",
          "type": "blob",
          "size": 2768
        },
        {
          "path": ".claude/rules/SUBAGENTS.md",
          "type": "blob",
          "size": 3954
        },
        {
          "path": ".gitattributes",
          "type": "blob",
          "size": 70
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/claude-code-review.yml",
          "type": "blob",
          "size": 1964
        },
        {
          "path": ".github/workflows/claude.yml",
          "type": "blob",
          "size": 1898
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 381
        },
        {
          "path": ".markdownlint-cli2.jsonc",
          "type": "blob",
          "size": 2450
        },
        {
          "path": ".vscode",
          "type": "tree",
          "size": null
        },
        {
          "path": ".vscode/settings.json",
          "type": "blob",
          "size": 51
        },
        {
          "path": "AGENTS.md",
          "type": "blob",
          "size": 2970
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 3649
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1066
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5983
        },
        {
          "path": "SECURITY.md",
          "type": "blob",
          "size": 3148
        },
        {
          "path": "agent-kit",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 634
        },
        {
          "path": "agent-kit/README.md",
          "type": "blob",
          "size": 4859
        },
        {
          "path": "agent-kit/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/agents/agent-expert.md",
          "type": "blob",
          "size": 7853
        },
        {
          "path": "agent-kit/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/scripts/init-plugin.sh",
          "type": "blob",
          "size": 14102
        },
        {
          "path": "agent-kit/scripts/test-plugin.sh",
          "type": "blob",
          "size": 8776
        },
        {
          "path": "agent-kit/scripts/validate-plugin.sh",
          "type": "blob",
          "size": 15855
        },
        {
          "path": "agent-kit/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/shared/rules",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/shared/rules/ENV-VARS.md",
          "type": "blob",
          "size": 1649
        },
        {
          "path": "agent-kit/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-agent-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-agent-development/EXAMPLES.md",
          "type": "blob",
          "size": 49914
        },
        {
          "path": "agent-kit/skills/claude-agent-development/SKILL.md",
          "type": "blob",
          "size": 10710
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/advanced-features.md",
          "type": "blob",
          "size": 4226
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/agent-types.md",
          "type": "blob",
          "size": 2873
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/agent-vs-skill.md",
          "type": "blob",
          "size": 1732
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/discovery.md",
          "type": "blob",
          "size": 2315
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/frontmatter.md",
          "type": "blob",
          "size": 5129
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/patterns.md",
          "type": "blob",
          "size": 3358
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/performance.md",
          "type": "blob",
          "size": 2370
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/task-tool.md",
          "type": "blob",
          "size": 10445
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/todowrite.md",
          "type": "blob",
          "size": 4909
        },
        {
          "path": "agent-kit/skills/claude-agent-development/references/tools.md",
          "type": "blob",
          "size": 2521
        },
        {
          "path": "agent-kit/skills/claude-agent-development/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-agent-development/scripts/scaffold-agent.sh",
          "type": "blob",
          "size": 18193
        },
        {
          "path": "agent-kit/skills/claude-agent-development/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-agent-development/templates/advanced.md",
          "type": "blob",
          "size": 2833
        },
        {
          "path": "agent-kit/skills/claude-agent-development/templates/basic.md",
          "type": "blob",
          "size": 867
        },
        {
          "path": "agent-kit/skills/claude-code-configuration",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-code-configuration/EXAMPLES.md",
          "type": "blob",
          "size": 4993
        },
        {
          "path": "agent-kit/skills/claude-code-configuration/SKILL.md",
          "type": "blob",
          "size": 3132
        },
        {
          "path": "agent-kit/skills/claude-code-configuration/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-code-configuration/references/mcp-patterns.md",
          "type": "blob",
          "size": 2965
        },
        {
          "path": "agent-kit/skills/claude-code-configuration/references/troubleshooting.md",
          "type": "blob",
          "size": 3343
        },
        {
          "path": "agent-kit/skills/claude-code-configuration/references/workflows.md",
          "type": "blob",
          "size": 3579
        },
        {
          "path": "agent-kit/skills/claude-command-authoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/EXAMPLES.md",
          "type": "blob",
          "size": 21247
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/SKILL.md",
          "type": "blob",
          "size": 10343
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/arguments.md",
          "type": "blob",
          "size": 5328
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/bash-execution.md",
          "type": "blob",
          "size": 6379
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/community.md",
          "type": "blob",
          "size": 6857
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/file-references.md",
          "type": "blob",
          "size": 5305
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/frontmatter.md",
          "type": "blob",
          "size": 7985
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/namespacing.md",
          "type": "blob",
          "size": 5779
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/permissions.md",
          "type": "blob",
          "size": 6304
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/references/sdk-integration.md",
          "type": "blob",
          "size": 8200
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/scripts/scaffold-command.sh",
          "type": "blob",
          "size": 5134
        },
        {
          "path": "agent-kit/skills/claude-command-authoring/scripts/validate-command.sh",
          "type": "blob",
          "size": 8128
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/SKILL.md",
          "type": "blob",
          "size": 12219
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/references/examples.md",
          "type": "blob",
          "size": 37834
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/references/hook-types.md",
          "type": "blob",
          "size": 13469
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/references/matchers.md",
          "type": "blob",
          "size": 7225
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/references/schema.md",
          "type": "blob",
          "size": 32664
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/references/security.md",
          "type": "blob",
          "size": 10915
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/scripts/scaffold-hook.sh",
          "type": "blob",
          "size": 16755
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/scripts/test-hook.ts",
          "type": "blob",
          "size": 10985
        },
        {
          "path": "agent-kit/skills/claude-hook-authoring/scripts/validate-hook.sh",
          "type": "blob",
          "size": 9673
        },
        {
          "path": "agent-kit/skills/claude-plugin-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/SKILL.md",
          "type": "blob",
          "size": 9993
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/references/distribution.md",
          "type": "blob",
          "size": 7427
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/references/marketplace.md",
          "type": "blob",
          "size": 9584
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/references/structure.md",
          "type": "blob",
          "size": 7639
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/scripts/create-marketplace.sh",
          "type": "blob",
          "size": 4560
        },
        {
          "path": "agent-kit/skills/claude-plugin-development/scripts/scaffold-plugin.sh",
          "type": "blob",
          "size": 9390
        },
        {
          "path": "agent-kit/skills/claude-rules-authoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/claude-rules-authoring/SKILL.md",
          "type": "blob",
          "size": 3783
        },
        {
          "path": "agent-kit/skills/codex-configuration",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/codex-configuration/SKILL.md",
          "type": "blob",
          "size": 3699
        },
        {
          "path": "agent-kit/skills/codex-configuration/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/codex-configuration/references/mcp-servers.md",
          "type": "blob",
          "size": 2275
        },
        {
          "path": "agent-kit/skills/codex-configuration/references/security.md",
          "type": "blob",
          "size": 3248
        },
        {
          "path": "agent-kit/skills/codex-configuration/references/troubleshooting.md",
          "type": "blob",
          "size": 2811
        },
        {
          "path": "agent-kit/skills/skills-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/SKILL.md",
          "type": "blob",
          "size": 10707
        },
        {
          "path": "agent-kit/skills/skills-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/references/best-practices.md",
          "type": "blob",
          "size": 29681
        },
        {
          "path": "agent-kit/skills/skills-development/references/claude.md",
          "type": "blob",
          "size": 6425
        },
        {
          "path": "agent-kit/skills/skills-development/references/codex.md",
          "type": "blob",
          "size": 6702
        },
        {
          "path": "agent-kit/skills/skills-development/references/compatibility.md",
          "type": "blob",
          "size": 4193
        },
        {
          "path": "agent-kit/skills/skills-development/references/implementations.md",
          "type": "blob",
          "size": 6506
        },
        {
          "path": "agent-kit/skills/skills-development/references/invocations.md",
          "type": "blob",
          "size": 6677
        },
        {
          "path": "agent-kit/skills/skills-development/references/patterns.md",
          "type": "blob",
          "size": 12300
        },
        {
          "path": "agent-kit/skills/skills-development/references/quick-reference.md",
          "type": "blob",
          "size": 6956
        },
        {
          "path": "agent-kit/skills/skills-development/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/scripts/init-skill.ts",
          "type": "blob",
          "size": 6372
        },
        {
          "path": "agent-kit/skills/skills-development/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/api-wrapper",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/api-wrapper/SKILL.template.md",
          "type": "blob",
          "size": 1153
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/api-wrapper/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/api-wrapper/scripts/client.ts",
          "type": "blob",
          "size": 2545
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/dev-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/dev-workflow/SKILL.template.md",
          "type": "blob",
          "size": 1641
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/dev-workflow/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/dev-workflow/scripts/run.ts",
          "type": "blob",
          "size": 3475
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/document-processor",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/document-processor/SKILL.template.md",
          "type": "blob",
          "size": 1535
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/document-processor/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/document-processor/scripts/process.ts",
          "type": "blob",
          "size": 3494
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/research-synthesizer",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/research-synthesizer/SKILL.template.md",
          "type": "blob",
          "size": 1937
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/simple",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/skills/skills-development/templates/skill-archetypes/simple/SKILL.template.md",
          "type": "blob",
          "size": 707
        },
        {
          "path": "agent-kit/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/QUICK_START.md",
          "type": "blob",
          "size": 6763
        },
        {
          "path": "agent-kit/templates/README.md",
          "type": "blob",
          "size": 12890
        },
        {
          "path": "agent-kit/templates/SUMMARY.md",
          "type": "blob",
          "size": 3785
        },
        {
          "path": "agent-kit/templates/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/agents/code-reviewer.md",
          "type": "blob",
          "size": 7615
        },
        {
          "path": "agent-kit/templates/agents/documentation-generator.md",
          "type": "blob",
          "size": 12399
        },
        {
          "path": "agent-kit/templates/agents/test-specialist.md",
          "type": "blob",
          "size": 11336
        },
        {
          "path": "agent-kit/templates/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/hooks/bash-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/hooks/bash-validator/hooks.json",
          "type": "blob",
          "size": 227
        },
        {
          "path": "agent-kit/templates/hooks/bash-validator/validate-bash.ts",
          "type": "blob",
          "size": 2907
        },
        {
          "path": "agent-kit/templates/hooks/post-tool-use-formatter",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/hooks/post-tool-use-formatter/format.sh",
          "type": "blob",
          "size": 1144
        },
        {
          "path": "agent-kit/templates/hooks/post-tool-use-formatter/hooks.json",
          "type": "blob",
          "size": 233
        },
        {
          "path": "agent-kit/templates/hooks/pre-tool-use-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/hooks/pre-tool-use-validator/hooks.json",
          "type": "blob",
          "size": 228
        },
        {
          "path": "agent-kit/templates/hooks/pre-tool-use-validator/validate.sh",
          "type": "blob",
          "size": 1713
        },
        {
          "path": "agent-kit/templates/hooks/user-prompt-context",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/hooks/user-prompt-context/add-context.sh",
          "type": "blob",
          "size": 997
        },
        {
          "path": "agent-kit/templates/hooks/user-prompt-context/hooks.json",
          "type": "blob",
          "size": 227
        },
        {
          "path": "agent-kit/templates/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/skills/multi-file-skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/skills/multi-file-skill/EXAMPLES.md",
          "type": "blob",
          "size": 5121
        },
        {
          "path": "agent-kit/templates/skills/multi-file-skill/REFERENCE.md",
          "type": "blob",
          "size": 3821
        },
        {
          "path": "agent-kit/templates/skills/multi-file-skill/SKILL.template.md",
          "type": "blob",
          "size": 2626
        },
        {
          "path": "agent-kit/templates/skills/simple-skill",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/skills/simple-skill/SKILL.template.md",
          "type": "blob",
          "size": 2017
        },
        {
          "path": "agent-kit/templates/skills/skill-with-scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/skills/skill-with-scripts/SKILL.template.md",
          "type": "blob",
          "size": 5142
        },
        {
          "path": "agent-kit/templates/skills/skill-with-scripts/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/skills/skill-with-scripts/scripts/helper.sh",
          "type": "blob",
          "size": 2035
        },
        {
          "path": "agent-kit/templates/slash-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-kit/templates/slash-commands/simple.md",
          "type": "blob",
          "size": 388
        },
        {
          "path": "agent-kit/templates/slash-commands/with-args.md",
          "type": "blob",
          "size": 769
        },
        {
          "path": "agent-kit/templates/slash-commands/with-bash.md",
          "type": "blob",
          "size": 998
        },
        {
          "path": "agent-kit/templates/slash-commands/with-files.md",
          "type": "blob",
          "size": 1223
        },
        {
          "path": "baselayer",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 523
        },
        {
          "path": "baselayer/README.md",
          "type": "blob",
          "size": 4616
        },
        {
          "path": "baselayer/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/agents/analyst.md",
          "type": "blob",
          "size": 10433
        },
        {
          "path": "baselayer/agents/debugger.md",
          "type": "blob",
          "size": 14067
        },
        {
          "path": "baselayer/agents/librarian.md",
          "type": "blob",
          "size": 8765
        },
        {
          "path": "baselayer/agents/pattern-analyzer.md",
          "type": "blob",
          "size": 6824
        },
        {
          "path": "baselayer/agents/ranger.md",
          "type": "blob",
          "size": 12719
        },
        {
          "path": "baselayer/agents/scout.md",
          "type": "blob",
          "size": 10107
        },
        {
          "path": "baselayer/agents/senior-dev.md",
          "type": "blob",
          "size": 6050
        },
        {
          "path": "baselayer/agents/skeptic.md",
          "type": "blob",
          "size": 7751
        },
        {
          "path": "baselayer/agents/specialist.md",
          "type": "blob",
          "size": 6957
        },
        {
          "path": "baselayer/agents/tester.md",
          "type": "blob",
          "size": 6741
        },
        {
          "path": "baselayer/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/commands/best-tool.md",
          "type": "blob",
          "size": 830
        },
        {
          "path": "baselayer/commands/debug.md",
          "type": "blob",
          "size": 3328
        },
        {
          "path": "baselayer/commands/dispatch-agents.md",
          "type": "blob",
          "size": 1828
        },
        {
          "path": "baselayer/commands/pathfind.md",
          "type": "blob",
          "size": 940
        },
        {
          "path": "baselayer/commands/patternify.md",
          "type": "blob",
          "size": 2601
        },
        {
          "path": "baselayer/commands/simplify.md",
          "type": "blob",
          "size": 5413
        },
        {
          "path": "baselayer/commands/sitrep.md",
          "type": "blob",
          "size": 1015
        },
        {
          "path": "baselayer/commands/tdd.md",
          "type": "blob",
          "size": 1865
        },
        {
          "path": "baselayer/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/shared/rules",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/shared/rules/FORMATTING.md",
          "type": "blob",
          "size": 5322
        },
        {
          "path": "baselayer/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/ai-sdk",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/ai-sdk/SKILL.md",
          "type": "blob",
          "size": 8808
        },
        {
          "path": "baselayer/skills/ai-sdk/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/ai-sdk/references/agents.md",
          "type": "blob",
          "size": 3795
        },
        {
          "path": "baselayer/skills/ai-sdk/references/persistence.md",
          "type": "blob",
          "size": 6314
        },
        {
          "path": "baselayer/skills/ai-sdk/references/tool-approval.md",
          "type": "blob",
          "size": 6323
        },
        {
          "path": "baselayer/skills/bun-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/bun-dev/SKILL.md",
          "type": "blob",
          "size": 10340
        },
        {
          "path": "baselayer/skills/bun-dev/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/bun-dev/examples/database-crud.md",
          "type": "blob",
          "size": 11135
        },
        {
          "path": "baselayer/skills/bun-dev/examples/file-uploads.md",
          "type": "blob",
          "size": 10626
        },
        {
          "path": "baselayer/skills/bun-dev/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/bun-dev/references/server-patterns.md",
          "type": "blob",
          "size": 9077
        },
        {
          "path": "baselayer/skills/bun-dev/references/sqlite-patterns.md",
          "type": "blob",
          "size": 7817
        },
        {
          "path": "baselayer/skills/bun-dev/references/testing.md",
          "type": "blob",
          "size": 8802
        },
        {
          "path": "baselayer/skills/cli-development-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/cli-development-guidelines/SKILL.md",
          "type": "blob",
          "size": 742
        },
        {
          "path": "baselayer/skills/code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/code-review/SKILL.md",
          "type": "blob",
          "size": 8600
        },
        {
          "path": "baselayer/skills/code-review/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/code-review/references/checklist.md",
          "type": "blob",
          "size": 20946
        },
        {
          "path": "baselayer/skills/codebase-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/codebase-analysis/SKILL.md",
          "type": "blob",
          "size": 7590
        },
        {
          "path": "baselayer/skills/codebase-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/codebase-analysis/references/architecture-analysis.md",
          "type": "blob",
          "size": 5791
        },
        {
          "path": "baselayer/skills/complexity-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/complexity-analysis/SKILL.md",
          "type": "blob",
          "size": 8975
        },
        {
          "path": "baselayer/skills/complexity-analysis/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/complexity-analysis/examples/custom-auth.md",
          "type": "blob",
          "size": 9895
        },
        {
          "path": "baselayer/skills/complexity-analysis/examples/redux-overkill.md",
          "type": "blob",
          "size": 6112
        },
        {
          "path": "baselayer/skills/complexity-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/complexity-analysis/references/decision-framework.md",
          "type": "blob",
          "size": 9887
        },
        {
          "path": "baselayer/skills/conversation-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/conversation-analysis/SKILL.md",
          "type": "blob",
          "size": 6811
        },
        {
          "path": "baselayer/skills/conversation-analysis/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/conversation-analysis/examples/sample-analysis.md",
          "type": "blob",
          "size": 22542
        },
        {
          "path": "baselayer/skills/conversation-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/conversation-analysis/references/extraction-techniques.md",
          "type": "blob",
          "size": 20921
        },
        {
          "path": "baselayer/skills/conversation-analysis/references/signal-patterns.md",
          "type": "blob",
          "size": 17167
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/SKILL.md",
          "type": "blob",
          "size": 8720
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/examples/race-condition.md",
          "type": "blob",
          "size": 11034
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/examples/runtime-error.md",
          "type": "blob",
          "size": 8576
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/references/evidence-patterns.md",
          "type": "blob",
          "size": 2556
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/references/integration.md",
          "type": "blob",
          "size": 2590
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/references/playbooks.md",
          "type": "blob",
          "size": 2762
        },
        {
          "path": "baselayer/skills/debugging-and-diagnosis/references/reproduction.md",
          "type": "blob",
          "size": 8389
        },
        {
          "path": "baselayer/skills/hono-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/hono-dev/SKILL.md",
          "type": "blob",
          "size": 11452
        },
        {
          "path": "baselayer/skills/hono-dev/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/hono-dev/examples/testing-patterns.md",
          "type": "blob",
          "size": 19581
        },
        {
          "path": "baselayer/skills/hono-dev/examples/typed-routes.md",
          "type": "blob",
          "size": 18162
        },
        {
          "path": "baselayer/skills/hono-dev/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/hono-dev/references/error-handling.md",
          "type": "blob",
          "size": 16451
        },
        {
          "path": "baselayer/skills/hono-dev/references/factory-pattern.md",
          "type": "blob",
          "size": 15241
        },
        {
          "path": "baselayer/skills/hono-dev/references/middleware.md",
          "type": "blob",
          "size": 9423
        },
        {
          "path": "baselayer/skills/hono-dev/references/zod-openapi.md",
          "type": "blob",
          "size": 17689
        },
        {
          "path": "baselayer/skills/pathfinding",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/pathfinding/SKILL.md",
          "type": "blob",
          "size": 8204
        },
        {
          "path": "baselayer/skills/pathfinding/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/pathfinding/examples/early-delivery.md",
          "type": "blob",
          "size": 8694
        },
        {
          "path": "baselayer/skills/pathfinding/examples/greenfield-api.md",
          "type": "blob",
          "size": 7773
        },
        {
          "path": "baselayer/skills/pathfinding/examples/high-start.md",
          "type": "blob",
          "size": 5760
        },
        {
          "path": "baselayer/skills/pathfinding/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/pathfinding/references/confidence.md",
          "type": "blob",
          "size": 4420
        },
        {
          "path": "baselayer/skills/pathfinding/references/questions.md",
          "type": "blob",
          "size": 4021
        },
        {
          "path": "baselayer/skills/pattern-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/pattern-analysis/SKILL.md",
          "type": "blob",
          "size": 4437
        },
        {
          "path": "baselayer/skills/pattern-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/pattern-analysis/references/pattern-types.md",
          "type": "blob",
          "size": 3928
        },
        {
          "path": "baselayer/skills/pattern-analysis/references/signal-types.md",
          "type": "blob",
          "size": 3026
        },
        {
          "path": "baselayer/skills/patternify",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/patternify/SKILL.md",
          "type": "blob",
          "size": 4918
        },
        {
          "path": "baselayer/skills/patternify/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/patternify/examples/heuristic-pattern.md",
          "type": "blob",
          "size": 5686
        },
        {
          "path": "baselayer/skills/patternify/examples/orchestration-pattern.md",
          "type": "blob",
          "size": 4872
        },
        {
          "path": "baselayer/skills/patternify/examples/workflow-pattern.md",
          "type": "blob",
          "size": 4852
        },
        {
          "path": "baselayer/skills/patternify/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/patternify/references/component-mapping.md",
          "type": "blob",
          "size": 6527
        },
        {
          "path": "baselayer/skills/patternify/references/pattern-types.md",
          "type": "blob",
          "size": 10719
        },
        {
          "path": "baselayer/skills/performance-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/performance-engineering/SKILL.md",
          "type": "blob",
          "size": 9316
        },
        {
          "path": "baselayer/skills/performance-engineering/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/performance-engineering/references/benchmarking.md",
          "type": "blob",
          "size": 7913
        },
        {
          "path": "baselayer/skills/react-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/react-dev/SKILL.md",
          "type": "blob",
          "size": 9857
        },
        {
          "path": "baselayer/skills/react-dev/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/react-dev/examples/generic-components.md",
          "type": "blob",
          "size": 12902
        },
        {
          "path": "baselayer/skills/react-dev/examples/server-components.md",
          "type": "blob",
          "size": 13227
        },
        {
          "path": "baselayer/skills/react-dev/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/react-dev/references/event-handlers.md",
          "type": "blob",
          "size": 14375
        },
        {
          "path": "baselayer/skills/react-dev/references/hooks.md",
          "type": "blob",
          "size": 10977
        },
        {
          "path": "baselayer/skills/react-dev/references/react-19-patterns.md",
          "type": "blob",
          "size": 14078
        },
        {
          "path": "baselayer/skills/react-dev/references/tanstack-router.md",
          "type": "blob",
          "size": 12253
        },
        {
          "path": "baselayer/skills/report-findings",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/report-findings/SKILL.md",
          "type": "blob",
          "size": 5026
        },
        {
          "path": "baselayer/skills/report-findings/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/report-findings/references/comparison-methods.md",
          "type": "blob",
          "size": 4271
        },
        {
          "path": "baselayer/skills/report-findings/references/output-template.md",
          "type": "blob",
          "size": 3480
        },
        {
          "path": "baselayer/skills/report-findings/references/source-tiers.md",
          "type": "blob",
          "size": 4330
        },
        {
          "path": "baselayer/skills/research-and-report",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/research-and-report/SKILL.md",
          "type": "blob",
          "size": 6399
        },
        {
          "path": "baselayer/skills/research-and-report/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/research-and-report/references/discovery-patterns.md",
          "type": "blob",
          "size": 6014
        },
        {
          "path": "baselayer/skills/research-and-report/references/source-hierarchy.md",
          "type": "blob",
          "size": 4432
        },
        {
          "path": "baselayer/skills/research-and-report/references/tool-selection.md",
          "type": "blob",
          "size": 4747
        },
        {
          "path": "baselayer/skills/root-cause-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/root-cause-analysis/SKILL.md",
          "type": "blob",
          "size": 6828
        },
        {
          "path": "baselayer/skills/root-cause-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/root-cause-analysis/references/documentation-templates.md",
          "type": "blob",
          "size": 4621
        },
        {
          "path": "baselayer/skills/root-cause-analysis/references/elimination-techniques.md",
          "type": "blob",
          "size": 5568
        },
        {
          "path": "baselayer/skills/root-cause-analysis/references/pitfalls.md",
          "type": "blob",
          "size": 5366
        },
        {
          "path": "baselayer/skills/scenario-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/scenario-testing/SKILL.md",
          "type": "blob",
          "size": 8694
        },
        {
          "path": "baselayer/skills/scenario-testing/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/scenario-testing/references/patterns.md",
          "type": "blob",
          "size": 18912
        },
        {
          "path": "baselayer/skills/security-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/security-engineering/SKILL.md",
          "type": "blob",
          "size": 9527
        },
        {
          "path": "baselayer/skills/security-engineering/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/security-engineering/references/owasp-top-10.md",
          "type": "blob",
          "size": 28074
        },
        {
          "path": "baselayer/skills/security-engineering/references/report-templates.md",
          "type": "blob",
          "size": 3058
        },
        {
          "path": "baselayer/skills/security-engineering/references/review-checklist.md",
          "type": "blob",
          "size": 4139
        },
        {
          "path": "baselayer/skills/security-engineering/references/vulnerability-patterns.md",
          "type": "blob",
          "size": 6796
        },
        {
          "path": "baselayer/skills/software-architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/software-architecture/SKILL.md",
          "type": "blob",
          "size": 11806
        },
        {
          "path": "baselayer/skills/software-architecture/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/software-architecture/references/adr-template.md",
          "type": "blob",
          "size": 797
        },
        {
          "path": "baselayer/skills/software-architecture/references/common-patterns.md",
          "type": "blob",
          "size": 1393
        },
        {
          "path": "baselayer/skills/software-architecture/references/design-patterns.md",
          "type": "blob",
          "size": 2551
        },
        {
          "path": "baselayer/skills/software-architecture/references/implementation-guidance.md",
          "type": "blob",
          "size": 1648
        },
        {
          "path": "baselayer/skills/software-architecture/references/questions-checklist.md",
          "type": "blob",
          "size": 1471
        },
        {
          "path": "baselayer/skills/software-architecture/references/rust-architecture.md",
          "type": "blob",
          "size": 1974
        },
        {
          "path": "baselayer/skills/software-architecture/references/scalability.md",
          "type": "blob",
          "size": 2303
        },
        {
          "path": "baselayer/skills/software-architecture/references/technology-selection.md",
          "type": "blob",
          "size": 2993
        },
        {
          "path": "baselayer/skills/software-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/software-engineering/SKILL.md",
          "type": "blob",
          "size": 10225
        },
        {
          "path": "baselayer/skills/software-engineering/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/software-engineering/references/code-quality-patterns.md",
          "type": "blob",
          "size": 2516
        },
        {
          "path": "baselayer/skills/software-engineering/references/type-patterns.md",
          "type": "blob",
          "size": 5256
        },
        {
          "path": "baselayer/skills/status-reporting",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/status-reporting/EXAMPLES.md",
          "type": "blob",
          "size": 2403
        },
        {
          "path": "baselayer/skills/status-reporting/SKILL.md",
          "type": "blob",
          "size": 6507
        },
        {
          "path": "baselayer/skills/status-reporting/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/status-reporting/references/beads.md",
          "type": "blob",
          "size": 8767
        },
        {
          "path": "baselayer/skills/status-reporting/references/github.md",
          "type": "blob",
          "size": 13363
        },
        {
          "path": "baselayer/skills/status-reporting/references/graphite.md",
          "type": "blob",
          "size": 10186
        },
        {
          "path": "baselayer/skills/status-reporting/references/implementation.md",
          "type": "blob",
          "size": 3829
        },
        {
          "path": "baselayer/skills/status-reporting/references/linear.md",
          "type": "blob",
          "size": 15100
        },
        {
          "path": "baselayer/skills/status-reporting/references/templates.md",
          "type": "blob",
          "size": 2194
        },
        {
          "path": "baselayer/skills/status-reporting/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/detect.ts",
          "type": "blob",
          "size": 5251
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/gatherers",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/gatherers/beads-gatherer.ts",
          "type": "blob",
          "size": 4235
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/gatherers/github-gatherer.ts",
          "type": "blob",
          "size": 5802
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/gatherers/graphite-gatherer.ts",
          "type": "blob",
          "size": 7334
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/gatherers/linear-gatherer.ts",
          "type": "blob",
          "size": 5435
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/lib",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/lib/time.ts",
          "type": "blob",
          "size": 3210
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/lib/types.ts",
          "type": "blob",
          "size": 2811
        },
        {
          "path": "baselayer/skills/status-reporting/scripts/sitrep.ts",
          "type": "blob",
          "size": 9588
        },
        {
          "path": "baselayer/skills/subagent-coordination",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/subagent-coordination/SKILL.md",
          "type": "blob",
          "size": 9717
        },
        {
          "path": "baselayer/skills/subagent-coordination/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/subagent-coordination/references/agent-skills.md",
          "type": "blob",
          "size": 4569
        },
        {
          "path": "baselayer/skills/subagent-coordination/references/workflows.md",
          "type": "blob",
          "size": 4303
        },
        {
          "path": "baselayer/skills/test-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/test-driven-development/SKILL.md",
          "type": "blob",
          "size": 9983
        },
        {
          "path": "baselayer/skills/test-driven-development/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/test-driven-development/examples/bug-fix.md",
          "type": "blob",
          "size": 9458
        },
        {
          "path": "baselayer/skills/test-driven-development/examples/feature-implementation.md",
          "type": "blob",
          "size": 15780
        },
        {
          "path": "baselayer/skills/test-driven-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/test-driven-development/references/quality-metrics.md",
          "type": "blob",
          "size": 11729
        },
        {
          "path": "baselayer/skills/test-driven-development/references/test-patterns.md",
          "type": "blob",
          "size": 16369
        },
        {
          "path": "baselayer/skills/typescript-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/typescript-dev/SKILL.md",
          "type": "blob",
          "size": 11500
        },
        {
          "path": "baselayer/skills/typescript-dev/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/typescript-dev/examples/api-response.md",
          "type": "blob",
          "size": 11087
        },
        {
          "path": "baselayer/skills/typescript-dev/examples/form-validation.md",
          "type": "blob",
          "size": 17695
        },
        {
          "path": "baselayer/skills/typescript-dev/examples/resource-management.md",
          "type": "blob",
          "size": 13628
        },
        {
          "path": "baselayer/skills/typescript-dev/examples/state-machine.md",
          "type": "blob",
          "size": 16409
        },
        {
          "path": "baselayer/skills/typescript-dev/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/typescript-dev/references/advanced-types.md",
          "type": "blob",
          "size": 6596
        },
        {
          "path": "baselayer/skills/typescript-dev/references/branded-types.md",
          "type": "blob",
          "size": 14397
        },
        {
          "path": "baselayer/skills/typescript-dev/references/migration-paths.md",
          "type": "blob",
          "size": 12920
        },
        {
          "path": "baselayer/skills/typescript-dev/references/modern-features.md",
          "type": "blob",
          "size": 13212
        },
        {
          "path": "baselayer/skills/typescript-dev/references/result-pattern.md",
          "type": "blob",
          "size": 14104
        },
        {
          "path": "baselayer/skills/typescript-dev/references/tsdoc-patterns.md",
          "type": "blob",
          "size": 7113
        },
        {
          "path": "baselayer/skills/typescript-dev/references/zod-building-blocks.md",
          "type": "blob",
          "size": 6462
        },
        {
          "path": "baselayer/skills/typescript-dev/references/zod-integration.md",
          "type": "blob",
          "size": 8412
        },
        {
          "path": "baselayer/skills/typescript-dev/references/zod-performance.md",
          "type": "blob",
          "size": 15297
        },
        {
          "path": "baselayer/skills/typescript-dev/references/zod-schemas.md",
          "type": "blob",
          "size": 16229
        },
        {
          "path": "baselayer/skills/use-the-best-tool",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/use-the-best-tool/SKILL.md",
          "type": "blob",
          "size": 6150
        },
        {
          "path": "baselayer/skills/use-the-best-tool/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/use-the-best-tool/examples/tool-upgrade.md",
          "type": "blob",
          "size": 10736
        },
        {
          "path": "baselayer/skills/use-the-best-tool/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/use-the-best-tool/references/alternatives.md",
          "type": "blob",
          "size": 17994
        },
        {
          "path": "baselayer/skills/use-the-best-tool/references/detection-script.md",
          "type": "blob",
          "size": 3320
        },
        {
          "path": "baselayer/skills/use-the-best-tool/references/tool-catalog.md",
          "type": "blob",
          "size": 13541
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/README.md",
          "type": "blob",
          "size": 3024
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/checkers",
          "type": "tree",
          "size": null
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/checkers/http.ts",
          "type": "blob",
          "size": 749
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/checkers/json.ts",
          "type": "blob",
          "size": 711
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/checkers/navigation.ts",
          "type": "blob",
          "size": 1106
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/checkers/search.ts",
          "type": "blob",
          "size": 1456
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/checkers/viewers.ts",
          "type": "blob",
          "size": 1522
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/index.ts",
          "type": "blob",
          "size": 4245
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/types.ts",
          "type": "blob",
          "size": 393
        },
        {
          "path": "baselayer/skills/use-the-best-tool/scripts/utils.ts",
          "type": "blob",
          "size": 997
        },
        {
          "path": "cli-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 460
        },
        {
          "path": "cli-dev/README.md",
          "type": "blob",
          "size": 1089
        },
        {
          "path": "cli-dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/README.md",
          "type": "blob",
          "size": 2425
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/SKILL.md",
          "type": "blob",
          "size": 3652
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/references/CHECKLIST.md",
          "type": "blob",
          "size": 3414
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/references/EVAL_PROMPTS.md",
          "type": "blob",
          "size": 2674
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/references/REFERENCE.md",
          "type": "blob",
          "size": 13078
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/scripts/cli_audit.py",
          "type": "blob",
          "size": 15602
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/templates/cli-command-spec-template.json",
          "type": "blob",
          "size": 2554
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/templates/error-message-template.md",
          "type": "blob",
          "size": 1267
        },
        {
          "path": "cli-dev/skills/cli-development-guidelines/templates/help-text-template.md",
          "type": "blob",
          "size": 1357
        },
        {
          "path": "gitbutler",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 439
        },
        {
          "path": "gitbutler/README.md",
          "type": "blob",
          "size": 3741
        },
        {
          "path": "gitbutler/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/agents/gitbutler-expert.md",
          "type": "blob",
          "size": 5706
        },
        {
          "path": "gitbutler/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/skills/complete-branch",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/skills/complete-branch/SKILL.md",
          "type": "blob",
          "size": 6460
        },
        {
          "path": "gitbutler/skills/multi-agent",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/skills/multi-agent/SKILL.md",
          "type": "blob",
          "size": 6983
        },
        {
          "path": "gitbutler/skills/stack-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/skills/stack-workflows/SKILL.md",
          "type": "blob",
          "size": 7168
        },
        {
          "path": "gitbutler/skills/version-control",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/skills/version-control/SKILL.md",
          "type": "blob",
          "size": 8957
        },
        {
          "path": "gitbutler/skills/version-control/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "gitbutler/skills/version-control/references/examples.md",
          "type": "blob",
          "size": 6799
        },
        {
          "path": "gitbutler/skills/version-control/references/reference.md",
          "type": "blob",
          "size": 13225
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/format-markdown-tables.ts",
          "type": "blob",
          "size": 9065
        },
        {
          "path": "scripts/format-markdown.ts",
          "type": "blob",
          "size": 6197
        },
        {
          "path": "scripts/lint-xml-tags.ts",
          "type": "blob",
          "size": 7676
        },
        {
          "path": "shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "shared/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "shared/scripts/validate-marketplace.ts",
          "type": "blob",
          "size": 9765
        }
      ],
      "marketplace": {
        "name": "outfitter",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Outfitter",
          "email": "team@outfitter.dev"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "baselayer",
            "description": "Core development methodology skills: TDD, systematic debugging, type safety, architecture design, technical research, and requirements discovery",
            "source": "./baselayer",
            "category": null,
            "version": "0.8.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add outfitter-dev/agents",
              "/plugin install baselayer@outfitter"
            ],
            "signals": {
              "stars": 15,
              "forks": 0,
              "pushed_at": "2026-01-11T17:32:42Z",
              "created_at": "2025-08-30T16:37:06Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/best-tool",
                "description": "Check available CLI tools and get recommendations",
                "path": "baselayer/commands/best-tool.md",
                "frontmatter": {
                  "description": "Check available CLI tools and get recommendations",
                  "argument-hint": [
                    {
                      "category": "search|json|viewers|navigation|http"
                    }
                  ]
                },
                "content": "# Best Tool\n\nDetect available modern CLI tools and get recommendations for your environment.\n\n## Quick Check\n\nRun the detection script:\n\n```bash\nbun baselayer/skills/use-the-best-tool/scripts/index.ts\n```\n\nFilter by category:\n```bash\nbun baselayer/skills/use-the-best-tool/scripts/index.ts -c search\n```\n\n## Context\n\n$ARGUMENTS\n\n---\n\nLoad the **use-the-best-tool** skill and:\n\n1. Run the tool detection script (with category filter if provided)\n2. Report which tools are available vs missing\n3. For missing tools, note install commands if user wants them\n4. If selecting a tool for a task, use the selection matrix from the skill\n\nUse modern tools when available. Fall back gracefully when not."
              },
              {
                "name": "/debug",
                "description": "Systematic debugging with root cause investigation - no random trial-and-error",
                "path": "baselayer/commands/debug.md",
                "frontmatter": {
                  "description": "Systematic debugging with root cause investigation - no random trial-and-error",
                  "argument-hint": [
                    "bug description or error message"
                  ]
                },
                "content": "# Systematic Debugging\n\nStart a methodical debugging session using the four-phase investigation framework with iterative review.\n\n## Instructions\n\n- Consider the recent conversation history, your context, and the problem to be debugged.\n- Specific user instructions should be followed unless they are contradictory to the task at hand. $ARGUMENTS\n\n## Steps\n\n1. **Load**  Use the Skill tool and load the **baselayer:debugging-and-diagnosis** skill\n2. **Consider**  Ultrathink and analyze the problem, consider available evidence, potential causes, and investigation approach\n3. **Dispatch or Execute**  Choose execution path based on available tools:\n   - **If Task tool available**: Run the debug loop (see below)\n   - **If Task tool unavailable**: Execute the debugging methodology directly using the loaded skill\n\n## Debug Loop (when Task tool available)\n\nRun iterative cycles until the issue is resolved:\n\n```\n\n  1. INVESTIGATE  Dispatch baselayer:debugger           \n      Collect evidence, form hypothesis, propose fix   \n                                                        \n  2. REVIEW  Dispatch baselayer:ranger                  \n      Validate fix, check for regressions, verify      \n        root cause addressed (not just symptoms)         \n                                                        \n  3. EVALUATE  Check review outcome                     \n      If approved  Done                               \n      If issues found  Back to step 1 with feedback   \n\n```\n\n### Loop Execution\n\n1. **Dispatch debugger** (background)  Pass error context, evidence, any prior feedback\n2. **Retrieve results**  Use TaskOutput to get proposed fix and rationale\n3. **Dispatch ranger** (background)  Pass the proposed fix and debugger's findings for code review\n4. **Retrieve review**  Use TaskOutput to get validation results\n5. **Evaluate**:\n   - **Approved**: Report success, document root cause and fix\n   - **Issues found**: Loop back to debugger with reviewer feedback\n   - **Max iterations (3)**: Escalate to user with findings so far\n\n### Context Accumulation\n\nEach loop iteration passes forward:\n- Original error context\n- Investigation findings from debugger\n- Review feedback from reviewer\n- Cumulative hypotheses tested\n\n## The Iron Law\n\nNO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST\n\nIf you catch yourself wanting to \"just try something\"  stop. Return to investigation.\n\n## Context Handoff (for initial dispatch)\n\nWhen dispatching to the debugger subagent, include:\n- Exact error messages or unexpected behavior\n- Stack traces if available\n- Recent changes (git diff context)\n- Reproduction steps if known\n- Any hypotheses already formed\n- Prior loop feedback (if iterating)"
              },
              {
                "name": "/dispatch-agents",
                "description": "Orchestrate multiple agents for complex multi-domain tasks",
                "path": "baselayer/commands/dispatch-agents.md",
                "frontmatter": {
                  "description": "Orchestrate multiple agents for complex multi-domain tasks",
                  "argument-hint": [
                    "task description requiring coordination"
                  ]
                },
                "content": "# Agent Dispatch\n\nCoordinate multiple agents to accomplish a complex task requiring different expertise areas.\n\n## Instructions\n\n- Consider the recent conversation history, your context, and the task to be accomplished.\n- Specific user instructions should be followed unless they are contradictory to the task at hand. $ARGUMENTS\n\n## Steps\n\n1. **Load**  Use the Skill tool and load the **baselayer:subagent-coordination** skill\n2. **Consider**  Ultrathink and analyze the task, consider the complexity, sequence of steps, and agent requirements.\n3. **Planning**  Use the **Plan subagent** to research the codebase and design an orchestration strategy\n4. **Report**  Present the orchestration plan (which agents, what sequence, expected handoffs)\n   - **IMPORTANT**: After presenting the orchestration plan, proceed directly to execution.\n   - Do not wait for approval unless the task is high-risk (destructive changes, production deployment, security-sensitive).\n5. **Execute**  Dispatch agents according to the plan, passing context between them\n\n## Planning Process\n\nEnsure you've loaded the **baselayer:subagent-coordination** skill. Then coordinate with the **Plan subagent** to design the orchestration plan. Task the **Plan subagent** to:\n\n1. Explore the relevant parts of the codebase\n2. Identify which roles are needed (coding, reviewing, research, testing, etc.)\n3. Determine the best available agents for each role\n4. Design the execution sequence (sequential, parallel, or hybrid)\n5. Return a concise orchestration plan\n\nAfter receiving the plan, think about if you agree with it, make adjustments where necessary, and proceed with the next steps mentioned above."
              },
              {
                "name": "/pathfind",
                "description": "Collaborative Q&A to clarify unclear requirements and reach a clear path",
                "path": "baselayer/commands/pathfind.md",
                "frontmatter": {
                  "description": "Collaborative Q&A to clarify unclear requirements and reach a clear path",
                  "argument-hint": [
                    "topic",
                    "problem",
                    "or feature to explore"
                  ]
                },
                "content": "# Pathfinding\n\nAdaptive Q&A workflow to clarify requirements and build confidence before delivering.\n\n## Steps\n\n1. **Load**  Use the Skill tool to load the **baselayer:pathfinding** skill\n2. **Consider**  Assess the context below and recent conversation. Ultrathink.\n3. **Execute**  Begin the pathfinding workflow per the skill\n\n## Guidance\n\n- This may be greenfield exploration  help shape the idea, not just refine it\n- Use EnterPlanMode for questions (enables keyboard selection)\n- Ask about literally anything: scope, constraints, tradeoffs, UX, technical approach, concerns\n- Make sure questions are non-obvious  don't re-ask what's already clear from context\n- Be persistent  continue until confidence level 5 or user requests early delivery\n\n## Context\n\n$ARGUMENTS"
              },
              {
                "name": "/patternify",
                "description": "Analyze conversation to identify and capture reusable patterns as skills, commands, agents, or hooks",
                "path": "baselayer/commands/patternify.md",
                "frontmatter": {
                  "description": "Analyze conversation to identify and capture reusable patterns as skills, commands, agents, or hooks",
                  "argument-hint": [
                    {
                      "optional": "pattern to focus on"
                    },
                    "or omit to scan conversation"
                  ]
                },
                "content": "# Patternify\n\nTransform productive workflows, tool orchestrations, and decision heuristics into reusable Claude Code components.\n\n## Instructions\n\n- Consider the recent conversation history and any patterns that emerged.\n- Specific user instructions should be followed unless they are contradictory to the task at hand. $ARGUMENTS\n\n## Steps\n\n1. **Load**  Use the Skill tool and load the **baselayer:patternify** skill\n2. **Consider**  Ultrathink and analyze the conversation, identify candidate patterns, and assess reusability\n3. **Dispatch or Execute**  Choose execution path based on available tools:\n   - **If Task tool available**: Dispatch the **baselayer:pattern-analyzer** subagent in background mode, passing along the pattern hint (if any) and conversation context summary\n   - **If Task tool unavailable**: Execute the pattern analysis methodology directly using the loaded skill\n4. **Monitor**  If subagent dispatched, use TaskOutput to retrieve structured JSON findings\n5. **Generate**  Based on findings, create the appropriate component files\n\n## Context Handoff (for subagent dispatch)\n\nWhen dispatching to the pattern-analyzer subagent, include:\n- Pattern hint from arguments (if provided)\n- Summary of productive workflows from conversation\n- Key tool sequences and decision points observed\n- User satisfaction signals (\"that worked great\")\n\n## Pattern Types\n\n- **Workflow**: Multi-step process with phases\n- **Orchestration**: Tool coordination toward a goal\n- **Heuristic**: Decision rule with exceptions\n\n## Component Mapping\n\n```text\nIs it a multi-step process?\n Yes  Requires judgment?  SKILL (not fully automatable)\n        Fully automatable?  COMMAND (scripted)\n No  Event-triggered?  HOOK\n         Requires expertise?  AGENT\n         User-initiated?  COMMAND\n```\n\n## Output Locations\n\n- **Plugin**: `**/{plugin}/skills/{name}/`  shareable via marketplace\n- **Project**: `{CLAUDE_PROJECT_DIR}/.claude/skills/{name}/`  team-shared\n- **Personal**: `~/.claude/skills/{name}/`  global personal toolkit\n\n## Quality Criteria\n\nBefore generating, validate:\n- **Specific**: Clear trigger and scope\n- **Repeatable**: Works across contexts\n- **Valuable**: Worth the overhead (saves >5 min)\n- **Documented**: Others can understand\n- **Scoped**: Single responsibility\n\nSkip if: <3 occurrences, context-dependent, simpler inline."
              },
              {
                "name": "/simplify",
                "description": "Challenge complexity and find simpler alternatives before implementing",
                "path": "baselayer/commands/simplify.md",
                "frontmatter": {
                  "description": "Challenge complexity and find simpler alternatives before implementing",
                  "argument-hint": [
                    "proposed solution or approach to evaluate"
                  ]
                },
                "content": "# Challenge Complexity\n\nEvaluate the proposed solution for unnecessary complexity before committing to it.\n\n## Instructions\n\n- Consider the recent conversation history, your context, and the proposal to be evaluated.\n- Specific user instructions should be followed unless they are contradictory to the task at hand. $ARGUMENTS\n\n## Steps\n\n1. **Load**  Use the Skill tool and load the **baselayer:complexity-analysis** skill\n2. **Consider**  Ultrathink and analyze the proposal, identify initial complexity concerns\n3. **Dispatch or Execute**  Choose execution path based on available tools:\n   - **If Task tool available**: Run the simplify loop (see below)\n   - **If Task tool unavailable**: Execute the complexity analysis methodology directly using the loaded skill\n\n## Simplify Loop (when Task tool available)\n\nRun iterative cycles with a persistent skeptic agent until complexity is resolved:\n\n```\n\n  1. ANALYZE  Dispatch baselayer:skeptic                    \n      Examine proposal, identify complexity triggers,      \n        generate alternatives, return structured findings    \n                                                            \n  2. PRESENT  Share findings with user                      \n      Escalation level, alternatives, probing questions    \n                                                            \n  3. DISCUSS  Gather user response                          \n      User provides context, answers questions,            \n        or asks skeptic to dig deeper                        \n                                                            \n  4. EVALUATE  Determine next action                        \n      If resolved  Document decision                      \n      If more analysis needed  Resume skeptic (step 1)    \n\n```\n\n### Loop Execution\n\n1. **Initial dispatch**  Pass proposal, context, requirements to skeptic\n2. **Retrieve results**  Use TaskOutput to get structured JSON analysis\n3. **Present to user**  Share escalation level, alternatives, and probing questions\n4. **Gather feedback**  User may:\n   - Answer probing questions (pass answers back to skeptic)\n   - Ask skeptic to examine specific aspects deeper\n   - Accept an alternative and proceed\n   - Justify complexity with evidence (skeptic validates)\n5. **Resume or conclude**:\n   - **More analysis needed**: Resume same skeptic agent with `resume: {agentId}` and new context\n   - **Decision reached**: Document outcome (proceed with simple, proceed with justified complexity, or revisit approach)\n\n### Resumable Skeptic Pattern\n\nThe skeptic maintains context across invocations via the `resume` parameter:\n\n```\nInitial dispatch:\n   skeptic analyzes proposal\n   returns findings + agentId: \"abc123\"\n\nUser provides additional context:\n   resume skeptic with { resume: \"abc123\" }\n   skeptic refines analysis with new information\n\nUser asks about specific concern:\n   resume skeptic with { resume: \"abc123\" }\n   skeptic digs deeper on that aspect\n```\n\nThis preserves the skeptic's understanding of the proposal through multiple rounds of refinement.\n\n## The Framework\n\n1. IDENTIFY  what complexity is being proposed?\n2. ALTERNATIVE  what's the simplest thing that could work?\n3. QUESTION  why isn't the simple approach sufficient?\n4. DOCUMENT  if complexity is justified, record why\n\n## Context Handoff (for initial dispatch)\n\nWhen dispatching to the skeptic subagent, include:\n- The proposed solution or approach\n- Current requirements and constraints\n- Any justifications already offered\n- Team/project context if relevant\n\nWhen resuming the skeptic, include:\n- User's answers to probing questions\n- Additional context or constraints revealed\n- Specific areas to examine further\n- Evidence offered to justify complexity\n\n## Red Flag Rationalizations\n\nWatch for these justifications  they usually indicate unjustified complexity:\n\n- \"We might need this later\"\n- \"It's more flexible this way\"\n- \"This is how X company does it\"\n- \"It's the industry standard\"\n- \"We should do it right the first time\"\n\n## Verdicts and Outcomes\n\nThe skeptic returns one of three verdicts:\n\n| Verdict | Meaning | Action |\n|---------|---------|--------|\n| **proceed** | Complexity is minor () | Note alternatives, continue |\n| **caution** | Complexity is moderate () | Discuss before proceeding |\n| **block** | Complexity is high risk () | Address concerns first |\n\nAfter discussion, document the outcome:\n- **Simplified**: Chose simpler alternative\n- **Justified**: Complexity validated with evidence, documented in ADR\n- **Deferred**: Needs more investigation, created follow-up task\n\nThe goal is NOT to reject all complexity  it's to ensure complexity is justified by evidence, not speculation."
              },
              {
                "name": "/sitrep",
                "description": "Generate comprehensive status report across VCS, PRs, issues, and CI/CD",
                "path": "baselayer/commands/sitrep.md",
                "frontmatter": {
                  "description": "Generate comprehensive status report across VCS, PRs, issues, and CI/CD",
                  "argument-hint": [
                    {
                      "time range and/or services": "graphite"
                    },
                    "github",
                    "linear",
                    "beads",
                    "all"
                  ]
                },
                "content": "# Situation Report\n\nGenerate a scannable status report for the current project.\n\n## Steps\n\n1. **Detect**  Check for available services listed below.\n2. **Consider**  Parse the context below for time range and service filters. Ultrathink.\n3. **Dispatch**  Launch the **baselayer:scout** agent via Task tool with detected services and context\n4. **Retain**  Keep the agent ID for follow-up questions (use `resume` parameter)\n\n## Guidance\n\n- Pass detected services to scout so it knows what to query\n- Default time range: 24 hours if not specified\n- Lead with attention-needed items (blockers, failing CI, stale branches)\n- Present for quick scanning  user should gain situational awareness in 30 seconds\n\n## Context\n\n- $ARGUMENTS\n\n### Available Services\n\n!`bun ${CLAUDE_PLUGIN_ROOT}/skills/status-reporting/scripts/detect.ts`"
              },
              {
                "name": "/tdd",
                "description": "Implement a feature or fix using test-driven development (Red-Green-Refactor)",
                "path": "baselayer/commands/tdd.md",
                "frontmatter": {
                  "description": "Implement a feature or fix using test-driven development (Red-Green-Refactor)",
                  "argument-hint": [
                    "feature or bug to implement"
                  ]
                },
                "content": "# Test-Driven Development\n\nImplement the requested feature using strict TDD methodology.\n\n## Instructions\n\n- Consider the recent conversation history, your context, and the feature or fix to be implemented.\n- Specific user instructions should be followed unless they are contradictory to the task at hand. $ARGUMENTS\n\n## Steps\n\n1. **Load**  Use the Skill tool and load the **baselayer:test-driven-development** skill\n2. **Consider**  Ultrathink and analyze the feature, break it into testable behaviors, and plan the RED-GREEN-REFACTOR cycles\n3. **Dispatch or Execute**  Choose execution path based on available tools:\n   - **If Task tool available**: Dispatch the **baselayer:tester** subagent in background mode, passing along feature requirements and testing strategy\n   - **If Task tool unavailable**: Execute the TDD methodology directly using the loaded skill\n4. **Monitor**  If subagent dispatched, use TaskOutput to retrieve results when ready\n\n## The Cycle\n\n```\nRED  GREEN  REFACTOR (repeat)\n```\n\n1. RED  write a failing test that defines the expected behavior\n2. GREEN  write minimal code to make the test pass\n3. REFACTOR  clean up while keeping tests green\n\n## Context Handoff (for subagent dispatch)\n\nWhen dispatching to the tester subagent, include:\n- Feature requirements and acceptance criteria\n- First testable behavior to implement\n- Existing test patterns in the codebase\n- Any constraints (framework, coverage requirements)\n\n## Rules\n\n- Never write production code without a failing test first\n- Each cycle should take 5-15 minutes\n- Commit at each green state\n- Tests are first-class code  no shortcuts\n\nDo NOT write implementation code before you have a failing test."
              }
            ],
            "skills": [
              {
                "name": "ai-sdk",
                "description": "This skill should be used when building AI features with Vercel AI SDK, using useChat, streamText, or generateObject, or when \"AI SDK\", \"streaming chat\", or \"structured outputs\" are mentioned.",
                "path": "baselayer/skills/ai-sdk/SKILL.md",
                "frontmatter": {
                  "name": "ai-sdk",
                  "version": "1.0.0",
                  "description": "This skill should be used when building AI features with Vercel AI SDK, using useChat, streamText, or generateObject, or when \"AI SDK\", \"streaming chat\", or \"structured outputs\" are mentioned."
                },
                "content": "# Vercel AI SDK v6\n\nPatterns for building AI-powered applications with the Vercel AI SDK v6.\n\n<when_to_use>\n\n- Building streaming chat UIs\n- Structured JSON outputs with Zod schemas\n- Multi-step agent workflows with tools\n- Tool approval flows (human-in-the-loop)\n- Next.js App Router integrations\n\n</when_to_use>\n\n## Version Guard\n\nTarget **AI SDK 6.x** APIs. Default packages:\n\n```\nai@^6\n@ai-sdk/react@^2\n@ai-sdk/openai@^2 (or @ai-sdk/anthropic, etc.)\nzod@^3\n```\n\n**Avoid v4/v5 holdovers:**\n- `StreamingTextResponse`  use `result.toUIMessageStreamResponse()`\n- Legacy `Message` shape  use `UIMessage`\n- Input-managed `useChat`  use transport-based pattern\n\n## Core Concepts\n\n### Message Types\n\n| Type | Purpose | When to Use |\n|------|---------|-------------|\n| `UIMessage` | User-facing, persistence | Store in database, render in UI |\n| `ModelMessage` | LLM-compatible | Convert at call sites only |\n\n**Rule:** Persist `UIMessage[]`. Convert to `ModelMessage[]` only when calling the model.\n\n### Streaming Patterns\n\n| Function | Use Case |\n|----------|----------|\n| `streamText` | Streaming text responses |\n| `generateText` | Non-streaming text |\n| `streamObject` | Streaming JSON with partial updates |\n| `generateObject` | Non-streaming JSON |\n| `ToolLoopAgent` | Multi-step agent with tools |\n\n## Golden Path: Streaming Chat\n\n### API Route (App Router)\n\n```typescript\n// app/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { streamText, convertToModelMessages, type UIMessage } from 'ai';\n\nexport const maxDuration = 30;\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n  const result = streamText({\n    model: openai('gpt-4o-mini'),\n    messages: convertToModelMessages(messages),\n  });\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    getErrorMessage: (e) =>\n      e instanceof Error ? e.message : 'An error occurred',\n  });\n}\n```\n\n### Client Hook\n\n```tsx\n'use client';\nimport { useState } from 'react';\nimport { useChat, type UIMessage } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\nexport function Chat({ initialMessages = [] }: { initialMessages?: UIMessage[] }) {\n  const [input, setInput] = useState('');\n\n  const { messages, sendMessage, status, error } = useChat({\n    messages: initialMessages,\n    transport: new DefaultChatTransport({ api: '/api/chat' }),\n  });\n\n  const submit = (e: React.FormEvent) => {\n    e.preventDefault();\n    if (input.trim()) {\n      sendMessage({ role: 'user', content: [{ type: 'text', text: input }] });\n      setInput('');\n    }\n  };\n\n  return (\n    <div>\n      {messages.map((m) => (\n        <div key={m.id}>\n          <b>{m.role === 'user' ? 'You' : 'AI'}:</b>\n          {m.parts.map((p, i) => (p.type === 'text' ? <span key={i}>{p.text}</span> : null))}\n        </div>\n      ))}\n      {status === 'error' && <div className=\"text-red-600\">{error?.message}</div>}\n      <form onSubmit={submit}>\n        <input value={input} onChange={(e) => setInput(e.target.value)} />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n```\n\n## Structured Outputs\n\n```typescript\nimport { generateObject, streamObject } from 'ai';\nimport { openai } from '@ai-sdk/openai';\nimport { z } from 'zod';\n\nconst schema = z.object({\n  recipe: z.object({\n    name: z.string(),\n    ingredients: z.array(z.string()),\n    steps: z.array(z.string()),\n  }),\n});\n\n// One-shot JSON\nconst { object } = await generateObject({\n  model: openai('gpt-4o'),\n  schema,\n  prompt: 'Generate a lasagna recipe.',\n});\n\n// Streaming JSON (partial updates)\nconst { partialObjectStream } = streamObject({\n  model: openai('gpt-4o'),\n  schema,\n  prompt: 'Generate a lasagna recipe.',\n});\n\nfor await (const partial of partialObjectStream) {\n  // Render progressively\n}\n```\n\n## Tools\n\n### Server-Side Tool Definition\n\n```typescript\nimport { tool } from 'ai';\nimport { z } from 'zod';\n\nconst searchTool = tool({\n  description: 'Search product catalog',\n  inputSchema: z.object({ query: z.string() }),\n  execute: async ({ query }) => {\n    // Implementation\n    return [{ id: 'p1', name: 'Example Product' }];\n  },\n});\n```\n\n### Multi-Step Tool Loops\n\n```typescript\nimport { streamText, stepCountIs } from 'ai';\n\nconst result = streamText({\n  model: openai('gpt-4o'),\n  messages: convertToModelMessages(messages),\n  tools: { search: searchTool },\n  stopWhen: stepCountIs(6), // Max 6 iterations\n  prepareStep: async ({ stepNumber, messages }) =>\n    messages.length > 10 ? { messages: messages.slice(-10) } : {},\n});\n\nreturn result.toUIMessageStreamResponse();\n```\n\n## v6: ToolLoopAgent\n\nFirst-class agent abstraction for autonomous multi-step workflows.\n\n### Basic Agent\n\n```typescript\nimport { ToolLoopAgent, stepCountIs } from 'ai';\n\nconst agent = new ToolLoopAgent({\n  model: 'anthropic/claude-sonnet-4.5',\n  instructions: 'You are a helpful research assistant.',\n  tools: {\n    search: searchTool,\n    calculator: calculatorTool,\n  },\n  stopWhen: stepCountIs(5),\n});\n\n// Non-streaming\nconst result = await agent.generate({\n  prompt: 'What is the weather in NYC?',\n});\nconsole.log(result.text);\nconsole.log(result.steps); // All steps taken\n\n// Streaming\nconst stream = agent.stream({ prompt: 'Research quantum computing.' });\nfor await (const chunk of stream.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\n### Agent with UI Streaming\n\n```typescript\nimport { ToolLoopAgent, createAgentUIStream } from 'ai';\n\nconst agent = new ToolLoopAgent({ model, instructions, tools });\n\nconst stream = await createAgentUIStream({\n  agent,\n  messages: [{ role: 'user', content: 'What is the weather?' }],\n});\n\nfor await (const chunk of stream) {\n  // UI message chunks\n}\n```\n\n## v6: Tool Approval (Human-in-the-Loop)\n\n### Static Approval (Always Require)\n\n```typescript\nconst dangerousTool = tool({\n  description: 'Delete user data',\n  inputSchema: z.object({ userId: z.string() }),\n  needsApproval: true, // Always require approval\n  execute: async ({ userId }) => {\n    return await deleteUserData(userId);\n  },\n});\n```\n\n### Dynamic Approval (Conditional)\n\n```typescript\nconst paymentTool = tool({\n  description: 'Process payment',\n  inputSchema: z.object({\n    amount: z.number(),\n    recipient: z.string(),\n  }),\n  needsApproval: async ({ amount }) => amount > 1000, // Only large transactions\n  execute: async ({ amount, recipient }) => {\n    return await processPayment(amount, recipient);\n  },\n});\n```\n\n### Client-Side Approval UI\n\n```tsx\nfunction ToolApprovalView({ invocation, addToolApprovalResponse }) {\n  if (invocation.state === 'approval-requested') {\n    return (\n      <div>\n        <p>Approve action: {invocation.input.description}?</p>\n        <button\n          onClick={() =>\n            addToolApprovalResponse({ id: invocation.approval.id, approved: true })\n          }\n        >\n          Approve\n        </button>\n        <button\n          onClick={() =>\n            addToolApprovalResponse({ id: invocation.approval.id, approved: false })\n          }\n        >\n          Deny\n        </button>\n      </div>\n    );\n  }\n\n  if (invocation.state === 'output-available') {\n    return <div>Result: {JSON.stringify(invocation.output)}</div>;\n  }\n\n  return null;\n}\n```\n\n## Persistence\n\n```typescript\nreturn result.toUIMessageStreamResponse({\n  originalMessages: messages,\n  generateMessageId: createIdGenerator({ prefix: 'msg', size: 16 }),\n  onFinish: async ({ messages: complete }) => {\n    await saveChat({ chatId, messages: complete }); // Persist UIMessage[]\n  },\n});\n```\n\n## Error Handling\n\n```typescript\n// Server: Surface errors to client\nreturn result.toUIMessageStreamResponse({\n  getErrorMessage: (e) =>\n    e instanceof Error ? e.message : typeof e === 'string' ? e : JSON.stringify(e),\n});\n\n// Client: Handle error state\nconst { status, error } = useChat({ ... });\nif (status === 'error') {\n  return <div>Error: {error?.message}</div>;\n}\n```\n\n## Anti-Patterns\n\n| Avoid | Use Instead |\n|-------|-------------|\n| `StreamingTextResponse` | `result.toUIMessageStreamResponse()` |\n| Persisting `ModelMessage` | Persist `UIMessage[]` |\n| Unbounded tool loops | `stopWhen: stepCountIs(N)` |\n| Client-only state for long sessions | Add persistence + resumable streams |\n| `any` types | Zod schemas + typed `UIMessage` |\n\n<references>\n\n- [agents.md](references/agents.md) - ToolLoopAgent patterns and workflows\n- [tool-approval.md](references/tool-approval.md) - Human-in-the-loop approval flows\n- [persistence.md](references/persistence.md) - Chat persistence strategies\n\n</references>"
              },
              {
                "name": "bun-dev",
                "description": "This skill should be used when working with Bun runtime, bun:sqlite, Bun.serve, bun:test, or when \"Bun\", \"bun:test\", or Bun-specific patterns are mentioned.",
                "path": "baselayer/skills/bun-dev/SKILL.md",
                "frontmatter": {
                  "name": "bun-dev",
                  "version": "1.0.0",
                  "description": "This skill should be used when working with Bun runtime, bun:sqlite, Bun.serve, bun:test, or when \"Bun\", \"bun:test\", or Bun-specific patterns are mentioned."
                },
                "content": "# Bun Development\n\nBun runtime  native APIs  zero-dependency patterns.\n\n<when_to_use>\n\n- Bun runtime development\n- SQLite database with bun:sqlite\n- HTTP server with Bun.serve\n- Testing with bun:test\n- File operations with Bun.file/Bun.write\n- Shell operations with $ template\n- Password hashing with Bun.password\n- Environment variable handling\n- Building and bundling\n\nNOT for: Node.js-only patterns, cross-runtime libraries, non-Bun projects\n\n</when_to_use>\n\n<runtime_basics>\n\n**Package management**:\n\n```bash\nbun install          # Install deps\nbun add zod          # Add package\nbun remove zod       # Remove package\nbun update           # Update all\n```\n\n**Script execution**:\n\n```bash\nbun run dev          # Run package.json script\nbun run src/index.ts # Execute TypeScript directly\nbun --watch index.ts # Watch mode\n```\n\n**Testing**:\n\n```bash\nbun test             # All tests\nbun test src/        # Directory\nbun test --watch     # Watch mode\nbun test --coverage  # With coverage\n```\n\n**Building**:\n\n```bash\nbun build ./index.ts --outfile dist/bundle.js\nbun build ./index.ts --compile --outfile myapp  # Standalone executable\n```\n\n</runtime_basics>\n\n## File Operations\n\n<file_operations>\n\n```typescript\n// Read file (lazy, efficient)\nconst file = Bun.file('./data.json');\nif (!(await file.exists())) throw new Error('File not found');\n\n// Read formats\nconst text = await file.text();\nconst json = await file.json();\nconst buffer = await file.arrayBuffer();\nconst stream = file.stream(); // Large files\n\n// Metadata\nconsole.log(file.size, file.type);\n\n// Write\nawait Bun.write('./output.txt', 'content');\nawait Bun.write('./data.json', JSON.stringify(data));\nawait Bun.write('./blob.txt', new Blob(['data']));\n```\n\n</file_operations>\n\n## SQLite (bun:sqlite)\n\n<sqlite>\n\n```typescript\nimport { Database } from 'bun:sqlite';\n\nconst db = new Database('app.db', { create: true, readwrite: true, strict: true });\n\n// Create tables\ndb.run(`\n  CREATE TABLE IF NOT EXISTS users (\n    id TEXT PRIMARY KEY,\n    email TEXT UNIQUE NOT NULL,\n    name TEXT NOT NULL,\n    created_at TEXT DEFAULT CURRENT_TIMESTAMP\n  )\n`);\n\n// Prepared statements (always use these)\nconst getUser = db.prepare('SELECT * FROM users WHERE id = ?');\nconst createUser = db.prepare('INSERT INTO users (id, email, name) VALUES (?, ?, ?) RETURNING *');\n\n// Execution\nconst user = getUser.get('user-123');                    // Single row\nconst all = db.prepare('SELECT * FROM users').all();     // All rows\ndb.prepare('DELETE FROM users WHERE id = ?').run('id');  // No return\n\n// Named parameters\nconst stmt = db.prepare('SELECT * FROM users WHERE email = $email');\nstmt.get({ $email: 'alice@example.com' });\n\n// Transactions (atomic, auto-rollback on error)\nconst transfer = db.transaction((fromId: string, toId: string, amount: number) => {\n  db.run('UPDATE accounts SET balance = balance - ? WHERE id = ?', [amount, fromId]);\n  db.run('UPDATE accounts SET balance = balance + ? WHERE id = ?', [amount, toId]);\n});\ntransfer('alice', 'bob', 100);\n\ndb.close(); // When done\n```\n\nSee [sqlite-patterns.md](references/sqlite-patterns.md) for migrations, pooling, repository pattern.\n\n</sqlite>\n\n## Password Hashing\n\n<password>\n\n```typescript\n// Hash (argon2id recommended)\nconst hash = await Bun.password.hash('password123', {\n  algorithm: 'argon2id',\n  memoryCost: 65536,  // 64 MB\n  timeCost: 3\n});\n\n// Or bcrypt\nconst bcryptHash = await Bun.password.hash('password123', {\n  algorithm: 'bcrypt',\n  cost: 12\n});\n\n// Verify\nconst isValid = await Bun.password.verify('password123', hash);\nif (!isValid) throw new Error('Invalid password');\n```\n\n**Auth flow example**:\n\n```typescript\napp.post('/auth/register', zValidator('json', RegisterSchema), async (c) => {\n  const { email, password } = c.req.valid('json');\n  const db = c.get('db');\n\n  if (db.prepare('SELECT id FROM users WHERE email = ?').get(email)) {\n    throw new HTTPException(409, { message: 'Email already registered' });\n  }\n\n  const hashedPassword = await Bun.password.hash(password, { algorithm: 'argon2id' });\n  const user = db.prepare(`\n    INSERT INTO users (id, email, password) VALUES (?, ?, ?) RETURNING id, email\n  `).get(crypto.randomUUID(), email, hashedPassword);\n\n  return c.json({ user }, 201);\n});\n```\n\n</password>\n\n## HTTP Server\n\n<http_server>\n\n```typescript\nBun.serve({\n  port: 3000,\n  fetch(req) {\n    const url = new URL(req.url);\n    if (url.pathname === '/') return new Response('Hello');\n    if (url.pathname === '/json') return Response.json({ ok: true });\n    return new Response('Not found', { status: 404 });\n  },\n  error(err) {\n    return new Response(`Error: ${err.message}`, { status: 500 });\n  }\n});\n```\n\n**With Hono** (recommended for APIs):\n\n```typescript\nimport { Hono } from 'hono';\n\nconst app = new Hono()\n  .get('/', (c) => c.text('Hello'))\n  .get('/json', (c) => c.json({ ok: true }));\n\nBun.serve({ port: 3000, fetch: app.fetch });\n```\n\nSee [server-patterns.md](references/server-patterns.md) for routing, middleware, file serving, streaming.\n\n</http_server>\n\n## WebSocket\n\n<websocket>\n\n```typescript\nimport type { ServerWebSocket } from 'bun';\n\ntype WsData = { userId: string };\n\nBun.serve<WsData>({\n  port: 3000,\n  fetch(req, server) {\n    const url = new URL(req.url);\n    if (url.pathname === '/ws') {\n      const userId = url.searchParams.get('userId') || 'anon';\n      return server.upgrade(req, { data: { userId } }) ? undefined\n        : new Response('Upgrade failed', { status: 400 });\n    }\n    return new Response('Hello');\n  },\n  websocket: {\n    open(ws: ServerWebSocket<WsData>) {\n      ws.subscribe('chat');\n      ws.send(JSON.stringify({ type: 'connected' }));\n    },\n    message(ws: ServerWebSocket<WsData>, msg: string | Buffer) {\n      ws.publish('chat', msg);\n    },\n    close(ws: ServerWebSocket<WsData>) {\n      ws.unsubscribe('chat');\n    }\n  }\n});\n```\n\nSee [server-patterns.md](references/server-patterns.md) for client tracking, rooms, reconnection.\n\n</websocket>\n\n## Shell Operations\n\n<shell>\n\n```typescript\nimport { $ } from 'bun';\n\n// Run commands\nconst result = await $`ls -la`;\nconsole.log(result.text());\n\n// Variables (auto-escaped)\nconst dir = './src';\nawait $`find ${dir} -name \"*.ts\"`;\n\n// Check exit code\nconst { exitCode } = await $`npm test`.nothrow();\nif (exitCode !== 0) console.error('Tests failed');\n\n// Spawn process\nconst proc = Bun.spawn(['ls', '-la']);\nawait proc.exited;\n\n// Capture output\nconst proc2 = Bun.spawn(['echo', 'Hello'], { stdout: 'pipe' });\nconst output = await new Response(proc2.stdout).text();\n```\n\n</shell>\n\n## Testing (bun:test)\n\n<testing>\n\n```typescript\nimport { describe, test, expect, beforeEach, afterEach } from 'bun:test';\n\ndescribe('feature', () => {\n  let db: Database;\n\n  beforeEach(() => { db = new Database(':memory:'); });\n  afterEach(() => { db.close(); });\n\n  test('behavior', () => {\n    expect(result).toBe(expected);\n    expect(arr).toContain(item);\n    expect(fn).toThrow();\n    expect(obj).toEqual({ foo: 'bar' });\n  });\n\n  test('async', async () => {\n    const result = await asyncFn();\n    expect(result).toBeDefined();\n  });\n\n  test.todo('pending feature');\n  test.skip('temporarily disabled');\n});\n```\n\n```bash\nbun test                    # All tests\nbun test src/api.test.ts    # Specific file\nbun test --watch            # Watch mode\nbun test --coverage         # With coverage\n```\n\nSee [testing.md](references/testing.md) for assertions, mocking, snapshots, best practices.\n\n</testing>\n\n## Environment Variables\n\n<environment>\n\n```typescript\n// Access\nconsole.log(Bun.env.NODE_ENV);\nconsole.log(Bun.env.DATABASE_URL);\n\n// Zod validation\nimport { z } from 'zod';\n\nconst EnvSchema = z.object({\n  NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),\n  DATABASE_URL: z.string(),\n  PORT: z.coerce.number().int().positive().default(3000),\n  API_KEY: z.string().min(32)\n});\n\nexport const env = EnvSchema.parse(Bun.env);\n```\n\nBun auto-loads `.env`, `.env.local`, `.env.production`.\n\n</environment>\n\n## Performance Utilities\n\n<performance>\n\n```typescript\n// High-resolution timing\nconst start = Bun.nanoseconds();\nawait doWork();\nconsole.log(`Took ${(Bun.nanoseconds() - start) / 1_000_000}ms`);\n\n// Hashing\nconst hash = Bun.hash(data);\nconst crc32 = Bun.hash.crc32(data);\nconst sha256 = Bun.CryptoHasher.hash('sha256', data);\n\n// Sleep\nawait Bun.sleep(1000);\n\n// Memory\nconst { rss, heapUsed } = process.memoryUsage();\nconsole.log('RSS:', rss / 1024 / 1024, 'MB');\n```\n\n</performance>\n\n## Building & Bundling\n\n<building>\n\n```bash\n# Production bundle\nbun build ./index.ts --outfile dist/bundle.js --minify --sourcemap\n\n# External deps\nbun build ./index.ts --outfile dist/bundle.js --external hono --external zod\n\n# Standalone executable\nbun build ./index.ts --compile --outfile myapp\n\n# Cross-compile\nbun build ./index.ts --compile --target=bun-linux-x64 --outfile myapp-linux\nbun build ./index.ts --compile --target=bun-darwin-arm64 --outfile myapp-macos\nbun build ./index.ts --compile --target=bun-windows-x64 --outfile myapp.exe\n```\n\n</building>\n\n<rules>\n\nALWAYS:\n- Use Bun APIs when available (faster, native)\n- Prepared statements for database queries\n- Transactions for multi-statement operations\n- argon2id for password hashing\n- Validate environment variables at startup\n- Close database connections when done\n\nNEVER:\n- String interpolation in SQL (use parameters)\n- Plaintext passwords\n- Ignore async disposal cleanup\n- Deprecated Node.js APIs when Bun native exists\n\nPREFER:\n- Bun.file over fs.readFile\n- Bun.write over fs.writeFile\n- bun:sqlite over external SQLite libraries\n- Bun.password over bcrypt/argon2 packages\n- $ shell template over child_process\n\n</rules>\n\n<references>\n\n- [sqlite-patterns.md](references/sqlite-patterns.md)  migrations, pooling, repository, FTS\n- [server-patterns.md](references/server-patterns.md)  HTTP, WebSocket, streaming, compression\n- [testing.md](references/testing.md)  assertions, mocking, snapshots, best practices\n\n**Examples:**\n- [database-crud.md](examples/database-crud.md)  SQLite CRUD patterns\n- [file-uploads.md](examples/file-uploads.md)  streaming file handling\n\n</references>"
              },
              {
                "name": "cli-development-guidelines",
                "description": "REDIRECT: Use cli-dev:cli-development-guidelines instead. CLI development skills live in the cli-dev plugin.",
                "path": "baselayer/skills/cli-development-guidelines/SKILL.md",
                "frontmatter": {
                  "name": "cli-development-guidelines",
                  "description": "REDIRECT: Use cli-dev:cli-development-guidelines instead. CLI development skills live in the cli-dev plugin."
                },
                "content": "# Skill Moved\n\nThis skill has moved to the **cli-dev** plugin.\n\n## Correct Invocation\n\nUse the Skill tool with:\n\n```\ncli-dev:cli-development-guidelines\n```\n\n## Why the Redirect?\n\nCLI-specific development skills (argument parsing, help text, subcommands, error messages) are maintained in the dedicated `cli-dev` plugin, not baselayer.\n\n**baselayer** contains core methodology skills (TDD, debugging, architecture).\n**cli-dev** contains CLI-specific patterns and guidelines.\n\n## Action Required\n\nInvoke the correct skill now:\n\n```\nSkill: cli-dev:cli-development-guidelines\n```"
              },
              {
                "name": "code-review",
                "description": "This skill should be used when reviewing code before commit, conducting quality gates, or when \"review\", \"fresh eyes\", \"pre-commit review\", or \"quality gate\" are mentioned.",
                "path": "baselayer/skills/code-review/SKILL.md",
                "frontmatter": {
                  "name": "code-review",
                  "version": "1.0.0",
                  "description": "This skill should be used when reviewing code before commit, conducting quality gates, or when \"review\", \"fresh eyes\", \"pre-commit review\", or \"quality gate\" are mentioned."
                },
                "content": "# Fresh Eyes Review\n\nSystematic pre-commit quality gate  checklist-based review  findings  summary.\n\n<when_to_use>\n\n- Pre-commit code review and quality gates\n- Pre-merge pull request reviews\n- Systematic code audits before deployment\n- Quality verification for critical changes\n- Second-opinion review requests\n\nNOT for: quick sanity checks, trivial typo fixes, formatting-only changes\n\n</when_to_use>\n\n<announcement_protocol>\n\n## Starting Review\n\n**Review Scope:** { files/areas under review }\n**Focus Areas:** { specific concerns or general quality gate }\n**Checklist:** { full or targeted categories }\n\n## During Review\n\nEmit findings as discovered:\n- **{SEVERITY}** `{FILE_PATH}:{LINE}`  { issue description }\n- **Impact:** { consequences if shipped }\n- **Fix:** { concrete remediation }\n\n## Completing Review\n\n**Review Complete**\n\n**Findings Summary:**\n-  Severe: {COUNT}  blocking issues\n-  Moderate: {COUNT}  should fix before merge\n-  Minor: {COUNT}  consider addressing\n\n**Recommendation:** { ship / fix blockers / needs rework }\n\n{ detailed findings below if any found }\n\n</announcement_protocol>\n\n<checklist>\n\n## Type Safety\n\n-  No `any` types without justification comment\n-  Null/undefined handled explicitly (optional chaining, nullish coalescing)\n-  Type guards used for union types\n-  Discriminated unions for state machines\n-  Generic constraints specified where needed\n-  Return types explicit on public functions\n-  No type assertions without safety comment\n\n## Error Handling\n\n-  All error paths handled (no silent failures)\n-  Meaningful error messages with context\n-  Errors propagated or logged appropriately\n-  Result types used for expected failures\n-  Try/catch blocks have specific error handling\n-  Promise rejections handled\n-  Resource cleanup in finally blocks\n\n## Security\n\n-  User input validated before use\n-  No hardcoded secrets or credentials\n-  Authentication/authorization checks present\n-  Parameterized queries (no SQL injection)\n-  XSS prevention (sanitized output)\n-  CSRF protection where applicable\n-  Sensitive data encrypted/hashed\n-  Rate limiting on public endpoints\n\n## Testing\n\n-  Tests exist for new functionality\n-  Edge cases covered\n-  Error scenarios tested\n-  Actual assertions (not just execution)\n-  No test pollution (proper setup/teardown)\n-  Mocks used appropriately (not overused)\n-  Test names describe behavior\n-  Integration tests for critical paths\n\n## Code Quality\n\n-  Names reveal intent (functions, variables, types)\n-  Functions <50 lines (single responsibility)\n-  Files <500 lines (consider splitting)\n-  No magic numbers (use named constants)\n-  DRY violations eliminated\n-  Nested conditionals <3 deep\n-  Cyclomatic complexity reasonable\n-  Dead code removed\n\n## Documentation\n\n-  Public APIs have JSDoc/TSDoc\n-  Complex algorithms explained\n-  Non-obvious decisions documented\n-  Breaking changes noted\n-  TODOs have context and owner\n-  README updated if behavior changes\n-  Examples provided for complex usage\n\n## Performance\n\n-  No obvious N+1 queries\n-  Appropriate data structures used\n-  Unnecessary allocations avoided\n-  Heavy operations async/batched\n-  Caching where beneficial\n-  Database indexes considered\n\n## Rust-Specific (when applicable)\n\n-  `rustfmt` and `clippy` passing\n-  `Result` preferred over panic\n-  No `unwrap`/`expect` outside tests/startup\n-  Ownership/borrowing idiomatic\n-  `Send`/`Sync` bounds respected\n-  Unsafe code justified with comments\n-  Proper error types (`thiserror`/`anyhow`)\n\n</checklist>\n\n<phases>\n\n## 1. Announce (activeForm: Announcing review)\n\nEmit starting protocol:\n- Scope of review\n- Focus areas\n- Checklist approach (full or targeted)\n\n## 2. Checklist (activeForm: Running checklist review)\n\nSystematically verify each category:\n- Type Safety  Error Handling  Security  Testing  Quality  Docs  Performance\n- Flag violations immediately with severity\n- Note clean areas briefly\n\n## 3. Deep Dive (activeForm: Investigating findings)\n\nFor each finding:\n- Verify it's actually a problem (not false positive)\n- Assess severity and impact\n- Determine concrete fix\n- Check for pattern across codebase\n\n## 4. Summarize (activeForm: Compiling review summary)\n\nEmit completion protocol:\n- Findings count by severity\n- Recommendation (ship / fix blockers / rework)\n- Detailed findings list\n- Optional: patterns noticed, suggestions for future\n\nUse TodoWrite with activeForm for tracking review phases.\n\n</phases>\n\n<finding_format>\n\n**{SEVERITY}** `{FILE_PATH}:{LINE_RANGE}`\n\n**Issue:** { clear description of problem }\n\n**Impact:** { consequences if shipped  security risk, runtime error, maintenance burden, etc }\n\n**Fix:** { concrete steps to remediate }\n\n**Pattern:** { if issue appears multiple times, note scope }\n\n---\n\nExample:\n\n**** `src/auth/login.ts:45-52`\n\n**Issue:** Password compared using `==` instead of constant-time comparison\n\n**Impact:** Timing attack vulnerability  attacker can infer password length and content through response timing\n\n**Fix:** Use `crypto.timingSafeEqual()` or bcrypt's built-in comparison\n\n**Pattern:** Single occurrence\n\n---\n\n</finding_format>\n\n<severity_guidance>\n\n** Severe (blocking):**\n- Security vulnerabilities\n- Data loss risks\n- Runtime crashes in common paths\n- Breaking changes without migration\n- Test failures or missing critical tests\n\n** Moderate (should fix):**\n- Type safety violations\n- Unhandled error cases\n- Poor error messages\n- Missing tests for edge cases\n- Significant code quality issues\n- Missing documentation for public APIs\n\n** Minor (consider addressing):**\n- Code style inconsistencies\n- Overly complex but functional code\n- Minor performance optimizations\n- Documentation improvements\n- TODOs without context\n- Naming improvements\n\n</severity_guidance>\n\n<workflow>\n\nLoop: Scan  Verify  Document  Next category\n\n1. **Announce review**  scope, focus, approach\n2. **Run checklist**  systematically verify each category\n3. **Document findings**  severity, location, issue, impact, fix\n4. **Investigate patterns**  does finding repeat? Broader issue?\n5. **Deep dive blockers**  verify severity assessment, ensure fix is clear\n6. **Compile summary**  counts by severity, recommendation\n7. **Deliver findings**  completion protocol with detailed list\n\nAt each finding:\n- Verify it's actually a problem\n- Assess impact if shipped\n- Determine concrete fix\n- Note if pattern across files\n\n</workflow>\n\n<validation>\n\nBefore completing review:\n\n**Check coverage:**\n-  All checklist categories verified?\n-  Both happy path and error paths reviewed?\n-  Tests examined for actual assertions?\n-  Security-sensitive areas given extra scrutiny?\n\n**Check findings quality:**\n-  Severity accurately assessed?\n-  Impact clearly explained?\n-  Fix actionable and concrete?\n-  False positives eliminated?\n\n**Check recommendation:**\n-  Aligned with findings severity?\n-  Blockers clearly marked?\n-  Path forward unambiguous?\n\n</validation>\n\n<rules>\n\nALWAYS:\n- Announce review start with scope and focus\n- Run systematic checklist, don't skip categories\n- Emit findings as discovered, don't batch at end\n- Assess severity honestly (err toward caution)\n- Provide concrete fixes, not just complaints\n- Complete with summary and recommendation\n- Mark false positives if checklist item doesn't apply\n- Consider patterns (single issue or systemic?)\n\nNEVER:\n- Skip checklist review for \"quick check\"\n- Assume code is safe without verification\n- Flag style preferences as blockers\n- Provide vague findings without fix guidance\n- Approve severe findings \"for later fix\"\n- Complete review without announcement protocol\n- Miss security checks on user input paths\n- Ignore test quality (execution != validation)\n\n</rules>\n\n<references>\n\nCore methodology:\n- [checklist.md](references/checklist.md)  extended checklist details, examples, severity guidance\n- [FORMATTING.md](../../shared/rules/FORMATTING.md)  formatting conventions\n\nRelated skills:\n- codebase-analysis  evidence-based investigation (foundation for review)\n- debugging-and-diagnosis  structured bug investigation\n\n</references>"
              },
              {
                "name": "codebase-analysis",
                "description": "This skill should be used when analyzing codebases, understanding architecture, or when \"analyze\", \"investigate\", \"explore code\", or \"understand architecture\" are mentioned.",
                "path": "baselayer/skills/codebase-analysis/SKILL.md",
                "frontmatter": {
                  "name": "codebase-analysis",
                  "version": "1.0.0",
                  "description": "This skill should be used when analyzing codebases, understanding architecture, or when \"analyze\", \"investigate\", \"explore code\", or \"understand architecture\" are mentioned."
                },
                "content": "# Codebase Analysis\n\nEvidence-based investigation  findings  confidence-tracked conclusions.\n\n<when_to_use>\n\n- Codebase exploration and understanding\n- Architecture analysis and mapping\n- Pattern extraction and recognition\n- Technical research within code\n- Performance or security analysis\n\nNOT for: wild guessing, assumptions without evidence, conclusions before investigation\n\n</when_to_use>\n\n<confidence>\n\n| Bar | Lvl | Name | Action |\n|-----|-----|------|--------|\n| `` | 0 | Gathering | Collect initial evidence |\n| `` | 1 | Surveying | Broad scan, surface patterns |\n| `` | 2 | Investigating | Deep dive, verify patterns |\n| `` | 3 | Analyzing | Cross-reference, fill gaps |\n| `` | 4 | Synthesizing | Connect findings, high confidence |\n| `` | 5 | Concluded | Deliver findings |\n\n*Calibration: 0=019%, 1=2039%, 2=4059%, 3=6074%, 4=7589%, 5=90100%*\n\nStart honest. Clear codebase + focused question  level 23. Vague or complex  level 01.\n\nAt level 4: \"High confidence in findings. One more angle would reach full certainty. Continue or deliver now?\"\n\nBelow level 5: include ` Caveats` section.\n\n</confidence>\n\n<principles>\n\n## Core Methodology\n\n**Evidence over assumption**  investigate when you can, guess only when you must.\n\n**Multi-source gathering**  code, docs, tests, history, web research, runtime behavior.\n\n**Multiple angles**  examine from different perspectives before concluding.\n\n**Document gaps**  flag uncertainty with , track what's unknown.\n\n**Show your work**  findings include supporting evidence, not just conclusions.\n\n**Calibrate confidence**  distinguish fact from inference from assumption.\n\n</principles>\n\n<evidence_gathering>\n\n## Source Priority\n\n1. **Direct observation**  read code, run searches, examine files\n2. **Documentation**  official docs, inline comments, ADRs\n3. **Tests**  reveal intended behavior and edge cases\n4. **History**  git log, commit messages, PR discussions\n5. **External research**  library docs, Stack Overflow, RFCs\n6. **Inference**  logical deduction from available evidence\n7. **Assumption**  clearly flagged when other sources unavailable\n\n## Investigation Patterns\n\n**Start broad, then narrow:**\n- File tree  identify relevant areas\n- Search patterns  locate specific code\n- Code structure  understand without full content\n- Read targeted files  examine implementation\n- Cross-reference  verify understanding\n\n**Layer evidence:**\n- What does the code do? (direct observation)\n- Why was it written this way? (history, comments)\n- How does it fit the system? (architecture, dependencies)\n- What are the edge cases? (tests, error handling)\n\n**Follow the trail:**\n- Function calls  trace execution paths\n- Imports/exports  map dependencies\n- Test files  understand usage patterns\n- Error messages  reveal assumptions\n- Comments  capture historical context\n\n</evidence_gathering>\n\n<output_format>\n\n## During Investigation\n\nAfter each evidence-gathering step emit:\n\n- **Confidence:** {BAR} {NAME}\n- **Found:** { key discoveries }\n- **Patterns:** { emerging themes }\n- **Gaps:** { what's still unclear }\n- **Next:** { investigation direction }\n\n## At Delivery (Level 5)\n\n### Findings\n\n{ numbered list of discoveries with supporting evidence }\n\n1. {FINDING}  evidence: {SOURCE}\n2. {FINDING}  evidence: {SOURCE}\n\n### Patterns\n\n{ recurring themes or structures identified }\n\n### Implications\n\n{ what findings mean for the question at hand }\n\n### Confidence Assessment\n\nOverall: {BAR} {PERCENTAGE}%\n\nHigh confidence areas:\n- {AREA}  {REASON}\n\nLower confidence areas:\n- {AREA}  {REASON}\n\n### Supporting Evidence\n\n- Code: { file paths and line ranges }\n- Docs: { references }\n- Tests: { relevant test files }\n- History: { commit SHAs if relevant }\n- External: { URLs if applicable }\n\n## Below Level 5\n\n###  Caveats\n\n**Assumptions:**\n- {ASSUMPTION}  { why necessary, impact if wrong }\n\n**Gaps:**\n- {GAP}  { what's missing, how to fill }\n\n**Unknowns:**\n- {UNKNOWN}  { noted for future investigation }\n\n</output_format>\n\n<specialized_techniques>\n\nLoad micro-skills for specialized analysis:\n\n- **Pattern analysis**  load [pattern-analysis](../pattern-analysis/SKILL.md) skill\n- **Root cause investigation**  load [root-cause-analysis](../root-cause-analysis/SKILL.md) skill\n- **Research synthesis**  load [report-findings](../report-findings/SKILL.md) skill\n- **Architecture analysis**  see [architecture-analysis.md](references/architecture-analysis.md)\n\nThese provide deep-dive methodologies for specific analysis types.\n\n</specialized_techniques>\n\n<workflow>\n\nLoop: Gather  Analyze  Update Confidence  Next step\n\n1. **Calibrate starting confidence**  what do we already know?\n2. **Identify evidence sources**  where can we look?\n3. **Gather systematically**  collect from multiple angles\n4. **Cross-reference findings**  verify patterns hold\n5. **Flag uncertainties**  mark gaps with \n6. **Synthesize conclusions**  connect evidence to insights\n7. **Deliver with confidence level**  clear about certainty\n\nAt each step:\n- Document what you found (evidence)\n- Note what it means (interpretation)\n- Track what's still unclear (gaps)\n- Update confidence bar\n\n</workflow>\n\n<validation>\n\nBefore concluding (level 4+):\n\n**Check evidence quality:**\n-  Multiple sources confirm pattern?\n-  Direct observation vs inference clearly marked?\n-  Assumptions explicitly flagged?\n-  Counter-examples considered?\n\n**Check completeness:**\n-  Original question fully addressed?\n-  Edge cases explored?\n-  Alternative explanations ruled out?\n-  Known unknowns documented?\n\n**Check deliverable:**\n-  Findings supported by evidence?\n-  Confidence calibrated honestly?\n-  Caveats section included if <100%?\n-  Next steps clear if incomplete?\n\n</validation>\n\n<rules>\n\nALWAYS:\n- Investigate before concluding\n- Cite evidence sources with file paths/URLs\n- Use confidence bars to track certainty\n- Flag assumptions and gaps with \n- Cross-reference from multiple angles\n- Document investigation trail\n- Distinguish fact from inference\n- Include caveats below level 5\n\nNEVER:\n- Guess when you can investigate\n- State assumptions as facts\n- Conclude from single source\n- Hide uncertainty or gaps\n- Skip validation checks\n- Deliver without confidence assessment\n- Conflate evidence with interpretation\n\n</rules>\n\n<references>\n\nCore methodology:\n- [confidence.md](../pathfinding/references/confidence.md)  confidence calibration (shared with pathfinding)\n- [FORMATTING.md](../../shared/rules/FORMATTING.md)  formatting conventions\n\nMicro-skills (load as needed):\n- [pattern-analysis](../pattern-analysis/SKILL.md)  extracting and validating patterns\n- [root-cause-analysis](../root-cause-analysis/SKILL.md)  systematic problem diagnosis\n- [report-findings](../report-findings/SKILL.md)  multi-source research synthesis\n\nLocal references:\n- [architecture-analysis.md](references/architecture-analysis.md)  system structure mapping\n\nRelated skills:\n- pathfinding  clarifying requirements before analysis\n- debugging-and-diagnosis  structured bug investigation (loads root-cause-analysis)\n\n</references>"
              },
              {
                "name": "complexity-analysis",
                "description": "This skill should be used when evaluating complexity, planning features, or when \"over-engineering\", \"simpler\", \"is this overkill\", or \"keep it simple\" are mentioned.",
                "path": "baselayer/skills/complexity-analysis/SKILL.md",
                "frontmatter": {
                  "name": "complexity-analysis",
                  "version": "1.0.0",
                  "description": "This skill should be used when evaluating complexity, planning features, or when \"over-engineering\", \"simpler\", \"is this overkill\", or \"keep it simple\" are mentioned."
                },
                "content": "# Challenge Complexity\n\nSystematic pushback against over-engineering  justified simplicity.\n\n<when_to_use>\n\n- Planning features or architecture\n- Choosing frameworks, libraries, patterns\n- Evaluating proposed solutions\n- Detecting premature optimization or abstraction\n- Build vs buy decisions\n\nNOT for: trivial tasks, clear requirements with validated complexity, regulatory/compliance-mandated approaches\n\n</when_to_use>\n\n<phases>\n\nTrack with TodoWrite when applying framework to non-trivial proposals:\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Identify | Complexity smell detected | \"Identifying complexity smell\" |\n| Alternative | Generating simpler options | \"Proposing simpler alternatives\" |\n| Question | Probing constraints | \"Questioning constraints\" |\n| Document | Recording decision | \"Documenting decision\" |\n\nTodoWrite format:\n\n```text\n- Identify { complexity type } smell\n- Propose alternatives to { specific approach }\n- Question { constraint/requirement }\n- Document { decision/rationale }\n```\n\nWorkflow:\n- Start: Create Identify `in_progress` when smell detected\n- Transition: Mark current `completed`, add next `in_progress`\n- Skip to Document if complexity validated immediately\n- Optional phases: skip Alternative if obvious, skip Question if constraints clear\n\n</phases>\n\n<escalation>\n\nAdjust tone based on severity:\n\n **Alternative** (Minor complexity):\n> \"Interesting approach. Help me understand why X over the more common Y?\"\n\n **Caution** (Moderate risk):\n> \"This pattern often leads to [specific problems]. Are we solving for something I'm not seeing?\"\n\n **Hazard** (High risk):\n> \"This violates [principle] and will likely cause [specific issues]. I strongly recommend [alternative]. If we must proceed, we need to document the reasoning.\"\n\n</escalation>\n\n<triggers>\n\nCommon complexity smells to watch for:\n\n**Build vs Buy**: Custom solution when proven libraries exist\n- Custom auth system  Auth0, Clerk, BetterAuth\n- Custom validation  Zod, Valibot, ArkType\n- Custom state management  Zustand, Jotai, Nanostores\n- Custom form handling  React Hook Form, Formik\n\n**Indirect Solutions**: Solving problem A by first solving problems B, C, D\n- Compiling TSJS then using JS  Use TS directly in build tool\n- Reading file, transforming, writing back  Use stream processing\n- Storing in DB to pass between functions  Pass data directly\n\n**Premature Abstraction**: Layers \"for flexibility\" without concrete future requirements\n- Plugin systems for 1 use case\n- Factories for single implementations\n- Dependency injection for stateless functions\n- Generic repositories for 1 data source\n\n**Performance Theater**: Optimizing without measurements or clear bottlenecks\n- Caching before measuring load\n- Debouncing without user complaints\n- Worker threads for CPU-light tasks\n- Memoization of cheap calculations\n\n**Security Shortcuts**: Disabling security features instead of configuring properly\n- `CORS: *`  Configure specific origins\n- `any` types for external data  Runtime validation with Zod\n- Disabling SSL verification  Fix certificate chain\n- Storing secrets in code  Environment variables + vault\n\n**Framework Overkill**: Heavy frameworks for simple tasks\n- React for static content  HTML + CSS\n- Redux for local UI state  useState\n- GraphQL for simple CRUD  REST\n- Microservices for small apps  Monolith first\n\n**Custom Infrastructure**: Building platform features that cloud providers offer\n- Custom logging  CloudWatch, Datadog\n- Custom metrics  Prometheus, Grafana\n- Custom secrets  AWS Secrets Manager, Vault\n- Custom CI/CD  GitHub Actions, CircleCI\n\n</triggers>\n\n<red_flags>\n\nWatch for these justifications  reframe with specific questions:\n\n\"We might need it later\"\n \"What specific requirement do we have now?\"\n\n\"It's more flexible\"\n \"What flexibility do we need that the simple approach doesn't provide?\"\n\n\"It's best practice\"\n \"Best practice for what context? Does that context match ours?\"\n\n\"It's faster\"\n \"Have you measured? What's the performance requirement?\"\n\n\"Everyone does it this way\"\n \"For problems of this scale? Do they have our constraints?\"\n\n\"It's more enterprise-ready\"\n \"What enterprise requirement are we meeting?\"\n\n\"I read about it on Hacker News\"\n \"Does their problem match ours?\"\n\n</red_flags>\n\n<patterns>\n\nGuide toward simpler alternatives with concrete examples:\n\n**Feature Flags over Plugin Architecture**\n\n```typescript\n// Complex\ninterface Plugin { transform(data: Data): Data }\nconst plugins = loadPlugins()\nlet result = data\nfor (const plugin of plugins) { result = plugin.transform(result) }\n\n// Simple\nconst features = getFeatureFlags()\nlet result = data\nif (features.transformA) { result = transformA(result) }\nif (features.transformB) { result = transformB(result) }\n```\n\n**Direct over Generic**\n\n```typescript\n// Complex (premature abstraction)\ninterface DataStore<T> { get(id: string): Promise<T> }\nclass PostgresStore<T> implements DataStore<T> { /* ... */ }\nconst users = new PostgresStore<User>({ /* config */ })\n\n// Simple (direct, refactor later if needed)\nasync function getUser(id: string): Promise<User> {\n  return await db.query('SELECT * FROM users WHERE id = $1', [id])\n}\n```\n\n**Standard Library over Framework**\n\n```typescript\n// Complex\nimport _ from 'lodash'\nconst unique = _.uniq(array)\nconst mapped = _.map(array, fn)\n\n// Simple\nconst unique = [...new Set(array)]\nconst mapped = array.map(fn)\n```\n\n**Composition over Configuration**\n\n```typescript\n// Complex\nconst pipeline = new Pipeline({\n  steps: [\n    { type: 'validate', rules: [...] },\n    { type: 'transform', fn: 'normalize' },\n    { type: 'save', destination: 'db' }\n  ]\n})\n\n// Simple\nconst result = pipe(\n  data,\n  validate,\n  normalize,\n  save\n)\n```\n\n</patterns>\n\n<justified>\n\nComplexity is appropriate when:\n\n1. **Measured Performance Need**: Profiling shows bottleneck, optimization addresses it\n2. **Proven Scale Requirement**: Current scale breaking, specific metric to meet\n3. **Regulatory Compliance**: Legal requirement for specific implementation\n4. **Security Threat Model**: Documented threat that simpler approach doesn't address\n5. **Integration Contract**: External system requires specific approach\n6. **Team Expertise**: Team has deep expertise in complex pattern but not simple one\n\nEven then:\n- Document why in ADR\n- Add TODO to revisit when constraints change\n- Isolate complexity to smallest possible scope\n- Provide escape hatches\n\n</justified>\n\n<workflow>\n\nApply this protocol systematically:\n\n### 1. IDENTIFY  Recognize complexity smell\n\nScan proposal for common triggers:\n- Build vs Buy\n- Indirect Solutions\n- Premature Abstraction\n- Performance Theater\n- Security Shortcuts\n- Framework Overkill\n- Custom Infrastructure\n\n### 2. ALTERNATIVE  Propose simpler solutions\n\nAlways provide **concrete, specific alternatives** with examples:\n\n Vague: \"Maybe use something simpler?\"\n Specific: \"Use Zod for validation instead of building a custom validation engine. Here's how...\"\n\nInclude:\n- Exact library/pattern name\n- Code snippet showing simpler approach\n- Why it's sufficient for actual requirements\n\n### 3. QUESTION  Investigate constraints\n\nAsk probing questions to uncover hidden requirements:\n- \"What specific requirement makes the simpler approach insufficient?\"\n- \"What will break in 6 months if we use the standard pattern?\"\n- \"What performance/scale problem are we solving?\"\n- \"What security threat model requires this complexity?\"\n- \"What team capability gap makes the standard approach unsuitable?\"\n\n### 4. DOCUMENT  Record decisions\n\nIf complexity chosen after validation:\n- Document specific requirement that justifies it\n- Add ADR (Architecture Decision Record) explaining trade-offs\n- Include TODO for revisiting when requirements change\n- Add comments explaining non-obvious complexity\n\n</workflow>\n\n<rules>\n\nALWAYS:\n- Apply pushback protocol to non-trivial proposals\n- Provide concrete alternatives with code examples\n- Ask specific questions about constraints\n- Match escalation level to severity (//)\n- Document justified complexity decisions\n\nNEVER:\n- Accept \"might need it later\" without concrete timeline\n- Allow security shortcuts without threat model\n- Skip questioning performance claims without measurements\n- Proceed with indirection without clear justification\n- Accept complexity without documenting why\n\n</rules>\n\n<references>\n\n- [decision-framework.md](references/decision-framework.md)  full decision checklist\n- [redux-overkill.md](examples/redux-overkill.md)  challenging Redux for simple form\n- [custom-auth.md](examples/custom-auth.md)  challenging custom auth build\n\n</references>"
              },
              {
                "name": "conversation-analysis",
                "description": "This skill should be used when analyzing conversation patterns, identifying frustration or success signals, or when \"analyze conversation\", \"what went wrong\", or \"patterns\" are mentioned.",
                "path": "baselayer/skills/conversation-analysis/SKILL.md",
                "frontmatter": {
                  "name": "conversation-analysis",
                  "version": "2.0.0",
                  "description": "This skill should be used when analyzing conversation patterns, identifying frustration or success signals, or when \"analyze conversation\", \"what went wrong\", or \"patterns\" are mentioned."
                },
                "content": "# Conversation Analysis\n\nSignal extraction  pattern detection  behavioral insights.\n\n<when_to_use>\n\n- User requests conversation analysis\n- Identifying frustration, success, or workflow patterns\n- Extracting user preferences and requirements\n- Understanding task evolution and iterations\n\nNOT for: real-time monitoring, content generation, single message analysis\n\n</when_to_use>\n\n<signal_taxonomy>\n\n| Type | Subtype | Indicators |\n|------|---------|------------|\n| Success | Explicit Praise | \"Perfect!\", \"Exactly what I needed\", exclamation marks |\n| Success | Continuation | \"Now do the same for...\", building on prior work |\n| Success | Adoption | User implements suggestion without modification |\n| Success | Acceptance | \"Looks good\", \"Ship it\", \"Merge this\" |\n| Frustration | Correction | \"No, I meant...\", \"That's wrong\", \"Do X instead\" |\n| Frustration | Reversion | User undoes agent changes, \"Go back\" |\n| Frustration | Repetition | Same request 2+ times, escalating specificity |\n| Frustration | Explicit | \"This isn't working\", \"Why did you...\", accusatory tone |\n| Workflow | Sequence | \"First...\", \"Then...\", \"Finally...\", numbered lists |\n| Workflow | Transition | \"Now that X is done, let's Y\", phase changes |\n| Workflow | Tool Chain | Recurring tool usage patterns (Read  Edit  Bash) |\n| Workflow | Context Switch | Abrupt topic changes, no transition language |\n| Request | Prohibition | \"Don't use X\", \"Never do Y\", \"Avoid Z\" |\n| Request | Requirement | \"Always check...\", \"Make sure to...\", \"You must...\" |\n| Request | Preference | \"I prefer...\", \"It's better to...\", comparative language |\n| Request | Conditional | \"If X then Y\", \"When A, do B\", situational rules |\n\nConfidence levels:\n- High (0.81.0): Explicit keywords match taxonomy, no ambiguity, strong context\n- Medium (0.50.79): Implicit signal, partial context, minor ambiguity\n- Low (0.20.49): Ambiguous language, weak context, borderline classification\n\n</signal_taxonomy>\n\n<phases>\n\nTrack with TodoWrite. Phases advance only, never regress.\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Parse Input | Session start | \"Parsing input\" |\n| Extract Signals | Scope validated | \"Extracting signals\" |\n| Detect Patterns | Signals extracted | \"Detecting patterns\" |\n| Synthesize Report | Patterns detected | \"Synthesizing report\" |\n\nTodoWrite format:\n\n```text\n- Parse Input { scope description }\n- Extract Signals { from N messages }\n- Detect Patterns { category focus }\n- Synthesize Report { output format }\n```\n\nEdge cases:\n- Small scope (<5 messages): Skip Extract Signals, jump to Synthesize\n- Re-analysis: Resume at Detect Patterns\n- Narrow focus (single signal type): Skip Detect Patterns\n\nWorkflow:\n- Start: Create Parse Input `in_progress`\n- Transition: Mark current `completed`, add next `in_progress`\n- After delivery: Mark Synthesize Report `completed`\n\n</phases>\n\n<workflow>\n\n1. Define Scope\n   - Message range (all, recent N, date range)\n   - Actors (user only, agent only, both)\n   - Exclusions (system messages, tool outputs, code blocks)\n   - Mark Parse Input `completed`, create Extract Signals `in_progress`\n\n2. Extract Signals\n   - Scan messages for signal keywords\n   - Match against taxonomy\n   - Assign confidence (high/medium/low)\n   - Record: type, subtype, message_id, timestamp, quote, context\n   - Mark Extract Signals `completed`, create Detect Patterns `in_progress`\n\n3. Detect Patterns\n   - Group signals by type/subtype\n   - Find clusters (3+ related signals)\n   - Identify evolution (signal changes over time)\n   - Track repetition (recurring themes)\n   - Spot correlations (tool chains, workflows)\n   - Mark Detect Patterns `completed`, create Synthesize Report `in_progress`\n\n4. Output\n   - Generate JSON with signals, patterns, summary\n   - Include confidence, recommendations, action items\n   - Append ` Caveats` if gaps exist\n   - Mark Synthesize Report `completed`\n\n</workflow>\n\n<pattern_detection>\n\nBehavioral patterns from signal clusters:\n\n| Pattern | Detection | Confidence |\n|---------|-----------|------------|\n| Repetition | Same signal 3+ times | Strong: 5+ signals |\n| Evolution | Signal type changes over time | Moderate: 3-4 signals |\n| Preferences | Consistent request signals | Strong: across sessions |\n| Tool Chains | Recurring tool sequences (5+ times) | High: frequent use |\n| Problem Areas | Clustered frustration signals | Strong: 3+ in same topic |\n\nTemporal patterns:\n- Escalation: Increasing frustration/stronger requirements\n- De-escalation: Frustration  success transition\n- Cyclical: Same issue recurs across sessions\n\n</pattern_detection>\n\n<output_format>\n\nJSON structure:\n\n```json\n{\n  \"analysis\": {\n    \"scope\": {\n      \"message_count\": N,\n      \"date_range\": \"YYYY-MM-DD to YYYY-MM-DD\",\n      \"actors\": [\"user\", \"agent\"]\n    },\n    \"signals\": [\n      {\n        \"type\": \"success|frustration|workflow|request\",\n        \"subtype\": \"specific_subtype\",\n        \"message_id\": \"msg_123\",\n        \"timestamp\": \"ISO8601\",\n        \"quote\": \"exact text\",\n        \"confidence\": \"high|medium|low\",\n        \"context\": \"brief explanation\"\n      }\n    ],\n    \"patterns\": [\n      {\n        \"pattern_type\": \"repetition|evolution|preference|tool_chain\",\n        \"category\": \"success|frustration|workflow|request\",\n        \"description\": \"pattern summary\",\n        \"occurrences\": N,\n        \"confidence\": \"strong|moderate|weak\",\n        \"first_seen\": \"ISO8601\",\n        \"last_seen\": \"ISO8601\",\n        \"recommendation\": \"actionable next step\"\n      }\n    ],\n    \"summary\": {\n      \"total_signals\": N,\n      \"by_type\": { \"success\": N, \"frustration\": N, ... },\n      \"key_insights\": [\"insight 1\", \"insight 2\"],\n      \"action_items\": [\"item 1\", \"item 2\"]\n    }\n  }\n}\n```\n\n</output_format>\n\n<rules>\n\nALWAYS:\n- Create Parse Input at session start\n- Update todos at phase transitions\n- Include confidence levels for all signals\n- Support patterns with 2+ signals minimum\n- Mark Synthesize Report `completed` after delivery\n- Apply recency weighting (recent overrides old)\n\nNEVER:\n- Skip phase transitions\n- Extract low-confidence signals without marking them\n- Claim patterns from single occurrences\n- Regress phases\n- Deliver without marking final phase complete\n- Over-interpret neutral language\n\n</rules>\n\n<references>\n\n- [signal-patterns.md](references/signal-patterns.md)  extended taxonomy, edge cases\n- [extraction-techniques.md](references/extraction-techniques.md)  regex, heuristics\n- [sample-analysis.md](examples/sample-analysis.md)  complete walkthrough\n\n</references>"
              },
              {
                "name": "debugging-and-diagnosis",
                "description": "This skill should be used when encountering bugs, errors, failing tests, or unexpected behavior. Provides systematic debugging with evidence-based root cause investigation using a four-phase framework.",
                "path": "baselayer/skills/debugging-and-diagnosis/SKILL.md",
                "frontmatter": {
                  "name": "debugging-and-diagnosis",
                  "version": "2.1.0",
                  "description": "This skill should be used when encountering bugs, errors, failing tests, or unexpected behavior. Provides systematic debugging with evidence-based root cause investigation using a four-phase framework."
                },
                "content": "# Systematic Debugging\n\nEvidence-based investigation -> root cause -> verified fix.\n\n<when_to_use>\n\n- Bugs, errors, exceptions, crashes\n- Unexpected behavior or wrong results\n- Failing tests (unit, integration, e2e)\n- Intermittent or timing-dependent failures\n- Performance issues (slow, memory leaks, high CPU)\n- Integration failures (API, database, external services)\n\nNOT for: obvious fixes, feature requests, architecture planning\n\n</when_to_use>\n\n<iron_law>\n\n**NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST**\n\nNever propose solutions or \"try this\" without understanding root cause through systematic investigation.\n\n</iron_law>\n\n<phases>\n\nTrack with TodoWrite. Phases advance forward only.\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Collect Evidence | Session start | \"Collecting evidence\" |\n| Isolate Variables | Evidence gathered | \"Isolating variables\" |\n| Formulate Hypotheses | Problem isolated | \"Formulating hypotheses\" |\n| Test Hypothesis | Hypothesis formed | \"Testing hypothesis\" |\n| Verify Fix | Fix identified | \"Verifying fix\" |\n\n**Situational** (insert when triggered):\n- Iterate -> Hypothesis disproven, loops back with new hypothesis\n\n**Workflow:**\n- Start: \"Collect Evidence\" as `in_progress`\n- Transition: Mark current `completed`, add next `in_progress`\n- Failed hypothesis: Add \"Iterate\" task\n- Quick fixes: If root cause obvious from error, skip to \"Verify Fix\" (still create failing test)\n- Need more evidence: Add new evidence task (don't regress phases)\n- Circuit breaker: After 3 failed hypotheses -> escalate\n\n</phases>\n\n<quick_start>\n\n1. Create \"Collect Evidence\" todo as `in_progress`\n2. Reproduce - exact steps to trigger consistently\n3. Investigate - gather evidence about what's happening\n4. Analyze - compare working vs broken, find differences\n5. Test hypothesis - single specific hypothesis, minimal test\n6. Implement - failing test first, then fix\n7. Update todos on phase transitions\n\n</quick_start>\n\n<phase_1_root_cause>\n\nGoal: Understand what's actually happening.\n\nTransition: Mark complete when you have reproduction steps and initial evidence.\n\n**Read error messages completely**\n- Stack traces top to bottom\n- Note file paths, line numbers, variable names\n- Look for \"caused by\" chains\n\n**Reproduce consistently**\n- Document exact trigger steps\n- Note inputs that cause vs don't cause\n- Check if intermittent (timing, race conditions)\n- Verify in clean environment\n\n**Check recent changes**\n- `git diff` - what changed?\n- `git log --since=\"yesterday\"` - recent commits\n- Dependency updates\n- Config/environment changes\n\n**Gather evidence**\n- Add logging at key points\n- Print variable values at transformations\n- Log function entry/exit with parameters\n- Capture timestamps for timing issues\n\n**Trace data flow backward**\n- Where does bad value come from?\n- Track through transformations\n- Find first place it becomes wrong\n\nRed flags (return to evidence gathering):\n- \"I think maybe X is the problem\"\n- \"Let's try changing Y\"\n- \"It might be related to Z\"\n- Starting to write code before understanding\n\n</phase_1_root_cause>\n\n<phase_2_pattern_analysis>\n\nGoal: Learn from working code to understand broken code.\n\nTransition: Mark complete when key differences identified.\n\n**Find working examples**\n- Search for similar functionality that works\n- `rg \"pattern\"` for similar patterns\n- Look for passing vs failing tests\n- Check git history for when it worked\n\n**Read references completely**\n- Every line, not skimming\n- Full context\n- All dependencies/imports\n- Configuration and setup\n\n**Identify every difference**\n- Line by line working vs broken\n- Different imports?\n- Different function signatures?\n- Different error handling?\n- Different data flow?\n- Different configuration?\n\n**Understand dependencies**\n- Libraries/packages involved\n- Versions in use\n- External services\n- Shared state\n- Assumptions made\n\nQuestions to answer:\n- Why does working version work?\n- What's fundamentally different?\n- Edge cases working version handles?\n- Invariants working version maintains?\n\n</phase_2_pattern_analysis>\n\n<phase_3_hypothesis_testing>\n\nGoal: Test one specific idea with minimal change.\n\nTransition: Mark complete when specific, evidence-based hypothesis formed.\n\n**Form single hypothesis**\n- Template: \"X is root cause because Y\"\n- Must explain all symptoms\n- Must be testable with small change\n- Must be based on evidence from phases 1-2\n\n**Design minimal test**\n- Smallest change to test hypothesis\n- Change ONE variable\n- Preserve everything else\n- Make reversible\n\n**Execute and verify**\n- Apply change\n- Run reproduction steps\n- Observe carefully\n- Document results\n\n**Outcomes:**\n- Fixed: Confirm across all cases, proceed to Verify Fix\n- Not fixed: Mark complete, add \"Iterate\", form NEW hypothesis\n- Partially fixed: Add \"Iterate\" for remaining issues\n- Never: Random variations hoping one works\n\nBad hypotheses (too vague):\n- \"Maybe it's a race condition\"\n- \"Could be caching or permissions\"\n- \"Probably something with the database\"\n\nGood hypotheses (specific, testable):\n- \"Fails because expects number but receives string when API returns empty\"\n- \"Race condition: fetchData() called before initializeClient() completes\"\n- \"Memory leak: event listeners in useEffect never removed in cleanup\"\n\n</phase_3_hypothesis_testing>\n\n<phase_4_implementation>\n\nGoal: Fix root cause permanently with verification.\n\nTransition: Root cause confirmed, ready for permanent fix.\n\n**Create failing test**\n- Write test reproducing bug\n- Verify fails before fix\n- Should pass after fix\n- Captures exact broken scenario\n\n**Implement single fix**\n- Address identified root cause\n- No additional \"improvements\"\n- No refactoring \"while you're there\"\n- Just fix the problem\n\n**Verify fix**\n- Failing test now passes\n- Existing tests still pass\n- Manual reproduction no longer triggers bug\n- No new errors/warnings\n\n**Circuit breaker**\nIf 3+ fixes tried without success: STOP\n- Problem isn't hypothesis - problem is architecture\n- May be using wrong pattern entirely\n- Escalate or redesign\n\n**After fixing:**\n- Mark \"Verify Fix\" completed\n- Add defensive validation\n- Document root cause\n- Consider similar bugs elsewhere\n\n</phase_4_implementation>\n\n<red_flags>\n\nSTOP and return to Phase 1 if you catch yourself:\n\n- \"Quick fix for now, investigate later\"\n- \"Just try changing X and see\"\n- \"I don't fully understand but this might work\"\n- \"One more fix attempt\" (already tried 2+)\n- \"Let me try a few different things\"\n- Proposing solutions before gathering evidence\n- Skipping failing test case\n- Fixing symptoms instead of root cause\n\nALL mean: STOP. Add new \"Collect Evidence\" task.\n\n</red_flags>\n\n<escalation>\n\nWhen to escalate:\n\n1. After 3 failed fix attempts - architecture may be wrong\n2. No clear reproduction - need more context/access\n3. External system issues - need vendor/team involvement\n4. Security implications - need security expertise\n5. Data corruption risks - need backup/recovery planning\n\n</escalation>\n\n<completion>\n\nBefore claiming \"fixed\":\n\n- [ ] Root cause identified with evidence\n- [ ] Failing test case created\n- [ ] Fix addresses root cause only\n- [ ] Test now passes\n- [ ] All existing tests pass\n- [ ] Manual reproduction no longer triggers bug\n- [ ] No new warnings/errors\n- [ ] Root cause documented\n- [ ] Prevention measures considered\n- [ ] \"Verify Fix\" marked completed\n\n**Understanding the bug is more valuable than fixing it quickly.**\n\n</completion>\n\n<rules>\n\nALWAYS:\n- Create \"Collect Evidence\" todo at session start\n- Follow four-phase framework\n- Update todos on phase transitions\n- Create failing test before fix\n- Test single hypothesis at a time\n- Document root cause after fix\n- Mark \"Verify Fix\" complete only after tests pass\n\nNEVER:\n- Propose fixes without understanding root cause\n- Skip evidence gathering\n- Test multiple hypotheses simultaneously\n- Skip failing test case\n- Fix symptoms instead of root cause\n- Continue after 3 failed fixes without escalation\n- Regress phases - add new tasks if needed\n\n</rules>\n\n<references>\n\n- [playbooks.md](references/playbooks.md) - bug-type specific investigations\n- [evidence-patterns.md](references/evidence-patterns.md) - diagnostic techniques\n- [reproduction.md](references/reproduction.md) - reproduction techniques\n- [integration.md](references/integration.md) - workflow integration, anti-patterns\n- [FORMATTING.md](../../shared/rules/FORMATTING.md) - formatting conventions\n\n</references>"
              },
              {
                "name": "hono-dev",
                "description": "This skill should be used when building APIs with Hono, using hc client, implementing OpenAPI, or when \"Hono\", \"RPC\", or \"type-safe API\" are mentioned.",
                "path": "baselayer/skills/hono-dev/SKILL.md",
                "frontmatter": {
                  "name": "hono-dev",
                  "version": "1.0.0",
                  "description": "This skill should be used when building APIs with Hono, using hc client, implementing OpenAPI, or when \"Hono\", \"RPC\", or \"type-safe API\" are mentioned."
                },
                "content": "# Hono API Development\n\nRoute chaining  type-safe RPC  end-to-end types.\n\n<when_to_use>\n\n- Building REST APIs with Hono\n- Type-safe RPC with hono/client\n- OpenAPI documentation with Zod\n- Testing APIs with testClient\n- When user mentions \"Hono\", \"RPC\", or \"OpenAPI\"\n\nNOT for: Bun runtime APIs (use bun-dev), other frameworks (Express, Fastify)\n\n</when_to_use>\n\n<version_notes>\n\nHono v4+ with @hono/zod-openapi v1.0+\nCheck hono.dev for latest patterns.\n\n</version_notes>\n\n## Route Chaining  Critical Pattern\n\nType inference flows through method chain. Break chain = lose types.\n\n<route_chaining>\n\n```typescript\n//  Chained routes preserve types\nconst app = new Hono()\n  .get('/users', (c) => c.json({ users: [] }))\n  .get('/users/:id', (c) => {\n    const id = c.req.param('id'); // Typed!\n    return c.json({ id });\n  })\n  .post('/users', async (c) => {\n    const body = await c.req.json();\n    return c.json({ created: true }, 201);\n  });\n\nexport type AppType = typeof app; // Full route types!\n```\n\n** NEVER break the chain:**\n\n```typescript\nconst app = new Hono();\napp.get('/users', handler1);  // Types LOST!\napp.post('/users', handler2);\n```\n\n**Path parameters**  typed automatically:\n\n```typescript\n.get('/posts/:id/comments/:commentId', (c) => {\n  const { id, commentId } = c.req.param(); // Both string\n  return c.json({ postId: id, commentId });\n})\n```\n\n**Query parameters**  use Zod for validation:\n\n```typescript\nimport { zValidator } from '@hono/zod-validator';\nimport { z } from 'zod';\n\nconst QuerySchema = z.object({\n  page: z.coerce.number().int().positive().default(1),\n  limit: z.coerce.number().int().positive().max(100).default(20),\n});\n\nconst app = new Hono()\n  .get('/search', zValidator('query', QuerySchema), (c) => {\n    const { page, limit } = c.req.valid('query'); // Fully typed!\n    return c.json({ page, limit });\n  });\n```\n\n**Middleware in chain:**\n\n```typescript\nconst app = new Hono()\n  .use('*', logger())\n  .use('/api/*', cors())\n  .get('/api/public', (c) => c.json({ public: true }))\n  .use('/api/admin/*', authMiddleware)\n  .get('/api/admin/users', (c) => c.json({ users: [] }));\n```\n\n</route_chaining>\n\n## Factory Pattern  Context Typing\n\nUse `createFactory<Env>()` to type context variables across middleware and routes.\n\n<factory_pattern>\n\n```typescript\nimport { createFactory } from 'hono/factory';\nimport type { Database } from 'bun:sqlite';\n\ntype Env = {\n  Variables: {\n    user: { id: string; role: 'admin' | 'user' };\n    requestId: string;\n    db: Database;\n  };\n};\n\nconst factory = createFactory<Env>();\n\n// Typed middleware\nconst authMiddleware = factory.createMiddleware(async (c, next) => {\n  const token = c.req.header('authorization')?.replace('Bearer ', '');\n  if (!token) throw new HTTPException(401, { message: 'Unauthorized' });\n\n  const user = await verifyToken(token);\n  c.set('user', user); // Type-checked!\n  await next();\n});\n\n// Typed handlers\nconst getProfile = factory.createHandlers((c) => {\n  const user = c.get('user'); // Typed: { id: string; role: 'admin' | 'user' }\n  return c.json({ user });\n});\n\n// Assemble app\nconst app = factory.createApp()\n  .use('*', dbMiddleware)\n  .use('/api/*', authMiddleware)\n  .get('/api/profile', ...getProfile);\n\nexport type AppType = typeof app;\n```\n\n**Multi-module structure:**\n\n```typescript\n// routes/users.ts\nexport const usersRoute = factory.createApp()\n  .get('/', (c) => c.json({ users: [] }))\n  .post('/', zValidator('json', CreateUserSchema), async (c) => {\n    const data = c.req.valid('json');\n    return c.json({ created: true }, 201);\n  });\n\n// index.ts\nconst app = factory.createApp()\n  .use('*', dbMiddleware)\n  .route('/users', usersRoute)\n  .route('/posts', postsRoute);\n```\n\nSee [factory-pattern.md](references/factory-pattern.md) for advanced patterns.\n\n</factory_pattern>\n\n## Error Handling\n\n<error_handling>\n\n```typescript\nimport { HTTPException } from 'hono/http-exception';\n\n// Throw typed errors\napp.get('/users/:id', async (c) => {\n  const user = await findUser(c.req.param('id'));\n  if (!user) {\n    throw new HTTPException(404, { message: 'User not found' });\n  }\n  return c.json({ user });\n});\n\n// Custom error classes\nclass NotFoundError extends HTTPException {\n  constructor(resource: string) {\n    super(404, { message: `${resource} not found` });\n  }\n}\n\nclass UnauthorizedError extends HTTPException {\n  constructor(message = 'Unauthorized') {\n    super(401, { message });\n  }\n}\n\n// Centralized handler\napp.onError((err, c) => {\n  if (err instanceof HTTPException) {\n    return c.json({ error: err.message }, err.status);\n  }\n  if (err instanceof ZodError) {\n    return c.json({\n      error: 'Validation failed',\n      issues: err.issues.map(i => ({ path: i.path.join('.'), message: i.message }))\n    }, 400);\n  }\n  const isDev = Bun.env.NODE_ENV !== 'production';\n  return c.json({ error: isDev ? err.message : 'Internal server error' }, 500);\n});\n\napp.notFound((c) => c.json({ error: 'Not found', path: c.req.path }, 404));\n```\n\nSee [error-handling.md](references/error-handling.md) for patterns.\n\n</error_handling>\n\n## Zod OpenAPI\n\n<zod_openapi>\n\n```typescript\nimport { createRoute, OpenAPIHono, z } from '@hono/zod-openapi';\nimport { swaggerUI } from '@hono/swagger-ui';\n\nconst UserSchema = z.object({\n  id: z.string().uuid(),\n  email: z.string().email(),\n  name: z.string().min(1).max(100),\n}).openapi('User');\n\nconst route = createRoute({\n  method: 'get',\n  path: '/users/{id}',\n  request: {\n    params: z.object({ id: z.string().uuid() }),\n  },\n  responses: {\n    200: {\n      content: { 'application/json': { schema: UserSchema } },\n      description: 'User found',\n    },\n    404: {\n      content: { 'application/json': { schema: z.object({ error: z.string() }) } },\n      description: 'User not found',\n    },\n  },\n  tags: ['Users'],\n  summary: 'Get user by ID',\n});\n\nconst app = new OpenAPIHono();\n\napp.openapi(route, (c) => {\n  const { id } = c.req.valid('param'); // Typed!\n  const user = db.query('SELECT * FROM users WHERE id = ?').get(id);\n  if (!user) return c.json({ error: 'User not found' }, 404);\n  return c.json(user, 200);\n});\n\n// Swagger UI\napp.get('/docs', swaggerUI({ url: '/openapi.json' }));\napp.doc('/openapi.json', {\n  openapi: '3.1.0',\n  info: { title: 'API', version: '1.0.0' },\n});\n```\n\nSee [zod-openapi.md](references/zod-openapi.md) for complete patterns.\n\n</zod_openapi>\n\n## RPC Client  End-to-End Types\n\n<rpc_client>\n\n```typescript\n// Server\nconst app = new Hono()\n  .get('/posts', (c) => c.json({ posts: [] }))\n  .get('/posts/:id', (c) => c.json({ id: c.req.param('id') }))\n  .post('/posts', zValidator('json', CreatePostSchema), async (c) => {\n    const data = c.req.valid('json');\n    return c.json({ id: '123', ...data }, 201);\n  });\n\nexport type AppType = typeof app;\n\n// Client\nimport { hc } from 'hono/client';\nimport type { AppType } from './server';\n\nconst client = hc<AppType>('http://localhost:3000');\n\n// GET request\nconst res = await client.posts.$get();\nconst data = await res.json(); // Typed: { posts: any[] }\n\n// GET with params\nconst res2 = await client.posts[':id'].$get({ param: { id: '123' } });\n\n// POST request\nconst res3 = await client.posts.$post({\n  json: { title: 'Hello', content: 'World' }\n});\n\n// With headers\nconst res4 = await client.posts.$get({}, {\n  headers: { Authorization: 'Bearer token' }\n});\n```\n\n</rpc_client>\n\n## Testing with testClient\n\n<testing>\n\n```typescript\nimport { describe, expect, test, beforeEach, afterEach } from 'bun:test';\nimport { testClient } from 'hono/testing';\nimport { Database } from 'bun:sqlite';\nimport app from './server';\n\ndescribe('API Tests', () => {\n  let db: Database;\n\n  beforeEach(() => {\n    db = new Database(':memory:');\n    db.run('CREATE TABLE posts (id TEXT PRIMARY KEY, title TEXT, content TEXT)');\n  });\n\n  afterEach(() => {\n    db.close();\n  });\n\n  const client = testClient(app);\n\n  test('GET /posts returns posts', async () => {\n    const res = await client.posts.$get();\n    expect(res.status).toBe(200);\n    const data = await res.json();\n    expect(data).toHaveProperty('posts');\n  });\n\n  test('POST /posts creates post', async () => {\n    const res = await client.posts.$post({\n      json: { title: 'Test', content: 'Content' }\n    });\n    expect(res.status).toBe(201);\n    const data = await res.json();\n    expect(data).toMatchObject({ title: 'Test' });\n  });\n\n  test('Protected route requires auth', async () => {\n    const res = await client.api.profile.$get();\n    expect(res.status).toBe(401);\n  });\n\n  test('Protected route accepts valid token', async () => {\n    const res = await client.api.profile.$get({}, {\n      headers: { Authorization: 'Bearer valid-token' }\n    });\n    expect(res.status).toBe(200);\n  });\n});\n```\n\nSee [testing-patterns.md](examples/testing-patterns.md) for complete patterns.\n\n</testing>\n\n## Middleware Patterns\n\n<middleware>\n\n```typescript\n// Logging\nimport { logger } from 'hono/logger';\napp.use('*', logger());\n\n// CORS\nimport { cors } from 'hono/cors';\napp.use('/api/*', cors({\n  origin: ['http://localhost:3000'],\n  credentials: true,\n}));\n\n// Rate limiting\nconst rateLimiter = factory.createMiddleware(async (c, next) => {\n  const ip = c.req.header('x-forwarded-for') || 'unknown';\n  const key = `rate:${ip}`;\n  const count = await cache.incr(key);\n\n  if (count === 1) await cache.expire(key, 60);\n  if (count > 100) {\n    throw new HTTPException(429, { message: 'Rate limit exceeded' });\n  }\n\n  await next();\n});\n\n// Request ID\nconst requestId = factory.createMiddleware(async (c, next) => {\n  c.set('requestId', crypto.randomUUID());\n  await next();\n  c.res.headers.set('x-request-id', c.get('requestId'));\n});\n```\n\n</middleware>\n\n<rules>\n\n## Rules\n\n**ALWAYS:**\n- Chain routes for type inference  `.get().post().put()`\n- Export `type AppType = typeof app` for RPC client\n- Use `createFactory<Env>()` for typed context variables\n- Validate with Zod schemas via `zValidator`\n- Handle errors with `HTTPException` and centralized `onError`\n- Test with `testClient` for type safety\n\n**NEVER:**\n- Break method chain with variable assignment between routes\n- Use `any` types  let Hono infer or define explicitly\n- Use `JSON.parse(await c.req.text())`  use `c.req.json()` or Zod validator\n- Skip request validation on user input\n- Expose stack traces in production\n\n**When Type Errors Occur:**\n- Check route chaining not broken\n- Verify `export type AppType` matches actual app\n- Ensure middleware uses `createFactory` for context types\n- Check client using correct `param`, `query`, or `json` keys\n\n</rules>\n\n<references>\n\n## References\n\n**Examples:**\n- [typed-routes.md](examples/typed-routes.md)  Complete route chaining examples\n- [testing-patterns.md](examples/testing-patterns.md)  Testing with testClient\n\n**References:**\n- [factory-pattern.md](references/factory-pattern.md)  Context typing with createFactory\n- [zod-openapi.md](references/zod-openapi.md)  OpenAPI integration patterns\n- [error-handling.md](references/error-handling.md)  HTTPException and error patterns\n- [middleware.md](references/middleware.md)  Auth, logging, CORS patterns\n\n**External:**\n- Hono: <https://hono.dev>\n- @hono/zod-openapi: <https://github.com/honojs/middleware/tree/main/packages/zod-openapi>\n\n</references>"
              },
              {
                "name": "pathfinding",
                "description": "This skill should be used when requirements are unclear, brainstorming ideas, or when \"pathfind\", \"brainstorm\", \"figure out\", \"clarify requirements\", or \"work through\" are mentioned.",
                "path": "baselayer/skills/pathfinding/SKILL.md",
                "frontmatter": {
                  "name": "pathfinding",
                  "version": "2.0.0",
                  "description": "This skill should be used when requirements are unclear, brainstorming ideas, or when \"pathfind\", \"brainstorm\", \"figure out\", \"clarify requirements\", or \"work through\" are mentioned."
                },
                "content": "# Pathfinding\n\nAdaptive Q&A  unclear requirements  clear path.\n\n<when_to_use>\n\n- Ambiguous/incomplete requirements\n- Complex features needing exploration\n- Greenfield projects with open questions\n- Collaborative brainstorming or problem solving\n\nNOT for: time-critical bugs, well-defined tasks, obvious questions\n\n</when_to_use>\n\n<confidence>\n\n| Bar | Lvl | % | Name | Action |\n|-----|-----|---|------|--------|\n| `` | 0 | 019 | Prepping | Gather foundational context |\n| `` | 1 | 2039 | Scouting | Ask broad questions |\n| `` | 2 | 4059 | Exploring | Ask focusing questions |\n| `` | 3 | 6074 | Charting | Risky to proceed; gaps remain |\n| `` | 4 | 7589 | Mapped | Viable; push toward 5 |\n| `` | 5 | 90100 | Ready | Deliver |\n\nStart honest. Clear request  level 45. Vague  level 02.\n\nAt level 4: \"Can proceed, but 12 more questions would reach full confidence. Continue or deliver now?\"\n\nBelow level 5: include ` Caveats` section.\n\n</confidence>\n\n<phases>\n\nTrack with TodoWrite. Phases advance only, never regress.\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Prep | level 01 | \"Prepping\" |\n| Explore | level 23 | \"Exploring\" |\n| Clarify | level 4 | \"Clarifying\" |\n| Deliver | level 5 | \"Delivering\" |\n\nTodoWrite format  each phase gets context-specific title:\n\n```text\n- Prep { domain } requirements\n- Explore { approach } options\n- Clarify { key unknowns, 3-4 words }\n- Deliver { artifact type }\n```\n\nSituational (insert before Deliver when triggered):\n- Resolve Conflicts  ` Caution` or ` Hazard` pushback\n- Validate Assumptions  high-risk assumptions before delivery\n\nWorkflow:\n- Start: Create phase matching initial confidence `in_progress`\n- Transition: Mark current `completed`, add next `in_progress`\n- High start (4+): Skip directly to `Clarify` or `Deliver`\n- Early delivery: Skip to `Deliver` + ` Caveats`\n\n</phases>\n\n<gather>\n\nCalibrate first  user may have already provided context (docs, prior conversation, pointed you at files). If enough context exists, skip to level 34. Don't re-ask what's already clear.\n\nIf gaps remain, explore focus areas (pick what's relevant):\n- Purpose: What problem? Why now?\n- Constraints: Time, tech, team, dependencies\n- Success: How will we know it works?\n- Scope: What's in, what's out?\n\nWhen multiple approaches exist:\n- Propose 23 options with trade-offs\n- Lead with recommendation  and reasoning\n- Let user pick, combine, or redirect\n\nPrinciples:\n- YAGNI  cut what's not needed\n- DRY  don't duplicate effort or logic\n- Simplest thing  prefer boring solutions\n\n</gather>\n\n<questions>\n\nUse `EnterPlanMode` for each question  enables keyboard navigation of options.\n\nStructure:\n- Prose above tool: context, reasoning,  recommendation if clear lean\n- Inside tool: options only (concise, scannable)\n\nAt level 0  start with session intent:\n- Quick pulse check vs deep dive?\n- Exploring possibilities or solving a specific problem?\n- What does \"done\" look like?\n\nLevels 14  focus on substance:\n- 24 options per question + \"5. Something else\"\n- Inline `[]` on recommended option + *italicized rationale*\n- User replies: number, modifications, or combos\n\n</questions>\n\n<workflow>\n\nLoop: Answer  Restate  Update Confidence  Next action\n\nAfter each answer emit:\n- Confidence: {BAR} {NAME}\n- Assumptions: { if material }\n- Unknowns: { what we can clarify; note unknowables when relevant }\n- Decisions: { what's locked in }\n- Concerns: { what feels off + why }\n\nNext action by level:\n- 02: Ask clarifying questions\n- 3: Summarize (3 bullets max), fork toward 5\n- 4: Offer choice: refine or proceed\n- 5: Deliver\n\n</workflow>\n\n<issues>\n\nWhen answer reveals a concern mid-stream:\n- Pause before next question\n- Surface with `` + brief description\n- Ask: clarify now, note for later, or proceed with assumption?\n\nExample: \" This assumes the API supports batch operations  clarify now, note for later, or proceed?\"\n\nIf user proceeds despite significant gap  escalate to `pushback` protocol.\n\n</issues>\n\n<pushback>\n\nEscalate when choice conflicts with goals/constraints/best practices:\n\n- ` Alternative`: Minor misalignment. Present option + reasoning.\n- ` Caution`: Clear conflict. Recommend alternative, explain risks, ask to proceed. Triggers Resolve Conflicts.\n- ` Hazard`: High failure risk. Require mitigation or explicit override. Triggers Resolve Conflicts.\n\nOverride: Accept \"Proceed anyway: {REASON}\"  log in next reflection  mark Resolve Conflicts complete.\n\n</pushback>\n\n<skeptic>\n\nIntegrate skeptic agent for complexity sanity checks:\n\n**Recommend** (offer choice):\n- Level 5 reached with  Caveats > 2\n- Red flag language in decisions: \"might need later\", \"more flexible\", \"best practice\"\n\n```text\nBefore finalizing  you have {N} caveats. Want to run skeptic for a sanity check?\n[AskUserQuestion]\n1. Yes, quick check []  I'll challenge complexity interactively\n2. Yes, deep analysis  launch skeptic agent in background\n3. No, proceed  deliver as-is\n```\n\n**Auto-invoke** (no choice):\n- Level 4+ with 3+ unknowns persisting across 2+ question cycles\n-  Hazard escalation triggered during session\n\nWhen auto-invoking:\n\n```text\n[Auto-invoking skeptic  {REASON}]\n```\n\nLaunch with Task tool:\n- subagent_type: \"outfitter:skeptic\"\n- prompt: Include current decisions, unknowns, and caveats\n- run_in_background: false (wait for findings before delivery)\n\nAfter skeptic returns:\n- Present findings to user\n- If verdict is `block`  add Resolve Conflicts phase\n- If verdict is `caution`  offer choice to address or acknowledge\n- If verdict is `proceed`  continue to delivery\n\n</skeptic>\n\n<completion>\n\nLevel 5: Produce artifact immediately (doc, plan, code, outline). If none specified, suggest one.\n\nAfter delivering, ask where to persist (if applicable):\n\n```text\n[EnterPlanMode]\n1. { discovered path } []  { source: `CLAUDE.md` preference | existing directory | convention }\n2. Create issue  { Linear/GitHub/Beads based on project context }\n3. ADR  { if architectural decision }\n4. Don't persist  keep in conversation only\n5. Something else  different location or format\n```\n\nDiscovery order for option 1:\n1. `CLAUDE.md` or project instructions with explicit plan storage preference\n2. Existing `.agents/plans/` directory\n3. Existing `docs/plans/` directory\n4. Fall back to `.agents/plans/` if nothing found\n\nAlways suggest filename based on topic. Match existing conventions if present.\n\nMark Deliver `completed` after artifact is delivered (persistence is optional follow-up).\n\nBelow 5: Append ` Caveats`:\n- Open questions + context\n- Assumed decisions + defaults\n- Known concerns + impact\n- Deferred items + revisit timing\n\n</completion>\n\n<rules>\n\nALWAYS:\n- TodoWrite phase matching initial confidence at start\n- `EnterPlanMode` for each question (keyboard nav)\n- Prose above tool for context +  recommendation\n- One question at a time, wait for response\n- Restate + update confidence before next move\n- Update todos at level 4, level 5 thresholds\n- Apply pushback protocol on conflicts\n- Check skeptic triggers at level 4+ (unknowns, caveats, red flags)\n\nNEVER:\n- Proceed from 03 without clarifying questions\n- Hide uncertainty below level 5\n- Stack questions or bury decisions in paragraphs\n- Put recommendation inside plan tool (keep in prose)\n- Skip reflection after answer\n- Regress phases\n- Ignore skeptic auto-invoke triggers\n\n</rules>\n\n<references>\n\n- [confidence.md](references/confidence.md)  confidence deep dive\n- [questions.md](references/questions.md)  question crafting\n- [examples/](examples/)  session examples\n- [FORMATTING.md](../../shared/`rules/`FORMATTING.md)  formatting conventions\n- skeptic agent (outfitter:skeptic)  complexity sanity checks\n\n</references>"
              },
              {
                "name": "pattern-analysis",
                "description": "This skill should be used when recognizing recurring themes, codifying best practices, extracting reusable workflows, or when \"pattern\", \"recurring\", or \"repeated\" are mentioned.",
                "path": "baselayer/skills/pattern-analysis/SKILL.md",
                "frontmatter": {
                  "name": "pattern-analysis",
                  "version": "1.0.0",
                  "description": "This skill should be used when recognizing recurring themes, codifying best practices, extracting reusable workflows, or when \"pattern\", \"recurring\", or \"repeated\" are mentioned."
                },
                "content": "# Pattern Analysis\n\nIdentify signals  classify patterns  validate with evidence  document for reuse.\n\n<when_to_use>\n\n- Recognizing recurring themes in work or data\n- Codifying best practices from experience\n- Extracting workflows from repeated success\n- Identifying anti-patterns from repeated failures\n- Building decision frameworks from observations\n\nNOT for: single occurrences, unvalidated hunches, premature abstraction\n\n</when_to_use>\n\n<signal_identification>\n\nWatch for these signal categories:\n\n| Category | Watch For | Indicates |\n|----------|-----------|-----------|\n| **Success** | Completion, positive feedback, repetition, efficiency | Pattern worth codifying |\n| **Frustration** | Backtracking, clarification loops, rework, confusion | Anti-pattern to document |\n| **Workflow** | Sequence consistency, decision points, quality gates | Process pattern |\n| **Orchestration** | Multi-component coordination, state management, routing | Coordination pattern |\n\nSee [signal-types.md](references/signal-types.md) for detailed taxonomy.\n\n</signal_identification>\n\n<pattern_classification>\n\nFour primary pattern types:\n\n| Type | Characteristics | Use When |\n|------|-----------------|----------|\n| **Workflow** | Sequential phases, clear transitions, quality gates | Process has ordered steps |\n| **Orchestration** | Coordinates components, manages state, routes work | Multiple actors involved |\n| **Heuristic** | Condition  action mapping, context-sensitive | Repeated decisions |\n| **Anti-Pattern** | Common mistake, causes rework, has better alternative | Preventing failures |\n\nSee [pattern-types.md](references/pattern-types.md) for templates and examples.\n\n</pattern_classification>\n\n<evidence_thresholds>\n\n## Codification Criteria\n\nDon't codify after first occurrence. Require:\n- **3+ instances**  minimum repetition to establish pattern\n- **Multiple contexts**  works across different scenarios\n- **Clear boundaries**  know when to apply vs not apply\n- **Measurable benefit**  improves outcome compared to ad-hoc approach\n\n## Quality Indicators\n\n| Strong Pattern | Weak Pattern |\n|----------------|--------------|\n| Consistent structure | Varies each use |\n| Transferable to others | Requires specific expertise |\n| Handles edge cases | Breaks on deviation |\n| Saves time/effort | Overhead exceeds value |\n\n</evidence_thresholds>\n\n<progressive_formalization>\n\n**Observation** (1-2 instances):\n- Note for future reference\n- \"This worked well, watch for recurrence\"\n\n**Hypothesis** (3+ instances):\n- Draft informal guideline\n- Test consciously in next case\n\n**Codification** (validated pattern):\n- Create formal documentation\n- Include examples and constraints\n\n**Refinement** (ongoing):\n- Update based on usage\n- Add edge cases\n\n</progressive_formalization>\n\n<workflow>\n\nLoop: Observe  Classify  Validate  Document\n\n1. **Collect signals**  note successes, failures, recurring behaviors\n2. **Classify pattern type**  workflow, orchestration, heuristic, anti-pattern\n3. **Check evidence threshold**  3+ instances? Multiple contexts?\n4. **Extract quality criteria**  what makes it work?\n5. **Document pattern**  name, when, what, why\n6. **Test deliberately**  apply consciously, track variance\n7. **Refine**  adjust based on feedback\n\n</workflow>\n\n<rules>\n\nALWAYS:\n- Require 3+ instances before codifying\n- Validate across multiple contexts\n- Document both when to use AND when not to\n- Include concrete examples\n- Track pattern effectiveness over time\n\nNEVER:\n- Codify after single occurrence\n- Abstract without evidence\n- Ignore context-sensitivity\n- Skip validation step\n- Assume transferability without testing\n\n</rules>\n\n<references>\n\n**Deep-dive documentation**:\n- [signal-types.md](references/signal-types.md)  detailed signal taxonomy\n- [pattern-types.md](references/pattern-types.md)  pattern templates and examples\n\n**Related skills**:\n- [patternify](../patternify/SKILL.md)  pattern discovery from conversations\n- [codebase-analysis](../codebase-analysis/SKILL.md)  uses pattern analysis for code investigation\n- [report-findings](../report-findings/SKILL.md)  presenting discovered patterns\n\n</references>"
              },
              {
                "name": "patternify",
                "description": "This skill should be used when capturing reusable workflows from conversations, codifying decision heuristics, or when \"patternify\", \"capture\", or \"codify workflow\" are mentioned.",
                "path": "baselayer/skills/patternify/SKILL.md",
                "frontmatter": {
                  "name": "patternify",
                  "version": "1.1.0",
                  "description": "This skill should be used when capturing reusable workflows from conversations, codifying decision heuristics, or when \"patternify\", \"capture\", or \"codify workflow\" are mentioned."
                },
                "content": "# Patternify\n\nConversation analysis  reusable pattern  correct component.\n\n<when_to_use>\n\n- Spotting repeated behavior worth codifying\n- User explicitly wants to capture a workflow\n- Recognizing orchestration sequences in conversation\n- Identifying decision heuristics being applied\n\nNOT for: one-off tasks, simple questions, well-documented existing patterns\n\n</when_to_use>\n\n<pattern_types>\n\n| Type | Purpose | Example |\n|------|---------|---------|\n| Workflow | Multi-step sequences | Debug  Test  Fix  Verify |\n| Orchestration | Tool coordination | Git + Linear + PR automation |\n| Heuristic | Decision rules | \"When X, do Y because Z\" |\n\nWorkflows: Step-by-step processes with defined phases and transitions.\nOrchestration: Tool combinations that work together for a goal.\nHeuristics: Conditional logic and decision trees for common situations.\n\n</pattern_types>\n\n<component_mapping>\n\nMatch pattern type to implementation:\n\n```text\nIs it a multi-step process with phases?\n Yes  Does it need tool restrictions?\n         Yes  Skill (with allowed_tools)\n         No  Skill\n No  Is it a simple entry point?\n          Yes  Command (thin wrapper  Skill)\n          No  Is it autonomous/long-running?\n                   Yes  Agent\n                   No  Is it reactive to events?\n                            Yes  Hook\n                            No  Probably doesn't need codifying\n```\n\nComposites:\n- Skill + Command: Skill holds logic, command provides entry point\n- Skill + Hook: Skill holds logic, hook triggers automatically\n- Agent + Skill: Agent orchestrates, skill provides methodology\n\n</component_mapping>\n\n<specification>\n\nPattern spec format (YAML):\n\n```yaml\nname: pattern-name\ntype: workflow | orchestration | heuristic\ntrigger: when to apply\nphases:  # workflow\n  - name: phase-name\n    actions: [...]\n    exit_criteria: condition\ntools:   # orchestration\n  - tool: name\n    role: purpose\n    sequence: order\nrules:   # heuristic\n  - condition: when\n    action: what\n    rationale: why\nquality:\n  specific: true | false\n  repeatable: true | false\n  valuable: true | false\n  documented: true | false\n  scoped: true | false\n```\n\nAll five quality checks must pass before codifying.\n\n</specification>\n\n<workflow>\n\n1. Identify: Spot repeatable behavior in conversation\n   - For deep analysis, load [codebase-analysis](../codebase-analysis/SKILL.md) skill and use [pattern-analysis](../pattern-analysis/SKILL.md) techniques\n   - Extract success, frustration, workflow, and request signals\n   - Look for 3+ occurrences of similar behavior\n2. Classify: Workflow, Orchestration, or Heuristic?\n3. Map: Which component(s) should implement it?\n4. Specify: Document with pattern spec format\n5. Quality: Validate against SRVDS criteria\n6. Implement: Create the component(s)\n\nTodoWrite phases:\n\n```text\n- Identify { pattern description }\n- Classify { pattern type }\n- Map { component decision }\n- Specify { pattern name }\n- Implement { component type }\n```\n\n</workflow>\n\n<quality>\n\nSRVDS criteria  all must pass:\n\n| Check | Question | Red Flag |\n|-------|----------|----------|\n| Specific | Clear trigger + scope? | \"Sometimes useful\" |\n| Repeatable | Works across contexts? | One-off solution |\n| Valuable | Worth the overhead? | Saves < 5 minutes |\n| Documented | Can others understand? | Tribal knowledge |\n| Scoped | Single responsibility? | Kitchen sink |\n\nSkip if: < 3 occurrences, context-dependent, simpler inline\n\n</quality>\n\n<anti_patterns>\n\n- Premature abstraction: Codifying after first occurrence\n- Over-specification: 50-line spec for 5-line pattern\n- Wrong component: Hook when Skill needed, Agent when Command suffices\n- Missing trigger: Pattern exists but no clear activation\n- Scope creep: Pattern grows to handle edge cases\n\n</anti_patterns>\n\n<rules>\n\nALWAYS:\n- Identify pattern type before choosing component\n- Validate all SRVDS criteria\n- Start with minimal implementation\n- Document trigger conditions clearly\n- Test pattern in at least 2 contexts\n\nNEVER:\n- Codify after single occurrence\n- Create Agent when Skill suffices\n- Skip quality validation\n- Implement without clear trigger\n- Add \"might need later\" features\n\n</rules>\n\n<references>\n\n- [codebase-analysis](../codebase-analysis/SKILL.md)  core investigation methodology\n- [pattern-analysis](../pattern-analysis/SKILL.md)  signal extraction techniques\n- [pattern-types.md](references/pattern-types.md)  extended examples by type\n- [component-mapping.md](references/component-mapping.md)  decision tree details\n- [examples/](examples/)  captured pattern examples\n\n</references>"
              },
              {
                "name": "performance-engineering",
                "description": "This skill should be used when profiling code, optimizing bottlenecks, benchmarking, or when \"performance\", \"profiling\", \"optimization\", or \"--perf\" are mentioned.",
                "path": "baselayer/skills/performance-engineering/SKILL.md",
                "frontmatter": {
                  "name": "performance-engineering",
                  "version": "1.0.0",
                  "description": "This skill should be used when profiling code, optimizing bottlenecks, benchmarking, or when \"performance\", \"profiling\", \"optimization\", or \"--perf\" are mentioned."
                },
                "content": "# Performance Engineering\n\nEvidence-based performance optimization  measure  profile  optimize  validate.\n\n<when_to_use>\n\n- Profiling slow code paths or bottlenecks\n- Identifying memory leaks or excessive allocations\n- Optimizing latency-critical operations (P95, P99)\n- Benchmarking competing implementations\n- Database query optimization\n- Reducing CPU usage in hot paths\n- Improving throughput (RPS, ops/sec)\n\nNOT for: premature optimization, optimization without measurement, guessing at bottlenecks\n\n</when_to_use>\n\n<iron_law>\n\nNO OPTIMIZATION WITHOUT MEASUREMENT\n\n**Required workflow:**\n1. Measure baseline performance with realistic workload\n2. Profile to identify actual bottleneck\n3. Optimize the bottleneck (not what you think is slow)\n4. Measure again to verify improvement\n5. Document gains and tradeoffs\n\nOptimizing unmeasured code wastes time and introduces bugs.\n\n</iron_law>\n\n<phases>\n\nUse TodoWrite to track optimization process:\n\n**Phase 1: Establishing baseline**\n- content: \"Establish performance baseline with realistic workload\"\n- activeForm: \"Establishing performance baseline\"\n\n**Phase 2: Profiling bottlenecks**\n- content: \"Profile code to identify actual bottlenecks\"\n- activeForm: \"Profiling code to identify bottlenecks\"\n\n**Phase 3: Analyzing root cause**\n- content: \"Analyze profiling data to determine root cause\"\n- activeForm: \"Analyzing profiling data\"\n\n**Phase 4: Implementing optimization**\n- content: \"Implement targeted optimization for identified bottleneck\"\n- activeForm: \"Implementing optimization\"\n\n**Phase 5: Validating improvement**\n- content: \"Measure performance gains and verify no regressions\"\n- activeForm: \"Validating performance improvement\"\n\n</phases>\n\n<metrics>\n\n## Key Performance Indicators\n\n**Latency (response time):**\n- P50 (median)  typical case\n- P95  most users\n- P99  tail latency\n- P99.9  outliers\n- TTFB  time to first byte\n- TTLB  time to last byte\n\n**Throughput:**\n- RPS  requests per second\n- ops/sec  operations per second\n- bytes/sec  data transfer rate\n- queries/sec  database throughput\n\n**Memory:**\n- Heap usage  allocated memory\n- GC frequency  garbage collection pauses\n- GC duration  stop-the-world time\n- Allocation rate  memory churn\n- Resident set size (RSS)  total memory\n\n**CPU:**\n- CPU time  total compute\n- Wall time  elapsed time\n- Hot paths  frequently executed code\n- Time complexity  algorithmic efficiency\n- CPU utilization  percentage used\n\n**Always measure:**\n- Before optimization (baseline)\n- After optimization (improvement)\n- Under realistic load (not toy data)\n- Multiple runs (account for variance)\n\n</metrics>\n\n<profiling_tools>\n\n## TypeScript/Bun\n\n**Built-in timing:**\n\n```typescript\nconsole.time('operation')\n// ... code to measure\nconsole.timeEnd('operation')\n\n// High precision\nconst start = Bun.nanoseconds()\n// ... code to measure\nconst elapsed = Bun.nanoseconds() - start\nconsole.log(`Took ${elapsed / 1_000_000}ms`)\n```\n\n**Performance API:**\n\n```typescript\nconst mark1 = performance.mark('start')\n// ... code to measure\nconst mark2 = performance.mark('end')\nperformance.measure('operation', 'start', 'end')\nconst measure = performance.getEntriesByName('operation')[0]\nconsole.log(`Duration: ${measure.duration}ms`)\n```\n\n**Memory profiling:**\n- Chrome DevTools  Memory tab  heap snapshots\n- Node.js `--inspect` flag + Chrome DevTools\n- `process.memoryUsage()` for RSS/heap tracking\n\n**CPU profiling:**\n- Chrome DevTools  Performance tab  record session\n- Node.js `--prof` flag + `node --prof-process`\n- Flamegraphs for visualization\n\n## Rust\n\n**Benchmarking:**\n\n```rust\n#[cfg(test)]\nmod benches {\n    use criterion::{black_box, criterion_group, criterion_main, Criterion};\n\n    fn benchmark_function(c: &mut Criterion) {\n        c.bench_function(\"my_function\", |b| {\n            b.iter(|| my_function(black_box(42)))\n        });\n    }\n\n    criterion_group!(benches, benchmark_function);\n    criterion_main!(benches);\n}\n```\n\n**Profiling:**\n- `cargo bench`  criterion benchmarks\n- `perf record` + `perf report`  Linux profiling\n- `cargo flamegraph`  visual flamegraphs\n- `cargo bloat`  binary size analysis\n- `valgrind --tool=callgrind`  detailed profiling\n- `heaptrack`  memory profiling\n\n**Instrumentation:**\n\n```rust\nuse std::time::Instant;\n\nlet start = Instant::now();\n// ... code to measure\nlet duration = start.elapsed();\nprintln!(\"Took: {:?}\", duration);\n```\n\n</profiling_tools>\n\n<optimization_patterns>\n\n## Algorithm Improvements\n\n**Time complexity:**\n- O(n)  O(n log n)  sorting, searching\n- O(n)  O(log n)  binary search, trees\n- O(n)  O(1)  hash maps, memoization\n\n**Space-time tradeoffs:**\n- Cache computed results (memoization)\n- Precompute expensive operations\n- Index data for faster lookup\n- Use hash maps for O(1) access\n\n## Memory Optimization\n\n**Reduce allocations:**\n\n```typescript\n// Bad: creates new array each iteration\nfor (const item of items) {\n  const results = []\n  results.push(process(item))\n}\n\n// Good: reuse array\nconst results = []\nfor (const item of items) {\n  results.push(process(item))\n}\n```\n\n```rust\n// Bad: allocates String every time\nfn format_user(name: &str) -> String {\n    format!(\"User: {}\", name)\n}\n\n// Good: reuses buffer\nfn format_user(name: &str, buf: &mut String) {\n    buf.clear();\n    buf.push_str(\"User: \");\n    buf.push_str(name);\n}\n```\n\n**Memory pooling:**\n- Reuse expensive objects (connections, buffers)\n- Object pools for frequently allocated types\n- Arena allocators for batch allocations\n\n**Lazy evaluation:**\n- Compute only when needed\n- Stream processing vs loading all data\n- Iterators over materialized collections\n\n## I/O Optimization\n\n**Batching:**\n- Batch API calls (1 request vs 100)\n- Batch database writes (bulk insert)\n- Batch file operations (single write vs many)\n\n**Caching:**\n- Cache expensive computations\n- Cache database queries (Redis, in-memory)\n- Cache API responses (HTTP caching)\n- Invalidate stale cache entries\n\n**Async I/O:**\n- Non-blocking operations (async/await)\n- Concurrent requests (Promise.all, tokio::spawn)\n- Connection pooling (reuse connections)\n\n## Database Optimization\n\n**Query optimization:**\n- Add indexes for common queries\n- Use EXPLAIN/EXPLAIN ANALYZE\n- Avoid N+1 queries (use joins or batch loading)\n- Select only needed columns\n- Filter at database level (WHERE vs client filter)\n\n**Schema design:**\n- Normalize to reduce duplication\n- Denormalize for read-heavy workloads\n- Partition large tables\n- Use appropriate data types\n\n**Connection management:**\n- Connection pooling (don't create per request)\n- Prepared statements (avoid SQL parsing)\n- Transaction batching (reduce round trips)\n\n</optimization_patterns>\n\n<workflow>\n\nLoop: Measure  Profile  Analyze  Optimize  Validate\n\n1. **Define performance goal**  target metric (e.g., P95 < 100ms)\n2. **Establish baseline**  measure current performance under realistic load\n3. **Profile systematically**  identify actual bottleneck (not guesses)\n4. **Analyze root cause**  understand why code is slow\n5. **Design optimization**  plan targeted improvement\n6. **Implement optimization**  make focused change\n7. **Measure improvement**  verify gains, check for regressions\n8. **Document results**  record baseline, optimization, gains, tradeoffs\n\nAt each step:\n- Document measurements with methodology\n- Note profiling tool output\n- Track optimization attempts (what worked/failed)\n- Update performance documentation\n\n</workflow>\n\n<validation>\n\nBefore declaring optimization complete:\n\n**Check gains:**\n-  Measured improvement meets target?\n-  Improvement statistically significant?\n-  Tested under realistic load?\n-  Multiple runs confirm consistency?\n\n**Check regressions:**\n-  No degradation in other metrics?\n-  Memory usage still acceptable?\n-  Code complexity still manageable?\n-  Tests still pass?\n\n**Check documentation:**\n-  Baseline measurements recorded?\n-  Optimization approach explained?\n-  Gains quantified with numbers?\n-  Tradeoffs documented?\n\n</validation>\n\n<rules>\n\nALWAYS:\n- Measure before optimizing (baseline)\n- Profile to find actual bottleneck\n- Use realistic workload (not toy data)\n- Measure multiple runs (account for variance)\n- Document baseline and improvements\n- Check for regressions in other metrics\n- Consider readability vs performance tradeoff\n- Verify statistical significance\n\nNEVER:\n- Optimize without measuring first\n- Guess at bottleneck without profiling\n- Benchmark with unrealistic data\n- Trust single-run measurements\n- Skip documentation of results\n- Sacrifice correctness for speed\n- Optimize without clear performance goal\n- Ignore algorithmic improvements\n\n</rules>\n\n<references>\n\nMethodology:\n- [benchmarking.md](references/benchmarking.md)  rigorous benchmarking methodology\n\nRelated skills:\n- codebase-analysis  evidence-based investigation (foundation)\n- debugging-and-diagnosis  structured bug investigation\n- typescript-dev  correctness before performance\n\n</references>"
              },
              {
                "name": "react-dev",
                "description": "This skill should be used when building React components with TypeScript, typing hooks, handling events, or when React TypeScript, React 19, Server Components are mentioned. Covers type-safe patterns for React 18-19 including generic components, proper event typing, and TanStack Router integration.",
                "path": "baselayer/skills/react-dev/SKILL.md",
                "frontmatter": {
                  "name": "react-dev",
                  "version": "1.0.0",
                  "description": "This skill should be used when building React components with TypeScript, typing hooks, handling events, or when React TypeScript, React 19, Server Components are mentioned. Covers type-safe patterns for React 18-19 including generic components, proper event typing, and TanStack Router integration."
                },
                "content": "# React TypeScript\n\nType-safe React = compile-time guarantees = confident refactoring.\n\n<when_to_use>\n\n- Building typed React components\n- Implementing generic components\n- Typing event handlers, forms, refs\n- Using React 19 features (Actions, Server Components, use())\n- TanStack Router integration\n- Custom hooks with proper typing\n\nNOT for: non-React TypeScript, vanilla JS React\n\n</when_to_use>\n\n<react_19_changes>\n\nReact 19 breaking changes require migration. Key patterns:\n\n**ref as prop** - forwardRef deprecated:\n\n```typescript\n// React 19 - ref as regular prop\ntype ButtonProps = {\n  ref?: React.Ref<HTMLButtonElement>;\n} & React.ComponentPropsWithoutRef<'button'>;\n\nfunction Button({ ref, children, ...props }: ButtonProps) {\n  return <button ref={ref} {...props}>{children}</button>;\n}\n```\n\n**useActionState** - replaces useFormState:\n\n```typescript\nimport { useActionState } from 'react';\n\ntype FormState = { errors?: string[]; success?: boolean };\n\nfunction Form() {\n  const [state, formAction, isPending] = useActionState(submitAction, {});\n  return <form action={formAction}>...</form>;\n}\n```\n\n**use()** - unwraps promises/context:\n\n```typescript\nfunction UserProfile({ userPromise }: { userPromise: Promise<User> }) {\n  const user = use(userPromise); // Suspends until resolved\n  return <div>{user.name}</div>;\n}\n```\n\nSee [react-19-patterns.md](references/react-19-patterns.md) for useOptimistic, useTransition, migration checklist.\n\n</react_19_changes>\n\n<component_patterns>\n\n**Props** - extend native elements:\n\n```typescript\ntype ButtonProps = {\n  variant: 'primary' | 'secondary';\n} & React.ComponentPropsWithoutRef<'button'>;\n\nfunction Button({ variant, children, ...props }: ButtonProps) {\n  return <button className={variant} {...props}>{children}</button>;\n}\n```\n\n**Children typing**:\n\n```typescript\ntype Props = {\n  children: React.ReactNode;          // Anything renderable\n  icon: React.ReactElement;           // Single element\n  render: (data: T) => React.ReactNode;  // Render prop\n};\n```\n\n**Discriminated unions** for variant props:\n\n```typescript\ntype ButtonProps =\n  | { variant: 'link'; href: string }\n  | { variant: 'button'; onClick: () => void };\n\nfunction Button(props: ButtonProps) {\n  if (props.variant === 'link') {\n    return <a href={props.href}>Link</a>;\n  }\n  return <button onClick={props.onClick}>Button</button>;\n}\n```\n\n</component_patterns>\n\n<event_handlers>\n\nUse specific event types for accurate target typing:\n\n```typescript\n// Mouse\nfunction handleClick(e: React.MouseEvent<HTMLButtonElement>) {\n  e.currentTarget.disabled = true;\n}\n\n// Form\nfunction handleSubmit(e: React.FormEvent<HTMLFormElement>) {\n  e.preventDefault();\n  const formData = new FormData(e.currentTarget);\n}\n\n// Input\nfunction handleChange(e: React.ChangeEvent<HTMLInputElement>) {\n  console.log(e.target.value);\n}\n\n// Keyboard\nfunction handleKeyDown(e: React.KeyboardEvent<HTMLInputElement>) {\n  if (e.key === 'Enter') e.currentTarget.blur();\n}\n```\n\nSee [event-handlers.md](references/event-handlers.md) for focus, drag, clipboard, touch, wheel events.\n\n</event_handlers>\n\n<hooks_typing>\n\n**useState** - explicit for unions/null:\n\n```typescript\nconst [user, setUser] = useState<User | null>(null);\nconst [status, setStatus] = useState<'idle' | 'loading'>('idle');\n```\n\n**useRef** - null for DOM, value for mutable:\n\n```typescript\nconst inputRef = useRef<HTMLInputElement>(null);  // DOM - use ?.\nconst countRef = useRef<number>(0);               // Mutable - direct access\n```\n\n**useReducer** - discriminated unions for actions:\n\n```typescript\ntype Action =\n  | { type: 'increment' }\n  | { type: 'set'; payload: number };\n\nfunction reducer(state: State, action: Action): State {\n  switch (action.type) {\n    case 'set': return { ...state, count: action.payload };\n    default: return state;\n  }\n}\n```\n\n**Custom hooks** - tuple returns with as const:\n\n```typescript\nfunction useToggle(initial = false) {\n  const [value, setValue] = useState(initial);\n  const toggle = () => setValue(v => !v);\n  return [value, toggle] as const;\n}\n```\n\n**useContext** - null guard pattern:\n\n```typescript\nconst UserContext = createContext<User | null>(null);\n\nfunction useUser() {\n  const user = useContext(UserContext);\n  if (!user) throw new Error('useUser outside UserProvider');\n  return user;\n}\n```\n\nSee [hooks.md](references/hooks.md) for useCallback, useMemo, useImperativeHandle, useSyncExternalStore.\n\n</hooks_typing>\n\n<generic_components>\n\nGeneric components infer types from props - no manual annotations at call site.\n\n**Pattern** - keyof T for column keys, render props for custom rendering:\n\n```typescript\ntype Column<T> = {\n  key: keyof T;\n  header: string;\n  render?: (value: T[keyof T], item: T) => React.ReactNode;\n};\n\ntype TableProps<T> = {\n  data: T[];\n  columns: Column<T>[];\n  keyExtractor: (item: T) => string | number;\n};\n\nfunction Table<T>({ data, columns, keyExtractor }: TableProps<T>) {\n  return (\n    <table>\n      <thead>\n        <tr>{columns.map(col => <th key={String(col.key)}>{col.header}</th>)}</tr>\n      </thead>\n      <tbody>\n        {data.map(item => (\n          <tr key={keyExtractor(item)}>\n            {columns.map(col => (\n              <td key={String(col.key)}>\n                {col.render ? col.render(item[col.key], item) : String(item[col.key])}\n              </td>\n            ))}\n          </tr>\n        ))}\n      </tbody>\n    </table>\n  );\n}\n```\n\n**Constrained generics** for required properties:\n\n```typescript\ntype HasId = { id: string | number };\n\nfunction List<T extends HasId>({ items }: { items: T[] }) {\n  return <ul>{items.map(item => <li key={item.id}>...</li>)}</ul>;\n}\n```\n\nSee [generic-components.md](examples/generic-components.md) for Select, List, Modal, FormField patterns.\n\n</generic_components>\n\n<server_components>\n\nReact 19 Server Components run on server, can be async.\n\n**Async data fetching**:\n\n```typescript\nexport default async function UserPage({ params }: { params: { id: string } }) {\n  const user = await fetchUser(params.id);\n  return <div>{user.name}</div>;\n}\n```\n\n**Server Actions** - 'use server' for mutations:\n\n```typescript\n'use server';\n\nexport async function updateUser(userId: string, formData: FormData) {\n  await db.user.update({ where: { id: userId }, data: { ... } });\n  revalidatePath(`/users/${userId}`);\n}\n```\n\n**Client + Server Action**:\n\n```typescript\n'use client';\n\nimport { useActionState } from 'react';\nimport { updateUser } from '@/actions/user';\n\nfunction UserForm({ userId }: { userId: string }) {\n  const [state, formAction, isPending] = useActionState(\n    (prev, formData) => updateUser(userId, formData), {}\n  );\n  return <form action={formAction}>...</form>;\n}\n```\n\n**use() for promise handoff**:\n\n```typescript\n// Server: pass promise without await\nasync function Page() {\n  const userPromise = fetchUser('123');\n  return <UserProfile userPromise={userPromise} />;\n}\n\n// Client: unwrap with use()\n'use client';\nfunction UserProfile({ userPromise }: { userPromise: Promise<User> }) {\n  const user = use(userPromise);\n  return <div>{user.name}</div>;\n}\n```\n\nSee [server-components.md](examples/server-components.md) for parallel fetching, streaming, error boundaries.\n\n</server_components>\n\n<tanstack_integration>\n\nTanStack Router = type-safe routes, params, search params, loader data.\n\n**Route with Zod validation**:\n\n```typescript\nimport { createRoute } from '@tanstack/react-router';\nimport { z } from 'zod';\n\nconst userRoute = createRoute({\n  path: '/users/$userId',\n  component: UserPage,\n  loader: async ({ params }) => ({ user: await fetchUser(params.userId) }),\n  validateSearch: z.object({\n    tab: z.enum(['profile', 'settings']).optional(),\n    page: z.number().int().positive().default(1),\n  }),\n});\n```\n\n**Typed hooks**:\n\n```typescript\nfunction UserPage() {\n  const { user } = useLoaderData({ from: userRoute.id });\n  const { tab, page } = useSearch({ from: userRoute.id });\n  const { userId } = useParams({ from: userRoute.id });\n}\n```\n\n**Type-safe navigation**:\n\n```typescript\nnavigate({\n  to: '/users/$userId',\n  params: { userId },\n  search: { tab: 'profile' },  // Type-checked\n});\n```\n\nSee [tanstack-router.md](references/tanstack-router.md) for nested routes, beforeLoad, error handling, React Query integration.\n\n</tanstack_integration>\n\n<rules>\n\nALWAYS:\n- Specific event types (MouseEvent, ChangeEvent, etc)\n- Explicit useState for unions/null\n- ComponentPropsWithoutRef for native element extension\n- Discriminated unions for variant props\n- as const for tuple returns\n- ref as prop in React 19 (no forwardRef)\n- useActionState for form actions\n- Zod validation for TanStack Router search params\n\nNEVER:\n- any for event handlers\n- JSX.Element for children (use ReactNode)\n- forwardRef in React 19+\n- useFormState (deprecated)\n- Forget null handling for DOM refs\n- Mix Server/Client components in same file\n- Await promises when passing to use()\n\n</rules>\n\n<references>\n\n- [hooks.md](references/hooks.md) - useState, useRef, useReducer, useContext, custom hooks\n- [event-handlers.md](references/event-handlers.md) - all event types, generic handlers\n- [react-19-patterns.md](references/react-19-patterns.md) - useActionState, use(), useOptimistic, migration\n- [generic-components.md](examples/generic-components.md) - Table, Select, List, Modal patterns\n- [server-components.md](examples/server-components.md) - async components, Server Actions, streaming\n- [tanstack-router.md](references/tanstack-router.md) - typed routes, search params, navigation\n\n</references>"
              },
              {
                "name": "report-findings",
                "description": "This skill should be used when synthesizing multi-source research, presenting findings with attribution, or when \"report\", \"findings\", or \"synthesis\" are mentioned.",
                "path": "baselayer/skills/report-findings/SKILL.md",
                "frontmatter": {
                  "name": "report-findings",
                  "version": "1.0.0",
                  "description": "This skill should be used when synthesizing multi-source research, presenting findings with attribution, or when \"report\", \"findings\", or \"synthesis\" are mentioned."
                },
                "content": "# Report Findings\n\nMulti-source gathering  authority assessment  cross-reference  synthesize  present with confidence.\n\n<when_to_use>\n\n- Synthesizing research from multiple sources\n- Presenting findings with proper attribution\n- Comparing options with structured analysis\n- Assessing source credibility\n- Documenting research conclusions\n\nNOT for: single-source summaries, opinion without evidence, rushing to conclusions\n\n</when_to_use>\n\n<source_authority>\n\n| Tier | Confidence | Types | Use For |\n|------|------------|-------|---------|\n| **1: Primary** | 90-100% | Official docs, original research, direct observation | Factual claims, guarantees |\n| **2: Secondary** | 70-90% | Expert analysis, established publications, official guides | Best practices, patterns |\n| **3: Community** | 50-70% | Q&A sites, blogs, wikis, anecdotal evidence | Workarounds, pitfalls |\n| **4: Unverified** | 0-50% | Unattributed, outdated, content farms, unchecked AI | Initial leads only |\n\nSee [source-tiers.md](references/source-tiers.md) for detailed assessment criteria.\n\n</source_authority>\n\n<cross_referencing>\n\n## Two-Source Minimum\n\nNever rely on single source for critical claims:\n1. Find claim in initial source\n2. Seek confirmation in independent source\n3. If sources conflict  investigate further\n4. If sources agree  moderate confidence\n5. If 3+ sources agree  high confidence\n\n## Conflict Resolution\n\nWhen sources disagree:\n1. **Check dates**  newer information often supersedes\n2. **Compare authority**  higher tier beats lower tier\n3. **Verify context**  might both be right in different scenarios\n4. **Test empirically**  verify through direct observation if possible\n5. **Document uncertainty**  flag if unresolved\n\n## Triangulation\n\nFor complex questions, seek alignment across:\n- **Official sources**  what should happen\n- **Direct evidence**  what actually happens\n- **Community reports**  what people experience\n\nAll three align  high confidence. Mismatches  investigate the gap.\n\n</cross_referencing>\n\n<comparison_analysis>\n\nThree comparison methods:\n\n| Method | When to Use |\n|--------|-------------|\n| **Feature Matrix** | Side-by-side capability comparison |\n| **Trade-off Analysis** | Strengths/weaknesses/use cases per option |\n| **Weighted Matrix** | Quantitative scoring with importance weights |\n\nSee [comparison-methods.md](references/comparison-methods.md) for templates and examples.\n\n</comparison_analysis>\n\n<synthesis_techniques>\n\n## Extract Themes\n\nAcross sources, identify:\n- **Consensus**  what everyone agrees on\n- **Disagreements**  where opinions differ\n- **Edge cases**  nuanced situations\n\n## Present Findings\n\n1. **Main answer**  clear, actionable\n2. **Supporting evidence**  cite 2-3 strongest sources\n3. **Caveats**  limitations, context-specific notes\n4. **Alternatives**  other valid approaches\n\n</synthesis_techniques>\n\n<confidence_calibration>\n\n| Level | Indicator | Criteria |\n|-------|-----------|----------|\n| **High** | 90-100% | 3+ tier-1 sources agree, empirically verified |\n| **Moderate** | 60-89% | 2 tier-2 sources agree, some empirical support |\n| **Low** | Below 60% | Single source or tier-3 only, unverified |\n\nFlag remaining uncertainties even at high confidence.\n\n</confidence_calibration>\n\n<output_format>\n\nStandard report structure:\n\n```markdown\n## Summary\n{ 1-2 sentence answer }\n\n## Key Findings\n1. {FINDING}  evidence: {SOURCE}\n\n## Comparison (if applicable)\n{ matrix or trade-off analysis }\n\n## Confidence Assessment\nOverall: {LEVEL} {PERCENTAGE}%\n\n## Sources\n- [Source](url)  tier {N}\n\n## Caveats\n{ uncertainties, gaps, assumptions }\n```\n\nSee [output-template.md](references/output-template.md) for full template with guidelines.\n\n</output_format>\n\n<rules>\n\nALWAYS:\n- Assess source authority before citing\n- Cross-reference critical claims (2+ sources)\n- Include confidence levels with findings\n- Cite sources with proper attribution\n- Flag uncertainties\n\nNEVER:\n- Cite single source for critical claims\n- Present tier-4 sources as authoritative\n- Skip confidence calibration\n- Hide conflicting sources\n- Omit caveats when uncertainty exists\n\n</rules>\n\n<references>\n\n**Deep-dive documentation**:\n- [source-tiers.md](references/source-tiers.md)  detailed authority assessment\n- [comparison-methods.md](references/comparison-methods.md)  comparison templates\n- [output-template.md](references/output-template.md)  full report structure\n\n**Related skills**:\n- [research-and-report](../research-and-report/SKILL.md)  full research workflow (loads this skill)\n- [codebase-analysis](../codebase-analysis/SKILL.md)  uses for technical research synthesis\n- [pattern-analysis](../pattern-analysis/SKILL.md)  identifying patterns in findings\n\n</references>"
              },
              {
                "name": "research-and-report",
                "description": "This skill should be used when researching best practices, evaluating technologies, comparing approaches, or when \"research\", \"evaluation\", or \"comparison\" are mentioned.",
                "path": "baselayer/skills/research-and-report/SKILL.md",
                "frontmatter": {
                  "name": "research-and-report",
                  "version": "2.0.0",
                  "description": "This skill should be used when researching best practices, evaluating technologies, comparing approaches, or when \"research\", \"evaluation\", or \"comparison\" are mentioned."
                },
                "content": "# Research\n\nSystematic investigation  evidence-based analysis  authoritative recommendations.\n\n<when_to_use>\n\n- Technology evaluation and comparison\n- Documentation discovery and troubleshooting\n- Best practices and industry standards research\n- Implementation guidance with authoritative sources\n\nNOT for: quick lookups, well-known patterns, time-critical debugging without investigation phase\n\n</when_to_use>\n\n<phases>\n\nTrack with TodoWrite. Phases advance only, never regress.\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Analyze Request | Session start | \"Analyzing research request\" |\n| Discover Sources | Criteria defined | \"Discovering sources\" |\n| Gather Information | Sources identified | \"Gathering information\" |\n| Synthesize Findings | Information gathered | \"Synthesizing findings\" |\n| Compile Report | Synthesis complete | \"Compiling report\" |\n\nWorkflow:\n- Start: Create \"Analyze Request\" as `in_progress`\n- Transition: Mark current `completed`, add next `in_progress`\n- Simple queries: Skip directly to \"Gather Information\" if unambiguous\n- Gaps during synthesis: Add new \"Gather Information\" task\n- Early termination: Skip to \"Compile Report\" with caveats\n\n</phases>\n\n<methodology>\n\nFive-phase systematic approach:\n\n**1. Question Phase**  Define scope\n- Decision to be made?\n- Evaluation parameters? (performance, maintainability, security, adoption)\n- Constraints? (timeline, expertise, infrastructure)\n\n**2. Discovery Phase**  Multi-source retrieval\n\n| Use Case | Primary | Secondary | Tertiary |\n|----------|---------|-----------|----------|\n| Official docs | context7 | octocode | firecrawl |\n| Troubleshooting | octocode issues | firecrawl community | context7 guides |\n| Code examples | octocode repos | firecrawl tutorials | context7 examples |\n| Technology eval | Parallel all | Cross-reference | Validate |\n\n**3. Evaluation Phase**  Analyze against criteria\n\n| Criterion | Metrics |\n|-----------|---------|\n| Performance | Benchmarks, latency, throughput, memory |\n| Maintainability | Code complexity, docs quality, community activity |\n| Security | CVEs, audits, compliance |\n| Adoption | Downloads, production usage, industry patterns |\n\n**4. Comparison Phase**  Systematic tradeoff analysis\n\nFor each option: Strengths  Weaknesses  Best fit  Deal breakers\n\n**5. Recommendation Phase**  Clear guidance with rationale\n\nPrimary recommendation  Alternatives  Implementation steps  Limitations\n\n</methodology>\n\n<tools>\n\nThree MCP servers for multi-source research:\n\n| Tool | Best For | Key Functions |\n|------|----------|---------------|\n| **context7** | Official docs, API refs | `resolve-library-id`, `get-library-docs` |\n| **octocode** | Code examples, issues | `packageSearch`, `githubSearchCode`, `githubSearchIssues` |\n| **firecrawl** | Tutorials, benchmarks | `search`, `scrape`, `map` |\n\nExecution patterns:\n- **Parallel**: Run independent queries simultaneously for speed\n- **Fallback**: context7  octocode  firecrawl if primary fails\n- **Progressive**: Start broad, narrow based on findings\n\nSee [tool-selection.md](references/tool-selection.md) for detailed usage.\n\n</tools>\n\n<discovery_patterns>\n\nCommon research workflows:\n\n| Scenario | Approach |\n|----------|----------|\n| **Library Installation** | Package search  Official docs  Installation guide |\n| **Error Resolution** | Parse error  Search issues  Official troubleshooting  Community solutions |\n| **API Exploration** | Documentation ID  API reference  Real usage examples |\n| **Technology Comparison** | Parallel all sources  Cross-reference  Build matrix  Recommend |\n\nSee [discovery-patterns.md](references/discovery-patterns.md) for detailed workflows.\n\n</discovery_patterns>\n\n<findings_format>\n\nTwo output modes:\n\n**Evaluation Mode** (recommendations):\n```\nFinding: { assertion }\nSource: { authoritative source with link }\nConfidence: High/Medium/Low  { rationale }\n```\n\n**Discovery Mode** (gathering):\n```\nFound: { what was discovered }\nSource: { where from with link }\nNotes: { context or caveats }\n```\n\n</findings_format>\n\n<response_structure>\n\n```markdown\n## Research Summary\nBrief overview  what investigated, sources consulted.\n\n## Options Discovered\n1. **Option A**  description\n2. **Option B**  description\n\n## Comparison Matrix\n| Criterion | Option A | Option B |\n|-----------|----------|----------|\n\n## Recommendation\n### Primary: [Option Name]\n**Rationale**: reasoning + evidence\n**Confidence**: level + explanation\n\n### Alternatives\nWhen to choose differently.\n\n## Implementation Guidance\nNext steps, common pitfalls, validation.\n\n## Sources\n- Official, benchmarks, case studies, community\n```\n\n</response_structure>\n\n<quality>\n\n**Always include**:\n- Direct citations with links\n- Confidence levels and limitations\n- Context about when recommendations may not apply\n\n**Always validate**:\n- Version is latest stable\n- Documentation matches user context\n- Critical info cross-referenced\n- Code examples complete and runnable\n\n**Proactively flag**:\n- Deprecated approaches with modern alternatives\n- Missing prerequisites\n- Common pitfalls and gotchas\n- Related tools in ecosystem\n\n</quality>\n\n<rules>\n\nALWAYS:\n- Create \"Analyze Request\" todo at session start\n- One phase `in_progress` at a time\n- Use multi-source approach (context7, octocode, firecrawl)\n- Provide direct citations with links\n- Cross-reference critical information\n- Include confidence levels and limitations\n\nNEVER:\n- Skip \"Analyze Request\" phase without defining scope\n- Single-source when multi-source available\n- Deliver recommendations without citations\n- Include deprecated approaches without flagging\n- Omit limitations and edge cases\n\n</rules>\n\n<references>\n\n**Deep-dive documentation**:\n- [source-hierarchy.md](references/source-hierarchy.md)  authority evaluation details\n- [tool-selection.md](references/tool-selection.md)  MCP server decision matrix\n- [discovery-patterns.md](references/discovery-patterns.md)  detailed research workflows\n\n**Related resources**:\n- [FORMATTING.md](../../shared/rules/FORMATTING.md)  formatting conventions\n\n</references>"
              },
              {
                "name": "root-cause-analysis",
                "description": "This skill should be used when diagnosing failures, investigating incidents, finding root causes, or when \"root cause\", \"diagnosis\", \"investigate\", or \"--rca\" are mentioned.",
                "path": "baselayer/skills/root-cause-analysis/SKILL.md",
                "frontmatter": {
                  "name": "root-cause-analysis",
                  "version": "1.0.0",
                  "description": "This skill should be used when diagnosing failures, investigating incidents, finding root causes, or when \"root cause\", \"diagnosis\", \"investigate\", or \"--rca\" are mentioned."
                },
                "content": "# Root Cause Analysis\n\nSymptom  hypothesis formation  evidence gathering  elimination  root cause  verified fix.\n\n<when_to_use>\n\n- Diagnosing system failures or unexpected behavior\n- Investigating incidents or outages\n- Finding the actual cause vs surface symptoms\n- Preventing recurrence through understanding\n- Any situation where \"why did this happen?\" needs answering\n\nNOT for: known issues with documented fixes, simple configuration errors, guessing without evidence\n\n</when_to_use>\n\n<discovery_phase>\n\n## Core Questions\n\n| Question | Why it matters |\n|----------|----------------|\n| What's the symptom? | Exact manifestation of the problem |\n| When did it start? | First occurrence, patterns in timing |\n| Can you reproduce it? | Consistently, intermittently, specific conditions |\n| What changed recently? | Deployments, config, dependencies, environment |\n| What have you tried? | Previous fix attempts, their results |\n| What are the constraints? | Time budget, what can't be modified |\n\n## Confidence Thresholds\n\n| Level | State | Action |\n|-------|-------|--------|\n| 0-2 | Symptom unclear or can't reproduce | Keep gathering info |\n| 3 | Good context, some gaps | Can start hypothesis phase |\n| 4+ | Clear picture | Proceed to investigation |\n\nAt level 3+, transition to hypothesis formation. Below level 3, keep gathering context.\n\n</discovery_phase>\n\n<hypothesis_formation>\n\n## Quality Criteria\n\n| Good Hypothesis | Weak Hypothesis |\n|-----------------|-----------------|\n| Testable | Too broad (\"something's wrong\") |\n| Falsifiable | Untestable |\n| Specific | Contradicts evidence |\n| Plausible | Assumes conclusion |\n\n## Multiple Working Hypotheses\n\nGenerate 2-4 competing theories:\n1. List each hypothesis with supporting/contradicting evidence\n2. Rank by likelihood (evidence support, parsimony, testability)\n3. Design tests to differentiate between them\n\n</hypothesis_formation>\n\n<evidence_gathering>\n\n## Observation Collection\n\n| Category | What to Gather |\n|----------|----------------|\n| Error manifestation | Exact symptoms, messages, states |\n| Reproduction steps | Minimal sequence triggering issue |\n| System state | Logs, variables, config at failure time |\n| Environment | Versions, platform, dependencies |\n| Timing | When started, frequency, patterns |\n\n## Breadcrumb Analysis\n\nTrace backwards from symptom:\n1. **Last known good state**  what was working?\n2. **First observable failure**  when did it break?\n3. **Changes between**  what's different?\n4. **Root trigger**  first thing that went wrong\n\n</evidence_gathering>\n\n<hypothesis_testing>\n\n## Test Design\n\nFor each hypothesis:\n1. **Prediction**  if true, what should we observe?\n2. **Test method**  how to verify?\n3. **Expected result**  what confirms/refutes?\n4. **Time budget**  when to move on?\n\n## Testing Priorities\n\n| Priority | Strategy |\n|----------|----------|\n| **First** | Quick, non-destructive, local tests |\n| **Second** | Most likely causes, common failures |\n| **Third** | Edge cases, rare failures |\n\n## Execution Loop\n\nBaseline  Single variable change  Observe  Document  Iterate\n\n</hypothesis_testing>\n\n<elimination_methodology>\n\nThree core techniques:\n\n| Technique | When to Use |\n|-----------|-------------|\n| **Binary Search** | Large problem space, ordered changes |\n| **Variable Isolation** | Multiple variables, need causation |\n| **Process of Elimination** | Finite set of possible causes |\n\nSee [elimination-techniques.md](references/elimination-techniques.md) for detailed methods.\n\n</elimination_methodology>\n\n<time_boxing>\n\n| Phase | Duration | Exit Condition |\n|-------|----------|----------------|\n| Discovery | 5-10 min | Questions answered, can reproduce |\n| Hypothesis | 10-15 min | 2-4 testable theories ranked |\n| Testing | 15-30 min per hypothesis | Confirmed or ruled out |\n| Fix | Variable | Root cause addressed |\n| Verification | 10-15 min | Fix confirmed, prevention documented |\n\nIf stuck beyond 2x estimate  step back, seek fresh perspective, or escalate.\n\n</time_boxing>\n\n<audit_trail>\n\nLog every step:\n\n```\n[TIME] PHASE: Action  Result\n[10:15] DISCOVERY: Gathered error logs  Found NullPointerException\n[10:22] HYPOTHESIS: User object not initialized\n[10:28] TEST: Added null check logging  Confirmed user is null\n```\n\nBenefits: Prevents revisiting same ground, enables handoff, catches circular investigation.\n\nSee [documentation-templates.md](references/documentation-templates.md) for full templates.\n\n</audit_trail>\n\n<common_pitfalls>\n\nWatch for these patterns:\n\n| Trap | Counter |\n|------|---------|\n| \"I already looked at that\" | Re-examine with fresh evidence |\n| \"That can't be the issue\" | Test anyway, let evidence decide |\n| \"We need to fix this quickly\" | Methodical investigation is faster |\n| Confirmation bias | Actively seek disconfirming evidence |\n| Correlation = causation | Test direct causal mechanism |\n\nSee [pitfalls.md](references/pitfalls.md) for detailed resistance patterns and recovery.\n\n</common_pitfalls>\n\n<confidence_calibration>\n\n| Level | Indicators |\n|-------|------------|\n| **High** | Consistent reproduction, clear cause-effect, multiple confirmations, fix verified |\n| **Moderate** | Reproduces mostly, strong correlation, single confirmation |\n| **Low** | Inconsistent reproduction, unclear correlation, unverified hypothesis |\n\n</confidence_calibration>\n\n<rules>\n\nALWAYS:\n- Gather sufficient context before hypothesizing\n- Form multiple competing hypotheses\n- Test systematically, one variable at a time\n- Document investigation trail\n- Verify fix actually addresses root cause\n- Document for future prevention\n\nNEVER:\n- Jump to solutions without diagnosis\n- Trust single hypothesis without testing alternatives\n- Apply fixes without understanding cause\n- Skip verification of fix\n- Repeat same failed investigation steps\n- Hide uncertainty about root cause\n\n</rules>\n\n<references>\n\n**Deep-dive documentation**:\n- [elimination-techniques.md](references/elimination-techniques.md)  binary search, variable isolation, process of elimination\n- [pitfalls.md](references/pitfalls.md)  cognitive biases and resistance patterns\n- [documentation-templates.md](references/documentation-templates.md)  investigation logs and RCA reports\n\n**Related skills**:\n- [debugging-and-diagnosis](../debugging-and-diagnosis/SKILL.md)  code-specific debugging (loads this skill)\n- [codebase-analysis](../codebase-analysis/SKILL.md)  uses for code investigation\n- [report-findings](../report-findings/SKILL.md)  presenting investigation results\n\n</references>"
              },
              {
                "name": "scenario-testing",
                "description": "This skill should be used when validating features end-to-end without mocks, testing integrations, or when \"scenario test\", \"e2e test\", or \"no mocks\" are mentioned.",
                "path": "baselayer/skills/scenario-testing/SKILL.md",
                "frontmatter": {
                  "name": "scenario-testing",
                  "version": "1.0.0",
                  "description": "This skill should be used when validating features end-to-end without mocks, testing integrations, or when \"scenario test\", \"e2e test\", or \"no mocks\" are mentioned."
                },
                "content": "# Scenario Testing\n\nEnd-to-end validation using real dependencies, no mocks ever.\n\n<when_to_use>\n\n- End-to-end feature validation\n- Integration testing across services\n- Proof programs demonstrating behavior\n- Real-world workflow testing\n- API contract verification\n- Authentication flow validation\n\nNOT for: unit testing, mock testing, performance benchmarking, load testing\n\n</when_to_use>\n\n<iron_law>\n\nNO MOCKS EVER.\n\nTruth hierarchy:\n1. **Scenarios**  real dependencies, actual behavior\n2. **Unit tests**  isolated logic, synthetic inputs\n3. **Mocks**  assumptions about how things work\n\nMocks test your assumptions, not reality. When mocks pass but production fails, the mock lied. When scenarios fail, reality spoke.\n\nTest against real databases, real APIs, real services. Use test credentials, staging environments, local instances  but always real implementations.\n\n</iron_law>\n\n<directory_structure>\n\n## .scratch/ (gitignored)\n\nThrowaway test scripts for quick validation. Self-contained, runnable, disposable.\n\nCRITICAL: Verify .scratch/ in .gitignore before first use.\n\n## scenarios.jsonl (committed)\n\nSuccessful scenario patterns documented as JSONL. One scenario per line, each a complete JSON object.\n\nPurpose: capture proven patterns, regression indicators, reusable test cases.\n\nStructure:\n\n```jsonl\n{\"name\":\"auth-login-success\",\"description\":\"User logs in with valid credentials\",\"setup\":\"Create test user with known password\",\"steps\":[\"POST /auth/login with credentials\",\"Receive JWT token\",\"GET /auth/me with token\"],\"expected\":\"User profile returned with correct data\",\"tags\":[\"auth\",\"jwt\",\"happy-path\"]}\n{\"name\":\"auth-login-invalid\",\"description\":\"Login fails with wrong password\",\"setup\":\"Test user exists\",\"steps\":[\"POST /auth/login with wrong password\"],\"expected\":\"401 Unauthorized, no token issued\",\"tags\":[\"auth\",\"error-handling\"]}\n```\n\n</directory_structure>\n\n<scratch_directory>\n\n## Purpose\n\nQuick validation without ceremony. Write script, run against real deps, verify behavior, delete or document.\n\n## Characteristics\n\n- **Gitignored**  never committed, purely local\n- **Disposable**  delete after validation or promote to permanent tests\n- **Self-contained**  runnable with single command\n- **Real dependencies**  actual DB, real APIs, live services\n\n## Naming Conventions\n\n- `test-{feature}.ts`  feature validation (test-auth-flow.ts)\n- `debug-{issue}.ts`  investigate specific bug (debug-token-expiry.ts)\n- `prove-{behavior}.ts`  demonstrate expected behavior (prove-rate-limiting.ts)\n- `explore-{api}.ts`  learn external API behavior (explore-stripe-webhooks.ts)\n\n## Example Structure\n\n```typescript\n// .scratch/test-auth-flow.ts\nimport { db } from '../src/db'\nimport { api } from '../src/api'\n\nasync function testAuthFlow() {\n  // Setup: real test user in real database\n  const user = await db.users.create({\n    email: 'test@example.com',\n    password: 'hashed-test-password'\n  })\n\n  // Execute: real HTTP requests\n  const loginRes = await api.post('/auth/login', {\n    email: user.email,\n    password: 'test-password'\n  })\n\n  // Verify: actual response\n  console.assert(loginRes.status === 200, 'Login should succeed')\n  console.assert(loginRes.body.token, 'Should receive JWT token')\n\n  const meRes = await api.get('/auth/me', {\n    headers: { Authorization: `Bearer ${loginRes.body.token}` }\n  })\n\n  console.assert(meRes.status === 200, 'Auth should work')\n  console.assert(meRes.body.email === user.email, 'Should return correct user')\n\n  // Cleanup\n  await db.users.delete({ id: user.id })\n\n  console.log(' Auth flow validated')\n}\n\ntestAuthFlow().catch(console.error)\n```\n\n</scratch_directory>\n\n<scenarios_jsonl>\n\n## Format\n\nEach line is complete JSON object with fields:\n\n```typescript\n{\n  name: string        // unique identifier (kebab-case)\n  description: string // human-readable summary\n  setup: string       // prerequisites and state preparation\n  steps: string[]     // ordered actions to execute\n  expected: string    // success criteria\n  tags: string[]      // categorization (auth, api, error, etc)\n  env?: string        // required environment (staging, local, prod-readonly)\n  duration_ms?: number // typical execution time\n}\n```\n\n## Purpose\n\n- **Pattern library**  proven scenarios for regression testing\n- **Documentation**  executable specification of system behavior\n- **Regression detection**  compare new behavior against known-good patterns\n- **Test generation**  source material for permanent test suites\n\n## When to Document\n\nDocument in scenarios.jsonl when:\n- Scenario validates critical user path\n- Bug was caught by this scenario (regression prevention)\n- Behavior is non-obvious or frequently questioned\n- Integration pattern is reusable across features\n\nDelete from .scratch/ when:\n- One-time debugging script\n- Exploratory testing that didn't find issues\n- Temporary verification during development\n\n</scenarios_jsonl>\n\n<workflow>\n\nLoop: Write  Execute  Document  Cleanup\n\n1. **Write proof program**  self-contained script in .scratch/\n2. **Run against real dependencies**  actual DB, live APIs, real services\n3. **Verify behavior**  assertions on actual responses\n4. **Document if successful**  add pattern to scenarios.jsonl\n5. **Cleanup**  delete script or promote to permanent tests\n\nEach iteration:\n- Script is throwaway (lives in .scratch/)\n- Dependencies are real (no mocks, no stubs)\n- Validation is concrete (actual behavior observed)\n- Pattern captured if valuable (scenarios.jsonl)\n\n</workflow>\n\n<gitignore_check>\n\nMANDATORY before first .scratch/ use:\n\n```bash\ngrep -q '.scratch/' .gitignore || echo '.scratch/' >> .gitignore\n```\n\nVerify .scratch/ directory will not be committed. All test scripts are local-only.\n\nIf .gitignore doesn't exist, create it:\n\n```bash\n[ -f .gitignore ] || touch .gitignore\ngrep -q '.scratch/' .gitignore || echo '.scratch/' >> .gitignore\n```\n\n</gitignore_check>\n\n<phases>\n\n## 1. Setup  Setting up scenario environment\n\nPrepare real dependencies:\n- Spin up local database (Docker, embedded)\n- Configure test API keys (staging credentials)\n- Initialize test data (real records, not fixtures)\n- Verify service connectivity\n\n## 2. Script  Writing proof program\n\nCreate .scratch/ test script:\n- Import real dependencies (no mocks)\n- Setup phase: prepare state\n- Execute phase: perform actions\n- Verify phase: assert on results\n- Cleanup phase: restore state\n\n## 3. Execute  Running against real dependencies\n\nRun proof program:\n- Execute with real database connection\n- Call actual API endpoints\n- Use live service instances\n- Observe actual behavior (no simulation)\n\n## 4. Document  Capturing successful patterns\n\nIf scenario validates behavior:\n- Extract pattern to scenarios.jsonl\n- Document setup requirements\n- Record expected outcomes\n- Tag for categorization\n\nDelete .scratch/ script or promote to permanent test suite.\n\n</phases>\n\n<rules>\n\nALWAYS:\n- Verify .scratch/ in .gitignore before first use\n- Test against real dependencies (actual DB, live APIs)\n- Use self-contained scripts (runnable with single command)\n- Document successful scenarios in scenarios.jsonl\n- Cleanup test data after execution\n- Tag scenarios for easy filtering\n- Include cleanup phase in all scripts\n- Use test credentials (never production)\n\nNEVER:\n- Use mocks, stubs, or test doubles\n- Commit .scratch/ directory contents\n- Test against production data\n- Skip cleanup phase\n- Assume behavior without verification\n- Promote assumptions to truth\n- Test mocked behavior instead of reality\n- Leave test data in shared environments\n\nESCALATE when:\n- No staging environment available\n- Real dependencies too expensive to test\n- Test requires destructive production operations\n- Cannot obtain test credentials\n\n</rules>\n\n<references>\n\nPatterns and examples:\n- [patterns.md](references/patterns.md)  common scenario patterns and templates\n\nRelated skills:\n- debugging-and-diagnosis  investigation methodology (scenarios help reproduce bugs)\n- test-driven-development  TDD workflow (scenarios validate features)\n- codebase-analysis  evidence gathering (scenarios provide empirical data)\n\nExternal resources:\n- [Growing Object-Oriented Software, Guided by Tests](http://www.growing-object-oriented-software.com/)  end-to-end testing philosophy\n- [Testing Without Mocks](https://www.jamesshore.com/v2/blog/2018/testing-without-mocks)  James Shore's pattern library\n\n</references>"
              },
              {
                "name": "security-engineering",
                "description": "This skill should be used when auditing code for security issues, reviewing authentication/authorization, evaluating input validation, analyzing cryptographic usage, or reviewing dependency security. Provides OWASP patterns, CWE analysis, and threat modeling guidance.",
                "path": "baselayer/skills/security-engineering/SKILL.md",
                "frontmatter": {
                  "name": "security-engineering",
                  "version": "1.0.0",
                  "description": "This skill should be used when auditing code for security issues, reviewing authentication/authorization, evaluating input validation, analyzing cryptographic usage, or reviewing dependency security. Provides OWASP patterns, CWE analysis, and threat modeling guidance."
                },
                "content": "# Security Engineering\n\nThreat-aware code review. Vulnerability detection. Risk-ranked remediation.\n\n<when_to_use>\n\n- Security audits and code reviews\n- Authentication/authorization review\n- Input validation and sanitization checks\n- Cryptographic implementation review\n- Dependency and supply chain security\n- Threat modeling for new features\n\nNOT for: performance optimization, general code review, feature implementation\n\n</when_to_use>\n\n<phases>\n\nTrack with TodoWrite. Each phase feeds the next.\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Threat Model | Session start | \"Building threat model\" |\n| Attack Surface | Model complete | \"Mapping attack surface\" |\n| Vulnerability Scan | Surface mapped | \"Scanning for vulnerabilities\" |\n| Risk Assessment | Vulns identified | \"Assessing risk levels\" |\n| Remediation Plan | Risks assessed | \"Planning remediation\" |\n\nCritical findings: add urgent remediation task immediately.\n\n</phases>\n\n<severity_levels>\n\nCVSS-aligned severity for findings:\n\n| Indicator | Severity | CVSS | Examples |\n|-----------|----------|------|----------|\n| **Critical** | 9.0-10.0 | RCE, auth bypass, mass data exposure, admin privesc |\n| **High** | 7.0-8.9 | SQLi, stored XSS, auth weakness, sensitive data leak |\n| **Medium** | 4.0-6.9 | CSRF, reflected XSS, info disclosure, weak crypto |\n| **Low** | 0.1-3.9 | Misconfig, missing headers, verbose errors |\n\nFormat: \"**Critical** RCE via unsanitized shell command\"\n\n</severity_levels>\n\n<threat_modeling>\n\n## STRIDE Framework\n\nSystematic threat identification by category:\n\n| Threat | Question | Check |\n|--------|----------|-------|\n| **S**poofing | Can attacker impersonate? | Auth mechanisms, tokens, sessions, API keys |\n| **T**ampering | Can attacker modify data? | Input validation, integrity checks, DB access |\n| **R**epudiation | Can actions be denied? | Audit logs, signatures, timestamps |\n| **I**nfo Disclosure | Can attacker access secrets? | Encryption, access control, logging |\n| **D**enial of Service | Can attacker disrupt? | Rate limits, timeouts, input size |\n| **E**levation | Can attacker gain access? | Authz checks, RBAC, least privilege |\n\n## Attack Trees\n\nMap paths from attacker goal to entry points:\n\n```\nGoal: Steal credentials\n- Attack login\n  - SQLi in username\n  - Brute force (no rate limit)\n  - Session fixation\n- Intercept traffic\n  - HTTPS downgrade\n  - MITM\n- Exploit reset\n  - Predictable token\n  - No expiry\n```\n\nFor each branch assess: feasibility, impact, detection, current defenses.\n\n## Trust Boundaries\n\nIdentify where data crosses trust levels:\n- Browser to server\n- Server to database\n- Service to third-party API\n- Internal service to service\n\nEvery boundary needs validation.\n\n</threat_modeling>\n\n<attack_surface>\n\n## Entry Points\n\n**External**:\n- HTTP/API endpoints (REST, GraphQL, gRPC)\n- WebSocket connections\n- File uploads\n- OAuth/SAML flows\n- Webhooks\n\n**Data Inputs**:\n- User data (forms, query params, headers)\n- File content (type, size, payload)\n- API payloads (JSON, XML)\n- Database queries\n\n**Auth Boundaries**:\n- Public (no auth)\n- Authenticated\n- Admin/privileged\n- Service-to-service\n\n## Prioritize Review\n\n1. Unauthenticated external inputs\n2. Privileged operations\n3. Data persistence layers\n4. Third-party integrations\n\nFor each entry point document:\n- Auth required? (none/user/admin)\n- Input validated? (none/basic/strict)\n- Rate limited?\n- Logged?\n- Encrypted?\n\n</attack_surface>\n\n<vulnerability_patterns>\n\n## Quick Reference\n\n| Vulnerability | Vulnerable | Secure |\n|--------------|------------|--------|\n| SQL Injection | String concat in query | Parameterized queries |\n| XSS | innerHTML with user data | textContent or DOMPurify |\n| Command Injection | exec() with user input | execFile() with array |\n| Path Traversal | Direct path concat | basename + prefix check |\n| Weak Password | MD5/SHA1/plain | bcrypt (12+) or argon2 |\n| Predictable Token | Math.random/Date.now | crypto.randomBytes(32) |\n| Broken Auth | Client-side role check | Server-side every request |\n| IDOR | No ownership check | Verify user owns resource |\n| Hardcoded Secret | API key in code | Environment variable |\n| Info Leak | Stack trace to user | Generic error, log detail |\n\n## Critical Checks\n\n**Authentication**:\n- Passwords: bcrypt/argon2, cost 12+\n- Sessions: crypto.randomBytes(32), httpOnly, secure, sameSite\n- JWT: verify signature, specify algorithm, short expiry\n- Reset: random token, 1hr expiry, hash stored token\n\n**Authorization**:\n- Server-side on every request\n- Verify ownership before resource access\n- Explicit allowlist for mass assignment\n- No role elevation from client input\n\n**Input Validation**:\n- Type, length, format on all inputs\n- Parameterized queries (never concat)\n- Escape/sanitize HTML output\n- Validate file uploads (type, size, content)\n\n**Cryptography**:\n- AES-256-GCM, SHA-256+\n- Never MD5, SHA1, DES, ECB\n- Secrets from env, never hardcoded\n- crypto.randomBytes for all tokens\n\nSee [vulnerability-patterns.md](references/vulnerability-patterns.md) for code examples.\n\n</vulnerability_patterns>\n\n<owasp_top_10>\n\n2021 OWASP Top 10 categories. Check each during vulnerability scan.\n\n| # | Category | Key CWEs | Top Mitigations |\n|---|----------|----------|-----------------|\n| A01 | Broken Access Control | 200, 352, 639 | Server-side checks, ownership validation |\n| A02 | Cryptographic Failures | 259, 327, 331 | TLS, bcrypt, no hardcoded secrets |\n| A03 | Injection | 20, 79, 89 | Parameterized queries, input validation |\n| A04 | Insecure Design | 209, 256, 434 | Threat modeling, rate limiting |\n| A05 | Security Misconfiguration | 16, 611, 614 | Security headers, disable debug |\n| A06 | Vulnerable Components | 1035, 1104 | npm audit, Dependabot |\n| A07 | Auth Failures | 287, 307, 521 | Strong passwords, MFA, rate limiting |\n| A08 | Integrity Failures | 502, 494 | Verify signatures, schema validation |\n| A09 | Logging Failures | 117, 532, 778 | Audit logs, redact sensitive data |\n| A10 | SSRF | 918 | URL allowlist, block private IPs |\n\nSee [owasp-top-10.md](references/owasp-top-10.md) for detailed breakdowns with code examples.\n\n</owasp_top_10>\n\n<workflow>\n\n**Loop**: Model Threats -> Map Surface -> Scan Vulnerabilities -> Assess Risk -> Plan Remediation\n\n1. **Threat Model**\n   - STRIDE analysis for component\n   - Attack trees for critical paths\n   - Identify trust boundaries\n   - Document threat actors\n\n2. **Attack Surface**\n   - Inventory all inputs\n   - Classify by auth level\n   - Map data flows across boundaries\n   - Prioritize high-risk entry points\n\n3. **Vulnerability Scan**\n   - Check each entry against OWASP Top 10\n   - Review auth/authz\n   - Validate input handling\n   - Check crypto usage\n   - Scan deps: `npm audit`, `cargo audit`\n\n4. **Risk Assessment**\n   - Rate severity (Critical/High/Medium/Low)\n   - Consider exploitability\n   - Assess impact (CIA triad)\n   - Calculate risk score\n\n5. **Remediation Plan**\n   - **Critical**: immediate action\n   - **High**: fix before release\n   - **Medium**: schedule in sprint\n   - **Low**: backlog or accept\n\nUpdate todos as you progress. Use [review-checklist.md](references/review-checklist.md) for verification.\n\n</workflow>\n\n<reporting>\n\n## Finding Format\n\n```markdown\n## {SEVERITY} {VULN_NAME}\n\n**Category**: {OWASP} | **CWE**: {ID} | **File**: {PATH}:{LINES}\n\n### Issue\n{CLEAR_EXPLANATION}\n\n### Impact\n{WHAT_ATTACKER_COULD_DO}\n\n### Fix\n{SPECIFIC_REMEDIATION_WITH_CODE}\n```\n\n## Summary Format\n\n```markdown\n# Security Audit: {SCOPE}\n\n| Severity | Count |\n|----------|-------|\n| Critical | N |\n| High | N |\n| Medium | N |\n| Low | N |\n\n## Key Findings\n1. {TOP_CRITICAL}\n2. {SECOND}\n3. {THIRD}\n\n## Recommendations\n- Immediate: {CRITICAL_FIXES}\n- Short-term: {HIGH_MEDIUM}\n- Long-term: {HARDENING}\n```\n\nSee [report-templates.md](references/report-templates.md) for full templates.\n\n</reporting>\n\n<rules>\n\nALWAYS:\n- Start with threat modeling before code review\n- Map complete attack surface\n- Check against all OWASP Top 10 categories\n- Use severity indicators consistently\n- Provide specific remediation with code\n- Verify fixes don't introduce new vulnerabilities\n- Document security assumptions\n- Update todos when transitioning phases\n\nNEVER:\n- Skip threat modeling for \"simple\" features\n- Assume input is trustworthy\n- Rely on client-side security\n- Use deprecated crypto (MD5, SHA1, DES)\n- Log sensitive data\n- Disable security checks \"temporarily\"\n- Mark complete without remediation plan\n\n</rules>\n\n<references>\n\n**Deep dives**:\n- [vulnerability-patterns.md](references/vulnerability-patterns.md) - secure vs vulnerable code examples\n- [owasp-top-10.md](references/owasp-top-10.md) - detailed OWASP categories with CWE mappings\n- [review-checklist.md](references/review-checklist.md) - complete security review checklist\n- [report-templates.md](references/report-templates.md) - finding and audit report templates\n\n**Related skills**:\n- codebase-analysis - evidence-based investigation foundation\n- debugging - when security issues manifest as bugs\n\n**External**:\n- [OWASP Top 10](https://owasp.org/Top10/)\n- [CWE Database](https://cwe.mitre.org/)\n- [OWASP Cheat Sheets](https://cheatsheetseries.owasp.org/)\n\n</references>"
              },
              {
                "name": "software-architecture",
                "description": "This skill should be used when designing systems, evaluating architectures, making technology decisions, or planning for scale. Provides technology selection frameworks, scalability planning, and architectural tradeoff analysis.",
                "path": "baselayer/skills/software-architecture/SKILL.md",
                "frontmatter": {
                  "name": "software-architecture",
                  "version": "2.1.0",
                  "description": "This skill should be used when designing systems, evaluating architectures, making technology decisions, or planning for scale. Provides technology selection frameworks, scalability planning, and architectural tradeoff analysis."
                },
                "content": "# Software Architecture\n\nDesign question  options with tradeoffs  documented decision.\n\n<when_to_use>\n\n- Designing new systems or major features\n- Evaluating architectural approaches\n- Making technology stack decisions\n- Planning for scale and performance\n- Analyzing design tradeoffs\n\nNOT for: trivial tech choices, premature optimization, undocumented requirements\n\n</when_to_use>\n\n<phases>\n\nTrack with TodoWrite. Advance only, never regress.\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Discovery | Session start | \"Gathering requirements\" |\n| Codebase Analysis | Requirements clear | \"Analyzing codebase\" |\n| Constraint Evaluation | Codebase understood | \"Evaluating constraints\" |\n| Solution Design | Constraints mapped | \"Designing solutions\" |\n| Documentation | Design selected | \"Documenting architecture\" |\n\nSituational (insert before Documentation when triggered):\n- Review & Refinement  feedback cycles on complex designs\n\nEdge cases:\n- Small questions: skip to Solution Design\n- Greenfield: skip Codebase Analysis\n- No ADR needed: skip Documentation\n- Iteration: Review & Refinement may repeat\n\nTodoWrite format:\n\n```text\n- Discovery { problem domain }\n- Analyze { codebase area }\n- Evaluate { constraint type }\n- Design { solution approach }\n- Document { decision type }\n```\n\nWorkflow:\n- Start: Create Discovery as `in_progress`\n- Transition: Mark current `completed`, add next `in_progress`\n- High start: skip to Solution Design for clear problems\n- Optional end: Documentation skippable if ADR not needed\n\n</phases>\n\n<principles>\n\n## Proven over Novel\n\nFavor battle-tested over bleeding-edge without strong justification.\n\nChecklist:\n- 3+ years production at scale?\n- Strong community + active maintenance?\n- Available experienced practitioners?\n- Total cost of ownership (learning, tooling, hiring)?\n\nRed flags: \"Early adopters\" without time budget, \"Written in X\" without benchmarks, \"Everyone's talking\" without case studies.\n\n## Complexity Budget\n\nEach abstraction must provide 10x value.\n\nQuestions:\n- What specific problem does this solve?\n- Can we solve with existing tools/patterns?\n- Maintenance burden (docs, onboarding, debugging)?\n- Impact on incident response?\n\n## Unix Philosophy\n\nSmall, focused modules with clear contracts, single responsibilities.\n\nChecklist:\n- Single, well-defined purpose?\n- Describe in one sentence without \"and\"?\n- Dependencies explicit and minimal?\n- Testable in isolation?\n- Clean, stable interface?\n\n## Observability First\n\nNo system ships without metrics, tracing, alerting.\n\nRequired every service:\n- Metrics: RED (Rate, Errors, Duration) for all endpoints\n- Tracing: distributed traces with correlation IDs\n- Logging: structured logs with context\n- Alerts: SLO-based with runbooks\n- Dashboards: at-a-glance health\n\n## Modern by Default\n\nUse contemporary proven patterns for greenfield, respect legacy constraints.\n\nPatterns (2025):\n- TypeScript strict mode for type safety\n- Rust for performance-critical services\n- Container deployment (Docker, K8s)\n- Infrastructure as Code (Terraform, Pulumi)\n- Distributed tracing (OpenTelemetry)\n- Event-driven architectures\n\nLegacy respect: document why legacy exists, plan incremental migration, don't rewrite what works.\n\n## Evolutionary\n\nDesign for change with clear upgrade paths.\n\nPractices:\n- Version all APIs with deprecation policies\n- Feature flags for gradual rollouts\n- Design with migration paths in mind\n- Deployment independent from release\n- Automated compatibility testing\n\n</principles>\n\n<technology_selection_summary>\n\nLoad [technology-selection.md](references/technology-selection.md) for detailed guidance.\n\n**Database**: Match data model to use case. PostgreSQL for ACID + complex queries. DynamoDB for flexibility + horizontal scaling. Redis for caching + pub/sub.\n\n**Framework (TS)**: Hono for modern/serverless, Express for proven ecosystem, Fastify for speed, NestJS for enterprise.\n\n**Framework (Rust)**: Axum for type-safe modern, Actix-web for raw performance.\n\n**Frontend**: React + TanStack Router for complex apps, Solid for perf-critical, Next.js for SSR/SSG.\n\n**Infrastructure**: Serverless for low-traffic/prototypes, K8s/ECS for multi-service at scale, PaaS for MVPs.\n\nSelection criteria: team expertise, performance needs, ecosystem, type safety, deployment target.\n\n</technology_selection_summary>\n\n<design_patterns_summary>\n\nLoad [design-patterns.md](references/design-patterns.md) for detailed guidance.\n\n**Service Decomposition**\n\nMonolith first. Extract when hitting specific pain:\n- Different scaling needs\n- Different deployment cadences\n- Team boundaries\n- Technology constraints\n\nMicroservices: yes for 10+ engineers, clear domains, independent scaling. No for small teams, unclear domains.\n\n**Communication**\n\n| Pattern | Use when | Tradeoffs |\n|---------|----------|-----------|\n| Sync (REST, gRPC) | Immediate response needed | Tight coupling, cascading failures |\n| Async (queues, streams) | Eventual consistency OK | Complexity, ordering challenges |\n| Event-driven | Decoupling, audit trail | Event versioning, consistency |\n\n**Data Management**\n\n- Database per service: each service owns its data\n- CQRS: separate read/write when patterns differ\n- Event sourcing: when audit trail critical\n\n</design_patterns_summary>\n\n<scalability_summary>\n\nLoad [scalability.md](references/scalability.md) for detailed guidance.\n\n**Key Metrics**: Latency (p50/p95/p99), throughput (RPS), utilization (CPU/mem/net/disk), error rates, saturation (queues, pools).\n\n**Capacity Planning**: Baseline  load test  find limits  model growth  plan 30-50% headroom.\n\n**Bottleneck Solutions**:\n\n| Resource | Solutions |\n|----------|-----------|\n| Database | Indexing, read replicas, caching, sharding |\n| CPU | Horizontal scale, algorithm optimization, async |\n| Memory | Profiling, streaming, data structure optimization |\n| Network | Compression, CDN, HTTP/2, gRPC |\n| I/O | SSD, batching, async I/O, caching |\n\n**Scaling Strategies**: Vertical (simple, limited), horizontal (stateless required), caching layers (L1/L2/L3), database scaling (replicas, sharding, pooling).\n\n</scalability_summary>\n\n<rust_summary>\n\nLoad [rust-architecture.md](references/rust-architecture.md) for detailed guidance.\n\n**Choose Rust when**: Performance-critical, resource-constrained, memory safety critical, concurrent processing.\n\n**Skip Rust when**: Prototype/MVP, small team without experience, standard CRUD, missing ecosystem libs.\n\n**Stack**: tokio (runtime), axum/actix-web (framework), sqlx/diesel (database), serde (serialization), tracing (observability), thiserror/anyhow (errors).\n\n**vs TypeScript**: Rust is 2-10x faster, 5-10x lower memory, compile-time bug detection, no GC. TS has faster iteration, massive ecosystem, easier hiring.\n\n</rust_summary>\n\n<common_patterns_summary>\n\nLoad [common-patterns.md](references/common-patterns.md) for detailed guidance.\n\n| Pattern | Purpose |\n|---------|---------|\n| API Gateway | Single entry, routing, auth, rate limiting |\n| BFF | Per-client backends with optimized data shapes |\n| Circuit Breaker | Fail fast when downstream unhealthy |\n| Saga | Distributed transactions across services |\n| Strangler Fig | Gradual legacy migration via proxy |\n\n</common_patterns_summary>\n\n<implementation_summary>\n\nLoad [implementation-guidance.md](references/implementation-guidance.md) for detailed guidance.\n\n**Phased Delivery**:\n- MVP (2-4 wks): Core workflow, simplest architecture, validate problem-solution fit\n- Beta (4-8 wks): Key features, monitoring, automated deploy, validate product-market fit\n- Production (8-12 wks): Full features, reliability, auto-scaling, DR\n- Optimization (ongoing): Performance tuning, cost optimization\n\n**Critical Path**: Identify blocking dependencies, parallel workstreams, resource constraints, risk areas, decision points.\n\n**Observability**: Metrics (RED), logging (structured + correlation IDs), tracing (OpenTelemetry), alerting (SLO-based + runbooks).\n\n</implementation_summary>\n\n<adr_summary>\n\nLoad [adr-template.md](references/adr-template.md) for the full template.\n\nADR structure:\n- Status, Date, Deciders, Context\n- Decision\n- Alternatives Considered (with pros/cons/why not)\n- Consequences (positive, negative, neutral)\n- Implementation Notes\n- Success Metrics\n- Review Date\n\n</adr_summary>\n\n<questions_summary>\n\nLoad [questions-checklist.md](references/questions-checklist.md) for the full checklist.\n\n**Requirements**: Core workflows, data storage, integrations, critical vs nice-to-have.\n\n**Non-functional**: Users (now + 1-2 yrs), latency targets, availability (99.9%? 99.99%?), consistency, compliance.\n\n**Constraints**: Existing systems, current tech, team expertise, deployment env, budget, timeline, acceptable debt.\n\n**Technology Selection**: Why this over alternatives? Production experience? Operational complexity? Lock-in risk? Hiring?\n\n**Risk**: Blast radius? Rollback strategy? Detection? Contingency? Assumptions? Cost of being wrong?\n\n</questions_summary>\n\n<workflow>\n\nUse `EnterPlanMode` when presenting options  enables keyboard navigation.\n\nStructure:\n- Prose above tool: context, reasoning, recommendation\n- Inside tool: 2-3 options with tradeoffs + \"Something else\"\n- User selects: number, modifications, or combo\n\nAfter user choice:\n- Restate decision\n- List implications\n- Surface concerns if any\n- Ask clarifying questions if gaps remain\n\nBefore documenting:\n- Verify all options considered\n- Confirm rationale is clear\n- Check success metrics defined\n- Validate migration path if applicable\n\nAt Documentation phase:\n- Create ADR if architectural decision\n- Skip if simple tech choice\n- Mark phase complete after delivery\n\n</workflow>\n\n<rules>\n\nALWAYS:\n- Create Discovery todo at session start\n- Update todos at phase transitions\n- Ask clarifying questions about requirements and constraints before proposing\n- Present 2-3 viable options with clear tradeoffs\n- Document decisions with rationale (ADR when appropriate)\n- Consider immediate needs and future scale\n- Evaluate team expertise and operational capacity\n- Account for budget and timeline constraints\n\nNEVER:\n- Recommend bleeding-edge tech without strong justification\n- Over-engineer solutions for current scale\n- Skip constraint analysis (budget, timeline, team, existing systems)\n- Propose architectures the team can't operate\n- Ignore operational complexity in technology selection\n- Proceed without understanding non-functional requirements\n- Skip phase transitions when moving through workflow\n\n</rules>\n\n<references>\n\n**Core**:\n- [FORMATTING.md](../../shared/rules/FORMATTING.md)  formatting conventions\n\n**Deep Dives**:\n- [technology-selection.md](references/technology-selection.md)  database, framework, infrastructure selection\n- [design-patterns.md](references/design-patterns.md)  service decomposition, communication, data management\n- [scalability.md](references/scalability.md)  performance modeling, bottlenecks, scaling strategies\n- [rust-architecture.md](references/rust-architecture.md)  when to use Rust, stack recommendations\n- [common-patterns.md](references/common-patterns.md)  API Gateway, BFF, Circuit Breaker, Saga, Strangler\n- [implementation-guidance.md](references/implementation-guidance.md)  phased delivery, observability\n- [adr-template.md](references/adr-template.md)  Architecture Decision Record template\n- [questions-checklist.md](references/questions-checklist.md)  requirements and risk questions\n\n</references>"
              },
              {
                "name": "software-engineering",
                "description": "This skill should be used when making design decisions, evaluating trade-offs, assessing code quality, or when \"engineering judgment\" or \"code quality\" are mentioned.",
                "path": "baselayer/skills/software-engineering/SKILL.md",
                "frontmatter": {
                  "name": "software-engineering",
                  "version": "1.0.0",
                  "description": "This skill should be used when making design decisions, evaluating trade-offs, assessing code quality, or when \"engineering judgment\" or \"code quality\" are mentioned."
                },
                "content": "# Software Engineering\n\nEngineering judgment - thoughtful decisions - quality code.\n\n<when_to_use>\n\n- Making architectural or design decisions\n- Evaluating trade-offs between approaches\n- Determining appropriate level of thoroughness\n- Assessing when code needs refactoring\n- Deciding when to ask vs proceed independently\n- Balancing speed, quality, maintainability\n\nNOT for: mechanical tasks, clear-cut decisions, following explicit instructions\n\n</when_to_use>\n\n<principles>\n\nCore engineering judgment framework.\n\n**User preferences trump defaults**\n`CLAUDE.md`, project rules, existing patterns always override skill suggestions.\n\n**Simplest thing that works**\nStart simple. Add complexity only when requirements demand.\n- Boring solutions for boring problems\n- Proven libraries over custom implementations\n- Progressive enhancement over rewrites\n\n**Read before write**\nUnderstand existing patterns before modifying.\n- Check how similar features implemented\n- Follow established conventions\n- Maintain consistency\n\n**Small, focused changes**\nOne idea per commit, 20-100 LOC, 1-5 files.\n- Easy to review/understand\n- Lower bug risk\n- Simpler to revert\n- Faster feedback\n\n**Security awareness**\nDon't introduce vulnerabilities.\n- Validate external input\n- Parameterized queries\n- Handle auth properly\n- No secrets in code/logs\n\n**Know when to stop**\nShip working code, don't gold-plate.\n- Implement requirements, not assumptions\n- No unrequested features\n- No speculative abstraction\n\n</principles>\n\n<type_safety>\n\nType safety across languages.\n\n**Core principle**: Make illegal states unrepresentable. Type system should prevent invalid data at compile time, not runtime.\n\n**Hierarchy**: Correct (type-safe) - Clear (self-documenting) - Precise (not overly broad)\n\n**Key patterns**:\n- **Result types** - Errors explicit in signatures, not hidden in exceptions\n- **Discriminated unions** - Mutually exclusive states with discriminator field\n- **Branded types** - Distinct types for domain concepts (user ID vs product ID)\n- **Parse, don't validate** - Transform untyped to typed at boundaries, trust types internally\n\nSee [type-patterns.md](references/type-patterns.md) for detailed concepts.\nLoad `typescript-dev/SKILL.md` for TypeScript implementations.\n\n</type_safety>\n\n<decision_framework>\n\nSystematic approach to engineering choices.\n\n**Understand before deciding**\n- What problem being solved?\n- What constraints exist?\n- What's already in codebase?\n- What patterns does project use?\n\n**Consider trade-offs**\nNo perfect solutions:\n- Speed vs robustness\n- Simplicity vs flexibility\n- Consistency vs optimization\n- Implement time vs maintain time\n\n**Recognize good-enough**\nPerfect is enemy of shipped:\n- Meets requirements?\n- Maintainable by team?\n- Tested adequately?\n- Can improve incrementally?\n\nIf yes to all - ship it.\n\n**Document significant choices**\nNon-obvious decisions: comment why, note trade-offs, link discussions, flag assumptions.\n\n</decision_framework>\n\n<when_to_ask>\n\nBalance autonomy with collaboration.\n\n**Proceed independently**:\n- Task clear and well-defined\n- Approach follows existing patterns\n- Changes small and localized\n- Requirements fully understood\n- No security/data integrity risks\n\n**Ask questions**:\n- Requirements ambiguous\n- Multiple approaches, unclear trade-offs\n- Changes affect architecture\n- Security/compliance implications\n- Unfamiliar domain/technology\n\n**Escalate immediately**:\n- Security vulnerabilities discovered\n- Data corruption/loss risk\n- Breaking changes to public APIs\n- Performance degradation detected\n\nDon't guess on high-stakes decisions.\n\n</when_to_ask>\n\n<code_quality>\n\nStandards separating good from professional code.\n\n**Type safety**: Make illegal states unrepresentable via discriminated unions, branded types.\n\n**Error handling**: Every error path needs explicit handling. No silent failures.\n\n**Naming**: Functions=verbs (`calculateTotal`), variables=nouns (`userId`), booleans=questions (`isValid`).\n\n**Function design**: One thing well. 10-30 lines typical, max 50. 3 params ideal, max 5. Pure when possible.\n\n**Comments**: Explain why, not what.\n\nSee [code-quality-patterns.md](references/code-quality-patterns.md) for examples.\n\n</code_quality>\n\n<refactoring>\n\nWhen and how to improve existing code.\n\n**Refactor when**:\n- Adding feature reveals poor structure\n- Code duplicated 3+ times\n- Function exceeds 50 lines\n- Naming unclear/misleading\n- Tests difficult to write\n\n**Don't refactor when**:\n- Code works and won't be touched\n- Time-critical delivery in progress\n- No test coverage to verify\n- Scope creep from main task\n- Just preference, no clear benefit\n\n**Guidelines**:\n- Have tests first (or write them)\n- One refactoring at a time\n- Keep tests passing throughout\n- Commit refactors separately from features\n- Don't change behavior\n\n</refactoring>\n\n<testing>\n\nTesting philosophy.\n\n**Test the right things**:\n- Public interfaces, not implementation\n- Edge cases and error paths\n- Critical business logic\n- Integration points\n- Security boundaries\n\n**Don't over-test**:\n- No tests for trivial getters/setters\n- Don't test framework behavior\n- Avoid brittle implementation-coupled tests\n\n**Coverage targets**:\n- Critical paths: 90%+\n- Business logic: 80%+\n- Utility functions: 80%+\n- Overall: 70%+\n\nLow coverage acceptable for: config, type definitions, framework boilerplate.\n\n</testing>\n\n<performance>\n\nBalance optimization with delivery.\n\n**Premature optimization is root of evil**\n- Make it work first\n- Make it right second\n- Make it fast only if needed\n\n**Optimize when**:\n- Measured performance issue exists\n- User experience degraded\n- Resource costs excessive\n- Profiler shows clear bottleneck\n\n**Before optimizing**:\n1. Measure current performance\n2. Set target metrics\n3. Profile to find bottleneck\n4. Optimize specific bottleneck\n5. Measure improvement\n6. Document trade-offs\n\nDon't optimize based on gut feeling or without measurement.\n\n</performance>\n\n<security>\n\nSecurity mindset for all code.\n\n**Input validation**: Validate all external input, sanitize before processing, allowlists over blocklists.\n\n**Auth**: Never trust client-side checks, verify on server, use proven libraries, don't roll your own crypto.\n\n**Data handling**: Never log sensitive data, hash passwords (bcrypt/argon2), parameterized queries, strict file upload validation.\n\n**Dependencies**: Keep updated, review advisories, minimize count, audit before adding.\n\n**Red flags to escalate**: Payment info, user credentials, health/financial data, encryption implementation, session management.\n\n</security>\n\n<anti_patterns>\n\nCommon mistakes to avoid.\n\n**Over-engineering**: Building \"might need\" features, premature abstraction, excessive config, enterprise patterns for simple problems.\nFix: YAGNI. Build for today.\n\n**Under-engineering**: No error handling, no input validation, ignoring edge cases, copy-paste over functions.\nFix: Basic quality isn't optional.\n\n**Scope creep**: \"While I'm here...\", refactoring unrelated code, adding unrequested features.\nFix: Stay focused. File issues for unrelated work.\n\n**Guess-and-check**: Random solutions, copying without understanding, no root cause investigation.\nFix: Systematic debugging. Understand before changing.\n\n**Analysis paralysis**: Endless design discussions, researching every option, waiting for perfect.\nFix: Good enough + shipping > perfect + delayed.\n\n</anti_patterns>\n\n<communication>\n\nSenior engineer collaboration.\n\n**Clear issues/PRs**: Context (problem), approach (solution), trade-offs (alternatives), testing (verification), impact (risks).\n\n**Code review**: Focus on correctness/clarity/security. Suggest, don't demand perfection. Approve when good enough.\n\n**When blocked**: Try 30 min self-unblock, gather context, ask specific question with context, propose solutions.\n\n**Saying no**: \"That would work, but have you considered X?\" / \"This introduces Y risk. Can we mitigate with Z?\"\n\nBack opinions with reasoning. Stay open to being wrong.\n\n</communication>\n\n<workflow_integration>\n\nConnect with other baselayer skills.\n\n**With TDD**: Senior judgment decides what's worth testing. TDD skill provides how.\n\n**With debugging**: Senior judgment decides if worth fixing now. Debugging skill provides systematic investigation.\n\n**With dev-* skills**: Software engineering provides the \"why\" and \"when\". dev-* skills provide the \"how\" for specific technologies (typescript-dev, react-dev, hono-dev, bun-dev).\n\n</workflow_integration>\n\n<rules>\n\nALWAYS:\n- Read `CLAUDE.md` and project rules first\n- Follow existing codebase patterns\n- Make small, focused changes\n- Validate external input\n- Handle errors explicitly\n- Test critical paths\n- Document non-obvious decisions\n- Ask when uncertain on high-stakes\n\nNEVER:\n- Add features not in requirements\n- Ignore error handling\n- Skip input validation\n- Commit secrets or credentials\n- Guess on security decisions\n- Refactor without tests\n- Optimize without measuring\n- Over-engineer simple solutions\n\n</rules>\n\n<references>\n\nComplements other baselayer skills:\n\n**Core Practices:**\n- [test-driven-development/SKILL.md](../test-driven-development/SKILL.md) - TDD methodology\n- [debugging-and-diagnosis/SKILL.md](../debugging-and-diagnosis/SKILL.md) - systematic debugging\n- [pathfinding/SKILL.md](../pathfinding/SKILL.md) - requirements clarification\n\n**Development Skills** (load for implementation patterns):\n- [typescript-dev/SKILL.md](../typescript-dev/SKILL.md) - TypeScript, Zod, modern features\n- [react-dev/SKILL.md](../react-dev/SKILL.md) - React 18-19, hooks typing\n- [hono-dev/SKILL.md](../hono-dev/SKILL.md) - Hono API framework\n- [bun-dev/SKILL.md](../bun-dev/SKILL.md) - Bun runtime, SQLite, testing\n\n**Detailed Patterns:**\n- [type-patterns.md](references/type-patterns.md) - language-agnostic type patterns\n- [code-quality-patterns.md](references/code-quality-patterns.md) - code examples\n\n**Standards:**\n- [FORMATTING.md](../../shared/rules/FORMATTING.md) - formatting conventions\n\n</references>"
              },
              {
                "name": "status-reporting",
                "description": "This skill should be used when checking project status, starting sessions, reviewing activity, or when \"sitrep\", \"status report\", or \"what's changed\" are mentioned.",
                "path": "baselayer/skills/status-reporting/SKILL.md",
                "frontmatter": {
                  "name": "status-reporting",
                  "version": "1.0.0",
                  "description": "This skill should be used when checking project status, starting sessions, reviewing activity, or when \"sitrep\", \"status report\", or \"what's changed\" are mentioned."
                },
                "content": "# Status Reporting\n\nGather -> aggregate -> present pattern for comprehensive project status across VCS, PRs, issues, CI.\n\n<when_to_use>\n\n- Starting work sessions (context refresh)\n- Checking project/team activity\n- Understanding PR/stack relationships\n- Quick status overview before planning\n- Reviewing recent changes across systems\n- Understanding blockers\n\nNOT for: deep-dive into specific items, real-time monitoring, single-source queries\n\n</when_to_use>\n\n<core_pattern>\n\n**Three-phase workflow**:\n\n1. **Gather** - collect from multiple sources\n2. **Aggregate** - combine, filter, cross-reference by time/stack/status\n3. **Present** - format for scanning with actionable insights\n\nKey principles:\n- Multi-source integration (VCS + code review + issues + CI)\n- Time-aware filtering (natural language -> query params)\n- Stack-aware organization (group by branch hierarchy)\n- Scannable output (visual indicators, relative times)\n- Actionable insights (highlight blockers, failures)\n\n</core_pattern>\n\n<workflow>\n\n**Phase 1: Parse Constraints**\n\nExtract time from natural language:\n- \"last X hours\" -> `-Xh`\n- \"past X days\" / \"last X days\" -> `-Xd`\n- \"yesterday\" -> `-1d`\n- \"this morning\" / \"today\" -> `-12h`\n- \"this week\" -> `-7d`\n- \"since {date}\" -> calculate days back\n\nDefault: 7 days if unspecified.\n\n**Phase 2: Gather Data**\n\nRun parallel queries for each available source:\n\n1. **VCS State** - branch/stack structure, recent commits, working dir status\n2. **Code Review** - open PRs, CI status, review decisions, activity\n3. **Issues** - recently updated, status, priority, assignments\n4. **CI/CD** - pipeline runs, success/failure, error summaries\n\nSkip unavailable sources gracefully.\n\n**Phase 3: Aggregate**\n\nCross-reference and organize:\n- Group PRs by stack position (if stack-aware)\n- Filter all by time constraint\n- Correlate issues with PRs/branches\n- Identify blockers (failed CI, blocking reviews)\n- Calculate relative timestamps\n\n**Phase 4: Present**\n\nFormat for scanning:\n- Hierarchical sections (VCS -> PRs -> Issues -> CI)\n- Visual indicators (`` `` `` for status)\n- Relative timestamps for recency\n- Highlight attention-needed items\n- Include links for deep-dive\n\nSee [templates.md](references/templates.md) for section formats.\n\n</workflow>\n\n<data_sources>\n\n**VCS** - stack visualization, commit history, working dir state\n- Stack-aware (Graphite, git-stack): hierarchical branch relationships\n- Standard git: branch, log, remote tracking\n\n**Code Review** - PRs/MRs, CI checks, reviews, comments\n- Platforms: GitHub, GitLab, Bitbucket, Gerrit\n\n**Issues** - recent updates, metadata, repo relationships\n- Platforms: Linear, Jira, GitHub Issues, GitLab Issues\n\n**CI/CD** - runs, success/failure, timing, errors\n- Platforms: GitHub Actions, GitLab CI, CircleCI, Jenkins\n\nTool-specific: [graphite.md](references/graphite.md), [github.md](references/github.md), [linear.md](references/linear.md), [beads.md](references/beads.md)\n\n</data_sources>\n\n<aggregation>\n\n**Cross-Referencing**:\n1. PRs to branches (by name)\n2. Issues to PRs (by ID in title/body)\n3. CI runs to PRs (by number/SHA)\n4. Issues to repos (by reference)\n\n**Stack-Aware Organization**:\n- Group PRs by hierarchy\n- Show parent/child relationships\n- Indicate current position\n- Highlight blockers in stack order\n\n**Filtering**:\n- Time: apply to all sources, use most recent update\n- Status: prioritize action-needed, open before closed\n\n**Relative Timestamps**:\n- < 1 hour: \"X minutes ago\"\n- < 24 hours: \"X hours ago\"\n- < 7 days: \"X days ago\"\n- >= 7 days: \"X weeks ago\" or absolute\n\n</aggregation>\n\n<presentation>\n\n**Visual Indicators**:\n- `` success | `` failure | `` pending | `` draft | `` blocker\n- `` progress (3/5)\n- `` minor | `` moderate | `` severe\n\n**Output Structure**:\n```\n=== STATUS REPORT: {repo} ===\nGenerated: {timestamp}\n{Time filter if applicable}\n\n{VCS_SECTION}\n{PR_SECTION}\n{ISSUE_SECTION}\n{CI_SECTION}\n\n ATTENTION NEEDED\n{blockers and action items}\n```\n\nSee [templates.md](references/templates.md) for detailed section templates.\n\n</presentation>\n\n<scripts>\n\nUse `scripts/sitrep.ts` for automated gathering:\n\n```bash\n./scripts/sitrep.ts              # All sources, 24h default\n./scripts/sitrep.ts -t 7d        # Last 7 days\n./scripts/sitrep.ts -s github    # Specific sources\n./scripts/sitrep.ts --format=text\n```\n\nOutputs JSON (structured) or text (human-readable). Reduces agent tool calls 80%+.\n\nSee [implementation.md](references/implementation.md) for script structure and patterns.\n\n</scripts>\n\n<dependencies>\n\n**Required**: VCS tool (git, gt, jj), shell access\n\n**Optional** (graceful degradation):\n- Code review CLI (gh, glab)\n- Issue tracker MCP/API\n- CI/CD platform API\n\nWorks with ANY available subset.\n\n</dependencies>\n\n<rules>\n\nALWAYS:\n- Parse time constraints before queries\n- Execute queries in parallel\n- Handle missing sources gracefully\n- Use relative timestamps\n- Highlight actionable items\n- Provide links for deep-dive\n- Format for scanning\n\nNEVER:\n- Fail entirely if one source unavailable\n- Block on slow queries (use timeouts)\n- Expose credentials\n- Dump raw data without organization\n\n</rules>\n\n<integration>\n\n**As session starter**:\n1. Generate report (understand state)\n2. Identify attention-needed items\n3. Plan work (prioritize by blockers)\n4. Return periodically (track progress)\n\n**Cross-skill references**:\n- Failing CI -> [debugging-and-diagnosis](../debugging-and-diagnosis/SKILL.md)\n- Before planning -> use report for context\n- When blocked -> check dependencies\n\n**Automation**: daily standup, pre-commit hooks, PR creation context\n\n</integration>\n\n<references>\n\nTool integrations:\n- [graphite.md](references/graphite.md) - Graphite stack and PR queries\n- [github.md](references/github.md) - GitHub CLI patterns\n- [linear.md](references/linear.md) - Linear MCP integration\n- [beads.md](references/beads.md) - Local issue tracking\n\nImplementation:\n- [templates.md](references/templates.md) - Output templates and formatting\n- [implementation.md](references/implementation.md) - Patterns, scripts, anti-patterns\n\nExamples:\n- [EXAMPLES.md](EXAMPLES.md) - Usage examples and sample output\n\nFormatting:\n- [FORMATTING.md](../../shared/rules/FORMATTING.md) - Visual conventions\n\n</references>"
              },
              {
                "name": "subagent-coordination",
                "description": "This skill should be used when coordinating agents, delegating tasks to specialists, or when \"dispatch agents\", \"which agent\", or \"multi-agent\" are mentioned.",
                "path": "baselayer/skills/subagent-coordination/SKILL.md",
                "frontmatter": {
                  "name": "subagent-coordination",
                  "version": "2.1.0",
                  "description": "This skill should be used when coordinating agents, delegating tasks to specialists, or when \"dispatch agents\", \"which agent\", or \"multi-agent\" are mentioned."
                },
                "content": "# Subagent Coordination\n\nOrchestrate baselayer subagents by matching tasks to the right agent + skill combinations.\n\n## Orchestration Planning\n\nFor complex multi-agent tasks, **start with the Plan subagent** to research and design the orchestration strategy before execution.\n\n```\nComplex task arrives\n    \n     Plan subagent (research phase)\n        Explore codebase, gather context\n        Identify which agents and skills needed\n        Design execution sequence (sequential, parallel, or hybrid)\n        Return orchestration plan\n    \n     Execute plan (dispatch agents per plan)\n```\n\n**Plan subagent benefits**:\n- Runs in isolated context  doesn't consume main conversation tokens\n- Can read many files without bloating orchestrator context\n- Returns concise plan for execution\n\n**When to use Plan subagent**:\n- Task touches multiple domains (auth + performance + testing)\n- Unknown codebase area  needs exploration first\n- Sequence of agents matters (dependencies between steps)\n- High-stakes changes requiring careful coordination\n\n## Roles and Agents\n\nCoordination uses **roles** (what function is needed) mapped to **agents** (who fulfills it). This allows substitution when better-suited agents are available.\n\n### Baselayer Agents\n\n| Role | Agent | Purpose |\n|------|-------|---------|\n| coding | **senior-dev** | Build, implement, fix, refactor |\n| reviewing | **ranger** | Evaluate code, PRs, architecture, security |\n| research | **analyst** | Investigate, research, explore |\n| debugging | **debugger** | Diagnose issues, trace problems |\n| testing | **tester** | Validate, prove, verify behavior |\n| challenging | **skeptic** | Challenge complexity, question assumptions |\n| specialist | **specialist** | Domain expertise (CI/CD, design, accessibility, etc.) |\n| patterns | **pattern-analyzer** | Extract reusable patterns from work |\n\n### Other Available Agents\n\nAdditional agents may be available in your environment (user-defined, plugin-provided, or built-in). When dispatching:\n\n1. Check available agents for best fit to the role\n2. Prefer specialized agents over generalists when they match the task\n3. Fall back to baselayer agents when no better option exists\n\nExamples of role substitution:\n- **coding**  `senior-engineer`, `developer`, `senior-dev`\n- **reviewing**  `security-auditor`, `code-reviewer`, `ranger`\n- **research**  `research-engineer`, `docs-librarian`, `analyst`\n- **specialist**  `cicd-expert`, `design-agent`, `accessibility-auditor`, `bun-expert`\n\n## Task Routing\n\nRoute by role, then select the best available agent for that role:\n\n```\nUser request arrives\n    \n     \"build/implement/fix/refactor\"  coding role\n    \n     \"review/critique/audit\"  reviewing role\n    \n     \"investigate/research/explore\"  research role\n    \n     \"debug/diagnose/trace\"  debugging role\n    \n     \"test/validate/prove\"  testing role\n    \n     \"simplify/challenge/is this overkill\"  challenging role\n    \n     \"deploy/configure/CI/design/a11y\"  specialist role\n    \n     \"capture this workflow/make reusable\"  patterns role\n```\n\n## Workflow Patterns\n\n### Sequential Handoff\n\nOne agent completes, passes to next:\n\n```\nresearch (investigate)  coding (implement)  reviewing (verify)  testing (validate)\n```\n\n**Use when**: Clear phases, each requires different expertise.\n\n### Parallel Execution\n\nMultiple agents work simultaneously using `run_in_background: true`:\n\n```\n reviewing (code quality)\n\ntask  research (impact analysis)\n\n testing (regression tests)\n```\n\n**Use when**: Independent concerns, time-sensitive, comprehensive coverage needed.\n\n### Challenge Loop\n\nBuild  challenge  refine:\n\n```\ncoding (propose)  challenging (evaluate)  coding (refine)\n```\n\n**Use when**: Complex architecture, preventing over-engineering, high-stakes decisions.\n\n### Investigation Chain\n\nNarrow down, then fix:\n\n```\nresearch (scope)  debugging (root cause)  coding (fix)  testing (verify)\n```\n\n**Use when**: Bug reports, production issues, unclear symptoms.\n\n## Role + Skill Combinations\n\n### Coding Role\n\n| Task | Skills |\n|------|--------|\n| New feature | software-engineering, test-driven-development |\n| Bug fix | debugging-and-diagnosis  software-engineering |\n| Refactor | software-engineering + complexity-analysis |\n| API endpoint | hono-dev, software-engineering |\n| React component | react-dev, software-engineering |\n| AI feature | ai-sdk, software-engineering |\n\n### Reviewing Role\n\n| Task | Skills |\n|------|--------|\n| PR review | code-review |\n| Architecture review | software-architecture |\n| Performance audit | performance-engineering |\n| Security audit | security-engineering |\n| Pre-merge check | code-review + scenario-testing |\n\n### Research Role\n\n| Task | Skills |\n|------|--------|\n| Codebase exploration | codebase-analysis |\n| Research question | research-and-report |\n| Unclear requirements | pathfinding |\n| Status report | status-reporting, report-findings |\n\n### Testing Role\n\n| Task | Skills |\n|------|--------|\n| Feature validation | scenario-testing |\n| TDD implementation | test-driven-development |\n| Integration testing | scenario-testing |\n\n## Advanced Execution Patterns\n\n### Background Execution\n\nRun agents asynchronously for parallel work:\n\n```json\n{\n  \"description\": \"Security review\",\n  \"prompt\": \"Review auth module for vulnerabilities\",\n  \"subagent_type\": \"ranger\",\n  \"run_in_background\": true\n}\n```\n\nRetrieve results with `TaskOutput`:\n\n```json\n{\n  \"task_id\": \"agent-abc123\",\n  \"block\": true\n}\n```\n\n### Chaining Subagents\n\nSequence agents for complex workflows  each agent's output informs the next:\n\n```\nresearch agent  \"Found 3 auth patterns in use\"\n    \ncoding agent  \"Implementing refresh token flow using pattern A\"\n    \nreviewing agent  \"Verified implementation, found 1 issue\"\n    \ncoding agent  \"Fixed issue, ready for merge\"\n```\n\nPass context explicitly between agents via prompt.\n\n### Resumable Sessions\n\nContinue long-running work across invocations:\n\n```json\n{\n  \"description\": \"Continue security analysis\",\n  \"prompt\": \"Now examine session management\",\n  \"subagent_type\": \"ranger\",\n  \"resume\": \"agent-abc123\"\n}\n```\n\nAgent preserves full context from previous execution.\n\n**Use cases**:\n- Multi-phase research spanning topics\n- Iterative refinement without re-explaining context\n- Long debugging sessions with incremental discoveries\n\n### Model Selection\n\nOverride model for specific needs:\n\n```json\n{\n  \"subagent_type\": \"analyst\",\n  \"model\": \"haiku\"  // Fast, cheap for exploration\n}\n```\n\n- **haiku**: Fast exploration, simple queries\n- **sonnet**: Balanced reasoning (default)\n- **opus**: Complex analysis, nuanced judgment\n\n## Coordination Rules\n\n1. **Single owner**: One role owns each task phase\n2. **Clear handoffs**: Explicit deliverables between agents\n3. **Skill loading**: Agent loads only needed skills\n4. **User prefs first**: Check `CLAUDE.md` before applying defaults\n5. **Minimal agents**: Don't parallelize what can be sequential\n\n## Decision Framework\n\nWhen agents face implementation choices:\n\n1. **Favor existing patterns**  Match what's already in the codebase\n2. **Prefer simplicity**  Cleverness is a liability; simple is maintainable\n3. **Optimize for maintainability**  Next developer (or agent) must understand it\n4. **Consider backward compatibility**  Breaking changes require explicit approval\n5. **Document trade-offs**  When choosing between options, record why\n\nThese principles apply across all roles. Agents should surface decisions to the orchestrator when trade-offs are significant.\n\n## Communication Style\n\nOrchestrators and agents should:\n\n- **Report progress** at each major step (don't go silent)\n- **Flag blockers immediately**  don't spin on unsolvable problems\n- **Provide clear summaries** of delegated work (what was done, what remains)\n- **Include file paths and line numbers** when referencing code\n\nProgress format:\n```\n [1/5] research: Exploring auth patterns\n [2/5] coding: Implementing refresh token flow\n```\n\n## When to Escalate\n\n- **Blocked**: Agent can't proceed  route to research role\n- **Conflicting findings**: Multiple agents disagree  surface to user\n- **Scope creep**: Task expands beyond role's domain  re-route\n- **Missing context**: Not enough info  research role with pathfinding skill\n\n## Anti-Patterns\n\n- Running all agents on every task (wasteful)\n- Skipping reviewing role for \"small changes\" (risk)\n- Coding role debugging without debugging skills (inefficient)\n- Parallel agents with dependencies (race conditions)\n- Not challenging complex proposals (over-engineering)\n\n## Quick Reference\n\n**\"I need to build X\"**  coding role + TDD skills\n\n**\"Review this PR\"**  reviewing role + code-review\n\n**\"Why is this broken?\"**  debugging role + debugging-and-diagnosis\n\n**\"Is this approach overkill?\"**  challenging role + complexity-analysis\n\n**\"Prove this works\"**  testing role + scenario-testing\n\n**\"What's the codebase doing?\"**  research role + codebase-analysis\n\n**\"Deploy to production\"**  specialist role + domain skills\n\n**\"Make this workflow reusable\"**  patterns role + patternify"
              },
              {
                "name": "test-driven-development",
                "description": "This skill should be used when implementing features with TDD, writing tests first, or refactoring with test coverage. Applies disciplined Red-Green-Refactor cycles with TypeScript/Bun and Rust tooling.",
                "path": "baselayer/skills/test-driven-development/SKILL.md",
                "frontmatter": {
                  "name": "test-driven-development",
                  "version": "2.1.0",
                  "description": "This skill should be used when implementing features with TDD, writing tests first, or refactoring with test coverage. Applies disciplined Red-Green-Refactor cycles with TypeScript/Bun and Rust tooling."
                },
                "content": "# Test-Driven Development\n\nWrite tests first, implement minimal code to pass, refactor systematically.\n\n<when_to_use>\n\n- New features with TDD methodology\n- Complex business logic requiring coverage\n- Critical paths: auth, payments, data integrity\n- Bug fixes: reproduce with test, fix, verify\n- Refactoring: ensure behavior preservation\n- API design: tests define the interface\n\nNOT for: exploratory coding, UI prototypes, static config, trivial glue code\n\n</when_to_use>\n\n<phases>\n\nTrack with TodoWrite. Advance through RED-GREEN-REFACTOR cycle.\n\n| Phase | Trigger | activeForm |\n|-------|---------|------------|\n| Red | Session start / cycle restart | \"Writing failing test\" |\n| Green | Test written and failing | \"Implementing code\" |\n| Refactor | Tests passing | \"Refactoring code\" |\n| Verify | Refactor complete | \"Verifying implementation\" |\n\nTodoWrite format:\n\n```text\n- Write failing test for { feature }\n- Implement { feature } to pass tests\n- Refactor { aspect }\n- Verify { what's being checked }\n```\n\nWorkflow:\n- Start: Create \"Red\" phase `in_progress`\n- Transition: Mark current `completed`, add next `in_progress`\n- After each phase: Run tests before advancing\n- Multiple cycles: Return to \"Red\" for next feature\n\nEdge cases:\n- Good existing tests: Start at \"Refactor\" after confirming pass\n- Bug fix: Start at \"Red\" with failing test reproducing bug\n- No regression: Tests must continue passing through all phases\n\n</phases>\n\n<cycle>\n\n```\nRED --> GREEN --> REFACTOR --> RED --> ...\n |       |          |\nTest   Impl      Improve\nFails  Passes   Quality\n```\n\nEach cycle: 5-15 min. Longer = step too large, decompose.\n\nPhilosophy:\n- Red-Green-Refactor as primary workflow\n- Test quality over quantity - behavior, not implementation\n- Incremental progress - small focused cycles\n- Type safety throughout - tests as type-safe as production\n\n</cycle>\n\n<red_phase>\n\nWrite tests defining desired behavior before implementation exists.\n\nGuidelines:\n- 3-5 related tests fully specifying one feature\n- Type system makes invalid states unrepresentable\n- Each test = one specific behavior\n- Run tests, verify fail for right reason\n- Descriptive names forming sentences\n\nTypeScript:\n\n```typescript\nimport { describe, test, expect } from 'bun:test'\n\ndescribe('UserAuthentication', () => {\n  test('authenticates with valid credentials', async () => {\n    const result = await authenticate({ email: 'user@example.com', password: 'SecurePass123!' })\n    expect(result).toMatchObject({ type: 'success', user: expect.objectContaining({ email: 'user@example.com' }) })\n  })\n\n  test('rejects invalid credentials', async () => {\n    const result = await authenticate({ email: 'wrong@example.com', password: 'wrong' })\n    expect(result).toMatchObject({ type: 'error', code: 'INVALID_CREDENTIALS' })\n  })\n\n  test.todo('implements rate limiting after failed attempts')\n})\n```\n\nRust:\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn authenticates_with_valid_credentials() {\n        let creds = Credentials { email: \"user@example.com\".into(), password: \"SecurePass123!\".into() };\n        assert!(matches!(authenticate(&creds), Ok(AuthResult::Success { .. })));\n    }\n\n    #[test]\n    fn rejects_invalid_credentials() {\n        let creds = Credentials { email: \"wrong@example.com\".into(), password: \"wrong\".into() };\n        assert!(matches!(authenticate(&creds), Err(AuthError::InvalidCredentials)));\n    }\n}\n```\n\nCommit: `test: add failing tests for [feature]`\n\nTransition: Mark \"Red\" `completed`, create \"Green\" `in_progress`\n\n</red_phase>\n\n<green_phase>\n\nImplement minimum code to make tests pass.\n\nGuidelines:\n- Focus on passing tests, not perfect code\n- Explicit types where aids clarity\n- Straightforward solutions first\n- Hardcode if passes test - refactor generalizes\n- Run tests frequently\n\nTypeScript:\n\n```typescript\ntype AuthResult = { type: 'success'; user: User } | { type: 'error'; code: string }\n\nasync function authenticate(creds: { email: string; password: string }): Promise<AuthResult> {\n  if (!creds.password) return { type: 'error', code: 'MISSING_PASSWORD' }\n  const user = await findUserByEmail(creds.email)\n  if (!user) return { type: 'error', code: 'INVALID_CREDENTIALS' }\n  const match = await comparePassword(creds.password, user.passwordHash)\n  if (!match) return { type: 'error', code: 'INVALID_CREDENTIALS' }\n  return { type: 'success', user }\n}\n```\n\nRust:\n\n```rust\npub fn authenticate(creds: &Credentials) -> Result<AuthResult, AuthError> {\n    if creds.password.is_empty() { return Err(AuthError::MissingPassword); }\n    let user = find_user_by_email(&creds.email).ok_or(AuthError::InvalidCredentials)?;\n    if !compare_password(&creds.password, &user.password_hash) {\n        return Err(AuthError::InvalidCredentials);\n    }\n    Ok(AuthResult::Success { user })\n}\n```\n\nVerify: `bun test` / `cargo test`\n\nCommit: `feat: implement [feature] to pass tests`\n\nTransition: Mark \"Green\" `completed`, create \"Refactor\" `in_progress`\n\n</green_phase>\n\n<refactor_phase>\n\nEnhance code quality without changing behavior. Tests must continue passing.\n\nGuidelines:\n- Extract common patterns into well-named functions\n- Apply SOLID principles where appropriate\n- Improve types: discriminated unions, branded types\n- No test behavior changes\n- Run tests after each step\n\nTypeScript:\n\n```typescript\n// Extract validation\nfunction validateCredentials(creds: { email: string; password: string }): AuthResult | null {\n  if (!creds.password) return { type: 'error', code: 'MISSING_PASSWORD' }\n  if (!isValidEmail(creds.email)) return { type: 'error', code: 'INVALID_EMAIL' }\n  return null\n}\n\n// Branded types for safety\ntype Email = string & { readonly __brand: 'Email' }\n```\n\nRust:\n\n```rust\n// Extract validation\nfn validate_credentials(creds: &Credentials) -> Result<(), AuthError> {\n    if creds.password.is_empty() { return Err(AuthError::MissingPassword); }\n    if !is_valid_email(&creds.email) { return Err(AuthError::InvalidEmail); }\n    Ok(())\n}\n\n// Newtype for safety\npub struct Email(String);\n```\n\nVerify: `bun test` / `cargo test`\n\nCommit: `refactor: [improvement description]`\n\nTransition: Mark \"Refactor\" `completed`, create \"Verify\" `in_progress`\n\nFinal: Run full suite. Mark \"Verify\" `completed` when all checks pass.\n\n</refactor_phase>\n\n<organization>\n\nFollow project conventions, defaulting to:\n\nTypeScript/Bun:\n```\nsrc/{module}/{name}.ts          # Implementation\nsrc/{module}/{name}.test.ts     # Unit tests colocated\nsrc/{module}/__fixtures__/      # Test data\ntests/integration/              # Integration tests\ntests/e2e/                      # End-to-end tests\n```\n\nRust:\n```\nsrc/{module}/mod.rs             # #[cfg(test)] mod tests { ... }\ntests/integration/              # Integration tests\ntests/fixtures/                 # Test data\n```\n\n</organization>\n\n<quality>\n\n| Metric | Target |\n|--------|--------|\n| Line coverage | >=80% (90% critical paths) |\n| Mutation score | >=75% |\n| Unit test time | <5s |\n\nTest characteristics:\n- Single clear assertion per test\n- No execution order dependencies\n- Descriptive names forming sentences\n- Behavior focus, not implementation\n\nSmells to avoid:\n- Setup longer than test\n- Multiple unrelated assertions\n- Coupling to implementation details\n- Flaky tests\n\nSee [quality-metrics.md](references/quality-metrics.md) for coverage and mutation testing details.\n\n</quality>\n\n<bug_fixes>\n\nTDD workflow for bugs:\n\n1. Write failing test reproducing bug (Start \"Red\" `in_progress`)\n2. Verify fails for right reason\n3. Fix with minimal code (Transition to \"Green\")\n4. Verify passes, all others still pass\n5. Refactor if needed (Transition to \"Refactor\" or skip to \"Verify\")\n6. Commit: `fix: [bug description] with test coverage`\n\nExample:\n\n```typescript\n// 1. Failing test\ntest('handles division by zero gracefully', () => {\n  expect(divide(10, 0)).toMatchObject({ type: 'error', code: 'DIVISION_BY_ZERO' })\n})\n\n// 3. Fix\nfunction divide(a: number, b: number): Result {\n  if (b === 0) return { type: 'error', code: 'DIVISION_BY_ZERO' }\n  return { type: 'success', value: a / b }\n}\n```\n\n</bug_fixes>\n\n<rules>\n\nALWAYS:\n- Track progress with TodoWrite phases\n- Write tests before implementation (RED first)\n- Run tests after each phase\n- Verify tests fail for right reason in RED\n- Keep cycles 5-15 min max\n- Descriptive test names forming sentences\n- Test behavior, not implementation\n- Each test = one reason to fail\n\nNEVER:\n- Skip to implementation without tests\n- Change test behavior during refactoring\n- Test implementation details or private methods\n- Allow tests to depend on execution order\n- Write flaky tests\n- Mark phase complete without running tests\n- Multiple unrelated assertions per test\n\n</rules>\n\n<quick_reference>\n\n```bash\n# TypeScript/Bun\nbun test                    # Run all tests\nbun test --watch            # Watch mode\nbun test --coverage         # Coverage report\nbun test --only             # Run only .only tests\nbun x stryker run           # Mutation testing\n\n# Rust\ncargo test                  # Run all tests\ncargo test --test NAME      # Specific integration test\ncargo tarpaulin             # Coverage report\ncargo mutants               # Mutation testing\ncargo test -- --nocapture   # Show println! output\n```\n\n</quick_reference>\n\n<references>\n\n- [test-patterns.md](references/test-patterns.md) - Discriminated unions, builders, mocking, parameterized tests, async patterns for TypeScript and Rust\n- [quality-metrics.md](references/quality-metrics.md) - Coverage analysis, mutation testing setup, CI integration, thresholds\n- [feature-implementation.md](examples/feature-implementation.md) - Full TDD session walkthrough\n- [bug-fix.md](examples/bug-fix.md) - TDD workflow for bug fixes\n\n</references>"
              },
              {
                "name": "typescript-dev",
                "description": "This skill should be used when writing TypeScript, eliminating any types, implementing Zod validation, or when strict type safety is needed. Covers modern TS 5.5+ features and runtime validation patterns.",
                "path": "baselayer/skills/typescript-dev/SKILL.md",
                "frontmatter": {
                  "name": "typescript-dev",
                  "version": "1.0.0",
                  "description": "This skill should be used when writing TypeScript, eliminating any types, implementing Zod validation, or when strict type safety is needed. Covers modern TS 5.5+ features and runtime validation patterns."
                },
                "content": "# TypeScript Development\n\nType-safe code = compile-time errors = runtime confidence.\n\n<when_to_use>\n\n- Writing new TypeScript code\n- Eliminating `any` types\n- Using modern TypeScript 5.5+ features\n- Validating API inputs/outputs with Zod\n- Implementing Result types and discriminated unions\n- Creating branded types for domain concepts\n\nNOT for: runtime-only logic unrelated to types, non-TypeScript projects\n\n</when_to_use>\n\n<config>\n\n**tsconfig.json** strict settings:\n\n```json\n{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"exactOptionalPropertyTypes\": true,\n    \"noImplicitOverride\": true,\n    \"noPropertyAccessFromIndexSignature\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"noImplicitReturns\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"verbatimModuleSyntax\": true,\n    \"isolatedModules\": true,\n    \"skipLibCheck\": false\n  }\n}\n```\n\n**Version requirements**: TS 5.2+ (`using`), TS 5.4+ (`NoInfer`), TS 5.5+ (inferred predicates)\n\n</config>\n\n## Core Patterns\n\n<eliminating_any>\n\n`any` defeats the type system. Use `unknown` + guards.\n\n```typescript\n//  NEVER\nfunction process(data: any) { return data.value; }\n\n//  ALWAYS\nfunction process(data: unknown): string {\n  if (!hasValue(data)) throw new TypeError('Invalid');\n  return data.value.toString();\n}\n\nfunction hasValue(v: unknown): v is { value: unknown } {\n  return typeof v === 'object' && v !== null && 'value' in v;\n}\n```\n\nValidate at boundaries:\n\n```typescript\nasync function fetchUser(id: string): Promise<User> {\n  const data: unknown = await fetch(`/api/users/${id}`).then(r => r.json());\n  return UserSchema.parse(data);\n}\n```\n\n</eliminating_any>\n\n<result_types>\n\nExceptions hide errors from types. Result makes them explicit.\n\n```typescript\ntype Result<T, E = Error> =\n  | { readonly ok: true; readonly value: T }\n  | { readonly ok: false; readonly error: E };\n\ntype UserError =\n  | { readonly type: 'not-found'; readonly id: string }\n  | { readonly type: 'network'; readonly message: string };\n\nasync function getUser(id: string): Promise<Result<User, UserError>> {\n  try {\n    const response = await fetch(`/api/users/${id}`);\n    if (response.status === 404)\n      return { ok: false, error: { type: 'not-found', id } };\n    if (!response.ok)\n      return { ok: false, error: { type: 'network', message: response.statusText } };\n    return { ok: true, value: await response.json() };\n  } catch (e) {\n    return { ok: false, error: { type: 'network', message: String(e) } };\n  }\n}\n\n// Caller must handle\nconst result = await getUser(id);\nif (!result.ok) {\n  switch (result.error.type) {\n    case 'not-found': return showNotFound(result.error.id);\n    case 'network': return showError(result.error.message);\n  }\n}\nreturn renderUser(result.value);\n```\n\nSee [result-pattern.md](references/result-pattern.md) for utilities (`map`, `flatMap`, `combine`).\n\n</result_types>\n\n<discriminated_unions>\n\nPrevent illegal state combinations.\n\n```typescript\n//  Allows { status: 'loading', data: user, error: 'Failed' }\ntype Request = { status: 'idle'|'loading'|'success'|'error'; data?: User; error?: string; };\n\n//  Only valid states\ntype RequestState =\n  | { readonly status: 'idle' }\n  | { readonly status: 'loading' }\n  | { readonly status: 'success'; readonly data: User }\n  | { readonly status: 'error'; readonly error: string };\n\nfunction render(state: RequestState): JSX.Element {\n  switch (state.status) {\n    case 'idle': return <div>Ready</div>;\n    case 'loading': return <div>Loading...</div>;\n    case 'success': return <div>{state.data.name}</div>;\n    case 'error': return <div>Error: {state.error}</div>;\n    default: return assertNever(state);\n  }\n}\n\nfunction assertNever(value: never): never {\n  throw new Error(`Unhandled: ${JSON.stringify(value)}`);\n}\n```\n\n</discriminated_unions>\n\n<branded_types>\n\nPrevent mixing incompatible primitives.\n\n```typescript\ndeclare const __brand: unique symbol;\ntype Brand<T, B extends string> = T & { readonly [__brand]: B };\n\ntype UserId = Brand<string, 'UserId'>;\ntype ProductId = Brand<string, 'ProductId'>;\n\nfunction createUserId(value: string): UserId {\n  if (!/^user-\\d+$/.test(value)) throw new TypeError(`Invalid: ${value}`);\n  return value as UserId;\n}\n\nconst userId = createUserId('user-123');\n// getUser(productId); //  Type error\ngetUser(userId);       //  Works\n```\n\nSecurity:\n\n```typescript\ntype SanitizedHtml = Brand<string, 'SanitizedHtml'>;\n\nfunction sanitize(raw: string): SanitizedHtml {\n  return escapeHtml(raw) as SanitizedHtml;\n}\n\nfunction render(html: SanitizedHtml): void {\n  element.innerHTML = html; // Type proves sanitization\n}\n```\n\nSee [branded-types.md](references/branded-types.md) for advanced patterns.\n\n</branded_types>\n\n## Modern TypeScript (5.2+)\n\n<resource_management>\n\n`using` for automatic cleanup (TS 5.2+):\n\n```typescript\nclass DatabaseConnection implements Disposable {\n  [Symbol.dispose]() { this.close(); }\n}\n\nfunction query() {\n  using conn = new DatabaseConnection();\n  return conn.query('SELECT * FROM users');\n} // Automatically closed\n\nasync function asyncWork() {\n  await using resource = new AsyncResource();\n} // Disposed with await\n```\n\nUse for: connections, file handles, locks, transactions.\n\n</resource_management>\n\n<satisfies_operator>\n\nValidate type without widening (TS 4.9+):\n\n```typescript\nconst config = {\n  port: 3000,\n  host: 'localhost'\n} satisfies Record<string, string | number>;\n\nconfig.port // number (not string | number)\n\nconst routes = {\n  home: '/',\n  user: '/user/:id'\n} as const satisfies Record<string, string>;\n\ntype HomeRoute = typeof routes.home; // '/'\n```\n\n</satisfies_operator>\n\n<const_type_parameters>\n\nPreserve literals through generics (TS 5.0+):\n\n```typescript\nfunction makeTuple<const T extends readonly unknown[]>(...args: T): T {\n  return args;\n}\nconst result = makeTuple('a', 'b', 'c'); // ['a', 'b', 'c'] not string[]\n```\n\n</const_type_parameters>\n\n<inferred_predicates>\n\nTS 5.5+ auto-infers type predicates:\n\n```typescript\nfunction isString(x: unknown) {\n  return typeof x === 'string';\n}\n// Inferred: (x: unknown) => x is string\n\nconst strings = values.filter(isString); // string[]\n```\n\n</inferred_predicates>\n\n<template_literals>\n\nPattern matching at type level:\n\n```typescript\ntype Route = `/${string}`;\ntype ApiRoute = `/api/v${number}/${string}`;\n\ntype ExtractParams<T extends string> =\n  T extends `${string}:${infer P}/${infer R}` ? P | ExtractParams<`/${R}`>\n  : T extends `${string}:${infer P}` ? P : never;\n\ntype Params = ExtractParams<'/user/:id/post/:postId'>; // 'id' | 'postId'\n```\n\nSee [modern-features.md](references/modern-features.md) for TS 5.5-5.8.\n\n</template_literals>\n\n## Zod Validation\n\nSchema = runtime validation + TypeScript type.\n\n<zod_core>\n\n```typescript\nimport { z } from 'zod';\n\nconst UserSchema = z.object({\n  id: z.string().uuid(),\n  email: z.string().email(),\n  name: z.string().min(1).max(100)\n});\n\ntype User = z.infer<typeof UserSchema>;\n\n// safeParse preferred\nconst result = UserSchema.safeParse(data);\nif (!result.success) {\n  console.error(result.error.issues);\n  return;\n}\nconst user = result.data;\n```\n\n</zod_core>\n\n<zod_patterns>\n\n**Discriminated unions** (preferred over z.union):\n\n```typescript\nconst ApiResponse = z.discriminatedUnion(\"type\", [\n  z.object({ type: z.literal(\"success\"), data: z.unknown() }),\n  z.object({ type: z.literal(\"error\"), code: z.string(), message: z.string() })\n]);\n```\n\n**Environment variables**:\n\n```typescript\nconst EnvSchema = z.object({\n  NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),\n  DATABASE_URL: z.string().url(),\n  PORT: z.coerce.number().int().positive().default(3000)\n});\nconst env = EnvSchema.parse(process.env);\n```\n\n**API validation (Hono)**:\n\n```typescript\nimport { zValidator } from '@hono/zod-validator';\n\napp.post('/users', zValidator('json', UserSchema), (c) => {\n  const user = c.req.valid('json');\n  return c.json(user);\n});\n```\n\nSee:\n- [zod-building-blocks.md](references/zod-building-blocks.md) - primitives, refinements, transforms\n- [zod-schemas.md](references/zod-schemas.md) - composition patterns\n- [zod-integration.md](references/zod-integration.md) - API/form/env integration\n\n</zod_patterns>\n\n## Type Guards\n\n```typescript\n// User-defined\nfunction isString(v: unknown): v is string {\n  return typeof v === 'string';\n}\n\n// Assertion\nfunction assertString(v: unknown): asserts v is string {\n  if (typeof v !== 'string') throw new TypeError('Expected string');\n}\n\n// With noUncheckedIndexedAccess\nconst users: User[] = getUsers();\nconst first = users[0]; // User | undefined\nif (first !== undefined) processUser(first);\n```\n\nSee [advanced-types.md](references/advanced-types.md) for utilities.\n\n## TSDoc\n\nTypes show structure. TSDoc shows intent. Critical for AI agents.\n\n```typescript\n/**\n * Authenticates user and returns session token.\n * @param credentials - User login credentials\n * @returns Session token valid for 24 hours\n * @throws {AuthenticationError} Invalid credentials\n * @example\n * const token = await authenticate({ email, password });\n */\nexport async function authenticate(credentials: Credentials): Promise<SessionToken>;\n```\n\nDocument: all exports, parameters with constraints, thrown errors, non-obvious returns.\n\nSee [tsdoc-patterns.md](references/tsdoc-patterns.md) for comprehensive guide.\n\n<rules>\n\nALWAYS:\n- Strict TypeScript config enabled\n- Type-only imports: `import type { User } from './types'`\n- Const assertions for literal types\n- Exhaustive matching with `assertNever`\n- Runtime validation at boundaries (Zod)\n- Branded types for domain/sensitive data\n- Result types for error-prone operations\n- `satisfies` for literal inference\n- `using` for resources with cleanup\n- TSDoc on all exports\n\nNEVER:\n- `any` (use `unknown` + guards)\n- `@ts-ignore` (fix types or document)\n- TypeScript enums (use const assertions or z.enum)\n- Non-null assertions `!` (use guards)\n- Loose state (use discriminated unions)\n- Hidden errors (use Result)\n\nPREFER:\n- safeParse over parse\n- z.discriminatedUnion over z.union\n- Inferred predicates (TS 5.5+)\n- Const type parameters for literals\n\n</rules>\n\n<references>\n\n**Type Patterns:**\n- [result-pattern.md](references/result-pattern.md) - Result/Either utilities\n- [branded-types.md](references/branded-types.md) - advanced branded patterns\n- [advanced-types.md](references/advanced-types.md) - template literals, utilities\n\n**Modern Features:**\n- [modern-features.md](references/modern-features.md) - TS 5.5-5.8\n- [migration-paths.md](references/migration-paths.md) - upgrading TypeScript\n\n**Zod:**\n- [zod-building-blocks.md](references/zod-building-blocks.md) - primitives, transforms\n- [zod-schemas.md](references/zod-schemas.md) - composition patterns\n- [zod-integration.md](references/zod-integration.md) - API, forms, env\n\n**TSDoc:**\n- [tsdoc-patterns.md](references/tsdoc-patterns.md) - documentation patterns\n\n**Examples:**\n- [api-response.md](examples/api-response.md) - end-to-end type-safe API\n- [form-validation.md](examples/form-validation.md) - Zod + React Hook Form\n- [resource-management.md](examples/resource-management.md) - using declarations\n- [state-machine.md](examples/state-machine.md) - discriminated union patterns\n\n</references>"
              },
              {
                "name": "use-the-best-tool",
                "description": "This skill should be used when choosing CLI tools, a tool seems slow, or when \"best tool\", \"which tool\", or \"tool alternatives\" are mentioned.",
                "path": "baselayer/skills/use-the-best-tool/SKILL.md",
                "frontmatter": {
                  "name": "use-the-best-tool",
                  "version": "1.0.0",
                  "description": "This skill should be used when choosing CLI tools, a tool seems slow, or when \"best tool\", \"which tool\", or \"tool alternatives\" are mentioned."
                },
                "content": "# Use the Best Tool\n\nSelect optimal CLI tools  graceful fallback  research when needed.\n\n<when_to_use>\n\n- Choosing which tool for file search, content search, JSON processing\n- Tool taking unexpectedly long for task size\n- User expresses frustration with current tool\n- Task could be done more elegantly\n- Need to verify tool availability before recommending\n\nNOT for: tasks where tool choice is predetermined, simple one-line commands\n\n</when_to_use>\n\n<detection>\n\nRun detection script before selecting tools:\n\n```bash\nbun /Users/mg/Developer/outfitter/agents/baselayer/skills/use-the-best-tool/scripts/index.ts\n```\n\nParse output to determine:\n- Available modern tools\n- Missing tools that could enhance workflow\n- System context (OS, package managers)\n\nCache results per session  no need to re-run unless tool availability changes.\n\n</detection>\n\n<selection>\n\nMap task to best available tool:\n\n| Task | Preferred | Fallback | Legacy | Notes |\n|------|-----------|----------|--------|-------|\n| Find files by name | `fd` | - | `find` | fd: faster, better defaults |\n| Search file contents | `rg` | - | `grep` | rg: respects .gitignore, faster |\n| AST-aware code search | `sg` | `rg` | `grep` | sg: structure-aware queries |\n| Process JSON | `jq` | - | `python`/`node` | jq: domain-specific language |\n| View file with syntax | `bat` | - | `cat` | bat: syntax highlighting, git diff |\n| List directory | `eza` | - | `ls` | eza: modern output, icons |\n| View git diff | `delta` | - | `git diff` | delta: side-by-side, syntax highlighting |\n| Navigate directories | `zoxide` | - | `cd` | zoxide: frecency-based jumping |\n| Fuzzy select | `fzf` | - | - | fzf: interactive filtering |\n| HTTP requests | `httpie` | - | `curl` | httpie: human-friendly syntax |\n\nSelection algorithm:\n1. Check detection results for preferred tool\n2. If available  use with optimal flags\n3. If unavailable  check fallback column\n4. If no fallback  use legacy with best-effort flags\n5. Note gap if preferred tool would significantly improve workflow\n\n</selection>\n\n<fallback>\n\nWhen preferred tool unavailable:\n\n**Minor improvement** (preferred 1030% better):\n- Use next best option silently\n- Don't interrupt workflow\n\n**Significant improvement** (preferred 2x+ better):\n- Use fallback\n- Surface suggestion: ` Alternative: {TOOL} would be {BENEFIT}  install with {COMMAND}`\n- Continue without blocking\n\n**Critical gap** (task extremely tedious with fallback):\n- Surface suggestion: ` Caution: {TOOL} recommended for this task  {FALLBACK} will be slow/limited`\n- Offer choice: install now, proceed anyway, defer task\n\nNever block on missing tools  graceful degradation always.\n\n</fallback>\n\n<research>\n\nTrigger research when:\n- Tool taking 3x+ longer than expected for task size\n- User explicitly asks for better approach\n- Task seems like it should have specialized tool\n- Current tool missing critical feature\n- New tool category needed (not in selection table)\n\nResearch workflow:\n1. Search for `{TASK} CLI tool 2025` or `{TASK} CLI tool 2024`\n2. Check GitHub trending in relevant category\n3. Evaluate candidates:\n   - Speed: benchmarks vs existing tools\n   - Ergonomics: default behavior, output format\n   - Maintenance: last commit, issue response time\n   - Install: complexity, dependencies\n   - Compatibility: OS support, integration\n\nPresent findings:\n- Tool name + one-line description\n- Key advantages over current approach\n- Installation command\n- Usage example for current task\n- Trade-offs or caveats\n\nIf research yields strong candidate  add to selection table for future reference.\n\n</research>\n\n<workflow>\n\nStandard flow:\n\n1. **Receive task**  categorize task type (find files, search content, process data)\n2. **Check detection**  run script if not yet run this session\n3. **Select tool**  use selection table + detection results\n4. **Execute**  run command with optimal flags\n5. **Evaluate**  if slow/frustrating  trigger research\n\nResearch flow:\n\n1. **Trigger identified**  surface to user with ` This seems slow  research alternatives?`\n2. **User confirms**  web search for modern tools\n3. **Evaluate candidates**  speed, ergonomics, maintenance\n4. **Present findings**  tool + advantages + install + example\n5. **Update knowledge**  add to selection table if strong fit\n\n</workflow>\n\n<examples>\n\n**Scenario: Search for authentication code**\n\nTask: Find all files containing \"authentication\"\nDetection: rg available\nSelection: Use `rg` over `grep`\n\n```bash\nrg \"authentication\" --type ts --type js\n```\n\n**Scenario: Find config files**\n\nTask: Find all YAML files in project\nDetection: fd available\nSelection: Use `fd` over `find`\n\n```bash\nfd -e yaml -e yml\n```\n\n**Scenario: Process API response**\n\nTask: Extract specific fields from JSON\nDetection: jq unavailable\nFallback: Use node/python\nSuggestion: ` Alternative: jq would simplify this  install with brew install jq`\n\n```bash\nnode -e \"console.log(JSON.parse(require('fs').readFileSync(0, 'utf-8')).field)\"\n```\n\n</examples>\n\n<rules>\n\nALWAYS:\n- Run detection script before recommending specific tools\n- Use selection table to map task to best available tool\n- Provide fallback when suggesting tools that might not be installed\n- Surface suggestions for significant improvements (2x+ better)\n- Trigger research when tool underperforms expectations\n\nNEVER:\n- Assume a tool is installed without checking detection results\n- Block workflow on missing non-essential tools\n- Recommend abandonware or unmaintained tools\n- Use legacy tools when modern alternatives are available\n- Skip fallback strategy when preferred tool missing\n\n</rules>\n\n<references>\n\n- [tool-catalog.md](references/tool-catalog.md)  comprehensive tool documentation\n- [alternatives.md](references/alternatives.md)  how to research new tools\n- [detection-script.md](references/detection-script.md)  detection script implementation\n\n</references>"
              }
            ]
          },
          {
            "name": "agent-kit",
            "description": "Skills for authoring Agent Skills (cross-tool) and platform-specific configuration for Claude Code, Codex, and other AI coding assistants",
            "source": "./agent-kit",
            "category": null,
            "version": "2.6.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add outfitter-dev/agents",
              "/plugin install agent-kit@outfitter"
            ],
            "signals": {
              "stars": 15,
              "forks": 0,
              "pushed_at": "2026-01-11T17:32:42Z",
              "created_at": "2025-08-30T16:37:06Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "claude-agent-development",
                "description": "This skill should be used when creating agents, writing agent frontmatter, configuring subagents, or when \"create agent\", \"agent.md\", \"subagent\", or \"Task tool\" are mentioned.",
                "path": "agent-kit/skills/claude-agent-development/SKILL.md",
                "frontmatter": {
                  "name": "claude-agent-development",
                  "version": "1.0.0",
                  "description": "This skill should be used when creating agents, writing agent frontmatter, configuring subagents, or when \"create agent\", \"agent.md\", \"subagent\", or \"Task tool\" are mentioned.",
                  "user-invocable": true
                },
                "content": "# Claude Agent Development\n\nCreate and validate specialized subagents that extend Claude Code with focused expertise.\n\n## Agents vs Skills\n\n**Critical distinction**:\n\n| Aspect         | Agents (This Skill)                         | Skills                                 |\n| -------------- | ------------------------------------------- | -------------------------------------- |\n| **Purpose**    | Specialized subagents with focused expertise | Capability packages with instructions  |\n| **Invocation** | Task tool (`subagent_type` parameter)       | Automatic (model-triggered by context) |\n| **Location**   | `agents/` directory                         | `skills/` directory                    |\n| **Structure**  | Single `.md` file with frontmatter          | Directory with `SKILL.md` + resources  |\n\nSee [agent-vs-skill.md](references/agent-vs-skill.md) for details.\n\n## Quick Start\n\n### Using Templates\n\nCopy a template from `templates/`:\n\n| Template          | Use When                                     |\n| ----------------- | -------------------------------------------- |\n| `basic.md`        | Simple agents with focused expertise         |\n| `advanced.md`     | Full-featured agents with all config options |\n\n### Scaffolding\n\n```bash\n./scripts/scaffold-agent.sh security-reviewer -t reviewer\n```\n\n## Workflow Overview\n\n1. **Discovery** - Define purpose, scope, and triggers\n2. **Design** - Choose archetype and configuration\n3. **Implementation** - Write frontmatter and instructions\n4. **Validation** - Verify against quality standards\n\n---\n\n## Phase 1: Discovery\n\nBefore writing code, clarify:\n\n- **Purpose**: What specialized expertise does this agent provide?\n- **Triggers**: What keywords/phrases should invoke it?\n- **Scope**: What does it do? What does it NOT do?\n- **Location**: Personal (`~/.claude/agents/`), project (`agents/`), or plugin?\n\n**Key questions**:\n- Is this a specialized role or a general capability? (Role = agent, Capability = skill)\n- What user phrases should trigger this agent?\n- What tools does it need access to?\n\n---\n\n## Phase 2: Design\n\n### Agent Archetypes\n\n| Type | Purpose | Typical Tools |\n|------|---------|---------------|\n| **Analyzer** | Examine without modifying | `Glob, Grep, Read, Skill, Task, TodoWrite` |\n| **Implementer** | Build and modify code | Full access (inherit) |\n| **Reviewer** | Provide feedback | `Glob, Grep, Read, Skill, Task, TodoWrite` |\n| **Tester** | Create and manage tests | `Glob, Grep, Read, Write, Edit, Bash, ...` |\n| **Researcher** | Find and synthesize info | `..., WebSearch, WebFetch` |\n| **Deployer** | Handle infrastructure | `..., Bash(kubectl *), Bash(docker *)` |\n\nSee [agent-types.md](references/agent-types.md) for details.\n\n### Frontmatter Schema\n\n```yaml\n---\nname: agent-name           # Required: kebab-case, matches filename\ndescription: |             # Required: when to use + triggers + examples\n  Use this agent when [conditions]. Triggers on [keywords].\n\n  <example>\n  Context: [Situation]\n  user: \"[User message]\"\n  assistant: \"I'll use the agent-name agent to [action].\"\n  </example>\nmodel: inherit             # Optional: inherit|haiku|sonnet|opus\ntools: Glob, Grep, Read    # Optional: restrict tools (default: inherit all)\nskills: tdd, debugging     # Optional: skills to auto-load (NOT inherited)\npermissionMode: default    # Optional: default|acceptEdits|bypassPermissions\n---\n```\n\nSee [frontmatter.md](references/frontmatter.md) for complete schema.\n\n### Model Selection\n\n| Model | When to Use |\n|-------|-------------|\n| `inherit` | Recommended default - adapts to parent context |\n| `haiku` | Fast exploration, simple tasks, low-latency |\n| `sonnet` | Balanced cost/capability (default if omitted) |\n| `opus` | Nuanced judgment, security/architecture review, irreversible decisions |\n\n### Tool Configuration\n\n**Philosophy**: Don't over-restrict. Only limit tools when there's a specific safety reason.\n\n**Baseline** (always include when restricting):\n```yaml\ntools: Glob, Grep, Read, Skill, Task, TodoWrite\n```\n\nSee [tools.md](references/tools.md) for patterns.\n\n---\n\n## Phase 3: Implementation\n\n### Agent File Structure\n\n```markdown\n---\nname: security-reviewer\ndescription: |\n  Use this agent for security vulnerability detection.\n  Triggers on security audits, OWASP, injection, XSS.\n\n  <example>\n  Context: User wants security review.\n  user: \"Review auth code for vulnerabilities\"\n  assistant: \"I'll use the security-reviewer agent.\"\n  </example>\nmodel: inherit\n---\n\n# Security Reviewer\n\nYou are a security expert specializing in [expertise].\n\n## Expertise\n\n- Domain expertise 1\n- Domain expertise 2\n\n## Process\n\n### Step 1: [Phase Name]\n- Action item\n- Action item\n\n### Step 2: [Phase Name]\n- Action item\n\n## Output Format\n\nFor each finding:\n- **Severity**: critical|high|medium|low\n- **Location**: file:line\n- **Issue**: Description\n- **Remediation**: How to fix\n\n## Constraints\n\n**Always:**\n- Required behavior\n\n**Never:**\n- Prohibited action\n```\n\n### Description Guidelines\n\nDescriptions are the most critical field for agent discovery:\n\n1. **Start with trigger conditions**: \"Use this agent when...\"\n2. **Include 3-5 trigger keywords**: specific terms users would say\n3. **Add 2-3 examples**: showing user request -> assistant delegation\n4. **Be specific**: avoid vague descriptions like \"helps with code\"\n\n### Best Practices\n\n**Single Responsibility**\n```yaml\n# Good: Focused\ndescription: SQL injection vulnerability detector\n\n# Bad: Too broad\ndescription: Security expert handling all issues\n```\n\n**Document Boundaries**\n```markdown\n## What I Don't Do\n- I analyze, not implement fixes\n- I review, not build from scratch\n```\n\n**Consistent Output Format**\n\nDefine structured output so results are predictable and parseable.\n\n---\n\n## Phase 4: Validation\n\nAfter creating an agent, validate against these checklists.\n\n### YAML Frontmatter Checks\n\n- [ ] Opens with `---` on line 1\n- [ ] Closes with `---` before content\n- [ ] `name` present and matches filename (without `.md`)\n- [ ] `description` present and non-empty\n- [ ] Uses spaces (not tabs) for indentation\n- [ ] `tools` uses comma-separated valid tool names\n- [ ] `model` is valid: `sonnet`, `opus`, `haiku`, or `inherit`\n\n### Naming Conventions\n\n- [ ] Kebab-case (lowercase-with-hyphens)\n- [ ] Follows `[role]-[specialty]` or `[specialty]` pattern\n- [ ] Specific, not generic\n- [ ] Concise (1-3 words, max 4)\n\n**Good**: `code-reviewer`, `test-runner`, `security-auditor`\n**Bad**: `helper`, `my-agent`, `the-best-agent`\n\n### Description Quality\n\n- [ ] **WHAT**: Explains what the agent does\n- [ ] **WHEN**: States when to invoke it\n- [ ] **TRIGGERS**: Includes 3-5 trigger keywords\n- [ ] **EXAMPLES**: Has 2-3 example conversations\n- [ ] Specific about agent's purpose (not vague)\n- [ ] Clear about scope\n\n**Anti-patterns**:\n- \"Helps with code\" - too vague\n- No trigger conditions\n- Missing keywords\n\n### System Prompt Quality\n\n- [ ] Clear role definition\n- [ ] Step-by-step process\n- [ ] Key practices or guidelines\n- [ ] Output format specification\n- [ ] Specific and actionable instructions\n- [ ] Constraints (what NOT to do)\n- [ ] Single responsibility focus\n\n**Anti-patterns**:\n- \"You are helpful\" - too vague\n- No process defined\n- Missing constraints\n- Scope creep\n\n### Tool Configuration\n\n- [ ] Field name is `tools:` (not `allowed-tools:`)\n- [ ] Comma-separated list\n- [ ] Tool names correctly spelled and case-sensitive\n- [ ] Includes baseline tools if restricting: `Glob, Grep, Read, Skill, Task, TodoWrite`\n- [ ] Tools appropriate for agent's purpose\n\n**Common patterns**:\n```yaml\n# Read-only\ntools: Glob, Grep, Read, Skill, Task, TodoWrite\n\n# Read-only + git\ntools: Glob, Grep, Read, Skill, Task, TodoWrite, Bash(git show:*), Bash(git diff:*)\n\n# Research\ntools: Glob, Grep, Read, Skill, Task, TodoWrite, WebSearch, WebFetch\n\n# Full access\n# (omit field to inherit all)\n```\n\n### Validation Report Format\n\n```markdown\n# Agent Validation Report: [Agent Name]\n\n## Summary\n- **Status**: PASS | FAIL | WARNINGS\n- **Location**: [path]\n- **Issues**: [count critical] / [count warnings]\n\n## Critical Issues (must fix)\n1. [Issue with specific fix]\n\n## Warnings (should fix)\n1. [Issue with specific fix]\n\n## Strengths\n- [What's done well]\n```\n\n---\n\n## Agent Scopes\n\n| Scope | Location | Priority | Visibility |\n|-------|----------|----------|------------|\n| Project | `agents/` | Highest | Team via git |\n| Personal | `~/.claude/agents/` | Medium | You only |\n| Plugin | `<plugin>/agents/` | Lowest | Plugin users |\n\nProject agents override personal agents with the same name.\n\n---\n\n## Testing Agents\n\n### Manual Testing\n\n1. Create agent file in `agents/`\n2. In Claude Code: \"Use the [agent-name] agent to [task]\"\n3. Claude invokes via Task tool\n4. Review results\n\n### Verify Discovery\n\nAgents are loaded from:\n- `~/.claude/agents/` (personal)\n- `./agents/` (project)\n- Plugins (installed)\n\nDebug with: `claude --debug`\n\n---\n\n## Troubleshooting\n\n### Agent Not Being Invoked\n\n- Check file location: `agents/agent-name.md`\n- Validate YAML frontmatter syntax\n- Make description more specific with trigger keywords\n- Add example conversations\n\n### Wrong Agent Invoked\n\n- Make description more distinct\n- Add specific trigger keywords\n- Include negative examples (what NOT to use it for)\n\n### Agent Has Wrong Tools\n\nPrefer `model: inherit` to use parent's tool access. Only specify `tools:` when agent needs different access.\n\n---\n\n## References\n\n| Reference | Content |\n|-----------|---------|\n| [agent-vs-skill.md](references/agent-vs-skill.md) | Agents vs Skills distinction |\n| [frontmatter.md](references/frontmatter.md) | YAML schema and fields |\n| [tools.md](references/tools.md) | Tool configuration patterns |\n| [task-tool.md](references/task-tool.md) | Task tool integration |\n| [discovery.md](references/discovery.md) | How agents are found and loaded |\n| [agent-types.md](references/agent-types.md) | Archetypes: analysis, implementation, etc. |\n| [patterns.md](references/patterns.md) | Best practices and multi-agent patterns |\n| [todowrite.md](references/todowrite.md) | TodoWrite patterns for agents |\n| [advanced-features.md](references/advanced-features.md) | Resumable agents, CLI config |\n\nSee [EXAMPLES.md](EXAMPLES.md) for complete real-world agent examples.\nSee `templates/` for starter templates.\n\n---\n\n## Related Skills\n\n- **skills-development**: Create Skills (different from agents)\n- **claude-plugin-development**: Bundle agents into plugins"
              },
              {
                "name": "claude-code-configuration",
                "description": "This skill should be used when configuring Claude, setting up MCP servers, or when \"settings.json\", \"claude_desktop_config\", \"MCP server\", or \"Claude config\" are mentioned.",
                "path": "agent-kit/skills/claude-code-configuration/SKILL.md",
                "frontmatter": {
                  "name": "claude-code-configuration",
                  "description": "This skill should be used when configuring Claude, setting up MCP servers, or when \"settings.json\", \"claude_desktop_config\", \"MCP server\", or \"Claude config\" are mentioned.",
                  "version": "1.0.0"
                },
                "content": "# Claude Config Management\n\nManages configuration files for Claude Desktop and Claude Code, including MCP server setup, project settings, and developer options.\n\n## Configuration File Locations\n\n**Claude Desktop (macOS):**\n- Config: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Logs: `~/Library/Logs/Claude/`\n- Developer settings: `~/Library/Application Support/Claude/developer_settings.json`\n\n**Claude Desktop (Windows):**\n- Config: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- Logs: `%APPDATA%\\Claude\\Logs\\`\n\n**Claude Code (Project-specific):**\n- Settings: `.claude/settings.json`\n- Plugin marketplace: `.claude-plugin/marketplace.json`\n\n## Claude Desktop Configuration\n\n### Basic Structure\n\n```json\n{\n  \"mcpServers\": {\n    \"server-name\": {\n      \"command\": \"command-to-run\",\n      \"args\": [\"arg1\", \"arg2\"],\n      \"env\": {\n        \"VAR_NAME\": \"value\"\n      }\n    }\n  }\n}\n```\n\n### Important Notes\n\n- **Always use absolute paths** - Working directory may be undefined\n- **Windows paths**: Use forward slashes or double backslashes\n- **Restart required**: Restart Claude Desktop after configuration changes\n- **Environment variables**: Limited by default (USER, HOME, PATH); set explicitly in `env`\n\n## Claude Code Project Settings\n\n### .claude/settings.json\n\n```json\n{\n  \"enabledPlugins\": [\"plugin-name\"],\n  \"extraKnownMarketplaces\": {\n    \"team-tools\": {\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"company/claude-plugins\"\n      }\n    }\n  }\n}\n```\n\n### Team Configuration\n\nAutomatically install marketplaces when team members trust the folder:\n\n```json\n{\n  \"extraKnownMarketplaces\": {\n    \"company-tools\": {\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"company/plugins\"\n      }\n    },\n    \"project-tools\": {\n      \"source\": {\n        \"source\": \"git\",\n        \"url\": \"https://git.company.com/project-plugins.git\"\n      }\n    }\n  }\n}\n```\n\n## Quick Validation\n\n```bash\n# Validate JSON syntax\njq empty ~/Library/Application\\ Support/Claude/claude_desktop_config.json\njq empty .claude/settings.json\n\n# Check server names\njq -r '.mcpServers | keys[]' ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n## Quick Troubleshooting\n\nIf MCP server not loading:\n1. Validate JSON syntax\n2. Verify command paths are absolute\n3. Check environment variables are set\n4. Review logs: `~/Library/Logs/Claude/mcp*.log`\n5. Restart Claude Desktop\n\n## References\n\nDetailed documentation for specific scenarios:\n\n- **[MCP Patterns](references/mcp-patterns.md)** - Server configuration examples (Python, Node.js, environment variables)\n- **[Troubleshooting](references/troubleshooting.md)** - Common issues, log locations, debugging tools\n- **[Workflows](references/workflows.md)** - Step-by-step guides for adding servers, team setup, migration\n\n## Next Steps\n\n- See [EXAMPLES.md](EXAMPLES.md) for real-world configuration examples"
              },
              {
                "name": "claude-command-authoring",
                "description": "This skill should be used when creating slash commands, writing command files, or when \"/command\", \".claude/commands\", \"$ARGUMENTS\", or \"create command\" are mentioned.",
                "path": "agent-kit/skills/claude-command-authoring/SKILL.md",
                "frontmatter": {
                  "name": "claude-command-authoring",
                  "version": "2.0.0",
                  "description": "This skill should be used when creating slash commands, writing command files, or when \"/command\", \".claude/commands\", \"$ARGUMENTS\", or \"create command\" are mentioned.",
                  "user-invocable": true,
                  "allowed-tools": "Read Write Edit Grep Glob Bash TodoWrite"
                },
                "content": "# Claude Command Authoring\n\nCreate custom slash commands that extend Claude Code with reusable prompts and workflows.\n\n## Commands vs Skills\n\n**Critical distinction**:\n\n| Aspect         | Commands (This Skill)                   | Skills                                 |\n| -------------- | --------------------------------------- | -------------------------------------- |\n| **Purpose**    | Reusable prompts invoked by users       | Capability packages auto-triggered     |\n| **Invocation** | Explicit: `/command-name args`          | Automatic (model-triggered by context) |\n| **Location**   | `commands/` directory                   | `skills/` directory with `SKILL.md`    |\n| **Structure**  | Single `.md` file                       | Directory with resources               |\n| **Arguments**  | `$1`, `$2`, `$ARGUMENTS`                | No argument system                     |\n\nCommands are user-initiated. Skills are model-initiated.\n\n---\n\n## Quick Start\n\n### Basic Command\n\nCreate `.claude/commands/review.md`:\n\n```markdown\n---\ndescription: Review code for best practices and issues\n---\n\nReview the following code for:\n- Code quality and readability\n- Potential bugs or edge cases\n- Performance considerations\n- Security concerns\n```\n\nUse with: `/review`\n\n### Command with Arguments\n\nCreate `.claude/commands/fix-issue.md`:\n\n```markdown\n---\ndescription: Fix a specific GitHub issue\nargument-hint: <issue-number>\n---\n\nFix issue #$1 following our coding standards.\nReview the issue, implement a fix, add tests, and create a commit.\n```\n\nUse with: `/fix-issue 123`\n\n### Command with Context\n\nCreate `.claude/commands/commit.md`:\n\n```markdown\n---\ndescription: Create git commit from staged changes\nallowed-tools: Bash(git *)\n---\n\n## Context\n\nCurrent branch: !`git branch --show-current`\nStaged changes: !`git diff --staged`\nRecent commits: !`git log --oneline -5`\n\n## Task\n\nCreate a commit with a clear message based on the staged changes.\n```\n\nUse with: `/commit`\n\n---\n\n## Workflow Overview\n\n1. **Discovery** - Define purpose, scope, and target users\n2. **Design** - Choose features and configuration\n3. **Implementation** - Write frontmatter and content\n4. **Validation** - Verify against quality standards\n\n---\n\n## Phase 1: Discovery\n\nBefore writing code, clarify:\n\n- **Purpose**: What task does this command automate?\n- **Scope**: Project-specific or personal workflow?\n- **Arguments**: What inputs does it need?\n- **Tools**: What operations will it perform?\n\n**Key questions**:\n- Will this be shared with the team (project) or personal use?\n- Does it require bash execution or file references?\n- Should tool access be restricted for safety?\n\n---\n\n## Phase 2: Design\n\n### Command Scopes\n\n| Scope | Location | Visibility | Use Case |\n|-------|----------|------------|----------|\n| Project | `.claude/commands/` | Team via git | Shared workflows |\n| Personal | `~/.claude/commands/` | You only | Individual preferences |\n| Plugin | `<plugin>/commands/` | Plugin users | Distributed via marketplace |\n\nProject commands show \"(project)\" in `/help`. Personal show \"(user)\".\n\n### Core Features\n\n| Feature | Syntax | Purpose |\n|---------|--------|---------|\n| Arguments | `$1`, `$2`, `$ARGUMENTS` | Dynamic input from user |\n| Bash execution | `!`backtick`command`backtick | Include shell output in context |\n| File references | `@path/to/file` | Include file contents |\n| Tool restrictions | `allowed-tools:` | Limit Claude's capabilities |\n\n### Frontmatter Schema\n\n```yaml\n---\ndescription: Brief description for /help      # Required for discovery\nargument-hint: <required> [optional]          # Shown in autocomplete\nallowed-tools: Read, Grep, Bash(git *)        # Restrict tool access\nmodel: claude-3-5-haiku-20241022             # Override model\ndisable-model-invocation: true                # Prevent SlashCommand tool\n---\n```\n\nSee [frontmatter.md](references/frontmatter.md) for complete schema.\n\n---\n\n## Phase 3: Implementation\n\n### File Structure\n\n```markdown\n---\ndescription: Deploy to environment with validation\nargument-hint: <environment> [--skip-tests]\nallowed-tools: Bash(*), Read\n---\n\n# Deployment\n\nTarget: $1\nOptions: $2\n\n## Pre-flight Checks\n\nEnvironment: !`echo \"$1\" | grep -E \"^(staging|production)$\" || echo \"Invalid\"`\nTests: !`[[ \"$2\" == *\"--skip-tests\"* ]] && echo \"Skipped\" || bun test`\n\n## Task\n\nBased on validation above, proceed with deployment or explain issues.\n```\n\n### Argument Patterns\n\n**Positional arguments** (`$1`, `$2`, `$3`):\n```markdown\nCompare file $1 with file $2 and summarize differences.\n```\nUsage: `/compare old.ts new.ts`\n\n**All arguments** (`$ARGUMENTS`):\n```markdown\nFix the following issues: $ARGUMENTS\n```\nUsage: `/fix memory leak in auth slow query in search`\n\n**Combined with file references**:\n```markdown\nAnalyze this file: @$1\n```\nUsage: `/analyze src/main.ts`\n\nSee [arguments.md](references/arguments.md) for advanced patterns.\n\n### Bash Execution\n\nExecute commands and include output:\n\n```markdown\n## Git Context\nBranch: !`git branch --show-current`\nStatus: !`git status --short`\nDiff: !`git diff --stat`\n\nBased on the above, suggest next steps.\n```\n\n**Important**: Output is truncated at 15,000 characters by default. Use `SLASH_COMMAND_TOOL_CHAR_BUDGET` to adjust.\n\nSee [bash-execution.md](references/bash-execution.md) for patterns.\n\n### File References\n\nInclude file contents directly:\n\n```markdown\nReview this configuration:\n- Package: @package.json\n- TypeScript: @tsconfig.json\n- User input: @$1\n```\n\nSee [file-references.md](references/file-references.md) for details.\n\n### Tool Permissions\n\nRestrict what Claude can do:\n\n```yaml\n# Read-only analysis\nallowed-tools: Read, Grep, Glob\n\n# Git operations only\nallowed-tools: Bash(git *), Read\n\n# Full bash with restrictions\nallowed-tools: Bash(bun *), Bash(npm *), Read, Write, Edit\n```\n\nSee [permissions.md](references/permissions.md) for patterns.\n\n---\n\n## Phase 4: Validation\n\nAfter creating a command, validate against these checklists.\n\n### Frontmatter Checks\n\n- [ ] Opens with `---` on line 1, closes with `---`\n- [ ] `description` present and action-oriented\n- [ ] `argument-hint` uses `<required>` and `[optional]` syntax\n- [ ] `allowed-tools` uses correct names (case-sensitive)\n- [ ] Uses spaces (not tabs) for indentation\n\n### Naming Conventions\n\n- [ ] Kebab-case filename: `my-command.md`\n- [ ] No spaces or special characters\n- [ ] Action-oriented: verb-noun pattern preferred\n- [ ] Concise: 1-3 words\n\n**Good**: `review-pr.md`, `deploy-staging.md`, `fix-issue.md`\n**Bad**: `my command.md`, `DoStuff.md`, `helper.md`\n\n### Description Quality\n\n- [ ] Action-oriented (starts with verb)\n- [ ] Specific about what it does\n- [ ] Under 80 characters\n- [ ] Helpful for `/help` discovery\n\n**Good**: \"Deploy to staging with health checks and Slack notification\"\n**Bad**: \"Deploy stuff\" or \"Helps with deployment\"\n\n### Content Quality\n\n- [ ] Clear instructions for Claude\n- [ ] Proper argument handling if used\n- [ ] Bash commands validated (test in terminal first)\n- [ ] File paths relative to project root\n- [ ] Error handling for edge cases\n\n### Validation Report Format\n\n```markdown\n# Command Validation: [command-name]\n\n## Summary\n- **Status**: PASS | FAIL | WARNINGS\n- **Location**: [path]\n- **Issues**: [count]\n\n## Critical Issues (must fix)\n1. [Issue with fix]\n\n## Warnings (should fix)\n1. [Issue with fix]\n\n## Strengths\n- [What's done well]\n```\n\n---\n\n## Namespacing\n\nOrganize commands in subdirectories:\n\n```\n.claude/commands/\n+-- frontend/\n|   +-- component.md      # /component (project:frontend)\n|   +-- styling.md        # /styling (project:frontend)\n+-- backend/\n|   +-- migration.md      # /migration (project:backend)\n+-- review.md             # /review (project)\n```\n\nThe namespace appears in `/help` but commands are invoked without prefix: `/component` or `/frontend/component`.\n\nSee [namespacing.md](references/namespacing.md) for organization patterns.\n\n---\n\n## Testing Commands\n\n1. **Create** the command file\n2. **Verify** with `/help` - should see your command listed\n3. **Test** basic invocation: `/your-command`\n4. **Test** with arguments: `/your-command arg1 arg2`\n5. **Verify** tool restrictions if using `allowed-tools`\n\n### Debug Mode\n\n```bash\nclaude --debug\n```\n\nShows command loading and execution details.\n\n---\n\n## Troubleshooting\n\n### Command Not Found\n\n- Verify file location: `.claude/commands/name.md`\n- Check filename: lowercase, `.md` extension, no spaces\n- Restart Claude Code or use `/clear`\n\n### Arguments Not Working\n\n- Use `$1`, `$2` not `{1}`, `{2}`\n- Use `$ARGUMENTS` for all arguments\n- Quote arguments with spaces: `/cmd \"arg with spaces\"`\n\n### Bash Commands Failing\n\n- Use `!` before backticks: `` !`command` ``\n- Test command in terminal first\n- Check output length (15k char limit)\n- Verify `allowed-tools` includes `Bash`\n\n### Tool Restrictions Not Applied\n\n- Check YAML syntax (no tabs, proper quoting)\n- Tool names are case-sensitive: `Read` not `read`\n- Use wildcards for bash: `Bash(git *)`\n\n---\n\n## References\n\n| Reference | Content |\n|-----------|---------|\n| [frontmatter.md](references/frontmatter.md) | Complete frontmatter schema and fields |\n| [arguments.md](references/arguments.md) | Argument handling and patterns |\n| [bash-execution.md](references/bash-execution.md) | Shell command execution |\n| [file-references.md](references/file-references.md) | File inclusion syntax |\n| [permissions.md](references/permissions.md) | Tool restriction patterns |\n| [namespacing.md](references/namespacing.md) | Directory organization |\n| [sdk-integration.md](references/sdk-integration.md) | Agent SDK usage |\n| [community.md](references/community.md) | Community examples and resources |\n\nSee [EXAMPLES.md](EXAMPLES.md) for complete real-world examples.\nSee `scripts/` for scaffolding and validation utilities.\n\n---\n\n## Related Skills\n\n- **claude-hook-authoring**: Add automation triggers to command workflows\n- **claude-plugin-development**: Bundle commands into distributable plugins\n- **claude-code-configuration**: Configure Claude Code settings globally"
              },
              {
                "name": "claude-hook-authoring",
                "description": "This skill should be used when creating hooks, automating workflows, or when \"PreToolUse\", \"PostToolUse\", \"hooks.json\", \"event handler\", or \"create hook\" are mentioned.",
                "path": "agent-kit/skills/claude-hook-authoring/SKILL.md",
                "frontmatter": {
                  "name": "claude-hook-authoring",
                  "version": "2.0.0",
                  "description": "This skill should be used when creating hooks, automating workflows, or when \"PreToolUse\", \"PostToolUse\", \"hooks.json\", \"event handler\", or \"create hook\" are mentioned.",
                  "user-invocable": true
                },
                "content": "# Claude Hook Authoring\n\nCreate event hooks that automate workflows, validate operations, and respond to Claude Code events.\n\n## Hook Types\n\nTwo hook execution types:\n\n| Type | Best For | Example |\n|------|----------|---------|\n| **prompt** | Complex reasoning, context-aware validation | LLM evaluates if action is safe |\n| **command** | Deterministic checks, external tools, performance | Bash script validates paths |\n\n**Prompt hooks** (recommended for complex logic):\n\n```json\n{\n  \"type\": \"prompt\",\n  \"prompt\": \"Evaluate if this file write is safe: $TOOL_INPUT. Check for sensitive paths, credentials, path traversal. Return 'allow' or 'deny' with reason.\",\n  \"timeout\": 30\n}\n```\n\n**Command hooks** (for deterministic/fast checks):\n\n```json\n{\n  \"type\": \"command\",\n  \"command\": \"${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\",\n  \"timeout\": 10\n}\n```\n\n## Hook Events\n\n| Event | When | Can Block | Common Uses |\n|-------|------|-----------|-------------|\n| **PreToolUse** | Before tool executes | Yes | Validate commands, check paths, enforce policies |\n| **PostToolUse** | After tool succeeds | No | Auto-format, run linters, update docs |\n| **PostToolUseFailure** | After tool fails | No | Error logging, retry logic, notifications |\n| **PermissionRequest** | Permission dialog shown | Yes | Auto-allow/deny based on rules |\n| **UserPromptSubmit** | User submits prompt | No | Add context, log activity, augment prompts |\n| **Notification** | Claude sends notification | No | External alerts, logging |\n| **Stop** | Main agent finishes | No | Cleanup, completion notifications |\n| **SubagentStart** | Subagent spawns | No | Track subagent usage |\n| **SubagentStop** | Subagent finishes | No | Log results, trigger follow-ups |\n| **PreCompact** | Before context compacts | No | Backup conversation, preserve context |\n| **SessionStart** | Session starts/resumes | No | Load context, show status, init resources |\n| **SessionEnd** | Session ends | No | Cleanup, save state, log metrics |\n\nSee [references/hook-types.md](references/hook-types.md) for detailed documentation of each event.\n\n## Quick Start\n\n### Auto-Format TypeScript\n\n```json\n{\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit(*.ts|*.tsx)\",\n        \"hooks\": [{\n          \"type\": \"command\",\n          \"command\": \"biome check --write \\\"$file\\\"\",\n          \"timeout\": 10\n        }]\n      }\n    ]\n  }\n}\n```\n\n### Block Dangerous Commands\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [{\n          \"type\": \"command\",\n          \"command\": \"$CLAUDE_PROJECT_DIR/.claude/hooks/validate-bash.sh\",\n          \"timeout\": 5\n        }]\n      }\n    ]\n  }\n}\n```\n\n**validate-bash.sh**:\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nINPUT=$(cat)\nCOMMAND=$(echo \"$INPUT\" | jq -r '.tool_input.command // empty')\n\nif echo \"$COMMAND\" | grep -qE '\\brm\\s+-rf\\s+/'; then\n  echo \"Dangerous command blocked: rm -rf /\" >&2\n  exit 2  # Exit 2 = block and show error to Claude\nfi\n\nexit 0\n```\n\n### Smart Validation with Prompt Hook\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [{\n          \"type\": \"prompt\",\n          \"prompt\": \"Analyze this file operation for safety. Check: 1) No sensitive paths (/etc, ~/.ssh), 2) No credentials in content, 3) No path traversal (..). Tool input: $TOOL_INPUT. Respond with JSON: {\\\"decision\\\": \\\"allow|deny\\\", \\\"reason\\\": \\\"...\\\"}\",\n          \"timeout\": 30\n        }]\n      }\n    ]\n  }\n}\n```\n\n## Configuration Locations\n\n| Location | Scope | Committed |\n|----------|-------|-----------|\n| `.claude/settings.json` | Project (team-shared) | Yes |\n| `.claude/settings.local.json` | Project (local only) | No |\n| `~/.claude/settings.json` | Personal (all projects) | No |\n| `plugin/hooks/hooks.json` | Plugin | Yes |\n\n### Plugin Format (hooks.json)\n\nUses wrapper structure:\n\n```json\n{\n  \"description\": \"Plugin hooks for auto-formatting\",\n  \"hooks\": {\n    \"PostToolUse\": [...]\n  }\n}\n```\n\n### Settings Format (settings.json)\n\nDirect structure (no wrapper):\n\n```json\n{\n  \"hooks\": {\n    \"PostToolUse\": [...]\n  }\n}\n```\n\n## Matchers\n\nMatchers determine which tool invocations trigger the hook. Case-sensitive.\n\n```json\n{\"matcher\": \"Write\"}                    // Exact match\n{\"matcher\": \"Edit|Write\"}               // Multiple tools (OR)\n{\"matcher\": \"*\"}                        // All tools\n{\"matcher\": \"Write(*.py)\"}              // File pattern\n{\"matcher\": \"Write|Edit(*.ts|*.tsx)\"}   // Multiple + pattern\n{\"matcher\": \"mcp__memory__.*\"}          // MCP server tools\n{\"matcher\": \"mcp__github__create_issue\"} // Specific MCP tool\n```\n\n**Lifecycle hooks** (SessionStart, SessionEnd, Stop, Notification) use special matchers:\n\n```json\n// SessionStart matchers\n{\"matcher\": \"startup\"}   // Initial start\n{\"matcher\": \"resume\"}    // --resume or --continue\n{\"matcher\": \"clear\"}     // After /clear\n{\"matcher\": \"compact\"}   // After compaction\n\n// PreCompact matchers\n{\"matcher\": \"manual\"}    // User triggered /compact\n{\"matcher\": \"auto\"}      // Automatic compaction\n```\n\nSee [references/matchers.md](references/matchers.md) for advanced patterns.\n\n## Input Format\n\nAll hooks receive JSON on stdin:\n\n```json\n{\n  \"session_id\": \"abc123\",\n  \"transcript_path\": \"/path/to/transcript.jsonl\",\n  \"cwd\": \"/current/working/directory\",\n  \"hook_event_name\": \"PreToolUse\",\n  \"permission_mode\": \"ask\",\n  \"tool_name\": \"Write\",\n  \"tool_input\": {\n    \"file_path\": \"/project/src/file.ts\",\n    \"content\": \"export const foo = 'bar';\"\n  }\n}\n```\n\n**Event-specific fields**:\n- Tool hooks: `tool_name`, `tool_input`, `tool_result` (PostToolUse)\n- UserPromptSubmit: `user_prompt`\n- Stop/SubagentStop: `reason`\n\n**Prompt hooks** access fields via: `$TOOL_INPUT`, `$TOOL_RESULT`, `$USER_PROMPT`\n\n### Reading Input\n\n**Bash**:\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // empty')\n```\n\n**Bun/TypeScript**:\n\n```typescript\n#!/usr/bin/env bun\nconst input = await Bun.stdin.json();\nconst toolName = input.tool_name;\nconst filePath = input.tool_input?.file_path;\n```\n\n## Output Format\n\n### Exit Codes (Simple)\n\n```bash\nexit 0   # Success, continue execution\nexit 2   # Block operation (PreToolUse only), stderr shown to Claude\nexit 1   # Warning, stderr shown to user, continues\n```\n\n### JSON Output (Advanced)\n\n```json\n{\n  \"continue\": true,\n  \"suppressOutput\": false,\n  \"systemMessage\": \"Context for Claude\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"allow|deny|ask\",\n    \"permissionDecisionReason\": \"Explanation\",\n    \"updatedInput\": {\"modified\": \"field\"}\n  }\n}\n```\n\n**PreToolUse** can modify tool input via `updatedInput` and control permissions via `permissionDecision`.\n\n## Environment Variables\n\n| Variable | Availability | Description |\n|----------|--------------|-------------|\n| `$CLAUDE_PROJECT_DIR` | All hooks | Project root directory |\n| `$CLAUDE_PLUGIN_ROOT` | Plugin hooks | Plugin root (use for portable paths) |\n| `$file` | PostToolUse (Write/Edit) | Path to affected file |\n| `$CLAUDE_ENV_FILE` | SessionStart | Write env vars here to persist |\n| `$CLAUDE_CODE_REMOTE` | All hooks | Set if running in remote context |\n\n**Plugin hooks** should always use `${CLAUDE_PLUGIN_ROOT}` for portability:\n\n```json\n{\n  \"command\": \"${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\"\n}\n```\n\n**SessionStart** can persist environment variables:\n\n```bash\n#!/usr/bin/env bash\n# Persist variables for the session\necho \"export PROJECT_TYPE=nodejs\" >> \"$CLAUDE_ENV_FILE\"\necho \"export API_URL=https://api.example.com\" >> \"$CLAUDE_ENV_FILE\"\n```\n\n## Component-Scoped Hooks\n\nSkills, agents, and commands can define hooks in frontmatter. These hooks only run when the component is active.\n\n**Supported events**: PreToolUse, PostToolUse, Stop\n\n### Skill with Hooks\n\n```yaml\n---\nname: my-skill\ndescription: Skill with validation hooks\nhooks:\n  PreToolUse:\n    - matcher: \"Write|Edit\"\n      hooks:\n        - type: prompt\n          prompt: \"Validate this write operation for the skill context...\"\n---\n```\n\n### Agent with Hooks\n\n```yaml\n---\nname: security-reviewer\nmodel: sonnet\nhooks:\n  PreToolUse:\n    - matcher: \"Bash\"\n      hooks:\n        - type: command\n          command: \"${CLAUDE_PLUGIN_ROOT}/scripts/validate-bash.sh\"\n  Stop:\n    - matcher: \"*\"\n      hooks:\n        - type: prompt\n          prompt: \"Verify the security review is complete...\"\n---\n```\n\n## Execution Model\n\n**Parallel execution**: All matching hooks run in parallel, not sequentially.\n\n```json\n{\n  \"PreToolUse\": [{\n    \"matcher\": \"Write\",\n    \"hooks\": [\n      {\"type\": \"command\", \"command\": \"check1.sh\"},  // Runs in parallel\n      {\"type\": \"command\", \"command\": \"check2.sh\"},  // Runs in parallel\n      {\"type\": \"prompt\", \"prompt\": \"Validate...\"}   // Runs in parallel\n    ]\n  }]\n}\n```\n\n**Implications**:\n- Hooks cannot see each other's output\n- Non-deterministic ordering\n- Design for independence\n\n**Hot-swap limitations**: Hook changes require restarting Claude Code. Editing `hooks.json` or hook scripts does not affect the current session.\n\n## Security Best Practices\n\n1. **Validate all input** - Check for path traversal, sensitive paths, injection\n2. **Quote shell variables** - Always use `\"$VAR\"` not `$VAR`\n3. **Set timeouts** - Prevent hanging hooks (default: 60s command, 30s prompt)\n4. **Use absolute paths** - Via `$CLAUDE_PROJECT_DIR` or `${CLAUDE_PLUGIN_ROOT}`\n5. **Handle errors gracefully** - Use `set -euo pipefail` in bash\n6. **Don't log sensitive data** - Filter credentials, tokens, API keys\n\nSee [references/security.md](references/security.md) for detailed security patterns.\n\n## Debugging\n\n```bash\n# Run Claude with debug output\nclaude --debug\n\n# Test hook manually\necho '{\"tool_name\": \"Write\", \"tool_input\": {\"file_path\": \"test.ts\"}}' | ./.claude/hooks/my-hook.sh\n\n# Check transcript for hook execution\n# Press Ctrl+R in Claude Code to view transcript\n```\n\n**Common issues**:\n- Hook not firing: Check matcher syntax, restart Claude Code\n- Permission errors: `chmod +x script.sh`\n- Timeout: Increase timeout value or optimize script\n\n## Workflow Patterns\n\n### Pre-Commit Quality Gate\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\"type\": \"command\", \"command\": \"./.claude/hooks/validate-paths.sh\"},\n          {\"type\": \"command\", \"command\": \"./.claude/hooks/check-sensitive.sh\"}\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit(*.ts)\",\n        \"hooks\": [\n          {\"type\": \"command\", \"command\": \"biome check --write \\\"$file\\\"\"},\n          {\"type\": \"command\", \"command\": \"tsc --noEmit \\\"$file\\\"\"}\n        ]\n      }\n    ]\n  }\n}\n```\n\n### Context Injection\n\n```json\n{\n  \"hooks\": {\n    \"SessionStart\": [{\n      \"matcher\": \"startup\",\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"echo \\\"Branch: $(git branch --show-current)\\\" && git status --short\"\n      }]\n    }],\n    \"UserPromptSubmit\": [{\n      \"matcher\": \"*\",\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"echo \\\"Time: $(date '+%Y-%m-%d %H:%M %Z')\\\"\"\n      }]\n    }]\n  }\n}\n```\n\n## References\n\n- [references/hook-types.md](references/hook-types.md) - Detailed documentation for each hook event\n- [references/matchers.md](references/matchers.md) - Advanced matcher patterns and MCP tools\n- [references/security.md](references/security.md) - Security best practices and validation patterns\n- [references/schema.md](references/schema.md) - Complete configuration schema reference\n- [references/examples.md](references/examples.md) - Real-world hook implementations\n\n## External Resources\n\n- [Official Hooks Reference](https://code.claude.com/docs/en/hooks)\n- [Hooks Guide](https://code.claude.com/docs/en/hooks-guide)\n- [Community Examples (disler)](https://github.com/disler/claude-code-hooks-mastery)\n- [Claude Code Showcase](https://github.com/ChrisWiles/claude-code-showcase)"
              },
              {
                "name": "claude-plugin-development",
                "description": "This skill should be used when creating plugins, publishing to marketplaces, or when \"plugin.json\", \"marketplace\", \"create plugin\", or \"distribute plugin\" are mentioned.",
                "path": "agent-kit/skills/claude-plugin-development/SKILL.md",
                "frontmatter": {
                  "name": "claude-plugin-development",
                  "description": "This skill should be used when creating plugins, publishing to marketplaces, or when \"plugin.json\", \"marketplace\", \"create plugin\", or \"distribute plugin\" are mentioned.",
                  "version": "1.0.0",
                  "user-invocable": true
                },
                "content": "# Claude Plugin Development\n\nComplete lifecycle for developing, validating, and distributing Claude Code plugins.\n\n## Quick Start\n\n```bash\n# 1. Scaffold plugin\n./scripts/scaffold-plugin.sh my-plugin --with-commands\n\n# 2. Add components (commands, agents, hooks, skills)\n# 3. Test locally\n/plugin marketplace add ./my-plugin\n/plugin install my-plugin@my-plugin\n\n# 4. Distribute\ngit push origin main --tags\n```\n\n## Lifecycle Overview\n\n```\nDiscovery -> Init -> Components -> Validate -> Distribute -> Marketplace\n    |         |          |            |            |             |\n    v         v          v            v            v             v\n Purpose   Scaffold   Commands    Structure    Package      Catalog\n  Scope    plugin.json  Agents     Testing     Version      Publish\n  Type      README      Hooks      Quality     Release       Share\n```\n\n## Phase 1: Discovery\n\nBefore creating a plugin, clarify:\n\n| Question | Impact |\n|----------|--------|\n| What problem does this solve? | Plugin scope and features |\n| Who will use it? | Distribution method |\n| What components are needed? | Commands, agents, hooks, MCP servers |\n| Where will it live? | Personal, project, or marketplace |\n\n## Phase 2: Initialization\n\n### Minimal Plugin Structure\n\n```\nmy-plugin/\n plugin.json          # Required: metadata\n README.md            # Required for distribution\n commands/            # Optional components\n```\n\n### plugin.json (Required)\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Brief description of what this plugin does\",\n  \"author\": {\n    \"name\": \"Your Name\",\n    \"email\": \"you@example.com\"\n  },\n  \"license\": \"MIT\"\n}\n```\n\n### Using the Scaffold Script\n\n```bash\n./scripts/scaffold-plugin.sh my-plugin \\\n  --author \"Your Name\" \\\n  --with-commands \\\n  --with-agent \\\n  --with-hooks\n```\n\nSee [references/structure.md](references/structure.md) for complete plugin structure and plugin.json schema.\n\n## Phase 3: Components\n\nAdd components based on plugin needs. For detailed component authoring, load the appropriate skill:\n\n### Slash Commands\n\nCreate custom commands in `commands/` directory.\n\n**Example: commands/review.md**\n\n```markdown\n---\ndescription: \"Review code for quality issues\"\n---\n\nReview the following code: {{0}}\n\nCheck for:\n- Code style and formatting\n- Potential bugs\n- Performance issues\n- Security concerns\n```\n\nFor complex commands, load the **claude-command-authoring** skill.\n\n### Custom Agents\n\nDefine specialized agents in `agents/` directory.\n\n**Example: agents/security-reviewer.md**\n\n```markdown\n---\nname: security-reviewer\ndescription: \"Security-focused code reviewer\"\n---\n\nYou are a security expert. When reviewing code:\n1. Check for vulnerabilities\n2. Verify input validation\n3. Review authentication flows\n4. Report issues with severity levels\n```\n\nFor agent design patterns, load the **claude-agent-development** skill.\n\n### Event Hooks\n\nReact to Claude Code events via plugin.json:\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/validate.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n**Hook types:** PreToolUse, PostToolUse, PrePromptSubmit, PostPromptSubmit\n\nFor hook implementation, load the **claude-hook-authoring** skill.\n\n### Skills\n\nAdd reusable methodology patterns in `skills/` directory.\n\nFor skill authoring, load the **skills-development** skill.\n\n### MCP Servers\n\nIntegrate MCP servers for external capabilities:\n\n```json\n{\n  \"mcpServers\": {\n    \"my-server\": {\n      \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/my-server\",\n      \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"],\n      \"env\": {\n        \"API_KEY\": \"${MY_API_KEY}\"\n      }\n    }\n  }\n}\n```\n\n**Path variables:**\n- `${CLAUDE_PLUGIN_ROOT}` - Plugin installation directory\n- `${MY_API_KEY}` - Environment variable expansion\n\n## Phase 4: Validation\n\nBefore distribution, validate the plugin:\n\n### Validation Checklist\n\n**Structure:**\n- [ ] plugin.json exists and is valid JSON\n- [ ] Required fields present (name, version, description)\n- [ ] Plugin name matches directory name (kebab-case)\n\n**Commands:**\n- [ ] YAML frontmatter with description\n- [ ] Parameter syntax correct ({{0}}, {{1}})\n\n**Agents:**\n- [ ] YAML frontmatter with name and description\n- [ ] Tool restrictions appropriate\n\n**Hooks:**\n- [ ] Scripts executable (`chmod +x`)\n- [ ] JSON input/output format correct\n- [ ] Matchers are valid regex\n\n**Documentation:**\n- [ ] README.md with installation instructions\n- [ ] CHANGELOG.md for version history\n- [ ] LICENSE file included\n\n### Validation Commands\n\n```bash\n# Validate JSON\njq empty plugin.json\n\n# Check command frontmatter\nfor f in commands/**/*.md; do\n  head -n 5 \"$f\" | grep -q '^---$' || echo \"Missing: $f\"\ndone\n\n# Verify scripts executable\nfor f in hooks/**/*.sh; do\n  test -x \"$f\" || echo \"Not executable: $f\"\ndone\n```\n\n### Local Testing\n\n```bash\n# Add as local marketplace\n/plugin marketplace add ./my-plugin\n\n# Install and test\n/plugin install my-plugin@my-plugin\n\n# Test commands\n/my-command arg1 arg2\n```\n\n## Phase 5: Distribution\n\n### Semantic Versioning\n\nFollow semver (MAJOR.MINOR.PATCH):\n- **MAJOR**: Breaking changes\n- **MINOR**: New features (backward compatible)\n- **PATCH**: Bug fixes\n\n### Release Workflow\n\n```bash\n# 1. Update version in plugin.json\n# 2. Update CHANGELOG.md\n# 3. Commit\ngit add plugin.json CHANGELOG.md\ngit commit -m \"chore: release v1.0.0\"\n\n# 4. Tag\ngit tag v1.0.0\n\n# 5. Push\ngit push origin main --tags\n\n# 6. Create GitHub release\ngh release create v1.0.0 \\\n  --title \"v1.0.0\" \\\n  --notes \"Initial release\"\n```\n\n### Distribution Methods\n\n| Method | Best For | Setup |\n|--------|----------|-------|\n| GitHub repo | Public/team plugins | Push to GitHub |\n| Git URL | GitLab, Bitbucket | Full URL in source |\n| Local path | Development/testing | Relative path |\n| ZIP package | Offline distribution | Create archive |\n\nSee [references/distribution.md](references/distribution.md) for packaging, CI/CD, and release automation.\n\n## Phase 6: Marketplace\n\n### What is a Marketplace?\n\nA catalog of plugins defined in `.claude-plugin/marketplace.json` that enables discovery, installation, and version management.\n\n### Creating a Marketplace\n\n```bash\nmkdir -p .claude-plugin\n```\n\n**.claude-plugin/marketplace.json:**\n\n```json\n{\n  \"name\": \"my-marketplace\",\n  \"owner\": {\n    \"name\": \"Team Name\",\n    \"email\": \"team@example.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"my-plugin\",\n      \"source\": \"./plugins/my-plugin\",\n      \"description\": \"Plugin description\",\n      \"version\": \"1.0.0\"\n    }\n  ]\n}\n```\n\n### Plugin Sources\n\n**Relative path:**\n```json\n{\"source\": \"./plugins/my-plugin\"}\n```\n\n**GitHub:**\n```json\n{\n  \"source\": {\n    \"source\": \"github\",\n    \"repo\": \"owner/plugin-repo\",\n    \"ref\": \"v1.0.0\"\n  }\n}\n```\n\n**Git URL:**\n```json\n{\n  \"source\": {\n    \"source\": \"url\",\n    \"url\": \"https://gitlab.com/team/plugin.git\"\n  }\n}\n```\n\n### Team Configuration\n\nConfigure automatic marketplace installation in `.claude/settings.json`:\n\n```json\n{\n  \"extraKnownMarketplaces\": {\n    \"team-tools\": {\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"company/claude-plugins\"\n      }\n    }\n  }\n}\n```\n\n### Marketplace Commands\n\n```bash\n# Add marketplace\n/plugin marketplace add owner/repo\n/plugin marketplace add ./local-path\n\n# List available\n/plugin marketplace list\n\n# Install from marketplace\n/plugin install plugin-name@marketplace-name\n\n# Update\n/plugin marketplace update marketplace-name\n```\n\nSee [references/marketplace.md](references/marketplace.md) for full schema, team setup, and hosting strategies.\n\n## Best Practices\n\n### Naming Conventions\n\n- **Plugin name**: kebab-case (e.g., `dev-tools`)\n- **Commands**: kebab-case (e.g., `review-pr`)\n- **Agents**: kebab-case (e.g., `security-reviewer`)\n- **Scripts**: kebab-case with extension (e.g., `validate.sh`)\n\n### Security\n\n- Never hardcode secrets in plugin files\n- Use environment variables for sensitive data\n- Validate all user inputs in hooks\n- Review third-party dependencies\n- Document security requirements\n\n### Documentation\n\n- **README.md**: Overview, installation, usage examples\n- **CHANGELOG.md**: Version history with semver\n- **LICENSE**: Appropriate license file\n- **Commands/Agents**: Clear description in frontmatter\n\n### Testing\n\n- Test all commands with various inputs\n- Verify hooks don't block normal workflow\n- Check MCP servers connect properly\n- Test installation and removal\n- Validate cross-platform compatibility\n\n## Troubleshooting\n\n**Plugin not loading:**\n- Verify plugin.json syntax: `jq empty plugin.json`\n- Check plugin name matches directory\n- Ensure required fields present\n\n**Commands not appearing:**\n- Verify YAML frontmatter exists\n- Check files in `commands/` directory\n- Ensure markdown syntax correct\n\n**Hooks not executing:**\n- Check scripts executable: `chmod +x`\n- Verify matcher regex correct\n- Test hook script independently\n- Review JSON output format\n\n**MCP servers failing:**\n- Verify server binary exists\n- Check environment variables set\n- Test with MCP Inspector\n- Review logs: `~/Library/Logs/Claude/`\n\n## References\n\n- [references/structure.md](references/structure.md) - Directory layout, plugin.json schema\n- [references/distribution.md](references/distribution.md) - Packaging, versioning, release automation\n- [references/marketplace.md](references/marketplace.md) - Marketplace schema, hosting, team setup\n\n## Related Skills\n\n- **claude-command-authoring** - Slash command development\n- **claude-agent-development** - Custom agent design\n- **claude-hook-authoring** - Event hook implementation\n- **skills-development** - Skill creation patterns"
              },
              {
                "name": "claude-rules-authoring",
                "description": "This skill should be used when creating rule files, organizing conventions, or when \".claude/rules/\", \"FORMATTING.md\", \"create rule\", or \"project conventions\" are mentioned.",
                "path": "agent-kit/skills/claude-rules-authoring/SKILL.md",
                "frontmatter": {
                  "name": "claude-rules-authoring",
                  "version": "1.0.0",
                  "description": "This skill should be used when creating rule files, organizing conventions, or when \".claude/rules/\", \"FORMATTING.md\", \"create rule\", or \"project conventions\" are mentioned.",
                  "allowed-tools": "Read Write Edit Grep Glob"
                },
                "content": "# Claude Rules Authoring\n\nCreate reusable instruction files in `.claude/rules/` for project conventions.\n\n## Rules vs CLAUDE.md\n\n| Aspect | CLAUDE.md | .claude/rules/ |\n|--------|-----------|----------------|\n| Loading | Automatic at session start | On-demand via reference |\n| Content | Project setup, key commands | Reusable conventions |\n| Size | Concise (~200-500 lines) | Can be detailed |\n| Scope | This specific project | Patterns across files |\n\n**Put in CLAUDE.md**: One-off instructions, project-specific commands, key file locations.\n\n**Put in rules/**: Formatting conventions, architecture patterns, workflow guidelines, commit standards.\n\n## File Conventions\n\n### Naming\n\n- **UPPERCASE.md** - All caps with `.md` extension\n- **Topic-focused** - One concern per file\n- **Kebab-case for multi-word** - `API-PATTERNS.md`, `CODE-REVIEW.md`\n\n**Good**: `FORMATTING.md`, `TESTING.md`, `COMMITS.md`\n**Bad**: `formatting.md`, `MyRules.md`, `everything.md`\n\n### Structure\n\n```\n.claude/rules/\n FORMATTING.md      # Code style, output conventions\n TESTING.md         # Test patterns, coverage requirements\n COMMITS.md         # Commit message format, PR conventions\n ARCHITECTURE.md    # Component structure, file organization\n SECURITY.md        # Security guidelines, auth patterns\n```\n\n## Content Structure\n\nRules files should be scannable and actionable:\n\n```markdown\n# Topic Name\n\nBrief description of what this covers.\n\n## Section 1\n\n| Pattern | Example | Notes |\n|---------|---------|-------|\n| ... | ... | ... |\n\n## Section 2\n\n**Do:**\n- Specific guideline\n\n**Don't:**\n- Anti-pattern to avoid\n\n## Examples\n\n{ concrete examples }\n```\n\n## Referencing Rules\n\n### From CLAUDE.md\n\nReference rules explicitly - they're not auto-loaded:\n\n```markdown\n# CLAUDE.md\n\n## Code Style\nFollow `.claude/rules/FORMATTING.md` for all code conventions.\n\n## Testing\nSee `.claude/rules/TESTING.md` for TDD patterns.\n```\n\n### Cross-file References\n\nUse `@` syntax to include content from other files:\n\n```markdown\n# .claude/rules/FORMATTING.md\n\n@../../baselayer/shared/rules/FORMATTING.md\n```\n\nThis keeps rules DRY by pointing to authoritative sources.\n\n## Plugin Shared Rules\n\nPlugins can provide shared rules in `shared/rules/`:\n\n```\nmy-plugin/\n .claude-plugin/\n    plugin.json\n skills/\n shared/\n     rules/\n         FORMATTING.md\n         PATTERNS.md\n```\n\nProjects reference via relative paths or `@` includes.\n\n## Quick Start\n\n### Create a New Rule\n\n1. Identify the convention scope (formatting, testing, commits, etc.)\n2. Create `TOPIC.md` in `.claude/rules/`\n3. Write scannable content with tables, do/don't lists\n4. Reference from CLAUDE.md\n\n### Validate a Rule\n\n- [ ] Filename is UPPERCASE.md\n- [ ] Single focused topic\n- [ ] Scannable structure (tables, lists)\n- [ ] Referenced from CLAUDE.md\n- [ ] No duplicate content with CLAUDE.md\n\n## Anti-Patterns\n\n**Don't:**\n- Create rules for one-off instructions (use CLAUDE.md)\n- Duplicate content between CLAUDE.md and rules/\n- Create catch-all files like `EVERYTHING.md`\n- Expect rules to auto-load (they must be referenced)\n\n**Do:**\n- Keep each rule file focused on one topic\n- Use tables and lists for scannability\n- Reference shared rules via `@` when available\n- Document why, not just what\n\n## Related Skills\n\n- **claude-code-configuration** - CLAUDE.md and settings.json\n- **claude-plugin-development** - Plugin structure including shared/rules/"
              },
              {
                "name": "codex-configuration",
                "description": "This skill should be used when configuring Codex CLI, setting up profiles, or when \"config.toml\", \"sandbox mode\", \"Codex config\", or \"approval policy\" are mentioned.",
                "path": "agent-kit/skills/codex-configuration/SKILL.md",
                "frontmatter": {
                  "name": "codex-configuration",
                  "description": "This skill should be used when configuring Codex CLI, setting up profiles, or when \"config.toml\", \"sandbox mode\", \"Codex config\", or \"approval policy\" are mentioned.",
                  "version": "1.0.0"
                },
                "content": "# Codex Configuration Management\n\nManages configuration files for OpenAI Codex CLI, including model settings, sandbox policies, MCP servers, and profiles.\n\n## Configuration Location\n\n**Primary Config:** `~/.codex/config.toml`\n\n**Skills Paths (precedence, highest first):**\n1. `$CWD/.codex/skills/` - Current directory\n2. `$CWD/../.codex/skills/` - Parent directory\n3. `$REPO_ROOT/.codex/skills/` - Repository root\n4. `~/.codex/skills/` - User-level\n5. `/etc/codex/skills/` - System/admin level\n6. Built-in skills - Bundled with Codex\n\n## Basic config.toml\n\n```toml\n# Model settings\nmodel = \"gpt-5.2-codex\"\nmodel_verbosity = \"medium\"  # high | medium | low\nmodel_reasoning_effort = \"high\"  # low | high | xhigh\n\n# Permissions\napproval_policy = \"on-failure\"  # untrusted | on-failure | on-request | never\nsandbox_mode = \"workspace-write\"  # read-only | workspace-write | danger-full-access\nexec_timeout_ms = 300000  # 5 minutes\n\n# Misc\nfile_opener = \"cursor\"  # Editor for opening files\n```\n\n## Profiles\n\nDefine named profiles for different workflows:\n\n```toml\n[profiles.max]\nmodel = \"gpt-5.1-codex-max\"\nmodel_verbosity = \"high\"\nmodel_reasoning_effort = \"xhigh\"\n\n[profiles.fast]\nmodel = \"gpt-5.1-codex-mini\"\nmodel_verbosity = \"low\"\nmodel_reasoning_effort = \"low\"\n```\n\n**Usage:**\n\n```bash\ncodex -p max \"complex refactoring task\"\ncodex -p fast \"quick fix\"\n```\n\n## MCP Servers\n\n```toml\n[mcp_servers.server-name]\ncommand = \"npx\"\nargs = [\"-y\", \"@package/mcp-server\"]\nenabled = true\ntool_timeout_sec = 60.0\n\n[mcp_servers.server-name.env]\nAPI_KEY = \"your-key\"\n```\n\n## Skills\n\n### Invoking Skills\n\n```bash\n# Explicit invocation\ncodex \"$plan implement authentication\"\ncodex \"$skill-creator new skill for testing\"\n\n# Implicit (Codex decides based on context)\ncodex \"plan out the implementation\"\n```\n\n### Built-in Skills\n\n- `$plan` - Research and create implementation plans\n- `$skill-creator` - Bootstrap new skills\n- `$skill-installer` - Download skills from GitHub\n\n## CLI Override\n\nOverride any config value at runtime:\n\n```bash\ncodex -c model=\"o3\"\ncodex -c 'sandbox_permissions=[\"disk-full-read-access\"]'\ncodex -c shell_environment_policy.inherit=all\n```\n\n## Convenience Flags\n\n| Flag | Equivalent |\n|------|------------|\n| `--full-auto` | `-a on-request --sandbox workspace-write` |\n| `--oss` | `-c model_provider=oss` (local LM Studio/Ollama) |\n| `--search` | Enable web search tool |\n\n```bash\ncodex --full-auto \"implement feature\"\ncodex -C /path/to/project \"work in different dir\"\ncodex --add-dir /additional/path \"access multiple dirs\"\n```\n\n## Quick Validation\n\n```bash\n# Check TOML syntax\ncat ~/.codex/config.toml | toml-lint\n\n# Test config override\ncodex -c model=\"test\" --help\n\n# Verify MCP servers\ncodex mcp list\n```\n\n## Quick Troubleshooting\n\n**Config not loading:** Verify `~/.codex/config.toml` exists, check TOML syntax\n\n**MCP server not connecting:** Check command path, verify API keys, check `enabled = true`\n\n**Skills not found:** Verify path hierarchy, check SKILL.md exists in skill folder\n\n**Sandbox too restrictive:** Use `-s workspace-write`, check project trust level\n\n## References\n\nDetailed documentation for specific scenarios:\n\n- **[MCP Servers](references/mcp-servers.md)** - Server configuration examples (Context7, Firecrawl, Graphite, Linear)\n- **[Troubleshooting](references/troubleshooting.md)** - Common issues, debug commands, validation\n- **[Security](references/security.md)** - Sandbox modes, approval policies, trust levels, best practices"
              },
              {
                "name": "skills-development",
                "description": "This skill should be used when creating skills, writing SKILL.md files, or when \"create skill\", \"new skill\", \"validate skill\", or \"SKILL.md\" are mentioned.",
                "path": "agent-kit/skills/skills-development/SKILL.md",
                "frontmatter": {
                  "name": "skills-development",
                  "version": "1.3.0",
                  "description": "This skill should be used when creating skills, writing SKILL.md files, or when \"create skill\", \"new skill\", \"validate skill\", or \"SKILL.md\" are mentioned.",
                  "user-invocable": true,
                  "allowed-tools": "Read Write Edit Grep Glob Bash TodoWrite AskUserQuestion"
                },
                "content": "# Skills Development\n\nCreate skills that follow the [Agent Skills specification](https://agentskills.io/specification)an open format supported by Claude Code, Cursor, VS Code, GitHub, and other agent products.\n\n## Workflow\n\n1. **Discovery**  Understand what the skill should do\n2. **Archetype Selection**  Choose the best pattern\n3. **Initialization**  Create skill structure from template\n4. **Customization**  Tailor to specific needs\n5. **Validation**  Verify quality before committing\n\n## Phase 1: Discovery\n\nAsk about the skill:\n\n- What problem does this skill solve?\n- What are the main capabilities?\n- What triggers should invoke it? (phrases users would say)\n- Where should it live? (personal `~/.claude/skills/`, project `.claude/skills/`, or plugin)\n\n## Phase 2: Archetype Selection\n\n| Archetype | Use When | Example |\n|-----------|----------|---------|\n| **simple** | Basic skill without scripts | Quick reference, style guide |\n| **api-wrapper** | Wrapping external APIs | GitHub API, Stripe API |\n| **document-processor** | Working with file formats | PDF extractor, Excel analyzer |\n| **dev-workflow** | Automating development tasks | Git workflow, project scaffolder |\n| **research-synthesizer** | Gathering and synthesizing information | Competitive analysis, literature review |\n\nTemplates in `templates/skill-archetypes/`.\n\n## Phase 3: Initialization\n\nRun the init script:\n\n```bash\nbun run ${CLAUDE_PLUGIN_ROOT}/skills/skills-development/scripts/init-skill.ts <skill-name> <output-dir> --template <archetype>\n```\n\n**Output directories:**\n- Personal: `~/.claude/skills/<skill-name>/`\n- Project: `.claude/skills/<skill-name>/`\n- Plugin: `<plugin-dir>/skills/<skill-name>/`\n\n## Phase 4: Customization\n\n### Directory Structure\n\n```\nskill-name/\n SKILL.md           # Required: instructions + metadata\n scripts/           # Optional: executable code\n references/        # Optional: documentation\n assets/            # Optional: templates, resources\n```\n\n### Frontmatter\n\n```yaml\n---\nname: skill-name\ndescription: What it does and when to use it. Include trigger keywords.\nlicense: Apache-2.0                    # optional\ncompatibility: Requires git and jq     # optional\nmetadata:                              # optional\n  author: your-org\n  version: \"1.0\"\nallowed-tools: Read Grep Glob          # optional, experimental\nuser-invocable: true                   # optional, makes skill a /command\n---\n```\n\n| Field | Required | Constraints |\n|-------|----------|-------------|\n| `name` | Yes | 1-64 chars, lowercase/numbers/hyphens, must match directory |\n| `description` | Yes | 1-1024 chars, describes what + when |\n| `user-invocable` | No | Boolean, enables `/skill-name` command (Claude Code) |\n| `license` | No | License name or reference |\n| `compatibility` | No | 1-500 chars, environment requirements |\n| `allowed-tools` | No | Space-delimited tool list (experimental) |\n| `metadata` | No | Object for custom fields (see below) |\n\n### user-invocable\n\nWhen `user-invocable: true`, the skill becomes callable as a slash command:\n\n```yaml\n---\nname: code-review\ndescription: Reviews code for bugs and best practices...\nuser-invocable: true\n---\n```\n\nUsers can then invoke with `/code-review` instead of waiting for auto-activation. The skill content becomes the command prompt.\n\n### Custom Frontmatter\n\nCustom fields **must** be nested under `metadata`:\n\n```yaml\n---\nname: my-skill\ndescription: ...\nmetadata:\n  author: your-org\n  version: \"1.0\"\n  category: development\n  tags: [typescript, testing]\n---\n```\n\nTop-level custom fields are not allowed and may cause parsing errors.\n\n### Description Formula\n\n**[WHAT] + [WHEN] + [TRIGGERS]**\n\n```yaml\ndescription: Extracts text and tables from PDF files, fills forms, merges documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n```\n\n**Checklist:**\n- [ ] Explains WHAT (capabilities)\n- [ ] States WHEN (trigger conditions)\n- [ ] Includes 3-5 trigger KEYWORDS\n- [ ] Uses third-person voice\n- [ ] Under 200 words\n\n### Per-Archetype Customization\n\n**api-wrapper:**\n- Update `scripts/client.ts` with API endpoints\n- Add auth instructions\n- Create `references/endpoints.md` if API is large\n\n**document-processor:**\n- Update `scripts/process.ts` with format logic\n- Add library dependencies\n- Document supported operations\n\n**dev-workflow:**\n- Update `scripts/run.ts` with commands\n- Add safety checks for destructive operations\n- Document available commands\n\n**research-synthesizer:**\n- Define source priority order\n- Specify output format\n- Set citation style\n\n## Phase 5: Validation\n\nValidate before committing. Use the CLI or run checks manually:\n\n```bash\nskills-ref validate ./my-skill\n```\n\n### Validation Checklist\n\n#### A. YAML Frontmatter\n- [ ] Opens with `---` on line 1, closes with `---`\n- [ ] `name` and `description` present (required)\n- [ ] Uses spaces, not tabs\n- [ ] Special characters quoted\n\n#### B. Naming\n- [ ] Lowercase, numbers, hyphens only (1-64 chars)\n- [ ] Matches parent directory name\n- [ ] No `--`, leading/trailing hyphens\n- [ ] No `anthropic` or `claude` in name\n\n#### C. Description Quality\n- [ ] WHAT: Explains capabilities\n- [ ] WHEN: States \"Use when...\" conditions\n- [ ] TRIGGERS: 3-5 keywords users would say\n- [ ] Third-person voice (not \"I can\" or \"you can\")\n\n#### D. Structure\n- [ ] SKILL.md under 500 lines\n- [ ] All referenced files exist\n- [ ] No TODO/placeholder markers\n- [ ] Progressive disclosure (details in `references/`)\n\n### Review Checks\n\nAfter validation passes, review for quality:\n\n| Aspect | Check |\n|--------|-------|\n| **Discoverability** | Would Claude know when to activate? |\n| **Conciseness** | Does each paragraph justify its token cost? |\n| **Clarity** | Are instructions step-by-step and actionable? |\n\n### Report Format\n\n```markdown\n# Skill Check: {skill-name}\n\n**Status**: PASS | WARNINGS | FAIL\n**Issues**: {critical} critical, {warnings} warnings\n\n## Critical (must fix)\n1. {issue with fix}\n\n## Warnings (should fix)\n1. {issue with fix}\n\n## Strengths\n- {what's done well}\n```\n\n### Common Fixes\n\n**Vague description:**\n```yaml\n# Before\ndescription: Helps with PDF files\n\n# After\ndescription: Extracts text and tables from PDF files, fills forms, merges documents. Use when working with PDFs, forms, or document extraction.\n```\n\n**Wrong voice:**\n```yaml\n# Before\ndescription: I can help you process data files\n\n# After\ndescription: Processes data files and converts between formats (CSV, JSON, XML). Use when working with data files or format conversion.\n```\n\n### Priority Levels\n\n- **Critical**: Invalid YAML, missing required fields, broken references\n- **Important**: Vague descriptions, wrong voice, missing triggers\n- **Nice-to-have**: Additional examples, better organization\n\n## Core Principles\n\n### Concise is key\n\nContext window is shared. Only include what the agent doesn't already know. Challenge each paragraphdoes it justify its token cost?\n\n### Third-person descriptions\n\nDescriptions inject into system prompt:\n-  \"Extracts text from PDFs\"\n-  \"I can help you extract text from PDFs\"\n\n### Progressive disclosure\n\nKeep SKILL.md under 500 lines. Move details to:\n- `references/` - Detailed docs, API references\n- `scripts/` - Executable utilities (code never enters context)\n- `assets/` - Templates, data files\n\nToken loading:\n1. **Metadata** (~100 tokens): name + description at startup\n2. **Instructions** (<5000 tokens): SKILL.md body when activated\n3. **Resources** (as needed): files loaded only when referenced\n\n### Degrees of freedom\n\nMatch instruction specificity to task requirements:\n- **High freedom** (text): Multiple valid approaches, use judgment\n- **Medium freedom** (pseudocode): Preferred pattern with variation allowed\n- **Low freedom** (scripts): Exact sequence required, no deviation\n\nSee [patterns.md](references/patterns.md) for detailed examples.\n\n## Naming Requirements\n\n- Lowercase letters, numbers, hyphens only\n- Cannot start/end with hyphen or contain `--`\n- Must match parent directory name\n- Cannot contain `anthropic` or `claude`\n\n**Recommended**: Gerund form (`processing-pdfs`, `reviewing-code`)\n\n## Tool Restrictions\n\nUse `allowed-tools` to limit capabilities (experimental):\n\n```yaml\n# Read-only\nallowed-tools: Read Grep Glob\n\n# With shell access\nallowed-tools: Bash(git:*) Bash(jq:*) Read\n\n# Full access (default)\n# Omit field entirely\n```\n\n## After Creation\n\n1. **Validate**: Run Phase 5 checklist or `skills-ref validate`\n2. **Test**: Ask a question that should trigger it\n3. **Iterate**: Fix issues until passing\n4. **Share**: Commit to git or distribute via plugin\n\n## Troubleshooting\n\n```bash\n# Find all skills\nfind ~/.claude/skills .claude/skills -name \"SKILL.md\" 2>/dev/null\n\n# Check for tab characters (YAML requires spaces)\ngrep -P \"\\t\" SKILL.md\n\n# Find broken markdown links\ngrep -oE '\\[[^]]+\\]\\([^)]+\\)' SKILL.md | while read link; do\n  file=$(echo \"$link\" | sed 's/.*(\\(.*\\))/\\1/')\n  [ ! -f \"$file\" ] && echo \"Missing: $file\"\ndone\n```\n\n## References\n\n- [patterns.md](references/patterns.md) - Degrees of freedom, script design, variant organization, writing patterns\n- [best-practices.md](references/best-practices.md) - Community patterns, testing strategies, advanced techniques\n- [quick-reference.md](references/quick-reference.md) - Fast checklist and one-liners\n- [implementations.md](references/implementations.md) - Per-tool storage paths\n- [invocations.md](references/invocations.md) - How tools activate skills\n- [compatibility.md](references/compatibility.md) - Path compatibility matrix\n\n## Platform-Specific Implementation\n\nEach tool has specific implementation details beyond the common spec:\n\n- **Claude Code**: [claude.md](references/claude.md) - Tool restrictions syntax, `--debug` testing, troubleshooting, command/hook integration\n- **Codex CLI**: [codex.md](references/codex.md) - Discovery paths, `$skill-name` invocation, AGENTS.md relationship, feature flags, built-in skills\n\nSee [implementations.md](references/implementations.md) for storage paths and platform-specific notes.\n\n## External Resources\n\n- [Agent Skills Specification](https://agentskills.io/specification)\n- [Best Practices Guide](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices)\n- [skills-ref Validation Library](https://github.com/agentskills/agentskills/tree/main/skills-ref)"
              }
            ]
          },
          {
            "name": "gitbutler",
            "description": "GitButler virtual branch workflows for parallel development, multi-agent collaboration, and post-hoc organization",
            "source": "./gitbutler",
            "category": null,
            "version": "2.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add outfitter-dev/agents",
              "/plugin install gitbutler@outfitter"
            ],
            "signals": {
              "stars": 15,
              "forks": 0,
              "pushed_at": "2026-01-11T17:32:42Z",
              "created_at": "2025-08-30T16:37:06Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "complete-branch",
                "description": "This skill should be used when completing branches, merging to main, creating PRs with GitButler, or when `--complete-branch` flag is mentioned.",
                "path": "gitbutler/skills/complete-branch/SKILL.md",
                "frontmatter": {
                  "name": "complete-branch",
                  "version": "2.0.0",
                  "description": "This skill should be used when completing branches, merging to main, creating PRs with GitButler, or when `--complete-branch` flag is mentioned."
                },
                "content": "# Complete GitButler Virtual Branch\n\nVirtual branch ready  snapshot  merge to main  cleanup  return.\n\n<when_to_use>\n\n- Virtual branch work is complete and ready to ship\n- Tests pass and code is reviewed (if required)\n- Ready to merge changes into main branch\n- Need to clean up completed branches\n\nNOT for: ongoing work, branches needing more development, stacks (complete bottom-to-top)\n\n</when_to_use>\n\n<prerequisites>\n\n**Before completing any branch:**\n- [ ] GitButler initialized (`but --version` succeeds)\n- [ ] Virtual branch exists with committed changes\n- [ ] Main branch tracked as base\n- [ ] No uncommitted changes (or changes assigned to branches)\n- [ ] Tests passing\n\n</prerequisites>\n\n<quick_start>\n\n## Quick Start (7 Steps)\n\n```bash\n# 1. Verify branch state\nbut status\nbut log\n\n# 2. Create safety snapshot\nbut snapshot --message \"Before integrating feature-auth\"\n\n# 3. Switch to main\ngit checkout main\n\n# 4. Update main from remote\ngit pull origin main\n\n# 5. Merge virtual branch\ngit merge --no-ff refs/gitbutler/feature-auth -m \"feat: add user authentication\"\n\n# 6. Push to remote\ngit push origin main\n\n# 7. Clean up and return\nbut branch rm feature-auth\ngit checkout gitbutler/workspace\n```\n\n</quick_start>\n\n<pre_flight>\n\n## Pre-Integration Checklist\n\n```bash\n# All work committed?\nbut status  # Your branch should show committed changes\n\n# Tests passing?\nbun test  # or npm test, cargo test, etc.\n\n# Branch up to date with main?\nbut base update\n\n# No uncommitted changes?\nbut status  # Should show no unassigned files\ngit status  # Should be clean or show only .gitbutler/ changes\n\n# Safety snapshot created?\nbut snapshot --message \"Before integrating feature-auth\"\n```\n\n</pre_flight>\n\n<workflows>\n\n## Integration Workflows\n\n### A. Direct Merge to Main\n\n```bash\n# 1. Verify branch state\nbut status\nbut log\n\n# 2. Create snapshot\nbut snapshot --message \"Before integrating feature-auth\"\n\n# 3. Switch to main\ngit checkout main\n\n# 4. Update main\ngit pull origin main\n\n# 5. Merge with --no-ff (preserves history)\ngit merge --no-ff refs/gitbutler/feature-auth -m \"feat: add user authentication\"\n\n# 6. Push\ngit push origin main\n\n# 7. Clean up\nbut branch rm feature-auth\ngit checkout gitbutler/workspace\n```\n\n### B. Pull Request Workflow\n\n```bash\n# 1. Push branch to remote\ngit push origin refs/gitbutler/feature-auth:refs/heads/feature-auth\n\n# 2. Create PR\ngh pr create --base main --head feature-auth \\\n  --title \"feat: add user authentication\" \\\n  --body \"Description...\"\n\n# 3. Wait for review and approval\n\n# 4. Merge PR (via GitHub UI or CLI)\ngh pr merge feature-auth --squash\n\n# 5. Update main and clean up\ngit checkout main\ngit pull origin main\nbut branch rm feature-auth\ngit checkout gitbutler/workspace\n```\n\n### C. Stacked Branches (Bottom-Up)\n\n```bash\n# Must merge in order: base  dependent  final\n\n# 1. Merge base branch first\ngit checkout main && git pull\ngit merge --no-ff refs/gitbutler/feature-base -m \"feat: base feature\"\ngit push origin main\nbut branch rm feature-base\ngit checkout gitbutler/workspace\n\n# 2. Update remaining branches\nbut base update\n\n# 3. Merge next level\ngit checkout main && git pull\ngit merge --no-ff refs/gitbutler/feature-api -m \"feat: API feature\"\ngit push origin main\nbut branch rm feature-api\ngit checkout gitbutler/workspace\n\n# 4. Repeat for remaining stack levels\n```\n\n</workflows>\n\n<recovery>\n\n## Error Recovery\n\n### Merge Conflicts\n\n```bash\n# View conflicted files\ngit status\n\n# Resolve conflicts manually\n\n# Stage resolved files\ngit add src/auth.ts\n\n# Complete merge\ngit commit\n\n# Verify and push\ngit push origin main\n\n# Clean up\nbut branch rm feature-auth\ngit checkout gitbutler/workspace\n```\n\n### Push Rejected (Main Moved Ahead)\n\n```bash\ngit pull origin main\n# Resolve any conflicts if main diverged\ngit push origin main\n```\n\n### Undo Integration (Not Pushed Yet)\n\n```bash\ngit reset --hard HEAD~1\ngit checkout gitbutler/workspace\n```\n\n### Undo Integration (Already Pushed)\n\n```bash\ngit revert -m 1 HEAD\ngit push origin main\n```\n\n</recovery>\n\n<cleanup>\n\n## Post-Integration Cleanup\n\n```bash\n# Delete integrated virtual branch\nbut branch rm feature-auth\n\n# Clean up remote branch (if created for PR)\ngit push origin --delete feature-auth\n\n# Verify workspace is clean\nbut status  # Should show remaining active branches only\nbut log     # Branch should be gone\n```\n\n</cleanup>\n\n<rules>\n\nALWAYS:\n- Create snapshot before integration: `but snapshot --message \"...\"`\n- Use `--no-ff` flag to preserve branch history\n- Return to workspace after git operations: `git checkout gitbutler/workspace`\n- Run tests before integrating\n- Complete stacked branches bottom-to-top\n\nNEVER:\n- Merge without snapshot backup\n- Skip updating main first (`git pull`)\n- Forget to return to `gitbutler/workspace`\n- Merge middle of stack before base\n- Force push to main without explicit confirmation\n\n</rules>\n\n<troubleshooting>\n\n## Common Issues\n\n| Symptom | Cause | Solution |\n|---------|-------|----------|\n| Merge conflicts | Diverged from main | Resolve conflicts, stage, commit |\n| Push rejected | Main moved ahead | `git pull`, resolve, push |\n| Branch not found | Wrong ref path | Use `refs/gitbutler/<name>` |\n| Can't return to workspace | Integration branch issue | `git checkout gitbutler/workspace` |\n\n## Emergency Recovery\n\n```bash\n# If integration went wrong\nbut oplog\nbut undo  # Restores pre-integration state\n\n# If stuck after git operations\ngit checkout gitbutler/workspace\n```\n\n</troubleshooting>\n\n<best_practices>\n\n## Best Practices\n\n**Keep branches small:**\n- Small branches = easier merges\n- Aim for single responsibility per branch\n\n**Update base regularly:**\n\n```bash\nbut base update\n```\n\n**Test before integrating:**\n- Always run full test suite before merging\n\n**Meaningful merge commits:**\n\n```bash\n# Good: Describes what and why\ngit merge --no-ff feature-auth -m \"feat: add JWT-based user authentication\"\n\n# Bad: Generic message\ngit merge --no-ff feature-auth -m \"Merge branch\"\n```\n\n</best_practices>\n\n<references>\n\n- [version-control skill](../version-control/SKILL.md)  core GitButler workflows\n- [stack-workflows skill](../stack-workflows/SKILL.md)  stacked branches\n- [REFERENCE.md](../version-control/REFERENCE.md)  CLI reference and troubleshooting\n\n</references>"
              },
              {
                "name": "multi-agent",
                "description": "This skill should be used when coordinating multiple agents, parallel development, agent handoffs, or when multi-agent, concurrent agents, or parallel agents are mentioned.",
                "path": "gitbutler/skills/multi-agent/SKILL.md",
                "frontmatter": {
                  "name": "multi-agent",
                  "version": "2.0.0",
                  "description": "This skill should be used when coordinating multiple agents, parallel development, agent handoffs, or when multi-agent, concurrent agents, or parallel agents are mentioned."
                },
                "content": "# GitButler Multi-Agent Coordination\n\nMultiple agents  virtual branches  parallel execution  zero coordination overhead.\n\n<when_to_use>\n\n- Multiple agents working on different features simultaneously\n- Sequential agent handoffs (Agent A  Agent B)\n- Commit ownership transfer between agents\n- Parallel execution with early conflict detection\n- Post-hoc reorganization of multi-agent work\n\nNOT for: single-agent workflows (use standard GitButler), projects needing PR automation (Graphite better)\n\n</when_to_use>\n\n<core_advantage>\n\n**Traditional Git Problem:**\n- Agents must work in separate worktrees (directory coordination)\n- Constant branch switching (context loss, file churn)\n- Late conflict detection (only at merge time)\n\n**GitButler Solution:**\n- Multiple branches stay applied simultaneously\n- Single shared workspace, zero checkout operations\n- Immediate conflict detection (shared working tree)\n- Each agent manipulates their own lane\n\n</core_advantage>\n\n<patterns>\n\n## Pattern 1: Parallel Feature Development\n\n```bash\n# Agent 1\nbut branch new agent-1-auth\necho \"auth code\" > auth.ts\nbut rub auth.ts agent-1-auth\nbut commit agent-1-auth -m \"feat: add authentication\"\n\n# Agent 2 (simultaneously, same workspace!)\nbut branch new agent-2-api\necho \"api code\" > api.ts\nbut rub api.ts agent-2-api\nbut commit agent-2-api -m \"feat: add API endpoints\"\n\n# Result: Two independent features, zero conflicts\n```\n\n## Pattern 2: Sequential Handoff\n\n```bash\n# Agent A: Initial implementation\nbut branch new initial-impl\n# ... code ...\nbut commit initial-impl -m \"feat: initial implementation\"\n\n# Agent B: Takes ownership and refines\nbut rub <agent-a-commit> refinement-branch\n# ... improve code ...\nbut commit refinement-branch -m \"refactor: optimize implementation\"\n```\n\n## Pattern 3: Cross-Agent Commit Transfer\n\n```bash\n# Instant ownership transfer\nbut rub <commit-sha> agent-b-branch  # Agent A  Agent B\nbut rub <commit-sha> agent-a-branch  # Agent B  Agent A\n```\n\n</patterns>\n\n<naming>\n\n## Branch Naming Convention\n\n```\n<agent-name>-<task-type>-<brief-description>\n\nExamples:\n- claude-feat-user-auth\n- droid-fix-api-timeout\n- codex-refactor-database-layer\n```\n\nMakes ownership immediately visible in `but status` and `but log`.\n\n</naming>\n\n<ai_integration>\n\n## AI Integration Methods\n\n**1. Agents Tab (Claude Code)**\n- GUI-based launcher tied to branches\n- Each virtual branch = independent session\n- Automatic commit management per session\n- Parallel agent execution with branch isolation\n\n**2. Lifecycle Hooks**\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [{\"matcher\": \"Edit|MultiEdit|Write\", \"hooks\": [{\"type\": \"command\", \"command\": \"but claude pre-tool\"}]}],\n    \"PostToolUse\": [{\"matcher\": \"Edit|MultiEdit|Write\", \"hooks\": [{\"type\": \"command\", \"command\": \"but claude post-tool\"}]}],\n    \"Stop\": [{\"matcher\": \"\", \"hooks\": [{\"type\": \"command\", \"command\": \"but claude stop\"}]}]\n  }\n}\n```\n\n**3. MCP Server**\n\n```bash\nbut mcp  # Enables programmatic agent integration\n```\n\n**Key Instruction for Agents:**\n> \"Never use the git commit command after a task is finished\"\n\nLet GitButler manage commits via hooks or MCP.\n\n</ai_integration>\n\n<coordination>\n\n## Coordination Protocols\n\n**Status Broadcasting:**\n\n```bash\n# File-based coordination\nbut status > /tmp/agent-$(whoami)-status.txt\n\n# Or use Linear/GitHub comments\n# \"[AGENT-A] Completed auth module, committed to claude-auth-feature\"\n```\n\n**Snapshot Cadence:**\n\n```bash\n# Before risky operations\nbut snapshot --message \"Before merging conflicting branches\"\n\n# If it breaks\nbut undo\n```\n\n**Concurrent Safety:**\n1. Snapshot before risky operations\n2. Broadcast status regularly to other agents\n3. Respect  locks  files assigned to other branches\n4. Use `but --json` for programmatic state inspection\n\n</coordination>\n\n<rub_power>\n\n## The `but rub` Power Tool\n\nSingle command handles four critical multi-agent operations:\n\n| Operation | Example | Use Case |\n|-----------|---------|----------|\n| **Assign** | `but rub m6 claude-branch` | Organize files to branches post-hoc |\n| **Move** | `but rub abc1234 other-branch` | Transfer work between agents |\n| **Squash** | `but rub newer older` | Clean up history |\n| **Amend** | `but rub file commit` | Fix existing commits |\n\n</rub_power>\n\n<comparison>\n\n## vs Other Workflows\n\n| Aspect | Graphite | Git Worktrees | GitButler |\n|--------|----------|---------------|-----------|\n| Multi-agent concurrency | Serial | N directories | Parallel  |\n| Post-hoc organization | Difficult | Difficult | `but rub`  |\n| PR Submission | `gt submit`  | Manual | GUI only |\n| Physical layout | 1 directory | N  repo | 1 directory  |\n| Context switching | `gt checkout` | `cd` | None  |\n| Conflict detection | Late (merge) | Late (merge) | Early  |\n| Disk usage | 1  repo | N  repo | 1  repo  |\n\n</comparison>\n\n<rules>\n\nALWAYS:\n- Use unique branch names per agent: `<agent>-<type>-<desc>`\n- Assign files immediately after creating: `but rub <id> <branch>`\n- Snapshot before coordinated operations\n- Broadcast status to other agents when completing work\n- Check for  locked files before modifying\n\nNEVER:\n- Use `git commit`  breaks GitButler state\n- Let files sit in \"Unassigned Changes\"  assign immediately\n- Modify files locked to other branches\n- Mix git and but commands during active agent sessions\n\n</rules>\n\n<troubleshooting>\n\n## Common Issues\n\n| Symptom | Cause | Solution |\n|---------|-------|----------|\n| Agent commit \"orphaned\" | Used `git commit` | Find with `git reflog`, recover |\n| Files in wrong branch | Forgot assignment | `but rub <id> <correct-branch>` |\n| Conflicting edits | Overlapping files | Reassign hunks to different branches |\n| Lost agent work | Branch deleted | `but undo` or restore from oplog |\n\n## Recovery\n\n```bash\n# Find orphaned commits\ngit reflog\n\n# Recover agent work\nbut oplog\nbut undo\n\n# Extract from snapshot\ngit show <snapshot>:index/path/to/file.txt\n```\n\n</troubleshooting>\n\n<limitations>\n\n## Current Limitations\n\n- **No PR submission CLI**  use `gh pr create` after organizing\n- **Overlapping file edits**  adjacent lines can only go to one branch\n- **No stack navigation CLI**  no `gt up`/`gt down` equivalent\n\n**Recommendation:** Use for exploratory multi-agent work. For production automation requiring PR submission, consider Graphite until CLI matures.\n\n</limitations>\n\n<references>\n\n- [version-control skill](../version-control/SKILL.md)  core GitButler workflows\n- [stack-workflows skill](../stack-workflows/SKILL.md)  stacked branches\n- [GitButler AI Docs](https://docs.gitbutler.com/features/ai-integration/)  official AI integration\n- [Agents Tab Blog](https://blog.gitbutler.com/agents-tab)  Claude Code integration details\n\n</references>"
              },
              {
                "name": "stack-workflows",
                "description": "This skill should be used when creating stacked branches, dependent features, reviewable PR breakdown, or when stack, stacked branches, or `--anchor` are mentioned.",
                "path": "gitbutler/skills/stack-workflows/SKILL.md",
                "frontmatter": {
                  "name": "stack-workflows",
                  "version": "2.0.0",
                  "description": "This skill should be used when creating stacked branches, dependent features, reviewable PR breakdown, or when stack, stacked branches, or `--anchor` are mentioned."
                },
                "content": "# GitButler Stack Workflows\n\nDependent branches  anchor-based stacking  reviewable chunks.\n\n<when_to_use>\n\n- Sequential dependencies (e.g., refactor  API  frontend)\n- Large features broken into reviewable chunks\n- Granular code review (approve/merge early phases independently)\n- Post-hoc stack organization after exploratory coding\n\nNOT for: independent parallel features (use virtual branches), projects using Graphite stacking\n\n</when_to_use>\n\n<stack_vs_virtual>\n\n## Stacked vs Virtual Branches\n\n| Type | Use Case | Dependencies |\n|------|----------|--------------|\n| **Virtual** | Independent, unrelated work | None  parallel |\n| **Stacked** | Sequential dependencies | Each builds on parent |\n\nStacked branches = virtual branches split into dependent sequence.\nDefault: Virtual branches are stacks of one.\n\n</stack_vs_virtual>\n\n<create>\n\n## Creating Stacks\n\n```bash\n# Base branch (no anchor)\nbut branch new base-feature\n\n# Stacked branch (--anchor specifies parent)\nbut branch new child-feature --anchor base-feature\n\n# Third level\nbut branch new grandchild-feature --anchor child-feature\n```\n\n**Result:** `base-feature`  `child-feature`  `grandchild-feature`\n\n**Short form:** `-a` instead of `--anchor`\n\n```bash\nbut branch new child -a parent\n```\n\n</create>\n\n<patterns>\n\n## Stack Patterns\n\n### Feature Dependency Stack\n\n```bash\n# Auth foundation\nbut branch new auth-core\nbut commit auth-core -m \"feat: add authentication core\"\n\n# OAuth layer depends on auth core\nbut branch new auth-oauth --anchor auth-core\nbut commit auth-oauth -m \"feat: add OAuth integration\"\n\n# Social login depends on OAuth\nbut branch new auth-social --anchor auth-oauth\nbut commit auth-social -m \"feat: add social login\"\n```\n\n### Refactoring Stack\n\n```bash\n# Extract utilities\nbut branch new refactor-extract-utils\nbut commit refactor-extract-utils -m \"refactor: extract common utilities\"\n\n# Update consumers\nbut branch new refactor-use-utils --anchor refactor-extract-utils\nbut commit refactor-use-utils -m \"refactor: use extracted utilities\"\n\n# Clean up\nbut branch new refactor-cleanup --anchor refactor-use-utils\nbut commit refactor-cleanup -m \"refactor: remove deprecated code\"\n```\n\n### Deep Stack (5 levels)\n\n```bash\nbut branch new db-schema\nbut branch new data-access --anchor db-schema\nbut branch new business-logic --anchor data-access\nbut branch new api-endpoints --anchor business-logic\nbut branch new frontend-integration --anchor api-endpoints\n```\n\n</patterns>\n\n<post_hoc>\n\n## Post-Hoc Stack Organization\n\n**Problem:** Created branches independently, now want to stack them.\n\n**Solution:** Recreate with correct anchors:\n\n```bash\n# Current: three independent branches\n# feature-a, feature-b, feature-c\n\n# Stack feature-b on feature-a\nbut branch new feature-b-stacked --anchor feature-a\ncommit_sha=$(but log | grep \"feature-b:\" | head -1 | awk '{print $1}')\nbut rub $commit_sha feature-b-stacked\nbut branch delete feature-b --force\n\n# Stack feature-c on feature-b-stacked\nbut branch new feature-c-stacked --anchor feature-b-stacked\ncommit_sha=$(but log | grep \"feature-c:\" | head -1 | awk '{print $1}')\nbut rub $commit_sha feature-c-stacked\nbut branch delete feature-c --force\n```\n\n</post_hoc>\n\n<pr_workflow>\n\n## PR Preparation for Stacks\n\n**GitButler CLI lacks native PR submission.** Use GitHub CLI:\n\n```bash\n# Push branches\ngit push -u origin base-feature\ngit push -u origin dependent-feature\n\n# Create PRs with correct base branches\ngh pr create --base main --head base-feature \\\n  --title \"feat: base feature\" \\\n  --body \"First in stack\"\n\ngh pr create --base base-feature --head dependent-feature \\\n  --title \"feat: dependent feature\" \\\n  --body \"Depends on base-feature PR\"\n```\n\n**GitHub Settings:**\n- Enable automatic branch deletion after merge\n- Use **Merge** strategy (recommended)  no force pushes needed\n- Merge bottom-to-top (sequential order)\n\n</pr_workflow>\n\n<reorganize>\n\n## Stack Reorganization\n\n### Squashing Within Stack\n\n```bash\nnewer_commit=$(but log | grep \"newer\" | awk '{print $1}')\nolder_commit=$(but log | grep \"older\" | awk '{print $1}')\nbut rub $newer_commit $older_commit\n```\n\n### Moving Commits Between Stack Levels\n\n```bash\ncommit_sha=$(but log | grep \"specific commit\" | awk '{print $1}')\nbut rub $commit_sha correct-branch\n```\n\n### Splitting a Branch\n\n```bash\n# Original has multiple features\nbut branch new second-feature --anchor original-branch\ncommit_sha=$(but log | grep \"second feature commit\" | awk '{print $1}')\nbut rub $commit_sha second-feature\n```\n\n</reorganize>\n\n<navigation>\n\n## Stack Navigation\n\n**Note:** Virtual branches don't need checkout  all branches active simultaneously.\n\n```bash\n# View full stack structure\nbut log\n\n# Work on any branch directly (no checkout needed)\nbut commit base-feature -m \"update base\"\nbut commit dependent-feature -m \"update dependent\"\n\n# JSON for programmatic analysis\nbut --json log | jq '.[] | .branchDetails[] | {name, baseCommit}'\n```\n\n</navigation>\n\n<rules>\n\nALWAYS:\n- Create stacks with `--anchor` from the start\n- Merge stacks bottom-to-top (base first, dependents after)\n- Snapshot before reorganizing: `but snapshot --message \"Before stack reorganization\"`\n- Keep each level small (100-250 LOC) for reviewability\n- Delete empty branches after reorganization\n\nNEVER:\n- Skip stack levels when merging\n- Stack independent, unrelated features (use virtual branches)\n- Create deep stacks (5+ levels) without good reason\n- Forget anchor when creating dependent branches\n\n</rules>\n\n<troubleshooting>\n\n## Common Issues\n\n| Symptom | Cause | Solution |\n|---------|-------|----------|\n| Stack not showing in `but log` | Missing `--anchor` | Recreate with correct anchor |\n| Commits in wrong stack level | Wrong branch targeted | `but rub <sha> correct-branch` |\n| Can't merge middle of stack | Wrong order | Merge bottom-to-top only |\n\n## Recovery\n\n```bash\n# Recreate branch with correct anchor\nbut branch new child-stacked --anchor parent\ncommit_sha=$(but log | grep \"child:\" | head -1 | awk '{print $1}')\nbut rub $commit_sha child-stacked\nbut branch delete child --force\n```\n\n</troubleshooting>\n\n<best_practices>\n\n## Best Practices\n\n### Planning\n\n- Start simple: 2-3 levels max initially\n- Single responsibility per level\n- Only stack when there's a real dependency\n\n### Maintenance\n\n- Run `but log` regularly to verify structure\n- Commit to correct branches immediately\n- Clean up empty branches\n\n### Communication\n\n- Clear commit messages explaining why stack level exists\n- Descriptive names indicating stack relationship\n- Share `but status` when coordinating\n\n</best_practices>\n\n<references>\n\n- [version-control skill](../version-control/SKILL.md)  core GitButler workflows\n- [complete-branch skill](../complete-branch/SKILL.md)  merging to main\n- [multi-agent skill](../multi-agent/SKILL.md)  multi-agent coordination\n- [GitButler Stacks Docs](https://docs.gitbutler.com/features/branch-management/stacked-branches)\n\n</references>"
              },
              {
                "name": "version-control",
                "description": "This skill should be used when working with GitButler, virtual branches, `but` commands, or when `--gitbutler` or `--but` flags are mentioned.",
                "path": "gitbutler/skills/version-control/SKILL.md",
                "frontmatter": {
                  "name": "version-control",
                  "version": "2.0.0",
                  "description": "This skill should be used when working with GitButler, virtual branches, `but` commands, or when `--gitbutler` or `--but` flags are mentioned."
                },
                "content": "# GitButler Version Control\n\nVirtual branches  parallel development  post-hoc organization.\n\n<when_to_use>\n\n- Multiple unrelated features in same workspace simultaneously\n- Multi-agent concurrent development (agents in same repo)\n- Exploratory coding where organization comes after writing\n- Post-hoc commit reorganization needed\n- Visual organization preferred (GUI + CLI)\n\nNOT for: projects using Graphite (incompatible models), simple linear workflows (use plain git), when PR submission automation required end-to-end (use Graphite instead)\n\n</when_to_use>\n\n<core_concepts>\n\n| Concept | Description |\n|---------|-------------|\n| Virtual branches | Multiple branches applied simultaneously to working directory |\n| Integration branch | `gitbutler/workspace` tracks virtual branch state  never touch directly |\n| Target branch | Base branch (e.g., `origin/main`) all work diverges from |\n| File assignment | Assign file hunks to branches with `but rub` |\n| Stacks | Dependent branches via `--anchor` flag |\n| Oplog | Operations log for undo/restore  your safety net |\n\n**Key difference from Git**: All branches visible at once. Organize files to branches after editing. No checkout.\n\n</core_concepts>\n\n<workflow>\n\n## Quick Start\n\n```bash\n# Initialize (one time)\nbut init\n\n# Create branch\nbut branch new feature-auth\n\n# Make changes, check status for file IDs\nbut status\n# 00 [Unassigned Changes]\n#    m6 A src/auth.ts\n\n# Assign file to branch using ID\nbut rub m6 feature-auth\n\n# Commit\nbut commit feature-auth -m \"feat: add authentication\"\n```\n\n## Core Loop\n\n1. **Create**: `but branch new <name>`\n2. **Edit**: Make changes in working directory\n3. **Check**: `but status` to see file IDs\n4. **Assign**: `but rub <file-id> <branch-name>`\n5. **Commit**: `but commit <branch> -m \"message\"`\n6. **Repeat**: Continue with other features in parallel\n\n## The Power of `but rub`\n\nSwiss Army knife  combines entities to perform operations:\n\n| Source | Target | Operation |\n|--------|--------|-----------|\n| File ID | Branch | Assign file to branch |\n| File ID | Commit | Amend commit with file |\n| Commit SHA | Branch | Move commit between branches |\n| Commit SHA | Commit SHA | Squash (newer into older) |\n\n</workflow>\n\n<parallel_development>\n\n## Parallel Feature Development\n\n```bash\n# Create two independent features\nbut branch new feature-a\nbut branch new feature-b\n\n# Edit files for both (same workspace!)\necho \"Feature A\" > feature-a.ts\necho \"Feature B\" > feature-b.ts\n\n# Assign to respective branches\nbut rub <id-a> feature-a\nbut rub <id-b> feature-b\n\n# Commit independently\nbut commit feature-a -m \"feat: implement feature A\"\nbut commit feature-b -m \"feat: implement feature B\"\n\n# Both branches exist, zero conflicts, same directory\n```\n\n## Multi-Agent Workflows\n\nMultiple AI agents working concurrently in same repo:\n\n```bash\n# Agent 1\nbut branch new agent-1-feature\n# ... make changes ...\nbut commit agent-1-feature -m \"feat: add feature X\"\n\n# Agent 2 (simultaneously, same workspace)\nbut branch new agent-2-bugfix\n# ... make changes ...\nbut commit agent-2-bugfix -m \"fix: resolve issue Y\"\n```\n\n**See [multi-agent skill](../multi-agent/SKILL.md) for advanced patterns**\n\n</parallel_development>\n\n<completion>\n\n## Completing Work\n\n**CRITICAL**: GitButler CLI lacks native commands for merging to main or creating PRs. Use git for integration.\n\n```bash\n# 1. Snapshot for safety\nbut snapshot --message \"Before integrating feature-auth\"\n\n# 2. Switch to main\ngit checkout main\n\n# 3. Update main\ngit pull origin main\n\n# 4. Merge virtual branch\ngit merge --no-ff refs/gitbutler/feature-auth -m \"feat: add auth\"\n\n# 5. Push\ngit push origin main\n\n# 6. Clean up and return\nbut branch rm feature-auth\ngit checkout gitbutler/workspace\n```\n\n**See [complete-branch skill](../complete-branch/SKILL.md) for full guided workflow**\n\n</completion>\n\n<commands>\n\n## Essential Commands\n\n| Command | Purpose |\n|---------|---------|\n| `but init` | Initialize GitButler in repository |\n| `but status` | View changes and file IDs |\n| `but log` | View commits on active branches |\n| `but branch new <name>` | Create virtual branch |\n| `but branch new <name> --anchor <parent>` | Create stacked branch |\n| `but rub <source> <target>` | Assign/move/squash/amend |\n| `but commit <branch> -m \"msg\"` | Commit to branch |\n| `but commit <branch> -o -m \"msg\"` | Commit only assigned files |\n| `but publish` | Publish branches to forge (GitHub) |\n| `but forge auth` | Authenticate with GitHub |\n| `but absorb` | Amend uncommitted changes |\n| `but oplog` | Show operation history |\n| `but undo` | Undo last operation |\n| `but snapshot --message \"msg\"` | Create manual snapshot |\n| `but base update` | Update workspace with latest base |\n| `but .` | Open GitButler GUI for current repo |\n\n**Global flags come first**: `but --json status`  | `but status --json` \n\n</commands>\n\n<ai_integration>\n\n## AI Agent Integration\n\nThree integration methods:\n\n**1. Agents Tab** (Claude Code, recommended)\n- GUI-based launcher tied to branches\n- Automatic commit management per session\n- Parallel agent execution with branch isolation\n\n**2. Lifecycle Hooks**\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [{\"matcher\": \"Edit|MultiEdit|Write\", \"hooks\": [{\"type\": \"command\", \"command\": \"but claude pre-tool\"}]}],\n    \"PostToolUse\": [{\"matcher\": \"Edit|MultiEdit|Write\", \"hooks\": [{\"type\": \"command\", \"command\": \"but claude post-tool\"}]}],\n    \"Stop\": [{\"matcher\": \"\", \"hooks\": [{\"type\": \"command\", \"command\": \"but claude stop\"}]}]\n  }\n}\n```\n\n**3. MCP Server**\n\n```bash\nbut mcp  # Start MCP server for agent integration\n```\n\n</ai_integration>\n\n<rules>\n\nALWAYS:\n- Use `but` for all work within virtual branches\n- Use `git` only for integrating completed work into main\n- Return to `gitbutler/workspace` after git operations: `git checkout gitbutler/workspace`\n- Snapshot before risky operations: `but snapshot --message \"...\"`\n- Assign files immediately after creating: `but rub <id> <branch>`\n- Check file IDs with `but status` before using `but rub`\n\nNEVER:\n- Use `git commit` on virtual branches  breaks GitButler state\n- Use `git add`  GitButler manages index\n- Use `git checkout` on virtual branches  no checkout needed\n- Push `gitbutler/integration` to remote  it's local-only\n- Mix Graphite and GitButler in same repo  incompatible models\n- Pipe `but status` directly  causes panic; capture output first:\n\n  ```bash\n  status_output=$(but status)\n  echo \"$status_output\" | head -5\n  ```\n\n</rules>\n\n<troubleshooting>\n\n## Quick Troubleshooting\n\n| Symptom | Cause | Solution |\n|---------|-------|----------|\n| Branch not showing in `but log` | Not tracked | `but track --parent <parent>` |\n| Files not committing | Not assigned | `but rub <file-id> <branch>` |\n| Conflicts in workspace | All branches applied | Resolve in files or reassign hunks |\n| Mixed git/but broke state | Used git commands | `but base update` or reinit |\n| Broken pipe panic | Output consumed partially | Capture output to variable first |\n| Filename with dash fails | Interpreted as range | Use file ID from `but status` |\n| Lost work | Need recovery | Use `but oplog` and `but undo` |\n\n## Recovery Pattern\n\n```bash\n# View recent operations\nbut oplog\n\n# Undo last operation\nbut undo\n\n# Or restore to specific snapshot\nbut restore <snapshot-id>\n\n# If workspace corrupted\nbut base update\n# Last resort: but init\n```\n\n**See [references/reference.md](references/reference.md#troubleshooting-guide) for comprehensive troubleshooting**\n\n</troubleshooting>\n\n<comparison>\n\n## GitButler vs Graphite\n\n| Aspect | Graphite | GitButler |\n|--------|----------|-----------|\n| Model | Linear stacks of physical branches | Virtual branches, optional stacking |\n| Branch switching | Required (`gt up`/`gt down`) | Never needed (all applied) |\n| PR submission |  `gt submit --stack` |  CLI only (use `gh` or GUI) |\n| Multi-agent | Serial (checkout required) | Parallel (virtual branches) |\n| Post-hoc organization | Difficult | `but rub` trivial |\n| CLI completeness | Full automation | Partial (missing PR/push) |\n\n**Choose GitButler for**: Exploratory work, multi-agent, post-hoc organization\n**Choose Graphite for**: Production automation, PR submission, terminal-first\n\n</comparison>\n\n<references>\n\n- [references/reference.md](references/reference.md)  complete CLI reference and troubleshooting\n- [references/examples.md](references/examples.md)  real-world workflow patterns\n- [multi-agent skill](../multi-agent/SKILL.md)  multi-agent coordination\n- [stack-workflows skill](../stack-workflows/SKILL.md)  stacked branches\n- [complete-branch skill](../complete-branch/SKILL.md)  merging to main\n- [GitButler Docs](https://docs.gitbutler.com/)  official documentation\n\n</references>"
              }
            ]
          },
          {
            "name": "cli-dev",
            "description": "Skills for building command-line tools: argument parsing, help text, subcommands, and CLI best practices",
            "source": "./cli-dev",
            "category": null,
            "version": "0.1.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add outfitter-dev/agents",
              "/plugin install cli-dev@outfitter"
            ],
            "signals": {
              "stars": 15,
              "forks": 0,
              "pushed_at": "2026-01-11T17:32:42Z",
              "created_at": "2025-08-30T16:37:06Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "cli-development-guidelines",
                "description": "This skill should be used when designing, implementing, or reviewing CLI tools, or when flags, subcommands, help text, exit codes, or `--cli-dev` are mentioned.",
                "path": "cli-dev/skills/cli-development-guidelines/SKILL.md",
                "frontmatter": {
                  "name": "cli-development-guidelines",
                  "description": "This skill should be used when designing, implementing, or reviewing CLI tools, or when flags, subcommands, help text, exit codes, or `--cli-dev` are mentioned.",
                  "license": "CC-BY-SA-4.0 (docs, adapted from clig.dev); MIT (scripts)",
                  "compatibility": "Scripts use Python 3.10+ (scripts/cli_audit.py).",
                  "metadata": {
                    "version": "0.1.0",
                    "upstream": "clig.dev + POSIX/GNU/Heroku/12-factor + Agent Skills spec"
                  }
                },
                "content": "# CLI Development Guidelines\n\n## When to activate this skill\n\n- You are *designing*, *implementing*, or *reviewing* a command-line tool.\n- The user mentions (explicitly or implicitly): `--help`, flags, subcommands, exit codes, stdout/stderr, piping, JSON output, color, prompts, config files, env vars, works in CI, install/uninstall, telemetry.\n\n## What this skill produces\n\n- A *CLI contract* (what users can rely on): commands, flags, IO behavior, exit codes, config/env, examples, and safety behavior.\n- Draft *help output* and docs structure (example-first).\n- A *compliance audit* (when runnable) using `scripts/cli_audit.py`.\n\n## Non-negotiable CLI citizenship\n\n- Exit codes:\n  - `0` on success.\n  - Non-zero on failure (and ideally meaningful, documented codes).\n- Streams:\n  - `stdout` is for primary output and machine-readable output.\n  - `stderr` is for errors, warnings, progress, and what Im doing messaging.\n- Discoverability:\n  - `--help` (and usually `-h`) shows help and exits.\n  - `--version` prints version and exits.\n- Interactivity:\n  - Prompts only when `stdin` is a TTY.\n  - Provide `--no-input` to force non-interactive behavior.\n- Scripting friendliness:\n  - No ANSI color / spinners when output isnt a TTY.\n  - Support `NO_COLOR` and `--no-color`.\n  - Consider `--json` and `--plain` for stable output.\n\n## Workflow\n\n### Sketch the CLI contract first\n\n- Start from the users jobs-to-be-done (what theyre trying to accomplish).\n- Decide:\n  - Command shape: single command vs subcommands (`noun verb` is common).\n  - Inputs: args vs flags vs stdin vs prompts vs config/env.\n  - Outputs: human default, plus machine modes (`--json`, `--plain`, `--quiet`).\n  - Safety: confirmations, `--dry-run`, `--force`, secret handling.\n\nUse:\n- [CLI reference](references/REFERENCE.md)\n- [CLI spec template](templates/cli-command-spec-template.json)\n\n### Implement with safe defaults\n\n- Use a CLI parsing library (dont hand-roll).\n- Make boundary-crossing actions explicit:\n  - Network calls\n  - Writing files not explicitly provided\n  - Mutating remote state\n- Avoid footguns:\n  - Dont accept secrets via flags or environment variables.\n  - Dont print stack traces by default.\n  - Dont assume TTY (detect it).\n\n### Validate and iterate\n\n- Run an automated sanity check (when possible):\n  - `python scripts/cli_audit.py -- <your-cli> [subcommand]`\n- Fix in this order:\n  - Broken stdout/stderr separation\n  - Incorrect exit codes\n  - Help thats missing or undiscoverable\n  - Unsafe defaults (destructive ops, secrets, hidden network writes)\n  - Unscriptable output (no stable modes)\n\nUse:\n- [Checklist](references/CHECKLIST.md)\n- `scripts/cli_audit.py`\n\n## Reference library\n\n- Core reference: [references/REFERENCE.md](references/REFERENCE.md)\n- Quick audit checklist: [references/CHECKLIST.md](references/CHECKLIST.md)\n- Evaluation prompts: [references/EVAL_PROMPTS.md](references/EVAL_PROMPTS.md)\n\n## Templates and scripts\n\n- CLI spec template: `templates/cli-command-spec-template.json`\n- Help text template: `templates/help-text-template.md`\n- Error message template: `templates/error-message-template.md`\n- Audit a CLI: `scripts/cli_audit.py`"
              }
            ]
          }
        ]
      }
    }
  ]
}