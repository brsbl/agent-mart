{
  "owner": {
    "id": "tylerburleigh",
    "display_name": "Tyler Burleigh",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/3513754?u=e33be4b8ad3d2f22c3737999fb8b566e61dfedbe&v=4",
    "url": "https://github.com/tylerburleigh",
    "bio": "AI Research Scientist @ Khan Academy\r\n\r\nBuilder, AI coding enthusiast",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 12,
      "total_stars": 5,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "tylerburleigh/claude-sdd-toolkit",
      "url": "https://github.com/tylerburleigh/claude-sdd-toolkit",
      "description": "Development tools and workflows for Claude Code to support Spec Driven Development.",
      "homepage": "",
      "signals": {
        "stars": 5,
        "forks": 0,
        "pushed_at": "2025-12-02T21:43:10Z",
        "created_at": "2025-10-24T13:23:12Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agents/sdd-next.md",
          "type": "blob",
          "size": 6674
        },
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 287
        },
        {
          "path": ".doc-cache",
          "type": "tree",
          "size": null
        },
        {
          "path": ".doc-cache/parse_cache.db",
          "type": "blob",
          "size": 1744896
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 646
        },
        {
          "path": "PLAN_ENHANCE.md",
          "type": "blob",
          "size": 5628
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 8997
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/doc-query.md",
          "type": "blob",
          "size": 5202
        },
        {
          "path": "agents/run-tests.md",
          "type": "blob",
          "size": 5428
        },
        {
          "path": "agents/sdd-fidelity-review.md",
          "type": "blob",
          "size": 5612
        },
        {
          "path": "agents/sdd-modify.md",
          "type": "blob",
          "size": 9344
        },
        {
          "path": "agents/sdd-plan-review.md",
          "type": "blob",
          "size": 4783
        },
        {
          "path": "agents/sdd-pr.md",
          "type": "blob",
          "size": 8671
        },
        {
          "path": "agents/sdd-update.md",
          "type": "blob",
          "size": 11037
        },
        {
          "path": "agents/sdd-validate.md",
          "type": "blob",
          "size": 6103
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/sdd-begin.md",
          "type": "blob",
          "size": 10617
        },
        {
          "path": "commands/sdd-setup.md",
          "type": "blob",
          "size": 22455
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/advanced-topics.md",
          "type": "blob",
          "size": 21024
        },
        {
          "path": "docs/architecture.md",
          "type": "blob",
          "size": 12328
        },
        {
          "path": "docs/changelog.md",
          "type": "blob",
          "size": 36387
        },
        {
          "path": "docs/cli-reference.md",
          "type": "blob",
          "size": 21694
        },
        {
          "path": "docs/codebase.json",
          "type": "blob",
          "size": 7144593
        },
        {
          "path": "docs/component-inventory.md",
          "type": "blob",
          "size": 6316
        },
        {
          "path": "docs/configuration.md",
          "type": "blob",
          "size": 18659
        },
        {
          "path": "docs/core-concepts.md",
          "type": "blob",
          "size": 12052
        },
        {
          "path": "docs/doc-generation-state.json",
          "type": "blob",
          "size": 718
        },
        {
          "path": "docs/getting-started.md",
          "type": "blob",
          "size": 7040
        },
        {
          "path": "docs/index.md",
          "type": "blob",
          "size": 1559
        },
        {
          "path": "docs/project-overview.md",
          "type": "blob",
          "size": 6614
        },
        {
          "path": "docs/providers",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/providers/OVERVIEW.md",
          "type": "blob",
          "size": 14112
        },
        {
          "path": "docs/security",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/security/PROVIDER_SECURITY.md",
          "type": "blob",
          "size": 15031
        },
        {
          "path": "docs/security/TESTING.md",
          "type": "blob",
          "size": 13998
        },
        {
          "path": "docs/security/THREAT_MODEL.md",
          "type": "blob",
          "size": 12572
        },
        {
          "path": "docs/skills-reference.md",
          "type": "blob",
          "size": 24097
        },
        {
          "path": "docs/third-party-notices.md",
          "type": "blob",
          "size": 1987
        },
        {
          "path": "docs/troubleshooting.md",
          "type": "blob",
          "size": 16667
        },
        {
          "path": "docs/workflows.md",
          "type": "blob",
          "size": 25081
        },
        {
          "path": "hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/block-codebase-bash-access",
          "type": "blob",
          "size": 3771
        },
        {
          "path": "hooks/block-codebase-json",
          "type": "blob",
          "size": 3623
        },
        {
          "path": "hooks/block-json-specs",
          "type": "blob",
          "size": 3915
        },
        {
          "path": "hooks/block-spec-bash-access",
          "type": "blob",
          "size": 3898
        },
        {
          "path": "hooks/hooks.json",
          "type": "blob",
          "size": 713
        },
        {
          "path": "pytest.ini",
          "type": "blob",
          "size": 679
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/benchmark_output_tokens.py",
          "type": "blob",
          "size": 14772
        },
        {
          "path": "scripts/benchmark_prepare_task_latency.py",
          "type": "blob",
          "size": 9766
        },
        {
          "path": "scripts/extract_sdd_commands.py",
          "type": "blob",
          "size": 7178
        },
        {
          "path": "scripts/measure_token_efficiency.py",
          "type": "blob",
          "size": 8931
        },
        {
          "path": "scripts/test_compact_json.sh",
          "type": "blob",
          "size": 8185
        },
        {
          "path": "scripts/validate_sdd_commands.py",
          "type": "blob",
          "size": 17331
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/doc-query",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/doc-query/SKILL.md",
          "type": "blob",
          "size": 34286
        },
        {
          "path": "skills/doc-query/config.yaml",
          "type": "blob",
          "size": 2169
        },
        {
          "path": "skills/llm-doc-gen",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/llm-doc-gen/SKILL.md",
          "type": "blob",
          "size": 24202
        },
        {
          "path": "skills/run-tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/run-tests/SKILL.md",
          "type": "blob",
          "size": 17010
        },
        {
          "path": "skills/sdd-fidelity-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-fidelity-review/SKILL.md",
          "type": "blob",
          "size": 15468
        },
        {
          "path": "skills/sdd-modify",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-modify/SKILL.md",
          "type": "blob",
          "size": 30403
        },
        {
          "path": "skills/sdd-modify/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-modify/examples/apply-review.md",
          "type": "blob",
          "size": 18342
        },
        {
          "path": "skills/sdd-modify/examples/bulk-modify.md",
          "type": "blob",
          "size": 23754
        },
        {
          "path": "skills/sdd-modify/examples/interactive.md",
          "type": "blob",
          "size": 13078
        },
        {
          "path": "skills/sdd-next",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-next/SKILL.md",
          "type": "blob",
          "size": 30584
        },
        {
          "path": "skills/sdd-plan-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-plan-review/SKILL.md",
          "type": "blob",
          "size": 23971
        },
        {
          "path": "skills/sdd-plan",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-plan/SKILL.md",
          "type": "blob",
          "size": 50179
        },
        {
          "path": "skills/sdd-pr",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-pr/SKILL.md",
          "type": "blob",
          "size": 10895
        },
        {
          "path": "skills/sdd-render",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-render/SKILL.md",
          "type": "blob",
          "size": 55961
        },
        {
          "path": "skills/sdd-update",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-update/SKILL.md",
          "type": "blob",
          "size": 30963
        },
        {
          "path": "skills/sdd-validate",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sdd-validate/SKILL.md",
          "type": "blob",
          "size": 10199
        },
        {
          "path": "specs",
          "type": "tree",
          "size": null
        },
        {
          "path": "specs/active",
          "type": "tree",
          "size": null
        },
        {
          "path": "specs/active/prepare-task-doc-context-2025-11-24-001.json",
          "type": "blob",
          "size": 23803
        },
        {
          "path": "specs/active/prepare-task-enriched-context-2025-01-24-001.json",
          "type": "blob",
          "size": 39297
        },
        {
          "path": "specs/archived",
          "type": "tree",
          "size": null
        },
        {
          "path": "specs/archived/git-integration-2025-10-26-001.json",
          "type": "blob",
          "size": 60315
        },
        {
          "path": "specs/archived/list-specs-improvements-2025-11-09-001.json",
          "type": "blob",
          "size": 30733
        },
        {
          "path": "specs/archived/multi-file-docs-bmad-2025-11-16-001.json",
          "type": "blob",
          "size": 79889
        },
        {
          "path": "specs/archived/rich-output-optimization-2025-11-07-001.json",
          "type": "blob",
          "size": 72136
        },
        {
          "path": "specs/completed",
          "type": "tree",
          "size": null
        },
        {
          "path": "specs/completed/add-pending-folder-support-for-2025-10-30-0847.json",
          "type": "blob",
          "size": 89119
        },
        {
          "path": "specs/completed/ai-consultation-refactor-2025-11-05-001.json",
          "type": "blob",
          "size": 113695
        },
        {
          "path": "specs/completed/ai-enhanced-rendering-2025-10-28-001.json",
          "type": "blob",
          "size": 104209
        },
        {
          "path": "specs/completed/auto-completion-detection-2025-10-26-001.json",
          "type": "blob",
          "size": 59741
        },
        {
          "path": "specs/completed/auto-time-tracking-2025-10-27-001.json",
          "type": "blob",
          "size": 75705
        },
        {
          "path": "specs/completed/cli-verbosity-reduction-2025-11-09-001.json",
          "type": "blob",
          "size": 39128
        },
        {
          "path": "specs/completed/cli-verbosity-rollout-2025-11-15-001.json",
          "type": "blob",
          "size": 126121
        },
        {
          "path": "specs/completed/code-doc-integration-2025-10-24-002.json",
          "type": "blob",
          "size": 121203
        },
        {
          "path": "specs/completed/compact-json-output-2025-11-03-001.json",
          "type": "blob",
          "size": 81814
        },
        {
          "path": "specs/completed/doc-query-enhancements-2025-10-24-001.json",
          "type": "blob",
          "size": 83704
        },
        {
          "path": "specs/completed/doc-scope-enhancements-2025-11-21-001.json",
          "type": "blob",
          "size": 55127
        },
        {
          "path": "specs/completed/enhance-sdd-fix-deps-2025-11-17-001.json",
          "type": "blob",
          "size": 53181
        },
        {
          "path": "specs/completed/feedback-review-2025-11-18-001.json",
          "type": "blob",
          "size": 82970
        },
        {
          "path": "specs/completed/git-agent-file-staging-2025-11-03-001.json",
          "type": "blob",
          "size": 61897
        },
        {
          "path": "specs/completed/git-integration-simplified-2025-11-02-001.json",
          "type": "blob",
          "size": 90078
        },
        {
          "path": "specs/completed/integrate-code-doc-2025-11-20-001.json",
          "type": "blob",
          "size": 28712
        },
        {
          "path": "specs/completed/journal-accessibility-2025-11-19-001.json",
          "type": "blob",
          "size": 51403
        },
        {
          "path": "specs/completed/json-output-standardization-2025-11-08-001.json",
          "type": "blob",
          "size": 103360
        },
        {
          "path": "specs/completed/llm-doc-analysis-integration-2025-11-20-001.json",
          "type": "blob",
          "size": 127011
        },
        {
          "path": "specs/completed/llm-doc-gen-2025-11-19-001.json",
          "type": "blob",
          "size": 147128
        },
        {
          "path": "specs/completed/llm-doc-gen-optimization-2025-11-20-001.json",
          "type": "blob",
          "size": 166054
        },
        {
          "path": "specs/completed/opencode-provider-2025-11-18-001.json",
          "type": "blob",
          "size": 122103
        },
        {
          "path": "specs/completed/phase5-agent-optimization-2025-11-07-001.json",
          "type": "blob",
          "size": 92177
        },
        {
          "path": "specs/completed/plain-mode-support-2025-11-08-001.json",
          "type": "blob",
          "size": 86665
        },
        {
          "path": "specs/completed/plain-text-output-config-2025-11-08-001.json",
          "type": "blob",
          "size": 60970
        },
        {
          "path": "specs/completed/prepare-task-default-context-2025-11-23-001.json",
          "type": "blob",
          "size": 70864
        },
        {
          "path": "specs/completed/prepare-task-doc-context-2025-11-24-001.json",
          "type": "blob",
          "size": 24090
        },
        {
          "path": "specs/completed/provider-abstraction-refactor-2025-11-10-001.json",
          "type": "blob",
          "size": 35520
        },
        {
          "path": "specs/completed/readme-simplification-2025-11-22-001.json",
          "type": "blob",
          "size": 50095
        },
        {
          "path": "specs/completed/sdd-begin-cli-streamline-2025-11-17-001.json",
          "type": "blob",
          "size": 10918
        },
        {
          "path": "specs/completed/sdd-cli-config-2025-11-03-001.json",
          "type": "blob",
          "size": 64846
        },
        {
          "path": "specs/completed/sdd-fidelity-review-2025-11-05-001.json",
          "type": "blob",
          "size": 123778
        },
        {
          "path": "specs/completed/sdd-next-context-optimization-2025-11-15-001.json",
          "type": "blob",
          "size": 46559
        },
        {
          "path": "specs/completed/sdd-validate-docs-2025-10-24-001.json",
          "type": "blob",
          "size": 27314
        },
        {
          "path": "specs/completed/setup-template-centralization-2025-11-10-001.json",
          "type": "blob",
          "size": 56657
        },
        {
          "path": "specs/completed/spec-modification-tools-2025-11-02-001.json",
          "type": "blob",
          "size": 117158
        },
        {
          "path": "specs/completed/specs-reorganization-2025-10-24-001.json",
          "type": "blob",
          "size": 44147
        },
        {
          "path": "specs/completed/subagent-refactoring-2025-10-28-001.json",
          "type": "blob",
          "size": 71859
        },
        {
          "path": "specs/completed/task-category-metadata-2025-10-26-001.json",
          "type": "blob",
          "size": 53914
        },
        {
          "path": "specs/completed/tui-upgrade-2025-11-06-001.json",
          "type": "blob",
          "size": 197080
        },
        {
          "path": "specs/completed/update-task-metadata-cli-2025-11-01-001.json",
          "type": "blob",
          "size": 23126
        },
        {
          "path": "specs/completed/verbosity-remaining-commands-2025-11-15-001.json",
          "type": "blob",
          "size": 85361
        },
        {
          "path": "specs/pending",
          "type": "tree",
          "size": null
        },
        {
          "path": "specs/pending/cli-command-naming-2025-11-19-001.json",
          "type": "blob",
          "size": 10751
        },
        {
          "path": "specs/pending/semantic-search-2025-10-24-001.json",
          "type": "blob",
          "size": 49620
        },
        {
          "path": "src",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/.gitignore",
          "type": "blob",
          "size": 897
        },
        {
          "path": "src/claude_skills/README.md",
          "type": "blob",
          "size": 6842
        },
        {
          "path": "src/claude_skills/claude_skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/__init__.py",
          "type": "blob",
          "size": 830
        },
        {
          "path": "src/claude_skills/claude_skills/cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/cli/__init__.py",
          "type": "blob",
          "size": 50
        },
        {
          "path": "src/claude_skills/claude_skills/cli/provider_runner.py",
          "type": "blob",
          "size": 12345
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/__init__.py",
          "type": "blob",
          "size": 10761
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/llm_doc_gen_cmd.py",
          "type": "blob",
          "size": 9289
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/options.py",
          "type": "blob",
          "size": 5354
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/output_utils.py",
          "type": "blob",
          "size": 25860
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/registry.py",
          "type": "blob",
          "size": 10868
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/schema.py",
          "type": "blob",
          "size": 1787
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/verbosity.py",
          "type": "blob",
          "size": 4900
        },
        {
          "path": "src/claude_skills/claude_skills/cli/sdd/work_mode.py",
          "type": "blob",
          "size": 1530
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev/gendocs.py",
          "type": "blob",
          "size": 1774
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev/git_config_helper.py",
          "type": "blob",
          "size": 19163
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev/install_helper.py",
          "type": "blob",
          "size": 14532
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev/migrate.py",
          "type": "blob",
          "size": 2626
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev/registry.py",
          "type": "blob",
          "size": 1189
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev/setup_permissions.py",
          "type": "blob",
          "size": 27019
        },
        {
          "path": "src/claude_skills/claude_skills/cli/skills_dev/start_helper.py",
          "type": "blob",
          "size": 17779
        },
        {
          "path": "src/claude_skills/claude_skills/common",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/common/__init__.py",
          "type": "blob",
          "size": 8161
        },
        {
          "path": "src/claude_skills/claude_skills/common/ai_config.py",
          "type": "blob",
          "size": 35691
        },
        {
          "path": "src/claude_skills/claude_skills/common/ai_config_setup.py",
          "type": "blob",
          "size": 4896
        },
        {
          "path": "src/claude_skills/claude_skills/common/ai_tools.py",
          "type": "blob",
          "size": 29390
        },
        {
          "path": "src/claude_skills/claude_skills/common/cache",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/common/cache/__init__.py",
          "type": "blob",
          "size": 450
        },
        {
          "path": "src/claude_skills/claude_skills/common/cache/cache_key.py",
          "type": "blob",
          "size": 7241
        },
        {
          "path": "src/claude_skills/claude_skills/common/cache/cache_manager.py",
          "type": "blob",
          "size": 21851
        },
        {
          "path": "src/claude_skills/claude_skills/common/cache/cli.py",
          "type": "blob",
          "size": 8788
        },
        {
          "path": "src/claude_skills/claude_skills/common/cli_utils.py",
          "type": "blob",
          "size": 4933
        },
        {
          "path": "src/claude_skills/claude_skills/common/completion.py",
          "type": "blob",
          "size": 16992
        },
        {
          "path": "src/claude_skills/claude_skills/common/config.py",
          "type": "blob",
          "size": 8839
        },
        {
          "path": "src/claude_skills/claude_skills/common/consultation_limits.py",
          "type": "blob",
          "size": 3118
        },
        {
          "path": "src/claude_skills/claude_skills/common/contracts.py",
          "type": "blob",
          "size": 19922
        },
        {
          "path": "src/claude_skills/claude_skills/common/dependency_analysis.py",
          "type": "blob",
          "size": 12345
        },
        {
          "path": "src/claude_skills/claude_skills/common/doc_helper.py",
          "type": "blob",
          "size": 23436
        },
        {
          "path": "src/claude_skills/claude_skills/common/doc_integration.py",
          "type": "blob",
          "size": 12270
        },
        {
          "path": "src/claude_skills/claude_skills/common/git_config.py",
          "type": "blob",
          "size": 9916
        },
        {
          "path": "src/claude_skills/claude_skills/common/git_metadata.py",
          "type": "blob",
          "size": 21487
        },
        {
          "path": "src/claude_skills/claude_skills/common/hierarchy_validation.py",
          "type": "blob",
          "size": 30815
        },
        {
          "path": "src/claude_skills/claude_skills/common/integrations.py",
          "type": "blob",
          "size": 19943
        },
        {
          "path": "src/claude_skills/claude_skills/common/json_output.py",
          "type": "blob",
          "size": 8393
        },
        {
          "path": "src/claude_skills/claude_skills/common/metrics.py",
          "type": "blob",
          "size": 6361
        },
        {
          "path": "src/claude_skills/claude_skills/common/paths.py",
          "type": "blob",
          "size": 23856
        },
        {
          "path": "src/claude_skills/claude_skills/common/plain_ui.py",
          "type": "blob",
          "size": 19853
        },
        {
          "path": "src/claude_skills/claude_skills/common/printer.py",
          "type": "blob",
          "size": 10597
        },
        {
          "path": "src/claude_skills/claude_skills/common/progress.py",
          "type": "blob",
          "size": 13137
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/.gitignore",
          "type": "blob",
          "size": 349
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/__init__.py",
          "type": "blob",
          "size": 3511
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/base.py",
          "type": "blob",
          "size": 10121
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/claude.py",
          "type": "blob",
          "size": 14767
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/codex.py",
          "type": "blob",
          "size": 19514
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/cursor_agent.py",
          "type": "blob",
          "size": 22174
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/detectors.py",
          "type": "blob",
          "size": 5839
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/gemini.py",
          "type": "blob",
          "size": 13070
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/opencode.py",
          "type": "blob",
          "size": 20838
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/opencode",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/opencode/.gitignore",
          "type": "blob",
          "size": 72
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/opencode/.package-lock.json",
          "type": "blob",
          "size": 400
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/opencode/package.json",
          "type": "blob",
          "size": 485
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/opencode_wrapper.js",
          "type": "blob",
          "size": 7362
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/package.json",
          "type": "blob",
          "size": 531
        },
        {
          "path": "src/claude_skills/claude_skills/common/providers/registry.py",
          "type": "blob",
          "size": 11648
        },
        {
          "path": "src/claude_skills/claude_skills/common/query_operations.py",
          "type": "blob",
          "size": 17973
        },
        {
          "path": "src/claude_skills/claude_skills/common/reporting.py",
          "type": "blob",
          "size": 7467
        },
        {
          "path": "src/claude_skills/claude_skills/common/rich_ui.py",
          "type": "blob",
          "size": 20716
        },
        {
          "path": "src/claude_skills/claude_skills/common/schema_loader.py",
          "type": "blob",
          "size": 3159
        },
        {
          "path": "src/claude_skills/claude_skills/common/sdd_config.py",
          "type": "blob",
          "size": 16580
        },
        {
          "path": "src/claude_skills/claude_skills/common/setup_templates.py",
          "type": "blob",
          "size": 4652
        },
        {
          "path": "src/claude_skills/claude_skills/common/spec.py",
          "type": "blob",
          "size": 12045
        },
        {
          "path": "src/claude_skills/claude_skills/common/spec_analysis.py",
          "type": "blob",
          "size": 10712
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/__init__.py",
          "type": "blob",
          "size": 375
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/backups_readme.md",
          "type": "blob",
          "size": 3563
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/fidelity_reviews_readme.md",
          "type": "blob",
          "size": 5021
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/human_readable_readme.md",
          "type": "blob",
          "size": 3547
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/reports_readme.md",
          "type": "blob",
          "size": 2853
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/reviews_readme.md",
          "type": "blob",
          "size": 3650
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/setup",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/setup/__init__.py",
          "type": "blob",
          "size": 774
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/setup/ai_config.yaml",
          "type": "blob",
          "size": 5987
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/setup/git_config.json",
          "type": "blob",
          "size": 1516
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/setup/sdd_config.json",
          "type": "blob",
          "size": 701
        },
        {
          "path": "src/claude_skills/claude_skills/common/templates/setup/settings.local.json",
          "type": "blob",
          "size": 4165
        },
        {
          "path": "src/claude_skills/claude_skills/common/tui_progress.py",
          "type": "blob",
          "size": 21518
        },
        {
          "path": "src/claude_skills/claude_skills/common/ui_factory.py",
          "type": "blob",
          "size": 8938
        },
        {
          "path": "src/claude_skills/claude_skills/common/ui_protocol.py",
          "type": "blob",
          "size": 7585
        },
        {
          "path": "src/claude_skills/claude_skills/common/validation.py",
          "type": "blob",
          "size": 8688
        },
        {
          "path": "src/claude_skills/claude_skills/context_tracker",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/context_tracker/__init__.py",
          "type": "blob",
          "size": 148
        },
        {
          "path": "src/claude_skills/claude_skills/context_tracker/cli.py",
          "type": "blob",
          "size": 21839
        },
        {
          "path": "src/claude_skills/claude_skills/context_tracker/parser.py",
          "type": "blob",
          "size": 4087
        },
        {
          "path": "src/claude_skills/claude_skills/dev_tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/dev_tools/README.md",
          "type": "blob",
          "size": 5244
        },
        {
          "path": "src/claude_skills/claude_skills/dev_tools/__init__.py",
          "type": "blob",
          "size": 100
        },
        {
          "path": "src/claude_skills/claude_skills/dev_tools/generate_docs.py",
          "type": "blob",
          "size": 12225
        },
        {
          "path": "src/claude_skills/claude_skills/dev_tools/sdd_start_helper.py",
          "type": "blob",
          "size": 12503
        },
        {
          "path": "src/claude_skills/claude_skills/dev_tools/setup_project_permissions.py",
          "type": "blob",
          "size": 14307
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/__init__.py",
          "type": "blob",
          "size": 369
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/cli.py",
          "type": "blob",
          "size": 56393
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/codebase_query.py",
          "type": "blob",
          "size": 14570
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/doc_query_lib.py",
          "type": "blob",
          "size": 63088
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/sdd_integration.py",
          "type": "blob",
          "size": 29282
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/workflows/__init__.py",
          "type": "blob",
          "size": 448
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/workflows/impact_analysis.py",
          "type": "blob",
          "size": 24725
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/workflows/refactor_candidates.py",
          "type": "blob",
          "size": 16180
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/workflows/trace_data.py",
          "type": "blob",
          "size": 19620
        },
        {
          "path": "src/claude_skills/claude_skills/doc_query/workflows/trace_entry.py",
          "type": "blob",
          "size": 15074
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/AB_TESTING_README.md",
          "type": "blob",
          "size": 13849
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/__init__.py",
          "type": "blob",
          "size": 975
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/ab_testing.py",
          "type": "blob",
          "size": 24226
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/ai_consultation.py",
          "type": "blob",
          "size": 9030
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/__init__.py",
          "type": "blob",
          "size": 461
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/ai_consultation.py",
          "type": "blob",
          "size": 28585
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/analysis_insights.py",
          "type": "blob",
          "size": 26754
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/ast_analysis.py",
          "type": "blob",
          "size": 19974
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/calculator.py",
          "type": "blob",
          "size": 4440
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/cli.py",
          "type": "blob",
          "size": 27773
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/detectors.py",
          "type": "blob",
          "size": 14283
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/formatter.py",
          "type": "blob",
          "size": 22001
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/generator.py",
          "type": "blob",
          "size": 17075
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/optimization",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/optimization/__init__.py",
          "type": "blob",
          "size": 1133
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/optimization/cache.py",
          "type": "blob",
          "size": 13681
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/optimization/filters.py",
          "type": "blob",
          "size": 20510
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/optimization/indexing.py",
          "type": "blob",
          "size": 28368
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/optimization/parallel.py",
          "type": "blob",
          "size": 13305
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/optimization/streaming.py",
          "type": "blob",
          "size": 24125
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parser.py",
          "type": "blob",
          "size": 6817
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/__init__.py",
          "type": "blob",
          "size": 1281
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/base.py",
          "type": "blob",
          "size": 15117
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/css.py",
          "type": "blob",
          "size": 7537
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/factory.py",
          "type": "blob",
          "size": 15468
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/go.py",
          "type": "blob",
          "size": 13425
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/html.py",
          "type": "blob",
          "size": 7302
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/javascript.py",
          "type": "blob",
          "size": 14120
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/parsers/python.py",
          "type": "blob",
          "size": 24245
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/performance_benchmark.py",
          "type": "blob",
          "size": 16743
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/schema.py",
          "type": "blob",
          "size": 14721
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/analysis/tree_cache.py",
          "type": "blob",
          "size": 4673
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/data_collector.py",
          "type": "blob",
          "size": 16256
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/detectors.py",
          "type": "blob",
          "size": 20031
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/freshness.py",
          "type": "blob",
          "size": 11453
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/generators",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/generators/__init__.py",
          "type": "blob",
          "size": 728
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/generators/architecture_generator.py",
          "type": "blob",
          "size": 25220
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/generators/component_generator.py",
          "type": "blob",
          "size": 17831
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/generators/index_generator.py",
          "type": "blob",
          "size": 17915
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/generators/overview_generator.py",
          "type": "blob",
          "size": 15608
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/main.py",
          "type": "blob",
          "size": 16534
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/markdown_validator.py",
          "type": "blob",
          "size": 6322
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/orchestrator.py",
          "type": "blob",
          "size": 11953
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/parsers.py",
          "type": "blob",
          "size": 8741
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/state_manager.py",
          "type": "blob",
          "size": 22603
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/test_detectors.py",
          "type": "blob",
          "size": 11407
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/test_parsers.py",
          "type": "blob",
          "size": 4818
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/test_state_manager.py",
          "type": "blob",
          "size": 25473
        },
        {
          "path": "src/claude_skills/claude_skills/llm_doc_gen/workflow_engine.py",
          "type": "blob",
          "size": 23585
        },
        {
          "path": "src/claude_skills/claude_skills/run_tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/run_tests/__init__.py",
          "type": "blob",
          "size": 312
        },
        {
          "path": "src/claude_skills/claude_skills/run_tests/cli.py",
          "type": "blob",
          "size": 14366
        },
        {
          "path": "src/claude_skills/claude_skills/run_tests/consultation.py",
          "type": "blob",
          "size": 37404
        },
        {
          "path": "src/claude_skills/claude_skills/run_tests/pytest_parser.py",
          "type": "blob",
          "size": 11241
        },
        {
          "path": "src/claude_skills/claude_skills/run_tests/pytest_runner.py",
          "type": "blob",
          "size": 8026
        },
        {
          "path": "src/claude_skills/claude_skills/run_tests/test_discovery.py",
          "type": "blob",
          "size": 13220
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_fidelity_review",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_fidelity_review/__init__.py",
          "type": "blob",
          "size": 313
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_fidelity_review/cli.py",
          "type": "blob",
          "size": 26354
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_fidelity_review/consultation.py",
          "type": "blob",
          "size": 59020
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_fidelity_review/report.py",
          "type": "blob",
          "size": 38729
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_fidelity_review/review.py",
          "type": "blob",
          "size": 48959
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next/__init__.py",
          "type": "blob",
          "size": 842
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next/cli.py",
          "type": "blob",
          "size": 58827
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next/context_utils.py",
          "type": "blob",
          "size": 19067
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next/discovery.py",
          "type": "blob",
          "size": 25499
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next/project.py",
          "type": "blob",
          "size": 11988
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next/validation.py",
          "type": "blob",
          "size": 5619
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_next/workflow.py",
          "type": "blob",
          "size": 2339
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan/__init__.py",
          "type": "blob",
          "size": 669
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan/cli.py",
          "type": "blob",
          "size": 9194
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan/planner.py",
          "type": "blob",
          "size": 5634
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan/templates.py",
          "type": "blob",
          "size": 9576
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan_review",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan_review/__init__.py",
          "type": "blob",
          "size": 723
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan_review/cli.py",
          "type": "blob",
          "size": 17389
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan_review/prompts.py",
          "type": "blob",
          "size": 9767
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan_review/reporting.py",
          "type": "blob",
          "size": 3663
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan_review/reviewer.py",
          "type": "blob",
          "size": 5326
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_plan_review/synthesis.py",
          "type": "blob",
          "size": 11188
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_pr",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_pr/__init__.py",
          "type": "blob",
          "size": 585
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_pr/cli.py",
          "type": "blob",
          "size": 10334
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_pr/pr_context.py",
          "type": "blob",
          "size": 11397
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_pr/pr_creation.py",
          "type": "blob",
          "size": 7085
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/__init__.py",
          "type": "blob",
          "size": 1533
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/ai_prompts.py",
          "type": "blob",
          "size": 17196
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/cli.py",
          "type": "blob",
          "size": 12816
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/complexity_scorer.py",
          "type": "blob",
          "size": 15235
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/dependency_graph.py",
          "type": "blob",
          "size": 18396
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/executive_summary.py",
          "type": "blob",
          "size": 18592
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/insight_generator.py",
          "type": "blob",
          "size": 20493
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/markdown_enhancer.py",
          "type": "blob",
          "size": 22924
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/markdown_parser.py",
          "type": "blob",
          "size": 17762
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/narrative_enhancer.py",
          "type": "blob",
          "size": 16307
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/orchestrator.py",
          "type": "blob",
          "size": 23404
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/priority_ranker.py",
          "type": "blob",
          "size": 13926
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/progressive_disclosure.py",
          "type": "blob",
          "size": 14863
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/renderer.py",
          "type": "blob",
          "size": 9679
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/spec_analyzer.py",
          "type": "blob",
          "size": 15679
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/task_grouper.py",
          "type": "blob",
          "size": 16952
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_render/visualization_builder.py",
          "type": "blob",
          "size": 19227
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/MODIFICATIONS_FORMAT.md",
          "type": "blob",
          "size": 7724
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/__init__.py",
          "type": "blob",
          "size": 905
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/assumptions.py",
          "type": "blob",
          "size": 6340
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/cli.py",
          "type": "blob",
          "size": 16105
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/estimates.py",
          "type": "blob",
          "size": 4716
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/examples/bulk_modifications_example.json",
          "type": "blob",
          "size": 1419
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/modification.py",
          "type": "blob",
          "size": 56377
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/modifications_schema.json",
          "type": "blob",
          "size": 5423
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/review_parser.py",
          "type": "blob",
          "size": 19931
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/revision.py",
          "type": "blob",
          "size": 8334
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_spec_mod/task_operations.py",
          "type": "blob",
          "size": 9247
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/__init__.py",
          "type": "blob",
          "size": 1178
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/cli.py",
          "type": "blob",
          "size": 84120
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/git_commit.py",
          "type": "blob",
          "size": 7966
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/git_pr.py",
          "type": "blob",
          "size": 9990
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/journal.py",
          "type": "blob",
          "size": 20456
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/lifecycle.py",
          "type": "blob",
          "size": 16515
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/list_phases.py",
          "type": "blob",
          "size": 6430
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/list_specs.py",
          "type": "blob",
          "size": 9171
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/operations",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/operations/fix_imports.sh",
          "type": "blob",
          "size": 626
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/query.py",
          "type": "blob",
          "size": 4172
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/query_tasks.py",
          "type": "blob",
          "size": 9644
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/status.py",
          "type": "blob",
          "size": 17726
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/status_report.py",
          "type": "blob",
          "size": 20059
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/time_tracking.py",
          "type": "blob",
          "size": 9834
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/validation.py",
          "type": "blob",
          "size": 13609
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/verification.py",
          "type": "blob",
          "size": 6975
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_update/workflow.py",
          "type": "blob",
          "size": 19793
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate/__init__.py",
          "type": "blob",
          "size": 896
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate/cli.py",
          "type": "blob",
          "size": 30140
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate/diff.py",
          "type": "blob",
          "size": 19835
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate/fix.py",
          "type": "blob",
          "size": 32158
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate/formatting.py",
          "type": "blob",
          "size": 6356
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate/reporting.py",
          "type": "blob",
          "size": 6779
        },
        {
          "path": "src/claude_skills/claude_skills/sdd_validate/stats.py",
          "type": "blob",
          "size": 4823
        },
        {
          "path": "src/claude_skills/claude_skills/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/README.md",
          "type": "blob",
          "size": 10975
        },
        {
          "path": "src/claude_skills/claude_skills/tests/__init__.py",
          "type": "blob",
          "size": 39
        },
        {
          "path": "src/claude_skills/claude_skills/tests/conftest.py",
          "type": "blob",
          "size": 39942
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate/auto_fix_spec.json",
          "type": "blob",
          "size": 2007
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate/clean_spec.json",
          "type": "blob",
          "size": 1531
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate/deep_hierarchy_spec.json",
          "type": "blob",
          "size": 2552
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate/dependency_spec.json",
          "type": "blob",
          "size": 5023
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate/errors_spec.json",
          "type": "blob",
          "size": 1123
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate/warnings_spec-validation-report.md",
          "type": "blob",
          "size": 1087
        },
        {
          "path": "src/claude_skills/claude_skills/tests/fixtures/sdd_validate/warnings_spec.json",
          "type": "blob",
          "size": 2220
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/__init__.py",
          "type": "blob",
          "size": 102
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/cli_runner.py",
          "type": "blob",
          "size": 4846
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_ai_tools_cli.py",
          "type": "blob",
          "size": 15898
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_bulk_modify.py",
          "type": "blob",
          "size": 12688
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_context_cli.py",
          "type": "blob",
          "size": 1452
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_doc_cli.py",
          "type": "blob",
          "size": 11973
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_fidelity_incremental_workflow.py",
          "type": "blob",
          "size": 2170
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_fidelity_report_views.py",
          "type": "blob",
          "size": 3557
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_list_commands.py",
          "type": "blob",
          "size": 32331
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_modify_validation.py",
          "type": "blob",
          "size": 24908
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_provider_orchestration.py",
          "type": "blob",
          "size": 3141
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_run_tests_consultation_cli.py",
          "type": "blob",
          "size": 12682
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_run_tests_doc_integration.py",
          "type": "blob",
          "size": 8024
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_fidelity_review_cli.py",
          "type": "blob",
          "size": 1200
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_next_cli.py",
          "type": "blob",
          "size": 19621
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_next_doc_integration.py",
          "type": "blob",
          "size": 11303
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_plan_cli.py",
          "type": "blob",
          "size": 1084
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_plan_doc_integration.py",
          "type": "blob",
          "size": 12277
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_plan_review_cli.py",
          "type": "blob",
          "size": 3703
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_render",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_render/__init__.py",
          "type": "blob",
          "size": 48
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_render/test_render_pipeline.py",
          "type": "blob",
          "size": 16315
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_render_cli.py",
          "type": "blob",
          "size": 1116
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_spec_mod_cli.py",
          "type": "blob",
          "size": 2810
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_update_cli.py",
          "type": "blob",
          "size": 34219
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_validate_cli.py",
          "type": "blob",
          "size": 21723
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_sdd_validate_new_features.py",
          "type": "blob",
          "size": 6838
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_skills_dev_cli.py",
          "type": "blob",
          "size": 1926
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_spec_modification_cli.py",
          "type": "blob",
          "size": 31662
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_status_report.py",
          "type": "blob",
          "size": 3972
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_task_category_workflow.py",
          "type": "blob",
          "size": 23519
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_test_cli.py",
          "type": "blob",
          "size": 949
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_ui_config_integration.py",
          "type": "blob",
          "size": 4028
        },
        {
          "path": "src/claude_skills/claude_skills/tests/integration/test_unified_cli.py",
          "type": "blob",
          "size": 10578
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/__init__.py",
          "type": "blob",
          "size": 39
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/__init__.py",
          "type": "blob",
          "size": 152
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/conftest.py",
          "type": "blob",
          "size": 7079
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/fixtures/sample_codebase.json",
          "type": "blob",
          "size": 10052
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_ai_consultation.py",
          "type": "blob",
          "size": 11300
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_analysis_insights.py",
          "type": "blob",
          "size": 13330
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_cache_performance.py",
          "type": "blob",
          "size": 9572
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_cli.py",
          "type": "blob",
          "size": 5765
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_detectors.py",
          "type": "blob",
          "size": 10771
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_filters.py",
          "type": "blob",
          "size": 23979
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_generator_streaming.py",
          "type": "blob",
          "size": 19089
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_parsers_base.py",
          "type": "blob",
          "size": 5384
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_parsers_css.py",
          "type": "blob",
          "size": 5826
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_parsers_factory.py",
          "type": "blob",
          "size": 19099
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_parsers_go.py",
          "type": "blob",
          "size": 5235
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_parsers_html.py",
          "type": "blob",
          "size": 5435
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_parsers_javascript.py",
          "type": "blob",
          "size": 8825
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_parsers_python.py",
          "type": "blob",
          "size": 57884
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_persistent_cache.py",
          "type": "blob",
          "size": 15844
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/llm_doc_gen/analysis/test_two_tier.py",
          "type": "blob",
          "size": 18057
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_apply_modifications_cli.py",
          "type": "blob",
          "size": 9664
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_cli_registry.py",
          "type": "blob",
          "size": 2835
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_cli_skills_dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_cli_skills_dev/__init__.py",
          "type": "blob",
          "size": 41
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_cli_skills_dev/test_setup_permissions.py",
          "type": "blob",
          "size": 17228
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/__init__.py",
          "type": "blob",
          "size": 221
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_ai_config_models.py",
          "type": "blob",
          "size": 11467
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_ai_tools.py",
          "type": "blob",
          "size": 13625
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_cache.py",
          "type": "blob",
          "size": 25251
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_cache_cli.py",
          "type": "blob",
          "size": 6400
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_cache_manager.py",
          "type": "blob",
          "size": 10093
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_config.py",
          "type": "blob",
          "size": 6058
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_json_output.py",
          "type": "blob",
          "size": 8574
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_setup_templates.py",
          "type": "blob",
          "size": 5342
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_common/test_tui_progress.py",
          "type": "blob",
          "size": 46904
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_dev_tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_dev_tools/__init__.py",
          "type": "blob",
          "size": 40
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_dev_tools/test_sdd_start_helper.py",
          "type": "blob",
          "size": 10352
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_doc_query",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_doc_query/__init__.py",
          "type": "blob",
          "size": 40
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_doc_query/conftest.py",
          "type": "blob",
          "size": 3653
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_doc_query/test_lib.py",
          "type": "blob",
          "size": 29633
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_parse_review_cli.py",
          "type": "blob",
          "size": 10638
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers/test_base_provider.py",
          "type": "blob",
          "size": 7672
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers/test_claude_provider.py",
          "type": "blob",
          "size": 14846
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers/test_codex_provider.py",
          "type": "blob",
          "size": 7183
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers/test_cursor_agent_provider.py",
          "type": "blob",
          "size": 8867
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers/test_gemini_provider.py",
          "type": "blob",
          "size": 4867
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers/test_opencode_provider.py",
          "type": "blob",
          "size": 30573
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_providers/test_provider_detectors.py",
          "type": "blob",
          "size": 2082
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_revision.py",
          "type": "blob",
          "size": 13725
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_run_tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_run_tests/__init__.py",
          "type": "blob",
          "size": 66
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_run_tests/test_cli_model_overrides.py",
          "type": "blob",
          "size": 907
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_run_tests/test_consultation_models.py",
          "type": "blob",
          "size": 5903
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_run_tests/test_pytest_parser.py",
          "type": "blob",
          "size": 22152
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/__init__.py",
          "type": "blob",
          "size": 40
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_cli_utils.py",
          "type": "blob",
          "size": 8983
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_completion.py",
          "type": "blob",
          "size": 37778
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_doc_helper.py",
          "type": "blob",
          "size": 22170
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_doc_integration.py",
          "type": "blob",
          "size": 22438
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_git_metadata.py",
          "type": "blob",
          "size": 22563
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_integrations.py",
          "type": "blob",
          "size": 29952
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_paths.py",
          "type": "blob",
          "size": 8077
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_plain_ui.py",
          "type": "blob",
          "size": 12987
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_printer.py",
          "type": "blob",
          "size": 12529
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_progress.py",
          "type": "blob",
          "size": 13467
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_rich_ui.py",
          "type": "blob",
          "size": 11382
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_schema_loader.py",
          "type": "blob",
          "size": 2778
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_spec.py",
          "type": "blob",
          "size": 10587
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_ui_factory.py",
          "type": "blob",
          "size": 13352
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_common/test_ui_protocol.py",
          "type": "blob",
          "size": 5653
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_fidelity_review",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_fidelity_review/__init__.py",
          "type": "blob",
          "size": 80
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_fidelity_review/test_consultation.py",
          "type": "blob",
          "size": 19578
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_fidelity_review/test_fidelity_cli_incremental.py",
          "type": "blob",
          "size": 8506
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_fidelity_review/test_issue_aggregation_panel.py",
          "type": "blob",
          "size": 8737
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_fidelity_review/test_recommendation_consensus.py",
          "type": "blob",
          "size": 8735
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_fidelity_review/test_review.py",
          "type": "blob",
          "size": 11306
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next/__init__.py",
          "type": "blob",
          "size": 42
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next/conftest.py",
          "type": "blob",
          "size": 128
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next/test_discovery.py",
          "type": "blob",
          "size": 14651
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next/test_doc_integration.py",
          "type": "blob",
          "size": 6429
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next/test_project.py",
          "type": "blob",
          "size": 9683
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next/test_validation.py",
          "type": "blob",
          "size": 6065
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_next/test_workflow.py",
          "type": "blob",
          "size": 1411
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan/__init__.py",
          "type": "blob",
          "size": 42
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan/conftest.py",
          "type": "blob",
          "size": 128
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan/test_hierarchy_validation.py",
          "type": "blob",
          "size": 22221
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan/test_templates.py",
          "type": "blob",
          "size": 9263
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan_review",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan_review/__init__.py",
          "type": "blob",
          "size": 48
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan_review/test_cli_artifacts.py",
          "type": "blob",
          "size": 6418
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_plan_review/test_models.py",
          "type": "blob",
          "size": 2439
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/__init__.py",
          "type": "blob",
          "size": 40
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/conftest.py",
          "type": "blob",
          "size": 5019
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_ai_models.py",
          "type": "blob",
          "size": 3438
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_cli_models.py",
          "type": "blob",
          "size": 2837
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_complexity_scorer.py",
          "type": "blob",
          "size": 5346
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_dependency_graph.py",
          "type": "blob",
          "size": 6650
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_markdown_parser.py",
          "type": "blob",
          "size": 11707
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_priority_ranker.py",
          "type": "blob",
          "size": 15903
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_progressive_disclosure.py",
          "type": "blob",
          "size": 9271
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_spec_analyzer.py",
          "type": "blob",
          "size": 5909
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_render/test_task_grouper.py",
          "type": "blob",
          "size": 15550
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_spec_mod",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_spec_mod/__init__.py",
          "type": "blob",
          "size": 59
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_spec_mod/test_add_node.py",
          "type": "blob",
          "size": 11828
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_spec_mod/test_move_node.py",
          "type": "blob",
          "size": 11428
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_spec_mod/test_remove_node.py",
          "type": "blob",
          "size": 10928
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_spec_mod/test_transaction_support.py",
          "type": "blob",
          "size": 12099
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_spec_mod/test_update_node_field.py",
          "type": "blob",
          "size": 9399
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/__init__.py",
          "type": "blob",
          "size": 33
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/conftest.py",
          "type": "blob",
          "size": 130
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_journal.py",
          "type": "blob",
          "size": 14006
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_lifecycle.py",
          "type": "blob",
          "size": 16976
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_query_operations.py",
          "type": "blob",
          "size": 31342
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_status.py",
          "type": "blob",
          "size": 10284
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_status_report_layout.py",
          "type": "blob",
          "size": 7780
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_time_tracking.py",
          "type": "blob",
          "size": 21008
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_verification.py",
          "type": "blob",
          "size": 11056
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_update/test_workflow.py",
          "type": "blob",
          "size": 21497
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/__init__.py",
          "type": "blob",
          "size": 46
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/fixtures/spec_with_fixable_issues.json",
          "type": "blob",
          "size": 892
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/fixtures/valid_spec.json",
          "type": "blob",
          "size": 1203
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/test_fix.py",
          "type": "blob",
          "size": 39458
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/test_formatting.py",
          "type": "blob",
          "size": 4483
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/test_reporting.py",
          "type": "blob",
          "size": 12060
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_sdd_validate/test_stats.py",
          "type": "blob",
          "size": 6509
        },
        {
          "path": "src/claude_skills/claude_skills/tests/unit/test_suggest_modifications.py",
          "type": "blob",
          "size": 10722
        },
        {
          "path": "src/claude_skills/pyproject.toml",
          "type": "blob",
          "size": 1802
        },
        {
          "path": "src/claude_skills/pytest.ini",
          "type": "blob",
          "size": 477
        },
        {
          "path": "src/claude_skills/requirements-test.txt",
          "type": "blob",
          "size": 567
        },
        {
          "path": "src/claude_skills/schemas",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/claude_skills/schemas/documentation-schema.json",
          "type": "blob",
          "size": 9422
        },
        {
          "path": "src/claude_skills/schemas/sdd-spec-schema.json",
          "type": "blob",
          "size": 11317
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/doc_query",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/doc_query/test_codebase_query.py",
          "type": "blob",
          "size": 18524
        },
        {
          "path": "tests/doc_query/test_scope_command.py",
          "type": "blob",
          "size": 23142
        },
        {
          "path": "tests/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/fixtures/context_tracker",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/fixtures/context_tracker/transcript.jsonl",
          "type": "blob",
          "size": 187
        },
        {
          "path": "tests/integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/integration/test_fallback_integration.py",
          "type": "blob",
          "size": 1618
        },
        {
          "path": "tests/integration/test_prepare_task_cli.py",
          "type": "blob",
          "size": 11702
        },
        {
          "path": "tests/llm_doc_gen",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/llm_doc_gen/test_ab_testing.py",
          "type": "blob",
          "size": 20567
        },
        {
          "path": "tests/llm_doc_gen/test_component_generator.py",
          "type": "blob",
          "size": 18661
        },
        {
          "path": "tests/llm_doc_gen/test_freshness.py",
          "type": "blob",
          "size": 16760
        },
        {
          "path": "tests/llm_doc_gen/test_overview_generator.py",
          "type": "blob",
          "size": 18684
        },
        {
          "path": "tests/llm_doc_gen/test_performance_benchmark.py",
          "type": "blob",
          "size": 17663
        },
        {
          "path": "tests/sdd_next",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/sdd_next/test_context_utils.py",
          "type": "blob",
          "size": 13876
        },
        {
          "path": "tests/sdd_next/test_prepare_task_context.py",
          "type": "blob",
          "size": 13992
        },
        {
          "path": "tests/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/skills/llm_doc_gen",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/skills/llm_doc_gen/__init__.py",
          "type": "blob",
          "size": 35
        },
        {
          "path": "tests/skills/llm_doc_gen/test_ai_consultation.py",
          "type": "blob",
          "size": 7407
        },
        {
          "path": "tests/skills/llm_doc_gen/test_architecture_generator.py",
          "type": "blob",
          "size": 20305
        },
        {
          "path": "tests/skills/llm_doc_gen/test_component_generator.py",
          "type": "blob",
          "size": 11585
        },
        {
          "path": "tests/skills/llm_doc_gen/test_e2e_generators.py",
          "type": "blob",
          "size": 19781
        },
        {
          "path": "tests/skills/llm_doc_gen/test_e2e_orchestration.py",
          "type": "blob",
          "size": 14604
        },
        {
          "path": "tests/skills/llm_doc_gen/test_overview_generator.py",
          "type": "blob",
          "size": 7565
        },
        {
          "path": "tests/skills/llm_doc_gen/test_workflow_engine.py",
          "type": "blob",
          "size": 10962
        },
        {
          "path": "tests/test_cli_verbosity.py",
          "type": "blob",
          "size": 20027
        },
        {
          "path": "tests/test_doc_query_advanced_verbosity.py",
          "type": "blob",
          "size": 7252
        },
        {
          "path": "tests/test_doc_query_json_output.py",
          "type": "blob",
          "size": 1245
        },
        {
          "path": "tests/test_doc_query_verbosity.py",
          "type": "blob",
          "size": 12790
        },
        {
          "path": "tests/test_indexed_resolution.py",
          "type": "blob",
          "size": 11904
        },
        {
          "path": "tests/test_output_reduction.py",
          "type": "blob",
          "size": 18484
        },
        {
          "path": "tests/test_parallel_parsing.py",
          "type": "blob",
          "size": 17001
        },
        {
          "path": "tests/test_persistent_cache.py",
          "type": "blob",
          "size": 21113
        },
        {
          "path": "tests/test_sdd_fidelity_review_verbosity.py",
          "type": "blob",
          "size": 1780
        },
        {
          "path": "tests/test_sdd_next_verbosity.py",
          "type": "blob",
          "size": 6303
        },
        {
          "path": "tests/test_sdd_plan_review_verbosity.py",
          "type": "blob",
          "size": 2011
        },
        {
          "path": "tests/test_sdd_plan_verbosity.py",
          "type": "blob",
          "size": 3664
        },
        {
          "path": "tests/test_sdd_pr_verbosity.py",
          "type": "blob",
          "size": 2717
        },
        {
          "path": "tests/test_sdd_render_verbosity.py",
          "type": "blob",
          "size": 1555
        },
        {
          "path": "tests/test_sdd_spec_mod_verbosity.py",
          "type": "blob",
          "size": 3836
        },
        {
          "path": "tests/test_sdd_update_tasks_verbosity.py",
          "type": "blob",
          "size": 11340
        },
        {
          "path": "tests/test_sdd_update_verbosity.py",
          "type": "blob",
          "size": 5736
        },
        {
          "path": "tests/test_sdd_validate_verbosity.py",
          "type": "blob",
          "size": 2308
        },
        {
          "path": "tests/test_start_helper_contracts.py",
          "type": "blob",
          "size": 3345
        },
        {
          "path": "tests/test_support_verbosity.py",
          "type": "blob",
          "size": 6435
        },
        {
          "path": "tests/test_verbosity_output_reduction.py",
          "type": "blob",
          "size": 15332
        },
        {
          "path": "tests/test_verbosity_regression.py",
          "type": "blob",
          "size": 13051
        },
        {
          "path": "tests/unit",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/unit/test_ai_config_fallback.py",
          "type": "blob",
          "size": 1697
        },
        {
          "path": "tests/unit/test_consultation_limits.py",
          "type": "blob",
          "size": 3057
        },
        {
          "path": "tests/unit/test_execute_tool_fallback.py",
          "type": "blob",
          "size": 4726
        }
      ],
      "marketplace": {
        "name": "claude-sdd-toolkit",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "tylerburleigh",
          "email": "tylerburleigh@gmail.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "sdd-toolkit",
            "description": null,
            "source": {
              "source": "github",
              "repo": "tylerburleigh/claude-sdd-toolkit"
            },
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add tylerburleigh/claude-sdd-toolkit",
              "/plugin install sdd-toolkit@claude-sdd-toolkit"
            ],
            "signals": {
              "stars": 5,
              "forks": 0,
              "pushed_at": "2025-12-02T21:43:10Z",
              "created_at": "2025-10-24T13:23:12Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "doc-query",
                "description": "Targeted query capabilities for machine-readable codebase documentation with cross-reference tracking, call graph analysis, and workflow automation. Enables fast lookups of classes, functions, dependencies, and function relationships without parsing source code.",
                "path": "skills/doc-query/SKILL.md",
                "frontmatter": {
                  "name": "doc-query",
                  "description": "Targeted query capabilities for machine-readable codebase documentation with cross-reference tracking, call graph analysis, and workflow automation. Enables fast lookups of classes, functions, dependencies, and function relationships without parsing source code."
                },
                "content": "# doc-query: Codebase Documentation Query System\n\n## Description\n\nThe `Skill(sdd-toolkit:doc-query)` skill provides targeted query capabilities for machine-readable codebase documentation generated by the `sdd doc generate` command. It enables fast, structured lookups of classes, functions, modules, dependencies, and complexity metrics without parsing source code directly, plus advanced cross-reference tracking and call graph analysis.\n\n## Key Features\n\n- **Entity Lookup**: Find classes, functions, and modules by exact name or regex pattern\n- **Cross-Reference Tracking**: Find callers/callees, build call graphs, track class instantiations and imports\n- **Call Graph Analysis**: Visualize function call relationships with configurable depth and direction\n- **Module Summaries**: `describe-module` surfaces docstrings, hot spots, dependencies, and key entities in one call\n- **Structured Output**: Commands return structured output ready for scripts or downstream tools\n- **Complexity Analysis**: Identify refactoring candidates with configurable complexity thresholds\n- **Dependency Mapping**: Understand module relationships and perform impact analysis\n- **Context Gathering**: Smart context collection for specific tasks or feature areas\n- **Workflow Automation**: High-level commands that combine multiple queries into single operations\n\n## Quick Start\n\nNew to doc-query? Start with the **scope command** for comprehensive module analysis:\n\n```bash\n# Get focused context for planning a change\nsdd doc scope <module_path> --plan\n\n# Get focused context for implementing a change\nsdd doc scope <module_path> --implement --function <function_name>\n```\n\nThe `scope` command provides tailored information for different workflows:\n- **`--plan`**: Module summary, complexity analysis, and architectural overview\n- **`--implement`**: Function callers, call graphs, and class usage patterns\n\n**For deeper analysis**, use these automated workflow commands:\n\n```bash\n# Understand how a feature works end-to-end\nsdd doc trace-entry <function_name>\n\n# See what breaks if you change a function\nsdd doc impact <function_name>\n\n# Find high-priority refactoring candidates\nsdd doc refactor-candidates\n\n# Track how data flows through your system\nsdd doc trace-data <ClassName>\n```\n\nThese workflow commands combine 6-8 manual steps into single operations with intelligent analysis and risk assessment.\n\n**For specific lookups**, use basic commands:\n- `sdd doc find-function <name>` - Locate a function\n- `sdd doc callers <function>` - See who calls this function\n- `sdd doc call-graph <function>` - Visualize call relationships\n- `sdd doc dependencies <module> --reverse` - Impact analysis\n\n**See below** for complete command reference and advanced usage patterns.\n\n## When to Use This Skill\n\n###  Use `Skill(sdd-toolkit:doc-query)` when:\n\n1. **Starting a new task** - Quickly find relevant classes, functions, and modules\n2. **Bug fixing** - Locate specific functions and understand their dependencies\n3. **Feature implementation** - Find similar existing implementations to follow patterns\n4. **Refactoring** - Identify high-complexity functions that need attention\n5. **Impact analysis** - Understand what modules will be affected by changes\n6. **Test planning** - Find test files and estimate coverage\n7. **Code exploration** - Navigate and understand codebase structure with module-level summaries\n\n###  Don't use `Skill(sdd-toolkit:doc-query)` when:\n\n1. Documentation hasn't been generated yet (run `sdd doc generate` first)\n2. You need to read actual source code (use `Explore` or `Read` tool instead)\n3. You need to analyze runtime behavior (use debugging tools)\n\n**Note**: Documentation staleness is automatically detected and docs are auto-regenerated by default if out of date. Use `--skip-refresh` for faster queries without regeneration or `--no-staleness-check` to skip staleness detection entirely.\n\n---\n\n## Exploration Workflows Quick Reference\n\nUse these workflows to systematically explore any codebase. All workflows are **codebase-agnostic** and work across languages, frameworks, and architectures.\n\n| Workflow | Automated Command | Manual Alternative | When to Use It |\n|----------|-------------------|-------------------|----------------|\n| **TRACE-ENTRY-POINT** | `trace-entry <function>` | 6-step pattern | \"How does [action] work?\" |\n| **TRACE-DATA-OBJECT** | `trace-data <class>` | 6-step pattern | \"What happens to [entity]?\" |\n| **IMPACT-ANALYSIS** | `impact <entity>` | 7-step pattern | \"What breaks if I modify X?\" |\n| **REFACTOR-PRIORITY** | `refactor-candidates` | Manual complexity analysis | \"What should I refactor first?\" |\n| **EXPLORE-FEATURE-AREA** | Use `context` + manual queries | 5-step pattern | \"Tell me about the [feature] system\" |\n| **FIND-PATTERN** | Manual queries only | 6-step pattern | \"How do we do [validation/auth/caching]?\" |\n| **ONBOARD-TO-CODEBASE** | Manual queries only | 6-step pattern | \"I'm new here, where do I start?\" |\n| **TRACE-ERROR-FLOW** | Manual queries only | 5-step pattern | \"How are errors handled?\" |\n| **TRACE-CONFIGURATION** | Manual queries only | 5-step pattern | \"Where is [config/flag] used?\" |\n| **TRACE-TEST-COVERAGE** | Manual queries only | 5-step pattern | \"What tests cover [feature]?\" |\n\n**Note:** Workflows with automated commands (top 4) reduce 6-7 manual steps to 1 command. Others require manual query composition using basic commands.\n\n### Decision Tree: Which Workflow Should I Use?\n\n```\nSTART: What do you want to know?\n\n \"How does [action/request/event] work?\"\n   sdd doc trace-entry <function>  [AUTOMATED]\n\n \"What happens to [data/entity]?\"\n   sdd doc trace-data <class>  [AUTOMATED]\n\n \"What breaks if I change [X]?\"\n   sdd doc impact <entity>  [AUTOMATED]\n\n \"What should I refactor?\"\n   sdd doc refactor-candidates  [AUTOMATED]\n\n \"Tell me about [feature/module/system]\"\n   sdd doc context + manual queries  [MANUAL]\n\n \"How do we do [pattern] here?\" (e.g., validation, auth, caching)\n   Manual query pattern (see below)  [MANUAL]\n\n \"I'm new here, where do I start?\"\n   Manual onboarding pattern (see below)  [MANUAL]\n\n \"How are errors handled?\"\n   Manual error tracing pattern (see below)  [MANUAL]\n\n \"Where is [config/flag] used?\"\n   Manual config tracing pattern (see below)  [MANUAL]\n\n \"What tests cover [feature]?\"\n    Manual test coverage pattern (see below)  [MANUAL]\n```\n\n### Workflow Tiers\n\n**Tier 1: Automated Workflows** (One-command solutions for common tasks)\n- `trace-entry` - Understand execution flow end-to-end\n- `trace-data` - Follow data lifecycle through system\n- `impact` - Assess blast radius of changes\n- `refactor-candidates` - Identify technical debt priorities\n\n**Tier 2: Manual Query Patterns** (Advanced usage for specialized needs)\n- EXPLORE-FEATURE-AREA - Comprehensive feature discovery\n- FIND-PATTERN - Implementation pattern analysis\n- ONBOARD-TO-CODEBASE - Systematic codebase orientation\n- TRACE-ERROR-FLOW - Error handling investigation\n- TRACE-CONFIGURATION - Configuration tracking\n- TRACE-TEST-COVERAGE - Test strategy understanding\n\n---\n\n## Tool Verification\n\n**Before using this skill**, verify the required tools are available:\n\n```bash\n# Verify sdd doc CLI is installed and accessible\nsdd doc --help\n```\n\n**Expected output**: Help text showing available commands (stats, search, find-class, describe-module, etc.)\n\n**IMPORTANT - CLI Usage Only**:\n-  **DO**: Use `sdd doc` CLI wrapper commands (e.g., `sdd doc stats`, `sdd doc search`, `sdd doc find-class`)\n-  **DO NOT**: Execute Python scripts directly (e.g., `python doc_query.py`, `bash python cli.py`)\n\nThe CLI provides proper error handling, validation, argument parsing, and interface consistency. Direct script execution bypasses these safeguards and may fail.\n\nIf the verification command fails, ensure the SDD toolkit is properly installed and accessible in your environment.\n\n## Requirements\n\n- Documentation must be generated by running `sdd doc generate`\n- Documentation files expected in `docs/` directory:\n  - `codebase.json` (required)\n  - `index.md` (optional, navigation hub)\n  - `project-overview.md` (optional, executive summary)\n  - `architecture.md` (optional, system design)\n  - `component-inventory.md` (optional, component catalog)\n\n**Note**: You should NOT read the `codebase.json` document manually.\n\n## Auto-Detection\n\n`sdd doc` CLI automatically searches for documentation in multiple locations (in order of priority):\n\n1. **Current directory**: `./docs/`\n2. **Parent directory**: `../docs/`\n3. **Alternative naming**: `./documentation/`\n4. **Claude home**: `~/.claude/docs/`\n\n**No --docs-path needed** for most cases! The tool will find your documentation automatically.\n\n**Explicit path override**: Use `--docs-path PATH` to specify a custom location:\n```bash\nsdd doc stats --docs-path /path/to/project/docs\n```\n\n**Check detection**: The `stats` command shows which path was detected:\n```bash\nsdd doc stats\n# Output includes: \"Found documentation at: /path/to/docs\"\n```\n\n---\n\n## Documentation Staleness Detection\n\n**NEW**: `doc-query` now automatically detects and regenerates stale documentation by default!\n\n### How It Works\n\nEvery query command automatically checks if source files have been modified since documentation was generated:\n\n1. **Compares timestamps**: Documentation generation time vs. latest source file modification\n2. **Auto-regenerates if stale**: Automatically regenerates documentation before running the query\n3. **Shows progress**: Displays regeneration status and completion\n4. **Performance**: Staleness check adds ~10-50ms; regeneration takes 30-60s when needed\n\n### Default Behavior\n\n```bash\n$ sdd doc find-function calculate_score\n\n Documentation is stale, regenerating...\n Documentation regenerated successfully\n\nFound 1 result(s):\n...\n```\n\n### Flags to Control Behavior\n\n#### `--skip-refresh`: Skip Auto-Regeneration\n\nSkips auto-regeneration even if docs are stale, showing only a warning:\n\n```bash\n$ sdd doc find-function calculate_score --skip-refresh\n\n  Documentation is stale (generated 3 days ago, source modified 2 hours after generation)\n    To auto-refresh: remove --skip-refresh flag or run 'sdd doc generate'\n    To suppress this warning: use --no-staleness-check\n\nFound 1 result(s):\n...\n```\n\n**When to use:**\n- Speed is critical\n- You're running many queries in succession\n- You know docs are recent enough for your needs\n- Exploratory queries where perfect accuracy isn't required\n\n#### `--no-staleness-check`: Skip Check Entirely\n\nDisables staleness detection completely for maximum speed:\n\n```bash\n$ sdd doc find-function calculate_score --no-staleness-check\n\nFound 1 result(s):\n...\n```\n\n**When to use:**\n- You know docs are fresh\n- You're working in CI/CD where docs were just generated\n- Performance-critical automated workflows\n- When staleness doesn't matter for your use case\n\n### Examples\n\n**Workflow 1: Default behavior (recommended)**\n```bash\n# Automatically regenerates if needed - guaranteed fresh results\nsdd doc impact UserService\n```\n\n**Workflow 2: Fast exploration**\n```bash\n# Skip regeneration for quick lookups\nsdd doc find-class User --skip-refresh\nsdd doc describe-module auth.py --skip-refresh\n```\n\n**Workflow 3: Maximum performance**\n```bash\n# Skip staleness check entirely\nsdd doc search \"validation\" --no-staleness-check\n```\n\n---\n\n## Automated Workflow Commands\n\nThese commands automate common workflows by combining multiple queries into single, purpose-built commands. **Use these first** for the fastest results.\n\n### 1. Trace Entry Point\n\nTrace execution flow from an entry function, showing the complete call chain with architectural layers and complexity analysis.\n\n```bash\nsdd doc trace-entry <function> [--max-depth N] [--docs-path PATH]\n```\n\n**Options:**\n- `--max-depth N` - Maximum call chain depth (default: 5)\n\n**Examples:**\n```bash\n# Trace execution flow from main\nsdd doc trace-entry main\n\n# Trace with custom depth\nsdd doc trace-entry process_request --max-depth 3\n```\n\n**Output includes:**\n- Complete call chain tree visualization\n- Architectural layer classification (Presentation, Business Logic, Data, etc.)\n- Complexity scores for each function\n- Hot spot identification (high complexity or high fan-out)\n- Summary statistics\n\n**When to use:**\n- Understanding how a feature works end-to-end\n- Finding performance bottlenecks in execution paths\n- Identifying complex call chains that need refactoring\n- Documenting system flows\n\n### 2. Trace Data Lifecycle\n\nTrace how a data object (class) flows through the codebase, showing CRUD operations and usage patterns.\n\n```bash\nsdd doc trace-data <classname> [--include-properties] [--docs-path PATH]\n```\n\n**Options:**\n- `--include-properties` - Include detailed property access analysis\n\n**Examples:**\n```bash\n# Trace User class lifecycle\nsdd doc trace-data User\n\n# Include property access patterns\nsdd doc trace-data User --include-properties\n```\n\n**Output includes:**\n- CREATE operations (where instances are created)\n- READ operations (functions that access the data)\n- UPDATE operations (functions that modify the data)\n- DELETE operations (where data is destroyed)\n- Usage map organized by architectural layer\n- Property access analysis (when --include-properties is used)\n\n**When to use:**\n- Understanding data flow through the system\n- Finding all places where data is modified\n- Identifying mutation hot spots\n- Planning data model refactoring\n\n### 3. Impact Analysis\n\nAnalyze the impact of changing a function or class, calculating the blast radius with risk assessment.\n\n```bash\nsdd doc impact <entity> [--depth N] [--docs-path PATH]\n```\n\n**Options:**\n- `--depth N` - Maximum depth for indirect dependency traversal (default: 2)\n\n**Examples:**\n```bash\n# Analyze impact of changing a function\nsdd doc impact calculate_score\n\n# Deep analysis with 3 levels\nsdd doc impact UserService --depth 3\n```\n\n**Output includes:**\n- Direct dependents (functions/classes that directly use this entity)\n- Indirect dependents (2nd+ degree dependencies)\n- Test coverage estimation\n- Risk score and level (high/medium/low)\n- Actionable recommendations based on risk level\n- Layer-by-layer impact breakdown\n\n**When to use:**\n- Pre-refactoring risk assessment\n- Understanding blast radius before changes\n- Planning safe refactoring strategies\n- Identifying coordination needs for changes\n\n### 4. Refactor Candidates\n\nFind high-priority refactoring candidates by combining complexity metrics with usage data.\n\n```bash\nsdd doc refactor-candidates [--min-complexity N] [--limit N] [--docs-path PATH]\n```\n\n**Options:**\n- `--min-complexity N` - Minimum complexity threshold (default: 10)\n- `--limit N` - Maximum number of candidates to return (default: 20)\n\n**Examples:**\n```bash\n# Find refactoring candidates\nsdd doc refactor-candidates\n\n# Focus on high-complexity functions\nsdd doc refactor-candidates --min-complexity 20 --limit 10\n```\n\n**Output includes:**\n- Prioritized list sorted by priority score (complexity  dependents)\n- Risk level categorization (high/medium/low)\n- Quick wins (high complexity, low dependents - safe to refactor)\n- Major refactors (high complexity, high dependents - need planning)\n- Actionable recommendations for each candidate\n- Summary statistics and risk distribution\n\n**When to use:**\n- Planning technical debt reduction\n- Prioritizing refactoring work\n- Identifying quick wins vs major efforts\n- Code quality improvement initiatives\n\n---\n\n## Basic Query Commands\n\nThese commands provide targeted lookups for specific entities and relationships. Combine them to build custom workflows when automated commands don't fit your needs.\n\n### 1. Find Class\n\nFind a specific class by exact name or regex pattern.\n\n```bash\nsdd doc find-class <name> [--pattern] [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Find exact class\nsdd doc find-class WizardSession\n\n# Find classes matching pattern\nsdd doc find-class \".*Session.*\" --pattern\n```\n\n**When to use:**\n- Starting work on a feature involving a specific class\n- Understanding inheritance hierarchies\n- Finding class implementation location\n\n### 2. Find Function\n\nFind a specific function by exact name or regex pattern.\n\n```bash\nsdd doc find-function <name> [--pattern] [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Find exact function\nsdd doc find-function calculate_score\n\n# Find functions matching pattern\nsdd doc find-function \".*score.*\" --pattern\n```\n\n**When to use:**\n- Bug fixing in a specific function\n- Understanding function complexity and parameters\n- Finding function implementation location\n\n### 3. Describe Module\n\nProduce a rich summary for a specific module, including docstring, key classes/functions, dependencies, and complexity signals.\n\n```bash\nsdd doc describe-module <module> [--top-functions N] [--include-docstrings] [--skip-dependencies] [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Quick overview with defaults\nsdd doc describe-module app/services/scoring.py\n\n# Focus on the top 3 complex functions and include docstring snippets\nsdd doc describe-module app/services/scoring.py --top-functions 3 --include-docstrings\n\n# Export summary as JSON for downstream tooling\nsdd doc describe-module scoring.py --json\n```\n\n**When to use:**\n- Evaluating an unfamiliar file before editing\n- Sharing a concise module summary with teammates\n- Feeding structured module data into other tooling via `--json`\n- Spotting complexity hot-spots without scanning entire documentation\n\n### 4. Find Module\n\nFind a module by name or pattern.\n\n```bash\nsdd doc find-module <name> [--pattern] [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Find exact module\nsdd doc find-module app/services/scoring.py\n\n# Find modules matching pattern\nsdd doc find-module \".*scoring.*\" --pattern\n```\n\n**When to use:**\n- Understanding module structure\n- Finding all entities in a module\n- Checking module dependencies\n- Jumping into module descriptions via `describe-module`\n\n### 5. Complexity Analysis\n\nList functions above a complexity threshold.\n\n```bash\nsdd doc complexity [--threshold N] [--module M] [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Find all functions with complexity >= 5\nsdd doc complexity\n\n# Find high-complexity functions (>= 8)\nsdd doc complexity --threshold 8\n\n# Find complex functions in a specific module\nsdd doc complexity --module scoring.py\n```\n\n**When to use:**\n- Identifying refactoring candidates\n- Code quality assessment\n- Planning technical debt reduction\n\n### 5. Dependencies\n\nShow module dependencies (direct or reverse).\n\n```bash\nsdd doc dependencies <module> [--reverse] [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Show what a module imports\nsdd doc dependencies app/services/scoring.py\n\n# Show what imports this module (reverse dependencies)\nsdd doc dependencies app/models/session.py --reverse\n```\n\n**When to use:**\n- Impact analysis before changes\n- Understanding module relationships\n- Identifying circular dependencies\n- Planning refactoring\n\n#### Understanding Reverse Dependencies\n\n**How it works:**\n- Forward dependencies: Shows what a module **imports** (from its import statements)\n- Reverse dependencies: Shows what modules **import this module** (who depends on it)\n\n**Important: Import Names vs File Paths**\n\nThe dependency system tracks **import strings as they appear in code**, not normalized file paths.\n\n** Forward dependencies** work with file paths:\n```bash\n# This works - shows what this file imports\nsdd doc dependencies src/myapp/services/auth.py\n```\n\n** Reverse dependencies** require import names:\n```bash\n#  CORRECT - Use the import name\nsdd doc dependencies \"myapp.services.auth\" --reverse\nsdd doc dependencies \"auth\" --reverse  # May work for short names\n\n#  INCORRECT - File path won't match import strings\nsdd doc dependencies src/myapp/services/auth.py --reverse\n# Returns: No results (even if modules import this)\n```\n\n**Why the difference?**\n\nWhen Python code imports a module:\n```python\nfrom myapp.services.auth import login  # Import string: \"myapp.services.auth\"\nimport myapp.services.auth             # Import string: \"myapp.services.auth\"\n```\n\nThe dependency tracker stores `\"myapp.services.auth\"` (the import string), not `\"src/myapp/services/auth.py\"` (the file path).\n\n**Finding the correct import name:**\n\nIf you're not sure of the import name, use forward dependencies first:\n```bash\n# 1. Check what imports this module (look at the output)\nsdd doc dependencies src/myapp/services/auth.py\n\n# 2. Look for project-internal imports (not stdlib)\n# Output might show: \"myapp.models\", \"myapp.config\", etc.\n\n# 3. Use similar patterns for reverse lookups\nsdd doc dependencies \"myapp.services.auth\" --reverse\n```\n\n**Practical workflow for impact analysis:**\n\n```bash\n# Step 1: Find the module you want to analyze\nsdd doc find-module \"auth\" --pattern\n\n# Step 2: Check forward deps (what it uses)\nsdd doc dependencies src/myapp/services/auth.py\n\n# Step 3: Infer import name from file structure\n# File: src/myapp/services/auth.py\n# Likely import: myapp.services.auth\n\n# Step 4: Check reverse deps (who uses it)\nsdd doc dependencies \"myapp.services.auth\" --reverse\n\n# Step 5: Analyze the blast radius\n# Combine results to understand full impact\n```\n\n**Edge cases:**\n\n- **Standard library imports** (e.g., `argparse`, `json`): These will show reverse dependencies for all modules that import them\n- **Re-exported modules** (e.g., `__init__.py`): These may not show direct imports if other modules import from the parent package\n- **Relative imports** (e.g., `from . import foo`): Stored as relative strings, may need exact match\n\n### 6. Callers\n\nShow functions that call the specified function using cross-reference data from AST analysis.\n\n```bash\nsdd doc callers <function> [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Find all functions that call calculate_score\nsdd doc callers calculate_score\n\n# Find callers with specific path\nsdd doc callers process_data --docs-path ./docs\n```\n\n**Output includes:**\n- Function name and location of each caller\n- Line number where the call occurs\n- Call type (function_call, method_call, etc.)\n- File paths for easy navigation\n\n**When to use:**\n- Understanding function usage patterns\n- Impact analysis before refactoring\n- Finding entry points to a subsystem\n- Identifying who depends on this function\n\n### 7. Callees\n\nShow functions called by the specified function using cross-reference data from AST analysis.\n\n```bash\nsdd doc callees <function> [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Find all functions called by main\nsdd doc callees main\n\n# Find callees with specific path\nsdd doc callees process_request --docs-path ./docs\n```\n\n**Output includes:**\n- Function name and location of each callee\n- Line number where the call occurs\n- Call type (function_call, method_call, class_instantiation)\n- File paths for easy navigation\n\n**When to use:**\n- Understanding function implementation scope\n- Tracing execution paths from a function\n- Identifying dependencies of a function\n- Planning refactoring boundaries\n\n### 8. Call Graph\n\nBuild and visualize function call graphs with configurable depth and direction.\n\n```bash\nsdd doc call-graph <function> [--depth N] [--direction up|down|both] [--docs-path PATH]\n```\n\n**Options:**\n- `--depth N` - Maximum graph depth (default: 3)\n- `--direction` - Graph direction:\n  - `down`: Show callees (functions this calls) - default\n  - `up`: Show callers (functions that call this)\n  - `both`: Show both callers and callees\n\n**Examples:**\n```bash\n# Show call graph for a function (what it calls)\nsdd doc call-graph process_request\n\n# Show upstream callers (who calls this)\nsdd doc call-graph calculate_score --direction up --depth 2\n\n# Show bidirectional graph\nsdd doc call-graph main --direction both --depth 3\n```\n\n**Output includes:**\n- Tree or graph visualization of call relationships\n- Depth indicators showing call chain levels\n- Cycle detection warnings\n- Node count and relationship statistics\n\n**When to use:**\n- Visualizing complex call relationships\n- Understanding execution flow across multiple layers\n- Creating architecture documentation\n- Planning refactoring boundaries\n- Identifying circular dependencies\n- Generating call graphs for documentation\n\n### 9. Search\n\nSearch across all entities (classes, functions, modules).\n\n```bash\nsdd doc search <query> [--limit N] [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Search for anything related to authentication\nsdd doc search \"auth\"\n\n# Search for scoring-related entities\nsdd doc search \"score.*\"\n\n# Limit results to first 10 matches\nsdd doc search \"CLI\" --limit 10\n```\n\n**When to use:**\n- Exploratory searches\n- Finding all related entities\n- Broad context gathering\n- Use `--limit` to control output volume for broad searches\n\n### 10. Context\n\nGather comprehensive context for a feature area.\n\n```bash\nsdd doc context <area> [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# Get all entities related to wizard functionality\nsdd doc context \"wizard\"\n\n# Get all scoring-related context\nsdd doc context \"scoring\"\n```\n\n**When to use:**\n- Starting work on a feature area\n- Understanding feature scope\n- Gathering context for SDD tasks\n\n### 11. Statistics\n\nShow documentation statistics and metrics.\n\n```bash\nsdd doc stats [--docs-path PATH]\n```\n\n**When to use:**\n- Quick codebase overview\n- Assessing code quality\n- Checking documentation freshness\n\n### 12. List Entities\n\nList all classes, functions, or modules.\n\n```bash\nsdd doc list-classes [--module M] [--docs-path PATH]\nsdd doc list-functions [--module M] [--docs-path PATH]\nsdd doc list-modules [--docs-path PATH]\n```\n\n**Examples:**\n```bash\n# List all classes\nsdd doc list-classes\n\n# List functions in a specific module\nsdd doc list-functions --module scoring.py\n\n# List all modules\nsdd doc list-modules\n```\n\n**When to use:**\n- Getting an overview of entities\n- Browsing codebase structure\n- Verifying documentation completeness\n\n---\n\n## Advanced: Manual Workflow Patterns\n\nFor specialized needs or custom analysis, you can manually combine basic query commands. The automated workflows (above) handle 90% of use cases, but these patterns provide fine-grained control when needed.\n\n### When to Use Manual Patterns\n\nThese workflows provide systematic approaches to understanding any codebase. All patterns use generic placeholders like `[feature]`, `[entity]`, `[pattern]` - substitute with your domain-specific terms.\n\n---\n\n### Workflow 1: TRACE-ENTRY-POINT\n\n**Goal:** Understand the end-to-end flow of a user action, API request, or system event.\n\n**Use cases:** \"How does the scoring process work?\", \"What happens when a user clicks 'Submit'?\", \"How are webhook events processed?\"\n\n#### Automated Approach (Recommended)\n\n```bash\nsdd doc trace-entry <function_name> [--max-depth N]\n```\n\n**Examples:**\n```bash\n# Trace execution from FastAPI endpoint\nsdd doc trace-entry process_scoring_request\n\n# Trace with custom depth\nsdd doc trace-entry handle_submit --max-depth 3\n```\n\n**Output:** Complete call chain, architectural layers, complexity analysis, hot spots\n\n#### Manual Approach (For Custom Analysis)\n\nIf you need fine-grained control or the function name is unknown:\n\n```bash\n# 1. Find entry point\nsdd doc search \"[endpoint|route|handler].*[feature]\"\n\n# 2. Get callers/callees\nsdd doc callees <function>  # or call-graph for visualization\n\n# 3. Describe key modules\nsdd doc describe-module <module>\n```\n\n### Workflow 2: TRACE-DATA-OBJECT\n\n**Goal:** Follow a specific data structure or entity through its lifecycle.\n\n**Use cases:** \"What happens to a User object?\", \"How is OrderData transformed?\", \"Where is ConfigSettings used?\"\n\n#### Automated Approach (Recommended)\n\n```bash\nsdd doc trace-data <ClassName> [--include-properties]\n```\n\n**Example:** `sdd doc trace-data User`\n\n**Output:** CRUD operations, usage map by layer, property access patterns\n\n#### Manual Approach\n\n```bash\n# 1. Find class definition\nsdd doc find-class <ClassName>\n\n# 2. Find instantiation sites\nsdd doc call-graph <ClassName> --direction both\n\n# 3. Search for usage patterns\nsdd doc search \"create.*[Entity]|update.*[Entity]\"\n```\n\n### Workflow 3: IMPACT-ANALYSIS\n\n**Goal:** Identify all code affected by modifying a function, class, or module.\n\n**Use cases:** \"What breaks if I refactor this function?\", \"What depends on this API endpoint?\", \"Can I safely delete this class?\"\n\n#### Automated Approach (Recommended)\n\n```bash\nsdd doc impact <entity> [--depth N]\n```\n\n**Example:** `sdd doc impact calculate_score --depth 2`\n\n**Output:** Direct/indirect dependents, test coverage estimate, risk score (high/medium/low), actionable recommendations\n\n#### Manual Approach\n\n```bash\n# 1. Find callers\nsdd doc callers <function>\n\n# 2. Find reverse dependencies\nsdd doc dependencies <module> --reverse\n\n# 3. Assess complexity\nsdd doc complexity --module <module>\n\n# 4. Check usage\nsdd doc search \"<exact-name>\"\n```\n\n**Note:** For reverse dependencies, use import names not file paths (e.g., `\"myapp.utils.scoring\"` not `utils/scoring.py`). See \"Understanding Reverse Dependencies\" section.\n\n### Workflow 4: REFACTOR-PRIORITY\n\n**Goal:** Identify high-complexity, high-impact code for refactoring.\n\n**Use cases:** \"What should I refactor first?\", Technical debt reduction planning\n\n#### Automated Approach (Recommended)\n\n```bash\nsdd doc refactor-candidates [--min-complexity N] [--limit N]\n```\n\n**Example:** `sdd doc refactor-candidates --min-complexity 15`\n\n**Output:** Prioritized list by priority score (complexity  dependents), risk categorization, quick wins vs major refactors\n\n#### Manual Approach\n\n```bash\n# 1. Find high-complexity functions\nsdd doc complexity --threshold 15\n\n# 2. For each, assess impact\nsdd doc callers <function>\nsdd doc dependencies <module> --reverse\n```\n\n---\n\n### Additional Manual Patterns\n\nFor specialized investigations without automated commands, combine basic queries:\n\n#### EXPLORE-FEATURE-AREA\n**Goal:** Comprehensive feature context gathering\n\n```bash\nsdd doc context \"[feature]\"  # Get all related entities\nsdd doc describe-module [key-modules]  # Understand each layer\nsdd doc complexity | grep \"[feature]\"  # Find hot spots\n```\n\n#### FIND-PATTERN\n**Goal:** Discover how patterns (validation, caching, auth) are implemented\n\n```bash\nsdd doc search \"[pattern-keyword]\"  # Find implementations\nsdd doc find-class \".*[Pattern].*\" --pattern  # Find pattern classes\nsdd doc describe-module [pattern-file]  # Understand architecture\n```\n\n#### ONBOARD-TO-CODEBASE\n**Goal:** Get oriented in an unfamiliar codebase\n\n```bash\nsdd doc stats  # Overview: size, complexity baseline\nsdd doc search \"main|index|app\"  # Find entry points\nsdd doc list-modules  # Understand architecture\nsdd doc complexity --threshold 10  # Identify areas to avoid initially\n```\n\n#### TRACE-ERROR-FLOW\n**Goal:** Understand error propagation and handling\n\n```bash\nsdd doc find-class \".*Error.*|.*Exception.*\" --pattern  # Find error types\nsdd doc search \"raise|throw|except\"  # Find error handling\nsdd doc describe-module [error-module]  # Understand error architecture\n```\n\n#### TRACE-CONFIGURATION\n**Goal:** Track configuration usage\n\n```bash\nsdd doc find-class \"[Config|Settings].*\" --pattern  # Find config classes\nsdd doc search \"get_settings|config\"  # Find access patterns\nsdd doc dependencies [config-module] --reverse  # Find consumers\n```\n\n#### TRACE-TEST-COVERAGE\n**Goal:** Understand testing strategy\n\n```bash\nsdd doc list-modules | grep \"test\"  # Find test files\nsdd doc describe-module tests/[feature]_test.py  # Understand test structure\nsdd doc dependencies tests/[test-file]  # See what's being tested\n```\n\n---\n\n## When to Use Manual Queries vs Automated Workflows\n\n**Use automated workflows (`trace-entry`, `trace-data`, `impact`, `refactor-candidates`) when:**\n- You have a specific function/class name\n- You need comprehensive analysis with risk assessment\n- You want architectural layer classification\n- Time is limited and you need fast results\n\n**Use manual query patterns when:**\n- Exploring unfamiliar territory without specific targets\n- Need custom analysis outside automated workflow scope\n- Building integration scripts or custom tooling\n- Investigating specialized patterns (error handling, config, tests)\n- Learning the codebase structure from scratch\n\n---\n\n## Complete Examples\n\n### Example 1: Tracing Execution Flow\n\nUnderstand how the scoring feature works end-to-end:\n\n```bash\nsdd doc trace-entry run_scoring\n```\n\nShows complete call chain from HTMX endpoint  scoring service  LLM service  OpenAI API, with architectural layer classification, complexity scores for each function, and hot spot identification.\n\n### Example 2: Impact Analysis for Refactoring\n\nAssess the blast radius before refactoring `get_session` function:\n\n```bash\nsdd doc impact get_session\n```\n\nReturns risk level CRITICAL (complexity 85  50+ dependents), lists direct and indirect dependents, estimates test coverage, and provides actionable recommendations for safe refactoring approach.\n\n### Example 3: Finding Refactoring Candidates\n\nIdentify high-priority technical debt:\n\n```bash\nsdd doc refactor-candidates --min-complexity 15\n```\n\nReturns prioritized list sorted by risk score (complexity  dependents), categorizes by risk level, identifies quick wins (high complexity, low dependents) vs major refactors (high complexity, high dependents), with specific recommendations for each.\n\n---\n\n## Performance Notes\n\n- All queries are fast (milliseconds) as they only read JSON\n- No source code parsing or AST analysis\n- Documentation is cached in memory during a query session\n- For large codebases (>1000 files), queries remain performant\n\n\n---\n\n*For more information on generating documentation, see the `Skill(sdd-toolkit:code-doc)` skill.*\n*For spec-driven development workflows, see `Skill(sdd-toolkit:sdd-plan)`, `Skill(sdd-toolkit:sdd-next)`, and `Skill(sdd-toolkit:sdd-update)` skills.*"
              },
              {
                "name": "llm-doc-gen",
                "description": "LLM-powered documentation generation for narrative architecture docs, tutorials, and developer guides. Uses AI consultation to create contextual, human-readable documentation from code analysis and spec data.",
                "path": "skills/llm-doc-gen/SKILL.md",
                "frontmatter": {
                  "name": "llm-doc-gen",
                  "description": "LLM-powered documentation generation for narrative architecture docs, tutorials, and developer guides. Uses AI consultation to create contextual, human-readable documentation from code analysis and spec data."
                },
                "content": "# LLM-Based Documentation Generation Skill\n\n## Overview\n\nThis skill generates comprehensive, navigable documentation using Large Language Model (LLM) consultation. It creates sharded documentation (organized topic files) by having LLMs read and analyze source code directly, then synthesizing their insights into structured, human-readable guides.\n\n**Core Capability:** Transform codebases into sharded documentation by orchestrating LLM analysis through workflow-driven steps, managing state for resumability, and producing organized topic files instead of monolithic documents.\n\n**Use this skill when:**\n- Creating architecture documentation that explains *why*, not just *what*\n- Generating developer onboarding guides with contextual explanations\n- Writing tutorials that synthesize multiple code concepts\n- Producing design documentation from implementation details\n- Creating narrative content that requires interpretation and synthesis\n\n**Key features:**\n- **Sharded documentation** - Organized topic files (architecture/, guides/, reference/) instead of monolithic docs\n- **State-based resumability** - Resume interrupted scans from last checkpoint\n- **Multi-agent consultation** - Parallel LLM queries for comprehensive insights\n- **Workflow orchestration** - Step-by-step analysis guided by workflow engine\n- **Direct source reading** - LLMs read code directly (no AST parsing required)\n- **Research-then-synthesis** - LLMs provide research, main agent composes organized docs\n\n**Do NOT use for:**\n- Quick prototyping or throwaway code\n- Projects under 100 lines\n- Code that changes daily (docs become stale quickly)\n- When simple README.md is sufficient\n\n##  Long-Running Operations\n\n**This skill may run operations that take up to 5 minutes. Be patient and wait for completion.**\n\n### CRITICAL: Avoid BashOutput Spam\n- **ALWAYS use foreground execution with 5-minute timeout:** `Bash(command=\"...\", timeout=300000)`\n- **WAIT for the command to complete** - this may take the full 5 minutes\n- **NEVER use `run_in_background=True` for test suites, builds, or analysis**\n- If you must use background (rare), **wait at least 60 seconds** between BashOutput checks\n- **Maximum 3 BashOutput calls per background process** - then kill it or let it finish\n\n### Why?\nPolling BashOutput repeatedly creates spam and degrades user experience. Long operations should run in foreground with appropriate timeout, not in background with frequent polling.\n\n### Example (CORRECT):\n```\n# Test suite that might take 5 minutes (timeout in milliseconds)\nresult = Bash(command=\"pytest src/\", timeout=300000)  # Wait up to 5 minutes\n# The command will block here until completion - this is correct behavior\n```\n\n### Example (WRONG):\n```\n# Don't use background + polling\nbash_id = Bash(command=\"pytest\", run_in_background=True)\noutput = BashOutput(bash_id)  # Creates spam!\n```\n\n---\n\n## Sharded Documentation Output\n\nUnlike monolithic documentation files, llm-doc-gen produces organized, navigable documentation sharded by topic:\n\n**Example Output Structure:**\n```\ndocs/\n index.md                    # Main navigation and project overview\n architecture/\n    overview.md             # System architecture and design\n    components.md           # Component descriptions\n    data-flow.md            # Data flow and interactions\n guides/\n    getting-started.md      # Developer onboarding\n    development.md          # Development workflows\n    deployment.md           # Deployment procedures\n reference/\n     api.md                  # API reference\n     configuration.md        # Configuration options\n     troubleshooting.md      # Common issues and solutions\n```\n\n**Benefits:**\n- **Navigable** - Find specific topics easily\n- **Maintainable** - Update individual sections without touching others\n- **Scalable** - Grows organically with project complexity\n- **Readable** - Focused docs instead of overwhelming single file\n\n**State File for Resumability:**\n\nThe skill maintains a `project-doc-state.json` file to enable resuming interrupted scans:\n\n```json\n{\n  \"version\": \"1.0\",\n  \"project_name\": \"MyProject\",\n  \"last_updated\": \"2025-11-19T20:00:00Z\",\n  \"current_step\": \"generate-guides\",\n  \"completed_steps\": [\"scan-structure\", \"analyze-architecture\", \"generate-architecture-docs\"],\n  \"files_analyzed\": [\"src/main.py\", \"src/auth.py\", \"src/db.py\"],\n  \"sections_generated\": [\n    \"docs/index.md\",\n    \"docs/architecture/overview.md\",\n    \"docs/architecture/components.md\"\n  ],\n  \"workflow_mode\": \"full_scan\"\n}\n```\n\nIf the scan is interrupted, simply run `sdd llm-doc-gen resume ./docs` to continue from the last checkpoint.\n\n---\n\n## Core Workflow\n\n### Workflow-Driven Documentation Generation\n\nThe llm-doc-gen skill uses a workflow engine that orchestrates LLM analysis through systematic steps:\n\n```\n\n Step 1: Initialize                      \n  \n                                         \n   Scan project structure               \n   Create state file (project-doc-state.json) \n   Detect project type                  \n   Plan documentation sections          \n   Check for existing docs/resume       \n\n                 \n                 \n\n Step 2: Analyze Architecture            \n  \n                                         \n   LLMs read source files directly      \n   Identify components and patterns     \n   Analyze data flow and interactions   \n   Multi-agent consultation (parallel)  \n   Update state: architecture analyzed  \n\n                 \n                 \n\n Step 3: Generate Architecture Docs      \n  \n                                         \n   Synthesize LLM research findings     \n   Create docs/architecture/overview.md \n   Create docs/architecture/components.md \n   Create docs/architecture/data-flow.md \n   Update state: architecture docs done \n\n                 \n                 \n\n Step 4: Generate Guides                 \n  \n                                         \n   Analyze developer workflows          \n   Create docs/guides/getting-started.md \n   Create docs/guides/development.md    \n   Create docs/guides/deployment.md     \n   Update state: guides done            \n\n                 \n                 \n\n Step 5: Generate Reference              \n  \n                                         \n   Extract API patterns                 \n   Create docs/reference/api.md         \n   Create docs/reference/configuration.md \n   Create docs/reference/troubleshooting.md \n   Update state: reference done         \n\n                 \n                 \n\n Step 6: Finalize                        \n  \n                                         \n   Generate docs/index.md with navigation \n   Validate all sections created        \n   Update state: complete                \n   Archive state file                   \n\n```\n\n**Resumability:**\n\nIf interrupted at any step, the workflow can resume from the last completed step using the state file:\n\n```bash\n# Workflow interrupted after Step 3\nsdd llm-doc-gen resume ./docs\n# Resumes from Step 4: Generate Guides\n```\n\n**Key Workflow Principles:**\n\n1. **Stateful Execution**\n   - Each step updates project-doc-state.json\n   - Resume from any checkpoint\n   - No duplicate work\n\n2. **LLMs Read Code Directly**\n   - No AST parsing or pre-processing\n   - LLMs analyze source files natively\n   - Simpler, more maintainable\n\n3. **Sharded Output**\n   - Each step produces focused docs\n   - Organized by topic (architecture/, guides/, reference/)\n   - Easy to navigate and maintain\n\n4. **Multi-Agent Research**\n   - Parallel LLM consultation at each step\n   - Synthesis of multiple perspectives\n   - Richer, more comprehensive insights\n\n---\n\n## Using Codebase Analysis Insights\n\n**CRITICAL: The llm-doc-gen skill automatically integrates analysis insights when available.**\n\n### Before Generating Documentation\n\n**Check for analysis data:**\n\n1. Look for `codebase.json` in the project root\n2. If found: Analysis insights will be automatically integrated into documentation generation\n3. If missing: Generation continues without insights (graceful degradation - still produces quality docs)\n\n### Informing the User\n\n**Always tell the user about insights status:**\n\n**If `codebase.json` exists:**\n```\n Found codebase analysis data (codebase.json)\n Using factual metrics to enhance documentation quality\n```\n\n**If `codebase.json` is missing:**\n```\n  No analysis data found (codebase.json)\n Tip: Run `sdd doc generate` first for better results with factual insights\n Continuing with AI reasoning only\n```\n\n### What Happens Automatically\n\nWhen `codebase.json` exists, the generators automatically:\n- Extract high-value metrics (most-called functions, entry points, complexity, dependencies)\n- Format insights within token budgets (250-450 tokens depending on generator type)\n- Include formatted insights in LLM prompts for factual grounding\n- Use insights to improve architectural pattern identification and accuracy\n\n**You don't need to pass special flags or parameters.** The integration is automatic.\n\n### Error Handling\n\n**If insight extraction fails:**\n- Generation continues without insights\n- Log a warning but don't fail the operation\n- Inform user: \"Warning: Could not load analysis insights, continuing with AI reasoning only\"\n\n**Never fail documentation generation due to missing or corrupt analysis data.** Graceful degradation is built-in.\n\n### Expected Improvements\n\nWhen insights are used, expect documentation to include:\n- Specific function/class names with actual call counts and usage metrics\n- Identified entry points and critical code paths\n- Real module dependency relationships with reference counts\n- Complexity metrics for refactoring guidance\n\nFor details about the integration architecture, performance, and best practices, see `docs/llm-doc-gen/ANALYSIS_INTEGRATION.md`.\n\n---\n\n## Tool Verification\n\n**Before using this skill**, verify that LLM tools are available:\n\n```bash\n# Check which tools are available for llm-doc-gen\nsdd test check-tools --skill llm-doc-gen\n\n# For JSON output\nsdd test check-tools --skill llm-doc-gen --json\n```\n\n**Expected:** At least one LLM tool should be detected as available.\n\n**IMPORTANT - How This Skill Works:**\n-  **Skill invokes LLM tools** - Uses `execute_tool_with_fallback()` and `execute_tools_parallel()`\n-  **Provider abstraction** - Shared `claude_skills.common.ai_tools` infrastructure\n-  **Multi-agent support** - Parallel consultation of 2+ LLMs for comprehensive insights\n-  **No direct LLM calls** - Does not invoke OpenAI/Anthropic APIs directly\n\nThe skill shells out to installed CLI tools (cursor-agent, gemini, codex) which handle the actual LLM API communication.\n\nIf no LLM tools are installed, this skill cannot function. Install at least one of the supported tools before using llm-doc-gen.\n\n---\n\n## Quick Start\n\n### Basic Usage\n\n```bash\n# Generate complete sharded documentation\nsdd llm-doc-gen scan ./src --project-name MyProject --output-dir ./docs\n\n# Resume interrupted scan\nsdd llm-doc-gen resume ./docs\n\n# Generate specific section only\nsdd llm-doc-gen section architecture --source ./src --output ./docs/architecture/\n\n# Single-agent mode (faster, less comprehensive)\nsdd llm-doc-gen scan ./src --single-agent --tool cursor-agent\n```\n\n### Output\n\nAfter running `sdd llm-doc-gen scan`, you'll get organized documentation:\n\n```\ndocs/\n index.md                    # Navigation and overview\n architecture/               # System design docs\n    overview.md\n    components.md\n    data-flow.md\n guides/                     # Developer guides\n    getting-started.md\n    development.md\n    deployment.md\n reference/                  # Reference docs\n     api.md\n     configuration.md\n     troubleshooting.md\n```\n\n---\n\n## When to Use This Skill\n\n###  Use `Skill(sdd-toolkit:llm-doc-gen)` when:\n\n1. **Architecture Documentation**\n   - Explaining system design and component relationships\n   - Documenting architectural decisions and trade-offs\n   - Creating high-level overviews for stakeholders\n\n2. **Developer Onboarding**\n   - Writing guides that explain \"how things work here\"\n   - Creating contextual documentation for new team members\n   - Synthesizing knowledge across multiple modules\n\n3. **Tutorial Creation**\n   - Generating step-by-step guides from code examples\n   - Explaining complex features with narrative flow\n   - Creating learning materials from implementation\n\n4. **Design Documentation**\n   - Documenting design patterns and their rationale\n   - Explaining implementation choices\n   - Creating architecture decision records (ADRs)\n\n5. **Specification-Based Docs**\n   - Generating implementation guides from SDD specs\n   - Creating post-implementation documentation\n   - Synthesizing spec intent with actual code\n\n###  Don't use `Skill(sdd-toolkit:llm-doc-gen)` when:\n\n1. **You need structural accuracy**\n   - Use `sdd doc generate` for programmatic extraction\n   - LLMs may miss edge cases or hallucinate details\n   - Structural docs require 100% accuracy\n\n2. **Simple API documentation**\n   - `sdd doc generate` handles function signatures better\n   - No need for narrative in pure API reference\n   - Programmatic extraction is faster and more accurate\n\n3. **Quick prototyping or spikes**\n   - LLM consultation adds overhead (30-60s per doc)\n   - Not worth it for throwaway code\n   - Save for production documentation\n\n4. **Documentation already exists**\n   - Don't regenerate if existing docs are current\n   - LLM costs add up quickly\n   - Update manually for small changes\n\n---\n\n## Critical Rules\n\n### MUST DO:\n\n1. **Always use the workflow engine**\n   - Don't skip initialization step\n   - Let the workflow manage state and checkpoints\n   - Enable resumability by maintaining state file\n\n2. **Use multi-agent by default**\n   - Parallel consultation provides richer insights\n   - Synthesis of multiple perspectives improves quality\n   - Only use single-agent for quick iterations or cost constraints\n\n3. **Let LLMs read code directly**\n   - Provide source file paths to LLMs\n   - No pre-processing or parsing required\n   - Trust LLMs to understand code structure\n\n4. **Maintain state file integrity**\n   - Don't manually edit project-doc-state.json\n   - Use `sdd llm-doc-gen resume` to continue interrupted scans\n   - State file enables checkpointing and progress tracking\n\n5. **Report LLM failures transparently**\n   - If an LLM tool fails, inform the user\n   - Explain which models succeeded/failed\n   - Provide fallback options\n\n### MUST NOT DO:\n\n1. **Never let LLMs write files directly**\n   - Always use research-then-synthesis pattern\n   - Workflow engine controls all file operations\n   - LLMs return analysis text only\n\n2. **Never skip the initialization step**\n   - State file setup is critical for resumability\n   - Project structure scan informs documentation organization\n   - Skipping initialization breaks checkpoint recovery\n\n3. **Never mix monolithic and sharded output**\n    - Stick to sharded documentation structure\n    - Avoid reintroducing a single-file Markdown export\n    - Organized topics are more maintainable\n\n\n4. **Never ignore timeout/failure**\n   - LLM calls can hang or fail\n   - Always implement timeout handling\n   - Provide graceful fallback to single-agent or manual\n\n5. **Never batch without state tracking**\n   - LLM consultation is expensive (time and API cost)\n   - State file tracks progress through sections\n   - Always show progress during generation\n\n---\n\n## Detailed Workflow Steps\n\n### Step-by-Step Execution\n\nWhen you run `sdd llm-doc-gen scan ./src --project-name MyProject`, the workflow engine executes these steps:\n\n#### Step 1: Initialize (5-10 seconds)\n\n**Actions:**\n- Scan project directory structure\n- Detect project type (web app, library, CLI tool, etc.)\n- Create `docs/project-doc-state.json` file\n- Plan documentation sections based on project type\n- Check for existing documentation to resume\n\n**Output:**\n```\n Scanning project structure...\n Detected: Python web application (Flask)\n Planned sections: architecture, guides, reference\n State file created: docs/project-doc-state.json\n```\n\n**Resume Check:**\nIf state file exists, you'll be prompted:\n```\nFound existing documentation state (last updated 2 hours ago).\n\nResume from where you left off? [Y/n]\n```\n\n---\n\n#### Step 2: Analyze Architecture (30-60 seconds)\n\n**Actions:**\n- LLMs read main source files (entry points, core modules)\n- Identify system components and their relationships\n- Analyze data flow and interaction patterns\n- Multi-agent consultation (2+ LLMs in parallel)\n- Synthesize findings from multiple perspectives\n\n**Expected Output:**\n```\n Consulting 2 AI models for architecture analysis...\n   Tools: cursor-agent, gemini\n\n cursor-agent completed (28.3s)\n gemini completed (24.1s)\n\n Analysis complete:\n   - 5 core components identified\n   - 3 data flow patterns documented\n   - 12 source files analyzed\n```\n\n**State Update:**\n`current_step: \"generate-architecture-docs\"`, `completed_steps: [\"initialize\", \"analyze-architecture\"]`\n\n---\n\n#### Step 3: Generate Architecture Docs (20-40 seconds)\n\n**Actions:**\n- Synthesize LLM research findings\n- Create `docs/architecture/overview.md`\n- Create `docs/architecture/components.md`\n- Create `docs/architecture/data-flow.md`\n- Update state file\n\n**Expected Output:**\n```\n Generating architecture documentation...\n\n Created: docs/architecture/overview.md (2.1 KB)\n Created: docs/architecture/components.md (3.4 KB)\n Created: docs/architecture/data-flow.md (1.8 KB)\n\n State updated: 3 architecture docs complete\n```\n\n---\n\n#### Step 4: Generate Guides (40-80 seconds)\n\n**Actions:**\n- Analyze developer workflows and setup procedures\n- Create `docs/guides/getting-started.md`\n- Create `docs/guides/development.md`\n- Create `docs/guides/deployment.md`\n- Update state file\n\n**Expected Output:**\n```\n Generating developer guides...\n\n Analyzing: Setup procedures, development workflows, deployment...\n\n Created: docs/guides/getting-started.md (4.2 KB)\n Created: docs/guides/development.md (3.1 KB)\n Created: docs/guides/deployment.md (2.5 KB)\n\n State updated: 3 guide docs complete\n```\n\n---\n\n#### Step 5: Generate Reference (30-50 seconds)\n\n**Actions:**\n- Extract API patterns and endpoints\n- Document configuration options\n- Identify common issues and solutions\n- Create reference documentation\n- Update state file\n\n**Expected Output:**\n```\n Generating reference documentation...\n\n Created: docs/reference/api.md (5.3 KB)\n Created: docs/reference/configuration.md (2.8 KB)\n Created: docs/reference/troubleshooting.md (1.9 KB)\n\n State updated: 3 reference docs complete\n```\n\n---\n\n#### Step 6: Finalize (10-15 seconds)\n\n**Actions:**\n- Generate `docs/index.md` with navigation\n- Validate all sections created\n- Mark state as complete\n- Archive state file\n\n**Expected Output:**\n```\n Finalizing documentation...\n\n Created: docs/index.md (navigation index)\n Validated: All 9 documentation files present\n\n Documentation Complete:\n   Total sections: 9 files\n   Total size: 27.1 KB\n   Time elapsed: 2m 45s\n\n Output directory: ./docs\n```\n\n---\n\n### Resumability\n\nIf the workflow is interrupted at any step, the state file preserves progress:\n\n```json\n{\n  \"current_step\": \"generate-guides\",\n  \"completed_steps\": [\"initialize\", \"analyze-architecture\", \"generate-architecture-docs\"],\n  \"sections_generated\": [\n    \"docs/architecture/overview.md\",\n    \"docs/architecture/components.md\",\n    \"docs/architecture/data-flow.md\"\n  ]\n}\n```\n\n**To resume:**\n```bash\nsdd llm-doc-gen resume ./docs\n```\n\n**Resume output:**\n```\n Resuming documentation generation...\n Found state file (last updated 1 hour ago)\n Progress: 3/9 sections complete (33%)\n  Resuming from: Step 4 (Generate Guides)\n```\n\nThe workflow continues from Step 4, skipping already-completed sections.\n\n---\n\n### User Interaction Points\n\nThe workflow prompts for user input at key decision points:\n\n**1. Resume Check** (if state file exists)\n```\nFound existing documentation state.\n\nResume from where you left off? [Y/n]\n```\n\n**2. Project Type Confirmation** (if auto-detection uncertain)\n```\nDetected project type: Web Application\n\nIs this correct? [Y/n]\n> If no: What type of project is this? [library/cli/api/other]\n```\n\n**3. Section Selection** (optional)\n```\nGenerate all sections or specific sections only?\n\n1. All sections (recommended)\n2. Architecture only\n3. Guides only\n4. Reference only\n5. Custom selection\n\nChoice [1]:\n```\n\n**4. LLM Tool Failure**\n```\n  Warning: cursor-agent failed (timeout)\n\nContinue with remaining tools? [Y/n]\nAvailable: gemini\n```\n\n---\n\n## Next Steps\n\nThis skill is currently under development. The sections above define the core purpose and workflow. Implementation details, CLI commands, and examples will be added in subsequent phases.\n\n**Current Status:** Phase 1 - Documentation & Planning (IN PROGRESS)\n\n**Remaining Work:**\n- CLI command structure definition\n- Prompt template development\n- Synthesis logic implementation\n- Integration with code-doc and SDD\n- Comprehensive examples and use cases"
              },
              {
                "name": "run-tests",
                "description": "Comprehensive pytest testing and debugging framework. Use when running tests, debugging failures, fixing broken tests, or investigating test errors. Includes systematic investigation workflow with external AI tool consultation and verification strategies.",
                "path": "skills/run-tests/SKILL.md",
                "frontmatter": {
                  "name": "run-tests",
                  "description": "Comprehensive pytest testing and debugging framework. Use when running tests, debugging failures, fixing broken tests, or investigating test errors. Includes systematic investigation workflow with external AI tool consultation and verification strategies."
                },
                "content": "# Pytest Testing and Debugging Skill\n\n## Overview\n\nThis skill provides a systematic approach to running tests and debugging failures using pytest. The core workflow integrates investigation, external tool consultation, and verification to efficiently resolve test failures.\n\n**Key capabilities:**\n- Run tests with presets for common scenarios (debug, quick, coverage)\n- Systematic investigation and hypothesis formation\n- External AI tool consultation (gemini, codex, cursor-agent) when tests fail\n- Multi-agent analysis for complex issues\n- Test discovery and structure analysis\n\n##  Long-Running Operations\n\n**This skill may run operations that take up to 5 minutes. Be patient and wait for completion.**\n\n### CRITICAL: Avoid BashOutput Spam\n- **ALWAYS use foreground execution with 5-minute timeout:** `Bash(command=\"...\", timeout=300000)`\n- **WAIT for the command to complete** - this may take the full 5 minutes\n- **NEVER use `run_in_background=True` for test suites, builds, or analysis**\n- If you must use background (rare), **wait at least 60 seconds** between BashOutput checks\n- **Maximum 3 BashOutput calls per background process** - then kill it or let it finish\n\n### Why?\nPolling BashOutput repeatedly creates spam and degrades user experience. Long operations should run in foreground with appropriate timeout, not in background with frequent polling.\n\n### Example (CORRECT):\n```\n# Test suite that might take 5 minutes (timeout in milliseconds)\nresult = Bash(command=\"pytest src/\", timeout=300000)  # Wait up to 5 minutes\n# The command will block here until completion - this is correct behavior\n```\n\n### Example (WRONG):\n```\n# Don't use background + polling\nbash_id = Bash(command=\"pytest\", run_in_background=True)\noutput = BashOutput(bash_id)  # Creates spam!\n```\n\n## Core Workflow\n\n**5-Phase Process:**\n\n1. **Run Tests** - Execute tests with appropriate flags\n2. **Investigate** - Analyze failures, form hypothesis\n3. **Gather Context** - Optionally use code documentation for faster understanding\n4. **Consult** - Get external tool insights (mandatory for failures if tools available)\n5. **Fix & Verify** - Implement changes and confirm no regressions\n\n**Key principles:**\n- **Investigation-first** - Always analyze before consulting\n- **Hypothesis-driven** - Form theories, then validate\n- **Mandatory consultation for failures** - If tests fail and tools exist, consult them\n- **Skip when passing** - Tests pass? Done. No consultation needed.\n\n**Quick decision guide:**\n-  Tests pass?  Done\n-  Simple fix (typo/obvious)?  Fix  Verify\n-  Complex/unclear?  Investigate  Consult  Fix  Verify\n\n## Phase 1: Run Tests\n\n### Discover Test Structure (Optional)\n\nIf unfamiliar with test organization:\n\n```bash\n# Quick summary\nsdd test discover --summary\n\n# Directory tree\nsdd test discover --tree\n```\n\n### Run Tests\n\n```bash\n# Quick run (stop on first failure)\nsdd test run --quick\n\n# Debug mode (verbose with locals and prints)\nsdd test run --preset-debug\n\n# Run specific test\nsdd test run tests/test_module.py::test_function\n\n# Coverage report\nsdd test run --coverage\n\n# List all presets\nsdd test run --list\n```\n\nOr use pytest directly:\n\n```bash\npytest -v                # Verbose\npytest -vv -l -s        # Very verbose, show locals, show prints\npytest -x                # Stop on first failure\npytest -k \"test_user\"   # Run tests matching pattern\n```\n\n### Capture Output\n\nFor large test suites with many failures:\n\n```bash\n# Save output to timestamped file\nsdd test run --preset-debug | tee /tmp/test-run-$(date +%Y%m%d-%H%M%S).log\n```\n\n## Phase 2: Investigate Failures\n\n### Categorize the Failure\n\n- **Assertion** - Expected vs actual mismatch\n- **Exception** - Runtime errors (AttributeError, KeyError, etc.)\n- **Import** - Missing dependencies or module issues\n- **Fixture** - Fixture or configuration issues\n- **Timeout** - Performance or hanging issues\n- **Flaky** - Non-deterministic failures\n\n### Extract Key Information\n\nFor each failure:\n- Test file and function name\n- Line number where failure occurred\n- Error type and message\n- Full stack trace\n- Relevant code context\n\n### Examine the Code\n\n- Read the failing test\n- Read the implementation being tested\n- Understand what the test verifies\n- Identify expected vs actual behavior\n- **Form your hypothesis** - What's causing the failure?\n\n## Phase 3: Gather Code Context (Optional)\n\n**When available:** If codebase documentation exists (generated by `sdd doc generate`), use it for faster investigation.\n\n**Check availability:**\n```bash\nsdd doc stats\n```\n\n**Useful commands when debugging:**\n```bash\n# Search for functions or concepts\nsdd doc search \"authentication\"\n\n# Show function definition\nsdd doc show-function AuthService.login\n\n# Find dependencies\nsdd doc list-dependencies src/services/authService.ts\n\n# Find what depends on a file (impact analysis)\nsdd doc dependencies --reverse src/auth.py\n```\n\n**Benefits:**\n- Faster context gathering\n- Better root cause analysis\n- Discover similar patterns\n- Impact analysis\n\n**If not available:** Continue with standard file exploration. Run `sdd doc generate` to create documentation for future use.\n\n## Phase 4: Consult External Tools\n\n**CRITICAL:** This is **mandatory** for test failures when external tools exist.\n\n### Check Tool Availability\n\n```bash\nsdd test check-tools\n```\n\n**Decision:**\n- **Any tool available AND tests failed**  Consult (mandatory)\n- **No tools available**  Skip to Phase 5\n- **Tests passed**  Skip to Phase 5 (no consultation needed)\n\n### Consult Tools\n\n**All external tools operate in read-only mode.** They analyze and suggest; YOU implement all fixes.\n\n```bash\n# Auto-route based on failure type\nsdd test consult assertion --error \"Full error message\" --hypothesis \"Your theory about the cause\"\n\n# Include code for context\nsdd test consult exception --error \"AttributeError: ...\" --hypothesis \"Missing return\" --test-code tests/test_file.py --impl-code src/module.py\n\n# Show routing matrix\nsdd test consult --list-routing\n\n# Manual tool selection\nsdd test consult --tool gemini --prompt \"Custom question...\"\n```\n\n### Tool Selection Guide\n\n| Tool | Best For | Example Use |\n|------|----------|-------------|\n| **Gemini** | Hypothesis validation, framework explanations, strategic guidance | \"Why is this fixture not found?\" |\n| **Codex** | Code-level review, specific fix suggestions | \"Review this code and suggest fixes\" |\n| **Cursor** | Repo-wide discovery, finding patterns | \"Find all call sites\" |\n\n### When to Use Multiple Tools\n\nUse multi-agent consultation for:\n- High-stakes fixes affecting critical functionality\n- Complex issues with unclear root cause\n- Need validation from multiple perspectives\n- Uncertain between multiple approaches\n\n```bash\n# Auto-selects configured consensus agents\nsdd test consult assertion --error \"...\" --hypothesis \"...\" --multi-agent\n\n# Override which agents participate (comma-separated list)\nsdd test consult exception --error \"...\" --hypothesis \"...\" --multi-agent --agents gemini,codex\n```\n\n### Effective Prompting\n\n1. **Share your hypothesis** - Ask \"is my theory correct?\" not \"what's wrong?\"\n2. **Provide complete context** - Error messages, code, stack traces\n3. **Include what you've tried** - Show your investigation work\n4. **Ask for explanations** - Understand \"why\", not just \"how to fix\"\n5. **Be specific** - State exactly what you need\n\n## Phase 5: Fix & Verify\n\n### Synthesize Findings\n\nCombine insights from:\n- Your investigation and hypothesis\n- External tool recommendations\n- Any additional research\n\n### Implement Fix\n\n```bash\n# Make targeted changes using Edit tool\n# Example: Add missing return statement\n```\n\n### Verify\n\n```bash\n# Run the specific fixed test\nsdd test run tests/test_module.py::test_function\n\n# If passing, run full suite\nsdd test run\n\n# Verify no regressions\npytest tests/ -v\n```\n\n### Document\n\nAdd comments explaining:\n- What was wrong\n- Why the fix works\n- Any assumptions or limitations\n\n## CLI Reference\n\n### sdd test check-tools\n\nCheck availability of external tools and get routing suggestions.\n\n```bash\n# Basic check\nsdd test check-tools\n\n# Get routing for specific failure type\nsdd test check-tools --route assertion\nsdd test check-tools --route fixture\n```\n\n### sdd test run\n\nSmart pytest runner with presets for common scenarios.\n\n```bash\n# List all presets\nsdd test run --list\n\n# Presets\nsdd test run --quick      # Stop on first failure\nsdd test run --preset-debug      # Verbose + locals + prints\nsdd test run --coverage   # Coverage report\nsdd test run --fast       # Skip slow tests\nsdd test run --parallel   # Run in parallel\n\n# Run specific test\nsdd test run tests/test_file.py::test_name\n```\n\n### sdd test consult\n\nExternal tool consultation with auto-routing.\n\n```bash\n# Auto-route based on failure type\nsdd test consult {assertion|exception|fixture|import|timeout|flaky} --error \"...\" --hypothesis \"...\"\n\n# Include code\nsdd test consult exception --error \"...\" --hypothesis \"...\" --test-code tests/test.py --impl-code src/module.py\n\n# Multi-agent mode\nsdd test consult assertion --error \"...\" --hypothesis \"...\" --multi-agent\n\n# Manual tool selection\nsdd test consult --tool {gemini|codex|cursor} --prompt \"...\"\n\n# Show routing matrix\nsdd test consult --list-routing\n\n# Dry run\nsdd test consult fixture --error \"...\" --hypothesis \"...\" --dry-run\n```\n\n### sdd test discover\n\nTest structure analyzer and discovery.\n\n```bash\n# Quick summary\nsdd test discover --summary\n\n# Directory tree\nsdd test discover --tree\n\n# All fixtures\nsdd test discover --fixtures\n\n# All markers\nsdd test discover --markers\n\n# Detailed analysis\nsdd test discover --detailed\n\n# Analyze specific directory\nsdd test discover tests/unit --summary\n```\n\n### Global Options\n\nAvailable on all commands:\n- `--no-color` - Disable colored output\n- `--verbose`, `-v` - Show detailed output\n- `--quiet`, `-q` - Minimal output (errors only)\n\n## Common Patterns\n\n### Multiple Failing Tests\n\n1. Group by error type\n2. Fix one group at a time\n3. Look for common root causes\n4. Consider whether tests need updating vs code needs fixing\n\n### Flaky Tests\n\n```bash\n# Run test multiple times\npytest tests/test_flaky.py --count=10\n\n# Run with random order\npytest --random-order\n```\n\n### Fixture Issues\n\n```bash\n# Show fixture setup and teardown\npytest --setup-show tests/test_module.py\n\n# List available fixtures\npytest --fixtures\n```\n\n**Common fixture problems:**\n- Fixture not in conftest.py or test file\n- Fixture name doesn't match exactly\n- conftest.py in wrong directory\n- Incorrect fixture scope\n\n### Integration Test Failures\n\nCheck in order:\n1. External dependencies\n2. Test environment setup\n3. Database state\n4. Configuration\n5. Network connectivity\n\n## Tool Routing Matrix\n\nQuick reference for which tool to use based on failure type:\n\n| Failure Type | Primary Tool | Secondary (if needed) | Why |\n|--------------|--------------|----------------------|-----|\n| **Assertion mismatch** | Codex | Gemini | Code-level bug analysis |\n| **Exceptions** | Codex | Gemini | Precise code review |\n| **Import/packaging** | Gemini | Cursor | Framework expertise |\n| **Fixture issues** | Gemini | Cursor | Pytest scoping knowledge |\n| **Timeout/performance** | Gemini + Cursor | - | Strategy + pattern discovery |\n| **Flaky tests** | Gemini + Cursor | - | Diagnosis + state dependencies |\n| **Multi-file issues** | Cursor | Gemini | Discovery + synthesis |\n| **Unclear errors** | Gemini | Web search | Explanation first |\n\n**Query type routing:**\n- \"Why is this happening?\"  Gemini\n- \"Is this code wrong?\"  Codex\n- \"Where else does this occur?\"  Cursor\n- \"What should I do?\"  Gemini + Codex\n\n## Special Scenarios\n\n### Verification Runs (Confirming Refactors)\n\nWhen running tests to verify refactoring:\n\n```bash\n# Run full suite\nsdd test run\n\n# If all pass: Done! No consultation needed.\n# If tests fail: Follow standard debugging workflow\n```\n\n**Key point:** Passing verification runs require no consultation. Only investigate failures.\n\n### When Tools Disagree\n\nIf two tools give different recommendations:\n\n1. **Compare reasoning** - Which explanation is more thorough?\n2. **Check scope** - Which considers broader impact?\n3. **Apply critical thinking** - Which aligns with your investigation?\n4. **Try simplest first** - Implement less invasive fix first\n5. **Document uncertainty** - Note in code comments\n\n### When to Escalate to Additional Tools\n\nUse additional tools when:\n- Answer is unclear or vague\n- Answer contradicts your analysis\n- Answer raises new questions\n- Partial answer (addresses some aspects only)\n- High-stakes scenario (critical functionality)\n\n## Timeout and Retry Behavior\n\n**Consultation timeouts:**\n- Default: 90 seconds\n- Configurable via `.claude/ai_config.yaml` (`run-tests.consultation.timeout_seconds`)\n\n**When tools time out:**\n1. Simplify prompt (remove large code blocks)\n2. Try different tool from routing matrix\n3. Check if tool process is hung: `ps aux | grep <tool>`\n4. Increase timeout in config if needed\n\n## Tool Availability Fallbacks\n\n| Recommended | If Unavailable | How to Compensate |\n|-------------|----------------|-------------------|\n| **Gemini** | Codex or Cursor | Ask \"why\" with extra context; use web search |\n| **Codex** | Gemini | Ask for very specific code examples |\n| **Cursor** | Manual Grep + Gemini | Use Grep to find patterns, Gemini to analyze |\n\n## Advanced Topics\n\n### Multi-Agent Analysis\n\nMulti-agent mode consults two agents in parallel and synthesizes their insights:\n\n```bash\nsdd test consult fixture --error \"...\" --hypothesis \"...\" --multi-agent\n```\n\n**Output includes:**\n- Consensus points (where agents agree)\n- Unique insights from each agent\n- Synthesis combining both analyses\n- High-confidence recommendations\n\n**Benefits:**\n- Higher confidence through multiple perspectives\n- Better coverage (each agent contributes unique insights)\n- Risk reduction (divergent views expose alternatives)\n\n### Using pytest-pdb for Debugging\n\n```bash\n# Drop into debugger on failure\npytest --pdb\n\n# Drop into debugger on first failure\npytest -x --pdb\n```\n\n### Custom Markers for Test Organization\n\n```python\n# conftest.py\ndef pytest_configure(config):\n    config.addinivalue_line(\"markers\", \"slow: marks tests as slow\")\n    config.addinivalue_line(\"markers\", \"integration: marks integration tests\")\n    config.addinivalue_line(\"markers\", \"unit: marks unit tests\")\n\n# Usage\n@pytest.mark.slow\ndef test_complex_calculation():\n    pass\n```\n\n### Mocking External Services\n\n```python\nfrom unittest.mock import Mock, patch\n\ndef test_api_call():\n    with patch('requests.get') as mock_get:\n        mock_get.return_value.json.return_value = {\"status\": \"ok\"}\n        result = fetch_data()\n        assert result[\"status\"] == \"ok\"\n        mock_get.assert_called_once()\n```\n\n## Troubleshooting\n\n### \"Fixture not found\"\n\n1. Check fixture is defined in conftest.py or same file\n2. Verify fixture name matches exactly\n3. Check fixture scope is appropriate\n4. Ensure conftest.py is in correct directory\n\n### \"Import error\"\n\n1. Check PYTHONPATH includes src directory\n2. Verify `__init__.py` files exist\n3. Check for circular imports\n4. Verify package installed in development mode\n\n### \"Tests pass locally but fail in CI\"\n\n1. Check for hardcoded paths\n2. Verify all dependencies in requirements\n3. Check for timezone issues\n4. Look for race conditions\n5. Check file system differences\n\n### \"Test is too slow\"\n\n1. Use fixtures with appropriate scope\n2. Mock external services\n3. Use in-memory databases\n4. Parallelize: `sdd test run --parallel`\n\n## Best Practices\n\n### Running Tests\n\n1. Start with verbose mode (`-v`) for better visibility\n2. Use `-x` to stop on first failure when debugging\n3. Run specific tests to iterate faster\n4. Use markers to organize test runs\n\n### Debugging Strategy\n\n1. Read error messages carefully\n2. Check last line of stack trace first\n3. Use `-l` flag to see local variables\n4. Add temporary print statements for quick debugging\n\n### Consultation Workflow\n\n**For test failures:**\n1. Do initial investigation first\n2. Check tool availability: `sdd test check-tools`\n3. Consult available tools (mandatory if tests failed)\n4. Share your hypothesis - don't ask blind questions\n5. Synthesize insights from tools + your analysis\n6. YOU implement using Edit/Write tools\n7. Test thoroughly\n\n**Skip consultation when:**\n- Tests all passed\n- Verification/smoke tests succeeded\n- Post-fix confirmation (tests already passed once)\n- No tools available\n\n## Success Criteria\n\nA test debugging session is successful when:\n-  All tests pass\n-  No new tests are broken\n-  Root cause is understood\n-  Fix is documented\n-  Code is cleaner/clearer than before (when appropriate)"
              },
              {
                "name": "sdd-fidelity-review",
                "description": "Review implementation fidelity against specifications by comparing actual code to spec requirements. Identifies deviations, assesses impact, and generates compliance reports for tasks, phases, or entire specs.",
                "path": "skills/sdd-fidelity-review/SKILL.md",
                "frontmatter": {
                  "name": "sdd-fidelity-review",
                  "description": "Review implementation fidelity against specifications by comparing actual code to spec requirements. Identifies deviations, assesses impact, and generates compliance reports for tasks, phases, or entire specs."
                },
                "content": "# Implementation Fidelity Review Skill\n\n## Overview\n\nThe `sdd-fidelity-review` skill compares actual implementation against SDD specification requirements to ensure fidelity between plan and code. It identifies deviations, assesses their impact, and generates detailed compliance reports.\n\n## Skill Family\n\nThis skill is part of the **Spec-Driven Development** quality assurance family:\n- **Skill(sdd-toolkit:sdd-plan)** - Creates specifications\n- **Skill(sdd-toolkit:sdd-next)** - Finds next tasks and creates execution plans\n- **Implementation** - Code is written\n- **sdd-update-subagent** - Updates progress\n- **Skill(sdd-toolkit:sdd-fidelity-review)** (this skill) - Reviews implementation fidelity\n- **run-tests-subagent** - Runs tests\n\n## When to Use This Skill\n\nUse this skill when you need to:\n- Verify implementation matches specification requirements\n- Identify deviations between plan and actual code\n- Assess task or phase completion accuracy\n- Review pull requests for spec compliance\n- Audit completed work for fidelity\n- Document implementation variations\n\n**Do NOT use for:**\n- Creating specifications (use sdd-plan)\n- Finding next tasks (use sdd-next)\n- Updating task status (use sdd-update)\n- Running tests (use run-tests)\n\n##  Long-Running Operations\n\n**This skill may run operations that take up to 5 minutes. Be patient and wait for completion.**\n\n### CRITICAL: Avoid BashOutput Spam\n- **ALWAYS use foreground execution with 5-minute timeout:** `Bash(command=\"...\", timeout=300000)`\n- **WAIT for the command to complete** - this may take the full 5 minutes\n- **NEVER use `run_in_background=True` for test suites, builds, or analysis**\n- If you must use background (rare), **wait at least 60 seconds** between BashOutput checks\n- **Maximum 3 BashOutput calls per background process** - then kill it or let it finish\n\n### Why?\nPolling BashOutput repeatedly creates spam and degrades user experience. Long operations should run in foreground with appropriate timeout, not in background with frequent polling.\n\n### Example (CORRECT):\n```\n# Test suite that might take 5 minutes (timeout in milliseconds)\nresult = Bash(command=\"pytest src/\", timeout=300000)  # Wait up to 5 minutes\n# The command will block here until completion - this is correct behavior\n```\n\n### Example (WRONG):\n```\n# Don't use background + polling\nbash_id = Bash(command=\"pytest\", run_in_background=True)\noutput = BashOutput(bash_id)  # Creates spam!\n```\n\n## Review Types\n\n### 1. Phase Review\n**Scope:** Single phase within specification (typically 3-10 tasks)\n**When to use:** Phase completion checkpoints, before moving to next phase\n**Output:** Phase-specific fidelity report with per-task breakdown\n**Best practice:** Use at phase boundaries to catch drift before starting next phase\n\n### 2. Task Review\n**Scope:** Individual task implementation (typically 1 file)\n**When to use:** Critical task validation, complex implementation verification\n**Output:** Task-specific compliance check with implementation comparison\n**Best practice:** Use for high-risk tasks (auth, data handling, API contracts)\n\n**Note:** For full spec reviews, run phase-by-phase reviews for better manageability and quality.\n\n## Reading Specifications (CRITICAL)\n\n**This skill delegates ALL spec file access to the `sdd fidelity-review` CLI tool:**\n\n-  **NEVER** use `Read()` tool on .json spec files - bypasses hooks and wastes context tokens (specs can be 50KB+)\n-  **NEVER** use Python to parse spec JSON directly\n-  **NEVER** use `jq` to query spec files via Bash\n-  **NEVER** use Bash commands to read specs (e.g., `cat`, `head`, `tail`, `grep`)\n-  **NEVER** use command chaining to access specs (e.g., `sdd --version && cat specs/active/spec.json`)\n-  **ALWAYS** use `sdd fidelity-review` CLI commands to access spec data\n-  The CLI provides efficient, structured access with proper parsing and validation\n-  Spec files are large - reading them directly wastes valuable context window space\n\n**All spec loading, task extraction, and requirement analysis happens inside the CLI tool.**\n\n## Querying Spec and Task Data Efficiently\n\nBefore running a fidelity review, you may need to gather context about the spec, phases, or tasks. Use these efficient CLI commands instead of creating bash loops:\n\n### Query Multiple Tasks at Once\n```bash\n# Get all tasks in a phase\nsdd query-tasks <spec-id> --parent phase-1 --json\n\n# Get tasks by status\nsdd query-tasks <spec-id> --status completed --json\n\n# Combine filters\nsdd query-tasks <spec-id> --parent phase-2 --status pending --json\n\n# Get all tasks (no limit)\nsdd query-tasks <spec-id> --limit 0 --json\n```\n\n### Get Single Task Details\n```bash\n# Get detailed information about a specific task\nsdd get-task <spec-id> task-1-3\n```\n\n### List Phases\n```bash\n# See all phases with progress information\nsdd list-phases <spec-id>\n```\n\n###  DON'T Do This (Inefficient)\n```bash\n# BAD: Bash loop calling sdd get-task repeatedly\nfor i in 1 2 3 4 5; do\n  sdd get-task spec-id \"task-1-$i\"\ndone\n\n# BAD: Creating temp scripts\ncat > /tmp/get_tasks.sh << 'EOF'\n...\nEOF\n\n# BAD: Using grep to parse JSON\nsdd get-task spec-id task-1 | grep -o '\"status\":\"[^\"]*\"'\n```\n\n###  DO This Instead\n```bash\n# GOOD: Single command gets all tasks in phase-1\nsdd query-tasks spec-id --parent phase-1 --json\n\n# GOOD: Parse JSON properly with jq if needed\nsdd query-tasks spec-id --parent phase-1 --json | jq '.[] | select(.status==\"completed\")'\n```\n\n## Workflow\n\nThis skill delegates all fidelity review logic to the dedicated `sdd fidelity-review` CLI tool, which handles spec loading, implementation analysis, AI consultation, and report generation.\n\n### Step 1: Validate Inputs\n\nEnsure the user provides:\n- `spec_id`: The specification to review\n- Either `task_id` (for task-level review) or `phase_id` (for phase-level review)\n\n### Step 2: Construct CLI Command\n\nBuild the appropriate `sdd fidelity-review` command based on review scope:\n\n**For task review:**\n```bash\nsdd fidelity-review <spec-id> --task <task-id>\n```\n\n**For phase review:**\n```bash\nsdd fidelity-review <spec-id> --phase <phase-id>\n```\n\n### Step 3: Execute CLI Command\n\nUse the Bash tool to execute the constructed command:\n```bash\nsdd fidelity-review <spec-id> --task <task-id>\n```\n\n**CRITICAL:** The CLI tool handles ALL spec file operations. Do NOT:\n- Read spec files with Read tool\n- Parse specs with Python or jq\n- Use cat/head/tail/grep on spec files\n- Create temporary bash scripts (e.g., `/tmp/*.sh`)\n- Use bash loops to iterate through tasks (e.g., `for i in 1 2 3; do sdd get-task...`)\n- Call `sdd get-task` in a loop - use `sdd query-tasks` for batch retrieval\n- Use grep/sed/awk to parse JSON outputs - all commands return structured JSON\n\n**When you need task/spec context before running fidelity review:**\n Use `sdd query-tasks <spec-id> --parent <phase-id> --json` to get all tasks in a phase\n Use `sdd query-tasks <spec-id> --status <status> --json` to filter by status\n Use `sdd get-task <spec-id> <task-id>` to get a single task's details\n Use `sdd list-phases <spec-id>` to see all phases\n\nThen execute the fidelity review with the appropriate scope.\n\nYour job is to execute the CLI command and parse its JSON output.\n\nThe CLI tool handles:\n- Loading and validating the specification\n- Extracting task/phase requirements\n- Analyzing implementation files\n- Consulting AI tools (gemini, codex, cursor-agent) for deviation analysis\n- Detecting consensus across multiple AI perspectives\n- Categorizing deviations (exact match, minor, major, missing)\n- Assessing impact levels\n- Generating structured report\n\n### Step 4: Parse and Present Results\n\nThe CLI returns JSON output with the structure:\n```json\n{\n  \"spec_id\": \"...\",\n  \"review_type\": \"task|phase\",\n  \"scope\": {\"id\": \"...\", \"title\": \"...\"},\n  \"summary\": {\n    \"tasks_reviewed\": 0,\n    \"files_analyzed\": 0,\n    \"deviations_found\": 0,\n    \"fidelity_score\": 0\n  },\n  \"findings\": [\n    {\n      \"task_id\": \"...\",\n      \"assessment\": \"exact_match|minor_deviation|major_deviation|missing\",\n      \"deviations\": [...],\n      \"impact\": \"low|medium|high\",\n      \"ai_consensus\": \"...\"\n    }\n  ],\n  \"recommendations\": [...]\n}\n```\n\nParse this JSON, surface the structured findings directly to the invoking workflow, and include a link or path to the saved JSON report. The agents responsibility is to faithfully relay the CLIs assessed deviations, recommendations, consensus signals, and metadataperform validation/formatting as needed, but do not introduce any new analysis beyond what the CLI returned. Do not open or read the saved artifact; simply point the caller to its location.\n\n## Report Structure\n\n```markdown\n# Implementation Fidelity Review\n\n**Spec:** {spec-title} ({spec-id})\n**Scope:** {review-scope}\n**Date:** {review-date}\n\n## Summary\n\n- **Tasks Reviewed:** {count}\n- **Files Analyzed:** {count}\n- **Overall Fidelity:** {percentage}%\n- **Deviations Found:** {count}\n\n## Fidelity Score\n\n-  Exact Matches: {count} tasks\n-  Minor Deviations: {count} tasks\n-  Major Deviations: {count} tasks\n-  Missing Functionality: {count} items\n\n## Detailed Findings\n\n### Task: {task-id} - {task-title}\n\n**Specified:**\n- {requirement-1}\n- {requirement-2}\n\n**Implemented:**\n- {actual-1}\n- {actual-2}\n\n**Assessment:** {exact-match|minor-deviation|major-deviation}\n\n**Deviations:**\n1. {deviation-description}\n   - **Impact:** {low|medium|high}\n   - **Recommendation:** {action}\n\n## Recommendations\n\n1. {recommendation-1}\n2. {recommendation-2}\n\n## Journal Analysis\n\n**Documented Deviations:**\n- {task-id}: {deviation-summary} (from journal on {date})\n\n**Undocumented Deviations:**\n- {task-id}: {deviation-summary} (should be journaled)\n```\n\n## Integration with SDD Workflow\n\n### When to Invoke\n\nFidelity reviews can be triggered at multiple points in the development workflow:\n\n**1. After task completion (Optional verification):**\n   - Optional verification step for critical tasks\n   - Ensures task acceptance criteria fully met\n   - Particularly useful for high-risk tasks (auth, data handling, API contracts)\n   - Can be automated via verification task metadata\n\n**2. Phase completion (Recommended):**\n   - Review entire phase before moving to next phase\n   - Catch drift early before it compounds\n   - Best practice: Use at phase boundaries\n   - Prevents accumulated technical debt\n\n**3. Spec completion (Pre-PR audit):**\n   - Final comprehensive audit before PR creation\n   - Run phase-by-phase reviews for better quality\n   - Ensures PR matches spec intent\n   - Documents any deviations for PR description\n\n**4. PR review (Automated compliance):**\n   - Automated or manual PR compliance checks\n   - Verify changes align with original specification\n   - Useful for reviewer context and validation\n\n### Review Outcome Handling\n\nThe `sdd-fidelity-review` skill hands its synthesized resultsJSON findings plus the saved JSON report referencedirectly back to the caller. The invoking workflow decides what to do next. Common follow-up actions the main agent may optionally consider include journaling deviations, planning remediation work, running regression tests, or proposing spec updates after stakeholder review. No automatic delegation occurs; the fidelity-review skills responsibility ends once it delivers the consensus results and report pointer.\n\n### Report Handoff\n\nFidelity review generates a detailed report comparing implementation against specification:\n\n**Usage Pattern:**\n1. Skill executes `sdd fidelity-review` CLI tool\n2. CLI analyzes implementation, generates JSON output, and saves the JSON consensus report in `.fidelity-reviews/`\n3. Skill parses the JSON, presents the summarized findings, and surfaces the stored report path to the caller\n\n## Fidelity Assessment\n\n### Exact Match ()\nImplementation precisely matches specification requirements. No deviations detected.\n\n### Minor Deviation ()\nSmall differences from spec with no functional impact:\n- Different variable names (but consistent with codebase style)\n- Minor refactoring for code quality\n- Improved error messages\n- Additional logging or comments\n\n### Major Deviation ()\nSignificant differences affecting functionality or architecture:\n- Different API signatures than specified\n- Missing required features\n- Different data structures\n- Changed control flow or logic\n\n### Missing Functionality ()\nSpecified features not implemented:\n- Required functions missing\n- Incomplete implementation\n- Skipped acceptance criteria\n\n## Best Practices\n\n### DO\n Validate that spec_id and task_id/phase_id are provided\n Present findings clearly with categorized deviations\n Highlight recommendations for remediation\n Note AI consensus from multiple tool perspectives\n Provide context from the fidelity assessment\n Surface the saved JSON report path so the caller can inspect the full consensus artifacts\n\n### DON'T\n Attempt to manually implement review logic (CLI handles it)\n Read spec files directly with Read/Python/jq/Bash (CLI loads them)\n Create temporary bash scripts or use bash loops (e.g., `for i in...; do sdd get-task...`)\n Call `sdd get-task` in a loop - use `sdd query-tasks` for batch queries instead\n Use grep/sed/awk to parse JSON - all CLI commands return structured JSON\n Skip input validation\n Ignore the CLI tool's consensus analysis\n Make up review findings not from CLI output\n Perform additional analysis beyond the CLI's consensus results\n Open the persisted JSON report; reference its filepath instead\n\n## Example Invocations\n\n**Phase review:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-fidelity-review-subagent\",\n  prompt: \"Review phase phase-1 in spec user-auth-001. Compare all completed tasks in Phase 1 (User Model & Authentication) against specification requirements.\",\n  description: \"Phase 1 fidelity review\"\n)\n```\n\n**Task-specific review:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-fidelity-review-subagent\",\n  prompt: \"Review task task-2-3 in spec user-auth-001. Compare implementation in src/middleware/auth.ts against task requirements for JWT authentication middleware.\",\n  description: \"Review auth middleware task\"\n)\n```\n\n## Error Handling\n\n### Missing Required Information\nIf invoked without required information, the skill returns a structured error indicating which fields are missing.\n\n### Spec Not Found\nIf the specified spec file doesn't exist, the skill reports which directories were searched and suggests verification steps.\n\n### No Implementation Found\nIf the specified files don't exist, the skill warns that the task appears incomplete or the file paths are incorrect.\n\n## Success Criteria\n\nA successful fidelity review:\n-  Compares all specified requirements against implementation\n-  Identifies and categorizes deviations accurately\n-  Assesses impact of deviations\n-  Provides actionable recommendations\n-  Generates clear, structured report\n-  Automatically saves to `specs/.fidelity-reviews/` directory\n-  Documents findings for future reference\n\n---\n\n*For creating specifications, use Skill(sdd-toolkit:sdd-plan). For task progress updates, use sdd-update-subagent. For running tests, use run-tests-subagent.*"
              },
              {
                "name": "sdd-modify",
                "description": "Apply spec modifications systematically. Use to apply review feedback, bulk modifications, or interactive spec updates with safety checks, validation, and rollback support.",
                "path": "skills/sdd-modify/SKILL.md",
                "frontmatter": {
                  "name": "sdd-modify",
                  "description": "Apply spec modifications systematically. Use to apply review feedback, bulk modifications, or interactive spec updates with safety checks, validation, and rollback support."
                },
                "content": "# Spec-Driven Development: Modify Skill\n\n## When to Use This Skill\n\nUse `Skill(sdd-toolkit:sdd-modify)` to:\n- **Apply review feedback systematically** - Parse and apply modifications from sdd-fidelity-review or sdd-plan-review outputs\n- **Execute bulk modifications** - Apply multiple spec changes from JSON files with validation\n- **Interactive spec updates** - Guided workflow for making structural changes to specifications\n- **Parse review reports** - Convert review feedback to structured modification format\n- **Preview modifications** - See what would change before applying (dry-run mode)\n\n**Do NOT use for:**\n- Simple task status updates (use `sdd-update` instead)\n- Creating new specifications (use `sdd-plan` instead)\n- Validation only (use `sdd-validate` instead)\n- Finding next task to work on (use `sdd-next` instead)\n\n## Core Philosophy\n\n**Systematic Modification**: Spec modifications should be systematic, validated, and safe. This skill provides a guided workflow with previews, user approval, automatic backups, validation, and rollback support to ensure spec integrity.\n\n**Feedback Loop Completion**: This skill closes the loop: Review  Parse  Modify  Validate  Re-review. It enables systematic application of review feedback without manual error-prone editing.\n\n## Skill Family\n\nThis skill is part of the **Spec-Driven Development** workflow:\n- **sdd-plan** - Creates specifications\n- **sdd-fidelity-review** - Reviews implementation against spec\n- **sdd-plan-review** - Multi-model spec review before implementation\n- **sdd-modify** (this skill) - Applies modifications systematically\n- **sdd-validate** - Validates spec structure\n- **sdd-update** - Tracks task progress and metadata\n\n## Relationship to sdd-update\n\n**When to use sdd-modify vs sdd-update:**\n\n| Operation | Use sdd-modify | Use sdd-update |\n|-----------|---------------|---------------|\n| Change task status (in_progress, blocked) |  No |  Yes |\n| Mark task completed |  No |  Yes |\n| Add journal entries |  No |  Yes |\n| Update task descriptions |  Yes |  No |\n| Add/remove tasks |  Yes |  No |\n| Add verification steps |  Yes |  No |\n| Apply review feedback |  Yes |  No |\n| Bulk structural changes |  Yes |  No |\n| Move spec between folders |  No |  Yes |\n| Update spec metadata |  Yes (structural) |  Yes (progress) |\n\n**Summary:**\n- **sdd-update** = Task progress, status, journaling (lightweight metadata updates)\n- **sdd-modify** = Structural changes, bulk modifications, review feedback (heavyweight spec restructuring)\n\n## Reading Specifications (CRITICAL)\n\n**When working with spec files, ALWAYS use `sdd` CLI commands:**\n-  **ALWAYS** use `sdd` commands to read/query spec files\n-  **NEVER** use `Read()` tool on .json spec files - bypasses hooks and wastes context tokens\n-  **NEVER** use Bash commands to read spec files (e.g., `cat`, `head`, `tail`, `grep`, `jq`)\n-  **NEVER** use Python to directly read/write spec JSON files (e.g., `python << EOF ... json.load()`, `open()`)\n-  **NEVER** bypass the Read() hook by using alternative file access methods\n- The `sdd` CLI provides efficient, structured access with proper parsing and validation\n- Spec files can be 50KB+ and reading them directly wastes valuable context window space\n\n**To understand spec structure without reading the spec:**\n-  Get the schema: `sdd schema` - outputs the complete spec schema JSON\n- This shows all required and optional fields, including metadata structure\n\n**For simple metadata updates (like adding a title field):**\n-  Use: `sdd update-frontmatter <spec-id> <key> <value> [--dry-run]`\n- Example: `sdd update-frontmatter my-spec-001 title \"My Specification Title\"`\n- This is faster and safer than using `sdd apply-modifications` for single-field updates\n\n## Command Execution Best Practices (CRITICAL)\n\n**CRITICAL: Run sdd commands individually, never in loops or chains**\n\n### DO: Individual Command Execution\n\nRun each `sdd` command as a separate Bash tool call:\n\n```bash\n# Parse review report\nsdd parse-review my-spec-001 --review reports/review.md --output suggestions.json\n\n# Preview modifications\nsdd apply-modifications my-spec-001 --from suggestions.json --dry-run\n\n# Apply modifications\nsdd apply-modifications my-spec-001 --from suggestions.json\n```\n\n### DON'T: Loops, Chains, or Compound Commands\n\n**Never use bash loops:**\n```bash\n#  WRONG - Do not use loops\nfor spec in specs/*.json; do\n  sdd apply-modifications $(basename $spec .json) --from mods.json\ndone\n```\n\n**Never chain commands:**\n```bash\n#  WRONG - Do not chain commands\nsdd parse-review my-spec-001 --review review.md && sdd apply-modifications my-spec-001 --from suggestions.json\n```\n\n**Never use compound commands:**\n```bash\n#  WRONG - Do not combine with other commands\necho \"Parsing review...\" && sdd parse-review my-spec-001 --review review.md\n```\n\n**Never use semicolons:**\n```bash\n#  WRONG - Do not use semicolons\nsdd parse-review spec-1 --review r1.md; sdd parse-review spec-2 --review r2.md\n```\n\n### Why Individual Execution Matters\n\n1. **Transaction Safety** - Each modification operation is a transaction with automatic rollback\n2. **Error Handling** - Easier to identify which operation failed\n3. **Rollback Boundaries** - Clear transaction boundaries prevent partial modifications\n4. **Permission Clarity** - User can approve/deny each operation separately\n5. **Progress Visibility** - User sees each step complete\n6. **Debugging** - Easier to trace issues to specific operations\n7. **Idempotency** - Safe to retry individual failed operations\n\n### Correct Pattern: Sequential Individual Calls\n\n**For multiple specs:**\n```bash\n#  CORRECT - Individual calls\nsdd apply-modifications spec-1 --from mods.json\n# Wait for completion, check result\n\nsdd apply-modifications spec-2 --from mods.json\n# Wait for completion, check result\n\nsdd apply-modifications spec-3 --from mods.json\n# Wait for completion, check result\n```\n\n**For workflow steps:**\n```bash\n#  CORRECT - Sequential individual operations\nsdd parse-review my-spec-001 --review reports/review.md --output suggestions.json\n# Wait, parse results\n\nsdd apply-modifications my-spec-001 --from suggestions.json --dry-run\n# Wait, review preview\n\nsdd apply-modifications my-spec-001 --from suggestions.json\n# Wait, verify completion\n```\n\n## Workflow 1: Apply Review Feedback\n\nComplete workflow for applying feedback from sdd-fidelity-review or sdd-plan-review.\n\n### Step 1: Generate Review Report\n\nFirst, run a review to identify issues:\n\n```bash\n# Run fidelity review\nSkill(sdd-toolkit:sdd-fidelity-review) \"Review implementation for spec my-spec-001\"\n\n# This generates: reports/my-spec-001-fidelity-review.md\n```\n\n### Step 2: Parse Review Report\n\nConvert review feedback to structured modifications:\n\n```bash\nsdd parse-review my-spec-001 --review reports/my-spec-001-fidelity-review.md --output suggestions.json\n```\n\n**Output:**\n```\n Parsed 5 modifications from review report\n Saved to suggestions.json\n\nModifications by type:\n  - update_task: 3\n  - add_verification: 2\n\nConfidence scores:\n  - High confidence: 4 modifications\n  - Medium confidence: 1 modification\n  - Low confidence: 0 modifications\n```\n\n### Step 3: Preview Modifications\n\nSee what would change before applying:\n\n```bash\nsdd apply-modifications my-spec-001 --from suggestions.json --dry-run\n```\n\n**Output:**\n```\n Modification Preview (Dry-Run)\n\nTasks to Update:\n  task-2-1: \"Implement auth\"\n     \"Implement OAuth 2.0 authentication with PKCE flow\"\n\n  task-2-2: \"Add login endpoint\"\n     \"Add /auth/login endpoint with rate limiting\"\n\n  task-3-1: \"Write tests\"\n     \"Write comprehensive tests covering edge cases and error handling\"\n\nVerification Steps to Add:\n  task-2-1 verify-2-1-3: \"Verify token expiration handling\"\n  task-2-2 verify-2-2-4: \"Verify rate limiting with concurrent requests\"\n\nImpact Summary:\n  - 3 tasks will be updated\n  - 2 verification steps will be added\n  - 2 phases affected\n  - 0 tasks will be added\n  - 0 tasks will be removed\n\nNo validation errors predicted.\n```\n\n### Step 4: Apply Modifications\n\nApply the changes with automatic backup and validation:\n\n```bash\nsdd apply-modifications my-spec-001 --from suggestions.json\n```\n\n**Output:**\n```\n Backup created: specs/.backups/my-spec-001-20251106-143022.json\n Applied 5 modifications\n Validation passed\n Spec updated successfully\n\nChanges:\n  - Updated 3 task descriptions\n  - Added 2 verification steps\n\nNext steps:\n  - Review updated spec: sdd context show my-spec-001\n  - Continue implementation with updated guidance\n  - Run fidelity review again to confirm issues resolved\n```\n\n### Step 5: Verify Results\n\nOptionally, run fidelity review again to confirm issues are resolved:\n\n```bash\nSkill(sdd-toolkit:sdd-fidelity-review) \"Re-review spec my-spec-001 after modifications\"\n```\n\n## Workflow 2: Bulk Modifications from JSON\n\nApply pre-defined modifications from a JSON file.\n\n### Step 1: Create Modification File\n\nCreate a JSON file with desired modifications:\n\n```json\n{\n  \"modifications\": [\n    {\n      \"operation\": \"update_task\",\n      \"task_id\": \"task-2-1\",\n      \"updates\": {\n        \"description\": \"Implement OAuth 2.0 authentication with PKCE flow and refresh tokens\",\n        \"task_category\": \"implementation\",\n        \"file_path\": \"app/services/auth_service.py\"\n      }\n    },\n    {\n      \"operation\": \"add_verification\",\n      \"task_id\": \"task-2-1\",\n      \"verify_id\": \"verify-2-1-4\",\n      \"description\": \"Verify refresh token rotation works correctly\",\n      \"command\": \"pytest tests/test_auth.py::test_refresh_token_rotation -v\",\n      \"verification_type\": \"automated\"\n    },\n    {\n      \"operation\": \"update_metadata\",\n      \"task_id\": \"task-2-2\",\n      \"metadata\": {\n        \"estimated_hours\": 3,\n        \"priority\": \"high\"\n      }\n    }\n  ]\n}\n```\n\n**Save as:** `my-modifications.json`\n\n### Step 2: Validate Modification Structure\n\nCheck that the modification file is valid:\n\n```bash\nsdd validate-modifications my-modifications.json\n```\n\n**Output:**\n```\n Modification file is valid\n All task references exist in spec\n All required fields present\n No schema violations\n\nReady to apply 3 modifications.\n```\n\n### Step 3: Preview Impact\n\nRun dry-run to see what would change:\n\n```bash\nsdd apply-modifications my-spec-001 --from my-modifications.json --dry-run\n```\n\n### Step 4: Apply with Validation\n\nApply the modifications:\n\n```bash\nsdd apply-modifications my-spec-001 --from my-modifications.json\n```\n\n**Output shows:**\n- Backup location\n- Number of modifications applied\n- Validation results\n- Changes summary\n\n## Workflow 3: Interactive Guided Modification\n\nUse the skill for step-by-step guided modifications (NOT YET IMPLEMENTED - FUTURE ENHANCEMENT).\n\n```bash\nSkill(sdd-toolkit:sdd-modify) \"Guide me through updating spec my-spec-001\"\n```\n\n**Future workflow:**\n1. Skill asks what type of modification you want to make\n2. Provides options: Update task, Add task, Add verification, etc.\n3. Prompts for required information\n4. Shows preview of change\n5. Asks for confirmation\n6. Applies modification\n7. Validates result\n8. Offers to make more changes or finish\n\n**Current Status:** Interactive mode is planned for Phase 2. For now, use Workflows 1 or 2.\n\n## CLI Commands Reference\n\n### Parse Review Report\n\nConvert review feedback to structured modification JSON:\n\n```bash\nsdd parse-review <spec-id> --review <review-report.md> --output <suggestions.json>\n```\n\n**Options:**\n- `--review` - Path to review report (markdown from sdd-fidelity-review or sdd-plan-review)\n- `--output` - Where to save parsed modifications JSON (optional, defaults to `{spec-id}-suggestions.json`)\n\n**Example:**\n```bash\nsdd parse-review my-spec-001 \\\n  --review reports/my-spec-001-review.md \\\n  --output suggestions.json\n```\n\n### Apply Modifications\n\nApply modifications to a spec with validation and backup:\n\n```bash\nsdd apply-modifications <spec-id> --from <modifications.json> [--dry-run] [--no-validate]\n```\n\n**Options:**\n- `--from` - Path to modifications JSON file (required)\n- `--dry-run` - Preview changes without applying (optional)\n- `--no-validate` - Skip validation after applying (NOT RECOMMENDED)\n\n**Examples:**\n```bash\n# Preview modifications\nsdd apply-modifications my-spec-001 --from suggestions.json --dry-run\n\n# Apply modifications with validation\nsdd apply-modifications my-spec-001 --from suggestions.json\n\n# Apply without validation (dangerous, not recommended)\nsdd apply-modifications my-spec-001 --from suggestions.json --no-validate\n```\n\n### Validate Modifications\n\nCheck modification file structure before applying:\n\n```bash\nsdd validate-modifications <modifications.json>\n```\n\n**Example:**\n```bash\nsdd validate-modifications suggestions.json\n```\n\n## Modification JSON Schema\n\nModification files use this structure:\n\n```json\n{\n  \"modifications\": [\n    {\n      \"operation\": \"update_task\",\n      \"task_id\": \"task-2-1\",\n      \"field\": \"description\",\n      \"value\": \"New task description\"\n    },\n    {\n      \"operation\": \"add_verification\",\n      \"task_id\": \"task-2-1\",\n      \"verify_id\": \"verify-2-1-4\",\n      \"description\": \"Verification description\",\n      \"command\": \"optional command to run\"\n    },\n    {\n      \"operation\": \"update_metadata\",\n      \"task_id\": \"task-2-1\",\n      \"field\": \"actual_hours\",\n      \"value\": 4.5\n    }\n  ]\n}\n```\n\n### Supported Operations\n\n#### High-Level Task-Centric Operations (Recommended)\n\n**1. update_task** - Modify multiple task fields in one operation\n\n```json\n{\n  \"operation\": \"update_task\",\n  \"task_id\": \"task-2-1\",\n  \"updates\": {\n    \"title\": \"Updated title\",\n    \"description\": \"Updated description\",\n    \"file_path\": \"app/services/auth.py\",\n    \"task_category\": \"implementation\"\n  }\n}\n```\n\n**Updatable fields:**\n- `title` - Task title\n- `description` - Task description\n- `task_category` - Task category (implementation, test, documentation, etc.)\n- `skill` - Skill to use for this task\n- `command` - Command to run for this task\n- `file_path` - Related file path\n- `status_note` - Note about current status\n- `status` - Task status (pending, in_progress, completed, blocked)\n\n**Notes:**\n- Can update multiple fields in single operation\n- Unknown fields are rejected with clear error\n- Validates task exists and is correct type\n\n**2. add_verification** - Add verification step to task\n\n```json\n{\n  \"operation\": \"add_verification\",\n  \"task_id\": \"task-2-1\",\n  \"verify_id\": \"verify-2-1-4\",\n  \"description\": \"Verify X works correctly\",\n  \"command\": \"pytest tests/test_x.py -v\",\n  \"verification_type\": \"automated\"\n}\n```\n\n**Required fields:**\n- `task_id` - Parent task\n- `verify_id` - Unique verification ID (must follow pattern verify-X-Y-Z)\n- `description` - What to verify\n\n**Optional fields:**\n- `command` - Command to run for verification\n- `verification_type` - Type of verification (\"manual\" or \"automated\", defaults to \"manual\")\n\n**Notes:**\n- Auto-generates boilerplate (type, status, dependencies)\n- Validates parent task exists\n- Prevents duplicate verify_id\n\n**3. update_metadata** - Update task metadata fields\n\n```json\n{\n  \"operation\": \"update_metadata\",\n  \"task_id\": \"task-2-1\",\n  \"metadata\": {\n    \"details\": \"Detailed implementation notes\",\n    \"estimated_hours\": 4,\n    \"priority\": \"high\",\n    \"complexity\": \"medium\"\n  }\n}\n```\n\n**Common metadata fields:**\n- `details` - Detailed implementation notes\n- `estimated_hours` - Estimated time\n- `actual_hours` - Actual time spent\n- `priority` - Task priority (high, medium, low)\n- `complexity` - Task complexity (high, medium, low)\n- Any custom fields your workflow needs\n\n**Notes:**\n- Merges with existing metadata (doesn't replace)\n- Can update multiple metadata fields at once\n- Works on any node type (task, subtask, verify, phase)\n\n**4. batch_update** - Apply same change to multiple nodes\n\n```json\n{\n  \"operation\": \"batch_update\",\n  \"node_ids\": [\"task-1-1\", \"task-1-2\", \"task-1-3\"],\n  \"field\": \"metadata\",\n  \"value\": {\"priority\": \"high\"}\n}\n```\n\n**Required fields:**\n- `node_ids` - List of node IDs to update\n- `field` - Field name to update\n- `value` - Value to set for all nodes\n\n**Notes:**\n- Useful for bulk operations (e.g., set priority for all tasks in phase)\n- Partial success possible (reports which nodes succeeded/failed)\n- Works with any updatable field including metadata\n\n#### Low-Level Node Operations (Advanced)\n\nFor direct node manipulation, use these operations:\n\n**5. add_node** - Add any node type (task, subtask, verify, phase, group)\n\n```json\n{\n  \"operation\": \"add_node\",\n  \"parent_id\": \"phase-2\",\n  \"node_data\": {\n    \"node_id\": \"task-2-5\",\n    \"type\": \"task\",\n    \"title\": \"New task\",\n    \"description\": \"Task description\",\n    \"status\": \"pending\",\n    \"metadata\": {},\n    \"dependencies\": {\"blocks\": [], \"blocked_by\": [], \"depends\": []}\n  }\n}\n```\n\n**6. remove_node** - Remove node (optionally with descendants)\n\n```json\n{\n  \"operation\": \"remove_node\",\n  \"node_id\": \"task-2-5\",\n  \"cascade\": true\n}\n```\n\n**7. update_node_field** - Update single field on any node\n\n```json\n{\n  \"operation\": \"update_node_field\",\n  \"node_id\": \"task-2-1\",\n  \"field\": \"description\",\n  \"value\": \"Updated description\"\n}\n```\n\n**8. move_node** - Move node to different parent\n\n```json\n{\n  \"operation\": \"move_node\",\n  \"node_id\": \"task-1-3\",\n  \"new_parent_id\": \"phase-2\",\n  \"position\": 0\n}\n```\n\n#### Future Operations (Not Yet Implemented)\n\n**9. reorder_tasks** - Change task order within phase (PLANNED)\n\n```json\n{\n  \"operation\": \"reorder_tasks\",\n  \"phase_id\": \"phase-2\",\n  \"new_order\": [\"task-2-2\", \"task-2-1\", \"task-2-3\"]\n}\n```\n\n## Safety Features\n\n### 1. Automatic Backup\n\nEvery apply operation creates a backup before making changes:\n\n```\nspecs/.backups/my-spec-001-20251106-143022.json\n```\n\nBackups include:\n- Full spec content at time of modification\n- Timestamp in filename\n- Preserved indefinitely (manual cleanup required)\n\n**Restoring from backup:**\n```bash\ncp specs/.backups/my-spec-001-20251106-143022.json specs/active/my-spec-001.json\n```\n\n### 2. Transaction Rollback\n\nIf validation fails after applying modifications:\n1. All changes are automatically rolled back\n2. Spec restored to pre-modification state\n3. Backup preserved for manual inspection\n4. Clear error message indicates rollback occurred\n\n**Example rollback scenario:**\n```\n Validation failed after applying modifications\n Rolled back all changes\n Spec restored to original state\n Backup preserved: specs/.backups/my-spec-001-20251106-143022.json\n\nValidation errors:\n  - Task task-2-3 missing required field: description\n  - Invalid phase_id reference in task task-3-1\n\nSuggestions:\n  - Review modification file for invalid task references\n  - Ensure all required fields are included\n  - Run sdd-validate on modification file before applying\n```\n\n### 3. Validation After Apply\n\nAfter every modification (unless `--no-validate` used):\n1. Full spec validation runs\n2. Checks schema compliance\n3. Validates references (phase_id, task_id, etc.)\n4. Ensures required fields present\n5. Reports any issues found\n\n**If validation passes:**\n- Changes committed\n- Success message shown\n- Ready to continue\n\n**If validation fails:**\n- Automatic rollback triggered\n- Error messages explain what's wrong\n- Suggestions for fixing provided\n\n### 4. Idempotency\n\nModifications are designed to be idempotent:\n- Applying same modification twice is safe\n- Second application results in \"no changes\" not error\n- Safe to retry failed operations\n\n**Example:**\n```bash\n# First application\nsdd apply-modifications my-spec-001 --from mods.json\n# Output:  Applied 5 modifications\n\n# Second application (same file)\nsdd apply-modifications my-spec-001 --from mods.json\n# Output:  No changes needed (all modifications already applied)\n```\n\n### 5. Preview Before Apply\n\nAlways preview with `--dry-run` before applying significant changes:\n\n```bash\n# Preview first\nsdd apply-modifications my-spec-001 --from mods.json --dry-run\n\n# Review output, then apply if looks correct\nsdd apply-modifications my-spec-001 --from mods.json\n```\n\n## Integration with Review Skills\n\n### sdd-fidelity-review Integration\n\n**Complete closed-loop workflow:**\n\n```bash\n# 1. Run fidelity review\nSkill(sdd-toolkit:sdd-fidelity-review) \"Review spec my-spec-001\"\n#  Generates: reports/my-spec-001-fidelity-review.md\n\n# 2. Parse review to extract fixes\nsdd parse-review my-spec-001 --review reports/my-spec-001-fidelity-review.md\n\n# 3. Preview modifications\nsdd apply-modifications my-spec-001 --from my-spec-001-suggestions.json --dry-run\n\n# 4. Apply modifications\nsdd apply-modifications my-spec-001 --from my-spec-001-suggestions.json\n\n# 5. Re-review to confirm fixes\nSkill(sdd-toolkit:sdd-fidelity-review) \"Re-review spec my-spec-001\"\n#  Should show issues resolved\n```\n\n### sdd-plan-review Integration\n\n**Apply consensus recommendations:**\n\n```bash\n# 1. Run multi-model plan review\nSkill(sdd-toolkit:sdd-plan-review) \"Review spec my-spec-001\"\n#  Generates consensus recommendations\n\n# 2. Extract high-confidence recommendations\n# (Manual step or automated filter for consensus items)\n\n# 3. Apply consensus improvements\nsdd apply-modifications my-spec-001 --from consensus-improvements.json\n```\n\n## Error Handling\n\n### Common Error Scenarios\n\n**1. Spec Not Found**\n\n```\n Error: Spec 'my-spec-001' not found\n\nSearched locations:\n  - specs/active/my-spec-001.json\n  - specs/pending/my-spec-001.json\n  - specs/completed/my-spec-001.json\n\nSuggestions:\n  - Verify spec ID is correct\n  - Check that spec exists in specs/ folder\n  - Use full path if spec is in non-standard location\n```\n\n**2. Invalid Modification File**\n\n```\n Error: Modification file invalid\n\nValidation errors:\n  - Line 5: Missing required field 'operation'\n  - Line 12: Invalid task_id format 'task2' (expected 'task-2-X')\n  - Line 18: Unknown operation 'delete_task' (supported: update_task, add_verification, update_metadata)\n\nSuggestions:\n  - Review modification schema documentation\n  - Use sdd parse-review to generate valid modification files\n  - Validate modification file structure before applying\n```\n\n**3. Task Reference Error**\n\n```\n Error: Task not found in spec\n\nCannot modify task-5-3: Task does not exist in spec my-spec-001\n\nAvailable tasks in spec:\n  - task-1-1 through task-1-3 (Phase 1)\n  - task-2-1 through task-2-4 (Phase 2)\n  - task-3-1 through task-3-2 (Phase 3)\n\nSuggestions:\n  - Verify task_id exists in spec\n  - Use sdd context show my-spec-001 to see all task IDs\n  - Check for typos in task_id\n```\n\n**4. Validation Failure After Apply**\n\n```\n Error: Validation failed after applying modifications\n All changes rolled back\n Spec restored to original state\n\nValidation errors:\n  - Task task-2-3: Missing required field 'description'\n  - Task task-3-1: Invalid phase_id reference 'phase-5' (phase doesn't exist)\n\nModifications attempted: 5\nBackup location: specs/.backups/my-spec-001-20251106-143022.json\n\nSuggestions:\n  - Review modification file for completeness\n  - Ensure all required fields included in update operations\n  - Verify phase references are correct\n  - Fix issues and retry\n```\n\n### Rollback Communication\n\nWhen rollback occurs:\n1. **Clear indication** - \"All changes rolled back\"\n2. **Reason explained** - Shows validation errors that triggered rollback\n3. **Backup location** - Shows where backup is preserved\n4. **Actionable suggestions** - Tells you how to fix the issue\n\n## Best Practices\n\n### 1. Always Preview First\n\nRun `--dry-run` before applying significant changes:\n\n```bash\n# Preview\nsdd apply-modifications my-spec-001 --from mods.json --dry-run\n\n# Review output carefully\n\n# Apply if preview looks correct\nsdd apply-modifications my-spec-001 --from mods.json\n```\n\n### 2. Start with Small Batches\n\nWhen making many changes:\n- Apply in small batches (5-10 modifications at a time)\n- Validate after each batch\n- Easier to identify and fix issues\n\n```bash\n# Split modifications into batches\nsdd apply-modifications my-spec-001 --from batch1.json\nsdd apply-modifications my-spec-001 --from batch2.json\nsdd apply-modifications my-spec-001 --from batch3.json\n```\n\n### 3. Preserve Backups\n\nKeep backups until changes are verified:\n- Don't delete backups immediately\n- Wait until implementation complete\n- Use for comparison or rollback if needed\n\n```bash\n# Compare current spec to backup\ndiff specs/active/my-spec-001.json specs/.backups/my-spec-001-20251106-143022.json\n```\n\n### 4. Validate Modification Files\n\nBefore applying, validate the modification file structure:\n\n```bash\n# Validate first\nsdd validate-modifications my-modifications.json\n\n# Then apply\nsdd apply-modifications my-spec-001 --from my-modifications.json\n```\n\n### 5. Document Major Changes\n\nAfter significant modifications, add journal entry via sdd-update:\n\n```bash\nsdd add-journal my-spec-001 \\\n  --title \"Spec Updated from Fidelity Review\" \\\n  --content \"Applied 5 modifications based on fidelity review feedback. Updated task descriptions for clarity and added verification steps.\" \\\n  --entry-type note\n```\n\n### 6. Use Parse-Review for Review Feedback\n\nDon't manually create modification files from review reports:\n- Use `sdd parse-review` to automatically extract modifications\n- Reduces errors\n- Faster\n- More reliable\n\n```bash\n#  Good\nsdd parse-review my-spec-001 --review reports/review.md\n\n#  Bad\n# Manually transcribing review feedback into JSON\n```\n\n### 7. Re-Review After Modifications\n\nAfter applying review feedback, run review again to confirm:\n\n```bash\n# Apply modifications\nsdd apply-modifications my-spec-001 --from suggestions.json\n\n# Re-review to confirm issues resolved\nSkill(sdd-toolkit:sdd-fidelity-review) \"Re-review spec my-spec-001\"\n```\n\n### 8. Handle Rollbacks Gracefully\n\nIf rollback occurs:\n1. Read the error messages carefully\n2. Fix issues in modification file\n3. Preview again with `--dry-run`\n4. Retry application\n\n```bash\n# Failed with rollback\nsdd apply-modifications my-spec-001 --from mods.json\n#  Rolled back due to validation errors\n\n# Fix mods.json based on error messages\n\n# Preview to verify fix\nsdd apply-modifications my-spec-001 --from mods.json --dry-run\n\n# Retry\nsdd apply-modifications my-spec-001 --from mods.json\n```\n\n## Limitations\n\n### Current Limitations\n\n1. **No interactive guided mode** - Interactive workflow is planned for Phase 2\n2. **No task reordering** - Cannot change task order within phases yet (use move_node as workaround)\n3. **Limited phase operations** - Can add/remove phases with low-level operations, but no high-level convenience operations\n4. **Single spec at a time** - No batch operations across multiple specs\n5. **Manual batch creation** - No automated batching or dependency resolution for complex multi-spec workflows\n\n### Future Enhancements (Phase 2)\n\n- **Interactive modification builder** - Guided prompts for building modifications\n- **Modification templates** - Common patterns as reusable templates\n- **Diff visualization** - Better visual diff output with highlighting\n- **Undo/redo support** - History of modifications with rollback to any point\n- **Automated batching** - Smart grouping of related modifications\n- **Multi-spec operations** - Apply same modification to multiple specs\n- **Phase operations** - Add, remove, reorder phases\n- **Task operations** - Add, remove, reorder tasks\n- **Dependency tracking** - Handle task dependencies during modifications\n\n## Troubleshooting\n\n### Issue: Parse-review finds no modifications\n\n**Problem:**\n```\nsdd parse-review my-spec-001 --review reports/review.md\n No modifications found in review report\n```\n\n**Solutions:**\n1. Check review report format - Should contain clear modification language\n2. Ensure review was generated by sdd-fidelity-review or sdd-plan-review\n3. Look for patterns like \"update task X to Y\", \"add verification step\"\n4. Manual modification file creation may be needed for non-standard formats\n\n### Issue: Task ID not found\n\n**Problem:**\n```\n Error: Task task-5-3 not found in spec\n```\n\n**Solutions:**\n1. List all task IDs: `sdd context show my-spec-001`\n2. Check for typos in task_id\n3. Verify task exists in current spec version\n4. Ensure you're modifying the correct spec\n\n### Issue: Validation fails after apply\n\n**Problem:**\n```\n Validation failed after applying modifications\n Rolled back all changes\n```\n\n**Solutions:**\n1. Read validation error messages carefully\n2. Check that all required fields are included in modifications\n3. Verify all references (phase_id, task_id) are valid\n4. Fix issues in modification file\n5. Preview with --dry-run before retrying\n6. Apply in smaller batches to isolate problematic modifications\n\n### Issue: Modifications applied but no visible changes\n\n**Problem:**\n```\n Applied 5 modifications\n# But spec looks unchanged\n```\n\n**Solutions:**\n1. Check if modifications were already applied (idempotency)\n2. Verify modification file targets correct fields\n3. Compare with backup: `diff specs/active/spec.json specs/.backups/spec-backup.json`\n4. Review modification values - may be identical to existing values\n\n### Issue: Cannot find backup file\n\n**Problem:**\nNeed to rollback but backup file missing\n\n**Solutions:**\n1. Check `.backups/` folder in specs directory\n2. Backups use timestamp: `{spec-id}-{YYYYMMDD-HHMMSS}.json`\n3. If backup missing, check git history for previous version\n4. Use `git log specs/active/{spec-id}.json` to see commits\n\n## Examples Directory\n\nSee `skills/sdd-modify/examples/` for detailed walkthroughs:\n\n- **apply-review.md** - Complete workflow for applying fidelity review feedback\n- **bulk-modify.md** - Bulk modifications from JSON file\n- **interactive.md** - Interactive guided modification (future)\n\n## Summary\n\nThe sdd-modify skill provides systematic, safe spec modification:\n-  **Safe** - Automatic backup, validation, and rollback\n-  **Systematic** - Parse review feedback automatically\n-  **Validated** - Full validation after every apply\n-  **Transparent** - Clear previews and error messages\n-  **Integrated** - Works seamlessly with review workflows\n\n**Key Workflow:**\n```\nReview  Parse  Preview  Apply  Validate  Re-review\n```\n\nFor simple task status updates and journaling, use `Skill(sdd-toolkit:sdd-update)` instead."
              },
              {
                "name": "sdd-next",
                "description": "Task preparation skill for spec-driven workflows. Reads specifications, identifies next actionable tasks, and creates detailed execution plans. Use when ready to implement a task from an existing spec - bridges the gap between planning and coding.",
                "path": "skills/sdd-next/SKILL.md",
                "frontmatter": {
                  "name": "sdd-next",
                  "description": "Task preparation skill for spec-driven workflows. Reads specifications, identifies next actionable tasks, and creates detailed execution plans. Use when ready to implement a task from an existing spec - bridges the gap between planning and coding."
                },
                "content": "# SDD-Next: Concise Playbook\n\n## Overview\n\n- **Purpose:** Repeatable workflow for discovering specs, selecting actionable tasks, and keeping the user in the loop from planning through wrap-up.\n- **Scope:** Single-task pulls and phase-focused loops; work happens inside project root.\n- **Audience:** AI agents orchestrating SDD workflows who must respect human checkpoints and CLI guardrails.\n\n### High-Level Flow Diagram\n\n```\nStart\n  |\n  v\nRead Work Mode Config (Step 0)\n  |\n  +-- single mode --> Discover Specs -> Gather Context -> Select Task\n  |                     |                         |\n  |                     |                     Alternatives?\n  |                     |                     /         \\\n  |                     |            yes -> Browse   no -> Prepare Recommended Task\n  |                     |                     \\         /\n  |                     v                      v       v\n  |                   Draft Plan -> Seek Approval -> Implementation Handoff\n  |                     |\n  |                     v\n  |                   Post-Implementation Checklist -> Surface Next -> Finish\n  |\n  +-- autonomous mode --> Phase Loop (auto-complete all tasks) -> Finish\n```\n\n---\n\n## Step 0: Read Work Mode Configuration\n\n**CRITICAL: This must be the FIRST step when sdd-next is invoked.**\n\nBefore doing anything else, read the work mode from the user's configuration:\n\n```bash\nsdd get-work-mode --json\n```\n\n**Expected output:**\n```json\n{\"work_mode\": \"single\"}\n```\nor\n```json\n{\"work_mode\": \"autonomous\"}\n```\n\n**Routing based on work_mode:**\n- If `\"single\"`: Follow **Single Task Workflow** (Sections 3.1-3.6)\n  - Plan and execute one task at a time with explicit user approval\n  - After task completion, surface next recommendation and wait for user decision\n- If `\"autonomous\"`: Follow **Autonomous Mode Workflow** (Section starting at line 438)\n  - Complete all tasks in current phase automatically within context limits\n  - Check context after EVERY task completion\n  - Stop only for blockers, plan deviations, or when context 85%\n\n---\n\n## CRITICAL: Global Requirements & Conventions\n\n### Working Directory & Commands\n- Stay inside repo root and keep commands one-per-line (no `&&` chaining)\n- Remember spec folders map to lifecycle (`specs/pending`, `specs/active`, `specs/completed`)\n\n###  CRITICAL: Spec Reading Rules (NEVER VIOLATE)\n\n**ALWAYS use `sdd` commands to read spec JSON files:**\n```bash\n sdd prepare-task {spec-id}\n sdd task-info {spec-id} {task-id}\n sdd progress {spec-id}\n```\n\n**NEVER use these tools/commands on spec JSON:**\n```bash\n Read(/path/to/spec.json)          # Wastes 10,000+ tokens (specs are 50KB+)\n cat specs/active/spec.json        # Bypasses validation and hooks\n head specs/active/spec.json       # Wastes context\n jq '.tasks' spec.json             # Bypasses error handling\n grep \"task-1\" spec.json           # Inefficient, error-prone\n```\n\n**Why:** Spec files are large JSON (machine-readable, not human-readable). Direct reading wastes valuable context tokens and bypasses built-in validation, error handling, and hooks.\n\n### User Interaction Requirements\n\n### Context Gathering Best Practices\n\n**Default workflow (stick to this unless spec says otherwise)**\n1. Run `sdd prepare-task` with no flags. The returned `context` block already includes the previous sibling, parent metadata, phase progress, sibling files, the latest journal summary, and file-focused documentation context (when available via `context.file_docs`).\n2. Only call `sdd task-info`, `sdd get-task`, or `sdd progress` if the spec explicitly asks for extra metadata or you need files that are not exposed in `context`.\n3. After completing the task, re-run `sdd prepare-task` to surface the next recommendation and refreshed context.\n\n**When to use enhancement flags (`extended_context`)**\n- `--include-full-journal`: You need the full journal history for the previous sibling (long-running refactors, nuanced design notes).\n- `--include-phase-history`: You are preparing phase summaries or retrospectives and need every entry tied to the current phase.\n- `--include-spec-overview`: You must report spec-wide progress without running `sdd progress`.\n- Combine flags only when you plan to read the extra dataeach flag increases the JSON payload.\n\n**Decision guide**\n- Need additional detail beyond `context`?\n  - **Yes  Task metadata/files**: `sdd task-info {spec_id} {task_id}` (or `sdd get-task` if the spec mentions nested metadata).\n  - **Yes  Journal history**: Use `--include-full-journal` (previous sibling) or `sdd get-journal` for arbitrary tasks.\n  - **Yes  Phase backlog/alternatives**: `sdd query-tasks --parent {phase_id}` when presenting options to the user.\n  - **No**: Stick with prepare-task output; avoid redundant commands.\n\n**Anti-patterns to avoid**\n- Running `task-info`, `check-deps`, and `get-task` back-to-back \"just in case.\" The default `prepare-task` response now includes all dependency details in `context.dependencies`, eliminating the need for `check-deps` in 95% of cases. Call these commands only when `context` is insufficient for special requirements.\n- Re-running `sdd progress` or `sdd list-phases` after every plan change. Use `context.phase` for quick updates and run `sdd progress` only before reporting global status.\n- Fetching the entire spec or invoking doc-query before inspecting the prepare-task payload.\n\n#### Command Value Matrix\n\n| Command | Returns | Use when | Redundant / Notes |\n| --- | --- | --- | --- |\n| `sdd prepare-task` | Recommended task plus `context` (previous sibling, parent, phase, sibling files, journal summary, dependencies, file_docs) | **Always**  first call for every task | `file_docs` automatically included when doc-query documentation is available |\n| `sdd task-info` | Raw task metadata straight from the spec | Spec explicitly references metadata not surfaced in `context` (acceptance criteria, detailed instructions) | Usually covered by `prepare-task`; only call when spec requires |\n| `sdd get-task` | Full JSON node, including deep metadata blobs | Rare audits where you must inspect the spec data exactly as stored | Redundant with `task-info` for normal flows |\n| `sdd progress` | Spec-wide counts, percentages, current phase | Preparing a status report or verifying completion prompts | `context.phase` already shows local progress; only run when reporting overall stats |\n| `sdd list-phases` | Every phase with completion % | Re-prioritizing phases or presenting alternate scopes to the user | Typically unnecessary after `progress`; use only on request |\n| `sdd get-journal` | Journal entries for any task | Need history beyond summaries (retro write-ups, deep audits) | `--include-full-journal` adds previous sibling history; `get-journal` is for arbitrary tasks |\n\n\n**Gate key decisions with `AskUserQuestion` (MANDATORY):**\n- Spec selection (when multiple available)\n- Task selection (recommended vs alternatives)\n- Plan approval (before implementation)\n- Blocker handling (alternative tasks or resolve)\n- Completion verification (for verify tasks)\n\n**Anti-Pattern:** Never use text-based numbered lists like \"1. Option A, 2. Option B\". Always use `AskUserQuestion` tool for structured choices.\n\n---\n\n##  CRITICAL: Context Checking Pattern\n\n**Before checking context, you MUST generate a session marker first.**\n\nThis is a **two-step process** that must run **sequentially**:\n\n### Step 1: Generate Session Marker (REQUIRED FIRST)\n```bash\nsdd session-marker\n```\n\n### Step 2: Check Context Using the Marker\n```bash\nsdd context --session-marker \"SESSION_MARKER_<hash>\"\n```\n\n**Output Format:**\n```json\n{\"context_percentage_used\": 78}\n```\n\n### CRITICAL REQUIREMENTS\n\n **Run as TWO SEPARATE Bash tool calls** (never combine)\n **Run SEQUENTIALLY, not in parallel** (step 2 depends on step 1 being logged)\n **NEVER combine with && or $()** - The marker must be logged to transcript first\n **NEVER run in parallel** - Step 2 will fail if step 1 hasn't been logged\n\n### Context Thresholds\n\n- **< 85%**: Safe to continue\n- ** 85%**: Stop and recommend to the user that they `/clear` and then `/sdd-begin` for the next task\n\n### CRITICAL: Never Anticipate Context Usage\n\n **ONLY check actual context percentage  NEVER speculate about future consumption:**\n\n DO NOT stop early because:\n  - \"Phase 2 implementation will consume context\"\n  - \"File reading tasks are coming\"\n  - \"I predict I'll hit 85% during the next phase\"\n  - \"I should have buffer space for future work\"\n\n DO ONLY stop when:\n  - Context is CURRENTLY at or above 85%\n  - You have JUST checked context and confirmed actual usage\n\n**Rationale:** Predicting context usage is unreliable and defeats the purpose of checking. The threshold (85%) is designed to give adequate headroom; stopping earlier wastes that safety margin.\n\n### When to Check Context\n\n- **Autonomous mode**: After EVERY task completion (REQUIRED)\n- **Single-task mode**: After task completion (recommended)\n- **Session start**: Before intensive work (optional)\n\n---\n\n## Work Mode Behavior\n\nWhen sdd-next is invoked, it automatically reads the `work_mode` setting from `.claude/sdd_config.json` (see Step 0) and routes to the appropriate workflow:\n\n**Single Task Mode** (`\"work_mode\": \"single\"`) - Default\n- Follows Sections 3.13.6 below\n- Plan and execute one task at a time with explicit user approval\n- After task completion, surface next recommendation and wait for user decision\n- User maintains full control over which tasks to execute and when\n\n**Autonomous Mode** (`\"work_mode\": \"autonomous\"`)\n- Follows dedicated Autonomous Mode section (later in this document)\n- Complete all tasks in current phase automatically within context limits\n- Check context after EVERY task completion (required)\n- Stop only for blockers, plan deviations, or when context 85%\n- Continues until phase is complete or manual intervention needed\n\n---\n\n## Single Task Workflow\n\nUse this workflow when the configured work mode is **Single Task Mode** (`\"work_mode\": \"single\"` in config). Execute one task at a time with explicit user approval for each step.\n\n### 3.1 Choose the Spec\n\n- If user supplies spec id, confirm it exists via `sdd progress {spec-id}`\n- Otherwise list candidates: `sdd find-specs`\n- Apply recommendation heuristic:\n  - Prefer `status: active` with non-zero progress (started but incomplete)\n  - If multiple qualify, pick highest completion % or with `in_progress` tasks\n  - If none have progress, pick most recently touched active spec\n- Surface recommendation explicitly: tag as `(Recommended)` in `AskUserQuestion`\n- Present options via `AskUserQuestion` (include \"Other / provide id\")\n\n### 3.2 Gather High-Level Context\n\n- Use `sdd progress {spec-id}` and `sdd list-phases {spec-id}` for status summary\n- Highlight objectives, blockers, completion percentages\n- Offer additional context commands (`sdd list-blockers`, `sdd render`) only on request\n\n### 3.3 Select the Task\n\n- Ask via `AskUserQuestion`: accept recommended task or browse alternatives?\n- **Recommendation path**: `sdd prepare-task {spec-id}`  surface task id, file, estimates, blockers\n- **Browsing path**: Use `sdd query-tasks {spec-id}` (filter `--parent`, `--status`) + `sdd list-blockers {spec-id}`  present shortlist via `AskUserQuestion`\n\n### 3.4 Deep Dive & Plan Approval\n\nGather every detail with a single call (omit `{task-id}` to accept the recommended task):\n```bash\nsdd prepare-task {spec-id} {task-id}\n```\n\nThat response already contains everything you need:\n- `task_data`  title, metadata, instructions pulled from the spec\n- `dependencies`  top-level blocking status (can_start, blocked_by list)\n- `context`  stitched data from the previous sibling, parent task, current phase, sibling files, task journal, AND detailed dependency information (context.dependencies) with full task titles, statuses, and file paths\n\nTreat `context` as the authoritative source rather than chaining `sdd task-info`, `sdd check-deps`, and `sdd get-task`. Typical fields:\n\n```json\n\"context\": {\n  \"previous_sibling\": {\n    \"task_id\": \"task-3-1-2\",\n    \"title\": \"Tighten plan creation language\",\n    \"summary\": \"Updated scope guardrails for Section 3.3\"\n  },\n  \"parent_task\": {\n    \"task_id\": \"task-3-1\",\n    \"title\": \"Polish the planning workflow\",\n    \"position_label\": \"Phase 3  Task 1\"\n  },\n  \"phase\": {\n    \"name\": \"Implementation\",\n    \"percentage\": 58,\n    \"blockers\": []\n  },\n  \"sibling_files\": [\n    {\"path\": \"skills/sdd-next/SKILL.md\", \"reason\": \"Touched by previous sibling\"}\n  ],\n  \"task_journal\": {\n    \"entry_count\": 0,\n    \"entries\": []\n  },\n  \"dependencies\": {\n    \"blocking\": [],\n    \"blocked_by_details\": [\n      {\n        \"id\": \"task-2-3\",\n        \"title\": \"Update context gathering\",\n        \"status\": \"in_progress\",\n        \"file_path\": \"src/context.py\"\n      }\n    ],\n    \"soft_depends\": []\n  }\n}\n```\n\n- `context.previous_sibling`: reference recent work for continuity or reuse its journal summary when explaining why the new task matters (`context.previous_sibling.title`).\n- `context.parent_task`: verify how this subtask fits into the backlog; use `context.parent_task.position_label` to show progress.\n- `context.phase`: surface phase health (`context.phase.percentage`, `context.phase.blockers`) without calling `sdd progress`.\n- `context.sibling_files`: prime file navigation by reviewing whatever the spec already touched before opening new files.\n- `context.task_journal`: access journal entries for this task showing decision history and status changes without separate calls.\n- `context.dependencies`: detailed dependency information with task titles, statuses, and file paths for `blocking` (tasks this blocks), `blocked_by_details` (tasks blocking this), and `soft_depends` (soft dependencies)eliminates need for separate `sdd check-deps` call in 95% of cases.\n\nOnly fall back to `sdd task-info` or `sdd check-deps` when the spec explicitly calls for metadata that is not surfaced through the standard payload.\n\nDraft the execution plan around the spec intent, dependency gates, and the insights above. Example:\n1. Confirm previous edits in `context.sibling_files` to maintain consistent tone.\n2. Align deliverables with `context.parent_task.title`/`position_label`.\n3. Call out open risks or blockers via `context.phase`.\n4. Reference `context.previous_sibling.summary` if you need to explain how the work continues an earlier change.\n\n**Present plan and get approval via `AskUserQuestion`:**\n- Options: \"Approve & Start\", \"Request Changes\", \"More Details\", \"Defer\"\n- Handle response appropriately\n\nIf recommended task is blocked, pause for guidance or loop back to task selection.\n\n### 3.5 Implementation Handoff\n\n**Before coding:**\n```bash\nsdd update-status {spec-id} {task-id} in_progress --note \"context\"\n```\n\n**During implementation:**\n- Follow execution plan\n- Document any deviations immediately\n\n**Using `sdd doc scope --implement` During Implementation:**\n\nWhen documentation is available and you need detailed implementation context for a file, use:\n```bash\nsdd doc scope <file-path> --implement\n```\n\nThis provides implementation-focused context including:\n- Detailed function signatures and parameters\n- Full implementation logic and patterns\n- Code examples from the actual file\n- Dependencies and imports\n- Usage examples and patterns\n\n**When to use `scope --implement`:**\n- **Starting implementation of a task** - Get comprehensive context before writing code\n- **Understanding existing patterns** - See how current code works before extending it\n- **Refactoring tasks** - Review full implementation details before restructuring\n- **Complex file modifications** - Need deep understanding of current implementation\n- **Following established patterns** - Extract patterns from existing code to maintain consistency\n\n**When NOT to use `scope --implement`:**\n- **During planning phase** - Use `scope --plan` instead (lighter context)\n- **Quick edits or trivial changes** - Direct file reading may be faster\n- **Documentation unavailable** - Fall back to Read tool\n- **Context limits approaching** - Avoid heavy payloads near 85% threshold\n\n**Example workflow:**\n```bash\n# 1. Task started, need implementation context\nsdd doc scope src/services/auth.ts --implement\n\n# 2. Review detailed implementation patterns and signatures\n# (command returns comprehensive implementation context)\n\n# 3. Implement changes following discovered patterns\n# 4. Mark task complete with journal entry\n```\n\n**Optimization tips:**\n- Use `scope --implement` at task start, not repeatedly during coding\n- Cache insights from output rather than re-running\n- Switch to targeted `Read` calls for specific line ranges if context is tight\n\n**After implementation:**\n\nMark task complete using sdd-update subagent (atomically marks complete + creates journal):\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-update-subagent\",\n  prompt: \"Complete task {task-id} in spec {spec-id}. Completion note: [Summary of what was accomplished, tests run, verification performed].\",\n  description: \"Mark task complete\"\n)\n```\n\nJournal content must include:\n- What was accomplished\n- Tests run and results\n- Verification performed\n- Files created/modified\n- Any deviations from plan\n\n### 3.6 Surface Next Recommendation\n\n**Immediately after completion:**\n```bash\nsdd prepare-task {spec-id}\n```\n\n- Summarize next task's scope and blockers\n- Check with user before proceeding\n- If no pending work or spec complete, surface that clearly and confirm next steps\n\n---\n\n##  CRITICAL: Completion Requirements\n\n### When Marking Tasks Complete\n\n**ONLY mark a task as completed when you have FULLY accomplished it.**\n\n### Never Mark Complete If:\n\n Tests are failing\n Implementation is partial\n You encountered unresolved errors\n You couldn't find necessary files or dependencies\n Blockers exist that prevent verification\n\n### If Blocked or Incomplete:\n\n Keep task as `in_progress`\n Create new task describing what needs resolution\n Document blocker using `sdd-update` subagent\n Present alternatives to user via `AskUserQuestion`\n\n### Resolving Blocked Tasks:\n\nWhen a task has been marked as blocked and the blocker is later resolved:\n\n```bash\nsdd unblock-task {spec-id} {task-id} --resolution \"Brief description of how blocker was resolved\"\n```\n\n**Example:**\n```bash\nsdd unblock-task feature-auth-001 task-3-2 --resolution \"API endpoint now available in staging environment\"\n```\n\nThis marks the task as unblocked and ready to proceed. The task will then appear in `sdd prepare-task` recommendations.\n\n### Completion Journal Requirements\n\n**MUST provide journal content** describing:\n- What was accomplished\n- Tests run and results\n- Verification performed\n- Any deviations from plan\n- Files created/modified\n\n**Example:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-update-subagent\",\n  prompt: \"Complete task task-2-3 in spec my-spec-001. Completion note: Implemented JWT auth middleware with PKCE flow. All 12 unit tests passing. Manual verification: login flow works in dev environment. Created src/middleware/auth.ts (180 lines) and tests/middleware/auth.spec.ts (45 tests).\",\n  description: \"Mark task-2-3 complete\"\n)\n```\n\n### 3.7 Journal vs Git History\n\n| Use the Spec Journal When | Use Git History When |\n|----------------------------|------------------------|\n| Closing **any** SDD task (journaling is mandatory and captures intent, verification, and follow-ups). | Investigating merge conflicts, bisects, or broader repo archaeology unrelated to a single spec task. |\n| You need implementation details, test results, deviations, or next-task hints (`journal.entries[]` already hold this context in structured JSON). | You must inspect low-level commit metadata, e.g., to see who touched a file outside the spec workflow. |\n| Preparing status updates: previous sibling journal summaries come bundled in `sdd prepare-task`. | Youre debugging historical code paths predating the current spec. |\n\n**Anti-pattern:** Running `git log` / `git show` to understand a recently completed SDD task when the journal already documents the work. That wastes time and risks contradicting the canonical record. Start with the spec journal; escalate to git history only if a fact is missing or you are diagnosing repo-level issues (rebases, conflicts, regressions).\n\n**Journal advantages**\n- Full implementation narrative (what changed and why) tied to `task_id`.\n- Test and verification results in one place, ready for audits.\n- Deviations, blockers, and next-task hints captured while they are fresh.\n- Structured JSON makes it trivial for `sdd prepare-task` to surface the latest context without extra commands.\n- Archives context even if commits are squashed or rebased later.\n\n---\n\n##  CRITICAL: Verification Tasks\n\n### Detecting Verification Tasks\n\nCheck task metadata for `type: verify` or `verification_type` field:\n\n```bash\nsdd task-info {spec-id} {task-id}\n```\n\n### Dispatch by Verification Type\n\n| verification_type | Action |\n|-------------------|--------|\n| `\"auto\"` | Invoke `sdd-toolkit:run-tests-subagent` |\n| `\"fidelity\"` | Invoke `sdd-toolkit:sdd-fidelity-review-subagent` |\n| `\"manual\"` | Present checklist to user for manual confirmation |\n\n### Automated Tests (`verification_type: \"auto\"`)\n\n```\nTask(\n  subagent_type: \"sdd-toolkit:run-tests-subagent\",\n  prompt: \"Run tests for {task-id} in spec {spec-id}. Execute tests and handle failures.\",\n  description: \"Run tests\"\n)\n```\n\nAfter tests complete:\n1. Present findings to user\n2. Use `AskUserQuestion` to get approval before marking complete\n3. Options: \"Accept & Complete\", \"Fix Failures\", \"Review Details\"\n\n### Fidelity Review (`verification_type: \"fidelity\"`)\n\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-fidelity-review-subagent\",\n  prompt: \"Review {scope} '{target}' in spec {spec-id}. Compare completed tasks against requirements.\",\n  description: \"Fidelity review for {scope}\"\n)\n```\n\nAfter review completes:\n1. Present fidelity report\n2. Use `AskUserQuestion` for decision:\n   - \"Accept & Complete\" - Mark verification complete, journal deviations\n   - \"Revise Implementation\" - Reopen parent tasks for fixes\n   - \"Update Spec\" - Document accepted deviations\n\n### Manual Review (`verification_type: \"manual\"`)\n\nPresent checklist from task metadata to user for confirmation via `AskUserQuestion`.\n\n---\n\n## Post-Implementation Checklist\n\nAfter completing a task:\n\n- [ ] Task status updated (`in_progress`  `completed`) with journal entry\n- [ ] Follow-up commands or monitoring notes captured in journal\n- [ ] Blockers or deviations surfaced to user; next steps agreed\n- [ ] **Context check performed** (two-step pattern above)\n- [ ] Next recommended task retrieved via `sdd prepare-task {spec-id}` and shared with user\n- [ ] Spec context refreshed via `sdd progress {spec-id}` for reporting\n\n---\n\n## Autonomous Mode (Phase Completion)\n\nUse this workflow when the configured work mode is **Autonomous Mode** (`\"work_mode\": \"autonomous\"` in config). If the user changes the config to Single Task Mode mid-session, switch to Section 3 (Single Task Workflow).\n\n### When to Use\n\n- Config file has `\"work_mode\": \"autonomous\"` set\n- User wants to complete multiple tasks in current phase without per-task approval\n- User has sufficient context headroom (check context before starting)\n\n### Key Characteristics\n\n- **Phase-scoped**: Completes all tasks within current phase only (does not cross phase boundaries)\n- **Context-aware**: Checks context after EVERY task, stops if 85%\n- **Defensive stops**: Stops for blocked tasks and plan deviations (requires user approval)\n- **No plan approval**: Creates execution plans internally without showing user\n\n### Autonomous Workflow Loop\n\n#### Step 1: Task Execution Loop\n\nFor each task in current phase:\n\n1. **Prepare next task:**\n   ```bash\n   sdd prepare-task {spec-id}\n   ```\n\n2. **Check phase complete:** If no more tasks in current phase  Exit loop\n\n3. **Check for blockers:**\n   - If next task blocked: **STOP**\n   - Present blocker info via `AskUserQuestion`\n   - Options: alternative tasks, resolve blocker, or stop\n   - Exit autonomous mode\n\n4. **Create execution plan (silently):**\n   - Analyze task metadata from `prepare-task` output\n   - Create detailed internal plan (no user approval needed)\n   - Include all standard components: prerequisites, steps, success criteria\n\n5. **Mark task in_progress:**\n   ```bash\n   sdd update-status {spec-id} {task-id} in_progress\n   ```\n\n6. **Execute implementation** according to internal plan\n\n7. **Handle plan deviations:**\n   - If implementation deviates: **STOP**\n   - Document deviation\n   - Present to user via `AskUserQuestion`\n   - Options: revise plan, update spec, explain more, rollback\n   - Exit autonomous mode\n\n8. **Mark task complete:**\n   ```\n   Task(\n     subagent_type: \"sdd-toolkit:sdd-update-subagent\",\n     prompt: \"Complete task {task-id} in spec {spec-id}. Completion note: [Brief summary of what was accomplished, tests run, verification performed].\",\n     description: \"Mark task complete\"\n   )\n   ```\n\n9. ** CRITICAL: Check context usage (REQUIRED):**\n\n   Run two-step pattern as SEPARATE, SEQUENTIAL Bash calls:\n   ```bash\n   # First call:\n   sdd session-marker\n   ```\n   ```bash\n   # Second call (only after first completes):\n   sdd context --session-marker \"SESSION_MARKER_<hash>\"\n   ```\n\n   **Check ACTUAL context percentage reported, do NOT speculate:**\n   - If context ACTUALLY 85% (as reported by command): **STOP**, exit loop, go to Summary\n   - If context <85%: Continue to next iteration\n\n   **CRITICAL:** Do not stop based on predictions like \"upcoming work will use context\" or \"I should have buffer space for the next phase.\" Only stop when actual usage reaches the threshold. The 85% threshold already provides safety margin.\n\n10. **Check phase completion:**\n    - If current phase complete: Exit loop, go to Summary\n    - Otherwise: Return to step 1\n\n#### Step 2: Present Summary Report\n\nWhen autonomous mode exits:\n\n```markdown\n## Autonomous Execution Summary\n\n**Mode:** Phase Completion (Autonomous)\n**Spec:** {spec-title} ({spec-id})\n**Phase:** {phase-title} ({phase-id})\n\n### Tasks Completed\n task-1-1: [title] - Duration: X min\n task-1-2: [title] - Duration: Y min\n\n### Phase Progress\nPhase {phase-id}: {completed}/{total} tasks ({percentage}%)\nOverall: {total_completed}/{total_tasks} tasks ({overall_percentage}%)\n\n### Context Usage\nCurrent context: {context_percentage}%\n\n### Exit Reason\n{One of:}\n-  Phase Complete\n-  Context Limit: 85% threshold\n-  Blocked Task\n-  Plan Deviation\n-  No Actionable Tasks\n\n### Next Steps\n{Contextual recommendations based on exit reason}\n```\n\n### Autonomous Mode Best Practices\n\n**DO:**\n-  Check context after EVERY task completion\n-  Stop immediately when context 85%\n-  Base stopping decisions on ACTUAL context percentage, never predictions\n-  Use the full safety margin (continue until 85% reported)\n-  Stop for blocked tasks (don't auto-pivot)\n-  Stop for plan deviations (don't auto-revise)\n-  Create detailed internal plans\n-  Present comprehensive summary at end\n\n**DON'T:**\n-  Cross phase boundaries\n-  Skip plan creation (always plan, just don't show)\n-  Continue past 85% context\n-  Stop early based on predictions of future context usage\n-  Auto-resolve blockers\n-  Auto-revise plans on deviations\n-  Batch task completions\n\n---\n\n## Phase Loop with Human Checkpoints\n\n### Scope Confirmation\n\nShow `sdd list-phases {spec-id}` with progress. Ask via `AskUserQuestion`:\n- Focus on target phase\n- Adjust scope\n- Revert to single-task mode\n\n### Queue Preparation\n\nPrime backlog:\n```bash\nsdd query-tasks {spec-id} --parent {phase-id} --status pending\n```\n\nIf queue empty or blocked:\n```bash\nsdd list-blockers {spec-id}\n```\nPause for user direction.\n\n### Task Loop\n\nReuse Single Task Workflow (steps 3.33.6) for each pending task.\n\nAfter each completion:\n- Refresh phase: `sdd check-complete {spec-id} --phase {phase-id}`\n- If granted \"auto-continue for this phase\", note permission but still report blockers immediately\n\n### Phase Wrap-Up\n\nSummarize results:\n```bash\nsdd progress {spec-id}\nsdd query-tasks {spec-id} --parent {phase-id}\n```\n\nPresent accomplishments, verification outcomes, blockers.\n\nAsk via `AskUserQuestion`: continue to next phase, perform phase review, or stop.\n\n---\n\n## Troubleshooting\n\n### Spec File Not Found / Path Errors\n\n**Cause:** Wrong working directory or relative paths\n\n**Solution:**\n- Provide absolute path: `sdd prepare-task {spec-id} --path /absolute/path/to/specs`\n- Run `sdd find-specs` to discover available specs\n\n### All Tasks Blocked\n\n**Diagnosis:**\n```bash\nsdd list-blockers {spec-id}\nsdd check-complete {spec-id}\n```\n\n**Solution:** Present alternatives via `AskUserQuestion` or resolve blockers before continuing\n\n---\n\n## Quick Reference\n\n### Core Commands\n\n```bash\n# Discovery\nsdd find-specs\nsdd progress {spec-id}\nsdd list-phases {spec-id}\n\n# Task Selection\nsdd prepare-task {spec-id}              # Primary command - includes all context\nsdd next-task {spec-id}                 # Simpler alternative - just task ID\nsdd task-info {spec-id} {task-id}       # Rarely needed - only for non-recommended tasks\nsdd check-deps {spec-id} {task-id}      # Rarely needed - now in context.dependencies\n\n# Context Checking (TWO STEPS)\nsdd session-marker\nsdd context --session-marker \"SESSION_MARKER_<hash>\"\n\n# Advanced\nsdd query-tasks {spec-id} --status pending --parent {phase-id}\nsdd list-blockers {spec-id}\nsdd unblock-task {spec-id} {task-id} [--resolution \"reason\"]\nsdd check-complete {spec-id} --phase {phase-id}\n```\n\n### Critical Patterns Summary\n\n| Pattern | Requirement |\n|---------|-------------|\n| **Spec reading** | Always use `sdd` commands, NEVER `Read()` or `cat` on JSON |\n| **Context checking** | Two-step sequential (marker  context), never combined |\n| **Task completion** | Never mark complete if tests failing/partial/errors |\n| **Autonomous mode** | Check context after EVERY task, stop at 85% |\n| **Verification** | Dispatch to appropriate subagent by `verification_type` |\n| **User decisions** | Always use `AskUserQuestion`, never text lists |"
              },
              {
                "name": "sdd-plan-review",
                "description": "Multi-model consultation for SDD specifications providing structured feedback. Coordinates parallel AI reviewers, synthesizes actionable insights, and categorizes findings by feedback type without modifying specs or executing fixes.",
                "path": "skills/sdd-plan-review/SKILL.md",
                "frontmatter": {
                  "name": "sdd-plan-review",
                  "description": "Multi-model consultation for SDD specifications providing structured feedback. Coordinates parallel AI reviewers, synthesizes actionable insights, and categorizes findings by feedback type without modifying specs or executing fixes."
                },
                "content": "# Spec-Driven Development: Plan Review Skill\n\n## Overview\n\n`Skill(sdd-toolkit:sdd-plan-review)` is the multi-perspective feedback stage for Spec-Driven Development. It convenes multiple AI reviewers to provide structured, actionable feedback across key dimensions before any implementation begins.\n\n- Builds shared understanding of spec strengths, risks, and improvement opportunities\n- Produces categorized feedback organized by type (Missing Information, Design Concerns, Risk Flags, etc.)\n- Synthesizes reviewer perspectives into clear, prioritized insights\n- Recommends handoffs to the correct downstream skills instead of applying changes directly\n\nThis stage is advisory-only. The output is a structured feedback report and clear guidance on where follow-up work belongs.\n\n## Scope & Responsibilities\n\n**This skill delivers:**\n- Multi-model feedback on draft specs across architecture, feasibility, risk, and verification\n- Categorized feedback organized by type (Missing Information, Design Concerns, Risk Flags, Enhancement Suggestions, etc.)\n- Consolidated findings that highlight reviewer consensus and diverse perspectives\n- Advisory recommendations on which downstream skill should address each finding\n- Structured reports (Markdown and JSON) that capture review context for the broader workflow\n\n**This skill does not:**\n- Edit specifications or apply fixes\n- Update spec metadata, journals, or approval status\n- Make approval/rejection decisions (provides feedback only)\n\n## Position in the SDD Workflow\n\n```\nPLAN  PLAN-REVIEW (consult)  UPDATE/NEXT/VALIDATE\n```\n\n- **Entry point:** A draft spec exists and needs multi-perspective feedback.\n- **Core activity:** `sdd-plan-review` convenes multiple AI reviewers and synthesizes structured, actionable feedback.\n\n**Role of this skill:** Provide diverse perspectives and categorized feedback before implementation starts. It informs, but never performs, follow-up edits.\n\n## Scope Boundaries\n\n-  **Do:** Convene multi-model reviews, interrogate assumptions, aggregate perspectives, and categorize feedback by type (Missing Information, Design Concerns, Risk Flags, etc.).\n-  **Do:** Capture review metadata, feedback categories, and rationale in the generated report so downstream skills have clear guidance.\n-  **Don't:** Edit specs, adjust estimates, rewrite acceptance criteria, or change task hierarchies.\n-  **Don't:** Update journals, statuses, or frontmatter.\n-  **Don't:** Author execution plans or task breakdowns.\n\n##  Long-Running Operations\n\n**This skill may run operations that take up to 5 minutes. Be patient and wait for completion.**\n\n### CRITICAL: Avoid BashOutput Spam\n- **ALWAYS use foreground execution with 5-minute timeout:** `Bash(command=\"...\", timeout=300000)`\n- **WAIT for the command to complete** - this may take the full 5 minutes\n- **NEVER use `run_in_background=True` for test suites, builds, or analysis**\n- If you must use background (rare), **wait at least 60 seconds** between BashOutput checks\n- **Maximum 3 BashOutput calls per background process** - then kill it or let it finish\n\n### Why?\nPolling BashOutput repeatedly creates spam and degrades user experience. Long operations should run in foreground with appropriate timeout, not in background with frequent polling.\n\n### Example (CORRECT):\n```\n# Test suite that might take 5 minutes (timeout in milliseconds)\nresult = Bash(command=\"pytest src/\", timeout=300000)  # Wait up to 5 minutes\n# The command will block here until completion - this is correct behavior\n```\n\n### Example (WRONG):\n```\n# Don't use background + polling\nbash_id = Bash(command=\"pytest\", run_in_background=True)\noutput = BashOutput(bash_id)  # Creates spam!\n```\n\n## Core Philosophy\n\n**Diverse Perspectives Improve Quality**: Multiple AI models reviewing a specification catch more issues and provide richer insights than a single review. By consulting different AI CLIs (gemini, codex, cursor-agent) in parallel, we validate design decisions, identify risks, and surface improvement opportunities before costly implementation.\n\n**Feedback, Not Gatekeeping**: This skill provides structured, actionable feedback to inform decision-making, not approval/rejection gatekeeping. The output helps spec authors understand strengths, risks, and opportunities from multiple perspectives.\n\n**Key Benefits:**\n- Surfaces specification gaps and improvement opportunities before coding begins\n- Validates architecture from multiple expert angles\n- Identifies hidden risks and edge cases\n- Evaluates implementation feasibility realistically\n- Provides diverse perspectives on complex decisions\n- Generates categorized, actionable feedback\n- Reduces expensive rework and technical debt\n\n## When to Use This Skill\n\nRequest `Skill(sdd-toolkit:sdd-plan-review)` when you need multi-perspective feedback on a draft specification:\n- New or revised specs that benefit from diverse expert perspectives\n- High-risk, high-effort, or multi-team initiatives where blind spots are expensive\n- Novel architectures, emerging technologies, or unfamiliar integrations\n- Security-sensitive surfaces (auth, PII, critical data flows) that need scrutiny\n- Aggressive timelines or estimates that need feasibility validation\n\n**Do NOT request this skill when:**\n- The spec is trivial, low-risk, or already well-understood (<5 tasks, standard patterns)\n- Implementation is already underway\n- You need someone to make direct specification edits\n- The work is exploratory, disposable, or prototype-only\n\n**Reminder:** This skill provides structured feedbackdecisions about addressing findings flow through the calling agent.\n\n## Decision Guide: Should We Convene a Review?\n\n```\nSituation?\n Draft spec ready for approval  Engage plan-review (full)\n Security-critical area (auth/data/privacy)  Engage plan-review (security)\n Feasibility questions or aggressive estimates  Engage plan-review (feasibility)\n Major architectural novelty or integration risk  Engage plan-review (full)\n Lightweight, low-risk spec  Skip; proceed directly to sdd-next\n Work already executing  Use fidelity-review or update workflows instead\n Unsure confidence level  Engage plan-review (quick) to gain signal\n\nAfter the consultation:\n Return to calling agent for next steps\n```\n\n## Tool Verification\n\n**Before using this skill**, verify the required tools are available:\n\n```bash\nsdd list-review-tools\n```\n\n**IMPORTANT - CLI Usage Only**:\n-  **DO**: Use `sdd review` CLI wrapper commands (e.g., `sdd review`, `sdd list-review-tools`)\n-  **DO NOT**: Execute Python scripts directly or call AI CLIs directly (e.g., `python sdd_review.py`, `bash gemini ...`, `codex ...`)\n\nThe CLI provides proper error handling, validation, argument parsing, and interface consistency. It orchestrates AI CLI calls automatically. Direct script or AI CLI execution bypasses these safeguards and may fail.\n\nIf the verification command fails, ensure the SDD toolkit is properly installed and accessible in your environment.\n\n## Quick Start\n\n### Check Available Tools\n\n```bash\n# List which AI CLI tools are installed\nsdd list-review-tools\n\n# Expected output:\n#  Available (2):\n#   gemini\n#   codex\n#  Not Available (1):\n#   cursor-agent\n```\n\n### Basic Review\n\n```bash\n# Review a spec with automatic tool detection\nsdd review user-auth-001\n\n# Review with specific type\nsdd review user-auth-001 --type full\n\n# Quick review (fast, basic checks only)\nsdd review user-auth-001 --type quick\n\n# Security-focused review\nsdd review user-auth-001 --type security\n\n# Feasibility check (estimates, dependencies)\nsdd review user-auth-001 --type feasibility\n```\n\n## Quick Reference: Common Commands\n\n| Command | Purpose | Typical Duration |\n|---------|---------|------------------|\n| `sdd list-review-tools` | Check which AI CLIs are installed | Instant |\n| `sdd review <spec> --type quick` | Fast completeness check | 10-15 min |\n| `sdd review <spec> --type full` | Comprehensive analysis | 20-30 min |\n| `sdd review <spec> --type security` | Security vulnerability scan | 15-20 min |\n| `sdd review <spec> --type feasibility` | Estimate & dependency validation | 10-15 min |\n\n## Typical Workflow\n\n1. **Request the consultation**\n   ```bash\n   sdd review myspec --type full\n   ```\n   - Confirm the correct review type and tools, run once per major draft.\n\n2. **Interpret the feedback report**\n   - Review categorized findings organized by feedback type\n   - Note reviewer consensus and diverse perspectives\n   - Identify priority findings that need addressing\n\n3. **Prepare the advisory handoff**\n   - Summarize key findings and improvement opportunities\n   - Prioritize feedback by category and severity\n   - Recommend downstream actions based on findings\n\n## Outputs\n\n- **Feedback report (Markdown):** Automatically saved to `specs/.reviews/<spec-id>-review-<type>.md` and printed to stdout; captures categorized findings, reviewer perspectives, and recommended handoffs.\n- **JSON summary:** Automatically saved alongside the Markdown as `specs/.reviews/<spec-id>-review-<type>.json`; includes feedback categories, participating tools, and issue catalog for orchestration.\n- **Exit codes for automation:**\n  - `0`: Review completed successfully with feedback\n  - `1`: Review failed (configuration, tool errors)\n  - `2`: Critical feedback items found (for CI/CD integration)\n\n## Feedback Categories\n\nReview findings are organized into structured categories to make feedback actionable:\n\n### Missing Information\nIdentifies gaps where the spec needs more detail for successful implementation.\n\n**Examples:**\n- \"Task 2.3 lacks acceptance criteria - unclear when task is complete\"\n- \"Authentication flow missing error handling details\"\n- \"Database migration steps not specified in Phase 3\"\n- \"No rollback strategy defined for deployment tasks\"\n\n### Design Concerns\nHighlights architectural or design choices that may need reconsideration.\n\n**Examples:**\n- \"Tight coupling between auth module and user service may hinder testing\"\n- \"Synchronous API calls in task 1.4 could create bottlenecks under load\"\n- \"Consider event-driven pattern instead of polling for real-time updates\"\n- \"Circular dependency between modules A and B needs resolution\"\n\n### Risk Flags\nSurfaces potential security, performance, or reliability risks.\n\n**Examples:**\n- \"Admin endpoints lack authentication checks (security risk)\"\n- \"No rate limiting on public API (DoS vulnerability)\"\n- \"Storing passwords in plaintext violates security best practices\"\n- \"Missing input validation could allow SQL injection\"\n- \"No monitoring for critical payment processing flow\"\n\n### Feasibility Questions\nRaises concerns about estimates, dependencies, or implementation approach.\n\n**Examples:**\n- \"Task 3.2 estimated at 2 hours but involves complex OAuth integration (likely 6-8 hours)\"\n- \"Phase 2 assumes legacy API has endpoint X - need to verify availability\"\n- \"Database migration in task 4.1 requires DBA access - confirm permissions\"\n- \"Timeline assumes 3 developers but team currently has 2\"\n\n### Enhancement Suggestions\nProposes improvements that aren't critical but would strengthen the spec.\n\n**Examples:**\n- \"Consider adding health check endpoints for monitoring\"\n- \"Could benefit from batch processing for large datasets\"\n- \"Adding retry logic would improve resilience\"\n- \"Documentation task for API endpoints would help future maintenance\"\n\n### Clarification Requests\nIdentifies ambiguous language or unclear requirements.\n\n**Examples:**\n- \"What does 'performant' mean in acceptance criteria? Need specific metrics\"\n- \"Task 2.1 says 'update user profile' - which fields are in scope?\"\n- \"'Handle errors gracefully' is vague - specify retry strategy, logging, user messaging\"\n- \"Does 'mobile support' include tablets or just phones?\"\n\n## Review Types\n\n### Overview Table\n\n| Type | Models | Duration | Dimensions Emphasized | Use When |\n|------|--------|----------|----------------------|----------|\n| **quick** | 2 | 10-15 min | Completeness, Clarity | Simple specs, time-constrained, low-risk changes |\n| **full** | 3-4 | 20-30 min | All 6 dimensions | Complex specs, moderate-to-high risk, novel architecture |\n| **security** | 2-3 | 15-20 min | Risk Management | Auth/authz, data handling, API security, compliance |\n| **feasibility** | 2-3 | 10-15 min | Feasibility | Tight deadlines, resource constraints, uncertain scope |\n\n### Quick Review\n\n**Focus**: Basic completeness and clarity\n**Models**: 2 tools (diverse perspectives)\n**Best For**: Simple specs, low-risk changes, time pressure\n\n**What it checks:**\n- All required sections present\n- Tasks clearly described with acceptance criteria\n- Dependencies explicitly stated\n- Basic verification steps exist\n- No obvious gaps or ambiguities\n\n**Skip detailed analysis of:**\n- Architecture soundness\n- Performance implications\n- Security edge cases\n- Implementation complexity\n\n### Full Review\n\n**Focus**: Comprehensive analysis across all dimensions\n**Models**: 3-4 tools (architecture, security, implementation, integration perspectives)\n**Best For**: Complex specs, moderate-to-high risk, cross-team changes, novel patterns\n\n**What it checks:**\n- **Completeness**: All sections present, sufficient detail, no gaps\n- **Clarity**: Clear descriptions, acceptance criteria, unambiguous language\n- **Feasibility**: Realistic estimates, achievable dependencies, proper sizing\n- **Architecture**: Sound design, proper abstractions, scalability, maintainability\n- **Risk Management**: Risks identified, edge cases covered, failure modes handled\n- **Verification**: Comprehensive testing plan, verification steps, quality gates\n\n**Most thorough review type** - use when cost of failure is high.\n\n### Security Review\n\n**Focus**: Security vulnerabilities and risks\n**Models**: 2-3 tools (offensive, defensive, compliance perspectives)\n**Best For**: Auth/authz, data handling, API security, regulated domains, PII/PHI\n\n**What it checks:**\n- Authentication and authorization design\n- Input validation and sanitization\n- Secrets management (API keys, passwords, tokens)\n- Access control and principle of least privilege\n- Audit logging and monitoring\n- Data encryption (at rest, in transit)\n- SQL/command injection prevention\n- CSRF/XSS protections\n- Rate limiting and DoS protection\n- Compliance requirements (GDPR, HIPAA, SOC2)\n\n**Emphasizes risk_management dimension** in scoring.\n\n### Feasibility Review\n\n**Focus**: Implementation realism and estimate accuracy\n**Models**: 2-3 tools (optimist, realist, pessimist perspectives)\n**Best For**: Tight deadlines, resource constraints, uncertain requirements, large efforts\n\n**What it checks:**\n- Time estimates realistic for each task\n- Required skills present in team\n- Dependencies actually exist and are accessible\n- External APIs/services available and documented\n- Performance requirements achievable with approach\n- Complexity accurately assessed (not underestimated)\n- Blockers identified and mitigated\n- Resource requirements feasible (compute, storage, budget)\n\n**Identifies underestimated tasks** and impossible requirements.\n\n## Review Dimensions\n\nEvery review examines specs across **6 dimensions** to structure feedback:\n\n1. **Completeness**\n   - All sections present\n   - Sufficient detail for implementation\n   - No missing requirements or undefined dependencies\n   - Acceptance criteria for all tasks\n\n2. **Clarity**\n   - Clear, unambiguous descriptions\n   - Specific acceptance criteria\n   - Well-defined task boundaries\n   - No vague or confusing language\n\n3. **Feasibility**\n   - Realistic time estimates\n   - Achievable dependencies\n   - Required skills available\n   - No impossible requirements\n\n4. **Architecture**\n   - Sound design decisions\n   - Proper abstractions\n   - Scalability considerations\n   - Low coupling, high cohesion\n\n5. **Risk Management**\n   - Risks identified\n   - Edge cases covered\n   - Failure modes addressed\n   - Mitigation strategies present\n\n6. **Verification**\n   - Comprehensive test plan\n   - Verification steps defined\n   - Quality gates established\n   - Testing gaps identified\n\nThese dimensions help organize feedback into actionable categories. Reviewers provide specific findings and suggestions within each dimension rather than numerical scores.\n\n## The Review Workflow\n\n### Phase 1: Preparation\n\n**Before running review, ensure:**\n\n1. **Check tool availability**\n   ```bash\n   sdd list-review-tools\n   ```\n   - Need at least 1 tool installed\n   - 2+ tools recommended for multi-model review\n   - All 3 tools ideal for comprehensive analysis\n\n2. **Load specification**\n   - Spec must be complete (not draft fragments)\n   - JSON format required\n   - Frontmatter should include complexity/risk metadata\n\n3. **Select review type**\n   - Auto-selected based on spec metadata\n   - Or explicitly specify with `--type` flag\n   - See Decision Tree above for guidance\n\n**The tool automatically:**\n- Detects which AI CLI tools are available\n- Parses spec frontmatter and content\n- Determines appropriate review scope\n- Selects models based on review type\n\n### Phase 2: Execute Review\n\n**Multi-model consultation (parallel execution):**\n\n```bash\nsdd review user-auth-001 --type full\n```\n\n**What happens:**\n1. **Initiate each model review** with enforced critical framing\n2. **Call all AI CLI tools simultaneously** (ThreadPoolExecutor)\n3. **Collect responses** as they complete (timeouts: 60-120s per tool)\n4. **Handle failures gracefully** (continue with successful responses)\n5. **Parse responses** (JSON extraction with fallback strategies)\n\n**Progress indicators:**\n```\nReviewing specification: user-auth-001.json\nUsing 3 tool(s): gemini, codex, cursor-agent\n\nStarting full review...\n gemini completed (15.2s)\n codex completed (22.5s)\n cursor-agent timeout (120s)\n\nReview Complete\nExecution time: 120.1s\nModels responded: 2/3\n```\n\n**Automatic error handling:**\n- Timeouts  Automatic retries with backoff\n- Rate limits  Sequential mode fallback\n- Auth failures  Skip tool with clear message\n- Parse failures  Use other model responses\n\n### Phase 3: Interpret Results\n\n**Understanding the report:**\n\n**Feedback Organization:**\nThe report groups findings by category (Missing Information, Design Concerns, Risk Flags, Feasibility Questions, Enhancement Suggestions, Clarification Requests) to make them actionable.\n\n**Reviewer Consensus:**\n- **Strong consensus**: Multiple reviewers identified the same issue\n- **Diverse perspectives**: Different reviewers raised different concerns\n- **Conflicting views**: Reviewers disagree (both perspectives documented)\n\n**Priority Levels:**\n- **CRITICAL**: Security vulnerabilities, blockers, data loss risks  **Address immediately**\n- **HIGH**: Design flaws, missing information, quality issues  **Address before implementation**\n- **MEDIUM**: Improvements, unclear requirements  **Consider addressing**\n- **LOW**: Nice-to-have enhancements  **Note for future**\n\n**Example findings:**\n```\n Feedback Summary:\n\n### Risk Flags (CRITICAL)\n1. Missing authentication on admin endpoints\n   Priority: CRITICAL | Flagged by: gemini, codex\n   Impact: Unauthorized access to sensitive operations\n   Recommendation: Add JWT validation middleware to routes\n\n### Feasibility Questions (HIGH)\n2. Time estimates may be unrealistic for Phase 2\n   Priority: HIGH | Flagged by: codex\n   Impact: Timeline risk - complex OAuth integration underestimated\n   Recommendation: Revisit estimates for tasks 2.3-2.5 (suggest +50%)\n\n### Missing Information (MEDIUM)\n3. Error handling strategy not defined\n   Priority: MEDIUM | Flagged by: gemini\n   Impact: Unclear how failures should be handled\n   Recommendation: Add error handling details to affected tasks\n```\n\n### Phase 4: Synthesize Findings & Recommend Handoffs\n\n1. **Organize feedback by category and priority**\n   - Group findings by category (Missing Information, Design Concerns, Risk Flags, etc.)\n   - Prioritize within each category by CRITICAL / HIGH / MEDIUM / LOW\n   - Note reviewer consensus and diverse perspectives\n\n2. **Identify the type of downstream work**\n   - Structural or architectural redesign\n   - Documentation, metadata, or acceptance criteria updates\n   - Additional planning or investigation needed\n   - Additional audits (security review, validation)\n\n3. **Capture the feedback summary**\n   - Highlight key findings and improvement opportunities\n   - Note areas of consensus and areas where reviewers disagree\n   - Return the path to the JSON report for full context\n\n## Advanced Topics\n\n### Error Handling\n\n**Automatic recovery:**\n\n| Error Type | Tool Behavior | User Impact |\n|------------|---------------|-------------|\n| **Timeout** (>120s) | Retry with backoff (2 attempts) | Longer wait, usually succeeds |\n| **Rate limit** (HTTP 429) | Wait + retry, or sequential mode | Slower execution |\n| **Auth failure** (401/403) | Skip tool, continue with others | Reduced confidence |\n| **Network error** | Retry 2x with backoff | Usually recovers |\n| **Parse failure** | Use other model responses | No impact if 2 models succeed |\n\n**Partial results:**\n\n| Scenario | Outcome | Confidence |\n|----------|---------|------------|\n| 3/3 tools succeed | Full review | High |\n| 2/3 tools succeed | Continue with 2 | Medium (noted in report) |\n| 1/3 tools succeed | Continue with 1 | Low (single-model warning) |\n| 0/3 tools succeed | Review fails | Error with troubleshooting |\n\n## Best Practices\n\n### When to Review\n\n**Always review:**\n- High-risk or high-priority specs\n- Security-sensitive implementations (auth, data, payments)\n- Novel architecture or technology choices\n- Before final approval and team commitment\n\n**Consider reviewing:**\n- Medium complexity ( 10 tasks)\n- Cross-team dependencies\n- Specs with aggressive timelines\n- Unclear or novel requirements\n\n**Skip review:**\n- Simple specs (< 5 tasks)\n- Well-understood patterns (CRUD operations)\n- Low-risk internal refactorings\n- Trivial bug fixes\n\n### Review Quality Tips\n\n**For best results:**\n\n1. **Review complete specs, not fragments**\n   - All phases defined\n   - Tasks described\n   - Dependencies stated\n   - Verification steps present\n\n2. **Use appropriate review type**\n   - Quick: Simple, low-risk\n   - Full: Complex, moderate-to-high risk\n   - Security: Auth/data handling\n   - Feasibility: Tight timelines\n\n3. **Address issues by priority**\n   - CRITICAL  Must fix before proceeding\n   - HIGH  Should fix, significant impact\n   - MEDIUM  Consider, nice-to-have\n   - LOW  Note for future improvements\n\n4. **Don't blindly accept all feedback**\n   - Consider context and tradeoffs\n   - Models may misunderstand requirements\n   - Use judgment on disagreements\n   - Recommend when issues might be deferred\n\n### Coordinating Follow-Up Work\n\n**Prioritization guide for addressing feedback:**\n\n```\nCRITICAL findings:\n  - Security vulnerabilities\n  - Blocking dependencies\n  - Data loss risks\n  - Compliance violations\n   Address immediately before implementation\n\nHIGH findings:\n  - Design flaws\n  - Missing information\n  - Unrealistic estimates\n  - Quality concerns\n   Address before implementation begins\n\nMEDIUM findings:\n  - Unclear requirements\n  - Missing optimizations\n  - Incomplete documentation\n   Consider addressing; may defer with rationale\n\nLOW findings:\n  - Nice-to-have improvements\n  - Edge case enhancements\n  - Future considerations\n   Note for future work; safe to defer\n```\n\n**Balance perspectives:**\n\nWhen models disagree:\n1. Review each perspective and note context differences.\n2. Identify root causes or assumptions driving the disagreement.\n\nRemember to include the JSON file path at the end of your report back."
              },
              {
                "name": "sdd-plan",
                "description": "Plan-first development methodology that creates detailed specifications before coding. Use when building features, refactoring code, or implementing complex changes. Creates structured plans with phases, file-level details, and verification steps to prevent drift and ensure production-ready code.",
                "path": "skills/sdd-plan/SKILL.md",
                "frontmatter": {
                  "name": "sdd-plan",
                  "description": "Plan-first development methodology that creates detailed specifications before coding. Use when building features, refactoring code, or implementing complex changes. Creates structured plans with phases, file-level details, and verification steps to prevent drift and ensure production-ready code."
                },
                "content": "## Core Philosophy\n\n**Plan First, Code Second**: Every development task begins with a detailed specification that acts as a contract between intent and implementation. This prevents the common failure mode where AI \"works once and then falls apart\" in real codebases.\n\n**Staged Planning (Recommended)**: For complex features, create specifications in two stages: (1) high-level phase structure for user review and approval, then (2) detailed task breakdown. This reduces wasted effort and enables early course correction before detailed planning begins.\n\n**Atomic Tasks**: Each task represents a single, focused change to one file. Tasks are the fundamental unit of work in SDD, and keeping them atomic provides:\n- **Precise dependency tracking**: File-level dependencies are explicit and clear\n- **Granular progress monitoring**: Each completed task represents concrete, verifiable progress\n- **Parallel implementation**: Independent tasks can be worked on simultaneously\n- **Straightforward verification**: Each task has a focused scope and clear success criteria\n- **Easy rollback**: Changes can be reverted at the file level without affecting other work\n\nWhen a feature requires changes across multiple files, decompose it into multiple tasks with proper dependencies, or use subtasks to organize related file changes under a parent task. Never bundle multiple file changes into a single task. Always practice atomic task decomposition and verification.\n\n**Key Benefits:**\n- Reduces hallucinated APIs and misread intent\n- Prevents breaking existing functionality\n- Provides clear verification criteria\n- Enables confident iteration\n- Creates auditable development process\n- Early feedback checkpoint reduces rework (staged approach)\n\n## When to Use This Skill\n\nUse `Skill(sdd-toolkit:sdd-plan)` (this skill) for:\n- New features or significant functionality additions\n- Complex refactoring across multiple files\n- API integrations or external service connections\n- Architecture changes or system redesigns\n- Any task where precision and reliability are critical\n- Large codebases where context drift is a risk\n\n**Do NOT use for:**\n- Simple one-file changes or bug fixes\n- Trivial modifications or formatting changes\n- Exploratory prototyping or spikes\n- Quick experiments or proof-of-concepts\n- Updating existing specs (use Skill(sdd-toolkit:sdd-update))\n- Finding what to work on next (use Skill(sdd-toolkit:sdd-next))\n- Tracking task progress (use Skill(sdd-toolkit:sdd-update))\n\n## The Spec-Driven Development Process\n\n### Phase 1: Specification Creation\n\nCreate a detailed specification document before writing any code.\n\nStart by reading the JSON schema for the JSON you will be generating:\nRun `sdd schema` to get the complete spec schema JSON.\n\nThis will tell you what fields are required and optional in the specification, and what data types are expected for each field.\n\n#### 1.0 High-Level Phase Planning Stage (Recommended First Step)\n\n**Purpose**: Before diving into detailed task planning, create a high-level phase structure for user review and approval. This staged approach reduces wasted effort and enables early course correction.\n\n**When to Use Staged Planning:**\n- Complex features requiring multiple phases (3+ phases expected)\n- Projects where requirements might need adjustment\n- Situations where you want early stakeholder feedback\n- Large refactorings affecting many files\n\n**When to Skip to Full Planning:**\n- Simple, well-understood tasks (1-2 phases max)\n- Urgent changes where speed is critical\n- When you're highly confident in the approach\n\n**Staged Planning Workflow:**\n\n1. **Generate Phase-Only Plan** (Markdown format for easy review)\n2. **User Review & Approval Checkpoint**\n3. **Generate Detailed Tasks** (Complete JSON spec)\n\n##### 1.0.1 Creating the Phase-Only Plan\n\nGenerate a concise markdown document outlining just the high-level phases. **Do not create detailed tasks yet.**\n\n**Phase-Only Markdown Template:**\n\n```markdown\n# High-Level Plan: [Feature/Change Name]\n\n## Overview\nBrief description of what this change accomplishes and why.\n\n## Objectives\n- Primary objective\n- Secondary objectives\n- Success criteria\n\n## Proposed Phases\n\n### Phase 1: [Phase Name]\n**Purpose**: What this phase accomplishes\n**Dependencies**: What must exist before starting\n**Risk Level**: Low/Medium/High\n**Key Deliverables**:\n- Deliverable 1\n- Deliverable 2\n\n**Estimated Files Affected**: 3-5 files\n**Estimated Complexity**: Low/Medium/High\n\n### Phase 2: [Phase Name]\n[Repeat structure for each phase]\n\n### Phase N: [Phase Name]\n[Repeat structure for each phase]\n\n## Implementation Order\n1. Phase X (must complete first)\n2. Phase Y (depends on X)\n3. Phase Z (can run parallel to Y)\n\n## Key Integration Points\n- How phases connect to each other\n- Critical dependencies between phases\n- Potential breaking points or risks\n\n## Questions for Review\n- Any specific concerns about this approach?\n- Are there phases missing or phases that should be combined?\n- Does the order make sense?\n```\n\n**Guidelines for Phase Planning:**\n- **Be concise**: Each phase description should be 3-5 sentences max\n- **Focus on \"what\" not \"how\"**: Save implementation details for later\n- **Identify dependencies**: Make phase ordering clear\n- **Highlight risks**: Call out high-risk phases early\n- **Estimate scope**: Rough file counts help set expectations\n- **Ask questions**: Invite feedback on unclear areas\n\n##### 1.0.2 User Review & Approval Checkpoint\n\n**Present the phase-only plan to the user and explicitly request approval before proceeding.**\n\n**Example Interaction Pattern:**\n\n```\nAI: \"Let me first propose the high-level phase structure for this feature.\n    This will help us ensure we're on the right track before diving into\n    detailed task planning.\"\n\n[AI generates phase-only markdown following template above]\n\nAI: \"I've outlined 4 phases for implementing user authentication:\n    1. Database Schema (foundational)\n    2. Auth Service Layer (core logic)\n    3. API Integration (connects to app)\n    4. Testing & Verification (ensures quality)\n\n    Does this phase structure make sense? Any phases you'd like to add,\n    remove, or reorganize before I create the detailed task breakdown?\"\n\n[User reviews and responds]\n\nUser: \"Looks good, but let's add a phase for migration of existing users\n       between Phase 2 and 3.\"\n\nAI: \"Great point! I'll add 'Phase 3: User Migration' between Auth Service\n    and API Integration. Let me update the plan...\"\n\n[AI revises phase structure]\n\nAI: \"Updated plan with migration phase. Does this revised structure work?\"\n\nUser: \"Perfect, go ahead with the detailed planning.\"\n\nAI: \"Excellent! Now I'll create the complete specification with detailed\n    tasks for each phase...\"\n\n[AI proceeds to section 1.1-1.3.2 to generate full JSON spec]\n```\n\n**Key Points for This Checkpoint:**\n-  **Explicit approval required**: Don't proceed without clear confirmation\n-  **Invite feedback**: Encourage the user to suggest changes\n-  **Be flexible**: Expect iteration on phase structure\n-  **Summarize changes**: Clearly state what you're updating\n-  **Confirm before proceeding**: Get final \"go ahead\" before detailed work\n\n##### 1.0.3 Benefits of Staged Planning\n\n**For Users:**\n- Review and redirect early (5 minutes vs 30 minutes)\n- Easier to understand high-level structure\n- Natural checkpoint for collaboration\n- Confidence that detailed work will be on target\n\n**For AI:**\n- Validated direction before detailed generation\n- Clearer constraints and requirements\n- Reduced rework from misunderstanding\n- Better context for task generation\n\n##### 1.0.4 Proceeding to Detailed Planning\n\nOnce the phase structure is approved:\n1. **Proceed to section 1.1**: Understand the Intent (if not already done)\n2. **Continue to section 1.2**: Analyze the Codebase\n3. **Generate full spec in section 1.3.2**: Using approved phases as structure\n4. **Reference approval**: \"Based on the approved phase structure, I'll now create detailed tasks for each phase...\"\n\n**Important**: The approved phase structure should guide your detailed JSON generation. Maintain consistency between what was approved and what you generate.\n\n---\n\n#### 1.1 Understand the Intent\n\nBegin by deeply understanding what needs to be accomplished:\n- **Core objective**: What is the primary goal?\n- **User perspective**: How will users interact with this?\n- **Success criteria**: What defines \"done\"?\n- **Constraints**: What limitations or requirements exist?\n\n#### 1.2 Analyze the Codebase\n\nBefore creating the plan, explore the relevant parts of the codebase:\n- Identify existing patterns and conventions\n- Locate related functionality\n- Map dependencies and integration points\n- Review similar implementations for consistency\n- Note potential conflicts or breaking changes\n\n**Automatic Documentation Availability Check:**\n\nThis skill automatically checks if codebase documentation is available to enhance planning quality and speed.\n\n**How It Works:**\n\n1. **Automatic Check**: Before manual codebase exploration, the skill runs `sdd doc stats` to verify documentation availability\n2. **Smart Prompting**: If documentation is missing or stale, you'll receive a clear prompt explaining the benefits\n3. **User Decision**: You can choose to generate documentation now (2-5 minutes) or proceed with manual analysis\n4. **Graceful Degradation**: If you skip documentation, the skill seamlessly falls back to manual codebase exploration\n\n**Value Proposition:**\n\nWith documentation available, codebase analysis becomes **dramatically more effective**:\n- **Comprehensive Understanding**: See the entire codebase structure, patterns, and relationships at a glance\n- **Better Specs**: Create more accurate plans based on complete knowledge of existing implementations\n- **Faster Planning**: Reduce analysis time from hours to minutes\n- **Consistency**: Automatically align new features with existing architectural patterns\n- **Future Benefit**: Documentation accelerates all subsequent planning and development tasks\n\n**When Documentation Is Unavailable:**\n\nYou'll see a prompt like:\n```\n  Codebase documentation not found\n\nDocumentation enables:\n- Comprehensive codebase understanding\n- Faster, more accurate planning\n- Automatic pattern and dependency discovery\n\nGenerate documentation now? (2-5 minutes)\n1. Yes, generate for better planning\n2. No, use manual codebase exploration\n```\n\n**Recommendation**: For medium to large codebases or complex features, generating documentation upfront significantly improves spec quality and saves planning time.\n\n**Quick Reference: Useful Documentation Commands for Planning**\n\nWhen documentation is available, these commands accelerate codebase analysis and planning:\n\n**Recommended Starting Point:**\n\n| Command | Purpose | Example Usage |\n|---------|---------|---------------|\n| `sdd doc scope <module> --plan` | **Get focused planning context for a module** (recommended baseline) | `sdd doc scope src/auth/login.ts --plan` |\n\nThis gives you module summary, complexity analysis, and architectural overview in a single command.\n\n**When to Use Existing Commands Instead:**\n\nWhile `scope --plan` provides comprehensive context, use individual commands when you need focused, specific information:\n\n| Use Case | Recommended Command | When to Choose This |\n|----------|---------------------|---------------------|\n| **Quick module overview** | `sdd doc describe-module <path>` | You only need a summary without complexity/dependency details |\n| **Complexity-focused analysis** | `sdd doc complexity <file>` | Planning refactoring or assessing technical debt for a specific file |\n| **Dependency mapping** | `sdd doc dependencies <file>` | Impact analysis or understanding integration points |\n| **Reverse dependency check** | `sdd doc dependencies --reverse <file>` | Breaking change impact assessment |\n\nChoose individual commands when:\n- You need targeted information quickly (avoid information overload)\n- Working within strict context limits\n- Performing specific analysis tasks (complexity assessment, impact analysis)\n- Documentation is stale/incomplete and you need just one aspect\n\nChoose `scope --plan` when:\n- Starting a new feature or major change (comprehensive context needed)\n- Need balanced view of module for task planning\n- Want architectural patterns + complexity + dependencies together\n\n**Additional Commands:**\n\n| Command | Purpose | Example Usage |\n|---------|---------|---------------|\n| `sdd doc stats` | Check documentation status and metrics | `sdd doc stats` |\n| `sdd doc search <query>` | Find relevant implementations and patterns | `sdd doc search \"authentication flow\"` |\n| `sdd doc context <file>` | Get comprehensive file context and relationships | `sdd doc context src/auth/login.ts` |\n| `sdd doc dependencies --reverse <file>` | Find what depends on a file (impact analysis) | `sdd doc dependencies --reverse src/models/User.ts` |\n| `sdd doc complexity <file>` | Assess code complexity and maintainability | `sdd doc complexity src/services/payment.ts` |\n| `sdd doc list-modules` | Get overview of all modules in the codebase | `sdd doc list-modules` |\n\n**Common Planning Workflows with Documentation:**\n\n- **Understanding existing features:** `sdd doc search`  find similar implementations\n- **Impact analysis:** `sdd doc dependencies --reverse`  see what will be affected\n- **Complexity assessment:** `sdd doc complexity`  estimate effort and risks\n- **Pattern discovery:** `sdd doc context`  understand existing architectural patterns\n- **Codebase overview:** `sdd doc list-modules` + `sdd doc stats`  understand project structure\n\n#### 1.2.1 Using `Skill(sdd-toolkit:doc-query)` for Efficient Codebase Analysis\n\n**Proactive Documentation Generation**\n\nBefore starting codebase analysis, **automatically check** if documentation exists. If missing, offer to generate it for faster and more accurate planning.\n\n**Auto-Detection Workflow:**\n\n1. **Check for existing documentation** (fast check):\n```bash\nsdd doc stats\n```\n\n2. **If documentation not found**, proactively ask the user:\n```\nI notice this codebase doesn't have documentation yet. Would you like me to\ngenerate it? This will enable much faster and more accurate codebase analysis.\n\nGenerating documentation will take 2-5 minutes but will speed up all future\nplanning tasks.\n\nGenerate documentation now? [Y/n]\n```\n\n3. **If user agrees**, use Task tool to invoke llm-doc-gen subagent for documentation generation:\n```\nTask(\n  subagent_type: \"sdd-toolkit:llm-doc-gen\",\n  prompt: \"Generate codebase documentation\",\n  description: \"Generate docs\"\n)\n```\n\nThen use Task tool with doc-query subagent for codebase analysis.\n\n4. **If user declines** or generation fails, fall back to manual exploration using `Explore`, or alternatively Glob/Read.\n\n**Documentation-First Approach:**\n- **10x faster codebase analysis** - Seconds vs minutes of manual exploration\n- **Better quality specs** - Comprehensive understanding of patterns and dependencies\n- **Future time savings** - Documentation used across all subsequent planning tasks\n- **Consistency** - Follow existing patterns automatically\n\n---\n\n**Using Existing Documentation:**\n\nIf codebase documentation has been generated, use Task tool with doc-query subagent to efficiently gather context before planning. This provides structured, comprehensive codebase understanding without manual exploration.\n\n**Recommended Analysis Workflow:**\n\nThe doc-query subagent provides the following capabilities (command examples shown for reference):\n\n**Step 1: Get Codebase Overview**\n```bash\n# See overall structure and metrics\nsdd doc stats\n\n# Example output:\n# Total Modules: 37\n# Total Classes: 84\n# Total Functions: 53\n# Average Complexity: 2.42\n# Max Complexity: 8\n```\n\n**Step 2: Search for Similar Implementations**\n```bash\n# Find existing implementations of similar features\nsdd doc search \"feature-keyword\"\n\n# Example: Planning authentication? Search for \"auth\"\nsdd doc search \"auth\"\n# Finds: AuthService, authentication middleware, User model, etc.\n```\n\n**Step 3: Gather Feature Area Context**\n```bash\n# Get all entities related to feature area\nsdd doc context \"feature-area\"\n\n# Example: Planning user management\nsdd doc context \"user\"\n# Returns: All classes, functions, modules related to users\n```\n\n**Step 4: Analyze Target Module Complexity**\n```bash\n# Identify high-complexity functions in target area\nsdd doc complexity --threshold 5 --module target_module.py\n\n# Use to:\n# - Identify refactoring needs\n# - Plan testing strategy\n# - Estimate implementation complexity\n```\n\n**Step 5: Map Dependencies and Impact**\n```bash\n# Check what a module depends on\nsdd doc dependencies app/services/module.py\n\n# Check what depends on it (reverse dependencies - impact analysis)\nsdd doc dependencies app/services/module.py --reverse\n\n# Use to:\n# - Understand integration points\n# - Identify breaking change risks\n# - Plan implementation order\n```\n\n**Step 6: Find Test Files and Coverage**\n```bash\n# Find tests for a module\nsdd doc search \"test.*module_name\"\n```\n\n**Integration Example:**\n\nWhen planning \"Add JWT Authentication\" feature:\n\n```bash\n# 1. Check docs exist\nsdd doc stats\n\n# 2. Search for existing auth\nsdd doc search \"auth\"\n# Found: app/middleware/auth.py, app/models/session.py\n\n# 3. Get full auth context\nsdd doc context \"auth\"\n# Returns: 4 classes, 3 functions, dependencies\n\n# 4. Check auth middleware dependencies\nsdd doc dependencies app/middleware/auth.py --reverse\n# Shows: 5 routes depend on this middleware\n\n# 5. Find similar implementations\nsdd doc find-class \".*Service.*\" --pattern\n# Identify service layer patterns to follow\n\n# 6. Check complexity of related code\nsdd doc complexity --module auth.py\n# Understand existing auth complexity\n```\n\n**When codebase documentation has not been generated:**\nFall back to manual codebase exploration:\n- Use `Explore` to explore the codebase\n- Use `Glob` to find files: `**/*auth*.py`\n- Use `Grep` to search code: `class.*Service`\n- Use `Read` to examine files directly\n\n**After Analysis:**\nUse gathered insights to create accurate, well-informed specifications in Phase 1.3.\n\n#### 1.3 Create the Specification Document\n\n**NOTE**: If you used staged planning (section 1.0), you should now have an approved phase structure. Use that as the foundation for your detailed specification. Maintain consistency with what the user approved.\n\n**IMPORTANT**: The specification is a JSON file (created in section 1.3.2). The markdown template below is a **conceptual planning guide** to help you gather and organize information before creating the JSON. You will NOT create this markdown file - it shows what information to plan for.\n\n**PLANNING GUIDE (Markdown Template for Information Gathering):**\n\nNOTE: This template shows WHAT to plan, not WHAT to create. Use it to organize your thoughts, then proceed to section 1.3.2 to create the actual JSON spec file.\n\n**SPECIFICATION TEMPLATE:**\n\n```markdown\n# Specification: [Feature/Change Name]\n\n## Overview\nBrief description of what this change accomplishes and why.\n\n## Objectives\n- Primary objective\n- Secondary objectives\n- Success criteria\n\n## Phases\n\n### Phase 1: [Phase Name]\n**Purpose**: What this phase accomplishes\n**Dependencies**: What must exist before starting\n**Risk Level**: Low/Medium/High\n\n**Files to Modify:**\n- `path/to/file1.ext`\n  - **Changes**: Specific modifications needed\n  - **Reasoning**: Why these changes are necessary\n  - **Integration points**: How this connects to other parts\n\n- `path/to/file2.ext`\n  - **Changes**: Specific modifications needed\n  - **Reasoning**: Why these changes are necessary\n  - **Integration points**: How this connects to other parts\n\n**Verification Steps:**\n1. Specific check to perform\n2. Expected outcome\n3. How to validate correctness\n\n### Phase 2: [Phase Name]\n[Repeat structure for each phase]\n\n## Implementation Order\n1. Phase X (must complete first)\n2. Phase Y (depends on X)\n3. Phase Z (can run parallel to Y)\n\n## Verification Checklist\n- [ ] All planned files modified\n- [ ] No unintended side effects\n- [ ] Tests pass\n- [ ] Documentation updated\n- [ ] No regressions introduced\n- [ ] Follows existing patterns\n- [ ] Performance acceptable\n- [ ] Security considerations addressed\n\n## Rollback Plan\nHow to revert changes if issues arise.\n\n## Post-Implementation\n- Monitoring requirements\n- Documentation to update\n- Team communication needs\n```\n\n**Critical Specification Requirements:**\n- **File-level detail**: Specify EXACTLY which files will be modified\n- **Clear reasoning**: Every change must have explicit justification\n- **Phase ordering**: Define clear dependencies between phases\n- **Verification criteria**: Include specific, testable checks\n- **Integration awareness**: Note how changes affect other systems\n\n#### 1.3.1 Plan the Task Hierarchy (Visualization Guide)\n\n**IMPORTANT**: This section shows hierarchy notation for PLANNING and VISUALIZATION only. You will NOT create files in this format. This is a way to conceptualize the structure before creating the JSON in section 1.3.2.\n\nUse this notation to plan your hierarchy, then translate it into JSON structure in section 1.3.2.\n\n**Hierarchy Levels:**\n1. **[Spec]** - Root of entire specification\n2. **[Phase]** - Major implementation phase from spec\n3. **[Group]** - Container for related tasks (\"File Modifications\", \"Verifications\")\n4. **[Task]** - Individual file modification or logical unit\n5. **[Subtask]** - Specific change within a file\n6. **[Verify]** - Verification step (automated or manual)\n\n**Format Requirements:**\n\n**Spec Level** (root of everything):\n```\n[Spec] Feature Name (0/total tasks, 0%) {#spec-root}\n```\n- Always uses ID `{#spec-root}`\n- Shows total task count across all phases\n- Initial progress always 0%\n\n**Phase Level** (major implementation stages):\n```\n[Phase] Phase Name (0/phase_task_count tasks) {#phase-N}\n```\n- Sequential numbering: phase-1, phase-2, etc.\n- Task count only for this phase\n- All phases start as `[pending]`\n\n**Group Level** (task containers within phase):\n```\n[Group] File Modifications (0/group_task_count tasks) {#phase-N-files}\n[Group] Verification (0/verify_task_count tasks) {#phase-N-verify}\n```\n- Two standard groups per phase: `-files` and `-verify`\n- Additional phase-specific groups (e.g., `{#phase-1-investigation}`) are allowed when usefulkeep IDs in the `phase-N-*` format\n- File modifications group typically comes first\n- Verification group is usually blocked by the primary work groups\n\n**Task Level** (individual work units):\n```\n[Task] path/to/file.ext [pending] {#task-N-M}\n[Task] path/to/file.ext [pending] [depends: task-X-Y] {#task-N-M}\n[Task] path/to/file.ext [pending] [blocked-by: task-X-Y] {#task-N-M}\n[Task] path/to/file.ext [pending] [parallel-safe] {#task-N-M}\n```\n- One task per file or logical unit\n- N = phase number, M = task number within phase\n- Dependency markers optional but important\n\n**Subtask Level** (granular steps):\n```\n[Subtask] Specific change description [pending] {#task-N-M-P}\n```\n- P = subtask number\n- Use when task needs breakdown\n- Each should be < 30 minutes\n\n**Verification Level** (validation steps):\n```\n[Verify] What to check [pending] [auto] {#verify-N-M}\n[Verify] What to check [pending] [manual] {#verify-N-M}\n[Verify] What to check [pending] [fidelity] {#verify-N-M}\n```\n- Mark as `[auto]` if can be scripted (e.g., running tests)\n- Mark as `[manual]` if requires human judgment (e.g., code review checklist)\n- Mark as `[fidelity]` for implementation-vs-spec comparison (uses sdd-fidelity-review skill)\n- Include command for automated checks\n- Include skill/scope/target metadata for fidelity checks\n\n**Example Hierarchy:**\n```\n[Spec] User Authentication (0/23 tasks, 0%) {#spec-root}\n\n [Phase] Database Schema (0/7 tasks) {#phase-1}\n   \n    [Group] File Modifications (0/3 tasks) {#phase-1-files}\n      \n       [Task] db/migrations/001_add_users.sql [pending] {#task-1-1}\n          [Subtask] Create users table [pending] {#task-1-1-1}\n          [Subtask] Add constraints [pending] {#task-1-1-2}\n          [Subtask] Create indexes [pending] {#task-1-1-3}\n      \n       [Task] src/models/User.ts [pending] [depends: task-1-1] {#task-1-2}\n          [Subtask] Define interface [pending] {#task-1-2-1}\n      \n       [Task] src/types/index.ts [pending] [parallel-safe] {#task-1-3}\n           [Subtask] Export User type [pending] {#task-1-3-1}\n   \n    [Group] Verification [blocked-by: phase-1-files] (0/5 tasks) {#phase-1-verify}\n        [Verify] Migration runs [pending] [auto] {#verify-1-1}\n           Command: `npm run migrate`\n        [Verify] Model imports [pending] [auto] {#verify-1-2}\n        [Verify] Tests pass [pending] [auto] {#verify-1-3}\n           Command: `npm test -- user.spec.ts`\n        [Verify] Implementation fidelity [pending] [fidelity] {#verify-1-4}\n           Skill: sdd-fidelity-review\n           Scope: phase\n           Target: phase-1\n        [Verify] Validation works [pending] [manual] {#verify-1-5}\n```\n\n**Verification Steps:**\n- Group all verifications together (separate from file modifications)\n- One verification per test/check\n- Include command/steps for automated verifications\n- Mark manual verifications clearly\n- Add fidelity reviews at phase boundaries to ensure implementation matches spec\n\n**Rule of Thumb:**\n- Each task/subtask should be completable in < 30 minutes\n- If estimating > 30 minutes, break into subtasks\n- Verification tasks can be longer (might include multiple test runs)\n\n### Dependency Tracking\n\n**Dependency Types:**\n\n**Hard Dependencies** (`[blocked-by: task-id]`):\n- Cannot start until dependency completes\n- Used for sequential requirements\n- Example: Can't write tests until model is created\n```\n[Task] tests/user.spec.ts [pending] [blocked-by: task-1-2] {#task-1-4}\n```\n\n**Soft Dependencies** (`[depends: task-id]`):\n- Recommended order but not strictly required\n- Used for logical sequencing\n- Example: Should implement helper before service, but not required\n```\n[Task] src/services/auth.ts [pending] [depends: task-1-2] {#task-2-1}\n```\n\n**Blocks** (`[blocks: task-id]`):\n- Explicit marker that this task blocks others\n- Usually redundant with blocked-by but helps navigation\n- Used sparingly for critical path items\n\n**Parallel-Safe** (`[parallel-safe]`):\n- Can be done in any order\n- No dependencies on other tasks\n- Can be implemented simultaneously\n```\n[Task] src/types/index.ts [pending] [parallel-safe] {#task-1-3}\n```\n\n**Phase Dependencies:**\n- Phases are sequential by default\n- Later phases blocked by earlier phases\n- Make this explicit in hierarchy:\n```\n[Phase] Auth Service [blocked-by: phase-1] (0/8 tasks) {#phase-2}\n```\n\n### Progress Indicators\n\n**Multi-Level Progress Tracking:**\n\nShow progress at every level of hierarchy:\n```\n[Spec] Feature (0/23 tasks, 0%) {#spec-root}\n [Phase] Setup [pending] (0/7 tasks, 0%) {#phase-1}\n     [Group] File Modifications (0/3 tasks, 0%) {#phase-1-files}\n```\n\n**Progress Calculation (At Creation Time):**\n- All tasks start at `[pending]`\n- All progress percentages are 0%\n- Task counts come from spec structure\n- Progress format: `(completed/total tasks, percentage%)`\n\n**Status Values (At Creation):**\n- `[pending]` - All tasks initially pending\n- No tasks marked as `in_progress`, `completed`, or `blocked` at creation\n- Implementation status tracking happens later via sdd-update\n\n**Display Format:**\n- Spec level: Total task count and percentage\n- Phase level: Task count for that phase\n- Group level: Task count for that group\n- Individual tasks: Status only, no count\n\n**Automatic Task Count Calculation:**\n\nYou don't need to manually calculate task counts - the sdd-validate subagent can fix this automatically:\n\n```\n# Preview fixes without applying (recommended first step)\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Preview auto-fixes for specs/pending/your-spec.json. Show what would be changed without applying.\",\n  description: \"Preview task count fixes\"\n)\n\n# Apply fixes to task counts and hierarchy integrity\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Auto-fix specs/pending/your-spec.json. Apply all fixable issues.\",\n  description: \"Apply task count fixes\"\n)\n```\n\n**How it works:**\n- Uses `recalculate_progress()` from `sdd_common/progress.py`\n- Recursively calculates counts from leaf nodes up through hierarchy\n- Leaf nodes (individual tasks/subtasks) = 1 task each\n- Parent nodes sum their children's counts\n- Ensures counts stay synchronized as spec evolves\n\n**When to use:**\n- After adding/removing tasks from JSON hierarchy\n- When validation reports count mismatches\n- Before running sdd-next (ensures accurate counts)\n- Any time counts seem out of sync\n\n**Common pitfall:** Don't manually update `total_tasks` or `completed_tasks` in the JSON - let the sdd-validate subagent or `sdd-update` handle it automatically to avoid arithmetic errors.\n\n### Task ID Format\n\n**Hierarchical ID Structure:**\n- Spec: `{#spec-root}`\n- Phase: `{#phase-N}`\n- Group: `{#phase-N-files}` or `{#phase-N-verify}`\n- Task: `{#task-N-M}` (phase number, task number)\n- Subtask: `{#task-N-M-P}` (includes subtask number)\n- Verification: `{#verify-N-M}`\n\n**Examples:**\n```\n{#spec-root}          - Root spec\n{#phase-1}            - Phase 1\n{#phase-1-files}      - Phase 1 file modifications group\n{#task-1-1}           - Phase 1, task 1\n{#task-1-1-1}         - Phase 1, task 1, subtask 1\n{#phase-1-verify}     - Phase 1 verification group\n{#verify-1-1}         - Phase 1, verification 1\n```\n\n**ID Stability:**\n- IDs assigned at creation time\n- Remain stable during refinement if possible\n- If structure changes significantly, regenerate with new IDs\n- Never reuse IDs within same spec\n\n#### 1.3.2 Create the JSON Spec File (Single Source of Truth)\n\n**THIS IS THE ACTUAL SPEC FILE YOU WILL CREATE.** After planning your structure using the guides in sections 1.3 and 1.3.1, now create the JSON file that will be used by sdd-next, sdd-update, and all other SDD tools.\n\n**If you completed staged planning (section 1.0):** Base your JSON hierarchy on the approved phase structure. The phase names, ordering, and dependencies should match what the user approved. Now you're adding the detailed task breakdown within each phase.\n\n**Note:** Generate this JSON file manually following the structure described below.\n\n**Location:**\n`specs/pending/{spec-id}.json`\n\n**Initial Spec File Structure:**\n\n```json\n{\n  \"spec_id\": \"user-auth-2025-10-18-001\",\n  \"generated\": \"2025-10-18T10:00:00Z\",\n  \"last_updated\": \"2025-10-18T10:00:00Z\",\n\n  \"hierarchy\": {\n    \"spec-root\": {\n      \"type\": \"spec\",\n      \"title\": \"User Authentication\",\n      \"status\": \"pending\",\n      \"parent\": null,\n      \"children\": [\"phase-1\", \"phase-2\", \"phase-3\"],\n      \"total_tasks\": 24,\n      \"completed_tasks\": 0,\n      \"metadata\": {}\n    },\n\n    \"phase-1\": {\n      \"type\": \"phase\",\n      \"title\": \"Database Schema\",\n      \"status\": \"pending\",\n      \"parent\": \"spec-root\",\n      \"children\": [\"phase-1-files\", \"phase-1-verify\"],\n      \"total_tasks\": 8,\n      \"completed_tasks\": 0,\n      \"metadata\": {}\n    },\n\n    \"phase-1-files\": {\n      \"type\": \"group\",\n      \"title\": \"File Modifications\",\n      \"status\": \"pending\",\n      \"parent\": \"phase-1\",\n      \"children\": [\"task-1-0\", \"task-1-1\", \"task-1-2\", \"task-1-3\"],\n      \"total_tasks\": 4,\n      \"completed_tasks\": 0,\n      \"metadata\": {}\n    },\n\n    \"task-1-0\": {\n      \"type\": \"task\",\n      \"title\": \"Analyze existing user data schema\",\n      \"status\": \"pending\",\n      \"parent\": \"phase-1-files\",\n      \"children\": [],\n      \"dependencies\": {\n        \"blocks\": [\"task-1-1\"],\n        \"blocked_by\": [],\n        \"depends\": []\n      },\n      \"total_tasks\": 1,\n      \"completed_tasks\": 0,\n      \"metadata\": {\n        \"task_category\": \"investigation\",\n        \"estimated_hours\": 2\n      }\n    },\n\n    \"task-1-1\": {\n      \"type\": \"task\",\n      \"title\": \"db/migrations/001_add_users.sql\",\n      \"status\": \"pending\",\n      \"parent\": \"phase-1-files\",\n      \"children\": [\"task-1-1-1\", \"task-1-1-2\", \"task-1-1-3\"],\n      \"dependencies\": {\n        \"blocks\": [],\n        \"blocked_by\": [\"task-1-0\"],\n        \"depends\": []\n      },\n      \"total_tasks\": 3,\n      \"completed_tasks\": 0,\n      \"metadata\": {\n        \"file_path\": \"db/migrations/001_add_users.sql\",\n        \"estimated_hours\": 1,\n        \"task_category\": \"implementation\"\n      }\n    },\n\n    \"task-1-1-1\": {\n      \"type\": \"subtask\",\n      \"title\": \"Create users table\",\n      \"status\": \"pending\",\n      \"parent\": \"task-1-1\",\n      \"children\": [],\n      \"dependencies\": {\n        \"blocks\": [],\n        \"blocked_by\": [],\n        \"depends\": []\n      },\n      \"total_tasks\": 1,\n      \"completed_tasks\": 0,\n      \"metadata\": {}\n    },\n\n    \"phase-1-verify\": {\n      \"type\": \"group\",\n      \"title\": \"Verification\",\n      \"status\": \"pending\",\n      \"parent\": \"phase-1\",\n      \"children\": [\"verify-1-1\", \"verify-1-2\"],\n      \"dependencies\": {\n        \"blocks\": [],\n        \"blocked_by\": [\"phase-1-files\"],\n        \"depends\": []\n      },\n      \"total_tasks\": 2,\n      \"completed_tasks\": 0,\n      \"metadata\": {}\n    },\n\n    \"verify-1-1\": {\n      \"type\": \"verify\",\n      \"title\": \"Migration runs without errors\",\n      \"status\": \"pending\",\n      \"parent\": \"phase-1-verify\",\n      \"children\": [],\n      \"dependencies\": {\n        \"blocks\": [],\n        \"blocked_by\": [],\n        \"depends\": []\n      },\n      \"total_tasks\": 1,\n      \"completed_tasks\": 0,\n      \"metadata\": {\n        \"verification_type\": \"auto\",\n        \"command\": \"npm run migrate\",\n        \"expected\": \"Migration completes successfully\"\n      }\n    },\n\n    \"verify-1-2\": {\n      \"type\": \"verify\",\n      \"title\": \"Phase 1 implementation fidelity review\",\n      \"status\": \"pending\",\n      \"parent\": \"phase-1-verify\",\n      \"children\": [],\n      \"dependencies\": {\n        \"blocks\": [],\n        \"blocked_by\": [],\n        \"depends\": []\n      },\n      \"total_tasks\": 1,\n      \"completed_tasks\": 0,\n      \"metadata\": {\n        \"verification_type\": \"fidelity\",\n        \"skill\": \"sdd-fidelity-review\",\n        \"scope\": \"phase\",\n        \"target\": \"phase-1\",\n        \"on_failure\": {\n          \"consult\": true,\n          \"revert_status\": \"in_progress\",\n          \"continue_on_failure\": false\n        }\n      }\n    }\n  }\n}\n```\n\n**Spec File Generation Rules:**\n1. Every node in the hierarchy becomes an entry\n2. All statuses initially \"pending\"\n3. All completed_tasks initially 0\n4. Parent-child relationships must be bidirectional\n5. Include dependency objects when a node blocks or depends on others (omit when no relationships exist)\n6. Metadata should include `file_path` for tasks that target specific files (strongly recommended for implementation/refactoring work)\n7. Metadata should include `task_category` to classify work type (optional but recommended)\n8. Generated and last_updated timestamps at root\n9. `spec_id` must follow `{feature}-{YYYY-MM-DD}-{nnn}` (three-digit sequence) to satisfy schema validation\n\n**Critical:**\n- JSON spec file is the single source of truth\n- Updated by sdd-update, not this skill\n- Read by sdd-next to find next tasks\n- Store in specs/pending/ (new specs), specs/active/ (in progress), specs/completed/, or specs/archived/\n- Consider adding to .gitignore (user preference)\n- Human-readable views can be generated on-demand using `sdd render`\n\n#### Task Category Metadata\n\nTasks should include a `task_category` field in their metadata to classify the type of work being performed. This helps with task planning, time estimation, and workflow optimization.\n\n**Available Categories:**\n\n- **`investigation`**: Exploring or analyzing existing code to understand behavior, trace bugs, or map dependencies\n- **`implementation`**: Writing new functionality, features, or code that adds capabilities\n- **`refactoring`**: Improving code structure, organization, or quality without changing external behavior\n- **`decision`**: Architectural or design choices requiring analysis, comparison, or selection between alternatives\n- **`research`**: Gathering information, reading documentation, exploring external libraries, or learning new technologies\n\n**Category Selection Guidelines:**\n\n| Category | When to Use | Typical Duration | Needs file_path? |\n|----------|-------------|------------------|-----------------|\n| `investigation` | Need to understand existing code before making changes | Short-Medium | No (optional) |\n| `implementation` | Creating new files, adding features, writing new code | Medium-Long | Yes (strongly recommended) |\n| `refactoring` | Reorganizing existing code without changing behavior | Medium | Yes (strongly recommended) |\n| `decision` | Need to choose between approaches or make architectural decisions | Short | No |\n| `research` | Learning about external tools, reading specs, exploring patterns | Short-Medium | No |\n\n**Examples:**\n\n```json\n// Investigation task - analyzing existing code\n{\n  \"task-1-1\": {\n    \"type\": \"subtask\",\n    \"title\": \"Analyze current authentication flow\",\n    \"status\": \"pending\",\n    \"parent\": \"phase-1\",\n    \"children\": [],\n    \"metadata\": {\n      \"task_category\": \"investigation\",\n      \"estimated_hours\": 2\n    }\n  }\n}\n\n// Implementation task - writing new functionality\n{\n  \"task-2-1\": {\n    \"type\": \"task\",\n    \"title\": \"src/services/authService.ts\",\n    \"status\": \"pending\",\n    \"parent\": \"phase-2-files\",\n    \"children\": [],\n    \"metadata\": {\n      \"file_path\": \"src/services/authService.ts\",\n      \"task_category\": \"implementation\",\n      \"estimated_hours\": 4\n    }\n  }\n}\n\n// Refactoring task - improving code structure\n{\n  \"task-3-1\": {\n    \"type\": \"task\",\n    \"title\": \"Extract validation logic to utility module\",\n    \"status\": \"pending\",\n    \"parent\": \"phase-3-files\",\n    \"children\": [],\n    \"metadata\": {\n      \"file_path\": \"src/utils/validation.ts\",\n      \"task_category\": \"refactoring\",\n      \"estimated_hours\": 3\n    }\n  }\n}\n\n// Decision task - architectural choice\n{\n  \"task-1-2\": {\n    \"type\": \"subtask\",\n    \"title\": \"Choose between JWT vs session-based authentication\",\n    \"status\": \"pending\",\n    \"parent\": \"phase-1\",\n    \"children\": [],\n    \"metadata\": {\n      \"task_category\": \"decision\",\n      \"estimated_hours\": 1\n    }\n  }\n}\n\n// Research task - external learning\n{\n  \"task-1-3\": {\n    \"type\": \"subtask\",\n    \"title\": \"Review OAuth 2.0 best practices and security guidelines\",\n    \"status\": \"pending\",\n    \"parent\": \"phase-1\",\n    \"children\": [],\n    \"metadata\": {\n      \"task_category\": \"research\",\n      \"estimated_hours\": 2\n    }\n  }\n}\n```\n\n#### Verification Task Metadata\n\nWhen creating verification tasks with automated execution:\n\n```json\n{\n  \"verify-1-1\": {\n    \"type\": \"verify\",\n    \"metadata\": {\n      \"verification_type\": \"auto\",\n      \"agent\": \"run-tests\",\n      \"command\": \"npm test\"\n    }\n  },\n  \"verify-1-2\": {\n    \"type\": \"verify\",\n    \"metadata\": {\n      \"verification_type\": \"fidelity\",\n      \"agent\": \"sdd-fidelity-review\",\n      \"scope\": \"phase\",\n      \"target\": \"phase-1\"\n    }\n  }\n}\n```\n\n**Important:**\n- Use the `\"agent\"` field (base agent name) whenever the verification will be run by an automation tool; purely manual checks can omit it\n- Supported automation agent values today: `\"run-tests\"`, `\"sdd-fidelity-review\"`\n- When `agent` is provided, the system invokes automation via `Task(subagent_type: \"sdd-toolkit:{skill-name}-subagent\")`\n\n**Setting Default Category (CLI):**\n\nWhen creating specs via the CLI, you can set a default category that will be stored in the spec metadata:\n\n```bash\n# Create spec with explicit default category\nsdd create \"User Authentication\" --template medium --category investigation\n\n# Create spec without default category\nsdd create \"User Authentication\" --template medium\n```\n\nThe `--category` flag is useful when most tasks in a spec will be the same type (e.g., an investigation-heavy spec or a refactoring-focused spec).\n\n**Best Practices:**\n\n**Choosing the Right Category:**\n- Use **`investigation`** when you need to understand existing code, trace dependencies, or analyze current behavior before making changes\n- Use **`implementation`** when creating new functionality, adding features, or writing new code files\n- Use **`refactoring`** when improving code structure without changing external behavior (e.g., extracting functions, renaming variables)\n- Use **`decision`** when you need to evaluate alternatives or make architectural choices (often early in phases)\n- Use **`research`** when gathering external information, reading documentation, or learning about libraries/tools\n\n**Task Ordering:**\n- **Always use `investigation` before `implementation`**: Understanding code first prevents mistakes and reduces rework\n- **Place `decision` and `research` tasks early in phases**: These inform later implementation work\n- **Group `refactoring` separately from `implementation`**: Keep behavioral changes distinct from structural improvements\n- **Combine `decision` with `research`**: Research tasks often provide the information needed for decision tasks\n\n**Mixed-Type Phases:**\n- Phases often contain multiple task categories (investigation  decision  implementation  verification)\n- Start phases with investigation/research tasks to gather context\n- Place decision tasks after investigation but before implementation\n- End phases with verification tasks to validate the work\n- Use dependencies to enforce proper ordering between different category types\n\n**Other Guidelines:**\n- **Always specify category for tasks**: Helps with accurate time estimation and resource planning\n- **Optional for subtasks**: If a subtask's category is obvious from its parent, it can be omitted\n- **Add `file_path` for implementation/refactoring tasks whenever a single file is the focus**: This keeps downstream tools precise without blocking broader refactors\n- **Skip `file_path` for investigation/decision/research**: These categories often span multiple files or are conceptual\n\n### Phase 2: Spec Validation\n\nAfter creating a JSON specification, validate it to ensure correct format and sdd-next compatibility.\n\n**About Validation:**\n\nThe JSON spec file is validated for:\n- Hierarchy integrity and consistency\n- Task count accuracy\n- Dependency graph validity\n- Required field presence\n- Proper node relationships\n\n**Validation is JSON-only** - markdown files are optional generated artifacts, not validated.\n\n**Using the sdd-validate Subagent:**\n\nTo validate specs within Claude Code, invoke the sdd-validate subagent using the Task tool:\n\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Validate the spec at specs/pending/your-spec.json. Check for structural errors, missing fields, and dependency issues.\",\n  description: \"Validate spec file\"\n)\n```\n\n**When to invoke the subagent:**\n- After creating a new spec (verify initial structure)\n- Before implementation begins (ensure spec is valid)\n- After manual JSON edits (check for errors)\n- When validation errors are suspected (diagnose issues)\n\n#### 2.1 Using the sdd-validate Subagent\n\nThe sdd-validate subagent provides validation, reporting, fixing, and statistics operations for spec files.\n\n**Core Operations:**\n- **validate**  Validate JSON spec structure and integrity\n- **report**  Generate detailed analysis with actionable guidance\n- **fix**  Preview/apply auto-fixes for common hierarchy and metadata issues\n- **stats**  Summarize hierarchy size, verification coverage, and complexity metrics\n\n##### Validate Operation (Recommended)\n\nValidates the JSON spec file structure, hierarchy, and integrity.\n\n**Invocation:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Validate the spec at specs/pending/your-spec.json. Check for structural errors, missing fields, and dependency issues.\",\n  description: \"Validate spec file\"\n)\n```\n\n##### Report Operation\n\nProduces in-depth analysis, grouped by severity, with suggested remedies.\n\n**Invocation:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Generate a detailed validation report for specs/pending/your-spec.json. Save the report to specs/reports/your-spec.md.\",\n  description: \"Generate validation report\"\n)\n```\n\n##### Fix Operation\n\nAutomatically fixes common JSON spec issues. Preview before applying.\n\n**Invocation for preview:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Preview auto-fixes for specs/pending/your-spec.json. Show what would be changed without applying.\",\n  description: \"Preview spec fixes\"\n)\n```\n\n**Invocation to apply fixes:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Auto-fix specs/pending/your-spec.json. Apply all fixable issues and validate afterward.\",\n  description: \"Apply spec fixes\"\n)\n```\n\n##### Stats Operation (Optional)\n\nSummarizes hierarchy composition, depth, and verification footprint.\n\n**Invocation:**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Generate comprehensive statistics for specs/pending/your-spec.json. Include quality score, progress metrics, and completeness analysis.\",\n  description: \"Generate spec statistics\"\n)\n```\n\n**Note:** JSON remains the source of truth. Markdown reports generated via the subagent are helpful for review, but edits must be made in the JSON and re-rendered.\n\n#### 2.2 Validation Checklist\n\n**Before sdd-next Usage:**\n\nInvoke the sdd-validate subagent to ensure the JSON spec file is properly formatted:\n\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Validate the spec at specs/pending/your-spec.json. Check for structural errors, missing fields, and dependency issues.\",\n  description: \"Validate spec before implementation\"\n)\n```\n\n**Required for sdd-next:**\n-  All errors must be fixed\n-  Hierarchy integrity maintained\n-  Task counts are accurate across hierarchy\n-  All required fields present\n-  Dependencies are valid\n\n**If Validation Fails:**\n\n| Error Type | Solution |\n|------------|----------|\n| Task count mismatch | Use auto-fix via subagent or regenerate spec file manually |\n| Hierarchy integrity issues | Use auto-fix via subagent or check parent/child references manually |\n| Missing required fields | Add missing fields, then re-validate with subagent |\n| Invalid dependencies | Check dependency IDs match actual task IDs |\n| Circular dependencies | Remove or adjust blocking relationships |\n\n**Auto-Fix Workflow:**\n\nIf validation fails with fixable errors, use the sdd-validate subagent to preview and apply fixes:\n\n**Step 1: Preview fixes**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Preview auto-fixes for specs/pending/your-spec.json. Show what would be changed without applying.\",\n  description: \"Preview fixes\"\n)\n```\n\n**Step 2: Apply fixes if preview looks good**\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Auto-fix specs/pending/your-spec.json. Apply all fixable issues and validate afterward.\",\n  description: \"Apply fixes\"\n)\n```\n\n**Step 3: Validation confirmation**\nThe subagent will automatically re-validate after applying fixes and report the results.\n\n## Best Practices\n\n### Specification Quality\n- **Be specific**: \"Add error handling to API calls\" not \"improve error handling\"\n- **Include examples**: Show what the change looks like in context\n- **Think ahead**: Consider maintenance, testing, and documentation needs\n- **Stay grounded**: Base plans on actual codebase exploration, not assumptions\n\n## Common Pitfalls to Avoid\n\n **Skipping codebase analysis**: Don't guess at file locations or patterns\n **Vague specifications**: \"Improve performance\" is not actionable\n **Premature optimization**: Don't add features not in the spec\n **Verification shortcuts**: Every step matters, don't skip any\n **Spec drift**: Keep spec updated if requirements change\n **Over-engineering**: Match complexity to actual requirements\n\n## Quick Reference\n\n**Short task (<5 files, simple changes)**\n- **Phases**: 1-2 phases maximum\n- **Hierarchy depth**: 2-3 levels (spec  phase  task, minimal subtasks)\n- **Task count**: 3-8 tasks total\n- **Verification**: 1-2 verifications per phase (minimum 20% coverage)\n- **Spec structure**: Brief objectives, files, key changes, basic verification\n- **Focus**: Verification to prevent breaks, keep hierarchy flat\n\n**Medium task (5-15 files, moderate complexity)**\n- **Phases**: 2-4 phases with clear dependencies\n- **Hierarchy depth**: 3-4 levels (spec  phase  group  task  subtask)\n- **Task count**: 10-25 tasks with selective subtask breakdown\n- **Verification**: 2-4 verifications per phase (aim for 30-40% coverage)\n- **Spec structure**: Full specification with detailed file-level planning\n- **Focus**: Risk assessment, comprehensive verification steps, dependency tracking\n\n**Large task (>15 files or high complexity)**\n- **Phases**: 4-6 phases (if more, split into multiple specs)\n- **Hierarchy depth**: 4-5 levels maximum (deeper = harder to manage)\n- **Task count**: 25-50 tasks (>50 suggests splitting into multiple specs)\n- **Verification**: 3-5 verifications per phase (target 40-50% coverage)\n- **Spec structure**: Detailed multi-phase with extensive verification and rollback planning\n- **Focus**: Consider splitting if >6 phases or >50 tasks; higher user involvement in refinement\n\n**Rule of thumb**: If hierarchy exceeds 5 levels or a single phase has >15 tasks, reorganize or split the spec.\n\n---\n\n**Remember**: The time spent on specification pays exponential dividends in implementation quality and developer confidence. Never skip the planning phase."
              },
              {
                "name": "sdd-pr",
                "description": "AI-powered PR creation after spec completion. Analyzes spec metadata, git diffs, commit history, and journal entries to generate comprehensive PR descriptions with user approval before creation.",
                "path": "skills/sdd-pr/SKILL.md",
                "frontmatter": {
                  "name": "sdd-pr",
                  "description": "AI-powered PR creation after spec completion. Analyzes spec metadata, git diffs, commit history, and journal entries to generate comprehensive PR descriptions with user approval before creation."
                },
                "content": "# Spec-Driven Development: PR Creation Skill\n\n## Overview\n\nThe `sdd-pr` skill creates professional, comprehensive pull requests by analyzing your completed specs and git history. Instead of manually writing PR descriptions, this skill uses AI to analyze all available context and generate detailed, well-structured PR descriptions that make code review more effective.\n\n## When to Use This Skill\n\nUse `Skill(sdd-toolkit:sdd-pr)` to:\n\n- **After Spec Completion**: Create PRs when handed off from sdd-update\n- **Comprehensive PRs**: Generate detailed PR descriptions that reviewers will appreciate\n- **Save Time**: Automate the tedious task of writing thorough PR descriptions\n- **Maintain Quality**: Ensure consistent, high-quality PR documentation\n\n**When NOT to use:**\n- For quick, trivial changes (just use gh CLI directly)\n- When you need a very specific custom PR format\n- For PRs that don't have an associated spec\n\n##  Long-Running Operations\n\n**This skill may run operations that take up to 5 minutes. Be patient and wait for completion.**\n\n### CRITICAL: Avoid BashOutput Spam\n- **ALWAYS use foreground execution with 5-minute timeout:** `Bash(command=\"...\", timeout=300000)`\n- **WAIT for the command to complete** - this may take the full 5 minutes\n- **NEVER use `run_in_background=True` for test suites, builds, or analysis**\n- If you must use background (rare), **wait at least 60 seconds** between BashOutput checks\n- **Maximum 3 BashOutput calls per background process** - then kill it or let it finish\n\n### Why?\nPolling BashOutput repeatedly creates spam and degrades user experience. Long operations should run in foreground with appropriate timeout, not in background with frequent polling.\n\n### Example (CORRECT):\n```\n# Test suite that might take 5 minutes (timeout in milliseconds)\nresult = Bash(command=\"pytest src/\", timeout=300000)  # Wait up to 5 minutes\n# The command will block here until completion - this is correct behavior\n```\n\n### Example (WRONG):\n```\n# Don't use background + polling\nbash_id = Bash(command=\"pytest\", run_in_background=True)\noutput = BashOutput(bash_id)  # Creates spam!\n```\n\n## Core Philosophy\n\n### From Template to Intelligence\n\nTraditional PR creation uses static templates that miss important context. The sdd-pr skill:\n\n1. **Analyzes Multiple Sources**\n   - Spec metadata (what you planned)\n   - Git diffs (what you actually changed)\n   - Commit history (how it evolved)\n   - Journal entries (why you made decisions)\n\n2. **Generates Context-Aware Descriptions**\n   - Explains the \"why\" not just the \"what\"\n   - Highlights key decisions from journal entries\n   - Provides technical depth from git diffs\n   - Maintains professional tone and structure\n\n3. **Requires User Approval**\n   - Always shows draft before creation\n   - User reviews and can request revisions\n   - No PRs created without explicit confirmation\n\n## Workflow\n\n### Step 1: Invocation\n\nThe skill is typically invoked via handoff from sdd-update after spec completion:\n\n```\nSkill(sdd-toolkit:sdd-pr) \"Create PR for spec my-feature-2025-11-03-001\"\n```\n\n### Step 2: Context Gathering\n\nThe skill gathers context from multiple sources:\n\n**Spec Metadata**\n```json\n{\n  \"title\": \"Add user authentication\",\n  \"description\": \"Implement OAuth 2.0 authentication...\",\n  \"objectives\": [\"Support GitHub and Google OAuth providers\", ...]\n}\n```\n\n**Completed Tasks**\n- File paths modified\n- Changes made in each file\n- Task completion status\n\n**Commit History**\n- Commit messages and SHAs\n- Task associations\n- Development progression\n\n**Journal Entries**\n- Technical decisions\n- Implementation notes\n- Challenges overcome\n\n**Git Diff**\n- Actual code changes\n- File-level summary if diff is large\n\n### Step 3: AI Analysis\n\nThe agent analyzes all gathered context to:\n- Understand the feature's purpose and scope\n- Identify key changes and their impact\n- Extract important decisions from journals\n- Synthesize technical details from diffs\n\n### Step 4: Draft Generation\n\nThe agent generates a comprehensive PR description following best practices:\n\n```markdown\n\nPull Request Draft\n\n\nTitle: Add user authentication with OAuth 2.0\n\nBranch: feat-auth  main\n\n\n\n## Summary\n\nAdds user authentication using OAuth 2.0, supporting GitHub and Google\nproviders. Includes login/logout flows, session management, and profile access.\n\n## What Changed\n\n### Key Features\n- OAuth 2.0 integration with GitHub and Google\n- Secure session management with httpOnly cookies\n- User profile endpoint with auth middleware\n\n### Files Modified\n- `src/auth/oauth.py`: OAuth provider implementation\n- `src/auth/middleware.py`: Auth middleware\n- `src/api/routes.py`: Login/logout/profile endpoints\n\n## Technical Approach\n\nChose OAuth 2.0 over JWT-based auth for better security and simpler\nimplementation. OAuth handles token refresh automatically and provides\nbetter user experience with provider-managed consent screens.\n\n## Implementation Details\n\n### Phase 1: OAuth Integration\n-  Implement OAuth provider classes\n-  Add callback URL handling\n-  Store tokens securely\n\n### Phase 2: Session Management\n-  Create session middleware\n-  Implement logout functionality\n\n## Testing\n\n- Added 15 unit tests for OAuth providers\n- Verified login/logout flows manually\n- Tested with both GitHub and Google accounts\n\n## Commits\n\n- abc1234: task-1-1: Implement OAuth providers\n- def5678: task-1-2: Add session middleware\n- ghi9012: task-2-1: Create profile endpoint\n\n\n```\n\n### Step 5: User Review\n\nThe agent shows the draft and asks for user approval:\n\n```\nAgent: \"Here's the PR description I've generated:\n\n[shows full PR with title and body]\n\nWould you like me to create this PR, or would you like me to revise it?\"\n```\n\n### Step 6: PR Creation\n\nOnce approved, the agent invokes the creation command:\n\n```bash\nsdd create-pr spec-id --approve --title \"PR Title\" --description \"$(cat <<'EOF'\n[full PR body]\nEOF\n)\"\n```\n\nThe skill then:\n1. Pushes branch to remote\n2. Creates PR via `gh` CLI immediately (no additional confirmation)\n3. Updates spec metadata with PR URL and number\n\n## Context Sources\n\nThe skill analyzes four key sources:\n\n### 1. Spec Metadata\nHigh-level information about the feature/change:\n- Title and description\n- Objectives and success criteria\n- Phase and task structure\n\n### 2. Completed Tasks\nGranular details about implementation:\n- File paths modified\n- Changes made in each file\n- Task completion timestamps\n\n### 3. Commit History\nDevelopment progression:\n- Commit messages and SHAs\n- Task-to-commit associations\n- Chronological flow\n\n### 4. Journal Entries\nDecision logs and notes:\n- Technical approach decisions\n- Challenges and solutions\n- Implementation rationale\n\n**CLI Command:**\n```bash\nsdd get-journal <spec-id> [--task-id <task-id>]\n```\n\n### 5. Git Diff\nActual code changes:\n- Full diff or file-level summary\n- Code-level understanding\n- Verification of changes\n\n## PR Description Structure\n\nThe generated PR follows this structure:\n\n### 1. Title (50-80 characters)\n```\nAdd user authentication with OAuth 2.0\n```\nAction-oriented, specific, concise.\n\n### 2. Summary (2-3 sentences)\nHigh-level overview of what changed and why it matters.\n\n### 3. What Changed\n- **Key Features**: Bullet list of main features\n- **Files Modified**: File-by-file change summary\n\n### 4. Technical Approach\nExplains key decisions and technical rationale from journal entries.\n\n### 5. Implementation Details\nBreakdown by phase with completed tasks.\n\n### 6. Testing\nVerification steps and test coverage.\n\n### 7. Commits\nDevelopment history showing progression.\n\n## Best Practices\n\n### For Better PR Descriptions\n\n1. **Write Detailed Journal Entries**\n   The AI uses journal entries to explain technical decisions:\n   ```bash\n   sdd journal my-spec --content \"Chose approach X because of Y...\"\n   ```\n\n2. **Use Clear Commit Messages**\n   Commit messages help explain the development flow:\n   ```bash\n   git commit -m \"task-1-1: Implement OAuth provider classes\"\n   ```\n\n3. **Review Before Approving**\n   Always review the draft and ask for revisions if needed:\n   ```\n   \"Can you emphasize the security aspects more?\"\n   ```\n\n4. **Keep Specs Updated**\n   Ensure spec metadata is current before completion:\n   - All tasks marked completed\n   - Journal entries added\n   - Objectives reflect actual work\n\n## Examples\n\n### Example 1: Feature Addition\n\n```bash\n# Skill invoked after spec completion\nSkill(sdd-toolkit:sdd-pr) \"Create PR for oauth-feature-2025-11-03-001\"\n\n# Agent analyzes context and shows draft\n# User reviews and approves\n# PR created automatically\n```\n\n**Generated PR**: Comprehensive description with OAuth implementation details, security considerations, and testing approach.\n\n### Example 2: Bug Fix\n\n```bash\n# Skill invoked for bug fix spec\nSkill(sdd-toolkit:sdd-pr) \"Create PR for memory-leak-fix-2025-11-03-002\"\n\n# Agent analyzes and shows draft\n# PR explains root cause, fix approach, and verification\n```\n\n**Generated PR**: Detailed bug analysis with root cause from journal entries, fix implementation, and memory usage improvements.\n\n### Example 3: Manual Invocation\n\n```bash\n# Invoke skill directly with prompt\nSkill(sdd-toolkit:sdd-pr) \"Create PR for spec refactor-api-2025-11-03-003\"\n\n# Agent gathers context, analyzes, and shows draft\n# Review and approve\n# PR created\n```\n\n## Troubleshooting\n\n### \"Spec missing git.branch_name metadata\"\n\n**Problem**: Spec doesn't have branch information\n\n**Solution**: Ensure git integration is enabled when creating the spec. The spec must have branch metadata.\n\n### \"Branch push failed\"\n\n**Problem**: Git push errors\n\n**Solution**:\n```bash\n# Check remote\ngit remote -v\n\n# Check credentials\ngit push -u origin <branch-name>\n```\n\n### \"Diff too large\"\n\n**Problem**: Git diff exceeds size limit\n\n**Solution**: Skill automatically shows file-level summary instead of full diff when it's too large."
              },
              {
                "name": "sdd-render",
                "description": "Render JSON specs to human-readable markdown with AI-enhanced insights, visualizations, and progressive disclosure",
                "path": "skills/sdd-render/SKILL.md",
                "frontmatter": {
                  "name": "sdd-render",
                  "description": "Render JSON specs to human-readable markdown with AI-enhanced insights, visualizations, and progressive disclosure"
                },
                "content": "# Spec Rendering Skill\n\n## Overview\n\nTransform JSON specification files into beautifully formatted, human-readable markdown documentation. The sdd-render skill bridges the gap between machine-readable specs and human comprehension, making it easy to review progress, share status, and understand project structure at a glance.\n\n**Features:**\n- **Markdown generation** - Convert JSON specs to formatted markdown with progress tracking\n- **Visual progress indicators** - Status icons and percentage completion for phases/tasks\n- **Dependency visualization** - Show task dependencies and blockers\n- **Hierarchical structure** - Phases, groups, tasks, and subtasks clearly organized\n- **Metadata display** - Estimates, complexity, reasoning, and file paths\n- **Multiple output destinations** - Default location or custom paths via --output flag\n\n## Core Workflow\n\n** CRITICAL REQUIREMENT: MANDATORY PRE-EXECUTION CHECKLIST **\n\nBefore executing ANY `sdd render` command, you MUST complete this validation:\n\n```\n\n PRE-EXECUTION DECISION TREE (MANDATORY)                     \n\n                                                             \n  Has user EXPLICITLY specified a rendering mode?         \n    (e.g., \"use basic mode\", \"render with full AI\")         \n                                                             \n         YES               NO                      \n                                                           \n                                                           \n                             STOP - DO NOT RENDER YET     \n                                                           \n                                                           \n                             REQUIRED ACTION:            \n                               Use AskUserQuestion tool     \n                               to ask for mode preference   \n                                                           \n                                                           \n                        Proceed with render    \n                                                             \n\n```\n\n**CRITICAL: Always Ask User for Rendering Mode**\n\nUnless the user has explicitly specified a rendering mode in their request, you MUST use the AskUserQuestion tool to ask which mode they want:\n\n**Example Usage:**\n```\nAskUserQuestion(\n  questions: [{\n    question: \"Which rendering mode would you like to use?\",\n    header: \"Render Mode\",\n    multiSelect: false,\n    options: [\n      {\n        label: \"Basic (fast, no AI)\",\n        description: \"Quick rendering without AI features (< 2 seconds)\"\n      },\n      {\n        label: \"Enhanced - Summary\",\n        description: \"Executive summary with AI (~1-2 minutes)\"\n      },\n      {\n        label: \"Enhanced - Standard (recommended)\",\n        description: \"Balanced AI features (~3-5 minutes) [DEFAULT]\"\n      },\n      {\n        label: \"Enhanced - Full\",\n        description: \"Complete AI analysis (~5-8 minutes)\"\n      },\n      {\n        label: \"Generate all versions for comparison\",\n        description: \"Creates basic, standard, and full versions\"\n      }\n    ]\n  }]\n)\n```\n\n**When to skip asking:**\n- User explicitly requested a mode: \"render with basic mode\", \"use full AI enhancement\"\n- User requested multiple versions: \"generate all three versions\", \"compare enhancement levels\"\n- User is batch rendering multiple specs (use default enhanced standard)\n\n**After getting the answer:**\n- Map user's choice to the appropriate CLI flags\n- Execute sdd render with the selected mode\n- Report the rendering time and output location\n\n---\n\n###  ANTI-PATTERNS: What NOT to Do\n\n**WRONG APPROACH #1: Immediate execution without asking**\n\n```\nUser: \"Let's call the sdd-render skill for /path/to/spec.json\"\n\n Assistant: I'll render the specification file for you.\n   [Immediately executes: sdd render /path/to/spec.json]\n\n   PROBLEM: Skipped asking about rendering mode preference\n```\n\n**CORRECT APPROACH #1: Ask first, then execute**\n\n```\nUser: \"Let's call the sdd-render skill for /path/to/spec.json\"\n\n Assistant: I'll help you render that specification. First, let me ask\n   which rendering mode you'd like to use.\n   [Uses AskUserQuestion tool to present mode options]\n   [After user answers, executes with chosen mode]\n```\n\n---\n\n**WRONG APPROACH #2: Assuming default is okay**\n\n```\nUser: \"Can you render this spec?\"\n\n Assistant: I'll use the default enhanced standard mode.\n   [Executes without asking]\n\n   PROBLEM: Assumed user wants default without confirming\n```\n\n**CORRECT APPROACH #2: Explicit confirmation**\n\n```\nUser: \"Can you render this spec?\"\n\n Assistant: Which rendering mode would you prefer?\n   [Presents options with AskUserQuestion]\n   [User selects mode]\n   [Executes with selected mode]\n```\n\n---\n\n**ONLY ACCEPTABLE: User explicitly specifies mode**\n\n```\nUser: \"Render this spec with basic mode for speed\"\n\n Assistant: I'll render using basic mode as you requested.\n   [Executes: sdd render <spec-id> --mode basic]\n\n   REASON: User explicitly specified \"basic mode\" - no need to ask\n```\n\n**3-Phase Process:**\n\n1. **Prepare** - Ask user for mode (unless explicit), locate spec file, verify output destination\n2. **Render** - Execute sdd render with appropriate flags based on user choice\n3. **Review/Share** - View output and distribute as needed\n\n**Key principles:**\n- **Rendering is read-only** - Never modifies source JSON specs\n- **Output customization** - Use --output for specific destinations\n- **Batch operations** - Process multiple specs when needed\n- **Always render AFTER updates** - Let other skills modify specs first, then render\n- **Always ask for mode** - Unless explicitly specified by user\n\n**Quick decision guide:**\n-  Need quick status check?  Ask user, they might want basic mode for speed\n-  Sharing with team?  Ask user, they might want enhanced standard\n-  Multiple specs?  Use default enhanced standard for batch operations\n-  Need to modify spec?  Use `Skill(sdd-toolkit:sdd-plan)` instead\n-  Need to update tasks?  Use sdd-update-subagent first, then render\n\n## Skill Family\n\nThis skill is part of the **Spec-Driven Development** family:\n- **Skill(sdd-toolkit:sdd-plan)** - Creates specifications and task hierarchies\n- **Skill(sdd-toolkit:sdd-next)** - Identifies next tasks and creates execution plans\n- **Skill(sdd-toolkit:sdd-render)** (this skill) - Renders JSON specs to human-readable formats\n- **sdd-update-subagent** - Updates task and spec progress\n\n## Use This Skill When\n\n**Reporting and Communication:**\n- Need to review a spec's overall structure and progress quickly\n- Want to share spec status with team members or stakeholders\n- Creating documentation for project planning meetings\n- Generating weekly/monthly progress reports\n- Onboarding new developers to understand project scope\n\n**Analysis and Planning:**\n- Analyzing task dependencies visually before starting work\n- Identifying blockers across multiple phases\n- Understanding critical path and task relationships\n- Reviewing spec structure for completeness\n- Validating phase organization and task breakdown\n\n**Documentation:**\n- Creating permanent records of project plans\n- Archiving completed specifications for reference\n- Generating proposals or estimates from specs\n- Producing client-facing project timelines\n\n## Decision Matrix\n\n### Rendering Scope Decision\n\n| Scenario | Action | Why |\n|----------|--------|-----|\n| Single active spec review | `sdd render {spec-id}` | Quick status check |\n| All active specs status | Batch render all active specs | Comprehensive project overview |\n| Client presentation | `sdd render {spec-id} --output client/report.md` | Professional delivery |\n| Debugging spec structure | `sdd render {spec-id} --verbose` | Detailed diagnostics |\n| Daily standup prep | Render + grep for progress | Extract quick metrics |\n| Post-update verification | Render after sdd-update | Visualize changes |\n\n### Output Destination Decision\n\n| Audience | Destination | Format Considerations |\n|----------|------------|----------------------|\n| Development team | `specs/.human-readable/` (default) | Version controlled, easy access |\n| Stakeholders | `docs/reports/` or `docs/status/` | Permanent documentation location |\n| Clients | Custom path + PDF conversion | Professional presentation format |\n| CI/CD pipelines | stdout (`--output -`) | Pipeline integration, no file I/O |\n| Archive | `docs/archive/` with timestamp | Historical record keeping |\n\n### Troubleshooting Decision Tree\n\n**When rendering fails, check in order:**\n\n1. **Spec file exists?**\n   -  No  Use `sdd find-specs --verbose` to locate\n   -  Yes  Continue to step 2\n\n2. **JSON is valid?**\n   - Test: `python3 -m json.tool <spec-file>.json`\n   -  Invalid  Fix JSON syntax or regenerate with sdd-plan\n   -  Valid  Continue to step 3\n\n3. **Output directory writable?**\n   - Test: `ls -la $(dirname <output-path>)`\n   -  No permission  Create directory or use default location\n   -  Writable  Continue to step 4\n\n4. **Still failing?**\n   - Run with `--debug` flag for detailed error messages\n   - Check Troubleshooting section (line 799) for specific errors\n   - Verify sdd CLI is properly installed: `sdd render --help`\n\n## Do NOT Use For\n\n**Spec Modification:**\n- Creating new specifications (use `Skill(sdd-toolkit:sdd-plan)`)\n- Updating task status or progress (use sdd-update-subagent)\n- Modifying spec structure or metadata (use `Skill(sdd-toolkit:sdd-plan)`)\n- Adding or removing tasks (use `Skill(sdd-toolkit:sdd-plan)`)\n\n**Task Execution:**\n- Finding next tasks to work on (use `Skill(sdd-toolkit:sdd-next)`)\n- Creating execution plans (use `Skill(sdd-toolkit:sdd-next)`)\n- Actually implementing code (use appropriate coding tools)\n- Running tests or verification (use `Skill(sdd-toolkit:run-tests)`)\n\n**Other:**\n- Writing conceptual documentation (tutorials, guides)\n- Generating code or test files\n- Real-time collaboration (this creates static snapshots)\n\n## Tool Verification\n\n**Before using this skill**, verify the required tools are available:\n\n```bash\n# Verify sdd render command is installed\nsdd render --help\n```\n\n**Expected output**: Help text showing available options for the render command\n\n**IMPORTANT - CLI Usage Only**:\n-  **DO**: Use `sdd render` CLI command (e.g., `sdd render {spec-id}`)\n-  **DO NOT**: Execute Python scripts directly (e.g., `python cli.py`, `python renderer.py`)\n\nThe CLI provides proper error handling, validation, argument parsing, and interface consistency. Direct script execution bypasses these safeguards and may fail.\n\nIf the verification command fails, ensure the SDD toolkit is properly installed and accessible in your environment.\n\n## Agent Boundaries\n\n**CRITICAL: This skill is READ-ONLY**\n\nThis skill transforms JSON specs into markdown. It NEVER modifies the source specification files or any code.\n\n**MANDATORY: Pre-Execution Mode Selection**\n\nBefore executing ANY render command, you MUST ask the user for their preferred rendering mode using the AskUserQuestion tool (unless the user explicitly specified a mode in their request). This is a non-negotiable requirement of the skill contract. See the Pre-Execution Decision Tree in the Core Workflow section above.\n\n**What this skill does:**\n-  Reads JSON spec files from specs/active, specs/completed, specs/archived\n-  Generates markdown output files\n-  Writes to specs/.human-readable/ or custom --output path\n-  Displays progress, dependencies, and task metadata\n\n**What this skill NEVER does:**\n-  Modifies source JSON spec files\n-  Updates task status or completion timestamps\n-  Creates or modifies code files\n-  Changes spec metadata or structure\n-  Executes tests or verification steps\n\n**Handoff Points - When to Use Other Skills:**\n\n**After successful rendering:**\n\n1. **Spec structure looks wrong?**\n   -  Hand off to `Skill(sdd-toolkit:sdd-plan)` to modify spec structure\n   - Example: Missing phases, incorrect task organization\n\n2. **Task status needs updating?**\n   -  Hand off to sdd-update-subagent to update progress\n   - Example: Mark tasks as completed, update timestamps\n   - **IMPORTANT:** Update first, THEN render to visualize changes\n\n3. **Ready to implement tasks?**\n   -  Hand off to `Skill(sdd-toolkit:sdd-next)` to identify next task\n   - Example: Need execution plan with gathered context\n\n4. **Need to verify implementation?**\n   -  Hand off to `Skill(sdd-toolkit:run-tests)` to run tests\n   - Example: Run verification steps from spec\n\n5. **Output is satisfactory?**\n   -  Done, no further action needed\n   - Share the rendered markdown as needed\n\n**Never chain this skill with spec modification:**\n-  **Wrong:** Update task status  Render (race condition risk)\n-  **Correct:** Use sdd-update-subagent  Then render separately\n\n**Always render AFTER making changes:**\n- Create new spec with sdd-plan  Render to review\n- Complete tasks with sdd-update  Render to visualize progress\n- Major spec updates  Render to verify changes\n\n**Consultation is never required for rendering:**\n- Rendering is a deterministic transformation (JSON  Markdown)\n- If rendering fails, use Troubleshooting Decision Tree (line 102)\n- No external tool consultation needed for render operations\n\n---\n\n## Quick Start\n\n**Execution Workflow:**\n\n1. **Ask user for mode preference** (unless they explicitly specified):\n   - Use AskUserQuestion tool (see example in Core Workflow section above)\n   - Present the 5 mode options\n\n2. **Execute the appropriate command** based on user's answer:\n\n   **If user chose \"Basic (fast, no AI)\":**\n   ```bash\n   sdd render {spec-id} --mode basic\n   # ~2 seconds\n   ```\n\n   **If user chose \"Enhanced - Summary\":**\n   ```bash\n   sdd render {spec-id} --enhancement-level summary\n   # ~1-2 minutes\n   # Note: --mode enhanced is implied when --enhancement-level is specified\n   ```\n\n   **If user chose \"Enhanced - Standard\" (or didn't specify):**\n   ```bash\n   sdd render {spec-id}\n   # Default: enhanced mode with standard level (~3-5 minutes)\n   # Equivalent to: sdd render {spec-id} --enhancement-level standard\n   ```\n\n   **If user chose \"Enhanced - Full\":**\n   ```bash\n   sdd render {spec-id} --enhancement-level full\n   # ~5-8 minutes\n   # Note: --mode enhanced is implied when --enhancement-level is specified\n   ```\n\n   **If user chose \"Generate all versions for comparison\":**\n   ```bash\n   # Generate all three versions with different output names\n   sdd render {spec-id} --mode basic -o specs/.human-readable/{spec-id}-basic.md\n   sdd render {spec-id} --enhancement-level standard -o specs/.human-readable/{spec-id}-standard.md\n   sdd render {spec-id} --enhancement-level full -o specs/.human-readable/{spec-id}-full.md\n   ```\n\n3. **Report results** to the user (output location and any relevant information)\n\n**Output Location:**\nBy default, rendered markdown is saved to `specs/.human-readable/{spec-id}.md`\n\n**Mode Options for AskUserQuestion:**\n\nPresent these 5 options to the user:\n\n| Option Label | CLI Command | Use Case |\n|-------------|-------------|----------|\n| \"Basic (fast, no AI)\" | `--mode basic` | Quick status checks (~2s) |\n| \"Enhanced - Summary\" | `--enhancement-level summary` | Executive summaries (~1-2 min) |\n| \"Enhanced - Standard (recommended)\" | (default, no flags needed) | Most use cases (~3-5 min) [DEFAULT] |\n| \"Enhanced - Full\" | `--enhancement-level full` | Comprehensive analysis (~5-8 min) |\n| \"Generate all versions for comparison\" | Multiple commands with different `-o` paths | Side-by-side comparison |\n\nSee the [AI Enhancement Modes](#ai-enhancement-modes) section below for detailed feature comparison.\n\n---\n\n## Current Rendering Features\n\n### Basic Markdown Generation\n\nThe renderer converts JSON specification files into clean, readable markdown with:\n\n**Header Section:**\n- Spec title and ID\n- Overall status and progress (X/Y tasks, percentage)\n- Estimated effort and complexity\n- Description and objectives\n\n**Phase Sections:**\n- Phase titles with progress indicators\n- Phase-level metadata (purpose, risk level, estimates)\n- Phase dependencies (blocked by, depends on)\n- Nested task groups\n\n**Task Details:**\n- Task title with status icon\n- File path being modified\n- Estimated hours\n- Changes description and reasoning\n- Dependencies and blockers\n- Subtask hierarchy\n\n**Verification Steps:**\n- Verification type (manual, automated, integration)\n- Commands to execute\n- Expected outcomes\n\n### Status Icons\n\nVisual indicators make progress instantly recognizable:\n\n-  **Pending** - Task not yet started\n-  **In Progress** - Currently being worked on\n-  **Completed** - Successfully finished\n-  **Blocked** - Waiting on dependencies\n-  **Failed** - Encountered errors\n\n### Progress Tracking\n\nProgress is calculated and displayed at multiple levels:\n\n**Spec Level:**\n```\nUser Authentication System\nStatus: in_progress (15/23 tasks, 65%)\n```\n\n**Phase Level:**\n```\n## Phase 2: Authentication Service (5/8 tasks, 62%)\n```\n\n**Group Level:**\n```\n### File Modifications (4/5 tasks)\n```\n\n### Dependency Visualization\n\nDependencies are clearly shown to understand task relationships:\n\n```markdown\n**Depends on:** task-1-2, task-1-3\n**Blocked by:** task-2-1\n**Blocks:** task-3-1, task-3-2, task-3-3\n```\n\nThis makes it easy to:\n- Identify what must be completed before starting a task\n- See what's blocking progress\n- Understand which tasks depend on the current task\n\n### Output Customization\n\n**Default Output:**\n```bash\nsdd render my-spec-001\n# Creates: specs/.human-readable/my-spec-001.md\n```\n\n**Custom Output Path:**\n```bash\nsdd render my-spec-001 --output docs/current-project.md\n# Creates: docs/current-project.md\n```\n\n**Specify Specs Directory:**\n```bash\nsdd render my-spec-001 --path /path/to/specs\n# Useful when working with multiple projects\n```\n\n---\n\n## AI Enhancement Modes\n\nThe sdd-render skill supports multiple rendering modes to balance speed and feature richness. Choose the mode based on your needs for performance versus detailed AI-generated insights.\n\n### Mode Overview\n\n**Default Rendering:**\nWhen you run `sdd render {spec-id}` without any flags, it uses **Enhanced Mode with Standard level** for balanced performance and features (~3-5 minutes).\n\n**Two primary modes:**\n\n1. **Basic Mode** (`--mode basic`)\n   - Fast, traditional markdown rendering\n   - No AI features\n   - Uses SpecRenderer for deterministic output\n   - Typical rendering time: < 2 seconds\n   - Use when speed is critical or AI features aren't needed\n   - **Must be explicitly specified** to override the enhanced default\n\n2. **Enhanced Mode** (default, `--mode enhanced` optional)\n   - AI-powered analysis and insights\n   - Uses external AI CLI tools (gemini, cursor-agent, codex)\n   - Default enhancement level: `standard`\n   - Typical rendering time: 1-8 minutes depending on level\n   - Automatically falls back to basic mode if AI tools unavailable\n   - **The `--mode enhanced` flag is optional** - specifying `--enhancement-level` automatically enables enhanced mode\n\n### Enhancement Levels\n\nWhen using enhanced mode (the default), you can optionally specify one of three enhancement levels:\n\n| Level | Features | Performance | Best For |\n|-------|----------|-------------|----------|\n| **summary** | Executive summary only | ~1-2 minutes | Quick AI overview for stakeholders |\n| **standard** | Base features + narrative enhancement | ~3-5 minutes | Team reviews and status reports |\n| **full** | All AI features (insights, visualizations, analysis) | ~5-8 minutes | Comprehensive documentation and planning |\n\n### Feature Comparison\n\n| Feature | Basic | Enhanced (summary) | Enhanced (standard) | Enhanced (full) |\n|---------|-------|-------------------|-------------------|-----------------|\n| Markdown generation |  |  |  |  |\n| Progress indicators |  |  |  |  |\n| Dependency visualization |  |  |  |  |\n| Task hierarchies |  |  |  |  |\n| Executive summary |  |  |  |  |\n| Narrative enhancement |  |  |  |  |\n| Priority ranking |  |  |  |  |\n| Complexity scoring |  |  |  |  |\n| AI insights & recommendations |  |  |  |  |\n| Dependency graphs (Mermaid) |  |  |  |  |\n| Task grouping suggestions |  |  |  |  |\n\n### Usage Examples\n\n**Default Rendering (Enhanced Standard):**\n```bash\n# Uses enhanced mode with standard level by default\nsdd render my-spec-001\n\n# Equivalent explicit forms\nsdd render my-spec-001 --enhancement-level standard\nsdd render my-spec-001 --mode enhanced --enhancement-level standard\n\n# With custom output\nsdd render my-spec-001 --output docs/team-status.md\n```\n\n**Basic Mode (fastest, no AI):**\n```bash\n# Must explicitly specify --mode basic to override enhanced default\nsdd render my-spec-001 --mode basic\n\n# For quick status checks\nsdd render my-spec-001 --mode basic --output /tmp/quick-status.md\n\n# When AI features aren't needed\nsdd render my-spec-001 --mode basic\n```\n\n**Enhanced Mode with Summary:**\n```bash\n# Specifying --enhancement-level automatically enables enhanced mode\nsdd render my-spec-001 --enhancement-level summary\n\n# For stakeholder updates (--mode enhanced is optional, implied by --enhancement-level)\nsdd render my-spec-001 --enhancement-level summary --output reports/exec-summary.md\n```\n\n**Enhanced Mode with Full Features:**\n```bash\n# Specifying --enhancement-level automatically enables enhanced mode\nsdd render my-spec-001 --enhancement-level full\n\n# Maximum AI analysis with all features (--mode enhanced is implied)\nsdd render my-spec-001 --enhancement-level full --output docs/comprehensive-plan.md\n```\n\n### Generating Multiple Versions for Comparison\n\nYou can generate all three versions to compare outputs:\n\n```bash\n#!/bin/bash\nSPEC_ID=\"my-spec-001\"\n\n# Generate basic version (fast reference)\nsdd render $SPEC_ID --mode basic --output specs/.human-readable/${SPEC_ID}-basic.md\n\n# Generate standard enhanced version (balanced)\nsdd render $SPEC_ID --mode enhanced --enhancement-level standard --output specs/.human-readable/${SPEC_ID}-standard.md\n\n# Generate full enhanced version (comprehensive)\nsdd render $SPEC_ID --mode enhanced --enhancement-level full --output specs/.human-readable/${SPEC_ID}-full.md\n\necho \"Generated three versions in specs/.human-readable/\"\nls -lh specs/.human-readable/${SPEC_ID}-*.md\n```\n\n### Choosing the Right Mode\n\n**Use Default (Enhanced Standard) when:**\n-  Most common use case - balanced speed and features\n-  Team reviews and status reports\n-  Narrative flow improves comprehension\n-  Weekly/monthly updates\n-  Client-facing documentation\n-  No special requirements (this is the default!)\n\n**Override to Basic Mode when:**\n- You need quick status checks (< 2 seconds)\n- Working iteratively with frequent renders (rapid feedback loop)\n- AI insights are not needed\n- Output will be consumed by automated tools\n- CI/CD pipeline integration where speed matters\n- Daily standup preparation with time constraints\n- Offline environment or AI tools unavailable\n\n**Override to Enhanced Summary when:**\n- Stakeholders need high-level AI overview only\n- Executive reporting required (lighter than standard)\n- Want faster than standard (~1-2 minutes vs ~3-5 minutes)\n- AI-generated executive summary is the primary value\n- Quick decision-making with AI context\n\n**Override to Enhanced Full when:**\n- Comprehensive project planning with deep analysis\n- Need AI insights, recommendations, and visualizations\n- Visual dependency graphs are valuable\n- Archiving/documentation purposes (one-time comprehensive render)\n- New team member onboarding (detailed explanations helpful)\n- Performance not critical (~5-8 minutes acceptable)\n- Maximum information density desired\n\n### Interactive Mode Selection\n\n**When invoked via the sdd-render skill (not direct CLI):**\n\nThe skill will proactively ask you which rendering mode you prefer using an interactive question:\n\n```\nWhich rendering mode would you like to use?\n Basic (fast, < 2 seconds, no AI)\n Enhanced - Summary (executive summary, ~1-2 minutes)\n Enhanced - Standard (recommended, balanced, ~3-5 minutes)  default\n Enhanced - Full (comprehensive analysis, ~5-8 minutes)\n```\n\n**Benefits of interactive selection:**\n- No need to remember command-line flags\n- Clear explanation of each option's tradeoffs\n- Visual comparison of performance vs features\n- Can choose \"Other\" to specify custom CLI parameters\n- Default option clearly marked (Enhanced Standard)\n\n**When to skip the question:**\nIf you already know which mode you want, you can specify it in your initial request:\n- \"Render with basic mode\"\n- \"Render with full AI enhancement\"\n- \"Generate all three versions for comparison\"\n\nThe skill will respect your explicit request and skip the interactive question.\n\n### AI Tooling\n\nEnhanced mode uses external CLI tools for AI processing:\n\n**Tool Priority Order:**\n1. **gemini** (pro) - Primary for strategic analysis and summaries\n2. **cursor-agent** (composer-1) - Secondary for repository-wide context\n3. **codex** (gpt-5-codex) - Tertiary for code-level insights (disabled by default)\n\n**Automatic Fallback:**\n- System detects available tools automatically\n- Tries tools in priority order\n- Falls back to basic rendering if no AI tools available\n- Configurable via `.claude/ai_config.yaml` (`sdd-render.tools` and `sdd-render.models`)\n\n### Performance Considerations\n\n**Rendering Times:**\n- Basic: < 2 seconds (deterministic, no network calls)\n- Enhanced (summary): ~1-2 minutes (one AI call for executive summary)\n- Enhanced (standard): ~3-5 minutes (summary + narrative enhancement)\n- Enhanced (full): ~5-8 minutes (all AI features, multiple analysis passes)\n\n**Network Requirements:**\n- Basic mode: No network required\n- Enhanced mode: Requires AI tool availability and API access\n- Offline fallback: Enhanced mode falls back to basic if tools unavailable\n\n**Cost Considerations:**\n- Basic mode: No API costs\n- Enhanced mode: AI tool usage may incur API costs depending on configured tools\n- Full enhancement level uses the most AI tokens\n\n---\n\n## Output Samples\n\n### Spec Header\n\n```markdown\n# User Authentication System\n\n**Spec ID:** user-auth-2025-10-24-001\n**Status:** in_progress (15/23 tasks, 65%)\n**Estimated Effort:** 45 hours\n**Complexity:** High\n\n## Description\n\nImplement a secure user authentication system with JWT tokens, role-based access control, and session management.\n\n## Objectives\n\n- Secure password hashing with bcrypt\n- JWT token generation and validation\n- Role-based access control middleware\n- Session management and refresh tokens\n- Account lockout after failed attempts\n```\n\n### Phase with Tasks\n\n```markdown\n## Phase 2: Authentication Service (5/8 tasks, 62%)\n\n**Purpose:** Implement core authentication logic\n**Risk Level:** Medium\n**Estimated Hours:** 18\n\n### Tasks\n\n####  task-2-1: Create AuthService class\n**File:** src/services/authService.ts\n**Estimated:** 3 hours\n**Status:** completed\n**Completed:** 2025-10-24 14:30:15\n\n**Changes:**\nImplement user registration with password hashing, add login method with JWT generation, include password validation logic\n\n**Reasoning:** Centralizes authentication logic\n\n**Blocks:** task-2-2, task-2-3\n\n---\n\n####  task-2-2: Implement JWT middleware\n**File:** src/middleware/auth.ts\n**Estimated:** 2 hours\n**Status:** in_progress\n\n**Changes:**\nCreate Express middleware for JWT verification, add token expiration checking, handle invalid token responses\n\n**Reasoning:** Protects API routes\n\n**Depends on:** task-2-1 \n**Blocks:** task-2-3, task-2-4, task-2-5\n\n---\n\n####  task-2-3: Add role-based authorization\n**File:** src/middleware/rbac.ts\n**Estimated:** 2.5 hours\n**Status:** pending\n\n**Changes:**\nCreate role checking middleware, define permission mappings, add route-level access control\n\n**Reasoning:** Enables fine-grained access control\n\n**Blocked by:** task-2-2 \n```\n\n### Verification Steps\n\n```markdown\n#### verify-2-1: Verify authentication flow\n**Type:** integration\n**Estimated:** 1 hour\n\n**Commands:**\n```bash\nnpm test -- auth.integration.spec.ts\n```\n\n**Expected Outcome:**\nAll authentication tests pass, JWT token format is valid, protected routes reject invalid tokens\n```\n\n### Before/After Comparison\n\n**JSON Input:**\n```json\n{\n  \"id\": \"task-2-1\",\n  \"type\": \"task\",\n  \"title\": \"Create AuthService class\",\n  \"status\": \"completed\",\n  \"metadata\": {\n    \"file_path\": \"src/services/authService.ts\",\n    \"estimated_hours\": 3,\n    \"changes\": \"Implement user registration with password hashing\",\n    \"reasoning\": \"Centralizes authentication logic\"\n  },\n  \"dependencies\": {\n    \"blocks\": [\"task-2-2\", \"task-2-3\"]\n  }\n}\n```\n\n**Rendered Output:**\n```markdown\n####  task-2-1: Create AuthService class\n**File:** src/services/authService.ts\n**Estimated:** 3 hours\n**Status:** completed\n\n**Changes:**\nImplement user registration with password hashing\n\n**Reasoning:** Centralizes authentication logic\n\n**Blocks:** task-2-2, task-2-3\n```\n\n---\n\n## CLI Tools Reference\n\n### Core Commands\n\n**Default Rendering (Enhanced Standard):**\n```bash\nsdd render {spec-id}\n```\nRenders a JSON spec with AI-enhanced narrative to markdown in the default location (`specs/.human-readable/`). Uses enhanced mode with standard level by default.\n\n**Basic Mode (Fast, No AI):**\n```bash\nsdd render {spec-id} --mode basic\n```\nQuick rendering without AI features for speed-critical scenarios. Must explicitly specify `--mode basic` to override the enhanced default.\n\n**Full AI Enhancement:**\n```bash\nsdd render {spec-id} --enhancement-level full\n```\nMaximum AI analysis with insights, visualizations, and recommendations. The `--mode enhanced` flag is optional - it's automatically enabled when you specify `--enhancement-level`.\n\n**Custom Output Path:**\n```bash\nsdd render {spec-id} --output {path}\nsdd render {spec-id} -o {path}\n```\nSpecify where to save the rendered markdown file\n\n**Specify Specs Directory:**\n```bash\nsdd render {spec-id} --path {specs-dir}\n```\nUse when specs are not in the default location\n\n**Render from File Path:**\n```bash\nsdd render /path/to/spec-file.json\n```\nDirectly render a JSON file by providing its full path\n\n### Command Options\n\n**Available Options:**\n\n| Option | Short | Description | Default |\n|--------|-------|-------------|---------|\n| `--mode` | | Rendering mode: `basic` (fast, no AI) or `enhanced` (AI features). Optional - automatically set to `enhanced` when `--enhancement-level` is specified. | `enhanced` (with `standard` level) |\n| `--enhancement-level` | | AI enhancement level: `summary`, `standard`, or `full`. Automatically enables `enhanced` mode. | `standard` |\n| `--output` | `-o` | Output file path | `specs/.human-readable/{spec-id}.md` |\n| `--path` | | Specs directory path | Auto-discovery |\n| `--verbose` | `-v` | Show detailed output | Off |\n| `--debug` | | Show debug information | Off |\n\n**Key Options Explained:**\n\n- `--mode basic` - Explicitly disables AI features for fast rendering (< 2 seconds). Must be specified to override enhanced default.\n- `--mode enhanced` - Enables AI features (default, can be omitted). Automatically enabled when `--enhancement-level` is specified.\n- `--enhancement-level summary` - Executive summary only (~1-2 minutes). Automatically enables enhanced mode.\n- `--enhancement-level standard` - Balanced AI features (default, ~3-5 minutes). Automatically enables enhanced mode.\n- `--enhancement-level full` - All AI features including visualizations (~5-8 minutes). Automatically enables enhanced mode.\n\n### Examples\n\n**Render with default settings (enhanced standard):**\n```bash\nsdd render user-auth-2025-10-24-001\n# Uses: mode=enhanced (default), level=standard (default) (~3-5 minutes)\n```\n\n**Fast render without AI (basic mode):**\n```bash\nsdd render user-auth-2025-10-24-001 --mode basic\n# Must explicitly specify --mode basic to override enhanced default\n# Quick status check (< 2 seconds)\n```\n\n**Executive summary only:**\n```bash\nsdd render user-auth-2025-10-24-001 --enhancement-level summary\n# Automatically enables enhanced mode (~1-2 minutes)\n```\n\n**Full AI analysis:**\n```bash\nsdd render user-auth-2025-10-24-001 --enhancement-level full\n# Automatically enables enhanced mode (~5-8 minutes)\n```\n\n**Render to custom location:**\n```bash\nsdd render user-auth-2025-10-24-001 --output docs/auth-plan.md\n# Default enhanced standard mode with custom path\n```\n\n**Basic mode to custom location (fast):**\n```bash\nsdd render user-auth-2025-10-24-001 --mode basic --output /tmp/quick-status.md\n# Speed-optimized with custom output\n```\n\n**Render with verbose output:**\n```bash\nsdd render user-auth-2025-10-24-001 --verbose\n# Shows: Total tasks, output size, processing time, AI tool used\n```\n\n**Render from specific specs directory:**\n```bash\nsdd render my-spec-001 --path /projects/myapp/specifications\n```\n\n**Render and view immediately:**\n```bash\nsdd render my-spec-001 && less specs/.human-readable/my-spec-001.md\n```\n\n**Generate multiple versions for comparison:**\n```bash\n# Basic (fast reference)\nsdd render my-spec-001 --mode basic -o specs/.human-readable/my-spec-001-basic.md\n\n# Standard (default, balanced)\nsdd render my-spec-001 -o specs/.human-readable/my-spec-001-standard.md\n\n# Full (comprehensive)\nsdd render my-spec-001 --enhancement-level full -o specs/.human-readable/my-spec-001-full.md\n```\n\n---\n\n## Workflow Examples\n\n### Example 1: Weekly Progress Report\n\n**Situation:** Need to generate a progress report for the weekly team meeting\n\n**When to use this approach:**\n-  Regular team meetings require status updates\n-  Spec has been updated recently (tasks completed, status changed)\n-  Need to track progress over time with dated reports\n-  Team members prefer markdown over JSON\n\n**Decision checklist:**\n- **Spec updated?**  Yes  Render will show current progress\n- **Need comparison?**  Keep previous week's report for comparison\n- **Multiple projects?**  Batch render all active specs (see Example 3)\n- **Presentation format?**  Consider PDF conversion (see Example 2)\n\n**Steps:**\n\n1. **Render current spec:**\n```bash\nsdd render user-auth-2025-10-24-001 -o reports/week-$(date +%Y-%m-%d).md\n```\n\n2. **Review the output:**\n```bash\nless reports/week-2025-10-24.md\n```\n\n3. **Share with team:**\n```bash\n# Copy to shared docs folder\ncp reports/week-2025-10-24.md /shared/team-docs/\n\n# Or email directly\nmail -s \"Weekly Progress\" team@company.com < reports/week-2025-10-24.md\n```\n\n**Output includes:**\n- Overall progress percentage\n- Completed tasks this week\n- Upcoming tasks\n- Any blockers\n\n**Why this approach works:**\n- Timestamped filenames create historical record\n- Custom output path keeps reports organized\n- Markdown format is email-friendly and readable in any text editor\n\n### Example 2: Client Status Update\n\n**Situation:** Client wants to see project progress in readable format\n\n**Steps:**\n\n1. **Render spec to client docs:**\n```bash\nsdd render mobile-app-2025-09-15-001 --output client/project-status-$(date +%B).md\n```\n\n2. **Convert to PDF** (optional, requires pandoc):\n```bash\npandoc client/project-status-October.md -o client/project-status-October.pdf\n```\n\n3. **Send to client:**\n- Markdown is readable in email or GitHub\n- PDF is professional and printable\n\n### Example 3: Onboarding New Developer\n\n**Situation:** New developer joins and needs to understand project scope\n\n**Steps:**\n\n1. **Render all active specs:**\n```bash\nfor spec in specs/active/*.json; do\n  spec_id=$(basename $spec .json)\n  sdd render $spec_id\ndone\n```\n\n2. **Create index document:**\n```bash\nls specs/.human-readable/ > docs/project-index.txt\n```\n\n3. **Point developer to documentation:**\n- All specs are now in readable format\n- Developer can browse and understand scope\n- No need to parse JSON manually\n\n### Example 4: Pre-Planning Review\n\n**Situation:** Before starting implementation, review the spec structure\n\n**When to use this approach:**\n-  New spec just created with `Skill(sdd-toolkit:sdd-plan)`\n-  Want to verify structure before beginning work\n-  Looking for dependency issues or circular references\n-  Assessing scope and task breakdown quality\n\n**Decision checklist:**\n- **New spec?**  Always review before implementation starts\n- **Complex dependencies?**  Look for dependency visualization in output\n- **Team review?**  Share rendered version for feedback\n- **Issues found?**  Hand off to `Skill(sdd-toolkit:sdd-plan)` to modify\n\n**Steps:**\n\n1. **Render the spec:**\n```bash\nsdd render api-redesign-2025-10-01-001 --verbose\n```\n\n2. **Review for issues:**\n- Check dependency chains (look for circular dependencies)\n- Verify phase organization (logical progression?)\n- Look for missing tasks (gaps in implementation?)\n- Identify potential blockers (tasks with no dependencies marked?)\n\n3. **Make adjustments** (if needed):\n- Use `Skill(sdd-toolkit:sdd-plan)` to update spec\n- Re-render to verify changes\n```bash\nsdd render api-redesign-2025-10-01-001\n```\n\n**Why this approach works:**\n- Human-readable format makes structural issues obvious\n- Verbose mode shows additional diagnostics\n- Iterative review-modify-verify cycle ensures quality\n- Catches planning issues before implementation begins\n\n### Example 5: Archiving Completed Project\n\n**Situation:** Project is complete, need permanent documentation\n\n**Steps:**\n\n1. **Render final version:**\n```bash\nsdd render user-dashboard-2025-08-01-001 --output archive/user-dashboard-final-$(date +%Y-%m-%d).md\n```\n\n2. **Create summary document:**\n```bash\necho \"# User Dashboard Project - Completed $(date +%Y-%m-%d)\" > archive/README.md\necho \"\" >> archive/README.md\necho \"See user-dashboard-final-*.md for complete specification\" >> archive/README.md\n```\n\n3. **Archive the spec:**\n- Move JSON to specs/completed/\n- Keep markdown in permanent docs\n- Commit to git for history\n\n### Example 6: Comparing Enhancement Levels\n\n**Situation:** Evaluating AI enhancement value or choosing the right level for your workflow\n\n**When to use this approach:**\n-  First time using AI enhancements (want to see differences)\n-  Deciding which level to use for regular workflows\n-  Demonstrating AI capabilities to stakeholders\n-  Benchmarking rendering performance\n-  Creating documentation at multiple detail levels\n\n**Decision checklist:**\n- **Evaluating features?**  Generate all three to compare side-by-side\n- **Performance testing?**  Time each mode with `time` command\n- **Choosing default?**  Try all levels once, then stick with preferred\n- **Multiple audiences?**  Keep multiple versions (basic for developers, full for stakeholders)\n\n**Steps:**\n\n1. **Generate all three versions:**\n```bash\n#!/bin/bash\nSPEC_ID=\"user-auth-2025-10-24-001\"\n\necho \"Generating basic version (no AI)...\"\ntime sdd render $SPEC_ID --mode basic \\\n  --output specs/.human-readable/${SPEC_ID}-basic.md\n\necho \"Generating standard version (default AI)...\"\ntime sdd render $SPEC_ID --enhancement-level standard \\\n  --output specs/.human-readable/${SPEC_ID}-standard.md\n\necho \"Generating full version (maximum AI)...\"\ntime sdd render $SPEC_ID --enhancement-level full \\\n  --output specs/.human-readable/${SPEC_ID}-full.md\n\necho \"All versions generated!\"\n```\n\n2. **Compare file sizes and render times:**\n```bash\nls -lh specs/.human-readable/${SPEC_ID}-*.md\n\n# Example output:\n# -rw-r--r-- 1 user user  45K Oct 24 10:15 user-auth-2025-10-24-001-basic.md     (1.2s)\n# -rw-r--r-- 1 user user  78K Oct 24 10:16 user-auth-2025-10-24-001-standard.md (58s)\n# -rw-r--r-- 1 user user 120K Oct 24 10:17 user-auth-2025-10-24-001-full.md     (92s)\n```\n\n3. **Review each version:**\n```bash\n# Quick scan of basic version\nless specs/.human-readable/${SPEC_ID}-basic.md\n\n# Review standard enhancements\nless specs/.human-readable/${SPEC_ID}-standard.md\n\n# Examine full AI features\nless specs/.human-readable/${SPEC_ID}-full.md\n```\n\n4. **Compare specific sections using diff:**\n```bash\n# Compare basic vs standard\ndiff specs/.human-readable/${SPEC_ID}-basic.md \\\n     specs/.human-readable/${SPEC_ID}-standard.md | head -50\n\n# Compare standard vs full\ndiff specs/.human-readable/${SPEC_ID}-standard.md \\\n     specs/.human-readable/${SPEC_ID}-full.md | head -50\n```\n\n**What to look for in each version:**\n\n**Basic Mode:**\n- Clean, fast markdown rendering\n- Standard progress indicators and task lists\n- No AI-generated content\n- Smallest file size\n\n**Enhanced Standard:**\n- Includes basic features plus:\n- Executive summary section\n- Narrative transitions between phases\n- Contextual explanations\n- Moderately larger file size\n\n**Enhanced Full:**\n- Includes standard features plus:\n- AI-generated insights and recommendations\n- Priority ranking analysis\n- Complexity scoring\n- Dependency graphs (Mermaid diagrams)\n- Task grouping suggestions\n- Largest file size with most detail\n\n**Why this approach works:**\n- Side-by-side comparison shows clear value of each level\n- Timing data helps make performance tradeoff decisions\n- Can choose different levels for different use cases\n- One-time evaluation informs long-term workflow choices\n- Demonstrates ROI of AI features to team/management\n\n**Making your choice:**\n- **Choose Basic** if speed > features and you don't need AI insights\n- **Choose Standard** if you want AI narrative without full analysis (balanced default)\n- **Choose Full** if you need comprehensive AI features and time isn't critical\n\n---\n\n## Integration Points\n\n### With Skill(sdd-toolkit:sdd-plan)\n\n**Creating Specs  Rendering Specs:**\n\n```\n1. Create spec with sdd-plan\n   \n2. Spec saved as JSON in specs/active/\n   \n3. Render with sdd-render for human review\n   \n4. Share rendered markdown with team\n```\n\n**Use case:** After creating a new specification, immediately render it to markdown for team review before beginning implementation.\n\n### With Skill(sdd-toolkit:sdd-next)\n\n**Understanding Context  Finding Tasks:**\n\n```\n1. Render spec to understand overall structure\n   \n2. Use sdd-next to identify next actionable task\n   \n3. Render again after completing tasks to see progress\n```\n\n**Use case:** Before starting work, render the spec to understand the big picture, then use sdd-next for focused task execution.\n\n### With sdd-update-subagent\n\n**Tracking Progress  Visualizing Progress:**\n\n```\n1. Complete a task\n   \n2. Update status with sdd-update\n   \n3. Render spec to see updated progress\n   \n4. Share progress report with stakeholders\n```\n\n**Use case:** After completing milestones, render the spec to generate a progress report showing what's been accomplished.\n\n### With Skill(sdd-toolkit:run-tests)\n\n**Verification  Documentation:**\n\n```\n1. Run tests with run-tests skill\n   \n2. Update verification steps with results\n   \n3. Render spec to document test outcomes\n```\n\n**Use case:** After running verification steps, the rendered spec shows which verifications passed and which are pending.\n\n### With External Tools\n\n**Generated markdown can be:**\n\n- **Committed to git** for version control of project plans\n- **Converted to PDF** using pandoc or similar tools\n- **Embedded in wikis** (GitHub, Confluence, Notion)\n- **Included in reports** using standard markdown processors\n- **Shared via email** (readable in plain text)\n- **Published to static sites** using Jekyll, Hugo, etc.\n\n---\n\n## Common Workflows\n\n### Daily: Quick Status Check\n\n```bash\n# Render and view current status\nsdd render current-project-001 && less specs/.human-readable/current-project-001.md\n\n# Look for:\n# - Progress percentage\n# - Tasks completed today\n# - Upcoming blockers\n```\n\n### Weekly: Team Sync\n\n```bash\n# Generate weekly report\nsdd render current-project-001 -o team-sync/week-$(date +%U).md\n\n# Review in meeting:\n# - Progress since last week\n# - Upcoming milestones\n# - Team allocation\n```\n\n### Monthly: Stakeholder Update\n\n```bash\n# Render all active projects\nfor spec in specs/active/*.json; do\n  spec_id=$(basename $spec .json)\n  sdd render $spec_id -o stakeholder-updates/$(date +%Y-%m)/$spec_id.md\ndone\n\n# Create summary:\n# - Cross-project status\n# - Key achievements\n# - Upcoming priorities\n```\n\n### As-Needed: Debugging Spec Structure\n\n```bash\n# Render with verbose output\nsdd render problem-spec-001 --verbose --debug\n\n# Check for:\n# - Malformed JSON\n# - Circular dependencies\n# - Missing metadata\n# - Progress calculation issues\n```\n\n---\n\n## Troubleshooting\n\n### Issue: Spec Not Found\n\n**Symptoms:**\n```\nError: Spec not found: my-spec-001\n```\n\n**Solutions:**\n\n1. **Check spec ID is correct:**\n```bash\n# List available specs\nsdd find-specs --verbose\n```\n\n2. **Specify specs directory explicitly:**\n```bash\nsdd render my-spec-001 --path /path/to/specs\n```\n\n3. **Use full path to JSON file:**\n```bash\nsdd render /path/to/specs/active/my-spec-001.json\n```\n\n### Issue: Output File Permission Denied\n\n**Symptoms:**\n```\nError: Permission denied: /output/path/file.md\n```\n\n**Solutions:**\n\n1. **Check directory permissions:**\n```bash\nls -la /output/path/\n```\n\n2. **Create output directory:**\n```bash\nmkdir -p /output/path\n```\n\n3. **Use default output location:**\n```bash\n# Omit --output flag to use default\nsdd render my-spec-001\n```\n\n### Issue: Malformed JSON\n\n**Symptoms:**\n```\nError: Failed to load spec file: Invalid JSON\n```\n\n**Solutions:**\n\n1. **Validate JSON:**\n```bash\npython3 -m json.tool specs/active/my-spec-001.json\n```\n\n2. **Check for common issues:**\n- Trailing commas\n- Missing quotes\n- Unclosed brackets\n\n3. **Regenerate spec:**\n```bash\n# Use sdd-plan to recreate the spec\n# This ensures valid JSON structure\n```\n\n### Issue: Missing Metadata\n\n**Symptoms:**\nRendered markdown shows \"Untitled\" or missing information\n\n**Solutions:**\n\n1. **Update spec with missing information:**\n- Use `Skill(sdd-toolkit:sdd-plan)` to add metadata\n- Ensure title, description, objectives are populated\n\n2. **Re-render:**\n```bash\nsdd render my-spec-001\n```\n\n---\n\n## Advanced Usage\n\n### Batch Rendering\n\n**Render all active specs:**\n```bash\n#!/bin/bash\nfor spec in specs/active/*.json; do\n  spec_id=$(basename \"$spec\" .json)\n  echo \"Rendering $spec_id...\"\n  sdd render \"$spec_id\"\ndone\n```\n\n**Render all specs in a status folder:**\n```bash\n# Render all completed specs\nfor spec in specs/completed/*.json; do\n  spec_id=$(basename \"$spec\" .json)\n  sdd render \"$spec_id\" -o docs/completed/$spec_id.md\ndone\n```\n\n### Integration with Git Hooks\n\n**Pre-commit hook to render specs:**\n```bash\n#!/bin/bash\n# .git/hooks/pre-commit\n\n# Render all active specs before committing\nfor spec in specs/active/*.json; do\n  if [ -f \"$spec\" ]; then\n    spec_id=$(basename \"$spec\" .json)\n    sdd render \"$spec_id\"\n    git add \"specs/.human-readable/$spec_id.md\"\n  fi\ndone\n```\n\n**Benefits:**\n- Always have up-to-date rendered versions\n- Track changes in readable markdown\n- Easy to review spec changes in PRs\n\n### Custom Output Processing\n\n**Extract progress percentage:**\n```bash\nsdd render my-spec-001 -o /tmp/spec.md\ngrep \"Status:\" /tmp/spec.md | grep -oP '\\d+%'\n```\n\n**Generate progress badge:**\n```bash\nprogress=$(sdd render my-spec-001 -o - | grep -oP '\\d+%' | head -1)\necho \"![Progress](https://img.shields.io/badge/progress-$progress-blue)\"\n```\n\n**Create searchable index:**\n```bash\n# Render all specs and create full-text search index\nfor spec in specs/active/*.json; do\n  spec_id=$(basename \"$spec\" .json)\n  sdd render \"$spec_id\" >> docs/searchable-index.md\ndone\n```\n\n---\n\n## Performance Considerations\n\n### Rendering Speed by Mode\n\n**Basic Mode Performance:**\n- Small spec (10-20 tasks): < 100ms\n- Medium spec (50-100 tasks): < 500ms\n- Large spec (200+ tasks): < 2 seconds\n- Very large spec (500+ tasks): < 5 seconds\n\n**Enhanced Mode Performance:**\nPerformance depends on the enhancement level chosen:\n\n| Mode | Small Spec | Medium Spec | Large Spec | Very Large Spec |\n|------|-----------|-------------|------------|-----------------|\n| Basic (no AI) | < 100ms | < 500ms | < 2s | < 5s |\n| Enhanced (summary) | ~1 min | ~1.5 min | ~2 min | ~2.5 min |\n| Enhanced (standard) | ~3 min | ~4 min | ~5 min | ~6 min |\n| Enhanced (full) | ~5 min | ~6 min | ~7 min | ~8 min |\n\n**Note:** Enhanced mode times are dominated by AI processing rather than spec size, so scaling is relatively flat.\n\n**Factors affecting basic mode performance:**\n- Number of tasks and subtasks\n- Depth of task hierarchy\n- Size of metadata fields\n- Output file I/O\n\n**Factors affecting enhanced mode performance:**\n- AI tool response time (network latency)\n- Enhancement level (summary < standard < full)\n- AI model availability (gemini is fastest)\n- Spec complexity affects AI analysis quality, not time\n\n### Optimization Tips\n\n**For speed-critical workflows:**\n```bash\n# Use basic mode when speed matters\nsdd render my-spec-001 --mode basic\n\n# Output to stdout (skips file I/O)\nsdd render my-spec-001 --mode basic --output -\n\n# Batch render with basic mode\nfor spec in specs/active/*.json; do\n  sdd render $(basename $spec .json) --mode basic\ndone\n```\n\n**For balanced workflows (default):**\n```bash\n# Default enhanced standard provides good balance\nsdd render my-spec-001\n\n# Cache results for repeated access\nsdd render my-spec-001 --output /tmp/cached-spec.md\n```\n\n**For comprehensive analysis (one-time renders):**\n```bash\n# Full enhancement for documentation\nsdd render my-spec-001 --enhancement-level full --output docs/comprehensive.md\n```\n\n### AI Enhancement Performance\n\n**Default Behavior:**\n- Mode: Enhanced (can be changed with `--mode basic`)\n- Level: Standard (can be changed with `--enhancement-level`)\n- Estimated time: ~3-5 minutes for most specs\n\n**AI Tooling:**\nAI enhancements use external CLI tools via subprocess. The default priority order is:\n1. **gemini** (pro model) - Primary for strategic analysis and summaries\n2. **cursor-agent** (composer-1 model) - Secondary for repository-wide context\n3. **codex** (gpt-5-codex model) - Tertiary for code-level insights (disabled by default)\n\n**Automatic Fallback:**\n- System detects available tools automatically\n- Tries tools in priority order\n- Falls back to basic rendering if no AI tools available\n- No user intervention required\n\n**Configuration:**\nAI tool settings can be customized in `.claude/ai_config.yaml` (`sdd-render` section)\n\n**Performance characteristics:**\n- AI processing is one-time per render (results embedded in markdown)\n- Output file is static (no runtime overhead when viewing)\n- Can switch between modes based on needs\n- Enhanced mode results are cacheable for repeated access\n\n---\n\n## File Locations\n\n### Default Paths\n\n**Input:**\n- Auto-discovered from: `specs/active/`, `specs/completed/`, `specs/archived/`\n- Can be overridden with `--path` option\n\n**Output:**\n- Default: `specs/.human-readable/{spec-id}.md`\n- Can be overridden with `--output` option\n\n### Directory Structure\n\n```\nproject/\n specs/\n    active/               # Active specifications (JSON)\n       my-spec-001.json\n    completed/            # Completed specifications\n    archived/             # Archived specifications\n    .human-readable/      # Rendered markdown (generated)\n        my-spec-001.md    # Human-readable version\n docs/\n     planning/             # Optional: copy rendered docs here\n```\n\n**Note:** The `.human-readable/` directory is automatically created if it doesn't exist.\n\n---\n\n## Success Criteria\n\nA rendering operation is successful when:\n\n**File Creation:**\n-  Markdown file created at expected location\n-  File size > 0 bytes (not empty)\n-  File is valid markdown format\n\n**Content Completeness:**\n-  Contains expected sections (metadata, phases, tasks)\n-  Progress percentages calculated correctly\n-  Dependencies displayed accurately\n-  All task metadata present (file paths, estimates, status)\n-  Verification steps included (if present in spec)\n\n**No Errors:**\n-  No error messages during rendering\n-  No warnings about missing data\n-  Spec JSON file unchanged (read-only verified)\n\n### Validation Checklist\n\nRun these commands to verify successful rendering:\n\n```bash\n# 1. Check file exists\ntest -f specs/.human-readable/{spec-id}.md && echo \" File created\"\n\n# 2. Check file size (should be > 0)\ntest -s specs/.human-readable/{spec-id}.md && echo \" File not empty\"\n\n# 3. Check key sections present\ngrep -q \"^## Phase\" specs/.human-readable/{spec-id}.md && echo \" Phases found\"\n\n# 4. Check progress indicators\ngrep -q \"tasks, [0-9]*%)\" specs/.human-readable/{spec-id}.md && echo \" Progress calculated\"\n\n# 5. Check status icons present\ngrep -E \"^#### (||||)\" specs/.human-readable/{spec-id}.md && echo \" Status icons present\"\n\n# 6. Verify source JSON unchanged\ngit diff specs/active/{spec-id}.json && echo \" Source spec unchanged\"\n```\n\n### When Rendering is NOT Successful\n\n**Symptoms and solutions:**\n\n| Symptom | Likely Cause | Solution |\n|---------|--------------|----------|\n| File created but empty | Invalid JSON spec | Validate with `python3 -m json.tool` |\n| Missing sections | Incomplete spec structure | Check spec has phases and tasks |\n| Progress shows 0% with completed tasks | Task status fields incorrect | Verify task.status values |\n| No dependency info | Dependencies not in spec | Check spec.dependencies structure |\n| Permission denied | Output directory not writable | Use default location or create directory |\n| \"Spec not found\" error | Wrong spec-id or path | Use `sdd find-specs --verbose` |\n\n**When to troubleshoot vs escalate:**\n\n- **Minor issues** (formatting, missing optional fields)  Check Troubleshooting section\n- **Cannot render at all**  Verify installation: `sdd render --help`\n- **Spec structure problems**  Use `Skill(sdd-toolkit:sdd-plan)` to fix spec\n- **Persistent errors**  Check spec JSON validity with validation tools\n\n---\n\n## Summary\n\n**Core Responsibility:**\nTransform JSON specification files into human-readable, well-formatted markdown documentation for easy review, sharing, and understanding.\n\n**Current Capabilities:**\n-  Convert JSON specs to formatted markdown\n-  Display progress with visual indicators\n-  Show task hierarchies and dependencies\n-  Include metadata (estimates, complexity, reasoning)\n-  Support custom output paths\n-  Handle specs from multiple status folders\n\n**Integration Points:**\n- Reads specs created by `Skill(sdd-toolkit:sdd-plan)`\n- Visualizes progress updated by sdd-update-subagent\n- Complements `Skill(sdd-toolkit:sdd-next)` for context understanding\n- Works alongside `Skill(sdd-toolkit:run-tests)` for verification documentation\n\n**Key Benefits:**\n- Make specs accessible to non-technical stakeholders\n- Enable quick progress reviews without parsing JSON\n- Facilitate team communication and reporting\n- Create permanent records of project plans\n- Support multiple use cases (reports, onboarding, planning)\n\n**When to Use:**\nUse this skill whenever you need to convert a machine-readable spec into a human-friendly format for review, sharing, or documentation purposes."
              },
              {
                "name": "sdd-update",
                "description": "Progress tracking for spec-driven development. Use to update task status, track progress, journal decisions, move specs between folders, and maintain spec files. Handles the administrative/clerical aspects of specification documents during development.",
                "path": "skills/sdd-update/SKILL.md",
                "frontmatter": {
                  "name": "sdd-update",
                  "description": "Progress tracking for spec-driven development. Use to update task status, track progress, journal decisions, move specs between folders, and maintain spec files. Handles the administrative/clerical aspects of specification documents during development."
                },
                "content": "# Spec-Driven Development: Update Skill\n\n## When to Use This Skill\n\nUse `Skill(sdd-toolkit:sdd-update)` to:\n- **Complete tasks** (atomically marks as completed AND creates journal entry using `complete-task`)\n- Mark tasks as in_progress or blocked\n- Document decisions and deviations in journal entries\n- Add verification results to specs\n- Move specs between lifecycle folders (e.g., pending => active, active => completed)\n- Update spec metadata fields (progress tracking, status)\n\n**Do NOT use for:**\n- Creating specifications\n- Finding what to work on next\n- Writing code or running tests\n- **Structural spec modifications** (use `Skill(sdd-toolkit:sdd-modify)` instead - see below)\n\n## Core Philosophy\n\n**Document Reality**: JSON spec files are living documents that evolve during implementation. This skill ensures the spec accurately reflects current progress, decisions, and status. All updates are made through CLI commands that handle validation, backups, and progress recalculation automatically.\n\n## Reading Specifications (CRITICAL)\n\n**When working with spec files, ALWAYS use `sdd` CLI commands:**\n-  **ALWAYS** use `sdd` commands to read/query spec files (e.g., `sdd update-status`, `sdd add-journal`, `sdd list-blockers`)\n-  **NEVER** use `Read()` tool on .json spec files - bypasses hooks and wastes context tokens (specs can be 50KB+)\n-  **NEVER** use Bash commands to read spec files (e.g., `cat`, `head`, `tail`, `grep`, `jq`)\n-  **NEVER** use command chaining to access specs (e.g., `sdd --version && cat specs/active/spec.json`)\n- The `sdd` CLI provides efficient, structured access with proper parsing and validation\n- Spec files are large and reading them directly wastes valuable context window space\n\n## Skill Family\n\nThis skill is part of the **Spec-Driven Development** workflow:\n- **sdd-plan** - Creates specifications  **sdd-plan-review** / **sdd-fidelity-review** - Reviews specs  **sdd-modify** - Applies review feedback  **sdd-next** - Finds next task  **Implementation**  **sdd-update** (this skill) - Updates progress\n\n## Relationship to sdd-modify\n\n**When to use sdd-update vs sdd-modify:**\n\n| Operation | Use sdd-update | Use sdd-modify |\n|-----------|---------------|----------------|\n| Mark task completed |  Yes |  No |\n| Update task status (in_progress, blocked) |  Yes |  No |\n| Add journal entries |  Yes |  No |\n| Move spec between folders |  Yes |  No |\n| **Update task descriptions** |  No |  Yes |\n| **Add/remove tasks** |  No |  Yes |\n| **Add verification steps** |  No |  Yes |\n| **Apply review feedback systematically** |  No |  Yes |\n| **Bulk structural modifications** |  No |  Yes |\n\n**Key Distinction:**\n- **sdd-update** = Lightweight metadata updates (status, progress, journal entries)\n- **sdd-modify** = Heavyweight structural changes (task descriptions, adding tasks/verifications, review feedback)\n\n**Example - When to use sdd-modify:**\n\nIf you need to:\n- Apply feedback from sdd-fidelity-review or sdd-plan-review\n- Update multiple task descriptions for clarity\n- Add verification steps discovered during implementation\n- Make bulk modifications to spec structure\n\nThen use: `Skill(sdd-toolkit:sdd-modify)`\n\nSee **Systematic Spec Modification** section below for details.\n\n## Workflow 1: Starting a Task\n\nMark a task as in_progress when you begin work:\n\n```bash\nsdd update-status {spec-id} {task-id} in_progress\n```\n\nThe CLI automatically records the start timestamp for tracking purposes.\n\n## Workflow 2: Tracking Progress\n\n### Add Journal Entries\n\nDocument decisions, deviations, or important notes:\n\n```bash\n# Document a decision\nsdd add-journal {spec-id} --title \"Decision Title\" --content \"Explanation of decision and rationale\" --task-id {task-id} --entry-type decision\n\n# Document a deviation from the plan\nsdd add-journal {spec-id} --title \"Deviation: Changed Approach\" --content \"Created separate service file instead of modifying existing. Improves separation of concerns.\" --task-id {task-id} --entry-type deviation\n\n# Document task completion (use status_change, NOT completion)\nsdd add-journal {spec-id} --title \"Task Completed: Implement Auth\" --content \"Successfully implemented authentication with JWT tokens. All tests passing.\" --task-id {task-id} --entry-type status_change\n\n# Document a note\nsdd add-journal {spec-id} --title \"Implementation Note\" --content \"Using Redis for session storage as discussed.\" --task-id {task-id} --entry-type note\n```\n\n**Entry types:** `decision`, `deviation`, `blocker`, `note`, `status_change`\n\n## Workflow 3: Handling Blockers\n\n### Mark Task as Blocked\n\nWhen a task cannot proceed:\n\n```bash\nsdd mark-blocked {spec-id} {task-id} --reason \"Description of blocker\" --type {type} --ticket \"TICKET-123\"\n```\n\n**Blocker types:**\n- `dependency` - Waiting on external dependency\n- `technical` - Technical issue blocking progress\n- `resource` - Resource unavailability\n- `decision` - Awaiting architectural/product decision\n\n### Unblock Task\n\nWhen blocker is resolved:\n\n```bash\nsdd unblock-task {spec-id} {task-id} --resolution \"Description of how it was resolved\"\n```\n\n### List All Blockers\n\n```bash\nsdd list-blockers {spec-id}\n```\n\n## Workflow 4: Adding Verification Results\n\n### Manual Verification Recording\n\nDocument verification results:\n\n```bash\n# Verification passed\nsdd add-verification {spec-id} {verify-id} PASSED --command \"npm test\" --output \"All tests passed\" --notes \"Optional notes\"\n\n# Verification failed\nsdd add-verification {spec-id} {verify-id} FAILED --command \"npm test\" --output \"3 tests failed\" --issues \"List of issues found\"\n\n# Partial success\nsdd add-verification {spec-id} {verify-id} PARTIAL --notes \"Most checks passed, minor issues remain\"\n```\n\n### Automatic Verification Execution\n\nIf verification tasks have metadata specifying how to execute them, run automatically:\n\n```bash\n# Execute verification based on metadata\nsdd execute-verify {spec-id} {verify-id}\n\n# Execute and automatically record result\nsdd execute-verify {spec-id} {verify-id} --record\n```\n\n**Requirements:** Verification task must have `skill` or `command` in its metadata.\n\n### Verify on Task Completion\n\nAutomatically run verifications when marking a task complete:\n\n```bash\nsdd update-status {spec-id} {task-id} completed --verify\n```\n\nThe `--verify` flag runs all associated verify tasks. If any fail, the task reverts to `in_progress`.\n\n### Configurable Failure Handling\n\nVerification tasks can specify custom failure behavior via `on_failure` metadata:\n\n```json\n{\n  \"verify-1-1\": {\n    \"metadata\": {\n      \"on_failure\": {\n        \"consult\": true,\n        \"revert_status\": \"in_progress\",\n        \"max_retries\": 2,\n        \"continue_on_failure\": false\n      }\n    }\n  }\n}\n```\n\n**on_failure fields:**\n- `consult` (boolean) - Recommend AI consultation for debugging\n- `revert_status` (string) - Status to revert parent task to on failure\n- `max_retries` (integer) - Number of automatic retry attempts (0-5)\n- `continue_on_failure` (boolean) - Continue with other verifications if this fails\n\n## Workflow 5: Completing Tasks\n\n### Complete a Task (Recommended: Atomic Status + Journal)\n\nWhen finishing a task, use `complete-task` to atomically mark it complete AND create a journal entry:\n\n```bash\n# Complete with automatic journal entry\nsdd complete-task {spec-id} {task-id} --journal-content \"Successfully implemented JWT authentication with token refresh. All tests passing including edge cases for expired tokens.\"\n\n# Customize the journal entry\nsdd complete-task {spec-id} {task-id} --journal-title \"Task Completed: Authentication Implementation\" --journal-content \"Detailed description of what was accomplished...\" --entry-type status_change\n\n# Add a brief status note\nsdd complete-task {spec-id} {task-id} --note \"All tests passing\" --journal-content \"Implemented authentication successfully.\"\n```\n\n**What `complete-task` does automatically:**\n1. Updates task status to `completed`\n2. Records completion timestamp\n3. Creates a journal entry documenting the completion\n4. Clears the `needs_journaling` flag\n5. Syncs metadata and recalculates progress\n6. Automatically journals parent nodes (phases, groups) that auto-complete\n\n**This is the recommended approach** because it ensures proper documentation of task completion.\n\n#### Parent Node Journaling\n\nWhen completing a task causes parent nodes (phases or task groups) to auto-complete, `complete-task` automatically creates journal entries for those parents:\n\n- **Automatic detection**: The system detects when all child tasks in a phase/group are completed\n- **Automatic journaling**: Creates journal entries like \"Phase Completed: Phase 1\" for each auto-completed parent\n- **No manual action needed**: You don't need to manually journal parent completions\n- **Hierarchical**: Works for multiple levels (e.g., completing a task can journal both its group AND its phase)\n\nExample output:\n```bash\n$ sdd complete-task my-spec-001 task-1-2 --journal-content \"Completed final task\"\n Task marked complete\n Journal entry added\n Auto-journaled 2 parent node(s): group-1, phase-1\n```\n\n### Alternative: Status-Only Update (Not Recommended for Completion)\n\nIf you need to mark a task completed without journaling (rare), use:\n\n```bash\nsdd update-status {spec-id} {task-id} completed --note \"Brief completion note\"\n```\n\n **Warning:** This sets `needs_journaling=True` and requires a follow-up `add-journal` call. Use `complete-task` instead to avoid forgetting to journal.\n\n### Complete a Spec\n\nWhen all phases are verified and complete:\n\n```bash\n# Check if ready to complete\nsdd check-complete {spec-id}\n\n# Complete spec (updates metadata, regenerates docs, moves to completed/)\nsdd complete-spec {spec-id}\n\n# Skip documentation regeneration\nsdd complete-spec {spec-id} --skip-doc-regen\n```\n\n## Workflow 6: Moving Specs Between Folders\n\n### Activate from Backlog\n\nMove a spec from pending/ to active/ when ready to start work:\n\n```bash\nsdd activate-spec {spec-id}\n```\n\nThis updates metadata status to \"active\" and makes the spec visible to sdd-next.\n\n### Move to Completed\n\nUse `complete-spec` (see Workflow 5) to properly complete and move a spec.\n\n### Archive Superseded Specs\n\nMove specs that are no longer relevant:\n\n```bash\nsdd move-spec {spec-id} archived\n```\n\n## Fidelity Review Configuration\n\nThe optional pre-completion fidelity review behavior can be configured via `.claude/sdd_config.json`:\n\n```json\n{\n  \"fidelity_review\": {\n    \"enabled\": true,\n    \"on_task_complete\": \"prompt\",\n    \"on_phase_complete\": \"always\",\n    \"skip_categories\": [\"investigation\", \"research\"],\n    \"min_task_complexity\": \"medium\"\n  }\n}\n```\n\n**Configuration options:**\n\n- `enabled` (boolean, default: `true`) - Master switch for fidelity review features\n- `on_task_complete` (string, default: `\"prompt\"`) - When to offer fidelity review for task completion:\n  - `\"always\"` - Automatically run fidelity review before marking any task complete\n  - `\"prompt\"` - Ask user if they want to run fidelity review (recommended)\n  - `\"never\"` - Skip automatic prompts, only use manual invocation or verification tasks\n\n- `on_phase_complete` (string, default: `\"always\"`) - When to offer fidelity review for phase completion:\n  - `\"always\"` - Automatically run phase-level fidelity review when all tasks in phase complete\n  - `\"prompt\"` - Ask user if they want to run phase review\n  - `\"never\"` - Skip automatic phase reviews\n\n- `skip_categories` (array, default: `[]`) - Task categories that don't require fidelity review:\n  - Common values: `[\"investigation\", \"research\", \"decision\"]`\n  - Tasks with these categories will skip automatic review prompts\n\n- `min_task_complexity` (string, default: `\"low\"`) - Minimum task complexity for automatic review:\n  - `\"low\"` - Review all tasks (most thorough)\n  - `\"medium\"` - Only review medium/high complexity tasks\n  - `\"high\"` - Only review high complexity tasks (least intrusive)\n\n**When fidelity review is triggered:**\n\nBased on configuration, when completing a task via `sdd-update`, the system will:\n\n1. Check if task category is in `skip_categories`  skip if true\n2. Check task complexity against `min_task_complexity`  skip if below threshold\n3. Check `on_task_complete` setting:\n   - `\"always\"`  Automatically invoke fidelity review subagent\n   - `\"prompt\"`  Ask user: \"Run fidelity review before completing?\"\n   - `\"never\"`  Skip (user can still manually invoke)\n\n**Note:** Verification tasks with `verification_type: \"fidelity\"` always run regardless of configuration.\n\n## Workflow 7: Git Commit Integration\n\nWhen git integration is enabled (via `.claude/git_config.json`), the sdd-update skill can automatically create commits after task completion based on configured commit cadence preferences.\n\n### Commit Cadence Configuration\n\nThe commit cadence determines when to offer automatic commits:\n\n- **task**: Commit after each task completion (frequent commits, granular history)\n- **phase**: Commit after each phase completion (fewer commits, milestone-based)\n- **manual**: Never auto-commit (user manages commits manually)\n\nThe cadence preference is configured project-wide in `.claude/git_config.json` and accessed via `get_git_setting('commit_cadence')`.\n\n### Commit Workflow Steps\n\nWhen completing a task and git integration is enabled, the workflow follows these steps:\n\n**1. Check Commit Cadence**\n\nFirst, confirm whether automatic commits are enabled for the current event type. `sdd-update` reads `.claude/git_config.json` at runtime, so you only need to inspect the configuration (for example: `sdd skills-dev start-helper session-summary . --json`) to see whether the cadence is set to `task`, `phase`, or `manual`.\n\n**2. Check for Changes**\n\nBefore offering a commit, verify there are uncommitted changes:\n\n```bash\n# Check for changes (run in repo root directory)\ngit status --porcelain\n\n# If output is empty, skip commit offer (nothing to commit)\n# If output has content, proceed with commit workflow\n```\n\n**3. Generate Commit Message**\n\nCreate a structured commit message from task metadata using the pattern `{task-id}: {task-title}` (for example, `task-2-3: Implement JWT verification middleware`). The CLI applies this format automatically when generating commits.\n\n**4. Preview and Stage Changes (Two-Step Workflow)**\n\nThe workflow now supports **agent-controlled file staging** with two approaches:\n\n**Option A: Show Preview (Default - Recommended)**\n\nWhen `file_staging.show_before_commit = true` (default), the agent sees uncommitted files and can selectively stage:\n\n```bash\n# Step 1: Preview uncommitted files (automatic via show_commit_preview_and_wait)\n# Shows: modified, untracked, and staged files\nsdd complete-task SPEC_ID TASK_ID\n\n# Step 2: Agent stages only task-related files\ngit add specs/active/spec.json\ngit add src/feature/implementation.py\ngit add tests/test_feature.py\n# (Deliberately skip unrelated files like debug scripts, personal notes)\n\n# Step 3: Create commit with staged files only\nsdd create-task-commit SPEC_ID TASK_ID\n```\n\n**Benefits:**\n-  Agent controls what files are committed\n-  Unrelated files protected from accidental commits\n-  Clean, focused task commits\n\n**Option B: Auto-Stage All (Backward Compatible)**\n\nWhen `file_staging.show_before_commit = false`, the old behavior is preserved:\n\n```bash\n# Automatically stages all files and commits (old behavior)\ngit add --all\ngit commit -m \"{task-id}: {task-title}\"\n```\n\n**Configuration:**\n\nFile staging behavior is controlled in `.claude/git_config.json`:\n\n```json\n{\n  \"enabled\": true,\n  \"auto_commit\": true,\n  \"commit_cadence\": \"task\",\n  \"file_staging\": {\n    \"show_before_commit\": true  // false = auto-stage all (backward compatible)\n  }\n}\n```\n\n**Command Reference:**\n\n```bash\n# Complete task (shows preview if enabled)\nsdd complete-task SPEC_ID TASK_ID\n\n# Create commit from staged files\nsdd create-task-commit SPEC_ID TASK_ID\n\n# Example workflow:\nsdd complete-task user-auth-001 task-1-2\n# (Review preview, stage desired files)\ngit add specs/active/user-auth-001.json src/auth/service.py\nsdd create-task-commit user-auth-001 task-1-2\n```\n\n**All git commands use `cwd=repo_root`** obtained from `find_git_root()` to ensure they run in the correct repository directory.\n\n**5. Record Commit Metadata**\n\nAfter successful commit, capture the commit SHA and update spec metadata:\n\n```bash\n# Get the commit SHA\ngit rev-parse HEAD\n\n# Example output: a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0\n```\n\n### Error Handling\n\nGit operations should be non-blocking - failures should not prevent task completion:\n\n**Error handling principles:**\n\n- Check `returncode` for all git commands\n- Log warnings for failures but continue execution\n- Git failures do NOT prevent task completion\n- User can manually commit if automatic commit fails\n- Provide clear error messages in logs for debugging\n\n### Repository Root Detection\n\nAll git commands must run in the repository root directory:\n\n- `sdd-update` automatically discovers the repo root (similar to running `git rev-parse --show-toplevel` from the spec directory).\n- If no git repository is detected, the commit workflow is skipped and the task still completes.\n- Manual workflows should `cd` to the project root (the directory containing `.git/`) before running git commands.\n\n### Complete Example Workflow\n\n1. Complete the task with `sdd complete-task SPEC_ID TASK_ID`.\n2. If git integration is enabled and cadence matches the event, `sdd-update` checks for uncommitted changes.\n3. Stage files either via the preview workflow (recommended) or `git add --all` when auto-staging is enabled.\n4. Run `sdd create-task-commit SPEC_ID TASK_ID` to generate the commit; the command formats the message and records the SHA automatically.\n5. If no changes are staged or the git command fails, the tool logs a warning and the task completion still succeeds.\n\n### Configuration File\n\nGit integration is configured via `.claude/git_config.json`:\n\n```json\n{\n  \"enabled\": true,\n  \"auto_branch\": true,\n  \"auto_commit\": true,\n  \"auto_push\": false,\n  \"auto_pr\": false,\n  \"commit_cadence\": \"task\"\n}\n```\n\n**Settings:**\n- `enabled`: Enable/disable all git integration\n- `auto_commit`: Enable automatic commits (requires enabled: true)\n- `commit_cadence`: When to commit - \"task\", \"phase\", or \"manual\"\n\nSee **Workflow 7: Git Commit Integration** in sdd-next SKILL.md for branch creation workflow details.\n\n## Workflow 8: Git Push & PR Handoff\n\nWhen a spec is completed, the workflow can automatically push commits to the remote repository. Pull request creation is handed off to the dedicated PR workflow.\n\n### Push-Only Scope (PRs Deferred)\n\n- `Skill(sdd-toolkit:sdd-update)` handles local commits and optional pushes during completion workflows, but it does **not** create pull requests.\n- Pull requests are beyond the scope of your responsibilities.\n- If push automation is disabled or fails, finish the spec update, run `git push -u origin <branch>` manually, and then involve the PR skill/agent.\n\n## Common CLI Patterns\n\n### Preview Changes\n\nUse `--dry-run` to preview changes before applying:\n\n```bash\nsdd update-status {spec-id} {task-id} completed --dry-run\nsdd mark-blocked {spec-id} {task-id} --reason \"Test\" --dry-run\n```\n\n### Query Spec State\n\n```bash\n# Get overall progress\nsdd status-report {spec-id}\n\n# List all phases with progress\nsdd list-phases {spec-id}\n\n# Find tasks by status\nsdd query-tasks {spec-id} --status pending\nsdd query-tasks {spec-id} --status blocked\n\n# Find tasks by type\nsdd query-tasks {spec-id} --type verify\n\n# Get specific task details\nsdd get-task {spec-id} {task-id}\n```\n\n### Update Metadata\n\n```bash\n# Update spec metadata fields\nsdd update-frontmatter {spec-id} status \"active\"\nsdd update-frontmatter {spec-id} owner \"user@example.com\"\nsdd update-frontmatter {spec-id} priority \"high\"\n\n# Sync metadata with hierarchy state\nsdd sync-metadata {spec-id}\n```\n\n### Update Task Metadata\n\nUpdate metadata fields for individual tasks using `update-task-metadata`:\n\n```bash\n# Update predefined metadata fields using individual flags\nsdd update-task-metadata {spec-id} {task-id} --file-path \"src/auth.py\"\nsdd update-task-metadata {spec-id} {task-id} --description \"Updated task description\"\nsdd update-task-metadata {spec-id} {task-id} --task-category \"implementation\"\nsdd update-task-metadata {spec-id} {task-id} --actual-hours 2.5\n\n# Update custom metadata fields using JSON\nsdd update-task-metadata {spec-id} {task-id} \\\n  --metadata '{\"focus_areas\": [\"performance\", \"security\"], \"priority\": \"high\"}'\n\n# Combine individual flags with custom JSON (flags take precedence)\nsdd update-task-metadata {spec-id} {task-id} \\\n  --file-path \"src/middleware.py\" \\\n  --metadata '{\"focus_areas\": [\"authentication\"], \"complexity\": \"medium\"}'\n\n# Complex nested metadata structures\nsdd update-task-metadata {spec-id} {task-id} \\\n  --metadata '{\n    \"focus_areas\": [\"error handling\", \"edge cases\"],\n    \"blockers\": [\"clarification needed\", \"dependency X\"],\n    \"implementation_notes\": {\n      \"approach\": \"incremental\",\n      \"testing_strategy\": \"unit + integration\"\n    }\n  }'\n```\n\n**Available individual flags:**\n- `--file-path` - File path associated with this task\n- `--description` - Task description\n- `--task-category` - Category (e.g., implementation, testing, documentation)\n- `--actual-hours` - Actual hours spent on task\n- `--status-note` - Status note or completion note\n- `--verification-type` - Verification type (auto, manual, none)\n- `--command` - Command executed\n\n**Custom metadata with --metadata:**\n- Accepts JSON object with any custom fields\n- Useful for tracking focus areas, priorities, blockers, complexity, etc.\n- Merges with individual flags (individual flags take precedence)\n- Supports nested structures and arrays\n\n**Common use cases:**\n```bash\n# Track focus areas for investigation tasks\nsdd update-task-metadata {spec-id} task-1-1 \\\n  --metadata '{\"focus_areas\": [\"code-doc structure\", \"skill patterns\"]}'\n\n# Document blockers and complexity\nsdd update-task-metadata {spec-id} task-2-3 \\\n  --metadata '{\"blockers\": [\"API design unclear\"], \"complexity\": \"high\"}'\n\n# Track implementation approach\nsdd update-task-metadata {spec-id} task-3-2 \\\n  --metadata '{\n    \"approach\": \"refactor existing code\",\n    \"estimated_subtasks\": 4,\n    \"dependencies\": [\"task-3-1\"]\n  }'\n```\n\n### Validation\n\nFor comprehensive spec validation, use the sdd-validate subagent:\n\n```\nTask(\n  subagent_type: \"sdd-toolkit:sdd-validate-subagent\",\n  prompt: \"Validate specs/active/{spec-id}.json\",\n  description: \"Validate spec file\"\n)\n```\n\nFor deep audits:\n\n```bash\nsdd audit-spec {spec-id}\n```\n\n## JSON Structure Reference\n\n### Task Status Values\n\n- `pending` - Not yet started\n- `in_progress` - Currently being worked on\n- `completed` - Successfully finished\n- `blocked` - Cannot proceed due to dependencies or issues\n\n### Journal Entry Structure\n\nJournal entries are stored in a top-level `journal` array:\n\n```json\n{\n  \"journal\": [\n    {\n      \"timestamp\": \"2025-10-18T14:30:00Z\",\n      \"entry_type\": \"decision\",\n      \"title\": \"Brief title\",\n      \"task_id\": \"task-1-2\",\n      \"author\": \"claude-sonnet-4.5\",\n      \"content\": \"Detailed explanation\",\n      \"metadata\": {}\n    }\n  ]\n}\n```\n\n### Verification Result Structure\n\nStored in verification task metadata:\n\n```json\n{\n  \"verify-1-1\": {\n    \"metadata\": {\n      \"verification_result\": {\n        \"date\": \"2025-10-18T16:45:00Z\",\n        \"status\": \"PASSED\",\n        \"output\": \"Command output\",\n        \"notes\": \"Additional context\"\n      }\n    }\n  }\n}\n```\n\n### Folder Structure\n\n```\nspecs/\n pending/      # Backlog - planned but not activated\n active/       # Currently being implemented\n completed/    # Finished and verified\n archived/     # Old or superseded\n```\n\n## Best Practices\n\n### When to Update\n\n- **Update immediately** - Don't wait; update status as work happens\n- **Be specific** - Vague notes aren't helpful later\n- **Document WHY** - Always explain rationale, not just what changed\n\n### Journaling\n\n- **Link to evidence** - Reference tickets, PRs, discussions\n- **Decision rationale** - Explain why decisions were made\n- **Use bulk-journal** - Efficiently document multiple completed tasks\n\n### Multi-Tool Coordination\n\n- **Read before write** - Always load latest state before updating\n- **Update your tasks only** - Don't modify other tools' work\n- **Clear handoffs** - Add journal entry when passing work to another tool\n\n### File Organization\n\n- **Clean transitions** - Move specs promptly when status changes\n- **Never rename specs** - Spec file names are based on spec_id\n- **Backup before changes** - CLI handles automatic backups\n\n## Troubleshooting\n\n### Spec File Corruption\n\n**Recovery:**\n1. Check for backup: `specs/active/{spec-id}.json.backup`\n2. If no backup, regenerate from original spec\n3. Manually mark completed tasks based on journal entries\n4. Validate repaired file\n\n### Orphaned Tasks\n\n**Resolution:**\n1. If task in file but not in spec: Check if spec was updated; remove if confirmed deleted\n2. If task in spec but not in file: Regenerate spec file using sdd-plan\n3. Always preserve completed task history even if spec changed\n\n### Merge Conflicts\n\n**When:** Multiple tools update state simultaneously\n\n**Resolution:**\n1. Load both versions\n2. Identify conflicting nodes\n3. Choose most recent update (check timestamps)\n4. Recalculate progress from leaf nodes up\n5. Validate merged state\n\n## Common Mistakes\n\n### Using `--entry-type completion`\n\n**Error:**\n```bash\nsdd add-journal: error: argument --entry-type: invalid choice: 'completion'\nExit code: 2\n```\n\n**Cause:** Confusing the `bulk-journal --template` option with `add-journal --entry-type`\n\n**Fix:** Use `--entry-type status_change` instead:\n\n```bash\n#  WRONG - \"completion\" is not a valid entry type\nsdd add-journal {spec-id} --task-id {task-id} --entry-type completion --title \"...\" --content \"...\"\n\n#  CORRECT - Use \"status_change\" for task completion entries\nsdd add-journal {spec-id} --task-id {task-id} --entry-type status_change --title \"Task Completed\" --content \"...\"\n\n#  ALTERNATIVE - Use bulk-journal with completion template\nsdd bulk-journal {spec-id} --template completion\n```\n\n**Why this happens:** The `bulk-journal` command has a `--template` parameter that accepts `completion` as a value for batch journaling. However, `add-journal` has an `--entry-type` parameter with different valid values. These are two separate parameters for different purposes:\n- `bulk-journal --template completion` - Batch journal multiple completed tasks using a template\n- `add-journal --entry-type status_change` - Add individual journal entry about task status changes\n\n### Reading Spec Files Directly\n\n**Error:** Using Read tool, cat, grep, or jq on spec files\n\n**Fix:** Always use `sdd` CLI commands:\n\n```bash\n#  WRONG - Wastes context tokens and bypasses validation\nRead(\"specs/active/my-spec.json\")\ncat specs/active/my-spec.json\n\n#  CORRECT - Use sdd CLI for structured access\nsdd status-report {spec-id}\nsdd get-task {spec-id} {task-id}\nsdd query-tasks {spec-id} --status pending\n```\n\n## Command Reference\n\n### Status Management\n- `update-status` - Change task status\n- `mark-blocked` - Mark task as blocked with reason\n- `unblock-task` - Unblock a task with resolution\n\n### Documentation\n- `add-journal` - Add journal entry to spec\n- `bulk-journal` - Add entries for multiple completed tasks\n- `check-journaling` - Detect tasks without journal entries\n- `add-verification` - Document verification results\n- `execute-verify` - Run verification task automatically\n\n### Lifecycle\n- `activate-spec` - Move spec from pending/ to active/\n- `move-spec` - Move spec between folders\n- `complete-spec` - Mark complete and move to completed/\n\n### Query & Reporting\n- `status-report` - Get progress and status summary\n- `query-tasks` - Filter tasks by status, type, or parent\n- `get-task` - Get detailed task information\n- `list-phases` - List all phases with progress\n- `list-blockers` - List all blocked tasks\n- `check-complete` - Verify if spec/phase is ready to complete\n\n### Metadata\n- `update-task-metadata` - Update task metadata fields (individual flags or JSON)\n- `update-frontmatter` - Update spec metadata fields\n- `sync-metadata` - Synchronize metadata with hierarchy\n\n### Validation\n- `validate-spec` - Check spec file consistency\n- `audit-spec` - Deep audit of spec file integrity\n\n### Common Flags\n- `--dry-run` - Preview changes without saving\n- `--verify` - Auto-run verify tasks on completion\n\n## Systematic Spec Modification\n\nFor **structural modifications** to specs (not progress tracking), use `Skill(sdd-toolkit:sdd-modify)`.\n\n### What is Systematic Spec Modification?\n\nSystematic modification applies structured changes to specs with:\n- Automatic backup before changes\n- Validation after changes\n- Transaction support with rollback\n- Preview before applying (dry-run mode)\n\n### Common Use Cases\n\n**1. Apply Review Feedback**\n\nAfter running sdd-fidelity-review or sdd-plan-review:\n\n```bash\n# Parse review feedback into structured modifications\nsdd parse-review my-spec-001 --review reports/review.md --output suggestions.json\n\n# Preview modifications\nsdd apply-modifications my-spec-001 --from suggestions.json --dry-run\n\n# Apply modifications\nsdd apply-modifications my-spec-001 --from suggestions.json\n```\n\n**2. Bulk Modifications**\n\nApply multiple structural changes at once:\n\n```bash\n# Create modifications.json with desired changes\n# (update task descriptions, add verifications, correct metadata)\n\n# Apply bulk modifications\nsdd apply-modifications my-spec-001 --from modifications.json\n```\n\n**3. Update Task Descriptions**\n\nMake task descriptions more specific based on implementation learnings:\n\n```json\n{\n  \"modifications\": [\n    {\n      \"operation\": \"update_task\",\n      \"task_id\": \"task-2-1\",\n      \"field\": \"description\",\n      \"value\": \"Implement OAuth 2.0 authentication with PKCE flow and JWT tokens\"\n    }\n  ]\n}\n```\n\n### When to Use sdd-modify\n\nUse `Skill(sdd-toolkit:sdd-modify)` when you need to:\n- Apply review feedback from sdd-fidelity-review or sdd-plan-review\n- Update task descriptions for clarity (beyond just journaling)\n- Add verification steps discovered during implementation\n- Make multiple structural changes at once\n- Ensure changes are validated and safely applied\n\n### See Also\n\n- **Skill(sdd-toolkit:sdd-modify)** - Full documentation on systematic spec modification\n- **skills/sdd-modify/examples/** - Detailed workflow examples\n- **sdd parse-review --help** - Parse review reports into modification format\n- **sdd apply-modifications --help** - Apply modifications with validation"
              },
              {
                "name": "sdd-validate",
                "description": "Validate SDD JSON specs, auto-fix common issues, generate detailed reports, and analyze dependencies.",
                "path": "skills/sdd-validate/SKILL.md",
                "frontmatter": {
                  "name": "sdd-validate",
                  "description": "Validate SDD JSON specs, auto-fix common issues, generate detailed reports, and analyze dependencies."
                },
                "content": "# Spec Validation Skill\n\n## Overview\n\nThe **Skill(sdd-toolkit:sdd-validate)** skill provides comprehensive validation for Spec-Driven Development (SDD) JSON specification files. It checks for structural consistency, auto-fixes common issues, generates detailed reports, and analyzes dependencies.\n\n**Key capabilities:**\n- Validate JSON spec structure and hierarchy integrity\n- Auto-fix 13 common issue types with preview and backup support\n- Generate detailed validation reports in Markdown or JSON\n- Calculate comprehensive spec statistics (depth, coverage, complexity)\n- Analyze dependencies (cycles, orphans, deadlocks, bottlenecks)\n- Differentiated exit codes for warnings vs errors\n- Draft 07 JSON Schema validation (installs automatically when `jsonschema` is available; run `pip install claude-skills[validation]` to enable)\n\n## Understanding Exit Codes\n\nExit codes indicate the **state of your spec**, not command success/failure:\n\n- **Exit 0**:  Spec is valid (no errors)\n- **Exit 1**:   Spec has warnings (usable but improvable)\n- **Exit 2**:  Spec has errors (needs fixing) - **THIS IS EXPECTED FOR NEW SPECS**\n- **Exit 3**:  File not found or access error (actual command failure)\n\n**Important:** Exit code 2 means \"I found errors in your spec\" not \"I failed to validate\". The validate command succeeded at detecting issues - your spec just needs work. This is the normal starting point for most specs.\n\n## When to Use This Skill\n\nUse `Skill(sdd-toolkit:sdd-validate)` to:\n- Confirm a freshly created spec parses correctly\n- Auto-fix common validation issues\n- Check for structural errors before running other SDD skills\n- Generate validation reports for review or CI/CD\n- Analyze spec statistics and dependency issues\n\n## Core Workflow\n\n1. **Validate**: `sdd validate {spec-id}` - Check for issues\n2. **Fix**: `sdd fix {spec-id}` - Auto-fix common problems (creates backup)\n3. **Re-validate**: Check for newly revealed issues\n4. **Repeat**: Continue until error count stops decreasing\n5. **Manual fixes**: Use `--verbose` for details when plateau is reached\n\n**Key concept:** Error count decreasing = keep fixing. Plateau (same count for 2+ passes) = switch to manual fixes.\n\n## Key Concepts\n\n### Always Re-validate After Fixing\nFixing issues often reveals new problems that were previously hidden. Always run `sdd validate` after `sdd fix` to see the current state.\n\n### Error Count Progression\nTrack how error count changes across passes:\n- **Decreasing** (88  23  4) - Continue auto-fixing\n- **Plateau** (4  4  4) - Switch to manual fixes with `--verbose`\n\n### When to Stop Auto-Fixing\nSwitch to manual intervention when:\n- Error count unchanged for 2+ passes\n- `sdd fix` reports \"skipped issues requiring manual intervention\"\n- All remaining issues need context or human judgment\n\n### Input Format: Spec Names vs Paths\n\nAll sdd-validate commands accept **both** spec names and paths for maximum flexibility:\n\n**Spec name (recommended):**\n```bash\nsdd validate pomodoro-timer-2025-11-18-001\n```\nAutomatically searches in `specs/pending/`, `specs/active/`, `specs/completed/`, and `specs/archived/`.\n\n**Relative path:**\n```bash\nsdd validate specs/pending/pomodoro-timer-2025-11-18-001.json\nsdd validate ../other-project/specs/active/my-spec.json\n```\n\n**Absolute path:**\n```bash\nsdd validate /full/path/to/my-spec.json\n```\n\n**Smart fallback:** If you provide a path that doesn't exist (e.g., `specs/pending/my-spec.json`), the command extracts the spec name (`my-spec`) and searches for it automatically.\n\n## Command Reference\n\n### validate\n\nValidate the JSON spec structure and print a summary.\n\n```bash\nsdd validate {spec-id} [--verbose]\n```\n\n**Flags:**\n- `--verbose` - Show detailed issue information with locations\n- `--report` - Generate validation report alongside spec\n- `--report-format {markdown,json}` - Choose report format\n\n**Exit codes:**\n- `0` - Clean validation\n- `1` - Warnings only\n- `2` - Errors detected (expected when spec has issues)\n\n**Example:**\n```bash\n$ sdd validate my-spec\n Validation found 12 errors\n   8 auto-fixable, 4 require manual intervention\n\n   Errors:\n   - 5 incorrect task count rollups\n   - 2 missing metadata blocks\n   - 1 orphaned node (task-5-3)\n   - 2 circular dependencies\n   - 2 parent/child mismatches\n\n   Run 'sdd fix my-spec' to auto-fix 8 issues\n   Use '--verbose' for detailed issue information\n```\n\n### fix\n\nAuto-fix common validation issues with preview and backup support.\n\n```bash\nsdd fix {spec-id} [--preview] [--dry-run] [--no-backup]\n```\n\n**Flags:**\n- `--preview` / `--dry-run` - Show what would be fixed without modifying files\n- `--no-backup` - Skip backup creation (use with caution)\n- `--diff` - Show before/after changes\n- `--diff-format {markdown,json}` - Choose diff format\n\n**Auto-fixable issues:**\n- Incorrect task count rollups\n- Missing metadata blocks\n- Orphaned nodes\n- Parent/child hierarchy mismatches\n- Malformed timestamps\n- Invalid status/type values\n- Bidirectional dependency inconsistencies\n\n**Selective fix application:**\n```bash\n# Apply specific fixes by ID\nsdd fix {spec-id} --select counts.recalculate\n\n# Apply all fixes in a category\nsdd fix {spec-id} --select metadata\n\n# Apply multiple specific fixes\nsdd fix {spec-id} --select counts.recalculate metadata.ensure:task-001\n```\n\n**Example:**\n```bash\n$ sdd fix my-spec --preview\n Would apply 8 fixes:\n   - Fix 5 task count rollups\n   - Add 2 metadata blocks\n   - Reconnect 1 orphaned node\n\n  Would skip 4 issues requiring manual intervention:\n   - task-3-2: Circular dependency\n   - task-5-2: Dependency references non-existent task\n\n$ sdd fix my-spec\n Applied 8 fixes\nCreated backup: my-spec.json.backup\n\n$ sdd validate my-spec\n Validation found 4 errors (manual intervention required)\n```\n\n### report\n\nGenerate a detailed validation report with stats and dependency analysis.\n\n```bash\nsdd report {spec-id} [--output <path>]\n```\n\n**Flags:**\n- `--output` - Output file path (use `-` for stdout)\n- `--bottleneck-threshold N` - Minimum tasks blocked to flag bottleneck (default: 3)\n\nReport includes: validation summary, categorized issues, statistics, and dependency findings.\n\n### stats\n\nCalculate and display comprehensive spec statistics.\n\n```bash\nsdd stats {spec-id}\n```\n\n**Shows:**\n- Node, task, phase, and verification counts\n- Status breakdown (pending, in_progress, completed, blocked)\n- Hierarchy maximum depth\n- Average tasks per phase\n- Verification coverage percentage\n- Overall progress percentage\n\n### analyze-deps\n\nAnalyze dependencies for cycles, orphans, deadlocks, and bottlenecks.\n\n**Note:** This command analyzes spec-wide dependency issues. For checking individual task dependencies, use `sdd prepare-task` from sdd-next which includes dependency details by default in `context.dependencies` (e.g., `sdd prepare-task {spec-id} {task-id}`). The standalone `sdd check-deps` command is rarely needed now.\n\n```bash\nsdd analyze-deps {spec-id} [--bottleneck-threshold N]\n```\n\n**Analyzes:**\n- **Cycles** - Circular dependency chains\n- **Orphaned** - Tasks referencing missing dependencies\n- **Deadlocks** - Tasks blocked by each other\n- **Bottlenecks** - Tasks blocking many others\n\n**Example:**\n```bash\n$ sdd analyze-deps my-spec\n  Dependency Analysis: 3 issues found\n\nCycles (2):\n  1. task-3-2  task-3-5  task-3-2\n  2. task-4-1  task-4-3  task-4-1\n\nOrphaned dependencies (1):\n  task-5-2 references non-existent \"task-2-9\"\n\nRecommendation: Fix circular dependencies first to unblock work\n```\n\n## Common Patterns\n\n### Issue  Fix Mapping\n\n- **Incorrect task counts**  Auto-fixed by recalculating from hierarchy\n- **Missing metadata**  Auto-fixed by adding empty metadata blocks\n- **Orphaned nodes**  Auto-fixed by reconnecting to parent\n- **Circular dependencies**  Requires manual fix (remove one edge)\n- **Invalid timestamps**  Auto-fixed to ISO 8601 format\n- **Parent/child mismatches**  Auto-fixed by correcting hierarchy references\n\n### Typical Fix Cycles\n\n**Most specs (2-3 passes):**\n```bash\nPass 1: 47 errors  fix  8 errors\nPass 2: 8 errors  fix  2 errors\nPass 3: 2 errors  fix  0 errors \n```\n\n**Complex specs with circular deps (4-5 passes):**\n```bash\nPass 1: 88 errors  fix  23 errors\nPass 2: 23 errors  fix  4 errors\nPass 3: 4 errors  fix  4 errors (plateau)\n Manual: Remove circular dependencies\nPass 4: Validate  0 errors \n```\n\n## Troubleshooting\n\n### Auto-fix Succeeded But Errors Remain\n\nThis is normal. `sdd fix` reports success when it applies fixes successfully, not when all issues are resolved. Fixing one problem often reveals another (e.g., fixing parent-child mismatches may reveal orphaned nodes).\n\n**Solution:** Re-validate to see remaining issues, then run fix again or address manually.\n\n### Error Count Plateau\n\nWhen error count stays the same for 2+ passes:\n\n1. Run `sdd validate {spec-id} --verbose` to see detailed issue information\n2. Identify issues marked \"requires manual intervention\"\n3. Manually fix issues that need context or human judgment\n4. Re-validate after manual fixes\n\n**Understanding Spec Requirements:**\n- Run `sdd schema` to see the complete spec structure, required fields, and valid values\n- The schema shows all field types, enum values (like `status`, `type`, `verification_type`), and optional vs required fields\n- Use this when validation errors reference unknown fields or invalid values\n\n**Common manual-only issues:**\n- Circular dependencies (remove one dependency edge)\n- Orphaned dependencies (fix task ID typos)\n- Logical inconsistencies (requires understanding spec intent)\n- Custom metadata problems\n\n### How Many Passes Are Normal?\n\n- **2-3 passes**: Typical for most specs\n- **5+ passes**: May indicate circular dependencies or structural issues\n\n**Rule:** If error count decreases each pass, keep going. If it plateaus, switch to manual.\n\n## Advanced Usage\n\n### Global Flags\n\nAvailable on all commands:\n- `--quiet` / `-q` - Suppress progress messages\n- `--verbose` / `-v` - Show detailed information"
              }
            ]
          }
        ]
      }
    }
  ]
}