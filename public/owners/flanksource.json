{
  "owner": {
    "id": "flanksource",
    "display_name": "flanksource",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/58787470?v=4",
    "url": "https://github.com/flanksource",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 3,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "flanksource/claude-code-plugin",
      "url": "https://github.com/flanksource/claude-code-plugin",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-11-21T06:41:47Z",
        "created_at": "2025-11-12T04:24:02Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 518
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 1283
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/troubleshooting-config-item",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/troubleshooting-config-item/SKILL.md",
          "type": "blob",
          "size": 5715
        },
        {
          "path": "skills/troubleshooting-health-checks",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/troubleshooting-health-checks/SKILL.md",
          "type": "blob",
          "size": 4511
        },
        {
          "path": "skills/troubleshooting-health-checks/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/troubleshooting-health-checks/reference/query-syntax.md",
          "type": "blob",
          "size": 679
        },
        {
          "path": "skills/troubleshooting-notifications",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/troubleshooting-notifications/SKILL.md",
          "type": "blob",
          "size": 8059
        }
      ],
      "marketplace": {
        "name": "flanksource-mission-control",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Flanksource Inc.",
          "email": "contact@flanksource.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "mission-control-skills",
            "description": "Collection of skills to diagnose and fix issues with mission control",
            "source": "./",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add flanksource/claude-code-plugin",
              "/plugin install mission-control-skills@flanksource-mission-control"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-11-21T06:41:47Z",
              "created_at": "2025-11-12T04:24:02Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "troubleshooting-config-items",
                "description": "Troubleshoots infrastructure and application configuration items in Mission Control by diagnosing health issues, analyzing recent changes, and investigating resource relationships. Use when users ask about unhealthy or failing resources, mention specific config items by name or ID, inquire about Kubernetes pods/deployments/services, AWS EC2 instances/volumes, Azure VMs, or other infrastructure components. Also use when investigating why a resource is down, stopped, degraded, or showing errors, or when analyzing what changed that caused an issue.",
                "path": "skills/troubleshooting-config-item/SKILL.md",
                "frontmatter": {
                  "name": "troubleshooting-config-items",
                  "description": "Troubleshoots infrastructure and application configuration items in Mission Control by diagnosing health issues, analyzing recent changes, and investigating resource relationships. Use when users ask about unhealthy or failing resources, mention specific config items by name or ID, inquire about Kubernetes pods/deployments/services, AWS EC2 instances/volumes, Azure VMs, or other infrastructure components. Also use when investigating why a resource is down, stopped, degraded, or showing errors, or when analyzing what changed that caused an issue.",
                  "allowed-tools": "search_catalog, describe_config, list_catalog_types, get_related_configs, search_catalog_changes, get_notification_detail, get_notifications_for_resource"
                },
                "content": "# Config Item Troubleshooting Skill\n\n## Core Purpose\n\nThis skill enables Claude to troubleshoot infrastructure and application configuration items in Mission Control, diagnose health issues, analyze changes, and identify root causes through systematic investigation of config relationships and history.\n\n## Understanding Config Items\n\nA **ConfigItem** represents a discoverable infrastructure or application configuration (Kubernetes Pods, AWS EC2 instances, Azure VMs, database instances, etc.). Each config item contains:\n\n- **health**: Overall health status (\"healthy\", \"unhealthy\", \"warning\", \"unknown\")\n- **status**: Operational state (e.g., \"Running\", \"Stopped\", \"Pending\")\n- **description**: Human-readable description (often contains error messages when unhealthy)\n- **.config**: The actual JSON specification/manifest (e.g., Kubernetes Pod spec, AWS instance details)\n- **type**: The kind of resource (e.g., \"Kubernetes::Pod\", \"AWS::EC2::Instance\")\n- **tags**: Metadata for filtering and organization\n- **parent_id/path**: Hierarchical relationships to other configs\n- **external_id**: External system identifier\n\n## Key Workflows\n\n### Initial Investigation\n\n**1. Search and Identify the Config**\nUse the MCP `search_catalog` tool to find the config item:\n\n- Search by id, name, type, tags, or other attributes\n- Narrow down to the specific config experiencing issues\n\n**2. Get Complete Config Details**\nUse the MCP `describe_config` tool to retrieve full config information:\n\n- Review the **health** field for overall status\n- Check the **status** field for operational state\n- Read the **description** field carefully - this often contains error messages or status information\n- Examine the **.config** JSON field - this contains the full specification/manifest\n\n### Change Analysis\n\n**3. Review Recent Changes**\nIf the issue isn't immediately apparent, use the MCP `search_catalog_changes` tool:\n\n- Get changes for the specific config item\n- Look for recent modifications to the specification\n- Check `change_type` (created, updated, deleted)\n- Review `severity` (critical, high, medium, low, info)\n- Examine `patches` and `diff` fields to see what changed\n- Check `source` to understand where the change originated\n- Note the `created_at` timestamp to correlate with when issues started\n\n### Relationship Navigation\n\n**4. Investigate Related Configs**\nUse the MCP `get_related_configs` tool to navigate the config hierarchy:\n\n- **Children**: Resources created/managed by this config\n  - Example: A Kubernetes Deployment → ReplicaSets → Pods\n  - Example: An AWS Auto Scaling Group → EC2 Instances\n- **Parents**: Resources that manage this config\n  - Example: A Pod → ReplicaSet → Deployment\n- **Dependencies**: Resources this config depends on\n  - Example: A Pod → ConfigMaps, Secrets, PersistentVolumeClaims\n\n**Troubleshooting Pattern:**\nWhen a parent resource is unhealthy, investigate its children to find the actual failing component. When a child is unhealthy, check the parent for misconfigurations.\n\n## Critical Requirements\n\n**Hierarchical Thinking:**\n\n- Kubernetes: Namespace → Deployment → ReplicaSet → Pod → Container\n- AWS: VPC → Subnet → EC2 Instance → Volume\n- Azure: Resource Group → VM → Disk\n\n**Change Impact Analysis:**\n\n- Compare current config with previous working state\n- Identify what changed and when\n- Correlate timing of changes with health degradation\n\n**Evidence-Based Diagnosis:**\n\n- Support conclusions with specific evidence from the config data\n- Quote relevant error messages from description fields\n- Reference specific fields in the .config JSON\n- Cite change diffs and timestamps\n\n## Diagnosis Workflow\n\nFollow this systematic approach:\n\n1. **Identify** - Find the config item\n2. **Assess** - Review health, status, description, and .config spec\n3. **Analyze Changes** - Check recent modifications and events\n4. **Navigate Relationships** - Investigate parent/child/dependency configs\n5. **Review Analysis** - Check automated findings\n6. **Synthesize** - Determine root cause from all evidence\n7. **Recommend** - Provide specific remediation steps\n\n## Example Troubleshooting Scenarios\n\n**Scenario 1: Unhealthy Kubernetes Deployment**\n\n- Get Deployment details → health: unhealthy\n- Get related configs (children) → ReplicaSets → Pods\n- Find Pod in CrashLoopBackOff\n- Check Pod .config → image pull error\n- Check changes → recent image tag update\n- Root cause: Invalid image tag deployed\n- Recommendation: Rollback to previous image or fix image tag\n\n**Scenario 2: AWS EC2 Instance Issues**\n\n- Get Instance details → status: stopped, health: unhealthy\n- Check description → \"InsufficientInstanceCapacity\"\n- Review changes → instance type changed to unavailable type\n- Get related configs → Security Groups, Volumes\n- Root cause: Requested instance type not available in AZ\n- Recommendation: Change to available instance type or different AZ"
              },
              {
                "name": "troubleshooting-health-checks",
                "description": "Debugs and troubleshoots Mission Control health checks by analyzing check configurations, reviewing failure patterns, and identifying root causes. Use when users ask about failing health checks, mention specific health check names or IDs, inquire why a health check is failing or unhealthy, or need help understanding health check errors and timeouts.",
                "path": "skills/troubleshooting-health-checks/SKILL.md",
                "frontmatter": {
                  "name": "troubleshooting-health-checks",
                  "description": "Debugs and troubleshoots Mission Control health checks by analyzing check configurations, reviewing failure patterns, and identifying root causes. Use when users ask about failing health checks, mention specific health check names or IDs, inquire why a health check is failing or unhealthy, or need help understanding health check errors and timeouts.",
                  "allowed-tools": "search_health_checks, get_check_status, run_health_check, list_all_checks, search_catalog, describe_config, search_catalog_changes"
                },
                "content": "# Health Check Troubleshooting Skill\n\n## Core Purpose\n\nThis skill enables Claude to troubleshoot Mission Control health checks by analyzing check configurations, diagnosing failure patterns, identifying timeout and error root causes, and recommending configuration adjustments to improve reliability.\n\nNote: Read @skills/troubleshooting-health-checks/reference/query-syntax.md to for query syntax\n\n## Health check troubleshooting workflow\n\nCopy this checklist and track your progress:\n\n```\nTroubleshooting Progress:\n- [ ] Step 1: Gather health check information\n- [ ] Step 2: Analyze failure patterns\n- [ ] Step 3: Cross-reference configuration issues\n- [ ] Step 4: Create diagnostic summary\n- [ ] Step 5: Verify remediation steps\n```\n\n## Gather health check information\n\nTo begin with, get the id of the check in question.\nUse `search_health_checks` with query syntax to find checks. Read @skills/troubleshooting-health-checks/reference/query-syntax.md to for query syntax\nElse, if you could not get the health check Id from the user provided name, use `list_all_checks` to get complete metadata for all health checks .\n\nThen, follow this procedure:\n\n- **Historical Context**: Use `get_check_status` to retrieve execution history\n- **Investigate the check specification**: Understand the intention of the check.\n- **Investiagte the chagnes to the canray**: Use `search_catalog_changes(<canary_uuid>)` to get the changes on the canary.\n  Look for the change details to see any new changes on the specification.\n\n## Analyze failure patterns\n\nExamine the historical data to identify patterns. Look for:\n\n- **Intermittent failures**: Passes sometimes, fails others\n  - Suggests: Network instability, load-related issues, race conditions\n- **Consistent failures**: Always failing\n  - Suggests: Configuration error, endpoint down, authentication issue\n- **Recent pattern changes**: Was passing, now failing\n  - Suggests: Recent deployment, config change, infrastructure change\n- **Timeout patterns**: Fails with timeout errors\n  - Suggests: Performance degradation, insufficient timeout value\n- **Time-based patterns**: Fails at specific times\n  - Suggests: Scheduled jobs, traffic patterns, resource contention\n\nDuration analysis:\n\n- Increasing duration → Performance degrading (may lead to timeouts)\n- Spiky duration → Intermittent load or resource contention\n- Consistent slow duration → Timeout threshold too aggressive\n\n## Create diagnostic summary\n\nOrganize findings systematically. Include:\n\n- **Primary diagnosis**\n\n  - Root cause identification with supporting evidence\n  - Quote specific error messages from last_result\n  - Reference historical pattern statistics\n  - Cite configuration values that contribute to the issue\n\n- **Contributing factors**\n\n  - Secondary issues that may worsen the problem\n  - Environmental factors (network, infrastructure)\n  - Configuration mismatches\n\n- **Impact assessment**\n  - How long has the issue persisted\n  - Frequency and severity of failures\n  - Potential downstream effects\n\nExample diagnostic format:\n\n> The health check \"api-status\" (ID: check-123) is failing based on `get_check_status` history showing error \"timeout exceeded\" in recent executions. Historical data shows duration increasing from 3s to 5s over 6 hours. This indicates backend performance degradation requiring investigation and potential timeout adjustment.\n\n## Verify remediation steps\n\nProvide and validate specific fixes. For each recommendation:\n\n- Use `run_health_check` to test fixes immediately\n- Verify check passes after configuration changes\n- Monitor execution duration and response\n\n## Success criteria checklist\n\nBefore completing troubleshooting:\n\n- [ ] Health check configuration fully analyzed\n- [ ] Failure pattern clearly identified with evidence\n- [ ] Root cause diagnosed with supporting data\n- [ ] Specific remediation steps provided\n- [ ] Configuration adjustments justified\n- [ ] Validation approach included"
              },
              {
                "name": "troubleshooting-notifications",
                "description": "Investigates Mission Control notifications to identify root causes and provide remediation. Use when users mention notification IDs, ask about alerts or notifications, request help understanding \"why did I get this notification\", want to troubleshoot a specific alert, or ask about notification patterns and history. This skill retrieves notification details, analyzes historical patterns, routes to resource-specific troubleshooting (config items or health checks), correlates findings, and delivers actionable remediation steps with prevention recommendations.",
                "path": "skills/troubleshooting-notifications/SKILL.md",
                "frontmatter": {
                  "name": "troubleshooting-notifications",
                  "description": "Investigates Mission Control notifications to identify root causes and provide remediation. Use when users mention notification IDs, ask about alerts or notifications, request help understanding \"why did I get this notification\", want to troubleshoot a specific alert, or ask about notification patterns and history. This skill retrieves notification details, analyzes historical patterns, routes to resource-specific troubleshooting (config items or health checks), correlates findings, and delivers actionable remediation steps with prevention recommendations.",
                  "allowed-tools": "get_notification_detail, get_notifications_for_resource"
                },
                "content": "# Notification Troubleshooting Skill\n\n## When to Invoke This Skill\n\nInvoke this skill when users:\n\n- Mention a specific notification ID or title\n- Ask to investigate or troubleshoot a notification\n- Ask \"why did I get this alert/notification\"\n- Request help understanding a Mission Control notification\n- Ask about notification history or patterns\n\n## Core Purpose\n\nThis skill enables Claude to investigate Mission Control notifications, trace them to their root cause, and provide actionable remediation steps by systematically analyzing notification details, resource context, and historical patterns.\n\n## Understanding Notifications\n\nA **Notification** represents an alert or event triggered by Mission Control when a resource experiences issues or state changes. Each notification contains:\n\n- **id**: Unique identifier for the notification\n- **title**: Short summary of the notification\n- **message**: Detailed description of what triggered the notification\n- **severity**: Alert level (critical, error, warning, info)\n- **resource_id**: ID of the affected resource\n- **resource_type**: Type of resource (\"ConfigItem\", \"HealthCheck\", etc.)\n- **created_at**: When the notification was created\n- **status**: Current status (active, resolved, acknowledged)\n\n## Systematic Troubleshooting Workflow\n\nFollow this step-by-step approach:\n\n### Step 1: Retrieve Notification Details\n\n**CALL** `get_notification_detail` with the notification ID\n\n**OBSERVE** the response and extract:\n\n- `title` and `message` - what is the alert about?\n- `severity` - how critical is this?\n- `resource_id` and `resource_type` - what resource is affected?\n- `created_at` - when did this start?\n- `status` - is this still active?\n\n**ANALYZE** the message field carefully - it often contains:\n\n- Error messages or stack traces\n- Threshold violations\n- State transition information\n- Specific failure reasons\n\n### Step 2: Analyze Notification History\n\n**CALL** `get_notifications_for_resource` for the affected resource\n\n**LOOK FOR** patterns:\n\n- **Recurring notifications**: Same issue happening repeatedly\n- **Frequency changes**: Issue getting worse or better\n- **Event correlation**: Multiple related notifications around same time\n- **Resolution patterns**: What changed when past notifications resolved\n\n**IDENTIFY** if this is:\n\n- A new issue (first occurrence)\n- A recurring problem (happened before)\n- Part of a larger incident (multiple resources affected)\n\n### Step 3: Route to Resource-Specific Troubleshooting\n\nBased on `resource_type`, invoke the appropriate skill:\n\n**IF** `resource_type == \"ConfigItem\"`:\n\n```\nCALL Skill tool with skill=\"mission-control-skills:config_item\"\nPROVIDE the resource_id and context from notification\n```\n\n**IF** `resource_type == \"HealthCheck\"`:\n\n```\nCALL Skill tool with skill=\"mission-control-skills:health\"\nPROVIDE the resource_id and context from notification\n```\n\n**The invoked skill will**:\n\n- Investigate the specific resource\n- Analyze current state and changes\n- Identify root cause\n- Provide remediation steps\n\n### Step 4: Correlate Findings\n\n**SYNTHESIZE** information from:\n\n1. Notification message and severity\n2. Historical notification patterns\n3. Resource-level investigation findings\n4. Timing of events and changes\n\n**DETERMINE**:\n\n- Root cause of the notification\n- Why it triggered at this specific time\n- Whether issue is ongoing or resolved\n- Related resources that may be affected\n\n### Step 5: Provide Recommendations\n\n**DELIVER**:\n\n1. **Root Cause**: Clear explanation of what went wrong\n2. **Evidence**: Specific data points supporting the diagnosis\n3. **Remediation**: Step-by-step actions to resolve\n4. **Prevention**: How to avoid this notification in the future\n\n## Common Notification Scenarios\n\n### Scenario 1: Config Item Unhealthy Notification\n\n```\n1. GET notification details\n   → severity: error\n   → message: \"ConfigItem kubernetes/prod/api-deployment is unhealthy\"\n   → resource_type: ConfigItem\n   → resource_id: \"config-123\"\n\n2. GET notification history for config-123\n   → 3 similar notifications in past 24h\n   → Pattern: recurring every 4 hours\n\n3. INVOKE config_item skill with resource_id\n   → Skill finds: Pod CrashLoopBackOff\n   → Root cause: OOMKilled - memory limit too low\n\n4. SYNTHESIZE findings\n   → Notification triggered by health check failure\n   → Recurring because pod keeps restarting\n   → Memory limit increased 3 days ago (from changes)\n\n5. RECOMMEND\n   → Increase memory limit from 512Mi to 1Gi\n   → Monitor for next hour to confirm resolution\n   → Set alert threshold higher to avoid false positives\n```\n\n### Scenario 2: Health Check Failure Notification\n\n```\n1. GET notification details\n   → severity: critical\n   → message: \"Database connection timeout\"\n   → resource_type: HealthCheck\n   → resource_id: \"hc-456\"\n\n2. GET notification history for hc-456\n   → First occurrence - new issue\n   → No previous failures for this check\n\n3. INVOKE health skill with resource_id\n   → Skill finds: Network policy blocking connection\n   → Changed 30 minutes ago\n\n4. SYNTHESIZE findings\n   → New network policy deployed\n   → Blocks egress to database port\n   → Health check can't reach database\n\n5. RECOMMEND\n   → Update network policy to allow database traffic\n   → Test health check manually after fix\n   → Review change approval process\n```\n\n## Error Handling\n\n**IF** `get_notification_detail` returns not found:\n\n- Verify notification ID is correct\n- Check if user has permissions to view notification\n- Ask user to confirm the notification ID\n\n**IF** `resource_id` is null or missing:\n\n- Notification may be system-level (not resource-specific)\n- Analyze message for manual troubleshooting clues\n- Search for related notifications in same timeframe\n\n**IF** `resource_type` is not ConfigItem or HealthCheck:\n\n- Investigate the resource type directly\n- Use general troubleshooting principles\n- Document findings and ask for guidance\n\n**IF** notification history is empty:\n\n- This is a new type of issue\n- Focus more on recent changes\n- Less context available for pattern analysis\n\n## Critical Requirements\n\n**Evidence-Based Analysis**:\n\n- Quote specific error messages from notification\n- Reference timestamps and correlation\n- Support conclusions with data from tools\n\n**Hierarchical Investigation**:\n\n- Start with notification (symptom)\n- Trace to resource (source)\n- Navigate relationships (context)\n- Identify change (cause)\n\n**Actionable Remediation**:\n\n- Provide specific commands or actions\n- Explain why each step will help\n- Include validation steps\n- Consider prevention measures\n\n## Skill Invocation Pattern\n\nWhen routing to other skills, use this format:\n\n```markdown\nBased on the notification for resource_type=\"ConfigItem\", I'm now invoking the config_item troubleshooting skill to investigate the underlying resource.\n\n[CALL Skill tool with skill=\"mission-control-skills:config_item\"]\n\n[After skill returns]\nThe config_item skill has identified: [summarize findings]\nCombined with the notification history showing [pattern], the root cause is [diagnosis].\n```\n\n## Key Success Criteria\n\n✓ Notification context fully understood\n✓ Historical patterns analyzed\n✓ Appropriate skill invoked for resource type\n✓ Root cause identified with evidence\n✓ Clear remediation steps provided\n✓ Prevention recommendations included"
              }
            ]
          }
        ]
      }
    }
  ]
}