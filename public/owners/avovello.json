{
  "owner": {
    "id": "avovello",
    "display_name": "Volodymyr Bezuhlyi",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/2870210?v=4",
    "url": "https://github.com/avovello",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 14,
      "total_commands": 18,
      "total_skills": 0,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "avovello/cc-plugins",
      "url": "https://github.com/avovello/cc-plugins",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-04T11:54:07Z",
        "created_at": "2025-11-05T06:15:26Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 7859
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 8015
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1093
        },
        {
          "path": "QUICKSTART.md",
          "type": "blob",
          "size": 7809
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 13915
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-integration/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-integration/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 279
        },
        {
          "path": "plugins/ai-integration/README.md",
          "type": "blob",
          "size": 3049
        },
        {
          "path": "plugins/ai-integration/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-integration/agents/embedding-generator.md",
          "type": "blob",
          "size": 455
        },
        {
          "path": "plugins/ai-integration/agents/llm-integrator.md",
          "type": "blob",
          "size": 552
        },
        {
          "path": "plugins/ai-integration/agents/ml-pipeline-builder.md",
          "type": "blob",
          "size": 433
        },
        {
          "path": "plugins/ai-integration/agents/model-evaluator.md",
          "type": "blob",
          "size": 426
        },
        {
          "path": "plugins/ai-integration/agents/prompt-optimizer.md",
          "type": "blob",
          "size": 490
        },
        {
          "path": "plugins/ai-integration/agents/rag-implementer.md",
          "type": "blob",
          "size": 555
        },
        {
          "path": "plugins/ai-integration/agents/vector-db-configurator.md",
          "type": "blob",
          "size": 439
        },
        {
          "path": "plugins/ai-integration/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-integration/commands/ai-integration.md",
          "type": "blob",
          "size": 2527
        },
        {
          "path": "plugins/audit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/audit/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/audit/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 300
        },
        {
          "path": "plugins/audit/README.md",
          "type": "blob",
          "size": 4935
        },
        {
          "path": "plugins/audit/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/audit/agents/dependency-analyzer.md",
          "type": "blob",
          "size": 4037
        },
        {
          "path": "plugins/audit/agents/documentation-generator.md",
          "type": "blob",
          "size": 8998
        },
        {
          "path": "plugins/audit/agents/pattern-detector.md",
          "type": "blob",
          "size": 9392
        },
        {
          "path": "plugins/audit/agents/structure-mapper.md",
          "type": "blob",
          "size": 3426
        },
        {
          "path": "plugins/audit/agents/tech-debt-assessor.md",
          "type": "blob",
          "size": 9941
        },
        {
          "path": "plugins/audit/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/audit/commands/audit.md",
          "type": "blob",
          "size": 2304
        },
        {
          "path": "plugins/bugfix",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/bugfix/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/bugfix/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 292
        },
        {
          "path": "plugins/bugfix/README.md",
          "type": "blob",
          "size": 1363
        },
        {
          "path": "plugins/bugfix/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/bugfix/agents/bug-reproducer.md",
          "type": "blob",
          "size": 9484
        },
        {
          "path": "plugins/bugfix/agents/fix-implementer.md",
          "type": "blob",
          "size": 4147
        },
        {
          "path": "plugins/bugfix/agents/fix-planner.md",
          "type": "blob",
          "size": 7758
        },
        {
          "path": "plugins/bugfix/agents/fix-tester.md",
          "type": "blob",
          "size": 2566
        },
        {
          "path": "plugins/bugfix/agents/impact-assessor.md",
          "type": "blob",
          "size": 6199
        },
        {
          "path": "plugins/bugfix/agents/regression-tester.md",
          "type": "blob",
          "size": 2850
        },
        {
          "path": "plugins/bugfix/agents/root-cause-analyst.md",
          "type": "blob",
          "size": 9238
        },
        {
          "path": "plugins/bugfix/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/bugfix/commands/bugfix.md",
          "type": "blob",
          "size": 1196
        },
        {
          "path": "plugins/deploy",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/deploy/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/deploy/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 268
        },
        {
          "path": "plugins/deploy/README.md",
          "type": "blob",
          "size": 1428
        },
        {
          "path": "plugins/deploy/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/deploy/agents/ci-cd-configurator.md",
          "type": "blob",
          "size": 1809
        },
        {
          "path": "plugins/deploy/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/deploy/commands/deploy.md",
          "type": "blob",
          "size": 2324
        },
        {
          "path": "plugins/document",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 296
        },
        {
          "path": "plugins/document/README.md",
          "type": "blob",
          "size": 2208
        },
        {
          "path": "plugins/document/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document/agents/api-documenter.md",
          "type": "blob",
          "size": 462
        },
        {
          "path": "plugins/document/agents/architecture-documenter.md",
          "type": "blob",
          "size": 390
        },
        {
          "path": "plugins/document/agents/diagram-creator.md",
          "type": "blob",
          "size": 336
        },
        {
          "path": "plugins/document/agents/doc-consistency-checker.md",
          "type": "blob",
          "size": 309
        },
        {
          "path": "plugins/document/agents/example-generator.md",
          "type": "blob",
          "size": 298
        },
        {
          "path": "plugins/document/agents/onboarding-guide-creator.md",
          "type": "blob",
          "size": 355
        },
        {
          "path": "plugins/document/agents/runbook-writer.md",
          "type": "blob",
          "size": 314
        },
        {
          "path": "plugins/document/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document/commands/document.md",
          "type": "blob",
          "size": 1990
        },
        {
          "path": "plugins/feature-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-development/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-development/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 415
        },
        {
          "path": "plugins/feature-development/README.md",
          "type": "blob",
          "size": 7739
        },
        {
          "path": "plugins/feature-development/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-development/agents/code-architect.md",
          "type": "blob",
          "size": 12379
        },
        {
          "path": "plugins/feature-development/agents/code-explorer.md",
          "type": "blob",
          "size": 6839
        },
        {
          "path": "plugins/feature-development/agents/code-reviewer.md",
          "type": "blob",
          "size": 7705
        },
        {
          "path": "plugins/feature-development/agents/implementation-documenter.md",
          "type": "blob",
          "size": 16363
        },
        {
          "path": "plugins/feature-development/agents/test-runner.md",
          "type": "blob",
          "size": 8232
        },
        {
          "path": "plugins/feature-development/agents/test-writer.md",
          "type": "blob",
          "size": 25223
        },
        {
          "path": "plugins/feature-development/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-development/commands/feature.md",
          "type": "blob",
          "size": 9657
        },
        {
          "path": "plugins/feature-development/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-development/skills/clarifying-questions.md",
          "type": "blob",
          "size": 6087
        },
        {
          "path": "plugins/feature-development/skills/clean-architecture.md",
          "type": "blob",
          "size": 11224
        },
        {
          "path": "plugins/feature-development/skills/design-patterns.md",
          "type": "blob",
          "size": 12794
        },
        {
          "path": "plugins/feature-development/skills/domain-driven-design.md",
          "type": "blob",
          "size": 12030
        },
        {
          "path": "plugins/feature-development/skills/review-loop.md",
          "type": "blob",
          "size": 2959
        },
        {
          "path": "plugins/feature-development/skills/solid-principles.md",
          "type": "blob",
          "size": 7570
        },
        {
          "path": "plugins/feature-development/skills/testing-loop.md",
          "type": "blob",
          "size": 2762
        },
        {
          "path": "plugins/harden",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/harden/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/harden/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 288
        },
        {
          "path": "plugins/harden/README.md",
          "type": "blob",
          "size": 2957
        },
        {
          "path": "plugins/harden/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/harden/agents/auth-hardener.md",
          "type": "blob",
          "size": 1494
        },
        {
          "path": "plugins/harden/agents/compliance-checker.md",
          "type": "blob",
          "size": 905
        },
        {
          "path": "plugins/harden/agents/penetration-tester.md",
          "type": "blob",
          "size": 793
        },
        {
          "path": "plugins/harden/agents/secrets-manager.md",
          "type": "blob",
          "size": 1208
        },
        {
          "path": "plugins/harden/agents/security-config-auditor.md",
          "type": "blob",
          "size": 733
        },
        {
          "path": "plugins/harden/agents/security-header-configurator.md",
          "type": "blob",
          "size": 781
        },
        {
          "path": "plugins/harden/agents/vulnerability-scanner.md",
          "type": "blob",
          "size": 9727
        },
        {
          "path": "plugins/harden/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/harden/commands/harden.md",
          "type": "blob",
          "size": 8821
        },
        {
          "path": "plugins/migrate",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/migrate/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/migrate/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 260
        },
        {
          "path": "plugins/migrate/README.md",
          "type": "blob",
          "size": 1686
        },
        {
          "path": "plugins/migrate/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/migrate/agents/migration-planner.md",
          "type": "blob",
          "size": 1921
        },
        {
          "path": "plugins/migrate/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/migrate/commands/migrate.md",
          "type": "blob",
          "size": 16690
        },
        {
          "path": "plugins/optimize",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/optimize/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/optimize/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 280
        },
        {
          "path": "plugins/optimize/README.md",
          "type": "blob",
          "size": 11294
        },
        {
          "path": "plugins/optimize/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/optimize/agents/benchmark-validator.md",
          "type": "blob",
          "size": 13014
        },
        {
          "path": "plugins/optimize/agents/bottleneck-identifier.md",
          "type": "blob",
          "size": 12424
        },
        {
          "path": "plugins/optimize/agents/cache-strategist.md",
          "type": "blob",
          "size": 15657
        },
        {
          "path": "plugins/optimize/agents/code-optimizer.md",
          "type": "blob",
          "size": 12191
        },
        {
          "path": "plugins/optimize/agents/load-tester.md",
          "type": "blob",
          "size": 11726
        },
        {
          "path": "plugins/optimize/agents/performance-profiler.md",
          "type": "blob",
          "size": 10322
        },
        {
          "path": "plugins/optimize/agents/query-optimizer.md",
          "type": "blob",
          "size": 9790
        },
        {
          "path": "plugins/optimize/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/optimize/commands/optimize.md",
          "type": "blob",
          "size": 14257
        },
        {
          "path": "plugins/prototype",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prototype/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prototype/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 270
        },
        {
          "path": "plugins/prototype/README.md",
          "type": "blob",
          "size": 2408
        },
        {
          "path": "plugins/prototype/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prototype/agents/ab-test-setup.md",
          "type": "blob",
          "size": 296
        },
        {
          "path": "plugins/prototype/agents/cleanup-agent.md",
          "type": "blob",
          "size": 286
        },
        {
          "path": "plugins/prototype/agents/decision-synthesizer.md",
          "type": "blob",
          "size": 319
        },
        {
          "path": "plugins/prototype/agents/experiment-planner.md",
          "type": "blob",
          "size": 344
        },
        {
          "path": "plugins/prototype/agents/quick-implementer.md",
          "type": "blob",
          "size": 372
        },
        {
          "path": "plugins/prototype/agents/results-analyzer.md",
          "type": "blob",
          "size": 320
        },
        {
          "path": "plugins/prototype/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prototype/commands/prototype.md",
          "type": "blob",
          "size": 1864
        },
        {
          "path": "plugins/qa",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/qa/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/qa/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 322
        },
        {
          "path": "plugins/qa/README.md",
          "type": "blob",
          "size": 3069
        },
        {
          "path": "plugins/qa/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/qa/agents/browser-tester.md",
          "type": "blob",
          "size": 7376
        },
        {
          "path": "plugins/qa/agents/test-runner.md",
          "type": "blob",
          "size": 7855
        },
        {
          "path": "plugins/qa/agents/test-writer.md",
          "type": "blob",
          "size": 12936
        },
        {
          "path": "plugins/qa/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/qa/commands/e2e.md",
          "type": "blob",
          "size": 2376
        },
        {
          "path": "plugins/qa/commands/integration.md",
          "type": "blob",
          "size": 2694
        },
        {
          "path": "plugins/qa/commands/qa.md",
          "type": "blob",
          "size": 2235
        },
        {
          "path": "plugins/qa/commands/unit.md",
          "type": "blob",
          "size": 2296
        },
        {
          "path": "plugins/qa/commands/write-tests.md",
          "type": "blob",
          "size": 3498
        },
        {
          "path": "plugins/qa/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/qa/skills/e2e-testing.md",
          "type": "blob",
          "size": 1924
        },
        {
          "path": "plugins/qa/skills/integration-testing.md",
          "type": "blob",
          "size": 3033
        },
        {
          "path": "plugins/qa/skills/unit-testing.md",
          "type": "blob",
          "size": 2239
        },
        {
          "path": "plugins/refactor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/refactor/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/refactor/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 267
        },
        {
          "path": "plugins/refactor/README.md",
          "type": "blob",
          "size": 9160
        },
        {
          "path": "plugins/refactor/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/refactor/agents/code-modernizer.md",
          "type": "blob",
          "size": 1500
        },
        {
          "path": "plugins/refactor/agents/complexity-reducer.md",
          "type": "blob",
          "size": 11671
        },
        {
          "path": "plugins/refactor/agents/debt-prioritizer.md",
          "type": "blob",
          "size": 11607
        },
        {
          "path": "plugins/refactor/agents/dependency-updater.md",
          "type": "blob",
          "size": 2369
        },
        {
          "path": "plugins/refactor/agents/duplication-eliminator.md",
          "type": "blob",
          "size": 5306
        },
        {
          "path": "plugins/refactor/agents/refactor-validator.md",
          "type": "blob",
          "size": 5720
        },
        {
          "path": "plugins/refactor/agents/test-preserver.md",
          "type": "blob",
          "size": 1610
        },
        {
          "path": "plugins/refactor/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/refactor/commands/refactor.md",
          "type": "blob",
          "size": 11907
        },
        {
          "path": "plugins/research",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/research/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/research/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 288
        },
        {
          "path": "plugins/research/README.md",
          "type": "blob",
          "size": 746
        },
        {
          "path": "plugins/research/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/research/agents/ecosystem-evaluator.md",
          "type": "blob",
          "size": 2831
        },
        {
          "path": "plugins/research/agents/feature-comparator.md",
          "type": "blob",
          "size": 4997
        },
        {
          "path": "plugins/research/agents/information-gatherer.md",
          "type": "blob",
          "size": 5808
        },
        {
          "path": "plugins/research/agents/performance-evaluator.md",
          "type": "blob",
          "size": 3676
        },
        {
          "path": "plugins/research/agents/recommendation-synthesizer.md",
          "type": "blob",
          "size": 3707
        },
        {
          "path": "plugins/research/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/research/commands/research.md",
          "type": "blob",
          "size": 1160
        },
        {
          "path": "plugins/review",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/review/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/review/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 309
        },
        {
          "path": "plugins/review/README.md",
          "type": "blob",
          "size": 4368
        },
        {
          "path": "plugins/review/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/review/agents/architect-reviewer.md",
          "type": "blob",
          "size": 7051
        },
        {
          "path": "plugins/review/agents/backend-bash-reviewer.md",
          "type": "blob",
          "size": 312
        },
        {
          "path": "plugins/review/agents/backend-go-reviewer.md",
          "type": "blob",
          "size": 288
        },
        {
          "path": "plugins/review/agents/backend-nodejs-reviewer.md",
          "type": "blob",
          "size": 315
        },
        {
          "path": "plugins/review/agents/backend-php-reviewer.md",
          "type": "blob",
          "size": 9161
        },
        {
          "path": "plugins/review/agents/backend-python-reviewer.md",
          "type": "blob",
          "size": 302
        },
        {
          "path": "plugins/review/agents/devops-cicd-reviewer.md",
          "type": "blob",
          "size": 268
        },
        {
          "path": "plugins/review/agents/devops-docker-reviewer.md",
          "type": "blob",
          "size": 282
        },
        {
          "path": "plugins/review/agents/devops-kubernetes-reviewer.md",
          "type": "blob",
          "size": 275
        },
        {
          "path": "plugins/review/agents/frontend-css-reviewer.md",
          "type": "blob",
          "size": 307
        },
        {
          "path": "plugins/review/agents/frontend-html-reviewer.md",
          "type": "blob",
          "size": 289
        },
        {
          "path": "plugins/review/agents/frontend-react-reviewer.md",
          "type": "blob",
          "size": 302
        },
        {
          "path": "plugins/review/agents/frontend-vue-reviewer.md",
          "type": "blob",
          "size": 301
        },
        {
          "path": "plugins/review/agents/performance-algorithm-reviewer.md",
          "type": "blob",
          "size": 347
        },
        {
          "path": "plugins/review/agents/performance-database-reviewer.md",
          "type": "blob",
          "size": 315
        },
        {
          "path": "plugins/review/agents/performance-resource-reviewer.md",
          "type": "blob",
          "size": 321
        },
        {
          "path": "plugins/review/agents/security-authentication-reviewer.md",
          "type": "blob",
          "size": 596
        },
        {
          "path": "plugins/review/agents/security-crypto-reviewer.md",
          "type": "blob",
          "size": 585
        },
        {
          "path": "plugins/review/agents/security-input-reviewer.md",
          "type": "blob",
          "size": 7318
        },
        {
          "path": "plugins/review/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/review/commands/review.md",
          "type": "blob",
          "size": 6202
        }
      ],
      "marketplace": {
        "name": "cc-plugins",
        "version": "0.2.0",
        "description": null,
        "owner_info": {
          "name": "Claude Code Marketplace Contributors",
          "email": "noreply@anthropic.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "audit",
            "description": "Internal codebase audit for legacy code analysis, architecture documentation, technical debt assessment, and dependency mapping",
            "source": "./plugins/audit",
            "category": "analysis",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install audit@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/audit",
                "description": "Internal codebase audit for architecture understanding, technical debt assessment, and dependency analysis",
                "path": "plugins/audit/commands/audit.md",
                "frontmatter": {
                  "description": "Internal codebase audit for architecture understanding, technical debt assessment, and dependency analysis"
                },
                "content": "# Audit Command\n\n**Purpose**: Internal codebase audit for architecture understanding, technical debt assessment, and dependency analysis\n\n## Workflow\n\n### Step 1: Validate Target\n\n- Check that target directory exists\n- Determine if it's a full codebase or specific component\n- Identify project type (Node.js, Python, PHP, Go, etc.)\n\n### Step 2: Launch Parallel Auditors\n\nStart 5 specialized agents in parallel:\n\n1. **structure-mapper**: Map directory structure and organization\n2. **dependency-analyzer**: Analyze external dependencies\n3. **pattern-detector**: Identify code patterns and conventions\n4. **tech-debt-assessor**: Assess technical debt and code smells\n5. **documentation-generator**: (waits for others, runs last)\n\nEach agent operates independently and returns their findings.\n\n### Step 3: Consolidate Findings\n\nMerge outputs from all agents:\n- Structure map from structure-mapper\n- Dependency analysis from dependency-analyzer\n- Pattern inventory from pattern-detector\n- Tech debt report from tech-debt-assessor\n\n### Step 4: Generate Documentation\n\nInvoke **documentation-generator** with consolidated findings to create:\n- `ARCHITECTURE.md` - System architecture overview\n- `COMPONENTS.md` - Component documentation\n- `DEPENDENCIES.md` - Dependency analysis\n- `TECHNICAL_DEBT.md` - Tech debt assessment\n- `AUDIT_REPORT.md` - Complete audit summary\n\n### Step 5: Present Findings\n\nCreate final summary report highlighting:\n- Key architectural insights\n- Critical technical debt items\n- Recommended next steps\n- Onboarding guide for new developers\n\n## Output Format\n\nThe audit produces:\n\n```\naudit-output/\n├── ARCHITECTURE.md\n├── COMPONENTS.md\n├── DEPENDENCIES.md\n├── TECHNICAL_DEBT.md\n└── AUDIT_REPORT.md\n```\n\nEach file contains structured, actionable information about YOUR codebase.\n\n## Usage\n\n```bash\n/audit \"target/directory\"\n```\n\nOr for full codebase:\n\n```bash\n/audit\n```\n\n## Notes\n\n- Audit is read-only (no code changes)\n- Analyzes INTERNAL code (your existing codebase)\n- Focus is on understanding what you have, not evaluating external options\n- All outputs are in markdown format\n- Findings are fact-based, not opinionated"
              }
            ],
            "skills": []
          },
          {
            "name": "research",
            "description": "Technology research, API exploration, and best practices discovery with comparative analysis and recommendations",
            "source": "./plugins/research",
            "category": "analysis",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install research@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/research",
                "description": "Technology research, API exploration, and best practices discovery with comparative analysis",
                "path": "plugins/research/commands/research.md",
                "frontmatter": {
                  "description": "Technology research, API exploration, and best practices discovery with comparative analysis"
                },
                "content": "# Research Command\n\n**Purpose**: Technology research, API exploration, and best practices discovery with comparative analysis\n\n## Workflow\n\n1. **Define Research Scope**: Clarify what needs to be researched\n2. **Gather Information**: Collect data about each option (5 agents in parallel)\n3. **Compare Features**: Create comparison matrices\n4. **Evaluate Performance**: Assess performance characteristics\n5. **Evaluate Ecosystem**: Check community, maintenance, resources\n6. **Synthesize Recommendation**: Generate final recommendation with reasoning\n\n## Specialized Agents\n- information-gatherer: Collects raw information\n- feature-comparator: Compares features side-by-side\n- performance-evaluator: Evaluates performance and scalability\n- ecosystem-evaluator: Assesses community and maintenance\n- recommendation-synthesizer: Creates final recommendation\n\n## Usage\n```bash\n/research \"Compare React vs Vue vs Svelte for dashboard app\"\n```\n\n## Output\n- RESEARCH_REPORT.md with comparison and recommendation\n- REFERENCES.md with links and resources"
              }
            ],
            "skills": []
          },
          {
            "name": "feature-development",
            "description": "Systematic feature development with 7-phase workflow: discovery, exploration, clarifying questions, architecture design (SOLID, Clean Architecture, Design Patterns, DDD), implementation, QA-DEV-REVIEW loops, and summary",
            "source": "./plugins/feature-development",
            "category": "development",
            "version": "1.2.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install feature-development@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/feature",
                "description": "Systematic 7-phase feature development with architecture design (SOLID, Clean Architecture, Design Patterns, DDD) and QA-DEV-REVIEW loops",
                "path": "plugins/feature-development/commands/feature.md",
                "frontmatter": {
                  "description": "Systematic 7-phase feature development with architecture design (SOLID, Clean Architecture, Design Patterns, DDD) and QA-DEV-REVIEW loops"
                },
                "content": "# Feature Development Command\n\n**Purpose**: Systematic feature development with deep codebase understanding, clarifying questions, multiple architecture options, and automated QA-DEV-REVIEW loops.\n\n## Usage\n\n```bash\n/feature \"Add user authentication with OAuth2\"\n\n# With E2E browser testing for UI features\n/feature \"Add shopping cart UI\" --e2e\n```\n\n## The 7-Phase Workflow\n\nThis command guides you through a comprehensive feature development process that prioritizes understanding before building.\n\n---\n\n## Phase 1: Discovery\n\n**Goal**: Clarify what needs to be built\n\nBefore any exploration or implementation, understand the requirements:\n\n1. **Gather Context**:\n   - What problem are we solving?\n   - Who are the users?\n   - What are the constraints?\n   - What are the success criteria?\n\n2. **Confirm Understanding**:\n   - Summarize requirements back to user\n   - Identify any obvious gaps or ambiguities\n   - Get confirmation before proceeding\n\n**Output**: Clear problem statement and requirements summary\n\n---\n\n## Phase 2: Codebase Exploration\n\n**Goal**: Understand relevant existing code at both high and low levels\n\nLaunch **multiple parallel code-explorer agents** to analyze:\n\n1. **Similar Features**: Find existing features that solve related problems\n2. **Architecture Patterns**: Identify current patterns and conventions\n3. **Integration Points**: Map where the new feature connects to existing code\n4. **Data Models**: Understand current data structures\n\n**Parallel Agent Calls**:\n```\ncode-explorer: \"Trace how existing [similar feature] works end-to-end\"\ncode-explorer: \"Map the architecture layers for [relevant domain]\"\ncode-explorer: \"Find all integration points for [system component]\"\ncode-explorer: \"Analyze data models and relationships for [domain]\"\n```\n\n**Output**: Comprehensive codebase analysis with file references and patterns\n\n---\n\n## Phase 3: Clarifying Questions\n\n**Goal**: Resolve ALL ambiguities before proceeding\n\n> **CRITICAL**: This is one of the most important phases. DO NOT proceed until all questions are answered.\n\nAfter exploration, present ALL unresolved ambiguities:\n\n1. **Edge Cases**: What happens when X fails? What if Y is empty?\n2. **Error Handling**: How should errors be handled? User-facing messages?\n3. **Performance**: Expected load? Caching requirements?\n4. **Security**: Authentication? Authorization? Data sensitivity?\n5. **Backward Compatibility**: Breaking changes? Migration needed?\n6. **Design Preferences**: UI/UX choices? API design decisions?\n\n**Format**:\n```markdown\n## Questions Requiring Answers\n\n### Must Answer (Blocking)\n1. [Critical question 1]\n2. [Critical question 2]\n\n### Should Clarify (Recommended)\n1. [Important question 1]\n2. [Important question 2]\n\n### Nice to Know (Optional)\n1. [Additional question 1]\n```\n\n**PAUSE**: Wait for user answers before proceeding to Phase 4.\n\n---\n\n## Phase 4: Architecture Design\n\n**Goal**: Design robust architecture using proven principles and patterns\n\nLaunch **code-architect agent** with architecture skills to design the optimal solution.\n\n### Architecture Skills Applied\n\nThe code-architect uses the following skills to ensure quality design:\n\n| Skill | Purpose |\n|-------|---------|\n| **solid-principles** | Single Responsibility, Open/Closed, Liskov Substitution, Interface Segregation, Dependency Inversion |\n| **clean-architecture** | Layered structure with Dependency Rule (Entities → Use Cases → Adapters → Frameworks) |\n| **design-patterns** | Creational, Structural, Behavioral patterns appropriate for the problem |\n| **domain-driven-design** | Ubiquitous Language, Bounded Contexts, Strategic/Tactical patterns |\n\n### Design Process\n\n1. **Analyze Requirements** against architecture principles\n2. **Identify Applicable Patterns** from codebase exploration\n3. **Design Component Structure** following Clean Architecture layers\n4. **Apply SOLID Principles** to ensure maintainability\n5. **Define Bounded Contexts** if domain complexity warrants\n\n### Architecture Output\n\n**For the Recommended Approach**:\n- Component responsibilities (Single Responsibility)\n- Abstraction boundaries (Dependency Inversion)\n- Extension points (Open/Closed)\n- Interface contracts (Interface Segregation)\n- Data flow through layers (Clean Architecture)\n- Applicable design patterns with rationale\n\n**Trade-offs Documented**:\n- Complexity vs simplicity\n- Flexibility vs performance\n- Consistency with existing codebase\n\n**PAUSE**: Wait for user to approve architecture before implementing.\n\n---\n\n## Phase 5: Implementation\n\n**Goal**: Build the feature following approved architecture\n\n> **IMPORTANT**: Only proceed after explicit user approval of architecture.\n\n**Implementation Process**:\n1. Follow codebase conventions discovered in Phase 2\n2. Implement in logical order (data models → services → APIs → UI)\n3. Add proper error handling and validation\n4. Include logging and monitoring hooks\n5. Write inline documentation\n\n**Best Practices**:\n- Keep functions small and focused\n- Follow existing patterns exactly\n- Handle edge cases identified in Phase 3\n- Don't over-engineer\n\n---\n\n## Phase 6: Quality Review (QA-DEV-REVIEW Loop)\n\n**Goal**: Ensure code quality through automated testing and review loops\n\n### Part A: Testing Loop (max 3 iterations)\n\n```\n1. Write Tests\n   ↓\n2. Run Tests\n   ↓\n3. Tests Fail? → Analyze Failures → Fix Code → Re-run (loop)\n   ↓\n4. All Pass → Continue to Review\n```\n\n**Test Types**:\n- Unit tests for business logic\n- Integration tests for component interactions\n- API tests for endpoints\n\n**Coverage Target**: 80%+\n\n### Part B: Review Loop (max 2 iterations)\n\nLaunch **parallel code-reviewer agents** to assess:\n\n```\ncode-reviewer: \"Check for simplicity and unnecessary complexity\"\ncode-reviewer: \"Verify correctness and edge case handling\"\ncode-reviewer: \"Ensure project convention adherence\"\n```\n\n**Review Categories**:\n1. **Project Guidelines**: CLAUDE.md compliance, naming conventions\n2. **Bug Detection**: Race conditions, null handling, logic errors\n3. **Code Quality**: Duplication, error handling, test coverage\n\n**Confidence-Based Filtering**:\n- Only report issues with confidence score 80+\n- Critical issues grouped separately\n- Actionable fixes provided\n\n**Loop Process**:\n```\n1. Run Quality Checks (linters, formatters, security)\n   ↓\n2. Parallel Code Review\n   ↓\n3. Issues Found? → Fix Issues → Re-review (loop)\n   ↓\n4. All Clean → Continue to Summary\n```\n\n### Part C: E2E Testing (Optional)\n\nIf `--e2e` flag is provided for UI features:\n\n```\nRun QA plugin commands:\n- /e2e - Execute Playwright browser tests\n- browser-tester agent for interactive testing\n```\n\n> **See also**: QA plugin for standalone testing workflows\n\n---\n\n## Phase 7: Summary\n\n**Goal**: Document what was built and next steps\n\n**Summary Contents**:\n1. **Accomplishments**: What was implemented\n2. **Key Decisions**: Architecture choices and rationale\n3. **Files Modified**: List of all changed files\n4. **Testing Results**: Coverage and quality metrics\n5. **Next Steps**: Recommendations for follow-up work\n\n**Format**:\n```markdown\n## Feature Implementation Summary\n\n### Completed\n- [x] Component 1 implemented\n- [x] Component 2 implemented\n- [x] Tests written (87% coverage)\n- [x] Code review passed\n\n### Key Decisions\n1. Used Approach B because [reason]\n2. Chose [pattern] for [reason]\n\n### Files Changed\n- src/services/FeatureService.js (new)\n- src/controllers/FeatureController.js (new)\n- src/models/Feature.js (new)\n- src/routes/index.js (modified)\n\n### Quality Metrics\n- Test Coverage: 87%\n- Linter: Pass\n- Security Scan: Pass\n\n### Next Steps\n1. [Suggested follow-up 1]\n2. [Suggested follow-up 2]\n```\n\n---\n\n## Specialized Agents\n\n### code-explorer\nDeep codebase analysis agent that traces execution paths, maps architecture layers, and documents dependencies.\n\n**Use For**: Understanding existing features, finding patterns, identifying integration points\n\n### code-architect\nArchitecture design agent that applies SOLID principles, Clean Architecture, Design Patterns, and DDD to generate robust implementation blueprints.\n\n**Use For**: Designing architecture with proven principles, defining component responsibilities, planning data flows\n\n**Skills**: solid-principles, clean-architecture, design-patterns, domain-driven-design\n\n### code-reviewer\nQuality review agent with confidence-based issue filtering (80+ threshold).\n\n**Use For**: Bug detection, code quality assessment, convention compliance\n\n---\n\n## Processing Loops\n\n### Testing Loop\n- **Purpose**: Ensure all tests pass\n- **Max Iterations**: 3\n- **Process**: Test → Analyze Failures → Fix → Re-test\n\n### Review Loop\n- **Purpose**: Ensure code quality standards\n- **Max Iterations**: 2\n- **Process**: Review → Fix Issues → Re-review\n\n---\n\n## Key Principles\n\n1. **Understand Before Building**: Read code thoroughly before writing\n2. **Ask Questions Early**: Resolve ambiguities before implementation\n3. **Present Options**: Show trade-offs, let user decide\n4. **Parallel Exploration**: Launch multiple agents for efficiency\n5. **Confidence Filtering**: Only report high-confidence issues\n6. **Loop Until Done**: Automated fixing until quality gates pass\n\n---\n\n## E2E Testing Integration\n\nFor features with UI components, use the `--e2e` flag:\n\n```bash\n/feature \"Add shopping cart\" --e2e\n```\n\nThis integrates with the **QA plugin** for browser testing:\n- Playwright-based E2E tests\n- Interactive browser testing via `browser-tester` agent\n\n---\n\n## Version\n\n1.2.0"
              }
            ],
            "skills": []
          },
          {
            "name": "prototype",
            "description": "Quick experimentation through rapid prototyping, A/B testing, and data-driven decision making",
            "source": "./plugins/prototype",
            "category": "development",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install prototype@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/prototype",
                "description": "Quick experimentation through rapid prototyping, A/B testing, and data-driven decision making",
                "path": "plugins/prototype/commands/prototype.md",
                "frontmatter": {
                  "description": "Quick experimentation through rapid prototyping, A/B testing, and data-driven decision making"
                },
                "content": "# Prototype Command\n\n**Purpose**: Quick experimentation through rapid prototyping, A/B testing, and data-driven decision making\n\n## Overview\n\nThe prototype command enables rapid experimentation to validate ideas before full implementation. Research shows that **prototyping reduces development waste by 40-60%**.\n\n**Key Distinction**: Prototype creates lightweight POCs for validation, while Feature builds production-ready implementations.\n\n## Workflow\n\n### Step 1: Plan Experiment\n- Define hypothesis\n- Identify metrics\n- Design experiment\n- Estimate effort\n\n### Step 2: Implement POC\n- Build minimal working version\n- Focus on validation, not production quality\n- Use mocks and simplifications\n- Implement quickly\n\n### Step 3: Test Experiment\n- Run with real users (if applicable)\n- Collect metrics\n- Gather feedback\n- Document results\n\n### Step 4: Analyze Results\n- Compare to hypothesis\n- Analyze metrics\n- Identify insights\n- Make recommendation\n\n### Step 5: Decide\n- Go/No-Go decision\n- Plan full implementation (if go)\n- Document learnings\n\n### Step 6: Cleanup\n- Remove prototype code (if no-go)\n- Archive experiment data\n- Share learnings\n\n## Usage Examples\n\n```bash\n/prototype \"test new recommendation algorithm\"\n/prototype \"experiment with dark mode UI\"\n/prototype \"A/B test new checkout flow\"\n/prototype \"validate API design for new feature\"\n```\n\n## Output\n\n```\nprototype-output/\n├── EXPERIMENT_PLAN.md        # Experiment design\n├── IMPLEMENTATION.md         # What was built\n├── RESULTS.md                # Experiment results\n├── ANALYSIS.md               # Data analysis\n├── DECISION.md               # Go/No-Go decision\n└── LEARNINGS.md              # Key insights\n```\n\n**Priority**: P3 - MEDIUM"
              }
            ],
            "skills": []
          },
          {
            "name": "refactor",
            "description": "Systematic technical debt reduction and code refactoring with continuous improvement cycles",
            "source": "./plugins/refactor",
            "category": "improvement",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install refactor@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/refactor",
                "description": "Systematic technical debt reduction and code refactoring to improve maintainability and reduce complexity",
                "path": "plugins/refactor/commands/refactor.md",
                "frontmatter": {
                  "description": "Systematic technical debt reduction and code refactoring to improve maintainability and reduce complexity"
                },
                "content": "# Refactor Command\n\n**Purpose**: Systematic technical debt reduction and code refactoring to improve maintainability, reduce complexity, and modernize code\n\n## Overview\n\nThe refactor command addresses the critical gap between identifying technical debt (via Audit plugin) and actually fixing it. Research shows teams spend 10-30% of sprint time on refactoring, making this a critical workflow.\n\n**Key Distinction**: Refactor improves existing code without changing behavior, while Feature adds new functionality and Bugfix repairs broken behavior.\n\n## Workflow\n\n### Step 1: Validate Target\n\n1. **Check target exists**\n   - If specific file/directory provided: verify it exists\n   - If description provided: identify files needing refactoring\n   - If no target: offer to analyze recent Audit plugin output\n\n2. **Determine refactoring scope**\n   - Single function refactoring\n   - Class/module refactoring\n   - Package/directory refactoring\n   - Dependency updates\n   - Architecture improvement\n\n3. **Identify project type**\n   - Language (JavaScript, Python, PHP, Go, Java, etc.)\n   - Framework (React, Django, Laravel, etc.)\n   - Test framework (Jest, pytest, PHPUnit, etc.)\n\n### Step 2: Analyze Current State\n\nRun **pre-refactor-analyzer** agent to:\n- Capture current code structure\n- Extract existing tests\n- Measure complexity metrics (cyclomatic complexity, nesting depth, function length)\n- Document current behavior\n- Identify refactoring opportunities\n- Estimate impact and effort\n\n**Output**:\n```\nrefactor-plan/\n├── CURRENT_STATE.md          # Current code analysis\n├── COMPLEXITY_METRICS.md     # Before metrics\n├── EXISTING_TESTS.md         # Current test coverage\n└── OPPORTUNITIES.md          # Refactoring opportunities\n```\n\n### Step 3: Prioritize Improvements\n\nRun **debt-prioritizer** agent to:\n- Score each refactoring opportunity by:\n  - Impact (how much improvement)\n  - Effort (how much work)\n  - Risk (how likely to break things)\n- Calculate impact/effort ratio\n- Recommend priority order\n- Identify quick wins (high impact, low effort)\n- Flag high-risk refactorings\n\n**Output**: Prioritized list with recommendations\n\n### Step 4: Create Refactoring Plan\n\nRun **refactor-planner** agent to:\n- Design refactoring approach\n- Break into safe, incremental steps\n- Identify test coverage gaps\n- Plan test additions/updates\n- Define success criteria\n- Create rollback plan\n\n**Output**: `REFACTORING_PLAN.md` with step-by-step approach\n\n### Step 5: Review Plan (Optional)\n\nPresent plan to user:\n- Refactoring steps\n- Expected improvements\n- Risks and mitigations\n- Estimated time\n\nWait for approval before proceeding.\n\n### Step 6: Launch Parallel Refactoring Agents\n\nBased on refactoring type, launch appropriate agents **in parallel**:\n\n**Always Launch**:\n1. **test-preserver** - Ensures tests pass throughout refactoring\n\n**Conditionally Launch** (based on refactoring type):\n\n**Code Structure**:\n- **complexity-reducer** - Simplify complex functions/classes\n- **duplication-eliminator** - Remove duplicate code\n- **naming-improver** - Improve variable/function names\n\n**Modernization**:\n- **code-modernizer** - Apply modern language features\n- **pattern-upgrader** - Apply better design patterns\n- **dependency-updater** - Update outdated dependencies\n\n**Performance**:\n- **performance-improver** - Apply performance optimizations identified in analysis\n\n**Architecture**:\n- **architecture-improver** - Improve architectural patterns\n\n### Step 7: Apply Refactorings Incrementally\n\nFor each refactoring step:\n\n1. **Apply Change**\n   - Make single, focused change\n   - Keep changes small and atomic\n\n2. **Run Tests** (test-preserver agent)\n   - Run relevant test suite\n   - Check for failures\n\n3. **If Tests Pass**: ✅\n   - Commit change\n   - Move to next step\n\n4. **If Tests Fail**: ❌\n   - Analyze failure\n   - Revert change OR\n   - Fix test if behavior change is intentional\n   - Re-run tests\n   - If still failing after 2 attempts: skip this refactoring, log issue\n\n5. **Measure Progress**\n   - Update complexity metrics\n   - Track improvements\n\n### Step 8: Verify Improvements\n\nRun **refactor-validator** agent to:\n- Re-measure complexity metrics\n- Compare before/after\n- Verify all tests still pass\n- Check no behavior changes\n- Validate improvements achieved\n\n**Success Criteria**:\n- ✅ All tests pass\n- ✅ Complexity reduced (or other goal achieved)\n- ✅ No unintended behavior changes\n- ✅ Code coverage maintained or improved\n\n### Step 9: Document Changes\n\nGenerate documentation:\n```\nrefactor-output/\n├── REFACTORING_SUMMARY.md    # What was changed and why\n├── IMPROVEMENTS.md            # Before/after metrics\n├── COMMIT_MESSAGE.md          # Suggested commit message\n└── TECHNICAL_DEBT_UPDATE.md  # Updated tech debt status\n```\n\n### Step 10: Create Commit (Optional)\n\nIf requested, create git commit:\n- Use suggested commit message\n- Mark as \"Refactor:\" in conventional commits format\n- Include before/after metrics in commit body\n\n## Refactoring Loop\n\n```\nFor each refactoring step:\n  Apply → Test → (Pass?) → Commit → Next\n                    ↓ Fail\n                  Revert or Fix → Re-test → (Pass?) → Commit\n                                              ↓ Fail (after 2 attempts)\n                                            Skip & Log\n```\n\n**Max Iterations**: 50 refactoring steps per session\n**Safety**: Each step is tested before proceeding\n\n## Configuration\n\nOptional `.claude/refactor-config.yaml`:\n\n```yaml\nrefactor:\n  safety:\n    require_test_coverage: true      # Require tests before refactoring\n    min_coverage_threshold: 80       # Min coverage % required\n    auto_revert_on_failure: true     # Auto revert if tests fail\n    max_attempts_per_step: 2         # Max attempts to fix failing tests\n\n  scope:\n    max_steps_per_session: 50        # Max refactoring steps\n    incremental_commits: true        # Commit after each successful step\n\n  priorities:\n    prefer_quick_wins: true          # Prioritize high impact / low effort\n    max_risk_level: \"medium\"         # Skip high-risk refactorings\n\n  metrics:\n    track_complexity: true           # Track cyclomatic complexity\n    track_duplication: true          # Track code duplication\n    track_coverage: true             # Track test coverage\n```\n\n## Usage Examples\n\n### Example 1: Reduce Function Complexity\n\n```bash\n/refactor \"reduce complexity of src/auth/validateUser.js\"\n\n# Output:\n# ✅ Analyzed validateUser function (complexity: 15)\n# ✅ Planned 5 refactoring steps\n# ✅ Step 1/5: Extract email validation → tests pass\n# ✅ Step 2/5: Extract password validation → tests pass\n# ✅ Step 3/5: Extract role checking → tests pass\n# ✅ Step 4/5: Simplify conditionals → tests pass\n# ✅ Step 5/5: Improve variable names → tests pass\n#\n# Complexity reduced: 15 → 6 (60% improvement)\n# All 23 tests pass ✅\n```\n\n### Example 2: Eliminate Code Duplication\n\n```bash\n/refactor \"eliminate duplication in src/services/\"\n\n# Output:\n# ✅ Found 8 instances of duplicate code\n# ✅ Prioritized by impact (420 lines can be eliminated)\n# ✅ Step 1/8: Extract common validation logic → tests pass\n# ✅ Step 2/8: Create shared utility function → tests pass\n# ...\n#\n# Duplication eliminated: 420 lines → 65 lines (85% reduction)\n# All 156 tests pass ✅\n```\n\n### Example 3: Update Dependencies\n\n```bash\n/refactor \"update outdated dependencies\"\n\n# Output:\n# ✅ Analyzed 45 dependencies\n# ✅ Found 12 outdated (8 with breaking changes)\n# ✅ Prioritized by risk\n# ✅ Step 1/12: Update lodash 4.17.20 → 4.17.21 → tests pass\n# ✅ Step 2/12: Update axios 0.27.0 → 1.6.0 → tests pass\n# ⚠️  Step 3/12: Update webpack 4 → 5 → tests fail\n#    → Analyzing failures...\n#    → Fixed config incompatibility\n#    → Re-tested → tests pass\n# ...\n#\n# Updated 12 dependencies\n# All 203 tests pass ✅\n```\n\n### Example 4: Modernize Code\n\n```bash\n/refactor \"modernize src/utils/ to ES6+\"\n\n# Output:\n# ✅ Analyzed code (ES5 patterns detected)\n# ✅ Planned modernization steps\n# ✅ Step 1/15: Convert var → const/let → tests pass\n# ✅ Step 2/15: Convert function() → arrow functions → tests pass\n# ✅ Step 3/15: Use destructuring → tests pass\n# ✅ Step 4/15: Use template literals → tests pass\n# ✅ Step 5/15: Use async/await instead of promises → tests pass\n# ...\n#\n# Modernized 45 files to ES6+\n# All 178 tests pass ✅\n```\n\n### Example 5: Address Audit Findings\n\n```bash\n# After running /audit, you have TECHNICAL_DEBT.md with issues\n/refactor \"address high-priority items from audit\"\n\n# Output:\n# ✅ Loaded audit-output/TECHNICAL_DEBT.md\n# ✅ Found 5 high-priority items\n# ✅ Prioritized by impact/effort\n#\n# Item 1/5: God class UserService (650 lines)\n#   ✅ Split into UserAuthService\n#   ✅ Split into UserProfileService\n#   ✅ Split into UserNotificationService\n#   → tests pass\n#\n# Item 2/5: Long function processPayment (120 lines)\n#   ✅ Extract validation logic\n#   ✅ Extract payment processing\n#   ✅ Extract notification logic\n#   → tests pass\n# ...\n```\n\n## Quality Gates\n\nBefore completing refactoring:\n\n- ✅ All tests pass\n- ✅ Code coverage maintained or improved\n- ✅ Complexity reduced (if that was the goal)\n- ✅ No unintended behavior changes\n- ✅ No new linter errors\n\nIf any gate fails:\n- Report issue\n- Offer to revert changes\n- Suggest next steps\n\n## Safety Features\n\n1. **Test-Driven**: Every step is tested before proceeding\n2. **Incremental**: Small, atomic changes that can be reverted\n3. **Automatic Rollback**: Failed changes are reverted automatically\n4. **Behavior Preservation**: Verifies no unintended behavior changes\n5. **Risk Assessment**: High-risk refactorings flagged for review\n\n## Output Files\n\n```\nrefactor-output/\n├── CURRENT_STATE.md           # Initial analysis\n├── REFACTORING_PLAN.md        # Step-by-step plan\n├── REFACTORING_SUMMARY.md     # What changed\n├── IMPROVEMENTS.md            # Before/after metrics\n├── COMPLEXITY_BEFORE.md       # Initial metrics\n├── COMPLEXITY_AFTER.md        # Final metrics\n├── COMMIT_MESSAGE.md          # Suggested commit message\n└── TECHNICAL_DEBT_UPDATE.md   # Updated debt status\n```\n\n## Integration with Other Plugins\n\n- **After Audit**: `/audit` identifies debt → `/refactor` fixes it\n- **Before Feature**: Refactor first to create clean foundation\n- **With Review**: Can refactor based on review feedback\n- **With Optimize**: Refactor improves structure, Optimize improves speed\n\n## Notes\n\n- **Behavior Preservation**: Refactoring should NOT change behavior\n- **Test Coverage**: Requires existing tests (or creates them first)\n- **Incremental**: Small steps are safer than big rewrites\n- **Continuous**: Refactoring should be ongoing, not a one-time event\n- **Team Practice**: Research shows teams spend 10-30% of time on this\n\n## Best Practices\n\n1. **Refactor in small steps** - Easier to verify and revert\n2. **Test after each step** - Catch issues immediately\n3. **Commit frequently** - Each successful step can be committed\n4. **Focus on one thing** - Don't mix refactoring types\n5. **Measure improvements** - Track metrics to validate benefits\n6. **Use for onboarding** - Refactoring is a great way to learn code\n\n## Common Refactoring Patterns\n\nThe plugin supports these common refactorings:\n\n**Method-Level**:\n- Extract Method\n- Inline Method\n- Rename Method\n- Add Parameter\n- Remove Parameter\n\n**Class-Level**:\n- Extract Class\n- Inline Class\n- Extract Interface\n- Move Method\n- Move Field\n\n**Code Cleanup**:\n- Remove Duplication\n- Simplify Conditionals\n- Replace Magic Numbers\n- Improve Naming\n\n**Modernization**:\n- Use Modern Syntax\n- Update Dependencies\n- Apply Design Patterns\n- Improve Error Handling"
              }
            ],
            "skills": []
          },
          {
            "name": "optimize",
            "description": "Performance optimization through systematic profiling, bottleneck identification, and speed improvements",
            "source": "./plugins/optimize",
            "category": "improvement",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install optimize@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/optimize",
                "description": "Performance optimization through systematic profiling, bottleneck identification, and speed improvements",
                "path": "plugins/optimize/commands/optimize.md",
                "frontmatter": {
                  "description": "Performance optimization through systematic profiling, bottleneck identification, and speed improvements"
                },
                "content": "# Optimize Command\n\n**Purpose**: Performance optimization through systematic profiling, bottleneck identification, and measurable speed improvements\n\n## Overview\n\nThe optimize command addresses performance bottlenecks through data-driven optimization. Research shows that **80% of performance issues come from 20% of code**, making targeted optimization critical.\n\n**Key Distinction**: Optimize improves speed and efficiency, while Refactor improves maintainability without changing performance, and Bugfix repairs broken behavior.\n\n## Workflow\n\n### Step 1: Validate Target\n\n1. **Check target exists**\n   - If specific file/endpoint provided: verify it exists\n   - If performance goal provided: identify optimization scope\n   - If no target: offer to analyze recent performance metrics\n\n2. **Determine optimization scope**\n   - API endpoint optimization\n   - Database query optimization\n   - Frontend rendering optimization\n   - Algorithm optimization\n   - Resource usage optimization (memory, CPU, I/O)\n\n3. **Identify project type**\n   - Language (JavaScript, Python, PHP, Go, Java, etc.)\n   - Framework (React, Django, Laravel, Express, etc.)\n   - Database (PostgreSQL, MySQL, MongoDB, Redis)\n   - Infrastructure (serverless, containers, VMs)\n\n### Step 2: Profile Current Performance\n\nRun **performance-profiler** agent to:\n- Establish performance baseline\n- Measure current response times, throughput, resource usage\n- Identify slow operations (>100ms API calls, >1s page loads)\n- Measure database query times\n- Profile CPU/memory usage\n- Document current performance metrics\n\n**Output**:\n```\noptimize-analysis/\n├── BASELINE_METRICS.md        # Current performance numbers\n├── PROFILING_DATA.md          # Detailed profiling results\n├── SLOW_OPERATIONS.md         # Operations exceeding thresholds\n└── RESOURCE_USAGE.md          # CPU, memory, I/O usage\n```\n\n### Step 3: Identify Bottlenecks\n\nRun **bottleneck-identifier** agent to:\n- Analyze profiling data\n- Identify performance hotspots (80/20 rule)\n- Categorize bottlenecks by type:\n  - Algorithm complexity (O(n²) → O(n log n))\n  - Database queries (N+1, missing indexes)\n  - Network calls (excessive API calls, no caching)\n  - Resource inefficiency (memory leaks, CPU spikes)\n  - Frontend rendering (unnecessary re-renders)\n- Estimate potential improvement for each\n- Prioritize by impact\n\n**Output**: Prioritized list of bottlenecks with estimated improvements\n\n### Step 4: Create Optimization Plan\n\nRun appropriate specialized agents based on bottleneck types:\n\n**Database Issues** → **query-optimizer** agent:\n- Analyze slow queries\n- Design indexes\n- Optimize query structure\n- Implement query caching\n\n**Caching Opportunities** → **cache-strategist** agent:\n- Identify cacheable data\n- Design cache strategy (Redis, CDN, in-memory)\n- Determine cache invalidation approach\n- Plan cache warming\n\n**Algorithm Issues** → **code-optimizer** agent:\n- Analyze algorithm complexity\n- Design more efficient algorithms\n- Plan data structure improvements\n- Optimize hot code paths\n\n**Output**: `OPTIMIZATION_PLAN.md` with step-by-step approach\n\n### Step 5: Review Plan (Optional)\n\nPresent plan to user:\n- Expected improvements (e.g., \"Reduce API response time from 450ms to 80ms\")\n- Specific optimizations\n- Risks and trade-offs\n- Implementation effort\n\nWait for approval before proceeding.\n\n### Step 6: Apply Optimizations Incrementally\n\nFor each optimization:\n\n1. **Benchmark Before**\n   - Measure current performance\n   - Run performance tests\n   - Document baseline\n\n2. **Apply Optimization**\n   - Make focused change\n   - Keep changes atomic\n\n3. **Benchmark After**\n   - Measure new performance\n   - Compare to baseline\n   - Verify improvement achieved\n\n4. **Run Tests**\n   - Ensure all tests pass\n   - Verify no behavior changes\n   - Check for regressions\n\n5. **If Improved**: ✅\n   - Document improvement\n   - Commit change\n   - Move to next optimization\n\n6. **If No Improvement or Regression**: ❌\n   - Revert change\n   - Analyze why it didn't help\n   - Try alternative approach\n\n### Step 7: Load Test\n\nRun **load-tester** agent to:\n- Simulate realistic load\n- Test under stress conditions\n- Verify improvements hold at scale\n- Identify new bottlenecks under load\n- Measure key metrics:\n  - Response time (p50, p95, p99)\n  - Throughput (requests/second)\n  - Error rate\n  - Resource utilization\n\n**Success Criteria**:\n- ✅ Performance targets met (e.g., p95 < 200ms)\n- ✅ No errors under normal load\n- ✅ Graceful degradation under stress\n- ✅ Resource usage within limits\n\n### Step 8: Validate Improvements\n\nRun **benchmark-validator** agent to:\n- Re-run all performance benchmarks\n- Compare before/after metrics\n- Verify targets achieved\n- Check for side effects or regressions\n- Validate improvements persist\n\n**Success Criteria**:\n- ✅ Performance improved by target % (e.g., 50% faster)\n- ✅ All tests pass\n- ✅ No behavior changes\n- ✅ No new bottlenecks introduced\n\n### Step 9: Document Optimizations\n\nGenerate documentation:\n```\noptimize-output/\n├── OPTIMIZATION_SUMMARY.md    # What was optimized and why\n├── IMPROVEMENTS.md            # Before/after metrics\n├── BENCHMARKS.md              # Detailed benchmark results\n├── COMMIT_MESSAGE.md          # Suggested commit message\n└── MONITORING_RECOMMENDATIONS.md  # What to monitor going forward\n```\n\n### Step 10: Create Commit (Optional)\n\nIf requested, create git commit:\n- Use suggested commit message\n- Mark as \"perf:\" in conventional commits format\n- Include before/after metrics in commit body\n\n## Optimization Loop\n\n```\nFor each optimization:\n  Benchmark → Apply → Benchmark → (Improved?) → Commit → Next\n                                      ↓ No improvement\n                                    Revert → Analyze → Try Alternative\n```\n\n**Max Iterations**: 20 optimizations per session\n**Safety**: Each optimization is benchmarked and tested\n\n## Performance Targets\n\n### API Response Times\n| Target | Rating |\n|--------|--------|\n| < 100ms | Excellent ✅ |\n| 100-300ms | Good ✓ |\n| 300-1000ms | Acceptable ⚠️ |\n| > 1000ms | Poor - Optimize 🔴 |\n\n### Page Load Times\n| Target | Rating |\n|--------|--------|\n| < 1s | Excellent ✅ |\n| 1-3s | Good ✓ |\n| 3-5s | Acceptable ⚠️ |\n| > 5s | Poor - Optimize 🔴 |\n\n### Database Queries\n| Target | Rating |\n|--------|--------|\n| < 10ms | Excellent ✅ |\n| 10-50ms | Good ✓ |\n| 50-100ms | Acceptable ⚠️ |\n| > 100ms | Poor - Optimize 🔴 |\n\n## Configuration\n\nOptional `.claude/optimize-config.yaml`:\n\n```yaml\noptimize:\n  targets:\n    api_response_time_ms: 200        # Target p95 response time\n    page_load_time_ms: 2000          # Target page load\n    database_query_ms: 50            # Target query time\n    throughput_rps: 1000             # Requests per second\n\n  thresholds:\n    min_improvement_percent: 20      # Minimum improvement to accept\n    max_regression_percent: 5        # Maximum acceptable regression\n\n  benchmarking:\n    warm_up_runs: 10                 # Warm-up iterations\n    measurement_runs: 100            # Measurement iterations\n    load_test_duration_seconds: 300  # Load test duration\n\n  safety:\n    require_tests_pass: true         # Require tests before/after\n    auto_revert_on_regression: true  # Revert if performance degrades\n```\n\n## Usage Examples\n\n### Example 1: Optimize Slow API Endpoint\n\n```bash\n/optimize \"improve performance of /api/users endpoint\"\n\n# Output:\n# ✅ Profiled /api/users endpoint (current: 450ms p95)\n# ✅ Identified 3 bottlenecks:\n#    1. N+1 query (300ms) - HIGH IMPACT\n#    2. Missing index on user_roles (100ms) - MEDIUM IMPACT\n#    3. Eager loading all fields (50ms) - LOW IMPACT\n#\n# ✅ Step 1/3: Fix N+1 query with eager loading\n#    Before: 450ms → After: 150ms (67% faster) ✅\n#\n# ✅ Step 2/3: Add index on user_roles.user_id\n#    Before: 150ms → After: 80ms (47% faster) ✅\n#\n# ✅ Step 3/3: Implement field selection\n#    Before: 80ms → After: 65ms (19% faster) ✅\n#\n# Overall improvement: 450ms → 65ms (86% faster) 🚀\n# All 87 tests pass ✅\n```\n\n### Example 2: Optimize Database Queries\n\n```bash\n/optimize \"improve database query performance in src/services/\"\n\n# Output:\n# ✅ Analyzed 234 database queries\n# ✅ Found 12 slow queries (>100ms)\n# ✅ Identified optimization opportunities:\n#    - 5 missing indexes\n#    - 3 N+1 query patterns\n#    - 4 queries returning unnecessary data\n#\n# ✅ Step 1/12: Add index on orders.customer_id\n#    Query time: 450ms → 12ms (96% faster) ✅\n#\n# ✅ Step 2/12: Fix N+1 in getOrdersWithItems\n#    Query count: 1+N → 2 queries (reduced from 150 to 2) ✅\n#    Time: 800ms → 45ms (94% faster) ✅\n# ...\n#\n# Total queries optimized: 12\n# Average improvement: 88% faster\n# All 156 tests pass ✅\n```\n\n### Example 3: Optimize Frontend Rendering\n\n```bash\n/optimize \"reduce React component re-renders in dashboard\"\n\n# Output:\n# ✅ Profiled React dashboard (current: 3.2s initial render)\n# ✅ Identified performance issues:\n#    - Unnecessary re-renders: 847 renders for 12 components\n#    - Large component tree: 45 nested levels\n#    - Missing memoization: 15 expensive calculations\n#\n# ✅ Step 1/5: Add React.memo to list components\n#    Renders: 847 → 23 (97% reduction) ✅\n#\n# ✅ Step 2/5: Use useMemo for expensive calculations\n#    Calculation time: 1.2s → 5ms (99.6% faster) ✅\n#\n# ✅ Step 3/5: Implement virtual scrolling for long lists\n#    Render time: 1.8s → 120ms (93% faster) ✅\n# ...\n#\n# Overall: 3.2s → 0.4s initial render (87.5% faster) 🚀\n# Lighthouse score: 45 → 92 ✅\n```\n\n### Example 4: Optimize Algorithm Complexity\n\n```bash\n/optimize \"improve performance of findDuplicates function\"\n\n# Output:\n# ✅ Analyzed findDuplicates algorithm\n# ✅ Current complexity: O(n²) nested loops\n# ✅ Current performance: 12.5s for 10,000 items\n#\n# ✅ Optimization: Replace nested loops with Set-based approach\n#    Complexity: O(n²) → O(n)\n#    Performance: 12.5s → 45ms (99.6% faster) 🚀\n#\n# Benchmark results (10,000 items):\n#    Before: 12,500ms\n#    After: 45ms\n#    Improvement: 277x faster\n#\n# All 34 tests pass ✅\n```\n\n### Example 5: Optimize with Caching\n\n```bash\n/optimize \"add caching to user profile API\"\n\n# Output:\n# ✅ Analyzed /api/profile endpoint (current: 250ms p95)\n# ✅ Identified caching opportunity:\n#    - User data changes infrequently\n#    - High read/write ratio (1000:1)\n#    - Cache hit rate potential: 95%\n#\n# ✅ Designed cache strategy:\n#    - Redis cache with 5-minute TTL\n#    - Cache warming for active users\n#    - Invalidation on user updates\n#\n# ✅ Implemented Redis caching\n#    Cache hit: 5ms\n#    Cache miss: 250ms (writes to cache)\n#    Expected p95: 25ms (90% faster)\n#\n# ✅ Load test results:\n#    With 95% cache hit rate: 25ms p95 ✅\n#    Throughput: 500 rps → 5,000 rps (10x) 🚀\n#\n# All 67 tests pass ✅\n```\n\n## Quality Gates\n\nBefore completing optimization:\n\n- ✅ Performance improved by minimum threshold (e.g., 20%)\n- ✅ All tests pass\n- ✅ No behavior changes\n- ✅ No new errors or exceptions\n- ✅ Improvements verified under load\n- ✅ No unacceptable trade-offs (e.g., excessive memory usage)\n\nIf any gate fails:\n- Report issue\n- Offer to revert changes\n- Suggest alternative approaches\n\n## Safety Features\n\n1. **Benchmark-Driven**: Every optimization is measured before/after\n2. **Test-Verified**: All tests must pass\n3. **Incremental**: Small changes that can be reverted\n4. **Load-Tested**: Verify improvements hold at scale\n5. **Automatic Rollback**: Revert if optimization makes things worse\n\n## Output Files\n\n```\noptimize-output/\n├── BASELINE_METRICS.md        # Initial performance\n├── OPTIMIZATION_PLAN.md       # Step-by-step plan\n├── OPTIMIZATION_SUMMARY.md    # What was optimized\n├── IMPROVEMENTS.md            # Before/after metrics\n├── BENCHMARKS.md              # Detailed benchmark results\n├── LOAD_TEST_RESULTS.md       # Performance under load\n├── COMMIT_MESSAGE.md          # Suggested commit message\n└── MONITORING_RECOMMENDATIONS.md  # What to monitor\n```\n\n## Integration with Other Plugins\n\n- **After Audit**: `/audit` identifies slow operations → `/optimize` speeds them up\n- **After Review**: Address performance issues found in code review\n- **Before Deploy**: Optimize before shipping to production\n- **With Refactor**: Refactor for maintainability, then optimize for speed\n- **Different from Refactor**: Refactor improves structure, Optimize improves speed\n\n## Notes\n\n- **Measure First**: Always profile before optimizing\n- **80/20 Rule**: Focus on the biggest bottlenecks\n- **Test Thoroughly**: Ensure correctness isn't sacrificed for speed\n- **Trade-offs**: Consider memory vs CPU vs complexity trade-offs\n- **Premature Optimization**: Don't optimize until you have performance issues\n- **Real Data**: Use production-like data and load for testing\n\n## Best Practices\n\n1. **Profile first** - Don't guess where the bottlenecks are\n2. **Focus on hotspots** - 80% of time is spent in 20% of code\n3. **Measure everything** - Benchmark before and after every change\n4. **Test under load** - Performance can change dramatically under stress\n5. **Consider trade-offs** - Faster isn't always better if it uses 10x memory\n6. **Cache strategically** - Right caching can provide 10-100x improvements\n7. **Database first** - Database is often the biggest bottleneck\n\n## Common Optimization Patterns\n\nThe plugin supports these optimization strategies:\n\n**Database**:\n- Add indexes\n- Fix N+1 queries\n- Optimize query structure\n- Implement query caching\n- Add connection pooling\n\n**Algorithms**:\n- Reduce complexity (O(n²) → O(n log n))\n- Use better data structures (array → hash map)\n- Eliminate redundant work\n- Optimize hot paths\n\n**Caching**:\n- Application caching (Redis, Memcached)\n- Database query caching\n- CDN for static assets\n- HTTP caching headers\n\n**Frontend**:\n- Code splitting\n- Lazy loading\n- Memoization\n- Virtual scrolling\n- Debouncing/throttling\n\n**Infrastructure**:\n- Load balancing\n- Horizontal scaling\n- Resource optimization\n- Compression"
              }
            ],
            "skills": []
          },
          {
            "name": "harden",
            "description": "Security hardening through vulnerability scanning, configuration auditing, and comprehensive security improvements",
            "source": "./plugins/harden",
            "category": "improvement",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install harden@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/harden",
                "description": "Security hardening with vulnerability scanning, configuration auditing, and security improvements",
                "path": "plugins/harden/commands/harden.md",
                "frontmatter": {
                  "description": "Security hardening with vulnerability scanning, configuration auditing, and security improvements"
                },
                "content": "# Harden Command\n\n**Purpose**: Security hardening through systematic vulnerability scanning, configuration auditing, and comprehensive security improvements\n\n## Overview\n\nThe harden command provides holistic security improvement beyond finding specific vulnerabilities. Research shows that **60% of breaches exploit known vulnerabilities** that could have been prevented through proper hardening.\n\n**Key Distinction**: Harden provides comprehensive security improvement, while Review finds specific issues in code.\n\n## Workflow\n\n### Step 1: Validate Target\n\n1. **Check target exists**\n   - If specific component provided: verify it exists\n   - If security goal provided: identify scope\n   - If no target: offer full application security hardening\n\n2. **Determine hardening scope**\n   - Application security\n   - Authentication/authorization\n   - Infrastructure security\n   - Data protection\n   - API security\n   - Compliance requirements\n\n3. **Identify technology stack**\n   - Languages and frameworks\n   - Database systems\n   - Web servers\n   - Cloud infrastructure\n   - Third-party services\n\n### Step 2: Scan for Vulnerabilities\n\nRun **vulnerability-scanner** agent to:\n- Scan dependencies for known CVEs\n- Check OWASP Top 10 vulnerabilities\n- Identify insecure configurations\n- Find exposed secrets\n- Detect security misconfigurations\n- Scan for common vulnerabilities (SQL injection, XSS, etc.)\n\n**Output**:\n```\nharden-analysis/\n├── VULNERABILITIES.md         # Identified vulnerabilities\n├── CVE_REPORT.md             # Known CVEs in dependencies\n├── SECURITY_MISCONFIG.md     # Configuration issues\n└── EXPOSED_SECRETS.md        # Potential secrets in code\n```\n\n### Step 3: Audit Security Configuration\n\nRun **security-config-auditor** agent to:\n- Review authentication configuration\n- Check authorization setup\n- Audit CORS policies\n- Review HTTPS/TLS configuration\n- Check CSP headers\n- Audit logging and monitoring\n- Review error handling\n\n**Output**: Configuration security assessment\n\n### Step 4: Prioritize Issues\n\nPrioritize vulnerabilities by:\n- **Severity**: Critical, High, Medium, Low\n- **Exploitability**: How easy to exploit\n- **Impact**: Data breach, service disruption, etc.\n- **CVSS Score**: Industry-standard scoring\n\n**Output**: Prioritized security roadmap\n\n### Step 5: Create Hardening Plan\n\nDesign comprehensive hardening approach:\n- Authentication hardening\n- Secrets management\n- Security headers\n- Input validation\n- Dependency updates\n- Configuration fixes\n\n**Output**: `HARDENING_PLAN.md` with step-by-step approach\n\n### Step 6: Launch Specialized Hardening Agents\n\nBased on findings, launch appropriate agents:\n\n**Authentication/Authorization**:\n- **auth-hardener** - Strengthen authentication and authorization\n\n**Secrets Management**:\n- **secrets-manager** - Secure API keys, passwords, tokens\n\n**Infrastructure Security**:\n- **security-header-configurator** - Add security headers (CSP, HSTS, etc.)\n\n**Penetration Testing**:\n- **penetration-tester** - Test security controls\n\n**Compliance**:\n- **compliance-checker** - Verify compliance standards (GDPR, SOC2, etc.)\n\n### Step 7: Apply Hardening Incrementally\n\nFor each security improvement:\n\n1. **Apply Fix**\n   - Make security improvement\n   - Update configuration\n\n2. **Test Functionality**\n   - Ensure application still works\n   - No breaking changes\n\n3. **Verify Security**\n   - Confirm vulnerability fixed\n   - No new vulnerabilities introduced\n\n4. **If Successful**: ✅\n   - Document fix\n   - Commit change\n   - Move to next item\n\n### Step 8: Penetration Test\n\nRun **penetration-tester** agent to:\n- Test authentication bypass attempts\n- Try SQL injection\n- Test XSS vulnerabilities\n- Attempt CSRF attacks\n- Test authorization flaws\n- Try common exploits\n\n**Success Criteria**:\n- ✅ No critical vulnerabilities\n- ✅ All high-severity issues fixed\n- ✅ Security controls working\n- ✅ Penetration tests pass\n\n### Step 9: Verify Compliance\n\nRun **compliance-checker** agent to:\n- Verify OWASP Top 10 coverage\n- Check compliance standards (GDPR, HIPAA, PCI-DSS, SOC2)\n- Validate security controls\n- Document compliance status\n\n### Step 10: Document Security Improvements\n\nGenerate documentation:\n```\nharden-output/\n├── HARDENING_SUMMARY.md      # What was hardened\n├── VULNERABILITIES_FIXED.md  # Issues resolved\n├── SECURITY_CONTROLS.md      # New security measures\n├── COMPLIANCE_STATUS.md      # Compliance verification\n└── SECURITY_CHECKLIST.md     # Ongoing security tasks\n```\n\n## Configuration\n\nOptional `.claude/harden-config.yaml`:\n\n```yaml\nharden:\n  scope:\n    scan_dependencies: true           # Scan for CVEs\n    scan_code: true                   # Scan source code\n    audit_configuration: true         # Audit config files\n    test_security_controls: true      # Penetration testing\n\n  severity_thresholds:\n    fix_critical: true                # Auto-fix critical issues\n    fix_high: true                    # Auto-fix high severity\n    report_medium: true               # Report medium severity\n    report_low: false                 # Ignore low severity\n\n  compliance:\n    standards:                        # Compliance requirements\n      - owasp-top-10\n      - gdpr\n      - soc2\n\n  secrets:\n    scan_patterns:                    # Patterns for secret detection\n      - api_key\n      - password\n      - secret\n      - token\n      - private_key\n```\n\n## Usage Examples\n\n### Example 1: Full Application Hardening\n\n```bash\n/harden \"comprehensive security hardening\"\n\n# Output:\n# ✅ Scanned 245 dependencies (found 8 CVEs)\n# ✅ Scanned source code (found 12 vulnerabilities)\n# ✅ Audited configuration (found 15 issues)\n#\n# Critical Issues (3):\n#   1. SQL injection vulnerability in search endpoint\n#   2. Hardcoded API key in config\n#   3. Missing authentication on admin endpoint\n#\n# ✅ Step 1/20: Fixed SQL injection with parameterized queries\n# ✅ Step 2/20: Moved API key to environment variable\n# ✅ Step 3/20: Added authentication middleware to admin routes\n# ...\n#\n# Security hardening complete:\n# - 3 critical vulnerabilities fixed\n# - 5 high-severity issues resolved\n# - 8 dependencies updated\n# - 15 configuration improvements applied\n# ✅ All 156 tests pass\n```\n\n### Example 2: Strengthen Authentication\n\n```bash\n/harden \"strengthen authentication and authorization\"\n\n# Output:\n# ✅ Audited authentication system\n# ✅ Found 6 issues:\n#    1. Weak password requirements (min 6 chars)\n#    2. No rate limiting on login\n#    3. JWT tokens never expire\n#    4. No MFA support\n#    5. Session fixation vulnerability\n#    6. Insufficient authorization checks\n#\n# ✅ Applied hardening:\n#    1. Increased password requirements (12+ chars, complexity)\n#    2. Added rate limiting (5 attempts per 15 min)\n#    3. Set JWT expiration (1 hour access, 7 days refresh)\n#    4. Implemented MFA with TOTP\n#    5. Regenerate session ID on login\n#    6. Added role-based authorization checks\n#\n# Authentication hardened ✅\n# Penetration tests pass ✅\n```\n\n## Quality Gates\n\nBefore completing hardening:\n\n- ✅ All critical vulnerabilities fixed\n- ✅ All high-severity issues addressed\n- ✅ No secrets in code\n- ✅ Security headers configured\n- ✅ Penetration tests pass\n- ✅ All tests pass\n\n## Safety Features\n\n1. **Non-Breaking**: Security fixes preserve functionality\n2. **Tested**: All changes tested for correctness\n3. **Incremental**: Small, focused security improvements\n4. **Validated**: Penetration testing confirms fixes\n5. **Documented**: All changes documented\n\n## Output Files\n\n```\nharden-output/\n├── VULNERABILITY_SCAN.md     # Initial scan results\n├── HARDENING_PLAN.md         # Step-by-step plan\n├── HARDENING_SUMMARY.md      # What was hardened\n├── VULNERABILITIES_FIXED.md  # Issues resolved\n├── SECURITY_CONTROLS.md      # Security measures added\n├── PENETRATION_TEST.md       # Security test results\n├── COMPLIANCE_STATUS.md      # Compliance verification\n└── SECURITY_CHECKLIST.md     # Ongoing security tasks\n```\n\n## Integration with Other Plugins\n\n- **After Review**: `/review` finds issues → `/harden` fixes them comprehensively\n- **Before Deploy**: Harden before production deployment\n- **With Audit**: `/audit` identifies debt, `/harden` improves security\n- **Ongoing**: Regular security hardening (monthly/quarterly)\n\n## Best Practices\n\n1. **Defense in Depth**: Multiple layers of security\n2. **Least Privilege**: Minimal permissions required\n3. **Fail Secure**: Default to secure state on errors\n4. **Keep Updated**: Regular dependency updates\n5. **Security by Design**: Build security in from the start\n6. **Test Security**: Regular penetration testing"
              }
            ],
            "skills": []
          },
          {
            "name": "review",
            "description": "Multi-perspective code review with 19 specialized reviewers covering architecture, security, performance, backend, frontend, and DevOps",
            "source": "./plugins/review",
            "category": "quality",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install review@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/review",
                "description": "Multi-perspective code review with 19 specialized reviewers covering architecture, security, and performance",
                "path": "plugins/review/commands/review.md",
                "frontmatter": {
                  "description": "Multi-perspective code review with 19 specialized reviewers covering architecture, security, and performance"
                },
                "content": "# Code Review Command\n\n**Purpose**: Multi-perspective code review with 19 specialized reviewers\n\n## Workflow\n\n### Step 1: Analyze Changed Files\n\nDetermine file types and which reviewers are needed:\n\n```bash\n# Get changed files\ngit diff --name-only origin/main...HEAD\n\n# Categorize files:\n# - Backend: *.php, *.py, *.js (non-frontend), *.go, *.sh\n# - Frontend: *.jsx, *.tsx, *.vue, *.html, *.css, *.scss\n# - Config: Dockerfile, *.yaml (k8s), .github/workflows/*.yml\n```\n\n### Step 2: Launch Parallel Reviewers\n\n**Always Launch** (regardless of file types):\n1. **architect-reviewer** - Architecture implications of any change\n2. **security-input-reviewer** - Check any user input handling\n3. **security-authentication-reviewer** - If auth-related changes detected\n\n**Conditionally Launch** (based on file types changed):\n\n**Security** (3 reviewers):\n- **security-authentication-reviewer**: If auth files changed\n- **security-input-reviewer**: If files handle user input\n- **security-crypto-reviewer**: If crypto/hashing files changed\n\n**Performance** (3 reviewers):\n- **performance-algorithm-reviewer**: If algorithm-heavy code changed\n- **performance-database-reviewer**: If database query files changed\n- **performance-resource-reviewer**: If resource management code changed\n\n**Backend** (5 reviewers - based on file extensions):\n- **backend-php-reviewer**: If `*.php` files changed\n- **backend-python-reviewer**: If `*.py` files changed\n- **backend-nodejs-reviewer**: If `*.js`, `*.ts` (backend) changed\n- **backend-go-reviewer**: If `*.go` files changed\n- **backend-bash-reviewer**: If `*.sh` files changed\n\n**Frontend** (4 reviewers - based on file extensions):\n- **frontend-react-reviewer**: If `*.jsx`, `*.tsx` files changed\n- **frontend-vue-reviewer**: If `*.vue` files changed\n- **frontend-html-reviewer**: If `*.html` or templates changed\n- **frontend-css-reviewer**: If `*.css`, `*.scss`, styled-components changed\n\n**DevOps** (3 reviewers - based on config files):\n- **devops-docker-reviewer**: If `Dockerfile`, `docker-compose.yml` changed\n- **devops-kubernetes-reviewer**: If k8s `*.yaml` files changed\n- **devops-cicd-reviewer**: If `.github/workflows/*.yml` or CI config changed\n\n**Each reviewer must**:\n- Review ONLY their domain\n- Assign confidence score (0-100) to each issue found\n- Filter and return only issues with confidence ≥ 80\n- Categorize severity: critical / high / medium / low\n- Provide specific file:line citations with GitHub permalinks\n\n### Step 3: Consolidate Review Results\n\nMerge all reviewer outputs:\n- Group by severity (critical, high, medium, low)\n- Remove duplicate issues (same issue reported by multiple reviewers)\n- Sort by confidence score (highest first)\n\n### Step 4: Apply Quality Gates\n\nCheck if changes meet quality criteria:\n- **Critical issues**: 0 allowed\n- **High issues**: ≤ 2 allowed\n- **Medium issues**: ≤ 10 allowed\n\n**If quality gates PASS**:\n- Proceed to Step 6 (Generate Report)\n\n**If quality gates FAIL**:\n- Proceed to Step 5 (Fix Loop)\n\n### Step 5: Fix Loop (max 2 iterations)\n\n**Iteration 1 & 2**:\n1. Present critical and high issues to user\n2. Apply fixes for critical/high issues\n3. Re-run ONLY the affected reviewers (not all 19)\n4. Check quality gates again\n5. If gates still fail and iteration < 2: repeat\n6. If gates still fail and iteration ≥ 2: escalate to user\n\n**Escalation Message**:\n```\n⚠️ Code review found persistent issues after 2 fix iterations.\n\nRemaining issues:\n- Critical: X\n- High: Y\n\nOptions:\n1. Manually address these issues\n2. Accept risk and proceed (not recommended for critical issues)\n3. Request architectural review\n```\n\n### Step 6: Generate Report\n\nCreate comprehensive review report:\n\n````markdown\n# Code Review Report\n\n**Date**: [ISO date]\n**Branch**: [branch name]\n**Reviewers**: [list of reviewers that ran]\n**Status**: ✅ APPROVED / ⚠️ NEEDS WORK / ❌ BLOCKED\n\n## Summary\n\n- **Files Reviewed**: X\n- **Issues Found**: Y\n- **Critical**: 0\n- **High**: Z\n- **Medium**: W\n- **Low**: V\n\n## Issues by Severity\n\n### Critical Issues (0)\n[None - or list with full details]\n\n### High Priority Issues (Z)\n\n#### 1. [Issue Title]\n- **File**: src/auth/login.js:45\n- **Reviewer**: security-authentication-reviewer\n- **Confidence**: 95\n- **Issue**: JWT token not properly validated before use\n- **Impact**: Authentication bypass possible\n- **Fix**: Add token signature verification before trust\n- **Link**: [GitHub permalink]\n\n[Repeat for each high issue]\n\n### Medium Priority Issues (W)\n[Brief list with links]\n\n### Low Priority Issues (V)\n[Brief list or omit if too many]\n\n## Review by Category\n\n### Architecture Review\n- **Reviewer**: architect-reviewer\n- **Issues**: X\n- **Summary**: [1-2 sentence summary]\n\n### Security Review\n- **Reviewers**: 3 security specialists\n- **Issues**: X\n- **Summary**: [1-2 sentence summary]\n\n[Continue for each category]\n\n## Recommendations\n\n### Must Fix Before Merge\n1. [Critical/High issue 1]\n2. [Critical/High issue 2]\n\n### Should Fix Soon\n1. [Medium issue 1]\n2. [Medium issue 2]\n\n### Consider for Future\n1. [Low priority improvement 1]\n2. [Low priority improvement 2]\n\n## Approval Status\n\n[If APPROVED]:\n✅ **APPROVED** - All quality gates passed\n\n[If NEEDS WORK]:\n⚠️ **NEEDS WORK** - Address X critical and Y high issues\n\n[If BLOCKED]:\n❌ **BLOCKED** - Critical security/architecture issues must be resolved\n````\n\n### Step 7: Post Review Actions\n\n- Comment review report on PR (if GitHub PR)\n- Save report to `./review-reports/review-[timestamp].md`\n- Update review status\n\n## Output Format\n\nThe review produces:\n- `review-reports/review-[timestamp].md` - Full review report\n- Console output with summary\n- PR comment (if applicable)\n\n## Usage\n\n```bash\n# Review current changes\n/review\n\n# Review specific files\n/review src/auth/*.js\n\n# Review PR\n/review --pr=123\n```\n\n## Notes\n\n- Minimum 2 reviewers always run (architect + security-input)\n- Maximum 19 reviewers if all file types present\n- Average 5-8 reviewers for typical changes\n- Review takes 2-5 minutes depending on change size\n- All reviewers run in parallel for speed"
              }
            ],
            "skills": []
          },
          {
            "name": "bugfix",
            "description": "Systematic bug fixing with reproduction, root cause analysis, fix implementation, and comprehensive regression testing",
            "source": "./plugins/bugfix",
            "category": "quality",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install bugfix@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/bugfix",
                "description": "Systematic bug fixing with reproduction, root cause analysis, fix implementation, and regression testing",
                "path": "plugins/bugfix/commands/bugfix.md",
                "frontmatter": {
                  "description": "Systematic bug fixing with reproduction, root cause analysis, fix implementation, and regression testing"
                },
                "content": "# Bugfix Command\n\n**Purpose**: Systematic bug fixing with reproduction, root cause analysis, fix implementation, and regression testing\n\n## Workflow\n\n1. **Bug Reproduction**: Reproduce the bug reliably\n2. **Root Cause Analysis**: Identify the exact cause\n3. **Impact Assessment**: Assess severity and affected areas\n4. **Fix Planning**: Plan the fix approach\n5. **Fix Implementation**: Implement the fix\n6. **Testing Loop**: Test → (if fail) → Re-analyze → Re-fix → Re-test (max 3 iterations)\n7. **Regression Testing**: Run full test suite\n\n## Specialized Agents (7)\n- bug-reproducer: Reproduces bugs and creates failing tests\n- root-cause-analyst: Identifies root causes\n- impact-assessor: Assesses impact and severity\n- fix-planner: Plans fix approach\n- fix-implementer: Implements fixes\n- fix-tester: Tests fixes\n- regression-tester: Runs regression tests\n\n## Usage\n```bash\n/bugfix \"Login fails with special characters in password\"\n```\n\n## Processing Loop\nFix → Test → (if fail) → Re-analyze → Re-fix → Re-test (max 3 iterations)\n\n## Version\n1.0.0"
              }
            ],
            "skills": []
          },
          {
            "name": "deploy",
            "description": "CI/CD pipeline setup, deployment automation, monitoring configuration, and rollback strategies",
            "source": "./plugins/deploy",
            "category": "operations",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install deploy@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/deploy",
                "description": "Automate deployment workflows with CI/CD pipelines, monitoring, and rollback capabilities",
                "path": "plugins/deploy/commands/deploy.md",
                "frontmatter": {
                  "description": "Automate deployment workflows with CI/CD pipelines, monitoring, and rollback capabilities"
                },
                "content": "# Deploy Command\n\n**Purpose**: Automate deployment workflows with CI/CD pipelines, monitoring, and rollback capabilities\n\n## Workflow\n\n### Step 1: Determine Deployment Goal\n- Setup CI/CD pipeline\n- Deploy to environment (staging/production)\n- Configure monitoring/alerting\n- Implement feature flags\n- Setup infrastructure\n\n### Step 2: Analyze Current State\n- Detect existing deployment setup\n- Identify gaps (no CI/CD, no monitoring, etc.)\n- Assess infrastructure needs\n\n### Step 3: Create Deployment Plan\nRun **deployment-strategist** agent:\n- Choose deployment strategy (blue-green, canary, rolling)\n- Plan CI/CD pipeline stages\n- Design monitoring setup\n- Create rollback plan\n\n### Step 4: Implement Infrastructure\nLaunch agents in parallel:\n1. **ci-cd-configurator** - Setup GitHub Actions/GitLab CI/Jenkins\n2. **infrastructure-coder** - Create Terraform/CloudFormation\n3. **monitoring-configurator** - Setup Datadog/Grafana/Prometheus\n\n### Step 5: Deploy\nRun **deployment-validator** agent:\n- Execute deployment\n- Run health checks\n- Verify monitoring\n- Test rollback mechanism\n\n### Step 6: Monitor\n- Real-time deployment monitoring\n- Automatic rollback on failure\n- Success confirmation\n\n## Usage Examples\n\n```bash\n/deploy \"Setup GitHub Actions CI/CD\"\n/deploy \"Deploy to staging\"\n/deploy \"Setup monitoring for production\"\n/deploy \"Implement feature flags\"\n/deploy production\n```\n\n## Agents (7)\n\n1. **ci-cd-configurator** - Setup CI/CD pipelines\n2. **infrastructure-coder** - Create IaC (Terraform, CloudFormation)\n3. **monitoring-configurator** - Setup monitoring/alerting\n4. **deployment-strategist** - Plan deployment strategy\n5. **rollback-planner** - Plan rollback mechanisms\n6. **feature-flag-implementer** - Implement feature flags\n7. **deployment-validator** - Validate deployment health\n\n## Deployment Strategies\n\n**Blue-Green**: Two identical environments, switch between them\n**Canary**: Gradual rollout to subset of users\n**Rolling**: Update instances one by one\n**Feature Flags**: Deploy dark, enable gradually\n\n## Output\n\n```\ndeploy-output/\n├── DEPLOYMENT_PLAN.md\n├── ci-cd-config.yml\n├── infrastructure.tf\n├── monitoring-config.yml\n└── ROLLBACK_PROCEDURE.md\n```"
              }
            ],
            "skills": []
          },
          {
            "name": "migrate",
            "description": "Framework and database migrations with zero-downtime strategies and rollback planning",
            "source": "./plugins/migrate",
            "category": "operations",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install migrate@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/migrate",
                "description": "Framework upgrades, database migrations, and API version migrations with zero-downtime strategies",
                "path": "plugins/migrate/commands/migrate.md",
                "frontmatter": {
                  "description": "Framework upgrades, database migrations, and API version migrations with zero-downtime strategies"
                },
                "content": "# Migrate Command\n\n**Purpose**: Systematic framework upgrades, database migrations, and API version migrations with zero-downtime strategies and comprehensive rollback planning\n\n## Overview\n\nThe migrate command handles complex migrations that are essential for keeping tech stacks modern: React 17→18, Vue 2→3, PostgreSQL 12→15, Python 2→3, API v1→v2, etc.\n\n**Key Distinction**:\n- **Migrate** changes underlying frameworks/databases\n- **Refactor** improves code structure without changing behavior\n- **Feature** adds new functionality\n\n## Workflow\n\n### Step 1: Validate Migration Target\n\n1. **Parse migration request**\n   - Source version (React 17, PostgreSQL 12, etc.)\n   - Target version (React 18, PostgreSQL 15, etc.)\n   - Scope (full codebase, specific modules)\n\n2. **Validate feasibility**\n   - Check current version\n   - Verify target version exists\n   - Assess compatibility\n\n3. **Identify migration type**\n   - Framework upgrade (React, Vue, Angular, Django)\n   - Database migration (PostgreSQL, MySQL, MongoDB)\n   - Language upgrade (Python 2→3, PHP 7→8, Node 14→20)\n   - API versioning (v1→v2)\n   - Package manager migration (npm→pnpm, bower→npm)\n\n### Step 2: Analyze Breaking Changes\n\nRun **compatibility-analyzer** agent to:\n- Fetch official migration guides\n- Identify breaking changes\n- Scan codebase for affected patterns\n- Detect deprecated APIs in use\n- Identify incompatible dependencies\n- Assess migration complexity\n- Estimate effort and risk\n\n**Output**:\n```\nmigration-plan/\n├── BREAKING_CHANGES.md       # All breaking changes from docs\n├── IMPACT_ANALYSIS.md        # What's affected in codebase\n├── DEPENDENCY_ANALYSIS.md    # Dependency compatibility\n└── RISK_ASSESSMENT.md        # Migration risks\n```\n\n### Step 3: Plan Migration Strategy\n\nRun **migration-planner** agent to:\n- Choose migration strategy:\n  - **Big Bang**: Full migration at once (lower complexity)\n  - **Incremental**: Gradual migration (lower risk)\n  - **Parallel Run**: Run old and new side-by-side\n  - **Dual-Write**: Write to both, read from one\n- Design migration phases\n- Plan feature flag strategy\n- Design rollback approach\n- Create testing strategy\n- Define success criteria\n\n**Output**: `MIGRATION_STRATEGY.md` with detailed approach\n\n**Strategy Decision Matrix**:\n```\nBig Bang Migration:\n✅ Simple codebase\n✅ Good test coverage\n✅ Can afford downtime\n❌ Large codebase\n❌ Critical 24/7 system\n\nIncremental Migration:\n✅ Large codebase\n✅ No downtime allowed\n✅ Multiple teams\n❌ Simple upgrade\n❌ Tight deadline\n\nParallel Run:\n✅ Database migrations\n✅ Critical systems\n✅ Complex business logic\n❌ Resource constraints\n```\n\n### Step 4: Review Plan (Optional)\n\nPresent migration plan to user:\n- Migration strategy (Big Bang vs Incremental)\n- Breaking changes to address\n- Estimated timeline\n- Risk mitigation approaches\n- Rollback plan\n\nWait for approval before proceeding.\n\n### Step 5: Prepare Environment\n\n**Pre-Migration Steps**:\n1. **Backup**: Create full backup\n2. **Baseline**: Capture current metrics\n3. **Branch**: Create migration branch\n4. **Tests**: Ensure all tests pass\n5. **Dependencies**: Update package manager\n6. **Documentation**: Backup current docs\n\n### Step 6: Execute Migration\n\nBased on strategy, launch appropriate agents:\n\n#### For Big Bang Migration:\n\nRun **code-transformer** agent:\n1. Update dependencies\n2. Transform code patterns\n3. Update configurations\n4. Fix breaking changes\n5. Update imports/requires\n6. Migrate database schema (if applicable)\n\n#### For Incremental Migration:\n\nRun **dual-write-implementer** agent:\n1. **Phase 1: Setup**\n   - Add new version dependencies\n   - Add feature flags\n   - Setup dual environment\n\n2. **Phase 2: Dual Write**\n   - Write to both old and new\n   - Read from old (stable)\n   - Monitor consistency\n\n3. **Phase 3: Dual Read**\n   - Write to both\n   - Read from new (gradual)\n   - Compare results\n\n4. **Phase 4: New Only**\n   - Switch fully to new\n   - Keep old as fallback\n   - Monitor closely\n\n5. **Phase 5: Cleanup**\n   - Remove old code\n   - Remove feature flags\n   - Update documentation\n\n### Step 7: Transform Code\n\nRun **code-transformer** agent for each breaking change:\n\n**Example Transformations**:\n\n**React 17→18**:\n```javascript\n// Before: ReactDOM.render\nimport ReactDOM from 'react-dom';\nReactDOM.render(<App />, document.getElementById('root'));\n\n// After: createRoot\nimport { createRoot } from 'react-dom/client';\nconst root = createRoot(document.getElementById('root'));\nroot.render(<App />);\n```\n\n**Python 2→3**:\n```python\n# Before: print statement\nprint \"Hello, World!\"\n\n# After: print function\nprint(\"Hello, World!\")\n```\n\n**PostgreSQL 12→15**:\n```sql\n-- Before: Old syntax\nGRANT ALL ON SCHEMA public TO user;\n\n-- After: New syntax\nGRANT ALL ON SCHEMA public TO user;\nGRANT ALL ON ALL TABLES IN SCHEMA public TO user;\n```\n\n### Step 8: Test Migration\n\nRun **migration-tester** agent to:\n\n**Test Levels**:\n1. **Unit Tests**: Verify all pass\n2. **Integration Tests**: Check module interactions\n3. **End-to-End Tests**: Validate user flows\n4. **Performance Tests**: Compare before/after\n5. **Data Integrity**: Verify data consistency\n6. **Backward Compatibility**: Ensure old clients work\n\n**Test Strategy**:\n```\nFor each test suite:\n  Run tests → Pass? → Continue\n              ↓ Fail\n        Analyze → Fix → Re-test → Pass? → Continue\n                                     ↓ Fail (after 3 attempts)\n                                   Document & Flag\n```\n\n### Step 9: Create Rollback Plan\n\nRun **rollback-planner** agent to:\n- Document rollback procedure\n- Create rollback scripts\n- Test rollback process\n- Define rollback triggers\n- Identify rollback window\n\n**Rollback Triggers**:\n- Test failure rate > 10%\n- Performance degradation > 20%\n- Error rate increase > 5%\n- Critical bug discovered\n- Data corruption detected\n\n**Output**: `ROLLBACK_PLAN.md` with step-by-step rollback instructions\n\n### Step 10: Execute Cutover\n\n**For Production Migration**:\n\n1. **Pre-Cutover Checklist**:\n   - ✅ All tests passing\n   - ✅ Rollback plan ready\n   - ✅ Backup completed\n   - ✅ Team briefed\n   - ✅ Monitoring configured\n   - ✅ Communication plan ready\n\n2. **Cutover Window**:\n   - Choose low-traffic period\n   - Enable maintenance mode (if needed)\n   - Execute migration\n   - Run smoke tests\n   - Monitor metrics\n\n3. **Post-Cutover Monitoring**:\n   - Error rates\n   - Response times\n   - User reports\n   - System stability\n\n4. **Decision Point** (after 24-48 hours):\n   - All clear → Proceed to cleanup\n   - Issues found → Rollback\n\n### Step 11: Cleanup (After Successful Migration)\n\nRun **cleanup** agent to:\n- Remove old version code\n- Remove feature flags\n- Remove dual-write logic\n- Update dependencies\n- Clean up configurations\n- Archive old documentation\n\n### Step 12: Document Migration\n\nRun **documentation-updater** agent to:\n- Update technical documentation\n- Create migration runbook\n- Document breaking changes handled\n- Update API documentation\n- Create team training materials\n\n**Output**:\n```\nmigration-output/\n├── MIGRATION_SUMMARY.md      # What was migrated\n├── CHANGES_MADE.md           # All code changes\n├── BREAKING_CHANGES_FIXED.md # How each was handled\n├── ROLLBACK_PLAN.md          # Rollback procedure\n├── TESTING_RESULTS.md        # Test outcomes\n├── LESSONS_LEARNED.md        # Post-mortem insights\n└── TEAM_GUIDE.md             # Developer reference\n```\n\n## Migration Strategies in Detail\n\n### Strategy 1: Big Bang Migration\n\n**Best For**: Small to medium codebases, good test coverage, acceptable downtime\n\n**Process**:\n```\n1. Create migration branch\n2. Update all dependencies at once\n3. Fix all breaking changes\n4. Run full test suite\n5. Deploy to staging\n6. Test thoroughly\n7. Deploy to production (with downtime window)\n8. Monitor closely\n```\n\n**Pros**:\n- ✅ Simpler to execute\n- ✅ Faster completion\n- ✅ No dual-code maintenance\n\n**Cons**:\n- ❌ Higher risk\n- ❌ Requires downtime\n- ❌ All-or-nothing\n\n### Strategy 2: Incremental Migration\n\n**Best For**: Large codebases, zero-downtime requirement, multiple teams\n\n**Process**:\n```\n1. Migrate module by module\n2. Use feature flags\n3. Run old and new in parallel\n4. Gradually shift traffic\n5. Monitor each phase\n6. Rollback capability at each phase\n```\n\n**Pros**:\n- ✅ Lower risk\n- ✅ No downtime\n- ✅ Gradual validation\n\n**Cons**:\n- ❌ More complex\n- ❌ Longer timeline\n- ❌ Maintain both versions\n\n### Strategy 3: Parallel Run (Dual-Write)\n\n**Best For**: Database migrations, critical systems, complex business logic\n\n**Process**:\n```\nPhase 1: Setup\n  ├─ Install new database version\n  └─ Configure replication\n\nPhase 2: Dual Write\n  ├─ Write to both databases\n  ├─ Read from old (primary)\n  └─ Compare results\n\nPhase 3: Verify Consistency\n  ├─ Run reconciliation checks\n  └─ Fix any discrepancies\n\nPhase 4: Switch Read\n  ├─ Read from new (primary)\n  ├─ Write to both\n  └─ Monitor closely\n\nPhase 5: Full Cutover\n  ├─ New database only\n  ├─ Keep old as backup\n  └─ Archive after 30 days\n```\n\n**Pros**:\n- ✅ Zero downtime\n- ✅ Continuous validation\n- ✅ Easy rollback\n\n**Cons**:\n- ❌ 2x write overhead\n- ❌ Data consistency complexity\n- ❌ Resource intensive\n\n## Configuration\n\nOptional `.claude/migrate-config.yaml`:\n\n```yaml\nmigrate:\n  strategy:\n    default: \"incremental\"         # big_bang, incremental, parallel_run\n    allow_downtime: false          # Allow maintenance windows\n    max_downtime_minutes: 30       # Max acceptable downtime\n\n  testing:\n    run_full_suite: true           # Run all tests\n    require_100_percent_pass: true # Must all pass\n    performance_threshold: 1.2     # Max 20% slowdown\n\n  rollback:\n    auto_rollback_enabled: true    # Auto rollback on failure\n    rollback_window_hours: 48      # Time to keep rollback ready\n    error_rate_threshold: 0.05     # 5% error rate triggers rollback\n\n  monitoring:\n    monitor_duration_hours: 48     # Monitor after cutover\n    alert_on_anomalies: true       # Alert on unusual patterns\n\n  documentation:\n    create_runbook: true           # Create migration runbook\n    update_team_docs: true         # Update team documentation\n```\n\n## Usage Examples\n\n### Example 1: React 17 to 18\n\n```bash\n/migrate \"Upgrade React 17 to 18\"\n\n# Output:\n# ✅ Detected React 17.0.2 → Target: React 18.2.0\n# ✅ Analyzed breaking changes (4 major changes found)\n# ✅ Scanned codebase: 156 files affected\n#\n# Breaking Changes:\n# 1. ReactDOM.render → createRoot (45 files)\n# 2. Automatic batching behavior (12 files need review)\n# 3. Stricter hydration (3 files)\n# 4. useEffect timing changes (8 files)\n#\n# Strategy: Big Bang (good test coverage, can afford 2hr window)\n#\n# ✅ Updated package.json\n# ✅ Transformed 45 ReactDOM.render calls\n# ✅ Updated test utilities\n# ✅ Fixed hydration warnings\n# ✅ All 342 tests pass\n#\n# Migration complete! React 18.2.0 ✅\n```\n\n### Example 2: PostgreSQL 12 to 15\n\n```bash\n/migrate \"Migrate PostgreSQL 12 to 15\"\n\n# Output:\n# ✅ Detected PostgreSQL 12.8 → Target: 15.3\n# ✅ Analyzed breaking changes (6 changes found)\n# ✅ Database size: 45GB, 127 tables\n#\n# Strategy: Parallel Run (zero-downtime required)\n#\n# Phase 1: Setup (Day 1)\n#   ✅ Provisioned PostgreSQL 15 instance\n#   ✅ Configured logical replication\n#   ✅ Tested connectivity\n#\n# Phase 2: Dual Write (Days 2-3)\n#   ✅ Enabled dual-write mode\n#   ✅ Monitoring replication lag: <100ms\n#   ✅ Running consistency checks\n#\n# Phase 3: Verification (Day 4)\n#   ✅ Compared 1M random records: 100% match\n#   ✅ Query performance: PG15 10% faster\n#   ✅ All indexes migrated\n#\n# Phase 4: Read Switch (Day 5)\n#   ✅ Directed read traffic to PG15\n#   ✅ Monitoring query performance\n#   ✅ No errors detected\n#\n# Phase 5: Full Cutover (Day 6)\n#   ✅ Switched to PG15 exclusively\n#   ✅ PG12 kept as hot backup\n#   ✅ 24hr monitoring: all green\n#\n# Migration complete! PostgreSQL 15.3 ✅\n# Rollback available for 48 hours\n```\n\n### Example 3: Python 2 to 3\n\n```bash\n/migrate \"Upgrade Python 2.7 to Python 3.11\"\n\n# Output:\n# ✅ Detected Python 2.7 → Target: Python 3.11\n# ✅ Analyzed breaking changes (15 major changes)\n# ✅ Scanned: 234 Python files\n#\n# Breaking Changes:\n# 1. print statement → function (456 occurrences)\n# 2. dict.iteritems() → dict.items() (89 occurrences)\n# 3. unicode/str handling (123 occurrences)\n# 4. integer division (67 occurrences)\n# ... and 11 more\n#\n# Strategy: Incremental (large codebase)\n#\n# ✅ Phase 1: Automated transformations\n#   → Run 2to3 tool\n#   → Fixed 1,234 automatic conversions\n#   → Tests: 89% pass rate\n#\n# ✅ Phase 2: Manual fixes (remaining 11%)\n#   → Fixed unicode handling (45 files)\n#   → Updated dependencies (23 packages)\n#   → Tests: 98% pass rate\n#\n# ✅ Phase 3: Edge cases (remaining 2%)\n#   → Fixed custom C extensions (3 files)\n#   → Updated async patterns (5 files)\n#   → Tests: 100% pass rate\n#\n# Migration complete! Python 3.11 ✅\n# All 1,567 tests passing\n```\n\n### Example 4: API v1 to v2\n\n```bash\n/migrate \"Migrate API from v1 to v2\"\n\n# Output:\n# ✅ Analyzed API changes\n# ✅ Found 23 endpoints affected\n#\n# Strategy: Incremental with Dual Support\n#\n# Phase 1: Add v2 Endpoints (Week 1)\n#   ✅ Created v2 routes alongside v1\n#   ✅ Implemented new response format\n#   ✅ Both versions operational\n#\n# Phase 2: Migrate Clients (Weeks 2-3)\n#   ✅ Updated mobile app → v2\n#   ✅ Updated web app → v2\n#   ✅ Updated partner integrations → v2\n#   ✅ 85% of traffic on v2\n#\n# Phase 3: Deprecation (Week 4)\n#   ✅ Added deprecation warnings to v1\n#   ✅ Notified remaining clients\n#   ✅ 99% of traffic on v2\n#\n# Phase 4: Sunset v1 (Week 6)\n#   ✅ Removed v1 endpoints\n#   ✅ Updated documentation\n#   ✅ 100% on v2\n#\n# Migration complete! API v2 ✅\n```\n\n## Quality Gates\n\nBefore completing migration:\n\n- ✅ All breaking changes addressed\n- ✅ Test pass rate: 100%\n- ✅ Performance acceptable (< 20% degradation)\n- ✅ No critical bugs\n- ✅ Rollback plan tested\n- ✅ Documentation updated\n\nIf any gate fails:\n- Report issue\n- Recommend rollback or fixes\n- Update migration plan\n\n## Safety Features\n\n1. **Comprehensive Analysis**: Analyzes all breaking changes upfront\n2. **Incremental Approach**: Can migrate in phases\n3. **Rollback Ready**: Tested rollback plan always available\n4. **Dual-Write Support**: Run old and new in parallel\n5. **Monitoring**: Continuous monitoring during migration\n6. **Test Coverage**: Full test suite required\n\n## Output Files\n\n```\nmigration-output/\n├── MIGRATION_SUMMARY.md      # Executive summary\n├── BREAKING_CHANGES.md       # All breaking changes\n├── IMPACT_ANALYSIS.md        # Codebase impact\n├── MIGRATION_STRATEGY.md     # Chosen strategy\n├── CHANGES_MADE.md           # All code changes\n├── ROLLBACK_PLAN.md          # Rollback procedure\n├── TESTING_RESULTS.md        # Test outcomes\n├── PERFORMANCE_COMPARISON.md # Before/after metrics\n└── TEAM_GUIDE.md             # Developer reference\n```\n\n## Integration with Other Plugins\n\n- **After Research**: `/research` evaluates version → `/migrate` performs upgrade\n- **With Test**: Can run tests during migration\n- **Before Deploy**: Migrate in staging before production\n- **With Monitor**: Monitor metrics during and after migration\n\n## Notes\n\n- **Planning is Critical**: 70% planning, 30% execution\n- **Test Coverage Required**: Need tests to validate migration\n- **Rollback is Essential**: Always have a rollback plan\n- **Incremental is Safer**: For large systems, go incremental\n- **Monitor Closely**: Watch for issues 24-48 hours post-migration\n\n## Best Practices\n\n1. **Analyze First**: Understand all breaking changes before starting\n2. **Test in Staging**: Never migrate production without staging test\n3. **Have Rollback Ready**: Test rollback procedure\n4. **Monitor Metrics**: Watch error rates, performance, user reports\n5. **Communicate**: Keep team informed throughout migration\n6. **Document Everything**: Future migrations benefit from lessons learned\n\n## Common Migration Patterns\n\nThe plugin supports:\n\n**Framework Migrations**:\n- React (any version)\n- Vue 2→3\n- Angular 1→2+\n- Django 1.x→4.x\n- Rails 5→7\n\n**Database Migrations**:\n- PostgreSQL\n- MySQL\n- MongoDB\n- Redis\n\n**Language Migrations**:\n- Python 2→3\n- PHP 7→8\n- Node 14→20\n- Java 8→17\n\n**API Migrations**:\n- REST API versioning\n- GraphQL schema evolution\n- gRPC updates"
              }
            ],
            "skills": []
          },
          {
            "name": "document",
            "description": "Documentation maintenance through automated API documentation, architecture diagrams, and comprehensive developer guides",
            "source": "./plugins/document",
            "category": "knowledge",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install document@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/document",
                "description": "Documentation maintenance with automated API docs, architecture diagrams, and developer guides",
                "path": "plugins/document/commands/document.md",
                "frontmatter": {
                  "description": "Documentation maintenance with automated API docs, architecture diagrams, and developer guides"
                },
                "content": "# Document Command\n\n**Purpose**: Documentation maintenance through automated API documentation, architecture diagrams, and comprehensive developer guides\n\n## Overview\n\nThe document command ensures documentation stays synchronized with code. Research shows that **outdated documentation costs teams 20-30% of development time** in confusion and miscommunication.\n\n**Key Distinction**: Document maintains existing documentation, while Audit generates initial documentation.\n\n## Workflow\n\n### Step 1: Analyze Code\n- Scan API endpoints\n- Analyze architecture\n- Identify undocumented features\n- Find outdated documentation\n\n### Step 2: Generate Documentation\nRun specialized agents:\n- **api-documenter**: API endpoint documentation\n- **architecture-documenter**: System architecture docs\n- **onboarding-guide-creator**: New developer guides\n- **runbook-writer**: Operational procedures\n\n### Step 3: Add Examples\n- Code examples for APIs\n- Usage patterns\n- Common scenarios\n- Integration examples\n\n### Step 4: Create Diagrams\n- Architecture diagrams\n- Sequence diagrams\n- Data flow diagrams\n- Entity relationship diagrams\n\n### Step 5: Validate Consistency\n- Check doc accuracy\n- Verify examples work\n- Ensure completeness\n\n## Usage Examples\n\n```bash\n/document \"update API documentation for /api/users endpoints\"\n/document \"create architecture documentation\"\n/document \"generate onboarding guide for new developers\"\n/document \"create runbook for deployment process\"\n```\n\n## Output\n\n```\ndocumentation/\n├── API.md                     # API documentation\n├── ARCHITECTURE.md            # System architecture\n├── ONBOARDING.md             # Developer onboarding\n├── RUNBOOK.md                # Operational procedures\n├── examples/                 # Code examples\n└── diagrams/                 # Architecture diagrams\n```\n\n**Priority**: P3 - MEDIUM"
              }
            ],
            "skills": []
          },
          {
            "name": "ai-integration",
            "description": "AI/ML workflows including LLM integration, vector databases, RAG implementation, and ML pipelines",
            "source": "./plugins/ai-integration",
            "category": "ai-ml",
            "version": "0.1.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install ai-integration@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/ai-integration",
                "description": "AI/ML workflows including LLM integration, vector databases, RAG implementation, and ML pipelines",
                "path": "plugins/ai-integration/commands/ai-integration.md",
                "frontmatter": {
                  "description": "AI/ML workflows including LLM integration, vector databases, RAG implementation, and ML pipelines"
                },
                "content": "# AI Integration Command\n\n**Purpose**: AI/ML workflows including LLM integration, vector databases, RAG implementation, and ML pipelines\n\n## Overview\n\nThe ai-integration command provides comprehensive AI/ML integration workflows. With the explosion of AI capabilities, teams need systematic approaches to integrate LLMs, embeddings, and ML models.\n\n**Key Use Cases**:\n- LLM API integration (OpenAI, Anthropic, etc.)\n- Vector database setup (Pinecone, Weaviate, Qdrant)\n- RAG (Retrieval-Augmented Generation) implementation\n- Embedding generation and search\n- Prompt engineering and optimization\n- ML pipeline development\n\n## Workflow\n\n### Step 1: Define Use Case\n- Identify AI/ML requirement\n- Choose appropriate approach\n- Define success criteria\n\n### Step 2: Setup Infrastructure\nRun specialized agents:\n- **llm-integrator**: Integrate LLM APIs\n- **vector-db-configurator**: Setup vector database\n- **embedding-generator**: Generate embeddings\n\n### Step 3: Implement Features\n- RAG implementation\n- Semantic search\n- AI-powered features\n\n### Step 4: Optimize\n- **prompt-optimizer**: Improve prompts\n- **model-evaluator**: Test and validate\n\n### Step 5: Deploy\n- ML pipeline setup\n- Monitoring configuration\n- Cost optimization\n\n## Usage Examples\n\n```bash\n/ai-integration \"add semantic search to documentation\"\n/ai-integration \"implement RAG for customer support\"\n/ai-integration \"integrate GPT-4 for content generation\"\n/ai-integration \"setup vector database for embeddings\"\n```\n\n## Specialized Agents (7)\n\n### 1. **llm-integrator**\nIntegrates LLM APIs (OpenAI, Anthropic, Cohere, etc.)\n\n### 2. **vector-db-configurator**\nSets up vector databases (Pinecone, Weaviate, Qdrant, Chroma)\n\n### 3. **embedding-generator**\nGenerates and manages embeddings\n\n### 4. **rag-implementer**\nImplements RAG (Retrieval-Augmented Generation)\n\n### 5. **prompt-optimizer**\nOptimizes prompts for better results\n\n### 6. **ml-pipeline-builder**\nBuilds ML training/inference pipelines\n\n### 7. **model-evaluator**\nTests and validates AI/ML performance\n\n## Output\n\n```\nai-integration-output/\n├── INTEGRATION_PLAN.md       # Integration design\n├── IMPLEMENTATION.md         # What was built\n├── PROMPTS.md                # Optimized prompts\n├── EVALUATION.md             # Performance metrics\n└── DEPLOYMENT_GUIDE.md       # Deployment instructions\n```\n\n**Priority**: NEW - HIGH (emerging importance)"
              }
            ],
            "skills": []
          },
          {
            "name": "qa",
            "description": "Quality Assurance workflows with browser testing (Playwright MCP), test writing, and comprehensive test execution for unit, integration, and E2E testing",
            "source": "./plugins/qa",
            "category": "quality",
            "version": "0.2.0",
            "author": {
              "name": "Claude Code Marketplace Contributors",
              "email": "noreply@anthropic.com"
            },
            "install_commands": [
              "/plugin marketplace add avovello/cc-plugins",
              "/plugin install qa@cc-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-04T11:54:07Z",
              "created_at": "2025-11-05T06:15:26Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/e2e",
                "description": "Run end-to-end tests using Playwright for browser automation",
                "path": "plugins/qa/commands/e2e.md",
                "frontmatter": {
                  "description": "Run end-to-end tests using Playwright for browser automation"
                },
                "content": "# E2E Command\n\nRuns end-to-end tests using Playwright for browser automation.\n\n## Usage\n\n```bash\n/e2e                       # Run all E2E tests\n/e2e [test-file]           # Run specific test file\n/e2e [pattern]             # Run tests matching pattern\n/e2e --headed              # Run with visible browser\n/e2e --browser=firefox     # Run in specific browser\n/e2e --debug               # Run in debug mode\n```\n\n## What It Does\n\nThe `/e2e` command executes Playwright-based end-to-end tests:\n\n1. **Detect Configuration** - Find playwright.config.ts\n2. **Start Dev Server** - If configured in playwright config\n3. **Run Tests** - Execute E2E test suites\n4. **Generate Report** - HTML report with screenshots/videos\n5. **Report Results** - Summary with failures and artifacts\n\n## Agents Used\n\n| Agent | Purpose |\n|-------|---------|\n| `test-runner` | Execute Playwright test suite |\n\n## Browser Options\n\n```bash\n/e2e --browser=chromium    # Google Chrome\n/e2e --browser=firefox     # Mozilla Firefox\n/e2e --browser=webkit      # Apple Safari\n/e2e --browser=all         # All browsers\n```\n\n## Output\n\n```markdown\n# E2E Test Report\n\n## Summary\n- Total: 24 tests\n- Passed: 22 (91.7%)\n- Failed: 2 (8.3%)\n- Duration: 2m 15s\n\n## Browser Results\n| Browser | Passed | Failed |\n|---------|--------|--------|\n| Chromium | 23 | 1 |\n| Firefox | 22 | 2 |\n| WebKit | 24 | 0 |\n\n## Failed Tests\n1. login.spec.ts:23 - Timeout waiting for dashboard\n   Screenshot: test-results/login-failed.png\n\n## View Report\nnpx playwright show-report\n```\n\n## Options\n\n| Option | Description |\n|--------|-------------|\n| `--headed` | Show browser window |\n| `--debug` | Run in debug mode |\n| `--browser=<name>` | Specific browser |\n| `--workers=<n>` | Parallel workers |\n| `--retries=<n>` | Retry failed tests |\n| `--ui` | Interactive UI mode |\n\n## Examples\n\n```bash\n# Run all E2E tests\n/e2e\n\n# Run specific test file\n/e2e tests/e2e/auth/login.spec.ts\n\n# Run tests matching pattern\n/e2e auth\n\n# Debug failing test\n/e2e login.spec.ts --debug --headed\n\n# Run in specific browser\n/e2e --browser=firefox\n\n# Interactive mode\n/e2e --ui\n```\n\n## Interactive Testing\n\nFor manual browser exploration before writing tests:\n\n```bash\n/e2e --explore [url]\n```\n\nThis uses the `browser-tester` agent with Playwright MCP for interactive testing."
              },
              {
                "name": "/integration",
                "description": "Run integration tests for API, database, and service testing",
                "path": "plugins/qa/commands/integration.md",
                "frontmatter": {
                  "description": "Run integration tests for API, database, and service testing"
                },
                "content": "# Integration Command\n\nRuns integration tests for API, database, and service testing.\n\n## Usage\n\n```bash\n/integration               # Run all integration tests\n/integration [file]        # Run specific test file\n/integration [pattern]     # Run tests matching pattern\n/integration --api         # Run API tests only\n/integration --db          # Run database tests only\n```\n\n## What It Does\n\nThe `/integration` command executes integration tests:\n\n1. **Setup Environment** - Prepare test database/services\n2. **Run Tests** - Execute integration test suite\n3. **Report Results** - Summary with failures\n4. **Cleanup** - Reset test environment\n\n## Agents Used\n\n| Agent | Purpose |\n|-------|---------|\n| `test-runner` | Execute integration test suite |\n\n## Test Types\n\n| Type | Description | Location |\n|------|-------------|----------|\n| API | HTTP endpoint tests | tests/integration/api/ |\n| Database | CRUD operation tests | tests/integration/db/ |\n| Service | External service tests | tests/integration/services/ |\n\n## Output\n\n```markdown\n# Integration Test Report\n\n## Summary\n- Total: 34 tests\n- Passed: 33 (97%)\n- Failed: 1 (3%)\n- Duration: 45s\n\n## Test Categories\n| Category | Passed | Failed |\n|----------|--------|--------|\n| API | 18 | 0 |\n| Database | 12 | 1 |\n| Services | 4 | 0 |\n\n## Failed Tests\n1. users.test.ts:78 - POST /api/users validation\n   Expected: 400 Bad Request\n   Received: 500 Internal Server Error\n```\n\n## Options\n\n| Option | Description |\n|--------|-------------|\n| `--api` | API tests only |\n| `--db` | Database tests only |\n| `--services` | Service tests only |\n| `--verbose` | Detailed output |\n| `--bail` | Stop on first failure |\n\n## Environment Setup\n\nIntegration tests may require:\n\n```bash\n# Start test database\ndocker-compose -f docker-compose.test.yml up -d\n\n# Run migrations\nnpm run db:migrate:test\n\n# Seed test data\nnpm run db:seed:test\n```\n\n## Examples\n\n```bash\n# Run all integration tests\n/integration\n\n# Run API tests only\n/integration --api\n\n# Run specific test file\n/integration tests/integration/api/users.test.ts\n\n# Run tests matching pattern\n/integration users\n\n# Database tests only\n/integration --db\n```\n\n## Test Database\n\n### Options\n\n| Strategy | Pros | Cons |\n|----------|------|------|\n| In-memory SQLite | Fast | Limited features |\n| Docker container | Realistic | Slower startup |\n| Transactions | Fast cleanup | Complexity |\n\n### Recommended Setup\n\n```typescript\n// tests/setup.ts\nbeforeAll(async () => {\n  await db.migrate.latest();\n});\n\nbeforeEach(async () => {\n  await db.seed.run();\n});\n\nafterEach(async () => {\n  await db('users').truncate();\n});\n```"
              },
              {
                "name": "/qa",
                "description": "Comprehensive quality assurance workflow including unit, integration, and E2E tests",
                "path": "plugins/qa/commands/qa.md",
                "frontmatter": {
                  "description": "Comprehensive quality assurance workflow including unit, integration, and E2E tests"
                },
                "content": "# QA Command\n\nRuns comprehensive quality assurance workflow including unit, integration, and E2E tests.\n\n## Usage\n\n```bash\n/qa                    # Run full QA suite\n/qa [target]           # Run QA on specific area\n/qa --coverage         # Run with coverage reports\n/qa --quick            # Run unit tests only (fast)\n```\n\n## What It Does\n\nThe `/qa` command orchestrates a complete quality assurance workflow:\n\n### 1. Unit Tests (Fast)\n- Run isolated function/component tests\n- Generate coverage report\n- **Stop on failure** - Critical tests must pass\n\n### 2. Integration Tests (Medium)\n- Run API and database tests\n- Verify component interactions\n- **Stop on failure** - Integration issues block deployment\n\n### 3. E2E Tests (Comprehensive)\n- Run Playwright browser tests\n- Test complete user workflows\n- Capture screenshots/videos on failure\n\n## Execution Order\n\n```\nUnit Tests → Integration Tests → E2E Tests\n   (~10s)        (~1-2min)        (~3-5min)\n```\n\nTests run sequentially - if unit tests fail, integration and E2E tests are skipped.\n\n## Agents Used\n\n| Phase | Agent | Purpose |\n|-------|-------|---------|\n| Unit | `test-runner` | Execute unit test suite |\n| Integration | `test-runner` | Execute integration tests |\n| E2E | `test-runner` | Execute Playwright tests |\n\n## Output\n\n```markdown\n# QA Report\n\n## Summary\n- Unit Tests: 98 passed, 0 failed (12s)\n- Integration Tests: 34 passed, 0 failed (45s)\n- E2E Tests: 24 passed, 0 failed (2m 15s)\n- Coverage: 87.3%\n\n## Status: PASSED\n\n## Details\n[Detailed results from each phase]\n```\n\n## Options\n\n| Option | Description |\n|--------|-------------|\n| `--coverage` | Generate coverage reports |\n| `--quick` | Run unit tests only |\n| `--verbose` | Show detailed output |\n| `--bail` | Stop on first failure (default) |\n| `--no-bail` | Run all tests even on failure |\n\n## Requirements\n\n- Test frameworks configured (Jest/Vitest, pytest, Playwright)\n- Test files in standard locations\n- Dependencies installed\n\n## Examples\n\n```bash\n# Full QA suite\n/qa\n\n# Quick validation (unit tests only)\n/qa --quick\n\n# With coverage\n/qa --coverage\n\n# Test specific module\n/qa auth\n```"
              },
              {
                "name": "/unit",
                "description": "Run unit tests for isolated function and component testing",
                "path": "plugins/qa/commands/unit.md",
                "frontmatter": {
                  "description": "Run unit tests for isolated function and component testing"
                },
                "content": "# Unit Command\n\nRuns unit tests for isolated function and component testing.\n\n## Usage\n\n```bash\n/unit                      # Run all unit tests\n/unit [file]               # Run specific test file\n/unit [pattern]            # Run tests matching pattern\n/unit --coverage           # Run with coverage report\n/unit --watch              # Run in watch mode\n```\n\n## What It Does\n\nThe `/unit` command executes unit tests:\n\n1. **Detect Framework** - Jest, Vitest, pytest, PHPUnit\n2. **Run Tests** - Execute unit test suite\n3. **Generate Coverage** - Code coverage report (if requested)\n4. **Report Results** - Summary with failures\n\n## Agents Used\n\n| Agent | Purpose |\n|-------|---------|\n| `test-runner` | Execute unit test suite |\n\n## Framework Commands\n\n| Framework | Command |\n|-----------|---------|\n| Jest | `npm test -- tests/unit/` |\n| Vitest | `npx vitest run tests/unit/` |\n| pytest | `pytest tests/unit/` |\n| PHPUnit | `./vendor/bin/phpunit tests/Unit/` |\n\n## Output\n\n```markdown\n# Unit Test Report\n\n## Summary\n- Total: 98 tests\n- Passed: 97 (99%)\n- Failed: 1 (1%)\n- Duration: 12s\n\n## Coverage\n| Category | Statements | Branches | Functions |\n|----------|------------|----------|-----------|\n| Services | 92.1% | 85.3% | 88.9% |\n| Utils | 98.2% | 95.0% | 100% |\n| Total | 87.3% | 82.4% | 88.2% |\n\n## Failed Tests\n1. user.test.ts:45 - UserService.createUser\n   Expected: \"user@example.com\"\n   Received: undefined\n```\n\n## Options\n\n| Option | Description |\n|--------|-------------|\n| `--coverage` | Generate coverage report |\n| `--watch` | Watch mode for development |\n| `--verbose` | Detailed output |\n| `--bail` | Stop on first failure |\n| `--update` | Update snapshots |\n\n## Examples\n\n```bash\n# Run all unit tests\n/unit\n\n# Run with coverage\n/unit --coverage\n\n# Run specific file\n/unit tests/unit/services/user.test.ts\n\n# Run tests matching pattern\n/unit user\n\n# Watch mode for development\n/unit --watch\n\n# Run only failed tests\n/unit --failed\n```\n\n## Coverage Targets\n\n| Metric | Target | Description |\n|--------|--------|-------------|\n| Statements | 80%+ | Lines of code executed |\n| Branches | 75%+ | Conditional paths tested |\n| Functions | 80%+ | Functions called |\n| Lines | 80%+ | Actual lines covered |"
              },
              {
                "name": "/write-tests",
                "description": "Generate automated test code from requirements, source code, or recorded browser actions",
                "path": "plugins/qa/commands/write-tests.md",
                "frontmatter": {
                  "description": "Generate automated test code from requirements, source code, or recorded browser actions"
                },
                "content": "# Write Tests Command\n\nGenerates automated test code from requirements, source code, or recorded browser actions.\n\n## Usage\n\n```bash\n/write-tests [target]              # Generate tests for target\n/write-tests --unit [file]         # Generate unit tests\n/write-tests --integration [api]   # Generate integration tests\n/write-tests --e2e [flow]          # Generate E2E tests\n/write-tests --from-actions        # Convert recorded actions to tests\n```\n\n## What It Does\n\nThe `/write-tests` command generates test code:\n\n1. **Analyze Target** - Read source code or requirements\n2. **Identify Test Cases** - Determine what to test\n3. **Generate Tests** - Create test files\n4. **Add Edge Cases** - Include error scenarios\n5. **Create Fixtures** - Generate test data\n\n## Agents Used\n\n| Agent | Purpose |\n|-------|---------|\n| `test-writer` | Generate test code |\n\n## Test Generation Modes\n\n### Unit Tests\n\n```bash\n/write-tests --unit src/services/user.ts\n```\n\nGenerates:\n- Function tests\n- Class method tests\n- Mock configurations\n- Edge case coverage\n\n### Integration Tests\n\n```bash\n/write-tests --integration /api/users\n```\n\nGenerates:\n- API endpoint tests\n- Request/response validation\n- Error handling tests\n- Database setup/teardown\n\n### E2E Tests\n\n```bash\n/write-tests --e2e login\n```\n\nGenerates:\n- Playwright test specs\n- Page Object Models\n- User flow tests\n- Visual validation\n\n### From Recorded Actions\n\n```bash\n/write-tests --from-actions\n```\n\nConverts browser-tester recorded actions into Playwright tests.\n\n## Output\n\n```markdown\n# Test Generation Report\n\n## Generated Files\n\n### 1. tests/unit/services/user.test.ts\n- Tests: 8\n- Coverage: UserService class\n- Includes: create, update, delete, find operations\n\n### 2. tests/e2e/auth/login.spec.ts\n- Tests: 4\n- Scenarios: Valid login, invalid credentials, validation\n- Page Objects: LoginPage\n\n### 3. tests/factories/userFactory.ts\n- Utilities: createUser, createUsers, createAdmin\n\n## Test Cases Generated\n- [x] Happy path scenarios\n- [x] Error handling\n- [x] Edge cases\n- [x] Input validation\n\n## Next Steps\n1. Run tests with `/unit` or `/e2e`\n2. Add additional scenarios if needed\n3. Verify coverage targets met\n```\n\n## Options\n\n| Option | Description |\n|--------|-------------|\n| `--unit` | Generate unit tests |\n| `--integration` | Generate integration tests |\n| `--e2e` | Generate E2E tests |\n| `--from-actions` | From recorded browser actions |\n| `--coverage` | Focus on coverage gaps |\n| `--edge-cases` | Include edge cases |\n\n## Examples\n\n```bash\n# Generate unit tests for a service\n/write-tests --unit src/services/auth.ts\n\n# Generate integration tests for API\n/write-tests --integration /api/products\n\n# Generate E2E tests for checkout flow\n/write-tests --e2e checkout\n\n# Convert recorded actions to tests\n/write-tests --from-actions\n\n# Generate tests for coverage gaps\n/write-tests --coverage src/controllers/\n```\n\n## Workflow Integration\n\n### Manual Testing → Automated Tests\n\n```bash\n# 1. Explore with browser-tester\n/e2e --explore https://app.example.com/login\n\n# 2. Record actions during exploration\n# (browser-tester documents actions)\n\n# 3. Generate tests from recorded actions\n/write-tests --from-actions\n\n# 4. Run generated tests\n/e2e\n```\n\n### Coverage-Driven Test Generation\n\n```bash\n# 1. Run tests with coverage\n/unit --coverage\n\n# 2. Generate tests for uncovered code\n/write-tests --coverage src/services/\n```"
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}