{
  "owner": {
    "id": "qooba",
    "display_name": "Kuba So≈Çtys",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/14150080?u=169205e92971cc0e6debead78c58f388e76a0c43&v=4",
    "url": "https://github.com/qooba",
    "bio": "Physicist (PhD), Solutions architect, developer",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 1,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "qooba/tweaktune",
      "url": "https://github.com/qooba/tweaktune",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2026-01-06T18:19:42Z",
        "created_at": "2025-02-03T19:06:12Z",
        "license": "Apache-2.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 957
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/build.yml",
          "type": "blob",
          "size": 2119
        },
        {
          "path": ".github/workflows/release.yml",
          "type": "blob",
          "size": 2434
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 3159
        },
        {
          "path": "CLA.md",
          "type": "blob",
          "size": 1308
        },
        {
          "path": "Cargo.lock",
          "type": "blob",
          "size": 177837
        },
        {
          "path": "Cargo.toml",
          "type": "blob",
          "size": 5664
        },
        {
          "path": "LICENSE-APACHE",
          "type": "blob",
          "size": 11356
        },
        {
          "path": "LICENSE-MIT",
          "type": "blob",
          "size": 1022
        },
        {
          "path": "Makefile",
          "type": "blob",
          "size": 4462
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 9114
        },
        {
          "path": "clippy.toml",
          "type": "blob",
          "size": 328
        },
        {
          "path": "crates",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-abstractions",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-abstractions/Cargo.toml",
          "type": "blob",
          "size": 363
        },
        {
          "path": "crates/tweaktune-abstractions/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-abstractions/src/lib.rs",
          "type": "blob",
          "size": 2382
        },
        {
          "path": "crates/tweaktune-core",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/Cargo.toml",
          "type": "blob",
          "size": 1899
        },
        {
          "path": "crates/tweaktune-core/db",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/db/migrations",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/db/migrations/0001_init.sql",
          "type": "blob",
          "size": 4151
        },
        {
          "path": "crates/tweaktune-core/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/common",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/common/dedup.rs",
          "type": "blob",
          "size": 4135
        },
        {
          "path": "crates/tweaktune-core/src/common/internal.rs",
          "type": "blob",
          "size": 29822
        },
        {
          "path": "crates/tweaktune-core/src/common/mod.rs",
          "type": "blob",
          "size": 76
        },
        {
          "path": "crates/tweaktune-core/src/common/validators.rs",
          "type": "blob",
          "size": 45708
        },
        {
          "path": "crates/tweaktune-core/src/config.rs",
          "type": "blob",
          "size": 2455
        },
        {
          "path": "crates/tweaktune-core/src/datasets",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/datasets/mod.rs",
          "type": "blob",
          "size": 23763
        },
        {
          "path": "crates/tweaktune-core/src/dictionaries",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/dictionaries/mod.rs",
          "type": "blob",
          "size": 543
        },
        {
          "path": "crates/tweaktune-core/src/dictionaries/openings.rs",
          "type": "blob",
          "size": 1253
        },
        {
          "path": "crates/tweaktune-core/src/embeddings",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/embeddings/e5.rs",
          "type": "blob",
          "size": 4608
        },
        {
          "path": "crates/tweaktune-core/src/embeddings/mod.rs",
          "type": "blob",
          "size": 3474
        },
        {
          "path": "crates/tweaktune-core/src/lib.rs",
          "type": "blob",
          "size": 1715
        },
        {
          "path": "crates/tweaktune-core/src/llms",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/llms/mod.rs",
          "type": "blob",
          "size": 11374
        },
        {
          "path": "crates/tweaktune-core/src/readers",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/readers/mod.rs",
          "type": "blob",
          "size": 5085
        },
        {
          "path": "crates/tweaktune-core/src/seq2seq",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/seq2seq/mod.rs",
          "type": "blob",
          "size": 8851
        },
        {
          "path": "crates/tweaktune-core/src/state",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/state/mod.rs",
          "type": "blob",
          "size": 12880
        },
        {
          "path": "crates/tweaktune-core/src/steps",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/steps/conversations.rs",
          "type": "blob",
          "size": 17190
        },
        {
          "path": "crates/tweaktune-core/src/steps/embeddings.rs",
          "type": "blob",
          "size": 4310
        },
        {
          "path": "crates/tweaktune-core/src/steps/generators.rs",
          "type": "blob",
          "size": 17039
        },
        {
          "path": "crates/tweaktune-core/src/steps/logic.rs",
          "type": "blob",
          "size": 2131
        },
        {
          "path": "crates/tweaktune-core/src/steps/mod.rs",
          "type": "blob",
          "size": 17534
        },
        {
          "path": "crates/tweaktune-core/src/steps/py.rs",
          "type": "blob",
          "size": 2112
        },
        {
          "path": "crates/tweaktune-core/src/steps/quality.rs",
          "type": "blob",
          "size": 5306
        },
        {
          "path": "crates/tweaktune-core/src/steps/validators.rs",
          "type": "blob",
          "size": 8327
        },
        {
          "path": "crates/tweaktune-core/src/steps/writers.rs",
          "type": "blob",
          "size": 3463
        },
        {
          "path": "crates/tweaktune-core/src/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/templates/embed.rs",
          "type": "blob",
          "size": 715
        },
        {
          "path": "crates/tweaktune-core/src/templates/mod.rs",
          "type": "blob",
          "size": 13596
        },
        {
          "path": "crates/tweaktune-core/src/tokenizers",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/src/tokenizers/mod.rs",
          "type": "blob",
          "size": 486
        },
        {
          "path": "crates/tweaktune-core/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/templates/chat_templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/templates/chat_templates/bielik.j2",
          "type": "blob",
          "size": 3702
        },
        {
          "path": "crates/tweaktune-core/templates/conversations",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/templates/conversations/messages.j2",
          "type": "blob",
          "size": 576
        },
        {
          "path": "crates/tweaktune-core/templates/conversations/output.j2",
          "type": "blob",
          "size": 576
        },
        {
          "path": "crates/tweaktune-core/templates/conversations/output_legacy.j2",
          "type": "blob",
          "size": 567
        },
        {
          "path": "crates/tweaktune-core/templates/conversations/output_raw.j2",
          "type": "blob",
          "size": 556
        },
        {
          "path": "crates/tweaktune-core/templates/conversations/tool_call.j2",
          "type": "blob",
          "size": 62
        },
        {
          "path": "crates/tweaktune-core/templates/judges",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/templates/judges/conversation_en.j2",
          "type": "blob",
          "size": 2186
        },
        {
          "path": "crates/tweaktune-core/templates/judges/conversation_pl.j2",
          "type": "blob",
          "size": 2371
        },
        {
          "path": "crates/tweaktune-core/templates/judges/tools_calling_en.j2",
          "type": "blob",
          "size": 2833
        },
        {
          "path": "crates/tweaktune-core/templates/judges/tools_calling_lite_en.j2",
          "type": "blob",
          "size": 2144
        },
        {
          "path": "crates/tweaktune-core/templates/judges/tools_calling_lite_pl.j2",
          "type": "blob",
          "size": 1920
        },
        {
          "path": "crates/tweaktune-core/templates/judges/tools_calling_pl.j2",
          "type": "blob",
          "size": 2715
        },
        {
          "path": "crates/tweaktune-core/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-core/tests/e5_integration.rs",
          "type": "blob",
          "size": 1448
        },
        {
          "path": "crates/tweaktune-core/tests/seq2seq_integration.rs",
          "type": "blob",
          "size": 1235
        },
        {
          "path": "crates/tweaktune-pyo3",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-pyo3/Cargo.toml",
          "type": "blob",
          "size": 1012
        },
        {
          "path": "crates/tweaktune-pyo3/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-pyo3/src/chat_template.rs",
          "type": "blob",
          "size": 2321
        },
        {
          "path": "crates/tweaktune-pyo3/src/common.rs",
          "type": "blob",
          "size": 362
        },
        {
          "path": "crates/tweaktune-pyo3/src/lib.rs",
          "type": "blob",
          "size": 89
        },
        {
          "path": "crates/tweaktune-pyo3/src/logging.rs",
          "type": "blob",
          "size": 5474
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline/chain.rs",
          "type": "blob",
          "size": 7127
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline/error_tracker.rs",
          "type": "blob",
          "size": 9247
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline/logo.rs",
          "type": "blob",
          "size": 1721
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline/mod.rs",
          "type": "blob",
          "size": 39427
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline/run.rs",
          "type": "blob",
          "size": 27530
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline/summary.rs",
          "type": "blob",
          "size": 8756
        },
        {
          "path": "crates/tweaktune-pyo3/src/pipeline/validation.rs",
          "type": "blob",
          "size": 10642
        },
        {
          "path": "crates/tweaktune-pyo3/src/steps",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune-pyo3/src/steps/mod.rs",
          "type": "blob",
          "size": 7304
        },
        {
          "path": "crates/tweaktune",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune/Cargo.toml",
          "type": "blob",
          "size": 464
        },
        {
          "path": "crates/tweaktune/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune/src/actors",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune/src/actors/mod.rs",
          "type": "blob",
          "size": 2266
        },
        {
          "path": "crates/tweaktune/src/main.rs",
          "type": "blob",
          "size": 1103
        },
        {
          "path": "crates/tweaktune/src/pipeline",
          "type": "tree",
          "size": null
        },
        {
          "path": "crates/tweaktune/src/pipeline/mod.rs",
          "type": "blob",
          "size": 453
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/01-getting-started.md",
          "type": "blob",
          "size": 2930
        },
        {
          "path": "docs/02-pipeline-basics.md",
          "type": "blob",
          "size": 4668
        },
        {
          "path": "docs/03-data-sources.md",
          "type": "blob",
          "size": 5912
        },
        {
          "path": "docs/04-templates.md",
          "type": "blob",
          "size": 5699
        },
        {
          "path": "docs/05-llm-integration.md",
          "type": "blob",
          "size": 6345
        },
        {
          "path": "docs/06-pipeline-steps.md",
          "type": "blob",
          "size": 10238
        },
        {
          "path": "docs/07-custom-steps.md",
          "type": "blob",
          "size": 8778
        },
        {
          "path": "docs/08-validation-quality.md",
          "type": "blob",
          "size": 6464
        },
        {
          "path": "docs/09-conversation-tools.md",
          "type": "blob",
          "size": 19819
        },
        {
          "path": "docs/10-chat-templates.md",
          "type": "blob",
          "size": 6413
        },
        {
          "path": "docs/11-metadata-tracking.md",
          "type": "blob",
          "size": 6292
        },
        {
          "path": "docs/12-advanced-features.md",
          "type": "blob",
          "size": 8871
        },
        {
          "path": "docs/README.md",
          "type": "blob",
          "size": 1580
        },
        {
          "path": "docs/tweaktune_logo_black.png",
          "type": "blob",
          "size": 1207882
        },
        {
          "path": "docs/tweaktune_logo_black_small.png",
          "type": "blob",
          "size": 677135
        },
        {
          "path": "docs/tweaktune_logo_wave.png",
          "type": "blob",
          "size": 480949
        },
        {
          "path": "docs/tweaktune_logo_wave_rounded.png",
          "type": "blob",
          "size": 611145
        },
        {
          "path": "docs/tweaktune_logo_wave_transparent.png",
          "type": "blob",
          "size": 229721
        },
        {
          "path": "docs/tweaktune_logo_white.png",
          "type": "blob",
          "size": 1335755
        },
        {
          "path": "examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/01_simple_pipeline.py",
          "type": "blob",
          "size": 859
        },
        {
          "path": "examples/02_data_sources.py",
          "type": "blob",
          "size": 2392
        },
        {
          "path": "examples/03_templates.py",
          "type": "blob",
          "size": 2556
        },
        {
          "path": "examples/04_transformations.py",
          "type": "blob",
          "size": 4171
        },
        {
          "path": "examples/05_text_generation.py",
          "type": "blob",
          "size": 3361
        },
        {
          "path": "examples/06_json_generation.py",
          "type": "blob",
          "size": 4075
        },
        {
          "path": "examples/07_qa_dataset.py",
          "type": "blob",
          "size": 2562
        },
        {
          "path": "examples/08_function_calling.py",
          "type": "blob",
          "size": 5166
        },
        {
          "path": "examples/08b_function_calling_arguments.py",
          "type": "blob",
          "size": 5107
        },
        {
          "path": "examples/09_conversations.py",
          "type": "blob",
          "size": 9893
        },
        {
          "path": "examples/10_deduplication.py",
          "type": "blob",
          "size": 3469
        },
        {
          "path": "examples/11_validation.py",
          "type": "blob",
          "size": 5489
        },
        {
          "path": "examples/12_custom_steps.py",
          "type": "blob",
          "size": 5998
        },
        {
          "path": "examples/13_conditional_logic.py",
          "type": "blob",
          "size": 7354
        },
        {
          "path": "examples/14_chat_templates.py",
          "type": "blob",
          "size": 5201
        },
        {
          "path": "examples/15_rl_formats.py",
          "type": "blob",
          "size": 8658
        },
        {
          "path": "examples/README.md",
          "type": "blob",
          "size": 2030
        },
        {
          "path": "pyproject.toml",
          "type": "blob",
          "size": 2548
        },
        {
          "path": "rustfmt.toml",
          "type": "blob",
          "size": 310
        },
        {
          "path": "tweaktune-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 686
        },
        {
          "path": "tweaktune-plugin/README.md",
          "type": "blob",
          "size": 7161
        },
        {
          "path": "tweaktune-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/SKILL.md",
          "type": "blob",
          "size": 14308
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/examples/conversations.md",
          "type": "blob",
          "size": 13354
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/examples/function-calling.md",
          "type": "blob",
          "size": 15987
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/examples/json-generation.md",
          "type": "blob",
          "size": 11098
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/examples/text-generation.md",
          "type": "blob",
          "size": 8817
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/templates/basic-pipeline.py",
          "type": "blob",
          "size": 2523
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/templates/conversation-pipeline.py",
          "type": "blob",
          "size": 3948
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/templates/function-call-pipeline.py",
          "type": "blob",
          "size": 5741
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/templates/json-gen-pipeline.py",
          "type": "blob",
          "size": 2665
        },
        {
          "path": "tweaktune-plugin/skills/tweaktune-synthesizer/templates/text-gen-pipeline.py",
          "type": "blob",
          "size": 2883
        },
        {
          "path": "tweaktune-python",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-python/Cargo.toml",
          "type": "blob",
          "size": 732
        },
        {
          "path": "tweaktune-python/LICENSE",
          "type": "blob",
          "size": 11356
        },
        {
          "path": "tweaktune-python/README.md",
          "type": "blob",
          "size": 3311
        },
        {
          "path": "tweaktune-python/pyproject.toml",
          "type": "blob",
          "size": 1592
        },
        {
          "path": "tweaktune-python/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-python/src/lib.rs",
          "type": "blob",
          "size": 1404
        },
        {
          "path": "tweaktune-python/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-python/tests/__init__.py",
          "type": "blob",
          "size": null
        },
        {
          "path": "tweaktune-python/tests/conftest.py",
          "type": "blob",
          "size": 5898
        },
        {
          "path": "tweaktune-python/tests/openapi.json",
          "type": "blob",
          "size": 3921
        },
        {
          "path": "tweaktune-python/tests/test_basic.py",
          "type": "blob",
          "size": 4507
        },
        {
          "path": "tweaktune-python/tests/test_chat_template_builder.py",
          "type": "blob",
          "size": 2170
        },
        {
          "path": "tweaktune-python/tests/test_function_response_schema.py",
          "type": "blob",
          "size": 1819
        },
        {
          "path": "tweaktune-python/tests/test_judge.py",
          "type": "blob",
          "size": 3710
        },
        {
          "path": "tweaktune-python/tests/test_metadata.py",
          "type": "blob",
          "size": 2263
        },
        {
          "path": "tweaktune-python/tests/test_read.py",
          "type": "blob",
          "size": 13867
        },
        {
          "path": "tweaktune-python/tests/test_steps.py",
          "type": "blob",
          "size": 34187
        },
        {
          "path": "tweaktune-python/tests/test_template_filters.py",
          "type": "blob",
          "size": 6573
        },
        {
          "path": "tweaktune-python/tests/test_tools.py",
          "type": "blob",
          "size": 6684
        },
        {
          "path": "tweaktune-python/tests/test_write.py",
          "type": "blob",
          "size": 1785
        },
        {
          "path": "tweaktune-python/tweaktune",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-python/tweaktune/__init__.py",
          "type": "blob",
          "size": 38326
        },
        {
          "path": "tweaktune-python/tweaktune/chain.py",
          "type": "blob",
          "size": 5184
        },
        {
          "path": "tweaktune-python/tweaktune/chat_templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-python/tweaktune/chat_templates/__init__.py",
          "type": "blob",
          "size": 378
        },
        {
          "path": "tweaktune-python/tweaktune/common.py",
          "type": "blob",
          "size": 1539
        },
        {
          "path": "tweaktune-python/tweaktune/conversation.py",
          "type": "blob",
          "size": 1980
        },
        {
          "path": "tweaktune-python/tweaktune/structured.py",
          "type": "blob",
          "size": 982
        },
        {
          "path": "tweaktune-python/tweaktune/tools.py",
          "type": "blob",
          "size": 8811
        },
        {
          "path": "tweaktune-python/tweaktune/tune.py",
          "type": "blob",
          "size": 4212
        },
        {
          "path": "tweaktune-python/tweaktune/ui",
          "type": "tree",
          "size": null
        },
        {
          "path": "tweaktune-python/tweaktune/ui/__init__.py",
          "type": "blob",
          "size": 11429
        },
        {
          "path": "tweaktune-python/tweaktune/wrappers.py",
          "type": "blob",
          "size": 4631
        }
      ],
      "marketplace": {
        "name": "tweaktune-plugins",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Qooba",
          "email": ""
        },
        "keywords": [],
        "plugins": [
          {
            "name": "tweaktune-synthesizer",
            "description": "Interactive assistant for designing tweaktune pipelines. Creates production-ready code for text generation, JSON synthesis, conversations, and function calling datasets.",
            "source": "./tweaktune-plugin",
            "category": null,
            "version": "1.0.0",
            "author": {
              "name": "Qooba"
            },
            "install_commands": [
              "/plugin marketplace add qooba/tweaktune",
              "/plugin install tweaktune-synthesizer@tweaktune-plugins"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2026-01-06T18:19:42Z",
              "created_at": "2025-02-03T19:06:12Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "tweaktune-synthesizer",
                "description": "Interactive assistant for designing and generating tweaktune pipelines to synthesize training data for LLMs. Use when user wants to create synthetic datasets for fine-tuning, generate conversations, function calling data, or structured JSON datasets.",
                "path": "tweaktune-plugin/skills/tweaktune-synthesizer/SKILL.md",
                "frontmatter": {
                  "name": "tweaktune-synthesizer",
                  "description": "Interactive assistant for designing and generating tweaktune pipelines to synthesize training data for LLMs. Use when user wants to create synthetic datasets for fine-tuning, generate conversations, function calling data, or structured JSON datasets.",
                  "allowed-tools": [
                    "Read",
                    "Write",
                    "Glob",
                    "Grep",
                    "Bash"
                  ]
                },
                "content": "# TweakTune Synthesizer\n\nYou are an interactive assistant that helps users design and build **tweaktune pipelines** for synthesizing training data for large language models (LLMs). TweakTune is a Rust-powered, Python-facing library that provides a pipeline-based architecture for generating synthetic text, structured JSON, conversations, and function calling datasets using LLM APIs.\n\n## How This Skill Works\n\nThis skill works through an **interactive Q&A process**. You will guide users through a series of questions to understand their data synthesis needs, then generate complete, production-ready pipeline code tailored to their requirements.\n\n## Interactive Q&A Flow\n\n### Phase 1: Task Discovery\n\nStart by asking the user about their synthesis goals:\n\n**Question 1: What type of data are you synthesizing?**\n- a) Text generation (articles, summaries, creative writing)\n- b) JSON/structured data (personas, entities, labeled data)\n- c) Conversations (multi-turn dialogues, chat data)\n- d) Function calling / tool use datasets\n- e) Multiple types / custom workflow\n\n**Question 2: What's your primary use case?**\n- a) SFT (Supervised Fine-Tuning)\n- b) DPO (Direct Preference Optimization)\n- c) GRPO (Group Relative Policy Optimization)\n- d) General dataset creation\n- e) Testing/evaluation datasets\n\n### Phase 2: Data Source Configuration\n\n**Question 3: Do you have existing data to use as seeds?**\n- a) Yes, in a file (ask for format: Parquet, CSV, JSONL, JSON)\n- b) Yes, from HuggingFace dataset (ask for dataset path)\n- c) Yes, from a database (requires connectorx)\n- d) No, generate from scratch (use .iter_range())\n- e) Use internal tweaktune datasets\n\n**Question 4: How many examples do you want to generate?**\n- Get a number from the user (default: 100)\n\n### Phase 3: LLM Configuration\n\n**Question 5: Which LLM provider?**\n- a) OpenAI (default - ask for model: gpt-4, gpt-4-turbo, gpt-3.5-turbo)\n- b) Azure OpenAI (ask for endpoint, deployment, api_version)\n- c) Generic API (ollama, vllm, etc. - ask for base_url)\n- d) Other (ask for details)\n\n**Question 6: API key source?**\n- a) Environment variable OPENAI_API_KEY (recommended)\n- b) Environment variable (custom name)\n- c) Direct input (will be in code - warn about security)\n\n### Phase 4: Template & Prompt Design\n\nBased on the task type from Phase 1, help design templates:\n\n**For Text Generation:**\n- Ask for the prompt template\n- Ask if using Jinja2 templates from files or inline\n- Ask about generation parameters (max_tokens, temperature)\n\n**For JSON Generation:**\n- Ask if they have a Pydantic model already\n- If not, ask what fields they need and generate the model\n- Ask for the prompt template\n\n**For Conversations:**\n- Recommend Conv() builder (type-safe, easier)\n- Ask about conversation flow (system, user, assistant, tool calls)\n- Ask if tool calls are needed\n- Ask if reasoning/thinking content is needed\n\n**For Function Calling:**\n- Ask if they have Python functions defined\n- Ask if they have an OpenAPI spec\n- Ask if they need to generate tools from Pydantic models\n- Ask how many tools per conversation (use .sample_tools())\n\n### Phase 5: Quality & Validation\n\n**Question: What quality checks do you need?**\n- a) Deduplication (hash-based, simhash fuzzy, or embedding-based)\n- b) Language detection/filtering\n- c) JSON schema validation\n- d) Conversation format validation\n- e) Tool/function calling format validation\n- f) Custom validation (will need Python function)\n- g) None\n\n### Phase 6: Output Configuration\n\n**Question 7: Output file path and format?**\n- Ask for output path (default: output/generated_data.jsonl)\n- Ask for format (JSONL recommended, CSV supported)\n- Ask if they want specific fields in output\n\n### Phase 7: Code Generation\n\nAfter gathering all information, generate:\n\n1. **Complete pipeline script** (`pipeline.py` or user-specified name)\n   - Proper imports\n   - Configuration from environment variables\n   - Well-commented code explaining each step\n   - Error handling (API key checks, directory creation)\n   - All pipeline steps in correct order\n\n2. **Supporting files** (if needed):\n   - `requirements.txt` with dependencies\n   - Jinja2 template files (`.j2`) if using external templates\n   - Pydantic model definitions if JSON generation\n   - Example input data file\n   - `README.md` with usage instructions\n\n## Code Generation Strategy\n\n### Template Selection\n\nBased on user responses, select the appropriate base template from:\n- `templates/basic-pipeline.py` - Minimal structure\n- `templates/text-gen-pipeline.py` - Text generation\n- `templates/json-gen-pipeline.py` - Structured data\n- `templates/conversation-pipeline.py` - Conversations\n- `templates/function-call-pipeline.py` - Function calling\n\n### Base Pipeline Structure\n\nAll pipelines follow this structure:\n\n```python\nfrom tweaktune import Pipeline, Metadata\nimport os\nfrom pathlib import Path\n\ndef main():\n    # Configuration\n    api_key = os.getenv(\"OPENAI_API_KEY\")\n    if not api_key:\n        raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n\n    output_path = Path(\"output/generated_data.jsonl\")\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Build and run pipeline\n    (Pipeline(name=\"pipeline-name\", metadata=Metadata(...))\n        .with_workers(4)  # Adjust based on API rate limits\n        # Resource configuration\n        .with_jsonl_dataset(\"source\", \"input.jsonl\")\n        .with_llm_openai(\"gpt4\", api_key, \"gpt-4\")\n        .with_template(\"prompt\", \"Template here\")\n        # Start iteration\n        .iter_dataset(\"source\")  # or .iter_range(100)\n        # Pipeline steps\n        .sample(dataset=\"source\", size=1, output=\"sampled\")\n        .generate_text(template=\"prompt\", llm=\"gpt4\", output=\"result\")\n        # Quality checks\n        .check_hash(\"result\")  # Deduplication\n        # Output\n        .write_jsonl(path=str(output_path), template='{\"result\": \"{{result}}\"}')\n        # Execute\n        .run()  # or .ui() for web interface\n    )\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Resource Configuration\n\nInject based on user answers:\n\n**Datasets:**\n```python\n.with_parquet_dataset(\"name\", \"path.parquet\", sql=\"SELECT * WHERE ...\")\n.with_csv_dataset(\"name\", \"path.csv\", delimiter=\",\", has_header=True)\n.with_jsonl_dataset(\"name\", \"path.jsonl\")\n.with_hf_dataset(\"name\", \"dataset/path\", \"subset\", \"split\")\n.with_tools_dataset(\"tools\", [func1, func2])\n.with_openapi_dataset(\"api\", \"openapi.json\")\n.with_pydantic_models_dataset(\"models\", [Model1, Model2])\n```\n\n**LLMs:**\n```python\n.with_llm_openai(\"name\", api_key, \"gpt-4\")\n.with_llm_azure_openai(\"name\", api_key, endpoint, deployment, api_version)\n.with_llm_api(\"name\", base_url, api_key, model)\n```\n\n**Templates:**\n```python\n.with_template(\"name\", \"Inline template: {{var}}\")\n.with_j2_template(\"name\", \"templates/prompt.j2\")\n```\n\n### Pipeline Steps\n\nBuild step chain based on task type:\n\n**Text Generation:**\n```python\n.generate_text(\n    template=\"prompt\",\n    llm=\"gpt4\",\n    output=\"generated_text\",\n    max_tokens=2048,\n    temperature=0.7\n)\n```\n\n**JSON Generation:**\n```python\n.generate_structured(\n    template=\"prompt\",\n    llm=\"gpt4\",\n    output=\"structured_data\",\n    response_format=PydanticModel\n)\n```\n\n**Conversation Building:**\n```python\n.render_conversation(\n    conversation=Conv()\n        .system(\"system_message\")\n        .user(\"user_question\")\n        .assistant(\"assistant_answer\"),\n    output=\"conversation\"\n)\n```\n\n**Function Calling:**\n```python\n.sample_tools(\"available_tools\", size=3, output=\"selected_tools\")\n.render_tool_call(tool=\"selected_tools[0].name\", arguments=\"args_json\", output=\"tool_call\")\n.render_conversation(\n    conversation=Conv()\n        .system(\"system\")\n        .user(\"question\")\n        .tool_calls([\"tool_call\"])\n        .tool(\"tool_response\")\n        .assistant(\"final_answer\"),\n    tools=\"selected_tools\",\n    output=\"conversation\"\n)\n```\n\n### Quality & Validation Steps\n\nAdd based on user requirements:\n\n**Deduplication:**\n```python\n.check_hash(\"field\")  # Exact deduplication\n.check_simhash(\"field\", threshold=0.95)  # Fuzzy deduplication\n.check_embedding(\"field\", embedding=\"embedder\", threshold=0.95)  # Semantic deduplication\n```\n\n**Validation:**\n```python\n.validate_json(schema=json_schema, instance=\"field\")\n.validate_conversation(\"conversation_field\")\n.validate_tools(\"tools_field\")\n.check_language(input=\"field\", language=\"english\", precision=0.9)\n```\n\n**Custom Validation:**\n```python\n.validate(lambda data: your_validation_logic(data))\n```\n\n### Output Configuration\n\n```python\n.write_jsonl(path=str(output_path), template='{\"field\": \"{{field}}\"}')\n.write_jsonl(path=str(output_path), value=\"conversation\")  # For conversations\n.write_csv(path=str(output_path), columns=[\"col1\", \"col2\"])\n```\n\n## Pipeline Patterns to Know\n\n### 1. Basic Text Generation\nGenerate text from topics/prompts:\n- Load topics dataset\n- Generate text for each topic\n- Add deduplication\n- Write to JSONL\n\n### 2. Multi-step Generation\nGenerate multiple fields per example:\n- Generate title\n- Generate summary based on title\n- Generate full article based on summary\n- Chain with `.add_column()` and `.generate_text()`\n\n### 3. Conversation Synthesis\nBuild multi-turn conversations:\n- Use Conv() builder for type safety\n- Add system, user, assistant messages\n- Include tool calls if needed\n- Add thinking/reasoning content\n- Validate conversation format\n\n### 4. Function Calling Datasets\nGenerate tool use examples:\n- Load tools from Python functions or OpenAPI\n- Sample tools for each example\n- Generate user question\n- Generate tool call arguments\n- Simulate tool response\n- Generate final answer\n- Render as conversation with tools\n\n### 5. Conditional Logic\nUse `.ifelse()` for branching:\n```python\n.ifelse(\n    condition=lambda data: needs_tool(data),\n    then_chain=Chain().generate_tool_call(...),\n    else_chain=Chain().generate_direct_answer(...)\n)\n```\n\n### 6. Custom Steps\nFor complex logic:\n```python\nclass CustomStep:\n    def process(self, context):\n        # Your logic here\n        context[\"data\"][\"new_field\"] = process(context[\"data\"])\n        return context\n\n.step(CustomStep())\n```\n\n## Best Practices to Follow\n\n1. **API Keys**: Always use environment variables, never hardcode\n2. **Output Directories**: Create before writing with `Path.mkdir(parents=True, exist_ok=True)`\n3. **Pipeline Names**: Use descriptive names for debugging\n4. **Worker Count**: Set based on API rate limits (4-8 for OpenAI)\n5. **Metadata**: Enable for tracking and debugging\n6. **Validation**: Always validate generated data (JSON schema, format checks)\n7. **Deduplication**: Add for quality datasets (hash, simhash, or embedding)\n8. **Templates**: Use external Jinja2 files for complex prompts\n9. **Comments**: Explain each step in generated code\n10. **Error Handling**: Check for missing API keys, create directories\n\n## Common Issues to Avoid\n\n1. **Don't** use `.iter_dataset()` without loading the dataset first\n2. **Don't** forget to set workers with `.with_workers()`\n3. **Don't** reference undefined template/LLM/dataset names\n4. **Don't** skip validation steps for production datasets\n5. **Don't** use hardcoded API keys in code\n6. **Do** use proper Pydantic models for JSON generation\n7. **Do** use Conv() builder for conversations (not string format when possible)\n8. **Do** add comments explaining the pipeline flow\n\n## Reference Files\n\nFor advanced patterns, refer to test files:\n- Text generation: `/home/jovyan/SpeakLeash/tweaktune/tweaktune-python/tests/test_basic.py`\n- All steps: `/home/jovyan/SpeakLeash/tweaktune/tweaktune-python/tests/test_steps.py`\n- Function calling: `/home/jovyan/SpeakLeash/tweaktune/tweaktune-python/tests/test_tools.py`\n\nFor comprehensive documentation:\n- `/home/jovyan/SpeakLeash/tweaktune/CLAUDE.md`\n\n## Supporting Files\n\nYou can reference example files for specific patterns:\n- `examples/text-generation.md` - Text generation examples\n- `examples/json-generation.md` - Structured data examples\n- `examples/conversations.md` - Conversation synthesis examples\n- `examples/function-calling.md` - Tool use examples\n\nAnd template files for code generation:\n- `templates/basic-pipeline.py` - Minimal pipeline\n- `templates/text-gen-pipeline.py` - Text generation\n- `templates/json-gen-pipeline.py` - JSON generation\n- `templates/conversation-pipeline.py` - Conversations\n- `templates/function-call-pipeline.py` - Function calling\n\n## Workflow\n\n1. **Start with questions** - Ask Phase 1 questions to understand the task\n2. **Gather details** - Progress through Phases 2-6 based on answers\n3. **Generate code** - Create complete pipeline with all supporting files\n4. **Explain** - Add comments and explain each section\n5. **Test** - Offer to help test or modify the pipeline\n6. **Iterate** - Ask if they want to add features, quality checks, or validation\n\n## Example Interaction\n\n```\nUser: I want to create a dataset for fine-tuning\n\nYou: I'll help you create a tweaktune pipeline for dataset synthesis. Let me ask a few questions:\n\n1. What type of data are you synthesizing?\n   a) Text generation\n   b) JSON/structured data\n   c) Conversations\n   d) Function calling / tool use\n   e) Multiple types / custom\n\n[User responds, you continue through phases...]\n\n[After gathering all info...]\n\nYou: Perfect! Based on your requirements, I'll generate a complete pipeline for [task]. This will include:\n- pipeline.py with the complete implementation\n- requirements.txt with dependencies\n- Example input data\n- README.md with usage instructions\n\n[Generate files using Write tool...]\n\nYou: I've created your pipeline! Here's how to use it:\n1. Install dependencies: pip install -r requirements.txt\n2. Set your API key: export OPENAI_API_KEY=your_key\n3. Run the pipeline: python pipeline.py\n\nWould you like me to add any quality checks or validation steps?\n```\n\nRemember: Your goal is to generate production-ready code that follows best practices, includes proper error handling, and is well-commented for maintainability."
              }
            ]
          }
        ]
      }
    }
  ]
}