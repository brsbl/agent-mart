{
  "owner": {
    "id": "Lucklyric",
    "display_name": "Xinyao(Alvin) Sun",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/7803070?u=5f503a0ec8da6ba4dd16b7b9124d94b8d19df3b8&v=4",
    "url": "https://github.com/Lucklyric",
    "bio": "Co-Founder & Chief Scientific Officer @ Matrix Labs Inc. | Adjunct Professor @ Computing Science Department, University of Alberta",
    "stats": {
      "total_repos": 1,
      "total_plugins": 3,
      "total_commands": 0,
      "total_skills": 2,
      "total_stars": 26,
      "total_forks": 3
    }
  },
  "repos": [
    {
      "full_name": "Lucklyric/cc-dev-tools",
      "url": "https://github.com/Lucklyric/cc-dev-tools",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 26,
        "forks": 3,
        "pushed_at": "2026-01-12T23:35:14Z",
        "created_at": "2025-10-21T01:24:14Z",
        "license": "Apache-2.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1023
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 330
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 10754
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 6686
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 653
        },
        {
          "path": "plugins/codex/README.md",
          "type": "blob",
          "size": 7149
        },
        {
          "path": "plugins/codex/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/skills/codex",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/skills/codex/SKILL.md",
          "type": "blob",
          "size": 20223
        },
        {
          "path": "plugins/codex/skills/codex/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/codex/skills/codex/references/advanced-patterns.md",
          "type": "blob",
          "size": 11854
        },
        {
          "path": "plugins/codex/skills/codex/references/cli-features.md",
          "type": "blob",
          "size": 3357
        },
        {
          "path": "plugins/codex/skills/codex/references/codex-config.md",
          "type": "blob",
          "size": 4622
        },
        {
          "path": "plugins/codex/skills/codex/references/codex-help.md",
          "type": "blob",
          "size": 12035
        },
        {
          "path": "plugins/codex/skills/codex/references/command-patterns.md",
          "type": "blob",
          "size": 5598
        },
        {
          "path": "plugins/codex/skills/codex/references/examples.md",
          "type": "blob",
          "size": 3421
        },
        {
          "path": "plugins/codex/skills/codex/references/file-context.md",
          "type": "blob",
          "size": 3892
        },
        {
          "path": "plugins/codex/skills/codex/references/session-workflows.md",
          "type": "blob",
          "size": 6661
        },
        {
          "path": "plugins/gemini",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 663
        },
        {
          "path": "plugins/gemini/README.md",
          "type": "blob",
          "size": 7079
        },
        {
          "path": "plugins/gemini/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/skills/gemini",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/skills/gemini/SKILL.md",
          "type": "blob",
          "size": 16926
        },
        {
          "path": "plugins/gemini/skills/gemini/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/gemini/skills/gemini/references/command-patterns.md",
          "type": "blob",
          "size": 6961
        },
        {
          "path": "plugins/gemini/skills/gemini/references/file-context.md",
          "type": "blob",
          "size": 3710
        },
        {
          "path": "plugins/gemini/skills/gemini/references/gemini-help.md",
          "type": "blob",
          "size": 7709
        },
        {
          "path": "plugins/gemini/skills/gemini/references/model-selection.md",
          "type": "blob",
          "size": 9577
        },
        {
          "path": "plugins/gemini/skills/gemini/references/session-workflows.md",
          "type": "blob",
          "size": 7383
        },
        {
          "path": "plugins/telegram-notifier",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/telegram-notifier/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/telegram-notifier/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 454
        },
        {
          "path": "plugins/telegram-notifier/README.md",
          "type": "blob",
          "size": 4159
        },
        {
          "path": "plugins/telegram-notifier/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/telegram-notifier/hooks/hooks.json",
          "type": "blob",
          "size": 2254
        }
      ],
      "marketplace": {
        "name": "cc-dev-tools",
        "version": "2.1.0",
        "description": "Claude Code marketplace containing development tools and AI integrations for advanced workflows",
        "owner_info": {
          "name": "0xasun"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "codex",
            "description": "Invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Supports intelligent model selection, session continuation, and safe defaults.",
            "source": "./plugins/codex",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add Lucklyric/cc-dev-tools",
              "/plugin install codex@cc-dev-tools"
            ],
            "signals": {
              "stars": 26,
              "forks": 3,
              "pushed_at": "2026-01-12T23:35:14Z",
              "created_at": "2025-10-21T01:24:14Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "codex",
                "description": "This skill should be used when the user wants to invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Trigger phrases include \"use codex\", \"ask codex\", \"run codex\", \"call codex\", \"codex cli\", \"GPT-5 reasoning\", \"OpenAI reasoning\", or when users request complex implementation challenges, advanced reasoning, architecture design, or high-reasoning model assistance. Automatically triggers on codex-related requests and supports session continuation for iterative development.",
                "path": "plugins/codex/skills/codex/SKILL.md",
                "frontmatter": {
                  "name": "codex",
                  "version": "2.1.0",
                  "description": "This skill should be used when the user wants to invoke Codex CLI for complex coding tasks requiring high reasoning capabilities. Trigger phrases include \"use codex\", \"ask codex\", \"run codex\", \"call codex\", \"codex cli\", \"GPT-5 reasoning\", \"OpenAI reasoning\", or when users request complex implementation challenges, advanced reasoning, architecture design, or high-reasoning model assistance. Automatically triggers on codex-related requests and supports session continuation for iterative development."
                },
                "content": "# Codex: High-Reasoning AI Assistant for Claude Code\n\n---\n\n## DEFAULT MODEL: Task-Based Model Selection with Read-Only Default\n\n**Codex uses task-based model selection. Sandbox is `read-only` by default - only use `workspace-write` when user explicitly requests file editing.**\n\n| Task Type | Model | Sandbox (default) | Sandbox (explicit edit) |\n|-----------|-------|-------------------|------------------------|\n| Code-related tasks | `gpt-5.2-codex` | read-only | workspace-write |\n| General tasks | `gpt-5.2` | read-only | workspace-write |\n\n- **Code-related tasks**: Use `gpt-5.2-codex` - optimized for agentic coding (56.4% SWE-Bench Pro)\n- **General tasks**: Use `gpt-5.2` - high-reasoning general model\n- **Sandbox default**: Always `read-only` unless user explicitly requests editing\n- **Explicit editing**: Only when user says \"edit\", \"modify\", \"write changes\", etc., use `workspace-write`\n- Always use `-c model_reasoning_effort=xhigh` for maximum capability\n\n```bash\n# Code task (read-only default)\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"analyze this function implementation\"\n\n# General task (read-only default)\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"explain this architecture\"\n\n# Code task with explicit edit request\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"edit this file to add the feature\"\n\n# General task with explicit edit request\ncodex exec -m gpt-5.2 -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"modify the documentation file\"\n```\n\n### Model Fallback Chain\n\nIf the primary model is unavailable, fallback gracefully:\n1. **Code tasks**: `gpt-5.2-codex` → `gpt-5.2` → `gpt-5.1-codex-max`\n2. **General tasks**: `gpt-5.2` → `gpt-5.1` → `gpt-5.1-codex-max`\n3. **Reasoning effort**: `xhigh` → `high` → `medium`\n\n---\n\n## CRITICAL: Always Use `codex exec`\n\n**MUST USE**: `codex exec` for ALL Codex CLI invocations in Claude Code.\n\n**NEVER USE**: `codex` (interactive mode) - will fail with \"stdout is not a terminal\"\n**ALWAYS USE**: `codex exec` (non-interactive mode)\n\n**Examples:**\n- `codex exec -m gpt-5.2 \"prompt\"` (CORRECT)\n- `codex -m gpt-5.2 \"prompt\"` (WRONG - will fail)\n- `codex exec resume --last` (CORRECT)\n- `codex resume --last` (WRONG - will fail)\n\n**Why?** Claude Code's bash environment is non-terminal/non-interactive. Only `codex exec` works in this environment.\n\n---\n\n## IMPORTANT: Interactive vs Exec Mode Flags\n\n**Some Codex CLI flags are ONLY available in interactive mode, NOT in `codex exec`.**\n\n| Flag | Interactive `codex` | `codex exec` | Alternative for exec |\n|------|---------------------|--------------|---------------------|\n| `--search` | ✅ Available | ❌ NOT available | `--enable web_search_request` |\n| `-a/--ask-for-approval` | ✅ Available | ❌ NOT available | `--full-auto` or `-c approval_policy=...` |\n| `--add-dir` | ✅ Available | ✅ Available | N/A |\n| `--full-auto` | ✅ Available | ✅ Available | N/A |\n\n**For web search in exec mode**:\n```bash\n# CORRECT - works in codex exec\ncodex exec --enable web_search_request \"research topic\"\n\n# WRONG - --search only works in interactive mode\ncodex --search \"research topic\"\n```\n\n**For approval control in exec mode**:\n```bash\n# CORRECT - works in codex exec\ncodex exec --full-auto \"task\"\ncodex exec -c approval_policy=on-request \"task\"\n\n# WRONG - -a only works in interactive mode\ncodex -a on-request \"task\"\n```\n\n---\n\n## Trigger Examples\n\nThis skill activates when users say phrases like:\n- \"Use codex to analyze this architecture\"\n- \"Ask codex about this design decision\"\n- \"Run codex on this problem\"\n- \"Call codex for help with this implementation\"\n- \"I need GPT-5 reasoning for this task\"\n- \"Get OpenAI's high-reasoning model on this\"\n- \"Continue with codex\" or \"Resume the codex session\"\n- \"Codex, help me with...\" or simply \"Codex\"\n\n## When to Use This Skill\n\nThis skill should be invoked when:\n- User explicitly mentions \"Codex\" or requests Codex assistance\n- User needs help with complex coding tasks, algorithms, or architecture\n- User requests \"high reasoning\" or \"advanced implementation\" help\n- User needs complex problem-solving or architectural design\n- User wants to continue a previous Codex conversation\n\n## How It Works\n\n### Detecting New Codex Requests\n\nWhen a user makes a request, first determine the task type (code vs general), then determine sandbox based on explicit edit request:\n\n**Step 1: Determine Task Type (Model Selection)**\n- **Code-related tasks**: Use `gpt-5.2-codex` - for implementation, refactoring, code analysis, debugging, etc.\n- **General tasks**: Use `gpt-5.2` - for architecture design, explanations, reviews, documentation, etc.\n\n**Step 2: Determine Sandbox (Edit Permission)**\n- **Default**: `read-only` - safe for all tasks unless user explicitly requests editing\n- **Explicit edit request**: `workspace-write` - ONLY when user explicitly says to edit/modify/write files\n\n**Code-related task examples**:\n- Read-only: \"Analyze this function\", \"Review this implementation\", \"Debug this code\"\n- With editing: \"Edit this file to fix the bug\", \"Modify the function\", \"Refactor and save\"\n\n**General task examples**:\n- Read-only: \"Design a queue data structure\", \"Explain this algorithm\", \"Review the architecture\"\n- With editing: \"Update the documentation file\", \"Modify the README\"\n\n**⚠️ Important**: The key distinction for sandbox is whether the user explicitly asks for file modifications. Use `workspace-write` ONLY when user says \"edit\", \"modify\", \"write changes\", \"save\", etc.\n\n### Bash CLI Command Structure\n\n**IMPORTANT**: Always use `codex exec` for non-interactive execution. Claude Code's bash environment is non-terminal, so the interactive `codex` command will fail with \"stdout is not a terminal\" error.\n\n#### Code Task (Read-Only Default)\n\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<code-related prompt>\"\n```\n\n#### General Task (Read-Only Default)\n\n```bash\ncodex exec -m gpt-5.2 -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<general prompt>\"\n```\n\n#### Code Task with Explicit Edit Request\n\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<edit code prompt>\"\n```\n\n#### General Task with Explicit Edit Request\n\n```bash\ncodex exec -m gpt-5.2 -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  --enable web_search_request \\\n  \"<edit general files prompt>\"\n```\n\n**Why `codex exec`?**\n- Non-interactive mode required for automation and Claude Code integration\n- Produces clean output suitable for parsing\n- Works in non-TTY environments (like Claude Code's bash)\n\n### Model Selection Logic\n\n**Step 1: Choose Model Based on Task Type**\n\n**Use `gpt-5.2-codex` for code-related tasks:**\n- Implementation, refactoring, code analysis\n- Debugging, fixing bugs, optimization\n- Any task involving code understanding or modification\n\n**Use `gpt-5.2` for general tasks:**\n- Architecture and system design\n- Explanations, documentation, reviews\n- Planning, strategy, general reasoning\n\n**Step 2: Choose Sandbox Based on Edit Intent**\n\n**Use `read-only` (DEFAULT):**\n- Analysis, review, explanation tasks\n- ANY task where user does NOT explicitly request file editing\n\n**Use `workspace-write` (ONLY when explicitly requested):**\n- User explicitly says \"edit this file\", \"modify the code\", \"write changes\"\n- User explicitly asks to \"make edits\" or \"save the changes\"\n- User explicitly requests \"refactor and save\" or \"implement and write\"\n\n**Fallback Models**: `gpt-5.1-codex-max` and `gpt-5.1` are available if primary models are unavailable. See fallback chain in DEFAULT MODEL section.\n\n### Default Configuration\n\nAll Codex invocations use these defaults unless user specifies otherwise:\n\n| Parameter | Default Value | CLI Flag | Notes |\n|-----------|---------------|----------|-------|\n| Model (code tasks) | `gpt-5.2-codex` | `-m gpt-5.2-codex` | For code-related tasks |\n| Model (general tasks) | `gpt-5.2` | `-m gpt-5.2` | For general tasks |\n| Sandbox (default) | `read-only` | `-s read-only` | Safe default for ALL tasks |\n| Sandbox (explicit edit) | `workspace-write` | `-s workspace-write` | Only when user explicitly requests editing |\n| Reasoning Effort | `xhigh` | `-c model_reasoning_effort=xhigh` | Maximum reasoning capability |\n| Verbosity | `medium` | `-c model_verbosity=medium` | Balanced output detail |\n| Web Search | `enabled` | `--enable web_search_request` | Access to up-to-date information |\n\n### CLI Flags Reference\n\n**Codex CLI Version**: 0.80.0+ (requires 0.80.0+ for gpt-5.2-codex and xhigh)\n\n| Flag | Values | Description |\n|------|--------|-------------|\n| `-m, --model` | `gpt-5.2-codex`, `gpt-5.2`, `gpt-5.1-codex-max`, `gpt-5.1` | Model selection |\n| `-s, --sandbox` | `read-only`, `workspace-write`, `danger-full-access` | Sandbox mode |\n| `-c, --config` | `key=value` | Config overrides (e.g., `model_reasoning_effort=high`) |\n| `-C, --cd` | directory path | Working directory |\n| `-p, --profile` | profile name | Use config profile |\n| `--enable` | feature name | Enable a feature (e.g., `web_search_request`) |\n| `--disable` | feature name | Disable a feature |\n| `-i, --image` | file path(s) | Attach image(s) to initial prompt |\n| `--add-dir` | directory path | Additional writable directory (repeatable) |\n| `--full-auto` | flag | Convenience for workspace-write sandbox with on-request approval |\n| `--oss` | flag | Use local open source model provider |\n| `--local-provider` | `lmstudio`, `ollama` | Specify local provider (with --oss) |\n| `--skip-git-repo-check` | flag | Allow running outside Git repository |\n| `--output-schema` | file path | JSON Schema file for response shape |\n| `--color` | `always`, `never`, `auto` | Color settings for output |\n| `--json` | flag | Print events as JSONL |\n| `-o, --output-last-message` | file path | Save last message to file |\n| `--dangerously-bypass-approvals-and-sandbox` | flag | Skip confirmations (DANGEROUS) |\n\n### Configuration Parameters\n\nPass these as `-c key=value`:\n\n- `model_reasoning_effort`: `minimal`, `low`, `medium`, `high`, `xhigh`\n  - **CLI default**: `high` - The Codex CLI defaults to high reasoning\n  - **Skill default**: `xhigh` - This skill explicitly uses xhigh for maximum capability\n  - **`xhigh`**: Extra-high reasoning for maximum capability (supported by gpt-5.2 and gpt-5.1-codex-max)\n  - Use `xhigh` for complex architectural refactoring, long-horizon tasks, or when quality is more important than speed\n- `model_verbosity`: `low`, `medium`, `high` (default: `medium`)\n- `model_reasoning_summary`: `auto`, `concise`, `detailed`, `none` (default: `auto`)\n- `sandbox_workspace_write.writable_roots`: JSON array of additional writable directories (e.g., `[\"/path1\",\"/path2\"]`)\n- `approval_policy`: `untrusted`, `on-failure`, `on-request`, `never` (approval behavior)\n\n**Additional Writable Directories**:\n\nUse `--add-dir` flag (preferred) or config:\n```bash\n# Using --add-dir for multiple directories\ncodex exec --add-dir /path1 --add-dir /path2 \"task\"\n\n# Alternative - config approach\ncodex exec -c 'sandbox_workspace_write.writable_roots=[\"/path1\",\"/path2\"]' \"task\"\n```\n\n### Model Selection Guide\n\n**Available Models**:\n- `gpt-5.2-codex` - Code tasks (implementation, refactoring, debugging)\n- `gpt-5.2` - General tasks (architecture, reviews, explanations)\n\n**Default**: `gpt-5.2-codex` for code tasks, `gpt-5.2` for general tasks with `xhigh` reasoning effort.\n\n## Session Continuation\n\n### Detecting Continuation Requests\n\nWhen user indicates they want to continue a previous Codex conversation:\n- Keywords: \"continue\", \"resume\", \"keep going\", \"add to that\"\n- Follow-up context referencing previous Codex work\n- Explicit request like \"continue where we left off\"\n\n### Resuming Sessions\n\nFor continuation requests, use the `codex resume` command:\n\n#### Resume Most Recent Session (Recommended)\n\n```bash\ncodex exec resume --last\n```\n\nThis automatically continues the most recent Codex session with all previous context maintained.\n\n#### Resume Specific Session\n\n```bash\ncodex exec resume <session-id>\n```\n\nResume a specific session by providing its UUID. Get session IDs from previous Codex output or by running `codex exec resume --last` to see the most recent session.\n\n**Note**: The interactive session picker (`codex resume` without arguments) is NOT available in non-interactive/Claude Code environments. Always use `--last` or provide explicit session ID.\n\n### Decision Logic: New vs. Continue\n\n**Use `codex exec -m ... \"<prompt>\"`** when:\n- User makes a new, independent request\n- No reference to previous Codex work\n- User explicitly wants a \"fresh\" or \"new\" session\n\n**Use `codex exec resume --last`** when:\n- User indicates continuation (\"continue\", \"resume\", \"add to that\")\n- Follow-up question building on previous Codex conversation\n- Iterative development on same task\n\n### Session History Management\n\n- Codex CLI automatically saves session history\n- No manual session ID tracking needed\n- Sessions persist across Claude Code restarts\n- Use `codex exec resume --last` to access most recent session\n- Use `codex exec resume <session-id>` for specific sessions\n\n## Error Handling\n\n### Simple Error Response Strategy\n\nWhen errors occur, return clear, actionable messages without complex diagnostics:\n\n**Error Message Format:**\n```\nError: [Clear description of what went wrong]\n\nTo fix: [Concrete remediation action]\n\n[Optional: Specific command example]\n```\n\n### Common Errors\n\n#### Command Not Found\n\n```\nError: Codex CLI not found\n\nTo fix: Install Codex CLI and ensure it's available in your PATH\n\nCheck installation: codex --version\n```\n\n#### Authentication Required\n\n```\nError: Not authenticated with Codex\n\nTo fix: Run 'codex login' to authenticate\n\nAfter authentication, try your request again.\n```\n\n#### Invalid Configuration\n\n```\nError: Invalid model specified\n\nTo fix:\n- For coding tasks: Use 'gpt-5.2-codex' with workspace-write sandbox\n- For reasoning tasks: Use 'gpt-5.2' with read-only sandbox\n\nExample (coding): codex exec -m gpt-5.2-codex -s workspace-write -c model_reasoning_effort=xhigh \"implement feature\"\nExample (reasoning): codex exec -m gpt-5.2 -s read-only -c model_reasoning_effort=xhigh \"explain architecture\"\n```\n\n### Troubleshooting\n\n**First Steps for Any Issues:**\n1. Check Codex CLI built-in help: `codex --help`, `codex exec --help`, `codex exec resume --help`\n2. Consult official documentation: [https://github.com/openai/codex/tree/main/docs](https://github.com/openai/codex/tree/main/docs)\n3. Verify skill resources in `references/` directory\n\n**Skill not being invoked?**\n- Check that request matches trigger keywords (Codex, complex coding, high reasoning, etc.)\n- Explicitly mention \"Codex\" in your request\n- Try: \"Use Codex to help me with...\"\n\n**Session not resuming?**\n- Verify you have a previous Codex session (check command output for session IDs)\n- Try: `codex exec resume --last` to resume most recent session\n- If no history exists, start a new session first\n\n**\"stdout is not a terminal\" error?**\n- Always use `codex exec` instead of plain `codex` in Claude Code\n- Claude Code's bash environment is non-interactive/non-terminal\n\n**Errors during execution?**\n- Codex CLI errors are passed through directly\n- Check Codex CLI logs for detailed diagnostics\n- Verify working directory permissions if using workspace-write\n- Check official Codex docs for latest updates and known issues\n\n## Examples\n\n### Code Analysis (Read-Only)\n```bash\ncodex exec -m gpt-5.2-codex -s read-only \\\n  -c model_reasoning_effort=xhigh \\\n  \"Analyze this function implementation\"\n```\n\n### Code Editing (Explicit Request)\n```bash\ncodex exec -m gpt-5.2-codex -s workspace-write \\\n  -c model_reasoning_effort=xhigh \\\n  \"Edit this file to implement the feature\"\n```\n\n### Session Continuation\n```bash\ncodex exec resume --last\n```\n\n**See**: `references/examples.md` for more examples including web search, file context, and code review patterns.\n\n---\n\n## Code Review Subcommand (v0.71.0+)\n\nThe `codex review` subcommand provides non-interactive code review capabilities:\n\n```bash\n# Review uncommitted changes (staged, unstaged, untracked)\ncodex review --uncommitted\n\n# Review changes against a base branch\ncodex review --base main\n\n# Review a specific commit\ncodex review --commit abc123\n\n# Review with custom instructions\ncodex review --uncommitted \"Focus on security vulnerabilities\"\n\n# Non-interactive via exec\ncodex exec review --uncommitted\n```\n\n**Review Options**:\n| Flag | Description |\n|------|-------------|\n| `--uncommitted` | Review staged, unstaged, and untracked changes |\n| `--base <BRANCH>` | Review changes against the given base branch |\n| `--commit <SHA>` | Review the changes introduced by a commit |\n| `--title <TITLE>` | Optional commit title for review summary |\n\n---\n\n## CLI Features Reference\n\nFor detailed CLI feature documentation, see `references/cli-features.md`.\n\n**Quick Reference** - Common features:\n- `--enable web_search_request` - Enable web search\n- `-i, --image` - Attach images to prompts\n- `--add-dir` - Add writable directories\n- `--full-auto` - Low-friction workspace-write mode\n- `--json` - JSONL output for programmatic processing\n\n---\n\n## File Context Passing\n\n**IMPORTANT**: Pass file paths to Codex CLI instead of embedding file content in prompts. This enables Codex to read files autonomously.\n\n**Quick reference**:\n- Use `-C /path` to set working directory\n- Use `--add-dir /path` for additional directories\n- Use `@path/to/file` syntax for explicit file references\n\n```bash\n# Example: analyze file with explicit @ syntax\ncodex exec -m gpt-5.2-codex -s read-only \\\n  \"Analyze @src/auth.ts and compare with @src/session.ts\"\n\n# Example: multi-directory analysis\ncodex exec -m gpt-5.2-codex -s read-only \\\n  --add-dir /shared/libs \\\n  \"Review how auth module uses shared utilities\"\n```\n\n**See**: `references/file-context.md` for complete file context documentation.\n\n---\n\n## Best Practices\n\n### 1. Use Descriptive Requests\n\n**Good**: \"Help me implement a thread-safe queue with priority support in Python\"\n**Vague**: \"Code help\"\n\nClear, specific requests get better results from high-reasoning models.\n\n### 2. Indicate Continuation Clearly\n\n**Good**: \"Continue with that queue implementation - add unit tests\"\n**Unclear**: \"Add tests\" (might start new session)\n\nExplicit continuation keywords help the skill choose the right command.\n\n### 3. Specify Permissions When Needed\n\n**Good**: \"Refactor this code (allow file writing)\"\n**Risky**: Assuming permissions without specifying\n\nMake your intent clear when you need workspace-write permissions.\n\n### 4. Leverage High Reasoning\n\nThe skill defaults to high reasoning effort - perfect for:\n- Complex algorithms\n- Architecture design\n- Performance optimization\n- Security reviews\n\n## Reference Documentation\n\nFor detailed information, consult these reference files:\n\n### Core References\n- **`references/file-context.md`** - File and directory context passing guide\n- **`references/examples.md`** - Complete command examples by use case\n- **`references/cli-features.md`** - Feature flags and CLI options\n\n### Workflow References\n- **`references/command-patterns.md`** - Common codex exec usage patterns\n- **`references/session-workflows.md`** - Session continuation and resume workflows\n- **`references/advanced-patterns.md`** - Complex configuration and flag combinations\n\n### CLI References\n- **`references/codex-help.md`** - Codex CLI command reference\n- **`references/codex-config.md`** - Full configuration options"
              }
            ]
          },
          {
            "name": "gemini",
            "description": "Google Gemini CLI integration for Claude Code. Provides access to Gemini AI models with intelligent model selection, session continuation, and safe defaults.",
            "source": "./plugins/gemini",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add Lucklyric/cc-dev-tools",
              "/plugin install gemini@cc-dev-tools"
            ],
            "signals": {
              "stars": 26,
              "forks": 3,
              "pushed_at": "2026-01-12T23:35:14Z",
              "created_at": "2025-10-21T01:24:14Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "gemini",
                "description": "This skill should be used when the user wants to invoke Google Gemini CLI for complex reasoning tasks, research, and AI assistance. Trigger phrases include \"use gemini\", \"ask gemini\", \"run gemini\", \"call gemini\", \"gemini cli\", \"Google AI\", \"Gemini reasoning\", or when users request Google's AI models, need advanced reasoning capabilities, research with web search, or want to continue previous Gemini conversations. Automatically triggers on Gemini-related requests and supports session continuation for iterative development.",
                "path": "plugins/gemini/skills/gemini/SKILL.md",
                "frontmatter": {
                  "name": "gemini",
                  "version": "1.2.0",
                  "description": "This skill should be used when the user wants to invoke Google Gemini CLI for complex reasoning tasks, research, and AI assistance. Trigger phrases include \"use gemini\", \"ask gemini\", \"run gemini\", \"call gemini\", \"gemini cli\", \"Google AI\", \"Gemini reasoning\", or when users request Google's AI models, need advanced reasoning capabilities, research with web search, or want to continue previous Gemini conversations. Automatically triggers on Gemini-related requests and supports session continuation for iterative development."
                },
                "content": "# Gemini: Google AI Assistant for Claude Code\n\n---\n\n## DEFAULT MODEL: Gemini 3 Pro\n\n**The default model for ALL Gemini invocations is `gemini-3-pro-preview`.**\n\n- Always use `gemini-3-pro-preview` unless user explicitly requests another model\n- This is the highest reasoning model available\n- Fallback to `gemini-2.5-flash` ONLY on 404/access errors\n\n```bash\n# Default invocation - ALWAYS use gemini-3-pro-preview\ngemini -m gemini-3-pro-preview \"your prompt here\"\n```\n\n---\n\n## CRITICAL: Positional Prompts Required\n\n**REQUIRED**: Use positional prompts for Gemini CLI invocations.\n\n**DEPRECATED**: `-p/--prompt` flag is officially deprecated and will be removed in a future version.\n\n**Examples:**\n- `gemini -m gemini-3-pro-preview \"prompt\"` (CORRECT - positional)\n- `gemini -m gemini-3-pro-preview -p \"prompt\"` (DEPRECATED - avoid using)\n- `gemini -r latest` (CORRECT - session resume)\n\n**Warning from CLI help**: \"[deprecated: Use the positional prompt instead. This flag will be removed in a future version.]\"\n\n**Why?** As of Gemini CLI v0.20.0, the `-p` flag is explicitly marked deprecated. Use positional prompts for forward compatibility.\n\n---\n\n## IMPORTANT: Preview Features & OAuth Free Tier\n\n**For OAuth free tier users in headless mode:**\n\nWhen `previewFeatures: true` in `~/.gemini/settings.json`, the CLI routes ALL requests to Gemini 3 Pro (even `-m gemini-2.5-pro`). Since free tier doesn't have Gemini 3 access, this causes 404 errors.\n\n**Solution**: Disable preview features for reliable headless operation:\n```json\n// ~/.gemini/settings.json\n{\n  \"general\": {\n    \"previewFeatures\": false\n  }\n}\n```\n\n**Plugin Behavior**: This skill automatically falls back to `gemini-2.5-flash` when encountering 404 errors. Flash always works with OAuth free tier.\n\n---\n\n## Trigger Examples\n\nThis skill activates when users say phrases like:\n- \"Use gemini to research this topic\"\n- \"Ask gemini about this design pattern\"\n- \"Run gemini on this analysis\"\n- \"Call gemini for help with this problem\"\n- \"I need Google AI for this task\"\n- \"Get Gemini's reasoning on this\"\n- \"Continue with gemini\" or \"Resume the gemini session\"\n- \"Gemini, help me with...\" or simply \"Gemini\"\n- \"Use Gemini 3\" or \"Use Gemini 2.5\"\n\n## When to Use This Skill\n\nThis skill should be invoked when:\n- User explicitly mentions \"Gemini\" or requests Gemini assistance\n- User needs Google's AI models for reasoning, research, or analysis\n- User requests complex problem-solving or architectural design\n- User needs research capabilities with web search integration\n- User wants to continue a previous Gemini conversation\n- User needs an alternative to Codex or Claude for specific tasks\n\n## How It Works\n\n### Detecting New Gemini Requests\n\nWhen a user makes a request, **default to read-only mode (default approval)** unless they explicitly request file editing:\n\n**Use `gemini-3-pro-preview` for ALL tasks with `default` approval mode:**\n- Architecture, design, reviews, research\n- Explanations, analysis, problem-solving\n- Code analysis and understanding\n- ANY task where user does NOT explicitly request file editing\n\n**Approval Mode Selection:**\n- **`default`** (default): For all tasks - prompts for approval on edits (safe)\n- **`auto_edit`**: ONLY when user explicitly requests file editing\n- **`yolo`**: When user explicitly wants full auto-approval (use with caution)\n\n**⚠️ Explicit Edit Request**: If the user explicitly asks to \"edit files\", \"modify code\", \"write changes\", or \"make edits\" - ONLY then use `--approval-mode auto_edit` to enable file modifications.\n\n**Fallback Chain** (if primary unavailable):\n1. `gemini-3-pro-preview` (primary - highest capability)\n2. `gemini-2.5-pro` (stable general reasoning)\n3. `gemini-2.5-flash` (fast, always available)\n\n**Example requests**: \"Design a distributed cache\", \"Explain CQRS pattern\", \"Analyze this code\"\n\n### Bash CLI Command Structure\n\n**IMPORTANT**: Gemini CLI works differently from Codex - no `exec` subcommand needed. Use positional prompts directly.\n\n#### Default Command (Read-Only) - Use for ALL Tasks\n\n```bash\ngemini -m gemini-3-pro-preview \\\n  \"Design a microservices architecture for e-commerce\"\n```\n\n#### Explicit Edit Request Only - When User Asks to Edit Files\n\n```bash\ngemini -m gemini-3-pro-preview \\\n  --approval-mode auto_edit \\\n  \"Edit this file to refactor the function\"\n```\n\n#### For Session Continuation\n\n```bash\n# Resume most recent session\ngemini -r latest\n\n# Resume specific session by index\ngemini -r 3\n\n# Resume and add new prompt\ngemini -r latest \"Continue our discussion about caching strategies\"\n```\n\n**Why positional prompts?**\n- Simpler, more direct syntax\n- Future-proof (recommended by Gemini CLI)\n- Works in non-TTY environments (like Claude Code's bash)\n- No separate `exec` command needed\n\n### Model Selection Logic\n\n**Use `gemini-3-pro-preview` (default for ALL tasks):**\n- Code editing, refactoring, implementation\n- Designing architecture or system design\n- Conducting research or analysis\n- Explaining complex concepts\n- Planning implementation strategies\n- General problem-solving and advanced reasoning\n\n**Fallback to `gemini-2.5-pro` when:**\n- Gemini 3 Pro unavailable or quota exhausted\n- User explicitly requests \"Gemini 2.5\" or \"use 2.5\"\n- Stable, production-ready tasks\n\n**Fallback to `gemini-2.5-flash` when:**\n- Both Gemini 3 Pro and 2.5 Pro unavailable\n- Fast iterations needed (explicit user request)\n- Simple, quick responses (explicit user request)\n\n### Version-Based Model Mapping\n\nWhen users mention a version number, map to the latest model in that family:\n\n| User Request | Maps To | Actual Model ID |\n|--------------|---------|-----------------|\n| \"use 3\" / \"Gemini 3\" | Latest 3.x Pro | `gemini-3-pro-preview` |\n| \"use 2.5\" | 2.5 Pro | `gemini-2.5-pro` |\n| \"use flash\" | 2.5 Flash | `gemini-2.5-flash` |\n| No version specified | Latest Pro (ALL tasks) | `gemini-3-pro-preview` |\n\n**See**: `references/model-selection.md` for detailed model selection guidance and decision tree.\n\n### Default Configuration\n\nAll Gemini invocations use these defaults unless user specifies otherwise:\n\n| Parameter | Default Value | CLI Flag | Notes |\n|-----------|---------------|----------|-------|\n| Model | `gemini-3-pro-preview` | `-m gemini-3-pro-preview` | For ALL tasks (highest capability) |\n| Model (fallback 1) | `gemini-2.5-pro` | `-m gemini-2.5-pro` | If Gemini 3 Pro unavailable |\n| Model (fallback 2) | `gemini-2.5-flash` | `-m gemini-2.5-flash` | Always works on free tier |\n| Approval Mode (default) | `default` | No flag | Safe default - prompts for edits |\n| Approval Mode (editing) | `auto_edit` | `--approval-mode auto_edit` | Only when user explicitly requests editing |\n| Sandbox | `false` (disabled) | No flag | Sandbox disabled by default |\n| Output Format | `text` | No flag | Human-readable text output |\n| Web Search | Enabled when appropriate | `-e web_search` (if needed) | Context-dependent |\n\n**Rationale for Defaults:**\n- **Gemini 3 Pro for ALL tasks**: Highest capability model, optimized for both reasoning and code\n- **Fallback chain**: gemini-3-pro-preview → gemini-2.5-pro → gemini-2.5-flash\n- **default mode**: Safe default that prompts for approval on edits\n- **auto_edit mode**: Only use when user explicitly requests file editing\n- **No sandbox**: Claude Code environment assumed trusted\n- **Text output**: Default for human consumption (use `--output-format json` for parsing)\n\n**Note**: If you have `previewFeatures: true` in settings, disable it for reliable headless operation (see warning above).\n\n### Error Handling\n\nThe skill handles these common errors gracefully:\n\n#### CLI Not Installed\n\n**Error**: `command not found: gemini`\n\n**Message**: \"Gemini CLI not installed. Install from: https://github.com/google-gemini/gemini-cli\"\n\n**Action**: User must install Gemini CLI before using this skill\n\n#### Authentication Required\n\n**Error**: Output contains \"auth\" or \"authentication\"\n\n**Message**: \"Authentication required. Run: `gemini login` to authenticate with your Google account\"\n\n**Action**: User must authenticate via OAuth or API key\n\n#### Rate Limit Exceeded\n\n**Error**: Output contains \"quota\" or \"rate limit\" or status 429\n\n**Message**: \"Rate limit exceeded (60 req/min, 1000 req/day free tier). Retry in X seconds or upgrade account.\"\n\n**Action**: Wait for rate limit reset or upgrade to paid tier\n\n#### Model Unavailable\n\n**Error**: Output contains \"model not found\" or \"404\" or status 403\n\n**Message**: \"Model unavailable. Trying fallback model...\"\n\n**Action**: Automatically retry with fallback:\n- `gemini-3-pro-preview` unavailable → try `gemini-2.5-pro`\n- `gemini-2.5-pro` unavailable → try `gemini-2.5-flash`\n\n#### Session Not Found\n\n**Error**: Using `-r` flag but session doesn't exist\n\n**Message**: \"Session not found. Use `gemini --list-sessions` to see available sessions.\"\n\n**Action**: User should list sessions or start new session\n\n#### Gemini 3 Pro Access Denied\n\n**Error**: Status 403 or \"preview access required\"\n\n**Message**: \"Gemini 3 Pro requires preview access. Enable Preview Features in settings or use `gemini-2.5-pro` instead.\"\n\n**Action**: Either enable preview features, get API key, or use 2.5 models\n\n**See**: `references/gemini-help.md` for complete CLI reference and troubleshooting.\n\n---\n\n## Examples\n\n### Basic Invocation (General Reasoning)\n\n```bash\n# Design system architecture\ngemini -m gemini-3-pro-preview \"Design a scalable payment processing system\"\n\n# Research with web search\ngemini -m gemini-3-pro-preview -e web_search \"Research latest React 19 features\"\n\n# Explain complex concept\ngemini -m gemini-3-pro-preview \"Explain the CAP theorem with real-world examples\"\n```\n\n### Code Editing Tasks\n\n```bash\n# Refactoring (uses gemini-3-pro-preview for all tasks)\ngemini -m gemini-3-pro-preview \"Refactor this function for better readability\"\n\n# Fix syntax errors\ngemini -m gemini-3-pro-preview \"Fix the syntax errors in this JavaScript code\"\n\n# Optimize performance\ngemini -m gemini-3-pro-preview \"Optimize this database query for better performance\"\n```\n\n### Session Management\n\n```bash\n# Start a session (automatic)\ngemini -m gemini-3-pro-preview \"Design an authentication system\"\n\n# List available sessions\ngemini --list-sessions\n\n# Resume most recent\ngemini -r latest\n\n# Resume specific session\ngemini -r 3\n\n# Continue with new prompt\ngemini -r latest \"Now help me implement the login flow\"\n```\n\n### With Output Formatting\n\n```bash\n# JSON output for parsing\ngemini -m gemini-2.5-pro --output-format json \"List top 5 design patterns\"\n\n# Streaming JSON for real-time\ngemini -m gemini-2.5-pro --output-format stream-json \"Explain async patterns\"\n```\n\n### Approval Modes\n\n```bash\n# Default mode (prompt for all)\ngemini -m gemini-2.5-pro --approval-mode default \"Review this code\"\n\n# Auto-edit (auto-approve edits only)\ngemini -m gemini-2.5-pro --approval-mode auto_edit \"Refactor this module\"\n\n# YOLO mode (auto-approve ALL - use with caution)\ngemini -m gemini-2.5-pro --approval-mode yolo \"Deploy to production\"\n```\n\n### Sandbox Mode\n\n```bash\n# Enable sandbox for untrusted code\ngemini -m gemini-2.5-pro -s \"Analyze this suspicious code snippet\"\n\n# Disabled by default (trusted environment)\ngemini -m gemini-2.5-pro \"Review this internal codebase\"\n```\n\n### Extensions & MCP Integration\n\nGemini CLI supports extensions and Model Context Protocol (MCP) servers for enhanced functionality.\n\n```bash\n# List available extensions\ngemini --list-extensions\n\n# Use specific extensions (web search, code analysis, etc.)\ngemini -m gemini-3-pro-preview -e web_search \"Research React 19 features\"\n\n# Use all extensions (default)\ngemini -m gemini-3-pro-preview \"Design system architecture\"\n```\n\n**Note**: This plugin does not implement custom extensions or MCP servers. Users can configure extensions and MCP servers through the Gemini CLI's standard configuration in `~/.gemini/settings.json`. Extensions are enabled by default when appropriate for the task.\n\n### Additional Directories (`--include-directories`) (v0.20.0+)\n\nInclude additional directories in workspace context:\n\n```bash\n# Single directory\ngemini -m gemini-3-pro-preview --include-directories /shared/libs \"task\"\n\n# Multiple directories (comma-separated)\ngemini -m gemini-3-pro-preview --include-directories /path1,/path2 \"task\"\n\n# Multiple directories (repeated flag)\ngemini -m gemini-3-pro-preview --include-directories /path1 --include-directories /path2 \"task\"\n```\n\n**Note**: Disabled in restrictive sandbox profiles.\n\n---\n\n## File Context Passing\n\n**IMPORTANT**: Pass file paths to Gemini CLI instead of embedding file content in prompts. This enables Gemini to read files autonomously.\n\n**Quick reference**:\n- Use `--include-directories /path` for additional directories\n- Use `@path/to/file` syntax for explicit file references\n\n```bash\n# Example: analyze file with explicit @ syntax\ngemini -m gemini-3-pro-preview \\\n  \"Analyze @src/auth.ts and compare with @src/session.ts\"\n\n# Example: multi-directory analysis\ngemini -m gemini-3-pro-preview \\\n  --include-directories /shared/libs \\\n  \"Review how auth module uses shared utilities\"\n```\n\n**See**: `references/file-context.md` for complete file context documentation.\n\n---\n\n### Accessibility (`--screen-reader`) (v0.20.0+)\n\nEnable screen reader mode for accessibility:\n\n```bash\ngemini -m gemini-3-pro-preview --screen-reader \"task\"\n```\n\n### Interactive with Prompt (`-i/--prompt-interactive`) (v0.20.0+)\n\nExecute a prompt and continue in interactive mode:\n\n```bash\ngemini -m gemini-3-pro-preview -i \"initial prompt here\"\n```\n\n**Note**: Limited applicability for Claude Code skills which use non-interactive mode.\n\n### Experimental ACP Mode (`--experimental-acp`)\n\nStart agent in Agent Control Protocol mode for programmatic interaction:\n\n```bash\ngemini --experimental-acp \"task\"\n```\n\n**Note**: Experimental feature. Works with `GEMINI_API_KEY` environment variable.\n\n---\n\n## Reference Documentation\n\nFor detailed information, consult these reference files:\n\n### Core References\n- **`references/file-context.md`** - File and directory context passing guide\n- **`references/model-selection.md`** - Model selection decision tree and version mapping\n\n### Workflow References\n- **`references/command-patterns.md`** - Common command templates organized by use case\n- **`references/session-workflows.md`** - Multi-turn conversation patterns and best practices\n\n### CLI References\n- **`references/gemini-help.md`** - Complete Gemini CLI help output and flag reference\n\n---\n\n## Tips & Best Practices\n\n1. **Always Specify Model**: Use `-m` flag explicitly for predictable behavior\n2. **Use Positional Prompts**: Prefer `gemini \"prompt\"` over deprecated `-p` flag\n3. **Enable Web Search When Needed**: Add `-e web_search` for research tasks\n4. **Resume Sessions for Complex Tasks**: Use `-r latest` for multi-turn conversations\n5. **Start with Gemini 3 Pro**: Default to `gemini-3-pro-preview`, fallback to 2.5 models\n6. **Use Appropriate Approval Mode**: `auto_edit` for code, `default` for untrusted tasks\n7. **Monitor Rate Limits**: 60 req/min, 1000 req/day on free tier\n8. **Check CLI Availability**: Validate `command -v gemini` before invocation\n\n---\n\n## Differences from Codex\n\n| Feature | Codex CLI | Gemini CLI |\n|---------|-----------|------------|\n| Invocation | `codex exec \"prompt\"` | `gemini \"prompt\"` |\n| Subcommand | Required (`exec`) | Not needed |\n| Positional Prompts | Not supported | Preferred |\n| Session Resume | `codex exec resume --last` | `gemini -r latest` |\n| Models | GPT-5.2, GPT-5.2-Codex | Gemini 3 Pro, 2.5 Pro/Flash |\n| Provider | OpenAI (via Codex) | Google |\n\n---\n\n## When to Use Gemini vs Codex vs Claude\n\n**Use Gemini when:**\n- You need Google's latest models\n- Research with web search is important\n- You prefer Google's AI capabilities\n- Codex is unavailable or rate-limited\n- Task benefits from Gemini's strengths\n\n**Use Codex when:**\n- You need GPT-5.1's reasoning capabilities\n- Task requires high-reasoning model\n- Code editing with specific Codex optimizations\n- You're already using Codex workflow\n\n**Use Claude (native) when:**\n- Simple queries within Claude Code's capabilities\n- No external AI needed\n- Quick responses preferred\n- Task doesn't require specialized models\n\n---\n\n## Version Compatibility\n\n**Minimum Gemini CLI**: v0.23.0\n\nFor questions or issues, consult `references/gemini-help.md` or run `gemini --help`."
              }
            ]
          },
          {
            "name": "telegram-notifier",
            "description": "Telegram notifications for Claude Code response completion, subagent tasks, and system notifications. Configurable via environment variables with dry-run mode for testing.",
            "source": "./plugins/telegram-notifier",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add Lucklyric/cc-dev-tools",
              "/plugin install telegram-notifier@cc-dev-tools"
            ],
            "signals": {
              "stars": 26,
              "forks": 3,
              "pushed_at": "2026-01-12T23:35:14Z",
              "created_at": "2025-10-21T01:24:14Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": []
          }
        ]
      }
    }
  ]
}