{
  "owner": {
    "id": "evangelosmeklis",
    "display_name": "Evangelos Meklis",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/57478341?u=8f29916b0125e8709ef65ce9fa7e33c1f7838d2b&v=4",
    "url": "https://github.com/evangelosmeklis",
    "bio": "Software Engineer @ Nokia \r\n(C++ / Python)",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 4,
      "total_stars": 7,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "evangelosmeklis/thufir",
      "url": "https://github.com/evangelosmeklis/thufir",
      "description": "Claude Code plugin to solve production issues",
      "homepage": "",
      "signals": {
        "stars": 7,
        "forks": 0,
        "pushed_at": "2025-12-20T10:09:17Z",
        "created_at": "2025-12-19T20:22:00Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1080
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 544
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/thufir.local.md.example",
          "type": "blob",
          "size": 4005
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 352
        },
        {
          "path": ".mcp.json",
          "type": "blob",
          "size": 998
        },
        {
          "path": "CHANGELOG.md",
          "type": "blob",
          "size": 3227
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7169
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1073
        },
        {
          "path": "MARKETPLACE.md",
          "type": "blob",
          "size": 6397
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 1759
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/analyze-github.md",
          "type": "blob",
          "size": 7721
        },
        {
          "path": "commands/analyze-gitlab.md",
          "type": "blob",
          "size": 8317
        },
        {
          "path": "commands/analyze-prometheus.md",
          "type": "blob",
          "size": 6436
        },
        {
          "path": "commands/investigate.md",
          "type": "blob",
          "size": 8052
        },
        {
          "path": "mcp-servers",
          "type": "tree",
          "size": null
        },
        {
          "path": "mcp-servers/gitlab",
          "type": "tree",
          "size": null
        },
        {
          "path": "mcp-servers/gitlab/requirements.txt",
          "type": "blob",
          "size": 58
        },
        {
          "path": "mcp-servers/gitlab/server.py",
          "type": "blob",
          "size": 11524
        },
        {
          "path": "mcp-servers/prometheus",
          "type": "tree",
          "size": null
        },
        {
          "path": "mcp-servers/prometheus/requirements.txt",
          "type": "blob",
          "size": 62
        },
        {
          "path": "mcp-servers/prometheus/server.py",
          "type": "blob",
          "size": 9069
        },
        {
          "path": "media",
          "type": "tree",
          "size": null
        },
        {
          "path": "media/Screenshot 2025-12-20 at 12.03.32.png",
          "type": "blob",
          "size": 64322
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/git-investigation",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/git-investigation/SKILL.md",
          "type": "blob",
          "size": 12376
        },
        {
          "path": "skills/git-investigation/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/git-investigation/examples/bisect-script.sh",
          "type": "blob",
          "size": 4348
        },
        {
          "path": "skills/git-investigation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/git-investigation/references/git-aliases.md",
          "type": "blob",
          "size": 7893
        },
        {
          "path": "skills/git-investigation/references/git-workflows.md",
          "type": "blob",
          "size": 12851
        },
        {
          "path": "skills/platform-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/platform-integration/SKILL.md",
          "type": "blob",
          "size": 11151
        },
        {
          "path": "skills/platform-integration/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/platform-integration/references/api-examples.md",
          "type": "blob",
          "size": 13666
        },
        {
          "path": "skills/prometheus-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/prometheus-analysis/SKILL.md",
          "type": "blob",
          "size": 9924
        },
        {
          "path": "skills/prometheus-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/prometheus-analysis/references/promql-cookbook.md",
          "type": "blob",
          "size": 12287
        },
        {
          "path": "skills/root-cause-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/root-cause-analysis/SKILL.md",
          "type": "blob",
          "size": 10587
        },
        {
          "path": "skills/root-cause-analysis/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/root-cause-analysis/examples/rca-report-template.md",
          "type": "blob",
          "size": 9547
        },
        {
          "path": "skills/root-cause-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/root-cause-analysis/references/investigation-checklist.md",
          "type": "blob",
          "size": 8737
        },
        {
          "path": "skills/root-cause-analysis/references/rca-patterns.md",
          "type": "blob",
          "size": 11494
        }
      ],
      "marketplace": {
        "name": "thufir",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Evangelos Meklis",
          "email": "vmeklis@hotmail.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "thufir",
            "description": "Root cause analysis plugin integrating Prometheus, GitHub, and GitLab for production incident investigation",
            "source": "./",
            "category": "DevOps",
            "version": "1.0.0",
            "author": {
              "name": "Evangelos Meklis",
              "email": "vmeklis@hotmail.com"
            },
            "install_commands": [
              "/plugin marketplace add evangelosmeklis/thufir",
              "/plugin install thufir@thufir"
            ],
            "signals": {
              "stars": 7,
              "forks": 0,
              "pushed_at": "2025-12-20T10:09:17Z",
              "created_at": "2025-12-19T20:22:00Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "Git Investigation",
                "description": "This skill should be used when the user asks to \"use git blame\", \"check git history\", \"find git commits\", \"use git log\", \"use git diff\", \"use git bisect\", \"trace code changes\", \"find who changed this code\", or mentions using git commands for investigating code history and changes during root cause analysis.",
                "path": "skills/git-investigation/SKILL.md",
                "frontmatter": {
                  "name": "Git Investigation",
                  "description": "This skill should be used when the user asks to \"use git blame\", \"check git history\", \"find git commits\", \"use git log\", \"use git diff\", \"use git bisect\", \"trace code changes\", \"find who changed this code\", or mentions using git commands for investigating code history and changes during root cause analysis.",
                  "version": "0.1.0"
                },
                "content": "# Git Investigation\n\n## Overview\n\nGit is a distributed version control system that tracks code changes over time. This skill provides guidance for using git commands to investigate code history, identify when bugs were introduced, and track down specific changes during root cause analysis.\n\n## When to Use This Skill\n\nApply this skill when:\n- Tracing when specific code was changed\n- Finding who authored problematic code\n- Identifying commits that introduced bugs\n- Comparing code versions before/after incidents\n- Searching commit messages for clues\n- Binary searching for breaking commits (bisect)\n\n## Essential Git Commands for RCA\n\n### git log - View Commit History\n\n**Basic usage**:\n```bash\ngit log\n```\n\n**Useful flags for RCA**:\n\n**Show commits with diffs**:\n```bash\ngit log -p\n```\n\n**Show commits for specific file**:\n```bash\ngit log -- path/to/file.js\n```\n\n**Show commits in time range**:\n```bash\ngit log --since=\"2025-12-19 00:00\" --until=\"2025-12-19 23:59\"\n```\n\n**Show one-line summaries**:\n```bash\ngit log --oneline\n```\n\n**Show commits by author**:\n```bash\ngit log --author=\"Developer Name\"\n```\n\n**Show commit graph**:\n```bash\ngit log --graph --oneline --all\n```\n\n**Search commit messages**:\n```bash\ngit log --grep=\"database\" --grep=\"pool\" --all-match\n```\n\n**Format output**:\n```bash\ngit log --format=\"%h %an %ad %s\" --date=short\n```\n\n### git blame - Find Line Authors\n\n**Basic usage**:\n```bash\ngit blame path/to/file.js\n```\n\n**Show line ranges**:\n```bash\ngit blame -L 40,50 path/to/file.js\n```\n\n**Show email addresses**:\n```bash\ngit blame -e path/to/file.js\n```\n\n**Follow line history through renames**:\n```bash\ngit blame -C -C -C path/to/file.js\n```\n\n**Show commit details**:\n```bash\ngit blame -s path/to/file.js\n```\n\n**Blame output format**:\n```\nabc123de (Developer Name 2025-12-19 10:15:00 +0000 45)   max: 10,\n```\n- `abc123de`: Commit SHA\n- `Developer Name`: Author\n- `2025-12-19 10:15:00`: Timestamp\n- `45`: Line number\n- `max: 10,`: Code content\n\n### git diff - Compare Versions\n\n**Compare working directory with last commit**:\n```bash\ngit diff\n```\n\n**Compare specific commits**:\n```bash\ngit diff commit1 commit2\n```\n\n**Compare file across commits**:\n```bash\ngit diff commit1 commit2 -- path/to/file.js\n```\n\n**Compare with previous commit**:\n```bash\ngit diff HEAD~1 HEAD\n```\n\n**Show diff for specific commit**:\n```bash\ngit show commit_sha\n```\n\n**Unified diff with context**:\n```bash\ngit diff -U5  # Show 5 lines of context\n```\n\n**Word-level diff**:\n```bash\ngit diff --word-diff\n```\n\n### git show - View Commit Details\n\n**Show complete commit**:\n```bash\ngit show commit_sha\n```\n\n**Show specific file in commit**:\n```bash\ngit show commit_sha:path/to/file.js\n```\n\n**Show commit metadata only**:\n```bash\ngit show --stat commit_sha\n```\n\n### git bisect - Binary Search for Breaking Commit\n\n**Use when**: You know code worked at one point and is broken now, but don't know which commit broke it.\n\n**Workflow**:\n\n1. **Start bisect**:\n```bash\ngit bisect start\n```\n\n2. **Mark current as bad**:\n```bash\ngit bisect bad\n```\n\n3. **Mark known good commit**:\n```bash\ngit bisect good commit_sha  # or tag, or HEAD~20\n```\n\n4. **Test current code** (git checks out midpoint)\n   - Run tests or reproduce bug\n   - If broken: `git bisect bad`\n   - If working: `git bisect good`\n\n5. **Repeat** until git identifies first bad commit\n\n6. **End bisect**:\n```bash\ngit bisect reset\n```\n\n**Automated bisect**:\n```bash\ngit bisect start HEAD v1.0\ngit bisect run ./test-script.sh\n```\n\nTest script should exit 0 for good, non-zero for bad.\n\n## Git Investigation Workflows\n\n### Workflow 1: Find When Line Changed\n\n**Goal**: Identify when specific line was last modified\n\n**Steps**:\n\n1. Use blame to find commit:\n```bash\ngit blame path/to/file.js | grep \"suspicious code\"\n```\n\n2. Extract commit SHA from blame output\n\n3. View commit details:\n```bash\ngit show commit_sha\n```\n\n4. Review commit message, author, timestamp, and changes\n\n### Workflow 2: Track File History\n\n**Goal**: See all changes to a file over time\n\n**Steps**:\n\n1. View commit history for file:\n```bash\ngit log -p -- path/to/file.js\n```\n\n2. Focus on time range around incident:\n```bash\ngit log --since=\"2025-12-18\" --until=\"2025-12-19\" -- path/to/file.js\n```\n\n3. Review each commit's diff to identify suspicious changes\n\n### Workflow 3: Find Recent Changes to Multiple Files\n\n**Goal**: Identify recent commits affecting several related files\n\n**Steps**:\n\n1. List recent commits with file stats:\n```bash\ngit log --since=\"2025-12-19\" --stat\n```\n\n2. Filter commits touching specific directory:\n```bash\ngit log --since=\"2025-12-19\" -- src/config/\n```\n\n3. Look for commits near incident time that modified relevant files\n\n### Workflow 4: Search Commit Messages\n\n**Goal**: Find commits related to specific feature or bug\n\n**Steps**:\n\n1. Search commit messages:\n```bash\ngit log --grep=\"database\" --grep=\"connection\" --all-match\n```\n\n2. Or search for any of multiple terms:\n```bash\ngit log --grep=\"database\\|connection\\|pool\"\n```\n\n3. Review matching commits for relevance\n\n### Workflow 5: Compare Working vs Deployed Version\n\n**Goal**: Identify differences between deployed and current code\n\n**Steps**:\n\n1. Find deployed commit SHA (from deployment logs or tags):\n```bash\ndeployed_sha=\"abc123\"\n```\n\n2. Compare with current code:\n```bash\ngit diff $deployed_sha HEAD\n```\n\n3. Or compare specific file:\n```bash\ngit diff $deployed_sha HEAD -- path/to/file.js\n```\n\n4. Review differences for potential issues\n\n### Workflow 6: Binary Search for Breaking Commit\n\n**Goal**: Find exact commit that introduced bug\n\n**Steps**:\n\n1. Identify known-good commit (e.g., last working version):\n```bash\ngit log --oneline\n# Find commit SHA before issue appeared\n```\n\n2. Start bisect:\n```bash\ngit bisect start\ngit bisect bad  # Current is broken\ngit bisect good good_commit_sha\n```\n\n3. Test each checkout:\n   - Reproduce issue or run tests\n   - Mark as `git bisect good` or `git bisect bad`\n\n4. Git identifies first bad commit\n\n5. Review that commit to find root cause\n\n## Advanced Git Techniques\n\n### Finding Deleted Code\n\n**Search for deleted lines**:\n```bash\ngit log -S \"deleted code pattern\" --all\n```\n\n**Example** - Find when \"max: 100\" was removed:\n```bash\ngit log -S \"max: 100\" -- src/config/database.js\n```\n\n### Following Renames\n\n**Track file across renames**:\n```bash\ngit log --follow -- path/to/file.js\n```\n\n**Blame with rename detection**:\n```bash\ngit blame -C -C -C path/to/file.js\n```\n\n### Finding Large Changes\n\n**Show commits by diff size**:\n```bash\ngit log --stat --format=\"%h %s\" | head -20\n```\n\n**Find commits with many changes**:\n```bash\ngit log --shortstat | grep -E \"file.*change\"\n```\n\n### Checking Specific Commit\n\n**View commit details**:\n```bash\ngit show commit_sha\n```\n\n**View files changed in commit**:\n```bash\ngit show --name-only commit_sha\n```\n\n**View commit as patch**:\n```bash\ngit format-patch -1 commit_sha\n```\n\n## Interpreting Git Output\n\n### Git Blame Output\n\n```\nabc123de src/config/database.js (Developer Name 2025-12-19 10:15:00 +0000 45)   max: 10,\n```\n\n**Extract**:\n- Commit: `abc123de`\n- File: `src/config/database.js`\n- Author: `Developer Name`\n- Date: `2025-12-19 10:15:00`\n- Line: `45`\n- Code: `max: 10,`\n\n**Action**: Check if timestamp correlates with incident start.\n\n### Git Log Output\n\n```\ncommit abc123def456789\nAuthor: Developer Name <dev@example.com>\nDate:   Thu Dec 19 10:15:00 2025 +0000\n\n    Refactor database configuration\n\n    Align pool size with staging environment\n```\n\n**Extract**:\n- Full SHA: `abc123def456789`\n- Author: `Developer Name <dev@example.com>`\n- Date: `Thu Dec 19 10:15:00 2025`\n- Message: Multi-line commit message\n\n**Red flags**:\n- Vague messages: \"fix bug\", \"update code\"\n- Large refactors near incident time\n- Config changes without explanation\n\n### Git Diff Output\n\n```diff\ndiff --git a/src/config/database.js b/src/config/database.js\nindex abc123d..def456e 100644\n--- a/src/config/database.js\n+++ b/src/config/database.js\n@@ -42,7 +42,7 @@ function createConnectionPool() {\n   return new Pool({\n     host: process.env.DB_HOST,\n     port: process.env.DB_PORT,\n-    max: 100,\n+    max: 10,  // Align with staging\n     min: 10,\n     idleTimeoutMillis: 30000\n   });\n```\n\n**Interpret**:\n- `-` line: Old code (removed)\n- `+` line: New code (added)\n- `@@ -42,7 +42,7 @@`: Line numbers (start at line 42, 7 lines shown)\n\n**Identify issue**: `max: 100` → `max: 10` is likely problematic reduction.\n\n## Best Practices\n\n### Do:\n\n- **Use time ranges** to focus on relevant commits\n```bash\ngit log --since=\"2025-12-19 00:00\" --until=\"2025-12-19 23:59\"\n```\n\n- **Filter by file/directory** to reduce noise\n```bash\ngit log -- src/config/\n```\n\n- **Combine flags** for precise queries\n```bash\ngit log --author=\"Developer\" --since=\"1 week ago\" -- src/\n```\n\n- **Use grep** to search commit messages\n```bash\ngit log --grep=\"database\"\n```\n\n- **Follow renames** when tracking file history\n```bash\ngit log --follow -- file.js\n```\n\n- **Use bisect** for efficient debugging\n```bash\ngit bisect start HEAD v1.0.0\n```\n\n### Don't:\n\n- Run `git log` without filters (too much output)\n- Ignore commit messages (valuable clues)\n- Forget time context (correlate with incident time)\n- Skip reading full diffs (may miss subtle bugs)\n- Blame individuals (focus on system improvements)\n\n## Integration with Thufir\n\nThis skill integrates with:\n- **root-cause-analysis skill**: Git provides evidence for RCA\n- **platform-integration skill**: Complements GitHub/GitLab API data\n- **RCA agent**: Agent uses git commands via Bash tool\n\n### Using Git in RCA Agent\n\nAgent can execute git commands:\n\n```bash\n# Find recent commits to file\ngit log --since=\"24 hours ago\" --oneline -- src/config/database.js\n\n# Blame specific line\ngit blame -L 45,45 src/config/database.js\n\n# Show commit details\ngit show abc123\n\n# Compare versions\ngit diff HEAD~1 HEAD -- src/config/database.js\n```\n\nAgent parses output to extract commit SHAs, authors, timestamps, and changes.\n\n## Common Patterns\n\n### Pattern 1: Stack Trace Points to File\n\n1. Extract file and line from stack trace\n2. Use `git blame` on that file/line\n3. Identify commit that last touched it\n4. Use `git show` to review commit\n5. Correlate commit time with incident\n\n### Pattern 2: Config Change Suspected\n\n1. List recent commits to config files:\n```bash\ngit log --since=\"1 week ago\" -- config/ src/config/\n```\n\n2. Review each commit's diff:\n```bash\ngit show commit_sha\n```\n\n3. Identify config value changes\n4. Correlate changes with incident symptoms\n\n### Pattern 3: Recent Deployment Broke Code\n\n1. Find deployed commit (from deployment logs)\n2. Compare with previous deployment:\n```bash\ngit diff previous_commit deployed_commit\n```\n\n3. Review all changes in that diff\n4. Identify suspicious changes\n5. Test hypothesis by reverting specific changes\n\n### Pattern 4: Bug Introduced Sometime Ago\n\n1. Identify known-good version\n2. Use git bisect:\n```bash\ngit bisect start HEAD good_commit\ngit bisect run ./test-reproduction.sh\n```\n\n3. Git identifies first bad commit\n4. Review that commit for root cause\n\n## Additional Resources\n\n### Reference Files\n\nFor advanced git techniques:\n- **`references/git-aliases.md`** - Useful git aliases for RCA\n- **`references/git-workflows.md`** - Complete RCA investigation workflows\n\n### Example Files\n\nWorking examples:\n- **`examples/bisect-script.sh`** - Sample automated bisect script\n\n## Quick Reference\n\n**Recent commits**: `git log --since=\"1 day ago\" --oneline`\n**Blame line**: `git blame -L 45,45 file.js`\n**Show commit**: `git show abc123`\n**Diff commits**: `git diff commit1 commit2`\n**Search messages**: `git log --grep=\"pattern\"`\n**File history**: `git log -p -- file.js`\n**Binary search**: `git bisect start HEAD good_commit`\n\n**Correlate timestamps**: Always compare git timestamps with incident timeline\n**Follow renames**: Use `--follow` flag for moved files\n**Read full diffs**: Don't just trust commit messages\n\n---\n\nMaster git investigation techniques to efficiently trace code history and identify exact commits that introduced production issues."
              },
              {
                "name": "Platform Integration (GitHub/GitLab)",
                "description": "This skill should be used when the user asks to \"fetch GitHub issue\", \"get GitLab issue\", \"analyze GitHub PR\", \"search GitHub repo\", \"check GitLab commits\", \"use GitHub API\", \"use GitLab API\", or mentions fetching data from GitHub or GitLab for incident investigation. Provides guidance for integrating with GitHub and GitLab APIs for RCA.",
                "path": "skills/platform-integration/SKILL.md",
                "frontmatter": {
                  "name": "Platform Integration (GitHub/GitLab)",
                  "description": "This skill should be used when the user asks to \"fetch GitHub issue\", \"get GitLab issue\", \"analyze GitHub PR\", \"search GitHub repo\", \"check GitLab commits\", \"use GitHub API\", \"use GitLab API\", or mentions fetching data from GitHub or GitLab for incident investigation. Provides guidance for integrating with GitHub and GitLab APIs for RCA.",
                  "version": "0.1.0"
                },
                "content": "# Platform Integration (GitHub/GitLab)\n\n## Overview\n\nGitHub and GitLab are popular code hosting platforms that also track issues, pull requests, and commits. This skill provides guidance for fetching and analyzing data from these platforms during root cause analysis, particularly when production issues are reported via GitHub/GitLab issues.\n\n## When to Use This Skill\n\nApply this skill when:\n- Analyzing GitHub or GitLab issues reporting production problems\n- Fetching commit history for affected code\n- Using git blame to identify code authors\n- Searching repositories for error-related code\n- Correlating issues with pull requests or merges\n- Tracking who made changes related to incidents\n\n## Platform Similarities and Differences\n\nBoth GitHub and GitLab provide similar capabilities:\n- Issue tracking\n- Pull/Merge request management\n- Repository hosting\n- Commit history and blame\n- Code search\n- API access\n\n**Key differences**:\n- **GitHub**: Uses \"Pull Requests\" (PRs)\n- **GitLab**: Uses \"Merge Requests\" (MRs)\n- **API endpoints**: Different base URLs and authentication\n- **Issue references**: GitHub uses `#123`, GitLab uses `!123` for MRs\n\nThis skill covers both platforms; adapt examples to your platform of choice.\n\n## Authentication\n\n### GitHub Personal Access Token\n\nCreate token at: https://github.com/settings/tokens\n\n**Required scopes**:\n- `repo` - Full repository access (includes issues, commits, code)\n- `read:org` - Read organization data (if using org repos)\n\n**Usage in API calls**:\n```\nAuthorization: Bearer ghp_yourtoken\n```\n\n### GitLab Personal Access Token\n\nCreate token at: https://gitlab.com/-/profile/personal_access_tokens\n\n**Required scopes**:\n- `api` - Full API access\n- `read_repository` - Read repository data\n\n**Usage in API calls**:\n```\nAuthorization: Bearer glpat_yourtoken\n```\n\n**Configure in Thufir settings** (`.claude/thufir.local.md`):\n```yaml\ngithub:\n  token: \"ghp_your_token_here\"\n  default_repo: \"owner/repository\"\n\ngitlab:\n  token: \"glpat_your_token_here\"\n  default_project: \"group/project\"\n```\n\n## Working with Issues\n\n### Fetching Issue Details\n\n**GitHub API**:\n```\nGET /repos/{owner}/{repo}/issues/{issue_number}\n```\n\n**GitLab API**:\n```\nGET /projects/{id}/issues/{issue_iid}\n```\n\n### Issue Structure\n\nIssues contain:\n- **Title**: Brief description\n- **Body/Description**: Detailed description, often includes error logs\n- **Labels**: Tags like \"production\", \"incident\", \"bug\"\n- **State**: open, closed\n- **Created/Updated timestamps**\n- **Comments**: Discussion and updates\n- **Assignees**: Who's working on it\n\n### Extracting RCA Information\n\nFrom issue body, extract:\n- **Error messages**: Search for stack traces, error codes\n- **Reproduction steps**: How to trigger the issue\n- **Affected features**: Which part of the system broke\n- **Time of occurrence**: When users first noticed\n- **User impact**: How many users affected\n\n**Example parsing**:\n```\nIssue body:\n\"Users are getting 500 errors when trying to log in.\nError: ConnectionPoolExhausted at 2025-12-19 14:32 UTC\nApproximately 15,000 users affected.\"\n\nExtracted:\n- Error: ConnectionPoolExhausted\n- Time: 2025-12-19 14:32 UTC\n- Impact: 15,000 users\n- Feature: Login\n```\n\n### Filtering Issues\n\n**GitHub - List issues with labels**:\n```\nGET /repos/{owner}/{repo}/issues?labels=production,incident&state=open\n```\n\n**GitLab - List issues with labels**:\n```\nGET /projects/{id}/issues?labels=production,incident&state=opened\n```\n\n## Commit Analysis\n\n### Fetching Recent Commits\n\n**GitHub - List commits**:\n```\nGET /repos/{owner}/{repo}/commits?since=2025-12-19T00:00:00Z\n```\n\n**GitLab - List commits**:\n```\nGET /projects/{id}/repository/commits?since=2025-12-19T00:00:00Z\n```\n\n### Commit Information\n\nEach commit includes:\n- **SHA**: Unique identifier\n- **Message**: Commit description\n- **Author**: Name and email\n- **Timestamp**: When committed\n- **Files changed**: List of modified files\n- **Diff**: Changes made\n\n### Finding Relevant Commits\n\nFilter commits by:\n1. **Time range**: Commits before incident start\n2. **Files**: Commits touching affected files\n3. **Author**: Specific developer\n4. **Message content**: Keywords like \"fix\", \"update\", \"config\"\n\n### Using Git Blame\n\nGit blame identifies who last modified each line.\n\n**GitHub - Get blame**:\n```\nGET /repos/{owner}/{repo}/blame/{ref}/{path}\n```\n\n**GitLab - Get blame**:\n```\nGET /projects/{id}/repository/files/{path}/blame?ref=main\n```\n\n**Parse blame output** to find:\n- Line number\n- Commit SHA\n- Author\n- Timestamp\n- Original code\n\n**Use for RCA**:\n- Identify who changed problematic code\n- Find when change was introduced\n- Trace back to original commit\n\n## Code Search\n\n### Searching for Error Messages\n\n**GitHub - Search code**:\n```\nGET /search/code?q=ConnectionPoolExhausted+repo:owner/repo\n```\n\n**GitLab - Search in project**:\n```\nGET /projects/{id}/search?scope=blobs&search=ConnectionPoolExhausted\n```\n\n### Search Strategies\n\n**Search for error strings**:\n- Remove variable parts: `ConnectionPoolExhausted` not `ConnectionPoolExhausted: timeout=5000ms`\n- Search exact phrases with quotes: `\"Could not acquire connection\"`\n- Use AND/OR for multiple terms\n\n**Search for code patterns**:\n- Function names from stack traces\n- Class names\n- Configuration keys\n- API endpoint paths\n\n**Example RCA search workflow**:\n1. Extract error from issue: `ConnectionPoolExhausted`\n2. Search code for error string\n3. Find where error is raised\n4. Use blame to identify recent changes\n5. Review commits for root cause\n\n## Pull/Merge Request Analysis\n\n### Fetching PR/MR Details\n\n**GitHub - Get pull request**:\n```\nGET /repos/{owner}/{repo}/pulls/{pr_number}\n```\n\n**GitLab - Get merge request**:\n```\nGET /projects/{id}/merge_requests/{mr_iid}\n```\n\n### PR/MR Information\n\nIncludes:\n- **Title and description**\n- **Author**\n- **Created/merged timestamps**\n- **Files changed**\n- **Diff**: Code changes\n- **Commits**: List of commits in the PR/MR\n- **Status**: open, merged, closed\n\n### Correlating Issues with PRs/MRs\n\n**Link issues to PRs**:\n- PR descriptions often reference issues: \"Fixes #123\"\n- GitHub automatically links PRs that fix issues\n- Check if incident-related issue has linked PRs\n\n**Identify problematic merge**:\n- Find PRs merged around incident time\n- Check PRs that modified affected files\n- Review PRs from specific authors\n\n## Integration with Thufir MCP\n\nThufir provides MCP servers for GitHub and GitLab:\n\n### GitHub MCP Tools\n\n**get_issue**:\n- Fetch issue by number\n- Returns title, body, labels, timestamps\n\n**list_commits**:\n- List commits in time range\n- Filter by path, author\n\n**get_blame**:\n- Get blame for specific file\n- Identify line authors\n\n**search_code**:\n- Search repository for code patterns\n- Find error strings in codebase\n\n### GitLab MCP Tools\n\n**get_issue**:\n- Fetch issue by IID\n- Returns description, labels, timestamps\n\n**list_commits**:\n- List commits with filters\n- Since/until time range\n\n**get_blame**:\n- Get blame for file path\n- Identify code authors\n\n**search_code**:\n- Search project blobs\n- Find error patterns\n\n### Using MCP for RCA\n\n**Workflow example**:\n\n1. **Fetch issue details**:\n```\nUse MCP: github_get_issue\nParameters: issue_number=456\nResult: Issue describes login failures at 14:32 UTC\n```\n\n2. **Extract error and search code**:\n```\nUse MCP: github_search_code\nParameters: query=\"ConnectionPoolExhausted\"\nResult: Found in src/config/database.js\n```\n\n3. **Get blame for suspicious file**:\n```\nUse MCP: github_get_blame\nParameters: path=\"src/config/database.js\"\nResult: Line 45 changed by Developer X in commit abc123\n```\n\n4. **List recent commits**:\n```\nUse MCP: github_list_commits\nParameters: since=\"2025-12-19T00:00:00Z\", path=\"src/config/database.js\"\nResult: Commit abc123 at 10:15 UTC changed pool size\n```\n\n## Best Practices\n\n### Issue Analysis\n\n- Read full issue body, not just title\n- Check comments for additional context\n- Look for error logs in code blocks\n- Note timestamps in issue description\n- Check for related/duplicate issues\n\n### Commit Investigation\n\n- Focus on commits in time window before incident\n- Prioritize commits to affected files\n- Read commit messages for clues\n- Review full diffs, not just summaries\n- Check for configuration changes\n\n### Code Search\n\n- Start with exact error strings\n- Broaden search if no results\n- Use repo/project scoping\n- Search in relevant file paths\n- Check multiple branches if needed\n\n### Blame Usage\n\n- Blame specific suspicious lines\n- Don't blame entire files (too much data)\n- Cross-reference with commit history\n- Correlate blame timestamps with incident timeline\n- Use blame to find commit, then review commit details\n\n## Common Patterns\n\n### Pattern 1: Issue Reports Production Error\n\n1. Fetch issue via MCP\n2. Extract error message from body\n3. Search code for error string\n4. Use blame on file containing error\n5. Review recent commits to that file\n6. Identify root cause commit\n\n### Pattern 2: Deployment Caused Issue\n\n1. List commits merged around deployment time\n2. Review PRs merged just before deployment\n3. Check files changed in those PRs\n4. Correlate changed files with error location\n5. Identify problematic PR/commit\n\n### Pattern 3: Configuration Change\n\n1. Search for config files in recent commits\n2. Use `git diff` to see what changed\n3. Identify configuration value changes\n4. Correlate config change with incident symptoms\n5. Validate hypothesis with evidence\n\n## Integration with Other Skills\n\nThis skill works with:\n- **root-cause-analysis skill**: Provides evidence from GitHub/GitLab\n- **git-investigation skill**: Deep git analysis using local repository\n- **prometheus-analysis skill**: Correlate issue timestamps with metrics\n- **RCA agent**: Agent orchestrates API calls to gather issue data\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed API patterns and examples:\n- **`references/api-examples.md`** - Complete API call examples for common scenarios\n\n## Quick Reference\n\n**GitHub**:\n- Base URL: `https://api.github.com`\n- Auth: `Authorization: Bearer ghp_token`\n- Issues: `/repos/{owner}/{repo}/issues/{number}`\n- Commits: `/repos/{owner}/{repo}/commits`\n- Blame: `/repos/{owner}/{repo}/blame/{ref}/{path}`\n- Search: `/search/code?q=query+repo:owner/repo`\n\n**GitLab**:\n- Base URL: `https://gitlab.com/api/v4`\n- Auth: `Authorization: Bearer glpat_token`\n- Issues: `/projects/{id}/issues/{iid}`\n- Commits: `/projects/{id}/repository/commits`\n- Blame: `/projects/{id}/repository/files/{path}/blame`\n- Search: `/projects/{id}/search?scope=blobs&search=query`\n\n**Workflow**: Issue → Error → Search → Blame → Commits → Root Cause\n\n---\n\nUse GitHub and GitLab APIs to gather comprehensive incident context, correlate issues with code changes, and identify specific commits that introduced problems."
              },
              {
                "name": "Prometheus Analysis",
                "description": "This skill should be used when the user asks to \"query Prometheus\", \"analyze Prometheus metrics\", \"check Prometheus alerts\", \"write PromQL\", \"interpret Prometheus data\", \"fetch metrics\", or mentions Prometheus querying, alerting, or metrics analysis. Provides guidance for querying and interpreting Prometheus metrics for root cause analysis.",
                "path": "skills/prometheus-analysis/SKILL.md",
                "frontmatter": {
                  "name": "Prometheus Analysis",
                  "description": "This skill should be used when the user asks to \"query Prometheus\", \"analyze Prometheus metrics\", \"check Prometheus alerts\", \"write PromQL\", \"interpret Prometheus data\", \"fetch metrics\", or mentions Prometheus querying, alerting, or metrics analysis. Provides guidance for querying and interpreting Prometheus metrics for root cause analysis.",
                  "version": "0.1.0"
                },
                "content": "# Prometheus Analysis\n\n## Overview\n\nPrometheus is a time-series metrics collection and alerting system widely used for monitoring production systems. This skill provides guidance for querying Prometheus metrics, interpreting alert data, and using metrics for root cause analysis.\n\n## When to Use This Skill\n\nApply this skill when:\n- Analyzing Prometheus alerts that have fired\n- Querying metrics to understand system behavior\n- Investigating metric anomalies or spikes\n- Correlating metrics with incidents\n- Writing PromQL queries for specific metrics\n- Interpreting time-series data patterns\n\n## Prometheus Fundamentals\n\n### Metric Types\n\n**Counter**: Cumulative value that only increases (e.g., total requests, error count)\n- Use `rate()` or `increase()` to get per-second rate or total increase\n- Example: `http_requests_total`\n\n**Gauge**: Value that can go up or down (e.g., CPU usage, memory usage, queue depth)\n- Query directly or use functions like `avg_over_time()`\n- Example: `node_memory_usage_bytes`\n\n**Histogram**: Distribution of values in buckets (e.g., request durations)\n- Provides `_sum`, `_count`, and `_bucket` metrics\n- Use for percentile calculations\n- Example: `http_request_duration_seconds`\n\n**Summary**: Similar to histogram but with pre-calculated quantiles\n- Example: `http_request_duration_seconds{quantile=\"0.95\"}`\n\n### Time Series Format\n\nMetrics have format: `metric_name{label1=\"value1\", label2=\"value2\"}`\n\nExample: `http_requests_total{method=\"POST\", status=\"500\", service=\"api\"}`\n\n## Querying Prometheus\n\n### Basic Queries\n\n**Instant query** (current value):\n```promql\nhttp_requests_total\n```\n\n**Range query** (over time):\n```promql\nhttp_requests_total[5m]\n```\n\n**Filter by labels**:\n```promql\nhttp_requests_total{status=\"500\", service=\"api\"}\n```\n\n**Rate of increase** (per-second rate):\n```promql\nrate(http_requests_total[5m])\n```\n\n### Common Aggregation Functions\n\n**Sum** across dimensions:\n```promql\nsum(rate(http_requests_total[5m])) by (status)\n```\n\n**Average**:\n```promql\navg(node_memory_usage_bytes) by (instance)\n```\n\n**Max/Min**:\n```promql\nmax(http_request_duration_seconds) by (endpoint)\n```\n\n**Count**:\n```promql\ncount(up == 0)  # Count instances that are down\n```\n\n### Useful RCA Queries\n\n**Error rate percentage**:\n```promql\nsum(rate(http_requests_total{status=~\"5..\"}[5m])) /\nsum(rate(http_requests_total[5m])) * 100\n```\n\n**95th percentile latency**:\n```promql\nhistogram_quantile(0.95,\n  rate(http_request_duration_seconds_bucket[5m])\n)\n```\n\n**Request rate by endpoint**:\n```promql\nsum(rate(http_requests_total[5m])) by (endpoint)\n```\n\n**Memory usage percentage**:\n```promql\n(node_memory_usage_bytes / node_memory_total_bytes) * 100\n```\n\n**Database connection pool usage**:\n```promql\nsum(db_connection_pool_active) / sum(db_connection_pool_max) * 100\n```\n\n## Working with Alerts\n\n### Alert Structure\n\nPrometheus alerts contain:\n- **Alert name**: Identifier for the alert rule\n- **Labels**: Dimensions and metadata (service, severity, etc.)\n- **Annotations**: Human-readable descriptions\n- **State**: pending, firing, resolved\n- **Active since**: When alert started firing\n- **Value**: Current metric value that triggered alert\n\n### Fetching Alert Details\n\nUse Prometheus API to fetch alerts:\n\n**List active alerts**:\n```\nGET /api/v1/alerts\n```\n\n**Query alert rule**:\n```\nGET /api/v1/rules\n```\n\n### Analyzing Alert Context\n\nWhen investigating an alert:\n\n1. **Check alert expression**: What PromQL query triggered the alert?\n2. **Review threshold**: What value caused the alert to fire?\n3. **Check alert duration**: How long has condition been true?\n4. **Review labels**: What services/instances are affected?\n5. **Query related metrics**: Get broader context around the alert\n\n### Example Alert Investigation\n\nAlert: `HighErrorRate`\nExpression: `rate(http_requests_total{status=~\"5..\"}[5m]) > 0.05`\n\n**Investigation queries**:\n\nQuery error rate breakdown:\n```promql\nrate(http_requests_total{status=~\"5..\"}[5m]) by (endpoint)\n```\n\nQuery total request rate:\n```promql\nrate(http_requests_total[5m])\n```\n\nQuery error rate percentage:\n```promql\n(sum(rate(http_requests_total{status=~\"5..\"}[5m])) /\n sum(rate(http_requests_total[5m]))) * 100\n```\n\nCheck for correlated latency increase:\n```promql\nhistogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n```\n\n## Metrics Patterns for RCA\n\n### Pattern 1: Sudden Spike\n\n**Signature**: Metric jumps sharply at specific time\n\n**Possible causes**:\n- Code deployment\n- Configuration change\n- Traffic surge\n- Dependency failure\n\n**Investigation**:\n- Correlate spike time with deployments\n- Check for sudden traffic increase\n- Query dependency health metrics\n- Review recent configuration changes\n\n### Pattern 2: Gradual Increase\n\n**Signature**: Metric grows steadily over hours/days\n\n**Possible causes**:\n- Memory leak\n- Resource exhaustion\n- Unbounded data growth\n- Missing cleanup job\n\n**Investigation**:\n- Check memory/disk usage trends\n- Review data volume growth\n- Query for resource leaks\n- Check scheduled job execution\n\n### Pattern 3: Periodic Pattern\n\n**Signature**: Metric spikes at regular intervals\n\n**Possible causes**:\n- Scheduled job or cron\n- Batch processing\n- Cache expiration\n- Garbage collection\n\n**Investigation**:\n- Identify period (hourly, daily, etc.)\n- Check for scheduled tasks at that interval\n- Review batch job schedules\n- Query job execution metrics\n\n### Pattern 4: Drop to Zero\n\n**Signature**: Metric suddenly drops to zero or very low value\n\n**Possible causes**:\n- Service crash\n- Instance termination\n- Network partition\n- Monitoring failure\n\n**Investigation**:\n- Check service health (`up` metric)\n- Review instance count\n- Query service availability\n- Check for infrastructure changes\n\n### Pattern 5: High Variability\n\n**Signature**: Metric fluctuates wildly\n\n**Possible causes**:\n- Intermittent errors\n- Race condition\n- Resource contention\n- Unhealthy load balancing\n\n**Investigation**:\n- Check error logs for patterns\n- Review load distribution across instances\n- Query resource utilization\n- Check for concurrency issues\n\n## Time Range Selection\n\nChoose appropriate time ranges for investigation:\n\n**Incident detection** (5-15 minutes):\n```promql\nrate(metric[5m])\n```\n\n**Trend analysis** (1-6 hours):\n```promql\nrate(metric[1h])\n```\n\n**Long-term patterns** (1-7 days):\n```promql\navg_over_time(metric[1d])\n```\n\n**Comparison with past**:\n```promql\n# Current value\nmetric\n\n# Value 1 week ago\nmetric offset 1w\n```\n\n## Correlating Metrics\n\n### Multiple Metric Analysis\n\nQuery related metrics together to understand full context:\n\n```promql\n# Error rate\nrate(http_requests_total{status=~\"5..\"}[5m])\n\n# Latency\nhistogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n\n# Request rate\nrate(http_requests_total[5m])\n\n# CPU usage\nrate(process_cpu_seconds_total[5m])\n\n# Memory usage\nprocess_resident_memory_bytes\n```\n\n### Identifying Correlations\n\nLook for metrics that change together:\n- Error rate ↑ + Latency ↑ → Performance degradation\n- Error rate ↑ + CPU ↑ → Resource exhaustion\n- Error rate ↑ + Request rate ↑ → Traffic surge\n- Error rate ↑ + Dependency metric ↓ → Dependency failure\n\n## Best Practices\n\n### Query Writing\n\n- Use appropriate time ranges (5m for recent, 1h for trends)\n- Filter by relevant labels to reduce cardinality\n- Use `rate()` for counters, not raw values\n- Aggregate when dealing with multiple instances\n- Use recording rules for expensive queries\n\n### Alert Investigation\n\n- Start with alert expression to understand trigger\n- Query wider time range to see pattern before/after\n- Break down aggregated metrics to find specific instances/endpoints\n- Check for correlated metric changes\n- Compare current values with historical baseline\n\n### Metric Interpretation\n\n- Consider metric type (counter, gauge, histogram)\n- Look for patterns over time, not just current values\n- Compare across instances to find outliers\n- Correlate with other metrics for complete picture\n- Validate hypotheses with multiple metrics\n\n## Integration with Thufir\n\nThis skill works with:\n- **Prometheus MCP server**: Fetches alerts and queries metrics via API\n- **root-cause-analysis skill**: Metrics provide evidence for RCA\n- **RCA agent**: Agent queries Prometheus to gather metric data\n\n### Using Prometheus MCP\n\nThe Thufir plugin includes Prometheus MCP server for querying:\n\n**Query instant value**:\n```\nUse MCP tool: prometheus_query\nQuery: rate(http_requests_total[5m])\n```\n\n**Query time range**:\n```\nUse MCP tool: prometheus_query_range\nQuery: rate(http_requests_total[5m])\nStart: 2025-12-19T14:00:00Z\nEnd: 2025-12-19T15:00:00Z\nStep: 15s\n```\n\n**Fetch active alerts**:\n```\nUse MCP tool: prometheus_alerts\n```\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed PromQL patterns and advanced queries:\n- **`references/promql-cookbook.md`** - Common PromQL queries for RCA scenarios\n\n## Quick Reference\n\n**Error rate**: `rate(http_requests_total{status=~\"5..\"}[5m])`\n**Latency p95**: `histogram_quantile(0.95, rate(duration_bucket[5m]))`\n**CPU usage**: `rate(process_cpu_seconds_total[5m])`\n**Memory**: `process_resident_memory_bytes`\n**Request rate**: `rate(http_requests_total[5m])`\n\n**Time ranges**: 5m (instant), 1h (trend), 1d (baseline)\n**Aggregations**: `sum`, `avg`, `max`, `min`, `count`\n**Filters**: `{label=\"value\"}`, `{label=~\"regex\"}`\n\n---\n\nUse Prometheus metrics to provide objective, time-series evidence for root cause analysis. Correlate metrics with code changes and system events to identify precise incident causes."
              },
              {
                "name": "Root Cause Analysis Methodology",
                "description": "This skill should be used when the user asks to \"perform root cause analysis\", \"investigate production issue\", \"analyze incident\", \"find root cause\", \"debug production error\", \"trace the cause\", or mentions investigating production problems, alerts, or outages. Provides systematic RCA methodology and investigation workflows.",
                "path": "skills/root-cause-analysis/SKILL.md",
                "frontmatter": {
                  "name": "Root Cause Analysis Methodology",
                  "description": "This skill should be used when the user asks to \"perform root cause analysis\", \"investigate production issue\", \"analyze incident\", \"find root cause\", \"debug production error\", \"trace the cause\", or mentions investigating production problems, alerts, or outages. Provides systematic RCA methodology and investigation workflows.",
                  "version": "0.1.0"
                },
                "content": "# Root Cause Analysis Methodology\n\n## Overview\n\nRoot cause analysis (RCA) is a systematic investigation process to identify the underlying cause of production incidents, errors, and outages. This skill provides structured methodologies for conducting effective RCA that goes beyond surface-level symptoms to find actionable root causes.\n\n## When to Use This Skill\n\nApply this skill when:\n- Production alerts fire indicating system degradation\n- Users report errors or unexpected behavior\n- Incidents occur requiring post-mortem investigation\n- Metrics show anomalous patterns\n- Any situation requiring systematic debugging of production issues\n\n## Core RCA Principles\n\n### 1. Timeline Reconstruction\n\nEstablish a clear timeline of events:\n- Identify when the issue first appeared (error logs, metrics, user reports)\n- Note when alerts fired or detection occurred\n- Map recent changes (deployments, configuration changes, infrastructure changes)\n- Identify when the issue resolved (if applicable)\n\nCreate a visual timeline connecting:\n- **WHEN**: Timestamps of key events\n- **WHAT**: What changed or broke at each point\n- **WHERE**: Which systems, services, or components were affected\n\n### 2. Symptom vs. Root Cause\n\nDistinguish between symptoms and root causes:\n\n**Symptoms** are observable effects:\n- \"API returning 500 errors\"\n- \"Database queries timing out\"\n- \"Memory usage at 95%\"\n\n**Root causes** are underlying reasons:\n- \"Connection pool exhausted due to size reduction in deployment\"\n- \"Missing database index causing full table scans\"\n- \"Memory leak introduced in commit abc123\"\n\nAlways trace from symptoms to root causes by asking \"why?\" repeatedly.\n\n### 3. The Five Whys Technique\n\nAsk \"why?\" five times to drill down from symptom to root cause:\n\n**Example:**\n1. **Why** are users seeing errors? → API is returning 500s\n2. **Why** is API returning 500s? → Database queries are timing out\n3. **Why** are queries timing out? → Connection pool is exhausted\n4. **Why** is connection pool exhausted? → Pool size was reduced from 100 to 10\n5. **Why** was pool size reduced? → Deployment of commit abc123 changed configuration\n\nRoot cause: Configuration change in commit abc123 reduced pool size inappropriately.\n\n### 4. Data-Driven Investigation\n\nBase conclusions on evidence:\n- **Metrics**: Error rates, latency percentiles, resource utilization\n- **Logs**: Error messages, stack traces, debug output\n- **Code**: Recent commits, blame information, diff analysis\n- **Configuration**: Recent changes to config files, environment variables\n- **Infrastructure**: Deployment logs, scaling events, resource changes\n\nAvoid speculation—validate hypotheses with data.\n\n## RCA Investigation Workflow\n\n### Step 1: Gather Initial Information\n\nCollect the triggering incident data:\n- Alert details (name, severity, time, affected systems)\n- Error messages and stack traces\n- Relevant metrics (error rates, latency, resource usage)\n- User reports or issue descriptions\n\n### Step 2: Establish Scope and Impact\n\nDetermine:\n- **Scope**: Which services, endpoints, or features are affected?\n- **Severity**: How many users impacted? Revenue impact?\n- **Duration**: When did it start? Is it ongoing?\n- **Frequency**: One-time or recurring issue?\n\n### Step 3: Build Timeline of Events\n\nConstruct chronological timeline:\n1. Query metrics to find when anomaly started\n2. Identify recent deployments or changes before incident\n3. Note when alerts fired\n4. Map any correlated events (scaling, traffic spikes, dependency failures)\n\n### Step 4: Search Codebase for Related Code\n\nIdentify relevant code:\n- Search for error messages in logs\n- Find files/functions mentioned in stack traces\n- Locate services or components mentioned in alerts\n- Use grep to find error-handling code, API endpoints, database queries\n\nFocus on:\n- Entry points (API endpoints, event handlers)\n- Data access layer (database queries, cache operations)\n- External integrations (third-party APIs, message queues)\n\n### Step 5: Analyze Recent Changes\n\nUse git to find recent changes to relevant code:\n- **git log**: Recent commits to affected files\n- **git blame**: Who changed specific lines and when\n- **git diff**: What changed between working and broken versions\n- **git bisect**: Binary search to find breaking commit (for regressions)\n\nPrioritize commits made shortly before incident started.\n\n### Step 6: Correlate Changes with Timeline\n\nConnect code changes to incident timeline:\n- Did deployment coincide with error spike?\n- Was configuration changed near incident start?\n- Did dependency update introduce regression?\n\nLook for temporal correlation between changes and symptoms.\n\n### Step 7: Identify Root Cause\n\nSynthesize findings to pinpoint root cause:\n- What specific code, configuration, or infrastructure change caused symptoms?\n- Why did this change cause the problem?\n- What assumption or validation was missing?\n\nEnsure root cause is:\n- **Specific**: Not \"the code is buggy\" but \"missing null check in function X\"\n- **Actionable**: Can be fixed with specific changes\n- **Validated**: Supported by evidence (metrics, logs, code)\n\n### Step 8: Verify Root Cause Hypothesis\n\nValidate the identified root cause:\n- Confirm timeline alignment (change introduced before symptoms appeared)\n- Check if reverting change would resolve issue\n- Look for similar patterns in logs or metrics\n- Test hypothesis in staging environment if possible\n\n### Step 9: Document Findings\n\nCreate RCA report including:\n- **Summary**: One-paragraph overview of incident and root cause\n- **Timeline**: Chronological event sequence\n- **Root Cause**: Specific code/config change that caused issue\n- **Impact**: Scope, severity, duration, affected users\n- **Evidence**: Metrics, logs, commits supporting conclusion\n- **Suggested Fix**: How to resolve and prevent recurrence\n\nSee `examples/rca-report-template.md` for report structure.\n\n## Investigation Techniques\n\n### Searching for Error Patterns\n\nWhen analyzing error messages:\n1. Extract key terms from error message (excluding variable values)\n2. Search codebase for error string\n3. Find where error is raised or logged\n4. Trace backwards to identify trigger conditions\n\n**Example:**\nError: `ConnectionPoolExhausted: Could not acquire connection within timeout`\n\nSearch for: `ConnectionPoolExhausted` or `Could not acquire connection`\nFind: Connection pool configuration and usage\nTrace: Recent changes to pool size or connection usage patterns\n\n### Using Git Blame Effectively\n\nGit blame identifies when lines were last changed:\n```bash\ngit blame path/to/file.js\n```\n\nFocus on:\n- Lines mentioned in stack traces\n- Configuration values that seem incorrect\n- Error-handling code paths\n- Recently changed lines (within incident timeframe)\n\nCross-reference blame timestamps with incident timeline.\n\n### Analyzing Metrics Patterns\n\nLook for metric patterns indicating root cause:\n- **Sudden spike**: Deployment, configuration change, traffic surge\n- **Gradual increase**: Memory leak, resource exhaustion, unbounded growth\n- **Periodic pattern**: Cron job, scheduled task, batch process\n- **Correlation**: Multiple metrics changing together (cause and effect)\n\nCompare metrics before, during, and after incident.\n\n### Dependency Analysis\n\nConsider dependencies that could cause issues:\n- Third-party API failures or slowdowns\n- Database performance degradation\n- Message queue backlogs\n- Infrastructure resource constraints\n- Network issues or DNS resolution failures\n\nCheck dependency health metrics and status pages.\n\n## Common Root Cause Categories\n\n### Code Changes\n- New bugs introduced in recent commits\n- Logic errors in conditionals or loops\n- Missing error handling or validation\n- Resource leaks (memory, connections, file handles)\n- Race conditions or concurrency issues\n\n### Configuration Changes\n- Incorrect values (pool sizes, timeouts, limits)\n- Missing required configuration\n- Environment variable changes\n- Feature flag toggles\n\n### Infrastructure Changes\n- Scaling events (too few or too many instances)\n- Resource limits (CPU, memory, disk)\n- Network configuration changes\n- Load balancer settings\n\n### Dependency Changes\n- Library or framework version updates\n- Third-party API changes or outages\n- Database schema migrations\n- Message queue or cache issues\n\n### Data Issues\n- Unexpected data volumes (traffic spikes)\n- Malformed data triggering edge cases\n- Data migration problems\n- Schema changes breaking assumptions\n\n## Best Practices\n\n### Do:\n- Start with evidence (metrics, logs, errors)\n- Build clear timeline before theorizing\n- Use Five Whys to drill down from symptoms\n- Validate hypotheses with data\n- Focus on specific, actionable root causes\n- Document findings thoroughly\n\n### Don't:\n- Jump to conclusions without evidence\n- Stop at symptoms (\"database is slow\" isn't a root cause)\n- Blame individuals (focus on systems and processes)\n- Ignore timeline correlations\n- Leave findings undocumented\n\n## Integration with Thufir Tools\n\nThis skill works in conjunction with:\n- **prometheus-analysis skill**: Query and interpret Prometheus metrics\n- **platform-integration skill**: Fetch GitHub/GitLab issues and commits\n- **git-investigation skill**: Use git tools for detailed code analysis\n- **RCA agent**: Autonomous investigation from alert to report\n\nThe RCA agent orchestrates these skills to perform end-to-end investigation.\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and advanced techniques:\n- **`references/rca-patterns.md`** - Common incident patterns and solutions\n- **`references/investigation-checklist.md`** - Step-by-step investigation checklist\n\n### Example Files\n\nWorking examples in `examples/`:\n- **`rca-report-template.md`** - Standard RCA report format\n\n## Quick Reference\n\n**Five Whys**: Ask \"why?\" five times to find root cause\n**Timeline**: Map when issue started, what changed, when detected\n**Evidence**: Metrics + Logs + Code + Config changes\n**Root Cause**: Specific, actionable, validated cause (not symptom)\n**Report**: Summary, timeline, root cause, evidence, fix\n\n---\n\nApply this systematic methodology to transform vague production issues into clear, actionable root causes supported by evidence."
              }
            ]
          }
        ]
      }
    }
  ]
}