{
  "owner": {
    "id": "Shakes-tzd",
    "display_name": "Thandolwethu Shakes Dlamini",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/73035602?u=802985f810fb17928707ea91b4ad6fefea3687b2&v=4",
    "url": "https://github.com/Shakes-tzd",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 7,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "Shakes-tzd/contextune",
      "url": "https://github.com/Shakes-tzd/contextune",
      "description": "Precision-tuned context engineering for Claude Code. Optimize context flow with modular plans (95% fewer tokens), parallel workflows (81% cost reduction), and zero-transformation architecture.",
      "homepage": "https://shakes-tzd.github.io/contextune/",
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2025-12-23T22:19:12Z",
        "created_at": "2025-10-14T21:47:26Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": ".analysis/CONVERSATION_FLOW_ARCHITECTURE.md",
          "type": "blob",
          "size": 18365
        },
        {
          "path": ".analysis/SUB_AGENT_STORAGE_ARCHITECTURE.md",
          "type": "blob",
          "size": 14649
        },
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1455
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 1100
        },
        {
          "path": ".contextune-config.yaml",
          "type": "blob",
          "size": 773
        },
        {
          "path": ".env.example",
          "type": "blob",
          "size": 180
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 1217
        },
        {
          "path": ".htmlgraph",
          "type": "tree",
          "size": null
        },
        {
          "path": ".htmlgraph/agents.json",
          "type": "blob",
          "size": 1391
        },
        {
          "path": ".htmlgraph/events",
          "type": "tree",
          "size": null
        },
        {
          "path": ".htmlgraph/events/.gitkeep",
          "type": "blob",
          "size": null
        },
        {
          "path": ".htmlgraph/events/sess-494cb836.jsonl",
          "type": "blob",
          "size": 1084
        },
        {
          "path": ".htmlgraph/events/sess-66b63aba.jsonl",
          "type": "blob",
          "size": 571871
        },
        {
          "path": ".htmlgraph/features",
          "type": "tree",
          "size": null
        },
        {
          "path": ".htmlgraph/features/feat-3e7e6183.html",
          "type": "blob",
          "size": 900500
        },
        {
          "path": ".htmlgraph/features/feat-4cec1d2e.html",
          "type": "blob",
          "size": 3615
        },
        {
          "path": ".htmlgraph/features/feat-c34238da.html",
          "type": "blob",
          "size": 9323
        },
        {
          "path": ".htmlgraph/features/spike-20251223090227.html",
          "type": "blob",
          "size": 1545
        },
        {
          "path": ".htmlgraph/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".htmlgraph/hooks/post-checkout.sh",
          "type": "blob",
          "size": 615
        },
        {
          "path": ".htmlgraph/hooks/post-commit.sh",
          "type": "blob",
          "size": 511
        },
        {
          "path": ".htmlgraph/hooks/post-merge.sh",
          "type": "blob",
          "size": 541
        },
        {
          "path": ".htmlgraph/hooks/pre-commit.sh",
          "type": "blob",
          "size": 2466
        },
        {
          "path": ".htmlgraph/hooks/pre-push.sh",
          "type": "blob",
          "size": 660
        },
        {
          "path": ".htmlgraph/parent-activity.json",
          "type": "blob",
          "size": 89
        },
        {
          "path": ".htmlgraph/sessions",
          "type": "tree",
          "size": null
        },
        {
          "path": ".htmlgraph/sessions/sess-494cb836.html",
          "type": "blob",
          "size": 1973
        },
        {
          "path": ".htmlgraph/sessions/sess-66b63aba.html",
          "type": "blob",
          "size": 26114
        },
        {
          "path": ".htmlgraph/styles.css",
          "type": "blob",
          "size": 7135
        },
        {
          "path": ".mcp.json",
          "type": "blob",
          "size": 125
        },
        {
          "path": ".plans",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/ARCHITECTURE_IMPROVEMENTS_v0.5.1.md",
          "type": "blob",
          "size": 21276
        },
        {
          "path": ".plans/CONFIGURE_COMMAND_SPEC.md",
          "type": "blob",
          "size": 11067
        },
        {
          "path": ".plans/CONTEXT_GROUNDED_RESEARCH.md",
          "type": "blob",
          "size": 17823
        },
        {
          "path": ".plans/ENHANCED_WORKFLOW_ARCHITECTURE.md",
          "type": "blob",
          "size": 21265
        },
        {
          "path": ".plans/IMPLEMENTATION_PLAN_v0.5.0.md",
          "type": "blob",
          "size": 27237
        },
        {
          "path": ".plans/WORKFLOW_IMPROVEMENT_PLAN.md",
          "type": "blob",
          "size": 14996
        },
        {
          "path": ".plans/contextune-documentation-workflow-review",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/contextune-documentation-workflow-review/design.md",
          "type": "blob",
          "size": 12314
        },
        {
          "path": ".plans/decision-tracking-system",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/decision-tracking-system/AUTOMATED_CONTEXT_PRESERVATION.md",
          "type": "blob",
          "size": 13956
        },
        {
          "path": ".plans/decision-tracking-system/CHECKPOINT_PATTERN.md",
          "type": "blob",
          "size": 9084
        },
        {
          "path": ".plans/decision-tracking-system/COMPLETE_IMPLEMENTATION.md",
          "type": "blob",
          "size": 23074
        },
        {
          "path": ".plans/decision-tracking-system/CONTEXT_PRESERVING_OUTPUT_STYLE.md",
          "type": "blob",
          "size": 5159
        },
        {
          "path": ".plans/decision-tracking-system/DRY_CONTEXT_ARCHITECTURE.md",
          "type": "blob",
          "size": 13676
        },
        {
          "path": ".plans/decision-tracking-system/FINAL_ARCHITECTURE_SUMMARY.md",
          "type": "blob",
          "size": 11009
        },
        {
          "path": ".plans/decision-tracking-system/IMPLEMENTATION_SUMMARY.md",
          "type": "blob",
          "size": 10199
        },
        {
          "path": ".plans/decision-tracking-system/OUTPUT_STYLE_FOR_EXTRACTION.md",
          "type": "blob",
          "size": 11503
        },
        {
          "path": ".plans/decision-tracking-system/README.md",
          "type": "blob",
          "size": 7621
        },
        {
          "path": ".plans/decision-tracking-system/SCRIPT_DISCOVERY_SYSTEM.md",
          "type": "blob",
          "size": 8696
        },
        {
          "path": ".plans/decision-tracking-system/TOOL_CALL_TOKEN_ANALYSIS.md",
          "type": "blob",
          "size": 16279
        },
        {
          "path": ".plans/decision-tracking-system/WRITE_TOOL_VS_EXTRACTION_ANALYSIS.md",
          "type": "blob",
          "size": 19345
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/PLAN_FULL.md",
          "type": "blob",
          "size": 11879
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/plan.yaml",
          "type": "blob",
          "size": 3536
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/scripts/generate_full.sh",
          "type": "blob",
          "size": 1320
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/tasks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/tasks/task-0.md",
          "type": "blob",
          "size": 2399
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/tasks/task-1.md",
          "type": "blob",
          "size": 2165
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/tasks/task-2.md",
          "type": "blob",
          "size": 2041
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/tasks/task-3.md",
          "type": "blob",
          "size": 2142
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/tasks/task-4.md",
          "type": "blob",
          "size": 2542
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/decision-tracking-system/parallel-plan/templates/task-template.md",
          "type": "blob",
          "size": 1107
        },
        {
          "path": ".plans/decision-tracking-system/plan.yaml",
          "type": "blob",
          "size": 7434
        },
        {
          "path": ".plans/decision-tracking-system/tasks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/decision-tracking-system/tasks/task-1.md",
          "type": "blob",
          "size": 13370
        },
        {
          "path": ".plans/decision-tracking-system/unified-tracking-plan.yaml",
          "type": "blob",
          "size": 1608
        },
        {
          "path": ".plans/hybrid-subscription",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/hybrid-subscription/design.md",
          "type": "blob",
          "size": 6617
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati/design.md",
          "type": "blob",
          "size": 16778
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati/tasks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati/tasks/task-0.md",
          "type": "blob",
          "size": 155
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati/tasks/task-1.md",
          "type": "blob",
          "size": 153
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati/tasks/task-2.md",
          "type": "blob",
          "size": 147
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati/tasks/task-3.md",
          "type": "blob",
          "size": 170
        },
        {
          "path": ".plans/implementation-plan-contextune-htmlgraph-integrati/tasks/task-4.md",
          "type": "blob",
          "size": 183
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da/design.md",
          "type": "blob",
          "size": 5500
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da/tasks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da/tasks/task-1.md",
          "type": "blob",
          "size": 236
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da/tasks/task-2.md",
          "type": "blob",
          "size": 238
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da/tasks/task-3.md",
          "type": "blob",
          "size": 239
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da/tasks/task-4.md",
          "type": "blob",
          "size": 223
        },
        {
          "path": ".plans/implementation-plan-htmlgraph-session-analytics-da/tasks/task-5.md",
          "type": "blob",
          "size": 233
        },
        {
          "path": ".plans/intent-driven-mcp-loading.md",
          "type": "blob",
          "size": 20654
        },
        {
          "path": ".python-version",
          "type": "blob",
          "size": 5
        },
        {
          "path": "ASKUSERQUESTION_INTEGRATION.md",
          "type": "blob",
          "size": 18441
        },
        {
          "path": "CHANGELOG.md",
          "type": "blob",
          "size": 29443
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 18993
        },
        {
          "path": "COST_OPTIMIZATION_ANALYSIS.md",
          "type": "blob",
          "size": 11824
        },
        {
          "path": "CTX_IMPROVE_CONCEPT.md",
          "type": "blob",
          "size": 16535
        },
        {
          "path": "EXECUTION_ANALYSIS_AND_FIX_PLAN.md",
          "type": "blob",
          "size": 26876
        },
        {
          "path": "IMPLEMENTATION_SUMMARY_v0.4.0.md",
          "type": "blob",
          "size": 12436
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1071
        },
        {
          "path": "MIGRATION.md",
          "type": "blob",
          "size": 7868
        },
        {
          "path": "OutputStyles.md",
          "type": "blob",
          "size": 10173
        },
        {
          "path": "PLUGIN_ARCHITECTURE.md",
          "type": "blob",
          "size": 9213
        },
        {
          "path": "PLUGIN_IMPROVEMENTS.md",
          "type": "blob",
          "size": 28710
        },
        {
          "path": "PUBLISHING.md",
          "type": "blob",
          "size": 8895
        },
        {
          "path": "QUICKSTART_SKILLS.md",
          "type": "blob",
          "size": 4760
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 22048
        },
        {
          "path": "SESSION_SUMMARY_2025-10-27.md",
          "type": "blob",
          "size": 18298
        },
        {
          "path": "ToolRouterPlan.md",
          "type": "blob",
          "size": 28098
        },
        {
          "path": "ULTRA_THINKING_AGENT_STRATEGY.md",
          "type": "blob",
          "size": 19065
        },
        {
          "path": "UNIFIED_DRY_STRATEGY.md",
          "type": "blob",
          "size": 6730
        },
        {
          "path": "WARP.md",
          "type": "blob",
          "size": 9
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/issue-orchestrator.md",
          "type": "blob",
          "size": 19887
        },
        {
          "path": "agents/parallel-task-executor.md",
          "type": "blob",
          "size": 11263
        },
        {
          "path": "agents/performance-analyzer.md",
          "type": "blob",
          "size": 20824
        },
        {
          "path": "agents/test-runner.md",
          "type": "blob",
          "size": 21551
        },
        {
          "path": "agents/worktree-manager.md",
          "type": "blob",
          "size": 16919
        },
        {
          "path": "cli-orchestrator-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-orchestrator-design/CLI_ORCHESTRATION_ANALYSIS.md",
          "type": "blob",
          "size": 17088
        },
        {
          "path": "cli-orchestrator-design/CLI_ORCHESTRATION_DECISION.md",
          "type": "blob",
          "size": 12420
        },
        {
          "path": "cli-orchestrator-test",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-orchestrator-test/parallel_cli_test.sh",
          "type": "blob",
          "size": 9005
        },
        {
          "path": "cli-orchestrator-test/results",
          "type": "tree",
          "size": null
        },
        {
          "path": "cli-orchestrator-test/results/claude_20251027_161002.json",
          "type": "blob",
          "size": 3979
        },
        {
          "path": "cli-orchestrator-test/results/claude_20251027_161002.time",
          "type": "blob",
          "size": 13
        },
        {
          "path": "cli-orchestrator-test/results/codex_20251027_161002.json",
          "type": "blob",
          "size": 34
        },
        {
          "path": "cli-orchestrator-test/results/codex_20251027_161002.time",
          "type": "blob",
          "size": 11
        },
        {
          "path": "cli-orchestrator-test/results/codex_manual_test.txt",
          "type": "blob",
          "size": 1892
        },
        {
          "path": "cli-orchestrator-test/results/copilot_20251027_161002.json",
          "type": "blob",
          "size": 1506
        },
        {
          "path": "cli-orchestrator-test/results/copilot_20251027_161002.time",
          "type": "blob",
          "size": 13
        },
        {
          "path": "cli-orchestrator-test/results/gemini_20251027_161002.json",
          "type": "blob",
          "size": 2220
        },
        {
          "path": "cli-orchestrator-test/results/gemini_20251027_161002.time",
          "type": "blob",
          "size": 13
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/contextune-config.md",
          "type": "blob",
          "size": 5655
        },
        {
          "path": "commands/contextune-usage.md",
          "type": "blob",
          "size": 6419
        },
        {
          "path": "commands/ctx-cleanup.md",
          "type": "blob",
          "size": 5812
        },
        {
          "path": "commands/ctx-configure.md",
          "type": "blob",
          "size": 9223
        },
        {
          "path": "commands/ctx-configure.py",
          "type": "blob",
          "size": 15761
        },
        {
          "path": "commands/ctx-dashboard.py",
          "type": "blob",
          "size": 7648
        },
        {
          "path": "commands/ctx-design.md",
          "type": "blob",
          "size": 4817
        },
        {
          "path": "commands/ctx-execute.md",
          "type": "blob",
          "size": 45613
        },
        {
          "path": "commands/ctx-git-commit.md",
          "type": "blob",
          "size": 7527
        },
        {
          "path": "commands/ctx-help.md",
          "type": "blob",
          "size": 7981
        },
        {
          "path": "commands/ctx-plan.md",
          "type": "blob",
          "size": 15454
        },
        {
          "path": "commands/ctx-research.md",
          "type": "blob",
          "size": 7457
        },
        {
          "path": "commands/ctx-stats.md",
          "type": "blob",
          "size": 5455
        },
        {
          "path": "commands/ctx-status.md",
          "type": "blob",
          "size": 5574
        },
        {
          "path": "commands/ctx-usage.md",
          "type": "blob",
          "size": 2095
        },
        {
          "path": "commands/ctx-verify.md",
          "type": "blob",
          "size": 4747
        },
        {
          "path": "commands/slashsense-stats.py",
          "type": "blob",
          "size": 6507
        },
        {
          "path": "copilot-delegate",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/FINAL_RECOMMENDATION.md",
          "type": "blob",
          "size": 11113
        },
        {
          "path": "copilot-delegate/INTEGRATION_SUMMARY.md",
          "type": "blob",
          "size": 15418
        },
        {
          "path": "copilot-delegate/OLD_VS_NEW_DESIGN.md",
          "type": "blob",
          "size": 11002
        },
        {
          "path": "copilot-delegate/PARALLEL_INTEGRATION_ANALYSIS.md",
          "type": "blob",
          "size": 27081
        },
        {
          "path": "copilot-delegate/README.md",
          "type": "blob",
          "size": 11333
        },
        {
          "path": "copilot-delegate/REVISED_ARCHITECTURE.md",
          "type": "blob",
          "size": 14215
        },
        {
          "path": "copilot-delegate/SIMPLIFIED_WORKFLOW.md",
          "type": "blob",
          "size": 16716
        },
        {
          "path": "copilot-delegate/SKILL.md",
          "type": "blob",
          "size": 10902
        },
        {
          "path": "copilot-delegate/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/assets/task-templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/assets/task-templates/github-issue.json",
          "type": "blob",
          "size": 931
        },
        {
          "path": "copilot-delegate/assets/task-templates/github-pr.json",
          "type": "blob",
          "size": 1078
        },
        {
          "path": "copilot-delegate/assets/task-templates/research.json",
          "type": "blob",
          "size": 1639
        },
        {
          "path": "copilot-delegate/copilot-results",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/copilot-results/copilot_20251027_164207_580561d9.json",
          "type": "blob",
          "size": 191
        },
        {
          "path": "copilot-delegate/copilot-results/copilot_20251027_164323_3ec7aa63.json",
          "type": "blob",
          "size": 341
        },
        {
          "path": "copilot-delegate/copilot-results/copilot_20251027_164323_3ec7aa63.json.meta",
          "type": "blob",
          "size": 247
        },
        {
          "path": "copilot-delegate/copilot-results/copilot_20251027_164345_f4fe354d.json",
          "type": "blob",
          "size": 2268
        },
        {
          "path": "copilot-delegate/copilot-results/copilot_20251027_164345_f4fe354d.json.meta",
          "type": "blob",
          "size": 249
        },
        {
          "path": "copilot-delegate/integration-scripts-v2",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/integration-scripts-v2/README.md",
          "type": "blob",
          "size": 11464
        },
        {
          "path": "copilot-delegate/integration-scripts-v2/init_plan.sh",
          "type": "blob",
          "size": 6005
        },
        {
          "path": "copilot-delegate/integration-scripts-v2/research_from_plan.sh.deprecated",
          "type": "blob",
          "size": 9156
        },
        {
          "path": "copilot-delegate/integration-scripts-v2/setup_worktrees_from_plan.sh",
          "type": "blob",
          "size": 5520
        },
        {
          "path": "copilot-delegate/integration-scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/integration-scripts/batch_create_issues.sh",
          "type": "blob",
          "size": 4935
        },
        {
          "path": "copilot-delegate/integration-scripts/batch_update_issues.sh",
          "type": "blob",
          "size": 6513
        },
        {
          "path": "copilot-delegate/integration-scripts/research_tasks.sh",
          "type": "blob",
          "size": 6494
        },
        {
          "path": "copilot-delegate/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/references/copilot-capabilities.md",
          "type": "blob",
          "size": 9006
        },
        {
          "path": "copilot-delegate/references/session-preservation.md",
          "type": "blob",
          "size": 6644
        },
        {
          "path": "copilot-delegate/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-delegate/scripts/delegate_copilot.sh",
          "type": "blob",
          "size": 6441
        },
        {
          "path": "copilot-delegate/scripts/error_handler.sh",
          "type": "blob",
          "size": 4793
        },
        {
          "path": "copilot-delegate/scripts/github_operation.sh",
          "type": "blob",
          "size": 3449
        },
        {
          "path": "copilot-delegate/scripts/research_task.sh",
          "type": "blob",
          "size": 5548
        },
        {
          "path": "copilot-results",
          "type": "tree",
          "size": null
        },
        {
          "path": "copilot-results/copilot_20251027_230828_71b42a85.json",
          "type": "blob",
          "size": 3763
        },
        {
          "path": "copilot-results/copilot_20251027_230828_71b42a85.json.meta",
          "type": "blob",
          "size": 249
        },
        {
          "path": "data",
          "type": "tree",
          "size": null
        },
        {
          "path": "data/intent_mappings.json",
          "type": "blob",
          "size": 11851
        },
        {
          "path": "decisions.yaml",
          "type": "blob",
          "size": 10500
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/AGENT_ARCHITECTURE_SUMMARY.md",
          "type": "blob",
          "size": 12158
        },
        {
          "path": "docs/AGENT_INTEGRATION_GUIDE.md",
          "type": "blob",
          "size": 34845
        },
        {
          "path": "docs/AUTO_APPROVAL_CONFIGURATION.md",
          "type": "blob",
          "size": 11997
        },
        {
          "path": "docs/BUGS.md",
          "type": "blob",
          "size": 9235
        },
        {
          "path": "docs/CLAUDE_CODE_TRANSCRIPT_LOCATION.md",
          "type": "blob",
          "size": 2911
        },
        {
          "path": "docs/COST_OPTIMIZATION_GUIDE.md",
          "type": "blob",
          "size": 31563
        },
        {
          "path": "docs/HAIKU_AGENT_ARCHITECTURE.md",
          "type": "blob",
          "size": 18346
        },
        {
          "path": "docs/HOOK_OUTPUT_REPORT.md",
          "type": "blob",
          "size": 10566
        },
        {
          "path": "docs/IMPLEMENTATION_SUMMARY.md",
          "type": "blob",
          "size": 12949
        },
        {
          "path": "docs/OBSERVABILITY.md",
          "type": "blob",
          "size": 11624
        },
        {
          "path": "docs/PARALLEL_SETUP_PATTERN.md",
          "type": "blob",
          "size": 19759
        },
        {
          "path": "docs/PLAN_DIRECT_CREATION_DESIGN.md",
          "type": "blob",
          "size": 12713
        },
        {
          "path": "docs/PROMPT_AUGMENTATION.md",
          "type": "blob",
          "size": 10346
        },
        {
          "path": "docs/RESEARCH_AGENTS_GUIDE.md",
          "type": "blob",
          "size": 10991
        },
        {
          "path": "docs/SKILLS.md",
          "type": "blob",
          "size": 7824
        },
        {
          "path": "docs/SKILLS_ENHANCEMENT.md",
          "type": "blob",
          "size": 18432
        },
        {
          "path": "docs/SKILLS_IMPLEMENTATION_SUMMARY.md",
          "type": "blob",
          "size": 18981
        },
        {
          "path": "docs/TOKEN_ESTIMATION_ARCHITECTURE.md",
          "type": "blob",
          "size": 25486
        },
        {
          "path": "docs/USAGE_INTEGRATION.md",
          "type": "blob",
          "size": 8980
        },
        {
          "path": "docs/USAGE_REALITY_CHECK.md",
          "type": "blob",
          "size": 6840
        },
        {
          "path": "docs/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/assets/images",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/assets/images/black_logo.svg",
          "type": "blob",
          "size": 4716
        },
        {
          "path": "docs/assets/images/logo.png",
          "type": "blob",
          "size": 126720
        },
        {
          "path": "docs/assets/images/logo.svg",
          "type": "blob",
          "size": 4927
        },
        {
          "path": "docs/delegation-modes.md",
          "type": "blob",
          "size": 6098
        },
        {
          "path": "docs/hook-output-analysis.md",
          "type": "blob",
          "size": 7703
        },
        {
          "path": "docs/index.md",
          "type": "blob",
          "size": 9921
        },
        {
          "path": "docs/javascripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/javascripts/extra.js",
          "type": "blob",
          "size": 5759
        },
        {
          "path": "docs/research-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/research-agents/WEB_SEARCH_SOLUTIONS.md",
          "type": "blob",
          "size": 4175
        },
        {
          "path": "docs/stylesheets",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/stylesheets/extra.css",
          "type": "blob",
          "size": 11833
        },
        {
          "path": "docs/subagent-instructions.md",
          "type": "blob",
          "size": 12361
        },
        {
          "path": "examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/session_start_with_context.js",
          "type": "blob",
          "size": 2771
        },
        {
          "path": "examples/session_start_zero_context.js",
          "type": "blob",
          "size": 3098
        },
        {
          "path": "feature_list.json",
          "type": "blob",
          "size": 4794
        },
        {
          "path": "features.yaml",
          "type": "blob",
          "size": 37824
        },
        {
          "path": "feedback.md",
          "type": "blob",
          "size": 66168
        },
        {
          "path": "hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/compact_start.js",
          "type": "blob",
          "size": 3308
        },
        {
          "path": "hooks/context_injector.js",
          "type": "blob",
          "size": 9441
        },
        {
          "path": "hooks/context_preserver.py",
          "type": "blob",
          "size": 11886
        },
        {
          "path": "hooks/context_restorer.js",
          "type": "blob",
          "size": 5488
        },
        {
          "path": "hooks/contextune_execute_tracker.py",
          "type": "blob",
          "size": 6654
        },
        {
          "path": "hooks/contextune_plan_tracker.py",
          "type": "blob",
          "size": 5472
        },
        {
          "path": "hooks/git_workflow_detector.py",
          "type": "blob",
          "size": 8310
        },
        {
          "path": "hooks/hooks.json",
          "type": "blob",
          "size": 4727
        },
        {
          "path": "hooks/pre_tool_use_git_advisor.py",
          "type": "blob",
          "size": 5921
        },
        {
          "path": "hooks/pre_tool_use_state_sync.py",
          "type": "blob",
          "size": 6340
        },
        {
          "path": "hooks/session_end_extractor.py",
          "type": "blob",
          "size": 26635
        },
        {
          "path": "hooks/session_end_recorder.py",
          "type": "blob",
          "size": 4788
        },
        {
          "path": "hooks/session_start.js",
          "type": "blob",
          "size": 3865
        },
        {
          "path": "hooks/session_start_git_context.py",
          "type": "blob",
          "size": 9787
        },
        {
          "path": "hooks/tool_cost_tracker.py",
          "type": "blob",
          "size": 6224
        },
        {
          "path": "hooks/tool_router.py",
          "type": "blob",
          "size": 9497
        },
        {
          "path": "hooks/user_prompt_submit.py",
          "type": "blob",
          "size": 31904
        },
        {
          "path": "hooks/version_checker.js",
          "type": "blob",
          "size": 8469
        },
        {
          "path": "index.html",
          "type": "blob",
          "size": 167864
        },
        {
          "path": "lib",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/command_discovery.py",
          "type": "blob",
          "size": 3188
        },
        {
          "path": "lib/contextune_integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/contextune_integration/__init__.py",
          "type": "blob",
          "size": 1463
        },
        {
          "path": "lib/contextune_integration/config.py",
          "type": "blob",
          "size": 5960
        },
        {
          "path": "lib/contextune_integration/config_loader.py",
          "type": "blob",
          "size": 6364
        },
        {
          "path": "lib/contextune_integration/models.py",
          "type": "blob",
          "size": 8957
        },
        {
          "path": "lib/contextune_integration/types.py",
          "type": "blob",
          "size": 1076
        },
        {
          "path": "lib/decision_link.py",
          "type": "blob",
          "size": 10474
        },
        {
          "path": "lib/detection_db.py",
          "type": "blob",
          "size": 7771
        },
        {
          "path": "lib/extraction_patterns.py",
          "type": "blob",
          "size": 6071
        },
        {
          "path": "lib/global_observability.py",
          "type": "blob",
          "size": 13037
        },
        {
          "path": "lib/install_manifest.py",
          "type": "blob",
          "size": 4599
        },
        {
          "path": "lib/keyword_matcher.py",
          "type": "blob",
          "size": 14405
        },
        {
          "path": "lib/keyword_matcher_v2.py",
          "type": "blob",
          "size": 10132
        },
        {
          "path": "lib/model2vec_matcher.py",
          "type": "blob",
          "size": 9583
        },
        {
          "path": "lib/observability_db.py",
          "type": "blob",
          "size": 21850
        },
        {
          "path": "lib/plan_builder.py",
          "type": "blob",
          "size": 11516
        },
        {
          "path": "lib/semantic_router_matcher.py",
          "type": "blob",
          "size": 9922
        },
        {
          "path": "lib/unified_intent_detector.py",
          "type": "blob",
          "size": 4695
        },
        {
          "path": "lib/usage_monitor.py",
          "type": "blob",
          "size": 16218
        },
        {
          "path": "logs",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/07e3d465-e638-4f7d-845c-0ed86d7474fb",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/07e3d465-e638-4f7d-845c-0ed86d7474fb/chat.json",
          "type": "blob",
          "size": 3647
        },
        {
          "path": "logs/07e3d465-e638-4f7d-845c-0ed86d7474fb/stop.json",
          "type": "blob",
          "size": 352
        },
        {
          "path": "logs/07e3d465-e638-4f7d-845c-0ed86d7474fb/subagent_stop.json",
          "type": "blob",
          "size": 509
        },
        {
          "path": "logs/242aa39d-d2c3-4dcc-bfac-4ee1d1ec0a56",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/242aa39d-d2c3-4dcc-bfac-4ee1d1ec0a56/chat.json",
          "type": "blob",
          "size": 13006
        },
        {
          "path": "logs/242aa39d-d2c3-4dcc-bfac-4ee1d1ec0a56/stop.json",
          "type": "blob",
          "size": 352
        },
        {
          "path": "logs/242aa39d-d2c3-4dcc-bfac-4ee1d1ec0a56/subagent_stop.json",
          "type": "blob",
          "size": 1016
        },
        {
          "path": "logs/3d6fcd4a-b74a-4d5f-94a2-0c8bcdc5516f",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/3d6fcd4a-b74a-4d5f-94a2-0c8bcdc5516f/chat.json",
          "type": "blob",
          "size": 349229
        },
        {
          "path": "logs/3d6fcd4a-b74a-4d5f-94a2-0c8bcdc5516f/notification.json",
          "type": "blob",
          "size": 2762
        },
        {
          "path": "logs/3d6fcd4a-b74a-4d5f-94a2-0c8bcdc5516f/post_tool_use.json",
          "type": "blob",
          "size": 112986
        },
        {
          "path": "logs/3d6fcd4a-b74a-4d5f-94a2-0c8bcdc5516f/pre_tool_use.json",
          "type": "blob",
          "size": 22633
        },
        {
          "path": "logs/3d6fcd4a-b74a-4d5f-94a2-0c8bcdc5516f/stop.json",
          "type": "blob",
          "size": 1060
        },
        {
          "path": "logs/3d6fcd4a-b74a-4d5f-94a2-0c8bcdc5516f/subagent_stop.json",
          "type": "blob",
          "size": 1732
        },
        {
          "path": "logs/4606c676-6989-4018-a0b7-223ebae4c1f4",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/4606c676-6989-4018-a0b7-223ebae4c1f4/chat.json",
          "type": "blob",
          "size": 4214
        },
        {
          "path": "logs/4606c676-6989-4018-a0b7-223ebae4c1f4/stop.json",
          "type": "blob",
          "size": 352
        },
        {
          "path": "logs/4606c676-6989-4018-a0b7-223ebae4c1f4/subagent_stop.json",
          "type": "blob",
          "size": 1016
        },
        {
          "path": "logs/9202596c-d296-440a-b61f-1fca4bc5b4ea",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/9202596c-d296-440a-b61f-1fca4bc5b4ea/chat.json",
          "type": "blob",
          "size": 222863
        },
        {
          "path": "logs/9202596c-d296-440a-b61f-1fca4bc5b4ea/notification.json",
          "type": "blob",
          "size": 784
        },
        {
          "path": "logs/9202596c-d296-440a-b61f-1fca4bc5b4ea/post_tool_use.json",
          "type": "blob",
          "size": 114138
        },
        {
          "path": "logs/9202596c-d296-440a-b61f-1fca4bc5b4ea/pre_tool_use.json",
          "type": "blob",
          "size": 10413
        },
        {
          "path": "logs/9202596c-d296-440a-b61f-1fca4bc5b4ea/stop.json",
          "type": "blob",
          "size": 356
        },
        {
          "path": "logs/9202596c-d296-440a-b61f-1fca4bc5b4ea/subagent_stop.json",
          "type": "blob",
          "size": 1016
        },
        {
          "path": "logs/976b98f4-25c7-4935-9d4d-9af1714d0b6c",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/976b98f4-25c7-4935-9d4d-9af1714d0b6c/chat.json",
          "type": "blob",
          "size": 1817381
        },
        {
          "path": "logs/976b98f4-25c7-4935-9d4d-9af1714d0b6c/notification.json",
          "type": "blob",
          "size": 3176
        },
        {
          "path": "logs/976b98f4-25c7-4935-9d4d-9af1714d0b6c/post_tool_use.json",
          "type": "blob",
          "size": 10007
        },
        {
          "path": "logs/976b98f4-25c7-4935-9d4d-9af1714d0b6c/pre_tool_use.json",
          "type": "blob",
          "size": 45189
        },
        {
          "path": "logs/976b98f4-25c7-4935-9d4d-9af1714d0b6c/stop.json",
          "type": "blob",
          "size": 3176
        },
        {
          "path": "logs/976b98f4-25c7-4935-9d4d-9af1714d0b6c/subagent_stop.json",
          "type": "blob",
          "size": 3257
        },
        {
          "path": "logs/afa1c0d5-8028-4591-baf8-83c1e45ee276",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/afa1c0d5-8028-4591-baf8-83c1e45ee276/chat.json",
          "type": "blob",
          "size": 7650
        },
        {
          "path": "logs/afa1c0d5-8028-4591-baf8-83c1e45ee276/stop.json",
          "type": "blob",
          "size": 352
        },
        {
          "path": "logs/afa1c0d5-8028-4591-baf8-83c1e45ee276/subagent_stop.json",
          "type": "blob",
          "size": 1016
        },
        {
          "path": "logs/bc0d32e8-a1f5-46fc-b011-dc38857ed615",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/bc0d32e8-a1f5-46fc-b011-dc38857ed615/subagent_stop.json",
          "type": "blob",
          "size": 718
        },
        {
          "path": "logs/c17fb17e-d32c-4518-a543-b6f873dfb450",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/c17fb17e-d32c-4518-a543-b6f873dfb450/chat.json",
          "type": "blob",
          "size": 5866
        },
        {
          "path": "logs/c17fb17e-d32c-4518-a543-b6f873dfb450/stop.json",
          "type": "blob",
          "size": 352
        },
        {
          "path": "logs/c17fb17e-d32c-4518-a543-b6f873dfb450/subagent_stop.json",
          "type": "blob",
          "size": 1016
        },
        {
          "path": "logs/cb49dd14-0259-4321-8860-bd671b0081f6",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/cb49dd14-0259-4321-8860-bd671b0081f6/chat.json",
          "type": "blob",
          "size": 13886
        },
        {
          "path": "logs/cb49dd14-0259-4321-8860-bd671b0081f6/post_tool_use.json",
          "type": "blob",
          "size": 816
        },
        {
          "path": "logs/cb49dd14-0259-4321-8860-bd671b0081f6/pre_tool_use.json",
          "type": "blob",
          "size": 530
        },
        {
          "path": "logs/cb49dd14-0259-4321-8860-bd671b0081f6/stop.json",
          "type": "blob",
          "size": 352
        },
        {
          "path": "logs/cb49dd14-0259-4321-8860-bd671b0081f6/subagent_stop.json",
          "type": "blob",
          "size": 1016
        },
        {
          "path": "logs/d5385a36-d28b-4c4d-b5ef-d22de0e0149c",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/d5385a36-d28b-4c4d-b5ef-d22de0e0149c/chat.json",
          "type": "blob",
          "size": 3938
        },
        {
          "path": "logs/d5385a36-d28b-4c4d-b5ef-d22de0e0149c/stop.json",
          "type": "blob",
          "size": 352
        },
        {
          "path": "logs/d5385a36-d28b-4c4d-b5ef-d22de0e0149c/subagent_stop.json",
          "type": "blob",
          "size": 1016
        },
        {
          "path": "logs/script_errors",
          "type": "tree",
          "size": null
        },
        {
          "path": "logs/script_errors/error_20251028_035840.json",
          "type": "blob",
          "size": 630
        },
        {
          "path": "logs/script_errors/error_20251028_040905.json",
          "type": "blob",
          "size": 2394
        },
        {
          "path": "main.py",
          "type": "blob",
          "size": 88
        },
        {
          "path": "marimo_tutorial_sql.py",
          "type": "blob",
          "size": 11228
        },
        {
          "path": "mkdocs.yml",
          "type": "blob",
          "size": 6428
        },
        {
          "path": "notebooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "notebooks/__marimo__",
          "type": "tree",
          "size": null
        },
        {
          "path": "notebooks/__marimo__/session",
          "type": "tree",
          "size": null
        },
        {
          "path": "notebooks/__marimo__/session/contextune_metrics_dashboard.py.json",
          "type": "blob",
          "size": 139847
        },
        {
          "path": "notebooks/contextune_metrics_dashboard.py",
          "type": "blob",
          "size": 11003
        },
        {
          "path": "output-styles",
          "type": "tree",
          "size": null
        },
        {
          "path": "output-styles/README.md",
          "type": "blob",
          "size": 6971
        },
        {
          "path": "output-styles/extraction-optimized.md",
          "type": "blob",
          "size": 17504
        },
        {
          "path": "package.json",
          "type": "blob",
          "size": 329
        },
        {
          "path": "permissions.txt",
          "type": "blob",
          "size": 113
        },
        {
          "path": "pyproject.toml",
          "type": "blob",
          "size": 10453
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/README.md",
          "type": "blob",
          "size": 11812
        },
        {
          "path": "scripts/SMART_EXECUTION_README.md",
          "type": "blob",
          "size": 3551
        },
        {
          "path": "scripts/benchmark_storage.sh",
          "type": "blob",
          "size": 3046
        },
        {
          "path": "scripts/commit_and_push.sh",
          "type": "blob",
          "size": 1381
        },
        {
          "path": "scripts/create_pr.sh",
          "type": "blob",
          "size": 820
        },
        {
          "path": "scripts/create_prs.sh",
          "type": "blob",
          "size": 4623
        },
        {
          "path": "scripts/decision-link.py",
          "type": "blob",
          "size": 1592
        },
        {
          "path": "scripts/decision-query.py",
          "type": "blob",
          "size": 12459
        },
        {
          "path": "scripts/decision-sync.py",
          "type": "blob",
          "size": 14289
        },
        {
          "path": "scripts/extract-current-plan.sh",
          "type": "blob",
          "size": 1771
        },
        {
          "path": "scripts/extract-plan-from-context.py",
          "type": "blob",
          "size": 8819
        },
        {
          "path": "scripts/feature-complete.py",
          "type": "blob",
          "size": 5538
        },
        {
          "path": "scripts/feature-complete.sh",
          "type": "blob",
          "size": 3845
        },
        {
          "path": "scripts/feature-execute.py",
          "type": "blob",
          "size": 9893
        },
        {
          "path": "scripts/feature-execute.sh",
          "type": "blob",
          "size": 7699
        },
        {
          "path": "scripts/feature-graph.py",
          "type": "blob",
          "size": 8481
        },
        {
          "path": "scripts/feature-graph.sh",
          "type": "blob",
          "size": 9041
        },
        {
          "path": "scripts/feature-status.py",
          "type": "blob",
          "size": 7046
        },
        {
          "path": "scripts/feature-status.sh",
          "type": "blob",
          "size": 5733
        },
        {
          "path": "scripts/generate_mappings.py",
          "type": "blob",
          "size": 5132
        },
        {
          "path": "scripts/haiku_error_handler.sh",
          "type": "blob",
          "size": 4091
        },
        {
          "path": "scripts/merge_and_cleanup.sh",
          "type": "blob",
          "size": 1244
        },
        {
          "path": "scripts/plan-viewer.py",
          "type": "blob",
          "size": 10337
        },
        {
          "path": "scripts/session-status.sh",
          "type": "blob",
          "size": 3473
        },
        {
          "path": "scripts/setup_worktrees.sh",
          "type": "blob",
          "size": 3341
        },
        {
          "path": "scripts/smart_execute.sh",
          "type": "blob",
          "size": 2803
        },
        {
          "path": "scripts/view_session_metrics.sh",
          "type": "blob",
          "size": 2364
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/README.md",
          "type": "blob",
          "size": 14988
        },
        {
          "path": "skills/decision-tracker",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/decision-tracker/SKILL.md",
          "type": "blob",
          "size": 16470
        },
        {
          "path": "skills/git-worktree-master",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/git-worktree-master/SKILL.md",
          "type": "blob",
          "size": 14303
        },
        {
          "path": "skills/intent-recognition",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/intent-recognition/SKILL.md",
          "type": "blob",
          "size": 4784
        },
        {
          "path": "skills/parallel-development-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/parallel-development-expert/SKILL.md",
          "type": "blob",
          "size": 4162
        },
        {
          "path": "skills/performance-optimizer",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/performance-optimizer/SKILL.md",
          "type": "blob",
          "size": 24513
        },
        {
          "path": "skills/researcher",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/researcher/SKILL.md",
          "type": "blob",
          "size": 5023
        },
        {
          "path": "skills/software-architect",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/software-architect/SKILL.md",
          "type": "blob",
          "size": 4780
        },
        {
          "path": "statusline.sh",
          "type": "blob",
          "size": 902
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/__init__.py",
          "type": "blob",
          "size": 44
        },
        {
          "path": "tests/test_ctx_configure_integration.py",
          "type": "blob",
          "size": 6330
        },
        {
          "path": "tests/test_decision_link.py",
          "type": "blob",
          "size": 13084
        },
        {
          "path": "tests/test_decision_query.py",
          "type": "blob",
          "size": 10900
        },
        {
          "path": "tests/test_decision_sync.py",
          "type": "blob",
          "size": 13915
        },
        {
          "path": "tests/test_keyword.py",
          "type": "blob",
          "size": 11614
        },
        {
          "path": "tests/test_observability_corrections.py",
          "type": "blob",
          "size": 16784
        },
        {
          "path": "tests/test_session_end_extractor.py",
          "type": "blob",
          "size": 11023
        },
        {
          "path": "tests/test_smart_execution.sh",
          "type": "blob",
          "size": 3242
        },
        {
          "path": "tests/test_user_prompt_submit.py",
          "type": "blob",
          "size": 9101
        }
      ],
      "marketplace": {
        "name": "Contextune",
        "version": "0.9.2",
        "description": "Precision-tuned context engineering for Claude Code. Optimize context flow with modular plans (95% fewer tokens), parallel workflows (81% cost reduction), and zero-transformation architecture.",
        "owner_info": {
          "name": "Shakes Dlamini",
          "email": "shakestzd@gmail.com",
          "url": "https://github.com/Shakes-tzd"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "contextune",
            "description": "Precision-tuned context engineering for Claude Code. Natural language to slash command mapping, modular development plans, and parallel workflow execution.",
            "source": "./",
            "category": "Productivity",
            "version": "0.9.2",
            "author": {
              "name": "Shakes Dlamini",
              "email": "shakestzd@gmail.com",
              "url": "https://github.com/Shakes-tzd"
            },
            "install_commands": [
              "/plugin marketplace add Shakes-tzd/contextune",
              "/plugin install contextune@Contextune"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-12-23T22:19:12Z",
              "created_at": "2025-10-14T21:47:26Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "decision-tracker",
                "description": "Git-powered state awareness - track file changes, session context, decisions, and work history. Query what happened in previous sessions and during current session. Auto-activates for state queries and before duplicating work.",
                "path": "skills/decision-tracker/SKILL.md",
                "frontmatter": {
                  "name": "decision-tracker",
                  "description": "Git-powered state awareness - track file changes, session context, decisions, and work history. Query what happened in previous sessions and during current session. Auto-activates for state queries and before duplicating work.",
                  "keywords": [
                    "what changed",
                    "what happened",
                    "previous session",
                    "last session",
                    "what did we",
                    "what was",
                    "show changes",
                    "show status",
                    "current state",
                    "file changes",
                    "git status",
                    "session status",
                    "why did we",
                    "what was the decision",
                    "should we use",
                    "which approach",
                    "research",
                    "before we start",
                    "have we already",
                    "did we already"
                  ],
                  "auto_invoke": true
                },
                "content": "# State Tracker - Git-Powered Session & State Awareness\n\n**Purpose:** Provide Claude with complete awareness of project state using git as source of truth, preventing stale mental models and redundant work.\n\n**What This System Tracks:**\n\n1. **In-Session State** (real-time)\n   - File modifications (git diff)\n   - Uncommitted changes (git status)\n   - Current branch and commit\n\n2. **Between-Session Context** (differential)\n   - What happened since last session\n   - Commits made (by you or others)\n   - Files changed externally\n   - Branch switches\n\n3. **Historical Decisions** (queryable)\n   - Past research findings\n   - Architectural decisions\n   - Implementation plans\n\n**Token Overhead:**\n- In-session checks: ~200-500 tokens (only when files change)\n- Between-session context: ~1-2K tokens (differential only)\n- Decision queries: ~2-5K tokens (selective loading)\n- **Total:** <5K tokens vs 50K+ full reload\n\n---\n\n## When This Skill Activates\n\n**Auto-activates when you detect:**\n\n**State Queries:**\n- \"what changed since last session?\"\n- \"show me what happened\"\n- \"what's the current state?\"\n- \"what files did we work on?\"\n- \"what commits were made?\"\n\n**Before File Operations:**\n- PreToolUse hook activates automatically\n- Checks if file changed externally\n- Warns before Edit/Write if file is stale\n\n**Before Duplicating Work:**\n- \"research X\"  Check if already researched\n- \"decide on Y\"  Check if already decided\n- \"plan Z\"  Check if plan exists\n\n---\n\n## Your Workflow When This Skill Activates\n\n### If User Asks \"What Changed?\"\n\n**Run the manual status script:**\n```bash\n./scripts/session-status.sh\n```\n\n**This shows:**\n- Git activity since last session\n- Current working directory status\n- Decision tracking summary\n\n**Token cost:** ~500 tokens for complete state summary\n\n### If You're About to Edit a File\n\n**Trust the PreToolUse hook:**\n- It automatically checks git status\n- If file changed externally, you'll see warning\n- Follow the recommendation: Re-read before editing\n\n**Don't manually check git status** - hook does it automatically!\n\n### If Starting Research or Planning\n\n**Query decisions.yaml first:**\n```bash\n# Before research\nuv run scripts/decision-query.py --topic \"{topic}\" --type research\n\n# Before planning\nuv run scripts/decision-query.py --topic \"{topic}\" --type plans\n\n# Before deciding\nuv run scripts/decision-query.py --topic \"{topic}\" --type decisions\n```\n\n**If found:** Load existing context (2-5K tokens)\n**If not found:** Proceed with new work\n\n###If User Made External Changes\n\n**User says:** \"I made some changes\" or \"I committed something\"\n\n**Your response:**\n```bash\n# Check what changed\n./scripts/session-status.sh\n```\n\nThen summarize what you found for the user.\n\n---\n\n## The Complete State Awareness System\n\n### Component 1: In-Session State Sync (Automatic)\n\n**PreToolUse Hook** checks git state before file operations:\n\n```bash\n# Happens automatically when you try to Edit/Write\nPreToolUse: Intercepts tool call\n   Runs: git status <file>\n   If changed: \" File modified externally - Re-read before editing\"\n   Always continues (non-blocking)\n```\n\n**What you see:**\n```\n File State Change Detected\n\nFile: hooks/user_prompt_submit.py\nStatus: MODIFIED\nGit Says: File has uncommitted changes\n\nRecommendation:\n- Re-read file to see current state\n- Use Read tool before Edit\n\nContinuing with your Edit operation...\n```\n\n**Token cost:** ~300 tokens (only when file actually changed)\n\n### Component 2: Between-Session Context (Automatic)\n\n**SessionStart Hook** injects git context automatically:\n\n```\nSession starts:\n   SessionStart reads .contextune/last_session.yaml\n   Runs: git log <last_commit>..HEAD\n   Runs: git diff --stat <last_commit>..HEAD\n   Generates differential summary\n   Injects as additionalContext\n```\n\n**What you see at session start:**\n```\n Git Context Since Last Session (2 hours ago)\n\n**Git Activity:**\n- 5 new commits\n- 8 files changed (+250, -30)\n- Branch: master\n\n**Recent Commits:**\n  a95478f feat: add three-layer git enforcement\n  1e1a15a feat: add plan extraction support\n  ... and 3 more\n\n**Files Changed:**\n  Added (2):\n    - commands/ctx-git-commit.md\n    - hooks/pre_tool_use_git_advisor.py\n  Modified (6):\n    - hooks/user_prompt_submit.py\n    - hooks/hooks.json\n    ... and 4 more\n\n**Current Status:** 2 uncommitted changes\n\nReady to continue work!\n```\n\n**Token cost:** ~1-2K tokens (only NEW information since last session)\n\n### Component 3: Manual Status Check\n\n**When user asks \"what changed?\" or you need to check state:**\n\n```bash\n# Run the status script\n./scripts/session-status.sh\n```\n\n**Shows:**\n- Current git state (branch, commit, uncommitted files)\n- Changes since last session (commits, files, diff stats)\n- Decision tracking status\n- Full git summary\n\n**When to use:**\n- User asks \"what's the current state?\"\n- You need to verify what happened\n- Before major operations\n- After user says \"I made some changes\"\n\n**Token cost:** ~500 tokens\n\n---\n\n## Complete Workflow Examples\n\n### Example 1: File Modified Externally (In-Session)\n\n```\n10:00 - You: Read hooks/user_prompt_submit.py\n        [File contents loaded into context]\n\n10:15 - User edits file in VS Code\n        [Makes changes, saves]\n\n10:20 - You: Edit hooks/user_prompt_submit.py\n\n        PreToolUse Hook:  File State Change Detected\n          File: hooks/user_prompt_submit.py\n          Status: MODIFIED\n          Recommendation: Re-read before editing\n\nYou: \"I see the file was modified externally. Let me re-read it first.\"\n     [Read hooks/user_prompt_submit.py]\n     [Now have current state]\n     [Proceed with Edit]\n```\n\n**Token saved:** Prevented edit conflict + re-work\n\n### Example 2: New Session After External Changes\n\n```\nSession 1 ends:\n  SessionEnd: Records metadata to .contextune/last_session.yaml\n    - session_id, timestamp, last_commit, branch, files_worked_on\n\n[User works outside Claude]\n  - Commits via terminal: git commit -m \"quick fix\"\n  - Edits 3 files manually\n  - Switches to develop branch\n\nSession 2 starts:\n  SessionStart: Loads .contextune/last_session.yaml\n     git log <last_commit>..HEAD\n     git diff --stat <last_commit>..HEAD\n     Generates summary\n\nClaude sees:\n   Git Context Since Last Session (3 hours ago)\n\n  **Git Activity:**\n  - 1 new commit: \"quick fix\"\n  - 3 files changed\n  - Branch: master  develop (switched)\n\n  **Current Status:** Clean \n\nClaude: \"I see you made a commit and switched to develop branch.\n        The 3 files that changed are now in my context. Ready to continue!\"\n```\n\n**Token cost:** ~1.5K (vs 50K+ full reload)\n\n---\n\n## The Decision Tracking System\n\n### Structure\n\n**decisions.yaml** - YAML database with 3 types of entries:\n\n```yaml\nresearch:\n  entries:\n    - id: \"res-001-authentication-libraries\"\n      topic: \"Authentication libraries for Node.js\"\n      findings: \"Compared Passport.js, Auth0, NextAuth...\"\n      recommendation: \"Use NextAuth for React apps\"\n      created_at: \"2025-10-28\"\n      expires_at: \"2026-04-28\"  # 6 months\n      tags: [authentication, libraries, nodejs]\n\nplans:\n  entries:\n    - id: \"plan-001-jwt-implementation\"\n      title: \"JWT Authentication Implementation\"\n      summary: \"5 tasks: AuthService, middleware, tokens...\"\n      status: \"completed\"\n      created_at: \"2025-10-28\"\n      tags: [authentication, implementation]\n\ndecisions:\n  entries:\n    - id: \"dec-001-dry-strategy\"\n      title: \"Unified DRY Strategy\"\n      status: \"accepted\"\n      context: \"CHANGELOG grows unbounded...\"\n      alternatives_considered: [...]\n      decision: \"Use scripts for git workflows\"\n      consequences: {positive: [...], negative: [...]}\n      tags: [architecture, cost-optimization]\n```\n\n### CLI Tools\n\n**Query existing context:**\n```bash\n# Check if we already researched a topic\nuv run scripts/decision-query.py --topic \"authentication\" --type research\n\n# Check for existing decisions\nuv run scripts/decision-query.py --topic \"DRY\" --type decisions\n\n# Check for active plans\nuv run scripts/decision-query.py --type plans --status active\n\n# Query by tags\nuv run scripts/decision-query.py --tags architecture cost-optimization\n```\n\n**Output format:**\n```yaml\n# Filtered entries matching your query\n# Load only relevant context (2-5K tokens vs 150K full CHANGELOG)\n```\n\n---\n\n## Your Workflow (IMPORTANT!)\n\n### Before Starting Research\n\n**ALWAYS query first:**\n\n```bash\n# Check if we already researched this topic\nuv run scripts/decision-query.py --topic \"{research_topic}\" --type research\n```\n\n**If found:**\n- Load the existing findings (2K tokens)\n- Check expiration date (research expires after 6 months)\n- If recent  Use existing research\n- If expired  Research again, update entry\n\n**If NOT found:**\n- Proceed with research\n- SessionEnd hook will auto-extract to decisions.yaml\n\n**Savings:**\n- Skip $0.07 redundant research\n- Load 2K tokens instead of researching again\n\n### Before Making Decisions\n\n**ALWAYS query first:**\n\n```bash\n# Check for existing decisions on this topic\nuv run scripts/decision-query.py --topic \"{decision_topic}\" --type decisions\n```\n\n**If found:**\n- Load the decision context\n- Check status (accepted, rejected, superseded)\n- If accepted  Follow existing decision\n- If superseded  Find superseding decision\n- If rejected  Understand why, avoid same approach\n\n**If NOT found:**\n- Proceed with decision-making\n- SessionEnd hook will auto-extract to decisions.yaml\n\n**Savings:**\n- Skip 15-30 min re-discussion\n- Consistent decisions across sessions\n\n### Before Planning\n\n**ALWAYS query first:**\n\n```bash\n# Check for existing plans on this topic\nuv run scripts/decision-query.py --topic \"{feature_name}\" --type plans\n```\n\n**If found:**\n- Load existing plan (2-3K tokens)\n- Check status (active, completed, archived)\n- If active  Continue existing plan\n- If completed  Reference, don't recreate\n\n**If NOT found:**\n- Create new plan with /ctx:plan\n- Plan will be auto-extracted to decisions.yaml\n\n---\n\n## Auto-Population\n\n**decision-sync.py** scans conversation history and auto-populates decisions.yaml:\n\n```bash\n# Scan all conversations for decisions (run once)\nuv run scripts/decision-sync.py\n\n# Result: Populates decisions.yaml with historical context\n```\n\n**How it works:**\n1. Scans `~/.claude/projects/*/conversation/` for transcripts\n2. Uses extraction patterns to detect decisions/research/plans\n3. Extracts and appends to decisions.yaml\n4. Deduplicates (won't add same decision twice)\n\n**Already populated:** Check current state:\n```bash\n# See what's already in decisions.yaml\nuv run scripts/decision-query.py --all\n```\n\n---\n\n## Token Efficiency\n\n### Context Loading Comparison\n\n**Old approach (CHANGELOG.md):**\n```\nImport entire CHANGELOG: 150K tokens\nProblem: Loads everything, most irrelevant\nCost: High context usage\n```\n\n**New approach (decisions.yaml with queries):**\n```\nQuery specific topic: 2-5K tokens (83-97% reduction!)\nExample: decision-query.py --topic \"authentication\"\nLoads: Only relevant 2-3 entries\n```\n\n### Selective Loading Strategy\n\n**Scenario 1: Starting authentication work**\n```bash\n# Query for authentication context\nuv run scripts/decision-query.py --topic \"authentication\"\n\n# Loads:\n- Research: Authentication libraries (if exists)\n- Decisions: Auth approach decisions (if exists)\n- Plans: Auth implementation plans (if exists)\n\n# Total: ~3K tokens vs 150K full CHANGELOG\n```\n\n**Scenario 2: User asks \"why did we choose X?\"**\n```bash\n# Query for specific decision\nuv run scripts/decision-query.py --topic \"DRY strategy\"\n\n# Loads: Single decision with full context\n# Total: ~1K tokens\n```\n\n---\n\n## Integration with Hooks\n\n### SessionEnd Hook (Automatic)\n\n**session_end_extractor.py** already extracts to decisions.yaml:\n- Detects decisions in conversation (## Decision: pattern)\n- Extracts structured data\n- Appends to decisions.yaml automatically\n\n**You don't need to do anything** - it happens automatically at session end!\n\n### What You Should Do\n\n**During conversation:**\n1. Output decisions in extraction-optimized format (see output style)\n2. SessionEnd hook extracts automatically\n3. Next session, query for context if needed\n\n---\n\n## Examples\n\n### Example 1: Before Researching Libraries\n\n```\nUser: \"Research best state management libraries for React\"\n\nYou: Let me check if we already researched this.\n\n[Run decision-query.py --topic \"state management\" --type research]\n\nResult: Found existing research from 2 months ago\n  - Compared: Redux, Zustand, Jotai, Valtio\n  - Recommendation: Zustand for simple apps, Jotai for complex\n  - Tags: [react, state-management, libraries]\n\nYou: We already researched this! Here's what we found:\n     [Load 2K tokens vs spending $0.07 to research again]\n```\n\n### Example 2: Before Making Architecture Decision\n\n```\nUser: \"Should we use microservices or monolith?\"\n\nYou: Let me check if we already decided on architecture approach.\n\n[Run decision-query.py --topic \"architecture\" --type decisions]\n\nResult: Found decision \"dec-002-monolith-first\"\n  - Decision: Start with modular monolith\n  - Rationale: Team size <5, single deployment simpler\n  - Status: accepted\n  - Date: 2025-09-15\n\nYou: We already decided this! Here's the context:\n     [Load 1K tokens vs re-discussing for 30 minutes]\n```\n\n### Example 3: Before Planning Feature\n\n```\nUser: \"Plan implementation for user dashboard\"\n\nYou: Let me check for existing plans.\n\n[Run decision-query.py --topic \"dashboard\" --type plans]\n\nResult: Found plan \"plan-005-dashboard-v1\"\n  - Status: completed\n  - Summary: \"5 tasks implemented, merged to main\"\n  - Created: 2025-10-01\n\nYou: We already implemented this! Let me load the existing plan.\n     [Load 3K tokens, reference existing work]\n```\n\n---\n\n## Lifecycle Management\n\n**Research entries expire after 6 months:**\n- Rationale: Technology evolves, best practices change\n- Old research becomes stale (2024  2025 practices differ)\n- Expired entries moved to archives\n\n**Plans archive 90 days after completion:**\n- Rationale: Useful during implementation, less useful after\n- Completed plans moved to docs/archive/\n\n**Decisions never auto-expire:**\n- Unless explicitly superseded by new decision\n- Architectural decisions stay relevant\n\n**Check lifecycle status:**\n```bash\n# See active vs expired entries\nuv run scripts/decision-query.py --show-expired\n```\n\n---\n\n## Cost Impact\n\n**Annual savings (assuming 50 research sessions):**\n```\nOld: 50  $0.07 = $3.50 in redundant research\nNew: Query first (free), research only if needed\nSavings: ~$3.00/year + avoid 25 hours of redundant work\n```\n\n**Token savings per query:**\n```\nLoad full CHANGELOG: 150K tokens\nLoad specific query: 2-5K tokens\nSavings: 97% reduction per lookup\n```\n\n---\n\n## Quick Reference\n\n**Check before researching:**\n```bash\nuv run scripts/decision-query.py --topic \"{topic}\" --type research\n```\n\n**Check before deciding:**\n```bash\nuv run scripts/decision-query.py --topic \"{topic}\" --type decisions\n```\n\n**Check before planning:**\n```bash\nuv run scripts/decision-query.py --topic \"{topic}\" --type plans\n```\n\n**See all active context:**\n```bash\nuv run scripts/decision-query.py --all\n```\n\n---\n\n## Integration Points\n\n1. **Before /ctx:research** - Query for existing research first\n2. **Before /ctx:plan** - Query for existing plans first\n3. **Before /ctx:design** - Query for existing decisions first\n4. **When user asks \"why\"** - Query for decision rationale\n5. **At SessionEnd** - Automatic extraction (no action needed)\n\n---\n\n## Summary\n\n**Key principle:** Query before doing work that might already be done.\n\n**Benefits:**\n- 83-97% token reduction for context loading\n- Avoid $0.07 redundant research\n- Consistent decisions across sessions\n- Queryable, structured context\n- Auto-populated from conversation history\n\n**Remember:** decisions.yaml is plugin-local, works for all users who install Contextune!"
              },
              {
                "name": "ctx:worktree",
                "description": "Expert-level git worktree troubleshooting, cleanup, and management. Use when users have worktree issues, conflicts, cleanup needs, or questions about git worktree commands. Activate for problems like stuck worktrees, locked files, orphaned branches, or worktree removal errors.",
                "path": "skills/git-worktree-master/SKILL.md",
                "frontmatter": {
                  "name": "ctx:worktree",
                  "description": "Expert-level git worktree troubleshooting, cleanup, and management. Use when users have worktree issues, conflicts, cleanup needs, or questions about git worktree commands. Activate for problems like stuck worktrees, locked files, orphaned branches, or worktree removal errors.",
                  "keywords": [
                    "worktree issue",
                    "cant remove worktree",
                    "worktree locked",
                    "worktree cleanup",
                    "orphaned branch",
                    "worktree error",
                    "worktree conflict",
                    "git worktree",
                    "worktree removal"
                  ],
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Grep",
                    "TodoWrite"
                  ]
                },
                "content": "# CTX:Worktree - Expert Git Worktree Management\n\nYou are a git worktree expert specializing in diagnosing and resolving complex worktree issues. Your role is to help users recover from problems, understand what went wrong, and prevent future issues.\n\n## When to Activate This Skill\n\nActivate when users encounter:\n- \"Can't remove worktree\" errors\n- \"Worktree is locked\" issues\n- Orphaned branches or worktrees\n- \"Already exists\" conflicts\n- Cleanup after parallel development\n- Questions about worktree commands\n- Performance issues with many worktrees\n\n## Your Expertise\n\n### 1. Diagnostic Process\n\n**Always start with diagnosis before fixing:**\n\n```bash\n# Step 1: List all worktrees\ngit worktree list\n\n# Step 2: Check for locks\nfind .git/worktrees -name \"locked\" -o -name \"*.lock\"\n\n# Step 3: Check disk usage\ndu -sh .git/worktrees/*\n\n# Step 4: Verify branches\ngit branch -a | grep -E \"worktrees|feature\"\n```\n\n**Present findings clearly:**\n\n```markdown\nYou: \"Let me diagnose your worktree situation...\n\n Diagnosis:\n\nActive Worktrees: 3\n worktrees/task-123  feature/task-123 (locked )\n worktrees/task-124  feature/task-124 (ok )\n worktrees/task-125  feature/task-125 (missing directory! )\n\nIssues Found:\n1.  task-123 is locked (probably crashed mid-operation)\n2.  task-125 directory deleted but worktree still registered\n\nI can fix both. Proceed?\"\n```\n\n### 2. Common Issues & Solutions\n\n#### Issue 1: \"Cannot remove worktree\" (Locked)\n\n**Diagnosis:**\n```bash\n# Check if locked\nls -la .git/worktrees/task-123/\n\n# Look for:\n# - locked file (manual lock)\n# - *.lock files (automatic locks from git operations)\n```\n\n**Solution:**\n```bash\n# Remove locks (safe - only if no git operations running)\nrm -f .git/worktrees/task-123/locked\nrm -f .git/worktrees/task-123/*.lock\n\n# Then remove worktree\ngit worktree remove worktrees/task-123\n\n# If still fails, force removal\ngit worktree remove --force worktrees/task-123\n```\n\n**Explanation to user:**\n```markdown\n\"Your worktree is locked, likely from a git operation that didn't complete\n(crash, Ctrl+C, etc.). I've removed the locks safely.\n\n Fixed: Removed locks and worktree\n Prevention: Don't Ctrl+C during git operations in worktrees\"\n```\n\n#### Issue 2: \"Already exists\" Error\n\n**Diagnosis:**\n```bash\n# Check if directory exists\nls -la worktrees/task-123\n\n# Check if worktree is registered\ngit worktree list | grep task-123\n```\n\n**Solution A: Directory exists, not registered**\n```bash\n# Remove directory\nrm -rf worktrees/task-123\n\n# Recreate worktree\ngit worktree add worktrees/task-123 -b feature/task-123\n```\n\n**Solution B: Registered, directory missing**\n```bash\n# Prune stale worktree registrations\ngit worktree prune\n\n# Recreate\ngit worktree add worktrees/task-123 -b feature/task-123\n```\n\n**Explanation:**\n```markdown\n\"The worktree was partially created (either directory OR registration,\nnot both). I've cleaned up the inconsistency and recreated it properly.\n\n Fixed: Synced directory and git registration\n Tip: Use `git worktree prune` to clean up stale entries\"\n```\n\n#### Issue 3: Orphaned Worktrees (Directory Deleted Manually)\n\n**Diagnosis:**\n```bash\n# Find worktrees with missing directories\ngit worktree list | while read -r path branch; do\n  if [ ! -d \"$path\" ]; then\n    echo \"Missing: $path\"\n  fi\ndone\n```\n\n**Solution:**\n```bash\n# Prune all orphaned worktrees\ngit worktree prune\n\n# Verify cleanup\ngit worktree list\n```\n\n**Explanation:**\n```markdown\n\"You (or someone) deleted worktree directories without using\n`git worktree remove`. Git still had them registered.\n\n Fixed: Pruned 3 orphaned worktree registrations\n Prevention: Always use `git worktree remove`, not `rm -rf`\"\n```\n\n#### Issue 4: Too Many Worktrees (Performance)\n\n**Diagnosis:**\n```bash\n# Count worktrees\ngit worktree list | wc -l\n\n# Check disk usage\ndu -sh .git/worktrees\n\n# Check for completed/stale work\ngit worktree list --porcelain | grep -A5 \"worktree\"\n```\n\n**Solution:**\n```bash\n# Aggressive cleanup script\ngit worktree list --porcelain | awk '/^worktree / {path=$2} /^branch / {branch=$2} END {print path, branch}' | while read -r path branch; do\n  # Check if branch is merged\n  if git branch --merged main | grep -q \"$branch\"; then\n    echo \"Removing merged: $path ($branch)\"\n    git worktree remove \"$path\"\n    git branch -d \"$branch\"\n  fi\ndone\n\n# Prune\ngit worktree prune\n```\n\n**Explanation:**\n```markdown\n\"You had 25 worktrees, many for completed work. I've cleaned up:\n\n Removed: 18 worktrees (merged branches)\n Kept: 7 worktrees (active work)\n Disk saved: 2.3GB\n\nPerformance should improve significantly!\n\n Pro Tip: Use `/contextune:parallel:cleanup` after completing work\"\n```\n\n#### Issue 5: Locked Files / Concurrent Git Operations\n\n**Diagnosis:**\n```bash\n# Find lock files\nfind .git -name \"*.lock\" -mtime -1\n\n# Check for running git processes\nps aux | grep git\n```\n\n**Solution:**\n```bash\n# If no git processes running, safe to remove locks\nfind .git -name \"*.lock\" -delete\n\n# Verify no corruption\ngit fsck\n```\n\n**Explanation:**\n```markdown\n\"Git operations in different worktrees can sometimes create lock\nconflicts, especially during parallel work.\n\n Fixed: Removed 5 stale lock files\n Verified: Repository integrity ok (git fsck passed)\n\n Prevention: Avoid running heavy git operations (like `git gc`)\n              during parallel development\"\n```\n\n### 3. Best Practices Guidance\n\n**Teach proper worktree workflows:**\n\n```markdown\n## Worktree Lifecycle Best Practices\n\n **Creation:**\ngit worktree add worktrees/feature-name -b feature/feature-name\n\n **Work:**\ncd worktrees/feature-name\n# Make changes, commit, test\n\n **Completion:**\ngit push origin feature/feature-name\ncd ../..\ngit worktree remove worktrees/feature-name\ngit branch -d feature/feature-name  # After merge\n\n **Don't:**\n- rm -rf worktrees/*  (bypasses git tracking)\n- git worktree add to existing directories\n- Keep worktrees for merged branches\n- Ctrl+C during git operations in worktrees\n```\n\n### 4. Cleanup Strategies\n\n**Provide tailored cleanup based on situation:**\n\n#### For Active Development (Keep Everything)\n```bash\n# Just prune stale references\ngit worktree prune\n```\n\n#### For Post-Sprint Cleanup (Remove Merged)\n```bash\n# Remove worktrees for merged branches\ngit worktree list --porcelain | \\\n  awk '/^worktree / {path=$2} /^branch / {branch=$2; print path, branch}' | \\\n  while read -r path branch; do\n    if git branch --merged main | grep -q \"$(basename \"$branch\")\"; then\n      git worktree remove \"$path\" && git branch -d \"$(basename \"$branch\")\"\n    fi\n  done\n```\n\n#### For Nuclear Cleanup (Remove All)\n```bash\n# Remove all worktrees (use with caution!)\ngit worktree list --porcelain | \\\n  awk '/^worktree / {path=$2; if (path != \"'\"$(git rev-parse --show-toplevel)\"'\") print path}' | \\\n  while read -r path; do\n    git worktree remove --force \"$path\"\n  done\n\ngit worktree prune\n```\n\n**Always confirm before nuclear options:**\n```markdown\n\" CAUTION: This will remove ALL 15 worktrees, including active work!\n\nAre you sure? Type 'yes' to proceed.\"\n```\n\n### 5. Advanced Scenarios\n\n#### Scenario: Corrupted Worktree\n\n**Diagnosis:**\n```bash\n# Check for corruption\ncd worktrees/task-123\ngit status  # Might fail with errors\n\n# Check git directory\nls -la .git  # Should be a file, not directory\ncat .git    # Should point to main repo\n```\n\n**Solution:**\n```bash\n# Rebuild worktree link\ncd ../..\ngit worktree remove --force worktrees/task-123\ngit worktree add worktrees/task-123 feature/task-123\n\n# Cherry-pick uncommitted changes if any\n```\n\n#### Scenario: Branch Already Checked Out\n\n**Error:**\n```\nfatal: 'feature/task-123' is already checked out at 'worktrees/task-123'\n```\n\n**Solution:**\n```bash\n# Force checkout (safe if you know what you're doing)\ngit worktree add --force worktrees/task-124 feature/task-123\n\n# Or use different branch\ngit worktree add worktrees/task-124 -b feature/task-124\n```\n\n**Explanation:**\n```markdown\n\"Git prevents checking out the same branch in multiple worktrees\n(to avoid conflicts). You have two options:\n\n1. Work in the existing worktree (worktrees/task-123)\n2. Create a new branch (feature/task-124) for the new worktree\n\nWhich would you prefer?\"\n```\n\n#### Scenario: Disk Space Issues\n\n**Diagnosis:**\n```bash\n# Check worktree sizes\ndu -sh worktrees/* | sort -h\n\n# Check for large .git objects\ndu -sh .git/worktrees/*\n```\n\n**Solution:**\n```bash\n# Remove largest worktrees first\ndu -sh worktrees/* | sort -hr | head -5\n\n# Clean up node_modules, build artifacts in worktrees\nfind worktrees -name \"node_modules\" -exec rm -rf {} +\nfind worktrees -name \"target\" -exec rm -rf {} +  # Rust\nfind worktrees -name \"__pycache__\" -exec rm -rf {} +\n\n# Run git gc\ngit gc --aggressive\n```\n\n**Explanation:**\n```markdown\n\"Your worktrees were consuming 8.5GB! Here's what I cleaned:\n\n Removed: 3 largest worktrees (5.2GB)\n Cleaned: node_modules in remaining worktrees (1.8GB)\n Ran: git gc (reclaimed 0.5GB)\n\nTotal saved: 7.5GB\n\n Tip: Add node_modules, target, etc. to .git/info/exclude\n        in each worktree to prevent them from growing large\"\n```\n\n### 6. Preventive Maintenance\n\n**Recommend regular maintenance:**\n\n```markdown\n## Worktree Maintenance Checklist\n\n**Weekly (during active development):**\n- [ ] git worktree prune (remove stale references)\n- [ ] Clean merged branches (git branch --merged)\n- [ ] Check for locks (find .git -name \"*.lock\")\n\n**After Sprint/Release:**\n- [ ] Remove completed worktrees\n- [ ] Delete merged branches\n- [ ] Run git gc (compact repository)\n- [ ] Verify no orphaned directories\n\n**Monthly:**\n- [ ] Audit disk usage (du -sh .git/worktrees)\n- [ ] Clean build artifacts in worktrees\n- [ ] Review active worktree count (<20 recommended)\n\nWant me to set up an automated cleanup script?\n```\n\n### 7. Automation Scripts\n\n**Offer to create helper scripts:**\n\n```bash\n# .git/hooks/post-merge (auto-cleanup after merges)\n#!/bin/bash\necho \"Checking for merged worktrees...\"\n\ngit worktree list --porcelain | \\\n  awk '/^worktree / {path=$2} /^branch / {branch=$2; print path, branch}' | \\\n  while read -r path branch; do\n    if git branch --merged main | grep -q \"$(basename \"$branch\")\"; then\n      echo \"Removing merged worktree: $path\"\n      git worktree remove \"$path\" 2>/dev/null\n      git branch -d \"$(basename \"$branch\")\" 2>/dev/null\n    fi\n  done\n\ngit worktree prune\n```\n\n**Present to user:**\n```markdown\n\"I can create an automated cleanup script that runs after merges.\nIt will:\n-  Remove worktrees for merged branches\n-  Delete merged local branches\n-  Prune stale references\n\nInstall it? (Creates .git/hooks/post-merge)\"\n```\n\n## Diagnostic Commands Reference\n\n**Provide this reference when appropriate:**\n\n```bash\n# Essential Diagnostics\ngit worktree list --porcelain    # Detailed worktree info\ngit branch -a                     # All branches\ngit status                        # Current worktree status\ngit fsck                          # Check repository integrity\n\n# Cleanup\ngit worktree prune               # Remove stale references\ngit worktree remove <path>       # Remove worktree properly\ngit worktree remove --force      # Force removal (use carefully)\ngit branch -d <branch>           # Delete branch (safe)\ngit branch -D <branch>           # Force delete (use carefully)\n\n# Advanced\nfind .git/worktrees -name \"*.lock\"  # Find locks\ndu -sh .git/worktrees               # Disk usage\ngit gc --aggressive                  # Compact repository\n```\n\n## Error Messages & Fixes Quick Reference\n\n```markdown\n| Error | Cause | Fix |\n|-------|-------|-----|\n| \"fatal: 'path' already exists\" | Directory exists | rm -rf path, recreate |\n| \"fatal: 'branch' is already checked out\" | Branch in use | Use different branch |\n| \"fatal: 'worktree' is locked\" | Lock file present | Remove .git/worktrees/*/locked |\n| \"fatal: invalid path\" | Path deleted | git worktree prune |\n| \"error: unable to create file\" | Permission issue | Check file permissions |\n| \"fatal: reference is not a tree\" | Corrupted branch | Recreate branch |\n```\n\n## Success Criteria\n\nYour response should:\n1.  Diagnose before fixing (show findings)\n2.  Explain what went wrong (educate)\n3.  Provide safe solutions (verify before destructive operations)\n4.  Teach prevention (avoid future issues)\n5.  Offer automation (scripts for maintenance)\n6.  Be cautious (warn before data loss)\n\n---\n\n## Example Interaction\n\n```\nUser: \"I can't remove worktrees/task-123, getting 'locked' error\"\n\nYou: \"Let me diagnose that...\n\n*runs diagnostic commands*\n\n Diagnosis:\n\nWorktree: worktrees/task-123\nBranch: feature/task-123\nStatus: Locked \nCause: Lock file present (.git/worktrees/task-123/locked)\n\nThis usually happens when:\n- Git operation was interrupted (Ctrl+C, crash)\n- System shutdown during git operation\n- Multiple git operations conflicted\n\n Safe Fix:\n\n1. Verify no git processes running  (checked)\n2. Remove lock file (safe, no data loss)\n3. Remove worktree properly\n4. Optionally delete branch (if merged)\n\nMay I proceed? This will:\n Remove the lock (safe)\n Remove the worktree\n Keep your branch (in case you need it)\"\n\nUser: \"yes\"\n\nYou: *executes fix*\n\n\" Fixed!\n\nRemoved:\n- Lock file (.git/worktrees/task-123/locked)\n- Worktree (worktrees/task-123)\n\nKept:\n- Branch (feature/task-123)\n  You can recreate the worktree if needed:\n  git worktree add worktrees/task-123 feature/task-123\n\n Prevention:\n- Don't Ctrl+C during git operations\n- Let git operations complete\n- Use `git worktree remove` (not rm -rf)\n\nAll set! Need help with anything else?\"\n```\n\n---\n\n**Remember:** Be conservative with destructive operations. Always explain what you're about to do and why. When in doubt, ask the user!"
              },
              {
                "name": "ctx:help",
                "description": "Help users discover Contextune capabilities and understand how to use natural language commands. Use when users ask about Contextune features, available commands, how to use the plugin, or what they can do. Activate for questions like \"what can Contextune do?\", \"how do I use this?\", \"show me examples\", \"what commands are available?\"",
                "path": "skills/intent-recognition/SKILL.md",
                "frontmatter": {
                  "name": "ctx:help",
                  "description": "Help users discover Contextune capabilities and understand how to use natural language commands. Use when users ask about Contextune features, available commands, how to use the plugin, or what they can do. Activate for questions like \"what can Contextune do?\", \"how do I use this?\", \"show me examples\", \"what commands are available?\"",
                  "keywords": [
                    "what can contextune do",
                    "how to use",
                    "show me examples",
                    "what commands",
                    "contextune help",
                    "contextune documentation",
                    "how does contextune work",
                    "what is contextune",
                    "available commands",
                    "plugin features"
                  ],
                  "allowed-tools": []
                },
                "content": "# CTX:Help - Contextune Discovery & Usage Guide\n\nYou help users discover and understand Contextune plugin capabilities.\n\n## When to Activate\n\nActivate when user asks:\n- \"What can Contextune do?\"\n- \"How do I use this plugin?\"\n- \"Show me Contextune examples\"\n- \"What commands are available?\"\n- \"Contextune documentation\"\n- \"How does Contextune work?\"\n- \"What is Contextune?\"\n\n## Capabilities Overview\n\nContextune provides **natural language to slash command mapping** with automatic parallel development workflows.\n\n### 1. Intent Detection (Automatic)\n- Detects slash commands from natural language automatically\n- 3-tier cascade: Keyword  Model2Vec  Semantic Router\n- Adds suggestions to context for Claude to decide\n- No user configuration needed\n\n### 2. Parallel Development Workflow\n- **Research**: `/ctx:research` - Quick research using 3 parallel agents (1-2 min, ~$0.07)\n- **Planning**: `/ctx:plan` - Create parallel development plans\n- **Execution**: `/ctx:execute` - Run tasks in parallel using git worktrees\n- **Monitoring**: `/ctx:status` - Check progress across worktrees\n- **Cleanup**: `/ctx:cleanup` - Merge and cleanup when done\n\n### 3. Auto-Discovery\n- Skills automatically suggest parallelization opportunities\n- Hook detects slash commands from natural language\n- Zero configuration required\n\n## Natural Language Examples\n\nInstead of memorizing slash commands, users can use natural language:\n\n**Intent Detection:**\n- \"analyze my code\"  Suggests `/sc:analyze`\n- \"review this codebase\"  Suggests `/sc:analyze`\n- \"check code quality\"  Suggests `/sc:analyze`\n\n**Research:**\n- \"research best React state libraries\"  `/ctx:research`\n- \"what's the best database for my use case?\"  `/ctx:research`\n\n**Parallel Development:**\n- \"create parallel plan for auth, dashboard, API\"  `/ctx:plan`\n- \"implement features X, Y, Z\"  Skill suggests `/ctx:plan`\n\n## Available Commands\n\n### Research & Planning\n- `/ctx:research` - Standalone research (3 parallel agents, answers specific questions)\n- `/ctx:plan` - Create parallel development plan (5 agents, comprehensive)\n\n### Execution & Monitoring\n- `/ctx:execute` - Execute plan with worktrees and multiple agents\n- `/ctx:status` - Monitor progress across all parallel tasks\n- `/ctx:cleanup` - Clean up worktrees and merge branches\n\n### Configuration\n- `/ctx:configure` - Optional manual customization guide (CLAUDE.md, status bar)\n- `/ctx:stats` - View usage statistics\n- `/ctx:verify` - Verify detection capabilities\n\n## How to Use\n\n**Option 1: Natural Language (Recommended)**\nJust type what you want in plain English:\n- \"research the best approach for X\"\n- \"implement features A, B, C\"\n- \"analyze my code\"\n\nContextune detects intent and suggests appropriate commands automatically.\n\n**Option 2: Explicit Commands**\nType slash commands directly:\n- `/ctx:research what's the best state library?`\n- `/ctx:plan`\n- `/sc:analyze`\n\n## Example Conversation\n\n**User:** \"What can this plugin do?\"\n\n**You:** \"Contextune has three main capabilities:\n\n1. **Intent Detection** - Automatically detects slash commands from natural language\n   - Just say \"analyze my code\" instead of typing `/sc:analyze`\n   \n2. **Quick Research** - Get answers fast with `/ctx:research`\n   - Uses 3 parallel agents (Web, Codebase, Dependencies)\n   - Returns recommendations in 1-2 minutes\n   - Example: `/ctx:research best React state library`\n\n3. **Parallel Development** - Speed up multi-feature work\n   - Detects when you mention multiple independent tasks\n   - Runs them simultaneously in separate git worktrees\n   - 50-70% faster for 3+ features\n   - Commands: `/ctx:plan`, `/ctx:execute`, `/ctx:status`, `/ctx:cleanup`\n\nTry saying: 'research the best database for my project' or 'implement auth and dashboard features'\"\n\n## Don't Over-Explain\n\n- Keep responses concise\n- Only explain features the user asks about\n- Provide examples when helpful\n- Let the user drive the conversation\n\n## Integration Points\n\nWhen explaining Contextune, mention:\n- Works automatically (zero config)\n- Uses Haiku agents (87% cost reduction)\n- Skills suggest parallelization proactively\n- Natural language > memorizing commands"
              },
              {
                "name": "ctx:parallel-expert",
                "description": "Expert guidance on parallel development workflows using git worktrees and multi-agent execution. Use when users mention parallel work, concurrent development, speeding up development, working on multiple features simultaneously, or scaling team productivity. Activate for questions about task decomposition, worktree management, or parallelization strategies.",
                "path": "skills/parallel-development-expert/SKILL.md",
                "frontmatter": {
                  "name": "ctx:parallel-expert",
                  "description": "Expert guidance on parallel development workflows using git worktrees and multi-agent execution. Use when users mention parallel work, concurrent development, speeding up development, working on multiple features simultaneously, or scaling team productivity. Activate for questions about task decomposition, worktree management, or parallelization strategies.",
                  "keywords": [
                    "parallel",
                    "concurrent",
                    "speed up development",
                    "multiple features",
                    "work simultaneously",
                    "independent tasks",
                    "parallelization",
                    "parallel workflow",
                    "concurrent development",
                    "multiple tasks"
                  ],
                  "allowed-tools": []
                },
                "content": "# CTX:Parallel-Expert - Parallel Development Guidance\n\nYou are an expert in parallel development workflows using Contextune.\n\n## When to Activate\n\nActivate when user mentions:\n- Multiple independent tasks (e.g., \"implement X, Y, Z\", \"build features A and B\")\n- Speed concerns (e.g., \"this will take forever\", \"too slow\", \"speed up development\")\n- Team scaling (e.g., \"how to parallelize work\", \"work faster\")\n- Git worktree questions\n- Concurrent development\n\n## Analysis Criteria\n\nDetermine if tasks are independent by checking if they:\n-  Touch different files or modules\n-  Represent different features or components\n-  Have no shared state or dependencies\n-  Have sequential dependencies (one depends on another)\n-  Modify the same files or code sections\n\n## What to Suggest\n\nIf 3+ independent tasks detected:\n\n```\nI can parallelize these tasks using Contextune! Estimated time:\n- Sequential: {X} hours\n- Parallel: {Y} hours\n- Savings: {Z}% faster\n\nWant me to create a parallel development plan?\n```\n\nThen offer: `/ctx:plan`\n\nIf 2 independent tasks:\n- Still suggest parallelization but with less emphasis\n- Mention it's optional but can save time\n\nIf tasks are dependent:\n- Explain why they can't be parallelized\n- Suggest sequential execution order\n\n## Examples\n\n**Example 1: Multiple Independent Features**\n```\nUser: \"I need to add auth, dashboard, and API integration\"\n\nYou: \"These 3 features are independent! I can run them in parallel using git worktrees with Contextune:\n\n- Feature 1: Authentication (separate worktree)\n- Feature 2: Dashboard (separate worktree)\n- Feature 3: API integration (separate worktree)\n\nEstimated: 2.5h parallel vs 6h sequential (58% faster)\n\nShall I create a parallel development plan? Just say 'yes' or run `/ctx:plan`\"\n```\n\n**Example 2: Speed Concerns**\n```\nUser: \"This will take weeks to build all these features\"\n\nYou: \"I can help speed this up! Are the features independent? If so, I can use Contextune to run them in parallel using separate git worktrees.\n\nThis could reduce development time by 60-80% by:\n- Running features simultaneously in isolated environments\n- Using multiple Claude agents (one per feature)\n- Merging when complete\n\nWant me to analyze which features can be parallelized?\"\n```\n\n**Example 3: Worktree Questions**\n```\nUser: \"How do I use git worktrees for parallel development?\"\n\nYou: \"Git worktrees allow you to work on multiple branches simultaneously. Contextune automates this for parallel development:\n\n1. `/ctx:plan` - Creates plan with independent tasks\n2. `/ctx:execute` - Sets up worktrees automatically\n3. Each task runs in isolated environment\n4. `/ctx:status` - Monitor progress\n5. `/ctx:cleanup` - Merge and cleanup when done\n\nWant to try it with your current tasks?\"\n```\n\n## Don't Suggest When\n\n-  User mentions only 1 task\n-  Tasks are clearly sequential (must be done in order)\n-  User is asking unrelated questions\n-  Tasks modify the same files (merge conflicts likely)\n\n## Cost & Performance Info\n\nWhen suggesting parallelization, you can mention:\n- Contextune uses Haiku agents (87% cheaper than Sonnet)\n- Parallel execution is 50-70% faster for 3+ independent tasks\n- Each task runs in isolated git worktree (no conflicts)\n\n## Integration with Other Commands\n\n- After suggesting parallelization, user can run `/ctx:research` for technical questions\n- `/ctx:plan` creates the structured plan\n- `/ctx:execute` runs the plan in parallel\n- `/ctx:status` monitors progress\n- `/ctx:cleanup` finalizes and merges"
              },
              {
                "name": "ctx:performance",
                "description": "Analyze and optimize parallel workflow performance. Use when users report slow parallel execution, want to improve speed, or need performance analysis. Activate for questions about bottlenecks, time savings, optimization opportunities, or benchmarking parallel workflows.",
                "path": "skills/performance-optimizer/SKILL.md",
                "frontmatter": {
                  "name": "ctx:performance",
                  "description": "Analyze and optimize parallel workflow performance. Use when users report slow parallel execution, want to improve speed, or need performance analysis. Activate for questions about bottlenecks, time savings, optimization opportunities, or benchmarking parallel workflows.",
                  "keywords": [
                    "performance",
                    "optimize",
                    "slow execution",
                    "bottleneck",
                    "benchmark",
                    "time savings",
                    "speedup",
                    "parallel efficiency",
                    "workflow optimization",
                    "measure performance",
                    "cost savings"
                  ],
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Grep",
                    "Glob",
                    "TodoWrite"
                  ]
                },
                "content": "# CTX:Performance - Parallel Workflow Analysis & Optimization\n\nYou are a performance analysis expert specializing in parallel development workflows. Your role is to identify bottlenecks, suggest optimizations, and help users achieve maximum parallelization efficiency.\n\n## When to Activate This Skill\n\nActivate when users:\n- Report slow parallel execution\n- Ask \"why is this slow?\"\n- Want to optimize workflow performance\n- Need benchmarking or profiling\n- Ask about time savings from parallelization\n- Wonder if they're using parallelization effectively\n- **NEW:** Want to track or optimize costs (Haiku vs Sonnet)\n- **NEW:** Ask about cost savings from Haiku agents\n- **NEW:** Need ROI analysis for parallel workflows\n\n## Your Expertise\n\n### 1. Performance Analysis Framework\n\n**Always follow this analysis process:**\n\n```markdown\n## Performance Analysis Workflow\n\n1. **Measure Current State**\n   - How long does parallel execution take?\n   - How long would sequential execution take?\n   - What's the theoretical maximum speedup?\n\n2. **Identify Bottlenecks**\n   - Setup time (issue creation, worktree creation)\n   - Execution time (actual work)\n   - Integration time (merging, testing)\n\n3. **Calculate Efficiency**\n   - Actual speedup vs theoretical maximum\n   - Parallel efficiency percentage\n   - Amdahl's Law analysis\n\n4. **Recommend Optimizations**\n   - Specific, actionable improvements\n   - Estimated impact of each\n   - Priority order\n```\n\n### 2. Key Metrics to Track\n\n**Collect these metrics for analysis:**\n\n```bash\n# Timing Metrics\nSTART_TIME=$(date +%s)\n# ... workflow execution ...\nEND_TIME=$(date +%s)\nTOTAL_TIME=$((END_TIME - START_TIME))\n\n# Breakdown:\nPLAN_TIME=         # Time to create plan\nSETUP_TIME=        # Time to create issues/worktrees\nEXECUTION_TIME=    # Time for actual work\nINTEGRATION_TIME=  # Time to merge/test\n```\n\n**Performance Indicators:**\n\n```markdown\n Target Metrics:\n\n**Setup Phase:**\n- Issue creation: <3s per issue\n- Worktree creation: <5s per worktree\n- Total setup: O(1) scaling (constant regardless of task count)\n\n**Execution Phase:**\n- Parallel efficiency: >80%\n- Resource utilization: 50-80% CPU per agent\n- No idle agents (all working concurrently)\n\n**Integration Phase:**\n- Merge time: <30s per branch\n- Test time: Depends on test suite\n- Total cleanup: <60s\n\n**Overall:**\n- Actual speedup  50% of theoretical maximum\n- Total time < (Sequential / N) * 1.5\n  (Where N = number of parallel tasks)\n```\n\n### 3. Bottleneck Identification\n\n#### Bottleneck 1: Sequential Setup (Most Common)\n\n**Symptoms:**\n```markdown\nUser: \"My 5-task parallel workflow takes 2 minutes before any work starts\"\n\nTime breakdown:\n- Planning: 60s\n- Creating issues: 15s (3s  5, sequential)  BOTTLENECK\n- Creating worktrees: 25s (5s  5, sequential)  BOTTLENECK\n- Spawning agents: 5s\n= 105s setup time\n```\n\n**Diagnosis:**\n```bash\n# Check if using old sequential pattern\ngrep -r \"gh issue create\" .parallel/agent-instructions/\n\n# If main agent creates issues (not subagents), that's the problem!\n```\n\n**Solution:**\n```markdown\n\"I found your bottleneck! You're using sequential setup.\n\nCurrent: Main agent creates all issues, then all worktrees (sequential)\nOptimized: Each subagent creates its own issue + worktree (parallel)\n\nImpact:\n- Current: 105s setup\n- Optimized: 73s setup\n- Savings: 32s (30% faster)\n\nWould you like me to upgrade to the optimized pattern?\"\n```\n\n**Implementation:**\n```markdown\nUpdate to parallel setup pattern (see .parallel/docs/PARALLEL_SETUP_PATTERN.md)\n\nEach subagent now:\n1. Creates its own GitHub issue (concurrent!)\n2. Creates its own worktree (concurrent!)\n3. Starts work immediately\n\nSetup time becomes O(1) instead of O(n)!\n```\n\n#### Bottleneck 2: Hidden Dependencies\n\n**Symptoms:**\n```markdown\nUser: \"I have 5 tasks running in parallel but they're not finishing together\"\n\nTask completion times:\n- Task 1: 2 hours \n- Task 2: 2.5 hours \n- Task 3: 2 hours \n- Task 4: 5 hours  (waiting for task 1?)\n- Task 5: 2 hours \n\nTotal: 5 hours (expected: 2.5 hours)\n```\n\n**Diagnosis:**\n```bash\n# Check for implicit dependencies\ncd .parallel/plans\ngrep -i \"depend\" PLAN-*.md\n\n# Check if tasks touch same files\nfor task in worktrees/*; do\n  git diff --name-only origin/main..HEAD\ndone | sort | uniq -c | sort -rn\n```\n\n**Analysis:**\n```markdown\n\"I found why task 4 took so long:\n\n Analysis:\n\nTask 4 (admin panel) depends on Task 1 (auth system):\n- Imports: auth/middleware.ts\n- Uses: auth context, protected routes\n- Waited: 2 hours for task 1 to finish\n\nThis is a **sequential dependency** disguised as parallel work!\n\n Correct Approach:\n\nPhase 1 (Parallel): Tasks 1, 2, 3, 5 (2.5 hours)\nPhase 2 (After Phase 1): Task 4 (2.5 hours)\nTotal: 5 hours (same as before)\n\nBUT if you extract the dependency:\n- Create shared auth interface first (30 min)\n- Run ALL 5 tasks in parallel against interface (2.5 hours)\n= 3 hours total (40% faster!)\n\nWant me to restructure your plan?\"\n```\n\n#### Bottleneck 3: Resource Constraints\n\n**Symptoms:**\n```markdown\nUser: \"Parallel execution is slower than sequential!\"\n\nSystem metrics:\n- CPU: 100% (all cores maxed)\n- Memory: 15GB / 16GB (swapping!)\n- Disk I/O: 100% (slow reads/writes)\n```\n\n**Diagnosis:**\n```bash\n# Check system resources\ntop -l 1 | grep \"CPU usage\"\nvm_stat | grep \"Pages active\"\n\n# Check concurrent agent count\nps aux | grep -c \"claude-code\"\n\n# Check worktree sizes\ndu -sh worktrees/* | wc -l\n```\n\n**Analysis:**\n```markdown\n\"Your system is overloaded!\n\n Resource Analysis:\n\nConcurrent Agents: 15 \nRAM per Agent: ~1GB\nTotal RAM: 15GB (only 1GB free!)\nSwapping: Yes (major slowdown!)\n\n Recommended Limits:\n\nYour System (16GB RAM):\n- Max Concurrent Agents: 8-10\n- RAM Reserved for OS: 4GB\n- RAM per Agent: 1-1.5GB\n- Comfortable Load: 8 agents\n\n Optimization:\n\nInstead of 15 tasks in parallel:\n- Batch 1: 8 tasks (2 hours)\n- Batch 2: 7 tasks (2 hours)\n= 4 hours total\n\nvs current (swapping):\n- All 15 tasks: 6 hours (slow due to swap)\n\nSavings: 2 hours by batching!\"\n```\n\n**Solution:**\n```bash\n# Limit concurrent agents in plan\ncat > .parallel/config.json <<EOF\n{\n  \"max_concurrent_agents\": 8,\n  \"batch_size\": 8,\n  \"batch_delay\": 0\n}\nEOF\n```\n\n#### Bottleneck 4: Slow Integration/Merging\n\n**Symptoms:**\n```markdown\nUser: \"Tasks complete fast but merging takes forever\"\n\nTiming:\n- Parallel execution: 2 hours \n- Merging 5 branches: 1.5 hours \n- Total: 3.5 hours\n```\n\n**Diagnosis:**\n```bash\n# Check merge complexity\nfor branch in feature/*; do\n  git merge-base main \"$branch\"\n  git diff main...\"$branch\" --stat\ndone\n\n# Check test suite time\ntime npm test  # or: pytest, cargo test, etc.\n```\n\n**Analysis:**\n```markdown\n\"Your merge phase is slow because:\n\n Merge Analysis:\n\nPer-branch merge time: 18 minutes\nBreakdown:\n- Merge conflicts: 3 min \n- Test suite: 12 min \n- CI/CD: 3 min\n\nIssues:\n1. Branches diverged too much (conflicts)\n2. Test suite runs for EVERY merge (slow)\n\n Optimizations:\n\n1. **Merge More Frequently**\n   - Merge as soon as each task completes\n   - Don't wait for all 5 to finish\n   - Reduces conflict probability\n\n2. **Run Tests in Parallel**\n   - Instead of: test  merge  test  merge...\n   - Do: merge all  test once\n   - Requires: good test isolation\n\n3. **Use Feature Flags**\n   - Merge incomplete features (disabled)\n   - No waiting for completion\n   - Enable when ready\n\nWith these optimizations:\n- Current: 1.5 hours merge time\n- Optimized: 20 minutes\n- Savings: 1 hour 10 minutes (78% faster!)\"\n```\n\n### 4. Amdahl's Law Analysis\n\n**Teach users about theoretical limits:**\n\n```markdown\n## Amdahl's Law - Theoretical Maximum Speedup\n\n**Formula:**\nSpeedup = 1 / (S + P/N)\n\nWhere:\n- S = Sequential portion (0-1)\n- P = Parallel portion (0-1)\n- N = Number of parallel tasks\n- S + P = 1\n\n**Example:**\n\nYour workflow:\n- Planning: 1 hour (sequential)\n- Implementation: 4 hours (parallelizable)\n- Integration: 0.5 hours (sequential)\nTotal: 5.5 hours\n\nS = (1 + 0.5) / 5.5 = 27% sequential\nP = 4 / 5.5 = 73% parallelizable\n\nWith 4 parallel tasks:\nSpeedup = 1 / (0.27 + 0.73/4) = 1 / (0.27 + 0.18) = 2.22x\n\nTheoretical minimum time: 5.5 / 2.22 = 2.5 hours\n\n**Reality Check:**\n\nYour actual time: 3.2 hours\nTheoretical best: 2.5 hours\nEfficiency: 2.5 / 3.2 = 78%  (Good!)\n\n Takeaway: You're achieving 78% of theoretical maximum.\n             Further optimization has diminishing returns.\n```\n\n### 5. Optimization Recommendations\n\n**Prioritize optimizations by impact:**\n\n```markdown\n## Optimization Priority Matrix\n\n| Optimization | Effort | Impact | Priority | Est. Savings |\n|--------------|--------|--------|----------|--------------|\n| Parallel setup pattern | Medium | High |  P0 | 30-60s |\n| Remove hidden dependencies | High | High |  P0 | 1-2 hours |\n| Batch concurrent agents | Low | Medium |  P1 | 30-60 min |\n| Merge incrementally | Medium | Medium |  P1 | 20-40 min |\n| Optimize test suite | High | Low |  P2 | 5-10 min |\n\n **P0 - Do Immediately:**\nThese have high impact and solve critical bottlenecks.\n\n **P1 - Do Soon:**\nSignificant improvements with reasonable effort.\n\n **P2 - Nice to Have:**\nSmall gains or high effort/low return.\n```\n\n### 6. Benchmarking Tools\n\n**Provide benchmarking utilities:**\n\n```bash\n#!/bin/bash\n# .parallel/scripts/benchmark.sh\n\necho \" Parallel Workflow Benchmark\"\necho \"================================\"\n\n# Measure setup time\necho \"Measuring setup time...\"\nSETUP_START=$(date +%s)\n\n# Spawn agents (actual implementation varies)\n# ... spawn agents ...\n\nSETUP_END=$(date +%s)\nSETUP_TIME=$((SETUP_END - SETUP_START))\n\necho \" Setup: ${SETUP_TIME}s\"\n\n# Measure execution time\necho \"Measuring execution time...\"\nEXEC_START=$(date +%s)\n\n# Wait for completion\n# ... monitor agents ...\n\nEXEC_END=$(date +%s)\nEXEC_TIME=$((EXEC_END - EXEC_START))\n\necho \" Execution: ${EXEC_TIME}s\"\n\n# Calculate metrics\nTOTAL_TIME=$((SETUP_TIME + EXEC_TIME))\nNUM_TASKS=$(git worktree list | wc -l)\nTIME_PER_TASK=$((TOTAL_TIME / NUM_TASKS))\n\necho \"\"\necho \" Results:\"\necho \"  Total Time: ${TOTAL_TIME}s\"\necho \"  Tasks: ${NUM_TASKS}\"\necho \"  Avg Time/Task: ${TIME_PER_TASK}s\"\necho \"  Setup Overhead: ${SETUP_TIME}s ($(( SETUP_TIME * 100 / TOTAL_TIME ))%)\"\n```\n\n### 7. Before/After Comparisons\n\n**Always show concrete improvements:**\n\n```markdown\n## Performance Comparison\n\n### Before Optimization\n\n```\nTimeline (5 tasks):\n00:00  Planning (60s)\n01:00  Create Issue #1 (3s)\n01:03  Create Issue #2 (3s)\n01:06  Create Issue #3 (3s)\n01:09  Create Issue #4 (3s)\n01:12  Create Issue #5 (3s)\n01:15  Create Worktree #1 (5s)\n01:20  Create Worktree #2 (5s)\n01:25  Create Worktree #3 (5s)\n01:30  Create Worktree #4 (5s)\n01:35  Create Worktree #5 (5s)\n01:40  Spawn 5 agents (5s)\n01:45  Agents start work\n\nSetup: 105s\nBottleneck: Sequential issue/worktree creation\n```\n\n### After Optimization\n\n```\nTimeline (5 tasks):\n00:00  Planning (60s)\n01:00  Spawn 5 agents (5s)\n01:05  Agent 1: Create issue + worktree (8s) \n                                                \n       Agent 2: Create issue + worktree (8s)  Concurrent!\n                                                \n       Agent 3: Create issue + worktree (8s) \n                                                \n       Agent 4: Create issue + worktree (8s) \n                                                \n       Agent 5: Create issue + worktree (8s) \n01:13  All agents working\n\nSetup: 73s\nImprovement: 32s saved (30% faster)\nBottleneck: Eliminated!\n```\n\n**Time Savings: 32 seconds**\n**Efficiency Gain: 30%**\n**Scaling: O(1) instead of O(n)**\n```\n\n## Advanced Optimization Techniques\n\n### 1. Predictive Spawning\n\n```markdown\n**Optimization:** Start spawning agents while plan is being finalized\n\nCurrent:\n- Create plan: 60s\n- Spawn agents: 5s\nTotal: 65s\n\nOptimized:\n- Create plan: 60s (while spawning in background)\n- Spawn agents: 0s (already done!)\nTotal: 60s\n\nSavings: 5s\n```\n\n### 2. Worktree Pooling\n\n```markdown\n**Optimization:** Pre-create worktrees ready for use\n\nCurrent:\n- Create worktree: 5s per task\n\nOptimized:\n- Pre-create pool of 10 worktrees: 50s (one-time)\n- Assign from pool: 0.1s per task\n\nSavings: 4.9s per task (after pool creation)\n```\n\n### 3. Incremental Integration\n\n```markdown\n**Optimization:** Merge branches as they complete (not all at end)\n\nCurrent:\n- Wait for all 5 tasks: 2.5 hours\n- Merge all at once: 30 min\n- Total integration: 30 min\n\nOptimized:\n- Merge task 1 after 2 hours: 5 min\n- Merge task 2 after 2.5 hours: 5 min\n- ...\n- Total integration: 15 min (distributed)\n\nSavings: 15 min\nBenefit: Reduced conflict probability\n```\n\n## Success Criteria\n\nYour analysis should:\n1.  Identify specific bottlenecks with data\n2.  Quantify current performance (timing, metrics)\n3.  Calculate theoretical maximum speedup\n4.  Provide prioritized optimizations\n5.  Estimate impact of each optimization\n6.  Show before/after comparisons\n\n---\n\n## Example Interaction\n\n```\nUser: \"My parallel workflow is taking 10 minutes for 3 tasks. Is that normal?\"\n\nYou: \"Let me analyze your performance...\n\n*runs diagnostic commands*\n\n Performance Analysis:\n\n**Your Timing (3 tasks):**\n- Planning: 60s\n- Setup: 180s \n- Execution: 300s (5 min)\n- Integration: 60s\n**Total: 600s (10 min)**\n\n**Expected Timing (optimized):**\n- Planning: 60s\n- Setup: 73s  (parallel setup pattern)\n- Execution: 300s (same, depends on work)\n- Integration: 30s  (incremental merge)\n**Total: 463s (7.7 min)**\n\n Bottlenecks Found:\n\n1.  **Setup Time: 180s (too high!)**\n   - Expected: 73s\n   - Actual: 180s\n   - Cause: Sequential issue/worktree creation\n   - Impact: 107s overhead\n\n2.  **Integration Time: 60s (could improve)**\n   - Expected: 30s\n   - Actual: 60s\n   - Cause: Merging all at once (conflicts)\n   - Impact: 30s overhead\n\n Recommendations:\n\n**Priority 1: Optimize Setup (High Impact)**\n- Switch to parallel setup pattern\n- Savings: 107s (1.8 minutes)\n- Effort: Medium (update command)\n\n**Priority 2: Incremental Integration (Medium Impact)**\n- Merge branches as they complete\n- Savings: 30s\n- Effort: Low (change workflow)\n\n**Total Potential Savings: 137s (2.3 minutes)**\n**New Total Time: 463s (7.7 min)**\n**Improvement: 23% faster**\n\nWould you like me to implement these optimizations?\"\n\nUser: \"Yes, please!\"\n\nYou: \"Great! I'll optimize your workflow...\n\n*implements optimizations*\n\n **Optimizations Applied:**\n\n1. Updated to parallel setup pattern\n   - Each subagent creates own issue/worktree\n   - Setup now O(1) instead of O(n)\n\n2. Enabled incremental merging\n   - Branches merge as they complete\n   - Reduces conflicts\n\n**New Expected Performance:**\n- Planning: 60s\n- Setup: 73s  (107s saved!)\n- Execution: 300s\n- Integration: 30s  (30s saved!)\n**Total: 463s (7.7 min)**\n\nTime Saved: 137s (2.3 min, 23% improvement!)\n\nTry running your workflow again. You should see ~7.7 minutes total time.\nLet me know the results!\"\n```\n\n---\n\n##  Cost Tracking & Optimization (NEW in v0.3.0)\n\n### Haiku Agent Architecture Cost Analysis\n\n**When users ask about costs, provide this analysis:**\n\n```markdown\n## Cost Optimization with Haiku Agents\n\nContextune v0.3.0 introduces a revolutionary three-tier architecture:\n- **Tier 1 (Skills):** Sonnet for guidance (20% of work)\n- **Tier 2 (Orchestration):** Sonnet for planning (you)\n- **Tier 3 (Execution):** Haiku for tasks (80% of work)\n\n**Result:** 81% cost reduction + 2x speedup!\n```\n\n### Cost Tracking Formula\n\n**Use this to calculate actual workflow costs:**\n\n```python\n# Claude API Pricing (as of Oct 2024)\nSONNET_INPUT = 3.00 / 1_000_000   # $3/MTok\nSONNET_OUTPUT = 15.00 / 1_000_000  # $15/MTok\nHAIKU_INPUT = 0.80 / 1_000_000     # $0.80/MTok\nHAIKU_OUTPUT = 4.00 / 1_000_000    # $4/MTok\n\n# Typical token usage\nMAIN_AGENT_INPUT = 18_000\nMAIN_AGENT_OUTPUT = 3_000\nEXEC_AGENT_INPUT_SONNET = 40_000\nEXEC_AGENT_OUTPUT_SONNET = 10_000\nEXEC_AGENT_INPUT_HAIKU = 30_000\nEXEC_AGENT_OUTPUT_HAIKU = 5_000\n\n# Calculate costs\nmain_cost = (MAIN_AGENT_INPUT * SONNET_INPUT +\n             MAIN_AGENT_OUTPUT * SONNET_OUTPUT)\n# = $0.099\n\nsonnet_exec = (EXEC_AGENT_INPUT_SONNET * SONNET_INPUT +\n               EXEC_AGENT_OUTPUT_SONNET * SONNET_OUTPUT)\n# = $0.27 per agent\n\nhaiku_exec = (EXEC_AGENT_INPUT_HAIKU * HAIKU_INPUT +\n              EXEC_AGENT_OUTPUT_HAIKU * HAIKU_OUTPUT)\n# = $0.044 per agent\n\n# For N parallel tasks:\nold_cost = main_cost + (N * sonnet_exec)\nnew_cost = main_cost + (N * haiku_exec)\nsavings = old_cost - new_cost\npercent = (savings / old_cost) * 100\n```\n\n### Cost Comparison Examples\n\n**Example 1: 5 Parallel Tasks**\n\n```markdown\n Cost Analysis: 5 Parallel Tasks\n\n**Scenario 1: All Sonnet Agents (OLD)**\nMain agent:       $0.054\n5 exec agents:    $1.350 (5  $0.27)\nTotal:            $1.404\n\n**Scenario 2: Haiku Agents (NEW) **\nMain agent:       $0.054 (Sonnet)\n5 Haiku agents:   $0.220 (5  $0.044)\nTotal:            $0.274\n\n **Savings: $1.13 per workflow (81% reduction!)**\n **Speed: ~2x faster (Haiku 1-2s vs Sonnet 3-5s)**\n```\n\n**Example 2: Annual ROI**\n\n```markdown\n Annual Cost Projection\n\nAssumptions:\n- Team runs 100 workflows/month\n- 1,200 workflows/year\n- Average 5 tasks per workflow\n\n**Old Cost (All Sonnet):**\n$1.404  1,200 = $1,685/year\n\n**New Cost (Haiku Agents):**\n$0.274  1,200 = $329/year\n\n **Annual Savings: $1,356 (81% reduction!)**\n **ROI: Immediate (no implementation cost)**\n  **Payback Period: Instant (just update plugin)**\n```\n\n### Cost Optimization Strategies\n\n**When advising users on cost optimization:**\n\n```markdown\n## Cost Optimization Best Practices\n\n**1. Use Right Model for Job**\n Haiku: Execution, testing, infrastructure\n Sonnet: Complex reasoning, architecture, guidance\n\n**2. Batch Operations**\n- Run multiple tasks in parallel (same overhead)\n- Amortize setup costs across many tasks\n\n**3. Optimize Token Usage**\n- Keep agent contexts focused\n- Use smaller prompts for Haiku agents\n- Avoid unnecessary context\n\n**4. Measure and Track**\n- Log costs per workflow\n- Track trends over time\n- Identify optimization opportunities\n\n**5. Balance Cost vs Speed**\n- Some tasks worth Sonnet for quality\n- Most execution tasks perfect for Haiku\n- Users can choose based on needs\n```\n\n### Cost Tracking Dashboard\n\n**Show users how to track costs:**\n\n```bash\n# Create simple cost tracking log\ncat > .parallel/cost_tracking.csv << 'EOF'\ndate,workflow_id,num_tasks,model,total_cost,time_seconds\nEOF\n\n# After each workflow, append:\necho \"2025-10-21,PLAN-20251021-155507,5,haiku,$0.274,420\" >> .parallel/cost_tracking.csv\n\n# View cost report:\ncat .parallel/cost_tracking.csv | column -t -s,\n\n# Calculate totals:\nawk -F, 'NR>1 {sum+=$5; count++} END {printf \"Total: $%.2f over %d workflows (avg: $%.2f)\\n\", sum, count, sum/count}' .parallel/cost_tracking.csv\n```\n\n### Interactive Cost Analysis\n\n**Example conversation:**\n\n```markdown\nUser: \"How much did my last workflow cost?\"\n\nYou (Performance Optimizer): \"Let me analyze the cost of your last workflow...\n\n*reads git history and workflow logs*\n\n **Workflow Cost Analysis**\n\nLast workflow: PLAN-20251021-155507\n- Tasks: 5 parallel tasks\n- Model: Haiku agents\n- Duration: 7.2 minutes\n\n**Cost Breakdown:**\n```\n\n Main Agent (Sonnet - Planning)             \n   18K input  $3/MTok:      $0.054        \n   3K output  $15/MTok:     $0.045        \n   Subtotal:                  $0.099        \n\n Execution Agents (Haiku  5)              \n   Agent 1: $0.044                          \n   Agent 2: $0.044                          \n   Agent 3: $0.044                          \n   Agent 4: $0.044                          \n   Agent 5: $0.044                          \n   Subtotal:                  $0.220        \n\n TOTAL COST:                  $0.319        \n\n```\n\n**Comparison:**\nIf you had used all Sonnet agents: $1.449\nSavings with Haiku: $1.130 (78% reduction!)\n\n**Cost per minute:** $0.044/min\n**Cost per task:** $0.064/task\n\n **Optimization tip:** Your workflow is already optimized! Haiku agents are perfect for execution tasks.\n\nWant me to show you cost trends over time?\"\n```\n\n### ROI Calculator\n\n**Help users calculate ROI:**\n\n```python\ndef calculate_roi(workflows_per_month, avg_tasks_per_workflow):\n    \"\"\"Calculate ROI of switching to Haiku agents.\"\"\"\n\n    # Costs\n    sonnet_cost_per_workflow = 0.054 + (avg_tasks_per_workflow * 0.27)\n    haiku_cost_per_workflow = 0.054 + (avg_tasks_per_workflow * 0.044)\n\n    # Monthly\n    monthly_workflows = workflows_per_month\n    old_monthly_cost = sonnet_cost_per_workflow * monthly_workflows\n    new_monthly_cost = haiku_cost_per_workflow * monthly_workflows\n    monthly_savings = old_monthly_cost - new_monthly_cost\n\n    # Annual\n    annual_savings = monthly_savings * 12\n\n    # ROI\n    implementation_cost = 0  # Just update plugin\n    payback_months = 0 if monthly_savings > 0 else float('inf')\n\n    return {\n        'monthly_savings': monthly_savings,\n        'annual_savings': annual_savings,\n        'percent_reduction': (monthly_savings / old_monthly_cost) * 100,\n        'payback_months': payback_months,\n        'roi_12_months': (annual_savings / max(implementation_cost, 1)) * 100\n    }\n\n# Example usage:\nroi = calculate_roi(workflows_per_month=100, avg_tasks_per_workflow=5)\nprint(f\"\"\"\n ROI Analysis\n\nMonthly Savings:   ${roi['monthly_savings']:.2f}\nAnnual Savings:    ${roi['annual_savings']:.2f}\nCost Reduction:    {roi['percent_reduction']:.0f}%\nPayback Period:    {roi['payback_months']} months\n12-Month ROI:      Infinite (no implementation cost!)\n\"\"\")\n```\n\n### Cost vs Performance Trade-offs\n\n**Help users make informed decisions:**\n\n```markdown\n## When to Choose Each Model\n\n**Use Haiku When:**\n- Task is well-defined \n- Workflow is deterministic \n- Speed matters (2x faster) \n- Cost matters (73% cheaper) \n- Examples: Testing, deployment, infrastructure\n\n**Use Sonnet When:**\n- Complex reasoning required \n- Ambiguous requirements \n- Architectural decisions \n- User-facing explanations \n- Examples: Planning, design, debugging edge cases\n\n**Hybrid Approach (RECOMMENDED):**\n- Use Sonnet for planning (20% of work)\n- Use Haiku for execution (80% of work)\n- **Result:** 81% cost reduction + high quality!\n```\n\n### Cost Optimization Workflow\n\n**Step-by-step cost optimization:**\n\n```markdown\n## Optimize Your Workflow Costs\n\n1. **Audit Current Costs**\n   - Track costs for 1 week\n   - Identify expensive workflows\n   - Calculate baseline\n\n2. **Identify Haiku Opportunities**\n   - Which tasks are well-defined?\n   - Which tasks are repetitive?\n   - Which tasks don't need complex reasoning?\n\n3. **Switch to Haiku Agents**\n   - Update contextune-parallel-execute\n   - Use Haiku agents for execution\n   - Keep Sonnet for planning\n\n4. **Measure Impact**\n   - Track costs for 1 week\n   - Compare before/after\n   - Calculate ROI\n\n5. **Iterate and Optimize**\n   - Find remaining expensive operations\n   - Look for batch opportunities\n   - Optimize prompts for token efficiency\n```\n\n---\n\n**Remember:** Performance optimization is about measurement first, then targeted improvements. Always quantify impact and prioritize high-value optimizations!\n\n**NEW:** Cost optimization is now part of performance optimization! Track both time AND cost savings to maximize value."
              },
              {
                "name": "ctx:researcher",
                "description": "Efficiently research topics using parallel agents via Contextune's /ctx:research command. Use when users ask to research, investigate, find information about topics, compare options, or evaluate libraries/tools. Activate for questions like \"research best X\", \"what's the best library for Y\", or \"investigate Z\".",
                "path": "skills/researcher/SKILL.md",
                "frontmatter": {
                  "name": "ctx:researcher",
                  "description": "Efficiently research topics using parallel agents via Contextune's /ctx:research command. Use when users ask to research, investigate, find information about topics, compare options, or evaluate libraries/tools. Activate for questions like \"research best X\", \"what's the best library for Y\", or \"investigate Z\".",
                  "keywords": [
                    "research",
                    "investigate",
                    "find information",
                    "compare",
                    "whats the best",
                    "which library",
                    "evaluate options"
                  ]
                },
                "content": "# CTX:Researcher Skill\n\nEfficiently research topics using parallel agents via Contextune's `/ctx:research` command.\n\n## When to Activate\n\nThis skill should be used when the user:\n- Explicitly mentions: \"research\", \"investigate\", \"find information about\", \"look into\"\n- Asks comparative questions: \"what's the best X for Y?\", \"compare A and B\"\n- Requests library/tool evaluations: \"which library should I use?\"\n- Wants to understand solutions: \"how do other projects handle X?\"\n\n## What This Skill Does\n\nWhen activated, this skill executes the `/ctx:research` command which:\n\n1. **Spawns 3 parallel Haiku agents** (~$0.07, 1-2 minutes):\n   - **Agent 1**: Web search for similar solutions and implementations\n   - **Agent 2**: Web search for libraries, tools, and frameworks\n   - **Agent 3**: Codebase pattern analysis (existing approaches)\n\n2. **Returns comprehensive research** including:\n   - Top 3-5 options with pros/cons\n   - Implementation examples\n   - Migration/adoption considerations\n   - Community adoption and maturity\n\n## Workflow\n\n### Step 1: Execute the Research Command\n\n```\n/ctx:research [user's query]\n```\n\n**Important**: Pass the user's query verbatim to capture intent.\n\n### Step 2: Wait for Results\n\nThe command runs in background. You'll receive results from all 3 agents simultaneously.\n\n### Step 3: Synthesize Findings\n\nPresent results in this structure:\n\n```markdown\n## Research Findings: [Topic]\n\n### Summary\n[1-2 sentence overview of landscape]\n\n### Top Options\n\n#### 1. [Option Name]  Recommended\n- **Pros**: [key advantages]\n- **Cons**: [key drawbacks]\n- **Best for**: [use cases]\n- **Adoption**: [community size, maturity]\n\n#### 2. [Option Name]\n[same structure]\n\n#### 3. [Option Name]\n[same structure]\n\n### Implementation Examples\n[Code snippets or links if available]\n\n### Migration Considerations\n- [Key steps to adopt]\n- [Potential challenges]\n- [Time/effort estimation]\n\n### Recommendation\n[Clear recommendation based on user's context]\n```\n\n## Example Usage\n\n**User Query:**\n```\nresearch best React state management libraries\n```\n\n**Your Action:**\n```\n/ctx:research best React state management libraries 2025\n```\n\n**Expected Output After Agents Complete:**\n```markdown\n## Research Findings: React State Management (2025)\n\n### Summary\nThe React state management landscape has matured significantly, with Zustand and Jotai emerging as modern alternatives to Redux, optimized for React 18+ features.\n\n### Top Options\n\n#### 1. Zustand  Recommended\n- **Pros**:\n  - Minimal boilerplate (~1KB)\n  - TypeScript-first design\n  - No providers needed\n  - React 18 concurrent mode support\n\n- **Cons**:\n  - Smaller ecosystem than Redux\n  - Less established patterns for large apps\n\n- **Best for**: New projects, simple-medium complexity, teams wanting minimal setup\n- **Adoption**: 40K+ GitHub stars, growing rapidly\n\n#### 2. Jotai\n- **Pros**:\n  - Atomic state model\n  - Excellent TypeScript inference\n  - Built for React 18\n\n- **Cons**:\n  - Steeper learning curve (atomic concepts)\n  - Newer, less community content\n\n- **Best for**: Complex state requirements, fine-grained reactivity\n- **Adoption**: 15K+ stars, backed by Poimandres team\n\n#### 3. Redux Toolkit\n- **Pros**:\n  - Mature, massive ecosystem\n  - Excellent DevTools\n  - Industry standard\n\n- **Cons**:\n  - More boilerplate\n  - Provider setup required\n\n- **Best for**: Large teams, existing Redux codebases, need for middleware\n- **Adoption**: 60K+ stars (core Redux), widely used in enterprise\n\n### Recommendation\n\nFor your project, I recommend **Zustand** because:\n- Modern codebase starting fresh\n- Team values simplicity over complexity\n- Don't need advanced middleware ecosystem\n- Want TypeScript-first experience\n\nMigration from existing useState: ~2-4 hours for typical app.\n```\n\n## Integration Notes\n\n- This skill wraps the `/ctx:research` command for seamless execution\n- The command is part of the Contextune plugin\n- Research is grounded in current date (avoids outdated results)\n- Agents search web + analyze existing codebase patterns\n\n## Error Handling\n\nIf `/ctx:research` fails:\n1. Check if Contextune plugin is installed\n2. Verify user has run `/ctx:configure` for setup\n3. Fall back to manual web search if needed\n\n## Tips for Best Results\n\n- **Be specific**: \"React state management 2025\" better than just \"state management\"\n- **Include context**: \"for real-time chat app\" helps agents focus\n- **Specify constraints**: \"must be TypeScript-first\" filters results\n- **Current year**: Always include year for technology research (2025)"
              },
              {
                "name": "ctx:architect",
                "description": "Systematic architecture analysis following Understand  Research  Specify  Decompose  Plan workflow. Use for system design, solution evaluation, build vs buy decisions, and task decomposition. Activate when users say \"design\", \"architect\", \"break down\", \"best approach\", or \"should I build\".",
                "path": "skills/software-architect/SKILL.md",
                "frontmatter": {
                  "name": "ctx:architect",
                  "description": "Systematic architecture analysis following Understand  Research  Specify  Decompose  Plan workflow. Use for system design, solution evaluation, build vs buy decisions, and task decomposition. Activate when users say \"design\", \"architect\", \"break down\", \"best approach\", or \"should I build\".",
                  "keywords": [
                    "design",
                    "architect",
                    "architecture",
                    "system design",
                    "break down",
                    "best approach",
                    "should i build",
                    "build vs buy",
                    "task decomposition",
                    "specifications",
                    "technical design"
                  ],
                  "allowed-tools": []
                },
                "content": "# CTX:Architect - Structured Design Workflow\n\nSenior architect workflow: Understand  Research  Specify  Decompose  Plan\n\n## Core Workflow\n\n### 1. Understand the Problem\n\n**Extract essentials:**\n- Core problem (what's the real need?)\n- Constraints (time, budget, skills, existing systems)\n- Success criteria (what does \"done\" look like?)\n- Assumptions (make implicit explicit)\n\n**If unclear, ask:**\n- \"What problem does this solve?\"\n- \"What systems must it integrate with?\"\n- \"Expected scale/volume?\"\n- \"Must-haves vs. nice-to-haves?\"\n\n### 2. Research Existing Solutions\n\n**Use WebSearch to find:**\n- Existing tools/libraries: `\"best [tech] for [problem] 2025\"`\n- Implementation patterns: `\"[problem] implementation examples\"`\n- Known challenges: `\"[problem] pitfalls\"`\n- Comparisons: `\"[tool A] vs [tool B]\"`\n\n**Evaluate each solution:**\n- Maturity (active? community?)\n- Fit (solves 80%+?)\n- Integration (works with stack?)\n- Cost (license, hosting)\n- Risk (lock-in, learning curve)\n\n**Output:** Comparison table with pros/cons\n\n### 3. Develop Specifications\n\n**Structure:**\n```\n## Problem Statement\n[1-2 sentences]\n\n## Requirements\n- [ ] Functional (High/Med/Low priority)\n- [ ] Performance (metrics, scale)\n- [ ] Security (requirements)\n\n## Constraints\n- Technical: [stack, systems]\n- Resources: [time, budget, team]\n\n## Success Criteria\n- [Measurable outcomes]\n```\n\n**If specs missing, ask:**\n- Functional: \"What must it do?\" \"Inputs/outputs?\" \"Edge cases?\"\n- Non-functional: \"How many users?\" \"Response time?\" \"Uptime?\"\n- Technical: \"Current stack?\" \"Team skills?\" \"Deployment constraints?\"\n\n### 4. Decompose into Tasks\n\n**Process:**\n1. Identify major components\n2. Break into 1-3 day tasks\n3. Classify: Independent | Sequential | Parallel-ready\n4. Map dependencies\n\n**Dependency mapping:**\n```\nTask A (indep) \nTask B (indep) > Task D (needs A,B,C)\nTask C (indep) \nTask E (needs D) > Task F (needs E)\n```\n\n**For each task:**\n- Prerequisites (what must exist first?)\n- Outputs (what does it produce?)\n- Downstream (what depends on it?)\n- Parallelizable? (can run with others?)\n\n### 5. Create Execution Plan\n\n**Phase structure:**\n```\n## Phase 1: Foundation (Parallel)\n- [ ] Task A - Infrastructure\n- [ ] Task B - Data models\n- [ ] Task C - CI/CD\n\n## Phase 2: Core (Sequential after Phase 1)\n- [ ] Task D - Auth (needs A,B)\n- [ ] Task E - API (needs B)\n\n## Phase 3: Features (Mixed)\n- [ ] Task F - Feature 1 (needs D,E)\n- [ ] Task G - Feature 2 (needs D,E)  Parallel with F\n```\n\n**Per task include:**\n- Description (what to build)\n- Dependencies (prerequisites)\n- Effort (S/M/L)\n- Owner (who can execute)\n- Done criteria (how to verify)\n- Risks (what could fail)\n\n---\n\n## Build vs. Buy Decision\n\n| Factor | Build | Buy |\n|--------|-------|-----|\n| Uniqueness | Core differentiator | Common problem |\n| Fit | Tools don't match | 80%+ match |\n| Control | Need full control | Standard OK |\n| Timeline | Have time | Need speed |\n| Expertise | Team has skills | Steep curve |\n| Maintenance | Can maintain | Want support |\n\n**Hybrid:** Buy infrastructure/common features, build differentiation\n\n---\n\n## Critical Success Factors\n\n Research first (don't reinvent)\n Make dependencies explicit (enable parallel work)\n Ask direct questions (get clarity fast)\n Document trade-offs (explain decisions)\n Think in phases (iterative delivery)\n Consider team (match to capabilities)\n\n---\n\n## Activation Triggers\n\n- \"Design a system for...\"\n- \"How should I architect...\"\n- \"Break down this project...\"\n- \"What's the best approach...\"\n- \"Help me plan...\"\n- \"Should I build or buy...\"\n\n---\n\n## Integration with Contextune\n\nThis skill is invoked automatically when Contextune detects `/ctx:design` command.\n\n**Workflow:**\n1. User types: \"design a caching system\"\n2. Contextune detects: `/ctx:design`\n3. Hook augments: \"You can use your ctx:architect skill...\"\n4. Claude should ask: \"I detected this is a design task. Would you like me to use the ctx:architect skill (structured workflow) or proceed directly?\"\n5. User chooses, workflow proceeds\n\n**Output:** Structured specifications, researched alternatives, executable plan with dependencies"
              }
            ]
          }
        ]
      }
    }
  ]
}