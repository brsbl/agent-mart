{
  "owner": {
    "id": "opendatahub-io",
    "display_name": "Open Data Hub",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/57720972?v=4",
    "url": "https://github.com/opendatahub-io",
    "bio": "Organization for Open Data Hub community",
    "stats": {
      "total_repos": 1,
      "total_plugins": 11,
      "total_commands": 19,
      "total_skills": 19,
      "total_stars": 9,
      "total_forks": 10
    }
  },
  "repos": [
    {
      "full_name": "opendatahub-io/ai-helpers",
      "url": "https://github.com/opendatahub-io/ai-helpers",
      "description": "AI Helpers — collections of plugins for Claude Code, Gemini, and Cursor",
      "homepage": "https://opendatahub-io.github.io/ai-helpers/",
      "signals": {
        "stars": 9,
        "forks": 10,
        "pushed_at": "2026-01-12T13:39:31Z",
        "created_at": "2025-12-03T21:38:06Z",
        "license": "Apache-2.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1824
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/settings.json",
          "type": "blob",
          "size": 721
        },
        {
          "path": ".claudelint-custom.py",
          "type": "blob",
          "size": 10265
        },
        {
          "path": ".claudelint.yaml",
          "type": "blob",
          "size": 1381
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/ISSUE_TEMPLATE",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/ISSUE_TEMPLATE/01_claude_plugin_request.md",
          "type": "blob",
          "size": 1150
        },
        {
          "path": ".github/ISSUE_TEMPLATE/02_cursor_command_request.md",
          "type": "blob",
          "size": 1002
        },
        {
          "path": ".github/ISSUE_TEMPLATE/03_gemini_gem_request.md",
          "type": "blob",
          "size": 1140
        },
        {
          "path": ".github/ISSUE_TEMPLATE/04_bug_report.md",
          "type": "blob",
          "size": 1289
        },
        {
          "path": ".github/ISSUE_TEMPLATE/05_documentation_improvement.md",
          "type": "blob",
          "size": 988
        },
        {
          "path": ".github/ISSUE_TEMPLATE/06_category_request.md",
          "type": "blob",
          "size": 1128
        },
        {
          "path": ".github/ISSUE_TEMPLATE/07_idea_request.md",
          "type": "blob",
          "size": 1214
        },
        {
          "path": ".github/ISSUE_TEMPLATE/config.yml",
          "type": "blob",
          "size": 621
        },
        {
          "path": ".github/dependabot.yml",
          "type": "blob",
          "size": 399
        },
        {
          "path": ".github/labels.yml",
          "type": "blob",
          "size": 2803
        },
        {
          "path": ".github/pull_request_template.md",
          "type": "blob",
          "size": 2233
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/build.yml",
          "type": "blob",
          "size": 1522
        },
        {
          "path": ".github/workflows/deploy.yml",
          "type": "blob",
          "size": 1161
        },
        {
          "path": ".github/workflows/lint.yml",
          "type": "blob",
          "size": 613
        },
        {
          "path": ".github/workflows/sync-labels.yml",
          "type": "blob",
          "size": 473
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 462
        },
        {
          "path": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1094
        },
        {
          "path": "AGENTS.md",
          "type": "blob",
          "size": 5640
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 9
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "Makefile",
          "type": "blob",
          "size": 2609
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 10906
        },
        {
          "path": "TOOLS.md",
          "type": "blob",
          "size": 8669
        },
        {
          "path": "categories.json",
          "type": "blob",
          "size": 1152
        },
        {
          "path": "claude-external-plugin-sources.json",
          "type": "blob",
          "size": 304
        },
        {
          "path": "claude-plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/README.md",
          "type": "blob",
          "size": 3671
        },
        {
          "path": "claude-plugins/aipcc",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/aipcc/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/aipcc/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 182
        },
        {
          "path": "claude-plugins/aipcc/README.md",
          "type": "blob",
          "size": 1846
        },
        {
          "path": "claude-plugins/aipcc/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/aipcc/commands/commit-suggest.md",
          "type": "blob",
          "size": 6106
        },
        {
          "path": "claude-plugins/git",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/git/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/git/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 159
        },
        {
          "path": "claude-plugins/git/README.md",
          "type": "blob",
          "size": 237
        },
        {
          "path": "claude-plugins/git/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/git/skills/shallow-clone",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/git/skills/shallow-clone/SKILL.md",
          "type": "blob",
          "size": 915
        },
        {
          "path": "claude-plugins/git/skills/shallow-clone/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/git/skills/shallow-clone/scripts/shallow-clone.sh",
          "type": "blob",
          "size": 736
        },
        {
          "path": "claude-plugins/gitlab",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/gitlab/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/gitlab/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 162
        },
        {
          "path": "claude-plugins/gitlab/README.md",
          "type": "blob",
          "size": 485
        },
        {
          "path": "claude-plugins/gitlab/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/gitlab/skills/pipeline-debugger",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/gitlab/skills/pipeline-debugger/SKILL.md",
          "type": "blob",
          "size": 2682
        },
        {
          "path": "claude-plugins/gitlab/skills/pipeline-debugger/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/gitlab/skills/pipeline-debugger/scripts/check_pipeline.py",
          "type": "blob",
          "size": 10367
        },
        {
          "path": "claude-plugins/hello-world",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/hello-world/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/hello-world/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 133
        },
        {
          "path": "claude-plugins/hello-world/README.md",
          "type": "blob",
          "size": 810
        },
        {
          "path": "claude-plugins/hello-world/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/hello-world/commands/echo.md",
          "type": "blob",
          "size": 1492
        },
        {
          "path": "claude-plugins/jira",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/jira/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/jira/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 159
        },
        {
          "path": "claude-plugins/jira/README.md",
          "type": "blob",
          "size": 512
        },
        {
          "path": "claude-plugins/jira/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/jira/commands/sprint-summary.md",
          "type": "blob",
          "size": 3101
        },
        {
          "path": "claude-plugins/jira/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/jira/skills/upload-chat-log",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/jira/skills/upload-chat-log/SKILL.md",
          "type": "blob",
          "size": 4263
        },
        {
          "path": "claude-plugins/jira/skills/upload-chat-log/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/jira/skills/upload-chat-log/scripts/upload_chat_log.py",
          "type": "blob",
          "size": 4520
        },
        {
          "path": "claude-plugins/konflux",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/konflux/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/konflux/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 169
        },
        {
          "path": "claude-plugins/konflux/README.md",
          "type": "blob",
          "size": 3740
        },
        {
          "path": "claude-plugins/konflux/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/konflux/commands/application.md",
          "type": "blob",
          "size": 2330
        },
        {
          "path": "claude-plugins/konflux/commands/component.md",
          "type": "blob",
          "size": 8717
        },
        {
          "path": "claude-plugins/python-packaging",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 178
        },
        {
          "path": "claude-plugins/python-packaging/README.md",
          "type": "blob",
          "size": 4204
        },
        {
          "path": "claude-plugins/python-packaging/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/agents/investigator.md",
          "type": "blob",
          "size": 8889
        },
        {
          "path": "claude-plugins/python-packaging/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/complexity",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/complexity/SKILL.md",
          "type": "blob",
          "size": 4652
        },
        {
          "path": "claude-plugins/python-packaging/skills/complexity/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/complexity/scripts/pypi_inspect.py",
          "type": "blob",
          "size": 16419
        },
        {
          "path": "claude-plugins/python-packaging/skills/env-finder",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/env-finder/SKILL.md",
          "type": "blob",
          "size": 3297
        },
        {
          "path": "claude-plugins/python-packaging/skills/env-finder/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/env-finder/scripts/env_finder.py",
          "type": "blob",
          "size": 18957
        },
        {
          "path": "claude-plugins/python-packaging/skills/license-checker",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/license-checker/SKILL.md",
          "type": "blob",
          "size": 4990
        },
        {
          "path": "claude-plugins/python-packaging/skills/license-finder",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/license-finder/SKILL.md",
          "type": "blob",
          "size": 3001
        },
        {
          "path": "claude-plugins/python-packaging/skills/license-finder/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/license-finder/scripts/find_license.py",
          "type": "blob",
          "size": 3382
        },
        {
          "path": "claude-plugins/python-packaging/skills/source-finder",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/source-finder/SKILL.md",
          "type": "blob",
          "size": 1281
        },
        {
          "path": "claude-plugins/python-packaging/skills/source-finder/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/python-packaging/skills/source-finder/scripts/finder.py",
          "type": "blob",
          "size": 5696
        },
        {
          "path": "claude-plugins/rpm",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/rpm/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/rpm/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 133
        },
        {
          "path": "claude-plugins/rpm/README.md",
          "type": "blob",
          "size": 260
        },
        {
          "path": "claude-plugins/rpm/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/rpm/commands/examine.md",
          "type": "blob",
          "size": 5563
        },
        {
          "path": "claude-plugins/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/utils/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/utils/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 211
        },
        {
          "path": "claude-plugins/utils/README.md",
          "type": "blob",
          "size": 825
        },
        {
          "path": "claude-plugins/utils/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/utils/commands/placeholder.md",
          "type": "blob",
          "size": 865
        },
        {
          "path": "claude-plugins/vllm",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vllm/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vllm/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 132
        },
        {
          "path": "claude-plugins/vllm/README.md",
          "type": "blob",
          "size": 437
        },
        {
          "path": "claude-plugins/vllm/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vllm/skills/vllm-slack-summary",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vllm/skills/vllm-slack-summary/README.md",
          "type": "blob",
          "size": 2764
        },
        {
          "path": "claude-plugins/vllm/skills/vllm-slack-summary/SKILL.md",
          "type": "blob",
          "size": 2121
        },
        {
          "path": "claude-plugins/vllm/skills/vllm-slack-summary/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vllm/skills/vllm-slack-summary/scripts/generate_transcript.py",
          "type": "blob",
          "size": 15809
        },
        {
          "path": "cursor",
          "type": "tree",
          "size": null
        },
        {
          "path": "cursor/README.md",
          "type": "blob",
          "size": 1746
        },
        {
          "path": "cursor/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "cursor/commands/aipcc-commit-suggest.md",
          "type": "blob",
          "size": 53
        },
        {
          "path": "cursor/commands/jira-sprint-summary.md",
          "type": "blob",
          "size": 52
        },
        {
          "path": "cursor/commands/konflux-application.md",
          "type": "blob",
          "size": 52
        },
        {
          "path": "cursor/commands/konflux-component.md",
          "type": "blob",
          "size": 50
        },
        {
          "path": "cursor/commands/rpm-examine.md",
          "type": "blob",
          "size": 44
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/README.md",
          "type": "blob",
          "size": 1299
        },
        {
          "path": "docs/data.json",
          "type": "blob",
          "size": 16745
        },
        {
          "path": "docs/index.html",
          "type": "blob",
          "size": 78959
        },
        {
          "path": "gemini-gems",
          "type": "tree",
          "size": null
        },
        {
          "path": "gemini-gems/README.md",
          "type": "blob",
          "size": 2122
        },
        {
          "path": "gemini-gems/gems.yaml",
          "type": "blob",
          "size": 1466
        },
        {
          "path": "images",
          "type": "tree",
          "size": null
        },
        {
          "path": "images/claude",
          "type": "tree",
          "size": null
        },
        {
          "path": "images/claude/Containerfile",
          "type": "blob",
          "size": 1726
        },
        {
          "path": "images/claude/claude-settings.json",
          "type": "blob",
          "size": 591
        },
        {
          "path": "images/claude/known_marketplaces.json",
          "type": "blob",
          "size": 202
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/build-website.py",
          "type": "blob",
          "size": 22741
        },
        {
          "path": "scripts/generate_tools_docs.py",
          "type": "blob",
          "size": 15945
        },
        {
          "path": "scripts/update_claude_settings.py",
          "type": "blob",
          "size": 6936
        }
      ],
      "marketplace": {
        "name": "odh-ai-helpers",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "ODH"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "aipcc",
            "description": "Tools specifically designed for AIPCC workflows and processes",
            "source": "./claude-plugins/aipcc",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install aipcc@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/commit-suggest",
                "description": "Generate AIPCC Commits style commit messages or summarize existing commits",
                "path": "claude-plugins/aipcc/commands/commit-suggest.md",
                "frontmatter": {
                  "description": "Generate AIPCC Commits style commit messages or summarize existing commits",
                  "argument-hint": [
                    "N"
                  ]
                },
                "content": "## Name\naipcc:commit-suggest\n\n## Synopsis\n```\n/aipcc:commit-suggest       # Analyze staged changes\n/aipcc:commit-suggest [N]     # Analyze last N commits (1-100)\n```\n\n## Description\nAI-powered command that analyzes code changes and generates commit messages following the project's AIPCC format requirements.\n\n**Modes:**\n- **Mode 1 (no argument)** – Analyze staged changes (`git add` required)\n- **Mode 2 (with N)** – Analyze last N commits to rewrite (N=1) or summarize for squash (N≥2)\n\n**Use cases:**\n- Create AIPCC-formatted commit messages\n- Improve or rewrite existing commits to meet project standards\n- Generate squash messages for MR merges\n\n**Difference from `/git:summary`** – That command is read-only, while `aipcc:commit-suggest` generates actionable commit message suggestions for user review and manual use.\n\n## Implementation\n\nThe command operates in two modes based on input:\n\n**Mode 1 (no argument):**\n1. Collect staged changes via `git diff --cached`\n2. Analyze file paths and code content to determine appropriate AIPCC ticket reference\n3. Generate 3 AIPCC-formatted commit message suggestions (Recommended, Standard, Minimal)\n4. Display formatted suggestions and prompt user for selection\n   - Ask: \"Which suggestion would you like to use? (1/2/3 or skip)\"\n   - Support responses: `1`, `use option 2`, `commit with option 3`, `skip`\n   - Execute `git commit -s` with selected message if user requests (includes sign-off)\n\n**Mode 2 (with N):**\n1. Retrieve last N commits using `git log`\n2. Parse commit messages and analyze changes to maintain AIPCC format consistency\n3. For **N=1**: Suggest improved rewrite following AIPCC format\n   For **N≥2**: Merge commits into unified AIPCC-formatted squash message\n4. Generate 3 AIPCC-formatted commit message suggestions (Recommended, Standard, Minimal)\n5. Display formatted suggestions and prompt user for selection\n   - Ask: \"Which suggestion would you like to use? (1/2/3 or skip)\"\n   - Support responses: `1`, `use option 2`, `amend with option 3`, `skip`\n   - Execute `git commit --amend -s` (N=1) or squash operation (N≥2) if user requests\n\n## Examples\n\n```bash\n# Generate message for staged files\ngit add src/auth.ts src/middleware.ts\n/aipcc:commit-suggest\n\n# Rewrite last commit message\n/aipcc:commit-suggest 1\n\n# Summarize last 5 commits for squash\n/aipcc:commit-suggest 5\n```\n\n## Return Value\n\nGenerates 3 AIPCC-formatted commit message suggestions:\n- **Suggestion #1 (Recommended)** – Detailed with full body and Jira integration\n- **Suggestion #2 (Standard)** – Concise with essential information\n- **Suggestion #3 (Minimal)** – Brief description with required elements\n\nEach suggestion includes:\n- AIPCC format title (`AIPCC-XXX: description`)\n- Blank line between title and body\n- Body text explaining the changes in complete sentences\n- Optional Jira integration (`Fixes AIPCC-XXX`)\n- Required sign-off line\n\n**Example:**\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nSuggestion #1 (Recommended)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nAIPCC-123: Add JWT authentication middleware\n\nImplement token-based authentication for API endpoints to enhance\nsecurity. The middleware verifies JWT tokens and extracts user\ninformation for authorization decisions.\n\nFixes AIPCC-123\n\nCo-Authored-By: [AI_NAME] ([AI_MODEL])\n\nSigned-off-by: Your Name <your.email@example.com>\n\nWhich suggestion would you like to use? (1/2/3 or skip)\n```\n\n### Mode 2 Specifics\n\n- **N=1** – Suggest improved rewrite for the last commit in AIPCC format\n- **N≥2** – Generate unified AIPCC-formatted squash message with footer: `Squashed from N commits:` + original commit list\n\n## Commit Message Format Requirements\n\n### AIPCC Format\nAll commits must follow this project-specific format:\n```\nAIPCC-XXX: Short description\n\nLonger explanation of what the commit does, written in at least one\ncomplete sentence explaining the purpose and impact of the change.\n\n[Optional: Fixes AIPCC-XXX]\n\n[Optional: Co-Authored-By: [AI_NAME] ([AI_MODEL])]\n\nSigned-off-by: Your Name <your.email@example.com>\n```\n\n### Required Elements\n- **Title**: Must start with \"AIPCC-XXX:\" followed by a short description\n- **Body**: Must explain what the commit does in at least one complete sentence\n- **Sign-off**: All commits must include `Signed-off-by` line (use `git commit -s`)\n\n### Optional Elements\n- **Jira Integration**: Include \"Fixes AIPCC-XXX\" in the body to automatically close the Jira ticket when MR merges\n- **Co-authors**: `Co-Authored-By: Name <email@example.com>`\n- **AI Attribution**: `Co-Authored-By: [AI_NAME] ([AI_MODEL])` when AI assists with code generation\n- **Breaking Changes**: Note significant API changes in the body\n\n### Examples\n```\nAIPCC-456: Fix memory leak in authentication service\n\nResolve memory leak caused by unclosed database connections in the\nauth service. This improves server stability under high load.\n\nFixes AIPCC-456\n\nCo-Authored-By: [AI_NAME] ([AI_MODEL])\n\nSigned-off-by: Jane Developer <jane@example.com>\n```\n\n```\nAIPCC-789: Add user profile management API\n\nImplement REST endpoints for user profile CRUD operations.\nIncludes validation, error handling, and comprehensive test coverage.\n\nCo-Authored-By: [AI_NAME] ([AI_MODEL])\n\nSigned-off-by: John Developer <john@example.com>\n```\n\n## Arguments\n\n- **[N]** (optional): Number of recent commits to analyze (1-100)\n  - If omitted: Analyzes staged changes (Mode 1)\n  - If N=1: Suggests improved rewrite for the last commit\n  - If N≥2: Generates unified squash message for last N commits\n\n## See Also\n- **`/git:summary`** – Display repository status and recent commits (read-only)\n- **AIPCC Project Guidelines** – Internal project commit format requirements\n- [Conventional Commits Specification](https://www.conventionalcommits.org/) – General industry standard (adapted for AIPCC format)"
              }
            ],
            "skills": []
          },
          {
            "name": "git",
            "description": "Git workflow automation and utilities",
            "source": "./claude-plugins/git",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install git@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "shallow-clone",
                "description": "Perform a shallow clone of a Git repository to a temporary location.",
                "path": "claude-plugins/git/skills/shallow-clone/SKILL.md",
                "frontmatter": {
                  "name": "shallow-clone",
                  "description": "Perform a shallow clone of a Git repository to a temporary location.",
                  "allowed-tools": [
                    "Bash"
                  ]
                },
                "content": "# Shallow Clone\n\nProvides a script for creating a shallow clone of a Git repository to a temporary location. This skill should be used\nto analyze repository contents locally instead of using web APIs.\n\n## Usage\n\nUse the `scripts/shallow-clone.sh` script in this directory, for example:\n\n```bash\n./scripts/shallow-clone.sh <repository_url> [<tag_or_branch>]\n```\n\nThe script will print the path to the cloned repository when done, for example:\n\n```shell\n$ ./scripts/shallow-clone.sh https://github.com/psf/requests.git\nCloning https://github.com/psf/requests.git (shallow, ref: HEAD) to /tmp/shallow-clone-DDqkuv...\n/tmp/shallow-clone-DDqkuv/repo\n```\n\nAfter analyzing the local repository, clean up the temporary directory with:\n\n```shell\n$ rm -rf <path_to_temporary_directory>\n```"
              },
              {
                "name": "pipeline-debugger",
                "description": "Debug and monitor GitLab CI/CD pipelines for merge requests. Check pipeline status, view job logs, and troubleshoot CI failures. Use this when the user needs to investigate GitLab CI pipeline issues, check job statuses, or view specific job logs.",
                "path": "claude-plugins/gitlab/skills/pipeline-debugger/SKILL.md",
                "frontmatter": {
                  "name": "pipeline-debugger",
                  "description": "Debug and monitor GitLab CI/CD pipelines for merge requests. Check pipeline status, view job logs, and troubleshoot CI failures. Use this when the user needs to investigate GitLab CI pipeline issues, check job statuses, or view specific job logs.",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# GitLab CI Debugger\n\nThis skill enables Claude to investigate GitLab CI pipeline failures by:\n\n1. Checking the current pipeline status for a branch, merge request, or a specific pipeline ID\n2. Identifying failed jobs\n3. Retrieving failed job logs\n4. Analyzing error messages and suggesting fixes\n\n## Prerequisites\n\n- Git repository with GitLab remote configured\n- GitLab authentication via GITLAB_TOKEN env var or .netrc file\n\nThe script will fail if it detects any missing configuration. Interpret the error message and provide instructions\nfor setting up the required configuration.\n\n## Instructions\n\n**IMPORTANT**: Always run the script from the user's current working directory (where Claude was launched), NOT from the\nskill directory. The script needs access to the git repository context. Use the base directory (`<base_path>`) for this\nskill to execute the script with an absolute path.\n\nWhen the user asks to check CI status, debug pipeline failures, or view job logs:\n\n1. **Check Current Pipeline Status**\n    - Run `<base_path>/scripts/check_pipeline.py` without arguments to check the current branch's pipeline status\n    - The script will display all jobs grouped by stage with status indicators\n\n2. **Check Specific Branch**\n    - If the user asks to check on the pipeline status for a different branch than the current one, use the `-b` or\n      `--branch` option to specify that branch.\n        - Example: `<base_path>/scripts/check_pipeline.py -b feature-branch`\n\n3. **Check Specific Pipeline by ID**\n    - If the user provides a pipeline ID directly, use the `-p` or `--pipeline-id` option to inspect that pipeline\n    - This skips the merge request lookup and directly inspects the specified pipeline\n    - Example: `<base_path>/scripts/check_pipeline.py -p 12519874995`\n    - Note: `--pipeline-id` and `--branch` are mutually exclusive\n\n4. **View Job Logs**\n    - Use the `-j` or `--job` option to retrieve and display logs for a specific job\n    - Example: `<base_path>/scripts/check_pipeline.py -j \"test-job-name\"`\n    - Can be combined with any of the above options (branch, pipeline ID, or current branch)\n    - The script will show the job's metadata and full log output\n\n5. **Troubleshoot CI Failures**\n    - If the user asks to troubleshoot a CI failure, use the full log output of a job to identify the error and suggest\n      fixes."
              }
            ]
          },
          {
            "name": "gitlab",
            "description": "Tools and skills for interacting with GitLab resources",
            "source": "./claude-plugins/gitlab",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install gitlab@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "pipeline-debugger",
                "description": "Debug and monitor GitLab CI/CD pipelines for merge requests. Check pipeline status, view job logs, and troubleshoot CI failures. Use this when the user needs to investigate GitLab CI pipeline issues, check job statuses, or view specific job logs.",
                "path": "claude-plugins/gitlab/skills/pipeline-debugger/SKILL.md",
                "frontmatter": {
                  "name": "pipeline-debugger",
                  "description": "Debug and monitor GitLab CI/CD pipelines for merge requests. Check pipeline status, view job logs, and troubleshoot CI failures. Use this when the user needs to investigate GitLab CI pipeline issues, check job statuses, or view specific job logs.",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# GitLab CI Debugger\n\nThis skill enables Claude to investigate GitLab CI pipeline failures by:\n\n1. Checking the current pipeline status for a branch, merge request, or a specific pipeline ID\n2. Identifying failed jobs\n3. Retrieving failed job logs\n4. Analyzing error messages and suggesting fixes\n\n## Prerequisites\n\n- Git repository with GitLab remote configured\n- GitLab authentication via GITLAB_TOKEN env var or .netrc file\n\nThe script will fail if it detects any missing configuration. Interpret the error message and provide instructions\nfor setting up the required configuration.\n\n## Instructions\n\n**IMPORTANT**: Always run the script from the user's current working directory (where Claude was launched), NOT from the\nskill directory. The script needs access to the git repository context. Use the base directory (`<base_path>`) for this\nskill to execute the script with an absolute path.\n\nWhen the user asks to check CI status, debug pipeline failures, or view job logs:\n\n1. **Check Current Pipeline Status**\n    - Run `<base_path>/scripts/check_pipeline.py` without arguments to check the current branch's pipeline status\n    - The script will display all jobs grouped by stage with status indicators\n\n2. **Check Specific Branch**\n    - If the user asks to check on the pipeline status for a different branch than the current one, use the `-b` or\n      `--branch` option to specify that branch.\n        - Example: `<base_path>/scripts/check_pipeline.py -b feature-branch`\n\n3. **Check Specific Pipeline by ID**\n    - If the user provides a pipeline ID directly, use the `-p` or `--pipeline-id` option to inspect that pipeline\n    - This skips the merge request lookup and directly inspects the specified pipeline\n    - Example: `<base_path>/scripts/check_pipeline.py -p 12519874995`\n    - Note: `--pipeline-id` and `--branch` are mutually exclusive\n\n4. **View Job Logs**\n    - Use the `-j` or `--job` option to retrieve and display logs for a specific job\n    - Example: `<base_path>/scripts/check_pipeline.py -j \"test-job-name\"`\n    - Can be combined with any of the above options (branch, pipeline ID, or current branch)\n    - The script will show the job's metadata and full log output\n\n5. **Troubleshoot CI Failures**\n    - If the user asks to troubleshoot a CI failure, use the full log output of a job to identify the error and suggest\n      fixes."
              }
            ]
          },
          {
            "name": "hello-world",
            "description": "A hello world plugin",
            "source": "./claude-plugins/hello-world",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install hello-world@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/echo",
                "description": "Hello world plugin implementation",
                "path": "claude-plugins/hello-world/commands/echo.md",
                "frontmatter": {
                  "description": "Hello world plugin implementation",
                  "argument-hint": [
                    "name"
                  ]
                },
                "content": "## Name\nhello-world:echo\n\n## Synopsis\n```\n/hello-world:echo [name]\n```\n\n## Description\nThe `hello-world:echo` command prints a greeting message to the console. By default, it prints \"Hello world\", but when provided with a name argument `hello-world:echo $1`, it prints \"Hello ${1}\". This command serves as a basic example of a Claude Code plugin implementation, demonstrating the minimal structure required for a functional plugin command.\n\nIt provides a reference implementation for plugin developers. It demonstrates:\n- Basic command structure\n- Shell command execution within a plugin\n- Handling arguments\n- Minimal configuration requirements\n\nThe spec sections is inspired by https://man7.org/linux/man-pages/man7/man-pages.7.html#top_of_page\n\n## Implementation\n- The command executes a simple bash `echo` statement\n- Accepts an optional name argument (`$1`)\n- If `$1` is provided, outputs \"Hello $1\"\n- If no argument is provided, outputs \"Hello world\"\n- Output is sent directly to standard output\n- The command is stateless and has no side effects\n\n## Examples\n\n1. **Basic usage (no arguments)**:\n   ```\n   /hello-world:echo\n   ```\n   Output:\n   ```\n   Hello world\n   ```\n\n2. **With a name argument**:\n   ```\n   /hello-world:echo Alice\n   ```\n   Output:\n   ```\n   Hello Alice\n   ```\n\n3. **With multiple words as name**:\n   ```\n   /hello-world:echo \"John Doe\"\n   ```\n   Output:\n   ```\n   Hello John Doe\n   ```"
              }
            ],
            "skills": []
          },
          {
            "name": "jira",
            "description": "Jira workflow automation and utilities",
            "source": "./claude-plugins/jira",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install jira@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/sprint-summary",
                "description": "Generate comprehensive sprint summaries by analyzing JIRA sprint data, including issue breakdown, progress metrics, and team performance insights.",
                "path": "claude-plugins/jira/commands/sprint-summary.md",
                "frontmatter": {
                  "argument-hint": "<sprint-name> [options]",
                  "description": "Generate comprehensive sprint summaries by analyzing JIRA sprint data, including issue breakdown, progress metrics, and team performance insights."
                },
                "content": "## Name\njira:sprint-summary\n\n## Synopsis\n```\n/jira:sprint-summary <sprint-name> [options]\n```\n\n## Description\nGenerate comprehensive sprint summaries by analyzing JIRA sprint data, including issue breakdown, progress metrics, and team performance insights. This command provides data-driven insights for sprint retrospectives, stakeholder reporting, and process improvement.\n\n## Parameters\n- `sprint-name`: The exact name or identifier of the sprint (required)\n- `[options]`: Optional flags for customizing output (see Options section)\n\n## Prerequisites\n- JIRA MCP server must be configured and accessible\n- Appropriate JIRA permissions to access sprint and issue data\n- Valid sprint name that exists in the configured JIRA instance\n\n## Implementation\n\n### Core Features\n1. **Sprint Overview**: Retrieve basic sprint information (dates, status, goals)\n2. **Issue Analysis**: Categorize and analyze all issues in the sprint by:\n   - Issue type (Story, Bug, Task, Epic, etc.)\n   - Status (To Do, In Progress, Done, etc.)\n   - Priority levels\n   - Assignee distribution\n3. **Progress Metrics**: Calculate completion rates, velocity, and burndown data\n4. **Team Insights**: Analyze workload distribution and individual contributions\n5. **Quality Metrics**: Identify blocked issues, overdue items, and technical debt\n\n### Error Handling\n- **Missing JIRA Configuration**: If JIRA MCP server is not configured or not working, provide clear setup instructions and troubleshooting steps\n- **Missing Sprint Name**: If no sprint name provided, prompt for required parameter with examples\n- **Invalid Sprint**: If sprint doesn't exist, suggest similar sprint names or provide guidance on finding correct sprint identifiers\n- **Permission Issues**: Handle authentication and authorization errors gracefully with actionable feedback\n\n### Output Format\nGenerate a structured markdown report including:\n- Executive summary with key metrics\n- Sprint overview (dates, goals, team members)\n- Issue breakdown tables and charts\n- Progress visualization (completion rates, velocity trends)\n- Risk assessment (blocked items, potential delays)\n- Recommendations for sprint improvement\n\n## Options\n- `--format`: Output format (markdown, json, csv) - default: markdown\n- `--include-subtasks`: Include subtasks in analysis - default: false\n- `--detailed`: Generate detailed issue-by-issue breakdown - default: false\n- `--export`: Save summary to file with timestamp - default: false\n\n## Usage Scenarios\n- **Sprint Retrospectives**: Generate data-driven insights for team retrospective meetings\n- **Stakeholder Reporting**: Create executive summaries for leadership updates\n- **Performance Tracking**: Monitor team velocity and delivery consistency over time\n- **Process Improvement**: Identify bottlenecks and areas for workflow optimization\n- **Planning Sessions**: Use historical data to inform future sprint planning"
              }
            ],
            "skills": [
              {
                "name": "upload-chat-log",
                "description": "Export and upload the current chat conversation as a markdown file attachment to a JIRA ticket for later review and documentation.",
                "path": "claude-plugins/jira/skills/upload-chat-log/SKILL.md",
                "frontmatter": {
                  "name": "upload-chat-log",
                  "description": "Export and upload the current chat conversation as a markdown file attachment to a JIRA ticket for later review and documentation."
                },
                "content": "# Upload Chat Log to JIRA\n\nExport and upload the current chat conversation as a markdown file attachment to a JIRA ticket for later review and documentation.\n\n## Prerequisites\n\n- Python 3 and `uv` must be installed and available in PATH\n- `JIRA_API_TOKEN` environment variable must be set with a valid API token for https://issues.redhat.com\n- Appropriate JIRA permissions to add attachments to the target ticket\n\n## Usage\n\nThis skill exports the current conversation as a formatted markdown document and uploads it as an attachment to a specified JIRA ticket.\n\n## Implementation\n\n### Step 1: Determine the Ticket Key\n\n1. If a ticket key is provided by the user, use it\n2. Otherwise, search the conversation history for JIRA ticket references (e.g., \"AIPCC-1234\", \"working on PROJ-567\")\n3. If no ticket is found in context, ask the user: \"Which JIRA ticket should I attach this chat log to? (e.g., AIPCC-1234)\"\n\n### Step 2: Format the Conversation with Summary and Full Transcript\n\nCreate a document with two main sections: Summary and Full Chat Log. Format the document as follows:\n\n```markdown\n# Chat Log Export - JIRA Ticket: [ticket-key]\n\n**Exported**: [current timestamp]\n**Ticket**: https://issues.redhat.com/browse/[ticket-key]\n\n---\n\n## Summary\n\n[Provide a concise summary of the conversation including:\n- Main topic/task discussed\n- Key decisions made\n- Files created/modified\n- Important outcomes or next steps\n- 3-5 paragraphs maximum]\n\n---\n\n## Full Chat Transcript\n\n[Export the complete conversation transcript in the same format as the `/export` command:\n- All user messages and assistant responses\n- All tool calls and their results\n- Code blocks, thinking blocks, and system messages\n- Timestamps and metadata\n- The full, unabridged conversation from start to finish]\n```\n\nThe summary should be human-readable and highlight key points. The full transcript should be comprehensive for detailed review.\n\n### Step 3: Save to Temporary File\n\n1. Create a temporary file with a descriptive name: `chat-log-{ticket-key}-{timestamp}.md`\n2. Write the formatted conversation to this file\n3. Store in `/tmp/claude/` directory (respects TMPDIR environment)\n\n### Step 4: Upload to JIRA\n\n1. Use the upload script located at `scripts/upload_chat_log.py` relative to this skill\n2. Run the script directly (not via `python`) to invoke uv properly via the shebang:\n   ```bash\n   ./scripts/upload_chat_log.py <ticket-key> <file-path>\n   ```\n3. The script will:\n   - Read the `JIRA_API_TOKEN` environment variable\n   - Connect to https://issues.redhat.com\n   - Upload the file as an attachment to the specified ticket\n   - Return success or error messages\n\n### Step 5: Confirm and Clean Up\n\n1. If upload succeeds:\n   - Inform the user: \"Successfully uploaded chat log to {ticket-key} on https://issues.redhat.com\"\n   - Provide the direct link: `https://issues.redhat.com/browse/{ticket-key}`\n2. If upload fails:\n   - Display the error message from the script\n   - Provide troubleshooting guidance (check token, permissions, ticket exists)\n3. Delete the temporary file after upload attempt (success or failure)\n\n## Error Handling\n\n- **Missing JIRA_API_TOKEN**: Provide clear instructions on how to obtain and set the token\n- **Invalid Ticket Key**: Verify the ticket exists and is accessible\n- **Permission Denied**: Check that the API token has permission to add attachments\n- **Script Not Found**: Verify the script exists at the expected path\n- **Upload Failure**: Display the specific error and suggest checking network, credentials, and ticket accessibility\n\n## Examples\n\n### Basic Usage\n```\nUser: Upload this chat to AIPCC-7354\nAssistant: [Skill creates formatted chat log and uploads to AIPCC-7354]\n```\n\n### No Ticket Specified\n```\nUser: Upload this conversation to JIRA\nAssistant: Which JIRA ticket should I attach this chat log to? (e.g., AIPCC-1234)\nUser: RHEL-9876\nAssistant: [Skill uploads to RHEL-9876]\n```\n\n### Context Detection\n```\nUser: We're working on AIPCC-7354. Can you upload our conversation?\nAssistant: [Skill detects AIPCC-7354 from context and uploads automatically]\n```"
              }
            ]
          },
          {
            "name": "konflux",
            "description": "A plugin to analyze and trigger Konflux builds",
            "source": "./claude-plugins/konflux",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install konflux@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/application",
                "description": "Manage Konflux application",
                "path": "claude-plugins/konflux/commands/application.md",
                "frontmatter": {
                  "argument-hint": "<subcommand> [args]",
                  "description": "Manage Konflux application"
                },
                "content": "## Name\nkonflux:application\n\n## Synopsis\n\n```\n/konflux:application status <application>\n```\n\n## Description\nThe `konflux:application` command to manage Konflux application.\n\nThis command helps you:\n- List all components in the application\n- Understand the status of the components in the application - last build, snapshots, releases\n\n## Implementation\n\n### Subcommand: status\n\nThe command performs the following steps:\n\n1. **Prerequisites Check**:\n    - Verify `oc` CLI is installed: `which oc`\n    - Verify cluster access: `oc whoami`\n    - If not installed or not authenticated, provide clear instructions\n    - Verify `jq` CLI is installed: `which jq`\n    - Verify `git` CLI is installed: `which git`\n    - Verify the current directory is a Git repository: `git remote -v`\n\n2. **Parse Arguments**:\n    - `application`: Application name (required)\n\n3. **List components that belong to the application**:\n    - Get components\n      ```bash\n      kubeclt get component -o yaml | jq '.items[] | select(.spec.application==\"{application}\")\n      ```\n    - The application name is provided in `.spec.application`\n    - The component name is provided in `.spec.componentName`\n    - The Git repository URL is provided in `.spec.source.git.url`\n    - The commit SHA is provided in `.status.lastBuiltCommit`\n\n4. **Show status for each Konflux component**:\n    - Run the following Claude Code command to get status of each Konflux component from the application\n    ```bash\n    /konflux:component status {component}\n    ```\n\n\n## Return Value\n- **status**: Table of all components that belong to the provided application\n\n## Examples\n\n1. **Get status all components of the otel-main application**:\n   ```bash\n   /konflux:application status otel-main\n   ```\n\n## Arguments\n\n### status\n\n- **application** (required): Name of the Konflux application\n\n## Troubleshooting\n\n\n## Related Commands\n\n* `/konflux:component status <component>` - Show component status\n* `/konflux:component build <components> [--wait <duration>] [--wait-release <duration>] [--nudge]` - Trigger component build\n\n## Additional Resources\n\n- [Konflux upstream documentation](https://konflux-ci.dev/docs/)\n- [Konflux architecture documentation](https://github.com/konflux-ci/architecture)"
              },
              {
                "name": "/component",
                "description": "Manage Konflux component",
                "path": "claude-plugins/konflux/commands/component.md",
                "frontmatter": {
                  "argument-hint": "<subcommand> [args]",
                  "description": "Manage Konflux component"
                },
                "content": "## Name\nkonflux:component\n\n## Synopsis\n\n```\n/konflux:component status <component>\n/konflux:component build <components> [--wait duration] [--nudge] [--wait-for-release release-duration]\n```\n\n## Description\nThe `konflux:component` command to manage Konflux component(s).\n\nThis command helps you:\n- Get status of a component - last build, commit message, snapshot and release\n- Trigger build of a component and wait until the build or release is done\n\n## Implementation\n\n### Subcommand: status\n\nThe command performs the following steps:\n\n1. **Prerequisites Check**:\n    - Verify `oc` CLI is installed: `which oc`\n    - Verify cluster access: `oc whoami`\n    - If not installed or not authenticated, provide clear instructions\n    - Verify `git` CLI is installed: `which git`\n    - Verify the current directory is a Git repository: `git remote -v`\n\n2. **Parse Arguments**:\n    - `component`: Component name (required)\n\n3. **List components**:\n    - Get component\n      ```bash\n      kubeclt get component {component} -o yaml\n      ```\n    - The application name is provided `.spec.application`\n    - The component name is provided `.spec.componentName`\n    - The Git repository URL is provided `.spec.source.git.url`\n    - The commit SHA is provided `.status.lastBuiltCommit`\n    - The image is provided `.status.lastPromotedImage`\n\n4. **Get Git information**:\n    - Use `git branch -a --contains <commit-sha>` to find the branch name\n    - The Git repository should be in the current working directory. If it is not fail the command.\n\n5. **Get Snapshots**:\n    - Get snapshots of the component and order by oldest\n      ```bash\n      kubectl get snapshot -l pac.test.appstudio.openshift.io/sha={commit},appstudio.openshift.io/component={component} --sort-by=.metadata.creationTimestamp\n      ```\n\n6. **Get Releases**:\n    - Get releases object for each snapshot\n      ```bash\n      kubectl get release -l pac.test.appstudio.openshift.io/sha={commit},appstudio.openshift.io/component={component}\n      ```\n   - The snapshot is specified in `.spec.snapshot`\n   - The `.status.conditions` show if the release failed or succeeded\n\n7. **Display result**:\n   - Display the result:\n     ```\n     | Component        | Built SHA | lastPromotedImage    |  Commit Message             | Git Branch   | Snapshots (oldest first) |\n     |------------------|-----------|----------------------|-----------------------------|--------------|--------------------------|\n     | {component}      | {commit}  | {lastPromotedImage}  | {commit-message}            | {git-branch} | {snapshots}              |\n     | otel-bundle-main | 8ba2e60   |                      | Fix service account (#693)  | main         | otel-main-jnhfz          |\n     ```\n   - Display snapshot with release information for each snapshot\n     ```\n     Component: {component}\n     | Snapshot        | Release                       | Release status                           |\n     |-----------------|-------------------------------|------------------------------------------|\n     | {snapshot}      | {release}                     | {release-status}                         |\n     | otel-main-jnhfz | otel-main-jnhfz-8ba2e60-nnwnp | Failed (ManagedPipelineProcessed failed) |\n     ```\n\n### Subcommand: build\n\nThe command performs the following steps:\n\n1. **Prerequisites Check**:\n    - Verify `oc` CLI is installed: `which oc`\n    - Verify cluster access: `oc whoami`\n    - If not installed or not authenticated, provide clear instructions\n    - Verify `git` CLI is installed: `which git`\n    - Verify the current directory is a Git repository\n\n2. **Parse Arguments**:\n    - `$1`: Component(s) (required): Konflux Component(s) name\n    - `$2`: flag `--wait <duration>` (optional) wait duration for the build to finish\n      - The duration can have suffix `s` for seconds, `m` for minutes or `h` for hours.\n      - If other suffixes are specified fail the command\n    - `$3`: flag `--nudge` (optional) nudge files after the build finishes\n      - `--nudge` can be used only if `--wait` is used\n    - `$4`: flag `--wait-for-release <release-duration>` (optional) wait until release is done\n       - `--wait-for-release` can be used only if `--wait` is used\n       - The duration can have suffix `s` for seconds, `m` for minutes or `h` for hours.\n\n3. **Trigger the build**:\n    - Annotate each component to trigger the build\n      ```bash\n      kubectl annotate components/{compponent} build.appstudio.openshift.io/request=trigger-pac-build\n      ```\n\n4. **Get the build information**:\n      ```bash\n      kubectl get pipelinerun -l appstudio.openshift.io/component={component}\n      ```\n    - Wait up to 5 minutes, it takes time for the PipelineRun to be created\n    - The started pipeline name must have `-on-push` in the name\n\n5. **Wait for the build to finish**:\n   - If `--wait <duration>` is provided wait for the PipelineRun to finish. The duration can be in `s` for seconds, `m` for minutes or `h` for hours.\n   ```bash\n   kubectl wait --for=condition=Suceeded=true pipelinerun/{pipelinerun} --timeout={duration}\n   ```\n   - Extract the nudge files specified in the `.metadata.annotations[\"build.appstudio.openshift.io/build-nudge-files\"]` in the PipelineRun\n   - The Snapshot object is created when the build finishes\n   - Get the Snapshot object and extract container image `.spec.components[?(@.name==\"{component}\")].containerImage`\n     ```bash\n     kubectl get snapshot -l appstudio.openshift.io/build-pipelinerun={pipelinerun}\n     ```\n   - If the build fails use the troubleshooting instructions to explain the failure\n\n6. **Wait for the release to finish**:\n    - If `--wait-for-release <release-duration>` is provided wait for the Release to finish. The release-duration can be in `s` for seconds, `m` for minutes or `h` for hours.\n   ```bash\n   kubectl wait --for=condition=Released=true --timeout={release-duration} -l appstudio.openshift.io/build-pipelinerun={pipelinerun}\n   ```\n\n7. **Nudge files**:\n    - If `--wait <duration>` and `--nudge` are provided nudge the files by repacing the `containerImage` in those files\n\n8. **Display result**:\n    - Display the result:\n      ```\n      Component: {component} | PipelineRun: {pipelinerun-name} | Snapshot: {snapshot} | Container Image: {containerImage}\n      ```\n\n## Return Value\n- **status**: Table of all components\n- **build**: PipelineRun custom resource name which is executing the build and snapshot if the build finished\n\n## Examples\n\n1. **Get status of otel-collector-main component**:\n   ```bash\n   /konflux:component status otel-collector-main\n   ```\n\n2. **Trigger build of the otel-collector-main component**:\n   ```bash\n   /konflux:component build otel-collector-main\n   ```\n\n3. **Trigger build of the otel-collector-main and otel-operator-main component**:\n   ```bash\n   /konflux:component build otel-collector-main otel-operator-main\n   ```\n\n4. **Trigger build of the otel-collector-main component and wait 30 minutes to finish**:\n   ```bash\n   /konflux:component build otel-collector-main --wait 30m\n   ```\n## Arguments\n\n### status\n\n- **component** (required): Name of the Konflux component\n\n### build\n\n- **component** (required): Name of the Konflux component\n- **--wait <duration>** (required): Duration how long to wait for the pipelinerun to finish\n\n## Troubleshooting\n\n### build\n\n- ***PipelineRun progress and failure***:\n    - The PipelineRun creates TaskRun(s) objects which create actuall pods to run the build.\n    - The TaskRun for a specific PipelineRun can be found by `kubectl get taskrun -l tekton.dev/pipelineRun={pipelinerun}`\n    - The pod for a specific TaskRun can be found by `kubectl get pod -l tekton.dev/taskRun={taskrun}`\n    - Get the pod logs, kubernetes events, status and explain the failure\n\n- ***Release progress and failure***\n    - The release is executed as a PipelineRun. The release PipelineRun is defined in the Release object in `.status.managedProcessing.pipelineRun`\n    - The example value is `rhtap-releng-tenant/managed-vks2b`. Which means the PipelineRun name is `managed-vks2b` and runs in `rhtap-releng-tenant` Kubernetes namespace.\n    - The TaskRun for the release PipelineRun can be found by `kubectl get taskrun -l tekton.dev/pipelineRun={pipelinerun} -n {namespace}`\n    - The pod for the release TaskRun can be found by `kubectl get pod -l tekton.dev/taskRun={taskrun} -n {namespace}`\n\n## Related Commands\n\n* `/konflux:application status <application>` - Show application status\n\n## Additional Resources\n\n- [Konflux upstream documentation](https://konflux-ci.dev/docs/)\n- [Konflux architecture documentation](https://github.com/konflux-ci/architecture)"
              }
            ],
            "skills": []
          },
          {
            "name": "python-packaging",
            "description": "Tools and skills for Python package management",
            "source": "./claude-plugins/python-packaging",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install python-packaging@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "complexity",
                "description": "Analyze Python package build complexity by inspecting PyPI metadata. Evaluates compilation requirements, dependencies, distribution types, and provides recommendations for wheel building strategies.",
                "path": "claude-plugins/python-packaging/skills/complexity/SKILL.md",
                "frontmatter": {
                  "name": "complexity",
                  "description": "Analyze Python package build complexity by inspecting PyPI metadata. Evaluates compilation requirements, dependencies, distribution types, and provides recommendations for wheel building strategies.",
                  "allowed-tools": [
                    "Bash",
                    "Read"
                  ]
                },
                "content": "# Python Package Build Complexity Analysis\n\nThis skill helps you evaluate the build complexity of Python packages by analyzing their PyPI metadata. It determines whether a package likely requires compilation, assesses build complexity, and provides recommendations for wheel building strategies.\n\n## Instructions\n\nWhen a user asks about Python package build complexity, building wheels, or evaluating PyPI packages for compilation requirements:\n\n1. **Run the PyPI inspection script** using the package name and optional version:\n   ```bash\n   ./scripts/pypi_inspect.py <package_name> [version]\n   ```\n\n2. **Analyze the output** and provide interpretation focusing on:\n\n   ### Build Complexity Assessment\n   - **Compilation Requirements**: Whether the package needs C/C++/Rust/Fortran compilation\n   - **Complexity Score**: Numerical score indicating build difficulty (0-10+ scale)\n   - **Key Indicators**: Specific classifiers, keywords, or dependencies that suggest complexity\n\n   ### Distribution Analysis\n   - **Source Distribution Availability**: Whether sdist is available for building\n   - **Existing Wheels**: What wheel types already exist (platform-specific, universal)\n   - **Wheel Coverage**: Gaps in wheel availability that might need custom builds\n\n   ### Dependency Analysis\n   - **Complex Dependencies**: Dependencies that themselves require compilation\n   - **Version Constraints**: Python version requirements and compatibility\n   - **Transitive Complexity**: How dependencies affect overall build complexity\n\n3. **Provide actionable recommendations**:\n   - Whether to build from source or use existing wheels\n   - Required build tools and dependencies\n   - Platform-specific considerations\n   - Estimated build time and resource requirements\n\n## Key Complexity Indicators\n\n### High Complexity (Score 5+)\n- Native extensions (C/C++/Rust/Fortran classifiers)\n- CUDA/GPU acceleration keywords\n- Known complex packages (torch, tensorflow, numpy, scipy)\n- Missing or limited wheel availability\n- Many compiled dependencies\n\n### Medium Complexity (Score 2-4)\n- Some compilation indicators in description/keywords\n- Platform-specific wheels only\n- Mixed dependency complexity\n- Moderate build requirements\n\n### Low Complexity (Score 0-1)\n- Pure Python packages\n- Universal wheels available\n- Simple dependencies\n- No compilation requirements\n\n## Usage Examples\n\n### Basic Package Analysis\n```bash\n./scripts/pypi_inspect.py torch\n```\n**Interpretation**: Analyze latest PyTorch version for build complexity, focusing on CUDA dependencies and compilation requirements.\n\n### Specific Version Analysis\n```bash\n./scripts/pypi_inspect.py numpy 1.24.3\n```\n**Interpretation**: Evaluate specific numpy version, explaining why numpy requires compilation and what build tools are needed.\n\n### JSON Output for Processing\n```bash\n./scripts/pypi_inspect.py tensorflow --json\n```\n**Interpretation**: Get structured data for programmatic analysis, then explain the complexity factors in plain language.\n\n## Providing Recommendations\n\nBased on the analysis, provide specific guidance:\n\n### For High Complexity Packages\n- \"This package requires significant compilation infrastructure\"\n- \"Consider using pre-built wheels when available\"\n- \"Building from source will need: [specific tools]\"\n- \"Estimated build time: [timeframe]\"\n\n### For Wheel Building Strategies\n- \"Universal wheels available - use those for maximum compatibility\"\n- \"Platform-specific wheels needed for: [platforms]\"\n- \"Source build recommended for: [specific scenarios]\"\n- \"Dependencies that complicate building: [list]\"\n\n### For Development Planning\n- \"Budget [time] for build environment setup\"\n- \"Consider containerized builds for reproducibility\"\n- \"Test on target platforms before production deployment\"\n- \"Monitor for new wheel releases that might eliminate build needs\"\n\n## Error Handling\n\nIf the script fails or package is not found:\n- Verify package name spelling and availability on PyPI\n- Check if the package exists under a different name\n- Suggest alternative analysis approaches\n- Provide general guidance for unknown packages\n\n## Integration Notes\n\nThis skill works best when combined with:\n- **python-packaging:license-finder** - License information helps assess redistribution requirements\n- Package dependency analysis\n- Build environment setup\n- Continuous integration planning\n- Container build strategies"
              },
              {
                "name": "env-finder",
                "description": "Investigate environment variables that can be set when building Python wheels for a given project. Analyzes setup.py, CMake files, and other build configuration files to discover customizable build environment variables.",
                "path": "claude-plugins/python-packaging/skills/env-finder/SKILL.md",
                "frontmatter": {
                  "name": "env-finder",
                  "description": "Investigate environment variables that can be set when building Python wheels for a given project. Analyzes setup.py, CMake files, and other build configuration files to discover customizable build environment variables.",
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Grep",
                    "Glob"
                  ]
                },
                "content": "# Python Build Environment Variables Investigation\n\nThis skill helps you discover all environment variables that can be set when building Python wheels for a project. It performs a comprehensive analysis of build configuration files to identify customizable environment variables used during the wheel building process.\n\n## Instructions\n\nWhen a user asks about environment variables for building Python wheels, investigating build configuration, or understanding build customization options:\n\n1. **Run the Environment Variables Investigation Script**:\n   ```bash\n   ./scripts/env_finder.py [project_path]\n   ```\n\n2. **Analyze and present the findings** focusing on:\n\n   ### Build Configuration Variables\n   - **Setup.py Variables**: Environment variables used in setup.py for customizing builds\n   - **CMake Variables**: Variables defined in CMakeLists.txt and related files\n   - **Build Tool Variables**: Variables used by setuptools, distutils, or other build systems\n   - **Compiler Variables**: Variables affecting compilation (CC, CXX, CFLAGS, etc.)\n\n   ### Variable Categories\n\n   #### Compiler and Linker Variables\n   - `CC`, `CXX` - Compiler selection\n   - `CFLAGS`, `CXXFLAGS` - Compilation flags\n   - `LDFLAGS` - Linker flags\n   - `LIBS` - Additional libraries\n\n   #### Path Configuration Variables\n   - `PREFIX` - Installation prefix\n   - `LIBRARY_PATH` - Library search paths\n   - `INCLUDE_PATH` - Header file paths\n   - `PKG_CONFIG_PATH` - pkg-config search paths\n\n   #### Feature Control Variables\n   - `ENABLE_*` - Feature enable/disable flags\n   - `WITH_*` - Optional component inclusion\n   - `USE_*` - Build option selection\n   - `DISABLE_*` - Feature disable flags\n\n   #### Python-Specific Variables\n   - `PYTHON_INCLUDE_DIR` - Python headers location\n   - `PYTHON_LIBRARY` - Python library path\n   - `SETUPTOOLS_*` - Setuptools configuration\n   - `PIP_*` - pip-related build variables\n\n   ### Usage Context\n   - **When Variables Are Used**: During which build phase each variable takes effect\n   - **Default Values**: What happens when variables are not set\n   - **Required vs Optional**: Which variables are mandatory for successful builds\n\n3. **Provide actionable guidance**:\n   - How to set each variable for custom builds\n   - Common use cases for each variable\n   - Potential conflicts or compatibility issues\n   - Recommended values for different scenarios\n\n## Output Format\n\nThe skill should provide a structured list of environment variables with:\n\n1. **Variable Name**: Exact environment variable name\n2. **Purpose**: Clear description of what the variable controls\n3. **Type**: Expected value type (path, boolean, string, number)\n4. **Default Value**: What happens when not set\n5. **Source File**: Where the variable was discovered\n6. **Usage Context**: When and how the variable is used\n\n## Error Handling and Edge Cases\n\n### No Build Configuration Found\n- Report that no environment variables were found\n- Most packages don't have build configuration so it is fine"
              },
              {
                "name": "license-checker",
                "description": "Assess license compatibility for Python package redistribution using SPDX.org license database. Evaluates whether a given license allows building and distributing wheels, with real-time license information lookup.",
                "path": "claude-plugins/python-packaging/skills/license-checker/SKILL.md",
                "frontmatter": {
                  "name": "license-checker",
                  "description": "Assess license compatibility for Python package redistribution using SPDX.org license database. Evaluates whether a given license allows building and distributing wheels, with real-time license information lookup.",
                  "allowed-tools": [
                    "WebFetch"
                  ]
                },
                "content": "# Python Package License Compatibility Checker\n\nThis skill helps you evaluate whether a Python package license is compatible with redistribution, particularly for building and distributing wheels in enterprise environments. It uses the authoritative SPDX License List for accurate, up-to-date license information.\n\n## Assessment Instructions\n\nWhen a user provides a license name and asks about compatibility for redistribution, building wheels, or licensing restrictions, follow this methodology:\n\n### Step-by-Step Process\n\n1. **Fetch Current SPDX Data**:\n   ```\n   Use WebFetch to query: https://raw.githubusercontent.com/spdx/license-list-data/main/json/licenses.json\n   ```\n\n2. **License Matching**:\n   - Try exact SPDX ID match first\n   - Try case-insensitive SPDX ID match\n   - Try full name matching\n   - Try partial/fuzzy matching for common variations\n\n3. **Risk Classification**:\n   ```\n   IF (isOsiApproved AND isFsfLibre AND permissive_pattern):\n       Risk = Low, Status = Compatible\n   ELIF (isOsiApproved AND weak_copyleft_pattern):\n       Risk = Medium, Status = Compatible with Requirements\n   ELIF (strong_copyleft_pattern OR NOT isOsiApproved):\n       Risk = High, Status = Restricted/Incompatible\n   ```\n\n4. **Generate Assessment**:\n   - Include all SPDX metadata\n   - Provide clear compatibility guidance\n   - List specific requirements\n   - Add Red Hat context where relevant\n\n## License Assessment Framework\n\n### Input Processing\nAccept various formats and normalize them:\n- **SPDX Identifiers**: \"MIT\", \"Apache-2.0\", \"GPL-3.0-only\"\n- **Full Names**: \"MIT License\", \"Apache License 2.0\", \"GNU General Public License v3.0\"\n- **Common Aliases**: \"Apache 2\", \"BSD 3-Clause\", \"GPLv3\"\n- **Case Variations**: Handle case-insensitive matching\n\n### SPDX Data Analysis\nWhen processing SPDX license data, examine these key fields:\n- `licenseId`: Official SPDX identifier\n- `name`: Full license name\n- `isOsiApproved`: OSI approval status (boolean)\n- `isFsfLibre`: FSF Free Software status (boolean)\n- `isDeprecatedLicenseId`: Whether license is deprecated (boolean)\n- `reference`: URL to full license details\n- `seeAlso`: Array of additional reference URLs\n\n### Compatibility Assessment Logic\n\nUse SPDX flags and license patterns to determine compatibility:\n\n#### ✅ Highly Compatible (Low Risk)\n- OSI Approved AND FSF Libre\n- Permissive licenses (MIT, Apache, BSD, ISC family)\n- No strong copyleft requirements\n\n#### ⚠️ Compatible with Requirements (Medium Risk)\n- OSI Approved but specific obligations\n- Weak copyleft (LGPL, MPL)\n- File-level copyleft licenses\n\n#### ❌ Restricted/High Risk\n- Strong copyleft (GPL, AGPL)\n- Non-OSI approved licenses\n- Proprietary or unclear terms\n\n### Output Format\n\nProvide a structured assessment with:\n\n1. **SPDX Information**:\n   - Official SPDX ID\n   - Full license name\n   - OSI Approved: Yes/No\n   - FSF Libre: Yes/No\n   - Deprecated: Yes/No (if applicable)\n\n2. **Compatibility Assessment**:\n   - Status: Compatible/Restricted/Incompatible\n   - Redistribution: Allowed/Restricted/Prohibited\n   - Commercial Use: Allowed/Restricted/Prohibited\n\n3. **Requirements**: Key compliance obligations\n4. **Risk Level**: Low/Medium/High for enterprise use\n5. **Red Hat Context**: Special considerations if applicable\n\n\n## Red Hat Vendor Agreements\n\nRed Hat has specific licensing agreements with the following hardware vendors:\n\n- **NVIDIA**: Agreement covers CUDA libraries, runtimes, and related NVIDIA proprietary components\n- **Intel Gaudi**: Agreement covers Gaudi AI accelerator software and libraries\n- **IBM Spyre**: Agreement covers IBM Spyre AI hardware and associated software components\n\nWhen evaluating packages with dependencies on these vendor-specific components, note that Red Hat has explicit redistribution rights under these agreements.\n\n## Error Handling\n\n### SPDX Data Fetch Failures\nIf the SPDX license list cannot be retrieved, exit early and warn the user.\n\n### License Not Found in SPDX\nWhen a license identifier is not found in the SPDX license list:\n1. Check for common typos or variations\n2. Suggest SPDX-compliant alternatives\n3. Recommend contacting package maintainer\n4. Provide conservative risk assessment\n\n### Deprecated Licenses\nFor deprecated SPDX licenses:\n1. Note the deprecation status\n2. Suggest migrating to current equivalent\n3. Provide assessment based on deprecated license terms\n4. Recommend updating package licensing\n\nFor complex licensing scenarios involving multiple packages or custom license terms, recommend consultation with legal counsel.\n\n## Integration Notes\n\nThis skill works best when combined with:\n- **python-packaging:license-finder** - Use to find license names before compatibility assessment"
              },
              {
                "name": "license-finder",
                "description": "Deterministically find license information for Python packages by checking PyPI metadata first, then falling back to Git repository LICENSE files using shallow cloning.",
                "path": "claude-plugins/python-packaging/skills/license-finder/SKILL.md",
                "frontmatter": {
                  "name": "license-finder",
                  "description": "Deterministically find license information for Python packages by checking PyPI metadata first, then falling back to Git repository LICENSE files using shallow cloning.",
                  "allowed-tools": [
                    "Bash",
                    "Skill"
                  ]
                },
                "content": "# Python Package License Finder\n\nThis skill helps you deterministically find license information for Python packages using a two-step approach: first checking PyPI metadata, then searching the source repository if needed.\n\n## Instructions\n\nWhen a user asks to find the license for a Python package, follow this deterministic process:\n\n### Step 1: Check PyPI Metadata\nFirst, attempt to find the license from PyPI using the package inspection script:\n\n```bash\n./scripts/find_license.py <package_name> [version]\n```\n\nIf the script finds a license in the PyPI metadata, **stop here** and return the license name.\n\n### Step 2: Search Git Repository (if PyPI fails)\nIf no license is found in PyPI metadata, search the package's source repository:\n\n1. **Get the source repository URL** from the PyPI metadata (the script will provide it)\n2. **Use the shallow-clone skill** to clone the repository:\n   ```\n   Skill: git:shallow-clone\n   ```\n3. **Search for LICENSE files** in the cloned repository:\n   ```bash\n   find . -iname \"license*\" -o -iname \"copying*\" -o -iname \"copyright*\" | head -10\n   ```\n4. **Read the license file** to identify the license type:\n   ```bash\n   head -20 <license_file>\n   ```\n\n### Step 3: Report Results\n- **License Found**: Return the license name (e.g., \"MIT License\", \"Apache-2.0\", \"GPL-3.0\")\n- **License Not Found**: Report that the license could not be determined\n\n## Usage Examples\n\n### Find License for Popular Package\n```bash\n./scripts/find_license.py requests\n```\n**Expected**: Find \"Apache-2.0\" from PyPI metadata\n\n### Find License for Package with Missing PyPI License\n```bash\n./scripts/find_license.py some-package\n```\n**Expected**: Fall back to repository search if PyPI metadata is incomplete\n\n### Specific Version Analysis\n```bash\n./scripts/find_license.py django 4.2.0\n```\n**Expected**: Find license for specific Django version\n\n## Error Handling\n\n### Package Not Found\n- Verify package name spelling\n- Check package availability on PyPI\n- Suggest alternative package names\n\n### Repository Access Issues\n- Report if source repository is unavailable\n- Note private/restricted repositories\n- Suggest manual license verification\n\n### License File Parsing\n- Handle non-standard license file formats\n- Report unclear or multiple licenses\n- Recommend manual review for complex cases\n\n## Integration Notes\n\nThis skill complements:\n- **python-packaging:complexity** - License info helps assess redistribution complexity\n- **python-packaging:license-checker** - Provides license names for compatibility assessment\n- **python-packaging:source-finder** - Uses similar PyPI metadata analysis\n\nThe skill focuses on **finding** license information, while license-checker focuses on **assessing** license compatibility for redistribution."
              },
              {
                "name": "source-finder",
                "description": "Locate source code repositories for Python packages by analyzing PyPI metadata, project URLs, and code hosting platforms like GitHub, GitLab, and Bitbucket. Provides deterministic results with confidence levels.",
                "path": "claude-plugins/python-packaging/skills/source-finder/SKILL.md",
                "frontmatter": {
                  "name": "source-finder",
                  "description": "Locate source code repositories for Python packages by analyzing PyPI metadata, project URLs, and code hosting platforms like GitHub, GitLab, and Bitbucket. Provides deterministic results with confidence levels.",
                  "allowed-tools": [
                    "Bash",
                    "WebSearch",
                    "WebFetch"
                  ]
                },
                "content": "# Source Finder\n\nLocates source code repositories for Python packages with confidence scoring.\n\n## Usage\n\nTo find a source repository for a given package:\n\n1. Run the finder script, for example:\n\n```\n# Find repository\n$ ./scripts/finder.py requests\n\n# Output structure:\n{\n  \"url\": \"https://github.com/psf/requests\",\n  \"confidence\": \"high\",\n  \"method\": \"pypi_metadata_project_urls.Source\",\n  \"package_name\": \"requests\"\n}\n```\n\n2. Parse the JSON output:\n\n- `url`: Repository URL (or `null` if not found)\n- `confidence`: `high`, `medium`, or `low`\n- `method`: How the URL was found\n- `package_name`: the package that was searched\n\n3. If confidence is `low` or `url` is `null`, use WebSearch: `<package_name> python github repository`\n\n4. Present results with confidence level clearly indicated\n\n## Output Format\n\nAs a result, provide structured output including:\n\n- Repository URL\n- Confidence level (high/medium/low)\n- Method used to find the repository\n- Additional context or warnings"
              }
            ]
          },
          {
            "name": "rpm",
            "description": "Tools for working with RPMs",
            "source": "./claude-plugins/rpm",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install rpm@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/examine",
                "description": null,
                "path": "claude-plugins/rpm/commands/examine.md",
                "frontmatter": null,
                "content": "---\ndescription: Analyze RPM build.log failures\nargument-hint: [copr-chroot-url] OR [build-log-url] [srpm-url] OR [build.log] [specfile|dist-git] [sources]\n---\n\n## Name\nrpm:examine\n\n## Synopsis\n```\n/rpm:examine <copr-chroot-url>\n/rpm:examine <build-log-url> <srpm-url>\n/rpm:examine <build.log> <specfile|dist-git> [sources]\n```\n\n## Description\nAnalyze RPM build.log failures. Provide a comprehensive analysis with error summary, root cause, and actionable fixes.\n\n### Mode 1: Copr Results URL or Direct URLs to build.log and SRPM\nProvide a single Copr build results URL to automatically fetch all build artifacts or provide two URLs - one for build.log and one for SRPM.\n\n**What gets downloaded:**\n- `build-live.log.gz` or `build.log` - Main build log\n- `*.src.rpm` - Source RPM containing spec file, sources, and patches\n- `root.log.gz`, `state.log` - Additional context logs (optional)\n\n### Mode 2: Local Files\nProvide paths to local build artifacts.\n\n**Arguments:**\n1. `<build.log>` - Path to build log file (required)\n2. `<specfile|dist-git>` - Path to spec file or dist-git repo clone (required)\n3. `[sources]` - Path to source tarball or unpacked sources (optional)\n\n**Context gathering:**\nIf sources not provided, search in:\n- build.log parent directory\n- specfile parent directory\n- dist-git clone directory\n\n## Implementation\n\n### 1. Input Detection\n- **If single URL**: Copr results directory → continue to step 2a\n- **If two URLs**: Direct URLs to build.log and SRPM (Koji/Brew) → download both directly, then follow 2a steps 3-5\n- **If local path(s)**: Local workflow → continue to step 2b\n\n### 2. Artifact Collection\n\n#### 2a. URL Workflow\n1. Create temporary working directory\n2. Download files from Copr URL:\n   ```bash\n   curl -LO <copr-url>/builder-live.log.gz\n   curl -LO <copr-url>/*.src.rpm\n   curl -LO <copr-url>/root.log.gz      # optional\n   curl -LO <copr-url>/state.log        # optional\n   ```\n3. Decompress logs: `gunzip *.log.gz` (if needed)\n4. Extract SRPM: `rpm2cpio *.src.rpm | cpio -idmv`\n5. Locate extracted spec file\n\n#### 2b. Local Workflow\n1. Verify build.log exists and is readable\n2. Verify specfile/dist-git path exists\n3. Search for sources if not provided:\n   - Check build.log parent directory for `*.tar.*` or `*.src.rpm`\n   - Check specfile parent directory\n   - If dist-git repo, check for sources in repo\n\n### 3. Context Gathering\nCollect all relevant information before analysis:\n\n**Spec file analysis:**\n- BuildRequires dependencies\n- Patches and their application order\n- Macros and their expansions\n- Build steps (%prep, %build, %install, %check, %files)\n\n**Additional context:**\n- For dist-git repos: Run `git diff` to check uncommitted changes\n- Examine patch files for conflicts or application failures\n- Look for auxiliary files: `%{name}.conf`, `%{name}.desktop`, systemd units\n- Check for additional logs: `root.log`, `state.log`, `mock.log`\n\n**Source code (if needed):**\n- For compiler errors: Unpack sources to examine code\n- For test failures: Locate test files and configurations\n- For build system issues: Check `CMakeLists.txt`, `Makefile.am`, `setup.py`, etc.\n\n### 4. Analysis\n\n#### Scan Strategy\n1. **Start at the end**: Scan build.log from bottom up to find failure point\n2. **Identify the phase**: Determine which RPM build phase failed:\n   - `%prep` - Source unpacking and patch application\n   - `%build` - Compilation and building\n   - `%install` - Installation to buildroot\n   - `%check` - Test suite execution\n   - Binary RPM creation - File packaging\n3. **Find the trigger**: Locate exact command or operation that failed\n4. **Trace backwards**: Follow the chain of events leading to failure\n5. **Cross-reference**: Compare findings with specfile configuration\n\n#### Error Keywords to Search\n- `\"Error:\"`, `\"FAILED\"`, `\"fatal error:\"`\n- `\"configure: error:\"`, `\"No such file\"`\n- `\"undefined reference\"`, `\"make: ***\"`\n- `\"CMake Error\"`, `\"ninja: build stopped\"`\n- `\"ModuleNotFoundError\"`, `\"ImportError\"`\n- `\"Ignoring extra path from command line\"` - May indicate broken line continuation in spec file\n- `\"add_subdirectory given source\"` + `\"not an existing directory\"` - May indicate missing options due to spec formatting\n\n#### Hard To Find Error Patterns\n\n**Spec file whitespace issues:**\n- Trailing space after backslash (`\\ ` instead of `\\`) - Breaks line continuation, causing subsequent lines to be completely ignored by the shell\n- Missing backslash in multi-line constructs (especially in `%if` blocks)\n- **Detection**: Use `cat -A specfile.spec` to reveal trailing spaces (shows as `\\ $` at end of line) or `grep '\\\\ $' specfile.spec`\n- **Symptoms**: CMake/configure options appear ignored, features default to wrong values, mysterious \"directory not found\" errors\n\n### 5. Cleanup\n- If URL workflow was used, clean up temporary directory after analysis\n- Ask user before cleanup if they might need files for further investigation\n\n## Output Format\n\nProvide a clear, structured analysis:\n\n### 1. Error Summary\nBrief description of what failed (1-2 sentences)\n\n### 2. Root Cause\nTechnical explanation of why it failed:\n- Which phase encountered the error\n- What operation or command triggered it\n- Underlying technical reason\n\n### 3. Suggested Fixes\nSpecific, actionable steps to resolve:\n- Exact changes needed (with code/spec snippets if applicable)\n- Commands to run\n- Dependencies to add/modify\n- Patches to apply/modify\n\n### 4. Additional Recommendations\nOptional section for:\n- Related improvements\n- Potential future issues\n- Best practices\n- Warnings about side effects\n"
              }
            ],
            "skills": []
          },
          {
            "name": "utils",
            "description": "A generic utilities plugin serving as a catch-all for various helper commands and agents",
            "source": "./claude-plugins/utils",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install utils@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/placeholder",
                "description": "Placeholder command for the utils plugin",
                "path": "claude-plugins/utils/commands/placeholder.md",
                "frontmatter": {
                  "description": "Placeholder command for the utils plugin"
                },
                "content": "## Name\nutils:placeholder\n\n## Synopsis\n```\n/utils:placeholder\n```\n\n## Description\nThis is a placeholder command for the utils plugin. The utils plugin serves as a catch-all location for introducing new generic commands. Once enough related commands are accumulated, they can be segregated into more targeted, specialized plugins.\n\nThis placeholder exists to maintain the plugin structure and will be replaced with actual utility commands as they are developed.\n\n## Implementation\nThe utils plugin provides a home for:\n- Generic helper commands that don't fit into existing specialized plugins\n- Experimental commands that may later be moved to dedicated plugins\n- Common utilities that benefit multiple workflows\n- Commands that are waiting to be grouped with similar functionality\n\n## Arguments:\nNone"
              }
            ],
            "skills": []
          },
          {
            "name": "vllm",
            "description": "vLLM plugin",
            "source": "./claude-plugins/vllm",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install vllm@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "vLLM Slack Summary",
                "description": "Generate slack summaries of vLLM CI SIG Slack channel activity for the RHAIIS midstream release team",
                "path": "claude-plugins/vllm/skills/vllm-slack-summary/SKILL.md",
                "frontmatter": {
                  "name": "vLLM Slack Summary",
                  "description": "Generate slack summaries of vLLM CI SIG Slack channel activity for the RHAIIS midstream release team"
                },
                "content": "# vLLM slack Summary Skill\n\nAutomates generating slack summaries of the vLLM CI SIG Slack channel for the Red Hat AI Inference Server (RHAIIS) team.\n\n## Prerequisites\n\n- **slackdump** installed and authenticated with vLLM workspace\n  - Install: <https://github.com/rusq/slackdump>\n  - Auth: Run `slackdump workspace add`\n\n## Usage\n\n```bash\n./scripts/generate_transcript.py                    # Last 7 days (default)\n./scripts/generate_transcript.py --days 14          # Custom date range\n./scripts/generate_transcript.py --output-dir out   # Custom output directory\n```\n\n## Context\n\nWhen summarizing the transcript, focus on:\n\n- **Breaking changes** affecting the RHAIIS midstream build\n- **Hardware issues** with H100, A100, MI300, or B200 GPUs\n- **CI/CD infrastructure** changes impacting test reliability\n- **Dependencies** changes in build requirements or Python packages\n- **Performance regressions** that could affect RHAIIS\n- **Upstream releases** and their stability status\n\n## Output\n\nThe skill creates `vllm_slack_summary/` containing:\n\n```text\nvllm_slack_summary/\n├── slack_export/                               # Raw Slack export\n├── transcript.md                               # Markdown transcript\n└── slack_summary_YYYY-MM-DD_to_YYYY-MM-DD.md  # Summary report\n```\n\nAfter generating the transcript, analyze it and create a summary with:\n\n- Executive Summary (2-3 sentences)\n- Key Issues & Resolutions\n- CI/CD Infrastructure Changes\n- Action Items for Red Hat Team\n\n## Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| slackdump not found | Ensure slackdump is in PATH: `which slackdump` |\n| Authentication failed | Run `slackdump workspace add` |\n| No messages found | Check date range; channel may have no messages in that period |\n\n## Quick Reference\n\n- **Channel ID**: C07R5PAL2L9 (vLLM CI SIG)\n- **Transcript**: `vllm_slack_summary/transcript.md`\n- **Summary**: `vllm_slack_summary/slack_summary_YYYY-MM-DD_to_YYYY-MM-DD.md`"
              }
            ]
          },
          {
            "name": "fips-compliance-checker",
            "description": "Plugin to scan for FIPS compliance",
            "source": {
              "source": "url",
              "url": "https://github.com/opendatahub-io/fips-compliance-checker-claude-code-plugin.git"
            },
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add opendatahub-io/ai-helpers",
              "/plugin install fips-compliance-checker@odh-ai-helpers"
            ],
            "signals": {
              "stars": 9,
              "forks": 10,
              "pushed_at": "2026-01-12T13:39:31Z",
              "created_at": "2025-12-03T21:38:06Z",
              "license": "Apache-2.0"
            },
            "commands": [
              {
                "name": "/commit-suggest",
                "description": "Generate AIPCC Commits style commit messages or summarize existing commits",
                "path": "claude-plugins/aipcc/commands/commit-suggest.md",
                "frontmatter": {
                  "description": "Generate AIPCC Commits style commit messages or summarize existing commits",
                  "argument-hint": [
                    "N"
                  ]
                },
                "content": "## Name\naipcc:commit-suggest\n\n## Synopsis\n```\n/aipcc:commit-suggest       # Analyze staged changes\n/aipcc:commit-suggest [N]     # Analyze last N commits (1-100)\n```\n\n## Description\nAI-powered command that analyzes code changes and generates commit messages following the project's AIPCC format requirements.\n\n**Modes:**\n- **Mode 1 (no argument)** – Analyze staged changes (`git add` required)\n- **Mode 2 (with N)** – Analyze last N commits to rewrite (N=1) or summarize for squash (N≥2)\n\n**Use cases:**\n- Create AIPCC-formatted commit messages\n- Improve or rewrite existing commits to meet project standards\n- Generate squash messages for MR merges\n\n**Difference from `/git:summary`** – That command is read-only, while `aipcc:commit-suggest` generates actionable commit message suggestions for user review and manual use.\n\n## Implementation\n\nThe command operates in two modes based on input:\n\n**Mode 1 (no argument):**\n1. Collect staged changes via `git diff --cached`\n2. Analyze file paths and code content to determine appropriate AIPCC ticket reference\n3. Generate 3 AIPCC-formatted commit message suggestions (Recommended, Standard, Minimal)\n4. Display formatted suggestions and prompt user for selection\n   - Ask: \"Which suggestion would you like to use? (1/2/3 or skip)\"\n   - Support responses: `1`, `use option 2`, `commit with option 3`, `skip`\n   - Execute `git commit -s` with selected message if user requests (includes sign-off)\n\n**Mode 2 (with N):**\n1. Retrieve last N commits using `git log`\n2. Parse commit messages and analyze changes to maintain AIPCC format consistency\n3. For **N=1**: Suggest improved rewrite following AIPCC format\n   For **N≥2**: Merge commits into unified AIPCC-formatted squash message\n4. Generate 3 AIPCC-formatted commit message suggestions (Recommended, Standard, Minimal)\n5. Display formatted suggestions and prompt user for selection\n   - Ask: \"Which suggestion would you like to use? (1/2/3 or skip)\"\n   - Support responses: `1`, `use option 2`, `amend with option 3`, `skip`\n   - Execute `git commit --amend -s` (N=1) or squash operation (N≥2) if user requests\n\n## Examples\n\n```bash\n# Generate message for staged files\ngit add src/auth.ts src/middleware.ts\n/aipcc:commit-suggest\n\n# Rewrite last commit message\n/aipcc:commit-suggest 1\n\n# Summarize last 5 commits for squash\n/aipcc:commit-suggest 5\n```\n\n## Return Value\n\nGenerates 3 AIPCC-formatted commit message suggestions:\n- **Suggestion #1 (Recommended)** – Detailed with full body and Jira integration\n- **Suggestion #2 (Standard)** – Concise with essential information\n- **Suggestion #3 (Minimal)** – Brief description with required elements\n\nEach suggestion includes:\n- AIPCC format title (`AIPCC-XXX: description`)\n- Blank line between title and body\n- Body text explaining the changes in complete sentences\n- Optional Jira integration (`Fixes AIPCC-XXX`)\n- Required sign-off line\n\n**Example:**\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nSuggestion #1 (Recommended)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nAIPCC-123: Add JWT authentication middleware\n\nImplement token-based authentication for API endpoints to enhance\nsecurity. The middleware verifies JWT tokens and extracts user\ninformation for authorization decisions.\n\nFixes AIPCC-123\n\nCo-Authored-By: [AI_NAME] ([AI_MODEL])\n\nSigned-off-by: Your Name <your.email@example.com>\n\nWhich suggestion would you like to use? (1/2/3 or skip)\n```\n\n### Mode 2 Specifics\n\n- **N=1** – Suggest improved rewrite for the last commit in AIPCC format\n- **N≥2** – Generate unified AIPCC-formatted squash message with footer: `Squashed from N commits:` + original commit list\n\n## Commit Message Format Requirements\n\n### AIPCC Format\nAll commits must follow this project-specific format:\n```\nAIPCC-XXX: Short description\n\nLonger explanation of what the commit does, written in at least one\ncomplete sentence explaining the purpose and impact of the change.\n\n[Optional: Fixes AIPCC-XXX]\n\n[Optional: Co-Authored-By: [AI_NAME] ([AI_MODEL])]\n\nSigned-off-by: Your Name <your.email@example.com>\n```\n\n### Required Elements\n- **Title**: Must start with \"AIPCC-XXX:\" followed by a short description\n- **Body**: Must explain what the commit does in at least one complete sentence\n- **Sign-off**: All commits must include `Signed-off-by` line (use `git commit -s`)\n\n### Optional Elements\n- **Jira Integration**: Include \"Fixes AIPCC-XXX\" in the body to automatically close the Jira ticket when MR merges\n- **Co-authors**: `Co-Authored-By: Name <email@example.com>`\n- **AI Attribution**: `Co-Authored-By: [AI_NAME] ([AI_MODEL])` when AI assists with code generation\n- **Breaking Changes**: Note significant API changes in the body\n\n### Examples\n```\nAIPCC-456: Fix memory leak in authentication service\n\nResolve memory leak caused by unclosed database connections in the\nauth service. This improves server stability under high load.\n\nFixes AIPCC-456\n\nCo-Authored-By: [AI_NAME] ([AI_MODEL])\n\nSigned-off-by: Jane Developer <jane@example.com>\n```\n\n```\nAIPCC-789: Add user profile management API\n\nImplement REST endpoints for user profile CRUD operations.\nIncludes validation, error handling, and comprehensive test coverage.\n\nCo-Authored-By: [AI_NAME] ([AI_MODEL])\n\nSigned-off-by: John Developer <john@example.com>\n```\n\n## Arguments\n\n- **[N]** (optional): Number of recent commits to analyze (1-100)\n  - If omitted: Analyzes staged changes (Mode 1)\n  - If N=1: Suggests improved rewrite for the last commit\n  - If N≥2: Generates unified squash message for last N commits\n\n## See Also\n- **`/git:summary`** – Display repository status and recent commits (read-only)\n- **AIPCC Project Guidelines** – Internal project commit format requirements\n- [Conventional Commits Specification](https://www.conventionalcommits.org/) – General industry standard (adapted for AIPCC format)"
              },
              {
                "name": "/echo",
                "description": "Hello world plugin implementation",
                "path": "claude-plugins/hello-world/commands/echo.md",
                "frontmatter": {
                  "description": "Hello world plugin implementation",
                  "argument-hint": [
                    "name"
                  ]
                },
                "content": "## Name\nhello-world:echo\n\n## Synopsis\n```\n/hello-world:echo [name]\n```\n\n## Description\nThe `hello-world:echo` command prints a greeting message to the console. By default, it prints \"Hello world\", but when provided with a name argument `hello-world:echo $1`, it prints \"Hello ${1}\". This command serves as a basic example of a Claude Code plugin implementation, demonstrating the minimal structure required for a functional plugin command.\n\nIt provides a reference implementation for plugin developers. It demonstrates:\n- Basic command structure\n- Shell command execution within a plugin\n- Handling arguments\n- Minimal configuration requirements\n\nThe spec sections is inspired by https://man7.org/linux/man-pages/man7/man-pages.7.html#top_of_page\n\n## Implementation\n- The command executes a simple bash `echo` statement\n- Accepts an optional name argument (`$1`)\n- If `$1` is provided, outputs \"Hello $1\"\n- If no argument is provided, outputs \"Hello world\"\n- Output is sent directly to standard output\n- The command is stateless and has no side effects\n\n## Examples\n\n1. **Basic usage (no arguments)**:\n   ```\n   /hello-world:echo\n   ```\n   Output:\n   ```\n   Hello world\n   ```\n\n2. **With a name argument**:\n   ```\n   /hello-world:echo Alice\n   ```\n   Output:\n   ```\n   Hello Alice\n   ```\n\n3. **With multiple words as name**:\n   ```\n   /hello-world:echo \"John Doe\"\n   ```\n   Output:\n   ```\n   Hello John Doe\n   ```"
              },
              {
                "name": "/sprint-summary",
                "description": "Generate comprehensive sprint summaries by analyzing JIRA sprint data, including issue breakdown, progress metrics, and team performance insights.",
                "path": "claude-plugins/jira/commands/sprint-summary.md",
                "frontmatter": {
                  "argument-hint": "<sprint-name> [options]",
                  "description": "Generate comprehensive sprint summaries by analyzing JIRA sprint data, including issue breakdown, progress metrics, and team performance insights."
                },
                "content": "## Name\njira:sprint-summary\n\n## Synopsis\n```\n/jira:sprint-summary <sprint-name> [options]\n```\n\n## Description\nGenerate comprehensive sprint summaries by analyzing JIRA sprint data, including issue breakdown, progress metrics, and team performance insights. This command provides data-driven insights for sprint retrospectives, stakeholder reporting, and process improvement.\n\n## Parameters\n- `sprint-name`: The exact name or identifier of the sprint (required)\n- `[options]`: Optional flags for customizing output (see Options section)\n\n## Prerequisites\n- JIRA MCP server must be configured and accessible\n- Appropriate JIRA permissions to access sprint and issue data\n- Valid sprint name that exists in the configured JIRA instance\n\n## Implementation\n\n### Core Features\n1. **Sprint Overview**: Retrieve basic sprint information (dates, status, goals)\n2. **Issue Analysis**: Categorize and analyze all issues in the sprint by:\n   - Issue type (Story, Bug, Task, Epic, etc.)\n   - Status (To Do, In Progress, Done, etc.)\n   - Priority levels\n   - Assignee distribution\n3. **Progress Metrics**: Calculate completion rates, velocity, and burndown data\n4. **Team Insights**: Analyze workload distribution and individual contributions\n5. **Quality Metrics**: Identify blocked issues, overdue items, and technical debt\n\n### Error Handling\n- **Missing JIRA Configuration**: If JIRA MCP server is not configured or not working, provide clear setup instructions and troubleshooting steps\n- **Missing Sprint Name**: If no sprint name provided, prompt for required parameter with examples\n- **Invalid Sprint**: If sprint doesn't exist, suggest similar sprint names or provide guidance on finding correct sprint identifiers\n- **Permission Issues**: Handle authentication and authorization errors gracefully with actionable feedback\n\n### Output Format\nGenerate a structured markdown report including:\n- Executive summary with key metrics\n- Sprint overview (dates, goals, team members)\n- Issue breakdown tables and charts\n- Progress visualization (completion rates, velocity trends)\n- Risk assessment (blocked items, potential delays)\n- Recommendations for sprint improvement\n\n## Options\n- `--format`: Output format (markdown, json, csv) - default: markdown\n- `--include-subtasks`: Include subtasks in analysis - default: false\n- `--detailed`: Generate detailed issue-by-issue breakdown - default: false\n- `--export`: Save summary to file with timestamp - default: false\n\n## Usage Scenarios\n- **Sprint Retrospectives**: Generate data-driven insights for team retrospective meetings\n- **Stakeholder Reporting**: Create executive summaries for leadership updates\n- **Performance Tracking**: Monitor team velocity and delivery consistency over time\n- **Process Improvement**: Identify bottlenecks and areas for workflow optimization\n- **Planning Sessions**: Use historical data to inform future sprint planning"
              },
              {
                "name": "/application",
                "description": "Manage Konflux application",
                "path": "claude-plugins/konflux/commands/application.md",
                "frontmatter": {
                  "argument-hint": "<subcommand> [args]",
                  "description": "Manage Konflux application"
                },
                "content": "## Name\nkonflux:application\n\n## Synopsis\n\n```\n/konflux:application status <application>\n```\n\n## Description\nThe `konflux:application` command to manage Konflux application.\n\nThis command helps you:\n- List all components in the application\n- Understand the status of the components in the application - last build, snapshots, releases\n\n## Implementation\n\n### Subcommand: status\n\nThe command performs the following steps:\n\n1. **Prerequisites Check**:\n    - Verify `oc` CLI is installed: `which oc`\n    - Verify cluster access: `oc whoami`\n    - If not installed or not authenticated, provide clear instructions\n    - Verify `jq` CLI is installed: `which jq`\n    - Verify `git` CLI is installed: `which git`\n    - Verify the current directory is a Git repository: `git remote -v`\n\n2. **Parse Arguments**:\n    - `application`: Application name (required)\n\n3. **List components that belong to the application**:\n    - Get components\n      ```bash\n      kubeclt get component -o yaml | jq '.items[] | select(.spec.application==\"{application}\")\n      ```\n    - The application name is provided in `.spec.application`\n    - The component name is provided in `.spec.componentName`\n    - The Git repository URL is provided in `.spec.source.git.url`\n    - The commit SHA is provided in `.status.lastBuiltCommit`\n\n4. **Show status for each Konflux component**:\n    - Run the following Claude Code command to get status of each Konflux component from the application\n    ```bash\n    /konflux:component status {component}\n    ```\n\n\n## Return Value\n- **status**: Table of all components that belong to the provided application\n\n## Examples\n\n1. **Get status all components of the otel-main application**:\n   ```bash\n   /konflux:application status otel-main\n   ```\n\n## Arguments\n\n### status\n\n- **application** (required): Name of the Konflux application\n\n## Troubleshooting\n\n\n## Related Commands\n\n* `/konflux:component status <component>` - Show component status\n* `/konflux:component build <components> [--wait <duration>] [--wait-release <duration>] [--nudge]` - Trigger component build\n\n## Additional Resources\n\n- [Konflux upstream documentation](https://konflux-ci.dev/docs/)\n- [Konflux architecture documentation](https://github.com/konflux-ci/architecture)"
              },
              {
                "name": "/component",
                "description": "Manage Konflux component",
                "path": "claude-plugins/konflux/commands/component.md",
                "frontmatter": {
                  "argument-hint": "<subcommand> [args]",
                  "description": "Manage Konflux component"
                },
                "content": "## Name\nkonflux:component\n\n## Synopsis\n\n```\n/konflux:component status <component>\n/konflux:component build <components> [--wait duration] [--nudge] [--wait-for-release release-duration]\n```\n\n## Description\nThe `konflux:component` command to manage Konflux component(s).\n\nThis command helps you:\n- Get status of a component - last build, commit message, snapshot and release\n- Trigger build of a component and wait until the build or release is done\n\n## Implementation\n\n### Subcommand: status\n\nThe command performs the following steps:\n\n1. **Prerequisites Check**:\n    - Verify `oc` CLI is installed: `which oc`\n    - Verify cluster access: `oc whoami`\n    - If not installed or not authenticated, provide clear instructions\n    - Verify `git` CLI is installed: `which git`\n    - Verify the current directory is a Git repository: `git remote -v`\n\n2. **Parse Arguments**:\n    - `component`: Component name (required)\n\n3. **List components**:\n    - Get component\n      ```bash\n      kubeclt get component {component} -o yaml\n      ```\n    - The application name is provided `.spec.application`\n    - The component name is provided `.spec.componentName`\n    - The Git repository URL is provided `.spec.source.git.url`\n    - The commit SHA is provided `.status.lastBuiltCommit`\n    - The image is provided `.status.lastPromotedImage`\n\n4. **Get Git information**:\n    - Use `git branch -a --contains <commit-sha>` to find the branch name\n    - The Git repository should be in the current working directory. If it is not fail the command.\n\n5. **Get Snapshots**:\n    - Get snapshots of the component and order by oldest\n      ```bash\n      kubectl get snapshot -l pac.test.appstudio.openshift.io/sha={commit},appstudio.openshift.io/component={component} --sort-by=.metadata.creationTimestamp\n      ```\n\n6. **Get Releases**:\n    - Get releases object for each snapshot\n      ```bash\n      kubectl get release -l pac.test.appstudio.openshift.io/sha={commit},appstudio.openshift.io/component={component}\n      ```\n   - The snapshot is specified in `.spec.snapshot`\n   - The `.status.conditions` show if the release failed or succeeded\n\n7. **Display result**:\n   - Display the result:\n     ```\n     | Component        | Built SHA | lastPromotedImage    |  Commit Message             | Git Branch   | Snapshots (oldest first) |\n     |------------------|-----------|----------------------|-----------------------------|--------------|--------------------------|\n     | {component}      | {commit}  | {lastPromotedImage}  | {commit-message}            | {git-branch} | {snapshots}              |\n     | otel-bundle-main | 8ba2e60   |                      | Fix service account (#693)  | main         | otel-main-jnhfz          |\n     ```\n   - Display snapshot with release information for each snapshot\n     ```\n     Component: {component}\n     | Snapshot        | Release                       | Release status                           |\n     |-----------------|-------------------------------|------------------------------------------|\n     | {snapshot}      | {release}                     | {release-status}                         |\n     | otel-main-jnhfz | otel-main-jnhfz-8ba2e60-nnwnp | Failed (ManagedPipelineProcessed failed) |\n     ```\n\n### Subcommand: build\n\nThe command performs the following steps:\n\n1. **Prerequisites Check**:\n    - Verify `oc` CLI is installed: `which oc`\n    - Verify cluster access: `oc whoami`\n    - If not installed or not authenticated, provide clear instructions\n    - Verify `git` CLI is installed: `which git`\n    - Verify the current directory is a Git repository\n\n2. **Parse Arguments**:\n    - `$1`: Component(s) (required): Konflux Component(s) name\n    - `$2`: flag `--wait <duration>` (optional) wait duration for the build to finish\n      - The duration can have suffix `s` for seconds, `m` for minutes or `h` for hours.\n      - If other suffixes are specified fail the command\n    - `$3`: flag `--nudge` (optional) nudge files after the build finishes\n      - `--nudge` can be used only if `--wait` is used\n    - `$4`: flag `--wait-for-release <release-duration>` (optional) wait until release is done\n       - `--wait-for-release` can be used only if `--wait` is used\n       - The duration can have suffix `s` for seconds, `m` for minutes or `h` for hours.\n\n3. **Trigger the build**:\n    - Annotate each component to trigger the build\n      ```bash\n      kubectl annotate components/{compponent} build.appstudio.openshift.io/request=trigger-pac-build\n      ```\n\n4. **Get the build information**:\n      ```bash\n      kubectl get pipelinerun -l appstudio.openshift.io/component={component}\n      ```\n    - Wait up to 5 minutes, it takes time for the PipelineRun to be created\n    - The started pipeline name must have `-on-push` in the name\n\n5. **Wait for the build to finish**:\n   - If `--wait <duration>` is provided wait for the PipelineRun to finish. The duration can be in `s` for seconds, `m` for minutes or `h` for hours.\n   ```bash\n   kubectl wait --for=condition=Suceeded=true pipelinerun/{pipelinerun} --timeout={duration}\n   ```\n   - Extract the nudge files specified in the `.metadata.annotations[\"build.appstudio.openshift.io/build-nudge-files\"]` in the PipelineRun\n   - The Snapshot object is created when the build finishes\n   - Get the Snapshot object and extract container image `.spec.components[?(@.name==\"{component}\")].containerImage`\n     ```bash\n     kubectl get snapshot -l appstudio.openshift.io/build-pipelinerun={pipelinerun}\n     ```\n   - If the build fails use the troubleshooting instructions to explain the failure\n\n6. **Wait for the release to finish**:\n    - If `--wait-for-release <release-duration>` is provided wait for the Release to finish. The release-duration can be in `s` for seconds, `m` for minutes or `h` for hours.\n   ```bash\n   kubectl wait --for=condition=Released=true --timeout={release-duration} -l appstudio.openshift.io/build-pipelinerun={pipelinerun}\n   ```\n\n7. **Nudge files**:\n    - If `--wait <duration>` and `--nudge` are provided nudge the files by repacing the `containerImage` in those files\n\n8. **Display result**:\n    - Display the result:\n      ```\n      Component: {component} | PipelineRun: {pipelinerun-name} | Snapshot: {snapshot} | Container Image: {containerImage}\n      ```\n\n## Return Value\n- **status**: Table of all components\n- **build**: PipelineRun custom resource name which is executing the build and snapshot if the build finished\n\n## Examples\n\n1. **Get status of otel-collector-main component**:\n   ```bash\n   /konflux:component status otel-collector-main\n   ```\n\n2. **Trigger build of the otel-collector-main component**:\n   ```bash\n   /konflux:component build otel-collector-main\n   ```\n\n3. **Trigger build of the otel-collector-main and otel-operator-main component**:\n   ```bash\n   /konflux:component build otel-collector-main otel-operator-main\n   ```\n\n4. **Trigger build of the otel-collector-main component and wait 30 minutes to finish**:\n   ```bash\n   /konflux:component build otel-collector-main --wait 30m\n   ```\n## Arguments\n\n### status\n\n- **component** (required): Name of the Konflux component\n\n### build\n\n- **component** (required): Name of the Konflux component\n- **--wait <duration>** (required): Duration how long to wait for the pipelinerun to finish\n\n## Troubleshooting\n\n### build\n\n- ***PipelineRun progress and failure***:\n    - The PipelineRun creates TaskRun(s) objects which create actuall pods to run the build.\n    - The TaskRun for a specific PipelineRun can be found by `kubectl get taskrun -l tekton.dev/pipelineRun={pipelinerun}`\n    - The pod for a specific TaskRun can be found by `kubectl get pod -l tekton.dev/taskRun={taskrun}`\n    - Get the pod logs, kubernetes events, status and explain the failure\n\n- ***Release progress and failure***\n    - The release is executed as a PipelineRun. The release PipelineRun is defined in the Release object in `.status.managedProcessing.pipelineRun`\n    - The example value is `rhtap-releng-tenant/managed-vks2b`. Which means the PipelineRun name is `managed-vks2b` and runs in `rhtap-releng-tenant` Kubernetes namespace.\n    - The TaskRun for the release PipelineRun can be found by `kubectl get taskrun -l tekton.dev/pipelineRun={pipelinerun} -n {namespace}`\n    - The pod for the release TaskRun can be found by `kubectl get pod -l tekton.dev/taskRun={taskrun} -n {namespace}`\n\n## Related Commands\n\n* `/konflux:application status <application>` - Show application status\n\n## Additional Resources\n\n- [Konflux upstream documentation](https://konflux-ci.dev/docs/)\n- [Konflux architecture documentation](https://github.com/konflux-ci/architecture)"
              },
              {
                "name": "/examine",
                "description": null,
                "path": "claude-plugins/rpm/commands/examine.md",
                "frontmatter": null,
                "content": "---\ndescription: Analyze RPM build.log failures\nargument-hint: [copr-chroot-url] OR [build-log-url] [srpm-url] OR [build.log] [specfile|dist-git] [sources]\n---\n\n## Name\nrpm:examine\n\n## Synopsis\n```\n/rpm:examine <copr-chroot-url>\n/rpm:examine <build-log-url> <srpm-url>\n/rpm:examine <build.log> <specfile|dist-git> [sources]\n```\n\n## Description\nAnalyze RPM build.log failures. Provide a comprehensive analysis with error summary, root cause, and actionable fixes.\n\n### Mode 1: Copr Results URL or Direct URLs to build.log and SRPM\nProvide a single Copr build results URL to automatically fetch all build artifacts or provide two URLs - one for build.log and one for SRPM.\n\n**What gets downloaded:**\n- `build-live.log.gz` or `build.log` - Main build log\n- `*.src.rpm` - Source RPM containing spec file, sources, and patches\n- `root.log.gz`, `state.log` - Additional context logs (optional)\n\n### Mode 2: Local Files\nProvide paths to local build artifacts.\n\n**Arguments:**\n1. `<build.log>` - Path to build log file (required)\n2. `<specfile|dist-git>` - Path to spec file or dist-git repo clone (required)\n3. `[sources]` - Path to source tarball or unpacked sources (optional)\n\n**Context gathering:**\nIf sources not provided, search in:\n- build.log parent directory\n- specfile parent directory\n- dist-git clone directory\n\n## Implementation\n\n### 1. Input Detection\n- **If single URL**: Copr results directory → continue to step 2a\n- **If two URLs**: Direct URLs to build.log and SRPM (Koji/Brew) → download both directly, then follow 2a steps 3-5\n- **If local path(s)**: Local workflow → continue to step 2b\n\n### 2. Artifact Collection\n\n#### 2a. URL Workflow\n1. Create temporary working directory\n2. Download files from Copr URL:\n   ```bash\n   curl -LO <copr-url>/builder-live.log.gz\n   curl -LO <copr-url>/*.src.rpm\n   curl -LO <copr-url>/root.log.gz      # optional\n   curl -LO <copr-url>/state.log        # optional\n   ```\n3. Decompress logs: `gunzip *.log.gz` (if needed)\n4. Extract SRPM: `rpm2cpio *.src.rpm | cpio -idmv`\n5. Locate extracted spec file\n\n#### 2b. Local Workflow\n1. Verify build.log exists and is readable\n2. Verify specfile/dist-git path exists\n3. Search for sources if not provided:\n   - Check build.log parent directory for `*.tar.*` or `*.src.rpm`\n   - Check specfile parent directory\n   - If dist-git repo, check for sources in repo\n\n### 3. Context Gathering\nCollect all relevant information before analysis:\n\n**Spec file analysis:**\n- BuildRequires dependencies\n- Patches and their application order\n- Macros and their expansions\n- Build steps (%prep, %build, %install, %check, %files)\n\n**Additional context:**\n- For dist-git repos: Run `git diff` to check uncommitted changes\n- Examine patch files for conflicts or application failures\n- Look for auxiliary files: `%{name}.conf`, `%{name}.desktop`, systemd units\n- Check for additional logs: `root.log`, `state.log`, `mock.log`\n\n**Source code (if needed):**\n- For compiler errors: Unpack sources to examine code\n- For test failures: Locate test files and configurations\n- For build system issues: Check `CMakeLists.txt`, `Makefile.am`, `setup.py`, etc.\n\n### 4. Analysis\n\n#### Scan Strategy\n1. **Start at the end**: Scan build.log from bottom up to find failure point\n2. **Identify the phase**: Determine which RPM build phase failed:\n   - `%prep` - Source unpacking and patch application\n   - `%build` - Compilation and building\n   - `%install` - Installation to buildroot\n   - `%check` - Test suite execution\n   - Binary RPM creation - File packaging\n3. **Find the trigger**: Locate exact command or operation that failed\n4. **Trace backwards**: Follow the chain of events leading to failure\n5. **Cross-reference**: Compare findings with specfile configuration\n\n#### Error Keywords to Search\n- `\"Error:\"`, `\"FAILED\"`, `\"fatal error:\"`\n- `\"configure: error:\"`, `\"No such file\"`\n- `\"undefined reference\"`, `\"make: ***\"`\n- `\"CMake Error\"`, `\"ninja: build stopped\"`\n- `\"ModuleNotFoundError\"`, `\"ImportError\"`\n- `\"Ignoring extra path from command line\"` - May indicate broken line continuation in spec file\n- `\"add_subdirectory given source\"` + `\"not an existing directory\"` - May indicate missing options due to spec formatting\n\n#### Hard To Find Error Patterns\n\n**Spec file whitespace issues:**\n- Trailing space after backslash (`\\ ` instead of `\\`) - Breaks line continuation, causing subsequent lines to be completely ignored by the shell\n- Missing backslash in multi-line constructs (especially in `%if` blocks)\n- **Detection**: Use `cat -A specfile.spec` to reveal trailing spaces (shows as `\\ $` at end of line) or `grep '\\\\ $' specfile.spec`\n- **Symptoms**: CMake/configure options appear ignored, features default to wrong values, mysterious \"directory not found\" errors\n\n### 5. Cleanup\n- If URL workflow was used, clean up temporary directory after analysis\n- Ask user before cleanup if they might need files for further investigation\n\n## Output Format\n\nProvide a clear, structured analysis:\n\n### 1. Error Summary\nBrief description of what failed (1-2 sentences)\n\n### 2. Root Cause\nTechnical explanation of why it failed:\n- Which phase encountered the error\n- What operation or command triggered it\n- Underlying technical reason\n\n### 3. Suggested Fixes\nSpecific, actionable steps to resolve:\n- Exact changes needed (with code/spec snippets if applicable)\n- Commands to run\n- Dependencies to add/modify\n- Patches to apply/modify\n\n### 4. Additional Recommendations\nOptional section for:\n- Related improvements\n- Potential future issues\n- Best practices\n- Warnings about side effects\n"
              },
              {
                "name": "/placeholder",
                "description": "Placeholder command for the utils plugin",
                "path": "claude-plugins/utils/commands/placeholder.md",
                "frontmatter": {
                  "description": "Placeholder command for the utils plugin"
                },
                "content": "## Name\nutils:placeholder\n\n## Synopsis\n```\n/utils:placeholder\n```\n\n## Description\nThis is a placeholder command for the utils plugin. The utils plugin serves as a catch-all location for introducing new generic commands. Once enough related commands are accumulated, they can be segregated into more targeted, specialized plugins.\n\nThis placeholder exists to maintain the plugin structure and will be replaced with actual utility commands as they are developed.\n\n## Implementation\nThe utils plugin provides a home for:\n- Generic helper commands that don't fit into existing specialized plugins\n- Experimental commands that may later be moved to dedicated plugins\n- Common utilities that benefit multiple workflows\n- Commands that are waiting to be grouped with similar functionality\n\n## Arguments:\nNone"
              },
              {
                "name": "/aipcc-commit-suggest",
                "description": null,
                "path": "cursor/commands/aipcc-commit-suggest.md",
                "frontmatter": null,
                "content": "../../claude-plugins/aipcc/commands/commit-suggest.md"
              },
              {
                "name": "/jira-sprint-summary",
                "description": null,
                "path": "cursor/commands/jira-sprint-summary.md",
                "frontmatter": null,
                "content": "../../claude-plugins/jira/commands/sprint-summary.md"
              },
              {
                "name": "/konflux-application",
                "description": null,
                "path": "cursor/commands/konflux-application.md",
                "frontmatter": null,
                "content": "../../claude-plugins/konflux/commands/application.md"
              },
              {
                "name": "/konflux-component",
                "description": null,
                "path": "cursor/commands/konflux-component.md",
                "frontmatter": null,
                "content": "../../claude-plugins/konflux/commands/component.md"
              },
              {
                "name": "/rpm-examine",
                "description": null,
                "path": "cursor/commands/rpm-examine.md",
                "frontmatter": null,
                "content": "../../claude-plugins/rpm/commands/examine.md"
              }
            ],
            "skills": [
              {
                "name": "shallow-clone",
                "description": "Perform a shallow clone of a Git repository to a temporary location.",
                "path": "claude-plugins/git/skills/shallow-clone/SKILL.md",
                "frontmatter": {
                  "name": "shallow-clone",
                  "description": "Perform a shallow clone of a Git repository to a temporary location.",
                  "allowed-tools": [
                    "Bash"
                  ]
                },
                "content": "# Shallow Clone\n\nProvides a script for creating a shallow clone of a Git repository to a temporary location. This skill should be used\nto analyze repository contents locally instead of using web APIs.\n\n## Usage\n\nUse the `scripts/shallow-clone.sh` script in this directory, for example:\n\n```bash\n./scripts/shallow-clone.sh <repository_url> [<tag_or_branch>]\n```\n\nThe script will print the path to the cloned repository when done, for example:\n\n```shell\n$ ./scripts/shallow-clone.sh https://github.com/psf/requests.git\nCloning https://github.com/psf/requests.git (shallow, ref: HEAD) to /tmp/shallow-clone-DDqkuv...\n/tmp/shallow-clone-DDqkuv/repo\n```\n\nAfter analyzing the local repository, clean up the temporary directory with:\n\n```shell\n$ rm -rf <path_to_temporary_directory>\n```"
              },
              {
                "name": "pipeline-debugger",
                "description": "Debug and monitor GitLab CI/CD pipelines for merge requests. Check pipeline status, view job logs, and troubleshoot CI failures. Use this when the user needs to investigate GitLab CI pipeline issues, check job statuses, or view specific job logs.",
                "path": "claude-plugins/gitlab/skills/pipeline-debugger/SKILL.md",
                "frontmatter": {
                  "name": "pipeline-debugger",
                  "description": "Debug and monitor GitLab CI/CD pipelines for merge requests. Check pipeline status, view job logs, and troubleshoot CI failures. Use this when the user needs to investigate GitLab CI pipeline issues, check job statuses, or view specific job logs.",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# GitLab CI Debugger\n\nThis skill enables Claude to investigate GitLab CI pipeline failures by:\n\n1. Checking the current pipeline status for a branch, merge request, or a specific pipeline ID\n2. Identifying failed jobs\n3. Retrieving failed job logs\n4. Analyzing error messages and suggesting fixes\n\n## Prerequisites\n\n- Git repository with GitLab remote configured\n- GitLab authentication via GITLAB_TOKEN env var or .netrc file\n\nThe script will fail if it detects any missing configuration. Interpret the error message and provide instructions\nfor setting up the required configuration.\n\n## Instructions\n\n**IMPORTANT**: Always run the script from the user's current working directory (where Claude was launched), NOT from the\nskill directory. The script needs access to the git repository context. Use the base directory (`<base_path>`) for this\nskill to execute the script with an absolute path.\n\nWhen the user asks to check CI status, debug pipeline failures, or view job logs:\n\n1. **Check Current Pipeline Status**\n    - Run `<base_path>/scripts/check_pipeline.py` without arguments to check the current branch's pipeline status\n    - The script will display all jobs grouped by stage with status indicators\n\n2. **Check Specific Branch**\n    - If the user asks to check on the pipeline status for a different branch than the current one, use the `-b` or\n      `--branch` option to specify that branch.\n        - Example: `<base_path>/scripts/check_pipeline.py -b feature-branch`\n\n3. **Check Specific Pipeline by ID**\n    - If the user provides a pipeline ID directly, use the `-p` or `--pipeline-id` option to inspect that pipeline\n    - This skips the merge request lookup and directly inspects the specified pipeline\n    - Example: `<base_path>/scripts/check_pipeline.py -p 12519874995`\n    - Note: `--pipeline-id` and `--branch` are mutually exclusive\n\n4. **View Job Logs**\n    - Use the `-j` or `--job` option to retrieve and display logs for a specific job\n    - Example: `<base_path>/scripts/check_pipeline.py -j \"test-job-name\"`\n    - Can be combined with any of the above options (branch, pipeline ID, or current branch)\n    - The script will show the job's metadata and full log output\n\n5. **Troubleshoot CI Failures**\n    - If the user asks to troubleshoot a CI failure, use the full log output of a job to identify the error and suggest\n      fixes."
              },
              {
                "name": "upload-chat-log",
                "description": "Export and upload the current chat conversation as a markdown file attachment to a JIRA ticket for later review and documentation.",
                "path": "claude-plugins/jira/skills/upload-chat-log/SKILL.md",
                "frontmatter": {
                  "name": "upload-chat-log",
                  "description": "Export and upload the current chat conversation as a markdown file attachment to a JIRA ticket for later review and documentation."
                },
                "content": "# Upload Chat Log to JIRA\n\nExport and upload the current chat conversation as a markdown file attachment to a JIRA ticket for later review and documentation.\n\n## Prerequisites\n\n- Python 3 and `uv` must be installed and available in PATH\n- `JIRA_API_TOKEN` environment variable must be set with a valid API token for https://issues.redhat.com\n- Appropriate JIRA permissions to add attachments to the target ticket\n\n## Usage\n\nThis skill exports the current conversation as a formatted markdown document and uploads it as an attachment to a specified JIRA ticket.\n\n## Implementation\n\n### Step 1: Determine the Ticket Key\n\n1. If a ticket key is provided by the user, use it\n2. Otherwise, search the conversation history for JIRA ticket references (e.g., \"AIPCC-1234\", \"working on PROJ-567\")\n3. If no ticket is found in context, ask the user: \"Which JIRA ticket should I attach this chat log to? (e.g., AIPCC-1234)\"\n\n### Step 2: Format the Conversation with Summary and Full Transcript\n\nCreate a document with two main sections: Summary and Full Chat Log. Format the document as follows:\n\n```markdown\n# Chat Log Export - JIRA Ticket: [ticket-key]\n\n**Exported**: [current timestamp]\n**Ticket**: https://issues.redhat.com/browse/[ticket-key]\n\n---\n\n## Summary\n\n[Provide a concise summary of the conversation including:\n- Main topic/task discussed\n- Key decisions made\n- Files created/modified\n- Important outcomes or next steps\n- 3-5 paragraphs maximum]\n\n---\n\n## Full Chat Transcript\n\n[Export the complete conversation transcript in the same format as the `/export` command:\n- All user messages and assistant responses\n- All tool calls and their results\n- Code blocks, thinking blocks, and system messages\n- Timestamps and metadata\n- The full, unabridged conversation from start to finish]\n```\n\nThe summary should be human-readable and highlight key points. The full transcript should be comprehensive for detailed review.\n\n### Step 3: Save to Temporary File\n\n1. Create a temporary file with a descriptive name: `chat-log-{ticket-key}-{timestamp}.md`\n2. Write the formatted conversation to this file\n3. Store in `/tmp/claude/` directory (respects TMPDIR environment)\n\n### Step 4: Upload to JIRA\n\n1. Use the upload script located at `scripts/upload_chat_log.py` relative to this skill\n2. Run the script directly (not via `python`) to invoke uv properly via the shebang:\n   ```bash\n   ./scripts/upload_chat_log.py <ticket-key> <file-path>\n   ```\n3. The script will:\n   - Read the `JIRA_API_TOKEN` environment variable\n   - Connect to https://issues.redhat.com\n   - Upload the file as an attachment to the specified ticket\n   - Return success or error messages\n\n### Step 5: Confirm and Clean Up\n\n1. If upload succeeds:\n   - Inform the user: \"Successfully uploaded chat log to {ticket-key} on https://issues.redhat.com\"\n   - Provide the direct link: `https://issues.redhat.com/browse/{ticket-key}`\n2. If upload fails:\n   - Display the error message from the script\n   - Provide troubleshooting guidance (check token, permissions, ticket exists)\n3. Delete the temporary file after upload attempt (success or failure)\n\n## Error Handling\n\n- **Missing JIRA_API_TOKEN**: Provide clear instructions on how to obtain and set the token\n- **Invalid Ticket Key**: Verify the ticket exists and is accessible\n- **Permission Denied**: Check that the API token has permission to add attachments\n- **Script Not Found**: Verify the script exists at the expected path\n- **Upload Failure**: Display the specific error and suggest checking network, credentials, and ticket accessibility\n\n## Examples\n\n### Basic Usage\n```\nUser: Upload this chat to AIPCC-7354\nAssistant: [Skill creates formatted chat log and uploads to AIPCC-7354]\n```\n\n### No Ticket Specified\n```\nUser: Upload this conversation to JIRA\nAssistant: Which JIRA ticket should I attach this chat log to? (e.g., AIPCC-1234)\nUser: RHEL-9876\nAssistant: [Skill uploads to RHEL-9876]\n```\n\n### Context Detection\n```\nUser: We're working on AIPCC-7354. Can you upload our conversation?\nAssistant: [Skill detects AIPCC-7354 from context and uploads automatically]\n```"
              },
              {
                "name": "complexity",
                "description": "Analyze Python package build complexity by inspecting PyPI metadata. Evaluates compilation requirements, dependencies, distribution types, and provides recommendations for wheel building strategies.",
                "path": "claude-plugins/python-packaging/skills/complexity/SKILL.md",
                "frontmatter": {
                  "name": "complexity",
                  "description": "Analyze Python package build complexity by inspecting PyPI metadata. Evaluates compilation requirements, dependencies, distribution types, and provides recommendations for wheel building strategies.",
                  "allowed-tools": [
                    "Bash",
                    "Read"
                  ]
                },
                "content": "# Python Package Build Complexity Analysis\n\nThis skill helps you evaluate the build complexity of Python packages by analyzing their PyPI metadata. It determines whether a package likely requires compilation, assesses build complexity, and provides recommendations for wheel building strategies.\n\n## Instructions\n\nWhen a user asks about Python package build complexity, building wheels, or evaluating PyPI packages for compilation requirements:\n\n1. **Run the PyPI inspection script** using the package name and optional version:\n   ```bash\n   ./scripts/pypi_inspect.py <package_name> [version]\n   ```\n\n2. **Analyze the output** and provide interpretation focusing on:\n\n   ### Build Complexity Assessment\n   - **Compilation Requirements**: Whether the package needs C/C++/Rust/Fortran compilation\n   - **Complexity Score**: Numerical score indicating build difficulty (0-10+ scale)\n   - **Key Indicators**: Specific classifiers, keywords, or dependencies that suggest complexity\n\n   ### Distribution Analysis\n   - **Source Distribution Availability**: Whether sdist is available for building\n   - **Existing Wheels**: What wheel types already exist (platform-specific, universal)\n   - **Wheel Coverage**: Gaps in wheel availability that might need custom builds\n\n   ### Dependency Analysis\n   - **Complex Dependencies**: Dependencies that themselves require compilation\n   - **Version Constraints**: Python version requirements and compatibility\n   - **Transitive Complexity**: How dependencies affect overall build complexity\n\n3. **Provide actionable recommendations**:\n   - Whether to build from source or use existing wheels\n   - Required build tools and dependencies\n   - Platform-specific considerations\n   - Estimated build time and resource requirements\n\n## Key Complexity Indicators\n\n### High Complexity (Score 5+)\n- Native extensions (C/C++/Rust/Fortran classifiers)\n- CUDA/GPU acceleration keywords\n- Known complex packages (torch, tensorflow, numpy, scipy)\n- Missing or limited wheel availability\n- Many compiled dependencies\n\n### Medium Complexity (Score 2-4)\n- Some compilation indicators in description/keywords\n- Platform-specific wheels only\n- Mixed dependency complexity\n- Moderate build requirements\n\n### Low Complexity (Score 0-1)\n- Pure Python packages\n- Universal wheels available\n- Simple dependencies\n- No compilation requirements\n\n## Usage Examples\n\n### Basic Package Analysis\n```bash\n./scripts/pypi_inspect.py torch\n```\n**Interpretation**: Analyze latest PyTorch version for build complexity, focusing on CUDA dependencies and compilation requirements.\n\n### Specific Version Analysis\n```bash\n./scripts/pypi_inspect.py numpy 1.24.3\n```\n**Interpretation**: Evaluate specific numpy version, explaining why numpy requires compilation and what build tools are needed.\n\n### JSON Output for Processing\n```bash\n./scripts/pypi_inspect.py tensorflow --json\n```\n**Interpretation**: Get structured data for programmatic analysis, then explain the complexity factors in plain language.\n\n## Providing Recommendations\n\nBased on the analysis, provide specific guidance:\n\n### For High Complexity Packages\n- \"This package requires significant compilation infrastructure\"\n- \"Consider using pre-built wheels when available\"\n- \"Building from source will need: [specific tools]\"\n- \"Estimated build time: [timeframe]\"\n\n### For Wheel Building Strategies\n- \"Universal wheels available - use those for maximum compatibility\"\n- \"Platform-specific wheels needed for: [platforms]\"\n- \"Source build recommended for: [specific scenarios]\"\n- \"Dependencies that complicate building: [list]\"\n\n### For Development Planning\n- \"Budget [time] for build environment setup\"\n- \"Consider containerized builds for reproducibility\"\n- \"Test on target platforms before production deployment\"\n- \"Monitor for new wheel releases that might eliminate build needs\"\n\n## Error Handling\n\nIf the script fails or package is not found:\n- Verify package name spelling and availability on PyPI\n- Check if the package exists under a different name\n- Suggest alternative analysis approaches\n- Provide general guidance for unknown packages\n\n## Integration Notes\n\nThis skill works best when combined with:\n- **python-packaging:license-finder** - License information helps assess redistribution requirements\n- Package dependency analysis\n- Build environment setup\n- Continuous integration planning\n- Container build strategies"
              },
              {
                "name": "env-finder",
                "description": "Investigate environment variables that can be set when building Python wheels for a given project. Analyzes setup.py, CMake files, and other build configuration files to discover customizable build environment variables.",
                "path": "claude-plugins/python-packaging/skills/env-finder/SKILL.md",
                "frontmatter": {
                  "name": "env-finder",
                  "description": "Investigate environment variables that can be set when building Python wheels for a given project. Analyzes setup.py, CMake files, and other build configuration files to discover customizable build environment variables.",
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Grep",
                    "Glob"
                  ]
                },
                "content": "# Python Build Environment Variables Investigation\n\nThis skill helps you discover all environment variables that can be set when building Python wheels for a project. It performs a comprehensive analysis of build configuration files to identify customizable environment variables used during the wheel building process.\n\n## Instructions\n\nWhen a user asks about environment variables for building Python wheels, investigating build configuration, or understanding build customization options:\n\n1. **Run the Environment Variables Investigation Script**:\n   ```bash\n   ./scripts/env_finder.py [project_path]\n   ```\n\n2. **Analyze and present the findings** focusing on:\n\n   ### Build Configuration Variables\n   - **Setup.py Variables**: Environment variables used in setup.py for customizing builds\n   - **CMake Variables**: Variables defined in CMakeLists.txt and related files\n   - **Build Tool Variables**: Variables used by setuptools, distutils, or other build systems\n   - **Compiler Variables**: Variables affecting compilation (CC, CXX, CFLAGS, etc.)\n\n   ### Variable Categories\n\n   #### Compiler and Linker Variables\n   - `CC`, `CXX` - Compiler selection\n   - `CFLAGS`, `CXXFLAGS` - Compilation flags\n   - `LDFLAGS` - Linker flags\n   - `LIBS` - Additional libraries\n\n   #### Path Configuration Variables\n   - `PREFIX` - Installation prefix\n   - `LIBRARY_PATH` - Library search paths\n   - `INCLUDE_PATH` - Header file paths\n   - `PKG_CONFIG_PATH` - pkg-config search paths\n\n   #### Feature Control Variables\n   - `ENABLE_*` - Feature enable/disable flags\n   - `WITH_*` - Optional component inclusion\n   - `USE_*` - Build option selection\n   - `DISABLE_*` - Feature disable flags\n\n   #### Python-Specific Variables\n   - `PYTHON_INCLUDE_DIR` - Python headers location\n   - `PYTHON_LIBRARY` - Python library path\n   - `SETUPTOOLS_*` - Setuptools configuration\n   - `PIP_*` - pip-related build variables\n\n   ### Usage Context\n   - **When Variables Are Used**: During which build phase each variable takes effect\n   - **Default Values**: What happens when variables are not set\n   - **Required vs Optional**: Which variables are mandatory for successful builds\n\n3. **Provide actionable guidance**:\n   - How to set each variable for custom builds\n   - Common use cases for each variable\n   - Potential conflicts or compatibility issues\n   - Recommended values for different scenarios\n\n## Output Format\n\nThe skill should provide a structured list of environment variables with:\n\n1. **Variable Name**: Exact environment variable name\n2. **Purpose**: Clear description of what the variable controls\n3. **Type**: Expected value type (path, boolean, string, number)\n4. **Default Value**: What happens when not set\n5. **Source File**: Where the variable was discovered\n6. **Usage Context**: When and how the variable is used\n\n## Error Handling and Edge Cases\n\n### No Build Configuration Found\n- Report that no environment variables were found\n- Most packages don't have build configuration so it is fine"
              },
              {
                "name": "license-checker",
                "description": "Assess license compatibility for Python package redistribution using SPDX.org license database. Evaluates whether a given license allows building and distributing wheels, with real-time license information lookup.",
                "path": "claude-plugins/python-packaging/skills/license-checker/SKILL.md",
                "frontmatter": {
                  "name": "license-checker",
                  "description": "Assess license compatibility for Python package redistribution using SPDX.org license database. Evaluates whether a given license allows building and distributing wheels, with real-time license information lookup.",
                  "allowed-tools": [
                    "WebFetch"
                  ]
                },
                "content": "# Python Package License Compatibility Checker\n\nThis skill helps you evaluate whether a Python package license is compatible with redistribution, particularly for building and distributing wheels in enterprise environments. It uses the authoritative SPDX License List for accurate, up-to-date license information.\n\n## Assessment Instructions\n\nWhen a user provides a license name and asks about compatibility for redistribution, building wheels, or licensing restrictions, follow this methodology:\n\n### Step-by-Step Process\n\n1. **Fetch Current SPDX Data**:\n   ```\n   Use WebFetch to query: https://raw.githubusercontent.com/spdx/license-list-data/main/json/licenses.json\n   ```\n\n2. **License Matching**:\n   - Try exact SPDX ID match first\n   - Try case-insensitive SPDX ID match\n   - Try full name matching\n   - Try partial/fuzzy matching for common variations\n\n3. **Risk Classification**:\n   ```\n   IF (isOsiApproved AND isFsfLibre AND permissive_pattern):\n       Risk = Low, Status = Compatible\n   ELIF (isOsiApproved AND weak_copyleft_pattern):\n       Risk = Medium, Status = Compatible with Requirements\n   ELIF (strong_copyleft_pattern OR NOT isOsiApproved):\n       Risk = High, Status = Restricted/Incompatible\n   ```\n\n4. **Generate Assessment**:\n   - Include all SPDX metadata\n   - Provide clear compatibility guidance\n   - List specific requirements\n   - Add Red Hat context where relevant\n\n## License Assessment Framework\n\n### Input Processing\nAccept various formats and normalize them:\n- **SPDX Identifiers**: \"MIT\", \"Apache-2.0\", \"GPL-3.0-only\"\n- **Full Names**: \"MIT License\", \"Apache License 2.0\", \"GNU General Public License v3.0\"\n- **Common Aliases**: \"Apache 2\", \"BSD 3-Clause\", \"GPLv3\"\n- **Case Variations**: Handle case-insensitive matching\n\n### SPDX Data Analysis\nWhen processing SPDX license data, examine these key fields:\n- `licenseId`: Official SPDX identifier\n- `name`: Full license name\n- `isOsiApproved`: OSI approval status (boolean)\n- `isFsfLibre`: FSF Free Software status (boolean)\n- `isDeprecatedLicenseId`: Whether license is deprecated (boolean)\n- `reference`: URL to full license details\n- `seeAlso`: Array of additional reference URLs\n\n### Compatibility Assessment Logic\n\nUse SPDX flags and license patterns to determine compatibility:\n\n#### ✅ Highly Compatible (Low Risk)\n- OSI Approved AND FSF Libre\n- Permissive licenses (MIT, Apache, BSD, ISC family)\n- No strong copyleft requirements\n\n#### ⚠️ Compatible with Requirements (Medium Risk)\n- OSI Approved but specific obligations\n- Weak copyleft (LGPL, MPL)\n- File-level copyleft licenses\n\n#### ❌ Restricted/High Risk\n- Strong copyleft (GPL, AGPL)\n- Non-OSI approved licenses\n- Proprietary or unclear terms\n\n### Output Format\n\nProvide a structured assessment with:\n\n1. **SPDX Information**:\n   - Official SPDX ID\n   - Full license name\n   - OSI Approved: Yes/No\n   - FSF Libre: Yes/No\n   - Deprecated: Yes/No (if applicable)\n\n2. **Compatibility Assessment**:\n   - Status: Compatible/Restricted/Incompatible\n   - Redistribution: Allowed/Restricted/Prohibited\n   - Commercial Use: Allowed/Restricted/Prohibited\n\n3. **Requirements**: Key compliance obligations\n4. **Risk Level**: Low/Medium/High for enterprise use\n5. **Red Hat Context**: Special considerations if applicable\n\n\n## Red Hat Vendor Agreements\n\nRed Hat has specific licensing agreements with the following hardware vendors:\n\n- **NVIDIA**: Agreement covers CUDA libraries, runtimes, and related NVIDIA proprietary components\n- **Intel Gaudi**: Agreement covers Gaudi AI accelerator software and libraries\n- **IBM Spyre**: Agreement covers IBM Spyre AI hardware and associated software components\n\nWhen evaluating packages with dependencies on these vendor-specific components, note that Red Hat has explicit redistribution rights under these agreements.\n\n## Error Handling\n\n### SPDX Data Fetch Failures\nIf the SPDX license list cannot be retrieved, exit early and warn the user.\n\n### License Not Found in SPDX\nWhen a license identifier is not found in the SPDX license list:\n1. Check for common typos or variations\n2. Suggest SPDX-compliant alternatives\n3. Recommend contacting package maintainer\n4. Provide conservative risk assessment\n\n### Deprecated Licenses\nFor deprecated SPDX licenses:\n1. Note the deprecation status\n2. Suggest migrating to current equivalent\n3. Provide assessment based on deprecated license terms\n4. Recommend updating package licensing\n\nFor complex licensing scenarios involving multiple packages or custom license terms, recommend consultation with legal counsel.\n\n## Integration Notes\n\nThis skill works best when combined with:\n- **python-packaging:license-finder** - Use to find license names before compatibility assessment"
              },
              {
                "name": "license-finder",
                "description": "Deterministically find license information for Python packages by checking PyPI metadata first, then falling back to Git repository LICENSE files using shallow cloning.",
                "path": "claude-plugins/python-packaging/skills/license-finder/SKILL.md",
                "frontmatter": {
                  "name": "license-finder",
                  "description": "Deterministically find license information for Python packages by checking PyPI metadata first, then falling back to Git repository LICENSE files using shallow cloning.",
                  "allowed-tools": [
                    "Bash",
                    "Skill"
                  ]
                },
                "content": "# Python Package License Finder\n\nThis skill helps you deterministically find license information for Python packages using a two-step approach: first checking PyPI metadata, then searching the source repository if needed.\n\n## Instructions\n\nWhen a user asks to find the license for a Python package, follow this deterministic process:\n\n### Step 1: Check PyPI Metadata\nFirst, attempt to find the license from PyPI using the package inspection script:\n\n```bash\n./scripts/find_license.py <package_name> [version]\n```\n\nIf the script finds a license in the PyPI metadata, **stop here** and return the license name.\n\n### Step 2: Search Git Repository (if PyPI fails)\nIf no license is found in PyPI metadata, search the package's source repository:\n\n1. **Get the source repository URL** from the PyPI metadata (the script will provide it)\n2. **Use the shallow-clone skill** to clone the repository:\n   ```\n   Skill: git:shallow-clone\n   ```\n3. **Search for LICENSE files** in the cloned repository:\n   ```bash\n   find . -iname \"license*\" -o -iname \"copying*\" -o -iname \"copyright*\" | head -10\n   ```\n4. **Read the license file** to identify the license type:\n   ```bash\n   head -20 <license_file>\n   ```\n\n### Step 3: Report Results\n- **License Found**: Return the license name (e.g., \"MIT License\", \"Apache-2.0\", \"GPL-3.0\")\n- **License Not Found**: Report that the license could not be determined\n\n## Usage Examples\n\n### Find License for Popular Package\n```bash\n./scripts/find_license.py requests\n```\n**Expected**: Find \"Apache-2.0\" from PyPI metadata\n\n### Find License for Package with Missing PyPI License\n```bash\n./scripts/find_license.py some-package\n```\n**Expected**: Fall back to repository search if PyPI metadata is incomplete\n\n### Specific Version Analysis\n```bash\n./scripts/find_license.py django 4.2.0\n```\n**Expected**: Find license for specific Django version\n\n## Error Handling\n\n### Package Not Found\n- Verify package name spelling\n- Check package availability on PyPI\n- Suggest alternative package names\n\n### Repository Access Issues\n- Report if source repository is unavailable\n- Note private/restricted repositories\n- Suggest manual license verification\n\n### License File Parsing\n- Handle non-standard license file formats\n- Report unclear or multiple licenses\n- Recommend manual review for complex cases\n\n## Integration Notes\n\nThis skill complements:\n- **python-packaging:complexity** - License info helps assess redistribution complexity\n- **python-packaging:license-checker** - Provides license names for compatibility assessment\n- **python-packaging:source-finder** - Uses similar PyPI metadata analysis\n\nThe skill focuses on **finding** license information, while license-checker focuses on **assessing** license compatibility for redistribution."
              },
              {
                "name": "source-finder",
                "description": "Locate source code repositories for Python packages by analyzing PyPI metadata, project URLs, and code hosting platforms like GitHub, GitLab, and Bitbucket. Provides deterministic results with confidence levels.",
                "path": "claude-plugins/python-packaging/skills/source-finder/SKILL.md",
                "frontmatter": {
                  "name": "source-finder",
                  "description": "Locate source code repositories for Python packages by analyzing PyPI metadata, project URLs, and code hosting platforms like GitHub, GitLab, and Bitbucket. Provides deterministic results with confidence levels.",
                  "allowed-tools": [
                    "Bash",
                    "WebSearch",
                    "WebFetch"
                  ]
                },
                "content": "# Source Finder\n\nLocates source code repositories for Python packages with confidence scoring.\n\n## Usage\n\nTo find a source repository for a given package:\n\n1. Run the finder script, for example:\n\n```\n# Find repository\n$ ./scripts/finder.py requests\n\n# Output structure:\n{\n  \"url\": \"https://github.com/psf/requests\",\n  \"confidence\": \"high\",\n  \"method\": \"pypi_metadata_project_urls.Source\",\n  \"package_name\": \"requests\"\n}\n```\n\n2. Parse the JSON output:\n\n- `url`: Repository URL (or `null` if not found)\n- `confidence`: `high`, `medium`, or `low`\n- `method`: How the URL was found\n- `package_name`: the package that was searched\n\n3. If confidence is `low` or `url` is `null`, use WebSearch: `<package_name> python github repository`\n\n4. Present results with confidence level clearly indicated\n\n## Output Format\n\nAs a result, provide structured output including:\n\n- Repository URL\n- Confidence level (high/medium/low)\n- Method used to find the repository\n- Additional context or warnings"
              },
              {
                "name": "vLLM Slack Summary",
                "description": "Generate slack summaries of vLLM CI SIG Slack channel activity for the RHAIIS midstream release team",
                "path": "claude-plugins/vllm/skills/vllm-slack-summary/SKILL.md",
                "frontmatter": {
                  "name": "vLLM Slack Summary",
                  "description": "Generate slack summaries of vLLM CI SIG Slack channel activity for the RHAIIS midstream release team"
                },
                "content": "# vLLM slack Summary Skill\n\nAutomates generating slack summaries of the vLLM CI SIG Slack channel for the Red Hat AI Inference Server (RHAIIS) team.\n\n## Prerequisites\n\n- **slackdump** installed and authenticated with vLLM workspace\n  - Install: <https://github.com/rusq/slackdump>\n  - Auth: Run `slackdump workspace add`\n\n## Usage\n\n```bash\n./scripts/generate_transcript.py                    # Last 7 days (default)\n./scripts/generate_transcript.py --days 14          # Custom date range\n./scripts/generate_transcript.py --output-dir out   # Custom output directory\n```\n\n## Context\n\nWhen summarizing the transcript, focus on:\n\n- **Breaking changes** affecting the RHAIIS midstream build\n- **Hardware issues** with H100, A100, MI300, or B200 GPUs\n- **CI/CD infrastructure** changes impacting test reliability\n- **Dependencies** changes in build requirements or Python packages\n- **Performance regressions** that could affect RHAIIS\n- **Upstream releases** and their stability status\n\n## Output\n\nThe skill creates `vllm_slack_summary/` containing:\n\n```text\nvllm_slack_summary/\n├── slack_export/                               # Raw Slack export\n├── transcript.md                               # Markdown transcript\n└── slack_summary_YYYY-MM-DD_to_YYYY-MM-DD.md  # Summary report\n```\n\nAfter generating the transcript, analyze it and create a summary with:\n\n- Executive Summary (2-3 sentences)\n- Key Issues & Resolutions\n- CI/CD Infrastructure Changes\n- Action Items for Red Hat Team\n\n## Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| slackdump not found | Ensure slackdump is in PATH: `which slackdump` |\n| Authentication failed | Run `slackdump workspace add` |\n| No messages found | Check date range; channel may have no messages in that period |\n\n## Quick Reference\n\n- **Channel ID**: C07R5PAL2L9 (vLLM CI SIG)\n- **Transcript**: `vllm_slack_summary/transcript.md`\n- **Summary**: `vllm_slack_summary/slack_summary_YYYY-MM-DD_to_YYYY-MM-DD.md`"
              }
            ]
          }
        ]
      }
    }
  ]
}