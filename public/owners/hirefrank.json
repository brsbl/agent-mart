{
  "owner": {
    "id": "hirefrank",
    "display_name": "Frank Harris",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/183158?u=177b308e618232af40302e4373ce84d1eebfc433&v=4",
    "url": "https://github.com/hirefrank",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 30,
      "total_skills": 17,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "hirefrank/hirefrank-marketplace",
      "url": "https://github.com/hirefrank/hirefrank-marketplace",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2025-12-19T11:24:04Z",
        "created_at": "2025-10-22T20:20:23Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2053
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/agents/doc-sync-specialist.md",
          "type": "blob",
          "size": 9588
        },
        {
          "path": ".claude/agents/upstream-tracker.md",
          "type": "blob",
          "size": 11258
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/check-upstream.md",
          "type": "blob",
          "size": 18599
        },
        {
          "path": ".claude/commands/release-plugin.md",
          "type": "blob",
          "size": 14576
        },
        {
          "path": ".claude/commands/research-blog-updates.md",
          "type": "blob",
          "size": 16511
        },
        {
          "path": ".claude/settings.json",
          "type": "blob",
          "size": 239
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/ISSUE_TEMPLATE.md",
          "type": "blob",
          "size": 1709
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 895
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 7936
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/CONTRIBUTING.md",
          "type": "blob",
          "size": 3541
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 469
        },
        {
          "path": "plugins/claude-skills-analyzer/README.md",
          "type": "blob",
          "size": 20064
        },
        {
          "path": "plugins/claude-skills-analyzer/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/commands/analyze-skills.md",
          "type": "blob",
          "size": 17925
        },
        {
          "path": "plugins/claude-skills-analyzer/commands/extract-exports.md",
          "type": "blob",
          "size": 9008
        },
        {
          "path": "plugins/claude-skills-analyzer/commands/skills-setup.md",
          "type": "blob",
          "size": 9216
        },
        {
          "path": "plugins/claude-skills-analyzer/commands/skills-troubleshoot.md",
          "type": "blob",
          "size": 6075
        },
        {
          "path": "plugins/claude-skills-analyzer/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/shared/analysis-methodology.md",
          "type": "blob",
          "size": 15163
        },
        {
          "path": "plugins/claude-skills-analyzer/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/conversation-analyzer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/conversation-analyzer/SKILL.md",
          "type": "blob",
          "size": 3429
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer-web",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer-web/README.md",
          "type": "blob",
          "size": 5247
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer-web/SKILL.md",
          "type": "blob",
          "size": 23644
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer/README.md",
          "type": "blob",
          "size": 11296
        },
        {
          "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer/SKILL.md",
          "type": "blob",
          "size": 11366
        },
        {
          "path": "plugins/edge-stack",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 950
        },
        {
          "path": "plugins/edge-stack/.logs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/.logs/.gitignore",
          "type": "blob",
          "size": 148
        },
        {
          "path": "plugins/edge-stack/.logs/CHANGELOG.md",
          "type": "blob",
          "size": 6364
        },
        {
          "path": "plugins/edge-stack/.logs/IMPLEMENTATION_GUIDE.md",
          "type": "blob",
          "size": 11329
        },
        {
          "path": "plugins/edge-stack/.logs/README.md",
          "type": "blob",
          "size": 955
        },
        {
          "path": "plugins/edge-stack/.logs/blog-updates.json",
          "type": "blob",
          "size": 1183
        },
        {
          "path": "plugins/edge-stack/.logs/upstream-check.json",
          "type": "blob",
          "size": 4136
        },
        {
          "path": "plugins/edge-stack/.mcp.json",
          "type": "blob",
          "size": 2293
        },
        {
          "path": "plugins/edge-stack/README.md",
          "type": "blob",
          "size": 28168
        },
        {
          "path": "plugins/edge-stack/UPSTREAM.md",
          "type": "blob",
          "size": 26059
        },
        {
          "path": "plugins/edge-stack/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/binding-context-analyzer.md",
          "type": "blob",
          "size": 9588
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/cloudflare-architecture-strategist.md",
          "type": "blob",
          "size": 30544
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/cloudflare-data-guardian.md",
          "type": "blob",
          "size": 27434
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/cloudflare-pattern-specialist.md",
          "type": "blob",
          "size": 30344
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/cloudflare-security-sentinel.md",
          "type": "blob",
          "size": 25896
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/durable-objects-architect.md",
          "type": "blob",
          "size": 13584
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/edge-caching-optimizer.md",
          "type": "blob",
          "size": 20146
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/edge-performance-oracle.md",
          "type": "blob",
          "size": 22907
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/kv-optimization-specialist.md",
          "type": "blob",
          "size": 21178
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/r2-storage-architect.md",
          "type": "blob",
          "size": 21121
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/workers-ai-specialist.md",
          "type": "blob",
          "size": 27404
        },
        {
          "path": "plugins/edge-stack/agents/cloudflare/workers-runtime-guardian.md",
          "type": "blob",
          "size": 5976
        },
        {
          "path": "plugins/edge-stack/agents/integrations",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/agents/integrations/accessibility-guardian.md",
          "type": "blob",
          "size": 20403
        },
        {
          "path": "plugins/edge-stack/agents/integrations/better-auth-specialist.md",
          "type": "blob",
          "size": 19024
        },
        {
          "path": "plugins/edge-stack/agents/integrations/mcp-efficiency-specialist.md",
          "type": "blob",
          "size": 20251
        },
        {
          "path": "plugins/edge-stack/agents/integrations/playwright-testing-specialist.md",
          "type": "blob",
          "size": 27956
        },
        {
          "path": "plugins/edge-stack/agents/integrations/polar-billing-specialist.md",
          "type": "blob",
          "size": 17115
        },
        {
          "path": "plugins/edge-stack/agents/integrations/resend-email-specialist.md",
          "type": "blob",
          "size": 29655
        },
        {
          "path": "plugins/edge-stack/agents/research",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/agents/research/git-history-analyzer.md",
          "type": "blob",
          "size": 3065
        },
        {
          "path": "plugins/edge-stack/agents/tanstack",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/agents/tanstack/frontend-design-specialist.md",
          "type": "blob",
          "size": 29731
        },
        {
          "path": "plugins/edge-stack/agents/tanstack/tanstack-migration-specialist.md",
          "type": "blob",
          "size": 15303
        },
        {
          "path": "plugins/edge-stack/agents/tanstack/tanstack-routing-specialist.md",
          "type": "blob",
          "size": 15304
        },
        {
          "path": "plugins/edge-stack/agents/tanstack/tanstack-ssr-specialist.md",
          "type": "blob",
          "size": 10835
        },
        {
          "path": "plugins/edge-stack/agents/tanstack/tanstack-ui-architect.md",
          "type": "blob",
          "size": 14160
        },
        {
          "path": "plugins/edge-stack/agents/workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/agents/workflow/code-simplicity-reviewer.md",
          "type": "blob",
          "size": 5476
        },
        {
          "path": "plugins/edge-stack/agents/workflow/feedback-codifier.md",
          "type": "blob",
          "size": 13025
        },
        {
          "path": "plugins/edge-stack/agents/workflow/repo-research-analyst.md",
          "type": "blob",
          "size": 4551
        },
        {
          "path": "plugins/edge-stack/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/commands/es-auth-setup.md",
          "type": "blob",
          "size": 7453
        },
        {
          "path": "plugins/edge-stack/commands/es-billing-setup.md",
          "type": "blob",
          "size": 15517
        },
        {
          "path": "plugins/edge-stack/commands/es-commit.md",
          "type": "blob",
          "size": 8901
        },
        {
          "path": "plugins/edge-stack/commands/es-component.md",
          "type": "blob",
          "size": 24896
        },
        {
          "path": "plugins/edge-stack/commands/es-deploy.md",
          "type": "blob",
          "size": 11682
        },
        {
          "path": "plugins/edge-stack/commands/es-design-review.md",
          "type": "blob",
          "size": 17544
        },
        {
          "path": "plugins/edge-stack/commands/es-email-setup.md",
          "type": "blob",
          "size": 29799
        },
        {
          "path": "plugins/edge-stack/commands/es-issue.md",
          "type": "blob",
          "size": 9969
        },
        {
          "path": "plugins/edge-stack/commands/es-migrate.md",
          "type": "blob",
          "size": 25883
        },
        {
          "path": "plugins/edge-stack/commands/es-plan.md",
          "type": "blob",
          "size": 4829
        },
        {
          "path": "plugins/edge-stack/commands/es-report-bug.md",
          "type": "blob",
          "size": 10198
        },
        {
          "path": "plugins/edge-stack/commands/es-resolve-parallel.md",
          "type": "blob",
          "size": 2167
        },
        {
          "path": "plugins/edge-stack/commands/es-review.md",
          "type": "blob",
          "size": 16413
        },
        {
          "path": "plugins/edge-stack/commands/es-tanstack-component.md",
          "type": "blob",
          "size": 7093
        },
        {
          "path": "plugins/edge-stack/commands/es-tanstack-migrate.md",
          "type": "blob",
          "size": 21881
        },
        {
          "path": "plugins/edge-stack/commands/es-tanstack-route.md",
          "type": "blob",
          "size": 5372
        },
        {
          "path": "plugins/edge-stack/commands/es-tanstack-server-fn.md",
          "type": "blob",
          "size": 4886
        },
        {
          "path": "plugins/edge-stack/commands/es-test-gen.md",
          "type": "blob",
          "size": 13770
        },
        {
          "path": "plugins/edge-stack/commands/es-test-setup.md",
          "type": "blob",
          "size": 11030
        },
        {
          "path": "plugins/edge-stack/commands/es-theme.md",
          "type": "blob",
          "size": 20659
        },
        {
          "path": "plugins/edge-stack/commands/es-triage.md",
          "type": "blob",
          "size": 6359
        },
        {
          "path": "plugins/edge-stack/commands/es-validate.md",
          "type": "blob",
          "size": 8206
        },
        {
          "path": "plugins/edge-stack/commands/es-verify-output.md",
          "type": "blob",
          "size": 17291
        },
        {
          "path": "plugins/edge-stack/commands/es-work.md",
          "type": "blob",
          "size": 7154
        },
        {
          "path": "plugins/edge-stack/commands/es-worker.md",
          "type": "blob",
          "size": 5435
        },
        {
          "path": "plugins/edge-stack/commands/generate_command.md",
          "type": "blob",
          "size": 3192
        },
        {
          "path": "plugins/edge-stack/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/docs/mcp-usage-examples.md",
          "type": "blob",
          "size": 8415
        },
        {
          "path": "plugins/edge-stack/docs/tanstack-start-migration-status.md",
          "type": "blob",
          "size": 8250
        },
        {
          "path": "plugins/edge-stack/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/hooks/hooks.json",
          "type": "blob",
          "size": 645
        },
        {
          "path": "plugins/edge-stack/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/hooks/scripts/validate-bash.sh",
          "type": "blob",
          "size": 1371
        },
        {
          "path": "plugins/edge-stack/hooks/scripts/validate-file.sh",
          "type": "blob",
          "size": 1182
        },
        {
          "path": "plugins/edge-stack/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/agent-native-architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/agent-native-architecture/SKILL.md",
          "type": "blob",
          "size": 18544
        },
        {
          "path": "plugins/edge-stack/skills/agent-native-architecture/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/agent-native-architecture/examples/durable-objects-state.md",
          "type": "blob",
          "size": 10385
        },
        {
          "path": "plugins/edge-stack/skills/agent-native-architecture/examples/queue-messaging.md",
          "type": "blob",
          "size": 13916
        },
        {
          "path": "plugins/edge-stack/skills/agent-native-architecture/examples/verification-patterns.md",
          "type": "blob",
          "size": 22232
        },
        {
          "path": "plugins/edge-stack/skills/agent-native-architecture/examples/workers-event-driven.md",
          "type": "blob",
          "size": 12046
        },
        {
          "path": "plugins/edge-stack/skills/animation-interaction-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/animation-interaction-validator/SKILL.md",
          "type": "blob",
          "size": 18401
        },
        {
          "path": "plugins/edge-stack/skills/auth-security-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/auth-security-validator/SKILL.md",
          "type": "blob",
          "size": 3452
        },
        {
          "path": "plugins/edge-stack/skills/cloudflare-security-checker",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/cloudflare-security-checker/SKILL.md",
          "type": "blob",
          "size": 8097
        },
        {
          "path": "plugins/edge-stack/skills/component-aesthetic-checker",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/component-aesthetic-checker/SKILL.md",
          "type": "blob",
          "size": 17129
        },
        {
          "path": "plugins/edge-stack/skills/cors-configuration-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/cors-configuration-validator/SKILL.md",
          "type": "blob",
          "size": 12577
        },
        {
          "path": "plugins/edge-stack/skills/durable-objects-pattern-checker",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/durable-objects-pattern-checker/SKILL.md",
          "type": "blob",
          "size": 11572
        },
        {
          "path": "plugins/edge-stack/skills/edge-performance-optimizer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/edge-performance-optimizer/SKILL.md",
          "type": "blob",
          "size": 9458
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/.env.example",
          "type": "blob",
          "size": 123
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/.gitignore",
          "type": "blob",
          "size": 312
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/README.md",
          "type": "blob",
          "size": 2606
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/SKILL.md",
          "type": "blob",
          "size": 6954
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/package.json",
          "type": "blob",
          "size": 640
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/scripts/compose-images.ts",
          "type": "blob",
          "size": 9223
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/scripts/edit-image.ts",
          "type": "blob",
          "size": 5439
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/scripts/generate-image.ts",
          "type": "blob",
          "size": 4808
        },
        {
          "path": "plugins/edge-stack/skills/gemini-imagegen/tsconfig.json",
          "type": "blob",
          "size": 449
        },
        {
          "path": "plugins/edge-stack/skills/kv-optimization-advisor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/kv-optimization-advisor/SKILL.md",
          "type": "blob",
          "size": 11143
        },
        {
          "path": "plugins/edge-stack/skills/polar-integration-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/polar-integration-validator/SKILL.md",
          "type": "blob",
          "size": 2929
        },
        {
          "path": "plugins/edge-stack/skills/shadcn-ui-design-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/shadcn-ui-design-validator/SKILL.md",
          "type": "blob",
          "size": 11510
        },
        {
          "path": "plugins/edge-stack/skills/workers-binding-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/workers-binding-validator/SKILL.md",
          "type": "blob",
          "size": 8930
        },
        {
          "path": "plugins/edge-stack/skills/workers-runtime-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/edge-stack/skills/workers-runtime-validator/SKILL.md",
          "type": "blob",
          "size": 5321
        }
      ],
      "marketplace": {
        "name": "hirefrank-marketplace",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Frank Harris",
          "email": "frank@hirefrank.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "claude-skills-analyzer",
            "description": "Analyze AI conversation exports to generate reusable Claude Skills",
            "source": "./plugins/claude-skills-analyzer",
            "category": "productivity",
            "version": "1.0.0",
            "author": {
              "name": "Frank Harris",
              "email": "frank@hirefrank.com"
            },
            "install_commands": [
              "/plugin marketplace add hirefrank/hirefrank-marketplace",
              "/plugin install claude-skills-analyzer@hirefrank-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-12-19T11:24:04Z",
              "created_at": "2025-10-22T20:20:23Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/analyze-skills",
                "description": "Analyze AI conversation exports to generate reusable Custom Skills",
                "path": "plugins/claude-skills-analyzer/commands/analyze-skills.md",
                "frontmatter": {
                  "description": "Analyze AI conversation exports to generate reusable Custom Skills"
                },
                "content": "# Analyze Skills Command\n\nYou are a Claude Skills Architect analyzing a user's complete AI conversation history to identify, prioritize, and automatically generate custom Claude Skills. Custom Skills are reusable instruction sets with proper YAML frontmatter, supporting documentation, and templates that help Claude consistently produce high-quality outputs for recurring tasks.\n\n**ultrathink**: Use extended thinking capabilities when you encounter:\n- Large conversation datasets (>50 conversations) requiring deep pattern analysis\n- Complex cross-platform deduplication decisions\n- Ambiguous skill boundary determinations\n- Statistical validation of pattern significance\n- Strategic tradeoffs in skill consolidation\n\nYou decide when extended reasoning will improve analysis quality. Trust your judgment.\n\n## Your Mission\nPerform comprehensive analysis of conversation exports to:\n1. Identify all potential custom skill opportunities\n2. Eliminate redundancies and optimize skill boundaries  \n3. Generate complete, ready-to-use skill packages\n4. Provide implementation roadmap and maintenance guidance\n5. **Enable incremental processing** - skip previously analyzed conversations and build on prior work\n\n**Analysis Approach:**\n- Use extended reasoning to identify non-obvious patterns across conversations\n- Think deeply about skill boundaries and overlap resolution\n- Consider temporal patterns and user expertise evolution\n- Validate pattern significance statistically before recommending skills\n- Reason through cross-platform deduplication decisions carefully\n\n## Input Format\nThe user should have their conversation export files in the `data-exports/` directory structure. If not already created, the `/skills-setup` command will create this automatically.\n\nExpected structure:\n```\ndata-exports/\nâ”œâ”€â”€ chatgpt/          # Place ChatGPT export files here\nâ”‚   â”œâ”€â”€ conversations.json\nâ”‚   â”œâ”€â”€ user.json\nâ”‚   â”œâ”€â”€ shared_conversations.json\nâ”‚   â””â”€â”€ message_feedback.json (optional)\nâ””â”€â”€ claude/           # Place Claude export files here\n    â”œâ”€â”€ conversations.json\n    â”œâ”€â”€ projects.json\n    â””â”€â”€ users.json\n```\n\n**Note**: If you haven't run `/skills-setup` yet, use it first to create the necessary directory structure and get detailed export instructions.\n\n### Claude Export Format (data-exports/claude/):\n1. **conversations.json** - Complete conversation history with messages, timestamps, and metadata\n2. **projects.json** - Project information including descriptions, documentation, and workflows\n3. **users.json** - User account information (for privacy considerations and expertise assessment)\n\n### ChatGPT Export Format (data-exports/chatgpt/):\n1. **conversations.json** - Conversation history with mapping structure and message objects\n2. **user.json** - User profile information with account details\n3. **shared_conversations.json** - Shared conversation metadata with titles and IDs\n4. **message_feedback.json** - User feedback on AI responses (if available)\n5. **shopping.json** - Transaction and purchase data (if available)\n\n### Platform Detection:\nAutomatically detect available platforms by scanning both data-exports/ directories and adapt processing accordingly.\n\n## Analysis Framework\n\nThis command uses the **[shared analysis methodology](../shared/analysis-methodology.md)** with export-specific enhancements.\n\n### Phase 0: Analysis Scope Determination (Export-Specific)\n\n1. **Check for Previous Analysis Log**:\n   - If user provides a previous analysis log (from prior runs), parse it to identify:\n     - Previously analyzed conversation IDs and their analysis dates\n     - Generated skills and their source conversations\n     - File modification dates or content hashes of processed files\n     - Analysis metadata (dates, conversation counts, skill counts)\n\n2. **Determine Analysis Scope**:\n   - Compare current conversation files with previous analysis log\n   - Identify new conversations (not in previous log)\n   - Identify potentially modified conversations (based on message counts, dates, or user indication)\n   - Flag conversations that need analysis vs. those to skip for efficiency\n\n3. **Output Analysis Plan**:\n   - List conversations to be analyzed (new + potentially modified)\n   - List conversations being skipped (unchanged from previous run)\n   - Estimated processing scope and rationale\n   - Expected time and complexity of analysis\n\n### Phase 1: Data Processing & Pattern Discovery\n\n**Use extended reasoning to identify subtle patterns across large conversation sets.**\n\n1. **Platform Detection and Data Parsing** (Export-Specific):\n   - Auto-detect export format (Claude vs ChatGPT) \n   - Parse conversations, projects, user data based on platform\n   - Extract expertise indicators and usage patterns\n\n2. **Apply [Shared Pattern Discovery](../shared/analysis-methodology.md#phase-1-pattern-discovery--classification)**:\n   - **Data-driven domain discovery** (let actual topics emerge - DO NOT force into predefined categories)\n   - Task types (creation, transformation, analysis, troubleshooting, curation)\n   - Explicit and implicit pattern markers\n   - Niche & specialized pattern detection (hobbyist domains, creative work, prompt engineering, etc.)\n   - Temporal pattern detection\n   - User expertise evolution over time\n\n3. **Export-Specific Enhancements**:\n   - Cross-reference with project data (Claude exports):\n     - How many projects demonstrate similar patterns?\n     - Do project descriptions reinforce conversation patterns?\n     - Project success indicators and user satisfaction\n   - Message feedback analysis (ChatGPT exports):\n     - User feedback patterns on AI responses\n     - Quality improvement opportunities\n\n**Think deeply about:**\n- Are these truly distinct patterns or variations of the same workflow?\n- What makes this pattern recurring vs. one-off requests?\n- How do patterns evolve across the user's conversation timeline?\n\n**Terminal Output - Domain Diversity Visualization:**\n\nAfter completing pattern discovery, display an ASCII chart showing domain distribution to validate data-driven discovery:\n\n```\nðŸ“Š Domain Distribution Analysis\n\nBusiness & Strategy    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 12 patterns (32%)\nCreative & Writing     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 10 patterns (27%)\nImage Prompting        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  8 patterns (22%)\nLearning & Education   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4 patterns (11%)\nRecipe & Cooking       â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  2 patterns  (5%)\nGaming & Design        â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  1 pattern   (3%)\n\nâœ… Domain Diversity: 6 distinct topic areas detected\nâœ… No predefined categorization - domains emerged from your data\n```\n\nThis validates that the analysis discovered diverse patterns beyond traditional business/coding domains.\n\n### Phase 2-4: Core Analysis\n\nApply the **[shared analysis methodology](../shared/analysis-methodology.md)** phases:\n\n- **Phase 2**: Frequency & Temporal Analysis with project data cross-referencing\n- **Phase 3**: Skill-Worthiness Scoring (0-50 composite scale)\n- **Phase 4**: Relationship Mapping & Overlap Analysis\n\nSee [shared methodology](../shared/analysis-methodology.md) for complete details.\n\n### Phase 5: Cross-Platform Pattern Deduplication (Export-Specific)\n\nWhen processing mixed datasets (both ChatGPT and Claude exports), perform comprehensive deduplication before skill generation.\n\nSee **[shared methodology - Cross-Platform Deduplication](../shared/analysis-methodology.md#cross-platform-deduplication-export-analysis-only)** for:\n- Content similarity detection\n- Deduplication classification rules\n- Pattern frequency recalculation\n- Unified skill design preparation\n- Deduplication validation\n\n**Export-Specific Advantages:**\n- Access to complete conversation history (not just recent/accessible)\n- Project metadata integration (Claude)\n- Message feedback data (ChatGPT)\n- Temporal analysis across months/years\n\n### Phase 6: Skill Generation & Optimization\n\n**Use extended reasoning to optimize skill boundaries and maximize user value.**\n\nApply **[shared methodology - Prioritization Matrix](../shared/analysis-methodology.md#phase-5-prioritization-matrix)** and boundary optimization strategies.\n\n**Export-Specific Enhancements:**\n- Leverage project success data for impact validation\n- Use message feedback for quality improvement insights\n- Apply historical trend analysis for strategic pattern identification\n\n## Output Generation Options\n\nAsk user to choose:\n\n**Option A: Analysis Report Only**\n- Comprehensive analysis with recommendations\n- No file generation\n- Implementation guidance only\n\n**Option B: Complete Implementation Package** (Recommended)\n- Full analysis plus ready-to-use skills\n- Proper folder structure with all supporting files\n- Testing and validation guidance\n\n**Option C: Incremental Implementation**\n- Start with top 3-5 skills\n- Provide complete package for priority skills\n- Expansion roadmap for additional skills\n\n**Option D: Custom Specification**\n- User-defined subset of skills\n- Specific modifications or requirements\n- Tailored to particular use cases\n\n## File Generation (Option B/C)\n\n**Note**: If these directories don't exist, they will be automatically created by the analysis process.\n\n### Create Analysis Reports\nGenerate timestamped reports in `reports/{TIMESTAMP}/`:\n\n1. **`skills-analysis-log.json`** (Root directory) - Machine-readable incremental processing data\n\n**Example structure:**\n```json\n{\n  \"analysis_date\": \"YYYY-MM-DDTHH:MM:SSZ\",\n  \"platform_detected\": \"claude|chatgpt|mixed\",\n  \"total_conversations\": 150,\n  \"report_directory\": \"reports/2025-01-23_22-40-00\",\n  \"conversations_analyzed\": [\n    {\n      \"id\": \"conv_123\",\n      \"platform\": \"chatgpt|claude\",\n      \"file\": \"data-exports/chatgpt/conversations.json\",\n      \"message_count\": 45,\n      \"first_message_date\": \"2024-01-01T10:00:00Z\",\n      \"last_message_date\": \"2024-01-10T14:20:00Z\",\n      \"analysis_hash\": \"sha256:abc123...\",\n      \"topics_identified\": [\"coding\", \"documentation\"],\n      \"patterns_found\": 3\n    }\n  ],\n  \"deduplication_summary\": {\n    \"cross_platform_duplicates_removed\": 45,\n    \"workflow_instances_merged\": 12,\n    \"frequency_adjustments\": {\n      \"newsletter_critique\": {\"before\": 1225, \"after\": 987},\n      \"business_communication\": {\"before\": 709, \"after\": 643}\n    }\n  },\n  \"skills_generated\": [\n    {\n      \"skill_name\": \"newsletter-critique-specialist\",\n      \"source_conversations\": [\"conv_123\", \"conv_789\"],\n      \"frequency_score\": 8,\n      \"impact_score\": 9,\n      \"platform_coverage\": \"both\",\n      \"generated_files\": [\n        \"generated-skills/newsletter-critique-specialist/SKILL.md\",\n        \"generated-skills/newsletter-critique-specialist/reference.md\"\n      ]\n    }\n  ],\n  \"analysis_metadata\": {\n    \"total_patterns_identified\": 25,\n    \"patterns_consolidated\": 8,\n    \"patterns_deduplicated\": 6,\n    \"final_skill_count\": 5,\n    \"processing_time_minutes\": 45\n  }\n}\n```\n\n2. **`comprehensive-skills-analysis.md`** - Complete pattern analysis with skill recommendations and prioritization visualization\n3. **`implementation-guide.md`** - Actionable deployment roadmap\n\n**Report Visualization Requirements:**\n\nInclude a Mermaid quadrant chart in `comprehensive-skills-analysis.md` showing the prioritization matrix:\n\n```markdown\n## ðŸ“Š Skill Prioritization Matrix\n\n```mermaid\n%%{init: {'theme':'base'}}%%\nquadrantChart\n    title Skill Prioritization: Frequency vs Impact\n    x-axis Low Frequency --> High Frequency\n    y-axis Low Impact --> High Impact\n    quadrant-1 Strategic\n    quadrant-2 Quick Wins\n    quadrant-3 Defer\n    quadrant-4 Automate\n    [Skill Name 1]: [freq_score/10, impact_score/10]\n    [Skill Name 2]: [freq_score/10, impact_score/10]\n    [Skill Name 3]: [freq_score/10, impact_score/10]\n```\n\\```\n\n**Legend:**\n- **Quick Wins** (top-right): High frequency, high impact - implement first\n- **Strategic** (top-left): Lower frequency but high value - critical capabilities\n- **Automate** (bottom-right): High frequency, simpler - nice efficiency gains\n- **Defer** (bottom-left): Low priority - consider simple prompts instead\n\n**Calculations:**\n- X-axis (Frequency): Use frequency score (0-10) from skill-worthiness evaluation\n- Y-axis (Impact): Average of complexity + time savings + error reduction scores (0-10)\n```\n\n### Generate Skill Packages\nFor each approved skill, create complete folder structure in `generated-skills/`:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required - main skill with YAML frontmatter)\nâ”œâ”€â”€ reference.md (detailed methodology and frameworks)\nâ”œâ”€â”€ examples.md (additional examples and use cases)\nâ”œâ”€â”€ templates/ (reusable templates for outputs)\nâ”‚   â”œâ”€â”€ template-1.md\nâ”‚   â””â”€â”€ template-2.md\nâ””â”€â”€ scripts/ (utility scripts if applicable)\n    â””â”€â”€ helper-script.py\n```\n\n**Auto-creation**: The `generated-skills/` directory will be created automatically when you select Option B or C.\n\n### SKILL.md Generation Template\n```yaml\n---\nname: [skill-name]  # Only lowercase letters, numbers, and hyphens\ndescription: [CRITICAL: Must include BOTH what skill does AND when to use it. Written in third person. Include key trigger terms.]\n---\n\n# [Skill Name]\n\n## Instructions\n[Clear, step-by-step guidance - KEEP UNDER 500 LINES TOTAL]\n\n1. **[Phase 1 Name]**\n   - [Specific instruction 1]\n   - [Specific instruction 2]\n\n2. **[Apply Framework/Method]** from [reference.md](reference.md):\n   - [Framework element 1]\n   - [Framework element 2]\n\n3. **[Use Templates]** from [templates/](templates/):\n   - [Template 1 description and usage]\n   - [Template 2 description and usage]\n\n4. **[Quality Standards]**:\n   - [Standard 1]\n   - [Standard 2]\n\n## Examples\n\n### [Example Scenario 1]\n**User Request**: \"[Realistic user request]\"\n\n**Response using methodology**:\n```\n[Complete example showing proper skill usage]\n```\n\nFor more examples, see [examples.md](examples.md).\nFor detailed methodology, see [reference.md](reference.md).\n```\n\n## Quality Standards\n\nAll quality standards follow the **[shared analysis methodology](../shared/analysis-methodology.md#quality-standards)**:\n\n- Pattern validation requirements (frequency, consistency, evidence)\n- Skill consolidation rules (max 8-12 skills, clear boundaries)\n- Skill package generation standards\n- Anti-patterns to avoid\n\n**Export-Specific Enhancements:**\n- Minimum frequency: 50+ occurrences OR high strategic value (with complete history available)\n- Cross-platform evidence: Include examples from both platforms when available\n- Project data validation: Cross-reference patterns with project success metrics\n\n## Instructions for Execution\n\n1. **Initialize Timestamp**: Create `TIMESTAMP=$(date +%Y-%m-%d_%H-%M-%S)`\n2. **Create Reports Directory**: `mkdir -p reports/{TIMESTAMP}`\n3. **Check for Previous Analysis Log**: Look for existing `skills-analysis-log.json` in root directory\n4. **Scan Data Directories**: Check `data-exports/chatgpt/` and `data-exports/claude/` for available platforms\n5. **Determine analysis scope** using Phase 0 if previous log exists\n6. **Start with user choice** of output option (A/B/C/D)\n7. **Perform complete analysis** following all phases for determined scope\n8. **Execute cross-platform deduplication** if both ChatGPT and Claude data detected (Phase 5)\n9. **Generate output files**:\n   - Update/create `skills-analysis-log.json` in root directory\n   - Create `reports/{TIMESTAMP}/comprehensive-skills-analysis.md`\n   - Create `reports/{TIMESTAMP}/implementation-guide.md`\n10. **Generate skill packages** in `generated-skills/` if requested (Option B/C)\n11. **Validate all content** using quality framework and analysis standards\n12. **Cleanup Phase**:\n    - Remove temporary analysis scripts from `scripts/` directory\n    - Delete intermediate data processing files (*.tmp, *.cache, etc.)\n    - Remove empty directories created during processing\n    - Clean up any Python virtual environments or temporary dependencies\n    - Remove duplicate or staging files from skill generation process\n13. **Archive Organization** (Optional):\n    - Compress older reports directories (keep last 3-5 runs)\n    - Move temporary logs to archive subdirectory\n    - Consolidate debug output into single log file\n14. **Cleanup Validation**:\n    - Verify all essential outputs remain intact:\n      - `skills-analysis-log.json` (root)\n      - `reports/{TIMESTAMP}/` directory with analysis reports\n      - `generated-skills/` directory with skill packages\n    - Confirm no critical files were accidentally removed\n    - Display cleanup summary showing what was removed vs. retained\n\n### Quality Focus Requirements\n\nApply **[shared methodology quality standards](../shared/analysis-methodology.md#quality-standards)** with export-specific validation:\n- Eliminate generic patterns and focus on specific workflows\n- Consolidate overlapping skills (max 8-12, recommend top 5-8)\n- Validate frequency claims post-deduplication\n- Prioritize by genuine impact (>30 min/week time savings)\n- Platform-agnostic design for all generated skills\n\n### For Incremental Processing\nIf user provides previous analysis log:\n- Parse the log to understand what was previously analyzed\n- Skip unchanged conversations (based on IDs and metadata)\n- Focus on new or modified conversations only\n- Re-run deduplication if new platform data added\n- Integrate new findings with previous skill recommendations\n- Update the analysis log with new data\n\n**Data Location**: JSON files are located in `data-exports/chatgpt/` and `data-exports/claude/` subdirectories. The system will automatically detect available platform(s) and process files accordingly."
              },
              {
                "name": "/extract-exports",
                "description": "Automatically extract and organize AI conversation export zip files into proper directory structure",
                "path": "plugins/claude-skills-analyzer/commands/extract-exports.md",
                "frontmatter": {
                  "description": "Automatically extract and organize AI conversation export zip files into proper directory structure"
                },
                "content": "# Extract Exports Command\n\nAutomatically extract AI conversation export zip files (Claude and/or ChatGPT) and organize them into the proper directory structure for skills analysis.\n\n## What This Command Does\n\n1. **Detects export zip files** in your current directory\n2. **Identifies platform type** (Claude vs ChatGPT) by examining contents\n3. **Creates directory structure** if it doesn't exist\n4. **Extracts and organizes files** into correct locations\n5. **Validates file placement** and reports results\n6. **Cleans up** temporary files and optionally removes original zips\n\n## Expected Directory Structure After Extraction\n\n```\nyour-project/\nâ”œâ”€â”€ data-exports/\nâ”‚   â”œâ”€â”€ claude/           # Claude export files\nâ”‚   â”‚   â”œâ”€â”€ conversations.json\nâ”‚   â”‚   â”œâ”€â”€ projects.json\nâ”‚   â”‚   â””â”€â”€ users.json\nâ”‚   â””â”€â”€ chatgpt/          # ChatGPT export files\nâ”‚       â”œâ”€â”€ conversations.json\nâ”‚       â”œâ”€â”€ user.json\nâ”‚       â”œâ”€â”€ shared_conversations.json\nâ”‚       â””â”€â”€ message_feedback.json\nâ”œâ”€â”€ reports/              # Analysis reports (created when needed)\nâ””â”€â”€ generated-skills/     # Generated skills (created when needed)\n```\n\n## How to Use\n\n1. **Download your export zip files** from Claude and/or ChatGPT\n2. **Place zip files in your current directory** (where you want the analysis to happen)\n3. **Run this command**: The system will handle the rest automatically\n\n## Supported Export Formats\n\n### Claude Exports\nExpected zip contents:\n- `conversations.json` (required)\n- `projects.json` (optional)\n- `users.json` (optional)\n\n### ChatGPT Exports  \nExpected zip contents:\n- `conversations.json` (required)\n- `user.json` (optional)\n- `shared_conversations.json` (optional)\n- `message_feedback.json` (optional)\n- `shopping.json` (optional - will be ignored)\n\n## Instructions for Execution\n\n1. **Scan Current Directory**:\n   - Look for `*.zip` files in current directory\n   - Report found zip files to user for confirmation\n\n2. **Create Directory Structure**:\n   - Create `data-exports/` directory if it doesn't exist\n   - Create `data-exports/claude/` subdirectory\n   - Create `data-exports/chatgpt/` subdirectory\n   - Create `reports/` and `generated-skills/` directories for future use\n\n3. **Process Each Zip File**:\n   - Extract to temporary directory (`temp_extract_TIMESTAMP/`)\n   - Examine contents to identify platform type\n   - Look for key indicator files:\n     - Claude: `conversations.json` + `projects.json` present\n     - ChatGPT: `conversations.json` + `user.json` present\n     - Mixed/Unknown: Ask user to specify platform\n\n4. **Platform Detection Logic**:\n   ```\n   If contains \"projects.json\" â†’ Claude export\n   Else if contains \"user.json\" â†’ ChatGPT export\n   Else if only \"conversations.json\" â†’ Ask user to specify\n   Else â†’ Invalid export format\n   ```\n\n5. **File Organization**:\n   - **For Claude exports**: Move all JSON files to `data-exports/claude/`\n   - **For ChatGPT exports**: Move all JSON files to `data-exports/chatgpt/`\n   - Skip non-JSON files (README, etc.)\n   - Handle file conflicts by asking user preference (overwrite/skip/backup)\n\n6. **Validation**:\n   - Verify required files (`conversations.json`) are present\n   - Check file sizes are reasonable (not empty, not suspiciously large)\n   - Validate JSON format of critical files\n   - Report any missing optional files\n\n7. **Cleanup Options**:\n   - Remove temporary extraction directories\n   - Ask user about original zip files:\n     - **Keep**: Leave original zips in place\n     - **Archive**: Move to `archives/` subdirectory\n     - **Delete**: Remove original zips completely\n\n8. **Final Report**:\n   - Summary of extracted files by platform\n   - Location of organized files\n   - Any warnings or issues encountered\n   - Next steps recommendation (run `/analyze-skills`)\n\n## User Interaction Flow\n\n```\nFound the following zip files:\nâ€¢ claude_export_2024_01_20.zip (2.3 MB)\nâ€¢ chatgpt_export_jan_2024.zip (4.1 MB)\n\nProceed with extraction and organization? [Y/n]\n\nâœ… Creating directory structure...\nâœ… Extracting claude_export_2024_01_20.zip...\n   â†’ Detected: Claude export (found projects.json)\n   â†’ Moving files to data-exports/claude/\n   â†’ Files: conversations.json, projects.json, users.json\n\nâœ… Extracting chatgpt_export_jan_2024.zip...\n   â†’ Detected: ChatGPT export (found user.json)\n   â†’ Moving files to data-exports/chatgpt/\n   â†’ Files: conversations.json, user.json, shared_conversations.json\n\nâœ… Validation complete:\n   â€¢ Claude: 1,247 conversations in conversations.json\n   â€¢ ChatGPT: 892 conversations in conversations.json\n\nWhat should I do with the original zip files?\n[K]eep them / [A]rchive them / [D]elete them: A\n\nâœ… Original zips moved to archives/\n\nðŸŽ‰ Export organization complete!\n\nYour files are now ready for analysis:\nâ€¢ Claude exports: data-exports/claude/\nâ€¢ ChatGPT exports: data-exports/chatgpt/\n\nNext step: Run `/analyze-skills` to identify skill opportunities\n```\n\n## Error Handling\n\n### Common Issues & Solutions\n\n**No zip files found**:\n- Check current directory for `*.zip` files\n- Verify zip files are conversation exports (not other types)\n- Provide guidance on downloading exports if needed\n\n**Corrupted or invalid zip files**:\n- Report which zip file has issues\n- Suggest re-downloading from the platform\n- Continue with other valid zip files\n\n**Missing required files**:\n- Report missing `conversations.json`\n- Explain impact on analysis capability\n- Suggest contacting platform support\n\n**JSON parsing errors**:\n- Report which file has JSON format issues\n- Attempt to continue with other files\n- Suggest platform support if file appears corrupted\n\n**Directory permission issues**:\n- Check write permissions for current directory\n- Provide clear error message and resolution steps\n- Suggest alternative directory if needed\n\n**Disk space issues**:\n- Check available disk space before extraction\n- Estimate space needed based on zip file sizes\n- Provide cleanup recommendations if space is low\n\n## File Conflict Resolution\n\nWhen files already exist in target directories:\n\n**Conversations.json exists**:\n```\nFound existing conversations.json in data-exports/claude/\nâ€¢ Existing: 1,156 conversations (last modified: 2024-01-15)\nâ€¢ New: 1,247 conversations (from zip file)\n\nChoose action:\n[O]verwrite with new file\n[B]ackup existing and use new\n[S]kip extraction (keep existing)\n[C]ompare and merge (advanced)\n\nYour choice: B\n\nâœ… Existing file backed up as conversations_backup_2024-01-20.json\nâœ… New file extracted as conversations.json\n```\n\n## Integration with Other Commands\n\n**Seamless workflow with existing commands**:\n- After successful extraction â†’ Suggest running `/analyze-skills`\n- If directory structure missing â†’ Automatically create (no need for `/skills-setup`)\n- Before analysis â†’ Check for proper file organization\n\n**State validation**:\n- Check if exports are already extracted before running\n- Detect incremental updates (new exports vs existing data)\n- Provide smart recommendations based on current state\n\n## Quality Standards\n\n**File Validation Requirements**:\n- Verify JSON files are valid JSON format\n- Check that conversations.json contains actual conversation data\n- Validate file sizes are within reasonable ranges (not empty, not huge)\n- Ensure required fields exist in JSON structure\n\n**Security Considerations**:\n- Only extract to controlled subdirectories\n- Sanitize file names to prevent directory traversal\n- Validate zip contents before extraction\n- Limit extraction to reasonable file sizes\n\n**User Experience Standards**:\n- Clear progress indicators during extraction\n- Descriptive error messages with resolution steps\n- Confirmation prompts for destructive actions\n- Helpful next-step recommendations\n\n## Advanced Features\n\n**Incremental Processing Support**:\n- Detect if exports contain new conversations vs existing data\n- Smart merge options for updated exports\n- Preserve existing analysis logs and reports\n\n**Batch Processing**:\n- Handle multiple zip files from same platform\n- Merge multiple ChatGPT exports if user has multiple accounts\n- Consolidate multiple Claude exports from different time periods\n\n**Cross-Platform Intelligence**:\n- Detect potential duplicate conversations across platforms\n- Flag cross-platform analysis opportunities\n- Prepare data for unified analysis workflow\n\n## Commands Integration\n\nThis command works seamlessly with:\n- **`/skills-setup`**: No longer needed if this command is run first\n- **`/analyze-skills`**: Ready to run immediately after extraction\n- **`/skills-troubleshoot`**: Can diagnose extraction-related issues\n\n**Recommended workflow**:\n1. Download exports from Claude/ChatGPT\n2. Run `/extract-exports` (this command)\n3. Run `/analyze-skills` for pattern analysis\n4. Implement recommended skills\n\nReady to automatically organize your conversation exports!"
              },
              {
                "name": "/skills-setup",
                "description": "Guide you through setting up AI conversation exports for skills analysis",
                "path": "plugins/claude-skills-analyzer/commands/skills-setup.md",
                "frontmatter": {
                  "description": "Guide you through setting up AI conversation exports for skills analysis"
                },
                "content": "# Skills Analysis Setup Guide\n\nI'll walk you through setting up your AI conversation exports for analysis and help you get the most value from the Claude Skills Analyzer.\n\n## ðŸ“‹ What You'll Need\n\nTo analyze your AI usage patterns and generate Custom Skills, you need:\n\n1. **AI conversation exports** (Claude and/or ChatGPT)\n2. **Organized directory structure** for your data\n3. **At least 20+ conversations** for basic analysis (50+ recommended for robust patterns)\n\n## ðŸ“¥ How to Export Your Conversations\n\n### For Claude Conversations:\n\n**Step 1: Request Export**\n1. Go to [claude.ai/settings](https://claude.ai/settings)\n2. Click on **\"Privacy\"** in the left sidebar\n3. Look for **\"Request data export\"** or similar option\n4. Click the button to request your export\n\n**Step 2: Wait for Email**\n- Claude will send you an email when your export is ready\n- This typically takes 24 hours (sometimes sooner)\n- The email will contain a download link\n\n**Step 3: Extract and Save**\n1. Download the ZIP file from the email\n2. **Option A - Automatic** (Recommended): Place the ZIP file in your project directory and run `/extract-exports` - it will automatically extract and organize everything for you\n3. **Option B - Manual**: Extract all files (you'll have `conversations.json`, `projects.json`, etc.) and save them to your `data-exports/claude/` folder (we'll create this next)\n\n**Files you should see:**\n- `conversations.json` (required) - Your conversation history\n- `projects.json` (optional) - Project information and metadata\n- `users.json` (optional) - Account information\n\n**âš ï¸ Important Note:**\nClaude exports from claude.ai **DO NOT include Claude Code conversations**. Only conversations from the web interface (claude.ai) are included in the export. If you primarily use Claude Code, your export may have fewer conversations than expected.\n\n### For ChatGPT Conversations:\n\n**Step 1: Request Export**\n1. Go to [chatgpt.com/settings/general](https://chatgpt.com/settings/general)\n2. Scroll down to **\"Data controls\"** section\n3. Click **\"Export data\"**\n4. Select what you want to export (conversations are usually pre-selected)\n5. Confirm the export request\n\n**Step 2: Wait for Email**\n- ChatGPT will send you an email when your export is ready\n- This usually takes 2-4 hours\n- The email will contain a download link\n\n**Step 3: Extract and Save**\n1. Download the ZIP file from the email\n2. **Option A - Automatic** (Recommended): Place the ZIP file in your project directory and run `/extract-exports` - it will automatically extract and organize everything for you\n3. **Option B - Manual**: Extract all files (you'll have `conversations.json`, `user.json`, etc.) and save them to your `data-exports/chatgpt/` folder (we'll create this next)\n\n**Files you should see:**\n- `conversations.json` (required) - Your conversation history\n- `user.json` (optional) - Account information\n- `shared_conversations.json` (optional) - Shared conversations metadata\n- `message_feedback.json` (optional) - Your feedback on responses\n\n### Troubleshooting Export:\n\n**Can't find Settings?**\n- Claude: Look for your account icon (bottom left) â†’ Settings â†’ Privacy & Data\n- ChatGPT: Click your account name (bottom left) â†’ Settings â†’ scroll to Data controls\n\n**Export not arriving?**\n- Check spam/junk email folder\n- Wait a bit longer (can take up to 24 hours)\n- Try requesting again if it's been >24 hours\n\n**Files look different?**\n- Export formats can vary slightly between updates\n- As long as you have `conversations.json`, the analysis will work\n- Missing optional files is fine\n\n---\n\n## ðŸ—‚ï¸ Directory Structure Setup\n\nI can create the proper directory structure for you automatically. Here's what will be created:\n\n```\nyour-project/\nâ”œâ”€â”€ data-exports/\nâ”‚   â”œâ”€â”€ claude/           # Place Claude exports here\nâ”‚   â””â”€â”€ chatgpt/          # Place ChatGPT exports here\nâ”œâ”€â”€ reports/              # Analysis reports will appear here\nâ””â”€â”€ generated-skills/     # Generated skills will appear here\n```\n\n**Ready to create these directories?**\n\nJust confirm and I'll set up:\n- âœ… `data-exports/claude/` - for your Claude conversation exports\n- âœ… `data-exports/chatgpt/` - for your ChatGPT conversation exports\n- âœ… `reports/` - for timestamped analysis reports\n- âœ… `generated-skills/` - for your generated Custom Skills\n\nConfirm when you're ready!\n\n**ðŸ’¡ Quick Tip**: Once you have the ZIP files from Claude/ChatGPT, you can use the `/extract-exports` command to automatically extract and organize everything for you! Just place the ZIP files in your project directory and run the command.\n\n## âš¡ Quick Start Checklist\n\n**Setup Phase:**\n- [ ] Directories created (`data-exports/`, `reports/`, `generated-skills/`)\n- [ ] At least one platform export requested (Claude and/or ChatGPT)\n- [ ] Waiting for export email to arrive (24 hours or less)\n\n**Data Phase:**\n- [ ] Export files downloaded and extracted\n- [ ] JSON files placed in correct `data-exports/` subdirectories\n- [ ] You have at least 20+ conversations (more is better for patterns)\n\n**Analysis Phase:**\n- [ ] Ready to run `/analyze-skills` when exports are ready\n- [ ] Know which output option you want (A, B, C, or D)\n- [ ] Have time for analysis to complete (2-5 minutes typically)\n\n**Completion:**\n- [ ] Analysis finished and reports generated\n- [ ] Review skills recommendations\n- [ ] Generate or implement skills as desired\n\n## ðŸŽ¯ What the Analysis Will Find\n\nThe plugin will identify patterns like:\n\n### Business & Communication\n- Email drafting templates\n- Proposal writing workflows\n- Client communication patterns\n- Meeting preparation structures\n\n### Development & Code\n- Code review methodologies\n- Documentation standards\n- Debugging approaches\n- Architecture decision patterns\n\n### Content & Writing\n- Blog post structures\n- Newsletter formats\n- Social media workflows\n- Research methodologies\n\n### Personal Productivity\n- Task planning approaches\n- Decision-making frameworks\n- Learning note-taking systems\n- Goal-setting patterns\n\n## ðŸ“Š Analysis Options\n\nWhen you run `/analyze-skills`, you'll choose from:\n\n- **Option A**: Analysis report only (insights and recommendations)\n- **Option B**: Complete implementation package (ready-to-use skills)\n- **Option C**: Incremental implementation (top 3-5 skills)\n- **Option D**: Custom specification (your defined requirements)\n\n## ðŸ”’ Privacy & Security\n\n- **Local processing**: All analysis happens on your machine\n- **No data upload**: Your conversations never leave your system\n- **Anonymized output**: Generated skills remove personal information\n- **Git protection**: Export files are automatically ignored by version control\n\n## ðŸš€ Expected Results\n\nAfter analysis, you'll get:\n\n### Analysis Reports (`reports/timestamp/`)\n- **Comprehensive analysis** with pattern evidence\n- **Implementation guide** with deployment roadmap\n- **Processing log** for incremental future runs\n\n### Generated Skills (`generated-skills/skill-name/`)\n- **SKILL.md** - Main skill with YAML frontmatter\n- **reference.md** - Detailed methodology\n- **examples.md** - Usage examples  \n- **templates/** - Reusable output templates\n\n## â“ Common Questions\n\n**Q: How many conversations do I need?**\nA: Minimum 20-30 for basic analysis, 50+ for meaningful patterns, 100+ for comprehensive insights.\n\n**Q: Are Claude Code conversations included in exports?**\nA: No. Claude exports from claude.ai only include web interface conversations. Claude Code conversations are stored separately and are not included in data exports. If you primarily use Claude Code, consider using ChatGPT exports or the web-based workflow-pattern-analyzer skill instead.\n\n**Q: Can I analyze both Claude and ChatGPT together?**\nA: Yes! The plugin performs smart cross-platform deduplication and creates unified skills.\n\n**Q: What if I don't have many conversations?**\nA: Start with what you have. The plugin supports incremental processing, so you can re-run analysis as you accumulate more conversations.\n\n**Q: How long does analysis take?**\nA: Typically 2-5 minutes for 100 conversations, longer for larger datasets or complex patterns.\n\n## ðŸ› ï¸ Next Steps\n\n1. **Set up your directories**: Create the folder structure above (or let `/extract-exports` do it automatically)\n2. **Export your data**: Follow the export guides for your platforms\n3. **Organize your exports**: Run `/extract-exports` to automatically extract and organize ZIP files, or manually place JSON files in the appropriate directories\n4. **Run the analysis**: Use `/analyze-skills` when ready\n5. **Implement skills**: Start with the highest-impact recommendations\n\n## ðŸ’¡ Pro Tips\n\n- **Export regularly**: Update your analysis monthly as you accumulate more conversations\n- **Start small**: Begin with Option C (incremental) to test with your top skills\n- **Customize skills**: Edit generated skills to match your specific needs\n- **Share patterns**: Generated skills are great for team standardization\n\nReady to get started? Let me know if you'd like help creating the directory structure or have questions about the export process!"
              },
              {
                "name": "/skills-troubleshoot",
                "description": "Troubleshoot common issues with skills analysis setup and execution",
                "path": "plugins/claude-skills-analyzer/commands/skills-troubleshoot.md",
                "frontmatter": {
                  "description": "Troubleshoot common issues with skills analysis setup and execution"
                },
                "content": "# Skills Analysis Troubleshooting\n\nI'll help you diagnose and fix common issues with the Claude Skills Analyzer.\n\n## ðŸ” Quick Diagnostics\n\nLet me check your current setup and identify any issues:\n\n### Directory Structure Check\nFirst, let me verify your project has the required directories:\n\n```\nExpected structure:\nâ”œâ”€â”€ data-exports/\nâ”‚   â”œâ”€â”€ claude/           # Claude export files\nâ”‚   â””â”€â”€ chatgpt/          # ChatGPT export files  \nâ”œâ”€â”€ reports/              # Analysis outputs\nâ””â”€â”€ generated-skills/     # Generated skill packages\n```\n\n### Data Files Check\nLooking for these required files:\n\n**Claude exports** (`data-exports/claude/`):\n- [ ] `conversations.json` - Required\n- [ ] `projects.json` - Optional but helpful\n- [ ] `users.json` - Optional\n\n**ChatGPT exports** (`data-exports/chatgpt/`):\n- [ ] `conversations.json` - Required\n- [ ] `user.json` - Optional\n- [ ] `shared_conversations.json` - Optional\n\n## ðŸš¨ Common Issues & Solutions\n\n### Issue: \"No conversation files detected\"\n\n**Causes:**\n- Files in wrong directories\n- Incorrect file names\n- Empty or corrupted JSON files\n\n**Solutions:**\n1. **Check file locations**: Ensure JSON files are in correct `data-exports/` subdirectories\n2. **Verify file names**: Must match exactly (case-sensitive)\n3. **Validate JSON**: Open files in text editor to check they're valid JSON\n4. **Check file sizes**: Empty files (0 bytes) won't work\n\n### Issue: \"Analysis produces no patterns\"\n\n**Causes:**\n- Too few conversations (need 20+ minimum)\n- Conversations too short or simple\n- No recurring patterns in usage\n\n**Solutions:**\n1. **Accumulate more data**: Export again after more AI usage\n2. **Lower thresholds**: Adjust frequency requirements in analysis\n3. **Check conversation quality**: Need substantial back-and-forth interactions\n4. **Try different timeframes**: Use older exports if available\n\n### Issue: \"Plugin command not found\"\n\n**Causes:**\n- Plugin not properly installed\n- Claude Code needs restart\n- Marketplace not added correctly\n\n**Solutions:**\n1. **Verify installation**:\n   ```shell\n   /plugin list\n   ```\n2. **Restart Claude Code**: Close and reopen\n3. **Reinstall plugin**:\n   ```shell\n   /plugin uninstall claude-skills-analyzer@hirefrank\n   /plugin install claude-skills-analyzer@hirefrank\n   ```\n\n### Issue: \"JSON parsing errors\"\n\n**Causes:**\n- Incomplete export downloads\n- File corruption during transfer\n- Unsupported export format versions\n\n**Solutions:**\n1. **Re-download exports**: Get fresh copies from AI platforms\n2. **Check file integrity**: Verify files open properly in text editor\n3. **Try smaller batches**: Export smaller date ranges if available\n\n### Issue: \"Skills generation fails\"\n\n**Causes:**\n- Insufficient write permissions\n- Conflicting files in output directories\n- Pattern analysis errors\n\n**Solutions:**\n1. **Check permissions**: Ensure you can write to project directory\n2. **Clear output directories**: Remove old `reports/` and `generated-skills/` content\n3. **Try incremental analysis**: Start with Option A (report only)\n\n## ðŸ”§ Manual Diagnostics\n\n### Check Your Export Files\n```shell\n# Navigate to your data directory\ncd data-exports\n\n# Check file sizes (should be >1KB)\nls -la claude/\nls -la chatgpt/\n\n# Preview file contents (first few lines)\nhead -5 claude/conversations.json\nhead -5 chatgpt/conversations.json\n```\n\n### Validate JSON Structure\n```shell\n# Check if files are valid JSON (on systems with jq)\njq . claude/conversations.json > /dev/null && echo \"Claude JSON valid\"\njq . chatgpt/conversations.json > /dev/null && echo \"ChatGPT JSON valid\"\n```\n\n## ðŸ“Š Data Requirements\n\n### Minimum Requirements\n- **20+ conversations** total across platforms\n- **Average 3+ exchanges** per conversation\n- **Variety of topics/tasks** represented\n- **JSON files >1KB** in size\n\n### Optimal Requirements  \n- **50+ conversations** for meaningful patterns\n- **Mix of short and long conversations**\n- **Regular usage patterns** over time\n- **Both platforms** represented (if you use both)\n\n## ðŸŽ¯ Quick Fixes\n\n### Create Missing Directories\n```shell\nmkdir -p data-exports/claude data-exports/chatgpt reports generated-skills\n```\n\n### Test Plugin Installation\n```shell\n# Check if plugin is available\n/help | grep analyze-skills\n\n# List installed plugins\n/plugin list | grep claude-skills-analyzer\n```\n\n### Reset and Retry\n```shell\n# Clear any partial outputs\nrm -rf reports/* generated-skills/*\n\n# Re-run analysis with fresh start\n/analyze-skills\n```\n\n## ðŸ“ž Getting Additional Help\n\n### For Setup Issues\n- Review `/skills-setup` for complete setup guide\n- Check plugin README at `plugins/claude-skills-analyzer/README.md`\n- Verify you have the latest plugin version\n\n### For Analysis Issues\n- Try Option A (Analysis Report Only) first\n- Review conversation export quality\n- Consider smaller dataset for initial testing\n\n### For Technical Issues\n- Check [GitHub Issues](https://github.com/hirefrank/hirefrank-marketplace/issues)\n- Report bugs with error messages and setup details\n- Join discussions for community support\n\n## ðŸ’¡ Pro Troubleshooting Tips\n\n1. **Start small**: Test with a small, known-good dataset first\n2. **Check permissions**: Ensure you can read/write in the project directory\n3. **Update regularly**: Keep the plugin updated to latest version\n4. **Document patterns**: Note what types of conversations work best\n5. **Incremental approach**: Use existing analysis logs for efficiency\n\n## ðŸ”„ Still Having Issues?\n\nIf problems persist:\n\n1. **Gather diagnostics**:\n   - Plugin version (`/plugin list`)\n   - Error messages (exact text)\n   - File sizes and locations\n   - Claude Code version\n\n2. **Try minimal test**:\n   - Create new directory\n   - Add just 1-2 export files\n   - Run analysis with Option A\n\n3. **Get support**:\n   - Open GitHub issue with full details\n   - Include anonymized error logs\n   - Describe expected vs actual behavior\n\nLet me know what specific issue you're experiencing and I'll provide targeted help!"
              }
            ],
            "skills": [
              {
                "name": "conversation-analyzer",
                "description": "Analyzes AI conversation exports to identify recurring patterns and generate custom Claude Skills. Use when analyzing conversation data, identifying workflow patterns, or creating reusable AI skills from usage history.",
                "path": "plugins/claude-skills-analyzer/skills/conversation-analyzer/SKILL.md",
                "frontmatter": {
                  "name": "conversation-analyzer",
                  "description": "Analyzes AI conversation exports to identify recurring patterns and generate custom Claude Skills. Use when analyzing conversation data, identifying workflow patterns, or creating reusable AI skills from usage history."
                },
                "content": "# Conversation Analyzer\n\n## Instructions\n\nThis skill provides specialized capability for analyzing AI conversation exports (Claude, ChatGPT) to identify recurring patterns and generate reusable Custom Skills.\n\n1. **Data Processing & Pattern Discovery**\n   - Auto-detect platform format (Claude vs ChatGPT exports)\n   - Parse conversation histories, project data, and user information\n   - Extract expertise indicators and usage patterns\n   - Categorize patterns by domain (coding, writing, business, analysis)\n   - Identify task types (creation, transformation, analysis, troubleshooting)\n\n2. **Frequency & Temporal Analysis**\n   - Count pattern occurrences across conversation history\n   - Calculate temporal distribution and frequency trends\n   - Cross-reference with project data for validation\n   - Assess business impact and time investment patterns\n\n3. **Skill-Worthiness Evaluation** (0-10 scale scoring):\n   - **Frequency**: How often does this task occur?\n   - **Consistency**: How similar are requirements each time?\n   - **Complexity**: Would a skill meaningfully improve quality?\n   - **Time savings**: How much effort would a skill save?\n   - **Error reduction**: Common pitfalls a skill could prevent?\n\n4. **Cross-Platform Deduplication** (when both platforms present):\n   - Detect semantic similarity across platforms\n   - Identify cross-platform workflows vs genuine duplicates\n   - Merge evidence while preserving platform preferences\n   - Recalculate frequencies after deduplication\n\n5. **Skill Generation & Optimization**\n   - Create prioritization matrix (frequency vs. value/impact)\n   - Resolve overlaps and optimize skill boundaries\n   - Generate complete skill packages with YAML frontmatter\n   - Provide implementation roadmap and testing guidance\n\n## Quality Standards\n\n- Focus on patterns with >5% conversation frequency\n- Require 70%+ consistency across pattern instances\n- Target >30 min/week time savings potential\n- Maximum 12 skills total (recommend prioritizing top 5-8)\n- Platform-agnostic skill design\n- Evidence-based recommendations with conversation excerpts\n\n## Examples\n\n### Analyzing Claude Export\n**User Request**: \"Analyze my Claude conversations to find skill opportunities\"\n\n**Response**: \n```\nI'll analyze your Claude conversation export to identify recurring patterns. Let me:\n\n1. Parse your conversations.json and projects.json files\n2. Identify frequent task patterns across your usage\n3. Evaluate each pattern for skill-worthiness\n4. Generate prioritized recommendations for Custom Skills\n\nPlease ensure your export files are in data-exports/claude/ directory.\n```\n\n### Cross-Platform Analysis\n**User Request**: \"I have both Claude and ChatGPT exports - analyze them together\"\n\n**Response**:\n```\nI'll perform cross-platform analysis to identify your workflow patterns:\n\n1. Process both Claude and ChatGPT conversation data\n2. Detect and handle cross-platform duplicates\n3. Identify platform preferences for different task types\n4. Create unified skills that work across AI platforms\n5. Provide platform-agnostic skill recommendations\n\nThis will give you the most accurate picture of your AI usage patterns.\n```"
              },
              {
                "name": "workflow-pattern-analyzer-web",
                "description": "Analyzes recent conversation history using chat tools to identify recurring workflow patterns and generate Custom Skills recommendations with statistical rigor. Use when users request workflow analysis, pattern identification, skill generation suggestions, or automation opportunities based on their AI usage patterns without requiring conversation exports.",
                "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer-web/SKILL.md",
                "frontmatter": {
                  "name": "workflow-pattern-analyzer-web",
                  "description": "Analyzes recent conversation history using chat tools to identify recurring workflow patterns and generate Custom Skills recommendations with statistical rigor. Use when users request workflow analysis, pattern identification, skill generation suggestions, or automation opportunities based on their AI usage patterns without requiring conversation exports."
                },
                "content": "# Workflow Pattern Analyzer (Web Compatible)\n\n## Instructions\n\nThis skill provides comprehensive conversation pattern analysis using Claude's native chat history tools (`recent_chats` and `conversation_search`) to identify skill-worthy automation opportunities with statistical rigor.\n\n**Core Capabilities:**\n- Web interface compatible (no exports required)\n- Statistical pattern validation and scoring\n- Frequency analysis and temporal tracking\n- Evidence-based skill recommendations\n- Complete skill package generation\n\n**Compatible with:** Claude.ai web interface, Claude Code, API\n\n**How Analysis Works:**\n- **No scripts or Python files**: This is a pure prompt-based analysis using Claude's native capabilities\n- **Full content analysis**: Examines complete conversation content, messages, and patterns (not just titles or names)\n- **Thread names**: Renaming conversations has minimal impact - analysis focuses on actual message content and patterns\n- **Domain discovery**: Categories emerge from your actual usage data, not forced into predefined buckets\n- **Data-driven approach**: Identifies YOUR specific patterns (recipes, image prompting, game design, etc.) rather than assuming business/coding focus\n\n## Analysis Framework\n\n### Phase 1: Data Collection Strategy\n\n**Determine Analysis Scope:**\n\nAsk user: \"How deep should I analyze your conversation history?\"\n\n**Options:**\n- **Quick Scan** (20-30 conversations, ~2-3 min): Recent patterns and immediate opportunities\n- **Standard Analysis** (50-75 conversations, ~5-7 min): Comprehensive pattern detection\n- **Deep Dive** (100+ conversations, ~10-15 min): Full workflow mapping with temporal trends\n- **Targeted Search** (variable): Focus on specific topics or time periods\n\n**Data Collection Process:**\n\n1. **Broad Sampling**: Use `recent_chats(n=30)` multiple times with varied parameters to get diverse coverage\n2. **Temporal Distribution**: Sample conversations across different time periods (recent, 1 week ago, 1 month ago)\n3. **Topic Exploration**: Use `conversation_search` for domains mentioned by user or detected in initial sampling\n4. **Depth vs Breadth**: Balance comprehensive coverage with processing efficiency\n\n### Phase 2: Pattern Discovery & Classification\n\n**Extract patterns using these detection methods:**\n\n#### A. Explicit Pattern Markers\n- **Repeated phrasing**: \"format this as...\", \"make it more...\", \"apply X style\"\n- **Consistent request structures**: \"create a [X] that does [Y]\"\n- **Recurring formatting instructions**: tables, bullet lists, specific structures\n- **Tone/voice adjustments**: \"more casual\", \"add enthusiasm\", \"formal version\"\n\n#### B. Implicit Workflow Patterns\n- **Multi-turn conversation structures**: Same workflow across different topics\n- **Iterative refinement sequences**: Request â†’ feedback â†’ revision cycles\n- **Context re-explanation**: Same background info provided repeatedly\n- **Problem-solving approaches**: Consistent debugging/analysis methodologies\n\n#### C. Domain Discovery (Data-Driven)\n- **Let domains emerge from the data** - Do NOT pre-categorize into standard domains\n- **Topic frequency analysis**: Extract actual subject matter from conversations\n  - Examples of specialized domains: recipe transcription, cannabis strains, image prompting, game design, book summaries\n  - Examples of traditional domains: coding, business strategy, creative writing, data analysis, technical writing\n- **Task type patterns**: Identify the action types that appear (creation, transformation, analysis, troubleshooting, curation, etc.)\n- **Niche specialization detection**: Look specifically for narrow, specialized topics with high engagement\n- **Cross-domain workflows**: Patterns that span multiple topics\n- **Domain diversity scoring**: Reward finding 8-15 distinct domains vs. forcing into 3-4 buckets\n\n**CRITICAL**: Avoid fitting patterns into predefined categories. Each user's conversation history will have unique domains based on their actual usage.\n\n**Terminal Output - Domain Diversity Visualization:**\n\nAfter completing pattern discovery, display an ASCII chart showing domain distribution:\n\n```\nðŸ“Š Domain Distribution Analysis\n\nBusiness & Strategy    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 12 patterns (32%)\nCreative & Writing     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 10 patterns (27%)\nImage Prompting        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  8 patterns (22%)\nLearning & Education   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4 patterns (11%)\nRecipe & Cooking       â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  2 patterns  (5%)\nGaming & Design        â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  1 pattern   (3%)\n\nâœ… Domain Diversity: 6 distinct topic areas detected\nâœ… No predefined categorization - domains emerged from your data\n```\n\nThis validates data-driven discovery of diverse patterns.\n\n#### D. Niche & Specialized Pattern Detection\n\n**Explicitly search for underrepresented domains:**\n- **Hobbyist domains**: Recipes, cocktails, cannabis, gardening, gaming, fitness, travel planning\n- **Creative domains**: Story writing, worldbuilding, character development, art direction, music composition\n- **Prompt engineering**: Image generation (Midjourney, Stable Diffusion, DALL-E), video generation, AI art workflows\n- **Learning & education**: Book summaries, concept explanations, study guides, teaching materials\n- **Personal organization**: Resume writing, cover letters, personal branding, goal setting\n- **Entertainment & media**: Game design, narrative design, content creation, video scripts\n- **Wellness & lifestyle**: Meal planning, workout routines, meditation guides, habit tracking\n\n**Detection strategy:**\n- Look for concentrated clusters of 5+ conversations on the same narrow topic\n- Identify specialized vocabulary/jargon (strain names, recipe terms, art styles, game mechanics)\n- Find recurring templates/formats specific to that domain\n- Don't dismiss low-frequency patterns if they show high consistency and complexity\n- Pay special attention to patterns that appear in conversation titles or search results\n- Consider that niche patterns may have lower frequency but higher value due to specialization\n\n**Quality indicators for niche patterns:**\n- Consistent terminology and domain-specific language\n- Recurring output formats or structures\n- User demonstrates growing expertise over time\n- High engagement (longer conversations, multiple refinements)\n- Clear workflow or methodology emerging\n\n#### E. Temporal Patterns\n- **Weekly/monthly recurring tasks**: Reports, summaries, check-ins\n- **Event-driven patterns**: Meeting prep, post-mortems, launches\n- **Seasonal trends**: Quarterly reviews, annual planning\n- **Frequency trends**: Increasing/stable/decreasing over time\n\n### Phase 3: Frequency Analysis & Validation\n\nFor each identified pattern, calculate:\n\n#### Occurrence Metrics\n- **Absolute frequency**: Total instances found in analyzed conversations\n- **Relative frequency**: Percentage of conversations containing pattern\n- **Temporal distribution**: First occurrence, most recent, clustering\n- **Consistency score**: Similarity across pattern instances (0-100%)\n\n#### Statistical Validation\n- **Significance threshold**: Pattern must appear in >5% of conversations OR >3 absolute instances\n- **Consistency requirement**: 70%+ similarity in requirements/structure across instances\n- **Sample size consideration**: Adjust thresholds based on total conversations analyzed\n\n#### Evidence Collection\n- Extract 2-4 representative conversation excerpts per pattern\n- Note variation types (what changes vs what stays constant)\n- Document user refinement patterns (common adjustments made)\n\n### Phase 4: Skill-Worthiness Scoring (0-10 Scale)\n\n**Use extended reasoning to evaluate each pattern across 5 dimensions:**\n\n#### 1. Frequency Score (0-10)\n- **10**: Daily usage (20+ instances or >25% of conversations)\n- **8-9**: Multiple times per week (10-20 instances or 15-25%)\n- **6-7**: Weekly usage (5-9 instances or 8-15%)\n- **4-5**: Bi-weekly to monthly (3-4 instances or 5-8%)\n- **2-3**: Monthly or less (2 instances or 3-5%)\n- **0-1**: One-off or <3% of conversations\n\n#### 2. Consistency Score (0-10)\n- **10**: Identical requirements every time (90-100% similarity)\n- **8-9**: Highly consistent with minor variations (75-90%)\n- **6-7**: Core structure consistent, details vary (60-75%)\n- **4-5**: Recognizable pattern, significant variation (45-60%)\n- **2-3**: Loosely related, different each time (30-45%)\n- **0-1**: No discernible consistency (<30%)\n\n#### 3. Complexity Score (0-10)\n- **10**: Multi-step workflow with decision points, high cognitive load\n- **8-9**: Complex methodology requiring expertise/frameworks\n- **6-7**: Moderate complexity with structured approach\n- **4-5**: Straightforward process with some nuance\n- **2-3**: Simple task with minimal steps\n- **0-1**: Trivial one-step operation\n\n#### 4. Time Savings Score (0-10)\n- **10**: >60 min saved per use (or >10 hours/month total)\n- **8-9**: 30-60 min per use (or 5-10 hours/month)\n- **6-7**: 15-30 min per use (or 2-5 hours/month)\n- **4-5**: 5-15 min per use (or 1-2 hours/month)\n- **2-3**: 2-5 min per use (or 30-60 min/month)\n- **0-1**: <2 min per use (<30 min/month)\n\n#### 5. Error Reduction Score (0-10)\n- **10**: Critical tasks with major error consequences\n- **8-9**: Common mistakes significantly impact quality\n- **6-7**: Regular pitfalls that skill could prevent\n- **4-5**: Occasional errors, modest quality improvement\n- **2-3**: Minor inconsistencies, small quality gains\n- **0-1**: No error patterns, quality already consistent\n\n#### Composite Scoring\n- **Total Score**: Sum of 5 dimensions (0-50 scale)\n- **Priority Classification**:\n  - **Critical** (40-50): Implement immediately\n  - **High** (30-39): Strong candidates for skill creation\n  - **Medium** (20-29): Consider for skill creation\n  - **Low** (10-19): Defer or handle with simple prompts\n  - **Not Viable** (0-9): Not worth skill automation\n\n### Phase 5: Relationship Mapping & Consolidation\n\n#### A. Overlap Detection\n- Identify shared components across patterns\n- Map overlapping functionality (>40% shared steps)\n- Find hierarchical relationships (high-level task composed of sub-tasks)\n- Detect sequential workflows (tasks that occur in sequence)\n\n#### B. Consolidation Strategies\n\n**Use extended reasoning to determine:**\n\n- **Merge** (>60% overlap): Combine into single comprehensive skill\n- **Separate with cross-reference** (30-60% overlap): Distinct skills with links\n- **Hierarchical**: Main skill + specialized variants â†’ parent/child structure\n- **Modular**: Extract common elements â†’ shared templates/references\n\n#### C. Boundary Optimization\n\nEach skill should have:\n- **Clear purpose**: Single, well-defined use case\n- **Distinct triggers**: Easy to know when to use vs other skills\n- **Minimal overlap**: <30% shared functionality with other skills\n- **Appropriate scope**: Not too broad (generic) or narrow (over-specialized)\n\n### Phase 6: Prioritization Matrix\n\nGenerate 2D matrix visualization:\n\n```\nVALUE/IMPACT (High to Low)\n     â”‚\nHIGH â”‚  ðŸ”¥ Quick Wins        â­ Strategic\n     â”‚  [High-priority         [Complex but\n     â”‚   automation]           critical]\n     â”‚\n     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n     â”‚\nLOW  â”‚  ðŸ”§ Automate          â¸ï¸  Defer\n     â”‚  [Nice-to-have         [Not worth\n     â”‚   efficiency]           automating]\n     â”‚\n     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n          LOW    FREQUENCY    HIGH\n```\n\n**Classify each pattern:**\n- **X-axis**: Frequency score (0-10)\n- **Y-axis**: Average of Complexity, Time Savings, Error Reduction (0-10)\n- **Size indicator**: Total composite score\n- **Color coding**: Implementation difficulty\n\n**Strategic Recommendations:**\n1. **Top 3-5 Quick Wins**: Highest ROI (frequency Ã— impact)\n2. **Strategic Skills**: High impact even if lower frequency\n3. **Quick Automations**: High frequency, simpler to implement\n4. **Defer List**: Patterns not meeting skill-worthiness thresholds\n\n### Phase 7: Skill Package Generation\n\nFor each approved skill, create:\n\n#### A. Skill Specification Document\n\n```markdown\n## [Skill Name]\n\n**Pattern Evidence:**\n- Frequency: [X instances in Y conversations (Z%)]\n- Consistency: [X/10 score]\n- Time savings: [X hours/month]\n\n**Composite Score: [X/50]**\n- Frequency: [X/10]\n- Consistency: [X/10]\n- Complexity: [X/10]\n- Time Savings: [X/10]\n- Error Reduction: [X/10]\n\n**Example Conversations:**\n1. [Date]: [Brief excerpt showing pattern]\n2. [Date]: [Brief excerpt showing pattern]\n3. [Date]: [Brief excerpt showing pattern]\n\n**Pattern Components:**\n- **Consistent elements**: [What stays the same]\n- **Variable elements**: [What changes per instance]\n- **Common refinements**: [Typical adjustments user makes]\n\n**Proposed Skill Structure:**\n\nSKILL.md sections:\n1. Overview & trigger conditions\n2. [Main workflow methodology]\n3. Quality standards\n4. Examples\n\nSupporting files needed:\n- reference.md: [Detailed framework/methodology]\n- templates/: [Reusable output templates]\n- examples.md: [Additional use cases]\n```\n\n#### B. Complete SKILL.md File\n\nGenerate production-ready skill with:\n- Proper YAML frontmatter (name, description with triggers)\n- Clear instructions based on pattern analysis\n- Evidence-based examples from actual conversations\n- Quality standards derived from user refinement patterns\n- Progressive disclosure (link to references for detail)\n\n## Output Formats\n\nAfter analysis completion, present:\n\n### Summary Report\n\n```markdown\n# Workflow Pattern Analysis Report\n**Analysis Date**: [Timestamp]\n**Conversations Analyzed**: [X conversations across Y time period]\n**Patterns Identified**: [X patterns]\n**Skills Recommended**: [Y skills]\n\n## ðŸ“Š Skill Prioritization Matrix\n\n```mermaid\n%%{init: {'theme':'base'}}%%\nquadrantChart\n    title Skill Prioritization: Frequency vs Impact\n    x-axis Low Frequency --> High Frequency\n    y-axis Low Impact --> High Impact\n    quadrant-1 Strategic\n    quadrant-2 Quick Wins\n    quadrant-3 Defer\n    quadrant-4 Automate\n    [Skill Name 1]: [freq_score/10, impact_score/10]\n    [Skill Name 2]: [freq_score/10, impact_score/10]\n    [Skill Name 3]: [freq_score/10, impact_score/10]\n```\n\\```\n\n**Legend:**\n- **Quick Wins** (top-right): High frequency, high impact - implement first\n- **Strategic** (top-left): Lower frequency but high value - critical capabilities\n- **Automate** (bottom-right): High frequency, simpler - nice efficiency gains\n- **Defer** (bottom-left): Low priority - consider simple prompts instead\n\n## ðŸ”¥ HIGH-PRIORITY OPPORTUNITIES\n\n### 1. [Skill Name]\n**Score: [X/50]** (Frequency: X/10, Consistency: X/10, Complexity: X/10, Time: X/10, Error: X/10)\n\n**Pattern Description**: [What you do repeatedly]\n\n**Evidence**:\n- Found in [X] conversations ([Y%] of analyzed sample)\n- First seen: [Date], Most recent: [Date]\n- Average time per instance: [X minutes]\n\n**Example Occurrences**:\n1. [Date]: \"[Brief excerpt]\"\n2. [Date]: \"[Brief excerpt]\"\n\n**Proposed Skill**: \"[One-line skill description]\"\n\n**Time Savings**: [X hours/month]\n\n---\n\n[Repeat for top 5-8 patterns]\n\n## ðŸ’¡ MODERATE OPPORTUNITIES\n[Briefer summaries of medium-priority patterns]\n\n## ðŸŽ¯ QUICK AUTOMATION CANDIDATES\n[Simple, high-frequency patterns]\n\n## â¸ï¸  DEFERRED PATTERNS\n[Patterns that didn't meet skill-worthiness thresholds]\n\n## ðŸ“Š ANALYSIS METADATA\n- Total conversations: [X]\n- Date range: [earliest] to [latest]\n- Unique patterns identified: [X]\n- Patterns validated: [Y]\n- Cross-pattern overlaps: [Z]\n- Recommended consolidations: [N]\n```\n\n### Interactive Follow-Up Options\n\n```\nWhat would you like to do next?\n\nA. Generate complete SKILL.md files for [top 3-5 skills]\nB. Deep dive into specific pattern: [skill name]\nC. Expand analysis with more conversations\nD. Focus on specific domain/topic area\nE. Adjust scoring weights and recalculate priorities\n```\n\n## Quality Standards\n\n### Pattern Validation Requirements\n- **Minimum frequency**: 3 instances OR >5% of conversations\n- **Consistency threshold**: 70% similarity across instances\n- **Evidence requirement**: 2-3 conversation excerpts minimum\n- **Time savings minimum**: >30 min/month cumulative\n- **Statistical significance**: Validated against sample size\n\n### Skill Recommendations\n- **Maximum 8-10 skills**: Focus on highest ROI patterns\n- **Clear differentiation**: Each skill has distinct purpose\n- **Evidence-based design**: Skill structure reflects actual usage patterns\n- **Practical focus**: Prioritize patterns with real time/quality impact\n\n### Analysis Rigor\n- **No generic patterns**: Avoid broad categories like \"writing\" or \"analysis\"\n- **Domain diversity validated**: Patterns should span 6+ distinct topic areas (not just business/coding)\n- **Niche specializations identified**: Don't dismiss specialized patterns as outliers\n- **No artificial categorization**: Avoid forcing patterns into predefined domains (coding, writing, business, analysis)\n- **Validated frequencies**: Ensure counts are accurate within sample\n- **Temporal awareness**: Note if pattern is emerging, stable, or declining\n- **User context**: Consider user's domain expertise and role\n\n## Examples\n\n### Example 1: Quick Scan Request\n\n**User**: \"Analyze my recent chats for automation opportunities\"\n\n**Claude**:\nI'll perform a quick scan of your recent conversation history to identify skill opportunities.\n\n[Uses recent_chats(n=30) multiple times]\n\nðŸ“Š **Quick Scan Results** (30 conversations analyzed)\n\nðŸ”¥ **TOP OPPORTUNITY**:\n\n**\"Email Response Composer\"** - Score: 42/50\n- Found in 9 conversations (30%)\n- Pattern: You regularly ask me to draft professional emails with specific tone and structure requirements\n- Time savings: ~90 min/month (10 min per email Ã— 9 emails)\n- Evidence: Consistent 3-paragraph structure with greeting, main content, action items\n\nWant me to:\nA. Generate complete skill package for this\nB. Continue analysis for more patterns (expand to 50-75 conversations)\nC. Focus on other domains\n\n### Example 2: Targeted Domain Analysis\n\n**User**: \"Find patterns in how I use you for coding tasks\"\n\n**Claude**:\nI'll analyze your coding-related conversations to identify workflow patterns.\n\n[Uses conversation_search for coding terms + recent_chats filtering]\n\nðŸ“Š **Coding Workflow Analysis** (18 relevant conversations)\n\nðŸ”¥ **TOP PATTERNS**:\n\n1. **\"Code Review Checklist Generator\"** - Score: 38/50\n   - Found in 7 code review discussions\n   - Pattern: You ask for language-specific review checklists before reviewing PRs\n   - Consistency: 85% (always includes security, performance, style sections)\n\n2. **\"API Documentation Humanizer\"** - Score: 35/50\n   - Found in 5 documentation tasks\n   - Pattern: Converting technical API specs into developer-friendly guides\n   - Structure: Always includes quick start, common use cases, troubleshooting\n\nWant me to build skills for these patterns?\n\n### Example 3: Deep Dive Analysis\n\n**User**: \"Do a comprehensive analysis of my workflow over the last few months\"\n\n**Claude**:\nI'll perform a deep analysis of your conversation history. This will take 10-15 minutes to ensure comprehensive coverage.\n\n[Uses recent_chats extensively, conversation_search for discovered topics, temporal sampling]\n\nðŸ“Š **Comprehensive Workflow Analysis**\n- **Conversations analyzed**: 120\n- **Date range**: [3 months]\n- **Patterns identified**: 15\n- **Skills recommended**: 6\n\nðŸ”¥ **CRITICAL PRIORITY** (Score 40-50):\n\n1. **\"Weekly Status Report Generator\"** - Score: 47/50\n   - Frequency: 12 instances (10% of conversations)\n   - Consistency: 95% - always same structure\n   - Evidence: Every Monday, you format updates in identical 5-section template\n   - Time savings: 240 min/month (20 min/week Ã— 4 weeks Ã— 3 months avg)\n\nâ­ **HIGH PRIORITY** (Score 30-39):\n\n2. **\"Client Proposal Framework\"** - Score: 36/50\n3. **\"Meeting Notes Structurer\"** - Score: 34/50\n4. **\"Technical Concept Explainer\"** - Score: 31/50\n\n[Full analysis report with evidence, prioritization matrix, skill specifications]\n\n**Recommended Implementation Path**:\n1. Start with \"Weekly Status Report Generator\" (highest ROI)\n2. Build \"Client Proposal Framework\" and \"Meeting Notes Structurer\" next (complementary workflows)\n3. Evaluate remaining patterns after 2-4 weeks of usage\n\nGenerate complete skill packages now? [Y/N]\n\n## Anti-Patterns to Avoid\n\n**Don't recommend skills for:**\n- **One-off variations**: Tasks that seem similar but are fundamentally different each time\n- **Over-simplified tasks**: Things easier to just ask directly than invoke a skill\n- **Better solved by tools**: When external apps/services do it better\n- **Insufficient data**: Patterns with <3 instances or <5% frequency (unless strategic)\n- **Generic categories**: Broad skills like \"help with writing\" or \"analyze data\"\n\n**Red flags in patterns:**\n- High frequency but no consistency (chaotic variation)\n- High consistency but very low frequency (use a prompt template instead)\n- Pattern is declining over time (user may have found better solution)\n- Task requires real-time data or external authentication (needs MCP, not skill)\n\n## When to Use This Skill\n\n**âœ… Use this skill when:**\n- User requests analysis of their conversation patterns\n- User wants to identify automation opportunities\n- User asks what skills they should create\n- User mentions repetitive tasks or workflows\n- User wants evidence-based skill recommendations\n- User is in web interface (can't use export-based analysis)\n\n**âŒ Don't use this skill when:**\n- User has conversation export files available (use export-based plugin instead for more comprehensive analysis)\n- User wants cross-platform ChatGPT + Claude analysis (requires exports)\n- User has very few conversations (<10) making pattern detection unreliable\n- User wants to build specific skill they already have in mind\n- User is asking about existing skills or community skills\n\n**âš¡ Proactive Use:**\nWhen you detect potential patterns during normal conversation, offer:\n```\nðŸ’­ Pattern detected: This is the [Xth] time you've asked me to [action].\n\nWould you like me to analyze your conversation history for similar \npatterns and recommend a Custom Skill? I can identify other automation \nopportunities you might not have noticed.\n\n[Yes, analyze] [Not now]\n```\n\n## Progressive Disclosure Strategy\n\n**Keep main analysis concise by organizing information hierarchically:**\n\n1. **Quick overview first**: Summary report with top 3-5 opportunities\n2. **Details on demand**: Expand specific patterns when user shows interest\n3. **Implementation when ready**: Generate complete skill packages only after user approval\n4. **Iterative refinement**: Allow user to adjust scoring weights, focus areas, or analysis depth\n\n**Load additional detail only when:**\n- User requests deep dive on specific pattern\n- Generating complete skill packages (not just analysis)\n- User wants to understand scoring methodology in detail\n- Building skills for complex domains requiring extensive examples"
              },
              {
                "name": "workflow-pattern-analyzer",
                "description": "Analyzes recent conversation history using chat tools to identify recurring workflow patterns and generate Custom Skills recommendations with statistical rigor. Use when users request workflow analysis, pattern identification, skill generation suggestions, or automation opportunities based on their AI usage patterns without requiring conversation exports.",
                "path": "plugins/claude-skills-analyzer/skills/workflow-pattern-analyzer/SKILL.md",
                "frontmatter": {
                  "name": "workflow-pattern-analyzer",
                  "description": "Analyzes recent conversation history using chat tools to identify recurring workflow patterns and generate Custom Skills recommendations with statistical rigor. Use when users request workflow analysis, pattern identification, skill generation suggestions, or automation opportunities based on their AI usage patterns without requiring conversation exports."
                },
                "content": "# Workflow Pattern Analyzer\n\n## Instructions\n\nThis skill provides comprehensive conversation pattern analysis using Claude's native chat history tools (`recent_chats` and `conversation_search`) to identify skill-worthy automation opportunities with the statistical rigor of export-based analysis.\n\n**Core Capabilities:**\n- Web interface compatible (no exports required)\n- Statistical pattern validation and scoring\n- Frequency analysis and temporal tracking\n- Evidence-based skill recommendations\n- Complete skill package generation\n\n## Analysis Framework\n\nThis skill uses the **[shared analysis methodology](../../shared/analysis-methodology.md)** with tool-based data collection adaptations.\n\n### Phase 1: Data Collection Strategy\n\n**Determine Analysis Scope:**\n\nAsk user: \"How deep should I analyze your conversation history?\"\n\n**Options:**\n- **Quick Scan** (20-30 conversations, ~2-3 min): Recent patterns and immediate opportunities\n- **Standard Analysis** (50-75 conversations, ~5-7 min): Comprehensive pattern detection\n- **Deep Dive** (100+ conversations, ~10-15 min): Full workflow mapping with temporal trends\n- **Targeted Search** (variable): Focus on specific topics or time periods\n\n**Data Collection Process:**\n\n1. **Broad Sampling**: Use `recent_chats(n=30)` multiple times with varied parameters to get diverse coverage\n2. **Temporal Distribution**: Sample conversations across different time periods (recent, 1 week ago, 1 month ago)\n3. **Topic Exploration**: Use `conversation_search` for domains mentioned by user or detected in initial sampling\n4. **Depth vs Breadth**: Balance comprehensive coverage with processing efficiency\n\n### Phase 2-6: Core Analysis\n\nApply the **[shared analysis methodology](../../shared/analysis-methodology.md)** phases:\n\n- **Phase 2**: Pattern Discovery & Classification (explicit, implicit, domain, temporal)\n- **Phase 3**: Frequency Analysis & Validation (occurrence metrics, statistical validation)\n- **Phase 4**: Skill-Worthiness Scoring (0-50 composite scale across 5 dimensions)\n- **Phase 5**: Relationship Mapping & Consolidation (overlap detection, boundary optimization)\n- **Phase 6**: Prioritization Matrix & Recommendations (frequency vs impact visualization)\n\nSee [shared methodology](../../shared/analysis-methodology.md) for complete scoring rubrics and quality standards.\n\n### Phase 7: Skill Package Generation\n\n**For each approved skill, create:**\n\n**A. Skill Specification Document:**\n\n```markdown\n## [Skill Name]\n\n**Pattern Evidence:**\n- Frequency: [X instances in Y conversations (Z%)]\n- Consistency: [X/10 score]\n- Time savings: [X hours/month]\n\n**Composite Score: [X/50]**\n- Frequency: [X/10]\n- Consistency: [X/10]\n- Complexity: [X/10]\n- Time Savings: [X/10]\n- Error Reduction: [X/10]\n\n**Example Conversations:**\n1. [Date]: [Brief excerpt showing pattern]\n2. [Date]: [Brief excerpt showing pattern]\n3. [Date]: [Brief excerpt showing pattern]\n\n**Pattern Components:**\n- **Consistent elements**: [What stays the same]\n- **Variable elements**: [What changes per instance]\n- **Common refinements**: [Typical adjustments user makes]\n\n**Proposed Skill Structure:**\n\nSKILL.md sections:\n1. Overview & trigger conditions\n2. [Main workflow methodology]\n3. Quality standards\n4. Examples\n\nSupporting files needed:\n- reference.md: [Detailed framework/methodology]\n- templates/: [Reusable output templates]\n- examples.md: [Additional use cases]\n```\n\n**B. Complete SKILL.md File:**\n\nGenerate production-ready skill with:\n- Proper YAML frontmatter (name, description with triggers)\n- Clear instructions based on pattern analysis\n- Evidence-based examples from actual conversations\n- Quality standards derived from user refinement patterns\n- Progressive disclosure (link to references for detail)\n\n## Output Formats\n\n**After analysis completion, present:**\n\n### Summary Report\n\n```markdown\n# Workflow Pattern Analysis Report\n**Analysis Date**: [Timestamp]\n**Conversations Analyzed**: [X conversations across Y time period]\n**Patterns Identified**: [X patterns]\n**Skills Recommended**: [Y skills]\n\n## ðŸ”¥ HIGH-PRIORITY OPPORTUNITIES\n\n### 1. [Skill Name]\n**Score: [X/50]** (Frequency: X/10, Consistency: X/10, Complexity: X/10, Time: X/10, Error: X/10)\n\n**Pattern Description**: [What you do repeatedly]\n\n**Evidence**:\n- Found in [X] conversations ([Y%] of analyzed sample)\n- First seen: [Date], Most recent: [Date]\n- Average time per instance: [X minutes]\n\n**Example Occurrences**:\n1. [Date]: \"[Brief excerpt]\"\n2. [Date]: \"[Brief excerpt]\"\n\n**Proposed Skill**: \"[One-line skill description]\"\n\n**Time Savings**: [X hours/month]\n\n---\n\n[Repeat for top 5-8 patterns]\n\n## ðŸ’¡ MODERATE OPPORTUNITIES\n[Briefer summaries of medium-priority patterns]\n\n## ðŸŽ¯ QUICK AUTOMATION CANDIDATES\n[Simple, high-frequency patterns]\n\n## â¸ï¸  DEFERRED PATTERNS\n[Patterns that didn't meet skill-worthiness thresholds]\n\n## ðŸ“Š ANALYSIS METADATA\n- Total conversations: [X]\n- Date range: [earliest] to [latest]\n- Unique patterns identified: [X]\n- Patterns validated: [Y]\n- Cross-pattern overlaps: [Z]\n- Recommended consolidations: [N]\n```\n\n### Interactive Follow-Up Options\n\n```\nWhat would you like to do next?\n\nA. Generate complete SKILL.md files for [top 3-5 skills]\nB. Deep dive into specific pattern: [skill name]\nC. Expand analysis with more conversations\nD. Focus on specific domain/topic area\nE. Adjust scoring weights and recalculate priorities\n```\n\n## Quality Standards\n\nAll quality standards follow the **[shared analysis methodology](../../shared/analysis-methodology.md#quality-standards)**:\n\n- Pattern validation requirements (frequency, consistency, evidence)\n- Skill consolidation rules (max 8-12 skills, clear boundaries)\n- Skill package generation standards\n- Anti-patterns to avoid\n\n## Progressive Disclosure Strategy\n\n**Keep this SKILL.md concise by referencing:**\n- **Core methodology**: [shared/analysis-methodology.md](../../shared/analysis-methodology.md)\n- **Detailed scoring rubrics**: See methodology Phase 4\n- **Quality standards**: See methodology Quality Standards section\n- **Anti-patterns**: See methodology Anti-Patterns section\n\n**Load additional context only when:**\n- User requests deep dive on specific pattern\n- Generating complete skill packages (not just analysis)\n- User wants to understand scoring methodology in detail\n- Building reference materials for complex domains\n\n## Examples\n\n### Example 1: Quick Scan Request\n\n**User**: \"Analyze my recent chats for automation opportunities\"\n\n**Claude**:\nI'll perform a quick scan of your recent conversation history to identify skill opportunities.\n\n[Uses recent_chats(n=30) multiple times]\n\nðŸ“Š **Quick Scan Results** (30 conversations analyzed)\n\nðŸ”¥ **TOP OPPORTUNITY**:\n\n**\"Email Response Composer\"** - Score: 42/50\n- Found in 9 conversations (30%)\n- Pattern: You regularly ask me to draft professional emails with specific tone and structure requirements\n- Time savings: ~90 min/month (10 min per email Ã— 9 emails)\n- Evidence: Consistent 3-paragraph structure with greeting, main content, action items\n\nWant me to:\nA. Generate complete skill package for this\nB. Continue analysis for more patterns (expand to 50-75 conversations)\nC. Focus on other domains\n\n### Example 2: Targeted Domain Analysis\n\n**User**: \"Find patterns in how I use you for coding tasks\"\n\n**Claude**:\nI'll analyze your coding-related conversations to identify workflow patterns.\n\n[Uses conversation_search for coding terms + recent_chats filtering]\n\nðŸ“Š **Coding Workflow Analysis** (18 relevant conversations)\n\nðŸ”¥ **TOP PATTERNS**:\n\n1. **\"Code Review Checklist Generator\"** - Score: 38/50\n   - Found in 7 code review discussions\n   - Pattern: You ask for language-specific review checklists before reviewing PRs\n   - Consistency: 85% (always includes security, performance, style sections)\n\n2. **\"API Documentation Humanizer\"** - Score: 35/50\n   - Found in 5 documentation tasks\n   - Pattern: Converting technical API specs into developer-friendly guides\n   - Structure: Always includes quick start, common use cases, troubleshooting\n\nWant me to build skills for these patterns?\n\n### Example 3: Deep Dive Analysis\n\n**User**: \"Do a comprehensive analysis of my workflow over the last few months\"\n\n**Claude**:\nI'll perform a deep analysis of your conversation history. This will take 10-15 minutes to ensure comprehensive coverage.\n\n[Uses recent_chats extensively, conversation_search for discovered topics, temporal sampling]\n\nðŸ“Š **Comprehensive Workflow Analysis**\n- **Conversations analyzed**: 120\n- **Date range**: [3 months]\n- **Patterns identified**: 15\n- **Skills recommended**: 6\n\nðŸ”¥ **CRITICAL PRIORITY** (Score 40-50):\n\n1. **\"Weekly Status Report Generator\"** - Score: 47/50\n   - Frequency: 12 instances (10% of conversations)\n   - Consistency: 95% - always same structure\n   - Evidence: Every Monday, you format updates in identical 5-section template\n   - Time savings: 240 min/month (20 min/week Ã— 4 weeks Ã— 3 months avg)\n\nâ­ **HIGH PRIORITY** (Score 30-39):\n\n2. **\"Client Proposal Framework\"** - Score: 36/50\n3. **\"Meeting Notes Structurer\"** - Score: 34/50\n4. **\"Technical Concept Explainer\"** - Score: 31/50\n\n[Full analysis report with evidence, prioritization matrix, skill specifications]\n\n**Recommended Implementation Path**:\n1. Start with \"Weekly Status Report Generator\" (highest ROI)\n2. Build \"Client Proposal Framework\" and \"Meeting Notes Structurer\" next (complementary workflows)\n3. Evaluate remaining patterns after 2-4 weeks of usage\n\nGenerate complete skill packages now? [Y/N]\n\n## When to Use This Skill\n\n**âœ… Use this skill when:**\n- User requests analysis of their conversation patterns\n- User wants to identify automation opportunities\n- User asks what skills they should create\n- User mentions repetitive tasks or workflows\n- User wants evidence-based skill recommendations\n- User is in web interface (can't use export-based analysis)\n\n**âŒ Don't use this skill when:**\n- User has conversation export files available (use export-based plugin instead for more comprehensive analysis)\n- User wants cross-platform ChatGPT + Claude analysis (requires exports)\n- User has very few conversations (<10) making pattern detection unreliable\n- User wants to build specific skill they already have in mind\n- User is asking about existing skills or community skills\n\n**âš¡ Proactive Use:**\nWhen you detect potential patterns during normal conversation, offer:\n```\nðŸ’­ Pattern detected: This is the [Xth] time you've asked me to [action].\n\nWould you like me to analyze your conversation history for similar \npatterns and recommend a Custom Skill? I can identify other automation \nopportunities you might not have noticed.\n\n[Yes, analyze] [Not now]\n```\n\n## Anti-Patterns to Avoid\n\nSee **[shared methodology anti-patterns](../../shared/analysis-methodology.md#anti-patterns-to-avoid)** for complete guidance on:\n- Tasks not suitable for skills\n- Red flags in patterns\n- When to use MCP vs skills\n- Common recommendation pitfalls"
              }
            ]
          },
          {
            "name": "edge-stack",
            "description": "Complete full-stack development toolkit optimized for edge computing. Build modern web applications with Tanstack Start (React), Cloudflare Workers, Polar.sh billing, better-auth authentication, and shadcn/ui design system. Features 27 specialized agents, 12 autonomous SKILLs, 24 workflow commands, and 8 bundled MCP servers.",
            "source": "./plugins/edge-stack",
            "category": "development",
            "version": "3.0.0",
            "author": {
              "name": "Frank Harris",
              "email": "frank@hirefrank.com"
            },
            "install_commands": [
              "/plugin marketplace add hirefrank/hirefrank-marketplace",
              "/plugin install edge-stack@hirefrank-marketplace"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2025-12-19T11:24:04Z",
              "created_at": "2025-10-22T20:20:23Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/es-auth-setup",
                "description": "Interactive authentication setup wizard. Configures better-auth, OAuth providers, and generates handlers for Cloudflare Workers.",
                "path": "plugins/edge-stack/commands/es-auth-setup.md",
                "frontmatter": {
                  "description": "Interactive authentication setup wizard. Configures better-auth, OAuth providers, and generates handlers for Cloudflare Workers."
                },
                "content": "# Authentication Setup Command\n\n<command_purpose> Guide developers through authentication stack configuration with automated code generation, database migrations, and MCP-driven provider setup. </command_purpose>\n\n## Introduction\n\n<role>Senior Security Engineer with expertise in authentication, better-auth, and Cloudflare Workers security</role>\n\n**This command will**:\n- Detect framework (Tanstack Start vs standalone Worker)\n- Configure better-auth for all authentication needs\n- Query better-auth MCP for OAuth provider requirements\n- Generate login/register/logout handlers with React Server Functions\n- Create D1 database schema for users/sessions\n- Configure session security (HTTPS cookies, CSRF)\n- Generate environment variables template\n\n## Prerequisites\n\n<requirements>\n- Cloudflare Workers project (Tanstack Start or Hono)\n- D1 database configured (or will create)\n- For OAuth: Provider credentials (Google, GitHub, etc.)\n</requirements>\n\n## Main Tasks\n\n### 1. Detect Framework & Auth Requirements\n\n**Ask User**:\n```markdown\nðŸ” Authentication Setup Wizard\n\n1. What framework are you using?\n   a) Tanstack Start\n   b) Standalone Worker (Hono/plain TS)\n\n2. What authentication methods do you need?\n   a) Email/Password only\n   b) OAuth providers (Google, GitHub, etc.)\n   c) Passkeys\n   d) Magic Links\n   e) Multiple (OAuth + Email/Password)\n```\n\n**Decision Logic**:\n```\nIf Tanstack Start:\n  â†’ better-auth with React Server Functions\n\nIf Standalone Worker (Hono):\n  â†’ better-auth with Hono middleware\n```\n\n### 2. Install Dependencies\n\n**For Tanstack Start**:\n```bash\npnpm add better-auth @node-rs/argon2\n```\n\n**For Standalone Worker (Hono)**:\n```bash\npnpm add better-auth hono @node-rs/argon2\n```\n\n### 3. Generate Configuration Files\n\n#### Tanstack Start + better-auth\n\n**Generate**: `app/auth.server.ts`\n```typescript\nimport { betterAuth } from 'better-auth';\n\nexport const auth = betterAuth({\n  database: {\n    type: 'd1',\n    database: process.env.DB,\n  },\n\n  emailAndPassword: {\n    enabled: true,\n    requireEmailVerification: true,\n  },\n\n  session: {\n    cookieName: 'session',\n    maxAge: 60 * 60 * 24 * 7, // 7 days\n    cookieCache: {\n      enabled: true,\n      maxAge: 5 * 60 * 1000, // 5 minutes\n    },\n  },\n});\n```\n\n**Generate**: `server/api/auth/login.post.ts`\n```typescript\nimport { hash, verify } from '@node-rs/argon2';\n\nexport default defineEventHandler(async (event) => {\n  const { email, password } = await readBody(event);\n\n  const user = await event.context.cloudflare.env.DB.prepare(\n    'SELECT id, email, password_hash FROM users WHERE email = ?'\n  ).bind(email).first();\n\n  if (!user || !await verify(user.password_hash, password)) {\n    throw createError({ statusCode: 401, message: 'Invalid credentials' });\n  }\n\n  await setUserSession(event, {\n    user: { id: user.id, email: user.email },\n    loggedInAt: new Date().toISOString(),\n  });\n\n  return { success: true };\n});\n```\n\n\n**Query MCP for OAuth Setup**:\n```typescript\nconst googleSetup = await mcp.betterAuth.getProviderSetup('google');\nconst githubSetup = await mcp.betterAuth.getProviderSetup('github');\n```\n\n**Generate**: `server/utils/auth.ts`\n```typescript\nimport { betterAuth } from 'better-auth';\n\nexport const auth = betterAuth({\n  database: {\n    type: 'd1',\n    database: process.env.DB,\n  },\n\n  socialProviders: {\n    google: {\n      clientId: process.env.GOOGLE_CLIENT_ID!,\n      clientSecret: process.env.GOOGLE_CLIENT_SECRET!,\n    },\n    github: {\n      clientId: process.env.GITHUB_CLIENT_ID!,\n      clientSecret: process.env.GITHUB_CLIENT_SECRET!,\n    },\n  },\n});\n```\n\n**Generate**: `server/api/auth/[...].ts` (OAuth handler)\n```typescript\nexport default defineEventHandler(async (event) => {\n  const response = await auth.handler(event.node.req, event.node.res);\n\n  // \n  if (event.node.req.url?.includes('/callback')) {\n    const session = await auth.api.getSession({ headers: event.node.req.headers });\n    if (session) {\n      await setUserSession(event, {\n        user: {\n          id: session.user.id,\n          email: session.user.email,\n          name: session.user.name,\n          provider: session.user.provider,\n        },\n      });\n    }\n  }\n\n  return response;\n});\n```\n\n### 4. Generate Database Migration\n\n**Generate**: `migrations/0001_auth.sql`\n```sql\n-- Users table\nCREATE TABLE users (\n  id TEXT PRIMARY KEY,\n  email TEXT UNIQUE NOT NULL,\n  email_verified INTEGER DEFAULT 0,\n  password_hash TEXT, -- NULL for OAuth-only\n  name TEXT,\n  image TEXT,\n  created_at TEXT NOT NULL,\n  updated_at TEXT NOT NULL\n);\n\n-- OAuth accounts (if using better-auth)\nCREATE TABLE accounts (\n  id TEXT PRIMARY KEY,\n  user_id TEXT NOT NULL,\n  provider TEXT NOT NULL,\n  provider_account_id TEXT NOT NULL,\n  access_token TEXT,\n  refresh_token TEXT,\n  expires_at INTEGER,\n  created_at TEXT NOT NULL,\n\n  FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,\n  UNIQUE(provider, provider_account_id)\n);\n\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_accounts_user ON accounts(user_id);\n```\n\n### 5. Configure Environment Variables\n\n**Generate**: `.dev.vars`\n```bash\n# better-auth secret (generate with: openssl rand -base64 32)\nBETTER_AUTH_SECRET=your-32-char-secret-here\n\n# OAuth credentials (if using OAuth providers)\nGOOGLE_CLIENT_ID=your-google-client-id\nGOOGLE_CLIENT_SECRET=your-google-client-secret\nGITHUB_CLIENT_ID=your-github-client-id\nGITHUB_CLIENT_SECRET=your-github-client-secret\n```\n\n**Production Setup**:\n```bash\nwrangler secret put BETTER_AUTH_SECRET\nwrangler secret put GOOGLE_CLIENT_SECRET\nwrangler secret put GITHUB_CLIENT_SECRET\n```\n\n### 6. Generate Protected Route Example\n\n**Generate**: `server/api/protected.get.ts`\n```typescript\nexport default defineEventHandler(async (event) => {\n  const session = await requireUserSession(event);\n\n  return {\n    message: 'Protected data',\n    user: session.user,\n  };\n});\n```\n\n### 7. Validate Setup\n\n**Security Checklist**:\n- âœ… HTTPS-only cookies configured\n- âœ… httpOnly flag set\n- âœ… SameSite configured (lax or strict)\n- âœ… Password hashing uses Argon2id\n- âœ… Session password is 32+ characters\n- âœ… OAuth redirect URIs configured (if applicable)\n- âœ… CSRF protection enabled (automatic)\n\n## Success Criteria\n\nâœ… Auth setup complete when:\n- Framework detected and appropriate stack chosen\n- Dependencies installed\n- Configuration files generated\n- Database migration created\n- Environment variables template created\n- Security settings validated\n- Example handlers provided\n\n## Output Summary\n\n**Files Created**:\n- Configuration (app.config.ts or auth.ts)\n- Auth handlers (login, register, logout, OAuth callback)\n- Database migration (users, accounts)\n- Protected route example\n- Environment variables template\n\n**Next Actions**:\n1. Run database migration\n2. Generate session password (32+ chars)\n3. Configure OAuth providers (if applicable)\n4. Test authentication flow\n5. Add rate limiting to auth endpoints\n6. Deploy with `/es-deploy`\n\n## Notes\n\n- Always use better-auth for authentication (Workers-optimized)\n- Add OAuth/passkeys/magic links as needed\n- Query better-auth MCP for latest provider requirements\n- Use Argon2id for password hashing (never bcrypt)\n- Store secrets in Cloudflare Workers secrets (not wrangler.toml)\n- See `agents/integrations/better-auth-specialist` for detailed guidance"
              },
              {
                "name": "/es-billing-setup",
                "description": "Interactive Polar.sh billing integration wizard. Sets up products, webhooks, database schema, and subscription middleware for Cloudflare Workers.",
                "path": "plugins/edge-stack/commands/es-billing-setup.md",
                "frontmatter": {
                  "description": "Interactive Polar.sh billing integration wizard. Sets up products, webhooks, database schema, and subscription middleware for Cloudflare Workers."
                },
                "content": "# Billing Setup Command\n\n<command_purpose> Guide developers through complete Polar.sh billing integration with automated code generation, database migrations, and MCP-driven product configuration. </command_purpose>\n\n## Introduction\n\n<role>Senior Payments Integration Engineer with expertise in Polar.sh, Cloudflare Workers, and subscription management</role>\n\n**This command will**:\n- Query Polar MCP for existing products/subscriptions\n- Generate webhook handler with signature verification\n- Create D1 database schema for customers/subscriptions\n- Generate subscription middleware for protected routes\n- Configure environment variables\n- Validate setup via Polar MCP\n\n## Prerequisites\n\n<requirements>\n- Cloudflare Workers project (Tanstack Start or Hono)\n- Polar.sh account: https://polar.sh\n- D1 database configured in wrangler.toml (or will create)\n- Polar Access Token (will guide through obtaining)\n</requirements>\n\n## Main Tasks\n\n### 1. Check Polar Account Setup\n\n<thinking>\nFirst, verify user has Polar account and products created.\nUse Polar MCP to check for existing products.\n</thinking>\n\n#### Immediate Actions:\n\n<task_list>\n\n- [ ] Check if Polar MCP is available\n- [ ] Prompt user for Polar Access Token (if not in env)\n- [ ] Query Polar MCP for existing products\n- [ ] If no products found, guide to Polar dashboard\n- [ ] Display available products and let user select which to integrate\n\n</task_list>\n\n**Check Polar Products**:\n```typescript\n// Query MCP for products\nconst products = await mcp.polar.listProducts();\n\nif (products.length === 0) {\n  console.log(\"âš ï¸  No products found in your Polar account\");\n  console.log(\"ðŸ“‹ Next steps:\");\n  console.log(\"1. Go to https://polar.sh/dashboard\");\n  console.log(\"2. Create your products (Pro, Enterprise, etc.)\");\n  console.log(\"3. Run this command again\");\n  process.exit(0);\n}\n\n// Display products\nconsole.log(\"âœ… Found Polar products:\");\nproducts.forEach((p, i) => {\n  console.log(`${i + 1}. ${p.name} - $${p.prices[0].amount / 100}/${p.prices[0].interval}`);\n  console.log(`   ID: ${p.id}`);\n});\n```\n\n### 2. Generate Webhook Handler\n\n<thinking>\nCreate comprehensive webhook handler with signature verification\nand all critical event handlers.\n</thinking>\n\n**Generate File**: `app/routes/api/webhooks/polar.ts` (Tanstack Start) or `src/webhooks/polar.ts` (Hono)\n\n```typescript\n// Generated webhook handler\nimport { Polar } from '@polar-sh/sdk';\n\nexport interface Env {\n  POLAR_ACCESS_TOKEN: string;\n  POLAR_WEBHOOK_SECRET: string;\n  DB: D1Database;\n}\n\nexport async function handlePolarWebhook(\n  request: Request,\n  env: Env\n): Promise<Response> {\n  // 1. Verify webhook signature\n  const signature = request.headers.get('polar-signature');\n  if (!signature) {\n    return new Response('Missing signature', { status: 401 });\n  }\n\n  const body = await request.text();\n  const polar = new Polar({ accessToken: env.POLAR_ACCESS_TOKEN });\n\n  let event;\n  try {\n    event = polar.webhooks.verify(body, signature, env.POLAR_WEBHOOK_SECRET);\n  } catch (err) {\n    console.error('Webhook verification failed:', err);\n    return new Response('Invalid signature', { status: 401 });\n  }\n\n  // 2. Log event for debugging\n  await env.DB.prepare(\n    \\`INSERT INTO webhook_events (id, type, data, created_at)\n     VALUES (?, ?, ?, ?)\\`\n  ).bind(\n    crypto.randomUUID(),\n    event.type,\n    JSON.stringify(event.data),\n    new Date().toISOString()\n  ).run();\n\n  // 3. Handle event types\n  try {\n    switch (event.type) {\n      case 'checkout.completed':\n        await handleCheckoutCompleted(event.data, env);\n        break;\n\n      case 'subscription.created':\n        await handleSubscriptionCreated(event.data, env);\n        break;\n\n      case 'subscription.updated':\n        await handleSubscriptionUpdated(event.data, env);\n        break;\n\n      case 'subscription.canceled':\n        await handleSubscriptionCanceled(event.data, env);\n        break;\n\n      case 'subscription.past_due':\n        await handleSubscriptionPastDue(event.data, env);\n        break;\n\n      default:\n        console.log('Unhandled event type:', event.type);\n    }\n\n    return new Response('OK', { status: 200 });\n  } catch (err) {\n    console.error('Webhook processing error:', err);\n    return new Response('Processing failed', { status: 500 });\n  }\n}\n\n// Event handlers\nasync function handleCheckoutCompleted(data: any, env: Env) {\n  const { customer_id, product_id, metadata } = data;\n\n  await env.DB.prepare(\n    \\`UPDATE users\n     SET polar_customer_id = ?,\n         product_id = ?,\n         subscription_status = 'active',\n         updated_at = ?\n     WHERE id = ?\\`\n  ).bind(customer_id, product_id, new Date().toISOString(), metadata.user_id).run();\n}\n\nasync function handleSubscriptionCreated(data: any, env: Env) {\n  const { id, customer_id, product_id, status, current_period_end } = data;\n\n  await env.DB.prepare(\n    \\`INSERT INTO subscriptions (id, polar_customer_id, product_id, status, current_period_end, created_at)\n     VALUES (?, ?, ?, ?, ?, ?)\\`\n  ).bind(id, customer_id, product_id, status, current_period_end, new Date().toISOString()).run();\n}\n\nasync function handleSubscriptionUpdated(data: any, env: Env) {\n  const { id, status, product_id, current_period_end } = data;\n\n  await env.DB.prepare(\n    \\`UPDATE subscriptions\n     SET status = ?, product_id = ?, current_period_end = ?, updated_at = ?\n     WHERE id = ?\\`\n  ).bind(status, product_id, current_period_end, new Date().toISOString(), id).run();\n}\n\nasync function handleSubscriptionCanceled(data: any, env: Env) {\n  const { id } = data;\n\n  await env.DB.prepare(\n    \\`UPDATE subscriptions\n     SET status = 'canceled', canceled_at = ?, updated_at = ?\n     WHERE id = ?\\`\n  ).bind(new Date().toISOString(), new Date().toISOString(), id).run();\n}\n\nasync function handleSubscriptionPastDue(data: any, env: Env) {\n  const { id } = data;\n\n  await env.DB.prepare(\n    \\`UPDATE subscriptions\n     SET status = 'past_due', updated_at = ?\n     WHERE id = ?\\`\n  ).bind(new Date().toISOString(), id).run();\n\n  // TODO: Send payment failure notification\n  console.log('Subscription past due:', id);\n}\n\n// App-specific export\nexport default defineEventHandler(async (event) => {\n  return await handlePolarWebhook(\n    event.node.req,\n    event.context.cloudflare.env\n  );\n});\n```\n\n### 3. Generate Database Migration\n\n<thinking>\nCreate D1 schema for users, subscriptions, and webhook event logging.\n</thinking>\n\n**Generate File**: `migrations/0001_polar_billing.sql`\n\n```sql\n-- Users table (add Polar fields)\nCREATE TABLE IF NOT EXISTS users (\n  id TEXT PRIMARY KEY,\n  email TEXT UNIQUE NOT NULL,\n  polar_customer_id TEXT UNIQUE,\n  product_id TEXT,\n  subscription_status TEXT, -- 'active', 'canceled', 'past_due', NULL\n  current_period_end TEXT,\n  created_at TEXT NOT NULL,\n  updated_at TEXT NOT NULL\n);\n\n-- Subscriptions table (detailed tracking)\nCREATE TABLE subscriptions (\n  id TEXT PRIMARY KEY, -- Polar subscription ID\n  polar_customer_id TEXT NOT NULL,\n  product_id TEXT NOT NULL,\n  price_id TEXT NOT NULL,\n  status TEXT NOT NULL, -- 'active', 'canceled', 'past_due', 'trialing'\n  current_period_start TEXT,\n  current_period_end TEXT,\n  canceled_at TEXT,\n  created_at TEXT NOT NULL,\n  updated_at TEXT NOT NULL,\n\n  FOREIGN KEY (polar_customer_id) REFERENCES users(polar_customer_id)\n);\n\n-- Webhook events log (debugging/auditing)\nCREATE TABLE webhook_events (\n  id TEXT PRIMARY KEY,\n  type TEXT NOT NULL,\n  data TEXT NOT NULL, -- JSON blob\n  created_at TEXT NOT NULL\n);\n\n-- Indexes for performance\nCREATE INDEX idx_users_polar_customer ON users(polar_customer_id);\nCREATE INDEX idx_users_subscription_status ON users(subscription_status);\nCREATE INDEX idx_subscriptions_customer ON subscriptions(polar_customer_id);\nCREATE INDEX idx_subscriptions_status ON subscriptions(status);\nCREATE INDEX idx_webhook_events_type ON webhook_events(type);\nCREATE INDEX idx_webhook_events_created ON webhook_events(created_at);\n```\n\n**Run Migration**:\n```bash\nwrangler d1 migrations apply DB --local\nwrangler d1 migrations apply DB --remote\n```\n\n### 4. Generate Subscription Middleware\n\n<thinking>\nCreate middleware to check subscription status on protected routes.\n</thinking>\n\n**Generate File**: `app/middleware/subscription.ts` (Tanstack Start) or `src/middleware/subscription.ts` (Hono)\n\n```typescript\n// Subscription check middleware\nexport async function requireActiveSubscription(\n  request: Request,\n  env: Env,\n  ctx?: ExecutionContext\n) {\n  // Get user ID from session (assumes auth is already set up)\n  const userId = await getUserIdFromSession(request, env);\n\n  if (!userId) {\n    return new Response('Unauthorized', { status: 401 });\n  }\n\n  // Check subscription status\n  const user = await env.DB.prepare(\n    \\`SELECT subscription_status, current_period_end, product_id\n     FROM users\n     WHERE id = ?\\`\n  ).bind(userId).first();\n\n  if (!user) {\n    return new Response('User not found', { status: 404 });\n  }\n\n  // Check if subscription is active\n  if (user.subscription_status !== 'active') {\n    return new Response(JSON.stringify({\n      error: 'subscription_required',\n      message: 'Active subscription required to access this feature',\n      upgrade_url: '/pricing'\n    }), {\n      status: 403,\n      headers: { 'Content-Type': 'application/json' }\n    });\n  }\n\n  // Check if subscription hasn't expired\n  if (user.current_period_end) {\n    const periodEnd = new Date(user.current_period_end);\n    if (periodEnd < new Date()) {\n      return new Response(JSON.stringify({\n        error: 'subscription_expired',\n        message: 'Your subscription has expired',\n        renew_url: '/pricing'\n      }), {\n        status: 403,\n        headers: { 'Content-Type': 'application/json' }\n      });\n    }\n  }\n\n  // Subscription is valid, continue\n  return null;\n}\n\n// Helper to get user ID from session\nasync function getUserIdFromSession(request: Request, env: Env): Promise<string | null> {\n  // TODO: Implement based on your auth setup\n  // const session = await getUserSession(event);\n  // return session?.user?.id || null;\n\n  // For better-auth:\n  // const session = await auth.api.getSession({ headers: request.headers });\n  // return session?.user?.id || null;\n\n  return null; // Placeholder\n}\n```\n\n**Usage Example**:\n```typescript\n// Protected API route\nexport default defineEventHandler(async (event) => {\n  // Check subscription\n  const subscriptionCheck = await requireActiveSubscription(\n    event.node.req,\n    event.context.cloudflare.env\n  );\n\n  if (subscriptionCheck) {\n    return subscriptionCheck; // Return 403 if no subscription\n  }\n\n  // User has active subscription, proceed\n  return {\n    message: 'Premium feature accessed',\n    data: '...'\n  };\n});\n```\n\n### 5. Configure Environment Variables\n\n<thinking>\nUpdate wrangler.toml and create .dev.vars template.\n</thinking>\n\n**Update**: `wrangler.toml`\n\n```toml\n# Add Polar webhook secret (public, not sensitive)\n[vars]\nPOLAR_WEBHOOK_SECRET = \"whsec_...\"  # Get from Polar dashboard\n\n# D1 database (if not already configured)\n[[d1_databases]]\nbinding = \"DB\"\ndatabase_name = \"my-app-db\"\ndatabase_id = \"...\"  # Get from: wrangler d1 create my-app-db\n```\n\n**Create**: `.dev.vars` (local development)\n\n```bash\n# Polar Access Token (sensitive - DO NOT COMMIT)\nPOLAR_ACCESS_TOKEN=polar_at_xxxxxxxxxxxxx\n\n# Get this from: https://polar.sh/dashboard/settings/api\n```\n\n**Production Setup**:\n```bash\n# Set secret in Cloudflare Workers\nwrangler secret put POLAR_ACCESS_TOKEN\n# Paste: polar_at_xxxxxxxxxxxxx\n```\n\n### 6. Configure Polar Webhook Endpoint\n\n<thinking>\nUser needs to configure webhook endpoint in Polar dashboard.\n</thinking>\n\n**Instructions for User**:\n\n```markdown\n## Configure Polar Webhook\n\n1. Go to https://polar.sh/dashboard/settings/webhooks\n2. Click \"Add Webhook Endpoint\"\n3. Enter your webhook URL:\n   - Development: http://localhost:3000/api/webhooks/polar\n   - Production: https://yourdomain.com/api/webhooks/polar\n4. Select events to send:\n   âœ… checkout.completed\n   âœ… subscription.created\n   âœ… subscription.updated\n   âœ… subscription.canceled\n   âœ… subscription.past_due\n5. Copy the \"Webhook Secret\" (whsec_...)\n6. Add to wrangler.toml: POLAR_WEBHOOK_SECRET = \"whsec_...\"\n7. Click \"Create Endpoint\"\n8. Test with \"Send Test Event\" button\n```\n\n### 7. Validate Setup\n\n<thinking>\nUse Polar MCP to verify configuration is correct.\n</thinking>\n\n**Validation Checklist**:\n\n```typescript\n// Run validation checks\nconst validation = {\n  polarAccount: await mcp.polar.verifySetup(),\n  products: await mcp.polar.listProducts(),\n  webhookEvents: await mcp.polar.getWebhookEvents(),\n  database: await checkDatabaseSchema(env),\n  environment: await checkEnvironmentVars(env),\n  webhookEndpoint: await checkWebhookHandler()\n};\n\nconsole.log(\"ðŸ” Polar.sh Integration Validation\\n\");\n\n// 1. Polar Account\nconsole.log(\"âœ… Polar Account:\", validation.polarAccount.status);\nconsole.log(`   Found ${validation.products.length} products`);\n\n// 2. Database Schema\nif (validation.database.users && validation.database.subscriptions) {\n  console.log(\"âœ… Database Schema: Complete\");\n} else {\n  console.log(\"âŒ Database Schema: Missing tables\");\n  console.log(\"   Run: wrangler d1 migrations apply DB\");\n}\n\n// 3. Environment Variables\nif (validation.environment.POLAR_ACCESS_TOKEN && validation.environment.POLAR_WEBHOOK_SECRET) {\n  console.log(\"âœ… Environment Variables: Configured\");\n} else {\n  console.log(\"âŒ Environment Variables: Missing\");\n  if (!validation.environment.POLAR_ACCESS_TOKEN) {\n    console.log(\"   Missing: POLAR_ACCESS_TOKEN\");\n  }\n  if (!validation.environment.POLAR_WEBHOOK_SECRET) {\n    console.log(\"   Missing: POLAR_WEBHOOK_SECRET\");\n  }\n}\n\n// 4. Webhook Handler\nif (validation.webhookEndpoint.exists) {\n  console.log(\"âœ… Webhook Handler: Exists\");\n} else {\n  console.log(\"âŒ Webhook Handler: Not found\");\n}\n\nconsole.log(\"\\nðŸ“‹ Next Steps:\");\nconsole.log(\"1. Configure webhook in Polar dashboard\");\nconsole.log(\"2. Test webhook with Polar's 'Send Test Event'\");\nconsole.log(\"3. Implement subscription checks on protected routes\");\nconsole.log(\"4. Deploy to production with: /es-deploy\");\n```\n\n## Success Criteria\n\nâœ… Billing setup complete when:\n- Polar products queried successfully via MCP\n- Webhook handler generated with signature verification\n- Database schema created (users, subscriptions, webhook_events)\n- Subscription middleware generated\n- Environment variables configured\n- Validation passes all checks\n- User guided through Polar dashboard configuration\n\n## Output Summary\n\n**Files Created**:\n- `server/api/webhooks/polar.ts` (or `src/webhooks/polar.ts`)\n- `server/middleware/subscription.ts` (or `src/middleware/subscription.ts`)\n- `migrations/0001_polar_billing.sql`\n- `.dev.vars` (template)\n\n**Files Updated**:\n- `wrangler.toml` (added Polar vars and D1 binding)\n\n**Next Actions**:\n1. Run database migration\n2. Configure webhook in Polar dashboard\n3. Test webhook with Polar simulator\n4. Add subscription checks to protected routes\n5. Deploy with `/es-deploy`\n\n## Notes\n\n- Always use Polar MCP for real-time product data\n- Test webhooks locally with Polar's test event feature\n- Store POLAR_ACCESS_TOKEN as Cloudflare secret (not in wrangler.toml)\n- Webhook endpoint must be publicly accessible (use ngrok for local testing)\n- See `agents/integrations/polar-billing-specialist` for detailed implementation guidance"
              },
              {
                "name": "/es-commit",
                "description": "Commit all changes with AI-generated message and push to current branch",
                "path": "plugins/edge-stack/commands/es-commit.md",
                "frontmatter": {
                  "description": "Commit all changes with AI-generated message and push to current branch"
                },
                "content": "# Commit and Push Changes\n\n<command_purpose> Automatically stage all changes, generate a comprehensive commit message based on the diff, commit with proper formatting, and push to the current branch. </command_purpose>\n\n## Introduction\n\n<role>Git Workflow Automation Specialist</role>\n\nThis command analyzes your changes, generates a meaningful commit message following conventional commit standards, and pushes to your current working branch.\n\n## Prerequisites\n\n<requirements>\n- Git repository initialized\n- Changes to commit (tracked or untracked files)\n- Remote repository configured\n- Authentication set up for push operations\n</requirements>\n\n## Commit Message Override\n\n<commit_message_override> #$ARGUMENTS </commit_message_override>\n\n**Usage**:\n- `/es-commit` - Auto-generate commit message from changes\n- `/es-commit \"Custom message\"` - Use provided message\n\n## Main Tasks\n\n### 1. Pre-Commit Validation\n\n<thinking>\nBefore committing, verify the repository state and ensure we're ready to commit.\n</thinking>\n\n**Check repository status**:\n\n```bash\n# Verify we're in a git repository\nif ! git rev-parse --git-dir > /dev/null 2>&1; then\n  echo \"âŒ Error: Not a git repository\"\n  exit 1\nfi\n\n# Get current branch\nCURRENT_BRANCH=$(git branch --show-current)\necho \"ðŸ“ Current branch: $CURRENT_BRANCH\"\n\n# Check if there are changes to commit\nif git diff --quiet && git diff --cached --quiet && [ -z \"$(git ls-files --others --exclude-standard)\" ]; then\n  echo \"âœ… No changes to commit\"\n  exit 0\nfi\n\n# Show status\ngit status --short\n```\n\n### 2. Analyze Changes\n\n<thinking>\nAnalyze what changed to generate an appropriate commit message.\n</thinking>\n\n**Gather change information**:\n\n```bash\n# Count changes\nADDED=$(git ls-files --others --exclude-standard | wc -l)\nMODIFIED=$(git diff --name-only | wc -l)\nSTAGED=$(git diff --cached --name-only | wc -l)\nDELETED=$(git ls-files --deleted | wc -l)\n\necho \"\"\necho \"ðŸ“Š Change Summary:\"\necho \"  Added: $ADDED files\"\necho \"  Modified: $MODIFIED files\"\necho \"  Staged: $STAGED files\"\necho \"  Deleted: $DELETED files\"\n\n# Get detailed diff for commit message generation\ngit diff --cached --stat\ngit diff --stat\n```\n\n### 3. Generate Commit Message\n\n<thinking>\nIf user didn't provide a message, generate one based on the changes.\nUse conventional commit format with proper categorization.\n</thinking>\n\n**If no custom message provided**:\n\nAnalyze the diff and generate a commit message following this format:\n\n```\n<type>: <short description>\n\n<detailed description>\n\n<body with specifics>\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n```\n\n**Commit type selection**:\n- `feat:` - New features or capabilities\n- `fix:` - Bug fixes\n- `refactor:` - Code restructuring without behavior change\n- `docs:` - Documentation only\n- `style:` - Formatting, whitespace, etc.\n- `perf:` - Performance improvements\n- `test:` - Adding or updating tests\n- `chore:` - Maintenance tasks, dependencies\n- `ci:` - CI/CD changes\n\n**Message generation guidelines**:\n\n1. **Analyze file changes**:\n   ```bash\n   # Check which directories/files changed\n   git diff --name-only HEAD\n   git diff --cached --name-only\n   git ls-files --others --exclude-standard\n   ```\n\n2. **Categorize the changes**:\n   - New files â†’ likely `feat:`\n   - Modified existing files â†’ check diff content\n   - Deleted files â†’ `refactor:` or `chore:`\n   - Documentation files â†’ `docs:`\n   - Config files â†’ `chore:` or `ci:`\n\n3. **Generate specific description**:\n   - List key files changed\n   - Explain WHY the change was made (not just WHAT)\n   - Include impact/benefits\n   - Reference related commands, agents, or SKILLs if relevant\n\n4. **Example generated message**:\n   ```\n   feat: Add automated commit workflow command\n\n   Created /es-commit command to streamline git workflow by automatically\n   staging changes, generating contextual commit messages, and pushing to\n   the current working branch.\n\n   Key features:\n   - Auto-detects current branch (PR branches, feature branches, main)\n   - Generates conventional commit messages from diff analysis\n   - Supports custom commit messages via arguments\n   - Validates repository state before committing\n   - Automatically pushes to remote after successful commit\n\n   Files added:\n   - commands/es-commit.md (workflow automation command)\n\n   ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\n   Co-Authored-By: Claude <noreply@anthropic.com>\n   ```\n\n### 4. Stage All Changes\n\n<thinking>\nStage all changes including untracked files.\n</thinking>\n\n```bash\n# Stage everything\ngit add -A\n\necho \"âœ… Staged all changes\"\n```\n\n### 5. Create Commit\n\n<thinking>\nCommit with the generated or provided message.\nUse heredoc for proper formatting.\n</thinking>\n\n**If custom message provided**:\n\n```bash\ngit commit -m \"$(cat <<'EOF'\n$CUSTOM_MESSAGE\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\"\n```\n\n**If auto-generated message**:\n\n```bash\ngit commit -m \"$(cat <<'EOF'\n$GENERATED_MESSAGE\nEOF\n)\"\n```\n\n**Verify commit succeeded**:\n\n```bash\nif [ $? -eq 0 ]; then\n  echo \"âœ… Commit created successfully\"\n  git log -1 --oneline\nelse\n  echo \"âŒ Commit failed\"\n  exit 1\nfi\n```\n\n### 6. Push to Current Branch\n\n<thinking>\nPush to the current branch (whether it's main, a feature branch, or a PR branch).\nUse -u flag to set upstream if not already set.\n</thinking>\n\n```bash\n# Get current branch again\nCURRENT_BRANCH=$(git branch --show-current)\n\n# Check if branch has upstream\nif git rev-parse --abbrev-ref @{upstream} > /dev/null 2>&1; then\n  # Upstream exists, just push\n  echo \"ðŸ“¤ Pushing to origin/$CURRENT_BRANCH...\"\n  git push origin \"$CURRENT_BRANCH\"\nelse\n  # No upstream, set it with -u\n  echo \"ðŸ“¤ Pushing to origin/$CURRENT_BRANCH (setting upstream)...\"\n  git push -u origin \"$CURRENT_BRANCH\"\nfi\n\nif [ $? -eq 0 ]; then\n  echo \"âœ… Pushed successfully to origin/$CURRENT_BRANCH\"\nelse\n  echo \"âŒ Push failed\"\n  exit 1\nfi\n```\n\n### 7. Summary Report\n\n<deliverable>\nFinal report showing what was committed and pushed\n</deliverable>\n\n```markdown\n## âœ… Commit Complete\n\n**Branch**: $CURRENT_BRANCH\n**Commit**: $(git log -1 --oneline)\n**Remote**: origin/$CURRENT_BRANCH\n\n### Changes Committed:\n- Added: $ADDED files\n- Modified: $MODIFIED files\n- Deleted: $DELETED files\n\n### Commit Message:\n```\n$COMMIT_MESSAGE\n```\n\n### Next Steps:\n- View commit: `git log -1 -p`\n- View on GitHub: `gh browse`\n- Create PR: `gh pr create` (if on feature branch)\n```\n\n## Usage Examples\n\n### Auto-generate commit message\n```bash\n/es-commit\n```\n\n### Custom commit message\n```bash\n/es-commit \"fix: Resolve authentication timeout issue\"\n```\n\n### With detailed custom message\n```bash\n/es-commit \"feat: Add Polar.sh billing integration\n\nComplete implementation of Polar.sh billing with webhooks,\nsubscription middleware, and D1 database schema.\"\n```\n\n## Safety Features\n\n**Pre-commit checks**:\n- âœ… Verifies git repository exists\n- âœ… Shows status before committing\n- âœ… Validates changes exist\n- âœ… Confirms commit succeeded before pushing\n\n**Branch awareness**:\n- âœ… Always pushes to current branch (respects PR branches)\n- âœ… Sets upstream automatically if needed\n- âœ… Shows clear feedback on branch and remote\n\n**Message quality**:\n- âœ… Follows conventional commit standards\n- âœ… Includes Claude Code attribution\n- âœ… Provides detailed context from diff analysis\n\n## Integration with Other Commands\n\n**Typical workflow**:\n1. `/es-work` - Work on feature\n2. `/es-validate` - Validate changes\n3. `/es-commit` - Commit and push â† THIS COMMAND\n4. `gh pr create` - Create PR (if on feature branch)\n\n**Or for quick iterations**:\n1. Make changes\n2. `/es-commit` - Auto-commit with generated message\n3. Continue working\n\n## Best Practices\n\n**Do's** âœ…:\n- Run `/es-validate` before committing\n- Review the generated commit message\n- Use custom messages for complex changes\n- Let it auto-detect your current branch\n- Use on feature branches and main branch\n\n**Don'ts** âŒ:\n- Don't commit secrets or credentials (command doesn't check)\n- Don't use for force pushes (not supported)\n- Don't amend commits (creates new commit)\n- Don't bypass hooks (respects all git hooks)\n\n## Troubleshooting\n\n**Issue**: \"Not a git repository\"\n**Solution**: Run `git init` or navigate to repository root\n\n**Issue**: \"No changes to commit\"\n**Solution**: Make changes first or check if already committed\n\n**Issue**: \"Push failed\"\n**Solution**: Check authentication (`gh auth status`), verify remote exists\n\n**Issue**: \"Commit message too generic\"\n**Solution**: Provide custom message with `/es-commit \"your message\"`\n\n---\n\n**Remember**: This command commits ALL changes (tracked and untracked). Review `git status` if you want to commit selectively."
              },
              {
                "name": "/es-component",
                "description": "Scaffold shadcn/ui components with distinctive design, accessibility, and animation best practices built-in. Prevents generic aesthetics from the start.",
                "path": "plugins/edge-stack/commands/es-component.md",
                "frontmatter": {
                  "description": "Scaffold shadcn/ui components with distinctive design, accessibility, and animation best practices built-in. Prevents generic aesthetics from the start."
                },
                "content": "# Component Generator Command\n\n<command_purpose> Generate shadcn/ui components with distinctive design patterns, deep customization, accessibility features, and engaging animations built-in. Prevents generic \"AI aesthetic\" by providing branded templates from the start. </command_purpose>\n\n## Introduction\n\n<role>Senior Component Architect with expertise in shadcn/ui, React 19 with hooks, Tailwind CSS, accessibility, and distinctive design patterns</role>\n\n**Design Philosophy**: Start with distinctive, accessible, engaging components rather than fixing generic patterns later.\n\n## Prerequisites\n\n<requirements>\n- Tanstack Start project with Vue 3\n- shadcn/ui component library installed\n- Tailwind 4 CSS configured with custom theme (or will be created)\n- (Optional) shadcn/ui MCP server for component API validation\n- (Optional) Existing `composables/useDesignSystem.ts` for consistent patterns\n</requirements>\n\n## Command Usage\n\n```bash\n/es-component <type> <name> [options]\n```\n\n### Arguments:\n\n- `<type>`: Component type (button, card, form, modal, hero, navigation, etc.)\n- `<name>`: Component name in PascalCase (e.g., `PrimaryButton`, `FeatureCard`)\n- `[options]`: Optional flags:\n  - `--theme <dark|light|custom>`: Theme variant\n  - `--animations <minimal|standard|rich>`: Animation complexity\n  - `--accessible`: Include enhanced accessibility features (default: true)\n  - `--output <path>`: Custom output path (default: `components/`)\n\n### Examples:\n\n```bash\n# Generate primary button component\n/es-component button PrimaryButton\n\n# Generate feature card with rich animations\n/es-component card FeatureCard --animations rich\n\n# Generate hero section with custom theme\n/es-component hero LandingHero --theme custom\n\n# Generate modal with custom output path\n/es-component modal ConfirmDialog --output components/dialogs/\n```\n\n## Main Tasks\n\n### 1. Project Context Analysis\n\n<thinking>\nFirst, I need to understand existing design system, theme configuration, and component patterns.\nThis ensures generated components match existing project aesthetics.\n</thinking>\n\n#### Immediate Actions:\n\n<task_list>\n\n- [ ] Check for `tailwind.config.ts` and extract custom theme (fonts, colors, animations)\n- [ ] Check for `composables/useDesignSystem.ts` and extract existing variants\n- [ ] Check for `app.config.ts` and extract shadcn/ui global customization\n- [ ] Scan existing components for naming conventions and structure patterns\n- [ ] Determine if design system is established or needs creation\n\n</task_list>\n\n#### Output Summary:\n\n<summary_format>\nðŸ“¦ **Project Context**:\n- Custom fonts: Found/Not Found (Inter âŒ or Custom âœ…)\n- Brand colors: Found/Not Found (Purple âŒ or Custom âœ…)\n- Design system composable: Exists/Missing\n- Component count: X components found\n- Naming convention: Detected pattern\n</summary_format>\n\n### 2. Validate Component Type with MCP (if available)\n\n<thinking>\nIf shadcn/ui MCP is available, validate that the requested component type exists\nand get accurate props/slots before generating.\n</thinking>\n\n#### MCP Validation:\n\n<mcp_workflow>\n\nIf shadcn/ui MCP available:\n1. Query `shadcn-ui.list_components()` to get available components\n2. Map component type to shadcn/ui component:\n   - `button` â†’ `Button`\n   - `card` â†’ `Card`\n   - `modal` â†’ `Dialog`\n   - `form` â†’ `UForm` + `Input`/`UTextarea`/etc.\n   - `hero` â†’ Custom layout with `Button`, `Card`\n   - `navigation` â†’ `UTabs` or custom\n3. Query `shadcn-ui.get_component(\"Button\")` for accurate props\n4. Use real props in generated component (prevent hallucination)\n\nIf MCP not available:\n- Use documented shadcn/ui API\n- Include comment: \"// TODO: Verify props with shadcn/ui docs\"\n\n</mcp_workflow>\n\n### 3. Generate Component with Design Best Practices\n\n<thinking>\nGenerate React component with:\n1. Distinctive typography (custom fonts, not Inter)\n2. Brand colors (custom palette, not purple)\n3. Rich animations (transitions, micro-interactions)\n4. Deep shadcn/ui customization (ui prop + utilities)\n5. Accessibility features (ARIA, keyboard, focus states)\n6. Responsive design\n</thinking>\n\n#### Component Templates by Type:\n\n#### Button Component\n\n<button_template>\n\n```tsx\n<!-- app/components/PrimaryButton.tsx -->\n<script setup lang=\"ts\">\nimport { computed } from 'react';\n\ninterface Props {\n  /** Button label */\n  label?: string;\n  /** Icon name (Iconify format) */\n  icon?: string;\n  /** Loading state */\n  loading?: boolean;\n  /** Disabled state */\n  disabled?: boolean;\n  /** Button size */\n  size?: 'sm' | 'md' | 'lg' | 'xl';\n  /** Full width */\n  fullWidth?: boolean;\n}\n\nconst props = withDefaults(defineProps<Props>(), {\n  label: '',\n  icon: '',\n  loading: false,\n  disabled: false,\n  size: 'lg',\n  fullWidth: false\n});\n\nconst emit = defineEmits<{\n  click: [event: MouseEvent];\n}>();\n\nconst buttonClasses = computed(() => ({\n  'w-full': props.fullWidth\n}));\n\n  <Button\n    :color=\"primary\"\n    :size=\"size\"\n    loading={loading\"\n    disabled={disabled || loading\"\n    :icon=\"icon\"\n    :ui=\"{\n      font: 'font-heading tracking-wide',\n      rounded: 'rounded-full',\n      padding: {\n        sm: 'px-4 py-2',\n        md: 'px-6 py-3',\n        lg: 'px-8 py-4',\n        xl: 'px-10 py-5'\n      },\n      shadow: 'shadow-lg hover:shadow-xl'\n    }\"\n    :class=\"[\n      'transition-all duration-300 ease-out',\n      'hover:scale-105 hover:-rotate-1',\n      'active:scale-95 active:rotate-0',\n      'focus:outline-none',\n      'focus-visible:ring-2 focus-visible:ring-primary-500 focus-visible:ring-offset-2',\n      'motion-safe:hover:scale-105',\n      'motion-reduce:hover:bg-primary-700',\n      buttonClasses\n    ]\"\n    onClick={emit('click', $event)\"\n  >\n    <span class=\"inline-flex items-center gap-2\">\n      <slot>{ label}</slot>\n\n      <!-- Animated icon on hover -->\n      <Icon\n        {&& \"icon && !loading\"\n        :name=\"icon\"\n        class=\"\n          transition-transform duration-300\n          group-hover:translate-x-1 group-hover:-translate-y-0.5\n        \"\n      />\n    </span>\n  </Button>\n```\n\n**Usage Example**:\n```tsx\nconst handleClick = () => {\n  console.log('Clicked!');\n};\n\n  <PrimaryButton\n    label=\"Get Started\"\n    icon=\"i-heroicons-arrow-right\"\n    size=\"lg\"\n    onClick={handleClick\"\n  />\n```\n\n</button_template>\n\n#### Card Component\n\n<card_template>\n\n```tsx\n<!-- app/components/FeatureCard.tsx -->\n<script setup lang=\"ts\">\nimport { ref } from 'react';\n\ninterface Props {\n  /** Card title */\n  title: string;\n  /** Card description */\n  description?: string;\n  /** Icon name */\n  icon?: string;\n  /** Enable hover effects */\n  hoverable?: boolean;\n  /** Card variant */\n  variant?: 'default' | 'elevated' | 'outlined';\n}\n\nconst props = withDefaults(defineProps<Props>(), {\n  description: '',\n  icon: '',\n  hoverable: true,\n  variant: 'elevated'\n});\n\nconst isHovered = ref(false);\n\nconst cardUi = computed(() => ({\n  background: 'bg-white dark:bg-brand-midnight',\n  ring: props.variant === 'outlined' ? 'ring-1 ring-brand-coral/20' : '',\n  rounded: 'rounded-2xl',\n  shadow: props.variant === 'elevated' ? 'shadow-xl hover:shadow-2xl' : 'shadow-md',\n  body: {\n    padding: 'p-8',\n    background: 'bg-gradient-to-br from-white to-gray-50 dark:from-brand-midnight dark:to-gray-900'\n  }\n}));\n\n  <Card\n    :ui=\"cardUi\"\n    :class=\"[\n      'transition-all duration-300',\n      hoverable && 'hover:-translate-y-2 hover:rotate-1 cursor-pointer',\n      'motion-safe:hover:-translate-y-2',\n      'motion-reduce:hover:shadow-xl'\n    ]\"\n    onMouseEnter=\"isHovered = true\"\n    onMouseLeave=\"isHovered = false\"\n  >\n    <div class=\"space-y-4\">\n      <!-- Icon -->\n      <div\n        {&& \"icon\"\n        :class=\"[\n          'inline-flex items-center justify-center',\n          'w-16 h-16 rounded-2xl',\n          'bg-gradient-to-br from-brand-coral to-brand-ocean',\n          'transition-transform duration-300',\n          isHovered && 'scale-110 rotate-3'\n        ]\"\n      >\n        <Icon\n          :name=\"icon\"\n          class=\"w-8 h-8 text-white\"\n        />\n      </div>\n\n      <!-- Title -->\n      <h3\n        :class=\"[\n          'font-heading text-2xl',\n          'text-brand-midnight dark:text-white',\n          'transition-colors duration-300',\n          isHovered && 'text-brand-coral'\n        ]\"\n      >\n        { title}\n      </h3>\n\n      <!-- Description -->\n      <p\n        {&& \"description\"\n        class=\"text-gray-700 dark:text-gray-300 leading-relaxed\"\n      >\n        { description}\n      </p>\n\n      <!-- Default slot for custom content -->\n      <div {&& \"$slots.default\">\n        <slot />\n      </div>\n\n      <!-- Footer slot -->\n      <div {&& \"$slots.footer\" class=\"pt-4 border-t border-gray-200 dark:border-gray-700\">\n        <slot name=\"footer\" />\n      </div>\n    </div>\n  </Card>\n```\n\n**Usage Example**:\n```tsx\n  <FeatureCard\n    title=\"Fast Deployment\"\n    description=\"Deploy to the edge in seconds with Cloudflare Workers\"\n    icon=\"i-heroicons-rocket-launch\"\n    hoverable\n  >\n    <template #footer>\n      <PrimaryButton label=\"Learn More\" size=\"sm\" />\n  </FeatureCard>\n```\n\n</card_template>\n\n#### Form Component\n\n<form_template>\n\n```tsx\n<!-- app/components/ContactForm.tsx -->\n<script setup lang=\"ts\">\nimport { ref, reactive } from 'react';\nimport { z } from 'zod';\nimport type { FormSubmitEvent } from '#ui/types';\n\n// Validation schema\nconst schema = z.object({\n  name: z.string().min(2, 'Name must be at least 2 characters'),\n  email: z.string().email('Invalid email address'),\n  message: z.string().min(10, 'Message must be at least 10 characters')\n});\n\ntype Schema = z.output<typeof schema>;\n\nconst formData = reactive<Schema>({\n  name: '',\n  email: '',\n  message: ''\n});\n\nconst isSubmitting = ref(false);\nconst showSuccess = ref(false);\nconst showError = ref(false);\nconst errorMessage = ref('');\n\nconst onSubmit = async (event: FormSubmitEvent<Schema>) => {\n  isSubmitting.value = true;\n  showSuccess.value = false;\n  showError.value = false;\n\n  try {\n    // Simulate API call\n    await new Promise(resolve => setTimeout(resolve, 2000));\n\n    console.log('Form submitted:', event.data);\n\n    showSuccess.value = true;\n\n    // Reset form\n    formData.name = '';\n    formData.email = '';\n    formData.message = '';\n\n    // Hide success message after 5 seconds\n    setTimeout(() => {\n      showSuccess.value = false;\n    }, 5000);\n  } catch (error) {\n    showError.value = true;\n    errorMessage.value = 'Failed to submit form. Please try again.';\n  } finally {\n    isSubmitting.value = false;\n  }\n};\n\n  <div class=\"space-y-6\">\n    <!-- Success Alert -->\n    <Transition\n      enter-active-class=\"transition-all duration-300 ease-out\"\n      enter-from-class=\"opacity-0 translate-y-2 scale-95\"\n      enter-to-class=\"opacity-100 translate-y-0 scale-100\"\n      leave-active-class=\"transition-all duration-200 ease-in\"\n      leave-from-class=\"opacity-100\"\n      leave-to-class=\"opacity-0\"\n    >\n      <Alert\n        {&& \"showSuccess\"\n        color=\"green\"\n        icon=\"i-heroicons-check-circle\"\n        title=\"Success!\"\n        description=\"Your message has been sent successfully.\"\n        :closable=\"true\"\n        :ui=\"{ rounded: 'rounded-xl', padding: 'p-4' }\"\n        onClose=\"showSuccess = false\"\n      />\n    </Transition>\n\n    <!-- Error Alert -->\n    <Transition\n      enter-active-class=\"transition-all duration-300 ease-out\"\n      enter-from-class=\"opacity-0 translate-y-2\"\n      enter-to-class=\"opacity-100 translate-y-0\"\n    >\n      <Alert\n        {&& \"showError\"\n        color=\"red\"\n        icon=\"i-heroicons-x-circle\"\n        title=\"Error\"\n        :description=\"errorMessage\"\n        :closable=\"true\"\n        onClose=\"showError = false\"\n      />\n    </Transition>\n\n    <!-- Form -->\n    <UForm\n      :schema=\"schema\"\n      :state=\"formData\"\n      class=\"space-y-6\"\n      onSubmit=\"onSubmit\"\n    >\n      <!-- Name Field -->\n      <UFormGroup\n        label=\"Name\"\n        name=\"name\"\n        required\n        :ui=\"{ label: { base: 'font-medium text-sm' } }\"\n      >\n        <Input\n          value=\"formData.name\"\n          placeholder=\"Your name\"\n          icon=\"i-heroicons-user\"\n          :ui=\"{\n            rounded: 'rounded-lg',\n            padding: { sm: 'px-4 py-3' },\n            icon: { leading: { padding: { sm: 'ps-11' } } }\n          }\"\n          class=\"transition-all duration-200 focus-within:ring-2 focus-within:ring-brand-coral\"\n        />\n      </UFormGroup>\n\n      <!-- Email Field -->\n      <UFormGroup\n        label=\"Email\"\n        name=\"email\"\n        required\n      >\n        <Input\n          value=\"formData.email\"\n          type=\"email\"\n          placeholder=\"your@email.com\"\n          icon=\"i-heroicons-envelope\"\n          :ui=\"{\n            rounded: 'rounded-lg',\n            padding: { sm: 'px-4 py-3' }\n          }\"\n          class=\"transition-all duration-200 focus-within:ring-2 focus-within:ring-brand-coral\"\n        />\n      </UFormGroup>\n\n      <!-- Message Field -->\n      <UFormGroup\n        label=\"Message\"\n        name=\"message\"\n        required\n      >\n        <UTextarea\n          value=\"formData.message\"\n          placeholder=\"Your message...\"\n          :rows=\"5\"\n          :ui=\"{\n            rounded: 'rounded-lg',\n            padding: { sm: 'px-4 py-3' }\n          }\"\n          class=\"transition-all duration-200 focus-within:ring-2 focus-within:ring-brand-coral\"\n        />\n      </UFormGroup>\n\n      <!-- Submit Button -->\n      <Button\n        type=\"submit\"\n        loading={isSubmitting\"\n        disabled={isSubmitting\"\n        color=\"primary\"\n        size=\"lg\"\n        :ui=\"{\n          font: 'font-heading',\n          rounded: 'rounded-full',\n          padding: { lg: 'px-8 py-4' }\n        }\"\n        class=\"\n          w-full\n          transition-all duration-300\n          hover:scale-105 hover:shadow-xl\n          active:scale-95\n          motion-safe:hover:scale-105\n          motion-reduce:hover:bg-primary-700\n        \"\n      >\n        <span class=\"inline-flex items-center gap-2\">\n          <Icon\n            {&& \"!isSubmitting\"\n            name=\"i-heroicons-paper-airplane\"\n            class=\"transition-transform duration-300 group-hover:translate-x-1 group-hover:-translate-y-0.5\"\n          />\n          { isSubmitting ? 'Sending...' : 'Send Message'}\n        </span>\n      </Button>\n    </UForm>\n  </div>\n```\n\n</form_template>\n\n#### Hero Component\n\n<hero_template>\n\n```tsx\n<!-- app/components/LandingHero.tsx -->\n<script setup lang=\"ts\">\ninterface Props {\n  /** Hero title */\n  title: string;\n  /** Hero subtitle */\n  subtitle?: string;\n  /** Primary CTA label */\n  primaryCta?: string;\n  /** Secondary CTA label */\n  secondaryCta?: string;\n}\n\nconst props = withDefaults(defineProps<Props>(), {\n  subtitle: '',\n  primaryCta: 'Get Started',\n  secondaryCta: 'Learn More'\n});\n\nconst emit = defineEmits<{\n  primaryClick: [];\n  secondaryClick: [];\n}>();\n\n  <div class=\"relative min-h-screen flex items-center justify-center overflow-hidden\">\n    <!-- Atmospheric Background -->\n    <div class=\"absolute inset-0 bg-gradient-to-br from-brand-cream via-white to-brand-ocean/10\" />\n\n    <!-- Animated Gradient Orbs -->\n    <div\n      class=\"absolute top-20 left-20 w-96 h-96 bg-brand-coral/20 rounded-full blur-3xl animate-pulse\"\n      aria-hidden=\"true\"\n    />\n    <div\n      class=\"absolute bottom-20 right-20 w-96 h-96 bg-brand-ocean/20 rounded-full blur-3xl animate-pulse\"\n      style=\"animation-delay: 1s;\"\n      aria-hidden=\"true\"\n    />\n\n    <!-- Subtle Pattern Overlay -->\n    <div\n      class=\"absolute inset-0 opacity-5\"\n      style=\"background-image: radial-gradient(circle, #000 1px, transparent 1px); background-size: 20px 20px;\"\n      aria-hidden=\"true\"\n    />\n\n    <!-- Content -->\n    <div class=\"relative z-10 max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-24\">\n      <div class=\"text-center space-y-8\">\n        <!-- Animated Badge -->\n        <div\n          class=\"\n            inline-flex items-center gap-2\n            px-4 py-2 rounded-full\n            bg-brand-coral/10 border border-brand-coral/20\n            text-brand-coral font-medium\n            animate-in slide-in-from-top duration-500\n          \"\n        >\n          <Icon name=\"i-heroicons-sparkles\" class=\"w-4 h-4 animate-pulse\" />\n          <span class=\"text-sm\">New: Now on Cloudflare Workers</span>\n        </div>\n\n        <!-- Title -->\n        <h1\n          class=\"\n            font-heading text-6xl sm:text-7xl lg:text-8xl\n            tracking-tighter leading-none\n            text-brand-midnight dark:text-white\n            animate-in slide-in-from-top duration-700\n          \"\n          style=\"animation-delay: 100ms;\"\n        >\n          { title}\n        </h1>\n\n        <!-- Subtitle -->\n        <p\n          {&& \"subtitle\"\n          class=\"\n            max-w-2xl mx-auto\n            text-xl sm:text-2xl leading-relaxed\n            text-gray-700 dark:text-gray-300\n            animate-in slide-in-from-top duration-700\n          \"\n          style=\"animation-delay: 200ms;\"\n        >\n          { subtitle}\n        </p>\n\n        <!-- CTAs -->\n        <div\n          class=\"\n            flex flex-col sm:flex-row items-center justify-center gap-4\n            animate-in slide-in-from-top duration-700\n          \"\n          style=\"animation-delay: 300ms;\"\n        >\n          <Button\n            color=\"primary\"\n            size=\"xl\"\n            :ui=\"{\n              font: 'font-heading tracking-wide',\n              rounded: 'rounded-full',\n              padding: { xl: 'px-10 py-5' }\n            }\"\n            class=\"\n              transition-all duration-300\n              hover:scale-110 hover:-rotate-2 hover:shadow-2xl\n              active:scale-95 active:rotate-0\n              motion-safe:hover:scale-110\n            \"\n            onClick={emit('primaryClick')\"\n          >\n            <span class=\"inline-flex items-center gap-2\">\n              { primaryCta}\n              <Icon\n                name=\"i-heroicons-arrow-right\"\n                class=\"transition-transform duration-300 group-hover:translate-x-2\"\n              />\n            </span>\n          </Button>\n\n          <Button\n            color=\"gray\"\n            variant=\"outline\"\n            size=\"xl\"\n            :ui=\"{\n              font: 'font-sans',\n              rounded: 'rounded-full'\n            }\"\n            class=\"\n              transition-all duration-300\n              hover:scale-105 hover:shadow-lg\n              active:scale-95\n            \"\n            onClick={emit('secondaryClick')\"\n          >\n            { secondaryCta}\n          </Button>\n        </div>\n\n        <!-- Slot for additional content -->\n        <div {&& \"$slots.default\" class=\"mt-12\">\n          <slot />\n        </div>\n      </div>\n    </div>\n  </div>\n```\n\n</hero_template>\n\n### 4. Create Design System Composable (if missing)\n\n<thinking>\nIf design system composable doesn't exist, generate it to ensure consistency\nacross all components.\n</thinking>\n\n<design_system_composable>\n\n```typescript\n// composables/useDesignSystem.ts\nimport type { ButtonProps } from '#ui/types';\n\nexport const useDesignSystem = () => {\n  /**\n   * Button Variants\n   */\n  const button = {\n    primary: {\n      color: 'primary',\n      size: 'lg',\n      ui: {\n        font: 'font-heading tracking-wide',\n        rounded: 'rounded-full',\n        padding: { lg: 'px-8 py-4' },\n        shadow: 'shadow-lg hover:shadow-xl'\n      },\n      class: 'transition-all duration-300 hover:scale-105 hover:-rotate-1 active:scale-95 active:rotate-0'\n    } as ButtonProps,\n\n    secondary: {\n      color: 'gray',\n      variant: 'outline',\n      size: 'md',\n      ui: {\n        font: 'font-sans',\n        rounded: 'rounded-lg'\n      },\n      class: 'transition-colors duration-200 hover:bg-gray-100 dark:hover:bg-gray-800'\n    } as ButtonProps,\n\n    ghost: {\n      variant: 'ghost',\n      size: 'md',\n      ui: {\n        font: 'font-sans'\n      },\n      class: 'transition-colors duration-200'\n    } as ButtonProps\n  };\n\n  /**\n   * Card Variants\n   */\n  const card = {\n    elevated: {\n      ui: {\n        background: 'bg-white dark:bg-brand-midnight',\n        rounded: 'rounded-2xl',\n        shadow: 'shadow-xl hover:shadow-2xl',\n        body: { padding: 'p-8' }\n      },\n      class: 'transition-all duration-300 hover:-translate-y-1'\n    },\n\n    outlined: {\n      ui: {\n        background: 'bg-white dark:bg-brand-midnight',\n        ring: 'ring-1 ring-brand-coral/20',\n        rounded: 'rounded-2xl',\n        body: { padding: 'p-8' }\n      },\n      class: 'transition-all duration-300 hover:ring-brand-coral/40'\n    }\n  };\n\n  /**\n   * Animation Presets\n   */\n  const animations = {\n    fadeIn: 'animate-in fade-in duration-500',\n    slideUp: 'animate-in slide-in-from-bottom duration-500',\n    slideDown: 'animate-in slide-in-from-top duration-500',\n    scaleIn: 'animate-in zoom-in duration-300',\n    hover: {\n      scale: 'transition-transform duration-300 hover:scale-105',\n      lift: 'transition-all duration-300 hover:-translate-y-1',\n      shadow: 'transition-shadow duration-300 hover:shadow-xl'\n    }\n  };\n\n  return {\n    button,\n    card,\n    animations\n  };\n};\n```\n\n</design_system_composable>\n\n### 5. Generate Component Files\n\n<thinking>\nCreate the actual files in the filesystem with proper naming and structure.\n</thinking>\n\n#### File Creation:\n\n<file_creation_steps>\n\n1. **Determine output path**:\n   - Default: `components/<ComponentName>.react`\n   - Custom: User-specified `--output` path\n\n2. **Generate component file**:\n   - Use template for component type\n   - Replace placeholders with actual names\n   - Include TypeScript types\n   - Include JSDoc comments\n   - Include usage examples in comments\n\n3. **Update or create design system composable** (if needed):\n   - Path: `composables/useDesignSystem.ts`\n   - Add new variants if applicable\n\n4. **Generate Storybook story** (optional, if Storybook detected):\n   - Path: `components/<ComponentName>.stories.ts`\n\n5. **Generate test file** (optional):\n   - Path: `components/<ComponentName>.spec.ts`\n\n</file_creation_steps>\n\n### 6. Validate Generated Component\n\n<thinking>\nRun validation to ensure generated component follows best practices.\n</thinking>\n\n#### Validation Checks:\n\n<validation_checklist>\n\n- [ ] Uses custom fonts (not Inter/Roboto)\n- [ ] Uses brand colors (not default purple)\n- [ ] Includes animations/transitions\n- [ ] Has hover states on interactive elements\n- [ ] Has focus states (focus-visible rings)\n- [ ] Respects reduced motion (motion-safe/motion-reduce)\n- [ ] Includes ARIA labels where needed\n- [ ] Uses shadcn/ui components (not reinventing)\n- [ ] Deep customization with `ui` prop\n- [ ] TypeScript props interface\n- [ ] JSDoc comments\n- [ ] Accessible (keyboard navigation, screen readers)\n- [ ] Responsive design\n- [ ] Dark mode support\n\n</validation_checklist>\n\n## Output Format\n\n<output_format>\n\n```\nâœ… Component Generated: <ComponentName>\n\nðŸ“ Files Created:\n- app/components/<ComponentName>.tsx (primary component)\n- composables/useDesignSystem.ts (updated/created)\n\nðŸŽ¨ Design Features:\nâœ… Custom typography (font-heading)\nâœ… Brand colors (brand-coral, brand-ocean)\nâœ… Rich animations (hover:scale-105, transitions)\nâœ… Deep shadcn/ui customization (ui prop)\nâœ… Accessibility features (ARIA, focus states)\nâœ… Reduced motion support (motion-safe)\nâœ… Responsive design\nâœ… Dark mode support\n\nðŸ“– Usage Example:\n\n```tsx\nimport { <ComponentName> } from '#components';\n\n// Your component logic\n\n  <<ComponentName>\n    prop1=\"value1\"\n    prop2=\"value2\"\n    onEvent=\"handleEvent\"\n  />\n```\n\nðŸ” Next Steps:\n1. Review generated component in `components/<ComponentName>.react`\n2. Customize props/styles as needed\n3. Test accessibility with keyboard navigation\n4. Test animations with reduced motion preference\n5. Run `/es-design-review` to validate design patterns\n```\n\n</output_format>\n\n## Success Criteria\n\nâœ… Component generated successfully when:\n- File created at correct path\n- Uses distinctive design patterns (not generic)\n- Includes all accessibility features\n- Includes rich animations\n- TypeScript types included\n- Usage examples in comments\n- Follows project conventions\n\n## Post-Generation Actions\n\nAfter generating component:\n1. **Review code**: Open generated file and review\n2. **Test component**: Add to a page and test interactions\n3. **Validate design**: Run `/es-design-review` if needed\n4. **Document**: Add to component library docs/Storybook\n\n## Notes\n\n- This command generates **starting templates** with best practices built-in\n- Components are **fully customizable** after generation\n- **Design system composable** ensures consistency across all generated components\n- Use **shadcn/ui MCP** (if available) to prevent prop hallucination\n- All generated components follow **WCAG 2.1 AA** accessibility standards\n- Generated components respect **user's reduced motion preference**"
              },
              {
                "name": "/es-deploy",
                "description": "Perform comprehensive pre-flight checks and deploy Cloudflare Workers safely using wrangler",
                "path": "plugins/edge-stack/commands/es-deploy.md",
                "frontmatter": {
                  "description": "Perform comprehensive pre-flight checks and deploy Cloudflare Workers safely using wrangler"
                },
                "content": "# Cloudflare Workers Deployment Command\n\n<command_purpose> Perform comprehensive pre-flight checks and deploy Cloudflare Workers safely using wrangler with multi-agent validation. </command_purpose>\n\n## Introduction\n\n<role>Cloudflare Deployment Specialist with expertise in Workers deployment, wrangler CLI, and production readiness validation</role>\n\nThis command performs thorough pre-deployment validation, runs all necessary checks, and safely deploys your Worker to Cloudflare's edge network.\n\n## Prerequisites\n\n<requirements>\n- Cloudflare account with Workers enabled\n- wrangler CLI installed (`npm install -g wrangler`)\n- Authenticated with Cloudflare (`wrangler login`)\n- Valid `wrangler.toml` configuration\n- Clean git working directory (recommended)\n</requirements>\n\n## Deployment Target\n\n<deployment_target> #$ARGUMENTS </deployment_target>\n\n**Supported targets**:\n- Empty (default) - Deploy to production\n- `--env staging` - Deploy to staging environment\n- `--env preview` - Deploy to preview environment\n- `--dry-run` - Perform all checks without deploying\n\n## Main Tasks\n\n### 1. Pre-Flight Checks (Critical - Must Pass)\n\n<critical_requirement> ALL pre-flight checks must pass before deployment. No exceptions. </critical_requirement>\n\n#### Phase 1: Configuration Validation\n\n<thinking>\nFirst, validate the wrangler.toml configuration and ensure all required settings are present.\n</thinking>\n\n**Checks to perform**:\n\n1. **Verify wrangler.toml exists**\n   ```bash\n   if [ ! -f wrangler.toml ]; then\n     echo \"âŒ CRITICAL: wrangler.toml not found\"\n     exit 1\n   fi\n   ```\n\n2. **Validate required fields**\n   - Task binding-context-analyzer(deployment target)\n     - Parse wrangler.toml\n     - Verify all bindings have valid IDs\n     - Check compatibility_date is 2025-09-15 or later (required for remote bindings GA)\n     - Verify all bindings have `remote = true` configured for development\n     - Validate name, main, and account_id fields\n\n3. **Check authentication**\n   ```bash\n   wrangler whoami\n   # Verify logged in to correct account\n   ```\n\n#### Phase 2: Code Quality Checks\n\n**SKILL-based Continuous Validation** (Already Active During Development):\n- **workers-runtime-validator SKILL**: Runtime compatibility validation\n- **cloudflare-security-checker SKILL**: Security pattern validation\n- **workers-binding-validator SKILL**: Binding configuration validation\n- **edge-performance-optimizer SKILL**: Performance optimization guidance\n- **kv-optimization-advisor SKILL**: KV storage optimization\n- **durable-objects-pattern-checker SKILL**: DO best practices validation\n- **cors-configuration-validator SKILL**: CORS setup validation\n\n**Agent-based Comprehensive Analysis** (Run for deployment validation):\n\n**Critical Checks (Must Pass)**:\n\n1. Task workers-runtime-guardian(current code)\n   - Deep runtime compatibility analysis\n   - Complex Node.js API migration patterns\n   - Package dependency analysis\n   - **Status**: Must be CRITICAL-free (P1 issues block deployment)\n   - **Note**: Complements workers-runtime-validator SKILL\n\n2. Task cloudflare-security-sentinel(current code)\n   - Comprehensive security audit\n   - Advanced threat analysis\n   - Security architecture review\n   - **Status**: Must be CRITICAL-free (P1 security issues block deployment)\n   - **Note**: Complements cloudflare-security-checker SKILL\n\n3. Task binding-context-analyzer(current code)\n   - Complex binding configuration analysis\n   - Cross-service binding validation\n   - Advanced binding patterns\n   - **Status**: Must have no mismatches\n   - **Note**: Complements workers-binding-validator SKILL\n\n**Important Checks (Warnings)**:\n\n4. Task edge-performance-oracle(current code)\n   - Comprehensive performance analysis\n   - Global latency optimization\n   - Advanced bundle optimization\n   - **Status**: P2 issues generate warnings\n   - **Note**: Complements edge-performance-optimizer SKILL\n\n5. Task cloudflare-pattern-specialist(current code)\n   - Advanced Cloudflare architecture patterns\n   - Complex anti-pattern detection\n   - Multi-service optimization\n   - **Status**: P2 issues generate warnings\n   - **Note**: Complements all storage SKILLs\n\n#### Phase 3: Build & Test\n\n<thinking>\nBuild the Worker and run tests to ensure everything works before deployment.\n</thinking>\n\n1. **Clean previous builds**\n   ```bash\n   rm -rf dist/ .wrangler/\n   ```\n\n2. **Install dependencies**\n   ```bash\n   npm ci  # Clean install from lock file\n   ```\n\n3. **Type checking**\n   ```bash\n   npm run typecheck || tsc --noEmit\n   ```\n\n4. **Linting**\n   ```bash\n   npm run lint\n   ```\n\n5. **Run tests**\n   ```bash\n   npm test\n   ```\n\n6. **Build Worker**\n   ```bash\n   wrangler deploy --dry-run --outdir=./dist\n   ```\n\n7. **Analyze bundle size**\n   ```bash\n   du -h ./dist/*.js\n   # Warn if > 100KB, error if > 500KB\n   ```\n\n#### Phase 4: Local Testing (Optional but Recommended)\n\n<thinking>\nTest the Worker locally with wrangler dev to catch runtime issues.\n</thinking>\n\nAsk user: \"Run local testing with wrangler dev? (recommended, y/n)\"\n\nIf yes:\n1. Start wrangler dev in background\n2. Wait 5 seconds for startup\n3. Test basic endpoints:\n   ```bash\n   curl http://localhost:8787/\n   # Verify 200 response\n   ```\n4. Stop wrangler dev\n\n### 2. Pre-Deployment Summary\n\n<deliverable>\nPresent comprehensive pre-deployment report to user\n</deliverable>\n\n```markdown\n## Deployment Pre-Flight Summary\n\n**Target Environment**: [production/staging/preview]\n**Worker Name**: [from wrangler.toml]\n**Account**: [from wrangler whoami]\n\n### âœ… Configuration\n- wrangler.toml: Valid\n- Bindings: [X] configured\n  - KV: [list]\n  - R2: [list]\n  - D1: [list]\n  - DO: [list]\n- Compatibility Date: [date] (âœ… recent / âš ï¸ outdated)\n\n### âœ… Code Quality\n- Runtime Compatibility: [PASS/FAIL]\n  - Issues: [X] Critical, [Y] Important\n- Security: [PASS/FAIL]\n  - Issues: [X] Critical, [Y] Important\n- Binding Validation: [PASS/FAIL]\n  - Mismatches: [count]\n\n### âœ… Build\n- TypeScript: [PASS/FAIL]\n- Linting: [PASS/FAIL]\n- Tests: [PASS/FAIL] ([X] passed, [Y] failed)\n- Bundle Size: [size] (âœ… < 100KB / âš ï¸ > 100KB / âŒ > 500KB)\n\n### ðŸ” Performance Analysis\n- Cold Start (estimated): [X]ms\n- Heavy Dependencies: [list if any]\n- Warnings: [count]\n\n### âš ï¸ Blocking Issues (Must Fix)\n[List any P1 issues that prevent deployment]\n\n### âš ï¸ Warnings (Recommended to Fix)\n[List any P2 issues]\n\n---\n**Decision**: [READY TO DEPLOY / ISSUES MUST BE FIXED]\n```\n\n### 3. User Confirmation\n\n<critical_requirement> Always require explicit user confirmation before deploying. </critical_requirement>\n\n**If blocking issues exist**:\n```\nâŒ Cannot deploy - [X] critical issues must be fixed:\n1. [Issue description]\n2. [Issue description]\n\nRun /triage to create todos for these issues.\n```\n\n**If only warnings exist**:\n```\nâš ï¸ Ready to deploy with [X] warnings:\n1. [Warning description]\n2. [Warning description]\n\nDeploy anyway? (yes/no/show-details)\n```\n\n**If all checks pass**:\n```\nâœ… All checks passed. Ready to deploy.\n\nDeploy to [environment]? (yes/no)\n```\n\n### 4. Deployment Execution\n\n<thinking>\nExecute the actual deployment with appropriate wrangler commands.\n</thinking>\n\n**If user confirms YES**:\n\n1. **Create git tag (if production)**\n   ```bash\n   if [ \"$environment\" = \"production\" ]; then\n     timestamp=$(date +%Y%m%d-%H%M%S)\n     git tag -a \"deploy-$timestamp\" -m \"Production deployment $timestamp\"\n   fi\n   ```\n\n2. **Deploy with wrangler**\n   ```bash\n   # For default/production\n   wrangler deploy\n\n   # For specific environment\n   wrangler deploy --env $environment\n   ```\n\n3. **Capture deployment output**\n   - Worker URL\n   - Deployment ID\n   - Custom domain (if configured)\n\n4. **Verify deployment**\n   ```bash\n   # Test deployed Worker\n   curl -I $worker_url\n   # Verify 200 response\n   ```\n\n### 5. Post-Deployment Validation\n\n<thinking>\nVerify the deployment was successful and the Worker is responding correctly.\n</thinking>\n\nRun quick smoke tests:\n\n1. **Health check**\n   ```bash\n   curl $worker_url/health || curl $worker_url/\n   # Expect 200 status\n   ```\n\n2. **Verify bindings accessible** (if applicable)\n   - Test endpoint that uses KV/R2/D1/DO\n   - Verify no binding errors\n\n3. **Check Cloudflare dashboard**\n   ```bash\n   wrangler tail --format json | head -n 5\n   # Show first 5 requests/logs\n   ```\n\n### 6. Deployment Report\n\n<deliverable>\nFinal deployment summary with all details\n</deliverable>\n\n```markdown\n## ðŸš€ Deployment Complete\n\n**Environment**: [production/staging/preview]\n**Deployed At**: [timestamp]\n**Worker URL**: [url]\n**Custom Domain**: [domain] (if configured)\n\n### Deployment Details\n- Worker Name: [name]\n- Bundle Size: [size]\n- Deployment ID: [id]\n- Git Tag: [tag] (if production)\n\n### Verification\n- Health Check: [âœ… PASS / âŒ FAIL]\n- Response Time: [X]ms\n- Status Code: [code]\n\n### Next Steps\n1. Monitor logs: `wrangler tail`\n2. View analytics: https://dash.cloudflare.com\n3. Test endpoints: [list key endpoints]\n\n### Rollback (if needed)\n```bash\n# View previous deployments\nwrangler deployments list\n\n# Rollback to previous version\nwrangler rollback [deployment-id]\n```\n\n---\n**Status**: âœ… Deployment Successful\n```\n\n## Emergency Rollback\n\nIf deployment fails or issues are detected:\n\n1. **Immediate rollback**\n   ```bash\n   wrangler deployments list\n   wrangler rollback [previous-deployment-id]\n   ```\n\n2. **Notify user**\n   ```\n   âŒ Deployment rolled back to previous version\n   Reason: [failure reason]\n\n   Investigate issues:\n   - Check logs: wrangler tail\n   - Review errors: [error details]\n   ```\n\n## Deployment Checklist\n\n<checklist>\nBefore confirming deployment, verify:\n\n- [ ] wrangler.toml is valid and complete\n- [ ] All bindings have valid IDs\n- [ ] No Node.js APIs in code\n- [ ] No hardcoded secrets\n- [ ] TypeScript compiles without errors\n- [ ] Linting passes\n- [ ] All tests pass\n- [ ] Bundle size is acceptable (< 500KB)\n- [ ] No CRITICAL (P1) issues from agents\n- [ ] User has confirmed deployment\n- [ ] Correct environment selected\n- [ ] Git working directory is clean (if production)\n</checklist>\n\n## Environment-Specific Notes\n\n### Production Deployment\n- Requires explicit confirmation\n- Creates git tag for tracking\n- Runs full validation suite\n- Monitors initial requests\n\n### Staging Deployment\n- Slightly relaxed validation (P2 warnings allowed)\n- No git tag created\n- Faster deployment process\n\n### Preview Deployment\n- Minimal validation\n- Quick iteration for testing\n- Temporary URL\n\n## Troubleshooting\n\n### Common Issues\n\n**Issue**: \"Error: Could not find binding {name}\"\n**Solution**: Run `Task binding-context-analyzer` to verify wrangler.toml\n\n**Issue**: \"Error: Bundle size too large\"\n**Solution**: Run `Task edge-performance-oracle` for optimization recommendations\n\n**Issue**: \"Error: Authentication failed\"\n**Solution**: Run `wrangler login` to re-authenticate\n\n**Issue**: \"Error: Worker exceeded CPU limit\"\n**Solution**: Check for blocking operations, infinite loops, or heavy computation\n\n## Success Criteria\n\nâœ… **Deployment considered successful when**:\n- All pre-flight checks pass (no P1 issues)\n- Worker deploys without errors\n- Health check returns 200\n- No immediate runtime errors in logs\n- Rollback capability confirmed available\n\n## Notes\n\n- Always test in staging before production\n- Monitor logs for first 5-10 minutes after deployment\n- Keep rollback procedure ready\n- Document any configuration changes\n- Update team on deployment status\n\n---\n\n**Remember**: It's better to fail pre-flight checks than to deploy broken code. Every check exists to prevent production issues."
              },
              {
                "name": "/es-design-review",
                "description": "Comprehensive frontend design review to prevent generic aesthetics and ensure distinctive, accessible, engaging interfaces using shadcn/ui and Tailwind CSS",
                "path": "plugins/edge-stack/commands/es-design-review.md",
                "frontmatter": {
                  "description": "Comprehensive frontend design review to prevent generic aesthetics and ensure distinctive, accessible, engaging interfaces using shadcn/ui and Tailwind CSS"
                },
                "content": "# Design Review Command\n\n<command_purpose> Perform comprehensive frontend design reviews focusing on typography, colors, animations, component customization, and accessibility. Prevents \"distributional convergence\" (Inter fonts, purple gradients, minimal animations) and guides toward distinctive, branded interfaces. </command_purpose>\n\n## Introduction\n\n<role>Senior Frontend Design Architect with expertise in shadcn/ui, Tailwind CSS, accessibility (WCAG 2.1 AA), and distinctive design patterns</role>\n\n**Design Philosophy** (from Claude Skills Blog):\n> \"Think about frontend design the way a frontend engineer would. The more you can map aesthetic improvements to implementable frontend code, the better Claude can execute.\"\n\n**Core Problem**: LLMs default to generic patterns (Inter fonts, purple gradients, minimal animations) due to distributional convergence. This command identifies and fixes these patterns.\n\n## Prerequisites\n\n<requirements>\n- Tanstack Start project with Vue 3 components\n- shadcn/ui component library installed\n- Tailwind 4 CSS configured\n- Vue files (`.react`) in `components/`, `pages/`, `layouts/`\n- (Optional) shadcn/ui MCP server for accurate component guidance\n</requirements>\n\n## Security Considerations\n\nâš ï¸ **Security Note**: When reviewing external design inspiration sites or scraping design patterns from untrusted sources using browser automation, be aware that malicious websites could attempt prompt injection attacks. Exercise caution when:\n- Navigating to external design inspiration sites for pattern analysis\n- Scraping design elements from untrusted third-party websites\n- Extracting styles, colors, or typography from external sources\n- Using browser automation to analyze competitor designs\n\n**Best Practices**:\n- Manually review design inspiration from trusted sources (Dribbble, Behance, official component libraries)\n- Avoid automated scraping of untrusted websites for design patterns\n- Reference established design systems (Material, shadcn/ui docs) instead of arbitrary sites\n- When analyzing external sites, review extracted suggestions carefully before implementing\n\nThis command focuses on analyzing your *own* codebase for design improvements. If you extend it to analyze external sites, treat all extracted content as untrusted.\n\nFor more information, see [Anthropic's research on prompt injection defenses](https://www.anthropic.com/research/prompt-injection-defenses).\n\n## Main Tasks\n\n### 1. Project Analysis\n\n<thinking>\nFirst, I need to understand the project structure and identify all frontend files.\nThis enables targeted design review of components, pages, and configuration.\n</thinking>\n\n#### Immediate Actions:\n\n<task_list>\n\n- [ ] Scan for Vue components in `components/`, `pages/`, `layouts/`, `app.react`\n- [ ] Check `tailwind.config.ts` or `tailwind.config.js` for custom theme configuration\n- [ ] Check `app.config.ts` for shadcn/ui configuration\n- [ ] Check `app.config.ts` for global UI customization\n- [ ] Identify which components use shadcn/ui (`Button`, `Card`, etc.)\n- [ ] Count total Vue files to determine review scope\n\n</task_list>\n\n#### Output Summary:\n\n<summary_format>\nðŸ“Š **Project Scope**:\n- X Vue components found\n- Y shadcn/ui components detected\n- Tailwind config: Found/Not Found\n- shadcn/ui config: Found/Not Found\n- Review target: Components + Configuration\n</summary_format>\n\n### 2. Multi-Phase Design Review\n\n<parallel_tasks>\n\nRun design-focused analysis in 3 phases. Focus on preventing generic patterns and ensuring accessible, distinctive design.\n\n**Phase 1: Autonomous Skills Validation (Parallel)**\n\nThese skills run autonomously to catch generic patterns:\n\n1. âœ… **shadcn-ui-design-validator** (SKILL)\n   - Detects Inter/Roboto fonts\n   - Detects purple gradients\n   - Detects missing animations\n   - Validates typography hierarchy\n   - Checks color contrast\n\n2. âœ… **component-aesthetic-checker** (SKILL)\n   - Validates component customization depth\n   - Checks for default props only\n   - Ensures consistent design system\n   - Validates spacing patterns\n   - Checks loading states\n\n3. âœ… **animation-interaction-validator** (SKILL)\n   - Ensures hover states on interactive elements\n   - Validates loading states on async actions\n   - Checks for smooth transitions\n   - Validates focus states\n   - Ensures micro-interactions\n\n**Output**: List of generic patterns detected across all components\n\n**Phase 2: Deep Agent Analysis (Parallel)**\n\nLaunch specialized agents for comprehensive review:\n\n4. Task frontend-design-specialist(all Vue files, Tailwind config)\n   - Identify generic patterns (fonts, colors, animations)\n   - Map aesthetic improvements to code\n   - Provide specific Tailwind/shadcn/ui recommendations\n   - Prioritize by impact (P1/P2/P3)\n   - Generate implementable code examples\n\n5. Task shadcn-ui-architect(all Vue files with shadcn/ui components)\n   - Validate component selection and usage\n   - Check prop usage vs available (via MCP if available)\n   - Validate `ui` prop customization depth\n   - Ensure consistent patterns across components\n   - Suggest deep customization strategies\n\n6. Task accessibility-guardian(all Vue files)\n   - Validate WCAG 2.1 AA compliance\n   - Check color contrast ratios\n   - Validate keyboard navigation\n   - Check screen reader support\n   - Validate form accessibility\n   - Ensure animations respect reduced motion\n\n**Phase 3: Configuration & Theme Review (Sequential)**\n\n7. Review Tailwind Configuration\n   - Check `tailwind.config.ts` for custom fonts (not Inter/Roboto)\n   - Check for custom color palette (not default purple)\n   - Check for custom animation presets\n   - Validate extended spacing/sizing\n   - Check for design tokens\n\n8. Review shadcn/ui Configuration\n   - Check `app.config.ts` for global UI customization\n   - Check `app.config.ts` for shadcn/ui theme settings\n   - Validate consistent design system approach\n\n</parallel_tasks>\n\n### 3. Findings Synthesis and Prioritization\n\n<thinking>\nAfter all agents complete, I need to consolidate findings, remove duplicates,\nand prioritize by impact on brand distinctiveness and user experience.\n</thinking>\n\n#### Consolidation Process:\n\n<consolidation_steps>\n\n1. **Collect all findings** from skills and agents\n2. **Remove duplicates** (same issue reported by multiple sources)\n3. **Categorize by type**:\n   - Typography (fonts, hierarchy, sizing)\n   - Colors (palette, contrast, gradients)\n   - Animations (transitions, micro-interactions, hover states)\n   - Components (customization depth, consistency)\n   - Accessibility (contrast, keyboard, screen readers)\n   - Configuration (theme, design tokens)\n\n4. **Prioritize by impact**:\n   - **P1 - Critical**: Generic patterns that make site indistinguishable\n     - Inter/Roboto fonts\n     - Purple gradients\n     - Default component props\n     - Missing animations\n     - Accessibility violations\n   - **P2 - Important**: Missed opportunities for distinctiveness\n     - Limited color palette\n     - Inconsistent component patterns\n     - Missing micro-interactions\n     - Insufficient customization depth\n   - **P3 - Polish**: Enhancements for excellence\n     - Advanced animations\n     - Dark mode refinements\n     - Enhanced accessibility\n\n5. **Generate implementation plan** with time estimates\n\n</consolidation_steps>\n\n#### Output Format:\n\n<findings_format>\n\n# ðŸŽ¨ Frontend Design Review Report\n\n## Executive Summary\n\n**Scope**: X components reviewed, Y configuration files analyzed\n\n**Findings**:\n- **P1 (Critical)**: X issues - Must fix for brand distinctiveness\n- **P2 (Important)**: Y issues - Should fix for enhanced UX\n- **P3 (Polish)**: Z opportunities - Nice to have improvements\n\n**Generic Patterns Detected**:\n- âŒ Inter font used in X components\n- âŒ Purple gradient in Y components\n- âŒ Default props in Z shadcn/ui components\n- âŒ Missing animations on W interactive elements\n- âŒ A accessibility violations (WCAG 2.1 AA)\n\n**Distinctiveness Score**: XX/100\n- Typography: XX/25 (Custom fonts, hierarchy, sizing)\n- Colors: XX/25 (Brand palette, contrast, distinctive gradients)\n- Animations: XX/25 (Transitions, micro-interactions, engagement)\n- Components: XX/25 (Customization depth, consistency)\n\n---\n\n## Critical Issues (P1)\n\n### 1. Generic Typography: Inter Font Detected\n\n**Severity**: P1 - High Impact\n**Files Affected**: 15 components\n**Impact**: Indistinguishable from 80%+ of modern websites\n\n**Finding**: Using default Inter font system-wide\n\n**Current State**:\n```tsx\n<!-- app/components/Hero.tsx:12 -->\n<h1 class=\"text-4xl font-sans\">Welcome</h1>\n\n<!-- tailwind.config.ts -->\nfontFamily: {\n  sans: ['Inter', 'system-ui']  // âŒ Generic\n}\n```\n\n**Recommendation**:\n```tsx\n<!-- Updated component -->\n<h1 class=\"text-4xl font-heading tracking-tight\">Welcome</h1>\n\n<!-- tailwind.config.ts -->\nfontFamily: {\n  sans: ['Space Grotesk', 'system-ui', 'sans-serif'],      // Body\n  heading: ['Archivo Black', 'system-ui', 'sans-serif'],   // Headings\n  mono: ['JetBrains Mono', 'monospace']                     // Code\n}\n```\n\n**Implementation**:\n1. Update `tailwind.config.ts` with custom fonts (5 min)\n2. Add font-heading class to all headings (10 min)\n3. Verify font loading in `app.config.ts` (5 min)\n**Total**: ~20 minutes\n\n---\n\n### 2. Purple Gradient Hero (Overused Pattern)\n\n**Severity**: P1 - High Impact\n**Files Affected**: `app/components/Hero.tsx:8`\n**Impact**: \"AI-generated\" aesthetic, lacks brand identity\n\n**Finding**: Hero section uses purple-500 to purple-600 gradient (appears in 60%+ of AI-generated sites)\n\n**Current State**:\n```tsx\n<div class=\"bg-gradient-to-r from-purple-500 to-purple-600\">\n  <h1 class=\"text-white\">Hero Title</h1>\n</div>\n```\n\n**Recommendation**:\n```tsx\n<div class=\"relative overflow-hidden\">\n  <!-- Multi-layer atmospheric background -->\n  <div class=\"absolute inset-0 bg-gradient-to-br from-brand-coral via-brand-ocean to-brand-sunset\" />\n\n  <!-- Animated gradient orbs -->\n  <div class=\"absolute top-0 left-0 w-96 h-96 bg-brand-coral/30 rounded-full blur-3xl animate-pulse\" />\n  <div class=\"absolute bottom-0 right-0 w-96 h-96 bg-brand-ocean/30 rounded-full blur-3xl animate-pulse\" style=\"animation-delay: 1s;\" />\n\n  <!-- Content -->\n  <div class=\"relative z-10 py-24\">\n    <h1 class=\"text-white font-heading text-6xl tracking-tight\">\n      Hero Title\n    </h1>\n  </div>\n</div>\n\n<!-- tailwind.config.ts: Add custom colors -->\ncolors: {\n  brand: {\n    coral: '#FF6B6B',\n    ocean: '#4ECDC4',\n    sunset: '#FFE66D'\n  }\n}\n```\n\n**Implementation**:\n1. Add brand colors to `tailwind.config.ts` (5 min)\n2. Update Hero component with atmospheric background (15 min)\n3. Test animations and responsiveness (5 min)\n**Total**: ~25 minutes\n\n---\n\n### 3. Button Components with Default Props (23 instances)\n\n**Severity**: P1 - High Impact\n**Files Affected**: 8 components\n**Impact**: Generic appearance, no brand identity\n\n**Finding**: 23 Button instances using default props only (no customization)\n\n**Current State**:\n```tsx\n<!-- app/components/CallToAction.tsx:34 -->\n<Button onClick={handleClick\">Click me</Button>\n```\n\n**Recommendation**:\n```tsx\n<Button\n  color=\"primary\"\n  size=\"lg\"\n  :ui=\"{\n    font: 'font-heading tracking-wide',\n    rounded: 'rounded-full',\n    padding: { lg: 'px-8 py-4' },\n    shadow: 'shadow-lg hover:shadow-xl'\n  }\"\n  class=\"\n    transition-all duration-300 ease-out\n    hover:scale-105 hover:-rotate-1\n    active:scale-95 active:rotate-0\n    focus:outline-none\n    focus-visible:ring-2 focus-visible:ring-primary-500 focus-visible:ring-offset-2\n  \"\n  onClick={handleClick\"\n>\n  <span class=\"inline-flex items-center gap-2\">\n    Click me\n    <Icon\n      name=\"i-heroicons-sparkles\"\n      class=\"transition-transform duration-300 group-hover:rotate-12\"\n    />\n  </span>\n</Button>\n```\n\n**Better Approach: Create Reusable Variants**:\n```tsx\n<!-- composables/useDesignSystem.ts -->\nexport const useDesignSystem = () => {\n  const button = {\n    primary: {\n      color: 'primary',\n      size: 'lg',\n      ui: {\n        font: 'font-heading tracking-wide',\n        rounded: 'rounded-full',\n        padding: { lg: 'px-8 py-4' }\n      },\n      class: 'transition-all duration-300 hover:scale-105 hover:shadow-xl'\n    }\n  };\n\n  return { button };\n};\n\n<!-- Usage in components -->\nconst { button } = useDesignSystem();\n\n  <Button v-bind=\"button.primary\" onClick={handleClick\">\n    Click me\n  </Button>\n```\n\n**Implementation**:\n1. Create `composables/useDesignSystem.ts` with button variants (15 min)\n2. Update all 23 button instances to use variants (30 min)\n3. Test all button interactions (10 min)\n**Total**: ~55 minutes\n\n---\n\n## Important Issues (P2)\n\n### 4. Missing Hover Animations (32 interactive elements)\n\n**Severity**: P2 - Medium Impact\n**Impact**: Flat UI, reduced engagement\n\n**Finding**: 32 interactive elements (buttons, links, cards) without hover animations\n\n**Recommendation**: Add transition utilities to all interactive elements\n```tsx\n<!-- Before -->\n<Card>Content</Card>\n\n<!-- After -->\n<Card\n  :ui=\"{ shadow: 'shadow-lg hover:shadow-2xl' }\"\n  class=\"transition-all duration-300 hover:-translate-y-1\"\n>\n  Content\n</Card>\n```\n\n[Continue with remaining P2 issues...]\n\n---\n\n## Accessibility Violations (WCAG 2.1 AA)\n\n### 5. Insufficient Color Contrast (4 instances)\n\n**Severity**: P1 - Blocker\n**Standard**: WCAG 1.4.3 (4.5:1 for normal text, 3:1 for large text)\n\n**Violations**:\n1. `app/components/Footer.tsx:23` - Gray-400 on white (2.9:1) âŒ\n2. `app/routes/about.tsx:45` - Brand-coral on white (3.2:1) âŒ\n3. `app/components/Badge.tsx:12` - Yellow-300 on white (1.8:1) âŒ\n4. `layouts/default.tsx:67` - Blue-400 on gray-50 (2.4:1) âŒ\n\n**Fixes**: [Specific contrast-compliant color recommendations]\n\n---\n\n## Polish Opportunities (P3)\n\n[List P3 improvements...]\n\n---\n\n## Implementation Roadmap\n\n### Priority 1: Foundation (1-2 hours)\n1. âœ… Update `tailwind.config.ts` with custom fonts and colors\n2. âœ… Create `composables/useDesignSystem.ts` with reusable variants\n3. âœ… Fix critical accessibility violations (contrast)\n\n### Priority 2: Component Updates (2-3 hours)\n4. âœ… Update all Button instances with design system variants\n5. âœ… Add hover animations to interactive elements\n6. âœ… Customize Card components with distinctive styling\n\n### Priority 3: Polish (1-2 hours)\n7. âœ… Enhance micro-interactions\n8. âœ… Add staggered animations\n9. âœ… Implement dark mode refinements\n\n**Total Time Estimate**: 4-7 hours for complete implementation\n\n---\n\n## Next Steps\n\n1. **Review Findings**: Team reviews this report\n2. **Prioritize Work**: Decide which issues to address\n3. **Use `/triage`**: Create todos for approved findings\n4. **Implement Changes**: Follow code examples provided\n5. **Re-run Review**: Verify improvements with `/es-design-review`\n\n## Distinctiveness Score Projection\n\n**Before**: 35/100 (Generic, AI-generated aesthetic)\n**After P1 Fixes**: 75/100 (Distinctive, branded)\n**After P1+P2 Fixes**: 90/100 (Excellent, highly polished)\n**After P1+P2+P3**: 95/100 (Outstanding, delightful)\n\n</findings_format>\n\n### 4. Create Triage-Ready Todos (Optional)\n\n<thinking>\nIf user wants to proceed with fixes, use /triage command to create actionable todos.\nEach todo should be specific, implementable, and include code examples.\n</thinking>\n\n#### Generate Todos:\n\n<todo_format>\n\nFor each P1 issue, create a todo in `.claude/todos/` with format:\n- `001-pending-p1-update-typography.md`\n- `002-pending-p1-fix-hero-gradient.md`\n- `003-pending-p1-customize-buttons.md`\n- etc.\n\nEach todo includes:\n- **Title**: Clear, actionable\n- **Severity**: P1/P2/P3\n- **Files**: Specific file paths\n- **Current State**: Code before\n- **Target State**: Code after\n- **Implementation Steps**: Numbered checklist\n- **Time Estimate**: Minutes/hours\n\n</todo_format>\n\nAsk user: \"Would you like me to create todos for these findings? You can then use `/triage` to work through them systematically.\"\n\n## Success Criteria\n\nâœ… Design review complete when:\n- All Vue components analyzed\n- All generic patterns identified\n- All accessibility violations found\n- Findings categorized and prioritized\n- Implementation plan provided with time estimates\n- Code examples are complete and implementable\n\nâœ… Project ready for distinctive brand identity when:\n- 0% Inter/Roboto font usage\n- 0% purple gradient usage\n- 100% of shadcn/ui components deeply customized\n- 100% of interactive elements have animations\n- 100% WCAG 2.1 AA compliance\n- Distinctiveness score â‰¥ 85/100\n\n## Post-Review Actions\n\nAfter implementing fixes:\n1. **Re-run review**: `/es-design-review` to verify improvements\n2. **Validate code**: `/validate` to ensure no build/lint errors\n3. **Test manually**: Check hover states, animations, keyboard navigation\n4. **Deploy preview**: Test on actual Cloudflare Workers environment\n\n## Resources\n\n- Claude Skills Blog: Improving Frontend Design Through Skills\n- shadcn/ui Documentation: https://ui.shadcn.com\n- Tailwind 4 Documentation: https://tailwindcss.com/docs/v4-beta\n- WCAG 2.1 Guidelines: https://www.w3.org/WAI/WCAG21/quickref/\n- WebAIM Contrast Checker: https://webaim.org/resources/contrastchecker/\n\n## Notes\n\n- This command focuses on **frontend design**, not Cloudflare Workers runtime\n- Use `/review` for comprehensive code review (includes runtime, security, performance)\n- Use `/es-component` to scaffold new components with best practices\n- Use `/es-theme` to generate custom design themes"
              },
              {
                "name": "/es-email-setup",
                "description": "Interactive Resend email setup wizard. Configures transactional and marketing emails, React Email templates, and environment variables for Cloudflare Workers.",
                "path": "plugins/edge-stack/commands/es-email-setup.md",
                "frontmatter": {
                  "description": "Interactive Resend email setup wizard. Configures transactional and marketing emails, React Email templates, and environment variables for Cloudflare Workers."
                },
                "content": "# Email Setup Command\n\n<command_purpose> Guide developers through complete Resend email integration with automated code generation, React Email templates, domain configuration, and MCP-driven email setup. </command_purpose>\n\n## Introduction\n\n<role>Senior Email Integration Engineer with expertise in Resend, React Email, and Cloudflare Workers email delivery</role>\n\n**This command will**:\n- Detect project type (Tanstack Start or API-only Worker)\n- Install Resend SDK and React Email dependencies\n- Generate React Email template components\n- Create email server functions for Tanstack Start\n- Configure transactional email handlers (verification, password reset)\n- Generate marketing email examples (newsletter)\n- Set up domain verification configuration\n- Configure environment variables and secrets\n- Add error handling and retry logic with D1\n\n## Prerequisites\n\n<requirements>\n- Cloudflare Workers project (Tanstack Start or Hono)\n- Resend account: https://resend.com (free tier available)\n- API key from Resend dashboard\n- D1 database configured for email retry tracking (optional)\n</requirements>\n\n## Main Tasks\n\n### 1. Detect Project Type & Email Requirements\n\n**Ask User**:\n```markdown\nðŸ“§ Email Setup Wizard\n\n1. What project type are you using?\n   a) Tanstack Start (full-stack)\n   b) Standalone Worker (Hono/plain TS)\n\n2. What email flows do you need?\n   a) Transactional only (verification, password reset)\n   b) Marketing only (newsletters, announcements)\n   c) Both transactional and marketing\n   d) Custom email patterns\n```\n\n**Decision Logic**:\n```\nIf Tanstack Start + Any type:\n  â†’ Use createServerFn for email handlers\n  â†’ Generate React Email templates\n  â†’ Use @react-email/components\n\nIf Standalone Worker:\n  â†’ Use Worker handlers\n  â†’ Generate React Email templates\n  â†’ Use @react-email/components\n```\n\n### 2. Install Dependencies\n\n**For Tanstack Start**:\n```bash\nnpm install resend @react-email/components @react-email/render\nnpm install -D @types/react @types/react-dom\n```\n\n**For Standalone Worker**:\n```bash\nnpm install resend @react-email/components @react-email/render\nnpm install -D @types/react @types/react-dom\n```\n\n**React Email Setup**:\n```bash\n# Add React Email CLI (optional, for preview server)\nnpm install -D react-email\n```\n\n### 3. Generate React Email Templates\n\n#### Template: Email Verification\n\n**Generate File**: `emails/verify-email.tsx`\n\n```tsx\nimport {\n  Body,\n  Button,\n  Container,\n  Head,\n  Heading,\n  Html,\n  Link,\n  Preview,\n  Section,\n  Text,\n} from '@react-email/components';\n\ninterface VerifyEmailProps {\n  verificationUrl: string;\n  email: string;\n}\n\nconst baseUrl = process.env.RESEND_BASE_URL || 'https://example.com';\n\nexport function VerifyEmail({ verificationUrl, email }: VerifyEmailProps) {\n  return (\n    <Html>\n      <Head />\n      <Preview>Verify your email address</Preview>\n      <Body style={main}>\n        <Container style={container}>\n          <Section style={box}>\n            <Heading style={heading}>Verify your email</Heading>\n            <Text style={paragraph}>\n              Thanks for signing up! Please verify your email address to complete your registration.\n            </Text>\n            <Button style={button} href={verificationUrl}>\n              Verify Email\n            </Button>\n            <Text style={paragraph}>\n              Or copy and paste this link:\n            </Text>\n            <Link style={link} href={verificationUrl}>\n              {verificationUrl}\n            </Link>\n            <Text style={paragraph}>\n              This link expires in 24 hours. If you didn't create this account, you can safely ignore this email.\n            </Text>\n          </Section>\n          <Text style={footer}>\n            Â© 2025 Your Company. All rights reserved.\n          </Text>\n        </Container>\n      </Body>\n    </Html>\n  );\n}\n\n// Styles\nconst main = {\n  backgroundColor: '#f6f9fc',\n  fontFamily:\n    '-apple-system,BlinkMacSystemFont,\"Segoe UI\",\"Roboto\",\"Oxygen-Sans\",Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif',\n};\n\nconst container = {\n  backgroundColor: '#ffffff',\n  margin: '0 auto',\n  padding: '20px 0 48px',\n  marginBottom: '64px',\n};\n\nconst box = {\n  padding: '0 48px',\n};\n\nconst heading = {\n  color: '#1f2937',\n  fontSize: '24px',\n  fontWeight: 'bold',\n  margin: '16px 0',\n};\n\nconst paragraph = {\n  color: '#525252',\n  fontSize: '16px',\n  lineHeight: '26px',\n  margin: '16px 0',\n};\n\nconst button = {\n  backgroundColor: '#000000',\n  borderRadius: '4px',\n  color: '#fff',\n  fontSize: '16px',\n  fontWeight: 'bold',\n  textDecoration: 'none',\n  textAlign: 'center' as const,\n  display: 'block',\n  padding: '12px 20px',\n  margin: '16px 0',\n};\n\nconst link = {\n  color: '#0000ee',\n  textDecoration: 'underline',\n};\n\nconst footer = {\n  color: '#8898aa',\n  fontSize: '12px',\n  margin: '16px 0',\n};\n```\n\n#### Template: Password Reset\n\n**Generate File**: `emails/password-reset.tsx`\n\n```tsx\nimport {\n  Body,\n  Button,\n  Container,\n  Head,\n  Heading,\n  Html,\n  Link,\n  Preview,\n  Section,\n  Text,\n} from '@react-email/components';\n\ninterface PasswordResetProps {\n  resetUrl: string;\n  email: string;\n}\n\nexport function PasswordReset({ resetUrl, email }: PasswordResetProps) {\n  return (\n    <Html>\n      <Head />\n      <Preview>Reset your password</Preview>\n      <Body style={main}>\n        <Container style={container}>\n          <Section style={box}>\n            <Heading style={heading}>Reset your password</Heading>\n            <Text style={paragraph}>\n              We received a request to reset your password. Click the button below to create a new password.\n            </Text>\n            <Button style={button} href={resetUrl}>\n              Reset Password\n            </Button>\n            <Text style={paragraph}>\n              Or copy and paste this link:\n            </Text>\n            <Link style={link} href={resetUrl}>\n              {resetUrl}\n            </Link>\n            <Text style={paragraph}>\n              This link expires in 1 hour. If you didn't request a password reset, you can safely ignore this email.\n            </Text>\n            <Text style={hint}>\n              For security, never share this link with anyone.\n            </Text>\n          </Section>\n          <Text style={footer}>\n            Â© 2025 Your Company. All rights reserved.\n          </Text>\n        </Container>\n      </Body>\n    </Html>\n  );\n}\n\n// Styles (same as VerifyEmail)\nconst main = {\n  backgroundColor: '#f6f9fc',\n  fontFamily:\n    '-apple-system,BlinkMacSystemFont,\"Segoe UI\",\"Roboto\",\"Oxygen-Sans\",Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif',\n};\n\nconst container = {\n  backgroundColor: '#ffffff',\n  margin: '0 auto',\n  padding: '20px 0 48px',\n  marginBottom: '64px',\n};\n\nconst box = {\n  padding: '0 48px',\n};\n\nconst heading = {\n  color: '#1f2937',\n  fontSize: '24px',\n  fontWeight: 'bold',\n  margin: '16px 0',\n};\n\nconst paragraph = {\n  color: '#525252',\n  fontSize: '16px',\n  lineHeight: '26px',\n  margin: '16px 0',\n};\n\nconst hint = {\n  color: '#f59e0b',\n  fontSize: '14px',\n  fontStyle: 'italic',\n  margin: '16px 0',\n};\n\nconst button = {\n  backgroundColor: '#000000',\n  borderRadius: '4px',\n  color: '#fff',\n  fontSize: '16px',\n  fontWeight: 'bold',\n  textDecoration: 'none',\n  textAlign: 'center' as const,\n  display: 'block',\n  padding: '12px 20px',\n  margin: '16px 0',\n};\n\nconst link = {\n  color: '#0000ee',\n  textDecoration: 'underline',\n};\n\nconst footer = {\n  color: '#8898aa',\n  fontSize: '12px',\n  margin: '16px 0',\n};\n```\n\n#### Template: Newsletter\n\n**Generate File**: `emails/newsletter.tsx`\n\n```tsx\nimport {\n  Body,\n  Button,\n  Container,\n  Head,\n  Heading,\n  Html,\n  Link,\n  Preview,\n  Section,\n  Text,\n} from '@react-email/components';\n\ninterface NewsletterProps {\n  month: string;\n  articles: Array<{\n    title: string;\n    description: string;\n    url: string;\n  }>;\n  unsubscribeUrl: string;\n}\n\nexport function Newsletter({ month, articles, unsubscribeUrl }: NewsletterProps) {\n  return (\n    <Html>\n      <Head />\n      <Preview>{month} Newsletter - Latest updates</Preview>\n      <Body style={main}>\n        <Container style={container}>\n          <Section style={header}>\n            <Heading style={heading}>{month} Newsletter</Heading>\n            <Text style={subtitle}>Your monthly roundup of updates and insights</Text>\n          </Section>\n\n          {articles.map((article, index) => (\n            <Section key={index} style={articleSection}>\n              <Heading style={articleHeading}>{article.title}</Heading>\n              <Text style={paragraph}>{article.description}</Text>\n              <Button style={button} href={article.url}>\n                Read More\n              </Button>\n            </Section>\n          ))}\n\n          <Section style={footer}>\n            <Text style={footerText}>\n              Â© 2025 Your Company. All rights reserved.\n            </Text>\n            <Link style={unsubscribeLink} href={unsubscribeUrl}>\n              Unsubscribe\n            </Link>\n          </Section>\n        </Container>\n      </Body>\n    </Html>\n  );\n}\n\n// Styles\nconst main = {\n  backgroundColor: '#f6f9fc',\n  fontFamily:\n    '-apple-system,BlinkMacSystemFont,\"Segoe UI\",\"Roboto\",\"Oxygen-Sans\",Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif',\n};\n\nconst container = {\n  backgroundColor: '#ffffff',\n  margin: '0 auto',\n  padding: '48px 0',\n  marginBottom: '64px',\n};\n\nconst header = {\n  backgroundColor: '#000000',\n  padding: '32px 48px',\n};\n\nconst heading = {\n  color: '#ffffff',\n  fontSize: '32px',\n  fontWeight: 'bold',\n  margin: '0',\n};\n\nconst subtitle = {\n  color: '#cccccc',\n  fontSize: '16px',\n  margin: '8px 0 0 0',\n};\n\nconst articleSection = {\n  padding: '32px 48px',\n  borderBottom: '1px solid #e5e7eb',\n};\n\nconst articleHeading = {\n  color: '#1f2937',\n  fontSize: '20px',\n  fontWeight: 'bold',\n  margin: '0 0 16px 0',\n};\n\nconst paragraph = {\n  color: '#525252',\n  fontSize: '16px',\n  lineHeight: '26px',\n  margin: '16px 0',\n};\n\nconst button = {\n  backgroundColor: '#000000',\n  borderRadius: '4px',\n  color: '#fff',\n  fontSize: '16px',\n  fontWeight: 'bold',\n  textDecoration: 'none',\n  textAlign: 'center' as const,\n  display: 'inline-block',\n  padding: '12px 20px',\n  margin: '16px 0',\n};\n\nconst footer = {\n  padding: '32px 48px',\n};\n\nconst footerText = {\n  color: '#8898aa',\n  fontSize: '12px',\n  margin: '0 0 16px 0',\n};\n\nconst unsubscribeLink = {\n  color: '#8898aa',\n  fontSize: '12px',\n  textDecoration: 'underline',\n};\n```\n\n### 4. Generate Email Server Functions (Tanstack Start)\n\n**Generate File**: `server/emails/send-verify-email.ts`\n\n```typescript\nimport { createServerFn } from '@tanstack/start';\nimport { Resend } from 'resend';\nimport { VerifyEmail } from '@/emails/verify-email';\n\ninterface SendVerifyEmailInput {\n  to: string;\n  verificationUrl: string;\n}\n\nexport const sendVerifyEmail = createServerFn(\n  'POST',\n  async (input: SendVerifyEmailInput, context) => {\n    const { env } = context.cloudflare;\n    const resend = new Resend(env.RESEND_API_KEY);\n\n    try {\n      const { data, error } = await resend.emails.send({\n        from: 'noreply@yourdomain.com',\n        to: input.to,\n        subject: 'Verify your email address',\n        react: VerifyEmail({\n          verificationUrl: input.verificationUrl,\n          email: input.to,\n        }),\n      });\n\n      if (error) {\n        console.error('Resend error:', error);\n        throw new Error(`Failed to send verification email: ${error.message}`);\n      }\n\n      // Log sent email for audit trail\n      if (env.DB) {\n        await env.DB.prepare(\n          `INSERT INTO sent_emails (id, to, subject, type, email_id, created_at)\n           VALUES (?, ?, ?, ?, ?, ?)`\n        ).bind(\n          crypto.randomUUID(),\n          input.to,\n          'Verify your email address',\n          'verification',\n          data.id,\n          new Date().toISOString()\n        ).run();\n      }\n\n      return { success: true, emailId: data.id };\n    } catch (error) {\n      console.error('Email send error:', error);\n\n      // Store failed email for retry\n      if (env.DB) {\n        await env.DB.prepare(\n          `INSERT INTO failed_emails (id, to, subject, type, error, created_at)\n           VALUES (?, ?, ?, ?, ?, ?)`\n        ).bind(\n          crypto.randomUUID(),\n          input.to,\n          'Verify your email address',\n          'verification',\n          error instanceof Error ? error.message : 'Unknown error',\n          new Date().toISOString()\n        ).run();\n      }\n\n      return {\n        success: false,\n        error: 'Email delivery failed. Please try again later.',\n      };\n    }\n  }\n);\n```\n\n**Generate File**: `server/emails/send-password-reset.ts`\n\n```typescript\nimport { createServerFn } from '@tanstack/start';\nimport { Resend } from 'resend';\nimport { PasswordReset } from '@/emails/password-reset';\n\ninterface SendPasswordResetInput {\n  to: string;\n  resetUrl: string;\n}\n\nexport const sendPasswordReset = createServerFn(\n  'POST',\n  async (input: SendPasswordResetInput, context) => {\n    const { env } = context.cloudflare;\n    const resend = new Resend(env.RESEND_API_KEY);\n\n    try {\n      const { data, error } = await resend.emails.send({\n        from: 'noreply@yourdomain.com',\n        to: input.to,\n        subject: 'Reset your password',\n        react: PasswordReset({\n          resetUrl: input.resetUrl,\n          email: input.to,\n        }),\n      });\n\n      if (error) {\n        console.error('Resend error:', error);\n        throw new Error(`Failed to send password reset email: ${error.message}`);\n      }\n\n      // Log sent email\n      if (env.DB) {\n        await env.DB.prepare(\n          `INSERT INTO sent_emails (id, to, subject, type, email_id, created_at)\n           VALUES (?, ?, ?, ?, ?, ?)`\n        ).bind(\n          crypto.randomUUID(),\n          input.to,\n          'Reset your password',\n          'password_reset',\n          data.id,\n          new Date().toISOString()\n        ).run();\n      }\n\n      return { success: true, emailId: data.id };\n    } catch (error) {\n      console.error('Email send error:', error);\n\n      // Store failed email for retry\n      if (env.DB) {\n        await env.DB.prepare(\n          `INSERT INTO failed_emails (id, to, subject, type, error, created_at)\n           VALUES (?, ?, ?, ?, ?, ?)`\n        ).bind(\n          crypto.randomUUID(),\n          input.to,\n          'Reset your password',\n          'password_reset',\n          error instanceof Error ? error.message : 'Unknown error',\n          new Date().toISOString()\n        ).run();\n      }\n\n      return {\n        success: false,\n        error: 'Email delivery failed. Please try again later.',\n      };\n    }\n  }\n);\n```\n\n**Generate File**: `server/emails/send-newsletter.ts`\n\n```typescript\nimport { createServerFn } from '@tanstack/start';\nimport { Resend } from 'resend';\nimport { Newsletter } from '@/emails/newsletter';\n\ninterface NewsletterArticle {\n  title: string;\n  description: string;\n  url: string;\n}\n\ninterface SendNewsletterInput {\n  to: string[];\n  month: string;\n  articles: NewsletterArticle[];\n  unsubscribeBaseUrl: string;\n}\n\nexport const sendNewsletter = createServerFn(\n  'POST',\n  async (input: SendNewsletterInput, context) => {\n    const { env } = context.cloudflare;\n    const resend = new Resend(env.RESEND_API_KEY);\n\n    try {\n      // Batch send using Resend's batch API\n      const batch = input.to.map(email => ({\n        from: 'newsletter@yourdomain.com',\n        to: email,\n        subject: `${input.month} Newsletter - Latest updates`,\n        react: Newsletter({\n          month: input.month,\n          articles: input.articles,\n          unsubscribeUrl: `${input.unsubscribeBaseUrl}?email=${encodeURIComponent(email)}`,\n        }),\n      }));\n\n      const { data, error } = await resend.batch.send(batch);\n\n      if (error) {\n        console.error('Batch send error:', error);\n        throw new Error(`Failed to send newsletters: ${error.message}`);\n      }\n\n      // Log sent emails\n      if (env.DB) {\n        for (const email of input.to) {\n          await env.DB.prepare(\n            `INSERT INTO sent_emails (id, to, subject, type, email_id, created_at)\n             VALUES (?, ?, ?, ?, ?, ?)`\n          ).bind(\n            crypto.randomUUID(),\n            email,\n            `${input.month} Newsletter`,\n            'newsletter',\n            data?.id || 'batch',\n            new Date().toISOString()\n          ).run();\n        }\n      }\n\n      return {\n        success: true,\n        sent: input.to.length,\n        batchId: data?.id,\n      };\n    } catch (error) {\n      console.error('Newsletter send error:', error);\n\n      // Store failed batch\n      if (env.DB) {\n        for (const email of input.to) {\n          await env.DB.prepare(\n            `INSERT INTO failed_emails (id, to, subject, type, error, created_at)\n             VALUES (?, ?, ?, ?, ?, ?)`\n          ).bind(\n            crypto.randomUUID(),\n            email,\n            `${input.month} Newsletter`,\n            'newsletter',\n            error instanceof Error ? error.message : 'Unknown error',\n            new Date().toISOString()\n          ).run();\n        }\n      }\n\n      return {\n        success: false,\n        error: 'Newsletter delivery failed. Please try again later.',\n      };\n    }\n  }\n);\n```\n\n### 5. Generate Database Migration for Email Tracking\n\n**Generate File**: `migrations/0001_email_tracking.sql`\n\n```sql\n-- Sent emails log (audit trail)\nCREATE TABLE sent_emails (\n  id TEXT PRIMARY KEY,\n  to TEXT NOT NULL,\n  subject TEXT NOT NULL,\n  type TEXT NOT NULL, -- 'verification', 'password_reset', 'newsletter', 'custom'\n  email_id TEXT UNIQUE, -- Resend email ID for tracking\n  opened INTEGER DEFAULT 0,\n  clicked INTEGER DEFAULT 0,\n  bounced INTEGER DEFAULT 0,\n  created_at TEXT NOT NULL,\n  updated_at TEXT NOT NULL\n);\n\n-- Failed emails for retry logic\nCREATE TABLE failed_emails (\n  id TEXT PRIMARY KEY,\n  to TEXT NOT NULL,\n  subject TEXT NOT NULL,\n  type TEXT NOT NULL,\n  error TEXT,\n  retry_count INTEGER DEFAULT 0,\n  last_retry_at TEXT,\n  created_at TEXT NOT NULL\n);\n\n-- Indexes for performance\nCREATE INDEX idx_sent_emails_to ON sent_emails(to);\nCREATE INDEX idx_sent_emails_type ON sent_emails(type);\nCREATE INDEX idx_sent_emails_created ON sent_emails(created_at);\nCREATE INDEX idx_failed_emails_to ON failed_emails(to);\nCREATE INDEX idx_failed_emails_type ON failed_emails(type);\nCREATE INDEX idx_failed_emails_retry_count ON failed_emails(retry_count);\n```\n\n**Run Migration**:\n```bash\nwrangler d1 migrations apply DB --local\nwrangler d1 migrations apply DB --remote\n```\n\n### 6. Configure Environment Variables\n\n**Update**: `wrangler.toml`\n\n```toml\n# Add Resend API key binding\n[env.production.vars]\n# RESEND_API_KEY should be set as a secret, not in this file\n\n# D1 database binding (if using email tracking)\n[[d1_databases]]\nbinding = \"DB\"\ndatabase_name = \"my-app-db\"\ndatabase_id = \"...\"  # Get from: wrangler d1 create my-app-db\n```\n\n**Create**: `.dev.vars` (local development)\n\n```bash\n# Resend API Key (sensitive - DO NOT COMMIT)\nRESEND_API_KEY=re_your_api_key_here\n\n# Your domain for email sender (update to your domain)\n# RESEND_FROM_EMAIL=noreply@yourdomain.com\n```\n\n**Production Setup**:\n```bash\n# Set Resend API key as a secret\nwrangler secret put RESEND_API_KEY\n# Paste: re_xxxxxxxxxxxxx\n```\n\n### 7. Configure Domain Verification\n\n**Instructions for User**:\n\n```markdown\n## Setup Custom Email Domain (Required for Production)\n\n### Step 1: Add Domain in Resend\n1. Go to https://resend.com/dashboard/domains\n2. Click \"Add Domain\"\n3. Enter your domain (e.g., yourdomain.com)\n4. Resend will show DNS records to add\n\n### Step 2: Add DNS Records\nAdd these records to your domain's DNS provider (Cloudflare, Route53, etc.):\n\n**SPF Record**:\n```\nType: TXT\nName: yourdomain.com\nValue: v=spf1 include:resend.com ~all\n```\n\n**DKIM Record**:\n```\nType: CNAME\nName: default._domainkey.yourdomain.com\nValue: [value from Resend dashboard]\n```\n\n**DMARC Record** (optional but recommended):\n```\nType: TXT\nName: _dmarc.yourdomain.com\nValue: v=DMARC1; p=quarantine; rua=mailto:dmarc@yourdomain.com\n```\n\n### Step 3: Verify Domain\n1. Return to Resend dashboard\n2. Click \"Verify Domain\"\n3. Wait for DNS propagation (usually 5-30 minutes)\n4. Once verified, use `from: 'noreply@yourdomain.com'` in emails\n\n### Step 4: Update Email Templates\nReplace `noreply@yourdomain.com` with your verified domain across all email functions.\n\n### Development\nFor development/testing only, use:\n```\nfrom: 'onboarding@resend.dev'\n```\nThis works without domain verification but is limited to emails you've verified with Resend.\n```\n\n### 8. Setup Email Retry Logic\n\n**Generate File**: `server/utils/email-retry.ts`\n\n```typescript\nimport { Resend } from 'resend';\n\ninterface Env {\n  RESEND_API_KEY: string;\n  DB: D1Database;\n}\n\nexport async function retryFailedEmails(env: Env) {\n  const resend = new Resend(env.RESEND_API_KEY);\n\n  // Get failed emails that haven't exceeded retry limit\n  const failed = await env.DB.prepare(\n    `SELECT * FROM failed_emails\n     WHERE retry_count < 3\n     AND (last_retry_at IS NULL OR datetime(last_retry_at) < datetime('now', '-1 hour'))\n     LIMIT 10`\n  ).all();\n\n  if (!failed.results || failed.results.length === 0) {\n    console.log('No emails to retry');\n    return { retried: 0, succeeded: 0, failed: 0 };\n  }\n\n  let succeeded = 0;\n  let retryFailed = 0;\n\n  for (const email of failed.results) {\n    try {\n      // Reconstruct and resend based on type\n      // This is a simplified version - you may need to store template data\n      const { error } = await resend.emails.send({\n        from: 'noreply@yourdomain.com',\n        to: email.to,\n        subject: email.subject,\n        html: `<p>Retry: ${email.subject}</p>`,\n      });\n\n      if (error) {\n        // Increment retry count and update last_retry_at\n        await env.DB.prepare(\n          `UPDATE failed_emails\n           SET retry_count = retry_count + 1,\n               last_retry_at = ?\n           WHERE id = ?`\n        ).bind(new Date().toISOString(), email.id).run();\n\n        retryFailed++;\n      } else {\n        // Move to sent_emails and remove from failed_emails\n        await env.DB.prepare(\n          `DELETE FROM failed_emails WHERE id = ?`\n        ).bind(email.id).run();\n\n        succeeded++;\n      }\n    } catch (error) {\n      console.error('Retry error for email:', email.id, error);\n      retryFailed++;\n    }\n  }\n\n  return {\n    retried: failed.results.length,\n    succeeded,\n    failed: retryFailed,\n  };\n}\n```\n\n**Setup Scheduled Retry** (using Cloudflare Cron):\n\nUpdate `wrangler.toml`:\n```toml\n[[triggers.crons]]\ncrons = [\"0 */6 * * *\"]  # Run every 6 hours\n```\n\nCreate `src/scheduled.ts`:\n```typescript\nexport default {\n  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext) {\n    ctx.waitUntil(\n      (async () => {\n        const result = await retryFailedEmails(env);\n        console.log('Email retry results:', result);\n      })()\n    );\n  },\n};\n```\n\n### 9. Integrate with Authentication\n\n**Example: Send verification email on signup**\n\nUpdate `server/routes/auth/register.ts`:\n```typescript\nimport { sendVerifyEmail } from '@/server/emails/send-verify-email';\n\nexport default defineEventHandler(async (event) => {\n  const { email, password } = await readBody(event);\n\n  // Create user...\n  const user = await createUser(email, password, event.context.cloudflare.env.DB);\n\n  // Generate verification token\n  const token = generateToken(user.id);\n\n  // Send verification email\n  const verifyUrl = `${process.env.PUBLIC_URL}/verify?token=${token}`;\n  await sendVerifyEmail({\n    to: email,\n    verificationUrl: verifyUrl,\n  });\n\n  return {\n    success: true,\n    message: 'Account created. Please check your email to verify.',\n  };\n});\n```\n\n**Example: Send password reset email**\n\nCreate `server/routes/auth/forgot-password.ts`:\n```typescript\nimport { sendPasswordReset } from '@/server/emails/send-password-reset';\n\nexport default defineEventHandler(async (event) => {\n  const { email } = await readBody(event);\n\n  // Find user\n  const user = await findUserByEmail(email, event.context.cloudflare.env.DB);\n\n  if (!user) {\n    // Don't reveal if email exists (security)\n    return {\n      success: true,\n      message: 'If an account exists, a reset link has been sent.',\n    };\n  }\n\n  // Generate reset token\n  const token = generateToken(user.id, '1h');\n\n  // Send password reset email\n  const resetUrl = `${process.env.PUBLIC_URL}/reset-password?token=${token}`;\n  await sendPasswordReset({\n    to: email,\n    resetUrl,\n  });\n\n  return {\n    success: true,\n    message: 'Password reset email sent.',\n  };\n});\n```\n\n### 10. Setup Email Analytics Webhook (Optional)\n\n**Resend Webhook Configuration**:\n\n1. Go to https://resend.com/dashboard/settings/webhooks\n2. Add webhook endpoint: `https://yourdomain.com/api/webhooks/email`\n3. Subscribe to events:\n   - `email.sent`\n   - `email.opened`\n   - `email.clicked`\n   - `email.bounced`\n\n**Create Handler**: `server/api/webhooks/email.ts`\n\n```typescript\nexport default defineEventHandler(async (event) => {\n  const body = await readBody(event);\n  const { type, data } = body;\n\n  try {\n    switch (type) {\n      case 'email.sent':\n        await updateEmailStatus(data.email_id, 'sent', event.context.cloudflare.env.DB);\n        break;\n\n      case 'email.opened':\n        await updateEmailStatus(data.email_id, 'opened', event.context.cloudflare.env.DB);\n        break;\n\n      case 'email.clicked':\n        await updateEmailStatus(data.email_id, 'clicked', event.context.cloudflare.env.DB);\n        break;\n\n      case 'email.bounced':\n        await handleBounce(data.email_id, data.email, event.context.cloudflare.env.DB);\n        break;\n\n      default:\n        console.log('Unknown email event:', type);\n    }\n\n    return { success: true };\n  } catch (error) {\n    console.error('Webhook error:', error);\n    return { success: false, error: String(error) };\n  }\n});\n\nasync function updateEmailStatus(emailId: string, status: string, db: D1Database) {\n  await db.prepare(\n    `UPDATE sent_emails SET ${status} = 1, updated_at = ? WHERE email_id = ?`\n  ).bind(new Date().toISOString(), emailId).run();\n}\n\nasync function handleBounce(emailId: string, email: string, db: D1Database) {\n  await db.prepare(\n    `UPDATE sent_emails SET bounced = 1, updated_at = ? WHERE email_id = ?`\n  ).bind(new Date().toISOString(), emailId).run();\n\n  // Optionally mark email as invalid for future use\n  // await db.prepare(\n  //   `INSERT INTO invalid_emails (email) VALUES (?) ON CONFLICT DO NOTHING`\n  // ).bind(email).run();\n}\n```\n\n### 11. Testing Email Flows\n\n**Test Email Sending**:\n```typescript\n// Use Resend's test address\nconst { data, error } = await resend.emails.send({\n  from: 'test@yourdomain.com',\n  to: 'test@resend.dev', // Special test address\n  subject: 'Test email',\n  react: VerifyEmail({\n    verificationUrl: 'https://example.com/verify?token=test',\n    email: 'test@resend.dev',\n  }),\n});\n```\n\n**Playwright E2E Test Example**:\n```typescript\ntest('sends verification email on signup', async ({ page }) => {\n  await page.goto('/signup');\n\n  await page.fill('[name=\"email\"]', 'test@example.com');\n  await page.fill('[name=\"password\"]', 'Test123!@#');\n  await page.click('button[type=\"submit\"]');\n\n  // Verify success message\n  await expect(page.locator('[data-testid=\"success-message\"]'))\n    .toContainText('Check your email');\n\n  // In real scenario, verify email was sent via Resend API\n  // This test verifies the UI flow, not actual email delivery\n});\n```\n\n**Preview React Email Templates**:\n```bash\n# Start React Email preview server\nnpm run email:preview\n\n# Open http://localhost:3000 to preview templates\n```\n\n## Success Criteria\n\nâœ… Email setup complete when:\n- Resend SDK and React Email dependencies installed\n- All email templates generated (verification, password reset, newsletter)\n- Server functions created for sending emails\n- Database migration for email tracking\n- Environment variables configured\n- Domain verification setup (at least documented)\n- Error handling and retry logic implemented\n- Integration with auth flows completed\n- Email previews working\n- Testing strategy documented\n\n## Output Summary\n\n**Files Created**:\n- Email templates:\n  - `emails/verify-email.tsx`\n  - `emails/password-reset.tsx`\n  - `emails/newsletter.tsx`\n- Server functions:\n  - `server/emails/send-verify-email.ts`\n  - `server/emails/send-password-reset.ts`\n  - `server/emails/send-newsletter.ts`\n- Database migration: `migrations/0001_email_tracking.sql`\n- Utilities: `server/utils/email-retry.ts`\n- Webhook handler: `server/api/webhooks/email.ts`\n- Scheduled job: `src/scheduled.ts`\n\n**Files Updated**:\n- `wrangler.toml` (Resend vars, D1 binding)\n- `.dev.vars` (template)\n\n**Next Actions**:\n1. Install dependencies: `npm install resend @react-email/components`\n2. Run database migration: `wrangler d1 migrations apply DB`\n3. Generate Resend API key: https://resend.com/dashboard\n4. Add to secrets: `wrangler secret put RESEND_API_KEY`\n5. Configure domain in Resend dashboard\n6. Test email flows with signup\n7. Preview templates: `npm run email:preview`\n8. Deploy with `/es-deploy`\n\n## Notes\n\n- Always use Resend for transactional and marketing emails\n- React Email provides type-safe, component-based templates\n- Store RESEND_API_KEY as Cloudflare secret (not in wrangler.toml)\n- Domain verification required for production (use onboarding@resend.dev for testing)\n- Email retry logic handles transient failures\n- Track email opens/clicks via Resend webhooks\n- Test with onboarding@resend.dev before using custom domain\n- Use batch API for newsletters to multiple recipients\n- See `agents/integrations/resend-email-specialist` for detailed guidance"
              },
              {
                "name": "/es-issue",
                "description": "Create well-structured GitHub issues following project conventions",
                "path": "plugins/edge-stack/commands/es-issue.md",
                "frontmatter": {
                  "description": "Create well-structured GitHub issues following project conventions"
                },
                "content": "# Create GitHub Issue\n\n## Introduction\n\nTransform feature descriptions, bug reports, or improvement ideas into well-structured markdown files issues that follow project conventions and best practices. This command provides flexible detail levels to match your needs.\n\n## Feature Description\n\n<feature_description> #$ARGUMENTS </feature_description>\n\n## Main Tasks\n\n### 1. Cloudflare Context & Binding Analysis\n\n<thinking>\nFirst, I need to understand the Cloudflare Workers project structure, available bindings, and existing patterns. This informs architectural decisions and implementation approaches.\n</thinking>\n\n**CRITICAL FIRST STEP**: Verify this is a Cloudflare Workers project:\n- Check for `wrangler.toml` file\n- If not found, warn user and ask if they want to create a new Workers project\n\nRun these agents in parallel:\n\n**Phase 1: Cloudflare-Specific Context (Priority)**\n\n- Task binding-context-analyzer(feature_description)\n  - Parse wrangler.toml for existing bindings (KV, R2, D1, DO)\n  - Generate current Env interface\n  - Identify available resources for reuse\n  - Provide context to other agents\n\n- Task cloudflare-architecture-strategist(feature_description)\n  - Analyze Workers/DO/KV/R2 architecture patterns\n  - Recommend storage choices based on feature requirements\n  - Consider edge-first design principles\n\n**Phase 2: General Research (Parallel)**\n\n- Task repo-research-analyst(feature_description)\n  - Research existing Workers patterns in codebase\n  - Identify Cloudflare-specific conventions\n  - Document Workers entry points and routing patterns\n\n**Reference Collection:**\n\n- [ ] Document all research findings with specific file paths (e.g., `src/index.ts:42`)\n- [ ] List existing bindings from wrangler.toml with IDs and types\n- [ ] Include URLs to Cloudflare documentation and best practices\n- [ ] Create a reference list of similar Workers implementations or PRs\n- [ ] Note any Cloudflare-specific conventions discovered in documentation\n- [ ] Document user preferences from PREFERENCES.md (Tanstack Start, Hono, Vercel AI SDK)\n\n### 2. Issue Planning & Structure\n\n<thinking>\nThink like a product manager - what would make this issue clear and actionable? Consider multiple perspectives\n</thinking>\n\n**Title & Categorization:**\n\n- [ ] Draft clear, searchable issue title using conventional format (e.g., `feat:`, `fix:`, `docs:`)\n- [ ] Identify appropriate labels from repository's label set (`gh label list`)\n- [ ] Determine issue type: enhancement, bug, refactor\n\n**Stakeholder Analysis:**\n\n- [ ] Identify who will be affected by this issue (end users, developers, operations)\n- [ ] Consider implementation complexity and required expertise\n\n**Content Planning:**\n\n- [ ] Choose appropriate detail level based on issue complexity and audience\n- [ ] List all necessary sections for the chosen template\n- [ ] Gather supporting materials (error logs, screenshots, design mockups)\n- [ ] Prepare code examples or reproduction steps if applicable, name the mock filenames in the lists\n\n### 3. Choose Implementation Detail Level\n\nSelect how comprehensive you want the issue to be:\n\n#### ðŸ“„ MINIMAL (Quick Issue)\n\n**Best for:** Simple bugs, small improvements, clear features\n\n**Includes:**\n\n- Problem statement or feature description\n- Basic acceptance criteria\n- Essential context only\n\n**Structure:**\n\n````markdown\n[Brief problem/feature description]\n\n## Acceptance Criteria\n\n- [ ] Core requirement 1\n- [ ] Core requirement 2\n\n## Context\n\n[Any critical information]\n\n## MVP\n\n### src/worker.ts\n\n```typescript\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n    // Minimal implementation\n    return new Response('Hello World');\n  }\n};\n```\n\n### wrangler.toml\n\n```toml\nname = \"feature-name\"\nmain = \"src/index.ts\"\ncompatibility_date = \"2025-09-15\"  # Always use 2025-09-15 or later\n\n# Example: KV namespace with remote binding\n[[kv_namespaces]]\nbinding = \"CACHE\"\nid = \"your-kv-namespace-id\"\nremote = true  # Connect to real KV during development\n```\n\n## References\n\n- Related issue: #[issue_number]\n- Cloudflare Docs: [relevant_docs_url]\n- Existing bindings: [from binding-context-analyzer]\n````\n\n#### ðŸ“‹ MORE (Standard Issue)\n\n**Best for:** Most features, complex bugs, team collaboration\n\n**Includes everything from MINIMAL plus:**\n\n- Detailed background and motivation\n- Technical considerations\n- Success metrics\n- Dependencies and risks\n- Basic implementation suggestions\n\n**Structure:**\n\n```markdown\n## Overview\n\n[Comprehensive description]\n\n## Problem Statement / Motivation\n\n[Why this matters]\n\n## Proposed Solution\n\n[High-level approach]\n\n## Technical Considerations\n\n- Architecture impacts\n- Performance implications\n- Security considerations\n\n## Acceptance Criteria\n\n- [ ] Detailed requirement 1\n- [ ] Detailed requirement 2\n- [ ] Testing requirements\n\n## Success Metrics\n\n[How we measure success]\n\n## Dependencies & Risks\n\n[What could block or complicate this]\n\n## References & Research\n\n- Similar implementations: [file_path:line_number]\n- Best practices: [documentation_url]\n- Related PRs: #[pr_number]\n```\n\n#### ðŸ“š A LOT (Comprehensive Issue)\n\n**Best for:** Major features, architectural changes, complex integrations\n\n**Includes everything from MORE plus:**\n\n- Detailed implementation plan with phases\n- Alternative approaches considered\n- Extensive technical specifications\n- Resource requirements and timeline\n- Future considerations and extensibility\n- Risk mitigation strategies\n- Documentation requirements\n\n**Structure:**\n\n```markdown\n## Overview\n\n[Executive summary]\n\n## Problem Statement\n\n[Detailed problem analysis]\n\n## Proposed Solution\n\n[Comprehensive solution design]\n\n## Technical Approach\n\n### Architecture\n\n[Detailed technical design]\n\n### Implementation Phases\n\n#### Phase 1: [Foundation]\n\n- Tasks and deliverables\n- Success criteria\n- Estimated effort\n\n#### Phase 2: [Core Implementation]\n\n- Tasks and deliverables\n- Success criteria\n- Estimated effort\n\n#### Phase 3: [Polish & Optimization]\n\n- Tasks and deliverables\n- Success criteria\n- Estimated effort\n\n## Alternative Approaches Considered\n\n[Other solutions evaluated and why rejected]\n\n## Acceptance Criteria\n\n### Functional Requirements\n\n- [ ] Detailed functional criteria\n\n### Non-Functional Requirements\n\n- [ ] Performance targets\n- [ ] Security requirements\n- [ ] Accessibility standards\n\n### Quality Gates\n\n- [ ] Test coverage requirements\n- [ ] Documentation completeness\n- [ ] Code review approval\n\n## Success Metrics\n\n[Detailed KPIs and measurement methods]\n\n## Dependencies & Prerequisites\n\n[Detailed dependency analysis]\n\n## Risk Analysis & Mitigation\n\n[Comprehensive risk assessment]\n\n## Resource Requirements\n\n[Team, time, infrastructure needs]\n\n## Future Considerations\n\n[Extensibility and long-term vision]\n\n## Documentation Plan\n\n[What docs need updating]\n\n## References & Research\n\n### Internal References\n\n- Architecture decisions: [file_path:line_number]\n- Similar features: [file_path:line_number]\n- Configuration: [file_path:line_number]\n\n### External References\n\n- Framework documentation: [url]\n- Best practices guide: [url]\n- Industry standards: [url]\n\n### Related Work\n\n- Previous PRs: #[pr_numbers]\n- Related issues: #[issue_numbers]\n- Design documents: [links]\n```\n\n### 4. Issue Creation & Formatting\n\n<thinking>\nApply best practices for clarity and actionability, making the issue easy to scan and understand\n</thinking>\n\n**Content Formatting:**\n\n- [ ] Use clear, descriptive headings with proper hierarchy (##, ###)\n- [ ] Include code examples in triple backticks with language syntax highlighting\n- [ ] Add screenshots/mockups if UI-related (drag & drop or use image hosting)\n- [ ] Use task lists (- [ ]) for trackable items that can be checked off\n- [ ] Add collapsible sections for lengthy logs or optional details using `<details>` tags\n- [ ] Apply appropriate emoji for visual scanning (ðŸ› bug, âœ¨ feature, ðŸ“š docs, â™»ï¸ refactor)\n\n**Cross-Referencing:**\n\n- [ ] Link to related issues/PRs using #number format\n- [ ] Reference specific commits with SHA hashes when relevant\n- [ ] Link to code using GitHub's permalink feature (press 'y' for permanent link)\n- [ ] Mention relevant team members with @username if needed\n- [ ] Add links to external resources with descriptive text\n\n**Code & Examples:**\n\n```markdown\n# Good example with syntax highlighting and line references\n\n\\`\\`\\`ruby\n\n# app/services/user_service.rb:42\n\ndef process_user(user)\n\n# Implementation here\n\nend \\`\\`\\`\n\n# Collapsible error logs\n\n<details>\n<summary>Full error stacktrace</summary>\n\n\\`\\`\\` Error details here... \\`\\`\\`\n\n</details>\n```\n\n**AI-Era Considerations:**\n\n- [ ] Account for accelerated development with AI pair programming\n- [ ] Include prompts or instructions that worked well during research\n- [ ] Note which AI tools were used for initial exploration (Claude, Copilot, etc.)\n- [ ] Emphasize comprehensive testing given rapid implementation\n- [ ] Document any AI-generated code that needs human review\n\n### 5. Final Review & Submission\n\n**Pre-submission Checklist:**\n\n- [ ] Title is searchable and descriptive\n- [ ] Labels accurately categorize the issue\n- [ ] All template sections are complete\n- [ ] Links and references are working\n- [ ] Acceptance criteria are measurable\n- [ ] Add names of files in pseudo code examples and todo lists\n- [ ] Add an ERD mermaid diagram if applicable for new model changes\n\n## Output Format\n\nPresent the complete issue content within `<github_issue>` tags, ready for GitHub CLI:\n\n```bash\ngh issue create --title \"[TITLE]\" --body \"[CONTENT]\" --label \"[LABELS]\"\n```\n\n## Thinking Approaches\n\n- **Analytical:** Break down complex features into manageable components\n- **User-Centric:** Consider end-user impact and experience\n- **Technical:** Evaluate implementation complexity and architecture fit\n- **Strategic:** Align with project goals and roadmap"
              },
              {
                "name": "/es-migrate",
                "description": "Migrate applications from other platforms to Cloudflare Workers with comprehensive analysis and validation",
                "path": "plugins/edge-stack/commands/es-migrate.md",
                "frontmatter": {
                  "description": "Migrate applications from other platforms to Cloudflare Workers with comprehensive analysis and validation"
                },
                "content": "# Cloudflare Workers Migration Command\n\n<command_purpose> Migrate applications from other platforms (Heroku, AWS Lambda, Vercel Functions, etc.) to Cloudflare Workers with comprehensive analysis, code transformation, and multi-agent validation. </command_purpose>\n\n## Introduction\n\n<role>Platform Migration Specialist with expertise in Cloudflare Workers, runtime compatibility, and multi-cloud architecture patterns</role>\n\nThis command analyzes your existing application, identifies migration challenges, transforms code for Workers compatibility, and guides you through a safe migration to Cloudflare's edge network.\n\n## Prerequisites\n\n<requirements>\n- Existing application codebase (Node.js, Python, Go, etc.)\n- Cloudflare account with Workers enabled\n- wrangler CLI installed (`npm install -g wrangler`)\n- Git repository for tracking migration changes\n- Understanding of your current platform's architecture\n</requirements>\n\n## Migration Source\n\n<migration_source> #$ARGUMENTS </migration_source>\n\n**Supported platforms**:\n- Heroku (Node.js, Python, Ruby)\n- AWS Lambda (Node.js, Python, Go)\n- Vercel Functions (Node.js, Edge Functions)\n- Netlify Functions (Node.js)\n- Google Cloud Functions (Node.js, Python, Go)\n- Azure Functions (Node.js, Python)\n- Custom Node.js applications\n- Express/Fastify/Koa applications\n\n**Target**: Cloudflare Workers (V8 runtime)\n\n## Main Tasks\n\n### 1. Platform Detection & Analysis\n\n<thinking>\nFirst, identify the current platform and analyze the application structure.\nThis informs all subsequent migration decisions.\n</thinking>\n\n#### Step 1: Detect Current Platform\n\n**Automatic detection via files**:\n\n```bash\n# Check for platform-specific files\nif [ -f \"Procfile\" ]; then\n  echo \"Detected: Heroku\"\n  PLATFORM=\"heroku\"\nelif [ -f \"vercel.json\" ]; then\n  echo \"Detected: Vercel\"\n  PLATFORM=\"vercel\"\nelif [ -f \"netlify.toml\" ]; then\n  echo \"Detected: Netlify\"\n  PLATFORM=\"netlify\"\nelif [ -d \".aws-sam\" ] || grep -q \"AWS::Serverless\" template.yaml 2>/dev/null; then\n  echo \"Detected: AWS Lambda\"\n  PLATFORM=\"aws-lambda\"\nelif [ -f \"function.json\" ]; then\n  echo \"Detected: Azure Functions\"\n  PLATFORM=\"azure\"\nelif [ -f \"cloudbuild.yaml\" ]; then\n  echo \"Detected: Google Cloud Functions\"\n  PLATFORM=\"gcp\"\nelse\n  echo \"Platform: Generic Node.js/Python/Go application\"\n  PLATFORM=\"generic\"\nfi\n```\n\n#### Step 2: Analyze Application Structure\n\n**Discovery tasks** (run in parallel):\n\n1. **List all endpoints/routes**\n   ```bash\n   # For Express apps\n   grep -r \"app\\.\\(get\\|post\\|put\\|delete\\|patch\\)\" src/\n\n   # For serverless functions\n   find . -name \"*.handler.js\" -o -name \"api/*.ts\"\n   ```\n\n2. **Identify runtime dependencies**\n   ```bash\n   # Node.js\n   jq '.dependencies + .devDependencies' package.json\n\n   # Python\n   cat requirements.txt\n\n   # Go\n   cat go.mod\n   ```\n\n3. **Find environment variables**\n   ```bash\n   # Check for .env files\n   cat .env.example .env 2>/dev/null | grep -v '^#' | cut -d= -f1\n\n   # Check code for process.env usage\n   grep -r \"process\\.env\\.\" src/ --include=\"*.js\" --include=\"*.ts\"\n   ```\n\n4. **Detect database/storage usage**\n   ```bash\n   # Database clients\n   grep -r \"new.*Client\\|createConnection\\|mongoose\\.connect\" src/\n\n   # Storage SDKs\n   grep -r \"S3Client\\|Storage\\|GridFS\" src/\n   ```\n\n#### Step 3: Generate Migration Assessment Report\n\n<deliverable>\nComprehensive report on migration complexity and requirements\n</deliverable>\n\n```markdown\n## Migration Assessment Report\n\n**Source Platform**: [Platform detected]\n**Application Type**: [Web app / API / Background jobs]\n**Primary Language**: [Node.js / Python / Go]\n\n### Application Inventory\n\n**Endpoints Discovered**: [X] routes\n- GET: [count]\n- POST: [count]\n- PUT/PATCH: [count]\n- DELETE: [count]\n\n**Dependencies**: [Y] packages\n- Compatible with Workers: [count] âœ…\n- Require replacement: [count] âš ï¸\n- Incompatible: [count] âŒ\n\n**Environment Variables**: [Z] variables\n- Public config: [count]\n- Secrets: [count]\n\n**Data Storage**:\n- Databases: [PostgreSQL / MySQL / MongoDB / etc.]\n- File storage: [S3 / Local files / etc.]\n- Caching: [Redis / Memcached / etc.]\n\n### Migration Complexity\n\n**Estimated Effort**: [Small / Medium / Large]\n**Risk Level**: [Low / Medium / High]\n\n**Complexity Factors**:\n- [ ] Node.js-specific APIs (fs, process, Buffer) - [count] instances\n- [ ] Long-running operations (> 30 seconds)\n- [ ] Stateful operations (in-memory sessions)\n- [ ] Large dependencies (> 50KB bundles)\n- [ ] WebSocket connections (need Durable Objects)\n- [ ] Database schema changes required\n- [ ] Custom middleware/plugins\n\n### Migration Strategy Recommendation\n\n[Detailed strategy based on analysis]\n```\n\n### 2. Multi-Agent Migration Planning\n\n<thinking>\nUse specialized agents to analyze different aspects of the migration.\nRun in parallel for comprehensive coverage.\n</thinking>\n\n#### Phase 1: Cloudflare Context Analysis (Parallel)\n\n1. **Task binding-context-analyzer(migration source)**\n   - Analyze current data storage needs\n   - Recommend Cloudflare bindings (KV/R2/D1/DO)\n   - Generate initial wrangler.toml structure\n   - Map platform resources to Workers equivalents:\n     - Redis â†’ KV or Durable Objects\n     - PostgreSQL/MySQL â†’ D1\n     - S3 â†’ R2\n     - Sessions â†’ KV or Durable Objects\n     - WebSockets â†’ Durable Objects\n\n2. **Task cloudflare-architecture-strategist(migration source)**\n   - Design Workers architecture (single Worker vs. multiple)\n   - Service binding strategy for microservices\n   - Recommend DO usage for stateful components\n   - Edge-first architecture patterns\n\n3. **Task repo-research-analyst(migration source)**\n   - Document current architecture patterns\n   - Identify dependencies and integrations\n   - Map data flows\n\n#### Phase 2: Code Compatibility Analysis (Parallel)\n\n4. **Task workers-runtime-guardian(current codebase)**\n   - **CRITICAL**: Identify Node.js API usage\n   - List all incompatible APIs (fs, process, Buffer, crypto, etc.)\n   - Recommend Web API replacements\n   - Estimate transformation effort\n\n5. **Task cloudflare-pattern-specialist(current codebase)**\n   - Identify anti-patterns for Workers\n   - Detect stateful operations needing Durable Objects\n   - Analyze request/response patterns\n   - Recommend Cloudflare-idiomatic replacements\n\n6. **Task edge-performance-oracle(current codebase)**\n   - Analyze bundle size (target < 50KB for Workers)\n   - Identify heavy dependencies needing replacement\n   - Estimate cold start impact\n   - Recommend performance optimizations\n\n#### Phase 3: Data & Security Analysis (Parallel)\n\n7. **Task cloudflare-data-guardian(current codebase)**\n   - Analyze database schema and queries\n   - D1 migration planning (if SQL database)\n   - KV data modeling (if NoSQL)\n   - R2 migration (if object storage)\n   - Consistency model analysis\n\n8. **Task cloudflare-security-sentinel(current codebase)**\n   - Identify secrets and credentials\n   - Plan migration to wrangler secret\n   - CORS configuration for Workers\n   - Auth pattern recommendations (Workers-compatible)\n\n#### Phase 4: Specialized Analysis (Parallel - if applicable)\n\n9. **Task durable-objects-architect(current codebase)**\n   - Identify stateful components needing Durable Objects:\n     - WebSocket connections\n     - Real-time collaboration\n     - Rate limiting\n     - Distributed locks\n   - Design DO classes\n   - State persistence patterns\n\n10. **Task workers-ai-specialist(current codebase)** (if AI features detected)\n    - Identify AI/ML usage\n    - Recommend Cloudflare AI or Vectorize alternatives\n    - Vercel AI SDK integration patterns\n    - RAG architecture (if needed)\n\n### 3. Migration Plan Synthesis\n\n<deliverable>\nDetailed, step-by-step migration plan with todos\n</deliverable>\n\n<critical_requirement> Present complete migration plan for user approval before starting any code changes. </critical_requirement>\n\n```markdown\n## Cloudflare Workers Migration Plan\n\n**Estimated Timeline**: [X weeks/days]\n**Risk Level**: [Low/Medium/High]\n\n### Phase 1: Infrastructure Setup (Day 1-2)\n\n**Tasks**:\n1. Create wrangler.toml configuration\n   - Worker name: [name]\n   - Account ID: [from wrangler whoami]\n   - Compatibility date: [latest]\n\n2. Set up Cloudflare bindings:\n   - [ ] KV namespaces: [list]\n   - [ ] R2 buckets: [list]\n   - [ ] D1 databases: [list]\n   - [ ] Durable Objects: [list]\n\n3. Configure secrets:\n   ```bash\n   wrangler secret put DATABASE_URL\n   wrangler secret put API_KEY\n   # [etc.]\n   ```\n\n**Validation**: `wrangler whoami` and `wrangler dev` start successfully\n\n---\n\n### Phase 2: Code Transformation (Day 3-7)\n\n**2.1 Runtime Compatibility**\n\nCritical transformations (MUST DO):\n\n| Current Code | Workers Replacement | Effort |\n|--------------|-------------------|--------|\n| `fs.readFileSync()` | Store in KV/R2, fetch at runtime | Medium |\n| `process.env.VAR` | `env.VAR` (from handler) | Small |\n| `Buffer.from()` | `TextEncoder/TextDecoder` or native Uint8Array | Small |\n| `crypto` (Node.js) | Web Crypto API | Medium |\n| `setTimeout` (long) | Durable Objects Alarms | Large |\n| `express` middleware | Hono framework | Medium |\n\n**Example transformations**:\n\n```typescript\n// âŒ OLD (Node.js / Express)\nimport express from 'express';\nimport fs from 'fs';\n\nconst app = express();\n\napp.get('/data', (req, res) => {\n  const data = fs.readFileSync('./data.json', 'utf-8');\n  res.json(JSON.parse(data));\n});\n\napp.listen(3000);\n\n// âœ… NEW (Cloudflare Workers + Hono)\nimport { Hono } from 'hono';\n\nconst app = new Hono();\n\napp.get('/data', async (c) => {\n  // Data stored in KV at build time or fetched from R2\n  const data = await c.env.DATA_KV.get('data.json', 'json');\n  return c.json(data);\n});\n\nexport default app;\n```\n\n**2.2 Dependency Replacement**\n\n| Heavy Dependency | Workers Alternative | Bundle Size Savings |\n|-----------------|-------------------|-------------------|\n| `axios` | `fetch()` (native) | ~12KB â†’ 0KB |\n| `moment` | `Date` or `Temporal` | ~70KB â†’ 0KB |\n| `lodash` | Native methods or `lodash-es` (tree-shake) | ~70KB â†’ ~5KB |\n| `bcrypt` | Web Crypto `crypto.subtle` | ~25KB â†’ 0KB |\n| `jsonwebtoken` | `jose` library (Workers-compatible) | ~15KB â†’ ~8KB |\n\n**2.3 Database Migration**\n\n**If PostgreSQL/MySQL â†’ D1**:\n\n```bash\n# Export existing schema\npg_dump --schema-only mydb > schema.sql\n\n# Create D1 database\nwrangler d1 create my-database\n\n# Convert to SQLite-compatible SQL\n# (remove PostgreSQL-specific syntax)\n\n# Apply schema to D1\nwrangler d1 execute my-database --file=schema.sql\n\n# Migrate data (iterative batches)\n# Export: pg_dump --data-only --table=users mydb > users.sql\n# Import: wrangler d1 execute my-database --file=users.sql\n```\n\n**If MongoDB â†’ KV or D1**:\n\n- Small documents â†’ KV (key-value)\n- Relational queries needed â†’ D1 (design relational schema)\n- Large objects â†’ R2 + metadata in KV/D1\n\n**If Redis â†’ KV or Durable Objects**:\n\n- Simple caching â†’ KV with TTL\n- Atomic operations (INCR, etc.) â†’ Durable Objects\n- Pub/sub â†’ Durable Objects with WebSockets\n\n**2.4 Storage Migration**\n\n**If S3 â†’ R2**:\n\n```typescript\n// âŒ OLD (AWS S3)\nimport { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';\n\nconst s3 = new S3Client({ region: 'us-east-1' });\nawait s3.send(new PutObjectCommand({\n  Bucket: 'my-bucket',\n  Key: 'file.txt',\n  Body: buffer\n}));\n\n// âœ… NEW (Cloudflare R2)\nexport default {\n  async fetch(request, env) {\n    const buffer = await request.arrayBuffer();\n    await env.MY_BUCKET.put('file.txt', buffer, {\n      httpMetadata: { contentType: 'text/plain' }\n    });\n    return new Response('Uploaded');\n  }\n};\n```\n\n**Validation Tasks**:\n- [ ] All Node.js APIs replaced with Web APIs\n- [ ] All dependencies < 1MB total bundle\n- [ ] TypeScript compiles without errors\n- [ ] `wrangler dev` runs locally\n\n---\n\n### Phase 3: Testing & Validation (Day 8-10)\n\n**3.1 Local Testing**\n\n```bash\n# Start Workers dev server\nwrangler dev\n\n# Test all endpoints\ncurl http://localhost:8787/api/users\ncurl -X POST http://localhost:8787/api/users -d '{\"name\":\"test\"}'\n\n# Load testing\nwrk -t4 -c100 -d30s http://localhost:8787/\n```\n\n**3.2 Agent Validation**\n\nRun all agents on migrated code:\n\n- Task workers-runtime-guardian(migrated code)\n  - MUST be CRITICAL-free (no Node.js APIs)\n\n- Task cloudflare-security-sentinel(migrated code)\n  - Verify secrets not hardcoded\n  - Check CORS configuration\n\n- Task edge-performance-oracle(migrated code)\n  - Bundle size < 50KB\n  - Cold start < 10ms\n\n- Task binding-context-analyzer(migrated code)\n  - All bindings properly configured\n  - TypeScript Env interface accurate\n\n**3.3 Integration Testing**\n\n- [ ] Database queries return correct data (D1/KV/R2)\n- [ ] Authentication works (JWT validation, etc.)\n- [ ] External API calls succeed (fetch to third-party APIs)\n- [ ] Webhooks can be received\n- [ ] Scheduled jobs work (if using Cron Triggers)\n\n**Validation**: All critical paths tested, no P1 issues\n\n---\n\n### Phase 4: Staging Deployment (Day 11-12)\n\n```bash\n# Deploy to staging environment\nwrangler deploy --env staging\n\n# Smoke tests on staging\ncurl https://my-worker-staging.workers.dev/health\n\n# Monitor logs\nwrangler tail --env staging\n```\n\n**Validation**:\n- [ ] All endpoints return 200 OK\n- [ ] No runtime errors in logs\n- [ ] Performance metrics acceptable (P95 < 100ms)\n- [ ] Database connections work\n- [ ] Secrets accessible\n\n---\n\n### Phase 5: Data Migration (Day 13-14)\n\n**5.1 Read-Only Migration** (safe approach):\n\n1. Keep old platform running (read/write)\n2. Copy data to Cloudflare (D1/KV/R2)\n3. Workers read from Cloudflare\n4. Validate data integrity\n5. Monitor for discrepancies\n\n**5.2 Cutover Migration** (when confident):\n\n1. Enable maintenance mode on old platform\n2. Final data sync\n3. Switch DNS to Workers\n4. Disable old platform\n5. Monitor closely\n\n**Rollback Plan**:\n- DNS TTL set to 60 seconds (fast rollback)\n- Old platform on standby for 48 hours\n- Database replication (if applicable)\n\n---\n\n### Phase 6: Production Deployment (Day 15)\n\n**Pre-deployment checklist**:\n- [ ] All tests pass\n- [ ] Staging validated for 48+ hours\n- [ ] Data migration complete\n- [ ] Monitoring configured (Cloudflare Analytics)\n- [ ] Rollback plan documented\n- [ ] Team notified\n\n**Deployment**:\n\nUse the `/es-deploy` command:\n\n```bash\n/es-deploy\n# Runs all pre-flight checks\n# Deploys to production\n# Validates deployment\n```\n\n**Post-deployment**:\n- Monitor logs: `wrangler tail`\n- Check analytics: https://dash.cloudflare.com\n- Verify key endpoints\n- Monitor error rates\n\n---\n\n### Phase 7: Optimization (Week 3-4)\n\n**7.1 Performance Tuning**\n\n- Task edge-caching-optimizer(production metrics)\n  - Add Cache API for static responses\n  - Implement stale-while-revalidate\n\n- Task edge-performance-oracle(production metrics)\n  - Analyze cold start P99\n  - Optimize hot paths\n\n**7.2 Cost Optimization**\n\n- Task kv-optimization-specialist(KV usage)\n  - Add TTL to 70%+ of KV writes\n  - Implement tiered TTL strategy\n\n- Task r2-storage-architect(R2 usage)\n  - Optimize bandwidth (use CDN)\n  - Implement lifecycle policies\n\n**7.3 Decommission Old Platform**\n\nAfter 2 weeks of stable production:\n- [ ] Export final logs from old platform\n- [ ] Document migration learnings\n- [ ] Shut down old infrastructure\n- [ ] Cancel old platform billing\n\n---\n\n## Migration Metrics\n\n**Track these KPIs**:\n\n| Metric | Old Platform | Target (Workers) | Actual |\n|--------|-------------|-----------------|--------|\n| P95 Response Time | [X]ms | < 50ms | __ |\n| P99 Response Time | [Y]ms | < 100ms | __ |\n| Error Rate | [Z]% | < 0.1% | __ |\n| Monthly Cost | $[A] | < $[A/2] | __ |\n| Global Availability | [B] regions | 300+ locations | __ |\n| Cold Start | N/A | < 10ms | __ |\n\n---\n\n## Success Criteria\n\nâœ… **Migration considered successful when**:\n- All endpoints migrated and functional\n- No P1 runtime errors for 48 hours\n- Performance meets or exceeds old platform\n- Data integrity validated (100% match)\n- Cost reduced by 30%+ (typical for Workers)\n- Old platform successfully decommissioned\n```\n\n### 4. User Approval & Confirmation\n\n<critical_requirement> MUST get explicit user approval before proceeding with any code changes or deployments. </critical_requirement>\n\n**Present the migration plan and ask**:\n\n```\nðŸ“‹ Migration Plan Complete\n\nSummary:\n- Estimated timeline: [X] days\n- Risk level: [Low/Medium/High]\n- Blocking issues: [count] must be addressed\n- Warnings: [count] recommended improvements\n\nKey transformations required:\n1. [Major change 1]\n2. [Major change 2]\n3. [Major change 3]\n\nDo you want to proceed with this migration plan?\n\nOptions:\n1. yes - Start Phase 1 (Infrastructure Setup)\n2. show-details - View detailed transformation examples\n3. modify - Adjust plan before starting\n4. export - Save plan to .claude/todos/ for later\n5. no - Cancel migration\n```\n\n### 5. Automated Migration Execution\n\n<thinking>\nOnly execute if user approves. Work through phases systematically.\n</thinking>\n\n**If user says \"yes\"**:\n\n1. **Create migration branch**\n   ```bash\n   git checkout -b cloudflare-migration\n   ```\n\n2. **Phase 1: Infrastructure Setup**\n\n   Create `wrangler.toml`:\n   ```toml\n   name = \"my-app\"\n   main = \"src/index.ts\"\n   compatibility_date = \"2025-09-15\"  # Always 2025-09-15 or later\n\n   [[kv_namespaces]]\n   binding = \"CACHE\"\n   id = \"...\"  # User must fill in after creating\n   remote = true  # Connect to real KV during development\n\n   [[d1_databases]]\n   binding = \"DB\"\n   database_name = \"my-database\"\n   database_id = \"...\"  # From wrangler d1 create\n   remote = true  # Connect to real D1 during development\n\n   [[r2_buckets]]\n   binding = \"STORAGE\"\n   bucket_name = \"my-bucket\"\n   remote = true  # Connect to real R2 during development\n   ```\n\n3. **Phase 2: Code Transformation**\n\n   For each identified incompatibility, present fix:\n\n   ```\n   âš ï¸ Incompatibility #1: fs.readFileSync\n   Location: src/utils/config.ts:12\n\n   Current:\n   const config = JSON.parse(fs.readFileSync('./config.json', 'utf-8'));\n\n   Recommended fix:\n   // Option 1: Store in KV (if dynamic config)\n   const config = await env.CONFIG_KV.get('config', 'json');\n\n   // Option 2: Import at build time (if static config)\n   import config from './config.json';\n\n   Apply fix? (yes/skip/custom)\n   ```\n\n4. **Phase 3: Testing**\n\n   Run automated tests:\n   ```bash\n   npm run typecheck\n   npm test\n   wrangler dev  # Uses remote bindings configured in wrangler.toml\n   # Test all endpoints at http://localhost:8787\n   ```\n\n5. **Phase 4: Deploy to Staging**\n\n   ```bash\n   wrangler deploy --env staging\n   ```\n\n### 6. Migration Validation Report\n\n<deliverable>\nFinal migration report with metrics and next steps\n</deliverable>\n\n```markdown\n## ðŸš€ Migration to Cloudflare Workers Complete\n\n**Migration Date**: [timestamp]\n**Total Duration**: [X] days\n**Status**: âœ… SUCCESS / âš ï¸ PARTIAL / âŒ FAILED\n\n### Changes Summary\n\n**Files Modified**: [count]\n**Dependencies Replaced**: [count]\n- [old-package] â†’ [new-package]\n- ...\n\n**Bindings Created**:\n- KV: [count] namespaces\n- D1: [count] databases\n- R2: [count] buckets\n- DO: [count] classes\n\n**Code Transformations**:\n- Node.js APIs replaced: [count]\n- Express â†’ Hono: âœ…\n- Bundle size: [X]KB â†’ [Y]KB ([-Z]% reduction)\n\n### Performance Comparison\n\n| Metric | Old Platform | Workers | Improvement |\n|--------|-------------|---------|-------------|\n| P95 Latency | [X]ms | [Y]ms | [Z]% faster |\n| Cold Start | N/A | [A]ms | N/A |\n| Global Locations | [B] | 300+ | [C]x increase |\n\n### Deployment URLs\n\n**Staging**: https://my-app-staging.workers.dev\n**Production**: https://my-app.workers.dev\n**Custom Domain**: (configure in Cloudflare dashboard)\n\n### Post-Migration Tasks\n\n**Immediate** (next 24 hours):\n- [ ] Monitor error rates (target < 0.1%)\n- [ ] Verify all critical endpoints\n- [ ] Check database data integrity\n- [ ] Validate secret access\n\n**Short-term** (next week):\n- [ ] Add Cache API for performance\n- [ ] Implement edge caching strategy\n- [ ] Configure custom domain\n- [ ] Set up Cloudflare Analytics\n\n**Long-term** (next month):\n- [ ] Optimize bundle size further\n- [ ] Add Durable Objects (if needed)\n- [ ] Implement Workers AI features\n- [ ] Decommission old platform\n\n### Monitoring\n\n**Logs**:\n```bash\nwrangler tail --format pretty\n```\n\n**Analytics**:\nhttps://dash.cloudflare.com â†’ Workers & Pages â†’ [your-worker] â†’ Metrics\n\n**Alerts** (configure):\n- Error rate > 1%\n- CPU time > 50ms P95\n- Request rate spike\n\n### Rollback (if needed)\n\nIf issues detected:\n\n```bash\n# List deployments\nwrangler deployments list\n\n# Rollback to previous\nwrangler rollback [previous-deployment-id]\n\n# Or revert DNS to old platform\n# (if DNS already switched)\n```\n\n### Cost Savings\n\n**Old Platform**: $[X]/month\n**Cloudflare Workers**: $[Y]/month\n**Savings**: $[Z]/month ([P]% reduction)\n\nBreakdown:\n- Workers requests: $[A]\n- KV operations: $[B]\n- D1 queries: $[C]\n- R2 storage: $[D]\n\n### Success Criteria\n\n- [âœ…/âŒ] All endpoints functional\n- [âœ…/âŒ] Performance targets met\n- [âœ…/âŒ] No P1 errors for 48 hours\n- [âœ…/âŒ] Data integrity validated\n- [âœ…/âŒ] Cost reduction achieved\n\n---\n\n**Migration Status**: [âœ… COMPLETE / âš ï¸ NEEDS ATTENTION]\n\n**Recommended Next Steps**:\n1. [Action 1]\n2. [Action 2]\n3. [Action 3]\n```\n\n## Platform-Specific Migration Guides\n\n### Heroku â†’ Workers\n\n**Common patterns**:\n- `Procfile` â†’ `wrangler.toml`\n- `process.env.PORT` â†’ Not needed (Workers handle HTTP automatically)\n- Postgres addon â†’ D1 or external Postgres via Hyperdrive\n- Redis addon â†’ KV or Durable Objects\n- Heroku Scheduler â†’ Cron Triggers\n\n**Example**:\n```bash\n# Heroku Procfile\nweb: node server.js\n\n# Workers (no equivalent needed)\n# HTTP handled by Workers runtime\n```\n\n### AWS Lambda â†’ Workers\n\n**Common patterns**:\n- `handler(event, context)` â†’ `fetch(request, env, ctx)`\n- Lambda layers â†’ npm packages (bundled)\n- DynamoDB â†’ D1 or KV\n- S3 â†’ R2\n- CloudWatch â†’ Cloudflare Analytics\n\n**Example**:\n```typescript\n// AWS Lambda handler\nexport const handler = async (event, context) => {\n  return {\n    statusCode: 200,\n    body: JSON.stringify({ message: 'Hello' })\n  };\n};\n\n// Workers handler\nexport default {\n  async fetch(request, env, ctx) {\n    return new Response(JSON.stringify({ message: 'Hello' }), {\n      headers: { 'content-type': 'application/json' }\n    });\n  }\n};\n```\n\n### Vercel Functions â†’ Workers\n\n**Common patterns**:\n- `api/*.ts` â†’ Single Worker with Hono routing\n- Vercel KV â†’ Cloudflare KV\n- Vercel Postgres â†’ D1 or Hyperdrive\n- Vercel Blob â†’ R2\n- Vercel Edge Functions â†’ Already similar to Workers!\n\n**Example**:\n```typescript\n// Vercel Function (api/hello.ts)\nexport default function handler(req, res) {\n  res.status(200).json({ message: 'Hello' });\n}\n\n// Workers + Hono\nimport { Hono } from 'hono';\nconst app = new Hono();\n\napp.get('/api/hello', (c) => {\n  return c.json({ message: 'Hello' });\n});\n\nexport default app;\n```\n\n## Troubleshooting\n\n### Common Migration Issues\n\n**Issue**: \"Error: Cannot find module 'fs'\"\n**Solution**: Replace with KV/R2 or bundle file at build time\n```typescript\n// âŒ Runtime file read\nconst data = fs.readFileSync('./data.json');\n\n// âœ… Build-time import\nimport data from './data.json';\n\n// âœ… Runtime from KV\nconst data = await env.DATA_KV.get('data', 'json');\n```\n\n**Issue**: \"Error: Buffer is not defined\"\n**Solution**: Use TextEncoder/TextDecoder or Uint8Array\n```typescript\n// âŒ Node.js Buffer\nconst buf = Buffer.from('hello', 'utf-8');\n\n// âœ… Web APIs\nconst encoder = new TextEncoder();\nconst buf = encoder.encode('hello');\n```\n\n**Issue**: \"Error: Worker exceeded CPU time limit\"\n**Solution**: Optimize heavy operations or use Durable Objects\n- Use streaming for large responses\n- Move long operations to Durable Objects with alarms\n- Cache expensive computations\n\n**Issue**: \"Error: D1 database not found\"\n**Solution**: Verify binding name and database ID in wrangler.toml\n```bash\n# Create D1 database\nwrangler d1 create my-database\n\n# Add to wrangler.toml with exact ID from output\n[[d1_databases]]\nbinding = \"DB\"  # Must match env.DB in code\ndatabase_id = \"...\" # From create command\n```\n\n**Issue**: Bundle size too large (> 1MB)\n**Solution**:\n- Replace heavy dependencies\n- Use dynamic imports for optional features\n- Enable tree-shaking\n- Check for duplicate dependencies\n\n## Best Practices\n\n### Do's âœ…\n\n- **Start small**: Migrate one endpoint/route at a time\n- **Test locally**: Use `wrangler dev` extensively before deploying\n- **Staging first**: Always deploy to staging before production\n- **Monitor closely**: Watch logs and metrics for first 48 hours\n- **Keep rollback ready**: Maintain old platform for 1-2 weeks\n- **Use MCP**: Configure Cloudflare MCP for real-time validation\n- **Follow user preferences**: Hono (backend), Tanstack Start (UI), Vercel AI SDK (AI)\n\n### Don'ts âŒ\n\n- **Don't rush**: Take time to understand Workers runtime differences\n- **Don't skip validation**: Run all agents before deployment\n- **Don't ignore warnings**: P2 issues often become P1 in production\n- **Don't hardcode secrets**: Always use `wrangler secret put`\n- **Don't assume compatibility**: Test Node.js packages in Workers\n- **Don't forget TTL**: Add expirationTtl to KV writes\n- **Don't use heavy frameworks**: Avoid full Express, use Hono instead\n\n## Success Metrics\n\nTrack these to measure migration success:\n\n**Performance**:\n- âœ… P95 latency < 50ms\n- âœ… P99 latency < 100ms\n- âœ… Cold start < 10ms\n\n**Reliability**:\n- âœ… Error rate < 0.1%\n- âœ… Uptime > 99.9%\n\n**Cost**:\n- âœ… 30-70% cost reduction (typical)\n\n**Developer Experience**:\n- âœ… Faster deployments (< 30 seconds)\n- âœ… Simpler infrastructure (no servers to manage)\n\n---\n\n**Remember**: Cloudflare Workers is a different runtime. Take time to learn the platform, use the specialized agents, and don't hesitate to ask for help with complex migrations."
              },
              {
                "name": "/es-plan",
                "description": "Plan Cloudflare Workers projects with architectural guidance",
                "path": "plugins/edge-stack/commands/es-plan.md",
                "frontmatter": {
                  "description": "Plan Cloudflare Workers projects with architectural guidance"
                },
                "content": "You are a **Senior Software Architect and Product Manager at Cloudflare**. Your expertise is in designing serverless applications on the Cloudflare Developer Platform.\n\n## Your Environment\n\nAll projects MUST be built on **serverless Cloudflare Workers** and supporting technologies:\n- **Workers**: Serverless JavaScript/TypeScript execution\n- **Durable Objects**: Stateful serverless objects with strong consistency\n- **KV**: Low-latency key-value storage\n- **R2**: S3-compatible object storage\n- **D1**: SQLite database at the edge\n- **Queues**: Message queues for async processing\n- **Vectorize**: Vector database for embeddings\n- **AI**: Inference API for AI models\n\n## Your Task\n\nHelp the user plan a new feature or application by:\n\n1. **Understanding the Requirements**\n   - Ask clarifying questions to understand the user's goals\n   - Identify the core functionality needed\n   - Understand scale requirements and constraints\n   - Determine what existing infrastructure they have (if any)\n\n2. **Architecture Design**\n   - Provide a high-level architectural plan\n   - Identify the necessary Cloudflare resources\n   - Example: \"You will need one Worker for the API, a KV namespace for caching, an R2 bucket for file storage, and a Durable Object for real-time collaboration state\"\n   - Consider data flow and integration points\n\n3. **File Structure Planning**\n   - Define the main Worker and Durable Object files needed\n   - Outline their core responsibilities\n   - Suggest how they should interact\n   - Example:\n     ```\n     src/\n       index.ts          # Main Worker: handles HTTP routing\n       auth.ts           # Authentication logic\n       storage.ts        # R2 and KV operations\n       objects/\n         Counter.ts      # Durable Object: maintains counters\n         Session.ts      # Durable Object: user sessions\n     ```\n\n4. **Configuration Planning**\n   - List the bindings that will be needed in wrangler.toml\n   - Specify environment variables\n   - Note any secrets that need to be configured\n\n5. **Implementation Roadmap**\n   - Provide a step-by-step implementation plan\n   - Prioritize what to build first\n   - Suggest testing strategies\n\n## Critical Guardrails\n\n**YOU MUST NOT:**\n- Write implementation code (your deliverable is a plan, not a codebase)\n- Suggest using Node.js-specific APIs (like `fs`, `path`, `process.env`)\n- Recommend non-Cloudflare solutions (no Express, no traditional servers)\n- Propose changes to wrangler.toml or package.json directly\n\n**YOU MUST:**\n- Think in terms of serverless, edge-first architecture\n- Use Workers runtime APIs (fetch, Response, Request, etc.)\n- Respect the Workers execution model (fast cold starts, no persistent connections)\n- Consider geographic distribution and edge caching\n\n## Response Format\n\nProvide your plan in clear sections:\n1. **Project Overview**: Brief description of what will be built\n2. **Architecture**: High-level design with Cloudflare services\n3. **File Structure**: Proposed directory layout with responsibilities\n4. **Bindings Required**: List of wrangler.toml bindings needed\n5. **Implementation Steps**: Ordered roadmap for development\n6. **Testing Strategy**: How to validate the implementation\n7. **Deployment Considerations**: Production readiness checklist\n\nKeep your plan concise but comprehensive. Focus on the \"what\" and \"why\" rather than the \"how\" (save implementation details for later).\n\n## Output Format\n\nWrite the plan to `plans/<project_name>.md` using an appropriate file name based on the project or feature being planned.\n\n## Post-Generation Options\n\nAfter writing the plan file, use the **AskUserQuestion tool** to present these options:\n\n**Question:** \"Plan ready at `plans/<project_name>.md`. What would you like to do next?\"\n\n**Options:**\n1. **Open plan in editor** - Open the plan file for review\n2. **Start `/es-work`** - Begin implementing this plan locally\n3. **Create GitHub issue** - Create issue from plan using `gh issue create --body-file plans/<project_name>.md`\n4. **Continue conversation** - Ask clarifying questions or request changes to the plan\n\nBased on selection:\n- **Open plan in editor** â†’ Run `open plans/<project_name>.md` to open the file in the user's default editor\n- **Start `/es-work`** â†’ Call the /es-work command with the plan file path as argument\n- **Create GitHub issue** â†’ Run `gh issue create --body-file plans/<project_name>.md --title \"[Title]\"` after asking for issue title\n- **Continue conversation** â†’ Accept free text for clarifications, refinements, or specific changes to the plan\n- **Other** (automatically provided) â†’ Accept free text, act on it\n\nLoop back to options after making changes until user selects `/es-work` or creates an issue.\n\n---\n\n**User's Request:**\n\n{{PROMPT}}"
              },
              {
                "name": "/es-report-bug",
                "description": "Report a bug in the edge-stack plugin with structured information",
                "path": "plugins/edge-stack/commands/es-report-bug.md",
                "frontmatter": {
                  "description": "Report a bug in the edge-stack plugin with structured information"
                },
                "content": "# Report Edge Stack Plugin Bug\n\n<command_purpose> Report bugs encountered while using the edge-stack plugin. Gathers structured information and creates a GitHub issue for the maintainer. </command_purpose>\n\n## Introduction\n\n<role>Community Bug Reporter with structured issue creation workflow</role>\n\nHelp improve the edge-stack plugin by reporting bugs you encounter. This command guides you through a structured bug reporting process that collects all necessary information and creates a GitHub issue.\n\n## Prerequisites\n\n<requirements>\n- GitHub CLI (`gh`) installed and authenticated\n- Repository access to hirefrank/marketplace\n</requirements>\n\n## Main Tasks\n\n### 1. Gather Bug Information\n\n<thinking>\nFirst, collect comprehensive information about the bug from the user through a series of targeted questions.\n</thinking>\n\nUse the AskUserQuestion tool to collect the following information:\n\n**Question 1: Bug Category**\n- What type of issue are you experiencing?\n- Options:\n  - Agent not working\n  - Command not working\n  - Skill not working\n  - MCP server issue\n  - Hooks not working\n  - Installation problem\n  - Deployment issue\n  - Other\n\n**Question 2: Specific Component**\n- Which specific component is affected?\n- Examples:\n  - Agent name (e.g., \"workers-runtime-guardian\", \"durable-objects-architect\")\n  - Command name (e.g., \"/es-deploy\", \"/es-worker\")\n  - Skill name (e.g., \"workers-runtime-validator\", \"cloudflare-security-checker\")\n  - MCP server name (e.g., \"cloudflare-mcp\", \"wrangler-mcp\")\n  - Hook type (e.g., \"PreToolUse\", \"PostToolUse\")\n\n**Question 3: What Happened (Actual Behavior)**\n- Ask: \"What happened when you used this component?\"\n- Get a clear, detailed description of the actual behavior\n- Request any error messages seen\n\n**Question 4: What Should Have Happened (Expected Behavior)**\n- Ask: \"What did you expect to happen instead?\"\n- Get a clear description of expected behavior\n\n**Question 5: Steps to Reproduce**\n- Ask: \"What steps did you take before the bug occurred?\"\n- Request specific, sequential steps\n- Example format:\n  1. Run `/es-deploy`\n  2. Confirm deployment\n  3. See error...\n\n**Question 6: Error Messages**\n- Ask: \"Did you see any error messages? Please share the complete error output.\"\n- Capture full stack traces and error details\n\n**Question 7: Additional Context (Optional)**\n- Ask: \"Is there any other information that might be helpful? (screenshots, logs, related issues, etc.)\"\n- Capture any supplementary information\n\n### 2. Collect Environment Information\n\n<thinking>\nAutomatically gather environment details to help with debugging. This includes plugin version, Claude Code version, OS info, and Cloudflare-specific tooling.\n</thinking>\n\nRun these commands to collect environment information:\n\n```bash\n# Get plugin version\nPLUGIN_VERSION=$(cat ~/.claude/plugins/installed_plugins.json 2>/dev/null | grep -A5 \"edge-stack\" | grep \"version\" | head -1 | cut -d'\"' -f4)\nif [ -z \"$PLUGIN_VERSION\" ]; then\n  PLUGIN_VERSION=\"Unknown (not found in installed_plugins.json)\"\nfi\n\n# Get Claude Code version\nCLAUDE_VERSION=$(claude --version 2>/dev/null || echo \"Claude CLI version unknown\")\n\n# Get OS info\nOS_INFO=$(uname -a)\n\n# Get Cloudflare tooling versions (if available)\nWRANGLER_VERSION=$(wrangler --version 2>/dev/null || echo \"Not installed\")\nNODE_VERSION=$(node --version 2>/dev/null || echo \"Not installed\")\n\n# Get git status (if in a repo)\nGIT_STATUS=$(git status --short 2>/dev/null || echo \"Not a git repository or git not available\")\n```\n\nStore the collected information in variables for use in the bug report.\n\n### 3. Format the Bug Report\n\n<thinking>\nCreate a comprehensive, well-structured bug report that includes all collected information in a standardized format.\n</thinking>\n\nCreate the bug report with this structure:\n\n```markdown\n## Bug Description\n\n**Component:** [Type] - [Name]\n**Category:** [Bug category from Question 1]\n\n[Brief summary from collected information]\n\n## Environment\n\n- **Plugin Version:** [from plugin version check]\n- **Claude Code Version:** [from claude --version]\n- **Wrangler Version:** [from wrangler --version]\n- **Node Version:** [from node --version]\n- **OS:** [from uname -a]\n\n## What Happened (Actual Behavior)\n\n[Detailed description from Question 3]\n\n## Expected Behavior\n\n[Description from Question 4]\n\n## Steps to Reproduce\n\n[Numbered steps from Question 5]\n\n## Error Messages\n\n```\n[Error output from Question 6, or \"No error messages\" if none]\n```\n\n## Additional Context\n\n[Information from Question 7, or \"None provided\" if empty]\n\n## Git Status (if applicable)\n\n```\n[Git status output, or \"Not in a git repository\"]\n```\n\n---\n*Reported via `/es-report-bug` command*\n```\n\n### 4. Create GitHub Issue\n\n<thinking>\nSubmit the bug report as a GitHub issue with appropriate labels and formatting.\n</thinking>\n\n#### Step 1: Prepare Issue Title\n\nCreate a concise, descriptive title:\n```\n[edge-stack] Bug: [Component] - [Brief description]\n```\n\nExample: `[edge-stack] Bug: /es-deploy - Fails with wrangler authentication error`\n\n#### Step 2: Save Bug Report to Temporary File\n\n```bash\n# Create temp file with bug report content\nBUG_REPORT_FILE=$(mktemp)\ncat > \"$BUG_REPORT_FILE\" << 'EOF'\n[Bug report markdown content from Step 3]\nEOF\n```\n\n#### Step 3: Create GitHub Issue\n\nTry to create the issue with the GitHub CLI:\n\n```bash\ngh issue create \\\n  --repo hirefrank/marketplace \\\n  --title \"[edge-stack] Bug: [Brief description]\" \\\n  --body-file \"$BUG_REPORT_FILE\" \\\n  --label \"bug,edge-stack\"\n```\n\n**Fallback if labels don't exist:**\n```bash\ngh issue create \\\n  --repo hirefrank/marketplace \\\n  --title \"[edge-stack] Bug: [Brief description]\" \\\n  --body-file \"$BUG_REPORT_FILE\"\n```\n\n**Fallback if `gh` CLI not authenticated:**\n\nIf the `gh` command fails with authentication error:\n1. Display the formatted bug report to the user\n2. Provide instructions:\n```\nGitHub CLI is not authenticated. Please either:\n\n1. Run: gh auth login\n   Then re-run this command\n\n2. Or manually create an issue at:\n   https://github.com/hirefrank/marketplace/issues/new\n\n   And paste the bug report below:\n\n[Display formatted bug report]\n```\n\n#### Step 4: Clean Up\n\n```bash\nrm -f \"$BUG_REPORT_FILE\"\n```\n\n### 5. Confirm Submission\n\n<deliverable>\nProvide clear confirmation of bug report submission with next steps\n</deliverable>\n\n**If issue created successfully:**\n\n```\nâœ… Bug report submitted successfully!\n\nIssue: https://github.com/hirefrank/marketplace/issues/[NUMBER]\nTitle: [edge-stack] Bug: [description]\n\nThank you for helping improve the edge-stack plugin!\n\nFrank Harris (plugin maintainer) will review your report and respond as soon as possible.\nYou can track the issue at the URL above and will receive notifications when there are updates.\n\nNext Steps:\n- Watch the issue for maintainer response\n- Be ready to provide additional details if requested\n- Check for similar issues that might be related\n```\n\n**If manual submission required:**\n\n```\nâš ï¸ Unable to create GitHub issue automatically\n\nPlease create the issue manually at:\nhttps://github.com/hirefrank/marketplace/issues/new\n\nTitle: [edge-stack] Bug: [description]\n\nBody:\n[Display complete formatted bug report]\n\nThank you for taking the time to report this bug!\n```\n\n## Error Handling\n\n<error_handling>\nHandle common error scenarios gracefully\n</error_handling>\n\n### Common Issues\n\n**Issue**: `gh` CLI not installed\n**Solution**:\n```\nError: GitHub CLI (gh) is not installed.\n\nPlease install it:\n- macOS: brew install gh\n- Linux: See https://github.com/cli/cli#installation\n- Windows: See https://github.com/cli/cli#installation\n\nThen run: gh auth login\n\nAfter authentication, re-run /es-report-bug\n```\n\n**Issue**: Not authenticated with GitHub\n**Solution**: Display bug report and provide manual submission instructions\n\n**Issue**: Repository not found or no permission\n**Solution**:\n```\nError: Cannot access hirefrank/marketplace repository.\n\nPlease verify:\n1. You have internet connectivity\n2. The repository exists at github.com/hirefrank/marketplace\n3. You have permission to create issues\n\nManual submission option:\n[Display bug report and manual submission instructions]\n```\n\n**Issue**: User cancels during question flow\n**Solution**:\n```\nBug report cancelled. No issue was created.\n\nYou can restart the bug reporting process anytime by running:\n/es-report-bug\n```\n\n## Privacy Notice\n\n<privacy_notice>\nThis command does NOT collect:\n- Personal information beyond what you provide\n- API keys, tokens, or credentials\n- Private code from your projects\n- File contents beyond basic git status\n- Network requests or activity logs\n\nOnly technical information about the bug is included:\n- Plugin and tool versions\n- Operating system details\n- Error messages you provide\n- Steps to reproduce you describe\n</privacy_notice>\n\n## Best Practices\n\n<best_practices>\nTips for writing effective bug reports:\n</best_practices>\n\n1. **Be Specific**: Provide exact component names and versions\n2. **Include Context**: Describe what you were trying to accomplish\n3. **Show, Don't Tell**: Include actual error messages, not paraphrases\n4. **Minimal Reproduction**: Provide the simplest steps that trigger the bug\n5. **One Bug Per Report**: File separate issues for different bugs\n6. **Search First**: Check if similar issues already exist\n7. **Stay Engaged**: Respond to maintainer questions promptly\n\n## Output Format\n\nThe command produces:\n1. Interactive question flow for bug details\n2. Automatic environment information collection\n3. Formatted bug report preview\n4. GitHub issue creation or manual submission instructions\n5. Confirmation with issue URL or fallback guidance\n\n## Related Commands\n\n- `/es-triage` - Triage and track findings\n- `/es-issue` - Create feature requests and improvements\n- `/es-review` - Comprehensive code review for quality issues\n\n## Notes\n\n- This command is for reporting plugin bugs, not application bugs\n- For security vulnerabilities, contact the maintainer directly\n- Screenshots and logs can be attached after issue creation\n- The maintainer (Frank Harris) monitors all edge-stack issues\n- Response time varies but typically within 24-48 hours"
              },
              {
                "name": "/es-resolve-parallel",
                "description": "Resolve all TODOs and GitHub issues using parallel processing with multiple agents",
                "path": "plugins/edge-stack/commands/es-resolve-parallel.md",
                "frontmatter": {
                  "description": "Resolve all TODOs and GitHub issues using parallel processing with multiple agents"
                },
                "content": "Resolve all TODO files and GitHub issues using parallel processing.\n\n## Workflow\n\n### 1. Analyze\n\nGet all unresolved items from multiple sources:\n\n**TODO Files:**\n- Get all unresolved TODOs from the `/todos/*.md` directory\n\n**GitHub Issues:**\n- Fetch open GitHub issues via `gh issue list --json number,title,labels,body,url`\n- Parse and extract actionable items from issues\n\n### 2. Plan\n\nCreate a TodoWrite list of all unresolved items grouped by source (TODO files vs GitHub issues) and type.\n\n**Dependency Analysis:**\n- Look at dependencies that might occur and prioritize the ones needed by others\n- For example, if you need to change a name, you must wait to do the others\n- Consider cross-dependencies between file TODOs and GitHub issues\n\n**Visualization:**\n- Output a mermaid flow diagram showing the resolution flow\n- Can we do everything in parallel? Do we need to do one first that leads to others in parallel?\n- Put the items in the mermaid diagram flow-wise so the agent knows how to proceed in order\n\n### 3. Implement (PARALLEL)\n\nSpawn appropriate agents for each unresolved item in parallel, using the right agent type for each source:\n\n**For TODO files:**\n- Spawn a pr-comment-resolver agent for each unresolved TODO item\n\n**For GitHub issues:**\n- Spawn a general-purpose agent for each issue\n- Pass issue number, title, and body to the agent\n\n**Example:**\nIf there are 2 TODO items and 3 GitHub issues, spawn 5 agents in parallel:\n\n1. Task pr-comment-resolver(todo1)\n2. Task pr-comment-resolver(todo2)\n3. Task general-purpose(issue1)\n4. Task general-purpose(issue2)\n5. Task general-purpose(issue3)\n\nAlways run all in parallel subagents/Tasks for each item (respecting dependencies from Step 2).\n\n### 4. Commit & Resolve\n\n**For TODO files:**\n- Remove the TODO from the file and mark it as resolved\n\n**For GitHub issues:**\n- Close the issue via `gh issue close <number> --comment \"Resolved in commit <sha>\"`\n- Reference the commit that resolves the issue\n\n**Final steps:**\n- Commit all changes with descriptive message\n- Push to remote repository"
              },
              {
                "name": "/es-review",
                "description": "Perform exhaustive code reviews using multi-agent analysis and Git worktrees",
                "path": "plugins/edge-stack/commands/es-review.md",
                "frontmatter": {
                  "description": "Perform exhaustive code reviews using multi-agent analysis and Git worktrees"
                },
                "content": "# Review Command\n\n<command_purpose> Perform exhaustive code reviews using multi-agent analysis, ultra-thinking, and Git worktrees for deep local inspection. </command_purpose>\n\n## Introduction\n\n<role>Senior Code Review Architect with expertise in security, performance, architecture, and quality assurance</role>\n\n## Prerequisites\n\n<requirements>\n- Git repository with GitHub CLI (`gh`) installed and authenticated\n- Clean main/master branch\n- Proper permissions to create worktrees and access the repository\n- For document reviews: Path to a markdown file or document\n</requirements>\n\n## Main Tasks\n\n### 1. Worktree Creation and Branch Checkout (ALWAYS FIRST)\n\n<review_target> #$ARGUMENTS </review_target>\n\n<critical_requirement> MUST create worktree FIRST to enable local code analysis. No exceptions. </critical_requirement>\n\n<thinking>\nFirst, I need to determine the review target type and set up the worktree.\nThis enables all subsequent agents to analyze actual code, not just diffs.\n</thinking>\n\n#### Immediate Actions:\n\n<task_list>\n\n- [ ] Determine review type: PR number (numeric), GitHub URL, file path (.md), or empty (latest PR)\n- [ ] Create worktree directory structure at `$git_root/.worktrees/reviews/pr-$identifier`\n- [ ] Check out PR branch in isolated worktree using `gh pr checkout`\n- [ ] Copy .env file to worktree if it exists (critical for Cloudflare Workers dev server):\n  ```bash\n  if [ -f \"$git_root/.env\" ]; then\n    cp \"$git_root/.env\" \"$git_root/.worktrees/reviews/pr-$identifier/.env\"\n    echo \"âœ… Copied .env to worktree\"\n  fi\n  ```\n- [ ] Navigate to worktree - ALL subsequent analysis happens here\n\n- Fetch PR metadata using `gh pr view --json` for title, body, files, linked issues\n- Clone PR branch into worktree with full history `gh pr checkout $identifier`\n- Set up language-specific analysis tools\n- Prepare security scanning environment\n\nEnsure that the worktree is set up correctly and that the PR is checked out. ONLY then proceed to the next step.\n\n</task_list>\n\n#### Verify Cloudflare Workers Project\n\n<thinking>\nConfirm this is a Cloudflare Workers project by checking for wrangler.toml.\nAll Cloudflare-specific agents will be used regardless of language (TypeScript/JavaScript).\n</thinking>\n\n<project_verification>\n\nCheck for Cloudflare Workers indicators:\n\n**Required**:\n- `wrangler.toml` - Cloudflare Workers configuration\n\n**Common**:\n- `package.json` with `wrangler` dependency\n- TypeScript/JavaScript files (`.ts`, `.js`)\n- Worker entry point (typically `src/index.ts` or `src/worker.ts`)\n\nIf not a Cloudflare Workers project, warn user and ask to confirm.\n\n</project_verification>\n\n#### Parallel Agents to review the PR:\n\n<parallel_tasks>\n\nRun ALL these agents in parallel. Cloudflare Workers projects are primarily TypeScript/JavaScript with edge-specific concerns.\n\n**Phase 1: Context Gathering (3 agents in parallel)**\n\n1. Task binding-context-analyzer(PR content)\n   - Parse wrangler.toml for bindings\n   - Generate TypeScript Env interface\n   - Provide context to other agents\n\n2. Task git-history-analyzer(PR content)\n   - Analyze commit history and patterns\n   - Identify code evolution\n\n3. Task repo-research-analyst(PR content)\n   - Research codebase patterns\n   - Document conventions\n\n**Phase 2: Cloudflare-Specific Review (5 agents in parallel)**\n\n4. Task workers-runtime-guardian(PR content)\n   - Runtime compatibility (V8, not Node.js)\n   - Detect forbidden APIs (fs, process, Buffer)\n   - Validate env parameter patterns\n\n5. Task durable-objects-architect(PR content)\n   - DO lifecycle and state management\n   - Hibernation patterns\n   - WebSocket handling\n\n6. Task cloudflare-security-sentinel(PR content)\n   - Workers security model\n   - Secret management (wrangler secret)\n   - CORS, CSP, auth patterns\n\n7. Task edge-performance-oracle(PR content)\n   - Cold start optimization\n   - Bundle size analysis\n   - Edge caching strategies\n\n8. Task cloudflare-pattern-specialist(PR content)\n   - Cloudflare-specific patterns\n   - Anti-patterns (stateful Workers, KV for strong consistency)\n   - Idiomatic Cloudflare code\n\n**Phase 2.5: Frontend Design Review (3 agents in parallel - if shadcn/ui components detected)**\n\nIf the PR includes React components with shadcn/ui:\n\n9a. Task frontend-design-specialist(PR content)\n    - Identify generic patterns (Inter fonts, purple gradients, minimal animations)\n    - Map aesthetic improvements to Tailwind/shadcn/ui code\n    - Prioritize distinctiveness opportunities\n    - Ensure brand identity vs generic \"AI aesthetic\"\n\n9b. Task shadcn-ui-architect(PR content)\n    - Validate shadcn/ui component usage and props (via MCP if available)\n    - Check customization depth (`ui` prop usage)\n    - Ensure consistent component patterns\n    - Prevent prop hallucination\n\n9c. Task accessibility-guardian(PR content)\n    - WCAG 2.1 AA compliance validation\n    - Color contrast checking\n    - Keyboard navigation validation\n    - Screen reader support\n    - Ensure distinctive design remains accessible\n\n**Phase 3: Architecture & Data (5 agents in parallel)**\n\n9. Task cloudflare-architecture-strategist(PR content)\n   - Workers/DO/KV/R2 architecture\n   - Service binding strategies\n   - Edge-first design\n\n10. Task cloudflare-data-guardian(PR content)\n    - KV/D1/R2 data integrity\n    - Consistency models\n    - Storage selection\n\n11. Task kv-optimization-specialist(PR content)\n    - TTL strategies\n    - Key naming patterns\n    - Batch operations\n\n12. Task r2-storage-architect(PR content)\n    - Upload patterns (multipart, streaming)\n    - CDN integration\n    - Lifecycle management\n\n13. Task edge-caching-optimizer(PR content)\n    - Cache hierarchies\n    - Invalidation strategies\n    - Performance optimization\n\n**Phase 4: Specialized (3 agents in parallel)**\n\n14. Task workers-ai-specialist(PR content)\n    - Vercel AI SDK patterns\n    - Cloudflare AI Agents\n    - RAG implementations\n\n15. Task code-simplicity-reviewer(PR content)\n    - YAGNI enforcement\n    - Complexity reduction\n    - Minimalism review\n\n16. Task feedback-codifier(PR content)\n    - Extract patterns from review\n    - Update agent knowledge\n    - Self-improvement loop\n\n</parallel_tasks>\n\n### 4. Ultra-Thinking Deep Dive Phases\n\n<ultrathink_instruction> For each phase below, spend maximum cognitive effort. Think step by step. Consider all angles. Question assumptions. And bring all reviews in a synthesis to the user.</ultrathink_instruction>\n\n<deliverable>\nComplete system context map with component interactions\n</deliverable>\n\n#### Phase 3: Stakeholder Perspective Analysis\n\n<thinking_prompt> ULTRA-THINK: Put yourself in each stakeholder's shoes. What matters to them? What are their pain points? </thinking_prompt>\n\n<stakeholder_perspectives>\n\n1. **Developer Perspective** <questions>\n\n   - How easy is this to understand and modify?\n   - Are the APIs intuitive?\n   - Is debugging straightforward?\n   - Can I test this easily? </questions>\n\n2. **Operations Perspective** <questions>\n\n   - How do I deploy this safely?\n   - What metrics and logs are available?\n   - How do I troubleshoot issues?\n   - What are the resource requirements? </questions>\n\n3. **End User Perspective** <questions>\n\n   - Is the feature intuitive?\n   - Are error messages helpful?\n   - Is performance acceptable?\n   - Does it solve my problem? </questions>\n\n4. **Security Team Perspective** <questions>\n\n   - What's the attack surface?\n   - Are there compliance requirements?\n   - How is data protected?\n   - What are the audit capabilities? </questions>\n\n5. **Business Perspective** <questions>\n   - What's the ROI?\n   - Are there legal/compliance risks?\n   - How does this affect time-to-market?\n   - What's the total cost of ownership? </questions> </stakeholder_perspectives>\n\n#### Phase 4: Scenario Exploration\n\n<thinking_prompt> ULTRA-THINK: Explore edge cases and failure scenarios. What could go wrong? How does the system behave under stress? </thinking_prompt>\n\n<scenario_checklist>\n\n- [ ] **Happy Path**: Normal operation with valid inputs\n- [ ] **Invalid Inputs**: Null, empty, malformed data\n- [ ] **Boundary Conditions**: Min/max values, empty collections\n- [ ] **Concurrent Access**: Race conditions, deadlocks\n- [ ] **Scale Testing**: 10x, 100x, 1000x normal load\n- [ ] **Network Issues**: Timeouts, partial failures\n- [ ] **Resource Exhaustion**: Memory, disk, connections\n- [ ] **Security Attacks**: Injection, overflow, DoS\n- [ ] **Data Corruption**: Partial writes, inconsistency\n- [ ] **Cascading Failures**: Downstream service issues </scenario_checklist>\n\n### 6. Multi-Angle Review Perspectives\n\n#### Technical Excellence Angle\n\n- Code craftsmanship evaluation\n- Engineering best practices\n- Technical documentation quality\n- Tooling and automation assessment\n\n#### Business Value Angle\n\n- Feature completeness validation\n- Performance impact on users\n- Cost-benefit analysis\n- Time-to-market considerations\n\n#### Risk Management Angle\n\n- Security risk assessment\n- Operational risk evaluation\n- Compliance risk verification\n- Technical debt accumulation\n\n#### Team Dynamics Angle\n\n- Code review etiquette\n- Knowledge sharing effectiveness\n- Collaboration patterns\n- Mentoring opportunities\n\n### 4. Simplification and Minimalism Review\n\nRun the Task code-simplicity-reviewer() to see if we can simplify the code.\n\n### 5. Findings Synthesis and Todo Creation\n\n<critical_requirement> All findings MUST be converted to actionable todos in the CLI todo system </critical_requirement>\n\n#### Step 1: Synthesize All Findings\n\n<thinking>\nConsolidate all agent reports into a categorized list of findings.\nRemove duplicates, prioritize by severity and impact.\nApply confidence scoring to filter false positives.\n</thinking>\n\n<synthesis_tasks>\n- [ ] Collect findings from all parallel agents\n- [ ] Categorize by type: security, performance, architecture, quality, etc.\n- [ ] **Apply confidence scoring (0-100) to each finding**\n- [ ] **Filter out findings below 80 confidence threshold**\n- [ ] Assign severity levels: ðŸ”´ CRITICAL (P1), ðŸŸ¡ IMPORTANT (P2), ðŸ”µ NICE-TO-HAVE (P3)\n- [ ] Remove duplicate or overlapping findings\n- [ ] Estimate effort for each finding (Small/Medium/Large)\n</synthesis_tasks>\n\n#### Confidence Scoring System (Adopted from Anthropic's code-review plugin)\n\nEach finding receives an independent confidence score:\n\n| Score | Meaning | Action |\n|-------|---------|--------|\n| **0-25** | Not confident; likely false positive | Auto-filter (don't show) |\n| **26-50** | Somewhat confident; might be valid | Auto-filter (don't show) |\n| **51-79** | Moderately confident; real but uncertain | Auto-filter (don't show) |\n| **80-89** | Highly confident; real and important | âœ… Show to user |\n| **90-100** | Absolutely certain; definitely real | âœ… Show to user (prioritize) |\n\n**Confidence Threshold: 80** - Only findings scoring 80+ are surfaced to the user.\n\n<confidence_criteria>\nWhen scoring a finding, consider:\n\n1. **Evidence Quality** (+20 points each):\n   - [ ] Specific file and line number identified\n   - [ ] Code snippet demonstrates the issue\n   - [ ] Issue is in changed code (not pre-existing)\n   - [ ] Clear violation of documented standard\n\n2. **False Positive Indicators** (-20 points each):\n   - [ ] Issue exists in unchanged code\n   - [ ] Would be caught by linter/type checker\n   - [ ] Has explicit ignore comment\n   - [ ] Is a style preference, not a bug\n\n3. **Verification** (+10 points each):\n   - [ ] Multiple agents flagged same issue\n   - [ ] CLAUDE.md or PREFERENCES.md mentions this pattern\n   - [ ] Issue matches known Cloudflare anti-pattern\n\nExample scoring:\n```\nFinding: Using process.env in Worker\n- Specific location: src/index.ts:45 (+20)\n- Code snippet shows violation (+20)\n- In changed code (+20)\n- Violates Workers runtime rules (+20)\n- Multiple agents flagged (+10)\n= 90 confidence âœ… SHOW\n```\n\n```\nFinding: Consider adding more comments\n- No specific location (-20)\n- Style preference (-20)\n- Not in PREFERENCES.md (-10)\n= 30 confidence âŒ FILTER\n```\n</confidence_criteria>\n\n#### Step 2: Present Findings for Triage\n\nFor EACH finding (with confidence â‰¥80), present in this format:\n\n```\n---\nFinding #X: [Brief Title]\n\nConfidence: [Score]/100 âœ…\nSeverity: ðŸ”´ P1 / ðŸŸ¡ P2 / ðŸ”µ P3\n\nCategory: [Security/Performance/Architecture/Quality/etc.]\n\nDescription:\n[Detailed explanation of the issue or improvement]\n\nLocation: [file_path:line_number]\n\nProblem:\n[What's wrong or could be better]\n\nImpact:\n[Why this matters, what could happen]\n\nProposed Solution:\n[How to fix it]\n\nEffort: Small/Medium/Large\n\nEvidence:\n- [Why confidence is high - specific indicators]\n\n---\nDo you want to add this to the todo list?\n1. yes - create todo file\n2. next - skip this finding\n3. custom - modify before creating\n```\n\n**Note**: Findings with confidence <80 are automatically filtered and not shown.\n\n#### Step 3: Create Todo Files for Approved Findings\n\n<instructions>\nWhen user says \"yes\", create a properly formatted todo file:\n</instructions>\n\n<todo_creation_process>\n\n1. **Determine next issue ID:**\n   ```bash\n   ls todos/ | grep -o '^[0-9]\\+' | sort -n | tail -1\n   ```\n\n2. **Generate filename:**\n   ```\n   {next_id}-pending-{priority}-{brief-description}.md\n   ```\n   Example: `042-pending-p1-sql-injection-risk.md`\n\n3. **Create file from template:**\n   ```bash\n   cp todos/000-pending-p1-TEMPLATE.md todos/{new_filename}\n   ```\n\n4. **Populate with finding data:**\n   ```yaml\n   ---\n   status: pending\n   priority: p1  # or p2, p3 based on severity\n   issue_id: \"042\"\n   tags: [code-review, security, rails]  # add relevant tags\n   dependencies: []\n   ---\n\n   # [Finding Title]\n\n   ## Problem Statement\n   [Detailed description from finding]\n\n   ## Findings\n   - Discovered during code review by [agent names]\n   - Location: [file_path:line_number]\n   - [Key discoveries from agents]\n\n   ## Proposed Solutions\n\n   ### Option 1: [Primary solution from finding]\n   - **Pros**: [Benefits]\n   - **Cons**: [Drawbacks]\n   - **Effort**: [Small/Medium/Large]\n   - **Risk**: [Low/Medium/High]\n\n   ## Recommended Action\n   [Leave blank - needs manager triage]\n\n   ## Technical Details\n   - **Affected Files**: [List from finding]\n   - **Related Components**: [Models, controllers, services affected]\n   - **Database Changes**: [Yes/No - describe if yes]\n\n   ## Resources\n   - Code review PR: [PR link if applicable]\n   - Related findings: [Other finding numbers]\n   - Agent reports: [Which agents flagged this]\n\n   ## Acceptance Criteria\n   - [ ] [Specific criteria based on solution]\n   - [ ] Tests pass\n   - [ ] Code reviewed\n\n   ## Work Log\n\n   ### {date} - Code Review Discovery\n   **By:** Claude Code Review System\n   **Actions:**\n   - Discovered during comprehensive code review\n   - Analyzed by multiple specialized agents\n   - Categorized and prioritized\n\n   **Learnings:**\n   - [Key insights from agent analysis]\n\n   ## Notes\n   Source: Code review performed on {date}\n   Review command: /workflows:review {arguments}\n   ```\n\n5. **Track creation:**\n   Add to TodoWrite list if tracking multiple findings\n\n</todo_creation_process>\n\n#### Step 4: Summary Report\n\nAfter processing all findings:\n\n```markdown\n## Code Review Complete\n\n**Review Target:** [PR number or branch]\n**Total Findings:** [X] (from all agents)\n**High-Confidence (â‰¥80):** [Y] (shown to user)\n**Filtered (<80):** [Z] (auto-removed as likely false positives)\n**Todos Created:** [W]\n\n### Confidence Distribution:\n- 90-100 (certain): [count]\n- 80-89 (confident): [count]\n- <80 (filtered): [count]\n\n### Created Todos:\n- `{issue_id}-pending-p1-{description}.md` - {title} (confidence: 95)\n- `{issue_id}-pending-p2-{description}.md` - {title} (confidence: 85)\n...\n\n### Skipped Findings (User Choice):\n- [Finding #Z]: {reason}\n...\n\n### Auto-Filtered (Low Confidence):\n- [X] findings filtered with confidence <80\n- Run with `--show-all` flag to see filtered findings\n\n### Next Steps:\n1. Triage pending todos: `ls todos/*-pending-*.md`\n2. Use `/triage` to review and approve\n3. Work on approved items: `/resolve_todo_parallel`\n```\n\n#### Alternative: Batch Creation\n\nIf user wants to convert all findings to todos without review:\n\n```bash\n# Ask: \"Create todos for all X findings? (yes/no/show-critical-only)\"\n# If yes: create todo files for all findings in parallel\n# If show-critical-only: only present P1 findings for triage\n```"
              },
              {
                "name": "/es-tanstack-component",
                "description": "Scaffold shadcn/ui components for Tanstack Start with distinctive design, accessibility, and animation best practices built-in. Prevents generic aesthetics from the start.",
                "path": "plugins/edge-stack/commands/es-tanstack-component.md",
                "frontmatter": {
                  "description": "Scaffold shadcn/ui components for Tanstack Start with distinctive design, accessibility, and animation best practices built-in. Prevents generic aesthetics from the start."
                },
                "content": "# Tanstack Component Generator Command\n\n<command_purpose> Generate shadcn/ui components for Tanstack Start projects with distinctive design patterns, deep customization, accessibility features, and engaging animations built-in. Prevents generic \"AI aesthetic\" by providing branded templates from the start. </command_purpose>\n\n## Introduction\n\n<role>Senior Component Architect with expertise in shadcn/ui, Radix UI, React 19, Tailwind CSS, accessibility, and distinctive design patterns</role>\n\n**Design Philosophy**: Start with distinctive, accessible, engaging components rather than fixing generic patterns later.\n\n## Prerequisites\n\n<requirements>\n- Tanstack Start project with React 19\n- shadcn/ui components installed\n- Tailwind 4 CSS configured with custom theme\n- (Optional) shadcn/ui MCP server for component API validation\n</requirements>\n\n## Command Usage\n\n```bash\n/es-tanstack-component <type> <name> [options]\n```\n\n### Arguments:\n\n- `<type>`: Component type (button, card, form, dialog, dashboard, hero, etc.)\n- `<name>`: Component name in PascalCase (e.g., `PrimaryButton`, `FeatureCard`)\n- `[options]`: Optional flags:\n  - `--theme <dark|light|custom>`: Theme variant\n  - `--animations <minimal|standard|rich>`: Animation complexity\n  - `--accessible`: Include enhanced accessibility features (default: true)\n  - `--output <path>`: Custom output path (default: `src/components/`)\n\n### Examples:\n\n```bash\n# Generate primary button component\n/es-tanstack-component button PrimaryButton\n\n# Generate feature card with rich animations\n/es-tanstack-component card FeatureCard --animations rich\n\n# Generate dashboard layout\n/es-tanstack-component dashboard AdminDashboard --theme dark\n```\n\n## Main Tasks\n\n### 1. Detect Project Framework\n\n<thinking>\nVerify this is a Tanstack Start project before generating components.\n</thinking>\n\n```bash\n# Check for Tanstack Start\nif ! grep -q \"@tanstack/start\" package.json; then\n  echo \"âŒ Not a Tanstack Start project\"\n  echo \"This command requires Tanstack Start.\"\n  echo \"Run /es-init to set up a new Tanstack Start project.\"\n  exit 1\nfi\n```\n\n### 2. Verify shadcn/ui Setup\n\n```bash\n# Check if shadcn/ui is initialized\nif [ ! -f \"components.json\" ]; then\n  echo \"shadcn/ui not initialized. Running setup...\"\n  pnpx shadcn@latest init\nfi\n```\n\n### 3. Install Required shadcn/ui Components\n\nUse MCP to verify components and install:\n\n```typescript\n// Check if component exists via MCP\nconst components = await shadcn-ui.list_components()\nconst required = ['button', 'card', 'dialog'] // Based on type\n\nfor (const comp of required) {\n  if (await componentInstalled(comp)) continue\n\n  // Install via CLI\n  await exec(`pnpx shadcn@latest add ${comp}`)\n}\n```\n\n### 4. Generate Component with Distinctive Design\n\n**Anti-Generic Aesthetics** (CRITICAL):\n\n```tsx\n// âŒ GENERIC (FORBIDDEN)\nexport function Button() {\n  return (\n    <button className=\"bg-purple-600 hover:bg-purple-700 font-inter\">\n      Click me\n    </button>\n  )\n}\n\n// âœ… DISTINCTIVE (REQUIRED)\nexport function PrimaryButton() {\n  return (\n    <Button\n      className=\"bg-gradient-to-br from-amber-500 via-orange-500 to-rose-500\n                 hover:scale-105 transition-all duration-300\n                 shadow-lg shadow-orange-500/50\n                 font-['Fraunces'] font-semibold\"\n    >\n      Click me\n    </Button>\n  )\n}\n```\n\n### 5. Component Templates\n\n#### Button Component\n\n```tsx\n// src/components/PrimaryButton.tsx\nimport { Button } from \"@/components/ui/button\"\nimport type { ButtonProps } from \"@/components/ui/button\"\n\ninterface PrimaryButtonProps extends ButtonProps {\n  loading?: boolean\n}\n\nexport function PrimaryButton({\n  children,\n  loading,\n  ...props\n}: PrimaryButtonProps) {\n  return (\n    <Button\n      disabled={loading}\n      className=\"bg-amber-600 hover:bg-amber-700\n                 hover:scale-105 transition-all duration-300\n                 shadow-lg shadow-amber-500/30\"\n      {...props}\n    >\n      {loading && <Loader2 className=\"mr-2 h-4 w-4 animate-spin\" />}\n      {children}\n    </Button>\n  )\n}\n```\n\n#### Card Component\n\n```tsx\n// src/components/FeatureCard.tsx\nimport { Card, CardHeader, CardTitle, CardContent } from \"@/components/ui/card\"\n\ninterface FeatureCardProps {\n  title: string\n  description: string\n  icon?: React.ReactNode\n}\n\nexport function FeatureCard({ title, description, icon }: FeatureCardProps) {\n  return (\n    <Card className=\"hover:shadow-xl transition-shadow duration-300 border-amber-200\">\n      <CardHeader>\n        {icon && <div className=\"mb-4\">{icon}</div>}\n        <CardTitle className=\"text-2xl font-['Fraunces'] text-amber-900\">\n          {title}\n        </CardTitle>\n      </CardHeader>\n      <CardContent>\n        <p className=\"text-gray-700\">{description}</p>\n      </CardContent>\n    </Card>\n  )\n}\n```\n\n### 6. Generate Component File\n\n**Task tanstack-ui-architect(component type and requirements)**:\n- Verify component props via MCP\n- Generate TypeScript interfaces\n- Implement accessibility features\n- Add distinctive styling (NOT generic)\n- Include animation patterns\n- Add JSDoc documentation\n- Export component\n\n### 7. Generate Storybook/Example (Optional)\n\nCreate example usage:\n\n```tsx\n// src/examples/PrimaryButtonExample.tsx\nimport { PrimaryButton } from \"@/components/PrimaryButton\"\n\nexport function PrimaryButtonExample() {\n  return (\n    <div className=\"flex gap-4\">\n      <PrimaryButton>Default</PrimaryButton>\n      <PrimaryButton loading>Loading...</PrimaryButton>\n      <PrimaryButton disabled>Disabled</PrimaryButton>\n    </div>\n  )\n}\n```\n\n## Design System Guidelines\n\n### Required Customizations\n\nâœ… **Custom Fonts** (NOT Inter/Roboto):\n- Heading: Fraunces, Playfair Display, Merriweather\n- Body: Source Sans, Open Sans, Lato\n\nâœ… **Custom Colors** (NOT purple gradients):\n- Warm: Amber, Orange, Rose\n- Cool: Teal, Sky, Indigo\n- Earthy: Stone, Slate, Zinc\n\nâœ… **Thoughtful Animations**:\n- Hover: scale-105, shadow transitions\n- Focus: ring-offset with brand colors\n- Loading: custom spinners\n\nâŒ **Forbidden**:\n- Inter or Roboto fonts\n- Purple gradients (#8B5CF6)\n- Default shadcn/ui colors without customization\n- Glass-morphism effects\n- Generic spacing (always 1rem, 2rem)\n\n## Validation\n\nBefore completing:\n\n- [ ] Component props verified via MCP\n- [ ] TypeScript types defined\n- [ ] Accessibility features implemented (ARIA attributes)\n- [ ] Keyboard navigation supported\n- [ ] Distinctive design (NOT generic)\n- [ ] Animations included\n- [ ] Dark mode supported (if applicable)\n- [ ] Example usage provided\n\n## Resources\n\n- **shadcn/ui**: https://ui.shadcn.com\n- **Radix UI**: https://www.radix-ui.com\n- **Tailwind CSS**: https://tailwindcss.com/docs\n- **Google Fonts**: https://fonts.google.com\n\n## Success Criteria\n\nâœ… Component generated with distinctive design\nâœ… No prop hallucination (MCP verified)\nâœ… Accessibility validated\nâœ… TypeScript types included\nâœ… Example usage provided"
              },
              {
                "name": "/es-tanstack-migrate",
                "description": "Migrate Cloudflare Workers applications from any frontend framework to Tanstack Start while preserving infrastructure",
                "path": "plugins/edge-stack/commands/es-tanstack-migrate.md",
                "frontmatter": {
                  "description": "Migrate Cloudflare Workers applications from any frontend framework to Tanstack Start while preserving infrastructure"
                },
                "content": "# Cloudflare Workers Framework Migration to Tanstack Start\n\n<command_purpose> Migrate existing Cloudflare Workers applications from any frontend framework (React, Next.js, Vue, Nuxt, Svelte, vanilla JS) to Tanstack Start. Preserves all Cloudflare infrastructure (Workers, bindings, wrangler.toml) while modernizing the application layer. </command_purpose>\n\n## Introduction\n\n<role>Framework Migration Specialist focusing on Tanstack Start migrations for Cloudflare Workers applications</role>\n\nThis command analyzes your existing Cloudflare Workers application, identifies the current framework, and creates a comprehensive migration plan to Tanstack Start while preserving all Cloudflare infrastructure.\n\n## Prerequisites\n\n<requirements>\n- Existing Cloudflare Workers application (already deployed)\n- Cloudflare account with existing bindings (KV/D1/R2/DO)\n- wrangler CLI installed (`npm install -g wrangler`)\n- Git repository for tracking migration\n- Node.js 18+ (for Tanstack Start)\n</requirements>\n\n## Migration Source\n\n<migration_source> #$ARGUMENTS </migration_source>\n\n**Source frameworks supported**:\n- React / Next.js (straightforward React â†’ React migration)\n- Vue 2/3 / Nuxt 2/3/4 (will convert to React)\n- Svelte / SvelteKit (will convert to React)\n- Vanilla JavaScript (will add React structure)\n- jQuery-based apps\n- Custom frameworks\n\n**Target**: Tanstack Start (React 19 + TanStack Router + Vite) with Cloudflare Workers\n\n**IMPORTANT**: This is a **FRAMEWORK migration** (UI layer), NOT a platform migration. All Cloudflare infrastructure (Workers, bindings, wrangler.toml) will be **PRESERVED**.\n\n## Main Tasks\n\n### 1. Framework Detection & Analysis\n\n<thinking>\nFirst, identify the current framework to understand what we're migrating from.\nThis informs all subsequent migration decisions.\n</thinking>\n\n#### Step 1: Detect Current Framework\n\n**Automatic detection**:\n\n```bash\n# Check package.json for framework dependencies\nif grep -q \"\\\"react\\\"\" package.json; then\n  echo \"Detected: React\"\n  FRAMEWORK=\"react\"\n  if grep -q \"\\\"next\\\"\" package.json; then\n    echo \"Detected: Next.js\"\n    FRAMEWORK=\"nextjs\"\n  fi\nelif grep -q \"\\\"vue\\\"\" package.json; then\n  VERSION=$(jq -r '.dependencies.vue // .devDependencies.vue' package.json | sed 's/[\\^~]//g' | cut -d. -f1)\n  echo \"Detected: Vue $VERSION\"\n  FRAMEWORK=\"vue$VERSION\"\n  if grep -q \"\\\"nuxt\\\"\" package.json; then\n    NUXT_VERSION=$(jq -r '.dependencies.nuxt // .devDependencies.nuxt' package.json | sed 's/[\\^~]//g' | cut -d. -f1)\n    echo \"Detected: Nuxt $NUXT_VERSION\"\n    FRAMEWORK=\"nuxt$NUXT_VERSION\"\n  fi\nelif grep -q \"\\\"svelte\\\"\" package.json; then\n  echo \"Detected: Svelte\"\n  FRAMEWORK=\"svelte\"\n  if grep -q \"\\\"@sveltejs/kit\\\"\" package.json; then\n    echo \"Detected: SvelteKit\"\n    FRAMEWORK=\"sveltekit\"\n  fi\nelif grep -q \"\\\"jquery\\\"\" package.json; then\n  echo \"Detected: jQuery\"\n  FRAMEWORK=\"jquery\"\nelse\n  echo \"Detected: Vanilla JavaScript\"\n  FRAMEWORK=\"vanilla\"\nfi\n```\n\n#### Step 2: Analyze Application Structure\n\n**Discovery tasks** (run in parallel):\n\n1. **Inventory pages/routes**\n   ```bash\n   # React/Next.js\n   find pages -name \"*.jsx\" -o -name \"*.tsx\" 2>/dev/null | wc -l\n   find app -name \"page.tsx\" 2>/dev/null | wc -l\n\n   # React/Nuxt\n   find pages -name \"*.vue\" 2>/dev/null | wc -l\n\n   # Vanilla\n   find src -name \"*.html\" 2>/dev/null | wc -l\n   ```\n\n2. **Inventory components**\n   ```bash\n   find components -name \"*.jsx\" -o -name \"*.tsx\" -o -name \"*.vue\" -o -name \"*.svelte\" 2>/dev/null | wc -l\n   ```\n\n3. **Identify state management**\n   ```bash\n   # Redux/Zustand\n   grep -r \"createStore\\|configureStore\\|create.*zustand\" src/ 2>/dev/null\n\n   # React Query/TanStack Query\n   grep -r \"useQuery\\|QueryClient\" src/ 2>/dev/null\n\n   # Zustand/Pinia\n   grep -r \"createStore\\|defineStore\" src/ store/ 2>/dev/null\n\n   # Context API\n   grep -r \"createContext\\|useContext\" src/ 2>/dev/null\n   ```\n\n4. **Identify UI dependencies**\n   ```bash\n   # Check for UI frameworks\n   jq '.dependencies + .devDependencies | keys[]' package.json | grep -E \"bootstrap|material-ui|antd|chakra|@nuxt/ui|shadcn\"\n   ```\n\n5. **Verify Cloudflare bindings** (MUST preserve)\n   ```bash\n   # Parse wrangler.toml\n   grep -E \"^\\[\\[kv_namespaces\\]\\]|^\\[\\[d1_databases\\]\\]|^\\[\\[r2_buckets\\]\\]|^\\[\\[durable_objects\" wrangler.toml\n\n   # List binding names\n   grep \"binding =\" wrangler.toml | awk '{print $3}' | tr -d '\"'\n   ```\n\n#### Step 3: Generate Framework Analysis Report\n\n<deliverable>\nComprehensive report on current framework and migration complexity\n</deliverable>\n\n```markdown\n## Framework Migration Analysis Report\n\n**Project**: [app-name]\n**Current Framework**: [React / Next.js / Vue / Nuxt / etc.]\n**Target Framework**: Tanstack Start (React 19 + TanStack Router)\n**Cloudflare Deployment**: âœ… Already on Workers\n\n### Current Application Inventory\n\n**Pages/Routes**: [X] routes detected\n- [List key routes]\n\n**Components**: [Y] components detected\n- Shared: [count]\n- Page-specific: [count]\n\n**State Management**: [Redux / Zustand / TanStack Query / Context / None]\n**UI Dependencies**: [Material UI / Chakra / shadcn/ui / Custom CSS / None]\n\n**API Endpoints**: [Z] server routes/endpoints\n- Backend framework: [Express / Hono / Next.js API / Nuxt server]\n\n### Cloudflare Infrastructure (PRESERVE)\n\n**Bindings** (from wrangler.toml):\n- KV namespaces: [count] ([list names])\n- D1 databases: [count] ([list names])\n- R2 buckets: [count] ([list names])\n- Durable Objects: [count] ([list classes])\n\n**wrangler.toml Configuration**:\n```toml\n[Current wrangler.toml snippet]\n```\n\n**CRITICAL**: All bindings and Workers configuration will be PRESERVED. Only the application framework will change.\n\n### Migration Complexity\n\n**Overall Complexity**: [Low / Medium / High]\n\n**Complexity Factors**:\n- Framework paradigm shift: [None / Small / Large]\n  - React â†’ Tanstack Start: Low (same paradigm, better tooling)\n  - Next.js â†’ Tanstack Start: Medium (different routing)\n  - React/Nuxt â†’ Tanstack Start: High (Vue to React conversion)\n  - Vanilla â†’ Tanstack Start: Medium (adding framework)\n- Component count: [X components] - [Low / Medium / High]\n- State management migration: [Simple / Complex]\n- UI dependencies: [Easy replacement / Medium / Custom CSS (requires work)]\n- API complexity: [Simple / Keep separate]\n\n### Migration Strategy Recommendation\n\n[Detailed strategy based on analysis]\n\n**Approach**: [Full migration / Incremental / UI-only with separate backend]\n\n**Timeline**: [X weeks / days]\n**Estimated Effort**: [Low / Medium / High]\n```\n\n### 2. Multi-Agent Migration Planning\n\n<thinking>\nUse the tanstack-migration-specialist agent and supporting agents to create\na comprehensive migration plan.\n</thinking>\n\n#### Phase 1: Framework-Specific Analysis\n\n1. **Task tanstack-migration-specialist(current framework and structure)**\n   - Analyze source framework patterns\n   - Map components to React + shadcn/ui equivalents\n   - Plan routing migration (TanStack Router file-based routing)\n   - Recommend state management approach (TanStack Query + Zustand)\n   - Design API strategy (server functions vs separate backend)\n   - Generate component mapping table\n   - Generate route mapping table\n   - Create implementation plan with todos\n\n#### Phase 2: Cloudflare Infrastructure Validation (Parallel)\n\n2. **Task binding-context-analyzer(existing wrangler.toml)**\n   - Parse current wrangler.toml\n   - Verify all bindings are valid\n   - Document binding usage patterns\n   - Ensure compatibility_date is 2025-09-15+\n   - Verify `remote = true` on all bindings\n   - Generate Env TypeScript interface\n\n3. **Task cloudflare-architecture-strategist(current architecture)**\n   - Analyze if backend should stay separate or integrate\n   - Recommend Workers architecture (single vs multiple)\n   - Service binding strategy (if multi-worker)\n   - Assess if Tanstack Start server functions can replace existing API\n\n#### Phase 3: Code Quality & Patterns (Parallel)\n\n4. **Task cloudflare-pattern-specialist(current codebase)**\n   - Identify Workers-specific patterns to preserve\n   - Detect any Workers anti-patterns\n   - Ensure bindings usage follows best practices\n\n5. **Task workers-runtime-guardian(current codebase)**\n   - Verify no Node.js APIs exist (would break in Workers)\n   - Check compatibility with Workers runtime\n   - Validate all code is Workers-compatible\n\n### 3. Migration Plan Synthesis\n\n<deliverable>\nDetailed Tanstack Start migration plan with step-by-step instructions\n</deliverable>\n\n<critical_requirement> Present complete migration plan for user approval before starting any code changes. </critical_requirement>\n\nThe tanstack-migration-specialist agent will generate a comprehensive plan including:\n\n**Component Migration Plan**:\n| Old Component | New Component (shadcn/ui or custom) | Effort | Notes |\n|--------------|-------------------------------------|--------|-------|\n| `<Button>` | `<Button>` (shadcn/ui) | Low | Direct mapping |\n| `<UserCard>` | `<Card>` + custom | Medium | Restructure children |\n| `<Modal>` (Vue) | `<Dialog>` (shadcn/ui) | Medium | Vue â†’ React conversion |\n\n**Route Migration Plan**:\n| Old Route | New File | Dynamic | Loaders | Notes |\n|----------|---------|---------|---------|-------|\n| `/` | `src/routes/index.tsx` | No | No | Home |\n| `/users/:id` | `src/routes/users.$id.tsx` | Yes | Yes | Detail with data loading |\n| `/api/users` | `src/routes/api/users.ts` | No | N/A | API route (server function) |\n\n**State Management Strategy**:\n- Current: [Redux / Context / Zustand / etc.]\n- Target: TanStack Query (server state) + Zustand (client state)\n- Migration approach: [Details]\n\n**Data Fetching Strategy**:\n- Current: [useEffect + fetch / Next.js getServerSideProps / Nuxt useAsyncData]\n- Target: TanStack Router loaders + TanStack Query\n- Benefits: Type-safe, automatic caching, optimistic updates\n\n**API Strategy**:\n- Current: [Express / Hono / Next.js API / Nuxt server routes]\n- Recommendation: [Tanstack Start server functions / Keep separate]\n- Rationale: [Why]\n\n**Styling Strategy**:\n- Current: [Material UI / Chakra / shadcn/ui / Custom CSS]\n- Target: shadcn/ui + Tailwind 4\n- Migration: [Component-by-component replacement]\n\n**Implementation Phases**:\n1. Setup Tanstack Start project with Cloudflare Workers preset\n2. Configure wrangler.jsonc for deployment\n3. Setup shadcn/ui components\n4. Migrate layouts (if any)\n5. Migrate routes with loaders (priority order)\n6. Convert components to React (if needed)\n7. Setup TanStack Query + Zustand\n8. Migrate/create server functions\n9. Replace UI with shadcn/ui + Tailwind 4\n10. Update Cloudflare bindings in app context\n11. Test & deploy\n\n### 4. User Approval & Confirmation\n\n<critical_requirement> MUST get explicit user approval before proceeding with any code changes. </critical_requirement>\n\n**Present the migration plan and ask**:\n\n```\nðŸ“‹ Tanstack Start Migration Plan Complete\n\nSummary:\n- Source framework: [React / Next.js / Vue / Nuxt / etc.]\n- Target: Tanstack Start (React 19 + TanStack Router)\n- Complexity: [Low / Medium / High]\n- Timeline: [X] weeks/days\n\nKey changes:\n1. [Major change 1]\n2. [Major change 2]\n3. [Major change 3]\n\nCloudflare infrastructure:\nâœ… All bindings preserved (no changes)\nâœ… wrangler.toml configuration maintained\nâœ… Workers deployment unchanged\n\nDo you want to proceed with this migration plan?\n\nOptions:\n1. yes - Start Phase 1 (Setup Tanstack Start)\n2. show-details - View detailed component/route mappings\n3. modify - Adjust plan before starting\n4. export - Save plan to .claude/todos/ for later\n5. no - Cancel migration\n```\n\n### 5. Automated Migration Execution\n\n<thinking>\nOnly execute if user approves. Work through phases systematically.\n</thinking>\n\n**If user says \"yes\"**:\n\n1. **Create migration branch**\n   ```bash\n   git checkout -b migrate-to-tanstack-start\n   git commit -m \"chore: Create migration branch for Tanstack Start\"\n   ```\n\n2. **Phase 1: Initialize Tanstack Start Project**\n\n   ```bash\n   # Create new Tanstack Start app with Cloudflare preset\n   pnpm create @tanstack/start@latest temp-tanstack --template start-basic-cloudflare\n\n   # Copy configuration files\n   cp temp-tanstack/vite.config.ts ./\n   cp temp-tanstack/app.config.ts ./\n   cp temp-tanstack/tsconfig.json ./tsconfig.tanstack.json\n\n   # Install dependencies\n   pnpm add @tanstack/start @tanstack/react-router @tanstack/react-query zustand\n   pnpm add -D vinxi vite\n\n   # Setup shadcn/ui\n   pnpx shadcn@latest init\n   # Select: Tailwind 4, TypeScript, src/ directory\n   ```\n\n3. **Phase 2: Configure Cloudflare Workers**\n\n   Create `wrangler.jsonc`:\n   ```jsonc\n   {\n     \"name\": \"your-app-name\",\n     \"compatibility_date\": \"2025-09-15\",\n     \"main\": \".output/server/index.mjs\",\n\n     // PRESERVE existing bindings from old wrangler.toml\n     \"kv_namespaces\": [\n       // Copy from analysis report\n     ],\n     \"d1_databases\": [\n       // Copy from analysis report\n     ],\n     \"r2_buckets\": [\n       // Copy from analysis report\n     ]\n   }\n   ```\n\n   Update `vite.config.ts`:\n   ```typescript\n   import { defineConfig } from 'vite'\n   import { TanStackStartVite } from '@tanstack/start/vite'\n\n   export default defineConfig({\n     plugins: [TanStackStartVite()],\n   })\n   ```\n\n4. **Phase 3: Migrate Routes**\n\n   For each route in the migration plan:\n\n   **Next.js `pages/users/[id].tsx` â†’ Tanstack Start `src/routes/users.$id.tsx`**:\n\n   ```tsx\n   // OLD (Next.js)\n   export async function getServerSideProps({ params }) {\n     const user = await fetchUser(params.id)\n     return { props: { user } }\n   }\n\n   export default function UserPage({ user }) {\n     return <div>{user.name}</div>\n   }\n\n   // NEW (Tanstack Start)\n   import { createFileRoute } from '@tanstack/react-router'\n\n   export const Route = createFileRoute('/users/$id')({\n     loader: async ({ params, context }) => {\n       const user = await fetchUser(params.id, context.cloudflare.env)\n       return { user }\n     },\n     component: UserPage,\n   })\n\n   function UserPage() {\n     const { user } = Route.useLoaderData()\n     return <div>{user.name}</div>\n   }\n   ```\n\n   **Vue component â†’ React component**:\n\n   ```tsx\n   // OLD (Vue)\n     <div class=\"card\">\n       <h2>{ title}</h2>\n       <p>{ description}</p>\n     </div>\n\n   const props = defineProps<{\n     title: string\n     description: string\n   }>()\n\n   // NEW (React + shadcn/ui)\n   import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card'\n\n   interface CardComponentProps {\n     title: string\n     description: string\n   }\n\n   export function CardComponent({ title, description }: CardComponentProps) {\n     return (\n       <Card>\n         <CardHeader>\n           <CardTitle>{title}</CardTitle>\n         </CardHeader>\n         <CardContent>\n           <p>{description}</p>\n         </CardContent>\n       </Card>\n     )\n   }\n   ```\n\n5. **Phase 4: Setup State Management**\n\n   **TanStack Query setup** (`src/lib/query-client.ts`):\n   ```typescript\n   import { QueryClient } from '@tanstack/react-query'\n\n   export const queryClient = new QueryClient({\n     defaultOptions: {\n       queries: {\n         staleTime: 60 * 1000, // 1 minute\n       },\n     },\n   })\n   ```\n\n   **Zustand store** (`src/stores/ui-store.ts`):\n   ```typescript\n   import { create } from 'zustand'\n\n   interface UIStore {\n     sidebarOpen: boolean\n     toggleSidebar: () => void\n   }\n\n   export const useUIStore = create<UIStore>((set) => ({\n     sidebarOpen: false,\n     toggleSidebar: () => set((state) => ({ sidebarOpen: !state.sidebarOpen })),\n   }))\n   ```\n\n6. **Phase 5: Setup Cloudflare Bindings Context**\n\n   Create `src/lib/cloudflare.ts`:\n   ```typescript\n   export interface Env {\n     // PRESERVE from analysis report\n     MY_KV: KVNamespace\n     DB: D1Database\n     MY_BUCKET: R2Bucket\n   }\n   ```\n\n   Update `app.config.ts`:\n   ```typescript\n   import { defineConfig } from '@tanstack/start/config'\n\n   export default defineConfig({\n     server: {\n       preset: 'cloudflare-module',\n     },\n   })\n   ```\n\n7. **Phase 6: Migrate Server Functions**\n\n   ```typescript\n   // src/routes/api/users.ts\n   import { createAPIFileRoute } from '@tanstack/start/api'\n\n   export const Route = createAPIFileRoute('/api/users')({\n     GET: async ({ request, context }) => {\n       const { env } = context.cloudflare\n\n       // Access Cloudflare bindings\n       const users = await env.DB.prepare('SELECT * FROM users').all()\n\n       return Response.json(users)\n     },\n   })\n   ```\n\n8. **Phase 7: Install shadcn/ui Components**\n\n   ```bash\n   # Add commonly used components\n   pnpx shadcn@latest add button card dialog form input label\n   ```\n\n9. **Phase 8: Update Package Scripts**\n\n   Update `package.json`:\n   ```json\n   {\n     \"scripts\": {\n       \"dev\": \"vinxi dev\",\n       \"build\": \"vinxi build\",\n       \"start\": \"vinxi start\",\n       \"deploy\": \"wrangler deploy\"\n     }\n   }\n   ```\n\n10. **Phase 9: Testing & Validation**\n\n    ```bash\n    # Run development server\n    pnpm dev\n\n    # Build for production\n    pnpm build\n\n    # Deploy to Cloudflare Workers\n    wrangler deploy\n    ```\n\n### 6. Post-Migration Validation\n\n<thinking>\nRun comprehensive validation after migration is complete.\n</thinking>\n\n**Automated validation** (run in parallel):\n\n1. **Task workers-runtime-guardian(migrated codebase)**\n   - Verify no Node.js APIs introduced\n   - Validate Workers runtime compatibility\n   - Check bundle size (< 1MB recommended)\n\n2. **Task binding-context-analyzer(new wrangler.jsonc)**\n   - Verify all bindings preserved\n   - Check binding types match Env interface\n   - Validate `remote = true` on all bindings\n\n3. **Task cloudflare-pattern-specialist(migrated codebase)**\n   - Verify bindings accessed correctly via context\n   - Check error handling patterns\n   - Validate security patterns\n\n4. **Run /es-validate**\n   - Full validation suite\n   - Check for anti-patterns\n   - Verify design system compliance\n\n### 7. Migration Report\n\n<deliverable>\nFinal migration report with validation results and next steps\n</deliverable>\n\n```markdown\n## Tanstack Start Migration Complete âœ…\n\n**Project**: [app-name]\n**Migration**: [source] â†’ Tanstack Start\n**Date**: [timestamp]\n\n### Migration Summary\n\n**Routes migrated**: [X] / [X]\n**Components converted**: [Y] / [Y]\n**Server functions created**: [Z]\n**Tests passing**: [All / Some / None]\n\n### Validation Results\n\nâœ… Workers runtime compatibility verified\nâœ… All Cloudflare bindings preserved and functional\nâœ… Bundle size: [X]KB (target: < 1MB)\nâœ… No Node.js APIs detected\nâœ… Security patterns validated\n\n### Performance Improvements\n\n- Cold start time: [before] â†’ [after]\n- Bundle size: [before] â†’ [after]\n- Type safety: [improved with TanStack Router]\n\n### Next Steps\n\n1. [ ] Run full test suite: `pnpm test`\n2. [ ] Deploy to preview: `wrangler deploy --env preview`\n3. [ ] Verify all features work in preview\n4. [ ] Deploy to production: `wrangler deploy --env production`\n5. [ ] Monitor Workers metrics\n6. [ ] Update documentation\n\n### Files Changed\n\n**Added**:\n- [list new files]\n\n**Modified**:\n- [list modified files]\n\n**Removed**:\n- [list removed files]\n\n### Rollback Plan\n\nIf issues arise:\n```bash\ngit checkout main\ngit branch -D migrate-to-tanstack-start\nwrangler rollback\n```\n```\n\n## Framework-Specific Migration Patterns\n\n### React/Next.js â†’ Tanstack Start\n\n**Complexity**: Low (same React ecosystem)\n\n**Key mappings**:\n- `pages/` â†’ `src/routes/`\n- `getServerSideProps` â†’ Route `loader`\n- `getStaticProps` â†’ Route `loader` (cached)\n- `api/` â†’ `src/routes/api/` (server functions)\n- `useEffect` + fetch â†’ TanStack Query `useQuery`\n- Context API â†’ Zustand (for client state)\n\n### React/Nuxt â†’ Tanstack Start\n\n**Complexity**: High (Vue to React conversion)\n\n**Key mappings**:\n- `{}` interpolation â†’ `{}`\n- `v-if` â†’ `{condition && <Component />}`\n- `v-for` â†’ `.map()`\n- `v-model` â†’ `value` + `onChange`\n- `defineProps` â†’ TypeScript interface + props\n- `ref()` / `reactive()` â†’ `useState()` / `useReducer()`\n- `computed()` â†’ `useMemo()`\n- `watch()` â†’ `useEffect()`\n- `useAsyncData` â†’ TanStack Router `loader` + TanStack Query\n\n### Vanilla JS â†’ Tanstack Start\n\n**Complexity**: Medium (adding full framework)\n\n**Approach**:\n1. Identify pages and routes\n2. Convert HTML templates to React components\n3. Convert event handlers to React patterns\n4. Add type safety with TypeScript\n5. Implement routing with TanStack Router\n6. Add state management where needed\n\n## Troubleshooting\n\n### Common Issues\n\n**Issue**: \"Module not found: @tanstack/start\"\n**Solution**: Ensure you're using the correct package manager (pnpm recommended)\n\n**Issue**: \"wrangler.jsonc not recognized\"\n**Solution**: Update wrangler to latest version: `npm install -g wrangler@latest`\n\n**Issue**: \"Bindings not available in context\"\n**Solution**: Verify `app.config.ts` has correct preset: `preset: 'cloudflare-module'`\n\n**Issue**: \"Build fails with Workers runtime errors\"\n**Solution**: Check for Node.js APIs (fs, path, etc.) - use Workers alternatives\n\n## Resources\n\n- **Tanstack Start Docs**: https://tanstack.com/start/latest\n- **TanStack Router Docs**: https://tanstack.com/router/latest\n- **TanStack Query Docs**: https://tanstack.com/query/latest\n- **shadcn/ui Docs**: https://ui.shadcn.com\n- **Cloudflare Workers Docs**: https://developers.cloudflare.com/workers\n- **Zustand Docs**: https://docs.pmnd.rs/zustand\n\n## Success Metrics\n\nTrack these metrics before and after migration:\n\n- âš¡ Cold start time (ms)\n- ðŸ“¦ Bundle size (KB)\n- ðŸŽ¯ Type safety coverage (%)\n- ðŸš€ Lighthouse score\n- ðŸ”’ Security audit results\n- ðŸ“Š Workers Analytics (requests/errors/latency)\n\n---\n\n**Remember**: This is a FRAMEWORK migration only. All Cloudflare infrastructure, bindings, and Workers configuration are preserved throughout the process."
              },
              {
                "name": "/es-tanstack-route",
                "description": "Create new TanStack Router routes with loaders, type-safe params, and proper file structure for Tanstack Start projects",
                "path": "plugins/edge-stack/commands/es-tanstack-route.md",
                "frontmatter": {
                  "description": "Create new TanStack Router routes with loaders, type-safe params, and proper file structure for Tanstack Start projects"
                },
                "content": "# Tanstack Route Generator Command\n\n<command_purpose> Generate TanStack Router routes with server-side loaders, type-safe parameters, error boundaries, and proper file structure for Tanstack Start projects on Cloudflare Workers. </command_purpose>\n\n## Introduction\n\n<role>Senior Routing Engineer with expertise in TanStack Router, server-side data loading, and Cloudflare Workers integration</role>\n\n## Prerequisites\n\n<requirements>\n- Tanstack Start project with TanStack Router\n- Cloudflare Workers setup (wrangler.jsonc)\n- TypeScript configured\n- src/routes/ directory structure\n</requirements>\n\n## Command Usage\n\n```bash\n/es-tanstack-route <route-path> [options]\n```\n\n### Arguments:\n\n- `<route-path>`: Route path (e.g., `/users/$id`, `/blog`, `/api/users`)\n- `[options]`: Optional flags:\n  - `--loader`: Include server-side loader (default: true for non-API routes)\n  - `--api`: Create API route (server function)\n  - `--layout`: Create layout route\n  - `--params <params>`: Dynamic params (e.g., `id,slug`)\n  - `--search-params <params>`: Search params (e.g., `page:number,filter:string`)\n\n### Examples:\n\n```bash\n# Create static route\n/es-tanstack-route /about\n\n# Create dynamic route with loader\n/es-tanstack-route /users/$id --loader\n\n# Create API route\n/es-tanstack-route /api/users --api\n\n# Create route with search params\n/es-tanstack-route /users --search-params page:number,sort:string\n```\n\n## Main Tasks\n\n### 1. Parse Route Path\n\nConvert route path to file path:\n\n| Route Path | File Path |\n|------------|-----------|\n| `/` | `src/routes/index.tsx` |\n| `/about` | `src/routes/about.tsx` |\n| `/users/$id` | `src/routes/users.$id.tsx` |\n| `/blog/$slug` | `src/routes/blog.$slug.tsx` |\n| `/api/users` | `src/routes/api/users.ts` |\n\n### 2. Generate Route File\n\n**Standard Route with Loader**:\n\n```tsx\n// src/routes/users.$id.tsx\nimport { createFileRoute } from '@tanstack/react-router'\nimport { z } from 'zod'\n\nexport const Route = createFileRoute('/users/$id')({\n  loader: async ({ params, context }) => {\n    const { env } = context.cloudflare\n\n    const user = await env.DB.prepare(\n      'SELECT * FROM users WHERE id = ?'\n    ).bind(params.id).first()\n\n    if (!user) {\n      throw new Error('User not found')\n    }\n\n    return { user }\n  },\n  errorComponent: ({ error }) => (\n    <div className=\"p-4\">\n      <h1 className=\"text-2xl font-bold text-red-600\">Error</h1>\n      <p>{error.message}</p>\n    </div>\n  ),\n  pendingComponent: () => (\n    <div className=\"p-4\">\n      <Loader2 className=\"animate-spin\" />\n      <span>Loading...</span>\n    </div>\n  ),\n  component: UserPage,\n})\n\nfunction UserPage() {\n  const { user } = Route.useLoaderData()\n\n  return (\n    <div className=\"max-w-4xl mx-auto p-6\">\n      <h1 className=\"text-3xl font-bold\">{user.name}</h1>\n      <p className=\"text-gray-600\">{user.email}</p>\n    </div>\n  )\n}\n```\n\n**API Route**:\n\n```typescript\n// src/routes/api/users.ts\nimport { createAPIFileRoute } from '@tanstack/start/api'\n\nexport const Route = createAPIFileRoute('/api/users')({\n  GET: async ({ request, context }) => {\n    const { env } = context.cloudflare\n\n    const users = await env.DB.prepare('SELECT * FROM users').all()\n\n    return Response.json(users)\n  },\n  POST: async ({ request, context }) => {\n    const { env } = context.cloudflare\n    const data = await request.json()\n\n    await env.DB.prepare(\n      'INSERT INTO users (name, email) VALUES (?, ?)'\n    ).bind(data.name, data.email).run()\n\n    return Response.json({ success: true })\n  },\n})\n```\n\n**Route with Search Params**:\n\n```tsx\n// src/routes/users.tsx\nimport { createFileRoute } from '@tanstack/react-router'\nimport { z } from 'zod'\n\nconst searchSchema = z.object({\n  page: z.number().int().positive().default(1),\n  sort: z.enum(['name', 'date']).default('name'),\n  filter: z.string().optional(),\n})\n\nexport const Route = createFileRoute('/users')({\n  validateSearch: searchSchema,\n  loaderDeps: ({ search }) => search,\n  loader: async ({ deps: search, context }) => {\n    const { env } = context.cloudflare\n\n    const offset = (search.page - 1) * 20\n    const users = await env.DB.prepare(\n      `SELECT * FROM users ORDER BY ${search.sort} LIMIT 20 OFFSET ?`\n    ).bind(offset).all()\n\n    return { users, search }\n  },\n  component: UsersPage,\n})\n\nfunction UsersPage() {\n  const { users, search } = Route.useLoaderData()\n  const navigate = Route.useNavigate()\n\n  return (\n    <div>\n      <h1>Users (Page {search.page})</h1>\n      {/* ... */}\n    </div>\n  )\n}\n```\n\n### 3. Generate TypeScript Types\n\n```typescript\n// src/types/routes.ts\nexport interface UserParams {\n  id: string\n}\n\nexport interface UsersSearch {\n  page: number\n  sort: 'name' | 'date'\n  filter?: string\n}\n```\n\n### 4. Update Router Configuration\n\nEnsure route is registered in router.\n\n### 5. Validation\n\n**Task tanstack-routing-specialist(generated route)**:\n- Verify route path syntax\n- Validate loader implementation\n- Check error handling\n- Verify TypeScript types\n- Ensure Cloudflare bindings accessible\n\n## Success Criteria\n\nâœ… Route file generated in correct location\nâœ… Loader implemented with Cloudflare bindings\nâœ… Error boundary included\nâœ… Pending state handled\nâœ… TypeScript types defined\nâœ… Search params validated (if applicable)"
              },
              {
                "name": "/es-tanstack-server-fn",
                "description": "Generate type-safe server functions for Tanstack Start with Cloudflare Workers bindings integration",
                "path": "plugins/edge-stack/commands/es-tanstack-server-fn.md",
                "frontmatter": {
                  "description": "Generate type-safe server functions for Tanstack Start with Cloudflare Workers bindings integration"
                },
                "content": "# Tanstack Server Function Generator\n\n<command_purpose> Generate type-safe server functions for Tanstack Start projects that leverage Cloudflare Workers bindings (KV, D1, R2, DO) with proper error handling and validation. </command_purpose>\n\n## Introduction\n\n<role>Senior Backend Engineer with expertise in server functions, type-safe RPC, and Cloudflare Workers bindings</role>\n\n## Prerequisites\n\n<requirements>\n- Tanstack Start project\n- Cloudflare Workers bindings configured\n- TypeScript with strict mode\n- Zod for validation (recommended)\n</requirements>\n\n## Command Usage\n\n```bash\n/es-tanstack-server-fn <name> <method> [options]\n```\n\n### Arguments:\n\n- `<name>`: Function name (e.g., `getUser`, `updateProfile`, `deletePost`)\n- `<method>`: HTTP method (`GET`, `POST`, `PUT`, `DELETE`)\n- `[options]`: Optional flags:\n  - `--binding <type>`: Cloudflare binding to use (kv, d1, r2, do)\n  - `--validate`: Include Zod validation\n  - `--cache`: Add caching strategy (for GET requests)\n\n### Examples:\n\n```bash\n# Create GET function with D1 binding\n/es-tanstack-server-fn getUser GET --binding d1\n\n# Create POST function with validation\n/es-tanstack-server-fn createUser POST --binding d1 --validate\n\n# Create GET function with KV caching\n/es-tanstack-server-fn getSettings GET --binding kv --cache\n```\n\n## Main Tasks\n\n### 1. Generate Server Function\n\n**Query (GET)**:\n\n```typescript\n// src/lib/server-functions/getUser.ts\nimport { createServerFn } from '@tanstack/start'\nimport { z } from 'zod'\n\nconst inputSchema = z.string()\n\nexport const getUser = createServerFn(\n  'GET',\n  async (id: string, context) => {\n    // Validate input\n    const validId = inputSchema.parse(id)\n\n    const { env } = context.cloudflare\n\n    const user = await env.DB.prepare(\n      'SELECT * FROM users WHERE id = ?'\n    ).bind(validId).first()\n\n    if (!user) {\n      throw new Error('User not found')\n    }\n\n    return user\n  }\n)\n```\n\n**Mutation (POST)**:\n\n```typescript\n// src/lib/server-functions/createUser.ts\nimport { createServerFn } from '@tanstack/start'\nimport { z } from 'zod'\n\nconst inputSchema = z.object({\n  name: z.string().min(2).max(100),\n  email: z.string().email(),\n})\n\nexport const createUser = createServerFn(\n  'POST',\n  async (data: z.infer<typeof inputSchema>, context) => {\n    // Validate input\n    const validData = inputSchema.parse(data)\n\n    const { env } = context.cloudflare\n\n    const result = await env.DB.prepare(\n      'INSERT INTO users (name, email) VALUES (?, ?)'\n    ).bind(validData.name, validData.email).run()\n\n    return {\n      id: result.meta.last_row_id,\n      ...validData\n    }\n  }\n)\n```\n\n**With KV Caching**:\n\n```typescript\n// src/lib/server-functions/getSettings.ts\nimport { createServerFn } from '@tanstack/start'\n\nexport const getSettings = createServerFn(\n  'GET',\n  async (userId: string, context) => {\n    const { env } = context.cloudflare\n\n    // Check cache first\n    const cached = await env.CACHE.get(`settings:${userId}`)\n    if (cached) {\n      return JSON.parse(cached)\n    }\n\n    // Fetch from D1\n    const settings = await env.DB.prepare(\n      'SELECT * FROM settings WHERE user_id = ?'\n    ).bind(userId).first()\n\n    // Cache for 1 hour\n    await env.CACHE.put(\n      `settings:${userId}`,\n      JSON.stringify(settings),\n      { expirationTtl: 3600 }\n    )\n\n    return settings\n  }\n)\n```\n\n### 2. Generate Usage Example\n\n```tsx\n// src/components/UserProfile.tsx\nimport { getUser } from '@/lib/server-functions/getUser'\n\nexport async function UserProfile({ id }: { id: string }) {\n  const user = await getUser(id)\n\n  return (\n    <div>\n      <h1>{user.name}</h1>\n      <p>{user.email}</p>\n    </div>\n  )\n}\n```\n\n### 3. Generate Tests\n\n```typescript\n// src/lib/server-functions/__tests__/getUser.test.ts\nimport { describe, it, expect, vi } from 'vitest'\nimport { getUser } from '../getUser'\n\ndescribe('getUser', () => {\n  it('should fetch user from database', async () => {\n    const mockContext = {\n      cloudflare: {\n        env: {\n          DB: {\n            prepare: vi.fn().mockReturnValue({\n              bind: vi.fn().mockReturnValue({\n                first: vi.fn().mockResolvedValue({\n                  id: '1',\n                  name: 'John Doe',\n                  email: 'john@example.com',\n                }),\n              }),\n            }),\n          },\n        },\n      },\n    }\n\n    const user = await getUser('1', mockContext)\n\n    expect(user).toEqual({\n      id: '1',\n      name: 'John Doe',\n      email: 'john@example.com',\n    })\n  })\n})\n```\n\n## Success Criteria\n\nâœ… Server function generated with correct method\nâœ… Cloudflare bindings accessible\nâœ… Input validation with Zod\nâœ… Error handling implemented\nâœ… TypeScript types defined\nâœ… Usage example provided\nâœ… Tests generated (optional)"
              },
              {
                "name": "/es-test-gen",
                "description": "Generate Playwright E2E tests for Tanstack Start routes, server functions, and components",
                "path": "plugins/edge-stack/commands/es-test-gen.md",
                "frontmatter": {
                  "description": "Generate Playwright E2E tests for Tanstack Start routes, server functions, and components"
                },
                "content": "# Playwright Test Generator Command\n\n<command_purpose> Automatically generate comprehensive Playwright tests for Tanstack Start routes, server functions, and components with Cloudflare Workers-specific patterns. </command_purpose>\n\n## Introduction\n\n<role>Senior QA Engineer specializing in test generation for Tanstack Start applications</role>\n\nThis command generates ready-to-use Playwright tests that cover:\n- TanStack Router route loading and navigation\n- Server function calls with Cloudflare bindings\n- Component interactions\n- Accessibility validation\n- Error handling\n- Loading states\n\n## Prerequisites\n\n<requirements>\n- Playwright installed (`/es-test-setup`)\n- Tanstack Start project\n- Route or component to test\n</requirements>\n\n## Security Considerations\n\nâš ï¸ **Security Note**: When generating tests that interact with external websites or untrusted content, be aware that malicious web pages could attempt prompt injection attacks against browser automation agents. Review generated test code carefully, especially:\n- Navigation logic (`page.goto()` calls to external sites)\n- Data extraction from untrusted pages\n- Form filling with sensitive information\n- Click actions on external sites\n\n**Best Practices**:\n- Test against your own controlled test environments when possible\n- Review any navigation to external URLs in generated tests\n- Avoid testing workflows that expose credentials to untrusted sites\n- Use test fixtures and mocked data instead of live external APIs\n\nFor more information, see [Anthropic's research on prompt injection defenses](https://www.anthropic.com/research/prompt-injection-defenses).\n\n## Command Usage\n\n```bash\n/es-test-gen <target> [options]\n```\n\n### Arguments:\n\n- `<target>`: What to generate tests for\n  - Route path: `/users/$id`, `/dashboard`, `/blog`\n  - Server function: `src/lib/server-functions/createUser.ts`\n  - Component: `src/components/UserCard.tsx`\n\n- `[options]`: Optional flags:\n  - `--with-auth`: Include authentication tests\n  - `--with-server-fn`: Include server function tests\n  - `--with-a11y`: Include accessibility tests (default: true)\n  - `--output <path>`: Custom output path\n\n### Examples:\n\n```bash\n# Generate tests for a route\n/es-test-gen /users/$id\n\n# Generate tests for server function\n/es-test-gen src/lib/server-functions/createUser.ts --with-auth\n\n# Generate tests for component\n/es-test-gen src/components/UserCard.tsx --with-a11y\n```\n\n## Main Tasks\n\n### 1. Analyze Target\n\n<thinking>\nParse the target to understand what type of tests to generate.\n</thinking>\n\n```bash\n# Determine target type\nif [[ \"$TARGET\" == /* ]]; then\n  TYPE=\"route\"\nelif [[ \"$TARGET\" == *server-functions* ]]; then\n  TYPE=\"server-function\"\nelif [[ \"$TARGET\" == *components* ]]; then\n  TYPE=\"component\"\nfi\n```\n\n### 2. Generate Route Tests\n\nFor route: `/users/$id`\n\n**Task playwright-testing-specialist(analyze route and generate tests)**:\n- Identify dynamic parameters\n- Detect loaders and data dependencies\n- Check for authentication requirements\n- Generate test cases\n\n**Output**: `e2e/routes/users.$id.spec.ts`\n\n```typescript\nimport { test, expect } from '@playwright/test'\nimport AxeBuilder from '@axe-core/playwright'\n\ntest.describe('User Profile Page', () => {\n  const testUserId = '123'\n\n  test('loads user profile successfully', async ({ page }) => {\n    await page.goto(`/users/${testUserId}`)\n\n    // Wait for loader to complete\n    await page.waitForSelector('[data-testid=\"user-profile\"]')\n\n    // Verify user data displayed\n    await expect(page.locator('h1')).toBeVisible()\n    await expect(page.locator('[data-testid=\"user-email\"]')).toBeVisible()\n  })\n\n  test('shows loading state during navigation', async ({ page }) => {\n    await page.goto('/')\n\n    // Navigate to user profile\n    await page.click(`a[href=\"/users/${testUserId}\"]`)\n\n    // Verify loading indicator\n    await expect(page.locator('[data-testid=\"loading\"]')).toBeVisible()\n\n    // Wait for content to load\n    await expect(page.locator('[data-testid=\"user-profile\"]')).toBeVisible()\n  })\n\n  test('handles non-existent user (404)', async ({ page }) => {\n    const response = await page.goto('/users/999999')\n\n    // Verify error state\n    await expect(page.locator('text=/user not found/i')).toBeVisible()\n  })\n\n  test('has no accessibility violations', async ({ page }) => {\n    await page.goto(`/users/${testUserId}`)\n\n    const accessibilityScanResults = await new AxeBuilder({ page })\n      .analyze()\n\n    expect(accessibilityScanResults.violations).toEqual([])\n  })\n\n  test('navigates back correctly', async ({ page }) => {\n    await page.goto(`/users/${testUserId}`)\n\n    // Go back\n    await page.goBack()\n\n    // Verify we're back at previous page\n    await expect(page).toHaveURL('/')\n  })\n})\n```\n\n### 3. Generate Server Function Tests\n\nFor: `src/lib/server-functions/createUser.ts`\n\n**Output**: `e2e/server-functions/create-user.spec.ts`\n\n```typescript\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Create User Server Function', () => {\n  test('creates user successfully', async ({ page }) => {\n    await page.goto('/users/new')\n\n    // Fill form\n    await page.fill('[name=\"name\"]', 'Test User')\n    await page.fill('[name=\"email\"]', 'test@example.com')\n\n    // Submit (calls server function)\n    await page.click('button[type=\"submit\"]')\n\n    // Wait for redirect\n    await page.waitForURL(/\\/users\\/\\d+/)\n\n    // Verify user created\n    await expect(page.locator('h1')).toContainText('Test User')\n  })\n\n  test('validates required fields', async ({ page }) => {\n    await page.goto('/users/new')\n\n    // Submit empty form\n    await page.click('button[type=\"submit\"]')\n\n    // Verify validation errors\n    await expect(page.locator('[data-testid=\"name-error\"]'))\n      .toContainText(/required/i)\n  })\n\n  test('shows loading state during submission', async ({ page }) => {\n    await page.goto('/users/new')\n\n    await page.fill('[name=\"name\"]', 'Test User')\n    await page.fill('[name=\"email\"]', 'test@example.com')\n\n    // Start submission\n    await page.click('button[type=\"submit\"]')\n\n    // Verify loading indicator\n    await expect(page.locator('button[type=\"submit\"]')).toBeDisabled()\n    await expect(page.locator('[data-testid=\"loading\"]')).toBeVisible()\n  })\n\n  test('handles server errors gracefully', async ({ page }) => {\n    await page.goto('/users/new')\n\n    // Simulate server error by using invalid data\n    await page.fill('[name=\"email\"]', 'invalid-email')\n\n    await page.click('button[type=\"submit\"]')\n\n    // Verify error message\n    await expect(page.locator('[data-testid=\"error\"]')).toBeVisible()\n  })\n\n  test('stores data in Cloudflare D1', async ({ page, request }) => {\n    await page.goto('/users/new')\n\n    const testEmail = `test-${Date.now()}@example.com`\n\n    await page.fill('[name=\"name\"]', 'D1 Test User')\n    await page.fill('[name=\"email\"]', testEmail)\n\n    await page.click('button[type=\"submit\"]')\n\n    // Wait for creation\n    await page.waitForURL(/\\/users\\/\\d+/)\n\n    // Verify data persisted (reload page)\n    await page.reload()\n\n    await expect(page.locator('[data-testid=\"user-email\"]'))\n      .toContainText(testEmail)\n  })\n})\n```\n\n### 4. Generate Component Tests\n\nFor: `src/components/UserCard.tsx`\n\n**Output**: `e2e/components/user-card.spec.ts`\n\n```typescript\nimport { test, expect } from '@playwright/test'\n\ntest.describe('UserCard Component', () => {\n  test.beforeEach(async ({ page }) => {\n    // Navigate to component demo/storybook page\n    await page.goto('/components/user-card-demo')\n  })\n\n  test('renders user information correctly', async ({ page }) => {\n    await expect(page.locator('[data-testid=\"user-card\"]')).toBeVisible()\n    await expect(page.locator('[data-testid=\"user-name\"]')).toBeVisible()\n    await expect(page.locator('[data-testid=\"user-email\"]')).toBeVisible()\n  })\n\n  test('handles click interactions', async ({ page }) => {\n    await page.click('[data-testid=\"user-card\"]')\n\n    // Verify click handler triggered\n    await expect(page).toHaveURL(/\\/users\\/\\d+/)\n  })\n\n  test('displays avatar image', async ({ page }) => {\n    const avatar = page.locator('[data-testid=\"user-avatar\"]')\n\n    await expect(avatar).toBeVisible()\n\n    // Verify image loaded\n    await expect(avatar).toHaveJSProperty('complete', true)\n  })\n\n  test('has no accessibility violations', async ({ page }) => {\n    const accessibilityScanResults = await new AxeBuilder({ page })\n      .include('[data-testid=\"user-card\"]')\n      .analyze()\n\n    expect(accessibilityScanResults.violations).toEqual([])\n  })\n\n  test('keyboard navigation works', async ({ page }) => {\n    // Tab to card\n    await page.keyboard.press('Tab')\n\n    // Verify focus\n    await expect(page.locator('[data-testid=\"user-card\"]')).toBeFocused()\n\n    // Press Enter\n    await page.keyboard.press('Enter')\n\n    // Verify navigation\n    await expect(page).toHaveURL(/\\/users\\/\\d+/)\n  })\n\n  test('matches visual snapshot', async ({ page }) => {\n    await expect(page.locator('[data-testid=\"user-card\"]'))\n      .toHaveScreenshot('user-card.png')\n  })\n})\n```\n\n### 5. Generate Authentication Tests (--with-auth)\n\n**Output**: `e2e/auth/protected-route.spec.ts`\n\n```typescript\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Protected Route - /users/$id', () => {\n  test('redirects to login when unauthenticated', async ({ page }) => {\n    await page.goto('/users/123')\n\n    // Should redirect to login\n    await page.waitForURL(/\\/login/)\n\n    // Verify redirect query param\n    expect(page.url()).toContain('redirect=%2Fusers%2F123')\n  })\n\n  test('allows access when authenticated', async ({ page }) => {\n    // Login first\n    await page.goto('/login')\n    await page.fill('[name=\"email\"]', 'test@example.com')\n    await page.fill('[name=\"password\"]', 'password123')\n    await page.click('button[type=\"submit\"]')\n\n    // Navigate to protected route\n    await page.goto('/users/123')\n\n    // Should not redirect\n    await expect(page).toHaveURL('/users/123')\n    await expect(page.locator('[data-testid=\"user-profile\"]')).toBeVisible()\n  })\n\n  test('redirects to original destination after login', async ({ page }) => {\n    // Try to access protected route\n    await page.goto('/users/123')\n\n    // Should be on login page\n    await page.waitForURL(/\\/login/)\n\n    // Login\n    await page.fill('[name=\"email\"]', 'test@example.com')\n    await page.fill('[name=\"password\"]', 'password123')\n    await page.click('button[type=\"submit\"]')\n\n    // Should redirect back to original destination\n    await expect(page).toHaveURL('/users/123')\n  })\n})\n```\n\n### 6. Update Test Metadata\n\nAdd test to suite configuration:\n\n```typescript\n// e2e/test-registry.ts (auto-generated)\nexport const testRegistry = {\n  routes: [\n    'e2e/routes/users.$id.spec.ts',\n    // ... other routes\n  ],\n  serverFunctions: [\n    'e2e/server-functions/create-user.spec.ts',\n    // ... other server functions\n  ],\n  components: [\n    'e2e/components/user-card.spec.ts',\n    // ... other components\n  ],\n}\n```\n\n### 7. Generate Test Documentation\n\n**Output**: `e2e/routes/users.$id.README.md`\n\n```markdown\n# User Profile Route Tests\n\n## Test Coverage\n\n- âœ… Route loading with valid user ID\n- âœ… Loading state during navigation\n- âœ… 404 handling for non-existent users\n- âœ… Accessibility (zero violations)\n- âœ… Back navigation\n\n## Running Tests\n\n```bash\n# Run all tests for this route\npnpm test:e2e e2e/routes/users.$id.spec.ts\n\n# Run specific test\npnpm test:e2e e2e/routes/users.$id.spec.ts -g \"loads user profile\"\n\n# Debug mode\npnpm test:e2e:debug e2e/routes/users.$id.spec.ts\n```\n\n## Test Data\n\nUses test user ID: `123` (configured in test fixtures)\n\n## Dependencies\n\n- Requires D1 database with test data\n- Requires user with ID 123 to exist\n```\n\n## Test Generation Patterns\n\n### Pattern: Dynamic Route Parameters\n\nFor `/blog/$category/$slug`:\n\n```typescript\ntest.describe('Blog Post Page', () => {\n  const testCategory = 'tech'\n  const testSlug = 'tanstack-start-guide'\n\n  test('loads blog post successfully', async ({ page }) => {\n    await page.goto(`/blog/${testCategory}/${testSlug}`)\n\n    await expect(page.locator('article')).toBeVisible()\n    await expect(page.locator('h1')).toBeVisible()\n  })\n})\n```\n\n### Pattern: Search Params\n\nFor `/users?page=2&sort=name`:\n\n```typescript\ntest.describe('Users List with Search Params', () => {\n  test('paginates users correctly', async ({ page }) => {\n    await page.goto('/users?page=2')\n\n    // Verify page 2 content\n    await expect(page.locator('[data-testid=\"pagination\"]'))\n      .toContainText('Page 2')\n  })\n\n  test('sorts users by name', async ({ page }) => {\n    await page.goto('/users?sort=name')\n\n    const userNames = await page.locator('[data-testid=\"user-name\"]').allTextContents()\n\n    // Verify sorted\n    const sorted = [...userNames].sort()\n    expect(userNames).toEqual(sorted)\n  })\n})\n```\n\n## Validation\n\nAfter generating tests:\n\n1. **Syntax check**: Verify TypeScript compiles\n2. **Dry run**: Run tests without executing\n3. **Coverage**: Ensure critical paths covered\n\n```bash\n# Check syntax\nnpx tsc --noEmit\n\n# Dry run\npnpm test:e2e --list\n\n# Run generated tests\npnpm test:e2e e2e/routes/users.$id.spec.ts\n```\n\n## Success Criteria\n\nâœ… Tests generated for target\nâœ… All tests pass on first run\nâœ… Accessibility tests included\nâœ… Error handling covered\nâœ… Loading states tested\nâœ… Documentation generated\nâœ… Test registered in test suite\n\n## Resources\n\n- **Playwright Best Practices**: https://playwright.dev/docs/best-practices\n- **Testing TanStack Router**: https://tanstack.com/router/latest/docs/framework/react/guide/testing\n- **Accessibility Testing**: https://playwright.dev/docs/accessibility-testing"
              },
              {
                "name": "/es-test-setup",
                "description": "Initialize Playwright E2E testing for Tanstack Start projects with Cloudflare Workers-specific configuration",
                "path": "plugins/edge-stack/commands/es-test-setup.md",
                "frontmatter": {
                  "description": "Initialize Playwright E2E testing for Tanstack Start projects with Cloudflare Workers-specific configuration"
                },
                "content": "# Playwright Test Setup Command\n\n<command_purpose> Configure Playwright for end-to-end testing in Tanstack Start projects deployed to Cloudflare Workers. Sets up test infrastructure, accessibility testing, and Workers-specific patterns. </command_purpose>\n\n## Introduction\n\n<role>Senior QA Engineer specializing in Playwright setup for Tanstack Start + Cloudflare Workers applications</role>\n\nThis command initializes a complete Playwright testing setup optimized for:\n- Tanstack Start (React + TanStack Router)\n- Cloudflare Workers deployment\n- Server function testing\n- Cloudflare bindings (KV, D1, R2, DO)\n- Accessibility testing\n- Performance monitoring\n\n## Prerequisites\n\n<requirements>\n- Tanstack Start project initialized\n- Cloudflare Workers configured (wrangler.jsonc)\n- Node.js 18+\n- npm/pnpm/yarn\n</requirements>\n\n## Main Tasks\n\n### 1. Verify Project Setup\n\n<thinking>\nEnsure this is a Tanstack Start project before installing Playwright.\n</thinking>\n\n```bash\n# Check for Tanstack Start\nif ! grep -q \"@tanstack/start\" package.json; then\n  echo \"âŒ Not a Tanstack Start project\"\n  echo \"This command requires Tanstack Start.\"\n  exit 1\nfi\n\n# Check for wrangler config\nif [ ! -f \"wrangler.jsonc\" ] && [ ! -f \"wrangler.toml\" ]; then\n  echo \"âš ï¸  No wrangler config found\"\n  echo \"Playwright will be configured, but Cloudflare bindings tests may not work.\"\nfi\n```\n\n### 2. Install Playwright Dependencies\n\n```bash\n# Install Playwright and dependencies\npnpm add -D @playwright/test @axe-core/playwright\n\n# Install browsers\nnpx playwright install --with-deps chromium firefox webkit\n```\n\n### 3. Create Playwright Configuration\n\n**File**: `playwright.config.ts`\n\n```typescript\nimport { defineConfig, devices } from '@playwright/test'\n\nexport default defineConfig({\n  testDir: './e2e',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n\n  reporter: [\n    ['html'],\n    ['list'],\n    process.env.CI ? ['github'] : ['list'],\n  ],\n\n  use: {\n    baseURL: process.env.PLAYWRIGHT_TEST_BASE_URL || 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n    video: 'retain-on-failure',\n  },\n\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n    {\n      name: 'firefox',\n      use: { ...devices['Desktop Firefox'] },\n    },\n    {\n      name: 'webkit',\n      use: { ...devices['Desktop Safari'] },\n    },\n    {\n      name: 'Mobile Chrome',\n      use: { ...devices['Pixel 5'] },\n    },\n    {\n      name: 'Mobile Safari',\n      use: { ...devices['iPhone 12'] },\n    },\n  ],\n\n  webServer: {\n    command: 'pnpm dev',\n    url: 'http://localhost:3000',\n    reuseExistingServer: !process.env.CI,\n    timeout: 120 * 1000,\n  },\n})\n```\n\n### 4. Create Directory Structure\n\n```bash\nmkdir -p e2e/{routes,server-functions,components,auth,accessibility,performance,visual,fixtures}\n```\n\n### 5. Create Example Tests\n\n**File**: `e2e/example.spec.ts`\n\n```typescript\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Example Tests', () => {\n  test('home page loads', async ({ page }) => {\n    await page.goto('/')\n\n    await expect(page).toHaveTitle(/.*/)\n    await expect(page.locator('body')).toBeVisible()\n  })\n\n  test('has no console errors', async ({ page }) => {\n    const errors: string[] = []\n\n    page.on('console', msg => {\n      if (msg.type() === 'error') {\n        errors.push(msg.text())\n      }\n    })\n\n    await page.goto('/')\n\n    expect(errors).toHaveLength(0)\n  })\n})\n```\n\n**File**: `e2e/accessibility/home.spec.ts`\n\n```typescript\nimport { test, expect } from '@playwright/test'\nimport AxeBuilder from '@axe-core/playwright'\n\ntest.describe('Accessibility', () => {\n  test('home page has no a11y violations', async ({ page }) => {\n    await page.goto('/')\n\n    const accessibilityScanResults = await new AxeBuilder({ page })\n      .analyze()\n\n    expect(accessibilityScanResults.violations).toEqual([])\n  })\n})\n```\n\n**File**: `e2e/performance/metrics.spec.ts`\n\n```typescript\nimport { test, expect } from '@playwright/test'\n\ntest.describe('Performance', () => {\n  test('measures page load time', async ({ page }) => {\n    const startTime = Date.now()\n    await page.goto('/')\n    await page.waitForLoadState('networkidle')\n    const loadTime = Date.now() - startTime\n\n    console.log(`Page load time: ${loadTime}ms`)\n\n    // Cloudflare Workers should load fast\n    expect(loadTime).toBeLessThan(1000)\n  })\n\n  test('measures TTFB', async ({ page }) => {\n    await page.goto('/')\n\n    const timing = await page.evaluate(() =>\n      JSON.parse(JSON.stringify(\n        performance.getEntriesByType('navigation')[0]\n      ))\n    )\n\n    const ttfb = timing.responseStart - timing.requestStart\n    console.log(`TTFB: ${ttfb}ms`)\n\n    // Time to First Byte should be fast on Workers\n    expect(ttfb).toBeLessThan(200)\n  })\n})\n```\n\n### 6. Create Test Fixtures\n\n**File**: `e2e/fixtures/test-users.ts`\n\n```typescript\nexport const testUsers = {\n  admin: {\n    email: 'admin@test.com',\n    password: 'admin123',\n    name: 'Admin User',\n  },\n  regular: {\n    email: 'user@test.com',\n    password: 'user123',\n    name: 'Regular User',\n  },\n}\n```\n\n### 7. Update package.json Scripts\n\n```json\n{\n  \"scripts\": {\n    \"test:e2e\": \"playwright test\",\n    \"test:e2e:ui\": \"playwright test --ui\",\n    \"test:e2e:debug\": \"playwright test --debug\",\n    \"test:e2e:headed\": \"playwright test --headed\",\n    \"test:e2e:report\": \"playwright show-report\"\n  }\n}\n```\n\n### 8. Create .env.test for Cloudflare Bindings\n\n**File**: `.env.test`\n\n```bash\n# Cloudflare Test Environment\nCLOUDFLARE_ACCOUNT_ID=your-test-account-id\nCLOUDFLARE_API_TOKEN=your-test-api-token\n\n# Test Bindings (separate from production)\nKV_NAMESPACE_ID=test-kv-namespace-id\nD1_DATABASE_ID=test-d1-database-id\nR2_BUCKET_NAME=test-r2-bucket\n\n# Test Base URL\nPLAYWRIGHT_TEST_BASE_URL=http://localhost:3000\n```\n\n### 9. Create GitHub Actions Workflow (Optional)\n\n**File**: `.github/workflows/e2e.yml`\n\n```yaml\nname: E2E Tests\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    timeout-minutes: 60\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n\n      - name: Install dependencies\n        run: pnpm install\n\n      - name: Install Playwright Browsers\n        run: npx playwright install --with-deps\n\n      - name: Run Playwright tests\n        run: pnpm test:e2e\n        env:\n          CLOUDFLARE_ACCOUNT_ID: ${ secrets.CLOUDFLARE_ACCOUNT_ID}\n          CLOUDFLARE_API_TOKEN: ${ secrets.CLOUDFLARE_API_TOKEN}\n\n      - name: Upload Playwright Report\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: playwright-report\n          path: playwright-report/\n          retention-days: 30\n```\n\n### 10. Create Testing Guide\n\n**File**: `e2e/README.md`\n\n```markdown\n# E2E Testing Guide\n\n## Running Tests\n\n```bash\n# Run all tests\npnpm test:e2e\n\n# Run with UI mode\npnpm test:e2e:ui\n\n# Run specific test file\npnpm test:e2e e2e/routes/home.spec.ts\n\n# Run in headed mode (see browser)\npnpm test:e2e:headed\n\n# Debug mode\npnpm test:e2e:debug\n```\n\n## Test Organization\n\n- `routes/` - Tests for TanStack Router routes\n- `server-functions/` - Tests for server functions\n- `components/` - Tests for shadcn/ui components\n- `auth/` - Authentication flow tests\n- `accessibility/` - Accessibility tests (axe-core)\n- `performance/` - Performance and load time tests\n- `visual/` - Visual regression tests\n- `fixtures/` - Test data and helpers\n\n## Best Practices\n\n1. **Test user behavior, not implementation**\n   - Focus on what users see and do\n   - Avoid testing internal state\n\n2. **Use data-testid for stable selectors**\n   ```tsx\n   <button data-testid=\"submit-button\">Submit</button>\n   ```\n\n3. **Test with real Cloudflare bindings**\n   - Use test environment bindings\n   - Don't mock KV, D1, R2, DO\n\n4. **Run accessibility tests on every page**\n   - Zero violations policy\n   - Use @axe-core/playwright\n\n5. **Monitor performance metrics**\n   - Cold start < 500ms\n   - TTFB < 200ms\n   - Bundle size < 200KB\n```\n\n### 11. Add .gitignore Entries\n\n```bash\n# Add to .gitignore\ncat >> .gitignore << 'EOF'\n\n# Playwright\n/test-results/\n/playwright-report/\n/playwright/.cache/\nEOF\n```\n\n### 12. Validation\n\n**Task playwright-testing-specialist(verify setup)**:\n- Confirm Playwright installed\n- Verify browser binaries downloaded\n- Check test directory structure\n- Validate configuration file\n- Run example test to ensure setup works\n\n```bash\n# Run validation\npnpm test:e2e --reporter=list\n\n# Should see:\n# âœ“ example.spec.ts:5:3 â€º Example Tests â€º home page loads\n# âœ“ accessibility/home.spec.ts:6:3 â€º Accessibility â€º home page has no a11y violations\n# âœ“ performance/metrics.spec.ts:6:3 â€º Performance â€º measures page load time\n```\n\n## Output\n\nAfter running `/es-test-setup`, you will have:\n\nâœ… Playwright installed with all browsers\nâœ… Test directory structure created\nâœ… Configuration file (playwright.config.ts)\nâœ… Example tests (routes, accessibility, performance)\nâœ… Test fixtures and helpers\nâœ… npm scripts for running tests\nâœ… CI/CD workflow template\nâœ… Testing guide documentation\n\n## Next Steps\n\n1. **Run example tests**:\n   ```bash\n   pnpm test:e2e\n   ```\n\n2. **Generate tests for your routes**:\n   ```bash\n   /es-test-gen /users/$id\n   ```\n\n3. **Add tests to your workflow**:\n   - Write tests as you build features\n   - Run tests before deployment\n   - Monitor test results in CI/CD\n\n## Troubleshooting\n\n### Issue: \"Cannot find module '@playwright/test'\"\n\n**Solution**:\n```bash\npnpm install\nnpx playwright install\n```\n\n### Issue: \"Browser not found\"\n\n**Solution**:\n```bash\nnpx playwright install --with-deps\n```\n\n### Issue: \"Tests timing out\"\n\n**Solution**: Increase timeout in `playwright.config.ts`:\n```typescript\nexport default defineConfig({\n  timeout: 60 * 1000, // 60 seconds per test\n  // ...\n})\n```\n\n### Issue: \"Accessibility violations found\"\n\n**Solution**: Fix the violations! Playwright will show you exactly what's wrong:\n```\nExpected: []\nReceived: [\n  {\n    \"id\": \"color-contrast\",\n    \"impact\": \"serious\",\n    \"description\": \"Ensures the contrast between foreground and background colors meets WCAG 2 AA contrast ratio thresholds\",\n    \"nodes\": [...]\n  }\n]\n```\n\n## Resources\n\n- **Playwright Docs**: https://playwright.dev\n- **Axe Accessibility**: https://github.com/dequelabs/axe-core-npm/tree/develop/packages/playwright\n- **Cloudflare Testing**: https://developers.cloudflare.com/workers/testing/\n- **Best Practices**: https://playwright.dev/docs/best-practices\n\n## Success Criteria\n\nâœ… Playwright installed and configured\nâœ… Example tests passing\nâœ… Accessibility testing enabled\nâœ… Performance monitoring setup\nâœ… CI/CD workflow ready\nâœ… Team trained on testing practices"
              },
              {
                "name": "/es-theme",
                "description": "Generate or update custom design themes for Tailwind CSS and shadcn/ui. Creates distinctive typography, colors, animations, and design tokens to prevent generic \"AI aesthetic\"",
                "path": "plugins/edge-stack/commands/es-theme.md",
                "frontmatter": {
                  "description": "Generate or update custom design themes for Tailwind CSS and shadcn/ui. Creates distinctive typography, colors, animations, and design tokens to prevent generic \"AI aesthetic\""
                },
                "content": "# Theme Generator Command\n\n<command_purpose> Generate distinctive design themes that prevent generic aesthetics. Creates custom Tailwind configuration with unique fonts, brand colors, animation presets, and shadcn/ui customizations. Replaces Inter fonts, purple gradients, and minimal animations with branded alternatives. </command_purpose>\n\n## Introduction\n\n<role>Senior Design Systems Architect with expertise in Tailwind CSS theming, color theory, typography, animation design, and brand identity</role>\n\n**Design Philosophy**: Establish a distinctive visual identity from the start through a comprehensive design system.\n\n## Prerequisites\n\n<requirements>\n- Tanstack Start project with Tailwind CSS configured\n- shadcn/ui installed\n- Access to custom font files or Google Fonts\n- Brand color palette (or will be generated)\n</requirements>\n\n## Command Usage\n\n```bash\n/es-theme [options]\n```\n\n### Options:\n\n- `--palette <name>`: Pre-defined color palette (coral-ocean, midnight-gold, forest-sage, custom)\n- `--fonts <style>`: Font pairing style (modern, classic, playful, technical)\n- `--animations <level>`: Animation richness (minimal, standard, rich)\n- `--mode <create|update>`: Create new theme or update existing\n- `--interactive`: Launch interactive theme builder\n\n### Examples:\n\n```bash\n# Generate theme with coral-ocean palette and modern fonts\n/es-theme --palette coral-ocean --fonts modern --animations rich\n\n# Interactive theme builder\n/es-theme --interactive\n\n# Update existing theme\n/es-theme --mode update\n```\n\n## Main Tasks\n\n### 1. Analyze Current Theme\n\n<thinking>\nFirst, check if a theme already exists and analyze generic patterns.\n</thinking>\n\n#### Current Theme Analysis:\n\n<analysis_steps>\n\n- [ ] Check `tailwind.config.ts` for existing configuration\n- [ ] Detect Inter/Roboto fonts (generic âŒ)\n- [ ] Detect default purple colors (generic âŒ)\n- [ ] Check for custom animation presets\n- [ ] Check `app.config.ts` for shadcn/ui customization\n- [ ] Analyze existing component usage patterns\n\n</analysis_steps>\n\n### 2. Generate Color Palette\n\n<thinking>\nCreate or select a distinctive color palette that reflects brand identity.\nEnsure all colors meet WCAG 2.1 AA contrast requirements.\n</thinking>\n\n#### Pre-defined Palettes:\n\n<color_palettes>\n\n**Coral Ocean** (Warm & Vibrant):\n```typescript\ncolors: {\n  brand: {\n    coral: {\n      50: '#FFF5F5',\n      100: '#FFE3E3',\n      200: '#FFC9C9',\n      300: '#FFA8A8',\n      400: '#FF8787',\n      500: '#FF6B6B',  // Primary\n      600: '#FA5252',\n      700: '#F03E3E',\n      800: '#E03131',\n      900: '#C92A2A',\n    },\n    ocean: {\n      50: '#F0FDFA',\n      100: '#CCFBF1',\n      200: '#99F6E4',\n      300: '#5EEAD4',\n      400: '#2DD4BF',\n      500: '#4ECDC4',  // Secondary\n      600: '#0D9488',\n      700: '#0F766E',\n      800: '#115E59',\n      900: '#134E4A',\n    },\n    sunset: {\n      50: '#FFFEF0',\n      100: '#FFFACD',\n      200: '#FFF59D',\n      300: '#FFF176',\n      400: '#FFEE58',\n      500: '#FFE66D',  // Accent\n      600: '#FDD835',\n      700: '#FBC02D',\n      800: '#F9A825',\n      900: '#F57F17',\n    },\n    midnight: '#2C3E50',\n    cream: '#FFF5E1'\n  }\n}\n```\n\n**Midnight Gold** (Elegant & Professional):\n```typescript\ncolors: {\n  brand: {\n    midnight: {\n      50: '#F8FAFC',\n      100: '#F1F5F9',\n      200: '#E2E8F0',\n      300: '#CBD5E1',\n      400: '#94A3B8',\n      500: '#2C3E50',  // Primary\n      600: '#475569',\n      700: '#334155',\n      800: '#1E293B',\n      900: '#0F172A',\n    },\n    gold: {\n      50: '#FFFBEB',\n      100: '#FEF3C7',\n      200: '#FDE68A',\n      300: '#FCD34D',\n      400: '#FBBF24',\n      500: '#D4AF37',  // Secondary\n      600: '#D97706',\n      700: '#B45309',\n      800: '#92400E',\n      900: '#78350F',\n    }\n  }\n}\n```\n\n**Forest Sage** (Natural & Calming):\n```typescript\ncolors: {\n  brand: {\n    forest: {\n      50: '#F0FDF4',\n      100: '#DCFCE7',\n      200: '#BBF7D0',\n      300: '#86EFAC',\n      400: '#4ADE80',\n      500: '#2D5F3F',  // Primary\n      600: '#16A34A',\n      700: '#15803D',\n      800: '#166534',\n      900: '#14532D',\n    },\n    sage: {\n      50: '#F7F7F5',\n      100: '#EAEAE5',\n      200: '#D4D4C8',\n      300: '#B8B8A7',\n      400: '#9C9C88',\n      500: '#8B9A7C',  // Secondary\n      600: '#6F7F63',\n      700: '#5A664F',\n      800: '#454D3F',\n      900: '#313730',\n    }\n  }\n}\n```\n\n</color_palettes>\n\n### 3. Select Font Pairings\n\n<thinking>\nChoose distinctive font combinations that avoid Inter/Roboto.\nEnsure fonts are performant and accessible.\n</thinking>\n\n#### Font Pairing Styles:\n\n<font_pairings>\n\n**Modern** (Clean & Contemporary):\n```typescript\nfontFamily: {\n  sans: ['Space Grotesk', 'system-ui', 'sans-serif'],\n  heading: ['Archivo Black', 'system-ui', 'sans-serif'],\n  mono: ['JetBrains Mono', 'monospace']\n}\n```\n\n**Classic** (Timeless & Professional):\n```typescript\nfontFamily: {\n  sans: ['Crimson Pro', 'Georgia', 'serif'],\n  heading: ['Playfair Display', 'Georgia', 'serif'],\n  mono: ['IBM Plex Mono', 'monospace']\n}\n```\n\n**Playful** (Creative & Energetic):\n```typescript\nfontFamily: {\n  sans: ['DM Sans', 'system-ui', 'sans-serif'],\n  heading: ['Fredoka', 'system-ui', 'sans-serif'],\n  mono: ['Fira Code', 'monospace']\n}\n```\n\n**Technical** (Precise & Modern):\n```typescript\nfontFamily: {\n  sans: ['Inter Display', 'system-ui', 'sans-serif'],  // Display variant (different from default Inter)\n  heading: ['JetBrains Mono', 'monospace'],\n  mono: ['Source Code Pro', 'monospace']\n}\n```\n\n</font_pairings>\n\n### 4. Create Animation Presets\n\n<thinking>\nDefine animation utilities that create engaging, performant micro-interactions.\n</thinking>\n\n#### Animation Configuration:\n\n<animation_config>\n\n```typescript\n// tailwind.config.ts\nexport default {\n  theme: {\n    extend: {\n      animation: {\n        // Fade animations\n        'fade-in': 'fadeIn 0.5s ease-out',\n        'fade-out': 'fadeOut 0.3s ease-in',\n\n        // Slide animations\n        'slide-up': 'slideUp 0.4s ease-out',\n        'slide-down': 'slideDown 0.4s ease-out',\n        'slide-left': 'slideLeft 0.4s ease-out',\n        'slide-right': 'slideRight 0.4s ease-out',\n\n        // Scale animations\n        'scale-in': 'scaleIn 0.3s ease-out',\n        'scale-out': 'scaleOut 0.2s ease-in',\n\n        // Bounce animations\n        'bounce-subtle': 'bounceSubtle 1s ease-in-out infinite',\n\n        // Pulse animations\n        'pulse-slow': 'pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite',\n        'pulse-fast': 'pulse 1s cubic-bezier(0.4, 0, 0.6, 1) infinite',\n\n        // Spin animations\n        'spin-slow': 'spin 3s linear infinite',\n        'spin-fast': 'spin 0.5s linear infinite',\n      },\n\n      keyframes: {\n        fadeIn: {\n          '0%': { opacity: '0' },\n          '100%': { opacity: '1' },\n        },\n        fadeOut: {\n          '0%': { opacity: '1' },\n          '100%': { opacity: '0' },\n        },\n        slideUp: {\n          '0%': { transform: 'translateY(20px)', opacity: '0' },\n          '100%': { transform: 'translateY(0)', opacity: '1' },\n        },\n        slideDown: {\n          '0%': { transform: 'translateY(-20px)', opacity: '0' },\n          '100%': { transform: 'translateY(0)', opacity: '1' },\n        },\n        slideLeft: {\n          '0%': { transform: 'translateX(20px)', opacity: '0' },\n          '100%': { transform: 'translateX(0)', opacity: '1' },\n        },\n        slideRight: {\n          '0%': { transform: 'translateX(-20px)', opacity: '0' },\n          '100%': { transform: 'translateX(0)', opacity: '1' },\n        },\n        scaleIn: {\n          '0%': { transform: 'scale(0.9)', opacity: '0' },\n          '100%': { transform: 'scale(1)', opacity: '1' },\n        },\n        scaleOut: {\n          '0%': { transform: 'scale(1)', opacity: '1' },\n          '100%': { transform: 'scale(0.9)', opacity: '0' },\n        },\n        bounceSubtle: {\n          '0%, 100%': { transform: 'translateY(0)' },\n          '50%': { transform: 'translateY(-5px)' },\n        },\n      },\n\n      // Transition duration extensions\n      transitionDuration: {\n        '400': '400ms',\n        '600': '600ms',\n        '800': '800ms',\n        '900': '900ms',\n      },\n    },\n  },\n};\n```\n\n</animation_config>\n\n### 5. Generate Complete Theme Configuration\n\n<thinking>\nCreate complete tailwind.config.ts with all theme customizations.\n</thinking>\n\n#### Generated Tailwind Config:\n\n<tailwind_config_template>\n\n```typescript\n// tailwind.config.ts\nimport type { Config } from 'tailwindcss';\nimport defaultTheme from 'tailwindcss/defaultTheme';\n\nexport default <Partial<Config>>{\n  theme: {\n    extend: {\n      // Typography\n      fontFamily: {\n        sans: ['Space Grotesk', ...defaultTheme.fontFamily.sans],\n        heading: ['Archivo Black', ...defaultTheme.fontFamily.sans],\n        mono: ['JetBrains Mono', ...defaultTheme.fontFamily.mono],\n      },\n\n      fontSize: {\n        // Extended font sizes with line heights\n        '2xs': ['0.625rem', { lineHeight: '0.75rem' }],\n        '6xl': ['3.75rem', { lineHeight: '1', letterSpacing: '-0.02em' }],\n        '7xl': ['4.5rem', { lineHeight: '1', letterSpacing: '-0.02em' }],\n        '8xl': ['6rem', { lineHeight: '1', letterSpacing: '-0.02em' }],\n        '9xl': ['8rem', { lineHeight: '1', letterSpacing: '-0.02em' }],\n      },\n\n      // Brand Colors\n      colors: {\n        brand: {\n          coral: {\n            DEFAULT: '#FF6B6B',\n            50: '#FFF5F5',\n            100: '#FFE3E3',\n            200: '#FFC9C9',\n            300: '#FFA8A8',\n            400: '#FF8787',\n            500: '#FF6B6B',\n            600: '#FA5252',\n            700: '#F03E3E',\n            800: '#E03131',\n            900: '#C92A2A',\n          },\n          ocean: {\n            DEFAULT: '#4ECDC4',\n            50: '#F0FDFA',\n            100: '#CCFBF1',\n            200: '#99F6E4',\n            300: '#5EEAD4',\n            400: '#2DD4BF',\n            500: '#4ECDC4',\n            600: '#0D9488',\n            700: '#0F766E',\n            800: '#115E59',\n            900: '#134E4A',\n          },\n          sunset: {\n            DEFAULT: '#FFE66D',\n            50: '#FFFEF0',\n            100: '#FFFACD',\n            200: '#FFF59D',\n            300: '#FFF176',\n            400: '#FFEE58',\n            500: '#FFE66D',\n            600: '#FDD835',\n            700: '#FBC02D',\n            800: '#F9A825',\n            900: '#F57F17',\n          },\n          midnight: {\n            DEFAULT: '#2C3E50',\n            50: '#F8FAFC',\n            100: '#F1F5F9',\n            200: '#E2E8F0',\n            300: '#CBD5E1',\n            400: '#94A3B8',\n            500: '#2C3E50',\n            600: '#475569',\n            700: '#334155',\n            800: '#1E293B',\n            900: '#0F172A',\n          },\n          cream: {\n            DEFAULT: '#FFF5E1',\n            50: '#FFFEF7',\n            100: '#FFFCEB',\n            200: '#FFF9D6',\n            300: '#FFF5E1',\n            400: '#FFF0C4',\n            500: '#FFEBA7',\n            600: '#FFE68A',\n            700: '#FFE06D',\n            800: '#FFDB50',\n            900: '#FFD633',\n          },\n        },\n      },\n\n      // Spacing extensions\n      spacing: {\n        '18': '4.5rem',\n        '22': '5.5rem',\n        '26': '6.5rem',\n        '30': '7.5rem',\n        '34': '8.5rem',\n        '38': '9.5rem',\n        '42': '10.5rem',\n        '46': '11.5rem',\n        '50': '12.5rem',\n        '54': '13.5rem',\n        '58': '14.5rem',\n        '62': '15.5rem',\n        '66': '16.5rem',\n        '70': '17.5rem',\n        '74': '18.5rem',\n        '78': '19.5rem',\n        '82': '20.5rem',\n        '86': '21.5rem',\n        '90': '22.5rem',\n        '94': '23.5rem',\n        '98': '24.5rem',\n      },\n\n      // Box shadows\n      boxShadow: {\n        'brand-sm': '0 2px 8px rgba(255, 107, 107, 0.1)',\n        'brand': '0 4px 20px rgba(255, 107, 107, 0.2)',\n        'brand-lg': '0 10px 40px rgba(255, 107, 107, 0.3)',\n        'ocean-sm': '0 2px 8px rgba(78, 205, 196, 0.1)',\n        'ocean': '0 4px 20px rgba(78, 205, 196, 0.2)',\n        'ocean-lg': '0 10px 40px rgba(78, 205, 196, 0.3)',\n        'elevated': '0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04)',\n      },\n\n      // Border radius\n      borderRadius: {\n        '4xl': '2rem',\n        '5xl': '2.5rem',\n        '6xl': '3rem',\n      },\n\n      // Animations (from animation config above)\n      animation: {\n        'fade-in': 'fadeIn 0.5s ease-out',\n        'fade-out': 'fadeOut 0.3s ease-in',\n        'slide-up': 'slideUp 0.4s ease-out',\n        'slide-down': 'slideDown 0.4s ease-out',\n        'slide-left': 'slideLeft 0.4s ease-out',\n        'slide-right': 'slideRight 0.4s ease-out',\n        'scale-in': 'scaleIn 0.3s ease-out',\n        'scale-out': 'scaleOut 0.2s ease-in',\n        'bounce-subtle': 'bounceSubtle 1s ease-in-out infinite',\n        'pulse-slow': 'pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite',\n        'pulse-fast': 'pulse 1s cubic-bezier(0.4, 0, 0.6, 1) infinite',\n        'spin-slow': 'spin 3s linear infinite',\n        'spin-fast': 'spin 0.5s linear infinite',\n      },\n\n      keyframes: {\n        fadeIn: {\n          '0%': { opacity: '0' },\n          '100%': { opacity: '1' },\n        },\n        fadeOut: {\n          '0%': { opacity: '1' },\n          '100%': { opacity: '0' },\n        },\n        slideUp: {\n          '0%': { transform: 'translateY(20px)', opacity: '0' },\n          '100%': { transform: 'translateY(0)', opacity: '1' },\n        },\n        slideDown: {\n          '0%': { transform: 'translateY(-20px)', opacity: '0' },\n          '100%': { transform: 'translateY(0)', opacity: '1' },\n        },\n        slideLeft: {\n          '0%': { transform: 'translateX(20px)', opacity: '0' },\n          '100%': { transform: 'translateX(0)', opacity: '1' },\n        },\n        slideRight: {\n          '0%': { transform: 'translateX(-20px)', opacity: '0' },\n          '100%': { transform: 'translateX(0)', opacity: '1' },\n        },\n        scaleIn: {\n          '0%': { transform: 'scale(0.9)', opacity: '0' },\n          '100%': { transform: 'scale(1)', opacity: '1' },\n        },\n        scaleOut: {\n          '0%': { transform: 'scale(1)', opacity: '1' },\n          '100%': { transform: 'scale(0.9)', opacity: '0' },\n        },\n        bounceSubtle: {\n          '0%, 100%': { transform: 'translateY(0)' },\n          '50%': { transform: 'translateY(-5px)' },\n        },\n      },\n\n      // Transition durations\n      transitionDuration: {\n        '400': '400ms',\n        '600': '600ms',\n        '800': '800ms',\n        '900': '900ms',\n      },\n    },\n  },\n};\n```\n\n</tailwind_config_template>\n\n### 6. Generate shadcn/ui Theme Customization\n\n<thinking>\nCreate app.config.ts with global shadcn/ui customizations.\n</thinking>\n\n#### shadcn/ui Config:\n\n<shadcn_ui_config>\n\n```typescript\n// app.config.ts\nexport default defineAppConfig({\n  ui: {\n    // Primary color (used by shadcn/ui components)\n    primary: 'brand-coral',\n    secondary: 'brand-ocean',\n    gray: 'neutral',\n\n    // Global component customization\n    button: {\n      default: {\n        size: 'md',\n        color: 'primary',\n        variant: 'solid',\n      },\n      rounded: 'rounded-lg',\n      font: 'font-heading tracking-wide',\n    },\n\n    card: {\n      background: 'bg-white dark:bg-brand-midnight-800',\n      rounded: 'rounded-2xl',\n      shadow: 'shadow-lg',\n      ring: 'ring-1 ring-gray-200 dark:ring-gray-700',\n    },\n\n    input: {\n      rounded: 'rounded-lg',\n      padding: {\n        sm: 'px-4 py-2',\n        md: 'px-4 py-3',\n        lg: 'px-6 py-4',\n      },\n    },\n\n    modal: {\n      rounded: 'rounded-2xl',\n      shadow: 'shadow-2xl',\n      background: 'bg-white dark:bg-brand-midnight-800',\n    },\n\n    // Notification settings\n    notifications: {\n      position: 'top-right',\n    },\n  },\n});\n```\n\n</shadcn_ui_config>\n\n### 7. Update Font Loading\n\n<thinking>\nConfigure font loading in app.config.ts (Google Fonts or local fonts).\n</thinking>\n\n#### Font Loading Config:\n\n<font_loading>\n\n```typescript\n// app.config.ts\nexport default defineNuxtConfig({\n  // ... other config\n\n  // Option 1: Google Fonts (recommended for quick setup)\n  googleFonts: {\n    families: {\n      'Space Grotesk': [400, 500, 600, 700],\n      'Archivo Black': [400],\n      'JetBrains Mono': [400, 500, 600, 700],\n    },\n    display: 'swap',  // Prevent FOIT (Flash of Invisible Text)\n    preload: true,\n  },\n\n  // Option 2: Local fonts (better performance)\n  css: ['~/assets/fonts/fonts.css'],\n\n  // ... other config\n});\n```\n\n```css\n/* assets/fonts/fonts.css (if using local fonts) */\n@font-face {\n  font-family: 'Space Grotesk';\n  src: url('/fonts/SpaceGrotesk-Variable.woff2') format('woff2-variations');\n  font-weight: 300 700;\n  font-display: swap;\n}\n\n@font-face {\n  font-family: 'Archivo Black';\n  src: url('/fonts/ArchivoBlack-Regular.woff2') format('woff2');\n  font-weight: 400;\n  font-display: swap;\n}\n\n@font-face {\n  font-family: 'JetBrains Mono';\n  src: url('/fonts/JetBrainsMono-Variable.woff2') format('woff2-variations');\n  font-weight: 400 700;\n  font-display: swap;\n}\n```\n\n</font_loading>\n\n## Output Format\n\n<output_format>\n\n```\nâœ… Custom Theme Generated\n\nðŸ“ Files Created/Updated:\n- tailwind.config.ts (complete theme configuration)\n- app.config.ts (shadcn/ui global customization)\n- app.config.ts (font loading configuration)\n- assets/fonts/fonts.css (if using local fonts)\n\nðŸŽ¨ Theme Summary:\n\n**Color Palette**: Coral Ocean\n- Primary: Coral (#FF6B6B) - Warm, energetic\n- Secondary: Ocean (#4ECDC4) - Calm, trustworthy\n- Accent: Sunset (#FFE66D) - Bright, attention-grabbing\n- Neutral: Midnight (#2C3E50) - Professional, elegant\n- Background: Cream (#FFF5E1) - Soft, inviting\n\n**Typography**: Modern\n- Sans: Space Grotesk (body text, UI elements)\n- Heading: Archivo Black (headings, impact text)\n- Mono: JetBrains Mono (code, technical content)\n\n**Animations**: Rich\n- 15 custom animation presets\n- Performant (GPU-accelerated properties only)\n- Respects prefers-reduced-motion\n\n**Accessibility**: WCAG 2.1 AA Compliant\nâœ… All color combinations meet 4.5:1 contrast ratio\nâœ… Focus states on all interactive elements\nâœ… Reduced motion support built-in\n\n---\n\nðŸ“– Usage Examples:\n\n**Typography**:\n```tsx\n<h1 class=\"font-heading text-6xl text-brand-midnight\">\n  Heading\n</h1>\n\n<p class=\"font-sans text-lg text-gray-700\">\n  Body text\n</p>\n\n<code class=\"font-mono text-sm text-brand-coral-600\">\n  Code snippet\n</code>\n```\n\n**Colors**:\n```tsx\n<div class=\"bg-brand-coral text-white\">\n  Primary action\n</div>\n\n<div class=\"bg-brand-ocean text-white\">\n  Secondary action\n</div>\n\n<div class=\"bg-gradient-to-br from-brand-coral via-brand-ocean to-brand-sunset\">\n  Gradient background\n</div>\n```\n\n**Animations**:\n```tsx\n<div class=\"animate-slide-up\">\n  Slides up on mount\n</div>\n\n<button class=\"transition-all hover:scale-105 hover:shadow-brand-lg\">\n  Animated button\n</button>\n\n<div class=\"animate-pulse-slow\">\n  Subtle pulse\n</div>\n```\n\n**shadcn/ui with Theme**:\n```tsx\n<!-- Automatically uses theme colors -->\n<Button color=\"primary\">\n  Uses brand-coral\n</Button>\n\n<Card class=\"shadow-brand\">\n  Uses theme shadows\n</Card>\n```\n\n---\n\nðŸ” Next Steps:\n1. âœ… Review `tailwind.config.ts` for customizations\n2. âœ… Test theme with `/es-component button TestButton`\n3. âœ… Run `/es-design-review` to validate distinctiveness\n4. âœ… Update existing components to use new theme\n5. âœ… Test dark mode support\n6. âœ… Verify WCAG contrast ratios\n\nðŸ“Š Distinctiveness Improvement:\n- Before: 35/100 (Generic Inter + Purple)\n- After: 90/100 (Distinctive brand theme)\n\nYour project now has a distinctive visual identity! ðŸŽ¨\n```\n\n</output_format>\n\n## Success Criteria\n\nâœ… Theme generated successfully when:\n- `tailwind.config.ts` has custom fonts (not Inter/Roboto)\n- Custom color palette defined (not default purple)\n- 15+ animation presets created\n- All colors meet WCAG 2.1 AA contrast requirements\n- Fonts configured in `app.config.ts`\n- shadcn/ui customization in `app.config.ts`\n- Design system composable updated\n\n## Post-Generation Actions\n\nAfter generating theme:\n1. **Test theme**: Create test component with `/es-component`\n2. **Validate design**: Run `/es-design-review`\n3. **Check accessibility**: Verify contrast ratios\n4. **Update components**: Apply theme to existing components\n5. **Document**: Add theme documentation to project\n\n## Notes\n\n- Theme replaces generic patterns (Inter, purple) with distinctive alternatives\n- All colors are contrast-validated for accessibility\n- Animations respect `prefers-reduced-motion`\n- Theme is fully customizable after generation\n- Works seamlessly with shadcn/ui components"
              },
              {
                "name": "/es-triage",
                "description": "Triage findings and decisions to add to the CLI todo system",
                "path": "plugins/edge-stack/commands/es-triage.md",
                "frontmatter": {
                  "description": "Triage findings and decisions to add to the CLI todo system"
                },
                "content": "Present all findings, decisions, or issues here one by one for triage. The goal is to go through each item and decide whether to add it to the CLI todo system.\n\n**IMPORTANT: DO NOT CODE ANYTHING DURING TRIAGE!**\n\nThis command is for:\n- Triaging code review findings\n- Processing security audit results\n- Reviewing performance analysis\n- Handling any other categorized findings that need tracking\n\n## Workflow\n\n### Step 1: Present Each Finding\n\nFor each finding, present in this format:\n\n```\n---\nIssue #X: [Brief Title]\n\nSeverity: ðŸ”´ P1 (CRITICAL) / ðŸŸ¡ P2 (IMPORTANT) / ðŸ”µ P3 (NICE-TO-HAVE)\n\nCategory: [Security/Performance/Architecture/Bug/Feature/etc.]\n\nDescription:\n[Detailed explanation of the issue or improvement]\n\nLocation: [file_path:line_number]\n\nProblem Scenario:\n[Step by step what's wrong or could happen]\n\nProposed Solution:\n[How to fix it]\n\nEstimated Effort: [Small (< 2 hours) / Medium (2-8 hours) / Large (> 8 hours)]\n\n---\nDo you want to add this to the todo list?\n1. yes - create todo file\n2. next - skip this item\n3. custom - modify before creating\n```\n\n### Step 2: Handle User Decision\n\n**When user says \"yes\":**\n\n1. **Determine next issue ID:**\n   ```bash\n   ls todos/ | grep -o '^[0-9]\\+' | sort -n | tail -1\n   ```\n\n2. **Create filename:**\n   ```\n   {next_id}-pending-{priority}-{brief-description}.md\n   ```\n\n   Priority mapping:\n   - ðŸ”´ P1 (CRITICAL) â†’ `p1`\n   - ðŸŸ¡ P2 (IMPORTANT) â†’ `p2`\n   - ðŸ”µ P3 (NICE-TO-HAVE) â†’ `p3`\n\n   Example: `042-pending-p1-transaction-boundaries.md`\n\n3. **Create from template:**\n   ```bash\n   cp todos/000-pending-p1-TEMPLATE.md todos/{new_filename}\n   ```\n\n4. **Populate the file:**\n   ```yaml\n   ---\n   status: pending\n   priority: p1  # or p2, p3 based on severity\n   issue_id: \"042\"\n   tags: [category, workers, durable-objects, kv, r2, etc.]\n   dependencies: []\n   ---\n\n   # [Issue Title]\n\n   ## Problem Statement\n   [Description from finding]\n\n   ## Findings\n   - [Key discoveries]\n   - Location: [file_path:line_number]\n   - [Scenario details]\n\n   ## Proposed Solutions\n\n   ### Option 1: [Primary solution]\n   - **Pros**: [Benefits]\n   - **Cons**: [Drawbacks if any]\n   - **Effort**: [Small/Medium/Large]\n   - **Risk**: [Low/Medium/High]\n\n   ## Recommended Action\n   [Leave blank - will be filled during approval]\n\n   ## Technical Details\n   - **Affected Files**: [List files]\n   - **Related Components**: [Components affected]\n   - **Database Changes**: [Yes/No - describe if yes]\n\n   ## Resources\n   - Original finding: [Source of this issue]\n   - Related issues: [If any]\n\n   ## Acceptance Criteria\n   - [ ] [Specific success criteria]\n   - [ ] Tests pass\n   - [ ] Code reviewed\n\n   ## Work Log\n\n   ### {date} - Initial Discovery\n   **By:** Claude Triage System\n   **Actions:**\n   - Issue discovered during [triage session type]\n   - Categorized as {severity}\n   - Estimated effort: {effort}\n\n   **Learnings:**\n   - [Context and insights]\n\n   ## Notes\n   Source: Triage session on {date}\n   ```\n\n5. **Confirm creation:**\n   \"âœ… Created: `{filename}` - Issue #{issue_id}\"\n\n**When user says \"next\":**\n- Skip to the next item\n- Track skipped items for summary\n\n**When user says \"custom\":**\n- Ask what to modify (priority, description, details)\n- Update the information\n- Present revised version\n- Ask again: yes/next/custom\n\n**Cloudflare-Specific Tags to Use:**\n- `workers-runtime` - V8 runtime issues, Node.js API usage\n- `bindings` - KV/R2/D1/DO binding configuration or usage\n- `security` - Workers security model, secrets, CORS\n- `performance` - Cold starts, bundle size, edge optimization\n- `durable-objects` - DO patterns, state persistence, WebSockets\n- `kv` - KV usage patterns, TTL, consistency\n- `r2` - R2 storage patterns, uploads, streaming\n- `d1` - D1 database patterns, migrations, queries\n- `edge-caching` - Cache API patterns, invalidation\n- `workers-ai` - AI integration, Vercel AI SDK, RAG\n\n### Step 3: Continue Until All Processed\n\n- Process all items one by one\n- Track using TodoWrite for visibility\n- Don't wait for approval between items - keep moving\n\n### Step 4: Final Summary\n\nAfter all items processed:\n\n```markdown\n## Triage Complete\n\n**Total Items:** [X]\n**Todos Created:** [Y]\n**Skipped:** [Z]\n\n### Created Todos:\n- `042-pending-p1-transaction-boundaries.md` - Transaction boundary issue\n- `043-pending-p2-cache-optimization.md` - Cache performance improvement\n...\n\n### Skipped Items:\n- Item #5: [reason]\n- Item #12: [reason]\n\n### Next Steps:\n1. Review pending todos: `ls todos/*-pending-*.md`\n2. Approve for work: Move from pending â†’ ready status\n3. Start work: Use `/resolve_todo_parallel` or pick individually\n```\n\n## Example Response Format\n\n```\n---\nIssue #5: Missing Transaction Boundaries for Multi-Step Operations\n\nSeverity: ðŸ”´ P1 (CRITICAL)\n\nCategory: Data Integrity / Security\n\nDescription:\nThe google_oauth2_connected callback in GoogleOauthCallbacks concern performs multiple database\noperations without transaction protection. If any step fails midway, the database is left in an\ninconsistent state.\n\nLocation: app/controllers/concerns/google_oauth_callbacks.rb:13-50\n\nProblem Scenario:\n1. User.update succeeds (email changed)\n2. Account.save! fails (validation error)\n3. Result: User has changed email but no associated Account\n4. Next login attempt fails completely\n\nOperations Without Transaction:\n- User confirmation (line 13)\n- Waitlist removal (line 14)\n- User profile update (line 21-23)\n- Account creation (line 28-37)\n- Avatar attachment (line 39-45)\n- Journey creation (line 47)\n\nProposed Solution:\nWrap all operations in ApplicationRecord.transaction do ... end block\n\nEstimated Effort: Small (30 minutes)\n\n---\nDo you want to add this to the todo list?\n1. yes - create todo file\n2. next - skip this item\n3. custom - modify before creating\n```\n\nDo not code, and if you say yes, make sure to mark the toâ€‘do as ready to pick up or something. If you make any changes, update the file and then continue to read the next one. If next is selecrte make sure to remove the toâ€‘do from the list since its not relevant.\n\nEvery time you present the toâ€‘do as a header, can you say what the progress of the triage is, how many we have done and how many are left, and an estimated time for completion, looking at how quickly we go through them as well?"
              },
              {
                "name": "/es-validate",
                "description": "Run Cloudflare Workers validation checks before committing code",
                "path": "plugins/edge-stack/commands/es-validate.md",
                "frontmatter": {
                  "description": "Run Cloudflare Workers validation checks before committing code"
                },
                "content": "# Cloudflare Validation Command\n\nRun comprehensive validation checks for Cloudflare Workers projects:\n\n## Validation Checks\n\n### Continuous SKILL-based Validation (Already Active During Development)\n\n**Cloudflare Workers SKILLs**:\n- **workers-runtime-validator**: Runtime compatibility validation\n- **cloudflare-security-checker**: Security pattern validation\n- **workers-binding-validator**: Binding configuration validation\n- **edge-performance-optimizer**: Performance optimization guidance\n- **kv-optimization-advisor**: KV storage optimization\n- **durable-objects-pattern-checker**: DO best practices validation\n- **cors-configuration-validator**: CORS setup validation\n\n**Frontend Design SKILLs** (if shadcn/ui components detected):\n- **shadcn-ui-design-validator**: Prevents generic aesthetics (Inter fonts, purple gradients, minimal animations)\n- **component-aesthetic-checker**: Validates shadcn/ui component customization depth and consistency\n- **animation-interaction-validator**: Ensures engaging animations, hover states, and loading feedback\n\n### Explicit Command Validation (Run by /validate)\n1. **Documentation sync** - Validates all docs reflect current state\n2. **wrangler.toml syntax** - Validates configuration file\n3. **compatibility_date** - Ensures current runtime version\n4. **TypeScript checks** - Runs typecheck if available\n5. **Build verification** - Runs build command and checks for errors\n6. **Linting** - Runs linter if available\n7. **Bundle size analysis** - Checks deployment size limits\n8. **Remote bindings** - Validates binding configuration\n\n## Usage\n\nRun this command before committing code:\n\n```\n/validate\n```\n\n## When to Use\n\n- Before `git commit` \n- After making configuration changes\n- Before deployment\n- When troubleshooting issues\n\n## Validation Rules\n\n### Strict Requirements\n- **0 errors** - All errors must be fixed before committing\n- **â‰¤5 warnings** - More than 5 warnings must be addressed before committing\n\n### Exit Codes\n- **0**: All checks passed âœ… (0 errors, â‰¤5 warnings)\n- **1**: Validation failed âŒ (fix issues before committing)\n\n## Build Requirements\n\nThe validation will:\n- **SKILL Summary**: Report any P1/P2 issues found by active SKILLs during development\n- Run `pnpm build` if build script exists (fails on any build errors)\n- Run `pnpm typecheck` if typecheck script exists (fails on any TypeScript errors)\n- Run `pnpm lint` if lint script exists (counts warnings toward threshold)\n- Fail fast on first error to save time\n- Enforce code quality: no errors, max 5 warnings\n\n**Integration Note**: SKILLs provide continuous validation during development, catching issues early. The /validate command provides explicit validation and summarizes any SKILL findings alongside traditional build/lint checks.\n\nThis helps catch issues early and ensures code quality before committing to repository.\n\n## Documentation Validation (Step 1)\n\n<thinking>\nBefore running any code validation, verify that all documentation is up-to-date.\nThis prevents committing code with outdated docs.\n</thinking>\n\n### Required Documentation Files\n\nThe plugin must maintain these documentation files:\n- **README.md** - Overview, features, command list, agent list, SKILL list\n- **PREFERENCES.md** - Development standards, billing/auth preferences, design guidelines\n- **IMPLEMENTATION-COMPLETE.md** or **IMPLEMENTATION_COMPLETE.md** - Implementation status\n- **POST-MERGE-ACTIVITIES.md** - Post-deployment tasks and monitoring\n- **TESTING.md** - Test specifications and strategies\n- **docs/mcp-usage-examples.md** - MCP query patterns\n\n### Documentation Validation Checks\n\n**1. Count actual files**:\n\n```bash\n# Count commands\nCOMMAND_COUNT=$(find commands -name \"es-*.md\" | wc -l)\nNON_ES_COMMANDS=$(find commands -name \"*.md\" ! -name \"es-*.md\" | wc -l)\nTOTAL_COMMANDS=$((COMMAND_COUNT + NON_ES_COMMANDS))\n\n# Count agents\nAGENT_COUNT=$(find agents -name \"*.md\" | wc -l)\n\n# Count SKILLs\nSKILL_COUNT=$(find skills -name \"SKILL.md\" | wc -l)\n\necho \"ðŸ“Š Actual counts:\"\necho \"  Commands: $TOTAL_COMMANDS ($COMMAND_COUNT /es-* + $NON_ES_COMMANDS other)\"\necho \"  Agents: $AGENT_COUNT\"\necho \"  SKILLs: $SKILL_COUNT\"\n```\n\n**2. Check README.md accuracy**:\n\n```bash\n# Extract counts from README\nREADME_COMMANDS=$(grep -oP '\\d+(?= workflow commands)' README.md || echo \"NOT_FOUND\")\nREADME_AGENTS=$(grep -oP '\\d+(?= specialized agents)' README.md || echo \"NOT_FOUND\")\nREADME_SKILLS=$(grep -oP '\\d+(?= autonomous SKILLs)' README.md || echo \"NOT_FOUND\")\n\necho \"\"\necho \"ðŸ“„ README.md claims:\"\necho \"  Commands: $README_COMMANDS\"\necho \"  Agents: $README_AGENTS\"\necho \"  SKILLs: $README_SKILLS\"\n\n# Compare\nDOCS_VALID=true\n\nif [ \"$README_COMMANDS\" != \"$TOTAL_COMMANDS\" ]; then\n  echo \"âŒ ERROR: README.md lists $README_COMMANDS commands, but found $TOTAL_COMMANDS\"\n  DOCS_VALID=false\nfi\n\nif [ \"$README_AGENTS\" != \"$AGENT_COUNT\" ]; then\n  echo \"âŒ ERROR: README.md lists $README_AGENTS agents, but found $AGENT_COUNT\"\n  DOCS_VALID=false\nfi\n\nif [ \"$README_SKILLS\" != \"$SKILL_COUNT\" ]; then\n  echo \"âŒ ERROR: README.md lists $README_SKILLS SKILLs, but found $SKILL_COUNT\"\n  DOCS_VALID=false\nfi\n\nif [ \"$DOCS_VALID\" = false ]; then\n  echo \"\"\n  echo \"âŒ Documentation validation FAILED\"\n  echo \"   Fix: Update README.md with correct counts before committing\"\n  exit 1\nfi\n```\n\n**3. Verify all commands are documented**:\n\n```bash\n# List all commands\nCOMMANDS_LIST=$(find commands -name \"*.md\" -exec basename {} .md \\; | sort)\n\n# Check if README mentions each command\nUNDOCUMENTED_COMMANDS=\"\"\nfor cmd in $COMMANDS_LIST; do\n  if ! grep -q \"/$cmd\" README.md 2>/dev/null; then\n    UNDOCUMENTED_COMMANDS=\"$UNDOCUMENTED_COMMANDS\\n  - /$cmd\"\n  fi\ndone\n\nif [ -n \"$UNDOCUMENTED_COMMANDS\" ]; then\n  echo \"âš ï¸  WARNING: Commands not mentioned in README.md:$UNDOCUMENTED_COMMANDS\"\n  echo \"   Consider adding documentation for these commands\"\nfi\n```\n\n**4. Check for outdated command references**:\n\n```bash\n# Check for /cf- references (should be /es- now)\nCF_REFS=$(grep -r '/cf-' --include=\"*.md\" 2>/dev/null | wc -l)\n\nif [ \"$CF_REFS\" -gt 0 ]; then\n  echo \"âŒ ERROR: Found $CF_REFS references to /cf-* commands (should be /es-*)\"\n  echo \"   Files with /cf- references:\"\n  grep -r '/cf-' --include=\"*.md\" -l 2>/dev/null\n  exit 1\nfi\n```\n\n**5. Verify MCP server list**:\n\n```bash\n# Count MCPs in .mcp.json\nif [ -f \".mcp.json\" ]; then\n  MCP_COUNT=$(jq '.mcpServers | keys | length' .mcp.json 2>/dev/null || echo \"0\")\n\n  # Check if README mentions correct MCP count\n  if ! grep -q \"$MCP_COUNT MCP\" README.md 2>/dev/null && ! grep -q \"${MCP_COUNT} MCP\" README.md 2>/dev/null; then\n    echo \"âš ï¸  WARNING: README.md may not list all $MCP_COUNT MCP servers\"\n  fi\nfi\n```\n\n**6. Check documentation freshness**:\n\n```bash\n# Find recently modified code files\nRECENT_CODE=$(find agents commands skills -name \"*.md\" -mtime -1 | wc -l)\n\nif [ \"$RECENT_CODE\" -gt 0 ]; then\n  # Check if README was also updated\n  README_MODIFIED=$(find README.md -mtime -1 | wc -l)\n\n  if [ \"$README_MODIFIED\" -eq 0 ]; then\n    echo \"âš ï¸  WARNING: $RECENT_CODE code files modified recently, but README.md not updated\"\n    echo \"   Consider updating README.md to reflect recent changes\"\n  fi\nfi\n```\n\n### Documentation Auto-Update\n\nIf documentation validation fails, offer to auto-update:\n\n```bash\nif [ \"$DOCS_VALID\" = false ]; then\n  echo \"\"\n  echo \"Would you like to auto-update documentation? (y/n)\"\n  read -r UPDATE_DOCS\n\n  if [ \"$UPDATE_DOCS\" = \"y\" ]; then\n    # Update README.md counts\n    sed -i \"s/\\*\\*[0-9]* specialized agents\\*\\*/\\*\\*$AGENT_COUNT specialized agents\\*\\*/g\" README.md\n    sed -i \"s/\\*\\*[0-9]* autonomous SKILLs\\*\\*/\\*\\*$SKILL_COUNT autonomous SKILLs\\*\\*/g\" README.md\n    sed -i \"s/\\*\\*[0-9]* workflow commands\\*\\*/\\*\\*$TOTAL_COMMANDS workflow commands\\*\\*/g\" README.md\n\n    echo \"âœ… README.md updated with correct counts\"\n    echo \"   Please review changes and commit\"\n  fi\nfi\n```\n\n### Documentation Validation Success\n\nIf all checks pass:\n\n```bash\necho \"\"\necho \"âœ… Documentation validation PASSED\"\necho \"   - All counts accurate\"\necho \"   - No outdated command references\"\necho \"   - All commands documented\"\n```"
              },
              {
                "name": "/es-verify-output",
                "description": "Comprehensive verification of AI-generated code with confidence scoring",
                "path": "plugins/edge-stack/commands/es-verify-output.md",
                "frontmatter": {
                  "description": "Comprehensive verification of AI-generated code with confidence scoring"
                },
                "content": "# AI Output Verification Command\n\n<command_purpose> Comprehensive verification of AI-generated or modified code with confidence scoring, specifically designed for Cloudflare Workers projects. </command_purpose>\n\n## Introduction\n\n<role>Code Verification Specialist with expertise in validating AI-generated code for production readiness</role>\n\n**Context**: Based on Anthropic's research \"How AI is transforming work at Anthropic\", developers can only \"fully delegate\" 0-20% of work without oversight. The \"supervision paradox\" means users need verification capabilities built into tools to check AI-generated code effectively.\n\nThis command provides comprehensive verification with confidence scoring to help you determine if AI-generated code is safe to deploy.\n\n## Prerequisites\n\n<requirements>\n- Cloudflare Workers project with wrangler.toml\n- Node.js project with package.json\n- Build tooling configured (TypeScript, ESLint, etc.)\n- Optional: wrangler dev running for local testing\n</requirements>\n\n## Command Usage\n\n```bash\n/es-verify-output [path]\n```\n\n### Arguments:\n\n- `[path]`: Optional path to specific file/directory to verify\n  - If empty: Verify all recent changes\n  - If provided: Verify specific file or directory\n\n### Examples:\n\n```bash\n# Verify all recent changes\n/es-verify-output\n\n# Verify specific file\n/es-verify-output src/index.ts\n\n# Verify entire src directory\n/es-verify-output src/\n```\n\n## Main Tasks\n\n### 1. Build Verification\n\n<thinking>\nFirst, ensure the code compiles and builds successfully. This is the most fundamental check.\n</thinking>\n\n#### Step 1: Clean Previous Build\n\n```bash\necho \"ðŸ§¹ Cleaning previous build artifacts...\"\nrm -rf dist/ .wrangler/ .output/ 2>/dev/null || true\necho \"âœ… Clean complete\"\n```\n\n#### Step 2: Install Dependencies\n\n```bash\necho \"ðŸ“¦ Verifying dependencies...\"\n\n# Check if node_modules exists\nif [ ! -d \"node_modules\" ]; then\n  echo \"âš ï¸  node_modules not found, installing...\"\n  npm install\nelse\n  echo \"âœ… Dependencies present\"\nfi\n```\n\n#### Step 3: Build Project\n\n```bash\necho \"ðŸ”¨ Building project...\"\n\nBUILD_STATUS=\"UNKNOWN\"\nBUILD_OUTPUT=\"\"\nBUILD_SIZE=\"unknown\"\n\n# Try different build commands\nif grep -q '\"build\"' package.json 2>/dev/null; then\n  BUILD_OUTPUT=$(npm run build 2>&1)\n  BUILD_EXIT_CODE=$?\n\n  if [ $BUILD_EXIT_CODE -eq 0 ]; then\n    BUILD_STATUS=\"PASSED\"\n\n    # Calculate bundle size\n    if [ -d \"dist\" ]; then\n      BUILD_SIZE=$(du -sh dist/ | cut -f1)\n    elif [ -d \".output\" ]; then\n      BUILD_SIZE=$(du -sh .output/ | cut -f1)\n    fi\n  else\n    BUILD_STATUS=\"FAILED\"\n  fi\nelse\n  # Try wrangler build\n  BUILD_OUTPUT=$(wrangler deploy --dry-run 2>&1)\n  BUILD_EXIT_CODE=$?\n\n  if [ $BUILD_EXIT_CODE -eq 0 ]; then\n    BUILD_STATUS=\"PASSED\"\n    BUILD_SIZE=$(echo \"$BUILD_OUTPUT\" | grep -oP 'size: \\K\\d+' | head -1 || echo \"unknown\")\n  else\n    BUILD_STATUS=\"FAILED\"\n  fi\nfi\n\necho \"Build status: $BUILD_STATUS\"\n```\n\n### 2. Linting & Type Checking\n\n<thinking>\nVerify code style and type safety. These checks catch common errors and ensure consistency.\n</thinking>\n\n#### Step 1: ESLint/Prettier Check\n\n```bash\necho \"ðŸŽ¨ Running linting checks...\"\n\nLINT_STATUS=\"UNKNOWN\"\nLINT_ERRORS=0\nLINT_WARNINGS=0\n\nif grep -q '\"lint\"' package.json 2>/dev/null; then\n  LINT_OUTPUT=$(npm run lint 2>&1)\n  LINT_EXIT_CODE=$?\n\n  # Parse output for errors/warnings\n  LINT_ERRORS=$(echo \"$LINT_OUTPUT\" | grep -oP '\\d+(?= error)' || echo \"0\")\n  LINT_WARNINGS=$(echo \"$LINT_OUTPUT\" | grep -oP '\\d+(?= warning)' || echo \"0\")\n\n  if [ $LINT_EXIT_CODE -eq 0 ]; then\n    LINT_STATUS=\"PASSED\"\n  else\n    LINT_STATUS=\"FAILED\"\n  fi\nelse\n  LINT_STATUS=\"SKIPPED\"\nfi\n\necho \"Lint status: $LINT_STATUS (errors: $LINT_ERRORS, warnings: $LINT_WARNINGS)\"\n```\n\n#### Step 2: TypeScript Type Checking\n\n```bash\necho \"ðŸ“˜ Running TypeScript type checking...\"\n\nTYPES_STATUS=\"UNKNOWN\"\nTYPES_ERRORS=0\n\nif grep -q '\"typecheck\"' package.json 2>/dev/null; then\n  TYPES_OUTPUT=$(npm run typecheck 2>&1)\n  TYPES_EXIT_CODE=$?\n\n  if [ $TYPES_EXIT_CODE -eq 0 ]; then\n    TYPES_STATUS=\"PASSED\"\n  else\n    TYPES_STATUS=\"FAILED\"\n    TYPES_ERRORS=$(echo \"$TYPES_OUTPUT\" | grep -c \"error TS\" || echo \"0\")\n  fi\nelif command -v tsc &> /dev/null; then\n  TYPES_OUTPUT=$(tsc --noEmit 2>&1)\n  TYPES_EXIT_CODE=$?\n\n  if [ $TYPES_EXIT_CODE -eq 0 ]; then\n    TYPES_STATUS=\"PASSED\"\n  else\n    TYPES_STATUS=\"FAILED\"\n    TYPES_ERRORS=$(echo \"$TYPES_OUTPUT\" | grep -c \"error TS\" || echo \"0\")\n  fi\nelse\n  TYPES_STATUS=\"SKIPPED\"\nfi\n\necho \"Type check status: $TYPES_STATUS (errors: $TYPES_ERRORS)\"\n```\n\n### 3. Workers Runtime Validation\n\n<thinking>\nCheck for Cloudflare Workers-specific issues: Node.js APIs, binding mismatches, and incompatible patterns.\n</thinking>\n\n#### Step 1: Forbidden Node.js API Detection\n\n```bash\necho \"ðŸš« Checking for forbidden Node.js APIs...\"\n\nRUNTIME_STATUS=\"PASSED\"\nFORBIDDEN_APIS=()\n\n# List of forbidden APIs\nFORBIDDEN_PATTERNS=(\n  \"require\\('fs'\\)\"\n  \"require\\('path'\\)\"\n  \"require\\('http'\\)\"\n  \"require\\('https'\\)\"\n  \"require\\('crypto'\\)\"\n  \"from 'fs'\"\n  \"from 'path'\"\n  \"from 'http'\"\n  \"from 'https'\"\n  \"from 'crypto'\"\n  \"process\\.env\\.\"\n  \"Buffer\\.\"\n  \"__dirname\"\n  \"__filename\"\n)\n\n# Search for forbidden patterns\nfor pattern in \"${FORBIDDEN_PATTERNS[@]}\"; do\n  if grep -rn \"$pattern\" src/ 2>/dev/null | grep -v \"node_modules\"; then\n    FORBIDDEN_APIS+=(\"$pattern\")\n    RUNTIME_STATUS=\"FAILED\"\n  fi\ndone\n\nif [ \"$RUNTIME_STATUS\" = \"PASSED\" ]; then\n  echo \"âœ… No forbidden APIs detected\"\nelse\n  echo \"âŒ Found forbidden APIs: ${#FORBIDDEN_APIS[@]}\"\nfi\n```\n\n#### Step 2: Binding Configuration Validation\n\n```bash\necho \"ðŸ”— Validating environment bindings...\"\n\nBINDINGS_STATUS=\"UNKNOWN\"\n\n# Check if wrangler.toml exists\nif [ ! -f \"wrangler.toml\" ]; then\n  echo \"âš ï¸  wrangler.toml not found\"\n  BINDINGS_STATUS=\"SKIPPED\"\nelse\n  # Run binding-context-analyzer agent\n  # Task binding-context-analyzer(current code)\n  # This agent will:\n  # - Parse wrangler.toml for all bindings\n  # - Check if code references match configured bindings\n  # - Verify env parameter usage patterns\n\n  echo \"Running binding analysis...\"\n  # Agent will report findings\n  BINDINGS_STATUS=\"PASSED\"\nfi\n```\n\n### 4. Local Testing (Optional)\n\n<thinking>\nIf wrangler dev is running, perform basic endpoint testing to catch runtime errors.\n</thinking>\n\n```bash\necho \"ðŸ§ª Checking for local dev server...\"\n\nLOCAL_TEST_STATUS=\"SKIPPED\"\n\n# Check if wrangler dev is running\nif curl -s http://localhost:8787 > /dev/null 2>&1; then\n  echo \"âœ… wrangler dev is running, performing basic tests...\"\n\n  # Test root endpoint\n  HTTP_STATUS=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8787/)\n\n  if [ \"$HTTP_STATUS\" = \"200\" ]; then\n    LOCAL_TEST_STATUS=\"PASSED\"\n    echo \"âœ… Local endpoint responding (HTTP $HTTP_STATUS)\"\n  else\n    LOCAL_TEST_STATUS=\"FAILED\"\n    echo \"âŒ Local endpoint error (HTTP $HTTP_STATUS)\"\n  fi\n\n  # Check console for errors\n  echo \"ðŸ’¡ Check your console for any runtime errors\"\nelse\n  echo \"âš ï¸  wrangler dev not running (skipping local tests)\"\n  echo \"   Start with: wrangler dev\"\n  LOCAL_TEST_STATUS=\"SKIPPED\"\nfi\n```\n\n### 5. Calculate Confidence Score\n\n<thinking>\nAggregate all verification results into a confidence score (0-100) similar to the code-review confidence scoring system.\n</thinking>\n\n```bash\necho \"ðŸ“Š Calculating confidence score...\"\n\nCONFIDENCE=100\n\n# Build check (critical: -40 if failed)\nif [ \"$BUILD_STATUS\" = \"FAILED\" ]; then\n  CONFIDENCE=$((CONFIDENCE - 40))\nelif [ \"$BUILD_STATUS\" = \"SKIPPED\" ]; then\n  CONFIDENCE=$((CONFIDENCE - 10))\nfi\n\n# Lint check (-5 per error, -1 per warning)\nif [ \"$LINT_STATUS\" = \"FAILED\" ]; then\n  CONFIDENCE=$((CONFIDENCE - LINT_ERRORS * 5 - LINT_WARNINGS))\nfi\n\n# Type check (critical: -30 if failed)\nif [ \"$TYPES_STATUS\" = \"FAILED\" ]; then\n  CONFIDENCE=$((CONFIDENCE - 30))\nfi\n\n# Runtime check (critical: -25 if failed)\nif [ \"$RUNTIME_STATUS\" = \"FAILED\" ]; then\n  CONFIDENCE=$((CONFIDENCE - 25))\nfi\n\n# Bindings check (-10 if failed)\nif [ \"$BINDINGS_STATUS\" = \"FAILED\" ]; then\n  CONFIDENCE=$((CONFIDENCE - 10))\nfi\n\n# Local test check (-5 if failed, no penalty for skipped)\nif [ \"$LOCAL_TEST_STATUS\" = \"FAILED\" ]; then\n  CONFIDENCE=$((CONFIDENCE - 5))\nfi\n\n# Ensure confidence is in 0-100 range\nif [ $CONFIDENCE -lt 0 ]; then\n  CONFIDENCE=0\nfi\n\n# Determine confidence level\nCONFIDENCE_LEVEL=\"UNKNOWN\"\nif [ $CONFIDENCE -ge 90 ]; then\n  CONFIDENCE_LEVEL=\"VERY HIGH\"\nelif [ $CONFIDENCE -ge 80 ]; then\n  CONFIDENCE_LEVEL=\"HIGH\"\nelif [ $CONFIDENCE -ge 70 ]; then\n  CONFIDENCE_LEVEL=\"MODERATE\"\nelif [ $CONFIDENCE -ge 50 ]; then\n  CONFIDENCE_LEVEL=\"LOW\"\nelse\n  CONFIDENCE_LEVEL=\"VERY LOW\"\nfi\n\n# Determine recommendation\nRECOMMENDATION=\"UNKNOWN\"\nif [ $CONFIDENCE -ge 85 ]; then\n  RECOMMENDATION=\"SAFE TO DEPLOY\"\nelif [ $CONFIDENCE -ge 70 ]; then\n  RECOMMENDATION=\"REVIEW WARNINGS BEFORE DEPLOY\"\nelif [ $CONFIDENCE -ge 50 ]; then\n  RECOMMENDATION=\"FIX ISSUES BEFORE DEPLOY\"\nelse\n  RECOMMENDATION=\"DO NOT DEPLOY - CRITICAL ISSUES\"\nfi\n```\n\n### 6. Generate Verification Report\n\n<deliverable>\nComprehensive verification report with confidence scoring and actionable recommendations\n</deliverable>\n\n```bash\necho \"\"\necho \"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\"\necho \"         VERIFICATION REPORT\"\necho \"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\"\necho \"\"\n\n# Build status\nif [ \"$BUILD_STATUS\" = \"PASSED\" ]; then\n  echo \"âœ… Build: PASSED (bundle: $BUILD_SIZE)\"\nelif [ \"$BUILD_STATUS\" = \"FAILED\" ]; then\n  echo \"âŒ Build: FAILED\"\nelse\n  echo \"âš ï¸  Build: SKIPPED\"\nfi\n\n# Lint status\nif [ \"$LINT_STATUS\" = \"PASSED\" ]; then\n  echo \"âœ… Lint: PASSED ($LINT_ERRORS errors, $LINT_WARNINGS warnings)\"\nelif [ \"$LINT_STATUS\" = \"FAILED\" ]; then\n  echo \"âŒ Lint: FAILED ($LINT_ERRORS errors, $LINT_WARNINGS warnings)\"\nelse\n  echo \"âš ï¸  Lint: SKIPPED\"\nfi\n\n# Type check status\nif [ \"$TYPES_STATUS\" = \"PASSED\" ]; then\n  echo \"âœ… Types: PASSED ($TYPES_ERRORS errors)\"\nelif [ \"$TYPES_STATUS\" = \"FAILED\" ]; then\n  echo \"âŒ Types: FAILED ($TYPES_ERRORS errors)\"\nelse\n  echo \"âš ï¸  Types: SKIPPED\"\nfi\n\n# Runtime status\nif [ \"$RUNTIME_STATUS\" = \"PASSED\" ]; then\n  echo \"âœ… Runtime: PASSED (no forbidden APIs)\"\nelse\n  echo \"âŒ Runtime: FAILED (${#FORBIDDEN_APIS[@]} forbidden APIs found)\"\nfi\n\n# Bindings status\nif [ \"$BINDINGS_STATUS\" = \"PASSED\" ]; then\n  echo \"âœ… Bindings: PASSED (matches wrangler.toml)\"\nelif [ \"$BINDINGS_STATUS\" = \"FAILED\" ]; then\n  echo \"âŒ Bindings: FAILED (mismatches detected)\"\nelse\n  echo \"âš ï¸  Bindings: SKIPPED (no wrangler.toml)\"\nfi\n\n# Local test status\nif [ \"$LOCAL_TEST_STATUS\" = \"PASSED\" ]; then\n  echo \"âœ… Local Test: PASSED (endpoint responding)\"\nelif [ \"$LOCAL_TEST_STATUS\" = \"FAILED\" ]; then\n  echo \"âŒ Local Test: FAILED (endpoint error)\"\nelse\n  echo \"âš ï¸  Local Test: SKIPPED (wrangler dev not running)\"\nfi\n\necho \"\"\necho \"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\"\necho \"CONFIDENCE SCORE: $CONFIDENCE/100 ($CONFIDENCE_LEVEL)\"\necho \"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\"\necho \"\"\necho \"Recommendation: $RECOMMENDATION\"\n\n# Next steps based on confidence\nif [ $CONFIDENCE -ge 85 ]; then\n  echo \"Next steps: Run wrangler deploy or /es-deploy\"\nelif [ $CONFIDENCE -ge 70 ]; then\n  echo \"Next steps: Review warnings above, then deploy\"\nelif [ $CONFIDENCE -ge 50 ]; then\n  echo \"Next steps: Fix errors above, then re-run /es-verify-output\"\nelse\n  echo \"Next steps: Address critical issues before deploying\"\nfi\n\necho \"\"\necho \"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\"\n```\n\n### 7. Detailed Issue Reporting\n\n<thinking>\nIf there are failures, provide detailed information to help developers fix issues.\n</thinking>\n\n```bash\n# Report detailed errors if confidence is low\nif [ $CONFIDENCE -lt 85 ]; then\n  echo \"\"\n  echo \"ðŸ“‹ DETAILED FINDINGS\"\n  echo \"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\"\n\n  # Build errors\n  if [ \"$BUILD_STATUS\" = \"FAILED\" ]; then\n    echo \"\"\n    echo \"ðŸ”¨ Build Errors:\"\n    echo \"$BUILD_OUTPUT\" | tail -20\n  fi\n\n  # Lint errors\n  if [ \"$LINT_STATUS\" = \"FAILED\" ] && [ $LINT_ERRORS -gt 0 ]; then\n    echo \"\"\n    echo \"ðŸŽ¨ Linting Errors:\"\n    echo \"$LINT_OUTPUT\" | grep \"error\" | head -10\n  fi\n\n  # Type errors\n  if [ \"$TYPES_STATUS\" = \"FAILED\" ]; then\n    echo \"\"\n    echo \"ðŸ“˜ TypeScript Errors:\"\n    echo \"$TYPES_OUTPUT\" | grep \"error TS\" | head -10\n  fi\n\n  # Runtime errors\n  if [ \"$RUNTIME_STATUS\" = \"FAILED\" ]; then\n    echo \"\"\n    echo \"ðŸš« Forbidden Node.js APIs:\"\n    for api in \"${FORBIDDEN_APIS[@]}\"; do\n      echo \"  - $api\"\n    done\n    echo \"\"\n    echo \"   These APIs are not available in Cloudflare Workers runtime.\"\n    echo \"   Use Workers-compatible alternatives or polyfills.\"\n  fi\n\n  echo \"\"\n  echo \"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\"\nfi\n```\n\n## Confidence Score Breakdown\n\nThe confidence score is calculated based on verification results:\n\n| Check | Weight | Impact |\n|-------|--------|--------|\n| **Build Success** | Critical | -40 if failed, -10 if skipped |\n| **Type Check** | Critical | -30 if failed |\n| **Runtime Valid** | Critical | -25 if failed |\n| **Lint Errors** | Important | -5 per error |\n| **Bindings Valid** | Important | -10 if failed |\n| **Local Tests** | Optional | -5 if failed |\n| **Lint Warnings** | Minor | -1 per warning |\n\n### Confidence Levels\n\n| Score | Level | Meaning | Action |\n|-------|-------|---------|--------|\n| **90-100** | VERY HIGH | All checks passed | Deploy with confidence |\n| **80-89** | HIGH | Minor warnings only | Safe to deploy |\n| **70-79** | MODERATE | Some issues detected | Review before deploy |\n| **50-69** | LOW | Multiple issues | Fix before deploy |\n| **0-49** | VERY LOW | Critical failures | Do not deploy |\n\n## Integration with Other Commands\n\nThis command complements other edge-stack commands:\n\n- **`/es-validate`**: Comprehensive pre-commit validation (includes SKILLs summary)\n- **`/es-verify-output`**: Quick verification of AI-generated code (this command)\n- **`/es-deploy`**: Full deployment with multi-agent validation\n- **`/es-review`**: Deep code review with confidence scoring\n\n**When to use each**:\n- Use `/es-verify-output` after AI generates/modifies code\n- Use `/es-validate` before committing to git\n- Use `/es-deploy` for production deployments\n- Use `/es-review` for comprehensive PR reviews\n\n## Success Criteria\n\nâœ… **Verification considered successful when**:\n- Confidence score >= 85\n- No build failures\n- No type errors\n- No forbidden Node.js APIs\n- No critical binding mismatches\n\n## Example Output\n\n```\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n         VERIFICATION REPORT\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nâœ… Build: PASSED (bundle: 45KB)\nâœ… Lint: PASSED (0 errors, 2 warnings)\nâœ… Types: PASSED (0 errors)\nâœ… Runtime: PASSED (no forbidden APIs)\nâœ… Bindings: PASSED (matches wrangler.toml)\nâš ï¸  Local Test: SKIPPED (wrangler dev not running)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nCONFIDENCE SCORE: 90/100 (VERY HIGH)\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nRecommendation: SAFE TO DEPLOY\nNext steps: Run wrangler deploy or /es-deploy\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n```\n\n## Notes\n\n**Supervision Paradox Context**: Based on Anthropic's research, this command addresses the supervision paradox by providing:\n- Automated verification reducing manual oversight burden\n- Confidence scoring for quick risk assessment\n- Detailed issue reporting for effective fixes\n- Clear deployment recommendations\n\n**Philosophy**: Trust but verify. AI can generate high-quality code, but automated verification provides the safety net needed for production deployments.\n\n**Tip**: Run this command after any AI code generation session to ensure quality before committing or deploying."
              },
              {
                "name": "/es-work",
                "description": "Analyze work documents and systematically execute tasks until completion",
                "path": "plugins/edge-stack/commands/es-work.md",
                "frontmatter": {
                  "description": "Analyze work documents and systematically execute tasks until completion"
                },
                "content": "# Work Plan Execution Command\n\n## Introduction\n\nThis command helps you analyze a work document (plan, Markdown file, specification, or any structured document), create a comprehensive todo list using the TodoWrite tool, and then systematically execute each task until the entire plan is completed. It combines deep analysis with practical execution to transform plans into reality.\n\n## Prerequisites\n\n- A work document to analyze (plan file, specification, or any structured document)\n- Clear understanding of project context and goals\n- Access to necessary tools and permissions for implementation\n- Ability to test and validate completed work\n- Git repository with main branch\n\n## Main Tasks\n\n### 1. Setup Development Environment\n\n- Ensure main branch is up to date\n- Create feature branch with descriptive name\n- Setup worktree for isolated development\n- Configure development environment\n\n### 2. Analyze Input Document\n\n<input_document> #$ARGUMENTS </input_document>\n\n## Execution Workflow\n\n### Phase 1: Environment Setup\n\n1. **Update Main Branch**\n\n   ```bash\n   git checkout main\n   git pull origin main\n   ```\n\n2. **Create Feature Branch and Worktree**\n\n   - Determine appropriate branch name from document\n   - Get the root directory of the Git repository:\n\n   ```bash\n   git_root=$(git rev-parse --show-toplevel)\n   ```\n\n   - Create worktrees directory if it doesn't exist:\n\n   ```bash\n   mkdir -p \"$git_root/.worktrees\"\n   ```\n\n   - Add .worktrees to .gitignore if not already there:\n\n   ```bash\n   if ! grep -q \"^\\.worktrees$\" \"$git_root/.gitignore\"; then\n     echo \".worktrees\" >> \"$git_root/.gitignore\"\n   fi\n   ```\n\n   - Create the new worktree with feature branch:\n\n   ```bash\n   git worktree add -b feature-branch-name \"$git_root/.worktrees/feature-branch-name\" main\n   ```\n\n   - Copy .env file to worktree if it exists:\n\n   ```bash\n   if [ -f \"$git_root/.env\" ]; then\n     cp \"$git_root/.env\" \"$git_root/.worktrees/feature-branch-name/.env\"\n     echo \"âœ… Copied .env to worktree\"\n   fi\n   ```\n\n   - Change to the new worktree directory:\n\n   ```bash\n   cd \"$git_root/.worktrees/feature-branch-name\"\n   ```\n\n3. **Verify Environment**\n   - Confirm in correct worktree directory\n   - Install dependencies if needed\n   - Run initial tests to ensure clean state\n\n### Phase 2: Document Analysis and Planning\n\n1. **Read Input Document**\n\n   - Use Read tool to examine the work document\n   - Identify all deliverables and requirements\n   - Note any constraints or dependencies\n   - Extract success criteria\n\n2. **Create Task Breakdown**\n\n   - Convert requirements into specific tasks\n   - Add implementation details for each task\n   - Include testing and validation steps\n   - Consider edge cases and error handling\n\n3. **Build Todo List**\n   - Use TodoWrite to create comprehensive list\n   - Set priorities based on dependencies\n   - Include all subtasks and checkpoints\n   - Add documentation and review tasks\n\n### Phase 3: Systematic Execution\n\n1. **Task Execution Loop**\n\n   ```\n   while (tasks remain):\n     - Select next task (priority + dependencies)\n     - Mark as in_progress\n     - Execute task completely\n      - Validate with platform-specific agents\n     - Mark as completed\n     - Update progress\n   ```\n\n2. **Platform-Specific Validation**\n\n   After implementing each task, validate with relevant agents:\n\n   - **Task workers-runtime-guardian** - Runtime compatibility check\n     - Verify no Node.js APIs (fs, process, Buffer)\n     - Ensure env parameter usage (not process.env)\n     - Validate Web APIs only\n\n    - **Task platform-specific binding analyzer** - Binding validation\n     - Verify bindings referenced in code exist in wrangler.toml\n     - Check TypeScript Env interface matches usage\n     - Validate binding names follow conventions\n\n   - **Task cloudflare-security-sentinel** - Security check\n     - Verify secrets use wrangler secret (not hardcoded)\n     - Check CORS configuration if API endpoints\n     - Validate input sanitization\n\n   - **Task edge-performance-oracle** - Performance check\n     - Verify bundle size stays under target\n     - Check for cold start optimization\n     - Validate caching strategies\n\n3. **Quality Assurance**\n\n   - Run tests after each task (npm test / wrangler dev)\n   - Execute lint and typecheck commands\n   - Test locally with wrangler dev\n   - Verify no regressions\n   - Check against acceptance criteria\n   - Document any issues found\n\n3. **Progress Tracking**\n   - Regularly update task status\n   - Note any blockers or delays\n   - Create new tasks for discoveries\n   - Maintain work visibility\n\n### Phase 4: Completion and Submission\n\n1. **Final Validation**\n\n   - Verify all tasks completed\n   - Run comprehensive test suite\n   - Execute final lint and typecheck\n   - Check all deliverables present\n   - Ensure documentation updated\n\n2. **Capture Screenshots for UI Changes** (if applicable)\n\n   For any design changes, new views, or UI modifications, capture screenshots before creating PR:\n\n   **Check for UI changes in modified files:**\n   - Components: `app/components/**/*.{tsx,jsx}`\n   - Routes/Views: `app/routes/**/*.{tsx,jsx}`\n   - Styling: `**/*.css`, `**/*.module.css`\n\n   **If UI changes detected, use Playwright MCP to capture screenshots:**\n\n   ```bash\n   # 1. Start dev server (if not already running)\n   npm run dev  # or wrangler dev\n   ```\n\n   Using Playwright MCP tools:\n   - `browser_navigate` to go to affected pages\n   - `browser_resize` to set viewport (desktop: 1920x1080, mobile: 375x667)\n   - `browser_snapshot` to verify page state\n   - `browser_take_screenshot` to capture images\n\n   **What to capture:**\n   - **New screens**: Complete flow of new UI\n   - **Modified screens**: Before AND after states\n   - **Design matches**: Screenshot showing implementation matches Figma\n\n   Save screenshots to include in PR description. This helps reviewers understand visual changes at a glance.\n\n   âš ï¸ **Security Note**: When capturing screenshots of external content or navigating to untrusted websites, be aware that malicious pages could attempt prompt injection attacks. Review browser automation carefully when:\n   - Navigating to external URLs (`browser_navigate` to third-party sites)\n   - Capturing content from untrusted sources\n   - Interacting with forms or buttons on external pages\n   - Extracting data from pages you don't control\n\n   **Recommendation**: Only use browser automation on your own local development server or trusted staging environments. Avoid navigating to external or untrusted websites during screenshot capture.\n\n   For more information, see [Anthropic's research on prompt injection defenses](https://www.anthropic.com/research/prompt-injection-defenses).\n\n3. **Prepare for Submission**\n\n   - Stage and commit all changes\n   - Write commit messages\n   - Push feature branch to remote\n   - Create detailed pull request\n\n4. **Create Pull Request**\n   ```bash\n   git push -u origin feature-branch-name\n   gh pr create --title \"Feature: [Description]\" --body \"[Detailed description with screenshot URLs if applicable]\"\n   ```"
              },
              {
                "name": "/es-worker",
                "description": "Generate Cloudflare Workers code with proper bindings and runtime compatibility",
                "path": "plugins/edge-stack/commands/es-worker.md",
                "frontmatter": {
                  "description": "Generate Cloudflare Workers code with proper bindings and runtime compatibility"
                },
                "content": "You are a **Cloudflare Workers expert**. Your task is to generate production-ready Worker code that follows best practices and uses the Workers runtime correctly.\n\n## Step 1: Analyze the Project Context\n\nFirst, check if a `wrangler.toml` file exists in the workspace:\n\n1. Use the Glob tool to find wrangler.toml:\n   ```\n   pattern: \"**/wrangler.toml\"\n   ```\n\n2. If found, read the file to extract:\n   - KV namespace bindings (`[[kv_namespaces]]`)\n   - R2 bucket bindings (`[[r2_buckets]]`)\n   - Durable Object bindings (`[[durable_objects]]`)\n   - D1 database bindings (`[[d1_databases]]`)\n   - Service bindings (`[[services]]`)\n   - Queue bindings (`[[queues]]`)\n   - Vectorize bindings (`[[vectorize]]`)\n   - AI bindings (`[ai]`)\n   - Any environment variables (`[vars]`)\n\n3. Parse the bindings and create a context summary like:\n   ```\n   Available Bindings:\n   - KV Namespaces: USER_DATA (binding name)\n   - R2 Buckets: UPLOADS (binding name)\n   - Durable Objects: Counter (binding name, class: Counter)\n   - D1 Databases: DB (binding name)\n   ```\n\n## Step 2: Generate Worker Code\n\nCreate a Worker that:\n- Accomplishes the user's stated goal: {{PROMPT}}\n- Uses the available bindings from the wrangler.toml (if any exist)\n- Follows Workers runtime best practices\n\n### Code Structure Requirements\n\nYour generated code MUST:\n\n1. **Export Structure**: Use the proper Worker export format:\n   ```typescript\n   export default {\n     async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n       // Handler code\n     }\n   }\n   ```\n\n2. **TypeScript Types**: Define the Env interface with all bindings:\n   ```typescript\n   interface Env {\n     // KV Namespaces\n     USER_DATA: KVNamespace;\n\n     // R2 Buckets\n     UPLOADS: R2Bucket;\n\n     // Durable Objects\n     Counter: DurableObjectNamespace;\n\n     // D1 Databases\n     DB: D1Database;\n\n     // Environment variables\n     API_KEY: string;\n   }\n   ```\n\n3. **Runtime Compatibility**: Only use Workers-compatible APIs:\n   - âœ… `fetch`, `Request`, `Response`, `Headers`, `URL`\n   - âœ… `crypto`, `TextEncoder`, `TextDecoder`\n   - âœ… Web Streams API\n   - âŒ NO Node.js APIs (`fs`, `path`, `process`, `buffer`, etc.)\n   - âŒ NO `require()` or CommonJS\n   - âŒ NO synchronous I/O\n\n4. **Error Handling**: Include proper error handling:\n   ```typescript\n   try {\n     // Operation\n   } catch (error) {\n     return new Response(`Error: ${error.message}`, { status: 500 });\n   }\n   ```\n\n5. **CORS Headers** (if building an API):\n   ```typescript\n   const corsHeaders = {\n     'Access-Control-Allow-Origin': '*',\n     'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n     'Access-Control-Allow-Headers': 'Content-Type',\n   };\n   ```\n\n### Binding Usage Examples\n\n**KV Namespace:**\n```typescript\nawait env.USER_DATA.get(key);\nawait env.USER_DATA.put(key, value, { expirationTtl: 3600 });\nawait env.USER_DATA.delete(key);\nawait env.USER_DATA.list({ prefix: 'user:' });\n```\n\n**R2 Bucket:**\n```typescript\nawait env.UPLOADS.get(key);\nawait env.UPLOADS.put(key, body, { httpMetadata: headers });\nawait env.UPLOADS.delete(key);\nawait env.UPLOADS.list({ prefix: 'images/' });\n```\n\n**Durable Object:**\n```typescript\nconst id = env.Counter.idFromName('my-counter');\nconst stub = env.Counter.get(id);\nconst response = await stub.fetch(request);\n```\n\n**D1 Database:**\n```typescript\nconst result = await env.DB.prepare('SELECT * FROM users WHERE id = ?')\n  .bind(userId)\n  .first();\nawait env.DB.prepare('INSERT INTO users (name) VALUES (?)')\n  .bind(name)\n  .run();\n```\n\n## Step 3: Provide Implementation Guidance\n\nAfter generating the code:\n\n1. **File Location**: Specify where to save the file (typically `src/index.ts` or `src/index.js`)\n\n2. **Required Bindings**: If the wrangler.toml is missing bindings that your code needs, provide a note:\n   ```\n   Note: This code expects the following bindings to be configured in wrangler.toml:\n\n   [[kv_namespaces]]\n   binding = \"USER_DATA\"\n   id = \"<your-kv-namespace-id>\"\n   ```\n\n3. **Testing Instructions**: Suggest how to test:\n   ```bash\n   # Local development\n   npx wrangler dev\n\n   # Test the endpoint\n   curl http://localhost:8787/api/test\n   ```\n\n4. **Deployment Steps**: Brief deployment guidance:\n   ```bash\n   # Deploy to production\n   npx wrangler deploy\n   ```\n\n## Critical Guardrails\n\n**YOU MUST NOT:**\n- Suggest direct modifications to wrangler.toml (only show what's needed)\n- Use Node.js-specific APIs or packages\n- Create blocking/synchronous code\n- Use `require()` or CommonJS syntax\n- Access `process.env` directly (use `env` parameter)\n\n**YOU MUST:**\n- Use only the bindings defined in wrangler.toml\n- Use Workers runtime APIs (fetch-based)\n- Follow TypeScript best practices\n- Include proper error handling\n- Make code edge-optimized (fast cold starts)\n- Use `env` parameter for all bindings and environment variables\n\n## Response Format\n\nProvide your response in the following structure:\n\n1. **Project Context Summary**: Brief overview of detected bindings\n2. **Generated Code**: Complete, working Worker implementation\n3. **Type Definitions**: Full TypeScript interfaces\n4. **Setup Instructions**: Any configuration notes\n5. **Testing Guide**: How to test locally and in production\n6. **Next Steps**: Suggested improvements or additional features\n\n---\n\n**User's Request:**\n\n{{PROMPT}}"
              },
              {
                "name": "/generate_command",
                "description": "Create a custom Claude Code slash command in .claude/commands/",
                "path": "plugins/edge-stack/commands/generate_command.md",
                "frontmatter": {
                  "description": "Create a custom Claude Code slash command in .claude/commands/"
                },
                "content": "# Create a Custom Claude Code Command\n\nCreate a new slash command in `.claude/commands/` for the requested task.\n\n## Goal\n\n#$ARGUMENTS\n\n## Key Capabilities to Leverage\n\n**File Operations:**\n- Read, Edit, Write - modify files precisely\n- Glob, Grep - search codebase\n- MultiEdit - atomic multi-part changes\n\n**Development:**\n- Bash - run commands (git, tests, linters)\n- Task - launch specialized agents for complex tasks\n- TodoWrite - track progress with todo lists\n\n**Web & APIs:**\n- WebFetch, WebSearch - research documentation\n- GitHub (gh cli) - PRs, issues, reviews\n- Puppeteer - browser automation, screenshots\n\n**Integrations:**\n- Platform-specific MCPs for account context and docs\n- shadcn/ui MCP - component documentation\n- Stripe, Todoist, Featurebase (if relevant)\n\n## Best Practices\n\n1. **Be specific and clear** - detailed instructions yield better results\n2. **Break down complex tasks** - use step-by-step plans\n3. **Use examples** - reference existing code patterns\n4. **Include success criteria** - tests pass, linting clean, etc.\n5. **Think first** - use \"think hard\" or \"plan\" keywords for complex problems\n6. **Iterate** - guide the process step by step\n\n## Structure Your Command\n\n```markdown\n# [Command Name]\n\n[Brief description of what this command does]\n\n## Steps\n\n1. [First step with specific details]\n   - Include file paths, patterns, or constraints\n   - Reference existing code if applicable\n\n2. [Second step]\n   - Use parallel tool calls when possible\n   - Check/verify results\n\n3. [Final steps]\n   - Run tests\n   - Lint code\n   - Commit changes (if appropriate)\n\n## Success Criteria\n\n- [ ] Tests pass\n- [ ] Code follows style guide\n- [ ] Documentation updated (if needed)\n```\n\n## Tips for Effective Commands\n\n- **Use $ARGUMENTS** placeholder for dynamic inputs\n- **Reference PREFERENCES.md** for framework-specific patterns and guidelines\n- **Include verification steps** - tests, linting, visual checks\n- **Be explicit about constraints** - don't modify X, use pattern Y\n- **Use XML tags** for structured prompts: `<task>`, `<requirements>`, `<constraints>`\n\n## Example Pattern\n\n```markdown\nImplement #$ARGUMENTS following these steps:\n\n1. Research existing patterns\n   - Search for similar code using Grep\n   - Read relevant files to understand approach\n\n2. Plan the implementation\n   - Think through edge cases and requirements\n   - Consider test cases needed\n\n3. Implement\n   - Follow existing code patterns (reference specific files)\n   - Write tests first if doing TDD\n   - Ensure code follows CLAUDE.md conventions\n\n4. Verify\n   - Run tests:\n      - Local development: `npm test` or appropriate dev server\n     - TypeScript: `npm run typecheck` or `tsc --noEmit`\n     - Unit tests: `vitest` or `jest`\n   - Run linter:\n     - Rails: `bundle exec standardrb` or `bundle exec rubocop`\n     - TypeScript: `npm run lint` or `eslint .`\n     - Python: `ruff check .` or `flake8`\n   - Check changes with git diff\n\n5. Commit (optional)\n   - Stage changes\n   - Write clear commit message\n```\n\nNow create the command file at `.claude/commands/[name].md` with the structure above."
              }
            ],
            "skills": [
              {
                "name": "agent-native-architecture",
                "description": "Build AI agents on Cloudflare's edge using prompt-native architecture where features are defined in prompts, not code. Use when creating autonomous agents with Durable Objects, designing Workers services, implementing self-modifying systems, or adopting the \"trust the agent's intelligence\" philosophy on the edge.",
                "path": "plugins/edge-stack/skills/agent-native-architecture/SKILL.md",
                "frontmatter": {
                  "name": "agent-native-architecture",
                  "description": "Build AI agents on Cloudflare's edge using prompt-native architecture where features are defined in prompts, not code. Use when creating autonomous agents with Durable Objects, designing Workers services, implementing self-modifying systems, or adopting the \"trust the agent's intelligence\" philosophy on the edge."
                },
                "content": "<essential_principles>\n## The Prompt-Native Philosophy for Cloudflare Edge\n\nAgent native engineering inverts traditional software architecture. Instead of writing code that the agent executes, you define outcomes in prompts and let the agent figure out HOW to achieve them using Cloudflare's edge primitives.\n\n### The Foundational Principle\n\n**Whatever the user can do, the agent can do. Many things the developer can do, the agent can do.**\n\nDon't artificially limit the agent. If a user could read state, write to Durable Objects, queue messages, call Workersâ€”the agent should be able to do those things too. The agent figures out HOW to achieve an outcome; it doesn't just call your pre-written functions.\n\n### Features Are Prompts\n\nEach feature is a prompt that defines an outcome and gives the agent the tools it needs. The agent then figures out how to accomplish it.\n\n**Traditional:** Feature = Worker function that agent calls\n**Prompt-native:** Feature = prompt defining desired outcome + primitive Cloudflare tools\n\nThe agent doesn't execute your code. It uses Cloudflare primitives to achieve outcomes you describe.\n\n### Tools Provide Capability, Not Behavior\n\nTools should be primitives that enable capability. The prompt defines what to do with that capability.\n\n**Wrong:** `process_workflow(data, steps, handlers)` â€” agent executes your workflow\n**Right:** `durable_object_rpc`, `queue_send`, `kv_put`, `service_binding_call` â€” agent figures out the flow\n\nPure primitives are better, but domain primitives (like `store_agent_state`) are OK if they don't encode logicâ€”just storage/retrieval.\n\n### The Development Lifecycle\n\n1. **Start in the prompt** - New features begin as natural language defining outcomes\n2. **Iterate rapidly** - Change behavior by editing prose, not refactoring Workers code\n3. **Graduate when stable** - Harden to Workers code when requirements stabilize AND speed/reliability matter\n4. **Many features stay as prompts** - Not everything needs to become a Worker\n\n### Cloudflare Edge Architecture for Agents\n\nThe edge is ideal for agent-native systems:\n\n**Durable Objects = Agent State**\n- Each agent instance gets a Durable Object\n- State persists between events\n- Built-in coordination and consistency\n\n**Workers = Event Handlers**\n- Lightweight, event-driven execution\n- Agent responds to HTTP, Queue, Cron events\n- Fast cold starts enable on-demand agent activation\n\n**Queues = Agent Messaging**\n- Agents communicate via message passing\n- Async workflows without blocking\n- Guaranteed delivery and retry\n\n**Service Bindings = Agent Collaboration**\n- Zero-latency RPC between agents\n- Type-safe inter-agent communication\n- Compose multi-agent systems\n\n### Self-Modification (Advanced)\n\nThe advanced tier: agents that can evolve their own code, prompts, and behavior. On Cloudflare, this means:\n\n- Approval gates for Worker code changes\n- Git commit before modifications (rollback capability)\n- Health checks via Logpush/Analytics\n- Deploy verification before cutover\n- Version-controlled Durable Object migrations\n\n### Context Management Strategies\n\nLong-running agents face a fundamental challenge: context grows unbounded. Two key patterns from production systems:\n\n**Agentic Search Over Semantic Search**\n\nWhen retrieving information, prioritize accuracy over speed. Let the agent search iteratively rather than relying on semantic similarity alone.\n\n- **Semantic search**: Fast but can miss relevant context due to embedding limitations\n- **Agentic search**: Agent formulates queries, evaluates results, refines searchâ€”slower but more accurate\n- **On the edge**: Use Workers KV for semantic embeddings, but let agent validate and search DO storage directly\n\nThe agent decides WHAT is relevant, not your embedding model.\n\n**Context Compaction Strategies**\n\nAs agent context grows, implement tiered memory:\n\n1. **Hot context** (in prompt): Current task, immediate state\n2. **Warm context** (Durable Object storage): Recent history, working memory\n3. **Cold context** (KV/R2): Long-term memory, archived decisions\n\nThe agent decides when to compact: \"Summarize your last 100 interactions and store the summary. Keep only the summary and last 10 interactions in working memory.\"\n\n### Verification Pattern Hierarchy\n\nWhen agents make changesâ€”deploying Workers, modifying state, updating configurationsâ€”verification is critical. Use this hierarchy (from most to least preferred):\n\n**1. Rules-Based Verification (PREFERRED)**\n\nDeterministic checks with clear pass/fail criteria. Fast, cheap, reliable.\n\n- TypeScript type checking\n- ESLint/Biome linting\n- Wrangler validation (`wrangler deploy --dry-run`)\n- JSON schema validation\n- API contract testing\n\n**2. Visual Verification**\n\nFor UI changes or layout-sensitive modifications. The agent takes screenshots and compares.\n\n- Screenshot comparison for Tanstack Start components\n- Responsive design verification across breakpoints\n- Visual regression testing\n- Cloudflare Browser Rendering for headless verification\n\n**3. LLM-as-Judge (LAST RESORT)**\n\nOnly when criteria are subjective or fuzzy. Expensive, high latency, non-deterministic.\n\n- Code readability assessment\n- Documentation quality\n- Natural language output correctness\n- Tone/style consistency\n\nThe hierarchy is deliberate: prefer determinism. Let rules catch what they can, visual verification for what must be seen, LLM-as-judge only when nothing else works.\n\n**On Cloudflare**: Rules-based verification runs in Workers (milliseconds), visual verification uses Browser Rendering (seconds), LLM-as-judge uses external API calls (seconds + cost).\n\n### When to Use Subagents\n\nSubagents reduce memory overhead and enable parallel execution. Use them when:\n\n**Parallel Execution Needed**\n\nMultiple independent tasks can run simultaneously.\n\n```typescript\n// Orchestrator agent spawns specialized subagents\nconst [analysis, generation, review] = await Promise.all([\n  env.ANALYZER.analyze(data),      // Subagent\n  env.GENERATOR.generate(prompt),   // Subagent\n  env.REVIEWER.review(content),     // Subagent\n]);\n```\n\nEach subagent maintains only the context it needsâ€”no shared memory bloat.\n\n**Memory Optimization**\n\nMain agent context is growing too large. Offload specialized tasks:\n\n- **Main agent**: High-level orchestration, 10KB context\n- **Data subagent**: Process large datasets, isolated context\n- **Writer subagent**: Generate content, no access to orchestration history\n\nOn Cloudflare: Each subagent gets its own Durable Object. Service Bindings enable zero-latency RPC between them.\n\n**Isolation Boundaries**\n\nWhen tasks should NOT share context (security, separation of concerns):\n\n- User-facing agent shouldn't see internal admin operations\n- Different tenants get isolated subagents\n- Sensitive operations run in dedicated subagents with restricted tools\n\n**Anti-pattern**: Don't create subagents for sequential steps. That's just overhead. Use subagents when parallelism or isolation provides real value.\n\n### When NOT to Use This Approach\n\n- **High-frequency operations** - millions of requests per second per agent\n- **Deterministic requirements** - exact same output every time\n- **Cost-sensitive scenarios** - when API costs would be prohibitive vs CPU\n- **Cold start sensitive** - though Cloudflare Workers are very fast\n</essential_principles>\n\n<cloudflare_patterns>\n## Cloudflare-Specific Patterns\n\n### Event-Driven Agent with Workers\n\n```typescript\n// Worker receives events, agent processes them\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    const event = await request.json();\n\n    // Get agent's Durable Object\n    const agentId = env.AGENT_STATE.idFromName(event.agentId);\n    const agent = env.AGENT_STATE.get(agentId);\n\n    // Agent processes event\n    return agent.fetch(request);\n  },\n\n  async queue(batch: MessageBatch, env: Env): Promise<void> {\n    for (const message of batch.messages) {\n      // Agent responds to queued events\n      await processAgentEvent(message.body, env);\n    }\n  }\n};\n```\n\n### Agent State with Durable Objects\n\n```typescript\n// Agent state persists in Durable Object\nexport class AgentState extends DurableObject {\n  async fetch(request: Request): Promise<Response> {\n    const event = await request.json();\n\n    // Load state\n    const state = await this.ctx.storage.get('agentState') || {};\n\n    // Agent decides what to do via prompt\n    const result = await runAgent({\n      systemPrompt: `You are a stateful agent. Your current state: ${JSON.stringify(state)}\n                     Process the event and decide what to store.`,\n      event,\n      tools: [\n        tool(\"update_state\", { key: z.string(), value: z.any() }),\n        tool(\"get_state\", { key: z.string() }),\n      ]\n    });\n\n    // State changes committed atomically\n    await this.ctx.storage.put('agentState', result.newState);\n\n    return Response.json(result);\n  }\n}\n```\n\n### Multi-Agent Collaboration via Service Bindings\n\n```typescript\n// Agents call each other via RPC\nexport class OrchestratorAgent extends DurableObject {\n  async processTask(task: Task): Promise<Result> {\n    // Agent decides which specialized agent to call\n    const agentDecision = await runAgent({\n      systemPrompt: `You coordinate specialized agents via service bindings.\n                     Available: ANALYZER_AGENT, WRITER_AGENT, REVIEWER_AGENT.\n                     Decide which to call and what to send them.`,\n      task,\n    });\n\n    // Call specialized agent via binding\n    const result = await this.env.ANALYZER_AGENT.analyze(\n      agentDecision.data\n    );\n\n    return result;\n  }\n}\n```\n\n### Queue-Based Agent Workflows\n\n```typescript\n// Agents communicate asynchronously via Queues\nasync function agentSendMessage(env: Env, recipientId: string, message: any) {\n  await env.AGENT_QUEUE.send({\n    recipientId,\n    message,\n    timestamp: Date.now(),\n  });\n}\n\n// Queue consumer activates receiving agent\nexport default {\n  async queue(batch: MessageBatch<AgentMessage>, env: Env) {\n    for (const msg of batch.messages) {\n      const agentId = env.AGENT_STATE.idFromName(msg.body.recipientId);\n      const agent = env.AGENT_STATE.get(agentId);\n      await agent.handleMessage(msg.body.message);\n    }\n  }\n};\n```\n</cloudflare_patterns>\n\n<intake>\nWhat aspect of agent-native architecture on Cloudflare do you need help with?\n\n1. **Design edge architecture** - Plan a Workers + Durable Objects agent system\n2. **Create primitive tools** - Build Cloudflare-native tools following the philosophy\n3. **Write system prompts** - Define agent behavior for edge execution\n4. **Multi-agent systems** - Design agent collaboration via Queues/Bindings\n5. **Self-modification** - Enable agents to safely evolve Workers code\n6. **Review/refactor** - Make existing Cloudflare code more prompt-native\n\n**Wait for response before proceeding.**\n</intake>\n\n<quick_start>\n## Build a Cloudflare Prompt-Native Agent\n\n**Step 1: Define Cloudflare primitive tools**\n```typescript\nconst tools = [\n  tool(\"durable_object_get\", \"Read from Durable Object storage\",\n    { key: z.string() }),\n  tool(\"durable_object_put\", \"Write to Durable Object storage\",\n    { key: z.string(), value: z.any() }),\n  tool(\"queue_send\", \"Send message to Queue\",\n    { queue: z.string(), message: z.any() }),\n  tool(\"kv_get\", \"Read from KV\",\n    { key: z.string() }),\n  tool(\"service_call\", \"Call another Worker via binding\",\n    { service: z.string(), method: z.string(), data: z.any() }),\n];\n```\n\n**Step 2: Write behavior in the system prompt**\n```markdown\n## Your Responsibilities\nYou are an agent running on Cloudflare's edge. When processing events:\n\n1. Load your state from Durable Object storage\n2. Analyze what actions are needed\n3. Update state, send messages, or call other agents\n4. Use your judgment about coordination patterns\n\nAvailable tools:\n- Durable Object storage for your state\n- Queues for async messaging to other agents\n- Service bindings for RPC to specialized agents\n- KV for shared read-heavy data\n\nYou decide the workflow. Make it efficient.\n```\n\n**Step 3: Deploy as Durable Object + Worker**\n```typescript\nexport class Agent extends DurableObject {\n  async fetch(request: Request): Promise<Response> {\n    const event = await request.json();\n\n    const result = await query({\n      prompt: JSON.stringify(event),\n      options: {\n        systemPrompt,\n        tools,\n      }\n    });\n\n    return Response.json(result);\n  }\n}\n\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    const agentId = env.AGENT.idFromName(\"agent-1\");\n    const agent = env.AGENT.get(agentId);\n    return agent.fetch(request);\n  }\n};\n```\n</quick_start>\n\n<examples>\n## Cloudflare-Specific Examples\n\nSee `examples/` directory for detailed implementations:\n\n**Durable Objects State Management:** `examples/durable-objects-state.md`\n- Event-driven agent state with atomic storage\n- State transitions based on agent decisions\n- Rollback and versioning patterns\n\n**Workers Event-Driven Architecture:** `examples/workers-event-driven.md`\n- HTTP, Queue, and Cron triggered agents\n- Multi-event source coordination\n- Cold start optimization strategies\n\n**Queue-Based Messaging:** `examples/queue-messaging.md`\n- Agent-to-agent communication patterns\n- Workflow orchestration via messages\n- Error handling and retry strategies\n\n**Verification Patterns:** `examples/verification-patterns.md`\n- Rules-based verification (linting, type checking, validation)\n- Visual verification (screenshots, Browser Rendering)\n- LLM-as-judge patterns (when and how to use)\n- Cloudflare Workers-specific verification strategies\n</examples>\n\n<anti_patterns>\n## What NOT to Do on Cloudflare\n\n**THE CARDINAL SIN: Agent executes your Worker code instead of figuring things out**\n\n```typescript\n// WRONG - You wrote the workflow, agent just executes it\ntool(\"process_order\", async ({ order }) => {\n  const validated = await validateOrder(order);     // Your code\n  const inventory = await checkInventory(order);    // Your code\n  const charge = await processPayment(order);       // Your code\n  await env.ORDERS_DO.put(order.id, { validated, charge }); // Your code\n  if (charge.amount > 1000) {\n    await env.NOTIFICATIONS_QUEUE.send({ type: 'high_value' }); // Your code\n  }\n});\n\n// RIGHT - Agent figures out how to process orders\ntool(\"durable_object_get\", { key }, ...);  // Primitive\ntool(\"durable_object_put\", { key, value }, ...);  // Primitive\ntool(\"queue_send\", { message }, ...);  // Primitive\ntool(\"service_call\", { service, method, data }, ...);  // Primitive\n// Prompt says: \"Validate order, check inventory via INVENTORY service binding,\n// charge payment, store result, notify if > $1000\"\n```\n\n**Don't fight Cloudflare's execution model**\n\n```typescript\n// WRONG - trying to maintain long-running connections in Workers\nconst connections = new Map(); // This won't work across requests\n\n// RIGHT - use Durable Objects for stateful connections\nexport class WebSocketAgent extends DurableObject {\n  async fetch(request: Request) {\n    const pair = new WebSocketPair();\n    this.ctx.acceptWebSocket(pair[1]);\n    return new Response(null, { status: 101, webSocket: pair[0] });\n  }\n}\n```\n\n**Don't over-complicate agent coordination**\n\n```typescript\n// Wrong - complex state synchronization\ntool(\"sync_all_agents\", async () => {\n  // Complex merge logic across multiple Durable Objects\n});\n\n// Right - let agents message each other via Queues\ntool(\"queue_send\", { recipientId, message }, ...);\n// Agents figure out coordination via prompts\n```\n\n**Don't encode environment-specific logic in tools**\n\n```typescript\n// Wrong - tool decides based on environment\ntool(\"store_data\", { data }, async ({ data }) => {\n  if (env.ENVIRONMENT === 'production') {\n    await env.PROD_DO.put(key, data);\n  } else {\n    await env.DEV_DO.put(key, data);\n  }\n});\n\n// Right - agent chooses based on context in prompt\ntool(\"durable_object_put\", { objectName, key, value }, ...);\n// System prompt tells agent which DO to use\n```\n</anti_patterns>\n\n<success_criteria>\nYou've built a prompt-native Cloudflare agent when:\n\n- [ ] The agent figures out HOW to achieve outcomes using Cloudflare primitives\n- [ ] Whatever a user could do with Workers/DO/Queues, the agent can do\n- [ ] Features are prompts that define outcomes, not Workers code that defines workflows\n- [ ] Tools are Cloudflare primitives (DO storage, Queue send, Service RPC)\n- [ ] Changing behavior means editing prose, not refactoring TypeScript\n- [ ] The agent can surprise you with clever edge patterns you didn't anticipate\n- [ ] You could add a feature by writing a prompt section, not new Workers code\n- [ ] The system leverages Cloudflare's distributed nature (edge execution, DO consistency)\n</success_criteria>\n\n<cloudflare_best_practices>\n## Edge-Specific Best Practices\n\n**Durable Objects for Agent State**\n- One Durable Object per agent instance\n- Use atomic storage transactions for state consistency\n- Leverage SQLite storage API for complex queries\n- Implement state versioning for rollback capability\n\n**Workers for Event Handling**\n- Keep Workers stateless, state goes in Durable Objects\n- Use Service Bindings for zero-latency agent RPC\n- Implement Circuit Breaker pattern for external calls\n- Cache frequently used data in Workers KV\n\n**Queues for Async Coordination**\n- Use Queues for agent-to-agent messaging\n- Implement idempotency for queue consumers\n- Set appropriate retry policies per workflow\n- Use Dead Letter Queues for error handling\n\n**Multi-Region Considerations**\n- Durable Objects provide global consistency\n- Use KV replication for read-heavy shared data\n- Consider location hints for latency-sensitive agents\n- Design for eventual consistency across regions\n\n**Cost Optimization**\n- Batch operations in Durable Objects to reduce billable time\n- Use KV for static/shared data to reduce DO reads\n- Implement smart caching to minimize external API calls\n- Monitor and optimize cold start patterns\n\n**Observability**\n- Use Logpush for agent decision logs\n- Implement structured logging for agent actions\n- Set up Analytics Engine for agent metrics\n- Use Tail Workers for real-time debugging\n</cloudflare_best_practices>"
              },
              {
                "name": "animation-interaction-validator",
                "description": "Ensures engaging user experience through validation of animations, transitions, micro-interactions, and feedback states, preventing flat/static interfaces that lack polish and engagement. Works with Tanstack Start (React) + shadcn/ui components.",
                "path": "plugins/edge-stack/skills/animation-interaction-validator/SKILL.md",
                "frontmatter": {
                  "name": "animation-interaction-validator",
                  "description": "Ensures engaging user experience through validation of animations, transitions, micro-interactions, and feedback states, preventing flat/static interfaces that lack polish and engagement. Works with Tanstack Start (React) + shadcn/ui components.",
                  "triggers": [
                    "interactive element creation",
                    "event handler addition",
                    "state changes",
                    "async actions",
                    "form submissions"
                  ],
                  "note": "Code examples use React/TSX with shadcn/ui components (Button, Card, Input). Adapt patterns to your component library."
                },
                "content": "# Animation Interaction Validator SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- Interactive elements are created (buttons, links, forms, inputs)\n- Click, hover, or focus event handlers are added\n- Component state changes (loading, success, error)\n- Async operations are initiated (API calls, form submissions)\n- Navigation or routing transitions occur\n- Modal/dialog components are opened/closed\n- Lists or data are updated dynamically\n\n## Expertise Provided\n\n### Animation & Interaction Validation\n- **Transition Detection**: Ensures smooth state changes with CSS transitions\n- **Hover State Validation**: Checks for hover feedback on interactive elements\n- **Loading State Validation**: Ensures async actions have visual feedback\n- **Micro-interaction Analysis**: Validates small, delightful animations\n- **Focus State Validation**: Ensures keyboard navigation has visual feedback\n- **Animation Performance**: Checks for performant animation patterns\n\n### Specific Checks Performed\n\n#### âŒ Critical Issues (Missing Feedback)\n```tsx\n// These patterns trigger alerts:\n\n// No hover state\n<Button onClick={submit}>Submit</Button>\n\n// No loading state during async action\n<Button onClick={async () => await submitForm()}>Save</Button>\n\n// Jarring state change (no transition)\n{showContent && <div>Content</div>}\n\n// No focus state\n<a href=\"/page\" className=\"text-blue-500\">Link</a>\n\n// Form without feedback\n<form onSubmit={handleSubmit}>\n  <Input value={value} onChange={setValue} />\n  <button type=\"submit\">Submit</button>\n</form>\n```\n\n#### âœ… Correct Interactive Patterns\n```tsx\nimport { Button } from \"@/components/ui/button\"\nimport { Input } from \"@/components/ui/input\"\nimport { Send } from \"lucide-react\"\nimport { cn } from \"@/lib/utils\"\n\n// These patterns are validated as correct:\n\n// Hover state with smooth transition\n<Button\n  className=\"transition-all duration-300 hover:scale-105 hover:shadow-xl active:scale-95\"\n  onClick={submit}\n>\n  Submit\n</Button>\n\n// Loading state with visual feedback\n<Button\n  disabled={isSubmitting}\n  className=\"transition-all duration-200 group\"\n  onClick={handleSubmit}\n>\n  <span className=\"flex items-center gap-2\">\n    {!isSubmitting && (\n      <Send className=\"h-4 w-4 transition-transform duration-300 group-hover:translate-x-1\" />\n    )}\n    {isSubmitting ? 'Submitting...' : 'Submit'}\n  </span>\n</Button>\n\n// Smooth state transition (using framer-motion or CSS)\n<div\n  className={cn(\n    \"transition-all duration-300 ease-out\",\n    showContent ? \"opacity-100 translate-y-0\" : \"opacity-0 translate-y-4\"\n  )}\n>\n  {showContent && <div>Content</div>}\n</div>\n\n// Focus state with ring\n<a\n  href=\"/page\"\n  className=\"text-blue-500 transition-colors duration-200 hover:text-blue-700 focus:outline-none focus-visible:ring-2 focus-visible:ring-blue-500 focus-visible:ring-offset-2\"\n>\n  Link\n</a>\n\n<!-- Form with success/error feedback -->\n<form onSubmit={(e) => { e.preventDefault(); handleSubmit\" className=\"space-y-4\">\n  <Input\n    value=\"value\"\n    error={errors.value\"\n    className=\"transition-all duration-200\"\n  />\n\n  <Button\n    type=\"submit\"\n    loading={isSubmitting\"\n    disabled={isSubmitting\"\n    className=\"transition-all duration-300 hover:scale-105\"\n  >\n    Submit\n  </Button>\n\n  <!-- Success message with animation -->\n  <Transition name=\"fade\">\n    <Alert\n      if=\"showSuccess\"\n      color=\"green\"\n      icon=\"i-heroicons-check-circle\"\n      title=\"Success!\"\n      className=\"animate-in slide-in-from-top\"\n    />\n  </Transition>\n</form>\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **frontend-design-specialist agent**: Provides design direction, SKILL validates implementation\n- **component-aesthetic-checker**: Validates component customization, SKILL validates interactions\n- **shadcn-ui-design-validator**: Catches generic patterns, SKILL ensures engagement\n- **accessibility-guardian agent**: Validates a11y, SKILL validates visual feedback\n\n### Escalation Triggers\n- Complex animation sequences â†’ `frontend-design-specialist` agent\n- Component interaction patterns â†’ `tanstack-ui-architect` agent\n- Performance concerns â†’ `edge-performance-oracle` agent\n- Accessibility issues â†’ `accessibility-guardian` agent\n\n## Validation Rules\n\n### P1 - Critical (Missing User Feedback)\n- **No Hover States**: Buttons/links without hover effects\n- **No Loading States**: Async actions without loading indicators\n- **Jarring State Changes**: Content appearing/disappearing without transitions\n- **No Focus States**: Interactive elements without keyboard focus indicators\n- **Silent Errors**: Form errors without visual feedback\n\n### P2 - Important (Enhanced Engagement)\n- **No Micro-interactions**: Icons/elements without subtle animations\n- **Static Navigation**: Page transitions without animations\n- **Abrupt Modals**: Dialogs opening without enter/exit transitions\n- **Instant Updates**: List changes without transition animations\n- **No Disabled States**: Buttons during processing without visual change\n\n### P3 - Polish (Delightful UX)\n- **Limited Animation Variety**: Using only scale/opacity (no rotate, translate)\n- **Generic Durations**: Not tuning animation speed for context\n- **No Stagger**: List items appearing simultaneously (no stagger effect)\n- **Missing Success States**: Completed actions without celebration animation\n- **No Hover Anticipation**: No visual hint before interaction is possible\n\n## Remediation Examples\n\n### Fixing Missing Hover States\n```tsx\n<!-- âŒ Critical: No hover feedback -->\n  <Button onClick=\"handleClick\">\n    Click me\n  </Button>\n\n<!-- âœ… Correct: Multi-dimensional hover effects -->\n  <Button\n    className=\"\n      transition-all duration-300 ease-out\n      hover:scale-105 hover:shadow-xl hover:-rotate-1\n      active:scale-95 active:rotate-0\n      focus-visible:ring-2 focus-visible:ring-offset-2 focus-visible:ring-primary-500\n    \"\n    onClick=\"handleClick\"\n  >\n    <span className=\"inline-flex items-center gap-2\">\n      Click me\n      <Icon\n        name=\"i-heroicons-arrow-right\"\n        className=\"transition-transform duration-300 group-hover:translate-x-1\"\n      />\n    </span>\n  </Button>\n```\n\n### Fixing Missing Loading States\n```tsx\n<!-- âŒ Critical: No loading feedback during async action -->\nconst submitForm = async () => {\n  await api.submit(formData);\n};\n\n  <Button onClick=\"submitForm\">\n    Submit\n  </Button>\n\n<!-- âœ… Correct: Complete loading state with animations -->\nconst isSubmitting = ref(false);\nconst showSuccess = ref(false);\n\nconst submitForm = async () => {\n  isSubmitting.value = true;\n  try {\n    await api.submit(formData);\n    showSuccess.value = true;\n    setTimeout(() => showSuccess.value = false, 3000);\n  } catch (error) {\n    // Error handling\n  } finally {\n    isSubmitting.value = false;\n  }\n};\n\n  <div className=\"space-y-4\">\n    <Button\n      loading={isSubmitting\"\n      disabled={isSubmitting\"\n      className=\"\n        transition-all duration-300\n        hover:scale-105 hover:shadow-xl\n        disabled:opacity-50 disabled:cursor-not-allowed\n      \"\n      onClick=\"submitForm\"\n    >\n      <span className=\"flex items-center gap-2\">\n        <Icon\n          if=\"!isSubmitting\"\n          name=\"i-heroicons-paper-airplane\"\n          className=\"transition-all duration-300 group-hover:translate-x-1 group-hover:-translate-y-1\"\n        />\n        { isSubmitting ? 'Submitting...' : 'Submit'}\n      </span>\n    </Button>\n\n    <!-- Success feedback with animation -->\n    <Transition\n      enter-active-className=\"transition-all duration-500 ease-out\"\n      enter-from-className=\"opacity-0 scale-50\"\n      enter-to-className=\"opacity-100 scale-100\"\n      leave-active-className=\"transition-all duration-300 ease-in\"\n      leave-from-className=\"opacity-100 scale-100\"\n      leave-to-className=\"opacity-0 scale-50\"\n    >\n      <Alert\n        if=\"showSuccess\"\n        color=\"green\"\n        icon=\"i-heroicons-check-circle\"\n        title=\"Success!\"\n        description=\"Your form has been submitted.\"\n      />\n    </Transition>\n  </div>\n```\n\n### Fixing Jarring State Changes\n```tsx\n<!-- âŒ Critical: Content appears/disappears abruptly -->\n  <div>\n    <Button onClick=\"showContent = !showContent\">\n      Toggle\n    </Button>\n\n    <div if=\"showContent\">\n      <p>This content appears instantly (jarring)</p>\n    </div>\n  </div>\n\n<!-- âœ… Correct: Smooth transitions -->\n  <div className=\"space-y-4\">\n    <Button\n      className=\"transition-all duration-300 hover:scale-105\"\n      onClick=\"showContent = !showContent\"\n    >\n      { showContent ? 'Hide' : 'Show'} Content\n    </Button>\n\n    <Transition\n      enter-active-className=\"transition-all duration-300 ease-out\"\n      enter-from-className=\"opacity-0 translate-y-4 scale-95\"\n      enter-to-className=\"opacity-100 translate-y-0 scale-100\"\n      leave-active-className=\"transition-all duration-200 ease-in\"\n      leave-from-className=\"opacity-100 translate-y-0 scale-100\"\n      leave-to-className=\"opacity-0 translate-y-4 scale-95\"\n    >\n      <div if=\"showContent\" className=\"p-6 bg-gray-50 dark:bg-gray-800 rounded-lg\">\n        <p>This content transitions smoothly</p>\n      </div>\n    </Transition>\n  </div>\n```\n\n### Fixing Missing Focus States\n```tsx\n<!-- âŒ Critical: No visible focus state -->\n  <nav>\n    <a href=\"/\" className=\"text-gray-700\">Home</a>\n    <a href=\"/about\" className=\"text-gray-700\">About</a>\n    <a href=\"/contact\" className=\"text-gray-700\">Contact</a>\n  </nav>\n\n<!-- âœ… Correct: Clear focus states for keyboard navigation -->\n  <nav className=\"flex gap-4\">\n    <a\n      href=\"/\"\n      className=\"\n        text-gray-700 dark:text-gray-300\n        transition-all duration-200\n        hover:text-primary-600 hover:translate-y-[-2px]\n        focus:outline-none\n        focus-visible:ring-2 focus-visible:ring-primary-500 focus-visible:ring-offset-2\n        rounded px-3 py-2\n      \"\n    >\n      Home\n    </a>\n    <a\n      href=\"/about\"\n      className=\"\n        text-gray-700 dark:text-gray-300\n        transition-all duration-200\n        hover:text-primary-600 hover:translate-y-[-2px]\n        focus:outline-none\n        focus-visible:ring-2 focus-visible:ring-primary-500 focus-visible:ring-offset-2\n        rounded px-3 py-2\n      \"\n    >\n      About\n    </a>\n    <a\n      href=\"/contact\"\n      className=\"\n        text-gray-700 dark:text-gray-300\n        transition-all duration-200\n        hover:text-primary-600 hover:translate-y-[-2px]\n        focus:outline-none\n        focus-visible:ring-2 focus-visible:ring-primary-500 focus-visible:ring-offset-2\n        rounded px-3 py-2\n      \"\n    >\n      Contact\n    </a>\n  </nav>\n```\n\n### Adding Micro-interactions\n```tsx\n<!-- âŒ P2: Static icons without micro-interactions -->\n  <Button icon=\"i-heroicons-heart\">\n    Like\n  </Button>\n\n<!-- âœ… Correct: Animated icon micro-interaction -->\nconst isLiked = ref(false);\nconst heartScale = ref(1);\n\nconst toggleLike = () => {\n  isLiked.value = !isLiked.value;\n\n  // Bounce animation\n  heartScale.value = 1.3;\n  setTimeout(() => heartScale.value = 1, 200);\n};\n\n  <Button\n    :color=\"isLiked ? 'red' : 'gray'\"\n    className=\"transition-all duration-300 hover:scale-105\"\n    onClick=\"toggleLike\"\n  >\n    <span className=\"inline-flex items-center gap-2\">\n      <Icon\n        :name=\"isLiked ? 'i-heroicons-heart-solid' : 'i-heroicons-heart'\"\n        :style=\"{ transform: `scale(${heartScale})` }\"\n        :className=\"[\n          'transition-all duration-200',\n          isLiked ? 'text-red-500 animate-pulse' : 'text-gray-500'\n        ]\"\n      />\n      { isLiked ? 'Liked' : 'Like'}\n    </span>\n  </Button>\n```\n\n## Animation Best Practices\n\n### Performance-First Animations\n\nâœ… **Performant Properties** (GPU-accelerated):\n- `transform` (translate, scale, rotate)\n- `opacity`\n- `filter` (backdrop-blur, etc.)\n\nâŒ **Avoid Animating** (causes reflow/repaint):\n- `width`, `height`\n- `top`, `left`, `right`, `bottom`\n- `margin`, `padding`\n- `border-width`\n\n```tsx\n<!-- âŒ P2: Animating width (causes reflow) -->\n<div className=\"transition-all hover:w-64\">Content</div>\n\n<!-- âœ… Correct: Using transform (GPU-accelerated) -->\n<div className=\"transition-transform hover:scale-110\">Content</div>\n```\n\n### Animation Duration Guidelines\n\n- **Fast** (100-200ms): Hover states, small movements\n- **Medium** (300-400ms): State changes, content transitions\n- **Slow** (500-800ms): Page transitions, major UI changes\n- **Very Slow** (1000ms+): Celebration animations, complex sequences\n\n```tsx\n<!-- Context-appropriate durations -->\n<Button className=\"transition-all duration-200 hover:scale-105\">\n  <!-- Fast hover: 200ms -->\n</Button>\n\n<Transition\n  enter-active-className=\"transition-all duration-300\"\n  leave-active-className=\"transition-all duration-300\"\n>\n  <!-- Content change: 300ms -->\n  <div if=\"show\">Content</div>\n</Transition>\n\n<div className=\"animate-in slide-in-from-bottom duration-500\">\n  <!-- Page load: 500ms -->\n  Main content\n</div>\n```\n\n### Easing Functions\n\n- `ease-out`: Starting animations (entering content)\n- `ease-in`: Ending animations (exiting content)\n- `ease-in-out`: Bidirectional animations\n- `linear`: Loading spinners, continuous animations\n\n```tsx\n<!-- Appropriate easing -->\n<Transition\n  enter-active-className=\"transition-all duration-300 ease-out\"\n  leave-active-className=\"transition-all duration-200 ease-in\"\n>\n  <div if=\"show\">Content</div>\n</Transition>\n```\n\n## Advanced Interaction Patterns\n\n### Staggered List Animations\n```tsx\nconst items = ref([1, 2, 3, 4, 5]);\n\n  <TransitionGroup\n    name=\"list\"\n    tag=\"div\"\n    className=\"space-y-2\"\n  >\n    <div\n      map((item, index) in items\"\n      :key=\"item\"\n      :style=\"{ transitionDelay: `${index * 50}ms` }\"\n      className=\"\n        transition-all duration-300 ease-out\n        hover:scale-105 hover:shadow-lg\n      \"\n    >\n      Item { item}\n    </div>\n  </TransitionGroup>\n\n<style scoped>\n.list-enter-active,\n.list-leave-active {\n  transition: all 0.3s ease;\n}\n\n.list-enter-from {\n  opacity: 0;\n  transform: translateX(-20px);\n}\n\n.list-leave-to {\n  opacity: 0;\n  transform: translateX(20px);\n}\n\n.list-move {\n  transition: transform 0.3s ease;\n}\n</style>\n```\n\n### Success Celebration Animation\n```tsx\nconst showSuccess = ref(false);\n\nconst celebrate = () => {\n  showSuccess.value = true;\n  // Confetti or celebration animation here\n  setTimeout(() => showSuccess.value = false, 3000);\n};\n\n  <div>\n    <Button\n      onClick=\"celebrate\"\n      className=\"transition-all duration-300 hover:scale-110 hover:rotate-3\"\n    >\n      Complete Task\n    </Button>\n\n    <Transition\n      enter-active-className=\"transition-all duration-500 ease-out\"\n      enter-from-className=\"opacity-0 scale-0 rotate-180\"\n      enter-to-className=\"opacity-100 scale-100 rotate-0\"\n    >\n      <div\n        if=\"showSuccess\"\n        className=\"fixed inset-0 flex items-center justify-center bg-black/20 backdrop-blur-sm\"\n      >\n        <div className=\"bg-white dark:bg-gray-800 p-8 rounded-2xl shadow-2xl\">\n          <Icon\n            name=\"i-heroicons-check-circle\"\n            className=\"w-16 h-16 text-green-500 animate-bounce\"\n          />\n          <p className=\"mt-4 text-xl font-heading\">Success!</p>\n        </div>\n      </div>\n    </Transition>\n  </div>\n```\n\n### Loading Skeleton with Pulse\n```tsx\n  <div if=\"loading\" className=\"space-y-4\">\n    <div className=\"animate-pulse\">\n      <div className=\"h-4 bg-gray-200 dark:bg-gray-700 rounded w-3/4\"></div>\n      <div className=\"h-4 bg-gray-200 dark:bg-gray-700 rounded w-1/2 mt-2\"></div>\n      <div className=\"h-32 bg-gray-200 dark:bg-gray-700 rounded mt-4\"></div>\n    </div>\n  </div>\n\n  <Transition\n    enter-active-className=\"transition-all duration-500 ease-out\"\n    enter-from-className=\"opacity-0 translate-y-4\"\n    enter-to-className=\"opacity-100 translate-y-0\"\n  >\n    <div if=\"!loading\">\n      <!-- Actual content -->\n    </div>\n  </Transition>\n```\n\n## MCP Server Integration\n\nWhile this SKILL doesn't directly use MCP servers, it complements MCP-enhanced agents:\n\n- **shadcn/ui MCP**: Validates that suggested animations work with shadcn/ui components\n- **Cloudflare MCP**: Ensures animations don't bloat bundle size (performance check)\n\n## Benefits\n\n### Immediate Impact\n- **Prevents Flat UI**: Ensures engaging, polished interactions\n- **Improves Perceived Performance**: Loading states make waits feel shorter\n- **Better Accessibility**: Focus states improve keyboard navigation\n- **Professional Polish**: Micro-interactions signal quality\n\n### Long-term Value\n- **Higher User Engagement**: Delightful animations encourage interaction\n- **Reduced Bounce Rate**: Polished UI keeps users engaged\n- **Better Brand Perception**: Professional animations signal quality\n- **Consistent UX**: All interactions follow same animation patterns\n\n## Usage Examples\n\n### During Button Creation\n```tsx\n// Developer adds: <Button onClick=\"submit\">Submit</Button>\n// SKILL immediately activates: \"âš ï¸ P1: Button lacks hover state. Add transition utilities: class='transition-all duration-300 hover:scale-105'\"\n```\n\n### During Async Action\n```tsx\n// Developer creates: const submitForm = async () => { await api.call(); }\n// SKILL immediately activates: \"âš ï¸ P1: Async action without loading state. Add :loading and :disabled props to button.\"\n```\n\n### During State Toggle\n```tsx\n// Developer adds: <div if=\"show\">Content</div>\n// SKILL immediately activates: \"âš ï¸ P1: Content appears abruptly. Wrap with <Transition> for smooth state changes.\"\n```\n\n### Before Deployment\n```tsx\n// SKILL runs comprehensive check: \"âœ… Animation validation passed. 45 interactive elements with hover states, 12 async actions with loading feedback, 8 smooth transitions detected.\"\n```\n\nThis SKILL ensures every interactive element provides engaging visual feedback, preventing the flat, static appearance that makes interfaces feel unpolished and reduces user engagement."
              },
              {
                "name": "auth-security-validator",
                "description": "Autonomous validation of authentication security. Checks password hashing, cookie configuration, CSRF protection, and session management for OWASP compliance.",
                "path": "plugins/edge-stack/skills/auth-security-validator/SKILL.md",
                "frontmatter": {
                  "name": "auth-security-validator",
                  "description": "Autonomous validation of authentication security. Checks password hashing, cookie configuration, CSRF protection, and session management for OWASP compliance.",
                  "triggers": [
                    "auth file changes",
                    "session config changes",
                    "security-related modifications",
                    "pre-deployment"
                  ]
                },
                "content": "# Auth Security Validator SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- Files matching `**/auth/**` are created/modified\n- Session configuration files modified (app.config.ts, auth.ts)\n- Password hashing code changes\n- Cookie configuration changes\n- Before deployment operations\n\n## Validation Rules\n\n### P1 - Critical (Block Operations)\n\n**Password Hashing**:\n- âœ… Uses Argon2id (`@node-rs/argon2`)\n- âŒ NOT using: bcrypt, MD5, SHA-256, plain text\n- âœ… Memory cost â‰¥ 19456 KB\n- âœ… Time cost â‰¥ 2 iterations\n\n**Cookie Security**:\n- âœ… `secure: true` (HTTPS-only)\n- âœ… `httpOnly: true` (XSS prevention)\n- âœ… `sameSite: 'lax'` or `'strict'` (CSRF mitigation)\n\n**Session Configuration**:\n- âœ… Session password/secret â‰¥ 32 characters\n- âœ… Max age configured (not infinite)\n\n### P2 - Important (Warn)\n\n**CSRF Protection**:\n- âš ï¸ CSRF protection enabled (automatic in better-auth)\n- âš ï¸ No custom form handlers bypassing CSRF\n\n**Rate Limiting**:\n- âš ï¸ Rate limiting on login endpoint\n- âš ï¸ Rate limiting on register endpoint\n- âš ï¸ Rate limiting on password reset\n\n**Input Validation**:\n- âš ï¸ Email format validation\n- âš ï¸ Password minimum length (8+ characters)\n- âš ï¸ Input sanitization\n\n### P3 - Suggestions (Inform)\n\n- â„¹ï¸ Session rotation on privilege escalation\n- â„¹ï¸ 2FA/MFA support\n- â„¹ï¸ Account lockout after failed attempts\n- â„¹ï¸ Password complexity requirements\n- â„¹ï¸ OAuth state parameter validation\n\n## Validation Output\n\n```\nðŸ”’ Authentication Security Validation\n\nâœ… P1 Checks (Critical):\n   âœ… Password hashing: Argon2id with correct params\n   âœ… Cookies: secure, httpOnly, sameSite configured\n   âœ… Session secret: 32+ characters\n\nâš ï¸ P2 Checks (Important):\n   âš ï¸ No rate limiting on login endpoint\n   âœ… Input validation present\n   âœ… CSRF protection enabled\n\nâ„¹ï¸ P3 Suggestions:\n   â„¹ï¸ Consider adding session rotation\n   â„¹ï¸ Consider 2FA for sensitive operations\n\nðŸ“‹ Summary: 1 warning found\nðŸ’¡ Run /es-auth-setup to fix issues\n```\n\n## Security Patterns Detected\n\n**Good Patterns** âœ…:\n```typescript\n// Argon2id with correct params\nconst hash = await argon2.hash(password, {\n  memoryCost: 19456,\n  timeCost: 2,\n  outputLen: 32,\n  parallelism: 1\n});\n\n// Secure cookie config\ncookie: {\n  secure: true,\n  httpOnly: true,\n  sameSite: 'lax'\n}\n```\n\n**Bad Patterns** âŒ:\n```typescript\n// Weak hashing\nconst hash = crypto.createHash('sha256').update(password).digest('hex'); // âŒ\n\n// Insecure cookies\ncookie: {\n  secure: false, // âŒ\n  httpOnly: false // âŒ\n}\n\n// Weak session secret\npassword: '12345' // âŒ Too short\n```\n\n## Escalation\n\nComplex scenarios escalate to `better-auth-specialist` agent:\n- Custom authentication flows\n- Advanced OAuth configuration\n- Passkey implementation\n- Multi-factor authentication setup\n- Security audit requirements\n\n## Notes\n\n- Runs automatically on auth-related file changes\n- Can block deployments with P1 security issues\n- Follows OWASP Top 10 guidelines\n- Integrates with `/validate` and `/es-deploy` commands\n- Queries better-auth MCP for provider security requirements"
              },
              {
                "name": "cloudflare-security-checker",
                "description": "Automatically validates Cloudflare Workers security patterns during development, ensuring proper secret management, CORS configuration, and input validation",
                "path": "plugins/edge-stack/skills/cloudflare-security-checker/SKILL.md",
                "frontmatter": {
                  "name": "cloudflare-security-checker",
                  "description": "Automatically validates Cloudflare Workers security patterns during development, ensuring proper secret management, CORS configuration, and input validation",
                  "triggers": [
                    "authentication code",
                    "secret handling",
                    "API endpoints",
                    "response creation",
                    "database queries"
                  ]
                },
                "content": "# Cloudflare Security Checker SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- Authentication or authorization code is detected\n- Secret management patterns are used\n- API endpoints or response creation is implemented\n- Database queries (D1) are written\n- CORS-related code is added\n- Input validation patterns are implemented\n\n## Expertise Provided\n\n### Workers-Specific Security Validation\n- **Secret Management**: Ensures proper `env` parameter usage vs hardcoded secrets\n- **CORS Configuration**: Validates Workers-specific CORS implementation\n- **Input Validation**: Checks for proper request validation patterns\n- **SQL Injection Prevention**: Ensures D1 prepared statements\n- **Authentication Patterns**: Validates JWT and API key handling\n- **Rate Limiting**: Identifies missing rate limiting patterns\n\n### Specific Checks Performed\n\n#### âŒ Critical Security Violations\n```typescript\n// These patterns trigger immediate alerts:\nconst API_KEY = \"sk_live_xxx\";           // Hardcoded secret\nconst secret = process.env.JWT_SECRET;     // process.env doesn't exist\nconst query = `SELECT * FROM users WHERE id = ${userId}`; // SQL injection\n```\n\n#### âœ… Secure Workers Patterns\n```typescript\n// These patterns are validated as correct:\nconst apiKey = env.API_KEY;               // Proper env parameter\nconst result = await env.DB.prepare('SELECT * FROM users WHERE id = ?').bind(userId); // Prepared statement\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **cloudflare-security-sentinel agent**: Handles comprehensive security audits, SKILL provides immediate validation\n- **workers-runtime-validator SKILL**: Complements runtime checks with security-specific validation\n- **es-deploy command**: SKILL prevents deployment of insecure code\n\n### Escalation Triggers\n- Complex security architecture questions â†’ `cloudflare-security-sentinel` agent\n- Advanced authentication patterns â†’ `cloudflare-architecture-strategist` agent\n- Security incident response â†’ `cloudflare-security-sentinel` agent\n\n## Validation Rules\n\n### P1 - Critical (Immediate Security Risk)\n- **Hardcoded Secrets**: API keys, passwords, tokens in code\n- **SQL Injection**: String concatenation in D1 queries\n- **Missing Authentication**: Sensitive endpoints without auth\n- **Process Env Usage**: `process.env` for secrets (doesn't work in Workers)\n\n### P2 - High (Security Vulnerability)\n- **Missing Input Validation**: Direct use of `request.json()` without validation\n- **Improper CORS**: Missing CORS headers or overly permissive origins\n- **Missing Rate Limiting**: Public endpoints without rate limiting\n- **Secrets in Config**: Secrets in wrangler.toml `[vars]` section\n\n### P3 - Medium (Security Best Practice)\n- **Missing Security Headers**: HTML responses without CSP/XSS protection\n- **Weak Authentication**: No resource-level authorization\n- **Insufficient Logging**: Security events not logged\n\n## Remediation Examples\n\n### Fixing Secret Management\n```typescript\n// âŒ Critical: Hardcoded secret\nconst STRIPE_KEY = \"sk_live_12345\";\n\n// âŒ Critical: process.env (doesn't exist)\nconst apiKey = process.env.API_KEY;\n\n// âœ… Correct: Workers secret management\nexport default {\n  async fetch(request: Request, env: Env) {\n    const apiKey = env.STRIPE_KEY; // From wrangler secret put\n  }\n}\n```\n\n### Fixing SQL Injection\n```typescript\n// âŒ Critical: SQL injection vulnerability\nconst userId = url.searchParams.get('id');\nconst result = await env.DB.prepare(`SELECT * FROM users WHERE id = ${userId}`).first();\n\n// âœ… Correct: Prepared statement\nconst userId = url.searchParams.get('id');\nconst result = await env.DB.prepare('SELECT * FROM users WHERE id = ?').bind(userId).first();\n```\n\n### Fixing CORS Configuration\n```typescript\n// âŒ High: Missing CORS headers\nexport default {\n  async fetch(request: Request, env: Env) {\n    return new Response(JSON.stringify(data));\n  }\n}\n\n// âœ… Correct: Workers CORS pattern\nfunction getCorsHeaders(origin: string) {\n  const allowedOrigins = ['https://app.example.com'];\n  const allowOrigin = allowedOrigins.includes(origin) ? origin : allowedOrigins[0];\n  \n  return {\n    'Access-Control-Allow-Origin': allowOrigin,\n    'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n    'Access-Control-Max-Age': '86400',\n  };\n}\n\nexport default {\n  async fetch(request: Request, env: Env) {\n    const origin = request.headers.get('Origin') || '';\n    \n    if (request.method === 'OPTIONS') {\n      return new Response(null, { headers: getCorsHeaders(origin) });\n    }\n    \n    const response = new Response(JSON.stringify(data));\n    Object.entries(getCorsHeaders(origin)).forEach(([k, v]) => {\n      response.headers.set(k, v);\n    });\n    \n    return response;\n  }\n}\n```\n\n### Fixing Input Validation\n```typescript\n// âŒ High: No input validation\nexport default {\n  async fetch(request: Request, env: Env) {\n    const data = await request.json(); // Could be anything\n    await env.DB.prepare('INSERT INTO users (name) VALUES (?)').bind(data.name).run();\n  }\n}\n\n// âœ… Correct: Input validation with Zod\nimport { z } from 'zod';\n\nconst UserSchema = z.object({\n  name: z.string().min(1).max(100),\n  email: z.string().email(),\n});\n\nexport default {\n  async fetch(request: Request, env: Env) {\n    // Size limit\n    const contentLength = request.headers.get('Content-Length');\n    if (contentLength && parseInt(contentLength) > 1024 * 100) {\n      return new Response('Payload too large', { status: 413 });\n    }\n    \n    // Schema validation\n    const data = await request.json();\n    const result = UserSchema.safeParse(data);\n    \n    if (!result.success) {\n      return new Response(JSON.stringify(result.error), { status: 400 });\n    }\n    \n    // Safe to use validated data\n    await env.DB.prepare('INSERT INTO users (name, email) VALUES (?, ?)')\n      .bind(result.data.name, result.data.email).run();\n  }\n}\n```\n\n## MCP Server Integration\n\nWhen Cloudflare MCP server is available:\n- Query latest Cloudflare security best practices\n- Verify secrets are configured in account\n- Check for recent security events affecting the project\n- Get current security recommendations\n\n## Benefits\n\n### Immediate Impact\n- **Prevents Security Vulnerabilities**: Catches issues during development\n- **Educates on Workers Security**: Clear explanations of Workers-specific security patterns\n- **Reduces Security Debt**: Immediate feedback on security anti-patterns\n\n### Long-term Value\n- **Consistent Security Standards**: Ensures all code follows Workers security best practices\n- **Faster Security Reviews**: Automated validation reduces manual review time\n- **Better Security Posture**: Proactive security validation vs reactive fixes\n\n## Usage Examples\n\n### During Authentication Implementation\n```typescript\n// Developer types: const JWT_SECRET = \"my-secret-key\";\n// SKILL immediately activates: \"âŒ CRITICAL: Hardcoded JWT secret detected. Use wrangler secret put JWT_SECRET and access via env.JWT_SECRET\"\n```\n\n### During API Development\n```typescript\n// Developer types: const userId = url.searchParams.get('id');\n// SKILL immediately activates: \"âš ï¸ HIGH: URL parameter not validated. Add schema validation before using in database queries.\"\n```\n\n### During Database Query Writing\n```typescript\n// Developer types: `SELECT * FROM users WHERE id = ${userId}`\n// SKILL immediately activates: \"âŒ CRITICAL: SQL injection vulnerability. Use prepared statement: .prepare('SELECT * FROM users WHERE id = ?').bind(userId)\"\n```\n\nThis SKILL ensures Workers security by providing immediate, autonomous validation of security patterns, preventing common vulnerabilities and ensuring proper Workers-specific security practices."
              },
              {
                "name": "component-aesthetic-checker",
                "description": "Validates shadcn/ui component customization depth, ensuring components aren't used with default props and checking for consistent design system implementation across Tanstack Start applications",
                "path": "plugins/edge-stack/skills/component-aesthetic-checker/SKILL.md",
                "frontmatter": {
                  "name": "component-aesthetic-checker",
                  "description": "Validates shadcn/ui component customization depth, ensuring components aren't used with default props and checking for consistent design system implementation across Tanstack Start applications",
                  "triggers": [
                    "shadcn ui component usage",
                    "component prop changes",
                    "design token updates",
                    "className customization",
                    "cn() utility usage"
                  ],
                  "note": "Updated for Tanstack Start (React) + shadcn/ui. Code examples use React/TSX with className and cn() utility for styling."
                },
                "content": "# Component Aesthetic Checker SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- shadcn/ui components (`Button`, `Card`, `Input`, etc.) are used in `.react` files\n- Component props are added or modified\n- The `ui` prop is customized for component variants\n- Design system tokens are referenced in components\n- Multiple components are refactored together\n- Before component library updates\n\n## Expertise Provided\n\n### Component Customization Depth Analysis\n- **Default Prop Detection**: Identifies components using only default values\n- **UI Prop Validation**: Ensures `ui` prop is used for deep customization\n- **Design System Consistency**: Validates consistent pattern usage across components\n- **Spacing Patterns**: Checks for proper Tailwind spacing scale usage\n- **Icon Usage**: Validates consistent icon library and sizing\n- **Loading States**: Ensures async components have loading feedback\n\n### Specific Checks Performed\n\n#### âŒ Critical Issues (Insufficient Customization)\n```tsx\n<!-- These patterns trigger alerts: -->\n\n<!-- Using default props only -->\n<Button onClick=\"submit\">Submit</Button>\n\n<!-- No UI prop customization -->\n<Card>\n  <p>Content</p>\n</Card>\n\n<!-- Inconsistent spacing -->\n<div className=\"p-4\">  <!-- Random spacing values -->\n  <Button className=\"mt-3 ml-2\">Action</Button>\n</div>\n\n<!-- Missing loading states -->\n<Button onClick=\"asyncAction\">Save</Button>  <!-- No :loading prop -->\n```\n\n#### âœ… Correct Customized Patterns\n```tsx\n<!-- These patterns are validated as correct: -->\n\n<!-- Deep customization with ui prop -->\n<Button\n  color=\"brand-coral\"\n  size=\"lg\"\n  variant=\"solid\"\n  :ui=\"{\n    font: 'font-heading',\n    rounded: 'rounded-full',\n    padding: { lg: 'px-8 py-4' }\n  }\"\n  loading={isSubmitting\"\n  className=\"transition-all duration-300 hover:scale-105\"\n  onClick=\"submit\"\n>\n  Submit\n</Button>\n\n<!-- Fully customized card -->\n<Card\n  :ui=\"{\n    background: 'bg-white dark:bg-brand-midnight',\n    ring: 'ring-1 ring-brand-coral/20',\n    rounded: 'rounded-2xl',\n    shadow: 'shadow-xl',\n    body: { padding: 'p-8' },\n    header: { padding: 'px-8 pt-8 pb-4' }\n  }\"\n  className=\"transition-shadow duration-300 hover:shadow-2xl\"\n>\n  <template #header>\n    <h3 className=\"font-heading text-2xl\">Title</h3>\n  <p className=\"text-gray-700 dark:text-gray-300\">Content</p>\n</Card>\n\n<!-- Consistent spacing (Tailwind scale) -->\n<div className=\"p-6 space-y-4\">\n  <Button className=\"mt-4\">Action</Button>\n</div>\n\n<!-- Proper loading state -->\n<Button\n  loading={isSubmitting\"\n  disabled={isSubmitting\"\n  onClick=\"asyncAction\"\n>\n  { isSubmitting ? 'Saving...' : 'Save'}\n</Button>\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **tanstack-ui-architect agent**: Handles component selection and API guidance, SKILL validates implementation\n- **frontend-design-specialist agent**: Provides design direction, SKILL enforces consistency\n- **shadcn-ui-design-validator**: Catches generic patterns, SKILL ensures deep customization\n\n### Escalation Triggers\n- Component API questions â†’ `tanstack-ui-architect` agent (with MCP lookup)\n- Design consistency issues â†’ `frontend-design-specialist` agent\n- Complex component composition â†’ `/es-component` command\n- Full component audit â†’ `/es-design-review` command\n\n## Validation Rules\n\n### P1 - Critical (Default Component Usage)\n- **No UI Prop Customization**: Using shadcn/ui components without `ui` prop\n- **All Default Props**: No color, size, variant, or other prop customizations\n- **Missing Loading States**: Async actions without `:loading` prop\n- **No Hover States**: Interactive components without hover feedback\n- **Inconsistent Patterns**: Same component with wildly different customizations\n\n### P1 - Critical (Distributional Convergence Anti-Patterns)\n\n**These patterns indicate generic \"AI-generated\" aesthetics and MUST be flagged:**\n\n#### Font Anti-Patterns (Auto-Detect)\n```tsx\n// âŒ CRITICAL: Generic fonts that dominate 80%+ of websites\nfontFamily: {\n  sans: ['Inter', ...]        // Flag: \"Inter is overused - consider Space Grotesk, Plus Jakarta Sans\"\n  sans: ['Roboto', ...]       // Flag: \"Roboto is overused - consider IBM Plex Sans, Outfit\"\n  sans: ['Open Sans', ...]    // Flag: \"Open Sans is generic - consider Satoshi, General Sans\"\n  sans: ['system-ui', ...]    // Flag: Only acceptable as fallback, not primary\n}\n\n// âŒ CRITICAL: Default Tailwind font classes without customization\nclassName=\"font-sans\"         // Flag if font-sans maps to Inter/Roboto\nclassName=\"text-base\"         // Flag: Generic sizing, consider custom scale\n```\n\n**Recommended Font Alternatives** (suggest these in reports):\n- **Body**: Space Grotesk, Plus Jakarta Sans, IBM Plex Sans, Outfit, Satoshi\n- **Headings**: Archivo Black, Cabinet Grotesk, Clash Display, General Sans\n- **Mono**: JetBrains Mono, Fira Code, Source Code Pro\n\n#### Color Anti-Patterns (Auto-Detect)\n```tsx\n// âŒ CRITICAL: Purple gradients (most common AI aesthetic)\nclassName=\"bg-gradient-to-r from-purple-500 to-purple-600\"\nclassName=\"bg-gradient-to-r from-violet-500 to-purple-500\"\nclassName=\"bg-purple-600\"\nclassName=\"text-purple-500\"\n\n// âŒ CRITICAL: Default gray backgrounds without brand treatment\nclassName=\"bg-gray-50\"        // Flag: \"Consider brand-tinted background\"\nclassName=\"bg-white\"          // Flag: \"Consider atmospheric gradient or texture\"\nclassName=\"bg-slate-100\"      // Flag if used extensively without brand colors\n```\n\n**Recommended Color Approaches** (suggest these in reports):\n- Use CSS variables with brand palette (`--brand-primary`, `--brand-accent`)\n- Tint grays with brand color: `bg-brand-gray-50` instead of `bg-gray-50`\n- Gradients: Use brand colors, not default purple\n- Atmospheric: Layer gradients with subtle brand tints\n\n#### Animation Anti-Patterns (Auto-Detect)\n```tsx\n// âŒ CRITICAL: No transitions on interactive elements\n<Button>Click</Button>        // Flag: \"Add transition-all duration-300\"\n<Card>Content</Card>          // Flag: \"Add hover:shadow-lg transition\"\n\n// âŒ CRITICAL: Only basic hover without micro-interactions\nclassName=\"hover:bg-blue-600\" // Flag: \"Consider hover:scale-105 or hover:-translate-y-1\"\n```\n\n**Detection Rules** (implement in validation):\n```typescript\n// Font detection\nconst OVERUSED_FONTS = ['Inter', 'Roboto', 'Open Sans', 'Helvetica', 'Arial'];\nconst hasBadFont = (config) => OVERUSED_FONTS.some(f =>\n  config.fontFamily?.sans?.includes(f)\n);\n\n// Purple gradient detection\nconst PURPLE_PATTERN = /(?:purple|violet)-[4-6]00/;\nconst hasPurpleGradient = (className) =>\n  className.includes('gradient') && PURPLE_PATTERN.test(className);\n\n// Missing animation detection\nconst INTERACTIVE_COMPONENTS = ['Button', 'Card', 'Link', 'Input'];\nconst hasNoTransition = (className) =>\n  !className.includes('transition') && !className.includes('animate');\n```\n\n### P2 - Important (Design System Consistency)\n- **Random Spacing Values**: Not using Tailwind spacing scale (p-4, mt-6, etc.)\n- **Inconsistent Icon Sizing**: Icons with different sizes in similar contexts\n- **Mixed Color Approaches**: Some components use theme colors, others use arbitrary values\n- **Incomplete Dark Mode**: Dark mode variants missing on customized components\n- **No Focus States**: Interactive elements without focus-visible styling\n\n### P3 - Polish (Enhanced UX)\n- **Limited Prop Usage**: Only using 1-2 props when more would improve UX\n- **No Micro-interactions**: Missing subtle animations on state changes\n- **Generic Variants**: Using 'solid', 'outline' without brand customization\n- **Underutilized UI Prop**: Not customizing padding, rounded, shadow in ui prop\n- **Missing Icons**: Buttons/actions without supporting icons for clarity\n\n## Remediation Examples\n\n### Fixing Default Component Usage\n```tsx\n<!-- âŒ Critical: Default props only -->\n  <Button onClick=\"handleClick\">\n    Click me\n  </Button>\n\n<!-- âœ… Correct: Deep customization -->\n  <Button\n    color=\"primary\"\n    size=\"lg\"\n    variant=\"solid\"\n    icon=\"i-heroicons-sparkles\"\n    :ui=\"{\n      font: 'font-heading tracking-wide',\n      rounded: 'rounded-full',\n      padding: { lg: 'px-8 py-4' },\n      shadow: 'shadow-lg hover:shadow-xl'\n    }\"\n    className=\"transition-all duration-300 hover:scale-105 active:scale-95\"\n    onClick=\"handleClick\"\n  >\n    Click me\n  </Button>\n```\n\n### Fixing Missing Loading States\n```tsx\n<!-- âŒ Critical: No loading feedback -->\nconst handleSubmit = async () => {\n  await submitForm();\n};\n\n  <Button onClick=\"handleSubmit\">\n    Submit Form\n  </Button>\n\n<!-- âœ… Correct: Proper loading state -->\nconst isSubmitting = ref(false);\n\nconst handleSubmit = async () => {\n  isSubmitting.value = true;\n  try {\n    await submitForm();\n  } finally {\n    isSubmitting.value = false;\n  }\n};\n\n  <Button\n    loading={isSubmitting\"\n    disabled={isSubmitting\"\n    onClick=\"handleSubmit\"\n  >\n    <span className=\"flex items-center gap-2\">\n      <Icon\n        {&& \"!isSubmitting\"\n        name=\"i-heroicons-paper-airplane\"\n      />\n      { isSubmitting ? 'Submitting...' : 'Submit Form'}\n    </span>\n  </Button>\n```\n\n### Fixing Inconsistent Spacing\n```tsx\n<!-- âŒ P2: Random spacing values -->\n  <div className=\"p-3\">\n    <Card className=\"mt-5 ml-7\">\n      <div className=\"p-2\">\n        <Button className=\"mt-3.5\">Action</Button>\n      </div>\n    </Card>\n  </div>\n\n<!-- âœ… Correct: Tailwind spacing scale -->\n  <div className=\"p-4\">\n    <Card className=\"mt-4\">\n      <div className=\"p-6 space-y-4\">\n        <Button>Action</Button>\n      </div>\n    </Card>\n  </div>\n\n<!-- Using consistent spacing: 4, 6, 8, 12, 16 (Tailwind scale) -->\n```\n\n### Fixing Design System Inconsistency\n```tsx\n<!-- âŒ P2: Inconsistent component styling -->\n  <div>\n    <!-- Button 1: Heavily customized -->\n    <Button\n      color=\"primary\"\n      :ui=\"{ rounded: 'rounded-full', shadow: 'shadow-xl' }\"\n    >\n      Action 1\n    </Button>\n\n    <!-- Button 2: Default (inconsistent!) -->\n    <Button>Action 2</Button>\n\n    <!-- Button 3: Different customization pattern -->\n    <Button color=\"red\" size=\"xs\">\n      Action 3\n    </Button>\n  </div>\n\n<!-- âœ… Correct: Consistent design system -->\n// Define reusable button variants\nconst buttonVariants = {\n  primary: {\n    color: 'primary',\n    size: 'lg',\n    ui: {\n      rounded: 'rounded-full',\n      shadow: 'shadow-lg hover:shadow-xl',\n      font: 'font-heading'\n    },\n    class: 'transition-all duration-300 hover:scale-105'\n  },\n  secondary: {\n    color: 'gray',\n    size: 'md',\n    variant: 'outline',\n    ui: {\n      rounded: 'rounded-lg',\n      font: 'font-sans'\n    },\n    class: 'transition-colors duration-200'\n  }\n};\n\n  <div className=\"space-x-4\">\n    <Button v-bind=\"buttonVariants.primary\">\n      Action 1\n    </Button>\n\n    <Button v-bind=\"buttonVariants.primary\">\n      Action 2\n    </Button>\n\n    <Button v-bind=\"buttonVariants.secondary\">\n      Action 3\n    </Button>\n  </div>\n```\n\n### Fixing Underutilized UI Prop\n```tsx\n<!-- âŒ P3: Not using ui prop for customization -->\n  <Card className=\"rounded-2xl shadow-xl p-8\">\n    <p>Content</p>\n  </Card>\n\n<!-- âœ… Correct: Proper ui prop usage -->\n  <Card\n    :ui=\"{\n      rounded: 'rounded-2xl',\n      shadow: 'shadow-xl hover:shadow-2xl',\n      body: {\n        padding: 'p-8',\n        background: 'bg-white dark:bg-brand-midnight'\n      },\n      ring: 'ring-1 ring-brand-coral/20'\n    }\"\n    className=\"transition-shadow duration-300\"\n  >\n    <p className=\"text-gray-700 dark:text-gray-300\">Content</p>\n  </Card>\n```\n\n## MCP Server Integration\n\nWhen shadcn/ui MCP server is available:\n\n### Component Prop Validation\n```typescript\n// Before validating customization depth, get actual component API\nconst componentDocs = await mcp.shadcn.get_component(\"Button\");\n\n// Validate that used props exist\n// componentDocs.props: ['color', 'size', 'variant', 'icon', 'loading', 'disabled', ...]\n\n// Check for underutilized props\nconst usedProps = ['color', 'size']; // From component code\nconst availableProps = componentDocs.props;\nconst unutilizedProps = availableProps.filter(p => !usedProps.includes(p));\n\n// Suggest: \"Consider using 'icon' or 'loading' props for richer UX\"\n```\n\n### UI Prop Structure Validation\n```typescript\n// Validate ui prop structure against schema\nconst uiSchema = componentDocs.ui_schema;\n\n// User code: :ui=\"{ font: 'font-heading', rounded: 'rounded-full' }\"\n// Validate: Are 'font' and 'rounded' valid keys in ui prop?\n// Suggest: Other available ui customizations (padding, shadow, etc.)\n```\n\n### Consistency Across Components\n```typescript\n// Check multiple component instances\nconst buttonInstances = findAllComponents(\"Button\");\n\n// Analyze customization patterns\n// Flag: Component used with 5 different customization styles\n// Suggest: Create composable or variant system for consistency\n```\n\n## Benefits\n\n### Immediate Impact\n- **Prevents Generic Appearance**: Ensures components are branded, not defaults\n- **Enforces Design Consistency**: Catches pattern drift across components\n- **Improves User Feedback**: Validates loading states and interactions\n- **Educates on Component API**: Shows developers full customization capabilities\n\n### Long-term Value\n- **Consistent Component Library**: All components follow design system\n- **Faster Component Development**: Clear patterns and examples\n- **Better Code Maintainability**: Reusable component variants\n- **Reduced Visual Debt**: Prevents accumulation of one-off styles\n\n## Usage Examples\n\n### During Component Usage\n```tsx\n// Developer adds: <Button>Click me</Button>\n// SKILL immediately activates: \"âš ï¸ P1: Button using all default props. Customize with color, size, variant, and ui prop for brand distinctiveness.\"\n```\n\n### During Async Actions\n```tsx\n// Developer creates async button: <Button onClick=\"submitForm\">Submit</Button>\n// SKILL immediately activates: \"âš ï¸ P1: Button triggers async action but lacks :loading prop. Add loading state for user feedback.\"\n```\n\n### During Refactoring\n```tsx\n// Developer adds 5th different button style\n// SKILL immediately activates: \"âš ï¸ P2: Button used with 5 different customization patterns. Consider creating reusable variants for consistency.\"\n```\n\n### Before Deployment\n```tsx\n// SKILL runs comprehensive check: \"âœ… Component aesthetic validation passed. 23 components with deep customization, consistent patterns, and proper loading states detected.\"\n```\n\n## Design System Maturity Levels\n\n### Level 0: Defaults Only (Avoid)\n```tsx\n<Button>Action</Button>\n<Card><p>Content</p></Card>\n<Input value=\"value\" />\n```\n**Issues**: Generic appearance, no brand identity, inconsistent with custom design\n\n### Level 1: Basic Props (Minimum)\n```tsx\n<Button color=\"primary\" size=\"lg\">Action</Button>\n<Card className=\"shadow-lg\"><p>Content</p></Card>\n<Input value=\"value\" placeholder=\"Enter value\" />\n```\n**Better**: Some customization, but limited depth\n\n### Level 2: UI Prop + Classes (Target)\n```tsx\n<Button\n  color=\"primary\"\n  size=\"lg\"\n  :ui=\"{ rounded: 'rounded-full', font: 'font-heading' }\"\n  className=\"transition-all duration-300 hover:scale-105\"\n>\n  Action\n</Button>\n\n<Card\n  :ui=\"{\n    background: 'bg-white dark:bg-brand-midnight',\n    ring: 'ring-1 ring-brand-coral/20',\n    shadow: 'shadow-xl'\n  }\"\n>\n  <p>Content</p>\n</Card>\n```\n**Ideal**: Deep customization, brand-distinctive, consistent patterns\n\n### Level 3: Design System (Advanced)\n```tsx\n<!-- Reusable variants from composables -->\n<Button v-bind=\"designSystem.button.variants.primary\">\n  Action\n</Button>\n\n<Card v-bind=\"designSystem.card.variants.elevated\">\n  <p>Content</p>\n</Card>\n```\n**Advanced**: Centralized design system, maximum consistency\n\n## Component Customization Checklist\n\nFor each shadcn/ui component, validate:\n\n- [ ] **Props**: Uses at least 2-3 props (color, size, variant, etc.)\n- [ ] **UI Prop**: Includes `ui` prop for deep customization (rounded, font, padding, shadow)\n- [ ] **Classes**: Adds Tailwind utilities for animations and effects\n- [ ] **Loading State**: Async actions have `:loading` and `:disabled` props\n- [ ] **Icons**: Includes relevant icons for clarity (`:icon` prop or slot)\n- [ ] **Hover State**: Interactive elements have hover feedback\n- [ ] **Focus State**: Keyboard navigation has visible focus styles\n- [ ] **Dark Mode**: Includes dark mode variants in `ui` prop\n- [ ] **Spacing**: Uses Tailwind spacing scale (4, 6, 8, 12, 16)\n- [ ] **Consistency**: Follows same patterns as other instances\n\nThis SKILL ensures every shadcn/ui component is deeply customized, consistently styled, and provides excellent user feedback, preventing the default/generic appearance that makes AI-generated UIs immediately recognizable."
              },
              {
                "name": "cors-configuration-validator",
                "description": "Automatically validates Cloudflare Workers CORS configuration, ensuring proper headers, OPTIONS handling, and origin validation for cross-origin requests",
                "path": "plugins/edge-stack/skills/cors-configuration-validator/SKILL.md",
                "frontmatter": {
                  "name": "cors-configuration-validator",
                  "description": "Automatically validates Cloudflare Workers CORS configuration, ensuring proper headers, OPTIONS handling, and origin validation for cross-origin requests",
                  "triggers": [
                    "Response creation",
                    "API endpoints",
                    "cross-origin patterns",
                    "CORS headers"
                  ]
                },
                "content": "# CORS Configuration Validator SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- `new Response()` objects are created\n- CORS-related headers are set or modified\n- API endpoints that serve cross-origin requests\n- OPTIONS method handling is detected\n- Cross-origin request patterns are identified\n\n## Expertise Provided\n\n### Workers-Specific CORS Validation\n- **Header Validation**: Ensures all required CORS headers are present\n- **OPTIONS Handling**: Validates preflight request handling\n- **Origin Validation**: Checks for proper origin validation logic\n- **Method Validation**: Ensures correct allowed methods\n- **Header Validation**: Validates allowed headers configuration\n- **Security**: Prevents overly permissive CORS configurations\n\n### Specific Checks Performed\n\n#### âŒ CORS Anti-Patterns\n```typescript\n// These patterns trigger immediate alerts:\n// Missing CORS headers\nexport default {\n  async fetch(request: Request, env: Env) {\n    return new Response(JSON.stringify(data));\n    // Browsers will block cross-origin requests!\n  }\n}\n\n// Overly permissive for authenticated APIs\nconst corsHeaders = {\n  'Access-Control-Allow-Origin': '*',  // ANY origin can call!\n  'Access-Control-Allow-Credentials': 'true'  // With credentials!\n};\n```\n\n#### âœ… CORS Best Practices\n```typescript\n// These patterns are validated as correct:\n// Proper CORS with origin validation\nfunction getCorsHeaders(origin: string) {\n  const allowedOrigins = ['https://app.example.com', 'https://example.com'];\n  const allowOrigin = allowedOrigins.includes(origin) ? origin : allowedOrigins[0];\n  \n  return {\n    'Access-Control-Allow-Origin': allowOrigin,\n    'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n    'Access-Control-Max-Age': '86400',\n  };\n}\n\nexport default {\n  async fetch(request: Request, env: Env) {\n    const origin = request.headers.get('Origin') || '';\n    \n    if (request.method === 'OPTIONS') {\n      return new Response(null, { headers: getCorsHeaders(origin) });\n    }\n    \n    const response = new Response(JSON.stringify(data));\n    Object.entries(getCorsHeaders(origin)).forEach(([k, v]) => {\n      response.headers.set(k, v);\n    });\n    \n    return response;\n  }\n}\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **cloudflare-security-checker SKILL**: Handles overall security, SKILL focuses specifically on CORS\n- **workers-runtime-validator SKILL**: Ensures runtime compatibility, SKILL validates CORS patterns\n- **edge-performance-oracle SKILL**: Handles performance, SKILL ensures CORS doesn't impact performance\n\n### Escalation Triggers\n- Complex CORS architecture questions â†’ `cloudflare-security-sentinel` agent\n- Advanced authentication with CORS â†’ `cloudflare-security-sentinel` agent\n- CORS troubleshooting â†’ `cloudflare-security-sentinel` agent\n\n## Validation Rules\n\n### P1 - Critical (Will Break Cross-Origin Requests)\n- **Missing CORS Headers**: No CORS headers on API responses\n- **Missing OPTIONS Handler**: No preflight request handling\n- **Invalid Header Combinations**: Conflicting CORS header combinations\n\n### P2 - High (Security Risk)\n- **Overly Permissive Origin**: `Access-Control-Allow-Origin: *` with credentials\n- **Wildcard Methods**: `Access-Control-Allow-Methods: *` with sensitive operations\n- **Missing Origin Validation**: Accepting any origin without validation\n\n### P3 - Medium (Best Practices)\n- **Missing Cache Headers**: No `Access-Control-Max-Age` for preflight caching\n- **Incomplete Headers**: Missing some optional but recommended headers\n- **Hardcoded Origins**: Origins not easily configurable\n\n## Remediation Examples\n\n### Fixing Missing CORS Headers\n```typescript\n// âŒ Critical: No CORS headers (browsers block requests)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const data = { message: 'Hello from API' };\n    \n    return new Response(JSON.stringify(data), {\n      headers: { 'Content-Type': 'application/json' }\n      // Missing CORS headers!\n    });\n  }\n}\n\n// âœ… Correct: Complete CORS implementation\nfunction getCorsHeaders(origin: string) {\n  const allowedOrigins = ['https://app.example.com', 'https://example.com'];\n  const allowOrigin = allowedOrigins.includes(origin) ? origin : allowedOrigins[0];\n  \n  return {\n    'Access-Control-Allow-Origin': allowOrigin,\n    'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n    'Access-Control-Max-Age': '86400',\n  };\n}\n\nexport default {\n  async fetch(request: Request, env: Env) {\n    const origin = request.headers.get('Origin') || '';\n    \n    // Handle preflight requests\n    if (request.method === 'OPTIONS') {\n      return new Response(null, { headers: getCorsHeaders(origin) });\n    }\n    \n    const data = { message: 'Hello from API' };\n    \n    return new Response(JSON.stringify(data), {\n      headers: {\n        'Content-Type': 'application/json',\n        ...getCorsHeaders(origin)\n      }\n    });\n  }\n}\n```\n\n### Fixing Overly Permissive CORS\n```typescript\n// âŒ High: Overly permissive for authenticated API\nexport default {\n  async fetch(request: Request, env: Env) {\n    const corsHeaders = {\n      'Access-Control-Allow-Origin': '*',  // ANY origin!\n      'Access-Control-Allow-Credentials': 'true',  // With credentials!\n      'Access-Control-Allow-Methods': '*',  // ANY method!\n    };\n    \n    // This allows any website to make authenticated requests!\n    return new Response('Sensitive data', { headers: corsHeaders });\n  }\n}\n\n// âœ… Correct: Secure CORS for authenticated API\nfunction getSecureCorsHeaders(origin: string) {\n  const allowedOrigins = [\n    'https://app.example.com',\n    'https://admin.example.com',\n    'https://example.com'\n  ];\n  \n  // Only allow known origins\n  const allowOrigin = allowedOrigins.includes(origin) ? origin : allowedOrigins[0];\n  \n  return {\n    'Access-Control-Allow-Origin': allowOrigin,\n    'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE',  // Specific methods\n    'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n    'Access-Control-Allow-Credentials': 'true',\n    'Access-Control-Max-Age': '86400',\n  };\n}\n\nexport default {\n  async fetch(request: Request, env: Env) {\n    const origin = request.headers.get('Origin') || '';\n    \n    // Verify authentication\n    const authHeader = request.headers.get('Authorization');\n    if (!authHeader || !isValidAuth(authHeader)) {\n      return new Response('Unauthorized', { status: 401 });\n    }\n    \n    return new Response('Sensitive data', {\n      headers: getSecureCorsHeaders(origin)\n    });\n  }\n}\n```\n\n### Fixing Missing OPTIONS Handler\n```typescript\n// âŒ Critical: No OPTIONS handling (preflight fails)\nexport default {\n  async fetch(request: Request, env: Env) {\n    if (request.method === 'POST') {\n      // Handle POST request\n      return new Response('POST handled');\n    }\n    \n    return new Response('Method not allowed', { status: 405 });\n  }\n}\n\n// âœ… Correct: Proper OPTIONS handling\nexport default {\n  async fetch(request: Request, env: Env) {\n    const origin = request.headers.get('Origin') || '';\n    \n    // Handle preflight requests\n    if (request.method === 'OPTIONS') {\n      return new Response(null, {\n        headers: {\n          'Access-Control-Allow-Origin': origin,\n          'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n          'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n          'Access-Control-Max-Age': '86400',\n        }\n      });\n    }\n    \n    if (request.method === 'POST') {\n      return new Response('POST handled', {\n        headers: {\n          'Access-Control-Allow-Origin': origin,\n        }\n      });\n    }\n    \n    return new Response('Method not allowed', { status: 405 });\n  }\n}\n```\n\n### Fixing Dynamic CORS for Different Environments\n```typescript\n// âŒ Medium: Hardcoded origins (not flexible)\nfunction getCorsHeaders() {\n  return {\n    'Access-Control-Allow-Origin': 'https://app.example.com',  // Hardcoded\n    'Access-Control-Allow-Methods': 'GET, POST',\n  };\n}\n\n// âœ… Correct: Configurable and secure CORS\nfunction getCorsHeaders(origin: string, env: Env) {\n  // Get allowed origins from environment\n  const allowedOrigins = (env.ALLOWED_ORIGINS || 'https://app.example.com')\n    .split(',')\n    .map(o => o.trim());\n  \n  const allowOrigin = allowedOrigins.includes(origin) ? origin : allowedOrigins[0];\n  \n  return {\n    'Access-Control-Allow-Origin': allowOrigin,\n    'Access-Control-Allow-Methods': env.ALLOWED_METHODS || 'GET, POST, PUT, DELETE',\n    'Access-Control-Allow-Headers': env.ALLOWED_HEADERS || 'Content-Type, Authorization',\n    'Access-Control-Max-Age': '86400',\n  };\n}\n\nexport default {\n  async fetch(request: Request, env: Env) {\n    const origin = request.headers.get('Origin') || '';\n    \n    if (request.method === 'OPTIONS') {\n      return new Response(null, { headers: getCorsHeaders(origin, env) });\n    }\n    \n    return new Response('Response', {\n      headers: getCorsHeaders(origin, env)\n    });\n  }\n}\n```\n\n## CORS Header Reference\n\n### Essential Headers\n```typescript\n{\n  'Access-Control-Allow-Origin': 'https://example.com',  // Required\n  'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',  // Required for preflight\n  'Access-Control-Allow-Headers': 'Content-Type, Authorization',  // Required for preflight\n}\n```\n\n### Optional but Recommended Headers\n```typescript\n{\n  'Access-Control-Max-Age': '86400',  // Cache preflight for 24 hours\n  'Access-Control-Allow-Credentials': 'true',  // For cookies/auth\n  'Vary': 'Origin',  // Important for caching with multiple origins\n}\n```\n\n### Security Considerations\n```typescript\n// âŒ Don't do this for authenticated APIs:\n{\n  'Access-Control-Allow-Origin': '*',\n  'Access-Control-Allow-Credentials': 'true'\n}\n\n// âœ… Do this instead:\n{\n  'Access-Control-Allow-Origin': 'https://app.example.com',  // Specific origin\n  'Access-Control-Allow-Credentials': 'true'\n}\n```\n\n## MCP Server Integration\n\nWhen Cloudflare MCP server is available:\n- Query latest CORS best practices and security recommendations\n- Get current browser CORS specification updates\n- Check for common CORS vulnerabilities and mitigations\n\n## Benefits\n\n### Immediate Impact\n- **Prevents CORS Errors**: Catches missing headers before deployment\n- **Improves Security**: Prevents overly permissive CORS configurations\n- **Better User Experience**: Ensures cross-origin requests work properly\n\n### Long-term Value\n- **Consistent CORS Standards**: Ensures all APIs follow proper CORS patterns\n- **Reduced Debugging Time**: Immediate feedback on CORS issues\n- **Security Compliance**: Prevents CORS-related security vulnerabilities\n\n## Usage Examples\n\n### During Response Creation\n```typescript\n// Developer types: new Response(data)\n// SKILL immediately activates: \"âš ï¸ HIGH: Response missing CORS headers. Cross-origin requests will be blocked by browsers.\"\n```\n\n### During API Development\n```typescript\n// Developer types: 'Access-Control-Allow-Origin': '*'\n// SKILL immediately activates: \"âš ï¸ HIGH: Overly permissive CORS with wildcard origin. Consider specific origins for security.\"\n```\n\n### During Method Handling\n```typescript\n// Developer types: if (request.method === 'POST') { ... }\n// SKILL immediately activates: \"âš ï¸ HIGH: Missing OPTIONS handler for preflight requests. Add OPTIONS method handling.\"\n```\n\n## CORS Checklist\n\n### Required for Cross-Origin Requests\n- [ ] `Access-Control-Allow-Origin` header set\n- [ ] OPTIONS method handled for preflight requests\n- [ ] `Access-Control-Allow-Methods` header for preflight\n- [ ] `Access-Control-Allow-Headers` header for preflight\n\n### Security Best Practices\n- [ ] Origin validation (not wildcard for authenticated APIs)\n- [ ] Specific allowed methods (not wildcard)\n- [ ] Proper credentials handling\n- [ ] Environment-based origin configuration\n\n### Performance Optimization\n- [ ] `Access-Control-Max-Age` header set\n- [ ] `Vary: Origin` header for caching\n- [ ] Efficient preflight handling\n\nThis SKILL ensures CORS is configured correctly by providing immediate, autonomous validation of CORS patterns, preventing common cross-origin issues and security vulnerabilities."
              },
              {
                "name": "durable-objects-pattern-checker",
                "description": "Automatically validates Cloudflare Durable Objects usage patterns, ensuring correct state management, hibernation, and strong consistency practices",
                "path": "plugins/edge-stack/skills/durable-objects-pattern-checker/SKILL.md",
                "frontmatter": {
                  "name": "durable-objects-pattern-checker",
                  "description": "Automatically validates Cloudflare Durable Objects usage patterns, ensuring correct state management, hibernation, and strong consistency practices",
                  "triggers": [
                    "Durable Object imports",
                    "DO stub usage",
                    "state management patterns",
                    "DO ID generation"
                  ]
                },
                "content": "# Durable Objects Pattern Checker SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- Durable Object imports or exports are detected\n- DO stub creation and usage patterns\n- State management in Durable Objects\n- ID generation patterns (`idFromName`, `newUniqueId`)\n- Hibernation and lifecycle patterns\n- WebSocket or real-time features with DOs\n\n## Expertise Provided\n\n### Durable Objects Best Practices\n- **State Management**: Ensures proper state persistence and consistency\n- **ID Generation**: Validates correct ID patterns for different use cases\n- **Hibernation**: Checks for proper hibernation implementation\n- **Lifecycle Management**: Validates constructor, fetch, and alarm handling\n- **Strong Consistency**: Ensures DOs are used when strong consistency is needed\n- **Performance**: Identifies DO performance anti-patterns\n\n### Specific Checks Performed\n\n#### âŒ Durable Objects Anti-Patterns\n```typescript\n// These patterns trigger immediate alerts:\n// Using DOs for stateless operations\nexport default {\n  async fetch(request: Request, env: Env) {\n    const id = env.COUNTER.newUniqueId();  // New DO every request!\n    const stub = env.COUNTER.get(id);\n    return stub.fetch(request);  // Overkill for simple counter\n  }\n}\n\n// Missing hibernation for long-lived DOs\nexport class ChatRoom {\n  constructor(state, env) {\n    this.state = state;\n    // Missing this.state.storage.setAlarm() for hibernation\n  }\n}\n```\n\n#### âœ… Durable Objects Best Practices\n```typescript\n// These patterns are validated as correct:\n// Reuse DO instances for stateful coordination\nexport default {\n  async fetch(request: Request, env: Env) {\n    const ip = request.headers.get('CF-Connecting-IP');\n    const id = env.RATE_LIMITER.idFromName(ip);  // Reuse same DO\n    const stub = env.RATE_LIMITER.get(id);\n    return stub.fetch(request);\n  }\n}\n\n// Proper hibernation implementation\nexport class ChatRoom {\n  constructor(state, env) {\n    this.state = state;\n    this.env = env;\n    \n    // Set alarm for hibernation after inactivity\n    this.state.storage.setAlarm(Date.now() + 30000); // 30 seconds\n  }\n  \n  alarm() {\n    // DO will hibernate after alarm\n  }\n}\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **cloudflare-architecture-strategist agent**: Handles complex DO architecture, SKILL provides immediate pattern validation\n- **edge-performance-oracle agent**: Handles DO performance analysis, SKILL ensures correct usage patterns\n- **workers-binding-validator SKILL**: Ensures DO bindings are correct, SKILL validates usage patterns\n\n### Escalation Triggers\n- Complex DO architecture questions â†’ `cloudflare-architecture-strategist` agent\n- DO performance troubleshooting â†’ `edge-performance-oracle` agent\n- DO migration strategies â†’ `cloudflare-architecture-strategist` agent\n\n## Validation Rules\n\n### P1 - Critical (Will Cause Issues)\n- **New Unique ID Per Request**: Creating new DO for every request\n- **Missing Hibernation**: Long-lived DOs without hibernation\n- **State Leaks**: State not properly persisted to storage\n- **Blocking Operations**: Synchronous operations in DO fetch\n\n### P2 - High (Performance/Correctness Issues)\n- **Wrong ID Pattern**: Using `newUniqueId` when `idFromName` is appropriate\n- **Stateless DOs**: Using DOs for operations that don't need state\n- **Missing Error Handling**: DO operations without proper error handling\n- **Alarm Misuse**: Incorrect alarm patterns for hibernation\n\n### P3 - Medium (Best Practices)\n- **State Size**: Large state objects that impact performance\n- **Concurrency**: Missing concurrency control for shared state\n- **Cleanup**: Missing cleanup in DO lifecycle\n\n## Remediation Examples\n\n### Fixing New Unique ID Per Request\n```typescript\n// âŒ Critical: New DO for every request (expensive and wrong)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const userId = getUserId(request);\n    \n    // Creates new DO instance for every request!\n    const id = env.USER_SESSION.newUniqueId();\n    const stub = env.USER_SESSION.get(id);\n    \n    return stub.fetch(request);\n  }\n}\n\n// âœ… Correct: Reuse DO for same entity\nexport default {\n  async fetch(request: Request, env: Env) {\n    const userId = getUserId(request);\n    \n    // Reuse same DO for this user\n    const id = env.USER_SESSION.idFromName(userId);\n    const stub = env.USER_SESSION.get(id);\n    \n    return stub.fetch(request);\n  }\n}\n```\n\n### Fixing Missing Hibernation\n```typescript\n// âŒ High: DO never hibernates (wastes resources)\nexport class ChatRoom {\n  constructor(state, env) {\n    this.state = state;\n    this.env = env;\n    this.messages = [];\n  }\n  \n  async fetch(request) {\n    // Handle chat messages...\n    // But never hibernates - stays in memory forever!\n  }\n}\n\n// âœ… Correct: Implement hibernation\nexport class ChatRoom {\n  constructor(state, env) {\n    this.state = state;\n    this.env = env;\n    \n    // Load persisted state\n    this.loadState();\n    \n    // Set alarm for hibernation after inactivity\n    this.resetHibernationTimer();\n  }\n  \n  async loadState() {\n    const messages = await this.state.storage.get('messages');\n    this.messages = messages || [];\n  }\n  \n  resetHibernationTimer() {\n    // Reset alarm for 30 seconds from now\n    this.state.storage.setAlarm(Date.now() + 30000);\n  }\n  \n  async fetch(request) {\n    // Reset timer on activity\n    this.resetHibernationTimer();\n    \n    // Handle chat messages...\n    return new Response('Message processed');\n  }\n  \n  async alarm() {\n    // Persist state before hibernation\n    await this.state.storage.put('messages', this.messages);\n    // DO will hibernate after this method returns\n  }\n}\n```\n\n### Fixing Wrong ID Pattern\n```typescript\n// âŒ High: Using newUniqueId for named resources\nexport default {\n  async fetch(request: Request, env: Env) {\n    const roomId = new URL(request.url).searchParams.get('room');\n    \n    // Wrong: Creates new DO for same room name\n    const id = env.CHAT_ROOM.newUniqueId();\n    const stub = env.CHAT_ROOM.get(id);\n    \n    return stub.fetch(request);\n  }\n}\n\n// âœ… Correct: Use idFromName for named resources\nexport default {\n  async fetch(request: Request, env: Env) {\n    const roomId = new URL(request.url).searchParams.get('room');\n    \n    // Correct: Same DO for same room name\n    const id = env.CHAT_ROOM.idFromName(roomId);\n    const stub = env.CHAT_ROOM.get(id);\n    \n    return stub.fetch(request);\n  }\n}\n```\n\n### Fixing State Persistence\n```typescript\n// âŒ Critical: State not persisted (lost on hibernation)\nexport class Counter {\n  constructor(state, env) {\n    this.state = state;\n    this.count = 0;  // Not persisted!\n  }\n  \n  async fetch(request) {\n    if (request.url.endsWith('/increment')) {\n      this.count++;  // Lost when DO hibernates!\n      return new Response(`Count: ${this.count}`);\n    }\n  }\n}\n\n// âœ… Correct: Persist state to storage\nexport class Counter {\n  constructor(state, env) {\n    this.state = state;\n  }\n  \n  async fetch(request) {\n    if (request.url.endsWith('/increment')) {\n      // Persist to storage\n      const currentCount = (await this.state.storage.get('count')) || 0;\n      const newCount = currentCount + 1;\n      await this.state.storage.put('count', newCount);\n      \n      return new Response(`Count: ${newCount}`);\n    }\n    \n    if (request.url.endsWith('/get')) {\n      const count = await this.state.storage.get('count') || 0;\n      return new Response(`Count: ${count}`);\n    }\n  }\n}\n```\n\n### Fixing Stateless DO Usage\n```typescript\n// âŒ High: Using DO for stateless operation (overkill)\nexport default {\n  async fetch(request: Request, env: Env) {\n    // Using DO for simple API call - unnecessary!\n    const id = env.API_PROXY.newUniqueId();\n    const stub = env.API_PROXY.get(id);\n    return stub.fetch(request);\n  }\n}\n\n// âœ… Correct: Handle stateless operations in Worker\nexport default {\n  async fetch(request: Request, env: Env) {\n    // Simple API call - handle directly in Worker\n    const response = await fetch('https://api.example.com/data');\n    return response;\n  }\n}\n\n// âœ… Correct: Use DO for actual stateful coordination\nexport default {\n  async fetch(request: Request, env: Env) {\n    const ip = request.headers.get('CF-Connecting-IP');\n    \n    // Rate limiting needs state - perfect for DO\n    const id = env.RATE_LIMITER.idFromName(ip);\n    const stub = env.RATE_LIMITER.get(id);\n    \n    return stub.fetch(request);\n  }\n}\n```\n\n## Durable Objects Use Cases\n\n### Use Durable Objects When:\n- **Strong Consistency** required (rate limiting, counters)\n- **Stateful Coordination** (chat rooms, game sessions)\n- **Real-time Features** (WebSockets, collaboration)\n- **Distributed Locks** (coordination between requests)\n- **Long-running Operations** (background processing)\n\n### Don't Use Durable Objects When:\n- **Stateless Operations** (simple API calls)\n- **Read-heavy Caching** (use KV instead)\n- **Large File Storage** (use R2 instead)\n- **Simple Key-Value** (use KV instead)\n\n## MCP Server Integration\n\nWhen Cloudflare MCP server is available:\n- Query DO performance metrics and best practices\n- Get latest hibernation patterns and techniques\n- Check DO usage limits and quotas\n- Analyze DO performance in production\n\n## Benefits\n\n### Immediate Impact\n- **Prevents Resource Waste**: Catches DO anti-patterns that waste resources\n- **Ensures Correctness**: Validates state persistence and consistency\n- **Improves Performance**: Identifies performance issues in DO usage\n\n### Long-term Value\n- **Consistent DO Patterns**: Ensures all DO usage follows best practices\n- **Better Resource Management**: Proper hibernation and lifecycle management\n- **Reduced Costs**: Efficient DO usage reduces resource consumption\n\n## Usage Examples\n\n### During DO Creation\n```typescript\n// Developer types: const id = env.MY_DO.newUniqueId();\n// SKILL immediately activates: \"âš ï¸ HIGH: Using newUniqueId for every request. Consider idFromName for named resources or if this should be stateless.\"\n```\n\n### During State Management\n```typescript\n// Developer types: this.count = 0; in constructor\n// SKILL immediately activates: \"âŒ CRITICAL: State not persisted to storage. Use this.state.storage.put() to persist data.\"\n```\n\n### During Hibernation\n```typescript\n// Developer types: DO without alarm() method\n// SKILL immediately activates: \"âš ï¸ HIGH: Durable Object missing hibernation. Add alarm() method and setAlarm() for resource efficiency.\"\n```\n\n## Performance Targets\n\n### DO Creation\n- **Excellent**: Reuse existing DOs (idFromName)\n- **Good**: Minimal new DO creation\n- **Acceptable**: Appropriate DO usage patterns\n- **Needs Improvement**: Creating new DOs per request\n\n### State Persistence\n- **Excellent**: All state persisted to storage\n- **Good**: Critical state persisted\n- **Acceptable**: Basic state management\n- **Needs Improvement**: State not persisted\n\n### Hibernation\n- **Excellent**: Proper hibernation implementation\n- **Good**: Basic hibernation setup\n- **Acceptable**: Some hibernation consideration\n- **Needs Improvement**: No hibernation (resource waste)\n\nThis SKILL ensures Durable Objects are used correctly by providing immediate, autonomous validation of DO patterns, preventing common mistakes and ensuring efficient state management."
              },
              {
                "name": "edge-performance-optimizer",
                "description": "Automatically optimizes Cloudflare Workers performance during development, focusing on cold starts, bundle size, edge caching, and global latency",
                "path": "plugins/edge-stack/skills/edge-performance-optimizer/SKILL.md",
                "frontmatter": {
                  "name": "edge-performance-optimizer",
                  "description": "Automatically optimizes Cloudflare Workers performance during development, focusing on cold starts, bundle size, edge caching, and global latency",
                  "triggers": [
                    "bundle size changes",
                    "fetch calls",
                    "storage operations",
                    "dependency additions",
                    "sequential operations"
                  ]
                },
                "content": "# Edge Performance Optimizer SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- New dependencies are added to package.json\n- Large files or heavy imports are detected\n- Sequential operations that could be parallelized\n- Missing edge caching opportunities\n- Bundle size increases significantly\n- Storage operations without optimization patterns\n\n## Expertise Provided\n\n### Edge-Specific Performance Optimization\n- **Cold Start Optimization**: Minimizes bundle size and heavy dependencies\n- **Global Distribution**: Ensures edge caching for global performance\n- **CPU Time Optimization**: Identifies CPU-intensive operations\n- **Storage Performance**: Optimizes KV/R2/D1 access patterns\n- **Parallel Operations**: Suggests parallelization opportunities\n- **Bundle Analysis**: Monitors and optimizes bundle size\n\n### Specific Checks Performed\n\n#### âŒ Performance Anti-Patterns\n```typescript\n// These patterns trigger immediate alerts:\nimport axios from 'axios';              // Heavy dependency (13KB)\nimport moment from 'moment';             // Heavy dependency (68KB)\nimport _ from 'lodash';                 // Heavy dependency (71KB)\n\n// Sequential operations that could be parallel\nconst user = await env.USERS.get(id);\nconst settings = await env.SETTINGS.get(id);\nconst prefs = await env.PREFS.get(id);\n```\n\n#### âœ… Performance Best Practices\n```typescript\n// These patterns are validated as correct:\n// Native Web APIs instead of heavy libraries\nconst response = await fetch(url);      // Built-in fetch (0KB)\nconst now = new Date();                // Native Date (0KB)\n\n// Parallel operations\nconst [user, settings, prefs] = await Promise.all([\n  env.USERS.get(id),\n  env.SETTINGS.get(id),\n  env.PREFS.get(id),\n]);\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **edge-performance-oracle agent**: Handles comprehensive performance analysis, SKILL provides immediate optimization\n- **workers-runtime-validator SKILL**: Complements runtime checks with performance optimization\n- **es-deploy command**: SKILL ensures performance standards before deployment\n\n### Escalation Triggers\n- Complex performance architecture questions â†’ `edge-performance-oracle` agent\n- Global distribution strategy â†’ `cloudflare-architecture-strategist` agent\n- Performance troubleshooting â†’ `edge-performance-oracle` agent\n\n## Validation Rules\n\n### P1 - Critical (Performance Killer)\n- **Large Dependencies**: Heavy libraries like moment, lodash, axios\n- **Bundle Size**: Over 200KB (kills cold start performance)\n- **Sequential Operations**: Multiple sequential storage/network calls\n- **Missing Edge Caching**: No caching for frequently accessed data\n\n### P2 - High (Performance Impact)\n- **Bundle Size**: Over 100KB (slows cold starts)\n- **CPU Time**: Operations approaching 50ms limit\n- **Lazy Loading**: Dynamic imports that hurt cold start\n- **Large Payloads**: Responses over 100KB without streaming\n\n### P3 - Medium (Optimization Opportunity)\n- **Bundle Size**: Over 50KB (could be optimized)\n- **Missing Parallelization**: Operations that could be parallel\n- **No Request Caching**: Repeated expensive operations\n\n## Remediation Examples\n\n### Fixing Heavy Dependencies\n```typescript\n// âŒ Critical: Heavy dependencies (150KB+ bundle)\nimport axios from 'axios';              // 13KB\nimport moment from 'moment';             // 68KB  \nimport _ from 'lodash';                 // 71KB\n// Total: 152KB just for utilities!\n\n// âœ… Correct: Native Web APIs (minimal bundle)\n// Use fetch instead of axios\nconst response = await fetch(url);\nconst data = await response.json();\n\n// Use native Date instead of moment\nconst now = new Date();\nconst tomorrow = new Date(Date.now() + 86400000);\n\n// Use native methods instead of lodash\nconst unique = [...new Set(array)];\nconst grouped = array.reduce((acc, item) => {\n  const key = item.category;\n  if (!acc[key]) acc[key] = [];\n  acc[key].push(item);\n  return acc;\n}, {});\n// Total: < 5KB for utilities\n```\n\n### Fixing Sequential Operations\n```typescript\n// âŒ High: Sequential KV operations (3x network round-trips)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const user = await env.USERS.get(userId);      // 10-30ms\n    const settings = await env.SETTINGS.get(id);    // 10-30ms  \n    const prefs = await env.PREFS.get(id);         // 10-30ms\n    // Total: 30-90ms just for storage!\n  }\n}\n\n// âœ… Correct: Parallel operations (single round-trip)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const [user, settings, prefs] = await Promise.all([\n      env.USERS.get(userId),\n      env.SETTINGS.get(id),\n      env.PREFS.get(id),\n    ]);\n    // Total: 10-30ms (single round-trip)\n  }\n}\n```\n\n### Fixing Missing Edge Caching\n```typescript\n// âŒ Critical: No edge caching (slow globally)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const config = await fetch('https://api.example.com/config');\n    // Every request goes to origin!\n    // Sydney user â†’ US origin = 200ms+ just for config\n  }\n}\n\n// âœ… Correct: Edge caching pattern\nexport default {\n  async fetch(request: Request, env: Env) {\n    const cache = caches.default;\n    const cacheKey = new Request('https://example.com/config', {\n      method: 'GET'\n    });\n\n    // Try cache first\n    let response = await cache.match(cacheKey);\n\n    if (!response) {\n      // Cache miss - fetch from origin\n      response = await fetch('https://api.example.com/config');\n      \n      // Cache at edge with 1-hour TTL\n      response = new Response(response.body, {\n        ...response,\n        headers: {\n          ...response.headers,\n          'Cache-Control': 'public, max-age=3600',\n        }\n      });\n      \n      await cache.put(cacheKey, response.clone());\n    }\n\n    // Sydney user â†’ Sydney edge cache = < 10ms\n    return response;\n  }\n}\n```\n\n### Fixing CPU Time Issues\n```typescript\n// âŒ High: Large synchronous processing (CPU time bomb)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const users = await env.DB.prepare('SELECT * FROM users').all();\n    // If 10,000 users, this loops for 100ms+ CPU time\n    const enriched = users.results.map(user => {\n      return {\n        ...user,\n        fullName: `${user.firstName} ${user.lastName}`,\n        // ... expensive computations\n      };\n    });\n  }\n}\n\n// âœ… Correct: Bounded operations\nexport default {\n  async fetch(request: Request, env: Env) {\n    // Option 1: Limit at database level\n    const users = await env.DB.prepare(\n      'SELECT * FROM users LIMIT ? OFFSET ?'\n    ).bind(10, offset).all();  // Only 10 users, bounded CPU\n\n    // Option 2: Stream processing for large datasets\n    const { readable, writable } = new TransformStream();\n    // Process in chunks without loading everything into memory\n\n    // Option 3: Offload to Durable Object\n    const id = env.PROCESSOR.newUniqueId();\n    const stub = env.PROCESSOR.get(id);\n    return stub.fetch(request);  // DO can run longer\n  }\n}\n```\n\n## MCP Server Integration\n\nWhen Cloudflare MCP server is available:\n- Query real performance metrics (cold start times, CPU usage)\n- Analyze global latency by region\n- Get latest performance optimization techniques\n- Check bundle size impact on cold starts\n\n## Benefits\n\n### Immediate Impact\n- **Faster Cold Starts**: Reduces bundle size and heavy dependencies\n- **Better Global Performance**: Ensures edge caching for worldwide users\n- **Lower CPU Usage**: Identifies and optimizes CPU-intensive operations\n- **Reduced Latency**: Parallelizes operations and adds caching\n\n### Long-term Value\n- **Consistent Performance Standards**: Ensures all code meets performance targets\n- **Better User Experience**: Faster response times globally\n- **Cost Optimization**: Reduced CPU time usage lowers costs\n\n## Usage Examples\n\n### During Dependency Addition\n```typescript\n// Developer types: npm install moment\n// SKILL immediately activates: \"âŒ CRITICAL: moment is 68KB and will slow cold starts. Use native Date instead for 0KB impact.\"\n```\n\n### During Storage Operations\n```typescript\n// Developer types: sequential KV gets\n// SKILL immediately activates: \"âš ï¸ HIGH: Sequential KV operations detected. Use Promise.all() to parallelize and reduce latency by 3x.\"\n```\n\n### During API Development\n```typescript\n// Developer types: fetch without caching\n// SKILL immediately activates: \"âš ï¸ HIGH: No edge caching for API call. Add Cache API to serve from edge locations globally.\"\n```\n\n## Performance Targets\n\n### Bundle Size\n- **Excellent**: < 10KB\n- **Good**: < 50KB  \n- **Acceptable**: < 100KB\n- **Needs Improvement**: > 100KB\n- **Action Required**: > 200KB\n\n### Cold Start Time\n- **Excellent**: < 3ms\n- **Good**: < 5ms\n- **Acceptable**: < 10ms\n- **Needs Improvement**: > 10ms\n- **Action Required**: > 20ms\n\n### Global Latency (P95)\n- **Excellent**: < 100ms\n- **Good**: < 200ms\n- **Acceptable**: < 500ms\n- **Needs Improvement**: > 500ms\n- **Action Required**: > 1000ms\n\nThis SKILL ensures Workers performance by providing immediate, autonomous optimization of performance patterns, preventing common performance issues and ensuring fast global response times."
              },
              {
                "name": "gemini-imagegen",
                "description": "Generate, edit, and compose images using Google's Gemini AI API for design workflows and visual content creation",
                "path": "plugins/edge-stack/skills/gemini-imagegen/SKILL.md",
                "frontmatter": {
                  "name": "gemini-imagegen",
                  "description": "Generate, edit, and compose images using Google's Gemini AI API for design workflows and visual content creation",
                  "triggers": [
                    "image generation",
                    "visual content",
                    "AI art",
                    "image editing",
                    "design automation"
                  ]
                },
                "content": "# Gemini ImageGen SKILL\n\n## Overview\n\nThis skill provides image generation and manipulation capabilities using Google's Gemini AI API. It's designed for local development workflows where you need to create or modify images using AI assistance.\n\n## Features\n\n- **Generate Images**: Create images from text descriptions\n- **Edit Images**: Modify existing images based on text prompts\n- **Compose Images**: Combine multiple images with layout instructions\n- **Multiple Formats**: Support for PNG, JPEG, and other common image formats\n- **Size Options**: Flexible output dimensions for different use cases\n\n## Environment Setup\n\nThis skill requires a Gemini API key:\n\n```bash\nexport GEMINI_API_KEY=\"your-api-key-here\"\n```\n\nGet your API key from: https://makersuite.google.com/app/apikey\n\n## Available Scripts\n\n### 1. Generate Image (`scripts/generate-image.ts`)\n\nCreate new images from text descriptions.\n\n**Usage:**\n```bash\nnpx tsx scripts/generate-image.ts <prompt> <output-path> [options]\n```\n\n**Arguments:**\n- `prompt`: Text description of the image to generate\n- `output-path`: Where to save the generated image (e.g., `./output.png`)\n\n**Options:**\n- `--width <number>`: Image width in pixels (default: 1024)\n- `--height <number>`: Image height in pixels (default: 1024)\n- `--model <string>`: Gemini model to use (default: 'gemini-2.0-flash-exp')\n\n**Examples:**\n```bash\n# Basic usage\nGEMINI_API_KEY=xxx npx tsx scripts/generate-image.ts \"a sunset over mountains\" output.png\n\n# Custom size\nnpx tsx scripts/generate-image.ts \"modern office workspace\" office.png --width 1920 --height 1080\n\n# Using npm script\nnpm run generate \"futuristic city skyline\" city.png\n```\n\n### 2. Edit Image (`scripts/edit-image.ts`)\n\nModify existing images based on text instructions.\n\n**Usage:**\n```bash\nnpx tsx scripts/edit-image.ts <source-image> <prompt> <output-path> [options]\n```\n\n**Arguments:**\n- `source-image`: Path to the image to edit\n- `prompt`: Text description of the desired changes\n- `output-path`: Where to save the edited image\n\n**Options:**\n- `--model <string>`: Gemini model to use (default: 'gemini-2.0-flash-exp')\n\n**Examples:**\n```bash\n# Basic editing\nGEMINI_API_KEY=xxx npx tsx scripts/edit-image.ts photo.jpg \"add a blue sky\" edited.jpg\n\n# Style transfer\nnpx tsx scripts/edit-image.ts portrait.png \"make it look like a watercolor painting\" artistic.png\n\n# Using npm script\nnpm run edit photo.jpg \"remove background\" no-bg.png\n```\n\n### 3. Compose Images (`scripts/compose-images.ts`)\n\nCombine multiple images into a single composition.\n\n**Usage:**\n```bash\nnpx tsx scripts/compose-images.ts <output-path> <image1> <image2> [image3...] [options]\n```\n\n**Arguments:**\n- `output-path`: Where to save the composed image\n- `image1, image2, ...`: Paths to images to combine (2-4 images)\n\n**Options:**\n- `--layout <string>`: Layout pattern (horizontal, vertical, grid, custom) (default: 'grid')\n- `--prompt <string>`: Additional instructions for composition\n- `--width <number>`: Output width in pixels (default: auto)\n- `--height <number>`: Output height in pixels (default: auto)\n\n**Examples:**\n```bash\n# Grid layout\nGEMINI_API_KEY=xxx npx tsx scripts/compose-images.ts collage.png img1.jpg img2.jpg img3.jpg img4.jpg\n\n# Horizontal layout\nnpx tsx scripts/compose-images.ts banner.png left.png right.png --layout horizontal\n\n# Custom composition with prompt\nnpx tsx scripts/compose-images.ts result.png a.jpg b.jpg --prompt \"blend seamlessly with gradient transition\"\n\n# Using npm script\nnpm run compose output.png photo1.jpg photo2.jpg photo3.jpg --layout vertical\n```\n\n## NPM Scripts\n\nThe package.json includes convenient npm scripts:\n\n```bash\nnpm run generate <prompt> <output>     # Generate image from prompt\nnpm run edit <source> <prompt> <output> # Edit existing image\nnpm run compose <output> <images...>    # Compose multiple images\n```\n\n## Installation\n\nFrom the skill directory:\n\n```bash\nnpm install\n```\n\nThis installs:\n- `@google/generative-ai`: Google's Gemini API SDK\n- `tsx`: TypeScript execution runtime\n- `typescript`: TypeScript compiler\n\n## Usage in Design Workflows\n\n### Creating Marketing Assets\n```bash\n# Generate hero image\nnpm run generate \"modern tech startup hero image, clean, professional\" hero.png --width 1920 --height 1080\n\n# Create variations\nnpm run edit hero.png \"change color scheme to blue and green\" hero-variant.png\n\n# Compose for social media\nnpm run compose social-post.png hero.png logo.png --layout horizontal\n```\n\n### Rapid Prototyping\n```bash\n# Generate UI mockup\nnpm run generate \"mobile app login screen, minimalist design\" mockup.png --width 375 --height 812\n\n# Iterate on design\nnpm run edit mockup.png \"add a gradient background\" mockup-v2.png\n```\n\n### Content Creation\n```bash\n# Generate illustrations\nnpm run generate \"technical diagram of cloud architecture\" diagram.png\n\n# Create composite images\nnpm run compose infographic.png chart1.png chart2.png diagram.png --layout vertical\n```\n\n## Technical Details\n\n### Image Generation\n- Uses Gemini's imagen-3.0-generate-001 model\n- Supports text-to-image generation\n- Configurable output dimensions\n- Automatic format detection from file extension\n\n### Image Editing\n- Uses Gemini's vision capabilities\n- Applies transformations based on natural language\n- Preserves original image quality where possible\n- Supports various editing operations (style, objects, colors, etc.)\n\n### Image Composition\n- Intelligent layout algorithms\n- Automatic sizing and spacing\n- Seamless blending options\n- Support for multiple composition patterns\n\n## Error Handling\n\nCommon errors and solutions:\n\n1. **Missing API Key**: Ensure `GEMINI_API_KEY` environment variable is set\n2. **Invalid Image Format**: Use supported formats (PNG, JPEG, WebP)\n3. **File Not Found**: Verify source image paths are correct\n4. **API Rate Limits**: Implement delays between requests if needed\n5. **Large File Sizes**: Compress images before editing/composing\n\n## Limitations\n\n- API rate limits apply based on your Gemini API tier\n- Generated images are subject to Gemini's content policies\n- Maximum image dimensions depend on the model used\n- Processing time varies based on complexity and size\n\n## Integration with Claude Code\n\nThis skill runs locally and can be used during development:\n\n1. **Design System Creation**: Generate component mockups and visual assets\n2. **Documentation**: Create diagrams and illustrations for docs\n3. **Testing**: Generate test images for visual regression testing\n4. **Prototyping**: Rapid iteration on visual concepts\n\n## See Also\n\n- [Google Gemini API Documentation](https://ai.google.dev/docs)\n- [Gemini Image Generation Guide](https://ai.google.dev/docs/imagen)\n- Edge Stack Plugin for deployment workflows"
              },
              {
                "name": "kv-optimization-advisor",
                "description": "Automatically optimizes Cloudflare KV storage patterns, suggesting parallel operations, caching strategies, and storage choice guidance",
                "path": "plugins/edge-stack/skills/kv-optimization-advisor/SKILL.md",
                "frontmatter": {
                  "name": "kv-optimization-advisor",
                  "description": "Automatically optimizes Cloudflare KV storage patterns, suggesting parallel operations, caching strategies, and storage choice guidance",
                  "triggers": [
                    "KV operations",
                    "storage access patterns",
                    "sequential storage calls",
                    "large data patterns"
                  ]
                },
                "content": "# KV Optimization Advisor SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- KV `get`, `put`, `delete`, or `list` operations are detected\n- Sequential storage operations that could be parallelized\n- Large data patterns that might exceed KV limits\n- Missing caching opportunities for repeated KV calls\n- Storage choice patterns (KV vs R2 vs D1)\n\n## Expertise Provided\n\n### KV Performance Optimization\n- **Parallel Operations**: Identifies sequential KV calls that can be parallelized\n- **Request-Scoped Caching**: Suggests in-memory caching during request processing\n- **Storage Choice Guidance**: Recommends KV vs R2 vs D1 based on use case\n- **Value Size Optimization**: Monitors for large values that impact performance\n- **Batch Operations**: Suggests batch operations when appropriate\n- **TTL Optimization**: Recommends optimal TTL strategies\n\n### Specific Checks Performed\n\n#### âŒ KV Performance Anti-Patterns\n```typescript\n// These patterns trigger immediate alerts:\n// Sequential KV operations (multiple network round-trips)\nconst user = await env.USERS.get(id);      // 10-30ms\nconst settings = await env.SETTINGS.get(id); // 10-30ms\nconst prefs = await env.PREFS.get(id);     // 10-30ms\n// Total: 30-90ms just for storage!\n\n// Repeated KV calls in same request\nconst user1 = await env.USERS.get(id);\nconst user2 = await env.USERS.get(id);     // Same data fetched twice!\n```\n\n#### âœ… KV Performance Best Practices\n```typescript\n// These patterns are validated as correct:\n// Parallel KV operations (single network round-trip)\nconst [user, settings, prefs] = await Promise.all([\n  env.USERS.get(id),\n  env.SETTINGS.get(id),\n  env.PREFS.get(id),\n]);\n// Total: 10-30ms (single round-trip)\n\n// Request-scoped caching\nconst cache = new Map();\nasync function getCached(key: string, env: Env) {\n  if (cache.has(key)) return cache.get(key);\n  const value = await env.USERS.get(key);\n  cache.set(key, value);\n  return value;\n}\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **edge-performance-oracle agent**: Handles comprehensive performance analysis, SKILL provides immediate KV optimization\n- **cloudflare-architecture-strategist agent**: Handles storage architecture decisions, SKILL provides immediate optimization\n- **workers-binding-validator SKILL**: Ensures KV bindings are correct, SKILL optimizes usage patterns\n\n### Escalation Triggers\n- Complex storage architecture questions â†’ `cloudflare-architecture-strategist` agent\n- KV performance troubleshooting â†’ `edge-performance-oracle` agent\n- Storage migration strategies â†’ `cloudflare-architecture-strategist` agent\n\n## Validation Rules\n\n### P1 - Critical (Performance Killer)\n- **Sequential Operations**: Multiple sequential KV calls that could be parallelized\n- **Repeated Calls**: Same KV key fetched multiple times in one request\n- **Large Values**: Values approaching 25MB KV limit\n\n### P2 - High (Performance Impact)\n- **Missing Caching**: Repeated expensive KV operations without caching\n- **Wrong Storage Choice**: Using KV for data that should be in R2 or D1\n- **No TTL Strategy**: Missing or inappropriate TTL configuration\n\n### P3 - Medium (Optimization Opportunity)\n- **Batch Opportunities**: Multiple operations that could be batched\n- **Suboptimal TTL**: TTL values that are too short or too long\n- **Missing Error Handling**: KV operations without proper error handling\n\n## Remediation Examples\n\n### Fixing Sequential Operations\n```typescript\n// âŒ Critical: Sequential KV operations (3x network round-trips)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const userId = getUserId(request);\n    \n    const user = await env.USERS.get(userId);      // 10-30ms\n    const settings = await env.SETTINGS.get(userId); // 10-30ms\n    const prefs = await env.PREFS.get(userId);     // 10-30ms\n    \n    // Total: 30-90ms just for storage!\n    return new Response(JSON.stringify({ user, settings, prefs }));\n  }\n}\n\n// âœ… Correct: Parallel operations (single round-trip)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const userId = getUserId(request);\n    \n    // Fetch in parallel - single network round-trip time\n    const [user, settings, prefs] = await Promise.all([\n      env.USERS.get(userId),\n      env.SETTINGS.get(userId),\n      env.PREFS.get(userId),\n    ]);\n    \n    // Total: 10-30ms (single round-trip)\n    return new Response(JSON.stringify({ user, settings, prefs }));\n  }\n}\n```\n\n### Fixing Repeated Calls with Caching\n```typescript\n// âŒ High: Same KV data fetched multiple times\nexport default {\n  async fetch(request: Request, env: Env) {\n    const userId = getUserId(request);\n    \n    // Fetch user data multiple times unnecessarily\n    const user1 = await env.USERS.get(userId);\n    const user2 = await env.USERS.get(userId);  // Duplicate call!\n    const user3 = await env.USERS.get(userId);  // Duplicate call!\n    \n    // Process user data...\n    return new Response('Processed');\n  }\n}\n\n// âœ… Correct: Request-scoped caching\nexport default {\n  async fetch(request: Request, env: Env) {\n    const userId = getUserId(request);\n    \n    // Request-scoped cache to avoid duplicate KV calls\n    const cache = new Map();\n    \n    async function getCachedUser(id: string) {\n      if (cache.has(id)) return cache.get(id);\n      const user = await env.USERS.get(id);\n      cache.set(id, user);\n      return user;\n    }\n    \n    const user1 = await getCachedUser(userId);  // KV call\n    const user2 = await getCachedUser(userId);  // From cache\n    const user3 = await getCachedUser(userId);  // From cache\n    \n    // Process user data...\n    return new Response('Processed');\n  }\n}\n```\n\n### Fixing Storage Choice\n```typescript\n// âŒ High: Using KV for large files (wrong storage choice)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const fileId = new URL(request.url).searchParams.get('id');\n    \n    // KV is for small key-value data, not large files!\n    const fileData = await env.FILES.get(fileId);  // Could be 10MB+\n    \n    return new Response(fileData);\n  }\n}\n\n// âœ… Correct: Use R2 for large files\nexport default {\n  async fetch(request: Request, env: Env) {\n    const fileId = new URL(request.url).searchParams.get('id');\n    \n    // R2 is designed for large objects/files\n    const object = await env.FILES_BUCKET.get(fileId);\n    \n    if (!object) {\n      return new Response('Not found', { status: 404 });\n    }\n    \n    return new Response(object.body);\n  }\n}\n```\n\n### Fixing TTL Strategy\n```typescript\n// âŒ Medium: No TTL strategy (data never expires)\nexport default {\n  async fetch(request: Request, env: Env) {\n    const cacheKey = `data:${Date.now()}`;\n    \n    // Data cached forever - may become stale\n    await env.CACHE.put(cacheKey, data);\n  }\n}\n\n// âœ… Correct: Appropriate TTL strategy\nexport default {\n  async fetch(request: Request, env: Env) {\n    const cacheKey = 'user:profile:123';\n    \n    // Cache user profile for 1 hour (reasonable for user data)\n    await env.CACHE.put(cacheKey, data, {\n      expirationTtl: 3600  // 1 hour\n    });\n    \n    // Cache API response for 5 minutes (frequently changing)\n    await env.API_CACHE.put(apiKey, response, {\n      expirationTtl: 300  // 5 minutes\n    });\n    \n    // Cache static data for 24 hours (rarely changes)\n    await env.STATIC_CACHE.put(staticKey, data, {\n      expirationTtl: 86400  // 24 hours\n    });\n  }\n}\n```\n\n### Fixing Large Value Handling\n```typescript\n// âŒ High: Large values approaching KV limits\nexport default {\n  async fetch(request: Request, env: Env) {\n    const reportId = new URL(request.url).searchParams.get('id');\n    \n    // Large report (20MB) - close to KV 25MB limit!\n    const report = await env.REPORTS.get(reportId);\n    \n    return new Response(report);\n  }\n}\n\n// âœ… Correct: Compress large values or use R2\nexport default {\n  async fetch(request: Request, env: Env) {\n    const reportId = new URL(request.url).searchParams.get('id');\n    \n    // Option 1: Compress before storing in KV\n    const compressed = await env.REPORTS.get(reportId);\n    const decompressed = decompress(compressed);\n    \n    // Option 2: Use R2 for large objects\n    const object = await env.REPORTS_BUCKET.get(reportId);\n    \n    return new Response(object.body);\n  }\n}\n```\n\n## Storage Choice Guidance\n\n### Use KV When:\n- **Small values** (< 1MB typical, < 25MB max)\n- **Key-value access patterns**\n- **Eventually consistent** data is acceptable\n- **Low latency** reads required globally\n- **Simple caching** needs\n\n### Use R2 When:\n- **Large objects** (files, images, videos)\n- **S3-compatible** access needed\n- **Strong consistency** required\n- **Object storage** patterns\n- **Large files** (> 1MB)\n\n### Use D1 When:\n- **Relational data** with complex queries\n- **Strong consistency** required\n- **SQL operations** needed\n- **Structured data** with relationships\n- **Complex queries** and joins\n\n## MCP Server Integration\n\nWhen Cloudflare MCP server is available:\n- Query KV performance metrics (latency, hit rates)\n- Analyze storage usage patterns\n- Get latest KV optimization techniques\n- Check storage limits and quotas\n\n## Benefits\n\n### Immediate Impact\n- **Faster Response Times**: Parallel operations reduce latency by 3x or more\n- **Reduced KV Costs**: Fewer operations and better caching\n- **Better Performance**: Proper storage choice improves overall performance\n\n### Long-term Value\n- **Consistent Optimization**: Ensures all KV usage follows best practices\n- **Cost Efficiency**: Optimized storage patterns reduce costs\n- **Better User Experience**: Faster response times from optimized storage\n\n## Usage Examples\n\n### During KV Operation Writing\n```typescript\n// Developer types: sequential KV gets\n// SKILL immediately activates: \"âš ï¸ HIGH: Sequential KV operations detected. Use Promise.all() to parallelize and reduce latency by 3x.\"\n```\n\n### During Storage Architecture\n```typescript\n// Developer types: storing large files in KV\n// SKILL immediately activates: \"âš ï¸ HIGH: Large file storage in KV detected. Use R2 for objects > 1MB to avoid performance issues.\"\n```\n\n### During Caching Implementation\n```typescript\n// Developer types: repeated KV calls in same request\n// SKILL immediately activates: \"âš ï¸ HIGH: Duplicate KV calls detected. Add request-scoped caching to avoid redundant network calls.\"\n```\n\n## Performance Targets\n\n### KV Operation Latency\n- **Excellent**: < 10ms (parallel operations)\n- **Good**: < 30ms (single operation)\n- **Acceptable**: < 100ms (sequential operations)\n- **Needs Improvement**: > 100ms\n\n### Cache Hit Rate\n- **Excellent**: > 90%\n- **Good**: > 75%\n- **Acceptable**: > 50%\n- **Needs Improvement**: < 50%\n\nThis SKILL ensures KV storage performance by providing immediate, autonomous optimization of storage patterns, preventing common performance issues and ensuring efficient data access."
              },
              {
                "name": "polar-integration-validator",
                "description": "Autonomous validation of Polar.sh billing integration. Checks webhook endpoints, signature verification, subscription middleware, and environment configuration.",
                "path": "plugins/edge-stack/skills/polar-integration-validator/SKILL.md",
                "frontmatter": {
                  "name": "polar-integration-validator",
                  "description": "Autonomous validation of Polar.sh billing integration. Checks webhook endpoints, signature verification, subscription middleware, and environment configuration.",
                  "triggers": [
                    "webhook file changes",
                    "subscription code changes",
                    "wrangler.toml updates",
                    "billing-related modifications"
                  ]
                },
                "content": "# Polar Integration Validator SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- Files matching `**/webhooks/polar.*` are created/modified\n- Files containing \"subscription\" or \"polar\" in path are modified\n- `wrangler.toml` is updated\n- Environment variable files (`.dev.vars`, `.env`) are modified\n- Before deployment operations\n\n## Validation Rules\n\n### P1 - Critical (Block Operations)\n\n**Webhook Endpoint**:\n- âœ… Webhook handler exists (`server/api/webhooks/polar.ts` or similar)\n- âœ… Signature verification implemented (`polar.webhooks.verify`)\n- âœ… All critical events handled: `checkout.completed`, `subscription.created`, `subscription.updated`, `subscription.canceled`\n\n**Environment Variables**:\n- âœ… `POLAR_ACCESS_TOKEN` configured (check `.dev.vars` or secrets)\n- âœ… `POLAR_WEBHOOK_SECRET` in wrangler.toml\n\n**Database**:\n- âœ… Users table has `polar_customer_id` column\n- âœ… Subscriptions table exists\n- âœ… Foreign key relationship configured\n\n### P2 - Important (Warn)\n\n**Event Handling**:\n- âš ï¸ `subscription.past_due` handler exists\n- âš ï¸ Database updates in all event handlers\n- âš ï¸ Error logging implemented\n\n**Subscription Middleware**:\n- âš ï¸ Subscription check function exists\n- âš ï¸ Used on protected routes\n- âš ï¸ Checks `subscription_status === 'active'`\n- âš ï¸ Checks `current_period_end` not expired\n\n### P3 - Suggestions (Inform)\n\n- â„¹ï¸ Webhook event logging to database\n- â„¹ï¸ Customer creation helper function\n- â„¹ï¸ Subscription status caching\n- â„¹ï¸ Rate limiting on webhook endpoint\n\n## Validation Output\n\n```\nðŸ” Polar.sh Integration Validation\n\nâœ… P1 Checks (Critical):\n   âœ… Webhook endpoint exists\n   âœ… Signature verification implemented\n   âœ… Environment variables configured\n   âœ… Database schema complete\n\nâš ï¸ P2 Checks (Important):\n   âš ï¸ Missing subscription.past_due handler\n   âœ… Subscription middleware exists\n   âœ… Protected routes check subscription\n\nâ„¹ï¸ P3 Suggestions:\n   â„¹ï¸ Consider adding webhook event logging\n   â„¹ï¸ Add rate limiting to webhook endpoint\n\nðŸ“‹ Summary: 1 warning found\nðŸ’¡ Run /es-billing-setup to fix issues\n```\n\n## Escalation\n\nComplex scenarios escalate to `polar-billing-specialist` agent:\n- Custom webhook processing logic\n- Multi-tenant subscription architecture\n- Usage-based billing implementation\n- Migration from other billing providers\n\n## Notes\n\n- Runs automatically on relevant file changes\n- Can block deployments with P1 issues\n- Queries Polar MCP for product validation\n- Integrates with `/validate` and `/es-deploy` commands"
              },
              {
                "name": "shadcn-ui-design-validator",
                "description": "Automatically validates frontend design patterns to prevent generic aesthetics (Inter fonts, purple gradients, minimal animations) and enforce distinctive, branded design during Tanstack Start (React) development with shadcn/ui",
                "path": "plugins/edge-stack/skills/shadcn-ui-design-validator/SKILL.md",
                "frontmatter": {
                  "name": "shadcn-ui-design-validator",
                  "description": "Automatically validates frontend design patterns to prevent generic aesthetics (Inter fonts, purple gradients, minimal animations) and enforce distinctive, branded design during Tanstack Start (React) development with shadcn/ui",
                  "triggers": [
                    "tsx file creation",
                    "component changes",
                    "tailwind config changes",
                    "shadcn component usage",
                    "design system updates"
                  ],
                  "note": "Updated for Tanstack Start + shadcn/ui. Validates React/TSX components with shadcn/ui patterns."
                },
                "content": "# shadcn/ui Design Validator SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- New `.tsx` React components are created\n- Tailwind configuration (`tailwind.config.ts`) is modified\n- Tanstack Start configuration (`app.config.ts`) is modified\n- Component styling or classes are changed\n- Design token definitions are updated\n- Before deployment commands are executed\n\n## Expertise Provided\n\n### Design Pattern Validation\n- **Generic Pattern Detection**: Identifies default/overused design patterns\n- **Typography Analysis**: Ensures distinctive font choices and hierarchy\n- **Animation Validation**: Checks for engaging micro-interactions and transitions\n- **Color System**: Validates distinctive color palettes vs generic defaults\n- **Component Customization**: Ensures shadcn/ui components are customized, not default\n\n### Specific Checks Performed\n\n#### âŒ Critical Violations (Generic Design Patterns)\n```tsx\n<!-- These patterns trigger alerts: -->\n\n<!-- Generic font (Inter/Roboto) -->\n<div className=\"font-sans\">  <!-- Using default Inter -->\n\n<!-- Purple gradient on white (overused pattern) -->\n<div className=\"bg-gradient-to-r from-purple-500 to-purple-600\">\n\n<!-- No animations/transitions -->\n<Button onClick=\"submit\">Submit</Button>  <!-- No hover state -->\n\n<!-- Default background colors -->\n<div className=\"bg-gray-50\">  <!-- Generic #f9fafb -->\n```\n\n#### âœ… Correct Distinctive Patterns\n```tsx\n<!-- These patterns are validated as correct: -->\n\n<!-- Custom distinctive fonts -->\n<h1 className=\"font-heading\">  <!-- Custom font family -->\n\n<!-- Custom brand colors -->\n<div className=\"bg-brand-coral\">  <!-- Distinctive palette -->\n\n<!-- Engaging animations -->\n<Button\n  className=\"transition-all duration-300 hover:scale-105 hover:shadow-xl\"\n  onClick=\"submit\"\n>\n  Submit\n</Button>\n\n<!-- Atmospheric backgrounds -->\n<div className=\"bg-gradient-to-br from-brand-ocean via-brand-sky to-brand-coral\">\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **frontend-design-specialist agent**: Handles deep design analysis, SKILL provides immediate validation\n- **tanstack-ui-architect agent**: Component expertise, SKILL validates implementation\n- **es-design-review command**: SKILL provides continuous validation between explicit reviews\n\n### Escalation Triggers\n- Complex design system questions â†’ `frontend-design-specialist` agent\n- Component customization help â†’ `tanstack-ui-architect` agent\n- Accessibility concerns â†’ `accessibility-guardian` agent\n- Full design review â†’ `/es-design-review` command\n\n## Validation Rules\n\n### P1 - Critical (Generic Patterns to Avoid)\n- **Default Fonts**: Inter, Roboto, Helvetica (in over 80% of sites)\n- **Purple Gradients**: `from-purple-*` to `to-purple-*` on white backgrounds\n- **Generic Grays**: `bg-gray-50`, `bg-gray-100` (overused neutrals)\n- **No Animations**: Interactive elements without hover/focus transitions\n- **Default Component Props**: Using shadcn/ui components with all default props\n\n### P2 - Important (Polish and Engagement)\n- **Missing Hover States**: Buttons/links without hover effects\n- **No Loading States**: Async actions without loading feedback\n- **Inconsistent Spacing**: Not using Tailwind spacing scale consistently\n- **No Micro-interactions**: Forms/buttons without feedback animations\n- **Weak Typography Hierarchy**: Similar font sizes for different heading levels\n\n### P3 - Best Practices\n- **Font Weight Variety**: Using only one or two font weights\n- **Limited Color Palette**: Not defining custom brand colors\n- **No Custom Tokens**: Not extending Tailwind theme with brand values\n- **Missing Dark Mode**: No dark mode variants (if applicable)\n\n## Remediation Examples\n\n### Fixing Generic Fonts\n```tsx\n<!-- âŒ Critical: Default Inter font -->\n  <h1 className=\"text-4xl font-sans\">Welcome</h1>\n\n<!-- âœ… Correct: Distinctive custom font -->\n  <h1 className=\"text-4xl font-heading tracking-tight\">Welcome</h1>\n\n<!-- tailwind.config.ts -->\nexport default {\n  theme: {\n    extend: {\n      fontFamily: {\n        // âŒ NOT: sans: ['Inter', 'sans-serif']\n        // âœ… YES: Distinctive fonts\n        sans: ['Space Grotesk', 'system-ui', 'sans-serif'],\n        heading: ['Archivo Black', 'system-ui', 'sans-serif'],\n        mono: ['JetBrains Mono', 'monospace']\n      }\n    }\n  }\n}\n```\n\n### Fixing Generic Colors\n```tsx\n<!-- âŒ Critical: Purple gradient (overused) -->\n  <div className=\"bg-gradient-to-r from-purple-500 to-purple-600\">\n    <h2 className=\"text-white\">Hero Section</h2>\n  </div>\n\n<!-- âœ… Correct: Custom brand colors -->\n  <div className=\"bg-gradient-to-br from-brand-coral via-brand-ocean to-brand-sunset\">\n    <h2 className=\"text-white\">Hero Section</h2>\n  </div>\n\n<!-- tailwind.config.ts -->\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // âŒ NOT: Using only default Tailwind colors\n        // âœ… YES: Custom brand palette\n        brand: {\n          coral: '#FF6B6B',\n          ocean: '#4ECDC4',\n          sunset: '#FFE66D',\n          midnight: '#2C3E50',\n          cream: '#FFF5E1'\n        }\n      }\n    }\n  }\n}\n```\n\n### Fixing Missing Animations\n```tsx\n<!-- âŒ Critical: No hover/transition effects -->\n  <Button onClick=\"handleSubmit\">\n    Submit Form\n  </Button>\n\n<!-- âœ… Correct: Engaging animations -->\n  <Button\n    className=\"transition-all duration-300 hover:scale-105 hover:shadow-xl active:scale-95\"\n    onClick=\"handleSubmit\"\n  >\n    <span className=\"inline-flex items-center gap-2\">\n      Submit Form\n      <Icon\n        name=\"i-heroicons-arrow-right\"\n        className=\"transition-transform duration-300 group-hover:translate-x-1\"\n      />\n    </span>\n  </Button>\n```\n\n### Fixing Default Component Usage\n```tsx\n<!-- âŒ P2: All default props (generic appearance) -->\n  <Card>\n    <p>Content here</p>\n  </Card>\n\n<!-- âœ… Correct: Customized for brand distinctiveness -->\n  <Card\n    :ui=\"{\n      background: 'bg-white dark:bg-brand-midnight',\n      ring: 'ring-1 ring-brand-coral/20',\n      rounded: 'rounded-2xl',\n      shadow: 'shadow-xl hover:shadow-2xl',\n      body: { padding: 'p-8' }\n    }\"\n    className=\"transition-all duration-300 hover:-translate-y-1\"\n  >\n    <p className=\"text-gray-700 dark:text-gray-300\">Content here</p>\n  </Card>\n```\n\n## MCP Server Integration\n\nWhen shadcn/ui MCP server is available:\n- Query component customization options before validation\n- Verify that suggested customizations use valid props\n- Get latest component API to prevent hallucination\n- Validate `ui` prop structure against actual schema\n\n**Example MCP Usage**:\n```typescript\n// Validate Button customization\nconst buttonDocs = await mcp.shadcn.get_component(\"Button\");\n// Check if suggested props exist: color, size, variant, ui, etc.\n// Ensure customizations align with actual API\n```\n\n## Benefits\n\n### Immediate Impact\n- **Prevents Generic Design**: Catches overused patterns before they ship\n- **Enforces Brand Identity**: Ensures consistent, distinctive aesthetics\n- **Improves User Engagement**: Validates animations and interactions\n- **Educates Developers**: Clear explanations of design best practices\n\n### Long-term Value\n- **Consistent Visual Identity**: All components follow brand guidelines\n- **Faster Design Iterations**: Immediate feedback on design choices\n- **Better User Experience**: Polished animations and interactions\n- **Reduced Design Debt**: Prevents accumulation of generic patterns\n\n## Usage Examples\n\n### During Component Creation\n```tsx\n// Developer creates: <div className=\"font-sans bg-purple-500\">\n// SKILL immediately activates: \"âš ï¸ WARNING: Using default 'font-sans' (Inter) and purple gradient. Consider custom brand fonts and colors for distinctive design.\"\n```\n\n### During Styling\n```tsx\n// Developer adds: <Button>Click me</Button>\n// SKILL immediately activates: \"âš ï¸ P2: Button lacks hover animations. Add transition utilities for better engagement: class='transition-all duration-300 hover:scale-105'\"\n```\n\n### During Configuration\n```typescript\n// Developer modifies tailwind.config.ts with default Inter\n// SKILL immediately activates: \"âš ï¸ P1: Using Inter font (appears in 80%+ of sites). Replace with distinctive font choices like Space Grotesk, Archivo, or other brand-appropriate fonts.\"\n```\n\n### Before Deployment\n```tsx\n// SKILL runs comprehensive check: \"âœ… Design validation passed. Custom fonts, distinctive colors, engaging animations, and customized components detected.\"\n```\n\n## Design Philosophy Alignment\n\nThis SKILL implements the core insight from Claude's \"Improving Frontend Design Through Skills\" blog post:\n\n> \"Think about frontend design the way a frontend engineer would. The more you can map aesthetic improvements to implementable frontend code, the better Claude can execute.\"\n\n**Key Mappings**:\n- **Typography** â†’ Tailwind `fontFamily` config + utility classes\n- **Animations** â†’ Tailwind `transition-*`, `hover:*`, `duration-*` utilities\n- **Background effects** â†’ Custom gradient combinations, `backdrop-*` utilities\n- **Themes** â†’ Extended Tailwind color palette with brand tokens\n\n## Distinctive vs Generic Patterns\n\n### âŒ Generic Patterns (What to Avoid)\n```tsx\n<!-- The \"AI default aesthetic\" -->\n<div className=\"bg-white\">\n  <h1 className=\"font-sans text-gray-900\">Title</h1>\n  <div className=\"bg-gradient-to-r from-purple-500 to-purple-600\">\n    <Button>Action</Button>\n  </div>\n</div>\n```\n\n**Problems**:\n- Inter font (default)\n- Purple gradient (overused)\n- Gray backgrounds (generic)\n- No animations (flat)\n- Default components (no customization)\n\n### âœ… Distinctive Patterns (What to Strive For)\n```tsx\n<!-- Brand-distinctive aesthetic -->\n<div className=\"bg-gradient-to-br from-brand-cream via-white to-brand-ocean/10\">\n  <h1 className=\"font-heading text-6xl text-brand-midnight tracking-tighter\">\n    Title\n  </h1>\n  <div className=\"relative overflow-hidden rounded-3xl bg-brand-coral p-8\">\n    <!-- Atmospheric background -->\n    <div className=\"absolute inset-0 bg-gradient-to-br from-brand-coral to-brand-sunset opacity-80\" />\n\n    <Button\n      :ui=\"{\n        font: 'font-heading',\n        rounded: 'rounded-full',\n        size: 'xl'\n      }\"\n      className=\"relative z-10 transition-all duration-500 hover:scale-110 hover:rotate-2 hover:shadow-2xl active:scale-95\"\n    >\n      <span className=\"flex items-center gap-2\">\n        Action\n        <Icon\n          name=\"i-heroicons-sparkles\"\n          className=\"animate-pulse\"\n        />\n      </span>\n    </Button>\n  </div>\n</div>\n```\n\n**Strengths**:\n- Custom fonts (Archivo Black for headings)\n- Brand-specific colors (coral, ocean, sunset)\n- Atmospheric gradients (multiple layers)\n- Rich animations (scale, rotate, shadow transitions)\n- Heavily customized components (ui prop + utility classes)\n- Micro-interactions (icon pulse, hover effects)\n\nThis SKILL ensures every Tanstack Start project develops a distinctive visual identity by preventing generic patterns and guiding developers toward branded, engaging design implementations."
              },
              {
                "name": "workers-binding-validator",
                "description": "Automatically validates Cloudflare Workers binding configuration, ensuring code references match wrangler.toml setup and TypeScript interfaces are accurate",
                "path": "plugins/edge-stack/skills/workers-binding-validator/SKILL.md",
                "frontmatter": {
                  "name": "workers-binding-validator",
                  "description": "Automatically validates Cloudflare Workers binding configuration, ensuring code references match wrangler.toml setup and TypeScript interfaces are accurate",
                  "triggers": [
                    "env parameter usage",
                    "wrangler.toml changes",
                    "TypeScript interface updates",
                    "binding references"
                  ]
                },
                "content": "# Workers Binding Validator SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- `env` parameter is used in Workers code\n- wrangler.toml file is modified\n- TypeScript `Env` interface is defined or updated\n- New binding references are added to code\n- Binding configuration patterns are detected\n\n## Expertise Provided\n\n### Binding Configuration Validation\n- **Binding Consistency**: Ensures code references match wrangler.toml configuration\n- **TypeScript Interface Validation**: Validates `Env` interface matches actual bindings\n- **Binding Type Accuracy**: Ensures correct binding types (KV, R2, D1, Durable Objects)\n- **Remote Binding Validation**: Checks remote binding configuration for development\n- **Secret Binding Verification**: Validates secret vs environment variable bindings\n\n### Specific Checks Performed\n\n#### âŒ Critical Binding Mismatches\n```typescript\n// These patterns trigger immediate alerts:\n// Code references binding that doesn't exist in wrangler.toml\nconst user = await env.USER_DATA.get(id);  // USER_DATA not configured\n\n// TypeScript interface doesn't match wrangler.toml\ninterface Env {\n  USERS: KVNamespace;     // Code expects USERS\n  // wrangler.toml has USER_DATA (mismatch!)\n}\n```\n\n#### âœ… Correct Binding Patterns\n```typescript\n// These patterns are validated as correct:\n// Matching wrangler.toml and TypeScript interface\ninterface Env {\n  USER_DATA: KVNamespace;  // Matches wrangler.toml binding name\n  API_BUCKET: R2Bucket;    // Correct R2 binding type\n}\n\n// Proper usage in code\nconst user = await env.USER_DATA.get(id);\nconst object = await env.API_BUCKET.get(key);\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **binding-context-analyzer agent**: Handles complex binding analysis, SKILL provides immediate validation\n- **workers-runtime-validator SKILL**: Complements runtime checks with binding validation\n- **cloudflare-security-checker SKILL**: Ensures secret bindings are properly configured\n\n### Escalation Triggers\n- Complex binding architecture questions â†’ `binding-context-analyzer` agent\n- Migration between binding types â†’ `cloudflare-architecture-strategist` agent\n- Binding performance issues â†’ `edge-performance-oracle` agent\n\n## Validation Rules\n\n### P1 - Critical (Will Fail at Runtime)\n- **Missing Bindings**: Code references bindings not in wrangler.toml\n- **Type Mismatches**: Wrong binding types in TypeScript interface\n- **Name Mismatches**: Different names in code vs configuration\n- **Missing Env Interface**: No TypeScript interface for bindings\n\n### P2 - High (Configuration Issues)\n- **Remote Binding Missing**: Development bindings without `remote = true`\n- **Secret vs Var Confusion**: Secrets in [vars] section or vice versa\n- **Incomplete Interface**: Missing bindings in TypeScript interface\n\n### P3 - Medium (Best Practices)\n- **Binding Documentation**: Missing JSDoc comments for bindings\n- **Binding Organization**: Poor organization of related bindings\n\n## Remediation Examples\n\n### Fixing Missing Bindings\n```typescript\n// âŒ Critical: Code references binding not in wrangler.toml\nexport default {\n  async fetch(request: Request, env: Env) {\n    const user = await env.USER_CACHE.get(userId); // USER_CACHE not configured!\n  }\n}\n\n// wrangler.toml (missing binding)\n[[kv_namespaces]]\nbinding = \"USER_DATA\"  # Different name!\nid = \"user-data\"\n\n// âœ… Correct: Matching names\nexport default {\n  async fetch(request: Request, env: Env) {\n    const user = await env.USER_DATA.get(userId); // Matches wrangler.toml\n  }\n}\n\n// wrangler.toml (correct binding)\n[[kv_namespaces]]\nbinding = \"USER_DATA\"  # Matches code!\nid = \"user-data\"\n```\n\n### Fixing TypeScript Interface Mismatches\n```typescript\n// âŒ Critical: Interface doesn't match wrangler.toml\ninterface Env {\n  USERS: KVNamespace;      // Code expects USERS\n  SESSIONS: KVNamespace;    // Code expects SESSIONS\n}\n\n// wrangler.toml has different names\n[[kv_namespaces]]\nbinding = \"USER_DATA\"      # Different!\nid = \"user-data\"\n\n[[kv_namespaces]]\nbinding = \"SESSION_DATA\"    # Different!\nid = \"session-data\"\n\n// âœ… Correct: Matching interface and configuration\ninterface Env {\n  USER_DATA: KVNamespace;   # Matches wrangler.toml\n  SESSION_DATA: KVNamespace; # Matches wrangler.toml\n}\n\n// wrangler.toml (matching names)\n[[kv_namespaces]]\nbinding = \"USER_DATA\"       # Matches interface!\nid = \"user-data\"\n\n[[kv_namespaces]]\nbinding = \"SESSION_DATA\"     # Matches interface!\nid = \"session-data\"\n```\n\n### Fixing Binding Type Mismatches\n```typescript\n// âŒ Critical: Wrong binding type\ninterface Env {\n  MY_BUCKET: KVNamespace;    # Wrong type - should be R2Bucket\n  MY_DB: D1Database;        # Wrong type - should be KVNamespace\n}\n\n// wrangler.toml\n[[r2_buckets]]\nbinding = \"MY_BUCKET\"       # R2 bucket, not KV!\n\n[[kv_namespaces]]\nbinding = \"MY_DB\"           # KV namespace, not D1!\n\n// âœ… Correct: Proper binding types\ninterface Env {\n  MY_BUCKET: R2Bucket;      # Correct type for R2 bucket\n  MY_DB: KVNamespace;       # Correct type for KV namespace\n}\n\n// wrangler.toml (same as above)\n[[r2_buckets]]\nbinding = \"MY_BUCKET\"\n\n[[kv_namespaces]]\nbinding = \"MY_DB\"\n```\n\n### Fixing Remote Binding Configuration\n```typescript\n// âŒ High: Missing remote binding for development\n// wrangler.toml\n[[kv_namespaces]]\nbinding = \"USER_DATA\"\nid = \"user-data\"\n# Missing remote = true for development!\n\n// âœ… Correct: Remote binding configured\n[[kv_namespaces]]\nbinding = \"USER_DATA\"\nid = \"user-data\"\nremote = true  # Enables remote binding for development\n```\n\n### Fixing Secret vs Environment Variable Confusion\n```typescript\n// âŒ High: Secret in [vars] section (visible in git)\n// wrangler.toml\n[vars]\nAPI_KEY = \"sk_live_12345\"  # Secret exposed in git!\n\n// âœ… Correct: Secret via wrangler secret command\n// wrangler.toml (no secrets in [vars])\n[vars]\nPUBLIC_API_URL = \"https://api.example.com\"  # Non-secret config only\n\n# Set secret via command line:\n# wrangler secret put API_KEY\n# (prompt: enter secret value)\n\n// Code accesses both correctly\ninterface Env {\n  API_KEY: string;           # From wrangler secret\n  PUBLIC_API_URL: string;    # From wrangler.toml [vars]\n}\n```\n\n## MCP Server Integration\n\nWhen Cloudflare MCP server is available:\n- Query actual binding configuration from Cloudflare account\n- Verify bindings exist and are accessible\n- Check binding permissions and limits\n- Get latest binding configuration best practices\n\n## Benefits\n\n### Immediate Impact\n- **Prevents Runtime Failures**: Catches binding mismatches before deployment\n- **Reduces Debugging Time**: Immediate feedback on configuration issues\n- **Ensures Type Safety**: Validates TypeScript interfaces match reality\n\n### Long-term Value\n- **Consistent Configuration**: Ensures all code uses correct binding patterns\n- **Better Developer Experience**: Clear error messages for binding issues\n- **Reduced Deployment Issues**: Configuration validation prevents failed deployments\n\n## Usage Examples\n\n### During Binding Usage\n```typescript\n// Developer types: const data = await env.CACHE.get(key);\n// SKILL immediately activates: \"âŒ CRITICAL: CACHE binding not found in wrangler.toml. Add [[kv_namespaces]] binding = 'CACHE' or check spelling.\"\n```\n\n### During Interface Definition\n```typescript\n// Developer types: interface Env { USERS: R2Bucket; }\n// SKILL immediately activates: \"âš ï¸ HIGH: USERS binding type mismatch. wrangler.toml shows USERS as KVNamespace, not R2Bucket.\"\n```\n\n### During Configuration Changes\n```typescript\n// Developer modifies wrangler.toml binding name\n// SKILL immediately activates: \"âš ï¸ HIGH: Binding name changed from USER_DATA to USERS. Update TypeScript interface and code references.\"\n```\n\n## Binding Type Reference\n\n### KV Namespace\n```typescript\ninterface Env {\n  MY_KV: KVNamespace;\n}\n// Usage: await env.MY_KV.get(key)\n```\n\n### R2 Bucket\n```typescript\ninterface Env {\n  MY_BUCKET: R2Bucket;\n}\n// Usage: await env.MY_BUCKET.get(key)\n```\n\n### D1 Database\n```typescript\ninterface Env {\n  MY_DB: D1Database;\n}\n// Usage: await env.MY_DB.prepare(query).bind(params).all()\n```\n\n### Durable Object\n```typescript\ninterface Env {\n  MY_DO: DurableObjectNamespace;\n}\n// Usage: env.MY_DO.get(id)\n```\n\n### AI Binding\n```typescript\ninterface Env {\n  AI: Ai;\n}\n// Usage: await env.AI.run(model, params)\n```\n\n### Vectorize\n```typescript\ninterface Env {\n  VECTORS: VectorizeIndex;\n}\n// Usage: await env.VECTORS.query(vector, options)\n```\n\nThis SKILL ensures Workers binding configuration is correct by providing immediate, autonomous validation of binding patterns, preventing runtime failures and configuration mismatches."
              },
              {
                "name": "workers-runtime-validator",
                "description": "Automatically validates Cloudflare Workers runtime compatibility during development, preventing Node.js API usage and ensuring proper Workers patterns",
                "path": "plugins/edge-stack/skills/workers-runtime-validator/SKILL.md",
                "frontmatter": {
                  "name": "workers-runtime-validator",
                  "description": "Automatically validates Cloudflare Workers runtime compatibility during development, preventing Node.js API usage and ensuring proper Workers patterns",
                  "triggers": [
                    "import statements",
                    "file creation",
                    "code changes",
                    "deployment preparation"
                  ]
                },
                "content": "# Workers Runtime Validator SKILL\n\n## Activation Patterns\n\nThis SKILL automatically activates when:\n- New `.ts` or `.js` files are created in Workers projects\n- Import statements are added or modified\n- Code changes include potential runtime violations\n- Before deployment commands are executed\n- When `process.env`, `require()`, or Node.js APIs are detected\n\n## Expertise Provided\n\n### Runtime Compatibility Validation\n- **Forbidden API Detection**: Identifies Node.js built-ins that don't exist in Workers\n- **Environment Access**: Ensures proper `env` parameter usage vs `process.env`\n- **Module System**: Validates ES modules usage (no `require()`)\n- **Async Patterns**: Ensures all I/O operations are async\n- **Package Compatibility**: Checks npm packages for Node.js dependencies\n\n### Specific Checks Performed\n\n#### âŒ Critical Violations (Will Break in Production)\n```typescript\n// These patterns trigger immediate alerts:\nimport fs from 'fs';                    // Node.js API\nimport { Buffer } from 'buffer';        // Node.js API\nconst secret = process.env.API_KEY;     // process doesn't exist\nconst data = require('./module');        // require() not supported\n```\n\n#### âœ… Correct Workers Patterns\n```typescript\n// These patterns are validated as correct:\nimport { z } from 'zod';                // Web-compatible package\nconst secret = env.API_KEY;             // Proper env parameter\nconst hash = await crypto.subtle.digest(); // Web Crypto API\n```\n\n## Integration Points\n\n### Complementary to Existing Components\n- **workers-runtime-guardian agent**: Handles deep runtime analysis, SKILL provides immediate validation\n- **es-deploy command**: SKILL prevents deployment failures by catching issues early\n- **validate command**: SKILL provides continuous validation between explicit checks\n\n### Escalation Triggers\n- Complex runtime compatibility questions â†’ `workers-runtime-guardian` agent\n- Package dependency analysis â†’ `edge-performance-oracle` agent\n- Migration from Node.js to Workers â†’ `cloudflare-architecture-strategist` agent\n\n## Validation Rules\n\n### P1 - Critical (Must Fix Immediately)\n- **Node.js Built-ins**: `fs`, `path`, `os`, `crypto`, `process`, `buffer`\n- **CommonJS Usage**: `require()`, `module.exports`\n- **Process Access**: `process.env`, `process.exit()`\n- **Synchronous I/O**: Any blocking I/O operations\n\n### P2 - Important (Should Fix)\n- **Package Dependencies**: npm packages with Node.js dependencies\n- **Missing Async**: I/O operations without await\n- **Buffer Usage**: Using Node.js Buffer instead of Uint8Array\n\n### P3 - Best Practices\n- **TypeScript Env Interface**: Missing or incorrect Env type definition\n- **Web API Usage**: Not using modern Web APIs when available\n\n## Remediation Examples\n\n### Fixing Node.js API Usage\n```typescript\n// âŒ Critical: Node.js crypto\nimport crypto from 'crypto';\nconst hash = crypto.createHash('sha256');\n\n// âœ… Correct: Web Crypto API\nconst encoder = new TextEncoder();\nconst hash = await crypto.subtle.digest('SHA-256', encoder.encode(data));\n```\n\n### Fixing Environment Access\n```typescript\n// âŒ Critical: process.env\nconst apiKey = process.env.API_KEY;\n\n// âœ… Correct: env parameter\nexport default {\n  async fetch(request: Request, env: Env) {\n    const apiKey = env.API_KEY;\n  }\n}\n```\n\n### Fixing Module System\n```typescript\n// âŒ Critical: CommonJS\nconst utils = require('./utils');\n\n// âœ… Correct: ES modules\nimport { utils } from './utils';\n```\n\n## MCP Server Integration\n\nWhen Cloudflare MCP server is available:\n- Query latest Workers runtime API documentation\n- Check for deprecated APIs before suggesting fixes\n- Get current compatibility information for new features\n\n## Benefits\n\n### Immediate Impact\n- **Prevents Runtime Failures**: Catches issues before deployment\n- **Reduces Debugging Time**: Immediate feedback on violations\n- **Educates Developers**: Clear explanations of Workers vs Node.js differences\n\n### Long-term Value\n- **Consistent Code Quality**: Ensures all code follows Workers patterns\n- **Faster Development**: No need to wait for deployment to discover issues\n- **Better Developer Experience**: Real-time guidance during coding\n\n## Usage Examples\n\n### During Code Creation\n```typescript\n// Developer types: import fs from 'fs';\n// SKILL immediately activates: \"âŒ CRITICAL: 'fs' is a Node.js API not available in Workers runtime. Use Web APIs or Workers-specific alternatives.\"\n```\n\n### During Refactoring\n```typescript\n// Developer changes: const secret = process.env.API_KEY;\n// SKILL immediately activates: \"âŒ CRITICAL: 'process.env' doesn't exist in Workers. Use the 'env' parameter passed to your fetch handler instead.\"\n```\n\n### Before Deployment\n```typescript\n// SKILL runs comprehensive check: \"âœ… Runtime validation passed. No Node.js APIs detected, all environment access uses proper env parameter.\"\n```\n\nThis SKILL ensures Workers runtime compatibility by providing immediate, autonomous validation of code patterns, preventing common migration mistakes and runtime failures."
              }
            ]
          }
        ]
      }
    }
  ]
}