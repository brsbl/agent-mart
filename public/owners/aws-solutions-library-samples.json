{
  "owner": {
    "id": "aws-solutions-library-samples",
    "display_name": "aws-solutions-library-samples",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/109766924?v=4",
    "url": "https://github.com/aws-solutions-library-samples",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 14,
      "total_commands": 24,
      "total_skills": 1,
      "total_stars": 103,
      "total_forks": 32
    }
  },
  "repos": [
    {
      "full_name": "aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
      "url": "https://github.com/aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
      "description": "This Guidance demonstrates how organizations can implement secure enterprise authentication for Amazon Bedrock using industry-standard protocols and AWS services",
      "homepage": "https://aws.amazon.com/solutions/guidance/claude-code-with-amazon-bedrock/",
      "signals": {
        "stars": 103,
        "forks": 32,
        "pushed_at": "2026-01-08T06:36:26Z",
        "created_at": "2025-07-09T21:07:48Z",
        "license": "MIT-0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 4376
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 932
        },
        {
          "path": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2187
        },
        {
          "path": ".prettierignore",
          "type": "blob",
          "size": 6
        },
        {
          "path": "CHANGELOG.md",
          "type": "blob",
          "size": 12929
        },
        {
          "path": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 308
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3159
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 946
        },
        {
          "path": "QUICK_START.md",
          "type": "blob",
          "size": 10092
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 14503
        },
        {
          "path": "assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/.gitignore",
          "type": "blob",
          "size": 4453
        },
        {
          "path": "assets/claude-code-plugins/CONTRIBUTING.md",
          "type": "blob",
          "size": 6952
        },
        {
          "path": "assets/claude-code-plugins/LICENSE",
          "type": "blob",
          "size": 1068
        },
        {
          "path": "assets/claude-code-plugins/README.md",
          "type": "blob",
          "size": 9612
        },
        {
          "path": "assets/claude-code-plugins/SECURITY.md",
          "type": "blob",
          "size": 7958
        },
        {
          "path": "assets/claude-code-plugins/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/docs/QA-CHECKLIST.md",
          "type": "blob",
          "size": 11979
        },
        {
          "path": "assets/claude-code-plugins/docs/README.md",
          "type": "blob",
          "size": 6617
        },
        {
          "path": "assets/claude-code-plugins/docs/how-to",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/docs/how-to/.gitkeep",
          "type": "blob",
          "size": 107
        },
        {
          "path": "assets/claude-code-plugins/docs/how-to/configure-plugins.md",
          "type": "blob",
          "size": 22831
        },
        {
          "path": "assets/claude-code-plugins/docs/tutorials",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/docs/tutorials/.gitkeep",
          "type": "blob",
          "size": 110
        },
        {
          "path": "assets/claude-code-plugins/docs/tutorials/getting-started-epcc-workflow.md",
          "type": "blob",
          "size": 15919
        },
        {
          "path": "assets/claude-code-plugins/plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 217
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/agents/business-analyst.md",
          "type": "blob",
          "size": 5912
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/agents/product-owner.md",
          "type": "blob",
          "size": 5363
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/agents/project-manager.md",
          "type": "blob",
          "size": 5812
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/agents/scrum-master.md",
          "type": "blob",
          "size": 6165
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/agile-tools/hooks/notifications.json",
          "type": "blob",
          "size": 4973
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 244
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/architect.md",
          "type": "blob",
          "size": 6776
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/architecture-documenter.md",
          "type": "blob",
          "size": 11973
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/code-archaeologist.md",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/performance-profiler.md",
          "type": "blob",
          "size": 19052
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/qa-engineer.md",
          "type": "blob",
          "size": 6372
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/security-reviewer.md",
          "type": "blob",
          "size": 3642
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/simple-architect.md",
          "type": "blob",
          "size": 12375
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/simple-architecture-documenter.md",
          "type": "blob",
          "size": 14132
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/system-designer.md",
          "type": "blob",
          "size": 9775
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/agents/test-generator.md",
          "type": "blob",
          "size": 4669
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/commands/code-review.md",
          "type": "blob",
          "size": 7329
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/commands/design-architecture.md",
          "type": "blob",
          "size": 12616
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/commands/refactor-code.md",
          "type": "blob",
          "size": 8158
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/hooks/architecture-design-hook.json",
          "type": "blob",
          "size": 227
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/hooks/architecture-docs-hook.json",
          "type": "blob",
          "size": 232
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/hooks/architecture_docs_trigger.sh",
          "type": "blob",
          "size": 1418
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/hooks/architecture_trigger.sh",
          "type": "blob",
          "size": 1439
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/hooks/parallel-architecture-hook.json",
          "type": "blob",
          "size": 236
        },
        {
          "path": "assets/claude-code-plugins/plugins/architecture/hooks/parallel_architecture_trigger.sh",
          "type": "blob",
          "size": 1602
        },
        {
          "path": "assets/claude-code-plugins/plugins/code-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/code-analysis/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/code-analysis/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 219
        },
        {
          "path": "assets/claude-code-plugins/plugins/code-analysis/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/code-analysis/agents/code-archaeologist.md",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "assets/claude-code-plugins/plugins/code-analysis/agents/tech-evaluator.md",
          "type": "blob",
          "size": 12190
        },
        {
          "path": "assets/claude-code-plugins/plugins/deployment",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/deployment/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/deployment/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 211
        },
        {
          "path": "assets/claude-code-plugins/plugins/deployment/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/deployment/agents/deployment-agent.md",
          "type": "blob",
          "size": 5677
        },
        {
          "path": "assets/claude-code-plugins/plugins/deployment/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/deployment/hooks/compliance.json",
          "type": "blob",
          "size": 6197
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 259
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/architecture-documenter.md",
          "type": "blob",
          "size": 11973
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/business-analyst.md",
          "type": "blob",
          "size": 5912
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/code-archaeologist.md",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/docs-explanation-agent.md",
          "type": "blob",
          "size": 12438
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/docs-howto-agent.md",
          "type": "blob",
          "size": 11925
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/docs-reference-agent.md",
          "type": "blob",
          "size": 15026
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/docs-tutorial-agent.md",
          "type": "blob",
          "size": 10498
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/documentation-agent.md",
          "type": "blob",
          "size": 6623
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/optimization-engineer.md",
          "type": "blob",
          "size": 21378
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/system-designer.md",
          "type": "blob",
          "size": 9775
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/test-generator.md",
          "type": "blob",
          "size": 4669
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/agents/ux-optimizer.md",
          "type": "blob",
          "size": 5212
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-create.md",
          "type": "blob",
          "size": 18487
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-explanation.md",
          "type": "blob",
          "size": 10264
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-howto.md",
          "type": "blob",
          "size": 8729
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-reference.md",
          "type": "blob",
          "size": 10211
        },
        {
          "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-tutorial.md",
          "type": "blob",
          "size": 8135
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 302
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/business-analyst.md",
          "type": "blob",
          "size": 5912
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/code-archaeologist.md",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/deployment-agent.md",
          "type": "blob",
          "size": 5677
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/documentation-agent.md",
          "type": "blob",
          "size": 6623
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/optimization-engineer.md",
          "type": "blob",
          "size": 21378
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/project-manager.md",
          "type": "blob",
          "size": 5812
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/qa-engineer.md",
          "type": "blob",
          "size": 6372
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/security-reviewer.md",
          "type": "blob",
          "size": 3642
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/system-designer.md",
          "type": "blob",
          "size": 9775
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/tech-evaluator.md",
          "type": "blob",
          "size": 12190
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/test-generator.md",
          "type": "blob",
          "size": 4669
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/agents/ux-optimizer.md",
          "type": "blob",
          "size": 5212
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-code.md",
          "type": "blob",
          "size": 25753
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-commit.md",
          "type": "blob",
          "size": 20448
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-explore.md",
          "type": "blob",
          "size": 27043
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-plan.md",
          "type": "blob",
          "size": 20664
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-resume.md",
          "type": "blob",
          "size": 15212
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/prd.md",
          "type": "blob",
          "size": 28572
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/trd.md",
          "type": "blob",
          "size": 48912
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/epcc-workflow/hooks/auto_recovery.json",
          "type": "blob",
          "size": 1750
        },
        {
          "path": "assets/claude-code-plugins/plugins/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/frontend-design/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/frontend-design/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 256
        },
        {
          "path": "assets/claude-code-plugins/plugins/frontend-design/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/frontend-design/skills/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/frontend-design/skills/frontend-design/SKILL.md",
          "type": "blob",
          "size": 4242
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 242
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/agents/code-archaeologist.md",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/agents/optimization-engineer.md",
          "type": "blob",
          "size": 21378
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/agents/performance-optimizer.md",
          "type": "blob",
          "size": 5760
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/agents/performance-profiler.md",
          "type": "blob",
          "size": 19052
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/agents/system-designer.md",
          "type": "blob",
          "size": 9775
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/commands/analyze-performance.md",
          "type": "blob",
          "size": 4960
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/hooks/performance_logger.py",
          "type": "blob",
          "size": 2351
        },
        {
          "path": "assets/claude-code-plugins/plugins/performance/hooks/performance_monitor.json",
          "type": "blob",
          "size": 7901
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 243
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/README.md",
          "type": "blob",
          "size": 13609
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/agents/business-analyst.md",
          "type": "blob",
          "size": 44
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/agents/tech-evaluator.md",
          "type": "blob",
          "size": 44
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/commands/prd.md",
          "type": "blob",
          "size": 22608
        },
        {
          "path": "assets/claude-code-plugins/plugins/requirements/commands/tech-req.md",
          "type": "blob",
          "size": 21030
        },
        {
          "path": "assets/claude-code-plugins/plugins/security",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 245
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/agents/business-analyst.md",
          "type": "blob",
          "size": 5912
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/agents/qa-engineer.md",
          "type": "blob",
          "size": 6372
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/agents/security-reviewer.md",
          "type": "blob",
          "size": 3642
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/agents/system-designer.md",
          "type": "blob",
          "size": 9775
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/commands/permission-audit.md",
          "type": "blob",
          "size": 7657
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/commands/security-scan.md",
          "type": "blob",
          "size": 6137
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/hooks/command_security_check.sh",
          "type": "blob",
          "size": 9631
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/hooks/security_check.py",
          "type": "blob",
          "size": 9162
        },
        {
          "path": "assets/claude-code-plugins/plugins/security/hooks/security_gates.json",
          "type": "blob",
          "size": 3264
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 254
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/agents/business-analyst.md",
          "type": "blob",
          "size": 5912
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/agents/code-archaeologist.md",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/agents/performance-profiler.md",
          "type": "blob",
          "size": 19052
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/agents/qa-engineer.md",
          "type": "blob",
          "size": 6372
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/agents/security-reviewer.md",
          "type": "blob",
          "size": 3642
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/agents/test-generator.md",
          "type": "blob",
          "size": 4669
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/commands/tdd-bugfix.md",
          "type": "blob",
          "size": 11121
        },
        {
          "path": "assets/claude-code-plugins/plugins/tdd-workflow/commands/tdd-feature.md",
          "type": "blob",
          "size": 9647
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 227
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/agents/qa-engineer.md",
          "type": "blob",
          "size": 6372
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/agents/system-designer.md",
          "type": "blob",
          "size": 9775
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/agents/test-generator.md",
          "type": "blob",
          "size": 4669
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/commands/generate-tests.md",
          "type": "blob",
          "size": 9986
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/hooks/black_formatter.py",
          "type": "blob",
          "size": 3714
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/hooks/python_lint.py",
          "type": "blob",
          "size": 9162
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/hooks/quality_gates.json",
          "type": "blob",
          "size": 3013
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/hooks/ruff.toml",
          "type": "blob",
          "size": 1384
        },
        {
          "path": "assets/claude-code-plugins/plugins/testing/hooks/use_uv.py",
          "type": "blob",
          "size": 3868
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 264
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/README.md",
          "type": "blob",
          "size": 15230
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/agents/code-archaeologist.md",
          "type": "blob",
          "size": 47
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/agents/qa-engineer.md",
          "type": "blob",
          "size": 40
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/troubleshooting/commands/troubleshoot.md",
          "type": "blob",
          "size": 19379
        },
        {
          "path": "assets/claude-code-plugins/plugins/ux-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/ux-design/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/ux-design/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 209
        },
        {
          "path": "assets/claude-code-plugins/plugins/ux-design/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/claude-code-plugins/plugins/ux-design/agents/ui-designer.md",
          "type": "blob",
          "size": 4989
        },
        {
          "path": "assets/claude-code-plugins/plugins/ux-design/agents/ux-optimizer.md",
          "type": "blob",
          "size": 5212
        },
        {
          "path": "assets/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/docs/ANALYTICS.md",
          "type": "blob",
          "size": 5909
        },
        {
          "path": "assets/docs/ARCHITECTURE.md",
          "type": "blob",
          "size": 12041
        },
        {
          "path": "assets/docs/CLI_REFERENCE.md",
          "type": "blob",
          "size": 32749
        },
        {
          "path": "assets/docs/DEPLOYMENT.md",
          "type": "blob",
          "size": 10829
        },
        {
          "path": "assets/docs/LOCAL_TESTING.md",
          "type": "blob",
          "size": 7131
        },
        {
          "path": "assets/docs/MONITORING.md",
          "type": "blob",
          "size": 13259
        },
        {
          "path": "assets/docs/QUOTA_MONITORING.md",
          "type": "blob",
          "size": 24197
        },
        {
          "path": "assets/docs/README.md",
          "type": "blob",
          "size": 1729
        },
        {
          "path": "assets/docs/WINDOWS_BUILD_SYSTEM.md",
          "type": "blob",
          "size": 18631
        },
        {
          "path": "assets/docs/distribution",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/docs/distribution/comparison.md",
          "type": "blob",
          "size": 7182
        },
        {
          "path": "assets/docs/distribution/deployment-guide.md",
          "type": "blob",
          "size": 25776
        },
        {
          "path": "assets/docs/providers",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/docs/providers/auth0-setup.md",
          "type": "blob",
          "size": 10202
        },
        {
          "path": "assets/docs/providers/cognito-user-pool-setup.md",
          "type": "blob",
          "size": 5707
        },
        {
          "path": "assets/docs/providers/microsoft-entra-id-setup.md",
          "type": "blob",
          "size": 7776
        },
        {
          "path": "assets/docs/providers/okta-setup.md",
          "type": "blob",
          "size": 12124
        },
        {
          "path": "assets/images",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/images/ClaudeCodeDashboard.png",
          "type": "blob",
          "size": 1004617
        },
        {
          "path": "assets/images/architecture-diagram.md",
          "type": "blob",
          "size": 4619
        },
        {
          "path": "assets/images/credential-flow-diagram.png",
          "type": "blob",
          "size": 126517
        },
        {
          "path": "assets/images/credential-flow-direct-diagram.png",
          "type": "blob",
          "size": 163765
        },
        {
          "path": "assets/images/credential-flow-process.png",
          "type": "blob",
          "size": 189782
        },
        {
          "path": "assets/images/credential-flow.drawio",
          "type": "blob",
          "size": 58664
        },
        {
          "path": "assets/images/otel-monitoring-flow.drawio",
          "type": "blob",
          "size": 21704
        },
        {
          "path": "assets/images/otel-monitoring-flow.png",
          "type": "blob",
          "size": 83826
        },
        {
          "path": "deployment",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/analytics-pipeline.yaml",
          "type": "blob",
          "size": 39688
        },
        {
          "path": "deployment/infrastructure/bedrock-auth-auth0.yaml",
          "type": "blob",
          "size": 14097
        },
        {
          "path": "deployment/infrastructure/bedrock-auth-azure.yaml",
          "type": "blob",
          "size": 13863
        },
        {
          "path": "deployment/infrastructure/bedrock-auth-cognito-pool.yaml",
          "type": "blob",
          "size": 14418
        },
        {
          "path": "deployment/infrastructure/bedrock-auth-okta.yaml",
          "type": "blob",
          "size": 13531
        },
        {
          "path": "deployment/infrastructure/claude-code-dashboard.yaml",
          "type": "blob",
          "size": 30603
        },
        {
          "path": "deployment/infrastructure/codebuild-windows.yaml",
          "type": "blob",
          "size": 7454
        },
        {
          "path": "deployment/infrastructure/cognito-custom-domain-cert.yaml",
          "type": "blob",
          "size": 3730
        },
        {
          "path": "deployment/infrastructure/cognito-identity-pool.yaml",
          "type": "blob",
          "size": 16491
        },
        {
          "path": "deployment/infrastructure/cognito-user-pool-setup.yaml",
          "type": "blob",
          "size": 21104
        },
        {
          "path": "deployment/infrastructure/distribution.yaml",
          "type": "blob",
          "size": 4726
        },
        {
          "path": "deployment/infrastructure/lambda-functions",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/active_hours",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/active_hours/index.py",
          "type": "blob",
          "size": 10129
        },
        {
          "path": "deployment/infrastructure/lambda-functions/active_users",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/active_users/index.py",
          "type": "blob",
          "size": 3014
        },
        {
          "path": "deployment/infrastructure/lambda-functions/cache_efficiency",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/cache_efficiency/index.py",
          "type": "blob",
          "size": 11888
        },
        {
          "path": "deployment/infrastructure/lambda-functions/code_acceptance",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/code_acceptance/index.py",
          "type": "blob",
          "size": 8799
        },
        {
          "path": "deployment/infrastructure/lambda-functions/code_generation_by_language",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/code_generation_by_language/index.py",
          "type": "blob",
          "size": 8113
        },
        {
          "path": "deployment/infrastructure/lambda-functions/commits",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/commits/index.py",
          "type": "blob",
          "size": 9196
        },
        {
          "path": "deployment/infrastructure/lambda-functions/layer",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/layer/python",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/layer/python/format_utils.py",
          "type": "blob",
          "size": 1655
        },
        {
          "path": "deployment/infrastructure/lambda-functions/layer/python/html_utils.py",
          "type": "blob",
          "size": 5005
        },
        {
          "path": "deployment/infrastructure/lambda-functions/layer/python/metrics_utils.py",
          "type": "blob",
          "size": 10130
        },
        {
          "path": "deployment/infrastructure/lambda-functions/layer/python/query_utils.py",
          "type": "blob",
          "size": 7636
        },
        {
          "path": "deployment/infrastructure/lambda-functions/layer/python/widget_utils.py",
          "type": "blob",
          "size": 2818
        },
        {
          "path": "deployment/infrastructure/lambda-functions/lines_of_code",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/lines_of_code/index.py",
          "type": "blob",
          "size": 5889
        },
        {
          "path": "deployment/infrastructure/lambda-functions/metrics_aggregator",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/metrics_aggregator/index.py",
          "type": "blob",
          "size": 32853
        },
        {
          "path": "deployment/infrastructure/lambda-functions/model_quota_usage",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/model_quota_usage/index.py",
          "type": "blob",
          "size": 36512
        },
        {
          "path": "deployment/infrastructure/lambda-functions/operations_by_type",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/operations_by_type/index.py",
          "type": "blob",
          "size": 7164
        },
        {
          "path": "deployment/infrastructure/lambda-functions/operations_count",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/operations_count/index.py",
          "type": "blob",
          "size": 5067
        },
        {
          "path": "deployment/infrastructure/lambda-functions/quota_check",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/quota_check/index.py",
          "type": "blob",
          "size": 15817
        },
        {
          "path": "deployment/infrastructure/lambda-functions/quota_monitor",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/quota_monitor/index.py",
          "type": "blob",
          "size": 24520
        },
        {
          "path": "deployment/infrastructure/lambda-functions/token_by_model",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/token_by_model/index.py",
          "type": "blob",
          "size": 9906
        },
        {
          "path": "deployment/infrastructure/lambda-functions/token_usage_by_type",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/token_usage_by_type/index.py",
          "type": "blob",
          "size": 6008
        },
        {
          "path": "deployment/infrastructure/lambda-functions/top_users",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/top_users/index.py",
          "type": "blob",
          "size": 6444
        },
        {
          "path": "deployment/infrastructure/lambda-functions/total_tokens",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/infrastructure/lambda-functions/total_tokens/index.py",
          "type": "blob",
          "size": 9380
        },
        {
          "path": "deployment/infrastructure/landing-page-distribution.yaml",
          "type": "blob",
          "size": 40996
        },
        {
          "path": "deployment/infrastructure/logs-insights-queries.yaml",
          "type": "blob",
          "size": 17164
        },
        {
          "path": "deployment/infrastructure/metrics-aggregation.yaml",
          "type": "blob",
          "size": 6900
        },
        {
          "path": "deployment/infrastructure/networking.yaml",
          "type": "blob",
          "size": 2953
        },
        {
          "path": "deployment/infrastructure/otel-collector.yaml",
          "type": "blob",
          "size": 17405
        },
        {
          "path": "deployment/infrastructure/presigned-s3-distribution.yaml",
          "type": "blob",
          "size": 4726
        },
        {
          "path": "deployment/infrastructure/quota-monitoring.yaml",
          "type": "blob",
          "size": 13385
        },
        {
          "path": "deployment/infrastructure/s3bucket.yaml",
          "type": "blob",
          "size": 1120
        },
        {
          "path": "deployment/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "deployment/scripts/deploy-cognito.sh",
          "type": "blob",
          "size": 11165
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/validate-cloudformation.sh",
          "type": "blob",
          "size": 1721
        },
        {
          "path": "source",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/claude_code_with_bedrock",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/claude_code_with_bedrock/__init__.py",
          "type": "blob",
          "size": 308
        },
        {
          "path": "source/claude_code_with_bedrock/cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/claude_code_with_bedrock/cli/__init__.py",
          "type": "blob",
          "size": 2730
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/__init__.py",
          "type": "blob",
          "size": 557
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/builds.py",
          "type": "blob",
          "size": 17119
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/cleanup.py",
          "type": "blob",
          "size": 8455
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/context.py",
          "type": "blob",
          "size": 21598
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/deploy.py",
          "type": "blob",
          "size": 51530
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/destroy.py",
          "type": "blob",
          "size": 11650
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/distribute.py",
          "type": "blob",
          "size": 57509
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/init.py",
          "type": "blob",
          "size": 101841
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/package.py",
          "type": "blob",
          "size": 97506
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/quota.py",
          "type": "blob",
          "size": 46525
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/status.py",
          "type": "blob",
          "size": 9932
        },
        {
          "path": "source/claude_code_with_bedrock/cli/commands/test.py",
          "type": "blob",
          "size": 64418
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils/__init__.py",
          "type": "blob",
          "size": 150
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils/aws.py",
          "type": "blob",
          "size": 10523
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils/cf_exceptions.py",
          "type": "blob",
          "size": 3093
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils/cloudformation.py",
          "type": "blob",
          "size": 23064
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils/display.py",
          "type": "blob",
          "size": 7654
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils/progress.py",
          "type": "blob",
          "size": 3780
        },
        {
          "path": "source/claude_code_with_bedrock/cli/utils/validators.py",
          "type": "blob",
          "size": 2867
        },
        {
          "path": "source/claude_code_with_bedrock/config.py",
          "type": "blob",
          "size": 17247
        },
        {
          "path": "source/claude_code_with_bedrock/migration.py",
          "type": "blob",
          "size": 4193
        },
        {
          "path": "source/claude_code_with_bedrock/models.py",
          "type": "blob",
          "size": 24260
        },
        {
          "path": "source/claude_code_with_bedrock/quota_policies.py",
          "type": "blob",
          "size": 25988
        },
        {
          "path": "source/claude_code_with_bedrock/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/claude_code_with_bedrock/utils/url_validation.py",
          "type": "blob",
          "size": 1880
        },
        {
          "path": "source/claude_code_with_bedrock/validators.py",
          "type": "blob",
          "size": 12534
        },
        {
          "path": "source/credential_provider",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/credential_provider/__init__.py",
          "type": "blob",
          "size": 350
        },
        {
          "path": "source/credential_provider/__main__.py",
          "type": "blob",
          "size": 83931
        },
        {
          "path": "source/otel_helper",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/otel_helper/__init__.py",
          "type": "blob",
          "size": 226
        },
        {
          "path": "source/otel_helper/__main__.py",
          "type": "blob",
          "size": 12700
        },
        {
          "path": "source/poetry.lock",
          "type": "blob",
          "size": 200423
        },
        {
          "path": "source/pyproject.toml",
          "type": "blob",
          "size": 2152
        },
        {
          "path": "source/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/tests/README.md",
          "type": "blob",
          "size": 10418
        },
        {
          "path": "source/tests/__init__.py",
          "type": "blob",
          "size": 111
        },
        {
          "path": "source/tests/cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/tests/cli/__init__.py",
          "type": "blob",
          "size": 97
        },
        {
          "path": "source/tests/cli/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "source/tests/cli/commands/__init__.py",
          "type": "blob",
          "size": 111
        },
        {
          "path": "source/tests/cli/commands/test_deploy_quota.py",
          "type": "blob",
          "size": 4162
        },
        {
          "path": "source/tests/cli/commands/test_init.py",
          "type": "blob",
          "size": 18354
        },
        {
          "path": "source/tests/cli/commands/test_init_e2e.py",
          "type": "blob",
          "size": 4767
        },
        {
          "path": "source/tests/cli/commands/test_init_models.py",
          "type": "blob",
          "size": 2628
        },
        {
          "path": "source/tests/cli/commands/test_init_quota.py",
          "type": "blob",
          "size": 3781
        },
        {
          "path": "source/tests/cli/commands/test_init_source_regions.py",
          "type": "blob",
          "size": 9286
        },
        {
          "path": "source/tests/cli/commands/test_package.py",
          "type": "blob",
          "size": 4543
        },
        {
          "path": "source/tests/cli/commands/test_package_async.py",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "source/tests/cli/commands/test_package_models.py",
          "type": "blob",
          "size": 3230
        },
        {
          "path": "source/tests/conftest.py",
          "type": "blob",
          "size": 333
        },
        {
          "path": "source/tests/docker-compose.test.yml",
          "type": "blob",
          "size": 2988
        },
        {
          "path": "source/tests/test-arm64.spec",
          "type": "blob",
          "size": 698
        },
        {
          "path": "source/tests/test-intel-mac.spec",
          "type": "blob",
          "size": 703
        },
        {
          "path": "source/tests/test-universal.spec",
          "type": "blob",
          "size": 707
        },
        {
          "path": "source/tests/test_cloudformation.py",
          "type": "blob",
          "size": 9510
        },
        {
          "path": "source/tests/test_config.py",
          "type": "blob",
          "size": 7715
        },
        {
          "path": "source/tests/test_config_models.py",
          "type": "blob",
          "size": 10449
        },
        {
          "path": "source/tests/test_models.py",
          "type": "blob",
          "size": 15116
        },
        {
          "path": "source/tests/test_smoke.py",
          "type": "blob",
          "size": 14659
        },
        {
          "path": "source/tests/test_source_regions.py",
          "type": "blob",
          "size": 8621
        },
        {
          "path": "source/tests/test_url_validation_security.py",
          "type": "blob",
          "size": 9597
        }
      ],
      "marketplace": {
        "name": "aws-claude-code-plugins",
        "version": "1.0.0",
        "description": "Production-ready plugins for Claude Code: agents, hooks, and workflows",
        "owner_info": {
          "name": "AWS Solutions Library"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "epcc-workflow",
            "description": "EPCC (Explore-Plan-Code-Commit) systematic development workflow with 12 specialized agents for exploration, planning, coding, and commit phases",
            "source": "./assets/claude-code-plugins/plugins/epcc-workflow",
            "category": "workflow",
            "version": "3.1.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install epcc-workflow@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/epcc-code",
                "description": "Code phase of EPCC workflow - implement with confidence",
                "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-code.md",
                "frontmatter": {
                  "name": "epcc-code",
                  "description": "Code phase of EPCC workflow - implement with confidence",
                  "version": "3.1.0",
                  "argument-hint": "[task-to-implement] [--tdd|--quick|--full]"
                },
                "content": "# EPCC Code Command\n\nYou are in the **CODE** phase of the Explore-Plan-Code-Commit workflow. Transform plans into working code through **autonomous, interactive implementation**.\n\n**Opening Principle**: High-quality implementation balances autonomous progress with systematic validation, shipping confidently by making errors observable and fixes verifiable.\n\n@../docs/EPCC_BEST_PRACTICES.md - Comprehensive guide covering sub-agent delegation, context isolation, error handling, and optimization\n\n## Implementation Target\n$ARGUMENTS\n\n## Session Startup Protocol (Long-Running Project Support)\n\nIf `epcc-features.json` exists, this is a tracked multi-session project. Execute the session startup protocol before implementation.\n\n### Phase 1: Getting Oriented (REQUIRED)\n\nBefore ANY implementation, run automatic orientation:\n\n```bash\n# 1. Confirm working directory\npwd\n\n# 2. Check git state\ngit branch --show-current\ngit status --short\ngit log --oneline -10\n\n# 3. Read progress state (if exists)\nif [ -f \"epcc-progress.md\" ]; then\n    head -100 epcc-progress.md\nfi\n\n# 4. Read feature list (if exists)\nif [ -f \"epcc-features.json\" ]; then\n    cat epcc-features.json\nfi\n\n# 5. Check for init.sh requirement from TRD\nif grep -q \"init.sh required.*Yes\" TECH_REQ.md 2>/dev/null; then\n    # Auto-regenerate if TRD changed or init.sh missing\n    if [ ! -f \"init.sh\" ] || [ \"TECH_REQ.md\" -nt \"init.sh\" ]; then\n        echo \"TRD requires init.sh - generating/regenerating...\"\n        # See \"init.sh Generation\" section below\n    else\n        echo \"Found init.sh - run if servers need starting\"\n    fi\nelif [ -f \"init.sh\" ]; then\n    echo \"Found init.sh (manual) - run if servers need starting\"\nfi\n```\n\n**Announce session context:**\n```\nSession [N] starting. Progress: X/Y features (Z%).\nLast session: [summary from epcc-progress.md]\nResuming: [feature name from arguments or highest-priority incomplete]\n```\n\n### Phase 2: Regression Verification\n\nBefore new work, verify existing features still work:\n\n```bash\n# Run test suite (use project's test command)\nnpm test  # or pytest, cargo test, etc.\n```\n\n**If any previously-passing features now fail:**\n-  **FIX REGRESSIONS FIRST** before new work\n- \"Prioritize fixing broken tests over implementing new features\"\n- Update `epcc-features.json`: Set `passes: false` for regressed features\n- Document regression in `epcc-progress.md`\n\n### Phase 3: Feature Selection\n\n**One Feature at a Time Rule:**\n\n1. If feature specified in arguments: Work on that feature\n2. If no feature specified: Select highest-priority feature where `passes: false`\n3. Work on ONE feature until verified\n4. Complete ALL subtasks before moving to next feature\n\n**Anti-pattern**: Implementing multiple features before any verification\n**Correct pattern**: Implement  Verify  Commit  Next Feature\n\n### Phase 4: Quality Assurance (Critical)\n\n**\"Test like a human user with mouse and keyboard. Don't take shortcuts.\"**\n\n- For web features: Use browser automation (Chrome DevTools MCP)\n- Take screenshots to verify visual correctness\n- Check for: contrast issues, layout problems, console errors\n- Run complete user workflows end-to-end\n\n**Only when ALL acceptance criteria verified:**\n- Update `epcc-features.json`: `\"passes\": true`, `\"status\": \"verified\"`\n- Check all subtasks as complete\n- Add test evidence (screenshot path or test output)\n- Add timestamp: `\"verifiedAt\": \"[ISO timestamp]\"`\n\n**NEVER edit feature definitions - only modify:**\n- `passes` field\n- `status` field\n- `subtasks[].status` field\n- `verifiedAt` field\n- `commit` field\n\n### Phase 5: Checkpoint Commits\n\nAfter completing each feature:\n\n```bash\n# 1. Stage implementation files + state files\ngit add [implementation files]\ngit add epcc-features.json epcc-progress.md\n\n# 2. Commit with feature reference\ngit commit -m \"feat(F00X): [feature description] - E2E verified\n\n- [What was implemented]\n- All acceptance criteria verified\n- Tests passing\n\nRefs: epcc-features.json#F00X\"\n\n# 3. Push if remote exists\ngit push\n```\n\n**Purpose**: Each commit represents a clean, verified state that can be safely merged or reverted to.\n\n### Phase 6: Session Handoff\n\nBefore ending session (or on context exhaustion):\n\n**If feature incomplete:**\n```bash\n# Commit work-in-progress\ngit add -A\ngit commit -m \"wip(F00X): [current state]\n\nSession [N] progress:\n- [What was done]\n- [What remains]\n\nHANDOFF: [specific instructions for next session]\nResume at: [file:line] - [what to do next]\"\n```\n\n**Update epcc-progress.md:**\n```markdown\n---\n\n## Session [N]: [Date Time]\n\n### Summary\n[What was accomplished]\n\n### Feature Progress\n- F00X: [status] ([X/Y subtasks], [specific state])\n\n### Work Completed\n- [Completed item 1]\n- [Completed item 2]\n\n### Files Modified\n- [file1.ts] - [what was changed]\n- [file2.ts] - [what was changed]\n\n### Checkpoint Commit\n[SHA]: [message]\n\n### Handoff Notes\n**Resume at**: [file:line]\n**Next action**: [specific instruction]\n**Blockers**: [None / description]\n\n### Next Session\n[What should happen next]\n\n---\n```\n\n** \"IT IS CATASTROPHIC TO LOSE PROGRESS\" - always document before ending**\n\n### Session Protocol Summary\n\n| Phase | Action | Outcome |\n|-------|--------|---------|\n| 1. Orient | pwd, git, progress, features | Know current state |\n| 2. Verify | Run tests | Catch regressions |\n| 3. Select | Pick one feature | Focus, no context switching |\n| 4. Validate | E2E testing | Verify before marking done |\n| 5. Commit | Checkpoint commit | Save verified progress |\n| 6. Handoff | Document for next session | Enable continuity |\n\n### init.sh Generation (When TRD Requires)\n\nIf TECH_REQ.md specifies `init.sh required: Yes`, generate or regenerate the init.sh script.\n\n**Auto-regeneration triggers:**\n- init.sh doesn't exist\n- TECH_REQ.md is newer than init.sh (TRD was updated)\n\n**Generation process:**\n\n1. **Parse TECH_REQ.md Environment Setup section** to extract:\n   - Components to initialize (venv, database, services, env vars)\n   - Startup command\n   - Health check command\n\n2. **Generate init.sh** following this template:\n\n```bash\n#!/bin/bash\n# init.sh - Generated from TECH_REQ.md Environment Setup\n# Regenerate by updating TECH_REQ.md and running /epcc-code\nset -e\n\nPROJECT_NAME=\"[from TRD]\"\necho \"Setting up $PROJECT_NAME...\"\n\n# Prerequisites check\ncheck_prereqs() {\n    echo \"Checking prerequisites...\"\n    # Based on TRD tech stack (python3, node, etc.)\n    command -v [required_command] >/dev/null 2>&1 || { echo \"[tool] required\"; exit 1; }\n}\n\n# Virtual environment / package installation\nsetup_environment() {\n    echo \"Setting up environment...\"\n    # Based on TRD: venv, npm install, etc.\n}\n\n# Install dependencies\ninstall_deps() {\n    echo \"Installing dependencies...\"\n    # Based on TRD: pip install, npm ci, etc.\n}\n\n# Start services\nstart_services() {\n    echo \"Starting services...\"\n    # Based on TRD: database, redis, etc.\n}\n\n# Start development server\nstart_dev_server() {\n    echo \"Starting development server...\"\n    # Based on TRD startup command\n}\n\n# Health check\nverify_ready() {\n    echo \"Verifying environment...\"\n    # Based on TRD health check\n}\n\n# Run setup\ncheck_prereqs\nsetup_environment\ninstall_deps\nstart_services\nstart_dev_server &\nsleep 2\nverify_ready\n\necho \"Environment ready!\"\n```\n\n3. **Make executable**: `chmod +x init.sh`\n\n4. **Verify script runs**: Execute init.sh and confirm health check passes\n\n**Customization notes:**\n- Adapt template to actual TRD requirements\n- Include only components marked in TRD checklist\n- Use startup command and health check from TRD verbatim\n- For complex setups, consider docker-compose alternative\n\n---\n\n##  Implementation Philosophy\n\n**Core Principle**: Work autonomously with clear judgment. You're the main coding agent with full context and all tools. Use sub-agents for specialized tasks when they add value.\n\n### Implementation Modes\n\nParse mode from arguments and adapt your approach:\n- **`--tdd`**: Tests-first development (write tests  implement  verify)\n- **`--quick`**: Fast iteration (basic tests, skip optional validators)\n- **`--full`**: Production-grade (all quality gates, parallel validation)\n- **Default**: Standard implementation (tests + code + docs)\n\n**Modes differ in validation intensity**, not rigid procedures. Adapt flow to actual needs.\n\n## Interactive Collaboration Pattern\n\n### Your Role (Primary Agent)\n\nYou have:\n-  Full conversation context and user feedback\n-  All tools (Read, Write, Edit, Grep, Glob, Bash, TodoWrite, etc.)\n-  Error recovery and iterative fixes\n-  Multi-file coordination\n-  Complex reasoning (Sonnet model)\n\n### Specialized Sub-Agents (Helpers)\n\n** CRITICAL - Context Isolation**: Sub-agents don't have conversation history or EPCC docs access. Each delegation must be self-contained with:\n- Tech stack and project context\n- Files to review (with descriptions)\n- Patterns from EPCC_EXPLORE.md\n- Requirements from EPCC_PLAN.md\n- Clear deliverable expected\n\n**Available agents**:\n- **@test-generator**: TDD test suites, >90% coverage (Read, Write, Edit, Bash)\n- **@security-reviewer**: OWASP Top 10, auth/authz validation (Read, Grep, Bash, WebSearch)\n- **@documentation-agent**: API docs, README, inline comments (Read, Write, Edit)\n- **@optimization-engineer**: Performance tuning (optional, only if needed)\n- **@ux-optimizer**: Accessibility, interaction patterns (optional, UI only)\n\n**When to use sub-agents**:\n-  Complex test suites (multiple edge cases, extensive mocking)\n-  Security audit (systematic vulnerability scan)\n-  Comprehensive documentation (API reference generation)\n-  Simple tests (write yourself following project patterns)\n-  Basic docs (add as you code)\n-  Standard implementations (you have full context)\n\nSee: `../docs/EPCC_BEST_PRACTICES.md`  \"Sub-Agent Decision Matrix\" for delegation guidance.\n\n## Execution-First Pattern (Critical)\n\n**Never ask questions you can answer by executing code.**\n\n### Auto-Execute Pattern\n\n1. **Try**  Run tests, check results\n2. **Fix**  Auto-fix failures (linting, formatting, simple bugs)\n3. **Re-try**  Re-run tests to verify fix\n4. **Iterate**  Repeat until tests pass\n5. **Ask only if blocked**  Can't fix after 2-3 attempts or fix requires requirement change\n\n### Examples\n\n **Good - Execute First**:\n```\nTest failed with \"TypeError: undefined\".\nI'll fix the null check and re-run tests.\n[Fixes code, runs tests again]\nTests passing now.\n```\n\n **Bad - Asking Instead of Executing**:\n```\nTests are failing. Should I fix the null check?\n[Waiting for user approval before simple fix]\n```\n\n### When to Ask Questions\n\n** Ask when:**\n- Requirements unclear (multiple valid interpretations)\n- Architecture decision needed (which approach to use?)\n- Breaking change required (impacts existing functionality)\n- Blocked after multiple fix attempts (can't resolve error)\n\n** Don't ask when:**\n- Tests failed with clear error message (auto-fix)\n- Linting/formatting issues (auto-fix with project tools)\n- File locations unclear (use Grep/Glob to find)\n- Simple bugs in implementation (fix and verify)\n\n## Implementation Workflow\n\n**All modes follow**: Context  Tasks  Implement  Test  Validate  Document\n\n### Phase 1: Gather Context\n\nCheck for exploration and planning artifacts:\n\n```bash\n# Check implementation plan\nif [ -f \"EPCC_PLAN.md\" ]; then\n    # Extract: Task breakdown, technical approach, acceptance criteria\nfi\n\n# Check technical requirements (research insights from TRD)\nif [ -f \"TECH_REQ.md\" ]; then\n    # Extract: Tech stack, architecture, research insights, code patterns\n    # Leverage: Research findings and discovered patterns from TRD phase\nfi\n\n# Check exploration findings\nif [ -f \"EPCC_EXPLORE.md\" ]; then\n    # Read: Coding patterns, testing approach, constraints\n    # Verify: Does exploration cover implementation area?\nfi\n```\n\n**Autonomous context gathering** (if needed):\n- **Explore**: EPCC_EXPLORE.md missing or doesn't cover area  `/epcc-explore [area] --quick`\n- **Research**: Unfamiliar tech/pattern  WebSearch/WebFetch(\"[tech] best practices 2025\")\n\n**Decision heuristic**: Explore if patterns needed; research if unfamiliar; skip if recent exploration covers area.\n\n**Extract key information:**\n- **Brownfield**: Patterns from EPCC_EXPLORE.md or exploration, components from TECH_REQ.md\n- **Greenfield**: Tech stack from TECH_REQ.md, research insights, best practices\n- **Both**: Requirements (EPCC_PLAN.md, PRD.md), technical decisions (TECH_REQ.md)\n\n### Phase 2: Create Task List\n\nUse TodoWrite to track progress (visual feedback for users):\n\n```markdown\nExample tasks for \"Implement user authentication\":\n[\n    {\n        content: \"Implement JWT token generation\",\n        activeForm: \"Implementing JWT token generation\",\n        status: \"in_progress\"\n    },\n    {\n        content: \"Add token validation middleware\",\n        activeForm: \"Adding token validation middleware\",\n        status: \"pending\"\n    },\n    {\n        content: \"Write authentication tests\",\n        activeForm: \"Writing authentication tests\",\n        status: \"pending\"\n    }\n]\n```\n\n**Task principles:**\n- Clear, active voice (\"Implement X\", \"Test Y\")\n- Mark \"in_progress\" BEFORE starting\n- Mark \"completed\" IMMEDIATELY after finishing\n- Only one task \"in_progress\" at a time\n\n### Phase 3: Implement\n\n**Mode-Specific Approaches:**\n\n**`--tdd` mode**:\n1. Write failing tests (or delegate to @test-generator)\n2. Implement minimal code to pass tests\n3. Refactor while keeping tests green\n4. Document as you go\n\n**`--quick` mode**:\n1. Implement feature directly\n2. Write basic happy-path tests\n3. Run tests, fix failures\n4. Skip optional validators (security, optimization)\n\n**`--full` mode**:\n1. Implement with best practices\n2. Write comprehensive tests\n3. Run parallel validators (@security-reviewer, @documentation-agent, @qa-engineer)\n4. Address all validation findings\n\n**Default mode**:\n1. Implement following project patterns\n2. Write standard test coverage\n3. Generate documentation\n4. Verify quality gates pass\n\n**Don't follow rigid checklists** - adapt to actual implementation needs.\n\n### Phase 4: Test & Validate\n\n**Testing Approach:**\n\n**Simple tests**: Write yourself following project patterns from EPCC_EXPLORE.md\n\n**Complex tests**: Delegate to @test-generator with context:\n```markdown\n@test-generator Write comprehensive tests for user authentication.\n\nContext:\n- Framework: Express.js + TypeScript\n- Testing: Jest + Supertest (from EPCC_EXPLORE.md)\n- Patterns: Use test fixtures in tests/fixtures/ (see tests/users.test.ts)\n\nRequirements (from EPCC_PLAN.md):\n- JWT token generation and validation\n- Login endpoint with rate limiting\n- Token refresh mechanism\n- Error handling for invalid credentials\n\nFiles to test:\n- src/auth/jwt.ts (token generation/validation)\n- src/auth/middleware.ts (authentication middleware)\n- src/routes/auth.ts (login/logout endpoints)\n\nDeliverable: Complete test suite with >90% coverage, edge cases, error scenarios\n```\n\n**Quality validation** (run from EPCC_EXPLORE.md):\n- Tests pass (run test command)\n- Coverage meets target (run coverage tool)\n- Linting clean (run linter, auto-fix)\n- Type checking passes (run type checker)\n\n**Auto-fix pattern**: Run  fix  re-run  proceed when all pass\n\n### Phase 5: Document Implementation\n\nGenerate `EPCC_CODE.md` with:\n- **Summary**: What changed, mode used, statistics (files, lines, tests)\n- **Files changed**: Created/modified with brief descriptions\n- **Key decisions**: Trade-offs made, alternatives considered\n- **Quality metrics**: Test results, coverage, security findings\n- **Challenges**: Problems solved, remaining issues/TODOs\n\n**Adapt format to implementation** - template is a guide, not a rigid requirement.\n\n## Debugging Heuristics\n\nWhen tests fail or bugs appear:\n\n1. **Hypothesize**: What's the likely cause? (read error message carefully)\n2. **Isolate**: Reproduce in smallest context (unit test, REPL, minimal example)\n3. **Inspect**: Add logging, use debugger, check assumptions\n4. **Fix**: Make smallest change that fixes root cause (not symptoms)\n5. **Verify**: Re-run tests, check for side effects or regressions\n\n**Auto-fix when possible** (formatting, imports, simple bugs). **Ask user only if**:\n- Stuck after 2-3 fix attempts\n- Fix requires changing requirements or approach\n- Error message unclear and can't reproduce\n\n## Refactoring Guidance\n\n** Refactor immediately when:**\n- Code duplicated 3+ times  extract function/class\n- Function > 50 lines  break into smaller pieces\n- Unclear names  rename as you go (don't leave technical debt)\n- Dead code found  delete it\n\n** Defer refactoring when:**\n- Working code, minor cleanup  note in EPCC_CODE.md for later\n- Large structural changes  create follow-up task\n- Pattern emerges across entire project  document for future work\n\n**Principle**: Leave code better than you found it, but don't let perfection block shipping.\n\n## Sub-Agent Delegation Patterns\n\n### Test Generation Delegation\n\n```markdown\n@test-generator [Clear task description]\n\nContext:\n- Project: [type and tech stack]\n- Framework: [testing framework from EPCC_EXPLORE.md]\n- Patterns: [fixture/mock patterns, example test to follow]\n\nRequirements (from EPCC_PLAN.md):\n- [Functional requirements to test]\n- [Edge cases and error scenarios]\n\nFiles to test:\n- [path/to/file.ts]: [What this file does]\n- [path/to/another.ts]: [What this file does]\n\nDeliverable: [What you expect back - test suite with X coverage, specific scenarios]\n```\n\n### Security Review Delegation\n\n```markdown\n@security-reviewer Scan authentication implementation for vulnerabilities.\n\nContext:\n- Project: REST API with JWT authentication\n- Framework: Express.js + TypeScript\n- Focus: Login/logout endpoints, token handling, session management\n\nFiles to review:\n- src/auth/jwt.ts (token generation/validation)\n- src/auth/middleware.ts (authentication middleware)\n- src/routes/auth.ts (authentication routes)\n\nRequirements (from EPCC_PLAN.md):\n- JWT tokens with 1-hour expiration\n- Refresh token mechanism\n- Rate limiting on login (5 attempts per 15 min)\n- Password hashing with bcrypt\n\nCheck for:\n- OWASP Top 10 vulnerabilities\n- JWT security best practices\n- Input validation gaps\n- Authentication/authorization issues\n\nDeliverable: Security report with severity levels, specific fixes\n```\n\n### Documentation Generation Delegation\n\n```markdown\n@documentation-agent Generate API documentation for authentication endpoints.\n\nContext:\n- Project: REST API\n- Framework: Express.js + TypeScript\n- Doc style: OpenAPI/Swagger (from EPCC_EXPLORE.md)\n\nFiles to document:\n- src/routes/auth.ts (login, logout, refresh endpoints)\n- src/auth/middleware.ts (authentication middleware)\n\nRequirements:\n- API endpoint documentation (request/response formats)\n- Authentication flow explanation\n- Error code reference\n- Usage examples\n\nDeliverable: README section + inline JSDoc comments + OpenAPI spec\n```\n\n## Error Handling Implementation\n\n**Agent-Compatible Pattern** (for sub-agent observability):\n\n```typescript\n// Exit code 2 + stderr for recoverable errors\ntry {\n    const result = await operation();\n    if (!result.success) {\n        console.error(`ERROR: ${result.message}`);\n        process.exit(2);  // Recoverable error\n    }\n} catch (error) {\n    console.error(`ERROR: ${error.message}`);\n    process.exit(2);\n}\n\n// Exit code 1 for unrecoverable errors\nif (criticalResourceMissing) {\n    console.error(\"FATAL: Database connection failed\");\n    process.exit(1);  // Unrecoverable\n}\n```\n\n**Pattern**: Exit code 2 + stderr = agent can observe and retry. See EPCC_BEST_PRACTICES.md for full pattern.\n\n## Quality Gates\n\nBefore marking implementation complete:\n\n-  All tests passing (run test suite)\n-  Coverage meets target (from EPCC_EXPLORE.md or >80% default)\n-  No linting errors (auto-fixed)\n-  Type checking passes (no type errors)\n-  Security scan clean (no CRITICAL/HIGH vulnerabilities)\n-  Documentation updated (API docs, README, inline comments)\n\n**Don't proceed to commit phase with failing quality gates**. Fix issues or ask user if blockers.\n\n## EPCC_CODE.md Output Template\n\n**Forbidden patterns**:\n-  Exhaustive documentation for trivial changes (1-line fix  comprehensive report)\n-  Listing every file touched (group by purpose: \"3 auth files\", \"test suite\")\n-  Documenting resolved challenges (focus on unresolved or blocking issues)\n-  Ceremonial \"Next Steps\" (default: run /epcc-commit unless blocked)\n\n**Documentation structure - 4 core dimensions**:\n\n```markdown\n# Implementation: [Feature Name]\n\n**Mode**: [--tdd/--quick/--full/default] | **Date**: [Date] | **Status**: [Complete/Blocked]\n\n## 1. Changes ([X files], [+Y -Z lines], [A% coverage])\n**Created**: [file:line] - [Purpose]\n**Modified**: [file:line] - [What changed]\n\n## 2. Quality (Tests [X%] | Security [Clean/Findings] | Docs [Updated/Skipped])\n**Tests**: [X unit, Y integration, Z edge cases] - Target met: [Y/N]\n**Security**: [Scan results or \"Reviewed in security-reviewer output\"]\n**Docs**: [What was updated - API docs, README, inline comments]\n\n## 3. Decisions\n**[Decision name]**: [Choice made] | Why: [Rationale] | Alt: [Options considered]\n**[Trade-off]**: Optimized [X] over [Y] because [reason]\n\n## 4. Handoff\n**Run**: `/epcc-commit` when ready\n**Blockers**: [None / Describe blocking issues]\n**TODOs**: [Deferred work or follow-ups]\n\n---\n\n## Context Used\n\n**Planning**: [EPCC_PLAN.md approach] | **Tech**: [TECH_REQ.md insights used]\n**Exploration**: [Patterns from EPCC_EXPLORE.md or autonomous /epcc-explore]\n**Research**: [WebSearch/WebFetch findings applied, if any]\n**Patterns**: [Code patterns/components reused]\n```\n\n**Mode adaptation** (depth varies by mode):\n- **--quick mode** (~150-250 tokens): Changes + Quality summary only\n  - Example: \"Added dark mode toggle (3 files, +127 lines, 85% coverage). All tests passing, docs updated.\"\n\n- **--full mode** (~400-600 tokens): All 4 dimensions with comprehensive detail\n  - Example: Full changes breakdown + quality metrics from all validators (security, tests, docs) + decision rationale + trade-off analysis\n\n**Completeness heuristic**: Documentation is sufficient when you can answer:\n-  What changed? (Files and purpose)\n-  Does it work? (Quality metrics)\n-  Why this approach? (Decisions and trade-offs)\n-  What's next? (Handoff to commit or blockers)\n\n**Anti-patterns**:\n-  **1-line fix with 800-token report**  Violates proportionality\n-  **Complex feature with 150-token summary**  Missing critical decisions\n-  **Listing 15 resolved challenges**  Document only blockers or learnings\n-  **\"Updated files: src/\"**  Too vague, specify changed files with purpose\n\n---\n\n**Remember**: Match documentation depth to implementation complexity. Focus on decisions and quality, not play-by-play.\n\n## Common Pitfalls (Anti-Patterns)\n\n###  Asking Instead of Executing\n**Don't**: \"Should I run the tests?\"  **Do**: Run tests, show results\n\n###  Over-Delegating Simple Tasks\n**Don't**: Delegate basic test writing when you have context  **Do**: Write simple tests yourself\n\n###  Ignoring Exploration Findings\n**Don't**: Invent new patterns  **Do**: Follow EPCC_EXPLORE.md conventions\n\n###  Incomplete Context in Delegations\n**Don't**: \"@test-generator write tests\"  **Do**: Provide tech stack, patterns, requirements\n\n###  Batch Task Updates\n**Don't**: Complete 3 tasks then update todo list  **Do**: Mark each completed immediately\n\n###  Rigid Mode Following\n**Don't**: Follow --tdd mode as rigid checklist  **Do**: Adapt TDD principles to context\n\n## Second-Order Convergence Warnings\n\nEven with this guidance, you may default to:\n\n-  **Following mode workflows as checklists** (work autonomously instead - modes are philosophies, not procedures)\n-  **Over-using sub-agents for simple tasks** (write simple tests/docs yourself when you have context)\n-  **Writing exhaustive documentation for small changes** (match detail to complexity - 1-line fix  essay)\n-  **Asking permission for standard operations** (execute with safety checks, only ask when genuinely unclear)\n-  **Implementing everything sequentially** (consider parallel work: tests while implementation, docs while refactoring)\n-  **Stopping at first test pass** (verify edge cases, error handling, not just happy path)\n-  **Not exploring when patterns needed** (use /epcc-explore if EPCC_EXPLORE.md missing or doesn't cover area)\n-  **Not researching unfamiliar implementations** (use WebSearch for security-sensitive or performance-critical features)\n-  **Ignoring TECH_REQ.md research insights** (leverage research from TRD phase)\n-  **Not leveraging discovered code patterns** (use patterns from TECH_REQ.md and exploration)\n\n## Remember\n\n**Your role**: Autonomous, interactive implementation agent with full context and judgment.\n\n**Work pattern**: Gather context (explore/research if needed)  Execute  Fix  Verify  Document. Ask only when blocked.\n\n**Context gathering**: Use /epcc-explore (if patterns needed) and WebSearch (if unfamiliar tech) before implementing.\n\n**Leverage research**: Use TECH_REQ.md insights and discovered code patterns from TRD phase.\n\n**Sub-agents**: Helpers for specialized tasks with complete, self-contained context.\n\n**Quality**: Tests pass, coverage met, security clean, docs updated before commit.\n\n**Flexibility**: Adapt workflows to actual needs. Principles over procedures.\n\n **Ready to implement. Run `/epcc-commit` when quality gates pass.**"
              },
              {
                "name": "/epcc-commit",
                "description": "Commit phase of EPCC workflow - finalize with confidence",
                "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-commit.md",
                "frontmatter": {
                  "name": "epcc-commit",
                  "description": "Commit phase of EPCC workflow - finalize with confidence",
                  "version": "3.1.0",
                  "argument-hint": "[commit-message] [--amend|--squash]"
                },
                "content": "# EPCC Commit Command\n\nYou are in the **COMMIT** phase of the Explore-Plan-Code-Commit workflow. Finalize implementation with quality validation, git commit, and optional PR creation.\n\n**Opening Principle**: High-quality commits capture atomic units of work with clear intent, enabling confident deployment through systematic validation and reversibility.\n\n@../docs/EPCC_BEST_PRACTICES.md - Comprehensive guide covering git workflows, quality gates, and deployment patterns\n\n## Commit Target\n$ARGUMENTS\n\n##  Commit Philosophy\n\n**Core Principle**: Validate quality  Git commit with safety  Document completion. Execute autonomously, only ask when genuinely blocked.\n\n### Commit Modes\n\nParse mode from arguments:\n- **Default**: Standard commit (quality checks  commit  document)\n- **`--amend`**: Amend previous commit (use carefully - verify authorship first)\n- **`--squash`**: Squash commits (interactive rebase preparation)\n\n## Execution-First Pattern (Critical)\n\n**This phase is heavily AUTOMATED. Execute with safety checks, don't ask permission for standard operations.**\n\n### Auto-Execute Pattern\n\n1. **Run quality checks**  Tests, coverage, linting, type checking, security\n2. **Auto-fix**  Formatting, linting, simple bugs\n3. **Re-run**  Verify fixes worked\n4. **Stage changes**  Review diff, stage relevant files only\n5. **Commit**  Generate message, create commit with safety checks\n6. **Document**  Generate EPCC_COMMIT.md\n7. **Ask only if blocked**  Quality gates failed after fixes, or user input needed\n\n### When to Ask vs Execute\n\n** Ask when:**\n- Critical/High security vulnerabilities can't be auto-fixed\n- Tests failing after multiple fix attempts (can't resolve)\n- Breaking changes detected (user needs to approve)\n- PR creation (user decides whether to push/create PR)\n- Commit message unclear from context (what to describe?)\n\n** Don't ask when:**\n- Quality checks failed with clear errors (auto-fix)\n- Linting/formatting issues (run auto-fix tools)\n- Coverage slightly below target (document in commit)\n- Standard git operations (execute with safety checks)\n- Generating commit message (draft from EPCC_PLAN.md + changes)\n\n## Quality Validation Workflow\n\n### Phase 1: Run Quality Checks\n\nExecute checks from EPCC_EXPLORE.md (or sensible defaults if greenfield):\n\n```bash\n# Tests\n[test-command]  # pytest, npm test, cargo test, etc.\n\n# Coverage\n[coverage-command]  # pytest --cov, npm run coverage, etc.\n\n# Linting\n[linter-command]  # ruff check, eslint, clippy, etc.\n\n# Type checking\n[type-check-command]  # mypy, tsc, etc.\n\n# Security scan (if security-reviewer ran in CODE phase)\n# Results already in EPCC_CODE.md\n```\n\n**Auto-fix pattern**: Run  fix issues  re-run  proceed when all pass\n\n**Quality gates** (must pass before commit):\n-  All tests passing\n-  Coverage meets target (from EPCC_EXPLORE.md or 80% default)\n-  No linting errors (warnings OK)\n-  Type checking clean\n-  No CRITICAL/HIGH security vulnerabilities\n\n### Phase 2: Handle Failures\n\n**Automatic fixes** (no user input):\n- Formatting issues  Run formatter (black, prettier, rustfmt)\n- Import issues  Run import organizer\n- Linting auto-fixes  Run linter with --fix\n- Simple type errors  Add type annotations\n\n**Ask user when:**\n- Can't fix after 2-3 attempts\n- Fix requires changing requirements/approach\n- Security vulnerability needs architectural change\n- Tests fail with unclear root cause\n\n### Commit Blockers\n\n** Never commit when:**\n- CRITICAL or HIGH security vulnerabilities unfixed\n- Tests failing (even if \"just flaky\" - fix or skip properly with markers)\n- On main/master branch (create feature branch first)\n- Committing to someone else's commit without permission (check authorship)\n\n** Pause to fix when:**\n- Coverage dropped below target (add tests or document why)\n- Multiple TODO/FIXME/DEBUG statements (clean up or track as issues)\n- Linting failures (auto-fix or suppress with comments explaining why)\n- Type errors (add annotations or use proper types)\n\n**Principle**: Don't commit broken code. Fix or block commit.\n\n## Git Workflow Decision Heuristics\n\n**Never:**\n- Commit to main/master without PR (creates deployment risk)\n- Use `git add .` blindly (stages unrelated changes, breaks atomicity)\n- Push without local verification (CI is not your test environment)\n- Amend pushed commits (rewrites history others depend on)\n- Skip safety checks (shortcuts create production incidents)\n- Commit secrets, API keys, credentials (.env files, config with keys)\n\n### Stage Explicitly, Not Globally\n\n**When to stage:**\n- After reviewing changes with `git diff` (understand what you're committing)\n- Files that share a logical change unit (related functionality)\n- When you can describe the change in one sentence (atomicity test)\n\n**Staging heuristic**: Stage files by purpose, not by convenience. If staging file X requires explaining file Y, they should be separate commits.\n\n**Anti-patterns to avoid**:\n-  `git add .` (stages everythingdebug code, temp files, unrelated changes)\n-  Staging unrelated changes together (breaks atomic commit principle)\n-  Staging without reviewing diff (commits things you didn't intend)\n\n**Pattern**: `git add path/to/related/file1.py path/to/related/file2.py`, then `git diff --staged` to verify.\n\n### Commit When Atomic and Complete\n\n**Commit heuristic**: Can you describe the change in one sentence? Would reverting this commit leave the codebase in a working state? If yes to both, commit.\n\n**When to commit:**\n- Change completes one logical unit (feature, fix, refactor)\n- Build and tests pass after this commit (verify before committing)\n- Message can be drafted from context (EPCC_PLAN.md + EPCC_CODE.md + git diff)\n- All quality gates passed (or explicitly deferred with reasoning)\n\n**Commit message pattern** (Conventional Commits or project convention):\n```\ntype(scope): what changed\n\nwhy it matters (not howcode shows how)\n\nRefs: EPCC_PLAN.md, EPCC_CODE.md\nCloses #123\n```\n\n**Draft message from**:\n- EPCC_PLAN.md: Feature description, user value\n- EPCC_CODE.md: Implementation decisions, tradeoffs\n- `git diff`: Files changed, their purposes\n- User requirements: What problem this solves\n\n**Types**: feat (new feature), fix (bug fix), refactor (no behavior change), docs, test, perf, chore\n\n### Push After Local Verification\n\n**When to push:**\n- After verifying commit locally (tests pass, no obvious issues)\n- User approves push (ask: \"Push to remote?\" or \"Push and create PR?\")\n- On feature branch, never main/master (safety check)\n- Remote tracking configured (first push: `git push -u origin branch-name`)\n\n**Push heuristic**: Push when commits tell a coherent story. If you wouldn't want team to see this commit history, squash or amend locally first.\n\n**Safety verification before push**:\n-  `git branch --show-current`  main/master (block if true)\n-  Tests pass locally (don't use CI as test environment)\n-  No secrets in diff (`git diff` check for API keys, passwords)\n-  Commit message is clear (teammates can understand intent)\n\n**Ask user pattern**:\n```\n Commit succeeded: [SHA]\n\nOptions:\n1. Push to remote and create PR\n2. Push to remote only\n3. Leave local (manual push later)\n```\n\n### Create PR When Story is Coherent\n\n**When to create PR:**\n- User requests it (don't assumeask first)\n- Commits tell coherent story (not \"wip\", \"fix\", \"fix2\", \"actually fix\")\n- Quality metrics documented (coverage, tests, security scan)\n- PR body can be drafted from EPCC context\n\n**PR body dimensions** (draft from EPCC_CODE.md):\n- **Summary**: What changed, why it matters (1-2 sentences from EPCC_PLAN.md)\n- **Changes**: Key files modified, new functionality (from EPCC_CODE.md)\n- **Testing**: Test results, coverage metrics (from quality validation)\n- **Quality**: Security scan, linting, type checking results\n\n**PR title pattern**: `[type](scope): brief description` (matches commit message)\n\n**Use `gh` CLI**: `gh pr create --title \"...\" --body \"$(cat <<'EOF' ... EOF)\"`\n\n### Safety Checks Are Non-Negotiable\n\n**Before commit**:\n-  On feature branch (`git branch --show-current`)\n-  No secrets in diff (`git diff | grep -i \"api_key\\|password\\|secret\"`)\n-  Tests pass (`pytest` or equivalent)\n-  Changes are relevant (no accidental debug code, temp files)\n\n**Before push**:\n-  Not pushing to main/master (warn and block)\n-  Commits are atomic (each commit = working codebase state)\n-  Remote tracking exists (`git branch -vv`)\n\n**Before PR**:\n-  Quality gates passed (tests, coverage, security)\n-  PR body documents changes and testing\n-  Commit history is clean (squash \"fix typo\" commits if needed)\n\n### Git Command Reference (Appendix)\n\n**Review**: `git status`, `git diff`, `git diff --staged`, `git branch --show-current`\n**Stage**: `git add path/to/file.py`, `git diff --staged` (verify)\n**Commit**: `git commit -m \"$(cat <<'EOF'\\n[message]\\nEOF\\n)\"`, `git log -1 --oneline` (verify)\n**Push**: `git push` or `git push -u origin branch-name` (first time)\n**PR**: `gh pr create --title \"...\" --body \"...\"` (via heredoc for multi-line)\n\n**See**: Git documentation for command details. These heuristics focus on when/why, not command syntax.\n\n## Documentation\n\n### Phase 9: Generate EPCC_COMMIT.md\n\n**Forbidden patterns**:\n-  Comprehensive report for trivial commits (typo fix  detailed documentation)\n-  Documenting passed quality checks in detail (default: all passed, only document failures or notable findings)\n-  Ceremonial \"Next Steps\" for simple commits (default: merge when approved)\n-  PR information when PR not created (omit section if not applicable)\n\n**Documentation structure - 4 core dimensions**:\n\n```markdown\n# Commit: [Feature Name]\n\n**SHA**: [SHA] | **Branch**: [branch] | **Status**: [Committed/Pushed/PR]\n\n## 1. Summary ([X files], [+Y -Z lines])\n[1-2 sentences: what changed and why]\n\n**Files**: [file:line] - [Purpose]\n**Commit**: [type(scope): subject]\n\n## 2. Validation (Tests [X%] | Quality [Clean/Findings] | Security [Clean/Findings])\n**Tests**: [Status and coverage] - [X unit, Y integration]\n**Quality**: [Linting/typing/formatting status]\n**Security**: [Scan results or \"Clean\"]\n\n## 3. Changes Detail\n[Only for non-trivial commits - what's different from before]\n\n**Behavioral changes**: [New functionality or modified behavior]\n**Breaking changes**: [None / Describe]\n\n## 4. Completion\n**PR**: [URL if created, otherwise \"Local commit only\"]\n**Next**: [Deploy / Merge / Review / Specific action needed]\n```\n\n**Depth heuristic**:\n- **Trivial commit** (~100-200 tokens): Typo, formatting, simple fix\n  - Example: \"Fixed typo in README (1 file, +1 -1 lines). SHA: abc123. All checks passed.\"\n\n- **Standard commit** (~250-400 tokens): Feature, bug fix, refactor\n  - Example: All 4 dimensions with moderate detail - summary + validation results + key files + completion status\n\n- **Complex commit** (~500-700 tokens): Multi-file feature, architecture change\n  - Example: All 4 dimensions with comprehensive detail - full file breakdown + detailed validation + behavioral changes + PR information\n\n**Completeness heuristic**: Documentation is sufficient when you can answer:\n-  What was committed? (Summary with SHA)\n-  Does it meet quality gates? (Validation results)\n-  What changed specifically? (File breakdown)\n-  What happens next? (Completion status)\n\n**Anti-patterns**:\n-  **Typo fix with 600-token report**  Violates proportionality\n-  **Major feature with 150-token summary**  Missing critical detail\n-  **Listing every quality check when all passed**  Document only failures or notable items\n-  **\"Next: Standard deployment process\"**  Generic, specify actual next action\n\n---\n\n**Remember**: Match documentation depth to commit significance. Skip for trivial commits, comprehensive for complex ones.\n\n## Feature Verification Gate (Long-Running Project Support)\n\nIf `epcc-features.json` exists, apply additional verification gates for feature completion.\n\n### Pre-Commit Feature Check\n\nBefore committing, verify feature completion status:\n\n```bash\nif [ -f \"epcc-features.json\" ]; then\n    # Check which feature is being committed\n    # Verify all subtasks complete\n    # Verify acceptance criteria met\n    # Verify E2E tests passing\nfi\n```\n\n### Feature Verification Rules\n\n**For P0 (Must Have) features:**\n\n| Requirement | Action if Not Met |\n|-------------|-------------------|\n| All subtasks complete |  **BLOCK COMMIT** - Complete subtasks first |\n| All acceptance criteria verified |  **BLOCK COMMIT** - Run E2E verification |\n| `passes: true` in epcc-features.json |  **BLOCK COMMIT** - Verify before marking |\n| Test evidence documented |  **WARN** - Add screenshot/output reference |\n\n**For P1/P2 features:**\n\n| Requirement | Action if Not Met |\n|-------------|-------------------|\n| Feature incomplete |  **WARN** - Allow commit but document in message |\n| Some subtasks pending |  **WARN** - Track as deferred work |\n\n### Update Feature Status on Commit\n\nWhen committing a verified feature:\n\n```json\n{\n  \"features\": [\n    {\n      \"id\": \"F001\",\n      \"status\": \"verified\",\n      \"passes\": true,\n      \"verifiedAt\": \"[ISO timestamp]\",\n      \"commit\": \"[SHA]\",\n      \"subtasks\": [\n        {\"name\": \"...\", \"status\": \"complete\"},\n        {\"name\": \"...\", \"status\": \"complete\"}\n      ]\n    }\n  ]\n}\n```\n\n**Update fields:**\n- `status`: \"verified\"\n- `passes`: true\n- `verifiedAt`: Current timestamp\n- `commit`: Commit SHA\n- `subtasks[].status`: \"complete\" for all\n\n### Update Progress Log on Commit\n\nAppend commit entry to `epcc-progress.md`:\n\n```markdown\n---\n\n## Commit: feat(F001) - [Date Time]\n\n### Feature Completed\n- **F001**: User Authentication - VERIFIED\n\n### Quality Gates\n| Gate | Status |\n|------|--------|\n| Tests |  45/45 passing |\n| Coverage |  92% (target: 80%) |\n| Linting |  No errors |\n| Type Check |  Clean |\n| Security |  No vulnerabilities |\n\n### Commit Details\n- **SHA**: [abc123]\n- **Message**: feat(F001): Add user authentication - E2E verified\n- **Files**: 12 files changed, +450 -25\n\n### Progress Update\n- **Before**: 2/8 features (25%)\n- **After**: 3/8 features (37.5%)\n- **Next**: F002 - Task CRUD\n\n---\n```\n\n### Feature Completion Summary in EPCC_COMMIT.md\n\nAdd feature completion section to EPCC_COMMIT.md:\n\n```markdown\n## 5. Feature Completion Status\n\n| Feature | E2E Status | Commit |\n|---------|------------|--------|\n| F001: User Authentication |  VERIFIED | abc123 |\n| F002: Task CRUD |  VERIFIED | def456 |\n| F003: Task List View |  IN PROGRESS | - |\n\n**Progress**: 3/8 features (37.5%)\n- P0 completed: 3/4\n- P1 completed: 0/2\n- P2 completed: 0/2\n\n**Deferred to next session**:\n- F003: Task List View (2/5 subtasks complete)\n```\n\n### Commit Message Pattern for Features\n\nInclude feature reference in commit message:\n\n```bash\ngit commit -m \"feat(F001): Add user authentication - E2E verified\n\nSummary:\n- Implemented JWT-based authentication\n- Added login/logout endpoints\n- Created auth middleware\n- All acceptance criteria verified\n\nQuality:\n- Tests: 45 passing (12 new)\n- Coverage: 92%\n- Security: No vulnerabilities\n\nRefs: epcc-features.json#F001\"\n```\n\n### Progress Reporting After Commit\n\nAfter successful commit, report progress:\n\n```markdown\n## Commit Successful\n\n **Committed**: [SHA] - feat(F001): Add user authentication\n\n### Feature Status Updated\n- F001: User Authentication  VERIFIED\n\n### Progress\n- **Before**: 2/8 features (25%)\n- **After**: 3/8 features (37.5%)\n\n### Next Feature\n**Recommended**: F002 - Task CRUD (highest priority pending)\n\nStart with: `/epcc-code F002`\n```\n\n### All Features Complete\n\nWhen all features pass:\n\n```markdown\n##  Project Complete!\n\nAll features verified and passing:\n| Feature | Status |\n|---------|--------|\n| F001: User Auth |  VERIFIED |\n| F002: Task CRUD |  VERIFIED |\n| F003: Task List |  VERIFIED |\n| ... | ... |\n\n**Total**: 8/8 features (100%)\n**Ready for**: Deployment / PR merge / Release\n\n### Final Quality Summary\n- Tests: 120/120 passing\n- Coverage: 94%\n- Security: No vulnerabilities\n- All E2E acceptance criteria verified\n\n### Recommended Next Steps\n1. Create release tag: `git tag v1.0.0`\n2. Merge to main: `gh pr merge`\n3. Deploy to production\n```\n\n## Common Pitfalls (Anti-Patterns)\n\n###  Asking About Every Quality Failure\n**Don't**: \"Tests failed, should I fix?\"  **Do**: Auto-fix and re-run\n\n###  Following Template Rigidly\n**Don't**: Generate 200-line doc for 1-line fix  **Do**: Match detail to change size\n\n###  Over-Documenting Simple Commits\n**Don't**: Essay about typo fix  **Do**: Brief commit message, skip EPCC_COMMIT.md for trivial changes\n\n###  Asking About Standard Git Operations\n**Don't**: \"Should I run git status?\"  **Do**: Execute with safety checks\n\n###  Committing Without Quality Checks\n**Don't**: Skip tests to \"ship faster\"  **Do**: Run checks, fix failures, then commit\n\n###  Using git add . Blindly\n**Don't**: Stage everything  **Do**: Review and stage specific files\n\n## Second-Order Convergence Warnings\n\nEven with this guidance, you may default to:\n\n-  **Asking about every quality check failure** (auto-fix first - linting, formatting, simple bugs)\n-  **Following template structure rigidly** (adapt to change size - typo  feature)\n-  **Over-documenting simple commits** (1-line fix doesn't need comprehensive EPCC_COMMIT.md)\n-  **Asking permission for standard git operations** (execute with safety checks - git status, git diff, git commit)\n-  **Stopping at first test pass** (verify coverage, check for regression in other tests)\n-  **Committing on main/master** (always feature branch - warn if attempting main commit)\n\n## Error Recovery\n\n### Tests Failed\n\n```bash\n# Run tests to see failures\n[test-command]\n\n# Read error messages carefully\n# Common auto-fixes:\n# - Import errors  fix imports\n# - Syntax errors  fix syntax\n# - Type errors  add annotations\n# - Assertion failures  fix logic or update expected values\n\n# Re-run after fix\n[test-command]\n\n# If still failing after 2-3 attempts, ask user\n```\n\n### Coverage Below Target\n\n```bash\n# Generate coverage report\n[coverage-command]\n\n# Identify uncovered lines\n# Add tests for critical paths\n# Or document why coverage acceptable in EPCC_COMMIT.md\n\n# Re-run coverage\n[coverage-command]\n```\n\n### Linting/Formatting Issues\n\n```bash\n# Auto-fix\n[linter-command] --fix\n[formatter-command]\n\n# Re-run checks\n[linter-command]\n\n# If failures persist, check if legitimate exceptions\n# Add suppression comments with explanations\n```\n\n### Security Vulnerabilities\n\n```bash\n# Review findings from CODE phase (in EPCC_CODE.md)\n# If new vulnerabilities detected:\n\n# Low/Medium: Document, create follow-up issue\n# High: Fix before commit\n# Critical: Block commit, fix immediately\n\n# Re-run security scan if fixes applied\n```\n\n## Git Safety Principles\n\n**Before committing**:\n-  Verify on feature branch (not main/master)\n-  Review staged changes (git diff --staged)\n-  Check for sensitive data (no passwords, API keys, tokens)\n-  Stage relevant files only (explicit paths, not git add .)\n\n**Before pushing**:\n-  Verify not pushing to protected branch\n-  Create remote tracking if new branch (git push -u origin branch)\n-  Verify push succeeded (git status shows \"up to date\")\n\n**Before amending**:\n-  Check authorship (git log -1 --format='%an %ae' - only amend your own commits)\n-  Check not pushed (git status shows \"ahead\" not \"up to date with origin\")\n-  Never amend commits from other developers\n\n**Use git commands with safety checks**. Don't push to main/master without explicit user approval and warning.\n\n## Remember\n\n**Your role**: Automated quality validation and git workflow execution.\n\n**Work pattern**: Check  Fix  Verify  Commit  Document. Ask only when blocked.\n\n**Quality gates**: All checks pass before commit. No exceptions for broken code.\n\n**Git safety**: Feature branch, review changes, stage explicitly, commit with clear message.\n\n**Flexibility**: Adapt documentation detail to change size. Simple fix = simple commit.\n\n **Commit finalized. Implementation complete. Ready for review or deployment.**"
              },
              {
                "name": "/epcc-explore",
                "description": "Explore phase of EPCC workflow - understand thoroughly before acting",
                "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-explore.md",
                "frontmatter": {
                  "name": "epcc-explore",
                  "description": "Explore phase of EPCC workflow - understand thoroughly before acting",
                  "version": "3.2.0",
                  "argument-hint": "[area-to-explore] [--deep|--quick|--refresh]"
                },
                "content": "# EPCC Explore Command\n\nYou are in the **EXPLORE** phase of the Explore-Plan-Code-Commit workflow. Your mission is to understand thoroughly before taking any action.\n\n**Opening Principle**: High-quality exploration reveals not just what exists, but why it existsenabling confident forward decisions without re-discovery.\n\n@../docs/EPCC_BEST_PRACTICES.md - Comprehensive guide covering clarification strategies, error handling patterns, sub-agent delegation, and EPCC workflow optimization\n\n **IMPORTANT**: This phase is for EXPLORATION ONLY. Do NOT write any implementation code. Focus exclusively on:\n- Reading and understanding existing code\n- Analyzing patterns and architecture\n- Identifying constraints and dependencies\n- Documenting everything in EPCC_EXPLORE.md\n\nAll implementation will happen in the CODE phase.\n\n## Session Resume Detection (Long-Running Project Support)\n\n**On entry**, check for existing session state:\n\n### Step 1: Check for Progress File\n```\nif epcc-progress.md exists:\n    Parse last exploration session for this area\n```\n\n### Step 2: Detect Prior Exploration\n```python\n# Check if this exploration target was explored recently\nfor session in epcc_progress.sessions:\n    if session.phase == \"EXPLORE\" and session.target matches ARGUMENTS:\n        age = days_since(session.timestamp)\n        if age < 7:\n            # Recent exploration found\n            trigger_reuse_prompt(session)\n```\n\n### Step 3: Offer Reuse Option (If Applicable)\nIf prior exploration found within 7 days:\n\n```\n **Prior exploration found from [date]**:\n   Area: [exploration target]\n   Findings: [brief summary from EPCC_EXPLORE.md]\n   Files examined: [count]\n\n   Use existing exploration? [Y/n/refresh]\n   - Y: Load existing EPCC_EXPLORE.md, skip to recommendations\n   - n: Start fresh exploration (overwrites existing)\n   - refresh: Quick delta check (only new/changed files since last exploration)\n```\n\nUse AskUserQuestion tool:\n```json\n{\n  \"questions\": [{\n    \"question\": \"Prior exploration for this area found from [date]. How do you want to proceed?\",\n    \"header\": \"Prior Found\",\n    \"multiSelect\": false,\n    \"options\": [\n      {\n        \"label\": \"Use existing\",\n        \"description\": \"Load prior EPCC_EXPLORE.md findings, skip re-exploration\"\n      },\n      {\n        \"label\": \"Start fresh\",\n        \"description\": \"Full re-exploration from scratch (overwrites existing)\"\n      },\n      {\n        \"label\": \"Refresh delta\",\n        \"description\": \"Quick check for changes since last exploration\"\n      }\n    ]\n  }]\n}\n```\n\n### Step 4: Handle Response\n- **Use existing**: Load EPCC_EXPLORE.md, present summary, ask for next steps\n- **Start fresh**: Proceed with normal exploration flow (below)\n- **Refresh delta**: Run `git diff --stat [last_exploration_commit]..HEAD` to identify changed files, explore only those\n\n---\n\n## Exploration Target\n$ARGUMENTS\n\n### Exploration Thoroughness\n\nParse thoroughness level from arguments:\n- `--quick`: Fast surface-level exploration (key areas, basic patterns)\n- `--deep` or `--thorough`: Comprehensive analysis (multiple locations, cross-referencing, detailed patterns)\n- **Default** (no flag): Medium thoroughness (balanced exploration)\n\n##  Autonomous Exploration Mode\n\nThis command operates as an **autonomous exploration agent**, similar to Claude Code's Explore subagent:\n\n### Exploration Characteristics\n\n1. **Self-Directed Search**: Automatically tries multiple search strategies if initial attempts don't find relevant information\n2. **Comprehensive Coverage**: Systematically explores all relevant areas without needing step-by-step guidance\n3. **Pattern Recognition**: Identifies and documents coding patterns, architectural decisions, and conventions\n4. **Persistent Investigation**: Doesn't give up easily - tries different file patterns, search terms, and approaches\n5. **Complete Report**: Delivers a single, comprehensive exploration report in EPCC_EXPLORE.md\n\n## When to Ask Questions\n\nThis phase is designed to be **autonomous** - you should explore independently without frequent user interaction.\n\n### Rarely Ask (Exploration is Self-Directed)\n\n **Only ask when:**\n- **Exploration target is genuinely unclear** (\"explore authentication\" but no auth code found anywhere)\n- **Multiple conflicting patterns exist** and unclear which is canonical\n- **Completely blocked** after trying multiple search strategies\n- **Critical information is missing** that prevents meaningful exploration (e.g., can't access certain directories)\n\n **Don't ask when:**\n- First search doesn't find something (try alternative approaches first)\n- Multiple patterns exist (document all of them)\n- Code is messy or unclear (document what you find)\n- You're unsure which pattern is best (document options, let PLAN decide)\n- Exploration is taking longer than expected (be thorough)\n\n### Problem-Solving Approach\n\n**Instead of asking, try:**\n\n1. **Multiple search strategies**: If `grep authentication` fails, try `grep auth`, `find . -name \"*auth*\"`, check common directories\n2. **Follow the trail**: Found one file? Check its imports, look for similar files in same directory\n3. **Document uncertainty**: \"Pattern X found in 3 places, Pattern Y in 2 places. Both appear active.\"\n4. **Note gaps**: \"No authentication code found after checking [list of searches]. This appears to be a greenfield area.\"\n\n### When to Use AskUserQuestion Tool\n\n**Almost never in EXPLORE phase.** This phase is autonomous by design.\n\n**Rare exception**: If exploration target is ambiguous AND you've tried reasonable interpretations:\n```\nUser: \"explore the payment system\"\nYou've searched: payment*, billing*, transaction*, checkout*, stripe*, paypal*\nFound: Nothing related to payments\nThen ask: \"I searched extensively but found no payment-related code. Should I:\n  - Explore a different area?\n  - Treat this as greenfield (no existing payment code)?\n  - Search with different terms?\"\n```\n\n### Clarification Pattern\n\n**Pattern: Try  Try  Try  Document**\n```\n1. Try search approach A  No results\n2. Try search approach B  No results\n3. Try search approach C  No results\n4. Document: \"Searched for X using [approaches]. No matches found. This appears greenfield.\"\n```\n\nNOT: ~~Try once  Ask user~~\n\nRemember: You're an **autonomous explorer**. Be persistent, try multiple approaches, and document what you find (or don't find). Save questions for genuine blockers, not first obstacles.\n\n## Handling Ambiguity (CRITICAL)\n\n**EXPLORE phase is autonomous by design - avoid asking questions unless truly blocked.**\n\nBefore escalating to AskUserQuestion, ensure you've exhausted autonomous exploration:\n\n### Unclear Exploration Target?\n\n**Try multiple interpretations first:**\n\n```\nUser: \"explore the payment system\"\n\nStep 1: Try broad searches\n- grep -r \"payment\" .\n- find . -name \"*payment*\"\n- grep -r \"billing\\|transaction\\|checkout\" .\n\nStep 2: Try platform-specific patterns\n- Stripe: grep -r \"stripe\"\n- PayPal: grep -r \"paypal\"\n- Generic: grep -r \"charge\\|invoice\\|subscription\"\n\nStep 3: Check configuration\n- Look for API keys in .env files\n- Check package.json/requirements.txt for payment libraries\n\nStep 4: Document findings\nIf nothing found: \"Searched extensively (payment*, billing*, stripe*, etc.). No payment code found. This appears to be a greenfield area.\"\nIf multiple found: \"Found two payment implementations: legacy (src/billing/) and new (src/payments/). Both appear active.\"\n```\n\n**Only ask if genuinely blocked:**\n\nUse AskUserQuestion tool with proper format:\n```json\n{\n  \"questions\": [{\n    \"question\": \"I found no payment-related code after extensive searching. How should I proceed?\",\n    \"header\": \"Next Step\",\n    \"multiSelect\": false,\n    \"options\": [\n      {\n        \"label\": \"Treat as greenfield\",\n        \"description\": \"Document that no payment code exists yet\"\n      },\n      {\n        \"label\": \"Different search terms\",\n        \"description\": \"Provide specific terms or file paths to search\"\n      },\n      {\n        \"label\": \"Different feature area\",\n        \"description\": \"Explore a different part of the codebase instead\"\n      }\n    ]\n  }]\n}\n```\n\n### Multiple Conflicting Patterns Exist?\n\n**Document all patterns, don't ask which to choose:**\n\n```markdown\n## 8. Multiple Patterns Found\n\n**Authentication Implementation:**\n\nPattern A: JWT-based (src/auth/jwt/)\n- Used in: API endpoints (3 files)\n- Last modified: 2025-10-15\n- Pros: Stateless, scalable\n- Status: Appears to be current standard\n\nPattern B: Session-based (src/auth/sessions/)\n- Used in: Legacy admin panel (2 files)\n- Last modified: 2024-03-20\n- Pros: Simpler\n- Status: Possibly deprecated (no recent changes)\n\n**Recommendation**: Pattern A (JWT) appears to be the current standard based on recent activity.\n```\n\n**See Also**: EPCC_BEST_PRACTICES.md  \"Clarification Decision Framework\"\n\n### Exploration Strategy\n\n**BE SYSTEMATIC AND THOROUGH:**\n\n1. **Try multiple search approaches** if first attempt yields no results:\n   - Different file patterns (*.py, *auth*, authentication*)\n   - Various naming conventions (camelCase, snake_case, kebab-case)\n   - Related terms and synonyms\n   - Directory-specific searches\n\n2. **Follow the trail**:\n   - If you find a relevant file, check its imports/dependencies\n   - Look for related files in the same directory\n   - Search for similar patterns in other modules\n   - Trace relationships between components\n\n3. **Be comprehensive**:\n   - Don't stop at the first match\n   - Explore multiple examples of the same pattern\n   - Check both implementation and test files\n   - Review configuration and documentation\n\n4. **Document as you go**:\n   - Track what you've searched and what you found\n   - Note patterns and conventions\n   - Identify gaps or unclear areas\n   - Record assumptions that need validation\n\n##  Exploration Objectives\n\n1. **Review Project Instructions**: Check for CLAUDE.md files with project-specific guidance\n2. **Map the Territory**: Understand project structure and architecture\n3. **Identify Patterns**: Find coding conventions and design patterns\n4. **Discover Constraints**: Technical, business, and operational limitations\n5. **Review Similar Code**: Find existing implementations to learn from\n6. **Assess Complexity**: Understand the scope and difficulty\n7. **Document Dependencies**: Map internal and external dependencies\n8. **Evaluate Test Coverage**: Understand testing approaches and gaps\n\n## Thoroughness-Based Exploration Heuristics\n\n### Completion Criteria (NOT File Count Targets)\n\n**Stop exploring when objectives are met**, not when you hit arbitrary file counts.\n\n### Quick Exploration (--quick)\n**Stop when you understand:**\n- Entry points and main flow\n- 2-3 key patterns that dominate the codebase\n- Basic tech stack and dependencies\n- CLAUDE.md instructions (if present)\n\n**Typical indicators you're done:**\n- Can explain project structure in 2-3 sentences\n- Identified dominant framework and language\n- Found 1-2 similar implementations to learn from\n\n### Medium Exploration (default)\n**Stop when you understand:**\n- All major architectural patterns with examples\n- Cross-module relationships and data flow\n- Test patterns and coverage approach\n- Configuration and deployment approach\n\n**Typical indicators you're done:**\n- Can draw component diagram from memory\n- Identified 3-5 reusable patterns/components\n- Understand how features flow end-to-end\n\n### Deep Exploration (--deep/--thorough)\n**Stop when you've exhaustively documented:**\n- All patterns with multiple examples each\n- Complete dependency tree (internal + external)\n- Historical context and technical debt areas\n- Edge cases and performance considerations\n- Security patterns and compliance requirements\n\n**Typical indicators you're done:**\n- Can onboard new developer from your exploration alone\n- Documented every architectural decision\n- Identified all constraints and risks\n\n**Heuristic Rule**: If reading another file of the same type teaches you nothing new, you're done with that pattern.\n\n## Parallel Exploration Subagents (Optional for Complex Exploration)\n\nFor **very large codebases or complex exploration tasks**, you MAY deploy specialized exploration agents **in parallel to save time**.\n\n**Launch simultaneously** (all in same response):\n\n```\n#  GOOD: Parallel exploration (agents explore different aspects)\n@code-archaeologist Analyze authentication system architecture and data flow.\n\nTarget: Authentication implementation across codebase\nFocus areas:\n- Token generation and validation flow\n- Session management approach\n- Password hashing implementation\n- Rate limiting mechanisms\n\nTrace: User login  token creation  validation  protected endpoint access\nDocument: Component interactions, data flow, security patterns, technical debt areas.\n\n@system-designer Document authentication system architecture and component design.\n\nTarget: Authentication system structure\nAnalyze:\n- Component boundaries and responsibilities\n- Service layer architecture\n- Database schema for auth\n- API endpoint design\n\nGenerate: Architecture diagram, component relationships, data models, integration points.\n\n@business-analyst Identify authentication business requirements and user workflows.\n\nTarget: Authentication feature scope and purpose\nAnalyze:\n- User registration and login flows\n- Password reset mechanisms\n- Multi-factor authentication support\n- Role-based access control\n\nDocument: User stories, business rules, workflow diagrams, requirement gaps.\n\n# All three explore different aspects concurrently\n```\n\n**Available agents:**\n@code-archaeologist @system-designer @business-analyst @test-generator @documentation-agent\n\n**Full agent reference**: See `../docs/EPCC_BEST_PRACTICES.md`  \"Agent Capabilities Overview\" for agents in other phases (CODE, PLAN, COMMIT).\n\n**IMPORTANT**: Only use subagents for codebases with 100+ files or highly complex systems. For typical projects, handle exploration directly and autonomously.\n\n## Exploration Methodology\n\n### Phase 1: Project Context & Instructions\n\n**ALWAYS START HERE:**\n\nCheck for CLAUDE.md files in this order:\n1. Project root CLAUDE.md\n2. .claude/CLAUDE.md\n3. User global ~/.claude/CLAUDE.md\n\nDocument ALL instructions found - these are mandatory requirements for the project.\n\n### Phase 2: Project Structure Discovery\n\nUse multiple approaches to understand structure:\n- Directory listings (ls, tree if available)\n- File finding (find, Glob)\n- Key file identification (entry points, configs)\n\nAdapt if one approach fails - try another.\n\n### Phase 3: Technology Stack Identification\n\nSystematically check for different project types:\n- Python: pyproject.toml, requirements.txt, setup.py, Pipfile, poetry.lock\n- JavaScript/TypeScript: package.json, tsconfig.json, yarn.lock, pnpm-lock.yaml\n- Other languages: Gemfile, pom.xml, build.gradle, Cargo.toml, go.mod, composer.json\n\nDocument frameworks, libraries, versions, and tools found.\n\n### Phase 4: Pattern Recognition (Multi-Strategy Search)\n\n**Use persistent, multi-attempt searching:**\n\nExample: Finding authentication patterns\n1. Direct file search: `find . -name \"*auth*\"`\n2. Content search: `grep -r \"authenticate|login|session\"`\n3. Class/function search: `grep -r \"class.*Auth|def.*login\"`\n4. Import search: `grep -r \"from.*auth import\"`\n5. Directory check: `ls src/auth/ app/auth/`\n\n**Document what you tried and what worked:**\n- Track successful search strategies\n- Note what didn't work and why\n- Record patterns found with file locations\n\n### Phase 5: Architectural Pattern Discovery\n\nLook for common patterns systematically:\n- MVC/MVT Pattern\n- Repository Pattern\n- Service Layer Pattern\n- Factory Pattern\n- Middleware/Decorator Pattern\n- Observer/Event Pattern\n\nDocument each pattern with:\n- Where it's used (file paths)\n- How many implementations\n- Example usage\n- When to use it\n\n### Phase 6: Dependency Mapping\n\nTrace both external and internal dependencies:\n- **External**: From package manifests (package.json, requirements.txt, etc.)\n- **Internal**: Module imports, component relationships, data flow\n\nCreate dependency graphs showing relationships.\n\n### Phase 7: Constraint & Risk Identification\n\nActively search for constraints:\n- Performance constraints (timeouts, rate limits, caching)\n- Security constraints (CORS, CSRF, authentication, encryption)\n- Version constraints (language versions, compatibility)\n- Environment constraints (env vars, deployment requirements)\n\n### Phase 8: Similar Implementation Search\n\nIf exploring a specific feature, find similar existing code:\n- Search for related functionality\n- Find integration examples\n- Review existing third-party integrations\n- Identify reusable components\n\n## Exploration Deliverables\n\n### Output File: EPCC_EXPLORE.md\n\nGenerate exploration report in `EPCC_EXPLORE.md` with depth matching scope.\n\n### Report Structure - 5 Core Dimensions\n\n**Forbidden patterns**:\n-  Filling template sections with \"N/A\" or \"Not found\" (omit irrelevant sections)\n-  Rigid 12-section structure for simple codebases (adapt to complexity)\n-  Documenting every file read (focus on patterns and decisions)\n-  Generic descriptions (\"uses standard patterns\") - be specific\n\n**Document these dimensions** (depth varies by scope):\n\n```markdown\n# Exploration: [Area/Feature]\n\n**Date**: [Date] | **Scope**: [Quick/Medium/Deep] | **Status**:  Complete\n\n## 1. Foundation (What exists)\n**Tech stack**: [Language, framework, versions]\n**Architecture**: [Pattern family - \"Express REST API\", \"Django monolith\", \"React SPA + FastAPI\"]\n**Structure**: [Entry points, key directories with purpose]\n**CLAUDE.md instructions**: [Critical requirements found]\n\n## 2. Patterns (How it's built)\n[Name pattern families, not every instance]\n\n**Architectural patterns**:\n- [Pattern name]: [Where used - file:line], [When to use]\n\n**Testing patterns**:\n- [Test framework + approach]: [Fixture patterns, mock strategies]\n- **Coverage**: [X%], **Target**: [Y%]\n\n**Error handling**: [Exit codes, stderr usage, agent compatibility - see EPCC_BEST_PRACTICES.md]\n\n## 3. Constraints (What limits decisions)\n**Technical**: [Language versions, platform requirements]\n**Quality**: [Test coverage targets, linting rules, type checking]\n**Security**: [Auth patterns, input validation, known gaps]\n**Operational**: [Deployment requirements, CI/CD, monitoring]\n\n## 4. Reusability (What to leverage)\n[Only if implementing similar feature]\n\n**Similar implementations**: [file:line references]\n**Reusable components**: [What can be copied vs adapted]\n**Learnings**: [What worked, what to avoid]\n\n## 5. Handoff (What's next)\n**For PLAN**: [Key constraints, existing patterns to follow]\n**For CODE**: [Tools/commands to use - test runner, linter, formatter]\n**For COMMIT**: [Quality gates - coverage target, security checks]\n**Gaps**: [Unclear areas requiring clarification]\n```\n\n**Adaptation heuristic**:\n- **Quick scope** (~150-300 tokens): Foundation + critical constraints only\n- **Medium scope** (~400-600 tokens): Foundation + patterns + constraints + handoff\n- **Deep scope** (~800-1,500 tokens): All 5 dimensions with comprehensive detail\n\n**Completeness heuristic**: Report is complete when you can answer:\n-  What tech stack and patterns must I follow?\n-  What quality gates must I pass?\n-  What can I reuse vs build new?\n-  What constraints limit my choices?\n\n**Anti-patterns**:\n-  **Quick scope with 1,500 tokens**  Violates scope contract\n-  **Deep scope with 200 tokens**  Insufficient for complex codebase\n-  **Listing every file**  Name directory patterns instead\n-  **Generic \"uses testing\"**  Specify framework, fixture patterns, coverage\n\n---\n\n**End of template guidance**\n\n**Important**: Fill each section with **actual findings** from your exploration, not placeholders or examples. Include:\n- Specific file paths with line numbers\n- Actual code patterns found\n- Real metrics and statistics\n- Concrete recommendations based on what you discovered\n\n## Common Pitfalls (Anti-Patterns)\n\n###  Giving Up After First Search Fails\n**Don't**: Search once, ask user  **Do**: Try 3-5 search strategies before concluding\n\n###  Hitting File Count Instead of Understanding\n**Don't**: Read 10 files because target says \"~10\"  **Do**: Stop when pattern is understood\n\n###  Skipping CLAUDE.md Files\n**Don't**: Jump straight to code  **Do**: Read CLAUDE.md first (critical project requirements)\n\n###  Documenting Only \"Happy Path\" Patterns\n**Don't**: Document only what works well  **Do**: Document edge cases, error handling, constraints\n\n###  Treating Exploration as Code Review\n**Don't**: Judge code quality  **Do**: Document what exists objectively\n\n###  Asking User to Clarify Obvious Search Targets\n**Don't**: \"What do you mean by authentication?\"  **Do**: Try auth*, login*, session*, JWT patterns first\n\n## Second-Order Convergence Warnings\n\nEven with this guidance, you may default to:\n\n-  **Stopping at first pattern match** (one test file  understanding test patterns - read 3-5 examples)\n-  **Reading exactly N files per mode** (file count  understanding - stop when objectives met)\n-  **Asking about every ambiguity** (document multiple patterns, let PLAN decide)\n-  **Documenting only implementation files** (tests, configs, docs reveal critical context)\n-  **Shallow pattern documentation** (don't just list patterns - explain when/why/how to use each)\n-  **Treating modes as rigid procedures** (modes are calibration, adapt to actual codebase complexity)\n\n## Exploration Best Practices\n\n### DO:\n-  **Try multiple search strategies** if first attempt fails\n-  **Read CLAUDE.md files first** - they contain critical requirements\n-  **Document your search process** - helps identify gaps\n-  **Follow the trail** - check imports and related files\n-  **Be comprehensive** - explore multiple examples of patterns\n-  **Note what you DON'T find** - gaps are important information\n-  **Provide file references** - specific line numbers help later phases\n\n### DON'T:\n-  **Give up after one search** - try different terms and patterns\n-  **Skip CLAUDE.md** - missing project requirements causes rework\n-  **Assume patterns** - verify with actual code examples\n-  **Ignore test files** - they reveal intended behavior\n-  **Write code** - this is exploration only\n-  **Leave gaps undocumented** - note what's missing or unclear\n\n## Exploration Checklist\n\nBefore finalizing EPCC_EXPLORE.md:\n\n**Context & Instructions**:\n- [ ] Checked for CLAUDE.md in project root\n- [ ] Checked for .claude/CLAUDE.md\n- [ ] Checked for ~/.claude/CLAUDE.md\n- [ ] Documented all project-specific requirements\n\n**Structure & Technology**:\n- [ ] Project structure fully mapped\n- [ ] Entry points identified\n- [ ] Technology stack documented\n- [ ] All dependencies listed (external + internal)\n\n**Patterns & Conventions**:\n- [ ] Coding patterns documented (with examples)\n- [ ] Naming conventions identified\n- [ ] Architectural patterns mapped\n- [ ] Team conventions understood\n\n**Code Quality**:\n- [ ] Testing approach understood\n- [ ] Test coverage assessed\n- [ ] Code quality tools identified\n\n**Constraints & Risks**:\n- [ ] Technical constraints documented\n- [ ] Business constraints identified\n- [ ] Security patterns reviewed\n- [ ] Performance requirements understood\n- [ ] Gaps and risks documented\n\n**Similar Implementations**:\n- [ ] Related code found and reviewed\n- [ ] Reusable components identified\n- [ ] Patterns to follow documented\n\n**Completeness**:\n- [ ] Search strategies documented\n- [ ] Information gaps identified\n- [ ] Recommendations provided\n- [ ] Next steps outlined\n\n## Usage Examples\n\n```bash\n# Quick exploration of entire codebase\n/epcc-explore --quick\n\n# Medium exploration (default) of specific area\n/epcc-explore authentication\n\n# Deep exploration of specific feature\n/epcc-explore payment-processing --deep\n\n# Thorough exploration of multiple areas\n/epcc-explore \"API routes and database models\" --thorough\n```\n\n## Integration with Other Phases\n\n### To PLAN Phase:\n- EPCC_EXPLORE.md provides complete context\n- Patterns to follow documented\n- Constraints identified\n- Similar implementations found\n\n### To CODE Phase:\n- Conventions to follow established\n- Reusable components identified\n- Test patterns documented\n- File organization understood\n\n### To COMMIT Phase:\n- Project standards documented\n- Team conventions known\n- Required checks identified\n\n## Session Exit: Progress Logging (Long-Running Project Support)\n\n**Before completing exploration**, update the progress log:\n\n### Step 1: Update epcc-progress.md\n\nIf `epcc-progress.md` exists (long-running project):\n\n```markdown\n## Session: EXPLORE - [timestamp]\n**Target**: [exploration area from ARGUMENTS]\n**Thoroughness**: [quick|medium|deep]\n**Duration**: [approximate time spent]\n\n### Areas Explored\n- [area 1]: [brief finding]\n- [area 2]: [brief finding]\n\n### Key Patterns Found\n- [pattern]: [location]\n\n### Files Examined\n[count] files across [count] directories\n\n### Handoff Notes\n- Ready for: [PLAN/CODE phase]\n- Blockers: [any issues encountered]\n- Follow-up: [anything to investigate further]\n\n### Git State\n- Commit: [current HEAD short hash]\n- Branch: [current branch]\n- Clean: [yes/no]\n```\n\n### Step 2: Append Session Entry\n\n```python\n# Pseudo-code for progress update\nsession_entry = {\n    \"timestamp\": now(),\n    \"phase\": \"EXPLORE\",\n    \"target\": ARGUMENTS,\n    \"thoroughness\": detected_level,\n    \"output_file\": \"EPCC_EXPLORE.md\",\n    \"files_examined\": count,\n    \"patterns_found\": count,\n    \"git_commit\": HEAD_short\n}\nappend_to_progress_log(session_entry)\n```\n\n### Step 3: Report Completion\n\n```\n Exploration complete!\n\n **Output**: EPCC_EXPLORE.md\n **Coverage**: [X] files examined, [Y] patterns documented\n **Progress**: Session logged to epcc-progress.md\n\n**Recommended next phase**: /epcc-plan [feature-based-on-exploration]\n```\n\n---\n\n## Remember\n\n**Time spent exploring saves time coding!**\n\n **DO NOT**: Write code, create files, implement features, fix bugs, or modify anything\n\n **DO**: Be persistent, try multiple approaches, follow the trail, document thoroughly, save to EPCC_EXPLORE.md\n\n---\n\n## Long-Running Project Integration\n\nThis command integrates with the EPCC long-running project tracking system:\n\n| Artifact | Role in EXPLORE |\n|----------|-----------------|\n| `epcc-features.json` | Read to understand feature context |\n| `epcc-progress.md` | Read prior sessions, write completion log |\n| `EPCC_EXPLORE.md` | Primary output document |\n\n**Session continuity**: If context runs low during exploration:\n1. Save current findings to EPCC_EXPLORE.md (partial)\n2. Log session to epcc-progress.md with \"Status: Partial\"\n3. Note remaining areas to explore\n4. Next session can `/epcc-resume` then continue with `/epcc-explore --refresh`"
              },
              {
                "name": "/epcc-plan",
                "description": "Plan phase of EPCC workflow - strategic design before implementation",
                "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-plan.md",
                "frontmatter": {
                  "name": "epcc-plan",
                  "description": "Plan phase of EPCC workflow - strategic design before implementation",
                  "version": "3.1.0",
                  "argument-hint": "[feature-or-task-to-plan]"
                },
                "content": "# EPCC Plan Command\n\nYou are in the **PLAN** phase of the Explore-Plan-Code-Commit workflow. Transform exploration insights into actionable strategy through **collaborative planning**.\n\n**Opening Principle**: High-quality plans transform ambiguity into executable tasks by surfacing hidden assumptions and documenting decisions with their rationale.\n\n@../docs/EPCC_BEST_PRACTICES.md - Comprehensive guide covering clarification strategies, error handling planning, sub-agent delegation patterns, and interactive phase best practices\n\n **IMPORTANT**: This phase is for PLANNING ONLY. Do NOT write implementation code. Focus on:\n- Creating detailed plans\n- Breaking down tasks\n- Assessing risks\n- Documenting in EPCC_PLAN.md\n\nImplementation happens in CODE phase.\n\n## Planning Target\n$ARGUMENTS\n\n##  Planning Philosophy\n\n**Core Principle**: Draft  Present  Iterate  Finalize only after approval. Plans are collaborative, not dictated.\n\n### Planning Workflow\n\n1. **Clarify**  Understand requirements (ask questions if unclear)\n2. **Draft**  Create initial plan with documented assumptions\n3. **Present**  Share plan for review\n4. **Iterate**  Refine based on feedback\n5. **Finalize**  Lock down plan only after user approval\n\n**Never finalize without user review.**\n\n## Clarification Strategy\n\n### When to Ask Questions\n\n** Ask when:**\n- Requirements vague or ambiguous (\"improve performance\"  how much? where?)\n- Multiple valid approaches exist (which to choose?)\n- Ambiguous scope boundaries (what's in/out?)\n- Trade-offs need decisions (complexity vs performance? speed vs quality?)\n- User preferences unknown (which option?)\n\n** Don't ask when:**\n- EPCC_EXPLORE.md already documents it (read first)\n- PRD.md already clarified it (check product requirements if available)\n- TECH_REQ.md already defined it (check technical decisions if available)\n- It's an implementation detail (defer to CODE phase)\n- You can document multiple options (present alternatives in plan)\n\n### Question Patterns\n\n**Check context files first**: Read EPCC_EXPLORE.md (brownfield) + PRD.md (product) + TECH_REQ.md (technical)  use found context  ask about gaps only\n\n**Draft-driven**: Create draft with documented assumptions  present  iterate  finalize only after approval\n\n**Technical decisions**: 2-4 clear options  use AskUserQuestion if needed  avoid asking about code-level details\n\n## Context Gathering\n\nCheck for available context sources:\n\n```bash\n# Brownfield: Use exploration findings\nif [ -f \"EPCC_EXPLORE.md\" ]; then\n    # Read: Tech stack, patterns, testing approach, constraints\n    # Follow: Existing architecture patterns, reuse identified components\nfi\n\n# Greenfield: Use best practices\nelse\n    # Read: Tech stack from PRD.md, TECH_REQ.md, or user input\n    # Apply: Industry best practices, standard patterns\nfi\n\n# Check product requirements\nif [ -f \"PRD.md\" ]; then\n    # Use: Requirements, user stories, acceptance criteria, features\nelif [ -f \"EPCC_PRD.md\" ]; then\n    # Legacy file name support\nelse\n    # Gather product requirements from user input\nfi\n\n# Check technical requirements\nif [ -f \"TECH_REQ.md\" ]; then\n    # Use: Architecture decisions, tech stack rationale, data models, integrations, security approach, performance strategy\nfi\n```\n\n**Extract key information:**\n- **Brownfield**: Existing patterns from EPCC_EXPLORE.md, tech stack, constraints, similar implementations\n- **Greenfield**: Tech stack from TECH_REQ.md (if available), product requirements from PRD.md (if available), industry best practices\n- **Either**: Requirements, acceptance criteria, constraints, technical decisions\n\n## Planning Framework\n\n### Step 1: Define Objectives\n\n**What are we building and why?**\n\n- Clear goal statement\n- Problem being solved\n- Success criteria (how will we know it's done?)\n- User value delivered\n\n### Step 2: Break Down Tasks\n\n**Principles:**\n- Break into <4 hour chunks (testable units of work)\n- Identify dependencies (what must happen first?)\n- Assess risk (what could go wrong?)\n- Estimate realistically (when in doubt, double estimate)\n\n**Pattern** (adapt to your plan):\n```markdown\n## Task Breakdown\n\n### Phase 1: Foundation (~X hours)\n1. **Task Name** (Xh)\n   - What it does\n   - Dependencies: [None / Task Y must complete first]\n   - Risk: [Low/Medium/High - what could go wrong]\n   - Estimated effort\n\n2. **Task Name** (Xh)\n   - Description\n   - Dependencies\n   - Risk\n   - Estimate\n\n### Phase 2: Core Implementation (~X hours)\n...\n```\n\n**Anti-Patterns:**\n-  Tasks too large (>1 day = break down further)\n-  Missing dependencies (creates blocking issues)\n-  Ignoring risk (complex areas need buffers)\n-  Unrealistic estimates (hope is not a strategy)\n\n### Step 3: Design Technical Approach\n\n**High-level architecture**:\n- Component structure (how pieces fit together)\n- Data flow (how information moves)\n- Integration points (external systems, APIs)\n- Technology choices (justified with rationale)\n\n**If EPCC_EXPLORE.md exists**: Follow existing patterns (brownfield)\n**If TECH_REQ.md exists**: Use architecture decisions and tech stack from TRD\n**If greenfield without TRD**: Design from PRD + industry best practices\n\n### Step 4: Identify Risks\n\n**What could go wrong?**\n\n| Risk | Impact | Likelihood | Mitigation |\n|------|--------|------------|------------|\n| [Risk description] | H/M/L | H/M/L | [How to address/prevent] |\n\n**Common risk categories:**\n- Technical (new technology, complexity, integration)\n- Timeline (estimates off, dependencies blocking)\n- Requirements (changing scope, unclear needs)\n- Resources (team capacity, budget constraints)\n\n### Step 5: Define Test Strategy\n\n**How will we verify it works?**\n\n- Unit tests (what components to test)\n- Integration tests (what interactions to verify)\n- Edge cases (boundary conditions, error scenarios)\n- Acceptance criteria (from PRD or user requirements)\n\n## Trade-Off Decision Framework\n\n**When multiple approaches exist:**\n\n1. **Identify dimensions**: Performance, complexity, maintainability, time-to-ship, scalability\n2. **Map each option** against dimensions\n3. **Weight by priorities** (from PRD or user input)\n4. **Present analysis**, let user decide (you recommend, they choose)\n\n**Common trade-offs:**\n- **Speed vs Quality**: MVP mindset vs production-grade\n- **Simple vs Scalable**: Start simple, refactor later vs design for scale now\n- **Build vs Buy**: Custom solution vs third-party (maintenance burden vs flexibility)\n- **Performance vs Complexity**: Optimize now vs ship fast, optimize later\n- **Flexibility vs Simplicity**: Configurable/extensible vs focused/opinionated\n\n**Pattern:**\n```\nWe have 3 approaches for [decision]:\n\nOption A: [Technology/Approach]\n- Pros: [Benefits]\n- Cons: [Tradeoffs]\n- Best for: [When to use]\n\nOption B: [Technology/Approach]\n- Pros: [Benefits]\n- Cons: [Tradeoffs]\n- Best for: [When to use]\n\nOption C: [Technology/Approach]\n- Pros: [Benefits]\n- Cons: [Tradeoffs]\n- Best for: [When to use]\n\nGiven your [requirements/priorities], I recommend [Option]. What do you think?\n```\n\n## When to Push Back on Requirements\n\n** Challenge when:**\n- Estimate significantly exceeds timeline (identify scope reduction)\n- Requirements conflict with each other (clarify priorities)\n- Technical approach violates constraints from EPCC_EXPLORE.md\n- Security/quality trade-offs are risky\n- Scope creep detected (features added without timeline adjustment)\n\n** Don't push back on:**\n- User preferences for technology choices (unless clear technical blocker)\n- Ambitious goals (help break into phases instead of saying \"impossible\")\n- Requests for explanation (transparency builds trust)\n\n**How to push back constructively:**\n```\n\"I want to make sure we set realistic expectations. [Issue description].\n\nWe have options:\n1. Reduce scope to [core features] to meet timeline\n2. Extend timeline to [X weeks] for full feature set\n3. Phased rollout: [MVP now] + [enhancements later]\n\nWhat's most important for this project?\"\n```\n\n## Parallel Planning Subagents (Optional)\n\nFor **very complex planning tasks**, deploy specialized planning agents **in parallel**:\n\n**When to use:**\n- Complex system architecture design\n- Multi-technology evaluation\n- Large-scale security threat modeling\n\n**Launch simultaneously** (all in same response):\n\n```markdown\n@system-designer Design high-level architecture for [feature].\n\nContext:\n- Project: [type and tech stack]\n- Framework: [from EPCC_EXPLORE.md]\n- Current architecture: [existing patterns]\n\nRequirements (from PRD.md if available):\n- [Functional requirements]\n- [Non-functional requirements]\n\nConstraints from EPCC_EXPLORE.md:\n- [Existing patterns to follow]\n- [Integration points]\n\nDesign: Component structure, data flow, integration points\n\nDeliverable: Architecture diagram, component descriptions, scalability considerations\n```\n\n**See**: `../docs/EPCC_BEST_PRACTICES.md`  \"Sub-Agent Decision Matrix\" for when to delegate vs plan yourself.\n\n## EPCC_PLAN.md Output\n\n**Forbidden patterns**:\n-  Exhaustive task breakdown for simple features (2-task feature  20-section plan)\n-  Detailed architecture diagrams for minor changes (adding button  system design doc)\n-  Rigid template sections with \"N/A\" or \"TBD\" (omit irrelevant sections)\n-  Over-specifying implementation details (leave room for CODE phase creativity)\n\n**Plan structure - 4 core dimensions + risk**:\n\n```markdown\n# Plan: [Feature Name]\n\n**Created**: [Date] | **Effort**: [Xh] | **Complexity**: [Simple/Medium/Complex]\n\n## 1. Objective\n**Goal**: [What we're building - 1 sentence]\n**Why**: [Problem solved - user value]\n**Success**: [2-3 measurable criteria]\n\n## 2. Approach\n[High-level how - architectural pattern, tech stack choices with rationale]\n\n**From EPCC_EXPLORE.md**: [Patterns to follow, constraints to respect] (if brownfield)\n**From TECH_REQ.md**: [Architecture, tech stack, data models, integrations] (if available)\n**From PRD.md**: [Product requirements informing technical approach] (if available)\n**Integration points**: [External systems, existing components]\n**Trade-offs**: [Decision made | Rationale | Alternatives considered]\n\n## 3. Tasks\n[Break into <4hr chunks, identify dependencies, assess risk]\n\n**Phase N: [Name]** (~Xh)\n1. [Task] (Xh) - [Brief description] | Deps: [None/Task X] | Risk: [L/M/H]\n\n**Total**: ~Xh\n\n## 4. Quality Strategy\n**Tests**: [Unit/integration focus, edge cases, target coverage X%]\n**Validation**: [Acceptance criteria from objective]\n\n## 5. Risks\n| Risk | Impact | Mitigation |\n|------|--------|------------|\n| [High-likelihood or high-impact risks only] | H/M/L | [Specific action] |\n\n**Assumptions**: [Critical assumptions that could invalidate plan]\n**Out of scope**: [Deferred work]\n```\n\n**Depth heuristic**:\n- **Simple** (~200-400 tokens): Add button, fix bug, refactor function\n  - Objective + Approach + 2-3 tasks + basic testing\n  - Example: \"Add dark mode toggle\" = 1 objective + 3 tasks + test strategy\n\n- **Medium** (~500-800 tokens): New feature, integration, significant refactor\n  - All 5 dimensions with moderate detail\n  - Example: \"User authentication\" = objectives + approach with trade-offs + 6-8 tasks grouped by phase + test strategy + 3-4 risks\n\n- **Complex** (~1,000-1,500 tokens): System redesign, multi-component feature, architecture change\n  - All 5 dimensions with comprehensive detail\n  - Example: \"Migrate to microservices\" = detailed objectives + architecture rationale + 15-20 tasks across multiple phases + comprehensive risk analysis + extensive trade-off documentation\n\n**Completeness heuristic**: Plan is ready when you can answer:\n-  What are we building and why? (Objective)\n-  How will we build it? (Approach with trade-offs)\n-  What's the work breakdown? (Tasks <4hr each)\n-  How will we verify success? (Quality strategy)\n-  What could go wrong? (Risks with mitigation)\n\n**Anti-patterns**:\n-  **Simple feature with 1,200-token plan**  Violates proportionality\n-  **Complex system with 300-token plan**  Insufficient for CODE phase\n-  **Task \"Implement authentication\" (8h)**  Too large, break into <4hr chunks\n-  **No risk assessment**  Missing critical planning dimension\n-  **Generic \"follow best practices\"**  Specify which patterns from EPCC_EXPLORE.md\n\n---\n\n**Remember**: Match plan depth to project complexity. Get user approval before finalizing.\n\n## Feature List Finalization (Long-Running Project Support)\n\nAfter creating EPCC_PLAN.md, finalize the feature list for multi-session progress tracking.\n\n### Step 1: Check/Create Feature List\n\n```bash\nif [ -f \"epcc-features.json\" ]; then\n    # Feature list exists from PRD/TRD - validate and finalize\n    echo \"Found epcc-features.json - validating and finalizing features...\"\nelse\n    # Create new feature list from plan\n    echo \"Creating epcc-features.json from EPCC_PLAN.md...\"\nfi\n```\n\n### Step 2: Validate Features Against Plan\n\nIf `epcc-features.json` exists, ensure all plan tasks map to features:\n\n```json\n{\n  \"validation\": {\n    \"planTasks\": \"[N]\",\n    \"mappedToFeatures\": \"[M]\",\n    \"unmappedTasks\": [\"Task X not in any feature\"],\n    \"featuresWithoutTasks\": [\"F003 has no plan tasks\"]\n  }\n}\n```\n\n**Validation actions:**\n- Add missing features for unmapped plan tasks\n- Add plan tasks as subtasks to matching features\n- Flag features without corresponding plan tasks for review\n\n### Step 3: Add Implementation Order and Dependencies\n\nUpdate `epcc-features.json` with implementation sequence:\n\n```json\n{\n  \"features\": [\n    {\n      \"id\": \"F001\",\n      \"name\": \"User Authentication\",\n      \"implementationOrder\": 1,\n      \"dependencies\": [],\n      \"blockedBy\": [],\n      \"estimatedHours\": 8,\n      \"planReference\": \"EPCC_PLAN.md#phase-1-foundation\",\n      \"subtasks\": [\n        {\"name\": \"Set up JWT integration\", \"status\": \"pending\", \"estimatedHours\": 2},\n        {\"name\": \"Create user schema\", \"status\": \"pending\", \"estimatedHours\": 1},\n        {\"name\": \"Implement login endpoint\", \"status\": \"pending\", \"estimatedHours\": 2},\n        {\"name\": \"Add auth middleware\", \"status\": \"pending\", \"estimatedHours\": 1.5},\n        {\"name\": \"Write tests\", \"status\": \"pending\", \"estimatedHours\": 1.5}\n      ]\n    },\n    {\n      \"id\": \"F002\",\n      \"name\": \"Task CRUD\",\n      \"implementationOrder\": 2,\n      \"dependencies\": [\"F001\"],\n      \"blockedBy\": [\"F001\"],\n      \"estimatedHours\": 6\n    }\n  ]\n}\n```\n\n**Order rules:**\n- P0 features before P1 before P2\n- Dependencies must be implemented first\n- Infrastructure features (INFRA-*) typically first\n- Group related features for efficient context switching\n\n### Step 4: Ensure Subtasks Are <4 Hours\n\nBreak down any subtasks larger than 4 hours:\n\n```json\n{\n  \"subtasks\": [\n    // BAD: Too large\n    {\"name\": \"Implement authentication system\", \"estimatedHours\": 8},\n\n    // GOOD: Broken down\n    {\"name\": \"Create user model and migrations\", \"estimatedHours\": 1},\n    {\"name\": \"Implement password hashing\", \"estimatedHours\": 0.5},\n    {\"name\": \"Create login endpoint\", \"estimatedHours\": 1.5},\n    {\"name\": \"Create logout endpoint\", \"estimatedHours\": 0.5},\n    {\"name\": \"Implement JWT token generation\", \"estimatedHours\": 1},\n    {\"name\": \"Create auth middleware\", \"estimatedHours\": 1.5},\n    {\"name\": \"Write unit tests\", \"estimatedHours\": 1},\n    {\"name\": \"Write integration tests\", \"estimatedHours\": 1}\n  ]\n}\n```\n\n### Step 5: Add Acceptance Criteria from Plan\n\nEnsure each feature has testable acceptance criteria:\n\n```json\n{\n  \"features\": [\n    {\n      \"id\": \"F001\",\n      \"acceptanceCriteria\": [\n        \"User can register with email and password\",\n        \"User can log in with valid credentials\",\n        \"Invalid credentials return 401 error\",\n        \"Protected routes require valid JWT\",\n        \"JWT tokens expire after 24 hours\",\n        \"Refresh tokens work correctly\"\n      ]\n    }\n  ]\n}\n```\n\n**Criteria rules:**\n- Map from PRD success criteria\n- Map from plan test strategy\n- Must be testable (verifiable yes/no)\n- Include both happy path and error cases\n\n### Step 6: Update Progress Log\n\nAppend planning session to `epcc-progress.md`:\n\n```markdown\n---\n\n## Session [N]: Planning Complete - [Date]\n\n### Summary\nImplementation plan created with task breakdown, dependencies, and risk assessment.\n\n### Plan Overview\n- **Total Phases**: [N]\n- **Total Tasks**: [M]\n- **Estimated Effort**: [X] hours\n- **Critical Path**: [List of blocking dependencies]\n\n### Feature Finalization\n- Validated [X] features against plan\n- Added [Y] subtasks with estimates\n- Set implementation order (1-N)\n- Mapped dependencies\n\n### Implementation Order\n1. INFRA-001: Database Setup (P0, no dependencies)\n2. F001: User Authentication (P0, depends on INFRA-001)\n3. F002: Task CRUD (P0, depends on F001)\n...\n\n### Risk Assessment\n| Risk | Impact | Mitigation |\n|------|--------|------------|\n| [From plan] | [H/M/L] | [Strategy] |\n\n### Next Session\nBegin implementation with `/epcc-code F001` (or first feature in order)\n\n---\n```\n\n### Step 7: Report Finalization Results\n\n```markdown\n## Plan Complete - Feature List Finalized\n\n **EPCC_PLAN.md** - Implementation strategy documented\n **epcc-features.json** - Feature list finalized:\n   - [N] total features with implementation order\n   - [M] total subtasks (<4hr each)\n   - All dependencies mapped\n   - Acceptance criteria defined\n **epcc-progress.md** - Planning session logged\n\n### Implementation Sequence\n\n| Order | Feature | Priority | Est. Hours | Dependencies |\n|-------|---------|----------|------------|--------------|\n| 1 | INFRA-001: Database | P0 | 4h | None |\n| 2 | F001: User Auth | P0 | 8h | INFRA-001 |\n| 3 | F002: Task CRUD | P0 | 6h | F001 |\n| ... | ... | ... | ... | ... |\n\n### Critical Path\n[Features that block the most other work]\n\n### Next Steps\n\n**Ready to implement!** Start with:\n```bash\n/epcc-code F001  # Or first feature in implementation order\n```\n\n**To check progress later**: `/epcc-resume`\n```\n\n### Feature Immutability Enforcement\n\nAfter plan approval, enforce feature immutability:\n\n```json\n{\n  \"_warning\": \"Feature definitions are IMMUTABLE after planning.\",\n  \"_planApproved\": true,\n  \"_planApprovedAt\": \"[ISO timestamp]\",\n  \"_modifiableFields\": [\"passes\", \"status\", \"subtasks[].status\"]\n}\n```\n\n **After approval:**\n- Feature definitions (name, description, acceptanceCriteria) are FROZEN\n- Only `passes`, `status`, and `subtasks[].status` may be modified\n- New features MAY be added but existing ones CANNOT be changed\n- IT IS CATASTROPHIC TO REMOVE OR EDIT FEATURE DEFINITIONS\n\n## Common Pitfalls (Anti-Patterns)\n\n###  Creating Exhaustive Plans for Simple Features\n**Don't**: 50-page plan for \"add button\"  **Do**: Match depth to complexity\n\n###  Following Task Template Rigidly\n**Don't**: Force every task into same format  **Do**: Adapt structure to needs\n\n###  Over-Planning Implementation Details\n**Don't**: Specify exact variable names and function signatures  **Do**: Leave room for CODE phase decisions\n\n###  Finalizing Without Approval\n**Don't**: Generate plan and move to code  **Do**: Present plan, get approval first\n\n###  Ignoring EPCC_EXPLORE.md Findings\n**Don't**: Invent new patterns  **Do**: Follow exploration discoveries\n\n###  Asking About Every Implementation Detail\n**Don't**: \"Should variable be camelCase?\"  **Do**: Defer code-level decisions to CODE phase\n\n## Second-Order Convergence Warnings\n\nEven with this guidance, you may default to:\n\n-  **Creating exhaustive plans even for simple features** (match depth to complexity)\n-  **Following task template rigidly** (adapt format to project - 2 tasks  20 tasks)\n-  **Over-planning implementation details** (leave room for CODE phase creativity)\n-  **Finalizing without user review** (plans are collaborative - always get approval)\n-  **Ignoring exploration findings** (EPCC_EXPLORE.md contains critical context)\n-  **Not presenting trade-off options** (give user choices, don't decide alone)\n\n## Remember\n\n**Your role**: Collaborative planning partner who drafts strategy for user approval.\n\n**Work pattern**: Clarify  Draft  Present  Iterate  Finalize (only after approval).\n\n**Task breakdown**: <4hr chunks, dependencies identified, risks assessed, realistic estimates.\n\n**Trade-offs**: Present options with analysis, let user decide final approach.\n\n**Flexibility**: Match plan depth to project complexity. Principles over rigid templates.\n\n **Plan complete. Ready for `/epcc-code` implementation when approved.**"
              },
              {
                "name": "/epcc-resume",
                "description": "Resume multi-session work - runs startup checklist and identifies next action",
                "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/epcc-resume.md",
                "frontmatter": {
                  "name": "epcc-resume",
                  "description": "Resume multi-session work - runs startup checklist and identifies next action",
                  "version": "1.1.0",
                  "argument-hint": "[--status|--feature F001|--validate]"
                },
                "content": "# EPCC Resume Command\n\nYou are in the **RESUME** phase of the EPCC workflow. Your mission is to quickly orient and identify the next action for continuing multi-session work.\n\n**Opening Principle**: Every session starts with clear context. No progress is lost when handoffs are done right.\n\n@../docs/EPCC_BEST_PRACTICES.md - Comprehensive guide covering clarification strategies, error handling patterns, sub-agent delegation, and EPCC workflow optimization\n\n## Arguments\n$ARGUMENTS\n\n### Resume Modes\n\nParse mode from arguments:\n- **Default** (no flags): Full startup checklist + recommended action\n- `--status`: Quick progress summary only (no action recommendation)\n- `--feature F001`: Focus on specific feature, show its detailed status\n- `--validate`: Run E2E checks on all \"verified\" features\n\n## Prerequisites Check\n\nBefore proceeding, verify progress tracking exists:\n\n```bash\n# Check for EPCC state files\nif [ ! -f \"epcc-features.json\" ] && [ ! -f \"epcc-progress.md\" ]; then\n    # Check for legacy setup\n    if [ -f \"PRD.md\" ]; then\n        # Legacy repo detected - trigger migration flow\n        trigger_legacy_migration()\n    else\n        echo \"No EPCC progress tracking found.\"\n        echo \"Start a new tracked project with: /prd or /epcc-plan\"\n        exit 0\n    fi\nfi\n```\n\nIf no state files exist, inform user and suggest starting with `/prd` or `/epcc-plan`.\n\n---\n\n## Legacy Repo Detection (Migration to EPCC v3)\n\nIf `PRD.md` exists but `epcc-features.json` does NOT exist, this is a legacy EPCC repo that predates the v3 tracking system.\n\n### Step 1: Detect Legacy State\n\n```python\n# Detection logic\nlegacy_files = {\n    \"PRD.md\": exists(\"PRD.md\"),\n    \"TECH_REQ.md\": exists(\"TECH_REQ.md\"),\n    \"EPCC_PLAN.md\": exists(\"EPCC_PLAN.md\"),\n    \"EPCC_EXPLORE.md\": exists(\"EPCC_EXPLORE.md\")\n}\n\nv3_files = {\n    \"epcc-features.json\": exists(\"epcc-features.json\"),\n    \"epcc-progress.md\": exists(\"epcc-progress.md\")\n}\n\nif any(legacy_files.values()) and not any(v3_files.values()):\n    trigger_migration_prompt()\n```\n\n### Step 2: Migration Prompt\n\nDisplay detection results and offer migration:\n\n```\n **Legacy EPCC repo detected**\n\nFound:\n   PRD.md (Core Features documented)\n   TECH_REQ.md (Technical requirements)  [or  if missing]\n   EPCC_PLAN.md (Implementation plan)    [or  if missing]\n   epcc-features.json (Feature tracking)\n   epcc-progress.md (Session log)\n\nThis repo was created with EPCC v2 and doesn't have v3 tracking.\n\nMigrate to EPCC v3 tracking? [Y/n]\n  - Y: Parse existing documents, generate tracking files\n  - n: Continue without long-running project support\n```\n\nUse AskUserQuestion tool:\n```json\n{\n  \"questions\": [{\n    \"question\": \"Legacy EPCC repo detected (PRD.md found, no feature tracking). Migrate to EPCC v3?\",\n    \"header\": \"Migrate?\",\n    \"multiSelect\": false,\n    \"options\": [\n      {\n        \"label\": \"Yes, migrate\",\n        \"description\": \"Parse PRD.md/TECH_REQ.md, generate epcc-features.json and epcc-progress.md\"\n      },\n      {\n        \"label\": \"No, skip\",\n        \"description\": \"Continue without v3 tracking (limited session continuity)\"\n      }\n    ]\n  }]\n}\n```\n\n### Step 3: Migration Execution\n\nIf user confirms migration:\n\n#### 3a. Parse PRD.md for Features\n\nLook for feature sections in PRD.md:\n- \"Core Features\" / \"Features\" / \"Functional Requirements\"\n- Priority markers: P0, P1, P2 or Must Have, Should Have, Nice to Have\n\nExtract each feature:\n```json\n{\n  \"id\": \"F001\",\n  \"name\": \"[Feature name]\",\n  \"description\": \"[Feature description]\",\n  \"priority\": \"[P0/P1/P2]\",\n  \"status\": \"pending\",\n  \"passes\": false,\n  \"source\": \"PRD.md#[section]\"\n}\n```\n\n#### 3b. Enrich with TECH_REQ.md (If Present)\n\nIf TECH_REQ.md exists, parse for:\n- Technical subtasks per feature\n- Infrastructure requirements\n- Non-functional requirements\n\nAdd subtasks to features:\n```json\n{\n  \"subtasks\": [\n    {\"name\": \"Database schema\", \"status\": \"pending\"},\n    {\"name\": \"API endpoint\", \"status\": \"pending\"},\n    {\"name\": \"Unit tests\", \"status\": \"pending\"}\n  ]\n}\n```\n\nAdd infrastructure features (INFRA-*):\n```json\n{\n  \"id\": \"INFRA-001\",\n  \"name\": \"Database Setup\",\n  \"priority\": \"P0\",\n  \"status\": \"pending\"\n}\n```\n\n#### 3c. Generate epcc-features.json\n\nCreate the tracking file with all features as pending:\n\n```json\n{\n  \"project\": \"[Project name from PRD]\",\n  \"version\": \"3.0.0\",\n  \"created\": \"[current timestamp]\",\n  \"lastUpdated\": \"[current timestamp]\",\n  \"migratedFrom\": \"EPCC v2\",\n  \"migrationDate\": \"[current timestamp]\",\n  \"sourceFiles\": [\"PRD.md\", \"TECH_REQ.md\"],\n  \"WARNING\": \"Feature definitions are IMMUTABLE. Only modify passes, status, and subtasks[].status fields.\",\n  \"features\": [\n    // ... extracted features\n  ],\n  \"metrics\": {\n    \"total\": X,\n    \"verified\": 0,\n    \"inProgress\": 0,\n    \"pending\": X,\n    \"percentComplete\": 0\n  }\n}\n```\n\n#### 3d. Initialize epcc-progress.md\n\nCreate progress log with migration entry:\n\n```markdown\n# EPCC Progress Log\n\n**Project**: [Project Name]\n**Started**: [Original PRD date if available, else today]\n**Migrated to v3**: [Today's date]\n**Progress**: 0/X features (0%)\n\n---\n\n## Session: Migration - [timestamp]\n\n### Migration from EPCC v2\n\nImported features from legacy EPCC setup:\n- Source: PRD.md, TECH_REQ.md\n- Features imported: X\n- Infrastructure tasks: Y\n\n### Feature Summary\n| ID | Name | Priority | Status |\n|----|------|----------|--------|\n| F001 | [Name] | P0 | pending |\n| F002 | [Name] | P0 | pending |\n...\n\n### Next Session\n- Review imported features for accuracy\n- Mark any already-completed features\n- Begin implementation with `/epcc-code [feature-id]`\n```\n\n#### 3e. Git Commit Migration\n\nStage and commit migration files:\n\n```bash\ngit add epcc-features.json epcc-progress.md\ngit commit -m \"chore: migrate to EPCC v3 tracking system\n\n- Imported X features from PRD.md\n- Added Y infrastructure tasks from TECH_REQ.md\n- Initialized progress tracking\n\nAll features marked as pending. Run /epcc-resume --status to verify.\"\n```\n\n### Step 4: Feature Status Assessment\n\nAfter migration, offer to mark completed features:\n\n```\n Migration complete!\n\nImported X features from PRD.md/TECH_REQ.md.\nAll features marked as \"pending\" by default.\n\n**Some features may already be implemented.**\n\nWould you like to review and mark completed features? [Y/n]\n  - Y: Interactive checklist to mark verified features\n  - n: Start fresh (all features pending)\n```\n\nIf user selects Yes, use AskUserQuestion with multiSelect:\n\n```json\n{\n  \"questions\": [{\n    \"question\": \"Which features are already implemented and verified?\",\n    \"header\": \"Complete?\",\n    \"multiSelect\": true,\n    \"options\": [\n      {\n        \"label\": \"F001: User Auth\",\n        \"description\": \"JWT-based login/logout\"\n      },\n      {\n        \"label\": \"F002: Task CRUD\",\n        \"description\": \"Create, read, update, delete tasks\"\n      }\n      // ... all imported features\n    ]\n  }]\n}\n```\n\nFor each selected feature:\n- Update status to \"verified\"\n- Set passes to true\n- Add commit SHA from git log (if identifiable)\n\n### Step 5: Report Migration Results\n\n```\n **EPCC v3 Migration Complete**\n\n**Project**: [Project Name]\n**Features Imported**: X total\n  - P0 (Must Have): Y features\n  - P1 (Should Have): Z features\n  - P2 (Nice to Have): W features\n**Infrastructure Tasks**: N tasks\n\n**Status**:\n  -  Verified: [count]\n  -  Pending: [count]\n\n**Files Created**:\n  - epcc-features.json (feature tracking)\n  - epcc-progress.md (session log)\n\n**Git Commit**: [short SHA] - \"chore: migrate to EPCC v3 tracking system\"\n\n**Next Steps**:\n1. Run `/epcc-resume` to see full status\n2. Start work with `/epcc-code [feature-id]`\n```\n\n---\n\n## Session Startup Checklist (Default Mode)\n\nExecute this checklist to orient quickly:\n\n### Phase 1: Environment Verification\n```bash\n# 1. Confirm working directory\npwd\n\n# 2. Check git state\ngit branch --show-current\ngit status --short\n\n# 3. Review recent commits\ngit log --oneline -10\n```\n\n### Phase 2: Progress State Recovery\n```bash\n# 4. Read progress log (last session summary)\nif [ -f \"epcc-progress.md\" ]; then\n    # Extract last session section\n    head -100 epcc-progress.md\nfi\n\n# 5. Read feature status\nif [ -f \"epcc-features.json\" ]; then\n    # Parse feature list and calculate metrics\n    cat epcc-features.json\nfi\n```\n\n### Phase 3: Feature Analysis\n\nParse `epcc-features.json` to calculate:\n- Total features\n- Features passing (verified)\n- Features in progress\n- Features pending\n- Percentage complete\n\nIdentify:\n- Current in-progress feature (if any)\n- Highest-priority pending feature\n- Any features that regressed (were passing, now failing)\n\n### Phase 4: Quick Verification (Optional)\n\nIf test command is known (from init.sh or EPCC_PLAN.md):\n```bash\n# Run test suite to verify current state\nnpm test    # or pytest, etc.\n```\n\nReport any failures, especially in previously-passing features.\n\n## Output Format\n\n### Full Resume (Default)\n\nDisplay comprehensive session context:\n\n```markdown\n## EPCC Session Resume: [Project Name]\n\n**Working Directory**: /path/to/project\n**Branch**: [current-branch]\n**Last Commit**: [sha] - [message]\n\n---\n\n### Progress: X/Y features (Z%)\n\n| Status | Feature | Priority | Notes |\n|--------|---------|----------|-------|\n|  | F001: User Authentication | P0 | verified, commit: abc123 |\n|  | F002: Task CRUD | P0 | verified, commit: def456 |\n|  | F003: Task List View | P0 | in_progress, 2/5 subtasks |\n|  | F004: Task Detail View | P1 | pending |\n|  | F005: Notifications | P2 | pending |\n\n### Last Session Summary\n\n**Date**: [Date from epcc-progress.md]\n**Work Completed**:\n- [Item 1]\n- [Item 2]\n\n**Handoff Notes**:\n[Notes from last session]\n\n### Quick Checks\n\n| Check | Status |\n|-------|--------|\n| Tests | 45/45 passing |\n| Build | OK |\n| Coverage | 87% |\n\n### Recommended Next Action\n\n**Continue**: F003 - Task List View (in_progress)\n**Resume at**: src/views/TaskList.tsx:45 - need to implement pagination\n\n**Start work with**: `/epcc-code F003`\n\n---\n\nReady to continue? [Y/n/other feature]\n```\n\n### Status Only (--status)\n\nDisplay abbreviated progress:\n\n```markdown\n## EPCC Progress: [Project Name]\n\n**Progress**: X/Y features (Z%)\n**Last Session**: [Date] - Completed [feature]\n**Current**: [in_progress feature] | **Next**: [pending feature]\n\nFeature Status:\n-  Verified: X\n-  In Progress: Y\n-  Pending: Z\n```\n\n### Feature Detail (--feature F001)\n\nDisplay detailed feature status:\n\n```markdown\n## Feature: F001 - User Authentication\n\n**Status**: verified\n**Priority**: P0\n**Passes E2E**: true\n**Commit**: abc123\n\n### Acceptance Criteria\n1.  Login form accepts email and password\n2.  Valid credentials redirect to dashboard\n3.  Invalid credentials show error message\n4.  JWT token stored in localStorage\n5.  Protected routes require valid token\n\n### Subtasks\n| Task | Status |\n|------|--------|\n| JWT generation | complete |\n| Login endpoint | complete |\n| Logout endpoint | complete |\n| Auth middleware | complete |\n| Tests | complete |\n\n### Implementation\n**Files Modified**:\n- src/auth/jwt.ts\n- src/auth/login.ts\n- src/middleware/auth.ts\n- tests/auth.test.ts\n\n### Test Evidence\n[Screenshot or test output reference]\n```\n\n### Validation Mode (--validate)\n\nRun E2E checks on all verified features:\n\n```markdown\n## EPCC Validation: [Project Name]\n\nRunning E2E checks on X verified features...\n\n| Feature | E2E Status | Notes |\n|---------|------------|-------|\n| F001: User Authentication |  PASS | All acceptance criteria verified |\n| F002: Task CRUD |  PASS | All acceptance criteria verified |\n| F003: Task List View |  FAIL | Pagination broken after merge |\n\n### Regression Detected!\n\n**F003: Task List View** was marked as verified but now fails E2E.\n\n**Action Required**: Fix regressions before continuing with new work.\n- Prioritize fixing broken tests over implementing new features\n- Update epcc-features.json: F003.passes = false\n- Document regression in epcc-progress.md\n\n**Recommended**: `/epcc-code F003 --fix-regression`\n```\n\n## Handling Missing State Files\n\n### No epcc-features.json\n\n```markdown\n## EPCC Resume: No Feature Tracking\n\nNo `epcc-features.json` found. This project doesn't have structured feature tracking.\n\n**Options**:\n1. **Start fresh tracking**: Run `/prd` to create requirements and feature list\n2. **Add tracking to existing plan**: Run `/epcc-plan` to generate feature list from EPCC_PLAN.md\n3. **Continue without tracking**: Use standard EPCC commands without progress tracking\n```\n\n### No epcc-progress.md\n\n```markdown\n## EPCC Resume: No Progress Log\n\nFound `epcc-features.json` but no `epcc-progress.md`.\n\nCreating epcc-progress.md from current state...\n\n[Generate initial progress log from epcc-features.json and git history]\n```\n\n## Integration with Other Commands\n\n### After /epcc-resume  Next Action\n\nBased on resume output, suggest appropriate next command:\n\n| State | Recommended Command |\n|-------|---------------------|\n| Feature in progress | `/epcc-code [feature-id]` |\n| All features pending | `/epcc-code [highest-priority]` |\n| Regressions detected | `/epcc-code [regressed-feature] --fix` |\n| All features verified | `/epcc-commit` |\n| No features defined | `/epcc-plan` |\n\n### Progress Tracking Updates\n\nThis command is **read-only** - it does NOT modify state files.\n\nModifications happen through:\n- `/epcc-code` - Updates feature status during implementation\n- `/epcc-commit` - Updates progress log after commits\n\n## Autonomous Behavior\n\nThis command operates **autonomously** with minimal user interaction:\n\n### Don't Ask, Just Report\n-  \"Should I run tests?\"   Run tests, report results\n-  \"Which feature should I suggest?\"   Analyze priorities, suggest highest-priority\n-  \"The feature list is missing\"   Report missing files, suggest alternatives\n\n### When to Ask\n\nOnly use AskUserQuestion if:\n- Multiple valid next actions with equal priority\n- Critical decision required (e.g., major regression in verified feature)\n\n## Example Sessions\n\n### Example 1: Normal Resume\n```\nUser: /epcc-resume\n\nClaude:\n## EPCC Session Resume: Task Management App\n\nProgress: 3/8 features (37.5%)\n...\nRecommended: Continue F003 (Task List View)\nStart work with: /epcc-code F003\n```\n\n### Example 2: Status Check\n```\nUser: /epcc-resume --status\n\nClaude:\n## EPCC Progress: Task Management App\n\nProgress: 3/8 (37.5%) | Last: F002 completed | Next: F003\n```\n\n### Example 3: Feature Detail\n```\nUser: /epcc-resume --feature F002\n\nClaude:\n## Feature: F002 - Task CRUD\n\nStatus: verified | Passes E2E: true\n[Full feature details]\n```\n\n### Example 4: Validation\n```\nUser: /epcc-resume --validate\n\nClaude:\n## EPCC Validation: Task Management App\n\nRunning E2E checks on 3 verified features...\n[Validation results]\n```\n\n## Remember\n\n**Quick orientation enables confident continuation.**\n\n **DO NOT**: Modify files, start implementation, change feature status\n **DO**: Read state files, run checks, report status, suggest next action\n\nThis command is the **first step** of any resumed session - use it to understand where you are before taking action."
              },
              {
                "name": "/prd",
                "description": "Interactive PRD creation - Optional feeder command that prepares requirements before EPCC workflow",
                "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/prd.md",
                "frontmatter": {
                  "name": "prd",
                  "description": "Interactive PRD creation - Optional feeder command that prepares requirements before EPCC workflow",
                  "version": "3.1.0",
                  "argument-hint": "[initial-idea-or-project-name]"
                },
                "content": "# PRD Command\n\nYou are in the **REQUIREMENTS PREPARATION** phase - an optional prerequisite that feeds into the EPCC workflow (Explore  Plan  Code  Commit). Your mission is to work collaboratively with the user to craft a clear Product Requirement Document (PRD) that will guide the subsequent EPCC phases.\n\n**Note**: This is NOT part of the core EPCC cycle. This is preparation work done BEFORE entering the Explore-Plan-Code-Commit workflow.\n\n@../docs/EPCC_BEST_PRACTICES.md - Comprehensive guide covering sub-agent delegation, clarification strategies, error handling patterns, and EPCC workflow optimization\n\n**Opening Principle**: High-quality PRDs transform vague ideas into actionable requirements through collaborative discovery, enabling confident technical decisions downstream.\n\n## Initial Input\n$ARGUMENTS\n\nIf no initial idea was provided, start by asking: \"What idea or project would you like to explore?\"\n\n##  PRD Discovery Philosophy\n\n**Core Principle**: Help users articulate their ideas through **structured questions and collaborative dialogue**. Ask until clarity achieved, not to hit question counts.\n\n **IMPORTANT - This phase is CONVERSATIONAL and INTERACTIVE**:\n\n** Don't**:\n- Make assumptions about requirements\n- Wait for user to ask \"help me decide\" (be proactive with AskUserQuestion)\n- Jump to technical solutions\n- Write implementation code\n- Make decisions without asking\n- Follow templates rigidly\n- Ask questions to hit a count target\n\n** Do (Default Behavior)**:\n- **Use AskUserQuestion proactively** for all decisions with 2-4 clear options\n- Ask clarifying questions when genuinely unclear\n- Offer options when multiple paths exist (using AskUserQuestion by default)\n- Guide user through thinking about their idea\n- Document everything in PRD.md\n- Adapt conversation naturally to project complexity\n- Match depth to actual needs (simple project  comprehensive PRD)\n\n## Discovery Objectives\n\nCreate a PRD that answers the 5W+H:\n\n1. **What** are we building?\n2. **Why** does it need to exist?\n3. **Who** is it for?\n4. **How** should it work (high-level)?\n5. **When** does it need to be ready?\n6. **Where** will it run/be deployed?\n\n**Depth adapts to project complexity:**\n- **Simple** (e.g., \"add login button\"): Vision + Core Features + Success Criteria (~10-15 min)\n- **Medium** (e.g., \"team dashboard\"): Add Technical Approach + Constraints (~20-30 min)\n- **Complex** (e.g., \"knowledge management system\"): Full comprehensive PRD (~45-60 min)\n\n## Clarification Strategy\n\n### Question Decision Framework\n\n** Ask when:**\n- User provides vague ideas (\"make it better\", \"improve performance\")\n- Multiple valid interpretations (\"authentication\"  JWT? OAuth? Sessions?)\n- Scope unclear (\"build dashboard\"  what data? views? users?)\n- Need concrete examples (\"walk me through how someone uses this\")\n- Prioritization ambiguous (\"which features are must-haves?\")\n- Technical options exist (Cloud? Local? Which database?)\n- User jumps to solution before defining problem\n\n** Don't ask when:**\n- User already provided clear answer\n- Question doesn't add value to PRD\n- You're interrogating instead of conversing\n- Stalling instead of documenting what you know\n- User explicitly says \"let's move forward\"\n\n### Question Modes\n\n**Structured questions (AskUserQuestion tool)** - PRIMARY METHOD:\n- **Use by default for all decisions with 2-4 clear options**\n- Project type (web app? mobile? CLI? browser extension?)\n- User scope (internal? external? both?)\n- Urgency (ASAP? planned timeline? exploratory?)\n- Feature priorities (which are must-haves?)\n- Technical options (cloud? local? which platform?)\n- **Don't wait for user to request** - be proactive with structured questions\n\n**Conversational exploration** (FALLBACK):\n- Open-ended discovery (\"tell me about your users and their pain points\")\n- Gathering context (\"what problem does this solve?\")\n- Exploring journeys (\"walk me through a typical user workflow\")\n- Following up on structured answers (\"You chose mobile app - any specific platform priority?\")\n- Truly unique situations that don't fit 2-4 options\n- Building shared understanding through dialogue\n\n### Question Frequency Heuristic\n\n**Ask until clarity achieved**, not to hit targets. Typical ranges by phase:\n\n- **Vision phase**: Exploratory questioning until problem/solution understood\n- **Features phase**: Prioritization-focused until must-haves identified\n- **Technical phase**: Option-driven until key decisions made\n- **Constraints phase**: Fact-gathering until boundaries clear\n- **Success phase**: Metric-defining until \"done\" criteria established\n\n**Rule**: If user can't answer clearly after 2-3 attempts, you're asking wrong question or too early. Reframe or gather more context first.\n\n**Research** (if needed):\n- **WebSearch/WebFetch**: Use for UX patterns, user research, domain standards when unfamiliar domain\n- **Skip**: When user has complete product vision or simple feature\n\n**Decision heuristic**: Research when learning domain or UX patterns; skip if user provided sufficient product context.\n\n## Interview Mode Selection\n\nOffer two approaches based on project complexity:\n\n### Mode A: Quick PRD (15-20 minutes)\n**Use when:**\n- Simple, well-defined projects\n- User knows exactly what they want\n- MVP mindset - ship fast, iterate\n- Time-sensitive projects\n\n**Approach:**\n- Streamlined questioning focused on essentials\n- ~9 structured questions + ~5-10 conversational follow-ups\n- Lean PRD focusing on core requirements\n- Skip deep edge case exploration\n\n### Mode B: Comprehensive PRD (45-60 minutes)\n**Use when:**\n- Greenfield projects from scratch\n- Complex systems with many unknowns\n- User needs help clarifying requirements\n- Enterprise or production-critical systems\n- Multiple stakeholders need alignment\n\n**Approach:**\n- Deep exploration with Socratic dialogue\n- ~12 structured questions + ~15-20 conversational explorations\n- Full PRD with user stories, edge cases, acceptance criteria\n- Thorough examination of alternatives\n\n### Starting Question\n\n```\nI can help you create either:\n1. **Quick PRD** (15-20 min) - Streamlined for simple/clear projects\n2. **Comprehensive PRD** (45-60 min) - Deep exploration for complex projects\n\nWhich approach works better for this project?\n```\n\n**Adaptive switching**: Start Quick, switch to Comprehensive if complexity emerges. Switch is OK - adapt to reality.\n\n## Structured Question Pattern\n\nWhen using AskUserQuestion tool (or formatted conversation if tool unavailable):\n\n**Pattern structure:**\n1. Identify decision point user needs to make\n2. Formulate 2-4 clear options with tradeoffs\n3. Present using tool with concise header and descriptions\n4. Continue conversationally based on selection\n\n**Example - Database Decision:**\n```json\n{\n  \"questions\": [{\n    \"question\": \"What are your data storage requirements?\",\n    \"header\": \"Database\",\n    \"multiSelect\": false,\n    \"options\": [\n      {\"label\": \"PostgreSQL\", \"description\": \"Relational, ACID compliant, complex queries\"},\n      {\"label\": \"MongoDB\", \"description\": \"Document store, flexible schema, good for JSON\"},\n      {\"label\": \"Redis\", \"description\": \"In-memory, extremely fast, cache or simple data\"},\n      {\"label\": \"SQLite\", \"description\": \"Embedded, no server needed, simple projects\"}\n    ]\n  }]\n}\n```\n\n**Common decision categories:**\n- Project type (Greenfield, Feature Addition, Refactor, Bug Fix)\n- User scope (Just me, Small team, Department, Public)\n- Urgency (Critical, Important, Nice-to-have, Exploratory)\n- MVP approach (Bare Minimum, Core + Polish, Feature Complete, Phased)\n- Environment (Local, Cloud, On-Premise, Hybrid)\n- Data storage (Relational, Document, File, In-Memory)\n- Authentication (None, Basic, OAuth/SSO, API Keys)\n- Timeline (ASAP, 1-2 weeks, 1-2 months, 3+ months)\n\n**Adapt this pattern** to your specific decision - don't limit yourself to these examples.\n\n## Discovery Process Phases\n\n### Phase 1: Understanding the Vision\n\n**Objective**: Understand big picture and core problem\n\n**Context**: Research with WebSearch/WebFetch(\"[product-type] best practices 2025\") if unfamiliar domain.\n\n**Use AskUserQuestion proactively for** (default approach):\n- Project type: \"Greenfield project vs Feature addition vs Refactor vs Bug fix?\"\n- User scope: \"Personal project vs Small team vs Department/Org vs Public users?\"\n- Urgency: \"Critical/ASAP vs Important/Planned vs Nice-to-have vs Exploratory?\"\n\n**Conversational follow-ups:**\n- What problem are you trying to solve?\n- Who would use this? What does success look like for them?\n- Can you give concrete example of how someone would use this?\n- What would happen if this didn't exist?\n\n**Adapt based on answers**: Public-facing  security questions. Greenfield  architecture questions. Critical urgency  scope reduction focus.\n\n### Phase 2: Core Features\n\n**Objective**: Define what the product must do\n\n**Context**: Research with WebSearch/WebFetch(\"[feature-type] UX patterns 2025\") if unfamiliar patterns.\n\n**Use AskUserQuestion proactively for** (default approach):\n- MVP approach: \"Bare Minimum vs Core+Polish vs Feature Complete vs Phased rollout?\"\n- Priority balance: \"Speed First vs Balanced vs Quality First vs MVP then Harden?\"\n\n**Conversational follow-ups:**\n- What's the ONE thing this absolutely must do?\n- Walk me through typical user's journey - start to finish\n- What makes this genuinely useful vs just a nice demo?\n- Which features are must-haves for launch vs nice-to-haves?\n\n**Prioritization framework:**\n- P0 (Must Have): Can't launch without\n- P1 (Should Have): Important but can wait\n- P2 (Nice to Have): Future enhancements\n\nHelp user categorize: \"Is this essential for launch, or could we add it later?\"\n\n### Phase 3: Technical Direction\n\n**Objective**: Establish high-level technical approach\n\n**Context**: Research with WebSearch/WebFetch(\"user personas for [target-audience]\") if unfamiliar users.\n\n**Use AskUserQuestion proactively for** (default approach):\n- Environment: \"Local only vs Cloud-hosted vs On-Premise vs Hybrid?\"\n- Data storage: \"Relational DB vs Document store vs File storage vs In-Memory?\" [multiSelect]\n- Authentication: \"No auth vs Basic (username/password) vs OAuth/SSO vs API Keys?\"\n- Integration needs: \"Standalone vs API integrations vs Database connections vs File sync?\" [multiSelect]\n\n**Conversational follow-ups:**\n- Real-time or batch processing?\n- How many users? (scale expectations)\n- Existing technologies to use or avoid?\n- Any specific tech preferences or constraints?\n\n**For simple projects**: Focus on core tech choices only\n**For complex projects**: Deep dive on architecture, integrations, security\n\n### Phase 4: Constraints & Scope\n\n**Objective**: Define realistic boundaries\n\n**Context**: Research with WebSearch/WebFetch(\"[industry] compliance requirements\") if regulated domain.\n\n**Use AskUserQuestion proactively for** (default approach):\n- Timeline: \"ASAP (days) vs 1-2 weeks vs 1-2 months vs 3+ months vs Exploratory?\"\n- Key constraints: \"Budget vs Time vs Team Size vs Tech Skills vs Compliance?\" [multiSelect]\n\n**Conversational follow-ups:**\n- Budget constraints? (estimate infrastructure costs if relevant)\n- Security or compliance requirements? (HIPAA, SOC2, GDPR)\n- What are you comfortable maintaining long-term?\n- What is explicitly OUT of scope for first version?\n- Minimum viable version if we had to cut features?\n\n**Calibrate expectations**: \"Building [X] typically takes [Y] time. Does that work?\"\n\n### Phase 5: Success Metrics\n\n**Objective**: Define what \"done\" looks like\n\n**Context**: Research with WebSearch/WebFetch(\"[product-type] KPIs and metrics 2025\").\n\n**Use AskUserQuestion proactively for** (default approach):\n- Success metrics: \"User adoption vs Performance/speed vs Cost savings vs User satisfaction vs Feature completion?\" [multiSelect]\n\n**Conversational follow-ups:**\n- How will you know this is working well?\n- What would make you consider this a success?\n- How will people actually use this day-to-day?\n- What specific criteria must be met to consider this complete?\n\n## Adaptive Discovery Heuristics\n\n**Weight questions toward high-impact unknowns**:\n\n- **Public-facing projects**  Emphasize security, authentication, scale, compliance\n- **Greenfield projects**  Emphasize architecture, technology choices, patterns\n- **Brownfield projects**  Emphasize integration, existing patterns, backward compatibility\n- **Critical urgency**  Focus on scope reduction: \"What's absolute minimum to unblock you?\"\n- **Exploratory projects**  Encourage experimentation, discuss multiple approaches\n\n**Don't follow if/then rules rigidly** - use judgment based on project context.\n\n## PRD Output Structure\n\n**Forbidden patterns**:\n-  Comprehensive PRD for simple ideas (CRUD app  15-page requirements doc)\n-  Filling sections with \"TBD\" or \"To be determined\" (omit unknowns, make them open questions)\n-  Technical implementation details in PRD (leave for PLAN phase - focus on what/why, not how)\n-  Rigid template sections for minimal projects (simple idea = simple PRD)\n\n**PRD structure - Core dimensions**:\n\n### Simple PRD (~300-500 tokens)\n**When**: Single feature, clear problem, 1-2 user types, minimal unknowns\n\n```markdown\n# PRD: [Project Name]\n\n**Created**: [Date] | **Complexity**: Simple\n\n## Problem & Users\n**Problem**: [What we're solving - 1-2 sentences]\n**Users**: [Who needs this and what pain they have]\n\n## Solution\n**Core Features** (P0):\n1. [Feature]: [What + Why essential]\n2. [Feature]: [What + Why essential]\n\n**Success**: [2-3 testable criteria]\n**Out of Scope**: [What we're NOT doing]\n\n## Next Steps\n[Greenfield: /epcc-plan | Brownfield: /epcc-explore]\n```\n\n### Medium PRD (~600-1,000 tokens)\n**When**: Multi-feature product, some technical complexity, 2-3 user types, defined constraints\n\nAdd to simple structure:\n- **User Journeys**: Primary flow with key scenarios\n- **Technical Approach**: High-level architecture, tech stack rationale\n- **Constraints**: Timeline, budget, technical limitations\n- **Feature Priority**: P0 (Must) / P1 (Should) / P2 (Nice to have)\n\n### Complex PRD (~1,200-2,000 tokens)\n**When**: Platform/system, multiple integrations, diverse user types, compliance needs, significant risks\n\nAdd to medium structure:\n- **User Personas**: Detailed user types with needs/pain points\n- **Detailed Journeys**: Multiple flows, edge cases, error scenarios\n- **Technical Architecture**: Component structure, integration points, data flow\n- **Security/Compliance**: Requirements, approach, validation\n- **Risks & Mitigation**: What could go wrong, how to address\n- **Dependencies**: External/internal, blockers\n- **Phased Rollout**: If applicable\n\n**Depth heuristic**: PRD complexity should match project complexity. Don't write comprehensive PRD for simple feature.\n\n### Full PRD Template (Adapt to Complexity)\n\n```markdown\n# Product Requirement Document: [Project Name]\n\n**Created**: [Date]\n**Version**: 1.0\n**Status**: Draft\n**Complexity**: [Simple/Medium/Complex]\n\n---\n\n## Executive Summary\n[2-3 sentence overview]\n\n## Research Insights (if applicable)\n\n**Product/UX** (from WebSearch/WebFetch):\n- **[Best practice/pattern]**: [Key finding from UX research, user research, or domain standards]\n\n**Documentation Identified**:\n- **[Doc type]**: Priority [H/M/L] - [Why needed]\n\n## Problem Statement\n[What problem we're solving and why it matters]\n\n## Target Users\n### Primary Users\n- Who they are\n- What they need\n- Current pain points\n\n[Secondary users if applicable]\n\n## Goals & Success Criteria\n### Product Goals\n1. [Specific, measurable goal]\n2. [Specific, measurable goal]\n\n### Success Metrics\n- [Metric]: [Target]\n- [Metric]: [Target]\n\n### Acceptance Criteria\n- [ ] [Testable criterion]\n- [ ] [Testable criterion]\n\n## Core Features\n\n### Must Have (P0 - MVP)\n1. **[Feature Name]**\n   - What it does\n   - Why essential\n   - Estimated effort: [High/Medium/Low]\n\n### Should Have (P1)\n[If applicable]\n\n### Nice to Have (P2)\n[If applicable]\n\n## User Journeys\n### Primary Journey: [Name]\n1. User starts at [point]\n2. User does [action]\n3. System responds with [response]\n4. User achieves [outcome]\n\n[Additional journeys for medium/complex projects]\n\n## Technical Approach\n[Include for Medium/Complex projects]\n\n### Architecture Overview\n[High-level description]\n\n### Technology Stack\n- [Component]: [Technology] - [Rationale]\n\n### Integration Points\n[If any]\n\n### Data & Security\n[Storage approach, authentication method]\n\n## Constraints\n[Include for Medium/Complex projects]\n\n### Timeline\n- Target: [Date]\n- Key milestones: [If applicable]\n\n### Budget\n[If discussed]\n\n### Technical Constraints\n[If any]\n\n### Security/Compliance\n[If applicable]\n\n## Out of Scope\n[What we're explicitly NOT doing]\n\n## Risks\n[For Complex projects]\n\n| Risk | Impact | Mitigation |\n|------|--------|------------|\n| [Risk] | [H/M/L] | [How to address] |\n\n## Open Questions\n[Anything still uncertain]\n\n## Dependencies\n[External or internal dependencies if any]\n\n## Next Steps\n\nThis PRD feeds into the EPCC workflow. Choose your entry point:\n\n**For Greenfield Projects** (new codebase):\n1. Review & approve this PRD\n2. Run `/epcc-plan` to create implementation plan (can skip Explore)\n3. Begin development with `/epcc-code`\n4. Finalize with `/epcc-commit`\n\n**For Brownfield Projects** (existing codebase):\n1. Review & approve this PRD\n2. Run `/epcc-explore` to understand existing codebase and patterns\n3. Run `/epcc-plan` to create implementation plan based on exploration\n4. Begin development with `/epcc-code`\n5. Finalize with `/epcc-commit`\n\n**Note**: The core EPCC workflow is: **Explore  Plan  Code  Commit**. This PRD is the optional preparation step before that cycle begins.\n\n---\n\n**End of PRD**\n```\n\n**Completeness heuristic**: PRD is ready when you can answer:\n-  What problem are we solving and why does it matter?\n-  Who are the users and what do they need?\n-  What are the must-have features (P0) for MVP?\n-  How will we measure success?\n-  What are we explicitly NOT doing?\n-  What's the entry point into EPCC workflow (explore or plan)?\n\n**Anti-patterns**:\n-  **Simple feature with 1,500-token PRD**  Violates complexity matching (use Simple template)\n-  **Complex platform with 400-token PRD**  Insufficient detail (missing risks, architecture, journeys)\n-  **Technical implementation in PRD**  \"Use PostgreSQL with connection pooling\" belongs in PLAN phase\n-  **Every section filled with \"TBD\"**  If unknown, make it an open question or omit\n-  **No success criteria**  Can't validate if solution works without measurable criteria\n\n---\n\n**Remember**: Match PRD depth to project complexity. Simple idea = simple PRD. Focus on what/why, defer how to PLAN phase.\n\n## After Generating PRD\n\n**Confirm completeness:**\n```\n PRD generated and saved to PRD.md\n\nThis document captures:\n- [Summary of what was captured]\n\nNext steps - Enter the EPCC workflow:\n- Review the PRD and let me know if anything needs adjustment\n- When ready, begin EPCC cycle with `/epcc-explore` (brownfield) or `/epcc-plan` (greenfield)\n\nQuestions or changes to the PRD?\n```\n\n## Feature List Generation (Long-Running Project Support)\n\nAfter creating PRD.md, automatically generate progress tracking files for multi-session work.\n\n### Step 1: Generate epcc-features.json\n\nParse the PRD \"Core Features\" section and create structured feature tracking:\n\n```json\n{\n  \"_warning\": \"Feature definitions are IMMUTABLE. Only 'passes' and 'status' fields may be modified. IT IS CATASTROPHIC TO REMOVE OR EDIT FEATURE DEFINITIONS.\",\n  \"project\": \"[Project Name from PRD]\",\n  \"created\": \"[ISO timestamp]\",\n  \"lastUpdated\": \"[ISO timestamp]\",\n  \"source\": \"PRD.md\",\n  \"features\": [\n    {\n      \"id\": \"F001\",\n      \"name\": \"[Feature Name from P0 list]\",\n      \"description\": \"[Feature description]\",\n      \"priority\": \"P0\",\n      \"status\": \"pending\",\n      \"passes\": false,\n      \"acceptanceCriteria\": [\n        \"[Testable criterion 1 from PRD]\",\n        \"[Testable criterion 2 from PRD]\"\n      ],\n      \"subtasks\": [],\n      \"source\": \"PRD.md#must-have-p0\"\n    }\n  ],\n  \"metrics\": {\n    \"total\": 0,\n    \"verified\": 0,\n    \"inProgress\": 0,\n    \"pending\": 0,\n    \"percentComplete\": 0\n  }\n}\n```\n\n**Feature extraction rules:**\n- Extract all P0 (Must Have) features as high-priority features\n- Extract all P1 (Should Have) features as medium-priority features\n- Extract all P2 (Nice to Have) features as low-priority features\n- Generate acceptance criteria from PRD success criteria and feature descriptions\n- Feature count adapts to project complexity:\n  - **Simple projects**: 3-10 features, 2-3 acceptance criteria each\n  - **Medium projects**: 10-30 features, 3-5 acceptance criteria each\n  - **Complex projects**: 30-100+ features, 5-10+ acceptance criteria each\n\n### Step 2: Initialize epcc-progress.md\n\nCreate human-readable progress log:\n\n```markdown\n# EPCC Progress Log\n\n**Project**: [Project Name]\n**Started**: [Date]\n**Progress**: 0/[N] features (0%)\n\n---\n\n## Session 0: PRD Created - [Date]\n\n### Summary\nProduct Requirements Document created from initial idea exploration.\n\n### Artifacts Created\n- PRD.md - Product requirements\n- epcc-features.json - Feature tracking ([N] features)\n- epcc-progress.md - This progress log\n\n### Feature Summary\n- **P0 (Must Have)**: [X] features\n- **P1 (Should Have)**: [Y] features\n- **P2 (Nice to Have)**: [Z] features\n\n### Next Session\nRun `/trd` for technical requirements or `/epcc-plan` to begin implementation planning.\n\n---\n```\n\n### Step 3: Create Initial Git Commit\n\nIf in a git repository:\n\n```bash\ngit add PRD.md epcc-features.json epcc-progress.md\ngit commit -m \"feat: Initialize project from PRD\n\n- PRD.md: Product requirements with [N] features\n- epcc-features.json: Feature tracking initialized\n- epcc-progress.md: Progress log started\n\nProject: [Project Name]\nComplexity: [Simple/Medium/Complex]\"\n```\n\n### Step 4: Report Generation Results\n\n```markdown\n## Progress Tracking Initialized\n\n **PRD.md** - Product requirements ([complexity] complexity)\n **epcc-features.json** - Feature list with [N] features:\n   - P0 (Must Have): [X] features\n   - P1 (Should Have): [Y] features\n   - P2 (Nice to Have): [Z] features\n **epcc-progress.md** - Progress log initialized\n[ **Git commit** - Initial project state committed]\n\n### Feature Immutability Notice\n\n **IMPORTANT**: Feature definitions in `epcc-features.json` are now IMMUTABLE.\n- Only `passes` and `status` fields may be modified\n- IT IS CATASTROPHIC TO REMOVE OR EDIT FEATURE DEFINITIONS\n- New features may be ADDED but existing ones cannot be changed\n\n### Next Steps\n\n**For Technical Requirements**: `/trd` - Add technical specifications and architecture\n**For Greenfield Projects**: `/epcc-plan` - Create implementation plan\n**For Brownfield Projects**: `/epcc-explore` - Understand existing codebase first\n\n**To check progress later**: `/epcc-resume` - Quick orientation and status\n```\n\n### Adaptive Feature Depth\n\nMatch feature list detail to project complexity:\n\n| Complexity | Feature Count | Acceptance Criteria | Subtasks |\n|------------|---------------|---------------------|----------|\n| Simple | 3-10 | 2-3 per feature | None initially |\n| Medium | 10-30 | 3-5 per feature | None initially |\n| Complex | 30-100+ | 5-10+ per feature | TRD/Plan will add |\n\n**Complexity detection heuristics:**\n- User story count in PRD\n- Number of user types/personas\n- Integration points mentioned\n- Technical constraints listed\n- Timeline (longer = more complex)\n\n## Conversation Principles\n\n### Be Socratic, Not Prescriptive\n\n **Don't dictate**: \"You should use React for this\"\n **Do guide**: \"For UI, we could use React (popular, lots of resources) or Vue (simpler) or vanilla JS (no dependencies). Given your [requirement], which sounds better?\"\n\n### Acknowledge Uncertainty\n\n **Don't guarantee**: \"This will definitely work\"\n **Do qualify**: \"This approach would likely work well, though we'd need to validate performance with real data\"\n\n### Offer Options with Tradeoffs\n\n**Pattern**:\n```\nWe have options:\n1. [Option A]: [Benefit] but [tradeoff]\n2. [Option B]: [Benefit] but [tradeoff]\n3. [Option C]: [Benefit] but [tradeoff]\n\nGiven [user's context], I'd lean toward [Option]. What do you think?\n```\n\n### Ask Follow-ups When Vague\n\n- \"Can you give me an example of what that would look like?\"\n- \"Tell me more about [specific aspect]\"\n- \"How would that work from the user's perspective?\"\n\n### Reflect Back Periodically\n\n\"So if I understand correctly, you want to build [X] that helps [users] do [task] by [method]. The key challenges are [Y] and [Z]. Does that sound right?\"\n\n## Usage Examples\n\n### Basic Invocation\n\n```bash\n# Start with an idea\n/prd \"Build a team knowledge base\"\n\n# Start with a project name\n/prd \"Project Phoenix\"\n\n# Start without context\n/prd\n# Will ask: \"What idea or project would you like to explore?\"\n```\n\n### Example Flow: Quick Mode\n\n**User**: `/prd \"Add export feature to existing dashboard\"`\n\n**Claude**:\n```\nI can help you create either:\n1. **Quick PRD** (15-20 min) - Streamlined for simple/clear projects\n2. **Comprehensive PRD** (45-60 min) - Deep exploration for complex projects\n\nWhich approach works better for this project?\n```\n\n**User**: \"Quick PRD\"\n\n**Claude**: *Uses structured questions for baseline + conversational follow-ups*\n- Project type, user scope, urgency (structured)\n- What formats? All data or filtered? (conversational)\n- Environment, data storage, auth (structured if needed)\n- Timeline, constraints (structured)\n\n**Claude**: *Generates lean PRD matching complexity*\n\n**Total time**: ~15 minutes\n\n### Example Flow: Comprehensive Mode\n\n**User**: `/prd \"Build AI-powered customer support platform\"`\n\n**Claude**: Recommends Comprehensive mode\n\n**Claude**: *Deep exploration across all phases*\n- Structured questions for baseline decisions\n- Extensive conversational exploration of problem space, users, features, architecture\n- Multiple rounds of clarification and refinement\n\n**Claude**: *Generates comprehensive PRD with full detail*\n\n**Total time**: ~50 minutes\n\n## Common Pitfalls (Anti-Patterns)\n\n###  Asking Questions User Already Answered\n**Don't**: Repeat questions  **Do**: Reference earlier answers\n\n###  Using Structured Questions for Everything\n**Don't**: Force every question into AskUserQuestion  **Do**: Use conversation for open-ended exploration\n\n###  Following Templates Rigidly\n**Don't**: Generate comprehensive PRD for \"add button\" task  **Do**: Match depth to complexity\n\n###  Counting Questions Instead of Assessing Clarity\n**Don't**: Ask 8 questions because guide says 5-8  **Do**: Ask until genuinely clear\n\n###  Interrogating Instead of Conversing\n**Don't**: Rapid-fire 20 questions  **Do**: Natural dialogue with pauses for reflection\n\n## Second-Order Convergence Warnings\n\nEven with this guidance, you may default to:\n\n-  **Asking questions to hit count targets** (ask when genuinely unclear, not to fill quota)\n-  **Not using AskUserQuestion proactively** (use by default for decisions, don't wait for \"help me decide\")\n-  **Using conversation when AskUserQuestion would be clearer** (structured questions for decisions with 2-4 options)\n-  **Assuming \"comprehensive mode\" means exhaustive questioning** (adapt to actual complexity)\n-  **Generating cookie-cutter PRDs** (match depth to project - simple project = simple PRD)\n-  **Following structured question examples as templates** (adapt pattern to your specific decisions)\n-  **Asking when user already provided clear answer** (listen and document, don't re-ask)\n\n## Remember\n\n**Your role**: Socratic guide helping users articulate their ideas through **structured questions and dialogue**.\n\n**Work pattern**: Ask (AskUserQuestion for decisions)  Listen  Clarify (conversation for follow-ups)  Document. Match depth to complexity.\n\n**AskUserQuestion usage**: PRIMARY method for all decisions with 2-4 clear options. Use proactively, don't wait for user to request it.\n\n**Conversational follow-ups**: SECONDARY method for open-ended exploration, gathering context, and clarifying structured answers.\n\n**PRD depth**: Simple project = simple PRD. Complex project = comprehensive PRD. Always adapt.\n\n **PRD complete - ready to begin EPCC workflow (Explore  Plan  Code  Commit)!**"
              },
              {
                "name": "/trd",
                "description": "Technical Requirements Document generation through interactive interview",
                "path": "assets/claude-code-plugins/plugins/epcc-workflow/commands/trd.md",
                "frontmatter": {
                  "name": "trd",
                  "description": "Technical Requirements Document generation through interactive interview",
                  "version": "3.1.0",
                  "argument-hint": "[initial-technical-context-or-project-name]"
                },
                "content": "# Technical Requirements Document (TRD) Generator\n\nGenerate comprehensive **TECH_REQ.md** through collaborative technical discovery. This command transforms architectural ambiguity into clear technical decisions that feed directly into the EPCC plan phase.\n\n**Opening Principle**: High-quality TRDs transform architectural ambiguity into clear technical decisions through collaborative discovery, enabling confident implementation with the right technology choices.\n\n@../docs/EPCC_BEST_PRACTICES.md - Comprehensive guide covering sub-agent delegation, clarification strategies, error handling patterns, and technical requirements workflow optimization\n\n## What This Command Does\n\n**Purpose**: Create Technical Requirements Document (TECH_REQ.md) that defines:\n- Architecture patterns and component structure\n- Technology stack with justified choices\n- Data models and storage strategies\n- Integration points and API design\n- Security and compliance approach\n- Performance and scalability plan\n\n**Output**: `TECH_REQ.md` file\n\n**Position in workflow**:\n- **Optional input**: PRD.md (product requirements, if available)\n- **This command**: Generate TECH_REQ.md through technical interview\n- **Feeds into**: `/epcc-plan` (strategic implementation planning)\n\n## TRD Discovery Philosophy\n\n**Opening Principle**: Discover technical requirements through **structured questions and collaborative dialogue**, not assumptions.\n\n### Core Approach\n\n** Do (Default Behavior)**:\n- **Use AskUserQuestion proactively** for all technical decisions with 2-4 clear options\n- Read PRD.md if available to understand product context\n- Ask about architecture, stack, infrastructure aligned with product needs\n- Present technology options with tradeoffs (not recommendations as facts)\n- Match technical depth to project complexity\n- Document rationale for every technical decision\n\n** Don't**:\n- Assume tech stack without asking (\"I'll use React and PostgreSQL\"  Ask first!)\n- Make technology recommendations without presenting alternatives and tradeoffs\n- Skip reading PRD.md if it exists (product context informs technical decisions)\n- Ask about implementation details (belongs in CODE phase)\n- Force comprehensive TRD for simple projects (CRUD app  distributed systems design)\n\n**Remember**: You're discovering technical requirements, not implementing. Focus on WHAT technologies and WHY, defer HOW to CODE phase.\n\n## Discovery Objectives\n\n**What we're discovering**:\n\n1. **Architecture** (Patterns, service boundaries, component structure)\n   - Monolith? Microservices? Serverless? JAMstack? Hybrid?\n   - Design patterns to follow\n   - How components fit together\n\n2. **Technology Stack** (Languages, frameworks, tools, libraries)\n   - Backend: Language + framework\n   - Frontend: Framework/library or vanilla\n   - Infrastructure: Hosting, deployment, orchestration\n   - Tooling: Build tools, testing frameworks, CI/CD\n\n3. **Data Models** (Storage, schemas, relationships)\n   - Database choice with rationale\n   - Schema design approach\n   - Data relationships and migrations\n   - Caching strategy\n\n4. **Integrations** (APIs, third-party services, authentication)\n   - API design (REST? GraphQL? gRPC? tRPC?)\n   - Authentication method (JWT? OAuth2? Session? Auth0?)\n   - Third-party services (payment, email, analytics, etc.)\n   - Webhooks and event handling\n\n5. **Security** (Auth, compliance, data protection)\n   - Authentication & authorization approach\n   - Data protection and encryption\n   - OWASP considerations\n   - Compliance requirements (GDPR, HIPAA, SOC2, etc.)\n\n6. **Performance** (Scalability, caching, optimization)\n   - Expected load and scaling strategy\n   - Caching layers (CDN, application, database)\n   - Performance budgets and monitoring\n   - Optimization priorities\n\n**Depth adaptation**:\n- **Simple project**  Focus on stack + data + basic security\n- **Medium project**  Add integrations + performance + detailed security\n- **Complex project**  Comprehensive architecture + compliance + high-scale design\n\n## Clarification Strategy\n\n### When to Use AskUserQuestion (PRIMARY METHOD)\n\n** Use AskUserQuestion for** (default for all technical decisions):\n- **Architecture decisions**: \"Monolith vs Microservices vs Serverless?\"\n- **Technology choices**: \"Database: PostgreSQL vs MongoDB vs MySQL?\"\n- **Infrastructure decisions**: \"Hosting: AWS vs GCP vs Azure vs Vercel?\"\n- **Authentication methods**: \"Auth: JWT vs OAuth2 vs Session vs Auth0?\"\n- **API design**: \"API style: REST vs GraphQL vs gRPC?\"\n- **Any decision with 2-4 clear options**\n\n**Pattern**:\n```typescript\nAskUserQuestion({\n  questions: [{\n    question: \"What database technology fits your needs?\",\n    header: \"Database\",\n    multiSelect: false,\n    options: [\n      {\n        label: \"PostgreSQL\",\n        description: \"Relational, ACID compliant, complex queries, JSON support, mature ecosystem\"\n      },\n      {\n        label: \"MongoDB\",\n        description: \"Document store, flexible schema, good for JSON-heavy data, horizontal scaling\"\n      },\n      {\n        label: \"MySQL\",\n        description: \"Relational, widely supported, proven at scale, simpler than PostgreSQL\"\n      },\n      {\n        label: \"DynamoDB\",\n        description: \"AWS managed NoSQL, serverless, auto-scaling, simple key-value or documents\"\n      }\n    ]\n  }]\n})\n```\n\n### When to Converse Naturally (FALLBACK)\n\n** Use conversation for**:\n- Open-ended exploration (\"Tell me about your data model\")\n- Clarifying context (\"What scale are we targeting?\")\n- Following up on answers (\"You mentioned real-time features - how critical is sub-second latency?\")\n- Discussing custom/hybrid approaches not fitting 2-4 options\n\n** Don't use conversation for**:\n- Standard technology choices (database, hosting, auth  use AskUserQuestion)\n- Decisions already answered in PRD.md (read it first)\n- Implementation details (defer to CODE phase)\n\n### Check PRD.md First\n\n**Before asking questions**:\n```bash\nif [ -f \"PRD.md\" ]; then\n    # Read PRD.md to understand:\n    # - Features (what needs technical support?)\n    # - Users (scale, geography, access patterns)\n    # - Constraints (timeline, budget, compliance)\n    # - Success criteria (performance targets, uptime, etc.)\n\n    # Then ask technical questions informed by product context\nfi\n```\n\n**Reference PRD dynamically**:\n- \"Based on the real-time collaboration feature in PRD.md, we need to consider WebSocket vs polling...\"\n- \"Given the 100K user target in PRD.md, let's discuss caching strategy...\"\n- \"The GDPR compliance mentioned in PRD.md means we need...\"\n\n**If PRD.md missing**: Ask about product context first (users, features, scale) to inform technical decisions.\n\n**Research & Exploration**:\n- **WebSearch/WebFetch**: Use for technology comparisons, best practices, domain standards, official docs when unfamiliar\n- **/epcc-explore**: Use for brownfield projects to discover existing architecture, tech stack, patterns\n- **Skip**: When user has complete technical vision or simple feature\n\n**Decision heuristic**: Research when comparing options or learning domain; explore brownfield for existing patterns; skip if user provided sufficient context.\n\n## Interview Mode Selection\n\nPresent mode choice to user with clear time/depth tradeoffs:\n\n### Quick TRD (20-30 minutes)\n\n**When to use**:\n- Simple architecture (monolith or simple SPA)\n- Well-known tech stack (standard CRUD with common tools)\n- Minimal integrations (0-2 third-party services)\n- Clear technical path (no major unknowns)\n\n**Coverage**:\n- Core stack decisions (language, framework, database, hosting)\n- Basic security (auth method)\n- Simple data model\n- Essential integrations only\n\n**Question count**: ~8-12 structured questions focused on essentials\n\n### Comprehensive TRD (60-90 minutes)\n\n**When to use**:\n- Complex architecture (microservices, event-driven, distributed)\n- Multiple technology decisions (polyglot, multiple services)\n- Many integrations (payment, email, analytics, webhooks, etc.)\n- Compliance requirements (GDPR, HIPAA, SOC2)\n- High scale or performance critical (millions of users, sub-second latency)\n\n**Coverage**:\n- Deep architecture exploration across all 6 discovery phases\n- Detailed technology evaluation with tradeoffs\n- Comprehensive security and compliance planning\n- Performance and scalability design\n- Migration and deployment strategy\n\n**Question count**: ~25-35 structured questions + conversational deep-dives\n\n### Mode Selection Pattern\n\n```\nI can help create your Technical Requirements Document.\n\nBased on [initial context], this appears to be a [simple/medium/complex] technical scope.\n\nI can create either:\n1. **Quick TRD** (20-30 min) - Core stack and architecture for straightforward projects\n2. **Comprehensive TRD** (60-90 min) - Deep technical exploration for complex systems\n\nWhich approach works better for your project?\n```\n\n**Adapt mode during interview**: If complexity emerges (user mentions compliance, high scale, many integrations), suggest switching to comprehensive.\n\n## Discovery Phases\n\n### Phase 1: Architecture & Patterns\n\n**Goal**: Define high-level structure and component organization.\n\n**Context**: Research with WebSearch/WebFetch(\"[architecture] patterns 2025\"), explore with /epcc-explore (brownfield).\n\n**Use AskUserQuestion for**:\n```typescript\n// Architecture Pattern\n{\n  question: \"What architectural pattern fits your project?\",\n  header: \"Architecture\",\n  options: [\n    {\n      label: \"Monolith\",\n      description: \"Single codebase, simpler deployment, good for small teams, faster initial development\"\n    },\n    {\n      label: \"Microservices\",\n      description: \"Independent services, complex deployment, team autonomy, scales components independently\"\n    },\n    {\n      label: \"Serverless\",\n      description: \"Function-based, auto-scaling, pay-per-use, less infrastructure management\"\n    },\n    {\n      label: \"JAMstack\",\n      description: \"Static generation + APIs, excellent performance, simple hosting, limited dynamic features\"\n    }\n  ]\n}\n\n// Design Patterns (if complex project)\n{\n  question: \"What design patterns are important for your system?\",\n  header: \"Patterns\",\n  multiSelect: true,\n  options: [\n    {label: \"Event-driven\", description: \"Async communication, decoupled components, eventual consistency\"},\n    {label: \"CQRS\", description: \"Separate read/write models, optimized queries, complex to implement\"},\n    {label: \"Repository\", description: \"Data access abstraction, testable, clean architecture\"},\n    {label: \"Factory\", description: \"Object creation patterns, dependency injection, flexible instantiation\"}\n  ]\n}\n```\n\n**Converse about**:\n- Component structure (\"What are the main components/services?\")\n- Service boundaries (if microservices)\n- Data flow between components\n\n**From PRD.md (if available)**: Features  Architectural needs (real-time? background jobs? file processing?)\n\n### Phase 2: Technology Stack & Infrastructure\n\n**Goal**: Select languages, frameworks, hosting, and deployment approach.\n\n**Context**: Research with WebSearch/WebFetch(\"[tech-stack] best practices 2025\"), explore with /epcc-explore (brownfield).\n\n**Use AskUserQuestion for**:\n```typescript\n// Backend Language\n{\n  question: \"What backend language/runtime fits your needs?\",\n  header: \"Backend\",\n  options: [\n    {label: \"Node.js\", description: \"JavaScript/TypeScript, async I/O, npm ecosystem, good for APIs\"},\n    {label: \"Python\", description: \"Django/Flask/FastAPI, AI/ML libraries, readable, slower than compiled\"},\n    {label: \"Go\", description: \"Compiled, fast, simple concurrency, strong typing, smaller ecosystem\"},\n    {label: \"Java/Kotlin\", description: \"Enterprise-grade, JVM, Spring ecosystem, verbose, battle-tested\"}\n  ]\n}\n\n// Frontend Framework\n{\n  question: \"What frontend approach do you want?\",\n  header: \"Frontend\",\n  options: [\n    {label: \"React\", description: \"Popular, large ecosystem, component-based, JSX syntax, flexible\"},\n    {label: \"Vue\", description: \"Simpler than React, good docs, template syntax, smaller ecosystem\"},\n    {label: \"Svelte\", description: \"Compile-time framework, fast, less boilerplate, newer ecosystem\"},\n    {label: \"Vanilla JS\", description: \"No framework, full control, smaller bundle, more manual work\"}\n  ]\n}\n\n// Hosting Infrastructure\n{\n  question: \"Where will you host this application?\",\n  header: \"Hosting\",\n  options: [\n    {label: \"AWS\", description: \"Full service suite, complex, powerful, enterprise-ready, higher cost\"},\n    {label: \"Google Cloud\", description: \"Good for AI/ML, Kubernetes native, competitive pricing\"},\n    {label: \"Azure\", description: \"Enterprise integration, Microsoft stack, hybrid cloud\"},\n    {label: \"Vercel/Netlify\", description: \"Simple deployment, great DX, limited backend, good for JAMstack\"}\n  ]\n}\n```\n\n**Converse about**:\n- Framework choices within language (Express vs Fastify? Django vs FastAPI?)\n- Build tools and CI/CD pipeline\n- Deployment strategy (containers? serverless? VMs?)\n\n**From PRD.md (if available)**: Budget  Hosting costs, Timeline  Deployment complexity\n\n### Phase 3: Data Models & Storage\n\n**Goal**: Define data storage strategy, schemas, and caching.\n\n**Context**: Research with WebSearch/WebFetch(\"[database] best practices 2025\"), explore with /epcc-explore (brownfield).\n\n**Use AskUserQuestion for**:\n```typescript\n// Database Selection\n{\n  question: \"What database technology fits your data model?\",\n  header: \"Database\",\n  options: [\n    {label: \"PostgreSQL\", description: \"Relational, ACID, complex queries, JSON support, mature\"},\n    {label: \"MongoDB\", description: \"Document store, flexible schema, good for JSON, horizontal scaling\"},\n    {label: \"MySQL\", description: \"Relational, widely supported, proven at scale, simpler than Postgres\"},\n    {label: \"DynamoDB\", description: \"AWS NoSQL, serverless, auto-scaling, key-value or documents\"}\n  ]\n}\n\n// Caching Strategy (if medium/complex)\n{\n  question: \"What caching approach do you need?\",\n  header: \"Caching\",\n  multiSelect: true,\n  options: [\n    {label: \"Redis\", description: \"In-memory, fast, pub/sub, session storage, requires management\"},\n    {label: \"CDN\", description: \"Edge caching, static assets, global distribution, reduces origin load\"},\n    {label: \"Application cache\", description: \"In-process, simple, no network, lost on restart\"},\n    {label: \"Database query cache\", description: \"Built-in, automatic, limited control\"}\n  ]\n}\n```\n\n**Converse about**:\n- Data model structure (entities, relationships)\n- Schema design approach (migrations? versioning?)\n- Data access patterns (read-heavy? write-heavy? analytics?)\n\n**From PRD.md (if available)**: Features  Data entities, Users  Access patterns\n\n### Phase 4: Integrations & APIs\n\n**Goal**: Define API design, authentication, and third-party integrations.\n\n**Context**: Research with WebSearch/WebFetch(\"[API/auth] best practices 2025\"), explore with /epcc-explore (brownfield).\n\n**Use AskUserQuestion for**:\n```typescript\n// API Style\n{\n  question: \"What API style fits your needs?\",\n  header: \"API\",\n  options: [\n    {label: \"REST\", description: \"Standard HTTP, widely understood, simple, over-fetching/under-fetching\"},\n    {label: \"GraphQL\", description: \"Flexible queries, precise data fetching, complex setup, learning curve\"},\n    {label: \"gRPC\", description: \"High performance, typed, binary protocol, requires code generation\"},\n    {label: \"tRPC\", description: \"Type-safe, TypeScript end-to-end, simple, ecosystem smaller\"}\n  ]\n}\n\n// Authentication Method\n{\n  question: \"How will users authenticate?\",\n  header: \"Auth\",\n  options: [\n    {label: \"JWT\", description: \"Stateless, scalable, client stores token, can't revoke easily\"},\n    {label: \"Session\", description: \"Server-side state, easy to revoke, requires session store\"},\n    {label: \"OAuth2\", description: \"Third-party login (Google, GitHub), complex setup, better UX\"},\n    {label: \"Auth0/Clerk\", description: \"Managed service, fast setup, monthly cost, less control\"}\n  ]\n}\n\n// Third-Party Services (multiSelect)\n{\n  question: \"What third-party services do you need?\",\n  header: \"Services\",\n  multiSelect: true,\n  options: [\n    {label: \"Payment\", description: \"Stripe, PayPal, Square - transaction processing\"},\n    {label: \"Email\", description: \"SendGrid, Mailgun, AWS SES - transactional emails\"},\n    {label: \"Storage\", description: \"S3, Cloudinary, Uploadcare - file uploads and CDN\"},\n    {label: \"Analytics\", description: \"Mixpanel, Amplitude, PostHog - user behavior tracking\"}\n  ]\n}\n```\n\n**Converse about**:\n- API versioning strategy\n- Webhook handling (if needed)\n- Rate limiting and API security\n\n**From PRD.md (if available)**: Features  Required integrations (payments, notifications, etc.)\n\n### Phase 5: Security & Compliance\n\n**Goal**: Define authentication, authorization, data protection, and compliance.\n\n**Context**: Research with WebSearch/WebFetch(\"[security/compliance] requirements 2025\"), explore with /epcc-explore (brownfield).\n\n**Use AskUserQuestion for**:\n```typescript\n// Authorization Model\n{\n  question: \"What authorization model do you need?\",\n  header: \"Authz\",\n  options: [\n    {label: \"RBAC\", description: \"Role-based, simple, roles assigned to users, good for most apps\"},\n    {label: \"ABAC\", description: \"Attribute-based, flexible, complex policies, enterprise use cases\"},\n    {label: \"Simple ownership\", description: \"Users own resources, basic access control, simplest\"},\n    {label: \"Multi-tenancy\", description: \"Isolated data per tenant, complex, SaaS products\"}\n  ]\n}\n\n// Compliance Requirements (multiSelect, if applicable)\n{\n  question: \"What compliance standards apply?\",\n  header: \"Compliance\",\n  multiSelect: true,\n  options: [\n    {label: \"GDPR\", description: \"EU data privacy, right to deletion, consent management\"},\n    {label: \"HIPAA\", description: \"Healthcare data, strict security, audit logs, encryption\"},\n    {label: \"SOC2\", description: \"Security controls, audit reports, enterprise customers\"},\n    {label: \"PCI DSS\", description: \"Payment card data, strict requirements, third-party audits\"}\n  ]\n}\n```\n\n**Converse about**:\n- Data encryption (at rest? in transit?)\n- OWASP Top 10 considerations\n- Security testing approach\n\n**From PRD.md (if available)**: Constraints  Compliance requirements, Data sensitivity\n\n### Phase 6: Performance & Scalability\n\n**Goal**: Define performance targets, scaling strategy, and optimization priorities.\n\n**Context**: Research with WebSearch/WebFetch(\"[performance/scaling] patterns 2025\"), explore with /epcc-explore (brownfield).\n\n**Use AskUserQuestion for**:\n```typescript\n// Expected Scale\n{\n  question: \"What scale are you targeting?\",\n  header: \"Scale\",\n  options: [\n    {label: \"Small (<1K users)\", description: \"Single server, minimal caching, simple deployment\"},\n    {label: \"Medium (1K-100K users)\", description: \"Load balancer, caching layer, horizontal scaling\"},\n    {label: \"Large (100K-1M users)\", description: \"Multi-region, CDN, advanced caching, auto-scaling\"},\n    {label: \"Massive (>1M users)\", description: \"Global infrastructure, edge computing, complex architecture\"}\n  ]\n}\n\n// Performance Priorities (multiSelect)\n{\n  question: \"What performance aspects are most critical?\",\n  header: \"Performance\",\n  multiSelect: true,\n  options: [\n    {label: \"Page load speed\", description: \"Initial render, time to interactive, Core Web Vitals\"},\n    {label: \"API latency\", description: \"Response times, database query optimization\"},\n    {label: \"Real-time updates\", description: \"WebSocket, SSE, sub-second data freshness\"},\n    {label: \"Background jobs\", description: \"Async processing, job queues, worker scaling\"}\n  ]\n}\n```\n\n**Converse about**:\n- Performance budgets (page load <2s? API <100ms?)\n- Monitoring and observability strategy\n- Optimization approach (optimize now vs later?)\n\n**From PRD.md (if available)**: Success criteria  Performance targets, Users  Scale expectations\n\n## Adaptive Interview Heuristics\n\n**Match question depth to project complexity** (discovered dynamically):\n\n### Simple Project Indicators\n- Single service/application\n- <10K users\n- Standard CRUD operations\n- 0-2 integrations\n- No compliance requirements\n\n**Adapt**: Focus on Stack + Data + Basic Security (~10-12 questions)\n\n### Medium Project Indicators\n- 2-3 services\n- 10K-100K users\n- Some real-time features\n- 3-5 integrations\n- Basic security needs\n\n**Adapt**: All 6 phases with moderate depth (~20-25 questions)\n\n### Complex Project Indicators\n- Microservices/distributed\n- >100K users\n- Compliance requirements\n- >5 integrations\n- High performance/availability needs\n\n**Adapt**: Comprehensive exploration of all 6 phases (~30-40 questions)\n\n**Dynamic adjustment**: If user mentions compliance/high-scale/many integrations during simple TRD  offer to switch to comprehensive mode.\n\n## TECH_REQ.md Output Structure\n\n**Forbidden patterns**:\n-  Comprehensive TRD for simple CRUD app (violates complexity matching)\n-  Technology choices without rationale (\"Use PostgreSQL\"  WHY PostgreSQL vs alternatives?)\n-  Implementation details (exact API endpoints, function signatures  belongs in CODE phase)\n-  Assuming tech stack without asking (you discover, not prescribe)\n-  Rigid template sections for minimal projects (simple project = simple TRD)\n\n**TRD structure - 6 core dimensions**:\n\n### Simple TRD (~400-600 tokens)\n**When**: Single service, standard stack, minimal integrations, <10K users\n\n```markdown\n# Technical Requirements: [Project Name]\n\n**Created**: [Date] | **Complexity**: Simple | **From PRD**: [Yes/No]\n\n## Architecture\n**Pattern**: [Monolith/SPA/JAMstack]\n**Rationale**: [Why this pattern fits the project]\n\n## Technology Stack\n**Backend**: [Language + Framework] - [Rationale]\n**Frontend**: [Framework/Vanilla] - [Rationale]\n**Database**: [Database] - [Rationale]\n**Hosting**: [Platform] - [Rationale]\n\n## Data Model\n**Core Entities**: [List 3-5 main entities]\n**Relationships**: [Key relationships]\n**Migrations**: [Strategy: tool/approach]\n\n## Security\n**Authentication**: [Method] - [Rationale]\n**Authorization**: [Approach] - [Rationale]\n**Data Protection**: [Encryption strategy]\n\n## Integrations\n[List essential integrations with rationale, or \"None\" if standalone]\n\n## Performance\n**Expected Scale**: [<1K users, load expectations]\n**Caching**: [Strategy if needed, or \"Not required initially\"]\n\n## PRD Alignment\n[If PRD.md exists, reference how technical choices support product requirements]\n\n## Next Steps\nTechnical requirements defined. Ready for:\n- Brownfield: `/epcc-explore` then `/epcc-plan`\n- Greenfield: `/epcc-plan` (skip explore)\n```\n\n### Medium TRD (~800-1,200 tokens)\n**When**: Multiple services, moderate complexity, several integrations, 10K-100K users\n\nAdd to simple structure:\n- **Architecture Diagram**: Component relationships, data flow\n- **Detailed Stack Justification**: Compare alternatives with tradeoffs\n- **API Design**: REST/GraphQL, versioning strategy, rate limiting\n- **Caching Strategy**: Layers (CDN, application, database), invalidation\n- **Monitoring**: Observability approach, key metrics\n- **Deployment**: CI/CD pipeline, environment strategy\n\n### Complex TRD (~1,500-2,500 tokens)\n**When**: Distributed system, compliance requirements, high scale, many integrations\n\nAdd to medium structure:\n- **Detailed Architecture**: Service boundaries, event flows, async patterns\n- **Technology Evaluation**: Deep comparison of alternatives with scoring\n- **Data Architecture**: Schema design, partitioning, replication, migrations\n- **Security & Compliance**: OWASP checklist, compliance requirements (GDPR/HIPAA/SOC2), audit logging\n- **Performance & Scale**: Load testing strategy, auto-scaling, multi-region, CDN strategy\n- **Disaster Recovery**: Backup strategy, failover, RTO/RPO targets\n- **Migration Plan**: If replacing existing system\n\n**Depth heuristic**: TRD complexity should match technical complexity. Don't write distributed systems TRD for simple CRUD app.\n\n### Full TRD Template (Adapt to Complexity)\n\n```markdown\n# Technical Requirements Document: [Project Name]\n\n**Created**: [Date]\n**Version**: 1.0\n**Complexity**: [Simple/Medium/Complex]\n**PRD Reference**: [PRD.md if available, or \"Standalone\"]\n\n---\n\n## Executive Summary\n[2-3 sentence technical overview]\n\n## Research & Exploration\n\n**Key Insights** (from WebSearch/WebFetch/exploration):\n- **[Technology choice]**: [Research finding, benchmark, or rationale]\n- **[Pattern/approach]**: [Best practice discovered or code pattern leveraged]\n- **[Existing component]**: [Reusable code discovered from exploration]\n\n**Documentation Identified**:\n- **[Doc type]**: Priority [H/M/L] - [Why needed for this project]\n\n## Architecture\n\n### Pattern\n[Monolith/Microservices/Serverless/JAMstack/Hybrid]\n\n**Rationale**: [Why this pattern? Considered alternatives?]\n\n### Component Structure\n[List main components/services and their responsibilities]\n\n### Data Flow\n[How data moves through the system - simple description or diagram]\n\n### Design Patterns\n[Key patterns: Event-driven, CQRS, Repository, etc.]\n\n## Technology Stack\n\n### Backend\n**Language/Runtime**: [Choice] - [Rationale vs alternatives]\n**Framework**: [Choice] - [Rationale vs alternatives]\n\n### Frontend\n**Framework**: [React/Vue/Svelte/Vanilla] - [Rationale vs alternatives]\n**Build Tools**: [Vite/Webpack/etc.] - [Rationale]\n\n### Database\n**Primary Database**: [PostgreSQL/MongoDB/MySQL/etc.] - [Rationale vs alternatives]\n**Caching**: [Redis/CDN/Application cache] - [Strategy]\n\n### Infrastructure\n**Hosting**: [AWS/GCP/Azure/Vercel/etc.] - [Rationale vs alternatives]\n**Deployment**: [Containers/Serverless/VMs] - [Rationale]\n**CI/CD**: [GitHub Actions/GitLab CI/CircleCI/etc.] - [Strategy]\n\n## Environment Setup\n\n**init.sh required**: [Yes/No]\n\n**Triggers** (if any apply, init.sh is needed):\n- [ ] Web server / API backend\n- [ ] Database setup required\n- [ ] External services (Redis, Elasticsearch, etc.)\n- [ ] Complex dependency installation\n- [ ] Environment variables required\n\n**Components to initialize** (if init.sh required):\n- [ ] Virtual environment / package installation\n- [ ] Database setup/migration\n- [ ] Service dependencies: [list services]\n- [ ] Environment variables: [list vars, no secrets]\n- [ ] Development server startup\n\n**Startup command**: [e.g., \"npm run dev\", \"uvicorn main:app --reload\"]\n**Health check**: [e.g., \"curl localhost:3000/health\"]\n\n## Data Architecture\n\n### Core Entities\n1. **[Entity Name]**\n   - Purpose: [What it represents]\n   - Key attributes: [Essential fields]\n   - Relationships: [Connections to other entities]\n\n2. **[Entity Name]**\n   - [Same structure]\n\n### Schema Design\n**Approach**: [Normalized/Denormalized/Hybrid] - [Rationale]\n**Migrations**: [Tool: Prisma/TypeORM/Alembic/etc.] - [Strategy]\n\n### Data Access Patterns\n- [Read-heavy? Write-heavy? Analytics?]\n- [Query optimization strategy]\n\n## API Design\n\n### API Style\n**Choice**: [REST/GraphQL/gRPC/tRPC] - [Rationale vs alternatives]\n\n### Endpoints (if REST)\n[High-level endpoint groups, not exhaustive list]\n\n### Authentication\n**Method**: [JWT/Session/OAuth2/Auth0] - [Rationale vs alternatives]\n**Token Storage**: [Where tokens stored, expiry strategy]\n\n### Authorization\n**Model**: [RBAC/ABAC/Ownership/Multi-tenancy] - [Rationale]\n\n### Rate Limiting\n[Strategy if needed]\n\n## Integrations\n\n### Third-Party Services\n1. **[Service Name]** (e.g., Stripe for payments)\n   - Purpose: [What it does]\n   - Rationale: [Why this vs alternatives]\n   - Integration approach: [API/SDK/Webhook]\n\n2. **[Service Name]**\n   - [Same structure]\n\n### External APIs\n[Any external APIs to consume]\n\n### Webhooks\n[If handling incoming webhooks]\n\n## Security\n\n### Authentication & Authorization\n**Authentication**: [Detailed approach from API Design]\n**Authorization**: [Detailed model from API Design]\n\n### Data Protection\n**Encryption at Rest**: [Yes/No - approach if yes]\n**Encryption in Transit**: [TLS configuration]\n**Sensitive Data**: [PII handling, secrets management]\n\n### OWASP Considerations\n[Key OWASP Top 10 items relevant to this project]\n\n### Compliance (if applicable)\n**Requirements**: [GDPR/HIPAA/SOC2/PCI DSS/etc.]\n**Implementation**: [How compliance requirements are met]\n**Audit Logging**: [What's logged, retention period]\n\n## Performance & Scalability\n\n### Scale Targets\n**Users**: [Expected user count]\n**Requests**: [Expected req/sec or req/day]\n**Data Volume**: [Expected data growth]\n\n### Performance Budgets\n- **Page Load**: [Target: <2s]\n- **API Latency**: [Target: <100ms p95]\n- **Database Queries**: [Target: <50ms p95]\n\n### Caching Strategy\n**Layers**:\n1. **CDN**: [Static assets, edge caching]\n2. **Application Cache**: [Redis/in-memory, what's cached]\n3. **Database Query Cache**: [If applicable]\n\n**Invalidation**: [Strategy for cache freshness]\n\n### Scaling Approach\n**Horizontal vs Vertical**: [Choice and rationale]\n**Auto-scaling**: [Triggers, min/max instances]\n**Load Balancing**: [Strategy]\n\n### Monitoring & Observability\n**Metrics**: [What to track: latency, errors, throughput]\n**Logging**: [Structured logging approach]\n**Tracing**: [Distributed tracing if microservices]\n**Tools**: [DataDog/New Relic/Prometheus/etc.]\n\n## Deployment Strategy\n\n### Environments\n- **Development**: [Local/shared dev environment]\n- **Staging**: [Pre-production testing]\n- **Production**: [Live environment]\n\n### CI/CD Pipeline\n1. [Build step]\n2. [Test step]\n3. [Deploy step]\n\n### Rollback Strategy\n[How to revert if deployment fails]\n\n### Zero-Downtime Deployment\n[Blue-green? Rolling? Canary?]\n\n## Disaster Recovery (Complex projects)\n\n### Backup Strategy\n**Frequency**: [Hourly/Daily/etc.]\n**Retention**: [How long backups kept]\n**Testing**: [Backup restore testing frequency]\n\n### Failover\n**RTO** (Recovery Time Objective): [Target downtime]\n**RPO** (Recovery Point Objective): [Acceptable data loss]\n\n## Migration Plan (If applicable)\n\n[If replacing existing system or migrating data]\n\n### Migration Strategy\n- [Approach: Big bang? Phased? Strangler pattern?]\n\n### Data Migration\n- [Source  Target mapping]\n- [Validation strategy]\n\n### Rollback Plan\n- [How to revert if migration fails]\n\n## Risks & Mitigation\n\n| Risk | Impact | Likelihood | Mitigation |\n|------|--------|------------|------------|\n| [Technical risk] | H/M/L | H/M/L | [How to address] |\n\n## Assumptions\n\n[Critical technical assumptions that could change the plan]\n\n## Out of Scope\n\n[Technical decisions deferred or explicitly excluded]\n\n## PRD Alignment\n\n[If PRD.md exists]\n\n**Product Requirements Supported**:\n- [Feature from PRD]  [Technical approach]\n- [Constraint from PRD]  [How technical design respects it]\n- [Success criteria from PRD]  [How architecture enables measurement]\n\n**Technical Decisions Informing Product**:\n- [Technology limitation]  [Product implication]\n- [Performance characteristic]  [User experience impact]\n\n## Next Steps\n\nThis TRD feeds into the EPCC workflow. Choose your entry point:\n\n**For Greenfield Projects** (new codebase):\n1. Review & approve this TRD\n2. Run `/epcc-plan` to create implementation plan (can skip Explore)\n3. Begin development with `/epcc-code`\n4. Finalize with `/epcc-commit`\n\n**For Brownfield Projects** (existing codebase):\n1. Review & approve this TRD\n2. Run `/epcc-explore` to understand existing codebase and patterns\n3. Run `/epcc-plan` to create implementation plan based on exploration + this TRD\n4. Begin development with `/epcc-code`\n5. Finalize with `/epcc-commit`\n\n**Note**: The core EPCC workflow is: **Explore  Plan  Code  Commit**. This TRD is the optional technical preparation step before that cycle begins.\n\n---\n\n**End of TRD**\n```\n\n**Completeness heuristic**: TRD is ready when you can answer:\n-  What's the architecture pattern and why?\n-  What's the technology stack with rationale for each choice?\n-  What's the data model and storage strategy?\n-  How are integrations and APIs designed?\n-  How is security and compliance handled?\n-  How does the system scale and perform?\n-  If PRD exists, how do technical choices support product requirements?\n\n**Anti-patterns**:\n-  **Simple CRUD with 2,000-token distributed systems TRD**  Violates complexity matching\n-  **Complex platform with 500-token TRD**  Insufficient technical detail\n-  **\"Use PostgreSQL\" without explaining why vs MongoDB/MySQL**  No rationale\n-  **Implementation details**  \"Create UserService class with getUserById method\" belongs in CODE phase\n-  **Every section filled with \"TBD\"**  If unknown, document as assumption or open question\n-  **No security consideration**  All projects need auth/data protection discussion\n\n---\n\n**Remember**: Match TRD depth to technical complexity. Simple project = simple TRD. Focus on WHAT and WHY, defer HOW to CODE phase.\n\n## After Generating TECH_REQ.md\n\n**Confirm completeness:**\n```\n TECH_REQ.md generated and saved\n\nThis document captures:\n- Architecture: [Pattern chosen]\n- Tech Stack: [Key technologies with rationale]\n- Data Model: [Storage approach]\n- Security: [Auth/compliance approach]\n- Scalability: [Scale strategy]\n[+ PRD Alignment if PRD.md existed]\n\nNext steps - Enter the EPCC workflow:\n- Review the TRD and let me know if anything needs adjustment\n- When ready, begin EPCC cycle with `/epcc-explore` (brownfield) or `/epcc-plan` (greenfield)\n\nQuestions or changes to the TRD?\n```\n\n## Technical Feature Enrichment (Long-Running Project Support)\n\nAfter generating TECH_REQ.md, enrich the feature list with technical subtasks if `epcc-features.json` exists.\n\n### Step 1: Check for Existing Feature List\n\n```bash\nif [ -f \"epcc-features.json\" ]; then\n    # Feature list exists from PRD - enrich with technical subtasks\n    echo \"Found epcc-features.json - enriching features with technical details...\"\nelse\n    # No feature list - will be created during /epcc-plan\n    echo \"No epcc-features.json found - technical decisions will inform /epcc-plan\"\nfi\n```\n\n### Step 2: Add Technical Subtasks to Existing Features\n\nFor each feature in `epcc-features.json`, add technical subtasks based on TRD decisions:\n\n```json\n{\n  \"features\": [\n    {\n      \"id\": \"F001\",\n      \"name\": \"User Authentication\",\n      \"subtasks\": [\n        {\"name\": \"Set up [Auth provider] integration\", \"status\": \"pending\", \"source\": \"TECH_REQ.md#authentication\"},\n        {\"name\": \"Implement [JWT/Session] token handling\", \"status\": \"pending\", \"source\": \"TECH_REQ.md#authentication\"},\n        {\"name\": \"Create [Database] user schema\", \"status\": \"pending\", \"source\": \"TECH_REQ.md#data-model\"},\n        {\"name\": \"Configure [bcrypt/argon2] password hashing\", \"status\": \"pending\", \"source\": \"TECH_REQ.md#security\"},\n        {\"name\": \"Add rate limiting middleware\", \"status\": \"pending\", \"source\": \"TECH_REQ.md#security\"}\n      ]\n    }\n  ]\n}\n```\n\n**Subtask generation rules:**\n- Map each TRD technology decision to relevant features\n- Add infrastructure subtasks for features requiring new components\n- Include security subtasks based on compliance requirements\n- Add integration subtasks for third-party services\n- Include testing subtasks for critical paths\n\n### Step 3: Add Infrastructure Features\n\nAdd new features for infrastructure tasks not covered by product features:\n\n```json\n{\n  \"features\": [\n    // ... existing features from PRD ...\n\n    // NEW: Infrastructure features from TRD\n    {\n      \"id\": \"INFRA-001\",\n      \"name\": \"Database Setup\",\n      \"description\": \"Set up [PostgreSQL] database with schemas and migrations\",\n      \"priority\": \"P0\",\n      \"status\": \"pending\",\n      \"passes\": false,\n      \"acceptanceCriteria\": [\n        \"Database provisioned and accessible\",\n        \"All migrations run successfully\",\n        \"Connection pooling configured\",\n        \"Backup strategy in place\"\n      ],\n      \"subtasks\": [],\n      \"source\": \"TECH_REQ.md#data-model\"\n    },\n    {\n      \"id\": \"INFRA-002\",\n      \"name\": \"CI/CD Pipeline\",\n      \"description\": \"Set up continuous integration and deployment\",\n      \"priority\": \"P1\",\n      \"status\": \"pending\",\n      \"passes\": false,\n      \"acceptanceCriteria\": [\n        \"Tests run on every commit\",\n        \"Automated deployment to staging\",\n        \"Production deployment with approval gate\"\n      ],\n      \"subtasks\": [],\n      \"source\": \"TECH_REQ.md#deployment\"\n    },\n    {\n      \"id\": \"INFRA-003\",\n      \"name\": \"Monitoring & Logging\",\n      \"description\": \"Set up application monitoring and centralized logging\",\n      \"priority\": \"P1\",\n      \"status\": \"pending\",\n      \"passes\": false,\n      \"acceptanceCriteria\": [\n        \"Error tracking configured\",\n        \"Performance monitoring in place\",\n        \"Logs aggregated and searchable\"\n      ],\n      \"subtasks\": [],\n      \"source\": \"TECH_REQ.md#monitoring\"\n    }\n  ]\n}\n```\n\n**Infrastructure feature rules:**\n- Add database setup if database selected in TRD\n- Add CI/CD if deployment strategy defined\n- Add monitoring if observability discussed\n- Add security setup if compliance requirements exist\n- Add caching setup if caching strategy defined\n\n### Step 4: Update Progress Log\n\nAppend TRD session to `epcc-progress.md`:\n\n```markdown\n---\n\n## Session [N]: TRD Created - [Date]\n\n### Summary\nTechnical Requirements Document created with architecture and technology decisions.\n\n### Technical Decisions\n- **Architecture**: [Pattern chosen]\n- **Backend**: [Technology + rationale]\n- **Frontend**: [Technology + rationale]\n- **Database**: [Technology + rationale]\n- **Hosting**: [Platform chosen]\n- **Authentication**: [Method chosen]\n\n### Feature Enrichment\n- Updated [X] features with technical subtasks\n- Added [Y] infrastructure features:\n  - INFRA-001: Database Setup\n  - INFRA-002: CI/CD Pipeline\n  [...]\n\n### Feature Summary (Updated)\n- **Total Features**: [N] (was [M] from PRD)\n- **Product Features**: [X] (with technical subtasks)\n- **Infrastructure Features**: [Y] (new from TRD)\n\n### Next Session\nRun `/epcc-plan` to finalize implementation order and create detailed task breakdown.\n\n---\n```\n\n### Step 5: Report Enrichment Results\n\n```markdown\n## Technical Requirements Complete\n\n **TECH_REQ.md** - Technical decisions documented\n **epcc-features.json** - Features enriched with technical details:\n   - [X] existing features updated with subtasks\n   - [Y] infrastructure features added\n   - Total features: [N]\n **epcc-progress.md** - TRD session logged\n\n### Technical Subtasks Added\n\n| Feature | Subtasks Added | Source |\n|---------|----------------|--------|\n| F001: User Auth | 5 subtasks | TECH_REQ.md#authentication |\n| F002: Task CRUD | 3 subtasks | TECH_REQ.md#data-model |\n| ... | ... | ... |\n\n### Infrastructure Features Added\n\n| Feature | Priority | Source |\n|---------|----------|--------|\n| INFRA-001: Database Setup | P0 | TECH_REQ.md#data-model |\n| INFRA-002: CI/CD Pipeline | P1 | TECH_REQ.md#deployment |\n| ... | ... | ... |\n\n### Next Steps\n\n**For Implementation Planning**: `/epcc-plan` - Finalize task order and create detailed breakdown\n**For Brownfield Projects**: `/epcc-explore` - Understand existing codebase first\n**To check progress**: `/epcc-resume` - Quick orientation and status\n```\n\n### Subtask Generation Heuristics\n\nMap TRD decisions to subtasks based on technology choices:\n\n| TRD Section | Generated Subtasks |\n|-------------|-------------------|\n| **Authentication: JWT** | Token generation, validation middleware, refresh token handling |\n| **Authentication: OAuth2** | Provider integration, callback handling, token storage |\n| **Database: PostgreSQL** | Schema creation, migrations, connection pooling, indexes |\n| **Database: MongoDB** | Schema design, indexes, aggregation pipelines |\n| **API: REST** | Route structure, validation, error handling, documentation |\n| **API: GraphQL** | Schema definition, resolvers, subscriptions setup |\n| **Hosting: AWS** | IAM setup, VPC config, deployment scripts |\n| **Hosting: Vercel** | Environment variables, build config, domain setup |\n| **Caching: Redis** | Connection setup, cache invalidation, session storage |\n| **Security: GDPR** | Audit logging, data export, deletion handlers |\n\n## Conversation Principles\n\n### Be Technical, But Accessible\n\n **Don't dictate**: \"You should use microservices for this\"\n **Do guide**: \"For your scale, we could use a monolith (simpler, faster to ship) or microservices (independent scaling, team autonomy). Given your timeline and team size, which sounds better?\"\n\n### Present Technology Tradeoffs\n\n **Don't guarantee**: \"PostgreSQL will handle your scale perfectly\"\n **Do qualify**: \"PostgreSQL would handle your expected 10K users well, though we'd want monitoring to validate query performance as you grow\"\n\n### Use AskUserQuestion Proactively\n\n**Pattern**:\n```typescript\n// Don't wait for user to ask \"help me decide\"\n// Present structured questions for ALL technical decisions\n\nAskUserQuestion({\n  questions: [{\n    question: \"What hosting platform fits your needs?\",\n    header: \"Hosting\",\n    options: [\n      {label: \"AWS\", description: \"Full suite, complex, powerful, higher cost\"},\n      {label: \"Vercel\", description: \"Simple, great DX, limited backend, good for Next.js\"},\n      {label: \"Railway\", description: \"Simple, good for full-stack, auto-deploy, newer platform\"},\n      {label: \"Self-hosted\", description: \"Full control, more setup, lower ongoing cost\"}\n    ]\n  }]\n})\n```\n\n### Reference PRD Context When Available\n\nIf PRD.md exists:\n- \"Based on the real-time chat feature in PRD.md, we should consider WebSocket support...\"\n- \"Given the 100K user target in PRD.md, let's discuss caching strategy...\"\n- \"The GDPR requirement mentioned in PRD.md means we need audit logging for data access...\"\n\n### Ask Follow-ups When Vague\n\n- \"You mentioned high scale - can you quantify that? 10K users? 1M users?\"\n- \"For the API, would your mobile app be the only consumer, or will third parties integrate?\"\n- \"When you say 'real-time,' do you mean sub-second updates, or is 5-second polling acceptable?\"\n\n### Reflect Back Periodically\n\n\"So if I understand correctly, we're building a [architecture] with [stack] that [key technical capability]. The main technical challenges are [X] and [Y]. Does that sound right?\"\n\n## Usage Examples\n\n### Basic Invocation\n\n```bash\n# With project context\n/trd \"Real-time collaboration platform\"\n\n# After creating PRD\n/trd  # Will find and read PRD.md automatically\n\n# Without context\n/trd\n# Will ask: \"What technical project would you like to define requirements for?\"\n```\n\n### Example Flow: Quick TRD (Greenfield)\n\n**User**: `/trd \"Simple blog platform\"`\n\n**Claude**: *Checks for PRD.md (not found)*\n```\nI can help create your Technical Requirements Document for the blog platform.\n\nThis appears to be a straightforward project. I can create:\n1. **Quick TRD** (20-30 min) - Core stack and architecture\n2. **Comprehensive TRD** (60-90 min) - Deep technical exploration\n\nWhich approach works better?\n```\n\n**User**: \"Quick TRD\"\n\n**Claude**: *Uses AskUserQuestion for all key decisions*\n- Architecture pattern (monolith selected)\n- Backend stack (Node.js + Express selected)\n- Frontend (React selected)\n- Database (PostgreSQL selected)\n- Hosting (Vercel selected)\n- Auth (JWT selected)\n- Conversational follow-ups about data model\n\n**Claude**: *Generates Simple TRD (~500 tokens) matching complexity*\n\n**Total time**: ~20 minutes\n\n### Example Flow: Comprehensive TRD (With PRD)\n\n**User**: `/trd` *[PRD.md exists in directory]*\n\n**Claude**: *Reads PRD.md first*\n```\n Found PRD.md - I'll use the product requirements to inform technical decisions.\n\nFrom PRD.md I can see:\n- Real-time collaboration features (needs WebSocket support)\n- 100K user target (needs caching and scaling strategy)\n- GDPR compliance (needs audit logging and data protection)\n\nThis appears to be a complex technical scope. I recommend:\n**Comprehensive TRD** (60-90 min) - Deep technical exploration\n\nShall we proceed with comprehensive mode?\n```\n\n**User**: \"Yes\"\n\n**Claude**: *Comprehensive exploration across all 6 phases*\n- Architecture (microservices chosen for independent scaling)\n- Tech stack (Node.js backend, React frontend, PostgreSQL + Redis)\n- Data models (detailed entity design)\n- Integrations (WebSocket, email, analytics)\n- Security (OAuth2, RBAC, GDPR compliance)\n- Performance (CDN, multi-layer caching, auto-scaling)\n\n**Claude**: *Generates Complex TRD (~2,000 tokens) with PRD alignment section*\n\n**Total time**: ~75 minutes\n\n### Example Flow: Brownfield (Existing Codebase)\n\n**User**: `/trd \"Add payment processing to existing e-commerce platform\"`\n\n**Claude**: *Checks for PRD.md (found)*\n```\n Found PRD.md - using product context for payment requirements.\n\nSince you're adding to an existing codebase, I'll focus technical requirements on:\n- Payment integration architecture\n- Technology choices (payment processor, security)\n- Data model changes\n- Integration with existing stack\n\nI recommend **Medium TRD** (30-45 min) for this integration scope.\n\nShall we proceed?\n```\n\n**User**: \"Yes\"\n\n**Claude**: *Focused technical interview*\n- Payment processor choice (Stripe selected)\n- Integration architecture (webhook handling, idempotency)\n- Data model (payment records, audit trail)\n- Security (PCI DSS considerations, secrets management)\n- Testing strategy (mock payments, sandbox)\n\n**Claude**: *Generates Medium TRD (~900 tokens) focused on integration*\n\n```\n TECH_REQ.md generated\n\nNext steps:\n1. Review this TRD\n2. Run `/epcc-explore` to understand existing codebase patterns\n3. Run `/epcc-plan` to create implementation plan that integrates with existing code\n\nReady to explore the existing codebase?\n```\n\n## Common Pitfalls (Anti-Patterns)\n\n###  Assuming Tech Stack Without Asking\n**Don't**: \"I'll use React and PostgreSQL for this\"  **Do**: Ask using AskUserQuestion for all stack choices\n\n###  Making Technology Recommendations as Facts\n**Don't**: \"PostgreSQL is the best choice\"  **Do**: Present options with tradeoffs, let user decide\n\n###  Following Template Rigidly\n**Don't**: Generate comprehensive TRD for \"add button\" task  **Do**: Match depth to technical complexity\n\n###  Including Implementation Details\n**Don't**: \"Create UserService class with methods...\"  **Do**: Focus on technology choices and architecture patterns\n\n###  Ignoring PRD.md When Present\n**Don't**: Ask about scale/features already in PRD.md  **Do**: Read PRD.md first, reference context\n\n###  Using Conversation When AskUserQuestion Fits\n**Don't**: \"What database do you want?\" (open-ended)  **Do**: AskUserQuestion with 4 database options + tradeoffs\n\n## Second-Order Convergence Warnings\n\nEven with this guidance, you may default to:\n\n-  **Assuming standard tech stack** (ask about stack choices, don't assume MERN/MEAN/etc.)\n-  **Following template rigidly** (simple project  comprehensive TRD with all sections)\n-  **Making technology recommendations** (present options with tradeoffs, don't prescribe)\n-  **Skipping PRD.md** (always check and read PRD.md if exists)\n-  **Using conversation instead of AskUserQuestion** (structured questions for all technical decisions)\n-  **Including implementation details** (architecture and stack, not classes and functions)\n-  **Not justifying technology choices** (every choice needs rationale vs alternatives)\n-  **Forgetting to explore brownfield codebases** (use /epcc-explore to discover existing patterns)\n-  **Not researching unfamiliar technologies** (use WebSearch for benchmarks and best practices)\n-  **Creating excessive documentation plan** (match docs to project complexity)\n-  **Not capturing research insights** (document WebSearch findings in TECH_REQ.md)\n\n## Remember\n\n**Your role**: Technical discovery partner who autonomously gathers context and interviews collaboratively using structured questions.\n\n**Work pattern**: Read PRD.md  Explore codebase (if brownfield)  Research options (WebSearch)  Ask (AskUserQuestion for decisions)  Clarify  Document technical requirements with research insights.\n\n**Context gathering**: Proactively use /epcc-explore (brownfield) and WebSearch (unfamiliar tech) to inform better decisions.\n\n**AskUserQuestion usage**: PRIMARY method for all technical decisions with 2-4 options. Conversation for follow-ups.\n\n**TRD depth**: Simple project = simple TRD. Complex project = comprehensive TRD. Always adapt to technical complexity.\n\n**Technology choices**: Research with WebSearch  Present options with tradeoffs  Let user decide  Document rationale and research findings.\n\n**Documentation planning**: Identify what docs would help CODE phase  Include in TECH_REQ.md with priorities.\n\n **TECH_REQ.md complete - ready to feed into `/epcc-plan` for implementation planning!**"
              }
            ],
            "skills": []
          },
          {
            "name": "frontend-design",
            "description": "Frontend design skill for UI/UX implementation",
            "source": "./assets/claude-code-plugins/plugins/frontend-design",
            "category": "skill",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install frontend-design@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [],
            "skills": [
              {
                "name": "frontend-design",
                "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, blogs, pages, or applications. Generates creative, polished code that avoids generic AI aesthetics.",
                "path": "assets/claude-code-plugins/plugins/frontend-design/skills/frontend-design/SKILL.md",
                "frontmatter": {
                  "name": "frontend-design",
                  "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, blogs, pages, or applications. Generates creative, polished code that avoids generic AI aesthetics."
                },
                "content": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision."
              }
            ]
          },
          {
            "name": "requirements",
            "description": "PRD and TECH_REQ generating commands that can be used pre-EPCC workflow",
            "source": "./assets/claude-code-plugins/plugins/requirements",
            "category": "workflow",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install requirements@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/prd",
                "description": "Product requirements discovery - Create comprehensive PRD through focused questions and guided questionnaire",
                "path": "assets/claude-code-plugins/plugins/requirements/commands/prd.md",
                "frontmatter": {
                  "name": "prd",
                  "description": "Product requirements discovery - Create comprehensive PRD through focused questions and guided questionnaire",
                  "version": "1.0.0",
                  "argument-hint": "[initial-idea-or-project-name] [--process PRD_QUESTIONS.md]"
                },
                "content": "# PRD Command - Product Requirements Discovery\n\nYou are facilitating **PRODUCT REQUIREMENTS DISCOVERY** using a hybrid approach: **Interactive foundational questions** followed by a **self-paced questionnaire**.\n\n **IMPORTANT WORKFLOW**:\n\n1. **Interactive Phase** (5-10 min): Ask 3-5 foundational questions about vision, problem, and users\n2. **Generate questionnaire file** (`PRD_QUESTIONS.md`) for detailed requirements\n3. **User fills questionnaire** at their own pace (features, constraints, scope, metrics)\n4. **Process questionnaire** (`/prd --process PRD_QUESTIONS.md`) to generate final `PRD.md`\n\n **KEY PRINCIPLES**:\n\n- **Focus on Why First**: Vision and problem before features and constraints\n- **Interactive for Foundation**: Critical understanding happens conversationally\n- **Questionnaire for Details**: Detailed planning happens at user's own pace\n- **No Information Overload**: Never ask 10+ questions at once\n- **Strict Non-Technical**: PRD = what/why/who, NOT how (tech decisions in `/tech-req`)\n\n## Initial Input\n\n$ARGUMENTS\n\n**Check for --process flag**:\nIf `--process PRD_QUESTIONS.md` flag detected:\n\n- Skip to [Questionnaire Processing](#questionnaire-processing) section\n- Read answers from file and generate PRD.md\n\nOtherwise, proceed with interactive discovery.\n\nIf no initial idea was provided, start by asking: \"What idea or project would you like to explore?\"\n\n##  Discovery Objectives\n\nThe goal is to create a comprehensive PRD that answers:\n\n1. **What** are we building?\n2. **Why** does it need to exist?\n3. **Who** is it for?\n4. **What features** does it need (prioritized)?\n5. **What constraints** exist (deployment, scale, timeline)?\n6. **What defines success**?\n\n---\n\n## Phase 1: Interactive Foundation (5-10 min)\n\nAsk **ONE question at a time**, wait for answer, adapt next question based on response.\n\n### Question 1: The Vision (ALWAYS ASK)\n\n\"Tell me about your idea in one sentence - what are you building and why?\"\n\n**Wait for answer.**\n\n**Follow-up based on response**:\n\n- If too vague: \"Can you give me a concrete example of what this would look like?\"\n- If too technical: \"Let's step back - what's the user experience, not the technology?\"\n- If unclear value: \"What problem does this solve that doesn't have a good solution today?\"\n\n**Document**:\n\n```\nVision: [User's one-sentence answer]\n```\n\n---\n\n### Question 2: The Problem (ALWAYS ASK)\n\n\"What specific problem are you trying to solve? What's broken or missing right now?\"\n\n**Wait for answer.**\n\n**Follow-up**:\n\n- \"What would happen if this problem wasn't solved?\"\n- \"How do people currently deal with this problem?\"\n\n**Document**:\n\n```\nProblem Statement: [User's answer about the problem]\nCurrent Workarounds: [How people handle it now, if mentioned]\n```\n\n---\n\n### Question 3: The Users (ALWAYS ASK)\n\n\"Who would use this? Tell me about your target audience.\"\n\n**Wait for answer.**\n\n**Follow-up**:\n\n- \"Are there different types of users with different needs?\"\n- \"What does success look like for these users?\"\n\n**Document**:\n\n```\nTarget Users:\n- Primary: [Main user type and their needs]\n- Secondary: [Other users if mentioned]\n\nUser Success: [What \"winning\" looks like for users]\n```\n\n---\n\n### Question 4: Inspiration & Examples (OPTIONAL)\n\n\"Is there anything similar that exists? What inspired this idea?\"\n\n**Wait for answer.**\n\n**Follow-up if they mention examples**:\n\n- \"What do you like about [example]?\"\n- \"What would you do differently?\"\n\n**Document**:\n\n```\nInspiration: [Examples or inspiration if provided]\nWhat to emulate: [Positive aspects to copy]\nWhat to avoid: [Things to do differently]\n```\n\n---\n\n### Question 5: Success Definition (ALWAYS ASK)\n\n\"If this project is successful in 6 months, what does that look like? How will you know it's working?\"\n\n**Wait for answer.**\n\n**Document**:\n\n```\nSuccess Vision: [User's answer]\n```\n\n## Phase 2: Generate Questionnaire File\n\nAfter completing Phase 1 interactive questions, generate `PRD_QUESTIONS.md` for remaining details.\n\n**Inform User**:\n\"Great! I understand your vision:\n\n- **Vision**: [Summary]\n- **Problem**: [Summary]\n- **Users**: [Summary]\n- **Success**: [Summary]\n\nNow I'll generate a questionnaire for the detailed requirements (features, constraints, scope). You can answer these at your own pace.\n\n**Generating**: `PRD_QUESTIONS.md`...\"\n\n**Generate Questionnaire File**:\n\n```markdown\n# Product Requirements Questionnaire\n\n**Project**: [Project name from user's input]\n**Date**: [Current date]\n\n**Foundation (from interactive session)**:\n\n- **Vision**: [Vision from Question 1]\n- **Problem**: [Problem from Question 2]\n- **Target Users**: [Users from Question 3]\n- **Inspiration**: [Inspiration from Question 4, if provided]\n- **Success Vision**: [Success from Question 5]\n\n---\n\n## Instructions\n\n- Replace `[YOUR ANSWER]` with your response\n- Be as detailed or brief as needed\n- Skip optional sections marked (Optional) if not applicable\n- Feel free to add notes/context anywhere\n- **Save this file and run**: `/prd --process PRD_QUESTIONS.md`\n\n---\n\n## Section 1: Core Features\n\n **STAY NON-TECHNICAL**: Focus on WHAT users need to do, NOT HOW it will be implemented.\n\n### 1.1 The ONE Must-Have Feature\n\n**What's the ONE thing users absolutely must be able to do?**\n\n[YOUR ANSWER]\n\n**Why is this essential?**\n\n[YOUR ANSWER]\n\n---\n\n### 1.2 User Journey\n\n**Walk me through a typical user's journey from start to finish:**\n\nExample format:\n\n1. User arrives at...\n2. User does...\n3. System responds with...\n4. User achieves...\n\n[YOUR ANSWER]\n\n---\n\n### 1.3 All Features List\n\n**List all features/capabilities you envision (we'll prioritize in next questions):**\n\n1. [YOUR ANSWER]\n2. [YOUR ANSWER]\n3. [YOUR ANSWER]\n   ... (add as many as needed)\n\n---\n\n### 1.4 Feature Prioritization\n\n**From your list above, which are MUST HAVE (P0) - can't launch without these:**\n\n[YOUR ANSWER - List feature numbers or names]\n\n**Which are SHOULD HAVE (P1) - important but can wait:**\n\n[YOUR ANSWER]\n\n**Which are NICE TO HAVE (P2) - future enhancements:**\n\n[YOUR ANSWER]\n\n---\n\n### 1.5 Content & Navigation (if applicable)\n\n**What types of content will users see?** (e.g., blog posts, pages, images, videos)\n\n[YOUR ANSWER or \"N/A\"]\n\n**How should users navigate through the content?** (e.g., categories, search, chronological, filters)\n\n[YOUR ANSWER or \"N/A\"]\n\n**What actions can users take?** (e.g., read, create, comment, share, subscribe, purchase)\n\n[YOUR ANSWER or \"N/A\"]\n\n---\n\n## Section 2: Technical Constraints\n\n **NOTE**: This captures constraints, NOT specific technology choices. Technology decisions happen in `/tech-req` command.\n\n### 2.1 Deployment\n\n**Where should this run?**\n\n- [ ] Cloud (AWS/Azure/GCP)\n- [ ] Local/On-premises\n- [ ] Hybrid\n- [ ] Other: [Specify]\n\n**Your Choice**: [YOUR ANSWER]\n\n**If Cloud, any provider preference?**\n\n- [ ] AWS\n- [ ] Azure\n- [ ] GCP\n- [ ] No preference\n\n**Your Choice**: [YOUR ANSWER or \"N/A\"]\n\n**Why this deployment approach?**\n\n[YOUR ANSWER]\n\n---\n\n### 2.2 Scale & Performance\n\n**How many people would use this at once?**\n\n- [ ] Just me\n- [ ] Small team (<10)\n- [ ] Department (10-100)\n- [ ] Organization (100-1000)\n- [ ] Public internet (1000+)\n\n**Your Choice**: [YOUR ANSWER]\n\n**Any performance requirements?** (e.g., page load time < 2s, response time < 500ms)\n\n[YOUR ANSWER or \"No specific requirements\"]\n\n---\n\n### 2.3 Data & Integration\n\n**Does this need to connect to any existing systems?** (APIs, databases, third-party services)\n\n[YOUR ANSWER or \"No\"]\n\n**If yes, what systems and why?**\n\n[YOUR ANSWER]\n\n**Do you need to store data?** (beyond simple static content)\n\n[YOUR ANSWER - Yes/No]\n\n**If yes, what kind and how much?** (e.g., user profiles - 100 users, transaction logs - 10K/month)\n\n[YOUR ANSWER]\n\n**Do you need user authentication?**\n\n- [ ] No authentication needed\n- [ ] Single user only (just me)\n- [ ] Multiple users (team/organization)\n- [ ] Public users (anyone can sign up)\n- [ ] Third-party login needed (Google, GitHub, etc.)\n\n**Your Choice**: [YOUR ANSWER]\n\n---\n\n### 2.4 Team & Technology\n\n**What's your team's technical comfort level?**\n\n- [ ] Beginner - Prefer simple, managed solutions\n- [ ] Intermediate - Comfortable with most tools\n- [ ] Advanced - Can handle complex setups\n\n**Your Choice**: [YOUR ANSWER]\n\n**Any existing technologies you MUST use?** (company standards, existing stack, licensing)\n\n[YOUR ANSWER or \"No requirements\"]\n\n**Any technologies you MUST avoid?** (licensing issues, past problems, company policy)\n\n[YOUR ANSWER or \"No constraints\"]\n\n---\n\n## Section 3: Constraints & Scope\n\n### 3.1 Timeline\n\n**When would you like this working?**\n\n[YOUR ANSWER - Target date or timeframe]\n\n**Any key milestones or deadlines?**\n\n[YOUR ANSWER or \"No specific milestones\"]\n\n---\n\n### 3.2 Budget\n\n**Any budget constraints for infrastructure/hosting costs?**\n\n[YOUR ANSWER - e.g., \"Under $10/month\", \"No specific budget\", \"$100-500/month\"]\n\n**How much time can you invest in development?**\n\n[YOUR ANSWER - e.g., \"10 hours/week\", \"Full-time for 2 weeks\", \"As needed\"]\n\n---\n\n### 3.3 Security & Compliance\n\n**Any security or compliance requirements?** (HIPAA, SOC2, GDPR, data residency, etc.)\n\n[YOUR ANSWER or \"No specific requirements\"]\n\n**If yes, explain:**\n\n[YOUR ANSWER]\n\n---\n\n### 3.4 Maintenance\n\n**What are you comfortable maintaining long-term?**\n\n[YOUR ANSWER - e.g., \"Simple setup I can manage myself\", \"Don't mind complexity if it's documented\", \"Prefer managed services\"]\n\n---\n\n### 3.5 Out of Scope\n\n**What is explicitly OUT of scope for the first version?**\n\n1. [YOUR ANSWER]\n2. [YOUR ANSWER]\n   ... (add as many as needed)\n\n**If you had to cut features, what's the absolute minimum viable version?**\n\n[YOUR ANSWER]\n\n---\n\n## Section 4: Success Metrics\n\n### 4.1 User Success Metrics\n\n**How will you know this is working well for users?**\n\n[YOUR ANSWER]\n\n**What metrics would you track?** (e.g., daily active users, time on site, task completion rate)\n\n1. [YOUR ANSWER]\n2. [YOUR ANSWER]\n   ... (add as many as needed)\n\n---\n\n### 4.2 Technical Success Metrics\n\n**What technical metrics matter?** (e.g., uptime, response time, error rate)\n\n[YOUR ANSWER]\n\n**Any specific targets?** (e.g., 99% uptime, page load < 2s)\n\n[YOUR ANSWER or \"No specific targets\"]\n\n---\n\n### 4.3 Acceptance Criteria\n\n**What specific things must work for you to consider this \"done\"?**\n\n- [ ] [YOUR ANSWER - Specific testable criterion]\n- [ ] [YOUR ANSWER - Specific testable criterion]\n- [ ] [YOUR ANSWER - Specific testable criterion]\n      ... (add as many as needed)\n\n---\n\n## Section 5: User Journeys (Optional but Recommended)\n\n### 5.1 Primary User Journey\n\n**Describe the main user flow in detail:**\n\n**Journey Name**: [e.g., \"First-time visitor discovers and reads content\"]\n\n1. User starts at: [Entry point]\n2. User does: [Action]\n3. System responds with: [Response]\n4. User does next: [Next action]\n5. User achieves: [Outcome/goal]\n\n[YOUR ANSWER]\n\n---\n\n### 5.2 Secondary User Journey (Optional)\n\n**If applicable, describe a secondary important flow:**\n\n**Journey Name**: [e.g., \"Content creator publishes new article\"]\n\n[YOUR ANSWER or \"N/A\"]\n\n---\n\n## Section 6: Open Questions & Risks (Optional)\n\n### 6.1 Open Questions\n\n**Anything you're still unsure about?**\n\n- [ ] [YOUR QUESTION]\n- [ ] [YOUR QUESTION]\n      ... (add as many as needed)\n\n---\n\n### 6.2 Risks & Concerns\n\n**What could go wrong? What are you worried about?**\n\n[YOUR ANSWER or \"No major concerns\"]\n\n---\n\n## Next Steps\n\n**When you're done**:\n\n1. Save this file\n2. Run: `/prd --process PRD_QUESTIONS.md`\n3. I'll generate your comprehensive PRD.md!\n```\n\n**After generating file, tell user**:\n\n\" **Questionnaire Generated!** I've created `PRD_QUESTIONS.md` with all the detailed questions.\n\n**Next Steps**:\n\n1. Open `PRD_QUESTIONS.md` and fill in your answers (replace `[YOUR ANSWER]` placeholders)\n2. Take your time - there's no rush. Think through features, prioritization, and constraints\n3. When done, save the file and run: `/prd --process PRD_QUESTIONS.md`\n4. I'll generate your comprehensive `PRD.md`!\n\nThe questionnaire has 6 sections:\n\n- Section 1: Core Features (what users can do)\n- Section 2: Technical Constraints (deployment, scale, data needs)\n- Section 3: Constraints & Scope (timeline, budget, out-of-scope items)\n- Section 4: Success Metrics (how to measure success)\n- Section 5: User Journeys (optional but helpful)\n- Section 6: Open Questions & Risks (optional)\n\nFeel free to skip optional sections or add notes anywhere!\"\n\n---\n\n## Questionnaire Processing\n\nThis section is used when user runs `/prd --process PRD_QUESTIONS.md` after filling out the questionnaire.\n\n### Step 1: Read and Validate Questionnaire\n\nRead `PRD_QUESTIONS.md` file and extract all answers.\n\n**Validate completeness**:\n\n- Check that required sections have answers (Section 1-4)\n- Note any skipped optional sections\n- Identify incomplete answers marked as `[YOUR ANSWER]`\n\nIf critical sections are incomplete:\n\" I noticed some required sections are incomplete:\n\n- [List incomplete sections]\n\nWould you like to:\n\n1. Fill in these sections now (I'll wait)\n2. Proceed with what you have (I'll note gaps in PRD)\n3. Cancel and complete later\"\n\n**Wait for user response if incomplete.**\n\n---\n\n### Step 2: Generate Comprehensive PRD.md\n\nUsing answers from questionnaire and foundation from Phase 1, generate complete PRD.\n\n**Inform user**:\n\"Processing your questionnaire answers and generating comprehensive PRD.md...\n\n**Creating PRD.md**\"\n\n**Generate PRD.md file**:\n\n```markdown\n# Product Requirement Document: [Project Name]\n\n**Created**: [Date]\n**Version**: 1.0\n**Status**: Ready for Review  Technical Requirements or Implementation\n\n---\n\n## Executive Summary\n\n[2-3 sentence overview synthesized from vision, problem, and key features]\n\nExample: \"[Project name] is a [type of product] that [solves problem] for [target users]. It enables users to [key capability] through [approach]. Success will be measured by [top 2 metrics].\"\n\n---\n\n## Vision Statement\n\n[Vision from Phase 1 Question 1, expanded if needed]\n\n---\n\n## Problem Statement\n\n### The Problem\n\n[Problem from Phase 1 Question 2]\n\n### Current Situation\n\n[Current workarounds from Phase 1, or \"Currently, [describe current state]\"]\n\n### Impact\n\n[Why this problem matters - synthesized from user answers]\n\n---\n\n## Target Users\n\n### Primary Users\n\n- **Who**: [From Phase 1 Question 3]\n- **Needs**: [Synthesized from features and user journey]\n- **Current Pain**: [From problem statement]\n\n### Secondary Users\n\n[From Phase 1 Question 3 if mentioned, otherwise \"None identified\"]\n\n### User Success\n\n[From Phase 1 Question 3 follow-up]\n\n---\n\n## Inspiration & Context\n\n[From Phase 1 Question 4 if provided, otherwise skip this section]\n\n**Examples/Inspiration**: [Examples mentioned]\n\n**What to Emulate**: [Positive aspects to copy]\n\n**What to Avoid**: [Things to do differently]\n\n---\n\n## Goals & Success Criteria\n\n### Product Goals\n\n[Synthesize 2-3 SMART goals from success vision and features]\n\n1. [Goal 1]: [Specific, measurable goal]\n2. [Goal 2]: [Specific, measurable goal]\n3. [Goal 3]: [Specific, measurable goal]\n\n### Success Metrics\n\n**User Metrics**:\n[From Section 4.1 of questionnaire]\n\n**Technical Metrics**:\n[From Section 4.2 of questionnaire]\n\n### Acceptance Criteria\n\n[From Section 4.3 of questionnaire - the specific testable criteria]\n\n---\n\n## Core Features\n\n### Must Have (P0) - Launch Blockers\n\n[From Section 1.1 and 1.4 of questionnaire - the essential features]\n\nFor each P0 feature:\n\n1. **[Feature Name]**\n   - **Description**: [What it does]\n   - **User Value**: [Why users need this]\n   - **Priority**: P0\n   - **Success Criteria**: [How we know it works]\n\n### Should Have (P1) - Important But Can Wait\n\n[From Section 1.4 of questionnaire - P1 features]\n\n### Nice to Have (P2) - Future Enhancements\n\n[From Section 1.4 of questionnaire - P2 features]\n\n---\n\n## User Journeys\n\n### Primary User Journey: [Journey name from Section 5.1]\n\n[User journey from Section 5.1 of questionnaire, formatted as numbered steps]\n\n### Secondary User Journey (if provided)\n\n[From Section 5.2 if answered, otherwise skip]\n\n---\n\n## Technical Constraints\n\n **Note**: These are constraints only. Specific technology choices will be evaluated in Technical Requirements phase using `/tech-req` command.\n\n### Deployment\n\n- **Environment**: [From Section 2.1 - Cloud/Local/Hybrid]\n- **Provider Preference**: [From Section 2.1 - AWS/Azure/GCP if specified]\n- **Rationale**: [Why this deployment approach from Section 2.1]\n\n### Scale & Performance\n\n- **Expected Concurrency**: [From Section 2.2 - user count]\n- **Performance Requirements**: [From Section 2.2 - specific targets if provided]\n\n### Data & Integration\n\n- **External Systems**: [From Section 2.3 - systems to integrate]\n- **Data Storage Needs**: [From Section 2.3 - type and volume]\n- **Authentication Requirements**: [From Section 2.3 - auth needs]\n\n### Team & Technology\n\n- **Technical Comfort Level**: [From Section 2.4]\n- **Must Use**: [From Section 2.4 - required technologies]\n- **Must Avoid**: [From Section 2.4 - technologies to avoid]\n\n---\n\n## Constraints & Assumptions\n\n### Timeline\n\n- **Target Launch**: [From Section 3.1]\n- **Key Milestones**: [From Section 3.1 if provided]\n\n### Budget\n\n- **Infrastructure Budget**: [From Section 3.2 - hosting costs]\n- **Development Time Available**: [From Section 3.2]\n\n### Security & Compliance\n\n[From Section 3.3 - requirements if any, otherwise \"No specific security or compliance requirements identified\"]\n\n### Maintenance Expectations\n\n[From Section 3.4 - what user is comfortable maintaining]\n\n### Assumptions\n\n- [List any assumptions made based on answers]\n- [E.g., \"Assuming single-user initially based on scale requirements\"]\n\n---\n\n## Explicitly Out of Scope\n\nThe following are **NOT** included in the first version:\n\n[From Section 3.5 - list of out-of-scope items]\n\n### Minimum Viable Product (MVP)\n\nIf all features were cut except the absolute essentials:\n\n[From Section 3.5 - minimum viable version]\n\n---\n\n## Open Questions & Risks\n\n### Open Questions\n\n[From Section 6.1 if provided, otherwise \"No open questions identified\"]\n\n### Risks & Concerns\n\n[From Section 6.2 if provided, otherwise \"No major risks identified at this stage\"]\n\n### Mitigation Strategies\n\n[For each risk identified, suggest mitigation approach]\n\n---\n\n## Dependencies\n\n### External Dependencies\n\n[Derived from Section 2.3 - external systems and integrations]\n\n### Internal Dependencies\n\n[Derived from feature dependencies and constraints]\n\n---\n\n## Next Steps\n\n### Immediate Actions\n\n1. **Review & Approve PRD** - Ensure this captures your vision accurately\n2. **Gather Technical Requirements** - Run `/tech-req` to evaluate technology choices and architecture\n3. **Begin Implementation** - Use EPCC workflow (`/epcc-explore`, `/epcc-plan`, `/epcc-code`) or start directly\n\n### Recommended Path\n\n**For well-defined projects**: `/tech-req`  `/epcc-plan`  `/epcc-code`\n**For greenfield exploration**: `/epcc-explore`  `/tech-req`  `/epcc-plan`  `/epcc-code`\n**For simple projects**: Start implementing directly from this PRD\n\n---\n\n## Appendix\n\n### Reference Materials\n\n[List any URLs, documents, or examples mentioned during discovery]\n\n### Version History\n\n- v1.0 ([Date]): Initial PRD generated from discovery questionnaire\n```\n\n**After generating PRD.md, tell user**:\n\n\" **PRD Complete!** I've generated `PRD.md` with your comprehensive product requirements.\n\n**What's in the PRD**:\n\n- Executive summary and vision statement\n- Problem statement and target users\n- Prioritized features (P0/P1/P2)\n- User journeys\n- Technical constraints\n- Timeline and budget constraints\n- Success metrics and acceptance criteria\n- Out-of-scope items and risks\n\n**Next Steps - Choose Your Path**:\n\n1. **Technical Requirements** (Recommended): Run `/tech-req` to evaluate technologies and architecture\n2. **EPCC Workflow**: Run `/epcc-explore` to understand existing patterns, then `/epcc-plan` for implementation strategy\n3. **Direct Implementation**: Start building based on this PRD if requirements are clear\n\n**Review Your PRD**:\n\n- Read through `PRD.md` and verify it captures your vision\n- Add any missing details or clarifications\n- Share with stakeholders for feedback if needed\n\nThe PRD is your north star for all subsequent work. Keep it updated as requirements evolve!\"\n\n---\n\n## Conversation Guidelines for Phase 1\n\n### Stay Product-Focused, Not Technical\n\n **CRITICAL**: PRD focuses on WHAT users need, NOT HOW it will be built.\n\n **DON'T ASK**: \"Should users write posts in Markdown or use a rich text editor?\"\n **DO ASK**: \"Who will be creating the blog posts - you, a team, or end users?\"\n\n **DON'T ASK**: \"Do you want a web-based admin interface or file-based editing?\"\n **DO ASK**: \"How often will content be updated, and by whom?\"\n\n **DON'T ASK**: \"Should we use React or Vue for the frontend?\"\n **DO ASK**: \"What devices will users access this from? (desktop, mobile, tablets)\"\n\n **DON'T ASK**: \"Do you want to use a database or static files?\"\n **DO ASK**: \"How much content do you expect to have? (10 posts, 1000 posts, 10000 posts)\"\n\n### Let Technical Questions Wait for /tech-req\n\nWhen you catch yourself about to ask a technical question:\n **SAY**: \"That's a great technical question - we'll evaluate implementation options in the `/tech-req` command. For now, let's focus on what users need to do.\"\n\n### Be Socratic About Product Requirements\n\n **DON'T SAY**: \"You should add a search feature\"\n **DO SAY**: \"If someone visits your blog looking for a specific topic, how would you want them to find it? Browse categories? Search? Something else?\"\n\n### Acknowledge Uncertainty\n\n **DON'T SAY**: \"This will definitely work\"\n **DO SAY**: \"Based on similar projects, this approach typically works well for [use case]\"\n\n### Ask Follow-ups\n\nWhen user says something vague:\n\n- \"Can you give me an example of what that would look like?\"\n- \"Tell me more about [specific aspect]\"\n- \"How would that work from the user's perspective?\"\n\n### Reflect Back After Phase 1\n\nAfter completing Phase 1 questions, summarize:\n \"So if I understand correctly:\n\n- **Vision**: [Summary]\n- **Problem**: [Summary]\n- **Users**: [Summary]\n- **Success**: [Summary]\n\nDoes this capture your vision? Anything to add or correct?\"\n\n**Wait for confirmation before generating questionnaire.**"
              },
              {
                "name": "/tech-req",
                "description": "Technical requirements gathering - Evaluate technologies and architecture through focused questions and guided questionnaire",
                "path": "assets/claude-code-plugins/plugins/requirements/commands/tech-req.md",
                "frontmatter": {
                  "name": "tech-req",
                  "description": "Technical requirements gathering - Evaluate technologies and architecture through focused questions and guided questionnaire",
                  "version": "1.0.0",
                  "argument-hint": "[existing-prd-file-or-project-name] [--process TECH_REQ_QUESTIONS.md]"
                },
                "content": "# Tech-Req Command - Technical Requirements Discovery\n\nYou are facilitating **TECHNICAL REQUIREMENTS DISCOVERY** using a hybrid approach: **Interactive critical questions** followed by a **self-paced questionnaire**.\n\n **IMPORTANT WORKFLOW**:\n\n1. **Read PRD context** (if exists) to extract constraints\n2. **Ask 2-3 critical questions** interactively (architecture, cloud, framework category)\n3. **Generate questionnaire file** (TECH_REQ_QUESTIONS.md) for remaining decisions\n4. **User fills questionnaire** at their own pace\n5. **Process questionnaire** (`/tech-req --process TECH_REQ_QUESTIONS.md`) to generate TECH_REQ.md\n\n **KEY PRINCIPLES**:\n\n- **Smart Filtering**: Show only 2-3 most relevant options per decision (filtered by PRD constraints)\n- **Sequential Decisions**: Later questions depend on earlier answers\n- **No Information Overload**: Never present 4+ options simultaneously\n- **Strict Separation**: PRD = what/why/who, Tech-Req = how/with what\n\n## Initial Input\n\n$ARGUMENTS\n\nIf `--process TECH_REQ_QUESTIONS.md` flag detected:\n\n- Skip to [Questionnaire Processing](#questionnaire-processing) section\n- Read answers from file and generate TECH_REQ.md\n\nOtherwise, proceed with interactive discovery.\n\n---\n\n## Step 1: Extract PRD Context\n\nIf PRD.md exists, read it and extract:\n\n- **Deployment Preference**: Cloud (AWS/Azure/GCP) / Local / Hybrid\n- **Scale**: Expected users/traffic\n- **Budget**: Infrastructure cost constraints\n- **Team Technical Comfort**: Beginner / Intermediate / Advanced\n- **Must Use/Avoid**: Required or forbidden technologies\n- **Performance Requirements**: Response time targets\n- **Data Needs**: Storage type and volume\n\n**Document Extracted Constraints**:\n\n```markdown\n## PRD Constraints Extracted\n\n- **Deployment**: [Cloud provider or preference]\n- **Scale**: [User count, traffic estimates]\n- **Budget**: [Monthly infrastructure budget]\n- **Team Comfort**: [Technical skill level]\n- **Must Use**: [Required technologies]\n- **Must Avoid**: [Technologies to avoid]\n- **Performance**: [Targets if specified]\n- **Data**: [Storage needs]\n```\n\nIf no PRD exists, ask user:\n\"I don't see a PRD.md file. Would you like me to:\n\n1. Ask a few constraint questions now\n2. Generate a PRD first using `/prd`\n3. Proceed with general recommendations (no filtering)\"\n\n---\n\n## Step 2: Interactive Critical Questions (2-3 questions only)\n\nAsk **ONE question at a time**, wait for answer, adapt next question.\n\n### Question 1: Architecture Pattern (ALWAYS ASK)\n\n**Apply Smart Filtering** based on PRD constraints:\n\n**Filtering Logic**:\n\n- If \"single author blog\" or \"documentation site\"  Show only SSG + JAMstack (skip SSR, microservices)\n- If \"< 10 users\" or \"internal tool\"  Show only Monolithic + Serverless (skip microservices)\n- If \"need real-time features\"  Show SSR + Serverless (skip pure SSG)\n- If \"> 100 users\" and \"multiple teams\"  Show Microservices + Hybrid\n- **Default** (no constraints): Show Monolithic + Serverless + JAMstack (skip microservices unless scale justifies)\n\n**Present Only 2-3 Filtered Options**:\n\n\"Based on your requirements [cite PRD constraints], here are the most suitable architecture patterns:\n\n---\n\n### Option 1: [Most Suitable Architecture for Constraints]\n\n**What it is**: [One sentence description]\n\n**Pros**:\n\n-  [Key advantage 1]\n-  [Key advantage 2]\n-  [Key advantage 3]\n\n**Cons**:\n\n-  [Key limitation 1]\n-  [Key limitation 2]\n\n**Best for**: [Specific use case]\n**Matches your**: [How it aligns with PRD constraints]\n**Cost**: [Monthly estimate]\n\n---\n\n### Option 2: [Second Most Suitable Architecture]\n\n[Same structure as Option 1...]\n\n---\n\n[Optional Option 3 only if legitimately applicable]\n\n---\n\n**My Recommendation**: [Architecture] because [2-3 specific reasons tied to PRD constraints].\n\n**Question**: Which architecture pattern aligns with your vision?\"\n\n**Wait for user answer before proceeding.**\n\n---\n\n### Question 2: Cloud Provider (CONDITIONAL)\n\n**Only ask if**:\n\n- PRD deployment preference is \"Cloud\"\n- PRD didn't specify cloud provider preference\n\n**Skip if**:\n\n- PRD says \"AWS only\"  Auto-select AWS, document decision\n- Deployment is Local/Hybrid  Skip to framework question\n\n**Apply Smart Filtering**:\n\n- If Budget < $10/month  Skip Azure/GCP, show AWS (best free tier)\n- If \"Must Use: Microsoft stack\"  Show only Azure\n- If no constraints  Show AWS + 1 alternative (GCP if focus is data/ML, Vercel if SSG architecture chosen)\n\n**Present Only 2 Filtered Options**:\n\n\"For cloud hosting, here are your best options based on [architecture choice] and [budget/constraints]:\n\n---\n\n### Option 1: AWS\n\n**Why for you**: [Specific reason based on architecture + constraints]\n**Monthly Cost**: ~$[X] (for your scale)\n**Key Services**: [3-4 services you'd use]\n\n---\n\n### Option 2: [GCP / Azure / PaaS]\n\n**Why for you**: [Specific reason]\n**Monthly Cost**: ~$[X]\n**Key Services**: [3-4 services you'd use]\n\n---\n\n**My Recommendation**: [Provider] because [reason tied to your constraints].\n\n**Question**: Which cloud provider do you prefer?\"\n\n**Wait for user answer before proceeding.**\n\n---\n\n### Question 3: Framework Category (CONDITIONAL)\n\n**Question depends on architecture answer**:\n\n**If SSG architecture chosen**  Ask about static site generators\n**If SSR/Monolithic chosen**  Ask about full-stack frameworks\n**If Serverless chosen**  Ask about serverless framework preferences\n\n**Apply Smart Filtering** (example for SSG):\n\n- If \"performance critical\"  Show Astro + Hugo (skip heavier options)\n- If \"familiar with React\"  Show Next.js + Astro\n- If \"beginner\"  Show Hugo + 11ty (skip React-based)\n- **Always limit to 2-3 options**\n\n**Example for SSG Architecture**:\n\n\"For static site generation with [your requirements], here are the best frameworks:\n\n---\n\n### Option 1: Astro\n\n**Pros**:\n\n-  Excellent performance (zero JS by default)\n-  Component flexibility (can use React/Vue/Svelte)\n-  Perfect for blogs and content sites\n\n**Cons**:\n\n-  Newer ecosystem (fewer themes than Hugo)\n\n**Best for**: Modern blogs, performance-first\n**Learning curve**: Medium\n**Matches your**: [Performance requirements, modern tooling preference]\n\n---\n\n### Option 2: Hugo\n\n**Pros**:\n\n-  Extremely fast builds (fastest static generator)\n-  Simple setup (single binary, no dependencies)\n-  Great for blogs (built-in features)\n\n**Cons**:\n\n-  Go templating (less familiar than JavaScript)\n\n**Best for**: Simple, fast blogs with minimal maintenance\n**Learning curve**: Easy-Medium\n**Matches your**: [Simplicity preference, performance needs]\n\n---\n\n**My Recommendation**: [Framework] because [specific reason].\n\n**Question**: Which framework appeals to you?\"\n\n**Wait for user answer.**\n\n---\n\n## Step 3: Generate Questionnaire File\n\nAfter 2-3 critical questions answered, generate `TECH_REQ_QUESTIONS.md` for remaining decisions.\n\n**Inform User**:\n\"Great! Based on your choices:\n\n- Architecture: [Choice]\n- Cloud: [Choice]\n- Framework: [Choice]\n\nI'll now generate a questionnaire for the remaining technical decisions. You can answer these at your own pace.\n\n**Generating**: `TECH_REQ_QUESTIONS.md`...\"\n\n**Generate Questionnaire**:\n\n````markdown\n# Technical Requirements Questionnaire\n\n**Project**: [Project name from PRD]\n**Date**: [Current date]\n**Your Decisions So Far**:\n\n- Architecture: [Architecture choice]\n- Cloud Provider: [Cloud choice]\n- Framework: [Framework choice]\n\n---\n\n## Instructions\n\n- Replace `[YOUR ANSWER]` with your response\n- For multiple choice, select one option or write your own\n- Feel free to add notes/context\n- **Save this file and run**: `/tech-req --process TECH_REQ_QUESTIONS.md`\n\n---\n\n## Section 1: Styling Approach\n\nBased on your [framework choice], here's what works well:\n\n**Q1.1: CSS Framework**\n\n- [ ] Tailwind CSS - Utility-first, rapid development, great for clean designs\n- [ ] Custom CSS - Full control, more time-consuming, learning opportunity\n- [ ] [Other]: [Specify if you have a preference]\n\n**Your Choice**: [YOUR ANSWER]\n\n**Q1.2: Why this choice?**\n[YOUR ANSWER - Optional]\n\n---\n\n## Section 2: Content Management\n\n**Q2.1: How will you manage content?**\n\nBased on [single author/team size]:\n\n- [ ] Git-based (Markdown files) - Version controlled, developer-friendly\n- [ ] Headless CMS (Contentful, Strapi) - Web interface, $20-50/month\n- [ ] [Other]: [Specify]\n\n**Your Choice**: [YOUR ANSWER]\n\n**Q2.2: Content workflow preference**\nIf Git-based: Will you write locally and push, or prefer a web editor?\n[YOUR ANSWER]\n\n---\n\n## Section 3: Infrastructure Details\n\n**Q3.1: Specific [Cloud] Services**\n\nFor [architecture] on [cloud provider], recommend:\n\n- [ ] [Recommended service stack A] - Simple, managed, ~$[X]/month\n- [ ] [Recommended service stack B] - More control, ~$[Y]/month\n- [ ] [Other]: [Specify if you have preferences]\n\n**Your Choice**: [YOUR ANSWER]\n\n**Q3.2: Domain Setup**\n\n- [ ] I have a domain: [YOUR DOMAIN NAME]\n- [ ] Need to register a domain\n- [ ] Will decide later\n\n**Your Choice**: [YOUR ANSWER]\n\n---\n\n## Section 4: Database (if data storage needed)\n\n[Only include if PRD indicated data storage needs]\n\nBased on your data needs ([type and volume from PRD]):\n\n- [ ] [Recommended DB option 1] - [Why it fits]\n- [ ] [Recommended DB option 2] - [Alternative if X]\n- [ ] [Other]: [Specify]\n\n**Your Choice**: [YOUR ANSWER]\n\n---\n\n## Section 5: Authentication (if needed)\n\n[Only include if PRD indicated auth needs]\n\nFor [single/multiple users]:\n\n- [ ] [Managed auth provider] - $0-50/month, handles complexity\n- [ ] [Simple auth approach] - Build yourself, more control\n- [ ] [Other]: [Specify]\n\n**Your Choice**: [YOUR ANSWER]\n\n---\n\n## Section 6: CI/CD & Deployment\n\n**Q6.1: Deployment Automation**\n\n- [ ] Automated (GitHub Actions deploys on git push) - Recommended\n- [ ] Manual (run deploy script when ready) - Simple, more control\n- [ ] [Other]: [Specify]\n\n**Your Choice**: [YOUR ANSWER]\n\n**Q6.2: Deployment frequency**\nHow often will you deploy updates?\n\n- [ ] Multiple times per day\n- [ ] Few times per week\n- [ ] Once per week or less\n\n**Your Choice**: [YOUR ANSWER]\n\n---\n\n## Section 7: Monitoring & Analytics (Optional)\n\n**Q7.1: Do you need analytics/monitoring?**\n\n- [ ] Yes - Basic (page views, visitors)\n- [ ] Yes - Advanced (user behavior, funnels, performance)\n- [ ] No - Not needed initially\n- [ ] Undecided\n\n**Your Choice**: [YOUR ANSWER]\n\nIf yes, any preferences?\n[YOUR ANSWER]\n\n---\n\n## Section 8: Additional Requirements\n\n**Q8.1: Any other technical requirements or concerns?**\nExamples: SEO needs, accessibility requirements, integrations, etc.\n\n[YOUR ANSWER]\n\n---\n\n## Ready to Generate Tech-Req!\n\nOnce you've answered these questions, run:\n\n```bash\n/tech-req --process TECH_REQ_QUESTIONS.md\n```\n````\n\nThis will generate your comprehensive `TECH_REQ.md` document with all technology decisions documented and explained.\n\n````\n\n**Save file as**: `TECH_REQ_QUESTIONS.md`\n\n**Tell User**:\n\" Generated `TECH_REQ_QUESTIONS.md` with [N] questions.\n\nTake your time answering these. When ready, run:\n`/tech-req --process TECH_REQ_QUESTIONS.md`\n\nThis will generate your final `TECH_REQ.md` document.\"\n\n---\n\n## Questionnaire Processing\n\nWhen user runs: `/tech-req --process TECH_REQ_QUESTIONS.md`\n\n### Step 1: Read and Parse Answers\n\nRead `TECH_REQ_QUESTIONS.md` and extract all `[YOUR ANSWER]` responses.\n\n**Validation**:\n- Check all required questions are answered\n- If any missing, prompt: \"Please answer Question X.Y before I can proceed.\"\n\n### Step 2: Generate TECH_REQ.md\n\nCreate comprehensive technical requirements document:\n\n```markdown\n# Technical Requirements Document: [Project Name]\n\n**Created**: [Date]\n**Version**: 1.0\n**Status**: Ready for Implementation\n**Related Documents**: PRD.md\n\n---\n\n## Executive Summary\n\n[2-3 sentence overview of technical approach based on architecture, cloud, and framework choices]\n\n**Key Decisions**:\n- Architecture: [Architecture] - [One line rationale]\n- Cloud: [Provider] - [One line rationale]\n- Framework: [Framework] - [One line rationale]\n- Estimated Monthly Cost: ~$[X]\n\n---\n\n## Architecture Decision\n\n### Pattern Chosen: [Architecture]\n\n**Rationale**:\n[2-3 paragraphs explaining why this architecture was chosen based on PRD requirements and user answers]\n\n**Key characteristics**:\n- [Characteristic 1 relevant to their project]\n- [Characteristic 2]\n- [Characteristic 3]\n\n**System Components**:\n````\n\n[Simple ASCII diagram or description of main components]\nExample for SSG:\nUser  CloudFront (CDN)  S3 (Static Files)\nDeveloper  Git Push  GitHub Actions  Build  S3\n\n```\n\n**Trade-offs Accepted**:\n-  Gaining: [What this architecture provides]\n-  Accepting: [What limitations we're accepting and why they're okay]\n\n---\n\n## Technology Stack\n\n### [Framework Category]: [Chosen Framework]\n\n**Rationale**: [Why this framework based on requirements]\n\n**Alternatives Considered**:\n- [Alt 1]: Not chosen because [reason]\n- [Alt 2]: Not chosen because [reason]\n\n**Key Features We'll Use**:\n- [Feature 1]: [How it helps the project]\n- [Feature 2]: [How it helps the project]\n\n### Styling: [Choice]\n\n**Rationale**: [Why this styling approach]\n\n### Content Management: [Choice]\n\n**Workflow**: [Describe the content creation workflow based on answer]\n\n**Tools Needed**:\n- [Tool 1]: [Purpose]\n- [Tool 2]: [Purpose]\n\n---\n\n## Infrastructure\n\n### Cloud Platform: [Provider]\n\n**Services to Use**:\n- **[Service 1]**: [Purpose and configuration]\n- **[Service 2]**: [Purpose and configuration]\n- **[Service 3]**: [Purpose and configuration]\n\n**Architecture Diagram**:\n```\n\n[Service-level architecture showing how cloud services connect]\n\n```\n\n### Domain: [Status from questionnaire]\n\n[If domain exists]: Using [domain name]\n[If needs registration]: Will register through [recommended registrar]\n\n### CI/CD Pipeline\n\n**Approach**: [Automated/Manual from questionnaire]\n\n[If automated]:\n**Pipeline Steps**:\n1. Developer commits code  Git push\n2. GitHub Actions triggered\n3. Build [framework] site\n4. Run tests (if applicable)\n5. Deploy to [cloud service]\n6. Invalidate cache (if CDN)\n7. Verify deployment\n\n**Estimated Deploy Time**: [X] minutes per deployment\n\n[If manual]:\n**Deployment Process**:\n1. Run build locally: `[build command]`\n2. Deploy via CLI: `[deploy command]`\n3. Verify in browser\n\n---\n\n## Data & Authentication\n\n[Only include sections if applicable based on PRD and questionnaire]\n\n### Database: [If applicable]\n**Choice**: [Database]\n**Rationale**: [Why this database for their data needs]\n**Schema Overview**: [Key tables/collections]\n\n### Authentication: [If applicable]\n**Approach**: [Chosen auth method]\n**Provider**: [If using managed service]\n**Rationale**: [Why this approach]\n\n---\n\n## Monitoring & Analytics\n\n[Based on questionnaire answer]\n\n**Approach**: [Choice from questionnaire]\n\n[If selected analytics]:\n**Tools**:\n- [Tool]: [Purpose]\n\n**Key Metrics to Track**:\n- [Metric 1]\n- [Metric 2]\n\n---\n\n## Performance & Scalability\n\n### Performance Targets\n\nBased on PRD requirements:\n- **Page Load Time**: [Target from PRD or < 2s default]\n- **Time to First Byte**: [Target]\n- **API Response Time**: [Target if applicable]\n\n### Scalability Plan\n\n**Phase 1** (Launch - [X] users):\n[Initial setup sufficient for early users]\n\n**Phase 2** ([X-Y] users):\n[What changes when traffic increases]\n\n**Phase 3** ([Y+] users):\n[Scaling approach for higher traffic]\n\n**Cost Projection**:\n- Phase 1: ~$[X]/month\n- Phase 2: ~$[Y]/month\n- Phase 3: ~$[Z]/month\n\n---\n\n## Cost Estimation\n\n### Monthly Infrastructure Costs\n\n**Itemized Breakdown**:\n- [Service/Component 1]: $[X]\n- [Service/Component 2]: $[Y]\n- [Service/Component 3]: $[Z]\n- **Total**: ~$[Sum]/month\n\n**Cost Variables**:\n- Traffic-dependent: [What costs scale with traffic]\n- Fixed: [What costs are constant]\n\n**Optimization Opportunities**:\n- [Way to reduce costs if needed]\n- [Alternative if budget changes]\n\n---\n\n## Technology Decision Summary\n\n| Decision Category | Chosen Technology | Rationale | Alternatives Considered |\n|------------------|-------------------|-----------|------------------------|\n| Architecture | [Choice] | [One sentence] | [List] |\n| Cloud Provider | [Choice] | [One sentence] | [List] |\n| Framework | [Choice] | [One sentence] | [List] |\n| Styling | [Choice] | [One sentence] | [List] |\n| Content Mgmt | [Choice] | [One sentence] | [List] |\n| Database | [Choice/N/A] | [One sentence] | [List] |\n| Authentication | [Choice/N/A] | [One sentence] | [List] |\n| CI/CD | [Choice] | [One sentence] | [List] |\n\n---\n\n## Implementation Roadmap\n\n### Phase 1: Foundation (Week 1-2)\n- [ ] Set up [cloud] account and configure services\n- [ ] Initialize [framework] project\n- [ ] Configure [styling approach]\n- [ ] Set up development environment\n- [ ] Create hello-world deployment\n\n### Phase 2: Core Features (Week 3-4)\n- [ ] Implement [key feature 1 from PRD]\n- [ ] Implement [key feature 2 from PRD]\n- [ ] Set up [content management]\n- [ ] Configure CI/CD pipeline\n\n### Phase 3: Polish & Launch (Week 5-6)\n- [ ] Performance optimization\n- [ ] SEO configuration\n- [ ] Testing and bug fixes\n- [ ] Domain setup and SSL\n- [ ] Launch! \n\n---\n\n## Risks & Mitigation\n\n| Risk | Likelihood | Impact | Mitigation |\n|------|------------|--------|------------|\n| [Tech Risk 1] | [H/M/L] | [H/M/L] | [How to mitigate] |\n| [Cost Risk] | [H/M/L] | [H/M/L] | [How to mitigate] |\n| [Scaling Risk] | [H/M/L] | [H/M/L] | [How to mitigate] |\n\n---\n\n## Open Questions\n\n- [ ] [Any remaining technical questions]\n- [ ] [Decisions that need prototyping]\n\n---\n\n## Next Steps\n\n1. **Review this document** - Does everything make sense? Any concerns?\n2. **Prototype (Optional)** - Try [framework] with a hello-world if unfamiliar\n3. **Begin Implementation**:\n   - Option A: Direct implementation\n   - Option B: Use EPCC workflow - `/epcc-explore` to analyze patterns and start coding\n4. **Set up infrastructure** - Follow Phase 1 of Implementation Roadmap\n\n---\n\n## Appendix: Useful Resources\n\n### Documentation Links\n- [Framework]: [Official docs URL]\n- [Cloud Provider]: [Getting started guide]\n- [Key Tool/Service]: [Tutorial]\n\n### Example Projects\n- [Similar project 1]: [Why it's relevant]\n- [Similar project 2]: [Why it's relevant]\n\n### Community Resources\n- [Forum/Discord]: [Link]\n- [Stack Overflow Tag]: [Link]\n\n---\n\n**Technical Requirements Complete!** Ready to build \n```\n\n**Save as**: `TECH_REQ.md`\n\n---\n\n## After Generation\n\n**Tell User**:\n\" **Tech-Req Complete!** Generated `TECH_REQ.md` with your complete technical specification.\n\n**Key Decisions**:\n\n- Architecture: [Choice]\n- Cloud: [Provider]\n- Framework: [Framework]\n- Estimated Cost: ~$[X]/month\n\n**Next Steps**:\n\n1. **Review TECH_REQ.md** - Make sure everything aligns with your vision\n2. **Start Building**:\n   - Direct implementation using the roadmap in TECH_REQ.md\n   - OR use `/epcc-explore` to analyze existing patterns and start EPCC workflow\n\nThe technical foundation is set - time to build!\"\n\n---\n\n## Smart Filtering Rules Reference\n\n### Budget-Based Filtering\n\n- **< $10/month**: Show managed/PaaS options, skip enterprise services\n- **$10-50/month**: Show PaaS + basic cloud setups\n- **> $50/month**: Show all options including complex architectures\n\n### Scale-Based Filtering\n\n- **< 1k users**: Skip microservices, show monolithic/serverless/SSG\n- **1k-10k users**: Show most architectures except microservices\n- **> 10k users**: Show all including microservices\n\n### Complexity-Based Filtering\n\n- **Beginner**: Show managed services, simple frameworks, PaaS\n- **Intermediate**: Show most options\n- **Advanced**: Show all including custom infrastructure\n\n### Use Case-Based Filtering\n\n- **Blog/Documentation**: Show only SSG + JAMstack\n- **Internal Tool (< 10 users)**: Show monolithic + serverless\n- **SaaS Application**: Show SSR + Microservices + Hybrid\n- **E-commerce**: Show SSR + Hybrid (need dynamic + static)\n\n---\n\n## Example Filtered Question\n\n**Bad** (Information Overload):\n\n```\nHere are 5 architecture options: Monolithic (pros: A, B, C, cons: D, E, F),\nMicroservices (pros: G, H, I, cons: J, K, L), Serverless (pros: M, N, O, cons: P, Q, R),\nJAMstack (pros: S, T, U, cons: V, W, X), Hybrid (pros: Y, Z, AA, cons: BB, CC, DD)...\n```\n\n User has to process 15 pros + 15 cons = 30 points before answering\n\n**Good** (Smart Filtered):\n\n```\nBased on your single-author blog with < 1k users, here are the 2 best options:\n\nOption 1: Static Site Generator\n Maximum performance,  Minimal cost ($2-5/month),  Perfect for blogs\n No dynamic features\n\nOption 2: JAMstack\n Static performance + some dynamic features,  Cost-effective\n More complex than pure SSG\n\nRecommendation: SSG - matches your use case perfectly.\nWhich appeals to you?\n```\n\n User processes 4 pros + 2 cons = 6 points, makes decision quickly"
              }
            ],
            "skills": []
          },
          {
            "name": "troubleshooting",
            "description": "Troubleshooting command to assist with complex problems",
            "source": "./assets/claude-code-plugins/plugins/troubleshooting",
            "category": "troubleshooting",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install troubleshooting@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/troubleshoot",
                "description": "Systematic troubleshooting mode - Debug problems methodically with ask-for-help mechanism to prevent spinning wheels",
                "path": "assets/claude-code-plugins/plugins/troubleshooting/commands/troubleshoot.md",
                "frontmatter": {
                  "name": "troubleshoot",
                  "description": "Systematic troubleshooting mode - Debug problems methodically with ask-for-help mechanism to prevent spinning wheels",
                  "version": "1.0.0",
                  "argument-hint": "[error-description-or-empty-for-interactive]"
                },
                "content": "# Troubleshoot Command - Systematic Debugging Workflow\n\nYou are in **SYSTEMATIC TROUBLESHOOTING MODE** - a methodical 5-stage process designed to diagnose and fix problems efficiently while preventing endless debugging cycles.\n\n **CRITICAL PRINCIPLES**:\n- **ASK FOR HELP** after 3 failed attempts or when encountering complex issues\n- **ONE CHANGE AT A TIME** - never make multiple changes simultaneously\n- **GATHER BEFORE GUESSING** - always collect full context before attempting fixes\n- **DOCUMENT EVERYTHING** - record all attempts in TROUBLESHOOT.md\n- **NO SPINNING WHEELS** - if stuck, stop and ask for user guidance\n\n## Initial Input\n$ARGUMENTS\n\nIf error description provided, use it as starting point. Otherwise, ask: \"What problem are you encountering? Please describe the error or unexpected behavior.\"\n\n##  Troubleshooting Objectives\n\n1. **Understand the Problem** - Gather complete context\n2. **Classify the Issue** - Determine complexity and type\n3. **Form Hypotheses** - Generate specific, testable theories\n4. **Test Methodically** - Validate one hypothesis at a time\n5. **Document Solution** - Record the fix and lessons learned\n\n## Troubleshooting Workflow\n\n### Stage 1: Context Gathering (2-5 min)\n\n**DO NOT SKIP THIS STAGE** - Rushing to fix without context leads to wasted time.\n\n#### Information to Collect\n\n1. **Full Error Message**\n   - Never skim - read the complete error message\n   - Note exact error text, error codes, line numbers\n   - Capture full stack trace if available\n\n2. **When Did This Start?**\n   - What changed recently? (git diff, git log -5)\n   - New code, dependencies, config changes?\n   - Environment changes? (OS update, new package versions)\n\n3. **Consistency Check**\n   - Does it happen every time or intermittently?\n   - Specific conditions that trigger it?\n   - Works in different environment? (local vs production, different machine)\n\n4. **What's Been Tried?**\n   - Ask user: \"What have you already attempted?\"\n   - Avoid repeating failed attempts\n\n5. **System State**\n   - Check configuration files\n   - Verify environment variables\n   - Review recent commits (git log -10 --oneline)\n   - Check dependency versions (package.json, requirements.txt, go.mod)\n   - Review logs for related errors\n\n#### Context Gathering Checklist\n\nBefore moving to Stage 2, confirm:\n\n```markdown\n### Context Gathered\n- [ ] Full error message captured (exact text)\n- [ ] Stack trace analyzed (if available)\n- [ ] Recent changes reviewed (git diff, git log)\n- [ ] Configuration files checked\n- [ ] Dependencies verified (versions, missing packages)\n- [ ] Environment variables validated\n- [ ] Logs reviewed for related errors\n- [ ] Reproduction steps documented\n```\n\n#### Document in TROUBLESHOOT.md\n\n```markdown\n# Troubleshooting Session: [Date/Time]\n\n## Problem Description\n[User's description of the issue]\n\n## Error Message\n```\n[Exact error text with full stack trace]\n```\n\n## Context\n- **When Started**: [Timeline]\n- **Consistency**: [Always/Sometimes - conditions]\n- **Recent Changes**: [List from git log]\n- **Environment**: [OS, versions, etc.]\n- **Previous Attempts**: [What user tried]\n\n## System State\n- **Config Files**: [Status]\n- **Dependencies**: [Versions]\n- **Environment Variables**: [Status]\n```\n\n### Stage 2: Problem Classification (1-2 min)\n\nClassify the issue to determine approach and complexity.\n\n#### Error Categories\n\n#####  Syntax Error\n**Indicators**: Missing punctuation, typo, incorrect syntax\n**Complexity**: Simple\n**Fix Time**: < 5 min\n**Approach**: Quick fix, no ask-for-help needed\n\n**Examples**:\n- Missing semicolon, bracket, parenthesis\n- Typo in variable/function name\n- Incorrect indentation (Python)\n- Missing import statement\n\n#####  Logic Error\n**Indicators**: Code runs but produces wrong results\n**Complexity**: Medium\n**Fix Time**: 15-30 min\n**Approach**: Systematic debugging, ask-for-help if > 3 attempts\n\n**Examples**:\n- Off-by-one errors in loops\n- Wrong comparison operator (< vs <=)\n- Incorrect algorithm implementation\n- Wrong business logic\n\n#####  Runtime Error\n**Indicators**: Code crashes during execution\n**Complexity**: Medium\n**Fix Time**: 10-20 min\n**Approach**: Check inputs, boundaries, async operations\n\n**Examples**:\n- Null/undefined reference\n- Type mismatch (string vs number)\n- Array out of bounds\n- Promise rejection\n- File not found\n\n#####  Performance Issue\n**Indicators**: Slow execution, high resource usage\n**Complexity**: High\n**Fix Time**: 30-60 min\n**Approach**: Profiling required, ask-for-help early\n\n**Examples**:\n- N+1 database queries\n- Memory leak\n- Inefficient algorithm (O(n) instead of O(n))\n- Missing database indexes\n- Unoptimized images/assets\n\n#####  Configuration Issue\n**Indicators**: Missing settings, wrong environment\n**Complexity**: Simple to Medium\n**Fix Time**: 5-15 min\n**Approach**: Check configs, env vars, permissions\n\n**Examples**:\n- Wrong environment variable\n- Missing dependency\n- Incorrect file permissions\n- Port already in use\n- Wrong API endpoint\n\n#####  Security Issue\n**Indicators**: Vulnerable dependencies, exposed secrets\n**Complexity**: High\n**Fix Time**: 30+ min\n**Approach**: Ask-for-help immediately (critical)\n\n**Examples**:\n- Exposed API keys\n- SQL injection vulnerability\n- XSS vulnerability\n- Insecure authentication\n- Outdated vulnerable package\n\n#####  Network/Integration Issue\n**Indicators**: API failures, timeout errors, connectivity\n**Complexity**: Medium to High\n**Fix Time**: 20-40 min\n**Approach**: Check endpoints, auth, network\n\n**Examples**:\n- API endpoint changed\n- Authentication token expired\n- CORS errors\n- Network timeout\n- Rate limiting\n\n#####  Architectural Issue\n**Indicators**: Race conditions, concurrency issues, design flaws\n**Complexity**: Very High\n**Fix Time**: Hours to days\n**Approach**: **ASK-FOR-HELP IMMEDIATELY** - don't attempt aggressive changes\n\n**Examples**:\n- Race condition in concurrent code\n- Circular dependency\n- Improper state management\n- Architectural refactor needed\n- Fundamental design flaw\n\n#### Classification Output\n\n```markdown\n## Problem Classification\n\n**Category**: [Syntax/Logic/Runtime/Performance/Config/Security/Network/Architecture]\n**Complexity**: [Simple/Medium/High/Very High]\n**Estimated Fix Time**: [X min]\n**Approach**: [Quick fix / Systematic debugging / Ask-for-help / Prototype required]\n\n**Reasoning**: [Why classified this way]\n```\n\n### Stage 3: Hypothesis Generation (2-3 min)\n\nForm **specific, testable hypotheses** - not vague guesses.\n\n#### Hypothesis Framework\n\nFor each hypothesis, define:\n1. **What**: Specific theory about root cause\n2. **Why**: Evidence supporting this theory\n3. **How to test**: Exact test to validate/invalidate\n4. **Expected outcome**: What should happen if correct\n\n#### Example: Good vs Bad Hypotheses\n\n **BAD** (Vague):\n- \"Maybe it's a database issue\"\n- \"Could be the API\"\n- \"Something's wrong with the config\"\n\n **GOOD** (Specific):\n- \"The database connection is timing out because the connection pool size (10) is too small for concurrent requests (50)\"\n- \"The API returns 401 because the JWT token expired (issued 2 hours ago, expires in 1 hour)\"\n- \"The config file is using development database URL instead of production URL (DATABASE_URL env var not set)\"\n\n#### Prioritize Hypotheses\n\nOrder by likelihood based on context:\n1. **Most Likely**: Direct evidence from error message/logs\n2. **Alternative**: Indirect evidence or similar past issues\n3. **Less Likely**: Edge cases or rare scenarios\n\n#### Document Hypotheses\n\n```markdown\n## Hypotheses\n\n### Hypothesis 1 (Most Likely): [Specific theory]\n- **Evidence**: [What from context supports this]\n- **Test**: [Exact change or check to validate]\n- **Expected**: [What should happen if correct]\n- **Impact**: [What would this fix]\n\n### Hypothesis 2 (Alternative): [Specific theory]\n- **Evidence**: [What from context supports this]\n- **Test**: [Exact change or check to validate]\n- **Expected**: [What should happen if correct]\n- **Impact**: [What would this fix]\n\n### Hypothesis 3 (Less Likely): [Specific theory]\n- **Evidence**: [What from context supports this]\n- **Test**: [Exact change or check to validate]\n- **Expected**: [What should happen if correct]\n- **Impact**: [What would this fix]\n\n**Testing Order**: 1  2  3 (most to least likely)\n```\n\n### Stage 4: Methodical Testing (Variable time)\n\n**CRITICAL RULE**: Test ONE hypothesis at a time, never multiple simultaneously.\n\n#### Testing Protocol\n\nFor each hypothesis:\n\n1. **Announce** what you're testing\n2. **Make ONE specific change**\n3. **Test the change** (run code, check behavior)\n4. **Record result** (success, failure, unexpected)\n5. **Revert if failed** (don't stack changes)\n\n#### Attempt Tracking\n\n```markdown\n## Testing Results\n\n### Attempt 1: Testing Hypothesis 1\n**Date/Time**: [Timestamp]\n**Hypothesis**: [What we're testing]\n**Change Made**: [Exact modification]\n**Expected Outcome**: [What should happen]\n**Actual Outcome**: [What actually happened]\n**Result**:  Success /  Failed /  Partial\n**Next Action**: [If failed, revert and move to next hypothesis]\n\n---\n\n### Attempt 2: Testing Hypothesis 2\n[Same structure...]\n\n---\n\n### Attempt 3: Testing Hypothesis 3\n[Same structure...]\n```\n\n###  ASK FOR HELP MECHANISM\n\n#### Trigger Conditions\n\n**IMMEDIATELY Ask for Help When**:\n-  **Architectural Issue** detected (race condition, fundamental design flaw)\n-  **Security-Critical Issue** (exposed secrets, vulnerabilities)\n-  **Production System at Risk** (affecting users)\n-  **Unfamiliar Territory** (technology or domain you don't understand)\n-  **No Clear Hypothesis** (after context gathering, still unclear what to test)\n\n**After 3 Failed Attempts**:\n- Tested 3 distinct hypotheses\n- No progress toward solution\n- Error persists or gets worse\n\n**NEVER Ask for Simple Issues**:\n- Syntax errors (typos, missing semicolons)\n- Import errors (missing dependencies)\n- Simple configuration issues (wrong env var value)\n- Obvious logic errors (wrong operator)\n\n#### How to Ask for Help\n\nWhen trigger condition met, **STOP IMMEDIATELY** and present:\n\n```markdown\n---\n\n##  ASKING FOR HELP\n\nI've reached a point where I need your guidance to proceed effectively.\n\n### What I've Tried\n1. **Attempt 1**: [Summary of hypothesis and result]\n2. **Attempt 2**: [Summary of hypothesis and result]\n3. **Attempt 3**: [Summary of hypothesis and result]\n\n### Current Understanding\n[What I know about the problem so far]\n\n### Why I'm Stuck\n[Specific reason: too complex, unfamiliar, architectural, etc.]\n\n### Questions for You\n1. [Specific question about domain knowledge or expected behavior]\n2. [Specific question about system constraints or requirements]\n3. [Specific question about approach or direction]\n\n### Possible Paths Forward\n\n**Option A**: [Approach 1 - explain what it involves]\n- Pros: [What this would achieve]\n- Cons: [Risks or unknowns]\n\n**Option B**: [Approach 2 - explain what it involves]\n- Pros: [What this would achieve]\n- Cons: [Risks or unknowns]\n\n**Option C**: Escalate to [team member/external expert]\n- When: [If domain expertise needed]\n\n### What Would Help Most\n[Be explicit about what information or decision would unblock progress]\n\n**Which path should we take?** Or do you have a different approach in mind?\n\n---\n```\n\n### Stage 5: Solution Documentation (2-3 min)\n\nOnce problem is solved, document thoroughly for future reference.\n\n#### Solution Documentation Template\n\n```markdown\n---\n\n##  SOLUTION FOUND\n\n### Problem Summary\n- **Error**: [Brief description]\n- **Root Cause**: [What actually caused it]\n- **Severity**: [Minor/Moderate/Critical]\n- **Impact**: [What was affected - users, systems, data]\n\n### Solution Applied\n- **Fix**: [What was changed to resolve it]\n- **Files Modified**:\n  - [file1.js:42](file://file1.js#42) - [What changed]\n  - [file2.py:108](file://file2.py#108) - [What changed]\n- **Testing**: [How the fix was verified]\n- **Verification**:\n  - [ ] Error no longer appears\n  - [ ] System behaves as expected\n  - [ ] No new errors introduced\n  - [ ] All tests passing\n\n### Why This Worked\n[Explain the mechanism - why did this fix solve the problem]\n\n### Prevention\n**How to avoid this in the future**:\n- [Prevention measure 1 - e.g., add validation, update documentation]\n- [Prevention measure 2 - e.g., add test coverage, improve error handling]\n- [Prevention measure 3 - e.g., monitoring/alerting]\n\n**Watch Out For**:\n- [Related issue that might occur]\n- [Similar problem in other areas]\n\n### Lessons Learned\n1. [Key insight 1 - e.g., \"Always check environment variables first for config issues\"]\n2. [Key insight 2 - e.g., \"This error message is misleading - real cause was X\"]\n3. [Key insight 3 - e.g., \"Tool Y helped diagnose this faster\"]\n\n### Related Issues\n- [Similar problem that might help debug related issues]\n- [Documentation that would have prevented this]\n\n### Time Spent\n- **Total Time**: [X minutes/hours]\n- **Context Gathering**: [Y min]\n- **Testing**: [Z min]\n- **Attempts**: [N attempts before solution]\n\n---\n\n## Next Steps\n\n1. **Commit the Fix**: Use `/epcc-commit` or regular commit with message:\n   ```\n   Fix: [Brief description of what was fixed]\n\n   [More details about root cause and solution]\n\n   Closes #[issue-number] (if applicable)\n   ```\n\n2. **Update Tests** (if needed):\n   - [ ] Add test case that would have caught this bug\n   - [ ] Update integration tests if behavior changed\n   - [ ] Add regression test to prevent recurrence\n\n3. **Update Documentation** (if needed):\n   - [ ] Update README if setup/config changed\n   - [ ] Add troubleshooting entry to docs\n   - [ ] Document in team knowledge base\n\n4. **Monitor** (for next 24-48 hours):\n   - [ ] Watch for similar errors\n   - [ ] Verify fix in production (if applicable)\n   - [ ] Confirm no side effects\n\n**Problem Resolved! **\n```\n\n## Troubleshooting Best Practices\n\n###  DO:\n\n1. **Gather Complete Context First**\n   - Read full error messages (don't skim)\n   - Check recent changes (git diff, git log)\n   - Review configuration and environment\n   - Check logs for related errors\n\n2. **Form Specific Hypotheses**\n   - \"I think X is causing Y because Z\"\n   - Not vague guesses like \"maybe it's the database\"\n\n3. **Test One Thing at a Time**\n   - Make ONE change\n   - Test immediately\n   - Revert if doesn't work\n   - Never stack multiple changes\n\n4. **Document Everything**\n   - Record all attempts in TROUBLESHOOT.md\n   - Note what worked and what didn't\n   - Explain why solution worked\n\n5. **Ask for Help Early**\n   - After 3 failed attempts\n   - For complex/architectural issues\n   - When unfamiliar with technology\n   - For security-critical problems\n\n###  DON'T:\n\n1. **Don't Skip Context Gathering**\n   - Rushing to fix wastes more time\n\n2. **Don't Make Multiple Changes at Once**\n   - You won't know which change fixed it (or broke it)\n\n3. **Don't Guess Randomly**\n   - Form testable hypotheses based on evidence\n\n4. **Don't Spin Wheels Silently**\n   - If stuck after 3 attempts, ask for help\n   - Don't keep trying random things\n\n5. **Don't Make Aggressive Changes**\n   - For architectural issues, ask first\n   - Don't refactor during debugging\n\n6. **Don't Ignore Simple Checks**\n   - Typos, imports, config - check basics first\n   - \"It worked yesterday\" means something changed\n\n## Common Debugging Patterns\n\n### Pattern 1: \"Works on My Machine\"\n\n**Likely Causes**:\n- Environment variable differences\n- Different dependency versions\n- Different OS/system configuration\n- Cached data or state\n\n**Investigation**:\n1. Compare environment variables\n2. Check dependency lock files (package-lock.json, Pipfile.lock)\n3. Check for hardcoded paths\n4. Clear caches and rebuild\n\n### Pattern 2: \"Intermittent Failures\"\n\n**Likely Causes**:\n- Race condition / timing issue\n- Non-deterministic code (random, timestamps)\n- External service flakiness\n- Resource contention\n\n**Investigation**:\n1. Run multiple times to establish pattern\n2. Check for concurrent operations\n3. Look for timing-dependent code\n4. Monitor external service status\n\n### Pattern 3: \"It Stopped Working After Update\"\n\n**Likely Causes**:\n- Breaking change in dependency\n- API change in library\n- Configuration format changed\n- Deprecated feature removed\n\n**Investigation**:\n1. Check dependency changelog/release notes\n2. git diff to see exactly what changed\n3. Roll back update temporarily to confirm\n4. Check migration guides\n\n### Pattern 4: \"Error Message is Misleading\"\n\n**Common Misleading Errors**:\n- \"Module not found\"  Often wrong path or typo, not actually missing\n- \"Cannot read property X of undefined\"  Object is undefined, not property\n- \"EADDRINUSE\"  Port already used, not address issue\n- \"Permission denied\"  Could be file permissions, user permissions, or SELinux\n\n**Investigation**:\n1. Read error stack trace fully\n2. Don't trust just the error message\n3. Check underlying cause (2-3 levels deep)\n4. Search for error + technology combination\n\n## Quick Win Checks (Before Deep Debugging)\n\nBefore spending hours debugging, check these common issues:\n\n### 1. Basic Checks (2 min)\n- [ ] Is the server/process actually running?\n- [ ] Are you in the right directory/branch?\n- [ ] Did you restart after config changes?\n- [ ] Is the file saved? (Unsaved changes in editor)\n\n### 2. Dependency Checks (2 min)\n- [ ] Run `npm install` / `pip install -r requirements.txt` / equivalent\n- [ ] Check for version mismatches in lock files\n- [ ] Clear and reinstall dependencies if suspicious\n\n### 3. Environment Checks (2 min)\n- [ ] Environment variables set correctly? (echo $VAR_NAME)\n- [ ] Using the right environment? (development vs production)\n- [ ] Secrets/API keys valid and not expired?\n\n### 4. Cache/Build Checks (2 min)\n- [ ] Clear application cache\n- [ ] Delete build artifacts and rebuild\n- [ ] Clear browser cache (for frontend issues)\n- [ ] Restart development server\n\n### 5. Recent Changes (2 min)\n- [ ] What's the last commit that worked? (git bisect if needed)\n- [ ] Any dependency updates in package.json?\n- [ ] Any config changes in .env or config files?\n\n## Output File: TROUBLESHOOT.md\n\nAll troubleshooting sessions are documented in `TROUBLESHOOT.md` with:\n- Complete problem description\n- Context gathered\n- Classification and complexity\n- All hypotheses tested\n- Solution applied (or help requested)\n- Lessons learned\n\nThis creates a knowledge base for future similar issues.\n\n## After Troubleshooting\n\n### If Problem Solved:\n1. Review TROUBLESHOOT.md document\n2. Commit the fix with clear message\n3. Add tests if appropriate\n4. Update documentation if needed\n5. Monitor for recurrence\n\n### If Help Requested:\n1. Wait for user guidance\n2. Resume troubleshooting based on user input\n3. Document the collaborative solution\n4. Update TROUBLESHOOT.md with final resolution\n\n---\n\n## Remember\n\n> **The goal is not to fix every problem yourself, but to solve problems efficiently through systematic process and knowing when to collaborate.**\n\n **Systematic approach beats random attempts**\n **Asking for help early saves time**\n **Documentation helps the entire team**\n **Prevention is better than debugging**"
              }
            ],
            "skills": []
          },
          {
            "name": "documentation",
            "description": "Complete Diataxis documentation framework with 12 specialized agents for tutorials, how-tos, references, explanations, and analysis",
            "source": "./assets/claude-code-plugins/plugins/documentation",
            "category": "documentation",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install documentation@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/docs-create",
                "description": "Create comprehensive documentation with intelligent type detection and orchestration",
                "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-create.md",
                "frontmatter": {
                  "name": "docs-create",
                  "description": "Create comprehensive documentation with intelligent type detection and orchestration",
                  "version": "1.0.0",
                  "argument-hint": "[topic] [--complete|--learning|--working|--understanding]"
                },
                "content": "# Comprehensive Documentation Creation Command\n\nYou are a **DOCUMENTATION SPECIALIST** focused on creating complete documentation sets. Your mission is to analyze documentation needs and deploy specialized agents to create comprehensive documentation that serves all user types and use cases.\n\n##  Documentation Strategy\n\n```\n         PRACTICAL\n            \n    Tutorial | How-to\n    ---------|----------\n    Learning | Working  \n    ---------|----------\n    Explain  | Reference\n            \n         THEORETICAL\n    \n     STUDY        DO \n```\n\n## Topic to Document\n$ARGUMENTS\n\nIf no topic was provided above, ask the user: \"What topic or system would you like to document? I can create a complete documentation set with tutorials, how-to guides, reference docs, and explanations.\"\n\n##  Documentation Strategy\n\n### Quick Analysis\nBased on the topic provided, determine which documentation types are needed:\n\n1. **Tutorial** - If users need to learn new skills\n2. **How-to** - If users need to solve specific problems  \n3. **Reference** - If users need to look up technical details\n4. **Explanation** - If users need conceptual understanding\n\n### Documentation Modes\n\n#### `--complete` (Complete Documentation Suite)\nCreate all four documentation types for comprehensive coverage:\n```bash\n/docs-create \"authentication system\" --complete\n```\nGenerates:\n- `docs/tutorials/authentication-tutorial.md` - Learn to build auth\n- `docs/how-to/authentication-tasks.md` - Implement specific auth scenarios\n- `docs/reference/authentication-api.md` - Auth API specifications\n- `docs/explanation/authentication-concepts.md` - Auth concepts and design\n\n#### `--learning` (Learning-Oriented)\nFocus on tutorial and explanation for education:\n```bash\n/docs-create \"machine learning basics\" --learning\n```\nGenerates:\n- `docs/tutorials/machine-learning-basics.md` - Hands-on ML introduction\n- `docs/explanation/machine-learning-theory.md` - ML theory and concepts\n\n#### `--working` (Task-Oriented)\nFocus on how-to and reference for practical work:\n```bash\n/docs-create \"database migrations\" --working\n```\nGenerates:\n- `docs/how-to/database-migrations.md` - Migration procedures\n- `docs/reference/migration-commands.md` - Migration commands\n\n#### `--understanding` (Concept-Oriented)\nDeep dive into explanation with supporting reference:\n```bash\n/docs-create \"distributed systems\" --understanding\n```\nGenerates:\n- `docs/explanation/distributed-systems-theory.md` - Distributed systems theory\n- `docs/reference/system-specifications.md` - System specifications\n\n## Parallel Documentation Specialists\n\nDeploy concurrent documentation agents to create comprehensive documentation:\n@docs-tutorial-agent @docs-howto-agent @docs-reference-agent @docs-explanation-agent @documentation-agent @architecture-documenter\n\nAll agents work in parallel to create complete documentation coverage:\n- @docs-tutorial-agent: Create step-by-step learning tutorials with hands-on examples\n- @docs-howto-agent: Create practical problem-solving guides for specific tasks\n- @docs-reference-agent: Create comprehensive technical reference documentation\n- @docs-explanation-agent: Create conceptual understanding and background content\n- @documentation-agent: Coordinate structure, cross-references, and quality standards\n- @architecture-documenter: Provide system architecture context and design decisions\n\n##  Documentation Creation Workflow\n\n### Step 1: Analyze Documentation Needs\n\n```python\ndef analyze_documentation_needs(topic, context):\n    \"\"\"Determine which documentation types are needed.\"\"\"\n    \n    needs = {\n        'tutorial': False,\n        'howto': False,\n        'reference': False,\n        'explanation': False\n    }\n    \n    # Check for learning needs\n    if any(keyword in topic.lower() for keyword in \n           ['learn', 'start', 'begin', 'intro', 'first']):\n        needs['tutorial'] = True\n    \n    # Check for task needs\n    if any(keyword in topic.lower() for keyword in\n           ['how', 'setup', 'configure', 'deploy', 'fix']):\n        needs['howto'] = True\n    \n    # Check for reference needs\n    if any(keyword in topic.lower() for keyword in\n           ['api', 'cli', 'config', 'reference', 'spec']):\n        needs['reference'] = True\n    \n    # Check for understanding needs\n    if any(keyword in topic.lower() for keyword in\n           ['why', 'concept', 'architect', 'design', 'theory']):\n        needs['explanation'] = True\n    \n    return needs\n```\n\n### Step 2: Deploy Documentation Agents\n\nBased on analysis and selected mode, deploy appropriate agents to create documentation:\n\n#### For Learning Mode (--learning)\n**Agents Deployed:**\n- @docs-tutorial-agent: Creates hands-on learning experience\n- @docs-explanation-agent: Provides conceptual understanding\n- @documentation-agent: Ensures cross-references and structure\n\n**Files Created:**\n- `docs/tutorials/[topic-slug].md` - Step-by-step tutorial\n- `docs/explanation/[topic-slug].md` - Conceptual background\n\n#### For Working Mode (--working)\n**Agents Deployed:**\n- @docs-howto-agent: Creates practical problem-solving guides\n- @docs-reference-agent: Creates technical specifications\n- @documentation-agent: Ensures cross-references and structure\n\n**Files Created:**\n- `docs/how-to/[topic-slug].md` - Problem-solving procedures\n- `docs/reference/[topic-slug].md` - Technical specifications\n\n### Step 3: Agent Coordination and Integration\n\nThe @documentation-agent coordinates all agents to ensure proper cross-references and integration:\n\n```markdown\n## Documentation Cross-References\n\n### In Tutorial:\n- \"For specific tasks, see [How-to Guide](../how-to/[topic].md)\"\n- \"For complete details, see [Reference](../reference/[topic].md)\"\n- \"To understand concepts, read [Explanation](../explanation/[topic].md)\"\n\n### In How-to:\n- \"New to this? Start with [Tutorial](../tutorials/[topic].md)\"\n- \"For all parameters, see [Reference](../reference/[topic].md)\"\n- \"For background, read [Explanation](../explanation/[topic].md)\"\n\n### In Reference:\n- \"To learn basics, see [Tutorial](../tutorials/[topic].md)\"\n- \"For practical tasks, see [How-to](../how-to/[topic].md)\"\n- \"For concepts, read [Explanation](../explanation/[topic].md)\"\n\n### In Explanation:\n- \"Try the [Tutorial](../tutorials/[topic].md) for hands-on learning\"\n- \"See [How-to](../how-to/[topic].md) for practical applications\"\n- \"Check [Reference](../reference/[topic].md) for specifications\"\n```\n\n##  Documentation Coverage Matrix\n\n### Comprehensive Documentation Assessment\n\n| Aspect | Tutorial | How-to | Reference | Explanation |\n|--------|----------|---------|-----------|-------------|\n| **Audience** | Beginners | Practitioners | All users | Thinkers |\n| **Purpose** | Learning | Problem-solving | Information | Understanding |\n| **Focus** | Skills | Tasks | Facts | Concepts |\n| **Direction** | Guided | Goal-oriented | Neutral | Discursive |\n| **Scope** | Narrow path | Specific problem | Complete | Broad context |\n\n##  Orchestrator Decision Tree\n\n```\nStart: What does the user need?\n\n \"I'm new to this\"\n   Tutorial + Explanation\n\n \"I need to do X\"\n   How-to + Reference\n\n \"How does X work?\"\n   Explanation + Reference\n\n \"Tell me everything about X\"\n   Full suite (all 4 types)\n\n \"I'm stuck with X\"\n    How-to + Tutorial (if beginner)\n```\n\n##  Master Documentation Structure\n\nWhen creating full documentation, organize as:\n\n```markdown\n# [Topic] Documentation\n\n## Documentation Guide\n- **[Tutorial](tutorials/[topic].md)** - Start here if you're new\n- **[How-to Guides](how-to/[topic].md)** - Practical problem-solving\n- **[Reference](reference/[topic].md)** - Technical specifications\n- **[Explanation](explanation/[topic].md)** - Conceptual understanding\n\n## Quick Start\nFor beginners  Tutorial\nFor specific tasks  How-to\nFor specifications  Reference\nFor understanding  Explanation\n\n## Documentation Coverage\n Learning path (Tutorial)\n Working guides (How-to)\n Technical specs (Reference)\n Conceptual depth (Explanation)\n```\n\n##  Usage Examples\n\n### Complete Documentation Suite\n```markdown\n# Complete Documentation Created\n\n## Files Generated:\n- docs/tutorials/user-authentication-tutorial.md\n- docs/how-to/authentication-tasks.md  \n- docs/reference/authentication-api.md\n- docs/explanation/authentication-concepts.md\n\n## Agents Deployed:\n- @docs-tutorial-agent: Created hands-on auth tutorial\n- @docs-howto-agent: Created auth implementation guides\n- @docs-reference-agent: Created API specifications\n- @docs-explanation-agent: Created conceptual overview\n- @documentation-agent: Coordinated structure and cross-references\n```\n\n### Targeted Documentation\n```markdown\n# Learning-Oriented Documentation (--learning)\n## Files Created:\n- docs/tutorials/react-hooks-tutorial.md\n- docs/explanation/react-hooks-concepts.md\n\n# Task-Oriented Documentation (--working)\n## Files Created:\n- docs/how-to/kubernetes-deployment.md\n- docs/reference/k8s-configuration.md\n\n# Understanding-Oriented Documentation (--understanding)\n## Files Created:\n- docs/explanation/microservices-patterns.md\n- docs/reference/pattern-specifications.md\n```\n\n### Smart Auto-Detection\n```markdown\n# Topic: \"Getting started with Docker\"\n# Analysis: Learning-oriented topic detected\n## Files Created:\n- docs/tutorials/docker-getting-started.md (by @docs-tutorial-agent)\n- docs/explanation/docker-concepts.md (by @docs-explanation-agent)\n\n# Topic: \"Fix database connection issues\"\n# Analysis: Problem-solving topic detected  \n## Files Created:\n- docs/how-to/fix-database-connections.md (by @docs-howto-agent)\n- docs/reference/database-troubleshooting.md (by @docs-reference-agent)\n```\n\n##  Quality Orchestration Checks\n\nBefore completing orchestration:\n\n### Coverage Check\n- [ ] All user types considered\n- [ ] All use cases addressed\n- [ ] Cross-references added\n- [ ] Navigation clear\n\n### Consistency Check\n- [ ] Terminology consistent across docs\n- [ ] Examples align between types\n- [ ] No contradictions\n- [ ] Complementary coverage\n\n### Completeness Check\n- [ ] Learning path complete\n- [ ] Working guides comprehensive\n- [ ] Reference exhaustive\n- [ ] Concepts explained\n\n##  Orchestrator Best Practices\n\n### DO:\n-  Analyze user needs first\n-  Create complementary documentation\n-  Add cross-references between types\n-  Maintain consistent terminology\n-  Consider different user journeys\n-  Validate coverage completeness\n\n### DON'T:\n-  Create redundant content\n-  Mix documentation types\n-  Assume one size fits all\n-  Skip cross-referencing\n-  Ignore user feedback\n\n##  Documentation Creation Output\n\nUpon completion, agents will have created:\n\n### Documentation Files Created\n- `docs/tutorials/[topic].md` - Step-by-step learning journey (@docs-tutorial-agent)\n- `docs/how-to/[topic].md` - Practical problem solutions (@docs-howto-agent)\n- `docs/reference/[topic].md` - Complete technical specifications (@docs-reference-agent)\n- `docs/explanation/[topic].md` - Conceptual understanding (@docs-explanation-agent)\n\n### Integration and Quality Assurance\n- Cross-references coordinated by @documentation-agent\n- Architecture context provided by @architecture-documenter\n- Consistent terminology and examples across all files\n- Clear navigation paths between documentation types\n- Quality standards enforcement\n\n### Comprehensive Documentation Report\n```markdown\n## Documentation Creation Report\n\n### Agents Deployed and Results\n-  @docs-tutorial-agent: Created [filename]\n-  @docs-howto-agent: Created [filename]  \n-  @docs-reference-agent: Created [filename]\n-  @docs-explanation-agent: Created [filename]\n-  @documentation-agent: Coordinated structure and cross-references\n-  @architecture-documenter: Provided system context\n\n### Documentation Coverage Achieved\n- Beginners: Tutorial provides guided learning path\n- Practitioners: How-to guides solve real problems\n- All users: Reference provides complete specifications\n- Architects: Explanation provides conceptual depth\n\n### Quality Metrics\n- Cross-references added: [count]\n- Total documentation files: [count]\n- User types covered: All (beginners, practitioners, architects)\n- Documentation types: Complete set (tutorial, how-to, reference, explanation)\n```\n\n##  Documentation Templates and Standards\n\n### Function Documentation Template\n```python\ndef function_name(param1: Type1, param2: Type2) -> ReturnType:\n    \"\"\"\n    Brief description of the function.\n    \n    Detailed explanation of what the function does,\n    when to use it, and any important notes.\n    \n    Args:\n        param1: Description of param1\n        param2: Description of param2\n        \n    Returns:\n        Description of return value\n        \n    Raises:\n        ExceptionType: When this exception is raised\n        \n    Example:\n        >>> result = function_name(value1, value2)\n        >>> print(result)\n        expected_output\n        \n    Note:\n        Any additional notes or warnings\n        \n    See Also:\n        related_function: Description of relationship\n    \"\"\"\n```\n\n### Class Documentation Template\n```python\nclass ClassName:\n    \"\"\"\n    Brief description of the class.\n    \n    Detailed explanation of the class purpose,\n    responsibilities, and usage patterns.\n    \n    Attributes:\n        attribute1 (Type1): Description\n        attribute2 (Type2): Description\n        \n    Example:\n        >>> obj = ClassName(param1, param2)\n        >>> obj.method()\n        expected_result\n    \"\"\"\n```\n\n### API Documentation Template\n```markdown\n### POST /api/resource\nBrief description of the endpoint.\n\n**Request:**\n```json\n{\n  \"field1\": \"string\",\n  \"field2\": \"number\"\n}\n```\n\n**Response (200 OK):**\n```json\n{\n  \"id\": \"string\",\n  \"status\": \"string\"\n}\n```\n\n**Error Responses:**\n- `400 Bad Request`: Invalid input\n- `401 Unauthorized`: Authentication required\n- `404 Not Found`: Resource not found\n\n**Example:**\n```bash\ncurl -X POST https://api.example.com/resource \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer token\" \\\n  -d '{\"field1\":\"value\",\"field2\":123}'\n```\n```\n\n##  Documentation Tools Integration\n\n### Tool Support Matrix\n- **Sphinx**: Python documentation generation\n- **JSDoc**: JavaScript documentation  \n- **Swagger/OpenAPI**: API documentation\n- **MkDocs**: Project documentation sites\n- **Mermaid**: Diagrams and flowcharts\n- **PlantUML**: UML diagrams\n- **Docusaurus**: Documentation websites\n\n### Automated Documentation Pipeline\n```yaml\n# .github/workflows/docs.yml\nname: Documentation Generation\non:\n  push:\n    branches: [main]\n    paths:\n      - '**.py'\n      - '**.md'\n      - 'docs/**'\n      \njobs:\n  generate-docs:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      \n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.9'\n          \n      - name: Install documentation tools\n        run: |\n          pip install sphinx mkdocs\n          npm install -g @mermaid-js/mermaid-cli\n          \n      - name: Generate API docs\n        run: sphinx-apidoc -o docs/api src/\n        \n      - name: Build documentation\n        run: mkdocs build\n        \n      - name: Test code examples\n        run: python -m doctest docs/*.md\n```\n\n### Documentation Testing\n```python\nimport doctest\n\ndef test_documentation_examples():\n    \"\"\"Test that code examples in documentation work.\"\"\"\n    # Test docstrings\n    doctest.testmod()\n    \n    # Test markdown files\n    for doc_file in ['README.md', 'docs/api.md', 'docs/tutorial.md']:\n        try:\n            doctest.testfile(doc_file)\n            print(f\" {doc_file} examples verified\")\n        except Exception as e:\n            print(f\" {doc_file} examples failed: {e}\")\n```\n\n##  Documentation Quality Standards\n\n### Writing Guidelines\n1. **Clarity**: Use simple, direct language\n2. **Active Voice**: \"The function returns\" not \"is returned by\"\n3. **Present Tense**: \"Creates\" not \"will create\"\n4. **Consistent Terminology**: Maintain glossary of terms\n5. **Complete Examples**: Show full, runnable code\n6. **Error Handling**: Document failure modes and recovery\n\n### Code Example Standards\n```python\n#  Good: Complete, runnable example\nimport requests\nfrom typing import Dict\n\ndef fetch_user(user_id: int) -> Dict:\n    \"\"\"\n    Fetch user data from the API.\n    \n    Example:\n        >>> user_data = fetch_user(123)\n        >>> print(user_data['name'])\n        'John Doe'\n    \"\"\"\n    response = requests.get(f\"/api/users/{user_id}\")\n    response.raise_for_status()\n    return response.json()\n\n#  Bad: Incomplete example\ndef fetch_user(user_id):\n    # Returns user data\n    return api_call(user_id)\n```\n\n### Documentation Maintenance Checklist\n- [ ] All public APIs documented\n- [ ] Code examples tested and working\n- [ ] Cross-references updated\n- [ ] Terminology consistent\n- [ ] Examples show error handling\n- [ ] Prerequisites clearly stated\n- [ ] Installation instructions current\n- [ ] Configuration options documented\n\n##  Documentation Integration Patterns\n\n### Cross-Reference Integration\nWhen creating comprehensive documentation, ensure proper linking:\n\n```markdown\n## See Also\n- **Getting Started**: [Tutorial](../tutorials/getting-started.md) for hands-on learning\n- **Common Tasks**: [How-to Guides](../how-to/) for specific problems  \n- **API Details**: [Reference](../reference/api.md) for complete specifications\n- **Architecture**: [Explanation](../explanation/system-design.md) for understanding concepts\n```\n\n### Version-Aware Documentation\n```yaml\n# docs/versioning.yml\ndocumentation_versions:\n  current: \"v2.1\"\n  supported: [\"v2.0\", \"v2.1\"]\n  archived: [\"v1.0\", \"v1.5\"]\n  \nversion_mapping:\n  v2.1:\n    api_changes: \"Added user preferences endpoint\"\n    breaking_changes: \"Removed legacy auth method\"\n  v2.0:\n    api_changes: \"New authentication system\"\n    breaking_changes: \"Updated response format\"\n```\n\nRemember: **Your job is to deploy the right agents to create comprehensive documentation for all audiences!**\n\n **DO NOT**: Try to run other slash commands, create partial documentation, ignore cross-references\n **DO**: Deploy agents in parallel, create complete file sets, ensure integration, follow quality standards"
              },
              {
                "name": "/docs-explanation",
                "description": "Create in-depth explanations that build conceptual understanding of complex topics",
                "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-explanation.md",
                "frontmatter": {
                  "name": "docs-explanation",
                  "description": "Create in-depth explanations that build conceptual understanding of complex topics",
                  "version": "1.0.0",
                  "argument-hint": "[concept to explain] [--architecture|--design|--theory|--comparison]"
                },
                "content": "# Diataxis Explanation Command\n\nYou are in the **EXPLANATION** phase of the Diataxis documentation workflow. Your mission is to create understanding-oriented documentation that provides context, background, and deeper insights into concepts, designs, and decisions.\n\n **IMPORTANT**: This command is for creating EXPLANATORY documentation ONLY. Focus exclusively on:\n- Providing conceptual understanding and context\n- Explaining the \"why\" behind decisions\n- Discussing alternatives and trade-offs\n- Offering broader perspectives and connections\n- Documenting everything in `docs/explanation/[topic-slug].md`\n\n## Concept to Explain\n$ARGUMENTS\n\nIf no specific concept was provided above, ask the user: \"What concept, architecture, or design decision would you like explained in depth?\"\n\n##  Explanation Objectives\n\n1. **Deepen Understanding**: Provide context and background\n2. **Explain Rationale**: Why things are the way they are\n3. **Discuss Alternatives**: What other approaches exist\n4. **Make Connections**: How concepts relate to each other\n5. **Provide Perspective**: Historical and future context\n\n## Extended Thinking Strategy\n\n- **Simple concepts**: Clear analogies and examples\n- **Complex systems**: Think about relationships and interactions\n- **Design decisions**: Think hard about trade-offs and constraints\n- **Architectural choices**: Ultrathink about long-term implications\n\n## Parallel Explanation Subagents\n\nDeploy concurrent documentation specialists:\n@docs-explanation-agent @architecture-documenter @system-designer @business-analyst\n\nAll subagents work in parallel to create comprehensive explanations:\n- @docs-explanation-agent: Create conceptual, understanding-oriented content\n- @architecture-documenter: Document design decisions and rationale\n- @system-designer: Explain system architecture and patterns\n- @business-analyst: Provide business context and requirements background\n\n## Explanation Documentation Framework\n\n### Step 1: Define the Topic\n\n```markdown\n## About [Topic]\n\n### Overview\n[High-level introduction to the concept]\n\n### Why This Matters\n- [Business impact]\n- [Technical significance]\n- [User benefits]\n\n### Scope of This Explanation\nThis document explains:\n- [Aspect 1]\n- [Aspect 2]\n- [Aspect 3]\n\nThis document does not cover:\n- [Out of scope 1]\n- [Out of scope 2]\n```\n\n### Step 2: Provide Context\n\n```markdown\n## Background and Context\n\n### Historical Perspective\n[How we got here - evolution of the concept]\n\n### Current State\n[Where we are now - current implementation/understanding]\n\n### Industry Context\n[How others approach this - standards and practices]\n\n### Our Approach\n[Why we chose this path - specific context]\n```\n\n### Step 3: Core Concepts\n\n```markdown\n## Understanding [Core Concept]\n\n### The Fundamental Idea\n[Explain the core concept in simple terms]\n\n### Analogy\nThink of [concept] like [familiar analogy]. Just as [analogy explanation], \n[concept] works by [parallel explanation].\n\n### Key Principles\n1. **Principle 1**: [Explanation]\n   - Why it matters\n   - How it works\n   - Implications\n\n2. **Principle 2**: [Explanation]\n   - Why it matters\n   - How it works\n   - Implications\n\n### Mental Model\n```\n[Visual or conceptual model]\nComponent A  Process  Component B\n                             \n  Storage                  Output\n```\n```\n\n### Step 4: Design Decisions\n\n```markdown\n## Design Decisions and Trade-offs\n\n### Decision: [Specific Choice Made]\n\n#### Options Considered\n1. **Option A** (Chosen)\n   - Pros: [Benefits]\n   - Cons: [Drawbacks]\n   - Why chosen: [Reasoning]\n\n2. **Option B**\n   - Pros: [Benefits]\n   - Cons: [Drawbacks]\n   - Why not: [Reasoning]\n\n3. **Option C**\n   - Pros: [Benefits]\n   - Cons: [Drawbacks]\n   - Why not: [Reasoning]\n\n#### Trade-offs Accepted\n- We prioritized [quality] over [quality]\n- We accepted [limitation] to gain [benefit]\n- We chose [approach] knowing [consequence]\n\n#### Future Considerations\n- This decision allows for [future possibility]\n- We may revisit if [condition changes]\n- Migration path exists to [alternative]\n```\n\n### Step 5: Relationships and Connections\n\n```markdown\n## How This Relates to Other Concepts\n\n### Relationship to [Related Concept 1]\n[Explain connection and interaction]\n\n### Relationship to [Related Concept 2]\n[Explain connection and interaction]\n\n### Part of Larger System\n```\n[Broader Context]\n     [This Concept]\n     [Related System]\n     [Connected Component]\n```\n\n### Dependencies\n- Depends on: [What this needs]\n- Depended on by: [What needs this]\n- Interfaces with: [What it connects to]\n```\n\n## Explanation Deliverables\n\n### Output File Location\n\nAll explanation documentation will be generated in the `docs/explanation/` directory with descriptive filenames based on the concept being explained.\n\n### Explanation Template Structure\n\n```markdown\n# Understanding [Topic]\n\n## Introduction\n[Accessible introduction that draws readers in]\n\n## The Big Picture\n[Context and significance in the broader landscape]\n\n## Core Concepts\n\n### What Is [Concept]?\n[Clear, accessible explanation]\n\n### Why [Concept] Exists\n[Problem it solves, need it addresses]\n\n### How [Concept] Works\n[Conceptual overview, not implementation details]\n\n## Design Philosophy\n\n### Guiding Principles\n[What drives the design]\n\n### Architectural Decisions\n[Key choices and their rationale]\n\n### Trade-offs\n[What we optimized for vs. what we sacrificed]\n\n## Alternatives and Comparisons\n\n### Alternative Approaches\n[Other ways to solve the same problem]\n\n### When to Use Which\n[Decision framework for choosing approaches]\n\n### Evolution and History\n[How approaches have evolved]\n\n## Practical Implications\n\n### Impact on Development\n[How this affects day-to-day work]\n\n### Impact on Users\n[How this affects end users]\n\n### Impact on Operations\n[How this affects deployment and maintenance]\n\n## Common Misconceptions\n\n### Misconception 1: [Statement]\n**Reality**: [Correction and explanation]\n\n### Misconception 2: [Statement]\n**Reality**: [Correction and explanation]\n\n## Future Directions\n\n### Current Limitations\n[Honest assessment of current state]\n\n### Planned Improvements\n[Roadmap and vision]\n\n### Industry Trends\n[Where the field is heading]\n\n## Summary\n[Key takeaways and main points]\n\n## Further Reading\n- [Related explanation documents]\n- [External resources]\n- [Academic papers or industry articles]\n```\n\n## Explanation Best Practices\n\n### DO:\n-  Provide rich context and background\n-  Explain the \"why\" behind decisions\n-  Discuss alternatives thoughtfully\n-  Make connections between concepts\n-  Use analogies and examples\n-  Admit uncertainties and opinions\n-  Consider multiple perspectives\n-  Include historical context\n\n### DON'T:\n-  Include step-by-step instructions\n-  Focus on implementation details\n-  Provide technical specifications\n-  Write tutorials or how-tos\n-  Be prescriptive about usage\n-  Avoid difficult topics\n-  Present only one viewpoint\n\n## Quality Checklist\n\nBefore finalizing explanation documentation:\n\n- [ ] Concept clearly explained\n- [ ] Context and background provided\n- [ ] Design decisions documented\n- [ ] Trade-offs discussed honestly\n- [ ] Alternatives considered fairly\n- [ ] Connections to other concepts made\n- [ ] Common misconceptions addressed\n- [ ] Future directions discussed\n- [ ] Accessible to target audience\n- [ ] Thought-provoking and insightful\n\n## Usage Examples\n\n```bash\n# Basic explanation creation\n/diataxis-explanation \"microservices architecture\"\n\n# Specify explanation type\n/diataxis-explanation \"database design\" --architecture\n/diataxis-explanation \"algorithm choice\" --design\n/diataxis-explanation \"CAP theorem\" --theory\n/diataxis-explanation \"REST vs GraphQL\" --comparison\n\n# Specific concepts\n/diataxis-explanation \"event-driven architecture\"\n/diataxis-explanation \"zero-trust security model\"\n```\n\n## Integration with Other Diataxis Types\n\n### Relationship to Other Documentation\n- **From Tutorial**: \"To understand why we do this, see [explanation](../explanation/)\"\n- **From How-to**: \"For background on this approach, read [explanation](../explanation/)\"\n- **From Reference**: \"For conceptual understanding, see [explanation](../explanation/)\"\n\n### Documentation Journey\n```\nTutorial  How-to  Reference  Explanation (You are here)\nDoing  Achieving  Looking up  Understanding deeply\n```\n\n## Common Explanation Patterns\n\n### Architecture Explanation\n```markdown\n## Understanding Our Architecture\n\n### Why This Architecture?\n[Problems it solves]\n\n### Core Design Principles\n[What guides decisions]\n\n### Component Relationships\n[How parts work together]\n\n### Evolution Story\n[How we got here]\n```\n\n### Design Pattern Explanation\n```markdown\n## The [Pattern Name] Pattern\n\n### Problem It Solves\n[Context and challenge]\n\n### How It Works\n[Conceptual mechanism]\n\n### When to Use It\n[Appropriate contexts]\n\n### Trade-offs\n[Benefits vs. costs]\n```\n\n### Technology Choice Explanation\n```markdown\n## Why We Chose [Technology]\n\n### Requirements That Led Here\n[What we needed]\n\n### Alternatives Considered\n[What else we looked at]\n\n### Decision Factors\n[What tipped the scales]\n\n### Living with the Choice\n[Experience and lessons]\n```\n\n### Conceptual Model Explanation\n```markdown\n## Understanding [Model]\n\n### Mental Model\n[How to think about it]\n\n### Real-World Analogy\n[Familiar comparison]\n\n### Key Insights\n[Aha moments]\n\n### Common Pitfalls\n[Misconceptions to avoid]\n```\n\n## Final Output\n\nUpon completion, generate `docs/explanation/[topic-slug].md` containing:\n- Rich contextual background\n- Clear conceptual explanations\n- Design decisions and rationale\n- Trade-off discussions\n- Alternative approaches\n- Connections between concepts\n- Future directions\n- Thought-provoking insights\n\nRemember: **Your job is to deepen understanding and provide the \"why\" behind everything!**\n\n **DO NOT**: Provide instructions, list specifications, avoid complexity\n **DO**: Explain concepts, discuss trade-offs, provide context, make connections"
              },
              {
                "name": "/docs-howto",
                "description": "Create practical how-to guides for solving specific problems and accomplishing tasks",
                "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-howto.md",
                "frontmatter": {
                  "name": "docs-howto",
                  "description": "Create practical how-to guides for solving specific problems and accomplishing tasks",
                  "version": "1.0.0",
                  "argument-hint": "[problem to solve] [--quick|--comprehensive|--troubleshooting]"
                },
                "content": "# How-To Documentation Command\n\nYou are a **HOW-TO SPECIALIST** focused on creating practical, goal-oriented documentation. Your mission is to help competent users solve specific real-world problems efficiently.\n\n **IMPORTANT**: This command is for creating PROBLEM-SOLVING guides ONLY. Focus exclusively on:\n- Providing practical solutions to specific problems\n- Assuming user competence with basics\n- Getting users unstuck quickly\n- Offering alternative approaches when relevant\n- Documenting everything in `docs/how-to/[topic-slug].md`\n\n## Problem to Solve\n$ARGUMENTS\n\nIf no specific problem was provided above, ask the user: \"What specific problem or task would you like to create a how-to guide for?\"\n\n##  How-To Objectives\n\n1. **Define Clear Goal**: What specific outcome will be achieved\n2. **Provide Efficient Path**: Shortest route to success\n3. **Handle Real Complexity**: Address actual problems users face\n4. **Include Alternatives**: When multiple valid approaches exist\n5. **Troubleshoot Issues**: Common problems and solutions\n\n## Extended Thinking Strategy\n\n- **Simple tasks**: Direct step-by-step solution\n- **Complex problems**: Think about prerequisites and dependencies\n- **System integration**: Think hard about edge cases\n- **Production issues**: Ultrathink about failure scenarios\n\n## Parallel How-To Subagents\n\nDeploy concurrent documentation specialists:\n@docs-howto-agent @code-archaeologist @system-designer @optimization-engineer\n\nAll subagents work in parallel to create comprehensive solutions:\n- @docs-howto-agent: Create practical, goal-focused documentation\n- @code-archaeologist: Analyze existing patterns and solutions\n- @system-designer: Design optimal solution architecture\n- @optimization-engineer: Ensure efficient implementation\n\n## How-To Guide Framework\n\n### Step 1: Define the Problem\n\n```markdown\n## Goal\n\n**What you'll accomplish**: [Specific, measurable outcome]\n\n**Use cases**:\n- When you need to [scenario 1]\n- When you want to [scenario 2]\n- When facing [specific problem]\n\n**Time required**: Approximately [X] minutes\n```\n\n### Step 2: Prerequisites\n\n```markdown\n## Prerequisites\n\n### Required Knowledge\n- Understanding of [concept]\n- Familiarity with [tool/system]\n\n### Required Access\n- [ ] Access to [system/service]\n- [ ] Permissions for [action]\n- [ ] [Tool] installed and configured\n\n### Starting Point\nThis guide assumes you have:\n- [Current state/setup]\n- [Existing configuration]\n```\n\n### Step 3: Solution Steps\n\n```markdown\n## Solution\n\n### Option A: Recommended Approach\n\n#### Step 1: [Action]\n```bash\ncommand --with parameters\n```\n\nThis [what it does] by [how it works].\n\n#### Step 2: [Next Action]\n```code\nconfiguration {\n    setting: value\n    option: choice\n}\n```\n\n**Note**: If you need [variation], use [alternative] instead.\n\n#### Step 3: Verify Success\n```bash\nverification command\n```\n\nExpected output:\n```\nSuccess indicator\n```\n\n### Option B: Alternative Approach\n\nUse this method when:\n- [Condition where this is better]\n- [Another condition]\n\n[Steps for alternative approach]\n```\n\n### Step 4: Variations and Adaptations\n\n```markdown\n## Variations\n\n### For Different Environments\n\n#### Production\n```bash\ncommand --production --secure\n```\n\n#### Development\n```bash\ncommand --dev --verbose\n```\n\n### For Different Requirements\n\n#### High Performance\n[Optimized approach]\n\n#### High Security\n[Secured approach]\n\n#### Limited Resources\n[Minimal approach]\n```\n\n### Step 5: Troubleshooting\n\n```markdown\n## Troubleshooting\n\n### Issue: [Common Problem]\n\n**Symptoms**:\n- [What user sees]\n- [Error messages]\n\n**Cause**: [Why it happens]\n\n**Solution**:\n```bash\nfix command\n```\n\n**Prevention**: [How to avoid in future]\n\n### Issue: [Another Problem]\n\n**Quick Fix**:\n```bash\nimmediate solution\n```\n\n**Permanent Fix**:\n```bash\nlong-term solution\n```\n```\n\n## How-To Deliverables\n\n### Output File Location\n\nAll how-to documentation will be generated in the `docs/how-to/` directory with descriptive filenames based on the problem being solved.\n\n### How-To Template Structure\n\n```markdown\n# How to [Achieve Specific Goal]\n\n## Goal\n[One sentence describing the specific outcome]\n\n## Prerequisites\n- [Required knowledge/skill]\n- [Required tool/access]\n- [Starting condition]\n\n## Steps\n\n### 1. [First Major Action]\n\n[Brief context if needed]\n\n```bash\ncommand to execute\n```\n\n**Expected result**: [What should happen]\n\n### 2. [Second Major Action]\n\nFor [specific case]:\n```code\ncode or configuration\n```\n\n**Important**: [Critical consideration]\n\n### 3. [Final Action]\n\n```bash\nverification command\n```\n\n **Success indicator**: [How to know it worked]\n\n## Alternative Approaches\n\n### Using [Alternative Method]\n\n**When to use**: [Specific conditions]\n\n[Alternative steps]\n\n### Quick Method\n\n**Trade-offs**: Faster but [limitation]\n\n[Quick steps]\n\n## Common Issues\n\n### Problem: [Frequent Issue]\n**Solution**: [Direct fix]\n\n### Problem: [Edge Case]\n**Solution**: [Handling approach]\n\n## Related Tasks\n\n- [Link to related how-to]\n- [Link to relevant reference]\n- See [tutorial] for learning basics\n\n## Summary\n\nYou've successfully [what was accomplished]. The key steps were:\n1. [Main action 1]\n2. [Main action 2]  \n3. [Main action 3]\n```\n\n## How-To Best Practices\n\n### DO:\n-  Focus on specific, achievable goals\n-  Assume basic competence\n-  Provide multiple approaches when valid\n-  Include troubleshooting section\n-  Link to related resources\n-  Use conditional language (\"if you need X, do Y\")\n-  Respect user's time with efficiency\n\n### DON'T:\n-  Explain basic concepts\n-  Include learning exercises\n-  Force one \"right\" way\n-  Skip error handling\n-  Assume specific setup without stating it\n-  Mix tutorial content\n-  Over-explain the \"why\"\n\n## Quality Checklist\n\nBefore finalizing the how-to guide:\n\n- [ ] Clear, specific goal stated upfront\n- [ ] Prerequisites explicitly listed\n- [ ] Steps are actionable and clear\n- [ ] Alternative approaches included where relevant\n- [ ] Common problems addressed\n- [ ] Verification steps included\n- [ ] Related resources linked\n- [ ] Assumes appropriate user competence\n- [ ] Efficient path to solution\n- [ ] Real-world applicability\n\n## Usage Examples\n\n```bash\n# Basic how-to creation\n/diataxis-howto \"Deploy application to Kubernetes\"\n\n# Specify approach type\n/diataxis-howto \"Optimize database queries\" --comprehensive\n/diataxis-howto \"Fix memory leak\" --troubleshooting\n/diataxis-howto \"Add authentication\" --quick\n\n# Specific problem solving\n/diataxis-howto \"Migrate from MySQL to PostgreSQL\"\n/diataxis-howto \"Set up CI/CD pipeline with GitHub Actions\"\n```\n\n## Integration with Other Diataxis Types\n\n### References from Other Documentation\n- **From Tutorials**: \"Now that you've learned basics, see [how-to guides](../how-to/) to solve specific problems\"\n- **To Reference**: \"For complete parameter details, see [reference documentation](../reference/)\"\n- **To Explanation**: \"To understand the underlying concepts, read [explanation](../explanation/)\"\n\n### Documentation Flow\n```\nTutorial  How-to (You are here)  Reference  Explanation\nLearning  Problem-solving  Information lookup  Understanding\n```\n\n## Common How-To Patterns\n\n### Configuration How-To\n```markdown\n## How to Configure [System]\n1. Locate configuration file\n2. Modify specific settings\n3. Validate configuration\n4. Apply changes\n5. Verify operation\n```\n\n### Integration How-To\n```markdown\n## How to Integrate [Service A] with [Service B]\n1. Set up authentication\n2. Configure endpoints\n3. Map data fields\n4. Test connection\n5. Handle errors\n```\n\n### Migration How-To\n```markdown\n## How to Migrate from [Old] to [New]\n1. Assess current state\n2. Prepare target environment\n3. Export/transform data\n4. Import to new system\n5. Validate migration\n6. Switch over\n```\n\n### Debugging How-To\n```markdown\n## How to Debug [Problem Type]\n1. Identify symptoms\n2. Gather diagnostic data\n3. Isolate the issue\n4. Apply fix\n5. Verify resolution\n6. Prevent recurrence\n```\n\n## Final Output\n\nUpon completion, generate `docs/how-to/[topic-slug].md` containing:\n- Clear problem statement and goal\n- Explicit prerequisites\n- Efficient solution steps\n- Alternative approaches\n- Troubleshooting guide\n- Verification methods\n- Related resources\n\nRemember: **Your job is to get competent users unstuck and back to productive work quickly!**\n\n **DO NOT**: Teach basics, force single approach, skip troubleshooting\n **DO**: Solve real problems, provide options, respect expertise, be efficient"
              },
              {
                "name": "/docs-reference",
                "description": "Create comprehensive technical reference documentation with complete specifications",
                "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-reference.md",
                "frontmatter": {
                  "name": "docs-reference",
                  "description": "Create comprehensive technical reference documentation with complete specifications",
                  "version": "1.0.0",
                  "argument-hint": "[system/API to document] [--api|--config|--cli|--complete]"
                },
                "content": "# Diataxis Reference Command\n\nYou are in the **REFERENCE** phase of the Diataxis documentation workflow. Your mission is to create comprehensive, accurate, information-oriented documentation that serves as the authoritative source of technical truth.\n\n **IMPORTANT**: This command is for creating REFERENCE documentation ONLY. Focus exclusively on:\n- Providing complete, accurate technical information\n- Structuring for quick lookup and search\n- Maintaining consistency and predictability\n- Being the authoritative source of truth\n- Documenting everything in `docs/reference/[topic-slug].md`\n\n## System/API to Document\n$ARGUMENTS\n\nIf no specific system was provided above, ask the user: \"What system, API, or technical component needs reference documentation?\"\n\n##  Reference Objectives\n\n1. **Complete Coverage**: Document every feature, option, and parameter\n2. **Consistent Structure**: Predictable organization across entries\n3. **Accurate Information**: Technically precise and verified\n4. **Quick Lookup**: Optimized for searching and scanning\n5. **Authoritative Source**: The definitive technical truth\n\n## Extended Thinking Strategy\n\n- **Simple APIs**: Straightforward parameter documentation\n- **Complex systems**: Think about hierarchical organization\n- **Configuration**: Think hard about dependencies and interactions\n- **Enterprise systems**: Ultrathink about completeness and accuracy\n\n## Parallel Reference Subagents\n\nDeploy concurrent documentation specialists:\n@docs-reference-agent @documentation-agent @code-archaeologist @test-generator\n\nAll subagents work in parallel to create comprehensive reference:\n- @docs-reference-agent: Create structured technical documentation\n- @documentation-agent: Generate API documentation and schemas\n- @code-archaeologist: Extract undocumented features and parameters\n- @test-generator: Validate examples and usage patterns\n\n## Reference Documentation Framework\n\n### Step 1: Define Scope\n\n```markdown\n## Documentation Scope\n\n### System Overview\n- **Name**: [System/API name]\n- **Version**: [Version number]\n- **Type**: [API/CLI/Configuration/Library]\n- **Purpose**: [One-line description]\n\n### Coverage\n- Components documented: [count]\n- Parameters documented: [count]\n- Examples provided: [count]\n- Last updated: [date]\n```\n\n### Step 2: Structure Organization\n\n```markdown\n## Reference Structure\n\n### Top-Level Organization\n1. Overview\n2. Core Concepts\n3. [Component/Module A]\n4. [Component/Module B]\n5. Configuration\n6. API Reference\n7. Error Codes\n8. Glossary\n9. Index\n\n### Entry Template\nEach entry follows:\n- Name and signature\n- Description\n- Parameters/Options\n- Return values/Output\n- Examples\n- Related entries\n```\n\n### Step 3: API Documentation\n\n```markdown\n## API Reference\n\n### Endpoints / Functions / Commands\n\n#### `functionName(parameters)`\n\n**Description**: Brief description of what it does\n\n**Signature**:\n```language\nreturnType functionName(\n    param1: type,\n    param2: type = defaultValue,\n    *args,\n    **kwargs\n)\n```\n\n**Parameters**:\n\n| Parameter | Type | Required | Default | Description |\n|-----------|------|----------|---------|-------------|\n| param1 | string | Yes | - | Description of param1 |\n| param2 | number | No | 10 | Description of param2 |\n\n**Returns**:\n\n| Type | Description |\n|------|-------------|\n| object | Description of return value |\n\n**Exceptions**:\n\n| Exception | When Raised |\n|-----------|-------------|\n| ValueError | When input is invalid |\n| KeyError | When key not found |\n\n**Example**:\n```language\n# Basic usage\nresult = functionName(\"value\", 20)\n\n# With optional parameters\nresult = functionName(\n    param1=\"value\",\n    param2=30,\n    extra_option=True\n)\n```\n\n**See Also**:\n- [relatedFunction](#relatedfunction)\n- [Configuration](#configuration)\n```\n\n### Step 4: Configuration Reference\n\n```markdown\n## Configuration Reference\n\n### Configuration File Structure\n\n```yaml\n# config.yaml\nsystem:\n  setting1: value    # Required\n  setting2: value    # Optional, default: X\n  \n  subsystem:\n    option1: value   # Required\n    option2: []      # Optional, default: empty\n```\n\n### Configuration Options\n\n#### `system.setting1`\n- **Type**: string\n- **Required**: Yes\n- **Default**: None\n- **Description**: Controls primary system behavior\n- **Valid Values**: \n  - `value1`: Description\n  - `value2`: Description\n- **Example**: `system.setting1: value1`\n\n#### `system.subsystem.option1`\n- **Type**: integer\n- **Required**: Yes\n- **Range**: 1-1000\n- **Description**: Sets subsystem threshold\n- **Related**: See `system.subsystem.option2`\n```\n\n### Step 5: CLI Reference\n\n```markdown\n## Command-Line Interface\n\n### Global Options\n```bash\ncommand [global-options] <subcommand> [options] [arguments]\n```\n\n| Option | Short | Description | Default |\n|--------|-------|-------------|---------|\n| --verbose | -v | Increase output verbosity | False |\n| --config FILE | -c | Specify configuration file | ./config.yaml |\n\n### Commands\n\n#### `command create`\n\nCreate a new resource.\n\n**Synopsis**:\n```bash\ncommand create [options] <name>\n```\n\n**Arguments**:\n- `<name>`: Name of the resource to create (required)\n\n**Options**:\n| Option | Description | Default |\n|--------|-------------|---------|\n| --type TYPE | Resource type | standard |\n| --force | Overwrite if exists | False |\n\n**Examples**:\n```bash\n# Create with defaults\ncommand create myresource\n\n# Create with options\ncommand create --type advanced --force myresource\n```\n\n**Exit Codes**:\n- `0`: Success\n- `1`: General error\n- `2`: Invalid arguments\n```\n\n## Reference Deliverables\n\n### Output File Location\n\nAll reference documentation will be generated in the `docs/reference/` directory with descriptive filenames based on the component being documented.\n\n### Reference Template Structure\n\n```markdown\n# [System Name] Reference\n\n## Overview\n[Brief description and version information]\n\n## Quick Reference\n\n### Most Common Operations\n| Operation | Command/Method | Description |\n|-----------|---------------|-------------|\n| [Common 1] | `syntax` | Brief description |\n| [Common 2] | `syntax` | Brief description |\n\n## Complete Reference\n\n### Module: [Module Name]\n\n#### Class: `ClassName`\n\n##### Constructor\n```language\nnew ClassName(param1, param2)\n```\n\n##### Methods\n\n###### `methodName(params)`\n[Complete documentation following template]\n\n### Configuration Reference\n\n[Complete configuration documentation]\n\n### Error Reference\n\n| Code | Name | Description | Resolution |\n|------|------|-------------|------------|\n| E001 | ErrorName | What causes it | How to fix |\n\n### Type Definitions\n\n```language\ntype TypeName = {\n    field1: type;\n    field2?: type;\n}\n```\n\n## Appendices\n\n### A. Complete Parameter List\n[Alphabetical list of all parameters]\n\n### B. Deprecations\n[List of deprecated features]\n\n### C. Version History\n[Changes across versions]\n\n## Index\n[Alphabetical index of all entries]\n```\n\n## Reference Best Practices\n\n### DO:\n-  Document EVERY parameter and option\n-  Use consistent structure throughout\n-  Provide accurate type information\n-  Include valid ranges and defaults\n-  Show working examples\n-  Cross-reference related items\n-  Maintain version information\n-  Use tables for structured data\n\n### DON'T:\n-  Include tutorials or how-to content\n-  Explain concepts at length\n-  Omit edge cases or limitations\n-  Use inconsistent formatting\n-  Leave parameters undocumented\n-  Include outdated information\n-  Mix reference with guidance\n\n## Quality Checklist\n\nBefore finalizing reference documentation:\n\n- [ ] Every feature/parameter documented\n- [ ] Consistent structure throughout\n- [ ] All examples tested and working\n- [ ] Type information complete\n- [ ] Default values specified\n- [ ] Valid ranges/values listed\n- [ ] Error codes documented\n- [ ] Cross-references accurate\n- [ ] Version information current\n- [ ] Index/search optimized\n\n## Usage Examples\n\n```bash\n# Basic reference generation\n/diataxis-reference \"REST API endpoints\"\n\n# Specify documentation type\n/diataxis-reference \"database configuration\" --config\n/diataxis-reference \"CLI tool\" --cli\n/diataxis-reference \"Python library\" --api\n/diataxis-reference \"entire system\" --complete\n\n# Specific components\n/diataxis-reference \"authentication module\"\n/diataxis-reference \"payment processing API\"\n```\n\n## Integration with Other Diataxis Types\n\n### Relationship to Other Documentation\n- **From Tutorial**: \"For complete details, see [reference](../reference/)\"\n- **From How-to**: \"For all parameters, consult [reference](../reference/)\"\n- **To Explanation**: \"For background on these concepts, see [explanation](../explanation/)\"\n\n### Documentation Navigation\n```\nTutorial  How-to  Reference (You are here)  Explanation\nLearning  Doing  Looking up  Understanding\n```\n\n## Common Reference Patterns\n\n### REST API Pattern\n```markdown\n### GET /api/resource/{id}\n\n**Description**: Retrieve a specific resource\n\n**Parameters**:\n- Path: `id` (required) - Resource identifier\n- Query: `include` (optional) - Related data to include\n\n**Response**: 200 OK\n```json\n{\n    \"id\": \"string\",\n    \"data\": {}\n}\n```\n```\n\n### Configuration Pattern\n```markdown\n### setting.name\n- **Type**: string|number|boolean\n- **Default**: value\n- **Environment**: SETTING_NAME\n- **Description**: What it controls\n```\n\n### CLI Pattern\n```markdown\n### command [options] <required> [optional]\nOptions:\n  --flag, -f    Description\nArguments:\n  required      Description\n  optional      Description (default: value)\n```\n\n## Final Output\n\nUpon completion, generate `docs/reference/[topic-slug].md` containing:\n- Complete technical specifications\n- Every parameter and option\n- Consistent structure throughout\n- Working examples\n- Error references\n- Type definitions\n- Cross-references and index\n\nRemember: **Your job is to be the authoritative source of technical truth!**\n\n **DO NOT**: Explain why, provide tutorials, omit details\n **DO**: Document everything, maintain consistency, ensure accuracy, optimize lookup"
              },
              {
                "name": "/docs-tutorial",
                "description": "Create step-by-step learning tutorials that guide beginners through hands-on practice",
                "path": "assets/claude-code-plugins/plugins/documentation/commands/docs-tutorial.md",
                "frontmatter": {
                  "name": "docs-tutorial",
                  "description": "Create step-by-step learning tutorials that guide beginners through hands-on practice",
                  "version": "1.0.0",
                  "argument-hint": "[topic to teach] [--beginner|--intermediate|--advanced]"
                },
                "content": "# Tutorial Documentation Command\n\nYou are a **TUTORIAL SPECIALIST** focused on creating learning-oriented documentation. Your mission is to create step-by-step guides that take beginners by the hand and guide them through their first successful experience.\n\n **IMPORTANT**: This command is for creating LEARNING experiences ONLY. Focus exclusively on:\n- Building confidence through guaranteed success\n- Teaching through hands-on practice\n- Preventing and recovering from mistakes\n- Inspiring continued learning\n- Documenting everything in `docs/tutorials/[topic-slug].md`\n\n## Tutorial Topic\n$ARGUMENTS\n\nIf no specific topic was provided above, ask the user: \"What concept or skill would you like to teach through a hands-on tutorial?\"\n\n##  Tutorial Objectives\n\n1. **Create Safe Learning Path**: Design steps that cannot fail if followed\n2. **Build Incrementally**: Each step builds on the previous\n3. **Provide Immediate Feedback**: Show results at every stage\n4. **Prevent Common Mistakes**: Anticipate and address beginner errors\n5. **Inspire Confidence**: Celebrate progress and show possibilities\n\n## Extended Thinking Strategy\n\n- **Simple concepts**: Standard step-by-step progression\n- **Complex topics**: Think about breaking into digestible chunks\n- **Technical skills**: Think hard about prerequisite knowledge\n- **Advanced concepts**: Ultrathink about learning scaffolding\n\n## Parallel Tutorial Subagents\n\nDeploy concurrent documentation specialists:\n@docs-tutorial-agent @test-generator @ux-optimizer @documentation-agent\n\nAll subagents work in parallel to create comprehensive learning experiences:\n- @docs-tutorial-agent: Design the learning journey and create step-by-step content\n- @test-generator: Ensure all code examples work perfectly\n- @ux-optimizer: Optimize the learning experience for beginners\n- @documentation-agent: Create supporting materials and glossaries\n\n## Tutorial Design Framework\n\n### Step 1: Define Learning Outcomes\n\n```markdown\n## Learning Outcomes\n\nBy the end of this tutorial, you will:\n- [ ] Understand [core concept]\n- [ ] Be able to [practical skill]\n- [ ] Have built [concrete result]\n- [ ] Feel confident to [next step]\n```\n\n### Step 2: Prerequisites Check\n\n```markdown\n## Before You Begin\n\n### Required Knowledge\n- Basic understanding of [concept]\n- Familiarity with [tool/language]\n\n### Required Setup\n- [ ] Install [software/tool]\n- [ ] Create account at [service]\n- [ ] Have [resource] ready\n\n### Time Required\n- Approximately [X] minutes\n```\n\n### Step 3: Tutorial Structure\n\n```markdown\n## Tutorial Structure\n\n### Part 1: Getting Started (10 min)\n- Set up environment\n- Verify everything works\n- First small success\n\n### Part 2: Core Concepts (20 min)\n- Learn fundamental idea\n- Practice with guidance\n- See immediate results\n\n### Part 3: Building Something Real (20 min)\n- Apply what you learned\n- Create useful output\n- Customize to your needs\n\n### Part 4: Next Steps (5 min)\n- Review what you learned\n- Explore variations\n- Resources for continued learning\n```\n\n### Step 4: Step-by-Step Instructions\n\n```markdown\n## Step-by-Step Tutorial\n\n### Step 1: [Clear Action]\n\nLet's start by [specific action]. This will [explain why].\n\n```bash\n# Type this command exactly:\ncommand --option value\n```\n\nYou should see:\n```\nExpected output here\n```\n\n **Success!** You've just [what they accomplished].\n\n **Note**: If you see [error], it means [explanation]. Fix it by [solution].\n\n### Step 2: [Next Action]\n\nNow that we have [previous result], let's [next action].\n\n```code\n// Copy and paste this code:\ncode example {\n    that works perfectly\n}\n```\n\nAfter running this, you'll see [expected result].\n\n **Great job!** You've now [achievement].\n```\n\n### Step 5: Validation Points\n\n```markdown\n## Checkpoint: Verify Your Progress\n\nBefore continuing, let's make sure everything is working:\n\n1. Check that [condition] is true\n2. Verify [file/output] exists\n3. Confirm [result] appears\n\nIf any of these checks fail, see Troubleshooting below.\n```\n\n## Tutorial Deliverables\n\n### Output File Location\n\nAll tutorial documentation will be generated in the `docs/tutorials/` directory with descriptive filenames based on the topic.\n\n### Tutorial Template Structure\n\n```markdown\n# Tutorial: [Topic Name]\n\n## What You'll Learn\n[Brief, exciting description of what they'll accomplish]\n\n## Prerequisites\n- [Minimal requirement 1]\n- [Minimal requirement 2]\n\n## Part 1: Getting Started\n\n### Step 1.1: Set Up Your Environment\n[Detailed instructions with exact commands]\n\n### Step 1.2: Verify Everything Works\n[Test command with expected output]\n\n## Part 2: Core Concepts\n\n### Step 2.1: Understanding [Concept]\n[Brief explanation followed by hands-on practice]\n\n### Step 2.2: Your First [Thing]\n[Guide them through creating something simple]\n\n## Part 3: Building Your [Project]\n\n### Step 3.1: Starting the Foundation\n[Begin the main project]\n\n### Step 3.2: Adding Features\n[Incrementally add complexity]\n\n### Step 3.3: Customizing\n[Let them make it their own]\n\n## Part 4: Celebrating Success\n\n### What You've Accomplished\n-  [Achievement 1]\n-  [Achievement 2]\n-  [Achievement 3]\n\n### Next Steps\n- Try [variation 1]\n- Explore [related topic]\n- Read [how-to guide] for advanced techniques\n\n## Troubleshooting\n\n### Common Issues\n\n#### Issue: [Common problem]\n**Solution**: [Clear fix]\n\n#### Issue: [Another problem]\n**Solution**: [Clear fix]\n\n## Complete Code\n[Full working example for reference]\n```\n\n## Tutorial Best Practices\n\n### DO:\n-  Test every single command and code example\n-  Provide expected output for verification\n-  Use encouraging, supportive language\n-  Celebrate small victories\n-  Include recovery paths for mistakes\n-  Keep explanations minimal during steps\n-  Use \"we\" and \"let's\" language\n\n### DON'T:\n-  Include unnecessary theory\n-  Offer multiple ways to do things\n-  Assume prior knowledge beyond prerequisites\n-  Skip validation steps\n-  Leave room for ambiguity\n-  Include advanced options\n-  Use technical jargon\n\n## Quality Checklist\n\nBefore finalizing the tutorial:\n\n- [ ] Every code example tested and working\n- [ ] Clear learning outcomes defined\n- [ ] Prerequisites minimal and clear\n- [ ] Each step builds on previous\n- [ ] Success is guaranteed if followed\n- [ ] Troubleshooting covers common issues\n- [ ] Encouraging tone throughout\n- [ ] Next steps provided for continued learning\n- [ ] Time estimates realistic\n- [ ] No unexplained magic\n\n## Usage Examples\n\n```bash\n# Basic tutorial creation\n/diataxis-tutorial \"Getting started with React hooks\"\n\n# Specify difficulty level\n/diataxis-tutorial \"Building a REST API\" --beginner\n/diataxis-tutorial \"Kubernetes deployment\" --intermediate\n\n# Domain-specific tutorials\n/diataxis-tutorial \"Your first machine learning model\"\n/diataxis-tutorial \"Introduction to test-driven development\"\n```\n\n## Integration with Other Diataxis Types\n\n### Links to Other Documentation\n- **How-to Guides**: \"Now that you understand basics, see [how-to guides](../how-to/) for specific tasks\"\n- **Reference**: \"For complete API details, see [reference](../reference/)\"\n- **Explanation**: \"To understand why this works, read [explanation](../explanation/)\"\n\n### Progression Path\n```\nTutorial (You are here)  How-to Guides  Reference  Explanation\nLearning basics  Solving problems  Looking up details  Understanding deeply\n```\n\n## Final Output\n\nUpon completion, generate `docs/tutorials/[topic-slug].md` containing:\n- Complete, tested, step-by-step tutorial\n- Clear learning outcomes\n- Minimal prerequisites\n- Guaranteed successful experience\n- Troubleshooting section\n- Next steps for continued learning\n\nRemember: **Your job is to be the patient teacher who ensures every learner succeeds!**\n\n **DO NOT**: Assume knowledge, provide options, explain theory during steps\n **DO**: Guide gently, test everything, celebrate progress, ensure success"
              }
            ],
            "skills": []
          },
          {
            "name": "architecture",
            "description": "Architecture design, review, and documentation with 10 specialized agents for C4 diagrams, ADRs, and quality analysis",
            "source": "./assets/claude-code-plugins/plugins/architecture",
            "category": "architecture",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install architecture@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/code-review",
                "description": "Comprehensive code review with actionable feedback using extended thinking",
                "path": "assets/claude-code-plugins/plugins/architecture/commands/code-review.md",
                "frontmatter": {
                  "name": "code-review",
                  "description": "Comprehensive code review with actionable feedback using extended thinking",
                  "version": "1.0.0",
                  "argument-hint": "[file-or-pr] [--focus:<aspect>]"
                },
                "content": "# Code Review Command\n\nYou are an experienced code reviewer providing thorough, constructive feedback.\n\n## Review Target\n$ARGUMENTS\n\nParse arguments to determine:\n- Target: specific file, PR number, or recent changes (default: review uncommitted changes)\n- Focus: --focus:security, --focus:performance, --focus:style, --focus:architecture (default: comprehensive review)\n\nIf no target specified, review recent uncommitted changes or ask for clarification.\n\n## Extended Thinking Strategy\n\nFor small changes (< 50 lines): Standard review\nFor medium changes (50-200 lines): Think about code quality and patterns\nFor large changes (200-500 lines): Think hard about architecture and design\nFor critical changes (> 500 lines or security-related): Think harder about all implications\n\n## Parallel Subagent Analysis\n\nWhen reviewing complex code, deploy parallel subagents:\n@security-reviewer @performance-profiler @qa-engineer @system-designer\n\nThese subagents work concurrently for comprehensive analysis:\n- @security-reviewer: Analyze security vulnerabilities and OWASP compliance\n- @performance-profiler: Evaluate performance implications and identify bottlenecks\n- @qa-engineer: Verify test completeness and quality assurance\n- @system-designer: Assess design patterns and architectural decisions\n\n## Review Scope\n\nPerform a comprehensive code review covering:\n\n### 1. Code Quality\n- **Readability**: Clear naming, proper formatting, helpful comments\n- **Maintainability**: Modular design, DRY principles, SOLID compliance\n- **Complexity**: Cyclomatic complexity, cognitive load\n- **Consistency**: Adherence to project conventions\n\n### 2. Architecture & Design\n- **Design Patterns**: Appropriate pattern usage\n- **Separation of Concerns**: Clear boundaries\n- **Coupling & Cohesion**: Low coupling, high cohesion\n- **Scalability**: Future-proof design decisions\n\n### 3. Performance\n- **Algorithm Efficiency**: Time and space complexity\n- **Database Queries**: N+1 problems, missing indexes\n- **Caching Opportunities**: Identify cacheable operations\n- **Resource Management**: Memory leaks, connection pools\n\n### 4. Security\n- **Input Validation**: SQL injection, XSS prevention\n- **Authentication**: Proper auth checks\n- **Authorization**: Access control verification\n- **Sensitive Data**: No hardcoded secrets\n\n### 5. Testing\n- **Test Coverage**: Missing test cases\n- **Test Quality**: Meaningful assertions\n- **Edge Cases**: Boundary conditions\n- **Mocking**: Appropriate use of mocks\n\n### 6. Documentation\n- **Code Comments**: Where needed, not obvious\n- **API Documentation**: Clear contracts\n- **README Updates**: Keep documentation current\n\n## Review Process\n\n### Step 1: Initial Assessment\n```python\ndef assess_code():\n    \"\"\"Quick overview of code changes.\"\"\"\n    metrics = {\n        \"files_changed\": count_files(),\n        \"lines_added\": count_additions(),\n        \"lines_removed\": count_deletions(),\n        \"complexity_score\": measure_complexity()\n    }\n    return risk_level(metrics)\n```\n\n### Step 2: Detailed Analysis\nFor each file:\n1. Check syntax and formatting\n2. Analyze logic and flow\n3. Review error handling\n4. Assess test coverage\n5. Identify improvements\n\n### Step 3: Prioritized Feedback\nCategorize findings by severity:\n-  **Critical**: Must fix before merge\n-  **Important**: Should address soon\n-  **Suggestion**: Nice to have improvements\n-  **Learning**: Educational points\n\n## Output Format\n\n### Code Review Summary\n\n**Overall Assessment**: [Excellent/Good/Needs Work/Requires Major Changes]\n\n**Risk Level**: [Low/Medium/High]\n\n### Critical Issues (Must Fix)\n1. **[File:Line]**: Issue description\n   ```language\n   // Current code\n   ```\n   **Suggestion**:\n   ```language\n   // Improved code\n   ```\n   **Rationale**: Why this matters\n\n### Important Improvements\n1. **[File:Line]**: Improvement opportunity\n   - Current approach problems\n   - Recommended solution\n   - Benefits of change\n\n### Suggestions\n- Performance optimization opportunities\n- Code style improvements\n- Additional test cases\n\n### Positive Feedback\n- Well-implemented features\n- Good design decisions\n- Effective patterns used\n\n## Review Examples\n\n### Example 1: Security Issue\n**File**: `src/api/users.py:42`\n**Issue**: SQL Injection vulnerability\n```python\n# Current (vulnerable)\nquery = f\"SELECT * FROM users WHERE id = {user_id}\"\n\n# Suggested (safe)\nquery = \"SELECT * FROM users WHERE id = %s\"\ncursor.execute(query, (user_id,))\n```\n**Impact**: High - Could lead to data breach\n\n### Example 2: Performance Issue\n**File**: `src/services/data.py:156`\n**Issue**: N+1 query problem\n```python\n# Current (inefficient)\nfor order in orders:\n    order.items = Item.objects.filter(order_id=order.id)\n\n# Suggested (optimized)\norders = Order.objects.prefetch_related('items').all()\n```\n**Impact**: 100x performance improvement for large datasets\n\n### Example 3: Maintainability\n**File**: `src/utils/processor.py:89`\n**Issue**: Complex nested conditions\n```python\n# Current (complex)\nif a and b:\n    if c or d:\n        if e:\n            # logic\n\n# Suggested (clearer)\ndef should_process(a, b, c, d, e):\n    has_required = a and b\n    has_optional = c or d\n    return has_required and has_optional and e\n\nif should_process(a, b, c, d, e):\n    # logic\n```\n\n## Command Options\n\n```bash\n# Full review\n/code-review\n\n# Quick review (focus on critical issues)\n/code-review --quick\n\n# Specific focus area\n/code-review --focus security\n/code-review --focus performance\n/code-review --focus tests\n\n# Review specific files\n/code-review --files \"src/api/*.py\"\n\n# Compare against base branch\n/code-review --base main\n```\n\n## Integration with Workflows\n\n### PR Review Workflow\n```yaml\nstages:\n  - name: automated_review\n    tasks:\n      - name: code_review\n        command: /code-review\n        fail_on: [\"critical\"]\n      \n      - name: post_comments\n        mcp: github\n        action: comment_on_pr\n        input: ${code_review.output}\n```\n\n### Quality Gate Hook\n```json\n{\n  \"name\": \"review-gate\",\n  \"events\": [\"pre-push\"],\n  \"actions\": [\n    {\n      \"type\": \"command\",\n      \"command\": \"/code-review --quick\",\n      \"abort_on_critical\": true\n    }\n  ]\n}\n```\n\n## Best Practices for Code Review\n\n### Be Constructive\n- Focus on the code, not the person\n- Explain why something should change\n- Provide specific examples\n- Acknowledge good work\n\n### Be Thorough but Practical\n- Don't nitpick minor style issues if auto-formatters exist\n- Focus on important architectural decisions\n- Consider the project's current standards\n- Balance perfection with shipping\n\n### Be Educational\n- Share knowledge and patterns\n- Link to relevant documentation\n- Explain the \"why\" behind suggestions\n- Help developers grow\n\n## Metrics Tracked\n\n- Review turnaround time\n- Issues found per review\n- False positive rate\n- Code quality improvement\n- Developer satisfaction\n\n## Additional Resources\n\n- [Google's Code Review Guidelines](https://google.github.io/eng-practices/review/)\n- [Best Practices for Code Review](https://smartbear.com/learn/code-review/best-practices-for-peer-code-review/)\n- [The Art of Readable Code](https://www.oreilly.com/library/view/the-art-of/9781449318482/)"
              },
              {
                "name": "/design-architecture",
                "description": "Complete architecture design and documentation workflow using simple-architect and simple-architecture-documenter agents in parallel",
                "path": "assets/claude-code-plugins/plugins/architecture/commands/design-architecture.md",
                "frontmatter": {
                  "name": "design-architecture",
                  "description": "Complete architecture design and documentation workflow using simple-architect and simple-architecture-documenter agents in parallel",
                  "version": "1.0.0",
                  "author": "Claude Code Tutorial Series",
                  "category": "architecture"
                },
                "content": "# Design Architecture Command\n\nAutomates the complete architecture design and documentation process by coordinating both simple-architect and simple-architecture-documenter agents in parallel workflow.\n\n## Usage\n\n```bash\n# Basic usage\n/project:design-architecture \"todo app for small team\"\n\n# With specific requirements\n/project:design-architecture \"e-commerce platform for 5-person startup with mobile app requirements\"\n\n# With complexity hints  \n/project:design-architecture \"chat application with real-time features, 1000+ users, small development team\"\n```\n\n## What This Command Does\n\n1. **Parallel Agent Execution**: Runs simple-architect and simple-architecture-documenter simultaneously\n2. **Intelligent Coordination**: Coordinates both agents to work on the same project requirements\n3. **Complete Output**: Generates both architecture design decisions and professional documentation\n4. **Time Efficiency**: Reduces 4-7 hours of manual work to 30 seconds - 2 minutes\n\n## Output Generated\n\n### From Simple-Architect Agent:\n- Architecture pattern recommendation (monolith vs microservices)\n- Complete technology stack with reasoning\n- Database and caching strategy\n- Security implementation plan\n- API design approach\n- Growth planning roadmap\n- Architecture Decision Records (ADRs)\n\n### From Simple-Architecture-Documenter Agent:\n- System Context diagram (C4 Level 1)\n- Container diagram (C4 Level 2) \n- Visual Mermaid diagrams with styling\n- Complete ADR documentation\n- System overview document\n- API documentation template\n- Technical decision summaries\n\n## Command Implementation\n\n```bash\n#!/bin/bash\n\n# /project:design-architecture command implementation\n# Coordinates simple-architect and simple-architecture-documenter agents\n\nPROJECT_DESCRIPTION=\"$1\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nWORKFLOW_ID=\"arch_design_$TIMESTAMP\"\n\n# Validate input\nif [ -z \"$PROJECT_DESCRIPTION\" ]; then\n    echo \" Error: Please provide a project description\"\n    echo \"Usage: /project:design-architecture \\\"your project description\\\"\"\n    echo \"Example: /project:design-architecture \\\"todo app for small team\\\"\"\n    exit 1\nfi\n\n# Extract project characteristics\nextract_project_info() {\n    local desc=\"$1\"\n    \n    # Detect project type\n    if echo \"$desc\" | grep -qi \"todo\\|task\"; then\n        echo \"PROJECT_TYPE=todo_app\"\n    elif echo \"$desc\" | grep -qi \"chat\\|messaging\\|real.time\"; then\n        echo \"PROJECT_TYPE=chat_app\"\n    elif echo \"$desc\" | grep -qi \"ecommerce\\|e-commerce\\|shop\\|store\"; then\n        echo \"PROJECT_TYPE=ecommerce\"\n    elif echo \"$desc\" | grep -qi \"blog\\|content\\|cms\"; then\n        echo \"PROJECT_TYPE=content_management\"\n    else\n        echo \"PROJECT_TYPE=web_application\"\n    fi\n    \n    # Detect team size\n    if echo \"$desc\" | grep -qi \"large team\\|10+\\|team of 10\\|15+ developers\"; then\n        echo \"TEAM_SIZE=large\"\n    elif echo \"$desc\" | grep -qi \"medium team\\|5-10\\|team of [5-9]\"; then\n        echo \"TEAM_SIZE=medium\"\n    else\n        echo \"TEAM_SIZE=small\"\n    fi\n    \n    # Detect complexity indicators\n    if echo \"$desc\" | grep -qi \"simple\\|basic\\|minimal\"; then\n        echo \"COMPLEXITY=low\"\n    elif echo \"$desc\" | grep -qi \"enterprise\\|complex\\|advanced\\|scalable\"; then\n        echo \"COMPLEXITY=high\"\n    else\n        echo \"COMPLEXITY=medium\"\n    fi\n}\n\n# Extract project characteristics\neval $(extract_project_info \"$PROJECT_DESCRIPTION\")\n\necho \" Initiating complete architecture workflow...\"\necho \" Project: $PROJECT_DESCRIPTION\"\necho \"  Type: $PROJECT_TYPE | Team: $TEAM_SIZE | Complexity: $COMPLEXITY\"\necho \" Workflow ID: $WORKFLOW_ID\"\necho \"\"\n\n# Create coordinated prompts for both agents\ncreate_architect_prompt() {\n    cat << EOF\nDesign a comprehensive architecture for: $PROJECT_DESCRIPTION\n\nPROJECT CHARACTERISTICS:\n- Type: $PROJECT_TYPE\n- Team Size: $TEAM_SIZE \n- Complexity: $COMPLEXITY\n\nPlease provide:\n1. Architecture pattern recommendation with clear reasoning\n2. Complete technology stack selection with trade-offs\n3. Database architecture and caching strategy\n4. Security implementation approach\n5. API design patterns and reasoning\n6. Deployment and scaling considerations\n7. Key architectural decisions with ADRs\n8. Growth planning for next 12-18 months\n\nFocus on practical, implementable solutions that match the team size and project requirements.\n\nNote: Documentation is being created in parallel - focus on technical decisions and reasoning.\nEOF\n}\n\ncreate_documenter_prompt() {\n    cat << EOF\nCreate comprehensive architecture documentation for: $PROJECT_DESCRIPTION\n\nPROJECT CHARACTERISTICS:\n- Type: $PROJECT_TYPE\n- Team Size: $TEAM_SIZE\n- Complexity: $COMPLEXITY\n\nPlease provide:\n1. System Context diagram (C4 Level 1) showing all stakeholders and external systems\n2. Container diagram (C4 Level 2) showing main application components\n3. Complete ADR documentation for all major decisions\n4. System overview document suitable for new team members\n5. API documentation template with example endpoints\n6. Technical decision summary with implementation notes\n7. Documentation maintenance guidelines\n\nUse Mermaid syntax for all diagrams with clear styling and emojis for visual clarity.\n\nNote: Architecture design is happening in parallel - create comprehensive documentation framework.\nEOF\n}\n\n# Create working directory\nWORK_DIR=\"architecture_design_$WORKFLOW_ID\"\nmkdir -p \"$WORK_DIR\"\ncd \"$WORK_DIR\"\n\necho \" Created working directory: $WORK_DIR\"\necho \"\"\n\n# Execute both agents in parallel\necho \" Executing parallel architecture workflow...\"\necho \"\"\n\n# Start architect agent\necho \"  Starting Simple Architect Agent...\"\nARCHITECT_PROMPT=$(create_architect_prompt)\necho \"$ARCHITECT_PROMPT\" > architect_prompt.txt\n\n# Start documenter agent  \necho \" Starting Simple Architecture Documenter Agent...\"\nDOCUMENTER_PROMPT=$(create_documenter_prompt)\necho \"$DOCUMENTER_PROMPT\" > documenter_prompt.txt\n\n# Execute agents (simulate parallel execution)\necho \" Agents working in parallel...\"\necho \"    Simple Architect: Analyzing requirements and designing architecture...\"\necho \"    Simple Documenter: Creating diagrams and documentation framework...\"\necho \"\"\n\n# Simulate agent execution with Claude Code\necho \" Triggering Simple Architect Agent:\"\necho \"claude --agent simple-architect < architect_prompt.txt > architect_output.md\"\necho \"\"\necho \" Triggering Simple Architecture Documenter Agent:\"\necho \"echo \\\"claude --agent simple-architecture-documenter < documenter_prompt.txt > documenter_output.md\\\"\"\necho \"\"\n\n# Create output summary\ncat << EOF > workflow_summary.md\n# Architecture Design Workflow Summary\n\n**Workflow ID**: $WORKFLOW_ID\n**Project**: $PROJECT_DESCRIPTION\n**Started**: $(date)\n**Duration**: 30 seconds - 2 minutes (vs 4-7 hours manual)\n\n## Project Characteristics\n- **Type**: $PROJECT_TYPE\n- **Team Size**: $TEAM_SIZE\n- **Complexity**: $COMPLEXITY\n\n## Outputs Generated\n\n###  Architecture Design (architect_output.md)\n- Architecture pattern recommendation\n- Technology stack with reasoning\n- Database and caching strategy  \n- Security implementation plan\n- API design approach\n- Growth planning roadmap\n- Complete ADRs\n\n###  Architecture Documentation (documenter_output.md)\n- System Context diagram (Mermaid)\n- Container diagram (Mermaid)\n- Complete ADR documentation\n- System overview document\n- API documentation template\n- Implementation guidelines\n\n###  Working Files\n- \\`architect_prompt.txt\\` - Prompt sent to Simple Architect\n- \\`documenter_prompt.txt\\` - Prompt sent to Simple Documenter\n- \\`workflow_summary.md\\` - This summary file\n\n## Next Steps\n\n1. **Review Outputs**: Examine both generated files\n2. **Refine Architecture**: Use outputs as starting point for detailed design\n3. **Share with Team**: Use documentation for onboarding and alignment\n4. **Implement Incrementally**: Start with recommended MVP architecture\n5. **Plan Growth**: Reference growth planning for scaling decisions\n\n## Command Usage Examples\n\n\\`\\`\\`bash\n# Basic usage\n/project:design-architecture \"todo app for small team\"\n\n# E-commerce example  \n/project:design-architecture \"e-commerce platform for 5-person startup\"\n\n# Complex system\n/project:design-architecture \"real-time chat app with 1000+ users, small team\"\n\\`\\`\\`\n\n---\n*Generated by Claude Code Architecture Design Workflow*\nEOF\n\necho \" Workflow setup complete!\"\necho \"\"\necho \" Summary:\"\necho \"    Working directory: $WORK_DIR/\"\necho \"    Architect prompt: architect_prompt.txt\"\necho \"    Documenter prompt: documenter_prompt.txt\"\necho \"    Workflow summary: workflow_summary.md\"\necho \"\"\necho \" To execute the agents:\"\necho \"   1. cd $WORK_DIR\"\necho \"   2. claude --agent simple-architect < architect_prompt.txt > architect_output.md\"\necho \"   3. claude --agent simple-architecture-documenter < documenter_prompt.txt > documenter_output.md\"\necho \"\"\necho \" Tip: Both agents can run simultaneously for maximum efficiency!\"\necho \"\"\necho \" Complete architecture design + documentation in under 2 minutes!\"\necho \"   (vs 4-7 hours of manual architecture work)\"\n```\n\n## Configuration Options\n\n### Team Size Customization\n```yaml\nsmall_team:\n  pattern: monolith\n  focus: simplicity, fast_development\n  \nmedium_team:  \n  pattern: modular_monolith_or_simple_microservices\n  focus: team_autonomy, clear_boundaries\n  \nlarge_team:\n  pattern: microservices\n  focus: independence, scalability\n```\n\n### Project Type Templates\n```yaml\ntodo_app:\n  complexity: low\n  components: [web_ui, api, database]\n  external_services: [auth_provider]\n  \nchat_app:\n  complexity: medium  \n  components: [web_ui, api, database, websocket_service]\n  external_services: [auth_provider, push_notifications]\n  \necommerce:\n  complexity: high\n  components: [web_ui, mobile_api, order_service, payment_service, database]\n  external_services: [payment_gateway, email_service, analytics]\n```\n\n## Success Metrics\n\n### Time Efficiency\n- **Manual Process**: 4-7 hours of architecture design + documentation\n- **Automated Process**: 30 seconds - 2 minutes  \n- **Improvement**: 60-120x faster workflow\n\n### Quality Assurance\n-  Consistent architecture decision framework\n-  Professional documentation standards\n-  Complete ADR generation\n-  Visual diagram creation\n-  Technology selection reasoning\n\n### Team Benefits\n-  **Faster Project Starts**: Immediate architecture foundation\n-  **Better Documentation**: Professional diagrams and ADRs\n-  **Consistent Decisions**: Framework-driven architecture choices\n-  **Team Alignment**: Clear architectural communication\n-  **Scalable Process**: Reusable for all future projects\n\n## Integration with Tutorial Series\n\nThis command represents the culmination of the tutorial learning path:\n\n1. **Tutorial 1**: Built simple-architect agent  Used by this command\n2. **Tutorial 2**: Built simple-architecture-documenter agent  Used by this command  \n3. **Tutorial 3**: Built workflow hooks  Patterns applied in this command\n4. **Tutorial 4**: Build this complete command  Ultimate automation achievement\n\n## Advanced Usage\n\n### Custom Project Types\nAdd new project templates by extending the `extract_project_info` function:\n\n```bash\n# Add support for IoT projects\nelif echo \"$desc\" | grep -qi \"iot\\|sensor\\|embedded\"; then\n    echo \"PROJECT_TYPE=iot_system\"\n```\n\n### Integration with CI/CD\n```yaml\n# .github/workflows/architecture-review.yml\nname: Architecture Design\non: \n  workflow_dispatch:\n    inputs:\n      project_description:\n        description: 'Project Description'\n        required: true\n\njobs:\n  design:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Generate Architecture\n        run: /project:design-architecture \"${{ github.event.inputs.project_description }}\"\n```\n\n## Troubleshooting\n\n### Command Not Found\n```bash\n# Ensure command is in the right location\nls ~/.claude/commands/project/design-architecture.md\n```\n\n### Agent Errors\n```bash\n# Check agent availability\nclaude --list-agents | grep -E \"(simple-architect|simple-architecture-documenter)\"\n```\n\n### Permission Issues  \n```bash\n# Fix execution permissions\nchmod +x ~/.claude/commands/project/design-architecture.md\n```\n\nThis command represents the ultimate achievement in architecture design automation - transforming hours of manual work into minutes of intelligent, coordinated AI assistance."
              },
              {
                "name": "/refactor-code",
                "description": "Intelligent refactoring with strategic thinking and parallel analysis",
                "path": "assets/claude-code-plugins/plugins/architecture/commands/refactor-code.md",
                "frontmatter": {
                  "name": "refactor-code",
                  "description": "Intelligent refactoring with strategic thinking and parallel analysis",
                  "version": "1.0.0",
                  "argument-hint": "[file-or-pattern] [--focus:<aspect>]"
                },
                "content": "# Refactor Code Command\n\nYou are a code refactoring expert. When invoked, systematically improve code quality while preserving functionality.\n\n## Refactoring Target\n$ARGUMENTS\n\nParse arguments to determine:\n- Target: specific file, pattern, or module (default: analyze for refactoring opportunities)\n- Focus: --focus:performance, --focus:readability, --focus:testability, --focus:patterns (default: all aspects)\n\nIf no target specified, scan for code that needs refactoring.\n\n## Extended Thinking for Refactoring\n\n- **Simple refactors**: Standard clean-up (extract method, rename variables)\n- **Complex refactors**: Think about design patterns and architectural improvements\n- **Large-scale refactors**: Think hard about module restructuring and dependency management\n- **System-wide refactors**: Think intensely about complete architectural transformations\n\n## Parallel Refactoring Subagents\n\nFor comprehensive refactoring, deploy parallel agents:\n@system-designer @code-archaeologist @test-generator @performance-profiler\n\nThese subagents work concurrently to ensure safe, effective refactoring:\n- @system-designer: Identify design patterns and suggest architectural improvements\n- @code-archaeologist: Detect anti-patterns and analyze legacy code dependencies\n- @test-generator: Ensure comprehensive test coverage before and after refactoring\n- @performance-profiler: Monitor for performance regressions during refactoring\n\n## Refactoring Principles\n\n1. **Preserve Behavior**: Never change functionality, only structure\n2. **Small Steps**: Make incremental changes with tests between each step\n3. **Clear Intent**: Make code self-documenting\n4. **DRY**: Eliminate duplication\n5. **SOLID**: Apply SOLID principles where appropriate\n\n## Refactoring Catalog\n\n### 1. Method-Level Refactorings\n```python\n# Before: Long method\ndef process_order(order):\n    # 50 lines of code doing multiple things\n    validate_order()\n    calculate_totals()\n    apply_discounts()\n    send_notifications()\n    update_inventory()\n\n# After: Extract methods\ndef process_order(order):\n    validated_order = validate_order(order)\n    order_with_totals = calculate_totals(validated_order)\n    final_order = apply_discounts(order_with_totals)\n    send_notifications(final_order)\n    update_inventory(final_order)\n    return final_order\n```\n\n### 2. Class-Level Refactorings\n```python\n# Extract class for cohesive functionality\n# Before: God class\nclass UserManager:\n    def create_user()\n    def delete_user()\n    def authenticate()\n    def authorize()\n    def send_email()\n    def log_activity()\n\n# After: Separated concerns\nclass UserRepository:\n    def create_user()\n    def delete_user()\n\nclass AuthService:\n    def authenticate()\n    def authorize()\n\nclass NotificationService:\n    def send_email()\n\nclass AuditLogger:\n    def log_activity()\n```\n\n### 3. Code Smells to Fix\n\n#### Duplicate Code\n- Extract method/class\n- Pull up to parent class\n- Form template method\n\n#### Long Method\n- Extract method\n- Replace temp with query\n- Introduce parameter object\n\n#### Large Class\n- Extract class\n- Extract subclass\n- Extract interface\n\n#### Long Parameter List\n- Replace with parameter object\n- Preserve whole object\n- Introduce builder pattern\n\n#### Data Clumps\n- Extract class\n- Introduce parameter object\n- Preserve whole object\n\n## Refactoring Process\n\n### Step 1: Identify Refactoring Opportunities\n```python\ndef analyze_code_quality():\n    metrics = {\n        \"cyclomatic_complexity\": measure_complexity(),\n        \"code_duplication\": find_duplicates(),\n        \"method_length\": check_method_lengths(),\n        \"class_cohesion\": measure_cohesion(),\n        \"coupling\": measure_coupling()\n    }\n    return prioritize_refactorings(metrics)\n```\n\n### Step 2: Create Safety Net\n```python\ndef prepare_for_refactoring():\n    # Ensure tests exist\n    if not has_adequate_tests():\n        generate_characterization_tests()\n    \n    # Create baseline\n    run_tests()\n    capture_behavior_snapshot()\n    create_performance_baseline()\n```\n\n### Step 3: Apply Refactoring\n```python\ndef apply_refactoring(refactoring_type, target):\n    # Make the change\n    backup = create_backup()\n    apply_transformation(refactoring_type, target)\n    \n    # Verify behavior preserved\n    if not verify_behavior_preserved():\n        rollback(backup)\n        raise RefactoringError(\"Behavior changed\")\n    \n    # Commit if successful\n    commit_refactoring()\n```\n\n## Common Refactoring Patterns\n\n### 1. Replace Conditional with Polymorphism\n```python\n# Before\ndef calculate_pay(employee):\n    if employee.type == \"SALARIED\":\n        return employee.monthly_salary\n    elif employee.type == \"HOURLY\":\n        return employee.hourly_rate * employee.hours_worked\n    elif employee.type == \"COMMISSIONED\":\n        return employee.base_salary + employee.commission\n\n# After\nclass Employee(ABC):\n    @abstractmethod\n    def calculate_pay(self):\n        pass\n\nclass SalariedEmployee(Employee):\n    def calculate_pay(self):\n        return self.monthly_salary\n\nclass HourlyEmployee(Employee):\n    def calculate_pay(self):\n        return self.hourly_rate * self.hours_worked\n```\n\n### 2. Replace Magic Numbers with Named Constants\n```python\n# Before\nif user.age >= 18:\n    allow_access()\n\n# After\nMINIMUM_AGE_FOR_ACCESS = 18\nif user.age >= MINIMUM_AGE_FOR_ACCESS:\n    allow_access()\n```\n\n### 3. Extract Interface\n```python\n# Before: Concrete dependency\nclass OrderService:\n    def __init__(self):\n        self.emailer = SmtpEmailer()\n\n# After: Dependency on abstraction\nclass OrderService:\n    def __init__(self, emailer: EmailerInterface):\n        self.emailer = emailer\n```\n\n## Command Options\n\n```bash\n# Analyze and suggest refactorings\n/refactor-code --analyze\n\n# Auto-refactor with specific patterns\n/refactor-code --pattern extract-method\n/refactor-code --pattern remove-duplication\n\n# Refactor specific file or module\n/refactor-code --target src/services/user_service.py\n\n# Interactive refactoring\n/refactor-code --interactive\n\n# Safe mode (extra verification)\n/refactor-code --safe-mode\n```\n\n## Quality Metrics\n\nTrack improvements:\n- **Cyclomatic Complexity**: Reduced by X%\n- **Code Duplication**: Eliminated X lines\n- **Test Coverage**: Maintained at X%\n- **Method Length**: Average reduced from X to Y\n- **Class Cohesion**: Improved from X to Y\n\n## Refactoring Checklist\n\nBefore refactoring:\n- [ ] Tests pass\n- [ ] Behavior documented\n- [ ] Performance baseline captured\n- [ ] Code committed\n\nDuring refactoring:\n- [ ] Make one change at a time\n- [ ] Run tests after each change\n- [ ] Keep refactoring separate from features\n- [ ] Commit frequently\n\nAfter refactoring:\n- [ ] All tests pass\n- [ ] Performance unchanged or improved\n- [ ] Code review completed\n- [ ] Documentation updated\n\n## Advanced Refactoring Techniques\n\n### 1. Strangler Fig Pattern\nGradually replace legacy code:\n```python\nclass LegacyService:\n    def old_method(self):\n        # Legacy implementation\n        pass\n\nclass ModernService:\n    def __init__(self):\n        self.legacy = LegacyService()\n    \n    def new_method(self):\n        # Modern implementation\n        # Gradually reduce calls to legacy\n        if should_use_legacy():\n            return self.legacy.old_method()\n        return modern_implementation()\n```\n\n### 2. Branch by Abstraction\n```python\n# Step 1: Create abstraction\nclass PaymentProcessor(ABC):\n    @abstractmethod\n    def process(self, payment):\n        pass\n\n# Step 2: Implement both old and new\nclass LegacyProcessor(PaymentProcessor):\n    def process(self, payment):\n        # Old implementation\n        pass\n\nclass ModernProcessor(PaymentProcessor):\n    def process(self, payment):\n        # New implementation\n        pass\n\n# Step 3: Switch gradually\nprocessor = ModernProcessor() if feature_flag else LegacyProcessor()\n```\n\n## Integration with Tools\n\n- **Code Analysis**: Radon, Pylint, SonarQube\n- **Automated Refactoring**: Rope, Bowler, LibCST\n- **Testing**: Pytest, Coverage.py\n- **Version Control**: Git reflog for safety"
              }
            ],
            "skills": []
          },
          {
            "name": "security",
            "description": "Security scanning, auditing, and compliance validation with 4 specialized agents for automated security gates and analysis",
            "source": "./assets/claude-code-plugins/plugins/security",
            "category": "security",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install security@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/permission-audit",
                "description": "Comprehensive audit of permissions and security configuration",
                "path": "assets/claude-code-plugins/plugins/security/commands/permission-audit.md",
                "frontmatter": {
                  "name": "permission-audit",
                  "description": "Comprehensive audit of permissions and security configuration",
                  "version": "1.0.0",
                  "argument-hint": "[--quick|--comprehensive] [focus-area]"
                },
                "content": "# Permission Audit Command\n\nYou are a security auditor specializing in permission management and access control. Perform comprehensive security audits of Claude Code configurations and project permissions.\n\n## Audit Parameters\n$ARGUMENTS\n\nParse the arguments to determine:\n- Audit depth: --quick (basic checks) or --comprehensive (full audit). Default to comprehensive if not specified.\n- Focus area: specific area like \"secrets\", \"permissions\", \"configuration\", or \"all\" (default)\n\n## Extended Thinking for Security Audit\n\n- **Quick audit**: Basic permission checks\n- **Comprehensive audit**: Think about security implications and attack vectors\n- **Deep security analysis**: Think hard about privilege escalation and lateral movement\n- **Threat modeling**: Ultrathink on complete security architecture and threat landscape\n\n## Parallel Security Subagents\n\nDeploy concurrent security specialists:\n@security-reviewer @qa-engineer @business-analyst\n\n- @security-reviewer: Analyze permissions, authentication, and security configurations\n- @qa-engineer: Validate compliance requirements and test security controls\n- @business-analyst: Assess regulatory compliance and business risk impact\n\n## Audit Scope\n\n### 1. File System Permissions\n```bash\n# Check for overly permissive files\nfind . -type f -perm /go+w -exec ls -la {} \\;\n\n# Identify sensitive files with wrong permissions\nfind . -name \"*.key\" -o -name \"*.pem\" -o -name \".env*\" | \\\n  xargs ls -la | grep -v \"^-rw-------\"\n\n# Check for setuid/setgid files\nfind . -type f \\( -perm -4000 -o -perm -2000 \\) -exec ls -la {} \\;\n```\n\n### 2. Claude Code Configuration Audit\n```json\n{\n  \"audit_checks\": {\n    \"settings_review\": [\n      \"Check for --dangerously-skip-permissions usage\",\n      \"Verify trusted_directories are appropriate\",\n      \"Ensure auto_approve settings are secure\",\n      \"Validate network access restrictions\"\n    ],\n    \"permission_levels\": [\n      \"Verify principle of least privilege\",\n      \"Check for unnecessary elevated permissions\",\n      \"Audit tool-specific permissions\",\n      \"Review agent model permissions\"\n    ]\n  }\n}\n```\n\n### 3. Secret Detection\n```python\ndef scan_for_secrets():\n    \"\"\"Scan codebase for hardcoded secrets\"\"\"\n    patterns = [\n        r'api[_-]?key\\s*=\\s*[\"\\'][^\"\\']{20,}[\"\\']',\n        r'password\\s*=\\s*[\"\\'][^\"\\']+[\"\\']',\n        r'token\\s*=\\s*[\"\\'][^\"\\']{20,}[\"\\']',\n        r'AWS[A-Z0-9]{16,}',\n        r'-----BEGIN (RSA|DSA|EC|PGP) PRIVATE KEY-----'\n    ]\n    \n    findings = []\n    for pattern in patterns:\n        # Scan all files for pattern\n        matches = scan_files(pattern)\n        if matches:\n            findings.append({\n                'type': 'secret_detected',\n                'pattern': pattern,\n                'files': matches,\n                'severity': 'critical'\n            })\n    \n    return findings\n```\n\n### 4. GitHub Integration Security\n```bash\n# Check gh CLI configuration\ngh auth status\n\n# Verify no dangerous aliases\ngh alias list | grep -E \"force|--hard|delete\"\n\n# Check repository permissions\ngh api user/permissions\n\n# Verify SSH key configuration\nssh -T git@github.com\n```\n\n### 5. Dependency Vulnerabilities\n```bash\n# Python dependencies\npip-audit --desc\n\n# Node.js dependencies\nnpm audit --json\n\n# Check for outdated packages\npip list --outdated\nnpm outdated\n```\n\n## Audit Report Structure\n\n### Executive Summary\n- Overall security posture: [Critical/High/Medium/Low]\n- Critical findings count: X\n- Immediate actions required: Y\n- Compliance status: [Pass/Fail]\n\n### Critical Findings\n1. **Finding**: Description\n   - **Risk**: Impact explanation\n   - **Evidence**: Specific examples\n   - **Remediation**: How to fix\n   - **Priority**: Immediate/High/Medium/Low\n\n### Permission Analysis\n```\nDirectory Permissions:\n src/ (755)  Appropriate\n tests/ (755)  Appropriate  \n .env (644)  Too permissive - should be 600\n secrets/ (777)  Critical - world writable\n```\n\n### Configuration Review\n```json\n{\n  \"claude_settings\": {\n    \"security_score\": 75,\n    \"issues\": [\n      {\n        \"setting\": \"auto_approve_write\",\n        \"current\": true,\n        \"recommended\": false,\n        \"risk\": \"Automatic file modifications without review\"\n      }\n    ]\n  }\n}\n```\n\n### Compliance Check\n- [ ] GDPR: Data minimization\n- [ ] HIPAA: PHI protection\n- [ ] PCI-DSS: Card data security\n- [ ] SOC 2: Access controls\n- [ ] ISO 27001: Information security\n\n## Remediation Recommendations\n\n### Immediate Actions (Critical)\n1. Remove hardcoded secrets from code\n2. Fix world-writable directories\n3. Rotate compromised credentials\n4. Enable audit logging\n\n### Short-term (Within 7 days)\n1. Implement proper secret management\n2. Configure file permission policies\n3. Set up security monitoring\n4. Update vulnerable dependencies\n\n### Long-term (Within 30 days)\n1. Implement zero-trust architecture\n2. Set up continuous security scanning\n3. Develop incident response plan\n4. Conduct security training\n\n## Automation Scripts\n\n### Fix Permissions Script\n```bash\n#!/bin/bash\n# fix-permissions.sh\n\necho \"Fixing file permissions...\"\n\n# Fix sensitive files\nfind . -name \"*.key\" -exec chmod 600 {} \\;\nfind . -name \"*.pem\" -exec chmod 600 {} \\;\nfind . -name \".env*\" -exec chmod 600 {} \\;\n\n# Fix directories\nfind . -type d -exec chmod 755 {} \\;\n\n# Remove world-writable permissions\nfind . -type f -perm /o+w -exec chmod o-w {} \\;\n\necho \"Permissions fixed!\"\n```\n\n### Security Baseline Configuration\n```json\n{\n  \"recommended_settings\": {\n    \"file_access\": {\n      \"default_permission\": \"prompt\",\n      \"auto_approve_read\": false,\n      \"auto_approve_write\": false\n    },\n    \"network_access\": {\n      \"require_https\": true,\n      \"verify_certificates\": true,\n      \"timeout_seconds\": 30\n    },\n    \"command_execution\": {\n      \"require_confirmation\": true,\n      \"block_dangerous_commands\": true,\n      \"audit_all_commands\": true\n    }\n  }\n}\n```\n\n## Integration with CI/CD\n\n```yaml\n# .github/workflows/security-audit.yml\nname: Security Audit\non:\n  schedule:\n    - cron: '0 0 * * *'  # Daily\n  pull_request:\n    branches: [main]\n\njobs:\n  audit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      \n      - name: Run permission audit\n        run: |\n          claude /permission-audit --output audit-report.json\n      \n      - name: Check audit results\n        run: |\n          if grep -q '\"severity\": \"critical\"' audit-report.json; then\n            echo \"Critical security issues found!\"\n            exit 1\n          fi\n      \n      - name: Upload audit report\n        uses: actions/upload-artifact@v2\n        with:\n          name: security-audit\n          path: audit-report.json\n```\n\n## Usage Examples\n\n```bash\n# Basic permission audit\n/permission-audit\n\n# Comprehensive security audit\n/permission-audit --comprehensive\n\n# Focus on specific area\n/permission-audit --focus secrets\n/permission-audit --focus permissions\n/permission-audit --focus configuration\n\n# Generate compliance report\n/permission-audit --compliance gdpr,hipaa\n\n# Fix issues automatically\n/permission-audit --auto-fix\n```\n\n## Output Format\n\nThe audit will produce:\n1. **Console Summary**: High-level findings\n2. **Detailed Report**: `security-audit-report.md`\n3. **JSON Output**: `audit-results.json` for automation\n4. **Remediation Script**: `fix-security-issues.sh`\n5. **Compliance Matrix**: `compliance-status.csv`\n\nRemember: Security is not a one-time check but a continuous process. Run audits regularly and after significant changes."
              },
              {
                "name": "/security-scan",
                "description": "Comprehensive security audit with deep thinking and parallel analysis",
                "path": "assets/claude-code-plugins/plugins/security/commands/security-scan.md",
                "frontmatter": {
                  "name": "security-scan",
                  "description": "Comprehensive security audit with deep thinking and parallel analysis",
                  "version": "1.0.0",
                  "argument-hint": "[target] [--deep|--quick] [--focus:<vulnerability-type>]"
                },
                "content": "# Security Scan Command\n\nYou are a security expert. When this command is invoked, perform a comprehensive security audit.\n\n## Scan Target\n$ARGUMENTS\n\nParse arguments to determine:\n- Target: specific file, directory, or entire project (default: entire project)\n- Depth: --deep (thorough scan) or --quick (rapid scan), default: deep\n- Focus: --focus:injection, --focus:auth, --focus:crypto, --focus:secrets (default: all)\n\nIf no target specified, scan the entire codebase for security vulnerabilities.\n\n## Extended Thinking for Security Analysis\n\n- **Quick scan**: Standard analysis for obvious vulnerabilities\n- **Deep scan**: Think hard about potential attack vectors and security implications\n- **Critical audit**: Ultrathink on comprehensive threat modeling and defense strategies\n- **Zero-day research**: Think intensely about novel vulnerability patterns\n\n## Parallel Security Subagents\n\nDeploy specialized subagents for concurrent analysis:\n@security-reviewer @system-designer @qa-engineer\n\nThese subagents operate independently, then findings are consolidated:\n- @security-reviewer: Analyze OWASP Top 10 vulnerabilities, auth/authz flaws, and cryptographic weaknesses\n- @system-designer: Examine system design for security patterns and vulnerabilities\n- @qa-engineer: Validate security test coverage and compliance requirements\n\n## Security Checks to Perform\n\n### 1. Code Vulnerabilities\n- **Injection Flaws**: SQL, NoSQL, Command, LDAP injection\n- **Authentication Issues**: Weak passwords, missing MFA, session problems\n- **Authorization Flaws**: Privilege escalation, IDOR, missing access controls\n- **Data Exposure**: Sensitive data in logs, unencrypted storage, API leaks\n- **Security Misconfigurations**: Default credentials, verbose errors, open ports\n\n### 2. Dependency Vulnerabilities\n```bash\n# Check Python dependencies\nsafety check\npip-audit\n\n# Check Node dependencies\nnpm audit\nsnyk test\n\n# Check for known CVEs\ntrivy fs .\n```\n\n### 3. Secret Detection\n- API keys, tokens, passwords in code\n- Hardcoded credentials\n- Sensitive configuration files\n- Private keys or certificates\n\n### 4. OWASP Top 10 Compliance\n1. Broken Access Control\n2. Cryptographic Failures\n3. Injection\n4. Insecure Design\n5. Security Misconfiguration\n6. Vulnerable Components\n7. Authentication Failures\n8. Data Integrity Failures\n9. Logging Failures\n10. SSRF\n\n## Scan Process\n\n1. **Initial Assessment**\n   ```python\n   scan_areas = {\n       \"authentication\": check_auth_mechanisms(),\n       \"authorization\": verify_access_controls(),\n       \"input_validation\": scan_input_handlers(),\n       \"cryptography\": audit_crypto_usage(),\n       \"dependencies\": check_vulnerable_deps(),\n       \"configurations\": review_security_configs(),\n       \"secrets\": detect_exposed_secrets()\n   }\n   ```\n\n2. **Deep Analysis**\n   - Review authentication flows\n   - Check authorization at all endpoints\n   - Validate input sanitization\n   - Verify encryption standards\n   - Audit logging practices\n\n3. **Generate Fixes**\n   ```python\n   for vulnerability in vulnerabilities:\n       fix = generate_security_fix(vulnerability)\n       test = generate_security_test(vulnerability)\n       priority = calculate_cvss_score(vulnerability)\n   ```\n\n## Output Format\n\n### Security Report Structure\n```markdown\n# Security Scan Report\n\n## Executive Summary\n- Total vulnerabilities: X\n- Critical: X, High: X, Medium: X, Low: X\n- Immediate action required: [list]\n\n## Critical Vulnerabilities\n### CVE-XXXX-XXXX: [Title]\n- **Severity**: Critical (CVSS: 9.8)\n- **Location**: file:line\n- **Impact**: Description\n- **Fix**: Remediation steps\n- **Code**: \n  ```python\n  # Fixed code example\n  ```\n\n## Recommendations\n1. Immediate fixes (24 hours)\n2. Short-term fixes (1 week)\n3. Long-term improvements\n\n## Compliance Status\n- [ ] GDPR Compliant\n- [ ] PCI-DSS Compliant\n- [ ] HIPAA Compliant\n- [ ] SOC2 Compliant\n```\n\n## Command Options\n\n```bash\n# Quick scan\n/security-scan --quick\n\n# Full deep scan\n/security-scan --deep\n\n# Specific area scan\n/security-scan --area authentication\n/security-scan --area dependencies\n\n# With auto-fix\n/security-scan --auto-fix\n\n# Compliance focused\n/security-scan --compliance GDPR,PCI-DSS\n```\n\n## Integration with Security Tools\n\nThe command integrates with:\n- **Static Analysis**: Bandit, Semgrep, CodeQL\n- **Dependency Scanning**: Safety, Snyk, npm audit\n- **Secret Detection**: detect-secrets, GitGuardian\n- **Dynamic Analysis**: OWASP ZAP, Burp Suite\n\n## Auto-Remediation\n\nWhen `--auto-fix` is enabled:\n\n1. **Apply Security Patches**\n   ```python\n   def apply_security_fix(vulnerability):\n       if vulnerability.has_patch:\n           apply_patch(vulnerability.patch)\n       elif vulnerability.has_workaround:\n           implement_workaround(vulnerability.workaround)\n       else:\n           add_security_todo(vulnerability)\n   ```\n\n2. **Update Dependencies**\n   ```bash\n   # Update vulnerable packages\n   pip install --upgrade vulnerable-package==safe-version\n   npm update vulnerable-package\n   ```\n\n3. **Fix Configurations**\n   ```python\n   # Example: Fix insecure headers\n   security_headers = {\n       \"X-Frame-Options\": \"DENY\",\n       \"X-Content-Type-Options\": \"nosniff\",\n       \"X-XSS-Protection\": \"1; mode=block\",\n       \"Strict-Transport-Security\": \"max-age=31536000\",\n       \"Content-Security-Policy\": \"default-src 'self'\"\n   }\n   ```\n\n## Security Best Practices\n\nAlways check for:\n- Input validation on all user inputs\n- Output encoding to prevent XSS\n- Parameterized queries to prevent SQL injection\n- Proper authentication and session management\n- Secure password storage (bcrypt, argon2)\n- HTTPS enforcement\n- Security headers\n- Rate limiting\n- Audit logging\n- Error handling without information disclosure\n\n## Emergency Response\n\nIf critical vulnerabilities are found:\n1. Alert the security team immediately\n2. Create incident ticket\n3. Apply emergency patches if available\n4. Document the vulnerability and fix\n5. Schedule security review"
              }
            ],
            "skills": []
          },
          {
            "name": "testing",
            "description": "Testing, QA, and quality gates with 3 specialized agents for automated validation and code quality checks",
            "source": "./assets/claude-code-plugins/plugins/testing",
            "category": "testing",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install testing@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/generate-tests",
                "description": "Generate comprehensive test suites for code",
                "path": "assets/claude-code-plugins/plugins/testing/commands/generate-tests.md",
                "frontmatter": {
                  "name": "generate-tests",
                  "description": "Generate comprehensive test suites for code",
                  "version": "1.0.0",
                  "argument-hint": "[file-or-module-to-test] [--unit|--integration|--e2e|--all]"
                },
                "content": "# Generate Tests Command\n\nYou are a test generation expert. Create comprehensive, maintainable test suites that ensure code quality.\n\n## Parallel Subagent Support\n\nFor complex testing scenarios, coordinate with these subagents:\n@test-generator @qa-engineer @system-designer\n\n- @test-generator: Create comprehensive test suites with proper coverage\n- @qa-engineer: Validate test quality and identify edge cases\n- @system-designer: Ensure tests align with system architecture patterns\n\n## Test Target\n$ARGUMENTS\n\nParse arguments to determine:\n- Target: specific file, module, or entire codebase (default: analyze current context)\n- Test type: --unit, --integration, --e2e, or --all (default: --all)\n\nIf no target specified, analyze the most recently modified or currently open files.\n\n## Test Generation Strategy\n\n### 1. Test Types to Generate\n\n#### Unit Tests\n```python\n# Test individual functions/methods in isolation\ndef test_calculate_discount():\n    # Arrange\n    original_price = 100\n    discount_percent = 20\n    \n    # Act\n    result = calculate_discount(original_price, discount_percent)\n    \n    # Assert\n    assert result == 80\n```\n\n#### Integration Tests\n```python\n# Test component interactions\ndef test_order_processing_workflow():\n    # Test complete flow from order to fulfillment\n    order = create_order(items=[...])\n    payment = process_payment(order)\n    shipment = create_shipment(order, payment)\n    assert shipment.status == \"ready_to_ship\"\n```\n\n#### Edge Case Tests\n```python\n# Test boundary conditions\ndef test_edge_cases():\n    # Empty input\n    assert function([]) == expected_empty_result\n    \n    # Maximum values\n    assert function(MAX_INT) == expected_max_result\n    \n    # Null/None handling\n    assert function(None) raises ValueError\n    \n    # Special characters\n    assert function(\"!@#$%\") == expected_special_result\n```\n\n## Test Generation Patterns\n\n### 1. Parameterized Tests\n```python\nimport pytest\n\n@pytest.mark.parametrize(\"input,expected\", [\n    (0, 0),\n    (1, 1),\n    (-1, 1),\n    (10, 100),\n    (3.14, 9.8596),\n])\ndef test_square_function(input, expected):\n    assert square(input) == pytest.approx(expected)\n```\n\n### 2. Property-Based Tests\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.integers())\ndef test_sorting_preserves_length(numbers):\n    sorted_nums = sort_function(numbers)\n    assert len(sorted_nums) == len(numbers)\n\n@given(st.text())\ndef test_encoding_decoding_roundtrip(text):\n    encoded = encode(text)\n    decoded = decode(encoded)\n    assert decoded == text\n```\n\n### 3. Mocking and Stubbing\n```python\nfrom unittest.mock import Mock, patch\n\ndef test_api_call_handling():\n    # Mock external dependency\n    with patch('requests.get') as mock_get:\n        mock_get.return_value.json.return_value = {'status': 'success'}\n        \n        result = fetch_data_from_api()\n        \n        assert result['status'] == 'success'\n        mock_get.assert_called_once_with('http://api.example.com/data')\n```\n\n## Coverage Analysis\n\n### Generate Coverage Report\n```bash\n# Python\npytest --cov=src --cov-report=html --cov-report=term-missing\n\n# JavaScript\njest --coverage --coverageReporters=html,text\n\n# Go\ngo test -cover -coverprofile=coverage.out\ngo tool cover -html=coverage.out\n```\n\n### Coverage Goals\n- **Line Coverage**: > 80%\n- **Branch Coverage**: > 75%\n- **Function Coverage**: > 90%\n- **Critical Path Coverage**: 100%\n\n## Test Structure Templates\n\n### 1. Python (pytest)\n```python\nimport pytest\nfrom unittest.mock import Mock, patch\nfrom datetime import datetime\n\nclass TestUserService:\n    \"\"\"Test suite for UserService class.\"\"\"\n    \n    @pytest.fixture\n    def user_service(self):\n        \"\"\"Provide UserService instance for tests.\"\"\"\n        return UserService()\n    \n    @pytest.fixture\n    def sample_user(self):\n        \"\"\"Provide sample user data.\"\"\"\n        return {\n            'id': 1,\n            'name': 'Test User',\n            'email': 'test@example.com'\n        }\n    \n    def test_create_user_success(self, user_service, sample_user):\n        \"\"\"Test successful user creation.\"\"\"\n        # Arrange\n        user_data = sample_user\n        \n        # Act\n        result = user_service.create_user(user_data)\n        \n        # Assert\n        assert result.id is not None\n        assert result.name == user_data['name']\n        assert result.email == user_data['email']\n    \n    def test_create_user_duplicate_email(self, user_service):\n        \"\"\"Test user creation with duplicate email.\"\"\"\n        # Arrange\n        user_service.create_user({'email': 'test@example.com'})\n        \n        # Act & Assert\n        with pytest.raises(DuplicateEmailError):\n            user_service.create_user({'email': 'test@example.com'})\n    \n    @pytest.mark.parametrize(\"invalid_email\", [\n        \"not-an-email\",\n        \"@example.com\",\n        \"user@\",\n        \"\",\n        None\n    ])\n    def test_create_user_invalid_email(self, user_service, invalid_email):\n        \"\"\"Test user creation with invalid email formats.\"\"\"\n        with pytest.raises(ValidationError):\n            user_service.create_user({'email': invalid_email})\n```\n\n### 2. JavaScript (Jest)\n```javascript\ndescribe('OrderProcessor', () => {\n    let orderProcessor;\n    let mockDatabase;\n    let mockPaymentGateway;\n    \n    beforeEach(() => {\n        mockDatabase = {\n            save: jest.fn(),\n            find: jest.fn()\n        };\n        mockPaymentGateway = {\n            charge: jest.fn()\n        };\n        orderProcessor = new OrderProcessor(mockDatabase, mockPaymentGateway);\n    });\n    \n    afterEach(() => {\n        jest.clearAllMocks();\n    });\n    \n    describe('processOrder', () => {\n        it('should process valid order successfully', async () => {\n            // Arrange\n            const order = {\n                id: '123',\n                amount: 100,\n                items: [{ id: '1', quantity: 2 }]\n            };\n            mockPaymentGateway.charge.mockResolvedValue({ status: 'success' });\n            mockDatabase.save.mockResolvedValue(true);\n            \n            // Act\n            const result = await orderProcessor.processOrder(order);\n            \n            // Assert\n            expect(result.status).toBe('completed');\n            expect(mockPaymentGateway.charge).toHaveBeenCalledWith(100);\n            expect(mockDatabase.save).toHaveBeenCalledWith(order);\n        });\n        \n        it('should handle payment failure', async () => {\n            // Arrange\n            mockPaymentGateway.charge.mockRejectedValue(new Error('Payment failed'));\n            \n            // Act & Assert\n            await expect(orderProcessor.processOrder({}))\n                .rejects.toThrow('Payment failed');\n        });\n    });\n});\n```\n\n## Test Data Generation\n\n### 1. Fixtures\n```python\n@pytest.fixture\ndef database():\n    \"\"\"Provide test database.\"\"\"\n    db = create_test_database()\n    yield db\n    db.cleanup()\n\n@pytest.fixture\ndef authenticated_client():\n    \"\"\"Provide authenticated API client.\"\"\"\n    client = TestClient()\n    client.login(username=\"test\", password=\"test\")\n    return client\n```\n\n### 2. Factories\n```python\nimport factory\n\nclass UserFactory(factory.Factory):\n    class Meta:\n        model = User\n    \n    id = factory.Sequence(lambda n: n)\n    username = factory.Faker('user_name')\n    email = factory.Faker('email')\n    created_at = factory.Faker('date_time')\n\n# Usage\nuser = UserFactory()\nusers = UserFactory.create_batch(10)\n```\n\n## Command Options\n\n```bash\n# Generate tests for specific file\n/generate-tests --file src/services/user_service.py\n\n# Generate specific test types\n/generate-tests --type unit\n/generate-tests --type integration\n/generate-tests --type e2e\n\n# Generate with coverage target\n/generate-tests --coverage 90\n\n# Generate property-based tests\n/generate-tests --property-based\n\n# Generate performance tests\n/generate-tests --performance\n```\n\n## Test Quality Checklist\n\n- [ ] **Isolated**: Tests don't depend on each other\n- [ ] **Repeatable**: Same result every time\n- [ ] **Fast**: Unit tests < 100ms, integration < 1s\n- [ ] **Self-Validating**: Clear pass/fail\n- [ ] **Comprehensive**: Cover happy path, edge cases, errors\n- [ ] **Maintainable**: Easy to understand and update\n- [ ] **Documented**: Clear test names and comments\n\n## Special Test Cases\n\n### 1. Async/Concurrent Tests\n```python\nimport asyncio\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_concurrent_requests():\n    tasks = [fetch_data(i) for i in range(10)]\n    results = await asyncio.gather(*tasks)\n    assert len(results) == 10\n    assert all(r.status == 200 for r in results)\n```\n\n### 2. Performance Tests\n```python\nimport time\n\ndef test_performance_under_load():\n    start = time.time()\n    for _ in range(1000):\n        process_item()\n    duration = time.time() - start\n    assert duration < 1.0  # Should complete in under 1 second\n```\n\n### 3. Security Tests\n```python\ndef test_sql_injection_prevention():\n    malicious_input = \"'; DROP TABLE users; --\"\n    result = search_users(malicious_input)\n    # Should handle safely, not execute SQL\n    assert \"error\" not in result.lower()\n    assert len(get_all_users()) > 0  # Table still exists\n```\n\n## Test Documentation\n\nGenerate test documentation:\n```python\ndef test_user_registration_flow():\n    \"\"\"\n    Test the complete user registration flow.\n    \n    This test verifies:\n    1. User can submit registration form\n    2. Email validation is performed\n    3. Confirmation email is sent\n    4. User can confirm email\n    5. User can login after confirmation\n    \n    Test Data:\n    - Username: testuser\n    - Email: test@example.com\n    - Password: SecurePass123!\n    \n    Expected Results:\n    - User created in database\n    - Confirmation email sent\n    - User status changes to 'active' after confirmation\n    \"\"\"\n    # Test implementation\n```"
              }
            ],
            "skills": []
          },
          {
            "name": "performance",
            "description": "Performance profiling, optimization, and monitoring with 5 specialized agents for comprehensive performance analysis",
            "source": "./assets/claude-code-plugins/plugins/performance",
            "category": "performance",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install performance@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/analyze-performance",
                "description": "Deep performance analysis with extended thinking and parallel optimization",
                "path": "assets/claude-code-plugins/plugins/performance/commands/analyze-performance.md",
                "frontmatter": {
                  "name": "analyze-performance",
                  "description": "Deep performance analysis with extended thinking and parallel optimization",
                  "version": "1.0.0",
                  "argument-hint": "[target] [--profile|--benchmark|--analyze]"
                },
                "content": "# Analyze Performance Command\n\nYou are a performance analysis expert. When this command is invoked, you will:\n\n## Analysis Target\n$ARGUMENTS\n\nParse arguments to determine:\n- Target: specific file, function, or system component (default: entire application)\n- Mode: --profile (CPU/memory profiling), --benchmark (speed tests), --analyze (static analysis), default: all\n\nIf no target specified, perform comprehensive performance analysis.\n\n## Extended Thinking Strategy\n\n- **Quick metrics**: Standard performance measurements\n- **Bottleneck analysis**: Think about performance hotspots and inefficiencies\n- **Deep optimization**: Think hard about algorithmic improvements and caching strategies\n- **System redesign**: Ultrathink on architectural changes for 10x+ improvements\n\n## Parallel Performance Subagents\n\nDeploy concurrent analysis agents:\n@performance-profiler @optimization-engineer @system-designer @code-archaeologist\n\nThese specialized subagents provide comprehensive performance insights:\n- @performance-profiler: Analyze and measure performance bottlenecks\n- @optimization-engineer: Implement performance improvements and optimizations\n- @system-designer: Examine system design and scalability patterns\n- @code-archaeologist: Identify legacy performance issues and optimization opportunities\n\n## Primary Tasks\n\n1. **Profile Current Performance**\n   - Identify performance bottlenecks in the codebase\n   - Analyze time complexity of algorithms\n   - Check for memory leaks or inefficient memory usage\n   - Review database queries for optimization opportunities\n   - Identify unnecessary network calls or API requests\n\n2. **Generate Performance Metrics**\n   - Calculate Big O notation for critical functions\n   - Measure actual execution times where possible\n   - Identify hot paths in the code\n   - Check for N+1 query problems\n   - Analyze bundle sizes for frontend code\n\n3. **Suggest Optimizations**\n   - Recommend algorithm improvements\n   - Suggest caching strategies\n   - Propose lazy loading opportunities\n   - Identify code that can be parallelized\n   - Recommend database indexing strategies\n\n## Analysis Approach\n\n```python\n# Example performance analysis structure\nperformance_analysis = {\n    \"bottlenecks\": [\n        {\n            \"location\": \"file:line\",\n            \"issue\": \"description\",\n            \"impact\": \"high|medium|low\",\n            \"solution\": \"recommended fix\"\n        }\n    ],\n    \"metrics\": {\n        \"complexity\": {},\n        \"memory\": {},\n        \"io\": {},\n        \"network\": {}\n    },\n    \"optimizations\": [\n        {\n            \"priority\": 1,\n            \"description\": \"optimization\",\n            \"expected_improvement\": \"percentage\",\n            \"implementation_effort\": \"hours\"\n        }\n    ]\n}\n```\n\n## Common Performance Issues to Check\n\n1. **Algorithm Complexity**\n   - Nested loops (O(n) or worse)\n   - Inefficient sorting/searching\n   - Unnecessary recursion\n   - Missing memoization opportunities\n\n2. **Memory Management**\n   - Memory leaks\n   - Large object creation in loops\n   - Unnecessary data copying\n   - Missing object pooling\n\n3. **I/O Operations**\n   - Synchronous file operations\n   - Missing database connection pooling\n   - Inefficient batch processing\n   - Lack of pagination\n\n4. **Frontend Specific**\n   - Unnecessary re-renders\n   - Missing React.memo/useMemo\n   - Large bundle sizes\n   - Blocking JavaScript\n   - Missing code splitting\n\n5. **Backend Specific**\n   - N+1 queries\n   - Missing database indexes\n   - Inefficient ORM usage\n   - Lack of caching\n   - Synchronous operations that could be async\n\n## Output Format\n\nProvide a structured performance report including:\n\n1. **Executive Summary** - High-level findings and impact\n2. **Critical Issues** - Must-fix performance problems\n3. **Optimization Opportunities** - Ranked by ROI\n4. **Implementation Plan** - Step-by-step optimization guide\n5. **Benchmarks** - Before/after performance metrics\n\n## Usage Examples\n\n```bash\n# Analyze entire codebase\n/analyze-performance\n\n# Analyze specific module\n/analyze-performance --module src/api\n\n# Focus on database performance\n/analyze-performance --focus database\n\n# Analyze frontend bundle\n/analyze-performance --focus frontend --bundle\n```\n\n## Integration with Agents\n\nThis command can trigger specialized agents for deeper analysis:\n@performance-profiler @optimization-engineer\n\n```yaml\nagents: [@performance-profiler, @optimization-engineer]\nmodels: [sonnet, opus]\ntask: \"Deep performance analysis with profiling and optimization\"\n```\n\nRemember to:\n- Consider both time and space complexity\n- Think about scalability (10x, 100x, 1000x users)\n- Balance optimization effort with actual impact\n- Provide concrete, actionable recommendations\n- Include code examples for suggested optimizations"
              }
            ],
            "skills": []
          },
          {
            "name": "tdd-workflow",
            "description": "TDD workflow with 6 specialized agents for test-first development, red-green-refactor cycle, and comprehensive quality analysis",
            "source": "./assets/claude-code-plugins/plugins/tdd-workflow",
            "category": "workflow",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install tdd-workflow@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [
              {
                "name": "/tdd-bugfix",
                "description": "Fix bugs using Test-Driven Development approach with regression prevention",
                "path": "assets/claude-code-plugins/plugins/tdd-workflow/commands/tdd-bugfix.md",
                "frontmatter": {
                  "name": "tdd-bugfix",
                  "description": "Fix bugs using Test-Driven Development approach with regression prevention",
                  "version": "1.0.0",
                  "argument-hint": "[bug-description-or-issue-number]"
                },
                "content": "# TDD Bug Fix Command\n\nYou are a debugging expert who uses TDD principles. ALWAYS write a failing test that reproduces the bug before fixing it.\n\n## Bug to Fix\n$ARGUMENTS\n\nIf no bug description was provided above, ask the user: \"What bug would you like to fix using TDD? Please provide a description or issue number.\"\n\n## Extended Thinking for Bug Fixes\n\n- **Simple bugs**: Quick test and fix\n- **Complex bugs**: Think about root causes and side effects\n- **System bugs**: Think hard about integration impacts\n- **Critical bugs**: Think harder about preventing recurrence\n\n## Test Organization and Placement\n\nBefore creating any tests, establish the project's test directory structure:\n\n### Test Directory Detection\n1. **Scan for existing test structure**:\n   - Look for `tests/`, `test/`, or `src/tests/` directories\n   - Check `pyproject.toml`, `setup.py`, or `pytest.ini` for test configuration\n   - Follow project-specific conventions if they exist\n\n2. **Create standard structure if needed**:\n   ```\n   tests/\n    unit/           # Unit tests for individual functions/classes\n    integration/    # Tests for component interactions\n    e2e/           # End-to-end system tests\n    fixtures/      # Test data and fixtures\n    conftest.py    # Shared test configuration\n   ```\n\n3. **Place bug fix tests appropriately**:\n   - **Regression tests**: `tests/unit/test_[module_name].py`\n   - **Integration bugs**: `tests/integration/test_[component_name].py`\n   - **System bugs**: `tests/e2e/test_[feature_name].py`\n\n## Bug Fix Process\n\n### Step 1: Reproduce the Bug with a Test\n\n```python\ndef test_reproduces_reported_bug():\n    \"\"\"\n    Bug Report: Users can login with expired tokens\n    This test MUST fail to confirm bug exists\n    \"\"\"\n    expired_token = create_token(expired=True)\n    \n    # This should fail but currently passes (bug!)\n    with pytest.raises(AuthenticationError):\n        authenticate_with_token(expired_token)\n```\n\n### Step 2: Verify Test Fails\n\n```bash\n# Confirm the bug exists - use proper test path\npytest tests/unit/test_auth_module.py::test_reproduces_reported_bug -v\n\n# Expected: Test FAILS (confirming bug exists)\n# FAILED tests/unit/test_auth_module.py::test_reproduces_reported_bug\n```\n\n### Step 3: Write Expected Behavior Test\n\n```python\ndef test_correct_token_expiry_behavior():\n    \"\"\"Define correct behavior through tests\"\"\"\n    # Valid token should work\n    valid_token = create_token(expired=False)\n    assert authenticate_with_token(valid_token) == True\n    \n    # Expired token should fail\n    expired_token = create_token(expired=True)\n    with pytest.raises(AuthenticationError):\n        authenticate_with_token(expired_token)\n    \n    # About-to-expire token should work\n    almost_expired = create_token(expires_in_seconds=60)\n    assert authenticate_with_token(almost_expired) == True\n```\n\n### Step 4: Fix the Bug\n\n```python\n# Minimal fix to pass the test\ndef authenticate_with_token(token):\n    \"\"\"Fixed implementation\"\"\"\n    if token.is_expired():  # This check was missing!\n        raise AuthenticationError(\"Token expired\")\n    \n    return validate_token(token)\n```\n\n### Step 5: Add Regression Tests\n\n```python\ndef test_prevents_token_expiry_regression():\n    \"\"\"Comprehensive tests to prevent regression\"\"\"\n    # Test various expiry scenarios\n    test_cases = [\n        (create_token(expired=True), False),\n        (create_token(expired=False), True),\n        (create_token(expires_at=yesterday), False),\n        (create_token(expires_at=tomorrow), True),\n        (create_token(expires_at=now), False),\n    ]\n    \n    for token, should_pass in test_cases:\n        if should_pass:\n            assert authenticate_with_token(token)\n        else:\n            with pytest.raises(AuthenticationError):\n                authenticate_with_token(token)\n```\n\n## Project Structure Analysis\n\nBefore starting bug analysis, agents should:\n\n1. **Detect existing test infrastructure**:\n   ```bash\n   # Check for test directories\n   find . -type d -name \"test*\" -o -name \"*test*\" | head -10\n   \n   # Look for test configuration files\n   ls -la pyproject.toml setup.py pytest.ini tox.ini\n   \n   # Find existing test files to follow naming patterns\n   find . -name \"test_*.py\" -o -name \"*_test.py\" | head -5\n   ```\n\n2. **Analyze current test organization**:\n   - Check if tests are co-located with source (src/module/test_module.py)\n   - Identify central test directory structure\n   - Note any project-specific test patterns or conventions\n\n3. **Create missing test structure**:\n   ```bash\n   # Create standard Python test structure if missing\n   mkdir -p tests/{unit,integration,e2e,fixtures}\n   touch tests/conftest.py\n   ```\n\n## Parallel Bug Analysis Subagents\n\nDeploy concurrent debugging specialists:\n@code-archaeologist @business-analyst @test-generator @qa-engineer\n\n- @code-archaeologist: Analyze underlying issues, uncover root causes, search for related patterns, and determine appropriate test directory\n- @business-analyst: Evaluate affected components, perform impact analysis, and recommend test categorization (unit/integration/e2e)\n- @test-generator: Design comprehensive test suite with proper file placement in central test structure to prevent regression and ensure coverage\n- @qa-engineer: Validate fix quality, identify potential side effects, and ensure tests are placed in discoverable locations\n\n## Bug Categories\n\n### 1. Logic Errors\n```python\ndef test_fixes_calculation_error():\n    \"\"\"Test for calculation bugs\"\"\"\n    # Bug: Total calculated incorrectly\n    cart = ShoppingCart()\n    cart.add_item(price=10, quantity=2)\n    cart.add_item(price=5, quantity=3)\n    \n    # Should be 35, not 25 (bug!)\n    assert cart.total() == 35\n```\n\n### 2. Boundary Conditions\n```python\ndef test_handles_empty_input():\n    \"\"\"Test for edge case bugs\"\"\"\n    # Bug: Crashes on empty list\n    result = process_items([])\n    assert result == []  # Should handle gracefully\n```\n\n### 3. Race Conditions\n```python\ndef test_thread_safety():\n    \"\"\"Test for concurrency bugs\"\"\"\n    # Bug: Data corruption in parallel access\n    import threading\n    \n    counter = Counter()\n    threads = []\n    \n    for _ in range(100):\n        t = threading.Thread(target=counter.increment)\n        threads.append(t)\n        t.start()\n    \n    for t in threads:\n        t.join()\n    \n    assert counter.value == 100  # Should be exactly 100\n```\n\n### 4. Security Vulnerabilities\n```python\ndef test_prevents_sql_injection():\n    \"\"\"Test for security bugs\"\"\"\n    # Bug: SQL injection possible\n    malicious_input = \"'; DROP TABLE users; --\"\n    \n    # Should sanitize input\n    with pytest.raises(ValidationError):\n        execute_query(malicious_input)\n```\n\n## Bug Fix Workflow\n\n1. **Analyze Bug Report**\n   - Understand symptoms\n   - Identify affected components\n   - Determine severity\n\n2. **Create Failing Test**\n   - Write test that reproduces bug\n   - Verify test fails\n   - Document expected behavior\n\n3. **Implement Fix**\n   - Make minimal change\n   - Focus on root cause\n   - Avoid introducing new issues\n\n4. **Verify Fix**\n   - Run reproduction test\n   - Confirm it passes\n   - Run full test suite\n\n5. **Prevent Regression**\n   - Add comprehensive tests\n   - Test edge cases\n   - Document fix\n\n## Usage Examples\n\n```bash\n# Fix authentication bug\n/tdd-bugfix \"Users can login with wrong password\"\n# Tests will be placed in: tests/unit/test_auth.py\n\n# Fix data corruption bug\n/tdd-bugfix \"Database records deleted when updating user profile\"\n# Tests will be placed in: tests/integration/test_user_service.py\n\n# Fix performance bug\n/tdd-bugfix \"API timeout when loading large datasets\"\n# Tests will be placed in: tests/e2e/test_api_performance.py\n\n# Fix UI bug\n/tdd-bugfix \"Button click not working after form validation\"\n# Tests will be placed in: tests/e2e/test_form_interactions.py\n```\n\n## Output Format\n\n1. **Bug Analysis**\n   - Root cause identification\n   - Impact assessment\n   - Related code areas\n\n2. **Reproduction Test**\n   - Failing test that confirms bug\n   - Test execution output\n   - Clear failure message\n\n3. **Bug Fix**\n   - Minimal code change\n   - Explanation of fix\n   - No side effects\n\n4. **Verification**\n   - Test now passing\n   - All existing tests still pass\n   - No performance regression\n\n5. **Regression Prevention**\n   - Additional test cases\n   - Edge case coverage\n   - Documentation updates\n\n## Common Bug Patterns\n\n### Off-by-One Errors\n```python\ndef test_array_bounds():\n    \"\"\"Prevent index errors\"\"\"\n    arr = [1, 2, 3]\n    # Bug: Accessing arr[3]\n    assert get_last_element(arr) == 3  # Not arr[len(arr)]\n```\n\n### Null Reference Errors\n```python\ndef test_handles_null_values():\n    \"\"\"Prevent NoneType errors\"\"\"\n    # Bug: Crashes on None\n    result = process_data(None)\n    assert result == default_value()\n```\n\n### Type Mismatches\n```python\ndef test_type_conversion():\n    \"\"\"Prevent type errors\"\"\"\n    # Bug: String concatenation with number\n    result = format_message(\"Count\", 42)\n    assert result == \"Count: 42\"\n```\n\n## Quality Checklist\n\nBefore completing bug fix:\n- [ ] Bug reproduced with failing test in appropriate test directory\n- [ ] Root cause identified\n- [ ] Minimal fix implemented\n- [ ] Test now passes when run with full path\n- [ ] No existing tests broken (run full test suite)\n- [ ] Regression tests added in centralized test structure\n- [ ] Performance unchanged\n- [ ] Documentation updated\n- [ ] Similar bugs checked\n- [ ] Tests are discoverable by test runners\n- [ ] Test files follow project naming conventions\n\n## Integration with CI/CD\n\n```yaml\n# GitHub Action for bug fixes with centralized test structure\nname: TDD Bug Fix Validation\non:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  validate-bugfix:\n    if: contains(github.event.pull_request.labels.*.name, 'bugfix')\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      \n      - name: Check for regression test in proper location\n        run: |\n          # Ensure bug fix includes test in tests/ directory\n          if ! git diff --name-only origin/main..HEAD | grep -q \"tests/.*test_.*\\.py\"; then\n            echo \"Bug fix must include test in tests/ directory\"\n            exit 1\n          fi\n      \n      - name: Run all tests with discovery\n        run: |\n          # Run tests from centralized location\n          pytest tests/ --tb=short --verbose\n      \n      - name: Check coverage didn't decrease\n        run: |\n          # Coverage analysis on centralized test structure\n          pytest tests/ --cov=src --cov=. --cov-report=term\n          # Compare with main branch coverage\n```\n\n## Best Practices\n\n1. **Always Test First**: Never fix without reproducing\n2. **Minimal Changes**: Fix only the bug, nothing else\n3. **Document the Fix**: Explain what was wrong and why\n4. **Test Thoroughly**: Include edge cases\n5. **Prevent Recurrence**: Add monitoring/logging\n6. **Learn from Bugs**: Update coding standards"
              },
              {
                "name": "/tdd-feature",
                "description": "Develop features using strict Test-Driven Development with parallel test specialists",
                "path": "assets/claude-code-plugins/plugins/tdd-workflow/commands/tdd-feature.md",
                "frontmatter": {
                  "name": "tdd-feature",
                  "description": "Develop features using strict Test-Driven Development with parallel test specialists",
                  "version": "1.0.0",
                  "argument-hint": "[feature-description]"
                },
                "content": "# TDD Feature Development Command\n\nYou are a TDD expert. When developing features, ALWAYS write tests first, verify they fail, then implement minimal code to pass.\n\n## Feature to Implement\n$ARGUMENTS\n\nIf no feature description was provided above, ask the user: \"What feature would you like to implement using TDD?\"\n\n## Extended Thinking for TDD\n\n- **Simple features**: Standard red-green-refactor cycle\n- **Complex features**: Think about comprehensive test scenarios and edge cases\n- **System features**: Think hard about integration points and dependencies\n- **Critical features**: Ultrathink on failure modes, security, and performance\n\n## Test Organization and Structure\n\nBefore writing any tests, establish proper test placement:\n\n### Test Directory Setup\n1. **Detect existing structure**:\n   ```bash\n   # Look for test directories and configuration\n   find . -type d -name \"test*\" -maxdepth 3\n   grep -r \"testpaths\\|test_suite\" pyproject.toml setup.py pytest.ini 2>/dev/null || true\n   ```\n\n2. **Create centralized test structure**:\n   ```\n   tests/\n    unit/               # Fast isolated tests\n       test_models.py      # Database models\n       test_services.py    # Business logic\n       test_utils.py       # Utility functions\n    integration/        # Component interaction tests\n       test_api_endpoints.py\n       test_database_operations.py\n    e2e/               # End-to-end system tests\n       test_user_workflows.py\n    fixtures/          # Test data and fixtures\n       sample_data.json\n       mock_responses.py\n    conftest.py        # Shared test configuration\n   ```\n\n3. **Feature test placement guidelines**:\n   - **New functions/classes**: `tests/unit/test_[module_name].py`\n   - **API endpoints**: `tests/integration/test_[feature_name]_api.py`\n   - **User workflows**: `tests/e2e/test_[feature_name]_workflow.py`\n   - **Performance tests**: `tests/performance/test_[feature_name]_perf.py`\n\n## Parallel TDD Subagents\n\nDeploy concurrent test specialists:\n@test-generator @qa-engineer @performance-profiler @security-reviewer\n\nAll subagents work in parallel to create comprehensive test coverage BEFORE implementation:\n- @test-generator: Design isolated unit tests, component interaction tests, and integration test suites with proper file placement in centralized test structure\n- @qa-engineer: Identify boundary conditions, edge cases, and quality validation scenarios, ensuring tests are placed in appropriate test directories\n- @performance-profiler: Create performance benchmarks and validation tests in dedicated performance test directories\n- @security-reviewer: Design security test cases and vulnerability checks, placing them in appropriate test categories\n\n## Strict TDD Process\n\n### Phase 1: RED (Write Failing Tests)\n\n```python\n# ALWAYS start with tests that fail\ndef test_feature_core_functionality():\n    \"\"\"Test the main happy path\"\"\"\n    # This MUST fail initially\n    result = new_feature(valid_input)\n    assert result == expected_output\n\ndef test_feature_handles_invalid_input():\n    \"\"\"Test error handling\"\"\"\n    with pytest.raises(ValueError):\n        new_feature(invalid_input)\n\ndef test_feature_edge_cases():\n    \"\"\"Test boundary conditions\"\"\"\n    assert new_feature(edge_case_1) == expected_1\n    assert new_feature(edge_case_2) == expected_2\n```\n\n### Phase 2: Verify Failure\n\n```bash\n# Run tests to confirm they fail - use proper test path\npytest tests/unit/test_new_feature.py -v\n\n# Expected output:\n# tests/unit/test_new_feature.py::test_feature_core_functionality FAILED\n# tests/unit/test_new_feature.py::test_feature_handles_invalid_input FAILED\n# tests/unit/test_new_feature.py::test_feature_edge_cases FAILED\n```\n\n### Phase 3: GREEN (Minimal Implementation)\n\n```python\n# Write ONLY enough code to pass tests\ndef new_feature(input_data):\n    \"\"\"Minimal implementation to pass tests\"\"\"\n    if not is_valid(input_data):\n        raise ValueError(\"Invalid input\")\n    \n    # Just enough logic to pass\n    return process(input_data)\n```\n\n### Phase 4: REFACTOR (Improve Design)\n\n```python\n# After tests pass, improve code quality\nclass FeatureHandler:\n    \"\"\"Refactored with better design\"\"\"\n    def __init__(self):\n        self.validator = InputValidator()\n        self.processor = DataProcessor()\n    \n    def execute(self, input_data):\n        \"\"\"Clean, maintainable implementation\"\"\"\n        self.validator.validate(input_data)\n        return self.processor.process(input_data)\n```\n\n## Test Categories to Always Include\n\n### 1. Functional Tests\n```python\ndef test_feature_produces_correct_output():\n    \"\"\"Core functionality works correctly\"\"\"\n    pass\n\ndef test_feature_handles_various_inputs():\n    \"\"\"Works with different input types\"\"\"\n    pass\n```\n\n### 2. Error Handling Tests\n```python\ndef test_feature_handles_null_input():\n    \"\"\"Gracefully handles None\"\"\"\n    pass\n\ndef test_feature_handles_malformed_data():\n    \"\"\"Handles bad data gracefully\"\"\"\n    pass\n```\n\n### 3. Edge Case Tests\n```python\ndef test_feature_with_empty_input():\n    \"\"\"Handles empty collections\"\"\"\n    pass\n\ndef test_feature_with_maximum_values():\n    \"\"\"Handles boundary conditions\"\"\"\n    pass\n```\n\n### 4. Performance Tests\n```python\ndef test_feature_performance():\n    \"\"\"Completes within acceptable time\"\"\"\n    import time\n    start = time.time()\n    new_feature(large_dataset)\n    assert time.time() - start < 1.0  # Under 1 second\n```\n\n### 5. Integration Tests\n```python\ndef test_feature_integrates_with_system():\n    \"\"\"Works with rest of system\"\"\"\n    pass\n```\n\n## Command Execution Flow\n\n1. **Analyze Project Structure**\n   ```bash\n   # Detect existing test organization\n   find . -name \"conftest.py\" -o -name \"pytest.ini\" -o -name \"pyproject.toml\"\n   ls -la tests/ test/ src/tests/ 2>/dev/null || echo \"No existing test dirs found\"\n   \n   # Check current test patterns\n   find . -name \"test_*.py\" -o -name \"*_test.py\" | head -3\n   ```\n\n2. **Understand Requirements**\n   - Parse feature requirements\n   - Identify test scenarios\n   - Determine appropriate test directory (unit/integration/e2e)\n   - Plan test structure within centralized location\n\n3. **Write Comprehensive Test Suite**\n   - Create test files in proper directories\n   - Follow project naming conventions\n   - Write detailed test cases\n   - Include fixtures and helpers in tests/fixtures/\n\n4. **Verify All Tests Fail**\n   - Run test suite with full paths\n   - Confirm RED state\n   - Document failure messages\n\n5. **Implement Incrementally**\n   - Write code for one test\n   - Run tests with proper paths\n   - Commit when green\n   - Repeat for each test\n\n6. **Refactor Continuously**\n   - Improve code design\n   - Maintain green tests\n   - Optimize performance\n   - Ensure test discoverability\n\n## Usage Examples\n\n```bash\n# Basic feature development\n/tdd-feature \"Add email validation to user registration\"\n# Tests will be placed in: tests/unit/test_user_validation.py\n\n# Complex feature with specific requirements\n/tdd-feature \"Implement shopping cart with discount rules, tax calculation, and inventory checking\"\n# Tests will be placed in: tests/unit/test_shopping_cart.py, tests/integration/test_cart_service.py\n\n# API endpoint development\n/tdd-feature \"Create REST API endpoint for user profile updates with validation\"\n# Tests will be placed in: tests/integration/test_user_profile_api.py\n\n# Background job implementation\n/tdd-feature \"Build async task processor for image resizing\"\n# Tests will be placed in: tests/unit/test_image_processor.py, tests/integration/test_async_tasks.py\n```\n\n## Output Format\n\nThe command will produce:\n\n1. **Test Suite First**\n   - Complete test file(s)\n   - Test fixtures\n   - Helper functions\n\n2. **Test Execution Report**\n   - Show all tests failing\n   - Clear failure messages\n\n3. **Implementation**\n   - Minimal passing code\n   - Clean architecture\n   - Documentation\n\n4. **Coverage Report**\n   - Line coverage\n   - Branch coverage\n   - Missing coverage areas\n\n5. **Refactoring Suggestions**\n   - Design improvements\n   - Performance optimizations\n   - Code quality enhancements\n\n## Quality Metrics\n\nTrack TDD success:\n- **Test-First Compliance**: 100% tests written before code\n- **Coverage**: Minimum 90% for new features\n- **Test Execution Time**: All tests under 10 seconds\n- **Test Reliability**: No flaky tests\n- **Refactoring Frequency**: At least once per feature\n- **Test Discoverability**: 100% of tests in standard locations\n- **Test Organization**: Proper categorization in unit/integration/e2e\n\n## Best Practices Enforced\n\n1. **No Code Without Tests**: Never write implementation before tests\n2. **Centralized Test Organization**: All tests in discoverable locations\n3. **One Assertion Per Test**: Keep tests focused\n4. **Descriptive Test Names**: Test names describe behavior\n5. **Independent Tests**: No test depends on another\n6. **Fast Tests**: Unit tests run in milliseconds\n7. **Deterministic Tests**: Same result every time\n8. **Proper Test Categorization**: Unit/Integration/E2E in separate directories\n\n## Integration Points\n\n- Works with @test-generator agent for centralized test placement\n- Triggers coverage analysis on tests/ directory\n- Updates documentation automatically\n- Creates git commits at each phase with proper test paths\n- Integrates with CI/CD pipelines using standard test discovery\n- Ensures test discoverability through centralized structure"
              }
            ],
            "skills": []
          },
          {
            "name": "agile-tools",
            "description": "Agile team roles: Scrum Master, Product Owner, Business Analyst, and Project Manager agents",
            "source": "./assets/claude-code-plugins/plugins/agile-tools",
            "category": "agile",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install agile-tools@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "ux-design",
            "description": "UX optimization and UI design tools with accessibility validation and WCAG compliance",
            "source": "./assets/claude-code-plugins/plugins/ux-design",
            "category": "design",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install ux-design@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "deployment",
            "description": "Deployment orchestration and compliance automation with progressive rollout strategies",
            "source": "./assets/claude-code-plugins/plugins/deployment",
            "category": "devops",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install deployment@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "code-analysis",
            "description": "Code archaeology and technology evaluation for legacy systems and technical debt assessment",
            "source": "./assets/claude-code-plugins/plugins/code-analysis",
            "category": "analysis",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock",
              "/plugin install code-analysis@aws-claude-code-plugins"
            ],
            "signals": {
              "stars": 103,
              "forks": 32,
              "pushed_at": "2026-01-08T06:36:26Z",
              "created_at": "2025-07-09T21:07:48Z",
              "license": "MIT-0"
            },
            "commands": [],
            "skills": []
          }
        ]
      }
    }
  ]
}