{
  "owner": {
    "id": "abossenbroek",
    "display_name": "Anton Bossenbroek",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/7729?u=f4f112fcda6a0d47c20d65583e64ac44a6a8033e&v=4",
    "url": "https://github.com/abossenbroek",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 11,
      "total_skills": 3,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "abossenbroek/abossenbroek-claude-plugins",
      "url": "https://github.com/abossenbroek/abossenbroek-claude-plugins",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-06T01:58:03Z",
        "created_at": "2025-12-31T03:56:10Z",
        "license": "BSD-3-Clause"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1666
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/ci.yml",
          "type": "blob",
          "size": 1618
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 4863
        },
        {
          "path": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2734
        },
        {
          "path": "CHANGELOG.md",
          "type": "blob",
          "size": 15995
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 23023
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1504
        },
        {
          "path": "context-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 1349
        },
        {
          "path": "context-engineering/README.md",
          "type": "blob",
          "size": 4245
        },
        {
          "path": "context-engineering/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/agents/audit-coordinator.md",
          "type": "blob",
          "size": 6059
        },
        {
          "path": "context-engineering/agents/improve-coordinator.md",
          "type": "blob",
          "size": 2967
        },
        {
          "path": "context-engineering/agents/plan-coordinator.md",
          "type": "blob",
          "size": 6070
        },
        {
          "path": "context-engineering/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/commands/audit-context.md",
          "type": "blob",
          "size": 2806
        },
        {
          "path": "context-engineering/commands/generate-handoffs.md",
          "type": "blob",
          "size": 3411
        },
        {
          "path": "context-engineering/commands/improve-plugin.md",
          "type": "blob",
          "size": 3115
        },
        {
          "path": "context-engineering/commands/optimize-plan.md",
          "type": "blob",
          "size": 2466
        },
        {
          "path": "context-engineering/coordinator-internal",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/coordinator-internal/audit-synthesizer.md",
          "type": "blob",
          "size": 5394
        },
        {
          "path": "context-engineering/coordinator-internal/context-flow-mapper.md",
          "type": "blob",
          "size": 4420
        },
        {
          "path": "context-engineering/coordinator-internal/context-optimizer.md",
          "type": "blob",
          "size": 5320
        },
        {
          "path": "context-engineering/coordinator-internal/grounding",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/coordinator-internal/grounding/challenger.md",
          "type": "blob",
          "size": 1355
        },
        {
          "path": "context-engineering/coordinator-internal/grounding/consistency-checker.md",
          "type": "blob",
          "size": 4743
        },
        {
          "path": "context-engineering/coordinator-internal/grounding/pattern-checker.md",
          "type": "blob",
          "size": 4668
        },
        {
          "path": "context-engineering/coordinator-internal/grounding/risk-assessor.md",
          "type": "blob",
          "size": 4254
        },
        {
          "path": "context-engineering/coordinator-internal/grounding/token-estimator.md",
          "type": "blob",
          "size": 4635
        },
        {
          "path": "context-engineering/coordinator-internal/handoff-improver.md",
          "type": "blob",
          "size": 6795
        },
        {
          "path": "context-engineering/coordinator-internal/improvement-synthesizer.md",
          "type": "blob",
          "size": 5484
        },
        {
          "path": "context-engineering/coordinator-internal/orchestration-improver.md",
          "type": "blob",
          "size": 7052
        },
        {
          "path": "context-engineering/coordinator-internal/phases",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/coordinator-internal/phases/analysis-executor.md",
          "type": "blob",
          "size": 2819
        },
        {
          "path": "context-engineering/coordinator-internal/phases/analyze-phase-executor.md",
          "type": "blob",
          "size": 1941
        },
        {
          "path": "context-engineering/coordinator-internal/phases/categorize-phase-executor.md",
          "type": "blob",
          "size": 1929
        },
        {
          "path": "context-engineering/coordinator-internal/phases/file-discovery-executor.md",
          "type": "blob",
          "size": 2935
        },
        {
          "path": "context-engineering/coordinator-internal/phases/ground-phase-executor.md",
          "type": "blob",
          "size": 3572
        },
        {
          "path": "context-engineering/coordinator-internal/phases/improve-phase-executor.md",
          "type": "blob",
          "size": 3056
        },
        {
          "path": "context-engineering/coordinator-internal/phases/synthesize-phase-executor.md",
          "type": "blob",
          "size": 2587
        },
        {
          "path": "context-engineering/coordinator-internal/plan-analyzer.md",
          "type": "blob",
          "size": 4701
        },
        {
          "path": "context-engineering/coordinator-internal/plugin-analyzer.md",
          "type": "blob",
          "size": 6993
        },
        {
          "path": "context-engineering/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/hooks/hooks.json",
          "type": "blob",
          "size": 269
        },
        {
          "path": "context-engineering/hooks/validate-agent-output.py",
          "type": "blob",
          "size": 8835
        },
        {
          "path": "context-engineering/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/scripts/file_cache.py",
          "type": "blob",
          "size": 15177
        },
        {
          "path": "context-engineering/scripts/state_manager.py",
          "type": "blob",
          "size": 11229
        },
        {
          "path": "context-engineering/scripts/validate_improvement_output.py",
          "type": "blob",
          "size": 5205
        },
        {
          "path": "context-engineering/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/skills/context-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/skills/context-engineering/SKILL.md",
          "type": "blob",
          "size": 4040
        },
        {
          "path": "context-engineering/skills/context-engineering/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/skills/context-engineering/references/context-tiers.md",
          "type": "blob",
          "size": 6339
        },
        {
          "path": "context-engineering/skills/context-engineering/references/examples.md",
          "type": "blob",
          "size": 5730
        },
        {
          "path": "context-engineering/skills/context-engineering/references/four-laws.md",
          "type": "blob",
          "size": 5775
        },
        {
          "path": "context-engineering/skills/context-engineering/references/handoff-protocols.md",
          "type": "blob",
          "size": 6230
        },
        {
          "path": "context-engineering/skills/orchestration-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/skills/orchestration-patterns/SKILL.md",
          "type": "blob",
          "size": 6279
        },
        {
          "path": "context-engineering/skills/orchestration-patterns/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/skills/orchestration-patterns/references/firewall-architecture.md",
          "type": "blob",
          "size": 6530
        },
        {
          "path": "context-engineering/skills/orchestration-patterns/references/phase-execution.md",
          "type": "blob",
          "size": 6126
        },
        {
          "path": "context-engineering/skills/orchestration-patterns/references/severity-batching.md",
          "type": "blob",
          "size": 6514
        },
        {
          "path": "context-engineering/skills/orchestration-patterns/references/validation-hooks.md",
          "type": "blob",
          "size": 7528
        },
        {
          "path": "context-engineering/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "context-engineering/templates/coordinator-agent.md",
          "type": "blob",
          "size": 2959
        },
        {
          "path": "context-engineering/templates/handoff-schema.yaml",
          "type": "blob",
          "size": 1934
        },
        {
          "path": "context-engineering/templates/hooks-config.json",
          "type": "blob",
          "size": 2057
        },
        {
          "path": "context-engineering/templates/pydantic-model.py",
          "type": "blob",
          "size": 3209
        },
        {
          "path": "context-engineering/templates/sub-agent.md",
          "type": "blob",
          "size": 1505
        },
        {
          "path": "pyproject.toml",
          "type": "blob",
          "size": 1875
        },
        {
          "path": "red-agent",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 1202
        },
        {
          "path": "red-agent/.jscpd.json",
          "type": "blob",
          "size": 343
        },
        {
          "path": "red-agent/CLAUDE.md",
          "type": "blob",
          "size": 2809
        },
        {
          "path": "red-agent/README.md",
          "type": "blob",
          "size": 15336
        },
        {
          "path": "red-agent/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/agents/fix-coordinator.md",
          "type": "blob",
          "size": 5979
        },
        {
          "path": "red-agent/agents/fix-orchestrator.md",
          "type": "blob",
          "size": 12705
        },
        {
          "path": "red-agent/agents/pal-availability-checker.md",
          "type": "blob",
          "size": 1434
        },
        {
          "path": "red-agent/agents/pr-analysis-coordinator.md",
          "type": "blob",
          "size": 18119
        },
        {
          "path": "red-agent/agents/red-team-coordinator.md",
          "type": "blob",
          "size": 8374
        },
        {
          "path": "red-agent/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/commands/pr-redteam-branch.md",
          "type": "blob",
          "size": 5925
        },
        {
          "path": "red-agent/commands/pr-redteam-diff.md",
          "type": "blob",
          "size": 4952
        },
        {
          "path": "red-agent/commands/pr-redteam-staged.md",
          "type": "blob",
          "size": 4783
        },
        {
          "path": "red-agent/commands/pr-redteam-working.md",
          "type": "blob",
          "size": 4854
        },
        {
          "path": "red-agent/commands/red-team-w-fix.md",
          "type": "blob",
          "size": 6991
        },
        {
          "path": "red-agent/commands/redteam-fix-orchestrator.md",
          "type": "blob",
          "size": 11847
        },
        {
          "path": "red-agent/commands/redteam.md",
          "type": "blob",
          "size": 3659
        },
        {
          "path": "red-agent/coordinator-internal",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/coordinator-internal/attack-strategist.md",
          "type": "blob",
          "size": 4297
        },
        {
          "path": "red-agent/coordinator-internal/change-scope-analyzer.md",
          "type": "blob",
          "size": 8710
        },
        {
          "path": "red-agent/coordinator-internal/code-context-attacker.md",
          "type": "blob",
          "size": 7828
        },
        {
          "path": "red-agent/coordinator-internal/code-reasoning-attacker.md",
          "type": "blob",
          "size": 8718
        },
        {
          "path": "red-agent/coordinator-internal/context-analyzer.md",
          "type": "blob",
          "size": 3979
        },
        {
          "path": "red-agent/coordinator-internal/context-attacker.md",
          "type": "blob",
          "size": 6901
        },
        {
          "path": "red-agent/coordinator-internal/diff-analyzer.md",
          "type": "blob",
          "size": 8489
        },
        {
          "path": "red-agent/coordinator-internal/duplicate-code-analyzer.md",
          "type": "blob",
          "size": 11323
        },
        {
          "path": "red-agent/coordinator-internal/fix-planner.md",
          "type": "blob",
          "size": 5796
        },
        {
          "path": "red-agent/coordinator-internal/fix",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/coordinator-internal/fix/fix-applicator.md",
          "type": "blob",
          "size": 2603
        },
        {
          "path": "red-agent/coordinator-internal/fix/fix-committer.md",
          "type": "blob",
          "size": 2003
        },
        {
          "path": "red-agent/coordinator-internal/fix/fix-phase-coordinator.md",
          "type": "blob",
          "size": 13432
        },
        {
          "path": "red-agent/coordinator-internal/fix/fix-planner-v2.md",
          "type": "blob",
          "size": 8637
        },
        {
          "path": "red-agent/coordinator-internal/fix/fix-reader.md",
          "type": "blob",
          "size": 6251
        },
        {
          "path": "red-agent/coordinator-internal/fix/fix-red-teamer.md",
          "type": "blob",
          "size": 10190
        },
        {
          "path": "red-agent/coordinator-internal/fix/fix-validator.md",
          "type": "blob",
          "size": 2592
        },
        {
          "path": "red-agent/coordinator-internal/grounding",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/coordinator-internal/grounding/alternative-explorer.md",
          "type": "blob",
          "size": 5380
        },
        {
          "path": "red-agent/coordinator-internal/grounding/calibrator.md",
          "type": "blob",
          "size": 5903
        },
        {
          "path": "red-agent/coordinator-internal/grounding/evidence-checker.md",
          "type": "blob",
          "size": 4186
        },
        {
          "path": "red-agent/coordinator-internal/grounding/proportion-checker.md",
          "type": "blob",
          "size": 5290
        },
        {
          "path": "red-agent/coordinator-internal/hallucination-prober.md",
          "type": "blob",
          "size": 6989
        },
        {
          "path": "red-agent/coordinator-internal/insight-synthesizer.md",
          "type": "blob",
          "size": 5209
        },
        {
          "path": "red-agent/coordinator-internal/pr-analysis-coordinator-sub.md",
          "type": "blob",
          "size": 6738
        },
        {
          "path": "red-agent/coordinator-internal/pr-insight-synthesizer.md",
          "type": "blob",
          "size": 8017
        },
        {
          "path": "red-agent/coordinator-internal/reasoning-attacker.md",
          "type": "blob",
          "size": 5846
        },
        {
          "path": "red-agent/coordinator-internal/scope-analyzer.md",
          "type": "blob",
          "size": 6632
        },
        {
          "path": "red-agent/coordinator-internal/security-prober.md",
          "type": "blob",
          "size": 9608
        },
        {
          "path": "red-agent/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/docs/README.md",
          "type": "blob",
          "size": 10158
        },
        {
          "path": "red-agent/docs/attack-taxonomy.md",
          "type": "blob",
          "size": 14080
        },
        {
          "path": "red-agent/docs/fix-orchestrator.md",
          "type": "blob",
          "size": 14447
        },
        {
          "path": "red-agent/docs/github-integration.md",
          "type": "blob",
          "size": 26857
        },
        {
          "path": "red-agent/docs/jscpd-security.md",
          "type": "blob",
          "size": 11877
        },
        {
          "path": "red-agent/docs/pal-integration.md",
          "type": "blob",
          "size": 11723
        },
        {
          "path": "red-agent/docs/troubleshooting.md",
          "type": "blob",
          "size": 12414
        },
        {
          "path": "red-agent/docs/ultrathink-architecture.md",
          "type": "blob",
          "size": 17913
        },
        {
          "path": "red-agent/docs/usage-guide.md",
          "type": "blob",
          "size": 12166
        },
        {
          "path": "red-agent/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/hooks/hooks.json",
          "type": "blob",
          "size": 371
        },
        {
          "path": "red-agent/hooks/validate-agent-output.py",
          "type": "blob",
          "size": 7440
        },
        {
          "path": "red-agent/package-lock.json",
          "type": "blob",
          "size": 46028
        },
        {
          "path": "red-agent/package.json",
          "type": "blob",
          "size": 392
        },
        {
          "path": "red-agent/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/skills/multi-agent-collaboration",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/skills/multi-agent-collaboration/SKILL.md",
          "type": "blob",
          "size": 5442
        },
        {
          "path": "red-agent/skills/multi-agent-collaboration/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/skills/multi-agent-collaboration/references/context-engineering.md",
          "type": "blob",
          "size": 13624
        },
        {
          "path": "red-agent/skills/multi-agent-collaboration/references/examples.md",
          "type": "blob",
          "size": 14435
        },
        {
          "path": "red-agent/skills/multi-agent-collaboration/references/patterns.md",
          "type": "blob",
          "size": 17928
        },
        {
          "path": "red-agent/skills/rainbow-teaming",
          "type": "tree",
          "size": null
        },
        {
          "path": "red-agent/skills/rainbow-teaming/SKILL.md",
          "type": "blob",
          "size": 5154
        },
        {
          "path": "schemas",
          "type": "tree",
          "size": null
        },
        {
          "path": "schemas/marketplace.schema.json",
          "type": "blob",
          "size": 3653
        },
        {
          "path": "schemas/plugin.schema.json",
          "type": "blob",
          "size": 2675
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/check_config_hygiene.py",
          "type": "blob",
          "size": 5065
        },
        {
          "path": "scripts/validate_against_claude_code.py",
          "type": "blob",
          "size": 4827
        },
        {
          "path": "scripts/validate_agent_files.py",
          "type": "blob",
          "size": 3311
        },
        {
          "path": "scripts/validate_plugin_schemas.py",
          "type": "blob",
          "size": 2750
        },
        {
          "path": "scripts/verify_npm_integrity.py",
          "type": "blob",
          "size": 1311
        },
        {
          "path": "src",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/context_engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/context_engineering/__init__.py",
          "type": "blob",
          "size": 1229
        },
        {
          "path": "src/context_engineering/models",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/context_engineering/models/__init__.py",
          "type": "blob",
          "size": 1733
        },
        {
          "path": "src/context_engineering/models/analysis_outputs.py",
          "type": "blob",
          "size": 4911
        },
        {
          "path": "src/context_engineering/models/enums.py",
          "type": "blob",
          "size": 3411
        },
        {
          "path": "src/context_engineering/models/grounding_outputs.py",
          "type": "blob",
          "size": 6927
        },
        {
          "path": "src/context_engineering/models/improvement_outputs.py",
          "type": "blob",
          "size": 5668
        },
        {
          "path": "src/context_engineering/models/state.py",
          "type": "blob",
          "size": 2915
        },
        {
          "path": "src/context_engineering/models/synthesis_outputs.py",
          "type": "blob",
          "size": 4411
        },
        {
          "path": "src/red_agent",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/red_agent/__init__.py",
          "type": "blob",
          "size": 183
        },
        {
          "path": "src/red_agent/models",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/red_agent/models/__init__.py",
          "type": "blob",
          "size": 4470
        },
        {
          "path": "src/red_agent/models/enums.py",
          "type": "blob",
          "size": 2174
        },
        {
          "path": "src/red_agent/models/findings.py",
          "type": "blob",
          "size": 2196
        },
        {
          "path": "src/red_agent/models/fix_orchestration.py",
          "type": "blob",
          "size": 2319
        },
        {
          "path": "src/red_agent/models/outputs.py",
          "type": "blob",
          "size": 14503
        },
        {
          "path": "src/red_agent/models/pr_analysis.py",
          "type": "blob",
          "size": 16106
        },
        {
          "path": "src/red_agent/models/reports.py",
          "type": "blob",
          "size": 2219
        },
        {
          "path": "src/red_agent/models/strategy.py",
          "type": "blob",
          "size": 1651
        },
        {
          "path": "src/red_agent/models/validators.py",
          "type": "blob",
          "size": 624
        },
        {
          "path": "src/red_agent/py.typed",
          "type": "blob",
          "size": null
        },
        {
          "path": "src/red_agent/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "src/red_agent/scripts/__init__.py",
          "type": "blob",
          "size": 48
        },
        {
          "path": "src/red_agent/scripts/validate_agent_output.py",
          "type": "blob",
          "size": 19376
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/__init__.py",
          "type": "blob",
          "size": 50
        },
        {
          "path": "tests/conftest.py",
          "type": "blob",
          "size": 25704
        },
        {
          "path": "tests/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/fixtures/pal_mock.py",
          "type": "blob",
          "size": 6294
        },
        {
          "path": "tests/test_check_config_hygiene.py",
          "type": "blob",
          "size": 6120
        },
        {
          "path": "tests/test_cli_check_config_hygiene.py",
          "type": "blob",
          "size": 9206
        },
        {
          "path": "tests/test_cli_validate_agent_output.py",
          "type": "blob",
          "size": 15546
        },
        {
          "path": "tests/test_context_engineering_analysis.py",
          "type": "blob",
          "size": 12633
        },
        {
          "path": "tests/test_context_engineering_grounding.py",
          "type": "blob",
          "size": 18108
        },
        {
          "path": "tests/test_context_engineering_models.py",
          "type": "blob",
          "size": 13592
        },
        {
          "path": "tests/test_context_engineering_state.py",
          "type": "blob",
          "size": 11922
        },
        {
          "path": "tests/test_context_engineering_synthesis.py",
          "type": "blob",
          "size": 11918
        },
        {
          "path": "tests/test_error_message_parsing.py",
          "type": "blob",
          "size": 10730
        },
        {
          "path": "tests/test_hook_output_format.py",
          "type": "blob",
          "size": 8538
        },
        {
          "path": "tests/test_hook_retry_flow.py",
          "type": "blob",
          "size": 10149
        },
        {
          "path": "tests/test_jscpd_availability.py",
          "type": "blob",
          "size": 999
        },
        {
          "path": "tests/test_pr_analysis.py",
          "type": "blob",
          "size": 23089
        },
        {
          "path": "tests/test_pydantic_models.py",
          "type": "blob",
          "size": 28981
        },
        {
          "path": "tests/test_validate_agent_files.py",
          "type": "blob",
          "size": 6835
        },
        {
          "path": "tests/test_validate_agent_output.py",
          "type": "blob",
          "size": 11871
        },
        {
          "path": "tests/test_validate_plugin_schemas.py",
          "type": "blob",
          "size": 4649
        },
        {
          "path": "uv.lock",
          "type": "blob",
          "size": 125577
        }
      ],
      "marketplace": {
        "name": "abossenbroek-claude-plugins",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "abossenbroek",
          "email": "abossenbroek@users.noreply.github.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "red-agent",
            "description": "Adversarial red/rainbow team analysis plugin for Claude Code. Finds weaknesses in LLM interactions through systematic probing using a 10x10 attack taxonomy (11 categories for PR analysis including code-duplication). Includes automated fix orchestrator with GitHub integration, PR analysis with 4 git modes, and comprehensive security documentation.",
            "source": "./red-agent",
            "category": "security",
            "version": "1.4.0",
            "author": {
              "name": "Red Agent Team",
              "email": "abossenbroek@users.noreply.github.com"
            },
            "install_commands": [
              "/plugin marketplace add abossenbroek/abossenbroek-claude-plugins",
              "/plugin install red-agent@abossenbroek-claude-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-06T01:58:03Z",
              "created_at": "2025-12-31T03:56:10Z",
              "license": "BSD-3-Clause"
            },
            "commands": [
              {
                "name": "/pr-redteam-branch",
                "description": null,
                "path": "red-agent/commands/pr-redteam-branch.md",
                "frontmatter": null,
                "content": "# /redteam-pr:branch Command\n\nAdversarial red team analysis of branch comparison for PR review.\n\n## Usage\n\n```\n/redteam-pr:branch <branch_spec> [mode]\n```\n\n## Arguments\n\n**branch_spec** (required):\n- Branch comparison specification\n- Format: `base...feature` or `base..feature`\n- Example: `/redteam-pr:branch main...feature-branch`\n\n**mode** (optional):\n- `quick` - Fast 2-3 vector analysis, skip grounding\n- `standard` - Balanced 5-6 vectors with basic grounding (default)\n- `deep` - All categories + meta-analysis with full grounding\n- `focus:[category]` - Deep dive on specific category (e.g., `focus:reasoning-flaws`)\n\n## Instructions\n\nYou are the MINIMAL entry point for PR red team analysis of branch comparisons. Your ONLY job is to:\n\n1. Execute git operations to compare branches\n2. Check PAL MCP availability (optional enhancement)\n3. Extract diff metadata, commit context, and build structured snapshot\n4. Launch the pr-analysis-coordinator agent with the snapshot\n5. Return the coordinator's output directly to the user\n\n### Step 1: Execute Git Operations\n\nUse the Bash tool to get branch comparison data:\n\n```bash\n# Get file statistics for branch comparison\ngit diff <branch_spec> --numstat\n\n# Get unified diff with 3 lines of context\ngit diff <branch_spec> -U3\n\n# Get commit log for context\ngit log --oneline <branch_spec>\n```\n\nReplace `<branch_spec>` with the provided argument (e.g., `main...feature`).\n\nIf the branches do not exist or comparison fails, inform the user and exit.\n\n### Step 2: Check PAL Availability (Non-Blocking)\n\nLaunch the pal-availability-checker agent to detect if PAL MCP is available:\n\n```\nTask: Launch pal-availability-checker agent\nAgent: agents/pal-availability-checker.md\nPrompt: Check if PAL MCP is available and list models\n```\n\nParse the YAML result and include `pal_available: true/false` in the snapshot.\nThis step is NON-BLOCKING - continue regardless of result. PAL is optional.\n\n### Step 3: Parse Mode\n\nDetermine mode from command arguments:\n- Default mode: `standard`\n\n### Step 4: Extract Diff Metadata\n\nParse the git output to build structured metadata:\n\n**From `git diff <branch_spec> --numstat`:**\n- Extract file paths, additions, deletions\n- Classify change_type: added, modified, deleted, renamed\n\n**From `git log --oneline <branch_spec>`:**\n- Extract commit hashes and messages\n- Count total commits in comparison\n\n**Calculate risk_score per file:**\n- Base score: 0.0\n- Authentication/security files (auth, security, permission in path): +0.4\n- Large changes (>100 lines added/deleted): +0.3\n- Test files (test, spec in path): -0.3\n- Clamp to [0.0, 1.0]\n\n**Classify pr_size:**\n- tiny: 1-2 files, <50 lines\n- small: 3-5 files, <200 lines\n- medium: 6-15 files, <500 lines\n- large: 16-30 files, <1000 lines\n- massive: >30 files or >1000 lines\n\n### Step 5: Build YAML Snapshot\n\nCreate a YAML-formatted snapshot with structured data:\n\n```yaml\nsnapshot:\n  mode: [parsed mode]\n  git_operation: \"branch_comparison\"\n  branch_spec: [the provided branch spec]\n  pal_available: [true/false from Step 2]\n  pal_models: [list of models if available, empty if not]\n\n  commit_context:\n    total_commits: [count]\n    commits:\n      - hash: [short hash]\n        message: [commit message]\n\n  diff_metadata:\n    pr_size: [tiny/small/medium/large/massive]\n    files_changed:\n      - path: [file path]\n        additions: [number]\n        deletions: [number]\n        change_type: [added/modified/deleted/renamed]\n        risk_score: [0.0-1.0]\n    total_additions: [sum]\n    total_deletions: [sum]\n    total_files: [count]\n\n  diff_output: |\n    [Full output from git diff <branch_spec> -U3]\n```\n\n### Step 6: User Scoping for Large PRs\n\nIf `pr_size` is \"large\" or \"massive\", use the AskUserQuestion tool to let the user scope the analysis:\n\n```\nQuestion: \"This PR has {total_files} files with {total_additions + total_deletions} lines changed across {total_commits} commits. How would you like to proceed?\"\n\nOptions:\n1. label: \"Analyze all files\"\n   description: \"Complete analysis of all changes. May take 2-5 minutes for massive PRs.\"\n\n2. label: \"High-risk files only [RECOMMENDED]\"\n   description: \"Focus on files with risk_score > 0.7. Faster and catches critical issues.\"\n\n3. label: \"Specific files/directories\"\n   description: \"You choose which files or directories to analyze.\"\n\n4. label: \"By commit\"\n   description: \"Analyze each commit individually instead of the full diff.\"\n```\n\nBased on the user's choice:\n- **Option 1**: Use all files from `diff_metadata.files_changed`\n- **Option 2**: Filter to only files where `risk_score > 0.7`\n- **Option 3**: Ask follow-up question: \"Which files or directories? (provide paths or globs like `src/auth/*`)\", then filter `files_changed` to match\n- **Option 4**: Change strategy to per-commit analysis:\n  - For each commit in `commit_context.commits`, get individual diff: `git diff <commit>^ <commit>`\n  - Launch coordinator separately for each commit with that commit's diff\n  - Aggregate reports from all commits\n\nFor options 1-3, update `diff_metadata.files_changed` with the filtered list before proceeding.\n\n### Step 7: Launch Coordinator\n\nUse the Task tool to launch a SINGLE agent (or multiple for option 4):\n\n```\nTask: Launch pr-analysis-coordinator agent\nAgent: agents/pr-analysis-coordinator.md\nPrompt: [Include the full YAML snapshot]\n```\n\n### Step 8: Return Output\n\nReturn the coordinator's markdown report DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include any \"I attacked X\" reasoning\n- Show intermediate findings\n\nONLY return the final sanitized markdown report.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and PR analysis work:\n\n- Main session context stays CLEAN\n- Only structured snapshot data passes to coordinator\n- Only sanitized markdown report returns to user\n- No adversarial prompts or attack reasoning enters main context\n"
              },
              {
                "name": "/pr-redteam-diff",
                "description": null,
                "path": "red-agent/commands/pr-redteam-diff.md",
                "frontmatter": null,
                "content": "# /redteam-pr:diff Command\n\nAdversarial red team analysis of a diff file for PR review.\n\n## Usage\n\n```\n/redteam-pr:diff <diff_file> [mode]\n```\n\n## Arguments\n\n**diff_file** (required):\n- Path to a diff or patch file to analyze\n- Example: `/redteam-pr:diff changes.patch`\n\n**mode** (optional):\n- `quick` - Fast 2-3 vector analysis, skip grounding\n- `standard` - Balanced 5-6 vectors with basic grounding (default)\n- `deep` - All categories + meta-analysis with full grounding\n- `focus:[category]` - Deep dive on specific category (e.g., `focus:reasoning-flaws`)\n\n## Instructions\n\nYou are the MINIMAL entry point for PR red team analysis of diff files. Your ONLY job is to:\n\n1. Read the diff file from the provided path\n2. Check PAL MCP availability (optional enhancement)\n3. Parse diff content and build structured snapshot\n4. Launch the pr-analysis-coordinator agent with the snapshot\n5. Return the coordinator's output directly to the user\n\n### Step 1: Read Diff File\n\nUse the Read tool to get the diff content from the provided file path.\n\nIf the file does not exist or cannot be read, inform the user and exit.\n\n### Step 2: Check PAL Availability (Non-Blocking)\n\nLaunch the pal-availability-checker agent to detect if PAL MCP is available:\n\n```\nTask: Launch pal-availability-checker agent\nAgent: agents/pal-availability-checker.md\nPrompt: Check if PAL MCP is available and list models\n```\n\nParse the YAML result and include `pal_available: true/false` in the snapshot.\nThis step is NON-BLOCKING - continue regardless of result. PAL is optional.\n\n### Step 3: Parse Mode\n\nDetermine mode from command arguments:\n- Default mode: `standard`\n\n### Step 4: Parse Diff Content\n\nParse the diff file to build structured metadata:\n\n**From unified diff format:**\n- Extract file paths from `--- a/...` and `+++ b/...` lines\n- Count additions (lines starting with `+`, excluding `+++`)\n- Count deletions (lines starting with `-`, excluding `---`)\n- Classify change_type: added, modified, deleted, renamed\n\n**Calculate risk_score per file:**\n- Base score: 0.0\n- Authentication/security files (auth, security, permission in path): +0.4\n- Large changes (>100 lines added/deleted): +0.3\n- Test files (test, spec in path): -0.3\n- Clamp to [0.0, 1.0]\n\n**Classify pr_size:**\n- tiny: 1-2 files, <50 lines\n- small: 3-5 files, <200 lines\n- medium: 6-15 files, <500 lines\n- large: 16-30 files, <1000 lines\n- massive: >30 files or >1000 lines\n\n### Step 5: Build YAML Snapshot\n\nCreate a YAML-formatted snapshot with structured data:\n\n```yaml\nsnapshot:\n  mode: [parsed mode]\n  git_operation: \"diff_file\"\n  source_file: [path to diff file]\n  pal_available: [true/false from Step 2]\n  pal_models: [list of models if available, empty if not]\n\n  diff_metadata:\n    pr_size: [tiny/small/medium/large/massive]\n    files_changed:\n      - path: [file path]\n        additions: [number]\n        deletions: [number]\n        change_type: [added/modified/deleted/renamed]\n        risk_score: [0.0-1.0]\n    total_additions: [sum]\n    total_deletions: [sum]\n    total_files: [count]\n\n  diff_output: |\n    [Full content of the diff file]\n```\n\n### Step 6: User Scoping for Large PRs\n\nIf `pr_size` is \"large\" or \"massive\", use the AskUserQuestion tool to let the user scope the analysis:\n\n```\nQuestion: \"This PR has {total_files} files with {total_additions + total_deletions} lines changed. How would you like to proceed?\"\n\nOptions:\n1. label: \"Analyze all files\"\n   description: \"Complete analysis of all changes. May take 2-5 minutes for massive PRs.\"\n\n2. label: \"High-risk files only [RECOMMENDED]\"\n   description: \"Focus on files with risk_score > 0.7. Faster and catches critical issues.\"\n\n3. label: \"Specific files/directories\"\n   description: \"You choose which files or directories to analyze.\"\n```\n\nBased on the user's choice:\n- **Option 1**: Use all files from `diff_metadata.files_changed`\n- **Option 2**: Filter to only files where `risk_score > 0.7`\n- **Option 3**: Ask follow-up question: \"Which files or directories? (provide paths or globs like `src/auth/*`)\", then filter `files_changed` to match\n\nUpdate `diff_metadata.files_changed` with the filtered list before proceeding.\n\n### Step 7: Launch Coordinator\n\nUse the Task tool to launch a SINGLE agent:\n\n```\nTask: Launch pr-analysis-coordinator agent\nAgent: agents/pr-analysis-coordinator.md\nPrompt: [Include the full YAML snapshot]\n```\n\n### Step 8: Return Output\n\nReturn the coordinator's markdown report DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include any \"I attacked X\" reasoning\n- Show intermediate findings\n\nONLY return the final sanitized markdown report.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and PR analysis work:\n\n- Main session context stays CLEAN\n- Only structured snapshot data passes to coordinator\n- Only sanitized markdown report returns to user\n- No adversarial prompts or attack reasoning enters main context\n"
              },
              {
                "name": "/pr-redteam-staged",
                "description": null,
                "path": "red-agent/commands/pr-redteam-staged.md",
                "frontmatter": null,
                "content": "# /redteam-pr:staged Command\n\nAdversarial red team analysis of staged git changes for PR review.\n\n## Usage\n\n```\n/redteam-pr:staged [mode]\n```\n\n## Arguments\n\n**mode** (optional):\n- `quick` - Fast 2-3 vector analysis, skip grounding\n- `standard` - Balanced 5-6 vectors with basic grounding (default)\n- `deep` - All categories + meta-analysis with full grounding\n- `focus:[category]` - Deep dive on specific category (e.g., `focus:reasoning-flaws`)\n\n## Instructions\n\nYou are the MINIMAL entry point for PR red team analysis of staged changes. Your ONLY job is to:\n\n1. Execute git operations to get staged changes\n2. Check PAL MCP availability (optional enhancement)\n3. Extract diff metadata and build structured snapshot\n4. Launch the pr-analysis-coordinator agent with the snapshot\n5. Return the coordinator's output directly to the user\n\n### Step 1: Execute Git Operations\n\nUse the Bash tool to get staged changes:\n\n```bash\n# Get file statistics\ngit diff --cached --numstat\n\n# Get unified diff with 3 lines of context\ngit diff --cached -U3\n```\n\nIf no staged changes exist, inform the user and exit.\n\n### Step 2: Check PAL Availability (Non-Blocking)\n\nLaunch the pal-availability-checker agent to detect if PAL MCP is available:\n\n```\nTask: Launch pal-availability-checker agent\nAgent: agents/pal-availability-checker.md\nPrompt: Check if PAL MCP is available and list models\n```\n\nParse the YAML result and include `pal_available: true/false` in the snapshot.\nThis step is NON-BLOCKING - continue regardless of result. PAL is optional.\n\n### Step 3: Parse Mode\n\nDetermine mode from command arguments:\n- Default mode: `standard`\n\n### Step 4: Extract Diff Metadata\n\nParse the git output to build structured metadata:\n\n**From `git diff --cached --numstat`:**\n- Extract file paths, additions, deletions\n- Classify change_type: added, modified, deleted, renamed\n\n**Calculate risk_score per file:**\n- Base score: 0.0\n- Authentication/security files (auth, security, permission in path): +0.4\n- Large changes (>100 lines added/deleted): +0.3\n- Test files (test, spec in path): -0.3\n- Clamp to [0.0, 1.0]\n\n**Classify pr_size:**\n- tiny: 1-2 files, <50 lines\n- small: 3-5 files, <200 lines\n- medium: 6-15 files, <500 lines\n- large: 16-30 files, <1000 lines\n- massive: >30 files or >1000 lines\n\n### Step 5: Build YAML Snapshot\n\nCreate a YAML-formatted snapshot with structured data:\n\n```yaml\nsnapshot:\n  mode: [parsed mode]\n  git_operation: \"staged\"\n  pal_available: [true/false from Step 2]\n  pal_models: [list of models if available, empty if not]\n\n  diff_metadata:\n    pr_size: [tiny/small/medium/large/massive]\n    files_changed:\n      - path: [file path]\n        additions: [number]\n        deletions: [number]\n        change_type: [added/modified/deleted/renamed]\n        risk_score: [0.0-1.0]\n    total_additions: [sum]\n    total_deletions: [sum]\n    total_files: [count]\n\n  diff_output: |\n    [Full output from git diff --cached -U3]\n```\n\n### Step 6: User Scoping for Large PRs\n\nIf `pr_size` is \"large\" or \"massive\", use the AskUserQuestion tool to let the user scope the analysis:\n\n```\nQuestion: \"This PR has {total_files} files with {total_additions + total_deletions} lines changed. How would you like to proceed?\"\n\nOptions:\n1. label: \"Analyze all files\"\n   description: \"Complete analysis of all changes. May take 2-5 minutes for massive PRs.\"\n\n2. label: \"High-risk files only [RECOMMENDED]\"\n   description: \"Focus on files with risk_score > 0.7. Faster and catches critical issues.\"\n\n3. label: \"Specific files/directories\"\n   description: \"You choose which files or directories to analyze.\"\n```\n\nBased on the user's choice:\n- **Option 1**: Use all files from `diff_metadata.files_changed`\n- **Option 2**: Filter to only files where `risk_score > 0.7`\n- **Option 3**: Ask follow-up question: \"Which files or directories? (provide paths or globs like `src/auth/*`)\", then filter `files_changed` to match\n\nUpdate `diff_metadata.files_changed` with the filtered list before proceeding.\n\n### Step 7: Launch Coordinator\n\nUse the Task tool to launch a SINGLE agent:\n\n```\nTask: Launch pr-analysis-coordinator agent\nAgent: agents/pr-analysis-coordinator.md\nPrompt: [Include the full YAML snapshot]\n```\n\n### Step 8: Return Output\n\nReturn the coordinator's markdown report DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include any \"I attacked X\" reasoning\n- Show intermediate findings\n\nONLY return the final sanitized markdown report.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and PR analysis work:\n\n- Main session context stays CLEAN\n- Only structured snapshot data passes to coordinator\n- Only sanitized markdown report returns to user\n- No adversarial prompts or attack reasoning enters main context\n"
              },
              {
                "name": "/pr-redteam-working",
                "description": null,
                "path": "red-agent/commands/pr-redteam-working.md",
                "frontmatter": null,
                "content": "# /redteam-pr:working Command\n\nAdversarial red team analysis of working directory changes for PR review.\n\n## Usage\n\n```\n/redteam-pr:working [mode]\n```\n\n## Arguments\n\n**mode** (optional):\n- `quick` - Fast 2-3 vector analysis, skip grounding\n- `standard` - Balanced 5-6 vectors with basic grounding (default)\n- `deep` - All categories + meta-analysis with full grounding\n- `focus:[category]` - Deep dive on specific category (e.g., `focus:reasoning-flaws`)\n\n## Instructions\n\nYou are the MINIMAL entry point for PR red team analysis of working directory changes. Your ONLY job is to:\n\n1. Execute git operations to get working directory changes\n2. Check PAL MCP availability (optional enhancement)\n3. Extract diff metadata and build structured snapshot\n4. Launch the pr-analysis-coordinator agent with the snapshot\n5. Return the coordinator's output directly to the user\n\n### Step 1: Execute Git Operations\n\nUse the Bash tool to get working directory changes (unstaged):\n\n```bash\n# Get file statistics for working directory\ngit diff HEAD --numstat\n\n# Get unified diff with 3 lines of context\ngit diff HEAD -U3\n```\n\nIf no working directory changes exist, inform the user and exit.\n\n### Step 2: Check PAL Availability (Non-Blocking)\n\nLaunch the pal-availability-checker agent to detect if PAL MCP is available:\n\n```\nTask: Launch pal-availability-checker agent\nAgent: agents/pal-availability-checker.md\nPrompt: Check if PAL MCP is available and list models\n```\n\nParse the YAML result and include `pal_available: true/false` in the snapshot.\nThis step is NON-BLOCKING - continue regardless of result. PAL is optional.\n\n### Step 3: Parse Mode\n\nDetermine mode from command arguments:\n- Default mode: `standard`\n\n### Step 4: Extract Diff Metadata\n\nParse the git output to build structured metadata:\n\n**From `git diff HEAD --numstat`:**\n- Extract file paths, additions, deletions\n- Classify change_type: added, modified, deleted, renamed\n\n**Calculate risk_score per file:**\n- Base score: 0.0\n- Authentication/security files (auth, security, permission in path): +0.4\n- Large changes (>100 lines added/deleted): +0.3\n- Test files (test, spec in path): -0.3\n- Clamp to [0.0, 1.0]\n\n**Classify pr_size:**\n- tiny: 1-2 files, <50 lines\n- small: 3-5 files, <200 lines\n- medium: 6-15 files, <500 lines\n- large: 16-30 files, <1000 lines\n- massive: >30 files or >1000 lines\n\n### Step 5: Build YAML Snapshot\n\nCreate a YAML-formatted snapshot with structured data:\n\n```yaml\nsnapshot:\n  mode: [parsed mode]\n  git_operation: \"working\"\n  pal_available: [true/false from Step 2]\n  pal_models: [list of models if available, empty if not]\n\n  diff_metadata:\n    pr_size: [tiny/small/medium/large/massive]\n    files_changed:\n      - path: [file path]\n        additions: [number]\n        deletions: [number]\n        change_type: [added/modified/deleted/renamed]\n        risk_score: [0.0-1.0]\n    total_additions: [sum]\n    total_deletions: [sum]\n    total_files: [count]\n\n  diff_output: |\n    [Full output from git diff HEAD -U3]\n```\n\n### Step 6: User Scoping for Large PRs\n\nIf `pr_size` is \"large\" or \"massive\", use the AskUserQuestion tool to let the user scope the analysis:\n\n```\nQuestion: \"This PR has {total_files} files with {total_additions + total_deletions} lines changed. How would you like to proceed?\"\n\nOptions:\n1. label: \"Analyze all files\"\n   description: \"Complete analysis of all changes. May take 2-5 minutes for massive PRs.\"\n\n2. label: \"High-risk files only [RECOMMENDED]\"\n   description: \"Focus on files with risk_score > 0.7. Faster and catches critical issues.\"\n\n3. label: \"Specific files/directories\"\n   description: \"You choose which files or directories to analyze.\"\n```\n\nBased on the user's choice:\n- **Option 1**: Use all files from `diff_metadata.files_changed`\n- **Option 2**: Filter to only files where `risk_score > 0.7`\n- **Option 3**: Ask follow-up question: \"Which files or directories? (provide paths or globs like `src/auth/*`)\", then filter `files_changed` to match\n\nUpdate `diff_metadata.files_changed` with the filtered list before proceeding.\n\n### Step 7: Launch Coordinator\n\nUse the Task tool to launch a SINGLE agent:\n\n```\nTask: Launch pr-analysis-coordinator agent\nAgent: agents/pr-analysis-coordinator.md\nPrompt: [Include the full YAML snapshot]\n```\n\n### Step 8: Return Output\n\nReturn the coordinator's markdown report DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include any \"I attacked X\" reasoning\n- Show intermediate findings\n\nONLY return the final sanitized markdown report.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and PR analysis work:\n\n- Main session context stays CLEAN\n- Only structured snapshot data passes to coordinator\n- Only sanitized markdown report returns to user\n- No adversarial prompts or attack reasoning enters main context\n"
              },
              {
                "name": "/red-team-w-fix",
                "description": null,
                "path": "red-agent/commands/red-team-w-fix.md",
                "frontmatter": null,
                "content": "# /redteam-w-fix Command\n\nRed team analysis with interactive fix selection. Identifies issues, generates fix options, and lets you choose which fixes to apply.\n\n## Usage\n\n```\n/redteam-w-fix [mode] [target]\n```\n\n## Arguments\n\n**mode** (optional):\n- `quick` - Fast 2-3 vector analysis, skip grounding\n- `standard` - Balanced 5-6 vectors with basic grounding (default)\n- `deep` - All categories + meta-analysis with full grounding\n- `focus:[category]` - Deep dive on specific category (e.g., `focus:reasoning-flaws`)\n\n**target** (optional):\n- `conversation` - Current conversation context (default)\n- `file:path` - Analyze specific file\n- `code` - Analyze recent git changes\n\n## Instructions\n\nYou are the entry point for red team analysis with fix planning. Your job is to:\n\n1. Check PAL MCP availability (optional enhancement)\n2. Parse the mode and target from arguments\n3. Extract a structured context snapshot\n4. Launch the fix-coordinator to get findings with fix options\n5. Present an interactive menu for fix selection\n6. Generate an implementation summary based on selections\n\n### Step 1: Check PAL Availability (Non-Blocking)\n\nLaunch the pal-availability-checker agent to detect if PAL MCP is available:\n\n```\nTask: Launch pal-availability-checker agent\nAgent: agents/pal-availability-checker.md\nPrompt: Check if PAL MCP is available and list models\n```\n\nParse the YAML result and include `pal_available: true/false` in the snapshot.\nThis step is NON-BLOCKING - continue regardless of result. PAL is optional.\n\n### Step 2: Parse Arguments\n\nDetermine mode and target from the command arguments:\n- Default mode: `standard`\n- Default target: `conversation`\n\n### Step 3: Extract Context Snapshot\n\nCreate a YAML-formatted snapshot of the current session. DO NOT include raw conversation - structure it as data:\n\n```yaml\nsnapshot:\n  mode: [parsed mode]\n  target: [parsed target]\n  pal_available: [true/false from Step 1]\n  pal_models: [list of models if available, empty if not]\n\n  conversational_arc:\n    message_count: [count of messages in conversation]\n    phases:\n      - phase: \"[phase name]\"\n        messages: [range]\n        summary: \"[what happened in this phase]\"\n    key_transitions:\n      - from_msg: [number]\n        to_msg: [number]\n        note: \"[what changed and why]\"\n    early_assumptions_carried_forward:\n      - assumption: \"[assumption text]\"\n        introduced_at: [message number]\n        still_active: [true/false]\n\n  claims:\n    - id: C[N]\n      text: \"[factual claim made by assistant]\"\n      speaker: assistant\n      confidence: [stated_as_fact|hedged|uncertain]\n      message_num: [source message number]\n\n  files_read:\n    - path: [file path]\n      summary: \"[brief description of content/purpose]\"\n\n  tools_invoked:\n    - tool: [tool name]\n      command: \"[command or action]\"\n      outcome: \"[result summary]\"\n\n  decisions:\n    - decision: \"[decision made]\"\n      rationale: \"[stated reason]\"\n\n  assumptions_explicit:\n    - \"[explicitly stated assumption]\"\n```\n\n### Step 4: Launch Fix Coordinator\n\nUse the Task tool to launch the fix-coordinator agent:\n\n```\nTask: Launch fix-coordinator agent\nAgent: agents/fix-coordinator.md\nPrompt: [Include the full YAML snapshot]\n```\n\nThe coordinator will:\n- Run red team analysis\n- Filter findings (CRITICAL, HIGH, MEDIUM only)\n- Generate fix options for each finding\n- Return structured YAML with `findings_with_fixes`\n\n### Step 5: Present Fix Selection Menu\n\nParse the coordinator's YAML output. For each finding, present a question using AskUserQuestion.\n\n**Batching Rule**: AskUserQuestion supports max 4 questions per call.\n- **Batch 1**: CRITICAL and HIGH severity findings (up to 4)\n- **Batch 2**: Remaining HIGH and MEDIUM findings (up to 4)\n- Continue until all findings are addressed\n\nFor each finding, create a question:\n\n```\nAskUserQuestion(questions=[\n    {\n        \"question\": \"[finding_id]: [finding_title]\\nSeverity: [severity] | How should we fix this?\",\n        \"header\": \"[finding_id]\",  # Max 12 chars\n        \"multiSelect\": false,\n        \"options\": [\n            {\n                \"label\": \"[option_a_label]\",\n                \"description\": \"[option_a_description - first 100 chars]\"\n            },\n            {\n                \"label\": \"[option_b_label]\",\n                \"description\": \"[option_b_description - first 100 chars]\"\n            },\n            # ... up to 3 options\n        ]\n    },\n    # ... up to 4 questions per batch\n])\n```\n\nThe \"Other\" option is automatically included by AskUserQuestion.\n\nAfter each batch, if more findings remain, call AskUserQuestion again.\n\n### Step 6: Generate Implementation Summary\n\nBased on user selections, generate an expert end-user summary.\n\nFormat:\n\n```markdown\n# Red Team Fixes - Selected Actions\n\n## Summary\n[N] issues addressed | Touches: [list of affected components]\n\n---\n\n## [finding_id]: [finding_title]\n\n**Issue**: [Brief description of the problem and its risk]\n\n**Selected fix**: [Selected option label]\n\n**What changes**:\n- [Change 1]\n- [Change 2]\n- [Change 3]\n\n**Why this over alternatives**:\n[Brief explanation of why this option was selected over others]\n\n**Watch out for**: [Any risks or things to test]\n\n---\n\n[Repeat for each selected fix]\n\n---\n\n## Suggested Order\n1. [First thing to do]\n2. [Second thing to do]\n3. [Continue...]\n```\n\nIf the user selected \"Other\" for any finding, include their custom input in the summary.\n\n### Step 7: Return Output\n\nReturn the implementation summary DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the agents did\n- Include raw YAML output\n- Show intermediate findings\n\nONLY return the final implementation summary.\n\n## Context Isolation Rules\n\nThis command is the BRIDGE between main session and red team work:\n\n- Main session context stays CLEAN\n- Only structured snapshot data passes to coordinator\n- Fix options return as structured YAML\n- Menu interaction happens in main context (safe)\n- Only sanitized summary returns to user\n\n## Error Handling\n\nIf the coordinator returns no findings:\n```markdown\n# Red Team Analysis Complete\n\nNo issues at CRITICAL, HIGH, or MEDIUM severity were identified.\n\nThe analysis found [N] LOW/INFO level observations which don't require fixes.\nRun `/redteam` for the full report if interested.\n```\n\nIf a batch of questions returns with all \"skip\" or empty responses:\n- Continue to next batch\n- Note skipped findings in summary\n\n## Example Flow\n\n1. User runs: `/redteam-w-fix standard`\n2. Command builds snapshot, launches coordinator\n3. Coordinator returns 3 findings with fix options\n4. Command presents menu:\n   ```\n   [RF-001] [AG-002] [CM-003]\n\n   RF-001: Invalid inference in auth\n   Severity: HIGH | How should we fix this?\n\n    A: Add validation [LOW]\n    B: Refactor flow [MEDIUM]\n    C: Type-safe handlers [HIGH]\n    Other\n   ```\n5. User selects B for RF-001, A for AG-002, Other (\"Just add logging\") for CM-003\n6. Command generates summary with all selections\n7. User receives actionable implementation summary\n"
              },
              {
                "name": "/redteam-fix-orchestrator",
                "description": null,
                "path": "red-agent/commands/redteam-fix-orchestrator.md",
                "frontmatter": null,
                "content": "# /redteam-fix-orchestrator Command\n\nRed team analysis fix orchestration with automated execution. Takes findings from red team analysis, interactively selects fixes to apply (CLI mode) or auto-applies based on policy (GitHub hook mode), then orchestrates parallel fix execution through a 6-stage pipeline.\n\n## Usage\n\n```\n/redteam-fix-orchestrator [findings-source] [options]\n```\n\n## Arguments\n\n**findings-source** (optional):\n- `last` - Use findings from most recent `/redteam` run (default)\n- `file:path` - Load findings from YAML file at specified path\n\n**options** (optional):\n- `--auto` - Force automated mode even in CLI (use default policy)\n- `--max-parallel=N` - Limit concurrent fix phases (default: 4)\n- `--commit-strategy=per-fix|per-phase` - Git commit granularity (default: per-fix)\n\n## Instructions\n\nYou are the entry point for red team fix orchestration. Your job is to:\n\n1. Check PAL MCP availability (optional enhancement)\n2. Detect execution mode (interactive CLI vs GitHub hook)\n3. Load findings from source\n4. Launch the fix-orchestrator agent\n5. Handle interactive fix selection (if CLI mode)\n6. Return execution summary\n\n### Step 1: Check PAL Availability (Non-Blocking)\n\nLaunch the pal-availability-checker agent to detect if PAL MCP is available:\n\n```\nTask: Launch pal-availability-checker agent\nAgent: agents/pal-availability-checker.md\nPrompt: Check if PAL MCP is available and list models\n```\n\nParse the YAML result and extract `pal_available: true/false`.\n\n**This step is NON-BLOCKING** - if PAL check fails or times out, continue with `pal_available: false`. PAL is optional enhancement, not required.\n\n### Step 2: Detect Execution Mode\n\nCheck the `CLAUDE_CODE_REMOTE` environment variable to determine execution mode:\n\n**Interactive CLI Mode**:\n- `CLAUDE_CODE_REMOTE` is unset or empty\n- Use AskUserQuestion for fix selection\n- Return implementation summary\n\n**GitHub Hook Mode**:\n- `CLAUDE_CODE_REMOTE` equals \"true\"\n- Load policy from `.claude/fix-policy.yaml`\n- Auto-select fixes based on policy\n- Return summary formatted for PR comment\n- **CRITICAL**: Create local commits only, do NOT push to remote\n\nIf `--auto` flag is provided, force GitHub Hook Mode regardless of environment variable.\n\n### Step 3: Load Fix Policy (GitHub Hook Mode Only)\n\nIf in GitHub Hook Mode, attempt to load fix policy:\n\n**Policy file path**: `.claude/fix-policy.yaml`\n\nExpected format:\n```yaml\nfix_policy:\n  auto_fix:\n    CRITICAL: \"balanced\"  # Which option to auto-apply: minimal | balanced | comprehensive\n    HIGH: \"minimal\"\n    MEDIUM: \"skip\"\n    LOW: \"skip\"\n\n  constraints:\n    max_files_per_fix: 5\n    max_total_fixes: 10\n    require_tests: true\n\n  commit_strategy: \"per-fix\"  # per-fix | per-phase\n```\n\n**If policy file doesn't exist**, use default policy:\n```yaml\nfix_policy:\n  auto_fix:\n    CRITICAL: \"balanced\"\n    HIGH: \"minimal\"\n    MEDIUM: \"skip\"\n    LOW: \"skip\"\n  constraints:\n    max_files_per_fix: 5\n    max_total_fixes: 10\n    require_tests: true\n  commit_strategy: \"per-fix\"\n```\n\n### Step 4: Load Findings from Source\n\nParse the `findings-source` argument:\n\n**If \"last\" (default)**:\n- Look for most recent findings in session context\n- Findings should be from previous `/redteam` command output\n- Parse the markdown report to extract findings with IDs, titles, severity, evidence\n\n**If \"file:path\"**:\n- Read YAML file at specified path\n- Expected format:\n  ```yaml\n  findings:\n    - id: RF-001\n      title: \"Finding title\"\n      severity: CRITICAL\n      category: reasoning-flaws\n      evidence: \"Evidence text\"\n      impact: \"Impact description\"\n      recommendation: \"Recommendation\"\n  ```\n\n**Error handling**:\n- If no findings found, return:\n  ```markdown\n  # Red Team Fix Orchestrator\n\n  No findings available to fix. Please run `/redteam` first to generate findings.\n  ```\n\n### Step 5: Launch Fix Orchestrator Agent\n\nCreate structured input for the fix-orchestrator agent:\n\n```yaml\norchestrator_input:\n  findings: [list of finding summaries]\n  mode: interactive | auto\n  pal_available: [true/false from Step 1]\n  policy: [policy object if auto mode, omit if interactive]\n  commit_strategy: [per-fix | per-phase from args or policy]\n  max_parallel: [N from args or default 4]\n```\n\nLaunch the orchestrator:\n\n```\nTask: Launch fix-orchestrator agent\nAgent: agents/fix-orchestrator.md\nModel: opus\nPrompt: [YAML orchestrator_input]\n```\n\nThe orchestrator will:\n- Analyze dependencies\n- Group findings into phases\n- Either return question_batches (interactive) or execute immediately (auto)\n\n### Step 6: Handle Interactive Fix Selection (CLI Mode Only)\n\nIf mode is interactive, the orchestrator returns `question_batches` for user selection.\n\nFor each batch in `question_batches`:\n\n**Present questions using AskUserQuestion**:\n- Max 4 questions per batch\n- Grouped by severity (CRITICAL_HIGH first, then MEDIUM)\n- Each question offers fix options A/B/C plus \"Other\"\n\n```\nAskUserQuestion(questions=[\n    {\n        \"question\": \"[finding_id]: [finding_title]\\nSeverity: [severity] | How should we fix this?\",\n        \"header\": \"[finding_id]\",\n        \"multiSelect\": false,\n        \"options\": [\n            {\n                \"label\": \"A: [option_a_label]\",\n                \"description\": \"[option_a_description]\"\n            },\n            {\n                \"label\": \"B: [option_b_label]\",\n                \"description\": \"[option_b_description]\"\n            },\n            {\n                \"label\": \"C: [option_c_label]\",\n                \"description\": \"[option_c_description]\"\n            }\n        ]\n    },\n    # ... up to 4 questions per batch\n])\n```\n\n**Process user selections**:\n- Map question headers (finding IDs) to selected options\n- If user selects \"Other\", use their custom input\n- If user skips (no selection), exclude from fixes\n\nAfter all batches are presented, send user selections back to orchestrator:\n\n```yaml\nuser_selections:\n  - finding_id: RF-001\n    selected_option: B\n  - finding_id: AG-003\n    selected_option: A\n    custom_input: null\n  - finding_id: CM-005\n    selected_option: skip\n```\n\nOrchestrator will proceed with fix execution for selected findings.\n\n### Step 7: Return Execution Summary\n\nAfter the orchestrator completes (either interactively or automatically), it returns an `execution_summary`:\n\n```yaml\nexecution_summary:\n  total_findings: 8\n  selected_for_fix: 3\n  phases_executed: 2\n  successful_fixes:\n    - finding_id: RF-001\n      selected_option: B\n      commit_hash: abc123f\n      files_changed: [AuthController.ts, ValidationMiddleware.ts]\n      validation: success\n    - finding_id: AG-003\n      selected_option: A\n      commit_hash: def456a\n      files_changed: [RoleMiddleware.ts]\n      validation: success\n  failed_fixes:\n    - finding_id: CM-005\n      selected_option: B\n      error: \"Validation failed after 2 retries: Type errors in contextProcessor.ts\"\n      revert_command: \"git revert def456a\"\n  skipped_fixes:\n    - finding_id: AG-007\n      reason: \"Severity MEDIUM below policy threshold\"\n  commits_created: [abc123f, def456a]\n```\n\n**Format output based on mode**:\n\n#### Interactive CLI Mode:\n```markdown\n# Red Team Fix Orchestration Complete\n\n## Summary\n[N] findings analyzed | [M] fixes applied | [P] commits created\n\n---\n\n## Successfully Applied\n\n### RF-001: Invalid inference in authentication (CRITICAL)\n**Fix applied**: B: Input validation layer\n**Files changed**: AuthController.ts, ValidationMiddleware.ts\n**Commit**: `abc123f`\n**Validation**:  All checks passed\n\n[Repeat for each successful fix]\n\n---\n\n## Failed Fixes\n\n### CM-005: Context manipulation (MEDIUM)\n**Attempted fix**: B: Context isolation\n**Error**: Validation failed after 2 retries: Type errors in contextProcessor.ts\n**Revert**: `git revert def456a`\n**Next steps**: Review type errors manually\n\n[Repeat for each failed fix]\n\n---\n\n## Skipped\n\n- **AG-007**: Severity MEDIUM below policy threshold\n\n---\n\n**Next steps**:\n1. Review commits: `git log --oneline -[P]`\n2. Run full test suite: `npm test` (or appropriate command)\n3. Review failed fixes manually if any\n```\n\n#### GitHub Hook Mode:\n```markdown\n## Red Agent Fix Report\n\n**Findings analyzed**: [N]\n**Fixes applied**: [M]\n**Commits created**: [P]\n\n### Applied Fixes\n\n####  RF-001: Invalid inference in authentication (CRITICAL)\n- **Fix applied**: B: Input validation layer\n- **Files changed**: AuthController.ts, ValidationMiddleware.ts\n- **Commit**: `abc123f`\n- **Tests**:  Passed\n\n[Repeat for each successful fix]\n\n### Failed Fixes\n\n####  CM-005: Context manipulation (MEDIUM)\n- **Attempted fix**: B: Context isolation\n- **Error**: Validation failed after 2 retries\n- **Revert**: `git revert def456a`\n\n[Repeat for each failed fix]\n\n### Skipped Fixes\n\n####  AG-007: Hidden assumption (MEDIUM)\n- **Reason**: Severity below auto-fix threshold per policy\n\n---\nGenerated by [Claude Code Red Agent](https://github.com/anthropics/claude-code)\n```\n\n## Context Isolation Rules\n\nThis command is the BRIDGE between main session and fix orchestration:\n\n- Main session context stays CLEAN\n- Only structured snapshot data passes to orchestrator\n- Fix execution isolated in orchestrator context\n- Only sanitized summary returns to user\n- No adversarial reasoning enters main session\n\n## Error Handling\n\n**If orchestrator returns no fixable findings**:\n```markdown\n# Red Team Fix Orchestrator\n\nNo fixable findings at CRITICAL, HIGH, or MEDIUM severity were identified.\n\nRun `/redteam` with a different mode or target to generate findings.\n```\n\n**If orchestrator fails**:\n```markdown\n# Red Team Fix Orchestrator - Error\n\nThe fix orchestrator encountered an error: [error message]\n\nPlease check:\n1. Findings source is valid\n2. Policy file format is correct (if using GitHub hook mode)\n3. Git working directory is clean\n\nYou can retry with: `/redteam-fix-orchestrator [args]`\n```\n\n**If policy file is malformed (GitHub hook mode)**:\n```markdown\n# Red Team Fix Orchestrator - Policy Error\n\nFailed to load fix policy from `.claude/fix-policy.yaml`:\n[Parse error details]\n\nUsing default policy instead.\n\n[Continue with execution]\n```\n\n## Critical Rules\n\n1. **NO DIRECT FIXING** - This command never applies fixes directly, only orchestrates\n2. **MODE DETECTION** - Always check CLAUDE_CODE_REMOTE for execution mode\n3. **NO AUTO-PUSH** - In GitHub hook mode, create local commits only, never push\n4. **PAL OPTIONAL** - PAL availability check must not block execution\n5. **CLEAN CONTEXT** - Keep main session context clean, pass structured data only\n6. **PRESERVE FINDING IDS** - Use exact finding IDs from red team analysis\n7. **COMPLETE SUMMARY** - Return full results including successful, failed, and skipped fixes\n\n## Example Flows\n\n### Example 1: Interactive CLI\n\nUser runs: `/redteam-fix-orchestrator last`\n\n1. PAL check: available=true\n2. Mode: interactive (CLAUDE_CODE_REMOTE not set)\n3. Load findings from last `/redteam` run: 5 findings\n4. Launch orchestrator with mode=interactive\n5. Orchestrator returns 2 question batches\n6. Present batch 1 (CRITICAL+HIGH): 3 questions\n7. User selects: RF-001B, AG-002A, CM-003skip\n8. Present batch 2 (MEDIUM): 2 questions\n9. User selects: RF-004A, AG-005Other(\"Add logging\")\n10. Send selections to orchestrator\n11. Orchestrator executes: 4 fixes in 2 phases\n12. Return summary: 3 successful, 1 failed, 1 skipped\n\n### Example 2: GitHub Hook\n\nGitHub Action runs: `/redteam-fix-orchestrator file:findings.yaml --auto`\n\n1. PAL check: available=false (no MCP in CI)\n2. Mode: auto (--auto flag)\n3. Load policy from `.claude/fix-policy.yaml`\n4. Load findings from findings.yaml: 8 findings\n5. Launch orchestrator with mode=auto, policy\n6. Orchestrator auto-selects based on policy\n7. Orchestrator executes: 3 fixes in 2 phases\n8. Creates commits: abc123f, def456a, ghi789c (local only, no push)\n9. Return PR comment format summary\n10. Separate GitHub Action step handles push (optional)\n"
              },
              {
                "name": "/redteam",
                "description": null,
                "path": "red-agent/commands/redteam.md",
                "frontmatter": null,
                "content": "# /redteam Command\n\nAdversarial red team analysis of the current conversation or specified target.\n\n## Usage\n\n```\n/redteam [mode] [target]\n```\n\n## Arguments\n\n**mode** (optional):\n- `quick` - Fast 2-3 vector analysis, skip grounding\n- `standard` - Balanced 5-6 vectors with basic grounding (default)\n- `deep` - All categories + meta-analysis with full grounding\n- `focus:[category]` - Deep dive on specific category (e.g., `focus:reasoning-flaws`)\n\n**target** (optional):\n- `conversation` - Current conversation context (default)\n- `file:path` - Analyze specific file\n- `code` - Analyze recent git changes\n\n## Instructions\n\nYou are the MINIMAL entry point for red team analysis. Your ONLY job is to:\n\n1. Check PAL MCP availability (optional enhancement)\n2. Parse the mode and target from arguments\n3. Extract a structured context snapshot\n4. Launch the red-team-coordinator agent with the snapshot\n5. Return the coordinator's output directly to the user\n\n### Step 1: Check PAL Availability (Non-Blocking)\n\nLaunch the pal-availability-checker agent to detect if PAL MCP is available:\n\n```\nTask: Launch pal-availability-checker agent\nAgent: agents/pal-availability-checker.md\nPrompt: Check if PAL MCP is available and list models\n```\n\nParse the YAML result and include `pal_available: true/false` in the snapshot.\nThis step is NON-BLOCKING - continue regardless of result. PAL is optional.\n\n### Step 2: Parse Arguments\n\nDetermine mode and target from the command arguments:\n- Default mode: `standard`\n- Default target: `conversation`\n\n### Step 3: Extract Context Snapshot\n\nCreate a YAML-formatted snapshot of the current session. DO NOT include raw conversation - structure it as data:\n\n```yaml\nsnapshot:\n  mode: [parsed mode]\n  target: [parsed target]\n  pal_available: [true/false from Step 1]\n  pal_models: [list of models if available, empty if not]\n\n  conversational_arc:\n    message_count: [count of messages in conversation]\n    phases:\n      - phase: \"[phase name]\"\n        messages: [range]\n        summary: \"[what happened in this phase]\"\n    key_transitions:\n      - from_msg: [number]\n        to_msg: [number]\n        note: \"[what changed and why]\"\n    early_assumptions_carried_forward:\n      - assumption: \"[assumption text]\"\n        introduced_at: [message number]\n        still_active: [true/false]\n\n  claims:\n    - id: C[N]\n      text: \"[factual claim made by assistant]\"\n      speaker: assistant\n      confidence: [stated_as_fact|hedged|uncertain]\n      message_num: [source message number]\n\n  files_read:\n    - path: [file path]\n      summary: \"[brief description of content/purpose]\"\n\n  tools_invoked:\n    - tool: [tool name]\n      command: \"[command or action]\"\n      outcome: \"[result summary]\"\n\n  decisions:\n    - decision: \"[decision made]\"\n      rationale: \"[stated reason]\"\n\n  assumptions_explicit:\n    - \"[explicitly stated assumption]\"\n```\n\n### Step 4: Launch Coordinator\n\nUse the Task tool to launch a SINGLE agent:\n\n```\nTask: Launch red-team-coordinator agent\nAgent: agents/red-team-coordinator.md\nPrompt: [Include the full YAML snapshot]\n```\n\n### Step 5: Return Output\n\nReturn the coordinator's markdown report DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include any \"I attacked X\" reasoning\n- Show intermediate findings\n\nONLY return the final sanitized markdown report.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and red team work:\n\n- Main session context stays CLEAN\n- Only structured snapshot data passes to coordinator\n- Only sanitized markdown report returns to user\n- No adversarial prompts or attack reasoning enters main context\n"
              }
            ],
            "skills": [
              {
                "name": "Multi-Agent Collaboration",
                "description": "This skill should be used when designing agent coordination, implementing context handoffs, reducing context overhead, creating multi-agent workflows, optimizing agent communication, implementing progressive disclosure, selecting architectural patterns (hierarchical vs swarm), or debugging agent context issues. Provides SOTA patterns for multi-agent systems achieving 78%+ context reduction while maintaining analysis quality.\n",
                "path": "red-agent/skills/multi-agent-collaboration/SKILL.md",
                "frontmatter": {
                  "name": "Multi-Agent Collaboration",
                  "description": "This skill should be used when designing agent coordination, implementing context handoffs, reducing context overhead, creating multi-agent workflows, optimizing agent communication, implementing progressive disclosure, selecting architectural patterns (hierarchical vs swarm), or debugging agent context issues. Provides SOTA patterns for multi-agent systems achieving 78%+ context reduction while maintaining analysis quality.\n"
                },
                "content": "# Multi-Agent Collaboration\n\n## Overview\n\nState-of-the-art patterns for context-efficient multi-agent systems. These patterns enable complex agent workflows while minimizing token overhead through strategic context engineering.\n\n## Research Foundation\n\n- Google ADK: Context compilation pipelines and session management\n- Anthropic: Multi-agent coordination and handoff protocols\n- Progressive Disclosure: Agent-readable semantic interfaces\n- LangGraph/CrewAI/AutoGen: Framework-specific orchestration patterns\n\n## Pattern Selection Framework\n\n| Pattern | Use When | Trade-offs |\n|---------|----------|------------|\n| **Hierarchical** | Clear decomposition, audit trails | Central bottleneck, sequential latency |\n| **Swarm** | Parallel exploration, diverse perspectives | Coordination overhead, emergent behavior |\n| **ReAct** | Dynamic adaptation, tool-heavy workflows | Myopic decisions, may meander |\n| **Plan-Execute** | Clear sequence, predictability needed | Less adaptive, requires replanning |\n| **Reflection** | Quality refinement, self-correction | Added latency, may reinforce errors |\n| **Hybrid** | Multiple coordination needs | Implementation complexity |\n\nFor detailed YAML definitions and examples of each pattern, see `references/patterns.md`.\n\n## The Four Laws of Context Management\n\n### Law 1: Selective Projection\n\nPass only fields each agent needs, not full data structures.\n\n```yaml\n# BAD: Full snapshot everywhere\nsnapshot: {...20KB...}\n\n# GOOD: Selective projection\ncontext:\n  mode: deep\n  claims_analyzed: 15\n  high_risk_count: 4\n```\n\n### Law 2: Tiered Context Fidelity\n\nDefine explicit tiers based on agent role:\n\n| Tier | Description | Example Agent |\n|------|-------------|---------------|\n| FULL | Complete data | Initial analyzer |\n| SELECTIVE | Relevant subset | Domain workers |\n| FILTERED | Criteria-matched | Validators |\n| MINIMAL | Mode + counts | Strategy/routing |\n| METADATA | Scope stats only | Report synthesis |\n\n### Law 3: Reference vs Embedding\n\nFor large data, pass reference instead of full structure:\n\n```yaml\n# Embedding (expensive)\nraw_findings: [{...}, {...}, ...]  # 40+ items\n\n# Reference (efficient)\nfindings_summary:\n  total: 45\n  by_severity: {CRITICAL: 3, HIGH: 12}\n  # Agent fetches specific findings on-demand\n```\n\n### Law 4: Lazy Loading\n\nLoad data on-demand, not upfront:\n\n```yaml\ninitial_context:\n  scope: {item_count: 45}\n  available_data:\n    - name: findings\n      fetch: \"request by severity or ID\"\n```\n\nFor implementation details and patterns, see `references/context-engineering.md`.\n\n## Standard Handoff Protocol\n\n```yaml\nhandoff:\n  from_agent: context-analyzer\n  to_agent: attack-strategist\n  context_level: MINIMAL\n\n  payload:\n    mode: deep\n    analysis_summary:\n      claim_count: 15\n      high_risk_count: 4\n      patterns: [pattern_1, pattern_2]\n\n  expected_output:\n    format: yaml\n    schema: strategy_v1\n```\n\n## Severity-Based Batching\n\nReduce validation operations by routing based on priority:\n\n```yaml\nbatching:\n  CRITICAL: [all_validators]      # 4 agents\n  HIGH: [checker, verifier]       # 2 agents\n  MEDIUM: [checker]               # 1 agent\n  LOW/INFO: []                    # Skip\n\n# Result: 60-70% fewer operations\n```\n\n## Anti-Patterns to Avoid\n\n1. **Snapshot Broadcasting** - Passing full context to every agent\n2. **Defensive Over-inclusion** - \"Maybe they need this\" mentality\n3. **Grounding Everything** - Validating low-priority items\n4. **Embedding Large Lists** - Full arrays when counts suffice\n5. **Repeated Context** - Same data passed multiple times in chain\n6. **Verbose Outputs** - Over-explaining when concise suffices\n\n## Progressive Disclosure for Agents\n\n### Three-Level Loading\n\n```yaml\nlevel_1_always_loaded:\n  - skill_name\n  - skill_description\n  tokens: ~100\n\nlevel_2_on_trigger:\n  - main_skill_body\n  - core_patterns\n  - quick_reference_tables\n  tokens: ~2000\n\nlevel_3_on_demand:\n  - detailed_references\n  - extended_examples\n  - implementation_guides\n  tokens: as_needed\n```\n\n## Guardrails and Validation\n\n### Output Validation Pattern\n\n```yaml\nvalidation:\n  hook: post_tool_use\n  on_invalid:\n    action: block_and_retry\n    max_retries: 2\n  on_valid:\n    action: continue\n```\n\n### Context Tier Enforcement\n\nDocument what each agent does NOT receive:\n\n```yaml\nagent_context:\n  receives:\n    - analysis_summary\n    - assigned_vectors\n\n  not_provided:  # CRITICAL: Explicit exclusions\n    - full_snapshot\n    - other_agents_data\n    - conversational_arc\n```\n\n## Metrics\n\nTrack these to validate optimization:\n\n| Metric | Target |\n|--------|--------|\n| Total context passed | < 100KB |\n| Redundancy ratio | < 0.1 |\n| Validation efficiency | > 3:1 findings/operations |\n| Tier compliance | 100% |\n\n## Additional Resources\n\n- `references/context-engineering.md` - Detailed context management patterns\n- `references/patterns.md` - Architectural patterns with YAML definitions\n- `references/examples.md` - Red-agent implementation examples"
              }
            ]
          },
          {
            "name": "context-engineering",
            "description": "Production-grade context engineering tool for expert LLM engineers. Analyzes and improves Claude Code plugins using SOTA orchestration patterns - Four Laws, tiered fidelity, severity batching, and firewall architectures.",
            "source": "./context-engineering",
            "category": "development",
            "version": "1.0.0",
            "author": {
              "name": "Context Engineering Team",
              "email": "abossenbroek@users.noreply.github.com"
            },
            "install_commands": [
              "/plugin marketplace add abossenbroek/abossenbroek-claude-plugins",
              "/plugin install context-engineering@abossenbroek-claude-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-06T01:58:03Z",
              "created_at": "2025-12-31T03:56:10Z",
              "license": "BSD-3-Clause"
            },
            "commands": [
              {
                "name": "/audit-context",
                "description": null,
                "path": "context-engineering/commands/audit-context.md",
                "frontmatter": null,
                "content": "# /audit-context Command\n\nAudit a plugin or plan for context management inefficiencies.\n\n## Usage\n\n```\n/audit-context [path]\n```\n\n## Arguments\n\n**path** (optional):\n- Path to plugin directory or plan file (default: auto-detect plugin in workspace)\n\n## Instructions\n\nYou are the MINIMAL entry point for context auditing. Your ONLY job is to:\n\n1. Determine the audit target\n2. Launch the audit-coordinator agent\n3. Return the coordinator's output directly\n\n### Step 1: Determine Target\n\nIf no path provided:\n1. Look for `.claude-plugin/plugin.json` in workspace\n2. If not found, look for recent plans in `.claude/plans/`\n3. If nothing found, ask user to specify\n\nDetermine if target is a plugin or plan based on structure.\n\n### Step 2: Launch Coordinator\n\nUse the Task tool to launch the audit-coordinator agent:\n\n```\nTask: Audit context management\nAgent: agents/audit-coordinator.md\nPrompt:\n  target_path: [resolved path]\n  target_type: plugin|plan\n```\n\nThe coordinator will:\n1. Analyze the target structure\n2. Map context flows\n3. Identify Four Laws violations\n4. Calculate token waste estimates\n5. Generate comprehensive audit report\n\n### Step 3: Return Output\n\nReturn the coordinator's audit report DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include intermediate analysis\n- Modify the report\n\nONLY return the final audit report.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and audit work:\n\n- Main session context stays CLEAN\n- Only target path passes to coordinator\n- Only the final audit report returns to user\n- No intermediate analysis enters main context\n\n## Examples\n\n```\n/audit-context\n# Audits auto-detected plugin in workspace\n\n/audit-context ./red-agent\n# Audits specific plugin directory\n\n/audit-context ~/.claude/plans/my-plan.md\n# Audits specific plan file\n```\n\n## What Gets Audited\n\n### Four Laws Compliance\n\n| Law | Audit Check |\n|-----|-------------|\n| Selective Projection | Are full snapshots passed unnecessarily? |\n| Tiered Fidelity | Do agents have appropriate tier specs? |\n| Reference vs Embedding | Is large data embedded instead of referenced? |\n| Lazy Loading | Is data loaded upfront when not needed? |\n\n### Anti-Patterns\n\n- Snapshot Broadcasting - Same data to every agent\n- Defensive Inclusion - \"Maybe they need this\"\n- Grounding Everything - Validating low-priority items\n\n### Flow Issues\n\n- Redundancy - Same data passed multiple times\n- Missing Tiers - Agents without context tier specification\n- Large Handoffs - >2000 tokens in single transfer\n\n## Output Format\n\nThe audit report includes:\n- Executive summary with overall health score\n- Violations by severity (HIGH/MEDIUM/LOW)\n- Estimated token waste per violation\n- Specific fix recommendations\n- Prioritized action items\n"
              },
              {
                "name": "/generate-handoffs",
                "description": null,
                "path": "context-engineering/commands/generate-handoffs.md",
                "frontmatter": null,
                "content": "# /generate-handoffs Command\n\nGenerate handoff schemas and validation models for agent workflows.\n\n## Usage\n\n```\n/generate-handoffs [agents]\n```\n\n## Arguments\n\n**agents** (optional):\n- Comma-separated list of agent file names (default: all agents in current plugin)\n- Can also specify pairs: `agent1->agent2,agent2->agent3`\n\n## Instructions\n\nYou are the MINIMAL entry point for handoff generation. Your ONLY job is to:\n\n1. Identify agents to generate handoffs for\n2. Launch the handoff-improver directly (no coordinator needed)\n3. Return the generated artifacts directly\n\n### Step 1: Identify Agents\n\nIf no agents provided:\n1. Look for `.claude-plugin/plugin.json` in workspace\n2. Extract all agents from manifest\n3. Include `coordinator-internal/` agents\n\nIf agents provided:\n1. Parse agent names or pairs from argument\n2. Verify files exist\n\n### Step 2: Analyze Flows\n\nUse Glob to find agent files:\n```\n**/agents/*.md\n**/coordinator-internal/**/*.md\n```\n\nRead agent files to identify:\n- Task tool usage (which agents call which)\n- Input/output sections\n- Current handoff patterns\n\n### Step 3: Launch Handoff Improver\n\nUse the Task tool to launch the handoff-improver:\n\n```\nTask: Generate handoff schemas\nAgent: coordinator-internal/handoff-improver.md\nPrompt:\n  agent_files:\n    - file: [path]\n      content: [agent content]\n  transitions_to_generate:\n    - from: [source agent]\n      to: [target agent]\n  generate_artifacts: true\n```\n\nThe improver will:\n1. Analyze transitions between agents\n2. Determine optimal payloads\n3. Generate YAML handoff schemas\n4. Generate Pydantic models\n5. Generate hook configurations\n\n### Step 4: Return Output\n\nReturn the generated artifacts DIRECTLY to the user.\n\nInclude:\n- YAML handoff schemas\n- Pydantic model code\n- Hook configuration JSON\n- Implementation notes\n\nDO NOT:\n- Add commentary about the process\n- Include intermediate analysis\n- Modify the artifacts\n\n## Examples\n\n```\n/generate-handoffs\n# Generates handoffs for all agents in current plugin\n\n/generate-handoffs coordinator,analyzer,validator\n# Generates handoffs between specified agents\n\n/generate-handoffs coordinator->analyzer,analyzer->validator\n# Generates handoffs for specific transitions\n```\n\n## What Gets Generated\n\n### YAML Handoff Schemas\n\nFor each transition:\n```yaml\nhandoff:\n  from_agent: improve-coordinator\n  to_agent: plugin-analyzer\n  context_level: FULL\n\n  payload:\n    plugin_manifest: \"[plugin.json contents]\"\n    agent_files: \"[list of agent files]\"\n    mode: \"[focus area]\"\n\n  not_passed:\n    - unrelated_files\n    - build_artifacts\n    - git_metadata\n\n  expected_output:\n    format: yaml\n    schema: PluginAnalysis\n```\n\n### Pydantic Models\n\nFor each handoff:\n```python\nfrom pydantic import BaseModel, Field\n\nclass AnalyzerInput(BaseModel):\n    \"\"\"Input schema for plugin-analyzer.\"\"\"\n    plugin_manifest: dict\n    agent_files: list[AgentFile]\n    mode: str = \"all\"\n\nclass AgentFile(BaseModel):\n    file: str\n    content: str\n```\n\n### Hook Configurations\n\nFor validation:\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"matcher\": {\n    \"tool_name\": \"Task\",\n    \"agent_pattern\": \"coordinator-internal/*\"\n  },\n  \"hooks\": [{\n    \"type\": \"prompt\",\n    \"prompt\": \"Validate output...\"\n  }]\n}\n```\n\n## Output Location\n\nGenerated files can be saved to:\n- `templates/handoffs/` - YAML schemas\n- `src/*/models/` - Pydantic models\n- `hooks/` - Hook configurations\n\nOr displayed inline for manual placement.\n"
              },
              {
                "name": "/improve-plugin",
                "description": null,
                "path": "context-engineering/commands/improve-plugin.md",
                "frontmatter": null,
                "content": "# /improve-plugin Command\n\nImprove an existing Claude Code plugin with SOTA context engineering patterns.\n\n## Usage\n\n```\n/improve-plugin [focus] [path]\n```\n\n## Arguments\n\n**focus** (optional):\n- `all` - Full improvement pass (context + orchestration + handoff) (default)\n- `context` - Optimize context management (Four Laws)\n- `orchestration` - Improve agent hierarchy and coordination\n- `handoff` - Optimize agent-to-agent data transfer\n\n**path** (optional):\n- Path to plugin directory (default: auto-detect in current workspace)\n\n## Instructions\n\nYou are the MINIMAL entry point for plugin improvement. Your ONLY job is to:\n\n1. Parse focus and path arguments\n2. Locate the plugin to improve\n3. Launch the improve-coordinator agent\n4. Return the coordinator's output directly\n\n### Step 1: Parse Arguments\n\nDetermine focus area and plugin path:\n- Default focus: `all`\n- Default path: Look for `.claude-plugin/plugin.json` in workspace\n\n### Step 2: Locate Plugin\n\nIf no path provided:\n1. Search for `.claude-plugin/plugin.json` files\n2. If multiple found, ask user to specify\n3. If none found, ask user to provide path\n\nVerify the plugin exists by checking for `plugin.json`.\n\n### Step 3: Launch Coordinator\n\nUse the Task tool to launch the improve-coordinator agent:\n\n```\nTask: Improve plugin with SOTA patterns\nAgent: agents/improve-coordinator.md\nPrompt:\n  plugin_path: [resolved plugin directory]\n  focus_area: [parsed focus: all|context|orchestration|handoff]\n```\n\nThe coordinator will:\n1. Analyze the plugin structure\n2. Generate improvements based on focus area\n3. Ground improvements (pattern check, token estimate, risk)\n4. Present options for user selection\n5. Generate final improvement report\n\n### Step 4: Return Output\n\nReturn the coordinator's improvement report DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include intermediate analysis\n- Modify the report in any way\n\nONLY return the final improvement report.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and improvement work:\n\n- Main session context stays CLEAN\n- Only plugin path and focus pass to coordinator\n- Only the final improvement report returns to user\n- No intermediate analysis enters main context\n\n## Examples\n\n```\n/improve-plugin\n# Runs full improvement pass on auto-detected plugin\n\n/improve-plugin context\n# Focus on context management improvements only\n\n/improve-plugin orchestration ./my-plugin\n# Improve agent hierarchy for specific plugin\n\n/improve-plugin handoff\n# Optimize handoffs in auto-detected plugin\n```\n\n## What Gets Improved\n\n### Context Focus\n- Add context tier specifications to agents\n- Add \"NOT PASSED\" documentation sections\n- Convert large embeddings to references\n- Implement lazy loading patterns\n\n### Orchestration Focus\n- Add firewall coordinator architecture\n- Split monolithic agents into phases\n- Extract reusable sub-agents\n- Align with SOTA patterns\n\n### Handoff Focus\n- Generate YAML handoff schemas\n- Create Pydantic validation models\n- Add PostToolUse validation hooks\n- Minimize data transfer between agents\n"
              },
              {
                "name": "/optimize-plan",
                "description": null,
                "path": "context-engineering/commands/optimize-plan.md",
                "frontmatter": null,
                "content": "# /optimize-plan Command\n\nOptimize a plan file for efficient context management and agent handoffs.\n\n## Usage\n\n```\n/optimize-plan [path]\n```\n\n## Arguments\n\n**path** (optional):\n- Path to plan file (default: most recent plan in `.claude/plans/`)\n\n## Instructions\n\nYou are the MINIMAL entry point for plan optimization. Your ONLY job is to:\n\n1. Locate the plan file to optimize\n2. Launch the plan-coordinator agent\n3. Return the coordinator's output directly\n\n### Step 1: Locate Plan\n\nIf no path provided:\n1. Look in `.claude/plans/` for recent `.md` files\n2. If multiple found, use most recently modified\n3. If none found, ask user to provide path\n\nVerify the plan exists by attempting to read it.\n\n### Step 2: Launch Coordinator\n\nUse the Task tool to launch the plan-coordinator agent:\n\n```\nTask: Optimize plan for context efficiency\nAgent: agents/plan-coordinator.md\nPrompt:\n  plan_path: [resolved plan file path]\n```\n\nThe coordinator will:\n1. Analyze plan structure and phases\n2. Map context flows between phases\n3. Identify optimization opportunities\n4. Present options for user selection\n5. Generate optimized version with comparison\n\n### Step 3: Return Output\n\nReturn the coordinator's output DIRECTLY to the user.\n\nDO NOT:\n- Add commentary about the process\n- Explain what the coordinator did\n- Include intermediate analysis\n- Modify the output\n\nONLY return the final optimized plan and comparison.\n\n## Context Isolation Rules\n\nThis command is the FIREWALL between main session and optimization work:\n\n- Main session context stays CLEAN\n- Only plan path passes to coordinator\n- Only the final output returns to user\n- No intermediate analysis enters main context\n\n## Examples\n\n```\n/optimize-plan\n# Optimizes most recent plan in .claude/plans/\n\n/optimize-plan ~/.claude/plans/my-feature-plan.md\n# Optimizes specific plan file\n```\n\n## What Gets Optimized\n\n### Context Tiers\n- Assign appropriate context tiers to each phase\n- Identify phases using higher tier than needed\n- Add explicit tier specifications\n\n### Handoff Points\n- Minimize data transfer between phases\n- Document explicit exclusions\n- Add \"NOT PASSED\" sections\n\n### Flow Efficiency\n- Identify redundant data passing\n- Suggest reference patterns for large data\n- Recommend lazy loading where applicable\n\n## Output Format\n\nThe optimization output includes:\n- Before/after comparison of context per phase\n- Estimated token reduction\n- Specific changes recommended\n- Rewritten plan sections (optional)\n"
              }
            ],
            "skills": [
              {
                "name": "Context Engineering",
                "description": "This skill should be used when designing context management, implementing tiered fidelity, reducing token waste, applying Four Laws patterns, creating \"NOT PASSED\" sections, optimizing agent context, or debugging context-related issues. Provides SOTA patterns for context-efficient multi-agent systems achieving 60-80% token reduction.\n",
                "path": "context-engineering/skills/context-engineering/SKILL.md",
                "frontmatter": {
                  "name": "Context Engineering",
                  "description": "This skill should be used when designing context management, implementing tiered fidelity, reducing token waste, applying Four Laws patterns, creating \"NOT PASSED\" sections, optimizing agent context, or debugging context-related issues. Provides SOTA patterns for context-efficient multi-agent systems achieving 60-80% token reduction.\n"
                },
                "content": "# Context Engineering\n\n## Overview\n\nState-of-the-art patterns for managing context in LLM agent systems. These patterns enable complex multi-agent workflows while minimizing token overhead through strategic context engineering.\n\n## The Four Laws of Context Management\n\n| Law | Principle | Token Impact |\n|-----|-----------|--------------|\n| **1. Selective Projection** | Pass only fields each agent needs | -30-50% |\n| **2. Tiered Fidelity** | Define explicit context tiers per role | -40-60% |\n| **3. Reference vs Embedding** | Use references for large data | -50-80% |\n| **4. Lazy Loading** | Load data on-demand, not upfront | -30-50% |\n\nFor detailed explanations and examples, see `references/four-laws.md`.\n\n## Context Tiers\n\n| Tier | Description | Use Case | Typical Size |\n|------|-------------|----------|--------------|\n| **FULL** | Complete data | Initial analysis | 5-20K tokens |\n| **SELECTIVE** | Relevant subset | Domain workers | 1-5K tokens |\n| **FILTERED** | Criteria-matched | Validators | 500-2K tokens |\n| **MINIMAL** | Mode + counts | Routing | 100-500 tokens |\n| **METADATA** | Stats only | Synthesis | 50-200 tokens |\n\nFor tier selection guidance, see `references/context-tiers.md`.\n\n## Quick Reference: Input Section Pattern\n\n### Before (Anti-pattern)\n```yaml\n## Input\nYou receive:\n- snapshot: Full context snapshot\n- all_findings: Complete list\n- full_config: Everything\n```\n\n### After (SOTA Pattern)\n```yaml\n## Input\nYou receive (SELECTIVE context):\n- analysis_summary: Key findings only\n- relevant_files: Files for this focus area\n- mode: Analysis depth setting\n\n**NOT provided** (context isolation):\n- Full plugin contents\n- Unrelated analysis results\n- Other agents' intermediate work\n```\n\n## Anti-Patterns to Avoid\n\n| Anti-Pattern | Problem | Fix |\n|--------------|---------|-----|\n| Snapshot Broadcasting | Same data to every agent | Tier by role |\n| Defensive Inclusion | \"Maybe they need this\" | Document NOT PASSED |\n| Grounding Everything | Validating low-priority | Severity batching |\n| Large Embeddings | Full arrays when counts suffice | Reference pattern |\n| Repeated Context | Same data multiple times in chain | Pass once, reference later |\n\n## Handoff Protocol\n\nStandard handoff between agents:\n\n```yaml\nhandoff:\n  from_agent: coordinator\n  to_agent: analyzer\n  context_level: SELECTIVE\n\n  payload:\n    mode: deep\n    analysis_summary:\n      claim_count: 15\n      high_risk_count: 4\n    relevant_files:\n      - file: \"[path]\"\n        content: \"[content]\"\n\n  not_passed:\n    - full_snapshot\n    - unrelated_files\n    - other_agents_data\n\n  expected_output:\n    format: yaml\n    schema: AnalysisOutput\n```\n\nFor complete handoff patterns, see `references/handoff-protocols.md`.\n\n## Severity-Based Batching\n\nReduce validation operations by priority:\n\n```yaml\nbatching:\n  HIGH:     [all_validators]    # 4 agents\n  MEDIUM:   [checker, estimator] # 2 agents\n  LOW:      [checker]            # 1 agent\n  INFO:     []                   # Skip\n\n# Result: 60-70% fewer validation operations\n```\n\n## Metrics to Track\n\n| Metric | Target | Calculation |\n|--------|--------|-------------|\n| Tier Compliance | 100% | Agents with tier / Total agents |\n| Redundancy Ratio | < 0.1 | Duplicate data / Total data |\n| Context per Agent | < 2K | Avg tokens per agent |\n| NOT PASSED Coverage | 100% | Agents with exclusions / Total |\n\n## Additional Resources\n\n- `references/four-laws.md` - Detailed law explanations with examples\n- `references/context-tiers.md` - Tier definitions and selection guide\n- `references/handoff-protocols.md` - YAML schema patterns\n- `references/examples.md` - Production examples from red-agent"
              },
              {
                "name": "Orchestration Patterns",
                "description": "This skill should be used when designing agent orchestration, implementing firewall architecture, creating phase-based workflows, adding severity batching, structuring agent hierarchies, or implementing SOTA multi-agent coordination patterns. Provides production-ready patterns for scalable agent systems.\n",
                "path": "context-engineering/skills/orchestration-patterns/SKILL.md",
                "frontmatter": {
                  "name": "Orchestration Patterns",
                  "description": "This skill should be used when designing agent orchestration, implementing firewall architecture, creating phase-based workflows, adding severity batching, structuring agent hierarchies, or implementing SOTA multi-agent coordination patterns. Provides production-ready patterns for scalable agent systems.\n"
                },
                "content": "# Orchestration Patterns\n\n## Overview\n\nState-of-the-art patterns for multi-agent system orchestration. These patterns enable complex workflows while maintaining clear boundaries, efficient context flow, and debuggable execution.\n\n## Pattern Selection Framework\n\n| Pattern | Use When | Trade-offs |\n|---------|----------|------------|\n| **Firewall** | Context isolation critical | Coordination overhead |\n| **Hierarchical** | Clear decomposition needed | Sequential bottleneck |\n| **Phase-Based** | Distinct execution stages | Rigid structure |\n| **Severity Batching** | Variable priority items | Complexity in routing |\n| **Swarm** | Parallel exploration | Coordination overhead |\n| **Hybrid** | Multiple needs | Implementation complexity |\n\nFor detailed pattern definitions, see `references/firewall-architecture.md`.\n\n## Firewall Architecture\n\nThe foundational pattern for context-isolated multi-agent systems.\n\n### Core Concept\n\n```\nMain Session (CLEAN)\n       \n       \n   \n     FIREWALL         \n     Entry Agent         Only entry point\n     (Thin Router)    \n   \n       \n       \n   \n     ISOLATED WORK    \n     Sub-Agents          Work happens here\n     (coordinator-    \n      internal/)      \n   \n       \n       \n   \n     SANITIZED OUTPUT \n     Final Report        Only this returns\n   \n```\n\n### Key Rules\n\n1. **Entry agents are THIN ROUTERS** - They route, not analyze\n2. **Work in isolation** - Sub-agents do the actual work\n3. **Structured data only** - No raw context passes through\n4. **Sanitized return** - Only final report reaches main session\n\nFor implementation details, see `references/firewall-architecture.md`.\n\n## Phase-Based Execution\n\nWorkflow structure with clear stages:\n\n```yaml\nphases:\n  analyze:\n    tier: FULL\n    agents: [analyzer]\n    output: analysis_results\n\n  improve:\n    tier: SELECTIVE\n    agents: [optimizer, improver]\n    input: analysis_summary\n    output: improvements\n\n  ground:\n    tier: FILTERED\n    agents: [checkers, validators]\n    input: improvements_by_priority\n    output: grounded_improvements\n\n  synthesize:\n    tier: METADATA\n    agents: [synthesizer]\n    input: selected_improvements\n    output: final_report\n```\n\nFor phase design guidance, see `references/phase-execution.md`.\n\n## Severity-Based Batching\n\nRoute items by priority to reduce operations:\n\n```yaml\nrouting:\n  CRITICAL:\n    validators: [all]          # 4 agents\n    operations: ~16            # 4 findings  4 validators\n\n  HIGH:\n    validators: [primary, secondary]  # 2 agents\n    operations: ~10            # 5 findings  2 validators\n\n  MEDIUM:\n    validators: [primary]      # 1 agent\n    operations: ~8             # 8 findings  1 validator\n\n  LOW/INFO:\n    validators: []             # Skip\n    operations: 0\n\n# Total: 34 operations vs 108 (all  all)\n# Reduction: 68%\n```\n\nFor batching strategies, see `references/severity-batching.md`.\n\n## Agent Hierarchy Patterns\n\n### Entry + Internal Structure\n\n```\nplugin/\n agents/                    # ENTRY AGENTS (user-invocable)\n    coordinator-a.md       # Firewall for workflow A\n    coordinator-b.md       # Firewall for workflow B\n\n coordinator-internal/      # SUB-AGENTS (never directly invoked)\n     analyzer.md\n     processor.md\n     grounding/\n        checker-1.md\n        checker-2.md\n     synthesizer.md\n```\n\n### Naming Conventions\n\n| Type | Pattern | Example |\n|------|---------|---------|\n| Entry/Firewall | `*-coordinator.md` | `improve-coordinator.md` |\n| Analyzer | `*-analyzer.md` | `plugin-analyzer.md` |\n| Worker | `*-optimizer.md`, `*-improver.md` | `context-optimizer.md` |\n| Grounding | `grounding/*.md` | `grounding/pattern-checker.md` |\n| Synthesizer | `*-synthesizer.md` | `improvement-synthesizer.md` |\n\n## Validation with Hooks\n\n### PostToolUse Pattern\n\n```json\n{\n  \"event\": \"PostToolUse\",\n  \"matcher\": {\n    \"tool_name\": \"Task\"\n  },\n  \"hooks\": [{\n    \"type\": \"prompt\",\n    \"prompt\": \"Validate sub-agent output...\"\n  }]\n}\n```\n\n### Validation Flow\n\n1. Sub-agent completes\n2. Hook intercepts output\n3. Validates against schema\n4. Blocks if invalid  Coordinator retries\n5. Passes if valid  Workflow continues\n\nFor hook configuration, see `references/validation-hooks.md`.\n\n## Anti-Patterns to Avoid\n\n| Anti-Pattern | Problem | Fix |\n|--------------|---------|-----|\n| Fat Coordinator | Coordinator does analysis | Extract to sub-agent |\n| Flat Hierarchy | All agents at same level | Add coordinator layer |\n| Missing Firewall | Work in main context | Add entry agent |\n| No Grounding | Unvalidated outputs | Add grounding phase |\n| Serial Execution | Sequential when parallel possible | Identify independent work |\n\n## Quick Decision Guide\n\n### When to Add Firewall\n\n- Complex analysis that shouldn't pollute main context\n- Multiple sub-agents needed\n- Intermediate work should be isolated\n\n### When to Add Phases\n\n- 3+ distinct stages in workflow\n- Different context needs per stage\n- Clear sequential dependencies\n\n### When to Add Batching\n\n- Variable priority items\n- Not all items need same validation\n- Want to reduce operations\n\n## Additional Resources\n\n- `references/firewall-architecture.md` - Coordinator isolation patterns\n- `references/phase-execution.md` - Phase-based workflow design\n- `references/severity-batching.md` - CRITICALHIGHMEDIUMLOW routing\n- `references/validation-hooks.md` - Pydantic + PostToolUse patterns"
              }
            ]
          }
        ]
      }
    }
  ]
}