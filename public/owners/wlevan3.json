{
  "owner": {
    "id": "wlevan3",
    "display_name": "wlevan3",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/89826498?v=4",
    "url": "https://github.com/wlevan3",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 1,
      "total_skills": 0,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "wlevan3/claude-plugins",
      "url": "https://github.com/wlevan3/claude-plugins",
      "description": "Personal Claude Code plugins marketplace",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-11-27T07:49:55Z",
        "created_at": "2025-11-27T07:48:52Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 461
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 595
        },
        {
          "path": "multi-ai-consult",
          "type": "tree",
          "size": null
        },
        {
          "path": "multi-ai-consult/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "multi-ai-consult/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 321
        },
        {
          "path": "multi-ai-consult/README.md",
          "type": "blob",
          "size": 2451
        },
        {
          "path": "multi-ai-consult/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "multi-ai-consult/commands/consult.md",
          "type": "blob",
          "size": 21756
        }
      ],
      "marketplace": {
        "name": "wjlevan-claude-plugins",
        "version": null,
        "description": "Personal Claude Code plugins by Walter Levan",
        "owner_info": {
          "name": "Walter Levan",
          "github": "wjlevan"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "multi-ai-consult",
            "description": "Consult Gemini, Codex, Qwen, and OpenCode AIs in parallel",
            "source": "./multi-ai-consult",
            "category": null,
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add wlevan3/claude-plugins",
              "/plugin install multi-ai-consult@wjlevan-claude-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-11-27T07:49:55Z",
              "created_at": "2025-11-27T07:48:52Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/consult",
                "description": "Consult Gemini, Codex, Qwen, and OpenCode AIs in parallel and synthesize responses",
                "path": "multi-ai-consult/commands/consult.md",
                "frontmatter": {
                  "description": "Consult Gemini, Codex, Qwen, and OpenCode AIs in parallel and synthesize responses"
                },
                "content": "# Multi-AI Consultation\n\nConsult multiple AIs in parallel, then synthesize their responses into a unified answer.\n\n## Configuration\n\nModels and timeouts can be overridden via environment variables:\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `CONSULT_GEMINI_MODEL` | `gemini-3-pro-preview` | Gemini model |\n| `CONSULT_CODEX_MODEL` | `gpt-5.1-codex-max` | Codex model |\n| `CONSULT_QWEN_MODEL` | (CLI default) | Qwen model |\n| `CONSULT_OPENCODE_MODEL` | `anthropic/claude-opus-4-5` | OpenCode model |\n| `CONSULT_TIMEOUT` | `120` | Timeout in seconds per CLI |\n| `CONSULT_MAX_RESPONSE_CHARS` | `20000` | Max chars per response (~5K tokens) |\n\n## Arguments\n\nParse these from the query if present:\n- `--only=gemini,codex` - Consult only specified AIs (comma-separated)\n- `--exclude=opencode` - Exclude specified AIs (comma-separated)\n- `--verbose` - Show individual AI responses before synthesis\n- `--dry-run` - Show prepared prompt without executing\n\n## Instructions\n\n### Step 1: Verify Dependencies\n\nCheck required CLIs and tools exist:\n\n```bash\n# Platform detection and timeout command selection\n# CRITICAL: macOS timeout behaves differently and may not inherit PATH\nif [[ \"$(uname)\" == \"Darwin\" ]]; then\n  # macOS: prefer gtimeout from GNU coreutils (brew install coreutils)\n  if command -v gtimeout >/dev/null 2>&1; then\n    TIMEOUT_CMD=\"$(command -v gtimeout)\"\n  elif command -v timeout >/dev/null 2>&1; then\n    TIMEOUT_CMD=\"$(command -v timeout)\"\n    echo \"Warning: Using macOS timeout - consider 'brew install coreutils' for gtimeout\"\n  else\n    echo \"Error: No timeout command found. Install with: brew install coreutils\"\n    exit 11\n  fi\nelse\n  # Linux: use standard timeout\n  TIMEOUT_CMD=\"$(command -v timeout)\"\nfi\n\necho \"Platform: $(uname), using timeout: $TIMEOUT_CMD\"\n\n# Check jq for JSON parsing\ncommand -v jq >/dev/null 2>&1 || { echo \"Warning: jq not found, JSON parsing may fail\"; }\n\n# Resolve FULL PATHS to CLI binaries\n# CRITICAL: timeout subprocess may not inherit shell PATH\nAVAILABLE_CLIS=\"\"\nGEMINI_BIN=\"\"\nCODEX_BIN=\"\"\nQWEN_BIN=\"\"\nOPENCODE_BIN=\"\"\n\nif command -v gemini >/dev/null 2>&1; then\n  GEMINI_BIN=\"$(command -v gemini)\"\n  AVAILABLE_CLIS=\"$AVAILABLE_CLIS gemini\"\n  echo \"  Gemini: $GEMINI_BIN\"\nfi\n\nif command -v codex >/dev/null 2>&1; then\n  CODEX_BIN=\"$(command -v codex)\"\n  AVAILABLE_CLIS=\"$AVAILABLE_CLIS codex\"\n  echo \"  Codex: $CODEX_BIN\"\nfi\n\nif command -v qwen >/dev/null 2>&1; then\n  QWEN_BIN=\"$(command -v qwen)\"\n  AVAILABLE_CLIS=\"$AVAILABLE_CLIS qwen\"\n  echo \"  Qwen: $QWEN_BIN\"\nfi\n\nif command -v opencode >/dev/null 2>&1; then\n  OPENCODE_BIN=\"$(command -v opencode)\"\n  AVAILABLE_CLIS=\"$AVAILABLE_CLIS opencode\"\n  echo \"  OpenCode: $OPENCODE_BIN\"\nfi\n```\n\nIf no AI CLIs are available, stop and provide installation guidance. Otherwise, proceed with available CLIs (graceful degradation).\n\n### CLI Command Reference\n\n| CLI | Command | Key Flags |\n|-----|---------|-----------|\n| Gemini | `gemini -m \"$MODEL\" -o json` | `-m`: model, `-o json`: JSON output |\n| Codex | `codex exec --json -m \"$MODEL\" --skip-git-repo-check` | `--json`: NDJSON output |\n| Qwen | `qwen -p \"\" -o json` | `-p \"\"`: stdin prompt, `-o json`: JSON output |\n| OpenCode | `opencode run -m \"$MODEL\" --format json` | `--format json`: NDJSON events |\n\n### Step 2: Prepare the Prompt\n\nConstruct a clear prompt:\n\n1. **Reword** the user's query for clarity\n2. **Include file contents** if files are being discussed (read them first)\n3. **Add context** about what kind of response is expected\n4. **Validate input** - ensure no sensitive data (API keys, passwords) is included\n\nStore in a variable using proper quoting:\n\n```bash\nPROMPT=\"Your prepared prompt here\"\n\n# For dry-run mode, display and exit\nif [ \"$DRY_RUN\" = \"true\" ]; then\n  echo \"=== DRY RUN - Prompt ===\"\n  printf '%s\\n' \"$PROMPT\"\n  exit 0\nfi\n```\n\n### Step 3: Execute All in Parallel\n\nCreate temp files and run CLIs with timeout. **Important:** Do NOT wrap commands in subshells `( )` - this breaks job control.\n\n```bash\n# Configuration with defaults\nTIMEOUT=\"${CONSULT_TIMEOUT:-120}\"\nMAX_RESPONSE_CHARS=\"${CONSULT_MAX_RESPONSE_CHARS:-20000}\"\nGEMINI_MODEL=\"${CONSULT_GEMINI_MODEL:-gemini-3-pro-preview}\"\nCODEX_MODEL=\"${CONSULT_CODEX_MODEL:-gpt-5.1-codex-max}\"\nOPENCODE_MODEL=\"${CONSULT_OPENCODE_MODEL:-anthropic/claude-opus-4-5}\"\n\n# Create temp files (use mktemp for safety)\nGEMINI_OUT=$(mktemp /tmp/consult_gemini.XXXXXX)\nGEMINI_ERR=$(mktemp /tmp/consult_gemini_err.XXXXXX)\nCODEX_OUT=$(mktemp /tmp/consult_codex.XXXXXX)\nCODEX_ERR=$(mktemp /tmp/consult_codex_err.XXXXXX)\nQWEN_OUT=$(mktemp /tmp/consult_qwen.XXXXXX)\nQWEN_ERR=$(mktemp /tmp/consult_qwen_err.XXXXXX)\nOPENCODE_OUT=$(mktemp /tmp/consult_opencode.XXXXXX)\nOPENCODE_ERR=$(mktemp /tmp/consult_opencode_err.XXXXXX)\n\n# Cleanup trap - runs on exit, interrupt, or termination\ncleanup() {\n  rm -f \"$GEMINI_OUT\" \"$GEMINI_ERR\" \"$CODEX_OUT\" \"$CODEX_ERR\" \\\n        \"$QWEN_OUT\" \"$QWEN_ERR\" \"$OPENCODE_OUT\" \"$OPENCODE_ERR\"\n  # Kill any remaining background jobs\n  jobs -p | xargs -r kill 2>/dev/null\n}\ntrap cleanup EXIT INT TERM\n\necho \"Starting parallel consultation...\"\necho \"  Timeout: ${TIMEOUT}s per CLI\"\necho \"  CLIs:$AVAILABLE_CLIS\"\n\n# Run in parallel using FULL PATHS and $TIMEOUT_CMD\n# CRITICAL: Use full paths resolved in Step 1 to avoid PATH inheritance issues\n# Use printf for safe prompt handling (handles special chars, -n, etc.)\n\n[ -n \"$GEMINI_BIN\" ] && {\n  printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$TIMEOUT\" \"$GEMINI_BIN\" -m \"$GEMINI_MODEL\" -o json > \"$GEMINI_OUT\" 2>\"$GEMINI_ERR\" &\n  GEMINI_PID=$!\n}\n\n[ -n \"$CODEX_BIN\" ] && {\n  printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$TIMEOUT\" \"$CODEX_BIN\" exec --json -m \"$CODEX_MODEL\" --skip-git-repo-check > \"$CODEX_OUT\" 2>\"$CODEX_ERR\" &\n  CODEX_PID=$!\n}\n\n[ -n \"$QWEN_BIN\" ] && {\n  printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$TIMEOUT\" \"$QWEN_BIN\" -p \"\" -o json > \"$QWEN_OUT\" 2>\"$QWEN_ERR\" &\n  QWEN_PID=$!\n}\n\n[ -n \"$OPENCODE_BIN\" ] && {\n  printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$TIMEOUT\" \"$OPENCODE_BIN\" run -m \"$OPENCODE_MODEL\" --format json > \"$OPENCODE_OUT\" 2>\"$OPENCODE_ERR\" &\n  OPENCODE_PID=$!\n}\n\necho \"All CLIs launched. Waiting for responses...\"\n\n# Wait for all and capture exit codes\n[ -n \"$GEMINI_PID\" ] && { wait $GEMINI_PID 2>/dev/null; GEMINI_EXIT=$?; } || GEMINI_EXIT=127\n[ -n \"$CODEX_PID\" ] && { wait $CODEX_PID 2>/dev/null; CODEX_EXIT=$?; } || CODEX_EXIT=127\n[ -n \"$QWEN_PID\" ] && { wait $QWEN_PID 2>/dev/null; QWEN_EXIT=$?; } || QWEN_EXIT=127\n[ -n \"$OPENCODE_PID\" ] && { wait $OPENCODE_PID 2>/dev/null; OPENCODE_EXIT=$?; } || OPENCODE_EXIT=127\n\necho \"All CLIs completed. Processing responses...\"\necho \"Exit codes: Gemini=$GEMINI_EXIT Codex=$CODEX_EXIT Qwen=$QWEN_EXIT OpenCode=$OPENCODE_EXIT\"\n```\n\n### Step 3.5: Progress Monitoring (Optional)\n\nFor long consultations, provide periodic status updates to show activity during the 2+ minutes of parallel execution:\n\n```bash\n# Optional: Monitor progress every 15 seconds\nmonitor_progress() {\n  local start_time=$(date +%s)\n  while true; do\n    sleep 15\n    local elapsed=$(( $(date +%s) - start_time ))\n\n    local status=\"\"\n    [ -s \"$GEMINI_OUT\" ] && status=\"${status} Gemini:$(wc -c < \"$GEMINI_OUT\" | tr -d ' ')b\"\n    [ -s \"$CODEX_OUT\" ] && status=\"${status} Codex:$(wc -c < \"$CODEX_OUT\" | tr -d ' ')b\"\n    [ -s \"$QWEN_OUT\" ] && status=\"${status} Qwen:$(wc -c < \"$QWEN_OUT\" | tr -d ' ')b\"\n    [ -s \"$OPENCODE_OUT\" ] && status=\"${status} OpenCode:$(wc -c < \"$OPENCODE_OUT\" | tr -d ' ')b\"\n\n    echo \"[${elapsed}s] Progress:${status:-\" waiting...\"}\"\n\n    # Check if all background jobs completed\n    if ! jobs -r 2>/dev/null | grep -q .; then\n      break\n    fi\n  done\n}\n\n# Start monitor in background before waiting\nmonitor_progress &\nMONITOR_PID=$!\n\n# ... (wait commands from Step 3) ...\n\n# Stop monitor after all CLIs complete\nkill $MONITOR_PID 2>/dev/null\n```\n\n**Simpler alternative:** Just use the status messages already added:\n- \"Starting parallel consultation...\" (before launch)\n- \"All CLIs launched. Waiting for responses...\" (after launch)\n- \"All CLIs completed. Processing responses...\" (after wait)\n\n### Step 4: Classify Errors and Retry with Backoff\n\nClassify error types and retry failures with exponential backoff (NOT parallel):\n\n| Exit Code | Meaning | Action |\n|-----------|---------|--------|\n| 0 | Success | Continue |\n| 124 | Timeout (GNU) | Retry with +60s timeout |\n| 127 | Command not found | Check PATH resolution - likely a setup issue |\n| 1-2 | General error | Check stderr AND stdout, retry once |\n| Other | Unknown | Check stderr AND stdout, retry once |\n\nCheck **BOTH stderr AND stdout** for error patterns (some CLIs embed errors in JSON):\n\n| Location | Pattern | Error Type | Retry? |\n|----------|---------|------------|--------|\n| stderr | `401`, `403`, `invalid.*key`, `unauthorized` | Auth failure | No - fix credentials |\n| stdout JSON | `\"error\":`, `\"FatalToolExecutionError\"` | API/tool error | No - check CLI setup |\n| stdout JSON | `\"type\":\"error\"` | Structured error event | Check message, maybe retry |\n| stderr | `429`, `rate.*limit`, `quota` | Rate limit | Yes - with backoff |\n| stderr | `timeout`, `timed out` | Timeout | Yes - increase timeout |\n| stderr | `connection`, `network`, `ENOTFOUND` | Network error | Yes - with backoff |\n\n```bash\n# Enhanced error classification function\nclassify_error() {\n  local exit_code=\"$1\" err_file=\"$2\" out_file=\"$3\"\n\n  # Exit 127 = command not found (PATH issue from Step 1)\n  if [ \"$exit_code\" -eq 127 ]; then\n    echo \"PATH_ERROR\"\n    return\n  fi\n\n  # Exit 124 = GNU timeout expired\n  if [ \"$exit_code\" -eq 124 ]; then\n    echo \"TIMEOUT\"\n    return\n  fi\n\n  # Check stderr for auth errors\n  if grep -qiE '401|403|invalid.*key|unauthorized' \"$err_file\" 2>/dev/null; then\n    echo \"AUTH_ERROR\"\n    return\n  fi\n\n  # Check stdout JSON for embedded errors (Qwen, Gemini tool errors)\n  if grep -qiE '\"error\":|FatalToolExecutionError|\"type\":\"error\"' \"$out_file\" 2>/dev/null; then\n    echo \"API_ERROR\"\n    return\n  fi\n\n  # Rate limit\n  if grep -qiE '429|rate.*limit|quota' \"$err_file\" 2>/dev/null; then\n    echo \"RATE_LIMIT\"\n    return\n  fi\n\n  # Network errors\n  if grep -qiE 'connection|network|ENOTFOUND|ETIMEDOUT' \"$err_file\" 2>/dev/null; then\n    echo \"NETWORK_ERROR\"\n    return\n  fi\n\n  echo \"UNKNOWN_ERROR\"\n}\n\nretry_with_backoff() {\n  local cli=\"$1\" exit_code=\"$2\" err_file=\"$3\" out_file=\"$4\"\n  local error_type=$(classify_error \"$exit_code\" \"$err_file\" \"$out_file\")\n\n  echo \"  $cli: $error_type (exit $exit_code)\"\n\n  # Don't retry auth or API errors\n  case \"$error_type\" in\n    AUTH_ERROR|API_ERROR|PATH_ERROR)\n      echo \"  $cli: Not retrying $error_type\"\n      return 1\n      ;;\n  esac\n\n  # Backoff delay: 2 seconds for first retry\n  echo \"  $cli: Retrying in 2s...\"\n  sleep 2\n\n  # Retry the specific CLI using full paths\n  local extra_timeout=60\n  [ \"$error_type\" = \"TIMEOUT\" ] && extra_timeout=90\n\n  case \"$cli\" in\n    gemini)\n      printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$((TIMEOUT + extra_timeout))\" \"$GEMINI_BIN\" -m \"$GEMINI_MODEL\" -o json > \"$out_file\" 2>\"$err_file\"\n      ;;\n    codex)\n      printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$((TIMEOUT + extra_timeout))\" \"$CODEX_BIN\" exec --json -m \"$CODEX_MODEL\" --skip-git-repo-check > \"$out_file\" 2>\"$err_file\"\n      ;;\n    qwen)\n      printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$((TIMEOUT + extra_timeout))\" \"$QWEN_BIN\" -p \"\" -o json > \"$out_file\" 2>\"$err_file\"\n      ;;\n    opencode)\n      printf '%s' \"$PROMPT\" | \"$TIMEOUT_CMD\" \"$((TIMEOUT + extra_timeout))\" \"$OPENCODE_BIN\" run -m \"$OPENCODE_MODEL\" --format json > \"$out_file\" 2>\"$err_file\"\n      ;;\n  esac\n}\n\n# Retry failed CLIs sequentially with backoff\n[ $GEMINI_EXIT -ne 0 ] && [ -n \"$GEMINI_BIN\" ] && retry_with_backoff gemini $GEMINI_EXIT \"$GEMINI_ERR\" \"$GEMINI_OUT\" && GEMINI_EXIT=$?\n[ $CODEX_EXIT -ne 0 ] && [ -n \"$CODEX_BIN\" ] && retry_with_backoff codex $CODEX_EXIT \"$CODEX_ERR\" \"$CODEX_OUT\" && CODEX_EXIT=$?\n[ $QWEN_EXIT -ne 0 ] && [ -n \"$QWEN_BIN\" ] && retry_with_backoff qwen $QWEN_EXIT \"$QWEN_ERR\" \"$QWEN_OUT\" && QWEN_EXIT=$?\n[ $OPENCODE_EXIT -ne 0 ] && [ -n \"$OPENCODE_BIN\" ] && retry_with_backoff opencode $OPENCODE_EXIT \"$OPENCODE_ERR\" \"$OPENCODE_OUT\" && OPENCODE_EXIT=$?\n```\n\n### Step 5: Parse Results with jq\n\nExtract text responses using proper jq filters. Stderr is separate, so JSON parsing won't break.\n\n**IMPORTANT:** AI responses can be very large (100K+ chars). Truncate to `MAX_RESPONSE_CHARS` to avoid token limit issues when synthesizing.\n\n```bash\n# Response truncation function - prevents token overflow\ntruncate_response() {\n  local response=\"$1\"\n  local max_chars=\"${2:-$MAX_RESPONSE_CHARS}\"\n  local char_count=\"${#response}\"\n\n  if [ \"$char_count\" -gt \"$max_chars\" ]; then\n    # Keep first 70% and last 20% for context\n    local head_chars=$((max_chars * 70 / 100))\n    local tail_chars=$((max_chars * 20 / 100))\n\n    local head_part=\"${response:0:$head_chars}\"\n    local tail_part=\"${response: -$tail_chars}\"\n\n    echo \"${head_part}\n\n... [TRUNCATED: ${char_count} chars total, showing first ${head_chars} and last ${tail_chars}] ...\n\n${tail_part}\"\n  else\n    echo \"$response\"\n  fi\n}\n\n# Gemini - check for errors first, then extract response\nif grep -q '\"error\"' \"$GEMINI_OUT\" 2>/dev/null; then\n  GEMINI_RESPONSE=\"\"\nelse\n  GEMINI_RESPONSE=$(jq -r '.response // .candidates[0].content.parts[0].text // empty' \"$GEMINI_OUT\" 2>/dev/null)\nfi\n\n# Codex - NDJSON format with multiple item types\n# NOTE: Codex outputs reasoning traces, NOT agent_message. Try multiple extraction patterns.\n# Pattern 1: Look for message items with content array containing output_text\nCODEX_RESPONSE=$(grep '\"item.completed\"' \"$CODEX_OUT\" 2>/dev/null | \\\n  jq -rs '\n    [.[] | select(.item.type == \"message\" and .item.content)] |\n    last |\n    .item.content |\n    if type == \"array\" then\n      [.[] | select(.type == \"output_text\") | .text] | join(\"\")\n    else\n      .\n    end\n  ' 2>/dev/null)\n\n# Pattern 2: Fall back to reasoning summaries if no message found\nif [ -z \"$CODEX_RESPONSE\" ]; then\n  CODEX_RESPONSE=$(grep '\"item.completed\"' \"$CODEX_OUT\" 2>/dev/null | \\\n    jq -rs '[.[] | select(.item.type == \"reasoning\") | .item.text // .item.summary // empty] | join(\"\\n\\n\")' 2>/dev/null)\nfi\n\n# Qwen - filter out error lines, then parse standard JSON\nQWEN_RESPONSE=$(grep -v 'FatalToolExecutionError' \"$QWEN_OUT\" 2>/dev/null | \\\n  jq -rs 'last | .response // empty' 2>/dev/null)\n\n# OpenCode - NDJSON, concatenate all text parts\nOPENCODE_RESPONSE=$(grep '\"type\":\"text\"' \"$OPENCODE_OUT\" 2>/dev/null | \\\n  jq -rs '[.[].part.text // .[].text // empty] | join(\"\")' 2>/dev/null)\n\n# Fallback to raw output if jq parsing fails (truncated for safety)\n[ -z \"$GEMINI_RESPONSE\" ] && [ -s \"$GEMINI_OUT\" ] && GEMINI_RESPONSE=$(head -c \"$MAX_RESPONSE_CHARS\" \"$GEMINI_OUT\")\n[ -z \"$CODEX_RESPONSE\" ] && [ -s \"$CODEX_OUT\" ] && CODEX_RESPONSE=$(head -c \"$MAX_RESPONSE_CHARS\" \"$CODEX_OUT\")\n[ -z \"$QWEN_RESPONSE\" ] && [ -s \"$QWEN_OUT\" ] && QWEN_RESPONSE=$(head -c \"$MAX_RESPONSE_CHARS\" \"$QWEN_OUT\")\n[ -z \"$OPENCODE_RESPONSE\" ] && [ -s \"$OPENCODE_OUT\" ] && OPENCODE_RESPONSE=$(head -c \"$MAX_RESPONSE_CHARS\" \"$OPENCODE_OUT\")\n\n# Apply truncation to prevent token overflow during synthesis\nGEMINI_RESPONSE=$(truncate_response \"$GEMINI_RESPONSE\")\nCODEX_RESPONSE=$(truncate_response \"$CODEX_RESPONSE\")\nQWEN_RESPONSE=$(truncate_response \"$QWEN_RESPONSE\")\nOPENCODE_RESPONSE=$(truncate_response \"$OPENCODE_RESPONSE\")\n\n# CRITICAL: Write to SEPARATE files to avoid 25K token limit\n# Claude can read each file individually during synthesis\necho \"$GEMINI_RESPONSE\" > /tmp/consult_gemini_response.txt\necho \"$CODEX_RESPONSE\" > /tmp/consult_codex_response.txt\necho \"$QWEN_RESPONSE\" > /tmp/consult_qwen_response.txt\necho \"$OPENCODE_RESPONSE\" > /tmp/consult_opencode_response.txt\n\n# Report file sizes for verification\necho \"Response sizes (chars):\"\necho \"  Gemini: ${#GEMINI_RESPONSE}\"\necho \"  Codex: ${#CODEX_RESPONSE}\"\necho \"  Qwen: ${#QWEN_RESPONSE}\"\necho \"  OpenCode: ${#OPENCODE_RESPONSE}\"\necho \"  TOTAL: $((${#GEMINI_RESPONSE} + ${#CODEX_RESPONSE} + ${#QWEN_RESPONSE} + ${#OPENCODE_RESPONSE}))\"\n```\n\n**IMPORTANT - Token Limit Prevention:**\n\nTo avoid the 25K token limit when reading responses:\n\n1. **NEVER write a combined file** - Don't concatenate all responses into one file\n2. **Read each response file separately** during synthesis:\n   - `Read(/tmp/consult_gemini_response.txt)`\n   - `Read(/tmp/consult_codex_response.txt)`\n   - `Read(/tmp/consult_qwen_response.txt)`\n   - `Read(/tmp/consult_opencode_response.txt)`\n3. **Max safe combined size**: ~80K chars (4 × 20K) ≈ 20K tokens, well under 25K limit\n4. **If responses are still too large**: Reduce `CONSULT_MAX_RESPONSE_CHARS` to 15000\n\n### Step 6: Report Status\n\nShow which AIs responded:\n\n```bash\necho \"---\"\necho \"Consultation Results:\"\n[ -n \"$GEMINI_RESPONSE\" ] && echo \"  Gemini: ✓\" || echo \"  Gemini: ✗ ($(head -1 \"$GEMINI_ERR\" 2>/dev/null || echo 'no response'))\"\n[ -n \"$CODEX_RESPONSE\" ] && echo \"  Codex: ✓\" || echo \"  Codex: ✗ ($(head -1 \"$CODEX_ERR\" 2>/dev/null || echo 'no response'))\"\n[ -n \"$QWEN_RESPONSE\" ] && echo \"  Qwen: ✓\" || echo \"  Qwen: ✗ ($(head -1 \"$QWEN_ERR\" 2>/dev/null || echo 'no response'))\"\n[ -n \"$OPENCODE_RESPONSE\" ] && echo \"  OpenCode: ✓\" || echo \"  OpenCode: ✗ ($(head -1 \"$OPENCODE_ERR\" 2>/dev/null || echo 'no response'))\"\n\n# Count successful responses\nSUCCESS_COUNT=0\n[ -n \"$GEMINI_RESPONSE\" ] && SUCCESS_COUNT=$((SUCCESS_COUNT + 1))\n[ -n \"$CODEX_RESPONSE\" ] && SUCCESS_COUNT=$((SUCCESS_COUNT + 1))\n[ -n \"$QWEN_RESPONSE\" ] && SUCCESS_COUNT=$((SUCCESS_COUNT + 1))\n[ -n \"$OPENCODE_RESPONSE\" ] && SUCCESS_COUNT=$((SUCCESS_COUNT + 1))\n\necho \"  Consensus basis: $SUCCESS_COUNT/4 AIs responded\"\necho \"---\"\n```\n\n### Step 7: Synthesize Response\n\nIf `--verbose` was specified, show individual responses first.\n\n#### Tiered Synthesis Strategy\n\nChoose synthesis approach based on **total response size**:\n\n```bash\n# Calculate total response size\nTOTAL_CHARS=$((${#GEMINI_RESPONSE} + ${#CODEX_RESPONSE} + ${#QWEN_RESPONSE} + ${#OPENCODE_RESPONSE}))\necho \"Total response size: $TOTAL_CHARS chars\"\n```\n\n| Tier | Total Size | Strategy |\n|------|-----------|----------|\n| **Small** | < 30K chars | Read all responses directly, synthesize in one pass |\n| **Medium** | 30K-80K chars | Summarize each response first, then synthesize summaries |\n| **Large** | > 80K chars | Process incrementally: read → summarize → integrate one at a time |\n\n**Tier 1 (Small):** Direct synthesis - read all and combine.\n\n**Tier 2 (Medium):** First summarize each response:\n\n```\nFor each AI response, extract:\n1. Main recommendation/answer (1-2 sentences)\n2. Key reasoning/evidence (2-3 bullet points)\n3. Notable caveats or alternatives\n4. Unique insights not mentioned by others\n```\n\n**Tier 3 (Large):** Incremental synthesis:\n1. Read + summarize Gemini response\n2. Read Codex, compare to Gemini summary, update synthesis\n3. Read Qwen, integrate new points\n4. Read OpenCode, finalize synthesis\n\n#### Synthesis Guidelines\n\nCombine all perspectives into a **single unified response**:\n\n- Do NOT show separate \"According to Gemini/Codex/Qwen/OpenCode\" sections\n- Integrate the best insights from all responding AIs into one cohesive answer\n- If they agree, present the consensus with high confidence\n- If they disagree, synthesize a balanced view incorporating all perspectives\n- Present as your own synthesized analysis\n- **Deduplicate**: AI responses often overlap - don't repeat the same point multiple times\n\n**Confidence indicator** (optional footer):\n- **High** (4/4 or 3/3 agree on core points)\n- **Medium** (3/4 agree, or 2/2 with partial overlap)\n- **Low** (significant disagreement or only 1-2 responses)\n\n### Step 8: Cleanup\n\nCleanup happens automatically via the trap, but you can also explicitly call:\n\n```bash\ncleanup\n```\n\n## Exit Codes\n\nUse distinct exit codes for scripting:\n\n| Code | Meaning |\n|------|---------|\n| 0 | Success - at least 2 AIs responded |\n| 1 | Partial success - only 1 AI responded |\n| 2 | All AIs failed - auth errors |\n| 3 | All AIs failed - rate limit |\n| 4 | All AIs failed - timeout |\n| 5 | All AIs failed - other errors |\n| 10 | No AI CLIs installed |\n| 11 | Missing required dependency (jq) |\n\n## Error Handling Summary\n\n### CLI Installation\nIf a CLI is missing, continue with others. Provide installation guidance only when asked:\n- **Gemini**: `npm install -g @anthropic-ai/gemini-cli` or `pip install google-generativeai`\n- **Codex**: `npm install -g @openai/codex`\n- **Qwen**: `npm install -g @anthropic-ai/qwen-cli`\n- **OpenCode**: See https://opencode.ai/docs/installation\n\n### Graceful Degradation\n- **3/4 respond**: Full synthesis, note one was unavailable\n- **2/4 respond**: Synthesis with reduced confidence\n- **1/4 responds**: Report single response, offer Claude-only alternative\n- **0/4 respond**: Report all errors, provide Claude-only response\n\n## Example\n\nUser: `/consult How should I structure my React state management?`\n\n1. **Verify**: Check available CLIs and jq\n2. **Prepare**: \"What are best practices for structuring React state management? Consider scalability, maintainability, and performance.\"\n3. **Execute**: Run available CLIs in parallel with 120s timeout\n4. **Retry**: Any failures get one retry with 2s backoff\n5. **Parse**: Extract responses using jq:\n   - Gemini: `.response`\n   - Codex: NDJSON `.item.text` from `agent_message`\n   - Qwen: `.response`\n   - OpenCode: NDJSON `.part.text`\n6. **Report**: \"Gemini ✓ | Codex ✓ | Qwen ✓ | OpenCode ✓ (4/4)\"\n7. **Synthesize**: \"For React state management, consider a layered approach: local state for UI concerns, Context for shared app state, and a dedicated store (Redux/Zustand) for complex global state. Key principles include...\""
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}