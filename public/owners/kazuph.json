{
  "owner": {
    "id": "kazuph",
    "display_name": "Kazuhiro Homma",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/849165?v=4",
    "url": "https://github.com/kazuph",
    "bio": "Creator of Akerun, Co-Founder \r\n at Photosynth Inc.\r\n",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 2,
      "total_skills": 2,
      "total_stars": 16,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "kazuph/reviw",
      "url": "https://github.com/kazuph/reviw",
      "description": "Human-in-the-loop review interface for AI coding workflows",
      "homepage": null,
      "signals": {
        "stars": 16,
        "forks": 0,
        "pushed_at": "2026-01-11T14:02:30Z",
        "created_at": "2025-11-26T07:24:33Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".artifacts",
          "type": "tree",
          "size": null
        },
        {
          "path": ".artifacts/csv-01-initial.png",
          "type": "blob",
          "size": 206168
        },
        {
          "path": ".artifacts/csv-02-comment-card.png",
          "type": "blob",
          "size": 207055
        },
        {
          "path": ".artifacts/csv-03-comment-saved.png",
          "type": "blob",
          "size": 193314
        },
        {
          "path": ".artifacts/csv-04-filter-menu.png",
          "type": "blob",
          "size": 205534
        },
        {
          "path": ".artifacts/csv-05-filtered.png",
          "type": "blob",
          "size": 219643
        },
        {
          "path": ".artifacts/dialog-position-test.png",
          "type": "blob",
          "size": 222424
        },
        {
          "path": ".artifacts/md-01-initial.png",
          "type": "blob",
          "size": 165628
        },
        {
          "path": ".artifacts/md-02-comment-card.png",
          "type": "blob",
          "size": 169532
        },
        {
          "path": ".artifacts/md-03-comment-saved.png",
          "type": "blob",
          "size": 160760
        },
        {
          "path": ".artifacts/md-04-comment-list.png",
          "type": "blob",
          "size": 178647
        },
        {
          "path": ".artifacts/md-05-code-block.png",
          "type": "blob",
          "size": 183576
        },
        {
          "path": ".artifacts/multi-01-csv.png",
          "type": "blob",
          "size": 193026
        },
        {
          "path": ".artifacts/multi-02-md.png",
          "type": "blob",
          "size": 178209
        },
        {
          "path": ".artifacts/multi-03-csv-comment.png",
          "type": "blob",
          "size": 193329
        },
        {
          "path": ".artifacts/multi-04-md-comment.png",
          "type": "blob",
          "size": 164927
        },
        {
          "path": ".artifacts/tsv-01-initial.png",
          "type": "blob",
          "size": 198392
        },
        {
          "path": ".artifacts/tsv-02-comment-card.png",
          "type": "blob",
          "size": 207059
        },
        {
          "path": ".artifacts/tsv-03-comment-saved.png",
          "type": "blob",
          "size": 193309
        },
        {
          "path": ".artifacts/tsv-04-filter-menu.png",
          "type": "blob",
          "size": 205535
        },
        {
          "path": ".artifacts/tsv-05-filtered.png",
          "type": "blob",
          "size": 219644
        },
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 394
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 90
        },
        {
          "path": "AGENTS.md",
          "type": "blob",
          "size": 810
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 2258
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1063
        },
        {
          "path": "README.ja.md",
          "type": "blob",
          "size": 15747
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 15607
        },
        {
          "path": "assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "assets/logo.svg",
          "type": "blob",
          "size": 3623
        },
        {
          "path": "assets/screenshot-csv.png",
          "type": "blob",
          "size": 197772
        },
        {
          "path": "assets/screenshot-diff.png",
          "type": "blob",
          "size": 210639
        },
        {
          "path": "assets/screenshot-md.png",
          "type": "blob",
          "size": 234594
        },
        {
          "path": "assets/screenshot-mermaid.png",
          "type": "blob",
          "size": 64202
        },
        {
          "path": "assets/screenshot-submit-dialog.png",
          "type": "blob",
          "size": 1188479
        },
        {
          "path": "cli.cjs",
          "type": "blob",
          "size": 268161
        },
        {
          "path": "examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/assets/screenshot-after.png",
          "type": "blob",
          "size": 3081
        },
        {
          "path": "examples/assets/screenshot-before.png",
          "type": "blob",
          "size": 3453
        },
        {
          "path": "examples/table-long-text.md",
          "type": "blob",
          "size": 3883
        },
        {
          "path": "examples/table-with-videos.md",
          "type": "blob",
          "size": 1057
        },
        {
          "path": "examples/test-features.md",
          "type": "blob",
          "size": 2784
        },
        {
          "path": "examples/videos",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/videos/test-video.mp4",
          "type": "blob",
          "size": 32159
        },
        {
          "path": "examples/videos/video-landscape.mp4",
          "type": "blob",
          "size": 8119
        },
        {
          "path": "examples/videos/video-portrait.mp4",
          "type": "blob",
          "size": 6753
        },
        {
          "path": "examples/videos/video-square.mp4",
          "type": "blob",
          "size": 6703
        },
        {
          "path": "package-lock.json",
          "type": "blob",
          "size": 49925
        },
        {
          "path": "package.json",
          "type": "blob",
          "size": 694
        },
        {
          "path": "plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 489
        },
        {
          "path": "plugin/README.md",
          "type": "blob",
          "size": 4931
        },
        {
          "path": "plugin/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/agents/report-builder.md",
          "type": "blob",
          "size": 9173
        },
        {
          "path": "plugin/agents/review-code-security.md",
          "type": "blob",
          "size": 7928
        },
        {
          "path": "plugin/agents/review-e2e.md",
          "type": "blob",
          "size": 8551
        },
        {
          "path": "plugin/agents/review-ui-ux.md",
          "type": "blob",
          "size": 8250
        },
        {
          "path": "plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/commands/do.md",
          "type": "blob",
          "size": 19238
        },
        {
          "path": "plugin/commands/done.md",
          "type": "blob",
          "size": 13178
        },
        {
          "path": "plugin/hooks-handlers",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/hooks-handlers/completion-checklist.sh",
          "type": "blob",
          "size": 1847
        },
        {
          "path": "plugin/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/hooks/hooks.json",
          "type": "blob",
          "size": 1214
        },
        {
          "path": "plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/artifact-proof",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/artifact-proof/SKILL.md",
          "type": "blob",
          "size": 16825
        },
        {
          "path": "plugin/skills/webapp-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/webapp-testing/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugin/skills/webapp-testing/SKILL.md",
          "type": "blob",
          "size": 9288
        },
        {
          "path": "plugin/skills/webapp-testing/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugin/skills/webapp-testing/examples/node_site_diagnostics.js",
          "type": "blob",
          "size": 1368
        },
        {
          "path": "screenshot-test.cjs",
          "type": "blob",
          "size": 4319
        },
        {
          "path": "screenshot-test.js",
          "type": "blob",
          "size": 1401
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/screenshot.mjs",
          "type": "blob",
          "size": 1963
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/csv.test.js",
          "type": "blob",
          "size": 3410
        },
        {
          "path": "tests/fixtures",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/fixtures/bullet-list.md",
          "type": "blob",
          "size": 783
        },
        {
          "path": "tests/fixtures/sample.csv",
          "type": "blob",
          "size": 158
        },
        {
          "path": "tests/fixtures/sample.md",
          "type": "blob",
          "size": 331
        },
        {
          "path": "tests/fixtures/sample.tsv",
          "type": "blob",
          "size": 158
        },
        {
          "path": "tests/fixtures/simple.md",
          "type": "blob",
          "size": 439
        },
        {
          "path": "tests/fixtures/test-mermaid.md",
          "type": "blob",
          "size": 9690
        },
        {
          "path": "tests/fixtures/test-questions.md",
          "type": "blob",
          "size": 1127
        },
        {
          "path": "tests/fixtures/test.diff",
          "type": "blob",
          "size": 133
        },
        {
          "path": "tests/link-click.test.js",
          "type": "blob",
          "size": 3269
        },
        {
          "path": "tests/localStorage-test.cjs",
          "type": "blob",
          "size": 6619
        },
        {
          "path": "tests/markdown.test.js",
          "type": "blob",
          "size": 9392
        },
        {
          "path": "tests/multifile.test.js",
          "type": "blob",
          "size": 6571
        },
        {
          "path": "tests/parsers.test.js",
          "type": "blob",
          "size": 10445
        },
        {
          "path": "tests/tsv.test.js",
          "type": "blob",
          "size": 3388
        },
        {
          "path": "vitest.config.js",
          "type": "blob",
          "size": 144
        }
      ],
      "marketplace": {
        "name": "reviw-plugins",
        "version": null,
        "description": "reviw - Browser-based file review tool with YAML output",
        "owner_info": {
          "name": "kazuph",
          "url": "https://github.com/kazuph"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "reviw-plugin",
            "description": "reviw CLI integration for Claude Code - task management, review workflow, and report generation",
            "source": "./plugin",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add kazuph/reviw",
              "/plugin install reviw-plugin@reviw-plugins"
            ],
            "signals": {
              "stars": 16,
              "forks": 0,
              "pushed_at": "2026-01-11T14:02:30Z",
              "created_at": "2025-11-26T07:24:33Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/do",
                "description": "Task Start - worktree creation, planning, and review preparation in reviw",
                "path": "plugin/commands/do.md",
                "frontmatter": {
                  "description": "Task Start - worktree creation, planning, and review preparation in reviw",
                  "argument-hint": "<task description>",
                  "allowed-tools": "Bash, Read, Write, Edit, Glob, Grep, TodoWrite, Task, AskUserQuestion"
                },
                "content": "# Task Start Command\n\nReceive requests for tasks to be done, set up the work environment, and create a plan.\n\n**Role: You are the Project Manager (PM) interviewing the Product Owner (user).**\n\n## Phase 0: Interactive Discovery (REQUIRED)\n\nBefore any implementation, conduct a structured interview with the user to fully understand requirements.\n\n### Step 0-1: Development Approach Question\n\n**Use AskUserQuestion tool** to ask about development approach:\n\n```\nQuestion: \"How would you like to organize this work?\"\nHeader: \"Approach\"\nOptions:\n  1. \"Use worktree (Recommended)\" - Create isolated branch in .worktree/ directory. Clean separation, easy cleanup.\n  2. \"Work in current branch\" - Make changes directly in current branch. Simpler for small changes.\n  3. \"Create new branch only\" - Create branch but work in main directory. Middle ground.\n```\n\n### Step 0-2: Specification Deep-Dive (PM Interview)\n\n**As Project Manager, drill down into specifications with multiple rounds of questions.**\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│  PM Interview Protocol (Iterative Questioning)                  │\n├─────────────────────────────────────────────────────────────────┤\n│                                                                 │\n│  Round 1: User Story & Scope                                    │\n│    - What problem does this solve?                              │\n│    - Who is the target user?                                    │\n│    - What is the expected outcome?                              │\n│    - What is NOT in scope?                                      │\n│                                                                 │\n│  Round 2: Functional Requirements (based on Round 1)            │\n│    - What are the specific actions users will take?             │\n│    - What data inputs/outputs are needed?                       │\n│    - What are the edge cases?                                   │\n│    - What validation rules apply?                               │\n│                                                                 │\n│  Round 3: Technical Constraints (based on Round 1-2)            │\n│    - Are there performance requirements?                        │\n│    - Are there existing patterns to follow?                     │\n│    - What dependencies are involved?                            │\n│    - Are there security considerations?                         │\n│                                                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n**Use AskUserQuestion tool iteratively:**\n\n1. First, ask 2-3 questions about user story and scope\n2. Based on answers, formulate 2-3 follow-up questions about functional details\n3. Based on answers, ask about technical constraints and preferences\n4. Summarize understanding and confirm before proceeding\n\n**Example question flow:**\n\n```\nRound 1 Example:\nQ1: \"What specific problem are you trying to solve?\"\nQ2: \"Who will use this feature and in what context?\"\nQ3: \"What does success look like for this feature?\"\n\nRound 2 Example (based on Round 1 answers):\nQ4: \"You mentioned X - what happens when Y?\"\nQ5: \"Should the system handle Z case?\"\nQ6: \"What error messages should users see?\"\n\nRound 3 Example (based on Round 1-2 answers):\nQ7: \"Should we follow the existing pattern in [file] or try something different?\"\nQ8: \"Given the requirements, I see two approaches: A or B. Which do you prefer?\"\n```\n\n### Step 0-3: Architecture & Implementation Approach\n\n**After understanding requirements, propose implementation approach and confirm:**\n\n```\nUse AskUserQuestion to present options:\n\nQuestion: \"Based on our discussion, here are the implementation approaches:\"\nHeader: \"Architecture\"\nOptions:\n  1. \"[Approach A]\" - [Brief explanation with trade-offs]\n  2. \"[Approach B]\" - [Brief explanation with trade-offs]\n  3. \"Let me explain more\" - Need more context before deciding\n```\n\n**Only proceed to implementation after user confirms approach.**\n\n### Step 0-4: Record Q&A in REPORT.md (REQUIRED)\n\n**All questions asked and answers received MUST be recorded in REPORT.md.**\n\nAfter completing the interview, add the following section to REPORT.md:\n\n```markdown\n## Requirements Discovery (Q&A Log)\n\n### Development Approach\n- **Q**: How would you like to organize this work?\n- **A**: [User's answer]\n\n### User Story & Scope\n- **Q**: [Question 1]\n- **A**: [Answer 1]\n\n- **Q**: [Question 2]\n- **A**: [Answer 2]\n\n### Functional Requirements\n- **Q**: [Question 3]\n- **A**: [Answer 3]\n\n### Architecture Decision\n- **Q**: [Implementation approach question]\n- **A**: [User's choice and reasoning]\n\n### Key Decisions Summary\n| Decision | Choice | Reasoning |\n|----------|--------|-----------|\n| Development approach | worktree / current branch | [reason] |\n| Architecture | [chosen approach] | [reason] |\n| [Other key decision] | [choice] | [reason] |\n```\n\n**Why this matters:**\n- Preserves context for future sessions (after compact)\n- Documents requirements for review\n- Enables traceability of decisions\n- Helps when resuming work\n\n## Important: Subagents Required\n\n**To prevent context exhaustion, the following tasks MUST be executed by subagents (Task tool):**\n\n| Task | Reason | Subagent |\n|------|------|-----------------|\n| webapp-testing | Context explosion from screenshot Read | `subagent_type: \"general-purpose\"` |\n| artifact-proof | Exhaustion from image/video processing | `subagent_type: \"general-purpose\"` |\n| E2E test execution | Context consumption from long logs | `subagent_type: \"general-purpose\"` |\n\n```\nWhen webapp-testing is executed directly in the main thread:\n   → Read screenshots → Context exhaustion → compact triggered\n   → Forgets /done content → Reports \"Implementation complete!\"\n   → Rejection → Infinite loop\n```\n\n**Correct approach:**\n```\nLaunch subagent with Task tool\n→ Execute webapp-testing within subagent\n→ Subagent summarizes results and returns\n→ Main thread context is preserved\n```\n\n## Arguments\n\n$ARGUMENTS = Request text for what to do, specification explanation, etc.\n\n## When Resuming a Task\n\n**At session startup / after compact, check existing worktrees before creating new ones.**\n\n```bash\n# Check worktrees in progress\ngit worktree list\n\n# Move to worktree\ncd .worktree/<feature-name>\n\n# Check progress\ncat .artifacts/<feature-name>/REPORT.md\n```\n\n**Check TODOs in REPORT.md and resume work from incomplete items.**\n\n### Report Location\n\n```\n.worktree/<feature-name>/.artifacts/<feature-name>/REPORT.md\n```\n\n※ `<feature-name>` = part after removing prefix from branch name (e.g., `feature/auth` → `auth`)\n\n## Execution Steps (For New Tasks)\n\n### 1. Work Environment Setup\n\nFirst, verify that the current project is a git repository.\n\n```bash\n# Execute at project root\ngit rev-parse --show-toplevel\n```\n\nNext, create a worktree for the task. Branch name is automatically generated appropriately from the request content.\n\n### worktree Naming Convention\n\n| Type | Branch Name | Example |\n|------|-----------|-----|\n| New feature | `feature/<feature-name>` | `feature/auth`, `feature/events` |\n| Bug fix | `fix/<content>` | `fix/login-error`, `fix/validation` |\n| Refactoring | `refactor/<target>` | `refactor/api-client` |\n| Documentation | `docs/<target>` | `docs/readme` |\n\n```bash\n# Create worktree (--from-current to branch from current branch)\ngit gtr new <branch-name> --from-current\n\n# Get worktree path\nWORKTREE_PATH=\"$(git gtr go <branch-name>)\"\n\n# Move to worktree\ncd \"$WORKTREE_PATH\"\n```\n\n### 2. .gitignore Configuration\n\n**Important:** Exclude `.worktree` and `.artifacts` from commit targets.\n\n```bash\n# Add to project root .gitignore (only if not already present)\nif ! grep -q \"^\\.worktree$\" .gitignore 2>/dev/null; then\n  echo \".worktree\" >> .gitignore\nfi\nif ! grep -q \"^\\.artifacts$\" .gitignore 2>/dev/null; then\n  echo \".artifacts\" >> .gitignore\nfi\n```\n\n**Reason:**\n- `.worktree/` - Work directory is for local use only\n- `.artifacts/` - Evidence (screenshots/videos) excluded to prevent repository bloat\n\n**When you want to commit specific evidence:**\n\nEven if included in `.gitignore`, you can explicitly add with `git add --force`:\n\n```bash\n# Force add specific files\ngit add --force .artifacts/<feature>/images/important-screenshot.png\ngit add --force .artifacts/<feature>/REPORT.md\n\n# Use Git LFS for videos\ngit lfs track \"*.mp4\" \"*.webm\"\ngit add .gitattributes\ngit add --force .artifacts/<feature>/videos/demo.mp4\n```\n\nThe recommended approach is to exclude by default and explicitly commit only what's needed.\n\n### 3. Deliverables Directory Preparation\n\nCreate `.artifacts/<feature-name>/` directory within the worktree.\n\n**Directory Structure:**\n```\n.worktree/<feature-name>/\n└── .artifacts/\n    └── <feature-name>/\n        ├── REPORT.md     # Plan, progress, and evidence links\n        ├── images/       # Screenshots\n        └── videos/       # Video files\n```\n\n```bash\nmkdir -p .artifacts/<feature-name>/{images,videos}\n```\n\n### 4. Planning (REPORT.md)\n\nCreate `.artifacts/<feature-name>/REPORT.md` and write the plan in the following format:\n\n```markdown\n# <Task Name>\n\nCreated: YYYY-MM-DD\nBranch: <branch-name>\nStatus: In Progress\n\n## Overview\n\n<Summary of request content>\n\n## Progress\n\n| Date | Content | Status |\n|------|------|------|\n| YYYY-MM-DD | Planning | Completed |\n| YYYY-MM-DD | API Implementation | In Progress |\n\n## PLAN\n\n### TODO\n\n- [ ] <Specific task 1>\n- [ ] <Specific task 2>\n- [ ] <Specific task 3>\n- [ ] Execute build and type check\n- [ ] Start development server\n- [ ] Verify operation with webapp-testing\n- [ ] Collect evidence with artifact-proof\n- [ ] Complete report with /done (review in reviw)\n\n### Completion Criteria\n\n- [ ] Implementation completed\n- [ ] Build successful\n- [ ] Operation verified\n- [ ] Evidence (screenshots/videos) collected\n- [ ] Reviewed in reviw\n\n## Test Results\n\n### Unit Tests\n- `tests/unit/xxx.test.ts`: PASS/FAIL\n\n### Integration Tests\n- `tests/integration/xxx.test.ts`: PASS/FAIL\n\n### E2E Tests\n- `tests/e2e/xxx.spec.ts`: PASS/FAIL\n\n## Technical Notes\n\n<Add notes and observations during implementation>\n\n## Evidence\n\n<Add links to evidence collected with artifact-proof>\n```\n\n### 5. Reflection to TodoWrite\n\nReflect the above PLAN to the TodoWrite tool as well. This visualizes progress.\n\n### 6. Parallel Implementation with Subagents\n\n**After planning, implementation MUST be executed with subagents (Task tool).**\n\nThe main thread should focus on the director role and proceed with the following flow:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Main Thread (Director)                                     │\n│                                                             │\n│  1. Planning completed                                      │\n│  2. Classify tasks by dependencies                          │\n│     ├─ Independent tasks → Launch subagents in parallel     │\n│     └─ Dependent tasks → Launch after previous completion   │\n│  3. Integrate results from each subagent                    │\n│  4. Proceed to next phase                                   │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Example of Parallel Execution:**\n\n```\n# Launch 3 independent component implementations in parallel\nTask(subagent_type=\"webapp-master\", prompt=\"Implement HeaderComponent...\")\nTask(subagent_type=\"webapp-master\", prompt=\"Implement SidebarComponent...\")\nTask(subagent_type=\"webapp-master\", prompt=\"Implement FooterComponent...\")\n```\n\n**Subagent Selection Criteria:**\n\n| Task Type | subagent_type | Notes |\n|-----------|---------------|------|\n| Web UI Implementation | `webapp-master` | General frontend |\n| Expo/RN Implementation | `expo-app-maker` | Mobile apps |\n| Code Investigation | `Explore` | Understanding existing code |\n| Design Review | `Plan` | Architecture review |\n| Operation Verification | `general-purpose` + webapp-testing skill | Verification phase |\n| Evidence Collection | `general-purpose` + artifact-proof skill | Completion report preparation |\n\n### 7. Confirm Action Guidelines Focused on Deliverables\n\n**Display important notes:**\n\n```\n+---------------------------------------------------------------+\n|  Task Start                                                   |\n+---------------------------------------------------------------+\n|                                                               |\n|  Current location: $WORKTREE_PATH                             |\n|  Branch: <branch-name>                                        |\n|                                                               |\n|  Implementation completion is only 1/3 of the work            |\n|                                                               |\n|  Completion criteria:                                         |\n|    1/3: Implementation complete                               |\n|    2/3: Build, start, and operation verification complete     |\n|    3/3: Review in reviw → User approval                       |\n|                                                               |\n|  Tools to use:                                                |\n|    - reviw: Browser-based review tool                         |\n|    - webapp-testing: Browser operation and verification       |\n|    - artifact-proof: Evidence collection                      |\n|                                                               |\n|  Execute /done when work is complete to start review          |\n|                                                               |\n+---------------------------------------------------------------+\n```\n\n## E2E Test Policy (CRITICAL - Read Before Implementation)\n\n**E2E tests will be strictly reviewed by the review-e2e agent at /done. Implementing without understanding these rules will result in rejection and rework.**\n\n### Absolute Prohibitions\n\n| Category | Prohibited | Reason |\n|----------|-----------|--------|\n| **Mocks** | `jest.fn`, `vi.fn`, `sinon.*`, `mock`, `Mock` | Fake behavior hides real bugs |\n| **Network intercepts** | `route.fulfill`, `page.route`, `nock`, `msw` | Must test real API |\n| **Time mocks** | `useFakeTimers`, `clock.*`, `setSystemTime` | Must test real timing |\n| **DB mocks** | `mockPrisma`, `mockFirestore`, `mockDatabase` | Must use real emulator |\n| **Auth shortcuts** | `loginAs`, `signInAs`, `setAuthToken`, `setSession` | Must go through UI |\n| **Direct API calls** | `fetch()`, `axios.*` in tests (except setup) | UI operations only |\n| **localStorage/sessionStorage direct manipulation** | `localStorage.setItem` in tests | Must use UI |\n\n### goto Restrictions\n\n```\n✅ Allowed:\n   - page.goto('/') or page.goto(baseUrl)  // First navigation only\n   - page.goto('http://localhost:9099')     // Emulator switch (Firebase etc.)\n   - page.goto(process.env.MAILPIT_URL)     // Emulator switch\n\n❌ Prohibited:\n   - page.goto('/dashboard')  // After initial navigation - use UI clicks\n   - page.goto('/settings')   // After initial navigation - use UI clicks\n```\n\n### Required Patterns\n\n| Pattern | Requirement |\n|---------|-------------|\n| **Navigation** | After first goto, ALL navigation must be via UI clicks |\n| **Authentication** | Must go through actual login form (UI flow) |\n| **Data creation** | Use seed data or create via UI operations |\n| **Waiting** | Use element/state-based waits, NOT `sleep` or `waitForTimeout` |\n| **Assertions** | Include DB/record change assertions, not just UI checks |\n\n### Dependency Injection (DI)\n\n```\n✅ Correct DI:\n   - Firebase Emulator (localhost:9099)\n   - Mailpit (localhost:8025)\n   - Environment variable switching\n\n❌ Wrong approach:\n   - Mocking Firebase in code\n   - Stubbing email sending\n   - In-memory database replacement\n```\n\n### Example: Good vs Bad E2E Test\n\n```typescript\n// ❌ BAD - Will be rejected at review\ntest('user can view dashboard', async () => {\n  await page.goto('/dashboard');  // NG: Direct navigation\n  localStorage.setItem('token', 'fake-token');  // NG: Auth shortcut\n  await expect(page.locator('.dashboard')).toBeVisible();\n});\n\n// ✅ GOOD - Will pass review\ntest('user can view dashboard', async () => {\n  await page.goto('/');  // OK: Initial navigation\n  await page.fill('[data-testid=\"email\"]', 'test@example.com');\n  await page.fill('[data-testid=\"password\"]', 'password123');\n  await page.click('[data-testid=\"login-button\"]');  // OK: UI flow\n  await expect(page.locator('.dashboard')).toBeVisible();\n\n  // Assert DB state changed\n  const user = await db.query('SELECT * FROM users WHERE email = ?', ['test@example.com']);\n  expect(user.last_login).toBeTruthy();\n});\n```\n\n**Understanding this policy before writing E2E tests prevents 90% of rejections at review.**\n\n## Prohibited Actions\n\n- **Direct work on main branch prohibited** - Always create a worktree before starting work\n- Starting implementation without a plan\n- Working on main branch without creating a worktree\n- Forgetting to collect evidence\n- Reporting completion without executing /done\n- Writing code directly in the main thread (causes context exhaustion)\n- Only declaring \"will implement\" without launching subagents\n- Executing parallelizable tasks sequentially (reduced efficiency)\n- **Writing E2E tests without reading the E2E Test Policy above**\n- **Using mocks, stubs, or shortcuts in E2E tests**\n\n## PR Creation Flow (Reference)\n\nFollow the project's CLAUDE.md for PR creation target (develop / main).\n\n```bash\n# 1. After completing work in worktree\ncd .worktree/<feature-name>\n\n# 2. Commit (after executing /done)\ngit add .\ngit commit -m \"feat: <content>\"\n\n# 3. Push\ngit push -u origin <branch-name>\n\n# 4. Create PR (follow project settings)\ngh pr create --base <target-branch> --head <branch-name>\n\n# 5. After merge, remove worktree\ncd ../..\ngit worktree remove .worktree/<feature-name>\n```\n\n**Note**: Some projects prohibit AI from creating PRs directly to main. Check the project's CLAUDE.md.\n\n## Example\n\n```\n/do Add a login button that navigates to /login when clicked\n```\n\nThis will:\n1. Create a worktree with `feature/add-login-button` branch\n2. Write the plan to `.worktree/add-login-button/.artifacts/add-login-button/REPORT.md`\n3. Register TODOs in TodoWrite\n4. Display deliverable-focused action guidelines"
              },
              {
                "name": "/done",
                "description": "Task completion check - Evidence collection, reviw review initiation",
                "path": "plugin/commands/done.md",
                "frontmatter": {
                  "description": "Task completion check - Evidence collection, reviw review initiation",
                  "allowed-tools": "Bash, Read, Write, Edit, Glob, Grep, TodoWrite, Task, AskUserQuestion"
                },
                "content": "# Task Completion Checklist\n\nWhen you think implementation is done, run this command to verify completion criteria are met.\n\n## Phase 0: Report Level Selection (REQUIRED)\n\n**Before starting the review process, ask user about desired report level.**\n\nUse AskUserQuestion tool:\n\n```\nQuestion: \"What level of report do you need for this task?\"\nHeader: \"Report Level\"\nOptions:\n  1. \"Full Review (Recommended)\" - All 3 review agents + detailed evidence + comprehensive REPORT.md\n  2. \"Quick Review\" - E2E + Code Security only, minimal evidence\n  3. \"Evidence Only\" - Skip review agents, just collect screenshots/videos\n  4. \"Skip to reviw\" - Already have evidence, go straight to reviw review\n```\n\n**Actions based on selection:**\n\n| Level | Review Agents | Evidence | REPORT.md |\n|-------|---------------|----------|-----------|\n| Full Review | All 3 (code-security, e2e, ui-ux) | Screenshots + Video | Comprehensive |\n| Quick Review | 2 (code-security, e2e) | Screenshots only | Summary |\n| Evidence Only | Skip | Screenshots + Video | Basic |\n| Skip to reviw | Skip | Use existing | Use existing |\n\n## Important: Subagent Mandatory (compact countermeasure)\n\n**Forgetting this rule and reporting \"Implemented!\" happens because context is lost due to compact.**\n**The following work MUST be executed by subagents (Task tool):**\n\n| Work | Reason | Subagent |\n|------|--------|----------|\n| Report creation/evidence organization | Context depletion from image/video processing | `subagent_type: \"report-builder\"` |\n| webapp-testing | Context explosion from screenshot Read | `subagent_type: \"general-purpose\"` |\n| E2E test execution | Context consumption from long logs | `subagent_type: \"general-purpose\"` |\n\n```\nBad pattern (direct execution on main thread):\n   webapp-testing screenshot capture\n   → Read screenshot\n   → Context depletion\n   → compact triggered\n   → /done contents forgotten\n   → Report with \"Implemented!\"\n   → Infinite loop\n\nGood pattern (execution via subagent):\n   Launch subagent with Task tool\n   → Execute webapp-testing within subagent\n   → Subagent verifies screenshots\n   → Return summary to main thread\n   → Main thread context preserved\n   → Can report while remembering /done rules\n```\n\n## Handoff from /do\n\nTasks started with `/do` have their PLAN recorded in `.artifacts/<feature>/REPORT.md`.\nFirst, verify the TODO status:\n\n```bash\n# Check REPORT.md in .artifacts directory\ncat .artifacts/*/REPORT.md | grep -A 50 \"## PLAN\"\n```\n\n**What does checking a TODO mean?**\n\n| Check status | Meaning | Next action |\n|--------------|---------|-------------|\n| `- [ ]` Unchecked | Not yet complete | Continue work |\n| `- [x]` Checked | **Verified** and complete | Move to next item |\n\n**Important: Do NOT check items for \"just implemented\"**\n\nConditions for checking:\n- Implementation + Build success + Operation verification + Evidence collection\n\n## Completion Criteria (3 stages)\n\n| Stage | Content | Progress |\n|-------|---------|----------|\n| 1/3 | Implementation complete | Do NOT report yet |\n| 2/3 | Build/start/operation verification complete | Do NOT report yet |\n| 3/3 | reviw review → User approval | Now finally complete |\n\n```\n+---------------------------------------------------------------+\n|  Implementation complete ≠ Task complete                      |\n+---------------------------------------------------------------+\n|                                                               |\n|  \"Implemented\" → Rejected                                     |\n|  \"Build passed\" → Rejected                                    |\n|  \"It works (no evidence)\" → Rejected                          |\n|                                                               |\n|  \"Verified operation with evidence\" → Finally review starts   |\n|                                                               |\n+---------------------------------------------------------------+\n```\n\n## Required Actions After Implementation\n\nDo NOT say \"complete\" until all of the following are executed:\n\n### 0. Verify TODO Current Status (Rejection Determination)\n\n```\nCheck current TODO status and reject if any of the following apply:\n\n- Only implementation TODOs are checked → Reject\n- Verification TODOs (build/operation check) are unchecked → Reject\n- Evidence collection TODOs are unchecked → Reject\n\nOn rejection, display:\n\"Implementation alone is not completion. Execute build → operation verification → evidence collection.\"\n```\n\n### 1. Execute Build\n   - Verify no errors with `npm run build` / `pnpm build` etc.\n   - Check for type errors, lint errors\n\n### 2. Start Development Server (for Web projects)\n   - Actually start the server\n\n### 3. Operation Verification\n   - Use `webapp-testing` skill to actually operate in browser\n   - Verify expected behavior\n\n### 4. Comprehensive Review (3 Integrated Review Agents in Parallel)\n\n**Launch all 3 review agents simultaneously with Task tool:**\n\n```\nLaunch THREE agents simultaneously with Task tool:\n\n1. subagent_type: \"reviw-plugin:review-code-security\"\n   → Type safety (any type detection)\n   → Error handling adequacy\n   → DRY principle violations\n   → XSS, injection, OWASP Top 10\n   → Hardcoded secrets, auth issues\n   → Append \"Code & Security Review\" section to REPORT.md\n\n2. subagent_type: \"reviw-plugin:review-e2e\"\n   → goto restrictions (only first \"/\" allowed)\n   → Mock/stub detection (ALL mocks prohibited)\n   → User flow reproduction fidelity\n   → DI (Dependency Injection) adequacy\n   → Record change assertions\n   → Wait strategy verification (no fixed sleeps)\n   → Hardcoded values/environment locks\n   → Append \"E2E Test Review\" section to REPORT.md\n\n3. subagent_type: \"reviw-plugin:review-ui-ux\"\n   → WCAG 2.2 AA compliance\n   → Keyboard navigation, focus management\n   → Design token compliance\n   → Text/copy consistency\n   → i18n coverage (if applicable)\n   → Append \"UI/UX Review\" section to REPORT.md\n   → **Note: Only execute if UI changes are included**\n```\n\n**Important: Execute all 3 agents in a single Task tool call for parallel execution.**\n\n**Agent name mapping (for reference):**\n| Old name (deprecated) | New integrated agent |\n|-----------------------|----------------------|\n| review-code-quality | reviw-plugin:review-code-security |\n| review-security | reviw-plugin:review-code-security |\n| review-a11y-ux | reviw-plugin:review-ui-ux |\n| review-figma-fidelity | reviw-plugin:review-ui-ux |\n| review-copy-consistency | reviw-plugin:review-ui-ux |\n| review-e2e-integrity | reviw-plugin:review-e2e |\n| e2e-health-reviewer | reviw-plugin:review-e2e |\n\n### 5. Review Agent Findings Check (CRITICAL - Do NOT Skip)\n\n**After review agents complete, check their findings BEFORE creating the report:**\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│  Review Agent Findings → Decision Gate                          │\n├─────────────────────────────────────────────────────────────────┤\n│                                                                 │\n│  Read REPORT.md sections added by review agents:                │\n│    - Code & Security Review                                     │\n│    - E2E Test Review                                            │\n│    - UI/UX Review (if applicable)                               │\n│                                                                 │\n│  Check for Critical/High severity issues:                       │\n│    YES → STOP. Fix issues first. Return to Step 1.              │\n│    NO  → Proceed to Step 6 (Report Creation)                    │\n│                                                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n**If Critical/High issues found:**\n1. Register ALL findings in TodoWrite (detailed, no summarization)\n2. Fix each issue\n3. Re-run build/verification\n4. Re-run review agents (return to Step 4)\n5. Only proceed when no Critical/High issues remain\n\n**This is NOT optional. Proceeding with Critical/High issues will result in rejection.**\n\n### 6. Report Creation/Evidence Organization\n\n**Only after review agents pass (no Critical/High issues), launch report-builder:**\n\n```\nLaunch ONE agent with Task tool:\n\nsubagent_type: \"reviw-plugin:report-builder\"\n   → artifact-proof skill auto-loads\n   → Calculate total review score (X/15 for 3 agents)\n   → Organize priority action items\n   → Execute report creation/evidence organization\n   → Ready to start reviw review\n```\n\n### 7. Start reviw Review\n\n**Important: Launch reviw in foreground**\n\n```bash\n# Open video file first (if exists)\nopen .artifacts/<feature>/demo.mp4\n\n# Open report with reviw (foreground)\nnpx reviw .artifacts/<feature>/REPORT.md\n```\n\nWhen reviw review starts:\n1. Browser opens, report is displayed\n2. User adds comments and Submit & Exit\n3. Feedback returns in YAML format\n4. Register feedback in TodoWrite and respond\n\n**Reason for foreground launch:**\n- To receive user review comments\n- Feedback won't be conveyed in background\n\n### 8. User Feedback Response (Improvement Cycle)\n\nAfter receiving user feedback from reviw:\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│  Feedback Response Cycle                                        │\n├─────────────────────────────────────────────────────────────────┤\n│                                                                 │\n│  1. Parse YAML feedback                                         │\n│  2. Register EACH comment in TodoWrite                          │\n│     - DO NOT summarize - copy exact text                        │\n│     - Include file:line references                              │\n│                                                                 │\n│  3. Fix issues one by one                                       │\n│     - Mark TODO complete after each fix                         │\n│                                                                 │\n│  4. After ALL fixes complete:                                   │\n│     - Re-run build                                              │\n│     - Re-collect evidence (webapp-testing)                      │\n│     - Update REPORT.md with new evidence                        │\n│                                                                 │\n│  5. Return to Step 6 (Start reviw Review again)                 │\n│     - User will verify fixes                                    │\n│     - Repeat until approval                                     │\n│                                                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n**NEVER do this:**\n- ❌ Write REPORT.md and declare \"done\" without fixing\n- ❌ Skip re-verification after fixes\n- ❌ Summarize feedback (copy exact text)\n- ❌ Batch multiple fixes without individual TODO tracking\n\n## reviw Usage Tips\n\n```bash\n# Open Markdown\nnpx reviw report.md\n\n# Open multiple files\nnpx reviw file1.md file2.csv\n\n# Open git diff\ngit diff HEAD | npx reviw\n\n# Specify port\nnpx reviw report.md --port 5000\n```\n\n## Prohibited Actions\n\n- Reporting only \"Implementation complete!\"\n- Completion declaration without operation verification\n- \"It works\" report without evidence\n- Omitting verification via mock/skip/bypass\n- **Checking TODO just for implementing**\n- **Launching reviw in background**\n\n## Report Template\n\n```\n## Implementation Details\n- [What was implemented]\n\n## TODO Completion Status (Handoff from /do)\n- [x] Implementation: [specific details]\n- [x] Build: Success\n- [x] Operation verification: Verified with webapp-testing\n- [x] Evidence: Collected with artifact-proof\n\n## Verification Results\n- Build: [success/failure]\n- Operation verification: [success/failure]\n- Evidence: [screenshot/video path]\n\n## Confirmation Items\n[If there's anything for user to confirm, describe here]\n```\n\n---\n\n**Until this checklist is satisfied, it cannot be called task complete.**\n**If completion is claimed with only implementation, immediately reject.**\n**Task completion only occurs after receiving reviw review.**"
              }
            ],
            "skills": [
              {
                "name": "artifact-proof",
                "description": "Accumulate evidence (screenshots, videos, logs) under .artifacts/<feature>/ for visual regression and PR documentation workflow. [MANDATORY] Before saying \"implementation complete\", you MUST use this skill to collect evidence and present a report with proof. Completion reports without evidence are PROHIBITED.",
                "path": "plugin/skills/artifact-proof/SKILL.md",
                "frontmatter": {
                  "name": "artifact-proof",
                  "description": "Accumulate evidence (screenshots, videos, logs) under .artifacts/<feature>/ for visual regression and PR documentation workflow. [MANDATORY] Before saying \"implementation complete\", you MUST use this skill to collect evidence and present a report with proof. Completion reports without evidence are PROHIBITED.",
                  "allowed-tools": [
                    "Shell"
                  ]
                },
                "content": "# Artifact Proof\n\nAn operational workflow for preserving development evidence (screenshots, videos, logs) in `.artifacts/<feature>/` and reusing it for PR descriptions.\nAssumes human-in-the-loop visual regression, requiring screenshots to be retaken and verified before commits and PR pushes.\n\n## Language Policy\n\n- **Skill instructions**: Written in English for universal understanding\n- **REPORT.md content**: Write in the user's native language to ensure clear communication with stakeholders. Match the language used by the user in their requests.\n\n## Triggers\n- When asked for work evidence for a PR\n- When visual diff checking is needed for UI changes\n- When E2E/Playwright execution results need to be preserved\n\n## Core Principles\n- Use `.artifacts/<feature>/` for evidence (screenshots, videos, REPORT.md) to avoid polluting the repository.\n- **IMPORTANT**: E2E test scripts belong in `tests/e2e/` (permanent project assets), NOT in `.artifacts/` (temporary evidence only).\n- Treat screenshots as semi-automated human-in-the-loop visual regression. After making changes, **retake all screenshots before commits and PR pushes to replace them**. Human verification ensures the changes are intentional before committing.\n- Browsers should primarily use Playwright's bundled Chromium. Chrome-based browsers are a last resort.\n- Editing should use `apply_patch` only. Operations that break others' changes (like `git reset`) are prohibited.\n\n## Directory and Naming\n- Decide on a FEATURE and create the following:\n  - `.artifacts/<feature>/REPORT.md`\n  - `.artifacts/<feature>/images/`\n  - `.artifacts/<feature>/videos/`\n- Naming examples: `20251130-login-before.png`, `20251130-login-after.png`, `20251130-login-run.webm`\n- **Video files (.webm, .mp4, etc.) must be managed with Git LFS** (details below)\n\n## Artifact Template (REPORT.md)\n\n```markdown\n# <feature> / <ticket>\n\nCreated: YYYY-MM-DD\nBranch: <branch-name>\nStatus: Awaiting Review\n\n## 📌 Attention Required (今回の確認項目)\n\n**Please review these specific points:**\n\n| # | Item | Question/Note |\n|---|------|---------------|\n| 1 | [Specific area to review] | [What you want feedback on] |\n| 2 | [Design decision] | [Options considered, why this choice] |\n| 3 | [Edge case handling] | [How it's handled, is this acceptable?] |\n\n---\n\n## 📋 Previous Feedback Response (累積フィードバック履歴)\n\n<details open>\n<summary><strong>Latest: YYYY-MM-DD</strong></summary>\n\n| Feedback | Status | How Addressed |\n|----------|--------|---------------|\n| \"Fix the button alignment\" | ✅ Done | Changed flexbox justify-content to center |\n| \"Add error handling\" | ✅ Done | Added try-catch with user-friendly message |\n\n</details>\n\n<details>\n<summary>YYYY-MM-DD (Previous)</summary>\n\n| Feedback | Status | How Addressed |\n|----------|--------|---------------|\n| \"Improve loading state\" | ✅ Done | Added skeleton loader |\n\n</details>\n\n<!--\nACCUMULATION RULE:\n- When receiving new feedback, move the current \"Latest\" to a new collapsed <details> block\n- Add new feedback response as the new \"Latest\" (with <details open>)\n- Never delete previous feedback - keep accumulating\n- Oldest feedback goes to the bottom\n-->\n\n---\n\n## Context\n- Background and requirements\n- Out of scope\n- Acceptance criteria\n\n## Plan\n- [ ] Task 1\n- [ ] Task 2\n- [ ] Task 3\n\n## Evidence\n\n### Screenshots (table layout recommended)\n| Before | After |\n|--------|-------|\n| ![Before](./images/YYYYMMDD-feature-before.png) | ![After](./images/YYYYMMDD-feature-after.png) |\n\n### Videos (image syntax for thumbnails, with flow column)\nUse image syntax `![](video.mp4)` to display video with thumbnail and controls.\n**Include a Flow column with arrow notation** to show what the video demonstrates at a glance.\n\n| Video | Flow | Description |\n|-------|------|-------------|\n| ![Login](./videos/YYYYMMDD-login.webm) | Top → Email → Password → Submit → Dashboard | Login flow demo |\n| ![Settings](./videos/YYYYMMDD-settings.webm) | Menu → Settings → Toggle → Save → Toast | Settings update demo |\n\nLink-only format (no thumbnail):\n- [Login demo](./videos/YYYYMMDD-login.webm): Top → Email → Password → Submit → Dashboard\n\n### Test Results\n```bash\n# Command executed\nnpx playwright test tests/e2e/feature.spec.ts --reporter=line\n\n# Result\n✓ 5 passed (10s)\n```\n\n### Verification Checklist\n- [ ] Build: `npm run build` passed\n- [ ] Dev server: Started successfully\n- [ ] Manual verification: Feature works as expected\n- [ ] E2E tests: All passing\n\n<details>\n<summary>Detailed verification logs (collapsed)</summary>\n\n#### Build Log\n```bash\n# Build output here\n```\n\n#### Test Output\n```bash\n# Test output here\n```\n\n</details>\n\n### How to Reproduce\n```bash\n# Steps to reproduce the evidence above\npnpm install\npnpm dev\n# Then navigate to http://localhost:3000/feature\n```\n\n## E2E Health Review (auto-appended)\n<!-- This section is auto-appended by e2e-health-reviewer agent -->\n\n<details>\n<summary>E2E Health Review Details</summary>\n\n### goto Restriction Check\n| File | Line | Code | Status |\n|------|------|------|--------|\n\n### Record Change Assertions\n- Status: ✅ / ⚠️ / ❌\n\n### Hardcode Detection\n| File | Line | Code | Issue |\n|------|------|------|-------|\n\n### Mock/Stub Detection\n- Status: ✅ / ❌\n\n</details>\n\n### Overall Score\n- Score: X/5\n\n## Notes\n- Items for user to confirm\n- Known limitations\n- Future improvements\n```\n\n## Example of Capturing Evidence with Playwright (Screenshots + Videos)\n\n**Note**: E2E test code should be in `tests/e2e/`, not here. Use this for quick evidence capture only.\n\n```bash\nFEATURE=${FEATURE:-feature}\nmkdir -p .artifacts/$FEATURE/{images,videos}\n\n# Run existing E2E test with evidence collection\nnpx playwright test tests/e2e/your-feature.spec.ts \\\n  --headed \\\n  --output=.artifacts/$FEATURE \\\n  --trace=retain-on-failure\n\n# Or quick one-liner for ad-hoc screenshot (TypeScript via tsx)\nnpx tsx -e \"\nimport { chromium } from 'playwright';\n\nconst feature = process.env.FEATURE || 'feature';\nconst browser = await chromium.launch({ headless: false });\nconst context = await browser.newContext({\n  viewport: { width: 1440, height: 900 },\n  recordVideo: { dir: \\\\\\`.artifacts/\\\\\\${feature}/videos\\\\\\` }\n});\nconst page = await context.newPage();\nawait page.goto(process.env.BASE_URL || 'http://localhost:3000', { waitUntil: 'networkidle' });\nconst stamp = new Date().toISOString().slice(0,10).replace(/-/g,'');\nawait page.screenshot({ path: \\\\\\`.artifacts/\\\\\\${feature}/images/\\\\\\${stamp}-step.png\\\\\\`, fullPage: true });\nawait browser.close();\n\"\n```\n- Playwright test example with trace:\n```bash\nFEATURE=${FEATURE:-feature}\nBASE_URL=http://localhost:3000 \\\nnpx playwright test tests/e2e/<spec>.spec.ts \\\n  --headed \\\n  --output=.artifacts/$FEATURE/images \\\n  --trace=retain-on-failure \\\n  --reporter=line\n```\n  After execution, if videos or trace outputs are scattered in different directories, organize them by moving to `.artifacts/$FEATURE/videos/`.\n\n## Operational Flow\n1) Create an Artifact md for the target task when starting work. Write Context and plans.\n2) Continuously append executed commands and logs.\n3) After UI changes, retake all screenshots and save to `.artifacts/<feature>/images/` (videos to `videos/`).\n4) Verify differences visually (human-in-the-loop). If intentional, paste into README.\n5) **Start review with reviw** (see \"Review with reviw\" section below)\n6) If rejected, re-implement, retake screenshots and videos as long as there are changes, update REPORT.md if necessary, execute step 5 again, and loop until approved\n7) Only commit after user approval; if there's a PR, reflect all modifications in the PR description\n\n## Review with reviw\n\nreviw is a CLI tool that reviews CSV/TSV/Markdown/Diff/text files in a browser and outputs comments in YAML format.\n\n### Basic Commands\n\n```bash\n# Open a report (must run in foreground)\nnpx reviw .artifacts/<feature>/REPORT.md\n\n# If there's a video, open it first\nopen .artifacts/<feature>/videos/demo.webm\nnpx reviw .artifacts/<feature>/REPORT.md\n\n# Review git diff\ngit diff HEAD | npx reviw\n\n# Open multiple files simultaneously\nnpx reviw file1.md file2.csv data.tsv\n```\n\n### Options\n\n| Option | Description |\n|--------|-------------|\n| `--port <number>` | Specify port number (default: 4989) |\n| `--encoding <enc>` | Specify character encoding (shift_jis, euc-jp, etc.) |\n| `--no-open` | Disable automatic browser launch |\n\n### reviw UI Features\n\n- **Markdown**: Side-by-side preview, scroll sync, Mermaid diagram rendering\n- **CSV/TSV**: Fixed header, column pinning, filtering\n- **Diff**: GitHub-style display, syntax highlighting\n- **Theme**: Light/dark mode toggle\n- **Comments**: Click cells/rows to add comments, Cmd/Ctrl+Enter to submit\n\n### Review Workflow\n\n```\nnpx reviw .artifacts/<feature>/REPORT.md  # Launch in foreground\n    ↓\nBrowser opens\n    ↓\nUser reviews content and adds comments\n    ↓\nClick \"Submit & Exit\"\n    ↓\nFeedback is output in YAML format\n    ↓\nRegister feedback in TodoWrite (detailed, no summarizing)\n    ↓\nFix → Review again with reviw → Repeat until approved\n```\n\n### Important: Foreground Launch Required\n\n```bash\n# Correct (can receive feedback)\nnpx reviw report.md\n\n# Wrong (cannot receive feedback)\nnpx reviw report.md &\n```\n\nLaunching in the background prevents receiving user comments, so **always launch in foreground**.\n\n> **Note for Claude Code users**: Claude Code can detect when background processes exit and capture their output, so you may use `run_in_background: true` with the Bash tool. The foreground requirement applies to other AI environments that cannot monitor background process completion.\n\n### Output Format (YAML)\n\n```yaml\nfile: report.md\nmode: markdown\ncomments:\n  - line: 15\n    content: \"Please add an explanation for this part\"\n  - line: 23\n    content: \"Error handling is needed\"\nsummary: \"Overall good, but please fix the above points\"\n```\n\n## Pasting Screenshots in PR Descriptions\n\n### Important: Use URLs that persist after branch deletion\n\nPR branches are often deleted after merging. Branch-name-based URLs become 404 after deletion, so **always use blob URLs with commit hashes**.\n\n```bash\n# Get current commit hash\nCOMMIT_HASH=$(git rev-parse HEAD)\n# Or short form\nCOMMIT_HASH=$(git rev-parse --short HEAD)\n```\n\n**Correct URL format (using commit hash):**\n```\n![alt](https://github.com/<org>/<repo>/blob/<commit-hash>/.artifacts/<feature>/images/screenshot.png?raw=true)\n```\n\n**Wrong URL format (using branch name - 404 after deletion):**\n```\n![alt](https://github.com/<org>/<repo>/blob/<branch-name>/.artifacts/<feature>/images/screenshot.png?raw=true)\n```\n\n### Screenshot Layout (Preventing Vertical Stacking)\n\nVertically stacked screenshots are hard to read. **Use HTML tables to arrange them horizontally as well**:\n\n```html\n<!-- 2-column layout -->\n<table>\n  <tr>\n    <td><img src=\"https://github.com/.../blob/<hash>/.artifacts/feature/images/before.png?raw=true\" width=\"400\"/></td>\n    <td><img src=\"https://github.com/.../blob/<hash>/.artifacts/feature/images/after.png?raw=true\" width=\"400\"/></td>\n  </tr>\n  <tr>\n    <td align=\"center\">Before</td>\n    <td align=\"center\">After</td>\n  </tr>\n</table>\n\n<!-- 3-column layout (comparing multiple screens) -->\n<table>\n  <tr>\n    <td><img src=\".../step1.png?raw=true\" width=\"280\"/></td>\n    <td><img src=\".../step2.png?raw=true\" width=\"280\"/></td>\n    <td><img src=\".../step3.png?raw=true\" width=\"280\"/></td>\n  </tr>\n  <tr>\n    <td align=\"center\">1. Login Screen</td>\n    <td align=\"center\">2. After Input</td>\n    <td align=\"center\">3. Completion Screen</td>\n  </tr>\n</table>\n```\n\n### Example Script for Pasting in PR Description\n\n```bash\nFEATURE=${FEATURE:-feature}\nORG=$(gh repo view --json owner -q .owner.login)\nREPO=$(gh repo view --json name -q .name)\nCOMMIT=$(git rev-parse HEAD)\n\n# Generate Markdown table from image list\necho \"<table><tr>\"\ncount=0\nfor img in .artifacts/$FEATURE/images/*.png; do\n  filename=$(basename \"$img\")\n  echo \"<td><img src=\\\"https://github.com/$ORG/$REPO/blob/$COMMIT/$img?raw=true\\\" width=\\\"400\\\"/></td>\"\n  count=$((count + 1))\n  # New row every 2 columns\n  if [ $((count % 2)) -eq 0 ]; then\n    echo \"</tr><tr>\"\n  fi\ndone\necho \"</tr></table>\"\n```\n\n### Update PR Description with GitHub CLI\n\n```bash\ngh api --method PATCH repos/<org>/<repo>/pulls/<num> -f body=\"$(cat /tmp/new-body.md)\"\n```\n\n## Managing Videos with Git LFS\n\nVideo files are large, so **they must be managed with Git LFS**.\n\n### Initial Setup\n```bash\n# If LFS is not installed\nbrew install git-lfs  # macOS\ngit lfs install\n\n# Add video files to LFS tracking\ngit lfs track \"*.webm\"\ngit lfs track \"*.mp4\"\ngit lfs track \"*.mov\"\ngit lfs track \".artifacts/**/*.webm\"\ngit lfs track \".artifacts/**/*.mp4\"\n\n# Commit .gitattributes\ngit add .gitattributes\ngit commit -m \"chore: add video files to Git LFS\"\n```\n\n### Flow for Adding Videos\n```bash\n# 1. Place the video\nmv recording.webm .artifacts/$FEATURE/videos/\n\n# 2. Verify LFS tracking\ngit lfs status\n\n# 3. Add/commit normally\ngit add .artifacts/$FEATURE/videos/\ngit commit -m \"docs: add demo video for $FEATURE\"\n```\n\n### Video Links in PR Description\nVideos cannot be played directly on GitHub, so provide them as links:\n```markdown\n[View demo video](./.artifacts/feature/videos/demo.webm)\n```\n\nOr convert to GIF for embedding:\n```bash\n# webm → gif conversion (using ffmpeg)\nffmpeg -i demo.webm -vf \"fps=10,scale=600:-1\" demo.gif\n```\n\n## reviw-Specific Features\n\n### Collapsible Sections (details/summary)\nUse collapsible sections for long logs or detailed information:\n```markdown\n<details>\n<summary>Click to expand: Detailed logs</summary>\n\nLong logs or detailed information here.\nCode blocks can be included.\n\n</details>\n```\n\n### Video Thumbnails (Image Syntax)\n**Recommended: Use image syntax for thumbnail display with flow column**\n```markdown\n| Video | Flow | Description |\n|-------|------|-------------|\n| ![Demo](./videos/demo.webm) | Home → Click → Modal → Submit → Success | Feature demo |\n```\n\nThe Flow column uses arrow notation (`→`) to show what steps the video demonstrates at a glance. Since Mermaid cannot be used inside tables, this is the recommended alternative.\n\n**Link syntax (no thumbnail):**\n```markdown\n[Play video](./videos/demo.webm): Home → Click → Modal → Submit → Success\n```\n\n### Images in Tables\nImages can be placed inside table cells:\n```markdown\n| Before | After |\n|--------|-------|\n| ![Before](./images/before.png) | ![After](./images/after.png) |\n```\n\n### Code Fences in Tables are NOT Supported\n**Putting code fences (```) inside table cells breaks the parser**:\n```markdown\n<!-- This does NOT work -->\n| Code | Diagram |\n|------|---------|\n| sample | ```mermaid\nflowchart TD\n``` |\n\n<!-- Place Mermaid outside tables instead -->\n| Code | Diagram |\n|------|---------|\n| sample | See below |\n\n```mermaid\nflowchart TD\n    A --> B\n```\n```\n\n### Mermaid Diagrams\nreviw auto-renders Mermaid diagrams:\n```markdown\n```mermaid\nflowchart LR\n    A[Start] --> B[Process] --> C[End]\n```\n```\nNote: Place Mermaid blocks outside tables, not inside table cells.\n\n## Best Practices\n- Include screen or state-descriptive words in screenshot/video filenames (e.g., `login-success.png`).\n- Use both full-page and element-level captures for better diff accuracy.\n- Preserve screenshots even for test failures to aid in debugging.\n- When creating PRs, paste Artifact content directly; update Artifacts based on review feedback.\n- **Don't stack screenshots vertically; use 2-3 column table layouts for horizontal utilization**.\n- **Always use commit hashes in image URLs so they display even after branch deletion**.\n- **Always manage videos with Git LFS to avoid repository bloat**.\n- **Use `![](video.mp4)` syntax for video thumbnails in reviw**.\n- **Include a Flow column with arrow notation** to describe video content at a glance.\n- **Use `<details>` for collapsible sections to keep reports clean**.\n- **Never put code fences inside table cells - it breaks the parser**.\n\n## Expected Outputs\n- `.artifacts/<feature>/` contains task-specific READMEs with linked evidence (screenshots, videos, logs).\n- Screenshots are updated to the latest before commits and PR pushes, with visual diffs verified by human eyes.\n- Artifacts can be directly reused as PR descriptions.\n- PR images use commit hash-based blob URLs that remain visible after branch deletion post-merge.\n- Video files are managed with Git LFS, reducing clone overhead."
              },
              {
                "name": "webapp-testing",
                "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs. [MANDATORY] Before saying \"implementation complete\", you MUST use this skill to run tests and verify functionality. Completion reports without verification are PROHIBITED.",
                "path": "plugin/skills/webapp-testing/SKILL.md",
                "frontmatter": {
                  "name": "webapp-testing",
                  "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs. [MANDATORY] Before saying \"implementation complete\", you MUST use this skill to run tests and verify functionality. Completion reports without verification are PROHIBITED.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Web Application Testing\n\nTo test local web applications, write TypeScript E2E tests using **Playwright Test** (`@playwright/test`).\n\n**CRITICAL: E2E Test File Placement**\n- **ALWAYS** place E2E test files in `tests/e2e/` or `e2e/` directory at the project root\n- **NEVER** place test scripts in `.artifacts/` - that's for evidence only (screenshots, videos)\n- E2E tests should be permanent project assets, not disposable artifacts\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task → Is it static HTML?\n    ├─ Yes → Read HTML file directly to identify selectors\n    │         ├─ Success → Write Playwright test using selectors\n    │         └─ Fails/Incomplete → Treat as dynamic (below)\n    │\n    └─ No (dynamic webapp) → Is the server already running?\n        ├─ No → Use webServer config in playwright.config.ts\n        │        to auto-start the dev server\n        │\n        └─ Yes → Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Playwright Test Setup\n\n### playwright.config.ts\n```typescript\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests/e2e',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: 'html',\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n    video: 'retain-on-failure',\n  },\n  projects: [\n    { name: 'chromium', use: { ...devices['Desktop Chrome'] } },\n  ],\n  webServer: {\n    command: 'npm run dev',\n    url: 'http://localhost:3000',\n    reuseExistingServer: !process.env.CI,\n    timeout: 120 * 1000,\n  },\n});\n```\n\n### Example Test: tests/e2e/login.spec.ts\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Login Flow', () => {\n  test('should login successfully with valid credentials', async ({ page }) => {\n    await page.goto('/login');\n    await page.waitForLoadState('networkidle');\n\n    await page.getByLabel('Email').fill('test@example.com');\n    await page.getByLabel('Password').fill('password123');\n    await page.getByRole('button', { name: 'Login' }).click();\n\n    await expect(page).toHaveURL('/dashboard');\n    await expect(page.getByRole('heading', { name: 'Welcome' })).toBeVisible();\n  });\n\n  test('should show error for invalid credentials', async ({ page }) => {\n    await page.goto('/login');\n\n    await page.getByLabel('Email').fill('invalid@example.com');\n    await page.getByLabel('Password').fill('wrong');\n    await page.getByRole('button', { name: 'Login' }).click();\n\n    await expect(page.getByText('Invalid credentials')).toBeVisible();\n  });\n});\n```\n\n## Running Tests\n\n```bash\n# Run all E2E tests\nnpx playwright test\n\n# Run specific test file\nnpx playwright test tests/e2e/login.spec.ts\n\n# Run with UI mode (interactive debugging)\nnpx playwright test --ui\n\n# Run headed (visible browser)\nnpx playwright test --headed\n\n# Generate test code interactively\nnpx playwright codegen http://localhost:3000\n```\n\n## Reconnaissance-Then-Action Pattern\n\nWhen you don't know the page structure:\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('discover and interact with page elements', async ({ page }) => {\n  await page.goto('/');\n  await page.waitForLoadState('networkidle');\n\n  // 1. Take screenshot for reconnaissance\n  await page.screenshot({ path: '/tmp/inspect.png', fullPage: true });\n\n  // 2. Log all buttons for analysis\n  const buttons = await page.getByRole('button').all();\n  for (const button of buttons) {\n    console.log('Button:', await button.textContent());\n  }\n\n  // 3. Get page content for selector discovery\n  const content = await page.content();\n  console.log(content);\n});\n```\n\n## Evidence Collection for PR Reviews\n\nWhen collecting evidence (screenshots/videos) for PR reviews, use this pattern:\n\n```bash\n# Run tests with evidence collection\nFEATURE=${FEATURE:-feature}\nmkdir -p .artifacts/$FEATURE/{images,videos}\n\nnpx playwright test tests/e2e/your-feature.spec.ts \\\n  --headed \\\n  --output=.artifacts/$FEATURE \\\n  --trace=retain-on-failure \\\n  --reporter=line\n```\n\n### Test with Built-in Evidence Collection\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Feature Demo', () => {\n  test('demonstrate feature workflow', async ({ page }, testInfo) => {\n    const feature = process.env.FEATURE || 'feature';\n    const timestamp = new Date().toISOString().slice(0, 10).replace(/-/g, '');\n\n    await page.goto('/feature');\n    await page.waitForLoadState('networkidle');\n\n    // Capture before state\n    await page.screenshot({\n      path: `.artifacts/${feature}/images/${timestamp}-before.png`,\n      fullPage: true\n    });\n\n    // Perform actions\n    await page.getByRole('button', { name: 'Enable Feature' }).click();\n    await expect(page.getByText('Feature Enabled')).toBeVisible();\n\n    // Capture after state\n    await page.screenshot({\n      path: `.artifacts/${feature}/images/${timestamp}-after.png`,\n      fullPage: true\n    });\n  });\n});\n```\n\n## Quick One-liner for Ad-hoc Verification\n\nFor quick checks without writing a full test file (use TypeScript via tsx):\n\n```bash\nnpx tsx -e \"\nimport { chromium } from 'playwright';\n\nconst browser = await chromium.launch();\nconst page = await browser.newPage();\nawait page.goto(process.env.BASE_URL || 'http://localhost:3000', { waitUntil: 'networkidle' });\nawait page.screenshot({ path: '/tmp/webapp.png', fullPage: true });\nawait browser.close();\nconsole.log('saved: /tmp/webapp.png');\n\"\n```\n\n## Common Pitfalls\n\n❌ **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\n✅ **Do** wait for `page.waitForLoadState('networkidle')` before inspection\n\n❌ **Don't** place E2E test files in `.artifacts/`\n✅ **Do** place E2E tests in `tests/e2e/` as permanent project assets\n\n❌ **Don't** write tests in Python\n✅ **Do** write tests in TypeScript using `@playwright/test`\n\n❌ **Don't** use Vitest for E2E tests\n✅ **Do** use Playwright Test for E2E, Vitest for unit/integration tests\n\n## Best Practices\n\n- **Use Playwright Test runner** - Not Vitest or other runners for E2E\n- **Always use TypeScript** - Never Python for Playwright tests\n- **Place tests in `tests/e2e/`** - Permanent project assets, not disposable\n- **Use role-based selectors** - `getByRole`, `getByLabel`, `getByText` over CSS\n- **Always close browser** - Playwright Test handles this automatically\n- **Add appropriate waits** - `waitForLoadState`, `waitForSelector`, `expect().toBeVisible()`\n- **Use `webServer` config** - Auto-start dev server in `playwright.config.ts`\n\n## File Structure Convention\n\n```\nproject/\n├── playwright.config.ts      # Playwright configuration\n├── tests/\n│   └── e2e/                  # E2E tests (permanent)\n│       ├── login.spec.ts\n│       ├── checkout.spec.ts\n│       └── settings.spec.ts\n├── .artifacts/               # Evidence only (temporary)\n│   └── <feature>/\n│       ├── images/           # Screenshots\n│       ├── videos/           # Recorded videos\n│       └── REPORT.md         # Review report\n└── test-results/             # Playwright auto-generated (gitignored)\n```\n\n**Key distinction:**\n- `tests/e2e/` = Permanent E2E test code (committed to repo)\n- `.artifacts/` = Temporary evidence for PR review (gitignored or LFS)\n- `test-results/` = Playwright's auto-generated output (gitignored)\n\n## Console/Error Collection\n\n```typescript\ntest('collect console logs', async ({ page }) => {\n  const consoleLogs: string[] = [];\n  const errors: string[] = [];\n\n  page.on('console', msg => consoleLogs.push(`${msg.type()}: ${msg.text()}`));\n  page.on('pageerror', err => errors.push(err.message));\n  page.on('requestfailed', req => errors.push(`Request failed: ${req.url()}`));\n\n  await page.goto('/');\n  await page.waitForLoadState('networkidle');\n\n  console.log('Console logs:', consoleLogs);\n  if (errors.length > 0) {\n    console.error('Errors:', errors);\n  }\n});\n```\n\n## Vitest vs Playwright Test: When to Use Each\n\n| Test Type | Tool | Reason |\n|-----------|------|--------|\n| Unit tests | Vitest | Fast, no browser needed |\n| Integration tests | Vitest | Fast, mock external deps |\n| Component tests | Vitest + browser mode | or Storybook |\n| **E2E tests** | **Playwright Test** | Full browser, real flows |\n\n**Do NOT use Vitest for E2E tests.** Playwright Test has:\n- Built-in parallelization for browser tests\n- Automatic retries and trace collection\n- Screenshot/video on failure\n- Web server management\n- Test generator (`codegen`)"
              }
            ]
          }
        ]
      }
    }
  ]
}