{
  "owner": {
    "id": "meaningfy-ws",
    "display_name": "Meaningfy",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/68598296?v=4",
    "url": "https://github.com/meaningfy-ws",
    "bio": "Building the next interoperability solution",
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 0,
      "total_skills": 2,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "meaningfy-ws/agent-skills",
      "url": "https://github.com/meaningfy-ws/agent-skills",
      "description": "a collection of agent skills ",
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-04T17:44:40Z",
        "created_at": "2026-01-04T16:24:02Z",
        "license": "GPL-3.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 822
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 4931
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 8415
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 35149
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 2199
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture/SKILL.md",
          "type": "blob",
          "size": 30448
        },
        {
          "path": "skills/architecture/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/architecture/references/ADR_TEMPLATE.md",
          "type": "blob",
          "size": 1405
        },
        {
          "path": "skills/architecture/references/architecture-project-structure.md",
          "type": "blob",
          "size": 18684
        },
        {
          "path": "skills/architecture/references/business-requirements-to-architecture.md",
          "type": "blob",
          "size": 10513
        },
        {
          "path": "skills/architecture/references/checklist-archimate-l1.md",
          "type": "blob",
          "size": 2247
        },
        {
          "path": "skills/architecture/references/checklist-archimate-l2.md",
          "type": "blob",
          "size": 2991
        },
        {
          "path": "skills/architecture/references/checklist-bpmn.md",
          "type": "blob",
          "size": 2880
        },
        {
          "path": "skills/architecture/references/checklist-uml-class-domain.md",
          "type": "blob",
          "size": 5600
        },
        {
          "path": "skills/architecture/references/checklist-uml-component.md",
          "type": "blob",
          "size": 1869
        },
        {
          "path": "skills/architecture/references/checklist-uml-sequence.md",
          "type": "blob",
          "size": 3663
        },
        {
          "path": "skills/architecture/references/decision-pattern-examples.md",
          "type": "blob",
          "size": 5888
        },
        {
          "path": "skills/architecture/references/diagram-examples-mermaid.md",
          "type": "blob",
          "size": 11771
        },
        {
          "path": "skills/architecture/references/diagram-examples.md",
          "type": "blob",
          "size": 6063
        },
        {
          "path": "skills/architecture/references/sequence-diagram-examples.md",
          "type": "blob",
          "size": 10849
        },
        {
          "path": "skills/cosmic-python",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/cosmic-python/SKILL.md",
          "type": "blob",
          "size": 17032
        },
        {
          "path": "skills/cosmic-python/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/cosmic-python/references/MEANINGFY_PROMPT.md",
          "type": "blob",
          "size": 21246
        },
        {
          "path": "skills/cosmic-python/references/example-adapters-layer.md",
          "type": "blob",
          "size": 11048
        },
        {
          "path": "skills/cosmic-python/references/example-advanced-patterns.md",
          "type": "blob",
          "size": 18829
        },
        {
          "path": "skills/cosmic-python/references/example-entrypoints-layer.md",
          "type": "blob",
          "size": 13368
        },
        {
          "path": "skills/cosmic-python/references/example-models-layer.md",
          "type": "blob",
          "size": 5739
        },
        {
          "path": "skills/cosmic-python/references/example-project-quality-ci.md",
          "type": "blob",
          "size": 14528
        },
        {
          "path": "skills/cosmic-python/references/example-services-layer.md",
          "type": "blob",
          "size": 13382
        },
        {
          "path": "skills/cosmic-python/references/example-testing-patterns.md",
          "type": "blob",
          "size": 16918
        },
        {
          "path": "skills/cosmic-python/references/phase-1-strategic-blueprint-checklist.md",
          "type": "blob",
          "size": 10971
        },
        {
          "path": "skills/cosmic-python/references/phase-2-clarity-gate-checklist.md",
          "type": "blob",
          "size": 15485
        },
        {
          "path": "skills/cosmic-python/references/stream-coding-methodology.md",
          "type": "blob",
          "size": 15019
        },
        {
          "path": "spec",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/CREATING_SKILLS.md",
          "type": "blob",
          "size": 12024
        },
        {
          "path": "spec/agent-skills-spec.md",
          "type": "blob",
          "size": 5037
        },
        {
          "path": "template",
          "type": "tree",
          "size": null
        },
        {
          "path": "template/SKILL.md",
          "type": "blob",
          "size": 1605
        }
      ],
      "marketplace": {
        "name": "agent-skills",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Meaningfy",
          "email": "info@meaningfy.ws"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "architecture-skills",
            "description": "Architecture and design skills including architecture patterns, ADRs, BPMN, UML diagrams, and architecture documentation",
            "source": "./",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add meaningfy-ws/agent-skills",
              "/plugin install architecture-skills@agent-skills"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-04T17:44:40Z",
              "created_at": "2026-01-04T16:24:02Z",
              "license": "GPL-3.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "cosmic-python",
                "description": "Clean Architecture and Cosmic Python guidance for well-tested, layered Python systems. Use for designing Python projects with layered architecture (models, adapters, services, entrypoints), enforcing Clean Code and SOLID principles, testing strategies (unit tests, BDD, Gherkin), CI/CD setup (pytest, tox, importlinter), and architectural decision-making (ADRs). Applicable to systems requiring strict boundary enforcement, clean separation of concerns, and comprehensive test coverage.",
                "path": "skills/cosmic-python/SKILL.md",
                "frontmatter": {
                  "name": "cosmic-python",
                  "description": "Clean Architecture and Cosmic Python guidance for well-tested, layered Python systems. Use for designing Python projects with layered architecture (models, adapters, services, entrypoints), enforcing Clean Code and SOLID principles, testing strategies (unit tests, BDD, Gherkin), CI/CD setup (pytest, tox, importlinter), and architectural decision-making (ADRs). Applicable to systems requiring strict boundary enforcement, clean separation of concerns, and comprehensive test coverage.",
                  "license": "Apache 2.0",
                  "version": "1.0.0"
                },
                "content": "# Cosmic Python: Code Architecture for Production Systems\n\n## ⚠️ CRITICAL DISTINCTION\n\n**Cosmic Python is NOT about system architecture** (service boundaries, deployment topology, C4 models—that's the separate **architecture** skill).\n\n**Cosmic Python IS about code structure** within a Python module or service: how to organize classes, functions, tests, and dependencies so that code is clean, testable, and maintainable.\n\nWhen to use Cosmic Python:\n- You have a **service/module to build** (the strategic scope is clear from architecture decisions)\n- You need to **structure the Python code** inside that service with clean layers\n- You want to enforce **clean code principles, SOLID, and dependency management**\n- You need **comprehensive test coverage** organized per layer\n\nThis skill pairs with:\n- **Stream Coding** (documentation-first methodology) – Use to plan WHAT to build\n- **Cosmic Python** (this skill) – Use to structure HOW to build the code\n- **Architecture** skill – Use for system-level design (separate scope)\n\n---\n\n## THE MEANINGFY CONTRACT: MINIMISE WTFs PER MINUTE\n\nOur goal is **clean code that passes code review quickly** while keeping developers productive and safe.\n\nThis is achieved through three non-negotiable commitments:\n\n### 1. Layered Architecture – Strict Separation of Concerns\n\nWithin each Python module or service, separate code into **four tightly-bounded layers**:\n\n- **`models/`** – Domain logic (business rules, entities, value objects)\n  - No I/O, no framework dependencies, pure domain\n  - Tests focus on business invariants and domain rules\n  - Fastest tests, run first\n\n- **`adapters/`** – Infrastructure and integration (databases, APIs, file systems)\n  - Implement repositories, gateways, clients\n  - Depend on `models` only; never on `services` or `entrypoints`\n  - Tests mock external services; focus on integration boundaries\n\n- **`services/`** – Use-case orchestration (application logic, workflows)\n  - Choreograph `models` and `adapters`\n  - Contain transaction boundaries and error handling policy\n  - May depend on `models` and `adapters`, never on `entrypoints`\n  - Tests use mocks for adapters; focus on orchestration logic\n\n- **`entrypoints/`** – Request/response boundaries (API, CLI, schedulers, workers)\n  - Parse input, call services, format responses\n  - Handle routing, status codes, argument validation\n  - Minimal business logic; delegate to `services`\n  - Tests verify contracts (status codes, response shapes, argument parsing)\n\n### 2. Dependency Direction – Always Enforced (DIP)\n\n**The Law:**\n```\nentrypoints → services → models\n              ↘\n              adapters → models\n```\n\n**Never the reverse.** High-level policy (models + services) must never depend on low-level details (adapters). Low-level details depend on abstractions (interfaces/protocols), not the other way around.\n\n**When you violate this:**\n- Circular dependencies appear\n- Models become framework-dependent\n- Testing becomes hard (can't mock cleanly)\n- You've broken the architecture\n\n**How to enforce:**\n- Use `importlinter` in CI/CD to block forbidden imports (see references)\n- Code review checklist: \"What imports what?\" before approving\n\n### 3. No Clean Code Without Tests – Every Layer Owns Its Tests\n\n> \"If you can't test it, you can't understand it. If you can't understand it, you can't maintain it.\"\n\n- **80%+ coverage** on production code (target per layer)\n- **Tests per layer:** Each layer tests its own responsibility, not other layers' internals\n- **TDD/BDD:** Write tests before code; BDD (Gherkin) for use cases\n- **Test pyramid:** Many unit tests (fast, isolated), fewer integration tests, minimal end-to-end\n\n---\n\n## CORE PRINCIPLES FROM MEANINGFY ENGINEERING\n\n### Clean Code Standards\n\n- **Intention-revealing names** – `calculate_customer_tier()` not `calc_tier()`\n- **Small, cohesive functions** – <25 lines is a good target; if you say \"and\" in description, split\n- **No magic strings** – Define constants or enums; raw string literals are technical debt\n- **Minimal nesting** – Deep nesting signals complexity; refactor\n- **DRY but not obsessively** – Three similar lines don't warrant a helper; ten do\n\n### SOLID Principles Applied Systematically\n\n- **SRP** – One responsibility per class/function; if multiple reasons to change, split\n- **OCP** – Extend via new classes/strategies, not conditional logic in existing code\n- **LSP** – Subclasses must respect contracts; avoid overrides that break expected behavior\n- **ISP** – Avoid \"fat\" interfaces; split into cohesive ones matching clients' needs\n- **DIP** – Depend on abstractions (interfaces/protocols), inject concrete implementations\n\n### Observability as First-Class\n\n- **Structured logging** – Logs are data, not strings; emit JSON with context\n- **Keep it in the right layers** – Observability belongs in `services` and `entrypoints`, not deep in `models`\n- **OpenTelemetry patterns** – Tracing and metrics via standard conventions\n- **No print statements in production** – Use logging framework always\n\n---\n\n## ONE-MINUTE CODE STRUCTURE CHECK\n\n**For each function/class, ask:**\n\n- Which layer does this belong in?\n- What should it depend on?\n- What should depend on it?\n- What tests does it need?\n- Does it have only one reason to change?\n\nIf you can't answer these clearly, **the architecture is drifting.** See the references for detailed refactoring paths.\n\n---\n\n## COMMON WORKFLOWS\n\n### Workflow 1: Implementing Code From Specs (Stream Coding Phase 3)\n\nWhen you have clear specs from **Stream Coding Phase 2** (doc is 9+/10 Clarity Gate):\n\n1. **Identify which layer each component belongs to** – Models? Services? Adapters?\n2. **Start with `models/`** – Pure domain logic, no I/O, no frameworks\n3. **Write unit tests for models first** – Verify domain rules before implementing services\n4. **Implement `adapters/`** – Repositories, gateways, clients; mock external services in tests\n5. **Implement `services/`** – Orchestrate models and adapters; test with mocked adapters\n6. **Implement `entrypoints/`** – CLI, API, schedulers; minimal logic, mostly delegation\n7. **Run full test suite** – Verify 80%+ coverage per layer\n8. **Run architectural checks** – `make check-architecture` to validate import contracts\n\n### Workflow 2: Code Review Against Cosmic Python Standards\n\n**Before approving a pull request, ask:**\n\n**Layering:**\n- Does `models/` import from `services`, `adapters`, or `entrypoints`? ❌ Should not\n- Do `adapters/` import from `services` or `entrypoints`? ❌ Should not\n- Do `services/` import from `entrypoints`? ❌ Should not\n- Is business logic in `services/` or `models/`, not scattered in `entrypoints/`? ✅ Should be\n\n**Clean Code:**\n- Are functions <25 lines? ✅ Target for readability\n- Do all functions have only one reason to change? ✅ Check for SRP violation\n- Are all symbolic identifiers (role names, status values, etc.) constants/enums, not magic strings? ✅ Required\n- Is there any deep nesting (3+ levels)? ❌ Refactor to smaller functions\n\n**Testing:**\n- Does each layer have appropriate unit tests? ✅ Required\n- Are important decisions (branches, error cases) tested? ✅ All branches covered\n- Do adapters use mocks for external systems? ✅ Tests must be isolated\n- Is coverage reported per layer? ✅ Verify with `coverage report`\n\n**Observability:**\n- Are logs in `services/` and `entrypoints/`, not deep in `models/`? ✅ Correct placement\n- Is logging structured (JSON context), not formatted strings? ✅ Required for production\n\n### Workflow 3: Test Organization Per Layer\n\nFor each layer, write tests that match its responsibility:\n\n| Layer | What to Test | How | Example |\n|-------|--------------|-----|---------|\n| **`models/`** | Domain rules, invariants, transformations | Unit tests, no I/O, fast | `test_user_cannot_have_negative_balance()` |\n| **`adapters/`** | Integration with external systems (mocked) | Unit tests with mocks, or integration with real test DBs | `test_postgres_repository_insert_user()` |\n| **`services/`** | Use-case orchestration and business workflows | Unit tests with mocked adapters | `test_user_signup_flow_sends_verification_email()` |\n| **`entrypoints/`** | Request parsing, response formatting, status codes | Unit tests, check contracts | `test_api_endpoint_returns_201_on_create()` |\n\n**Target:** 80%+ coverage overall, with focus on each layer's responsibility (not mixing concerns).\n\n### Workflow 4: Spotting and Fixing Architecture Drift\n\nCommon anti-patterns and how to fix them:\n\n| Anti-Pattern | How It Looks | Why It's Wrong | Fix |\n|--------------|--------------|----------------|-----|\n| **I/O in models** | `import requests` in `models/user.py` | Models can't be tested in isolation | Move HTTP call to `adapters/`, inject via DIP |\n| **Business rules in entrypoints** | API handler validates and transforms data | Logic is scattered, untestable | Extract to `services/`, call from handler |\n| **Circular imports** | `services/` → `adapters/` → `services/` | Can't import cleanly, hard to test | Restructure: `adapters/` → `models/`; `services/` → `adapters/` + `models/` |\n| **Magic strings everywhere** | `if user.role == \"admin\"` in 5 files | Refactoring is fragile; intent hidden | Define `ROLE_ADMIN = \"admin\"` constant once, import everywhere |\n| **No tests for branching** | `services/` has 5 branches but only happy path tested | Edge cases crash production | Add parametrized tests for each branch |\n| **Clever one-liners** | `[x for x in y if x.z and (a or b)]` | Unreadable; maintenance nightmare | Expand to 3-4 readable lines with intermediate variables |\n\n---\n\n## QUALITY ASSURANCE & TOOLING\n\n### Essential Tools for Well-Guarded Projects\n\n- **Poetry** – Dependency management, lockfiles, reproducible builds\n- **pytest + pytest-bdd** – Unit tests (TDD) and behavior specs (BDD/Gherkin)\n- **tox** – Test multiple Python versions in isolated environments\n- **importlinter** – Enforce architectural boundaries (block forbidden imports)\n- **pylint / flake8** – Static analysis, style compliance\n- **SonarQube / SonarCloud** – Code quality gates, duplication, security smells\n- **Codecov** – Coverage reporting, trend tracking, gate on new code\n\n### Typical Makefile Pattern\n\n```bash\nmake install                # Set up environment (poetry install)\nmake test                   # Run unit tests with coverage\nmake test-bdd               # Run BDD feature tests\nmake check-architecture     # Validate import contracts (importlinter)\nmake lint                   # Run style checks (pylint, flake8)\nmake ci                     # Full pipeline (all above)\n```\n\n### CI/CD Workflow\n\nBefore merging to main:\n1. Run tests and verify 80%+ coverage on new code\n2. Run `importlinter` to block dependency violations\n3. Run SonarCloud analysis; no new critical issues\n4. Verify Clarity Gate from spec still matches code\n\n---\n\n## PRINCIPLES & BEST PRACTICES\n\n### On Code Structure\n\n- **Organize by domain, not by layer** – `billing/models/`, `billing/services/`, not `models/billing/`\n- **Use constants/enums for all symbolic identifiers** – Never rely on \"magic strings\"\n- **Small, cohesive functions** – If you say \"and\" when describing what a function does, split it\n- **Avoid deep nesting** – >3 levels usually signals refactoring opportunity\n- **DRY but pragmatically** – 2-3 similar lines are OK; 5+ warrant extraction\n\n### On Testing\n\n- **Test the decisions, not the steps** – Test what varies (branches), not happy paths\n- **Test per layer, not per unit** – Models test domain rules; services test orchestration\n- **Use fixtures and parametrization** – pytest.mark.parametrize for multiple scenarios\n- **Mock external dependencies** – Adapters provide mocks for services tests\n- **BDD for use cases** – Gherkin feature files for end-to-end workflows\n\n### On Architecture Decisions\n\n- **Document major choices in ADRs** – Architecture Decision Records explain the trade-off\n- **5–8 ADRs per service is typical** – More suggests decisions are tangled\n- **Contract-first design** – Write OpenAPI/AsyncAPI specs before code\n- **Use dependency injection** – Never `import` concrete implementations directly in services\n\n### On Observability\n\n- **Structured logging** – Emit JSON with context, not formatted strings\n- **Keep observability in the right layers** – `services/` and `entrypoints/`, not deep in `models/`\n- **No print() in production** – Use logging framework; configure per environment\n- **OpenTelemetry for tracing** – Standard conventions for metrics and spans\n\n---\n\n## WHEN NOT TO USE COSMIC PYTHON\n\n- **Rapid prototypes** – Layering has upfront cost; worthwhile only if long-term maintenance matters\n- **Exploratory/spike code** – Keep spikes separate; migrate to Cosmic Python only when strategy is clear\n- **Simple scripts** – Single-file scripts don't need four layers\n\nThis approach requires **team discipline**. One developer ignoring layers breaks the architecture for everyone. All developers must respect boundaries and code review rigorously.\n\n---\n\n## COSMIC PYTHON + STREAM CODING: THE COMPLETE WORKFLOW\n\n**Stream Coding** (documentation-first planning) and **Cosmic Python** (clean code structure) work together:\n\n| Phase | Methodology | Focus | Output |\n|-------|-------------|-------|--------|\n| 1 | **Stream Coding** | Strategic: WHAT to build, WHY | Strategic Blueprint + ADRs |\n| 2 | **Stream Coding** | Specifications: HOW to build (AI-ready) | Implementation Specs (9+/10 Clarity Gate) |\n| 3 | **Cosmic Python** | Code: Implement following layers/SOLID | Production code (80%+ tested) |\n| 4 | **Cosmic Python** | Quality: Prevent drift, maintain specs | CI/CD gates, spec-first fixes |\n\n### The Integration\n\n- **Phase 2 specs must reference Cosmic Python layers** – \"Models layer will contain...\", \"Services layer will orchestrate...\"\n- **Phase 3 code follows Cosmic Python patterns** – Layering, SOLID, testing per layer\n- **Phase 4 maintenance** – When fixing bugs, update spec first, then regenerate code (not manual patches)\n\n---\n\n## REFERENCE MATERIALS\n\n### Layer-by-Layer Real-World Examples\n\n- **[example-models-layer.md](references/example-models-layer.md)** – Domain entities, value objects, Pydantic models, no I/O\n- **[example-adapters-layer.md](references/example-adapters-layer.md)** – Repositories, gateways, abstract interfaces, test doubles\n- **[example-services-layer.md](references/example-services-layer.md)** – Use-case orchestration, dependency injection, error handling patterns\n- **[example-entrypoints-layer.md](references/example-entrypoints-layer.md)** – FastAPI endpoints, Typer CLI, scheduler integration\n\n### Testing & Quality\n\n- **[example-testing-patterns.md](references/example-testing-patterns.md)** – Unit tests per layer, mocking strategy, fixtures, BDD patterns\n- **[example-project-quality-ci.md](references/example-project-quality-ci.md)** – Makefile, tox, importlinter, GitHub Actions, SonarCloud setup\n\n### Advanced Production Patterns\n\n- **[example-advanced-patterns.md](references/example-advanced-patterns.md)** – Configuration via decorators, exception hierarchies, protocols, cross-version services\n\n### Documentation-First Methodology (Stream Coding)\n\n- **[stream-coding-methodology.md](references/stream-coding-methodology.md)** – 40/40/20 time split, 4 mandatory spec sections, Clarity Gate, Rule of Divergence\n- **[phase-1-strategic-blueprint-checklist.md](references/phase-1-strategic-blueprint-checklist.md)** – 7 Questions framework, Strategic Blueprint, ADR writing\n- **[phase-2-clarity-gate-checklist.md](references/phase-2-clarity-gate-checklist.md)** – AI-ready specs, 13-item Clarity Gate, scoring rubric\n\n### Company Standards & Principles\n\n- **[MEANINGFY_PROMPT.md](references/MEANINGFY_PROMPT.md)** – Full Meaningfy engineering culture: project structure, layering rules, SOLID principles, CI/CD expectations, security\n\n---\n\n## SKILL RELATIONSHIPS\n\n- **architecture** ← System-level design (C4 models, service boundaries, deployment); use BEFORE Cosmic Python\n- **stream-coding** ← Documentation-first methodology (planning specs); use WITH Cosmic Python for Phase 3 implementation\n- **cosmic-python** ← Code structure within services (this skill)\n- Your **CI/CD tooling** → importlinter, SonarCloud, pytest, tox (configured per Cosmic Python standards)"
              }
            ]
          },
          {
            "name": "python-architecture-skills",
            "description": "Cosmic Python and clean architecture guidance for well-tested, layered Python systems",
            "source": "./",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add meaningfy-ws/agent-skills",
              "/plugin install python-architecture-skills@agent-skills"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-04T17:44:40Z",
              "created_at": "2026-01-04T16:24:02Z",
              "license": "GPL-3.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "cosmic-python",
                "description": "Clean Architecture and Cosmic Python guidance for well-tested, layered Python systems. Use for designing Python projects with layered architecture (models, adapters, services, entrypoints), enforcing Clean Code and SOLID principles, testing strategies (unit tests, BDD, Gherkin), CI/CD setup (pytest, tox, importlinter), and architectural decision-making (ADRs). Applicable to systems requiring strict boundary enforcement, clean separation of concerns, and comprehensive test coverage.",
                "path": "skills/cosmic-python/SKILL.md",
                "frontmatter": {
                  "name": "cosmic-python",
                  "description": "Clean Architecture and Cosmic Python guidance for well-tested, layered Python systems. Use for designing Python projects with layered architecture (models, adapters, services, entrypoints), enforcing Clean Code and SOLID principles, testing strategies (unit tests, BDD, Gherkin), CI/CD setup (pytest, tox, importlinter), and architectural decision-making (ADRs). Applicable to systems requiring strict boundary enforcement, clean separation of concerns, and comprehensive test coverage.",
                  "license": "Apache 2.0",
                  "version": "1.0.0"
                },
                "content": "# Cosmic Python: Code Architecture for Production Systems\n\n## ⚠️ CRITICAL DISTINCTION\n\n**Cosmic Python is NOT about system architecture** (service boundaries, deployment topology, C4 models—that's the separate **architecture** skill).\n\n**Cosmic Python IS about code structure** within a Python module or service: how to organize classes, functions, tests, and dependencies so that code is clean, testable, and maintainable.\n\nWhen to use Cosmic Python:\n- You have a **service/module to build** (the strategic scope is clear from architecture decisions)\n- You need to **structure the Python code** inside that service with clean layers\n- You want to enforce **clean code principles, SOLID, and dependency management**\n- You need **comprehensive test coverage** organized per layer\n\nThis skill pairs with:\n- **Stream Coding** (documentation-first methodology) – Use to plan WHAT to build\n- **Cosmic Python** (this skill) – Use to structure HOW to build the code\n- **Architecture** skill – Use for system-level design (separate scope)\n\n---\n\n## THE MEANINGFY CONTRACT: MINIMISE WTFs PER MINUTE\n\nOur goal is **clean code that passes code review quickly** while keeping developers productive and safe.\n\nThis is achieved through three non-negotiable commitments:\n\n### 1. Layered Architecture – Strict Separation of Concerns\n\nWithin each Python module or service, separate code into **four tightly-bounded layers**:\n\n- **`models/`** – Domain logic (business rules, entities, value objects)\n  - No I/O, no framework dependencies, pure domain\n  - Tests focus on business invariants and domain rules\n  - Fastest tests, run first\n\n- **`adapters/`** – Infrastructure and integration (databases, APIs, file systems)\n  - Implement repositories, gateways, clients\n  - Depend on `models` only; never on `services` or `entrypoints`\n  - Tests mock external services; focus on integration boundaries\n\n- **`services/`** – Use-case orchestration (application logic, workflows)\n  - Choreograph `models` and `adapters`\n  - Contain transaction boundaries and error handling policy\n  - May depend on `models` and `adapters`, never on `entrypoints`\n  - Tests use mocks for adapters; focus on orchestration logic\n\n- **`entrypoints/`** – Request/response boundaries (API, CLI, schedulers, workers)\n  - Parse input, call services, format responses\n  - Handle routing, status codes, argument validation\n  - Minimal business logic; delegate to `services`\n  - Tests verify contracts (status codes, response shapes, argument parsing)\n\n### 2. Dependency Direction – Always Enforced (DIP)\n\n**The Law:**\n```\nentrypoints → services → models\n              ↘\n              adapters → models\n```\n\n**Never the reverse.** High-level policy (models + services) must never depend on low-level details (adapters). Low-level details depend on abstractions (interfaces/protocols), not the other way around.\n\n**When you violate this:**\n- Circular dependencies appear\n- Models become framework-dependent\n- Testing becomes hard (can't mock cleanly)\n- You've broken the architecture\n\n**How to enforce:**\n- Use `importlinter` in CI/CD to block forbidden imports (see references)\n- Code review checklist: \"What imports what?\" before approving\n\n### 3. No Clean Code Without Tests – Every Layer Owns Its Tests\n\n> \"If you can't test it, you can't understand it. If you can't understand it, you can't maintain it.\"\n\n- **80%+ coverage** on production code (target per layer)\n- **Tests per layer:** Each layer tests its own responsibility, not other layers' internals\n- **TDD/BDD:** Write tests before code; BDD (Gherkin) for use cases\n- **Test pyramid:** Many unit tests (fast, isolated), fewer integration tests, minimal end-to-end\n\n---\n\n## CORE PRINCIPLES FROM MEANINGFY ENGINEERING\n\n### Clean Code Standards\n\n- **Intention-revealing names** – `calculate_customer_tier()` not `calc_tier()`\n- **Small, cohesive functions** – <25 lines is a good target; if you say \"and\" in description, split\n- **No magic strings** – Define constants or enums; raw string literals are technical debt\n- **Minimal nesting** – Deep nesting signals complexity; refactor\n- **DRY but not obsessively** – Three similar lines don't warrant a helper; ten do\n\n### SOLID Principles Applied Systematically\n\n- **SRP** – One responsibility per class/function; if multiple reasons to change, split\n- **OCP** – Extend via new classes/strategies, not conditional logic in existing code\n- **LSP** – Subclasses must respect contracts; avoid overrides that break expected behavior\n- **ISP** – Avoid \"fat\" interfaces; split into cohesive ones matching clients' needs\n- **DIP** – Depend on abstractions (interfaces/protocols), inject concrete implementations\n\n### Observability as First-Class\n\n- **Structured logging** – Logs are data, not strings; emit JSON with context\n- **Keep it in the right layers** – Observability belongs in `services` and `entrypoints`, not deep in `models`\n- **OpenTelemetry patterns** – Tracing and metrics via standard conventions\n- **No print statements in production** – Use logging framework always\n\n---\n\n## ONE-MINUTE CODE STRUCTURE CHECK\n\n**For each function/class, ask:**\n\n- Which layer does this belong in?\n- What should it depend on?\n- What should depend on it?\n- What tests does it need?\n- Does it have only one reason to change?\n\nIf you can't answer these clearly, **the architecture is drifting.** See the references for detailed refactoring paths.\n\n---\n\n## COMMON WORKFLOWS\n\n### Workflow 1: Implementing Code From Specs (Stream Coding Phase 3)\n\nWhen you have clear specs from **Stream Coding Phase 2** (doc is 9+/10 Clarity Gate):\n\n1. **Identify which layer each component belongs to** – Models? Services? Adapters?\n2. **Start with `models/`** – Pure domain logic, no I/O, no frameworks\n3. **Write unit tests for models first** – Verify domain rules before implementing services\n4. **Implement `adapters/`** – Repositories, gateways, clients; mock external services in tests\n5. **Implement `services/`** – Orchestrate models and adapters; test with mocked adapters\n6. **Implement `entrypoints/`** – CLI, API, schedulers; minimal logic, mostly delegation\n7. **Run full test suite** – Verify 80%+ coverage per layer\n8. **Run architectural checks** – `make check-architecture` to validate import contracts\n\n### Workflow 2: Code Review Against Cosmic Python Standards\n\n**Before approving a pull request, ask:**\n\n**Layering:**\n- Does `models/` import from `services`, `adapters`, or `entrypoints`? ❌ Should not\n- Do `adapters/` import from `services` or `entrypoints`? ❌ Should not\n- Do `services/` import from `entrypoints`? ❌ Should not\n- Is business logic in `services/` or `models/`, not scattered in `entrypoints/`? ✅ Should be\n\n**Clean Code:**\n- Are functions <25 lines? ✅ Target for readability\n- Do all functions have only one reason to change? ✅ Check for SRP violation\n- Are all symbolic identifiers (role names, status values, etc.) constants/enums, not magic strings? ✅ Required\n- Is there any deep nesting (3+ levels)? ❌ Refactor to smaller functions\n\n**Testing:**\n- Does each layer have appropriate unit tests? ✅ Required\n- Are important decisions (branches, error cases) tested? ✅ All branches covered\n- Do adapters use mocks for external systems? ✅ Tests must be isolated\n- Is coverage reported per layer? ✅ Verify with `coverage report`\n\n**Observability:**\n- Are logs in `services/` and `entrypoints/`, not deep in `models/`? ✅ Correct placement\n- Is logging structured (JSON context), not formatted strings? ✅ Required for production\n\n### Workflow 3: Test Organization Per Layer\n\nFor each layer, write tests that match its responsibility:\n\n| Layer | What to Test | How | Example |\n|-------|--------------|-----|---------|\n| **`models/`** | Domain rules, invariants, transformations | Unit tests, no I/O, fast | `test_user_cannot_have_negative_balance()` |\n| **`adapters/`** | Integration with external systems (mocked) | Unit tests with mocks, or integration with real test DBs | `test_postgres_repository_insert_user()` |\n| **`services/`** | Use-case orchestration and business workflows | Unit tests with mocked adapters | `test_user_signup_flow_sends_verification_email()` |\n| **`entrypoints/`** | Request parsing, response formatting, status codes | Unit tests, check contracts | `test_api_endpoint_returns_201_on_create()` |\n\n**Target:** 80%+ coverage overall, with focus on each layer's responsibility (not mixing concerns).\n\n### Workflow 4: Spotting and Fixing Architecture Drift\n\nCommon anti-patterns and how to fix them:\n\n| Anti-Pattern | How It Looks | Why It's Wrong | Fix |\n|--------------|--------------|----------------|-----|\n| **I/O in models** | `import requests` in `models/user.py` | Models can't be tested in isolation | Move HTTP call to `adapters/`, inject via DIP |\n| **Business rules in entrypoints** | API handler validates and transforms data | Logic is scattered, untestable | Extract to `services/`, call from handler |\n| **Circular imports** | `services/` → `adapters/` → `services/` | Can't import cleanly, hard to test | Restructure: `adapters/` → `models/`; `services/` → `adapters/` + `models/` |\n| **Magic strings everywhere** | `if user.role == \"admin\"` in 5 files | Refactoring is fragile; intent hidden | Define `ROLE_ADMIN = \"admin\"` constant once, import everywhere |\n| **No tests for branching** | `services/` has 5 branches but only happy path tested | Edge cases crash production | Add parametrized tests for each branch |\n| **Clever one-liners** | `[x for x in y if x.z and (a or b)]` | Unreadable; maintenance nightmare | Expand to 3-4 readable lines with intermediate variables |\n\n---\n\n## QUALITY ASSURANCE & TOOLING\n\n### Essential Tools for Well-Guarded Projects\n\n- **Poetry** – Dependency management, lockfiles, reproducible builds\n- **pytest + pytest-bdd** – Unit tests (TDD) and behavior specs (BDD/Gherkin)\n- **tox** – Test multiple Python versions in isolated environments\n- **importlinter** – Enforce architectural boundaries (block forbidden imports)\n- **pylint / flake8** – Static analysis, style compliance\n- **SonarQube / SonarCloud** – Code quality gates, duplication, security smells\n- **Codecov** – Coverage reporting, trend tracking, gate on new code\n\n### Typical Makefile Pattern\n\n```bash\nmake install                # Set up environment (poetry install)\nmake test                   # Run unit tests with coverage\nmake test-bdd               # Run BDD feature tests\nmake check-architecture     # Validate import contracts (importlinter)\nmake lint                   # Run style checks (pylint, flake8)\nmake ci                     # Full pipeline (all above)\n```\n\n### CI/CD Workflow\n\nBefore merging to main:\n1. Run tests and verify 80%+ coverage on new code\n2. Run `importlinter` to block dependency violations\n3. Run SonarCloud analysis; no new critical issues\n4. Verify Clarity Gate from spec still matches code\n\n---\n\n## PRINCIPLES & BEST PRACTICES\n\n### On Code Structure\n\n- **Organize by domain, not by layer** – `billing/models/`, `billing/services/`, not `models/billing/`\n- **Use constants/enums for all symbolic identifiers** – Never rely on \"magic strings\"\n- **Small, cohesive functions** – If you say \"and\" when describing what a function does, split it\n- **Avoid deep nesting** – >3 levels usually signals refactoring opportunity\n- **DRY but pragmatically** – 2-3 similar lines are OK; 5+ warrant extraction\n\n### On Testing\n\n- **Test the decisions, not the steps** – Test what varies (branches), not happy paths\n- **Test per layer, not per unit** – Models test domain rules; services test orchestration\n- **Use fixtures and parametrization** – pytest.mark.parametrize for multiple scenarios\n- **Mock external dependencies** – Adapters provide mocks for services tests\n- **BDD for use cases** – Gherkin feature files for end-to-end workflows\n\n### On Architecture Decisions\n\n- **Document major choices in ADRs** – Architecture Decision Records explain the trade-off\n- **5–8 ADRs per service is typical** – More suggests decisions are tangled\n- **Contract-first design** – Write OpenAPI/AsyncAPI specs before code\n- **Use dependency injection** – Never `import` concrete implementations directly in services\n\n### On Observability\n\n- **Structured logging** – Emit JSON with context, not formatted strings\n- **Keep observability in the right layers** – `services/` and `entrypoints/`, not deep in `models/`\n- **No print() in production** – Use logging framework; configure per environment\n- **OpenTelemetry for tracing** – Standard conventions for metrics and spans\n\n---\n\n## WHEN NOT TO USE COSMIC PYTHON\n\n- **Rapid prototypes** – Layering has upfront cost; worthwhile only if long-term maintenance matters\n- **Exploratory/spike code** – Keep spikes separate; migrate to Cosmic Python only when strategy is clear\n- **Simple scripts** – Single-file scripts don't need four layers\n\nThis approach requires **team discipline**. One developer ignoring layers breaks the architecture for everyone. All developers must respect boundaries and code review rigorously.\n\n---\n\n## COSMIC PYTHON + STREAM CODING: THE COMPLETE WORKFLOW\n\n**Stream Coding** (documentation-first planning) and **Cosmic Python** (clean code structure) work together:\n\n| Phase | Methodology | Focus | Output |\n|-------|-------------|-------|--------|\n| 1 | **Stream Coding** | Strategic: WHAT to build, WHY | Strategic Blueprint + ADRs |\n| 2 | **Stream Coding** | Specifications: HOW to build (AI-ready) | Implementation Specs (9+/10 Clarity Gate) |\n| 3 | **Cosmic Python** | Code: Implement following layers/SOLID | Production code (80%+ tested) |\n| 4 | **Cosmic Python** | Quality: Prevent drift, maintain specs | CI/CD gates, spec-first fixes |\n\n### The Integration\n\n- **Phase 2 specs must reference Cosmic Python layers** – \"Models layer will contain...\", \"Services layer will orchestrate...\"\n- **Phase 3 code follows Cosmic Python patterns** – Layering, SOLID, testing per layer\n- **Phase 4 maintenance** – When fixing bugs, update spec first, then regenerate code (not manual patches)\n\n---\n\n## REFERENCE MATERIALS\n\n### Layer-by-Layer Real-World Examples\n\n- **[example-models-layer.md](references/example-models-layer.md)** – Domain entities, value objects, Pydantic models, no I/O\n- **[example-adapters-layer.md](references/example-adapters-layer.md)** – Repositories, gateways, abstract interfaces, test doubles\n- **[example-services-layer.md](references/example-services-layer.md)** – Use-case orchestration, dependency injection, error handling patterns\n- **[example-entrypoints-layer.md](references/example-entrypoints-layer.md)** – FastAPI endpoints, Typer CLI, scheduler integration\n\n### Testing & Quality\n\n- **[example-testing-patterns.md](references/example-testing-patterns.md)** – Unit tests per layer, mocking strategy, fixtures, BDD patterns\n- **[example-project-quality-ci.md](references/example-project-quality-ci.md)** – Makefile, tox, importlinter, GitHub Actions, SonarCloud setup\n\n### Advanced Production Patterns\n\n- **[example-advanced-patterns.md](references/example-advanced-patterns.md)** – Configuration via decorators, exception hierarchies, protocols, cross-version services\n\n### Documentation-First Methodology (Stream Coding)\n\n- **[stream-coding-methodology.md](references/stream-coding-methodology.md)** – 40/40/20 time split, 4 mandatory spec sections, Clarity Gate, Rule of Divergence\n- **[phase-1-strategic-blueprint-checklist.md](references/phase-1-strategic-blueprint-checklist.md)** – 7 Questions framework, Strategic Blueprint, ADR writing\n- **[phase-2-clarity-gate-checklist.md](references/phase-2-clarity-gate-checklist.md)** – AI-ready specs, 13-item Clarity Gate, scoring rubric\n\n### Company Standards & Principles\n\n- **[MEANINGFY_PROMPT.md](references/MEANINGFY_PROMPT.md)** – Full Meaningfy engineering culture: project structure, layering rules, SOLID principles, CI/CD expectations, security\n\n---\n\n## SKILL RELATIONSHIPS\n\n- **architecture** ← System-level design (C4 models, service boundaries, deployment); use BEFORE Cosmic Python\n- **stream-coding** ← Documentation-first methodology (planning specs); use WITH Cosmic Python for Phase 3 implementation\n- **cosmic-python** ← Code structure within services (this skill)\n- Your **CI/CD tooling** → importlinter, SonarCloud, pytest, tox (configured per Cosmic Python standards)"
              }
            ]
          }
        ]
      }
    }
  ]
}