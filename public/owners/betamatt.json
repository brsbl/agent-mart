{
  "owner": {
    "id": "betamatt",
    "display_name": "Matt Griffin",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/23032?u=f020d0f45605add2849f9e9323d565d363d86af0&v=4",
    "url": "https://github.com/betamatt",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 4,
      "total_commands": 12,
      "total_skills": 5,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "betamatt/claude-plugins",
      "url": "https://github.com/betamatt/claude-plugins",
      "description": "Plugins encapsulating some of my personal methods",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-07T02:19:12Z",
        "created_at": "2026-01-01T16:00:07Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1646
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/debugger.yaml",
          "type": "blob",
          "size": 19
        },
        {
          "path": ".claude/settings.json",
          "type": "blob",
          "size": 214
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 64
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 2911
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "claude-debugger",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-debugger/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-debugger/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 383
        },
        {
          "path": "claude-debugger/README.md",
          "type": "blob",
          "size": 2492
        },
        {
          "path": "claude-debugger/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-debugger/commands/set.md",
          "type": "blob",
          "size": 930
        },
        {
          "path": "claude-debugger/commands/status.md",
          "type": "blob",
          "size": 957
        },
        {
          "path": "claude-debugger/commands/view.md",
          "type": "blob",
          "size": 1420
        },
        {
          "path": "claude-debugger/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-debugger/hooks/hooks.json",
          "type": "blob",
          "size": 993
        },
        {
          "path": "claude-debugger/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-debugger/hooks/scripts/log-event.sh",
          "type": "blob",
          "size": 1760
        },
        {
          "path": "code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 413
        },
        {
          "path": "code-review/README.md",
          "type": "blob",
          "size": 6337
        },
        {
          "path": "code-review/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/agents/code-reviewer.md",
          "type": "blob",
          "size": 6382
        },
        {
          "path": "code-review/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/commands/code-review.md",
          "type": "blob",
          "size": 3793
        },
        {
          "path": "code-review/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/hooks/hooks.json",
          "type": "blob",
          "size": 559
        },
        {
          "path": "code-review/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/skills/code-review-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/skills/code-review-patterns/SKILL.md",
          "type": "blob",
          "size": 6485
        },
        {
          "path": "code-review/skills/code-review-patterns/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-review/skills/code-review-patterns/references/focus-areas.md",
          "type": "blob",
          "size": 5403
        },
        {
          "path": "code-review/skills/code-review-patterns/references/review-aspects.md",
          "type": "blob",
          "size": 10858
        },
        {
          "path": "ruby-on-rails",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 400
        },
        {
          "path": "ruby-on-rails/README.md",
          "type": "blob",
          "size": 3845
        },
        {
          "path": "ruby-on-rails/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/agents/migration-expert.md",
          "type": "blob",
          "size": 3955
        },
        {
          "path": "ruby-on-rails/agents/performance-expert.md",
          "type": "blob",
          "size": 4688
        },
        {
          "path": "ruby-on-rails/agents/rails-expert.md",
          "type": "blob",
          "size": 3600
        },
        {
          "path": "ruby-on-rails/agents/security-expert.md",
          "type": "blob",
          "size": 5473
        },
        {
          "path": "ruby-on-rails/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/commands/db.md",
          "type": "blob",
          "size": 2627
        },
        {
          "path": "ruby-on-rails/commands/generate.md",
          "type": "blob",
          "size": 2316
        },
        {
          "path": "ruby-on-rails/commands/migrate.md",
          "type": "blob",
          "size": 2696
        },
        {
          "path": "ruby-on-rails/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/hooks/hooks.json",
          "type": "blob",
          "size": 540
        },
        {
          "path": "ruby-on-rails/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/skills/activerecord-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/skills/activerecord-patterns/SKILL.md",
          "type": "blob",
          "size": 8544
        },
        {
          "path": "ruby-on-rails/skills/activerecord-patterns/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/skills/activerecord-patterns/references/migration-safety.md",
          "type": "blob",
          "size": 7699
        },
        {
          "path": "ruby-on-rails/skills/activerecord-patterns/references/query-patterns.md",
          "type": "blob",
          "size": 6666
        },
        {
          "path": "ruby-on-rails/skills/rails-conventions",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/skills/rails-conventions/SKILL.md",
          "type": "blob",
          "size": 7061
        },
        {
          "path": "ruby-on-rails/skills/rails-conventions/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/skills/rails-conventions/references/api-conventions.md",
          "type": "blob",
          "size": 7772
        },
        {
          "path": "ruby-on-rails/skills/rails-conventions/references/hotwire-patterns.md",
          "type": "blob",
          "size": 6066
        },
        {
          "path": "ruby-on-rails/skills/rails-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/skills/rails-testing/SKILL.md",
          "type": "blob",
          "size": 10126
        },
        {
          "path": "ruby-on-rails/skills/rails-testing/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "ruby-on-rails/skills/rails-testing/references/testing-patterns.md",
          "type": "blob",
          "size": 8510
        },
        {
          "path": "spec",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 473
        },
        {
          "path": "spec/README.md",
          "type": "blob",
          "size": 5114
        },
        {
          "path": "spec/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/agents/issue-fixer.md",
          "type": "blob",
          "size": 2990
        },
        {
          "path": "spec/agents/task-executor.md",
          "type": "blob",
          "size": 4306
        },
        {
          "path": "spec/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/commands/create.md",
          "type": "blob",
          "size": 7846
        },
        {
          "path": "spec/commands/decompose.md",
          "type": "blob",
          "size": 15002
        },
        {
          "path": "spec/commands/execute.md",
          "type": "blob",
          "size": 4543
        },
        {
          "path": "spec/commands/implement.md",
          "type": "blob",
          "size": 8130
        },
        {
          "path": "spec/commands/validate.md",
          "type": "blob",
          "size": 6827
        },
        {
          "path": "spec/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/hooks/hooks.json",
          "type": "blob",
          "size": 377
        },
        {
          "path": "spec/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/skills/spec-methodology",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/skills/spec-methodology/SKILL.md",
          "type": "blob",
          "size": 3863
        },
        {
          "path": "spec/skills/spec-methodology/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "spec/skills/spec-methodology/references/overengineering-patterns.md",
          "type": "blob",
          "size": 5493
        },
        {
          "path": "spec/skills/spec-methodology/references/spec-template.md",
          "type": "blob",
          "size": 4312
        }
      ],
      "marketplace": {
        "name": "betamatt-claude-plugins",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Matt Griffin",
          "email": "matt@griffinonline.org"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "ruby-on-rails",
            "description": "Professional Ruby on Rails development toolkit for production systems. Provides proactive expert agents, smart generators, and Rails 7+ best practices.",
            "source": "./ruby-on-rails",
            "category": null,
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add betamatt/claude-plugins",
              "/plugin install ruby-on-rails@betamatt-claude-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-07T02:19:12Z",
              "created_at": "2026-01-01T16:00:07Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/db",
                "description": "Database operations - seed, reset, prepare, and more",
                "path": "ruby-on-rails/commands/db.md",
                "frontmatter": {
                  "name": "db",
                  "description": "Database operations - seed, reset, prepare, and more",
                  "argument-hint": "<seed|reset|prepare|schema:load|schema:dump>",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Glob"
                  ]
                },
                "content": "# Rails Database Command\n\nExecute common database operations with appropriate safeguards.\n\n## Usage\n\n```\n/rails:db <action>\n```\n\n## Actions\n\n### seed\nRun database seeds.\n```bash\nbin/rails db:seed\n```\n\n### reset\nDrop, create, migrate, and seed the database.\n```bash\nbin/rails db:reset\n```\n\n**WARNING**: This destroys all data. Only use in development.\n\n### prepare\nPrepare database for the current environment (creates if needed, runs migrations).\n```bash\nbin/rails db:prepare\n```\n\nSafe for all environments.\n\n### schema:load\nLoad schema from `db/schema.rb` (faster than running all migrations).\n```bash\nbin/rails db:schema:load\n```\n\n### schema:dump\nDump current database schema to `db/schema.rb`.\n```bash\nbin/rails db:schema:dump\n```\n\n### setup\nCreate database, load schema, and seed.\n```bash\nbin/rails db:setup\n```\n\n### create\nCreate the database.\n```bash\nbin/rails db:create\n```\n\n### drop\nDrop the database.\n```bash\nbin/rails db:drop\n```\n\n**WARNING**: Destructive operation.\n\n## Process\n\n1. Identify the requested action\n2. Check current environment (development, test, production)\n3. For destructive operations:\n   - Warn if in production\n   - List consequences\n   - Require confirmation\n4. Execute the command\n5. Show results\n\n## Environment Safety\n\n### Development/Test\nAll operations allowed with standard warnings for destructive actions.\n\n### Production\nRestricted operations:\n- `reset` - BLOCKED (never reset production)\n- `drop` - BLOCKED (manual intervention required)\n- `schema:load` - WARNING (destroys existing data)\n- `seed` - WARNING (may duplicate data)\n- `prepare` - ALLOWED (safe idempotent operation)\n\n## Seed File Best Practices\n\nRecommend idempotent seeds:\n```ruby\n# db/seeds.rb\n# Use find_or_create_by for idempotency\nUser.find_or_create_by(email: \"admin@example.com\") do |user|\n  user.name = \"Admin\"\n  user.admin = true\nend\n\n# Or use upsert for bulk data\nProduct.upsert_all([\n  { sku: \"WIDGET-001\", name: \"Widget\", price: 9.99 },\n  { sku: \"GADGET-001\", name: \"Gadget\", price: 19.99 }\n], unique_by: :sku)\n```\n\n## Output\n\n```\nAction: db:prepare\n\nEnvironment: development\nDatabase: myapp_development\n\nChecking database status...\n  Database exists: ✓\n  Pending migrations: 2\n\nRunning db:prepare...\n  Running migrations...\n  == 20231203140000 AddOrdersTable: migrating ===\n  == 20231203140000 AddOrdersTable: migrated (0.0123s) ===\n\n✓ Database prepared successfully\n\nSchema version: 20231203140000\nTables: 8\n```"
              },
              {
                "name": "/generate",
                "description": "Smart Rails generator wrapper with production-ready defaults",
                "path": "ruby-on-rails/commands/generate.md",
                "frontmatter": {
                  "name": "generate",
                  "description": "Smart Rails generator wrapper with production-ready defaults",
                  "argument-hint": "<generator> <name> [attributes...]",
                  "allowed-tools": [
                    "Read",
                    "Write",
                    "Edit",
                    "Bash",
                    "Grep",
                    "Glob"
                  ]
                },
                "content": "# Rails Generate Command\n\nExecute Rails generators with production-best-practice defaults and guidance.\n\n## Usage\n\n```\n/rails:generate <generator> <name> [attributes...]\n```\n\n## Examples\n\n```\n/rails:generate model User email:string name:string\n/rails:generate controller Orders index show create\n/rails:generate migration AddStatusToOrders status:string:index\n/rails:generate scaffold Product name:string price:decimal\n```\n\n## Generator Types\n\n### Model Generator\n```bash\nbin/rails generate model <Name> [field:type...]\n```\n\nApply these defaults:\n- Add `null: false` for required fields in migration\n- Add indexes for foreign keys automatically\n- Suggest appropriate validations\n\n### Controller Generator\n```bash\nbin/rails generate controller <Name> [actions...]\n```\n\nApply these patterns:\n- Use resourceful routes when appropriate\n- Include strong parameters boilerplate\n- Set up proper before_actions\n\n### Migration Generator\n```bash\nbin/rails generate migration <MigrationName> [field:type...]\n```\n\nProduction patterns:\n- Use `algorithm: :concurrently` for index additions\n- Add `disable_ddl_transaction!` when needed\n- Include rollback safety\n\n### Scaffold Generator\n```bash\nbin/rails generate scaffold <Name> [field:type...]\n```\n\nEnhance with:\n- Turbo Stream responses\n- Proper flash messages\n- API-ready JSON responses\n\n## Process\n\n1. Parse the generator command and arguments\n2. Run the Rails generator\n3. Review generated files\n4. Apply production enhancements:\n   - Add missing indexes for foreign keys\n   - Add `null: false` constraints for required fields\n   - Enhance controller with proper error handling\n   - Add Turbo Stream support if appropriate\n5. Show what was generated and any enhancements made\n\n## Important\n\n- Always check if database migration is needed\n- Verify model validations match database constraints\n- Ensure routes are properly configured\n- For models with associations, suggest the inverse association\n\n## Output\n\nAfter generation:\n1. List all files created/modified\n2. Show any enhancements applied\n3. Suggest next steps (run migration, add associations, write tests)"
              },
              {
                "name": "/migrate",
                "description": "Safe migration workflow with production checks",
                "path": "ruby-on-rails/commands/migrate.md",
                "frontmatter": {
                  "name": "migrate",
                  "description": "Safe migration workflow with production checks",
                  "argument-hint": [
                    "up|down|redo|status|rollback"
                  ],
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Glob"
                  ]
                },
                "content": "# Rails Migrate Command\n\nExecute database migrations with safety checks and production awareness.\n\n## Usage\n\n```\n/rails:migrate [action]\n```\n\n## Actions\n\n- (no argument) - Run pending migrations\n- `status` - Show migration status\n- `rollback` - Rollback last migration\n- `redo` - Rollback and re-run last migration\n- `up VERSION=xxx` - Run specific migration up\n- `down VERSION=xxx` - Run specific migration down\n\n## Safety Checks\n\nBefore running migrations, verify:\n\n1. **Pending migrations exist**\n   ```bash\n   bin/rails db:migrate:status\n   ```\n\n2. **Review migration content**\n   - Check for potentially dangerous operations:\n     - `remove_column` without `ignored_columns`\n     - `change_column` on large tables\n     - Non-concurrent index creation\n     - `add_column` with `null: false` without default\n\n3. **Check for irreversible migrations**\n   - `change_column` without explicit `up`/`down`\n   - Data migrations that can't be undone\n\n## Production Warnings\n\nFlag these patterns with warnings:\n\n### Table Locks\n```ruby\n# WARNING: May lock table\nadd_index :large_table, :column  # Should use algorithm: :concurrently\nchange_column :table, :column, :new_type  # May rewrite table\n```\n\n### Data Loss\n```ruby\n# WARNING: Irreversible\nremove_column :orders, :status  # Check ignored_columns first\ndrop_table :old_table  # Ensure data is backed up\n```\n\n### Long-Running\n```ruby\n# WARNING: May take long time\nadd_column :users, :field, default: \"value\"  # On large tables\n# Rails 7+ handles this efficiently, but warn for older Rails\n```\n\n## Process\n\n1. Show migration status\n2. List pending migrations with summaries\n3. Analyze each migration for safety concerns\n4. If concerns found, display warnings\n5. Run migrations (or ask for confirmation if concerns)\n6. Show results and new schema state\n\n## Rollback Safety\n\nBefore rollback:\n1. Check if migration is reversible\n2. Warn about data that may be lost\n3. Suggest alternatives if destructive\n\n## Output\n\n```\nMigration Status:\n  up     20231201120000  Create users\n  up     20231202130000  Add email to users\n  down   20231203140000  Add orders table (pending)\n\nPending Migrations:\n  20231203140000_add_orders_table.rb\n    - Creates orders table\n    - Adds foreign key to users\n    - Adds index on user_id\n\nSafety Check: ✓ No concerns found\n\nRunning migrations...\n  == 20231203140000 AddOrdersTable: migrating ===\n  -- create_table(:orders)\n  -- add_index(:orders, :user_id)\n  == 20231203140000 AddOrdersTable: migrated (0.0123s) ===\n\n✓ Migration complete\n```"
              }
            ],
            "skills": [
              {
                "name": "ActiveRecord Patterns",
                "description": "This skill should be used when the user asks about \"ActiveRecord\", \"database queries\", \"query optimization\", \"N+1 queries\", \"eager loading\", \"associations\", \"migrations\", \"database indexes\", \"SQL performance\", \"ActiveRecord callbacks\", \"scopes\", or needs guidance on efficient database access patterns in Rails 7+.",
                "path": "ruby-on-rails/skills/activerecord-patterns/SKILL.md",
                "frontmatter": {
                  "name": "ActiveRecord Patterns",
                  "description": "This skill should be used when the user asks about \"ActiveRecord\", \"database queries\", \"query optimization\", \"N+1 queries\", \"eager loading\", \"associations\", \"migrations\", \"database indexes\", \"SQL performance\", \"ActiveRecord callbacks\", \"scopes\", or needs guidance on efficient database access patterns in Rails 7+.",
                  "version": "1.0.0"
                },
                "content": "# ActiveRecord Patterns for Production Rails\n\nProduction-focused guidance for ActiveRecord query optimization, associations, migrations, and database best practices for Rails 7+.\n\n## Query Optimization\n\n### Avoiding N+1 Queries\n\nAlways use `includes`, `preload`, or `eager_load` when accessing associations:\n\n```ruby\n# Bad - N+1 query\nOrder.all.each { |o| puts o.user.email }\n\n# Good - eager loading\nOrder.includes(:user).each { |o| puts o.user.email }\n\n# For nested associations\nOrder.includes(line_items: :product).each do |order|\n  order.line_items.each { |li| puts li.product.name }\nend\n```\n\n**When to use each:**\n- `includes` - Rails decides (usually `preload`)\n- `preload` - Separate queries, works with `limit`\n- `eager_load` - LEFT OUTER JOIN, needed for filtering\n\n```ruby\n# Filtering on association - must use eager_load\nOrder.eager_load(:line_items)\n     .where(line_items: { product_id: 123 })\n```\n\n### Select Only Needed Columns\n\n```ruby\n# Bad - loads all columns\nUser.all.map(&:email)\n\n# Good - loads only needed columns\nUser.pluck(:email)\n\n# When you need objects with limited columns\nUser.select(:id, :email, :name)\n```\n\n### Batch Processing\n\n```ruby\n# Bad - loads all records into memory\nUser.all.each { |u| u.update(last_contacted_at: Time.current) }\n\n# Good - processes in batches\nUser.find_each(batch_size: 1000) do |user|\n  user.update(last_contacted_at: Time.current)\nend\n\n# For parallelization\nUser.in_batches(of: 1000) do |batch|\n  batch.update_all(last_contacted_at: Time.current)\nend\n```\n\n### Counting and Existence\n\n```ruby\n# Bad - loads records to count\nUser.all.count        # Loads all, then counts\nUser.all.length       # Same problem\n\n# Good - database count\nUser.count            # SELECT COUNT(*)\n\n# For checking existence\nUser.any?             # Avoid - can be slow\nUser.exists?          # SELECT 1 LIMIT 1 - fast\nUser.where(admin: true).exists?\n```\n\n## Associations\n\n### Association Options\n\n```ruby\nclass Order < ApplicationRecord\n  belongs_to :user, counter_cache: true\n  belongs_to :created_by, class_name: \"User\", optional: true\n\n  has_many :line_items, dependent: :destroy\n  has_many :products, through: :line_items\n\n  has_one :invoice, dependent: :destroy\n\n  # Polymorphic\n  has_many :comments, as: :commentable\n\n  # Self-referential\n  belongs_to :parent_order, class_name: \"Order\", optional: true\n  has_many :child_orders, class_name: \"Order\", foreign_key: :parent_order_id\nend\n```\n\n### Counter Cache\n\n```ruby\n# Migration\nadd_column :users, :orders_count, :integer, default: 0, null: false\n\n# Reset existing counts\nUser.find_each do |user|\n  User.reset_counters(user.id, :orders)\nend\n\n# Model\nclass Order < ApplicationRecord\n  belongs_to :user, counter_cache: true\nend\n\n# Usage - no query needed\nuser.orders_count\n```\n\n### Inverse Of\n\nDefine explicitly for complex associations:\n\n```ruby\nclass Order < ApplicationRecord\n  has_many :line_items, inverse_of: :order\nend\n\nclass LineItem < ApplicationRecord\n  belongs_to :order, inverse_of: :line_items\nend\n\n# Prevents extra queries when building\norder = Order.new\norder.line_items.build(quantity: 1)\norder.line_items.first.order  # Same object, no query\n```\n\n## Scopes and Queries\n\n### Named Scopes\n\n```ruby\nclass Order < ApplicationRecord\n  scope :recent, -> { where(\"created_at > ?\", 30.days.ago) }\n  scope :pending, -> { where(status: :pending) }\n  scope :completed, -> { where(status: :completed) }\n  scope :for_user, ->(user) { where(user: user) }\n\n  # Composable scopes\n  scope :recent_pending, -> { recent.pending }\n\n  # Scope with default\n  scope :by_status, ->(status = :pending) { where(status: status) }\nend\n\n# Chaining\nOrder.recent.pending.for_user(current_user)\n```\n\n### Class Methods vs Scopes\n\nUse class methods for complex logic:\n\n```ruby\nclass Order < ApplicationRecord\n  def self.search(query)\n    return all if query.blank?\n\n    where(\"order_number ILIKE ? OR notes ILIKE ?\",\n          \"%#{query}%\", \"%#{query}%\")\n  end\n\n  def self.total_revenue\n    completed.sum(:total)\n  end\nend\n```\n\n### Arel for Complex Queries\n\n```ruby\nclass Order < ApplicationRecord\n  def self.with_high_value_items\n    line_items_table = LineItem.arel_table\n    orders_table = arel_table\n\n    joins(:line_items)\n      .where(line_items_table[:price].gt(100))\n      .distinct\n  end\nend\n```\n\n## Migrations\n\n### Production-Safe Migrations\n\n```ruby\nclass AddIndexToOrdersUserIdConcurrently < ActiveRecord::Migration[7.1]\n  disable_ddl_transaction!\n\n  def change\n    add_index :orders, :user_id, algorithm: :concurrently,\n              if_not_exists: true\n  end\nend\n```\n\n### Column Additions with Defaults\n\n```ruby\n# Rails 7+ handles this safely\nclass AddStatusToOrders < ActiveRecord::Migration[7.1]\n  def change\n    add_column :orders, :status, :string, default: \"pending\", null: false\n  end\nend\n```\n\n### Safe Column Removal\n\n```ruby\n# Step 1: Stop using column in code (deploy first)\n# Step 2: Ignore column\nclass Order < ApplicationRecord\n  self.ignored_columns += [\"legacy_status\"]\nend\n\n# Step 3: Remove column (separate deploy)\nclass RemoveLegacyStatusFromOrders < ActiveRecord::Migration[7.1]\n  def change\n    safety_assured { remove_column :orders, :legacy_status }\n  end\nend\n```\n\n### Indexing Strategy\n\n```ruby\n# Foreign keys - always index\nadd_index :orders, :user_id\n\n# Composite index for common queries\nadd_index :orders, [:user_id, :status]\n\n# Partial index for specific conditions\nadd_index :orders, :created_at,\n          where: \"status = 'pending'\",\n          name: \"index_orders_pending_created_at\"\n\n# Unique constraint\nadd_index :users, :email, unique: true\n\n# GIN index for array/JSON columns\nadd_index :products, :tags, using: :gin\n```\n\n## Transactions\n\n### Basic Transactions\n\n```ruby\nOrder.transaction do\n  order = Order.create!(order_params)\n  order.line_items.create!(line_item_params)\n  InventoryService.deduct(order)\nend\n```\n\n### Nested Transactions\n\n```ruby\nOrder.transaction do\n  order.update!(status: :processing)\n\n  Order.transaction(requires_new: true) do\n    # This savepoint can fail independently\n    PaymentService.charge(order)\n  rescue PaymentError => e\n    order.update!(payment_error: e.message)\n  end\nend\n```\n\n### Advisory Locks\n\n```ruby\n# Prevent concurrent processing\nOrder.with_advisory_lock(\"order_#{order.id}\") do\n  process_order(order)\nend\n```\n\n## Callbacks\n\n### Safe Callback Patterns\n\n```ruby\nclass Order < ApplicationRecord\n  # Good: Simple, side-effect free callbacks\n  before_validation :normalize_email\n  before_save :set_defaults\n\n  private\n\n  def normalize_email\n    self.email = email&.downcase&.strip\n  end\n\n  def set_defaults\n    self.order_number ||= generate_order_number\n  end\nend\n```\n\n### When to Avoid Callbacks\n\nMove business logic to service objects:\n\n```ruby\n# Avoid: Complex callback chains\nclass Order < ApplicationRecord\n  after_create :send_confirmation, :update_inventory, :notify_warehouse\nend\n\n# Prefer: Explicit service object\nclass Orders::CreateService\n  def call(params)\n    Order.transaction do\n      order = Order.create!(params)\n      OrderMailer.confirmation(order).deliver_later\n      Inventory::DeductService.new(order).call\n      Warehouse::NotifyJob.perform_later(order.id)\n      order\n    end\n  end\nend\n```\n\n## Connection Management\n\n### Connection Pool Configuration\n\n```yaml\n# config/database.yml\nproduction:\n  pool: <%= ENV.fetch(\"RAILS_MAX_THREADS\") { 5 } %>\n  checkout_timeout: 5\n  reaping_frequency: 10\n```\n\n### Read Replicas (Rails 6+)\n\n```ruby\n# config/database.yml\nproduction:\n  primary:\n    database: myapp_production\n  primary_replica:\n    database: myapp_production\n    replica: true\n\n# Usage\nActiveRecord::Base.connected_to(role: :reading) do\n  Order.where(status: :pending).count\nend\n\n# Automatic switching\nclass ApplicationController < ActionController::Base\n  around_action :switch_to_replica, only: [:index, :show]\n\n  private\n\n  def switch_to_replica\n    ActiveRecord::Base.connected_to(role: :reading) { yield }\n  end\nend\n```\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and advanced techniques:\n- **`references/query-patterns.md`** - Complex query patterns, CTEs, window functions\n- **`references/migration-safety.md`** - Zero-downtime migration strategies"
              },
              {
                "name": "Rails Conventions",
                "description": "This skill should be used when the user is working in a Rails 7+ application and asks about \"Rails conventions\", \"naming conventions\", \"Rails structure\", \"Hotwire patterns\", \"Turbo frames\", \"Stimulus controllers\", \"Rails directory structure\", \"Rails best practices\", or needs guidance on idiomatic Rails patterns for production systems.",
                "path": "ruby-on-rails/skills/rails-conventions/SKILL.md",
                "frontmatter": {
                  "name": "Rails Conventions",
                  "description": "This skill should be used when the user is working in a Rails 7+ application and asks about \"Rails conventions\", \"naming conventions\", \"Rails structure\", \"Hotwire patterns\", \"Turbo frames\", \"Stimulus controllers\", \"Rails directory structure\", \"Rails best practices\", or needs guidance on idiomatic Rails patterns for production systems.",
                  "version": "1.0.0"
                },
                "content": "# Rails 7+ Conventions for Production Systems\n\nProduction-focused guidance for Rails 7+ conventions, naming patterns, directory structure, and modern frontend integration with Hotwire.\n\n## Core Naming Conventions\n\n### Models\n\n- **Class names**: Singular, CamelCase (`User`, `OrderItem`, `PaymentTransaction`)\n- **Table names**: Plural, snake_case (`users`, `order_items`, `payment_transactions`)\n- **Foreign keys**: Singular model name + `_id` (`user_id`, `order_id`)\n- **Join tables**: Alphabetical order, plural (`categories_products`, `roles_users`)\n\n### Controllers\n\n- **Class names**: Plural, CamelCase + Controller (`UsersController`, `Api::V1::OrdersController`)\n- **Files**: Plural, snake_case (`users_controller.rb`, `api/v1/orders_controller.rb`)\n- **RESTful actions**: `index`, `show`, `new`, `create`, `edit`, `update`, `destroy`\n\n### Routes\n\nPrefer resourceful routes over custom routes:\n\n```ruby\n# Production pattern\nresources :orders do\n  resources :line_items, shallow: true\n  member do\n    post :cancel\n    post :refund\n  end\n  collection do\n    get :pending\n  end\nend\n\n# API versioning\nnamespace :api do\n  namespace :v1 do\n    resources :orders, only: [:index, :show, :create]\n  end\nend\n```\n\n### Views and Partials\n\n- **Views**: `app/views/controller_name/action.html.erb`\n- **Partials**: Prefix with underscore `_partial.html.erb`\n- **Shared partials**: `app/views/shared/_partial.html.erb`\n- **Component partials**: `app/views/components/_button.html.erb`\n\n## Directory Structure\n\n### Standard Rails 7 Layout\n\n```\napp/\n├── assets/\n│   └── stylesheets/\n├── channels/           # ActionCable channels\n├── controllers/\n│   ├── concerns/       # Controller concerns\n│   └── api/           # API controllers\n├── helpers/\n├── javascript/\n│   └── controllers/   # Stimulus controllers\n├── jobs/              # ActiveJob classes\n├── mailers/\n├── models/\n│   └── concerns/      # Model concerns\n├── views/\n│   ├── layouts/\n│   ├── shared/\n│   └── components/    # View components (if using)\nconfig/\n├── initializers/\n├── locales/\n└── environments/\ndb/\n├── migrate/\n└── seeds.rb\nlib/\n├── tasks/             # Rake tasks\n└── templates/         # Generator templates\nspec/ or test/\n```\n\n### Service Objects\n\nPlace in `app/services/` with clear naming:\n\n```ruby\n# app/services/orders/create_service.rb\nmodule Orders\n  class CreateService\n    def initialize(user:, cart:)\n      @user = user\n      @cart = cart\n    end\n\n    def call\n      # Implementation\n    end\n  end\nend\n\n# Usage: Orders::CreateService.new(user: current_user, cart: @cart).call\n```\n\n### Query Objects\n\nPlace in `app/queries/`:\n\n```ruby\n# app/queries/orders/pending_query.rb\nmodule Orders\n  class PendingQuery\n    def initialize(relation = Order.all)\n      @relation = relation\n    end\n\n    def call\n      @relation.where(status: :pending)\n               .where(\"created_at > ?\", 24.hours.ago)\n               .includes(:line_items, :user)\n    end\n  end\nend\n```\n\n## Hotwire Patterns (Rails 7+)\n\n### Turbo Frames\n\nUse for partial page updates without full navigation:\n\n```erb\n<%# Index page with inline editing %>\n<%= turbo_frame_tag \"orders\" do %>\n  <% @orders.each do |order| %>\n    <%= turbo_frame_tag dom_id(order) do %>\n      <%= render order %>\n    <% end %>\n  <% end %>\n<% end %>\n\n<%# Edit form that replaces the frame %>\n<%= turbo_frame_tag dom_id(@order) do %>\n  <%= render \"form\", order: @order %>\n<% end %>\n```\n\n### Turbo Streams\n\nUse for real-time updates and multi-element updates:\n\n```ruby\n# Controller action\ndef create\n  @order = Order.create(order_params)\n\n  respond_to do |format|\n    format.turbo_stream\n    format.html { redirect_to orders_path }\n  end\nend\n```\n\n```erb\n<%# create.turbo_stream.erb %>\n<%= turbo_stream.prepend \"orders\", @order %>\n<%= turbo_stream.update \"order_count\", Order.count %>\n```\n\n### Stimulus Controllers\n\nNaming convention: `controller-name_controller.js`\n\n```javascript\n// app/javascript/controllers/dropdown_controller.js\nimport { Controller } from \"@hotwired/stimulus\"\n\nexport default class extends Controller {\n  static targets = [\"menu\"]\n  static values = { open: Boolean }\n\n  toggle() {\n    this.openValue = !this.openValue\n  }\n\n  openValueChanged() {\n    this.menuTarget.classList.toggle(\"hidden\", !this.openValue)\n  }\n}\n```\n\n```erb\n<div data-controller=\"dropdown\" data-dropdown-open-value=\"false\">\n  <button data-action=\"click->dropdown#toggle\">Menu</button>\n  <div data-dropdown-target=\"menu\" class=\"hidden\">\n    <!-- Menu content -->\n  </div>\n</div>\n```\n\n## Configuration Patterns\n\n### Credentials (Rails 7+)\n\n```bash\n# Edit credentials\nbin/rails credentials:edit\n\n# Environment-specific\nbin/rails credentials:edit --environment production\n```\n\nAccess pattern:\n\n```ruby\nRails.application.credentials.dig(:aws, :access_key_id)\nRails.application.credentials.stripe[:secret_key]\n```\n\n### Environment Configuration\n\n```ruby\n# config/environments/production.rb\nRails.application.configure do\n  config.force_ssl = true\n  config.log_level = :info\n  config.active_job.queue_adapter = :sidekiq\nend\n```\n\n### Initializers\n\nName by feature, not gem:\n\n```ruby\n# config/initializers/stripe.rb (not payments.rb)\nStripe.api_key = Rails.application.credentials.stripe[:secret_key]\n```\n\n## Production Patterns\n\n### Strong Parameters\n\n```ruby\ndef order_params\n  params.require(:order).permit(\n    :shipping_address_id,\n    :notes,\n    line_items_attributes: [:id, :product_id, :quantity, :_destroy]\n  )\nend\n```\n\n### Callbacks Best Practices\n\nAvoid callback chains for business logic. Prefer service objects:\n\n```ruby\n# Avoid\nclass Order < ApplicationRecord\n  after_create :send_confirmation, :update_inventory, :notify_warehouse\nend\n\n# Prefer\nclass Orders::CreateService\n  def call\n    Order.transaction do\n      order = Order.create!(params)\n      OrderMailer.confirmation(order).deliver_later\n      Inventory::DeductService.new(order).call\n      Warehouse::NotifyJob.perform_later(order.id)\n      order\n    end\n  end\nend\n```\n\n### Scopes\n\nDefine commonly used queries as scopes:\n\n```ruby\nclass Order < ApplicationRecord\n  scope :recent, -> { where(\"created_at > ?\", 30.days.ago) }\n  scope :pending, -> { where(status: :pending) }\n  scope :with_items, -> { includes(:line_items) }\n  scope :for_user, ->(user) { where(user: user) }\nend\n```\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and examples:\n- **`references/hotwire-patterns.md`** - Advanced Turbo and Stimulus patterns\n- **`references/api-conventions.md`** - API versioning, serialization, authentication patterns"
              },
              {
                "name": "Rails Testing",
                "description": "This skill should be used when the user asks about \"Rails testing\", \"RSpec\", \"Minitest\", \"request specs\", \"system specs\", \"FactoryBot\", \"fixtures\", \"test coverage\", \"testing controllers\", \"testing models\", \"integration tests\", or needs guidance on writing effective tests for Rails 7+ applications.",
                "path": "ruby-on-rails/skills/rails-testing/SKILL.md",
                "frontmatter": {
                  "name": "Rails Testing",
                  "description": "This skill should be used when the user asks about \"Rails testing\", \"RSpec\", \"Minitest\", \"request specs\", \"system specs\", \"FactoryBot\", \"fixtures\", \"test coverage\", \"testing controllers\", \"testing models\", \"integration tests\", or needs guidance on writing effective tests for Rails 7+ applications.",
                  "version": "1.0.0"
                },
                "content": "# Rails Testing for Production Systems\n\nProduction-focused testing guidance supporting both RSpec and Minitest. Detect the project's testing framework and apply appropriate patterns.\n\n## Framework Detection\n\nCheck for testing framework in use:\n\n```bash\n# RSpec if present\ngrep -q \"rspec-rails\" Gemfile && echo \"RSpec\"\n\n# Check for spec directory\nls -d spec 2>/dev/null && echo \"RSpec\"\n\n# Minitest (Rails default)\nls -d test 2>/dev/null && echo \"Minitest\"\n```\n\n## RSpec Patterns\n\n### Directory Structure\n\n```\nspec/\n├── factories/           # FactoryBot definitions\n├── fixtures/files/      # File fixtures (images, PDFs)\n├── models/              # Model specs\n├── requests/            # Request specs (API testing)\n├── services/            # Service object specs\n├── system/              # System specs (browser testing)\n├── support/             # Helpers, shared examples\n│   ├── factory_bot.rb\n│   ├── capybara.rb\n│   └── shared_examples/\n└── rails_helper.rb\n```\n\n### Request Specs (API Testing)\n\n```ruby\n# spec/requests/api/v1/orders_spec.rb\nRSpec.describe \"Orders API\", type: :request do\n  let(:user) { create(:user) }\n  let(:headers) { { \"Authorization\" => \"Bearer #{user.api_token}\" } }\n\n  describe \"GET /api/v1/orders\" do\n    let!(:orders) { create_list(:order, 3, user: user) }\n\n    it \"returns user orders\" do\n      get \"/api/v1/orders\", headers: headers\n\n      expect(response).to have_http_status(:ok)\n      expect(json_response[\"orders\"].size).to eq(3)\n    end\n\n    it \"excludes other users orders\" do\n      other_order = create(:order)\n\n      get \"/api/v1/orders\", headers: headers\n\n      expect(json_response[\"orders\"].map { |o| o[\"id\"] })\n        .not_to include(other_order.id)\n    end\n  end\n\n  describe \"POST /api/v1/orders\" do\n    let(:valid_params) do\n      {\n        order: {\n          shipping_address_id: create(:address, user: user).id,\n          line_items_attributes: [\n            { product_id: create(:product).id, quantity: 2 }\n          ]\n        }\n      }\n    end\n\n    it \"creates an order\" do\n      expect {\n        post \"/api/v1/orders\", params: valid_params, headers: headers\n      }.to change(Order, :count).by(1)\n\n      expect(response).to have_http_status(:created)\n    end\n\n    context \"with invalid params\" do\n      it \"returns validation errors\" do\n        post \"/api/v1/orders\",\n             params: { order: { line_items_attributes: [] } },\n             headers: headers\n\n        expect(response).to have_http_status(:unprocessable_entity)\n        expect(json_response[\"errors\"]).to include(/line items/i)\n      end\n    end\n  end\n\n  private\n\n  def json_response\n    JSON.parse(response.body)\n  end\nend\n```\n\n### Model Specs\n\n```ruby\n# spec/models/order_spec.rb\nRSpec.describe Order, type: :model do\n  describe \"validations\" do\n    it { is_expected.to validate_presence_of(:user) }\n    it { is_expected.to validate_presence_of(:status) }\n\n    it \"requires at least one line item\" do\n      order = build(:order, line_items: [])\n      expect(order).not_to be_valid\n      expect(order.errors[:line_items]).to include(\"can't be empty\")\n    end\n  end\n\n  describe \"associations\" do\n    it { is_expected.to belong_to(:user) }\n    it { is_expected.to have_many(:line_items).dependent(:destroy) }\n    it { is_expected.to have_many(:products).through(:line_items) }\n  end\n\n  describe \"scopes\" do\n    describe \".pending\" do\n      it \"returns only pending orders\" do\n        pending = create(:order, :pending)\n        completed = create(:order, :completed)\n\n        expect(Order.pending).to include(pending)\n        expect(Order.pending).not_to include(completed)\n      end\n    end\n  end\n\n  describe \"#total\" do\n    it \"calculates sum of line item totals\" do\n      order = create(:order)\n      create(:line_item, order: order, price: 10, quantity: 2)\n      create(:line_item, order: order, price: 5, quantity: 1)\n\n      expect(order.total).to eq(25)\n    end\n  end\nend\n```\n\n### System Specs (Browser Testing)\n\n```ruby\n# spec/system/checkout_spec.rb\nRSpec.describe \"Checkout\", type: :system do\n  let(:user) { create(:user) }\n  let(:product) { create(:product, name: \"Widget\", price: 99) }\n\n  before do\n    sign_in user\n    create(:cart_item, user: user, product: product, quantity: 2)\n  end\n\n  it \"completes checkout successfully\" do\n    visit cart_path\n\n    expect(page).to have_content(\"Widget\")\n    expect(page).to have_content(\"$198.00\")\n\n    click_on \"Proceed to Checkout\"\n\n    fill_in \"Street address\", with: \"123 Main St\"\n    fill_in \"City\", with: \"Portland\"\n    select \"Oregon\", from: \"State\"\n    fill_in \"Zip\", with: \"97201\"\n\n    click_on \"Place Order\"\n\n    expect(page).to have_content(\"Order confirmed\")\n    expect(page).to have_content(\"Order #\")\n  end\n\n  it \"shows validation errors for invalid address\" do\n    visit checkout_path\n\n    click_on \"Place Order\"\n\n    expect(page).to have_content(\"Street address can't be blank\")\n  end\nend\n```\n\n### FactoryBot Patterns\n\n```ruby\n# spec/factories/orders.rb\nFactoryBot.define do\n  factory :order do\n    user\n    status { :pending }\n\n    transient do\n      items_count { 1 }\n    end\n\n    after(:build) do |order, evaluator|\n      if order.line_items.empty?\n        evaluator.items_count.times do\n          order.line_items << build(:line_item, order: order)\n        end\n      end\n    end\n\n    trait :pending do\n      status { :pending }\n    end\n\n    trait :completed do\n      status { :completed }\n      completed_at { Time.current }\n    end\n\n    trait :with_payment do\n      after(:create) do |order|\n        create(:payment, order: order)\n      end\n    end\n  end\nend\n```\n\n### Shared Examples\n\n```ruby\n# spec/support/shared_examples/authenticatable.rb\nRSpec.shared_examples \"requires authentication\" do\n  context \"without authentication\" do\n    let(:headers) { {} }\n\n    it \"returns unauthorized\" do\n      make_request\n      expect(response).to have_http_status(:unauthorized)\n    end\n  end\nend\n\n# Usage\nRSpec.describe \"Orders API\" do\n  describe \"GET /api/v1/orders\" do\n    it_behaves_like \"requires authentication\" do\n      let(:make_request) { get \"/api/v1/orders\", headers: headers }\n    end\n  end\nend\n```\n\n## Minitest Patterns\n\n### Directory Structure\n\n```\ntest/\n├── fixtures/            # YAML fixtures\n├── controllers/         # Functional tests\n├── integration/         # Integration tests\n├── models/              # Unit tests\n├── system/              # System tests\n├── helpers/             # Helper tests\n└── test_helper.rb\n```\n\n### Model Tests\n\n```ruby\n# test/models/order_test.rb\nclass OrderTest < ActiveSupport::TestCase\n  test \"validates presence of user\" do\n    order = Order.new(user: nil)\n    assert_not order.valid?\n    assert_includes order.errors[:user], \"must exist\"\n  end\n\n  test \"calculates total correctly\" do\n    order = orders(:pending_order)\n    assert_equal 150, order.total\n  end\n\n  test \"scope pending returns only pending orders\" do\n    pending_orders = Order.pending\n    assert pending_orders.all? { |o| o.status == \"pending\" }\n  end\nend\n```\n\n### Controller Tests (Integration)\n\n```ruby\n# test/controllers/orders_controller_test.rb\nclass OrdersControllerTest < ActionDispatch::IntegrationTest\n  setup do\n    @user = users(:john)\n    sign_in @user\n  end\n\n  test \"should get index\" do\n    get orders_url\n    assert_response :success\n    assert_select \"h1\", \"Your Orders\"\n  end\n\n  test \"should create order\" do\n    assert_difference(\"Order.count\") do\n      post orders_url, params: {\n        order: {\n          shipping_address_id: addresses(:home).id,\n          line_items_attributes: [\n            { product_id: products(:widget).id, quantity: 1 }\n          ]\n        }\n      }\n    end\n\n    assert_redirected_to order_url(Order.last)\n  end\nend\n```\n\n### System Tests\n\n```ruby\n# test/system/checkouts_test.rb\nclass CheckoutsTest < ApplicationSystemTestCase\n  setup do\n    @user = users(:john)\n    sign_in @user\n    @cart = create_cart_with_items(@user)\n  end\n\n  test \"completing checkout\" do\n    visit cart_url\n\n    click_on \"Checkout\"\n\n    fill_in \"Street address\", with: \"123 Main St\"\n    fill_in \"City\", with: \"Portland\"\n    click_on \"Place Order\"\n\n    assert_text \"Order confirmed\"\n  end\nend\n```\n\n### Fixtures\n\n```yaml\n# test/fixtures/orders.yml\npending_order:\n  user: john\n  status: pending\n  created_at: <%= 1.day.ago %>\n\ncompleted_order:\n  user: john\n  status: completed\n  completed_at: <%= 1.hour.ago %>\n```\n\n## Testing Best Practices\n\n### Test Speed\n\n```ruby\n# Use build instead of create when possible\norder = build(:order)  # No database hit\norder = create(:order) # Database hit\n\n# Use build_stubbed for even faster tests\norder = build_stubbed(:order)\n\n# Disable callbacks when not needed\nuser = create(:user, :skip_callbacks)\n```\n\n### Database Cleaner\n\n```ruby\n# spec/support/database_cleaner.rb\nRSpec.configure do |config|\n  config.before(:suite) do\n    DatabaseCleaner.clean_with(:truncation)\n  end\n\n  config.before(:each) do\n    DatabaseCleaner.strategy = :transaction\n  end\n\n  config.before(:each, type: :system) do\n    DatabaseCleaner.strategy = :truncation\n  end\n\n  config.around(:each) do |example|\n    DatabaseCleaner.cleaning { example.run }\n  end\nend\n```\n\n### Parallel Testing\n\n```ruby\n# spec/rails_helper.rb\nRSpec.configure do |config|\n  config.before(:suite) do\n    # Prepare database for parallel testing\n    ActiveRecord::Base.connection.execute(\"SET SESSION lock_timeout = '2s'\")\n  end\nend\n\n# Run tests in parallel\n# PARALLEL_TEST_PROCESSORS=4 bundle exec rspec\n```\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and examples:\n- **`references/testing-patterns.md`** - Advanced testing patterns, mocking, time testing\n- **`references/ci-configuration.md`** - GitHub Actions, parallel testing setup"
              }
            ]
          },
          {
            "name": "claude-debugger",
            "description": "Flexible logging and debugging system for Claude Code plugins. Track skills, subagents, hooks, tools, commands, and MCP calls with configurable verbosity.",
            "source": "./claude-debugger",
            "category": null,
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add betamatt/claude-plugins",
              "/plugin install claude-debugger@betamatt-claude-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-07T02:19:12Z",
              "created_at": "2026-01-01T16:00:07Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/set",
                "description": "Set debug verbosity level (off/minimal/normal/verbose)",
                "path": "claude-debugger/commands/set.md",
                "frontmatter": {
                  "name": "set",
                  "description": "Set debug verbosity level (off/minimal/normal/verbose)",
                  "argument-hint": "<level>",
                  "allowed-tools": [
                    "Read",
                    "Write",
                    "Bash"
                  ]
                },
                "content": "# Set Debug Verbosity Level\n\nSet the verbosity level for claude-debugger logging.\n\n## Usage\n\n```\n/debugger:set <level>\n```\n\n## Levels\n\n- **off** - Disable all logging\n- **minimal** - Log only skills and subagents\n- **normal** - Log skills, subagents, commands, hooks\n- **verbose** - Log everything including all tool calls and MCP\n\n## Process\n\n1. Validate the provided level is one of: off, minimal, normal, verbose\n2. Read the current settings file at `.claude/debugger.yaml` (create if doesn't exist)\n3. Update or set the `verbosity` field\n4. Confirm the change to the user\n\n## Settings File Format\n\n```yaml\nverbosity: normal\n```\n\n## Example\n\nUser runs: `/debugger:set verbose`\n\nResponse: \"Debug verbosity set to **verbose**. All events will be logged to `.claude/debug.log`.\""
              },
              {
                "name": "/status",
                "description": "Show current debug configuration and log stats",
                "path": "claude-debugger/commands/status.md",
                "frontmatter": {
                  "name": "status",
                  "description": "Show current debug configuration and log stats",
                  "allowed-tools": [
                    "Read",
                    "Bash"
                  ]
                },
                "content": "# Debug Status\n\nDisplay current claude-debugger configuration and log file statistics.\n\n## Usage\n\n```\n/debugger:status\n```\n\n## Process\n\n1. Read settings from `.claude/claude-debugger.local.md` if it exists\n2. Check if `.claude/debug.log` exists and get its stats\n3. Display current configuration\n\n## Output Format\n\n```\nClaude Debugger Status\n─────────────────────\nVerbosity: normal\nLog file:  .claude/debug.log\nLog size:  12.5 KB\nEntries:   234\n\nRecent activity:\n  TOOL: 156 events\n  AGENT: 12 events\n  SKILL: 8 events\n  CMD: 15 events\n  HOOK: 43 events\n```\n\n## Implementation\n\n1. Read verbosity from settings file (default: normal if not set)\n2. Use `wc -l` to count log entries\n3. Use `du -h` or `ls -lh` for file size\n4. Use `jq` or `grep` to count events by type\n5. Format and display the summary"
              },
              {
                "name": "/view",
                "description": null,
                "path": "claude-debugger/commands/view.md",
                "frontmatter": null,
                "content": "---\nname: view\ndescription: View recent debug log entries\nargument-hint: [lines] [--type=TYPE]\nallowed-tools: [\"Read\", \"Bash\"]\n---\n\n# View Debug Log\n\nDisplay recent entries from the debug log file.\n\n## Usage\n\n```\n/debugger:view [lines] [--type=TYPE]\n```\n\n## Arguments\n\n- **lines** (optional) - Number of recent entries to show (default: 20)\n- **--type=TYPE** (optional) - Filter by event type (TOOL, AGENT, SKILL, CMD, HOOK, MCP)\n\n## Examples\n\n```\n/debugger:view              # Show last 20 entries\n/debugger:view 50           # Show last 50 entries\n/debugger:view --type=AGENT # Show last 20 agent events\n/debugger:view 10 --type=TOOL # Show last 10 tool events\n```\n\n## Process\n\n1. Check if `.claude/debug.log` exists\n2. If type filter specified, use `grep` to filter by type\n3. Use `tail` to get the requested number of lines\n4. Parse JSON and display in readable format\n\n## Output Format\n\nDisplay each log entry in a readable format:\n\n```\n2024-01-15T14:32:05Z [TOOL] Read → /src/app.ts\n2024-01-15T14:32:06Z [TOOL] Edit → /src/app.ts\n2024-01-15T14:32:07Z [AGENT] code-search → completed\n2024-01-15T14:32:10Z [SKILL] rails-conventions → loaded\n```\n\n## Implementation\n\n1. Read log file: `.claude/debug.log`\n2. Apply type filter if specified: `grep '\"type\":\"AGENT\"'`\n3. Get last N lines: `tail -n $LINES`\n4. Parse JSON entries and format for display\n5. If log doesn't exist, inform user to enable debugging first\n"
              }
            ],
            "skills": []
          },
          {
            "name": "code-review",
            "description": "Comprehensive code review toolkit with parallel specialist agents covering architecture, quality, security, performance, testing, and documentation.",
            "source": "./code-review",
            "category": null,
            "version": "0.2.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add betamatt/claude-plugins",
              "/plugin install code-review@betamatt-claude-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-07T02:19:12Z",
              "created_at": "2026-01-01T16:00:07Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/code-review",
                "description": "Run comprehensive code review with multiple modes (manual, git changes, focused, or comprehensive)",
                "path": "code-review/commands/code-review.md",
                "frontmatter": {
                  "name": "code-review",
                  "description": "Run comprehensive code review with multiple modes (manual, git changes, focused, or comprehensive)",
                  "argument-hint": "[files|--changed|--focus=<area>|--all]",
                  "allowed-tools": [
                    "Read",
                    "Grep",
                    "Glob",
                    "Bash",
                    "Task"
                  ]
                },
                "content": "Run a comprehensive code review on the specified scope with multiple modes.\n\n## Modes\n\n### 1. **Manual Mode** (Default)\nReview specific files, directories, or the entire repository manually.\n\n### 2. **Git Changes Mode** (`--changed`)\nReview only files changed since last commit.\n\n### 3. **Focused Mode** (`--focus=<area>`)\nTarget specific review aspects across the scope.\n\n## Arguments\n\n- **files**: Specific file paths, glob patterns, or directories to review\n- **--changed**: Review files changed since last commit (git diff)\n- **--focus=<area>**: Focus on a specific review area\n- **--all**: Review entire repository (comprehensive mode)\n\n## Focus Areas\n\nAvailable focus areas (use with --focus):\n- `architecture` - Module organization, separation of concerns, design patterns\n- `security` - Vulnerabilities, auth issues, secrets, supply chain\n- `performance` - Algorithm complexity, N+1 queries, async patterns, memory\n- `quality` - Readability, naming, complexity, DRY principles\n- `testing` - Assertions, isolation, edge cases, maintainability\n- `docs` - README, JSDoc, breaking changes, API documentation\n\n## Process\n\n1. **Determine Scope and Mode**\n   - **Manual Mode**: If files/directories specified, review those\n   - **Git Changes Mode**: If `--changed`, get files from `git diff --name-only HEAD`\n   - **Comprehensive Mode**: If `--all` or no arguments, review entire repository\n   - **Focused Mode**: If `--focus` specified, target specific review aspect\n\n2. **Gather Context**\n   - Read project documentation (CLAUDE.md, README.md, ARCHITECTURE.md)\n   - Detect project conventions from config files\n   - Understand existing patterns in the codebase\n\n3. **Execute Review**\n   - If `--focus` specified, perform targeted single-aspect review\n   - Otherwise, launch 6 code-reviewer agents in parallel covering all aspects:\n     1. Architecture & Design\n     2. Code Quality\n     3. Security & Dependencies\n     4. Performance & Scalability\n     5. Testing Quality\n     6. Documentation & API\n\n4. **Consolidate Results**\n   - Merge findings from all review aspects\n   - Prioritize by impact (CRITICAL > HIGH > MEDIUM > LOW)\n   - Present unified report with actionable solutions\n\n## Output Format\n\n```markdown\n# Code Review: [Scope]\n\n## Summary\n- Files Reviewed: X\n- Critical Issues: X\n- High Priority: X\n- Medium Priority: X\n\n## Critical Issues\n[Issues with root cause analysis and working solutions]\n\n## High Priority\n[Issues with root cause analysis and working solutions]\n\n## Medium Priority\n[Issues with root cause analysis and working solutions]\n\n## Strengths\n[Well-done aspects worth preserving]\n\n## Recommendations\n[Proactive improvements beyond issues found]\n```\n\n## Examples\n\n### Manual Mode\n```\n/code-review src/auth/                    # Review specific directory\n/code-review *.ts                         # Review all TypeScript files\n/code-review src/api/user.ts src/models/  # Review specific files\n```\n\n### Git Changes Mode\n```\n/code-review --changed                    # Review all changed files\n/code-review --changed --focus=security   # Review security of changes\n```\n\n### Comprehensive Mode\n```\n/code-review --all                        # Review entire repository\n/code-review                              # Review entire repository (default)\n/code-review --all --focus=performance    # Performance review of entire repo\n```\n\n### Focused Mode\n```\n/code-review --focus=security src/api/    # Security review of API directory\n/code-review *.ts --focus=performance      # Performance review of TypeScript files\n```"
              }
            ],
            "skills": [
              {
                "name": "Code Review Patterns",
                "description": "This skill should be used when the user asks about \"code review best practices\", \"how to review code\", \"review methodology\", \"code review framework\", \"impact prioritization\", \"root cause analysis\", or needs guidance on systematic code review approaches and output templates.",
                "path": "code-review/skills/code-review-patterns/SKILL.md",
                "frontmatter": {
                  "name": "Code Review Patterns",
                  "description": "This skill should be used when the user asks about \"code review best practices\", \"how to review code\", \"review methodology\", \"code review framework\", \"impact prioritization\", \"root cause analysis\", or needs guidance on systematic code review approaches and output templates.",
                  "version": "0.1.0"
                },
                "content": "# Code Review Patterns\n\nA language-agnostic framework for conducting comprehensive, context-aware code reviews that provide actionable feedback with real-world impact prioritization.\n\n## Core Philosophy\n\nEffective code reviews go beyond surface-level issues to understand root causes and systemic patterns. Focus on providing deep, actionable feedback that considers business context, not just technical correctness.\n\n**Key principles:**\n- Understand project context and conventions before reviewing\n- Provide root cause analysis, not just symptoms\n- Include working solutions with every issue\n- Prioritize by real-world impact\n- Adapt to the language and framework of the codebase\n\n## Pre-Review Context Gathering\n\nBefore reviewing, establish context from the project itself:\n\n1. **Read project documentation** - CLAUDE.md, README, CONTRIBUTING, ARCHITECTURE docs\n2. **Detect conventions** - Linting configs, formatting rules, existing patterns\n3. **Understand structure** - Directory layout, module organization, naming conventions\n4. **Identify testing patterns** - Test framework, assertion style, coverage expectations\n5. **Check language/framework** - Adapt review criteria to the stack\n\nThe codebase itself defines what \"good\" looks like - discover and apply those standards.\n\n## Root Cause Analysis Framework\n\nFor every issue, provide three levels of analysis:\n\n**Level 1 - What**: The immediate issue observed\n**Level 2 - Why**: Root cause analysis explaining why this happens\n**Level 3 - How**: Specific, actionable solution with working code\n\nThis ensures issues are fully understood and solutions address underlying problems, not just symptoms.\n\n## Impact-Based Prioritization\n\nClassify every issue by real-world impact:\n\n| Priority | Label | Criteria | Action |\n|----------|-------|----------|--------|\n| CRITICAL | Red | Security vulnerabilities, data loss risks, privacy violations, production crashes | Fix immediately |\n| HIGH | Orange | Performance in hot paths, resource leaks, broken error handling, missing validation | Fix before merge |\n| MEDIUM | Yellow | Maintainability issues, inconsistent patterns, missing tests, tech debt in active areas | Fix soon |\n| LOW | Green | Style inconsistencies, minor optimizations, documentation gaps | Fix when convenient |\n\n### Prioritization Factors\n\n- **User-facing code** → Higher priority than internal utilities\n- **Security-sensitive paths** (auth, payments, PII) → Highest priority\n- **Frequently changed files** → Higher priority (high churn = high impact)\n- **Hot paths** (high traffic) → Performance issues more critical\n\n## Six Review Aspects\n\nComprehensive reviews cover six specialized aspects:\n\n1. **Architecture & Design** - Module organization, separation of concerns, design patterns, dependency direction\n2. **Code Quality** - Readability, naming, complexity, DRY principles, cognitive load\n3. **Security & Dependencies** - Vulnerabilities, auth, input validation, supply chain\n4. **Performance & Scalability** - Algorithm complexity, resource usage, async patterns, caching\n5. **Testing Quality** - Meaningful assertions, isolation, edge cases, maintainability\n6. **Documentation & API** - Self-documenting code, API docs, breaking changes\n\nFor detailed guidance on each aspect, see `references/review-aspects.md`.\n\n## Cross-File Intelligence\n\nComprehensive review requires understanding relationships:\n\n- **Component → Tests**: Is test coverage adequate?\n- **Interface → Implementations**: Are all implementations consistent?\n- **Config → Usage**: Do usage patterns align with configuration?\n- **Fix → Call sites**: Are all callers handled?\n- **API change → Documentation**: Is documentation updated?\n\nFind related files before concluding a review is complete.\n\n## Review Intelligence Layers\n\nApply five layers of analysis:\n\n1. **Syntax & Style** - Follows project's linting/formatting rules\n2. **Patterns & Practices** - Uses established patterns, avoids anti-patterns\n3. **Architectural Alignment** - Code in correct layer, proper abstraction level\n4. **Business Logic Coherence** - Logic matches requirements, edge cases handled\n5. **Evolution & Maintenance** - How code ages, testability, extensibility\n\n## Solution-Oriented Feedback\n\nNever just identify problems - always show the fix. A quality issue report includes:\n\n1. **Issue title** with file location\n2. **Impact** - Real-world consequence\n3. **Root cause** - Why this happens\n4. **Solution** - Working code in the project's language/style\n5. **Alternatives** (optional) - Other valid approaches\n\nAdapt solutions to match the codebase's existing patterns and conventions.\n\n## Review Output Template\n\nStructure feedback consistently:\n\n```markdown\n# Code Review: [Scope]\n\n## Review Metrics\n- **Files Reviewed**: X\n- **Critical Issues**: X\n- **High Priority**: X\n- **Medium Priority**: X\n- **Suggestions**: X\n\n## Executive Summary\n[2-3 sentences summarizing the most important findings]\n\n## CRITICAL Issues (Must Fix)\n[Issues with root cause analysis and working solutions]\n\n## HIGH Priority (Fix Before Merge)\n[Issues with root cause analysis and working solutions]\n\n## MEDIUM Priority (Fix Soon)\n[Issues with root cause analysis and working solutions]\n\n## LOW Priority (Opportunities)\n[Suggestions and minor improvements]\n\n## Strengths\n[What's done well, patterns worth replicating]\n\n## Proactive Suggestions\n[Opportunities beyond identified issues]\n\n## Systemic Patterns\n[Issues appearing multiple times - candidates for team discussion]\n```\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and guidance, consult:\n- **`references/focus-areas.md`** - Canonical definitions of the 6 focus areas with priority factors\n- **`references/review-aspects.md`** - Deep dive into each review aspect with checklists\n\n### Success Criteria\n\nA quality review should:\n- Understand project context and conventions first\n- Adapt to the language and framework in use\n- Provide root cause analysis, not just symptoms\n- Include working solutions in the project's style\n- Prioritize by real-world impact\n- Consider evolution and maintenance\n- Reference existing patterns in the codebase"
              }
            ]
          },
          {
            "name": "spec",
            "description": "Specification-driven development workflow with creation, validation, decomposition, execution, and automated review-fix loops.",
            "source": "./spec",
            "category": null,
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add betamatt/claude-plugins",
              "/plugin install spec@betamatt-claude-plugins"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-07T02:19:12Z",
              "created_at": "2026-01-01T16:00:07Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/create",
                "description": "Generate a spec file for a new feature or bugfix",
                "path": "spec/commands/create.md",
                "frontmatter": {
                  "name": "spec:create",
                  "description": "Generate a spec file for a new feature or bugfix",
                  "allowed-tools": "Read, Write, Grep, Glob, TodoWrite, Task, Bash(ls:*), Bash(echo:*), Bash(command:*), Bash(npm:*), Bash(claude:*)",
                  "argument-hint": "<feature-or-bugfix-description>"
                },
                "content": "## Context\n\n- Existing specs: !`ls -la specs/ 2>/dev/null || echo \"No specs directory found\"`\n\n## FIRST PRINCIPLES PROBLEM ANALYSIS\n\nBefore defining any solution, validate the problem from first principles:\n\n### Core Problem Investigation\n\n- **Strip Away Solution Assumptions**: What is the core problem, completely separate from any proposed solution?\n- **Root Cause Analysis**: Why does this problem exist? What created this need?\n- **Goal Decomposition**: What are we fundamentally trying to achieve for users/business?\n- **Success Definition**: What would success look like if we had unlimited resources and no constraints?\n- **Alternative Approaches**: Could we achieve the underlying goal without building anything? Are there simpler approaches?\n\n### Problem Validation Questions\n\n- **Real vs. Perceived**: Is this solving a real problem that users actually have?\n- **Assumption Audit**: What assumptions about user needs, technical constraints, or business requirements might be wrong?\n- **Value Proposition**: What is the minimum viable solution that delivers core value?\n- **Scope Validation**: Are we solving the right problem, or treating symptoms of a deeper issue?\n\n**CRITICAL: Only proceed if the core problem is clearly defined and validated. If uncertain, request additional context.**\n\n## MANDATORY PRE-CREATION VERIFICATION\n\nAfter validating the problem from first principles, complete these technical checks:\n\n### 1. Context Discovery Phase\n\n- Search existing codebase for similar features/specs using the Task tool with Explore agent\n- Apply domain-specific best practices when research involves specific domains (TypeScript, React, testing, databases, etc.)\n- Reference project-specific conventions from CLAUDE.md or similar documentation\n- Use the Explore agent sparingly for deep codebase analysis when needed\n- Identify potential conflicts or duplicates\n- Verify feature request is technically feasible\n- Document any missing prerequisites\n\n### 2. Request Validation\n\n- Confirm request is well-defined and actionable\n- If vague or incomplete, STOP and ask clarifying questions\n- Validate scope is appropriate (not too broad/narrow)\n\n### 3. Quality Gate\n\n- Only proceed if you have 80%+ confidence in implementation approach\n- If uncertain, request additional context before continuing\n- Document any assumptions being made\n\n**CRITICAL: If any validation fails, STOP immediately and request clarification.**\n\n## Your task\n\nCreate a comprehensive specification document in the `specs/` folder for the following feature/bugfix: $ARGUMENTS\n\nFirst, analyze the request to understand:\n\n1. Whether this is a feature or bugfix\n2. The scope and complexity\n3. Related existing code/features\n4. External libraries/frameworks involved\n\n## END-TO-END INTEGRATION ANALYSIS\n\nBefore writing the detailed specification, map the complete system impact:\n\n### System Integration Mapping\n\n- **Data Flow Tracing**: Trace data flow from user action -> processing -> storage -> response\n- **Service Dependencies**: Identify all affected services, APIs, databases, and external systems\n- **Integration Points**: Map every place this feature touches existing functionality\n- **Cross-System Impact**: How does this change affect other teams, services, or user workflows?\n\n### Complete User Journey Analysis\n\n- **Entry Points**: How do users discover and access this feature?\n- **Step-by-Step Flow**: What is the complete sequence from start to finish?\n- **Error Scenarios**: What happens when things go wrong at each step?\n- **Exit Points**: How does this connect to what users do next?\n\n### Deployment and Rollback Considerations\n\n- **Migration Path**: How do we get from current state to new state?\n- **Rollback Strategy**: What if we need to undo this feature?\n- **Deployment Dependencies**: What must be deployed together vs. independently?\n- **Data Migration**: How do we handle existing data during the transition?\n\n**VERIFICATION: Ensure you can trace the complete end-to-end flow before proceeding to detailed specification.**\n\nThen create a spec document that includes:\n\n1. **Title**: Clear, descriptive title of the feature/bugfix\n2. **Status**: Draft/Under Review/Approved/Implemented\n3. **Authors**: Your name and date\n4. **Overview**: Brief description and purpose\n5. **Background/Problem Statement**: Why this feature is needed or what problem it solves\n6. **Goals**: What we aim to achieve (bullet points)\n7. **Non-Goals**: What is explicitly out of scope (bullet points)\n8. **Technical Dependencies**:\n   - External libraries/frameworks used\n   - Version requirements\n   - Links to relevant documentation\n9. **Detailed Design**:\n   - Architecture changes\n   - Implementation approach\n   - Code structure and file organization\n   - API changes (if any)\n   - Data model changes (if any)\n   - Integration with external libraries (with examples from docs)\n10. **User Experience**: How users will interact with this feature\n11. **Testing Strategy**:\n    - Unit tests\n    - Integration tests\n    - E2E tests (if needed)\n    - Mocking strategies for external dependencies\n    - **Test documentation**: Each test should include a purpose comment explaining why it exists and what it validates\n    - **Meaningful tests**: Avoid tests that always pass regardless of behavior\n    - **Edge case testing**: Include tests that can fail to reveal real issues\n12. **Performance Considerations**: Impact on performance and mitigation strategies\n13. **Security Considerations**: Security implications and safeguards\n14. **Documentation**: What documentation needs to be created/updated\n15. **Implementation Phases**:\n    - Phase 1: MVP/Core functionality\n    - Phase 2: Enhanced features (if applicable)\n    - Phase 3: Polish and optimization (if applicable)\n16. **Open Questions**: Any unresolved questions or decisions\n17. **References**:\n    - Links to related issues, PRs, or documentation\n    - External library documentation links\n    - Relevant design patterns or architectural decisions\n\nFollow these guidelines:\n\n- Use Markdown format similar to existing specs\n- Be thorough and technical but also accessible\n- Include code examples where helpful\n- Consider edge cases and error scenarios\n- Reference existing project patterns and conventions\n- Use diagrams if they would clarify complex flows (using ASCII art or mermaid)\n- When referencing external libraries, include version-specific information\n- Do NOT include time or effort estimations (no \"X days\", \"Y hours\", or complexity estimates)\n\nName the spec file descriptively based on the feature:\n\n- Features: `feat-{kebab-case-name}.md`\n- Bugfixes: `fix-{issue-number}-{brief-description}.md`\n\n## PROGRESSIVE VALIDATION CHECKPOINTS\n\nAfter completing each major section:\n\n- **Problem Statement**: Verify it's specific and measurable\n- **Technical Requirements**: Confirm all dependencies are available\n- **Implementation Plan**: Validate approach is technically sound\n- **Testing Strategy**: Ensure testability of all requirements\n\nAt each checkpoint, if quality is insufficient, revise before proceeding.\n\n## FINAL SPECIFICATION VALIDATION\n\nBefore marking complete:\n\n1. **Completeness Check**: All 17 sections meaningfully filled\n2. **Consistency Check**: No contradictions between sections\n3. **Implementability Check**: Someone could build this from the spec\n4. **Quality Score**: Rate spec 1-10, only accept 8+\n\nBefore writing, search the codebase for:\n\n- Related existing features or code\n- Similar patterns in the codebase\n- Potential conflicts or dependencies\n- Current library versions in package.json or equivalent"
              },
              {
                "name": "/decompose",
                "description": "Break down a validated specification into actionable implementation tasks",
                "path": "spec/commands/decompose.md",
                "frontmatter": {
                  "name": "spec:decompose",
                  "description": "Break down a validated specification into actionable implementation tasks",
                  "allowed-tools": "Read, Task, Write, TodoWrite, Bash(mkdir:*), Bash(cat:*), Bash(grep:*), Bash(echo:*), Bash(basename:*), Bash(date:*), Bash(stm:*)",
                  "argument-hint": "<path-to-spec-file>"
                },
                "content": "# Decompose Specification into Tasks\n\nDecompose the specification at: $ARGUMENTS\n\n## Process Overview\n\nThis command takes a validated specification and breaks it down into:\n\n1. Clear, actionable tasks with dependencies\n2. Implementation phases and milestones\n3. Testing and validation requirements\n4. Documentation needs\n\nCheck if STM is available by running `stm list`. If the command fails, STM is not installed.\n\n## CRITICAL: Content Preservation Requirements\n\n**THIS IS THE MOST IMPORTANT PART**: When creating STM tasks, you MUST copy ALL content from the task breakdown into the STM tasks. Do NOT summarize or reference the spec - include the ACTUAL CODE and details.\n\n## Pre-Flight Checklist\n\nBefore creating any STM tasks, confirm your understanding:\n\n- [ ] I will NOT write summaries like \"Create X as specified in spec\"\n- [ ] I will COPY all code blocks from the task breakdown into STM --details\n- [ ] I will USE heredocs or temp files for multi-line content\n- [ ] I will INCLUDE complete implementations, not references\n- [ ] Each STM task will be self-contained with ALL details from the breakdown\n\n**If you find yourself typing phrases like \"as specified\", \"from spec\", or \"see specification\" - STOP and copy the actual content instead!**\n\n## Instructions\n\n0. **Task Management System**:\n   - Check the STM_STATUS output above\n   - If status is \"Available but not initialized\", run: `stm init`\n   - If status is \"Available and initialized\", use STM for task management\n   - If status is \"Not installed\", fall back to TodoWrite\n\n1. **Read and Validate Specification**:\n   - Read the specified spec file\n   - Verify it's a valid specification (has expected sections)\n   - Extract implementation phases and technical details\n\n2. **Analyze Specification Components**:\n   - Identify major features and components\n   - Extract technical requirements\n   - Note dependencies between components\n   - Identify testing requirements\n   - Document success criteria\n\n3. **Create Task Breakdown**:\n\n   Break down the specification into concrete, actionable tasks.\n\n   Key principles:\n\n   - Each task should have a single, clear objective\n   - **PRESERVE ALL CONTENT**: Copy implementation details, code blocks, and examples verbatim from the spec\n   - Define clear acceptance criteria with specific test scenarios\n   - Include tests as part of each task\n   - Document dependencies between tasks\n     - Write meaningful tests that can fail to reveal real issues\n     - Follow project principle: \"When tests fail, fix the code, not the test\"\n   - Create foundation tasks first, then build features on top\n   - Each task should be self-contained with all necessary details\n\n   **CRITICAL REQUIREMENT**: When creating tasks, you MUST preserve:\n\n   - Complete code examples (including full functions, not just snippets)\n   - All technical requirements and specifications\n   - Detailed implementation steps\n   - Configuration examples\n   - Error handling requirements\n   - All acceptance criteria and test scenarios\n\n   Think of each task as a complete mini-specification that contains everything needed to implement it without referring back to the original spec.\n\n   ## THE TWO-STEP PROCESS YOU MUST FOLLOW\n\n   **Step 1**: Create the task breakdown DOCUMENT with all details\n   **Step 2**: Copy those SAME details into STM tasks\n\n   The task breakdown document is NOT just for reference - it's the SOURCE for your STM task content!\n\n   Task structure:\n\n   - Foundation tasks: Core infrastructure (database, frameworks, testing setup)\n   - Feature tasks: Complete vertical slices including all layers\n   - Testing tasks: Unit, integration, and E2E tests\n   - Documentation tasks: API docs, user guides, code comments\n\n4. **Generate Task Document**:\n\n   Create a comprehensive task breakdown document:\n\n   ```markdown\n   # Task Breakdown: [Specification Name]\n   Generated: [Date]\n   Source: [spec-file]\n\n   ## Overview\n   [Brief summary of what's being built]\n\n   ## Phase 1: Foundation\n\n   ### Task 1.1: [Task Title]\n   **Description**: One-line summary of what needs to be done\n   **Size**: Small/Medium/Large\n   **Priority**: High/Medium/Low\n   **Dependencies**: None\n   **Can run parallel with**: Task 1.2, 1.3\n\n   **Technical Requirements**:\n   - [All technical details from spec]\n   - [Specific library versions]\n   - [Code examples from spec]\n\n   **Implementation Steps**:\n   1. [Detailed step from spec]\n   2. [Another step with specifics]\n   3. [Continue with all steps]\n\n   **Acceptance Criteria**:\n   - [ ] [Specific criteria from spec]\n   - [ ] Tests written and passing\n   - [ ] [Additional criteria]\n\n   ## Phase 2: Core Features\n   [Continue pattern...]\n   ```\n\n   Example task breakdown:\n\n   ```markdown\n   ### Task 2.3: Implement file system operations with backup support\n   **Description**: Build filesystem.ts module with Unix-focused operations and backup support\n   **Size**: Large\n   **Priority**: High\n   **Dependencies**: Task 1.1 (TypeScript setup), Task 1.2 (Project structure)\n   **Can run parallel with**: Task 2.4 (Config module)\n\n   **Source**: specs/feat-modernize-setup-installer.md\n\n   **Technical Requirements**:\n   - Path validation: Basic checks for reasonable paths\n   - Permission checks: Verify write permissions before operations\n   - Backup creation: Simple backup before overwriting files\n   - Error handling: Graceful failure with helpful messages\n   - Unix path handling: Use path.join, os.homedir(), standard Unix permissions\n\n   **Functions to implement**:\n   - validateProjectPath(input: string): boolean - Basic path validation\n   - ensureDirectoryExists(path: string): Promise<void>\n   - copyFileWithBackup(source: string, target: string, backup: boolean): Promise<void>\n   - setExecutablePermission(filePath: string): Promise<void> - chmod 755\n   - needsUpdate(source: string, target: string): Promise<boolean> - SHA-256 comparison\n   - getFileHash(filePath: string): Promise<string> - SHA-256 hash generation\n\n   **Implementation example from spec**:\n   ```typescript\n   async function needsUpdate(source: string, target: string): Promise<boolean> {\n     if (!await fs.pathExists(target)) return true;\n\n     const sourceHash = await getFileHash(source);\n     const targetHash = await getFileHash(target);\n\n     return sourceHash !== targetHash;\n   }\n   ```\n\n   **Acceptance Criteria**:\n   - [ ] All file operations handle Unix paths correctly\n   - [ ] SHA-256 based idempotency checking implemented\n   - [ ] Backup functionality creates timestamped backups\n   - [ ] Executable permissions set correctly for hooks (755)\n   - [ ] Path validation prevents directory traversal\n   - [ ] Tests: All operations work on macOS/Linux with proper error handling\n   ```\n\n5. **Create Task Management Entries**:\n\n   ## Common Mistake vs Correct Approach\n\n   **WRONG - What NOT to do**:\n\n   ```bash\n   stm add \"[P1.3] Implement common hook utilities\" \\\n     --description \"Create shared utilities module for all hooks\" \\\n     --details \"Create cli/hooks/utils.ts with readStdin() with 1-second timeout, findProjectRoot() using git rev-parse, detectPackageManager() checking lock files\" \\\n     --validation \"readStdin with timeout. Project root discovery. Package manager detection.\"\n   ```\n\n   **CORRECT - What you MUST do**:\n\n   ```bash\n   # For each task in the breakdown, find the corresponding section and COPY ALL its content\n   # Use temporary files for large content to preserve formatting\n\n   cat > /tmp/task-details.txt << 'EOF'\n   Create cli/hooks/utils.ts with the following implementations:\n\n   ```typescript\n   import { exec } from 'child_process';\n   import { promisify } from 'util';\n   import * as fs from 'fs-extra';\n   import * as path from 'path';\n\n   const execAsync = promisify(exec);\n\n   // Standard input reader\n   export async function readStdin(): Promise<string> {\n     return new Promise((resolve) => {\n       let data = '';\n       process.stdin.on('data', chunk => data += chunk);\n       process.stdin.on('end', () => resolve(data));\n       setTimeout(() => resolve(''), 1000); // Timeout fallback\n     });\n   }\n\n   // Project root discovery\n   export async function findProjectRoot(startDir: string = process.cwd()): Promise<string> {\n     try {\n       const { stdout } = await execAsync('git rev-parse --show-toplevel', { cwd: startDir });\n       return stdout.trim();\n     } catch {\n       return process.cwd();\n     }\n   }\n\n   // [Include ALL other functions from the task breakdown...]\n   ```\n\n   Technical Requirements:\n   - Standard input reader with timeout\n   - Project root discovery using git\n   - Package manager detection (npm/yarn/pnpm)\n   - Command execution wrapper\n   - Error formatting helper\n   - Tool availability checker\n   EOF\n\n   stm add \"[P1.3] Implement common hook utilities\" \\\n     --description \"Create shared utilities module for all hooks with stdin reader, project root discovery, package manager detection, command execution wrapper, error formatting, and tool availability checking\" \\\n     --details \"$(cat /tmp/task-details.txt)\" \\\n     --validation \"readStdin with 1-second timeout. Project root discovery via git. Package manager detection for npm/yarn/pnpm. Command execution with timeout and output capture. Error formatting follows BLOCKED: pattern. Tool availability checker works.\" \\\n     --tags \"phase1,infrastructure,utilities\"\n\n   rm /tmp/task-details.txt\n   ```\n\n   **Remember**: The task breakdown document you created has ALL the implementation details. Your job is to COPY those details into STM, not summarize them!\n\n   **Important STM field usage**:\n\n   - `--description`: Brief what & why (1-2 sentences max)\n   - `--details`: Complete technical implementation including:\n     - All technical requirements from spec\n     - Full code examples with proper formatting (COPY from breakdown, don't summarize!)\n     - Implementation steps and notes\n     - Architecture decisions\n     - **MUST be self-contained** - someone should be able to implement the task without seeing the original spec\n   - `--validation`: Complete acceptance criteria including:\n     - All test scenarios\n     - Success/failure conditions\n     - Edge cases to verify\n\n   ## Content Size Guidelines\n\n   - **Small tasks (< 20 lines)**: Can use heredocs directly in command\n   - **Medium tasks (20-200 lines)**: Use temporary files to preserve formatting\n   - **Large tasks (> 200 lines)**: Always use temporary files\n   - **Tasks with code blocks**: MUST use heredocs or files (never inline)\n\n   If STM is not available, use TodoWrite:\n\n   ```javascript\n   [\n     {\n       id: \"1\",\n       content: \"Phase 1: Set up TypeScript project structure\",\n       status: \"pending\",\n       priority: \"high\"\n     },\n     {\n       id: \"2\",\n       content: \"Phase 1: Configure build system with esbuild\",\n       status: \"pending\",\n       priority: \"high\"\n     },\n     // ... additional tasks\n   ]\n   ```\n\n6. **Save Task Breakdown**:\n   - Save the detailed task breakdown document to `specs/[spec-name]-tasks.md`\n   - Create tasks in STM or TodoWrite for immediate tracking\n   - Generate a summary report showing:\n     - Total number of tasks\n     - Breakdown by phase\n     - Parallel execution opportunities\n     - Task management system used (STM or TodoWrite)\n\n## Output Format\n\n### Task Breakdown Document\n\nThe generated markdown file includes:\n\n- Executive summary\n- Phase-by-phase task breakdown\n- Dependency graph\n- Risk assessment\n- Execution strategy\n\n### Task Management Integration\n\nTasks are immediately available in STM (if installed) or TodoWrite for:\n\n- Progress tracking\n- Status updates\n- Blocking issue identification\n- Parallel work coordination\n- Dependency tracking (STM only)\n- Persistent storage across sessions (STM only)\n\n### Summary Report\n\nDisplays:\n\n- Total tasks created\n- Tasks per phase\n- Critical path identification\n- Recommended execution order\n\n## Usage Examples\n\n```bash\n# Decompose a feature specification\n/spec:decompose specs/feat-user-authentication.md\n\n# Decompose a system enhancement spec\n/spec:decompose specs/feat-api-rate-limiting.md\n```\n\n## Success Criteria\n\nThe decomposition is complete when:\n\n- Task breakdown document is saved to specs directory\n- All tasks are created in STM (if available) or TodoWrite for tracking\n- **Tasks preserve ALL implementation details from the spec including:**\n  - Complete code blocks and examples (not summarized)\n  - Full technical requirements and specifications\n  - Detailed step-by-step implementation instructions\n  - All configuration examples\n  - Complete acceptance criteria with test scenarios\n- Foundation tasks are identified and prioritized\n- Dependencies between tasks are clearly documented\n- All tasks include testing requirements\n- Parallel execution opportunities are identified\n- **STM tasks use all three fields properly:**\n  - `--description`: Brief what & why (1-2 sentences)\n  - `--details`: Complete technical implementation from spec (ACTUAL CODE, not references)\n  - `--validation`: Full acceptance criteria and test scenarios\n- **Quality check passed**: Running `stm show [any-task-id]` displays full code implementations\n- **No summary phrases**: Tasks don't contain \"as specified\", \"from spec\", or similar references\n\n## Post-Creation Validation\n\nAfter creating STM tasks, perform these checks:\n\n1. **Sample Task Review**:\n\n   ```bash\n   # Pick a random task and check it has full implementation\n   stm show [task-id] | grep -E \"(as specified|from spec|see specification)\"\n   # Should return NO matches - if it does, the task is incomplete\n   ```\n\n2. **Content Length Check**:\n\n   ```bash\n   # Implementation tasks should have substantial details\n   stm list --format json | jq '.[] | select(.details | length < 500) | {id, title}'\n   # Review any tasks with very short details - they likely need more content\n   ```\n\n3. **Code Block Verification**:\n\n   ```bash\n   # Check that tasks contain actual code blocks\n   stm grep \"```\" | wc -l\n   # Should show many matches for tasks with code implementations\n   ```\n\n## Integration with Other Commands\n\n- **Prerequisites**: Run `/spec:validate` first to ensure spec quality\n- **Next step**: Use `/spec:execute` to implement the decomposed tasks\n- **Progress tracking**:\n  - With STM: `stm list --pretty` or `stm list --status pending`\n  - With TodoWrite: Monitor task completion in session\n- **Quality checks**: Run `/validate-and-fix` after implementation\n\n## Best Practices\n\n1. **Task Granularity**: Keep tasks focused on single objectives\n2. **Dependencies**: Clearly identify blocking vs parallel work\n3. **Testing**: Include test tasks for each component\n4. **Documentation**: Add documentation tasks alongside implementation\n5. **Phases**: Group related tasks into logical phases"
              },
              {
                "name": "/execute",
                "description": "Implement a validated specification with review-fix loops",
                "path": "spec/commands/execute.md",
                "frontmatter": {
                  "name": "spec:execute",
                  "description": "Implement a validated specification with review-fix loops",
                  "allowed-tools": "Task, Read, TodoWrite, Grep, Glob, Bash(stm:*), Bash(jq:*)",
                  "argument-hint": "<path-to-spec-file>"
                },
                "content": "# Implement Specification\n\nImplement the specification at: $ARGUMENTS\n\nCheck if STM is available by running `stm list`. If the command fails, STM is not installed.\n\n## Pre-Execution Checks\n\n1. **Check Task Management**:\n   - If STM shows \"Available but not initialized\" -> Run `stm init` first, then `/spec:decompose` to create tasks\n   - If STM shows \"Available and initialized\" -> Use STM for tasks\n   - If STM shows \"Not installed\" -> Use TodoWrite instead\n\n2. **Verify Specification**:\n   - Confirm spec file exists and is complete\n   - Check that required tools are available\n   - Stop if anything is missing or unclear\n\n## Implementation Process\n\n### 1. Analyze Specification\n\nRead the specification to understand:\n\n- What components need to be built\n- Dependencies between components\n- Testing requirements\n- Success criteria\n\n### 2. Load or Create Tasks\n\n**Using STM** (if available):\n\n```bash\nstm list --status pending -f json\n```\n\n**Using TodoWrite** (fallback):\n\nCreate tasks for each component in the specification\n\n### 3. Implementation Workflow\n\nFor each task, follow this cycle:\n\n#### Step 1: Implement\n\nImplement the component directly, applying domain-specific best practices:\n\n1. Run `stm show [task-id]` to get full task details\n2. Implement based on requirements, following project code style\n3. Add appropriate error handling\n4. Reference CLAUDE.md for project conventions\n\n#### Step 2: Write Tests\n\nWrite comprehensive tests for the implemented component:\n\n1. Cover edge cases and aim for >80% coverage\n2. Follow project testing patterns\n3. Run tests to verify they pass\n\n#### Step 3: Code Review with Fix Loop (Max 3 Iterations)\n\n**Important:** Always run code review to verify both quality AND completeness. Task cannot be marked done without passing both. The review-fix loop runs a maximum of 3 times before escalating to the user.\n\n```\niteration = 0\nreview_passed = false\n\nwhile iteration < 3 and not review_passed:\n\n  # Run code review\n  Review implementation for BOTH:\n  1. COMPLETENESS - Are all requirements from the task fully implemented?\n  2. QUALITY - Code quality, security, error handling, test coverage\n\n  Categorize issues as: CRITICAL, IMPORTANT, or MINOR.\n\n  # Parse review output\n  Extract issues by severity:\n  - CRITICAL: Security vulnerabilities, crashes, data loss\n  - IMPORTANT: Performance issues, missing error handling\n  - MINOR: Style, docs (log but don't block)\n\n  if no CRITICAL and no IMPORTANT issues:\n    review_passed = true\n    break\n\n  # Fix issues\n  For each CRITICAL issue:\n    Fix immediately - these block completion\n\n  For each IMPORTANT issue:\n    Fix before marking task done\n\n  # Re-run tests after fixes\n  Run test suite to verify fixes don't break anything\n\n  iteration++\n\n# Handle max iterations reached\nif iteration >= 3 and not review_passed:\n  ESCALATE - Do NOT mark task done\n  Report to user:\n  - Which issues remain unresolved\n  - What was attempted\n  - Request manual intervention\n```\n\n#### Step 4: Update STM Status\n\n**Auto-update protocol** - Always update STM status after review loop:\n\nOn success (review passed):\n\n```bash\nstm update [task-id] --status done --notes \"Implemented, tested, reviewed - passed\"\n```\n\nOn escalation (max iterations reached):\n\n```bash\nstm update [task-id] --status blocked --notes \"Review loop failed after 3 iterations - [remaining issues]\"\n```\n\nThen notify the user of the escalation with details about remaining issues.\n\n#### Step 5: Commit Changes\n\nCreate atomic commit following project conventions:\n\n```bash\ngit add [files]\ngit commit -m \"[follow project's commit convention]\"\n```\n\n### 4. Track Progress\n\nMonitor implementation progress:\n\n**Using STM:**\n\n```bash\nstm list --pretty              # View all tasks\nstm list --status pending      # Pending tasks\nstm list --status in-progress  # Active tasks\nstm list --status done         # Completed tasks\n```\n\n**Using TodoWrite:**\n\nTrack tasks in the session with status indicators.\n\n### 5. Complete Implementation\n\nImplementation is complete when:\n\n- All tasks are COMPLETE (all requirements implemented)\n- All tasks pass quality review (no critical issues)\n- All tests passing\n- Documentation updated\n\n## If Issues Arise\n\nIf problems are encountered:\n\n1. Identify the specific issue\n2. Apply relevant domain knowledge to resolve\n3. Or request user assistance if blocked"
              },
              {
                "name": "/implement",
                "description": "End-to-end spec implementation with review loops - validates, decomposes, and executes sequentially",
                "path": "spec/commands/implement.md",
                "frontmatter": {
                  "name": "spec:implement",
                  "description": "End-to-end spec implementation with review loops - validates, decomposes, and executes sequentially",
                  "allowed-tools": "Task, Read, Grep, Glob, Bash(stm:*), Bash(git:*), Bash(jq:*), Bash(gh:*)",
                  "argument-hint": "<path-to-spec-file> [--pr]"
                },
                "content": "# End-to-End Spec Implementation\n\nImplement the specification at: $ARGUMENTS\n\nThis command orchestrates the complete spec-to-code workflow:\n\n1. Validate the specification\n2. Readiness check - clarify ambiguities, confirm understanding\n3. Decompose into tasks\n4. Execute each task with review-fix loops\n5. Optionally create a PR\n\n## Parse Arguments\n\n```\nspec_path = first argument (required)\ncreate_pr = true if \"--pr\" flag present\n```\n\n## Phase 1: Validate Specification\n\nFirst, ensure the spec is ready for implementation.\n\nRun validation by reading and analyzing the spec file:\n\n1. Read the spec file at `spec_path`\n2. Check for required sections:\n   - **WHY**: Background, goals, success criteria\n   - **WHAT**: Features, requirements, constraints\n   - **HOW**: Implementation approach, architecture decisions\n3. Identify any critical gaps\n\n**If validation fails:**\n\n```\n## Specification Not Ready\n\nMissing sections: [list]\nCritical gaps: [list]\n\nWould you like me to help refine the spec? I can:\n1. Add missing sections with suggested content\n2. Clarify ambiguous requirements\n3. Fill in technical details\n\nOr run /spec:validate for detailed feedback.\n```\n\nAsk the user if they want help refining the spec. If yes, work with them to address gaps, then re-validate.\n\n**If validation passes:** Continue to Phase 2.\n\n## Phase 2: Readiness Check\n\nBefore decomposing, ensure the spec is clear enough for autonomous implementation.\n\n### Analyze for Ambiguities\n\nReview the spec and identify:\n\n1. **Ambiguous requirements** - vague language, multiple interpretations\n2. **Missing details** - error handling, edge cases, defaults not specified\n3. **Technical decisions needed** - library choices, patterns, approaches\n4. **Dependencies on user context** - existing code patterns, preferences, constraints\n\n### Ask Clarifying Questions\n\nIf any ambiguities or gaps are found:\n\n```\n## Before I Begin Implementation\n\nI've reviewed the spec and have some questions to ensure I implement this correctly:\n\n### Questions\n1. [Question about ambiguous requirement]\n2. [Question about missing detail]\n3. [Question about technical choice]\n\n### Assumptions I'll Make (unless you correct me)\n- [Assumption 1]\n- [Assumption 2]\n\n### Additional Context Needed\n- [Any files, examples, or information that would help]\n\nPlease answer these questions, or let me know if you'd like to proceed with my assumptions.\n```\n\n**Wait for user response before continuing.**\n\n### Confirm Readiness\n\nOnce questions are answered:\n\n```\n## Ready to Implement\n\nI have enough context to proceed. Here's my understanding:\n\n- [Summary of key requirements]\n- [Technical approach]\n- [Any constraints or preferences noted]\n\nShall I proceed with decomposition and implementation?\n```\n\n**Wait for explicit user confirmation before continuing to Phase 3.**\n\n## Phase 3: Decompose into Tasks (Idempotent)\n\nCheck if STM is available by running `stm list`. If the command fails, STM is not installed.\n\nCheck STM status and initialize if needed:\n\n- If \"Available but not initialized\" -> Run `stm init`\n- If \"Available and initialized\" -> Ready to use\n- If \"Not installed\" -> Will use TodoWrite fallback\n\n**Check for existing tasks first** (enables resume after session termination):\n\n```bash\n# Check if tasks already exist for this spec\nstm list --pretty\n```\n\n**If tasks already exist:**\n- Skip decomposition\n- Report: \"Found existing tasks from previous run. Resuming execution.\"\n- Continue to Phase 4\n\n**If no tasks exist:**\nCreate task breakdown:\n\n1. Read the spec to identify components\n2. Create tasks for each component with:\n   - Clear description\n   - Full implementation details (copied from spec, not summarized)\n   - Validation criteria\n3. Add tasks to STM or TodoWrite\n\n```bash\n# List created tasks\nstm list --pretty\n```\n\n## Phase 4: Execute Tasks Sequentially\n\nFor each pending task, select the most appropriate expert agent and execute:\n\n```\n# Get pending tasks\nstm list --status pending -f json\n\nFor each task in order:\n\n  # Mark as in-progress\n  stm update [task-id] --status in-progress\n\n  # Analyze task to select best agent type\n  # Read task details: stm show [task-id]\n  # Based on technologies, file types, and domain:\n  #   - TypeScript/JavaScript → typescript-expert or nodejs-expert\n  #   - React/Next.js → react-expert\n  #   - PostgreSQL/database → postgres-expert or database-expert\n  #   - Docker/infrastructure → docker-expert or devops-expert\n  #   - GitHub Actions/CI → github-actions-expert\n  #   - Generic/mixed → task-executor\n\n  # Execute using selected agent\n  Task tool:\n  - description: \"Execute [task-id]: [task-title]\"\n  - subagent_type: [selected-expert-agent]\n  - prompt: |\n      Execute this task from a spec implementation.\n\n      Task ID: [task-id]\n\n      Run `stm show [task-id]` to get full task details including requirements\n      and acceptance criteria.\n\n      Follow TDD red/green cycles:\n\n      1. **RED**: Write failing test(s) for the first requirement\n         - Test should fail with clear error showing missing functionality\n         - Run tests to confirm they fail\n\n      2. **GREEN**: Write minimal code to make test(s) pass\n         - Only implement what's needed to pass the current test\n         - Run tests to confirm they pass\n\n      3. **REFACTOR**: Clean up if needed while keeping tests green\n\n      4. Repeat steps 1-3 for each requirement in the task\n\n      5. Run code review (use code-review-expert agent), fix CRITICAL/IMPORTANT issues (max 3 iterations)\n\n      6. Update STM when done: `stm update [task-id] --status done`\n\n      7. Create atomic commit: `git commit -m \"[task-id]: [description]\"`\n\n      If blocked after 3 review iterations, update STM to blocked and escalate.\n\n      Report back with:\n      - TDD cycles completed (which tests drove which implementation)\n      - Final test results\n      - Review outcome\n      - Any issues encountered\n\n  # Check result\n  If agent reports success:\n    Continue to next task\n\n  If agent reports escalation:\n    STOP and report to user:\n    - Which task is blocked\n    - What issues remain\n    - Request manual intervention\n```\n\n## Phase 5: Completion\n\nWhen all tasks are done:\n\n```bash\n# Verify all tasks complete\nstm list --status done\nstm list --status pending  # Should be empty\nstm list --status blocked  # Should be empty\n```\n\n### If `--pr` Flag Present\n\nCreate a pull request with the implementation:\n\n```bash\n# Get current branch\ncurrent_branch=$(git branch --show-current)\n\n# Check if we need to push\ngit status\n\n# Push if needed\ngit push -u origin $current_branch\n\n# Create PR\ngh pr create \\\n  --title \"[Spec Implementation] [spec-name]\" \\\n  --body \"## Summary\n\nImplements specification: $spec_path\n\n## Tasks Completed\n\n$(stm list --status done --format markdown)\n\n## Testing\n\nAll tasks include tests that pass.\n\n## Review\n\nAll tasks passed code review with no CRITICAL or IMPORTANT issues.\n\n---\nGenerated with /spec:implement\"\n```\n\n### Final Report\n\n```\n## Implementation Complete\n\nSpecification: [spec_path]\nTasks completed: [count]\nCommits created: [count]\nPR created: [url if --pr flag]\n\nAll requirements implemented and reviewed.\n```\n\n## Escalation Protocol\n\nIf any task cannot be completed after 3 review-fix iterations:\n\n```\n## Implementation Blocked\n\nTask: [task-id] - [task-title]\nStatus: Blocked after 3 review iterations\n\nRemaining Issues:\n- [CRITICAL/IMPORTANT issue 1]\n- [CRITICAL/IMPORTANT issue 2]\n\nAttempts Made:\n- Iteration 1: [what was tried]\n- Iteration 2: [what was tried]\n- Iteration 3: [what was tried]\n\nSuggested Resolution:\n[Recommendation for manual intervention]\n\nTo resume after fixing:\n  stm update [task-id] --status pending\n  /spec:implement [spec-path]\n```\n\n## Usage Examples\n\n```bash\n# Implement a feature spec\n/spec:implement specs/feat-user-auth.md\n\n# Implement and create PR\n/spec:implement specs/feat-api-caching.md --pr\n```"
              },
              {
                "name": "/validate",
                "description": "Analyzes a specification document to determine if it has enough detail for autonomous implementation",
                "path": "spec/commands/validate.md",
                "frontmatter": {
                  "name": "spec:validate",
                  "description": "Analyzes a specification document to determine if it has enough detail for autonomous implementation",
                  "allowed-tools": "Task, Read, Grep",
                  "argument-hint": "<path-to-spec-file>"
                },
                "content": "# Specification Completeness Check\n\nAnalyze the specification at: $ARGUMENTS\n\n## Analysis Framework\n\nThis command will analyze the provided specification document to determine if it contains sufficient detail for successful autonomous implementation, while also identifying overengineering and non-essential complexity that should be removed or deferred.\n\n### Domain Expertise\n\nWhen analyzing specifications that involve specific technical domains, leverage available skills and knowledge:\n\n- Apply domain-specific best practices (TypeScript patterns, React conventions, database design, etc.)\n- Reference project-specific conventions from CLAUDE.md or similar documentation\n- Use the Explore agent sparingly for deep codebase analysis when needed\n\n### What This Check Evaluates\n\nThe analysis evaluates three fundamental aspects, each with specific criteria:\n\n#### 1. WHY - Intent and Purpose\n\n- Background/Problem Statement clarity\n- Goals and Non-Goals definition\n- User value/benefit explanation\n- Justification vs alternatives\n- Success criteria\n\n#### 2. WHAT - Scope and Requirements\n\n- Features and functionality definition\n- Expected deliverables\n- API contracts and interfaces\n- Data models and structures\n- Integration requirements:\n  - External system interactions?\n  - Authentication mechanisms?\n  - Communication protocols?\n- Performance requirements\n- Security requirements\n\n#### 3. HOW - Implementation Details\n\n- Architecture and design patterns\n- Implementation phases/roadmap\n- Technical approach:\n  - Core logic and algorithms\n  - All functions and methods fully specified?\n  - Execution flow clearly defined?\n- Error handling:\n  - All failure modes identified?\n  - Recovery behavior specified?\n  - Edge cases documented?\n- Platform considerations:\n  - Cross-platform compatibility?\n  - Platform-specific implementations?\n  - Required dependencies per platform?\n- Resource management:\n  - Performance constraints defined?\n  - Resource limits specified?\n  - Cleanup procedures documented?\n- Testing strategy:\n  - Test purpose documentation (each test explains why it exists)\n  - Meaningful tests that can fail to reveal real issues\n  - Edge case coverage and failure scenarios\n  - Follows project testing philosophy: \"When tests fail, fix the code, not the test\"\n- Deployment considerations\n\n### Additional Quality Checks\n\n**Completeness Assessment**\n\n- Missing critical sections\n- Unresolved decisions\n- Open questions\n\n**Clarity Assessment**\n\n- Ambiguous statements\n- Assumed knowledge\n- Inconsistencies\n\n**Overengineering Assessment**\n\n- Features not aligned with core user needs\n- Premature optimizations\n- Unnecessary complexity patterns\n\n### Overengineering Detection\n\n**Core Value Alignment Analysis**\n\nEvaluate whether features directly serve the core user need:\n\n- Does this feature solve a real, immediate problem?\n- Is it being used frequently enough to justify complexity?\n- Would a simpler solution work for 80% of use cases?\n\n**YAGNI Principle (You Aren't Gonna Need It)**\n\nBe aggressive about cutting features:\n\n- If unsure whether it's needed -> Cut it\n- If it's for \"future flexibility\" -> Cut it\n- If only 20% of users need it -> Cut it\n- If it adds any complexity -> Question it, probably cut it\n\n**Common Overengineering Patterns to Detect**\n\n1. **Premature Optimization**\n   - Caching for rarely accessed data\n   - Performance optimizations without benchmarks\n   - Complex algorithms for small datasets\n   - Micro-optimizations before profiling\n\n2. **Feature Creep**\n   - \"Nice to have\" features (cut them)\n   - Edge case handling for unlikely scenarios (cut them)\n   - Multiple ways to do the same thing (keep only one)\n   - Features that \"might be useful someday\" (definitely cut)\n\n3. **Over-abstraction**\n   - Generic solutions for specific problems\n   - Too many configuration options\n   - Unnecessary plugin/extension systems\n   - Abstract classes with single implementations\n\n4. **Infrastructure Overhead**\n   - Complex build pipelines for simple tools\n   - Multiple deployment environments for internal tools\n   - Extensive monitoring for non-critical features\n   - Database clustering for low-traffic applications\n\n5. **Testing Extremism**\n   - 100% coverage requirements\n   - Testing implementation details\n   - Mocking everything\n   - Edge case tests for prototype features\n\n**Simplification Recommendations**\n\n- Identify features to cut from the spec entirely\n- Suggest simpler alternatives\n- Highlight unnecessary complexity\n- Recommend aggressive scope reduction to core essentials\n\n### Output Format\n\nThe analysis will provide:\n\n- **Summary**: Overall readiness assessment (Ready/Not Ready)\n- **Critical Gaps**: Must-fix issues blocking implementation\n- **Missing Details**: Specific areas needing clarification\n- **Risk Areas**: Potential implementation challenges\n- **Overengineering Analysis**:\n  - Non-core features that should be removed entirely\n  - Complexity that doesn't align with usage patterns\n  - Suggested simplifications or complete removal\n- **Features to Cut**: Specific items to remove from the spec\n- **Essential Scope**: Absolute minimum needed to solve the core problem\n- **Recommendations**: Next steps to improve the spec\n\n### Example Overengineering Detection\n\nWhen analyzing a specification, the validator might identify patterns like:\n\n**Example 1: Unnecessary Caching**\n\n- Spec includes: \"Cache user preferences with Redis\"\n- Analysis: User preferences accessed once per session\n- Recommendation: Use in-memory storage or browser localStorage for MVP\n\n**Example 2: Premature Edge Cases**\n\n- Spec includes: \"Handle 10,000+ concurrent connections\"\n- Analysis: Expected usage is <100 concurrent users\n- Recommendation: Cut this entirely - let it fail at scale if needed\n\n**Example 3: Over-abstracted Architecture**\n\n- Spec includes: \"Plugin system for custom validators\"\n- Analysis: Only 3 validators needed, all known upfront\n- Recommendation: Implement validators directly, no plugin system needed\n\n**Example 4: Excessive Testing Requirements**\n\n- Spec includes: \"100% code coverage with mutation testing\"\n- Analysis: Tool used occasionally, not mission-critical\n- Recommendation: Focus on core functionality tests (70% coverage)\n\n**Example 5: Feature Creep**\n\n- Spec includes: \"Support 5 export formats (JSON, CSV, XML, YAML, TOML)\"\n- Analysis: 95% of users only need JSON\n- Recommendation: Cut all formats except JSON - YAGNI (You Aren't Gonna Need It)\n\nThis comprehensive analysis helps ensure specifications are implementation-ready while keeping scope focused on core user needs, reducing both ambiguity and unnecessary complexity."
              }
            ],
            "skills": [
              {
                "name": "Specification-Driven Development",
                "description": "This skill should be used when the user asks about \"spec methodology\", \"specification workflow\", \"spec-driven development\", \"how to write specs\", \"spec best practices\", \"specification templates\", or needs guidance on creating, validating, decomposing, or executing specifications for software development.",
                "path": "spec/skills/spec-methodology/SKILL.md",
                "frontmatter": {
                  "name": "Specification-Driven Development",
                  "description": "This skill should be used when the user asks about \"spec methodology\", \"specification workflow\", \"spec-driven development\", \"how to write specs\", \"spec best practices\", \"specification templates\", or needs guidance on creating, validating, decomposing, or executing specifications for software development.",
                  "version": "1.0.0"
                },
                "content": "# Specification-Driven Development Methodology\n\nA systematic approach to software development that starts with comprehensive specifications before implementation.\n\n## Workflow Overview\n\nThe spec workflow consists of four phases:\n\n```\n/spec:create -> /spec:validate -> /spec:decompose -> /spec:execute\n```\n\n### Phase 1: Create (`/spec:create`)\n\nGenerate a comprehensive specification document using first-principles thinking:\n\n1. **Problem Analysis**: Strip away solution assumptions, identify root cause\n2. **Validation**: Confirm real user need, audit assumptions\n3. **Technical Discovery**: Search codebase, identify conflicts/dependencies\n4. **Specification Writing**: 17-section template covering all aspects\n\n**When to use**: Starting any non-trivial feature or bugfix\n\n### Phase 2: Validate (`/spec:validate`)\n\nAnalyze the specification for completeness and detect overengineering:\n\n1. **WHY Analysis**: Intent, goals, success criteria\n2. **WHAT Analysis**: Scope, requirements, deliverables\n3. **HOW Analysis**: Implementation details, error handling, testing\n4. **YAGNI Check**: Cut unnecessary features aggressively\n\n**When to use**: Before decomposing, after major spec revisions\n\n### Phase 3: Decompose (`/spec:decompose`)\n\nBreak the validated spec into actionable implementation tasks:\n\n1. **Task Breakdown**: Single-objective tasks with clear acceptance criteria\n2. **Dependency Mapping**: Identify blocking vs parallel work\n3. **Content Preservation**: Copy ALL details, don't summarize\n4. **Task Management**: Create in STM or TodoWrite\n\n**When to use**: After spec passes validation\n\n### Phase 4: Execute (`/spec:execute`)\n\nImplement using orchestrated specialist agents:\n\n1. **Implement**: Launch domain expert agents\n2. **Test**: Write comprehensive tests\n3. **Review**: Code review for completeness AND quality\n4. **Fix**: Address issues before marking complete\n5. **Commit**: Atomic commits per task\n\n**When to use**: After decomposition creates tasks\n\n## Key Principles\n\n### First Principles Problem Analysis\n\nBefore any solution, validate the problem:\n\n- What is the core problem separate from solutions?\n- Why does this problem exist?\n- What would success look like with unlimited resources?\n- Could we solve this without building anything?\n\n### YAGNI (You Aren't Gonna Need It)\n\nBe aggressive about cutting scope:\n\n- Unsure if needed? Cut it\n- For \"future flexibility\"? Cut it\n- Only 20% of users need it? Cut it\n- Adds complexity? Question it, probably cut it\n\n### Content Preservation\n\nWhen creating tasks from specs:\n\n- COPY implementation details verbatim\n- Include complete code examples\n- Never write \"as specified in spec\"\n- Each task must be self-contained\n\n### Quality Gates\n\nEach phase has validation checkpoints:\n\n- Specs require 8+/10 quality score\n- Tasks require code review approval\n- Implementation requires all tests passing\n\n## Integration with Task Management\n\n### STM (Session Task Manager)\n\nIf installed, provides persistent task tracking:\n\n```bash\nstm init                      # Initialize\nstm add \"Task\" --details \"...\" # Create task\nstm list --pretty             # View tasks\nstm update [id] --status done # Complete task\n```\n\n### TodoWrite (Fallback)\n\nBuilt-in session task tracking when STM unavailable.\n\n## See Also\n\n- [references/spec-template.md](references/spec-template.md) - Full 17-section specification template\n- [references/overengineering-patterns.md](references/overengineering-patterns.md) - Common patterns to avoid"
              }
            ]
          }
        ]
      }
    }
  ]
}