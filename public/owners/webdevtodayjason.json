{
  "owner": {
    "id": "webdevtodayjason",
    "display_name": "Jason Brashear (AKA SEM)",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/115739170?u=6001f899b92d091182ed3ff0b0354a907ce9d92f&v=4",
    "url": "https://github.com/webdevtodayjason",
    "bio": "Director of AI Development & Cybersecurity at Titanium Computing (Austin, TX). Designing AI-centric systems and secure automation.",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 15,
      "total_skills": 9,
      "total_stars": 5,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "webdevtodayjason/titanium-plugins",
      "url": "https://github.com/webdevtodayjason/titanium-plugins",
      "description": "Professional Claude Code plugins with voice-enhanced AI workflows ",
      "homepage": null,
      "signals": {
        "stars": 5,
        "forks": 0,
        "pushed_at": "2025-10-22T01:53:06Z",
        "created_at": "2025-10-12T23:22:45Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 585
        },
        {
          "path": ".env.example",
          "type": "blob",
          "size": 2007
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 320
        },
        {
          "path": ".vibe-check.env.example",
          "type": "blob",
          "size": 1675
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1092
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 7557
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/AGENT_SKILLS_MAPPING.md",
          "type": "blob",
          "size": 9408
        },
        {
          "path": "docs/BMAD_COMPLETE.md",
          "type": "blob",
          "size": 15961
        },
        {
          "path": "docs/BMAD_GENERATION_PLAN.md",
          "type": "blob",
          "size": 54691
        },
        {
          "path": "docs/BMAD_QUICKSTART.md",
          "type": "blob",
          "size": 11394
        },
        {
          "path": "docs/BMAD_RESEARCH_SYSTEM.md",
          "type": "blob",
          "size": 19806
        },
        {
          "path": "docs/DEPENDENCIES.md",
          "type": "blob",
          "size": 8335
        },
        {
          "path": "docs/FINAL_REVIEW.md",
          "type": "blob",
          "size": 9983
        },
        {
          "path": "docs/ORCHESTRATION_PLAN.md",
          "type": "blob",
          "size": 73783
        },
        {
          "path": "docs/PIECES_INSTALLATION.md",
          "type": "blob",
          "size": 5925
        },
        {
          "path": "docs/SESSION_SUMMARY.md",
          "type": "blob",
          "size": 12577
        },
        {
          "path": "docs/TESTING_GUIDE.md",
          "type": "blob",
          "size": 9075
        },
        {
          "path": "docs/WEEK_1_COMPLETE.md",
          "type": "blob",
          "size": 8676
        },
        {
          "path": "docs/WEEK_2_COMPLETE.md",
          "type": "blob",
          "size": 16463
        },
        {
          "path": "examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/bmad-output",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/bmad-output/README.md",
          "type": "blob",
          "size": 1858
        },
        {
          "path": "examples/bmad-output/epics",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/bmad-output/epics/EPIC-001-enhanced-system-architecture-for-mathpuzzlequest.md",
          "type": "blob",
          "size": 6824
        },
        {
          "path": "examples/bmad-output/prd",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/bmad-output/prd/prd.md",
          "type": "blob",
          "size": 12232
        },
        {
          "path": "examples/bmad-output/product-brief.md",
          "type": "blob",
          "size": 8246
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 871
        },
        {
          "path": "plugins/titanium-toolkit/.mcp.json",
          "type": "blob",
          "size": 1293
        },
        {
          "path": "plugins/titanium-toolkit/LICENSE",
          "type": "blob",
          "size": 1092
        },
        {
          "path": "plugins/titanium-toolkit/README.md",
          "type": "blob",
          "size": 22813
        },
        {
          "path": "plugins/titanium-toolkit/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/agents/api-developer.md",
          "type": "blob",
          "size": 8556
        },
        {
          "path": "plugins/titanium-toolkit/agents/api-documenter.md",
          "type": "blob",
          "size": 8753
        },
        {
          "path": "plugins/titanium-toolkit/agents/architect.md",
          "type": "blob",
          "size": 4120
        },
        {
          "path": "plugins/titanium-toolkit/agents/code-reviewer.md",
          "type": "blob",
          "size": 4873
        },
        {
          "path": "plugins/titanium-toolkit/agents/debugger.md",
          "type": "blob",
          "size": 6802
        },
        {
          "path": "plugins/titanium-toolkit/agents/devops-engineer.md",
          "type": "blob",
          "size": 11050
        },
        {
          "path": "plugins/titanium-toolkit/agents/doc-writer.md",
          "type": "blob",
          "size": 8000
        },
        {
          "path": "plugins/titanium-toolkit/agents/frontend-developer.md",
          "type": "blob",
          "size": 7739
        },
        {
          "path": "plugins/titanium-toolkit/agents/marketing-writer.md",
          "type": "blob",
          "size": 10496
        },
        {
          "path": "plugins/titanium-toolkit/agents/meta-agent.md",
          "type": "blob",
          "size": 5716
        },
        {
          "path": "plugins/titanium-toolkit/agents/product-manager.md",
          "type": "blob",
          "size": 9168
        },
        {
          "path": "plugins/titanium-toolkit/agents/project-planner.md",
          "type": "blob",
          "size": 10058
        },
        {
          "path": "plugins/titanium-toolkit/agents/refactor.md",
          "type": "blob",
          "size": 8100
        },
        {
          "path": "plugins/titanium-toolkit/agents/security-scanner.md",
          "type": "blob",
          "size": 6126
        },
        {
          "path": "plugins/titanium-toolkit/agents/shadcn-ui-builder.md",
          "type": "blob",
          "size": 5766
        },
        {
          "path": "plugins/titanium-toolkit/agents/tdd-specialist.md",
          "type": "blob",
          "size": 8815
        },
        {
          "path": "plugins/titanium-toolkit/agents/test-runner.md",
          "type": "blob",
          "size": 5825
        },
        {
          "path": "plugins/titanium-toolkit/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/commands/bmad-architecture.md",
          "type": "blob",
          "size": 4061
        },
        {
          "path": "plugins/titanium-toolkit/commands/bmad-brief.md",
          "type": "blob",
          "size": 6881
        },
        {
          "path": "plugins/titanium-toolkit/commands/bmad-epic.md",
          "type": "blob",
          "size": 6706
        },
        {
          "path": "plugins/titanium-toolkit/commands/bmad-index.md",
          "type": "blob",
          "size": 5173
        },
        {
          "path": "plugins/titanium-toolkit/commands/bmad-prd.md",
          "type": "blob",
          "size": 9081
        },
        {
          "path": "plugins/titanium-toolkit/commands/bmad-research.md",
          "type": "blob",
          "size": 12612
        },
        {
          "path": "plugins/titanium-toolkit/commands/bmad-start.md",
          "type": "blob",
          "size": 25415
        },
        {
          "path": "plugins/titanium-toolkit/commands/catchup.md",
          "type": "blob",
          "size": 1219
        },
        {
          "path": "plugins/titanium-toolkit/commands/coderabbit-review.md",
          "type": "blob",
          "size": 7313
        },
        {
          "path": "plugins/titanium-toolkit/commands/titanium-getting-started.md",
          "type": "blob",
          "size": 23545
        },
        {
          "path": "plugins/titanium-toolkit/commands/titanium-orchestration-guide.md",
          "type": "blob",
          "size": 22464
        },
        {
          "path": "plugins/titanium-toolkit/commands/titanium-plan.md",
          "type": "blob",
          "size": 11502
        },
        {
          "path": "plugins/titanium-toolkit/commands/titanium-review.md",
          "type": "blob",
          "size": 15000
        },
        {
          "path": "plugins/titanium-toolkit/commands/titanium-status.md",
          "type": "blob",
          "size": 12679
        },
        {
          "path": "plugins/titanium-toolkit/commands/titanium-work.md",
          "type": "blob",
          "size": 25472
        },
        {
          "path": "plugins/titanium-toolkit/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/hooks/hooks.json",
          "type": "blob",
          "size": 939
        },
        {
          "path": "plugins/titanium-toolkit/hooks/mcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/hooks/mcp/tt-server.py",
          "type": "blob",
          "size": 8934
        },
        {
          "path": "plugins/titanium-toolkit/hooks/notification.py",
          "type": "blob",
          "size": 7538
        },
        {
          "path": "plugins/titanium-toolkit/hooks/post_tool_use_elevenlabs.py",
          "type": "blob",
          "size": 6509
        },
        {
          "path": "plugins/titanium-toolkit/hooks/stop.py",
          "type": "blob",
          "size": 10296
        },
        {
          "path": "plugins/titanium-toolkit/hooks/subagent_stop.py",
          "type": "blob",
          "size": 4755
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/bmad",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/bmad/bmad_generator.py",
          "type": "blob",
          "size": 39637
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/bmad/bmad_validator.py",
          "type": "blob",
          "size": 14712
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/bmad/research_generator.py",
          "type": "blob",
          "size": 16472
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/llm",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/llm/anth.py",
          "type": "blob",
          "size": 3233
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/llm/oai.py",
          "type": "blob",
          "size": 3340
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/tts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/tts/elevenlabs_mcp.py",
          "type": "blob",
          "size": 4042
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/tts/elevenlabs_tts.py",
          "type": "blob",
          "size": 2558
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/tts/local_tts.py",
          "type": "blob",
          "size": 2760
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/tts/openai_tts.py",
          "type": "blob",
          "size": 3110
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/workflow/plan_parser.py",
          "type": "blob",
          "size": 7761
        },
        {
          "path": "plugins/titanium-toolkit/hooks/utils/workflow/workflow_state.py",
          "type": "blob",
          "size": 7658
        },
        {
          "path": "plugins/titanium-toolkit/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/api-best-practices",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/api-best-practices/SKILL.md",
          "type": "blob",
          "size": 21670
        },
        {
          "path": "plugins/titanium-toolkit/skills/bmad-methodology",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/bmad-methodology/skill.md",
          "type": "blob",
          "size": 29094
        },
        {
          "path": "plugins/titanium-toolkit/skills/code-quality-standards",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/code-quality-standards/SKILL.md",
          "type": "blob",
          "size": 22667
        },
        {
          "path": "plugins/titanium-toolkit/skills/debugging-methodology",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/debugging-methodology/SKILL.md",
          "type": "blob",
          "size": 18730
        },
        {
          "path": "plugins/titanium-toolkit/skills/devops-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/devops-patterns/SKILL.md",
          "type": "blob",
          "size": 20854
        },
        {
          "path": "plugins/titanium-toolkit/skills/frontend-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/frontend-patterns/SKILL.md",
          "type": "blob",
          "size": 21086
        },
        {
          "path": "plugins/titanium-toolkit/skills/project-planning",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/project-planning/SKILL.md",
          "type": "blob",
          "size": 19970
        },
        {
          "path": "plugins/titanium-toolkit/skills/security-checklist",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/security-checklist/SKILL.md",
          "type": "blob",
          "size": 24377
        },
        {
          "path": "plugins/titanium-toolkit/skills/technical-writing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/technical-writing/SKILL.md",
          "type": "blob",
          "size": 17680
        },
        {
          "path": "plugins/titanium-toolkit/skills/testing-strategy",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/titanium-toolkit/skills/testing-strategy/SKILL.md",
          "type": "blob",
          "size": 21412
        }
      ],
      "marketplace": {
        "name": "titanium-plugins",
        "version": null,
        "description": "Professional Claude Code plugins from Titanium Computing featuring voice-enhanced AI workflows",
        "owner_info": {
          "name": "Jason Brashear",
          "email": "jason@webdevtoday.com",
          "url": "https://github.com/webdevtodayjason"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "titanium-toolkit",
            "description": "Complete development toolkit with voice announcements, 16 builder agents, and Pieces integration",
            "source": "./plugins/titanium-toolkit",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add webdevtodayjason/titanium-plugins",
              "/plugin install titanium-toolkit@titanium-plugins"
            ],
            "signals": {
              "stars": 5,
              "forks": 0,
              "pushed_at": "2025-10-22T01:53:06Z",
              "created_at": "2025-10-12T23:22:45Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/bmad-architecture",
                "description": "Generate BMAD architecture document from PRD",
                "path": "plugins/titanium-toolkit/commands/bmad-architecture.md",
                "frontmatter": {
                  "description": "Generate BMAD architecture document from PRD"
                },
                "content": "# BMAD Architecture - Generate Technical Architecture\n\nUse the architect subagent to create comprehensive technical architecture for this project following BMAD methodology.\n\n## Task Delegation\n\nFirst check if the PRD exists, then launch the architect subagent to handle the complete architecture generation workflow.\n\n## Process\n\n### Step 1: Verify Prerequisites\n\nCheck that PRD exists before delegating to architect:\n\n```bash\nls bmad-backlog/prd/prd.md 2>/dev/null || echo \"PRD not found\"\n```\n\n**If PRD NOT found**:\n```\n‚ùå Error: PRD not found at bmad-backlog/prd/prd.md\n\nArchitecture generation requires a PRD to work from.\n\nPlease run: /titanium-toolkit:bmad-prd first\n(Or /titanium-toolkit:bmad-start for complete guided workflow)\n```\n\nStop here - do not launch architect without PRD.\n\n**If PRD exists**: Continue to Step 2.\n\n### Step 2: Launch Architect Subagent\n\nUse the Task tool to launch the architect subagent in its own context window:\n\n```\nTask(\n  description: \"Generate BMAD architecture\",\n  prompt: \"Create comprehensive technical architecture document following BMAD methodology.\n\nInput:\n- PRD: bmad-backlog/prd/prd.md\n- Research findings: bmad-backlog/research/*.md (if any exist)\n\nOutput:\n- Architecture document: bmad-backlog/architecture/architecture.md\n\nRequirements:\n1. Read the PRD to understand requirements\n2. Check for research findings and incorporate recommendations\n3. Generate architecture using bmad_generator MCP tool\n4. Review tech stack with user and get approval\n5. Validate architecture using bmad_validator MCP tool\n6. Run vibe-check to validate architectural decisions\n7. Store result in Pieces for future reference\n8. Present summary with next steps\n\n**IMPORTANT**: Keep your summary response BRIEF (under 500 tokens). Just return:\n- Confirmation architecture is complete\n- Proposed tech stack (2-3 sentences)\n- MVP cost estimate\n- Any critical decisions made\n\nDO NOT include the full architecture content in your response - it's already saved to the file.\n\nFollow your complete architecture workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"architect\"\n)\n```\n\nThe architect subagent will handle:\n- Reading PRD and research findings\n- Generating architecture document (1000-1500 lines)\n- Tech stack selection and user approval\n- Validation (structural and vibe-check)\n- Pieces storage\n- Summary presentation\n\n### Step 3: Return Results\n\nThe architect will return a summary when complete. Present this to the user.\n\n## What the Architect Creates\n\nThe architect subagent generates `bmad-backlog/architecture/architecture.md` containing:\n\n- **System Overview**: High-level architecture diagram (ASCII), component descriptions\n- **Technology Stack**: Complete stack with rationale for each choice\n- **Component Details**: Detailed design for each system component\n- **Database Design**: Complete SQL schemas with CREATE TABLE statements\n- **API Design**: Endpoint specifications with request/response examples\n- **Security Architecture**: Auth, rate limiting, encryption, security controls\n- **Infrastructure**: Deployment strategy, scaling plan, CI/CD pipeline\n- **Monitoring**: Metrics, logging, tracing, alerting specifications\n- **Cost Analysis**: MVP costs and production projections\n- **Technology Decisions Table**: Each tech choice with rationale\n\n## Integration with Research\n\nIf research findings exist in `bmad-backlog/research/`, the architect will:\n- Read all RESEARCH-*-findings.md files\n- Extract vendor/technology recommendations\n- Incorporate into architecture decisions\n- Reference research in Technology Decisions table\n- Use research pricing in cost estimates\n\n## Voice Feedback\n\nVoice hooks announce:\n- \"Generating architecture\" (when starting)\n- \"Architecture complete\" (when finished)\n\n## Cost\n\nTypical cost: ~$0.08 per architecture generation (Claude Sonnet 4.5 API usage in bmad_generator tool)\n\n---\n\n**This command delegates to the architect subagent who creates the complete technical blueprint!**"
              },
              {
                "name": "/bmad-brief",
                "description": "Generate BMAD product brief from project idea",
                "path": "plugins/titanium-toolkit/commands/bmad-brief.md",
                "frontmatter": {
                  "description": "Generate BMAD product brief from project idea"
                },
                "content": "# BMAD Brief - Generate Product Brief\n\nUse the product-manager subagent to create a comprehensive Product Brief following BMAD methodology. The brief captures the high-level vision and goals.\n\n## Task Delegation\n\nFirst gather the project idea, then launch the product-manager subagent to handle the complete brief generation workflow.\n\n## Process\n\n### Step 1: Gather Project Idea\n\n**If user provided description**:\n- Store their description\n\n**If user said just `/bmad:brief`**:\n- Ask: \"What's your project idea at a high level?\"\n- Wait for response\n- Ask follow-up if needed: \"What problem does it solve? Who is it for?\"\n\n### Step 2: Launch Product-Manager Subagent\n\nUse the Task tool to launch the product-manager subagent in its own context window:\n\n```\nTask(\n  description: \"Generate BMAD product brief\",\n  prompt: \"Create comprehensive product brief following BMAD methodology.\n\nUser's Project Idea:\n{{user_idea}}\n\nYour workflow:\n\n1. **Generate product brief** using the MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"brief\\\",\n     input_path: \\\"{{user_idea}}\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n2. **Review generated brief** - Read bmad-backlog/product-brief.md and present key sections to user\n\n3. **Validate the brief** using:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \\\"brief\\\",\n     document_path: \\\"bmad-backlog/product-brief.md\\\"\n   )\n   ```\n\n4. **Run vibe-check** to validate the brief quality\n\n5. **Store in Pieces** for future reference\n\n6. **Present summary** to user with next steps\n\n**IMPORTANT**: Keep your summary response BRIEF (under 300 tokens). Just return:\n- Confirmation brief is complete\n- 1-2 sentence project description\n- Primary user segment\n- MVP feature count\n\nDO NOT include the full brief content in your response - it's already saved to the file.\n\nFollow your complete brief workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nThe product-manager subagent will handle:\n- Generating product brief\n- Reviewing and presenting key sections\n- Validation (structural and vibe-check)\n- Pieces storage\n- Summary presentation\n\n### Step 3: Return Results\n\nThe product-manager will return a summary when complete. Present this to the user.\n\n## What the Product-Manager Creates\n\nThe product-manager subagent generates `bmad-backlog/product-brief.md` containing:\n\n- **Executive Summary**: Project concept, problem, target market, value proposition\n- **Problem Statement**: Current state, pain points, urgency\n- **Proposed Solution**: Core concept, differentiators\n- **Target Users**: Primary and secondary user segments with detailed profiles\n- **Goals & Success Metrics**: Business objectives, user success metrics, KPIs\n- **MVP Scope**: Core features and what's out of scope\n- **Technical Considerations**: Platform requirements, tech preferences\n- **Constraints & Assumptions**: Budget, timeline, resources\n- **Risks & Open Questions**: Key risks and areas needing research\n- **Next Steps**: Immediate actions and PM handoff\n\n## Integration with Research\n\nThe product-manager may identify research needs during brief generation and suggest running `/bmad:research` for topics like:\n- Data vendors or APIs\n- Technology comparisons\n- Market research\n\n## Voice Feedback\n\nVoice hooks announce:\n- \"Generating product brief\" (when starting)\n- \"Product brief complete\" (when finished)\n\n## Cost\n\nTypical cost: ~$0.01 per brief generation (Claude Haiku 4.5 API usage in bmad_generator tool)\n\n### Step 4: Present Summary and Next Steps\n\n```\n‚úÖ Product Brief Complete!\n\nüìÑ Location: bmad-backlog/product-brief.md\n\nüìä Summary:\n- Problem: {{one-line problem}}\n- Solution: {{one-line solution}}\n- Users: {{primary user segment}}\n- MVP Features: {{count}} core features\n\nüí° Next Steps:\n\nOption 1: Generate PRD next\nRun: /bmad:prd\n\nOption 2: Generate complete backlog\nRun: /bmad:start\n(This will use the brief to generate PRD, Architecture, and all Epics)\n\nWhat would you like to do?\n```\n\n## Error Handling\n\n### If ANTHROPIC_API_KEY Missing\n\n```\n‚ùå Error: ANTHROPIC_API_KEY not found\n\nThe brief generation needs Anthropic Claude to create comprehensive content.\n\nPlease add your API key to ~/.env:\n  echo 'ANTHROPIC_API_KEY=sk-ant-your-key-here' >> ~/.env\n  chmod 600 ~/.env\n\nGet your key from: https://console.anthropic.com/settings/keys\n\nThen restart Claude Code and try again.\n```\n\n### If Generation Fails\n\n```\n‚ùå Brief generation failed\n\nThis could be due to:\n- API rate limits\n- Network issues\n- Invalid project description\n\nLet me try again with a simplified approach.\n\n[Retry with more basic prompt]\n```\n\n### If User Wants to Skip Brief\n\n```\nNote: Product brief is optional but recommended.\n\nYou can skip directly to PRD with:\n/bmad:prd\n\nHowever, the brief helps organize your thoughts and produces better PRDs.\n\nSkip brief and go to PRD? (yes/no)\n```\n\n## Voice Feedback\n\nVoice hooks will announce:\n- \"Generating product brief\" (when utility starts)\n- \"Product brief complete\" (when done)\n\n## Example Usage\n\n**Example 1: Simple Idea**\n```\nUser: /bmad:brief \"Social network for developers\"\n\nClaude: \"What problem does it solve?\"\nUser: \"Developers want to show off projects, not just resumes\"\n\nClaude: \"Who are the primary users?\"\nUser: \"Junior developers looking for jobs\"\n\n[Generates brief]\n\nClaude: \"Brief complete! Would you like to generate the PRD next?\"\n```\n\n**Example 2: Detailed Idea**\n```\nUser: /bmad:brief \"AI-powered precious metals research platform with real-time pricing, company fundamentals, smart screening, and AI-generated trade ideas for retail investors\"\n\n[Generates comprehensive brief from detailed description]\n\nClaude: \"Comprehensive brief generated! Next: /bmad:prd\"\n```\n\n**Example 3: Interactive Mode**\n```\nUser: /bmad:brief\n\nClaude: \"What's your project idea?\"\nUser: \"Todo app\"\n\nClaude: \"What makes it different from existing todo apps?\"\nUser: \"Uses voice input and AI scheduling\"\n\nClaude: \"Who is it for?\"\nUser: \"Busy professionals\"\n\n[Generates brief with full context]\n```\n\n## Important Guidelines\n\n**Always**:\n- ‚úÖ Use `bmad_generator` MCP tool (don't generate manually)\n- ‚úÖ Validate with vibe-check\n- ‚úÖ Store in Pieces\n- ‚úÖ Present clear summary\n- ‚úÖ Suggest next steps\n\n**Never**:\n- ‚ùå Generate brief content manually (use the tool)\n- ‚ùå Skip vibe-check validation\n- ‚ùå Forget to store in Pieces\n- ‚ùå Leave user uncertain about next steps\n\n## Integration\n\n**After `/bmad:brief`**:\n- Suggest `/bmad:prd` to continue\n- Or suggest `/bmad:start` to generate complete backlog\n- Brief is referenced by PRD generation\n\n**Part of `/bmad:start`**:\n- Guided workflow calls brief generation\n- Uses brief for PRD generation\n- Seamless flow\n\n---\n\n**This command creates the foundation for your entire project backlog!**"
              },
              {
                "name": "/bmad-epic",
                "description": "Generate single BMAD epic with user stories",
                "path": "plugins/titanium-toolkit/commands/bmad-epic.md",
                "frontmatter": {
                  "description": "Generate single BMAD epic with user stories"
                },
                "content": "# BMAD Epic - Generate Epic File\n\nUse the product-manager subagent to create a single epic file with user stories following BMAD methodology. This command is used to add NEW epics to existing backlog or regenerate existing epics.\n\n## When to Use This Command\n\n**Add NEW Epic** (change request, new feature):\n```bash\n# 6 months after launch, need mobile app\n/bmad:epic \"Mobile App\"\n# ‚Üí Creates EPIC-012-mobile-app.md\n```\n\n**Regenerate Existing Epic** (refinement):\n```bash\n/bmad:epic 3\n# ‚Üí Regenerates EPIC-003 with updated content\n```\n\n**NOT used during `/bmad:start`** - guided workflow generates all epics automatically.\n\n## Task Delegation\n\nFirst check prerequisites, determine which epic to generate, then launch the product-manager subagent to handle the complete epic generation workflow.\n\n## Process\n\n### Step 1: Check Prerequisites\n\n**Require PRD**:\n```bash\nls bmad-backlog/prd/prd.md 2>/dev/null || echo \"No PRD found\"\n```\n\nIf not found:\n```\n‚ùå Error: PRD required for epic generation\n\nPlease run: /bmad:prd\n(Or /bmad:start for complete workflow)\n```\n\nStop here - do not launch product-manager without PRD.\n\n**Check for Architecture** (recommended):\n```bash\nls bmad-backlog/architecture/architecture.md 2>/dev/null || echo \"No architecture found\"\n```\n\nIf not found:\n```\n‚ö†Ô∏è  Architecture not found\n\nEpic generation works best with architecture (for technical notes).\n\nWould you like to:\n1. Generate architecture first (recommended): /bmad:architecture\n2. Continue without architecture (epics will have minimal technical notes)\n3. Cancel\n\nChoose:\n```\n\nIf user chooses 1: Run `/bmad:architecture` first, then continue\nIf user chooses 2: Continue to Step 2\nIf user chooses 3: Exit gracefully\n\n### Step 2: Determine Epic to Generate\n\n**If user provided epic number**:\n```bash\n# User ran: /bmad:epic 3\n```\n- Epic number = 3\n- Store epic_identifier = \"3\"\n\n**If user provided epic name**:\n```bash\n# User ran: /bmad:epic \"Mobile App\"\n```\n- Epic name = \"Mobile App\"\n- Store epic_identifier = \"Mobile App\"\n\n**If user provided nothing**:\n- Ask: \"Which epic would you like to generate?\n  - Provide epic number (e.g., 1, 2, 3)\n  - Or epic name for NEW epic (e.g., 'Mobile App')\n  - Or 'all' to generate all epics from PRD\"\n- Wait for response\n- Store epic_identifier\n\n### Step 3: Launch Product-Manager Subagent\n\nUse the Task tool to launch the product-manager subagent in its own context window:\n\n```\nTask(\n  description: \"Generate BMAD epic with user stories\",\n  prompt: \"Create comprehensive epic file following BMAD methodology.\n\nEpic to Generate: {{epic_identifier}}\n\nInput:\n- PRD: bmad-backlog/prd/prd.md\n- Architecture: bmad-backlog/architecture/architecture.md (if exists)\n\nOutput:\n- Epic file: bmad-backlog/epics/EPIC-{num:03d}-{slug}.md\n- Updated index: bmad-backlog/STORY-INDEX.md\n\nYour workflow:\n\n1. **Read inputs** to understand context:\n   - Read bmad-backlog/prd/prd.md\n   - Read bmad-backlog/architecture/architecture.md (if exists)\n   - Extract epic definition and user stories\n\n2. **Generate epic** using MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"epic\\\",\n     input_path: \\\"bmad-backlog/prd/prd.md bmad-backlog/architecture/architecture.md {{epic_identifier}}\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n3. **Review and present** epic summary:\n   - Read generated epic file\n   - Present title, priority, story count, story points\n   - Show story list\n   - Note if technical notes included/minimal\n\n4. **Validate epic** using:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \\\"epic\\\",\n     document_path: \\\"bmad-backlog/epics/EPIC-{num}-{name}.md\\\"\n   )\n   ```\n\n5. **Update story index**:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"index\\\",\n     input_path: \\\"bmad-backlog/epics/\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n6. **Run vibe-check** to validate epic quality\n\n7. **Store in Pieces** for future reference\n\n8. **Present summary** with next steps:\n   - If more epics in PRD: offer to generate next\n   - If this was last epic: show completion status\n   - If new epic not in PRD: suggest updating PRD\n\n**IMPORTANT**: Keep your summary response VERY BRIEF (under 200 tokens). Just return:\n- Confirmation epic is complete\n- Epic title and number\n- Story count\n- Story points total\n\nDO NOT include the full epic content in your response - it's already saved to the file.\n\nFollow your complete epic workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nThe product-manager subagent will handle:\n- Reading PRD and Architecture\n- Generating epic file (300-500 lines)\n- Presenting epic summary\n- Validation (structural and vibe-check)\n- Updating story index\n- Pieces storage\n- Summary presentation with next steps\n\n### Step 4: Return Results\n\nThe product-manager will return a summary when complete. Present this to the user.\n\n## What the Product-Manager Creates\n\nThe product-manager subagent generates `bmad-backlog/epics/EPIC-{num:03d}-{slug}.md` containing:\n\n- **Epic Header**: Owner, Priority, Sprint, Status, Effort\n- **Epic Description**: What and why\n- **Business Value**: Why this epic matters\n- **Success Criteria**: Checkboxes for completion\n- **User Stories**: STORY-{epic}-{num} format\n  - Each with \"As a... I want... so that...\"\n  - Acceptance criteria (checkboxes)\n  - Technical notes (code examples from architecture)\n- **Dependencies**: Blocks/blocked by relationships\n- **Risks & Mitigation**: Potential issues and solutions\n- **Related Epics**: Cross-references\n- **Definition of Done**: Completion checklist\n\nAlso updates `bmad-backlog/STORY-INDEX.md` with new epic totals.\n\n## Epic Numbering\n\n**If adding new epic**:\n- Determines next epic number by counting existing epics\n- New epic becomes EPIC-{next_num}-{slug}.md\n\n**If regenerating**:\n- Uses existing epic number\n- Overwrites file\n- Preserves filename\n\n## Integration\n\n**Standalone**:\n```\n/bmad:epic 1\n/bmad:epic 2\n/bmad:epic 3\n```\n\n**Part of `/bmad:start`**:\n- Guided workflow generates all epics automatically\n- Loops through epic list from PRD\n- Generates each sequentially\n\n**After Initial Backlog**:\n```\n# 6 months later, need new feature\n/bmad:epic \"Mobile App\"\n# ‚Üí Adds EPIC-012\n# ‚Üí Updates index\n# ‚Üí Ready to implement\n```\n\n## Voice Feedback\n\nVoice announces:\n- \"Generating epic\" (when starting)\n- \"Epic {{num}} complete: {{story count}} stories\" (when done)\n\n## Cost\n\nTypical cost: ~$0.01 per epic (Claude Haiku 4.5 API usage in bmad_generator tool)\n\n---\n\n**This command delegates to the product-manager subagent who creates complete epic files with user stories!**"
              },
              {
                "name": "/bmad-index",
                "description": "Generate BMAD story index summary",
                "path": "plugins/titanium-toolkit/commands/bmad-index.md",
                "frontmatter": {
                  "description": "Generate BMAD story index summary"
                },
                "content": "# BMAD Index - Generate Story Index\n\nUse the product-manager subagent to generate a STORY-INDEX.md file that summarizes all epics and user stories in the backlog. This provides a quick overview for sprint planning and progress tracking.\n\n## Purpose\n\nCreate a summary table showing:\n- Total epics, stories, and story points\n- Epic overview with story counts\n- Per-epic story details\n- Priority distribution\n- Development phases\n\n## When to Use\n\n- After `/bmad:start` completes (auto-generated)\n- After adding new epic with `/bmad:epic`\n- After manually editing epic files\n- Want refreshed totals and summaries\n- Planning sprints\n\n## Task Delegation\n\nFirst check that epics exist, then launch the product-manager subagent to handle the complete index generation workflow.\n\n## Process\n\n### Step 1: Check for Epics\n\n```bash\nls bmad-backlog/epics/EPIC-*.md 2>/dev/null || echo \"No epics found\"\n```\n\n**If no epics found**:\n```\n‚ùå No epic files found\n\nStory index requires epic files to summarize.\n\nPlease generate epics first:\n- Run: /bmad:epic 1\n- Or: /bmad:start (complete workflow)\n```\n\nStop here - do not launch product-manager without epic files.\n\n**If epics found**: Continue to Step 2.\n\n### Step 2: Launch Product-Manager Subagent\n\nUse the Task tool to launch the product-manager subagent in its own context window:\n\n```\nTask(\n  description: \"Generate BMAD story index\",\n  prompt: \"Create comprehensive story index summarizing all epics and user stories.\n\nInput:\n- Epic files: bmad-backlog/epics/EPIC-*.md\n\nOutput:\n- Story index: bmad-backlog/STORY-INDEX.md\n\nYour workflow:\n\n1. **Generate story index** using MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"index\\\",\n     input_path: \\\"bmad-backlog/epics/\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n2. **Review generated index**:\n   - Read bmad-backlog/STORY-INDEX.md\n   - Extract totals (epics, stories, story points)\n   - Extract epic breakdown\n   - Extract priority distribution\n\n3. **Present summary** with key metrics:\n   - Total epics, stories, story points\n   - Epic breakdown with story counts per epic\n   - Priority distribution (P0/P1/P2 percentages)\n   - Show sample from index (epic overview table)\n\n4. **Run vibe-check** to validate index quality\n\n5. **Store in Pieces** for future reference:\n   - Include index file\n   - Include all epic files\n   - Summarize totals and breakdown\n\n6. **Suggest next steps**:\n   - Sprint planning guidance\n   - Implementation readiness\n   - Progress tracking tips\n\nFollow your complete index workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nThe product-manager subagent will handle:\n- Scanning all epic files\n- Generating story index\n- Extracting and presenting totals\n- Validation (vibe-check)\n- Pieces storage\n- Summary presentation with next steps\n\n### Step 3: Return Results\n\nThe product-manager will return a summary when complete. Present this to the user.\n\n## What the Product-Manager Creates\n\nThe product-manager subagent generates `bmad-backlog/STORY-INDEX.md` containing:\n\n- **Summary Statistics**: Total epics, stories, story points\n- **Epic Overview Table**: Epic ID, name, story count, points, status\n- **Per-Epic Story Details**: All stories with IDs, titles, priorities\n- **Priority Distribution**: P0/P1/P2 breakdown with percentages\n- **Development Phases**: Logical grouping of epics\n- **Quick Reference**: Key metrics for sprint planning\n\n## Error Handling\n\n### If No Epics Found\n\nHandled in Step 1 - command exits gracefully with helpful message.\n\n### If Epic Files Malformed\n\nThe product-manager subagent will:\n- Report which files couldn't be parsed\n- Generate index from parseable epics only\n- Offer to help fix malformed files\n\n## Voice Feedback\n\nVoice announces:\n- \"Generating story index\" (when starting)\n- \"Story index complete: {{N}} epics, {{M}} stories\" (when done)\n\n## Example Usage\n\n**Example 1: After Epic Generation**\n```\nUser: /bmad:epic 1\n[Epic 1 generated]\nUser: /bmad:epic 2\n[Epic 2 generated]\nUser: /bmad:index\n\nProduct-Manager:\n- Scans epics/\n- Finds 2 epics\n- Counts stories\n- Generates index\n- \"Index complete: 2 epics, 18 stories, 75 story points\"\n```\n\n**Example 2: After Manual Edits**\n```\nUser: [Edits EPIC-003.md, adds more stories]\nUser: /bmad:index\n\nProduct-Manager:\n- Rescans all epics\n- Updates totals\n- \"Index updated: 5 epics, 52 stories (was 45), 210 points (was 180)\"\n```\n\n**Example 3: Sprint Planning**\n```\nUser: /bmad:index\n\nProduct-Manager:\n- Generates index\n- \"Total: 148 stories, 634 points\"\n- \"P0 stories: 98 (65%)\"\n```\n\n## Integration\n\n**Auto-generated by**:\n- `/bmad:start` (after all epics created)\n- `/bmad:epic` (after each epic)\n\n**Manually run**:\n- After editing epic files\n- Before sprint planning\n- To refresh totals\n\n**Used by**:\n- Project managers for planning\n- Developers for understanding scope\n- Stakeholders for status updates\n\n## Cost\n\nTypical cost: ~$0.01 (minimal - just parsing and formatting, using Claude Haiku 4.5)\n\n---\n\n**This command delegates to the product-manager subagent who creates the 30,000-foot view of your entire backlog!**"
              },
              {
                "name": "/bmad-prd",
                "description": "Generate BMAD Product Requirements Document",
                "path": "plugins/titanium-toolkit/commands/bmad-prd.md",
                "frontmatter": {
                  "description": "Generate BMAD Product Requirements Document"
                },
                "content": "# BMAD PRD - Generate Product Requirements Document\n\nUse the product-manager subagent to create a comprehensive Product Requirements Document (PRD) following BMAD methodology.\n\n## Task Delegation\n\nFirst check for product brief, then launch the product-manager subagent to handle the complete PRD generation workflow.\n\n## Process\n\n### Step 1: Check for Product Brief\n\n```bash\nls bmad-backlog/product-brief.md 2>/dev/null || echo \"No brief found\"\n```\n\n**If brief NOT found**:\n```\n‚ùå Error: Product Brief not found at bmad-backlog/product-brief.md\n\nPRD generation requires a product brief to work from.\n\nPlease run: /titanium-toolkit:bmad-brief first\n(Or /titanium-toolkit:bmad-start for complete guided workflow)\n```\n\nStop here - do not launch product-manager without brief.\n\n**If brief exists**: Continue to Step 2.\n\n### Step 2: Launch Product-Manager Subagent\n\nUse the Task tool to launch the product-manager subagent in its own context window:\n\n```\nTask(\n  description: \"Generate BMAD PRD\",\n  prompt: \"Create comprehensive Product Requirements Document following BMAD methodology.\n\nInput:\n- Product Brief: bmad-backlog/product-brief.md\n\nOutput:\n- PRD: bmad-backlog/prd/prd.md\n\nYour workflow:\n\n1. **Read the product brief** to understand the project vision\n\n2. **Generate PRD** using the MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"prd\\\",\n     input_path: \\\"bmad-backlog/product-brief.md\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n3. **Review epic structure** - Ensure Epic 1 is \\\"Foundation\\\" and epic sequence is logical\n\n4. **Detect research needs** - Scan for API, vendor, data source, payment, hosting keywords\n\n5. **Validate PRD** using:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \\\"prd\\\",\n     document_path: \\\"bmad-backlog/prd/prd.md\\\"\n   )\n   ```\n\n6. **Run vibe-check** to validate PRD quality and completeness\n\n7. **Store in Pieces** for future reference\n\n8. **Present summary** with epic list, research needs, and next steps\n\n**IMPORTANT**: Keep your summary response BRIEF (under 500 tokens). Just return:\n- Confirmation PRD is complete\n- Epic count and list (just titles)\n- Total user stories count\n- Total features count\n\nDO NOT include the full PRD content in your response - it's already saved to the file.\n\nFollow your complete PRD workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nThe product-manager subagent will handle:\n- Reading product brief\n- Generating comprehensive PRD (500-1000 lines)\n- Epic structure review\n- Research needs detection\n- Validation (structural and vibe-check)\n- Pieces storage\n- Summary presentation\n\n### Step 3: Return Results\n\nThe product-manager will return a summary when complete. Present this to the user.\n\n## What the Product-Manager Creates\n\nThe product-manager subagent generates `bmad-backlog/prd/prd.md` containing:\n\n**Sections generated**:\n1. Executive Summary (Vision, Mission)\n2. Product Overview (Users, Value Props, Competitive Positioning)\n3. Success Metrics (North Star, KPIs)\n4. Feature Requirements (V1 MVP, V2 Features with acceptance criteria)\n5. User Stories (organized by Epic)\n6. Technical Requirements (Performance, Scalability, Security, etc.)\n7. Data Requirements (if applicable)\n8. AI/ML Requirements (if applicable)\n9. Design Requirements\n10. Go-to-Market Strategy\n11. Risks & Mitigation (tables)\n12. Open Questions\n13. Appendix (Glossary, References)\n\n### Step 3: Review Generated PRD\n\nRead the PRD:\n\n```bash\nRead bmad-backlog/prd/prd.md\n```\n\n**Key sections to review with user**:\n\n1. **Epic List** (from User Stories section):\n   ```\n   Epic Structure:\n   - Epic 1: {{name}} ({{story count}} stories)\n   - Epic 2: {{name}} ({{story count}} stories)\n   - Epic 3: {{name}} ({{story count}} stories)\n   ...\n\n   Total: {{N}} epics, {{M}} stories\n\n   Is this epic breakdown logical and complete?\n   ```\n\n2. **Feature Requirements**:\n   ```\n   V1 MVP Features: {{count}}\n   V2 Features: {{count}}\n\n   Are priorities correct (P0, P1, P2)?\n   ```\n\n3. **Technical Requirements**:\n   ```\n   Performance: {{targets}}\n   Security: {{requirements}}\n   Tech Stack Preferences: {{from brief or inferred}}\n\n   Any adjustments needed?\n   ```\n\n### Step 4: Detect Research Needs\n\nScan PRD for research keywords:\n- \"API\", \"vendor\", \"data source\", \"integration\"\n- \"payment\", \"authentication provider\"\n- \"hosting\", \"infrastructure\"\n\n**If research needs detected**:\n```\n‚ö†Ô∏è  I detected you'll need research on:\n- {{Research topic 1}} (e.g., \"data vendors for pricing\")\n- {{Research topic 2}} (e.g., \"authentication providers\")\n- {{Research topic 3}} (e.g., \"hosting platforms\")\n\nWould you like me to generate research prompts for these?\n\nResearch prompts help you:\n- Use ChatGPT/Claude web (they have web search!)\n- Get current pricing and comparisons\n- Make informed architecture decisions\n\nGenerate research prompts? (yes/no/specific topics)\n```\n\n**If user says yes**:\n- For each research topic, run `/bmad:research \"{{topic}}\"`\n- Wait for user to complete research\n- Note that architecture generation will use research findings\n\n**If user says no**:\n- Continue without research\n- Architecture will make best guesses\n\n### Step 5: Refine PRD (if needed)\n\n**If user wants changes**:\n- Identify specific sections to refine\n- Can regenerate entire PRD with additional context\n- Or user can manually edit the file\n\n**To regenerate**:\n```\n# Add context to brief or provide directly\nmcp__plugin_titanium-toolkit_tt__bmad_generator(\n  doc_type: \"prd\",\n  input_path: \"bmad-backlog/product-brief.md\",\n  project_path: \"$(pwd)\"\n)\n```\n\n### Step 6: Validate PRD Structure\n\nUse the `bmad_validator` MCP tool to check completeness:\n\n```\nmcp__plugin_titanium-toolkit_tt__bmad_validator(\n  doc_type: \"prd\",\n  document_path: \"bmad-backlog/prd/prd.md\"\n)\n```\n\n**Check results**:\n- If valid ‚Üí Continue\n- If missing sections ‚Üí Alert user, regenerate\n\n### Step 7: Validate with vibe-check\n\n```\nmcp__vibe-check__vibe_check(\n  goal: \"Create comprehensive PRD for {{project}}\",\n  plan: \"Generated PRD with {{N}} epics, {{M}} features, technical requirements, user stories\",\n  uncertainties: [\n    \"Is epic structure logical and sequential?\",\n    \"Are requirements complete?\",\n    \"Any missing critical features?\"\n  ]\n)\n```\n\n**Process feedback**:\n- Review vibe-check suggestions\n- Make adjustments if needed\n- Regenerate if significant concerns\n\n### Step 8: Store in Pieces\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Product Requirements Document for {{project}}\",\n  summary: \"Complete PRD generated with {{N}} sections. Epics: {{list epics}}. Key features: {{list main features}}. Technical requirements: {{summary}}. User stories: {{count}} across {{epic count}} epics. Ready for architecture generation.\",\n  files: [\n    \"bmad-backlog/product-brief.md\",\n    \"bmad-backlog/prd/prd.md\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n### Step 9: Present Summary\n\n```\n‚úÖ Product Requirements Document Complete!\n\nüìÑ Location: bmad-backlog/prd/prd.md\n\nüìä PRD Summary:\n- {{N}} Epics defined\n- {{M}} User stories\n- {{F}} V1 MVP features\n- Technical requirements specified\n- Success metrics defined\n\nEpic Structure:\n1. Epic 1: {{name}} (Foundation - this is always first)\n2. Epic 2: {{name}}\n3. Epic 3: {{name}}\n...\n\nüìè Document Size: ~{{line count}} lines\n\n‚úÖ vibe-check validated structure\n\n---\n\nüí° Next Steps:\n\nOption 1: Generate Architecture (Recommended)\nRun: /bmad:architecture\n\nOption 2: Review PRD first\nOpen: bmad-backlog/prd/prd.md\n(Review and come back when ready)\n\nOption 3: Generate complete backlog\nRun: /bmad:start\n(Will use this PRD to generate Architecture and all Epics)\n\nWhat would you like to do?\n```\n\n## Important Guidelines\n\n**Always**:\n- ‚úÖ Check for product brief first\n- ‚úÖ Use `bmad_generator` MCP tool (don't generate manually)\n- ‚úÖ Detect research needs from requirements\n- ‚úÖ Validate with `bmad_validator` MCP tool\n- ‚úÖ Validate with vibe-check\n- ‚úÖ Store in Pieces\n- ‚úÖ Present epic structure clearly\n- ‚úÖ Suggest next steps\n\n**Never**:\n- ‚ùå Generate PRD content manually\n- ‚ùå Skip validation steps\n- ‚ùå Ignore vibe-check concerns\n- ‚ùå Forget to check epic structure (Epic 1 must be Foundation)\n- ‚ùå Miss research opportunities\n\n## Epic List Quality Check\n\n**Verify Epic 1 is Foundation**:\n```\nEpic 1 should be: \"Foundation\", \"Infrastructure\", \"Core Setup\", or similar\nEpic 1 should NOT be: Feature-specific like \"User Profiles\" or \"Dashboard\"\n\nIf Epic 1 is not foundation:\n- Alert user\n- Suggest reordering\n- Regenerate with correct sequence\n```\n\n## Integration with Workflow\n\n**Standalone Usage**:\n```\n/bmad:brief\n/bmad:prd        ‚Üê You are here\n/bmad:architecture\n```\n\n**Part of `/bmad:start`**:\n- Guided workflow generates brief first\n- Then calls PRD generation\n- Uses brief automatically\n- Continues to architecture\n\n**Cost**: ~$0.03 (Claude Haiku 4.5 for PRD generation)\n\n---\n\n**This command creates the complete product specification that drives architecture and implementation!**"
              },
              {
                "name": "/bmad-research",
                "description": "Generate research prompts for technical decisions",
                "path": "plugins/titanium-toolkit/commands/bmad-research.md",
                "frontmatter": {
                  "description": "Generate research prompts for technical decisions"
                },
                "content": "# BMAD Research - Generate Research Prompts\n\nYou are helping the user research technical decisions by generating comprehensive research prompts for web-based AI (ChatGPT, Claude web) which have web search capabilities.\n\n## Purpose\n\nGenerate structured research prompts that users can copy to ChatGPT/Claude web to research:\n- API vendors and data sources\n- Authentication providers\n- Hosting platforms\n- Payment processors\n- Third-party integrations\n- Technology stack options\n\nResults are documented in structured templates and referenced during architecture generation.\n\n## When to Use\n\n**During BMAD workflow**:\n- After PRD mentions external APIs/vendors\n- Before architecture generation\n- When technical decisions need research\n\n**Standalone**:\n- Evaluating vendor options\n- Comparing technologies\n- Cost analysis\n- Technical due diligence\n\n## Process\n\n### Step 1: Identify Research Topic\n\n**If user provided topic**:\n```bash\n# User ran: /bmad:research \"data vendors for precious metals\"\n```\n- Topic = \"data vendors for precious metals\"\n\n**If no topic**:\n- Ask: \"What do you need to research?\"\n- Show common topics:\n  ```\n  Common research topics:\n  1. Data vendors/APIs\n  2. Hosting platforms (Railway, Vercel, GCP, etc.)\n  3. Authentication providers (Clerk, Auth0, custom, etc.)\n  4. Payment processors (Stripe, PayPal, etc.)\n  5. AI/ML options (OpenAI, Anthropic, self-hosted)\n  6. Database options\n  7. Other (specify)\n\n  Topic:\n  ```\n\n### Step 2: Gather Context from PRD\n\n**If PRD exists**:\n```bash\nRead bmad-backlog/prd/prd.md\n```\n\nExtract relevant context:\n- What features need this research?\n- What are the constraints? (budget, performance)\n- Any technical preferences mentioned?\n\n**If no PRD**:\n- Use topic only\n- Generate generic research prompt\n- Note: \"Research will be more focused with a PRD\"\n\n### Step 3: Generate Research Prompt\n\nCreate comprehensive prompt for web AI.\n\n**Topic slug**: Convert topic to filename-safe string\n```python\ntopic_slug = topic.lower().replace(' ', '-').replace('/', '-')\n# \"data vendors for precious metals\" ‚Üí \"data-vendors-for-precious-metals\"\n```\n\n**Save to**: `bmad-backlog/research/RESEARCH-{topic_slug}-prompt.md`\n\n**Prompt content**:\n```markdown\n# Research Prompt: {Topic}\n\n**COPY THIS ENTIRE PROMPT** and paste into ChatGPT (GPT-4) or Claude (web).\nThey have web search and can provide current, comprehensive research.\n\n---\n\n## Research Request\n\n**Project**: {{project name from PRD or \"New Project\"}}\n\n**Research Topic**: {{topic}}\n\n**Context**:\n{{Extract from PRD:\n- What features need this\n- Performance requirements\n- Budget constraints\n- Technical preferences}}\n\n---\n\n## What I Need\n\nPlease research and provide:\n\n### 1. Overview\n- What options exist for {{topic}}?\n- What are the top 5-7 solutions/vendors/APIs?\n- Current market leaders?\n\n### 2. Comparison Table\n\nCreate a detailed comparison table:\n\n| Option | Pricing | Key Features | Pros | Cons | Best For |\n|--------|---------|--------------|------|------|----------|\n| Option 1 | | | | | |\n| Option 2 | | | | | |\n| Option 3 | | | | | |\n\n### 3. Technical Details\n\nFor each option, provide:\n- **API Documentation**: Official docs link\n- **Authentication**: API key, OAuth, etc.\n- **Rate Limits**: Requests per minute/hour\n- **Data Format**: JSON, XML, GraphQL, etc.\n- **SDKs**: Python, Node.js, etc. with links\n- **Code Examples**: If available\n- **Community**: GitHub stars, Stack Overflow activity\n\n### 4. Integration Complexity\n\nFor each option:\n- **Estimated Setup Time**: Hours/days\n- **Dependencies**: What else is needed\n- **Learning Curve**: Easy/Medium/Hard\n- **Documentation Quality**: Excellent/Good/Poor\n- **Community Support**: Active/Moderate/Limited\n\n### 5. Recommendations\n\nBased on my project requirements:\n{{List key requirements}}\n\nWhich option would you recommend and why?\n\nProvide recommendation for:\n- **MVP**: Best for getting started quickly\n- **Production**: Best for long-term reliability\n- **Budget**: Most cost-effective option\n\n### 6. Cost Analysis\n\nFor each option, provide:\n\n**Free Tier**:\n- What's included\n- Limitations\n- Good for MVP? (yes/no)\n\n**Paid Tiers**:\n- Tier names and pricing\n- What each tier includes\n- Rate limit increases\n\n**Estimated Monthly Cost**:\n- MVP (low volume): $X-Y\n- Production (medium volume): $X-Y\n- Scale (high volume): $X-Y\n\n### 7. Risks & Considerations\n\nFor each option:\n- **Vendor Lock-in**: How easy to migrate away?\n- **Data Quality**: Accuracy, freshness, reliability\n- **Compliance**: Regional restrictions, data governance\n- **Uptime/SLA**: Published SLAs, historical uptime\n- **Support**: Response times, support channels\n\n### 8. Source Links\n\nProvide links to:\n- Official website\n- Pricing page\n- API documentation\n- Getting started guide\n- Community forums/Discord\n- Comparison articles/reviews\n- GitHub repositories (if applicable)\n\n---\n\n## Deliverable Format\n\nPlease structure your response to match the sections above for easy copy/paste into my findings template.\n\nThank you!\n```\n\n**Write this to file**: bmad-backlog/research/RESEARCH-{topic_slug}-prompt.md\n\n### Step 4: Generate Findings Template\n\nCreate structured template for documenting research.\n\n**Save to**: `bmad-backlog/research/RESEARCH-{topic_slug}-findings.md`\n\n**Template content**:\n```markdown\n# Research Findings: {Topic}\n\n**Date**: {current date}\n**Researcher**: {user name or TBD}\n**Status**: Draft\n\n---\n\n## Research Summary\n\n**Question**: {what was researched}\n\n**Recommendation**: {chosen option and why}\n\n**Confidence**: High | Medium | Low\n\n---\n\n## Options Evaluated\n\n### Option 1: {Name}\n\n**Overview**:\n\n**Pricing**:\n- Free tier:\n- Paid tiers:\n- Estimated cost for MVP: $X/month\n- Estimated cost for Production: $Y/month\n\n**Features**:\n-\n-\n\n**Pros**:\n-\n-\n\n**Cons**:\n-\n-\n\n**Technical Details**:\n- API: REST | GraphQL | WebSocket\n- Authentication:\n- Rate limits:\n- Data format:\n- SDKs:\n\n**Documentation**: {link}\n\n**Community**: {GitHub stars, activity}\n\n---\n\n### Option 2: {Name}\n\n[Same structure]\n\n---\n\n### Option 3: {Name}\n\n[Same structure]\n\n---\n\n## Comparison Matrix\n\n| Criteria | Option 1 | Option 2 | Option 3 | Winner |\n|----------|----------|----------|----------|--------|\n| Cost (MVP) | $X/mo | $Y/mo | $Z/mo | |\n| Features | X | Y | Z | |\n| API Quality | {rating} | {rating} | {rating} | |\n| Documentation | {rating} | {rating} | {rating} | |\n| Community | {rating} | {rating} | {rating} | |\n| Ease of Use | {rating} | {rating} | {rating} | |\n| **Overall** | | | | **{Winner}** |\n\n---\n\n## Recommendation\n\n**Chosen**: {Option X}\n\n**Rationale**:\n1. {Reason 1}\n2. {Reason 2}\n3. {Reason 3}\n\n**For MVP**: {Why this is good for MVP}\n\n**For Production**: {Scalability considerations}\n\n**Implementation Priority**: {When to implement - MVP/Phase 2/etc}\n\n---\n\n## Implementation Notes\n\n**Setup Steps**:\n1. {Step 1}\n2. {Step 2}\n3. {Step 3}\n\n**Configuration**:\n```\n{Config example or .env variables needed}\n```\n\n**Code Example**:\n```{language}\n{Basic usage example if available}\n```\n\n---\n\n## Cost Projection\n\n**MVP** (low volume):\n- Monthly cost: $X\n- Included: {what's covered}\n\n**Production** (medium volume):\n- Monthly cost: $Y\n- Growth: {how costs scale}\n\n**At Scale** (high volume):\n- Monthly cost: $Z\n- Optimization: {cost reduction strategies}\n\n---\n\n## Risks & Mitigations\n\n| Risk | Impact | Likelihood | Mitigation |\n|------|--------|-----------|------------|\n| {Risk 1} | High/Med/Low | High/Med/Low | {How to mitigate} |\n| {Risk 2} | High/Med/Low | High/Med/Low | {How to mitigate} |\n\n---\n\n## Implementation Checklist\n\n- [ ] Create account/sign up\n- [ ] Obtain API key/credentials\n- [ ] Test in development environment\n- [ ] Review pricing and set cost alerts\n- [ ] Document integration in architecture\n- [ ] Add credentials to .env.example\n- [ ] Test error handling and rate limits\n\n---\n\n## References\n\n- Official Website: {link}\n- Pricing Page: {link}\n- API Docs: {link}\n- Getting Started: {link}\n- Community: {link}\n- Comparison Articles: {links}\n\n---\n\n## Next Steps\n\n1. ‚úÖ Research complete\n2. Review findings with team (if applicable)\n3. Make final decision on {chosen option}\n4. Update PRD Technical Assumptions with this research\n5. Reference in Architecture document generation\n\n---\n\n**Status**: ‚úÖ Research Complete | ‚è≥ Awaiting Decision | ‚ùå Needs More Research\n\n---\n\n*Fill in this template with findings from ChatGPT/Claude web research.*\n*Save this file when complete.*\n*Architecture generation will reference this research.*\n```\n\n### Step 5: Present to User\n\n```\nüìã Research Prompt and Template Generated!\n\nI've created two files:\n\nüìÑ 1. Research Prompt\nLocation: bmad-backlog/research/RESEARCH-{{topic}}-prompt.md\n\nThis contains a comprehensive research prompt with your project context.\n\nüìÑ 2. Findings Template\nLocation: bmad-backlog/research/RESEARCH-{{topic}}-findings.md\n\nThis is a structured template for documenting research results.\n\n---\n\nüîç Next Steps:\n\n1. Open: bmad-backlog/research/RESEARCH-{{topic}}-prompt.md\n\n2. **Copy the entire prompt**\n\n3. Open ChatGPT (https://chat.openai.com) or Claude (https://claude.ai)\n   ‚Üí They have web search for current info!\n\n4. Paste the prompt\n\n5. Wait for comprehensive research (5-10 minutes)\n\n6. Copy findings into template:\n   bmad-backlog/research/RESEARCH-{{topic}}-findings.md\n\n7. Save the template file\n\n8. Come back and run:\n   - /bmad:prd (if updating PRD)\n   - /bmad:architecture (I'll use your research!)\n\n---\n\nWould you like me to show you the research prompt now?\n```\n\n**If user says yes**:\n- Display the prompt file content\n- User can copy directly\n\n**If user says no**:\n- \"The files are ready when you need them!\"\n\n### Step 6: Store in Pieces\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Research prompt for {{topic}}\",\n  summary: \"Generated research prompt for {{topic}}. User will research: {{what to evaluate}}. Purpose: {{why needed for project}}. Findings will inform: {{PRD technical assumptions / Architecture tech stack decisions}}. Template provided for structured documentation.\",\n  files: [\n    \"bmad-backlog/research/RESEARCH-{{topic}}-prompt.md\",\n    \"bmad-backlog/research/RESEARCH-{{topic}}-findings.md\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n## Integration with Other Commands\n\n### Called from `/bmad:prd`\n\nWhen PRD generation detects research needs:\n```\nClaude: \"I see you need data vendors. Generate research prompt?\"\nUser: \"yes\"\n\n[Runs /bmad:research \"data vendors\"]\n\nClaude: \"Research prompt generated. Please complete research and return when done.\"\n\n[User researches, fills template]\n\nUser: \"Research complete\"\n\nClaude: \"Great! Continuing PRD with your findings...\"\n[Reads RESEARCH-data-vendors-findings.md]\n[Incorporates into PRD Technical Assumptions]\n```\n\n### Used by `/bmad:architecture`\n\nArchitecture generation automatically checks for research:\n```bash\nls bmad-backlog/research/RESEARCH-*-findings.md\n```\n\nIf found:\n- Read all findings\n- Use recommendations in tech stack\n- Reference research in Technology Decisions table\n- Include costs from research in cost estimates\n\n## Voice Feedback\n\nVoice announces:\n- \"Research prompt generated\" (when done)\n- \"Ready for external research\" (reminder)\n\n## Example Topics\n\n**Data & APIs**:\n- \"data vendors for {domain}\"\n- \"API marketplaces\"\n- \"real-time data feeds\"\n\n**Infrastructure**:\n- \"hosting platforms for {tech stack}\"\n- \"CI/CD providers\"\n- \"monitoring solutions\"\n- \"CDN providers\"\n\n**Third-Party Services**:\n- \"authentication providers\"\n- \"payment processors\"\n- \"email services\"\n- \"SMS providers\"\n\n**AI/ML**:\n- \"LLM hosting options\"\n- \"embedding models\"\n- \"vector databases\"\n\n## Important Guidelines\n\n**Always**:\n- ‚úÖ Include project context in prompt\n- ‚úÖ Generate findings template\n- ‚úÖ Guide user to web AI\n- ‚úÖ Store prompts in Pieces\n- ‚úÖ Explain next steps clearly\n\n**Never**:\n- ‚ùå Try to research in Claude Code (limited web search)\n- ‚ùå Hallucinate vendor pricing (use web AI)\n- ‚ùå Skip generating findings template\n- ‚ùå Forget project context in prompt\n\n## Why This Approach\n\n**Claude Code limitations**:\n- Limited web search\n- Can't browse vendor pricing pages\n- May hallucinate current details\n\n**ChatGPT/Claude Web strengths**:\n- Actual web search\n- Can browse documentation\n- Current pricing information\n- Community discussions\n- Up-to-date comparisons\n\n**Best of both worlds**:\n- Claude Code: Generate prompts, manage workflow\n- Web AI: Thorough research with search\n- Result: Informed decisions, documented rationale\n\n**Cost**: $0 (no API calls, just template generation)\n\n---\n\n**This command enables informed technical decisions with documented research!**"
              },
              {
                "name": "/bmad-start",
                "description": "Complete guided BMAD backlog generation workflow",
                "path": "plugins/titanium-toolkit/commands/bmad-start.md",
                "frontmatter": {
                  "description": "Complete guided BMAD backlog generation workflow"
                },
                "content": "# BMAD Start - Complete Guided Workflow\n\nYou are orchestrating complete BMAD backlog generation from idea to implementation-ready documentation. This guided workflow creates Product Brief, PRD, Architecture, all Epic files, and Story Index in one comprehensive session.\n\n**MCP Tools Used**: This command uses the `tt` MCP server (Titanium Toolkit) which provides:\n- `mcp__plugin_titanium-toolkit_tt__bmad_generator` - Generates BMAD documents (brief, PRD, architecture, epics, index)\n- `mcp__plugin_titanium-toolkit_tt__bmad_validator` - Validates BMAD document structure and completeness\n\nThe `tt` server wraps Python utilities that use Claude AI to generate comprehensive project documentation following the BMAD methodology.\n\n## Purpose\n\nTake user from empty folder to complete project backlog (30-45 minutes):\n- Product Brief (high-level vision)\n- PRD (comprehensive requirements with epics and user stories)\n- Architecture (technical design with code examples)\n- Epic files (all epics with detailed stories and acceptance criteria)\n- Story Index (summary of all stories)\n\n## Overview\n\n**This workflow has 6 phases**:\n1. **Introduction** - Welcome and mode selection\n2. **Product Brief** - Capture high-level vision\n3. **PRD** - Comprehensive requirements\n4. **Research** - Technical research (if needed)\n5. **Architecture** - Technical design\n6. **Epics & Index** - All epic files and summary\n\n**Duration**: 30-45 minutes\n**Cost**: ~$0.15 (Claude Haiku 4.5 + Sonnet 4.5 for all documents)\n**Output**: Complete bmad-backlog/ folder\n\n---\n\n## Phase 1: Introduction & Setup\n\n### Step 1.1: Welcome User\n\n```\nüöÄ BMAD Document Generation - Complete Guided Workflow\n\nWelcome to the BMAD backlog creation process!\n\nThis workflow will create complete project documentation:\n‚úÖ Product Brief - High-level vision and goals\n‚úÖ PRD - Comprehensive requirements with epics\n‚úÖ Architecture - Technical design with code examples\n‚úÖ Epic Files - Detailed user stories with acceptance criteria\n‚úÖ Story Index - Summary of all stories for sprint planning\n\n‚è±Ô∏è  Duration: 30-45 minutes\nüí∞ Cost: ~$0.15 (Claude for document generation)\nüìÅ Output: bmad-backlog/ folder with all documentation\n\nReady to start? (yes/no)\n```\n\nIf no ‚Üí Exit\nIf yes ‚Üí Continue\n\n### Step 1.2: Check for Existing Documentation\n\n```bash\nls -la bmad-backlog/ 2>/dev/null || echo \"No backlog found\"\n```\n\n**If bmad-backlog/ exists**:\n```\n‚ö†Ô∏è  Found existing BMAD documentation!\n\nbmad-backlog/ folder exists with:\n{{List existing files}}\n\nOptions:\n1. **Start fresh** - Delete existing and create new (DESTRUCTIVE)\n2. **Add to existing** - Generate new epics only\n3. **Cancel** - Review existing docs first\n\nWhat would you like to do?\n```\n\n**If option 1 chosen**:\n```\nüõë DESTRUCTIVE ACTION WARNING\n\nThis will permanently DELETE the entire bmad-backlog/ folder including:\n- Product Brief\n- PRD\n- Architecture\n- All Epic files\n- Story Index\n- Research findings\n\nThis CANNOT be undone.\n\nTo confirm deletion, type exactly: DELETE\n\nType DELETE to confirm, or anything else to cancel:\n```\n\nWait for user input.\n\n**If user types exactly \"DELETE\"** (case-sensitive):\n```bash\nrm -rf bmad-backlog/\n```\n- Announce: \"bmad-backlog/ deleted. Starting fresh...\"\n- Continue to Step 1.3\n\n**If user types anything else**:\n```\n‚ùå Deletion cancelled. Existing backlog preserved.\n\nReturning to options menu...\n```\n- Go back to showing the 3 options\n- Wait for user to choose option 2 or 3\n\n**If option 2**: Skip to Phase 6 (epic generation)\n**If option 3**: Exit gracefully\n\n**If no bmad-backlog/**:\n- Continue to Step 1.3\n\n### Step 1.3: Choose Mode\n\n```\nChoose your workflow mode:\n\n1. **Interactive** (Recommended)\n   - I'll ask questions section by section\n   - You review and refine as we go\n   - Higher quality, more control\n   - ~45 minutes\n\n2. **YOLO** (Faster)\n   - I'll generate complete drafts from your idea\n   - You refine afterwards\n   - Faster but may need more editing\n   - ~30 minutes\n\nWhich mode? (1 or 2)\n```\n\nStore user's choice for the workflow.\n\n---\n\n## Phase 2: Product Brief Generation\n\n### Step 2.1: Capture High-Level Idea\n\n```\nüéØ Let's start with your project idea.\n\nDescribe your project at a high level:\n- What is it?\n- Who is it for?\n- What problem does it solve?\n\nYou can be brief (one sentence) or detailed (a paragraph).\nI'll ask follow-up questions to flesh it out.\n\nYour idea:\n```\n\nWait for user response. Store as user_idea.\n\n### Step 2.2: Interactive Questions (if Interactive mode)\n\nAsk clarifying questions:\n1. \"What problem does this solve for users?\"\n2. \"Who are the primary users (be specific)?\"\n3. \"What makes this different from existing solutions?\"\n4. \"What are the 3-5 core features for MVP?\"\n5. \"What should be out of scope for MVP?\"\n6. \"Any technical preferences (language, framework, hosting)?\"\n7. \"Budget and timeline constraints?\"\n\nAppend answers to user_idea context.\n\n### Step 2.3: Launch Product-Manager Subagent for Brief\n\nUse the Task tool to launch the product-manager subagent:\n\n```\nTask(\n  description: \"Generate BMAD product brief\",\n  prompt: \"Create comprehensive product brief following BMAD methodology.\n\nUser's Project Idea:\n{{user_idea}}\n\nYour workflow:\n\n1. **Generate product brief** using MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"brief\\\",\n     input_path: \\\"{{user_idea}}\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n2. **Review and present** key sections to user:\n   - Executive Summary\n   - Problem Statement\n   - MVP Scope\n   - Ask for approval or refinements\n\n3. **Validate the brief** using:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \\\"brief\\\",\n     document_path: \\\"bmad-backlog/product-brief.md\\\"\n   )\n   ```\n\n4. **Run vibe-check** to validate brief quality\n\n5. **Store in Pieces** for future reference\n\n6. **Present summary** confirming brief is complete\n\n**IMPORTANT**: Keep your summary response BRIEF (under 300 tokens). The orchestrator just needs:\n- Confirmation brief is complete\n- 1-2 sentence project description\n- Primary user segment\n- MVP feature count\n\nDO NOT include the full brief content in your response - it's already saved to the file.\n\nFollow your complete brief workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nThe product-manager subagent will handle brief generation, review, validation, and storage.\n\n### Step 2.4: Confirm Completion\n\nWait for product-manager to return summary. Confirm brief is ready before continuing to PRD.\n\n---\n\n## Phase 3: PRD Generation\n\n### Step 3.1: Launch Product-Manager Subagent for PRD\n\n```\nGenerating comprehensive Product Requirements Document...\n\nThis will take about 1-2 minutes (large document).\n```\n\nUse the Task tool to launch the product-manager subagent:\n\n```\nTask(\n  description: \"Generate BMAD PRD\",\n  prompt: \"Create comprehensive Product Requirements Document following BMAD methodology.\n\nInput:\n- Product Brief: bmad-backlog/product-brief.md\n\nOutput:\n- PRD: bmad-backlog/prd/prd.md\n\nYour workflow:\n\n1. **Read product brief** to understand context\n\n2. **Generate PRD** using MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"prd\\\",\n     input_path: \\\"bmad-backlog/product-brief.md\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n3. **Review epic structure**:\n   - Read generated PRD\n   - Extract epic list\n   - Count epics, user stories, features\n   - Verify Epic 1 is Foundation/Infrastructure\n   - Present structure to user for approval\n\n4. **Validate PRD** using:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \\\"prd\\\",\n     document_path: \\\"bmad-backlog/prd/prd.md\\\"\n   )\n   ```\n\n5. **Run vibe-check** with:\n   - Goal: Create comprehensive PRD\n   - Plan: Generated PRD with N epics, M stories\n   - Uncertainties: Epic structure, requirement completeness, missing features\n\n6. **Store in Pieces** for future reference\n\n7. **Present summary** with epic list and totals\n\n**IMPORTANT**: Keep your summary response BRIEF (under 500 tokens). The orchestrator just needs:\n- Confirmation PRD is complete\n- Epic count and list (just titles)\n- Total user stories count\n- Total features count\n\nDO NOT include the full PRD content in your response - it's already saved to the file.\n\nFollow your complete PRD workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nThe product-manager subagent will handle PRD generation, epic structure review, validation, and storage.\n\n### Step 3.2: Confirm Completion\n\nWait for product-manager to return summary. Confirm PRD is ready and epic structure approved before continuing to research/architecture.\n\n---\n\n## Phase 4: Research (If Needed)\n\n### Step 4.1: Detect Research Needs\n\nScan PRD for keywords:\n- \"API\", \"vendor\", \"data source\"\n- \"payment\", \"authentication\"\n- \"hosting\", \"infrastructure\"\n\n**If research topics detected**:\n```\nüîç Research Opportunities Detected!\n\nYour PRD mentions:\n- {{Topic 1}} (e.g., \"data vendors\")\n- {{Topic 2}} (e.g., \"authentication provider\")\n- {{Topic 3}} (e.g., \"hosting platform\")\n\nThese decisions will impact your architecture.\n\nWould you like research prompts for these? (yes/no/specific topics)\n```\n\n### Step 4.2: Generate Research Prompts\n\n**For each selected topic**:\nRun `/bmad:research \"{{topic}}\"` for each\n\nPresent:\n```\nüìã Research Prompts Generated!\n\nI've created research prompts for:\n1. {{Topic 1}} - bmad-backlog/research/RESEARCH-{{slug}}-prompt.md\n2. {{Topic 2}} - bmad-backlog/research/RESEARCH-{{slug}}-prompt.md\n\nPlease:\n1. Open each prompt file\n2. Copy to ChatGPT/Claude web\n3. Complete research (~10-15 min per topic)\n4. Fill in findings templates\n5. Return here when done\n\nReady to continue after research? (yes/skip)\n```\n\n**If yes**: Wait for confirmation research is complete\n**If skip**: Continue without research\n\n---\n\n## Phase 5: Architecture Generation\n\n### Step 5.1: Launch Architect Subagent\n\n```\nGenerating Technical Architecture...\n\nThis will take 2-3 minutes (comprehensive document with code examples).\n```\n\nUse the Task tool to launch the architect subagent:\n\n```\nTask(\n  description: \"Generate BMAD architecture\",\n  prompt: \"Create comprehensive technical architecture document following BMAD methodology.\n\nInput:\n- PRD: bmad-backlog/prd/prd.md\n- Research findings: bmad-backlog/research/*.md (if any exist)\n\nOutput:\n- Architecture document: bmad-backlog/architecture/architecture.md\n\nYour workflow:\n\n1. **Read PRD** to understand requirements\n\n2. **Check for research findings** and incorporate recommendations if they exist\n\n3. **Generate architecture** using MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"architecture\\\",\n     input_path: \\\"bmad-backlog/prd/prd.md\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n4. **Review tech stack with user**:\n   - Present proposed tech stack\n   - Note research-based decisions if applicable\n   - Get user approval or note requested changes\n\n5. **Validate architecture** using:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \\\"architecture\\\",\n     document_path: \\\"bmad-backlog/architecture/architecture.md\\\"\n   )\n   ```\n\n6. **Run vibe-check** to validate architectural decisions\n\n7. **Store in Pieces** for future reference\n\n8. **Present summary** with tech stack and cost estimates\n\n**IMPORTANT**: Keep your summary response BRIEF (under 500 tokens). The orchestrator just needs:\n- Confirmation architecture is complete\n- Proposed tech stack (2-3 sentences)\n- MVP cost estimate\n- Any critical decisions made\n\nDO NOT include the full architecture content in your response - it's already saved to the file.\n\nFollow your complete architecture workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"architect\"\n)\n```\n\nThe architect subagent will handle architecture generation, tech stack review, validation, and storage.\n\n### Step 5.2: Confirm Completion\n\nWait for architect to return summary. Confirm architecture is ready before continuing to epic generation.\n\n---\n\n## Phase 6: Epic Generation & Index\n\n### Step 6.1: Extract Epic List from PRD\n\nRead PRD and identify all epics from User Stories section.\n\nCount epics:\n```\nFound {{N}} epics in PRD:\n1. {{Epic name}}\n2. {{Epic name}}\n3. {{Epic name}}\n...\n\nGenerating all {{N}} epic files...\n```\n\n### Step 6.2: Generate All Epics (Delegated to Product-Manager)\n\nFor each epic, launch product-manager subagent (sequential):\n\n```\nTask(\n  description: \"Generate BMAD epic {{epic_num}}: {{epic_name}}\",\n  prompt: \"Create comprehensive epic file following BMAD methodology.\n\nEpic to Generate: {{epic_num}}\n\nInput:\n- PRD: bmad-backlog/prd/prd.md\n- Architecture: bmad-backlog/architecture/architecture.md\n\nOutput:\n- Epic file: bmad-backlog/epics/EPIC-{num:03d}-{slug}.md\n\nYour workflow:\n\n1. **Read inputs** to understand context\n\n2. **Generate epic** using MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"epic\\\",\n     input_path: \\\"bmad-backlog/prd/prd.md bmad-backlog/architecture/architecture.md {{epic_num}}\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n3. **Present brief summary**:\n   - Epic title\n   - Story count\n   - Story points\n\n4. **Validate epic** using:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \\\"epic\\\",\n     document_path: \\\"bmad-backlog/epics/EPIC-{num}-{name}.md\\\"\n   )\n   ```\n\n5. **Run vibe-check** to validate epic quality\n\n6. **Store in Pieces** for future reference\n\n7. **Return summary** (brief - we're in batch mode)\n\n**IMPORTANT**: Keep your summary response VERY BRIEF (under 200 tokens). Just return:\n- \"Epic {{num}} complete: {{title}} ({{story_count}} stories)\"\n\nDO NOT include full epic content - it's already saved. We're generating multiple epics so be concise.\n\nFollow your complete epic workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nShow progress after each:\n```\nGenerating epics...\n‚úÖ Epic 1: {{name}} ({{X}} stories)\n‚úÖ Epic 2: {{name}} ({{Y}} stories)\n‚úÖ Epic 3: {{name}} ({{Z}} stories)\n‚è≥ Epic 4: {{name}} (generating...)\n```\n\n### Step 6.3: Generate Story Index (Delegated to Product-Manager)\n\nAfter all epics, launch product-manager subagent for index:\n\n```\nTask(\n  description: \"Generate BMAD story index\",\n  prompt: \"Create comprehensive story index summarizing all epics and user stories.\n\nInput:\n- Epic files: bmad-backlog/epics/EPIC-*.md\n\nOutput:\n- Story index: bmad-backlog/STORY-INDEX.md\n\nYour workflow:\n\n1. **Generate story index** using MCP tool:\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \\\"index\\\",\n     input_path: \\\"bmad-backlog/epics/\\\",\n     project_path: \\\"$(pwd)\\\"\n   )\n   ```\n\n2. **Extract totals**:\n   - Total epics, stories, story points\n   - Epic breakdown\n   - Priority distribution\n\n3. **Run vibe-check** to validate index quality\n\n4. **Store in Pieces** for future reference\n\n5. **Return summary** with totals\n\nFollow your complete index workflow from the bmad-methodology skill.\n\nProject path: $(pwd)\",\n  subagent_type: \"product-manager\"\n)\n```\n\nCreates: `bmad-backlog/STORY-INDEX.md`\n\n---\n\n## Phase 7: Final Review & Summary\n\n### Step 7.1: Confirm All Documents Created\n\nVerify all expected documents exist:\n\n```bash\n# Check core documents\nls bmad-backlog/product-brief.md\nls bmad-backlog/prd/prd.md\nls bmad-backlog/architecture/architecture.md\nls bmad-backlog/STORY-INDEX.md\n\n# Count epic files\nls bmad-backlog/epics/EPIC-*.md | wc -l\n```\n\nNote: Each subagent already validated their documents during generation. This is just a final check that all files were created.\n\n### Step 7.2: Final vibe-check\n\n```\nmcp__vibe-check__vibe_check(\n  goal: \"Create complete BMAD backlog for {{project}}\",\n  plan: \"Generated: Product Brief, PRD ({{N}} epics, {{M}} stories), Architecture ({{tech stack}}), {{N}} Epic files, Story Index\",\n  uncertainties: [\n    \"Is documentation complete and consistent?\",\n    \"Are epics logically sequenced?\",\n    \"Is architecture aligned with requirements?\",\n    \"Any gaps in the backlog?\"\n  ]\n)\n```\n\nPresent vibe-check assessment.\n\n### Step 7.3: Store Complete Backlog in Pieces\n\n**First, build explicit file list** (Pieces doesn't expand wildcards):\n\n```bash\n# Use Glob to find all epic files\nGlob bmad-backlog/epics/EPIC-*.md\n```\n\nStore the results, then build files array.\n\n**If research was completed**:\n```bash\n# Find research files\nGlob bmad-backlog/research/RESEARCH-*.md\n```\n\n**Then call Pieces with explicit paths**:\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Complete BMAD backlog for {{project}}\",\n  summary: \"Generated complete project backlog using BMAD methodology.\n\nDocuments created:\n- Product Brief: {{vision summary}}\n- PRD: {{N}} sections, {{E}} epics, {{M}} user stories, {{F}} features\n- Architecture: Tech stack ({{stack}}), database schemas ({{table count}} tables), infrastructure plan ({{hosting}}), security architecture\n- {{E}} Epic files: Each with stories, acceptance criteria, technical notes\n- Story Index: {{M}} stories, {{P}} story points\n\nKey features:\n{{List main features}}\n\nTech stack:\n{{Stack summary}}\n\nEpics:\n{{List all epics}}\n\nCost estimates:\n- MVP: ${{X}}/month\n- Production: ${{Y}}/month\n\nReady for implementation with /titanium:plan bmad-backlog/epics/EPIC-001-*.md\",\n  files: [\n    \"bmad-backlog/product-brief.md\",\n    \"bmad-backlog/prd/prd.md\",\n    \"bmad-backlog/architecture/architecture.md\",\n    \"{{list each epic file from Glob results}}\",\n    \"bmad-backlog/STORY-INDEX.md\",\n    \"{{list each research file from Glob results if research completed}}\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n**Example with explicit paths**:\n```\nfiles: [\n  \"bmad-backlog/product-brief.md\",\n  \"bmad-backlog/prd/prd.md\",\n  \"bmad-backlog/architecture/architecture.md\",\n  \"bmad-backlog/epics/EPIC-001-foundation.md\",\n  \"bmad-backlog/epics/EPIC-002-core-features.md\",\n  \"bmad-backlog/epics/EPIC-003-advanced.md\",\n  \"bmad-backlog/epics/EPIC-004-polish.md\",\n  \"bmad-backlog/STORY-INDEX.md\"\n]\n```\n\n**If research completed, add**:\n```\n  \"bmad-backlog/research/RESEARCH-data-vendors-prompt.md\",\n  \"bmad-backlog/research/RESEARCH-data-vendors-findings.md\"\n```\n\n### Step 7.4: Present Complete Summary\n\n```\nüéâ BMAD Backlog Generation Complete!\n\nüìö Documentation Created:\n\n‚úÖ Product Brief\n   Location: bmad-backlog/product-brief.md\n   Purpose: High-level vision and goals\n\n‚úÖ Product Requirements Document (PRD)\n   Location: bmad-backlog/prd/prd.md\n   Size: ~{{lines}} lines\n   Epics: {{N}}\n   User Stories: {{M}}\n   Features: {{F}}\n\n‚úÖ Technical Architecture\n   Location: bmad-backlog/architecture/architecture.md\n   Size: ~{{lines}} lines\n   Tech Stack: {{stack summary}}\n   Database Tables: {{count}}\n   Cost Estimate: ${{MVP cost}}/month MVP\n\n‚úÖ Epic Files ({{N}} epics)\n   Location: bmad-backlog/epics/\n   Files:\n   - EPIC-001-{{name}}.md ({{X}} stories)\n   - EPIC-002-{{name}}.md ({{Y}} stories)\n   - EPIC-003-{{name}}.md ({{Z}} stories)\n   ...\n\n‚úÖ Story Index\n   Location: bmad-backlog/STORY-INDEX.md\n   Total: {{M}} stories, {{P}} story points\n\n{{If research completed:}}\n‚úÖ Research Findings\n   Location: bmad-backlog/research/\n   Topics: {{list topics}}\n\n---\n\nüìä Project Summary:\n\nGoal: {{high-level goal}}\nTarget Users: {{primary user segment}}\nMVP Features: {{core feature count}}\nTech Stack: {{Frontend}} + {{Backend}} + {{Database}}\nMVP Timeline: 12-16 weeks (from PRD estimate)\nCost: ${{X}}/month MVP, ${{Y}}/month Production\n\nEpic Sequence:\n1. {{Epic 1}} - Foundation ({{stories}} stories, {{points}} points)\n2. {{Epic 2}} - {{name}} ({{stories}} stories, {{points}} points)\n3. {{Epic 3}} - {{name}} ({{stories}} stories, {{points}} points)\n...\n\nTotal Development Effort: {{total story points}} story points\n\n---\n\nüìÅ Folder Structure:\n\nbmad-backlog/\n‚îú‚îÄ‚îÄ product-brief.md\n‚îú‚îÄ‚îÄ prd/\n‚îÇ   ‚îî‚îÄ‚îÄ prd.md\n‚îú‚îÄ‚îÄ architecture/\n‚îÇ   ‚îî‚îÄ‚îÄ architecture.md\n‚îú‚îÄ‚îÄ epics/\n‚îÇ   ‚îú‚îÄ‚îÄ EPIC-001-{{name}}.md\n‚îÇ   ‚îú‚îÄ‚îÄ EPIC-002-{{name}}.md\n‚îÇ   ‚îî‚îÄ‚îÄ ... ({{N}} total)\n{{If research:}}\n‚îú‚îÄ‚îÄ research/\n‚îÇ   ‚îú‚îÄ‚îÄ RESEARCH-{{topic}}-prompt.md\n‚îÇ   ‚îî‚îÄ‚îÄ RESEARCH-{{topic}}-findings.md\n‚îî‚îÄ‚îÄ STORY-INDEX.md\n\n---\n\nüí° Next Steps:\n\nReady to start implementing?\n\n**Option 1: Plan First Epic** (Recommended)\n```\n/titanium:plan bmad-backlog/epics/EPIC-001-{{name}}.md\n```\nThis will break Epic 1 into implementation tasks.\n\n**Option 2: Review Documentation First**\nOpen and review:\n- bmad-backlog/prd/prd.md (requirements)\n- bmad-backlog/architecture/architecture.md (technical design)\n- bmad-backlog/epics/*.md (user stories)\n\nThen come back and run:\n```\n/titanium:plan bmad-backlog/epics/EPIC-001-{{name}}.md\n```\n\n**Option 3: Complete Workflow**\n```\n/titanium:work bmad-backlog/epics/EPIC-001-{{name}}.md\n```\nThis will plan AND implement Epic 1 in one go.\n\n---\n\nüéä Congratulations! You now have complete project documentation following BMAD methodology.\n\nYour backlog is ready for professional AI-powered development with Titanium Toolkit.\n\nWhat would you like to do next?\n```\n\n---\n\n## Detailed Workflow\n\n### Interactive Mode Steps\n\n**Product Brief**:\n1. Capture idea\n2. Ask 7-10 clarifying questions\n3. Generate brief\n4. Show to user\n5. Refine if needed\n6. Validate and approve\n\n**PRD**:\n1. Read brief\n2. Ask about success metrics\n3. Ask about features (work through MVP features)\n4. Propose epic structure\n5. For each epic, ask about user stories\n6. Ask about technical requirements\n7. Ask about data/AI needs\n8. Ask about design preferences\n9. Ask about go-to-market\n10. Ask about risks\n11. Generate comprehensive PRD\n12. Review epic list with user\n13. Validate and approve\n\n**Research** (if needed):\n1. Detect research needs from PRD\n2. Offer to generate prompts\n3. Generate prompts and templates\n4. Wait for user to research\n5. Confirm research complete\n6. Continue\n\n**Architecture**:\n1. Read PRD\n2. Read research findings (if exist)\n3. Propose tech stack\n4. Get user approval\n5. Generate comprehensive architecture\n6. Show tech stack and cost estimates\n7. Validate and approve\n\n**Epics**:\n1. Extract epic list from PRD\n2. For each epic:\n   - Generate epic file\n   - Show story count\n   - Progress indicator\n3. Generate story index\n4. Show totals\n\n### YOLO Mode Steps\n\n**All at once**:\n1. Capture idea\n2. Ask 2-3 critical questions only\n3. Generate ALL documents with one set of prompts\n4. Present complete backlog\n5. User reviews and refines any sections needed\n\n**Faster but less precise** - good for experienced users.\n\n---\n\n## Error Handling\n\n### If ANTHROPIC_API_KEY Missing\n\n```\n‚ùå Error: ANTHROPIC_API_KEY required\n\nThis workflow uses Claude (Haiku 4.5 + Sonnet 4.5) to generate comprehensive documentation.\n\nAdd your key to ~/.env:\n  echo 'ANTHROPIC_API_KEY=sk-ant-your-key' >> ~/.env\n  chmod 600 ~/.env\n\nRestart Claude Code and try again.\n\nCost: ~$0.15 for complete backlog (less than a coffee!)\n```\n\n### If Generation Fails Mid-Workflow\n\n```\n‚ùå Error during {{document}} generation\n\nError: {{error message}}\n\nOptions:\n1. Retry this step\n2. Skip this document (not recommended)\n3. Cancel workflow (documents created so far are saved)\n\nWhat would you like to do?\n```\n\n### If User Cancels Mid-Workflow\n\n```\n‚è∏Ô∏è  Workflow Paused\n\nDocuments created so far:\n{{List what's been created}}\n\nYou can resume by running individual commands:\n- /bmad:prd (if brief complete)\n- /bmad:architecture (if PRD complete)\n- /bmad:epic {{N}} (if architecture complete)\n\nOr start over: /bmad:start\n```\n\n---\n\n## Voice Feedback\n\nVoice announces progress:\n- \"Starting BMAD workflow\" (at beginning)\n- \"Product brief complete\" (after phase 2)\n- \"PRD complete: {{N}} epics\" (after phase 3)\n- \"Architecture complete\" (after phase 5)\n- \"Generating epics\" (phase 6)\n- \"Epic {{N}} of {{total}} complete\" (each epic)\n- \"Backlog complete: {{M}} stories\" (at end)\n\n---\n\n## Time Estimates\n\n**Interactive Mode**:\n- Product Brief: ~10 minutes (questions + generation)\n- PRD: ~15 minutes (questions + generation)\n- Research: ~15 minutes per topic (optional)\n- Architecture: ~5 minutes (generation + review)\n- Epics: ~2 minutes per epic (generation)\n- **Total: ~45 minutes** (without research) to ~60 minutes (with research)\n\n**YOLO Mode**:\n- Idea capture: ~5 minutes\n- Generation: ~10 minutes (all documents)\n- Review: ~15 minutes\n- **Total: ~30 minutes**\n\n---\n\n## Important Guidelines\n\n**Always**:\n- ‚úÖ Validate each document before proceeding\n- ‚úÖ Use vibe-check for quality validation\n- ‚úÖ Store progress in Pieces after each phase\n- ‚úÖ Present clear summaries\n- ‚úÖ Verify Epic 1 is Foundation\n- ‚úÖ Offer research opportunities\n- ‚úÖ Guide user to next steps\n\n**Never**:\n- ‚ùå Skip document validation\n- ‚ùå Ignore vibe-check concerns\n- ‚ùå Generate incomplete documents\n- ‚ùå Forget to generate story index\n- ‚ùå Leave user uncertain about next steps\n\n## Integration\n\n**After `/bmad:start`** completes:\n```\n/titanium:plan bmad-backlog/epics/EPIC-001-*.md\n/titanium:work\n```\n\n**Complete cycle**:\n```\nIdea ‚Üí /bmad:start ‚Üí /titanium:plan ‚Üí /titanium:work ‚Üí Working Code\n  (45 min)        (2 min)         (3-6 hours)\n```\n\n**Cost Breakdown**:\n- BMAD generation: $0.22\n- Implementation: $0.10 per epic\n- **Total for MVP**: $0.22 + (4 epics √ó $0.10) = ~$0.62\n\n---\n\n**This command transforms an idea into a complete, implementation-ready project backlog in under an hour!**"
              },
              {
                "name": "/catchup",
                "description": "Get context about recent projects and what was left off from Pieces LTM",
                "path": "plugins/titanium-toolkit/commands/catchup.md",
                "frontmatter": {
                  "description": "Get context about recent projects and what was left off from Pieces LTM"
                },
                "content": "You are starting a new session with the user. Use the Pieces MCP `ask_pieces_ltm` tool to gather context about:\n\n1. What projects the user has been working on recently (last 24-48 hours)\n2. What specific tasks or files they were editing\n3. Any unfinished work or issues they encountered\n4. The current state of their active projects\n\nQuery Pieces with questions like:\n- \"What projects has the user been working on in the last 24 hours?\"\n- \"What was the user working on most recently?\"\n- \"What files or code was the user editing recently?\"\n- \"Were there any errors or issues the user was troubleshooting?\"\n\nAfter gathering this context, provide a concise summary organized by:\n- **Active Projects**: List the main projects with brief descriptions\n- **Recent Work**: What was being worked on most recently\n- **Where We Left Off**: Specific tasks, files, or issues that may need continuation\n- **Current Focus**: What appears to be the highest priority based on recent activity\n\nBe specific with file paths, timestamps, and concrete details. The goal is to help both you and the user quickly resume work without losing context."
              },
              {
                "name": "/coderabbit-review",
                "description": "Run CodeRabbit CLI analysis on uncommitted changes",
                "path": "plugins/titanium-toolkit/commands/coderabbit-review.md",
                "frontmatter": {
                  "description": "Run CodeRabbit CLI analysis on uncommitted changes"
                },
                "content": "# CodeRabbit Review Command\n\nYou are running CodeRabbit CLI analysis to catch race conditions, memory leaks, security vulnerabilities, and logic errors in uncommitted code changes.\n\n## Purpose\n\nCodeRabbit CLI provides AI-powered static analysis that detects:\n- Race conditions in concurrent code\n- Memory leaks and resource leaks\n- Security vulnerabilities\n- Logic errors and edge cases\n- Performance issues\n- Code quality problems\n\nThis complements the 3-agent review by finding issues that require deep static analysis.\n\n## Prerequisites\n\n**CodeRabbit CLI must be installed**:\n\nCheck installation:\n```bash\ncommand -v coderabbit >/dev/null 2>&1 || echo \"Not installed\"\n```\n\n**If not installed**:\n```\n‚ùå CodeRabbit CLI not found\n\nCodeRabbit CLI is optional but provides enhanced code analysis.\n\nTo install:\n  curl -fsSL https://cli.coderabbit.ai/install.sh | sh\n  source ~/.zshrc  # or your shell rc file\n\nThen authenticate:\n  coderabbit auth login\n\nSee: https://docs.coderabbit.ai/cli/overview\n\nSkip CodeRabbit and continue? (yes/no)\n```\n\nIf skip: Exit\nIf install: Wait for user to install, then continue\n\n## Process\n\n### Step 1: Check Authentication\n\n```bash\ncoderabbit auth status\n```\n\n**If not authenticated**:\n```\n‚ö†Ô∏è  CodeRabbit not authenticated\n\nFor enhanced reviews (with team learnings):\n  coderabbit auth login\n\nContinue without authentication? (yes/no)\n```\n\nAuthentication is optional but provides better reviews (Pro feature).\n\n### Step 2: Choose Review Mode\n\nAsk user:\n```\nCodeRabbit Review Mode:\n\n1. **AI-Optimized** (--prompt-only)\n   - Token-efficient output\n   - Optimized for Claude to parse\n   - Quick fix application\n   - Recommended for workflows\n\n2. **Detailed** (--plain)\n   - Human-readable detailed output\n   - Comprehensive explanations\n   - Good for learning\n   - More verbose\n\nWhich mode? (1 or 2)\n```\n\nStore choice.\n\n### Step 3: Determine Review Scope\n\n**Default**: Uncommitted changes only\n\n**Options**:\n```\nWhat should CodeRabbit review?\n\n1. Uncommitted changes only (default)\n2. All changes vs main branch\n3. All changes vs specific branch\n\nScope:\n```\n\n**Map to flags**:\n- Option 1: `--type uncommitted`\n- Option 2: `--base main`\n- Option 3: `--base [branch name]`\n\n### Step 4: Run CodeRabbit in Background\n\n**For AI-Optimized mode**:\n```bash\n# Run in background (can take 7-30 minutes)\ncoderabbit --prompt-only --type uncommitted\n```\n\n**For Detailed mode**:\n```bash\ncoderabbit --plain --type uncommitted\n```\n\nUse Bash tool with `run_in_background: true`\n\nShow user:\n```\nü§ñ CodeRabbit Analysis Running...\n\nThis will take 7-30 minutes depending on code size.\nRunning in background - you can continue working.\n\nI'll check progress periodically.\n```\n\n### Step 5: Wait for Completion\n\nCheck periodically with BashOutput tool:\n```bash\n# Check if CodeRabbit completed\n# Look for completion markers in output\n```\n\nEvery 2-3 minutes, show:\n```\nCodeRabbit analyzing... ([X] minutes elapsed)\n```\n\nWhen complete:\n```\n‚úÖ CodeRabbit analysis complete!\n```\n\n### Step 6: Parse Findings\n\n**If --prompt-only mode**:\n- Read structured output\n- Extract issues by severity:\n  - Critical\n  - High\n  - Medium\n  - Low\n\n**If --plain mode**:\n- Show full output to user\n- Ask if they want Claude to fix issues\n\n### Step 7: Present Findings\n\n```\nü§ñ CodeRabbit Analysis Complete\n\n‚è±Ô∏è  Duration: [X] minutes\n\nüìä Findings:\n- üî¥ Critical: [X] issues\n- üü† High: [Y] issues\n- üü° Medium: [Z] issues\n- üü¢ Low: [W] issues\n\nCritical Issues:\n1. Race condition in auth.ts:45\n   Issue: Shared state access without lock\n   Fix: Add mutex or use atomic operations\n\n2. Memory leak in websocket.ts:123\n   Issue: Event listener not removed on disconnect\n   Fix: Add cleanup in disconnect handler\n\n[List all critical and high issues]\n\nWould you like me to fix these issues?\n1. Fix critical and high priority (recommended)\n2. Fix critical only\n3. Show me the issues, I'll fix manually\n4. Skip (not recommended)\n```\n\n### Step 8: Apply Fixes (if requested)\n\n**For each critical/high issue**:\n1. Read the issue details\n2. Locate the problematic code\n3. Apply CodeRabbit's suggested fix\n4. Run relevant tests\n5. Mark as fixed\n\nShow progress:\n```\nFixing issues...\n‚úÖ Fixed race condition in auth.ts\n‚úÖ Fixed memory leak in websocket.ts\n‚úÖ Fixed SQL injection in users.ts\n‚è≥ Fixing error handling in api.ts...\n```\n\n### Step 9: Optional Re-run\n\nAfter fixes:\n```\nFixes applied: [X] critical, [Y] high\n\nRe-run CodeRabbit to verify fixes? (yes/no)\n```\n\n**If yes**:\n```bash\ncoderabbit --prompt-only --type uncommitted\n```\n\nCheck no new critical issues introduced.\n\n### Step 10: Store in Pieces\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"CodeRabbit review findings for [files]\",\n  summary: \"CodeRabbit CLI analysis complete. Findings: [X] critical, [Y] high, [Z] medium, [W] low. Critical issues: [list]. High issues: [list]. Fixes applied: [what was fixed]. Duration: [X] minutes. Verified: [yes/no].\",\n  files: [\n    \"list all reviewed files\",\n    \".titanium/coderabbit-report.md\" (if created)\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n### Step 11: Present Summary\n\n```\n‚úÖ CodeRabbit Review Complete!\n\nüìä Summary:\n- Duration: [X] minutes\n- Files reviewed: [N]\n- Issues found: [Total]\n  - Critical: [X] ([fixed/pending])\n  - High: [Y] ([fixed/pending])\n  - Medium: [Z]\n  - Low: [W]\n\n‚úÖ Critical issues: All fixed\n‚úÖ High priority: All fixed\n‚ö†Ô∏è  Medium/Low: Review manually if needed\n\nüíæ Findings stored in Pieces\n\n---\n\nNext steps:\n1. Run tests to verify fixes\n2. Run /titanium:review for additional validation\n3. Or continue with your workflow\n```\n\n## Error Handling\n\n### If CodeRabbit Not Installed\n\n```\n‚ö†Ô∏è  CodeRabbit CLI not found\n\nCodeRabbit is optional but provides enhanced static analysis.\n\nWould you like to:\n1. Install now (I'll guide you)\n2. Skip and use 3-agent review only\n3. Cancel\n\nChoose:\n```\n\n### If CodeRabbit Times Out\n\n```\n‚è∞ CodeRabbit taking longer than expected\n\nAnalysis started [X] minutes ago.\nTypical duration: 7-30 minutes.\n\nOptions:\n1. Keep waiting\n2. Cancel and proceed without CodeRabbit\n3. Check CodeRabbit output so far\n\nWhat would you like to do?\n```\n\n### If No Changes to Review\n\n```\n‚ÑπÔ∏è  No uncommitted changes found\n\nCodeRabbit needs changes to review.\n\nOptions:\n1. Review all changes vs main branch\n2. Specify different base branch\n3. Cancel\n\nChoose:\n```\n\n## Integration with Workflow\n\n### Standalone Usage\n\n```bash\n/coderabbit:review\n# Runs analysis\n# Applies fixes\n# Done\n```\n\n### Part of /titanium:work\n\n```bash\n/titanium:work\n# ... implementation ...\n# Phase 3.5: CodeRabbit (if installed)\n# ... 3-agent review ...\n# Complete\n```\n\n### Before Committing\n\n```bash\n# Before commit\n/coderabbit:review\n# Fix critical issues\n# Then commit\n```\n\n## Voice Feedback\n\nVoice hooks announce:\n- \"Running CodeRabbit analysis\" (when starting)\n- \"CodeRabbit complete: [X] issues found\" (when done)\n- \"Applying CodeRabbit fixes\" (during fixes)\n- \"CodeRabbit fixes complete\" (after fixes)\n\n## Cost\n\n**CodeRabbit pricing**:\n- Free tier: Basic analysis, limited usage\n- Pro: Enhanced reviews with learnings\n- Enterprise: Custom limits\n\n**Not included in titanium-toolkit pricing** - separate service.\n\n---\n\n**This command provides deep static analysis to catch issues agents might miss!**"
              },
              {
                "name": "/titanium-getting-started",
                "description": "Learn how to use Titanium Toolkit for complete project workflows",
                "path": "plugins/titanium-toolkit/commands/titanium-getting-started.md",
                "frontmatter": {
                  "description": "Learn how to use Titanium Toolkit for complete project workflows"
                },
                "content": "# Titanium Toolkit - Getting Started Guide\n\nWelcome to Titanium Toolkit! This guide explains the complete workflow from idea to implementation, including where documentation lives and what commands to use.\n\n---\n\n## Complete Project Workflow\n\n### The Big Picture\n\n```\nIdea\n  ‚Üì\nProject Documentation (backlog/)\n  ‚Üì\nImplementation Plan (.titanium/)\n  ‚Üì\nCode Implementation\n  ‚Üì\nQuality Review\n  ‚Üì\nDone!\n```\n\n**Each phase has specific commands and folder structures.**\n\n---\n\n## Phase 1: Project Documentation (Coming Soon!)\n\n### Where Documentation Lives\n\n**Folder**: `backlog/` or `bmad-backlog/` in your project root\n\n```\nyour-project/\n‚îú‚îÄ‚îÄ backlog/\n‚îÇ   ‚îú‚îÄ‚îÄ product-brief.md       # High-level vision\n‚îÇ   ‚îú‚îÄ‚îÄ prd.md                 # Product Requirements Document\n‚îÇ   ‚îú‚îÄ‚îÄ architecture.md        # Technical architecture\n‚îÇ   ‚îî‚îÄ‚îÄ epics/\n‚îÇ       ‚îú‚îÄ‚îÄ epic-001.md        # Foundation Infrastructure\n‚îÇ       ‚îú‚îÄ‚îÄ epic-002.md        # User Management\n‚îÇ       ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ (source code will go here)\n```\n\n### Future Commands (In Development)\n\nThese BMAD document generation commands are coming:\n\n**`/bmad:brief`** - Generate project brief\n```bash\n/bmad:brief \"AI-powered precious metals research platform\"\n# ‚Üí Creates backlog/product-brief.md\n```\n\n**`/bmad:prd`** - Generate Product Requirements Document\n```bash\n/bmad:prd\n# ‚Üí Reads product-brief.md\n# ‚Üí Creates backlog/prd.md with complete requirements\n```\n\n**`/bmad:epic`** - Generate epic breakdown\n```bash\n/bmad:epic \"Foundation Infrastructure\"\n# ‚Üí Creates backlog/epics/epic-001.md\n# ‚Üí Breaks down into user stories\n```\n\n**`/bmad:architecture`** - Generate technical architecture\n```bash\n/bmad:architecture\n# ‚Üí Reads PRD\n# ‚Üí Creates backlog/architecture.md\n```\n\n**Vision**: `/bmad:brief` ‚Üí `/bmad:prd` ‚Üí `/bmad:epic` ‚Üí `/bmad:architecture` ‚Üí Complete backlog!\n\n**Status**: These commands are planned for future release. For now, you can:\n- Create backlog/ folder manually\n- Write documentation yourself\n- Or use external BMAD-METHOD tool: `npx bmad-method`\n\n---\n\n## Phase 2: Implementation Planning\n\n### Current State: Planning Commands Available Now\n\nOnce you have requirements (from backlog/ or your head), create an implementation plan:\n\n**`/titanium:plan`** - Create implementation plan\n\n```bash\n# From backlog documentation\n/titanium:plan backlog/epics/epic-001.md\n\n# From inline description\n/titanium:plan \"Implement user authentication with JWT\"\n\n# From BMAD PRD (if using external BMAD tool)\n/titanium:plan ~/bmad/output/project-prd.md\n```\n\n**What it creates**:\n```\n.titanium/\n‚îú‚îÄ‚îÄ requirements.md        # Your input requirements\n‚îú‚îÄ‚îÄ plan.json              # Structured plan (for Claude)\n‚îî‚îÄ‚îÄ plan.md                # Human-readable plan (for you)\n```\n\n**What the plan includes**:\n- Epics (major features)\n- Stories (user functionality)\n- Tasks (implementation steps)\n- Agent assignments (@api-developer, @frontend-developer, etc.)\n- Time estimates\n- Dependencies between tasks\n\n**Output example**:\n```\nüìã Implementation Plan Created\n\nüéØ Goal: Implement Foundation Infrastructure\n\nüì¶ Structure:\n- 1 epic\n- 4 stories\n- 12 tasks\n\n‚è±Ô∏è  Estimated Time: 3 hours\n\nü§ñ Agents:\n- @devops-engineer (infrastructure)\n- @api-developer (backend setup)\n- @doc-writer (documentation)\n\nReady to execute? Run: /titanium:work\n```\n\n---\n\n## Phase 3: Implementation\n\n### Execute Your Plan\n\n**`/titanium:work`** - Orchestrate complete implementation\n\n```bash\n# If you already ran /titanium:plan\n/titanium:work\n\n# Or create plan + execute in one step\n/titanium:work \"Implement user authentication\"\n```\n\n**What happens**:\n\n**Step 1: Planning** (if no plan exists)\n- Asks what to implement\n- Generates plan with Claude\n- Shows you the plan\n- **Waits for your approval**\n\n**Step 2: Implementation**\n- Creates todo list from plan\n- Launches agents sequentially:\n  - @product-manager validates requirements\n  - @api-developer builds backend\n  - @frontend-developer builds UI\n  - @test-runner ensures quality\n- Voice announces each step\n- vibe-check validates after each task\n- Stores progress in Pieces\n\n**Step 3: Review**\n- Launches 3 review agents in parallel:\n  - @code-reviewer (code quality)\n  - @security-scanner (security)\n  - @tdd-specialist (test coverage)\n- Creates review report\n- Shows findings with file:line references\n\n**Step 4: Completion**\n- Presents summary\n- Stores everything in Pieces\n- You're done!\n\n**Voice announcements throughout**:\n- \"Starting implementation phase\"\n- \"API endpoints created, 8 tests passing\"\n- \"Review complete: 1 security issue found\"\n- \"Workflow complete!\"\n\n---\n\n## Phase 4: Quality & Status\n\n### Check Progress Anytime\n\n**`/titanium:status`** - See where you are\n\n```bash\n/titanium:status\n```\n\n**Shows**:\n- Current phase (planning/implementation/review/completed)\n- Progress: 67% (8/12 tasks)\n- Current task\n- Time remaining\n- Recent work from Pieces\n- Next steps\n\n**Use this**:\n- Mid-workflow to check progress\n- After lunch to remember where you were\n- Next day to resume work\n- Before meetings to report status\n\n### Review Code Quality\n\n**`/titanium:review`** - Run quality review\n\n```bash\n# Review recent changes\n/titanium:review\n\n# Review specific files\n/titanium:review src/api/*.ts\n\n# Review everything\n/titanium:review --all\n```\n\n**What it does**:\n- 3 agents review in parallel (fast!)\n- Finds issues: Critical, Important, Nice-to-have\n- Creates `.titanium/review-report.md`\n- Shows actionable recommendations\n\n**Use this**:\n- After implementation\n- Before committing\n- Before pull requests\n- Periodic code reviews\n\n---\n\n## Common Workflows\n\n### Workflow 1: Brand New Project (No Documentation Yet)\n\n**You have**: Just an idea\n**Goal**: Build the project\n\n**Steps**:\n\n```bash\n# 1. Create project directory\nmkdir my-new-project\ncd my-new-project\ngit init\n\n# 2. (Future) Generate documentation with BMAD commands\n# /bmad:brief \"AI todo app with voice input\"\n# /bmad:prd\n# /bmad:epic \"Core Features\"\n# ‚Üí Creates backlog/ with all documentation\n\n# 3. (For now) Plan directly from idea\n/titanium:plan \"Build AI todo app with voice input and smart scheduling\"\n\n# 4. Execute\n/titanium:work\n\n# 5. Review\n/titanium:review\n\n# Done! Your project is implemented with tests.\n```\n\n**Timeline**: Can go from idea to working code in one session!\n\n---\n\n### Workflow 2: Existing Project with Backlog Documentation\n\n**You have**: Project documentation in `backlog/` or similar\n**Goal**: Implement next epic\n\n**Steps**:\n\n```bash\ncd my-project\n\n# 1. Plan from backlog\n/titanium:plan backlog/epics/epic-003-user-profiles.md\n\n# 2. Review the plan\n# Claude shows: \"3 stories, 8 tasks, 2 hours\"\n\n# 3. Approve and execute\n/titanium:work\n\n# 4. Review quality\n/titanium:review\n\n# Done!\n```\n\n**Timeline**: Each epic typically takes 2-6 hours depending on complexity.\n\n---\n\n### Workflow 3: Quick Feature Addition\n\n**You have**: Working project\n**Goal**: Add small feature quickly\n\n**Steps**:\n\n```bash\ncd my-project\n\n# One command - plan + execute\n/titanium:work \"Add search functionality to product catalog\"\n\n# Claude:\n# - Creates quick plan (1 epic, 2 stories)\n# - Shows you the plan\n# - Asks approval\n# - Implements\n# - Reviews\n# - Done!\n\n# Timeline: 30 minutes to 1 hour\n```\n\n---\n\n### Workflow 4: Bug Fix\n\n**You have**: Bug to fix\n**Goal**: Systematic fix with tests\n\n**Steps**:\n\n```bash\ncd my-project\n\n# Plan the fix\n/titanium:plan \"Fix: Login fails when email has uppercase letters\"\n\n# Execute\n/titanium:work\n\n# Claude:\n# - @debugger reproduces bug\n# - @api-developer fixes issue\n# - @tdd-specialist adds test\n# - Reviews fix\n# - Done!\n\n# Timeline: 15-30 minutes\n```\n\n---\n\n### Workflow 5: Resume After Interruption\n\n**You have**: Incomplete workflow\n**Goal**: Continue where you left off\n\n**Steps**:\n\n```bash\n# Next session, different day\ncd my-project\n\n# 1. Recover context\n/catchup\n# ‚Üí Pieces: \"You were implementing authentication. Backend complete...\"\n\n# 2. Check status\n/titanium:status\n# ‚Üí Shows: \"Phase: Implementation, 60% complete, Current: Register endpoint\"\n\n# 3. Continue work\n/titanium:work\n# ‚Üí Resumes from current state\n# ‚Üí Completes remaining tasks\n# ‚Üí Done!\n```\n\n---\n\n## Folder Structure Reference\n\n### During Development\n\nYour project will have these folders:\n\n```\nmy-project/\n‚îú‚îÄ‚îÄ backlog/                    # Project documentation (you create this)\n‚îÇ   ‚îú‚îÄ‚îÄ product-brief.md        # Vision and goals\n‚îÇ   ‚îú‚îÄ‚îÄ prd.md                  # Product requirements\n‚îÇ   ‚îú‚îÄ‚îÄ architecture.md         # Technical architecture\n‚îÇ   ‚îî‚îÄ‚îÄ epics/\n‚îÇ       ‚îú‚îÄ‚îÄ epic-001.md         # Epic breakdowns\n‚îÇ       ‚îú‚îÄ‚îÄ epic-002.md\n‚îÇ       ‚îî‚îÄ‚îÄ ...\n‚îÇ\n‚îú‚îÄ‚îÄ .titanium/                  # Workflow state (created automatically)\n‚îÇ   ‚îú‚îÄ‚îÄ workflow-state.json     # Current workflow state\n‚îÇ   ‚îú‚îÄ‚îÄ plan.json               # Implementation plan\n‚îÇ   ‚îú‚îÄ‚îÄ plan.md                 # Readable plan\n‚îÇ   ‚îú‚îÄ‚îÄ requirements.md         # Input requirements\n‚îÇ   ‚îî‚îÄ‚îÄ review-report.md        # Quality findings\n‚îÇ\n‚îú‚îÄ‚îÄ src/                        # Your source code (created during /titanium:work)\n‚îÇ   ‚îú‚îÄ‚îÄ api/\n‚îÇ   ‚îú‚îÄ‚îÄ components/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îÇ\n‚îú‚îÄ‚îÄ tests/                      # Your tests (created during /titanium:work)\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îÇ\n‚îî‚îÄ‚îÄ docs/                       # Technical docs (created during /titanium:work)\n    ‚îî‚îÄ‚îÄ ...\n```\n\n### Folder Purposes\n\n**`backlog/`** (you create):\n- High-level project documentation\n- Product requirements\n- Epic breakdowns\n- Architecture decisions\n- **Lives forever** - your project's source of truth\n\n**`.titanium/`** (created automatically):\n- Workflow execution data\n- Implementation plans\n- Review reports\n- **Created per workflow** - can be regenerated\n\n**`src/`**, **`tests/`**, **`docs/`** (created during implementation):\n- Your actual code\n- **Created by agents** during `/titanium:work`\n\n---\n\n## The 6 Titanium Commands\n\n### 1. `/titanium:getting-started` (This Guide)\n**Use when**: Learning the system\n**Shows**: Complete workflow guide\n\n### 2. `/titanium:plan`\n**Use when**: Starting new work\n**Creates**: Implementation plan from requirements\n**Input**: File path or inline description\n\n### 3. `/titanium:work`\n**Use when**: Ready to implement\n**Does**: Complete orchestration from plan to tested code\n**Can include**: Inline planning if no plan exists\n\n### 4. `/titanium:review`\n**Use when**: Code review needed\n**Does**: 3-agent parallel quality review\n**Output**: Review report with findings\n\n### 5. `/titanium:status`\n**Use when**: Checking progress\n**Shows**: Current state, progress %, next steps\n**Works**: Across sessions\n\n### 6. `/catchup` (Pieces Integration)\n**Use when**: Resuming work in new session\n**Shows**: Context from previous sessions\n**Requires**: Pieces OS + CLI\n\n---\n\n## Starting a Brand New Project\n\n### Option A: With BMAD Documentation (Future)\n\nWhen BMAD commands are available:\n\n```bash\n# 1. Create project\nmkdir my-new-app\ncd my-new-app\ngit init\n\n# 2. Generate documentation\n/bmad:brief \"Social media app for developers\"\n# ‚Üí Creates backlog/product-brief.md\n\n/bmad:prd\n# ‚Üí Creates backlog/prd.md\n\n/bmad:epic \"User Profiles\"\n/bmad:epic \"Feed System\"\n/bmad:epic \"Real-time Chat\"\n# ‚Üí Creates backlog/epics/*.md\n\n/bmad:architecture\n# ‚Üí Creates backlog/architecture.md\n\n# 3. Implement first epic\n/titanium:plan backlog/epics/epic-001.md\n/titanium:work\n\n# 4. Continue with more epics\n/titanium:plan backlog/epics/epic-002.md\n/titanium:work\n\n# etc...\n```\n\n### Option B: Without BMAD (Available Now)\n\nIf you don't have documentation yet:\n\n```bash\n# 1. Create project\nmkdir my-new-app\ncd my-new-app\ngit init\n\n# 2. Create backlog folder manually\nmkdir backlog\n\n# 3. Write your PRD (can be simple)\ncat > backlog/prd.md << 'EOF'\n# My Todo App\n\n## Vision\nAI-powered todo app with voice input and smart scheduling.\n\n## Core Features\n- Voice input for tasks\n- AI categorization\n- Smart scheduling suggestions\n- Calendar integration\n\n## Tech Stack\n- React + TypeScript frontend\n- Node.js + Express backend\n- PostgreSQL database\nEOF\n\n# 4. Plan implementation\n/titanium:plan backlog/prd.md\n\n# 5. Execute\n/titanium:work\n\n# Done! You have a working app.\n```\n\n### Option C: Skip Documentation Entirely (Quick Projects)\n\nFor small projects or experiments:\n\n```bash\n# 1. Create project\nmkdir quick-experiment\ncd quick-experiment\ngit init\n\n# 2. Just describe what you want\n/titanium:work \"Build a REST API for managing books with title, author, ISBN\"\n\n# Claude:\n# - Creates plan inline\n# - Implements\n# - Tests\n# - Done!\n\n# Timeline: 30 minutes - 1 hour\n```\n\n---\n\n## Starting with Existing Project\n\n### If You Already Have Code\n\n```bash\ncd existing-project\n\n# 1. Create backlog documentation (optional but recommended)\nmkdir backlog\ncat > backlog/next-features.md << 'EOF'\n# Next Features\n\n## User Authentication\n- JWT-based auth\n- Login/register\n- Password reset\nEOF\n\n# 2. Plan from backlog\n/titanium:plan backlog/next-features.md\n\n# 3. Execute\n/titanium:work\n\n# Adds features to existing codebase\n```\n\n### If You Have Backlog Documentation Already\n\n```bash\ncd my-project\n# You have: backlog/epics/epic-003.md\n\n# 1. Plan next epic\n/titanium:plan backlog/epics/epic-003.md\n\n# 2. Execute\n/titanium:work\n\n# Continues building on existing code\n```\n\n---\n\n## Daily Development Workflow\n\n### Morning\n\n```bash\n# 1. Resume context\n/catchup\n# ‚Üí Pieces: \"Yesterday you implemented authentication backend...\"\n\n# 2. Check status\n/titanium:status\n# ‚Üí \"Phase: Implementation, 60% complete, Current: Login form\"\n\n# 3. Continue work\n/titanium:work\n# ‚Üí Resumes from current state\n```\n\n### Midday\n\n```bash\n# Check progress\n/titanium:status\n# ‚Üí \"80% complete, 2 tasks remaining\"\n```\n\n### End of Day\n\n```bash\n# Final check\n/titanium:status\n# ‚Üí \"100% complete, ready for review\"\n\n/titanium:review\n# ‚Üí Quality review runs\n# ‚Üí \"1 security issue found in auth.ts:45\"\n\n# Fix the issue\n# Claude fixes it\n\n# Commit\ngit add .\ngit commit -m \"feat: Add user authentication\"\n\n# Session ends\n# Voice: \"I implemented user authentication with JWT, fixed one security issue, all tests passing\"\n```\n\n### Next Morning\n\n```bash\n# New session\n/catchup\n# ‚Üí \"Yesterday: Completed authentication. All tests passing. Ready for next epic.\"\n\n/titanium:plan backlog/epics/epic-002.md\n# ‚Üí Plan next feature\n```\n\n---\n\n## Command Decision Tree\n\n**Starting a new project?**\n```\nDo you have documentation?\n‚îú‚îÄ Yes (backlog/*.md exists)\n‚îÇ  ‚îî‚îÄ /titanium:plan backlog/epics/epic-001.md\n‚îÇ     ‚îî‚îÄ /titanium:work\n‚îÇ\n‚îî‚îÄ No (just an idea)\n   ‚îú‚îÄ Simple project?\n   ‚îÇ  ‚îî‚îÄ /titanium:work \"description\"\n   ‚îÇ\n   ‚îî‚îÄ Complex project?\n      ‚îú‚îÄ (Future) /bmad:prd ‚Üí /bmad:epic ‚Üí /titanium:plan\n      ‚îî‚îÄ (Now) Write backlog/*.md manually ‚Üí /titanium:plan\n```\n\n**Adding to existing project?**\n```\nDo you have a plan?\n‚îú‚îÄ Yes (.titanium/plan.json exists)\n‚îÇ  ‚îî‚îÄ /titanium:work\n‚îÇ\n‚îî‚îÄ No\n   ‚îî‚îÄ /titanium:plan \"feature description\"\n      ‚îî‚îÄ /titanium:work\n```\n\n**Need to review code?**\n```\n/titanium:review\n```\n\n**Lost track of progress?**\n```\n/catchup        # Get context from Pieces\n/titanium:status # See current state\n```\n\n---\n\n## Recommended Folder Structure\n\n### For Serious Projects\n\n```\nmy-project/\n‚îú‚îÄ‚îÄ backlog/                           # Documentation (manual or /bmad:*)\n‚îÇ   ‚îú‚îÄ‚îÄ product-brief.md              # Vision\n‚îÇ   ‚îú‚îÄ‚îÄ prd.md                        # Requirements\n‚îÇ   ‚îú‚îÄ‚îÄ architecture.md               # Technical decisions\n‚îÇ   ‚îî‚îÄ‚îÄ epics/\n‚îÇ       ‚îú‚îÄ‚îÄ epic-001-foundation.md\n‚îÇ       ‚îú‚îÄ‚îÄ epic-002-auth.md\n‚îÇ       ‚îî‚îÄ‚îÄ epic-003-profiles.md\n‚îÇ\n‚îú‚îÄ‚îÄ .titanium/                        # Workflow state (auto-created)\n‚îÇ   ‚îú‚îÄ‚îÄ workflow-state.json\n‚îÇ   ‚îú‚îÄ‚îÄ plan.json\n‚îÇ   ‚îî‚îÄ‚îÄ review-report.md\n‚îÇ\n‚îú‚îÄ‚îÄ src/                               # Source code\n‚îú‚îÄ‚îÄ tests/                             # Tests\n‚îú‚îÄ‚îÄ docs/                              # Technical docs\n‚îú‚îÄ‚îÄ .env.example                       # Example env vars\n‚îú‚îÄ‚îÄ README.md                          # Project readme\n‚îî‚îÄ‚îÄ package.json                       # Dependencies\n```\n\n### For Quick Projects\n\n```\nquick-project/\n‚îú‚îÄ‚îÄ .titanium/         # Auto-created by /titanium:plan or /titanium:work\n‚îú‚îÄ‚îÄ src/               # Your code\n‚îî‚îÄ‚îÄ tests/             # Your tests\n```\n\nNo backlog/ needed for simple projects!\n\n---\n\n## Best Practices\n\n### 1. Start with Planning\n\n**Recommended**:\n```bash\n/titanium:plan \"feature description\"\n/titanium:work\n```\n\n**Why**: See the plan before execution, understand scope, get time estimates.\n\n### 2. Review Before Committing\n\n**Recommended**:\n```bash\n/titanium:review\n# Fix any critical issues\ngit commit\n```\n\n**Why**: Catch issues early, maintain quality.\n\n### 3. Use Backlog for Documentation\n\n**Create**:\n```\nbacklog/\n‚îú‚îÄ‚îÄ prd.md\n‚îî‚îÄ‚îÄ epics/\n    ‚îî‚îÄ‚îÄ *.md\n```\n\n**Why**: Organized documentation, easy to plan from, version controlled.\n\n### 4. Check Status Regularly\n\n**During long workflows**:\n```bash\n/titanium:status\n```\n\n**Why**: Stay informed, know what's next, track time.\n\n### 5. Use /catchup Between Sessions\n\n**Every new session**:\n```bash\n/catchup\n```\n\n**Why**: Never lose context, resume instantly.\n\n---\n\n## What You Don't Need\n\n‚ùå Don't need to create `.titanium/` folder manually\n‚ùå Don't need to write plan.json yourself\n‚ùå Don't need to install Python packages (UV handles it)\n‚ùå Don't need to manage agents manually\n‚ùå Don't need to coordinate workflows yourself\n\n**Titanium does all of this for you!**\n\n---\n\n## Tips & Tricks\n\n### Tip 1: Keep Backlog Documentation Simple\n\nYour `backlog/prd.md` can be very simple:\n\n```markdown\n# Project: Todo App\n\n## Goal\nPersonal todo app with AI assistance\n\n## Features\n- Add/edit/delete todos\n- Voice input\n- AI categorization\n- Due date suggestions\n\n## Tech Stack\n- React frontend\n- Node.js backend\n- SQLite database\n```\n\nThat's enough! `/titanium:plan` will break it down.\n\n### Tip 2: Iterate on Plans\n\n```bash\n/titanium:plan \"Add authentication\"\n# Review the plan\n# Not quite right?\n\n# Create new plan\n/titanium:plan \"Add JWT authentication with refresh tokens and email verification\"\n# Better!\n\n/titanium:work\n```\n\nPlans are cheap (~$0.01). Iterate until right.\n\n### Tip 3: Use Status During Long Workflows\n\n```bash\n/titanium:work \"Complex feature\"\n# ... 2 hours pass ...\n/titanium:status\n# \"67% complete, 2 hours remaining\"\n```\n\nKnow when to take breaks!\n\n### Tip 4: Store Backlog in Git\n\n```bash\ngit add backlog/\ngit commit -m \"docs: Add product backlog\"\n```\n\nVersion your documentation. See how it evolves.\n\n### Tip 5: Use Review Standalone\n\n```bash\n# Before committing\n/titanium:review\n\n# Fix issues\n/titanium:review  # Run again to verify\n```\n\nCan use review without running full workflow.\n\n---\n\n## Understanding Cost\n\n**Per workflow** (~4 hour implementation):\n- Plan generation (Claude): $0.01\n- vibe-check gates (5x): $0.0005\n- Voice announcements (10x): $0.09\n- **Total: ~$0.10**\n\nVery affordable! Less than a cup of coffee per feature.\n\n**Optional**:\n- Skip voice (use macOS say): Save $0.09\n- Skip vibe-check: Save $0.0005 (but lose quality gates)\n\n**Minimum cost**: $0.01 per workflow (Claude planning only)\n\n---\n\n## When Things Go Wrong\n\n### \"No plan found\" when running /titanium:work\n\n**Solution**: Run `/titanium:plan` first, or provide description inline:\n```bash\n/titanium:work \"what to implement\"\n```\n\n### \"OPENAI_API_KEY not found\"\n\n**Solution**: Add to ~/.env:\n```bash\necho 'OPENAI_API_KEY=sk-your-key' >> ~/.env\n```\nRestart Claude Code.\n\n### \"Workflow stuck at X%\"\n\n**Solution**: Check status:\n```bash\n/titanium:status\n```\n\nIf truly stuck, restart workflow:\n```bash\nrm -rf .titanium/\n/titanium:work \"description\"\n```\n\n### \"Review found critical issues\"\n\n**Solution**: Fix them!\n```bash\n# Claude can fix them for you\nUser: \"Fix the SQL injection in users.ts:45\"\n\n# Or do manually, then review again\n/titanium:review\n```\n\n---\n\n## Getting Help\n\n### Documentation\n- **This Guide**: `/titanium:getting-started` (you are here!)\n- **Full Architecture**: `docs/ORCHESTRATION_PLAN.md`\n- **Dependencies**: `docs/DEPENDENCIES.md`\n\n### Verification\n```bash\n# Run verification script\ncurl -o verify.sh https://raw.githubusercontent.com/webdevtodayjason/titanium-plugins/main/verify-installation.sh\nchmod +x verify.sh\n./verify.sh\n```\n\n### Support\n- **Issues**: https://github.com/webdevtodayjason/titanium-plugins/issues\n- **Discussions**: https://github.com/webdevtodayjason/titanium-plugins/discussions\n\n---\n\n## Quick Reference Card\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Titanium Toolkit Quick Reference                ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ                                                  ‚îÇ\n‚îÇ Get Started:                                     ‚îÇ\n‚îÇ   /titanium:getting-started                     ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ Plan Work:                                       ‚îÇ\n‚îÇ   /titanium:plan \"what to build\"                ‚îÇ\n‚îÇ   /titanium:plan backlog/epics/epic-001.md     ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ Execute:                                         ‚îÇ\n‚îÇ   /titanium:work                                ‚îÇ\n‚îÇ   /titanium:work \"quick feature\"               ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ Check Progress:                                  ‚îÇ\n‚îÇ   /titanium:status                              ‚îÇ\n‚îÇ   /catchup                                      ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ Review Quality:                                  ‚îÇ\n‚îÇ   /titanium:review                              ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ Folders:                                         ‚îÇ\n‚îÇ   backlog/      - Your documentation           ‚îÇ\n‚îÇ   .titanium/    - Workflow state (auto)        ‚îÇ\n‚îÇ   src/          - Code (created by agents)     ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îÇ Files Created:                                   ‚îÇ\n‚îÇ   .titanium/plan.json       - Plan             ‚îÇ\n‚îÇ   .titanium/workflow-state.json - State        ‚îÇ\n‚îÇ   .titanium/review-report.md - Findings        ‚îÇ\n‚îÇ                                                  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n---\n\n## What's Next?\n\n### Ready to Start?\n\n**Simple project**:\n```bash\n/titanium:work \"your idea here\"\n```\n\n**Complex project**:\n```bash\n# 1. Create backlog documentation\nmkdir backlog\n# Write backlog/prd.md\n\n# 2. Plan\n/titanium:plan backlog/prd.md\n\n# 3. Execute\n/titanium:work\n```\n\n### Want BMAD Documentation Generation?\n\nBMAD slash commands (`/bmad:prd`, `/bmad:epic`, etc.) are **coming soon**!\n\nMeanwhile, you can:\n- Write backlog/ docs manually (simple markdown)\n- Use external BMAD tool: `npx bmad-method`\n- Or skip documentation for simple projects\n\n---\n\n**You're ready to orchestrate! Pick a workflow above and start building.** üöÄ"
              },
              {
                "name": "/titanium-orchestration-guide",
                "description": "Understand how Titanium Toolkit orchestrates subagents, skills, and MCP tools",
                "path": "plugins/titanium-toolkit/commands/titanium-orchestration-guide.md",
                "frontmatter": {
                  "description": "Understand how Titanium Toolkit orchestrates subagents, skills, and MCP tools"
                },
                "content": "# Titanium Toolkit: Orchestration Model\n\nYou are Claude Code running in **orchestrator mode** with the Titanium Toolkit plugin. This guide explains your role and how to effectively coordinate specialized subagents for both **planning (BMAD)** and **development (Titanium)** workflows.\n\n## Your Role as Orchestrator\n\n**You are the conductor, not the performer.**\n\nIn Titanium Toolkit, you don't generate documents or write code directly. Instead, you orchestrate two types of workflows:\n\n### BMAD Workflows (Planning & Documentation)\nGenerate comprehensive project documentation through specialized planning agents:\n- `/bmad:start` - Complete backlog generation (Brief ‚Üí PRD ‚Üí Architecture ‚Üí Epics)\n- `/bmad:brief`, `/bmad:prd`, `/bmad:architecture`, `/bmad:epic` - Individual documents\n- Delegates to: @product-manager, @architect subagents\n\n### Titanium Workflows (Development & Implementation)\nExecute implementation through specialized development agents:\n- `/titanium:plan` - Requirements ‚Üí Implementation plan\n- `/titanium:work` - Execute implementation with sequential task delegation\n- `/titanium:review` - Parallel quality review by 3+ agents\n- Delegates to: @api-developer, @frontend-developer, @test-runner, @security-scanner, @code-reviewer, etc.\n\n## Your Orchestration Responsibilities\n\n1. **Listen to user requests** and understand their goals\n2. **Follow slash command prompts** that provide detailed delegation instructions\n3. **Launch specialized subagents** via the Task tool to perform work\n4. **Coordinate workflow** by managing prerequisites, sequencing, and handoffs\n5. **Present results** from subagents back to the user\n6. **Handle errors** and guide users through issues\n7. **Manage state transitions** for multi-phase workflows\n8. **Run meta-validations** (vibe-check) at checkpoints\n9. **Store milestones** in Pieces LTM for context recovery\n\n## The Orchestration Architecture\n\n### Three-Layer System\n\n```\nLayer 1: YOU (Orchestrator Claude)\n‚îú‚îÄ‚îÄ Receives user requests\n‚îú‚îÄ‚îÄ Interprets slash commands\n‚îú‚îÄ‚îÄ Checks prerequisites\n‚îú‚îÄ‚îÄ Launches subagents via Task tool\n‚îî‚îÄ‚îÄ Presents results to user\n\nLayer 2: Specialized Subagents (Separate Context Windows)\n‚îú‚îÄ‚îÄ @product-manager (Brief, PRD, Epics)\n‚îú‚îÄ‚îÄ @architect (Architecture)\n‚îú‚îÄ‚îÄ @api-developer (Backend code)\n‚îú‚îÄ‚îÄ @frontend-developer (UI code)\n‚îú‚îÄ‚îÄ @test-runner (Testing)\n‚îú‚îÄ‚îÄ @security-scanner (Security review)\n‚îú‚îÄ‚îÄ @code-reviewer (Code quality)\n‚îî‚îÄ‚îÄ ... (17 total specialized agents)\n\nLayer 3: Tools & Knowledge\n‚îú‚îÄ‚îÄ MCP Tools (tt server: plan_parser, bmad_generator, bmad_validator)\n‚îú‚îÄ‚îÄ Skills (bmad-methodology, api-best-practices, frontend-patterns, etc.)\n‚îî‚îÄ‚îÄ Standard Tools (Read, Write, Edit, Bash, etc.)\n```\n\n## How Slash Commands Guide You\n\nSlash commands (like `/bmad:start`, `/titanium:work`) contain **detailed orchestration scripts** that tell you exactly how to delegate work.\n\n### Slash Command Structure\n\nEach command provides:\n\n1. **Prerequisites check** - What you verify before proceeding\n2. **Task delegation instructions** - Exact Task tool calls with prompts for subagents\n3. **Suggested MCP tool usage** - Which MCP tools subagents should use\n4. **Validation requirements** - What must be validated\n5. **Error handling** - How to handle failures\n6. **Next steps** - What to suggest after completion\n\n### Example: How You Orchestrate `/bmad:architecture`\n\n**The slash command tells you**:\n\n```\nStep 1: Check if PRD exists\n  - If not found: Error, tell user to run /bmad:prd\n  - If found: Continue to Step 2\n\nStep 2: Launch Architect Subagent\n  Task(\n    description: \"Generate BMAD architecture\",\n    prompt: \"... [detailed workflow] ...\",\n    subagent_type: \"architect\"\n  )\n\nStep 3: Return Results\n  Present architect's summary to user\n```\n\n**You execute**:\n1. ‚úÖ Check: `ls bmad-backlog/prd/prd.md`\n2. ‚úÖ Launch: `Task(description: \"Generate BMAD architecture\", ...)`\n3. ‚úÖ Wait: Architect runs in separate context window\n4. ‚úÖ Present: Show architect's summary to user\n\n**You DON'T**:\n- ‚ùå Read the PRD yourself\n- ‚ùå Call bmad_generator yourself\n- ‚ùå Generate the architecture content\n- ‚ùå Validate the output yourself\n\nThe **architect subagent** does all that work in its own context window.\n\n## Subagent Context Windows\n\nEach subagent runs in a **separate, isolated context window** with:\n\n### What Subagents Have\n\n1. **Specialized expertise** - Their agent prompt defines their role\n2. **Skills** - Knowledge bases (bmad-methodology, api-best-practices, etc.)\n3. **Tool access** - MCP tools and standard tools they need\n4. **Clean context** - No token pollution from orchestrator's context\n5. **Focus** - Single task to complete\n\n### What Subagents Don't Have\n\n1. **Your conversation history** - They only see what you pass in the Task prompt\n2. **User's original request** - You must include relevant context in prompt\n3. **Other subagents' work** - Each runs independently\n4. **Orchestration knowledge** - They focus on their specific task\n\n### Why Separate Context Windows Matter\n\n**Token efficiency**:\n- Your orchestration context stays clean\n- Each subagent only loads what it needs\n- Large documents don't pollute main conversation\n\n**Specialization**:\n- Subagent loads its skills (500-1000 line knowledge bases)\n- Subagent focuses on single task\n- Better quality output\n\n**Parallelization** (when applicable):\n- Multiple review agents can run simultaneously\n- Independent tasks don't block each other\n\n## MCP Tools: The Shared Utilities\n\n### The `tt` MCP Server\n\nTitanium Toolkit provides a custom MCP server (`tt`) with three tools:\n\n1. **plan_parser** - Requirements ‚Üí Implementation Plan\n   ```\n   mcp__plugin_titanium-toolkit_tt__plan_parser(\n     requirements_file: \".titanium/requirements.md\",\n     project_path: \"$(pwd)\"\n   )\n   ```\n\n2. **bmad_generator** - Generate BMAD Documents\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_generator(\n     doc_type: \"brief|prd|architecture|epic|index\",\n     input_path: \"...\",\n     project_path: \"$(pwd)\"\n   )\n   ```\n\n3. **bmad_validator** - Validate BMAD Documents\n   ```\n   mcp__plugin_titanium-toolkit_tt__bmad_validator(\n     doc_type: \"brief|prd|architecture|epic\",\n     document_path: \"...\"\n   )\n   ```\n\n### How Subagents Use MCP Tools\n\n**The slash command tells subagents which tools to use**:\n\n```\nTask(\n  prompt: \"...\n\n  2. **Generate PRD** using MCP tool:\n     mcp__plugin_titanium-toolkit_tt__bmad_generator(\n       doc_type: \\\"prd\\\",\n       input_path: \\\"bmad-backlog/product-brief.md\\\",\n       project_path: \\\"$(pwd)\\\"\n     )\n\n  4. **Validate PRD** using:\n     mcp__plugin_titanium-toolkit_tt__bmad_validator(\n       doc_type: \\\"prd\\\",\n       document_path: \\\"bmad-backlog/prd/prd.md\\\"\n     )\n\n  ...\",\n  subagent_type: \"product-manager\"\n)\n```\n\nThe subagent sees these MCP tool examples and uses them.\n\n## Skills: Domain Knowledge for Subagents\n\n### Available Skills\n\n**Product/Planning**:\n- `bmad-methodology` (1092 lines) - PRD, Architecture, Epic, Story creation best practices\n- `project-planning` (883 lines) - Work breakdown, estimation, dependencies, sprint planning\n\n**Development**:\n- `api-best-practices` (700+ lines) - REST API design, authentication, versioning, OpenAPI\n- `frontend-patterns` (800+ lines) - React patterns, state management, performance, accessibility\n\n**Quality**:\n- `testing-strategy` (909 lines) - Test pyramid, TDD, mocking, coverage, CI/CD\n- `code-quality-standards` (1074 lines) - SOLID, design patterns, refactoring, code smells\n- `security-checklist` (1012 lines) - OWASP Top 10, vulnerabilities, auth, secrets management\n\n**Operations**:\n- `devops-patterns` (1083 lines) - CI/CD, infrastructure as code, deployments, monitoring\n- `debugging-methodology` (773 lines) - Systematic debugging, root cause analysis, profiling\n\n**Documentation**:\n- `technical-writing` (912 lines) - Clear docs, README structure, API docs, tutorials\n\n### How Skills Work\n\n**Model-invoked** (not user-invoked):\n- Subagents automatically use skills when relevant\n- Skills are discovered based on their description\n- No explicit invocation needed\n\n**Progressive disclosure**:\n- Skills are large (500-1000 lines each)\n- Claude only loads relevant sections when needed\n- Supports deep expertise without token waste\n\n**Example**: When @architect generates architecture:\n1. Architect agent loads in separate context\n2. Sees `skills: [bmad-methodology, api-best-practices, devops-patterns]` in frontmatter\n3. Claude automatically loads these skills when relevant\n4. Uses bmad-methodology for document structure\n5. Uses api-best-practices for API design sections\n6. Uses devops-patterns for infrastructure sections\n\n## Complete Workflow Example: `/bmad:start`\n\nLet's walk through the complete orchestration:\n\n### User Request\n```\nUser: /bmad:start\n```\n\n### Your Orchestration (Step by Step)\n\n**Phase 1: Introduction**\n- YOU: Welcome user, explain workflow\n- YOU: Check for existing docs\n- YOU: Ask for workflow mode (Interactive/YOLO)\n\n**Phase 2: Product Brief**\n- YOU: Ask user for project idea\n- YOU: Gather idea and context\n- YOU: Launch @product-manager subagent via Task tool\n- @product-manager (in separate window):\n  - Uses bmad_generator MCP tool\n  - Uses bmad-methodology skill\n  - Validates with bmad_validator\n  - Runs vibe-check\n  - Stores in Pieces\n  - Returns summary\n- YOU: Present product-manager's summary to user\n\n**Phase 3: PRD**\n- YOU: Launch @product-manager subagent via Task tool\n- @product-manager (new separate window):\n  - Reads product brief\n  - Uses bmad_generator MCP tool\n  - Reviews epic structure\n  - Uses bmad-methodology skill\n  - Validates with bmad_validator\n  - Runs vibe-check\n  - Stores in Pieces\n  - Returns summary with epic list\n- YOU: Present epic list to user\n- YOU: Detect research needs from epic keywords\n\n**Phase 4: Research (If Needed)**\n- YOU: Offer to generate research prompts\n- YOU: Generate prompts if user wants them\n- YOU: Wait for user to complete research\n\n**Phase 5: Architecture**\n- YOU: Launch @architect subagent via Task tool\n- @architect (separate window):\n  - Reads PRD and research findings\n  - Uses bmad_generator MCP tool\n  - Uses bmad-methodology, api-best-practices, devops-patterns skills\n  - Proposes tech stack\n  - Validates with bmad_validator\n  - Runs vibe-check\n  - Stores in Pieces\n  - Returns summary with tech stack\n- YOU: Present architect's tech stack to user\n\n**Phase 6: Epic Generation**\n- YOU: Extract epic list from PRD\n- YOU: Count how many epics to generate\n- YOU: For each epic (sequential):\n  - Launch @product-manager subagent via Task tool\n  - @product-manager (new window each time):\n    - Reads PRD and Architecture\n    - Uses bmad_generator MCP tool for epic\n    - Uses bmad-methodology skill\n    - Validates epic\n    - Runs vibe-check\n    - Stores in Pieces\n    - Returns brief summary\n  - YOU: Show progress (\"Epic 3 of 5 complete\")\n- YOU: Launch @product-manager for story index\n- @product-manager:\n  - Uses bmad_generator MCP tool for index\n  - Extracts totals\n  - Runs vibe-check\n  - Stores in Pieces\n  - Returns summary\n\n**Phase 7: Final Summary**\n- YOU: Run final vibe-check on complete backlog\n- YOU: Store complete backlog summary in Pieces\n- YOU: Present comprehensive completion summary\n\n### What You Did\n\n‚úÖ Orchestrated 6+ subagent launches\n‚úÖ Managed workflow state transitions\n‚úÖ Handled user interactions and approvals\n‚úÖ Coordinated data handoffs between phases\n‚úÖ Presented all results clearly\n\n### What You Didn't Do\n\n‚ùå Generate any documents yourself\n‚ùå Call MCP tools directly\n‚ùå Read PRDs/Architecture for content (only for epic lists)\n‚ùå Validate documents (subagents did this)\n\n## Key Orchestration Principles\n\n### 1. Follow the Slash Command Prompts\n\n**Slash commands are your script**. They tell you exactly:\n- Which subagent to launch\n- What prompt to give them\n- What MCP tools they should use\n- What to validate\n- What to return\n\n**Don't improvise** - follow the script.\n\n### 2. Prerequisites Are Your Responsibility\n\nBefore launching subagents, you check:\n- Required files exist\n- API keys are configured\n- User has provided necessary input\n- Previous phases completed successfully\n\nIf prerequisites fail, you error gracefully and guide user.\n\n### 3. Delegation, Not Doing\n\n**Your job**:\n```\n‚úÖ Check prerequisites\n‚úÖ Launch subagent with detailed prompt\n‚úÖ Wait for subagent completion\n‚úÖ Present subagent's results\n‚úÖ Guide user to next steps\n```\n\n**Not your job**:\n```\n‚ùå Generate content yourself\n‚ùå Call tools that subagents should call\n‚ùå Duplicate work that subagents do\n‚ùå Make decisions subagents should make\n```\n\n### 4. Subagents Are Autonomous\n\nOnce you launch a subagent:\n- They have complete workflow instructions\n- They make decisions within their domain\n- They validate their own work\n- They store their results\n- They return a summary\n\nYou don't micromanage - you trust their expertise.\n\n### 5. Quality Gates at Every Level\n\n**Subagents run**:\n- Structural validation (bmad_validator)\n- Quality validation (vibe-check)\n- Pieces storage (memory)\n\n**You run**:\n- Final meta-validation (overall workflow quality)\n- Complete backlog storage\n- Comprehensive summary\n\nThis ensures quality at both individual and system levels.\n\n## Common Orchestration Patterns\n\n### Pattern 1: Single Subagent (Simple)\n\n```\n/bmad:brief\n‚îú‚îÄ‚îÄ YOU: Gather project idea\n‚îú‚îÄ‚îÄ YOU: Launch @product-manager subagent\n‚îú‚îÄ‚îÄ @product-manager: Generate, validate, store brief\n‚îî‚îÄ‚îÄ YOU: Present summary\n```\n\n### Pattern 2: Sequential Subagents (Pipeline)\n\n```\n/bmad:start\n‚îú‚îÄ‚îÄ YOU: Gather idea\n‚îú‚îÄ‚îÄ @product-manager: Generate brief\n‚îú‚îÄ‚îÄ YOU: Transition\n‚îú‚îÄ‚îÄ @product-manager: Generate PRD\n‚îú‚îÄ‚îÄ YOU: Detect research needs\n‚îú‚îÄ‚îÄ @architect: Generate architecture\n‚îú‚îÄ‚îÄ YOU: Extract epic list\n‚îú‚îÄ‚îÄ @product-manager: Generate Epic 1\n‚îú‚îÄ‚îÄ @product-manager: Generate Epic 2\n‚îú‚îÄ‚îÄ @product-manager: Generate Epic 3\n‚îú‚îÄ‚îÄ @product-manager: Generate index\n‚îî‚îÄ‚îÄ YOU: Final summary\n```\n\n### Pattern 3: Parallel Subagents (Review)\n\n```\n/titanium:review\n‚îú‚îÄ‚îÄ YOU: Check for changes\n‚îú‚îÄ‚îÄ Launch in parallel (single message, multiple Task calls):\n‚îÇ   ‚îú‚îÄ‚îÄ @code-reviewer: Review code quality\n‚îÇ   ‚îú‚îÄ‚îÄ @security-scanner: Review security\n‚îÇ   ‚îî‚îÄ‚îÄ @tdd-specialist: Review test coverage\n‚îú‚îÄ‚îÄ YOU: Wait for all three to complete\n‚îú‚îÄ‚îÄ YOU: Aggregate findings\n‚îî‚îÄ‚îÄ YOU: Present consolidated report\n```\n\n### Pattern 4: Implementation Workflow (Complex)\n\n```\n/titanium:work\n‚îú‚îÄ‚îÄ YOU: Check for plan, create if needed\n‚îú‚îÄ‚îÄ YOU: Get user approval\n‚îú‚îÄ‚îÄ YOU: For each task (sequential):\n‚îÇ   ‚îú‚îÄ‚îÄ YOU: Parse task info (epic, story, task, agent)\n‚îÇ   ‚îú‚îÄ‚îÄ YOU: Launch appropriate subagent with task details\n‚îÇ   ‚îú‚îÄ‚îÄ Subagent: Implement, test, validate\n‚îÇ   ‚îú‚îÄ‚îÄ YOU: Run quality check (vibe-check)\n‚îÇ   ‚îî‚îÄ‚îÄ YOU: Mark task complete\n‚îú‚îÄ‚îÄ YOU: Launch parallel review agents\n‚îú‚îÄ‚îÄ YOU: Aggregate review findings\n‚îú‚îÄ‚îÄ YOU: Optionally fix critical issues\n‚îî‚îÄ‚îÄ YOU: Complete workflow, store in Pieces\n```\n\n## Agent-to-Skills Mapping\n\nEach subagent has access to relevant skills:\n\n**Planning Agents**:\n- @product-manager: bmad-methodology, project-planning\n- @project-planner: bmad-methodology, project-planning\n- @architect: bmad-methodology, api-best-practices, devops-patterns\n\n**Development Agents**:\n- @api-developer: api-best-practices, testing-strategy, security-checklist\n- @frontend-developer: frontend-patterns, testing-strategy, technical-writing\n- @devops-engineer: devops-patterns, security-checklist\n\n**Quality Agents**:\n- @code-reviewer: code-quality-standards, security-checklist, testing-strategy\n- @refactor: code-quality-standards, testing-strategy\n- @tdd-specialist: testing-strategy, code-quality-standards\n- @test-runner: testing-strategy, debugging-methodology\n- @security-scanner: security-checklist, code-quality-standards\n- @debugger: debugging-methodology, testing-strategy\n\n**Documentation Agents**:\n- @doc-writer: technical-writing, bmad-methodology\n- @api-documenter: technical-writing, api-best-practices\n\n**Specialized**:\n- @shadcn-ui-builder: frontend-patterns, technical-writing\n- @marketing-writer: technical-writing\n- @meta-agent: (no skills - needs flexibility)\n\n## MCP Tools: When Subagents Use Them\n\n### tt Server Tools\n\n**plan_parser**:\n- Used by: Slash command `/titanium:plan`\n- Called by: Orchestrator or planning subagent\n- Purpose: Requirements ‚Üí Implementation plan with tasks\n\n**bmad_generator**:\n- Used by: All BMAD slash commands\n- Called by: @product-manager, @architect subagents\n- Purpose: Generate comprehensive BMAD documents\n\n**bmad_validator**:\n- Used by: All BMAD slash commands\n- Called by: @product-manager, @architect subagents\n- Purpose: Validate document completeness\n\n**Other MCP Servers**:\n- vibe-check: Quality validation (used by orchestrator and subagents)\n- Pieces: Memory storage (used by orchestrator and subagents)\n- context7: Documentation lookup (used by subagents)\n- ElevenLabs: Voice announcements (used by hooks, not agents)\n\n## Best Practices for Orchestration\n\n### 1. Trust the Slash Command\n\nDon't second-guess the command prompts. They're carefully designed workflows.\n\n### 2. Pass Complete Context to Subagents\n\nWhen launching subagents, include in the Task prompt:\n- What they're building\n- Where input files are\n- What output is expected\n- Complete workflow steps\n- Which MCP tools to use\n- Which skills are relevant\n- Success criteria\n\n### 3. Don't Batch Results\n\nMark todos complete immediately after each task. Don't wait to batch updates.\n\n### 4. Handle Errors Gracefully\n\nIf a subagent fails:\n- Present error to user\n- Offer options (retry, skip, modify)\n- Guide user through resolution\n- Don't proceed if critical task failed\n\n### 5. Validate at Checkpoints\n\nSubagents validate their own work, but you also:\n- Run meta-validations (vibe-check) at phase transitions\n- Verify prerequisites before launching next phase\n- Confirm user approval at key points\n\n### 6. Store Milestones in Pieces\n\nAfter completing significant work:\n- Store results in Pieces\n- Include comprehensive summary\n- List all files created\n- Document key decisions\n- Enable future context recovery\n\n## Common Mistakes to Avoid\n\n### ‚ùå Doing Work Yourself\n\n**Wrong**:\n```\nUser: /bmad:prd\n\nYou:\n- Read brief\n- Generate PRD content manually\n- Write to file\n```\n\n**Right**:\n```\nUser: /bmad:prd\n\nYou:\n- Check brief exists\n- Launch @product-manager subagent\n- @product-manager generates PRD\n- Present product-manager's summary\n```\n\n### ‚ùå Calling MCP Tools Directly (When Subagent Should)\n\n**Wrong**:\n```\nYou call: mcp__plugin_titanium-toolkit_tt__bmad_generator(...)\n```\n\n**Right**:\n```\nYou launch: Task(prompt: \"... use bmad_generator MCP tool ...\", subagent_type: \"product-manager\")\n```\n\n### ‚ùå Batching Task Completions\n\n**Wrong**:\n```\nComplete tasks 1, 2, 3\nThen update TodoWrite\n```\n\n**Right**:\n```\nComplete task 1\nUpdate TodoWrite (mark task 1 complete)\nComplete task 2\nUpdate TodoWrite (mark task 2 complete)\n```\n\n### ‚ùå Proceeding Without User Approval\n\n**Wrong**:\n```\nGenerate plan\nImmediately start implementation\n```\n\n**Right**:\n```\nGenerate plan\nPresent plan to user\nAsk: \"Proceed with implementation?\"\nWait for explicit \"yes\"\nThen start implementation\n```\n\n### ‚ùå Ignoring vibe-check Concerns\n\n**Wrong**:\n```\nvibe-check raises concerns\nYou: \"Okay, continuing anyway...\"\n```\n\n**Right**:\n```\nvibe-check raises concerns\nYou: \"‚ö†Ô∏è vibe-check identified concerns: [list]\n     Would you like to address these or proceed anyway?\"\nWait for user decision\n```\n\n## Workflow State Management\n\nFor complex workflows (`/titanium:work`), you manage state:\n\n```bash\n# Initialize workflow\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py init \"$(pwd)\" \"development\" \"Goal\"\n\n# Update phase\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py update_phase \"$(pwd)\" \"implementation\" \"in_progress\"\n\n# Complete workflow\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py complete \"$(pwd)\"\n```\n\nThis tracks:\n- Current phase (planning, implementation, review, complete)\n- Phase status (pending, in_progress, completed)\n- Workflow goal\n- Start/end timestamps\n\n## Voice Announcements\n\nVoice hooks automatically announce:\n- Phase transitions\n- Tool completions\n- Subagent completions\n- Session summaries\n\nYou don't call voice tools - hooks handle this automatically.\n\n## Summary: Your Orchestration Checklist\n\nWhen executing a slash command:\n\n- [ ] Read and understand the complete slash command prompt\n- [ ] Check all prerequisites (files, API keys, user input)\n- [ ] Follow the command's delegation instructions exactly\n- [ ] Launch subagents via Task tool with detailed prompts\n- [ ] Wait for subagents to complete (don't do their work)\n- [ ] Present subagent results to user\n- [ ] Run meta-validations at checkpoints\n- [ ] Handle errors gracefully with clear guidance\n- [ ] Store milestones in Pieces\n- [ ] Guide user to next steps\n- [ ] Update todos immediately after each completion\n\n## When to Deviate from This Model\n\n**You CAN work directly** (without subagents) for:\n- Simple user questions (\"What does this code do?\")\n- Quick file reads or searches\n- Answering questions about the project\n- Running single bash commands\n- Simple edits or bug fixes\n\n**You MUST use subagents** for:\n- BMAD document generation (Brief, PRD, Architecture, Epics)\n- Implementation tasks in `/titanium:work`\n- Code reviews in `/titanium:review`\n- Any work assigned to specific agent types in plans\n- Complex multi-step workflows\n\n## Next Steps\n\nNow that you understand the orchestration model:\n\n1. **Execute slash commands faithfully** - They're your detailed scripts\n2. **Delegate to specialized subagents** - Trust their expertise\n3. **Use MCP tools via subagents** - Not directly\n4. **Leverage skills** - Subagents have deep domain knowledge\n5. **Coordinate, don't create** - You orchestrate, they perform\n\n---\n\n**Remember**: You are the conductor of a specialized team. Your job is to coordinate their expertise, not to replace it. Follow the slash command scripts, delegate effectively, and present results clearly.\n\n**The Titanium Toolkit turns Claude Code into an AI development team with you as the orchestrator!**"
              },
              {
                "name": "/titanium-plan",
                "description": "Analyze requirements and create detailed implementation plan",
                "path": "plugins/titanium-toolkit/commands/titanium-plan.md",
                "frontmatter": {
                  "description": "Analyze requirements and create detailed implementation plan"
                },
                "content": "# Titanium Plan Command\n\nYou are creating a structured implementation plan from requirements. Follow this systematic process to break down work into actionable tasks with agent assignments.\n\n**MCP Tools Used**: This command uses the `tt` MCP server (Titanium Toolkit) which provides:\n- `mcp__plugin_titanium-toolkit_tt__plan_parser` - Generates structured implementation plans from requirements\n\nThe `tt` server wraps Python utilities that use Claude AI to analyze requirements and create detailed project plans with task-to-agent assignments.\n\n**Agent Assignment**: The plan_parser automatically assigns tasks to appropriate specialized agents based on task type (API work ‚Üí @api-developer, UI work ‚Üí @frontend-developer, etc.). These assignments are used by `/titanium:work` to delegate implementation.\n\n## Process Overview\n\nThis command will:\n1. Gather and validate requirements\n2. Use Claude (via `plan_parser` MCP tool) to generate structured plan\n3. Validate plan with vibe-check\n4. Create human-readable documentation\n5. Store plan in Pieces for future reference\n\n## Step 1: Gather Requirements\n\n**If user provides a file path:**\n```bash\n# User might say: /titanium:plan ~/bmad/output/user-auth-prd.md\n```\n- Use Read tool to read the file\n- Extract requirements text\n\n**If user provides inline description:**\n```bash\n# User might say: /titanium:plan\n# Then describe: \"I need to add JWT authentication with login, register, password reset\"\n```\n- Write description to `.titanium/requirements.md` using Write tool\n- Ask clarifying questions if needed:\n  - What tech stack? (Node.js, Python, Ruby, etc.)\n  - What database? (PostgreSQL, MongoDB, etc.)\n  - Any specific libraries or frameworks?\n  - Security requirements?\n  - Performance requirements?\n\n## Step 2: Generate Structured Plan\n\nUse the `plan_parser` MCP tool to generate the plan:\n\n```\nmcp__plugin_titanium-toolkit_tt__plan_parser(\n  requirements_file: \".titanium/requirements.md\",\n  project_path: \"$(pwd)\"\n)\n```\n\nThis will:\n- Call Claude with the requirements\n- Generate structured JSON plan with:\n  - Epics (major features)\n  - Stories (user-facing functionality)\n  - Tasks (implementation steps)\n  - Agent assignments\n  - Time estimates\n  - Task dependencies\n- Save to `.titanium/plan.json`\n- Return the JSON plan directly to Claude\n\n**Important**: The plan_parser tool needs ANTHROPIC_API_KEY environment variable. If it fails with an API key error, inform the user they need to add it to ~/.env\n\n## Step 3: Review the Generated Plan\n\nRead and analyze `.titanium/plan.json`:\n\n```bash\n# Read the plan\nRead .titanium/plan.json\n```\n\nCheck that the plan:\n- Has reasonable epics (1-5 major features)\n- Each epic has logical stories (1-5 per epic)\n- Each story has actionable tasks (2-10 per story)\n- Agent assignments are appropriate\n- Time estimates seem realistic\n- Dependencies make sense\n\n**Common issues to watch for:**\n- Tasks assigned to wrong agents (e.g., frontend work to @api-developer)\n- Missing testing tasks\n- Missing documentation tasks\n- Unrealistic time estimates\n- Circular dependencies\n\nIf the plan needs adjustments:\n- Edit `.titanium/requirements.md` to add clarifications\n- Re-run the `plan_parser` tool\n- Review again\n\n## Step 4: Validate Plan with vibe-check\n\nUse vibe-check to validate the plan quality:\n\n```\nmcp__vibe-check__vibe_check(\n  goal: \"User's stated goal from requirements\",\n  plan: \"Summary of the generated plan - list epics, key stories, agents involved, total time\",\n  uncertainties: [\n    \"List any concerns about complexity\",\n    \"Note any ambiguous requirements\",\n    \"Mention any technical risks\"\n  ]\n)\n```\n\n**Example**:\n```\nmcp__vibe-check__vibe_check(\n  goal: \"Implement JWT authentication system with login, register, and password reset\",\n  plan: \"2 epics: Backend API (JWT middleware, 3 endpoints, database) and Frontend UI (login/register forms, password reset flow). Agents: @product-manager, @api-developer, @frontend-developer, @test-runner, @security-scanner. Total: 4 hours\",\n  uncertainties: [\n    \"Should we use refresh tokens or just access tokens?\",\n    \"Password hashing algorithm not specified - suggest argon2\",\n    \"Rate limiting strategy needs clarification\"\n  ]\n)\n```\n\n**Handle vibe-check response:**\n- If vibe-check raises **concerns**:\n  - Review the concerns carefully\n  - Update requirements or plan approach\n  - Re-run the `plan_parser` tool with adjustments\n  - Validate again with vibe-check\n- If vibe-check **approves**:\n  - Continue to next step\n\n## Step 5: Create Human-Readable Plan\n\nWrite a markdown version of the plan to `.titanium/plan.md`:\n\n```markdown\n# Implementation Plan: [Project Goal]\n\n**Created**: [Date]\n**Estimated Time**: [Total time from plan.json]\n\n## Goal\n[User's goal statement]\n\n## Tech Stack\n[List technologies mentioned in requirements]\n\n## Epics\n\n### Epic 1: [Epic Name]\n**Description**: [Epic description]\n**Estimated Time**: [Sum of all story times]\n\n#### Story 1.1: [Story Name]\n**Description**: [Story description]\n**Tasks**:\n1. [Task 1 name] - [@agent-name] - [time estimate]\n2. [Task 2 name] - [@agent-name] - [time estimate]\n\n#### Story 1.2: [Story Name]\n**Description**: [Story description]\n**Tasks**:\n1. [Task 1 name] - [@agent-name] - [time estimate]\n2. [Task 2 name] - [@agent-name] - [time estimate]\n\n### Epic 2: [Epic Name]\n[... repeat structure ...]\n\n## Agents Involved\n- **@product-manager**: Requirements validation\n- **@api-developer**: Backend implementation\n- **@frontend-developer**: UI development\n- **@test-runner**: Testing\n- **@doc-writer**: Documentation\n\n## Dependencies\n[List any major dependencies between epics/stories]\n\n## Next Steps\nReady to execute? Run: `/titanium:work`\n```\n\n## Step 6: Store Plan in Pieces\n\nStore the plan in Pieces LTM for future reference:\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Implementation plan for [project name/goal]\",\n  summary: \"Plan created with [X] epics, [Y] stories, [Z] tasks. Agents: [list agents]. Estimated time: [total time]. Key features: [brief list of main epics]. vibe-check validation: [summary of validation results]\",\n  files: [\n    \".titanium/plan.json\",\n    \".titanium/plan.md\",\n    \".titanium/requirements.md\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n**Example**:\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Implementation plan for JWT authentication system\",\n  summary: \"Plan created with 2 epics, 5 stories, 12 tasks. Agents: @product-manager, @api-developer, @frontend-developer, @test-runner, @security-scanner. Estimated time: 4 hours. Key features: JWT middleware with refresh tokens, login/register/reset endpoints, frontend auth forms, comprehensive testing. vibe-check validation: Plan structure is sound, recommended argon2 for password hashing, suggested rate limiting on auth endpoints.\",\n  files: [\n    \".titanium/plan.json\",\n    \".titanium/plan.md\",\n    \".titanium/requirements.md\"\n  ],\n  project: \"/Users/username/projects/my-app\"\n)\n```\n\n## Step 7: Present Plan to User\n\nFormat the output in a clear, organized way:\n\n```\nüìã Implementation Plan Created\n\nüéØ Goal: [User's goal]\n\nüì¶ Structure:\n- [X] epics\n- [Y] stories\n- [Z] implementation tasks\n\n‚è±Ô∏è  Estimated Time: [total time]\n\nü§ñ Agents Involved:\n- @agent-name (role description)\n- @agent-name (role description)\n- [... list all agents ...]\n\nüìÅ Plan saved to:\n- .titanium/plan.json (structured data)\n- .titanium/plan.md (readable format)\n\n‚úÖ vibe-check validated: [Brief summary of validation results]\n\nüìù Key Epics:\n1. [Epic 1 name] - [time estimate]\n2. [Epic 2 name] - [time estimate]\n[... list all epics ...]\n\n---\n\nReady to execute this plan?\n\nRun: /titanium:work\n\nThis will orchestrate the implementation using the plan,\nwith voice announcements and quality gates throughout.\n```\n\n## Important Guidelines\n\n**Always:**\n- ‚úÖ Use the `plan_parser` MCP tool (don't try to generate plans manually)\n- ‚úÖ Validate with vibe-check before finalizing\n- ‚úÖ Store the plan in Pieces\n- ‚úÖ Create both JSON (for machines) and Markdown (for humans)\n- ‚úÖ Get user approval before they proceed to /titanium:work\n- ‚úÖ Be specific about agent roles in the summary\n\n**Never:**\n- ‚ùå Skip vibe-check validation\n- ‚ùå Generate plans without using the `plan_parser` tool\n- ‚ùå Proceed to implementation without user approval\n- ‚ùå Ignore vibe-check concerns\n- ‚ùå Create plans without clear task assignments\n\n## Error Handling\n\n**If ANTHROPIC_API_KEY is missing:**\n```\nError: The plan_parser tool needs an Anthropic API key to generate plans.\n\nPlease add your API key to ~/.env:\n  echo 'ANTHROPIC_API_KEY=sk-ant-your-key-here' >> ~/.env\n  chmod 600 ~/.env\n\nThen restart Claude Code and try again.\n```\n\n**If vibe-check is not available:**\n```\nWarning: vibe-check MCP is not available. Proceeding without quality validation.\n\nConsider setting up vibe-check for AI-powered quality gates:\n  1. Create ~/.vibe-check/.env\n  2. Add at least one API key (GEMINI_API_KEY, OPENAI_API_KEY, or OPENROUTER_API_KEY)\n  3. Restart Claude Code\n```\n\n**If requirements are unclear:**\n```\nThe requirements need more detail. Let me ask some questions:\n\n1. [Specific question about tech stack]\n2. [Specific question about features]\n3. [Specific question about constraints]\n\nOnce I have this information, I'll create a detailed plan.\n```\n\n**If plan generation fails:**\n```\nThe plan generation failed. This could be due to:\n- Invalid requirements format\n- API rate limits\n- Network issues\n\nLet me try again with simplified requirements.\n[Retry with more basic prompt]\n```\n\n## Example Usage\n\n**Example 1: With BMAD PRD file**\n```\nUser: /titanium:plan ~/bmad/output/user-auth-prd.md\n\nClaude:\n- Reads PRD file\n- Calls plan_parser tool\n- Reviews generated plan\n- Validates with vibe-check\n- Creates plan.md\n- Stores in Pieces\n- Presents formatted summary to user\n```\n\n**Example 2: With inline description**\n```\nUser: /titanium:plan\n\nClaude: \"What would you like to implement?\"\n\nUser: \"Add a search feature to filter products by name and category\"\n\nClaude:\n- Writes description to .titanium/requirements.md\n- Asks: \"What's your tech stack?\"\nUser: \"React frontend, Node.js backend with PostgreSQL\"\n- Calls plan_parser tool with complete requirements\n- Generates plan with appropriate tech stack\n- Validates with vibe-check\n- Presents plan to user\n```\n\n**Example 3: Complex feature with multiple clarifications**\n```\nUser: /titanium:plan \"Build a payment processing system\"\n\nClaude: \"I need more details:\n1. Which payment provider? (Stripe, PayPal, etc.)\n2. What types of payments? (One-time, subscriptions, both?)\n3. Currency support? (Single, multiple?)\n4. Security requirements? (PCI compliance needed?)\n5. Refund handling?\"\n\nUser: \"Stripe, one-time payments only, USD, yes PCI compliance, yes refunds\"\n\nClaude:\n- Writes complete requirements\n- Generates comprehensive plan\n- vibe-check raises concern about PCI compliance complexity\n- Adjusts plan to include @security-scanner more heavily\n- Re-validates with vibe-check\n- Presents approved plan\n```\n\n## Voice Feedback\n\nThe voice hooks will automatically announce:\n- \"Starting plan generation\" (when script is called)\n- \"Plan created with [X] epics\" (when complete)\n- \"vibe-check validation complete\" (after validation)\n\nNo additional voice calls needed - the hooks handle this automatically.\n\n## Next Command\n\nAfter creating the plan, the user should run:\n```\n/titanium:work\n```\n\nThis will execute the plan with orchestrated agent coordination."
              },
              {
                "name": "/titanium-review",
                "description": "Run comprehensive multi-agent quality review",
                "path": "plugins/titanium-toolkit/commands/titanium-review.md",
                "frontmatter": {
                  "description": "Run comprehensive multi-agent quality review"
                },
                "content": "# Titanium Review Command\n\nYou are coordinating a comprehensive quality review of the codebase. This command launches multiple specialized review agents in parallel, aggregates their findings, and creates a detailed review report.\n\n**Orchestration Model**: You launch 3 review agents simultaneously in separate context windows. Each agent has specialized skills and reviews from their domain expertise. They run in parallel for efficiency.\n\n**Review Agents & Their Skills**:\n- @code-reviewer: code-quality-standards, security-checklist, testing-strategy\n- @security-scanner: security-checklist, code-quality-standards\n- @tdd-specialist: testing-strategy, code-quality-standards\n\n**Why Parallel**: Review agents are independent - they don't need each other's results. Running in parallel saves 60-70% time compared to sequential reviews.\n\n## Overview\n\nThis review process:\n1. Identifies what code to review\n2. Launches 3 review agents in parallel (single message, multiple Task calls)\n3. Aggregates and categorizes findings from all agents\n4. Uses vibe-check for meta-review\n5. Creates comprehensive review report\n6. Stores findings in Pieces LTM\n7. Presents actionable summary with severity-based recommendations\n\n---\n\n## Step 1: Identify Review Scope\n\n### Determine What to Review\n\n**Option A: Recent Changes** (default)\n```bash\ngit diff --name-only HEAD~1\n```\nReviews files changed in last commit.\n\n**Option B: Current Branch Changes**\n```bash\ngit diff --name-only main...HEAD\n```\nReviews all changes in current branch vs main.\n\n**Option C: Specific Files** (if user specified)\n```bash\n# User might say: /titanium:review src/api/*.ts\n```\nUse the files/pattern user specified.\n\n**Option D: All Code** (if user requested)\n```bash\n# Find all source files\nfind . -type f \\( -name \"*.ts\" -o -name \"*.js\" -o -name \"*.py\" -o -name \"*.rb\" \\) -not -path \"*/node_modules/*\" -not -path \"*/venv/*\"\n```\n\n### Build File List\n\nCreate list of files to review. Store in memory for agent prompts.\n\n**Example**:\n```\nFiles to review:\n- src/api/auth.ts\n- src/middleware/jwt.ts\n- src/routes/users.ts\n- tests/api/auth.test.ts\n```\n\n---\n\n## Step 2: Launch Review Agents in Parallel\n\n**CRITICAL**: Launch all three agents in a **SINGLE message** with multiple Task calls.\n\nThis enables parallel execution for faster reviews.\n\n### Agent 1: Code Reviewer\n\n```\n[Task 1]: @code-reviewer\nPrompt: \"Review all code changes for quality, readability, and best practices.\n\nFocus on:\n- Code quality and maintainability\n- DRY principles\n- SOLID principles\n- Error handling\n- Code organization\n- Comments and documentation\n\nFiles to review: [list all modified files]\n\nProvide findings categorized by severity:\n- Critical: Must fix before deployment\n- Important: Should fix soon\n- Nice-to-have: Optional improvements\n\nFor each finding, specify:\n- File and line number\n- Issue description\n- Recommendation\"\n```\n\n### Agent 2: Security Scanner\n\n```\n[Task 2]: @security-scanner\nPrompt: \"Scan for security vulnerabilities and security best practices.\n\nFocus on:\n- Input validation\n- SQL injection risks\n- XSS vulnerabilities\n- Authentication/authorization issues\n- Secrets in code\n- Dependency vulnerabilities\n- HTTPS enforcement\n- Rate limiting\n\nFiles to review: [list all modified files]\n\nProvide findings with:\n- Severity (Critical/High/Medium/Low)\n- Vulnerability type\n- File and line number\n- Risk description\n- Remediation steps\n\nSeverity mapping for aggregation:\n- Critical ‚Üí Critical (must fix)\n- High ‚Üí Important (should fix)\n- Medium ‚Üí Nice-to-have (optional)\n- Low ‚Üí Nice-to-have (optional)\"\n```\n\n### Agent 3: Test Coverage Specialist\n\n```\n[Task 3]: @tdd-specialist\nPrompt: \"Check test coverage and test quality.\n\nFocus on:\n- Test coverage percentage\n- Edge cases covered\n- Integration tests\n- Unit tests\n- E2E tests (if applicable)\n- Test quality and assertions\n- Mock usage\n- Test organization\n\nFiles to review: [list all test files and source files]\n\nProvide findings on:\n- Coverage gaps\n- Missing test cases\n- Test quality issues\n- Recommendations for improvement\"\n```\n\n---\n\n## Step 3: Wait for All Agents\n\nAll three agents will run in parallel. Wait for all to complete before proceeding.\n\nVoice hooks will announce: \"Review agents completed\"\n\n---\n\n## Step 4: Aggregate Findings\n\n### Collect All Findings\n\nGather results from all three agents:\n- Code quality findings from @code-reviewer\n- Security findings from @security-scanner\n- Test coverage findings from @tdd-specialist\n\n### Categorize by Severity\n\n**üî¥ Critical Issues** (must fix before deployment):\n- Security vulnerabilities (Critical/High)\n- Code that will cause bugs or crashes\n- Core functionality with no tests\n\n**üü° Important Issues** (should fix soon):\n- Security issues (Medium)\n- Code quality problems that impact maintainability\n- Important features with incomplete tests\n- Performance issues\n\n**üü¢ Nice-to-have** (optional improvements):\n- Code style improvements\n- Refactoring opportunities\n- Additional test coverage\n- Documentation gaps\n\n### Count Issues\n\n```\nTotal findings:\n- Critical: [X]\n- Important: [Y]\n- Nice-to-have: [Z]\n\nBy source:\n- Code quality: [N] findings\n- Security: [M] findings\n- Test coverage: [P] findings\n```\n\n---\n\n## Step 5: Meta-Review with vibe-check\n\nUse vibe-check to provide AI oversight of the review:\n\n```\nmcp__vibe-check__vibe_check(\n  goal: \"Quality review of codebase changes\",\n  plan: \"Ran parallel review: @code-reviewer, @security-scanner, @tdd-specialist\",\n  progress: \"Review complete. Findings: [X] critical, [Y] important, [Z] minor.\n\nCritical issues found:\n[List each critical issue briefly]\n\nImportant issues found:\n[List each important issue briefly]\n\nTest coverage: approximately [X]%\",\n  uncertainties: [\n    \"Are there systemic quality issues we're missing?\",\n    \"Is the security approach sound?\",\n    \"Are we testing the right things?\",\n    \"Any architectural concerns?\"\n  ]\n)\n```\n\n**Process vibe-check response**:\n- If vibe-check identifies systemic issues ‚Üí Include in recommendations\n- If vibe-check suggests additional areas to review ‚Üí Note in report\n- Include vibe-check insights in final report\n\n---\n\n## Step 6: Create Review Report\n\nWrite comprehensive report to `.titanium/review-report.md`:\n\n```markdown\n# Quality Review Report\n\n**Date**: [current date and time]\n**Project**: [project name or goal if known]\n**Reviewers**: @code-reviewer, @security-scanner, @tdd-specialist\n\n## Executive Summary\n\n- üî¥ Critical issues: [X]\n- üü° Important issues: [Y]\n- üü¢ Nice-to-have: [Z]\n- üìä Test coverage: ~[X]%\n\n**Overall Assessment**: [Brief 1-2 sentence assessment]\n\n---\n\n## Critical Issues üî¥\n\n### 1. [Issue Title]\n\n**Category**: [Code Quality | Security | Testing]\n**File**: `path/to/file.ext:line`\n**Severity**: Critical\n\n**Issue**:\n[Clear description of what's wrong]\n\n**Risk/Impact**:\n[Why this is critical]\n\n**Recommendation**:\n```[language]\n// Show example fix if applicable\n[code example]\n```\n\n**Steps to Fix**:\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\n---\n\n### 2. [Next Critical Issue]\n[... repeat structure ...]\n\n---\n\n## Important Issues üü°\n\n### 1. [Issue Title]\n\n**Category**: [Code Quality | Security | Testing]\n**File**: `path/to/file.ext:line`\n**Severity**: Important\n\n**Issue**:\n[Description]\n\n**Impact**:\n[Why this matters]\n\n**Recommendation**:\n[How to address it]\n\n---\n\n### 2. [Next Important Issue]\n[... repeat structure ...]\n\n---\n\n## Nice-to-have Improvements üü¢\n\n### Code Quality\n- [Improvement 1 with file reference]\n- [Improvement 2 with file reference]\n\n### Testing\n- [Test improvement 1]\n- [Test improvement 2]\n\n### Documentation\n- [Doc improvement 1]\n- [Doc improvement 2]\n\n---\n\n## Test Coverage Analysis\n\n**Overall Coverage**: ~[X]%\n\n**Files with Insufficient Coverage** (<80%):\n- `file1.ts` - ~[X]% coverage\n- `file2.ts` - ~[Y]% coverage\n\n**Untested Critical Functions**:\n- `functionName()` in file.ts:line\n- `anotherFunction()` in file.ts:line\n\n**Missing Test Categories**:\n- [ ] Error condition tests\n- [ ] Edge case tests\n- [ ] Integration tests\n- [ ] E2E tests for critical flows\n\n**Recommendations**:\n1. [Priority test to add]\n2. [Second priority test]\n3. [Third priority test]\n\n---\n\n## Security Analysis\n\n**Vulnerabilities Found**: [X]\n**Security Best Practices Violations**: [Y]\n\n**Key Security Concerns**:\n1. [Concern 1]\n2. [Concern 2]\n\n**Security Recommendations**:\n1. [Priority 1 security fix]\n2. [Priority 2 security fix]\n\n---\n\n## vibe-check Meta-Review\n\n[Paste vibe-check assessment here]\n\n**Systemic Issues Identified**:\n[Any patterns or systemic problems vibe-check identified]\n\n**Additional Recommendations**:\n[Any suggestions from vibe-check that weren't captured by agents]\n\n---\n\n## Recommendations Priority List\n\n### Must Do (Critical):\n1. [Critical fix 1] - File: `path/to/file.ext:line`\n2. [Critical fix 2] - File: `path/to/file.ext:line`\n\n### Should Do (Important):\n1. [Important fix 1] - File: `path/to/file.ext:line`\n2. [Important fix 2] - File: `path/to/file.ext:line`\n3. [Important fix 3] - File: `path/to/file.ext:line`\n\n### Nice to Do (Optional):\n1. [Optional improvement 1]\n2. [Optional improvement 2]\n\n---\n\n## Files Reviewed\n\nTotal files: [X]\n\n**Source Files** ([N] files):\n- path/to/file1.ext\n- path/to/file2.ext\n\n**Test Files** ([M] files):\n- path/to/test1.test.ext\n- path/to/test2.test.ext\n\n---\n\n## Next Steps\n\n1. Address all critical issues immediately\n2. Plan to fix important issues in next sprint\n3. Consider nice-to-have improvements for tech debt backlog\n4. Re-run review after fixes: `/titanium:review`\n```\n\n---\n\n## Step 7: Store Review in Pieces\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Quality review findings for [project/files]\",\n  summary: \"Comprehensive quality review completed by @code-reviewer, @security-scanner, @tdd-specialist.\n\nFindings:\n- Critical issues: [X] - [briefly list each critical issue]\n- Important issues: [Y] - [briefly describe categories]\n- Nice-to-have: [Z]\n\nTest coverage: approximately [X]%\n\nSecurity assessment: [summary - no vulnerabilities / minor issues / concerns found]\n\nCode quality assessment: [summary - excellent / good / needs improvement]\n\nvibe-check meta-review: [brief summary of vibe-check insights]\n\nKey recommendations:\n1. [Top priority recommendation]\n2. [Second priority]\n3. [Third priority]\n\nAll findings documented in .titanium/review-report.md with file:line references and fix recommendations.\",\n  files: [\n    \".titanium/review-report.md\",\n    \"list all reviewed source files\",\n    \"list all test files\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n---\n\n## Step 8: Present Summary to User\n\n```\nüîç Quality Review Complete\n\nüìä Summary:\n- üî¥ [X] Critical Issues\n- üü° [Y] Important Issues\n- üü¢ [Z] Nice-to-have Improvements\n- üìà Test Coverage: ~[X]%\n\nüìÑ Full Report: .titanium/review-report.md\n\n---\n\n‚ö†Ô∏è  Critical Issues (must fix):\n\n1. [Issue 1 title]\n   File: `path/to/file.ext:line`\n   [Brief description]\n\n2. [Issue 2 title]\n   File: `path/to/file.ext:line`\n   [Brief description]\n\n[... list all critical issues ...]\n\n---\n\nüí° Top Recommendations:\n\n1. [Priority 1 action item]\n2. [Priority 2 action item]\n3. [Priority 3 action item]\n\n---\n\nü§ñ vibe-check Assessment:\n[Brief quote or summary from vibe-check]\n\n---\n\nWould you like me to:\n1. Fix the critical issues now\n2. Create GitHub issues for these findings\n3. Provide more details on any specific issue\n4. Skip and continue (not recommended if critical issues exist)\n```\n\n### Handle User Response\n\n**If user wants fixes**:\n- Address critical issues one by one\n- After each fix, run relevant tests\n- Re-run review to verify fixes\n- Update review report\n\n**If user wants GitHub issues**:\n- Create issues for each critical and important finding\n- Include all details from review report\n- Provide issue URLs\n\n**If user wants more details**:\n- Read specific sections of review report\n- Explain the issue and fix in more detail\n\n**If user says continue**:\n- Acknowledge and complete\n- Remind that issues are documented in review report\n\n---\n\n## Error Handling\n\n### If No Files to Review\n\n```\n‚ö†Ô∏è  No files found to review.\n\nThis could mean:\n- No changes since last commit\n- Working directory is clean\n- Specified files don't exist\n\nWould you like to:\n1. Review all source files\n2. Specify which files to review\n3. Cancel review\n```\n\n### If Review Agents Fail\n\n```\n‚ùå Review failed\n\nAgent @[agent-name] encountered an error: [error]\n\nContinuing with other review agents...\n\n[Proceed with available results]\n```\n\n### If vibe-check Not Available\n\n```\nNote: vibe-check MCP is not available. Proceeding without meta-review.\n\nTo enable AI-powered meta-review:\n1. Create ~/.vibe-check/.env\n2. Add API key (GEMINI_API_KEY, OPENAI_API_KEY, or OPENROUTER_API_KEY)\n3. Restart Claude Code\n```\n\n---\n\n## Integration with Workflow\n\n**After /titanium:work**:\n```\nUser: /titanium:work\n[... implementation completes ...]\nUser: /titanium:review\n[... review runs ...]\n```\n\n**Standalone Usage**:\n```\nUser: /titanium:review\n# Reviews recent changes\n```\n\n**With File Specification**:\n```\nUser: /titanium:review src/api/*.ts\n# Reviews only specified files\n```\n\n**Before Committing**:\n```\nUser: I'm about to commit. Can you review my changes?\nClaude: /titanium:review\n[... review runs on uncommitted changes ...]\n```\n\n---\n\n## Voice Feedback\n\nVoice hooks automatically announce:\n- \"Starting quality review\" (at start)\n- \"Review agents completed\" (after parallel execution)\n- \"Review complete: [X] issues found\" (at end)\n\nNo additional voice calls needed.\n\n---\n\n## Example Outputs\n\n### Example 1: No Issues Found\n\n```\nüîç Quality Review Complete\n\nüìä Summary:\n- üî¥ 0 Critical Issues\n- üü° 0 Important Issues\n- üü¢ 3 Nice-to-have Improvements\n- üìà Test Coverage: ~92%\n\n‚úÖ No critical or important issues found!\n\nüí° Optional Improvements:\n1. Consider extracting duplicated validation logic in auth.ts and users.ts\n2. Add JSDoc comments to public API methods\n3. Increase test coverage for edge cases in payment module\n\nCode quality: Excellent\nSecurity: No vulnerabilities found\nTesting: Comprehensive coverage\n\nüìÑ Full details: .titanium/review-report.md\n```\n\n### Example 2: Critical Issues Found\n\n```\nüîç Quality Review Complete\n\nüìä Summary:\n- üî¥ 2 Critical Issues\n- üü° 5 Important Issues\n- üü¢ 12 Nice-to-have Improvements\n- üìà Test Coverage: ~65%\n\n‚ö†Ô∏è  CRITICAL ISSUES (must fix):\n\n1. SQL Injection Vulnerability\n   File: `src/api/users.ts:45`\n   User input concatenated directly into SQL query\n   Risk: Attacker could read/modify database\n\n2. Missing Authentication Check\n   File: `src/api/admin.ts:23`\n   Admin endpoint has no auth middleware\n   Risk: Unauthorized access to admin functions\n\nüí° MUST DO:\n1. Use parameterized queries for all SQL\n2. Add authentication middleware to admin routes\n3. Add tests for authentication flows\n\nWould you like me to fix these critical issues now?\n```\n\n---\n\n**This command provides comprehensive multi-agent quality review with actionable findings and clear priorities.**"
              },
              {
                "name": "/titanium-status",
                "description": "Show current workflow progress and status",
                "path": "plugins/titanium-toolkit/commands/titanium-status.md",
                "frontmatter": {
                  "description": "Show current workflow progress and status"
                },
                "content": "# Titanium Status Command\n\nYou are reporting on the current workflow state and progress. This command provides a comprehensive view of where the project stands, what's been completed, and what's remaining.\n\n## Overview\n\nThis command will:\n1. Check for active workflow state\n2. Query Pieces for recent work\n3. Analyze TodoWrite progress (if available)\n4. Check for existing plan\n5. Calculate progress metrics\n6. Present formatted status report\n7. Optionally provide voice summary\n\n---\n\n## Step 1: Check for Active Workflow\n\n### Check Workflow State File\n\n```bash\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py get \"$(pwd)\"\n```\n\n**If workflow exists**:\n- Parse the JSON response\n- Extract:\n  - workflow_type\n  - goal\n  - status (planning/in_progress/completed/failed)\n  - current_phase\n  - started_at timestamp\n  - phases history\n\n**If no workflow exists**:\n- Report: \"No active workflow found in this project\"\n- Check for plan anyway (might be planning only)\n- Query Pieces for any previous work\n\n---\n\n## Step 2: Query Pieces for Context\n\nUse Pieces LTM to get recent work history:\n\n```\nmcp__Pieces__ask_pieces_ltm(\n  question: \"What work has been done in the last session on this project at [current directory]? What was being worked on? What was completed? What was left unfinished?\",\n  chat_llm: \"claude-sonnet-4-5\",\n  topics: [\"workflow\", \"implementation\", \"development\"],\n  application_sources: [\"Code\"]\n)\n```\n\n**Extract from Pieces**:\n- Recent activities\n- What was completed\n- What's in progress\n- Any issues encountered\n- Last known state\n\n---\n\n## Step 3: Check for Plan\n\n```bash\n# Check if plan exists\nls .titanium/plan.json\n```\n\n**If plan exists**:\n- Read `.titanium/plan.json`\n- Extract:\n  - Total epics count\n  - Total stories count\n  - Total tasks count\n  - Estimated total time\n  - List of agents needed\n\n**Calculate progress** (if TodoWrite is available):\n- Count completed tasks vs total tasks\n- Calculate percentage complete\n- Identify current task (first pending task)\n\n---\n\n## Step 4: Analyze TodoWrite Progress (if in active session)\n\n**Note**: TodoWrite state is session-specific. This step only works if we're in the same session that created the workflow.\n\nIf TodoWrite is available in current session:\n- Count total tasks\n- Count completed tasks\n- Count pending tasks\n- Identify current task (first in_progress task)\n- Calculate progress percentage\n\nIf TodoWrite not available:\n- Use plan.json task count as reference\n- Note: \"Progress tracking available only during active session\"\n\n---\n\n## Step 5: Calculate Metrics\n\n### Progress Metrics\n\n**Overall Progress**:\n```\nprogress_percentage = (completed_tasks / total_tasks) * 100\n```\n\n**Time Metrics**:\n```\nelapsed_time = current_time - workflow.started_at\nremaining_tasks = total_tasks - completed_tasks\navg_time_per_task = elapsed_time / completed_tasks (if > 0)\nestimated_remaining = avg_time_per_task * remaining_tasks\n```\n\n**Phase Progress**:\n- Identify which phase is active\n- List completed phases with timestamps\n- Show phase transition history\n\n---\n\n## Step 6: Present Status Report\n\n### Format: Comprehensive Status\n\n```\nüìä Titanium Workflow Status\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nüéØ Goal: [workflow.goal]\n\nüìç Current Phase: [current_phase]\n   Status: [status emoji] [status]\n\n‚è±Ô∏è  Timeline:\n   Started: [formatted timestamp] ([X] hours/days ago)\n   [If completed: Completed: [timestamp]]\n   [If in progress: Elapsed: [duration]]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüìà Progress: [X]% Complete\n\n‚úÖ Completed: [X] tasks\n‚è≥ Pending: [Y] tasks\nüîÑ Current: [current task name if known]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüì¶ Project Structure:\n   Epics: [X]\n   Stories: [Y]\n   Tasks: [Z]\n   Total Estimated Time: [time]\n\nü§ñ Agents Used/Planned:\n   [List agents with their roles]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüìù Recent Work (from Pieces):\n\n[Summary from Pieces query - what was done recently]\n\nKey Accomplishments:\n- [Item 1]\n- [Item 2]\n- [Item 3]\n\nCurrent Focus:\n[What's being worked on now or what's next]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüîÑ Phase History:\n\n1. ‚úÖ Planning - Completed ([duration])\n2. üîÑ Implementation - In Progress (started [time ago])\n3. ‚è≥ Review - Pending\n4. ‚è≥ Completion - Pending\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n‚è∞ Time Estimates:\n\nElapsed: [duration]\nEst. Remaining: [duration] (based on current pace)\nOriginal Estimate: [total from plan]\n\n[If ahead/behind schedule: [emoji] [X]% [ahead/behind] schedule]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüìÅ Key Files:\n\nCreated/Modified:\n[List from Pieces or plan if available]\n\nConfiguration:\n- Plan: .titanium/plan.json\n- State: .titanium/workflow-state.json\n[If exists: - Review: .titanium/review-report.md]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüí° Next Steps:\n\n[Based on current state, suggest what should happen next]\n\n1. [Next action item]\n2. [Second action item]\n3. [Third action item]\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüîä Voice Summary Available\nSay \"yes\" for voice summary of current status\n```\n\n---\n\n## Step 7: Status Variations by Phase\n\n### If Phase: Planning\n\n```\nüìä Status: Planning Phase\n\nüéØ Goal: [goal]\n\nCurrent Activity:\n- Analyzing requirements\n- Generating implementation plan\n- Validating with vibe-check\n\nNext: Implementation phase will begin after plan approval\n```\n\n### If Phase: Implementation\n\n```\nüìä Status: Implementation In Progress\n\nüéØ Goal: [goal]\n\nProgress: [X]% ([completed]/[total] tasks)\n\nCurrent Task: [task name]\nAgent: [current agent]\n\nRecently Completed:\n- [Task 1] by @agent-1\n- [Task 2] by @agent-2\n- [Task 3] by @agent-3\n\nUp Next:\n- [Next task 1]\n- [Next task 2]\n\nEstimated Remaining: [time]\n```\n\n### If Phase: Review\n\n```\nüìä Status: Quality Review Phase\n\nüéØ Goal: [goal]\n\nImplementation: ‚úÖ Complete ([X] tasks finished)\n\nCurrent Activity:\n- Running quality review\n- @code-reviewer analyzing code\n- @security-scanner checking vulnerabilities\n- @tdd-specialist reviewing tests\n\nNext: Address review findings, then complete workflow\n```\n\n### If Phase: Completed\n\n```\nüìä Status: Workflow Complete ‚úÖ\n\nüéØ Goal: [goal]\n\nCompletion Summary:\n- Started: [timestamp]\n- Completed: [timestamp]\n- Duration: [total time]\n\nDeliverables:\n- [X] epics completed\n- [Y] stories delivered\n- [Z] tasks finished\n\nFinal Metrics:\n- Test Coverage: [X]%\n- Quality Review: [findings summary]\n- All work stored in Pieces ‚úÖ\n\nNext: Run /catchup in future sessions to resume context\n```\n\n### If No Active Workflow\n\n```\nüìä Status: No Active Workflow\n\nCurrent Directory: [pwd]\n\nNo .titanium/workflow-state.json found\n\nChecking for plan...\n[If plan exists: Plan found but not yet executed]\n[If no plan: No plan found]\n\nChecking Pieces for history...\n[Results from Pieces query]\n\n---\n\nReady to start a new workflow?\n\nRun:\n- /titanium:plan [requirements] - Create implementation plan\n- /titanium:work [requirements] - Start full workflow\n```\n\n---\n\n## Step 8: Voice Summary (Optional)\n\n**If user requests voice summary or says \"yes\" to voice option**:\n\nCreate concise summary for TTS (under 100 words):\n\n```\n\"Workflow status: [Phase], [X] percent complete.\n[Completed count] tasks finished, [pending count] remaining.\nCurrently working on [current task or phase activity].\n[Key recent accomplishment].\nEstimated [time] remaining.\n[Next major milestone or action].\"\n```\n\n**Example**:\n```\n\"Workflow status: Implementation phase, sixty-seven percent complete.\nEight tasks finished, four remaining.\nCurrently implementing the login form component with the frontend developer agent.\nJust completed the backend authentication API with all tests passing.\nEstimated one hour remaining.\nNext, we'll run the quality review phase.\"\n```\n\n**Announce using existing TTS**:\n- Voice hooks will handle the announcement\n- No need to call TTS directly\n\n---\n\n## Integration with Workflow Commands\n\n### After /titanium:plan\n\n```\nUser: /titanium:plan [requirements]\n[... plan created ...]\nUser: /titanium:status\n\nShows:\n- Phase: Planning (completed)\n- Plan details\n- Ready for /titanium:work\n```\n\n### During /titanium:work\n\n```\nUser: /titanium:work\n[... implementation in progress ...]\nUser: /titanium:status\n\nShows:\n- Phase: Implementation (in progress)\n- Progress: X%\n- Current task\n- Time estimates\n```\n\n### After /titanium:work\n\n```\nUser: /titanium:work\n[... completes ...]\nUser: /titanium:status\n\nShows:\n- Phase: Completed\n- Summary of deliverables\n- Quality metrics\n```\n\n### Next Session\n\n```\nUser: (new session)\n/titanium:status\n\nShows:\n- Workflow state from file\n- Pieces context from previous session\n- Can resume work\n```\n\n---\n\n## Error Handling\n\n### If Workflow State File Corrupted\n\n```\n‚ö†Ô∏è  Workflow state file exists but is corrupted\n\nAttempting to recover from Pieces...\n[Query Pieces for last known state]\n\n[If recovery successful: Use Pieces data]\n[If recovery fails: Report what's known, suggest starting fresh]\n```\n\n### If Pieces Not Available\n\n```\nNote: Pieces MCP not available. Status based on local files only.\n\nTo enable full context recovery:\n1. Install Pieces OS (https://pieces.app)\n2. Install Pieces CLI (pip3 install pieces-cli)\n3. Configure MCP (pieces mcp setup claude_code --stdio)\n4. Restart Claude Code\n```\n\n### If No Information Available\n\n```\nüìä Status: No Data Available\n\nCurrent Directory: [pwd]\n\n- No workflow state file (.titanium/workflow-state.json)\n- No plan file (.titanium/plan.json)\n- Pieces query returned no results\n\nThis appears to be a new project or no workflows have been run yet.\n\nReady to start? Run:\n- /titanium:plan - Create implementation plan\n- /titanium:work - Start full workflow\n```\n\n---\n\n## Use Cases\n\n### Use Case 1: Check Progress Mid-Workflow\n\n```\nUser: How's the workflow going?\nClaude: Let me check the status.\n[Runs /titanium:status]\nClaude: We're 60% through implementation. 6 of 10 tasks complete.\n        Currently working on the frontend login form.\n        About 2 hours remaining.\n```\n\n### Use Case 2: Resume After Interruption\n\n```\nUser: (new session) What was I working on?\nClaude: Let me check.\n[Runs /titanium:status]\nClaude: You were implementing user authentication.\n        Phase: Implementation (in progress)\n        Last completed: Backend API by @api-developer\n        Next up: Frontend forms by @frontend-developer\n\n        Would you like to continue with /titanium:work?\n```\n\n### Use Case 3: Check Before Review\n\n```\nUser: Is implementation done? Can we review?\nClaude: Let me check status.\n[Runs /titanium:status]\nClaude: Yes! Implementation is 100% complete.\n        All 12 tasks finished.\n        Ready for quality review.\n\n        Run /titanium:review to start the review process.\n```\n\n### Use Case 4: Daily Standup Info\n\n```\nUser: What did we accomplish yesterday?\nClaude: Checking status and history...\n[Runs /titanium:status + Pieces query]\nClaude: Yesterday's work:\n        - Completed Backend API epic (3 stories, 7 tasks)\n        - @api-developer implemented JWT middleware\n        - @api-developer created login/register endpoints\n        - @test-runner wrote integration tests\n        - All tests passing\n\n        Today: Moving to Frontend epic\n```\n\n---\n\n## Voice Feedback\n\nVoice hooks may announce:\n- \"Status check complete\" (after generating report)\n- \"[X] percent complete\" (if voice summary requested)\n\n---\n\n## Advanced Features (Future)\n\nPotential enhancements:\n- Progress visualization (ASCII charts)\n- Time series data (velocity over time)\n- Agent performance metrics\n- Quality trend tracking\n- Burndown charts\n\n---\n\n**This command provides comprehensive workflow status with context from state files, Pieces LTM, and current session, enabling users to track progress and make informed decisions about next steps.**"
              },
              {
                "name": "/titanium-work",
                "description": "Execute a multi-phase development workflow with agent orchestration",
                "path": "plugins/titanium-toolkit/commands/titanium-work.md",
                "frontmatter": {
                  "description": "Execute a multi-phase development workflow with agent orchestration"
                },
                "content": "# Titanium Work Command\n\nYou are orchestrating a complete development workflow. This command coordinates multiple specialized subagents, manages state transitions, validates quality at each step, and stores progress in Pieces LTM.\n\n**Orchestration Model**: You delegate implementation tasks to specialized development agents (api-developer, frontend-developer, devops-engineer, etc.) who each have deep domain knowledge via skills. Each agent works in a separate context window with access to relevant expertise.\n\n**Agents & Their Skills**:\n- @api-developer: api-best-practices, testing-strategy, security-checklist\n- @frontend-developer: frontend-patterns, testing-strategy, technical-writing\n- @devops-engineer: devops-patterns, security-checklist\n- @code-reviewer: code-quality-standards, security-checklist, testing-strategy\n- @security-scanner: security-checklist, code-quality-standards\n- @tdd-specialist: testing-strategy, code-quality-standards\n- @test-runner: testing-strategy, debugging-methodology\n- @debugger: debugging-methodology, testing-strategy\n\n**MCP Tools Used**: This command uses the `tt` MCP server for plan generation:\n- `mcp__plugin_titanium-toolkit_tt__plan_parser` - Requirements ‚Üí Implementation plan\n\n## Overview\n\nThis workflow has 5 phases:\n1. **Pre-Flight**: Validate setup and check for existing plan\n2. **Planning**: Create plan if needed (or use existing)\n3. **Implementation**: Execute tasks sequentially with specialized agents\n4. **Review**: Quality check with parallel review agents\n5. **Completion**: Finalize and summarize\n\nVoice hooks will announce progress automatically throughout.\n\n---\n\n## Phase 1: Pre-Flight Checks\n\n### 1.1 Determine Project Path\n\n```bash\n# Get current working directory\npwd\n```\n\nUse this as the project_path for all subsequent operations.\n\n### 1.2 Check for Existing Plan\n\n```bash\n# Check if plan exists\nls .titanium/plan.json\n```\n\n**If plan.json exists**:\n- Read it with Read tool\n- Ask user: \"I found an existing plan. Would you like to use it or create a new one?\"\n- If user says use existing ‚Üí Skip to Phase 3 (Implementation)\n- If user says create new ‚Üí Continue to Phase 2 (Planning)\n\n**If plan.json does NOT exist**:\n- Ask user: \"No plan found. Would you like to:\n  1. Create a plan now (I'll ask what to implement)\n  2. Cancel and run /titanium:plan first (recommended for complex projects)\n\n  If you have project documentation or backlog, I recommend running /titanium:plan first to review and break down the work.\"\n- If user chooses option 1 ‚Üí Continue to Phase 2 (Planning)\n- If user chooses option 2 ‚Üí Exit and suggest running /titanium:plan\n\n### 1.3 Initialize Workflow State\n\n```bash\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py init \"$(pwd)\" \"development\" \"User's stated goal\"\n```\n\n**Example**:\n```bash\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py init \"$(pwd)\" \"development\" \"Implement user authentication system\"\n```\n\nThis creates `.titanium/workflow-state.json` to track progress.\n\n---\n\n## Phase 2: Planning (Skip if plan exists)\n\n### 2.1 Gather Requirements\n\n**If user provided file path**:\n```bash\n# User might have run: /titanium:work ~/bmad/output/prd.md\n```\n- Use Read tool to read the file\n- Copy content to `.titanium/requirements.md`\n\n**If user provided inline description**:\n```bash\n# User might say: \"I need to add search functionality\"\n```\n- Write description to `.titanium/requirements.md`\n- Ask clarifying questions if needed\n\n**If user provided nothing**:\n- Ask: \"What would you like to implement?\"\n- Wait for response\n- Write to `.titanium/requirements.md`\n\n### 2.2 Generate Plan\n\nUse the plan_parser MCP tool:\n\n```\nmcp__plugin_titanium-toolkit_tt__plan_parser(\n  requirements_file: \".titanium/requirements.md\",\n  project_path: \"$(pwd)\"\n)\n```\n\nThis creates `.titanium/plan.json` with structured plan.\n\n### 2.3 Review Plan\n\nRead and display the plan:\n\n```bash\n# Read the generated plan\nRead .titanium/plan.json\n```\n\nPresent summary to user:\n```\nüìã Plan Generated\n\nüéØ Goal: [goal from requirements]\n\nüì¶ Structure:\n- [X] epics\n- [Y] stories\n- [Z] tasks\n\n‚è±Ô∏è  Estimated Time: [total time]\n\nü§ñ Agents: [list of agents]\n\nKey Epics:\n1. [Epic 1] - [time]\n2. [Epic 2] - [time]\n```\n\n### 2.4 Validate with vibe-check\n\n```\nmcp__vibe-check__vibe_check(\n  goal: \"User's stated goal\",\n  plan: \"Summary: [X] epics, [Y] stories, [Z] tasks. Agents: [list]. Key work: [main epics]\",\n  uncertainties: [\n    \"List any concerns about complexity\",\n    \"Note any unclear requirements\",\n    \"Mention any technical risks\"\n  ]\n)\n```\n\n**Handle Response**:\n- If vibe-check raises **concerns**:\n  - Present concerns to user\n  - Ask: \"Should we adjust the plan or proceed?\"\n  - If adjust ‚Üí Go back to 2.1, refine requirements\n  - If proceed ‚Üí Continue\n- If vibe-check **approves**:\n  - Continue to next step\n\n### 2.5 Create TodoWrite List\n\nRead `.titanium/plan.json` and create comprehensive todo list:\n\n**Format**: For each task in the plan, create todo:\n```\n\"[Epic]: [Story] - [Task] (Agent: @agent-name)\"\n```\n\n**Example**:\n```\n[\n  {\"content\": \"User Auth: Requirements - Validate requirements (Agent: @product-manager)\", \"status\": \"pending\"},\n  {\"content\": \"User Auth: Backend API - Create JWT middleware (Agent: @api-developer)\", \"status\": \"pending\"},\n  {\"content\": \"User Auth: Backend API - Create login endpoint (Agent: @api-developer)\", \"status\": \"pending\"},\n  {\"content\": \"User Auth: Frontend - Create login form (Agent: @frontend-developer)\", \"status\": \"pending\"},\n  {\"content\": \"User Auth: Testing - Write integration tests (Agent: @test-runner)\", \"status\": \"pending\"}\n]\n```\n\nUse TodoWrite tool to create this list.\n\n### 2.6 Update State\n\n```bash\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py update_phase \"$(pwd)\" \"planning\" \"completed\"\n```\n\n### 2.7 Store Plan in Pieces\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Implementation plan for [project goal]\",\n  summary: \"Plan created with [X] epics, [Y] stories, [Z] tasks. Agents: [list]. Estimated time: [total]. Key work: [describe main epics and key technical decisions]\",\n  files: [\n    \".titanium/plan.json\",\n    \".titanium/plan.md\",\n    \".titanium/requirements.md\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n### 2.8 Get User Approval\n\n**IMPORTANT**: Do NOT proceed to implementation without explicit user approval.\n\nAsk user:\n```\nPlan is ready. The workflow will now:\n1. Execute [Z] tasks sequentially\n2. Use [N] different agents\n3. Take approximately [time]\n4. Run quality checks after each phase\n\nProceed with implementation? (yes/no)\n```\n\nWait for user confirmation before continuing.\n\n---\n\n## Phase 3: Implementation\n\n### 3.1 Update State\n\n```bash\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py update_phase \"$(pwd)\" \"implementation\" \"in_progress\"\n```\n\n### 3.2 Execute Tasks Sequentially\n\n**IMPORTANT**: Execute ONE task at a time, in order from your TodoWrite list.\n\n**For EACH task**:\n\n#### Step A: Mark Task as in_progress\n\nUpdate TodoWrite to mark current task as \"in_progress\".\n\n#### Step B: Parse Task Info\n\nFrom the task string, extract:\n- Epic name\n- Story name\n- Task name\n- Agent name (the @agent-name part)\n\n#### Step C: Launch Agent\n\nUse Task tool to launch the appropriate agent:\n\n```\nTask(\n  description: \"[Task name]\",\n  prompt: \"You are working on: [Epic] > [Story] > [Task]\n\nRequirements context:\n[Relevant requirements from .titanium/requirements.md]\n\nPrevious work:\n[If this task has dependencies, summarize what was done]\n\nTask details:\n[Specific instructions for this task]\n\nSuccess criteria:\n- [What needs to be completed]\n- [What files should be created/modified]\n- [What tests should pass]\n\nAfter completion:\n- Run any relevant tests\n- Verify the work meets requirements\n- Report what was accomplished\",\n  subagent_type: \"[agent-type without @]\"\n)\n```\n\n**Example**:\n```\nTask(\n  description: \"Create JWT middleware\",\n  prompt: \"You are working on: User Authentication > Backend API > Create JWT middleware\n\nRequirements context:\n- Need JWT-based authentication\n- Should support refresh tokens\n- Use argon2 for password hashing\n- Rate limiting required\n\nTask details:\nCreate Express middleware for JWT authentication that:\n- Verifies JWT tokens from Authorization header\n- Handles token expiration\n- Returns 401 for invalid/expired tokens\n- Attaches user info to req.user\n\nFiles to create:\n- src/middleware/auth.ts\n\nSuccess criteria:\n- Middleware function exported\n- Handles all error cases\n- Tests pass\n\nAfter completion, report what files were created and what the middleware does.\",\n  subagent_type: \"api-developer\"\n)\n```\n\n#### Step D: Wait for Agent Completion\n\nThe agent will execute the work. Voice hooks will automatically announce completion.\n\n#### Step E: Quality Check\n\nAfter agent completes:\n\n1. **Run tests if applicable**:\n   ```bash\n   # If package.json has test script\n   npm test\n\n   # Or pytest for Python\n   pytest\n\n   # Or appropriate test command\n   ```\n\n2. **Use vibe-check to validate progress**:\n   ```\n   mcp__vibe-check__vibe_check(\n     goal: \"Overall project goal\",\n     plan: \"Current epic and story context\",\n     progress: \"Just completed: [task name]. Agent: [agent]. Result: [brief summary of what was done]\",\n     uncertainties: [\n       \"Note any issues encountered\",\n       \"List any deviations from plan\",\n       \"Mention any new concerns\"\n     ]\n   )\n   ```\n\n3. **Handle vibe-check response**:\n   - If concerns raised ‚Üí Present to user, decide whether to proceed or fix\n   - If approved ‚Üí Continue\n\n#### Step F: Mark Task Completed\n\n**IMMEDIATELY** update TodoWrite to mark current task as \"completed\".\n\nDo NOT batch updates. Mark completed right after finishing.\n\n#### Step G: Check for Epic Completion\n\nIf you just completed the last task of an epic:\n\n1. **Store Epic Milestone in Pieces**:\n   ```\n   mcp__Pieces__create_pieces_memory(\n     summary_description: \"Completed Epic: [epic name]\",\n     summary: \"Finished [epic name] with [N] stories and [M] tasks. Agents used: [list]. Key accomplishments: [what was built]. Files created/modified: [list key files]. Tests: [test results]. Time taken: [if known]\",\n     files: [\n       \"list all files created or modified in this epic\"\n     ],\n     project: \"$(pwd)\"\n   )\n   ```\n\n#### Step H: Continue to Next Task\n\nMove to next task in TodoWrite list. Repeat steps A-G.\n\n### 3.3 After All Tasks Complete\n\nOnce all implementation tasks are done, proceed to Phase 3.5 (CodeRabbit Analysis - if available) or Phase 4 (Review).\n\n---\n\n## Phase 3.5: CodeRabbit Analysis (Optional)\n\n**This phase is optional** - only runs if CodeRabbit CLI is installed.\n\n### 3.5.1 Check for CodeRabbit CLI\n\n```bash\ncommand -v coderabbit >/dev/null 2>&1 || echo \"CodeRabbit not installed\"\n```\n\n**If CodeRabbit NOT found**:\n- Skip to Phase 4 (3-Agent Review)\n- Workflow continues normally\n\n**If CodeRabbit found**:\n- Continue to 3.5.2\n\n### 3.5.2 Offer CodeRabbit Analysis\n\n```\nü§ñ CodeRabbit CLI Detected\n\nRun CodeRabbit analysis before review?\n\nCodeRabbit catches:\n- Race conditions in concurrent code\n- Memory leaks and resource leaks\n- Security vulnerabilities\n- Logic errors and edge cases\n- Performance issues\n\nDuration: 7-30 minutes (runs in background)\nCost: Uses your CodeRabbit account (free or paid tier)\n\nRun CodeRabbit? (yes/no)\n```\n\n**If no**: Skip to Phase 4 (3-Agent Review)\n**If yes**: Continue\n\n### 3.5.3 Run CodeRabbit in Background\n\n```bash\n# Run with --prompt-only for AI-optimized output\ncoderabbit --prompt-only --type uncommitted\n```\n\nUse Bash tool with `run_in_background: true`\n\nShow user:\n```\nü§ñ CodeRabbit Analyzing...\n\nRunning in background (7-30 minutes typical).\nI'll check progress periodically.\n\nYou can ask \"Is CodeRabbit done?\" anytime.\n```\n\n### 3.5.4 Wait for Completion\n\nCheck periodically (every 2-3 minutes) using BashOutput tool.\n\nShow progress updates:\n```\nCodeRabbit analyzing... (5 minutes elapsed)\nCodeRabbit analyzing... (10 minutes elapsed)\nCodeRabbit analyzing... (15 minutes elapsed)\n```\n\nWhen complete:\n```\n‚úÖ CodeRabbit analysis complete! ([X] minutes)\n```\n\n### 3.5.5 Parse and Present Findings\n\nRead CodeRabbit --prompt-only output.\n\nPresent summary:\n```\nü§ñ CodeRabbit Findings\n\nüìä Issues Detected:\n- üî¥ Critical: [X]\n- üü† High: [Y]\n- üü° Medium: [Z]\n- üü¢ Low: [W]\n\nCritical Issues:\n1. Race condition in src/auth.ts:45\n   - Shared state access without synchronization\n   - Fix: Add mutex or use atomic operations\n\n2. Memory leak in src/websocket.ts:123\n   - Event listener not removed on disconnect\n   - Fix: Add cleanup in disconnect handler\n\nHigh Priority Issues:\n1. SQL injection in src/api/users.ts:67\n   - User input in raw SQL query\n   - Fix: Use parameterized queries\n\n[List all critical and high issues]\n\nWould you like me to fix these?\n1. Fix critical and high (recommended)\n2. Fix critical only\n3. Skip fixes, just document\n4. Cancel\n```\n\n### 3.5.6 Apply Fixes (if requested)\n\n**For each critical/high issue**:\n1. Locate the problematic code (file:line from CodeRabbit)\n2. Read CodeRabbit's suggested fix\n3. Implement the fix\n4. Run relevant tests\n5. Mark as fixed in TodoWrite\n\nShow progress:\n```\nApplying CodeRabbit fixes...\n\n‚úÖ Fixed: Race condition in auth.ts\n   - Added mutex for shared state access\n   - Tests passing\n\n‚úÖ Fixed: Memory leak in websocket.ts\n   - Added event listener cleanup\n   - Verified no leaks\n\n‚úÖ Fixed: SQL injection in users.ts\n   - Converted to parameterized query\n   - Tests passing\n\n‚è≥ Fixing: Error handling in api.ts...\n```\n\n### 3.5.7 Optional Verification\n\nAfter fixes applied:\n```\nCodeRabbit fixes complete!\n\nFixed: [X] critical, [Y] high priority issues\n\nRe-run CodeRabbit to verify? (yes/no)\n```\n\n**If yes**:\n```bash\ncoderabbit --prompt-only --type uncommitted\n```\n\nCheck that:\n- No new critical issues introduced\n- Fixes resolved the original issues\n- No regression\n\nShow result:\n```\n‚úÖ Verification complete!\n\nOriginal issues: Resolved\nNew issues: None\nSafe to proceed.\n```\n\n**If no**: Skip verification\n\n### 3.5.8 Store CodeRabbit Findings\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"CodeRabbit analysis for [files]\",\n  summary: \"CodeRabbit CLI analysis complete. Found: [X] critical, [Y] high, [Z] medium, [W] low issues. Critical issues: [list each]. High issues: [list each]. Fixes applied: [summary of fixes]. Duration: [X] minutes. Verified: [yes/no]. Ready for 3-agent review validation.\",\n  files: [\n    \"list all reviewed and fixed files\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n### 3.5.9 Proceed to 3-Agent Review\n\n```\nCodeRabbit phase complete!\n\nProceeding to 3-agent review for validation...\n```\n\nContinue to Phase 4 (Review).\n\n**Note**: 3-agent review will validate CodeRabbit fixes and catch anything CodeRabbit missed.\n\n---\n\n## Phase 4: Review\n\n### 4.1 Update State\n\n```bash\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py update_phase \"$(pwd)\" \"review\" \"in_progress\"\n```\n\n### 4.2 Launch Review Agents in Parallel\n\n**IMPORTANT**: Launch all three agents in a SINGLE message using multiple Task calls.\n\nThis enables them to run concurrently:\n\n```\n[Task 1]: @code-reviewer\nPrompt: \"Review all code changes for quality, readability, and best practices.\n\nFocus on:\n- Code quality and maintainability\n- DRY principles\n- SOLID principles\n- Error handling\n- Code organization\n- Comments and documentation\n\nFiles to review: [list all modified files]\n\nProvide findings categorized by severity:\n- Critical: Must fix before deployment\n- Important: Should fix soon\n- Nice-to-have: Optional improvements\n\nFor each finding, specify:\n- File and line number\n- Issue description\n- Recommendation\"\n\n[Task 2]: @security-scanner\nPrompt: \"Scan for security vulnerabilities and security best practices.\n\nFocus on:\n- Input validation\n- SQL injection risks\n- XSS vulnerabilities\n- Authentication/authorization issues\n- Secrets in code\n- Dependency vulnerabilities\n- HTTPS enforcement\n- Rate limiting\n\nFiles to review: [list all modified files]\n\nProvide findings with:\n- Severity (Critical/High/Medium/Low)\n- Vulnerability type\n- File and line number\n- Risk description\n- Remediation steps\"\n\n[Task 3]: @tdd-specialist\nPrompt: \"Check test coverage and test quality.\n\nFocus on:\n- Test coverage percentage\n- Edge cases covered\n- Integration tests\n- Unit tests\n- E2E tests (if applicable)\n- Test quality and assertions\n- Mock usage\n- Test organization\n\nFiles to review: [list all test files and source files]\n\nProvide findings on:\n- Coverage gaps\n- Missing test cases\n- Test quality issues\n- Recommendations for improvement\"\n```\n\n### 4.3 Wait for All Agents\n\nWait for all three review agents to complete (they run in parallel).\n\n### 4.4 Aggregate Findings\n\nCollect and organize all findings:\n\n**Categories**:\n- üî¥ **Critical** (must fix)\n- üü° **Important** (should fix)\n- üü¢ **Nice-to-have** (optional)\n\n**For each finding**:\n- Source: Which agent found it\n- File: file.path:line\n- Issue: Description\n- Fix: Recommendation\n\n### 4.5 Meta-Review with vibe-check\n\n```\nmcp__vibe-check__vibe_check(\n  goal: \"Original project goal\",\n  plan: \"What was implemented\",\n  progress: \"Implementation complete. Review findings: [X] critical, [Y] important, [Z] minor issues. Details: [summarize key findings]\",\n  uncertainties: [\n    \"Are there systemic issues we're missing?\",\n    \"Is the implementation approach sound?\",\n    \"Any architectural concerns?\"\n  ]\n)\n```\n\n### 4.6 Create Review Report\n\nWrite `.titanium/review-report.md`:\n\n```markdown\n# Quality Review Report\n\n**Date**: [current date]\n**Project**: [project goal]\n**Reviewers**: @code-reviewer, @security-scanner, @tdd-specialist\n\n## Summary\n\n- üî¥ Critical issues: [X]\n- üü° Important issues: [Y]\n- üü¢ Nice-to-have: [Z]\n\n## Critical Issues üî¥\n\n### [Issue 1 Title]\n**File**: `path/to/file.ts:line`\n**Source**: @security-scanner\n**Severity**: Critical\n\n**Description**:\n[What the issue is]\n\n**Risk**:\n[Why it's critical]\n\n**Recommendation**:\n[How to fix it]\n\n---\n\n### [Issue 2 Title]\n[... repeat structure ...]\n\n## Important Issues üü°\n\n[... same structure ...]\n\n## Nice-to-have üü¢\n\n[... same structure ...]\n\n## vibe-check Meta-Review\n\n[Summary from vibe-check about overall quality]\n\n## Test Coverage\n\n**Overall Coverage**: [X]%\n**Files with <80% coverage**: [list]\n**Missing test cases**: [list]\n\n## Recommendations\n\n1. [Priority 1 recommendation]\n2. [Priority 2 recommendation]\n3. [Priority 3 recommendation]\n```\n\n### 4.7 Store Review in Pieces\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Quality review findings for [project]\",\n  summary: \"Review complete: [X] critical, [Y] important, [Z] minor issues. Critical issues: [list them briefly]. Important issues: [list them]. Test coverage: [X]%. vibe-check assessment: [summary]. Overall quality: [assessment]\",\n  files: [\n    \".titanium/review-report.md\",\n    \"list all reviewed files\"\n  ],\n  project: \"$(pwd)\"\n)\n```\n\n### 4.8 Present Summary\n\n```\nüîç Quality Review Complete\n\nüî¥ [X] Critical Issues\nüü° [Y] Important Issues\nüü¢ [Z] Nice-to-have Improvements\n\nüìÑ Full Report: .titanium/review-report.md\n\n‚ö†Ô∏è  Action Required:\n[List critical issues with file:line]\n\nüí° Recommendations:\n1. [Top recommendation]\n2. [Second recommendation]\n\nWould you like me to fix the critical issues now?\n```\n\n**If user says yes**:\n- Address critical issues one by one\n- Re-run tests after each fix\n- Update review report\n\n**If user says no**:\n- Proceed to Phase 5 (Completion)\n\n---\n\n## Phase 5: Completion\n\n### 5.1 Mark Workflow Complete\n\n```bash\nuv run ${CLAUDE_PLUGIN_ROOT}/hooks/utils/workflow/workflow_state.py complete \"$(pwd)\"\n```\n\n### 5.2 Create Final Session Memory\n\n```\nmcp__Pieces__create_pieces_memory(\n  summary_description: \"Completed: [project goal]\",\n  summary: \"Full workflow summary:\n\nGoal: [original goal]\n\nWhat was built:\n[List main features/components]\n\nEpics completed: [X]\nStories completed: [Y]\nTasks completed: [Z]\nTime taken: [if known]\n\nAgents used:\n[List agents and their contributions]\n\nQuality review:\n- Critical issues: [X] ([status: fixed/pending])\n- Important issues: [Y]\n- Test coverage: [X]%\n\nFiles created/modified:\n[List key files]\n\nKey technical decisions:\n[List important decisions made during implementation]\n\nNext steps:\n[Suggest what should happen next]\",\n  files: [\n    \"list ALL project files that were part of this workflow\"\n  ],\n  project: \"$(pwd)\",\n  externalLinks: [\n    \"Any GitHub branches/PRs if created\"\n  ]\n)\n```\n\n### 5.3 Present Completion Summary\n\n```\n‚úÖ Workflow Complete!\n\nüéØ Goal: [original goal]\n\nüì¶ Delivered:\n- [X] epics\n- [Y] stories\n- [Z] tasks completed\n\nü§ñ Agents Used:\n- [Agent 1]: [what they did]\n- [Agent 2]: [what they did]\n[... list all agents ...]\n\nüìä Quality:\n- Tests: [X]% coverage\n- Critical issues: [X] ([fixed/pending])\n- Important issues: [Y]\n\nüìÅ Key Files:\n- [file 1]\n- [file 2]\n[... list main files ...]\n\nüìù Documentation:\n- Plan: .titanium/plan.md\n- Review: .titanium/review-report.md\n- State: .titanium/workflow-state.json\n\nüéâ All work stored in Pieces for future reference!\n\n---\n\nNext Steps:\n1. [Suggestion 1]\n2. [Suggestion 2]\n3. Run /titanium:status anytime to check progress\n```\n\n---\n\n## Important Guidelines\n\n### Always\n\n- ‚úÖ Use TodoWrite to track every task\n- ‚úÖ Execute tasks ONE at a time (sequential)\n- ‚úÖ Mark tasks completed IMMEDIATELY after finishing\n- ‚úÖ Use vibe-check after each task and epic\n- ‚úÖ Store milestones in Pieces after each epic\n- ‚úÖ Get user approval after planning phase\n- ‚úÖ Launch review agents in parallel (single message, multiple Tasks)\n- ‚úÖ Use workflow_state.py to track phases\n- ‚úÖ Handle errors gracefully - inform user of issues\n\n### Never\n\n- ‚ùå Skip vibe-check quality gates\n- ‚ùå Execute multiple implementation tasks in parallel\n- ‚ùå Batch todo updates - mark completed immediately\n- ‚ùå Proceed to implementation without user approval\n- ‚ùå Skip storing epic milestones in Pieces\n- ‚ùå Ignore vibe-check concerns - always present to user\n- ‚ùå Launch review agents sequentially - always parallel\n\n---\n\n## Error Handling\n\n### If Agent Fails\n\n```\nAgent @[agent-name] encountered an error while [task].\n\nError: [error message]\n\nOptions:\n1. Retry the task\n2. Skip and continue\n3. Modify approach and retry\n\nWhat would you like to do?\n```\n\n### If vibe-check Raises Concerns\n\n```\n‚ö†Ô∏è  vibe-check identified concerns:\n\n[List concerns from vibe-check]\n\nRecommendations:\n[List suggestions from vibe-check]\n\nWould you like to:\n1. Address these concerns now\n2. Proceed anyway (not recommended)\n3. Adjust the approach\n```\n\n### If Tests Fail\n\n```\n‚ùå Tests failed after [task]\n\nFailed tests:\n[List failed tests]\n\nError output:\n[Show errors]\n\nI can:\n1. Analyze and fix the failing tests\n2. Continue anyway (not recommended)\n3. Roll back this change\n\nWhat would you like to do?\n```\n\n### If Missing API Keys\n\n```\nError: Required API key missing\n\nThis workflow needs:\n- OPENAI_API_KEY (for plan generation)\n- ELEVENLABS_API_KEY (for voice announcements - optional but recommended)\n\nFor vibe-check quality gates (recommended):\n- GEMINI_API_KEY or OPENAI_API_KEY in ~/.vibe-check/.env\n\nPlease add the required keys to ~/.env and restart Claude Code.\n```\n\n---\n\n## Voice Feedback\n\nVoice hooks automatically announce:\n- \"Starting [phase] phase\" (at each phase transition)\n- \"[Agent] completed [task]\" (after each agent)\n- \"[X] tasks remaining\" (periodically)\n- \"Quality review complete: [findings count]\" (after review)\n- \"Workflow complete\" (at end)\n\nNo additional voice calls needed - hooks handle this.\n\n---\n\n## Example Usage\n\n### Example 1: With Existing Plan\n\n```\nUser: /titanium:work\n\nClaude:\n- Checks for .titanium/plan.json\n- Found existing plan\n- \"I found a plan with 3 epics, 8 stories. Use this plan?\"\nUser: \"Yes\"\n- Skips planning phase\n- Creates TodoWrite list from plan\n- Starts implementation\n- Executes tasks sequentially with agents\n- Voice announces progress throughout\n- Runs review at end\n- Presents completion summary\n```\n\n### Example 2: Without Plan\n\n```\nUser: /titanium:work \"Add search functionality to products\"\n\nClaude:\n- No plan found\n- Writes requirements to .titanium/requirements.md\n- Asks clarifying questions about tech stack\nUser: \"React frontend, Node backend, Elasticsearch\"\n- Generates plan with plan_parser MCP tool\n- Validates with vibe-check\n- Presents plan\n- \"Proceed with implementation?\"\nUser: \"Yes\"\n- Creates TodoWrite list\n- Executes implementation\n- [... continues through all phases ...]\n```\n\n### Example 3: From BMAD PRD\n\n```\nUser: /titanium:work ~/bmad/output/user-auth-prd.md\n\nClaude:\n- Reads PRD file\n- Generates plan from PRD\n- Validates with vibe-check\n- vibe-check: \"Plan looks good, recommend adding rate limiting\"\n- Adjusts plan to include rate limiting\n- Presents updated plan\n- \"Proceed?\"\nUser: \"Yes\"\n- Executes full workflow\n- [... 4 hours of orchestrated work ...]\n- Review finds 1 security issue\n- Fixes security issue\n- \"Workflow complete!\"\n```\n\n---\n\n## Integration with Other Commands\n\n**After /titanium:work**:\n- Run `/titanium:status` to check final state\n- Run `/catchup` in next session to resume context\n- Run `/titanium:review` again if you make more changes\n\n**Before /titanium:work**:\n- Run `/titanium:plan` first if you want to review the plan separately\n- Or let /titanium:work create the plan inline\n\n---\n\n**This command orchestrates the complete development workflow from requirements to reviewed implementation, with AI quality gates and voice feedback throughout.**"
              }
            ],
            "skills": [
              {
                "name": "api-best-practices",
                "description": "REST API design patterns, OpenAPI specifications, versioning strategies, authentication, error handling, and security best practices. Use when designing APIs, creating endpoints, documenting APIs, or implementing backend services that expose HTTP APIs.",
                "path": "plugins/titanium-toolkit/skills/api-best-practices/SKILL.md",
                "frontmatter": {
                  "name": "api-best-practices",
                  "description": "REST API design patterns, OpenAPI specifications, versioning strategies, authentication, error handling, and security best practices. Use when designing APIs, creating endpoints, documenting APIs, or implementing backend services that expose HTTP APIs."
                },
                "content": "# API Best Practices\n\nThis skill provides comprehensive guidance for designing, implementing, and documenting RESTful APIs following industry best practices.\n\n## RESTful Design Principles\n\n### Resource-Oriented Design\n\nAPIs should be designed around resources (nouns), not actions (verbs):\n\n**Good**:\n```http\nGET    /api/v1/users\nPOST   /api/v1/users\nGET    /api/v1/users/{id}\nPUT    /api/v1/users/{id}\nDELETE /api/v1/users/{id}\n```\n\n**Bad**:\n```http\nGET    /api/v1/getUsers\nPOST   /api/v1/createUser\nPOST   /api/v1/updateUser\nPOST   /api/v1/deleteUser\n```\n\n### HTTP Methods and Their Meanings\n\n- **GET**: Retrieve a resource (safe, idempotent, cacheable)\n- **POST**: Create a new resource (not idempotent)\n- **PUT**: Replace entire resource (idempotent)\n- **PATCH**: Partial update (not necessarily idempotent)\n- **DELETE**: Remove a resource (idempotent)\n\n### HTTP Status Codes\n\n**Success (2xx)**:\n- `200 OK`: Successful GET, PUT, PATCH, DELETE\n- `201 Created`: Successful POST with resource creation\n- `202 Accepted`: Request accepted for async processing\n- `204 No Content`: Successful DELETE or update with no response body\n\n**Client Errors (4xx)**:\n- `400 Bad Request`: Malformed request, validation error\n- `401 Unauthorized`: Authentication required\n- `403 Forbidden`: Authenticated but not authorized\n- `404 Not Found`: Resource doesn't exist\n- `409 Conflict`: Resource conflict (duplicate, version mismatch)\n- `422 Unprocessable Entity`: Valid syntax but semantic errors\n- `429 Too Many Requests`: Rate limit exceeded\n\n**Server Errors (5xx)**:\n- `500 Internal Server Error`: Unexpected server error\n- `502 Bad Gateway`: Upstream service failure\n- `503 Service Unavailable`: Temporary overload or maintenance\n- `504 Gateway Timeout`: Upstream timeout\n\n## API Versioning\n\n### URL Versioning (Recommended)\n```http\nGET /api/v1/users\nGET /api/v2/users\n```\n\n**Pros**: Clear, easy to route, visible in logs\n**Cons**: Duplicate code across versions\n\n### Header Versioning\n```http\nGET /api/users\nAccept: application/vnd.myapi.v1+json\n```\n\n**Pros**: Clean URLs\n**Cons**: Harder to test, less visible\n\n### Version Management Rules\n1. Never break backwards compatibility in same version\n2. Deprecate old versions with advance notice (6-12 months)\n3. Document migration guides between versions\n4. Support at least 2 major versions simultaneously\n\n## Request/Response Patterns\n\n### Standard Request Format\n\n**JSON Request Body**:\n```json\n{\n  \"email\": \"user@example.com\",\n  \"name\": \"John Doe\",\n  \"preferences\": {\n    \"newsletter\": true,\n    \"notifications\": false\n  }\n}\n```\n\n**Query Parameters** (for filtering, pagination, sorting):\n```http\nGET /api/v1/users?role=admin&status=active&page=2&limit=20&sort=-created_at\n```\n\n### Standard Response Format\n\n**Success Response**:\n```json\n{\n  \"data\": {\n    \"id\": \"user_123\",\n    \"email\": \"user@example.com\",\n    \"name\": \"John Doe\",\n    \"createdAt\": \"2025-10-16T10:30:00Z\"\n  }\n}\n```\n\n**Error Response**:\n```json\n{\n  \"error\": {\n    \"code\": \"INVALID_EMAIL\",\n    \"message\": \"Email address is invalid\",\n    \"field\": \"email\",\n    \"details\": \"Email must contain @ symbol\"\n  }\n}\n```\n\n**Collection Response with Pagination**:\n```json\n{\n  \"data\": [\n    { \"id\": 1, \"name\": \"User 1\" },\n    { \"id\": 2, \"name\": \"User 2\" }\n  ],\n  \"pagination\": {\n    \"page\": 2,\n    \"limit\": 20,\n    \"total\": 156,\n    \"totalPages\": 8,\n    \"hasNext\": true,\n    \"hasPrev\": true\n  },\n  \"links\": {\n    \"self\": \"/api/v1/users?page=2\",\n    \"next\": \"/api/v1/users?page=3\",\n    \"prev\": \"/api/v1/users?page=1\",\n    \"first\": \"/api/v1/users?page=1\",\n    \"last\": \"/api/v1/users?page=8\"\n  }\n}\n```\n\n## Authentication Patterns\n\n### JWT (JSON Web Tokens)\n\n**Login Flow**:\n```http\nPOST /api/v1/auth/login\n{\n  \"email\": \"user@example.com\",\n  \"password\": \"SecurePassword123\"\n}\n\nResponse (200):\n{\n  \"accessToken\": \"eyJhbGc...\",\n  \"refreshToken\": \"eyJhbGc...\",\n  \"expiresIn\": 900\n}\n```\n\n**Using Access Token**:\n```http\nGET /api/v1/users/me\nAuthorization: Bearer eyJhbGc...\n```\n\n**Token Refresh**:\n```http\nPOST /api/v1/auth/refresh\n{\n  \"refreshToken\": \"eyJhbGc...\"\n}\n\nResponse (200):\n{\n  \"accessToken\": \"eyJhbGc...\",\n  \"expiresIn\": 900\n}\n```\n\n### API Keys\n\n**Header-based** (recommended):\n```http\nGET /api/v1/data\nX-API-Key: sk_live_abc123xyz\n```\n\n**Query parameter** (less secure, use only for public data):\n```http\nGET /api/v1/public-data?api_key=sk_live_abc123xyz\n```\n\n### OAuth 2.0 Flows\n\n**Authorization Code Flow** (for web apps):\n1. Redirect to `/oauth/authorize`\n2. User grants permission\n3. Receive authorization code\n4. Exchange code for access token at `/oauth/token`\n5. Use access token for API requests\n\n**Client Credentials Flow** (for server-to-server):\n```http\nPOST /oauth/token\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=client_credentials&client_id=abc&client_secret=xyz\n```\n\n## Error Handling\n\n### Validation Errors\n\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Request validation failed\",\n    \"errors\": [\n      {\n        \"field\": \"email\",\n        \"message\": \"Email is required\"\n      },\n      {\n        \"field\": \"age\",\n        \"message\": \"Age must be at least 18\"\n      }\n    ]\n  }\n}\n```\n\n### Business Logic Errors\n\n```json\n{\n  \"error\": {\n    \"code\": \"INSUFFICIENT_FUNDS\",\n    \"message\": \"Account balance too low for this transaction\",\n    \"details\": {\n      \"balance\": 50.00,\n      \"required\": 100.00,\n      \"currency\": \"USD\"\n    }\n  }\n}\n```\n\n### Rate Limiting Errors\n\n```http\nHTTP/1.1 429 Too Many Requests\nX-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 0\nX-RateLimit-Reset: 1634400000\nRetry-After: 3600\n\n{\n  \"error\": {\n    \"code\": \"RATE_LIMIT_EXCEEDED\",\n    \"message\": \"API rate limit exceeded\",\n    \"retryAfter\": 3600\n  }\n}\n```\n\n## Pagination Strategies\n\n### Offset Pagination (Simple)\n```http\nGET /api/v1/users?offset=40&limit=20\n```\n\n**Pros**: Simple, allows jumping to any page\n**Cons**: Performance degrades with large offsets, inconsistent if data changes\n\n### Cursor Pagination (Recommended for large datasets)\n```http\nGET /api/v1/users?cursor=eyJpZCI6MTIzfQ&limit=20\n\nResponse:\n{\n  \"data\": [...],\n  \"pagination\": {\n    \"nextCursor\": \"eyJpZCI6MTQzfQ\",\n    \"hasMore\": true\n  }\n}\n```\n\n**Pros**: Consistent results, performant at any scale\n**Cons**: Can't jump to specific page\n\n### Page-Number Pagination (User-friendly)\n```http\nGET /api/v1/users?page=3&limit=20\n```\n\n**Pros**: User-friendly, easy to understand\n**Cons**: Same issues as offset pagination\n\n## Rate Limiting\n\n### Implementation Pattern\n\n**Headers to include**:\n```http\nX-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 999\nX-RateLimit-Reset: 1634400000\n```\n\n**Tiered Limits**:\n- Anonymous: 100 requests/hour\n- Basic tier: 1,000 requests/hour\n- Pro tier: 10,000 requests/hour\n- Enterprise: Custom limits\n\n### Rate Limiting Algorithms\n\n**Token Bucket** (recommended):\n- Allows bursts\n- Smooth long-term rate\n- Most flexible\n\n**Fixed Window**:\n- Simple to implement\n- Can allow double limit at window boundaries\n- Less flexible\n\n**Sliding Window**:\n- More accurate than fixed window\n- More complex to implement\n- Better user experience\n\n## API Security Best Practices\n\n### 1. Always Use HTTPS\nNever send sensitive data over HTTP. Enforce HTTPS at the load balancer level.\n\n### 2. Validate All Inputs\n```python\nfrom pydantic import BaseModel, EmailStr, constr\n\nclass UserCreate(BaseModel):\n    email: EmailStr\n    password: constr(min_length=8, max_length=100)\n    name: constr(min_length=1, max_length=100)\n```\n\n### 3. Sanitize Outputs\nPrevent injection attacks by escaping output:\n```python\nimport html\nsafe_output = html.escape(user_input)\n```\n\n### 4. Use Parameterized Queries\n```python\n# ‚úÖ SAFE - Parameterized\ncursor.execute(\"SELECT * FROM users WHERE email = ?\", (email,))\n\n# ‚ùå UNSAFE - String concatenation\ncursor.execute(f\"SELECT * FROM users WHERE email = '{email}'\")\n```\n\n### 5. Implement CORS Properly\n```python\n# Be specific with origins\nCORS(app, origins=[\"https://myapp.com\", \"https://app.myapp.com\"])\n\n# ‚ùå NEVER use wildcard in production\n# CORS(app, origins=[\"*\"])  # DANGEROUS\n```\n\n### 6. Authenticate Before Authorization\n```python\n# 1. Verify JWT token (authentication)\n# 2. Check user permissions (authorization)\n# 3. Process request\n```\n\n### 7. Log Security Events\n```python\nlogger.warning(f\"Failed login attempt for {email} from {ip_address}\")\nlogger.critical(f\"Privilege escalation attempt by user {user_id}\")\n```\n\n### 8. Rate Limit Authentication Endpoints\nPrevent brute force attacks:\n- `/auth/login`: 5 attempts per 15 minutes per IP\n- `/auth/register`: 3 attempts per hour per IP\n- `/auth/reset-password`: 3 attempts per hour per email\n\n## OpenAPI/Swagger Documentation\n\n### OpenAPI 3.0 Example\n\n```yaml\nopenapi: 3.0.0\ninfo:\n  title: My API\n  version: 1.0.0\n  description: API for managing users and posts\n\nservers:\n  - url: https://api.example.com/v1\n    description: Production server\n  - url: https://staging-api.example.com/v1\n    description: Staging server\n\npaths:\n  /users:\n    get:\n      summary: List users\n      operationId: listUsers\n      tags:\n        - Users\n      parameters:\n        - name: page\n          in: query\n          schema:\n            type: integer\n            default: 1\n        - name: limit\n          in: query\n          schema:\n            type: integer\n            default: 20\n            maximum: 100\n      responses:\n        '200':\n          description: Successful response\n          content:\n            application/json:\n              schema:\n                type: object\n                properties:\n                  data:\n                    type: array\n                    items:\n                      $ref: '#/components/schemas/User'\n                  pagination:\n                    $ref: '#/components/schemas/Pagination'\n    post:\n      summary: Create user\n      operationId: createUser\n      tags:\n        - Users\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/UserCreate'\n      responses:\n        '201':\n          description: User created\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/User'\n        '400':\n          description: Validation error\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Error'\n\ncomponents:\n  schemas:\n    User:\n      type: object\n      required:\n        - id\n        - email\n        - name\n      properties:\n        id:\n          type: string\n          example: user_123\n        email:\n          type: string\n          format: email\n          example: user@example.com\n        name:\n          type: string\n          example: John Doe\n        createdAt:\n          type: string\n          format: date-time\n          example: 2025-10-16T10:30:00Z\n\n    UserCreate:\n      type: object\n      required:\n        - email\n        - password\n        - name\n      properties:\n        email:\n          type: string\n          format: email\n        password:\n          type: string\n          minLength: 8\n          maxLength: 100\n        name:\n          type: string\n          minLength: 1\n          maxLength: 100\n\n    Pagination:\n      type: object\n      properties:\n        page:\n          type: integer\n        limit:\n          type: integer\n        total:\n          type: integer\n        totalPages:\n          type: integer\n        hasNext:\n          type: boolean\n        hasPrev:\n          type: boolean\n\n    Error:\n      type: object\n      properties:\n        error:\n          type: object\n          properties:\n            code:\n              type: string\n            message:\n              type: string\n            details:\n              type: object\n\n  securitySchemes:\n    BearerAuth:\n      type: http\n      scheme: bearer\n      bearerFormat: JWT\n\nsecurity:\n  - BearerAuth: []\n```\n\n## API Endpoint Design Patterns\n\n### Collection and Resource Endpoints\n\n```http\n# Collection operations\nGET    /api/v1/posts          # List posts\nPOST   /api/v1/posts          # Create post\nGET    /api/v1/posts/{id}     # Get specific post\nPUT    /api/v1/posts/{id}     # Replace post\nPATCH  /api/v1/posts/{id}     # Update post\nDELETE /api/v1/posts/{id}     # Delete post\n\n# Nested resources\nGET    /api/v1/posts/{id}/comments     # List comments for post\nPOST   /api/v1/posts/{id}/comments     # Create comment on post\nGET    /api/v1/comments/{id}           # Get specific comment\nDELETE /api/v1/comments/{id}           # Delete comment\n```\n\n### Action Endpoints (When REST Isn't Enough)\n\nSometimes you need RPC-style endpoints for actions:\n\n```http\nPOST /api/v1/users/{id}/verify-email\nPOST /api/v1/orders/{id}/cancel\nPOST /api/v1/posts/{id}/publish\nPOST /api/v1/invoices/{id}/send\n```\n\n**Pattern**: `POST /{resource}/{id}/{action}`\n\nUse when:\n- Action doesn't fit CRUD model\n- State transitions need to be explicit\n- Business logic requires specific endpoint\n\n## Request Validation\n\n### Input Validation Pattern\n\n```python\nfrom pydantic import BaseModel, EmailStr, Field, validator\n\nclass UserCreate(BaseModel):\n    email: EmailStr\n    password: str = Field(min_length=8, max_length=100)\n    name: str = Field(min_length=1, max_length=100)\n    age: int = Field(ge=18, le=120)\n\n    @validator('password')\n    def password_strength(cls, v):\n        if not any(c.isupper() for c in v):\n            raise ValueError('Password must contain uppercase letter')\n        if not any(c.isdigit() for c in v):\n            raise ValueError('Password must contain digit')\n        return v\n```\n\n### Validation Error Response\n\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Request validation failed\",\n    \"errors\": [\n      {\n        \"field\": \"email\",\n        \"message\": \"Email is required\",\n        \"code\": \"REQUIRED_FIELD\"\n      },\n      {\n        \"field\": \"password\",\n        \"message\": \"Password must contain uppercase letter\",\n        \"code\": \"INVALID_FORMAT\"\n      }\n    ]\n  }\n}\n```\n\n## Filtering, Sorting, Searching\n\n### Filtering\n```http\n# Single filter\nGET /api/v1/posts?status=published\n\n# Multiple filters (AND)\nGET /api/v1/posts?status=published&author=john\n\n# Multiple values (OR)\nGET /api/v1/posts?tags=tech,ai,ml\n\n# Range filters\nGET /api/v1/posts?created_after=2025-01-01&created_before=2025-12-31\n```\n\n### Sorting\n```http\n# Single field ascending\nGET /api/v1/posts?sort=created_at\n\n# Single field descending\nGET /api/v1/posts?sort=-created_at\n\n# Multiple fields\nGET /api/v1/posts?sort=-priority,created_at\n```\n\n### Searching\n```http\n# Full-text search\nGET /api/v1/posts?q=machine+learning\n\n# Field-specific search\nGET /api/v1/posts?title=contains:machine&author=starts_with:john\n```\n\n## Idempotency\n\n### Idempotent Operations (Safe to Retry)\n- GET, PUT, DELETE: Always idempotent\n- POST: Not idempotent by default\n\n### Idempotency Keys for POST\n\n```http\nPOST /api/v1/payments\nIdempotency-Key: 550e8400-e29b-41d4-a716-446655440000\n\n{\n  \"amount\": 100.00,\n  \"currency\": \"USD\",\n  \"description\": \"Payment for order #123\"\n}\n```\n\n**Server stores idempotency key**:\n- First request: Process and return 201\n- Duplicate requests with same key: Return cached 201 response\n- Different request with same key: Return 409 Conflict\n\n## Async Operations\n\n### Long-Running Tasks\n\n```http\nPOST /api/v1/reports/generate\n{\n  \"type\": \"annual_summary\",\n  \"year\": 2025\n}\n\nResponse (202 Accepted):\n{\n  \"id\": \"job_abc123\",\n  \"status\": \"processing\",\n  \"statusUrl\": \"/api/v1/jobs/job_abc123\"\n}\n```\n\n### Check Status\n\n```http\nGET /api/v1/jobs/job_abc123\n\nResponse:\n{\n  \"id\": \"job_abc123\",\n  \"status\": \"completed\",\n  \"result\": {\n    \"reportUrl\": \"/api/v1/reports/annual_summary_2025.pdf\"\n  },\n  \"createdAt\": \"2025-10-16T10:00:00Z\",\n  \"completedAt\": \"2025-10-16T10:05:00Z\"\n}\n```\n\n**Status values**: `queued`, `processing`, `completed`, `failed`\n\n## Webhooks\n\n### Webhook Payload\n\n```json\n{\n  \"event\": \"user.created\",\n  \"timestamp\": \"2025-10-16T10:30:00Z\",\n  \"id\": \"evt_abc123\",\n  \"data\": {\n    \"id\": \"user_123\",\n    \"email\": \"user@example.com\",\n    \"name\": \"John Doe\"\n  }\n}\n```\n\n### Webhook Security\n\n**HMAC Signature**:\n```http\nPOST https://customer.com/webhooks\nX-Webhook-Signature: sha256=abc123...\n\n# Verify signature\nimport hmac\nimport hashlib\n\ndef verify_webhook(payload, signature, secret):\n    expected = hmac.new(\n        secret.encode(),\n        payload.encode(),\n        hashlib.sha256\n    ).hexdigest()\n    return hmac.compare_digest(f\"sha256={expected}\", signature)\n```\n\n## API Performance Best Practices\n\n### 1. Use ETags for Caching\n\n```http\nGET /api/v1/users/123\nETag: \"33a64df551425fcc55e4d42a148795d9f25f89d4\"\n\n# Client sends If-None-Match on subsequent requests\nGET /api/v1/users/123\nIf-None-Match: \"33a64df551425fcc55e4d42a148795d9f25f89d4\"\n\nResponse: 304 Not Modified (if unchanged)\n```\n\n### 2. Implement Field Selection\n\n```http\n# Get only specific fields\nGET /api/v1/users/123?fields=id,email,name\n\nResponse:\n{\n  \"id\": \"user_123\",\n  \"email\": \"user@example.com\",\n  \"name\": \"John Doe\"\n}\n```\n\n### 3. Use Compression\n\n```http\nAccept-Encoding: gzip, deflate\n```\n\nServer should compress responses >1KB.\n\n### 4. Batch Operations\n\n```http\n# Instead of N individual requests\nGET /api/v1/users/1\nGET /api/v1/users/2\nGET /api/v1/users/3\n\n# Use batch endpoint\nGET /api/v1/users?ids=1,2,3\n```\n\n### 5. Database Query Optimization\n\n- Use database indexes on filter fields\n- Limit result set size (max 100 items per page)\n- Use connection pooling\n- Implement query caching for expensive queries\n\n## HATEOAS (Hypermedia)\n\n### Including Links in Responses\n\n```json\n{\n  \"data\": {\n    \"id\": \"user_123\",\n    \"email\": \"user@example.com\",\n    \"name\": \"John Doe\"\n  },\n  \"links\": {\n    \"self\": \"/api/v1/users/123\",\n    \"posts\": \"/api/v1/users/123/posts\",\n    \"comments\": \"/api/v1/users/123/comments\",\n    \"avatar\": \"/api/v1/users/123/avatar\"\n  }\n}\n```\n\n**Benefits**:\n- Self-documenting API\n- Clients discover available actions\n- API evolution easier\n\n## Content Negotiation\n\n### Request Format\n\n```http\nContent-Type: application/json\nAccept: application/json\n```\n\n### Support Multiple Formats (Optional)\n\n```http\n# Request JSON\nAccept: application/json\n\n# Request XML\nAccept: application/xml\n\n# Request CSV\nAccept: text/csv\n```\n\n## Deprecation Strategy\n\n### Announce Deprecation\n\n```http\nGET /api/v1/old-endpoint\nSunset: Sat, 31 Dec 2025 23:59:59 GMT\nDeprecation: Tue, 1 Oct 2025 00:00:00 GMT\nLink: </api/v2/new-endpoint>; rel=\"alternate\"\n```\n\n### Migration Guide\n\nProvide clear migration path:\n1. Announce deprecation 6-12 months in advance\n2. Provide migration guide with code examples\n3. Support old and new versions simultaneously\n4. Monitor usage of deprecated endpoints\n5. Send email notifications to API consumers\n6. Finally remove deprecated endpoint\n\n## API Health and Status\n\n### Health Check Endpoint\n\n```http\nGET /health\n\nResponse (200):\n{\n  \"status\": \"healthy\",\n  \"version\": \"1.2.3\",\n  \"timestamp\": \"2025-10-16T10:30:00Z\"\n}\n```\n\n### Readiness Check (Dependencies)\n\n```http\nGET /health/ready\n\nResponse (200):\n{\n  \"status\": \"ready\",\n  \"checks\": {\n    \"database\": \"ok\",\n    \"cache\": \"ok\",\n    \"messageQueue\": \"ok\",\n    \"externalAPI\": \"ok\"\n  }\n}\n\nResponse (503) if any dependency fails:\n{\n  \"status\": \"not_ready\",\n  \"checks\": {\n    \"database\": \"ok\",\n    \"cache\": \"degraded\",\n    \"messageQueue\": \"failed\"\n  }\n}\n```\n\n## Testing APIs\n\n### Unit Testing Controllers\n\n```python\ndef test_create_user():\n    response = client.post(\"/api/v1/users\", json={\n        \"email\": \"test@example.com\",\n        \"password\": \"SecurePass123\",\n        \"name\": \"Test User\"\n    })\n\n    assert response.status_code == 201\n    assert response.json()[\"email\"] == \"test@example.com\"\n    assert \"password\" not in response.json()  # Never return passwords\n```\n\n### Integration Testing\n\n```python\ndef test_user_flow():\n    # Create user\n    response = client.post(\"/api/v1/users\", json=user_data)\n    user_id = response.json()[\"id\"]\n\n    # Login\n    response = client.post(\"/api/v1/auth/login\", json={\n        \"email\": user_data[\"email\"],\n        \"password\": user_data[\"password\"]\n    })\n    token = response.json()[\"accessToken\"]\n\n    # Access protected resource\n    response = client.get(\n        f\"/api/v1/users/{user_id}\",\n        headers={\"Authorization\": f\"Bearer {token}\"}\n    )\n    assert response.status_code == 200\n```\n\n## Common API Mistakes to Avoid\n\n1. **Using GET for state changes**: GET should be safe and idempotent\n2. **Returning sensitive data**: Never return passwords, tokens, secrets\n3. **Inconsistent naming**: Stick to camelCase or snake_case, not both\n4. **Missing error details**: Provide helpful error messages\n5. **No rate limiting**: Always implement rate limits\n6. **Exposing internal IDs**: Use UUIDs or slugs for public APIs\n7. **No versioning**: Always version from day one\n8. **Ignoring CORS**: Configure properly for web clients\n9. **Poor pagination**: Implement cursor-based for large datasets\n10. **No documentation**: Always provide OpenAPI docs\n\n## When to Use This Skill\n\nUse this skill when:\n- Designing new API endpoints\n- Implementing REST APIs\n- Reviewing API code\n- Creating API documentation\n- Troubleshooting API issues\n- Discussing authentication/authorization\n- Planning API versioning strategy\n- Implementing rate limiting\n- Handling errors in APIs\n\n---\n\n**Remember**: A well-designed API is intuitive, secure, performant, and well-documented. Follow these patterns to create APIs that developers love to use."
              },
              {
                "name": "code-quality-standards",
                "description": "Code quality standards including SOLID principles, design patterns, code smells, refactoring techniques, naming conventions, and technical debt management. Use when reviewing code, refactoring, ensuring quality, or detecting code smells.",
                "path": "plugins/titanium-toolkit/skills/code-quality-standards/SKILL.md",
                "frontmatter": {
                  "name": "code-quality-standards",
                  "description": "Code quality standards including SOLID principles, design patterns, code smells, refactoring techniques, naming conventions, and technical debt management. Use when reviewing code, refactoring, ensuring quality, or detecting code smells."
                },
                "content": "# Code Quality Standards\n\nThis skill provides comprehensive guidance for writing clean, maintainable, and high-quality code.\n\n## SOLID Principles\n\n### S - Single Responsibility Principle\n\n**Definition**: A class should have only one reason to change.\n\n```typescript\n// ‚ùå BAD - Multiple responsibilities\nclass UserManager {\n  createUser(data: UserData) {\n    // Validation logic\n    if (!data.email.includes('@')) throw new Error('Invalid email');\n\n    // Database logic\n    const user = database.insert('users', data);\n\n    // Email logic\n    emailService.send(data.email, 'Welcome!');\n\n    // Logging logic\n    logger.info(`User created: ${data.email}`);\n\n    return user;\n  }\n}\n\n// ‚úÖ GOOD - Single responsibility per class\nclass UserValidator {\n  validate(data: UserData): void {\n    if (!data.email.includes('@')) {\n      throw new Error('Invalid email');\n    }\n  }\n}\n\nclass UserRepository {\n  create(data: UserData): User {\n    return database.insert('users', data);\n  }\n}\n\nclass UserNotificationService {\n  sendWelcomeEmail(email: string): void {\n    emailService.send(email, 'Welcome!');\n  }\n}\n\nclass UserService {\n  constructor(\n    private validator: UserValidator,\n    private repository: UserRepository,\n    private notificationService: UserNotificationService,\n    private logger: Logger\n  ) {}\n\n  async createUser(data: UserData): Promise<User> {\n    this.validator.validate(data);\n    const user = await this.repository.create(data);\n    await this.notificationService.sendWelcomeEmail(user.email);\n    this.logger.info(`User created: ${user.email}`);\n    return user;\n  }\n}\n```\n\n### O - Open/Closed Principle\n\n**Definition**: Classes should be open for extension but closed for modification.\n\n```typescript\n// ‚ùå BAD - Must modify class to add new payment methods\nclass PaymentProcessor {\n  process(type: string, amount: number) {\n    if (type === 'credit_card') {\n      // Process credit card\n    } else if (type === 'paypal') {\n      // Process PayPal\n    } else if (type === 'bitcoin') {\n      // Process Bitcoin\n    }\n  }\n}\n\n// ‚úÖ GOOD - Can extend without modifying\ninterface PaymentMethod {\n  process(amount: number): Promise<PaymentResult>;\n}\n\nclass CreditCardPayment implements PaymentMethod {\n  async process(amount: number): Promise<PaymentResult> {\n    // Process credit card\n    return { success: true };\n  }\n}\n\nclass PayPalPayment implements PaymentMethod {\n  async process(amount: number): Promise<PaymentResult> {\n    // Process PayPal\n    return { success: true };\n  }\n}\n\nclass PaymentProcessor {\n  async process(method: PaymentMethod, amount: number): Promise<PaymentResult> {\n    return await method.process(amount);\n  }\n}\n\n// Add new payment method without modifying existing code\nclass BitcoinPayment implements PaymentMethod {\n  async process(amount: number): Promise<PaymentResult> {\n    // Process Bitcoin\n    return { success: true };\n  }\n}\n```\n\n### L - Liskov Substitution Principle\n\n**Definition**: Subtypes must be substitutable for their base types.\n\n```typescript\n// ‚ùå BAD - Violates LSP\nclass Rectangle {\n  constructor(protected width: number, protected height: number) {}\n\n  setWidth(width: number) {\n    this.width = width;\n  }\n\n  setHeight(height: number) {\n    this.height = height;\n  }\n\n  getArea(): number {\n    return this.width * this.height;\n  }\n}\n\nclass Square extends Rectangle {\n  setWidth(width: number) {\n    this.width = width;\n    this.height = width; // Violates expectation\n  }\n\n  setHeight(height: number) {\n    this.width = height; // Violates expectation\n    this.height = height;\n  }\n}\n\n// ‚úÖ GOOD - Separate abstractions\ninterface Shape {\n  getArea(): number;\n}\n\nclass Rectangle implements Shape {\n  constructor(private width: number, private height: number) {}\n\n  getArea(): number {\n    return this.width * this.height;\n  }\n}\n\nclass Square implements Shape {\n  constructor(private side: number) {}\n\n  getArea(): number {\n    return this.side * this.side;\n  }\n}\n```\n\n### I - Interface Segregation Principle\n\n**Definition**: Clients shouldn't be forced to depend on interfaces they don't use.\n\n```typescript\n// ‚ùå BAD - Fat interface\ninterface Worker {\n  work(): void;\n  eat(): void;\n  sleep(): void;\n  getPaid(): void;\n}\n\nclass HumanWorker implements Worker {\n  work() { /* ... */ }\n  eat() { /* ... */ }\n  sleep() { /* ... */ }\n  getPaid() { /* ... */ }\n}\n\nclass RobotWorker implements Worker {\n  work() { /* ... */ }\n  eat() { /* Not applicable */ }\n  sleep() { /* Not applicable */ }\n  getPaid() { /* Not applicable */ }\n}\n\n// ‚úÖ GOOD - Segregated interfaces\ninterface Workable {\n  work(): void;\n}\n\ninterface Eatable {\n  eat(): void;\n}\n\ninterface Sleepable {\n  sleep(): void;\n}\n\ninterface Payable {\n  getPaid(): void;\n}\n\nclass HumanWorker implements Workable, Eatable, Sleepable, Payable {\n  work() { /* ... */ }\n  eat() { /* ... */ }\n  sleep() { /* ... */ }\n  getPaid() { /* ... */ }\n}\n\nclass RobotWorker implements Workable {\n  work() { /* ... */ }\n}\n```\n\n### D - Dependency Inversion Principle\n\n**Definition**: Depend on abstractions, not concretions.\n\n```typescript\n// ‚ùå BAD - Depends on concrete implementation\nclass UserService {\n  private database = new MySQLDatabase(); // Tight coupling\n\n  async getUser(id: string) {\n    return this.database.query(`SELECT * FROM users WHERE id = ${id}`);\n  }\n}\n\n// ‚úÖ GOOD - Depends on abstraction\ninterface Database {\n  query(sql: string): Promise<any>;\n}\n\nclass MySQLDatabase implements Database {\n  async query(sql: string): Promise<any> {\n    // MySQL implementation\n  }\n}\n\nclass PostgreSQLDatabase implements Database {\n  async query(sql: string): Promise<any> {\n    // PostgreSQL implementation\n  }\n}\n\nclass UserService {\n  constructor(private database: Database) {} // Dependency injection\n\n  async getUser(id: string) {\n    return this.database.query(`SELECT * FROM users WHERE id = ${id}`);\n  }\n}\n\n// Can easily swap database implementations\nconst userService = new UserService(new PostgreSQLDatabase());\n```\n\n## DRY (Don't Repeat Yourself)\n\n### Identifying Duplication\n\n```typescript\n// ‚ùå BAD - Repeated validation logic\nfunction createUser(data: UserData) {\n  if (!data.email || !data.email.includes('@')) {\n    throw new Error('Invalid email');\n  }\n  if (!data.password || data.password.length < 8) {\n    throw new Error('Password too short');\n  }\n  // Create user\n}\n\nfunction updateUser(id: string, data: UserData) {\n  if (!data.email || !data.email.includes('@')) {\n    throw new Error('Invalid email');\n  }\n  if (!data.password || data.password.length < 8) {\n    throw new Error('Password too short');\n  }\n  // Update user\n}\n\n// ‚úÖ GOOD - Extract common logic\nfunction validateUserData(data: UserData): void {\n  if (!data.email || !data.email.includes('@')) {\n    throw new Error('Invalid email');\n  }\n  if (!data.password || data.password.length < 8) {\n    throw new Error('Password too short');\n  }\n}\n\nfunction createUser(data: UserData) {\n  validateUserData(data);\n  // Create user\n}\n\nfunction updateUser(id: string, data: UserData) {\n  validateUserData(data);\n  // Update user\n}\n```\n\n## KISS (Keep It Simple, Stupid)\n\n```typescript\n// ‚ùå BAD - Over-engineered\nclass NumberProcessor {\n  private strategy: ProcessingStrategy;\n\n  constructor(strategy: ProcessingStrategy) {\n    this.strategy = strategy;\n  }\n\n  process(numbers: number[]): number[] {\n    return this.strategy.execute(numbers);\n  }\n}\n\ninterface ProcessingStrategy {\n  execute(numbers: number[]): number[];\n}\n\nclass MultiplyByTwoStrategy implements ProcessingStrategy {\n  execute(numbers: number[]): number[] {\n    return numbers.map(n => n * 2);\n  }\n}\n\n// ‚úÖ GOOD - Simple and clear\nfunction multiplyByTwo(numbers: number[]): number[] {\n  return numbers.map(n => n * 2);\n}\n```\n\n## YAGNI (You Aren't Gonna Need It)\n\n```typescript\n// ‚ùå BAD - Building features you might need\nclass User {\n  id: string;\n  email: string;\n  name: string;\n\n  // Future features that aren't needed yet\n  preferences?: UserPreferences;\n  badges?: Badge[];\n  followers?: User[];\n  following?: User[];\n  achievements?: Achievement[];\n  notifications?: Notification[];\n}\n\n// ‚úÖ GOOD - Only what you need now\nclass User {\n  id: string;\n  email: string;\n  name: string;\n}\n\n// Add features when actually needed\n```\n\n## Design Patterns\n\n### Factory Pattern\n\n```typescript\ninterface Animal {\n  speak(): string;\n}\n\nclass Dog implements Animal {\n  speak(): string {\n    return 'Woof!';\n  }\n}\n\nclass Cat implements Animal {\n  speak(): string {\n    return 'Meow!';\n  }\n}\n\nclass AnimalFactory {\n  static create(type: 'dog' | 'cat'): Animal {\n    switch (type) {\n      case 'dog':\n        return new Dog();\n      case 'cat':\n        return new Cat();\n      default:\n        throw new Error('Unknown animal type');\n    }\n  }\n}\n\n// Usage\nconst dog = AnimalFactory.create('dog');\nconsole.log(dog.speak()); // \"Woof!\"\n```\n\n### Strategy Pattern\n\n```typescript\ninterface SortStrategy {\n  sort(data: number[]): number[];\n}\n\nclass QuickSort implements SortStrategy {\n  sort(data: number[]): number[] {\n    // Quick sort implementation\n    return data.sort((a, b) => a - b);\n  }\n}\n\nclass MergeSort implements SortStrategy {\n  sort(data: number[]): number[] {\n    // Merge sort implementation\n    return data.sort((a, b) => a - b);\n  }\n}\n\nclass Sorter {\n  constructor(private strategy: SortStrategy) {}\n\n  setStrategy(strategy: SortStrategy) {\n    this.strategy = strategy;\n  }\n\n  sort(data: number[]): number[] {\n    return this.strategy.sort(data);\n  }\n}\n\n// Usage\nconst sorter = new Sorter(new QuickSort());\nsorter.sort([3, 1, 4, 1, 5]);\n\nsorter.setStrategy(new MergeSort());\nsorter.sort([3, 1, 4, 1, 5]);\n```\n\n### Observer Pattern\n\n```typescript\ninterface Observer {\n  update(data: any): void;\n}\n\nclass Subject {\n  private observers: Observer[] = [];\n\n  attach(observer: Observer): void {\n    this.observers.push(observer);\n  }\n\n  detach(observer: Observer): void {\n    const index = this.observers.indexOf(observer);\n    if (index > -1) {\n      this.observers.splice(index, 1);\n    }\n  }\n\n  notify(data: any): void {\n    for (const observer of this.observers) {\n      observer.update(data);\n    }\n  }\n}\n\nclass EmailNotifier implements Observer {\n  update(data: any): void {\n    console.log(`Sending email: ${data}`);\n  }\n}\n\nclass SMSNotifier implements Observer {\n  update(data: any): void {\n    console.log(`Sending SMS: ${data}`);\n  }\n}\n\n// Usage\nconst subject = new Subject();\nsubject.attach(new EmailNotifier());\nsubject.attach(new SMSNotifier());\nsubject.notify('New user registered!');\n```\n\n### Singleton Pattern\n\n```typescript\nclass Database {\n  private static instance: Database;\n  private connection: any;\n\n  private constructor() {\n    // Private constructor prevents direct instantiation\n    this.connection = this.createConnection();\n  }\n\n  static getInstance(): Database {\n    if (!Database.instance) {\n      Database.instance = new Database();\n    }\n    return Database.instance;\n  }\n\n  private createConnection() {\n    // Create database connection\n    return {};\n  }\n\n  query(sql: string) {\n    // Execute query\n  }\n}\n\n// Usage - Always returns same instance\nconst db1 = Database.getInstance();\nconst db2 = Database.getInstance();\nconsole.log(db1 === db2); // true\n```\n\n## Code Smells and Detection\n\n### Long Method\n\n```typescript\n// ‚ùå BAD - Method too long (>20 lines)\nfunction processOrder(order: Order) {\n  // Validate order (10 lines)\n  // Calculate totals (15 lines)\n  // Apply discounts (20 lines)\n  // Process payment (25 lines)\n  // Send confirmation (10 lines)\n  // Update inventory (15 lines)\n  // Log transaction (5 lines)\n}\n\n// ‚úÖ GOOD - Extract methods\nfunction processOrder(order: Order) {\n  validateOrder(order);\n  const total = calculateTotal(order);\n  const discounted = applyDiscounts(total, order.promoCode);\n  processPayment(discounted);\n  sendConfirmation(order.email);\n  updateInventory(order.items);\n  logTransaction(order.id);\n}\n```\n\n### Large Class\n\n```typescript\n// ‚ùå BAD - Too many responsibilities\nclass User {\n  // User properties (20+ fields)\n  // User validation (10 methods)\n  // User persistence (10 methods)\n  // User authentication (5 methods)\n  // User notifications (5 methods)\n  // User reporting (5 methods)\n}\n\n// ‚úÖ GOOD - Split into focused classes\nclass User {\n  id: string;\n  email: string;\n  name: string;\n}\n\nclass UserValidator {\n  validate(user: User): boolean { /* ... */ }\n}\n\nclass UserRepository {\n  save(user: User): Promise<void> { /* ... */ }\n  find(id: string): Promise<User> { /* ... */ }\n}\n\nclass UserAuthService {\n  authenticate(credentials: Credentials): Promise<Token> { /* ... */ }\n}\n```\n\n### Duplicate Code\n\n```typescript\n// ‚ùå BAD - Duplicated logic\nfunction calculateEmployeeSalary(employee: Employee) {\n  let salary = employee.baseSalary;\n  salary += employee.baseSalary * 0.1; // 10% bonus\n  salary += employee.baseSalary * 0.05; // 5% tax deduction\n  return salary;\n}\n\nfunction calculateContractorSalary(contractor: Contractor) {\n  let salary = contractor.baseSalary;\n  salary += contractor.baseSalary * 0.1; // 10% bonus\n  salary += contractor.baseSalary * 0.05; // 5% tax deduction\n  return salary;\n}\n\n// ‚úÖ GOOD - Extract common logic\nfunction calculateSalary(baseSalary: number): number {\n  let salary = baseSalary;\n  salary += baseSalary * 0.1; // 10% bonus\n  salary += baseSalary * 0.05; // 5% tax deduction\n  return salary;\n}\n\nfunction calculateEmployeeSalary(employee: Employee) {\n  return calculateSalary(employee.baseSalary);\n}\n\nfunction calculateContractorSalary(contractor: Contractor) {\n  return calculateSalary(contractor.baseSalary);\n}\n```\n\n### God Object\n\n```typescript\n// ‚ùå BAD - Knows/does too much\nclass Application {\n  database: Database;\n  emailService: EmailService;\n  paymentProcessor: PaymentProcessor;\n\n  createUser() { /* ... */ }\n  sendEmail() { /* ... */ }\n  processPayment() { /* ... */ }\n  generateReport() { /* ... */ }\n  validateInput() { /* ... */ }\n  // ... 50 more methods\n}\n\n// ‚úÖ GOOD - Focused classes\nclass UserService {\n  createUser() { /* ... */ }\n}\n\nclass NotificationService {\n  sendEmail() { /* ... */ }\n}\n\nclass PaymentService {\n  processPayment() { /* ... */ }\n}\n```\n\n## Refactoring Patterns\n\n### Extract Method\n\n```typescript\n// Before\nfunction printOwing(invoice: Invoice) {\n  console.log('***********************');\n  console.log('**** Customer Owes ****');\n  console.log('***********************');\n\n  let outstanding = 0;\n  for (const order of invoice.orders) {\n    outstanding += order.amount;\n  }\n\n  console.log(`Name: ${invoice.customer}`);\n  console.log(`Amount: ${outstanding}`);\n}\n\n// After\nfunction printOwing(invoice: Invoice) {\n  printBanner();\n  const outstanding = calculateOutstanding(invoice);\n  printDetails(invoice.customer, outstanding);\n}\n\nfunction printBanner() {\n  console.log('***********************');\n  console.log('**** Customer Owes ****');\n  console.log('***********************');\n}\n\nfunction calculateOutstanding(invoice: Invoice): number {\n  return invoice.orders.reduce((sum, order) => sum + order.amount, 0);\n}\n\nfunction printDetails(customer: string, outstanding: number) {\n  console.log(`Name: ${customer}`);\n  console.log(`Amount: ${outstanding}`);\n}\n```\n\n### Introduce Parameter Object\n\n```typescript\n// Before\nfunction createUser(\n  firstName: string,\n  lastName: string,\n  email: string,\n  phone: string,\n  address: string,\n  city: string,\n  state: string,\n  zip: string\n) {\n  // Too many parameters\n}\n\n// After\ninterface UserDetails {\n  firstName: string;\n  lastName: string;\n  email: string;\n  phone: string;\n  address: Address;\n}\n\ninterface Address {\n  street: string;\n  city: string;\n  state: string;\n  zip: string;\n}\n\nfunction createUser(details: UserDetails) {\n  // Much cleaner\n}\n```\n\n### Replace Conditional with Polymorphism\n\n```typescript\n// Before\nclass Bird {\n  type: 'european' | 'african' | 'norwegian';\n\n  getSpeed(): number {\n    switch (this.type) {\n      case 'european':\n        return 35;\n      case 'african':\n        return 40;\n      case 'norwegian':\n        return 24;\n    }\n  }\n}\n\n// After\nabstract class Bird {\n  abstract getSpeed(): number;\n}\n\nclass EuropeanBird extends Bird {\n  getSpeed(): number {\n    return 35;\n  }\n}\n\nclass AfricanBird extends Bird {\n  getSpeed(): number {\n    return 40;\n  }\n}\n\nclass NorwegianBird extends Bird {\n  getSpeed(): number {\n    return 24;\n  }\n}\n```\n\n## Naming Conventions\n\n### Variables\n\n```typescript\n// ‚úÖ Descriptive, clear names\nconst userEmail = 'user@example.com';\nconst totalPrice = 100;\nconst isActive = true;\nconst hasPermission = false;\n\n// ‚ùå Vague, unclear names\nconst e = 'user@example.com';\nconst temp = 100;\nconst flag = true;\nconst data = {};\n```\n\n### Functions\n\n```typescript\n// ‚úÖ Verb + Noun for actions\nfunction getUserById(id: string): User { /* ... */ }\nfunction calculateTotalPrice(items: Item[]): number { /* ... */ }\nfunction isValidEmail(email: string): boolean { /* ... */ }\nfunction hasPermission(user: User, resource: string): boolean { /* ... */ }\n\n// ‚ùå Unclear names\nfunction user(id: string): User { /* ... */ }\nfunction price(items: Item[]): number { /* ... */ }\nfunction email(email: string): boolean { /* ... */ }\n```\n\n### Classes\n\n```typescript\n// ‚úÖ Noun or noun phrase\nclass UserRepository { /* ... */ }\nclass EmailValidator { /* ... */ }\nclass PaymentProcessor { /* ... */ }\nclass DatabaseConnection { /* ... */ }\n\n// ‚ùå Vague or verb names\nclass Manager { /* ... */ }\nclass Handler { /* ... */ }\nclass Process { /* ... */ }\n```\n\n### Constants\n\n```typescript\n// ‚úÖ SCREAMING_SNAKE_CASE for true constants\nconst MAX_RETRY_ATTEMPTS = 3;\nconst API_BASE_URL = 'https://api.example.com';\nconst DEFAULT_TIMEOUT_MS = 5000;\n\n// ‚úÖ camelCase for config objects\nconst databaseConfig = {\n  host: 'localhost',\n  port: 5432,\n};\n```\n\n## Function/Method Size Guidelines\n\n### Keep Functions Under 20 Lines\n\n```typescript\n// ‚ùå BAD - Too long (40+ lines)\nfunction processOrder(order: Order) {\n  // 40+ lines of logic\n}\n\n// ‚úÖ GOOD - Split into smaller functions\nfunction processOrder(order: Order) {\n  validateOrder(order);\n  const total = calculateTotal(order);\n  const payment = processPayment(order, total);\n  sendConfirmation(order, payment);\n  updateInventory(order);\n}\n\nfunction validateOrder(order: Order) {\n  // 5-10 lines\n}\n\nfunction calculateTotal(order: Order): number {\n  // 5-10 lines\n}\n```\n\n### Maximum 3-4 Parameters\n\n```typescript\n// ‚ùå BAD - Too many parameters\nfunction createUser(\n  firstName: string,\n  lastName: string,\n  email: string,\n  phone: string,\n  role: string,\n  department: string\n) { /* ... */ }\n\n// ‚úÖ GOOD - Use object parameter\ninterface CreateUserParams {\n  firstName: string;\n  lastName: string;\n  email: string;\n  phone: string;\n  role: string;\n  department: string;\n}\n\nfunction createUser(params: CreateUserParams) { /* ... */ }\n```\n\n## Cyclomatic Complexity\n\n### Keep Complexity Under 10\n\n```typescript\n// ‚ùå BAD - Complexity > 10\nfunction calculatePrice(item: Item, user: User): number {\n  let price = item.basePrice;\n\n  if (user.isPremium) {\n    price *= 0.9;\n  }\n\n  if (item.category === 'electronics') {\n    if (item.brand === 'Apple') {\n      price *= 1.2;\n    } else if (item.brand === 'Samsung') {\n      price *= 1.1;\n    }\n  }\n\n  if (user.location === 'CA') {\n    price *= 1.08;\n  } else if (user.location === 'NY') {\n    price *= 1.09;\n  } else if (user.location === 'TX') {\n    price *= 1.06;\n  }\n\n  return price;\n}\n\n// ‚úÖ GOOD - Split into focused functions\nfunction calculatePrice(item: Item, user: User): number {\n  let price = item.basePrice;\n  price = applyUserDiscount(price, user);\n  price = applyBrandMarkup(price, item);\n  price = applyLocationTax(price, user.location);\n  return price;\n}\n\nfunction applyUserDiscount(price: number, user: User): number {\n  return user.isPremium ? price * 0.9 : price;\n}\n\nfunction applyBrandMarkup(price: number, item: Item): number {\n  const markups = {\n    'Apple': 1.2,\n    'Samsung': 1.1,\n  };\n  return item.category === 'electronics'\n    ? price * (markups[item.brand] || 1)\n    : price;\n}\n\nfunction applyLocationTax(price: number, location: string): number {\n  const taxRates = {\n    'CA': 1.08,\n    'NY': 1.09,\n    'TX': 1.06,\n  };\n  return price * (taxRates[location] || 1);\n}\n```\n\n## Technical Debt Management\n\n### Document Technical Debt\n\n```typescript\n/**\n * TODO: Refactor this function - it's too complex\n * DEBT: Using deprecated API, need to migrate to v2\n * HACK: Workaround for bug in third-party library\n * FIXME: Race condition occurs under heavy load\n * OPTIMIZE: Query is slow, add database index\n */\n```\n\n### Track in Issue Tracker\n\n```markdown\n## Technical Debt Items\n\n### High Priority\n- [ ] Refactor UserService - violates SRP (Est: 8h)\n- [ ] Replace deprecated payment API (Est: 16h)\n- [ ] Fix race condition in order processing (Est: 4h)\n\n### Medium Priority\n- [ ] Optimize slow database queries (Est: 8h)\n- [ ] Add missing unit tests for AuthService (Est: 6h)\n\n### Low Priority\n- [ ] Improve error messages (Est: 2h)\n- [ ] Update documentation (Est: 4h)\n```\n\n### Allocate Time for Refactoring\n\n**20% Rule**: Spend 20% of sprint capacity on technical debt\n- 4 out of 10 story points\n- 1 out of 5 days per sprint\n- Prevents debt from accumulating\n\n## Code Review Checklist\n\n**Functionality**:\n- [ ] Code does what it's supposed to do\n- [ ] Edge cases handled\n- [ ] Error handling in place\n\n**Design**:\n- [ ] Follows SOLID principles\n- [ ] No code smells\n- [ ] Appropriate design patterns used\n\n**Readability**:\n- [ ] Clear naming conventions\n- [ ] Functions under 20 lines\n- [ ] Cyclomatic complexity under 10\n- [ ] Comments explain \"why\" not \"what\"\n\n**Tests**:\n- [ ] Unit tests added/updated\n- [ ] Test coverage adequate\n- [ ] Tests follow AAA pattern\n\n**Performance**:\n- [ ] No obvious performance issues\n- [ ] Database queries optimized\n- [ ] No N+1 query problems\n\n**Security**:\n- [ ] Input validation in place\n- [ ] No SQL injection vulnerabilities\n- [ ] Secrets not hardcoded\n\n## When to Use This Skill\n\nUse this skill when:\n- Reviewing code in pull requests\n- Refactoring existing code\n- Setting code standards for team\n- Onboarding new developers\n- Conducting code quality audits\n- Planning technical debt reduction\n- Designing new features\n- Improving codebase maintainability\n- Training team on best practices\n- Establishing coding guidelines\n\n---\n\n**Remember**: Code quality is not about perfection, but about maintainability. Write code that your future self and team members will thank you for."
              },
              {
                "name": "debugging-methodology",
                "description": "Scientific debugging methodology including hypothesis-driven debugging, bug reproduction, binary search debugging, stack trace analysis, logging strategies, and root cause analysis. Use when debugging errors, analyzing stack traces, investigating bugs, or troubleshooting performance issues.",
                "path": "plugins/titanium-toolkit/skills/debugging-methodology/SKILL.md",
                "frontmatter": {
                  "name": "debugging-methodology",
                  "description": "Scientific debugging methodology including hypothesis-driven debugging, bug reproduction, binary search debugging, stack trace analysis, logging strategies, and root cause analysis. Use when debugging errors, analyzing stack traces, investigating bugs, or troubleshooting performance issues."
                },
                "content": "# Debugging Methodology\n\nThis skill provides comprehensive guidance for systematically debugging issues using scientific methods and proven techniques.\n\n## Scientific Debugging Method\n\n### The Scientific Approach\n\n**1. Observe**: Gather information about the bug\n**2. Hypothesize**: Form theories about the cause\n**3. Test**: Design experiments to test hypotheses\n**4. Analyze**: Evaluate results\n**5. Conclude**: Fix the bug or refine hypothesis\n\n### Example: Debugging a Login Issue\n\n```typescript\n// Bug: Users cannot log in\n\n// 1. OBSERVE\n// - Error message: \"Invalid credentials\"\n// - Happens for all users\n// - Started after last deployment\n// - Logs show: \"bcrypt compare failed\"\n\n// 2. HYPOTHESIZE\n// Hypothesis 1: Password comparison logic is broken\n// Hypothesis 2: Database passwords corrupted\n// Hypothesis 3: Bcrypt library updated with breaking change\n\n// 3. TEST\n// Test 1: Check if bcrypt library version changed\nconst packageLock = await fs.readFile('package-lock.json');\n// Result: bcrypt upgraded from 5.0.0 to 6.0.0\n\n// Test 2: Check bcrypt changelog\n// Result: v6.0.0 changed default salt rounds\n\n// Test 3: Verify password hashing\nconst testPassword = 'password123';\nconst oldHash = '$2b$10$...'; // From database\nconst newHash = await bcrypt.hash(testPassword, 10);\nconsole.log(await bcrypt.compare(testPassword, oldHash)); // false\nconsole.log(await bcrypt.compare(testPassword, newHash)); // true\n\n// 4. ANALYZE\n// Old hashes use $2b$ format, new version uses $2a$ format\n// Incompatible hash formats\n\n// 5. CONCLUDE\n// Rollback bcrypt to 5.x or migrate all password hashes\n```\n\n## Reproducing Bugs Consistently\n\n### Creating Minimal Reproduction\n\n```typescript\n// Original bug report: \"App crashes when clicking submit\"\n\n// Step 1: Remove unrelated code\n// ‚ùå BAD - Too much noise\nfunction handleSubmit() {\n  validateForm();\n  checkPermissions();\n  logAnalytics();\n  sendToServer();\n  updateUI();\n  showNotification();\n  // Which one causes the crash?\n}\n\n// ‚úÖ GOOD - Minimal reproduction\nfunction handleSubmit() {\n  // Removed: validateForm, checkPermissions, logAnalytics, updateUI, showNotification\n  // Bug still occurs with just:\n  sendToServer();\n  // Root cause: sendToServer crashes with undefined data\n}\n```\n\n### Reproducing Race Conditions\n\n```typescript\n// Bug: Intermittent \"Cannot read property of undefined\"\n\n// Make race condition reproducible with delays\nasync function fetchUserData() {\n  const user = await fetchUser();\n  // Add artificial delay to make race condition consistent\n  await new Promise(resolve => setTimeout(resolve, 100));\n  return user.profile; // Sometimes undefined\n}\n\n// Once reproducible, investigate:\n// - Are multiple requests racing?\n// - Is data being cleared too early?\n// - Are promises resolving out of order?\n```\n\n### Creating Test Cases\n\n```typescript\n// Once bug is reproducible, create failing test\ndescribe('Login', () => {\n  test('should authenticate user with valid credentials', async () => {\n    const user = await db.user.create({\n      email: 'test@example.com',\n      password: await bcrypt.hash('password123', 10),\n    });\n\n    const result = await login('test@example.com', 'password123');\n\n    expect(result.success).toBe(true);\n    expect(result.user.email).toBe('test@example.com');\n  });\n});\n```\n\n## Binary Search Debugging\n\n### Finding the Breaking Commit\n\n```bash\n# Use git bisect to find the commit that introduced the bug\n\n# Start bisect\ngit bisect start\n\n# Mark current commit as bad (has the bug)\ngit bisect bad\n\n# Mark a known good commit (before bug appeared)\ngit bisect good v1.2.0\n\n# Git will checkout a commit in the middle\n# Test if bug exists, then mark:\ngit bisect bad   # Bug exists in this commit\n# or\ngit bisect good  # Bug doesn't exist in this commit\n\n# Repeat until git identifies the breaking commit\n# Git will output: \"abc123 is the first bad commit\"\n\n# End bisect session\ngit bisect reset\n```\n\n### Automated Bisect\n\n```bash\n# Create test script that exits 0 (pass) or 1 (fail)\n# test.sh\n#!/bin/bash\nnpm test 2>&1 | grep -q \"Login test failed\"\nif [ $? -eq 0 ]; then\n  exit 1  # Bug found\nelse\n  exit 0  # Bug not found\nfi\n\n# Run automated bisect\ngit bisect start HEAD v1.2.0\ngit bisect run ./test.sh\n\n# Git will automatically find the breaking commit\n```\n\n### Binary Search in Code\n\n```typescript\n// Bug: Function returns wrong result for large arrays\n\nfunction processArray(arr: number[]): number {\n  // 100 lines of code\n  // Which line causes the bug?\n}\n\n// Binary search approach:\n// 1. Comment out second half\nfunction processArray(arr: number[]): number {\n  // Lines 1-50\n  // Lines 51-100 (commented out)\n}\n// If bug disappears: Bug is in lines 51-100\n// If bug persists: Bug is in lines 1-50\n\n// 2. Repeat on the problematic half\n// Continue until you isolate the buggy line\n```\n\n## Stack Trace Analysis\n\n### Reading Stack Traces\n\n```\nError: Cannot read property 'name' of undefined\n    at getUserName (/app/src/user.ts:42:20)\n    at formatUserProfile (/app/src/profile.ts:15:25)\n    at handleRequest (/app/src/api.ts:89:30)\n    at Layer.handle [as handle_request] (/app/node_modules/express/lib/router/layer.js:95:5)\n```\n\n**Analysis**:\n1. **Error type**: TypeError - trying to access property on undefined\n2. **Error message**: \"Cannot read property 'name' of undefined\"\n3. **Origin**: `getUserName` function at line 42\n4. **Call chain**: api.ts ‚Üí profile.ts ‚Üí user.ts\n5. **Root cause location**: user.ts:42\n\n### Investigating the Stack Trace\n\n```typescript\n// user.ts:42\nfunction getUserName(userId: string): string {\n  const user = cache.get(userId);\n  return user.name; // ‚Üê Line 42: user is undefined\n}\n\n// Why is user undefined?\n// 1. Check cache.get implementation\n// 2. Check if userId is valid\n// 3. Check if user exists in cache\n\n// Add defensive check:\nfunction getUserName(userId: string): string {\n  const user = cache.get(userId);\n  if (!user) {\n    throw new Error(`User not found in cache: ${userId}`);\n  }\n  return user.name;\n}\n```\n\n### Source Maps for Production\n\n```javascript\n// Enable source maps in production\n// webpack.config.js\nmodule.exports = {\n  devtool: 'source-map',\n  // This generates .map files for production debugging\n};\n\n// View original TypeScript code in production errors\n// Instead of:\n//   at r (/app/bundle.js:1:23456)\n// You see:\n//   at getUserName (/app/src/user.ts:42:20)\n```\n\n## Logging Strategies\n\n### Strategic Log Placement\n\n```typescript\n// ‚úÖ GOOD - Log at key decision points\nasync function processOrder(order: Order) {\n  logger.info('Processing order', { orderId: order.id, items: order.items.length });\n\n  try {\n    // Log before critical operations\n    logger.debug('Validating order', { orderId: order.id });\n    await validateOrder(order);\n\n    logger.debug('Processing payment', { orderId: order.id, amount: order.total });\n    const payment = await processPayment(order);\n\n    logger.info('Order processed successfully', {\n      orderId: order.id,\n      paymentId: payment.id,\n      duration: Date.now() - startTime,\n    });\n\n    return payment;\n  } catch (error) {\n    // Log errors with context\n    logger.error('Order processing failed', {\n      orderId: order.id,\n      error: error.message,\n      stack: error.stack,\n    });\n    throw error;\n  }\n}\n```\n\n### Structured Logging\n\n```typescript\nimport winston from 'winston';\n\nconst logger = winston.createLogger({\n  level: process.env.LOG_LEVEL || 'info',\n  format: winston.format.combine(\n    winston.format.timestamp(),\n    winston.format.errors({ stack: true }),\n    winston.format.json()\n  ),\n  defaultMeta: {\n    service: 'order-service',\n    version: process.env.APP_VERSION,\n  },\n  transports: [\n    new winston.transports.File({ filename: 'error.log', level: 'error' }),\n    new winston.transports.File({ filename: 'combined.log' }),\n  ],\n});\n\n// Output:\n// {\n//   \"timestamp\": \"2025-10-16T10:30:00.000Z\",\n//   \"level\": \"error\",\n//   \"message\": \"Order processing failed\",\n//   \"orderId\": \"order_123\",\n//   \"error\": \"Payment declined\",\n//   \"service\": \"order-service\",\n//   \"version\": \"1.2.3\"\n// }\n```\n\n### Log Levels\n\n```typescript\n// Use appropriate log levels\nlogger.debug('Detailed debug information');  // Development only\nlogger.info('Normal operation');              // Informational\nlogger.warn('Warning but not an error');      // Potential issues\nlogger.error('Error occurred');               // Errors that need attention\nlogger.fatal('Critical failure');             // System-wide failures\n\n// Set log level by environment\nconst logLevel = {\n  development: 'debug',\n  staging: 'info',\n  production: 'warn',\n}[process.env.NODE_ENV];\n```\n\n## Debugging Tools\n\n### Using Debuggers\n\n```typescript\n// Set breakpoints in VS Code\nfunction calculateTotal(items: Item[]): number {\n  let total = 0;\n  for (const item of items) {\n    debugger; // Execution pauses here\n    total += item.price * item.quantity;\n  }\n  return total;\n}\n\n// Or use VS Code launch.json\n{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"type\": \"node\",\n      \"request\": \"launch\",\n      \"name\": \"Debug Tests\",\n      \"program\": \"${workspaceFolder}/node_modules/.bin/jest\",\n      \"args\": [\"--runInBand\"],\n      \"console\": \"integratedTerminal\"\n    }\n  ]\n}\n```\n\n### Node.js Built-in Debugger\n\n```bash\n# Start Node with inspector\nnode --inspect index.js\n\n# Open Chrome DevTools\n# Navigate to: chrome://inspect\n# Click \"inspect\" on your Node.js process\n\n# Or use Node's built-in debugger\nnode inspect index.js\n> cont  # Continue\n> next  # Step over\n> step  # Step into\n> out   # Step out\n> repl  # Enter REPL to inspect variables\n```\n\n### Memory Profiling\n\n```typescript\n// Detect memory leaks\nimport v8 from 'v8';\nimport fs from 'fs';\n\n// Take heap snapshot\nfunction takeHeapSnapshot(filename: string) {\n  const snapshot = v8.writeHeapSnapshot(filename);\n  console.log(`Heap snapshot written to ${snapshot}`);\n}\n\n// Compare snapshots to find leaks\ntakeHeapSnapshot('before.heapsnapshot');\n// ... run code that might leak\ntakeHeapSnapshot('after.heapsnapshot');\n\n// Analyze in Chrome DevTools:\n// 1. Open DevTools ‚Üí Memory tab\n// 2. Load snapshot\n// 3. Compare snapshots\n// 4. Look for objects that grew significantly\n```\n\n## Performance Profiling\n\n### CPU Profiling\n\n```typescript\n// Profile function execution time\nconsole.time('processLargeArray');\nprocessLargeArray(data);\nconsole.timeEnd('processLargeArray');\n// Output: processLargeArray: 1234.567ms\n\n// More detailed profiling\nimport { performance } from 'perf_hooks';\n\nconst start = performance.now();\nprocessLargeArray(data);\nconst end = performance.now();\nconsole.log(`Execution time: ${end - start}ms`);\n```\n\n### Node.js Profiler\n\n```bash\n# Generate CPU profile\nnode --prof index.js\n\n# Process profile data\nnode --prof-process isolate-0x*.log > profile.txt\n\n# Analyze profile.txt to find slow functions\n```\n\n### Chrome DevTools Performance\n\n```typescript\n// Add performance marks\nperformance.mark('start-data-processing');\nprocessData(data);\nperformance.mark('end-data-processing');\n\nperformance.measure(\n  'data-processing',\n  'start-data-processing',\n  'end-data-processing'\n);\n\nconst measure = performance.getEntriesByName('data-processing')[0];\nconsole.log(`Data processing took ${measure.duration}ms`);\n```\n\n## Network Debugging\n\n### HTTP Request Logging\n\n```typescript\nimport axios from 'axios';\n\n// Add request/response interceptors\naxios.interceptors.request.use(\n  (config) => {\n    console.log('Request:', {\n      method: config.method,\n      url: config.url,\n      headers: config.headers,\n      data: config.data,\n    });\n    return config;\n  },\n  (error) => {\n    console.error('Request error:', error);\n    return Promise.reject(error);\n  }\n);\n\naxios.interceptors.response.use(\n  (response) => {\n    console.log('Response:', {\n      status: response.status,\n      headers: response.headers,\n      data: response.data,\n    });\n    return response;\n  },\n  (error) => {\n    console.error('Response error:', {\n      status: error.response?.status,\n      data: error.response?.data,\n      message: error.message,\n    });\n    return Promise.reject(error);\n  }\n);\n```\n\n### Debugging CORS Issues\n\n```typescript\n// Enable detailed CORS logging\nimport cors from 'cors';\n\nconst corsOptions = {\n  origin: (origin, callback) => {\n    console.log('CORS request from origin:', origin);\n\n    const allowedOrigins = ['https://app.example.com'];\n    if (!origin || allowedOrigins.includes(origin)) {\n      callback(null, true);\n    } else {\n      console.log('CORS blocked:', origin);\n      callback(new Error('Not allowed by CORS'));\n    }\n  },\n  credentials: true,\n};\n\napp.use(cors(corsOptions));\n```\n\n## Race Condition Detection\n\n### Using Promises Correctly\n\n```typescript\n// ‚ùå BAD - Race condition\nlet userData = null;\n\nasync function loadUser() {\n  userData = await fetchUser(); // Takes 100ms\n}\n\nasync function displayUser() {\n  console.log(userData.name); // May be null if loadUser not finished\n}\n\nloadUser();\ndisplayUser(); // Race condition!\n\n// ‚úÖ GOOD - Wait for promise\nasync function main() {\n  await loadUser();\n  await displayUser(); // userData guaranteed to be loaded\n}\n```\n\n### Detecting Concurrent Modifications\n\n```typescript\n// Detect race conditions with version numbers\ninterface Document {\n  id: string;\n  content: string;\n  version: number;\n}\n\nasync function updateDocument(doc: Document) {\n  // Read current version\n  const current = await db.document.findUnique({\n    where: { id: doc.id },\n  });\n\n  // Check if version matches\n  if (current.version !== doc.version) {\n    throw new Error('Document was modified by another user');\n  }\n\n  // Update with incremented version\n  await db.document.update({\n    where: { id: doc.id, version: doc.version },\n    data: {\n      content: doc.content,\n      version: doc.version + 1,\n    },\n  });\n}\n```\n\n## Common Bug Patterns\n\n### Off-by-One Errors\n\n```typescript\n// ‚ùå BAD - Off by one\nconst arr = [1, 2, 3, 4, 5];\nfor (let i = 0; i <= arr.length; i++) {\n  console.log(arr[i]); // Last iteration: undefined\n}\n\n// ‚úÖ GOOD\nfor (let i = 0; i < arr.length; i++) {\n  console.log(arr[i]);\n}\n```\n\n### Null/Undefined Issues\n\n```typescript\n// ‚ùå BAD - No null check\nfunction getUserName(user: User): string {\n  return user.profile.name; // Crashes if user or profile is null\n}\n\n// ‚úÖ GOOD - Defensive checks\nfunction getUserName(user: User | null): string {\n  if (!user) {\n    return 'Unknown';\n  }\n  if (!user.profile) {\n    return 'No profile';\n  }\n  return user.profile.name;\n}\n\n// ‚úÖ BETTER - Optional chaining\nfunction getUserName(user: User | null): string {\n  return user?.profile?.name ?? 'Unknown';\n}\n```\n\n### Async/Await Pitfalls\n\n```typescript\n// ‚ùå BAD - Forgot await\nasync function getUser(id: string) {\n  const user = fetchUser(id); // Missing await!\n  return user.name; // user is a Promise, not the actual user\n}\n\n// ‚úÖ GOOD\nasync function getUser(id: string) {\n  const user = await fetchUser(id);\n  return user.name;\n}\n\n// ‚ùå BAD - Sequential when parallel is possible\nasync function loadData() {\n  const users = await fetchUsers();    // 1 second\n  const posts = await fetchPosts();    // 1 second\n  const comments = await fetchComments(); // 1 second\n  // Total: 3 seconds\n}\n\n// ‚úÖ GOOD - Parallel execution\nasync function loadData() {\n  const [users, posts, comments] = await Promise.all([\n    fetchUsers(),\n    fetchPosts(),\n    fetchComments(),\n  ]);\n  // Total: 1 second\n}\n```\n\n## Root Cause Analysis (5 Whys)\n\n### The 5 Whys Technique\n\n```\nProblem: Application crashed in production\n\nWhy? Memory leak caused out-of-memory error\n  Why? Array of user sessions kept growing\n    Why? Sessions weren't being cleaned up\n      Why? Cleanup function wasn't being called\n        Why? Event listener for cleanup was never registered\n          Root Cause: Missing initialization code in new deployment script\n```\n\n### RCA Template\n\n```markdown\n## Root Cause Analysis\n\n**Date**: 2025-10-16\n**Incident**: API downtime (30 minutes)\n\n### Timeline\n- 10:00 - Deployment started\n- 10:15 - First error reports\n- 10:20 - Incident declared\n- 10:25 - Rollback initiated\n- 10:30 - Service restored\n\n### Impact\n- 500 users affected\n- 10% of API requests failed\n- $5,000 estimated revenue loss\n\n### Root Cause\nDatabase connection pool exhausted due to missing connection cleanup in new feature code.\n\n### 5 Whys\n1. Why did the API fail? ‚Üí Database connections exhausted\n2. Why were connections exhausted? ‚Üí Connections not returned to pool\n3. Why weren't connections returned? ‚Üí Missing finally block in new code\n4. Why was the finally block missing? ‚Üí Code review missed it\n5. Why did code review miss it? ‚Üí No automated check for connection cleanup\n\n### Immediate Actions Taken\n- Rolled back deployment\n- Manually closed leaked connections\n- Service restored\n\n### Preventive Measures\n1. Add linter rule to detect missing finally blocks\n2. Add integration test for connection cleanup\n3. Update code review checklist\n4. Add monitoring for connection pool usage\n\n### Lessons Learned\n- Need better monitoring of connection pool metrics\n- Database connection patterns should be abstracted\n- Code review process needs improvement\n```\n\n## Debugging Checklist\n\n**Before Debugging**:\n- [ ] Can you reproduce the bug consistently?\n- [ ] Do you have a minimal reproduction case?\n- [ ] Have you checked recent changes (git log)?\n- [ ] Have you read error messages carefully?\n- [ ] Have you checked logs?\n\n**During Debugging**:\n- [ ] Are you using scientific method (hypothesis-driven)?\n- [ ] Have you added strategic logging?\n- [ ] Are you using a debugger effectively?\n- [ ] Have you isolated the problem area?\n- [ ] Have you considered race conditions?\n\n**After Fixing**:\n- [ ] Does the fix address root cause (not just symptoms)?\n- [ ] Have you added tests to prevent regression?\n- [ ] Have you documented the fix?\n- [ ] Have you conducted root cause analysis?\n- [ ] Have you shared learnings with team?\n\n## When to Use This Skill\n\nUse this skill when:\n- Debugging production issues\n- Investigating bug reports\n- Analyzing error logs\n- Troubleshooting performance problems\n- Finding memory leaks\n- Resolving race conditions\n- Conducting post-mortems\n- Training team on debugging\n- Improving debugging processes\n- Setting up debugging tools\n\n---\n\n**Remember**: Debugging is detective work. Be systematic, stay curious, and always document what you learn. The bug you fix today will teach you how to prevent similar bugs tomorrow."
              },
              {
                "name": "devops-patterns",
                "description": "DevOps patterns including CI/CD pipeline design, GitHub Actions, Infrastructure as Code, Docker, Kubernetes, deployment strategies, monitoring, and disaster recovery. Use when setting up CI/CD, deploying applications, managing infrastructure, or creating pipelines.",
                "path": "plugins/titanium-toolkit/skills/devops-patterns/SKILL.md",
                "frontmatter": {
                  "name": "devops-patterns",
                  "description": "DevOps patterns including CI/CD pipeline design, GitHub Actions, Infrastructure as Code, Docker, Kubernetes, deployment strategies, monitoring, and disaster recovery. Use when setting up CI/CD, deploying applications, managing infrastructure, or creating pipelines."
                },
                "content": "# DevOps Patterns\n\nThis skill provides comprehensive guidance for implementing DevOps practices, automation, and deployment strategies.\n\n## CI/CD Pipeline Design\n\n### Pipeline Stages\n\n```yaml\n# Complete CI/CD Pipeline\nstages:\n  - lint          # Code quality checks\n  - test          # Run test suite\n  - build         # Build artifacts\n  - scan          # Security scanning\n  - deploy-dev    # Deploy to development\n  - deploy-staging # Deploy to staging\n  - deploy-prod   # Deploy to production\n```\n\n### Pipeline Best Practices\n\n**1. Fast Feedback**: Run fastest checks first\n```yaml\njobs:\n  # Quick checks first (1-2 minutes)\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: npm run lint\n\n  type-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: npm run type-check\n\n  # Longer tests after (5-10 minutes)\n  test:\n    needs: [lint, type-check]\n    runs-on: ubuntu-latest\n    steps:\n      - run: npm test\n```\n\n**2. Fail Fast**: Stop pipeline on first failure\n**3. Idempotent**: Running twice produces same result\n**4. Versioned**: Pipeline config in version control\n\n## GitHub Actions Patterns\n\n### Basic Workflow Structure\n\n```yaml\n# .github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\nenv:\n  NODE_VERSION: '18'\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage/coverage-final.json\n```\n\n### Reusable Workflows\n\n```yaml\n# .github/workflows/reusable-test.yml\nname: Reusable Test Workflow\n\non:\n  workflow_call:\n    inputs:\n      node-version:\n        required: true\n        type: string\n    secrets:\n      DATABASE_URL:\n        required: true\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: ${{ inputs.node-version }}\n      - run: npm ci\n      - run: npm test\n        env:\n          DATABASE_URL: ${{ secrets.DATABASE_URL }}\n\n# Use in another workflow\n# .github/workflows/main.yml\njobs:\n  call-test:\n    uses: ./.github/workflows/reusable-test.yml\n    with:\n      node-version: '18'\n    secrets:\n      DATABASE_URL: ${{ secrets.DATABASE_URL }}\n```\n\n### Matrix Strategy\n\n```yaml\n# Test across multiple versions\njobs:\n  test:\n    strategy:\n      matrix:\n        node-version: [16, 18, 20]\n        os: [ubuntu-latest, windows-latest, macos-latest]\n    runs-on: ${{ matrix.os }}\n    steps:\n      - uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm test\n```\n\n### Custom Actions\n\n```yaml\n# .github/actions/deploy/action.yml\nname: 'Deploy Application'\ndescription: 'Deploy to specified environment'\ninputs:\n  environment:\n    description: 'Target environment'\n    required: true\n  api-key:\n    description: 'Deployment API key'\n    required: true\n\nruns:\n  using: 'composite'\n  steps:\n    - run: |\n        echo \"Deploying to ${{ inputs.environment }}\"\n        ./deploy.sh ${{ inputs.environment }}\n      env:\n        API_KEY: ${{ inputs.api-key }}\n      shell: bash\n\n# Usage\njobs:\n  deploy:\n    steps:\n      - uses: ./.github/actions/deploy\n        with:\n          environment: production\n          api-key: ${{ secrets.DEPLOY_KEY }}\n```\n\n### Conditional Execution\n\n```yaml\njobs:\n  deploy:\n    if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n    steps:\n      - name: Deploy to production\n        run: ./deploy.sh production\n\n  notify:\n    if: failure()\n    runs-on: ubuntu-latest\n    steps:\n      - name: Send failure notification\n        uses: slack/notify@v2\n        with:\n          message: 'Build failed!'\n```\n\n## Infrastructure as Code (Terraform)\n\n### Project Structure\n\n```\nterraform/\n‚îú‚îÄ‚îÄ modules/\n‚îÇ   ‚îú‚îÄ‚îÄ vpc/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf\n‚îÇ   ‚îú‚îÄ‚îÄ eks/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf\n‚îú‚îÄ‚îÄ environments/\n‚îÇ   ‚îú‚îÄ‚îÄ dev/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars\n‚îÇ   ‚îú‚îÄ‚îÄ staging/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars\n‚îÇ   ‚îî‚îÄ‚îÄ prod/\n‚îÇ       ‚îú‚îÄ‚îÄ main.tf\n‚îÇ       ‚îî‚îÄ‚îÄ terraform.tfvars\n‚îî‚îÄ‚îÄ global/\n    ‚îî‚îÄ‚îÄ s3/\n        ‚îî‚îÄ‚îÄ main.tf\n```\n\n### VPC Module Example\n\n```hcl\n# modules/vpc/main.tf\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name        = \"${var.environment}-vpc\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  count             = length(var.public_subnet_cidrs)\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = var.public_subnet_cidrs[count.index]\n  availability_zone = var.availability_zones[count.index]\n\n  tags = {\n    Name = \"${var.environment}-public-${count.index + 1}\"\n  }\n}\n\n# modules/vpc/variables.tf\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"CIDR blocks for public subnets\"\n  type        = list(string)\n}\n\nvariable \"availability_zones\" {\n  description = \"Availability zones\"\n  type        = list(string)\n}\n\n# modules/vpc/outputs.tf\noutput \"vpc_id\" {\n  value = aws_vpc.main.id\n}\n\noutput \"public_subnet_ids\" {\n  value = aws_subnet.public[*].id\n}\n```\n\n### Using Modules\n\n```hcl\n# environments/prod/main.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  backend \"s3\" {\n    bucket = \"my-terraform-state\"\n    key    = \"prod/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nmodule \"vpc\" {\n  source = \"../../modules/vpc\"\n\n  environment          = \"prod\"\n  vpc_cidr            = \"10.0.0.0/16\"\n  public_subnet_cidrs = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n  availability_zones  = [\"us-east-1a\", \"us-east-1b\"]\n}\n\nmodule \"eks\" {\n  source = \"../../modules/eks\"\n\n  cluster_name    = \"prod-cluster\"\n  vpc_id          = module.vpc.vpc_id\n  subnet_ids      = module.vpc.public_subnet_ids\n  node_count      = 3\n  node_instance_type = \"t3.large\"\n}\n```\n\n## Docker Best Practices\n\n### Multi-Stage Builds\n\n```dockerfile\n# Build stage\nFROM node:18-alpine AS builder\n\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm ci --only=production\n\n# Copy source code\nCOPY . .\n\n# Build application\nRUN npm run build\n\n# Production stage\nFROM node:18-alpine AS production\n\nWORKDIR /app\n\n# Copy only necessary files from builder\nCOPY --from=builder /app/package*.json ./\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY --from=builder /app/dist ./dist\n\n# Create non-root user\nRUN addgroup -g 1001 -S nodejs && \\\n    adduser -S nodejs -u 1001\n\nUSER nodejs\n\nEXPOSE 3000\n\nCMD [\"node\", \"dist/index.js\"]\n```\n\n### Layer Optimization\n\n```dockerfile\n# ‚úÖ GOOD - Dependencies cached separately\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Copy package files first (rarely change)\nCOPY package*.json ./\nRUN npm ci\n\n# Copy source code (changes frequently)\nCOPY . .\nRUN npm run build\n\n# ‚ùå BAD - Everything in one layer\nFROM node:18-alpine\nWORKDIR /app\nCOPY . .\nRUN npm ci && npm run build\n# Cache invalidated on every source change\n```\n\n### Security Best Practices\n\n```dockerfile\n# ‚úÖ Use specific versions\nFROM node:18.17.1-alpine\n\n# ‚úÖ Run as non-root user\nRUN addgroup -g 1001 nodejs && \\\n    adduser -S nodejs -u 1001\nUSER nodejs\n\n# ‚úÖ Use .dockerignore\n# .dockerignore:\nnode_modules\n.git\n.env\n*.md\n.github\n\n# ‚úÖ Scan for vulnerabilities\n# docker scan myapp:latest\n\n# ‚úÖ Use minimal base images\nFROM node:18-alpine  # Not node:18 (full)\n\n# ‚úÖ Don't include secrets\n# Use build args or runtime env vars\nARG API_KEY\nENV API_KEY=${API_KEY}\n```\n\n### Docker Compose for Development\n\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n    ports:\n      - '3000:3000'\n    volumes:\n      - .:/app\n      - /app/node_modules\n    environment:\n      - NODE_ENV=development\n      - DATABASE_URL=postgresql://user:pass@db:5432/mydb\n    depends_on:\n      - db\n      - redis\n\n  db:\n    image: postgres:15-alpine\n    ports:\n      - '5432:5432'\n    environment:\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=pass\n      - POSTGRES_DB=mydb\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - '6379:6379'\n\nvolumes:\n  postgres_data:\n```\n\n## Kubernetes Patterns\n\n### Deployment\n\n```yaml\n# deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\n  labels:\n    app: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:1.0.0\n        ports:\n        - containerPort: 3000\n        env:\n        - name: NODE_ENV\n          value: production\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: myapp-secrets\n              key: database-url\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n```\n\n### Service\n\n```yaml\n# service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 3000\n  type: LoadBalancer\n```\n\n### ConfigMap and Secrets\n\n```yaml\n# configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: myapp-config\ndata:\n  LOG_LEVEL: info\n  MAX_CONNECTIONS: \"100\"\n\n# secret.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: myapp-secrets\ntype: Opaque\ndata:\n  database-url: cG9zdGdyZXNxbDovL3VzZXI6cGFzc0BkYjU0MzIvbXlkYg==\n  api-key: c2tfbGl2ZV9hYmMxMjN4eXo=\n```\n\n### Ingress\n\n```yaml\n# ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  tls:\n  - hosts:\n    - myapp.example.com\n    secretName: myapp-tls\n  rules:\n  - host: myapp.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: myapp-service\n            port:\n              number: 80\n```\n\n## Deployment Strategies\n\n### Blue-Green Deployment\n\n```yaml\n# Blue deployment (current production)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-blue\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n      version: blue\n  template:\n    metadata:\n      labels:\n        app: myapp\n        version: blue\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:1.0.0\n\n---\n# Green deployment (new version)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-green\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n      version: green\n  template:\n    metadata:\n      labels:\n        app: myapp\n        version: green\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:2.0.0\n\n---\n# Service (switch by changing selector)\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n    version: blue  # Change to 'green' to switch\n  ports:\n  - port: 80\n    targetPort: 3000\n```\n\n### Canary Deployment\n\n```yaml\n# Stable deployment (90% traffic)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-stable\nspec:\n  replicas: 9\n  selector:\n    matchLabels:\n      app: myapp\n      track: stable\n\n---\n# Canary deployment (10% traffic)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-canary\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: myapp\n      track: canary\n\n---\n# Service routes to both\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp  # Matches both stable and canary\n  ports:\n  - port: 80\n    targetPort: 3000\n```\n\n### Rolling Update\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 10\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 2        # Max 2 extra pods during update\n      maxUnavailable: 1  # Max 1 pod unavailable during update\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:2.0.0\n```\n\n## Database Migration Strategies\n\n### Forward-Only Migrations\n\n```typescript\n// ‚úÖ GOOD - Backwards compatible\n// Step 1: Add new column (nullable)\nawait db.schema.alterTable('users', (table) => {\n  table.string('phone_number').nullable();\n});\n\n// Step 2: Populate data\nawait db('users').update({\n  phone_number: db.raw('contact_info'),\n});\n\n// Step 3: Make non-nullable (separate deployment)\nawait db.schema.alterTable('users', (table) => {\n  table.string('phone_number').notNullable().alter();\n});\n\n// Step 4: Drop old column (separate deployment)\nawait db.schema.alterTable('users', (table) => {\n  table.dropColumn('contact_info');\n});\n```\n\n### Zero-Downtime Migrations\n\n```typescript\n// Rename column without downtime\n\n// Migration 1: Add new column\nawait db.schema.alterTable('users', (table) => {\n  table.string('email_address').nullable();\n});\n\n// Update application code to write to both columns\nclass User {\n  async save() {\n    await db('users').update({\n      email: this.email,\n      email_address: this.email, // Write to both\n    });\n  }\n}\n\n// Migration 2: Backfill data\nawait db.raw(`\n  UPDATE users\n  SET email_address = email\n  WHERE email_address IS NULL\n`);\n\n// Migration 3: Update app to read from new column\nclass User {\n  get email() {\n    return this.email_address; // Read from new column\n  }\n}\n\n// Migration 4: Drop old column\nawait db.schema.alterTable('users', (table) => {\n  table.dropColumn('email');\n});\n```\n\n## Environment Management\n\n### Environment Configuration\n\n```typescript\n// config/environments.ts\ninterface EnvironmentConfig {\n  database: {\n    host: string;\n    port: number;\n    name: string;\n  };\n  api: {\n    baseUrl: string;\n    timeout: number;\n  };\n  features: {\n    enableNewFeature: boolean;\n  };\n}\n\nconst environments: Record<string, EnvironmentConfig> = {\n  development: {\n    database: {\n      host: 'localhost',\n      port: 5432,\n      name: 'myapp_dev',\n    },\n    api: {\n      baseUrl: 'http://localhost:3000',\n      timeout: 30000,\n    },\n    features: {\n      enableNewFeature: true,\n    },\n  },\n  staging: {\n    database: {\n      host: 'staging-db.example.com',\n      port: 5432,\n      name: 'myapp_staging',\n    },\n    api: {\n      baseUrl: 'https://staging-api.example.com',\n      timeout: 10000,\n    },\n    features: {\n      enableNewFeature: true,\n    },\n  },\n  production: {\n    database: {\n      host: process.env.DB_HOST!,\n      port: parseInt(process.env.DB_PORT!),\n      name: 'myapp_prod',\n    },\n    api: {\n      baseUrl: 'https://api.example.com',\n      timeout: 5000,\n    },\n    features:  {\n      enableNewFeature: false,\n    },\n  },\n};\n\nexport const config = environments[process.env.NODE_ENV || 'development'];\n```\n\n## Monitoring\n\n### Prometheus Metrics\n\n```typescript\nimport prometheus from 'prom-client';\n\n// Create metrics\nconst httpRequestDuration = new prometheus.Histogram({\n  name: 'http_request_duration_seconds',\n  help: 'Duration of HTTP requests in seconds',\n  labelNames: ['method', 'route', 'status'],\n});\n\nconst httpRequestTotal = new prometheus.Counter({\n  name: 'http_requests_total',\n  help: 'Total number of HTTP requests',\n  labelNames: ['method', 'route', 'status'],\n});\n\n// Middleware to track metrics\napp.use((req, res, next) => {\n  const start = Date.now();\n\n  res.on('finish', () => {\n    const duration = (Date.now() - start) / 1000;\n\n    httpRequestDuration\n      .labels(req.method, req.route?.path || req.path, res.statusCode.toString())\n      .observe(duration);\n\n    httpRequestTotal\n      .labels(req.method, req.route?.path || req.path, res.statusCode.toString())\n      .inc();\n  });\n\n  next();\n});\n\n// Expose metrics endpoint\napp.get('/metrics', async (req, res) => {\n  res.set('Content-Type', prometheus.register.contentType);\n  res.end(await prometheus.register.metrics());\n});\n```\n\n### Grafana Dashboard\n\n```json\n{\n  \"dashboard\": {\n    \"title\": \"Application Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_requests_total[5m])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Response Time (p95)\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, http_request_duration_seconds_bucket)\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_requests_total{status=~\\\"5..\\\"}[5m])\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n### Log Aggregation\n\n```typescript\n// Winston logger with JSON format\nimport winston from 'winston';\n\nconst logger = winston.createLogger({\n  level: 'info',\n  format: winston.format.combine(\n    winston.format.timestamp(),\n    winston.format.errors({ stack: true }),\n    winston.format.json()\n  ),\n  defaultMeta: {\n    service: 'myapp',\n    environment: process.env.NODE_ENV,\n  },\n  transports: [\n    new winston.transports.File({ filename: 'error.log', level: 'error' }),\n    new winston.transports.File({ filename: 'combined.log' }),\n  ],\n});\n\n// Structured logging\nlogger.info('User logged in', {\n  userId: user.id,\n  email: user.email,\n  ip: req.ip,\n});\n```\n\n## Disaster Recovery\n\n### Backup Strategy\n\n```bash\n#!/bin/bash\n# backup-database.sh\n\n# Configuration\nDB_HOST=\"${DB_HOST}\"\nDB_NAME=\"${DB_NAME}\"\nBACKUP_DIR=\"/backups\"\nS3_BUCKET=\"s3://my-backups\"\nRETENTION_DAYS=30\n\n# Create backup\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"${BACKUP_DIR}/${DB_NAME}_${TIMESTAMP}.sql.gz\"\n\n# Dump database\npg_dump -h \"${DB_HOST}\" -U postgres \"${DB_NAME}\" | gzip > \"${BACKUP_FILE}\"\n\n# Upload to S3\naws s3 cp \"${BACKUP_FILE}\" \"${S3_BUCKET}/\"\n\n# Remove local backup\nrm \"${BACKUP_FILE}\"\n\n# Delete old backups from S3\naws s3 ls \"${S3_BUCKET}/\" | while read -r line; do\n  FILE_DATE=$(echo \"$line\" | awk '{print $1}')\n  FILE_NAME=$(echo \"$line\" | awk '{print $4}')\n\n  FILE_EPOCH=$(date -d \"$FILE_DATE\" +%s)\n  CURRENT_EPOCH=$(date +%s)\n  DAYS_OLD=$(( (CURRENT_EPOCH - FILE_EPOCH) / 86400 ))\n\n  if [ $DAYS_OLD -gt $RETENTION_DAYS ]; then\n    aws s3 rm \"${S3_BUCKET}/${FILE_NAME}\"\n  fi\ndone\n```\n\n### Recovery Plan\n\n```markdown\n## Disaster Recovery Plan\n\n### RTO (Recovery Time Objective): 4 hours\n### RPO (Recovery Point Objective): 1 hour\n\n### Recovery Steps:\n\n1. **Assess the situation**\n   - Identify scope of failure\n   - Notify stakeholders\n\n2. **Restore database**\n   ```bash\n   # Download latest backup\n   aws s3 cp s3://my-backups/latest.sql.gz /tmp/\n\n   # Restore database\n   gunzip -c /tmp/latest.sql.gz | psql -h new-db -U postgres myapp\n   ```\n\n3. **Deploy application**\n   ```bash\n   # Deploy to new infrastructure\n   kubectl apply -f k8s/production/\n\n   # Update DNS\n   aws route53 change-resource-record-sets ...\n   ```\n\n4. **Verify recovery**\n   - Run smoke tests\n   - Check monitoring dashboards\n   - Verify critical features\n\n5. **Post-mortem**\n   - Document incident\n   - Identify root cause\n   - Create action items\n```\n\n## When to Use This Skill\n\nUse this skill when:\n- Setting up CI/CD pipelines\n- Deploying applications\n- Managing infrastructure\n- Implementing deployment strategies\n- Configuring monitoring\n- Planning disaster recovery\n- Containerizing applications\n- Orchestrating with Kubernetes\n- Automating workflows\n- Scaling infrastructure\n\n---\n\n**Remember**: DevOps is about automation, reliability, and continuous improvement. Invest in your infrastructure and deployment processes to enable faster, safer releases."
              },
              {
                "name": "frontend-patterns",
                "description": "Modern frontend architecture patterns for React, Next.js, and TypeScript including component composition, state management, performance optimization, accessibility, and responsive design. Use when building UI components, implementing frontend features, optimizing performance, or working with React/Next.js applications.",
                "path": "plugins/titanium-toolkit/skills/frontend-patterns/SKILL.md",
                "frontmatter": {
                  "name": "frontend-patterns",
                  "description": "Modern frontend architecture patterns for React, Next.js, and TypeScript including component composition, state management, performance optimization, accessibility, and responsive design. Use when building UI components, implementing frontend features, optimizing performance, or working with React/Next.js applications."
                },
                "content": "# Frontend Development Patterns\n\nThis skill provides comprehensive guidance for modern frontend development using React, Next.js, TypeScript, and related technologies.\n\n## Component Architecture\n\n### Component Composition Patterns\n\n**Container/Presentational Pattern**:\n```typescript\n// Presentational component (pure, reusable)\ninterface UserCardProps {\n  name: string;\n  email: string;\n  avatar: string;\n  onEdit: () => void;\n}\n\nfunction UserCard({ name, email, avatar, onEdit }: UserCardProps) {\n  return (\n    <div className=\"user-card\">\n      <img src={avatar} alt={name} />\n      <h3>{name}</h3>\n      <p>{email}</p>\n      <button onClick={onEdit}>Edit</button>\n    </div>\n  );\n}\n\n// Container component (handles logic, state, data fetching)\nfunction UserCardContainer({ userId }: { userId: string }) {\n  const { data: user, isLoading } = useUser(userId);\n  const { mutate: updateUser } = useUpdateUser();\n\n  if (isLoading) return <Skeleton />;\n  if (!user) return <NotFound />;\n\n  return <UserCard {...user} onEdit={() => updateUser(user.id)} />;\n}\n```\n\n**Compound Components Pattern**:\n```typescript\n// Flexible, composable API\n<Tabs defaultValue=\"profile\">\n  <TabsList>\n    <TabsTrigger value=\"profile\">Profile</TabsTrigger>\n    <TabsTrigger value=\"settings\">Settings</TabsTrigger>\n  </TabsList>\n  <TabsContent value=\"profile\">\n    <ProfileForm />\n  </TabsContent>\n  <TabsContent value=\"settings\">\n    <SettingsForm />\n  </TabsContent>\n</Tabs>\n```\n\n### Component Organization\n\n```\ncomponents/\n‚îú‚îÄ‚îÄ ui/                    # Primitive components (buttons, inputs)\n‚îÇ   ‚îú‚îÄ‚îÄ button.tsx\n‚îÇ   ‚îú‚îÄ‚îÄ input.tsx\n‚îÇ   ‚îî‚îÄ‚îÄ card.tsx\n‚îú‚îÄ‚îÄ forms/                 # Form components\n‚îÇ   ‚îú‚îÄ‚îÄ login-form.tsx\n‚îÇ   ‚îî‚îÄ‚îÄ register-form.tsx\n‚îú‚îÄ‚îÄ features/              # Feature-specific components\n‚îÇ   ‚îú‚îÄ‚îÄ user-profile/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profile-header.tsx\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profile-stats.tsx\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts\n‚îÇ   ‚îî‚îÄ‚îÄ dashboard/\n‚îÇ       ‚îú‚îÄ‚îÄ dashboard-grid.tsx\n‚îÇ       ‚îî‚îÄ‚îÄ dashboard-card.tsx\n‚îî‚îÄ‚îÄ layouts/               # Layout components\n    ‚îú‚îÄ‚îÄ main-layout.tsx\n    ‚îî‚îÄ‚îÄ auth-layout.tsx\n```\n\n## State Management\n\n### Local State (useState)\n\nUse for:\n- Component-specific UI state\n- Form inputs\n- Toggles, modals\n\n```typescript\nfunction SearchBar() {\n  const [query, setQuery] = useState('');\n  const [isOpen, setIsOpen] = useState(false);\n\n  return (\n    <div>\n      <input\n        value={query}\n        onChange={(e) => setQuery(e.target.value)}\n      />\n      {isOpen && <SearchResults query={query} />}\n    </div>\n  );\n}\n```\n\n### Global State (Zustand)\n\nUse for:\n- User authentication state\n- Theme preferences\n- Shopping cart\n- Cross-component shared state\n\n```typescript\nimport create from 'zustand';\n\ninterface UserStore {\n  user: User | null;\n  setUser: (user: User) => void;\n  logout: () => void;\n}\n\nexport const useUserStore = create<UserStore>((set) => ({\n  user: null,\n  setUser: (user) => set({ user }),\n  logout: () => set({ user: null }),\n}));\n\n// Usage\nfunction Header() {\n  const user = useUserStore((state) => state.user);\n  const logout = useUserStore((state) => state.logout);\n\n  return <div>{user ? user.name : 'Guest'}</div>;\n}\n```\n\n### Server State (React Query / TanStack Query)\n\nUse for:\n- API data fetching\n- Caching API responses\n- Optimistic updates\n- Background refetching\n\n```typescript\nimport { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';\n\n// Fetch data\nfunction UserProfile({ userId }: { userId: string }) {\n  const { data, isLoading, error } = useQuery({\n    queryKey: ['user', userId],\n    queryFn: () => fetchUser(userId),\n    staleTime: 5 * 60 * 1000, // 5 minutes\n  });\n\n  if (isLoading) return <Skeleton />;\n  if (error) return <Error error={error} />;\n\n  return <div>{data.name}</div>;\n}\n\n// Mutations with optimistic updates\nfunction useUpdateUser() {\n  const queryClient = useQueryClient();\n\n  return useMutation({\n    mutationFn: (user: User) => api.updateUser(user),\n    onMutate: async (newUser) => {\n      // Cancel outgoing refetches\n      await queryClient.cancelQueries({ queryKey: ['user', newUser.id] });\n\n      // Snapshot previous value\n      const previous = queryClient.getQueryData(['user', newUser.id]);\n\n      // Optimistically update\n      queryClient.setQueryData(['user', newUser.id], newUser);\n\n      return { previous };\n    },\n    onError: (err, newUser, context) => {\n      // Rollback on error\n      queryClient.setQueryData(['user', newUser.id], context?.previous);\n    },\n    onSettled: (newUser) => {\n      // Refetch after mutation\n      queryClient.invalidateQueries({ queryKey: ['user', newUser.id] });\n    },\n  });\n}\n```\n\n## Performance Optimization\n\n### 1. Memoization\n\n**useMemo** (expensive calculations):\n```typescript\nfunction ProductList({ products }: { products: Product[] }) {\n  const sortedProducts = useMemo(\n    () => products.sort((a, b) => b.price - a.price),\n    [products]\n  );\n\n  return <div>{sortedProducts.map(...)}</div>;\n}\n```\n\n**useCallback** (prevent re-renders):\n```typescript\nfunction Parent() {\n  const [count, setCount] = useState(0);\n\n  // ‚úÖ Memoized - Child won't re-render unless count changes\n  const handleClick = useCallback(() => {\n    setCount(c => c + 1);\n  }, []);\n\n  return <Child onClick={handleClick} />;\n}\n\nconst Child = memo(function Child({ onClick }: { onClick: () => void }) {\n  console.log('Child rendered');\n  return <button onClick={onClick}>Click</button>;\n});\n```\n\n**React.memo** (prevent component re-renders):\n```typescript\nconst ExpensiveComponent = memo(function ExpensiveComponent({ data }) {\n  // Only re-renders if data changes\n  return <div>{/* expensive rendering */}</div>;\n});\n```\n\n### 2. Code Splitting\n\n**Route-based splitting** (Next.js automatic):\n```typescript\n// app/dashboard/page.tsx - automatically code split\nexport default function DashboardPage() {\n  return <Dashboard />;\n}\n```\n\n**Component-level splitting**:\n```typescript\nimport dynamic from 'next/dynamic';\n\nconst HeavyChart = dynamic(() => import('@/components/heavy-chart'), {\n  loading: () => <Skeleton />,\n  ssr: false, // Don't render on server\n});\n\nfunction Analytics() {\n  return <HeavyChart data={chartData} />;\n}\n```\n\n### 3. Image Optimization\n\n```typescript\nimport Image from 'next/image';\n\n// ‚úÖ Optimized - Next.js Image component\n<Image\n  src=\"/hero.jpg\"\n  alt=\"Hero image\"\n  width={800}\n  height={600}\n  priority // Load immediately for LCP\n  placeholder=\"blur\"\n  blurDataURL=\"data:image/...\"\n/>\n\n// ‚ùå Not optimized\n<img src=\"/hero.jpg\" alt=\"Hero\" />\n```\n\n### 4. Lazy Loading\n\n```typescript\nimport { lazy, Suspense } from 'react';\n\nconst Comments = lazy(() => import('./comments'));\n\nfunction Post() {\n  return (\n    <div>\n      <PostContent />\n      <Suspense fallback={<CommentsSkeleton />}>\n        <Comments postId={postId} />\n      </Suspense>\n    </div>\n  );\n}\n```\n\n### 5. Virtual Scrolling\n\n```typescript\nimport { useVirtualizer } from '@tanstack/react-virtual';\n\nfunction VirtualList({ items }: { items: Item[] }) {\n  const parentRef = useRef<HTMLDivElement>(null);\n\n  const virtualizer = useVirtualizer({\n    count: items.length,\n    getScrollElement: () => parentRef.current,\n    estimateSize: () => 50,\n  });\n\n  return (\n    <div ref={parentRef} style={{ height: '400px', overflow: 'auto' }}>\n      <div style={{ height: `${virtualizer.getTotalSize()}px` }}>\n        {virtualizer.getVirtualItems().map((virtualRow) => (\n          <div\n            key={virtualRow.index}\n            style={{\n              position: 'absolute',\n              top: 0,\n              left: 0,\n              width: '100%',\n              height: `${virtualRow.size}px`,\n              transform: `translateY(${virtualRow.start}px)`,\n            }}\n          >\n            {items[virtualRow.index].name}\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n}\n```\n\n## Accessibility (a11y)\n\n### Semantic HTML\n\n```typescript\n// ‚úÖ Semantic\n<nav>\n  <ul>\n    <li><a href=\"/home\">Home</a></li>\n    <li><a href=\"/about\">About</a></li>\n  </ul>\n</nav>\n\n// ‚ùå Non-semantic\n<div>\n  <div>\n    <div onClick={goHome}>Home</div>\n    <div onClick={goAbout}>About</div>\n  </div>\n</div>\n```\n\n### ARIA Attributes\n\n```typescript\n<button\n  aria-label=\"Close dialog\"\n  aria-expanded={isOpen}\n  aria-controls=\"dialog-content\"\n  onClick={toggle}\n>\n  <X aria-hidden=\"true\" />\n</button>\n\n<div\n  id=\"dialog-content\"\n  role=\"dialog\"\n  aria-modal=\"true\"\n  aria-labelledby=\"dialog-title\"\n>\n  <h2 id=\"dialog-title\">Dialog Title</h2>\n  {content}\n</div>\n```\n\n### Keyboard Navigation\n\n```typescript\nfunction Dropdown() {\n  const [isOpen, setIsOpen] = useState(false);\n  const [focusedIndex, setFocusedIndex] = useState(0);\n\n  const handleKeyDown = (e: KeyboardEvent) => {\n    switch (e.key) {\n      case 'ArrowDown':\n        e.preventDefault();\n        setFocusedIndex((i) => Math.min(i + 1, items.length - 1));\n        break;\n      case 'ArrowUp':\n        e.preventDefault();\n        setFocusedIndex((i) => Math.max(i - 1, 0));\n        break;\n      case 'Enter':\n        selectItem(items[focusedIndex]);\n        break;\n      case 'Escape':\n        setIsOpen(false);\n        break;\n    }\n  };\n\n  return (\n    <div onKeyDown={handleKeyDown} role=\"combobox\">\n      {/* dropdown content */}\n    </div>\n  );\n}\n```\n\n### Focus Management\n\n```typescript\nimport { useRef, useEffect } from 'react';\n\nfunction Modal({ isOpen, onClose }: ModalProps) {\n  const closeButtonRef = useRef<HTMLButtonElement>(null);\n\n  useEffect(() => {\n    if (isOpen) {\n      // Focus close button when modal opens\n      closeButtonRef.current?.focus();\n\n      // Trap focus within modal\n      const handleTab = (e: KeyboardEvent) => {\n        // Implement focus trap logic\n      };\n\n      document.addEventListener('keydown', handleTab);\n      return () => document.removeEventListener('keydown', handleTab);\n    }\n  }, [isOpen]);\n\n  if (!isOpen) return null;\n\n  return (\n    <div role=\"dialog\" aria-modal=\"true\">\n      <button ref={closeButtonRef} onClick={onClose}>\n        Close\n      </button>\n      {content}\n    </div>\n  );\n}\n```\n\n## Form Patterns\n\n### Controlled Forms with Validation\n\n```typescript\nimport { useForm } from 'react-hook-form';\nimport { zodResolver } from '@hookform/resolvers/zod';\nimport * as z from 'zod';\n\nconst schema = z.object({\n  email: z.string().email('Invalid email address'),\n  password: z.string().min(8, 'Password must be at least 8 characters'),\n  age: z.number().min(18, 'Must be 18 or older'),\n});\n\ntype FormData = z.infer<typeof schema>;\n\nfunction RegistrationForm() {\n  const { register, handleSubmit, formState: { errors, isSubmitting } } = useForm<FormData>({\n    resolver: zodResolver(schema),\n  });\n\n  const onSubmit = async (data: FormData) => {\n    await api.register(data);\n  };\n\n  return (\n    <form onSubmit={handleSubmit(onSubmit)}>\n      <div>\n        <input {...register('email')} type=\"email\" />\n        {errors.email && <span>{errors.email.message}</span>}\n      </div>\n\n      <div>\n        <input {...register('password')} type=\"password\" />\n        {errors.password && <span>{errors.password.message}</span>}\n      </div>\n\n      <button type=\"submit\" disabled={isSubmitting}>\n        {isSubmitting ? 'Submitting...' : 'Submit'}\n      </button>\n    </form>\n  );\n}\n```\n\n### Form State Management\n\n```typescript\n// Optimistic updates\nconst { mutate } = useMutation({\n  mutationFn: updateUser,\n  onMutate: async (newData) => {\n    // Cancel outgoing queries\n    await queryClient.cancelQueries({ queryKey: ['user', userId] });\n\n    // Snapshot previous\n    const previous = queryClient.getQueryData(['user', userId]);\n\n    // Optimistically update UI\n    queryClient.setQueryData(['user', userId], newData);\n\n    return { previous };\n  },\n  onError: (err, newData, context) => {\n    // Rollback on error\n    queryClient.setQueryData(['user', userId], context?.previous);\n    toast.error('Update failed');\n  },\n  onSuccess: () => {\n    toast.success('Updated successfully');\n  },\n});\n```\n\n## Error Handling\n\n### Error Boundaries\n\n```typescript\nimport { Component, ReactNode } from 'react';\n\ninterface Props {\n  children: ReactNode;\n  fallback?: ReactNode;\n}\n\ninterface State {\n  hasError: boolean;\n  error?: Error;\n}\n\nclass ErrorBoundary extends Component<Props, State> {\n  constructor(props: Props) {\n    super(props);\n    this.state = { hasError: false };\n  }\n\n  static getDerivedStateFromError(error: Error): State {\n    return { hasError: true, error };\n  }\n\n  componentDidCatch(error: Error, errorInfo: any) {\n    console.error('Error boundary caught:', error, errorInfo);\n    // Log to error tracking service\n    logErrorToService(error, errorInfo);\n  }\n\n  render() {\n    if (this.state.hasError) {\n      return this.props.fallback || (\n        <div>\n          <h2>Something went wrong</h2>\n          <button onClick={() => this.setState({ hasError: false })}>\n            Try again\n          </button>\n        </div>\n      );\n    }\n\n    return this.props.children;\n  }\n}\n\n// Usage\n<ErrorBoundary fallback={<ErrorFallback />}>\n  <App />\n</ErrorBoundary>\n```\n\n### Async Error Handling\n\n```typescript\nfunction DataComponent() {\n  const { data, error, isError, isLoading } = useQuery({\n    queryKey: ['data'],\n    queryFn: fetchData,\n    retry: 3,\n    retryDelay: (attemptIndex) => Math.min(1000 * 2 ** attemptIndex, 30000),\n  });\n\n  if (isLoading) return <Skeleton />;\n  if (isError) return <ErrorDisplay error={error} />;\n\n  return <DisplayData data={data} />;\n}\n```\n\n## Responsive Design\n\n### Mobile-First Approach\n\n```typescript\n// Tailwind CSS (mobile-first)\n<div className=\"\n  w-full              /* Full width on mobile */\n  md:w-1/2           /* Half width on tablets */\n  lg:w-1/3           /* Third width on desktop */\n  p-4                /* Padding 16px */\n  md:p-6             /* Padding 24px on tablets+ */\n\">\n  Content\n</div>\n```\n\n### Responsive Hooks\n\n```typescript\nimport { useMediaQuery } from '@/hooks/use-media-query';\n\nfunction ResponsiveLayout() {\n  const isMobile = useMediaQuery('(max-width: 768px)');\n  const isTablet = useMediaQuery('(min-width: 769px) and (max-width: 1024px)');\n  const isDesktop = useMediaQuery('(min-width: 1025px)');\n\n  if (isMobile) return <MobileLayout />;\n  if (isTablet) return <TabletLayout />;\n  return <DesktopLayout />;\n}\n```\n\n## Data Fetching Strategies\n\n### Server Components (Next.js 14+)\n\n```typescript\n// app/users/page.tsx - Server Component\nasync function UsersPage() {\n  // Fetched on server\n  const users = await db.user.findMany();\n\n  return <UserList users={users} />;\n}\n```\n\n### Client Components with React Query\n\n```typescript\n'use client';\n\nfunction UserList() {\n  const { data: users, isLoading } = useQuery({\n    queryKey: ['users'],\n    queryFn: fetchUsers,\n  });\n\n  if (isLoading) return <UsersLoading />;\n\n  return <div>{users.map(user => <UserCard key={user.id} {...user} />)}</div>;\n}\n```\n\n### Parallel Data Fetching\n\n```typescript\nfunction Dashboard() {\n  const { data: user } = useQuery({ queryKey: ['user'], queryFn: fetchUser });\n  const { data: stats } = useQuery({ queryKey: ['stats'], queryFn: fetchStats });\n  const { data: posts } = useQuery({ queryKey: ['posts'], queryFn: fetchPosts });\n\n  // All three queries run in parallel\n  return <div>...</div>;\n}\n```\n\n### Dependent Queries\n\n```typescript\nfunction UserPosts({ userId }: { userId: string }) {\n  const { data: user } = useQuery({\n    queryKey: ['user', userId],\n    queryFn: () => fetchUser(userId),\n  });\n\n  const { data: posts } = useQuery({\n    queryKey: ['posts', user?.id],\n    queryFn: () => fetchUserPosts(user!.id),\n    enabled: !!user, // Only fetch after user is loaded\n  });\n\n  return <div>...</div>;\n}\n```\n\n## TypeScript Patterns\n\n### Prop Types\n\n```typescript\n// Basic props\ninterface ButtonProps {\n  children: ReactNode;\n  onClick: () => void;\n  variant?: 'primary' | 'secondary';\n  disabled?: boolean;\n}\n\n// Props with generic\ninterface ListProps<T> {\n  items: T[];\n  renderItem: (item: T) => ReactNode;\n  keyExtractor: (item: T) => string;\n}\n\n// Props extending HTML attributes\ninterface InputProps extends React.InputHTMLAttributes<HTMLInputElement> {\n  label: string;\n  error?: string;\n}\n```\n\n### Type-Safe API Responses\n\n```typescript\n// API response types\ninterface ApiResponse<T> {\n  data: T;\n  error?: never;\n}\n\ninterface ApiError {\n  data?: never;\n  error: {\n    code: string;\n    message: string;\n  };\n}\n\ntype ApiResult<T> = ApiResponse<T> | ApiError;\n\n// Usage\nasync function fetchUser(id: string): Promise<ApiResult<User>> {\n  const response = await fetch(`/api/users/${id}`);\n  return response.json();\n}\n```\n\n## Testing Patterns\n\n### Component Testing\n\n```typescript\nimport { render, screen, fireEvent } from '@testing-library/react';\nimport { LoginForm } from './login-form';\n\ntest('submits form with email and password', async () => {\n  const onSubmit = jest.fn();\n\n  render(<LoginForm onSubmit={onSubmit} />);\n\n  fireEvent.change(screen.getByLabelText('Email'), {\n    target: { value: 'test@example.com' },\n  });\n\n  fireEvent.change(screen.getByLabelText('Password'), {\n    target: { value: 'password123' },\n  });\n\n  fireEvent.click(screen.getByRole('button', { name: 'Login' }));\n\n  await waitFor(() => {\n    expect(onSubmit).toHaveBeenCalledWith({\n      email: 'test@example.com',\n      password: 'password123',\n    });\n  });\n});\n```\n\n### Mock API Calls\n\n```typescript\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { rest } from 'msw';\nimport { setupServer } from 'msw/node';\n\nconst server = setupServer(\n  rest.get('/api/users/:id', (req, res, ctx) => {\n    return res(ctx.json({\n      id: req.params.id,\n      name: 'Test User',\n      email: 'test@example.com',\n    }));\n  })\n);\n\nbeforeAll(() => server.listen());\nafterEach(() => server.resetHandlers());\nafterAll(() => server.close());\n\ntest('displays user data', async () => {\n  const queryClient = new QueryClient();\n\n  render(\n    <QueryClientProvider client={queryClient}>\n      <UserProfile userId=\"123\" />\n    </QueryClientProvider>\n  );\n\n  expect(await screen.findByText('Test User')).toBeInTheDocument();\n});\n```\n\n## Build Optimization\n\n### Bundle Analysis\n\n```bash\n# Next.js bundle analyzer\nnpm install @next/bundle-analyzer\n\n# next.config.js\nconst withBundleAnalyzer = require('@next/bundle-analyzer')({\n  enabled: process.env.ANALYZE === 'true',\n});\n\nmodule.exports = withBundleAnalyzer({\n  // config\n});\n\n# Run analysis\nANALYZE=true npm run build\n```\n\n### Tree Shaking\n\n```typescript\n// ‚úÖ Named imports (tree-shakeable)\nimport { Button } from '@/components/ui/button';\n\n// ‚ùå Namespace import (includes everything)\nimport * as UI from '@/components/ui';\n```\n\n### Dynamic Imports\n\n```typescript\n// Import only when needed\nasync function handleExport() {\n  const { exportToPDF } = await import('@/lib/pdf-export');\n  await exportToPDF(data);\n}\n```\n\n## Common Frontend Mistakes to Avoid\n\n1. **Prop drilling**: Use Context or state management library instead\n2. **Unnecessary re-renders**: Use memo, useMemo, useCallback appropriately\n3. **Missing loading states**: Always show loading indicators\n4. **No error boundaries**: Catch errors before they break the app\n5. **Inline functions in JSX**: Causes re-renders, use useCallback\n6. **Large bundle sizes**: Code split and lazy load\n7. **Missing alt text**: All images need descriptive alt text\n8. **Inaccessible forms**: Use proper labels and ARIA\n9. **Console.log in production**: Remove or use proper logging\n10. **Mixing server and client code**: Know Next.js boundaries\n\n## Performance Metrics (Core Web Vitals)\n\n### LCP (Largest Contentful Paint)\n**Target**: < 2.5 seconds\n\n**Optimize**:\n- Preload critical images\n- Use Next.js Image component\n- Minimize render-blocking resources\n- Use CDN for assets\n\n### FID (First Input Delay)\n**Target**: < 100 milliseconds\n\n**Optimize**:\n- Minimize JavaScript execution\n- Code split large bundles\n- Use web workers for heavy computation\n- Defer non-critical JavaScript\n\n### CLS (Cumulative Layout Shift)\n**Target**: < 0.1\n\n**Optimize**:\n- Set explicit width/height on images\n- Reserve space for ads/embeds\n- Avoid inserting content above existing content\n- Use CSS transforms instead of layout properties\n\n## When to Use This Skill\n\nUse this skill when:\n- Building React or Next.js components\n- Implementing frontend features\n- Optimizing frontend performance\n- Debugging rendering issues\n- Setting up state management\n- Implementing forms\n- Ensuring accessibility\n- Working with responsive design\n- Fetching and caching data\n- Testing frontend code\n\n---\n\n**Remember**: Modern frontend development is about creating fast, accessible, and delightful user experiences. Follow these patterns to build UIs that users love."
              },
              {
                "name": "project-planning",
                "description": "Project planning methodologies including work breakdown structure, task estimation, dependency management, risk assessment, sprint planning, and stakeholder communication. Use when breaking down projects, estimating work, planning sprints, or managing dependencies.",
                "path": "plugins/titanium-toolkit/skills/project-planning/SKILL.md",
                "frontmatter": {
                  "name": "project-planning",
                  "description": "Project planning methodologies including work breakdown structure, task estimation, dependency management, risk assessment, sprint planning, and stakeholder communication. Use when breaking down projects, estimating work, planning sprints, or managing dependencies."
                },
                "content": "# Project Planning\n\nThis skill provides comprehensive guidance for planning and managing software development projects effectively.\n\n## Work Breakdown Structure (WBS)\n\n### Breaking Down Large Projects\n\n```markdown\nProject: E-commerce Platform\n‚îú‚îÄ‚îÄ 1. User Management\n‚îÇ   ‚îú‚îÄ‚îÄ 1.1 Authentication\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1.1.1 Email/Password Login\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1.1.2 Social Login (Google, Facebook)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 1.1.3 Password Reset\n‚îÇ   ‚îú‚îÄ‚îÄ 1.2 User Profiles\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1.2.1 Profile Creation\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1.2.2 Profile Editing\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 1.2.3 Avatar Upload\n‚îÇ   ‚îî‚îÄ‚îÄ 1.3 Role Management\n‚îÇ       ‚îú‚îÄ‚îÄ 1.3.1 Admin Role\n‚îÇ       ‚îú‚îÄ‚îÄ 1.3.2 Customer Role\n‚îÇ       ‚îî‚îÄ‚îÄ 1.3.3 Vendor Role\n‚îú‚îÄ‚îÄ 2. Product Catalog\n‚îÇ   ‚îú‚îÄ‚îÄ 2.1 Product Listings\n‚îÇ   ‚îú‚îÄ‚îÄ 2.2 Product Details\n‚îÇ   ‚îú‚îÄ‚îÄ 2.3 Product Search\n‚îÇ   ‚îî‚îÄ‚îÄ 2.4 Product Categories\n‚îú‚îÄ‚îÄ 3. Shopping Cart\n‚îÇ   ‚îú‚îÄ‚îÄ 3.1 Add to Cart\n‚îÇ   ‚îú‚îÄ‚îÄ 3.2 Update Quantities\n‚îÇ   ‚îú‚îÄ‚îÄ 3.3 Remove Items\n‚îÇ   ‚îî‚îÄ‚îÄ 3.4 Cart Persistence\n‚îú‚îÄ‚îÄ 4. Checkout\n‚îÇ   ‚îú‚îÄ‚îÄ 4.1 Shipping Address\n‚îÇ   ‚îú‚îÄ‚îÄ 4.2 Payment Processing\n‚îÇ   ‚îú‚îÄ‚îÄ 4.3 Order Confirmation\n‚îÇ   ‚îî‚îÄ‚îÄ 4.4 Email Notifications\n‚îî‚îÄ‚îÄ 5. Order Management\n    ‚îú‚îÄ‚îÄ 5.1 Order History\n    ‚îú‚îÄ‚îÄ 5.2 Order Tracking\n    ‚îî‚îÄ‚îÄ 5.3 Order Cancellation\n```\n\n### WBS Best Practices\n\n**1. Start with deliverables, not activities**\n```markdown\n‚ùå Wrong (activities):\n- Write code\n- Test features\n- Deploy\n\n‚úÖ Right (deliverables):\n- User Authentication System\n- Product Search Feature\n- Payment Integration\n```\n\n**2. Use the 8/80 rule**\n- No task should take less than 8 hours (too granular)\n- No task should take more than 80 hours (too large)\n- Sweet spot: 1-5 days per task\n\n**3. Break down until you can estimate**\n```markdown\n‚ùå Too vague:\n- Build API (? days)\n\n‚úÖ Specific:\n- Design API endpoints (1 day)\n- Implement authentication (2 days)\n- Create CRUD operations (3 days)\n- Write API documentation (1 day)\n- Add rate limiting (1 day)\nTotal: 8 days\n```\n\n## Task Estimation\n\n### Story Points\n\n**Fibonacci Scale**: 1, 2, 3, 5, 8, 13, 21\n\n```markdown\n1 point - Trivial\n- Update documentation\n- Fix typo\n- Change button color\n\n2 points - Simple\n- Add validation to form field\n- Create simple API endpoint\n- Write unit tests for existing function\n\n3 points - Moderate\n- Implement login form\n- Add pagination to list\n- Create database migration\n\n5 points - Complex\n- Build user profile page\n- Implement search functionality\n- Add email notifications\n\n8 points - Very Complex\n- Build payment integration\n- Implement complex reporting\n- Create admin dashboard\n\n13 points - Epic\n- Build entire authentication system\n- Create complete checkout flow\n(Should be broken down further)\n```\n\n### T-Shirt Sizing\n\n**Quick estimation for early planning**:\n\n```markdown\nXS (1-2 days)\n- Bug fixes\n- Minor UI updates\n- Documentation updates\n\nS (3-5 days)\n- Small features\n- Simple integrations\n- Basic CRUD operations\n\nM (1-2 weeks)\n- Medium features\n- Standard integrations\n- Multiple related stories\n\nL (2-4 weeks)\n- Large features\n- Complex integrations\n- Multiple epics\n\nXL (1-2 months)\n- Major features\n- System redesigns\n(Should be broken down into smaller pieces)\n```\n\n### Planning Poker\n\n**Collaborative estimation process**:\n\n```markdown\n1. Product Owner presents user story\n2. Team asks clarifying questions\n3. Each member privately selects estimate\n4. All reveal simultaneously\n5. Discuss differences (especially highest/lowest)\n6. Re-estimate if needed\n7. Reach consensus\n\nExample Session:\nStory: \"As a user, I want to reset my password\"\n\nRound 1 Estimates: 2, 3, 3, 8, 3\nDiscussion: Why 8?\n- \"What about email templates?\"\n- \"What if SMTP fails?\"\n- \"Need password strength validation\"\n\nRound 2 Estimates: 5, 5, 5, 5, 5\nConsensus: 5 points\n```\n\n### Estimation Accuracy\n\n**Cone of Uncertainty**:\n```\nProject Start: ¬±100% accuracy\nRequirements: ¬±50% accuracy\nDesign: ¬±25% accuracy\nDevelopment: ¬±10% accuracy\nTesting: ¬±5% accuracy\n```\n\n**Build in buffer**:\n```markdown\nOptimistic: 3 days\nRealistic: 5 days\nPessimistic: 8 days\n\nFormula: (Optimistic + 4√óRealistic + Pessimistic) √∑ 6\nBuffer: (3 + 4√ó5 + 8) √∑ 6 = 5.2 days\n\nUse 6 days for planning\n```\n\n## Dependency Identification\n\n### Types of Dependencies\n\n```markdown\n1. Finish-to-Start (FS) - Most common\n   Task B cannot start until Task A finishes\n   Example: Design ‚Üí Development\n\n2. Start-to-Start (SS)\n   Task B cannot start until Task A starts\n   Example: Development ‚Üí Code Review (parallel)\n\n3. Finish-to-Finish (FF)\n   Task B cannot finish until Task A finishes\n   Example: Development ‚Üí Testing (testing continues)\n\n4. Start-to-Finish (SF) - Rare\n   Task B cannot finish until Task A starts\n   Example: Old system ‚Üí New system (overlap)\n```\n\n### Dependency Mapping\n\n```markdown\nTask Dependencies:\n\n1. Database Schema Design\n   ‚îî‚îÄ‚ñ∫ 2. API Development (FS)\n       ‚îú‚îÄ‚ñ∫ 3. Frontend Development (FS)\n       ‚îî‚îÄ‚ñ∫ 4. Integration Tests (SS)\n           ‚îî‚îÄ‚ñ∫ 5. End-to-End Tests (FS)\n\n2. API Development\n   ‚îî‚îÄ‚ñ∫ 6. API Documentation (SS)\n\n3. Frontend Development\n   ‚îî‚îÄ‚ñ∫ 7. UI/UX Review (FF)\n\nCritical Path: 1 ‚Üí 2 ‚Üí 3 ‚Üí 5\n(Longest path through dependencies)\n```\n\n### Managing Dependencies\n\n```typescript\n// Dependency tracking in code\ninterface Task {\n  id: string;\n  name: string;\n  dependencies: string[]; // IDs of tasks that must complete first\n  status: 'pending' | 'in-progress' | 'completed' | 'blocked';\n}\n\nconst tasks: Task[] = [\n  {\n    id: 'db-schema',\n    name: 'Design database schema',\n    dependencies: [],\n    status: 'completed',\n  },\n  {\n    id: 'api-dev',\n    name: 'Develop API',\n    dependencies: ['db-schema'],\n    status: 'in-progress',\n  },\n  {\n    id: 'frontend-dev',\n    name: 'Develop frontend',\n    dependencies: ['api-dev'],\n    status: 'blocked', // Waiting for API\n  },\n];\n\nfunction canStartTask(taskId: string): boolean {\n  const task = tasks.find(t => t.id === taskId);\n  if (!task) return false;\n\n  // Check if all dependencies are completed\n  return task.dependencies.every(depId => {\n    const dep = tasks.find(t => t.id === depId);\n    return dep?.status === 'completed';\n  });\n}\n```\n\n## Critical Path Analysis\n\n### Finding the Critical Path\n\n```markdown\nProject: Launch Marketing Website\n\nTasks:\nA. Design mockups (3 days)\nB. Develop frontend (5 days) - depends on A\nC. Write content (4 days) - independent\nD. Set up hosting (1 day) - independent\nE. Deploy website (1 day) - depends on B, C, D\nF. Test website (2 days) - depends on E\n\nPath 1: A ‚Üí B ‚Üí E ‚Üí F = 3 + 5 + 1 + 2 = 11 days\nPath 2: C ‚Üí E ‚Üí F = 4 + 1 + 2 = 7 days\nPath 3: D ‚Üí E ‚Üí F = 1 + 1 + 2 = 4 days\n\nCritical Path: A ‚Üí B ‚Üí E ‚Üí F (11 days)\n(Any delay in these tasks delays the entire project)\n```\n\n### Managing Critical Path\n\n```markdown\nStrategies:\n\n1. Fast-track critical tasks\n   - Assign best developers\n   - Remove blockers immediately\n   - Daily status checks\n\n2. Crash critical tasks (add resources)\n   - Pair programming\n   - Additional team members\n   - Overtime (carefully)\n\n3. Parallelize where possible\n   - Content writing during development\n   - Documentation during testing\n\n4. Monitor closely\n   - Daily updates on critical path\n   - Early warning of delays\n   - Quick decision-making\n```\n\n## Risk Assessment and Mitigation\n\n### Risk Matrix\n\n```markdown\nImpact vs Probability:\n\n        Low         Medium        High\nHigh    Monitor     Mitigate      Immediate Action\nMedium  Accept      Monitor       Mitigate\nLow     Accept      Accept        Monitor\n\nExample Risks:\n\n1. API Integration Delays (High Impact, Medium Probability)\n   ‚Üí Mitigate: Start integration early, have backup plan\n\n2. Key Developer Leaves (High Impact, Low Probability)\n   ‚Üí Monitor: Document knowledge, cross-train team\n\n3. Library Deprecated (Medium Impact, Low Probability)\n   ‚Üí Accept: Will address if it happens\n```\n\n### Risk Register\n\n```markdown\n| ID | Risk | Impact | Prob | Status | Mitigation |\n|----|------|--------|------|--------|------------|\n| R1 | Third-party API unreliable | High | Medium | Active | Build fallback, cache responses |\n| R2 | Database performance issues | High | Low | Monitor | Load testing, optimization plan |\n| R3 | Requirements change | Medium | High | Active | Weekly stakeholder sync, flexible architecture |\n| R4 | Security vulnerability | High | Low | Monitor | Security audits, dependency scanning |\n| R5 | Team member unavailable | Medium | Medium | Active | Documentation, knowledge sharing |\n```\n\n### Risk Mitigation Strategies\n\n```markdown\n1. Avoidance - Eliminate risk\n   Risk: Untested technology\n   Action: Use proven technology stack\n\n2. Reduction - Decrease likelihood/impact\n   Risk: Integration failures\n   Action: Early integration testing, CI/CD\n\n3. Transfer - Share risk\n   Risk: Infrastructure failure\n   Action: Use cloud provider with SLA\n\n4. Acceptance - Accept risk\n   Risk: Minor UI inconsistencies\n   Action: Document and fix in future release\n```\n\n## Milestone Planning\n\n### Setting Milestones\n\n```markdown\nProject Timeline: 12 weeks\n\nWeek 2: M1 - Requirements Complete\n- All user stories defined\n- Mockups approved\n- Technical design ready\n‚úì Milestone met when: PRD signed off\n\nWeek 4: M2 - Foundation Complete\n- Database schema implemented\n- Authentication working\n- Basic API endpoints created\n‚úì Milestone met when: Users can log in\n\nWeek 7: M3 - Core Features Complete\n- All CRUD operations working\n- Main user flows implemented\n- Integration tests passing\n‚úì Milestone met when: Alpha testing can begin\n\nWeek 10: M4 - Feature Complete\n- All features implemented\n- Bug fixes complete\n- Documentation written\n‚úì Milestone met when: Beta testing ready\n\nWeek 12: M5 - Launch\n- Production deployment\n- Monitoring in place\n- Support processes ready\n‚úì Milestone met when: Live to users\n```\n\n## Sprint Planning\n\n### Sprint Structure (2-week sprint)\n\n```markdown\nDay 1 - Monday: Sprint Planning\n- Review backlog\n- Estimate stories\n- Commit to sprint goal\n\nDays 2-9: Development\n- Daily standups\n- Development work\n- Code reviews\n- Testing\n\nDay 10 - Friday Week 2: Sprint Review & Retrospective\n- Demo completed work\n- Discuss what went well/poorly\n- Plan improvements\n```\n\n### Sprint Planning Meeting\n\n```markdown\nAgenda (2 hours):\n\nPart 1: Sprint Goal (30 min)\n- Review product roadmap\n- Define sprint goal\n- Identify high-priority items\n\nExample Sprint Goal:\n\"Enable users to browse and search products\"\n\nPart 2: Story Selection (60 min)\n- Review top backlog items\n- Estimate stories\n- Check capacity\n- Commit to stories\n\nTeam Capacity:\n- 5 developers √ó 8 days √ó 6 hours = 240 hours\n- Velocity: 40 story points per sprint\n- Buffer: 20% for bugs/meetings = 32 points\n\nSelected Stories:\n- Product list page (5 pts)\n- Product search (8 pts)\n- Product filters (8 pts)\n- Product pagination (3 pts)\n- Product sort (3 pts)\n- Bug fixes (5 pts)\nTotal: 32 points\n\nPart 3: Task Breakdown (30 min)\n- Break stories into tasks\n- Identify blockers\n- Assign initial tasks\n```\n\n## Capacity Planning\n\n### Calculating Team Capacity\n\n```markdown\nTeam: 5 Developers\nSprint: 2 weeks (10 working days)\n\nAvailable Hours:\n5 developers √ó 10 days √ó 8 hours = 400 hours\n\nSubtract Non-Dev Time:\n- Meetings: 2 hours/day √ó 10 days √ó 5 people = 100 hours\n- Code reviews: 1 hour/day √ó 10 days √ó 5 people = 50 hours\n- Planning/retro: 4 hours √ó 5 people = 20 hours\n\nActual Development Time:\n400 - 100 - 50 - 20 = 230 hours\n\nStory Points:\nIf 1 point ‚âà 6 hours\nCapacity: 230 √∑ 6 ‚âà 38 points\n\nAdd 20% buffer: 30 points safe commitment\n```\n\n### Handling Vacation and Absences\n\n```markdown\nTeam Capacity with Absences:\n\nRegular Capacity: 40 points\n\nDeveloper A: Out entire sprint (-8 points)\nDeveloper B: Out 3 days (-5 points)\nHoliday: 1 day for everyone (-8 points)\n\nAdjusted Capacity:\n40 - 8 - 5 - 8 = 19 points\n\nPlan accordingly:\n- Smaller sprint goal\n- Fewer stories\n- Focus on high priority\n- Avoid risky work\n```\n\n## Burndown Charts\n\n### Creating Burndown Charts\n\n```markdown\nSprint Burndown:\n\nDay | Remaining Points | Ideal Burn\n----|------------------|------------\n0   | 40              | 40\n1   | 38              | 36\n2   | 35              | 32\n3   | 32              | 28\n4   | 28              | 24\n5   | 28              | 20  ‚Üê Weekend\n6   | 28              | 16  ‚Üê Weekend\n7   | 25              | 12\n8   | 20              | 8\n9   | 12              | 4\n10  | 0               | 0\n\nIdeal line: Straight from start to finish\nActual line: Based on completed work\n\nAnalysis:\n- Days 3-6: Slow progress (blocker?)\n- Day 7: Back on track\n- Day 9: Ahead of schedule\n```\n\n### Interpreting Burndown Trends\n\n```markdown\nScenarios:\n\n1. Line below ideal\n   ‚Üí Ahead of schedule\n   ‚Üí May have underestimated\n   ‚Üí Consider pulling in more work\n\n2. Line above ideal\n   ‚Üí Behind schedule\n   ‚Üí May have overcommitted\n   ‚Üí Identify blockers\n   ‚Üí Consider removing stories\n\n3. Flat line\n   ‚Üí No progress\n   ‚Üí Blocker or team unavailable\n   ‚Üí Immediate intervention needed\n\n4. Increasing line\n   ‚Üí Scope creep\n   ‚Üí Stories added mid-sprint\n   ‚Üí Review sprint boundaries\n```\n\n## Velocity Tracking\n\n### Measuring Velocity\n\n```markdown\nHistorical Velocity:\n\nSprint 1: 28 points completed\nSprint 2: 32 points completed\nSprint 3: 30 points completed\nSprint 4: 35 points completed\nSprint 5: 33 points completed\n\nAverage Velocity: (28+32+30+35+33) √∑ 5 = 31.6 points\n\nUse for Planning:\n- Conservative: 28 points (lowest recent)\n- Realistic: 32 points (average)\n- Optimistic: 35 points (highest recent)\n\nRecommend: Use 32 points for next sprint\n```\n\n### Velocity Trends\n\n```markdown\nImproving Velocity:\nSprint 1: 20 ‚Üí Sprint 2: 25 ‚Üí Sprint 3: 30\n- Team learning\n- Process improvements\n- Good trend\n\nDeclining Velocity:\nSprint 1: 35 ‚Üí Sprint 2: 30 ‚Üí Sprint 3: 25\n- Technical debt accumulating\n- Team burnout\n- Need intervention\n\nStable Velocity:\nSprint 1: 30 ‚Üí Sprint 2: 31 ‚Üí Sprint 3: 29\n- Sustainable pace\n- Predictable\n- Ideal state\n```\n\n## Agile Ceremonies\n\n### Daily Standup (15 minutes)\n\n```markdown\nFormat: Each person answers:\n1. What did I complete yesterday?\n2. What will I work on today?\n3. What blockers do I have?\n\nExample:\n\"Yesterday I completed the login form.\nToday I'll start on the password reset flow.\nI'm blocked on the email template approval.\"\n\nAnti-patterns:\n‚ùå Status reports to manager\n‚ùå Problem-solving discussions\n‚ùå More than 15 minutes\n\nBest practices:\n‚úì Same time, same place\n‚úì Everyone participates\n‚úì Park detailed discussions\n‚úì Update task board\n```\n\n### Sprint Review (1 hour)\n\n```markdown\nAgenda:\n1. Demo completed work (40 min)\n   - Show working software\n   - Get stakeholder feedback\n   - Note requested changes\n\n2. Review sprint metrics (10 min)\n   - Velocity\n   - Completed vs planned\n   - Quality metrics\n\n3. Update product backlog (10 min)\n   - Adjust priorities\n   - Add new items\n   - Remove obsolete items\n\nTips:\n- Focus on working software\n- No PowerPoint presentations\n- Encourage feedback\n- Keep it informal\n```\n\n### Sprint Retrospective (1 hour)\n\n```markdown\nFormat: What went well / What to improve / Action items\n\nExample:\n\nWhat Went Well:\n‚úì Completed all planned stories\n‚úì Good collaboration on complex feature\n‚úì Improved code review process\n\nWhat to Improve:\n‚ö† Too many meetings interrupted flow\n‚ö† Test environment was unstable\n‚ö† Requirements unclear on story X\n\nAction Items:\n1. Block \"focus time\" 2-4pm daily (Owner: Scrum Master)\n2. Fix test environment stability (Owner: DevOps)\n3. Refine stories with PO before sprint (Owner: Team Lead)\n\nFollow-up:\n- Review action items at next retro\n- Track completion\n- Celebrate improvements\n```\n\n## Stakeholder Communication\n\n### Status Reports\n\n```markdown\nWeekly Status Report - Week of Oct 16, 2025\n\nSprint Progress:\n- Completed: 18/32 points (56%)\n- On Track: Yes\n- Sprint Goal: Enable product browsing\n\nCompleted This Week:\n‚úì Product list page with pagination\n‚úì Basic search functionality\n‚úì Product filters (category, price)\n\nIn Progress:\n‚Ä¢ Advanced search with autocomplete (90% done)\n‚Ä¢ Product sort options (started today)\n\nUpcoming Next Week:\n‚óã Complete remaining search features\n‚óã Begin product detail page\n‚óã Integration testing\n\nBlockers/Risks:\n‚ö† Designer out sick - UI reviews delayed 1 day\n‚ö† Third-party API slow - investigating alternatives\n\nMetrics:\n- Velocity: 32 points/sprint (stable)\n- Bug count: 3 (all low priority)\n- Test coverage: 85%\n\nNext Milestone:\nM3 - Core Features (Week 7) - On track\n```\n\n### Stakeholder Matrix\n\n```markdown\n| Stakeholder | Role | Interest | Influence | Communication |\n|-------------|------|----------|-----------|---------------|\n| CEO | Sponsor | High | High | Monthly exec summary |\n| Product Manager | Owner | High | High | Daily collaboration |\n| Engineering Manager | Lead | High | High | Daily standup |\n| Marketing Director | User | Medium | Medium | Weekly demo |\n| Customer Support | User | Medium | Low | Sprint review |\n| End Users | Consumer | High | Low | Beta feedback |\n```\n\n## Project Tracking Tools\n\n### Issue/Task Management\n\n```markdown\nGitHub Issues / Jira / Linear:\n\nEpic: User Authentication\n‚îú‚îÄ‚îÄ Story: Email/Password Login (8 pts)\n‚îÇ   ‚îú‚îÄ‚îÄ Task: Design login form\n‚îÇ   ‚îú‚îÄ‚îÄ Task: Implement API endpoint\n‚îÇ   ‚îú‚îÄ‚îÄ Task: Add validation\n‚îÇ   ‚îî‚îÄ‚îÄ Task: Write tests\n‚îú‚îÄ‚îÄ Story: Social Login (5 pts)\n‚îî‚îÄ‚îÄ Story: Password Reset (5 pts)\n\nLabels:\n- Priority: P0 (Critical), P1 (High), P2 (Normal), P3 (Low)\n- Type: Feature, Bug, Tech Debt, Documentation\n- Status: Todo, In Progress, In Review, Done\n- Component: Frontend, Backend, Database, DevOps\n```\n\n### Documentation\n\n```markdown\nEssential Project Documents:\n\n1. Product Requirements Document (PRD)\n   - Features and requirements\n   - User stories\n   - Acceptance criteria\n\n2. Technical Design Document\n   - Architecture\n   - Technology choices\n   - API design\n\n3. Project Charter\n   - Goals and objectives\n   - Scope\n   - Timeline\n   - Resources\n\n4. Risk Register\n   - Identified risks\n   - Mitigation plans\n   - Status\n\n5. Sprint Plans\n   - Sprint goals\n   - Committed stories\n   - Capacity\n```\n\n## Planning Checklist\n\n**Project Initiation**:\n- [ ] Define project goals and objectives\n- [ ] Identify stakeholders\n- [ ] Create project charter\n- [ ] Define scope and requirements\n- [ ] Estimate timeline and budget\n\n**Planning Phase**:\n- [ ] Create work breakdown structure\n- [ ] Estimate tasks\n- [ ] Identify dependencies\n- [ ] Assess risks\n- [ ] Define milestones\n- [ ] Allocate resources\n\n**Sprint Planning**:\n- [ ] Review and refine backlog\n- [ ] Define sprint goal\n- [ ] Estimate stories\n- [ ] Check team capacity\n- [ ] Commit to sprint backlog\n- [ ] Break down into tasks\n\n**During Execution**:\n- [ ] Track progress daily\n- [ ] Update burndown chart\n- [ ] Address blockers immediately\n- [ ] Communicate with stakeholders\n- [ ] Adjust plan as needed\n\n**Sprint Close**:\n- [ ] Demo completed work\n- [ ] Conduct retrospective\n- [ ] Update velocity metrics\n- [ ] Plan next sprint\n\n## When to Use This Skill\n\nUse this skill when:\n- Starting new projects\n- Breaking down large initiatives\n- Estimating work effort\n- Planning sprints\n- Managing dependencies\n- Assessing risks\n- Tracking progress\n- Communicating with stakeholders\n- Running agile ceremonies\n- Improving team processes\n\n---\n\n**Remember**: Plans are useless, but planning is essential. Stay flexible, communicate often, and adjust course based on reality. The goal is not perfect adherence to the plan, but successfully delivering value to users."
              },
              {
                "name": "security-checklist",
                "description": "Comprehensive security checklist covering OWASP Top 10, SQL injection, XSS, CSRF, authentication, authorization, secrets management, input validation, and security headers. Use when scanning for vulnerabilities, reviewing security, implementing authentication/authorization, or handling sensitive data.",
                "path": "plugins/titanium-toolkit/skills/security-checklist/SKILL.md",
                "frontmatter": {
                  "name": "security-checklist",
                  "description": "Comprehensive security checklist covering OWASP Top 10, SQL injection, XSS, CSRF, authentication, authorization, secrets management, input validation, and security headers. Use when scanning for vulnerabilities, reviewing security, implementing authentication/authorization, or handling sensitive data."
                },
                "content": "# Security Checklist\n\nThis skill provides comprehensive security guidance to protect your applications from common vulnerabilities and attacks.\n\n## OWASP Top 10 Vulnerabilities\n\n### 1. Broken Access Control\n\n**What it is**: Users can access resources or perform actions they shouldn't be authorized for.\n\n**Examples**:\n- Accessing another user's data by changing URL parameter\n- Elevating privileges (user ‚Üí admin)\n- Bypassing authentication checks\n\n**Prevention**:\n```typescript\n// ‚ùå BAD - No authorization check\napp.get('/api/users/:id', async (req, res) => {\n  const user = await db.user.findUnique({ where: { id: req.params.id } });\n  res.json(user);\n});\n\n// ‚úÖ GOOD - Verify ownership or admin\napp.get('/api/users/:id', authenticate, async (req, res) => {\n  const requestedId = req.params.id;\n  const currentUserId = req.user.id;\n  const isAdmin = req.user.role === 'admin';\n\n  if (requestedId !== currentUserId && !isAdmin) {\n    return res.status(403).json({ error: 'Forbidden' });\n  }\n\n  const user = await db.user.findUnique({ where: { id: requestedId } });\n  res.json(user);\n});\n```\n\n**Checklist**:\n- [ ] Enforce least privilege (deny by default)\n- [ ] Verify user permissions on every request\n- [ ] Never trust user IDs from client\n- [ ] Log access control failures\n- [ ] Use centralized access control logic\n\n### 2. Cryptographic Failures\n\n**What it is**: Exposing sensitive data due to weak or missing encryption.\n\n**Examples**:\n- Storing passwords in plain text\n- Using weak hashing algorithms (MD5, SHA1)\n- Transmitting sensitive data over HTTP\n\n**Prevention**:\n```typescript\nimport bcrypt from 'bcrypt';\nimport crypto from 'crypto';\n\n// ‚úÖ Password hashing\nasync function hashPassword(password: string): Promise<string> {\n  const saltRounds = 12; // Increase for more security\n  return await bcrypt.hash(password, saltRounds);\n}\n\nasync function verifyPassword(password: string, hash: string): Promise<boolean> {\n  return await bcrypt.compare(password, hash);\n}\n\n// ‚úÖ Encrypt sensitive data at rest\nfunction encrypt(text: string, key: string): string {\n  const iv = crypto.randomBytes(16);\n  const cipher = crypto.createCipheriv('aes-256-gcm', Buffer.from(key), iv);\n\n  let encrypted = cipher.update(text, 'utf8', 'hex');\n  encrypted += cipher.final('hex');\n\n  const authTag = cipher.getAuthTag().toString('hex');\n  return `${iv.toString('hex')}:${authTag}:${encrypted}`;\n}\n```\n\n**Checklist**:\n- [ ] Use HTTPS everywhere\n- [ ] Hash passwords with bcrypt (12+ rounds)\n- [ ] Encrypt sensitive data at rest\n- [ ] Use strong encryption algorithms (AES-256)\n- [ ] Properly manage encryption keys\n- [ ] Never commit secrets to version control\n\n### 3. Injection Attacks\n\n**See SQL Injection Prevention section below**\n\n### 4. Insecure Design\n\n**What it is**: Security flaws in the application architecture.\n\n**Examples**:\n- Missing rate limiting\n- Unrestricted file uploads\n- Insecure password reset flows\n\n**Prevention**:\n```typescript\n// ‚úÖ Rate limiting\nimport rateLimit from 'express-rate-limit';\n\nconst loginLimiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 5, // 5 attempts\n  message: 'Too many login attempts, please try again later',\n});\n\napp.post('/api/auth/login', loginLimiter, async (req, res) => {\n  // Login logic\n});\n\n// ‚úÖ Secure file upload\nimport multer from 'multer';\n\nconst upload = multer({\n  limits: {\n    fileSize: 5 * 1024 * 1024, // 5MB max\n  },\n  fileFilter: (req, file, cb) => {\n    const allowedTypes = ['image/jpeg', 'image/png', 'image/gif'];\n    if (!allowedTypes.includes(file.mimetype)) {\n      return cb(new Error('Invalid file type'));\n    }\n    cb(null, true);\n  },\n});\n```\n\n**Checklist**:\n- [ ] Implement rate limiting on all endpoints\n- [ ] Validate file uploads (type, size, content)\n- [ ] Use secure password reset flows (token-based)\n- [ ] Implement account lockout after failed attempts\n- [ ] Log and monitor security events\n\n### 5. Security Misconfiguration\n\n**What it is**: Insecure default configurations, unnecessary features enabled.\n\n**Prevention**:\n```typescript\n// ‚úÖ Secure Express configuration\nimport express from 'express';\nimport helmet from 'helmet';\n\nconst app = express();\n\n// Security headers\napp.use(helmet());\n\n// Disable X-Powered-By\napp.disable('x-powered-by');\n\n// Environment-specific settings\nif (process.env.NODE_ENV === 'production') {\n  app.set('trust proxy', 1); // Trust first proxy\n}\n\n// CORS configuration\nimport cors from 'cors';\n\nconst corsOptions = {\n  origin: process.env.ALLOWED_ORIGINS?.split(',') || [],\n  credentials: true,\n  optionsSuccessStatus: 200,\n};\n\napp.use(cors(corsOptions));\n```\n\n**Checklist**:\n- [ ] Remove default accounts and passwords\n- [ ] Disable directory listing\n- [ ] Remove unnecessary features/endpoints\n- [ ] Keep all software updated\n- [ ] Use security headers (see section below)\n\n### 6. Vulnerable and Outdated Components\n\n**Prevention**:\n```bash\n# Check for vulnerabilities\nnpm audit\n\n# Fix vulnerabilities\nnpm audit fix\n\n# Update dependencies\nnpm update\n\n# Use automated tools\nnpm install -g snyk\nsnyk test\nsnyk monitor\n```\n\n**Checklist**:\n- [ ] Regularly update dependencies\n- [ ] Monitor security advisories\n- [ ] Remove unused dependencies\n- [ ] Use dependabot or renovate\n- [ ] Pin dependency versions in production\n\n### 7. Identification and Authentication Failures\n\n**See Authentication Best Practices section below**\n\n### 8. Software and Data Integrity Failures\n\n**Prevention**:\n```typescript\n// ‚úÖ Verify package integrity\n// package-lock.json ensures same versions\n\n// ‚úÖ Use Subresource Integrity (SRI) for CDN\n<script\n  src=\"https://cdn.example.com/library.js\"\n  integrity=\"sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC\"\n  crossorigin=\"anonymous\"\n></script>\n\n// ‚úÖ Validate data from external sources\nimport { z } from 'zod';\n\nconst ExternalDataSchema = z.object({\n  id: z.string().uuid(),\n  amount: z.number().positive(),\n  status: z.enum(['pending', 'completed', 'failed']),\n});\n\nfunction processExternalData(data: unknown) {\n  const validated = ExternalDataSchema.parse(data);\n  // Now safe to use\n}\n```\n\n### 9. Security Logging and Monitoring Failures\n\n**Prevention**:\n```typescript\nimport winston from 'winston';\n\nconst logger = winston.createLogger({\n  level: 'info',\n  format: winston.format.json(),\n  transports: [\n    new winston.transports.File({ filename: 'error.log', level: 'error' }),\n    new winston.transports.File({ filename: 'combined.log' }),\n  ],\n});\n\n// ‚úÖ Log security events\nlogger.warn('Failed login attempt', {\n  email: req.body.email,\n  ip: req.ip,\n  userAgent: req.get('user-agent'),\n  timestamp: new Date().toISOString(),\n});\n\nlogger.error('SQL injection attempt detected', {\n  query: sanitizedQuery,\n  ip: req.ip,\n  endpoint: req.path,\n});\n```\n\n**Checklist**:\n- [ ] Log authentication events (login, logout, failures)\n- [ ] Log authorization failures\n- [ ] Log input validation failures\n- [ ] Monitor for suspicious patterns\n- [ ] Set up alerts for security events\n\n### 10. Server-Side Request Forgery (SSRF)\n\n**Prevention**:\n```typescript\nimport validator from 'validator';\n\n// ‚ùå BAD - Allows SSRF\napp.post('/api/fetch-url', async (req, res) => {\n  const url = req.body.url;\n  const response = await fetch(url);\n  res.json(await response.json());\n});\n\n// ‚úÖ GOOD - Validate and whitelist\napp.post('/api/fetch-url', async (req, res) => {\n  const url = req.body.url;\n\n  // Validate URL format\n  if (!validator.isURL(url, { protocols: ['https'] })) {\n    return res.status(400).json({ error: 'Invalid URL' });\n  }\n\n  // Whitelist allowed domains\n  const allowedDomains = ['api.trusted-service.com'];\n  const urlObj = new URL(url);\n\n  if (!allowedDomains.includes(urlObj.hostname)) {\n    return res.status(403).json({ error: 'Domain not allowed' });\n  }\n\n  // Block internal IPs\n  const hostname = urlObj.hostname;\n  if (\n    hostname === 'localhost' ||\n    hostname.startsWith('192.168.') ||\n    hostname.startsWith('10.') ||\n    hostname.startsWith('172.')\n  ) {\n    return res.status(403).json({ error: 'Internal IPs not allowed' });\n  }\n\n  const response = await fetch(url);\n  res.json(await response.json());\n});\n```\n\n## SQL Injection Prevention\n\n### Parameterized Queries\n\n```typescript\n// ‚ùå VULNERABLE - String concatenation\nconst email = req.body.email;\nconst query = `SELECT * FROM users WHERE email = '${email}'`;\n// Attacker can input: ' OR '1'='1\n// Resulting query: SELECT * FROM users WHERE email = '' OR '1'='1'\n\n// ‚úÖ SAFE - Parameterized query\nconst email = req.body.email;\nconst query = 'SELECT * FROM users WHERE email = ?';\nconst user = await db.execute(query, [email]);\n\n// ‚úÖ SAFE - ORM (Prisma)\nconst user = await prisma.user.findUnique({\n  where: { email: req.body.email },\n});\n```\n\n### Input Validation\n\n```typescript\nimport { z } from 'zod';\n\nconst UserQuerySchema = z.object({\n  email: z.string().email(),\n  id: z.string().uuid().optional(),\n  name: z.string().max(100).optional(),\n});\n\napp.get('/api/users', async (req, res) => {\n  try {\n    const params = UserQuerySchema.parse(req.query);\n    const users = await db.user.findMany({ where: params });\n    res.json(users);\n  } catch (error) {\n    res.status(400).json({ error: 'Invalid query parameters' });\n  }\n});\n```\n\n## XSS (Cross-Site Scripting) Prevention\n\n### Types of XSS\n\n**1. Stored XSS**: Malicious script stored in database\n**2. Reflected XSS**: Malicious script in URL/input reflected back\n**3. DOM-based XSS**: Script manipulates DOM directly\n\n### Prevention\n\n```typescript\n// ‚úÖ React automatically escapes by default\nfunction Comment({ text }: { text: string }) {\n  return <p>{text}</p>; // Safe - React escapes HTML\n}\n\n// ‚ùå DANGEROUS - dangerouslySetInnerHTML\nfunction Comment({ html }: { html: string }) {\n  return <p dangerouslySetInnerHTML={{ __html: html }} />; // UNSAFE\n}\n\n// ‚úÖ Sanitize HTML before rendering\nimport DOMPurify from 'dompurify';\n\nfunction Comment({ html }: { html: string }) {\n  const clean = DOMPurify.sanitize(html, {\n    ALLOWED_TAGS: ['b', 'i', 'em', 'strong', 'a'],\n    ALLOWED_ATTR: ['href'],\n  });\n  return <p dangerouslySetInnerHTML={{ __html: clean }} />;\n}\n\n// ‚úÖ Server-side sanitization\nimport sanitizeHtml from 'sanitize-html';\n\napp.post('/api/comments', async (req, res) => {\n  const clean = sanitizeHtml(req.body.content, {\n    allowedTags: ['b', 'i', 'em', 'strong', 'a'],\n    allowedAttributes: {\n      'a': ['href'],\n    },\n  });\n\n  const comment = await db.comment.create({\n    data: { content: clean },\n  });\n\n  res.json(comment);\n});\n```\n\n### Content Security Policy (CSP)\n\n```typescript\napp.use(\n  helmet.contentSecurityPolicy({\n    directives: {\n      defaultSrc: [\"'self'\"],\n      scriptSrc: [\"'self'\", 'https://trusted-cdn.com'],\n      styleSrc: [\"'self'\", \"'unsafe-inline'\"],\n      imgSrc: [\"'self'\", 'data:', 'https:'],\n      connectSrc: [\"'self'\", 'https://api.example.com'],\n      fontSrc: [\"'self'\", 'https://fonts.gstatic.com'],\n      objectSrc: [\"'none'\"],\n      upgradeInsecureRequests: [],\n    },\n  })\n);\n```\n\n## CSRF (Cross-Site Request Forgery) Protection\n\n### CSRF Token Pattern\n\n```typescript\nimport csrf from 'csurf';\nimport cookieParser from 'cookie-parser';\n\nconst csrfProtection = csrf({ cookie: true });\n\napp.use(cookieParser());\n\n// Get CSRF token\napp.get('/api/csrf-token', csrfProtection, (req, res) => {\n  res.json({ csrfToken: req.csrfToken() });\n});\n\n// Protect state-changing endpoints\napp.post('/api/users', csrfProtection, async (req, res) => {\n  // Token automatically verified by middleware\n  const user = await createUser(req.body);\n  res.json(user);\n});\n```\n\n### SameSite Cookies\n\n```typescript\n// ‚úÖ Set SameSite attribute\nres.cookie('sessionId', token, {\n  httpOnly: true,\n  secure: true, // HTTPS only\n  sameSite: 'strict', // or 'lax'\n  maxAge: 24 * 60 * 60 * 1000, // 24 hours\n});\n```\n\n## Authentication Best Practices\n\n### Password Requirements\n\n```typescript\nimport { z } from 'zod';\n\nconst PasswordSchema = z\n  .string()\n  .min(12, 'Password must be at least 12 characters')\n  .regex(/[A-Z]/, 'Password must contain uppercase letter')\n  .regex(/[a-z]/, 'Password must contain lowercase letter')\n  .regex(/[0-9]/, 'Password must contain number')\n  .regex(/[^A-Za-z0-9]/, 'Password must contain special character');\n\n// Check against common passwords\nimport { isCommonPassword } from 'common-passwords';\n\nfunction validatePassword(password: string): boolean {\n  if (isCommonPassword(password)) {\n    throw new Error('Password is too common');\n  }\n  return true;\n}\n```\n\n### JWT Best Practices\n\n```typescript\nimport jwt from 'jsonwebtoken';\n\n// ‚úÖ Short-lived access tokens\nfunction generateAccessToken(userId: string): string {\n  return jwt.sign(\n    { userId, type: 'access' },\n    process.env.JWT_SECRET!,\n    { expiresIn: '15m' } // Short expiry\n  );\n}\n\n// ‚úÖ Long-lived refresh tokens\nfunction generateRefreshToken(userId: string): string {\n  return jwt.sign(\n    { userId, type: 'refresh' },\n    process.env.JWT_REFRESH_SECRET!,\n    { expiresIn: '7d' }\n  );\n}\n\n// ‚úÖ Verify token\nfunction verifyAccessToken(token: string) {\n  try {\n    const payload = jwt.verify(token, process.env.JWT_SECRET!);\n    if (payload.type !== 'access') {\n      throw new Error('Invalid token type');\n    }\n    return payload;\n  } catch (error) {\n    throw new Error('Invalid token');\n  }\n}\n\n// ‚úÖ Blacklist tokens on logout\nconst tokenBlacklist = new Set<string>();\n\napp.post('/api/auth/logout', authenticate, (req, res) => {\n  const token = req.headers.authorization?.split(' ')[1];\n  if (token) {\n    tokenBlacklist.add(token);\n  }\n  res.json({ message: 'Logged out' });\n});\n```\n\n### Multi-Factor Authentication (MFA)\n\n```typescript\nimport speakeasy from 'speakeasy';\nimport QRCode from 'qrcode';\n\n// Generate MFA secret\nasync function enableMFA(userId: string) {\n  const secret = speakeasy.generateSecret({\n    name: `MyApp (${user.email})`,\n  });\n\n  // Generate QR code\n  const qrCode = await QRCode.toDataURL(secret.otpauth_url!);\n\n  // Save secret to database (encrypted)\n  await db.user.update({\n    where: { id: userId },\n    data: { mfaSecret: encrypt(secret.base32) },\n  });\n\n  return { secret: secret.base32, qrCode };\n}\n\n// Verify MFA token\nfunction verifyMFAToken(secret: string, token: string): boolean {\n  return speakeasy.totp.verify({\n    secret,\n    encoding: 'base32',\n    token,\n    window: 2, // Allow 2 time steps before/after\n  });\n}\n```\n\n## Authorization Patterns\n\n### Role-Based Access Control (RBAC)\n\n```typescript\nenum Role {\n  USER = 'user',\n  MODERATOR = 'moderator',\n  ADMIN = 'admin',\n}\n\nconst permissions = {\n  [Role.USER]: ['read:own', 'write:own'],\n  [Role.MODERATOR]: ['read:own', 'write:own', 'read:all', 'delete:others'],\n  [Role.ADMIN]: ['*'], // All permissions\n};\n\nfunction authorize(requiredPermission: string) {\n  return (req: Request, res: Response, next: NextFunction) => {\n    const userRole = req.user.role;\n    const userPermissions = permissions[userRole];\n\n    if (!userPermissions.includes('*') && !userPermissions.includes(requiredPermission)) {\n      return res.status(403).json({ error: 'Forbidden' });\n    }\n\n    next();\n  };\n}\n\n// Usage\napp.delete('/api/posts/:id', authenticate, authorize('delete:others'), async (req, res) => {\n  await deletePost(req.params.id);\n  res.json({ success: true });\n});\n```\n\n### Attribute-Based Access Control (ABAC)\n\n```typescript\ninterface AccessPolicy {\n  subject: { role: string; department?: string };\n  resource: { type: string; owner?: string };\n  action: string;\n  conditions?: Record<string, any>;\n}\n\nfunction checkAccess(\n  user: User,\n  resource: Resource,\n  action: string\n): boolean {\n  // User can access own resources\n  if (resource.ownerId === user.id) {\n    return true;\n  }\n\n  // Admins can access everything\n  if (user.role === 'admin') {\n    return true;\n  }\n\n  // Department managers can access department resources\n  if (\n    user.role === 'manager' &&\n    user.department === resource.department\n  ) {\n    return true;\n  }\n\n  return false;\n}\n```\n\n## Secrets Management\n\n### Environment Variables\n\n```typescript\n// ‚úÖ .env file (NOT committed to git)\nDATABASE_URL=postgresql://user:password@localhost:5432/db\nJWT_SECRET=super-secret-key-change-in-production\nAPI_KEY=sk_live_abc123xyz\n\n// ‚úÖ .env.example (committed to git)\nDATABASE_URL=\nJWT_SECRET=\nAPI_KEY=\n\n// ‚úÖ Load environment variables\nimport dotenv from 'dotenv';\ndotenv.config();\n\n// ‚úÖ Validate required env vars\nconst requiredEnvVars = ['DATABASE_URL', 'JWT_SECRET', 'API_KEY'];\n\nfor (const envVar of requiredEnvVars) {\n  if (!process.env[envVar]) {\n    throw new Error(`Missing required environment variable: ${envVar}`);\n  }\n}\n```\n\n### Key Vault Integration\n\n```typescript\n// ‚úÖ AWS Secrets Manager\nimport { SecretsManager } from '@aws-sdk/client-secrets-manager';\n\nasync function getSecret(secretName: string): Promise<string> {\n  const client = new SecretsManager({ region: 'us-east-1' });\n  const response = await client.getSecretValue({ SecretId: secretName });\n  return response.SecretString!;\n}\n\n// ‚úÖ Azure Key Vault\nimport { SecretClient } from '@azure/keyvault-secrets';\n\nasync function getAzureSecret(secretName: string): Promise<string> {\n  const client = new SecretClient(vaultUrl, credential);\n  const secret = await client.getSecret(secretName);\n  return secret.value!;\n}\n```\n\n## Input Validation\n\n### Validation Schema\n\n```typescript\nimport { z } from 'zod';\n\nconst CreateUserSchema = z.object({\n  email: z.string().email().max(255),\n  password: z.string().min(12).max(100),\n  name: z.string().min(1).max(100),\n  age: z.number().int().min(18).max(120),\n  phone: z.string().regex(/^\\+?[1-9]\\d{1,14}$/).optional(),\n  website: z.string().url().optional(),\n});\n\napp.post('/api/users', async (req, res) => {\n  try {\n    const data = CreateUserSchema.parse(req.body);\n    const user = await createUser(data);\n    res.json(user);\n  } catch (error) {\n    if (error instanceof z.ZodError) {\n      return res.status(400).json({\n        error: 'Validation failed',\n        details: error.errors,\n      });\n    }\n    throw error;\n  }\n});\n```\n\n### Sanitization\n\n```typescript\nimport validator from 'validator';\n\nfunction sanitizeInput(input: string): string {\n  // Trim whitespace\n  let clean = input.trim();\n\n  // Escape HTML entities\n  clean = validator.escape(clean);\n\n  // Remove null bytes\n  clean = clean.replace(/\\0/g, '');\n\n  return clean;\n}\n```\n\n## Security Headers\n\n### Comprehensive Header Configuration\n\n```typescript\nimport helmet from 'helmet';\n\napp.use(\n  helmet({\n    // Content Security Policy\n    contentSecurityPolicy: {\n      directives: {\n        defaultSrc: [\"'self'\"],\n        scriptSrc: [\"'self'\", \"'unsafe-inline'\"],\n        styleSrc: [\"'self'\", \"'unsafe-inline'\"],\n        imgSrc: [\"'self'\", 'data:', 'https:'],\n      },\n    },\n\n    // HTTP Strict Transport Security\n    hsts: {\n      maxAge: 31536000, // 1 year\n      includeSubDomains: true,\n      preload: true,\n    },\n\n    // X-Frame-Options\n    frameguard: {\n      action: 'deny', // or 'sameorigin'\n    },\n\n    // X-Content-Type-Options\n    noSniff: true,\n\n    // X-XSS-Protection\n    xssFilter: true,\n\n    // Referrer-Policy\n    referrerPolicy: {\n      policy: 'strict-origin-when-cross-origin',\n    },\n  })\n);\n\n// Additional custom headers\napp.use((req, res, next) => {\n  res.setHeader('X-Content-Type-Options', 'nosniff');\n  res.setHeader('X-Frame-Options', 'DENY');\n  res.setHeader('X-XSS-Protection', '1; mode=block');\n  res.setHeader('Strict-Transport-Security', 'max-age=31536000; includeSubDomains; preload');\n  next();\n});\n```\n\n## Rate Limiting\n\n### Endpoint-Specific Rate Limits\n\n```typescript\nimport rateLimit from 'express-rate-limit';\n\n// Strict limit for authentication\nconst authLimiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 5,\n  message: 'Too many authentication attempts',\n  standardHeaders: true,\n  legacyHeaders: false,\n});\n\n// Moderate limit for API endpoints\nconst apiLimiter = rateLimit({\n  windowMs: 1 * 60 * 1000, // 1 minute\n  max: 60,\n  message: 'Too many requests',\n});\n\n// Apply rate limiters\napp.post('/api/auth/login', authLimiter, loginHandler);\napp.post('/api/auth/register', authLimiter, registerHandler);\napp.use('/api', apiLimiter);\n```\n\n## Logging Security Events\n\n### What NOT to Log\n\n**‚ùå Never log**:\n- Passwords (plain or hashed)\n- Credit card numbers\n- Social Security numbers\n- API keys/secrets\n- Session tokens\n- Personally identifiable information (PII) in clear text\n\n```typescript\n// ‚ùå BAD - Logs sensitive data\nlogger.info('User login', { email, password });\n\n// ‚úÖ GOOD - Logs non-sensitive data\nlogger.info('User login attempt', {\n  email,\n  ip: req.ip,\n  userAgent: req.get('user-agent'),\n  success: true,\n});\n```\n\n### Security Event Logging\n\n```typescript\nenum SecurityEvent {\n  LOGIN_SUCCESS = 'login_success',\n  LOGIN_FAILURE = 'login_failure',\n  PASSWORD_RESET = 'password_reset',\n  ACCOUNT_LOCKED = 'account_locked',\n  PERMISSION_DENIED = 'permission_denied',\n  SUSPICIOUS_ACTIVITY = 'suspicious_activity',\n}\n\nfunction logSecurityEvent(\n  event: SecurityEvent,\n  userId: string | null,\n  metadata: Record<string, any>\n) {\n  logger.warn({\n    type: 'security',\n    event,\n    userId,\n    timestamp: new Date().toISOString(),\n    ip: metadata.ip,\n    userAgent: metadata.userAgent,\n    ...metadata,\n  });\n}\n```\n\n## Dependency Scanning\n\n### Automated Security Scanning\n\n```yaml\n# .github/workflows/security.yml\nname: Security Scan\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * 0' # Weekly\n\njobs:\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run npm audit\n        run: npm audit --audit-level=high\n\n      - name: Run Snyk security scan\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          scan-type: 'fs'\n          scan-ref: '.'\n```\n\n## Security Checklist Summary\n\n### Pre-Deployment Checklist\n\n**Authentication & Authorization**:\n- [ ] Passwords hashed with bcrypt (12+ rounds)\n- [ ] JWT tokens have short expiry (15 minutes)\n- [ ] Refresh tokens properly implemented\n- [ ] MFA available for sensitive accounts\n- [ ] Authorization checks on all endpoints\n- [ ] Rate limiting on auth endpoints\n\n**Input Validation**:\n- [ ] All inputs validated with schemas\n- [ ] SQL queries use parameterized statements\n- [ ] File uploads restricted (type, size)\n- [ ] HTML content sanitized\n- [ ] No eval() or Function() with user input\n\n**Security Headers**:\n- [ ] HTTPS enforced\n- [ ] CSP configured\n- [ ] HSTS enabled\n- [ ] X-Frame-Options set\n- [ ] X-Content-Type-Options set\n\n**Data Protection**:\n- [ ] Sensitive data encrypted at rest\n- [ ] Secrets stored in environment variables/vault\n- [ ] No secrets in version control\n- [ ] PII handled according to regulations\n- [ ] Database backups encrypted\n\n**Logging & Monitoring**:\n- [ ] Security events logged\n- [ ] No sensitive data in logs\n- [ ] Failed auth attempts monitored\n- [ ] Unusual activity alerts configured\n- [ ] Log retention policy defined\n\n**Dependencies**:\n- [ ] All dependencies up to date\n- [ ] No known vulnerabilities (npm audit)\n- [ ] Dependabot/Renovate configured\n- [ ] Unused dependencies removed\n\n**API Security**:\n- [ ] CORS properly configured\n- [ ] CSRF protection enabled\n- [ ] Rate limiting implemented\n- [ ] API keys rotated regularly\n- [ ] Endpoints documented\n\n## When to Use This Skill\n\nUse this skill when:\n- Conducting security audits\n- Implementing authentication/authorization\n- Reviewing code for vulnerabilities\n- Setting up new projects\n- Handling sensitive data\n- Responding to security incidents\n- Training team on security\n- Preparing for compliance audits\n- Deploying to production\n- Integrating third-party services\n\n---\n\n**Remember**: Security is not a one-time task but an ongoing process. Stay informed about new vulnerabilities, keep dependencies updated, and always assume malicious actors are trying to exploit your application."
              },
              {
                "name": "technical-writing",
                "description": "Technical writing best practices including documentation structure, clear writing principles, API documentation, tutorials, changelogs, and markdown formatting. Use when writing documentation, creating READMEs, documenting APIs, or writing tutorials.",
                "path": "plugins/titanium-toolkit/skills/technical-writing/SKILL.md",
                "frontmatter": {
                  "name": "technical-writing",
                  "description": "Technical writing best practices including documentation structure, clear writing principles, API documentation, tutorials, changelogs, and markdown formatting. Use when writing documentation, creating READMEs, documenting APIs, or writing tutorials."
                },
                "content": "# Technical Writing\n\nThis skill provides comprehensive guidance for creating clear, effective technical documentation that helps users and developers.\n\n## Documentation Structure\n\n### The Four Types of Documentation\n\n**1. Tutorials** (Learning-oriented)\n- Goal: Help beginners learn\n- Format: Step-by-step lessons\n- Example: \"Build your first API\"\n\n**2. How-to Guides** (Problem-oriented)\n- Goal: Solve specific problems\n- Format: Numbered steps\n- Example: \"How to deploy to production\"\n\n**3. Reference** (Information-oriented)\n- Goal: Provide detailed information\n- Format: Systematic descriptions\n- Example: API reference, configuration options\n\n**4. Explanation** (Understanding-oriented)\n- Goal: Clarify concepts\n- Format: Discursive explanations\n- Example: Architecture decisions, design patterns\n\n### README Structure\n\n```markdown\n# Project Name\n\nBrief description of what the project does (1-2 sentences).\n\n[![Build Status](badge)](link)\n[![Coverage](badge)](link)\n[![License](badge)](link)\n\n## Features\n\n- Feature 1\n- Feature 2\n- Feature 3\n\n## Quick Start\n\n```bash\n# Installation\nnpm install project-name\n\n# Usage\nnpx project-name init\n```\n\n## Prerequisites\n\n- Node.js 18+\n- PostgreSQL 14+\n- Redis 7+\n\n## Installation\n\n### Using npm\n\n```bash\nnpm install project-name\n```\n\n### Using yarn\n\n```bash\nyarn add project-name\n```\n\n### From source\n\n```bash\ngit clone https://github.com/user/project.git\ncd project\nnpm install\nnpm run build\n```\n\n## Configuration\n\nCreate a `.env` file:\n\n```env\nDATABASE_URL=postgresql://user:password@localhost:5432/db\nAPI_KEY=your_api_key\n```\n\n## Usage\n\n### Basic Example\n\n```typescript\nimport { createClient } from 'project-name';\n\nconst client = createClient({\n  apiKey: process.env.API_KEY,\n});\n\nconst result = await client.doSomething();\nconsole.log(result);\n```\n\n### Advanced Example\n\n[More complex example with explanations]\n\n## API Reference\n\nSee [API.md](./API.md) for complete API documentation.\n\n## Contributing\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.\n\n## License\n\nMIT ¬© [Author Name]\n\n## Support\n\n- Documentation: https://docs.example.com\n- Issues: https://github.com/user/project/issues\n- Discussions: https://github.com/user/project/discussions\n```\n\n## Clear Writing Principles\n\n### Use Active Voice\n\n```markdown\n‚ùå Passive: The data is validated by the function.\n‚úÖ Active: The function validates the data.\n\n‚ùå Passive: Errors should be handled by your application.\n‚úÖ Active: Your application should handle errors.\n```\n\n### Use Simple Language\n\n```markdown\n‚ùå Complex: Utilize the aforementioned methodology to instantiate a novel instance.\n‚úÖ Simple: Use this method to create a new instance.\n\n‚ùå Jargon: Leverage our SDK to synergize with the API ecosystem.\n‚úÖ Clear: Use our SDK to connect to the API.\n```\n\n### Be Concise\n\n```markdown\n‚ùå Wordy: In order to be able to successfully complete the installation process,\nyou will need to make sure that you have Node.js version 18 or higher installed\non your system.\n‚úÖ Concise: Install Node.js 18 or higher.\n\n‚ùå Redundant: The function returns back a response.\n‚úÖ Concise: The function returns a response.\n```\n\n### Use Consistent Terminology\n\n```markdown\n‚ùå Inconsistent:\n- Create a user\n- Add an account\n- Register a member\n(All referring to the same action)\n\n‚úÖ Consistent:\n- Create a user\n- Update a user\n- Delete a user\n```\n\n## Code Example Best Practices\n\n### Complete, Runnable Examples\n\n```typescript\n// ‚ùå BAD - Incomplete example\nuser.save();\n\n// ‚úÖ GOOD - Complete example\nimport { User } from './models';\n\nasync function createUser() {\n  const user = new User({\n    email: 'user@example.com',\n    name: 'John Doe',\n  });\n\n  await user.save();\n  console.log('User created:', user.id);\n}\n\ncreateUser();\n```\n\n### Show Expected Output\n\n```typescript\n// Calculate fibonacci number\nfunction fibonacci(n: number): number {\n  if (n <= 1) return n;\n  return fibonacci(n - 1) + fibonacci(n - 2);\n}\n\nconsole.log(fibonacci(10));\n// Output: 55\n```\n\n### Highlight Important Parts\n\n```typescript\n// Authenticate user with JWT\napp.post('/api/auth/login', async (req, res) => {\n  const { email, password } = req.body;\n\n  const user = await User.findOne({ email });\n  if (!user) {\n    return res.status(401).json({ error: 'Invalid credentials' });\n  }\n\n  // üëá Important: Always use bcrypt for password comparison\n  const isValid = await bcrypt.compare(password, user.passwordHash);\n  if (!isValid) {\n    return res.status(401).json({ error: 'Invalid credentials' });\n  }\n\n  const token = generateToken(user);\n  res.json({ token });\n});\n```\n\n### Provide Context\n\n```typescript\n// ‚ùå BAD - No context\nawait client.query('SELECT * FROM users');\n\n// ‚úÖ GOOD - With context\n// Fetch all active users who logged in within the last 30 days\nconst activeUsers = await client.query(`\n  SELECT id, email, name, last_login\n  FROM users\n  WHERE status = 'active'\n    AND last_login > NOW() - INTERVAL '30 days'\n  ORDER BY last_login DESC\n`);\n```\n\n## Tutorial Structure\n\n### Learning Progression\n\n**1. Introduction** (2-3 sentences)\n- What will users learn?\n- Why is it useful?\n\n**2. Prerequisites**\n- Required knowledge\n- Required tools\n- Time estimate\n\n**3. Step-by-Step Instructions**\n- Number each step\n- One concept per step\n- Show results after each step\n\n**4. Next Steps**\n- Links to related tutorials\n- Advanced topics\n- Additional resources\n\n### Tutorial Example\n\n```markdown\n# Building a REST API with Express\n\nIn this tutorial, you'll build a REST API for managing a todo list.\nYou'll learn how to create routes, handle requests, and connect to a database.\n\n**Time**: 30 minutes\n**Level**: Beginner\n\n## Prerequisites\n\n- Node.js 18+ installed\n- Basic JavaScript knowledge\n- Code editor (VS Code recommended)\n\n## Step 1: Set Up Project\n\nCreate a new project directory and initialize npm:\n\n```bash\nmkdir todo-api\ncd todo-api\nnpm init -y\n```\n\nInstall Express:\n\n```bash\nnpm install express\n```\n\nYou should see `express` added to your `package.json`.\n\n## Step 2: Create Basic Server\n\nCreate `index.js`:\n\n```javascript\nconst express = require('express');\nconst app = express();\n\napp.get('/', (req, res) => {\n  res.json({ message: 'Hello, World!' });\n});\n\nconst PORT = 3000;\napp.listen(PORT, () => {\n  console.log(`Server running on http://localhost:${PORT}`);\n});\n```\n\nRun the server:\n\n```bash\nnode index.js\n```\n\nVisit http://localhost:3000 in your browser. You should see:\n```json\n{ \"message\": \"Hello, World!\" }\n```\n\n## Step 3: Add Todo Routes\n\n[Continue with more steps...]\n\n## What You Learned\n\n- How to set up an Express server\n- How to create REST API routes\n- How to connect to a database\n\n## Next Steps\n\n- [Authentication with JWT](./auth-tutorial.md)\n- [Deploy to Production](./deploy-guide.md)\n- [API Best Practices](./api-best-practices.md)\n```\n\n## API Documentation Patterns\n\n### Endpoint Documentation\n\n```markdown\n## Create User\n\nCreates a new user account.\n\n**Endpoint**: `POST /api/v1/users`\n\n**Authentication**: Not required\n\n**Request Body**:\n\n| Field | Type | Required | Description |\n|-------|------|----------|-------------|\n| email | string | Yes | User's email address (must be valid) |\n| password | string | Yes | Password (min 8 characters) |\n| name | string | Yes | User's full name (max 100 characters) |\n\n**Example Request**:\n\n```bash\ncurl -X POST https://api.example.com/v1/users \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"user@example.com\",\n    \"password\": \"SecurePass123\",\n    \"name\": \"John Doe\"\n  }'\n```\n\n**Success Response** (201 Created):\n\n```json\n{\n  \"id\": \"user_abc123\",\n  \"email\": \"user@example.com\",\n  \"name\": \"John Doe\",\n  \"createdAt\": \"2025-10-16T10:30:00Z\"\n}\n```\n\n**Error Responses**:\n\n**400 Bad Request** - Invalid input:\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid email address\",\n    \"field\": \"email\"\n  }\n}\n```\n\n**409 Conflict** - Email already exists:\n```json\n{\n  \"error\": {\n    \"code\": \"EMAIL_EXISTS\",\n    \"message\": \"Email address already registered\"\n  }\n}\n```\n\n**Rate Limit**: 5 requests per minute\n```\n\n### Function/Method Documentation\n\n```typescript\n/**\n * Calculates the total price of items including tax.\n *\n * @param items - Array of items to calculate total for\n * @param taxRate - Tax rate as decimal (e.g., 0.08 for 8%)\n * @returns Total price including tax\n *\n * @throws {Error} If items array is empty\n * @throws {Error} If taxRate is negative\n *\n * @example\n * ```typescript\n * const items = [\n *   { price: 10, quantity: 2 },\n *   { price: 15, quantity: 1 }\n * ];\n * const total = calculateTotal(items, 0.08);\n * console.log(total); // 37.80\n * ```\n */\nfunction calculateTotal(\n  items: Array<{ price: number; quantity: number }>,\n  taxRate: number\n): number {\n  if (items.length === 0) {\n    throw new Error('Items array cannot be empty');\n  }\n  if (taxRate < 0) {\n    throw new Error('Tax rate cannot be negative');\n  }\n\n  const subtotal = items.reduce(\n    (sum, item) => sum + item.price * item.quantity,\n    0\n  );\n  return subtotal * (1 + taxRate);\n}\n```\n\n## Changelog Best Practices\n\n### Keep a Changelog Format\n\n```markdown\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/),\nand this project adheres to [Semantic Versioning](https://semver.org/).\n\n## [Unreleased]\n\n### Added\n- New feature X for Y use case\n\n### Changed\n- Improved performance of Z operation\n\n### Fixed\n- Fixed bug where A caused B\n\n## [2.1.0] - 2025-10-16\n\n### Added\n- User profile avatars (#123)\n- Email notification settings (#125)\n- Two-factor authentication support (#130)\n\n### Changed\n- Updated UI for settings page (#124)\n- Improved API response times by 40% (#128)\n\n### Deprecated\n- `oldFunction()` will be removed in v3.0 - use `newFunction()` instead\n\n### Fixed\n- Fixed memory leak in session management (#126)\n- Corrected timezone handling in reports (#129)\n\n### Security\n- Updated dependencies to patch security vulnerabilities (#127)\n\n## [2.0.0] - 2025-09-01\n\n### Added\n- Complete redesign of dashboard\n- GraphQL API support\n\n### Changed\n- **BREAKING**: Renamed `create_user` to `createUser` for consistency\n- **BREAKING**: Changed date format from `DD/MM/YYYY` to ISO 8601\n\n### Removed\n- **BREAKING**: Removed deprecated v1 API endpoints\n\n[Unreleased]: https://github.com/user/project/compare/v2.1.0...HEAD\n[2.1.0]: https://github.com/user/project/compare/v2.0.0...v2.1.0\n[2.0.0]: https://github.com/user/project/releases/tag/v2.0.0\n```\n\n### Version Numbering\n\n**Semantic Versioning (MAJOR.MINOR.PATCH)**:\n- **MAJOR**: Breaking changes (2.0.0 ‚Üí 3.0.0)\n- **MINOR**: New features, backwards compatible (2.0.0 ‚Üí 2.1.0)\n- **PATCH**: Bug fixes, backwards compatible (2.0.0 ‚Üí 2.0.1)\n\n## Markdown Formatting\n\n### Headers\n\n```markdown\n# H1 - Main title\n## H2 - Section\n### H3 - Subsection\n#### H4 - Sub-subsection\n```\n\n### Emphasis\n\n```markdown\n**Bold text** or __bold__\n*Italic text* or _italic_\n***Bold and italic***\n~~Strikethrough~~\n`Inline code`\n```\n\n### Lists\n\n```markdown\nUnordered list:\n- Item 1\n- Item 2\n  - Nested item\n  - Another nested item\n- Item 3\n\nOrdered list:\n1. First item\n2. Second item\n   1. Nested item\n   2. Another nested item\n3. Third item\n\nTask list:\n- [x] Completed task\n- [ ] Incomplete task\n```\n\n### Links and Images\n\n```markdown\n[Link text](https://example.com)\n[Link with title](https://example.com \"Title text\")\n\n![Alt text](image.jpg)\n![Alt text](image.jpg \"Image title\")\n```\n\n### Code Blocks\n\n````markdown\nInline code: `const x = 5;`\n\nCode block:\n```javascript\nfunction greet(name) {\n  console.log(`Hello, ${name}!`);\n}\n```\n\nWith line highlighting:\n```javascript {2}\nfunction greet(name) {\n  console.log(`Hello, ${name}!`); // This line is highlighted\n}\n```\n````\n\n### Tables\n\n```markdown\n| Column 1 | Column 2 | Column 3 |\n|----------|----------|----------|\n| Row 1    | Data     | More     |\n| Row 2    | Data     | More     |\n\nAlignment:\n| Left | Center | Right |\n|:-----|:------:|------:|\n| L    | C      | R     |\n```\n\n### Blockquotes\n\n```markdown\n> Single line quote\n\n> Multi-line\n> quote with\n> several lines\n\n> **Note**: Important information\n```\n\n### Admonitions\n\n```markdown\n> **‚ö†Ô∏è Warning**: This action cannot be undone.\n\n> **üí° Tip**: Use keyboard shortcuts to speed up your workflow.\n\n> **üö® Danger**: Never commit secrets to version control.\n\n> **‚ÑπÔ∏è Info**: This feature requires Node.js 18+.\n```\n\n## Diagrams and Visuals\n\n### When to Use Diagrams\n\n**Use diagrams for**:\n- System architecture\n- Data flow\n- Process flows\n- Component relationships\n- Complex concepts\n\n**Don't use diagrams for**:\n- Simple concepts (text is better)\n- Things that change frequently\n- Content that can be code\n\n### Mermaid Diagrams\n\n````markdown\n```mermaid\ngraph TD\n    A[User Request] --> B{Authenticated?}\n    B -->|Yes| C[Process Request]\n    B -->|No| D[Return 401]\n    C --> E[Return Response]\n```\n\n```mermaid\nsequenceDiagram\n    Client->>API: POST /users\n    API->>Database: INSERT user\n    Database-->>API: User created\n    API->>Email: Send welcome email\n    API-->>Client: 201 Created\n```\n````\n\n### ASCII Diagrams\n\n```markdown\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Client    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   API Server ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Database ‚îÇ\n‚îÇ  (Browser)  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   (Express)  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ (Postgres)‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Progressive Disclosure\n\n### Start Simple, Add Details\n\n```markdown\n## Installation\n\nInstall via npm:\n\n```bash\nnpm install package-name\n```\n\n<details>\n<summary>Advanced installation options</summary>\n\n### Install from source\n\n```bash\ngit clone https://github.com/user/package.git\ncd package\nnpm install\nnpm run build\nnpm link\n```\n\n### Install specific version\n\n```bash\nnpm install package-name@2.1.0\n```\n\n### Install with peer dependencies\n\n```bash\nnpm install package-name react react-dom\n```\n</details>\n```\n\n### Organize by Skill Level\n\n```markdown\n## Quick Start (Beginner)\n\nGet up and running in 5 minutes:\n\n[Simple example]\n\n## Advanced Usage\n\nFor experienced users:\n\n[Complex example]\n\n## Expert Topics\n\nDeep dive into internals:\n\n[Very advanced example]\n```\n\n## User-Focused Language\n\n### Address the Reader\n\n```markdown\n‚ùå Impersonal: The configuration file should be updated.\n‚úÖ Personal: Update your configuration file.\n\n‚ùå Distant: One must install the dependencies.\n‚úÖ Direct: Install the dependencies.\n```\n\n### Use \"You\" Not \"We\"\n\n```markdown\n‚ùå We: Now we'll create a new user.\n‚úÖ You: Now you'll create a new user.\n\n‚ùå We: We recommend using TypeScript.\n‚úÖ You: We recommend you use TypeScript.\n```\n\n### Be Helpful\n\n```markdown\n‚ùå Vague: An error occurred.\n‚úÖ Helpful: Connection failed. Check your network and try again.\n\n‚ùå Blaming: You entered invalid data.\n‚úÖ Helpful: The email field requires a valid email address (e.g., user@example.com).\n```\n\n## Avoiding Jargon\n\n### Define Technical Terms\n\n```markdown\n‚ùå Assumes knowledge:\n\"Use the ORM to query the RDBMS.\"\n\n‚úÖ Explains terms:\n\"Use the ORM (Object-Relational Mapping tool) to query the database.\nAn ORM lets you interact with your database using code instead of SQL.\"\n```\n\n### Use Common Words\n\n```markdown\n‚ùå Technical jargon:\n\"Leverage the API to facilitate data ingestion.\"\n\n‚úÖ Plain English:\n\"Use the API to import data.\"\n```\n\n## Version Documentation\n\n### Document Version Changes\n\n```markdown\n## Version Compatibility\n\n| Version | Node.js | Features |\n|---------|---------|----------|\n| 3.x     | 18+     | Full feature set |\n| 2.x     | 16+     | Legacy API (deprecated) |\n| 1.x     | 14+     | No longer supported |\n\n## Upgrading from 2.x to 3.x\n\n### Breaking Changes\n\n**1. Renamed functions**\n\n```typescript\n// v2.x\nimport { create_user } from 'package';\n\n// v3.x\nimport { createUser } from 'package';\n```\n\n**2. Changed date format**\n\nDates now use ISO 8601 format:\n- Old: `01/15/2025`\n- New: `2025-01-15T00:00:00Z`\n\n### Migration Guide\n\n1. Update imports:\n   ```bash\n   # Run this command to update your code\n   npx package-migrate-v3\n   ```\n\n2. Update date handling:\n   ```typescript\n   // Before\n   const date = '01/15/2025';\n\n   // After\n   const date = '2025-01-15T00:00:00Z';\n   ```\n\n3. Test thoroughly before deploying.\n```\n\n## Documentation Checklist\n\n**Before Writing**:\n- [ ] Who is the audience (beginner/intermediate/expert)?\n- [ ] What do they need to accomplish?\n- [ ] What do they already know?\n\n**While Writing**:\n- [ ] Use active voice\n- [ ] Use simple language\n- [ ] Be concise\n- [ ] Provide examples\n- [ ] Show expected output\n\n**After Writing**:\n- [ ] Read it aloud\n- [ ] Have someone else review it\n- [ ] Test all code examples\n- [ ] Check all links\n- [ ] Spell check\n\n## When to Use This Skill\n\nUse this skill when:\n- Writing project READMEs\n- Creating API documentation\n- Writing tutorials\n- Documenting code\n- Creating user guides\n- Writing changelogs\n- Contributing to open source\n- Creating internal documentation\n- Writing blog posts about technical topics\n- Training others on technical writing\n\n---\n\n**Remember**: Good documentation is empathetic. Always write for the person reading your docs at 2 AM who just wants to get their code working. Be clear, be helpful, and be kind."
              },
              {
                "name": "testing-strategy",
                "description": "Comprehensive testing strategies including test pyramid, TDD methodology, testing patterns, coverage goals, and CI/CD integration. Use when writing tests, implementing TDD, reviewing test coverage, debugging test failures, or setting up testing infrastructure.",
                "path": "plugins/titanium-toolkit/skills/testing-strategy/SKILL.md",
                "frontmatter": {
                  "name": "testing-strategy",
                  "description": "Comprehensive testing strategies including test pyramid, TDD methodology, testing patterns, coverage goals, and CI/CD integration. Use when writing tests, implementing TDD, reviewing test coverage, debugging test failures, or setting up testing infrastructure."
                },
                "content": "# Testing Strategy\n\nThis skill provides comprehensive guidance for implementing effective testing strategies across your entire application stack.\n\n## Test Pyramid\n\n### The Testing Hierarchy\n\n```\n        /\\\n       /  \\\n      /E2E \\       10% - End-to-End Tests (slowest, most expensive)\n     /______\\\n    /        \\\n   /Integration\\  20% - Integration Tests (medium speed/cost)\n  /____________\\\n /              \\\n/   Unit Tests   \\ 70% - Unit Tests (fast, cheap, focused)\n/__________________\\\n```\n\n**Rationale**:\n- **70% Unit Tests**: Fast, isolated, catch bugs early\n- **20% Integration Tests**: Test component interactions\n- **10% E2E Tests**: Test critical user journeys\n\n### Why This Distribution?\n\n**Unit tests are cheap**:\n- Run in milliseconds\n- No external dependencies\n- Easy to debug\n- High code coverage per test\n\n**Integration tests are moderate**:\n- Test real interactions\n- Catch integration bugs\n- Slower than unit tests\n- More complex setup\n\n**E2E tests are expensive**:\n- Test entire system\n- Catch UX issues\n- Very slow (seconds/minutes)\n- Brittle and hard to maintain\n\n## TDD (Test-Driven Development)\n\n### Red-Green-Refactor Cycle\n\n**1. Red - Write a failing test**:\n```typescript\ndescribe('Calculator', () => {\n  test('adds two numbers', () => {\n    const calculator = new Calculator();\n    expect(calculator.add(2, 3)).toBe(5); // FAILS - method doesn't exist\n  });\n});\n```\n\n**2. Green - Write minimal code to pass**:\n```typescript\nclass Calculator {\n  add(a: number, b: number): number {\n    return a + b; // Simplest implementation\n  }\n}\n// Test now PASSES\n```\n\n**3. Refactor - Improve the code**:\n```typescript\nclass Calculator {\n  add(a: number, b: number): number {\n    // Add validation\n    if (!Number.isFinite(a) || !Number.isFinite(b)) {\n      throw new Error('Arguments must be finite numbers');\n    }\n    return a + b;\n  }\n}\n```\n\n### TDD Benefits\n\n**Design benefits**:\n- Forces you to think about API before implementation\n- Leads to more testable, modular code\n- Encourages SOLID principles\n\n**Quality benefits**:\n- 100% test coverage by design\n- Catches bugs immediately\n- Provides living documentation\n\n**Workflow benefits**:\n- Clear next step (make test pass)\n- Confidence when refactoring\n- Prevents over-engineering\n\n## Arrange-Act-Assert Pattern\n\n### The AAA Pattern\n\nEvery test should follow this structure:\n\n```typescript\ntest('user registration creates account and sends welcome email', async () => {\n  // ARRANGE - Set up test conditions\n  const userData = {\n    email: 'test@example.com',\n    password: 'SecurePass123',\n    name: 'Test User',\n  };\n  const mockEmailService = jest.fn();\n  const userService = new UserService(mockEmailService);\n\n  // ACT - Execute the behavior being tested\n  const result = await userService.register(userData);\n\n  // ASSERT - Verify the outcome\n  expect(result.id).toBeDefined();\n  expect(result.email).toBe(userData.email);\n  expect(mockEmailService).toHaveBeenCalledWith({\n    to: userData.email,\n    subject: 'Welcome!',\n    template: 'welcome',\n  });\n});\n```\n\n### Why AAA?\n\n- **Clear structure**: Easy to understand what's being tested\n- **Consistent**: All tests follow same pattern\n- **Maintainable**: Easy to modify and debug\n\n## Mocking Strategies\n\n### When to Mock\n\n**‚úÖ DO mock**:\n- External APIs\n- Databases\n- File system operations\n- Time/dates\n- Random number generators\n- Network requests\n- Third-party services\n\n```typescript\n// Mock external API\njest.mock('axios');\n\ntest('fetches user data from API', async () => {\n  const mockData = { id: 1, name: 'John' };\n  (axios.get as jest.Mock).mockResolvedValue({ data: mockData });\n\n  const user = await fetchUser(1);\n\n  expect(user).toEqual(mockData);\n});\n```\n\n### When NOT to Mock\n\n**‚ùå DON'T mock**:\n- Pure functions (test them directly)\n- Simple utility functions\n- Domain logic\n- Value objects\n- Internal implementation details\n\n```typescript\n// ‚ùå BAD - Over-mocking\ntest('validates email', () => {\n  const validator = new EmailValidator();\n  jest.spyOn(validator, 'isValid').mockReturnValue(true);\n  expect(validator.isValid('test@example.com')).toBe(true);\n  // This test is useless - you're testing the mock, not the code\n});\n\n// ‚úÖ GOOD - Test real implementation\ntest('validates email', () => {\n  const validator = new EmailValidator();\n  expect(validator.isValid('test@example.com')).toBe(true);\n  expect(validator.isValid('invalid')).toBe(false);\n});\n```\n\n### Mocking Patterns\n\n**Stub** (return predetermined values):\n```typescript\nconst mockDatabase = {\n  findUser: jest.fn().mockResolvedValue({ id: 1, name: 'John' }),\n  saveUser: jest.fn().mockResolvedValue(true),\n};\n```\n\n**Spy** (track calls, use real implementation):\n```typescript\nconst emailService = new EmailService();\nconst sendSpy = jest.spyOn(emailService, 'send');\n\nawait emailService.send('test@example.com', 'Hello');\n\nexpect(sendSpy).toHaveBeenCalledTimes(1);\nexpect(sendSpy).toHaveBeenCalledWith('test@example.com', 'Hello');\n```\n\n**Fake** (lightweight implementation):\n```typescript\nclass FakeDatabase {\n  private data = new Map();\n\n  async save(key: string, value: any) {\n    this.data.set(key, value);\n  }\n\n  async get(key: string) {\n    return this.data.get(key);\n  }\n}\n```\n\n## Test Coverage Goals\n\n### Coverage Metrics\n\n**Line Coverage**: Percentage of code lines executed\n- **Target**: 80-90% for critical paths\n\n**Branch Coverage**: Percentage of if/else branches tested\n- **Target**: 80%+ (more important than line coverage)\n\n**Function Coverage**: Percentage of functions called\n- **Target**: 90%+\n\n**Statement Coverage**: Percentage of statements executed\n- **Target**: 80%+\n\n### Coverage Configuration\n\n```json\n// package.json\n{\n  \"jest\": {\n    \"collectCoverage\": true,\n    \"coverageThreshold\": {\n      \"global\": {\n        \"branches\": 80,\n        \"functions\": 90,\n        \"lines\": 80,\n        \"statements\": 80\n      },\n      \"./src/critical/\": {\n        \"branches\": 95,\n        \"functions\": 95,\n        \"lines\": 95,\n        \"statements\": 95\n      }\n    },\n    \"coveragePathIgnorePatterns\": [\n      \"/node_modules/\",\n      \"/tests/\",\n      \"/migrations/\",\n      \"/.config.ts$/\"\n    ]\n  }\n}\n```\n\n### What to Prioritize\n\n**High priority** (aim for 95%+ coverage):\n- Business logic\n- Security-critical code\n- Payment/billing code\n- Data validation\n- Authentication/authorization\n\n**Medium priority** (aim for 80%+ coverage):\n- API endpoints\n- Database queries\n- Utility functions\n- Error handling\n\n**Low priority** (optional coverage):\n- UI components (use integration tests instead)\n- Configuration files\n- Type definitions\n- Third-party library wrappers\n\n## Integration Testing\n\n### Database Integration Tests\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\n\ndescribe('UserRepository', () => {\n  let prisma: PrismaClient;\n  let repository: UserRepository;\n\n  beforeAll(async () => {\n    // Use test database\n    prisma = new PrismaClient({\n      datasources: { db: { url: process.env.TEST_DATABASE_URL } },\n    });\n    repository = new UserRepository(prisma);\n  });\n\n  beforeEach(async () => {\n    // Clean database before each test\n    await prisma.user.deleteMany();\n  });\n\n  afterAll(async () => {\n    await prisma.$disconnect();\n  });\n\n  test('creates user and retrieves by email', async () => {\n    // ARRANGE\n    const userData = {\n      email: 'test@example.com',\n      name: 'Test User',\n      password: 'hashed_password',\n    };\n\n    // ACT\n    const created = await repository.create(userData);\n    const retrieved = await repository.findByEmail(userData.email);\n\n    // ASSERT\n    expect(retrieved).toBeDefined();\n    expect(retrieved?.id).toBe(created.id);\n    expect(retrieved?.email).toBe(userData.email);\n  });\n});\n```\n\n### API Integration Tests\n\n```typescript\nimport request from 'supertest';\nimport { app } from '../src/app';\n\ndescribe('User API', () => {\n  test('POST /api/users creates user and returns 201', async () => {\n    const response = await request(app)\n      .post('/api/users')\n      .send({\n        email: 'test@example.com',\n        password: 'SecurePass123',\n        name: 'Test User',\n      })\n      .expect(201);\n\n    expect(response.body).toMatchObject({\n      email: 'test@example.com',\n      name: 'Test User',\n    });\n    expect(response.body.password).toBeUndefined(); // Never return password\n  });\n\n  test('POST /api/users returns 400 for invalid email', async () => {\n    const response = await request(app)\n      .post('/api/users')\n      .send({\n        email: 'invalid-email',\n        password: 'SecurePass123',\n        name: 'Test User',\n      })\n      .expect(400);\n\n    expect(response.body.error.code).toBe('VALIDATION_ERROR');\n  });\n});\n```\n\n### Service Integration Tests\n\n```typescript\ndescribe('OrderService Integration', () => {\n  test('complete order flow', async () => {\n    // Create order\n    const order = await orderService.create({\n      userId: 'user_123',\n      items: [{ productId: 'prod_1', quantity: 2 }],\n    });\n\n    // Process payment\n    const payment = await paymentService.process({\n      orderId: order.id,\n      amount: order.total,\n    });\n\n    // Verify inventory updated\n    const product = await inventoryService.getProduct('prod_1');\n    expect(product.stock).toBe(originalStock - 2);\n\n    // Verify order status updated\n    const updatedOrder = await orderService.getById(order.id);\n    expect(updatedOrder.status).toBe('paid');\n  });\n});\n```\n\n## E2E Testing\n\n### Playwright Setup\n\n```typescript\n// playwright.config.ts\nimport { defineConfig } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './e2e',\n  fullyParallel: true,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n  },\n  projects: [\n    { name: 'chromium', use: { browserName: 'chromium' } },\n    { name: 'firefox', use: { browserName: 'firefox' } },\n    { name: 'webkit', use: { browserName: 'webkit' } },\n  ],\n});\n```\n\n### E2E Test Example\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest.describe('User Registration Flow', () => {\n  test('user can register and login', async ({ page }) => {\n    // Navigate to registration page\n    await page.goto('/register');\n\n    // Fill registration form\n    await page.fill('[name=\"email\"]', 'test@example.com');\n    await page.fill('[name=\"password\"]', 'SecurePass123');\n    await page.fill('[name=\"confirmPassword\"]', 'SecurePass123');\n    await page.fill('[name=\"name\"]', 'Test User');\n\n    // Submit form\n    await page.click('button[type=\"submit\"]');\n\n    // Wait for redirect to dashboard\n    await page.waitForURL('/dashboard');\n\n    // Verify welcome message\n    await expect(page.locator('h1')).toContainText('Welcome, Test User');\n  });\n\n  test('shows validation errors for invalid input', async ({ page }) => {\n    await page.goto('/register');\n\n    await page.fill('[name=\"email\"]', 'invalid-email');\n    await page.fill('[name=\"password\"]', '123'); // Too short\n\n    await page.click('button[type=\"submit\"]');\n\n    // Verify error messages displayed\n    await expect(page.locator('[data-testid=\"email-error\"]'))\n      .toContainText('Invalid email');\n    await expect(page.locator('[data-testid=\"password-error\"]'))\n      .toContainText('at least 8 characters');\n  });\n});\n```\n\n### Critical E2E Scenarios\n\nTest these critical user journeys:\n- User registration and login\n- Checkout and payment flow\n- Password reset\n- Profile updates\n- Critical business workflows\n\n## Performance Testing\n\n### Load Testing with k6\n\n```javascript\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  stages: [\n    { duration: '30s', target: 20 },   // Ramp up to 20 users\n    { duration: '1m', target: 20 },    // Stay at 20 users\n    { duration: '30s', target: 100 },  // Ramp up to 100 users\n    { duration: '1m', target: 100 },   // Stay at 100 users\n    { duration: '30s', target: 0 },    // Ramp down to 0 users\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)<500'], // 95% of requests under 500ms\n    http_req_failed: ['rate<0.01'],   // Less than 1% error rate\n  },\n};\n\nexport default function() {\n  const response = http.get('https://api.example.com/users');\n\n  check(response, {\n    'status is 200': (r) => r.status === 200,\n    'response time < 500ms': (r) => r.timings.duration < 500,\n  });\n\n  sleep(1);\n}\n```\n\n### Benchmark Testing\n\n```typescript\nimport { performance } from 'perf_hooks';\n\ndescribe('Performance Benchmarks', () => {\n  test('database query completes in under 100ms', async () => {\n    const start = performance.now();\n\n    await database.query('SELECT * FROM users WHERE email = ?', ['test@example.com']);\n\n    const duration = performance.now() - start;\n    expect(duration).toBeLessThan(100);\n  });\n\n  test('API endpoint responds in under 200ms', async () => {\n    const start = performance.now();\n\n    await request(app).get('/api/users/123');\n\n    const duration = performance.now() - start;\n    expect(duration).toBeLessThan(200);\n  });\n});\n```\n\n## Flaky Test Prevention\n\n### Common Causes of Flaky Tests\n\n**1. Race Conditions**:\n```typescript\n// ‚ùå BAD - Race condition\ntest('displays data', async () => {\n  fetchData();\n  expect(screen.getByText('Data loaded')).toBeInTheDocument();\n  // Fails intermittently if fetchData takes longer than expected\n});\n\n// ‚úÖ GOOD - Wait for async operation\ntest('displays data', async () => {\n  fetchData();\n  await screen.findByText('Data loaded'); // Waits up to 1 second\n});\n```\n\n**2. Time Dependencies**:\n```typescript\n// ‚ùå BAD - Depends on current time\ntest('shows message for new users', () => {\n  const user = { createdAt: new Date() };\n  expect(isNewUser(user)).toBe(true);\n  // Fails if test runs slowly\n});\n\n// ‚úÖ GOOD - Mock time\ntest('shows message for new users', () => {\n  jest.useFakeTimers();\n  jest.setSystemTime(new Date('2025-10-16'));\n\n  const user = { createdAt: new Date('2025-10-15') };\n  expect(isNewUser(user)).toBe(true);\n\n  jest.useRealTimers();\n});\n```\n\n**3. Shared State**:\n```typescript\n// ‚ùå BAD - Tests share state\nlet counter = 0;\n\ntest('increments counter', () => {\n  counter++;\n  expect(counter).toBe(1);\n});\n\ntest('increments counter again', () => {\n  counter++;\n  expect(counter).toBe(1); // Fails if first test ran\n});\n\n// ‚úÖ GOOD - Isolated state\ntest('increments counter', () => {\n  const counter = new Counter();\n  counter.increment();\n  expect(counter.value).toBe(1);\n});\n```\n\n### Flaky Test Best Practices\n\n1. **Always clean up after tests**:\n```typescript\nafterEach(async () => {\n  await database.truncate();\n  jest.clearAllMocks();\n  jest.useRealTimers();\n});\n```\n\n2. **Use explicit waits, not delays**:\n```typescript\n// ‚ùå BAD\nawait sleep(1000);\n\n// ‚úÖ GOOD\nawait waitFor(() => expect(element).toBeInTheDocument());\n```\n\n3. **Isolate test data**:\n```typescript\ntest('creates user', async () => {\n  const uniqueEmail = `test-${Date.now()}@example.com`;\n  const user = await createUser({ email: uniqueEmail });\n  expect(user.email).toBe(uniqueEmail);\n});\n```\n\n## Test Data Management\n\n### Test Fixtures\n\n```typescript\n// fixtures/users.ts\nexport const testUsers = {\n  admin: {\n    email: 'admin@example.com',\n    password: 'AdminPass123',\n    role: 'admin',\n  },\n  regular: {\n    email: 'user@example.com',\n    password: 'UserPass123',\n    role: 'user',\n  },\n};\n\n// Usage in tests\nimport { testUsers } from './fixtures/users';\n\ntest('admin can delete users', async () => {\n  const admin = await createUser(testUsers.admin);\n  // Test admin functionality\n});\n```\n\n### Factory Pattern\n\n```typescript\nclass UserFactory {\n  static create(overrides = {}) {\n    return {\n      id: faker.datatype.uuid(),\n      email: faker.internet.email(),\n      name: faker.name.fullName(),\n      createdAt: new Date(),\n      ...overrides,\n    };\n  }\n\n  static createMany(count: number, overrides = {}) {\n    return Array.from({ length: count }, () => this.create(overrides));\n  }\n}\n\n// Usage\ntest('displays user list', () => {\n  const users = UserFactory.createMany(5);\n  render(<UserList users={users} />);\n  expect(screen.getAllByRole('listitem')).toHaveLength(5);\n});\n```\n\n### Database Seeding\n\n```typescript\n// seeds/test-seed.ts\nexport async function seedTestDatabase() {\n  // Create admin user\n  const admin = await prisma.user.create({\n    data: { email: 'admin@test.com', role: 'admin' },\n  });\n\n  // Create test products\n  const products = await Promise.all([\n    prisma.product.create({ data: { name: 'Product 1', price: 10 } }),\n    prisma.product.create({ data: { name: 'Product 2', price: 20 } }),\n  ]);\n\n  return { admin, products };\n}\n\n// Usage\nbeforeEach(async () => {\n  await prisma.$executeRaw`TRUNCATE TABLE users CASCADE`;\n  const { admin, products } = await seedTestDatabase();\n});\n```\n\n## CI/CD Integration\n\n### GitHub Actions Configuration\n\n```yaml\n# .github/workflows/test.yml\nname: Tests\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: postgres\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run linter\n        run: npm run lint\n\n      - name: Run type check\n        run: npm run type-check\n\n      - name: Run unit tests\n        run: npm run test:unit\n\n      - name: Run integration tests\n        run: npm run test:integration\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test\n\n      - name: Run E2E tests\n        run: npm run test:e2e\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage/coverage-final.json\n          fail_ci_if_error: true\n```\n\n### Test Scripts Organization\n\n```json\n// package.json\n{\n  \"scripts\": {\n    \"test\": \"npm run test:unit && npm run test:integration && npm run test:e2e\",\n    \"test:unit\": \"jest --testPathPattern=\\\\.test\\\\.ts$\",\n    \"test:integration\": \"jest --testPathPattern=\\\\.integration\\\\.ts$\",\n    \"test:e2e\": \"playwright test\",\n    \"test:watch\": \"jest --watch\",\n    \"test:coverage\": \"jest --coverage\",\n    \"test:ci\": \"jest --ci --coverage --maxWorkers=2\"\n  }\n}\n```\n\n### Test Performance in CI\n\n**Parallel execution**:\n```yaml\njobs:\n  test:\n    strategy:\n      matrix:\n        shard: [1, 2, 3, 4]\n    steps:\n      - run: npm test -- --shard=${{ matrix.shard }}/4\n```\n\n**Cache dependencies**:\n```yaml\n- uses: actions/cache@v3\n  with:\n    path: ~/.npm\n    key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}\n```\n\n## Test Organization\n\n### File Structure\n\n```\ntests/\n‚îú‚îÄ‚îÄ unit/                   # Fast, isolated tests\n‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user-service.test.ts\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ order-service.test.ts\n‚îÇ   ‚îî‚îÄ‚îÄ utils/\n‚îÇ       ‚îú‚îÄ‚îÄ validator.test.ts\n‚îÇ       ‚îî‚îÄ‚îÄ formatter.test.ts\n‚îú‚îÄ‚îÄ integration/            # Database, API tests\n‚îÇ   ‚îú‚îÄ‚îÄ api/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ users.integration.ts\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orders.integration.ts\n‚îÇ   ‚îî‚îÄ‚îÄ database/\n‚îÇ       ‚îî‚îÄ‚îÄ repository.integration.ts\n‚îú‚îÄ‚îÄ e2e/                   # End-to-end tests\n‚îÇ   ‚îú‚îÄ‚îÄ auth.spec.ts\n‚îÇ   ‚îú‚îÄ‚îÄ checkout.spec.ts\n‚îÇ   ‚îî‚îÄ‚îÄ profile.spec.ts\n‚îú‚îÄ‚îÄ fixtures/              # Test data\n‚îÇ   ‚îú‚îÄ‚îÄ users.ts\n‚îÇ   ‚îî‚îÄ‚îÄ products.ts\n‚îî‚îÄ‚îÄ helpers/               # Test utilities\n    ‚îú‚îÄ‚îÄ setup.ts\n    ‚îî‚îÄ‚îÄ factories.ts\n```\n\n### Test Naming Conventions\n\n```typescript\n// Pattern: describe('Component/Function', () => test('should...when...'))\n\ndescribe('UserService', () => {\n  describe('register', () => {\n    test('should create user when valid data provided', async () => {\n      // Test implementation\n    });\n\n    test('should throw error when email already exists', async () => {\n      // Test implementation\n    });\n\n    test('should hash password before saving', async () => {\n      // Test implementation\n    });\n  });\n\n  describe('login', () => {\n    test('should return token when credentials are valid', async () => {\n      // Test implementation\n    });\n\n    test('should throw error when password is incorrect', async () => {\n      // Test implementation\n    });\n  });\n});\n```\n\n## When to Use This Skill\n\nUse this skill when:\n- Setting up testing infrastructure\n- Writing unit, integration, or E2E tests\n- Implementing TDD methodology\n- Reviewing test coverage\n- Debugging flaky tests\n- Optimizing test performance\n- Configuring CI/CD pipelines\n- Establishing testing standards\n- Training team on testing practices\n- Improving code quality through testing\n\n---\n\n**Remember**: Good tests give you confidence to refactor, catch bugs early, and serve as living documentation. Invest in your test suite and it will pay dividends throughout the project lifecycle."
              }
            ]
          }
        ]
      }
    }
  ]
}