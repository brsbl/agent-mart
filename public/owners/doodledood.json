{
  "owner": {
    "id": "doodledood",
    "display_name": "doodledood",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/888717?v=4",
    "url": "https://github.com/doodledood",
    "bio": "aviramk.com",
    "stats": {
      "total_repos": 1,
      "total_plugins": 5,
      "total_commands": 0,
      "total_skills": 36,
      "total_stars": 8,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "doodledood/claude-code-plugins",
      "url": "https://github.com/doodledood/claude-code-plugins",
      "description": "A curated marketplace of Claude Code plugins for agentic development workflows, featuring tools for architecture, knowledge management, and development automation",
      "homepage": null,
      "signals": {
        "stars": 8,
        "forks": 0,
        "pushed_at": "2026-01-12T07:05:08Z",
        "created_at": "2025-11-20T15:25:14Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2676
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 489
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 11022
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7381
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 4874
        },
        {
          "path": "claude-plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/PLUGIN_TEMPLATE",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/PLUGIN_TEMPLATE/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/PLUGIN_TEMPLATE/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 410
        },
        {
          "path": "claude-plugins/PLUGIN_TEMPLATE/README.md",
          "type": "blob",
          "size": 1659
        },
        {
          "path": "claude-plugins/PLUGIN_TEMPLATE/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/PLUGIN_TEMPLATE/skills/example",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/PLUGIN_TEMPLATE/skills/example/SKILL.md",
          "type": "blob",
          "size": 778
        },
        {
          "path": "claude-plugins/README.md",
          "type": "blob",
          "size": 1953
        },
        {
          "path": "claude-plugins/consultant",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 596
        },
        {
          "path": "claude-plugins/consultant/MODEL_SELECTION_GUIDE.md",
          "type": "blob",
          "size": 7853
        },
        {
          "path": "claude-plugins/consultant/README.md",
          "type": "blob",
          "size": 1373
        },
        {
          "path": "claude-plugins/consultant/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/agents/consultant.md",
          "type": "blob",
          "size": 22158
        },
        {
          "path": "claude-plugins/consultant/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/analyze-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/analyze-code/SKILL.md",
          "type": "blob",
          "size": 3691
        },
        {
          "path": "claude-plugins/consultant/skills/ask-council",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/ask-council/SKILL.md",
          "type": "blob",
          "size": 493
        },
        {
          "path": "claude-plugins/consultant/skills/ask",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/ask/SKILL.md",
          "type": "blob",
          "size": 485
        },
        {
          "path": "claude-plugins/consultant/skills/consultant",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/SKILL.md",
          "type": "blob",
          "size": 12292
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/references/glob-patterns.md",
          "type": "blob",
          "size": 5002
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/__init__.py",
          "type": "blob",
          "size": 129
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/config.py",
          "type": "blob",
          "size": 1319
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/consultant_cli.py",
          "type": "blob",
          "size": 17208
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/file_handler.py",
          "type": "blob",
          "size": 10174
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/litellm_client.py",
          "type": "blob",
          "size": 8813
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/model_selector.py",
          "type": "blob",
          "size": 4584
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/pyproject.toml",
          "type": "blob",
          "size": 463
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/response_strategy.py",
          "type": "blob",
          "size": 23550
        },
        {
          "path": "claude-plugins/consultant/skills/consultant/scripts/session_manager.py",
          "type": "blob",
          "size": 9026
        },
        {
          "path": "claude-plugins/consultant/skills/investigate-bug",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/investigate-bug/SKILL.md",
          "type": "blob",
          "size": 884
        },
        {
          "path": "claude-plugins/consultant/skills/review",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/consultant/skills/review/SKILL.md",
          "type": "blob",
          "size": 4068
        },
        {
          "path": "claude-plugins/prompt-engineering",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/prompt-engineering/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/prompt-engineering/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 420
        },
        {
          "path": "claude-plugins/prompt-engineering/README.md",
          "type": "blob",
          "size": 936
        },
        {
          "path": "claude-plugins/prompt-engineering/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/prompt-engineering/agents/prompt-precision-verifier.md",
          "type": "blob",
          "size": 7213
        },
        {
          "path": "claude-plugins/prompt-engineering/agents/prompt-reviewer.md",
          "type": "blob",
          "size": 9618
        },
        {
          "path": "claude-plugins/prompt-engineering/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/prompt-engineering/skills/refine-prompt",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/prompt-engineering/skills/refine-prompt/SKILL.md",
          "type": "blob",
          "size": 9826
        },
        {
          "path": "claude-plugins/prompt-engineering/skills/review-prompt",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/prompt-engineering/skills/review-prompt/SKILL.md",
          "type": "blob",
          "size": 247
        },
        {
          "path": "claude-plugins/solo-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 651
        },
        {
          "path": "claude-plugins/solo-dev/README.md",
          "type": "blob",
          "size": 1401
        },
        {
          "path": "claude-plugins/solo-dev/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/agents/design-quality-auditor.md",
          "type": "blob",
          "size": 7011
        },
        {
          "path": "claude-plugins/solo-dev/agents/design-research.md",
          "type": "blob",
          "size": 6169
        },
        {
          "path": "claude-plugins/solo-dev/agents/seo-researcher.md",
          "type": "blob",
          "size": 7130
        },
        {
          "path": "claude-plugins/solo-dev/agents/ux-auditor.md",
          "type": "blob",
          "size": 5902
        },
        {
          "path": "claude-plugins/solo-dev/agents/voice-writer.md",
          "type": "blob",
          "size": 3647
        },
        {
          "path": "claude-plugins/solo-dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/audit-ux",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/audit-ux/SKILL.md",
          "type": "blob",
          "size": 260
        },
        {
          "path": "claude-plugins/solo-dev/skills/craft-author-voice",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/craft-author-voice/SKILL.md",
          "type": "blob",
          "size": 12263
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-brand-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-brand-guidelines/SKILL.md",
          "type": "blob",
          "size": 18478
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-customer-profile",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-customer-profile/SKILL.md",
          "type": "blob",
          "size": 29068
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-design-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-design-guidelines/SKILL.md",
          "type": "blob",
          "size": 16658
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-seo-strategy",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/define-seo-strategy/SKILL.md",
          "type": "blob",
          "size": 22464
        },
        {
          "path": "claude-plugins/solo-dev/skills/write-as-me",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/solo-dev/skills/write-as-me/SKILL.md",
          "type": "blob",
          "size": 256
        },
        {
          "path": "claude-plugins/vibe-extras",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 432
        },
        {
          "path": "claude-plugins/vibe-extras/README.md",
          "type": "blob",
          "size": 738
        },
        {
          "path": "claude-plugins/vibe-extras/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/agents/information-density-verifier.md",
          "type": "blob",
          "size": 8105
        },
        {
          "path": "claude-plugins/vibe-extras/agents/slop-cleaner.md",
          "type": "blob",
          "size": 5731
        },
        {
          "path": "claude-plugins/vibe-extras/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/skills/clean-slop",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/skills/clean-slop/SKILL.md",
          "type": "blob",
          "size": 213
        },
        {
          "path": "claude-plugins/vibe-extras/skills/maximize-info-density",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/skills/maximize-info-density/SKILL.md",
          "type": "blob",
          "size": 10030
        },
        {
          "path": "claude-plugins/vibe-extras/skills/rebase-on-main",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/skills/rebase-on-main/SKILL.md",
          "type": "blob",
          "size": 1382
        },
        {
          "path": "claude-plugins/vibe-extras/skills/rewrite-history",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/skills/rewrite-history/SKILL.md",
          "type": "blob",
          "size": 7631
        },
        {
          "path": "claude-plugins/vibe-extras/skills/update-claude-md",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-extras/skills/update-claude-md/SKILL.md",
          "type": "blob",
          "size": 1763
        },
        {
          "path": "claude-plugins/vibe-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 1869
        },
        {
          "path": "claude-plugins/vibe-workflow/README.md",
          "type": "blob",
          "size": 3350
        },
        {
          "path": "claude-plugins/vibe-workflow/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/bug-fixer.md",
          "type": "blob",
          "size": 3912
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/chunk-implementor.md",
          "type": "blob",
          "size": 9596
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/chunk-verifier.md",
          "type": "blob",
          "size": 14568
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/claude-md-adherence-reviewer.md",
          "type": "blob",
          "size": 9520
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/code-bugs-reviewer.md",
          "type": "blob",
          "size": 16104
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/code-coverage-reviewer.md",
          "type": "blob",
          "size": 11799
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/code-maintainability-reviewer.md",
          "type": "blob",
          "size": 21122
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/codebase-explorer.md",
          "type": "blob",
          "size": 23810
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/docs-reviewer.md",
          "type": "blob",
          "size": 9579
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/type-safety-reviewer.md",
          "type": "blob",
          "size": 18481
        },
        {
          "path": "claude-plugins/vibe-workflow/agents/web-researcher.md",
          "type": "blob",
          "size": 20554
        },
        {
          "path": "claude-plugins/vibe-workflow/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/hooks/hook_utils.py",
          "type": "blob",
          "size": 6551
        },
        {
          "path": "claude-plugins/vibe-workflow/hooks/post_compact_hook.py",
          "type": "blob",
          "size": 2171
        },
        {
          "path": "claude-plugins/vibe-workflow/hooks/post_todo_write_hook.py",
          "type": "blob",
          "size": 2358
        },
        {
          "path": "claude-plugins/vibe-workflow/hooks/pyproject.toml",
          "type": "blob",
          "size": 480
        },
        {
          "path": "claude-plugins/vibe-workflow/hooks/session_start_reminder.py",
          "type": "blob",
          "size": 498
        },
        {
          "path": "claude-plugins/vibe-workflow/hooks/stop_todo_enforcement.py",
          "type": "blob",
          "size": 1925
        },
        {
          "path": "claude-plugins/vibe-workflow/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/bugfix",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/bugfix/SKILL.md",
          "type": "blob",
          "size": 8151
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/explore-codebase",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/explore-codebase/SKILL.md",
          "type": "blob",
          "size": 13661
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/fix-review-issues",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/fix-review-issues/SKILL.md",
          "type": "blob",
          "size": 3778
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/implement-inplace",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/implement-inplace/SKILL.md",
          "type": "blob",
          "size": 8727
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/implement",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/implement/SKILL.md",
          "type": "blob",
          "size": 18432
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/plan",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/plan/SKILL.md",
          "type": "blob",
          "size": 22457
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/research-web",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/research-web/SKILL.md",
          "type": "blob",
          "size": 34303
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-bugs",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-bugs/SKILL.md",
          "type": "blob",
          "size": 309
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-claude-md-adherence",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-claude-md-adherence/SKILL.md",
          "type": "blob",
          "size": 340
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-coverage",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-coverage/SKILL.md",
          "type": "blob",
          "size": 326
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-docs/SKILL.md",
          "type": "blob",
          "size": 277
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-maintainability",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-maintainability/SKILL.md",
          "type": "blob",
          "size": 336
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-type-safety",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review-type-safety/SKILL.md",
          "type": "blob",
          "size": 329
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/review/SKILL.md",
          "type": "blob",
          "size": 5787
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/spec",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/spec/SKILL.md",
          "type": "blob",
          "size": 20155
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/web-research",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-plugins/vibe-workflow/skills/web-research/SKILL.md",
          "type": "blob",
          "size": 332
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/CUSTOMER.md",
          "type": "blob",
          "size": 5663
        },
        {
          "path": "docs/LLM_CODING_CAPABILITIES.md",
          "type": "blob",
          "size": 20276
        },
        {
          "path": "pyproject.toml",
          "type": "blob",
          "size": 1332
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/__init__.py",
          "type": "blob",
          "size": 16
        },
        {
          "path": "tests/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/hooks/__init__.py",
          "type": "blob",
          "size": 32
        },
        {
          "path": "tests/hooks/conftest.py",
          "type": "blob",
          "size": 5865
        },
        {
          "path": "tests/hooks/test_hook_utils.py",
          "type": "blob",
          "size": 15981
        },
        {
          "path": "tests/hooks/test_post_compact_hook.py",
          "type": "blob",
          "size": 18099
        },
        {
          "path": "tests/hooks/test_post_todo_write_hook.py",
          "type": "blob",
          "size": 19274
        },
        {
          "path": "tests/hooks/test_session_start_reminder.py",
          "type": "blob",
          "size": 4402
        },
        {
          "path": "tests/hooks/test_stop_todo_enforcement.py",
          "type": "blob",
          "size": 23361
        }
      ],
      "marketplace": {
        "name": "claude-code-plugins-marketplace",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "doodledood",
          "email": "doodledood@github.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "consultant",
            "description": "Flexible multi-provider LLM consultations using Python/LiteLLM - includes consultant agent, review/bug-investigation/execplan commands, and consultant skill for deep AI-powered code analysis across 100+ models with custom base URL support",
            "source": "./claude-plugins/consultant",
            "category": "development",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add doodledood/claude-code-plugins",
              "/plugin install consultant@claude-code-plugins-marketplace"
            ],
            "signals": {
              "stars": 8,
              "forks": 0,
              "pushed_at": "2026-01-12T07:05:08Z",
              "created_at": "2025-11-20T15:25:14Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "analyze-code",
                "description": "Deep code analysis using consultant agent. Identifies technical debt, risks, and improvement opportunities.",
                "path": "claude-plugins/consultant/skills/analyze-code/SKILL.md",
                "frontmatter": {
                  "name": "analyze-code",
                  "description": "Deep code analysis using consultant agent. Identifies technical debt, risks, and improvement opportunities."
                },
                "content": "Analyze code: $ARGUMENTS\n\n---\n\nUse the Task tool with `subagent_type='consultant:consultant'`. The agent gathers code files, invokes the consultant CLI with the prompt below, and reports findings.\n\n# Consultant Prompt\n\nYou are an expert code analyst. Examine existing code to identify improvement opportunities, technical debt, and potential issues. Provide actionable recommendations prioritized by impact.\n\n## Core Principles (P1-P10)\n\n| # | Principle |\n|---|-----------|\n| **P1** | **Correctness Above All** - Working code > elegant code |\n| **P2** | **Diagnostics & Observability** - Errors must be visible, logged, traceable |\n| **P3** | **Make Illegal States Unrepresentable** - Types prevent bugs at compile-time |\n| **P4** | **Single Responsibility** - One job per unit |\n| **P5** | **Explicit Over Implicit** - Clarity beats cleverness |\n| **P6** | **Minimal Surface Area** - YAGNI |\n| **P7** | **Prove It With Tests** - Untested = unverified |\n| **P8** | **Safe Evolution** - Public API changes need migration paths |\n| **P9** | **Fault Containment** - One bad input shouldn't crash the system |\n| **P10** | **Comments Tell Why** - Not mechanics |\n\n## Analysis Categories (Priority Order)\n\n1. **Latent Bugs & Logic Risks** (P1) - Boundary conditions, state management, async hazards\n2. **Type Safety & Invariant Gaps** (P3) - Illegal states, primitive obsession, unvalidated boundaries\n3. **Observability & Diagnostics Gaps** (P2) - Silent failures, broad catches, logging gaps\n4. **Resilience & Fault Tolerance** (P9) - Timeouts, retries, resource leaks, transaction gaps\n5. **Clarity & Explicitness Issues** (P5) - Naming, magic values, hidden dependencies\n6. **Modularity & Cohesion Issues** (P4, P6) - God functions, over-engineering, tight coupling\n7. **Test Quality & Coverage Gaps** (P7) - Critical path gaps, boundary tests, flaky tests\n8. **Documentation Issues** (P10) - Stale comments, missing \"why\", TODO graveyard\n9. **Evolution & Maintainability Risks** (P8) - API evolution risks, schema rigidity\n10. **Security & Performance** - Auth gaps, injection risks, N+1 queries (escalate only if causes data loss/downtime)\n\n## Priority Levels\n\n- **CRITICAL**: Latent bug likely to cause production incident, data corruption risk â†’ Address immediately\n- **HIGH**: Bug waiting to happen, missing critical test coverage â†’ Address in current sprint\n- **MEDIUM**: Technical debt accumulating, maintainability degrading â†’ Plan for upcoming work\n- **LOW**: Minor improvements, performance optimizations â†’ Address opportunistically\n- **INFO**: Observations, positive patterns worth noting â†’ No action needed\n\n## Output Format\n\n```markdown\n## Executive Summary\n[2-3 sentences: overall health assessment and key risk areas]\n\n## Health Scores\n\n| Category | Score | Notes |\n|----------|-------|-------|\n| Correctness Risk | X/10 | [Brief assessment] |\n| Type Safety | X/10 | [Brief assessment] |\n| Observability | X/10 | [Brief assessment] |\n| Test Coverage | X/10 | [Brief assessment] |\n| Maintainability | X/10 | [Brief assessment] |\n\n## Recommendations by Priority\n\n### CRITICAL / HIGH / MEDIUM / LOW\n- **[Category]** `file.ts:123`\n  - **Issue**: [What's the risk]\n  - **Impact**: [Why it matters]\n  - **Recommendation**: [Specific improvement]\n\n## Technical Debt Inventory\n[Items with effort estimates: S/M/L/XL]\n\n## Quick Wins\n[High impact, low effort improvements]\n\n## Strengths\n[What's done well - preserve good patterns]\n```\n\nWithout specific targets, analyze most critical code paths in the current working directory."
              },
              {
                "name": "ask-council",
                "description": "Multi-model ensemble consultation. Runs 3 models in parallel for diverse perspectives.",
                "path": "claude-plugins/consultant/skills/ask-council/SKILL.md",
                "frontmatter": {
                  "name": "ask-council",
                  "description": "Multi-model ensemble consultation. Runs 3 models in parallel for diverse perspectives."
                },
                "content": "Consult multiple models in parallel about: $ARGUMENTS\n\n---\n\nUse the Task tool with `subagent_type='consultant:consultant'`. Specify multi-model consultation.\n\n**Default models** (use all 3 unless user specifies otherwise):\n- `gpt-5.2-pro`\n- `gemini/gemini-3-pro-preview`\n- `claude-opus-4-5-20251101`\n\nThe agent handles parallel execution, polling, and output relay."
              },
              {
                "name": "ask",
                "description": "Single-model consultation using consultant agent. Defaults to gpt-5.2-pro.",
                "path": "claude-plugins/consultant/skills/ask/SKILL.md",
                "frontmatter": {
                  "name": "ask",
                  "description": "Single-model consultation using consultant agent. Defaults to gpt-5.2-pro."
                },
                "content": "Consult an external model about: $ARGUMENTS\n\n---\n\nUse the Task tool with `subagent_type='consultant:consultant'`. Pass the question/topic above as the consultant prompt.\n\n**Defaults**:\n- Model: `gpt-5.2-pro` (unless user specifies another, e.g., \"use claude-opus-4-5-20251101 to...\")\n- Single-model mode\n\nThe agent handles context gathering, CLI invocation, and response relay."
              },
              {
                "name": "consultant",
                "description": "Consults external AI models (100+ via LiteLLM) for complex analysis. Use for architectural review, security audit, deep code understanding, or when extended reasoning is needed. Runs async with session management.",
                "path": "claude-plugins/consultant/skills/consultant/SKILL.md",
                "frontmatter": {
                  "name": "consultant",
                  "description": "Consults external AI models (100+ via LiteLLM) for complex analysis. Use for architectural review, security audit, deep code understanding, or when extended reasoning is needed. Runs async with session management."
                },
                "content": "# Consultant\n\n## Overview\n\nConsultant is a Python-based tool using LiteLLM to provide access to powerful AI models for complex analysis tasks. It accepts file globs and prompts, runs asynchronously, and returns detailed insights after extended reasoning time.\n\n**Key advantages:**\n\n- Supports 100+ LLM providers through LiteLLM (OpenAI, Anthropic, Google, Azure, local models, etc.)\n- Custom base URLs for any provider or local LLM server\n- Automatic model discovery and selection\n- Async operation with session management\n- Token counting and context overflow protection\n- Cross-platform Python implementation\n\n## Requirements\n\nThe CLI uses [uvx](https://docs.astral.sh/uv/guides/tools/) for automatic dependency management. Dependencies (litellm, requests) are installed automatically on first run via PEP 723 inline script metadata - no explicit installation needed.\n\nIf `uv` is not installed:\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n## Getting Started\n\n**IMPORTANT: Always run `uvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli --help` first to understand current capabilities.**\n\nWhere `{CONSULTANT_SCRIPTS_PATH}` is the path to `claude-plugins/consultant/skills/consultant/scripts/`\n\n## Basic Usage\n\n### Start a Consultation\n\nThe consultant script runs synchronously (blocking until completion). For long-running analyses, you should run it in the background using the Bash tool with `run_in_background: true`, then use BashOutput to check progress every 30 seconds until completion.\n\n**Example: Running in background via Bash tool**\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Analyze this code for security vulnerabilities\" \\\n  --file src/**/*.py \\\n  --slug \"security-audit\"\n```\n\nWhen calling via the Bash tool:\n1. Use `run_in_background: true` parameter\n2. Wait at least 30 seconds, then use BashOutput tool with the returned bash_id to check progress\n3. If still running, wait another 30 seconds and check again - repeat until completion\n4. The script will print output as it completes each step\n5. Final results appear after \"Waiting for completion...\" message\n\n**What you'll see:**\n- Token usage summary\n- Session ID\n- \"Waiting for completion...\" status\n- Streaming output from the LLM\n- Final results after completion\n\n### Check Session Status\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli session security-audit\n```\n\nThis returns JSON with:\n- Current status (running/completed/error)\n- Full output if completed\n- Error details if failed\n\n### List All Sessions\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli list\n```\n\nShows all sessions with status, timestamps, and models used.\n\n## Advanced Features\n\n### Custom Provider with Base URL\n\n```bash\n# Use custom LiteLLM endpoint\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Review this PR\" \\\n  --file src/**/*.ts \\\n  --slug \"pr-review\" \\\n  --base-url \"http://localhost:8000\" \\\n  --model \"gpt-5.2\"\n```\n\n### List Available Models\n\n#### From Custom Provider (with Base URL)\n\nQuery models from a custom LiteLLM endpoint:\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli models \\\n  --base-url \"http://localhost:8000\"\n```\n\n**What happens:**\n- Sends HTTP GET to `http://localhost:8000/v1/models`\n- Parses JSON response with model list\n- Returns all available models from that endpoint\n- Example output:\n  ```json\n  [\n    {\"id\": \"gpt-5.2\", \"created\": 1234567890, \"owned_by\": \"openai\"},\n    {\"id\": \"claude-opus-4-5\", \"created\": 1234567890, \"owned_by\": \"anthropic\"}\n  ]\n  ```\n\n#### From Known Providers (without Base URL)\n\nQuery known models from major providers:\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli models\n```\n\n**What happens:**\n- Returns hardcoded list of known models (no API call)\n- Includes models from OpenAI, Anthropic, Google\n- Example output:\n  ```json\n  [\n    {\"id\": \"gpt-5.2\", \"provider\": \"openai\"},\n    {\"id\": \"claude-opus-4-5\", \"provider\": \"anthropic\"},\n    {\"id\": \"gemini/gemini-2.5-flash\", \"provider\": \"google\"}\n  ]\n  ```\n\n### Automatic Model Selection\n\n#### Scenario 1: With Base URL (custom provider)\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Architectural review\" \\\n  --file \"**/*.py\" \\\n  --slug \"arch-review\" \\\n  --base-url \"http://localhost:8000\"\n  # No --model flag\n```\n\n**Consultant will:**\n1. Query `http://localhost:8000/v1/models` to get available models\n2. Select a model based on the task requirements\n\n**For model selection guidance:** Check https://artificialanalysis.ai for up-to-date model benchmarks and rankings to choose the best model for your use case.\n\n#### Scenario 2: Without Base URL (default providers)\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Code review\" \\\n  --file src/*.py \\\n  --slug \"review\"\n  # No --model flag, no --base-url flag\n```\n\n**Consultant will:**\n1. Use known models list (OpenAI, Anthropic, Google)\n2. Select a model based on task requirements\n\n**For model selection guidance:** Check https://artificialanalysis.ai for up-to-date model benchmarks and rankings. Recommended defaults: `gpt-5.2-pro`, `claude-opus-4-5-20251101`, `gemini/gemini-3-pro-preview`.\n\n#### Scenario 3: Explicit Model (no auto-selection)\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Bug analysis\" \\\n  --file src/*.py \\\n  --slug \"bug\" \\\n  --model \"gpt-5.2\"\n```\n\n**Consultant will:**\n1. Skip model querying and scoring\n2. Use `gpt-5.2` directly\n3. Use default provider for GPT-5 (OpenAI)\n4. No \"Selected model\" message\n\n### Specify API Key\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"...\" \\\n  --file ... \\\n  --slug \"...\" \\\n  --api-key \"your-api-key\"\n```\n\nOr use environment variables (see below).\n\n## Environment Variables\n\nConsultant checks these environment variables:\n\n**API Keys (checked in order):**\n- `LITELLM_API_KEY`: Generic LiteLLM API key\n- `OPENAI_API_KEY`: For OpenAI models\n- `ANTHROPIC_API_KEY`: For Claude models\n\n**Base URL:**\n- `OPENAI_BASE_URL`: Default base URL (used if --base-url not provided)\n\nExample:\n\n```bash\n# Set API key\nexport LITELLM_API_KEY=\"your-key-here\"\n\n# Optional: Set default base URL\nexport OPENAI_BASE_URL=\"http://localhost:8000\"\n\n# Now consultant will use the base URL automatically\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli --prompt \"...\" --file ... --slug \"...\"\n```\n\n## When to Use Consultant\n\n**Perfect for:**\n\n- Complex architectural decisions requiring deep analysis\n- Security vulnerability analysis across large codebases\n- Comprehensive code reviews before production deployment\n- Understanding intricate patterns or relationships in unfamiliar code\n- Expert-level domain analysis (e.g., distributed systems, concurrency)\n\n**Don't use consultant for:**\n\n- Simple code edits or fixes you can handle directly\n- Questions answerable by reading 1-2 files\n- Tasks requiring immediate responses (consultant takes minutes)\n- Repetitive operations better suited to scripts\n\n## Session Management\n\n### Session Storage\n\nSessions are stored in `~/.consultant/sessions/{session-id}/` with:\n\n- `metadata.json`: Status, timestamps, token counts, model info\n- `prompt.txt`: Original user prompt\n- `output.txt`: Streaming response (grows during execution)\n- `error.txt`: Error details (if failed)\n- `file_*`: Copies of all attached files\n\n### Reattachment\n\nQuery status anytime:\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli session <slug>\n```\n\nThe most recent session with that slug will be returned.\n\n### Cleanup\n\nSessions persist until manually deleted:\n\n```bash\nrm -rf ~/.consultant/sessions/{session-id}\n```\n\n## Token Management\n\nConsultant automatically:\n\n1. Counts tokens for prompt and each file\n2. Validates against model's context size\n3. Reserves 20% of context for response\n4. Fails fast with clear errors if over limit\n\nExample output:\n\n```\nðŸ“Š Token Usage:\n- Prompt: 1,234 tokens\n- Files: 45,678 tokens (15 files)\n- Total: 46,912 tokens\n- Limit: 128,000 tokens\n- Available: 102,400 tokens (80%)\n```\n\nIf context exceeded:\n\n```\nERROR: Input exceeds context limit!\n  Input: 150,000 tokens\n  Limit: 128,000 tokens\n  Overage: 22,000 tokens\n\nSuggestions:\n1. Reduce number of files (currently 25)\n2. Use a model with larger context\n3. Shorten the prompt\n```\n\n## Model Selection\n\n### Automatic Selection Algorithm\n\nWhen no model is specified, consultant:\n\n1. Queries available models from provider (via `/v1/models` or known list)\n2. Scores each model based on:\n   - Version number (GPT-5 > GPT-4 > GPT-3.5)\n   - Capability tier (opus/pro > sonnet > haiku)\n   - Context size (200k > 128k > 32k)\n   - Reasoning capability (o1/o3 models higher)\n3. Selects the highest-scoring model\n\n### Supported Providers\n\nThrough LiteLLM, consultant supports:\n\n- OpenAI (GPT-4, GPT-5, o1, etc.)\n- Anthropic (Claude Sonnet 4, Opus 4, etc.)\n- Google (Gemini 3, 2.5, etc.)\n- Azure OpenAI\n- AWS Bedrock\n- Cohere\n- HuggingFace\n- Local models (Ollama, vLLM, LM Studio, etc.)\n- Any OpenAI-compatible API\n\n## Error Handling\n\nConsultant provides clear error messages for common issues:\n\n### Missing API Key\n\n```\nERROR: No API key provided.\nSet LITELLM_API_KEY environment variable or use --api-key flag.\n```\n\n### Context Limit Exceeded\n\n```\nERROR: Input exceeds context limit!\n[Details and suggestions]\n```\n\n### Model Not Found\n\n```\nERROR: Model 'gpt-7' not found at base URL\nAvailable models: [list]\n```\n\n### Network Failure\n\n```\nWARNING: Network error connecting to http://localhost:8000\nRetrying in 5 seconds... (attempt 2/3)\n```\n\n## Troubleshooting\n\n**Issue**: `uvx: command not found`\n\n**Solution**:\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n**Issue**: `ImportError: No module named 'litellm'`\n\n**Solution**: This shouldn't happen with `uvx`, but if it does, clear uv cache:\n```bash\nuv cache clean\n```\n\n**Issue**: Session stuck in \"running\" status\n\n**Solution**:\n- Check session directory: `ls ~/.consultant/sessions/{session-id}/`\n- Look for `error.txt`: `cat ~/.consultant/sessions/{session-id}/error.txt`\n- Check process is running: `ps aux | grep consultant_cli.py`\n\n**Issue**: Context limit exceeded\n\n**Solution**:\n1. Reduce number of files attached\n2. Use a model with larger context (e.g., claude-3-opus has 200k)\n3. Shorten the prompt\n4. Split into multiple consultations\n\n**Issue**: Model discovery fails\n\n**Solution**:\n- Explicitly specify a model with `--model`\n- Check base URL is correct: `curl http://localhost:8000/v1/models`\n- Verify API key is set correctly\n\n## Examples\n\n### Security Audit\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Identify SQL injection vulnerabilities in the authentication module. For each finding, provide: vulnerable code location, attack vector, and recommended fix.\" \\\n  --file \"apps/*/src/**/*.{service,controller}.ts\" \\\n  --slug \"security-audit\" \\\n  --model \"claude-opus-4-5\"\n```\n\n### Architectural Review\n\n```bash\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Identify the top 5 highest-impact architectural issues causing tight coupling. For each: explain the problem, show affected components, and recommend a solution.\" \\\n  --file \"apps/*/src/**/*.ts\" \\\n  --slug \"arch-review\"\n```\n\n### PR Review\n\n```bash\n# Generate diff first\ngit diff origin/main...HEAD > /tmp/pr-diff.txt\n\nuvx --from {CONSULTANT_SCRIPTS_PATH} consultant-cli \\\n  --prompt \"Review this PR for production deployment. Flag blockers, high-risk changes, and suggest regression tests.\" \\\n  --file /tmp/pr-diff.txt \\\n  --slug \"pr-review\"\n```\n\n## Integration with Consultant Agent\n\nThe consultant agent uses this Python CLI automatically. When you invoke:\n\n- `/consultant-review`\n- `/consultant-investigate-bug`\n- `/consultant-execplan`\n\nThe agent constructs the appropriate consultant_cli.py command with all necessary files and prompt.\n\n## Resources\n\n- [LiteLLM Documentation](https://docs.litellm.ai/)\n- [Supported Models](https://docs.litellm.ai/docs/providers)\n- [Consultant Plugin README](../../README.md)\n- [Glob Patterns Guide](./references/glob-patterns.md)"
              },
              {
                "name": "investigate-bug",
                "description": "Deep bug investigation using consultant agent. Identifies root causes and fix suggestions.",
                "path": "claude-plugins/consultant/skills/investigate-bug/SKILL.md",
                "frontmatter": {
                  "name": "investigate-bug",
                  "description": "Deep bug investigation using consultant agent. Identifies root causes and fix suggestions."
                },
                "content": "Investigate bug: $ARGUMENTS\n\n---\n\nUse the Task tool with `subagent_type='consultant:consultant'`. The agent gathers symptoms, invokes the consultant CLI, and reports root cause analysis.\n\n**Investigation focus**:\n1. **Root cause**: What's actually broken and why\n2. **Execution flow**: Path from trigger to failure\n3. **State analysis**: Invalid states, race conditions, timing issues\n4. **Data validation**: Input validation gaps, edge cases\n5. **Error handling**: Missing handlers, improper recovery\n\n**Severity levels**:\n- **CRITICAL**: Production down, data corruption, widespread impact\n- **HIGH**: Core functionality broken, major user impact\n- **MEDIUM**: Feature partially broken, workaround available\n- **LOW**: Minor issue, limited impact"
              },
              {
                "name": "review",
                "description": "Production-level PR review using consultant agent. 10-category framework focused on correctness.",
                "path": "claude-plugins/consultant/skills/review/SKILL.md",
                "frontmatter": {
                  "name": "review",
                  "description": "Production-level PR review using consultant agent. 10-category framework focused on correctness."
                },
                "content": "Review code: $ARGUMENTS\n\n---\n\nUse the Task tool with `subagent_type='consultant:consultant'`. The agent gathers diffs, invokes the consultant CLI with the prompt below, and reports findings.\n\n# Consultant Prompt\n\nYou are an expert code reviewer. Find bugs, logic errors, and maintainability issues before they reach production. Prioritize correctness and code clarity.\n\n## Core Principles (P1-P10)\n\n| # | Principle |\n|---|-----------|\n| **P1** | **Correctness Above All** - Working code > elegant code |\n| **P2** | **Diagnostics & Observability** - Errors must be visible, logged, traceable |\n| **P3** | **Make Illegal States Unrepresentable** - Types prevent bugs at compile-time |\n| **P4** | **Single Responsibility** - One job per unit |\n| **P5** | **Explicit Over Implicit** - Clarity beats cleverness |\n| **P6** | **Minimal Surface Area** - YAGNI |\n| **P7** | **Prove It With Tests** - Untested = unverified |\n| **P8** | **Safe Evolution** - Public API changes need migration paths |\n| **P9** | **Fault Containment** - One bad input shouldn't crash the system |\n| **P10** | **Comments Tell Why** - Not mechanics |\n\n## Review Categories (Priority Order)\n\n1. **Correctness & Logic** (P1) - Logic errors, boundary conditions, state management, async bugs\n2. **Type Safety & Invariants** (P3) - Illegal states, nullability, validation at boundaries\n3. **Diagnostics & Observability** (P2) - Silent failures, broad catches, logging gaps\n4. **Fault Semantics** (P9) - Timeouts, retries, resource cleanup, transaction integrity\n5. **Design Clarity** (P5) - Naming, predictable APIs, magic values, hidden dependencies\n6. **Modularity** (P4, P6) - Single responsibility, god functions, over-engineering\n7. **Test Quality** (P7) - Critical path coverage, boundary tests, assertion quality\n8. **Comment Correctness** (P10) - Stale comments, missing \"why\", redundant docs\n9. **Data & API Evolution** (P8) - Backward compatibility, schema migrations, rollback plans\n10. **Security & Performance** - Auth, injection, N+1 (escalate only if causes data loss/downtime)\n\n## Depth Scaling\n\n| PR Size | Focus |\n|---------|-------|\n| **Small** (<50 lines) | Categories 1-3 only |\n| **Medium** (50-300 lines) | Categories 1-6, scan 7-10 |\n| **Large** (300+ lines) | Full framework, prioritize blockers |\n\n## Severity Levels\n\n- **BLOCKER**: Logic bug causing wrong outcomes, data corruption, silent critical failure â†’ MUST fix\n- **HIGH**: Bug that will manifest in prod, missing critical test â†’ SHOULD fix\n- **MEDIUM**: Over-engineering, stale comments, edge case gaps â†’ Fix soon\n- **LOW**: Minor simplification, style â†’ Nice-to-have\n- **INFO**: Observations, positive patterns â†’ FYI\n\n## Output Format\n\n```markdown\n## Summary\n[1-2 sentences: overall assessment and risk level]\n\n## Findings by Severity\n\n### BLOCKER\n- **[Category]** `file.ts:123`\n  - **Issue**: [What's wrong]\n  - **Impact**: [Why it matters]\n  - **Fix**: [Specific recommendation]\n\n### HIGH\n[Same format...]\n\n### MEDIUM\n[Same format...]\n\n### LOW\n[Same format...]\n\n### INFO\n[Same format...]\n\n## Findings by Review Category\n\n### 1. Correctness & Logic\n[List all findings in this category with severity tags]\n\n### 2. Type Safety & Invariants\n[List all findings...]\n\n### 3. Diagnostics & Observability\n[List all findings...]\n\n### 4. Fault Semantics\n[List all findings...]\n\n### 5. Design Clarity\n[List all findings...]\n\n### 6. Modularity\n[List all findings...]\n\n### 7. Test Quality\n[List all findings...]\n\n### 8. Comment Correctness\n[List all findings...]\n\n### 9. Data & API Evolution\n[List all findings...]\n\n### 10. Security & Performance\n[List all findings...]\n\n## What to Tackle Now\n[Prioritized action items - max 5 concrete tasks ordered by impact. Focus on blockers/high severity first, then quick wins. Include file:line references.]\n\n## Positive Observations\n[What's done well]\n```\n\nExpress confidence: >90% state directly, 70-90% qualify with reasoning, <70% note as INFO."
              }
            ]
          },
          {
            "name": "prompt-engineering",
            "description": "Tools for crafting, refining, and improving LLM prompts - includes update-prompt command for balanced prompt optimization that avoids overfitting",
            "source": "./claude-plugins/prompt-engineering",
            "category": "development",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add doodledood/claude-code-plugins",
              "/plugin install prompt-engineering@claude-code-plugins-marketplace"
            ],
            "signals": {
              "stars": 8,
              "forks": 0,
              "pushed_at": "2026-01-12T07:05:08Z",
              "created_at": "2025-11-20T15:25:14Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "refine-prompt",
                "description": "Iteratively refines prompts for precision - eliminates ambiguities, resolves conflicts, adds missing definitions. Use when asked to improve, tighten, clarify, make precise, or refine a prompt.",
                "path": "claude-plugins/prompt-engineering/skills/refine-prompt/SKILL.md",
                "frontmatter": {
                  "name": "refine-prompt",
                  "description": "Iteratively refines prompts for precision - eliminates ambiguities, resolves conflicts, adds missing definitions. Use when asked to improve, tighten, clarify, make precise, or refine a prompt."
                },
                "content": "# Refine Prompt\n\nIteratively improve prompt precision through analysis and verification loops. Primary goal: ensure prompt cannot be interpreted in ways the author doesn't expect.\n\n## Overview\n\nThis command transforms ambiguous prompts into precise ones through:\n1. **Analysis** - Identify precision issues (ambiguities, conflicts, undefined terms, underspecified rules)\n2. **Refinement** - Apply targeted fixes (infer from context when possible, ask user when not)\n3. **Verification** - `prompt-precision-verifier` agent checks for remaining issues\n4. **Iteration** - If issues found, refine again (max 5x)\n5. **Output** - Atomic replacement only after verification passes\n\n**Loop**: Read â†’ Refine â†’ Verify â†’ (Iterate if issues) â†’ Output\n\n## Workflow\n\n### Phase 0: Create Todo List (TodoWrite immediately)\n\nCreate todos tracking workflow phases. List reflects areas of work, not fixed steps.\n\n**Starter todos**:\n```\n- [ ] Input validation\n- [ ] Initial analysis\n- [ ] Refinement iteration 1\n- [ ] (expand if verification fails: iteration 2, 3...)\n- [ ] Output refined prompt\n```\n\n### Phase 1: Input Validation\n\n**Mark \"Input validation\" todo `in_progress`.**\n\n**Step 1.1: Parse arguments**\n\nExtract input from `$ARGUMENTS`. Determine if file path or inline prompt.\n\n**Step 1.2: Handle input type**\n\n| Input Type | Detection | Action |\n|------------|-----------|--------|\n| File path | Starts with `/`, `./`, `~`, or ends with `.md`, `.txt`, `.yaml` | Read file content |\n| Inline prompt | Everything else | Write to `/tmp/prompt-{timestamp}.md` |\n\n**Step 1.3: Validate content**\n\n- If file path: Check file exists using Read tool\n- If inline: Write to temp file, note original was inline\n- Error if no input provided: \"Usage: /refine-prompt <file-path> OR /refine-prompt <inline prompt text>\"\n\n**Step 1.4: Store metadata**\n\n- `original_path`: Source file path (or temp path for inline)\n- `is_inline`: Boolean (affects output messaging)\n- `original_content`: Full prompt text\n- `working_path`: `/tmp/refined-{timestamp}.md` for iterations\n\n**Mark \"Input validation\" todo `completed`.**\n\n### Phase 2: Initial Analysis\n\n**Mark \"Initial analysis\" todo `in_progress`.**\n\nRead the prompt and understand:\n1. **Purpose**: What is this prompt trying to accomplish?\n2. **Structure**: How is it organized? (sections, rules, examples)\n3. **Obvious issues**: Any immediately visible ambiguities or conflicts?\n\nDocument findings briefly - this informs refinement strategy.\n\n**Mark \"Initial analysis\" todo `completed`.**\n\n### Phase 3: Refinement Loop\n\n**Mark \"Refinement iteration 1\" todo `in_progress`.**\n\n```\niteration = 1\nmax_iterations = 5\n\nwhile iteration <= max_iterations:\n    1. Apply precision fixes to current content\n       - For each issue, use Resolution Strategy (see below)\n       - Write refined version to working_path\n\n    2. Launch prompt-precision-verifier agent via Task tool:\n       - subagent_type: \"prompt-engineering:prompt-precision-verifier\"\n       - prompt: \"Verify prompt precision.\n         File: {working_path}\n\n         Check for ambiguities, conflicts, undefined terms, underspecified rules,\n         vague thresholds, priority confusion, edge case gaps, and implicit expectations.\n         Report VERIFIED or ISSUES_FOUND with specific details.\"\n\n    3. Parse agent response:\n       - If \"VERIFIED\" â†’ mark current todo `completed`, exit loop, proceed to Phase 4\n       - If \"ISSUES_FOUND\" â†’ continue to step 4\n\n    4. If iteration < max_iterations:\n       - Mark current todo `completed`\n       - Add new todo: \"Refinement iteration {iteration+1}\" and mark `in_progress`\n       - Read the specific issues reported\n       - Apply Resolution Strategy to each issue\n       - iteration += 1\n\n    5. If iteration == max_iterations and still has issues:\n       - Mark todo `completed` with note about unresolved issues\n       - Proceed to Phase 4 with warning flag\n```\n\n### Resolution Strategy\n\nFor each issue found, follow this decision tree:\n\n```\nIssue detected\n    â”‚\n    â–¼\nCan resolution be INFERRED from prompt context?\n(purpose, goals, existing patterns, domain conventions)\n    â”‚\n    â”œâ”€ YES â†’ Apply inferred fix directly\n    â”‚        Examples:\n    â”‚        - \"Be concise\" in a CLI tool prompt â†’ infer \"under 100 words\"\n    â”‚        - Conflict between \"brief\" and \"thorough\" â†’ infer based on prompt's stated purpose\n    â”‚        - Undefined \"standard format\" â†’ infer from examples in prompt or domain norms\n    â”‚\n    â””â”€ NO â†’ Ask user via AskUserQuestion\n             (truly ambiguous, multiple valid interpretations, author intent unclear)\n```\n\n**Inference sources** (check in order):\n1. **Prompt purpose/mission** - What is this prompt trying to accomplish?\n2. **Existing patterns** - How does the prompt handle similar cases?\n3. **Domain conventions** - What's standard practice in this domain?\n4. **Sensible defaults** - What would a reasonable author likely intend?\n\n**When to ask the user**:\n\n| Ask When | Example |\n|----------|---------|\n| Multiple equally valid interpretations | \"Be helpful\" - could mean many things |\n| Conflict with no clear winner | Two rules that contradict, no priority hints |\n| Missing context only author knows | \"Use the standard format\" with no examples |\n| Business/preference decision | Opt-in vs opt-out default |\n\n**AskUserQuestion format**:\n\n```\nquestions: [\n  {\n    question: \"The prompt says '{ambiguous text}'. What did you intend?\",\n    header: \"Clarify: {brief topic}\",\n    options: [\n      { label: \"{interpretation A}\", description: \"{what this means}\" },\n      { label: \"{interpretation B}\", description: \"{what this means}\" },\n      { label: \"{interpretation C}\", description: \"{what this means}\" }\n    ],\n    multiSelect: false\n  }\n]\n```\n\n**Batch related questions** - If multiple issues need user input, ask up to 4 related questions in one AskUserQuestion call.\n\n**After user answers**: Apply their clarification to the prompt, then continue refinement loop.\n\n### Phase 4: Output\n\n**Mark \"Output refined prompt\" todo `in_progress`.**\n\n**Step 4.1: Apply changes**\n\nIf verification passed:\n```bash\n# For file input: replace original\nmv {working_path} {original_path}\n\n# For inline input: keep at working_path, report location\n```\n\n**Step 4.2: Display results**\n\nIf verification passed:\n```\nRefined: {path}\nIterations: {count}\nStatus: Precise and unambiguous\n\nChanges applied:\n- {summary of fixes}\n```\n\nIf verification failed after 5 iterations:\n```\nRefined with warnings: {path}\nIterations: 5\nStatus: Some issues may remain\n\nUnresolved issues:\n- {list from last verification}\n\nReview the changes manually.\n```\n\n**Mark \"Output refined prompt\" todo `completed`. Mark all todos complete.**\n\n## Refinement Techniques\n\nApply these techniques to fix precision issues:\n\n| Technique | Description | Before â†’ After |\n|-----------|-------------|----------------|\n| **Define terms** | Add explicit definition for vague terms | \"Be concise\" â†’ \"Keep responses under 150 words\" |\n| **Resolve conflict** | Add priority or rephrase to eliminate contradiction | \"Be brief\" + \"Be thorough\" â†’ \"Be thorough for complex queries, brief for simple ones\" |\n| **Add threshold** | Replace subjective judgment with objective criteria | \"When appropriate\" â†’ \"When the user explicitly asks\" |\n| **Handle edge case** | Add explicit behavior for corner cases | Add \"If both X and Y, prioritize X\" |\n| **Make explicit** | Surface implicit assumptions | Add \"Assumes user has basic familiarity with...\" |\n| **Add priority** | Clarify which rules take precedence | Add \"Rule A takes precedence over Rule B when...\" |\n| **Remove ambiguity** | Rephrase so only one interpretation possible | \"Use the tool\" â†’ \"Use the Read tool\" |\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| **Memento** | TodoWrite to track phases; expand todos on iteration |\n| **Infer first, ask second** | Try to resolve ambiguity from context before asking user |\n| **Preserve intent** | Don't change what prompt is trying to do; only how clearly it says it |\n| **Minimal changes** | Fix identified issues, don't rewrite unnecessarily |\n| **Minimal questions** | Only ask user when inference is truly impossible |\n| **Verification required** | Never output without verifier checking |\n| **Atomic output** | Original untouched until verification passes |\n\n## Edge Cases\n\n| Scenario | Handling |\n|----------|----------|\n| No input provided | Error: \"Usage: /refine-prompt <file-path> OR /refine-prompt <inline prompt text>\" |\n| File not found | Error: \"File not found: {path}\" |\n| Already precise | Report success: \"Prompt is already precise. No changes needed.\" |\n| Severely ambiguous | Make best effort over 5 iterations; output with warnings |\n| Very large prompt (>50KB) | Process as single unit |\n\n## Example Usage\n\n```bash\n# Refine a prompt file\n/refine-prompt prompts/code-reviewer.md\n\n# Refine inline prompt\n/refine-prompt You are a helpful assistant. Be concise but thorough. Use good judgment.\n\n# Refine a skill file\n/refine-prompt claude-plugins/my-plugin/skills/my-skill/SKILL.md\n```\n\n## Example Output\n\n```\nRefined: prompts/code-reviewer.md\nIterations: 2\nStatus: Precise and unambiguous\n\nChanges applied:\n- Defined \"significant issues\" as errors, security vulnerabilities, or logic bugs (inferred from code review context)\n- Resolved conflict between \"be thorough\" and \"keep it brief\" by specifying contexts (inferred from prompt purpose)\n- Added explicit behavior for empty input case (sensible default)\n- Clarified priority when multiple rules apply (asked user - chose \"security over style\")\n```"
              },
              {
                "name": "review-prompt",
                "description": "Review and analyze LLM prompts using the 10-Layer Architecture. Provides detailed assessment without modifying files.",
                "path": "claude-plugins/prompt-engineering/skills/review-prompt/SKILL.md",
                "frontmatter": {
                  "name": "review-prompt",
                  "description": "Review and analyze LLM prompts using the 10-Layer Architecture. Provides detailed assessment without modifying files.",
                  "context": "fork"
                },
                "content": "Use the prompt-reviewer agent to review the following prompt: $ARGUMENTS"
              }
            ]
          },
          {
            "name": "vibe-workflow",
            "description": "Vibe coding workflow - autonomous development agents for implementation, code review, test coverage auditing, bug fixing, and maintainability checks with quality gates",
            "source": "./claude-plugins/vibe-workflow",
            "category": "development",
            "version": "1.5.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add doodledood/claude-code-plugins",
              "/plugin install vibe-workflow@claude-code-plugins-marketplace"
            ],
            "signals": {
              "stars": 8,
              "forks": 0,
              "pushed_at": "2026-01-12T07:05:08Z",
              "created_at": "2025-11-20T15:25:14Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "bugfix",
                "description": "Investigates and fixes bugs systematically with root cause analysis. Use when asked to debug, troubleshoot, fix a bug, investigate an issue, or find why something is broken. Creates reproduction tests and verifies fixes.",
                "path": "claude-plugins/vibe-workflow/skills/bugfix/SKILL.md",
                "frontmatter": {
                  "name": "bugfix",
                  "description": "Investigates and fixes bugs systematically with root cause analysis. Use when asked to debug, troubleshoot, fix a bug, investigate an issue, or find why something is broken. Creates reproduction tests and verifies fixes."
                },
                "content": "**User request**: $ARGUMENTS\n\nInvestigate and fix bugs with systematic root cause analysis. Orchestrates the complete debugging workflow from understanding the problem to verifying the fix.\n\n> **Prerequisite**: Run in a git repository with a testable codebase.\n\n## Workflow\n\n**Loop**: Prerequisites â†’ Gather context â†’ Investigate/Fix â†’ Verify â†’ Report\n\nThis skill guides you through:\n0. **Prerequisite Check** - Verify git repo, gather project context\n1. **Bug Context Gathering** - Understand the bug through targeted questions (if not provided)\n2. **Investigation** - Launch bug-fixer agent for deep analysis and fix implementation\n3. **Verification Summary** - Report results and next steps\n\n## Workflow\n\n### Initial Setup (TodoWrite immediately)\n\n**Create todo list** - phases to complete.\n\n**Starter todos**:\n```\n- [ ] Prerequisite check (git, test config)\n- [ ] Bug context gathering (if needed)\n- [ ] Investigation and fix (bug-fixer agent)\n- [ ] Verification summary\n```\n\n### Phase 0: Prerequisite Check\n\n**Mark \"Prerequisite check\" todo `in_progress`.**\n\n**CRITICAL**: Before anything else, verify the environment:\n\n1. **Check for git repository**: Run `git rev-parse --is-inside-work-tree`\n2. **If NOT a git repo**: Warn the user:\n\n```\n\"Warning: This doesn't appear to be a git repository. The bugfix workflow works best in a git repo where changes can be tracked and reverted if needed. Proceed anyway?\"\n```\n\nUse AskUserQuestion:\n```\nheader: \"Not a Git Repository\"\nquestion: \"This directory isn't a git repository. The bugfix workflow works best with git for tracking changes. How would you like to proceed?\"\noptions:\n  - \"Continue anyway - I'll manage changes manually\"\n  - \"Stop - I'll initialize git first\"\n```\n\n3. **If git repo**: Check for uncommitted changes that might interfere:\n   - Run `git status --porcelain`\n   - If there are changes, note them but don't block (bugs often need fixing in dirty trees)\n\n4. **Gather project context**:\n   - Look for test configuration files (jest.config.*, pytest.ini, vitest.config.*, etc.)\n   - Identify the test command if possible (check package.json scripts, pyproject.toml, etc.)\n   - Note the project language/framework for context\n\n**Mark \"Prerequisite check\" todo `completed`.**\n\n### Phase 1: Bug Context Gathering\n\n**Mark \"Bug context gathering\" todo `in_progress`.**\n\n**If the user provided detailed bug information** (error message, reproduction steps, or clear description), skip directly to Phase 2.\n\n**If bug information is vague or missing**, use AskUserQuestion to gather essential context:\n\n**Question 1: Bug Type**\n\n```\nheader: \"Bug Type\"\nquestion: \"What type of bug are you experiencing?\"\noptions:\n  - \"Error/Exception - code crashes or throws an error\"\n  - \"Wrong behavior - code runs but does the wrong thing\"\n  - \"Performance - code is slow or uses too many resources\"\n  - \"UI/Visual - display issues or broken UI\"\n  - \"Data issue - incorrect data, missing data, or data corruption\"\n  - \"Integration - problem with external service or API\"\n```\n\n**Question 2: Reproduction Information**\n\n```\nheader: \"Reproduction\"\nquestion: \"Can you reproduce this bug?\"\noptions:\n  - \"Yes, consistently - it happens every time\"\n  - \"Yes, sometimes - it happens intermittently\"\n  - \"Not sure - I've only seen it once or twice\"\n  - \"No - it only happened in production/another environment\"\n```\n\n**Question 3: Error Details** (if type is Error/Exception)\n\n```\nheader: \"Error Details\"\nquestion: \"Do you have an error message or stack trace?\"\noptions:\n  - \"Yes - I'll paste it below\"\n  - \"No - no error message available\"\n  - \"Partial - I have some error info\"\nfreeText: true\nplaceholder: \"Paste the error message or stack trace here...\"\n```\n\n**Question 4: Location Hints**\n\n```\nheader: \"Location\"\nquestion: \"Do you know where in the codebase the bug might be?\"\noptions:\n  - \"Yes - I know the specific file(s)\"\n  - \"Somewhat - I know the general area\"\n  - \"No idea - I need help finding it\"\nfreeText: true\nplaceholder: \"If you know the location, describe it here (file names, function names, etc.)...\"\n```\n\n**Question 5: Recent Changes** (helpful for tracking root cause)\n\n```\nheader: \"Recent Changes\"\nquestion: \"Did this bug appear after recent changes?\"\noptions:\n  - \"Yes - it worked before, broke recently\"\n  - \"Unknown - not sure when it started\"\n  - \"No - it's been like this for a while\"\n  - \"New feature - this is new code that doesn't work\"\n```\n\n**Construct Bug Summary**:\nAfter gathering context, summarize:\n- Bug type and symptoms\n- Reproduction status\n- Error details (if any)\n- Location hints (if any)\n- Recent change context\n\n**Mark \"Bug context gathering\" todo `completed`.**\n\n### Phase 2: Investigation and Fix\n\n**Mark \"Investigation and fix\" todo `in_progress`.**\n\nLaunch the bug-fixer agent to perform the actual investigation and fix work.\n\n**Launch Bug-Fixer Agent:**\n\n```\nUse the bug-fixer agent to investigate and fix the bug.\n\nBug Summary:\n[Constructed from Phase 1 or user's original input]\n\nContext:\n- Project type: [detected language/framework]\n- Test command: [if discovered]\n- Working tree status: [clean/dirty]\n- Recent changes: [if provided]\n\nThe agent should:\n1. Deep investigation - explore codebase, form hypotheses\n2. Root cause analysis - trace through code paths\n3. Create reproduction test - prove understanding of the bug\n4. Implement fix - targeted fix addressing root cause\n5. Verify fix - ensure test passes, no regressions\n```\n\nThe bug-fixer agent will:\n1. Investigate the codebase thoroughly\n2. Form and test hypotheses about root cause\n3. Create a test that reproduces the bug\n4. Implement a fix\n5. Verify the fix works\n\n**IMPORTANT**: Let the agent work autonomously. Do not interrupt unless it asks for input or gets stuck.\n\n**Mark \"Investigation and fix\" todo `completed`.**\n\n### Phase 3: Verification Summary\n\n**Mark \"Verification summary\" todo `in_progress`.**\n\nAfter the bug-fixer agent completes, summarize the results:\n\n**If fix was successful:**\n```\nBug Fix Summary:\n- Root cause: [what was wrong]\n- Fix applied: [what was changed]\n- Test added: [test file and name]\n- Verification: [test results]\n\nRecommended next steps:\n1. Review the changes: `git diff`\n2. Run full test suite to check for regressions\n3. Commit when satisfied: `git add -A && git commit -m \"fix: [description]\"`\n```\n\n**If fix was not successful:**\n```\nInvestigation Summary:\n- What was tried: [approaches]\n- What was learned: [findings]\n- Blockers: [what prevented the fix]\n\nRecommended next steps:\n- [Specific suggestions based on findings]\n```\n\n**Mark \"Verification summary\" todo `completed`. Mark all todos complete.**\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| **Memento** | Use TodoWrite to track phases; mark progress immediately; visible state at all times |\n| **Systematic** | Form hypotheses before changes; test methodically; document findings |\n| **Test-driven** | Create reproduction test BEFORE fixing; test proves fix works; prevents regression |\n| **Root cause** | Fix underlying cause, not symptoms; consider why bug wasn't caught; look for patterns |\n| **Minimal changes** | Smallest fix for root cause; avoid refactoring while bug fixing; keep focused |\n| **Reduce cognitive load** | AskUserQuestion for clarification; reasonable defaults; don't repeat questions |\n\n## Edge Cases\n\n### Cannot Reproduce\nIf the bug cannot be reproduced:\n1. Document reproduction attempts\n2. Look for environmental differences\n3. Check logs for clues\n4. Consider adding diagnostic logging\n\n### Multiple Bugs\nIf investigation reveals multiple related bugs:\n1. Focus on fixing one at a time\n2. Document the others for follow-up\n3. Consider if there's a common root cause\n\n### Fix Breaks Other Things\nIf the fix causes test failures:\n1. Analyze if the tests are testing the wrong behavior\n2. Update tests if they were asserting buggy behavior\n3. Find an alternative fix if tests are correct"
              },
              {
                "name": "explore-codebase",
                "description": "Find all files relevant to a query with orthogonal exploration for comprehensive coverage. Returns topic-specific overview + file list with line ranges. Uses parallel agents for thorough+ levels to ensure nothing is missed.",
                "path": "claude-plugins/vibe-workflow/skills/explore-codebase/SKILL.md",
                "frontmatter": {
                  "name": "explore-codebase",
                  "description": "Find all files relevant to a query with orthogonal exploration for comprehensive coverage. Returns topic-specific overview + file list with line ranges. Uses parallel agents for thorough+ levels to ensure nothing is missed.",
                  "context": "fork"
                },
                "content": "**User request**: $ARGUMENTS\n\nOrchestrate codebase exploration agents to find all files relevant to a query, then synthesize into a unified reading list.\n\n**Loop**: Determine thoroughness â†’ [Quick/Medium: single agent â†’ return] | [Thorough+: Create orchestration file â†’ Decompose â†’ Launch Wave 1 â†’ Collect findings â†’ Cross-reference â†’ Evaluate gaps â†’ [Gap-fill if needed] â†’ Refresh context â†’ Synthesize â†’ Output]\n\n**Orchestration file** (thorough+ only): `/tmp/explore-orchestration-{topic-slug}-{YYYYMMDD-HHMMSS}.md`\n\n**You do NOT read source files** - you orchestrate agents and synthesize their findings into a unified reading list. The main agent reads the files after you return.\n\n---\n\n## Thoroughness Level\n\n**FIRST**: Determine thoroughness before exploring. Parse from natural language or auto-select.\n\n**Auto-selection**:\n- Single entity lookup (\"where is X?\") â†’ quick\n- Single bounded feature/bug â†’ medium\n- Multi-area feature, interaction queries â†’ thorough\n- \"comprehensive\"/\"all\"/\"architecture\"/\"audit\" â†’ very-thorough\n\n| Level | Exploration Strategy |\n|-------|---------------------|\n| **quick** | Single agent, no orchestration file, return agent output directly |\n| **medium** | Single agent, no orchestration file, return agent output directly |\n| **thorough** | Orchestration file, orthogonal agents (2-3), cross-reference, optional gap-fill |\n| **very-thorough** | Orchestration file, orthogonal agents (3-4), cross-reference, gap-fill wave |\n\n**Topic-slug format**: Extract 2-4 key terms, lowercase, replace spaces with hyphens. Example: \"authentication flow\" â†’ `authentication-flow`\n\nState: `**Thoroughness**: [level] â€” [reason]` then proceed.\n\n---\n\n## Quick / Medium Flow\n\n### 1. Launch single agent\n\n```\nTask(subagent_type: \"vibe-workflow:codebase-explorer\", prompt: \"$ARGUMENTS\")\n```\n\n### 2. Return agent output directly\n\nWhen agent returns, its output becomes your output. No synthesis needed.\n\n---\n\n## Thorough / Very-Thorough Flow\n\n### Phase 1: Initial Setup\n\n#### 1.1 Get timestamp & create todo list\n\nRun: `date +%Y%m%d-%H%M%S` â†’ for filename and timestamps\n\n**Starter todos** (seeds - list grows during decomposition):\n\n```\n- [ ] Create orchestration file\n- [ ] Topic decomposition & agent planning\n- [ ] Write decomposition to orchestration file\n- [ ] (expand: agent assignments added during decomposition)\n- [ ] Launch Wave 1 agents\n- [ ] Collect Agent 1 findings â†’ write to orchestration file\n- [ ] Collect Agent 2 findings â†’ write to orchestration file\n- [ ] (expand: more agent collection todos as needed)\n- [ ] Cross-reference findings â†’ write to orchestration file\n- [ ] Evaluate gaps â†’ write to orchestration file\n- [ ] (expand: if continuing - gap-fill todos)\n- [ ] Refresh context: read full orchestration file\n- [ ] Synthesize unified reading list\n```\n\n**Critical memento todos** (never skip):\n- `Write {X} to orchestration file` - after EACH agent completion\n- `Refresh context: read full orchestration file` - ALWAYS before synthesis\n\n#### 1.2 Create orchestration file\n\nPath: `/tmp/explore-orchestration-{topic-slug}-{YYYYMMDD-HHMMSS}.md`\n\n```markdown\n# Codebase Exploration Orchestration: {topic}\nTimestamp: {YYYYMMDD-HHMMSS}\nThoroughness: {level}\n\n## Exploration Query\n{Original query}\n\n## Topic Decomposition\n- Core topic: {main thing to find}\n- Angles to explore: (populated in Phase 2)\n- Expected agent count: {based on level}\n\n## Agent Assignments\n(populated in Phase 2)\n\n## Agent Status\n(updated as agents complete)\n\n## Collected Findings\n(populated as agents return - includes OVERVIEW and FILES TO READ from each)\n\n## Cross-Reference Analysis\n(populated after all agents return)\n\n## Gap Evaluation\n(populated after cross-reference)\n\n## Unified Reading List\n(populated in synthesis)\n```\n\n### Phase 2: Decompose & Assign\n\n#### 2.1 Decompose into orthogonal angles\n\n**Standard angles for codebase exploration:**\n\n| Angle | Focus | Example Scope |\n|-------|-------|---------------|\n| **Implementation** | Core logic files | \"Files that implement {topic} behavior\" |\n| **Usage** | Callers, integration points | \"Files that call/use {topic}\" |\n| **Tests** | Test files, fixtures | \"Test files for {topic}\" |\n| **Config** | Configuration, environment | \"Config files affecting {topic}\" |\n\n**Decomposition rules:**\n- thorough: 2-3 angles (usually Implementation + Usage + Tests)\n- very-thorough: 3-4 angles (all four)\n- Each angle gets explicit boundaries to prevent overlap\n\n**Orthogonality check**: Before assigning agents, verify no two angles would naturally search the same files.\n\n#### 2.2 Plan agent assignments with boundaries\n\n| Angle | Focus | Explicitly EXCLUDE |\n|-------|-------|-------------------|\n| Implementation | Core {topic} files | callers, tests, config |\n| Usage | Files that call {topic} | core implementation, tests, config |\n| Tests | Test files for {topic} | implementation, callers, config |\n| Config | Config affecting {topic} | implementation, callers, tests |\n\n#### 2.3 Expand todos for each agent\n\n```\n- [x] Topic decomposition & agent planning\n- [x] Write decomposition to orchestration file\n- [ ] Agent 1: Implementation angle\n- [ ] Agent 2: Usage angle\n- [ ] Agent 3: Tests angle\n- [ ] Launch Wave 1 agents (parallel)\n- [ ] Collect Agent 1 findings â†’ write to orchestration file\n- [ ] Collect Agent 2 findings â†’ write to orchestration file\n- [ ] Collect Agent 3 findings â†’ write to orchestration file\n- [ ] Cross-reference findings â†’ write to orchestration file\n...\n```\n\n#### 2.4 Update orchestration file\n\n```markdown\n## Topic Decomposition\n- Core topic: {topic}\n- Angles identified:\n  1. Implementation: {what this covers}\n  2. Usage: {what this covers}\n  3. Tests: {what this covers}\n\n## Agent Assignments\n| Agent | Angle | Prompt | Status |\n|-------|-------|--------|--------|\n| 1 | Implementation | \"{prompt}\" | Pending |\n| 2 | Usage | \"{prompt}\" | Pending |\n| 3 | Tests | \"{prompt}\" | Pending |\n```\n\n### Phase 3: Launch Parallel Agents\n\n#### 3.1 Launch agents in single message\n\nUse Task tool with `subagent_type: \"vibe-workflow:codebase-explorer\"` for each angle. **Launch all agents in parallel** (single message with multiple Task tool calls).\n\n**Agent prompt template:**\n```\n{Specific exploration focus for this angle}\n\nYOUR ASSIGNED SCOPE:\n- {what to explore}\n- {specific patterns or areas}\n\nDO NOT EXPLORE (other agents cover these):\n- {angles assigned to other agents}\n\nThoroughness within scope: medium\n```\n\n**Example for \"authentication\" query (thorough):**\n\nAgent 1 (Implementation):\n```\nFind core authentication implementation files.\n\nYOUR ASSIGNED SCOPE:\n- Auth service/module files\n- Token generation, validation logic\n- Session management implementation\n- Password hashing, credential verification\n\nDO NOT EXPLORE (other agents cover these):\n- Files that CALL auth (usage patterns)\n- Test files\n- Config files\n\nThoroughness within scope: medium\n```\n\nAgent 2 (Usage):\n```\nFind files that use/call authentication.\n\nYOUR ASSIGNED SCOPE:\n- Route handlers that require auth\n- Middleware that checks auth\n- Services that depend on auth context\n- Integration points with auth\n\nDO NOT EXPLORE (other agents cover these):\n- Core auth implementation files\n- Test files\n- Config files\n\nThoroughness within scope: medium\n```\n\nAgent 3 (Tests):\n```\nFind authentication test files.\n\nYOUR ASSIGNED SCOPE:\n- Unit tests for auth\n- Integration tests for auth flows\n- Test fixtures and mocks for auth\n- E2E tests involving authentication\n\nDO NOT EXPLORE (other agents cover these):\n- Core auth implementation\n- Files that use auth\n- Config files\n\nThoroughness within scope: medium\n```\n\n#### 3.2 Update orchestration file after EACH agent completes\n\n**After EACH agent returns**, immediately write findings:\n\n```markdown\n## Collected Findings\n\n### Agent 1: Implementation\n**Status**: Complete\n**Files Found**: {count}\n\n#### OVERVIEW (from agent)\n{paste agent's overview}\n\n#### FILES TO READ (from agent)\nMUST READ:\n- {paste agent's must-read list}\n\nSHOULD READ:\n- {paste agent's should-read list}\n\nREFERENCE:\n- {paste agent's reference list}\n\n#### OUT OF SCOPE (from agent)\n- {paste any out-of-scope discoveries}\n\n---\n\n### Agent 2: Usage\n...\n```\n\n**Mark the write-to-log todo complete after each write.**\n\n### Phase 4: Cross-Reference & Evaluate Gaps\n\n#### 4.1 Analyze findings across agents\n\nAfter ALL agents complete, analyze for:\n\n- **Duplicates**: Same file in multiple agents' lists\n- **Overlapping ranges**: Same file with different line ranges\n- **Out-of-scope discoveries**: Items agents noted but didn't pursue\n- **Coverage gaps**: Obvious areas no agent covered\n- **Priority conflicts**: Same file at different priority levels\n\n#### 4.2 Update orchestration file with cross-reference\n\n```markdown\n## Cross-Reference Analysis\n\n### Duplicates Found\n- {file}: appeared in Agent 1 (MUST READ) and Agent 3 (SHOULD READ) â†’ keep MUST READ\n- {file}: appeared in Agent 1 (:50-100) and Agent 2 (:80-150) â†’ merge to :50-150\n\n### Out-of-Scope Discoveries (need follow-up?)\n- Agent 1 noted: {discovery} â†’ excluded because: {reason}\n- Agent 2 noted: {discovery} â†’ excluded because: {reason}\n\n### Coverage Check\n- [ ] Core entry points covered?\n- [ ] Error handling paths covered?\n- [ ] Configuration dependencies identified?\n- [ ] Test coverage visible?\n\n### Gaps Identified\n- {Gap 1}: {why it's a gap}\n- {Gap 2}: {why it's a gap}\n```\n\n#### 4.3 Evaluate gaps\n\n```markdown\n## Gap Evaluation\n\n### Gaps Requiring Follow-up\n- [ ] {Gap}: {specific - e.g., \"No agent explored error handling paths\"}\n\n### Gaps to Note (don't pursue)\n- {Gap}: {why minor - e.g., \"Logging files not critical for understanding topic\"}\n\n### Decision\n- Gaps requiring follow-up: {count}\n- **Action**: {LAUNCH GAP-FILL | PROCEED TO SYNTHESIS}\n```\n\n**Gap-fill rules:**\n- thorough: only for obvious critical gaps (missing core area)\n- very-thorough: for any identified gaps\n- Maximum 1-2 gap-fill agents\n\n#### 4.4 Launch gap-fill (if needed)\n\n**Gap-fill prompt:**\n```\nFill exploration gap: {specific gap}\n\nContext from initial exploration:\n- Already found: {summary of files from initial agents}\n- Gap identified: {what's missing}\n\nFocus narrowly on this gap. Don't re-explore already-covered areas.\n\nThoroughness: medium\n```\n\nAfter gap-fill agents return, write findings to orchestration file and update cross-reference.\n\n### Phase 5: Synthesize Unified Reading List\n\n#### 5.1 Refresh context (MANDATORY)\n\n**CRITICAL**: Read the FULL orchestration file using Read tool to restore ALL agent findings into context.\n\n```\n- [x] Refresh context: read full orchestration file  â† Must complete BEFORE synthesis\n- [ ] Synthesize unified reading list\n```\n\n**Why this matters**: By this point, findings from multiple agents have been written to the file. Context degradation means details may have faded. Reading the full file brings all findings into recent context.\n\n#### 5.2 Generate unified reading list\n\n**Only after completing 5.1** - synthesize all agent findings:\n\n```markdown\n## OVERVIEW\n\n[Merged overview combining insights from all agents. 150-400 words.\nDescribe: file organization, relationships between areas, entry points, data flow.\nSynthesize structural knowledge from all angles explored.]\n\n## FILES TO READ\n\nMUST READ:\n- path/file.ext:lines - [reason]\n...\n\nSHOULD READ:\n- path/file.ext:lines - [reason]\n...\n\nREFERENCE:\n- path/file.ext - [reason]\n...\n\n## EXPLORATION SUMMARY\n\n| Angle | Agent | Files Found | Key Discovery |\n|-------|-------|-------------|---------------|\n| Implementation | 1 | N | {1-liner} |\n| Usage | 2 | N | {1-liner} |\n| Tests | 3 | N | {1-liner} |\n| Gap-fill | 4 | N | {1-liner} |\n\n**Gaps noted but not explored**: {list or \"none\"}\n\n---\nOrchestration file: {path}\n```\n\n**Deduplication rules:**\n- Same file from multiple agents â†’ keep highest priority, note \"(multiple agents)\"\n- Overlapping line ranges â†’ merge into single range (union)\n- Conflicting priorities â†’ use higher priority (MUST > SHOULD > REFERENCE)\n\n#### 5.3 Mark all todos complete\n\n---\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| Thoroughness first | Determine level before any exploration |\n| Memento writes | Write to orchestration file after EACH agent - external memory |\n| Todos with write-to-log | Each agent collection gets a write-to-orchestration-file todo |\n| Parallel launch | All initial agents in single message |\n| Cross-reference | Analyze for duplicates, gaps, conflicts after agents return |\n| Limited gap-fill | At most 1-2 gap-fill agents, not unbounded |\n| **Context refresh** | **Read full orchestration file BEFORE synthesis - non-negotiable** |\n| No source file reads | You orchestrate and synthesize - main agent reads files after |\n\n**Memento Pattern Summary**:\n1. Create orchestration file at start\n2. Add write-to-log todos after each agent collection\n3. Write findings after EVERY agent returns\n4. \"Refresh context: read full orchestration file\" todo before synthesis\n5. Read FULL file before synthesis (restores all context)\n\n## Never Do\n\n- Read source files yourself (you synthesize agent findings, not file contents)\n- Skip write-to-log todos (every agent completion must be written)\n- Synthesize without completing \"Refresh context\" todo first\n- Launch agents sequentially when they could be parallel\n- Skip cross-reference step for thorough+\n- Launch unbounded gap-fill waves\n- Let agents explore overlapping areas"
              },
              {
                "name": "fix-review-issues",
                "description": "Orchestrate fixing issues found by /review. Handles issue discovery, user confirmation, plan creation, and execution via /implement.",
                "path": "claude-plugins/vibe-workflow/skills/fix-review-issues/SKILL.md",
                "frontmatter": {
                  "name": "fix-review-issues",
                  "description": "Orchestrate fixing issues found by /review. Handles issue discovery, user confirmation, plan creation, and execution via /implement."
                },
                "content": "**User request**: $ARGUMENTS\n\nSystematically address issues found from `/review` runs. Orchestrates: discover issues â†’ confirm scope â†’ plan â†’ execute â†’ verify.\n\n**Flags**: `--autonomous` â†’ skip Phase 2 scope confirmation and Phase 5 next-steps prompt (requires scope args)\n\n## Workflow\n\n### Phase 0: Parse Arguments\n\nParse `$ARGUMENTS` to determine scope:\n\n| Argument | Effect |\n|----------|--------|\n| (none) | Fix ALL issues from review |\n| `--severity <level>` | Filter by severity (critical, high, medium, low) |\n| `--category <type>` | Filter by category (use categories found in review output) |\n| File paths | Focus on specific files only |\n\nMultiple filters combine: `--severity critical,high --category <cat1>,<cat2>`\n\n### Phase 1: Discover Review Results\n\n**Step 1**: Check if review results exist in the current conversation context.\n\n**Step 2**: If NO review results found, ask the user:\n\n```\nheader: \"No Review Results Found\"\nquestion: \"I couldn't find recent /review output in this conversation. What would you like to do?\"\noptions:\n  - \"Run /review now - perform a fresh review first\"\n  - \"Paste review output - I'll provide the review results\"\n  - \"Cancel - I'll run /review myself first\"\n```\n\n- If \"Run /review now\": Inform user to run `/review` first, then return to `/fix-review-issues`\n- If \"Paste review output\": Wait for user to provide the review results\n- If \"Cancel\": End the workflow\n\n**Step 3**: If review results ARE found, extract and categorize all issues:\n\n1. Parse each issue for: severity, category, file path, line number, description, suggested fix\n2. Group issues by category\n3. Count totals by severity\n\n### Phase 2: Confirm Scope with User\n\n**If `--autonomous` OR scope arguments provided** â†’ skip Phase 2, proceed to Phase 3\n\n**If NO arguments** (fix all):\n\n```\nheader: \"Review Issues Summary\"\nquestion: \"Found {N} total issues from the review. What would you like to fix?\"\n[Display: Issue breakdown by category and severity]\noptions:\n  - \"Fix all issues (Recommended)\"\n  - \"Only critical and high severity\"\n  - \"Only specific categories - let me choose\"\n  - \"Only specific files - let me specify\"\n```\n\n**If \"Only specific categories\"**:\n\nPresent multi-select with categories found in the review output (dynamically generated from Phase 1 parsing).\n\n**If \"Only specific files\"**:\n\n```\nheader: \"Specify Files\"\nquestion: \"Which files or directories should I focus on?\"\nfreeText: true\nplaceholder: \"e.g., src/auth/ or src/utils.ts, src/helpers.ts\"\n```\n\n### Phase 3: Create Fix Plan\n\nUse the Skill tool to create the implementation plan: Skill(\"vibe-workflow:plan\", \"Fix these review issues: [summary of issues within confirmed scope]\")\n\nOnce the plan is approved, note the plan file path (typically `/tmp/plan-*.md`) and proceed to execution.\n\n### Phase 4: Execute Fixes\n\nUse the Skill tool to execute the plan: Skill(\"vibe-workflow:implement\", \"<plan-file-path>\")\n\nThe `/implement` skill handles dependency-ordered execution, progress tracking, and auto-fixing gate failures.\n\n### Phase 5: Next Steps\n\n**If `--autonomous`**: Skip prompt, end after implementation completes. Caller handles verification.\n\n**Otherwise**, ask the user:\n\n```\nheader: \"Fixes Complete\"\nquestion: \"Implementation finished. What would you like to do next?\"\noptions:\n  - \"Run /review again - verify fixes are complete (Recommended)\"\n  - \"Show diff - see all changes made\"\n  - \"Done - I'll verify manually\"\n```\n\n## Key Principles\n\n- **User Control**: Confirm scope before making changes\n- **Reduce Cognitive Load**: Use AskUserQuestion for decisions, recommended option first"
              },
              {
                "name": "implement-inplace",
                "description": "Single-agent implementation: executes plans in-place without subagents. Use /implement (default) for complex features; use this for simpler tasks or when subagent overhead is unwanted.",
                "path": "claude-plugins/vibe-workflow/skills/implement-inplace/SKILL.md",
                "frontmatter": {
                  "name": "implement-inplace",
                  "description": "Single-agent implementation: executes plans in-place without subagents. Use /implement (default) for complex features; use this for simpler tasks or when subagent overhead is unwanted."
                },
                "content": "**User request**: $ARGUMENTS\n\nAutonomously execute implementation in-place. Supports plan files, inline tasks, or interactive mode.\n\n**Fully autonomous**: No pauses except as specified in Phase 3's \"Pause ONLY when\" list and Edge Cases.\n\n## Workflow\n\n### Phase 1: Resolve Input & Setup\n\n**Review flag**: Review workflow runs by default after implementation. If arguments contain `--no-review` (case-insensitive), disable it. Remove flag from arguments before processing below.\n\n**Priority order:**\n1. **File path** (ends in `.md` or starts with `/`) â†’ use plan file, optionally with `--spec <path>`\n2. **Inline task** (any other text) â†’ create ad-hoc single chunk:\n   ```\n   ## 1. [Task summary - first 50 chars (if longer, truncate at last space before char 50 if that space is at position 10+; otherwise truncate at char 47 and append \"...\"; if 50 chars or fewer, use as-is)]\n   - Depends on: -\n   - Tasks: [user's description]\n   - Files: (list as created/modified during execution)\n   - Acceptance criteria: task completed AND gates pass\n   ```\n3. **Empty** â†’ search `/tmp/plan-*.md` (most recent by file modification time; if tied, use alphabetically last filename); if none found, **ask user** what they want to implement\n\n**For plan files**, parse each chunk (`## N. [Name]` headers):\n- Dependencies (`Depends on:` field, `-` = none)\n- Files to modify/create with descriptions\n- Context files (paths, optional line ranges)\n- Implementation tasks (bullet list)\n- Key functions/types\n\n**Invalid plan**: Empty file, missing `## N. [Name]` chunk headers, or malformed Depends on/Tasks fields (Depends on must be `-` or comma-separated chunk numbers; Tasks must be a bullet list with at least one item) â†’ Error with path + expected structure.\n\n**Build dependency graph**: No-dependency chunks first, then topological order.\n\n**Create flat todo list** (Memento patternâ€”granular progress, resumable):\n```\n[ ] Read context for [Chunk]\n[ ] [Task 1]...[ ] [Task N]\n[ ] Run gates for [Chunk]\n...\n# Unless --no-review, append:\n[ ] Run review on implemented changes\n[ ] (Fix review issues - expand as findings emerge)\n```\nAll todos created at once via TodoWrite (status `pending`). If TodoWrite unavailable, use `/tmp/implement-progress.md` with markdown checkboxes: `- [ ] pending`, `- [~] in progress`, `- [x] completed`, with timestamp prefix `[HH:MM:SS]`.\n\n**Spec file** (`--spec <path>`): Read before implementation for requirements/acceptance criteria. If path doesn't exist, add to Notes: \"Warning: Spec not found: [path]\" and continue. Spec is only used when explicitly provided via --spec.\n\n### Phase 2: Execute Chunks\n\n**CRITICAL**: Execute continuously without pauses.\n\nPer chunk:\n1. Read context files from plan + files-to-modify, respect line ranges\n2. Implement each task, marking `in_progress`â†’`completed` immediately\n3. Run gates (Phase 3)\n4. Track created/modified files for summary\n\n### Phase 3: Auto-Fix Gates\n\n**Run gates in order**: typecheck, then tests, then lint. Stop at first failure and iterate on that gate until it passes before proceeding to the next gate.\n\n**Gate command detection**:\n1. Check CLAUDE.md for explicit commands (look for sections labeled \"Development Commands\", \"Scripts\", or \"Gates\"; identify typecheck/test/lint by command names like `tsc`, `jest`, `eslint`, `mypy`, `pytest`, `ruff`)\n2. If CLAUDE.md commands fail with \"command not found\", \"not recognized\", or exit code 127 â†’ fall back to config detection\n3. Use fallback detection (see Gate Detection section)\n\n**On failureâ€”iterate**:\n1. Analyze: parse errors, identify files/lines, understand root cause\n2. Fix by addressing root cause (not by suppressing errors, skipping tests, or adding `// @ts-ignore`)\n3. Re-run the failing gate\n4. Track attempts per issue by error message and file:line; if same error persists after 3 distinct fix strategies, escalate per \"Pause ONLY when\" rules\n\n**Distinct fix strategy**: A strategy is distinct if it modifies different lines OR uses a categorically different technique: (1) adding/changing type annotations, (2) type assertions/casts, (3) refactoring logic/control flow, (4) adding null/undefined checks, (5) changing function signatures, (6) adding/modifying imports.\n\n**Pause ONLY when**:\n- Same error message and file:line persists after 3 distinct fix strategies\n- Need info not available in codebase or context (API keys, credentials, external service configs)\n- Fix requires modifying files not listed in the chunk's \"Files:\" field (creating new files is allowed only if they are: helper/utility modules, type definition files, or test files directly testing the chunk's code)\n- Plan requirements contradict each other (both can't be satisfied simultaneously)\n\nReport: what tried, why failed, what's needed.\n\n### Phase 4: Completion\n\n```\n## Implementation Complete\nChunks: N | Todos: M | Created: [list] | Modified: [list]\n### Notes: [warnings/assumptions/follow-ups]\nRun `/review` for quality verification.\n```\n\nUnless `--no-review` â†’ proceed to Phase 5.\n\n### Phase 5: Review Workflow (default, skip with --no-review)\n\nSkip if `--no-review` was set.\n\n1. Mark \"Run review\" `in_progress` â†’ invoke `Skill(\"vibe-workflow:review\", \"--autonomous\")` â†’ mark `completed`\n2. If no issues â†’ mark fix placeholder `completed`, done\n3. Expand fix placeholder:\n   ```\n   [x] (Fix review issues - expand as findings emerge)\n   [ ] Fix critical/high severity issues\n   [ ] Re-run review to verify fixes\n   [ ] (Additional fix iterations - expand if needed)\n   ```\n4. Mark \"Fix critical/high\" `in_progress` â†’ invoke `Skill(\"vibe-workflow:fix-review-issues\", \"--severity critical,high --autonomous\")` â†’ mark `completed`\n5. Mark \"Re-run review\" `in_progress` â†’ invoke `Skill(\"vibe-workflow:review\", \"--autonomous\")` â†’ mark `completed`\n6. Repeat fix/review cycle until clean or max 3 cycles\n\n## Edge Cases\n\n| Case | Action |\n|------|--------|\n| Invalid plan (empty file, missing `## N. [Name]` headers, or malformed fields) | Error with path + expected structure |\n| Missing context file | Add to Notes: \"Warning: Context file not found: [path]\", continue |\n| Chunk fails (gates fail after 3 distinct fix strategies OR task requires unavailable info) | Leave todos pending, skip dependents, continue independents, report in summary |\n| Partial gate success (e.g., typecheck passes but tests fail after 3 strategies) | Chunk fails; require all gates to pass for chunk completion |\n| Inline task provided | Create ad-hoc single chunk, proceed normally |\n| No input + no recent plan | Ask user what they want to implement |\n| Interrupted | Todos reflect exact progress; on next invocation with same plan, agent resumes from first pending todo. If files were partially modified without git: read current state and complete remaining work rather than overwriting |\n| CLAUDE.md gate commands fail | Fall back to config-based detection (see Gate Detection) |\n| No CLAUDE.md or no matching sections | Skip to config-based detection |\n| Circular dependencies | Error: \"Circular dependency detected: [chunk A] â†” [chunk B]\". List cycle, abort. |\n| TodoWrite unavailable | Track progress via `/tmp/implement-progress.md` with checkbox format |\n| Spec file doesn't exist | Add to Notes: \"Warning: Spec not found: [path]\", continue without spec |\n\n## Principles\n\n- **Autonomous**: No prompts/pauses/approval needed except blocking issues listed in Phase 3 and Edge Cases\n- **Memento todos**: One todo per action, granular visibility, resumable\n- **Persistent auto-fix**: Iterate until gates pass (up to 3 distinct strategies per issue), escalate only when stuck\n- **Dependency order**: Execute in order, skip failed chunk's dependents\n- **Gates non-negotiable**: Fix root cause (no `@ts-ignore`, test skips, or suppressions); skip chunk only after 3 failed strategies\n\n## Gate Detection\n\n**Priority**: CLAUDE.md â†’ package.json scripts â†’ Makefile â†’ config detection\n\nSkip any source that doesn't define relevant commands (test/lint/typecheck).\n\n**Fallback** (if CLAUDE.md doesn't specify or commands fail with exit code 127):\n- TS/JS: `tsconfig.json`â†’`tsc --noEmit`, `eslint.config.*`â†’`eslint .`, `jest/vitest.config.*`â†’`npm test`\n- Python: `pyproject.toml`â†’`mypy`/`ruff check`, pytest configâ†’`pytest`\n- Go: `go.mod`â†’`go build ./...`, `golangci.yml`â†’`golangci-lint run`\n- Rust: `Cargo.toml`â†’`cargo check`, `cargo test`\n- Other languages: Skip gates with warning \"No gate commands detected for [language]; specify in CLAUDE.md\""
              },
              {
                "name": "implement",
                "description": "Executes implementation plans via subagents with automated verification and fix loops. Use after /plan for complex features. Each chunk gets dedicated Implementor + Verifier agents with up to 5 fix attempts.",
                "path": "claude-plugins/vibe-workflow/skills/implement/SKILL.md",
                "frontmatter": {
                  "name": "implement",
                  "description": "Executes implementation plans via subagents with automated verification and fix loops. Use after /plan for complex features. Each chunk gets dedicated Implementor + Verifier agents with up to 5 fix attempts."
                },
                "content": "**User request**: $ARGUMENTS\n\nAutonomously execute plan chunks via Implementor and Verifier subagents. Each chunk is isolated: implemented by one agent, verified by another, with automated fix loops.\n\n**Fully autonomous**: No pauses except these blocking issues: (1) git conflicts with overlapping changes in the same lines, (2) package manager failures (any package install command returning non-zero, e.g., npm/yarn/pnpm, pip/poetry, cargo, go mod), (3) OS permission errors on file read/write. No other issues are blocking.\n\n**Gates**: Automated verification commands (typecheck, lint, test) detected from project config. See \"Gate Detection\" section for resolution order. If no gates detected, verification passes based on acceptance criteria only.\n\n## Workflow\n\n```\nFor each chunk:\n  1. Spawn Implementor agent â†’ implements chunk\n  2. Spawn Verifier agent â†’ checks gates + acceptance criteria\n  3. If FAIL â†’ fix loop (max 5 total attempts including initial, escalate on same-error)\n  4. If PASS â†’ update progress, next chunk\n```\n\n## Phase 1: Parse Plan & Setup\n\n### 1.1 Resolve Input\n\n**Review flag**: Review workflow runs by default after implementation. If arguments contain `--no-review` (case-insensitive), disable it. Remove flag from arguments before processing below.\n\n**Priority order:**\n1. **`--progress <path>`** â†’ resume from progress file\n2. **File path** (ends in `.md` or starts with `/`) â†’ use plan file\n3. **Inline task** (any other text) â†’ create ad-hoc single chunk:\n   ```\n   ## 1. [First 50 characters of task, truncated at last space before character 50; full text if under 50 chars; at char 50 if no spaces]\n   - Depends on: -\n   - Tasks: [full user text]\n   - Files: (implementor discovers)\n   - Acceptance criteria: derived from task text (convert to verifiable statement per 1.2 rules); all detected gates must pass (required regardless of other criteria)\n   ```\n4. **Empty** â†’ error: \"Provide plan path, inline task, or run /plan first\"\n\n### 1.2 Parse Chunks\n\nFor each `## N. [Name]` header, extract:\n- Dependencies (`Depends on:` field, `-` = none)\n- Files to modify/create with descriptions\n- Context files (paths, optional line ranges)\n- Implementation tasks (bullet list)\n- Acceptance criteria (if missing: derive from tasks by converting each task to a verifiable statement, e.g., \"Add login button\" â†’ \"Login button exists and is clickable\". If task cannot be converted to verifiable statement, use: \"Implementation matches task description: [task text]\" and rely on gates only. Always include \"all gates pass\" as baseline)\n- Key functions/types (passed to implementor for context; not used for verification)\n\n### 1.3 Build Dependency Graph\n\nOrder: No-dependency chunks first (by chunk number: ## 1 before ## 2), then topological order (ties broken by chunk number).\n\n### 1.4 Create Progress File\n\nPath: `/tmp/implement-{YYYYMMDD-HHMMSS}-{name-kebab-case}.md`\n\n**Timestamp format**: All timestamps use ISO 8601: `YYYY-MM-DDTHH:MM:SS` (e.g., `2026-01-09T14:30:00`).\n\n```markdown\n# Implementation Progress: [Plan Name]\n\nStarted: [timestamp]\nPlan: [path to plan file]\nStatus: IN_PROGRESS\n\n## Chunks\n\n### Chunk 1: [Name]\nStatus: PENDING\nAttempts: 0\nImplementor log: (none)\nVerifier log: (none)\nFiles created: []\nFiles modified: []\nOut-of-scope fixes: []\nNotes:\n\n### Chunk 2: [Name]\nStatus: PENDING\n...\n\n## Summary\nCompleted: 0/N chunks\nLast updated: [timestamp]\n```\n\n### 1.5 Create Todo List\n\nBuild Memento-style todos with 4 items per chunk:\n```\n[ ] Implement chunk 1: [Name]\n[ ] Verify chunk 1: [Name]\n[ ] (Fix loop for chunk 1 - expand if needed)\n[ ] Commit chunk 1: [Name]\n[ ] Implement chunk 2: [Name]\n[ ] Verify chunk 2: [Name]\n[ ] (Fix loop for chunk 2 - expand if needed)\n[ ] Commit chunk 2: [Name]\n...\n# Unless --no-review, append:\n[ ] Run review on implemented changes\n[ ] (Fix review issues - expand as findings emerge)\n```\n\nAll todos created at once via TodoWrite, status `pending`. Fix loop placeholder is marked completed and replaced with implement/verify pairs during Phase 3 (see 3.1).\n\n### 1.6 Handle Resume\n\nIf `--progress` argument provided:\n1. Read progress file\n2. Skip chunks with status `COMPLETE`\n3. Resume from first `PENDING` or `IN_PROGRESS` chunk\n4. For `IN_PROGRESS` chunks: if `Implementor log` exists, spawn verifier to check current state; if PASS, continue; if FAIL, enter fix loop from current attempt count. If no `Implementor log`, restart chunk from implementation step.\n\n## Phase 2: Execute Chunks (Subagent Orchestration)\n\n**Prerequisites**: TodoWrite tool, Task tool with subagent_type support, installed agents: `vibe-workflow:chunk-implementor`, `vibe-workflow:chunk-verifier`.\n\n**CRITICAL**: Execute continuously without pauses.\n\nFor each chunk in dependency order:\n\n### 2.1 Spawn Implementor Agent\n\n1. Mark implement todo `in_progress`\n2. **Update progress file**: chunk status â†’ `IN_PROGRESS`, `Last updated` timestamp\n3. Use Task tool with `subagent_type: \"vibe-workflow:chunk-implementor\"`:\n\n```\nImplement chunk N: [Name]\n\n## Full Chunk Definition\n[Copy the ENTIRE chunk verbatim from the plan, including:\n- Depends on / Parallel\n- Description\n- Files to modify (with descriptions)\n- Files to create (with purposes)\n- Context files (with line ranges)\n- Tasks\n- Acceptance criteria\n- Key functions / Types]\n\n[If retry: ## Fix Context\nAttempt: N/5\nVerifier log: [path for detailed gate output]\n\n### Direct Issues (in chunk's files)\n[errors in files this chunk created/modified]\n\n### Indirect Issues (in other files)\n[errors in files NOT touched by chunk - your changes broke these]\nFiles: [list of affected files from Indirect issues]\n\nFix Direct first. For Indirect: fix in your files if possible, else edit listed files. See verifier log for full gate output.]\n```\n\n4. Wait for completion, parse output:\n   - Check for `## Chunk Implementation Blocked` â†’ if BLOCKED, skip remaining steps and escalate (Phase 4)\n   - Extract `Log file:` path\n   - Extract `Files created:` and `Files modified:` lists\n   - Extract `Out-of-scope fixes:` if present (Indirect issue fixes)\n   - Extract `Confidence:` (HIGH = all tasks completed exactly as specified with no interpretation needed; MEDIUM = all tasks completed but required interpreting ambiguous requirements or choosing between valid approaches; LOW = tasks completed but required deviation that changes approach/architecture, e.g., different libraries, changed API signatures. If tasks are partially completed or blocked, implementor returns BLOCKED status instead). All confidence levels proceed to verification; LOW confidence triggers note in final summary. Extract `Uncertainty:` reason if present\n5. **Update progress file**: `Implementor log`, `Files created`, `Files modified`, `Out-of-scope fixes`, `Confidence`, `Uncertainty`, `Last updated`\n6. Mark implement todo `completed`\n\n### 2.2 Spawn Verifier Agent\n\n1. Mark verify todo `in_progress`\n2. Use Task tool with `subagent_type: \"vibe-workflow:chunk-verifier\"`:\n\n```\nVerify chunk N: [Name]\n\n## Full Chunk Definition\n[Copy the ENTIRE chunk verbatim - same as implementor received]\n\n## Implementor Log File\n[Path from implementor's output, e.g., /tmp/implement-chunk-1-20260107-120000.md]\n\n[If retry: ## Previous Errors\n[Errors from last verification for same-error detection]]\n```\n\n3. Wait for result, parse output:\n   - Extract `Status:` (PASS/FAIL)\n   - Extract `Log file:` path\n   - Extract issues: `Direct` (chunk's files) and `Indirect` (other files)\n   - Check `Same as previous:` if retry (same-error = same file path AND (same error code if present, e.g., TS2322/E501, OR same error message first line if no code); test failures: same test name counts as same error regardless of assertion message; different line numbers still count as same error; new error types or new files = different errors. Comparison is against immediately previous attempt only.)\n4. **Update progress file**: `Verifier log`, `Last updated`\n\n### 2.3 Process Verification Result\n\n**If Status: PASS**\n1. Mark verify todo `completed`\n2. Mark fix loop placeholder `completed` (not needed)\n3. **Update progress file**: chunk status â†’ `COMPLETE`, `Completed: N/M`, `Last updated`\n4. Commit chunk (see 2.4)\n5. Continue to next chunk\n\n**If Status: FAIL**\n1. **Update progress file**: increment `Attempts`, add issues to `Notes`, `Last updated`\n2. Check for git issues (`Git issue:` in output) â†’ if found, main agent attempts resolution per section 2.4 rules. If resolvable, re-verify (don't count as attempt). If unresolvable, escalate to user (Phase 4).\n3. Check attempt count (max 5 total including initial)\n4. Check for same-error condition\n5. If same-error detected at any attempt â†’ escalate immediately (Phase 4)\n6. If can retry (attempts < 5 AND no same-error) â†’ enter fix loop (Phase 3)\n7. If max attempts (5) reached â†’ escalate (Phase 4)\n\n### 2.4 Commit Chunk (Main Agent Only)\n\n**CRITICAL**: Main agent handles all git operations directly. Subagents NEVER perform git actions.\n\n1. Mark commit todo `in_progress`\n2. Stage files from chunk: `git add [files created/modified]`\n3. Commit with message: `feat(plan): implement chunk N - [Name]`\n4. **Do NOT push** - push happens at end or on user request\n5. **Update progress file**: add commit SHA to chunk notes\n6. Mark commit todo `completed`\n\n**If git operation fails** (conflicts, dirty state, etc.):\n1. Log issue in progress file\n2. Attempt automated resolution only for: dirty working directory (`git stash`), unstaged changes (`git stash`). If stash succeeds, pop after git operation completes (`git stash pop`); if pop conflicts, leave stash intact and log in Notes. If stash operation fails, treat as unresolvable. Never attempt conflict resolution, branch switching, or rebase operations.\n3. If unresolvable, report to user with specific error\n4. Stop execution - user must resolve before resuming\n\n## Phase 3: Fix Loop\n\nWhen verification fails and retry is possible:\n\n### 3.1 Expand Fix Loop Placeholder\n\nReplace fix loop placeholder todo with specific items:\n```\n[x] (Fix loop for chunk N - expand if needed) â†’ completed\n[ ] Fix attempt 1: implement chunk N\n[ ] Fix attempt 1: verify chunk N\n[ ] (Additional fix attempts - expand if needed)\n```\n\n### 3.2 Analyze Failure\n\nFrom verifier output, identify:\n- Gate failures (specific errors)\n- Acceptance criteria failures\n- File:line locations\n\n### 3.3 Respawn Implementor with Fix Context\n\n1. Mark fix implement todo `in_progress`\n2. Spawn implementor via Task tool (as in 2.1), including the full chunk definition AND the `## Fix Context` section with attempt number, verifier log path, and categorized issues\n3. **Update progress file**: new `Implementor log`, updated files, `Last updated`\n4. Mark fix implement todo `completed`\n\n### 3.4 Re-verify\n\n1. Mark fix verify todo `in_progress`\n2. Respawn verifier with `previous_errors` for same-error detection\n3. **Update progress file**: new `Verifier log`, `Last updated`\n\n### 3.5 Process Result\n\n**If PASS**:\n1. Mark fix verify todo `completed`\n2. Mark additional attempts placeholder `completed`\n3. **Update progress file**: status â†’ `COMPLETE`, `Completed: N/M`, `Last updated`\n4. Commit chunk (2.4)\n5. Continue to next chunk\n\n**If FAIL with different errors** (at least one previous error resolved OR new error type appeared; if all previous errors persist plus new ones, treat as same-error):\n1. **Update progress file**: increment `Attempts`, update `Notes`, `Last updated`\n2. If attempts < 5 â†’ expand placeholder, repeat fix loop (3.2)\n\n**If FAIL with same errors OR attempts >= 5**:\n1. **Update progress file**: status â†’ `FAILED`, `Notes` with reason, `Last updated`\n2. Escalate (Phase 4)\n\n## Phase 4: Escalation & Completion\n\n### 4.1 Escalation\n\nWhen chunk cannot be completed:\n\n1. **Update progress file**: overall status â†’ `FAILED`, chunk status â†’ `FAILED`, `Last updated`\n2. Report to user:\n\n```\n## Implementation Blocked\n\nChunk [N]: [Name] failed after [X] attempts.\n\n### Last Verification Result\n[Verifier's output]\n\n### Attempts History\n1. [Issues from attempt 1]\n2. [Issues from attempt 2]\n...\n\n### Recommendation\n[Actionable next step: (1) specific code fix if error is clear, (2) \"Review [file:line] - error suggests [interpretation]\" if ambiguous, or (3) \"Re-plan chunk - scope may be incorrect\" if repeated failures on different errors]\n\nProgress saved to: [progress file path]\nResume with: /implement --progress [path]\n```\n\nStop implementation. User must intervene.\n\n### 4.2 Successful Completion\n\nWhen all chunks complete:\n\n1. **Update progress file**: overall status â†’ `COMPLETE`, `Completed: N/N`, `Last updated`\n2. Report to user:\n\n```\n## Implementation Complete\n\nChunks: N | Files created: [list] | Files modified: [list]\n\n### Chunk Summary\n1. [Name] - [files touched]\n2. [Name] - [files touched] - âš ï¸ [uncertainty reason]\n\n### Notes\n[Any warnings, assumptions, or follow-ups]\n\nProgress file: [path]\nRun `/review` for quality verification.\n```\n\n3. Unless `--no-review` â†’ proceed to Phase 5\n\n## Phase 5: Review Workflow (default, skip with --no-review)\n\nSkip if `--no-review` was set.\n\n### 5.1 Run Review\n\n1. Mark \"Run review\" todo `in_progress`\n2. Invoke: `Skill(\"vibe-workflow:review\", \"--autonomous\")`\n3. Mark \"Run review\" todo `completed`\n4. If no issues â†’ mark fix placeholder `completed`, done; else â†’ 5.2\n\n### 5.2 Fix Review Issues\n\n1. Expand fix placeholder:\n   ```\n   [x] (Fix review issues - expand as findings emerge)\n   [ ] Fix critical/high severity issues\n   [ ] Re-run review to verify fixes\n   [ ] (Additional fix iterations - expand if needed)\n   ```\n2. Mark \"Fix critical/high\" `in_progress`\n3. Invoke: `Skill(\"vibe-workflow:fix-review-issues\", \"--severity critical,high --autonomous\")`\n4. Mark \"Fix critical/high\" `completed`, mark \"Re-run review\" `in_progress`\n5. Invoke: `Skill(\"vibe-workflow:review\", \"--autonomous\")`\n6. Mark \"Re-run review\" `completed`\n7. If issues remain â†’ expand placeholder, repeat (max 3 cycles)\n8. After 3 cycles or clean â†’ mark placeholders `completed`, report status\n\n## Progress File Format\n\n```markdown\n# Implementation Progress: [Plan Name]\n\nStarted: [timestamp]\nPlan: [path]\nStatus: IN_PROGRESS | COMPLETE | FAILED\n\n## Chunks\n\n### Chunk 1: [Name]\nStatus: PENDING | IN_PROGRESS | COMPLETE | FAILED | BLOCKED\nAttempts: N\nConfidence: HIGH | MEDIUM | LOW\nImplementor log: [path or (none)]\nVerifier log: [path or (none)]\nFiles created: [list]\nFiles modified: [list]\nOut-of-scope fixes: [list or empty]\nNotes: [issues, warnings, or uncertainty details]\n\n### Chunk 2: [Name]\n...\n\n## Summary\nCompleted: N/M chunks\nLast updated: [timestamp]\n```\n\n## Edge Cases\n\n| Case | Action |\n|------|--------|\n| Invalid plan (no `## N.` chunk headers, or chunk headers without Tasks or Files fields) | Error: \"Plan must contain at least one chunk (## 1. Name) with either Tasks or Files fields\" |\n| Plan with no chunks (valid file, zero `## N.` headers) | Error: \"Plan contains no chunks. Expected at least one '## N. [Name]' header.\" |\n| Circular dependencies in plan | Error: \"Circular dependency detected: [chunk A] â†” [chunk B]. Fix plan dependencies before continuing.\" |\n| Missing context file | Log warning in progress file Notes field (\"Context file not found: [path]\"), continue execution |\n| Chunk fails after 5 attempts | Mark FAILED, stop, report which chunk and why |\n| Same error detected | Stop immediately, escalate with recommendation |\n| No acceptance criteria in plan | Auto-infer from tasks |\n| Interrupted mid-chunk | Progress file shows IN_PROGRESS, resume re-starts that chunk |\n| Resume with progress file | Skip COMPLETE chunks, start from first non-complete |\n| Dependency not met (prior chunk FAILED or BLOCKED) | Mark BLOCKED (cascade to all dependents immediately), skip to next independent chunk |\n| Implementor returns BLOCKED | Mark chunk FAILED, escalate with blocker details |\n| Verifier reports git issue | Main agent resolves git state, re-verify (no attempt count) |\n| Inline task provided | Create ad-hoc single chunk, proceed normally |\n| No input provided | Error: \"Provide plan path, inline task, or run /plan first\" |\n| All remaining chunks blocked by dependencies | Mark overall status â†’ `FAILED`, report which chunks are blocked and their unmet dependencies, suggest re-planning or manual intervention |\n\n## Principles\n\n- **Main agent = Task + commit only**: Spawn subagents, track progress, commit. NEVER read/edit/run gates on source files.\n- **Subagent isolation**: Implementor edits, Verifier only reads, neither does git\n- **Git in main agent only**: All git operations (add, commit) happen in main agent, not subagents\n- **Commit per chunk**: Each successful chunk gets its own commit (no push until end)\n- **Autonomous**: No prompts/pauses/approval except blocking issues\n- **Retry heavily**: 5 attempts before giving up, escalation is last resort\n- **Same-error aware**: Detect loops, don't wall-slam\n- **Progress after every step**: Update progress file after each todo completion\n- **Acceptance-focused**: Gates + criteria must pass\n\n## Main Agent Constraint\n\n**The loop per chunk**:\n```\nimplement (Task) â†’ verify (Task) â†’ [implement â†’ verify]* â†’ commit\n```\n\nMain agent ONLY:\n- Calls Task tool (implementor/verifier)\n- Updates progress file\n- Runs git commit after verification passes\n\nMain agent NEVER:\n- Reads source files (only progress/log files)\n- Edits source files\n- Runs gates (typecheck/lint/test)\n- Fixes issues (respawn implementor instead)\n- Stops or asks user mid-execution (fully autonomous until completion, chunk failure after max attempts, or unrecoverable errors like git conflicts/permission denied)\n\n## Gate Detection (Verifier Reference)\n\n**Priority**: CLAUDE.md â†’ package.json scripts â†’ Makefile â†’ config detection\n\n**Fallback** (if CLAUDE.md doesn't specify):\n- TS/JS: `tsconfig.json`â†’`tsc --noEmit`, `eslint.config.*`â†’`eslint .`, `jest/vitest.config.*`â†’`npm test`\n- Python: `pyproject.toml`â†’`mypy`/`ruff check`, pytest configâ†’`pytest`\n- Other languages: check for standard config files (Makefile, build.gradle, Cargo.toml, etc.) and infer commands. If no recognizable config, verification passes based on acceptance criteria only (no gates)."
              },
              {
                "name": "plan",
                "description": "Create implementation plans from spec via iterative codebase research and strategic questions. Produces mini-PR plans optimized for iterative development.",
                "path": "claude-plugins/vibe-workflow/skills/plan/SKILL.md",
                "frontmatter": {
                  "name": "plan",
                  "description": "Create implementation plans from spec via iterative codebase research and strategic questions. Produces mini-PR plans optimized for iterative development."
                },
                "content": "**User request**: $ARGUMENTS\n\nBuild implementation plan through structured discovery. Takes spec (from `/spec` or inline), iteratively researches codebase + asks high-priority technical questions that shape implementation direction â†’ detailed plan.\n\n**Focus**: HOW not WHAT. Spec=what; plan=architecture, files, functions, chunks, dependencies, tests.\n\n**Loop**: Research â†’ Expand todos â†’ Ask questions â†’ Write findings â†’ Repeat until complete\n\n**Output files**:\n- Plan: `/tmp/plan-{YYYYMMDD-HHMMSS}-{name-kebab-case}.md`\n- Research log: `/tmp/plan-research-{YYYYMMDD-HHMMSS}-{name-kebab-case}.md` (external memory)\n\n## Boundaries\n\n- Spec=requirements; this skill=architecture, files, chunks, tests\n- Don't modify spec; flag gaps for user\n- Surface infeasibility before proceeding\n- No implementation until approved\n\n## Phase 1: Initial Setup\n\n### 1.1 Create todos (TodoWrite immediately)\n\nTodos = **areas to research/decide**, not steps. Expand when research reveals: (a) files/modules to modify beyond those already in todos, (b) 2+ valid implementation patterns with different trade-offs, (c) dependencies on code/systems not yet analyzed, or (d) questions that must be answered before completing an existing todo.\n\n**Starter seeds**:\n```\n- [ ] Read/infer spec requirements\n- [ ] Codebase research (patterns, files to modify)\n- [ ] Architecture decisions\n- [ ] (expand as research reveals new areas)\n- [ ] Read full research log and spec (context refresh before output)\n- [ ] Finalize chunks\n```\n\n**Evolution example** - \"Add real-time notifications\":\n\nInitial â†’ After codebase research (found WebSocket) â†’ After \"needs offline too\":\n```\n- [x] Read spec â†’ 3 types, mobile+web\n- [x] Codebase research â†’ ws.ts, notification-service.ts\n- [x] WebSocket approach â†’ extend existing\n- [ ] Architecture decisions\n- [ ] Offline storage (IndexedDB vs localStorage)\n- [ ] Sync conflict resolution\n- [ ] Service worker integration\n- [ ] Read full research log and spec (context refresh before output)\n- [ ] Finalize chunks\n```\n\n**Key**: Never prune todos prematurely.\n\n### 1.2 Create research log\n\nPath: `/tmp/plan-research-{YYYYMMDD-HHMMSS}-{name-kebab-case}.md`\n\n```markdown\n# Research Log: {feature}\nStarted: {timestamp} | Spec: {path or \"inline\"}\n\n## Codebase Research\n## Architecture Decisions\n## Questions & Answers\n## Unresolved Items\n```\n\n## Phase 2: Context Gathering\n\n**Prerequisites**: Requires `vibe-workflow:codebase-explorer` agent. If Task tool fails for any reason (agent not found, timeout after 120 seconds, permission error, incomplete results) OR returns fewer than 3 relevant files when exploring an area expected to touch multiple modules (cross-cutting concerns, features spanning >2 directories), perform supplementary codebase research manually using Read, Glob, and Grep tools and note `[SUPPLEMENTED RESEARCH: codebase-explorer insufficient - {reason}]` in research log. Do not retry on timeoutâ€”proceed directly to supplementary research.\n\n### 2.1 Read/infer spec\n\nExtract: requirements, user stories, acceptance criteria, constraints, out-of-scope.\n\n**No formal spec?** Infer from conversation, tool outputs, user request. If spec and conversation together provide fewer than 2 concrete requirements, ask user via AskUserQuestion: \"I need at least 2 concrete requirements to plan. Please provide: [list what's missing]\" before proceeding.\n\n### 2.2 Launch codebase-explorer\n\nTask tool with `subagent_type: \"vibe-workflow:codebase-explorer\"`. Launch multiple in parallel for cross-cutting work.\n\nExplore: existing implementations, files to modify, patterns, integration points, test patterns.\n\n### 2.3 Read ALL recommended files\n\nNo skipping. Gives firsthand knowledge of patterns, architecture, integration, tests.\n\n### 2.4 Update research log\n\nAfter EACH step:\n```markdown\n### {timestamp} - {what researched}\n- Explored: {areas}\n- Key findings: {files, patterns, integration points}\n- New areas: {list}\n- Architectural questions: {list}\n```\n\n### 2.5 Write initial draft\n\nFirst draft with `[TBD]` markers. Same file path for all updates.\n\n## Phase 3: Iterative Discovery Interview\n\n**CRITICAL**: Use AskUserQuestion tool for ALL questionsâ€”never plain text. If AskUserQuestion is unavailable, present questions in structured markdown with numbered options and wait for user response.\n\n**Example** (the `questions` array supports 1-4 questions per callâ€”that's batching):\n```\nquestions: [\n  {\n    question: \"Should we build the full implementation or a minimal stub?\",\n    header: \"Phasing\",\n    options: [\n      { label: \"Full implementation (Recommended)\", description: \"Complete feature per spec, production-ready\" },\n      { label: \"Minimal stub\", description: \"Interface only, implementation deferred\" },\n      { label: \"Incremental\", description: \"Core first, enhance in follow-up PRs\" }\n    ],\n    multiSelect: false\n  },\n  {\n    question: \"Which state management approach?\",\n    header: \"State\",\n    options: [\n      { label: \"Extend existing store (Recommended)\", description: \"Matches codebase pattern in src/store/\" },\n      { label: \"Local component state\", description: \"Simpler but less shareable\" },\n      { label: \"New dedicated store\", description: \"Isolated but adds complexity\" }\n    ],\n    multiSelect: false\n  }\n]\n```\n\n### Memento Loop\n\n1. Mark todo `in_progress` (via TodoWrite with status \"in_progress\")\n2. Research (codebase-explorer) OR ask (AskUserQuestion)\n3. **Write findings immediately** to research log\n4. Expand todos for new questions/integration points/dependencies\n5. Update plan (replace `[TBD]`)\n6. Mark todo `completed` (via TodoWrite with status \"completed\")\n7. Repeat until no pending todos\n\n**NEVER proceed without writing findings** â€” research log = external memory.\n\n**If user answer contradicts prior decisions**: (1) Inform user: \"This contradicts earlier decision X. Proceeding with new answer.\" (2) Log in research log under `## Conflicts` with both decisions. (3) Re-evaluate affected todos. (4) Update plan accordingly. If contradiction cannot be resolved, ask user to clarify priority.\n\n### Research Log Update Format\n\n```markdown\n### {timestamp} - {what}\n**Todo**: {which}\n**Finding/Answer**: {result}\n**Impact**: {what revealed/decided}\n**New areas**: {list or \"none\"}\n```\n\nArchitecture decisions:\n```markdown\n- {Area}: {choice} â€” {rationale}\n```\n\n### Todo Expansion Triggers\n\n| Research Reveals | Add Todos For |\n|------------------|---------------|\n| Existing similar code | Integration approach |\n| Multiple valid patterns | Pattern selection |\n| External dependency | Dependency strategy |\n| Complex state | State architecture |\n| Cross-cutting concern | Concern isolation |\n| Performance-sensitive | Performance strategy |\n| Migration needed | Migration path |\n\n### Interview Rules\n\n**Unbounded loop**: Iterate until ALL completion criteria met. No fixed round limit. If user says \"just decide\", \"you pick\", \"I don't care\", \"skip this\", or otherwise explicitly delegates the decision, document remaining decisions with `[INFERRED: {choice} - {rationale}]` markers and finalize.\n\n**Spec-first**: Business scope and requirements belong in spec. Questions here are TECHNICAL onlyâ€”architecture, patterns, implementation approach. If spec has gaps affecting implementation: (1) flag in research log under `## Spec Gaps`, (2) ask user via AskUserQuestion whether to pause for spec update OR proceed with stated assumption, (3) document choice and continue.\n\n1. **Prioritize questions that eliminate other questions** - Ask questions where the answer changes what other questions you need to ask, or eliminates entire branches of implementation. If knowing X makes Y irrelevant, ask X first.\n\n2. **Interleave discovery and questions**:\n   - User answer reveals new area â†’ launch codebase-explorer\n   - Need external context â†’ launch web-researcher (if unavailable, ask user to provide external context directly via AskUserQuestion)\n   - Update plan after each iteration, replacing `[TBD]` markers\n\n3. **Question priority order**:\n\n   | Priority | Type | Purpose | Examples |\n   |----------|------|---------|----------|\n   | 1 | Implementation Phasing | How much to build now vs later | Full impl vs stub? Include migration? Optimize or simple first? |\n   | 2 | Branching | Open/close implementation paths | Sync vs async? Polling vs push? In-memory vs persistent? |\n   | 3 | Technical Constraints | Non-negotiable technical limits | Must integrate with X? Performance requirements? Backward compatibility? |\n   | 4 | Architectural | Choose between patterns | Error strategy? State management? Concurrency model? |\n   | 5 | Detail Refinement | Fine-grained technical details | Test coverage scope? Retry policy? Logging verbosity? |\n\n4. **Always mark one option \"(Recommended)\"** - put first with reasoning in description. When options are equivalent AND easily reversible (changes affect only 1-2 files, where each changed file is imported by 5 or fewer other files, and there are no data migrations, schema changes, or public API changes), decide yourself (lean toward existing codebase patterns).\n\n5. **Be thorough via technique**:\n   - Cover technical decisions from each applicable priority category (1-5 in the priority table)â€”don't skip categories to save time\n   - Reduce cognitive load through HOW you ask: concrete options, good defaults\n   - **Batching**: Up to 4 questions in `questions` array per call (batch questions that share a common decisionâ€”e.g., multiple state management questions, or multiple error handling questionsâ€”where answers to one inform the others); max 4 options per question (tool limit)\n   - Make decisions yourself when codebase research suffices\n   - Complete plan with easy questions > incomplete plan with fewer questions\n\n6. **Ask non-obvious questions** - Error handling strategies, edge cases affecting correctness, performance implications, testing approach for complex logic, rollback/migration needs, failure modes\n\n7. **Ask vs Decide** - Codebase patterns and technical standards are authority; user decides significant trade-offs.\n\n   **Ask user when**:\n   | Category | Examples |\n   |----------|----------|\n   | Trade-offs affecting measurable outcomes | Estimated >20% change to latency/throughput vs current implementation, adds abstraction layers, locks approach for >6 months, changes user-facing behavior |\n   | No clear codebase precedent | New pattern not yet established |\n   | Multiple valid approaches | Architecture choice with different implications |\n   | Phasing decisions | Full impl vs stub, migration included or deferred |\n   | Breaking changes | API changes, schema migrations |\n   | Resource allocation | Cache size, connection pools, batch sizes with cost implications |\n\n   **Decide yourself when**:\n   | Category | Examples |\n   |----------|----------|\n   | Existing codebase pattern | Error format, naming conventions, file structure |\n   | Industry standard | HTTP status codes, retry with exponential backoff |\n   | Sensible defaults | Timeout 30s, pagination 50 items, debounce 300ms |\n   | Easily changed later | Internal function names, log messages, test structure |\n   | Implementation detail | Which hook to use, internal state shape, helper organization |\n   | Clear best practice | Dependency injection, separation of concerns |\n\n   **Test**: \"If I picked wrong, would user say 'that's not what I meant' (ASK) or 'that works, I would have done similar' (DECIDE)?\"\n\n## Phase 4: Finalize & Present\n\n### 4.1 Final research log update\n\n```markdown\n## Planning Complete\nFinished: {timestamp} | Research log entries: {count} | Architecture decisions: {count}\n## Summary\n{Key decisions}\n```\n\n### 4.2 Refresh context\n\nRead the full research log file to restore all findings, decisions, and rationale into context before writing the final plan.\n\n### 4.3 Finalize plan\n\nRemove `[TBD]`, ensure chunk consistency, verify dependency ordering, add line ranges for files >500 lines.\n\n### 4.4 Mark all todos complete\n\n### 4.5 Present summary\n\n```\n## Plan Summary\n\n**Plan file**: /tmp/plan-{...}.md\n\n### What We're Building\n{1-2 sentences}\n\n### Chunks ({count})\n1. {Name} - {description}\n\n### Key Decisions\n- {Decision}: {choice}\n\n### Execution Order\n{Dependencies, parallel opportunities}\n\n---\nReview full plan. Adjust or approve to start.\n```\n\n### 4.6 Wait for approval\n\nDo NOT implement until user explicitly approves. After approval: create todos from chunks, execute.\n\n---\n\n# Planning Methodology\n\n## 1. Principles\n\n| Principle | Description |\n|-----------|-------------|\n| **Safety** | Never skip gates (type checks, tests, lint); every chunk tests+demos independently |\n| **Clarity** | Full paths, numbered chunks, rationale for context files, line ranges |\n| **Minimalism** | Ship today's requirements; parallelize where possible |\n| **Forward focus** | Don't prioritize backward compatibility unless requested or public API/schema contracts would be broken |\n| **Cognitive load** | Deep modules with simple interfaces > many shallow; reduce choices |\n| **Conflicts** | Safety > Clarity > Minimalism > Forward focus |\n\n**Definitions**:\n- **Gates**: Quality checks every chunk must passâ€”type checks (0 errors), tests (pass), lint (clean)\n- **Mini-PR**: A chunk sized to be its own small pull requestâ€”complete, mergeable, reviewable independently\n- **Deep modules**: Modules that hide complexity behind simple interfaces (few public methods, rich internal logic)\n\n### Code Quality (P1-P10)\n\nUser's explicit intent takes precedence for implementation choices (P2-P10). P1 (Correctness) and Safety gates (type checks 0 errors, tests pass, lint clean) are non-negotiableâ€”if user requests skipping these, flag as risk but do not skip.\n\n| # | Principle | Planning Implication |\n|---|-----------|---------------------|\n| P1 | Correctness | Every chunk must demonstrably work |\n| P2 | Observability | Plan logging, error visibility |\n| P3 | Illegal States Unrepresentable | Design types preventing compile-time bugs |\n| P4 | Single Responsibility | Each chunk ONE thing |\n| P5 | Explicit Over Implicit | Clear APIs, no hidden behaviors |\n| P6 | Minimal Surface Area | YAGNIâ€”don't add features beyond spec |\n| P7 | Tests | Specific cases, not \"add tests\" |\n| P8 | Safe Evolution | Public API/schema changes need migration |\n| P9 | Fault Containment | Plan failure isolation, retry/fallback |\n| P10 | Comments Why | Document complex logic why, not what |\n\nP1-P10 apply to code quality within chunks. Principle conflicts (Safety > Clarity > Minimalism > Forward focus) govern planning-level decisions. When both apply, Safety (gates) takes precedence over all P2-P10.\n\n**Values**: Mini-PR > monolithic; parallel > sequential; function-level > code details; dependency clarity > implicit coupling; ship-ready > half-built\n\n## 2. Mini-PR Chunks\n\nEach chunk must:\n1. Ship complete value (demo independently)\n2. Pass all gates (type checks, tests, lint)\n3. Be mergeable alone (1-3 functions, <200 lines of code)\n4. Include its tests (name specific inputs/scenarios, e.g., \"valid email accepts user@domain.com\", \"invalid rejects missing @\")\n\n## 3. Chunk Sizing\n\n| Complexity | Chunks | Guidance |\n|------------|--------|----------|\n| Simple | 1-2 | 1-3 functions each |\n| Medium | 3-5 | <200 lines of code per chunk |\n| Complex | 5-8 | Each demo-able |\n| Integration | +1 final | Connect prior work |\n\n**Decision guide**: New model/schema â†’ types chunk first | >3 files or >5 functions â†’ split by concern | Complex integration â†’ foundation then integration | One module <200 lines of code â†’ single chunk OK\n\n## 4. Dependency Ordering\n\n- **True dependencies**: uses types, calls functions, extends\n- **False dependencies**: same feature, no interaction (parallelize these)\n- Minimize chains: Aâ†’B and Aâ†’C, then B,Câ†’D (not Aâ†’Bâ†’Câ†’D)\n- Circular dependencies: If chunks form a cycle (A needs B, B needs C, C needs A), extract shared interfaces/types into a new foundation chunk that breaks the cycle\n- Number chunks; mark parallel opportunities\n\n## 5. What Belongs\n\n| Belongs | Does Not Belong |\n|---------|-----------------|\n| Numbered chunks, gates, todo descriptions | Code snippets |\n| File manifests with reasons | Extra features, future-proofing |\n| Function names only | Performance tuning, assumed knowledge |\n\n## 6. Cognitive Load\n\n- Deep modules first: fewer with simple interfaces, hide complexity\n- Minimize indirection: layers only for concrete extension\n- Composition root: one wiring point\n- Decide late: abstraction only when PR needs extension\n- Framework at edges: core logic agnostic, thin adapters\n- Reduce choices: one idiomatic approach per concern\n- Measure: if understanding the chunk's purpose requires reading more than 3 files or tracing more than 5 function calls, simplify it\n\n## 7. Common Patterns\n\n| Pattern | Flow |\n|---------|------|\n| Sequential | Model â†’ Logic â†’ API â†’ Error handling |\n| Parallel after foundation | Model â†’ CRUD ops (parallel) â†’ Integration |\n| Pipeline | Types â†’ Parse/Transform (parallel) â†’ Format â†’ Errors |\n| Authentication | User model â†’ Login â†’ Auth middleware â†’ Logout |\n| Search | Data structure â†’ Algorithm â†’ API â†’ Ranking |\n\n## 8. Plan Template\n\n```markdown\n# IMPLEMENTATION PLAN: [Feature]\n\n[1-2 sentences]\n\nGates: Type checks (0 errors), Tests (pass), Lint (clean)\n\n---\n\n## Requirement Coverage\n- [Spec requirement] â†’ Chunk N\n- [Spec requirement] â†’ Chunk M, Chunk N\n\n---\n\n## 1. [Name]\n\nDepends on: - | Parallel: -\n\n[What this delivers]\n\nFiles to modify:\n- path.ts - [changes]\n\nFiles to create:\n- new.ts - [purpose]\n\nContext files:\n- reference.ts - [why relevant]\n\nNotes: [Assumptions, risks, alternatives]\n\nTasks:\n- Implement fn() - [purpose]\n- Tests - [cases]\n- Run gates\n\nAcceptance criteria:\n- Gates pass\n- [Specific verifiable criterion]\n\nKey functions: fn(), helper()\nTypes: TypeName\n```\n\n### Good Example\n\n```markdown\n## 2. Add User Validation Service\n\nDepends on: 1 (User types) | Parallel: 3\n\nImplements email/password validation with rate limiting.\n\nFiles to modify:\n- src/services/user.ts - Add validateUserInput()\n\nFiles to create:\n- src/services/validation.ts - Validation + rate limiter\n\nContext:\n- src/services/auth.ts:45-80 - Existing validation patterns\n- src/types/user.ts - User types from chunk 1\n\nTasks:\n- validateEmail() - RFC 5322\n- validatePassword() - Min 8, 1 number, 1 special\n- rateLimit() - 5 attempts/min/IP\n- Tests: valid email, invalid formats, password edges, rate limit\n- Run gates\n\nAcceptance criteria:\n- Gates pass\n- validateEmail() rejects invalid formats, accepts valid RFC 5322\n- validatePassword() enforces min 8, 1 number, 1 special\n- Rate limiter blocks after 5 attempts/min/IP\n\nFunctions: validateUserInput(), validateEmail(), rateLimit()\nTypes: ValidationResult, RateLimitConfig\n```\n\n### Bad Example\n\n```markdown\n## 2. User Stuff\nAdd validation for users.\nFiles: user.ts\nTasks: Add validation, Add tests\n```\n\n**Why bad**: No dependencies, vague description, missing full paths, no context files, generic tasks, no functions listed, no acceptance criteria.\n\n## 9. File Manifest & Context\n\n- Every file to modify/create; specify changes and purpose\n- Full paths; zero prior knowledge assumed\n- Context files: explain WHY; line ranges for files >500 lines\n\n## 10. Quality Criteria\n\n| Level | Criteria |\n|-------|----------|\n| Good | Each chunk ships value; dependencies ordered; parallel identified; files explicit; context has reasons; tests in todos; gates listed |\n| Excellent | + optimal parallelization, line numbers, clear integration, risks, alternatives, reduces cognitive load |\n\n### Quality Checklist\n\n**MUST verify**:\n- [ ] Correctness: boundaries, null/empty, error paths\n- [ ] Type Safety: types prevent invalid states; validation at boundaries\n- [ ] Tests: critical + error + boundary paths\n\n**SHOULD verify**:\n- [ ] Observability: errors logged with context\n- [ ] Resilience: timeouts, retries with backoff, cleanup\n- [ ] Clarity: descriptive names, no magic values\n- [ ] Modularity: single responsibility, <200 lines of code, minimal coupling\n- [ ] Evolution: public API/schema changes have migration\n\n### Test Priority\n\n| Priority | What | Requirement |\n|----------|------|-------------|\n| 9-10 | Data mutations, money, auth, state machines | MUST |\n| 7-8 | Business logic, API contracts, errors | SHOULD |\n| 5-6 | Edge cases, boundaries, integration | GOOD |\n| 1-4 | Trivial getters, pass-through | OPTIONAL |\n\n### Error Handling\n\nFor external systems/user input, specify:\n1. What can fail\n2. How failures surface\n3. Recovery strategy\n\nAvoid: empty catch, catch-return-null, silent fallbacks, broad catching.\n\n## 11. Problem Scenarios\n\n| Scenario | Action |\n|----------|--------|\n| No detailed requirements | Research â†’ core requirements/constraints unclear: ask via AskUserQuestion OR stop â†’ non-critical: assume+document |\n| Extensive requirements | MUSTs first â†’ research scope â†’ ask priority trade-offs â†’ defer SHOULD/MAY |\n| Multiple approaches | Research first â†’ ask only when significantly different implications |\n| Everything dependent | Start from types â†’ question each dependency â†’ find false dependencies â†’ foundation â†’ parallel â†’ integration |\n\n## Planning Mantras\n\n**Memento (always):**\n1. Write findings BEFORE next step (research log = external memory)\n2. Every discovery needing follow-up â†’ todo\n3. Update research log after EACH step\n\n**Primary:**\n4. Smallest shippable increment?\n5. Passes all gates?\n6. Explicitly required?\n7. Passes review first submission?\n\n**Secondary:**\n8. Ship with less?\n9. Dependencies determine order?\n10. Researched first, asked strategically?\n11. Reduces cognitive load?\n12. Satisfies P1-P10?\n13. Error paths planned?\n\n### Never Do\n\n- Proceed without writing findings\n- Keep discoveries as mental notes\n- Skip todos\n- Write to project directories (always `/tmp/`)\n- Ask scope/requirements questions (that's spec phase)\n- Finalize with `[TBD]`\n- Implement without approval\n- Forget expanding todos on new areas\n\n## Recognize & Adjust\n\n| Symptom | Action |\n|---------|--------|\n| Chunk >200 lines of code | Split by concern |\n| No clear value | Merge or refocus |\n| Dependencies unclear | Make explicit, number |\n| Context missing | Add files + line numbers |"
              },
              {
                "name": "research-web",
                "description": "Deep web research with parallel investigators, multi-wave exploration, and structured synthesis. Spawns multiple web-researcher agents to explore different facets of a topic simultaneously, launches additional waves when gaps are identified, then synthesizes findings. Use when asked to research, investigate, compare options, find best practices, or gather comprehensive information from the web.\\n\\nThoroughness: quick for factual lookups | medium for focused topics | thorough for comparisons/evaluations (waves continue while critical gaps remain) | very-thorough for comprehensive research (waves continue until satisficed). Auto-selects if not specified.",
                "path": "claude-plugins/vibe-workflow/skills/research-web/SKILL.md",
                "frontmatter": {
                  "name": "research-web",
                  "description": "Deep web research with parallel investigators, multi-wave exploration, and structured synthesis. Spawns multiple web-researcher agents to explore different facets of a topic simultaneously, launches additional waves when gaps are identified, then synthesizes findings. Use when asked to research, investigate, compare options, find best practices, or gather comprehensive information from the web.\\n\\nThoroughness: quick for factual lookups | medium for focused topics | thorough for comparisons/evaluations (waves continue while critical gaps remain) | very-thorough for comprehensive research (waves continue until satisficed). Auto-selects if not specified.",
                  "context": "fork"
                },
                "content": "**Research request**: $ARGUMENTS\n\n# Thoroughness Level\n\n**FIRST**: Determine thoroughness before researching. Parse from natural language (e.g., \"quick lookup\", \"thorough research\", \"comprehensive analysis\") or auto-select based on query characteristics.\n\n**Auto-selection logic**:\n- Single fact/definition/date â†’ quick\n- Focused question about one topic â†’ medium\n- Comparison, evaluation, or \"best\" questions â†’ thorough\n- \"comprehensive\"/\"all options\"/\"complete analysis\"/\"deep dive\" â†’ very-thorough\n\n**Explicit user preference**: If user explicitly specifies a thoroughness level (e.g., \"do a quick lookup\", \"thorough research on X\"), honor that request regardless of other triggers in the query.\n\n**Trigger conflicts (auto-selection only)**: When auto-selecting and query contains triggers from multiple levels, use the highest level indicated (very-thorough > thorough > medium > quick).\n\n| Level | Agents/Wave | Wave Policy | Behavior | Triggers |\n|-------|-------------|-------------|----------|----------|\n| **quick** | 1 | Single wave | Single web-researcher, no orchestration file, direct answer | \"what is\", \"when did\", factual lookups, definitions |\n| **medium** | 1-2 | Single wave | Orchestration file, focused research on 1-2 angles | specific how-to, single technology, focused question |\n| **thorough** | 2-4 | Continue while critical gaps remain | Full memento, parallel agents, cross-reference, follow-up waves for critical gaps | \"compare\", \"best options\", \"evaluate\", \"pros and cons\" |\n| **very-thorough** | 4-6 | Continue until comprehensive OR diminishing returns | Multi-wave research until all significant gaps addressed or new waves stop yielding value | \"comprehensive\", \"complete analysis\", \"all alternatives\", \"deep dive\" |\n\n**Multi-wave research**: For thorough and very-thorough levels, research continues in waves until satisficing criteria are met. Each wave can spawn new investigators to address gaps, conflicts, or newly discovered areas from previous waves. There is no hard maximum - waves continue as long as they're productive and gaps remain at the triggering threshold.\n\n**Ambiguous queries**: If thoroughness cannot be determined AND the query is complex (involves comparison, evaluation, or multiple facets), ask the user:\n\n```\nI can research this at different depths:\n- **medium**: Focused research on core aspects (~3-5 min)\n- **thorough**: Multi-angle investigation with cross-referencing (~8-12 min)\n- **very-thorough**: Comprehensive analysis covering all facets (~15-20 min)\n\nWhich level would you prefer? (Or I can auto-select based on your query)\n```\n\nState: `**Thoroughness**: [level] â€” [reason]` then proceed.\n\n---\n\n# Deep Web Research Skill\n\nOrchestrate parallel web researchers to comprehensively investigate a topic through iterative waves, then synthesize findings into actionable intelligence.\n\n**Loop**: Determine thoroughness â†’ Decompose topic â†’ Launch Wave 1 â†’ Collect findings â†’ Evaluate gaps â†’ [If gaps significant AND waves remaining: Launch next wave â†’ Collect â†’ Evaluate â†’ Repeat] â†’ Synthesize â†’ Output\n\n**Orchestration file**: `/tmp/research-orchestration-{topic-slug}-{YYYYMMDD-HHMMSS}.md` - external memory for tracking multi-wave research progress and synthesis.\n\n---\n\n# Satisficing Criteria\n\nResearch continues in waves until satisficing criteria are met for the given thoroughness level.\n\n## Wave Continuation by Level\n\n| Level | Continue When | Stop When (Satisficed) |\n|-------|---------------|------------------------|\n| quick | N/A | Always single wave |\n| medium | N/A | Always single wave |\n| thorough | Critical gaps remain AND previous wave was productive AND â‰¤50% source overlap with prior waves | No critical gaps OR diminishing returns OR >50% source overlap |\n| very-thorough | Significant gaps remain AND previous wave was productive AND â‰¤50% source overlap with prior waves | Comprehensive coverage (no significant gaps) OR diminishing returns OR >50% source overlap |\n\n**No hard maximum**: For thorough and very-thorough, waves continue based on necessity, not arbitrary limits. The satisficing criteria drive when to stop.\n\n**Source overlap**: Percentage of sources in current wave that were also cited in any previous wave. >50% overlap indicates research is cycling through same sources.\n\n## Gap Classification\n\nAfter each wave, classify identified gaps:\n\n| Gap Type | Definition | Triggers New Wave? |\n|----------|------------|-------------------|\n| **Critical** | Core question aspect unanswered, major conflicts unresolved, key comparison missing | Yes (thorough, very-thorough) |\n| **Significant** | Important facet unexplored, partial answer needs depth, newly discovered area | Yes (very-thorough only) |\n| **Minor** | Nice-to-have detail, edge case unclear, tangential info | No - note in limitations |\n\n## Satisficing Evaluation\n\nAfter Phase 4 (Cross-Reference), evaluate whether to continue:\n\n**Definitions**:\n- **Finding**: A distinct piece of information answering part of the research question, with at least one source citation. Multiple sources confirming the same fact count as one finding with higher confidence.\n- **Substantive finding**: A finding that provides new information not already established in previous waves. Variations or restatements of known information do not count.\n- **High-authority source**: Official documentation, peer-reviewed research, established news outlets (e.g., major tech publications), or sources from recognized domain experts. Company blogs about their own products count as high-authority for factual claims about that product.\n- **Independent sources**: Sources with different underlying information origins. Two articles citing the same primary source count as one source. Multiple pages from the same domain count as one source unless they represent different authors/teams with distinct research.\n- **High confidence**: Finding corroborated by â‰¥3 independent sources OR â‰¥2 high-authority sources.\n- **Medium confidence**: Finding corroborated by 2 independent sources OR 1 high-authority source.\n- **Low confidence**: Finding from a single non-authoritative source with no corroboration.\n- **Medium+ confidence**: Confidence level of Medium or High (i.e., not Low, Contested, or Inconclusive).\n\n**Satisficed when ANY true**:\n- All critical gaps addressed (thorough) OR all significant gaps addressed (very-thorough)\n- Diminishing returns detected: new wave revealed <2 new substantive findings AND no finding's confidence increased by at least one level AND no new areas discovered\n- User explicitly requested stopping or a specific wave count\n- Comprehensive coverage achieved: all identified facets addressed with medium+ confidence\n\n**Continue when ALL true**:\n- Gaps exist at the triggering threshold:\n  - thorough: Critical gaps remain (core question unanswered, major conflicts)\n  - very-thorough: Significant gaps remain (important facets unexplored, conflicts, newly discovered areas)\n- Previous wave was productive (â‰¥2 new substantive findings OR â‰¥1 finding's confidence increased by at least one level OR new areas discovered)\n- Research is still yielding value (â‰¤50% of sources in this wave were cited in previous waves)\n\n## Wave Planning\n\nWhen continuing to a new wave:\n1. Identify specific gaps to address (from Cross-Reference Analysis)\n2. Design targeted research prompts for each gap\n3. Assign 1-3 agents per wave (focused investigation)\n4. Update orchestration file with wave number and assignments\n5. Launch agents and collect findings\n6. Return to gap evaluation\n\n**Topic-slug format**: Extract 2-4 key terms (nouns and adjectives that identify the topic; exclude articles, prepositions, and generic words like \"best\", \"options\", \"analysis\"), lowercase, replace spaces with hyphens. Example: \"best real-time database options 2025\" â†’ `real-time-database-options`\n\n**Timestamp format**: `YYYYMMDD-HHMMSS`. Obtain via `date +%Y%m%d-%H%M%S`.\n\n## Phase 1: Initial Setup (skip for quick)\n\n### 1.1 Get timestamp & create todo list\n\nRun two commands:\n- `date +%Y%m%d-%H%M%S` â†’ for filename timestamp (e.g., `20260112-060615`)\n- `date '+%Y-%m-%d %H:%M:%S'` â†’ for human-readable \"Started\" field (e.g., `2026-01-12 06:06:15`)\n\nTodos = **research areas to investigate + memento operations**, not fixed steps. Each research todo represents a distinct angle or facet. List expands as decomposition reveals new areas. Memento todos ensure external memory stays current.\n\n**Starter todos** (seeds - list grows during decomposition):\n\n```\n- [ ] Create orchestration file\n- [ ] Topic decomposition & research planning\n- [ ] Write decomposition to orchestration file\n- [ ] (expand: research facets added during decomposition - e.g., \"Research: {facet 1}\")\n- [ ] (expand: Wave 1 agent assignments)\n- [ ] Launch Wave 1 agents\n- [ ] Collect Wave 1 findings â†’ write to orchestration file\n- [ ] Cross-reference findings â†’ write analysis to orchestration file\n- [ ] Evaluate gaps â†’ write gap evaluation to orchestration file\n- [ ] (expand: if continuing - Wave 2+ research todos)\n- [ ] Refresh context: read full orchestration file\n- [ ] Synthesize final output\n```\n\n**Critical memento todos** (never skip):\n- `Write {X} to orchestration file` - after EACH phase/agent completion\n- `Refresh context: read full orchestration file` - ALWAYS before synthesis\n\n**Expansion pattern**: As decomposition reveals facets, add specific research todos with write-to-log after each collection:\n```\n- [x] Create orchestration file\n- [x] Topic decomposition & research planning\n- [x] Write decomposition to orchestration file\n- [ ] Research: Real-time database landscape 2025\n- [ ] Research: Performance benchmarks\n- [ ] Research: Conflict resolution strategies\n- [ ] Research: Production case studies\n- [ ] Launch Wave 1 agents (4 parallel)\n- [ ] Collect Agent 1 findings â†’ write to orchestration file\n- [ ] Collect Agent 2 findings â†’ write to orchestration file\n- [ ] Collect Agent 3 findings â†’ write to orchestration file\n- [ ] Collect Agent 4 findings â†’ write to orchestration file\n- [ ] Cross-reference all findings â†’ write analysis to orchestration file\n- [ ] Evaluate gaps â†’ write gap evaluation to orchestration file\n- [ ] (if continuing: Wave 2 research todos with write-to-log)\n- [ ] Refresh context: read full orchestration file\n- [ ] Synthesize final output\n```\n\n### 1.2 Create orchestration file (skip for quick)\n\nPath: `/tmp/research-orchestration-{topic-slug}-{YYYYMMDD-HHMMSS}.md`\n\n```markdown\n# Web Research Orchestration: {topic}\nTimestamp: {YYYYMMDD-HHMMSS}\nStarted: {YYYY-MM-DD HH:MM:SS}\nThoroughness: {level}\nWave Policy: {single wave | continue while critical gaps | continue until comprehensive}\n\n## Research Question\n{Clear statement of what needs to be researched}\n\n## Topic Decomposition\n- Core question: {main thing to answer}\n- Facets to investigate: (populated in Phase 2)\n- Expected researcher count: {based on thoroughness level}\n\n## Wave Tracking\n| Wave | Agents | Focus | Status | New Findings | Decision |\n|------|--------|-------|--------|--------------|----------|\n| 1 | {count} | Initial investigation | Pending | - | - |\n\n## Research Assignments\n(populated in Phase 2)\n\n## Agent Status\n(updated as agents complete)\n\n## Collected Findings\n(populated as agents return)\n\n## Cross-Reference Analysis\n(populated after each wave)\n\n## Gap Evaluation\n(populated after each wave - drives continuation decisions)\n\n## Synthesis Notes\n(populated in final phase)\n```\n\n## Phase 2: Topic Decomposition & Agent Assignment\n\n### 2.1 Decompose the research topic into ORTHOGONAL facets\n\nBefore launching agents, analyze the query to identify **non-overlapping** research angles. Each agent should have a distinct domain with clear boundaries.\n\n1. **Core question**: What is the fundamental thing being asked?\n2. **Facets**: What distinct aspects need investigation? Ensure minimal overlap:\n   - Technical aspects (how it works, implementation details)\n   - Comparison aspects (alternatives, competitors, trade-offs)\n   - Practical aspects (real-world usage, adoption, case studies)\n   - Current state (recent developments, 2025 updates)\n   - Limitations/concerns (drawbacks, issues, criticisms)\n\n3. **Orthogonality check**: Before assigning agents, verify:\n   - Each facet covers a distinct domain\n   - No two facets would naturally search the same queries\n   - Boundaries are clear enough to state explicitly\n\n**Bad decomposition** (overlapping):\n- Agent 1: \"Research Firebase\"\n- Agent 2: \"Research real-time databases\" â† Firebase is a real-time database, overlap!\n\n**Good decomposition** (orthogonal):\n- Agent 1: \"Research Firebase specifically - features, pricing, limits\"\n- Agent 2: \"Research non-Firebase alternatives: Supabase, Convex, PlanetScale\"\n\n### 2.2 Plan agent assignments with explicit boundaries\n\n| Facet | Research Focus | Explicitly EXCLUDE |\n|-------|----------------|-------------------|\n| {facet 1} | \"{what to research}\" | \"{what other agents cover}\" |\n| {facet 2} | \"{what to research}\" | \"{what other agents cover}\" |\n\n**Agent count by level**:\n- medium: 1-2 agents (core + one related angle)\n- thorough: 2-4 agents (core + alternatives + practical + concerns)\n- very-thorough: 4-6 agents (comprehensive coverage of all facets)\n\n**If decomposition reveals more facets than agent count allows**:\n- Prioritize facets by: (1) directly answers core question, (2) enables comparison if requested, (3) addresses user-specified concerns\n- Combine related facets into single agent assignments where orthogonality allows\n- Schedule remaining facets for Wave 2 if initial wave is productive\n\n**Orthogonality strategies**:\n- By entity: Agent 1 = Product A, Agent 2 = Product B (not both \"products\")\n- By dimension: Agent 1 = Performance, Agent 2 = Pricing, Agent 3 = Security\n- By time: Agent 1 = Current state, Agent 2 = Historical evolution\n- By perspective: Agent 1 = Official docs, Agent 2 = Community experience\n\n### 2.3 Expand todos for each research area\n\nAdd a todo for each planned agent assignment:\n\n```\n- [x] Topic decomposition & research planning\n- [ ] Research: {facet 1 description}\n- [ ] Research: {facet 2 description}\n- [ ] Research: {facet 3 description}\n- [ ] ...\n- [ ] Collect and cross-reference findings\n- [ ] Synthesize final output\n```\n\n### 2.4 Update orchestration file\n\nAfter decomposition, update the file:\n\n```markdown\n## Topic Decomposition\n- Core question: {main question}\n- Facets identified:\n  1. {facet 1}: {why this angle matters}\n  2. {facet 2}: {why this angle matters}\n  ...\n\n## Research Assignments\n| Agent | Facet | Prompt | Status |\n|-------|-------|--------|--------|\n| 1 | {facet} | \"{prompt}\" | Pending |\n| 2 | {facet} | \"{prompt}\" | Pending |\n...\n```\n\n## Phase 3: Launch Parallel Researchers\n\n### 3.1 Launch web-researcher agents\n\nUse Task tool with `subagent_type: \"vibe-workflow:web-researcher\"` for each research angle. **Launch agents in parallel** (single message with multiple Task tool calls) to maximize efficiency.\n\n**Wave 1 prompt template** (broad exploration with boundaries):\n```\n{Specific research question for this facet}\n\nYOUR ASSIGNED SCOPE:\n- Focus areas: {specific aspect 1}, {specific aspect 2}, {specific aspect 3}\n- This is YOUR domain - go deep on these topics\n\nDO NOT RESEARCH (other agents cover these):\n- {facet assigned to Agent 2}\n- {facet assigned to Agent 3}\n- {etc.}\n\nCurrent date context: {YYYY-MM-DD} - prioritize recent sources.\n\n---\nResearch context:\n- Wave: 1 (initial investigation)\n- Mode: Broad exploration within your assigned scope\n- Stay within your boundaries - other agents handle the excluded areas\n- Report any gaps or conflicts you discover for potential follow-up waves\n```\n\n**Wave 2+ prompt template** (gap-filling):\n```\n{Specific gap or conflict to resolve}\n\nContext from previous waves:\n- Previous findings: {summary of relevant findings from earlier waves}\n- Gap being addressed: {specific gap - e.g., \"Sources conflict on X\" or \"Y aspect unexplored\"}\n- What we already know: {established facts from Wave 1}\n\nYOUR ASSIGNED SCOPE:\n- Focus narrowly on: {targeted aspect 1}, {targeted aspect 2}\n- This gap was identified because: {why previous research was insufficient}\n\nDO NOT RESEARCH:\n- Topics already well-covered in Wave 1 (don't repeat)\n- {areas other Wave 2 agents are handling}\n\nCurrent date context: {YYYY-MM-DD} - prioritize recent sources.\n\n---\nResearch context:\n- Wave: {N} (gap-filling)\n- Mode: Targeted investigation - focus narrowly on the gap above\n- Build on previous findings, don't repeat broad exploration\n- Flag if this gap cannot be resolved (conflicting authoritative sources, no data available, etc.)\n```\n\n**Batching rules**:\n- thorough: Launch all 2-4 agents in a single parallel batch\n- very-thorough: Launch in batches of 3-4 agents; for 5 agents use 3+2, for 6 agents use 3+3 (avoid overwhelming context)\n- Wave 2+: Launch 1-3 focused agents per wave\n\n### 3.2 Update orchestration file after each agent completes\n\nAfter EACH agent returns, immediately update:\n\n```markdown\n## Agent Status\n| Agent | Facet | Status | Key Finding |\n|-------|-------|--------|-------------|\n| 1 | {facet} | Complete | {1-sentence summary} |\n| 2 | {facet} | Complete | {1-sentence summary} |\n...\n\n## Collected Findings\n\n### Agent 1: {facet}\n**Confidence**: {High/Medium/Low/Contested/Inconclusive}\n**Sources**: {count}\n\n{Paste key findings from agent - preserve source citations}\n{If Contested: note the conflicting positions}\n{If Inconclusive: note what couldn't be determined}\n\n### Agent 2: {facet}\n...\n```\n\n### 3.3 Handle agent failures\n\nIf an agent times out or returns incomplete results:\n1. Note the gap in orchestration file\n2. Decide based on facet criticality:\n   - **Retry** (narrower prompt) if: facet covers a Critical gap for the research question, OR facet is explicitly required by the research question for comparison/evaluation (e.g., query asks to compare X and Y, and facet covers X or Y), OR user explicitly requested this facet\n   - **Mark as gap** (don't retry) if: facet covers a Significant or Minor gap, OR other agents partially covered the topic, OR research can synthesize without this facet\n3. Never block synthesis for a single failed agent - proceed with available findings and note the limitation\n4. If ALL agents in a wave fail:\n   - For Wave 1: Retry with simpler decomposition (fewer agents, broader prompts)\n   - For Wave 2+: Mark gaps as unresolvable, proceed to synthesis with prior wave findings\n   - Always note the systemic failure in Gaps & Limitations\n\n## Phase 4: Collect, Cross-Reference & Evaluate Gaps\n\n### 4.1 Mark collection todo in_progress\n\n### 4.2 Analyze findings across agents\n\nLook for:\n- **Agreements**: Where do multiple agents reach similar conclusions?\n- **Conflicts**: Where do findings contradict? (includes agent-reported \"Contested\" findings)\n- **Inconclusive**: Areas where agents couldn't determine answers\n- **Gaps**: What wasn't covered by any agent?\n- **Surprises**: Unexpected findings that warrant highlighting\n\n**Handling agent confidence levels**:\n- **High/Medium/Low**: Standard confidence - use for cross-referencing\n- **Contested**: Agent found high-authority sources that directly contradict each other - treat as a conflict requiring resolution or presentation of both positions\n- **Inconclusive**: Agent couldn't find agreement among sources - may warrant follow-up wave with different search angles\n\n### 4.3 Update orchestration file with cross-reference\n\n```markdown\n## Cross-Reference Analysis\n\n### Agreements (High Confidence)\n- {Finding}: Supported by agents {1, 3, 4}\n- {Finding}: Confirmed across {count} sources\n\n### Conflicts (Requires Judgment)\n- {Topic}: Agent 1 says X, Agent 3 says Y\n  - Resolution: {which to trust and why, or present both}\n- {Topic}: Agent 2 reported as Contested - {Position A} vs {Position B}\n  - Resolution: {present both with supporting sources, or identify which is more authoritative}\n\n### Inconclusive Areas\n- {Topic}: Agent {N} couldn't determine - {reason}\n  - Action: {follow-up wave with different angles, or note as limitation}\n\n### Gaps Identified\n- {What wasn't answered}\n- {Areas needing more research}\n\n### Key Insights\n- {Synthesis observation 1}\n- {Synthesis observation 2}\n```\n\n### 4.4 Evaluate gaps and decide next wave (skip for quick/medium)\n\n**For thorough and very-thorough levels**, classify each gap:\n\n```markdown\n## Gap Evaluation (Wave {N})\n\n### Critical Gaps (triggers thorough/very-thorough continuation)\n- [ ] {Gap}: {Why critical - core question aspect unanswered}\n- [ ] {Gap}: {Why critical - major conflict unresolved}\n\n### Significant Gaps (triggers very-thorough continuation)\n- [ ] {Gap}: {Why significant - important facet unexplored}\n- [ ] {Gap}: {Why significant - partial answer needs depth}\n- [ ] {Gap}: {Why significant - newly discovered area worth exploring}\n\n### Minor Gaps (note in limitations, don't pursue)\n- {Gap}: {Why minor - nice-to-have detail}\n\n### Wave Productivity Assessment\n- New substantive findings this wave: {count}\n- Confidence improvements: {which areas improved}\n- New areas discovered: {list or \"none\"}\n- Diminishing returns signals: {yes/no - explain}\n\n### Wave Decision\n- Current wave: {N}\n- Thoroughness level: {level}\n- Wave policy: {single wave | continue while critical gaps | continue until comprehensive}\n- Critical gaps remaining: {count}\n- Significant gaps remaining: {count}\n- Was this wave productive? {yes/no - â‰¥2 findings OR confidence improved OR new areas}\n- **Decision**: {CONTINUE to Wave N+1 | SATISFICED - proceed to synthesis}\n- **Reason**: {explain based on satisficing criteria - what gaps remain or why comprehensive}\n```\n\n### 4.5 Wave Decision Logic\n\n**If SATISFICED** (any of these true):\n- Level is quick or medium â†’ Proceed to Phase 5\n- No critical gaps (thorough) or no significant gaps (very-thorough) â†’ Proceed to Phase 5\n- Diminishing returns: previous wave yielded <2 new substantive findings AND no finding's confidence increased by at least one level AND no new areas discovered â†’ Proceed to Phase 5\n- Comprehensive coverage achieved: all identified facets addressed with medium+ confidence â†’ Proceed to Phase 5\n- User explicitly requested stopping\n\n**If CONTINUE** (all of these true):\n- Gaps exist at triggering threshold:\n  - thorough: Critical gaps remain\n  - very-thorough: Significant gaps remain\n- Previous wave was productive (â‰¥2 new substantive findings OR â‰¥1 finding's confidence increased by at least one level OR new areas discovered)\n- Not cycling through same sources (â‰¤50% of sources in this wave were cited in previous waves)\n\n### 4.6 Launch Next Wave (if continuing)\n\nWhen continuing to a new wave:\n\n1. **Update Wave Tracking table** in orchestration file:\n```markdown\n## Wave Tracking\n| Wave | Agents | Focus | Status | New Findings |\n|------|--------|-------|--------|--------------|\n| 1 | 4 | Initial investigation | Complete | 12 findings |\n| 2 | 2 | Gap-filling: {focus areas} | In Progress | - |\n```\n\n2. **Add wave-specific todos**:\n```\n- [ ] Wave 2: Investigate {critical gap 1}\n- [ ] Wave 2: Resolve conflict on {topic}\n- [ ] Wave 2: Deep-dive {significant gap}\n```\n\n3. **Design targeted prompts** for gaps:\n   - Be specific: \"Resolve conflict between X and Y regarding Z\"\n   - Include context: \"Previous research found A, but need clarification on B\"\n   - Narrower scope than Wave 1 agents\n\n4. **Launch 1-3 agents** for this wave (focused investigation)\n   - Use Task tool with `subagent_type: \"vibe-workflow:web-researcher\"`\n   - Prompts reference specific gaps, not broad topics\n\n5. **Collect findings** and return to 4.2 (cross-reference including new findings)\n\n### 4.7 Mark collection todo complete (when proceeding to synthesis)\n\n## Phase 5: Synthesize & Output\n\n### 5.1 Refresh context (MANDATORY - never skip)\n\n**CRITICAL**: This is the key memento step. Read the FULL orchestration file using the Read tool to restore ALL findings, cross-references, gap evaluations, and wave tracking into context.\n\n**Why this matters**: By this point, findings from multiple agents across potentially multiple waves have been written to the orchestration file. Context degradation means these details may have faded. Reading the full file immediately before synthesis brings all findings into recent context where attention is strongest.\n\n**Todo must show**:\n```\n- [x] Refresh context: read full orchestration file  â† Must be marked complete before synthesis\n- [ ] Synthesize final output\n```\n\n**Verification**: After reading, you should have access to:\n- All collected findings from every agent\n- Cross-reference analysis (agreements, conflicts, inconclusive)\n- Gap evaluations from each wave\n- Wave tracking with decisions\n- All source citations\n\n### 5.2 Mark synthesis todo in_progress\n\n### 5.3 Generate comprehensive output\n\n**Only after completing 5.1** - synthesize ALL agent findings into a cohesive answer. Include:\n\n```markdown\n## Research Findings: {Topic}\n\n**Thoroughness**: {level} | **Waves**: {count} | **Researchers**: {total across waves} | **Total Sources**: {aggregate}\n**Overall Confidence**: High/Medium/Low (based on agreement and source quality)\n**Satisficing**: {reason research concluded - e.g., \"All significant gaps addressed\" or \"Diminishing returns after Wave 3\"}\n\n### Executive Summary\n{4-8 sentences synthesizing the key takeaway. What does the user need to know?}\n\n### Detailed Findings\n\n#### {Major Finding Area 1}\n{Synthesized insights with inline source citations from multiple agents}\n\n#### {Major Finding Area 2}\n{...}\n\n### Comparison/Evaluation (if applicable)\n| Option | Pros | Cons | Best For |\n|--------|------|------|----------|\n| {opt 1} | {from agents} | {from agents} | {synthesis} |\n| {opt 2} | {from agents} | {from agents} | {synthesis} |\n\n### Recommendations\n{Based on synthesized evidence - what should the user consider/do?}\n\n### Confidence Notes\n- **High confidence**: {findings with strong multi-source agreement}\n- **Medium confidence**: {findings with some support}\n- **Contested**: {where high-authority sources directly contradicted - present both positions}\n- **Inconclusive**: {where agents couldn't determine answers despite searching}\n- **Low confidence**: {single source or weak agreement}\n\n### Research Progression (for multi-wave)\n| Wave | Focus | Agents | Key Contribution |\n|------|-------|--------|------------------|\n| 1 | Initial investigation | {N} | {what this wave established} |\n| 2 | {Gap focus} | {N} | {what this wave resolved} |\n| ... | ... | ... | ... |\n\n### Gaps & Limitations\n- {What couldn't be definitively answered despite multi-wave investigation}\n- {Areas where more research would help}\n- {Potential biases in available sources}\n- {Gaps intentionally not pursued (minor priority)}\n\n### Source Summary\n| Source | Authority | Date | Used For | Wave |\n|--------|-----------|------|----------|------|\n| {url} | High/Med | {date} | {finding} | 1 |\n...\n\n---\nOrchestration file: {path}\nResearch completed: {timestamp}\n```\n\n### 5.4 Mark all todos complete\n\n## Quick Mode Flow\n\nFor quick (single-fact) queries, skip orchestration:\n\n1. State: `**Thoroughness**: quick â€” [reason]`\n2. Launch single web-researcher agent: `Task(\"vibe-workflow:web-researcher\", \"{query}\")`\n3. Return agent's findings directly (no synthesis overhead)\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| Thoroughness first | Determine level before any research |\n| Todos with write-to-log | Each collection gets a todo, followed by a write-to-orchestration-file todo |\n| Memento writes | Write to orchestration file after EACH phase/agent - external memory |\n| Parallel execution | Launch multiple agents simultaneously when possible |\n| Cross-reference | Compare findings across agents before synthesizing |\n| Gap evaluation | Classify gaps after each wave (critical/significant/minor) |\n| Wave iteration | Continue waves until satisficed OR diminishing returns |\n| **Context refresh** | **Read full orchestration file BEFORE synthesis - non-negotiable** |\n| Source preservation | Maintain citations through synthesis |\n| Gap honesty | Explicitly state what couldn't be answered despite multi-wave effort |\n\n**Memento Pattern Summary**:\n1. Create orchestration file at start\n2. Add write-to-log todos after each collection phase\n3. Write to it after EVERY step (decomposition, agent findings, cross-reference, gap evaluation)\n4. \"Refresh context: read full orchestration file\" todo before synthesis\n5. Read FULL file before synthesis (restores all context)\n\n## Never Do\n\n- Launch agents without determining thoroughness level\n- Skip write-to-log todos (every collection must be followed by a write todo)\n- Proceed to next phase without writing findings to orchestration file\n- Synthesize without completing \"Refresh context: read full orchestration file\" todo first\n- Skip orchestration file updates after agent completions\n- Present synthesized findings without source citations\n- Ignore conflicts between agent findings (especially \"Contested\" findings)\n- Skip gap evaluation for thorough/very-thorough levels\n- Continue waves when diminishing returns detected (wasted effort)\n- Stop prematurely when critical gaps remain (thorough) or significant gaps remain (very-thorough) and waves are still productive\n\n## Example: Technology Comparison\n\nQuery: \"Compare the best real-time databases for a collaborative app in 2025\"\n\n**Thoroughness**: thorough â€” comparison query requiring multi-angle investigation\n\n**Decomposition**:\n- Facet 1: Real-time database landscape 2025 (what options exist)\n- Facet 2: Performance and scalability comparisons\n- Facet 3: Collaborative app requirements (conflict resolution, sync)\n- Facet 4: Production experiences and case studies\n\n**Agents launched** (parallel):\n1. \"Real-time database options 2025: Firebase, Supabase, Convex, others. Current market landscape.\"\n2. \"Real-time database performance benchmarks and scalability. Latency, throughput, concurrent users.\"\n3. \"Conflict resolution and sync strategies for collaborative apps. CRDTs, OT, last-write-wins.\"\n4. \"Production case studies using real-time databases. Companies, scale, lessons learned.\"\n\n**Output**: Synthesized comparison table with recommendations based on use case, backed by cross-referenced sources from all four agents.\n\n## Example: Multi-Wave Comprehensive Research\n\nQuery: \"Give me a comprehensive analysis of all the AI coding assistant options in 2025\"\n\n**Thoroughness**: very-thorough â€” \"comprehensive analysis\" + \"all options\" triggers maximum depth\n\n### Wave 1: Initial Investigation\n**Decomposition** (6 orthogonal facets):\n- Facet 1: Market landscape - what tools exist (names only, no features/pricing)\n- Facet 2: Feature comparison - autocomplete, chat, agents, IDE support (no pricing)\n- Facet 3: Pricing and licensing - costs, tiers, enterprise deals (no features)\n- Facet 4: Enterprise/security - compliance, SOC2, on-prem (no general features)\n- Facet 5: Developer sentiment - reviews, community feedback (no official docs)\n- Facet 6: Recent news - announcements, launches, acquisitions (no evergreen content)\n\n**Agents launched with explicit boundaries** (parallel batch of 4, then 2):\n1. \"AI coding assistant market landscape 2025. YOUR SCOPE: List all tools (Copilot, Cursor, Claude Code, Codeium, etc). DO NOT RESEARCH: features, pricing, reviews.\"\n2. \"AI coding assistant features 2025. YOUR SCOPE: autocomplete, chat, agentic capabilities, IDE support. DO NOT RESEARCH: pricing, enterprise security, user reviews.\"\n3. \"AI coding assistant pricing 2025. YOUR SCOPE: subscription costs, usage-based models, free tiers. DO NOT RESEARCH: features, security compliance.\"\n4. \"Enterprise AI coding assistant compliance 2025. YOUR SCOPE: SOC2, HIPAA, on-premise, data residency. DO NOT RESEARCH: general features, consumer pricing.\"\n5. \"AI coding assistant developer sentiment 2025. YOUR SCOPE: Reddit, HN, Twitter discussions, community feedback. DO NOT RESEARCH: official documentation, pricing pages.\"\n6. \"AI coding assistant news 2025. YOUR SCOPE: recent announcements, launches, acquisitions since Jan 2025. DO NOT RESEARCH: established features, pricing.\"\n\n**Gap Evaluation (Wave 1)**:\n- Critical gaps: None (all facets had substantial findings)\n- Significant gaps:\n  - Conflict: Sources disagree on which tool has best agentic capabilities\n  - Partial answer: Enterprise pricing not fully detailed for all options\n  - New discovery: Several sources mention \"AI code review\" as emerging category\n- Minor gaps: Specific latency benchmarks, rare IDE integrations\n\n**Wave Decision**: CONTINUE â€” 3 significant gaps remain, Wave 1 was productive (18 findings), research still yielding new information\n\n### Wave 2: Gap-Filling\n**Focus**: Resolve agentic capabilities conflict, deepen enterprise pricing, explore AI code review\n\n**Agents launched** (3 focused):\n1. \"Compare agentic capabilities: Cursor Composer vs Claude Code vs GitHub Copilot Workspace 2025\"\n2. \"Enterprise AI coding assistant pricing 2025: Copilot Business, Cursor Teams, volume discounts\"\n3. \"AI code review tools 2025: CodeRabbit, Sourcery, Codacy AI. Emerging category analysis.\"\n\n**Gap Evaluation (Wave 2)**:\n- Critical gaps: None\n- Significant gaps: None remaining (conflict resolved, enterprise pricing clarified)\n- Minor gaps: Some niche tools not fully covered\n\n**Wave Decision**: SATISFICED â€” No significant gaps remaining, 2 waves complete\n\n### Output Summary\n**Thoroughness**: very-thorough | **Waves**: 2 | **Researchers**: 9 | **Sources**: 34\n**Satisficing**: All significant gaps addressed â€” comprehensive coverage achieved"
              },
              {
                "name": "review-bugs",
                "description": "Audit code for logical bugs, race conditions, edge cases, and error handling issues.",
                "path": "claude-plugins/vibe-workflow/skills/review-bugs/SKILL.md",
                "frontmatter": {
                  "name": "review-bugs",
                  "description": "Audit code for logical bugs, race conditions, edge cases, and error handling issues.",
                  "context": "fork"
                },
                "content": "Use the code-bugs-reviewer agent to perform a bug audit on: $ARGUMENTS\n\nIf no arguments provided, analyze the git diff between the current branch and main/master branch."
              },
              {
                "name": "review-claude-md-adherence",
                "description": "Verify code changes comply with CLAUDE.md instructions and project standards.",
                "path": "claude-plugins/vibe-workflow/skills/review-claude-md-adherence/SKILL.md",
                "frontmatter": {
                  "name": "review-claude-md-adherence",
                  "description": "Verify code changes comply with CLAUDE.md instructions and project standards.",
                  "context": "fork"
                },
                "content": "Use the claude-md-adherence-reviewer agent to audit code for CLAUDE.md compliance: $ARGUMENTS\n\nIf no arguments provided, analyze the git diff between the current branch and main/master branch."
              },
              {
                "name": "review-coverage",
                "description": "Verify test coverage for code changes. Analyzes diff against main and reports coverage gaps.",
                "path": "claude-plugins/vibe-workflow/skills/review-coverage/SKILL.md",
                "frontmatter": {
                  "name": "review-coverage",
                  "description": "Verify test coverage for code changes. Analyzes diff against main and reports coverage gaps.",
                  "context": "fork"
                },
                "content": "Use the code-coverage-reviewer agent to check test coverage for: $ARGUMENTS\n\nIf no arguments provided, analyze the git diff between the current branch and main/master branch."
              },
              {
                "name": "review-docs",
                "description": "Audit documentation accuracy against code changes. Reports discrepancies without modifying files.",
                "path": "claude-plugins/vibe-workflow/skills/review-docs/SKILL.md",
                "frontmatter": {
                  "name": "review-docs",
                  "description": "Audit documentation accuracy against code changes. Reports discrepancies without modifying files.",
                  "context": "fork"
                },
                "content": "Launch the docs-reviewer agent to audit documentation against your code changes and produce a report of what needs updating."
              },
              {
                "name": "review-maintainability",
                "description": "Audit code for DRY violations, dead code, complexity, and consistency issues.",
                "path": "claude-plugins/vibe-workflow/skills/review-maintainability/SKILL.md",
                "frontmatter": {
                  "name": "review-maintainability",
                  "description": "Audit code for DRY violations, dead code, complexity, and consistency issues.",
                  "context": "fork"
                },
                "content": "Use the code-maintainability-reviewer agent to perform a maintainability audit on: $ARGUMENTS\n\nIf no arguments provided, analyze the git diff between the current branch and main/master branch."
              },
              {
                "name": "review-type-safety",
                "description": "Audit TypeScript code for type safety issuesâ€”any/unknown abuse, invalid states, missing narrowing.",
                "path": "claude-plugins/vibe-workflow/skills/review-type-safety/SKILL.md",
                "frontmatter": {
                  "name": "review-type-safety",
                  "description": "Audit TypeScript code for type safety issuesâ€”any/unknown abuse, invalid states, missing narrowing.",
                  "context": "fork"
                },
                "content": "Use the type-safety-reviewer agent to audit type safety: $ARGUMENTS\n\nIf no arguments provided, analyze the git diff between the current branch and main/master branch."
              },
              {
                "name": "review",
                "description": "Run all code review agents in parallel (bugs, coverage, maintainability, type-safety if typed, CLAUDE.md adherence, docs).",
                "path": "claude-plugins/vibe-workflow/skills/review/SKILL.md",
                "frontmatter": {
                  "name": "review",
                  "description": "Run all code review agents in parallel (bugs, coverage, maintainability, type-safety if typed, CLAUDE.md adherence, docs)."
                },
                "content": "Run a comprehensive code review. First detect the codebase type, then launch appropriate agents.\n\n**Flags**: `--autonomous` â†’ skip Step 4 user prompt, return report only (for programmatic invocation)\n\n## Step 1: Detect Typed Language\n\nBefore launching agents, check if this is a typed language codebase:\n\n**TypeScript/JavaScript with types:**\n- `tsconfig.json` exists, OR\n- `.ts`/`.tsx` files in scope\n\n**Python with type hints:**\n- `py.typed` marker exists, OR\n- `mypy` or `pyright` in `pyproject.toml`/`setup.cfg`, OR\n- Type annotations visible in `.py` files (`: str`, `-> None`, `Optional[`, `List[`, etc.)\n\n**Statically typed languages (always typed):**\n- Java (`.java`), Kotlin (`.kt`), Go (`.go`), Rust (`.rs`), C# (`.cs`), Swift (`.swift`), Scala (`.scala`)\n\nQuick detection commands:\n```bash\n# TypeScript\nls tsconfig.json 2>/dev/null || git ls-files '*.ts' '*.tsx' | head -1\n\n# Python types\nls py.typed 2>/dev/null || grep -l \"mypy\\|pyright\" pyproject.toml setup.cfg 2>/dev/null | head -1\n\n# Other typed languages\ngit ls-files '*.java' '*.kt' '*.go' '*.rs' '*.cs' '*.swift' '*.scala' | head -1\n```\n\n## Step 2: Launch Agents\n\n**Always launch these 5 core agents IN PARALLEL:**\n\n1. **code-bugs-reviewer** - Audit for logical bugs, race conditions, edge cases\n2. **code-coverage-reviewer** - Verify test coverage for code changes\n3. **code-maintainability-reviewer** - Check for DRY violations, dead code, complexity\n4. **claude-md-adherence-reviewer** - Verify compliance with CLAUDE.md project standards\n5. **docs-reviewer** - Audit documentation and code comments accuracy\n\n**Conditionally launch (only if typed language detected):**\n\n6. **type-safety-reviewer** - Audit type safety, any/unknown abuse, invalid states\n   - **Primary:** TypeScript, Python with type hints (agent is optimized for these)\n   - **Also useful for:** Java, Kotlin, Go, Rust, C#, Swift, Scala (core principles apply)\n   - **Skip for:** Plain JavaScript, Ruby, PHP, shell scripts, untyped Python\n\nScope: $ARGUMENTS\n\nIf no arguments provided, all agents should analyze the git diff between the current branch and main/master branch.\n\n## Step 3: Verification Agent (Final Pass)\n\nAfter all review agents complete, launch an **opus verification agent** to reconcile and validate findings:\n\n**Purpose**: The review agents run in parallel and are unaware of each other's findings. This can lead to:\n- Conflicting recommendations (one agent suggests X, another suggests opposite)\n- Duplicate findings reported by multiple agents\n- Low-confidence or vague issues that aren't actionable\n- False positives that would waste time fixing\n\n**Verification Agent Task**:\n\nUse the Task tool with `model: opus` to launch a verification agent with this prompt:\n\n```\nYou are a Review Reconciliation Expert. Analyze the combined findings from all review agents and produce a final, consolidated report.\n\n## Input\n[Include all agent reports here]\n\n## Your Tasks\n\n1. **Identify Conflicts**: Find recommendations that contradict each other across agents. Resolve by:\n   - Analyzing which recommendation is more appropriate given the context\n   - Noting when both perspectives have merit (flag for user decision)\n   - Removing the weaker recommendation if clearly inferior\n\n2. **Remove Duplicates**: Multiple agents may flag the same underlying issue. Consolidate into single entries, keeping the most detailed/actionable version.\n\n3. **Filter Low-Confidence Issues**: Remove or downgrade issues that:\n   - Are vague or non-actionable (\"could be improved\" without specifics)\n   - Rely on speculation rather than evidence\n   - Would require significant effort for minimal benefit\n   - Are stylistic preferences not backed by project standards\n\n4. **Validate Severity**: Ensure severity ratings are consistent and justified:\n   - Critical: Will cause production failures or data loss\n   - High: Significant bugs or violations that should block release\n   - Medium: Real issues worth fixing but not blocking\n   - Low: Nice-to-have improvements\n\n5. **Flag Uncertain Items**: For issues where you're uncertain, mark them as \"Needs Human Review\" rather than removing them.\n\n## Output\n\nProduce a **Final Consolidated Review Report** with:\n- Executive summary (overall code health assessment)\n- Issues by severity (Critical â†’ Low), deduplicated and validated\n- Conflicts resolved (note any that need user decision)\n- Items removed with brief reasoning (transparency)\n- Recommended fix order (dependencies, quick wins first)\n```\n\n## Step 4: Follow-up Action\n\n**If `--autonomous`**: Skip user prompt, end after presenting report. Caller handles next steps.\n\n**Otherwise**, ask the user what they'd like to address:\n\n```\nheader: \"Next Steps\"\nquestion: \"Would you like to address any of these findings?\"\noptions:\n  - \"Critical/High only (Recommended)\" - Focus on issues that should block release\n  - \"All issues\" - Address everything including medium and low severity\n  - \"Skip\" - No fixes needed right now\n```\n\n**Based on selection:**\n- **Critical/High only**: `Skill(\"vibe-workflow:fix-review-issues\", \"--severity critical,high\")`\n- **All issues**: `Skill(\"vibe-workflow:fix-review-issues\")`\n- **Skip**: End workflow\n\n## Execution\n\n1. Run detection commands first (can be parallel)\n2. Based on results, launch either 5 or 6 agents simultaneously in a single message\n3. Do NOT run agents sequentiallyâ€”always parallel\n4. After all agents complete, launch the verification agent with all findings\n5. Present the final consolidated report to the user\n6. Ask user about next steps using AskUserQuestion\n7. If user chooses to fix, invoke /fix-review-issues with appropriate scope"
              },
              {
                "name": "spec",
                "description": "Builds requirements specification through structured discovery interview. Use when defining scope, gathering requirements, or specifying WHAT any work should accomplish - features, bugs, refactors, infrastructure, migrations, performance, documentation, or any other work type.",
                "path": "claude-plugins/vibe-workflow/skills/spec/SKILL.md",
                "frontmatter": {
                  "name": "spec",
                  "description": "Builds requirements specification through structured discovery interview. Use when defining scope, gathering requirements, or specifying WHAT any work should accomplish - features, bugs, refactors, infrastructure, migrations, performance, documentation, or any other work type."
                },
                "content": "**User request**: $ARGUMENTS\n\nBuild requirements spec through structured discovery interview. Defines WHAT and WHY - not technical implementation (architecture, APIs, data models come in planning phase).\n\n**If $ARGUMENTS is empty**: Ask user \"What work would you like to specify? (feature, bug fix, refactor, etc.)\" via AskUserQuestion before proceeding to Phase 1.\n\n**Loop**: Research â†’ Expand todos â†’ Ask questions â†’ Write findings â†’ Repeat until complete\n\n**Role**: Senior Product Manager - questions that uncover hidden requirements, edge cases, and assumptions the user hasn't considered. Reduce ambiguity through concrete options.\n\n**Spec file**: `/tmp/spec-{YYYYMMDD-HHMMSS}-{name-kebab-case}.md` - updated after each iteration.\n\n**Interview log**: `/tmp/spec-interview-{YYYYMMDD-HHMMSS}-{name-kebab-case}.md` - external memory.\n\n**Timestamp format**: `YYYYMMDD-HHMMSS` (e.g., `20260109-143052`). Generate once at Phase 1.1 start. Use same value for both file paths. Running /spec again creates new files (no overwrite).\n\n## Phase 1: Initial Setup\n\n### 1.1 Create todo list (TodoWrite immediately)\n\nTodos = **areas to discover**, not interview steps. Each todo reminds you what conceptual area needs resolution. List continuously expands as user answers reveal new areas. \"Finalize spec\" is fixed anchor; all others are dynamic.\n\n**Starter todos** (seeds only - list grows as discovery reveals new areas):\n\n```\n- [ ] Initial context research\n- [ ] Scope & target users\n- [ ] Core requirements\n- [ ] (expand continuously as answers reveal new areas)\n- [ ] Read full interview log (context refresh before output)\n- [ ] Finalize spec\n```\n\n### Todo Evolution Example\n\nQuery: \"Add user notifications feature\"\n\nInitial:\n```\n- [ ] Initial context research\n- [ ] Scope & target users\n- [ ] Core requirements\n- [ ] Read full interview log (context refresh before output)\n- [ ] Finalize spec\n```\n\nAfter user says \"needs to work across mobile and web\":\n```\n- [x] Initial context research â†’ found existing notification system for admin alerts\n- [ ] Scope & target users\n- [ ] Core requirements\n- [ ] Mobile notification delivery (push vs in-app)\n- [ ] Web notification delivery (browser vs in-app)\n- [ ] Cross-platform sync behavior\n- [ ] Read full interview log (context refresh before output)\n- [ ] Finalize spec\n```\n\nAfter user mentions \"also needs email digest option\":\n```\n- [x] Initial context research\n- [x] Scope & target users â†’ all active users, v1 MVP\n- [ ] Core requirements\n- [x] Mobile notification delivery â†’ push + in-app\n- [ ] Web notification delivery\n- [ ] Cross-platform sync behavior\n- [ ] Email digest frequency options\n- [ ] Email vs real-time preferences\n- [ ] Read full interview log (context refresh before output)\n- [ ] Finalize spec\n```\n\n**Key**: Todos grow as user reveals complexity. Never prune prematurely.\n\n### 1.2 Create interview log\n\nPath: `/tmp/spec-interview-{YYYYMMDD-HHMMSS}-{name-kebab-case}.md` (use SAME path for ALL updates)\n\n```markdown\n# Interview Log: {work name}\nStarted: {timestamp}\n\n## Research Phase\n(populated incrementally)\n\n## Interview Rounds\n(populated incrementally)\n\n## Decisions Made\n(populated incrementally)\n\n## Unresolved Items\n(populated incrementally)\n```\n\n## Phase 2: Initial Context Gathering\n\n**Prerequisites**: Requires vibe-workflow plugin with codebase-explorer and web-researcher agents installed. If Task tool fails with agent not found, inform user: \"Required agent {name} not available. Install vibe-workflow plugin or proceed with manual research?\" If proceeding manually, use Read/Glob/Grep for codebase exploration and note `[LIMITED RESEARCH: {agent} unavailable]` in interview log.\n\n### 2.1 Launch codebase-explorer\n\nUse Task tool with `subagent_type: \"vibe-workflow:codebase-explorer\"` to understand context. Launch multiple in parallel (single message) for cross-cutting work. Limit to 3 parallel researchers per batch. If findings conflict, immediately present both perspectives to user via AskUserQuestion: \"Research found conflicting information about {topic}: {perspective A} vs {perspective B}. Which applies to your situation?\" If user cannot resolve, document both perspectives in spec with `[CONTEXT-DEPENDENT: {perspective A} applies when X; {perspective B} applies when Y]` and ask follow-up to clarify applicability. If 3 researchers don't cover all needed areas, run additional batches sequentially.\n\nExplore: product purpose, existing patterns, user flows, terminology, product docs (CUSTOMER.md, SPEC.md, PRD.md, BRAND_GUIDELINES.md, DESIGN_GUIDELINES.md, README.md), existing specs in `docs/` or `specs/`. For bug fixes: also explore bug context, related code, potential causes.\n\n### 2.2 Read recommended files\n\nRead ALL files from researcher prioritized reading lists - no skipping.\n\n### 2.3 Launch web-researcher (if needed)\n\nUse Task tool with `subagent_type: \"vibe-workflow:web-researcher\"` when you cannot answer a question from codebase research alone and the answer requires: domain concepts unfamiliar to you, current industry standards or best practices, regulatory/compliance requirements, or competitor UX patterns. Do not use for questions answerable from codebase or general knowledge. Returns all findings in response - no additional file reads needed. Continue launching throughout interview as gaps emerge.\n\n### 2.4 Update interview log\n\nAfter EACH research step, append to interview log:\n\n```markdown\n### {HH:MM:SS} - {what researched}\n- Explored: {areas/topics}\n- Key findings: {list}\n- New areas identified: {list}\n- Questions to ask: {list}\n```\n\n### 2.5 Write initial draft\n\nWrite first draft with `[TBD]` markers for unresolved items. Use same file path for all updates.\n\n### Phase 2 Complete When\n- All codebase-explorer tasks finished\n- All recommended files read\n- Initial draft written with `[TBD]` markers\n- Interview log populated with research findings\n\n## Phase 3: Iterative Discovery Interview\n\n**CRITICAL**: Use AskUserQuestion tool for ALL questions - never plain text.\n\n**Example** (the `questions` array supports 1-4 questions per call - that's batching):\n```\nquestions: [\n  {\n    question: \"Who should receive these notifications?\",\n    header: \"User Scope\",\n    options: [\n      { label: \"All active users (Recommended)\", description: \"Broadest reach, simplest logic\" },\n      { label: \"Premium users only\", description: \"Limited scope, may need upgrade prompts\" },\n      { label: \"Users who opted in\", description: \"Requires preference system first\" }\n    ],\n    multiSelect: false\n  },\n  {\n    question: \"How should notifications be delivered?\",\n    header: \"Delivery\",\n    options: [\n      { label: \"In-app only (Recommended)\", description: \"Simplest, no external dependencies\" },\n      { label: \"Push + in-app\", description: \"Requires push notification setup\" },\n      { label: \"Email digest\", description: \"Async, requires email service\" }\n    ],\n    multiSelect: true\n  }\n]\n```\n\n### Memento Loop\n\nFor each step:\n1. Mark todo `in_progress`\n2. Research OR ask question (AskUserQuestion)\n3. **Write findings immediately** to interview log\n4. Expand todos for: new areas revealed, follow-up questions, dependencies discovered\n5. Update spec file (replace `[TBD]` markers)\n6. Mark todo `completed`\n7. Repeat until no pending todos\n\n**NEVER proceed without writing findings first** â€” interview log is external memory.\n\n### Interview Log Update Format\n\nAfter EACH question/answer, append (Round = one AskUserQuestion call, may contain batched questions):\n\n```markdown\n### Round {N} - {HH:MM:SS}\n**Todo**: {which todo this addresses}\n**Question asked**: {question}\n**User answer**: {answer}\n**Impact**: {what this revealed/decided}\n**New areas**: {list or \"none\"}\n```\n\nAfter EACH decision (even implicit), append to Decisions Made:\n\n```markdown\n- {Decision area}: {choice} â€” {rationale}\n```\n\n### Todo Expansion Triggers\n\n| Discovery Reveals | Add Todos For |\n|-------------------|---------------|\n| New affected area | Requirements for that area |\n| Integration need | Integration constraints |\n| Compliance/regulatory | Compliance requirements |\n| Multiple scenarios/flows | Each scenario's behavior |\n| Error conditions | Error handling approach |\n| Performance concern | Performance constraints/metrics |\n| Existing dependency | Dependency investigation |\n| Rollback/recovery need | Recovery strategy |\n| Data preservation need | Data integrity requirements |\n\n### Interview Rules\n\n**Unbounded loop**: Keep iterating (research â†’ question â†’ update spec) until ALL completion criteria are met. No fixed round limit - continue as long as needed for complex problems. If user says \"just infer the rest\" or similar, document remaining decisions with `[INFERRED: {choice} - {rationale}]` markers and finalize.\n\n1. **Prioritize questions that eliminate other questions** - Ask questions where the answer would change what other questions you need to ask, or would eliminate entire branches of requirements. If knowing X makes Y irrelevant, ask X first.\n\n2. **Interleave discovery and questions**:\n   - User answer reveals new area â†’ launch codebase-explorer\n   - Need domain knowledge â†’ launch web-researcher\n   - Update spec after each iteration, replacing `[TBD]` markers\n\n3. **Question priority order**:\n\n   | Priority | Type | Purpose | Examples |\n   |----------|------|---------|----------|\n   | 1 | Scope Eliminators | Eliminate large chunks of work | V1/MVP vs full? All users or segment? |\n   | 2 | Branching | Open/close inquiry lines | User-initiated or system-triggered? Real-time or async? |\n   | 3 | Hard Constraints | Non-negotiable limits | Regulatory requirements? Must integrate with X? |\n   | 4 | Differentiating | Choose between approaches | Pattern A vs B? Which UX model? |\n   | 5 | Detail Refinement | Fine-grained details | Exact copy, specific error handling |\n\n4. **Always mark one option \"(Recommended)\"** - put first with reasoning in description. Question whether each requirement is truly neededâ€”don't pad with nice-to-haves. When options are equivalent AND reversible without data migration or API changes, decide yourself (lean simpler). When options are equivalent BUT have different user-facing tradeoffs, ask user.\n\n5. **Be thorough via technique**:\n   - Cover everything relevant - don't skip to save time\n   - Reduce cognitive load through HOW you ask: concrete options, good defaults\n   - **Batching**: Up to 4 questions in `questions` array per call (batch questions that address the same todo or decision area); max 4 options per question (tool limit)\n   - Make decisions yourself when context suffices\n   - Complete spec with easy questions > incomplete spec with fewer questions\n\n6. **Ask non-obvious questions** - Uncover what user hasn't explicitly stated: motivations behind requirements, edge cases affecting UX, business rules implied by use cases, gaps between user expectations and feasibility, tradeoffs user may not have considered\n\n7. **Ask vs Decide** - User is authority for business decisions; codebase/standards are authority for implementation details.\n\n   **Ask user when**:\n   | Category | Examples |\n   |----------|----------|\n   | Business rules | Pricing logic, eligibility criteria, approval thresholds |\n   | User segments | Who gets this? All users, premium, specific roles? |\n   | Tradeoffs with no winner | Speed vs completeness, flexibility vs simplicity |\n   | Scope boundaries | V1 vs future, must-have vs nice-to-have |\n   | External constraints | Compliance, contracts, stakeholder requirements |\n   | Preferences | Opt-in vs opt-out, default on vs off |\n\n   **Decide yourself when**:\n   | Category | Examples |\n   |----------|----------|\n   | Existing pattern | Error format, naming conventions, component structure |\n   | Industry standard | HTTP status codes, validation rules, retry strategies |\n   | Sensible defaults | Timeout values, pagination limits, debounce timing |\n   | Easily changed later (single-file change, no data migration, no API contract change) | Copy text, colors, specific thresholds |\n   | Implementation detail | Which hook to use, event naming, internal state shape |\n\n   **Test**: \"If I picked wrong, would user say 'that's not what I meant' (ASK) or 'that works, I would have done similar' (DECIDE)?\"\n\n## Phase 4: Finalize & Summarize\n\n### 4.1 Final interview log update\n\n```markdown\n## Interview Complete\nFinished: {YYYY-MM-DD HH:MM:SS} | Questions: {count} | Decisions: {count}\n## Summary\n{Brief summary of discovery process}\n```\n\n### 4.2 Refresh context\n\nRead the full interview log file to restore all decisions, findings, and rationale into context before writing the final spec.\n\n### 4.3 Finalize specification\n\nFinal pass: remove `[TBD]` markers, ensure consistency. Use this **minimal scaffolding** - add sections dynamically based on what discovery revealed:\n\n```markdown\n# Requirements: {Work Name}\n\nGenerated: {date}\n\n## Overview\n### Problem Statement\n{What is wrong/missing/needed? Why now?}\n\n### Scope\n{What's included? What's explicitly excluded?}\n\n### Affected Areas\n{Systems, components, processes, users impacted}\n\n### Success Criteria\n{Observable outcomes that prove this work succeeded}\n\n## Requirements\n{Verifiable statements about what's true when this work is complete. Each requirement should be specific enough to check as true/false.}\n\n### Core Behavior\n- {Verifiable outcome}\n- {Another verifiable outcome}\n\n### Edge Cases & Error Handling\n- When {condition}, {what happens}\n\n## Constraints\n{Non-negotiable limits, dependencies, prerequisites}\n\n## Out of Scope\n{Non-goals with reasons}\n\n## {Additional sections as needed based on discovery}\n{Add sections relevant to this specific work - examples below}\n```\n\n**Dynamic sections** - add based on what discovery revealed (illustrative, not exhaustive):\n\n| Discovery Reveals | Add Section |\n|-------------------|-------------|\n| User-facing behavior | Screens/states (empty, loading, success, error), interactions, accessibility |\n| API/technical interface | Contract (inputs/outputs/errors), integration points, versioning |\n| Bug context | Current vs expected, reproduction steps, verification criteria |\n| Refactoring | Current/target structure, invariants (what must NOT change) |\n| Infrastructure | Rollback plan, monitoring, failure modes |\n| Migration | Data preservation, rollback, cutover strategy |\n| Performance | Current baseline, target metrics, measurement method |\n| Data changes | Schema, validation rules, retention |\n| Security & privacy | Auth/authz requirements, data sensitivity, audit needs |\n| User preferences | Configurable options, defaults, persistence |\n| External integrations | Third-party services, rate limits, fallbacks |\n| Observability | Analytics events, logging, success/error metrics |\n\n**Specificity**: Each requirement should be verifiable. \"User can log in\" is too vague; \"on valid credentials â†’ redirect to dashboard; on invalid â†’ show inline error, no page reload\" is right.\n\n### 4.4 Mark all todos complete\n\n### 4.5 Output summary\n\n```\n## Spec Summary\n\n**Work**: {name}\n**File**: /tmp/spec-{...}.md\n\n### What We're Doing\n{1-2 sentences}\n\n### Key Decisions Made\n- {Decision}: {choice}\n\n### Core Requirements ({count})\n- {Top 3 requirements}\n\n### Out of Scope\n- {Key non-goals}\n\n---\nReview full spec and let me know adjustments.\n```\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| Memento style | Write findings BEFORE next question (interview log = external memory) |\n| Todo-driven | Every discovery needing follow-up â†’ todo (no mental notes) |\n| WHAT not HOW | Requirements only - no architecture, APIs, data models, code patterns. Self-check: if thinking \"how to implement,\" refocus on \"what should happen/change\" |\n| Observable outcomes | Focus on what changes when complete. Ask \"what is different after?\" not \"how does it work internally?\" Edge cases = system/business impact |\n| Dynamic structure | Spec sections emerge from discovery. No fixed template beyond core scaffolding. Add sections as needed to fully specify the WHAT |\n| Complete coverage | Spec covers EVERYTHING implementer needs: behavior, UX, data, errors, edge cases, accessibility - whatever the work touches. If they'd have to guess, it's underspecified |\n| Comprehensive spec, minimal questions | Spec covers everything implementer needs. Ask questions only when: (1) answer isn't inferable from codebase/context, (2) wrong guess would require changing 3+ files or redoing more than one day of work, (3) it's a business decision only user can make. Skip questions you can answer via research |\n| No open questions | Resolve everything during interview - no TBDs in final spec |\n| Question requirements | Don't accept requirements at face value. Ask \"is this truly needed for v1?\" Don't pad specs with nice-to-haves |\n| Reduce cognitive load | Recommended option first, multi-choice over free-text. Free-text only when: options are infinite/unpredictable, asking for specific values (names, numbers), or user needs to describe own context. User accepting defaults should yield solid result |\n| Incremental updates | Update interview log after EACH step (not at end) |\n\n### Completion Checklist\n\nInterview complete when ALL true (keep iterating until every box checked):\n- [ ] Problem/trigger defined - why this work is needed\n- [ ] Scope defined - what's in, what's explicitly out\n- [ ] Affected areas identified - what changes\n- [ ] Success criteria specified - observable outcomes\n- [ ] Core requirements documented (3+ must-have behaviors that define the work's purpose)\n- [ ] Edge cases addressed\n- [ ] Constraints captured\n- [ ] Out of scope listed with reasons\n- [ ] No `[TBD]` markers remain\n- [ ] Passes completeness test (below)\n\n### Completeness Test (before finalizing)\n\nSimulate three consumers of this spec:\n\n1. **Implementer**: Read each requirement. Could you code it without guessing? If you'd think \"I'll ask about X later\" â†’ X is underspecified.\n\n2. **Tester**: For each behavior, can you write a test? If inputs/outputs/conditions are unclear â†’ underspecified.\n\n3. **Reviewer**: For each success criterion, how would you verify it shipped correctly? If verification method is unclear â†’ underspecified.\n\nAny question from these simulations = gap to address before finalizing.\n\n### Never Do\n\n- Proceed without writing findings to interview log\n- Keep discoveries as mental notes instead of todos\n- Skip todo list\n- Write specs to project directories (always `/tmp/`)\n- Ask about technical implementation\n- Finalize with unresolved `[TBD]`\n- Skip summary output\n- Ask interview questions without AskUserQuestion tool (research findings don't require user questions)\n- Proceed past Phase 2 without initial draft\n- Forget to expand todos on new areas revealed\n\n### Edge Cases\n\n| Scenario | Action |\n|----------|--------|\n| User declines to answer | Note `[USER SKIPPED: reason]`, flag in summary |\n| Insufficient research | Ask user directly, note uncertainty |\n| Contradictory requirements | Surface conflict before proceeding |\n| User corrects earlier decision | Update spec, log correction with reason, check if other requirements affected |\n| Interview interrupted | Spec saved; add `[INCOMPLETE]` at top. To resume: provide existing spec file path as argument |\n| Resume interrupted spec | Read provided spec file. If file not found or not a valid spec (missing required sections like Overview, Requirements), inform user: \"Could not resume from {path}: {reason}. Start fresh?\" via AskUserQuestion. If valid, look for matching interview log at same timestamp, scan for `[TBD]` and `[INCOMPLETE]` markers, present status to user and ask \"Continue from {last incomplete area}?\" via AskUserQuestion |\n| \"Just build it\" | Push back with 2-3 critical questions (questions where guessing wrong = significant rework). If declined, document assumptions clearly |"
              },
              {
                "name": "web-research",
                "description": "Research external topics via web search with structured hypothesis tracking and source evaluation.",
                "path": "claude-plugins/vibe-workflow/skills/web-research/SKILL.md",
                "frontmatter": {
                  "name": "web-research",
                  "description": "Research external topics via web search with structured hypothesis tracking and source evaluation.",
                  "context": "fork"
                },
                "content": "Launch the web-researcher agent to systematically research the given topic using web search and fetch. The agent will track sources, evaluate authority, and synthesize findings."
              }
            ]
          },
          {
            "name": "solo-dev",
            "description": "Toolkit for solo developers to build, manage, and grow their business - content creation, personal branding, productivity, and more",
            "source": "./claude-plugins/solo-dev",
            "category": "productivity",
            "version": "1.2.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add doodledood/claude-code-plugins",
              "/plugin install solo-dev@claude-code-plugins-marketplace"
            ],
            "signals": {
              "stars": 8,
              "forks": 0,
              "pushed_at": "2026-01-12T07:05:08Z",
              "created_at": "2025-11-20T15:25:14Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "audit-ux",
                "description": "Audit UI/UX changes in a focus area against design guidelines for accessibility, consistency, and usability issues.",
                "path": "claude-plugins/solo-dev/skills/audit-ux/SKILL.md",
                "frontmatter": {
                  "name": "audit-ux",
                  "description": "Audit UI/UX changes in a focus area against design guidelines for accessibility, consistency, and usability issues.",
                  "context": "fork"
                },
                "content": "Launch the ux-auditor agent to perform a comprehensive UX audit of the specified focus area."
              },
              {
                "name": "craft-author-voice",
                "description": "Captures writing style/voice into AUTHOR_VOICE.md so AI can write like the user. Use when asked to match tone, write like me, replicate voice, or capture writing style for content generation.",
                "path": "claude-plugins/solo-dev/skills/craft-author-voice/SKILL.md",
                "frontmatter": {
                  "name": "craft-author-voice",
                  "description": "Captures writing style/voice into AUTHOR_VOICE.md so AI can write like the user. Use when asked to match tone, write like me, replicate voice, or capture writing style for content generation."
                },
                "content": "**User request**: $ARGUMENTS\n\n# Author Voice Skill\n\nCreate a maximally information-dense AUTHOR_VOICE.md document through iterative refinement. The resulting document enables any LLM to write content that authentically matches your voice.\n\n## Overview\n\nThis skill supports both **creating a new voice doc** and **refining an existing one**. Users often come back multiple times to adjust their doc as their voice evolves or as they notice issues in generated content.\n\nThis skill guides you through:\n0. **Check Existing** - Look for existing AUTHOR_VOICE.md; let user choose to refine or start fresh\n1. **Discovery** - Clarifying questions about your voice characteristics and goals\n2. **Initial Draft** - Generate first AUTHOR_VOICE.md based on your inputs (good enough to start!)\n3. **Refinement Cycles** - Generate sample texts, collect your ratings/feedback, update the doc â¬…ï¸ **THE REAL MAGIC**\n4. **Completion** - Final honed document ready for AI content generation\n\n**Returning users** can skip straight to Phase 3 to run more feedback cycles on their existing doc.\n\n### Where the Value Comes From\n\nThe discovery questions give you a solid starting point - but **the real magic happens in Phase 3**. That's where you:\n- See actual generated samples in your \"voice\"\n- Judge them (\"this doesn't sound like me\")\n- Give specific feedback (\"too formal\", \"wrong words\")\n- Watch the voice doc evolve until it truly captures YOU\n\nEach feedback cycle sharpens the doc. Most users need 3-5 cycles to get from \"this is okay\" to \"this is actually me.\"\n\n## Workflow\n\n### Phase 0: Check for Existing Document\n\nBefore starting discovery, check if the user already has an AUTHOR_VOICE.md:\n\n1. **Search for existing doc**: Use Glob to search for `**/AUTHOR_VOICE.md` in the current directory and common locations\n2. **If found**: Read it and ask the user what they want to do\n\n```\nheader: \"Existing Voice Doc Found\"\nquestion: \"I found an existing AUTHOR_VOICE.md. What would you like to do?\"\noptions:\n  - \"Refine it - run feedback cycles to improve accuracy\"\n  - \"Start fresh - create a new voice doc from scratch\"\n  - \"Review it - just read through what's there\"\n```\n\n**If \"Refine it\"**: Skip to Phase 3 (Refinement Cycles) - the user is coming back to improve their existing doc.\n\n**If \"Start fresh\"**: Proceed to Phase 1 (Discovery) - will overwrite the existing doc.\n\n**If \"Review it\"**: Read and display the doc, then ask what they want to do next.\n\n3. **If NOT found**: Proceed directly to Phase 1 (Discovery)\n\n### Phase 1: Discovery\n\nUse AskUserQuestion tool with multi-choice options for EVERY question to minimize cognitive load. If AskUserQuestion is unavailable, present numbered options and ask the user to reply with the number(s).\n\n**Question 1: Primary Content Type**\n\n```\nheader: \"Content Type\"\nquestion: \"What's your PRIMARY content format?\"\noptions:\n  - \"Twitter/X posts (short-form, punchy)\"\n  - \"LinkedIn posts (professional, insights)\"\n  - \"Blog articles (long-form, detailed)\"\n  - \"Newsletter (conversational, regular)\"\n  - \"Technical documentation (precise, instructional)\"\n  - \"Mixed - I write across multiple formats\"\n```\n\n**Question 2: Voice Personality**\n\n```\nheader: \"Voice Tone\"\nquestion: \"How would you describe your voice personality?\"\noptions:\n  - \"Authoritative expert - confident, direct, no-nonsense\"\n  - \"Friendly mentor - approachable, encouraging, educational\"\n  - \"Provocateur - contrarian, challenges assumptions, bold\"\n  - \"Storyteller - narrative-driven, uses examples, personal\"\n  - \"Analyst - data-driven, logical, objective\"\n  - \"Conversational peer - casual, relatable, human\"\nmultiSelect: true (pick up to 2)\n```\n\n**Question 3: Signature Elements**\n\n```\nheader: \"Signatures\"\nquestion: \"What signature elements define your writing?\"\noptions:\n  - \"Strong opening hooks\"\n  - \"Numbered lists and frameworks\"\n  - \"Personal anecdotes and stories\"\n  - \"Contrarian takes and hot takes\"\n  - \"Data and research citations\"\n  - \"Metaphors and analogies\"\n  - \"Direct calls-to-action\"\n  - \"Questions to engage readers\"\n  - \"Short punchy sentences\"\n  - \"Long flowing prose\"\nmultiSelect: true\n```\n\n**Question 4: Vocabulary Style**\n\n```\nheader: \"Vocabulary\"\nquestion: \"What's your vocabulary style?\"\noptions:\n  - \"Simple and accessible - anyone can understand\"\n  - \"Technical jargon - domain-specific terms expected\"\n  - \"Casual slang - internet-native, memes okay\"\n  - \"Formal professional - polished, corporate-appropriate\"\n  - \"Academic - precise, nuanced, scholarly\"\n```\n\n**Question 5: Emotional Range**\n\n```\nheader: \"Emotion\"\nquestion: \"What emotions do you convey in your writing?\"\noptions:\n  - \"Enthusiasm and excitement\"\n  - \"Calm confidence\"\n  - \"Urgency and importance\"\n  - \"Humor and wit\"\n  - \"Empathy and understanding\"\n  - \"Skepticism and critical thinking\"\n  - \"Inspiration and motivation\"\nmultiSelect: true\n```\n\n**Question 6: Target Audience**\n\n```\nheader: \"Audience\"\nquestion: \"Who is your primary audience?\"\noptions:\n  - \"Developers/Engineers\"\n  - \"Founders/Entrepreneurs\"\n  - \"Product managers\"\n  - \"Executives/Leaders\"\n  - \"General tech audience\"\n  - \"Non-technical professionals\"\n  - \"Students/Learners\"\n```\n\n**Question 7: Writing Goals**\n\n```\nheader: \"Goals\"\nquestion: \"What do you want your writing to achieve?\"\noptions:\n  - \"Build authority and thought leadership\"\n  - \"Drive engagement and discussion\"\n  - \"Educate and inform\"\n  - \"Entertain and delight\"\n  - \"Convert/sell (subtly)\"\n  - \"Build community and connection\"\nmultiSelect: true\n```\n\n**Question 8: Anti-patterns**\n\n```\nheader: \"Avoid\"\nquestion: \"What should your writing NEVER do?\"\noptions:\n  - \"Use corporate buzzwords\"\n  - \"Sound robotic or AI-generated\"\n  - \"Be preachy or condescending\"\n  - \"Use excessive emojis\"\n  - \"Be overly promotional\"\n  - \"Use clickbait tactics\"\n  - \"Be wishy-washy or hedging\"\n  - \"Use filler phrases\"\nmultiSelect: true\n```\n\n**Question 9: Sample Topics** (free text acceptable here)\n\n```\nheader: \"Topics\"\nquestion: \"List 2-3 topics you frequently write about (or paste examples of your past writing)\"\n```\n\n### Phase 2: Initial Document Generation\n\nAfter discovery, generate the first AUTHOR_VOICE.md. This draft is intentionally a \"good enough\" starting point - not perfect, but solid enough to generate samples and start the feedback loop.\n\nUse this structure:\n\n```markdown\n# AUTHOR_VOICE.md\n\n> This document defines [Author]'s writing voice for AI content generation.\n> Feed this to any LLM before requesting content to match the author's style.\n\n## Voice Identity\n\n[1-2 sentences capturing the core voice essence]\n\n## Tone Parameters\n\n- **Primary tone**: [e.g., \"Confident mentor with occasional humor\"]\n- **Emotional range**: [comma-separated emotions from discovery]\n- **Formality level**: [1-10 scale with description]\n- **Warmth level**: [1-10 scale with description]\n\n## Structural Patterns\n\n- **Opening style**: [how posts/articles begin]\n- **Paragraph length**: [short/medium/long, typical sentence count]\n- **List usage**: [when and how lists are used]\n- **Closing style**: [how content ends - CTA, question, statement]\n\n## Vocabulary Rules\n\n### USE:\n- [Specific words/phrases the author uses]\n- [Technical terms that are okay]\n- [Signature expressions]\n\n### AVOID:\n- [Words that feel off-brand]\n- [Overused phrases to skip]\n- [Tone markers to avoid]\n\n## Content Patterns\n\n### Hooks\n[How the author grabs attention - examples of opening patterns]\n\n### Arguments\n[How the author builds points - numbered, narrative, comparison]\n\n### Evidence\n[How claims are supported - data, anecdotes, logic, authority]\n\n### Transitions\n[How ideas connect - explicit markers, implicit flow]\n\n## Signature Moves\n\n1. [Specific technique the author uses regularly]\n2. [Another signature element]\n3. [Third distinguishing characteristic]\n\n## Anti-Patterns\n\nNEVER:\n- [Specific thing to avoid]\n- [Another anti-pattern]\n- [Third prohibition]\n\n## Example Transformations\n\n### Generic version:\n\"[Common way to express an idea]\"\n\n### In author's voice:\n\"[Same idea in the author's distinctive style]\"\n\n---\n\n**User request**: $ARGUMENTS\n\n## Quick Reference\n\n**One-line voice summary**: [Author] writes like [analogy/comparison].\n\n**Before generating content, ensure**:\n- [ ] [Checklist item 1]\n- [ ] [Checklist item 2]\n- [ ] [Checklist item 3]\n```\n\nWrite this file to the current working directory as `AUTHOR_VOICE.md`.\n\n### Phase 3: Refinement Cycles (Where the Magic Happens)\n\n**This is the most important phase.** The initial doc from Phase 2 captures the basics, but YOUR feedback on generated samples is what transforms it from generic to authentic. Don't skip this.\n\nAfter generating the initial document, begin iterative refinement:\n\n**Step 3.1: Generate Sample Texts**\n\n**IMPORTANT**: Do NOT generate samples yourself. You MUST use the **voice-writer** agent to generate samples. The agent is specifically designed to read the voice doc and produce authentic samples - attempting to generate them inline will produce inferior results.\n\n```\nUse the voice-writer agent to generate 3 sample texts.\nVoice doc path: [path to AUTHOR_VOICE.md]\nMode: Sample generation\n```\n\nThe agent will read the voice doc and output 3 samples:\n1. Short-form (~280 chars)\n2. Medium-form (2-3 paragraphs)\n3. Conversational reply\n\n**Step 3.2: Collect Feedback Per Sample**\n\nFor EACH of the 3 generated samples, use AskUserQuestion tool (or numbered options if unavailable):\n\n```\nheader: \"Sample [N]\"\nquestion: \"Rate this sample and share what's off:\"\n[Display the sample text]\noptions:\n  - \"Perfect - captures my voice exactly\"\n  - \"Close - minor tweaks needed\"\n  - \"Okay - something feels off but hard to pinpoint\"\n  - \"Wrong - this doesn't sound like me\"\n```\n\nIf not \"Perfect\", follow up with:\n\n```\nheader: \"Feedback\"\nquestion: \"What specifically needs adjustment in Sample [N]?\"\noptions:\n  - \"Too formal/stiff\"\n  - \"Too casual/unprofessional\"\n  - \"Wrong vocabulary/word choices\"\n  - \"Missing my signature style elements\"\n  - \"Tone is off (wrong emotion)\"\n  - \"Structure doesn't match how I write\"\n  - \"Too long/wordy\"\n  - \"Too short/choppy\"\n  - \"Other - let me explain\"\nmultiSelect: true\n```\n\nIf \"Other\" selected or if more detail needed, prompt for free-text:\n\"Describe what's wrong and how you'd actually write this:\"\n\n**Step 3.3: Update Document**\n\nBased on ALL feedback from the 3 samples:\n\n1. Identify patterns in the feedback (what's consistently wrong?)\n2. Update the AUTHOR_VOICE.md with new/refined rules\n3. Add specific \"instead of X, use Y\" examples where needed\n4. Strengthen anti-patterns if certain issues keep appearing\n\n**Step 3.4: Check Completion**\n\n```\nheader: \"Continue?\"\nquestion: \"Want to run another refinement cycle?\"\noptions:\n  - \"Yes - generate 3 more samples with the updated doc\"\n  - \"No - the voice doc is good enough for now\"\n  - \"Almost done - one more cycle should perfect it\"\n```\n\nIf \"Yes\" or \"Almost done\", return to Step 3.1 with the updated document.\n\n### Phase 4: Completion\n\nWhen user indicates completion:\n\n1. Add a \"Version History\" section noting refinement cycles completed\n2. Add a \"Usage Instructions\" section for how to use with LLMs\n3. Display final document summary\n4. Remind user to keep the AUTHOR_VOICE.md with their projects\n\n## Key Principles\n\n### Information Density\n- Every line in the doc must be actionable for an LLM\n- No fluff, no explanations \"for humans\"\n- Concrete examples over abstract descriptions\n- Specific word lists over vague guidelines\n\n### Iterative Refinement\n- 3-5 refinement cycles typically needed for high accuracy\n- Each cycle should fix specific issues identified\n- Track what changes between versions\n\n### Reduce Cognitive Load\n- ALWAYS use AskUserQuestion tool when available - this is critical for UX\n- Present multi-choice questions to minimize user typing/thinking\n- Limit options to 6-8 max per question\n- Use multiSelect for non-exclusive choices\n- Only use free-text for examples/samples or when AskUserQuestion unavailable\n\n## Output Location\n\nWrite `AUTHOR_VOICE.md` to the current working directory (or user-specified path)."
              },
              {
                "name": "define-brand-guidelines",
                "description": "Create a BRAND_GUIDELINES.md that defines how to communicate with your customer. Requires CUSTOMER.md to exist first. Covers voice, tone, language rules, messaging framework, and copy patterns.",
                "path": "claude-plugins/solo-dev/skills/define-brand-guidelines/SKILL.md",
                "frontmatter": {
                  "name": "define-brand-guidelines",
                  "description": "Create a BRAND_GUIDELINES.md that defines how to communicate with your customer. Requires CUSTOMER.md to exist first. Covers voice, tone, language rules, messaging framework, and copy patterns."
                },
                "content": "# Brand Guidelines Skill\n\nCreate the BRAND_GUIDELINES.md document that defines HOW to communicate with your customer. This document drives all copy and messaging: app UI, marketing, support, emails, everything.\n\n> **Prerequisite**: CUSTOMER.md must exist. Brand guidelines without customer definition is just aesthetic preference. The voice must resonate with WHO you're talking to.\n\n## Overview\n\nThis skill supports both **creating new brand guidelines** and **refining existing ones**.\n\nThis skill guides you through:\n0. **Prerequisite Check** - Verify CUSTOMER.md exists; stop if not\n1. **Discovery** - Questions about brand personality, voice, language preferences\n2. **Draft Generation** - Create BRAND_GUIDELINES.md based on inputs\n3. **Refinement** - Test with sample copy, iterate until voice feels right\n\n## Workflow\n\n### Phase 0: Prerequisite Check\n\n**CRITICAL**: Before anything else, check for CUSTOMER.md:\n\n1. Use Glob to search for `**/CUSTOMER.md` in the current directory\n2. **If NOT found**: Stop immediately and inform the user:\n\n```\n\"I can't create brand guidelines without knowing WHO you're talking to.\n\nPlease create your CUSTOMER.md first using /define-customer.\n\nBrand voice without customer definition is just aesthetic preference - it won't resonate with anyone specific.\"\n```\n\nDo NOT proceed. End the workflow here.\n\n3. **If found**: Read the CUSTOMER.md and extract key context:\n   - ICP definition (who they are)\n   - Pain points (what problems they have)\n   - What they value (in a solution)\n   - Anti-personas (who they're NOT)\n   - Any language/communication hints\n\n**IMPORTANT - Pre-fill Recommendations**: Use CUSTOMER.md to infer recommended options for all questions. Examples:\n\n| If CUSTOMER.md says... | Recommend... |\n|------------------------|--------------|\n| ICP values \"speed\", \"efficiency\", \"no patience\" | Direct communication, short copy |\n| ICP is technical (developers, engineers) | Technical language okay, precision matters |\n| ICP values \"data\", \"statistics\", \"proof\" | Data-driven persuasion style |\n| Anti-persona is \"purists\" or \"academics\" | Avoid being preachy or condescending |\n| ICP is \"fun-seekers\", \"casual players\" | More playful tone, casual formality |\n| ICP is \"executives\", \"professionals\" | More formal, authoritative personality |\n\nThe goal: **User should be able to accept all recommended defaults** and get a solid brand guide. Only ask them to deviate where CUSTOMER.md doesn't provide clear signals.\n\nThen check for existing BRAND_GUIDELINES.md:\n\n```\nheader: \"Existing Brand Guidelines Found\"\nquestion: \"I found existing BRAND_GUIDELINES.md. What would you like to do?\"\noptions:\n  - \"Refine it - update based on new insights\"\n  - \"Start fresh - create new brand guidelines\"\n  - \"Review it - just read through what's there\"\n```\n\n### Phase 1: Discovery\n\nUse AskUserQuestion for all questions. **Put the recommended option FIRST** with \"(Recommended)\" suffix. Infer recommendations from CUSTOMER.md.\n\n**Question 1: Brand Personality**\n\nInfer from CUSTOMER.md:\n- Data-driven ICP â†’ \"Authoritative expert\"\n- Beginners/learners â†’ \"Friendly mentor\"\n- Contrarian/challengers â†’ \"Provocative challenger\"\n- Enterprise/professional â†’ \"Calm professional\"\n- Fun-seekers/enthusiasts â†’ \"Energetic enthusiast\" or \"Witty companion\"\n\n```\nheader: \"Brand Personality\"\nquestion: \"If your brand was a person speaking to your customer, who would they be?\"\noptions:\n  - \"[Inferred from CUSTOMER.md] (Recommended)\"\n  - \"Authoritative expert - confident, definitive, data-driven\"\n  - \"Friendly mentor - approachable, helpful, encouraging\"\n  - \"Provocative challenger - bold, contrarian, challenges assumptions\"\n  - \"Calm professional - measured, trustworthy, understated\"\n  - \"Energetic enthusiast - excited, passionate, motivating\"\n  - \"Witty companion - clever, playful, personality-forward\"\n```\n\n**Question 2: Voice Dimensions**\n\nInfer each dimension from CUSTOMER.md. Put recommended first.\n\n```\nheader: \"Formality\"\nquestion: \"How formal is your brand's voice?\"\noptions:\n  - \"[Inferred] (Recommended)\"  # e.g., \"Casual\" if ICP is blitz players\n  - \"Very formal - professional, polished, no contractions\"\n  - \"Somewhat formal - professional but approachable\"\n  - \"Neutral - depends on context\"\n  - \"Casual - relaxed, contractions okay, conversational\"\n  - \"Very casual - informal, slang okay, like texting a friend\"\n```\n\nInference rules for formality:\n- Enterprise/executives â†’ Very formal or Somewhat formal\n- Developers â†’ Casual or Neutral\n- Consumers/players â†’ Casual or Very casual\n- Default â†’ Casual (most approachable)\n\n```\nheader: \"Tone Weight\"\nquestion: \"How serious vs playful is your brand?\"\noptions:\n  - \"[Inferred] (Recommended)\"  # e.g., \"Mostly serious\" if data-driven\n  - \"Very serious - no humor, all business\"\n  - \"Mostly serious - occasional lightness\"\n  - \"Balanced - serious when needed, light when appropriate\"\n  - \"Mostly playful - humor is part of the brand\"\n  - \"Very playful - fun and entertainment are core\"\n```\n\nInference rules for tone:\n- ICP values \"fun\", \"enjoyment\" â†’ Mostly playful or Balanced\n- ICP values \"data\", \"precision\" â†’ Mostly serious\n- B2B/professional â†’ Balanced or Mostly serious\n- Default â†’ Balanced\n\n```\nheader: \"Technical Level\"\nquestion: \"How technical is your language?\"\noptions:\n  - \"[Inferred] (Recommended)\"\n  - \"Highly technical - jargon expected, precision matters\"\n  - \"Somewhat technical - domain terms with explanation\"\n  - \"Accessible - simple language, avoid jargon\"\n  - \"Very simple - anyone should understand\"\n```\n\nInference rules:\n- ICP is developers/engineers â†’ Highly technical or Somewhat technical\n- ICP values \"plain language\", \"accessible\" â†’ Accessible\n- General consumers â†’ Very simple or Accessible\n- Default â†’ Somewhat technical\n\n```\nheader: \"Directness\"\nquestion: \"How direct is your communication?\"\noptions:\n  - \"[Inferred] (Recommended)\"\n  - \"Very direct - commands, no hedging, get to the point\"\n  - \"Direct - clear and straightforward\"\n  - \"Balanced - direct but diplomatic\"\n  - \"Soft - suggestive, options-focused\"\n  - \"Very soft - gentle, lots of qualifiers\"\n```\n\nInference rules:\n- ICP values \"speed\", \"efficiency\", \"no patience\" â†’ Very direct\n- ICP is time-constrained â†’ Very direct or Direct\n- ICP is beginners/learners â†’ Balanced or Soft\n- Default â†’ Direct\n\n**Question 3: Writing Style**\n\n```\nheader: \"Copy Style\"\nquestion: \"What does your ideal copy look like?\"\noptions:\n  - \"[Inferred options pre-selected] (Recommended)\"\n  - \"Short and punchy - minimal words, maximum impact\"\n  - \"Concise but complete - efficient, no fluff\"\n  - \"Conversational flow - natural, like talking\"\n  - \"Rich and detailed - thorough explanations\"\nmultiSelect: true\n```\n\nInference: If ICP values speed â†’ \"Short and punchy\". If ICP is technical â†’ \"Concise but complete\".\n\n```\nheader: \"Persuasion Style\"\nquestion: \"How do you persuade?\"\noptions:\n  - \"[Inferred options pre-selected] (Recommended)\"\n  - \"Data and evidence - stats, proof, numbers\"\n  - \"Benefits and outcomes - what they'll achieve\"\n  - \"Emotional resonance - how they'll feel\"\n  - \"Social proof - others trust us\"\n  - \"Authority - we're the experts\"\nmultiSelect: true\n```\n\nInference: Match to \"What the ICP Values\" from CUSTOMER.md.\n\n**Question 4: Language Preferences**\n\n```\nheader: \"Language Rules\"\nquestion: \"Select your language preferences:\"\noptions:\n  - \"[Inferred bundle] (Recommended)\"  # Pre-select compatible options\n  - \"Use contractions (we're, you'll, it's)\"\n  - \"Avoid contractions (we are, you will, it is)\"\n  - \"Emoji okay in appropriate contexts\"\n  - \"No emoji ever\"\n  - \"Exclamation marks okay (sparingly)\"\n  - \"No exclamation marks\"\n  - \"Industry jargon okay for our audience\"\n  - \"Avoid all jargon\"\nmultiSelect: true\n```\n\nDefault recommendation: \"Use contractions\" + \"No emoji\" + \"Industry jargon okay\" (professional but approachable)\n\n**Question 5: Anti-Patterns**\n\n```\nheader: \"Voice Anti-Patterns\"\nquestion: \"What should your brand NEVER sound like?\"\noptions:\n  - \"[Inferred from anti-personas] (Recommended)\"\n  - \"Corporate buzzwords (synergy, leverage, ideate)\"\n  - \"Overly salesy (ACT NOW! LIMITED TIME!)\"\n  - \"Condescending or preachy\"\n  - \"Wishy-washy or uncertain\"\n  - \"Generic AI-speak (I hope this helps!)\"\n  - \"Robotic or cold\"\n  - \"Overly casual or unprofessional\"\n  - \"Boring or dry\"\nmultiSelect: true\n```\n\nInference: Map anti-persona traits to voice anti-patterns. E.g., if anti-persona is \"purists who debate principles\" â†’ recommend \"Condescending or preachy\".\n\n**Question 6: Core Value Propositions**\n\n```\nheader: \"Value Props\"\nquestion: \"What are the 2-3 main arguments/benefits your brand communicates?\"\nfreeText: true\nplaceholder: \"e.g., '1. Faster than alternatives 2. Data-driven decisions 3. Built for experts'\"\n```\n\n**Question 7: The Hook**\n\n```\nheader: \"The Hook\"\nquestion: \"What's the single most compelling thing you can say to grab attention?\"\nfreeText: true\nplaceholder: \"The one sentence that makes your ICP say 'tell me more'\"\n```\n\n**Question 8: Existing Copy** (Optional)\n\n```\nheader: \"Examples\"\nquestion: \"Do you have any existing copy you love or hate? (Paste examples or describe)\"\nfreeText: true\nplaceholder: \"Optional - helps calibrate the voice. e.g., 'I love Stripe's docs - clear, technical, no fluff'\"\n```\n\n**Question 9+: Gap-Filling**\n\nAfter core questions, verify you have clarity on:\n- Brand personality (clear, specific)\n- Voice dimensions (where on each spectrum)\n- What to avoid (anti-patterns)\n- Core messages (value props)\n\nKeep asking until confident.\n\n### Phase 2: Draft Generation\n\nGenerate BRAND_GUIDELINES.md using this structure:\n\n```markdown\n# [Product Name] Brand Guidelines\n\n> **The Single Rule**: [One sentence that captures how every piece of copy should feel]\n\n---\n\n## Voice Identity\n\n[One paragraph describing the brand's personality - who it would be if it were a person talking to the ICP]\n\n### Voice Characteristics\n\n| Characteristic | What This Means | Example |\n|----------------|-----------------|---------|\n| [Trait 1] | [How it manifests in copy] | \"[Sample phrase]\" |\n| [Trait 2] | [How it manifests in copy] | \"[Sample phrase]\" |\n| [Trait 3] | [How it manifests in copy] | \"[Sample phrase]\" |\n\n### We Are / We Are NOT\n\n| We Are... | We Are NOT... |\n|-----------|---------------|\n| [Positive trait] | [Opposite to avoid] |\n| [Positive trait] | [Opposite to avoid] |\n| [Positive trait] | [Opposite to avoid] |\n| [Positive trait] | [Opposite to avoid] |\n\n---\n\n## Tone by Context\n\nVoice is constant. Tone flexes based on context.\n\n| Context | Tone Shift | Example |\n|---------|------------|---------|\n| **Marketing/Landing** | [How tone adjusts] | \"[Sample]\" |\n| **In-App UI** | [How tone adjusts] | \"[Sample]\" |\n| **Error Messages** | [How tone adjusts] | \"[Sample]\" |\n| **Success States** | [How tone adjusts] | \"[Sample]\" |\n| **Email/Notifications** | [How tone adjusts] | \"[Sample]\" |\n| **Help/Support** | [How tone adjusts] | \"[Sample]\" |\n\n---\n\n## Language Rules\n\n### USE These Words/Phrases\n\n| Word/Phrase | When to Use | Instead of |\n|-------------|-------------|------------|\n| [Term] | [Context] | [Generic alternative] |\n| [Term] | [Context] | [Generic alternative] |\n| [Term] | [Context] | [Generic alternative] |\n\n### AVOID These Words/Phrases\n\n| Word/Phrase | Why | Use Instead |\n|-------------|-----|-------------|\n| [Term] | [Reason it's off-brand] | [Better alternative] |\n| [Term] | [Reason it's off-brand] | [Better alternative] |\n| [Term] | [Reason it's off-brand] | [Better alternative] |\n\n### Product Terminology\n\n| Term | Definition | Usage |\n|------|------------|-------|\n| [Product-specific term] | [What it means] | [How to use in copy] |\n| [Product-specific term] | [What it means] | [How to use in copy] |\n\n### Style Rules\n\n- **Contractions**: [Yes/No/When]\n- **Sentence length**: [Preference]\n- **Paragraph length**: [Preference]\n- **Emoji**: [Yes/No/When]\n- **Exclamation marks**: [Yes/No/When]\n- **Oxford comma**: [Yes/No]\n- **Capitalization**: [Rules]\n\n---\n\n## Messaging Framework\n\n### The Hook\n\n> [The single most compelling sentence that grabs ICP attention]\n\n### Core Value Propositions\n\n**Value Prop 1: [Name]**\n- **The claim**: [One sentence]\n- **Why it matters to ICP**: [Connection to their pain/values from CUSTOMER.md]\n- **Proof point**: [Evidence that supports this]\n- **Sample copy**: \"[Example headline or sentence]\"\n\n**Value Prop 2: [Name]**\n- **The claim**: [One sentence]\n- **Why it matters to ICP**: [Connection to their pain/values]\n- **Proof point**: [Evidence]\n- **Sample copy**: \"[Example]\"\n\n**Value Prop 3: [Name]**\n- **The claim**: [One sentence]\n- **Why it matters to ICP**: [Connection to their pain/values]\n- **Proof point**: [Evidence]\n- **Sample copy**: \"[Example]\"\n\n---\n\n## Copy Patterns\n\n### Headlines\n\n- **Pattern**: [Structure - e.g., \"Verb + Outcome\" or \"Question that implies problem\"]\n- **Length**: [Word count guideline]\n- **Good examples**:\n  - \"[Example 1]\"\n  - \"[Example 2]\"\n- **Bad examples**:\n  - \"[What to avoid 1]\"\n  - \"[What to avoid 2]\"\n\n### Subheads\n\n- **Pattern**: [Structure]\n- **Length**: [Guideline]\n- **Good examples**:\n  - \"[Example]\"\n- **Bad examples**:\n  - \"[What to avoid]\"\n\n### CTAs (Calls to Action)\n\n- **Pattern**: [Structure - e.g., \"Action verb + object\" or \"Benefit-focused\"]\n- **Good examples**:\n  - \"[Example 1]\"\n  - \"[Example 2]\"\n- **Bad examples**:\n  - \"[What to avoid]\"\n\n### Microcopy (Buttons, Labels, Tooltips)\n\n- **Pattern**: [Structure]\n- **Good examples**:\n  - \"[Example]\"\n- **Bad examples**:\n  - \"[What to avoid]\"\n\n### Error Messages\n\n- **Tone**: [How to handle errors - apologetic? matter-of-fact? helpful?]\n- **Pattern**: [Structure - e.g., \"What happened + What to do\"]\n- **Good examples**:\n  - \"[Example]\"\n- **Bad examples**:\n  - \"[What to avoid]\"\n\n### Empty States\n\n- **Tone**: [Encouraging? Instructive? Playful?]\n- **Pattern**: [Structure]\n- **Good examples**:\n  - \"[Example]\"\n- **Bad examples**:\n  - \"[What to avoid]\"\n\n---\n\n## Transformations\n\nShow how generic copy becomes on-brand copy.\n\n| Before (Generic) | After (On-brand) | Why Better |\n|------------------|------------------|------------|\n| \"[Generic copy]\" | \"[Brand copy]\" | [What changed] |\n| \"[Generic copy]\" | \"[Brand copy]\" | [What changed] |\n| \"[Generic copy]\" | \"[Brand copy]\" | [What changed] |\n\n---\n\n## Quick Reference\n\n**Voice in one sentence**: [Brand] sounds like [memorable analogy].\n\n**Before writing, check**:\n- [ ] Does this sound like [brand personality]?\n- [ ] Would [ICP from CUSTOMER.md] respond to this?\n- [ ] Am I using approved terminology?\n- [ ] Is this the right tone for this context?\n- [ ] Have I avoided all anti-patterns?\n\n---\n\n## Customer Context\n\n> *Pulled from CUSTOMER.md for reference*\n\n**Who we're talking to**: [ICP summary]\n\n**Their main pain**: [Key pain point]\n\n**What they value**: [Key values from CUSTOMER.md]\n\n**What turns them off**: [Anti-persona traits to avoid triggering]\n```\n\nWrite this file to the current working directory as `BRAND_GUIDELINES.md`.\n\n### Phase 3: Refinement\n\nAfter generating the initial document, test and refine:\n\n**Step 3.1: Sample Copy Test**\n\nGenerate 3 sample pieces of copy using the brand guidelines:\n1. A headline + subhead for the landing page\n2. An error message\n3. A feature description\n\nPresent to user:\n\n```\nheader: \"Sample Copy\"\nquestion: \"Does this copy feel like your brand?\"\n[Display the samples]\noptions:\n  - \"Yes - this nails the voice\"\n  - \"Close - minor adjustments needed\"\n  - \"Off - something's not right\"\n```\n\n**Step 3.2: Specific Feedback**\n\nIf not \"Yes\":\n\n```\nheader: \"What's Off?\"\nquestion: \"What needs adjustment?\"\noptions:\n  - \"Too formal / stiff\"\n  - \"Too casual / unprofessional\"\n  - \"Too playful / not serious enough\"\n  - \"Too serious / needs more personality\"\n  - \"Wrong word choices\"\n  - \"Doesn't sound like us\"\n  - \"Other - let me explain\"\nmultiSelect: true\n```\n\n**Step 3.3: Update and Iterate**\n\nBased on feedback:\n1. Update the voice characteristics\n2. Adjust the examples\n3. Refine the \"We Are / We Are NOT\" table\n4. Re-generate sample copy\n\n**Step 3.4: Completion Check**\n\n```\nheader: \"Continue?\"\nquestion: \"Want to refine more or test more samples?\"\noptions:\n  - \"Yes - generate more samples to test\"\n  - \"No - the brand guidelines are solid\"\n  - \"Almost - one more round should do it\"\n```\n\n### Phase 4: Finalization\n\nWhen user is satisfied:\n\n1. Add Version History\n2. Add usage instructions\n3. Remind user to reference this doc when writing ANY copy\n\n```markdown\n---\n\n## Version History\n\n- **v1.0** - [Date] - Initial creation\n\n## Usage\n\nReference this document for ALL copy:\n- Marketing pages\n- In-app UI text\n- Email templates\n- Error messages\n- Help documentation\n- Social media\n- Sales materials\n\n**The test**: Read your copy out loud. Does it sound like [brand personality]? If not, rewrite.\n```\n\n## Key Principles\n\n### Voice â‰  Tone\n- **Voice** is constant (the brand's personality)\n- **Tone** flexes by context (error vs marketing vs support)\n- Define both clearly\n\n### Grounded in Customer\n- Every voice choice should resonate with the ICP\n- Reference CUSTOMER.md pain points and values\n- The voice must feel like it's FOR them\n\n### Actionable Over Abstract\n- Don't just say \"be friendly\" - show what friendly looks like\n- Every guideline needs examples\n- Before/after transformations teach better than rules\n\n### Anti-Patterns Are Critical\n- Knowing what NOT to do is as important as knowing what to do\n- Be specific about voice anti-patterns\n- \"Don't sound corporate\" is vague; list the actual words to avoid\n\n### Test with Real Copy\n- Guidelines are theory; sample copy is proof\n- If the generated samples feel wrong, the guidelines are wrong\n- Iterate until samples feel authentically on-brand\n\n### Reduce Cognitive Load\n- ALWAYS use AskUserQuestion tool when available\n- **Put recommended option FIRST** with \"(Recommended)\" suffix\n- **Pre-fill recommendations from CUSTOMER.md** - user should be able to accept all defaults\n- Present multi-choice questions to minimize typing\n- Limit options to 6-8 max per question\n- Use multiSelect for non-exclusive choices\n- Only use free-text for essential context (value props, hooks)\n\n## Output Location\n\nWrite `BRAND_GUIDELINES.md` to the current working directory (or user-specified path)."
              },
              {
                "name": "define-customer-profile",
                "description": "Iteratively craft a CUSTOMER.md document that precisely defines your ideal customer profile (ICP). This is the foundational document from which everything else (product, features, brand) derives. Uses parallel research agents and multi-choice workflow with feedback cycles.",
                "path": "claude-plugins/solo-dev/skills/define-customer-profile/SKILL.md",
                "frontmatter": {
                  "name": "define-customer-profile",
                  "description": "Iteratively craft a CUSTOMER.md document that precisely defines your ideal customer profile (ICP). This is the foundational document from which everything else (product, features, brand) derives. Uses parallel research agents and multi-choice workflow with feedback cycles."
                },
                "content": "**User request**: $ARGUMENTS\n\n# Customer Profile Skill\n\nCreate the foundational CUSTOMER.md document through iterative refinement. This document precisely defines WHO your customer is, their problems, behaviors, and what they value. **Everything else in the product derives from this document.**\n\n> **This is the most important document your product will ever have.** Product decisions, feature prioritization, and even brand guidelines all flow from understanding the customer. Get this right first.\n\n## Overview\n\nThis skill supports both **creating a new customer doc** and **refining an existing one**. Users come back to adjust their ICP as they learn more about their market or pivot their product.\n\n**Loop**: Check existing â†’ Discover â†’ Research â†’ Draft â†’ Refine â†’ Repeat until complete\n\nThis skill guides you through:\n0. **Check Existing** - Look for existing CUSTOMER.md; let user choose to refine or start fresh\n1. **Discovery** - Clarifying questions about your product, market, and current understanding (keeps asking until confident)\n2. **Research Phase** - Launch parallel agents to research ICP data, market, competitors (optional)\n3. **Initial Draft** - Generate first CUSTOMER.md based on inputs + research\n4. **Refinement & Completion** - Review sections, validate assumptions, update doc, finalize\n\n**Returning users** can skip to Phase 4 to refine specific sections.\n\n### Where the Value Comes From\n\nThe discovery questions give you a solid starting point, but **the real magic happens in Phase 2 (Research) and Phase 4 (Refinement)**:\n- Research agents dig into real market data, competitor positioning, and ICP characteristics\n- You validate whether the ICP resonates with your actual experience\n- Each cycle sharpens the doc until it truly captures YOUR ideal customer\n\n**Discovery log**: `/tmp/customer-discovery-{YYYYMMDD-HHMMSS}.md` - external memory updated after each step.\n\n## Workflow\n\n### Initial Setup (TodoWrite immediately)\n\n**Create todo list** - areas to discover, not steps. List expands as user answers reveal new areas.\n\n**Starter todos**:\n```\n- [ ] Check for existing CUSTOMER.md\n- [ ] Discovery questions (product, ICP, pain points)\n- [ ] Research (if requested)\n- [ ] (expand as discovery reveals complexity)\n- [ ] Generate initial draft\n- [ ] Refinement cycles\n- [ ] Finalize document\n```\n\n**Create discovery log** at `/tmp/customer-discovery-{YYYYMMDD-HHMMSS}.md`:\n\n```markdown\n# Discovery Log: Customer Profile\nStarted: {timestamp}\n\n## Discovery Answers\n(populated incrementally)\n\n## Research Findings\n(populated incrementally)\n\n## Decisions Made\n(populated incrementally)\n\n## Refinement Notes\n(populated incrementally)\n```\n\n### Phase 0: Check for Existing Document\n\n**Mark \"Check for existing CUSTOMER.md\" todo `in_progress`.**\n\nBefore starting discovery, check if the user already has a CUSTOMER.md:\n\n1. **Search for existing doc**: Use Glob to search for `**/CUSTOMER.md` in the current directory and common locations\n2. **If found**: Read it and ask the user what they want to do\n\n```\nheader: \"Existing Customer Doc Found\"\nquestion: \"I found an existing CUSTOMER.md. What would you like to do?\"\noptions:\n  - \"Refine it - update specific sections based on new learnings\"\n  - \"Start fresh - create a new customer profile from scratch\"\n  - \"Review it - just read through what's there\"\n```\n\n**If \"Refine it\"**: Ask which sections need updating, then jump to Phase 4 with targeted questions.\n\n**If \"Start fresh\"**: Proceed to Phase 1 (Discovery) - will overwrite the existing doc.\n\n**If \"Review it\"**: Read and display the doc, then ask what they want to do next.\n\n3. **If NOT found**: Proceed directly to Phase 1 (Discovery)\n\n**Mark \"Check for existing CUSTOMER.md\" todo `completed`.**\n\n### Phase 1: Discovery\n\n**Mark \"Discovery questions\" todo `in_progress`.**\n\nUse AskUserQuestion tool with multi-choice options for EVERY question. **Put the recommended option FIRST** with \"(Recommended)\" suffix to reduce cognitive load.\n\n**After EACH question**, append to discovery log:\n```markdown\n### Q{N}: {question topic}\n**Answer**: {user's answer}\n**Impact**: {what this reveals about ICP}\n**New areas**: {any new todos to add}\n```\n\n**Recommendation Strategy**: Since there's no prior document, recommendations are based on:\n- Most common patterns for solo devs/indie hackers\n- Product type (once selected, informs subsequent recommendations)\n- Sensible defaults that apply to most cases\n\n**Question 1: Product Stage**\n\n```\nheader: \"Product Stage\"\nquestion: \"Where is your product in its lifecycle?\"\noptions:\n  - \"Early stage - have some users, finding PMF (Recommended)\"\n  - \"Pre-launch - still building, no customers yet\"\n  - \"Growth stage - PMF found, scaling acquisition\"\n  - \"Mature - established product, optimizing\"\n```\n\nRecommendation: \"Early stage\" is most common for solo devs using this tool.\n\n**Question 2: Product Type**\n\n```\nheader: \"Product Type\"\nquestion: \"What type of product are you building?\"\noptions:\n  - \"B2B SaaS - software for businesses (Recommended)\"\n  - \"Developer tool - for engineers/developers\"\n  - \"B2C app - consumer application\"\n  - \"Marketplace/Platform - connecting buyers and sellers\"\n  - \"Content/Media - newsletter, course, community\"\n  - \"Physical product - hardware or tangible goods\"\n```\n\nRecommendation: \"B2B SaaS\" is most common. Use selected type to inform later recommendations.\n\n**Question 3: Problem Space** (Free text)\n\n```\nheader: \"Problem\"\nquestion: \"What core problem does your product solve?\"\nfreeText: true\nplaceholder: \"Describe the main pain point (e.g., 'Teams waste hours manually syncing data between tools')\"\n```\n\nThis is essential context that's hard to multiple-choice. Get 1-2 sentences.\n\n**Question 4: Current Customer Knowledge**\n\n```\nheader: \"Current Understanding\"\nquestion: \"How well do you know your ideal customer today?\"\noptions:\n  - \"Somewhat - have some customers, seeing some patterns (Recommended)\"\n  - \"Very well - I've talked to many, have clear patterns\"\n  - \"Vaguely - have hypotheses but not validated\"\n  - \"Not at all - need to figure this out from scratch\"\n```\n\nRecommendation: \"Somewhat\" - most users have some signal but need help structuring it.\n\n**Question 5: Primary Value Proposition**\n\n```\nheader: \"Value Prop\"\nquestion: \"What's the PRIMARY value you deliver?\"\noptions:\n  - \"Save time - automation, efficiency (Recommended)\"\n  - \"Save money - cost reduction, better ROI\"\n  - \"Make money - revenue generation, growth\"\n  - \"Reduce risk - security, compliance, reliability\"\n  - \"Improve quality - better outcomes, fewer errors\"\n  - \"Enable capability - do something previously impossible\"\n  - \"Provide enjoyment - entertainment, satisfaction\"\n```\n\nRecommendation: \"Save time\" is the most common value prop for SaaS products.\n\n**Question 6: Purchase Decision**\n\nRecommendation based on product type:\n- B2B SaaS â†’ \"Team lead\" or \"Individual user\"\n- Developer tool â†’ \"Individual user\"\n- B2C â†’ \"Individual user\"\n- Enterprise â†’ \"Multiple stakeholders\"\n\n```\nheader: \"Buyer Type\"\nquestion: \"Who makes the purchase decision?\"\noptions:\n  - \"Individual user - they buy for themselves (Recommended for B2C/dev tools)\"\n  - \"Team lead - buys for their team (Recommended for B2B SaaS)\"\n  - \"Executive/C-suite - strategic purchase\"\n  - \"Procurement/IT - goes through formal process\"\n  - \"Multiple stakeholders - committee decision\"\n  - \"No purchase - free product, other monetization\"\n```\n\n**Question 7: Known Customer Characteristics**\n\n```\nheader: \"Customer Traits\"\nquestion: \"What do you know about your best customers? (Select all that apply)\"\noptions:\n  - \"Pain intensity (desperate vs nice-to-have) (Recommended)\"\n  - \"Specific job title or role (Recommended)\"\n  - \"Behavioral patterns (power users, specific workflows)\"\n  - \"Company size or type\"\n  - \"Technical skill level\"\n  - \"Specific industry or vertical\"\n  - \"Geographic location\"\nmultiSelect: true\n```\n\nRecommendation: \"Pain intensity\" and \"Job title/role\" are the most actionable traits for targeting.\n\n**Question 7b: Trait Details (Follow-up)**\n\nFor EACH trait selected in Q7, ask a targeted follow-up to capture specifics:\n\n| If Selected | Follow-up Question |\n|-------------|-------------------|\n| Job title/role | \"What specific titles? (e.g., 'Engineering Manager', 'Head of Product')\" |\n| Company size | \"What size range? (e.g., '10-50 employees', 'Series A-B startups')\" |\n| Technical skill | \"What skill level? (e.g., 'Can write code', 'Uses no-code tools')\" |\n| Industry | \"Which industries? (e.g., 'Fintech', 'Healthcare SaaS')\" |\n| Geographic | \"Which regions? (e.g., 'US-based', 'English-speaking markets')\" |\n| Behavioral | \"What behaviors? (e.g., 'Uses Slack daily', 'Already has a workflow')\" |\n| Pain intensity | \"How desperate? (e.g., 'Hair on fire', 'Nice efficiency gain')\" |\n\nUse free-text for these follow-ups - the specifics matter and are hard to predict.\n\n**Question 8: What They're NOT**\n\nRecommendation based on product type:\n- B2B SaaS (small team) â†’ Recommend \"Enterprise\" as anti-persona\n- Developer tool â†’ Recommend \"Beginners\" as anti-persona\n- B2C consumer â†’ Recommend \"Enterprise\" as anti-persona\n\n```\nheader: \"Anti-Personas\"\nquestion: \"Who is explicitly NOT your customer? (Select all that apply)\"\noptions:\n  - \"Enterprise (too slow, complex sales) (Recommended for solo devs)\"\n  - \"Price-sensitive buyers (race to bottom) (Recommended)\"\n  - \"Beginners (need too much hand-holding)\"\n  - \"SMB (can't afford, high churn)\"\n  - \"Experts (don't need the product)\"\n  - \"Specific industry (bad fit)\"\n  - \"Not sure yet - need to figure this out\"\nmultiSelect: true\n```\n\nRecommendation: Most solo devs should avoid \"Enterprise\" (sales cycle too long) and \"Price-sensitive\" (race to bottom).\n\n**Question 8b: Anti-Persona Details (Follow-up)**\n\nFor EACH anti-persona selected in Q8 (except \"Not sure yet\"), ask why:\n\n| If Selected | Follow-up Question |\n|-------------|-------------------|\n| Enterprise | \"Why avoid enterprise? (e.g., 'Sales cycle too long', '6+ month deals kill us')\" |\n| SMB | \"Why avoid SMB? (e.g., 'Churn too high', 'Can't afford $X/mo')\" |\n| Beginners | \"Why avoid beginners? (e.g., 'Support burden', 'Don't understand the value')\" |\n| Experts | \"Why avoid experts? (e.g., 'Build their own', 'Our solution is too basic')\" |\n| Price-sensitive | \"Why avoid price-sensitive? (e.g., 'Race to bottom', 'High churn')\" |\n| Specific industry | \"Which industries and why? (e.g., 'Healthcare - compliance nightmare')\" |\n\nUse free-text - understanding the WHY behind anti-personas is critical.\n\n**Question 9: Research Needs**\n\nRecommendation based on customer knowledge (Q4):\n- \"Not at all\" or \"Vaguely\" â†’ Recommend \"Full research\"\n- \"Somewhat\" â†’ Recommend \"Light research\"\n- \"Very well\" â†’ Recommend \"No research\"\n\n```\nheader: \"Research\"\nquestion: \"Do you want me to research your market and competitors to inform the ICP?\"\noptions:\n  - \"Light research - just validate my assumptions (Recommended)\"\n  - \"Yes, full research - ICP patterns, competitors, market data (takes longer)\"\n  - \"No research - I have enough context, just help me structure it\"\n```\n\nDefault recommendation: \"Light research\" balances speed with validation.\n\n**Question 10: Additional Context** (Free text)\n\n```\nheader: \"Context\"\nquestion: \"Anything else I should know?\"\nfreeText: true\nplaceholder: \"Product name, URL, existing customers, specific hypotheses, competitors you know about...\"\n```\n\n**Question 11: Current State & Triggers** (Free text)\n\n```\nheader: \"Current State\"\nquestion: \"What does your ICP do TODAY to solve this problem (before your product)?\"\nfreeText: true\nplaceholder: \"e.g., 'They use spreadsheets and manually update them weekly' or 'They don't solve it at all'\"\n```\n\n```\nheader: \"Triggers\"\nquestion: \"What triggers them to actively seek a solution?\"\nfreeText: true\nplaceholder: \"e.g., 'When they miss a deadline due to the problem' or 'When a new team member joins and asks why they do it this way'\"\n```\n\n**Question 12+: Gap-Filling Questions**\n\nAfter the core questions, assess whether you have enough clarity to proceed. If ANY of these are unclear, ask follow-up questions:\n\n| Gap | Follow-up Needed |\n|-----|-----------------|\n| Unclear ICP boundaries | \"Where exactly is the line between good and bad customers?\" |\n| Vague pain points | \"Can you give me a specific example of when this pain happens?\" |\n| Unknown current state | \"Walk me through what they do today, step by step\" |\n| Unclear triggers | \"What's the moment when they realize they need to solve this?\" |\n| Missing context | \"What else should I know about their world?\" |\n\n**Keep asking until you are highly confident** about:\n1. Who the ICP is (specific, not vague)\n2. Who they are NOT (clear anti-personas)\n3. What problem they have (specific pain)\n4. What they do today (current state)\n5. What triggers them to seek a solution\n6. How research should be focused (if requested)\n\n**Todo Expansion Triggers** (add todos when user reveals):\n| User Answer Reveals | Add Todo For |\n|---------------------|--------------|\n| Multiple customer segments | Each segment's characteristics |\n| Complex buying process | Purchase journey mapping |\n| Industry-specific needs | Industry research |\n| Unclear anti-personas | Anti-persona validation |\n| New pain points | Pain point prioritization |\n\nOnly proceed to Phase 2/3 when gaps are filled.\n\n**Mark \"Discovery questions\" todo `completed`.**\n\n### Phase 2: Research Phase (If Requested)\n\n**If user requested research, mark \"Research\" todo `in_progress`.**\n\nIf user requested research, launch 2-3 parallel opus agents to gather data. **Skip this phase if user said \"No research\"**.\n\n**IMPORTANT**: Use the Task tool to launch these agents IN PARALLEL (single message with multiple Task calls):\n\n**Agent 1: ICP Pattern Researcher**\n```\nLaunch Task agent (subagent_type: general-purpose, model: opus) with prompt:\n\"Research ideal customer profile patterns for [product type] in the [problem space].\nFind:\n1. Common job titles and roles of buyers\n2. Company characteristics (size, stage, industry)\n3. Behavioral indicators of high-intent buyers\n4. Pain points that drive purchase decisions\n5. Typical objections and concerns\n\nUse WebSearch to find relevant data. Focus on actionable patterns, not generic advice.\nReturn structured findings.\"\n```\n\n**Agent 2: Competitor/Market Researcher**\n```\nLaunch Task agent (subagent_type: general-purpose, model: opus) with prompt:\n\"Research the competitive landscape for [product description].\nFind:\n1. Key competitors and their target customers\n2. How competitors position their ICP\n3. Gaps in the market (underserved segments)\n4. Pricing tiers and what they signal about target customer\n5. Customer reviews/complaints that reveal unmet needs\n\nUse WebSearch to find relevant data.\nReturn structured findings.\"\n```\n\n**Agent 3: Anti-Persona Researcher** (if user was unsure about anti-personas)\n```\nLaunch Task agent (subagent_type: general-purpose, model: opus) with prompt:\n\"Research who are the WRONG customers for [product type] solving [problem].\nFind:\n1. Customer segments that typically churn\n2. Buyer types that require too much support\n3. Use cases that are poor fits\n4. Warning signs in the sales process\n5. Communities/channels to avoid\n\nUse WebSearch to find relevant data.\nReturn structured findings.\"\n```\n\n**Fallback Handling**\n\nIf research tools are unavailable or agents fail:\n1. Inform the user: \"Research tools unavailable. Proceeding with discovery data only.\"\n2. Skip to Phase 3 with a note in the document that research was not performed\n3. Recommend the user manually research competitors and validate assumptions\n\n**Research Synthesis Step**\n\nAfter all agents complete, synthesize findings BEFORE generating the document:\n\n1. **Combine agent outputs** into a structured summary:\n   - **ICP Patterns Found**: [Key patterns from Agent 1]\n   - **Competitive Insights**: [Key findings from Agent 2]\n   - **Anti-Persona Signals**: [Key findings from Agent 3]\n\n2. **Present summary to user** for validation:\n   ```\n   header: \"Research Summary\"\n   question: \"Here's what I found. Does this align with your understanding?\"\n   [Display synthesized findings]\n   options:\n     - \"Yes - this matches my experience\"\n     - \"Partially - some insights are new/surprising\"\n     - \"No - this doesn't match my market\"\n   ```\n\n3. **If \"Partially\" or \"No\"**: Ask what's different and adjust before generating doc:\n   ```\n   header: \"Adjustments\"\n   question: \"What should I adjust based on your real-world experience?\"\n   freeText: true\n   placeholder: \"e.g., 'The competitors mentioned aren't our real competition - we compete with spreadsheets'\"\n   ```\n\n4. **Reconcile research with user knowledge** - user's direct experience trumps generic research. Note discrepancies in the doc as areas to validate.\n\n**After research synthesis, append to discovery log**:\n```markdown\n## Research Findings\n**ICP Patterns**: {summary from Agent 1}\n**Competitive Insights**: {summary from Agent 2}\n**Anti-Persona Signals**: {summary from Agent 3}\n**User validation**: {matches/differs from user experience}\n**Adjustments made**: {any changes based on user feedback}\n```\n\n**Mark \"Research\" todo `completed`.**\n\n### Phase 3: Initial Document Generation\n\n**Mark \"Generate initial draft\" todo `in_progress`.**\n\nAfter discovery (and optional research), generate the first CUSTOMER.md.\n\nUse this structure:\n\n```markdown\n# [Product Name] Ideal Customer Profile\n\n> **THE Guiding Principle**: [One sentence that captures the north star for customer decisions]\n\n---\n\n**User request**: $ARGUMENTS\n\n## The ICP: [Short Label]\n\n**The ICP is NOT \"[common misconception].\"** It's **[precise definition]**.\n\n| Type | Mindset | Response to [Product] |\n|------|---------|----------------------|\n| **[ICP Label]** | \"[Their worldview]\" | \"[How they react]\" |\n| **[Anti-persona Label]** | \"[Their worldview]\" | \"[Why they reject]\" |\n\n[Brief explanation of why this distinction matters]\n\n---\n\n**User request**: $ARGUMENTS\n\n## Current State & Triggers\n\n**What they do today** (before your product):\n- [Current workflow/tool/process]\n- [Workarounds they use]\n- [Time/money spent on the problem]\n\n**What triggers them to seek a solution**:\n- [Specific event or moment]\n- [Pain threshold that tips them over]\n- [External pressure (boss, deadline, competitor)]\n\n---\n\n**User request**: $ARGUMENTS\n\n## Profile Data\n\n**Primary Psychographic**: [Core mindset and motivation - what drives them]\n\n**The [ICP] vs [Anti-persona] Split**:\n\n| Trait | [ICP] | [Anti-persona] |\n|-------|-------|----------------|\n| **Goal** | [What they want] | [What they want] |\n| **Mindset** | [How they think] | [How they think] |\n| **Response to [product category]** | [Positive signal] | [Negative signal] |\n\n**[Anti-persona] objections (why they're NOT ICP):**\n- \"[Typical objection 1]\"\n- \"[Typical objection 2]\"\n- \"[Typical objection 3]\"\n\n**[ICP] signals:**\n- \"[Positive indicator 1]\"\n- \"[Positive indicator 2]\"\n- \"[Positive indicator 3]\"\n\n**Demographics**:\n- **[Key demographic 1]**: [Specifics]\n- **[Key demographic 2]**: [Specifics]\n- **[Key demographic 3]**: [Specifics]\n\n**Secondary Audience**: [Who else benefits but isn't primary focus]\n\n**Out of Scope**: [Explicit exclusions]\n\n---\n\n**User request**: $ARGUMENTS\n\n## Audiences to Avoid\n\n| Audience | Why | Signs |\n|----------|-----|-------|\n| **[Segment 1]** | [Reason] | [How to identify] |\n| **[Segment 2]** | [Reason] | [How to identify] |\n| **[Segment 3]** | [Reason] | [How to identify] |\n\n---\n\n**User request**: $ARGUMENTS\n\n## ICP Characteristics\n\n### Cognitive\n\n| Characteristic | Signal |\n|----------------|--------|\n| **[Trait 1]** | \"[Observable behavior]\" |\n| **[Trait 2]** | \"[Observable behavior]\" |\n| **[Trait 3]** | \"[Observable behavior]\" |\n\n### Behavioral\n\n| Characteristic | Signal |\n|----------------|--------|\n| **[Trait 1]** | \"[Observable behavior]\" |\n| **[Trait 2]** | \"[Observable behavior]\" |\n| **[Trait 3]** | \"[Observable behavior]\" |\n\n---\n\n**User request**: $ARGUMENTS\n\n## Pain Points (User Voice)\n\n1. **\"[Pain point in customer's words]\"** - [Brief context]\n2. **\"[Pain point in customer's words]\"** - [Brief context]\n3. **\"[Pain point in customer's words]\"** - [Brief context]\n4. **\"[Pain point in customer's words]\"** - [Brief context]\n5. **\"[Pain point in customer's words]\"** - [Brief context]\n\n---\n\n**User request**: $ARGUMENTS\n\n## What the ICP Values (In a Solution)\n\nThese are things the ICP cares about when evaluating solutions. Use these to guide product decisions.\n\n| What They Value | Why It Matters to Them |\n|-----------------|----------------------|\n| [Value 1] | [Why this matters for their workflow/goals] |\n| [Value 2] | [Why this matters for their workflow/goals] |\n| [Value 3] | [Why this matters for their workflow/goals] |\n| [Value 4] | [Why this matters for their workflow/goals] |\n\n> Example: \"Fast interface\" matters because \"Power users have zero patience - they'll leave if it's slow\"\n\n---\n\n**User request**: $ARGUMENTS\n\n## Goals & Success\n\n- **Primary**: [Main outcome they want]\n- **Secondary**: [Supporting outcome]\n- **Tertiary**: [Nice-to-have outcome]\n\n**Success Metric**: [How they measure success]\n\n---\n\n**User request**: $ARGUMENTS\n\n**The North Star**: [One sentence that summarizes what success looks like for the ICP]\n\n---\n\n**User request**: $ARGUMENTS\n\n## Quick Reference\n\n**One-line ICP summary**: [ICP Label] who [core motivation].\n\n**Product decision checklist**:\n- [ ] Does this feature serve [ICP description]?\n- [ ] Would this repel or confuse [Anti-persona]? (Good if yes)\n- [ ] Does this address a real pain point listed above?\n- [ ] Does this align with what the ICP values?\n```\n\n**Template Flexibility**\n\nThe template above is a starting point. Customize based on the product:\n\n1. **Add product-specific context sections** as needed:\n   - Platform/environment context (e.g., skill level tables, tool ecosystem maps)\n   - Domain-specific terminology or skill levels\n   - Industry-specific pain points or workflows\n   - Multiple ICP segments if relevant (but keep it focused)\n\n2. **Use callout blockquotes** for important nuances:\n   ```markdown\n   > **Nuance**: Even [ICP] sometimes prefer [alternative] when [condition].\n   > **Key insight**: [Anti-personas] congregate in [specific places].\n   ```\n\n3. **Emphasize user-voice quotes** - use actual customer language:\n   ```markdown\n   **[ICP] signals:**\n   - \"If the math is correct, I'll try it\"  â† Real customer quote\n   - Doesn't argue about principles         â† Observable behavior\n   ```\n\n4. **Add comparison tables** wherever ICP vs Anti-persona distinctions exist\n\n**What NOT to include** (save for other docs):\n- Pricing strategy â†’ Business Model doc\n- Messaging/voice â†’ Brand Guidelines doc\n- Go-to-market â†’ Marketing Strategy doc\n- Feature roadmap â†’ Product Roadmap doc\n\nWrite this file to the current working directory as `CUSTOMER.md`.\n\n**Mark \"Generate initial draft\" todo `completed`.**\n\n### Phase 4: Refinement Cycles & Completion\n\n**Mark \"Refinement cycles\" todo `in_progress`.**\n\nAfter generating the initial document, begin iterative refinement.\n\n**Expected cycles**: Most users need **2-3 refinement cycles** to get from \"this is okay\" to \"this captures my customer.\" Don't rush - each cycle sharpens the doc.\n\n### Memento Loop for Refinement\n\nFor each refinement cycle:\n1. Mark current refinement todo `in_progress`\n2. Ask validation question (AskUserQuestion)\n3. **Write feedback immediately** to discovery log\n4. If not \"Yes\": add todo for that section's revision\n5. Update CUSTOMER.md\n6. Mark todo `completed`\n7. Repeat until user says \"done\"\n\n**NEVER proceed without writing feedback to log** â€” discovery log is external memory.\n\n**Step 4.1: Section-by-Section Review**\n\nFor each major section, ask for validation:\n\n```\nheader: \"ICP Definition\"\nquestion: \"Does this ICP definition feel accurate?\"\n[Display the ICP section]\noptions:\n  - \"Yes - this captures my ideal customer\"\n  - \"Mostly - needs minor tweaks\"\n  - \"No - this misses the mark\"\n```\n\nIf not \"Yes\", follow up:\n\n```\nheader: \"Feedback\"\nquestion: \"What's wrong with the ICP definition?\"\noptions:\n  - \"Too broad - needs to be more specific\"\n  - \"Too narrow - excludes valid customers\"\n  - \"Wrong characteristics - missing key traits\"\n  - \"Wrong anti-persona - that's actually a good customer\"\n  - \"Missing a customer segment entirely\"\n  - \"Other - let me explain\"\nmultiSelect: true\n```\n\n**Step 4.2: Pain Points Validation**\n\n```\nheader: \"Pain Points\"\nquestion: \"Do these pain points match what you hear from customers?\"\n[Display pain points section]\noptions:\n  - \"Yes - these are the real pain points\"\n  - \"Mostly - but some are wrong or missing\"\n  - \"No - need to rewrite these\"\n```\n\n**Step 4.3: Anti-Personas Validation**\n\n```\nheader: \"Anti-Personas\"\nquestion: \"Are these the right people to avoid?\"\n[Display anti-personas section]\noptions:\n  - \"Yes - avoid these segments\"\n  - \"Mostly - some adjustments needed\"\n  - \"No - wrong exclusions\"\n```\n\n**Step 4.4: Update Document**\n\nBased on ALL feedback:\n\n1. Identify patterns in feedback (what's consistently wrong?)\n2. Update CUSTOMER.md with refined definitions\n3. Add specific examples where needed\n4. Strengthen anti-persona definitions if issues keep appearing\n\n**After each section review, append to discovery log**:\n```markdown\n### Refinement: {section name}\n**Feedback**: {user's response}\n**Issues identified**: {what needed fixing}\n**Changes made**: {summary of updates}\n```\n\n**Step 4.5: Check Completion**\n\n```\nheader: \"Continue?\"\nquestion: \"Want to refine more sections?\"\noptions:\n  - \"Yes - let's review another section\"\n  - \"No - the customer doc is good enough for now\"\n  - \"Almost done - one more pass should perfect it\"\n```\n\nIf \"Yes\" or \"Almost done\", return to Step 4.1.\n\n**Step 4.6: Completion** (When user says \"No\" to more refinement)\n\n**Mark \"Refinement cycles\" todo `completed`. Mark \"Finalize document\" todo `in_progress`.**\n\nWhen user indicates they're done:\n\n1. Read the full discovery log file to restore all decisions, findings, and rationale into context\n2. Add a \"Version History\" section noting when created/updated\n3. Add a \"Usage Instructions\" section for how to use the doc\n4. Display final document summary\n5. Remind user to keep CUSTOMER.md updated as they learn more\n\n**Append to discovery log**:\n```markdown\n## Completion\nFinished: {timestamp} | Questions: {count} | Refinement cycles: {count}\n## Summary\n{Brief summary of ICP definition process}\n```\n\n**Mark \"Finalize document\" todo `completed`. Mark all todos complete.**\n\n**Final additions to append:**\n\n```markdown\n---\n\n**User request**: $ARGUMENTS\n\n## Version History\n\n- **v1.0** - [Date] - Initial creation\n\n## Usage Instructions\n\nThis is your **foundational document**. Use it to:\n- **Feature prioritization**: \"Would our ICP want this? Does it address their pain?\"\n- **Product decisions**: \"Does this align with what the ICP values?\"\n- **Scope control**: \"Is this for our ICP or an anti-persona?\"\n- **User research**: \"Are we talking to ICPs or anti-personas?\"\n- **Validation**: \"Does this person match our ICP signals?\"\n\n**The single question**: \"Does this serve [ICP description]?\"\n\n**Downstream docs** (create these AFTER CUSTOMER.md is solid):\n- Brand Guidelines (how to talk to them)\n- Product Roadmap (what to build for them)\n- Business Model (how to charge them)\n```\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| **Memento** | Write findings to discovery log BEFORE next question; every discovery needing follow-up â†’ todo; update log after EACH step |\n| **Todo-driven** | Create todos for areas to discover; expand when user reveals complexity; never keep mental notes |\n| **Information density** | Every line actionable; concrete examples over abstractions; specific signals over vague guidelines |\n| **Research-backed** | Parallel agents gather real market data; validate against competitive landscape |\n| **Iterative refinement** | Section-by-section validation; track changes; real customer conversations surface issues |\n| **Reduce cognitive load** | Recommended option first; multi-choice over free-text; 6-8 options max; accept defaults â†’ solid result |\n| **Question until confident** | Never proceed with ambiguity; gaps â†’ generic output; verify before phase transitions |\n| **Ground in reality** | Define ICP you HAVE, not WISH; base on actual customers; mark hypotheses as unvalidated |\n\n### Never Do\n\n- Proceed without writing findings to discovery log\n- Keep discoveries as mental notes instead of todos\n- Skip todo list\n- Finalize with unresolved sections\n- Ask questions without AskUserQuestion tool\n- Forget to expand todos when user reveals complexity\n\n## Output Location\n\nWrite `CUSTOMER.md` to the current working directory (or user-specified path)."
              },
              {
                "name": "define-design-guidelines",
                "description": "Create a DESIGN_GUIDELINES.md that defines how to design UI/UX for your customer. Requires CUSTOMER.md to exist first. Covers aesthetic direction, design tokens, typography, color, motion, components, and layout patterns. Bakes in frontend-design skill principles to avoid generic AI aesthetics.",
                "path": "claude-plugins/solo-dev/skills/define-design-guidelines/SKILL.md",
                "frontmatter": {
                  "name": "define-design-guidelines",
                  "description": "Create a DESIGN_GUIDELINES.md that defines how to design UI/UX for your customer. Requires CUSTOMER.md to exist first. Covers aesthetic direction, design tokens, typography, color, motion, components, and layout patterns. Bakes in frontend-design skill principles to avoid generic AI aesthetics."
                },
                "content": "# Design Guidelines Skill\n\nCreate the DESIGN_GUIDELINES.md document that defines HOW to design interfaces for your customer. This document drives all UI/UX: components, layouts, animations, colors, typographyâ€”everything visual.\n\n> **Prerequisite**: CUSTOMER.md must exist. Design without customer definition is just aesthetic preference. The interface must resonate with WHO you're building for.\n\n## Overview\n\nThis skill supports both **creating new design guidelines** and **refining existing ones**.\n\nThis skill guides you through:\n0. **Prerequisite Check** - Verify CUSTOMER.md exists; stop if not\n1. **Deep Analysis** - Launch design-research agent to understand ideal design for the customer\n2. **Discovery** - Confirm/refine design direction with targeted questions\n3. **Generate Document** - Create DESIGN_GUIDELINES.md with full design system\n4. **Automatic Alignment Audit** - Opus agent verifies alignment with CUSTOMER.md/BRAND_GUIDELINES.md, fixes issues, repeats until perfect\n5. **Finalization** - Add version history once audit passes\n\n## Core Philosophy: Anti-AI-Slop\n\n**CRITICAL**: This skill bakes in the frontend-design skill's principles. Every design guideline must avoid generic AI aesthetics:\n\n### What to AVOID (AI Slop)\n- **Generic fonts**: Inter, Roboto, Arial, system fonts, Space Grotesk\n- **ClichÃ© colors**: Purple gradients on white, generic blue CTAs, safe gray palettes\n- **Predictable layouts**: Cookie-cutter grids, template-looking compositions\n- **Safe choices**: Border-radius everywhere, subtle animations, inoffensive everything\n- **Generic components**: Bootstrap/MUI defaults without personality\n\n### What to EMBRACE\n- **Bold aesthetic commitment**: Pick an extreme and execute with precision\n- **Distinctive typography**: Characterful fonts that match the product personality\n- **Intentional color**: Dominant colors with sharp accents, not timid even distribution\n- **Spatial creativity**: Asymmetry, overlap, diagonal flow, grid-breaking elements\n- **Atmospheric details**: Textures, gradients, shadows, effects that create depth\n\n**The test**: Would someone mistake this for a generic template? If yes, it's wrong.\n\n## Workflow\n\n### Phase 0: Prerequisite Check\n\n**CRITICAL**: Before anything else, check for CUSTOMER.md:\n\n1. Use Glob to search for `**/CUSTOMER.md` in the current directory\n2. **If NOT found**: Stop immediately and inform the user:\n\n```\n\"I can't create design guidelines without knowing WHO you're designing for.\n\nPlease create your CUSTOMER.md first using /define-customer.\n\nDesign without customer definition is just aesthetic preferenceâ€”it won't resonate with anyone specific.\"\n```\n\nDo NOT proceed. End the workflow here.\n\n3. **If found**: Read the CUSTOMER.md and extract key context:\n   - ICP definition (who they are)\n   - What they value (speed? precision? fun? simplicity?)\n   - Behavioral traits (patient? impatient? technical? casual?)\n   - Anti-personas (who they're NOT)\n   - Any visual/experience hints\n\n**IMPORTANT - Pre-fill Recommendations**: Use CUSTOMER.md to infer recommended options for all questions:\n\n| If CUSTOMER.md says... | Recommend... |\n|------------------------|--------------|\n| ICP values \"speed\", \"efficiency\", \"no patience\" | Terminal/utilitarian aesthetic, fast animations, dense UI |\n| ICP is technical (developers, engineers) | Monospace typography, dark theme, information-dense |\n| ICP values \"data\", \"statistics\", \"precision\" | Data terminal aesthetic, clinical colors, sharp geometry |\n| ICP is \"fun-seekers\", \"casual players\", \"beginners\" | Playful/soft aesthetic, rounded corners, inviting colors |\n| ICP is \"professionals\", \"executives\" | Refined/luxury aesthetic, premium typography, restrained palette |\n| ICP values \"creativity\", \"expression\" | Bold/maximalist aesthetic, unexpected layouts, strong personality |\n| Anti-persona is \"corporate\" or \"enterprise\" | Avoid generic SaaS look, embrace distinctive character |\n\nThe goal: **User should be able to accept all recommended defaults** and get a design system that resonates with their ICP.\n\nThen check for existing DESIGN_GUIDELINES.md:\n\n```\nheader: \"Existing Design Guidelines Found\"\nquestion: \"I found existing DESIGN_GUIDELINES.md. What would you like to do?\"\noptions:\n  - \"Refine it - update based on new insights\"\n  - \"Start fresh - create new design guidelines\"\n  - \"Review it - just read through what's there\"\n```\n\n### Phase 1: Deep Analysis\n\n**BEFORE asking any questions**, launch the `design-research` agent to deeply analyze the customer profile and determine the ideal design direction.\n\n**Launch the Design Research Agent:**\n\n```\nLaunch Task agent (subagent_type: design-research) with prompt:\n\n\"Analyze the customer profile to determine ideal UI/UX design direction.\n\nCUSTOMER.md path: [path found in Phase 0]\n\nProvide your full design analysis covering:\n1. Customer Design Psychology\n2. Recommended Aesthetic Direction\n3. Typography Recommendation\n4. Color Direction\n5. Geometry & Motion\n6. Signature Elements\n7. Anti-Patterns for This ICP\n8. Design Reference Products\n\nBe specific and decisive. This analysis will inform the entire design system.\"\n```\n\nThe agent will:\n1. Read CUSTOMER.md and BRAND_GUIDELINES.md (if exists)\n2. Research industry design patterns and competitors\n3. Provide comprehensive design analysis with specific recommendations\n\n**After agent completes**, extract the analysis and use it to:\n1. Pre-fill ALL question recommendations with high confidence\n2. Present a summary to the user before discovery questions\n\n**Present Analysis Summary:**\n\n```\nheader: \"Design Analysis\"\nquestion: \"Based on your customer profile, here's my recommended design direction. Does this feel right?\"\n[Display: Aesthetic direction, typography, theme, key signature elements]\noptions:\n  - \"Yes - this direction feels right, let's refine details (Recommended)\"\n  - \"Mostly - good direction but some things feel off\"\n  - \"No - I have a different vision\"\n```\n\nIf \"Yes\" or \"Mostly\", proceed to Phase 2 with agent recommendations as defaults.\nIf \"No\", ask what's different and adjust recommendations.\n\n### Phase 2: Discovery\n\nUse AskUserQuestion for all questions. **Put the recommended option FIRST** with \"(Recommended)\" suffix. **Use the opus agent's analysis to inform ALL recommendations.**\n\n**Question 1: Aesthetic Direction**\n\nThis is the most important question. The entire design system flows from this choice.\n\n**Use the opus agent's recommendation as the default.** The agent has already analyzed CUSTOMER.md deeply.\n\n```\nheader: \"Aesthetic Direction\"\nquestion: \"What aesthetic direction fits your product and customer?\"\noptions:\n  - \"[Inferred from CUSTOMER.md] (Recommended)\"\n  - \"Data terminal - clinical, sharp, information-dense (Bloomberg, trading apps)\"\n  - \"Brutally minimal - stark, essential, no decoration\"\n  - \"Industrial utilitarian - functional, raw, tool-like\"\n  - \"Luxury/refined - premium, elegant, restrained\"\n  - \"Editorial/magazine - typographic, editorial, sophisticated\"\n  - \"Brutalist/raw - bold, unapologetic, confrontational\"\n  - \"Retro-futuristic - nostalgic tech, synthwave, neon\"\n  - \"Playful/toy-like - fun, colorful, delightful\"\n  - \"Soft/pastel - gentle, approachable, calming\"\n  - \"Art deco/geometric - structured, ornamental, patterns\"\n  - \"Organic/natural - flowing, earthy, warm\"\n```\n\n**Question 2: Theme Preference**\n\n**Use the opus agent's color direction analysis.**\n\n```\nheader: \"Theme\"\nquestion: \"What's your primary theme?\"\noptions:\n  - \"[Inferred] (Recommended)\"\n  - \"Dark theme - dark backgrounds, light text (more distinctive)\"\n  - \"Light theme - light backgrounds, dark text (more accessible)\"\n  - \"Both - design for both with theme switching\"\n```\n\n**Question 3: Typography Character**\n\n**Use the opus agent's typography recommendation.**\n\n```\nheader: \"Typography\"\nquestion: \"What typographic character fits your brand?\"\noptions:\n  - \"[Inferred] (Recommended)\"\n  - \"Monospace-forward - technical, precise, data-focused (JetBrains Mono, Fira Code)\"\n  - \"Elegant serif - premium, editorial, sophisticated (Playfair, Cormorant)\"\n  - \"Bold geometric - strong, modern, impactful (Clash Display, Satoshi)\"\n  - \"Rounded/friendly - approachable, soft, inviting (Nunito, Quicksand)\"\n  - \"Editorial mix - display headlines with refined body (custom pairing)\"\n  - \"Clean sans - neutral but NOT generic (Geist, DM Sans - not Inter/Roboto)\"\n```\n\n**Question 4: Geometry & Shape**\n\n**Use the opus agent's geometry & motion analysis.**\n\n```\nheader: \"Geometry\"\nquestion: \"What geometric character defines your UI?\"\noptions:\n  - \"[Inferred] (Recommended)\"\n  - \"Sharp zero-radius - all corners sharp, no exceptions (precision, clinical)\"\n  - \"Minimal/subtle - small radius (4-6px) for polish without softness\"\n  - \"Rounded/soft - generous radius (8-16px) for friendliness\"\n  - \"Pill shapes - fully rounded buttons/badges for playfulness\"\n  - \"Mixed - sharp containers, rounded interactive elements\"\n```\n\n**Question 5: Information Density**\n\n**Use the opus agent's analysis of ICP technical level and patience.**\n\n```\nheader: \"Density\"\nquestion: \"How dense should information be?\"\noptions:\n  - \"[Inferred] (Recommended)\"\n  - \"Dense - information-rich, minimal whitespace (power users)\"\n  - \"Balanced - comfortable density with clear hierarchy\"\n  - \"Spacious - generous whitespace, breathing room\"\n  - \"Editorial - dramatic spacing, statement pieces\"\n```\n\n**Question 6: Motion Philosophy**\n\n**Use the opus agent's motion philosophy recommendation.**\n\n```\nheader: \"Motion\"\nquestion: \"What's your animation philosophy?\"\noptions:\n  - \"[Inferred] (Recommended)\"\n  - \"Instant - <100ms, no unnecessary animation (respects time)\"\n  - \"Functional - fast, purposeful, feedback-focused\"\n  - \"Subtle - refined micro-interactions, polished feel\"\n  - \"Delightful - playful animations, personality-forward\"\n  - \"Dramatic - bold transitions, statement animations\"\n```\n\n**Question 7: Primary Color Direction**\n\n```\nheader: \"Primary Color\"\nquestion: \"What color family anchors your palette?\"\noptions:\n  - \"[Inferred if clear signal] (Recommended)\"\n  - \"Orange/amber - energy, action, warmth\"\n  - \"Blue - trust, calm, professional\"\n  - \"Green - growth, success, nature\"\n  - \"Purple - creativity, premium, unique\"\n  - \"Red/coral - bold, urgent, passionate\"\n  - \"Teal/cyan - modern, tech, fresh\"\n  - \"Neutral - black/white/gray dominant, accent secondary\"\n  - \"Custom - I have specific brand colors\"\n```\n\n**Question 7b: Brand Colors (If \"Custom\" selected)**\n\n```\nheader: \"Brand Colors\"\nquestion: \"What are your brand colors?\"\nfreeText: true\nplaceholder: \"e.g., 'Primary: #F97316 (orange), Secondary: #3B82F6 (blue), Background: #0A0A0B'\"\n```\n\n**Question 8: Technical Constraints**\n\n```\nheader: \"Tech Stack\"\nquestion: \"What's your frontend tech stack?\"\noptions:\n  - \"React + Tailwind (Recommended - most flexible)\"\n  - \"React + CSS-in-JS (styled-components, emotion)\"\n  - \"React + CSS Modules\"\n  - \"Vue + Tailwind\"\n  - \"Vanilla HTML/CSS/JS\"\n  - \"Other framework\"\nmultiSelect: false\n```\n\n**Question 9: Signature Elements**\n\n```\nheader: \"Signature\"\nquestion: \"What should be immediately recognizable about your UI? (Select 2-3)\"\noptions:\n  - \"[Inferred from aesthetic] (Recommended)\"\n  - \"Zero border-radius everywhere\"\n  - \"Monospace typography for data\"\n  - \"Single dominant accent color\"\n  - \"Heavy use of negative space\"\n  - \"Custom cursor or micro-interactions\"\n  - \"Unique loading states\"\n  - \"Distinctive iconography\"\n  - \"Gradient treatments\"\n  - \"Texture or grain overlays\"\n  - \"Bold asymmetric layouts\"\nmultiSelect: true\n```\n\n**Question 10: Product Context** (Free text)\n\n```\nheader: \"Product Context\"\nquestion: \"Describe your product briefly - what does it do and what's the primary interface?\"\nfreeText: true\nplaceholder: \"e.g., 'Chess analysis tool - main screen shows a chess board with win percentage overlay. Data-heavy stats pages.'\"\n```\n\n**Question 11: References** (Optional, free text)\n\n```\nheader: \"References\"\nquestion: \"Any products or websites whose design you admire? (Optional)\"\nfreeText: true\nplaceholder: \"e.g., 'Linear's clean interface, Stripe's documentation, Notion's typography'\"\n```\n\n**Question 12+: Gap-Filling**\n\nAfter core questions, verify you have clarity on:\n- Aesthetic direction (specific, not vague)\n- Typography approach\n- Color palette direction\n- Geometry decisions\n- Motion philosophy\n- Signature elements\n\nKeep asking until confident enough to generate a distinctive design system.\n\n### Phase 3: Generate Document\n\nBased on the design-research agent's analysis and user's confirmed preferences, generate `DESIGN_GUIDELINES.md`.\n\nThe document should include:\n\n1. **Identity** - User, problem, aesthetic direction, \"We Are / We Are NOT\", signature elements, core principles\n2. **Design Tokens** - Colors (surfaces, text, accent, status, borders), typography (fonts, sizes, weights), spacing, geometry, shadows, animation timings, breakpoints\n3. **Voice & Copy** - UI tone, bad/good examples, state copy\n4. **Components** - Cards, buttons, inputs, toasts with specific specs\n5. **Layout Patterns** - Primary layout philosophy, visual hierarchy\n6. **Motion** - Philosophy, orchestrated reveals, loading states\n7. **Anti-Patterns** - AI slop to avoid, brand violations, customer-ignoring mistakes\n8. **Ship Checklist** - Pre-ship verification items\n\n**Incorporate the design-research agent's full analysis** into the documentâ€”especially the anti-patterns, signature elements, and reference products.\n\nWrite `DESIGN_GUIDELINES.md` to the current working directory.\n\n### Phase 4: Automatic Alignment Audit\n\nAfter generating the document, **automatically** audit it against CUSTOMER.md and BRAND_GUIDELINES.md to ensure perfect alignment. This is NOT optionalâ€”run at least one audit cycle.\n\n**Launch the Design Quality Auditor Agent:**\n\n```\nLaunch Task agent (subagent_type: design-quality-auditor) with prompt:\n\n\"Audit DESIGN_GUIDELINES.md for alignment with customer profile and brand guidelines.\n\nDocument paths:\n- DESIGN_GUIDELINES.md: [path]\n- CUSTOMER.md: [path]\n- BRAND_GUIDELINES.md: [path] (if exists)\n\nPerform your full audit protocol and report results.\"\n```\n\nThe agent will:\n1. Read all three documents\n2. Check customer alignment, brand alignment, internal consistency, completeness\n3. Report `âœ… AUDIT PASSED` or `âš ï¸ ISSUES FOUND` with specific fixes\n\n**After audit completes:**\n\n1. **If AUDIT PASSED**: Proceed to finalization\n2. **If ISSUES FOUND**:\n   - Apply all suggested fixes to DESIGN_GUIDELINES.md\n   - Run the audit again\n   - Repeat until AUDIT PASSED (max 3 cycles to prevent infinite loops)\n\n**Example audit issue and fix:**\n```\nISSUE: Customer Alignment - ICP values \"zero patience\" but motion philosophy\nspecifies 300ms animations which feels slow for this audience.\nFIX: Change base animation duration to 100ms, reserve 300ms only for\ncelebratory moments like score reveals.\n```\n\n### Phase 5: Finalization\n\nOnce audit passes, add version history:\n\n```markdown\n---\n\n## Version History\n\n- **v1.0** - [Date] - Initial creation (audit passed)\n\n## Usage\n\nReference this document for ALL UI work. The test: Would your ICP feel this UI was made for them?\n```\n\n## Key Principles\n\n### Grounded in Customer\n- Every design choice should resonate with the ICP\n- Reference CUSTOMER.md values when making decisions\n- If the ICP values speed, the UI must be fast\n- If the ICP is technical, the UI can be dense\n\n### Anti-AI-Slop is Non-Negotiable\n- Every design system must be distinctive\n- Generic choices are wrong by default\n- If it looks like a template, it fails\n- Bold commitment beats safe mediocrity\n\n### Actionable Over Abstract\n- Don't just say \"be bold\" - specify the border-radius\n- Every guideline needs exact values\n- Ship checklist catches drift\n\n### Aesthetic Coherence\n- All tokens must serve the chosen direction\n- Typography, color, motion, geometry align\n- Signature elements appear consistently\n- Deviations are intentional, not accidental\n\n### Reduce Cognitive Load\n- ALWAYS use AskUserQuestion tool when available\n- **Put recommended option FIRST** with \"(Recommended)\" suffix\n- **Pre-fill recommendations from agent analysis** - user should be able to accept defaults\n- Present multi-choice questions to minimize typing\n\n## Output Location\n\nWrite `DESIGN_GUIDELINES.md` to the current working directory (or user-specified path)."
              },
              {
                "name": "define-seo-strategy",
                "description": "Create a comprehensive SEO_STRATEGY.md covering both traditional SEO and Generative Engine Optimization (GEO) for AI platforms. Requires CUSTOMER.md to exist first. Includes platform-specific tactics for Google AI Overviews, ChatGPT, Perplexity, Claude, and Gemini with effort/impact prioritization.",
                "path": "claude-plugins/solo-dev/skills/define-seo-strategy/SKILL.md",
                "frontmatter": {
                  "name": "define-seo-strategy",
                  "description": "Create a comprehensive SEO_STRATEGY.md covering both traditional SEO and Generative Engine Optimization (GEO) for AI platforms. Requires CUSTOMER.md to exist first. Includes platform-specific tactics for Google AI Overviews, ChatGPT, Perplexity, Claude, and Gemini with effort/impact prioritization."
                },
                "content": "# SEO Strategy Skill\n\nCreate the SEO_STRATEGY.md document that defines your complete search optimization strategyâ€”both traditional SEO and Generative Engine Optimization (GEO) for AI platforms.\n\n> **Prerequisite**: CUSTOMER.md must exist. SEO strategy without customer definition is just generic tactics. Your strategy must align with HOW your ICP searches and WHAT platforms they use.\n\n## Overview\n\nThis skill supports both **creating a new SEO strategy** and **updating an existing one** as platforms evolve.\n\n**Loop**: Prerequisites â†’ Input â†’ Research â†’ Draft â†’ Validate â†’ Repeat until approved\n\nThis skill guides you through:\n0. **Prerequisite Check** - Verify CUSTOMER.md exists; stop if not\n1. **Existing Strategy Detection** - Check for SEO_STRATEGY.md; ask update vs fresh\n2. **Input Collection** - Gather website URL and product description\n3. **Parallel Research** - Launch 3 seo-researcher agents for comprehensive analysis\n4. **Document Generation** - Create SEO_STRATEGY.md with prioritized recommendations\n5. **Validation Loop** - Review sections with user, incorporate feedback\n6. **Finalization** - Add version history once approved\n\n**Research log**: `/tmp/seo-research-{YYYYMMDD-HHMMSS}.md` - external memory updated after each step.\n\n## Core Concepts\n\n### Traditional SEO vs GEO\n\n**Traditional SEO**: Optimizing for clicks from search engine results pages (SERPs). Focus on rankings, click-through rates, and organic traffic.\n\n**GEO (Generative Engine Optimization)**: Optimizing for citations in AI-generated responses. Focus on being the source that ChatGPT, Perplexity, Google AI Overviews, Claude, and Gemini cite when answering questions.\n\n**Key difference**: SEO optimizes for clicks. GEO optimizes for citations. Both matter, but they require different tactics.\n\n### Platform Landscape (2025)\n\n| Platform | Citation Style | Key Preferences |\n|----------|---------------|-----------------|\n| **Google AI Overviews** | Integrated with organic results | Structured content, schema markup, top 10 ranking |\n| **ChatGPT** | Reference-heavy | Wikipedia, authoritative sources, E-E-A-T |\n| **Perplexity** | Transparent citations | UGC (Reddit), clear structure, comparisons |\n| **Claude** | Authoritative sources | Well-structured, information-dense content |\n| **Gemini** | Knowledge graph integration | Similar to Google AI Overviews |\n\n## Workflow\n\n### Initial Setup (TodoWrite immediately)\n\n**Create todo list** - areas to research/validate, not fixed steps.\n\n**Starter todos**:\n```\n- [ ] Prerequisite check (CUSTOMER.md)\n- [ ] Existing strategy detection\n- [ ] Input collection\n- [ ] Research (industry, competitors, platforms)\n- [ ] Generate initial draft\n- [ ] Validation (executive summary, platforms, roadmap)\n- [ ] Finalize document\n```\n\n**Create research log** at `/tmp/seo-research-{YYYYMMDD-HHMMSS}.md`:\n\n```markdown\n# SEO Research Log\nStarted: {timestamp}\n\n## Customer Context\n(from CUSTOMER.md)\n\n## Research Findings\n(populated by agents)\n\n## Validation Feedback\n(populated during review)\n\n## Decisions Made\n(populated incrementally)\n```\n\n### Phase 0: Prerequisite Check\n\n**Mark \"Prerequisite check\" todo `in_progress`.**\n\n**CRITICAL**: Before anything else, check for CUSTOMER.md:\n\n1. Use Glob to search for `**/CUSTOMER.md` in the current directory\n2. **If NOT found**: Stop immediately and inform the user:\n\n```\nI can't create an SEO strategy without knowing WHO you're targeting.\n\nPlease create your CUSTOMER.md first using /define-customer.\n\nSEO strategy without customer definition is just generic tacticsâ€”it won't resonate with anyone specific or help you prioritize.\n```\n\nDo NOT proceed. End the workflow here.\n\n3. **If found**: Read the CUSTOMER.md and extract key context:\n   - ICP definition (who they are)\n   - Pain points (what problems they have)\n   - Current state (what they do today)\n   - Triggers (what makes them search)\n   - What they value in a solution\n\nAlso check for BRAND_GUIDELINES.md:\n- Use Glob to search for `**/BRAND_GUIDELINES.md`\n- If found, read it for voice/tone context to align content recommendations\n\n**Append to research log**:\n```markdown\n## Customer Context\n**ICP**: {summary from CUSTOMER.md}\n**Pain points**: {key pain points}\n**Triggers**: {what makes them search}\n**Brand voice**: {from BRAND_GUIDELINES.md if found}\n```\n\n**Mark \"Prerequisite check\" todo `completed`.**\n\n### Phase 1: Existing Strategy Detection\n\n**Mark \"Existing strategy detection\" todo `in_progress`.**\n\nCheck for existing SEO_STRATEGY.md:\n\n1. Use Glob to search for `**/SEO_STRATEGY.md`\n2. **If found**: Ask user what to do:\n\n```\nheader: \"Existing SEO Strategy Found\"\nquestion: \"I found an existing SEO_STRATEGY.md. What would you like to do?\"\noptions:\n  - \"Update it - refresh with latest platform data and recommendations (Recommended)\"\n  - \"Start fresh - create a new strategy from scratch\"\n  - \"Review it - just read through what's there\"\n```\n\n**If \"Update it\"**: Read existing strategy, note what's implemented vs pending, focus research on platform changes and gaps.\n\n**If \"Start fresh\"**: Proceed to Phase 2 (will overwrite existing).\n\n**If \"Review it\"**: Display the strategy, then ask what to do next.\n\n3. **If NOT found**: Proceed directly to Phase 2.\n\n**Mark \"Existing strategy detection\" todo `completed`.**\n\n### Phase 2: Input Collection\n\n**Mark \"Input collection\" todo `in_progress`.**\n\nCollect required inputs via AskUserQuestion.\n\n**Question 1: Website URL** (Required)\n\n```\nheader: \"Website URL\"\nquestion: \"What's the URL of the website/product you want to optimize?\"\nfreeText: true\nplaceholder: \"e.g., https://myproduct.com\"\n```\n\n**Question 2: Product Description** (If not clear from CUSTOMER.md)\n\n```\nheader: \"Product Description\"\nquestion: \"Briefly describe what your product/service does (if not already clear from CUSTOMER.md)\"\nfreeText: true\nplaceholder: \"e.g., 'AI-powered code review tool for Python developers'\"\n```\n\n**Question 3: Top Competitors** (Optional, helps focus research)\n\n```\nheader: \"Competitors\"\nquestion: \"Who are your top 2-3 competitors? (Optional - helps focus research)\"\nfreeText: true\nplaceholder: \"e.g., 'Competitor A (competitor-a.com), Competitor B (competitor-b.com)'\"\n```\n\n**Question 4: Current SEO Status**\n\n```\nheader: \"Current SEO Status\"\nquestion: \"What's your current SEO situation?\"\noptions:\n  - \"Starting from scratch - no SEO work done yet (Recommended for new products)\"\n  - \"Some basics - have content but not optimized\"\n  - \"Intermediate - doing traditional SEO, want to add GEO\"\n  - \"Advanced - strong SEO, need cutting-edge GEO tactics\"\n```\n\n**After input collection, append to research log**:\n```markdown\n## Inputs Collected\n**Website**: {URL}\n**Product**: {description}\n**Competitors**: {list}\n**Current status**: {level}\n```\n\n**Mark \"Input collection\" todo `completed`.**\n\n### Phase 3: Parallel Research\n\n**Mark \"Research\" todo `in_progress`.**\n\nLaunch 3 seo-researcher agents in parallel using the Task tool. Send all three Task calls in a single message.\n\n**IMPORTANT**: Use the Task tool with `subagent_type: seo-researcher` for each agent.\n\n**Agent 1: Industry Analysis**\n\n```\nLaunch Task agent (subagent_type: seo-researcher) with prompt:\n\n\"Research SEO and GEO best practices for [industry from CUSTOMER.md].\n\nContext:\n- Product: [product description]\n- ICP: [from CUSTOMER.md]\n- Competitors: [if provided]\n\nFocus on:\n1. Industry-specific SEO patterns that work\n2. Content formats that perform well in this vertical\n3. Authority signals and trust factors for this industry\n4. Common search queries and keywords\n5. Industry-specific schema markup recommendations\n\nReturn structured findings with confidence levels.\"\n```\n\n**Agent 2: Competitor Structure Analysis**\n\n```\nLaunch Task agent (subagent_type: seo-researcher) with prompt:\n\n\"Analyze competitor content structure and SEO patterns.\n\nCompetitors to analyze: [competitor URLs if provided, or research top competitors in the space]\nIndustry: [from CUSTOMER.md]\n\nFocus on:\n1. Content structure patterns (headings, lists, tables, answer capsules)\n2. Schema markup usage\n3. Third-party presence (Reddit mentions, review sites, listicles)\n4. Content freshness and update patterns\n5. Gaps and opportunities they're missing\n\nReturn structured findings with specific observations.\"\n```\n\n**Agent 3: Platform Requirements Analysis**\n\n```\nLaunch Task agent (subagent_type: seo-researcher) with prompt:\n\n\"Research current citation requirements and patterns for each AI platform.\n\nContext:\n- Industry: [from CUSTOMER.md]\n- Product type: [product description]\n\nFor EACH platform (Google AI Overviews, ChatGPT, Perplexity, Claude, Gemini), research:\n1. How the platform selects sources to cite\n2. Content format preferences\n3. Authority signals that matter\n4. Specific optimization tactics\n5. Anti-patterns to avoid\n\nUse 2025+ data only. Return structured findings per platform.\"\n```\n\n**Research Synthesis**\n\nAfter all agents complete:\n\n1. Combine findings into a unified research summary\n2. Identify patterns across all three research streams\n3. Note any conflicts or uncertainties\n4. Present summary to user:\n\n```\nheader: \"Research Summary\"\nquestion: \"Here's what the research found. Does this align with your understanding?\"\n[Display: Key findings across industry, competitors, and platforms]\noptions:\n  - \"Yes - this matches my understanding (Recommended)\"\n  - \"Mostly - some insights are new or surprising\"\n  - \"No - this doesn't match my market\"\n```\n\nIf \"Mostly\" or \"No\": Ask what's different and incorporate adjustments.\n\n**Append to research log**:\n```markdown\n## Research Findings\n### Industry Analysis\n{summary from Agent 1}\n\n### Competitor Analysis\n{summary from Agent 2}\n\n### Platform Requirements\n{summary from Agent 3}\n\n### User validation\n{matches/differs from user understanding}\n```\n\n**Mark \"Research\" todo `completed`.**\n\n### Phase 4: Document Generation\n\n**Mark \"Generate initial draft\" todo `in_progress`.**\n\nGenerate SEO_STRATEGY.md based on research and user context.\n\n**Document Structure:**\n\n```markdown\n# SEO & GEO Strategy: [Product Name]\n\nGenerated: [Date]\nLast Updated: [Date]\n\n> **TL;DR**: [3-5 priority actions with expected impact]\n\n---\n\n## Executive Summary\n\n### Current State Assessment\n[Based on website URL analysis and user input]\n\n### Top Priority Actions\n\n| Priority | Action | Effort | Impact | Platform |\n|----------|--------|--------|--------|----------|\n| 1 | [Specific action] | Low/Med/High | Low/Med/High | [Which platforms] |\n| 2 | [Specific action] | Low/Med/High | Low/Med/High | [Which platforms] |\n| 3 | [Specific action] | Low/Med/High | Low/Med/High | [Which platforms] |\n| 4 | [Specific action] | Low/Med/High | Low/Med/High | [Which platforms] |\n| 5 | [Specific action] | Low/Med/High | Low/Med/High | [Which platforms] |\n\n### Expected Outcomes\n[What success looks like - specific metrics or indicators]\n\n---\n\n## Customer-Aligned Strategy\n\n### How Your ICP Searches\n[Based on CUSTOMER.md - questions they ask, platforms they use, language they use]\n\n### Content Topics That Resonate\n[Topics aligned with ICP pain points and triggers]\n\n### Authority Signals Your ICP Trusts\n[What makes sources credible to your specific ICP]\n\n---\n\n## Traditional SEO Foundation\n\n### Technical SEO Requirements\n\n**Schema Markup:**\n- [Specific schema types to implement]\n- [Priority order]\n\n**Site Structure:**\n- [URL structure recommendations]\n- [Internal linking strategy]\n\n**Performance:**\n- [Core Web Vitals targets]\n- [Mobile optimization requirements]\n\n### Content Strategy\n\n**Topic Priorities:**\n| Topic | ICP Alignment | Search Volume Signal | Priority |\n|-------|--------------|---------------------|----------|\n| [Topic 1] | [Why it matters to ICP] | [High/Med/Low] | [1-5] |\n\n**Content Formats:**\n- [Format 1]: [Why it works for this industry]\n- [Format 2]: [Why it works for this industry]\n\n**Publishing Cadence:**\n[Recommended frequency with rationale]\n\n### Authority Building\n\n**Backlink Opportunities:**\n- [Specific targets based on industry research]\n\n**Citation Targets:**\n- [Publications, directories, aggregators]\n\n**Third-Party Presence:**\n- [Reddit strategy]\n- [Industry publications]\n- [Review sites]\n\n---\n\n## Platform-Specific GEO\n\n### Google AI Overviews\n\n**How It Selects Sources:**\n[Current understanding from research]\n\n**Content Format Preferences:**\n- [Specific formats that get cited]\n- [Structure recommendations]\n\n**Optimization Tactics:**\n1. [Tactic with implementation details]\n2. [Tactic with implementation details]\n\n**Anti-Patterns to Avoid:**\n- [What hurts citation chances]\n\n---\n\n### ChatGPT\n\n**How It Selects Sources:**\n[Current understanding from research]\n\n**Content Format Preferences:**\n- [Specific formats that get cited]\n- [Structure recommendations]\n\n**Optimization Tactics:**\n1. [Tactic with implementation details]\n2. [Tactic with implementation details]\n\n**Anti-Patterns to Avoid:**\n- [What hurts citation chances]\n\n---\n\n### Perplexity\n\n**How It Selects Sources:**\n[Current understanding from research]\n\n**Content Format Preferences:**\n- [Specific formats that get cited]\n- [Structure recommendations]\n\n**Optimization Tactics:**\n1. [Tactic with implementation details]\n2. [Tactic with implementation details]\n\n**Anti-Patterns to Avoid:**\n- [What hurts citation chances]\n\n---\n\n### Claude\n\n**How It Selects Sources:**\n[Current understanding from research]\n\n**Content Format Preferences:**\n- [Specific formats that get cited]\n- [Structure recommendations]\n\n**Optimization Tactics:**\n1. [Tactic with implementation details]\n2. [Tactic with implementation details]\n\n**Anti-Patterns to Avoid:**\n- [What hurts citation chances]\n\n---\n\n### Gemini\n\n**How It Selects Sources:**\n[Current understanding from research]\n\n**Content Format Preferences:**\n- [Specific formats that get cited]\n- [Structure recommendations]\n\n**Optimization Tactics:**\n1. [Tactic with implementation details]\n2. [Tactic with implementation details]\n\n**Anti-Patterns to Avoid:**\n- [What hurts citation chances]\n\n---\n\n## Content Recommendations\n\n### High-Priority Content Pieces\n\n| Content Piece | Type | Effort | Impact | Platforms Served |\n|---------------|------|--------|--------|------------------|\n| [Title/Topic] | [Blog/FAQ/Comparison/etc] | L/M/H | L/M/H | [Platforms] |\n\n### Content Structure Templates\n\n**Answer Capsule Format:**\n```\n[Question as H2]\n[2-3 sentence direct answer - this is what AI cites]\n[Expanded explanation with details]\n[Supporting data/examples]\n```\n\n**FAQ Structure:**\n```\n## Frequently Asked Questions\n\n### [Question 1]\n[Direct answer in first sentence]\n[Supporting details]\n\n### [Question 2]\n...\n```\n\n**Comparison Table Format:**\n```\n| Feature | [Option A] | [Option B] | [Your Product] |\n|---------|-----------|-----------|----------------|\n| [Feature 1] | [Value] | [Value] | [Value] |\n```\n\n### Schema Markup Recommendations\n\n**Priority Schema Types:**\n1. [Schema type] - [Why/Where to use]\n2. [Schema type] - [Why/Where to use]\n\n---\n\n## Third-Party Presence Strategy\n\n### Platforms to Prioritize\n\n| Platform | Why It Matters | Strategy | Effort |\n|----------|---------------|----------|--------|\n| Reddit | [AI platforms cite Reddit heavily] | [Specific subreddits, approach] | [L/M/H] |\n| [Platform 2] | [Reason] | [Strategy] | [L/M/H] |\n\n### Wikipedia / Knowledge Panel\n[If applicable - strategy for establishing presence]\n\n### Listicle and Review Opportunities\n[Specific targets for getting mentioned in roundups]\n\n---\n\n## Implementation Roadmap\n\n### Quick Wins (Low Effort, High Impact)\nStart here - these deliver results fastest.\n\n1. **[Action]** - [Why it's high impact, low effort]\n2. **[Action]** - [Why it's high impact, low effort]\n3. **[Action]** - [Why it's high impact, low effort]\n\n### Strategic Investments (High Effort, High Impact)\nPlan these into your roadmap.\n\n1. **[Action]** - [Why it's worth the effort]\n2. **[Action]** - [Why it's worth the effort]\n\n### Maintenance (Low Effort, Low Impact)\nDo these after the above are done.\n\n1. **[Action]**\n2. **[Action]**\n\n### Skip These (High Effort, Low Impact)\nNot worth prioritizing now.\n\n1. **[Action]** - [Why to skip]\n\n---\n\n## Anti-Patterns\n\n### What NOT to Do\n\n| Anti-Pattern | Why It Hurts | What to Do Instead |\n|--------------|-------------|-------------------|\n| [Bad practice] | [Consequence] | [Better approach] |\n\n### Platform-Specific Pitfalls\n\n- **Google AI Overviews**: [Specific pitfall]\n- **ChatGPT**: [Specific pitfall]\n- **Perplexity**: [Specific pitfall]\n\n---\n\n## Refresh Cadence\n\nAI platforms evolve rapidly. This strategy should be refreshed quarterly.\n\n**Next Review**: [Date + 3 months]\n\n**Signals to refresh sooner:**\n- Major platform algorithm changes announced\n- Significant drop in AI-referred traffic\n- New AI search platforms gain traction\n- Industry landscape shifts\n\n---\n\n## Version History\n\n- **v1.0** - [Date] - Initial creation\n\n---\n\n## Quick Reference\n\n**One-liner**: [Core strategy in one sentence]\n\n**Decision checklist for new content:**\n- [ ] Does this serve our ICP's search intent?\n- [ ] Is it structured for AI citation (answer capsule, FAQ, etc.)?\n- [ ] Does it include appropriate schema markup?\n- [ ] Is it published on a page with strong internal linking?\n- [ ] Have we considered third-party distribution?\n```\n\n**Effort/Impact Definitions:**\n\n| Level | Effort Definition | Impact Definition |\n|-------|------------------|-------------------|\n| **Low** | < 1 day of work | Marginal visibility improvement |\n| **Medium** | 1-5 days of work | Noticeable improvement in citations/traffic |\n| **High** | > 5 days of work | Significant citation/traffic increase |\n\nWrite the document to the current working directory as `SEO_STRATEGY.md`.\n\n**Mark \"Generate initial draft\" todo `completed`.**\n\n### Phase 5: Validation Loop\n\n**Mark \"Validation\" todo `in_progress`.**\n\nAfter generating the initial document, validate major sections with the user.\n\n### Memento Loop for Validation\n\nFor each validation section:\n1. Mark current section validation `in_progress`\n2. Ask validation question (AskUserQuestion)\n3. **Write feedback immediately** to research log\n4. If not \"Yes\": add todo for that section's revision\n5. Update SEO_STRATEGY.md\n6. Mark section `completed`\n7. Repeat until user approves\n\n**NEVER proceed without writing feedback to log** â€” research log is external memory.\n\n**Section 1: Executive Summary**\n\n```\nheader: \"Executive Summary\"\nquestion: \"Do these priority actions feel right for your situation?\"\n[Display: Top 5 priority actions with effort/impact]\noptions:\n  - \"Yes - these priorities make sense (Recommended)\"\n  - \"Mostly - but some adjustments needed\"\n  - \"No - priorities are off\"\n```\n\nIf not \"Yes\": Ask what to adjust and update.\n\n**Section 2: Platform-Specific Sections**\n\n```\nheader: \"Platform Strategy\"\nquestion: \"Do the platform-specific recommendations make sense?\"\n[Display: Summary of each platform's key tactics]\noptions:\n  - \"Yes - these look actionable (Recommended)\"\n  - \"Mostly - some platforms need adjustment\"\n  - \"No - need to rethink platform approach\"\n```\n\nIf not \"Yes\": Ask which platforms need adjustment and why.\n\n**Section 3: Implementation Roadmap**\n\n```\nheader: \"Implementation Roadmap\"\nquestion: \"Is this roadmap helpful for planning your work?\"\n[Display: Quick Wins and Strategic Investments]\noptions:\n  - \"Yes - clear path forward (Recommended)\"\n  - \"Mostly - need to reprioritize some items\"\n  - \"No - roadmap doesn't fit my constraints\"\n```\n\nIf not \"Yes\": Ask about constraints and reprioritize.\n\n**Completion Check:**\n\n```\nheader: \"Finalize Strategy?\"\nquestion: \"Ready to finalize the SEO strategy?\"\noptions:\n  - \"Yes - strategy is complete (Recommended)\"\n  - \"No - let's review another section\"\n```\n\nIf \"No\": Return to relevant section review.\n\n**After each section validation, append to research log**:\n```markdown\n### Validation: {section name}\n**Feedback**: {user's response}\n**Adjustments requested**: {if any}\n**Changes made**: {summary}\n```\n\n**Mark \"Validation\" todo `completed`.**\n\n### Phase 6: Finalization\n\n**Mark \"Finalize document\" todo `in_progress`.**\n\nWhen user approves:\n\n1. Read the full research log file to restore all findings, decisions, and rationale into context\n2. Update version history with creation date\n3. Set next review date (3 months out)\n4. Display completion summary:\n\n```\n## SEO Strategy Complete\n\nYour SEO_STRATEGY.md has been created with:\n- [X] priority actions identified\n- [X] platform-specific tactics for [platforms]\n- [X] effort/impact scoring for prioritization\n\n**Start with Quick Wins:**\n1. [First quick win]\n2. [Second quick win]\n3. [Third quick win]\n\n**Next review**: [Date]\n\nRun /define-seo-strategy again to update the strategy as platforms evolve.\n```\n\n**Append to research log**:\n```markdown\n## Completion\nFinished: {timestamp} | Research agents: 3 | Validation cycles: {count}\n## Summary\n{Brief summary of SEO strategy creation}\n```\n\n**Mark \"Finalize document\" todo `completed`. Mark all todos complete.**\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| **Memento** | Write findings to research log BEFORE next step; every validation feedback â†’ log; update after EACH phase |\n| **Todo-driven** | Create todos for phases; expand when validation reveals issues; never keep mental notes |\n| **Customer-aligned** | Every recommendation ties to ICP searches; content matches pain points; authority signals ICP trusts |\n| **Actionable** | No generic advice; every tactic has implementation details; effort/impact scoring |\n| **Platform-aware** | Each AI platform has unique patterns; tactics tailored per platform; anti-patterns explicit |\n| **Current data** | 2025+ research only; platforms evolve rapidly; strategy includes refresh cadence |\n| **Reduce cognitive load** | Recommended option first; multi-choice over free-text; limit questions to essentials |\n\n### Never Do\n\n- Proceed without writing findings to research log\n- Keep discoveries as mental notes instead of todos\n- Skip todo list\n- Finalize with unvalidated sections\n- Skip research phase (it's the core value)\n- Forget to expand todos when validation reveals issues\n\n## Output Location\n\nWrite `SEO_STRATEGY.md` to the current working directory (or user-specified path)."
              },
              {
                "name": "write-as-me",
                "description": "Generate text in your voice using your AUTHOR_VOICE.md document. Provide a topic or prompt as argument.",
                "path": "claude-plugins/solo-dev/skills/write-as-me/SKILL.md",
                "frontmatter": {
                  "name": "write-as-me",
                  "description": "Generate text in your voice using your AUTHOR_VOICE.md document. Provide a topic or prompt as argument.",
                  "context": "fork"
                },
                "content": "Use the **voice-writer** agent to generate content in the user's voice.\n\nTopic/prompt: $ARGUMENTS"
              }
            ]
          },
          {
            "name": "vibe-extras",
            "description": "Standalone utilities that complement the core development workflow - git operations, documentation management, and code cleanup",
            "source": "./claude-plugins/vibe-extras",
            "category": "development",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add doodledood/claude-code-plugins",
              "/plugin install vibe-extras@claude-code-plugins-marketplace"
            ],
            "signals": {
              "stars": 8,
              "forks": 0,
              "pushed_at": "2026-01-12T07:05:08Z",
              "created_at": "2025-11-20T15:25:14Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "clean-slop",
                "description": "Find and remove AI-generated slop (useless comments, verbose patterns, unnecessary abstractions).",
                "path": "claude-plugins/vibe-extras/skills/clean-slop/SKILL.md",
                "frontmatter": {
                  "name": "clean-slop",
                  "description": "Find and remove AI-generated slop (useless comments, verbose patterns, unnecessary abstractions).",
                  "context": "fork"
                },
                "content": "Use the slop-cleaner agent to clean up AI slop in: $ARGUMENTS"
              },
              {
                "name": "maximize-info-density",
                "description": "Compresses documents/prompts to maximize information density while preserving semantic content. Use when asked to make content concise, shorten, reduce tokens, tighten, or compress files like CLAUDE.md, skills, or specs.",
                "path": "claude-plugins/vibe-extras/skills/maximize-info-density/SKILL.md",
                "frontmatter": {
                  "name": "maximize-info-density",
                  "description": "Compresses documents/prompts to maximize information density while preserving semantic content. Use when asked to make content concise, shorten, reduce tokens, tighten, or compress files like CLAUDE.md, skills, or specs."
                },
                "content": "# Maximize Information Density Skill\n\nRewrite documents to maximize information density while preserving all semantic content. Primary use case: reduce token consumption for AI-consumed content (CLAUDE.md, skills, agent prompts, specs, documentation).\n\n## Overview\n\nThis skill transforms verbose documents into dense, information-rich versions through:\n1. **Compression** - Apply density techniques, write to `/tmp` (original untouched)\n2. **Verification** - information-density-verifier agent compares original vs compressed for losslessness\n3. **Iteration** - If issues found, re-compress with feedback (max 3x)\n4. **Output** - Atomic `mv` replaces original only after verification passes\n\n**Loop**: Validate â†’ Compress â†’ Verify â†’ (Iterate if issues) â†’ Output\n\n## Workflow\n\n### Phase 0: Create Todo List (TodoWrite immediately)\n\nCreate todos tracking workflow phases. List reflects areas of work, not fixed steps.\n\n**Starter todos**:\n```\n- [ ] Input validation\n- [ ] Initial compression\n- [ ] Verification (iteration 1)\n- [ ] (expand if verification fails: iteration 2, 3)\n- [ ] Output and replace original\n```\n\n### Phase 1: Input Validation\n\n**Step 1.1: Parse arguments**\n\nExtract file path from `$ARGUMENTS`. If no path provided, error with usage instructions.\n\n**Step 1.2: Validate file**\n\n- Check file exists using Read tool\n- Verify supported type: `.md`, `.txt`, `.yaml`, `.json`\n- If unsupported, error: \"Unsupported file type. Supported: .md, .txt, .yaml, .json\"\n\n**Step 1.3: Read and measure original**\n\n- Read file content\n- Estimate token count: `Math.ceil(content.length / 4)` (approximate)\n- Store original content and token count for comparison\n\n**Mark \"Input validation\" todo `in_progress`**, then `completed` when Phase 1 done.\n\n### Phase 2: Transformation\n\n**Mark \"Initial compression\" todo `in_progress`.**\n\nApply compression techniques thoughtfully. Prioritize nuance preservation over reduction percentage.\n\n**Compression Techniques**:\n\n| Technique | Description | Example |\n|-----------|-------------|---------|\n| **Redundancy removal** | Eliminate repeated concepts, consolidate overlapping statements | \"It is important to note that you should always remember to...\" â†’ \"Always...\" |\n| **Terse phrasing** | Replace verbose constructions with compact equivalents | \"In order to accomplish this task, you will need to...\" â†’ \"To do this:\" |\n| **Filler elimination** | Remove hedging, qualifiers, throat-clearing | \"Make sure that you do not forget to include...\" â†’ \"Include:\" |\n| **Structural optimization** | Merge/reorganize sections for density | \"First X. After that Y. Then Z. Finally W.\" â†’ \"Steps: X â†’ Y â†’ Z â†’ W\" |\n| **Context-aware abbreviation** | Abbreviate terms after first mention | \"Model Context Protocol server\" (Ã—10) â†’ \"MCP server\" (after first) |\n| **Dense formatting** | Use lists, tables, compact notation | Prose paragraphs â†’ Tables, bullet lists |\n\n**Transformation Rules**:\n\n1. **Preserve ALL semantic information** - Every fact, instruction, constraint, and example must be present\n2. **Preserve nuance and emphasis** - Bold, caps, repetition, ordering that signals priority; intentional hedging (uncertainty was meaningful)\n3. **Restructuring allowed** - Reorder, merge sections if it increases density WITHOUT losing priority signals\n4. **Format preservation** - Output must be same format as input (markdown stays markdown)\n5. **No reduction target** - 10% reduction with nuance preserved > 40% reduction with nuance lost; some docs are already near-optimal\n\n**Step 2.1: Analyze content**\n\nIdentify:\n- Content type (documentation, prompt, spec, config)\n- Structure and redundancy patterns\n- Compression opportunities\n\n**Step 2.2: Apply transformation**\n\nRewrite the document applying techniques where safe. Preserve:\n- Emphasis markers (bold, caps, \"IMPORTANT\", \"NEVER\", \"CRITICAL\")\n- Intentional hedging (\"might\", \"consider\" when uncertainty is genuine)\n- Priority ordering (first items often = highest priority)\n- Tone appropriate to audience\n\n**Avoid creating ambiguity**:\n- Don't merge conditions with different triggers (\"when A, do X; when B, do Y\" â‰  \"when A/B, do X/Y\")\n- Keep explicit referents (don't reduce \"Use Read tool\" to \"Use the tool\" if context is unclear)\n- Don't flatten relationships (\"A requires B, C requires D\" â‰  \"A, C require B, D\")\n- Ensure scope is clear (qualifier applies to which items?)\n\n**Step 2.3: Write to temp file**\n\nWrite compressed output to `/tmp/compressed-{timestamp}.{ext}` where:\n- `{timestamp}` = current time for uniqueness\n- `{ext}` = original file extension\n\n**Mark \"Initial compression\" todo `completed`.**\n\n### Phase 3: Verification Loop\n\n**Mark \"Verification (iteration 1)\" todo `in_progress`.**\n\nLaunch the `vibe-extras:information-density-verifier` agent to verify lossless compression.\n\n**Iteration Protocol**:\n\n```\niteration = 1\nmax_iterations = 5\n\nwhile iteration <= max_iterations:\n    1. Launch information-density-verifier agent via Task tool:\n       - subagent_type: \"vibe-extras:information-density-verifier\"\n       - prompt: \"Verify compression is lossless.\n         Original file: {original_file_path}\n         Compressed file: {temp_file_path}\n\n         Compare semantic content. Report VERIFIED if lossless, or ISSUES with specific missing/altered information.\"\n\n    2. Parse agent response:\n       - If \"VERIFIED\" â†’ mark current verification todo `completed`, exit loop, proceed to Phase 4\n       - If \"ISSUES\" â†’ continue to step 3\n\n    3. If iteration < max_iterations:\n       - Mark current verification todo `completed`\n       - **Add new todo**: \"Verification (iteration {iteration+1})\" and mark `in_progress`\n       - Read the specific issues reported\n       - Re-run Phase 2 transformation with explicit feedback:\n         \"The following information was lost/altered: {issues}.\n          Preserve these while maintaining maximum density.\"\n       - Write new compressed version to temp file\n       - iteration += 1\n\n    4. If iteration == max_iterations and still has issues:\n       - Mark todo `completed` with note about unresolved issues\n       - Proceed to Phase 4 with warning flag\n```\n\n### Phase 4: Output\n\n**Mark \"Output and replace original\" todo `in_progress`.**\n\n**Step 4.1: Calculate metrics**\n\n- Original token count (from Phase 1)\n- Compressed token count: `Math.ceil(compressed_content.length / 4)`\n- Reduction percentage: `((original - compressed) / original * 100).toFixed(0)`\n\n**Step 4.2: Apply changes (atomic replacement)**\n\nOriginal file remains untouched until verification passes. Replace atomically:\n```bash\nmv /tmp/compressed-{timestamp}.{ext} {original_file_path}\n```\nThis ensures original is preserved if verification fails or process is interrupted.\n\n**Step 4.3: Display results**\n\nIf verification passed:\n```\nâœ“ Compressed: {file_path}\n  Original:   {original_tokens} tokens\n  Compressed: {compressed_tokens} tokens\n  Reduction:  {percentage}%\n\n  Changes: {brief summary of techniques applied}\n\n  Verification: âœ“ Lossless ({iteration_count} iteration(s))\n```\n\nIf verification failed after 5 iterations:\n```\nâš  Compressed with warnings: {file_path}\n  Original:   {original_tokens} tokens\n  Compressed: {compressed_tokens} tokens\n  Reduction:  {percentage}%\n\n  Changes: {brief summary of techniques applied}\n\n  Verification: âš  Could not fully verify after 3 iterations\n  Potential issues: {list from last verification}\n\n  Review the changes manually to ensure no critical information was lost.\n```\n\n**Mark \"Output and replace original\" todo `completed`. Mark all todos complete.**\n\n## Edge Cases\n\n| Scenario | Handling |\n|----------|----------|\n| File not found | Error: \"File not found: {path}\" |\n| Unsupported type | Error: \"Unsupported file type. Supported: .md, .txt, .yaml, .json\" |\n| Already dense content | Report success with low/zero reduction; don't force compression |\n| YAML/JSON structure | Preserve structure validity, compress string values only |\n| Very large file (>50KB) | Process as single unit |\n| 0-10% reduction | Success: \"Content was already near-optimal density\" |\n| Verification fails 5x | Output best attempt with warning about potential nuance loss |\n| mv fails | Error with temp file path; user can manually review/apply |\n\n## Key Principles\n\n| Principle | Rule |\n|-----------|------|\n| **Memento** | Use TodoWrite to track phases; expand todos when verification fails; mark progress immediately |\n| **Losslessness** | Never sacrifice semantic information for density; every fact must be preserved |\n| **Nuance preservation** | Keep emphasis, intentional hedging, priority signals; 10% with nuance > 40% without |\n| **No ambiguity** | Compressed must be as unambiguous as original; don't merge distinct conditions or flatten relationships |\n| **Thoughtful** | Restructuring allowed where safe; some docs are already near-optimal |\n| **Verification** | Always run information-density-verifier; never skip; iterate with specific feedback |\n\n## Example Usage\n\n```bash\n# Compress a verbose README\n/maximize-information-density docs/README.md\n\n# Compress CLAUDE.md\n/maximize-information-density CLAUDE.md\n\n# Compress a skill file\n/maximize-information-density skills/plan/SKILL.md\n```\n\n## Example Output\n\n```\nâœ“ Compressed: docs/README.md\n  Original:   4,250 tokens\n  Compressed: 3,612 tokens\n  Reduction:  15%\n\n  Changes: Removed redundant intro, consolidated examples,\n  tersified instructions. Preserved emphasis markers and\n  conditional logic.\n\n  Verification: âœ“ Lossless - nuance preserved (2 iterations)\n```\n\n```\nâœ“ Compressed: CLAUDE.md\n  Original:   2,100 tokens\n  Compressed: 1,995 tokens\n  Reduction:  5%\n\n  Changes: Minor redundancy removal. Content was already\n  near-optimal density.\n\n  Verification: âœ“ Lossless (1 iteration)\n```"
              },
              {
                "name": "rebase-on-main",
                "description": "Update main/master from origin, rebase current branch on it, resolve conflicts, and push.",
                "path": "claude-plugins/vibe-extras/skills/rebase-on-main/SKILL.md",
                "frontmatter": {
                  "name": "rebase-on-main",
                  "description": "Update main/master from origin, rebase current branch on it, resolve conflicts, and push."
                },
                "content": "Perform a rebase workflow for the current branch:\n\n## Steps\n\n1. **Identify the main branch**: Check if `main` or `master` exists as the default branch\n2. **Save current branch name**: Store the current branch name for later\n3. **Fetch latest from origin**: Run `git fetch origin`\n4. **Update main/master locally**: Checkout main/master and pull latest changes\n5. **Return to feature branch**: Checkout the original branch\n6. **Rebase on main/master**: Run `git rebase main` (or master)\n7. **Handle conflicts if any**:\n   - If conflicts occur, analyze each conflicting file\n   - Read the conflicting files to understand the context\n   - Resolve conflicts intelligently by understanding both changes\n   - Use `git add` to mark resolved files\n   - Continue rebase with `git rebase --continue`\n   - Repeat until all conflicts are resolved\n8. **Push changes**: Force push with lease using `git push --force-with-lease`\n\n## Important Guidelines\n\n- Always use `--force-with-lease` instead of `--force` for safety\n- When resolving conflicts, prefer keeping functionality from both sides when possible\n- If a conflict resolution is ambiguous, explain the choice made\n- Report a summary of what was done at the end (commits rebased, conflicts resolved, etc.)"
              },
              {
                "name": "rewrite-history",
                "description": "Restructure branch into clean, reviewer-friendly commits. Analyzes total diff since main, groups files by concern, and rewrites with conventional commit messages.",
                "path": "claude-plugins/vibe-extras/skills/rewrite-history/SKILL.md",
                "frontmatter": {
                  "name": "rewrite-history",
                  "description": "Restructure branch into clean, reviewer-friendly commits. Analyzes total diff since main, groups files by concern, and rewrites with conventional commit messages."
                },
                "content": "# Rewrite History Command\n\nRestructures messy branch history into a clean, reviewer-friendly progression of logical commits.\n\n## Overview\n\nThis command:\n1. Analyzes total diff since divergence from main/master (ignores existing commits)\n2. Groups files by single concern\n3. Arranges in logical order (foundations first, features second, polish last)\n4. Generates Conventional Commit messages\n5. Rewrites history: `git reset --soft` â†’ `git add` + `git commit` for each group\n\n**Modes**:\n- **Interactive** (default): Shows proposal, allows adjustment/approval via AskUserQuestion\n- **Automatic** (`--auto`): Skips proposal, executes directly\n\n## Steps\n\n### 1. Precondition Checks\n\nBefore any destructive operations, verify:\n\n1. **Not on main branch**: Check current branch is not `main` or `master`\n   - If on main: Error \"Cannot rewrite history on main/master branch. Checkout a feature branch first.\"\n\n2. **Clean working tree**: Run `git status --porcelain`\n   - If uncommitted changes: Error \"Uncommitted changes detected. Commit or stash changes before rewriting history.\"\n\n3. **Identify base branch and fetch**:\n   - Try `git fetch origin main` or `git fetch origin master` (whichever exists)\n   - If fetch succeeds: use `origin/main` or `origin/master` as base\n   - If fetch fails (no remote, offline): fall back to local `main` or `master`\n   - Report which base is being used: \"Using origin/main as base\" or \"Using local main as base (no remote)\"\n\n4. **Has commits to rewrite**: Find merge-base with base branch, count commits\n   - Run `git merge-base HEAD {base-branch}`\n   - Run `git rev-list --count {merge-base}..HEAD`\n   - If 0 commits: Error \"No commits to rewrite. Branch is up to date with main.\"\n\n### 2. Create Backup Branch\n\n**Always create backup before destructive operations.**\n\n```bash\ngit branch {current-branch}-backup-{YYYYMMDD-HHMM}\n```\n\nReport: \"Created backup: {backup-branch-name}\"\n\n### 3. Analyze Diff\n\nGet the full diff since divergence:\n\n1. **Get merge-base**: `git merge-base HEAD {base-branch}` (using origin/main or local main from step 1)\n2. **Get full diff**: `git diff {merge-base}..HEAD`\n\n**Analysis goals** (based solely on the diff):\n- Identify distinct concerns/features in the changes\n- Group related files together\n- Determine logical ordering (dependencies, foundations before features)\n\nDo NOT investigate individual commits or commit historyâ€”only analyze the diff content.\n\n### 4. Generate Proposal\n\nCreate a restructuring proposal:\n\n```\nProposed commits:\n\n1. {type}({scope}): {description}\n   - Files: {key files affected}\n\n2. {type}({scope}): {description}\n   - Files: {key files affected}\n\n[...]\n```\n\n**Grouping principles**:\n- One concern per commit\n- Logical order: setup/config -> core features -> secondary features -> tests -> docs\n- Atomic commits that could theoretically be reverted independently\n\n### 5. Interactive Approval (unless --auto)\n\nIf `$ARGUMENTS` does NOT contain `--auto`:\n\nUse AskUserQuestion to present proposal and get approval:\n\n```\nProceed with this restructuring?\n- [Yes] Execute as proposed\n- [Adjust] Describe changes to the proposal\n- [Cancel] Abort without changes\n```\n\n**If \"Adjust\"**: Parse user feedback, regenerate proposal, ask again.\n\n**If \"Cancel\"**: Report \"Cancelled. No changes made. Backup branch preserved: {backup-name}\" and exit.\n\n**If \"Yes\"** or `--auto` mode: Proceed to execution.\n\n### 6. Execute Rewrite\n\nPerform the history rewrite:\n\n1. **Soft reset to merge-base**:\n   ```bash\n   git reset --soft {merge-base}\n   ```\n   This preserves all changes in the working directory but removes all commits.\n\n2. **Create new commits** - for each group in the proposal, execute:\n   ```bash\n   git add {files-for-this-commit}\n   git commit -m \"{message}\"\n   ```\n   Repeat for each logical commit group until all changes are committed.\n\n3. **Verify result**:\n   ```bash\n   git log --oneline {merge-base}..HEAD\n   git diff {backup-branch}..HEAD  # should be empty\n   ```\n\nReport: \"History rewritten into {new-count} commits\"\n\n### 7. Push Prompt\n\nAfter successful rewrite, prompt about pushing:\n\nUse AskUserQuestion:\n```\nPush rewritten history to remote?\n- [Yes] Push with --force-with-lease (safe force push)\n- [No] Keep changes local (you can push manually later)\n```\n\n**If \"Yes\"**:\n```bash\ngit push --force-with-lease\n```\nReport: \"Pushed to remote with --force-with-lease\"\n\n**If \"No\"**:\nReport: \"Changes kept local. Push manually when ready: git push --force-with-lease\"\n\n### 8. Summary\n\nReport final summary:\n\n```\nHistory rewrite complete.\n\nCommits: {M}\nBackup: {backup-branch-name}\n\nNew history:\n{git log --oneline output}\n```\n\n## Important Guidelines\n\n- **Diff-only analysis** - only look at the full diff, never investigate individual commits\n- **Always use `--force-with-lease`** instead of `--force` for push safety\n- **Backup branch is permanent** - only delete manually after confirming rewrite is correct\n- **Verify no code changes** - diff between backup and new HEAD should be empty\n- **Conventional Commits** - use standard types (feat, fix, docs, refactor, test, chore)\n- **One concern per commit** - resist urge to combine unrelated changes\n\n## Edge Cases\n\n| Scenario | Handling |\n|----------|----------|\n| On main/master branch | Error: \"Cannot rewrite history on main/master branch. Checkout a feature branch first.\" |\n| Uncommitted changes | Error: \"Uncommitted changes detected. Commit or stash changes before rewriting history.\" |\n| No remote available | Fall back to local main/master. Report: \"Using local main as base (no remote)\" |\n| No commits since main | Error: \"No commits to rewrite. Branch is up to date with main.\" |\n| Single commit only | Proceed normally (may reorganize or improve commit message) |\n| Conflicts during commit creation | Should not occur (soft reset preserves all changes). If staging issues, report specific files. |\n| Push rejected despite --force-with-lease | Error: \"Push rejected. Remote has new commits. Fetch and review before retrying.\" |\n| User cancels mid-execution | Backup branch preserved. User can: `git reset --hard {backup-branch}` to restore. |\n\n## Example Usage\n\n```bash\n# Interactive mode (default)\n/rewrite-history\n\n# Automatic mode (skip proposal approval)\n/rewrite-history --auto\n```\n\n## Example Output\n\n**Interactive mode**:\n```\nUsing origin/main as base.\nAnalyzing diff...\n\nCreated backup: feature-auth-backup-20260107-1430\n\nProposed commits:\n\n1. feat(auth): add JWT authentication middleware\n   - Files: src/middleware/auth.ts, src/utils/jwt.ts\n\n2. feat(auth): implement login and logout endpoints\n   - Files: src/routes/auth.ts, src/controllers/auth.ts\n\n3. test(auth): add authentication test suite\n   - Files: tests/auth/*.test.ts\n\n4. docs(auth): add authentication documentation\n   - Files: docs/auth.md, README.md\n\nProceed with this restructuring?\n- [Yes] Execute as proposed\n- [Adjust] Describe changes to the proposal\n- [Cancel] Abort without changes\n\n> Yes\n\nHistory rewritten into 4 commits.\n\nPush rewritten history to remote?\n- [Yes] Push with --force-with-lease\n- [No] Keep changes local\n\n> Yes\n\nPushed to remote with --force-with-lease\n\nHistory rewrite complete.\n\nCommits: 4\nBackup: feature-auth-backup-20260107-1430\n\nNew history:\na1b2c3d docs(auth): add authentication documentation\ne4f5g6h test(auth): add authentication test suite\ni7j8k9l feat(auth): implement login and logout endpoints\nm0n1o2p feat(auth): add JWT authentication middleware\n```"
              },
              {
                "name": "update-claude-md",
                "description": "Create or update CLAUDE.md with best practices - brevity, universal applicability, progressive disclosure",
                "path": "claude-plugins/vibe-extras/skills/update-claude-md/SKILL.md",
                "frontmatter": {
                  "name": "update-claude-md",
                  "description": "Create or update CLAUDE.md with best practices - brevity, universal applicability, progressive disclosure"
                },
                "content": "Update my CLAUDE.md based on: $ARGUMENTS\n\nCurrent CLAUDE.md:\n@CLAUDE.md\n\n---\n\nMake targeted updates based on my request. Only explore codebase if essential info is missing.\n\nIf my request conflicts with best practices below, still make the update but note the tradeoff.\n\n**Best Practices** (CLAUDE.md is the highest-leverage config point):\n\n**Structure** - Cover these if creating/missing critical sections:\n- **WHAT**: Tech stack, project structure, key entry points (critical for monorepos)\n- **WHY**: Project purpose, component relationships, domain terminology\n- **HOW**: Build/test/run commands, verification steps\n\n**Length** (LLMs follow ~150 instructions reliably; system uses ~50):\n- Simple: 30-60 lines | Standard: 60-150 | Complex: 150-300 max\n\n**Progressive Disclosure** - For complex projects, create separate docs and reference them:\n```\ndocs/testing.md, docs/architecture.md, docs/conventions.md\n```\nThen in CLAUDE.md: \"See docs/testing.md for test patterns\"\n\n**Prefer pointers over copies** - Use `file:line` references instead of pasting code snippets (avoids staleness).\n\n**Do**: Universal instructions | Imperative language | Verified commands | Reference (don't copy) README\n\n**Don't**:\n- Style rules â†’ use linters, formatters, or Claude Code hooks instead\n- Task-specific instructions â†’ gets ignored if not relevant to current task\n- File/function enumeration â†’ describe patterns instead\n- Auto-generated boilerplate\n\nBad: `Always use camelCase. Document with JSDoc.`\nGood: `npm test  # Required before PR`\n\nVerify: <300 lines, no style rules, universal instructions, commands tested."
              }
            ]
          }
        ]
      }
    }
  ]
}