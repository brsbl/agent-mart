{
  "owner": {
    "id": "emdashcodes",
    "display_name": "Em",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/689165?u=39088bdf4dd5adfa43e62e2c1100b6616e9ddf15&v=4",
    "url": "https://github.com/emdashcodes",
    "bio": null,
    "stats": {
      "total_repos": 2,
      "total_plugins": 10,
      "total_commands": 3,
      "total_skills": 15,
      "total_stars": 10,
      "total_forks": 1
    }
  },
  "repos": [
    {
      "full_name": "emdashcodes/wp-ability-toolkit",
      "url": "https://github.com/emdashcodes/wp-ability-toolkit",
      "description": "A toolkit for WordPress plugin development, testing AI agent integrations, and WordPress Ability API creation.",
      "homepage": "https://emdash.codes/wp-ability-toolkit/",
      "signals": {
        "stars": 6,
        "forks": 0,
        "pushed_at": "2025-10-20T16:40:28Z",
        "created_at": "2025-10-19T17:14:16Z",
        "license": "GPL-2.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2263
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/settings.local.json",
          "type": "blob",
          "size": 194
        },
        {
          "path": ".editorconfig",
          "type": "blob",
          "size": 449
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/pull_request_template.md",
          "type": "blob",
          "size": 337
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/ci.yml",
          "type": "blob",
          "size": 6496
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 401
        },
        {
          "path": ".markdownlint-cli2.yaml",
          "type": "blob",
          "size": 410
        },
        {
          "path": ".markdownlint.json",
          "type": "blob",
          "size": 385
        },
        {
          "path": ".markdownlintignore",
          "type": "blob",
          "size": 215
        },
        {
          "path": ".prettierignore",
          "type": "blob",
          "size": 518
        },
        {
          "path": ".prettierrc.cjs",
          "type": "blob",
          "size": 394
        },
        {
          "path": ".wp-env.json",
          "type": "blob",
          "size": 294
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 6947
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4228
        },
        {
          "path": "LICENSE.md",
          "type": "blob",
          "size": 18222
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 13532
        },
        {
          "path": "TODO.md",
          "type": "blob",
          "size": 291
        },
        {
          "path": "babel.config.cjs",
          "type": "blob",
          "size": 152
        },
        {
          "path": "claude-code-plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/SKILL.md",
          "type": "blob",
          "size": 17779
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/assets/category-template.php",
          "type": "blob",
          "size": 528
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/assets/client-ability-template.js",
          "type": "blob",
          "size": 1546
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/assets/client-category-template.js",
          "type": "blob",
          "size": 400
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/assets/server-ability-template.php",
          "type": "blob",
          "size": 2294
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/1.intro.md",
          "type": "blob",
          "size": 5297
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/2.getting-started.md",
          "type": "blob",
          "size": 4943
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/3.registering-abilities.md",
          "type": "blob",
          "size": 12663
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/4.using-abilities.md",
          "type": "blob",
          "size": 6750
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/5.rest-api.md",
          "type": "blob",
          "size": 8998
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/6.hooks.md",
          "type": "blob",
          "size": 6820
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/7.javascript-client.md",
          "type": "blob",
          "size": 7660
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/references/7.registering-categories.md",
          "type": "blob",
          "size": 2935
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/README.md",
          "type": "blob",
          "size": 1345
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/package-lock.json",
          "type": "blob",
          "size": 547
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/package.json",
          "type": "blob",
          "size": 47
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/scaffold-ability.php",
          "type": "blob",
          "size": 4411
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/scaffold-category.php",
          "type": "blob",
          "size": 2905
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/validate-ability.js",
          "type": "blob",
          "size": 10742
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/validate-ability.php",
          "type": "blob",
          "size": 10632
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/validate-category.js",
          "type": "blob",
          "size": 7655
        },
        {
          "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/scripts/validate-category.php",
          "type": "blob",
          "size": 8860
        },
        {
          "path": "claude-code-plugins/wordpress-plugin-scaffold",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-plugin-scaffold/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-plugin-scaffold/skills/wordpress-plugin-scaffold",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-plugin-scaffold/skills/wordpress-plugin-scaffold/SKILL.md",
          "type": "blob",
          "size": 11053
        },
        {
          "path": "claude-code-plugins/wordpress-plugin-scaffold/skills/wordpress-plugin-scaffold/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wordpress-plugin-scaffold/skills/wordpress-plugin-scaffold/references/wp-cli-installation.md",
          "type": "blob",
          "size": 5126
        },
        {
          "path": "claude-code-plugins/wp-env",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wp-env/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wp-env/skills/wp-env",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wp-env/skills/wp-env/SKILL.md",
          "type": "blob",
          "size": 10262
        },
        {
          "path": "claude-code-plugins/wp-env/skills/wp-env/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code-plugins/wp-env/skills/wp-env/references/command-reference.md",
          "type": "blob",
          "size": 16767
        },
        {
          "path": "claude-code-plugins/wp-env/skills/wp-env/references/configuration-guide.md",
          "type": "blob",
          "size": 18191
        },
        {
          "path": "claude-code-plugins/wp-env/skills/wp-env/references/troubleshooting.md",
          "type": "blob",
          "size": 2638
        },
        {
          "path": "eslint.config.js",
          "type": "blob",
          "size": 3204
        },
        {
          "path": "jest.config.cjs",
          "type": "blob",
          "size": 724
        },
        {
          "path": "jest.setup.cjs",
          "type": "blob",
          "size": 236
        },
        {
          "path": "package.json",
          "type": "blob",
          "size": 2685
        },
        {
          "path": "packages",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/README.md",
          "type": "blob",
          "size": 3451
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/package.json",
          "type": "blob",
          "size": 1453
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/__tests__",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/__tests__/streamAdapter.test.ts",
          "type": "blob",
          "size": 1454
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/components",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/components/ToolCall.tsx",
          "type": "blob",
          "size": 17780
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/conversationStorage.ts",
          "type": "blob",
          "size": 5543
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/debug.ts",
          "type": "blob",
          "size": 377
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/deltaAccumulator.ts",
          "type": "blob",
          "size": 2994
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/hooks/useAbortController.ts",
          "type": "blob",
          "size": 1152
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/hooks/useConversationStorage.ts",
          "type": "blob",
          "size": 1777
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/hooks/useMessageConverter.ts",
          "type": "blob",
          "size": 697
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/hooks/useStreamingRequest.ts",
          "type": "blob",
          "size": 2367
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/hooks/useToolCallHandler.ts",
          "type": "blob",
          "size": 9258
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/index.ts",
          "type": "blob",
          "size": 2101
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/streamAdapter.ts",
          "type": "blob",
          "size": 3053
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/toolRegistry.ts",
          "type": "blob",
          "size": 3076
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/types.ts",
          "type": "blob",
          "size": 3304
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/useWordPressChat.ts",
          "type": "blob",
          "size": 11873
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/utils/copyToClipboard.ts",
          "type": "blob",
          "size": 352
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/utils/errorParser.ts",
          "type": "blob",
          "size": 912
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/src/utils/toolFormatter.ts",
          "type": "blob",
          "size": 638
        },
        {
          "path": "packages/agenttic-ai-sdk-bridge/tsconfig.json",
          "type": "blob",
          "size": 692
        },
        {
          "path": "packages/wp-ability-toolkit",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/.distignore",
          "type": "blob",
          "size": 588
        },
        {
          "path": "packages/wp-ability-toolkit/.editorconfig",
          "type": "blob",
          "size": 448
        },
        {
          "path": "packages/wp-ability-toolkit/.github",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/.github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/.github/workflows/testing.yml",
          "type": "blob",
          "size": 786
        },
        {
          "path": "packages/wp-ability-toolkit/.phpcs.xml.dist",
          "type": "blob",
          "size": 20
        },
        {
          "path": "packages/wp-ability-toolkit/bin",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/bin/install-wp-tests.sh",
          "type": "blob",
          "size": 6350
        },
        {
          "path": "packages/wp-ability-toolkit/composer.json",
          "type": "blob",
          "size": 539
        },
        {
          "path": "packages/wp-ability-toolkit/composer.lock",
          "type": "blob",
          "size": 110232
        },
        {
          "path": "packages/wp-ability-toolkit/includes",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/includes/abilities",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/includes/abilities/create-ability.php",
          "type": "blob",
          "size": 4745
        },
        {
          "path": "packages/wp-ability-toolkit/includes/abilities/think.php",
          "type": "blob",
          "size": 1856
        },
        {
          "path": "packages/wp-ability-toolkit/includes/class-ability-tools-manager.php",
          "type": "blob",
          "size": 5906
        },
        {
          "path": "packages/wp-ability-toolkit/includes/class-ai-client.php",
          "type": "blob",
          "size": 2332
        },
        {
          "path": "packages/wp-ability-toolkit/includes/class-openai-client.php",
          "type": "blob",
          "size": 11201
        },
        {
          "path": "packages/wp-ability-toolkit/includes/class-plugin.php",
          "type": "blob",
          "size": 7573
        },
        {
          "path": "packages/wp-ability-toolkit/includes/class-prompt.php",
          "type": "blob",
          "size": 11794
        },
        {
          "path": "packages/wp-ability-toolkit/includes/class-rest-api.php",
          "type": "blob",
          "size": 8473
        },
        {
          "path": "packages/wp-ability-toolkit/includes/class-settings.php",
          "type": "blob",
          "size": 5021
        },
        {
          "path": "packages/wp-ability-toolkit/package.json",
          "type": "blob",
          "size": 1197
        },
        {
          "path": "packages/wp-ability-toolkit/phpunit.xml.dist",
          "type": "blob",
          "size": 444
        },
        {
          "path": "packages/wp-ability-toolkit/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/src/abilities",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/src/abilities/index.ts",
          "type": "blob",
          "size": 1585
        },
        {
          "path": "packages/wp-ability-toolkit/src/abilities/navigate.ts",
          "type": "blob",
          "size": 3995
        },
        {
          "path": "packages/wp-ability-toolkit/src/abilities/reload.ts",
          "type": "blob",
          "size": 2238
        },
        {
          "path": "packages/wp-ability-toolkit/src/admin",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/src/admin/settings.tsx",
          "type": "blob",
          "size": 5371
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/AbilityChat.tsx",
          "type": "blob",
          "size": 10784
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/AbilityChat.tsx.bak",
          "type": "blob",
          "size": 8798
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/ChatHeader.tsx",
          "type": "blob",
          "size": 1548
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/ChatWidgetElement.tsx",
          "type": "blob",
          "size": 3816
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/agenttic-ui-overrides.css",
          "type": "blob",
          "size": 6463
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/index.tsx",
          "type": "blob",
          "size": 694
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/toolRegistry.d.ts",
          "type": "blob",
          "size": 1237
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/toolRegistry.d.ts.map",
          "type": "blob",
          "size": 840
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/toolRegistry.js",
          "type": "blob",
          "size": 2016
        },
        {
          "path": "packages/wp-ability-toolkit/src/chat-widget/toolRegistry.js.map",
          "type": "blob",
          "size": 1604
        },
        {
          "path": "packages/wp-ability-toolkit/src/debug.ts",
          "type": "blob",
          "size": 377
        },
        {
          "path": "packages/wp-ability-toolkit/src/types",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/src/types/css.d.ts",
          "type": "blob",
          "size": 316
        },
        {
          "path": "packages/wp-ability-toolkit/src/utils",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/src/utils/continuation.ts",
          "type": "blob",
          "size": 4196
        },
        {
          "path": "packages/wp-ability-toolkit/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/tests/bootstrap.php",
          "type": "blob",
          "size": 2713
        },
        {
          "path": "packages/wp-ability-toolkit/tests/stubs",
          "type": "tree",
          "size": null
        },
        {
          "path": "packages/wp-ability-toolkit/tests/stubs/wordpress-tests.php",
          "type": "blob",
          "size": 3303
        },
        {
          "path": "packages/wp-ability-toolkit/tests/test-prompt.php",
          "type": "blob",
          "size": 2288
        },
        {
          "path": "packages/wp-ability-toolkit/tests/test-sample.php",
          "type": "blob",
          "size": 703
        },
        {
          "path": "packages/wp-ability-toolkit/tsconfig.json",
          "type": "blob",
          "size": 693
        },
        {
          "path": "packages/wp-ability-toolkit/webpack.config.js",
          "type": "blob",
          "size": 1337
        },
        {
          "path": "packages/wp-ability-toolkit/wp-ability-toolkit.php",
          "type": "blob",
          "size": 1691
        },
        {
          "path": "phpcs.xml.dist",
          "type": "blob",
          "size": 1646
        },
        {
          "path": "phpunit.xml.dist",
          "type": "blob",
          "size": 994
        },
        {
          "path": "pnpm-lock.yaml",
          "type": "blob",
          "size": 636218
        },
        {
          "path": "pnpm-workspace.yaml",
          "type": "blob",
          "size": 27
        }
      ],
      "marketplace": {
        "name": "emdashcodes-wp-ability-toolkit",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Em",
          "url": "https://emdash.codes"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "wordpress-ability-api",
            "description": "Create, validate, and register WordPress Abilities (server-side PHP and client-side JavaScript) with comprehensive scaffolding and validation tools",
            "source": "./claude-code-plugins/wordpress-ability-api",
            "category": "development-tools",
            "version": "1.0.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/wp-ability-toolkit",
              "/plugin install wordpress-ability-api@emdashcodes-wp-ability-toolkit"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2025-10-20T16:40:28Z",
              "created_at": "2025-10-19T17:14:16Z",
              "license": "GPL-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "wordpress-ability-api",
                "description": "This skill should be used when helping users create, edit, or register WordPress Abilities (both server-side PHP and client-side JavaScript), register ability categories, or set up the WordPress Abilities API as a dependency. Use when users say things like \"create an ability\", \"help me build an ability\", \"set up the Ability API\", or \"register a category\".",
                "path": "claude-code-plugins/wordpress-ability-api/skills/wordpress-ability-api/SKILL.md",
                "frontmatter": {
                  "name": "wordpress-ability-api",
                  "description": "This skill should be used when helping users create, edit, or register WordPress Abilities (both server-side PHP and client-side JavaScript), register ability categories, or set up the WordPress Abilities API as a dependency. Use when users say things like \"create an ability\", \"help me build an ability\", \"set up the Ability API\", or \"register a category\"."
                },
                "content": "# WordPress Ability API\n\n## Overview\n\nThis skill helps users work with the WordPress Abilities API - a standardized system for registering and discovering distinct units of functionality within WordPress. Use this skill to help users create server-side PHP abilities, client-side JavaScript abilities, register categories, and set up the API as a dependency.\n\nThe Abilities API makes WordPress functionality discoverable by AI agents and automation tools through machine-readable schemas, permissions, and validation.\n\n## When to Use This Skill\n\nActivate this skill when the user requests:\n\n- **Creating abilities**: \"Help me create an ability to...\", \"I want to make an ability that...\", \"Build me an ability for...\"\n- **Editing abilities**: \"Update my ability\", \"Fix this ability code\", \"Modify the ability to...\"\n- **Setting up the API**: \"Set up the Ability API\", \"Add the Ability API as a dependency\", \"Install the Abilities API\"\n- **Registering categories**: \"Create a category for my abilities\", \"Register an ability category\"\n\n## Workflow Decision Tree\n\nWhen this skill activates, determine what the user needs:\n\n1. **Are they creating/editing an ability?**\n   → Follow the \"Creating Abilities\" workflow below\n\n2. **Do they need to set up the API first?**\n   → Follow the \"Setting Up the API\" workflow below\n\n3. **Are they just learning about the API?**\n   → Reference the documentation in `references/` and explain concepts\n\n## Using the Scaffold Script\n\nThe skill includes a `scripts/scaffold-ability.php` script designed for programmatic ability generation. Use this when creating abilities to quickly generate validated boilerplate code.\n\n### Script Usage\n\n```bash\nphp scripts/scaffold-ability.php \\\n  --name=\"plugin/ability-name\" \\\n  --type=\"server\" \\\n  --category=\"data-retrieval\" \\\n  --label=\"Optional Label\" \\\n  --description=\"Optional description\"\n```\n\n**Required Arguments:**\n\n- `--name` - Ability name in format \"namespace/ability-name\"\n- `--type` - Either \"server\" (PHP) or \"client\" (JavaScript)\n- `--category` - Category slug (e.g., \"data-retrieval\", \"data-modification\")\n\n**Optional Arguments:**\n\n- `--label` - Human-readable label (auto-generated from name if omitted)\n- `--description` - Detailed description (placeholder if omitted)\n- `--readonly` - \"true\" or \"false\" (default: false)\n- `--destructive` - \"true\" or \"false\" (default: true)\n- `--idempotent` - \"true\" or \"false\" (default: false)\n\n**Output:** Complete ability code printed to stdout, ready to be written to plugin files.\n\n### When to Use the Scaffold Script\n\nUse the scaffold script after gathering requirements from the user (Steps 1-3 of the workflow below). The script generates clean, validated boilerplate that follows best practices.\n\n**Important:** Always gather required information from the user BEFORE calling the script, or generate sensible defaults based on context.\n\n## Creating Abilities\n\nWhen helping users create or edit abilities, follow this conversational workflow:\n\n### Step 1: Understand the Functionality\n\nAsk clarifying questions to understand what the ability should do:\n\n- **What should this ability do?** (e.g., \"Get site analytics\", \"Send notifications\", \"Update settings\")\n- **Is this a server-side or client-side ability?**\n  - **Server-side (PHP)**: Runs on the WordPress backend, accesses database, uses WordPress functions\n  - **Client-side (JavaScript)**: Runs in the browser, manipulates DOM, handles UI interactions\n- **What input parameters does it need?** (e.g., user ID, date range, options)\n- **What should it return?** (e.g., array of data, success boolean, error messages)\n- **Who should be able to use it?** (permissions: any user, logged-in users, administrators, custom capability)\n\n### Step 2: Determine Plugin Location\n\nAsk where the ability code should live:\n\n- **\"Which plugin should this ability be registered in?\"**\n  - If they have an existing plugin, use that\n  - If they need a new plugin, offer to create one using the `wordpress-plugin-scaffold` skill\n\n### Step 3: Check for Category\n\nAbilities must belong to a category. Ask:\n\n- **\"Which category should this ability belong to?\"**\n  - Example categories: `data-retrieval`, `data-modification`, `communication`, `ecommerce`, `user-management`\n  - If they need a custom category, use `scripts/scaffold-category.php` to generate it:\n\n```bash\nphp scripts/scaffold-category.php \\\n  --name=\"custom-category\" \\\n  --label=\"Custom Category\" \\\n  --description=\"Description of what abilities belong here\" \\\n  --type=\"server|client\"\n```\n\n- Alternatively, manually customize `assets/category-template.php`\n- See `references/7.registering-categories.md` for detailed category registration information\n\n### Step 4: Generate the Ability Code\n\nUse the scaffold script to generate complete, validated code:\n\n```bash\nphp scripts/scaffold-ability.php \\\n  --name=\"namespace/ability-name\" \\\n  --type=\"server|client\" \\\n  --category=\"category-slug\" \\\n  --label=\"Human Label\" \\\n  --description=\"Detailed description\" \\\n  --readonly=\"true|false\" \\\n  --destructive=\"true|false\" \\\n  --idempotent=\"true|false\"\n```\n\n**For server-side (PHP):** Outputs complete PHP code with callback and registration functions\n**For client-side (JavaScript):** Outputs complete JavaScript code with async callback\n\nAlternatively, manually copy and customize templates from `assets/` directory:\n\n- `server-ability-template.php` - PHP abilities\n- `client-ability-template.js` - JavaScript abilities\n\nReplace all `{{PLACEHOLDERS}}` with actual values. See templates for full list of placeholders.\n\n### Step 5: Validate the Code\n\nBefore adding the code to plugin files, validate it using the appropriate validation script:\n\n#### Validate Abilities\n\n**For PHP abilities:**\n\n```bash\nphp scripts/validate-ability.php path/to/ability-file.php\n```\n\n**For JavaScript abilities:**\n\n```bash\nnode scripts/validate-ability.js path/to/ability-file.js\n```\n\n#### Validate Categories\n\n**For PHP categories:**\n\n```bash\nphp scripts/validate-category.php path/to/category-file.php\n```\n\n**For JavaScript categories:**\n\n```bash\nnode scripts/validate-category.js path/to/category-file.js\n```\n\nAll validators check:\n\n- **Structure**: Required fields (name, label, description, schemas/callbacks) are present\n- **JSON Schema validity**: Schemas follow JSON Schema specification (abilities only)\n- **Best practices**: Proper naming (kebab-case), annotations, permission callbacks\n- **Common mistakes**: TODO placeholders, empty descriptions, security concerns\n\n**Exit codes:**\n\n- `0` - Validation passed\n- `1` - Validation failed (errors found)\n- `2` - File not found or invalid usage\n\nFix any errors reported by the validator before proceeding.\n\n### Step 6: Add to Plugin Files\n\nWrite the validated code to the appropriate plugin files:\n\n- **PHP abilities**: Add to plugin's main PHP file or create a dedicated `includes/abilities.php` file and hook into `abilities_api_init`\n- **JavaScript abilities**: Add to enqueued JavaScript file with `@wordpress/abilities` dependency\n- **Categories**: Register on `abilities_api_categories_init` hook before abilities\n\nUse the Write tool to add the code to the correct location in the plugin.\n\n### Step 7: Test the Ability\n\nAfter code is added to plugin files, suggest testing approaches:\n\n**Server-side (PHP):**\n\n- Use `wp_get_ability('namespace/name')` to verify registration\n- Test execution via REST API: `POST /wp-json/abilities/v1/abilities/{namespace}/{ability-name}/execute`\n- Or test directly: `$ability->execute( $input_data )`\n- Verify permissions work as expected\n- Check input validation catches invalid data\n\n**Client-side (JavaScript):**\n\n- Open browser DevTools console\n- Check registration: `wp.data.select('core/abilities').getAbility('namespace/ability-name')`\n- Execute ability: `wp.data.dispatch('core/abilities').executeAbility('namespace/ability-name', inputData)`\n- Check available abilities: `wp.data.select('core/abilities').getAbilities()`\n- Verify permissions and error handling work correctly\n\n## Setting Up the API\n\nThe WordPress Abilities API must be available before abilities can be registered. Help users set up the API based on their WordPress version:\n\n### Check WordPress Version\n\n**WordPress 6.9+**: The Abilities API is included in core - no setup needed!\n\n**WordPress < 6.9**: The API must be installed as a plugin or dependency.\n\n### Installation Options\n\nReference `references/2.getting-started.md` for detailed setup instructions. Guide users through the most appropriate method:\n\n#### Option 1: As a Plugin (Easiest for Testing)\n\nIf they're using **wp-env** (check for `.wp-env.json`), help them add it via the `wp-env` skill:\n\n```json\n{\n  \"plugins\": [\"WordPress/abilities-api\"]\n}\n```\n\nIf they're using **WP-CLI**:\n\n```bash\nwp plugin install https://github.com/WordPress/abilities-api/releases/latest/download/abilities-api.zip\nwp plugin activate abilities-api\n```\n\n#### Option 2: As a Plugin Dependency (Recommended for Plugins)\n\nHelp them add to their plugin header:\n\n```php\n/**\n * Plugin Name: My Plugin\n * Requires Plugins: abilities-api\n */\n```\n\nThen add availability check:\n\n```php\nif ( ! class_exists( 'WP_Ability' ) ) {\n    add_action( 'admin_notices', function() {\n        wp_admin_notice(\n            __( 'This plugin requires the Abilities API. Please install and activate it.', 'my-plugin' ),\n            'error'\n        );\n    } );\n    return;\n}\n```\n\n#### Option 3: As a Composer Dependency\n\n```bash\ncomposer require wordpress/abilities-api\n```\n\n### Verify Installation\n\nHelp users verify the API is loaded:\n\n```php\nif ( class_exists( 'WP_Ability' ) ) {\n    // API is available\n    echo 'Abilities API version: ' . WP_ABILITIES_API_VERSION;\n}\n```\n\n## Integration with Other Skills\n\nThis skill works well with:\n\n- **wordpress-plugin-scaffold**: Use when users need a new plugin to register abilities in\n- **wp-env**: Use for local development environment setup when installing the Abilities API\n\n## Reference Documentation\n\nThe `references/` directory contains complete API documentation:\n\n- **1.intro.md**: Core concepts, goals, and benefits of the Abilities API\n- **2.getting-started.md**: Installation methods and basic usage examples\n- **3.registering-abilities.md**: Comprehensive guide to `wp_register_ability()` with all parameters and examples\n- **4.using-abilities.md**: How to retrieve and execute abilities in PHP\n- **5.rest-api.md**: REST API endpoints for abilities\n- **6.hooks.md**: Available WordPress hooks in the Abilities API\n- **7.javascript-client.md**: Complete client-side JavaScript API reference\n- **7.registering-categories.md**: How to register ability categories\n\n**When to read references:**\n\n- For specific parameter details → `3.registering-abilities.md`\n- For setup instructions → `2.getting-started.md`\n- For client-side abilities → `7.javascript-client.md`\n- For category registration → `7.registering-categories.md`\n- For conceptual understanding → `1.intro.md`\n\n## Scripts and Templates\n\n### Scripts (`scripts/`)\n\nThe skill includes automation scripts for generating and validating both abilities and categories:\n\n#### Ability Scripts\n\n- **scaffold-ability.php**: Programmatically generate ability code from CLI arguments\n  - Accepts: name, type, category, label, description, and annotation flags\n  - Outputs: Complete, validated ability code to stdout\n  - Usage: `php scripts/scaffold-ability.php --name=\"plugin/ability\" --type=\"server\" --category=\"data-retrieval\"`\n  - Use when: Creating new abilities after gathering requirements\n\n- **validate-ability.php**: Validate PHP ability code independently of WordPress\n  - Checks: Required fields, JSON Schema validity, best practices\n  - Outputs: Detailed validation results with errors and warnings\n  - Usage: `php scripts/validate-ability.php path/to/ability-file.php`\n  - Use when: Validating server-side PHP ability code before registration\n\n- **validate-ability.js**: Validate JavaScript ability registration code\n  - Requirements: Node.js and acorn parser (`npm install acorn`)\n  - Parser: Uses acorn AST parser for accurate JavaScript parsing\n  - Checks: Required fields (name, category, callback), name format, schemas, permissions, annotations\n  - Outputs: Detailed validation results with errors and warnings\n  - Usage: `node scripts/validate-ability.js path/to/ability-file.js`\n  - Use when: Validating client-side JavaScript ability code before registration\n\n#### Category Scripts\n\n- **scaffold-category.php**: Programmatically generate category registration code\n  - Accepts: name, label, description, type (server/client)\n  - Outputs: Complete category registration code to stdout\n  - Usage: `php scripts/scaffold-category.php --name=\"category-slug\" --label=\"Label\" --description=\"Description\" --type=\"server\"`\n  - Use when: Creating custom categories for abilities\n  - Includes helpful comments about registration hooks and timing\n\n- **validate-category.php**: Validate PHP category registration code\n  - Parser: Uses PHP's `token_get_all()` for accurate parsing\n  - Checks: Name format (kebab-case), required fields, description quality\n  - Outputs: Detailed validation results with errors and warnings\n  - Usage: `php scripts/validate-category.php path/to/category-file.php`\n  - Use when: Validating server-side PHP category code\n\n- **validate-category.js**: Validate JavaScript category registration code\n  - Requirements: Node.js and acorn parser (`npm install acorn`)\n  - Parser: Uses acorn AST parser for accurate JavaScript parsing\n  - Checks: Same validations as PHP validator\n  - Outputs: Detailed validation results with errors and warnings\n  - Usage: `node scripts/validate-category.js path/to/category-file.js`\n  - Use when: Validating client-side JavaScript category code\n\n### Template Assets (`assets/`)\n\nThe skill also includes manual starter templates:\n\n- **server-ability-template.php**: Complete boilerplate for server-side PHP abilities\n- **client-ability-template.js**: Complete boilerplate for client-side JavaScript abilities\n- **category-template.php**: Template for server-side PHP category registration\n- **client-category-template.js**: Template for client-side JavaScript category registration\n\n**Note:** Templates use `{{PLACEHOLDER}}` syntax and are read by scaffold scripts. You can also manually copy and replace placeholders for custom needs. Scaffold scripts generate code by loading these templates and replacing placeholders with actual values.\n\n## Best Practices\n\nWhen helping users create abilities:\n\n1. **Use descriptive names**: `my-plugin/get-user-analytics` not `my-plugin/analytics`\n2. **Write detailed descriptions**: Help AI agents understand WHEN and HOW to use the ability\n3. **Define complete schemas**: Use JSON Schema to validate inputs and document outputs\n4. **Implement proper permissions**: Never use `__return_true` for sensitive operations\n5. **Use appropriate annotations**:\n   - `readonly: true` for data retrieval abilities\n   - `destructive: false` for abilities that only add/update (never delete)\n   - `idempotent: true` for abilities that can be called repeatedly safely\n6. **Handle errors gracefully**: Return `WP_Error` objects with clear error messages\n7. **Test thoroughly**: Verify schema validation, permissions, and error cases\n\n## Common Patterns\n\n### Read-Only Data Retrieval\n\n```php\n'meta' => array(\n    'annotations' => array(\n        'readonly' => true,\n        'destructive' => false,\n        'idempotent' => true,\n    ),\n)\n```\n\n### Data Modification (Non-Destructive)\n\n```php\n'meta' => array(\n    'annotations' => array(\n        'readonly' => false,\n        'destructive' => false,\n        'idempotent' => false,\n    ),\n)\n```\n\n### Potentially Destructive Operations\n\n```php\n'meta' => array(\n    'annotations' => array(\n        'readonly' => false,\n        'destructive' => true,\n        'idempotent' => false,\n    ),\n),\n'permission_callback' => function() {\n    return current_user_can( 'manage_options' );\n}\n```\n\n## Advanced Features\n\n### Client-Side Category Registration\n\nWhen registering client-side abilities with custom categories, use `registerAbilityCategory()` before registering the ability:\n\n```javascript\nimport { registerAbilityCategory, registerAbility } from '@wordpress/abilities';\n\n// Register the category first\nawait registerAbilityCategory('my-custom-category', {\n  label: 'My Custom Category',\n  description: 'Description of what abilities belong in this category',\n  meta: {\n    icon: 'dashicons-admin-customizer',\n    priority: 10,\n  },\n});\n\n// Then register abilities using that category\nawait registerAbility({\n  name: 'my-plugin/my-ability',\n  category: 'my-custom-category', // Uses the client-registered category\n  // ... other properties\n});\n```\n\n### Custom Ability Classes (Advanced)\n\nFor advanced use cases requiring custom behavior, specify a custom class that extends `WP_Ability` using the `ability_class` parameter:\n\n```php\nclass Custom_Ability extends WP_Ability {\n    // Override methods for custom behavior\n    public function execute( $input = array() ) {\n        // Custom execution logic\n        return parent::execute( $input );\n    }\n}\n\nwp_register_ability( 'my-plugin/custom-ability', array(\n    // ... standard parameters\n    'ability_class' => Custom_Ability::class, // Use custom class instead of WP_Ability\n) );\n```\n\n**Note:** This is an advanced feature. Most abilities should use the default `WP_Ability` class."
              }
            ]
          },
          {
            "name": "wordpress-plugin-scaffold",
            "description": "Scaffold WordPress plugins using WP-CLI commands with intelligent environment detection and comprehensive testing support",
            "source": "./claude-code-plugins/wordpress-plugin-scaffold",
            "category": "development-tools",
            "version": "1.0.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/wp-ability-toolkit",
              "/plugin install wordpress-plugin-scaffold@emdashcodes-wp-ability-toolkit"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2025-10-20T16:40:28Z",
              "created_at": "2025-10-19T17:14:16Z",
              "license": "GPL-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "wordpress-plugin-scaffold",
                "description": "Scaffold WordPress plugins using WP-CLI commands (wp scaffold plugin, wp scaffold plugin-tests). Use this skill when creating new WordPress plugins or adding test infrastructure to existing plugins.",
                "path": "claude-code-plugins/wordpress-plugin-scaffold/skills/wordpress-plugin-scaffold/SKILL.md",
                "frontmatter": {
                  "name": "wordpress-plugin-scaffold",
                  "description": "Scaffold WordPress plugins using WP-CLI commands (wp scaffold plugin, wp scaffold plugin-tests). Use this skill when creating new WordPress plugins or adding test infrastructure to existing plugins."
                },
                "content": "# WordPress Plugin Scaffold\n\nThis skill provides guidance for scaffolding WordPress plugins using WP-CLI's scaffold commands. It supports both creating new plugins from scratch and adding test infrastructure to existing plugins.\n\n**Note:** This skill works seamlessly with the **wp-env skill (if available)**. When wp-env setup or management is needed, activate the wp-env skill for comprehensive environment handling.\n\n## About WP-CLI Scaffold Commands\n\nWP-CLI provides two primary scaffolding commands for plugin development:\n\n### wp scaffold plugin\n\nGenerates starter code for a new plugin, including:\n\n- Main plugin PHP file\n- `readme.txt` for WordPress.org\n- `package.json` with Grunt tasks for i18n and readme conversion\n- Editor configuration files (`.editorconfig`, `.gitignore`, `.distignore`)\n- Optional: PHPUnit test suite, CI configuration, and PHP_CodeSniffer rules\n\n### wp scaffold plugin-tests\n\nAdds PHPUnit test infrastructure to an existing plugin, including:\n\n- `phpunit.xml.dist` configuration\n- CI configuration (CircleCI, GitHub Actions, GitLab, Bitbucket)\n- `bin/install-wp-tests.sh` for WordPress test suite setup\n- `tests/bootstrap.php` to activate the plugin during tests\n- `tests/test-sample.php` with example test cases\n- `.phpcs.xml.dist` for PHP_CodeSniffer rules\n\n## Prerequisites\n\nVerify WP-CLI is installed and accessible:\n\n```bash\nwp --version\n```\n\nIf WP-CLI is not installed, see [references/wp-cli-installation.md](references/wp-cli-installation.md) for comprehensive installation instructions across all platforms.\n\n## Environment Detection\n\n**IMPORTANT:** Before running any scaffold commands, detect which WordPress environment is available:\n\n### Detection Strategy\n\n1. **Check for existing WordPress installation** (preferred):\n\n   ```bash\n   wp core version 2>/dev/null\n   ```\n\n   - If successful → Use `wp scaffold plugin` directly\n   - You're already in a WordPress installation, no additional setup needed\n\n2. **Check for wp-env configuration**:\n\n   ```bash\n   # Look for wp-env config files\n   [ -f .wp-env.json ] || [ -f .wp-env.override.json ]\n   ```\n\n   - If found → Check if wp-env is running\n   - If running → Use `wp-env run cli wp scaffold plugin`\n   - If not running → **Activate the wp-env skill (if available)** to start the environment\n\n3. **Check for wp-env availability** (fallback):\n\n   ```bash\n   wp-env --version 2>/dev/null\n   ```\n\n   - If available → Ask user if they want to use wp-env\n   - **Activate the wp-env skill (if available)** for environment setup and management\n\n4. **No environment available** (error):\n   - Inform user they need either:\n     - A WordPress installation with `--path` flag\n     - wp-env setup (see wp-env skill if available)\n\n### Command Prefix Selection\n\nBased on detection, use the appropriate command prefix throughout this skill:\n\n- **In WordPress installation:** `wp scaffold plugin`\n- **Using wp-env:** `wp-env run cli wp scaffold plugin`\n\nAll examples below show the base command. Prepend `wp-env run cli` when using wp-env.\n\n## Workflow: Creating a New Plugin\n\nWhen creating a new WordPress plugin, follow this interactive workflow:\n\n### 1. Gather Plugin Metadata\n\nCollect the following information from the user, offering smart defaults:\n\n- **Plugin slug** (required) - Internal name, lowercase with hyphens\n  - Default: Infer from current directory name or user's request\n\n- **Plugin name** - Display name for the plugin header\n  - Default: Title-case version of slug\n\n- **Plugin description** - What the plugin does\n  - Default: Ask user to provide\n\n- **Plugin author** - Author name\n  - Default: Use `git config user.name` if available\n\n- **Plugin author URI** - Author website URL\n  - Default: Use `git config user.url` if available, otherwise skip\n\n- **Plugin URI** - Plugin project URL\n  - Default: Skip unless user provides\n\n### 2. Determine Additional Options\n\nAsk the user about these options:\n\n- **Include tests?** - Whether to generate PHPUnit test files\n  - Default: Yes (recommended for all plugins)\n  - Use `--skip-tests` flag to omit\n\n- **CI provider** - Which continuous integration service to use\n  - Options: `circle` (default), `github`, `gitlab`, `bitbucket`\n  - Use `--ci=<provider>` flag\n\n- **Target directory** - Where to create the plugin\n  - Default: Current working directory\n  - Use `--dir=<path>` to specify custom location\n\n### 3. Construct and Execute Command\n\nBuild the `wp scaffold plugin` command with gathered information:\n\n```bash\nwp scaffold plugin <slug> \\\n  --plugin_name=\"<name>\" \\\n  --plugin_description=\"<description>\" \\\n  --plugin_author=\"<author>\" \\\n  --plugin_author_uri=\"<author-uri>\" \\\n  --plugin_uri=\"<plugin-uri>\" \\\n  --ci=<provider>\n```\n\nAdd `--skip-tests` if user declined test files.\nAdd `--dir=<path>` if custom directory specified.\n\n### 4. Post-Scaffold Actions\n\nAfter successfully scaffolding the plugin:\n\n1. **Verify creation** - Confirm files were generated:\n\n   ```bash\n   ls -la <plugin-directory>\n   ```\n\n2. **Ask about activation** - If wp-env is running, offer to activate:\n   - \"Would you like me to activate this plugin in your wp-env environment?\"\n   - If yes, run: `wp-env run cli wp plugin activate <slug>`\n   - For network activation: `wp-env run cli wp plugin activate <slug> --network`\n\n3. **Next steps guidance** - Inform user about:\n   - Main plugin file location: `<slug>/<slug>.php`\n   - How to run tests if included: `wp-env run tests-cli --env-cwd=wp-content/plugins/<slug> phpunit`\n   - NPM scripts available: `npm run readme`, `npm run i18n`\n\n## Workflow: Adding Tests to Existing Plugin\n\nWhen adding test infrastructure to an existing plugin:\n\n### 1. Identify Plugin\n\nDetermine which plugin needs tests:\n\n- **Plugin slug** - The plugin directory name\n- **Plugin directory** - Path to the plugin (use `--dir` if non-standard)\n\n### 2. Determine CI Provider\n\nAsk which CI service the user wants:\n\n- Options: `circle` (default), `github`, `gitlab`, `bitbucket`\n\n### 3. Execute Command\n\nRun the scaffold plugin-tests command:\n\n```bash\n# Standard plugin location\nwp scaffold plugin-tests <plugin-slug> --ci=<provider>\n\n# Non-standard location\nwp scaffold plugin-tests --dir=<path/to/plugin> --ci=<provider>\n```\n\nAdd `--force` flag to overwrite existing test files if needed.\n\n### 4. Post-Scaffold Actions\n\nAfter generating test files:\n\n1. **Set up test environment** - Guide user through test setup:\n\n   ```bash\n   # Install WordPress test suite (if not using wp-env)\n   bash bin/install-wp-tests.sh wordpress_test root password localhost latest\n\n   # Or use wp-env for testing\n   wp-env run tests-cli --env-cwd=wp-content/plugins/<slug> phpunit\n   ```\n\n2. **Verify test execution** - Run the sample test:\n\n   ```bash\n   wp-env run tests-cli --env-cwd=wp-content/plugins/<slug> phpunit\n   ```\n\n3. **Next steps** - Inform user about:\n   - Writing additional tests in `tests/` directory\n   - Running specific test files or test cases\n   - CI/CD integration based on chosen provider\n\n## Common Options Reference\n\n| Option               | Description                                          | Example              |\n| -------------------- | ---------------------------------------------------- | -------------------- |\n| `--skip-tests`       | Don't generate PHPUnit test files                    | `--skip-tests`       |\n| `--ci=<provider>`    | CI configuration (circle, github, gitlab, bitbucket) | `--ci=github`        |\n| `--activate`         | Activate plugin after creation                       | `--activate`         |\n| `--activate-network` | Network activate plugin after creation               | `--activate-network` |\n| `--force`            | Overwrite existing files                             | `--force`            |\n| `--dir=<path>`       | Custom directory for plugin                          | `--dir=/custom/path` |\n\n**Note:** `--activate` and `--activate-network` flags work with local wp-cli WordPress installations but not with wp-env. For wp-env, use `wp-env run cli wp plugin activate` instead.\n\n## Best Practices\n\n### Plugin Naming\n\n- Use lowercase letters, numbers, and hyphens only\n- Be descriptive but concise\n- Follow WordPress plugin naming conventions\n- Examples: `my-contact-form`, `analytics-dashboard`, `custom-post-types`\n\n### When to Skip Tests\n\nSkip tests (`--skip-tests`) only when:\n\n- Creating a quick prototype or proof-of-concept\n- Building a personal plugin that won't be distributed\n- Planning to add tests later with `wp scaffold plugin-tests`\n\n**Always include tests for:**\n\n- Plugins intended for public distribution\n- Team projects with multiple contributors\n- Plugins with complex business logic\n- Any production-ready code\n\n### CI Provider Selection\n\nChoose a CI provider based on your repository host:\n\n- **GitHub repositories** → `--ci=github` (GitHub Actions)\n- **GitLab repositories** → `--ci=gitlab` (GitLab CI)\n- **Bitbucket repositories** → `--ci=bitbucket` (Bitbucket Pipelines)\n- **Other/unknown** → `--ci=circle` (CircleCI)\n\n### Working with wp-env\n\nWhen developing with wp-env:\n\n1. **Scaffold inside wp-env directory structure:**\n\n   ```bash\n   # Create plugin in wp-env's plugin directory\n   cd /path/to/wp-env-project\n   wp scaffold plugin my-plugin --dir=plugins/\n   ```\n\n2. **Or scaffold separately and configure .wp-env.json:**\n\n   ```json\n   {\n     \"plugins\": [\".\", \"../other-plugin\"]\n   }\n   ```\n\n3. **Activate after scaffolding:**\n\n   ```bash\n   wp-env run cli wp plugin activate my-plugin\n   ```\n\n4. **Run tests in wp-env:**\n\n   ```bash\n   wp-env run tests-cli --env-cwd=wp-content/plugins/my-plugin phpunit\n   ```\n\n## Example Interactions\n\n### Creating a New Plugin\n\n**User:** \"Create a new WordPress plugin called 'site-analytics' for tracking visitor analytics\"\n\n**Process:**\n\n1. Gather metadata (use smart defaults from git config)\n2. Ask about tests (default: yes) and CI provider (default: github)\n3. Execute: `wp scaffold plugin site-analytics --plugin_name=\"Site Analytics\" --plugin_description=\"Track visitor analytics and generate reports\" --plugin_author=\"Em\" --ci=github`\n4. Ask: \"Would you like me to activate this plugin in wp-env?\"\n\n### Adding Tests to Existing Plugin\n\n**User:** \"Add tests to my existing 'custom-widgets' plugin\"\n\n**Process:**\n\n1. Identify plugin location\n2. Ask about CI provider\n3. Execute: `wp scaffold plugin-tests custom-widgets --ci=github`\n4. Guide user through running tests with wp-env\n\n## Additional Resources\n\n- [WP-CLI Scaffold Plugin Documentation](https://developer.wordpress.org/cli/commands/scaffold/plugin/)\n- [WP-CLI Scaffold Plugin Tests Documentation](https://developer.wordpress.org/cli/commands/scaffold/plugin-tests/)\n- [Plugin Unit Tests Handbook](https://make.wordpress.org/cli/handbook/misc/plugin-unit-tests/)\n- [WordPress Plugin Handbook](https://developer.wordpress.org/plugins/)"
              }
            ]
          },
          {
            "name": "wp-env",
            "description": "Manage local WordPress development environments using @wordpress/env with Docker for plugin and theme development",
            "source": "./claude-code-plugins/wp-env",
            "category": "development-tools",
            "version": "1.0.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/wp-ability-toolkit",
              "/plugin install wp-env@emdashcodes-wp-ability-toolkit"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2025-10-20T16:40:28Z",
              "created_at": "2025-10-19T17:14:16Z",
              "license": "GPL-2.0"
            },
            "commands": [],
            "skills": [
              {
                "name": "wp-env",
                "description": "Local WordPress development environment management using @wordpress/env for plugin and theme development. Use this skill when setting up, configuring, starting, stopping, or managing wp-env Docker-based WordPress environments.",
                "path": "claude-code-plugins/wp-env/skills/wp-env/SKILL.md",
                "frontmatter": {
                  "name": "wp-env",
                  "description": "Local WordPress development environment management using @wordpress/env for plugin and theme development. Use this skill when setting up, configuring, starting, stopping, or managing wp-env Docker-based WordPress environments."
                },
                "content": "# wp-env - WordPress Local Development Environment\n\nThis skill provides assistance for working with `wp-env`, a tool that sets up local WordPress development environments using Docker with minimal configuration.\n\n## About wp-env\n\n`wp-env` (`@wordpress/env`) creates Docker-based WordPress environments for plugin and theme development. It provides:\n\n- **Zero-config setup** - Works out of the box for plugins and themes\n- **Dual environments** - Separate development (port 8888) and testing (port 8889) instances\n- **Pre-configured tools** - Includes WP-CLI, Composer, PHPUnit, and Xdebug\n- **Flexible configuration** - Customize via `.wp-env.json` for complex setups\n\n**Default Access:**\n\n- Development site: <http://localhost:8888>\n- Testing site: <http://localhost:8889>\n- Login: username `admin`, password `password`\n- Database: user `root`, password `password`\n\n## Prerequisites Check\n\nBefore working with wp-env, verify these dependencies are installed and running:\n\n```bash\n# Check Docker is installed and running\ndocker --version\ndocker ps\n\n# Check Node.js and npm\nnode --version\nnpm --version\n\n# Check if wp-env is installed\nwp-env --version\n```\n\n**If Docker is not running:** Start Docker Desktop application first - wp-env cannot function without Docker.\n\n**If wp-env is not installed:** Install globally with `npm -g install @wordpress/env`\n\n## Common Workflows\n\n### First-Time Environment Setup\n\nWhen setting up wp-env for the first time in a plugin or theme directory:\n\n```bash\n# 1. Ensure Docker Desktop is running\ndocker ps\n\n# 2. Install wp-env globally (if not already installed)\nnpm -g install @wordpress/env\n\n# 3. Navigate to your plugin or theme directory\ncd /path/to/your/plugin\n\n# 4. Start the environment (downloads WordPress, sets up containers)\nwp-env start\n\n# 5. Access the site at http://localhost:8888\n# Login with admin/password\n```\n\nwp-env will automatically detect if the current directory is a plugin or theme and mount it appropriately.\n\n### Daily Development Operations\n\n**Starting the environment:**\n\n```bash\n# Start with existing configuration\nwp-env start\n\n# Start and update WordPress/sources\nwp-env start --update\n\n# Start with Xdebug enabled for debugging\nwp-env start --xdebug\n```\n\n**Stopping the environment:**\n\n```bash\n# Stop containers (preserves data)\nwp-env stop\n```\n\n**Checking environment status:**\n\n```bash\n# View running containers\ndocker ps\n\n# Should show: wordpress (8888), tests-wordpress (8889), mariadb (3306)\n```\n\n### Running WP-CLI Commands\n\nExecute WordPress CLI commands inside the environment using `wp-env run`:\n\n```bash\n# List users on development instance\nwp-env run cli wp user list\n\n# Install a plugin\nwp-env run cli wp plugin install contact-form-7 --activate\n\n# Create a test post on the testing instance\nwp-env run tests-cli wp post create --post_title=\"Test Post\" --post_status=publish\n\n# Update permalink structure (enables REST API access)\nwp-env run cli \"wp rewrite structure /%postname%/\"\n\n# Open WordPress shell for interactive PHP\nwp-env run cli wp shell\n```\n\n**Environment types:**\n\n- `cli` / `wordpress` - Development environment (shares database with port 8888)\n- `tests-cli` / `tests-wordpress` - Testing environment (separate database, port 8889)\n\n**Working directory context:**\nBy default, commands run from WordPress root. For plugin-specific commands, use `--env-cwd`:\n\n```bash\n# Run composer install in your plugin directory\nwp-env run cli --env-cwd=wp-content/plugins/your-plugin composer install\n\n# Run PHPUnit tests in your plugin\nwp-env run tests-cli --env-cwd=wp-content/plugins/your-plugin phpunit\n```\n\n### Database Reset for Testing\n\nReset the database to clean state:\n\n```bash\n# Reset only the tests database (default)\nwp-env clean\n\n# Reset development database\nwp-env clean development\n\n# Reset both databases\nwp-env clean all\n```\n\n⚠️ **Warning:** This permanently deletes all posts, pages, media, and custom data.\n\n### Viewing Logs\n\nMonitor PHP errors and Docker container logs:\n\n```bash\n# View development environment logs (follows/watches by default)\nwp-env logs\n\n# View testing environment logs\nwp-env logs tests\n\n# View both environments\nwp-env logs all\n\n# Disable following/watching\nwp-env logs --watch=false\n```\n\n### Working with Ports\n\nIf the default port 8888 conflicts with another service:\n\n```bash\n# Using environment variables\nWP_ENV_PORT=3333 wp-env start\n\n# Check which ports are in use\ndocker ps\n```\n\nOr configure ports in `.wp-env.json`:\n\n```json\n{\n  \"port\": 3333,\n  \"testsPort\": 3334\n}\n```\n\nNote: Environment variables take precedence over `.wp-env.json` values.\n\n## Quick Reference - Essential Commands\n\n| Command                            | Description                                   |\n| ---------------------------------- | --------------------------------------------- |\n| `wp-env start`                     | Start the environment                         |\n| `wp-env start --update`            | Start and update WordPress/sources            |\n| `wp-env stop`                      | Stop the environment                          |\n| `wp-env clean [env]`               | Reset database (env: tests, development, all) |\n| `wp-env destroy`                   | Completely remove containers and data         |\n| `wp-env logs [env]`                | View logs (env: development, tests, all)      |\n| `wp-env run <container> <command>` | Execute command in container                  |\n| `wp-env install-path`              | Show where environment files are stored       |\n| `docker ps`                        | Check which containers are running            |\n\n**Common containers for `wp-env run`:**\n\n- `cli` - WP-CLI, Composer, PHPUnit (development)\n- `tests-cli` - WP-CLI, Composer, PHPUnit (testing)\n- `wordpress` - WordPress PHP environment (development)\n- `tests-wordpress` - WordPress PHP environment (testing)\n\n## Configuration with .wp-env.json\n\nCreate a `.wp-env.json` file in your project root to customize the environment.\n\n### Common Configuration Patterns\n\n**Basic plugin development:**\n\n```json\n{\n  \"plugins\": [\".\"]\n}\n```\n\n**Custom WordPress version:**\n\n```json\n{\n  \"core\": \"WordPress/WordPress#6.4.0\",\n  \"plugins\": [\".\"]\n}\n```\n\n**Multi-plugin setup:**\n\n```json\n{\n  \"plugins\": [\".\", \"WordPress/classic-editor\", \"../another-plugin\"]\n}\n```\n\nFor complete configuration reference with 20+ examples, environment-specific overrides, custom mappings, multisite setup, and lifecycle scripts, see [references/configuration-guide.md](references/configuration-guide.md).\n\n## When Things Go Wrong\n\n### Common Errors\n\n**Error: \"Error while running docker-compose command\"**\n\n- Check that Docker Desktop is started and running\n- Check Docker Desktop dashboard for logs, restart, or remove existing virtual machines\n- Then try rerunning `wp-env start`\n\n**Error: \"Host is already in use by another container\"**\n\n- The container you are attempting to start is already running, or another container is. You can stop an existing container by running `wp-env stop` from the directory that you started it in\n- If you do not remember the directory where you started `wp-env`, you can stop all containers by running `docker stop $(docker ps -q)`. This will stop all Docker containers, so use with caution\n- Then try rerunning `wp-env start`\n\nFor comprehensive troubleshooting including Ubuntu Docker setup, database issues, and advanced debugging, see [references/troubleshooting.md](references/troubleshooting.md).\n\n## Advanced Features\n\nFor detailed information on these features, see [references/command-reference.md](references/command-reference.md).\n\n**Xdebug:** Enable step debugging with `wp-env start --xdebug`. Configure your IDE for port 9003.\n\n**PHPUnit:** WordPress test files included. Run with `wp-env run tests-cli --env-cwd=wp-content/plugins/your-plugin phpunit`.\n\n**Composer:** Execute commands with `wp-env run cli --env-cwd=wp-content/plugins/your-plugin composer install`.\n\n## Best Practices\n\n### Directory Context\n\n- Run `wp-env start` from your plugin or theme directory for automatic mounting\n- Use `--env-cwd` when running commands that need to execute in specific directories\n- Use absolute paths when possible to avoid confusion\n\n### Development Workflow\n\n1. Start environment once per work session: `wp-env start`\n2. Make code changes - they're immediately reflected (no rebuild needed)\n3. Use `wp-env run cli wp` commands for WordPress operations\n4. Check logs when debugging: `wp-env logs`\n5. Stop when done: `wp-env stop`\n\n### Testing Workflow\n\n1. Use `tests-cli` and `tests-wordpress` for isolated testing\n2. Reset test database frequently: `wp-env clean tests`\n3. Keep test and development environments separate\n4. Use `wp-env clean all` before running full integration tests\n\n### Configuration Management\n\n- Keep `.wp-env.json` in version control for team consistency\n- Use `.wp-env.override.json` (gitignored) for local-only overrides\n- Document custom configurations in project README\n\n## Where Files Are Stored\n\nwp-env stores files in a home directory (defaults vary by platform):\n\n```bash\n# Get the install path for current project\nwp-env install-path\n\n# Default locations:\n# macOS/Windows: ~/.wp-env/$md5_of_project_path\n# Linux: ~/wp-env/$md5_of_project_path\n```\n\nOverride with `WP_ENV_HOME` environment variable:\n\n```bash\nWP_ENV_HOME=\"./local-wp-env\" wp-env start\n```\n\n## Additional Resources\n\n- **Command Reference:** [references/command-reference.md](references/command-reference.md) - Complete CLI documentation\n- **Configuration Guide:** [references/configuration-guide.md](references/configuration-guide.md) - All `.wp-env.json` options\n- **Troubleshooting:** [references/troubleshooting.md](references/troubleshooting.md) - Common issues and solutions\n\nExternal documentation:\n\n- [@wordpress/env npm package](https://www.npmjs.com/package/@wordpress/env)\n- [WordPress Developer Handbook - wp-env](https://developer.wordpress.org/block-editor/getting-started/devenv/get-started-with-wp-env/)\n- [Docker Desktop](https://docs.docker.com/desktop/)"
              }
            ]
          }
        ]
      }
    },
    {
      "full_name": "emdashcodes/claude-code-plugins",
      "url": "https://github.com/emdashcodes/claude-code-plugins",
      "description": "Claude Code plugins featuring specialized agents, commands, and development skills.",
      "homepage": "https://emdash.codes/claude-code/",
      "signals": {
        "stars": 4,
        "forks": 1,
        "pushed_at": "2026-01-08T19:24:31Z",
        "created_at": "2025-10-18T01:20:32Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 5483
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 43
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 4839
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 6518
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-agent-sdk-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-agent-sdk-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-agent-sdk-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 223
        },
        {
          "path": "plugins/claude-agent-sdk-dev/CHANGELOG.md",
          "type": "blob",
          "size": 512
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/SKILL.md",
          "type": "blob",
          "size": 10454
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_cost-tracking.md",
          "type": "blob",
          "size": 8864
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_custom-tools.md",
          "type": "blob",
          "size": 11714
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_hosting.md",
          "type": "blob",
          "size": 7159
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_mcp.md",
          "type": "blob",
          "size": 4894
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_migration-guide.md",
          "type": "blob",
          "size": 7704
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_modifying-system-prompts.md",
          "type": "blob",
          "size": 11299
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_overview.md",
          "type": "blob",
          "size": 7774
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_permissions.md",
          "type": "blob",
          "size": 10328
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_plugins.md",
          "type": "blob",
          "size": 7504
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_python.md",
          "type": "blob",
          "size": 55789
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_sessions.md",
          "type": "blob",
          "size": 4863
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_skills.md",
          "type": "blob",
          "size": 8756
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_slash-commands.md",
          "type": "blob",
          "size": 9184
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_streaming-vs-single-mode.md",
          "type": "blob",
          "size": 5517
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_structured-outputs.md",
          "type": "blob",
          "size": 7725
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_subagents.md",
          "type": "blob",
          "size": 9318
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_todo-tracking.md",
          "type": "blob",
          "size": 3741
        },
        {
          "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/references/agent-sdk_typescript.md",
          "type": "blob",
          "size": 39462
        },
        {
          "path": "plugins/claude-code-meta",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-hooks/SKILL.md",
          "type": "blob",
          "size": 12833
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-hooks/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-hooks/references/best-practices.md",
          "type": "blob",
          "size": 11425
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-hooks/references/hook-events.md",
          "type": "blob",
          "size": 14487
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-hooks/references/implementation-guide.md",
          "type": "blob",
          "size": 29222
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-mcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-mcp/SKILL.md",
          "type": "blob",
          "size": 14803
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-plugins/SKILL.md",
          "type": "blob",
          "size": 19846
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-plugins/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-plugins/references/plugin-marketplaces-guide.md",
          "type": "blob",
          "size": 13351
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-plugins/references/plugins-guide.md",
          "type": "blob",
          "size": 11871
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-plugins/references/plugins-reference.md",
          "type": "blob",
          "size": 11403
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/SKILL.md",
          "type": "blob",
          "size": 15699
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/assets/template-plugin-skill.md",
          "type": "blob",
          "size": 4756
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/references/agent-skills-spec.md",
          "type": "blob",
          "size": 1670
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/references/allowed-tools-guide.md",
          "type": "blob",
          "size": 11851
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/references/progressive-disclosure.md",
          "type": "blob",
          "size": 11854
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/scripts/init_skill.py",
          "type": "blob",
          "size": 12368
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/scripts/package_skill.py",
          "type": "blob",
          "size": 3247
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-skills/scripts/validate_skill.py",
          "type": "blob",
          "size": 10099
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/SKILL.md",
          "type": "blob",
          "size": 9130
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/assets/template-advanced.md",
          "type": "blob",
          "size": 1030
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/assets/template-basic.md",
          "type": "blob",
          "size": 101
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/assets/template-with-arguments.md",
          "type": "blob",
          "size": 421
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/assets/template-with-bash.md",
          "type": "blob",
          "size": 444
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/references/slash-commands-reference.md",
          "type": "blob",
          "size": 10317
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/scripts/create_slash_command.sh",
          "type": "blob",
          "size": 5249
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/SKILL.md",
          "type": "blob",
          "size": 10284
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/assets/code-reviewer.md",
          "type": "blob",
          "size": 3236
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/assets/custom.md",
          "type": "blob",
          "size": 3022
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/assets/debugger.md",
          "type": "blob",
          "size": 3383
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/references/subagents-reference.md",
          "type": "blob",
          "size": 17988
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-meta/skills/claude-code-subagents/scripts/create_subagent.sh",
          "type": "blob",
          "size": 7637
        },
        {
          "path": "plugins/google-docs-reader",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/google-docs-reader/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/google-docs-reader/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 258
        },
        {
          "path": "plugins/google-docs-reader/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/google-docs-reader/skills/google-docs-reader",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/google-docs-reader/skills/google-docs-reader/SKILL.md",
          "type": "blob",
          "size": 7908
        },
        {
          "path": "plugins/google-docs-reader/skills/google-docs-reader/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/google-docs-reader/skills/google-docs-reader/references/export_formats.md",
          "type": "blob",
          "size": 1786
        },
        {
          "path": "plugins/google-docs-reader/skills/google-docs-reader/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/google-docs-reader/skills/google-docs-reader/scripts/export_gdoc.py",
          "type": "blob",
          "size": 6992
        },
        {
          "path": "plugins/google-docs-reader/skills/google-docs-reader/scripts/read_exported_doc.py",
          "type": "blob",
          "size": 6277
        },
        {
          "path": "plugins/mermaid-diagram-to-image",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mermaid-diagram-to-image/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mermaid-diagram-to-image/skills/mermaid-diagram-to-image",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mermaid-diagram-to-image/skills/mermaid-diagram-to-image/SKILL.md",
          "type": "blob",
          "size": 8077
        },
        {
          "path": "plugins/nano-banana-image-editor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nano-banana-image-editor/.gitignore",
          "type": "blob",
          "size": 140
        },
        {
          "path": "plugins/nano-banana-image-editor/CHANGELOG.md",
          "type": "blob",
          "size": 1124
        },
        {
          "path": "plugins/nano-banana-image-editor/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nano-banana-image-editor/commands/image.md",
          "type": "blob",
          "size": 735
        },
        {
          "path": "plugins/nano-banana-image-editor/commands/upgrade.md",
          "type": "blob",
          "size": 6638
        },
        {
          "path": "plugins/nano-banana-image-editor/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/SKILL.md",
          "type": "blob",
          "size": 18279
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/references/best_practices.md",
          "type": "blob",
          "size": 9776
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/references/prompting_guide.md",
          "type": "blob",
          "size": 9560
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/scripts/create_image.py",
          "type": "blob",
          "size": 2376
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/scripts/edit_image.py",
          "type": "blob",
          "size": 2579
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/scripts/gemini_image.py",
          "type": "blob",
          "size": 7272
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/scripts/install_dependencies.sh",
          "type": "blob",
          "size": 1721
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/scripts/quick_crop.py",
          "type": "blob",
          "size": 3079
        },
        {
          "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/scripts/setup-gemini-token.py",
          "type": "blob",
          "size": 3809
        },
        {
          "path": "plugins/quill-export",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/quill-export/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/quill-export/skills/quill-export",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/quill-export/skills/quill-export/SKILL.md",
          "type": "blob",
          "size": 5838
        },
        {
          "path": "plugins/quill-export/skills/quill-export/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/quill-export/skills/quill-export/assets/meeting-template.md",
          "type": "blob",
          "size": 1458
        },
        {
          "path": "plugins/quill-export/skills/quill-export/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/quill-export/skills/quill-export/references/quill-schema.md",
          "type": "blob",
          "size": 5385
        },
        {
          "path": "plugins/quill-export/skills/quill-export/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/quill-export/skills/quill-export/scripts/export_meeting.py",
          "type": "blob",
          "size": 13354
        },
        {
          "path": "plugins/video-toolkit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/video-toolkit/.gitignore",
          "type": "blob",
          "size": 26
        },
        {
          "path": "plugins/video-toolkit/CHANGELOG.md",
          "type": "blob",
          "size": 1236
        },
        {
          "path": "plugins/video-toolkit/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/video-toolkit/agents/video-frame-analyzer.md",
          "type": "blob",
          "size": 6296
        },
        {
          "path": "plugins/video-toolkit/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/video-toolkit/commands/upgrade.md",
          "type": "blob",
          "size": 6297
        },
        {
          "path": "plugins/video-toolkit/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/SKILL.md",
          "type": "blob",
          "size": 63884
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/references/ffmpeg_commands.md",
          "type": "blob",
          "size": 6611
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/analyze_audio_gemini.py",
          "type": "blob",
          "size": 8465
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/analyze_video.sh",
          "type": "blob",
          "size": 11718
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/edit_video.py",
          "type": "blob",
          "size": 9465
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/extract_audio.py",
          "type": "blob",
          "size": 4961
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/extract_frames.py",
          "type": "blob",
          "size": 11141
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/identify_music.py",
          "type": "blob",
          "size": 10596
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/install_dependencies.sh",
          "type": "blob",
          "size": 4464
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/setup_api_keys.py",
          "type": "blob",
          "size": 5081
        },
        {
          "path": "plugins/video-toolkit/skills/video-toolkit/scripts/transcribe_audio.py",
          "type": "blob",
          "size": 6153
        }
      ],
      "marketplace": {
        "name": "emdashcodes-claude-code-plugins",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Em",
          "url": "https://github.com/emdashcodes"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "claude-code-meta",
            "description": "Complete toolkit for building and distributing Claude Code plugins, skills, hooks, subagents, slash commands, marketplaces, and MCP servers",
            "source": "./plugins/claude-code-meta",
            "category": "development-tools",
            "version": "1.1.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/claude-code-plugins",
              "/plugin install claude-code-meta@emdashcodes-claude-code-plugins"
            ],
            "signals": {
              "stars": 4,
              "forks": 1,
              "pushed_at": "2026-01-08T19:24:31Z",
              "created_at": "2025-10-18T01:20:32Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "claude-code-hooks",
                "description": "Claude Code hooks configuration patterns, event types, validation scripts, and decision control for automating workflows and integrating external tools. This skill should be used when creating hooks, validating tool usage, automating workflows, or integrating external tools with Claude Code.",
                "path": "plugins/claude-code-meta/skills/claude-code-hooks/SKILL.md",
                "frontmatter": {
                  "name": "claude-code-hooks",
                  "description": "Claude Code hooks configuration patterns, event types, validation scripts, and decision control for automating workflows and integrating external tools. This skill should be used when creating hooks, validating tool usage, automating workflows, or integrating external tools with Claude Code."
                },
                "content": "# Claude Code Hooks\n\nThis skill provides assistance for working with Claude Code hooks to enable automation of workflows and integration of external tools through an event-driven system.\n\n## About Hooks\n\nHooks are event-driven automation scripts that execute automatically when specific events occur during Claude Code's operation. Think of them as \"middleware\" for Claude's actions—they intercept events to validate inputs, enrich context, automate workflows, or integrate external tools, transforming Claude from a general assistant into a policy-aware, context-enriched agent.\n\n### What Hooks Provide\n\n1. **Input validation** - Block dangerous operations, enforce security policies, prevent path traversal\n2. **Workflow automation** - Auto-format code, run linters, backup files, send notifications\n3. **Context enrichment** - Load git status, inject project context, add session information\n4. **External integration** - Connect to APIs, trigger CI/CD, log to external systems\n5. **Decision control** - Auto-approve safe operations, require confirmation for sensitive actions\n\n### Anatomy of a Hook\n\nEvery hook consists of configuration in settings.json and an optional validation script:\n\n```\n.claude/\n├── settings.json         - Hook configuration (required)\n│   └── hooks:\n│       └── EventName:    - Which event to hook (PreToolUse, PostToolUse, etc.)\n│           └── matcher:  - Which tools to match (regex pattern)\n│               └── command: - What to execute (shell command or script)\n└── hooks/                - Hook scripts (optional)\n    └── script-name.py    - Validation/automation logic\n```\n\n#### Configuration (required)\n\nHooks are configured in settings.json with event type, tool matcher, and command:\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PROJECT_DIR}/.claude/hooks/validate-bash.py\",\n            \"timeout\": 60\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n#### Hook Scripts (optional)\n\nScripts receive JSON via stdin and communicate via exit codes:\n\n- **Exit 0** - Success (output shown in transcript or added as context)\n- **Exit 2** - Blocking error (stderr shown to Claude for processing)\n- **Other** - Non-blocking error (stderr shown to user)\n\nScripts can also output JSON for advanced control (permission decisions, additional context, custom output).\n\n### Hook Execution Flow\n\nHooks use a three-phase execution system:\n\n1. **Event triggered** - Claude performs action (e.g., runs Bash tool)\n2. **Hook executes** - Script receives event data via stdin, processes, exits with code\n3. **Decision applied** - Based on exit code/JSON output, Claude proceeds, blocks, or receives additional context\n\n## Hook Events Overview\n\nClaude Code supports these hook events:\n\n**PreToolUse** - Execute before a tool runs. Use for validation, blocking dangerous operations, or auto-approving safe actions.\n\n**PostToolUse** - Execute after a tool completes. Use for formatting code, running linters, sending notifications, or providing feedback to Claude.\n\n**UserPromptSubmit** - Execute when user submits a prompt. Use for adding contextual information, validating prompt content, or blocking sensitive data.\n\n**SessionStart** - Execute when Claude Code starts or resumes. Use for loading recent commits, showing current branch, displaying open issues, or initializing session context.\n\n**SessionEnd** - Execute when a session ends. Use for saving statistics, cleaning temporary files, or logging activity.\n\n**Stop/SubagentStop** - Execute when Claude attempts to stop. Use for ensuring tasks are complete or forcing continuation if needed.\n\n**PreCompact** - Execute before conversation history compaction. Use for saving important context or logging stats.\n\n**Notification** - Execute when Claude Code sends notifications. Use for forwarding to external systems or logging events.\n\nFor detailed information on each event type, see [references/hook-events.md](references/hook-events.md).\n\n## Basic Hook Configuration\n\nHooks are configured in settings.json files with this structure:\n\n```json\n{\n  \"hooks\": {\n    \"EventName\": [\n      {\n        \"matcher\": \"ToolPattern\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"path/to/script.py\",\n            \"timeout\": 60\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n**Key elements:**\n\n- `matcher`: Pattern to match tool names (e.g., `\"Write|Edit\"`, `\"Bash\"`, `\"*\"` for all)\n- `command`: Shell command or script to execute\n- `timeout`: Maximum execution time in seconds (default: 60)\n\nUse environment variables in commands:\n\n- `CLAUDE_PROJECT_DIR` - Project root directory\n- `CLAUDE_PLUGIN_ROOT` - Plugin directory (plugin hooks only)\n\n## Hook Scripts\n\n### Exit Codes\n\nHook scripts communicate through exit codes:\n\n- `0` - Success (stdout shown in transcript, or added as context for UserPromptSubmit/SessionStart)\n- `2` - Blocking error (stderr shown to Claude for processing)\n- Other - Non-blocking error (stderr shown to user)\n\n### Input Format\n\nHooks receive JSON via stdin with session information and event-specific data:\n\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\n\ninput_data = json.load(sys.stdin)\ntool_name = input_data.get(\"tool_name\")\ntool_input = input_data.get(\"tool_input\", {})\n\n# Hook logic here\nsys.exit(0)\n```\n\n### Output Format\n\nFor simple hooks, use exit codes. For advanced control, output JSON:\n\n```python\nimport json\n\noutput = {\n    \"decision\": \"block\",  # or undefined\n    \"reason\": \"Explanation\",\n    \"hookSpecificOutput\": {\n        \"hookEventName\": \"PreToolUse\",\n        \"permissionDecision\": \"allow\",  # \"allow\", \"deny\", \"ask\"\n        \"additionalContext\": \"Context for Claude\"\n    }\n}\n\nprint(json.dumps(output))\nsys.exit(0)\n```\n\n## Common Patterns\n\nFor detailed hook implementation:\n\n- [references/implementation-guide.md](references/implementation-guide.md) - Quick patterns and complete examples\n- [references/best-practices.md](references/best-practices.md) - Security, performance, and maintainability\n\n## Configuration Locations\n\n**User hooks:** `~/.claude/settings.json` - Personal preferences, cross-project automation\n\n**Project hooks:** `.claude/settings.json` - Team workflows, project-specific validations\n\n**Local hooks:** `.claude/settings.local.json` - Local testing, not committed to git\n\n**Plugin hooks:** `plugins/{name}/hooks/hooks.json` - Reusable workflows for plugins\n\n## MCP Integration\n\nHooks work with MCP tools using the naming pattern `mcp__<server>__<tool>`:\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"mcp__github__.*\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PROJECT_DIR}/.claude/hooks/validate-github.py\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n## Hook Creation Process\n\nTo create a hook, follow the \"Hook Creation Process\" in order, skipping steps only if there is a clear reason they are not applicable.\n\n### Step 1: Understanding the Hook Requirements\n\nSkip this step only when the hook's purpose and triggering conditions are already clearly understood.\n\nTo create an effective hook, clearly understand concrete examples of when the hook should trigger and what it should do. This understanding can come from either specific use cases or scenarios that need automation.\n\nFor example, when building a bash validation hook, relevant considerations include:\n\n- \"What dangerous bash commands should be blocked?\"\n- \"Should the hook allow sudo/rm -rf commands, or block them entirely?\"\n- \"What feedback should Claude receive when a command is blocked?\"\n- \"Are there any commands that should always be allowed despite matching block patterns?\"\n\nFor a code formatting hook:\n\n- \"Which file types need formatting? Python, JavaScript, both?\"\n- \"Should formatting failures block the operation or just warn?\"\n- \"What formatter tools are installed in the environment?\"\n\nConclude this step when there is a clear sense of what the hook should accomplish and when it should trigger.\n\n### Step 2: Planning the Hook Implementation\n\nTo turn requirements into an effective hook, analyze the use case by:\n\n1. Identifying which hook event is appropriate (PreToolUse for validation, PostToolUse for formatting, etc.)\n2. Determining the tool matcher pattern (specific tools like \"Bash\", wildcards like \"Write|Edit\", or \"*\" for all)\n3. Deciding if a simple command or script is needed\n\nExample: For blocking dangerous bash commands, the analysis shows:\n\n1. Use **PreToolUse** event (validate before execution)\n2. Match **\"Bash\"** tool specifically\n3. Need a **script** with pattern matching and exit code 2 for blocking\n\nExample: For auto-formatting code after edits, the analysis shows:\n\n1. Use **PostToolUse** event (format after write completes)\n2. Match **\"Write|Edit\"** tools\n3. Need a **script** that detects file extension and runs appropriate formatter\n\nReview [references/hook-events.md](references/hook-events.md) for event-specific details and [references/implementation-guide.md](references/implementation-guide.md) for code patterns.\n\n### Step 3: Choosing Configuration Location\n\nAt this point, determine where the hook configuration should live:\n\n- **User hooks** (`~/.claude/settings.json`) - Personal preferences that apply across all projects\n- **Project hooks** (`.claude/settings.json`) - Team workflows and project-specific policies\n- **Local hooks** (`.claude/settings.local.json`) - Testing and development, not committed to git\n- **Plugin hooks** (`plugins/{name}/hooks/hooks.json`) - Reusable workflows distributed with plugins\n\nChoose user-level for personal automation (e.g., \"always load git context at session start\").\n\nChoose project-level for team policies (e.g., \"block commits with sensitive data\").\n\nChoose local-level for testing hooks before committing to the project.\n\n### Step 4: Implementing the Hook\n\nWhen implementing the hook, start with the simplest approach that meets requirements.\n\n#### For Simple Hooks\n\nIf the hook just needs to run a command without validation, use inline commands:\n\n```json\n{\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"black \\\"${file_path}\\\"\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n#### For Validation Hooks\n\nIf the hook needs to make decisions, create a script:\n\n1. Create script file: `.claude/hooks/validate-bash.py`\n2. Implement validation logic with exit codes (0 = allow, 2 = block, other = error)\n3. Reference script in configuration with absolute path using `${CLAUDE_PROJECT_DIR}`\n\nReference [references/implementation-guide.md](references/implementation-guide.md) for quick patterns and production-ready examples.\n\n**Writing Style:** Focus on information that would be beneficial and non-obvious to the hook script. Consider security implications, edge cases, and performance optimizations from [references/best-practices.md](references/best-practices.md).\n\n### Step 5: Testing and Debugging\n\nOnce the hook is configured, test it thoroughly before relying on it:\n\n#### Test Manually\n\nTest the hook script independently before integrating:\n\n```bash\n# Create test input\necho '{\"tool_name\":\"Bash\",\"tool_input\":{\"command\":\"rm -rf /\"}}' | \\\n  .claude/hooks/validate-bash.py\n\n# Check exit code\necho \"Exit code: $?\"\n\n# Check stderr output\necho '{\"tool_name\":\"Bash\",\"tool_input\":{\"command\":\"rm -rf /\"}}' | \\\n  .claude/hooks/validate-bash.py 2>&1\n```\n\n#### Test in Claude Code\n\nRun Claude Code with debug mode to see hook execution:\n\n```bash\nclaude --debug\n```\n\nThis shows:\n\n- Hook loading and configuration\n- Hook execution timing\n- Hook output and exit codes\n- Decision outcomes\n\nUse transcript mode (Ctrl-R) to see hook progress messages in the conversation timeline.\n\n### Step 6: Iterate\n\nAfter deploying the hook, users may encounter edge cases or request improvements. This often happens during real usage when unexpected scenarios arise.\n\n**Iteration workflow:**\n\n1. **Use the hook** on real tasks and observe behavior\n2. **Notice struggles** - Does it block too much? Too little? Miss edge cases?\n3. **Identify improvements** - Should validation be stricter? Should error messages be clearer?\n4. **Update implementation** - Modify script logic or configuration\n5. **Test changes** - Use manual testing and `claude --debug` to verify improvements"
              },
              {
                "name": "claude-code-mcp",
                "description": "This skill should be used when configuring, installing, or managing MCP (Model Context Protocol) servers in Claude Code. Use when users need to connect Claude Code to external tools, databases, APIs, or services through MCP integration.",
                "path": "plugins/claude-code-meta/skills/claude-code-mcp/SKILL.md",
                "frontmatter": {
                  "name": "claude-code-mcp",
                  "description": "This skill should be used when configuring, installing, or managing MCP (Model Context Protocol) servers in Claude Code. Use when users need to connect Claude Code to external tools, databases, APIs, or services through MCP integration."
                },
                "content": "# Claude Code MCP Configuration\n\nGuide Claude through configuring and managing MCP (Model Context Protocol) servers to connect Claude Code with external tools, databases, and services.\n\n## Purpose\n\nMCP servers enable Claude Code to interact with external tools and data sources through a standardized protocol. This skill helps install, configure, and manage MCP servers across different scopes (local, project, user), authenticate with remote services, and troubleshoot connection issues.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Installing MCP servers (HTTP, SSE, or stdio transport)\n- Configuring MCP server authentication and environment variables\n- Managing MCP server scopes (local, project, user)\n- Troubleshooting MCP server connectivity or authentication issues\n- Setting up team-wide MCP server configurations\n- Importing MCP servers from Claude Desktop\n- Using MCP resources and prompts in conversations\n\n**Do NOT use this skill for:**\n\n- Creating or building MCP servers (use MCP SDK documentation instead)\n- Writing MCP server code (this skill is for configuration only)\n\n## MCP Server Transports\n\nMCP servers can connect using three transport mechanisms:\n\n### HTTP Transport (Recommended)\n\nBest for cloud-based services with REST APIs.\n\n**Basic syntax:**\n\n```bash\nclaude mcp add --transport http <name> <url>\n```\n\n**Examples:**\n\n```bash\n# Simple HTTP server\nclaude mcp add --transport http notion https://mcp.notion.com/mcp\n\n# With authentication header\nclaude mcp add --transport http secure-api https://api.example.com/mcp \\\n  --header \"Authorization: Bearer your-token\"\n\n# With custom headers\nclaude mcp add --transport http custom-api https://api.example.com/mcp \\\n  --header \"X-API-Key: key123\" \\\n  --header \"X-Custom-Header: value\"\n```\n\n### SSE Transport (Deprecated)\n\nServer-Sent Events transport. Use HTTP where available.\n\n**Basic syntax:**\n\n```bash\nclaude mcp add --transport sse <name> <url>\n```\n\n**Example:**\n\n```bash\nclaude mcp add --transport sse asana https://mcp.asana.com/sse\n```\n\n### Stdio Transport\n\nFor local processes needing direct system access.\n\n**Basic syntax:**\n\n```bash\nclaude mcp add --transport stdio <name> [--env KEY=value] -- <command> [args...]\n```\n\n**Examples:**\n\n```bash\n# NPM package\nclaude mcp add --transport stdio airtable \\\n  --env AIRTABLE_API_KEY=YOUR_KEY \\\n  -- npx -y airtable-mcp-server\n\n# Local script\nclaude mcp add --transport stdio custom-tool \\\n  --env CONFIG_PATH=/path/to/config \\\n  -- /usr/local/bin/custom-mcp-server\n\n# Python package\nclaude mcp add --transport stdio python-tool \\\n  -- python -m my_mcp_server\n```\n\n**Important:** Use `--` to separate Claude CLI flags from MCP server command/arguments.\n\n## MCP Server Scopes\n\nMCP servers can be configured at three different scopes:\n\n### Local Scope (Default)\n\n- **Location:** Project `.mcp.json` (gitignored)\n- **Visibility:** Current project only\n- **Use case:** Private configurations, testing, local development\n- **Command:** `claude mcp add --scope local` (or omit `--scope`)\n\n### Project Scope\n\n- **Location:** Project `.mcp.json` (committed to git)\n- **Visibility:** All team members using the project\n- **Use case:** Team-shared integrations, required tooling\n- **Command:** `claude mcp add --scope project`\n\n### User Scope\n\n- **Location:** `~/.claude/mcp.json`\n- **Visibility:** All projects for current user\n- **Use case:** Personal tools, cross-project services\n- **Command:** `claude mcp add --scope user`\n\n**Scope precedence:** Local > Project > User\n\nWhen the same server name exists in multiple scopes, the highest precedence wins.\n\n## MCP Configuration Workflow\n\nTo configure an MCP server, follow this process:\n\n### Step 1: Identify Requirements\n\nDetermine what information is needed:\n\n1. **Transport type** - HTTP, SSE, or stdio?\n2. **Server URL or command** - Where is the server?\n3. **Authentication** - API keys, OAuth, headers?\n4. **Environment variables** - Configuration needed?\n5. **Scope** - Local, project, or user?\n\nExample questions to ask:\n\n- \"What service are you connecting to?\"\n- \"Do you have an API key or authentication token?\"\n- \"Should this be available to your whole team (project scope) or just you (local/user scope)?\"\n- \"Is this a cloud service (HTTP) or local tool (stdio)?\"\n\n### Step 2: Determine Transport and Scope\n\nBased on the requirements:\n\n**Choose HTTP when:**\n\n- Connecting to cloud-based REST APIs\n- Service provides an MCP endpoint URL\n- No local process needed\n\n**Choose stdio when:**\n\n- Running local tools or scripts\n- Need direct system access\n- Using NPM packages or local executables\n\n**Choose SSE when:**\n\n- Service only supports SSE transport\n- HTTP is not available (prefer HTTP if both exist)\n\n**Choose scope based on:**\n\n- **Local:** Testing, temporary, contains secrets not in env vars\n- **Project:** Team needs access, shared configuration\n- **User:** Personal tool across all projects\n\n### Step 3: Install the MCP Server\n\nUse the appropriate `claude mcp add` command based on transport and scope.\n\n**HTTP example:**\n\n```bash\nclaude mcp add --transport http --scope project \\\n  notion https://mcp.notion.com/mcp\n```\n\n**Stdio example:**\n\n```bash\nclaude mcp add --transport stdio --scope user \\\n  airtable \\\n  --env AIRTABLE_API_KEY=${AIRTABLE_API_KEY} \\\n  -- npx -y airtable-mcp-server\n```\n\n**With multiple environment variables:**\n\n```bash\nclaude mcp add --transport stdio --scope project \\\n  custom-db \\\n  --env DB_HOST=${DB_HOST} \\\n  --env DB_PORT=${DB_PORT:-5432} \\\n  --env DB_NAME=analytics \\\n  -- /usr/local/bin/db-mcp-server\n```\n\n### Step 4: Verify Installation\n\nAfter installation:\n\n1. **List servers:**\n\n   ```bash\n   claude mcp list\n   ```\n\n2. **Get server details:**\n\n   ```bash\n   claude mcp get <server-name>\n   ```\n\n3. **Test in Claude Code:**\n   - Start Claude Code\n   - Ask the user to run `/mcp` to see server status\n   - Try using a tool from the server\n\n### Step 5: Authenticate (if required)\n\nSome servers require OAuth or additional authentication:\n\n1. **Start Claude Code**\n2. **Run `/mcp` command**\n3. **Select the server requiring authentication**\n4. **Follow browser authentication flow**\n5. **Verify authentication succeeded in `/mcp` menu**\n\nTokens are securely stored and auto-refreshed. Clear with \"Clear authentication\" from `/mcp` menu.\n\n### Step 6: Troubleshoot if Needed\n\nIf the server isn't working:\n\n**Check server status:**\n\n```bash\nclaude mcp list\n```\n\n**Get detailed information:**\n\n```bash\nclaude mcp get <server-name>\n```\n\n**Common issues:**\n\n1. **Server not starting (stdio)**\n   - Verify command is executable: `which npx`, `which python`\n   - Check environment variables are set\n   - Test command independently\n   - On Windows, use `cmd /c` wrapper: `-- cmd /c npx -y package`\n\n2. **Authentication failures (HTTP/SSE)**\n   - Verify API keys are correct\n   - Check headers are properly formatted\n   - Use `/mcp` to re-authenticate OAuth servers\n   - Verify URL is correct and accessible\n\n3. **Server timeout**\n   - Increase timeout: `MCP_TIMEOUT=10000 claude`\n   - Check network connectivity\n   - Verify server is responding\n\n4. **Output limit warnings**\n   - Increase output limit: `export MAX_MCP_OUTPUT_TOKENS=50000`\n   - Default is 25,000 tokens\n   - Warning at 10,000 tokens\n\nFor additional details on popular MCP servers and their specific configurations, consult the [official MCP documentation](https://docs.claude.com/en/docs/claude-code/mcp).\n\n## Common MCP Server Patterns\n\n### Cloud Service with API Key (HTTP)\n\n```bash\nclaude mcp add --transport http --scope user \\\n  service-name https://api.service.com/mcp \\\n  --header \"Authorization: Bearer ${API_KEY}\"\n```\n\n### Local NPM Package (stdio)\n\n```bash\nclaude mcp add --transport stdio --scope user \\\n  package-name \\\n  --env API_KEY=${API_KEY} \\\n  -- npx -y @org/mcp-package\n```\n\n### Team Database Access (stdio, project scope)\n\n```bash\nclaude mcp add --transport stdio --scope project \\\n  analytics-db \\\n  --env DB_URL=${ANALYTICS_DB_URL} \\\n  -- npx -y @bytebase/dbhub\n```\n\n### Personal Tool Across Projects (stdio, user scope)\n\n```bash\nclaude mcp add --transport stdio --scope user \\\n  my-tool \\\n  -- /usr/local/bin/my-mcp-tool\n```\n\n## Environment Variable Handling\n\nMCP configurations support environment variable expansion:\n\n**Syntax:**\n\n- `${VAR}` - Required variable (error if not set)\n- `${VAR:-default}` - Optional with default value\n\n**Examples:**\n\n```bash\n# Required variable\n--env DB_HOST=${DB_HOST}\n\n# Optional with default\n--env DB_PORT=${DB_PORT:-5432}\n\n# Literal value\n--env ENVIRONMENT=production\n\n# Multiple variables\n--env API_URL=${API_URL} \\\n--env API_KEY=${API_KEY} \\\n--env TIMEOUT=${TIMEOUT:-30}\n```\n\n**Setting environment variables:**\n\n```bash\n# In shell (temporary)\nexport API_KEY=your-key-here\nclaude mcp add --transport stdio tool --env API_KEY=${API_KEY} -- npx tool\n\n# In .env file (project)\necho \"API_KEY=your-key-here\" >> .env\nsource .env\nclaude mcp add ...\n\n# In shell profile (permanent)\necho 'export API_KEY=your-key-here' >> ~/.zshrc\nsource ~/.zshrc\n```\n\n## Managing MCP Servers\n\n### List All Servers\n\n```bash\nclaude mcp list\n```\n\nShows all configured servers across all scopes with status.\n\n### Get Server Details\n\n```bash\nclaude mcp get <server-name>\n```\n\nShows configuration, scope, transport type, and status.\n\n### Remove a Server\n\n```bash\nclaude mcp remove <server-name>\n```\n\nRemoves from the scope where it was added.\n\n### Check Status in Claude Code\n\nWithin Claude Code, use `/mcp` command to:\n\n- View all connected servers\n- See authentication status\n- Re-authenticate OAuth servers\n- Clear authentication tokens\n\n## Using MCP Tools in Conversations\n\nOnce servers are connected:\n\n### Access MCP Tools\n\nClaude Code automatically sees MCP tools. Just ask:\n\n```\n> \"Check Sentry for errors in the last 24 hours\"\n> \"Create a GitHub issue for this bug\"\n> \"Query the database for user count\"\n```\n\n### Use MCP Resources\n\nType `@` to list available resources:\n\n```\n> \"Analyze @github:issue://123\"\n> \"Review @notion:page://abc123\"\n```\n\nResources are auto-fetched and attached to context.\n\n### Use MCP Prompts as Slash Commands\n\nMCP prompts appear as slash commands:\n\n```\n/mcp__github__list_prs\n/mcp__github__pr_review 456\n/mcp__jira__create_issue \"Bug in login\" high\n```\n\n## Plugin-Provided MCP Servers\n\nPlugins can bundle MCP servers that start automatically:\n\n**Plugin configuration (`.mcp.json` in plugin root):**\n\n```json\n{\n  \"database-tools\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/db-server\",\n    \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"],\n    \"env\": {\n      \"DB_URL\": \"${DB_URL}\"\n    }\n  }\n}\n```\n\n**Key points:**\n\n- Managed via plugin install/uninstall, not `/mcp` commands\n- Use `${CLAUDE_PLUGIN_ROOT}` for plugin-relative paths\n- Start automatically when plugin is enabled\n- Appear in `/mcp` menu but managed by plugin\n\n## Team Configuration Best Practices\n\nFor team-wide MCP server setup:\n\n### Project Scope Configuration\n\n1. **Use project scope for shared integrations:**\n\n   ```bash\n   claude mcp add --scope project \\\n     github https://api.githubcopilot.com/mcp/\n   ```\n\n2. **Commit `.mcp.json` to repository**\n3. **Document required environment variables in README:**\n\n   ```markdown\n   ## Required Environment Variables\n   - `GITHUB_TOKEN` - GitHub personal access token\n   - `JIRA_API_KEY` - Jira API key\n   ```\n\n4. **Team members set environment variables locally:**\n\n   ```bash\n   export GITHUB_TOKEN=ghp_xxxx\n   export JIRA_API_KEY=xxxx\n   ```\n\n### Environment Variable Management\n\n**For sensitive values:**\n\n- Never commit actual secrets to `.mcp.json`\n- Use `${VAR}` expansion\n- Document required variables\n- Use `.env` files (gitignored) for local values\n\n**For non-sensitive values:**\n\n- Can specify directly in configuration\n- Example: `--env ENVIRONMENT=production`\n\n## Importing from Claude Desktop\n\nImport existing MCP servers from Claude Desktop:\n\n```bash\nclaude mcp add-from-claude-desktop\n```\n\nInteractively select which servers to import. Configurations are copied to appropriate scope.\n\n## Advanced: JSON Configuration\n\nAdd servers via JSON for programmatic setup:\n\n```bash\n# HTTP server\nclaude mcp add-json weather-api '{\n  \"type\": \"http\",\n  \"url\": \"https://api.weather.com/mcp\",\n  \"headers\": {\n    \"Authorization\": \"Bearer token\"\n  }\n}'\n\n# Stdio server\nclaude mcp add-json db-tool '{\n  \"type\": \"stdio\",\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"@tool/mcp\"],\n  \"env\": {\n    \"DB_URL\": \"${DB_URL}\"\n  }\n}'\n```\n\n## Additional Resources\n\nFor additional information about MCP:\n\n- **Popular MCP Servers**: Browse the [MCP servers repository](https://github.com/modelcontextprotocol/servers) for community-maintained servers\n- **Building MCP Servers**: See the [MCP SDK documentation](https://modelcontextprotocol.io/quickstart/server) to create your own servers\n- **Official Documentation**: Consult the [Claude Code MCP guide](https://docs.claude.com/en/docs/claude-code/mcp) for complete reference documentation\n\n## Troubleshooting\n\n### Server Not Appearing\n\n**Symptoms:** Server added but not visible in `/mcp`\n\n**Solutions:**\n\n- Restart Claude Code after adding server\n- Verify server was added: `claude mcp list`\n- Check correct scope: `claude mcp get <name>`\n- For stdio: verify command is executable\n\n### Authentication Failures\n\n**Symptoms:** OAuth flow fails or API returns 401/403\n\n**Solutions:**\n\n- Use `/mcp` to re-authenticate\n- Verify API key is correct\n- Check header format: `\"Authorization: Bearer token\"`\n- Clear and re-authenticate: `/mcp` → Clear authentication\n\n### Command Not Found (stdio)\n\n**Symptoms:** \"command not found\" for stdio servers\n\n**Solutions:**\n\n- Verify command exists: `which npx`, `which python`\n- Use full path: `-- /usr/local/bin/tool`\n- On Windows: use `-- cmd /c npx -y package`\n- Check PATH environment variable\n\n### Environment Variable Not Expanded\n\n**Symptoms:** `${VAR}` appears literally in configuration\n\n**Solutions:**\n\n- Verify variable is exported: `echo $VAR`\n- Set before running command: `export VAR=value`\n- Use shell substitution if needed: `--env VAR=$VAR` (expanded by shell)\n\n### Server Timeout\n\n**Symptoms:** Server connection times out\n\n**Solutions:**\n\n- Increase timeout: `MCP_TIMEOUT=10000 claude`\n- Check network connectivity\n- Verify server URL is correct\n- For stdio: check command starts quickly\n\n## Integration with Other Skills\n\nThis skill works alongside other claude-code-meta skills:\n\n- **Use `claude-code-plugins`** - For bundling MCP servers in plugins\n\nActivate these skills when working on plugin-provided MCP servers or automated MCP configuration workflows."
              },
              {
                "name": "claude-code-plugins",
                "description": "This skill should be used when creating, configuring, or distributing Claude Code plugins and marketplaces. Use when users ask about the plugin system architecture, how to package multiple components together, create marketplaces, or set up team-wide plugin distribution.",
                "path": "plugins/claude-code-meta/skills/claude-code-plugins/SKILL.md",
                "frontmatter": {
                  "name": "claude-code-plugins",
                  "description": "This skill should be used when creating, configuring, or distributing Claude Code plugins and marketplaces. Use when users ask about the plugin system architecture, how to package multiple components together, create marketplaces, or set up team-wide plugin distribution."
                },
                "content": "# Claude Code Plugins\n\nGuide Claude through creating, configuring, and distributing complete Claude Code plugins and marketplaces.\n\n## Purpose\n\nPlugins are packages that bundle multiple Claude Code extensions (commands, agents, skills, hooks, MCP servers) for distribution. This skill helps understand the plugin architecture, create well-structured plugins, set up marketplaces, and configure team-wide plugin distribution.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Creating a new plugin that bundles multiple components together\n- Setting up plugin marketplaces for team or community distribution\n- Configuring team-wide automatic plugin installation\n- Understanding how plugins, commands, agents, skills, hooks, and MCP servers relate\n- Deciding between creating individual components vs packaging them as plugins\n- Troubleshooting plugin structure or distribution issues\n\n**Do NOT use this skill for:**\n\n- Creating individual slash commands - use `claude-code-slash-commands` skill instead\n- Creating individual subagents - use `claude-code-subagents` skill instead\n- Creating individual hooks - use `claude-code-hooks` skill instead\n- Creating individual skills - use `skill-creator` skill instead\n\n## Plugin System Architecture\n\nClaude Code's extensibility system has two levels:\n\n### Individual Components (Project/User Level)\n\nComponents can be installed directly in projects or user directories:\n\n- **Commands** - `.claude/commands/` or `~/.claude/commands/`\n- **Agents** - `.claude/agents/` or `~/.claude/agents/`\n- **Hooks** - `.claude/settings.json` or `~/.claude/settings.json`\n- **Skills** - Activated via plugin marketplaces only\n\n### Plugins (Distribution Level)\n\nPlugins bundle multiple components for distribution:\n\n```\nmy-plugin/\n├── .claude-plugin/\n│   └── plugin.json          # Plugin metadata (required)\n├── commands/                 # Slash commands (optional)\n│   └── deploy.md\n├── agents/                   # Subagents (optional)\n│   └── reviewer.md\n├── skills/                   # Agent Skills (optional)\n│   └── code-quality/\n│       └── SKILL.md\n├── hooks/                    # Event handlers (optional)\n│   └── hooks.json\n└── .mcp.json                 # MCP servers (optional)\n```\n\n## When to Create Plugins vs Individual Components\n\n### Use Individual Components When:\n\n- Creating one-off customizations for a single project\n- Testing new workflows before wider distribution\n- Building personal preferences not shared with others\n- Components are independent and don't require coordination\n\n### Use Plugins When:\n\n- Bundling related components that work together\n- Distributing tools across multiple projects or teams\n- Versioning and updating components as a unit\n- Providing Skills (Skills require plugin distribution)\n- Creating reusable workflows for community sharing\n\n## Plugin Creation Process\n\nTo create a plugin, follow this process in order:\n\n### Step 1: Understanding Plugin Requirements\n\nSkip this step only when the plugin's purpose and components are already clearly defined.\n\nTo create an effective plugin, clearly understand what components the plugin should include and how they work together. This understanding can come from existing workflows that need packaging or new requirements.\n\nFor example, when building a deployment automation plugin, relevant considerations include:\n\n- \"What commands do users need? Deploy, rollback, status checks?\"\n- \"Should there be a specialized deployment agent?\"\n- \"What hooks are needed? Pre-deploy validation, post-deploy notifications?\"\n- \"Are there external tools to integrate via MCP?\"\n- \"Should this include Skills for automatic deployment analysis?\"\n\nFor a code quality plugin:\n\n- \"What formatting/linting commands are needed?\"\n- \"Should there be a code review agent?\"\n- \"What hooks trigger on file changes?\"\n- \"Should Skills provide automatic code analysis?\"\n\nConclude this step when there is a clear sense of:\n1. What components the plugin needs\n2. How components interact with each other\n3. Who will use the plugin (project team, organization, community)\n\n### Step 2: Planning Component Organization\n\nTo turn requirements into an effective plugin, analyze the use case by:\n\n1. Identifying which component types are needed (commands, agents, skills, hooks, MCP)\n2. Determining how components should be organized\n3. Deciding on plugin scope and distribution strategy\n\nExample: For a deployment automation plugin, the analysis shows:\n\n1. **Commands** - `/deploy`, `/rollback`, `/deploy-status`\n2. **Agent** - `deployment-manager` for handling complex deployments\n3. **Hooks** - PreToolUse validation for deployment commands\n4. **Skills** - `deployment-analysis` for automatic deployment planning\n5. **Distribution** - Organization-wide via private marketplace\n\nExample: For a code quality plugin, the analysis shows:\n\n1. **Commands** - `/format`, `/lint`, `/review-code`\n2. **Agent** - `code-reviewer` for comprehensive reviews\n3. **Hooks** - PostToolUse formatting after file edits\n4. **Skills** - `code-quality-checker` for automatic analysis\n5. **Distribution** - Open source via GitHub marketplace\n\nReview the component-specific skills for detailed guidance:\n- [references/plugins-guide.md](references/plugins-guide.md) for complete plugin documentation\n- `claude-code-slash-commands` skill for command creation\n- `claude-code-subagents` skill for agent creation\n- `claude-code-hooks` skill for hook creation\n- `skill-creator` skill for Skills creation\n\n### Step 3: Creating Plugin Structure\n\nAt this point, create the basic plugin structure:\n\n1. **Create plugin directory** - Choose a descriptive kebab-case name:\n   ```bash\n   mkdir my-plugin\n   cd my-plugin\n   ```\n\n2. **Create plugin manifest** - Required `.claude-plugin/plugin.json`:\n   ```bash\n   mkdir .claude-plugin\n   cat > .claude-plugin/plugin.json << 'EOF'\n   {\n     \"name\": \"my-plugin\",\n     \"version\": \"1.0.0\",\n     \"description\": \"Brief plugin description\",\n     \"author\": {\n       \"name\": \"Your Name\",\n       \"email\": \"your.email@example.com\"\n     },\n     \"license\": \"MIT\"\n   }\n   EOF\n   ```\n\n   **Important:** This plugin.json should contain ONLY basic metadata (name, version, description, author, license). Do NOT include component specifications like `skills`, `commands`, `agents`, etc. here - those belong in the marketplace.json to avoid manifest conflicts.\n\n3. **Create component directories** - Only create directories for components you'll include:\n   ```bash\n   mkdir -p commands    # If including commands\n   mkdir -p agents      # If including agents\n   mkdir -p skills      # If including Skills\n   mkdir -p hooks       # If including hooks\n   mkdir -p scripts     # If including helper scripts\n   ```\n\n4. **Add documentation** - Create README.md explaining the plugin:\n   ```bash\n   cat > README.md << 'EOF'\n   # My Plugin\n\n   Brief description of what this plugin does.\n\n   ## Components\n\n   - Commands: List commands provided\n   - Agents: List agents provided\n   - Skills: List Skills provided\n   - Hooks: Describe automation provided\n\n   ## Installation\n\n   ```\n   /plugin marketplace add owner/repo\n   /plugin install my-plugin@marketplace-name\n   ```\n   EOF\n   ```\n\n### Step 4: Implementing Plugin Components\n\nWhen implementing the plugin, create components using their respective creation processes:\n\n#### For Commands\n\nUse the `claude-code-slash-commands` skill and creation script:\n\n```bash\n# From plugin root\n./path/to/scripts/create_slash_command.sh command-name --plugin\n```\n\nOr activate `claude-code-slash-commands` skill for guidance.\n\n#### For Agents\n\nUse the `claude-code-subagents` skill and creation script:\n\n```bash\n# From plugin root\n./path/to/scripts/create_subagent.sh agent-name --plugin\n```\n\nOr activate `claude-code-subagents` skill for guidance.\n\n#### For Skills\n\nUse the `skill-creator` skill and follow the Agent Skills specification:\n\n```bash\n# From plugin root, create skill directory\nmkdir -p skills/my-skill\n```\n\nThen activate `skill-creator` skill for full guidance on writing SKILL.md.\n\n#### For Hooks\n\nUse the `claude-code-hooks` skill for guidance. Create `hooks/hooks.json`:\n\n```json\n{\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/scripts/format.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n#### For MCP Servers\n\nCreate `.mcp.json` at plugin root:\n\n```json\n{\n  \"mcpServers\": {\n    \"plugin-server\": {\n      \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/server\",\n      \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"]\n    }\n  }\n}\n```\n\n**Writing Style:** Focus on how components work together. Ensure commands, agents, and Skills reference each other appropriately. Use `${CLAUDE_PLUGIN_ROOT}` for all plugin-relative paths.\n\n### Step 5: Setting Up Distribution\n\nOnce the plugin components are implemented, set up distribution:\n\n#### Option A: Local Testing Marketplace\n\nFor development and testing:\n\n1. **Create marketplace directory** - Parallel to plugin:\n   ```bash\n   cd ..\n   mkdir -p dev-marketplace/.claude-plugin\n   ```\n\n2. **Create marketplace manifest**:\n   ```bash\n   cat > dev-marketplace/.claude-plugin/marketplace.json << 'EOF'\n   {\n     \"name\": \"dev-marketplace\",\n     \"owner\": {\n       \"name\": \"Developer\"\n     },\n     \"plugins\": [\n       {\n         \"name\": \"my-plugin\",\n         \"source\": \"./my-plugin\",\n         \"description\": \"Plugin under development\",\n         \"version\": \"1.0.0\",\n         \"strict\": true,\n         \"skills\": [\n           \"./skills/my-skill\"\n         ]\n       }\n     ]\n   }\n   EOF\n   ```\n\n   **Note:** Always set `\"strict\": true` and specify components (skills, commands, agents, etc.) in the marketplace.json, not in the individual plugin.json files.\n\n3. **Test installation**:\n   ```bash\n   claude\n   # In Claude Code:\n   /plugin marketplace add ./dev-marketplace\n   /plugin install my-plugin@dev-marketplace\n   ```\n\n#### Option B: GitHub Marketplace\n\nFor team or community distribution:\n\n1. **Create repository** - Create GitHub repository for plugins\n2. **Organize structure**:\n   ```\n   my-plugins-repo/\n   ├── .claude-plugin/\n   │   └── marketplace.json\n   └── plugins/\n       ├── plugin-one/\n       └── plugin-two/\n   ```\n\n3. **Create marketplace manifest**:\n   ```json\n   {\n     \"name\": \"my-marketplace\",\n     \"owner\": {\n       \"name\": \"Team Name\",\n       \"email\": \"team@example.com\"\n     },\n     \"plugins\": [\n       {\n         \"name\": \"plugin-one\",\n         \"source\": \"./plugins/plugin-one\",\n         \"description\": \"First plugin description\",\n         \"version\": \"1.0.0\",\n         \"author\": {\n           \"name\": \"Team Name\"\n         },\n         \"license\": \"MIT\",\n         \"strict\": true,\n         \"skills\": [\n           \"./skills/my-skill\"\n         ]\n       },\n       {\n         \"name\": \"plugin-two\",\n         \"source\": \"./plugins/plugin-two\",\n         \"description\": \"Second plugin description\",\n         \"version\": \"1.0.0\",\n         \"author\": {\n           \"name\": \"Team Name\"\n         },\n         \"license\": \"MIT\",\n         \"strict\": true,\n         \"commands\": [\n           \"./commands/my-command.md\"\n         ]\n       }\n     ]\n   }\n   ```\n\n   **Important:** Set `\"strict\": true` in each plugin entry. This tells Claude Code to use component specifications from the marketplace.json and ignore any component specs in individual plugin.json files, avoiding manifest conflicts.\n\n4. **Distribute**:\n   ```\n   /plugin marketplace add owner/repo\n   /plugin install plugin-one@my-marketplace\n   ```\n\nFor complete marketplace setup, see [references/plugin-marketplaces-guide.md](references/plugin-marketplaces-guide.md).\n\n### Step 6: Configuring Team Installation\n\nFor automatic team-wide plugin installation, configure project-level settings:\n\n1. **Create or edit** `.claude/settings.json` in project repository:\n   ```json\n   {\n     \"extraKnownMarketplaces\": {\n       \"team-tools\": {\n         \"source\": {\n           \"source\": \"github\",\n           \"repo\": \"company/claude-plugins\"\n         }\n       }\n     },\n     \"enabledPlugins\": {\n       \"deployment-tools@team-tools\": true,\n       \"code-quality@team-tools\": true\n     }\n   }\n   ```\n\n2. **Commit to repository** - Team members who trust the folder will automatically:\n   - Add configured marketplaces\n   - Install enabled plugins\n   - Receive plugin updates\n\n3. **Document for team** - Add installation instructions to project README.\n\n### Step 7: Testing and Iteration\n\nOnce the plugin is distributed, test thoroughly:\n\n#### Test Component Integration\n\n- **Test commands**: Run each command and verify it works\n- **Test agents**: Invoke agents automatically and explicitly\n- **Test Skills**: Trigger Skills and verify they're invoked correctly\n- **Test hooks**: Trigger events and verify hooks execute\n- **Test MCP servers**: Verify external tools are accessible\n\n#### Test Component Interaction\n\n- Verify commands can reference agents (e.g., \"Use the X agent to deploy\")\n- Verify Skills can recommend commands to users\n- Verify hooks work with plugin scripts using `${CLAUDE_PLUGIN_ROOT}`\n- Verify agents have appropriate tool access\n\n#### Test Distribution\n\n- Install from marketplace on clean Claude Code instance\n- Verify all components are loaded correctly\n- Test on different operating systems if applicable\n- Verify team installation works for project-level configuration\n\n**Iteration workflow:**\n\n1. **Use the plugin** on real tasks with real users\n2. **Notice issues** - Missing components? Integration problems? Unclear usage?\n3. **Identify improvements** - Should components be added/removed? Better organization?\n4. **Update plugin** - Modify components, bump version\n5. **Test changes** - Uninstall and reinstall to verify updates work\n6. **Document changes** - Update CHANGELOG.md and README.md\n\n## Plugin vs Individual Component Decision Tree\n\nUse this decision tree to determine the right approach:\n\n**Question 1: Are you creating multiple related components?**\n- Yes → Continue to Question 2\n- No → Create individual component in `.claude/` or `~/.claude/`\n\n**Question 2: Will these components be shared across projects or with others?**\n- Yes → Create plugin\n- No → Create individual components in project `.claude/` directory\n\n**Question 3: Do you need to include Skills?**\n- Yes → Create plugin (Skills require plugin distribution)\n- No → Continue to Question 4\n\n**Question 4: Do you need version control and updates for components as a unit?**\n- Yes → Create plugin\n- No → Create individual components\n\n## Common Plugin Patterns\n\n### Code Quality Plugin\n\n**Components:**\n- Commands: `/format`, `/lint`, `/review`\n- Agent: `code-reviewer`\n- Hooks: PostToolUse formatting\n- Skills: `code-quality-checker`\n\n**Use case:** Enforce code standards across team projects\n\n### Deployment Plugin\n\n**Components:**\n- Commands: `/deploy`, `/rollback`, `/status`\n- Agent: `deployment-manager`\n- Hooks: PreToolUse deployment validation\n- MCP: Deployment API integration\n\n**Use case:** Streamline deployment workflows\n\n### Documentation Plugin\n\n**Components:**\n- Commands: `/docs`, `/api-docs`, `/changelog`\n- Agent: `documentation-writer`\n- Skills: `doc-generator`\n\n**Use case:** Automate documentation generation\n\n### Testing Plugin\n\n**Components:**\n- Commands: `/test`, `/coverage`, `/benchmark`\n- Agent: `test-runner`\n- Hooks: PreToolUse test validation\n- Skills: `test-analyzer`\n\n**Use case:** Comprehensive testing workflows\n\n## Reference Documentation\n\nFor detailed information, refer to:\n\n- [references/plugins-guide.md](references/plugins-guide.md) - Complete plugin guide from docs\n- [references/plugin-marketplaces-guide.md](references/plugin-marketplaces-guide.md) - Marketplace creation and distribution\n- [references/plugins-reference.md](references/plugins-reference.md) - Technical specifications and schemas\n\nLoad these references when users need detailed technical information beyond the workflow guidance in this skill.\n\n## Best Practices\n\n### Plugin Design\n\n- **Single responsibility** - Each plugin should have a clear, focused purpose\n- **Component cohesion** - Bundle components that work together, not unrelated tools\n- **Clear naming** - Use descriptive kebab-case names that indicate purpose\n- **Complete documentation** - Include README.md with installation and usage instructions\n- **Semantic versioning** - Use semver for version management\n\n### Component Organization\n\n- **Logical grouping** - Organize related commands/agents/Skills together\n- **Consistent naming** - Use consistent naming patterns across components\n- **Clear references** - Have components reference each other (e.g., Skills mention commands)\n- **Appropriate tool access** - Grant agents only necessary tools\n\n### Distribution Strategy\n\n- **Local testing first** - Test with local marketplace before GitHub distribution\n- **Version control** - Commit plugin to git repository\n- **Changelog maintenance** - Document changes in CHANGELOG.md\n- **License clarity** - Include LICENSE file and license field in plugin.json\n- **Community engagement** - For public plugins, provide issue tracking and contribution guidelines\n\n### Team Adoption\n\n- **Project-level config** - Use `.claude/settings.json` for automatic installation\n- **Documentation** - Provide clear setup instructions for team members\n- **Training** - Help team members discover and use plugin features\n- **Feedback loops** - Gather team feedback and iterate\n\n## Troubleshooting\n\n### Plugin Not Loading\n\n**Symptoms:** Plugin installed but components not available\n\n**Solutions:**\n- Verify `.claude-plugin/plugin.json` exists and has valid JSON\n- Ensure component directories are at plugin root, not inside `.claude-plugin/`\n- Check that plugin is enabled: `/plugin` → Manage Plugins\n- Try uninstall and reinstall: `/plugin uninstall` then `/plugin install`\n\n### Components Not Found\n\n**Symptoms:** Plugin loads but specific components missing\n\n**Solutions:**\n- Verify component files exist in correct directories (`commands/`, `agents/`, etc.)\n- Check component file format (markdown for commands/agents, JSON for hooks)\n- For commands: Verify frontmatter and markdown structure\n- For agents: Verify frontmatter exists\n- For Skills: Verify SKILL.md exists with proper frontmatter\n\n### Hooks Not Executing\n\n**Symptoms:** Hooks configured but not firing\n\n**Solutions:**\n- Verify `hooks/hooks.json` has valid JSON syntax\n- Check hook scripts are executable: `chmod +x script.sh`\n- Use `${CLAUDE_PLUGIN_ROOT}` for plugin-relative paths\n- Test hook script independently with sample input\n- Run `claude --debug` to see hook execution details\n\n### MCP Servers Not Starting\n\n**Symptoms:** MCP servers configured but not accessible\n\n**Solutions:**\n- Verify `.mcp.json` has valid JSON syntax\n- Check MCP server command is accessible\n- Use `${CLAUDE_PLUGIN_ROOT}` for plugin-relative paths\n- Test MCP server independently\n- Check environment variables are set correctly\n\n## Integration with Other Skills\n\nThis skill works alongside other claude-code-meta skills:\n\n- **Use `claude-code-slash-commands`** - For creating individual commands within plugins\n- **Use `claude-code-subagents`** - For creating individual agents within plugins\n- **Use `claude-code-hooks`** - For creating hook configurations within plugins\n- **Use `skill-creator`** - For creating Skills within plugins\n\nActivate these skills when deep-diving into specific component creation while building plugins."
              },
              {
                "name": "claude-code-skills",
                "description": "Guide for creating effective Agent Skills in Claude Code. This skill should be used when users want to create a new Skill (or update an existing Skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations. Use when working specifically with Claude Code's Skills system.",
                "path": "plugins/claude-code-meta/skills/claude-code-skills/SKILL.md",
                "frontmatter": {
                  "name": "claude-code-skills",
                  "description": "Guide for creating effective Agent Skills in Claude Code. This skill should be used when users want to create a new Skill (or update an existing Skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations. Use when working specifically with Claude Code's Skills system.",
                  "license": "Complete terms in LICENSE.txt (Apache 2.0)"
                },
                "content": "# Claude Code Skills Creator\n\nThis skill provides comprehensive guidance for creating effective Agent Skills in Claude Code, including plugin integration.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks—they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n├── SKILL.md (required)\n│   ├── YAML frontmatter metadata (required)\n│   │   ├── name: (required)\n│   │   └── description: (required)\n│   └── Markdown instructions (required)\n└── Bundled Resources (optional)\n    ├── scripts/          - Executable code (Python/Bash/etc.)\n    ├── references/       - Documentation intended to be loaded into context as needed\n    └── assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n**Claude Code-specific frontmatter fields:**\n\n- `allowed-tools` (optional, Claude Code only): Comma-separated list of tools Claude can use when this skill is active. Restricts tool access for security or to keep the skill focused. See [references/allowed-tools-guide.md](references/allowed-tools-guide.md) for comprehensive guidance.\n\nExample frontmatter with `allowed-tools`:\n\n```yaml\n---\nname: safe-file-reader\ndescription: Read files without making changes. Use when you need read-only file access.\nallowed-tools: Read, Grep, Glob\n---\n```\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Claude Code Skills Integration\n\nSkills in Claude Code work within a rich ecosystem of extensibility features. Understanding how Skills relate to other components helps you choose the right tool for each task and build cohesive workflows.\n\n### How Skills Fit in the Claude Code Ecosystem\n\nClaude Code provides four main extensibility mechanisms:\n\n1. **Skills** - Specialized knowledge and workflows (this guide)\n2. **Slash Commands** - User-invoked prompts (e.g., `/deploy`, `/review`)\n3. **Subagents** - Specialized AI personalities with custom system prompts\n4. **Hooks** - Event-driven automation scripts\n\n### The allowed-tools Field in Claude Code\n\nClaude Code supports an `allowed-tools` frontmatter field that restricts which tools Claude can use when a skill is active.\n\n**Why use allowed-tools:**\n\n1. **Security** - Prevent Skills from making unintended modifications\n2. **Focus** - Keep Skills constrained to their specific purpose\n3. **User experience** - Avoid permission prompts for pre-approved tools\n\n**Common patterns:**\n\n```yaml\n# Read-only skill\nallowed-tools: Read, Grep, Glob\n\n# File operations skill\nallowed-tools: Read, Write, Edit, Glob\n\n# Code execution skill\nallowed-tools: Read, Write, Bash\n\n# Web research skill\nallowed-tools: Read, WebFetch, WebSearch\n```\n\nSee [references/allowed-tools-guide.md](references/allowed-tools-guide.md) for comprehensive guidance on tool permissions.\n\n### Distribution in Claude Code\n\nClaude Code Skills can be distributed in two ways:\n\n**1. Plugin-bundled Skills** (Recommended for most use cases)\n\n- Skills included in a Claude Code plugin\n- Distributed via plugin marketplaces\n- Can reference other plugin components (commands, agents, hooks)\n- Automatic updates when plugin updates\n\n**2. Standalone Skills**\n\n- Self-contained skill directories\n- Simpler for single-purpose, independent skills\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\n#### For Standalone Skills\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\n#### For Plugin-Bundled Skills (Claude Code)\n\n```bash\nscripts/init_skill.py <skill-name> --plugin --path <plugin-directory>\n```\n\nThe `--plugin` flag:\n\n- Creates the skill in the plugin's `skills/` directory\n- Adds a reminder to register the skill in `.claude-plugin/marketplace.json`\n- Optimizes the template for plugin distribution\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n- For plugin skills, includes guidance on `allowed-tools` and marketplace registration\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n**Plugin-bundled skills require an additional step:** Register the skill in your plugin's marketplace configuration (see Step 5 below).\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\nTo complete SKILL.md, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used?\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n### Step 5: Distribution in Claude Code\n\nOnce the skill is ready, distribute it via Claude Code's plugin marketplace system or as a standalone skill.\n\n#### Validating the Skill\n\nBefore distribution, validate the skill to ensure it meets all requirements:\n\n```bash\nscripts/validate_skill.py <path/to/skill-folder>\n```\n\nThe validation script checks:\n\n- YAML frontmatter format and required fields\n- Skill naming conventions and directory structure\n- Description completeness and quality\n- File organization and resource references\n- `allowed-tools` field syntax (Claude Code only)\n\nIf validation fails, fix the reported errors and run the validation command again.\n\n#### Option A: Plugin-Bundled Distribution (Recommended)\n\nFor skills distributed as part of a plugin:\n\n1. **Register in marketplace.json**:\n\n   Open your plugin's `.claude-plugin/marketplace.json` and add the skill:\n\n   ```json\n   {\n     \"plugins\": [\n       {\n         \"name\": \"my-plugin\",\n         \"skills\": [\n           \"./skills/my-skill\"\n         ]\n       }\n     ]\n   }\n   ```\n\n2. **Test locally**:\n\n   ```\n   /plugin marketplace add ./path/to/plugin\n   /plugin install my-plugin@local-marketplace\n   ```\n\n3. **Distribute via git**:\n\n   Commit the plugin (including the skill) to your git repository. Team members can install via:\n\n   ```\n   /plugin marketplace add owner/repo\n   /plugin install my-plugin@marketplace-name\n   ```\n\n#### Option B: Standalone Distribution\n\nFor independent skills not part of a larger plugin:\n\n1. **Create a minimal marketplace** for the skill\n2. **Distribute via git repository**\n3. Users install with `/plugin marketplace add` and `/plugin install`\n\n#### Option C: Zip File Distribution\n\nFor non-Claude Code environments (claude.ai, API), skills can be packaged as zip files:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nThe packaging script validates the skill and creates a distributable zip file. This method is an alternative to marketplace distribution and is commonly used for claude.ai and API deployments.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again"
              },
              {
                "name": "claude-code-slash-commands",
                "description": "This skill should be used when creating, configuring, or working with Claude Code slash commands. Use when users ask to create custom slash commands, set up command features like arguments or bash execution, or need guidance on slash command structure and best practices.",
                "path": "plugins/claude-code-meta/skills/claude-code-slash-commands/SKILL.md",
                "frontmatter": {
                  "name": "claude-code-slash-commands",
                  "description": "This skill should be used when creating, configuring, or working with Claude Code slash commands. Use when users ask to create custom slash commands, set up command features like arguments or bash execution, or need guidance on slash command structure and best practices."
                },
                "content": "# Claude Code Slash Commands\n\nGuide Claude through creating and configuring custom slash commands for Claude Code.\n\n## Purpose\n\nSlash commands let users define frequently-used prompts as Markdown files that Claude can execute on demand. This skill helps create well-structured slash commands with proper frontmatter, arguments, bash execution, and other advanced features.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Creating new custom slash commands (project or personal)\n- Adding arguments, bash execution, or file references to commands\n- Configuring frontmatter options (allowed-tools, model, argument-hint, etc.)\n- Troubleshooting slash command issues\n\n## Command Types\n\n### Project Commands\n\n- Stored at: `.claude/commands/`\n- Shared with the team (versioned in git)\n- Shown as `(project)` in `/help`\n\n### Personal Commands\n\n- Stored at: `~/.claude/commands/`\n- Available across all projects\n- Shown as `(user)` in `/help`\n\n### Plugin Commands\n\n- Stored at: `commands/` in plugin root\n- Distributed via plugin marketplaces\n- Shown as `(plugin:plugin-name)` in `/help`\n- Invoked with `/plugin-name:command-name` or just `/command-name`\n- Support all features (arguments, frontmatter, bash, file references)\n\n## Creating Slash Commands\n\n### Quick Creation with Helper Script\n\nUse the bundled creation script for fast, templated command setup:\n\n```bash\n# Create project command with basic template\nscripts/create_slash_command.sh my-command --project\n\n# Create personal command with advanced template\nscripts/create_slash_command.sh my-command --user --template advanced\n\n# Create plugin command (auto-detects plugin from current directory)\nscripts/create_slash_command.sh my-command --plugin\n\n# Create plugin command for specific plugin\nscripts/create_slash_command.sh my-command --plugin my-plugin-name\n\n# Available templates: basic, arguments, bash, advanced\n```\n\nThe script is located at: `scripts/create_slash_command.sh`\n\n**Plugin command creation:**\n\n- Use `--plugin` to create commands in a plugin's `commands/` directory\n- Auto-detects plugin when run from within a plugin directory\n- Or specify plugin name: `--plugin my-plugin-name`\n- Reminds you to register the command in `marketplace.json`\n\n### Manual Creation\n\nWhen creating commands manually, follow this structure:\n\n1. **Choose scope** - Decide between:\n   - Project: `.claude/commands/`\n   - Personal: `~/.claude/commands/`\n   - Plugin: `plugins/<plugin-name>/commands/`\n\n2. **Create directory** - Ensure the target directory exists:\n\n   ```bash\n   mkdir -p .claude/commands            # Project\n   mkdir -p ~/.claude/commands          # Personal\n   mkdir -p plugins/my-plugin/commands  # Plugin\n   ```\n\n3. **Create file** - Named `command-name.md` (the filename becomes the command)\n\n4. **Add frontmatter** - Include at minimum a `description` field\n\n5. **Write instructions** - Clear, actionable prompts for Claude\n\n6. **Register plugin commands** - If creating a plugin command:\n   - Open `.claude-plugin/marketplace.json`\n   - Find the plugin's entry in the `plugins` array\n   - Add `\"./commands/command-name.md\"` to the plugin's `commands` array\n\n## Available Templates\n\nFour templates are provided in `assets/` for common use cases:\n\n### Basic Template (`template-basic.md`)\n\nMinimal slash command with just description and instructions.\n\n**Use when:** Creating simple, straightforward prompts.\n\n### Arguments Template (`template-with-arguments.md`)\n\nShows how to use `$ARGUMENTS`, `$1`, `$2`, etc. for parameterized commands.\n\n**Use when:** Commands need user-provided input or parameters.\n\n### Bash Template (`template-with-bash.md`)\n\nDemonstrates bash command execution with the \\`!\\` prefix for gathering context.\n\n**Use when:** Commands need git status, file listings, or other system context.\n\n### Advanced Template (`template-advanced.md`)\n\nFull-featured template with all frontmatter options, bash execution, arguments, and file references.\n\n**Use when:** Building complex workflows or need multiple features.\n\n## Frontmatter Options\n\nAll available frontmatter fields:\n\n```yaml\n---\ndescription: Brief description shown in /help\nargument-hint: [arg1] [arg2]\nallowed-tools: Bash(git:*), Read, Write, Edit\nmodel: claude-sonnet-4-5-20250929\ndisable-model-invocation: false\n---\n```\n\n### Field Details\n\n- **description** (required) - Brief description of what the command does\n- **argument-hint** - Shown in autocomplete, helps users know what arguments to provide\n- **allowed-tools** - Pre-approved tools the command can use (bypasses permission prompts)\n- **model** - Specific model to use for this command (overrides conversation model)\n- **disable-model-invocation** - Prevents SlashCommand tool from executing this command\n\n## Advanced Features\n\n### Arguments\n\nTwo ways to handle arguments:\n\n**1. Capture all as string:**\n\n```markdown\nFix issue #$ARGUMENTS following our coding standards\n```\n\nUsage: `/fix-issue 123 high-priority` → `$ARGUMENTS = \"123 high-priority\"`\n\n**2. Individual positional arguments:**\n\n```markdown\nReview PR #$1 with priority $2 and assign to $3\n```\n\nUsage: `/review-pr 456 high alice` → `$1=\"456\"`, `$2=\"high\"`, `$3=\"alice\"`\n\n### Bash Command Execution\n\nExecute bash commands inline to gather context:\n\n```markdown\n---\nallowed-tools: Bash(git status:*), Bash(git diff:*)\n---\n\n## Context\n- Current status: \\`!\\` `git status`\n- Current diff: \\`!\\` `git diff HEAD`\n```\n\n**Important:** Commands prefixed with \\`!\\` run before the slash command is processed. Results are injected into the prompt.\n\n### File References\n\nReference files using \\`@\\` prefix:\n\n```markdown\nReview the implementation in \\@src/utils/helpers.js\nCompare \\@old-file.js with \\@new-file.js\n```\n\n### Extended Thinking Mode\n\nTrigger extended thinking by including keywords:\n\n- \"think carefully\"\n- \"analyze thoroughly\"\n- \"consider all implications\"\n\n## Workflow\n\nWhen creating a new slash command:\n\n1. **Understand requirements** - Ask user about:\n   - Command purpose and when it should be used\n   - Whether arguments are needed\n   - What context (bash, files) should be gathered\n   - Scope (project, personal, or plugin)\n\n2. **Choose template** - Select the most appropriate template:\n   - Basic for simple prompts\n   - Arguments for parameterized commands\n   - Bash for context-gathering commands\n   - Advanced for complex workflows\n\n3. **Use creation script or manual approach**:\n   - Project: `scripts/create_slash_command.sh <name> --project --template <type>`\n   - Personal: `scripts/create_slash_command.sh <name> --user --template <type>`\n   - Plugin: `scripts/create_slash_command.sh <name> --plugin [plugin-name] --template <type>`\n   - Manual: Create file in appropriate directory\n\n4. **Customize content**:\n   - Update frontmatter (especially description)\n   - Write clear, actionable instructions\n   - Add success criteria if applicable\n   - Configure allowed-tools if using bash\n\n5. **Register plugin commands** (plugin scope only):\n   - Add command to `.claude-plugin/marketplace.json`\n   - In the plugin's entry, add `\"./commands/<command-name>.md\"` to the `commands` array\n   - The script will remind you of this step\n\n6. **Test and iterate**:\n   - Project/personal: Run with `/command-name`\n   - Plugin: Run with `/plugin-name:command-name`\n   - Verify it works as expected\n   - Adjust based on results\n\n## Reference Documentation\n\nFor detailed information about slash commands, refer to `references/slash-commands-reference.md`, which contains:\n\n- Complete frontmatter field reference\n- Permission rules and SlashCommand tool details\n- MCP slash command integration\n- Plugin command structure\n- Skills vs slash commands comparison\n\nLoad this reference when users need detailed technical information beyond the workflow guidance in this skill.\n\n## Best Practices\n\n- **Keep it focused** - One command, one clear purpose\n- **Use descriptive names** - Command names should indicate what they do\n- **Document arguments** - Include argument-hint in frontmatter\n- **Specify allowed-tools** - Pre-approve tools to avoid permission prompts\n- **Test thoroughly** - Verify commands work before committing to project or publishing plugin\n- **Consider scope** - Project for team workflows, personal for individual preferences, plugin for reusable/distributable commands\n- **Register plugin commands** - Always update marketplace.json when creating plugin commands\n\n## Skills vs Slash Commands\n\nHelp users choose between creating a skill or a slash command:\n\n**Use Slash Commands when:**\n\n- Single file is sufficient\n- Simple, repeatable prompts\n- Manual invocation desired\n- Quick setup needed\n\n**Use Skills when:**\n\n- Multiple files/scripts needed\n- Complex workflows required\n- Automatic triggering desired\n- Bundled resources beneficial\n\nBoth can coexist; recommend the approach that best fits the use case."
              },
              {
                "name": "claude-code-subagents",
                "description": "This skill should be used when creating, configuring, or working with Claude Code subagents. Use when users ask to create custom subagents, set up subagent configurations, manage tool permissions, or need guidance on subagent architecture and best practices.",
                "path": "plugins/claude-code-meta/skills/claude-code-subagents/SKILL.md",
                "frontmatter": {
                  "name": "claude-code-subagents",
                  "description": "This skill should be used when creating, configuring, or working with Claude Code subagents. Use when users ask to create custom subagents, set up subagent configurations, manage tool permissions, or need guidance on subagent architecture and best practices."
                },
                "content": "# Claude Code Subagents\n\nGuide Claude through creating and configuring specialized subagents for Claude Code.\n\n## Purpose\n\nSubagents are pre-configured AI personalities that handle specific types of tasks with their own context windows, custom system prompts, and tool configurations. This skill helps create well-structured subagents that improve task delegation, context management, and specialized workflows.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Creating new custom subagents (project, personal, or plugin)\n- Configuring subagent properties (tools, model, system prompts)\n- Setting up specialized workflows with subagent delegation\n- Troubleshooting subagent invocation or behavior\n\n## Subagent Types\n\n### Project Subagents\n\n- Stored at: `.claude/agents/`\n- Shared with the team (versioned in git)\n- Highest priority when name conflicts occur\n- Team-specific workflows and conventions\n\n### Personal Subagents\n\n- Stored at: `~/.claude/agents/`\n- Available across all projects\n- Lower priority than project subagents\n- Personal preferences and workflows\n\n### Plugin Subagents\n\n- Stored at: `agents/` in plugin root\n- Distributed via plugin marketplaces\n- Shown as `(plugin:plugin-name)` in `/agents`\n- Support all configuration features\n- Can be invoked explicitly or automatically\n\n## Creating Subagents\n\n### Quick Creation with Helper Script\n\nUse the bundled creation script for fast, templated subagent setup:\n\n```bash\n# Create project subagent with code-reviewer template\nscripts/create_subagent.sh code-reviewer --project --template code-reviewer\n\n# Create personal subagent with custom template\nscripts/create_subagent.sh my-agent --user --template debugger\n\n# Create plugin subagent (auto-detects plugin from current directory)\nscripts/create_subagent.sh my-agent --plugin\n\n# Create plugin subagent for specific plugin\nscripts/create_subagent.sh my-agent --plugin my-plugin-name\n\n# Available templates: code-reviewer, debugger, custom\n```\n\nThe script is located at: `scripts/create_subagent.sh`\n\n**Plugin subagent creation:**\n\n- Use `--plugin` to create subagents in a plugin's `agents/` directory\n- Auto-detects plugin when run from within a plugin directory\n- Or specify plugin name: `--plugin my-plugin-name`\n- Reminds you to register the subagent in `marketplace.json`\n\n### Using the /agents Command\n\nThe `/agents` command provides an interactive interface:\n\n- View all subagents (built-in, user, project, plugin)\n- Create new subagents with guided setup\n- Generate subagents with Claude's assistance\n- Edit custom subagents including tool access\n- Delete custom subagents\n- See which subagents are active when duplicates exist\n- Manage tool permissions easily\n\n**Recommended workflow:**\n\n1. Run `/agents`\n2. Select 'Create New Agent'\n3. Choose scope (project/user)\n4. Let Claude generate the subagent based on your description\n5. Press `e` to edit the system prompt in your editor\n6. Customize as needed\n\n### Manual Creation\n\nWhen creating subagents manually, follow this structure:\n\n1. **Choose scope** - Decide between:\n   - Project: `.claude/agents/`\n   - Personal: `~/.claude/agents/`\n   - Plugin: `plugins/<plugin-name>/agents/`\n\n2. **Create directory** - Ensure the target directory exists:\n\n   ```bash\n   mkdir -p .claude/agents            # Project\n   mkdir -p ~/.claude/agents          # Personal\n   mkdir -p plugins/my-plugin/agents  # Plugin\n   ```\n\n3. **Create file** - Named `agent-name.md` (the filename becomes the agent name)\n\n4. **Add frontmatter** - Include required fields:\n\n   ```yaml\n   ---\n   name: agent-name\n   description: Description of when this subagent should be invoked\n   tools: Read, Write, Edit, Bash(git:*)  # Optional; inherits all if omitted\n   model: sonnet                          # Optional; sonnet/opus/haiku/inherit\n   ---\n   ```\n\n5. **Write system prompt** - Clear, detailed instructions defining the subagent's role, capabilities, and approach\n\n6. **Register plugin subagents** - If creating a plugin subagent:\n   - Open `.claude-plugin/marketplace.json`\n   - Find the plugin's entry in the `plugins` array\n   - Add `\"./agents/agent-name.md\"` to the plugin's `agents` array\n\n## Available Templates\n\nThree templates are provided in `assets/` for common use cases:\n\n### Code Reviewer (`code-reviewer.md`)\n\nSenior code reviewer focused on quality, security, and maintainability.\n\n**Use when:** Need automated code review after changes.\n\n**Features:**\n\n- Proactive invocation after code modifications\n- Comprehensive review checklist\n- Priority-based feedback organization\n- Security vulnerability detection\n\n### Debugger (`debugger.md`)\n\nExpert debugger for root cause analysis and issue resolution.\n\n**Use when:** Encountering errors, test failures, or unexpected behavior.\n\n**Features:**\n\n- Systematic debugging process\n- Hypothesis formation and testing\n- Strategic logging recommendations\n- Root cause identification\n\n### Custom Template (`custom.md`)\n\nBlank template for building specialized subagents.\n\n**Use when:** Need a starting point for unique workflows.\n\n## Configuration Reference\n\n### Frontmatter Fields\n\nAll available frontmatter fields:\n\n```yaml\n---\nname: agent-name                    # Required: lowercase, hyphens only\ndescription: When to invoke agent   # Required: specific, action-oriented\ntools: Read, Write, Bash(git:*)    # Optional: comma-separated list\nmodel: sonnet                      # Optional: sonnet/opus/haiku/inherit\n---\n```\n\n### Field Details\n\n- **name** (required) - Unique identifier (lowercase, alphanumeric + hyphens)\n- **description** (required) - Natural language description of when the subagent should be invoked\n- **tools** (optional) - Comma-separated list of allowed tools; inherits all if omitted\n- **model** (optional) - Model to use: `sonnet`, `opus`, `haiku`, or `inherit` (matches conversation model)\n\n### Tool Configuration\n\nSubagents can use Claude Code's internal tools. Examples:\n\n```yaml\n# Inherit all tools (including MCP tools)\n# Omit the tools field entirely\n\n# Specific tools only\ntools: Read, Write, Edit, Grep, Glob\n\n# Bash with patterns\ntools: Bash(git:*), Bash(npm:*), Read\n\n# Limited toolset for security\ntools: Read, Grep\n```\n\nSee full tool list in references documentation.\n\n## Workflow\n\nWhen creating a new subagent:\n\n1. **Understand requirements** - Ask user about:\n   - Subagent purpose and specialization\n   - When it should be invoked (automatic vs explicit)\n   - What tools it needs access to\n   - Scope (project, personal, or plugin)\n\n2. **Choose template** - Select the most appropriate template:\n   - Code-reviewer for code quality checks\n   - Debugger for troubleshooting workflows\n   - Custom for unique specialized needs\n\n3. **Use creation method**:\n   - **Recommended**: `/agents` command for guided setup\n   - **Script**: `scripts/create_subagent.sh <name> --<scope> --template <type>`\n   - **Manual**: Create file in appropriate directory\n\n4. **Customize configuration**:\n   - Update frontmatter (especially description)\n   - Configure tool access if needed\n   - Select appropriate model\n   - Write clear, detailed system prompt\n\n5. **Write effective system prompt**:\n   - Define the subagent's role and expertise\n   - Specify the workflow or process to follow\n   - Include success criteria and best practices\n   - Add examples if helpful\n   - Use imperative/infinitive form (verb-first)\n\n6. **Register plugin subagents** (plugin scope only):\n   - Add subagent to `.claude-plugin/marketplace.json`\n   - In the plugin's entry, add `\"./agents/<agent-name>.md\"` to the `agents` array\n   - The script will remind you of this step\n\n7. **Test and iterate**:\n   - Test automatic invocation with matching tasks\n   - Test explicit invocation: \"Use the X subagent to...\"\n   - Verify tool access works as expected\n   - Adjust description for better delegation\n   - Refine system prompt based on results\n\n## Invocation Patterns\n\n### Automatic Delegation\n\nClaude Code automatically delegates based on:\n\n- Task description matching subagent `description`\n- Context and available tools\n- Current conversation needs\n\n**Tips for better automatic delegation:**\n\n- Use proactive language in description: \"Use PROACTIVELY when...\", \"MUST BE USED for...\"\n- Be specific about trigger conditions\n- Include keywords users are likely to use\n\n### Explicit Invocation\n\nUsers can request subagents directly:\n\n```\n> Use the code-reviewer subagent to check my recent changes\n> Have the debugger subagent investigate this error\n> Ask the data-scientist subagent to analyze user growth\n```\n\n### Chaining Subagents\n\nFor complex workflows:\n\n```\n> First use the code-analyzer subagent to find issues, then use the optimizer subagent to fix them\n```\n\n## Reference Documentation\n\nFor detailed information about subagents, refer to `references/subagents-reference.md`, which contains:\n\n- Complete subagent architecture details\n- File format specification\n- Tool permission system\n- Model selection guide\n- Performance considerations\n- Advanced usage patterns\n- CLI-based subagent configuration\n\nLoad this reference when users need detailed technical information beyond the workflow guidance in this skill.\n\n## Best Practices\n\n- **Focus on single responsibility** - Each subagent should have a clear, specific purpose\n- **Write detailed system prompts** - Include role, process, examples, and constraints\n- **Use proactive descriptions** - Help Claude know when to delegate automatically\n- **Limit tool access appropriately** - Grant only necessary tools for security and focus\n- **Test both invocation types** - Verify automatic and explicit invocation work\n- **Consider context efficiency** - Subagents help preserve main context for longer sessions\n- **Version control project subagents** - Share team workflows via git\n- **Document expected behavior** - Include examples in system prompt when helpful\napproach that best fits the use case. Subagents and skills can work together—skills can include instructions for when to delegate to specific subagents."
              }
            ]
          },
          {
            "name": "mermaid-diagram-to-image",
            "description": "Convert Mermaid diagrams to images (PNG, SVG, PDF) using mermaid-cli.",
            "source": "./plugins/mermaid-diagram-to-image",
            "category": "development-tools",
            "version": "1.0.1",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/claude-code-plugins",
              "/plugin install mermaid-diagram-to-image@emdashcodes-claude-code-plugins"
            ],
            "signals": {
              "stars": 4,
              "forks": 1,
              "pushed_at": "2026-01-08T19:24:31Z",
              "created_at": "2025-10-18T01:20:32Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "mermaid-diagram-to-image",
                "description": "Convert Mermaid diagrams to images (PNG, SVG, PDF) using mermaid-cli. This skill should be used when Claude generates Mermaid diagram syntax and wants to create a visual representation for the user, or when converting existing Mermaid diagrams to image formats.",
                "path": "plugins/mermaid-diagram-to-image/skills/mermaid-diagram-to-image/SKILL.md",
                "frontmatter": {
                  "name": "mermaid-diagram-to-image",
                  "description": "Convert Mermaid diagrams to images (PNG, SVG, PDF) using mermaid-cli. This skill should be used when Claude generates Mermaid diagram syntax and wants to create a visual representation for the user, or when converting existing Mermaid diagrams to image formats."
                },
                "content": "# Mermaid Diagram to Image\n\nConvert Mermaid diagrams to high-quality images in PNG, SVG, or PDF formats using the mermaid-cli tool.\n\n## When to Use This Skill\n\nActivate this skill when:\n\n- Generating Mermaid diagram syntax and wanting to provide a visual representation to the user\n- Converting existing Mermaid diagrams (from files or discussion context) to image formats\n- User requests diagram visualization in a specific format (PNG for embedding, SVG for web, PDF for print)\n\n## Quick Start\n\nTo convert a Mermaid diagram to an image:\n\n1. **Identify the source** - Determine if working with diagram content, a file path, or inline Mermaid syntax\n2. **Create temporary file if needed** - Use `mktemp -t mermaid-XXXXXX.mmd` for inline content\n3. **Run conversion** - Execute mmdc with appropriate flags (input, output, dimensions, theme)\n4. **Clean up** - Use `rm -f /path/to/temp.mmd` to remove temporary file\n5. **Report results** - Confirm successful conversion with output filename\n\n## Conversion Workflow\n\n### Step 1: Parse Input\n\nDetermine the source of the Mermaid diagram:\n\n- **Diagram content in context** - Mermaid syntax recently generated or discussed\n- **File path** - User provides a path to a `.mmd` or `.md` file\n- **Inline Mermaid content** - Raw Mermaid syntax provided by user\n- **Format preferences** - User specifies output format (PNG, SVG, PDF) and options\n\n### Step 2: Set Up Variables\n\nEstablish conversion parameters with sensible defaults:\n\n**Output Format**\n\n- Default: `png`\n- Options: `png`, `svg`, `pdf`\n\n**Output Filename**\n\n- Default pattern: `mermaid-diagram-{SHORT_DESCRIPTIVE_NAME}`\n- Example: `mermaid-diagram-flowchart.png`, `mermaid-diagram-sequence.svg`\n- Base name on diagram type or content context\n\n**Default Image Settings (High Resolution)**\n\n- Width: `1600` pixels\n- Height: `1200` pixels\n- Scale: `2` (for crisp rendering)\n\n**Optional Parameters**\n\n- Theme: `default`, `forest`, `dark`, `neutral`\n- Background color: hex code or named color (e.g., `transparent`, `white`, `#f0f0f0`)\n- PDF fit: `-f` flag for PDF output\n\n### Step 3: Handle Input\n\n**If file path provided:**\n\n- Verify file exists using Read or Glob tools\n- Confirm file extension is `.mmd` or `.md`\n- Use file path directly in mmdc command\n\n**If Mermaid content provided:**\n\n- Create temporary file: `TEMP_FILE=$(mktemp -t mermaid-XXXXXX.mmd)`\n- Write diagram content to file using heredoc or echo\n- Store temp file path for cleanup after conversion\n\nExample:\n\n```bash\nTEMP_FILE=$(mktemp -t mermaid-XXXXXX.mmd)\ncat > \"$TEMP_FILE\" << 'EOF'\ngraph TD\n    A[Start] --> B[Process]\n    B --> C[End]\nEOF\n```\n\n### Step 4: Construct mmdc Command\n\nBuild the mermaid-cli command with appropriate flags:\n\n**Required Flags**\n\n- `-i <input-file>` - Input file (temp file or user-provided file)\n- `-o <output-file>` - Output file with appropriate extension\n\n**High Resolution Flags**\n\n- `-w 1600` - Width in pixels (default for quality output)\n- `-H 1200` - Height in pixels (default for quality output)\n- `-s 2` - Scale factor (2x for high resolution)\n\n**Optional Flags**\n\n- `-t <theme>` - Theme selection (`default`, `forest`, `dark`, `neutral`)\n- `-b <color>` - Background color (hex or named)\n- `-f` - Fit to page (PDF output only)\n\n**Example Commands**\n\nPNG conversion (default):\n\n```bash\nmmdc -i diagram.mmd -o output.png -w 1600 -H 1200 -s 2\n```\n\nSVG with dark theme:\n\n```bash\nmmdc -i diagram.mmd -o output.svg -t dark -b transparent\n```\n\nPDF with fit:\n\n```bash\nmmdc -i diagram.mmd -o output.pdf -f -w 1600 -H 1200\n```\n\n### Step 5: Execute and Clean Up\n\n**Execution**\n\n1. Run the constructed mmdc command using Bash tool\n2. Capture output and error messages\n3. Check exit code for success\n\n**Cleanup** (if temporary file created)\n\n1. Remove temporary file: `rm -f \"$TEMP_FILE\"`\n2. Verify file is in temp directory (e.g., `/tmp/` or `/var/folders/`) before deletion\n3. Use `-f` flag to avoid errors if file doesn't exist\n\n**Verification**\n\n1. Confirm output file was created\n2. Report success with output filename and location\n3. If applicable, note image specifications (format, dimensions)\n\n### Step 6: Report Results\n\nProvide clear feedback to user:\n\n**Success Message Template**\n\n```\nSuccessfully converted Mermaid diagram to {format}.\nOutput: {filename}\nDimensions: {width}x{height}\nTheme: {theme}\n```\n\n**Error Handling**\n\n- If mmdc fails, report error message from stderr\n- Common issues: invalid Mermaid syntax, missing dependencies, file permissions\n- Suggest fixes: validate syntax, check mmdc installation, verify write permissions\n\n## Default Settings\n\nApply these defaults for high-quality output:\n\n- **Format:** PNG\n- **Width:** 1600 pixels\n- **Height:** 1200 pixels\n- **Scale:** 2 (for crisp rendering)\n- **Theme:** default\n- **Filename pattern:** `mermaid-diagram-{descriptive-name}`\n\nOverride defaults based on user requirements or diagram characteristics.\n\n## Common Scenarios\n\n**Scenario 1: Generate and visualize**\n\n1. Generate Mermaid diagram syntax based on user request\n2. Create temporary file using `mktemp -t mermaid-XXXXXX.mmd`\n3. Write diagram content to temporary file\n4. Convert to PNG with default high-resolution settings\n5. Present image to user\n6. Clean up temporary file with `rm -f`\n\n**Scenario 2: Convert existing file**\n\n1. User provides file path to `.mmd` or `.md` file\n2. Verify file exists and read content\n3. Convert directly using file path\n4. Output image file in same directory or user-specified location\n\n**Scenario 3: Custom format and styling**\n\n1. User requests SVG with dark theme and transparent background\n2. Parse requirements\n3. Construct mmdc command with theme and background flags\n4. Execute conversion\n5. Confirm output meets specifications\n\n## Theme Options\n\nAvailable themes for customization:\n\n- `default` - Standard blue/gray Mermaid theme\n- `forest` - Green-themed palette\n- `dark` - Dark background with light text\n- `neutral` - Neutral gray tones\n\nApply theme with `-t` flag: `mmdc -i input.mmd -o output.png -t dark`\n\n## Mermaid Syntax Recognition\n\nRecognize Mermaid diagrams by these starting keywords:\n\n- `graph` or `flowchart` - Flowchart diagrams\n- `sequenceDiagram` - Sequence diagrams\n- `classDiagram` - Class diagrams\n- `stateDiagram` - State diagrams\n- `erDiagram` - Entity relationship diagrams\n- `gantt` - Gantt charts\n- `pie` - Pie charts\n- `journey` - User journey diagrams\n- `gitGraph` - Git graphs\n- `mindmap` - Mind maps\n- `timeline` - Timeline diagrams\n\n## Troubleshooting\n\n**mmdc command not found:**\n\n- Verify mermaid-cli is installed: `npm list -g @mermaid-js/mermaid-cli`\n- Install if missing: `npm install -g @mermaid-js/mermaid-cli`\n\n**Syntax errors in diagram:**\n\n- Validate Mermaid syntax at <https://mermaid.live>\n- Check for missing spaces, invalid keywords, or malformed connections\n- Review Mermaid documentation for diagram-specific syntax\n\n**Output file not created:**\n\n- Verify write permissions in output directory\n- Check disk space availability\n- Ensure output path is valid\n\n**Image quality issues:**\n\n- Increase width/height for larger diagrams\n- Adjust scale factor (try 3 for extra high resolution)\n- Use SVG format for lossless scaling\n\n## Best Practices\n\n1. **Proactive conversion** - When generating Mermaid diagrams, automatically convert to images for better user experience\n2. **Format selection** - Choose PNG for general use, SVG for web/scaling needs, PDF for documents\n3. **High resolution** - Use default high-resolution settings (1600x1200, scale 2) for quality output\n4. **Descriptive naming** - Name output files based on diagram type or content for easy identification\n5. **Cleanup** - Always clean up temporary files after successful conversion\n6. **Error reporting** - Provide clear error messages with actionable troubleshooting steps"
              }
            ]
          },
          {
            "name": "google-docs-reader",
            "description": "Read and analyze Google Docs, Sheets, and Slides by exporting them to local formats (DOCX, XLSX, PPTX) via browser download.",
            "source": "./plugins/google-docs-reader",
            "category": "productivity",
            "version": "1.0.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/claude-code-plugins",
              "/plugin install google-docs-reader@emdashcodes-claude-code-plugins"
            ],
            "signals": {
              "stars": 4,
              "forks": 1,
              "pushed_at": "2026-01-08T19:24:31Z",
              "created_at": "2025-10-18T01:20:32Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "google-docs-reader",
                "description": "Read and analyze Google Docs, Sheets, and Slides by exporting them to local formats (DOCX, XLSX, PPTX) via browser download. Use this skill when users request to read, summarize, or analyze content from Google Drive URLs or .gdoc/.gsheet/.gslides files.",
                "path": "plugins/google-docs-reader/skills/google-docs-reader/SKILL.md",
                "frontmatter": {
                  "name": "google-docs-reader",
                  "description": "Read and analyze Google Docs, Sheets, and Slides by exporting them to local formats (DOCX, XLSX, PPTX) via browser download. Use this skill when users request to read, summarize, or analyze content from Google Drive URLs or .gdoc/.gsheet/.gslides files."
                },
                "content": "# Google Docs Reader\n\n## Overview\n\nRead and analyze Google Workspace documents (Docs, Sheets, Slides) without direct API access. This skill exports Google Drive documents to local formats by opening export URLs in the browser, monitoring the Downloads folder, and moving files to a temporary directory for processing.\n\n## When to Use This Skill\n\nActivate this skill when users ask to:\n\n- Read or summarize Google Docs, Sheets, or Slides\n- Extract content from Google Drive URLs\n- Analyze `.gdoc`, `.gsheet`, or `.gslides` files from Google Drive File Stream/Desktop\n- Process multiple Google Workspace documents\n\n**Example user requests:**\n\n- \"Read this Google Doc and summarize it: <https://docs.google.com/document/d/ABC123/edit>\"\n- \"What's in this spreadsheet?\" (pointing to a `.gsheet` file)\n- \"Analyze the data in this Google Sheets URL\"\n- \"Convert this Google Slides to markdown\"\n\n## How It Works\n\nThe skill uses a browser-based export workflow:\n\n1. **Extract document ID** from URL or `.gdoc`/`.gsheet`/`.gslides` file\n2. **Determine document type** (Docs, Sheets, or Slides)\n3. **Build export URL** with appropriate format (DOCX, XLSX, PPTX)\n4. **Open URL in browser** (leverages existing Google account session)\n5. **Monitor Downloads folder** for the downloaded file\n6. **Move to temp directory** (`/tmp/gdoc_exports/`)\n7. **Process with document skills** (docx, xlsx, pptx skills)\n8. **Clean up** temporary file after reading\n\n## Export Formats\n\n- **Google Docs** → DOCX (Microsoft Word format)\n- **Google Sheets** → XLSX (Microsoft Excel format)\n- **Google Slides** → PPTX (Microsoft PowerPoint format)\n\n## Reading Google Docs\n\n### Complete Workflow (Export + Read)\n\nThe simplest approach is to use both scripts together:\n\n```bash\n# 1. Export the Google Doc\nEXPORTED=$(python3 ${CLAUDE_PLUGIN_ROOT}/skills/google-docs-reader/scripts/export_gdoc.py \"<google-drive-url-or-file>\")\n\n# 2. Read the exported file\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/google-docs-reader/scripts/read_exported_doc.py \"$EXPORTED\"\n```\n\n### Step-by-Step Workflow\n\n#### Step 1: Export\n\nRun the export script with your Google Docs URL or file:\n\n```bash\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/google-docs-reader/scripts/export_gdoc.py <input>\n```\n\nWhere `<input>` can be:\n\n- Google Drive URL (e.g., `https://docs.google.com/document/d/ABC123/edit`)\n- Path to `.gdoc`, `.gsheet`, or `.gslides` file\n- Raw document ID (assumes Google Docs type)\n\nThe script will:\n\n- Open the export URL in the default browser\n- Wait up to 30 seconds for download to complete\n- Move file to `/tmp/gdoc_exports/{DOC_ID}.{extension}`\n- Print the output file path\n\n#### Step 2: Read\n\nRead the exported file using the integrated reading script:\n\n```bash\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/google-docs-reader/scripts/read_exported_doc.py <exported-file>\n```\n\nThis automatically uses the appropriate tool based on file type:\n\n- **DOCX** → pandoc (markdown conversion)\n- **XLSX** → pandas (data analysis with preview, statistics)\n- **PPTX** → pandoc (text/markdown extraction)\n\n### Example Usage\n\n**Reading a Google Doc:**\n\n```bash\n# Export\npython3 scripts/export_gdoc.py \"https://docs.google.com/document/d/1abc.../edit\"\n# Output: /tmp/gdoc_exports/1abc...docx\n\n# Read as markdown\npython3 scripts/read_exported_doc.py /tmp/gdoc_exports/1abc...docx\n```\n\n**Reading a Google Sheet:**\n\n```bash\n# Export\npython3 scripts/export_gdoc.py \"https://docs.google.com/spreadsheets/d/1xyz.../edit\"\n# Output: /tmp/gdoc_exports/1xyz...xlsx\n\n# Read with data analysis\npython3 scripts/read_exported_doc.py /tmp/gdoc_exports/1xyz...xlsx\n# Shows: sheet names, dimensions, columns, preview, statistics\n```\n\n**Reading a Google Slides:**\n\n```bash\n# Export\npython3 scripts/export_gdoc.py \"https://docs.google.com/presentation/d/1def.../edit\"\n# Output: /tmp/gdoc_exports/1def...pptx\n\n# Read as markdown\npython3 scripts/read_exported_doc.py /tmp/gdoc_exports/1def...pptx\n```\n\n### Script Options\n\n```bash\npython3 scripts/export_gdoc.py <input> [options]\n\nOptions:\n  -o, --output-dir DIR    Output directory (default: /tmp/gdoc_exports)\n  -t, --timeout SECONDS   Download timeout (default: 30)\n  -h, --help              Show help message\n```\n\n## Processing Exported Files\n\nAfter export, use the appropriate tool to read content:\n\n### Google Docs (DOCX)\n\n- **Activate docx skill** if available\n- **Use pandoc** for markdown conversion: `pandoc file.docx -t markdown`\n- **Read directly** with document processing tools\n\n### Google Sheets (XLSX)\n\n- **Activate xlsx skill** if available for data analysis\n- **Use pandas** for programmatic access\n- **Convert to CSV** for simple text processing\n\n### Google Slides (PPTX)\n\n- **Activate pptx skill** if available\n- **Use pandoc** for text extraction: `pandoc file.pptx -t markdown`\n- **Extract speaker notes** with PowerPoint libraries\n\n## Authentication Requirements\n\n**Important:** This skill requires the user to be logged into Google in their default browser. The browser-based export method uses existing session cookies, avoiding the need for API credentials or OAuth flows.\n\nIf exports fail with authentication errors, ask the user to:\n\n1. Open the browser and log into the Google account\n2. Verify the account has access to the document\n3. Try the export again\n\n## Cleanup\n\nExported files are stored in `/tmp/gdoc_exports/` by default. This directory can be cleaned up manually or automatically:\n\n```bash\n# Remove all exported files\nrm -rf /tmp/gdoc_exports/\n\n# Remove specific file after processing\nrm /tmp/gdoc_exports/{DOC_ID}.docx\n```\n\n## Troubleshooting\n\n### Download timeout\n\nIf downloads take longer than 30 seconds:\n\n```bash\npython3 scripts/export_gdoc.py <input> --timeout 60\n```\n\n### File not found in Downloads\n\n- Check that browser is set to download files to `~/Downloads`\n- Verify no \"Save As\" dialog is blocking the download\n- Ensure sufficient disk space\n\n### Authentication errors\n\n- Log into Google account in the browser\n- Verify document sharing permissions\n- Try opening the document URL manually first\n\n## Dependencies\n\nThe reading functionality requires these tools:\n\n- **pandoc**: For reading DOCX and PPTX files\n\n  ```bash\n  brew install pandoc  # macOS\n  ```\n\n- **pandas + openpyxl**: For reading XLSX files\n\n  ```bash\n  pip3 install pandas openpyxl\n  ```\n\nThese dependencies are only needed for the reading step, not for export.\n\n## Resources\n\n### scripts/export_gdoc.py\n\nPython script that handles the complete export workflow:\n\n- Parses Google Drive URLs and `.gdoc` files\n- Extracts document IDs and determines document types\n- Builds and opens export URLs\n- Monitors Downloads folder\n- Moves files to temp directory\n\nExecute directly or import as a module for custom workflows.\n\n### scripts/read_exported_doc.py\n\nPython script that reads exported files using appropriate tools:\n\n- **DOCX files**: Converts to markdown using pandoc\n- **XLSX files**: Analyzes with pandas (shows preview, statistics, sheet info)\n- **PPTX files**: Extracts text using pandoc\n\nSupports multiple output formats:\n\n- DOCX: `markdown` (default), `plain`, `json`\n- XLSX: `summary` (default), `csv`, `json`\n- PPTX: `markdown` (default), `plain`, `json`\n\nUsage:\n\n```bash\npython3 scripts/read_exported_doc.py <file> [--format <format>] [--output <file>]\n```\n\n### references/export_formats.md\n\nDetailed reference on:\n\n- Available export formats for each Google Workspace type\n- URL patterns and format parameters\n- Quality trade-offs between formats\n- Document ID extraction methods\n- Authentication requirements\n\nLoad this file when users ask about format options or need deeper understanding of export mechanisms."
              }
            ]
          },
          {
            "name": "quill-export",
            "description": "Extract meeting recordings and transcripts from the Quill macOS app database with AI summary and cross-linking.",
            "source": "./plugins/quill-export",
            "category": "productivity",
            "version": "1.0.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/claude-code-plugins",
              "/plugin install quill-export@emdashcodes-claude-code-plugins"
            ],
            "signals": {
              "stars": 4,
              "forks": 1,
              "pushed_at": "2026-01-08T19:24:31Z",
              "created_at": "2025-10-18T01:20:32Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "quill-export",
                "description": "Extract meeting recordings and transcripts from the Quill macOS app database. Outputs formatted markdown with speaker identification, transcripts, and metadata. Use when working with Quill meeting data.",
                "path": "plugins/quill-export/skills/quill-export/SKILL.md",
                "frontmatter": {
                  "name": "quill-export",
                  "description": "Extract meeting recordings and transcripts from the Quill macOS app database. Outputs formatted markdown with speaker identification, transcripts, and metadata. Use when working with Quill meeting data."
                },
                "content": "# Quill Meeting Export\n\n## Overview\n\nExtract meeting data from Quill (macOS meeting recording app) and generate formatted markdown output with speaker-identified transcripts, meeting metadata, and Quill's AI-generated notes.\n\nThis skill provides:\n1. Database extraction from Quill's SQLite database\n2. Speaker name mapping from contact records\n3. Transcript formatting with speaker identification\n4. Markdown generation with YAML frontmatter\n5. Meeting search by ID or fuzzy name matching\n\n## When to Use This Skill\n\nActivate when working with Quill meeting data:\n- Extracting meeting transcripts\n- Converting Quill recordings to markdown\n- Searching for meetings by name\n- Getting meeting metadata and participants\n\n## Workflow\n\n### Step 1: List Available Meetings\n\nShow recent meetings from Quill:\n\n```bash\npython3 ~/.claude/skills/quill-export/scripts/export_meeting.py list [limit]\n```\n\n**Output** (to stderr):\n- Meeting ID (UUID)\n- Title\n- Date and time\n- Duration\n- Meeting type\n\n### Step 2: Export Meeting\n\nExport meeting by ID or search term:\n\n```bash\n# By exact ID\npython3 ~/.claude/skills/quill-export/scripts/export_meeting.py export 76490ffc-d751-4a2a-9ef5-df4d3ddce442\n\n# By fuzzy search term\npython3 ~/.claude/skills/quill-export/scripts/export_meeting.py export \"orchestrator\"\n```\n\n**Output** (to stdout):\n- Complete markdown document\n- YAML frontmatter with metadata\n- Transcript with real speaker names (if tagged in Quill)\n- Original Quill-generated notes\n- Audio file links\n\n**Fuzzy Search Behavior:**\n- Case-insensitive partial matching\n- If single match: Exports automatically\n- If multiple matches: Lists options (stderr) and exits\n- If no matches: Error message and exit\n\n### Step 3: Use the Markdown Output\n\nThe markdown is printed to stdout, allowing flexible usage:\n\n```bash\n# Save to file\npython3 export_meeting.py export \"meeting name\" > output.md\n\n# Pipe to other tools\npython3 export_meeting.py export <id> | pbcopy\n\n# Capture in a variable (from another script/tool)\nmarkdown=$(python3 export_meeting.py export <id>)\n```\n\n## Database Schema\n\nThe script queries Quill's SQLite database at `~/Library/Application Support/Quill/quill.db`.\n\nSee `references/quill-schema.md` for complete schema documentation including:\n- Meeting table structure\n- Transcript JSON format\n- ContactMeeting speaker mapping\n- Meeting type classifications\n\n## Speaker Name Mapping\n\nThe script automatically maps anonymous speaker IDs to real names:\n\n**How it works:**\n1. Queries `ContactMeeting` table for speaker IDs\n2. Looks up contact names in `Contact` table\n3. Replaces speaker IDs (e.g., `SPK-abc123`) with real names in transcript\n\n**When names are available:**\n```markdown\n**James LePage:** Hello, how are you?\n**Ember:** I'm doing well, thanks!\n```\n\n**When names are not available:**\n```markdown\n**SPK-mvjxhzyf43:** Hello, how are you?\n**SPK-h6xiau6chjv:** I'm doing well, thanks!\n```\n\n## Meeting Type Classification\n\nMeetings are categorized as `work` or `personal` based on type:\n\n**Work types:**\n- `1on1`, `internal_product`, `internal_sync`, `internal_standup`\n- `existing_vendor:customer`, `other`\n\n**Personal types:**\n- `personal`, `self_note`, `medical:patient`\n\nCategory appears in YAML frontmatter `type` field.\n\n## Markdown Output Format\n\n```markdown\n---\nmeeting_id: {UUID}\ntype: work|personal\ndate: YYYY-MM-DD\nstart_time: HH:MM\nduration: X minutes\nparticipants: [\"Name 1\", \"Name 2\"]\ntags: [\"meeting\", \"type\", ...]\n---\n\n# {Meeting Title}\n\n## Summary\n\n_AI summary will be generated here_\n\n## Key Discussion Points\n\n_Key points will be extracted here_\n\n## Action Items\n\n_Action items will be extracted here_\n\n## Related\n\n_Links to related tasks and projects_\n\n## Original Quill Notes\n\n{Quill's AI-generated meeting notes}\n\n## Transcript\n\n**Speaker:** Transcript text...\n\n## Audio\n\n[Recording](file:///path/to/audio.m4a)\n```\n\n## Audio File Handling\n\nAudio files remain in Quill's directory:\n- Location: `~/Library/Application Support/Quill/meetings/`\n- Linked using `file://` absolute URLs\n- Only the combined audio file is linked (`*-combined.m4a`)\n\n## Error Handling\n\n**Meeting not found:**\n- Prints error to stderr\n- Exit code 1\n\n**Multiple search matches:**\n- Lists all matching meetings to stderr\n- Prompts user to be more specific\n- Exit code 1\n\n**Database errors:**\n- Connection failures reported to stderr\n- Exit code 1\n\n## Usage Examples\n\n**List recent meetings:**\n```bash\npython3 export_meeting.py list 10\n```\n\n**Export by ID:**\n```bash\npython3 export_meeting.py export 76490ffc-d751-4a2a-9ef5-df4d3ddce442 > meeting.md\n```\n\n**Export by name search:**\n```bash\npython3 export_meeting.py export \"AI Discussion\" > meeting.md\n```\n\n**Integration with other tools:**\n```bash\n# Copy to clipboard\npython3 export_meeting.py export \"sync meeting\" | pbcopy\n\n# Save with custom filename\npython3 export_meeting.py export <id> > ~/Notes/$(date +%Y-%m-%d)-meeting.md\n```\n\n## Resources\n\n### scripts/export_meeting.py\nPython script for extracting meeting data and generating markdown.\n\n**Functions:**\n- `connect_db()` - Connect to Quill database\n- `get_speaker_names(conn, meeting_id)` - Map speaker IDs to names\n- `list_recent_meetings(conn, limit)` - List meetings\n- `search_meetings(conn, search_term)` - Fuzzy search by title\n- `get_meeting(conn, meeting_id)` - Fetch meeting data\n- `format_transcript(transcript, speaker_names)` - Format with names\n- `format_meeting_markdown(meeting)` - Generate markdown output\n\n### references/quill-schema.md\nComplete Quill database schema documentation.\n\n### assets/meeting-template.md\nTemplate showing markdown structure and formatting."
              }
            ]
          },
          {
            "name": "nano-banana-image-editor",
            "description": "Create and edit images with natural language using Gemini 3 Pro Image. Use for image generation, photo editing, infographics, icons, style transfer, and text rendering. Includes Google Search grounding for factual content and PIL/Pillow for quick crops.",
            "source": "./plugins/nano-banana-image-editor",
            "category": "productivity",
            "version": "1.0.1",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/claude-code-plugins",
              "/plugin install nano-banana-image-editor@emdashcodes-claude-code-plugins"
            ],
            "signals": {
              "stars": 4,
              "forks": 1,
              "pushed_at": "2026-01-08T19:24:31Z",
              "created_at": "2025-10-18T01:20:32Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/image",
                "description": "Create or edit images with natural language prompts",
                "path": "plugins/nano-banana-image-editor/commands/image.md",
                "frontmatter": {
                  "description": "Create or edit images with natural language prompts",
                  "argument-hint": [
                    "your image request"
                  ],
                  "allowed-tools": "Read, Skill"
                },
                "content": "# Image Generation/Editing Command\n\nActivate the nano-banana-image-editor skill to handle this image request.\n\n## Instructions\n\n1. **Activate the skill**: Use the `nano-banana-image-editor` skill\n2. **Read the prompting guide**: Load `references/prompting_guide.md` to understand how to craft effective prompts for Gemini 3 Pro Image\n3. **Translate the request**: Convert the user's natural language request into an optimized prompt following the guidelines in the prompting guide\n4. **Execute**: Use the appropriate script from the skill to generate or edit the image\n\n## User Request\n\n$ARGUMENTS"
              },
              {
                "name": "/upgrade",
                "description": "Upgrade the nano-banana-image-editor plugin to the latest version from the marketplace repository",
                "path": "plugins/nano-banana-image-editor/commands/upgrade.md",
                "frontmatter": {
                  "description": "Upgrade the nano-banana-image-editor plugin to the latest version from the marketplace repository",
                  "tools": "Bash, AskUserQuestion"
                },
                "content": "# Nano Banana Image Editor Plugin Upgrade\n\nYou are running the nano-banana-image-editor upgrade command to update the plugin to the latest version.\n\n## Your Task\n\nGuide the user through upgrading the nano-banana-image-editor plugin by pulling the latest changes from the marketplace repository.\n\n## Workflow\n\n### Step 1: Verify Current Installation\n\nCheck the current version and installation location:\n\n```bash\n# Get marketplace directory\nMARKETPLACE_DIR=$(dirname $(dirname ${CLAUDE_PLUGIN_ROOT}))\n\n# Get current version from marketplace.json\nCURRENT_VERSION=$(jq -r '.plugins[] | select(.name==\"nano-banana-image-editor\") | .version' \"$MARKETPLACE_DIR/.claude-plugin/marketplace.json\")\n\n# Verify git repository\ncd \"$MARKETPLACE_DIR\" && git rev-parse --git-dir >/dev/null 2>&1 && echo \"✓ Git repository found\" || echo \"✗ Not a git repository\"\n```\n\n**Output to user:**\n\n```\nCurrent version: [version]\nMarketplace directory: [path]\n```\n\n### Step 2: Check for Updates\n\nFetch the latest tags and check for updates:\n\n```bash\ncd \"$MARKETPLACE_DIR\"\ngit fetch --tags origin\n```\n\nThen get the version information:\n\n```bash\n# Get the latest version tag for this plugin\nLATEST_TAG=$(git tag -l 'nano-banana-image-editor/v*' --sort=-v:refname | head -n 1)\n\n# Get current tag (if on a tag)\nCURRENT_TAG=$(git describe --tags --exact-match 2>/dev/null || echo \"none\")\n\n# Filter to only nano-banana-image-editor tags if we're on a tag\nif [ \"$CURRENT_TAG\" != \"none\" ]; then\n  echo \"$CURRENT_TAG\" | grep -q '^nano-banana-image-editor/' || CURRENT_TAG=\"none\"\nfi\n\necho \"Latest tag: $LATEST_TAG\"\necho \"Current tag: $CURRENT_TAG\"\n```\n\n**Analyze the output:**\n\n- If `LATEST_TAG` is empty → No tagged releases available yet\n- If `CURRENT_TAG` equals `LATEST_TAG` → Already on latest version\n- If `LATEST_TAG` is newer → Continue to Step 3\n- If git fetch fails → Inform user there's a connection issue\n\n**Output to user:**\n\n```\nCurrent version: [CURRENT_VERSION] (tag: [CURRENT_TAG or \"not on a tagged release\"])\nLatest available: [LATEST_TAG]\n```\n\n### Step 3: Show Release Notes\n\nIf updates are available, show what's changed by reading the CHANGELOG:\n\n```bash\ncd \"$MARKETPLACE_DIR\" && git show \"$LATEST_TAG:plugins/nano-banana-image-editor/CHANGELOG.md\" | head -50\n```\n\n**Present the release notes** to the user, focusing on the latest version's changes.\n\n### Step 4: Confirm Upgrade\n\nUse the **AskUserQuestion** tool to ask:\n\n- **Question**: \"Ready to upgrade nano-banana-image-editor to the latest version?\"\n- **Options**:\n  - \"Yes, upgrade now\" (description: \"Pull latest changes from the repository\")\n  - \"No, not now\" (description: \"Keep current version\")\n\nIf user selects \"No, not now\":\n\n- Output: \"Upgrade cancelled. Your current version remains unchanged.\"\n- Exit the command\n\n### Step 5: Perform Upgrade\n\nIf user confirms, checkout the latest tagged release:\n\n```bash\ncd \"$MARKETPLACE_DIR\" && git checkout \"$LATEST_TAG\"\n```\n\n**Check the exit code:**\n\n- Exit code 0 → Success, continue to Step 6\n- Exit code != 0 → Error occurred, show user the error message and stop\n\n**Note:** This checks out the specific tagged release ensuring you get a stable, tested version.\n\n### Step 6: Rebuild Plugin Dependencies\n\nAfter pulling changes, reinstall Python dependencies:\n\n```bash\ncd ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor && bash scripts/install_dependencies.sh\n```\n\n**Monitor for errors:**\n\n- If successful → Continue to Step 7\n- If errors occur → Show errors to user and explain that manual intervention may be needed\n\n### Step 7: Verify New Version\n\nCheck the updated version:\n\n```bash\nNEW_VERSION=$(jq -r '.plugins[] | select(.name==\"nano-banana-image-editor\") | .version' \"$MARKETPLACE_DIR/.claude-plugin/marketplace.json\")\n```\n\n### Step 8: Success Message & Restart Prompt\n\n**Output to user:**\n\n```\n✅ Nano Banana Image Editor upgraded successfully!\n\nPrevious version: [old version]\nCurrent version: [new version]\n\n⚠️  Important: You must restart Claude Code to apply the changes.\n\nTo restart:\n1. Close this conversation\n2. Restart Claude Code\n3. Start a new session\n\nAfter restarting, you can verify the upgrade by running:\n/nano-banana-image-editor:image test\n```\n\n## Error Handling\n\n### Git Repository Not Found\n\nIf the marketplace directory is not a git repository:\n\n```\n❌ Upgrade failed: nano-banana-image-editor marketplace is not a git repository.\n\nThis can happen if the plugin was installed differently. To upgrade manually:\n\n1. Navigate to: [marketplace directory]\n2. Run: git fetch --tags origin\n3. List tags: git tag -l 'nano-banana-image-editor/v*' --sort=-v:refname\n4. Checkout latest: git checkout <latest-version-tag>\n5. Navigate to: [plugin directory]/skills/nano-banana-image-editor\n6. Run: bash scripts/install_dependencies.sh\n7. Restart Claude Code\n\nIf you continue to have issues, try reinstalling the plugin:\n/plugin marketplace remove emdashcodes-claude-code-plugins\n/plugin marketplace add emdashcodes/claude-code-plugins\n/plugin install nano-banana-image-editor@emdashcodes-claude-code-plugins\n```\n\n### Network/Connection Errors\n\nIf git fetch/pull fails due to network issues:\n\n```\n❌ Upgrade failed: Unable to connect to repository.\n\nPlease check your network connection and GitHub access.\n\nTo upgrade manually:\ncd [marketplace directory]\ngit fetch --tags origin\ngit tag -l 'nano-banana-image-editor/v*' --sort=-v:refname  # List versions\ngit checkout <latest-version-tag>\ncd [plugin directory]/skills/nano-banana-image-editor\nbash scripts/install_dependencies.sh\n\nThen restart Claude Code.\n```\n\n### Build Errors\n\nIf dependency installation fails:\n\n```\n❌ Upgrade completed but dependency installation failed.\n\nThe latest code was pulled, but there were errors during Python dependency installation.\nYou may need to troubleshoot manually.\n\nError details:\n[show error output]\n\nTo retry manually:\ncd [plugin directory]/skills/nano-banana-image-editor\nbash scripts/install_dependencies.sh\n\nIf issues persist, report at: https://github.com/emdashcodes/claude-code-plugins/issues\n```\n\n## Important Notes\n\n- This command upgrades to the latest **tagged release** (stable, tested versions)\n- Uses plugin-prefixed semantic versioning tags (e.g., `nano-banana-image-editor/v1.0.0`, `nano-banana-image-editor/v1.1.0`)\n- Your configuration file (`.nano-banana-config.json`) will not be affected\n- A restart of Claude Code is **required** for changes to take effect\n- The upgrade process does not modify your existing Gemini API token or settings"
              }
            ],
            "skills": [
              {
                "name": "nano-banana-image-editor",
                "description": "Edit and manipulate images using natural language prompts. Use this skill when users request image creation (photos, illustrations, icons, infographics) or editing tasks (removing objects, changing backgrounds, text overlays, cropping). Supports reference images for character consistency and style transfer. Supports Google Search grounding for real-time factual content (weather, sports, scientific data) - no need to search separately when creating infographics or factual visualizations.",
                "path": "plugins/nano-banana-image-editor/skills/nano-banana-image-editor/SKILL.md",
                "frontmatter": {
                  "name": "nano-banana-image-editor",
                  "description": "Edit and manipulate images using natural language prompts. Use this skill when users request image creation (photos, illustrations, icons, infographics) or editing tasks (removing objects, changing backgrounds, text overlays, cropping). Supports reference images for character consistency and style transfer. Supports Google Search grounding for real-time factual content (weather, sports, scientific data) - no need to search separately when creating infographics or factual visualizations."
                },
                "content": "# Image Editor\n\nThis skill enables AI-powered image editing and creation using **Google's Gemini 3 Pro Image** model (nicknamed \"Nano Banana Pro\"). It allows editing existing images or creating new images from scratch through natural language instructions.\n\n## When to Use This Skill\n\nUse this skill when users request:\n\n- Generate icons, images, and illustrations\n- Removing text, logos, or watermarks from images\n- Removing speaker overlays or video conference windows from slides\n- Changing backgrounds, objects, or colors\n- Cropping, resizing, or adjusting image composition\n- Adding or modifying visual elements\n- Style transfers or artistic transformations\n- Any image manipulation describable in natural language\n\n## Prerequisites\n\nIf needed, run the following script to install dependencies:\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/install_dependencies.sh\n```\n\nThis creates a Python virtual environment and installs the required packages (google-genai, Pillow).\n\n**Virtual environment location:**\n- Default: `${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv/`\n- Override: Set `NANO_BANANA_VENV` env var for multi-platform support (e.g., Docker containers)\n\n**API Key Setup:**\n\n1. Get an API key from [Google AI Studio](https://aistudio.google.com/app/apikey)\n2. **Run the setup script** to save the key to the plugin config:\n\n   ```bash\n   ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv/bin/${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/setup-gemini-token.py YOUR_API_KEY\n   ```\n\n   The script will:\n   - Test the API key to verify it works\n   - Save it to `.nano-banana-config.json` in the plugin directory\n   - Confirm that Gemini 3 Pro Image model is available\n\nAll script examples below use `${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3` to ensure the venv's Python interpreter is used.\n\n## How to Use\n\n### Creating New Images from Scratch\n\nUse the `create_image.py` script to generate new images from natural language prompts:\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  OUTPUT_IMAGE \"creation instruction\" --resolution 1K --aspect-ratio 1:1\n```\n\n**Example: Create an icon**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  cat-icon.png \"A playful orange tabby cat icon, simple and clean design\" \\\n  --resolution 1K --aspect-ratio 1:1\n```\n\n**Example: Create a high-resolution illustration**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  sunset.png \"A vibrant sunset over mountains with purple and orange sky\" \\\n  --resolution 4K --aspect-ratio 16:9\n```\n\n**Example: Create with reference images for style**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  landscape.png \"A mountain landscape in this artistic style\" \\\n  --reference style.png --resolution 2K --aspect-ratio 3:2\n```\n\n**Prompting Tips:**\n\n- Be specific about colors, style, and composition\n- Specify the desired mood or atmosphere\n- Use reference images to demonstrate desired style or composition\n- **Important**: See `references/prompting_guide.md` for comprehensive prompting strategies\n\n### Editing Existing Images\n\nUse the `edit_image.py` script to edit existing images with natural language prompts:\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/edit_image.py \\\n  INPUT_IMAGE OUTPUT_IMAGE \"editing instruction\" --resolution 1K --aspect-ratio 1:1\n```\n\n**Example: Remove text overlay**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/edit_image.py \\\n  slide.png slide-cleaned.png \\\n  \"Remove the text labels from the top of this diagram\"\n```\n\n**Example: Background removal with high resolution**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/edit_image.py \\\n  photo.jpg photo-no-bg.png \\\n  \"Remove the background and make it transparent white\" \\\n  --resolution 2K --aspect-ratio 4:3\n```\n\n**Example: Style transfer with reference image**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/edit_image.py \\\n  photo.jpg artistic.png \\\n  \"Apply the artistic style from the reference to this photo\" \\\n  --reference style.png --resolution 2K\n```\n\n### Advanced Multi-Image Features\n\n#### Recreating Templates with Different Characters\n\n**Important**: When recreating memes, comics, or templates with different characters, **always pass both the template AND the character references**.\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  output.png \"Recreate this meme template using these characters\" \\\n  --reference template.png --reference character1.png --reference character2.png \\\n  --resolution 2K --aspect-ratio 16:9\n```\n\n**Why both?**\n\n- The **template/meme reference** provides the composition, layout, poses, and panel structure\n- The **character references** provide facial features, hairstyles, and distinctive characteristics to maintain\n\n**Example: Recreating a two-panel comic meme**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  my-meme.png \"Recreate this two-panel comic using these two women as the characters. Maintain the exact composition and poses from the template.\" \\\n  --reference original-meme.png --reference my-characters.png \\\n  --resolution 2K --aspect-ratio 16:9\n```\n\n#### Character Consistency (Up to 5 People)\n\nCreate group photos maintaining facial resemblance:\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  group.png \"Office group photo of these people making funny faces\" \\\n  --reference person1.png --reference person2.png --reference person3.png \\\n  --resolution 2K --aspect-ratio 5:4\n```\n\n#### Object Composition (Up to 6 Objects)\n\nBlend multiple objects with high fidelity:\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  product.png \"Product showcase featuring these items on a marble surface\" \\\n  --reference item1.png --reference item2.png --reference item3.png \\\n  --resolution 4K --aspect-ratio 16:9\n```\n\n#### Advanced Editing with References\n\nEdit an image while using additional references:\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/edit_image.py \\\n  background.jpg composite.png \\\n  \"Add these people to the scene, natural lighting\" \\\n  --reference person1.png --reference person2.png \\\n  --resolution 2K\n```\n\n### Google Search Grounding\n\nEnable real-time information for factual content:\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  weather.png \"An infographic about today's weather in San Francisco\" \\\n  --search --resolution 2K --aspect-ratio 3:4\n```\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  plant-guide.png \"Create an educational infographic about String of Turtles houseplant care\" \\\n  --search --resolution 2K --aspect-ratio 3:4\n```\n\n**When to use `--search`:**\n\n- Weather visualizations and forecasts\n- Current events and news graphics\n- Scientific diagrams requiring factual accuracy\n- Educational infographics about real-world subjects\n- Sports statistics and data visualizations\n\n### Resolution and Aspect Ratio Selection\n\n**Resolution Options:**\n\n- `1K` (default) - Fast, good for iteration and testing (1024×1024 at 1:1)\n- `2K` - Professional quality (2048×2048 at 1:1)\n- `4K` - Maximum quality, studio-grade (4096×4096 at 1:1)\n\n**Common Aspect Ratios:**\n\n- `1:1` - Social media posts, profile pictures, icons\n- `16:9` - Presentations, YouTube thumbnails, desktop wallpapers\n- `9:16` - Instagram Stories, TikTok, mobile vertical content\n- `4:3` - Traditional displays, print media\n- `3:2` - Standard photography\n- `21:9` - Ultra-wide cinematic shots\n\n**Example with custom resolution and aspect ratio:**\n\n```bash\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  banner.png \"A website hero banner with mountains and sunrise\" \\\n  --resolution 4K --aspect-ratio 21:9\n```\n\n## Workflow\n\n1. **Identify the task** - Determine if the user wants to create a new image or edit an existing one\n2. **Check for dependencies and API key** - If errors occur, verify the API key is configured in the config file and that dependencies are installed\n3. **Prepare the prompt** - Translate the user's request into a clear, specific natural language instruction\n4. **Run the appropriate script**:\n   - Use `create_image.py` for generating new images\n   - Use `edit_image.py` for modifying existing images\n5. **Review the output** - Check if the result meets expectations; iterate if needed\n\n## Tips for Effective Prompts\n\n- **Be specific**: \"Remove the red text in the top-left corner\" is better than \"clean up the image\"\n- **Describe desired outcome**: \"Replace the blue background with white\" vs just \"change background\"\n- **Iterative editing**: Make one change at a time for better results\n- **Reference locations**: Use \"top left\", \"bottom right\", \"center\" to specify areas\n- **Use reference images**: Provide style examples, object references, or character photos when appropriate\n- **Pass ALL relevant references**: When recreating templates/memes with different characters, pass both the template image AND the character images as references\n- **Enable search for facts**: Add `--search` when generating content requiring real-time information\n\n**For comprehensive prompting strategies, see `references/prompting_guide.md`**\n**For best practices and workflow optimization, see `references/best_practices.md`**\n\n## Model Capabilities\n\n**Gemini 3 Pro Image supports:**\n\n- Object removal and addition with advanced reasoning\n- Background changes and removal\n- Accurate and legible text rendering in multiple languages\n- Color adjustments and advanced color grading\n- Studio-quality lighting controls (day/night, bokeh effects)\n- Camera angle and focus adjustments\n- Style transfers and artistic transformations\n- Multi-image blending (up to 14 reference images)\n- Character/subject consistency for up to 5 people across edits\n- Sketch-to-product and blueprint-to-3D transformations\n- Real-time data grounding via Google Search (recipes, weather, sports)\n- High-resolution output (2K and 4K with multiple aspect ratios)\n\n## Technical Specifications\n\n**Input Limits:**\n\n- Maximum images per prompt: 14 total\n  - Up to 6 images for object fidelity\n  - Up to 5 images for character consistency\n- Maximum file size: 7 MB per image\n- Supported formats: PNG, JPEG, WebP\n\n**Output Specifications:**\n\n- Resolution options: 1K, 2K, 4K\n- Supported aspect ratios: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9, 21:9\n- All generated images include SynthID watermarking\n\n**Resolution Examples:**\n\n- 1K at 1:1 = 1024×1024 pixels\n- 2K at 1:1 = 2048×2048 pixels\n- 4K at 1:1 = 4096×4096 pixels\n- 4K at 16:9 = 5504×3072 pixels\n- 4K at 21:9 = 6336×2688 pixels\n\n## Troubleshooting\n\n**\"No Gemini API key configured\" error:**\n\n- Run the setup script: `${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/setup-gemini-token.py YOUR_API_KEY`\n\n**\"No image in response\" message:**\n\n- The model may have returned text instead of an edited image\n- Try rephrasing the prompt more specifically\n- Check API rate limits or quota\n\n**Poor edit quality:**\n\n- Be more specific in the prompt\n- Try breaking complex edits into multiple steps\n- Ensure input image quality is sufficient\n\n**\"MALFORMED_FUNCTION_CALL\" error when editing:**\n\n- **Do NOT request watermark removal** - Gemini blocks prompts mentioning \"remove watermark\" to protect SynthID watermarks\n- Avoid prompts like \"remove the watermark\" or \"clean up watermarks\"\n- This is a content policy restriction, not a technical limitation\n\n**Prompts with dollar signs or special characters getting stripped:**\n\n- **Problem:** Dollar signs (`$3`, `$4.50`) and other bash special characters get removed from prompts\n- **Cause:** When using double quotes in bash, `$variable` syntax triggers variable expansion\n- **Solutions:**\n  - Use single quotes instead of double quotes: `'Espresso $3, Latte $4'`\n  - Escape dollar signs with backslash: `\"Espresso \\\\$3, Latte \\\\$4\"`\n  - Other special characters to watch: exclamation marks, backticks, backslashes, dollar signs, quotes\n\n**Example:**\n\n```bash\n# ❌ Wrong - dollar signs get expanded as variables\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  menu.png \"Coffee menu: Espresso $3, Latte $4\"\n\n# ✅ Correct - use single quotes\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  menu.png 'Coffee menu: Espresso $3, Latte $4'\n\n# ✅ Also correct - escape the dollar signs\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/create_image.py \\\n  menu.png \"Coffee menu: Espresso \\$3, Latte \\$4\"\n```\n\n## Non-AI Alternatives for Quick Edits\n\nFor simple, deterministic image operations, you can also use **PIL/Pillow** (Python) instead of the AI model. This is faster, free, and more predictable for basic tasks:\n\n### Quick Crop Script (Recommended)\n\nUse the included `quick_crop.py` script for fast, precise cropping:\n\n```bash\n# Remove 100px from the right edge\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/quick_crop.py \\\n  input.png output.png --remove-right 100\n\n# Exact crop box\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/quick_crop.py \\\n  input.png output.png --left 0 --top 0 --right 1200 --bottom 800\n\n# Remove pixels from bottom\n${NANO_BANANA_VENV:-${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/.venv}/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/nano-banana-image-editor/scripts/quick_crop.py \\\n  input.png output.png --remove-bottom 50\n```\n\n### Manual PIL/Pillow Code\n\nFor custom operations, use PIL directly:\n\n```python\nfrom PIL import Image\n\nimg = Image.open('input.png')\n# Crop: (left, top, right, bottom)\ncropped = img.crop((0, 0, img.size[0] - 100, img.size[1]))  # Remove 100px from right\ncropped.save('output.png')\n```\n\n### Resizing\n\n```python\nfrom PIL import Image\n\nimg = Image.open('input.png')\nresized = img.resize((1920, 1080))\nresized.save('output.png')\n```\n\n### Rotating\n\n```python\nfrom PIL import Image\n\nimg = Image.open('input.png')\nrotated = img.rotate(90, expand=True)\nrotated.save('output.png')\n```\n\n## References\n\n### Essential Guides\n\n**`references/prompting_guide.md`**\n\n- Photorealistic scenes with photography terminology\n- Stylized illustrations and stickers\n- Accurate text rendering in images\n- Product mockups and commercial photography\n- Minimalist and negative space design\n- Sequential art (comic panels, storyboards)\n- Image editing strategies (adding/removing elements, style transfer, composition)\n- Multi-image prompting techniques\n- Google Search grounding examples\n\n**`references/best_practices.md`**\n\n- Writing hyper-specific prompts for maximum control\n- Iterative refinement through multi-turn conversations\n- Step-by-step instructions for complex compositions\n- Using photography and camera terminology effectively\n- Multiple reference images best practices (character consistency, object fidelity, style transfer)\n- Resolution strategy (when to use 1K vs 2K vs 4K)\n- Aspect ratio selection for different use cases\n- When to use Google Search grounding\n- Quality checklist and workflow for complex projects\n\n### External Resources\n\n- [Google AI Studio](https://ai.google.dev/) - Web interface for testing Gemini models\n- [Pillow Documentation](https://pillow.readthedocs.io/) - PIL/Pillow for non-AI image operations"
              }
            ]
          },
          {
            "name": "video-toolkit",
            "description": "Video editing and analysis with FFmpeg and Whisper. Extract frames, transcribe audio, and perform video operations (clip, merge, split)",
            "source": "./plugins/video-toolkit",
            "category": "productivity",
            "version": "1.0.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/claude-code-plugins",
              "/plugin install video-toolkit@emdashcodes-claude-code-plugins"
            ],
            "signals": {
              "stars": 4,
              "forks": 1,
              "pushed_at": "2026-01-08T19:24:31Z",
              "created_at": "2025-10-18T01:20:32Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/upgrade",
                "description": "Upgrade the video-toolkit plugin to the latest version from the marketplace repository",
                "path": "plugins/video-toolkit/commands/upgrade.md",
                "frontmatter": {
                  "description": "Upgrade the video-toolkit plugin to the latest version from the marketplace repository",
                  "tools": "Bash, AskUserQuestion"
                },
                "content": "# Video Toolkit Plugin Upgrade\n\nYou are running the video-toolkit upgrade command to update the plugin to the latest version.\n\n## Your Task\n\nGuide the user through upgrading the video-toolkit plugin by pulling the latest changes from the marketplace repository.\n\n## Workflow\n\n### Step 1: Verify Current Installation\n\nCheck the current version and installation location:\n\n```bash\n# Get marketplace directory\nMARKETPLACE_DIR=$(dirname $(dirname ${CLAUDE_PLUGIN_ROOT}))\n\n# Get current version from marketplace.json\nCURRENT_VERSION=$(jq -r '.plugins[] | select(.name==\"video-toolkit\") | .version' \"$MARKETPLACE_DIR/.claude-plugin/marketplace.json\")\n\n# Verify git repository\ncd \"$MARKETPLACE_DIR\" && git rev-parse --git-dir >/dev/null 2>&1 && echo \"✓ Git repository found\" || echo \"✗ Not a git repository\"\n```\n\n**Output to user:**\n\n```\nCurrent version: [version]\nMarketplace directory: [path]\n```\n\n### Step 2: Check for Updates\n\nFetch the latest tags and check for updates:\n\n```bash\ncd \"$MARKETPLACE_DIR\"\ngit fetch --tags origin\n```\n\nThen get the version information:\n\n```bash\n# Get the latest version tag for this plugin\nLATEST_TAG=$(git tag -l 'video-toolkit/v*' --sort=-v:refname | head -n 1)\n\n# Get current tag (if on a tag)\nCURRENT_TAG=$(git describe --tags --exact-match 2>/dev/null || echo \"none\")\n\n# Filter to only video-toolkit tags if we're on a tag\nif [ \"$CURRENT_TAG\" != \"none\" ]; then\n  echo \"$CURRENT_TAG\" | grep -q '^video-toolkit/' || CURRENT_TAG=\"none\"\nfi\n\necho \"Latest tag: $LATEST_TAG\"\necho \"Current tag: $CURRENT_TAG\"\n```\n\n**Analyze the output:**\n\n- If `LATEST_TAG` is empty → No tagged releases available yet\n- If `CURRENT_TAG` equals `LATEST_TAG` → Already on latest version\n- If `LATEST_TAG` is newer → Continue to Step 3\n- If git fetch fails → Inform user there's a connection issue\n\n**Output to user:**\n\n```\nCurrent version: [CURRENT_VERSION] (tag: [CURRENT_TAG or \"not on a tagged release\"])\nLatest available: [LATEST_TAG]\n```\n\n### Step 3: Show Release Notes\n\nIf updates are available, show what's changed by reading the CHANGELOG:\n\n```bash\ncd \"$MARKETPLACE_DIR\" && git show \"$LATEST_TAG:plugins/video-toolkit/CHANGELOG.md\" | head -50\n```\n\n**Present the release notes** to the user, focusing on the latest version's changes.\n\n### Step 4: Confirm Upgrade\n\nUse the **AskUserQuestion** tool to ask:\n\n- **Question**: \"Ready to upgrade video-toolkit to the latest version?\"\n- **Options**:\n  - \"Yes, upgrade now\" (description: \"Pull latest changes from the repository\")\n  - \"No, not now\" (description: \"Keep current version\")\n\nIf user selects \"No, not now\":\n\n- Output: \"Upgrade cancelled. Your current version remains unchanged.\"\n- Exit the command\n\n### Step 5: Perform Upgrade\n\nIf user confirms, checkout the latest tagged release:\n\n```bash\ncd \"$MARKETPLACE_DIR\" && git checkout \"$LATEST_TAG\"\n```\n\n**Check the exit code:**\n\n- Exit code 0 → Success, continue to Step 6\n- Exit code != 0 → Error occurred, show user the error message and stop\n\n**Note:** This checks out the specific tagged release ensuring you get a stable, tested version.\n\n### Step 6: Rebuild Plugin Dependencies\n\nAfter pulling changes, reinstall Python dependencies:\n\n```bash\ncd ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit && bash scripts/install_dependencies.sh\n```\n\n**Monitor for errors:**\n\n- If successful → Continue to Step 7\n- If errors occur → Show errors to user and explain that manual intervention may be needed\n\n### Step 7: Verify New Version\n\nCheck the updated version:\n\n```bash\nNEW_VERSION=$(jq -r '.plugins[] | select(.name==\"video-toolkit\") | .version' \"$MARKETPLACE_DIR/.claude-plugin/marketplace.json\")\n```\n\n### Step 8: Success Message & Restart Prompt\n\n**Output to user:**\n\n```\n✅ Video Toolkit upgraded successfully!\n\nPrevious version: [old version]\nCurrent version: [new version]\n\n⚠️  Important: You must restart Claude Code to apply the changes.\n\nTo restart:\n1. Close this conversation\n2. Restart Claude Code\n3. Start a new session\n\nAfter restarting, you can verify the upgrade by running:\n/video-toolkit [test_video_file]\n```\n\n## Error Handling\n\n### Git Repository Not Found\n\nIf the marketplace directory is not a git repository:\n\n```\n❌ Upgrade failed: video-toolkit marketplace is not a git repository.\n\nThis can happen if the plugin was installed differently. To upgrade manually:\n\n1. Navigate to: [marketplace directory]\n2. Run: git fetch --tags origin\n3. List tags: git tag -l 'video-toolkit/v*' --sort=-v:refname\n4. Checkout latest: git checkout <latest-version-tag>\n5. Navigate to: [plugin directory]/skills/video-toolkit\n6. Run: bash scripts/install_dependencies.sh\n7. Restart Claude Code\n\nIf you continue to have issues, try reinstalling the plugin:\n/plugin marketplace remove emdashcodes-claude-code-plugins\n/plugin marketplace add emdashcodes/claude-code-plugins\n/plugin install video-toolkit@emdashcodes-claude-code-plugins\n```\n\n### Network/Connection Errors\n\nIf git fetch/pull fails due to network issues:\n\n```\n❌ Upgrade failed: Unable to connect to repository.\n\nPlease check your network connection and GitHub access.\n\nTo upgrade manually:\ncd [marketplace directory]\ngit fetch --tags origin\ngit tag -l 'video-toolkit/v*' --sort=-v:refname  # List versions\ngit checkout <latest-version-tag>\ncd [plugin directory]/skills/video-toolkit\nbash scripts/install_dependencies.sh\n\nThen restart Claude Code.\n```\n\n### Build Errors\n\nIf dependency installation fails:\n\n```\n❌ Upgrade completed but dependency installation failed.\n\nThe latest code was pulled, but there were errors during dependency installation.\nYou may need to troubleshoot manually.\n\nError details:\n[show error output]\n\nTo retry manually:\ncd [plugin directory]/skills/video-toolkit\nbash scripts/install_dependencies.sh\n\nIf issues persist, report at: https://github.com/emdashcodes/claude-code-plugins/issues\n```\n\n## Important Notes\n\n- This command upgrades to the latest **tagged release** (stable, tested versions)\n- Uses plugin-prefixed semantic versioning tags (e.g., `video-toolkit/v1.0.0`, `video-toolkit/v1.1.0`)\n- A restart of Claude Code is **required** for changes to take effect\n- The upgrade process will reinstall FFmpeg and Whisper dependencies"
              }
            ],
            "skills": [
              {
                "name": "video-toolkit",
                "description": "Video analysis and editing with FFmpeg and Whisper. This skill should be used when video files are shared (.mov, .mp4, .avi, etc.) or when you encounter \"cannot read binary files\" errors for video files, when users request video analysis or summarization, or when users ask to edit videos (clip, merge, split).",
                "path": "plugins/video-toolkit/skills/video-toolkit/SKILL.md",
                "frontmatter": {
                  "name": "video-toolkit",
                  "description": "Video analysis and editing with FFmpeg and Whisper. This skill should be used when video files are shared (.mov, .mp4, .avi, etc.) or when you encounter \"cannot read binary files\" errors for video files, when users request video analysis or summarization, or when users ask to edit videos (clip, merge, split).",
                  "allowed-tools": "Read, Write, Bash, Glob"
                },
                "content": "# Video Toolkit\n\nComprehensive video processing skill combining editing capabilities with multi-modal analysis (visual frames + audio transcription).\n\n## When to Use This Skill\n\nActivate this skill when:\n\n- User shares a video file (.mov, .mp4, .avi, .mkv, .webm, etc.)\n- User asks to analyze, summarize, or understand video content\n- User requests video editing operations (clip, merge, split)\n- User asks questions about what's in a video\n- You encounter \"cannot read binary files\" errors when trying to read video files\n- Guides agents to use proper video analysis workflow\n\n**What this means for users:**\n\nWhen you share a video file, Claude will automatically recognize it and offer to analyze it properly using the video-toolkit, rather than attempting to read the binary file directly.\n\n## Prerequisites\n\n**Required Dependencies:**\n\n1. **FFmpeg** - Video processing and frame extraction\n   - Installation handled by `scripts/install_dependencies.sh`\n   - Verify: `ffmpeg -version`\n\n2. **Python 3.8+** with virtual environment\n   - Installation handled by `scripts/install_dependencies.sh`\n\n3. **OpenAI Whisper** - Speech transcription (local, no API key required)\n   - Installed via pip in `.venv`\n   - Model: base (good balance of speed/accuracy)\n   - Other models available: tiny.en, small, medium, large\n\n4. **Google Gemini API** - Audio analysis and music detection\n   - Installed via pip in `.venv`\n   - Requires API key (see setup below)\n   - Model: gemini-2.5-flash\n\n5. **Shazam API** - Music identification\n   - Installed via pip in `.venv` (shazamio)\n   - No API key required (uses public endpoint)\n\n**Setup:**\n\n**Step 1: Install Dependencies**\n\nRun the installation script on first use:\n\n```bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/install_dependencies.sh\n```\n\nThis creates a Python virtual environment at `${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/` and installs the required packages (ffmpeg-python, openai-whisper, google-genai, shazamio).\n\n**Step 2: Configure API Keys**\n\nSet up Gemini API key for audio analysis:\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/setup_api_keys.py gemini YOUR_API_KEY\n```\n\nGet your Gemini API key from: https://aistudio.google.com/app/apikey\n\n**Optional:** If you want to use RapidAPI's Shazam endpoint instead of the public one:\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/setup_api_keys.py shazam YOUR_RAPIDAPI_KEY\n```\n\nNote: Shazam/music identification works without an API key using shazamio's public endpoint.\n\n## How to Use This Skill\n\n**IMPORTANT: Check API Key Setup First**\n\nBefore analyzing videos with audio, verify that the Gemini API key is configured:\n- Config file location: `/Users/emdash/Dev/claude-code-plugins/emdashcodes/.video-toolkit-config.json`\n- If the file doesn't exist or doesn't contain `gemini.apiKey`, run the setup first (see Prerequisites above)\n- The scripts will error with clear setup instructions if the API key is missing\n\n### Multi-Modal Video Analysis Workflow\n\nWhen analyzing a video file, follow this comprehensive workflow:\n\n**1. Frame Extraction**\n\nExtract visual frames using either **interval mode** or **scene detection mode**:\n\n**Interval Mode** (time-based):\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/extract_frames.py <video_path> <interval_seconds> <output_dir>\n```\n\n- `interval_seconds`: Time between frames (e.g., 2 for every 2 seconds)\n- `output_dir`: Temporary directory for frames\n- Best for: Consistent sampling, slideshows, time-based analysis\n\n**Scene Detection Mode** (change-based):\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/extract_frames.py <video_path> --scene-detect <output_dir> [threshold]\n```\n\n- `threshold`: Sensitivity (0.0-1.0, optional, default: 0.02)\n- Automatically detects visual changes\n- Best for: Screen recordings, presentations, variable content\n\n**Choosing the Right Mode:**\n\n| Video Type | Recommended Mode | Threshold/Interval | Recommended Value |\n|------------|------------------|-------------------|-------------------|\n| **Screen recordings** | **Interval** | 2-3 seconds | **Use 2-3s** |\n| **Presentations/Slides** | Scene detection | 0.05 - 0.10 | **Use 0.05** |\n| **Movies/Hard cuts** | Scene detection | 0.20 - 0.30 | **Use 0.20** |\n| **Surveillance/Static** | Interval | 5-10 seconds | **Use 5s** |\n| **Interviews/Dialogue** | Interval | 3-5 seconds | **Use 3s** |\n| **Action videos** | Interval | 1-2 seconds | **Use 1s** |\n\n**Agent Decision Making:**\n\n- For UI/screen recordings: Use interval mode with 2-3s (captures static periods reliably)\n- For presentations/slides: Use scene detection with 0.05 (good for slide transitions)\n- For movies with hard cuts: Use scene detection with 0.20\n- For talking heads/static: Use interval mode with 3-5s\n- For action/movement: Use interval mode with 1-2s\n- **DEFAULT**: Interval mode with 2s (safest for most videos)\n\n**IMPORTANT: Evaluate and Re-run if Needed**\n\n- After extraction, **check the frame count** - does it seem reasonable for the video duration?\n- If you get too few frames (e.g., <5 frames for a 2-min screen recording), **SWITCH TO INTERVAL MODE**\n- If you get too many frames (e.g., >100 frames), the threshold may be TOO LOW\n- **Think critically about the results, check some frames, and RE-RUN with different settings if necessary**\n- Don't proceed with analysis if frame extraction clearly failed or produced poor results\n\n**Scene Detection Limitation:**\nScene detection **only captures frames when visual content changes significantly**. If the video has long static periods (e.g., same screen for 30+ seconds), scene detection will miss that content entirely. **For videos with static content, USE INTERVAL MODE instead** with `--mode interval --interval 2` or `--interval 3`.\n\n**2. Audio Extraction**\n\nExtract audio track using `scripts/extract_audio.py`:\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/extract_audio.py <video_path> <output_wav_path>\n```\n\n- Converts to WAV format (Whisper-compatible)\n- Preserves original audio quality\n- Returns: Path to extracted WAV file\n\n**3. Audio Analysis (Sequential Workflow)**\n\nThe audio analysis follows a sequential workflow to maximize accuracy and efficiency:\n\n**3a. Speech Transcription (Whisper - Local)**\n\nTranscribe speech using Whisper (runs locally, no API key required):\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/transcribe_audio.py <wav_path> [model_name]\n```\n\n- `model_name`: Whisper model (default: base)\n  - tiny.en: Fastest, English only\n  - base: Good balance (recommended)\n  - small: Better accuracy\n  - medium: High accuracy\n  - large: Best accuracy, slowest\n- Returns: Timestamped transcript with speaker diarization info\n- **Purpose**: Extract speech/dialogue from the audio\n\n**3b. Audio Understanding (Gemini Audio API)**\n\nAnalyze audio comprehensively using Gemini Audio API:\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/analyze_audio_gemini.py <wav_path> [output_markdown]\n```\n\n- Analyzes full audio content (not just speech)\n- **Detects music** with precise timestamps (MM:SS to MM:SS format)\n- Identifies non-speech sounds (applause, ambient noise, sound effects)\n- **Translates foreign languages**: If Whisper detects non-English speech, Gemini provides both original and English translation\n- Returns:\n  - Markdown analysis saved to `[output_markdown]`\n  - JSON data automatically saved to `gemini_audio.json` in same directory\n  - JSON contains `has_music` flag and `music_segments` array for downstream processing\n- **Purpose**: Understand what's in the audio beyond speech, detect if music is present, translate foreign languages\n\n**3c. Music Identification (Shazam - Conditional)**\n\nIf Gemini detects music, identify songs using Shazam:\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/identify_music.py <wav_path> <gemini_json> [output_markdown]\n```\n\n- `<gemini_json>`: Path to the `gemini_audio.json` file created by `analyze_audio_gemini.py`\n- Only runs if Gemini detected music (checks `has_music` flag in JSON)\n- Extracts music segments based on Gemini's timestamps using FFmpeg\n- Identifies each segment with Shazam API\n- Returns: Song title, artist, album, genre, year\n- **Purpose**: Identify specific songs in the video\n\n**Sequential Workflow Summary:**\n\n```\n1. Whisper (local)     → Speech transcription\n2. Gemini Audio (API)  → Detect music + timestamps, analyze non-speech audio\n3. FFmpeg              → Extract music segments (if music detected)\n4. Shazam (API)        → Identify songs (if music detected)\n```\n\nThis approach ensures:\n- Whisper focuses on speech (what it does best, runs locally)\n- Gemini provides overall audio understanding and music detection\n- Shazam only processes clean music segments (better accuracy)\n- No unnecessary API calls if no music is present\n\n**Gemini vs Shazam - Complementary Capabilities:**\n\n- **Gemini Audio API**: AI-powered audio understanding\n  - Recognizes music **characteristics**: genre, mood, instrumentation, tempo\n  - Example: \"Rock/Alternative song with electric guitar and male vocals, energetic\"\n  - May recognize well-known classical pieces (especially if mentioned in speech)\n  - Provides timestamps and musical context\n  - **Does NOT** identify specific tracks, artists, or albums\n\n- **Shazam**: Audio fingerprint matching\n  - Identifies **specific recordings**: track title, artist, album, year\n  - Example: \"Substitution - Silversun Pickups, Swoon (2009)\"\n  - Requires at least 3 seconds of audio for reliable identification\n  - Provides Shazam URLs and metadata\n\nBoth work together: Gemini describes what the music *sounds like*, Shazam identifies which specific *track* it is.\n\n\n\n**3.5. Context Clarification with Intelligent Question Generation**\n\n**CRITICAL STEP**: After gathering initial data (frames, audio, music identification), ask the user context questions to understand the video's perspective and avoid misidentification.\n\n**Why this step is critical**: Visual evidence alone can be ambiguous. For example, seeing streaming platform with a BRB screen could mean either:\n\n- The user is streaming and stepped away (creator perspective)\n- The user is watching someone else's stream (viewer perspective)\n\nOnly the user can clarify their relationship to the content.\n\n---\n\n## Workflow: Analyze First, Then Ask\n\n**Step 1: Complete Initial Data Gathering**\n\nBefore asking any questions, run the full analysis pipeline through Step 3c:\n\n- ✓ Extract frames (Step 1)\n- ✓ Extract and transcribe audio (Steps 2, 3a)\n- ✓ Analyze audio with Gemini (Step 3b)\n- ✓ Identify music with Shazam if detected (Step 3c)\n\n\n**Step 2: Build Contextual Evidence**\n\nReview what was gathered:\n\n- **Visual evidence**: Sample 3-5 frames - what's visible? (UI, people, environments, screen content)\n- **Audio evidence**: What's the audio content? (speech, music, ambient sounds)\n- **Music evidence**: What songs were identified? With what timestamps?\n- **Conversation context**: What has the user said about this video?\n- **User knowledge**: What do you know about this user from conversation history and preferences?\n\n**Step 3: Ask Context Question (Q1) with Evidence**\n\nPresent Q1 with context from your gathered evidence to help the user answer:\n\n```python\n# Build context string from evidence\n# Adapt summary based on what was found in the video\n\n# Example 1: Stream Viewer\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Streaming platform interface with BRB screen, person visible, workspace shown\n- Audio: Music playing (\"Song Title\" by Artist Name), minimal speech\n- Duration: 1:57\n\"\"\"\n\n# Example 2: Tutorial/How-to\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Person's hands visible working with materials, step-by-step demonstrations\n- Audio: Instructional narration explaining process, background music\n- Duration: 8:34\n\"\"\"\n\n# Example 3: Screen Recording (Software Demo)\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: VS Code editor with code visible, cursor movements, terminal commands\n- Audio: Voiceover explaining code changes, keyboard typing sounds\n- Duration: 5:12\n\"\"\"\n\n# Example 4: Screen Recording (Gameplay)\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Game interface with HUD elements, character movement, gameplay\n- Audio: Game sounds, background music, occasional commentary\n- Duration: 12:45\n\"\"\"\n\n# Example 5: Personal/Casual\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Person on camera in home setting, handheld/phone camera movement\n- Audio: Person speaking directly to camera, ambient room sounds\n- Duration: 2:18\n\"\"\"\n\n# Example 6: Personal/Casual (Phone Clip)\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Quick clip of outdoor scene, vertical/portrait orientation, casual framing\n- Audio: Ambient sounds, brief speech, wind noise\n- Duration: 0:43\n\"\"\"\n\n# Example 7: Event/Performance\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Stage with performers, audience visible, concert venue setting\n- Audio: Live music performance, crowd noise, applause\n- Duration: 3:56\n\"\"\"\n\n# Example 8: Presentation/Slides\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Slide deck with bullet points and diagrams, presenter occasionally visible\n- Audio: Presenter speaking, slide transition sounds\n- Duration: 18:24\n\"\"\"\n\n# Example 9: Casual Documentation (Workspace)\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Desk setup with monitors and equipment, informal camera angles\n- Audio: Background music, ambient office sounds, no narration\n- Duration: 1:34\n\"\"\"\n\n# Example 10: Behind-the-Scenes\nevidence_summary = \"\"\"I've analyzed the video and found:\n- Visual: Production equipment, camera setup, people working on set\n- Audio: Technical discussions, equipment sounds, music playing\n- Duration: 4:27\n\"\"\"\n\n# Template for implementation:\n# Select the most relevant description based on gathered evidence\ndef build_evidence_summary(frames_analysis, audio_analysis, music_data, duration):\n    \"\"\"\n    Generate evidence summary based on analyzed content\n\n    Returns contextual summary that helps user identify video type\n    \"\"\"\n    visual_desc = describe_visual_content(frames_analysis)\n    audio_desc = describe_audio_content(audio_analysis, music_data)\n\n    return f\"\"\"I've analyzed the video and found:\n- Visual: {visual_desc}\n- Audio: {audio_desc}\n- Duration: {format_duration(duration)}\n\"\"\"\n\n# Present Q1 with evidence context\nAskUserQuestion(\n    questions=[\n        {\n            \"question\": f\"{evidence_summary}\\n\\nWhat type of video is this?\",\n            \"header\": \"Video Type\",\n            \"multiSelect\": false,\n            \"options\": [\n                {\n                    \"label\": \"Tutorial/How-to\",\n                    \"description\": \"Teaching or demonstrating something step-by-step\"\n                },\n                {\n                    \"label\": \"Personal\",\n                    \"description\": \"Personal video, daily life content, a moment or activity, clip from phone\"\n                },\n                {\n                    \"label\": \"Screen recording\",\n                    \"description\": \"Recording your own screen (software demo, debugging video, gameplay, etc.)\"\n                },\n                {\n                    \"label\": \"Watching something\",\n                    \"description\": \"Recording yourself viewing someone else's content\"\n                },\n                {\n                    \"label\": \"Event/Performance\",\n                    \"description\": \"Concert, presentation, ceremony, or live event\"\n                },\n                {\n                    \"label\": \"Other/Not sure\",\n                    \"description\": \"Type a custom description of what this video shows\"\n                }\n            ]\n        }\n    ]\n)\n```\n\n**Key Patterns in Evidence Summaries:**\n\n1. **Be specific about what's visible**: Not just \"screen content\" but \"VS Code editor with code\" or \"Streaming platform interface with BRB screen\"\n\n2. **Mention identifying audio**: \"Music playing (song identified)\" vs. \"instructional narration\" vs. \"live performance audio\"\n\n3. **Note video characteristics**: Portrait orientation, handheld movement, production quality\n\n4. **Keep it concise**: 2-3 bullet points max, user can read it quickly\n\n5. **Help user self-identify**: Evidence should make the correct option obvious\n\n**Step 4: Generate Smart Follow-up (Q2) Based on Evidence + Q1 Answer**\n\n**CRITICAL**: Generate Q2 dynamically based on:\n\n- ✓ User's Q1 answer\n- ✓ Visual evidence from frames\n- ✓ Audio evidence from transcription/Gemini\n- ✓ Music identification results\n- ✓ Conversation context\n- ✓ User preferences and history\n\n**Skip Q2 entirely if**:\n\n- The evidence makes the context obvious\n- Q1 answer is self-explanatory (Tutorial, Event/Performance)\n- You're highly confident about the analysis direction\n\n**Generate custom Q2 if needed**:\n\n**If Q1 = \"Watching something\" AND you identified what they were watching:**\n\n```python\n# Example: You saw streaming platform + identified music\nAskUserQuestion(\n    questions=[\n        {\n            \"question\": \"I can see streaming platform with a BRB screen and identified 'Song Title' by Artist Name playing in the background. Is this what was happening?\",\n            \"header\": \"Confirm Context\",\n            \"multiSelect\": false,\n            \"options\": [\n                {\n                    \"label\": \"Yes, that's correct\",\n                    \"description\": \"Watching a stream with music playing in my space\"\n                },\n                {\n                    \"label\": \"Partially correct\",\n                    \"description\": \"Some of that is right, but let me clarify\"\n                },\n                {\n                    \"label\": \"No, different context\",\n                    \"description\": \"That's not quite what was happening\"\n                }\n            ]\n        }\n    ]\n)\n```\n\n**If Q1 = \"Watching something\" AND you're uncertain what:**\n\n```python\nAskUserQuestion(\n    questions=[\n        {\n            \"question\": \"What were you watching?\",\n            \"header\": \"Content Source\",\n            \"multiSelect\": true,  # Allow multiple selections\n            \"options\": [\n                {\n                    \"label\": \"Live stream\",\n                    \"description\": \"Streaming platforms, Twitch, YouTube live, etc.\"\n                },\n                {\n                    \"label\": \"Video content\",\n                    \"description\": \"YouTube video, movie, TV show, etc.\"\n                },\n                {\n                    \"label\": \"Music playing\",\n                    \"description\": \"Music was playing in your space\"\n                },\n                {\n                    \"label\": \"Other media\",\n                    \"description\": \"Game, presentation, or other content\"\n                }\n            ]\n        }\n    ]\n)\n```\n\n**If Q1 = \"Personal\" AND video shows workspace/music:**\n\n```python\n# You already know music was playing and workspace is visible\n# Generate confirmation question instead of generic tags\nAskUserQuestion(\n    questions=[\n        {\n            \"question\": \"I can see your workspace and 'Song Title' playing. What tags describe this video?\",\n            \"header\": \"Context Tags\",\n            \"multiSelect\": true,\n            \"options\": [\n                {\n                    \"label\": \"Music playing\",\n                    \"description\": \"Background music in your space\"\n                },\n                {\n                    \"label\": \"Workspace/setup\",\n                    \"description\": \"Showing desk, equipment, or environment\"\n                },\n                {\n                    \"label\": \"Activity in progress\",\n                    \"description\": \"Doing something while recording\"\n                },\n                {\n                    \"label\": \"Artistic/experimental\",\n                    \"description\": \"Creative or artistic intent\"\n                }\n            ]\n        }\n    ]\n)\n```\n\n**If Q1 = \"Screen recording\":**\n\n```python\n# Only ask if genuinely uncertain from frames\n# You likely already saw what's on screen\nAskUserQuestion(\n    questions=[\n        {\n            \"question\": \"I can see {specific_app_or_content}. What were you recording?\",\n            \"header\": \"Screen Content\",\n            \"multiSelect\": false,\n            \"options\": [\n                {\n                    \"label\": \"Software/application\",\n                    \"description\": \"Demonstrating a program or workflow\"\n                },\n                {\n                    \"label\": \"Gameplay\",\n                    \"description\": \"Playing a game\"\n                },\n                {\n                    \"label\": \"Design/creative work\",\n                    \"description\": \"Working in design tools, editors, etc.\"\n                },\n                {\n                    \"label\": \"General computer use\",\n                    \"description\": \"Browsing, chatting, or mixed activities\"\n                }\n            ]\n        }\n    ]\n)\n```\n\n**If Q1 = \"Tutorial/How-to\" or \"Event/Performance\":**\n→ **Skip Q2** - these are self-explanatory, proceed to analysis\n\n**If Q1 = \"Other/Not sure\" (custom text provided):**\n→ Use the custom text to inform analysis, **skip Q2** unless truly necessary\n\n---\n\n## Store and Use Metadata\n\nAfter Q1 (and Q2 if asked), store structured metadata:\n\n```python\nvideo_metadata = {\n    \"video_type\": user_q1_answer,           # \"Watching something\"\n    \"perspective\": derived_perspective,      # \"First-Person Viewer\"\n    \"content_tags\": user_q2_answers,        # [\"live stream\", \"music playing\"]\n    \"evidence\": {\n        \"visual\": visual_summary,            # From frames\n        \"audio\": audio_summary,              # From Gemini\n        \"music\": music_identification,       # From Shazam\n        \"duration\": video_duration\n    }\n}\n```\n\n**Use this metadata throughout remaining analysis:**\n\n- Guide visual analysis focus (Step 5)\n- Inform subagent prompts\n- Set appropriate terminology in final summary\n- Avoid misidentifying perspective or intent\n\n---\n\n## Example: Context-Aware Question Flow\n\n**Scenario**: User shares video showing streaming platform with BRB screen, person visible, music playing\n\n**Data Gathered (Steps 1-3d)**:\n\n- Frames: Streaming platform UI, BRB overlay, person, workspace visible\n- Audio: Music \"Song Title\" by Artist Name (0:32-1:57), minimal speech\n- Duration: 1:57\n- Context: User information from conversation history\n\n**Q1 with Context**:\n\n```\nI've analyzed the video and found:\n- Visual: Streaming platform interface with BRB screen, person visible, workspace shown\n- Audio: Music playing (\"Song Title\" by Artist Name), minimal speech\n- Duration: 1:57\n\nWhat type of video is this?\n→ User selects: \"Watching something\"\n```\n\n**Smart Q2 Generation**:\n\n```python\n# You already know:\n# - Streaming platform with BRB = watching a stream\n# - Music identified = \"Song Title\" playing in their space\n# - Person visible = user on camera\n\n# Instead of generic \"What were you watching?\", generate specific confirmation:\n\"I can see streaming platform with a BRB screen and identified 'Song Title' by Artist Name\nplaying in the background. Were you watching someone's stream while music played in your space?\"\n\nOptions:\n- Yes, that's correct\n- Partially - let me clarify\n- No, different context\n```\n\n**Result**: Only 2 questions needed, and Q2 is informed and specific rather than generic.\n\n**Alternative - High Confidence, Skip Q2**:\nIf extremely confident from evidence, skip Q2 entirely:\n\n```\nQ1 answer: \"Watching something\"\n\n→ Skip Q2, proceed with metadata:\n{\n  video_type: \"Watching something\",\n  perspective: \"First-Person Viewer\",\n  content_tags: [\"live stream\", \"music playing\", \"workspace visible\"]\n}\n```\n\n---\n\n## Benefits of This Approach\n\n1. **Evidence-informed questions**: Q1 includes what you found, helping user answer\n2. **Smart Q2 generation**: Tailored to what you already know + user's Q1 answer\n3. **Skip when confident**: Don't ask unnecessary questions if evidence is clear\n4. **Confirmation over discovery**: Ask \"Is this correct?\" when you have strong evidence\n5. **Context-aware**: Uses conversation history, user preferences, and gathered data\n6. **Prevents misidentification**: Clarifies creator vs. viewer perspective early\n7. **Efficient**: Maximum 2 questions, often just 1\n\n---\n\n## Integration with Remaining Workflow\n\nAfter completing Step 3.5 (Context Clarification), proceed to:\n\n**Step 4**: Video Type Detection and Analysis Strategy\n\n- Use `video_metadata.perspective` to select appropriate analysis focus\n- Apply type-specific guidance based on clarified context\n\n**Step 5**: Visual Analysis with video-frame-analyzer Subagent(s)\n\n- Pass `video_metadata` to subagent prompts\n- Ensure analysis matches user's stated relationship to content\n- Use correct terminology (viewer/creator/observer language)\n\nThe metadata from context clarification informs all downstream analysis.\n\n---\n\n**4. Video Perspective and Type Detection (UPDATED)**\n\nAfter context clarification (Step 3.5), use the user's answers and gathered evidence to determine the appropriate analysis approach.\n\n---\n\n## Two-Dimensional Classification System\n\n**Dimension 1: Perspective** (Who is filming and why?)\n**Dimension 2: Content Type** (What's in the video?)\n\n### Perspective Classification\n\nDerive perspective from user's Q1 answer and evidence:\n\n| User's Q1 Answer | Perspective | Analysis Approach |\n|------------------|-------------|-------------------|\n| Tutorial/How-to | **First-Person Creator** | User is teaching/presenting |\n| Personal | **First-Person Creator** OR **Meta/Hybrid** | User is documenting their own life/activities |\n| Screen recording | **First-Person Creator** | User is demonstrating their own screen |\n| Watching something | **First-Person Viewer** | User is consuming someone else's content |\n| Event/Performance | **Third-Person Observer** | User is filming someone/something else |\n| Other/custom text | **Derive from description** | Analyze custom text to determine |\n\n### Expanded Content Type Taxonomy\n\nBased on perspective, select the appropriate content type analysis:\n\n---\n\n## First-Person Viewer Types\n\n**The user is watching/consuming content created by others**\n\n### Stream Viewer\n\n**Indicators**:\n\n- Visual: Streaming platform UI (Discord, Twitch, YouTube), others' stream content, BRB screens, chat visible\n- Audio: Music in viewer's space, ambient sounds, minimal commentary\n- Evidence: Streaming platform visible, user not the presenter/streamer\n\n**Analysis Focus**:\n\n- **Primary**: What stream/content is being watched? (streamer name, stream title, platform)\n- **Track**: BRB screens, waiting periods, stream states, chat activity\n- **Note**: Viewer's environment (workspace, room, objects visible)\n- **Look For**:\n  - Parallel activities (what is viewer doing while watching?)\n  - Music or ambient audio in viewer's space (distinct from stream audio)\n  - Environmental context and mood\n  - Correlation between stream content and viewer behavior\n\n### Reaction Video\n\n**Indicators**:\n\n- Visual: Split screen (content + reactor) or switches between content and reactions\n- Audio: Commentary over content, reactions, pauses for analysis\n- Evidence: User visible reacting to visible content\n\n**Analysis Focus**:\n\n- **Primary**: What content is being reacted to? User's reactions and commentary\n- **Track**: Reaction timing, pauses, emotional responses\n- **Note**: User's analysis, critiques, or engagement with content\n- **Look For**: Key moments that trigger reactions, commentary themes\n\n### Viewing Documentation\n\n**Indicators**:\n\n- Visual: Browser/player UI, content consumption in progress, informal framing\n- Audio: Background music, ambient sounds, casual environment\n- Evidence: Passive viewing being documented\n\n**Analysis Focus**:\n\n- **Primary**: What's being consumed, why is it being documented\n- **Track**: Viewing progression, pauses, environmental changes\n- **Note**: Mood, atmosphere, context for documentation\n- **Look For**: Artistic intent, thematic connections\n\n---\n\n## First-Person Creator Types\n\n**The user is creating/presenting content**\n\n### Tutorial/How-to\n\n**Indicators**:\n\n- Visual: Step-by-step demonstrations, hands visible, process shown\n- Audio: Instructional narration, explanations, process sounds\n- Evidence: Deliberate teaching structure\n\n**Analysis Focus**:\n\n- **Primary**: What's being taught, step-by-step process\n- **Track**: Instructions, materials/tools, technique demonstrations\n- **Note**: Key concepts, warnings, tips\n- **Look For**: Learning objectives, common mistakes addressed\n\n### Screen Recording (Creator)\n\n**Indicators**:\n\n- Visual: User's own screen with deliberate navigation, cursor movements, UI interactions\n- Audio: Voiceover tutorial, keyboard clicks, narration\n- Evidence: User demonstrating their own workflow\n\n**Analysis Focus**:\n\n- **Primary**: UI elements, workflow steps, applications used\n- **Track**: Mouse/cursor position, clicked elements, opened applications\n- **Note**: Workflow steps, error messages, command sequences\n- **Look For**: Transitions between applications, file operations, settings changes\n\n### Personal (Vlog/Life Content)\n\n**Indicators**:\n\n- Visual: Person on camera, home/outdoor settings, handheld or mounted camera\n- Audio: Direct-to-camera speech, personal narrative, ambient sounds\n- Evidence: User sharing personal moments or experiences\n\n**Analysis Focus**:\n\n- **Primary**: Setting/location, what person is saying/doing\n- **Track**: Emotional tone, activities, locations visited\n- **Note**: Personal details, narrative arc, objects/items shown\n- **Look For**: Story progression, mood shifts, environment changes\n\n### Presentation/Slides\n\n**Indicators**:\n\n- Visual: Slide layouts, bullet points, diagrams, presenter view\n- Audio: Presenter speaking, slide advance sounds\n- Evidence: Formal presentation structure\n\n**Analysis Focus**:\n\n- **Primary**: Slide content (headings, bullet points, data)\n- **Track**: Slide numbers, transitions, presenter appearance\n- **Note**: Key concepts, visualizations, quotes, formulas\n- **Look For**: Slide themes, speaker gestures, main arguments\n\n---\n\n## Meta/Hybrid Types\n\n**The user is documenting the process of creating/consuming**\n\n### Casual Documentation\n\n**Indicators**:\n\n- Visual: Informal framing, switches between activities, workspace visible, no clear structure\n- Audio: Ambient audio, music, casual speech, environmental sounds\n- Evidence: Informal recording of moments/activities\n\n**Analysis Focus**:\n\n- **Primary**: Activities happening, personal environment, objects/items\n- **Track**: Environmental changes, mood shifts, items introduced\n- **Note**: Personal details that provide context, atmosphere\n- **Look For**:\n  - Documentary-style observations\n  - Authentic, unscripted moments\n  - Connections between visual, audio, and thematic elements\n  - Artistic or experimental intent\n\n### Behind-the-Scenes\n\n**Indicators**:\n\n- Visual: Production equipment visible, setup shots, workspace, process in action\n- Audio: Technical discussions, process sounds, tools being used\n- Evidence: Documenting creation workflow\n\n**Analysis Focus**:\n\n- **Primary**: Creation process, tools/equipment, methodology\n- **Track**: Setup changes, workflow steps, technical decisions\n- **Note**: Challenges encountered, solutions implemented\n- **Look For**: Insights into creative/production process\n\n### Process Video\n\n**Indicators**:\n\n- Visual: Work-in-progress visible, tools/software, iterative changes\n- Audio: Narration of process, thinking out loud, work sounds\n- Evidence: Documenting work as it happens\n\n**Analysis Focus**:\n\n- **Primary**: Steps taken, decision-making, progress\n- **Track**: Iterations, changes, refinements\n- **Note**: Reasoning, challenges, solutions\n- **Look For**: Learning moments, key decisions\n\n---\n\n## Third-Person Observer Types\n\n**The user is filming someone/something else**\n\n### Event/Performance\n\n**Indicators**:\n\n- Visual: Stage/venue, audience, performers, event setting\n- Audio: Live audio, applause, ambient event noise\n- Evidence: User filming an event they're attending\n\n**Analysis Focus**:\n\n- **Primary**: Performers, performance content, venue\n- **Track**: Key performance moments, crowd reactions, technical elements\n- **Note**: Event highlights, special effects, atmosphere\n- **Look For**: Memorable moments, mistakes, energy shifts\n\n### Interview/Podcast\n\n**Indicators**:\n\n- Visual: Two+ people, static camera, simple background\n- Audio: Conversational dialogue, minimal music\n- Evidence: Discussion/interview being filmed\n\n**Analysis Focus**:\n\n**5. Visual Analysis with video-frame-analyzer Subagent(s)**\n\nAfter frames are extracted AND video type is assessed, delegate to the specialized **video-frame-analyzer** subagent(s) for systematic visual analysis:\n\n**Single Subagent (< 30 frames):**\nFor videos with fewer than 30 frames, use a single subagent:\n\n**IMPORTANT**: Use the full qualified subagent name: `video-toolkit:video-frame-analyzer`\n\n**Step 1: Assess Video Type (sample first 3-5 frames)**\n\nBefore full analysis, quickly review a few early frames to determine video type and appropriate analysis focus:\n\n```\nUse the video-toolkit:video-frame-analyzer subagent to assess video type from /tmp/video-toolkit-[timestamp]/frames\n\nSample frames 1-5 and determine:\n1. Video type (screen recording, vlog, presentation, music video, tutorial, etc.)\n2. Recommended analysis focus based on type (see Type-Specific Analysis Focus section)\n3. Key elements to track throughout the video\n\nSave assessment to: /tmp/video-toolkit-[timestamp]/video-type-assessment.md\n```\n\n**Step 2: Full Frame Analysis (with type-adaptive prompts)**\n\n```\nUse the video-toolkit:video-frame-analyzer subagent to analyze the frames in /tmp/video-toolkit-[timestamp]/frames\n\n**Video Type Detected:** [Insert detected type from assessment]\n\nThe following files are available:\n- Frames: /tmp/video-toolkit-[timestamp]/frames/*.png (X frames total)\n- Metadata: /tmp/video-toolkit-[timestamp]/frames/frames_metadata.json (contains frame timestamps)\n- Transcript: /tmp/video-toolkit-[timestamp]/transcript.md (if video has audio)\n- Audio Analysis: /tmp/video-toolkit-[timestamp]/audio_analysis.md (Gemini audio understanding, if available)\n- Music Identification: /tmp/video-toolkit-[timestamp]/music_identification.md (Shazam results, if music detected)\n- Video Type Assessment: /tmp/video-toolkit-[timestamp]/video-type-assessment.md\n\nBased on the detected video type, apply appropriate analysis focus:\n[Insert type-specific focus points from Type-Specific Analysis Focus section]\n\nAnalyze all frames, correlate visual content with transcript/audio using timestamps, and pay special attention to elements relevant for this video type.\n\nSave your complete analysis to: /tmp/video-toolkit-[timestamp]/video-analysis.md\n```\n\n**Parallel Subagents (≥ 30 frames):**\nFor videos with 30+ frames, **spawn multiple video-toolkit:video-frame-analyzer subagents in parallel**, each handling a subset of frames:\n\n**IMPORTANT**:\n- Use the full qualified subagent name: `video-toolkit:video-frame-analyzer`\n- Use a single message with multiple Task tool calls to run agents in parallel\n\nExample for 50 frames:\n\n```\n# Spawn 5 subagents in parallel, each analyzing 10 frames\n# Agent 1: frames 1-10\n# Agent 2: frames 11-20\n# Agent 3: frames 21-30\n# Agent 4: frames 31-40\n# Agent 5: frames 41-50\n```\n\n**How to split frames:**\n\n- **30-50 frames**: 3-5 subagents (10 frames each) - launch all in parallel\n- **50-100 frames**: 5-10 subagents (10 frames each) - launch in waves of 5\n- **100+ frames**: Consider using interval mode instead, or max 10 subagents in waves\n\n**Staged Execution for Long Videos:**\nFor videos requiring more than 5 subagents, launch them in **waves** to avoid overwhelming the system:\n\n**Example: 100 frames = 10 subagents**\n\n- **Wave 1**: Launch subagents 1-5 in parallel (frames 1-50)\n- Wait for Wave 1 to complete\n- **Wave 2**: Launch subagents 6-10 in parallel (frames 51-100)\n- Wait for Wave 2 to complete\n- Synthesize all results\n\n**Why staged execution?**\n\n- Prevents too many concurrent subagents\n- Better resource management\n- Easier to debug if something fails\n- More predictable performance\n\n**Prompt for parallel subagents:**\n\n**IMPORTANT**:\n1. First, assess video type with a quick subagent analyzing frames 1-5\n2. Then create the `partial-analyses/` directory: `mkdir -p /tmp/video-toolkit-[timestamp]/partial-analyses`\n3. Launch parallel subagents with type-aware prompts\n\n**Step 1: Quick Video Type Assessment**\n\n```\nUse the video-toolkit:video-frame-analyzer subagent to assess video type from frames 1-5 in /tmp/video-toolkit-[timestamp]/frames\n\nSample the first 5 frames and determine:\n1. Video type (screen recording, vlog, presentation, music video, tutorial, interview, documentary, gameplay, event, animation)\n2. Recommended analysis focus based on type\n3. Key elements to track throughout\n\nReview audio analysis if available to help determine type.\n\nSave assessment to: /tmp/video-toolkit-[timestamp]/video-type-assessment.md\n```\n\n**Step 2: Type-Adaptive Parallel Analysis**\n\nAfter video type is assessed, use this prompt template for each parallel subagent:\n\n```\nUse the video-toolkit:video-frame-analyzer subagent to analyze frames [start]-[end] from /tmp/video-toolkit-[timestamp]/frames\n\n**Video Type:** [Insert type from assessment]\n**Analysis Focus:** [Insert relevant focus points for this type]\n\nFiles available:\n- Frames: frame_00[start].png through frame_00[end].png\n- Metadata: /tmp/video-toolkit-[timestamp]/frames/frames_metadata.json\n- Transcript: /tmp/video-toolkit-[timestamp]/transcript.md (if available)\n- Audio Analysis: /tmp/video-toolkit-[timestamp]/audio_analysis.md (if available)\n- Video Type Assessment: /tmp/video-toolkit-[timestamp]/video-type-assessment.md\n\nFocus on frames [start] through [end] only. Based on video type, provide:\n1. Timestamp range covered\n2. Visual content description (emphasize type-specific elements)\n3. Key elements for this video type (UI/text for screen recordings, actions/setting for vlogs, etc.)\n4. Scene changes within your range\n5. Correlation with transcript/audio (if applicable)\n\nSave your analysis to: /tmp/video-toolkit-[timestamp]/partial-analyses/part[N].md\n```\n\n**Example for Vlog/Personal Video:**\n\n```\nUse the video-toolkit:video-frame-analyzer subagent to analyze frames 1-12 from /tmp/video-toolkit-[timestamp]/frames\n\n**Video Type:** Vlog/Personal\n**Analysis Focus:**\n- Primary: Setting/location, people present, activities happening\n- Track: Emotional tone, interactions, objects/items shown\n- Note: What person is doing, wearing, holding\n- Look For: Personal details (smoking, eating, gestures), environment changes\n\nFiles available:\n- Frames: frame_0001.png through frame_0012.png\n- Metadata: /tmp/video-toolkit-[timestamp]/frames/frames_metadata.json\n- Transcript: /tmp/video-toolkit-[timestamp]/transcript.md\n- Audio Analysis: /tmp/video-toolkit-[timestamp]/audio_analysis.md\n- Video Type Assessment: /tmp/video-toolkit-[timestamp]/video-type-assessment.md\n\nFocus on frames 1-12. Provide:\n1. Timestamp range: 0:00 - 0:22\n2. Visual content: Describe setting, people, activities with attention to personal details\n3. Personal elements: Note smoking, gestures, objects held, clothing, emotional state\n4. Scene/environment changes within this range\n5. Correlation with what's being said (transcript) and music/ambient audio\n\nSave your analysis to: /tmp/video-toolkit-[timestamp]/partial-analyses/part1.md\n```\n\n**Example Task tool invocation:**\n```python\n# First create the directory\nBash(\"mkdir -p /tmp/video-toolkit-[timestamp]/partial-analyses\")\n\n# Then spawn parallel subagents\nTask(\n    subagent_type=\"video-toolkit:video-frame-analyzer\",\n    description=\"Analyze frames 1-13\",\n    prompt=\"Analyze frames 1-13... Save to: /tmp/video-toolkit-[timestamp]/partial-analyses/part1.md\"\n)\n```\n\n**After parallel analysis completes:**\n\n1. Read all partial analyses from `partial-analyses/` directory (part1.md, part2.md, etc.)\n2. Synthesize into a unified comprehensive summary file at `/tmp/video-toolkit-[timestamp]/video-analysis.md`\n3. Correlate findings across all sections\n4. Clean up: `rm -rf /tmp/video-toolkit-[timestamp]/partial-analyses`\n5. **Save comprehensive analysis alongside source video** (see step 7 in Combined Summary Generation below)\n6. Present final summary to user\n\n**What the subagent(s) do:**\n\n- **Read frames_metadata.json** for accurate frame-to-timestamp mapping\n- **Read transcript.md** (if available) for audio content\n- Systematically analyze assigned frames using vision capabilities\n- **Correlate visual content with spoken dialogue** using timestamps\n- Identify video type, UI elements, text, and visual patterns\n- Generate analysis with multimodal correlation\n\n\n- **Note**: Important quotes, key points, visual aids\n- **Look For**: Emotional moments, agreements/disagreements\n\n### Documentary\n\n**Indicators**:\n\n- Visual: B-roll footage, archival material, location shots, graphics\n- Audio: Narrator voiceover, ambient audio, music\n- Evidence: Documentary storytelling structure\n\n**Analysis Focus**:\n\n- **Primary**: B-roll content, archival material, locations\n- **Track**: Text overlays (names, dates, locations), graphics\n- **Note**: Historical context, expert interviews, data\n- **Look For**: Primary sources, reenactments, maps/timelines\n\n---\n\n## Using the Classification\n\nAfter determining **perspective** and **content type** from Step 3.5 context clarification:\n\n1. **Select the appropriate analysis focus** from the tables above\n2. **Apply type-specific guidance** to visual analysis (Step 5)\n3. **Use correct terminology** in subagent prompts and final summary\n4. **Avoid misidentification** by respecting the user's stated relationship to the content\n\n**Example for \"Stream Viewer\" (First-Person Viewer)**:\n\n```python\nvideo_metadata = {\n    \"video_type\": \"Watching something\",\n    \"perspective\": \"First-Person Viewer\",\n    \"content_type\": \"Stream Viewer\",\n    \"context_tags\": [\"live stream\", \"music playing\"],\n    \"analysis_focus\": {\n        \"primary\": \"Stream content being watched, viewer's environment\",\n        \"track\": \"BRB screens, stream states, workspace, parallel activities\",\n        \"note\": \"Music in viewer's space, environmental context, mood\",\n        \"look_for\": \"Correlation between stream and viewer behavior, thematic connections\"\n    }\n}\n```\n\nThis metadata guides all subsequent analysis steps.\n\n---\n\n# Restructured Workflow: Optional Song Theme Research\n\n## Current Issue\n\nSong theme research (Step 3d) currently happens automatically after music identification, but:\n\n- Not all videos need thematic music analysis\n- Tutorial with background music? Music is just ambiance\n- Screen recording with Spotify playing? Not relevant to content\n- Wastes time/tokens when music isn't thematically important\n\n## Solution: Move to After Context Clarification\n\n**New sequence**:\n\n1. Frame Extraction\n2. Audio Extraction\n3. Audio Analysis (Sequential Workflow)\n   - 3a. Speech Transcription (Whisper)\n   - 3b. Audio Understanding (Gemini)\n   - 3c. Music Identification (Shazam - if music detected)\n   - ~~3d. Song Theme Research~~ ← **REMOVE FROM HERE**\n4. Context Clarification (NEW - Step 3.5)\n5. Video Perspective and Type Detection\n6. **OPTIONAL: Song Theme Research** ← **MOVE TO HERE (becomes Step 5.5)**\n7. Visual Analysis with subagents\n\n## When to Research Song Themes (Conditional Logic)\n\n**Research song themes IF**:\n\n- Video type suggests thematic music importance\n- User context indicates artistic/creative intent\n- Music plays during significant portions of video\n- Multiple perspective/content switches suggest deliberate choices\n\n**Skip song theme research IF**:\n\n- Video type is purely functional (tutorial, screen recording demo)\n- Music is brief background ambiance\n- User context suggests music is incidental\n- Analysis focus doesn't benefit from song meaning\n\n---\n\n## Step 5.5: Optional Song Theme Research (NEW)\n\n**When to Use**: After determining video type and perspective (Steps 3.5 and 4), conditionally research song themes if music appears thematically relevant.\n\n### Decision Logic\n\n**Research song themes for these video types**:\n\n| Video Type | Perspective | When to Research | Reasoning |\n|------------|-------------|------------------|-----------|\n| **Stream Viewer** | First-Person Viewer | ✅ USUALLY | Music in viewer's space may have thematic connection to stream content or mood |\n| **Casual Documentation** | Meta/Hybrid | ✅ USUALLY | Artistic/creative videos often use music deliberately |\n| **Personal** | First-Person Creator | ✅ IF ARTISTIC | Only if video seems artistic/experimental vs. casual life clip |\n| **Music Video/Creative** | First-Person Creator | ✅ ALWAYS | Music is the primary content |\n| **Vlog/Personal** | First-Person Creator | ⚠️ CONDITIONAL | Only if music plays significant role |\n| **Behind-the-Scenes** | Meta/Hybrid | ⚠️ CONDITIONAL | Only if music seems intentionally chosen |\n| **Tutorial/How-to** | First-Person Creator | ❌ SKIP | Music is background, not thematic |\n| **Screen Recording** | First-Person Creator | ❌ SKIP | Music is incidental (Spotify/background) |\n| **Presentation** | First-Person Creator | ❌ SKIP | Music not relevant to content |\n| **Event/Performance** | Third-Person Observer | ❌ SKIP | Music is part of event, not selected |\n\n### Conditional Check\n\nBefore researching song themes, evaluate:\n\n```python\ndef should_research_song_themes(video_metadata, music_data):\n    \"\"\"\n    Determine if song theme research would benefit analysis\n\n    Args:\n        video_metadata: From Step 3.5 context clarification\n        music_data: From Step 3c music identification\n\n    Returns:\n        bool: True if research would be valuable\n    \"\"\"\n\n    # No music detected? Skip\n    if not music_data.get(\"has_music\"):\n        return False\n\n    # Check video type thematic relevance\n    video_type = video_metadata[\"video_type\"]\n    perspective = video_metadata[\"perspective\"]\n\n    # Always research for these types\n    always_research = [\n        \"Music Video/Creative\",\n        \"Watching something\" + \"First-Person Viewer\",  # Stream viewer\n        \"Casual documentation\" + \"Meta/Hybrid\"\n    ]\n\n    # Never research for these types\n    skip_research = [\n        \"Tutorial/How-to\",\n        \"Screen recording\" + \"First-Person Creator\",\n        \"Presentation\",\n        \"Event/Performance\"\n    ]\n\n    # Check if video type + perspective matches \"always\" patterns\n    if any(pattern in f\"{video_type} + {perspective}\" for pattern in always_research):\n        return True\n\n    # Check if video type matches \"skip\" patterns\n    if any(pattern in video_type for pattern in skip_research):\n        return False\n\n    # Conditional cases - check additional factors\n\n    # Music duration significant? (>30% of video)\n    music_duration = sum(segment[\"duration\"] for segment in music_data[\"music_segments\"])\n    video_duration = video_metadata[\"evidence\"][\"duration\"]\n\n    if music_duration / video_duration > 0.3:\n        return True  # Music plays significant role\n\n    # User context suggests artistic intent?\n    context_tags = video_metadata.get(\"context_tags\", [])\n    if \"artistic/experimental\" in context_tags:\n        return True\n\n    # Default: skip unless evidence suggests thematic importance\n    return False\n```\n\n### Implementation\n\n**If research is warranted:**\n\n```python\nif should_research_song_themes(video_metadata, music_data):\n    # Research themes for each identified song\n    for song in music_data[\"songs\"]:\n        query = f\"{song['title']} {song['artist']} lyrics meaning themes\"\n\n        # Try Perplexity first (better for analysis)\n        try:\n            results = mcp__perplexity_search_web(query, recency=\"year\")\n            song[\"themes\"] = extract_themes(results)\n        except:\n            # Fallback to WebSearch if Perplexity unavailable\n            results = WebSearch(query)\n            song[\"themes\"] = extract_themes(results)\n\n    # Store theme research in metadata\n    video_metadata[\"song_themes\"] = {\n        song[\"title\"]: song[\"themes\"] for song in music_data[\"songs\"]\n    }\nelse:\n    # Skip research, note music was identified but themes not needed\n    video_metadata[\"song_themes\"] = None\n    # Music identification results still available in music_data\n```\n\n**Communicate decision to user:**\n\n```markdown\n✓ Music identified: \"Song Title\" by Artist Name (2009)\n✓ Researching song themes (video appears to use music thematically)\n  → Themes: song themes and meaning\n```\n\nOR\n\n```markdown\n✓ Music identified: \"Background Music Track\" (ambient)\n⊘ Skipping theme research (background music, not thematically relevant)\n```\n\n### Benefits\n\n1. **Efficiency**: Don't waste time/tokens on irrelevant research\n2. **Precision**: Only research when it enhances understanding\n3. **User experience**: Clear communication about what's happening\n4. **Flexibility**: Easy to adjust criteria based on video type\n\n### Example Decisions\n\n**Example 1: Stream Viewer Video (Em's case)**\n\n- Video type: \"Watching something\" (Stream Viewer)\n- Music: \"Song Title\" playing 0:32-1:57 (85% of video duration)\n- Decision: ✅ **Research themes** - music significant + viewer perspective\n- Result: Themes inform understanding of why this song was chosen\n\n**Example 2: Coding Tutorial**\n\n- Video type: \"Tutorial/How-to\"\n- Music: Lo-fi beats playing throughout\n- Decision: ❌ **Skip research** - background ambiance for focus\n- Result: Music noted but themes not analyzed\n\n**Example 3: Personal Phone Clip**\n\n- Video type: \"Personal\"\n- Music: 10 seconds of radio in background\n- Context tags: None suggesting artistic intent\n- Music duration: 10s / 120s = 8%\n- Decision: ❌ **Skip research** - incidental background music\n- Result: Music noted but not analyzed\n\n**Example 4: Artistic Video Essay**\n\n- Video type: \"Personal\"\n- Music: Specific song playing throughout\n- Context tags: [\"artistic/experimental\"]\n- Music duration: 90s / 100s = 90%\n- Decision: ✅ **Research themes** - artistic intent + significant duration\n- Result: Themes analyzed for artistic interpretation\n\n---\n\n## Updated SKILL.md Structure\n\n```markdown\n**3. Audio Analysis (Sequential Workflow)**\n- 3a. Speech Transcription (Whisper)\n- 3b. Audio Understanding (Gemini)\n- 3c. Music Identification (Shazam - if music detected)\n\n\n*6. Combined Summary Generation**\n\nAfter the video-frame-analyzer completes its analysis, synthesize all multimodal insights:\n\n**Available Analysis Files:**\n- `video-type-assessment.md` - Video type and analysis strategy\n- `transcript.md` - Speech transcription (Whisper)\n- `audio_analysis.md` - Audio understanding (Gemini)\n- `music_identification.md` - Identified songs (Shazam, if music detected)\n- `video-analysis.md` - Visual analysis (video-frame-analyzer, type-aware)\n- `reconciled_transcript.md` - Reconciled transcript (optional, created by comparing Whisper + Gemini)\n\n**Synthesis Steps:**\n1. Review video type assessment to understand analysis context\n2. Review visual analysis from video-frame-analyzer (type-aware analysis)\n3. If music was identified, review song themes from web search for thematic context\n4. **Compare and reconcile transcripts** (OPTIONAL):\n   - **ALWAYS spawn a Task subagent (general-purpose) to compare transcripts** (reduces token usage in main thread)\n   - The subagent should:\n     - Read both `transcript.md` (Whisper) and `audio_analysis.md` (Gemini) for speech content\n     - Note that Whisper specializes in speech transcription but can mishear words\n     - Note that Gemini Audio API also transcribes speech and may catch errors Whisper missed\n     - **Compare the two transcripts** and identify any discrepancies\n     - Use context, grammar, and semantic meaning to determine which is more accurate\n     - Create a reconciled transcript that uses the most accurate version\n     - Document any significant differences and reasoning for choices\n     - Save the reconciled transcript to `/tmp/video-toolkit-[timestamp]/reconciled_transcript.md`\n   - After subagent completes, read the reconciled transcript for use in synthesis\n3. Review audio analysis for non-speech sounds and music description\n4. If music was identified, review song details with timestamps\n5. **Correlate all insights using timestamps** to create unified narrative\n6. Identify synchronization between:\n   - What's visible (frames)\n   - What's said (Whisper)\n   - What's heard (Gemini audio)\n   - What music is playing (Shazam)\n7. **IMPORTANT: Save comprehensive analysis alongside source video**\n   - Copy `/tmp/video-toolkit-[timestamp]/video-analysis.md` to replace the placeholder analysis file\n   - Target location: `<video-directory>/<video-name>-analysis.md`\n   - This ensures the detailed analysis persists alongside the source video\n   - Example: `cp /tmp/video-toolkit-1234567890/video-analysis.md \"/path/to/video-analysis.md\"`\n8. Present comprehensive multimodal summary to user\n\n*7. Discussion and Follow-up**\n\nAfter generating summary:\n\n- Present findings in markdown format\n- Enable conversational follow-up questions\n- Offer to extract specific clips or moments\n- Provide additional analysis on request\n\n### Video Editing Workflow\n\nFor video editing operations, use `scripts/edit_video.py`:\n\n**Clip Video (Extract Segment)**\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/edit_video.py clip <input_video> <start_time> <end_time> <output_video>\n```\n\n- `start_time`: Format HH:MM:SS or MM:SS or seconds\n- `end_time`: Format HH:MM:SS or MM:SS or seconds\n- Example: `${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/edit_video.py clip video.mp4 00:01:30 00:02:45 clip.mp4`\n\n**Merge Videos (Concatenate)**\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/edit_video.py merge <output_video> <input1> <input2> [input3...]\n```\n\n- Concatenates multiple videos in order\n- Videos should have same codec/resolution for best results\n- Example: `${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/edit_video.py merge final.mp4 part1.mp4 part2.mp4 part3.mp4`\n\n**Split Video (By Duration)**\n\n```bash\n${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/edit_video.py split <input_video> <segment_duration> <output_prefix>\n```\n\n- `segment_duration`: Length of each segment in seconds\n- `output_prefix`: Prefix for output files (e.g., \"segment\" → segment_001.mp4, segment_002.mp4)\n- Example: `${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/.venv/bin/python3 ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/edit_video.py split long_video.mp4 300 chunk`\n\n### Orchestration Script (All-in-One Analysis)\n\nFor comprehensive analysis, use the orchestration wrapper with clear flag-based arguments:\n\n```bash\n# Basic usage (uses interval mode with 2s default - safest for most videos)\nbash ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/analyze_video.sh video.mp4\n\n# Interval mode with custom interval\nbash ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/analyze_video.sh video.mp4 --interval 3\n\n# Scene detection mode (for videos with clear scene changes like movies)\nbash ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/analyze_video.sh video.mp4 --mode scene-detect --threshold 0.05\n\n# With custom whisper model\nbash ${CLAUDE_PLUGIN_ROOT}/skills/video-toolkit/scripts/analyze_video.sh video.mp4 --interval 2 --whisper-model small\n```\n\n**Available Options:**\n\n- `--mode <scene-detect|interval>` - Frame extraction mode (default: interval)\n- `--threshold <value>` - Scene detection threshold 0.0-1.0 (default: 0.02)\n- `--interval <seconds>` - Interval between frames (default: 2)\n- `--whisper-model <model>` - Whisper model: tiny.en, base, small, medium, large (default: base)\n- `--help` - Show usage information\n\nThis script:\n\n1. Creates temporary working directory\n2. Extracts frames at specified interval\n3. Extracts audio\n4. Transcribes speech with Whisper (local)\n5. Analyzes audio with Gemini (API)\n6. If music detected, identifies songs with Shazam (API)\n7. Organizes results in structured format\n8. Returns paths to all artifacts\n\n**Returns:**\n\n- `frames/`: Directory of extracted frames\n- `frames/frames_metadata.json`: Frame timestamps\n- `audio.wav`: Extracted audio file\n- `transcript.md`: Speech transcription (Whisper)\n- `audio_analysis.md`: Audio understanding (Gemini)\n- `music_identification.md`: Song identification (Shazam, if music detected)\n- `analysis-summary.md`: Overview and next steps\n\n## Bundled Resources\n\n### Scripts\n\n**`scripts/install_dependencies.sh`**\n\n- Install FFmpeg, Python venv, Whisper, Gemini API, and Shazam\n- One-time setup, run on first use\n- Checks for existing installations\n\n**`scripts/setup_api_keys.py`**\n\n- Configure Gemini API key for audio analysis\n- Configure Shazam API key (optional, uses public endpoint by default)\n- Validates and saves API keys to config file\n\n**`scripts/extract_frames.py`**\n\n- FFmpeg-based frame extraction\n- Configurable interval and scene detection modes\n- Generates frames_metadata.json with timestamps\n- Efficient processing for long videos\n\n**`scripts/extract_audio.py`**\n\n- Extract audio track to WAV format\n- Handles various input codecs\n- Whisper-compatible output\n\n**`scripts/transcribe_audio.py`**\n\n- Whisper integration for speech transcription\n- Model selection support (tiny.en, base, small, medium, large)\n- Timestamped output with metadata\n- Runs locally (no API key required)\n\n**`scripts/analyze_audio_gemini.py`**\n\n- Gemini Audio API integration for comprehensive audio analysis\n- Detects music with precise timestamps\n- Identifies non-speech sounds and audio events\n- Returns markdown + JSON with music segments\n\n**`scripts/identify_music.py`**\n\n- Shazam integration for music identification\n- Extracts music segments based on Gemini timestamps\n- Identifies songs with title, artist, album, genre\n- Only runs if Gemini detected music\n\n**`scripts/edit_video.py`**\n\n- Unified editing tool (clip, merge, split)\n- FFmpeg-based for reliability\n- Error handling and validation\n\n**`scripts/analyze_video.sh`**\n\n- Orchestration wrapper for full analysis\n- Persists final summary alongside source video\n- Automatic cleanup of temporary files\n- Structured output format\n\n### References\n\n**`references/ffmpeg_commands.md`**\n\n- Common FFmpeg commands and patterns\n- Codec information and best practices\n- Troubleshooting guide\n\n## File Management\n\n**Final Analysis Summary:**\n\nThe complete analysis summary is automatically saved alongside the source video:\n\n- **Location**: Same directory as the source video\n- **Filename**: `<video-name>-analysis.md` (e.g., `test-analysis.md` for `test.mov`)\n- **Format**: Markdown with YAML frontmatter\n- **Persistence**: Permanent (lives next to your video file)\n\n**Temporary Working Files:**\n\nDuring analysis, temporary files are created in `/tmp/video-toolkit-{timestamp}/`:\n\n- **Frames**: `frames/` subdirectory with extracted PNG files\n- **Audio**: `audio.wav` (if video has audio)\n- **Transcript**: `transcript.md` with timestamped speech\n- **Audio Analysis**: `audio_analysis.md` (Gemini output)\n- **Music Identification**: `music_identification.md` (Shazam output, if music detected)\n\n**Cleanup Workflow:**\n\nAfter completing video analysis, **ALWAYS** use the **AskUserQuestion** tool to ask the user:\n\n```\nQuestion: \"Would you like me to keep these analysis files, or should I clean them up?\"\nOptions:\n- \"Clean up temporary files\" → Run: rm -rf /tmp/video-toolkit-{timestamp}\n  (Keeps only the persisted summary: <video-name>-analysis.md)\n- \"Keep everything\" → Inform user of /tmp location for frames/audio/transcripts\n  (User responsible for manual cleanup later)\n```\n\n**Important Notes:**\n\n- The final summary (`<video-name>-analysis.md`) is **always persisted** alongside the source video\n- Temporary files in `/tmp` contain frames, audio, transcripts (can be large)\n- User may want to keep frames for visual analysis or audio for further processing\n- If keeping files, remind user that `/tmp` persists until reboot or ~3 days on macOS\n\n**Manual Cleanup Commands (rarely needed):**\n\n```bash\n# Check if any temp files remain (shouldn't happen)\nls -lh /tmp/video-toolkit-*\n\n# Clean all video-toolkit temp files (if automatic cleanup failed)\nrm -rf /tmp/video-toolkit-*\n\n# Check disk usage in /tmp\ndu -sh /tmp/video-toolkit-* 2>/dev/null || echo \"No temp files found (good!)\"\n```\n\n## Output Format\n\n**Analysis Summary Template:**\n\n```markdown\n# Video Analysis: {filename}\n\n## Overview\n- **Duration**: MM:SS\n- **Resolution**: WxH\n- **File Size**: XX MB\n- **Analysis Date**: YYYY-MM-DD\n\n## Transcript\n[Timestamped transcript from Whisper]\n\n## Visual Analysis\n### Scene 1 (00:00 - 00:XX)\n- Frame descriptions\n- Key moments\n- Visual details\n\n### Scene 2 (00:XX - 00:XX)\n...\n\n## Key Highlights\n- Important moments\n- Notable quotes\n- Visual highlights\n\n## Summary\nOverall narrative and insights\n\n---\n*Generated by video-toolkit v1.0.0*\n```\n\n## Examples\n\n**Example 1: Analyze Meeting Recording**\n\n```\nUser: Can you analyze this meeting recording and summarize the key points?\n\nClaude:\n1. Run analyze_video.sh on the meeting file\n2. Extract frames every 5 seconds\n3. Transcribe audio with Whisper (base model)\n4. Analyze slides/screen sharing in frames\n5. Identify speakers and topics from transcript\n6. Generate summary with:\n   - Meeting agenda items\n   - Decisions made\n   - Action items\n   - Key discussion points\n```\n\n**Example 2: Extract Highlight Clip**\n\n```\nUser: Extract the segment from 2:30 to 4:15 from this video\n\nClaude:\npython scripts/edit_video.py clip input.mp4 00:02:30 00:04:15 highlight.mp4\n```\n\n**Example 3: Combine Multiple Clips**\n\n```\nUser: Merge these three video files into one\n\nClaude:\npython scripts/edit_video.py merge final_video.mp4 clip1.mp4 clip2.mp4 clip3.mp4\n```\n\n## Troubleshooting\n\n**FFmpeg Not Found:**\n\n- Run `scripts/install_dependencies.sh`\n- Or install manually: `brew install ffmpeg` (macOS) or `apt install ffmpeg` (Linux)\n\n**Whisper Model Download Slow:**\n\n- Models download on first use\n- Models cached in `~/.cache/whisper/`\n\n## Best Practices\n\n1. **Frame Interval Selection**\n   - Action videos: 1-2 seconds\n   - Dialogue/presentations: 3-5 seconds\n   - Surveillance/static: 10+ seconds\n\n2. **Whisper Model Selection**\n   - Quick analysis: tiny.en or base\n   - Important transcription: medium or large\n   - Non-English: Use multilingual models (not .en)\n\n3. **Temp File Management**\n   - Clean up after analysis unless user asks to keep\n   - Monitor disk space for long videos\n   - Use `/tmp` for automatic cleanup on reboot\n\n4. **Video Editing**\n   - Keep original files safe (don't overwrite)\n   - Use descriptive output filenames\n   - Check codec compatibility for merging"
              }
            ]
          },
          {
            "name": "claude-agent-sdk-dev",
            "description": "Development tools and documentation for building applications with the Claude Agent SDK. Covers Python and TypeScript APIs, core features, advanced features, and integrations.",
            "source": "./plugins/claude-agent-sdk-dev",
            "category": "development-tools",
            "version": "0.1.0",
            "author": {
              "name": "Em"
            },
            "install_commands": [
              "/plugin marketplace add emdashcodes/claude-code-plugins",
              "/plugin install claude-agent-sdk-dev@emdashcodes-claude-code-plugins"
            ],
            "signals": {
              "stars": 4,
              "forks": 1,
              "pushed_at": "2026-01-08T19:24:31Z",
              "created_at": "2025-10-18T01:20:32Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "claude-agent-sdk",
                "description": "This skill should be used when developing applications with the Claude Agent SDK, answering questions about SDK features and APIs, implementing SDK patterns, or troubleshooting SDK integration. Covers Python and TypeScript APIs, core features, advanced features, and integrations.",
                "path": "plugins/claude-agent-sdk-dev/skills/claude-agent-sdk/SKILL.md",
                "frontmatter": {
                  "name": "claude-agent-sdk",
                  "description": "This skill should be used when developing applications with the Claude Agent SDK, answering questions about SDK features and APIs, implementing SDK patterns, or troubleshooting SDK integration. Covers Python and TypeScript APIs, core features, advanced features, and integrations.",
                  "allowed-tools": "Read, Write, Edit, Bash, Glob, Grep, WebFetch"
                },
                "content": "# Claude Agent SDK Development\n\n## Overview\n\nThis skill provides comprehensive documentation and development guidance for building applications with the Claude Agent SDK. Use this skill when working with Claude Agent SDK based applications, implementing SDK features, or answering questions about SDK capabilities in both Python and TypeScript.\n\nThe Claude Agent SDK enables building conversational AI agents with access to tools, multi-turn sessions, streaming, structured outputs, and extensibility through Skills, Plugins, Slash Commands, and Subagents.\n\n## When to Use This Skill\n\nActivate this skill when:\n\n- Building new applications using the Claude Agent SDK\n- Implementing SDK features (sessions, permissions, streaming, structured outputs)\n- Adding extensibility (Skills, Plugins, Slash Commands, Subagents, MCP)\n- Integrating custom tools or external APIs\n- Troubleshooting SDK issues or migration from legacy implementations\n- Answering questions about SDK capabilities, APIs, or best practices\n- Setting up hosting and deployment for SDK applications\n- Implementing cost tracking and usage monitoring\n\n## Quick Start\n\n### API References\n\nThe SDK is available in both Python and TypeScript. For detailed API documentation, reference:\n\n- **Python API**: `references/agent-sdk_python.md`\n- **TypeScript API**: `references/agent-sdk_typescript.md`\n\n### Getting Started\n\nFor SDK overview and core concepts, reference:\n\n- **Overview**: `references/agent-sdk_overview.md`\n\n## Core Features\n\n### 1. Session Management\n\nSessions enable multi-turn conversations with state persistence. To implement sessions:\n\n**Reference**: `references/agent-sdk_sessions.md`\n\n**Key concepts**:\n\n- Creating and managing sessions\n- Persisting conversation state\n- Resuming sessions across requests\n- Session lifecycle and cleanup\n\n**When to reference**: When implementing multi-turn conversations, state persistence, or conversation continuity.\n\n### 2. Permissions System\n\nThe SDK includes a permissions system for controlling tool access and user approval flows.\n\n**Reference**: `references/agent-sdk_permissions.md`\n\n**Key concepts**:\n\n- Defining tool permissions\n- Implementing approval workflows\n- Permission tiers (auto-approve, prompt, deny)\n- Batch permission handling\n\n**When to reference**: When implementing tool restrictions, user approval flows, or security controls.\n\n### 3. System Prompt Modification\n\nCustomize agent behavior by modifying system prompts.\n\n**Reference**: `references/agent-sdk_modifying-system-prompts.md`\n\n**Key concepts**:\n\n- Overriding default system prompts\n- Adding custom instructions\n- Combining with Skills and Plugins\n- Best practices for prompt engineering\n\n**When to reference**: When customizing agent behavior, adding domain expertise, or implementing specialized agent personalities.\n\n### 4. Streaming vs Single-Turn Mode\n\nThe SDK supports both streaming and single-turn modes for different use cases.\n\n**Reference**: `references/agent-sdk_streaming-vs-single-mode.md`\n\n**Key concepts**:\n\n- Streaming for real-time responses\n- Single-turn for batch processing\n- Trade-offs and performance considerations\n- Implementation patterns\n\n**When to reference**: When deciding on interaction mode, implementing real-time UIs, or optimizing for specific use cases.\n\n### 5. Structured Outputs\n\nGenerate structured data with schema validation and type safety.\n\n**Reference**: `references/agent-sdk_structured-outputs.md`\n\n**Key concepts**:\n\n- Defining output schemas\n- JSON schema validation\n- Type-safe responses\n- Error handling\n\n**When to reference**: When generating structured data, implementing type-safe responses, or validating outputs.\n\n## Advanced Features\n\n### 1. Agent Skills\n\nSkills provide specialized knowledge and workflows to agents.\n\n**Reference**: `references/agent-sdk_skills.md`\n\n**Key concepts**:\n\n- Creating and registering Skills\n- Skill structure (SKILL.md, scripts, references, assets)\n- Skill activation and context loading\n- Distributing Skills\n\n**When to reference**: When adding specialized capabilities, domain knowledge, or reusable workflows to agents.\n\n### 2. Plugins\n\nPlugins bundle multiple components (Skills, Slash Commands, Subagents, Hooks, MCP servers) for distribution.\n\n**Reference**: `references/agent-sdk_plugins.md`\n\n**Key concepts**:\n\n- Plugin architecture\n- Creating plugin packages\n- Plugin manifest (plugin.json)\n- Distribution via marketplaces\n\n**When to reference**: When bundling related components, distributing tools, or creating reusable agent extensions.\n\n### 3. Slash Commands\n\nSlash Commands are user-invoked shortcuts that expand to prompts.\n\n**Reference**: `references/agent-sdk_slash-commands.md`\n\n**Key concepts**:\n\n- Creating slash commands\n- Command arguments and parameters\n- Integration with bash scripts\n- Command discovery\n\n**When to reference**: When implementing user-triggered workflows, shortcuts, or custom operations.\n\n### 4. Subagents\n\nSubagents are specialized agents with custom system prompts and tool access.\n\n**Reference**: `references/agent-sdk_subagents.md`\n\n**Key concepts**:\n\n- Creating subagent configurations\n- Tool permission scoping\n- Agent specialization patterns\n- Subagent invocation\n\n**When to reference**: When implementing specialized agents, task delegation, or multi-agent workflows.\n\n## Tools & Integration\n\n### 1. Custom Tools\n\nExtend agent capabilities with custom tools.\n\n**Reference**: `references/agent-sdk_custom-tools.md`\n\n**Key concepts**:\n\n- Tool definition schemas\n- Implementing tool handlers\n- Parameter validation\n- Error handling\n\n**When to reference**: When adding custom functionality, integrating APIs, or extending agent capabilities.\n\n### 2. MCP (Model Context Protocol)\n\nIntegrate external tools and services via MCP.\n\n**Reference**: `references/agent-sdk_mcp.md`\n\n**Key concepts**:\n\n- MCP server configuration\n- Tool discovery and registration\n- Connection management\n- MCP protocol implementation\n\n**When to reference**: When integrating external tools, databases, or third-party services.\n\n### 3. Hosting & Deployment\n\nDeploy SDK applications in production environments.\n\n**Reference**: `references/agent-sdk_hosting.md`\n\n**Key concepts**:\n\n- Deployment architectures\n- Environment configuration\n- Scaling considerations\n- Security best practices\n\n**When to reference**: When deploying to production, configuring infrastructure, or optimizing performance.\n\n### 4. Todo Lists\n\nImplement task tracking and progress visualization.\n\n**Reference**: `references/agent-sdk_todo-tracking.md`\n\n**Key concepts**:\n\n- Todo list API\n- Task state management\n- Progress tracking\n- UI integration\n\n**When to reference**: When implementing task tracking, progress visualization, or multi-step workflows.\n\n### 5. Cost Tracking & Usage Monitoring\n\nMonitor API usage and costs.\n\n**Reference**: `references/agent-sdk_cost-tracking.md`\n\n**Key concepts**:\n\n- Usage tracking APIs\n- Cost calculation\n- Token counting\n- Budget management\n\n**When to reference**: When implementing cost controls, usage analytics, or budget tracking.\n\n## Development Workflow\n\n### Building New Applications\n\nWhen starting a new SDK project:\n\n1. **Choose language**: Python or TypeScript\n2. **Review API reference**: Load the appropriate API reference doc\n3. **Understand core concepts**: Review session management and permissions\n4. **Implement basic agent**: Start with simple tool integration\n5. **Add features**: Sessions, streaming, structured outputs as needed\n6. **Extend with plugins**: Add Skills, Slash Commands, Subagents as appropriate\n7. **Deploy**: Reference hosting guide for production deployment\n\n### Answering SDK Questions\n\nWhen answering questions about the SDK:\n\n1. **Identify topic area**: Core features, advanced features, or tools/integration\n2. **Load relevant references**: Use the reference map above\n3. **Search for specifics**: Use Grep to find exact APIs, examples, or patterns\n4. **Provide code examples**: Reference examples from documentation\n5. **Link to additional resources**: Point to specific reference files for deeper exploration\n\n### Troubleshooting\n\nWhen debugging SDK issues:\n\n1. **Check migration guide**: If migrating from legacy implementation\n2. **Review permissions**: Verify tool permissions are correctly configured\n3. **Validate schemas**: For structured outputs, check schema definitions\n4. **Check MCP connections**: Verify MCP servers are running and accessible\n\n## Reference Documentation Index\n\nAll SDK documentation is available in the `references/` directory:\n\n**API References**:\n\n- `agent-sdk_python.md` - Python API\n- `agent-sdk_typescript.md` - TypeScript API\n\n**Core Features**:\n\n- `agent-sdk_overview.md` - SDK overview\n- `agent-sdk_permissions.md` - Permissions system\n- `agent-sdk_migration-guide.md` - Migration guide\n- `agent-sdk_modifying-system-prompts.md` - System prompts\n- `agent-sdk_sessions.md` - Session management\n- `agent-sdk_streaming-vs-single-mode.md` - Streaming modes\n- `agent-sdk_structured-outputs.md` - Structured outputs\n\n**Advanced Features**:\n\n- `agent-sdk_skills.md` - Agent Skills\n- `agent-sdk_plugins.md` - Plugins\n- `agent-sdk_slash-commands.md` - Slash Commands\n- `agent-sdk_subagents.md` - Subagents\n\n**Tools & Integration**:\n\n- `agent-sdk_custom-tools.md` - Custom tools\n- `agent-sdk_hosting.md` - Hosting & deployment\n- `agent-sdk_mcp.md` - MCP integration\n- `agent-sdk_todo-tracking.md` - Todo lists\n- `agent-sdk_cost-tracking.md` - Cost tracking\n\n## Best Practices\n\n### Code Examples\n\nWhen providing code examples:\n\n- Reference actual examples from documentation\n- Adapt to user's language preference (Python vs TypeScript)\n- Include error handling and edge cases\n- Show complete working examples, not just snippets\n\n### Integration Patterns\n\nCommon integration patterns:\n\n- **Skills + Custom Tools**: Combine domain knowledge with custom functionality\n- **Slash Commands + Subagents**: User-triggered specialized agents\n- **MCP + Permissions**: Secure external tool integration\n- **Sessions + Structured Outputs**: Stateful multi-turn interactions with type-safe responses"
              }
            ]
          }
        ]
      }
    }
  ]
}