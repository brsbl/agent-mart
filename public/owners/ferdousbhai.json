{
  "owner": {
    "id": "ferdousbhai",
    "display_name": "ferdous",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/23114244?u=63e2b8ed7484ec6306c90ae3c58bddfa31f71e10&v=4",
    "url": "https://github.com/ferdousbhai",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 0,
      "total_skills": 2,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "ferdousbhai/cloud-fullstack-skills",
      "url": "https://github.com/ferdousbhai/cloud-fullstack-skills",
      "description": "Claude Code plugin marketplace: Modal (serverless Python/GPUs) + TanStack Start (full-stack React with Cloudflare)",
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2026-01-03T06:22:26Z",
        "created_at": "2025-12-21T11:44:58Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 819
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 30
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1056
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 636
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/modal-deployment",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/modal-deployment/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/modal-deployment/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 166
        },
        {
          "path": "plugins/modal-deployment/README.md",
          "type": "blob",
          "size": 687
        },
        {
          "path": "plugins/modal-deployment/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/SKILL.md",
          "type": "blob",
          "size": 7984
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/dict.md",
          "type": "blob",
          "size": 2287
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/functions.md",
          "type": "blob",
          "size": 6198
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/gpu.md",
          "type": "blob",
          "size": 4545
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/images.md",
          "type": "blob",
          "size": 5157
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/networking.md",
          "type": "blob",
          "size": 8258
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/queue.md",
          "type": "blob",
          "size": 2484
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/sandbox.md",
          "type": "blob",
          "size": 2962
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/scaling.md",
          "type": "blob",
          "size": 6700
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/storage.md",
          "type": "blob",
          "size": 5616
        },
        {
          "path": "plugins/modal-deployment/skills/modal-deployment/references/web.md",
          "type": "blob",
          "size": 6818
        },
        {
          "path": "plugins/tanstack-start",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tanstack-start/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tanstack-start/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 169
        },
        {
          "path": "plugins/tanstack-start/README.md",
          "type": "blob",
          "size": 582
        },
        {
          "path": "plugins/tanstack-start/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/SKILL.md",
          "type": "blob",
          "size": 6246
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/better-auth.md",
          "type": "blob",
          "size": 1578
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/cloudflare-deployment.md",
          "type": "blob",
          "size": 3080
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/github-actions-deploy.md",
          "type": "blob",
          "size": 4033
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/migration.md",
          "type": "blob",
          "size": 2729
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/query-integration.md",
          "type": "blob",
          "size": 2061
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/routing.md",
          "type": "blob",
          "size": 2779
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/server-functions.md",
          "type": "blob",
          "size": 6522
        },
        {
          "path": "plugins/tanstack-start/skills/tanstack-start/references/server-routes.md",
          "type": "blob",
          "size": 1061
        }
      ],
      "marketplace": {
        "name": "cloud-fullstack-skills",
        "version": "0.0.1",
        "description": "Claude Code plugins for cloud deployment and full-stack development",
        "owner_info": {
          "name": "ferdousbhai"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "modal-deployment",
            "description": "Run Python code in the cloud with serverless containers, GPUs, and autoscaling using Modal",
            "source": "./plugins/modal-deployment",
            "category": "development",
            "version": "0.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ferdousbhai/cloud-fullstack-skills",
              "/plugin install modal-deployment@cloud-fullstack-skills"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2026-01-03T06:22:26Z",
              "created_at": "2025-12-21T11:44:58Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "modal-deployment",
                "description": "Run Python code in the cloud with serverless containers, GPUs, and autoscaling. Use when deploying ML models, running batch jobs, scheduling tasks, serving APIs with GPU acceleration, or scaling compute-intensive workloads. Triggers on requests for serverless GPU infrastructure, LLM inference, model training/fine-tuning, parallel data processing, cron jobs in the cloud, or deploying Python web endpoints.",
                "path": "plugins/modal-deployment/skills/modal-deployment/SKILL.md",
                "frontmatter": {
                  "name": "modal-deployment",
                  "description": "Run Python code in the cloud with serverless containers, GPUs, and autoscaling. Use when deploying ML models, running batch jobs, scheduling tasks, serving APIs with GPU acceleration, or scaling compute-intensive workloads. Triggers on requests for serverless GPU infrastructure, LLM inference, model training/fine-tuning, parallel data processing, cron jobs in the cloud, or deploying Python web endpoints."
                },
                "content": "# Modal\n\nModal is a serverless platform for running Python in the cloud with zero configuration. Define everything in code—no YAML, Docker, or Kubernetes required.\n\n## Quick Start\n\n```python\nimport modal\n\napp = modal.App(\"my-app\")\n\n@app.function()\ndef hello():\n    return \"Hello from Modal!\"\n\n@app.local_entrypoint()\ndef main():\n    print(hello.remote())\n```\n\nRun: `modal run app.py`\n\n## Core Concepts\n\n### Functions\nDecorate Python functions to run remotely:\n\n```python\n@app.function(gpu=\"H100\", memory=32768, timeout=600)\ndef train_model(data):\n    # Runs on H100 GPU with 32GB RAM, 10min timeout\n    return model.fit(data)\n```\n\n### Images\nDefine container environments via method chaining:\n\n```python\nimage = (\n    modal.Image.debian_slim(python_version=\"3.12\")\n    .apt_install(\"ffmpeg\", \"libsndfile1\")\n    .uv_pip_install(\"torch\", \"transformers\", \"numpy\")\n    .env({\"CUDA_VISIBLE_DEVICES\": \"0\"})\n)\n\napp = modal.App(\"ml-app\", image=image)\n```\n\nKey image methods:\n- `.debian_slim()` / `.micromamba()` - Base images\n- `.uv_pip_install()` / `.pip_install()` - Python packages\n- `.apt_install()` - System packages\n- `.run_commands()` - Shell commands\n- `.add_local_python_source()` - Local modules\n- `.env()` - Environment variables\n\n### GPUs\nAttach GPUs with a single parameter:\n\n```python\n@app.function(gpu=\"H100\")      # Single H100\n@app.function(gpu=\"A100-80GB\") # 80GB A100\n@app.function(gpu=\"H100:4\")    # 4x H100\n@app.function(gpu=[\"H100\", \"A100-40GB:2\"])  # Fallback options\n```\n\nAvailable: B200, H200, H100, A100-80GB, A100-40GB, L40S, L4, A10G, T4\n\n### Classes with Lifecycle Hooks\nLoad models once at container startup:\n\n```python\n@app.cls(gpu=\"L40S\")\nclass Model:\n    @modal.enter()\n    def load(self):\n        self.model = load_pretrained(\"model-name\")\n    \n    @modal.method()\n    def predict(self, x):\n        return self.model(x)\n\n# Usage\nModel().predict.remote(data)\n```\n\n### Web Endpoints\nDeploy APIs instantly:\n\n```python\n@app.function()\n@modal.fastapi_endpoint()\ndef api(text: str):\n    return {\"result\": process(text)}\n\n# For complex apps\n@app.function()\n@modal.asgi_app()\ndef fastapi_app():\n    from fastapi import FastAPI\n    web = FastAPI()\n    \n    @web.get(\"/health\")\n    def health():\n        return {\"status\": \"ok\"}\n    \n    return web\n```\n\n### Volumes (Persistent Storage)\n\n```python\nvolume = modal.Volume.from_name(\"my-data\", create_if_missing=True)\n\n@app.function(volumes={\"/data\": volume})\ndef save_file(content: str):\n    with open(\"/data/output.txt\", \"w\") as f:\n        f.write(content)\n    volume.commit()  # Persist changes\n```\n\n### Secrets\n\n```python\n@app.function(secrets=[modal.Secret.from_name(\"my-api-key\")])\ndef call_api():\n    import os\n    key = os.environ[\"API_KEY\"]\n```\n\nCreate secrets: Dashboard or `modal secret create my-secret KEY=value`\n\n### Dicts (Distributed Key-Value Store)\n\n```python\ncache = modal.Dict.from_name(\"my-cache\", create_if_missing=True)\n\n@app.function()\ndef cached_compute(key: str):\n    if key in cache:\n        return cache[key]\n    result = expensive_computation(key)\n    cache[key] = result\n    return result\n```\n\n### Queues (Distributed FIFO)\n\n```python\nqueue = modal.Queue.from_name(\"task-queue\", create_if_missing=True)\n\n@app.function()\ndef producer():\n    queue.put_many([{\"task\": i} for i in range(10)])\n\n@app.function()\ndef consumer():\n    while task := queue.get(timeout=60):\n        process(task)\n```\n\n### Parallel Processing\n\n```python\n# Map over inputs (auto-parallelized)\nresults = list(process.map(items))\n\n# Spawn async jobs\ncalls = [process.spawn(item) for item in items]\nresults = [call.get() for call in calls]\n\n# Batch processing (up to 1M inputs)\nprocess.spawn_map(range(100_000))\n```\n\n### Scheduling\n\n```python\n@app.function(schedule=modal.Period(hours=1))\ndef hourly_job():\n    pass\n\n@app.function(schedule=modal.Cron(\"0 9 * * 1-5\"))  # 9am weekdays\ndef daily_report():\n    pass\n```\n\n## CLI Commands\n\n```bash\nmodal run app.py          # Run locally-triggered function\nmodal serve app.py        # Hot-reload web endpoints\nmodal deploy app.py       # Deploy persistently\nmodal shell app.py        # Interactive shell in container\nmodal app list            # List deployed apps\nmodal app logs <name>     # Stream logs\nmodal volume list         # List volumes\nmodal secret list         # List secrets\n```\n\n## Common Patterns\n\n### LLM Inference\n\n```python\n@app.cls(gpu=\"H100\", image=image)\nclass LLM:\n    @modal.enter()\n    def load(self):\n        from vllm import LLM\n        self.llm = LLM(\"meta-llama/Llama-3-8B\")\n    \n    @modal.method()\n    def generate(self, prompt: str):\n        return self.llm.generate(prompt)\n```\n\n### Download Models at Build Time\n\n```python\ndef download_model():\n    from huggingface_hub import snapshot_download\n    snapshot_download(\"model-id\", local_dir=\"/models\")\n\nimage = (\n    modal.Image.debian_slim()\n    .pip_install(\"huggingface-hub\")\n    .run_function(download_model)\n)\n```\n\n### Concurrency for I/O-bound Work\n\n```python\n@app.function()\n@modal.concurrent(max_inputs=100)\nasync def fetch_urls(url: str):\n    async with aiohttp.ClientSession() as session:\n        return await session.get(url)\n```\n\n### Memory Snapshots (Faster Cold Starts)\n\n```python\n@app.cls(enable_memory_snapshot=True, gpu=\"A10G\")\nclass FastModel:\n    @modal.enter(snap=True)\n    def load(self):\n        self.model = load_model()  # Snapshot this state\n```\n\n## Autoscaling\n\n```python\n@app.function(\n    min_containers=2,       # Always keep 2 warm\n    max_containers=100,     # Scale up to 100\n    buffer_containers=5,    # Extra buffer for bursts\n    scaledown_window=300,   # Keep idle for 5 min\n)\ndef serve():\n    pass\n```\n\n## Best Practices\n\n1. **Put imports inside functions** when packages aren't installed locally\n2. **Use `@modal.enter()`** for expensive initialization (model loading)\n3. **Pin dependency versions** for reproducible builds\n4. **Use Volumes** for model weights and persistent data\n5. **Use memory snapshots** for sub-second cold starts in production\n6. **Set appropriate timeouts** for long-running tasks\n7. **Use `min_containers=1`** for production APIs to keep containers warm\n8. **Use absolute imports** with full package paths (not relative imports)\n\n### Fast Image Builds with uv_sync\n\nUse `.uv_sync()` instead of `.pip_install()` for faster dependency installation:\n\n```python\n# In pyproject.toml, define dependency groups:\n# [dependency-groups]\n# modal = [\"fastapi\", \"pydantic-ai>=1.0.0\", \"logfire\"]\n\nimage = (\n    modal.Image.debian_slim(python_version=\"3.12\")\n    .uv_sync(\"agent\", groups=[\"modal\"], frozen=False)\n    .add_local_python_source(\"agent.src\")  # Use dot notation for packages\n)\n```\n\n**Key points:**\n- Deploy from project root: `modal deploy agent/src/api.py`\n- Use dot notation in `.add_local_python_source(\"package.subpackage\")`\n- Imports must match: `from agent.src.config import ...` (not relative `from .config`)\n\n### Logfire Observability\n\nAdd observability with Logfire (especially for pydantic-ai):\n\n```python\n@app.cls(image=image, secrets=[..., modal.Secret.from_name(\"logfire\")], min_containers=1)\nclass Web:\n    @modal.enter()\n    def startup(self):\n        import logfire\n        logfire.configure(send_to_logfire=\"if-token-present\", environment=\"production\", service_name=\"my-agent\")\n        logfire.instrument_pydantic_ai()\n        self.agent = create_agent()\n```\n\n## Reference Documentation\n\nSee `references/` for detailed guides on images, functions, GPUs, scaling, web endpoints, storage, dicts, queues, sandboxes, and networking.\n\nOfficial docs: https://modal.com/docs"
              }
            ]
          },
          {
            "name": "tanstack-start",
            "description": "TanStack Start full-stack React framework with SSR, server functions, and Cloudflare deployment",
            "source": "./plugins/tanstack-start",
            "category": "development",
            "version": "0.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add ferdousbhai/cloud-fullstack-skills",
              "/plugin install tanstack-start@cloud-fullstack-skills"
            ],
            "signals": {
              "stars": 2,
              "forks": 0,
              "pushed_at": "2026-01-03T06:22:26Z",
              "created_at": "2025-12-21T11:44:58Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "tanstack-start",
                "description": "TanStack Start full-stack React framework. Use for: server functions with createServerFn, TanStack Router file-based routing, TanStack Query SSR integration, Cloudflare Workers deployment.",
                "path": "plugins/tanstack-start/skills/tanstack-start/SKILL.md",
                "frontmatter": {
                  "name": "tanstack-start",
                  "description": "TanStack Start full-stack React framework. Use for: server functions with createServerFn, TanStack Router file-based routing, TanStack Query SSR integration, Cloudflare Workers deployment."
                },
                "content": "# TanStack Start\n\nFull-stack React framework with SSR, server functions, and Vite bundling.\n\n## Project Setup\n\n**New project:**\n```bash\npnpm create cloudflare@latest my-app --framework=tanstack-start -y --no-deploy\n```\n\n**Existing app:** See [references/migration.md](references/migration.md) for converting React/Vite apps.\n\n## Critical Configuration\n\n### vite.config.ts\n\n```typescript\nimport { defineConfig } from 'vite'\nimport tsConfigPaths from 'vite-tsconfig-paths'\nimport { tanstackStart } from '@tanstack/react-start/plugin/vite'\nimport viteReact from '@vitejs/plugin-react'\n\nexport default defineConfig({\n  plugins: [\n    tsConfigPaths(),\n    tanstackStart(),\n    viteReact(),  // MUST come AFTER tanstackStart\n  ],\n})\n```\n\n### tsconfig.json gotcha\n\nDo NOT enable `verbatimModuleSyntax` - it leaks server bundles into client bundles.\n\n## Server Functions\n\nSee [references/server-functions.md](references/server-functions.md) for complete guide.\n\n> ⚠️ **Critical**: Route loaders run on server for initial SSR, but run on **CLIENT** during navigation. Always wrap server code in `createServerFn()` to ensure it runs server-side.\n\n**When to use what (Cloudflare Workers):**\n\n| Use Case | Solution |\n|----------|----------|\n| Server code in route loaders | `createServerFn()` |\n| Server code from client event handlers | API routes (`server.handlers`) work best |\n| Access Cloudflare bindings | `import { env } from 'cloudflare:workers'` |\n\n**createServerFn** - for loaders:\n```typescript\nimport { createServerFn } from '@tanstack/react-start'\n\nexport const getData = createServerFn().handler(async () => {\n  return { data: process.env.SECRET }  // Server-only\n})\n```\n\n**API routes** - for client event handlers:\n```tsx\n// routes/api/users.ts\nexport const Route = createFileRoute('/api/users')({\n  server: {\n    handlers: {\n      POST: async ({ request }) => {\n        const body = await request.json()\n        return Response.json(await db.users.create(body))\n      },\n    },\n  },\n})\n\n// In component: fetch('/api/users', { method: 'POST', body: JSON.stringify(data) })\n```\n\n**Key APIs:**\n- `createServerFn()` - Server-only functions for loaders\n- `server.handlers` - API routes for client event handlers\n- `createMiddleware({ type: 'function' })` - Reusable middleware\n- `@tanstack/react-start/server`: `getRequestHeaders()`, `setResponseHeader()`, `getCookies()`\n\n## Routing\n\nSee [references/routing.md](references/routing.md) for complete patterns.\n\n**File conventions** in `src/routes/`:\n| Pattern | Route |\n|---------|-------|\n| `index.tsx` | `/` |\n| `posts.$postId.tsx` | `/posts/:postId` |\n| `_layout.tsx` | Layout (no URL) |\n| `__root.tsx` | Root layout (required) |\n\n```tsx\nimport { createFileRoute } from '@tanstack/react-router'\nimport { createServerFn } from '@tanstack/react-start'\n\nconst getPost = createServerFn()\n  .handler(async () => await db.post.findFirst())\n\nexport const Route = createFileRoute('/posts/$postId')({\n  loader: ({ params }) => getPost({ data: params.postId }),\n  component: () => {\n    const post = Route.useLoaderData()\n    return <h1>{post.title}</h1>\n  },\n})\n```\n\n## Cloudflare Deployment\n\nSee [references/cloudflare-deployment.md](references/cloudflare-deployment.md) for complete guide.\n\n```bash\npnpm add -D @cloudflare/vite-plugin wrangler\n```\n\n**vite.config.ts** - add cloudflare plugin:\n```typescript\nimport { cloudflare } from '@cloudflare/vite-plugin'\n// Add to plugins: cloudflare({ viteEnvironment: { name: 'ssr' } })\n```\n\n**wrangler.jsonc**:\n```jsonc\n{\n  \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n  \"name\": \"my-app\",\n  \"compatibility_date\": \"<CURRENT_DATE>\",  // Use today's YYYY-MM-DD\n  \"compatibility_flags\": [\"nodejs_compat\"],\n  \"main\": \"@tanstack/react-start/server-entry\",\n  \"observability\": { \"enabled\": true }\n}\n```\n\n**Access Cloudflare bindings** in server functions:\n```typescript\nimport { env } from 'cloudflare:workers'\nconst value = await env.MY_KV.get('key')\n```\n\n**Static Prerendering** (v1.138.0+):\n```typescript\ntanstackStart({ prerender: { enabled: true } })\n```\n\n## TanStack Query Integration\n\nSee [references/query-integration.md](references/query-integration.md) for SSR setup.\n\n```bash\npnpm add @tanstack/react-query @tanstack/react-router-ssr-query\n```\n\n```tsx\n// Preload in loaders, consume with useSuspenseQuery\nloader: ({ context }) => context.queryClient.ensureQueryData(myQueryOptions)\n```\n\n## Better-Auth Integration\n\nSee [references/better-auth.md](references/better-auth.md) for complete guide.\n\n> ⚠️ **Critical**: Use `createFileRoute` with `server.handlers`, NOT the legacy `createAPIFileRoute`.\n\n**Mount the auth handler** at `/src/routes/api/auth/$.ts`:\n```typescript\nimport { auth } from '@/lib/auth'\nimport { createFileRoute } from '@tanstack/react-router'\n\nexport const Route = createFileRoute('/api/auth/$')({\n  server: {\n    handlers: {\n      GET: ({ request }) => auth.handler(request),\n      POST: ({ request }) => auth.handler(request),\n    },\n  },\n})\n```\n\n**Auth config** with `tanstackStartCookies` plugin:\n```typescript\nimport { betterAuth } from \"better-auth\"\nimport { tanstackStartCookies } from \"better-auth/tanstack-start\"\n\nexport const auth = betterAuth({\n  // ...your config\n  plugins: [tanstackStartCookies()] // MUST be last plugin\n})\n```\n\n**Protect routes** with middleware:\n```typescript\nimport { createMiddleware } from \"@tanstack/react-start\"\nimport { getRequestHeaders } from \"@tanstack/react-start/server\"\nimport { auth } from \"./auth\"\n\nexport const authMiddleware = createMiddleware().server(\n  async ({ next }) => {\n    const session = await auth.api.getSession({ headers: getRequestHeaders() })\n    if (!session) throw redirect({ to: \"/login\" })\n    return next()\n  }\n)\n\n// In route:\nexport const Route = createFileRoute('/dashboard')({\n  server: { middleware: [authMiddleware] },\n  component: Dashboard,\n})\n```\n\n## GitHub Actions Auto-Deploy\n\nSee [references/github-actions-deploy.md](references/github-actions-deploy.md) for CI/CD setup with preview deployments."
              }
            ]
          }
        ]
      }
    }
  ]
}