{
  "owner": {
    "id": "charlesjones-dev",
    "display_name": "Charles Jones",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/110809?u=e6e2c5d6e0967b8229e1b38ffb38aaccdac08bab&v=4",
    "url": "https://github.com/charlesjones-dev",
    "bio": "Building scalable, secure web applications with AI integration and modern distributed architectures.",
    "stats": {
      "total_repos": 1,
      "total_plugins": 8,
      "total_commands": 19,
      "total_skills": 10,
      "total_stars": 10,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "charlesjones-dev/claude-code-plugins-dev",
      "url": "https://github.com/charlesjones-dev/claude-code-plugins-dev",
      "description": "Automate developer busy work with AI-powered plugins for Claude Code.",
      "homepage": "https://charlesjones.dev",
      "signals": {
        "stars": 10,
        "forks": 0,
        "pushed_at": "2025-12-18T18:03:15Z",
        "created_at": "2025-10-17T19:15:04Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 5713
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/FUNDING.yml",
          "type": "blob",
          "size": 58
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 1971
        },
        {
          "path": "CHANGELOG.md",
          "type": "blob",
          "size": 22705
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 6779
        },
        {
          "path": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5233
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 9545
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5429
        },
        {
          "path": "SECURITY.md",
          "type": "blob",
          "size": 2445
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-accessibility",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-accessibility/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-accessibility/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 550
        },
        {
          "path": "plugins/ai-accessibility/LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "plugins/ai-accessibility/README.md",
          "type": "blob",
          "size": 13829
        },
        {
          "path": "plugins/ai-accessibility/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-accessibility/agents/accessibility-auditor.md",
          "type": "blob",
          "size": 605
        },
        {
          "path": "plugins/ai-accessibility/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-accessibility/commands/accessibility-audit.md",
          "type": "blob",
          "size": 7566
        },
        {
          "path": "plugins/ai-accessibility/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-accessibility/skills/accessibility-auditing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-accessibility/skills/accessibility-auditing/SKILL.md",
          "type": "blob",
          "size": 55539
        },
        {
          "path": "plugins/ai-ado",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-ado/.DS_Store",
          "type": "blob",
          "size": 8196
        },
        {
          "path": "plugins/ai-ado/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-ado/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 573
        },
        {
          "path": "plugins/ai-ado/LICENSE",
          "type": "blob",
          "size": 1070
        },
        {
          "path": "plugins/ai-ado/README.md",
          "type": "blob",
          "size": 28438
        },
        {
          "path": "plugins/ai-ado/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-ado/commands/ado-create-feature.md",
          "type": "blob",
          "size": 10407
        },
        {
          "path": "plugins/ai-ado/commands/ado-create-story.md",
          "type": "blob",
          "size": 16044
        },
        {
          "path": "plugins/ai-ado/commands/ado-create-task.md",
          "type": "blob",
          "size": 12424
        },
        {
          "path": "plugins/ai-ado/commands/ado-init.md",
          "type": "blob",
          "size": 17190
        },
        {
          "path": "plugins/ai-ado/commands/ado-log-story-work.md",
          "type": "blob",
          "size": 19764
        },
        {
          "path": "plugins/ai-ado/commands/ado-timesheet-report.md",
          "type": "blob",
          "size": 41839
        },
        {
          "path": "plugins/ai-ado/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-ado/skills/ado-work-items",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-ado/skills/ado-work-items/SKILL.md",
          "type": "blob",
          "size": 15184
        },
        {
          "path": "plugins/ai-git",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-git/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-git/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 527
        },
        {
          "path": "plugins/ai-git/LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "plugins/ai-git/README.md",
          "type": "blob",
          "size": 5218
        },
        {
          "path": "plugins/ai-git/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-git/commands/git-commit-push.md",
          "type": "blob",
          "size": 1573
        },
        {
          "path": "plugins/ai-git/commands/git-init.md",
          "type": "blob",
          "size": 12661
        },
        {
          "path": "plugins/ai-performance",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-performance/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-performance/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 535
        },
        {
          "path": "plugins/ai-performance/LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "plugins/ai-performance/README.md",
          "type": "blob",
          "size": 13937
        },
        {
          "path": "plugins/ai-performance/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-performance/agents/performance-auditor.md",
          "type": "blob",
          "size": 726
        },
        {
          "path": "plugins/ai-performance/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-performance/commands/performance-audit.md",
          "type": "blob",
          "size": 2808
        },
        {
          "path": "plugins/ai-performance/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-performance/skills/performance-auditing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-performance/skills/performance-auditing/SKILL.md",
          "type": "blob",
          "size": 28544
        },
        {
          "path": "plugins/ai-plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-plugins/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-plugins/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 526
        },
        {
          "path": "plugins/ai-plugins/LICENSE",
          "type": "blob",
          "size": 1070
        },
        {
          "path": "plugins/ai-plugins/README.md",
          "type": "blob",
          "size": 5124
        },
        {
          "path": "plugins/ai-plugins/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-plugins/commands/plugins-scaffold.md",
          "type": "blob",
          "size": 6186
        },
        {
          "path": "plugins/ai-plugins/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-plugins/skills/plugins-scaffolding",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-plugins/skills/plugins-scaffolding/SKILL.md",
          "type": "blob",
          "size": 29117
        },
        {
          "path": "plugins/ai-plugins/skills/skills-scaffolding",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-plugins/skills/skills-scaffolding/SKILL.md",
          "type": "blob",
          "size": 27859
        },
        {
          "path": "plugins/ai-security",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-security/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-security/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 508
        },
        {
          "path": "plugins/ai-security/LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "plugins/ai-security/README.md",
          "type": "blob",
          "size": 24511
        },
        {
          "path": "plugins/ai-security/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-security/agents/security-auditor.md",
          "type": "blob",
          "size": 613
        },
        {
          "path": "plugins/ai-security/agents/security-dependency-scanner.md",
          "type": "blob",
          "size": 879
        },
        {
          "path": "plugins/ai-security/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-security/commands/security-audit.md",
          "type": "blob",
          "size": 4493
        },
        {
          "path": "plugins/ai-security/commands/security-init.md",
          "type": "blob",
          "size": 10312
        },
        {
          "path": "plugins/ai-security/commands/security-scan-dependencies.md",
          "type": "blob",
          "size": 6678
        },
        {
          "path": "plugins/ai-security/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-security/skills/security-auditing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-security/skills/security-auditing/SKILL.md",
          "type": "blob",
          "size": 21274
        },
        {
          "path": "plugins/ai-security/skills/security-dependency-scanning",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-security/skills/security-dependency-scanning/SKILL.md",
          "type": "blob",
          "size": 32884
        },
        {
          "path": "plugins/ai-statusline",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-statusline/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-statusline/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 566
        },
        {
          "path": "plugins/ai-statusline/LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "plugins/ai-statusline/README.md",
          "type": "blob",
          "size": 8030
        },
        {
          "path": "plugins/ai-statusline/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-statusline/commands/statusline-edit.md",
          "type": "blob",
          "size": 3611
        },
        {
          "path": "plugins/ai-statusline/commands/statusline-wizard.md",
          "type": "blob",
          "size": 1842
        },
        {
          "path": "plugins/ai-statusline/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-statusline/skills/statusline-setup",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-statusline/skills/statusline-setup/SKILL.md",
          "type": "blob",
          "size": 13654
        },
        {
          "path": "plugins/ai-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-workflow/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-workflow/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 644
        },
        {
          "path": "plugins/ai-workflow/LICENSE",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "plugins/ai-workflow/README.md",
          "type": "blob",
          "size": 9612
        },
        {
          "path": "plugins/ai-workflow/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-workflow/commands/workflow-implement-phases.md",
          "type": "blob",
          "size": 2088
        },
        {
          "path": "plugins/ai-workflow/commands/workflow-plan-phases.md",
          "type": "blob",
          "size": 1872
        },
        {
          "path": "plugins/ai-workflow/commands/workflow-preflight.md",
          "type": "blob",
          "size": 6056
        },
        {
          "path": "plugins/ai-workflow/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-workflow/skills/implement-phases",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-workflow/skills/implement-phases/SKILL.md",
          "type": "blob",
          "size": 13720
        },
        {
          "path": "plugins/ai-workflow/skills/plan-phases",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-workflow/skills/plan-phases/SKILL.md",
          "type": "blob",
          "size": 10779
        },
        {
          "path": "plugins/ai-workflow/skills/preflight-checks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ai-workflow/skills/preflight-checks/SKILL.md",
          "type": "blob",
          "size": 6907
        }
      ],
      "marketplace": {
        "name": "claude-code-plugins-dev",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Charles Jones",
          "url": "https://charlesjones.dev"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "ai-ado",
            "description": "AI-powered Azure DevOps integration with skills - Intelligent work item management, configuration, and automation for Azure DevOps workflows with MCP integration",
            "source": "./plugins/ai-ado",
            "category": null,
            "version": "1.2.3",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-ado@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/ado-create-feature",
                "description": "Interactively create a new Feature work item in Azure DevOps using configured conventions.",
                "path": "plugins/ai-ado/commands/ado-create-feature.md",
                "frontmatter": {
                  "name": "ado-create-feature",
                  "description": "Interactively create a new Feature work item in Azure DevOps using configured conventions."
                },
                "content": "# Create Azure DevOps Feature\n\nInteractively create a new Feature work item in Azure DevOps using the organization's configured conventions and guidelines.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, feature titles, descriptions, or IDs after this command (e.g., `/ado-create-feature \"My Feature\"` or `/ado-create-feature 123`), you MUST COMPLETELY IGNORE them. Do NOT use any feature titles, descriptions, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive prompts as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Validate Azure DevOps configuration in CLAUDE.md, then begin gathering feature information. DO NOT skip these steps even if the user provided arguments after the command.\n\nThis command creates a Feature work item following the organization's Azure DevOps conventions defined in CLAUDE.md.\n\n### Phase 1: Validate Azure DevOps Configuration\n\nBefore proceeding with feature creation, verify that Azure DevOps configuration exists:\n\n1. Use the **Read tool** to read `CLAUDE.md` from the project root\n2. If the file doesn't exist OR doesn't contain an \"## Azure DevOps\" section:\n   - Display the following error message:\n     ```\n     ‚ùå Azure DevOps configuration not found\n\n     CLAUDE.md does not contain Azure DevOps configuration.\n\n     Please run /ado-init first to configure Azure DevOps settings for this project.\n\n     The /ado-init command will:\n     - Configure your organization, project, and team\n     - Set up Area Path and Iteration Path defaults\n     - Define naming conventions and work item guidelines\n     - Optionally configure the Azure DevOps MCP server\n     ```\n   - **STOP** and do not proceed further\n\n3. If Azure DevOps section exists:\n   - Parse the CLAUDE.md content to extract configuration values:\n     - Organization name (look for text after 'specify the organization as \"')\n     - Project name (look for text after 'the project as \"')\n     - Team name (look for text after 'the team as \"')\n     - Area Path (look for text after 'Area Path\" set to \"')\n     - Iteration Path (look for text after 'Iteration Path\" set to \"')\n     - Naming convention preference (check if \"Use decimal notation\" or \"Use descriptive\" appears in naming section)\n   - Store these values for use in feature creation\n   - Proceed to Phase 2\n\n**IMPORTANT**:\n- Use **Read tool** to check CLAUDE.md - DO NOT use bash commands\n- The entire command should STOP if Azure DevOps configuration is not found\n- Do not prompt the user for configuration values - they must run /ado-init first\n\n### Phase 2: Gather Feature Information\n\nCollect feature details from the user. The user can choose between AI-powered generation or manual input.\n\n**Step 0 - Choose Input Method:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"Would you like to use AI to generate the Feature details, or provide them manually?\n\nOptions:\n1. AI-powered: Provide a description and let AI generate the title and description\n2. Manual: Provide title and description yourself\n\nPlease respond with 'AI' or 'Manual'.\"\n\nWait for the user's response before proceeding.\n\n**If user chooses 'AI' (or similar affirmative response):**\n\n**Step AI-1 - Get Description Prompt:**\n\nSimply output the following text as your response message and STOP:\n\n\"Please provide a description or overview of what this Feature should accomplish. I'll use this to generate a professional title and detailed description.\n\n(Provide as much context as you'd like - the more detail you provide, the better the generated content will be.)\"\n\nWait for the user's description, then:\n\n1. Analyze the naming convention from Phase 1 configuration\n2. Generate a professional Feature title following the naming convention (e.g., \"1: Feature Name\" for decimal notation)\n3. Generate a comprehensive feature description that:\n   - Summarizes the feature's purpose\n   - Describes what user stories it will contain\n   - Provides an overview without excessive fine details\n   - Is clear and suitable for stakeholders\n\n**Step AI-2 - Confirm Generated Title:**\n\nDisplay the generated title and ask for confirmation:\n\n\"I've generated the following title based on your description:\n\n**Title:** [GENERATED_TITLE]\n\nWould you like to use this title, or would you prefer to provide your own?\n(Type 'yes' to use this title, or provide an alternative title)\"\n\nWait for response:\n- If user approves (says \"yes\", \"ok\", \"looks good\", etc.), store the generated title\n- If user provides alternative text, use that as the title instead\n\n**Step AI-3 - Confirm Generated Description:**\n\nDisplay the generated description and ask for confirmation:\n\n\"I've generated the following description:\n\n**Description:**\n[GENERATED_DESCRIPTION]\n\nWould you like to use this description, or would you prefer to provide your own?\n(Type 'yes' to use this description, or provide an alternative description)\"\n\nWait for response:\n- If user approves (says \"yes\", \"ok\", \"looks good\", etc.), store the generated description\n- If user provides alternative text, use that as the description instead\n\nThen proceed to Phase 3 with the final values.\n\n**If user chooses 'Manual':**\n\n**Step 1 - Feature Title:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the title for this Feature?\n\n(Based on your naming convention, use an appropriate format. For decimal notation, use: '1: Feature Name', '2: Feature Name', etc.)\"\n\nWait for the user's next message with the feature title before proceeding.\n\n**Step 2 - Feature Description:**\n\nAfter receiving the feature title, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the high-level description for this Feature?\n\n(Provide a summary of the feature's purpose and the user stories it will contain. This should be an overview without fine details.)\"\n\nWait for the user's next message with the feature description before proceeding.\n\n**IMPORTANT**:\n- Simply output the question text in your response message and STOP - do NOT call ANY tools (except when generating AI content)\n- DO NOT use the AskUserQuestion tool for any of these steps\n- After outputting each question, wait for the user's next message before proceeding\n- For AI mode: Generate content intelligently based on user's description and naming conventions\n- For AI mode: Always confirm generated content and allow user to override\n- Validate that title and description are provided (not empty)\n\n### Phase 3: Create Feature Work Item\n\nUsing the configuration from Phase 1 and the information from Phase 2, create the feature work item:\n\n1. Format the description as HTML for proper Azure DevOps display:\n   - Wrap the description in `<p>` tags\n   - Convert line breaks to `<br/>` tags\n   - If the description contains bullet points (lines starting with `-` or `*`), wrap them in `<ul>` and `<li>` tags\n\n2. Use the **wit_create_work_item** MCP tool with the following parameters:\n   - `project`: Use the project name from Phase 1 configuration\n   - `workItemType`: \"Feature\"\n   - `fields`: Array containing these field objects:\n     - Title field: `{\"name\": \"System.Title\", \"value\": \"[USER_PROVIDED_TITLE]\"}`\n     - Description field: `{\"name\": \"System.Description\", \"value\": \"[HTML_FORMATTED_DESCRIPTION]\", \"format\": \"Html\"}`\n     - Area Path field: `{\"name\": \"System.AreaPath\", \"value\": \"[AREA_PATH_FROM_CONFIG]\"}`\n     - Iteration Path field: `{\"name\": \"System.IterationPath\", \"value\": \"[ITERATION_PATH_FROM_CONFIG]\"}`\n     - State field: `{\"name\": \"System.State\", \"value\": \"New\"}`\n\n3. Wait for the MCP tool response\n\n**IMPORTANT**:\n- Use the exact field names shown above (e.g., \"System.Title\", \"System.Description\")\n- Ensure HTML formatting is applied to the description for readability\n- Use configuration values from Phase 1, not hardcoded values\n- The format parameter for Description must be \"Html\"\n\n### Phase 4: Display Success Message\n\nAfter successful feature creation, display a comprehensive success message:\n\n```\n‚úì Feature created successfully!\n\nFeature Details:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüéØ ID: [FEATURE_ID]\nüìã Title: [FEATURE_TITLE]\nüìÇ Project: [PROJECT_NAME]\nüìç Area Path: [AREA_PATH]\nüîÑ Iteration Path: [ITERATION_PATH]\n‚ú® State: New\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nNext Steps:\n1. Create User Stories under this Feature using /ado-create-story\n2. Review the feature in Azure DevOps web interface\n3. Add additional details or attachments as needed\n\nüí° To create a user story for this feature:\n   /ado-create-story\n   (You'll be prompted for parent Feature ID: [FEATURE_ID])\n\nüîó View in Azure DevOps:\n   https://dev.azure.com/[ORGANIZATION]/[PROJECT]/_workitems/edit/[FEATURE_ID]\n```\n\nReplace placeholders with actual values from the created feature and configuration.\n\n### Important Constraints\n\n**DO NOT:**\n- Proceed without Azure DevOps configuration in CLAUDE.md\n- Use bash commands for file operations\n- Create the feature without user-provided title and description\n- Use placeholder or empty values\n- Call tools during Steps 1-2 (questions should be simple text output)\n\n**DO:**\n- Use **Read tool** to check CLAUDE.md for Azure DevOps configuration\n- Simply output question text and STOP for Steps 1-2 (no tool calls)\n- Wait for user's response after each question before proceeding\n- Use **wit_create_work_item** MCP tool to create the feature\n- Apply proper HTML formatting to description field\n- Use configuration values from CLAUDE.md\n- Show clear success message with feature details\n- Provide helpful next steps and links\n\n### Error Handling\n\nIf the MCP tool returns an error:\n- Display the error message to the user\n- Suggest possible solutions:\n  - Verify Azure DevOps MCP server is configured and running\n  - Check that project and team names are correct\n  - Ensure user has permissions to create work items\n  - Verify Node.js 20+ is installed for MCP server\n- Recommend running /ado-init if configuration seems incorrect"
              },
              {
                "name": "/ado-create-story",
                "description": "Interactively create a new User Story work item as a child of an existing Feature in Azure DevOps.",
                "path": "plugins/ai-ado/commands/ado-create-story.md",
                "frontmatter": {
                  "name": "ado-create-story",
                  "description": "Interactively create a new User Story work item as a child of an existing Feature in Azure DevOps."
                },
                "content": "# Create Azure DevOps User Story\n\nInteractively create a new User Story work item as a child of an existing Feature in Azure DevOps using the organization's configured conventions and guidelines.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, story titles, descriptions, IDs, or other arguments after this command (e.g., `/ado-create-story \"My Story\"` or `/ado-create-story 123`), you MUST COMPLETELY IGNORE them. Do NOT use any story titles, descriptions, IDs, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive prompts as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Validate Azure DevOps configuration in CLAUDE.md, then begin gathering user story information. DO NOT skip these steps even if the user provided arguments after the command.\n\nThis command creates a User Story work item following the organization's Azure DevOps conventions defined in CLAUDE.md.\n\n### Phase 1: Validate Azure DevOps Configuration\n\nBefore proceeding with user story creation, verify that Azure DevOps configuration exists:\n\n1. Use the **Read tool** to read `CLAUDE.md` from the project root\n2. If the file doesn't exist OR doesn't contain an \"## Azure DevOps\" section:\n   - Display the following error message:\n     ```\n     ‚ùå Azure DevOps configuration not found\n\n     CLAUDE.md does not contain Azure DevOps configuration.\n\n     Please run /ado-init first to configure Azure DevOps settings for this project.\n\n     The /ado-init command will:\n     - Configure your organization, project, and team\n     - Set up Area Path and Iteration Path defaults\n     - Define naming conventions and work item guidelines\n     - Optionally configure the Azure DevOps MCP server\n     ```\n   - **STOP** and do not proceed further\n\n3. If Azure DevOps section exists:\n   - Parse the CLAUDE.md content to extract configuration values:\n     - Organization name (look for text after 'specify the organization as \"')\n     - Project name (look for text after 'the project as \"')\n     - Team name (look for text after 'the team as \"')\n     - Area Path (look for text after 'Area Path\" set to \"')\n     - Iteration Path (look for text after 'Iteration Path\" set to \"')\n     - Naming convention preference (check if decimal notation is used)\n   - Store these values for use in story creation\n   - Proceed to Phase 2\n\n**IMPORTANT**:\n- Use **Read tool** to check CLAUDE.md - DO NOT use bash commands\n- The entire command should STOP if Azure DevOps configuration is not found\n- Do not prompt the user for configuration values - they must run /ado-init first\n\n### Phase 2: Gather User Story Information\n\nCollect user story details from the user. The user can choose between AI-powered generation or manual input.\n\n**Step 0 - Choose Input Method:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"Would you like to use AI to generate the User Story details, or provide them manually?\n\nOptions:\n1. AI-powered: Provide a description and let AI generate the title, persona statement, background, and acceptance criteria\n2. Manual: Provide each field yourself\n\nPlease respond with 'AI' or 'Manual'.\"\n\nWait for the user's response before proceeding.\n\n**If user chooses 'AI' (or similar affirmative response):**\n\n**Step AI-0 - Get Parent Feature ID:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the ID of the parent Feature for this User Story?\n\n(This is the numeric ID of the Feature work item that will contain this story. You can find this in Azure DevOps or from the output of /ado-create-feature)\"\n\nWait for the user's next message with the parent feature ID before proceeding.\n\n**Step AI-1 - Get Description Prompt:**\n\nSimply output the following text as your response message and STOP:\n\n\"Please provide a description or overview of what this User Story should accomplish. I'll use this to generate a professional title, persona statement, background information, and acceptance criteria.\n\n(Provide as much context as you'd like - the more detail you provide, the better the generated content will be.)\"\n\nWait for the user's description, then:\n\n1. Analyze the naming convention from Phase 1 configuration\n2. Generate a professional User Story title following the naming convention (e.g., \"1.1: Story Name\" for decimal notation)\n3. Generate a user persona statement in the format: \"As a [role], I want to [action] so that [benefit]\"\n4. Generate relevant background information with technical details and constraints (formatted as bullet points)\n5. Generate comprehensive acceptance criteria using \"Given, When, Then\" format with multiple scenarios if appropriate\n\n**Step AI-2 - Confirm Generated Title:**\n\nDisplay the generated title and ask for confirmation:\n\n\"I've generated the following title based on your description:\n\n**Title:** [GENERATED_TITLE]\n\nWould you like to use this title, or would you prefer to provide your own?\n(Type 'yes' to use this title, or provide an alternative title)\"\n\nWait for response:\n- If user approves (says \"yes\", \"ok\", \"looks good\", etc.), store the generated title\n- If user provides alternative text, use that as the title instead\n\n**Step AI-3 - Confirm Generated Persona Statement:**\n\nDisplay the generated persona statement and ask for confirmation:\n\n\"I've generated the following user persona statement:\n\n**Persona Statement:**\n[GENERATED_PERSONA]\n\nWould you like to use this persona statement, or would you prefer to provide your own?\n(Type 'yes' to use this statement, or provide an alternative)\"\n\nWait for response:\n- If user approves, store the generated persona statement\n- If user provides alternative text, use that instead\n\n**Step AI-4 - Confirm Generated Background:**\n\nDisplay the generated background and ask for confirmation:\n\n\"I've generated the following background information:\n\n**Background:**\n[GENERATED_BACKGROUND]\n\nWould you like to use this background information, or would you prefer to provide your own?\n(Type 'yes' to use this background, 'none' to skip background, or provide alternative background information)\"\n\nWait for response:\n- If user approves, store the generated background\n- If user says 'none', mark background as skipped\n- If user provides alternative text, use that instead\n\n**Step AI-5 - Confirm Generated Acceptance Criteria:**\n\nDisplay the generated acceptance criteria and ask for confirmation:\n\n\"I've generated the following acceptance criteria:\n\n**Acceptance Criteria:**\n[GENERATED_CRITERIA]\n\nWould you like to use these acceptance criteria, or would you prefer to provide your own?\n(Type 'yes' to use these criteria, or provide alternative acceptance criteria)\"\n\nWait for response:\n- If user approves, store the generated acceptance criteria\n- If user provides alternative text, use that instead\n\n**Step AI-6 - Story Points:**\n\nSimply output the following text as your response message and STOP:\n\n\"What is the Story Points estimate for this User Story?\n\n(Use Fibonacci sequence values: 1, 2, 3, 5, 8, 13, 21, etc.)\"\n\nWait for the user's next message with story points before proceeding to Phase 3.\n\n**If user chooses 'Manual':**\n\n**Step 1 - Parent Feature ID:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the ID of the parent Feature for this User Story?\n\n(This is the numeric ID of the Feature work item that will contain this story. You can find this in Azure DevOps or from the output of /ado-create-feature)\"\n\nWait for the user's next message with the parent feature ID before proceeding.\n\n**Step 2 - Story Title:**\n\nAfter receiving the parent feature ID, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the title for this User Story?\n\n(Based on your naming convention, use an appropriate format. For decimal notation, use: '1.1: Story Name', '2.1: Story Name', etc.)\"\n\nWait for the user's next message with the story title before proceeding.\n\n**Step 3 - User Persona Statement:**\n\nAfter receiving the story title, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the user persona statement for this story?\n\n(Format: 'As a [role], I want to [action] so that [benefit]'\nExample: 'As a website visitor, I want to log in with my email and password so that I can access my personalized dashboard.')\"\n\nWait for the user's next message with the persona statement before proceeding.\n\n**Step 4 - Background Information:**\n\nAfter receiving the persona statement, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What background information should be included for this story?\n\n(Provide relevant context, technical details, or constraints. Use bullet points for clarity. Type 'none' to skip.)\"\n\nWait for the user's next message with background information (or 'none') before proceeding.\n\n**Step 5 - Acceptance Criteria:**\n\nAfter receiving the background information, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What are the acceptance criteria for this story?\n\n(Use 'Given, When, Then' format. Provide multiple scenarios if needed. Keep criteria concise for QA testers.\nExample:\nGiven a registered user with valid credentials\nWhen they enter email and password on the login page\nThen they should be authenticated and redirected to dashboard)\"\n\nWait for the user's next message with acceptance criteria before proceeding.\n\n**Step 6 - Story Points:**\n\nAfter receiving the acceptance criteria, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the Story Points estimate for this User Story?\n\n(Use Fibonacci sequence values: 1, 2, 3, 5, 8, 13, 21, etc.)\"\n\nWait for the user's next message with story points before proceeding.\n\n**IMPORTANT**:\n- Simply output the question text in your response message and STOP - do NOT call ANY tools (except when generating AI content)\n- DO NOT use the AskUserQuestion tool for any of these steps\n- After outputting each question, wait for the user's next message before proceeding\n- For AI mode: Generate content intelligently based on user's description and naming conventions\n- For AI mode: Always confirm generated content and allow user to override\n- For AI mode: Parent Feature ID is still required before generating other content\n- Validate that required fields are provided (not empty)\n- Parent Feature ID must be a valid number\n\n### Phase 3: Create User Story Work Item\n\nUsing the configuration from Phase 1 and the information from Phase 2, create the user story work item:\n\n1. Build the description in HTML format (WITHOUT acceptance criteria):\n   - Start with the persona statement wrapped in `<p>` tags\n   - If background information was provided (not 'none'):\n     - Add a blank line and `<p><strong>Background:</strong></p>`\n     - Format background as bullet list with `<ul>` and `<li>` tags\n   - **DO NOT include acceptance criteria in the description** - they go in a separate field\n\n2. Format the acceptance criteria in HTML format:\n   - Use proper line breaks with `<br/>` tags or bullet list format with `<ul>` and `<li>` tags\n   - This will be set in the separate Acceptance Criteria field\n\n3. Use the **wit_add_child_work_items** MCP tool with the following parameters:\n   - `parentId`: The parent feature ID provided by user (as number, not string)\n   - `project`: Use the project name from Phase 1 configuration\n   - `workItemType`: \"User Story\"\n   - `items`: Array containing a single item object with:\n     - `title`: User-provided title\n     - `description`: HTML-formatted description from step 1 (persona + background only)\n     - `format`: \"Html\"\n     - `areaPath`: Area Path from configuration\n     - `iterationPath`: Iteration Path from configuration\n\n4. After the user story is created, use the **wit_update_work_item** MCP tool to set both Story Points AND Acceptance Criteria:\n   - `id`: The ID of the newly created user story (from the response of wit_add_child_work_items)\n   - `updates`: Array containing two update operations:\n     - `{\"op\": \"add\", \"path\": \"/fields/Microsoft.VSTS.Scheduling.StoryPoints\", \"value\": \"[STORY_POINTS_VALUE]\"}`\n     - `{\"op\": \"add\", \"path\": \"/fields/Microsoft.VSTS.Common.AcceptanceCriteria\", \"value\": \"[HTML_FORMATTED_ACCEPTANCE_CRITERIA]\"}`\n\n5. Wait for both MCP tool responses\n\n**IMPORTANT**:\n- Use the exact field names and paths shown above\n- Ensure HTML formatting is applied to both description and acceptance criteria\n- **DO NOT include acceptance criteria in the description field** - use the separate AcceptanceCriteria field\n- Parent ID must be converted to a number (not a string)\n- Use configuration values from Phase 1, not hardcoded values\n- Story Points and Acceptance Criteria must be set in a separate update operation after creation\n- Both Story Points and Acceptance Criteria can be set in a single wit_update_work_item call with multiple update operations\n\n### Phase 4: Display Success Message\n\nAfter successful user story creation, display a comprehensive success message:\n\n```\n‚úì User Story created successfully!\n\nUser Story Details:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüéØ ID: [STORY_ID]\nüìã Title: [STORY_TITLE]\nüë§ Parent Feature: [PARENT_FEATURE_ID]\nüìÇ Project: [PROJECT_NAME]\nüìç Area Path: [AREA_PATH]\nüîÑ Iteration Path: [ITERATION_PATH]\n‚≠ê Story Points: [STORY_POINTS]\n‚ú® State: New\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nNext Steps:\n1. Create Task work items under this User Story using /ado-create-task\n2. Review the story in Azure DevOps web interface\n3. Assign team members and refine estimates as needed\n\nüí° To create a task for this story:\n   /ado-create-task\n   (You'll be prompted for parent User Story ID: [STORY_ID])\n\nüîó View in Azure DevOps:\n   https://dev.azure.com/[ORGANIZATION]/[PROJECT]/_workitems/edit/[STORY_ID]\n```\n\nReplace placeholders with actual values from the created story and configuration.\n\n### Important Constraints\n\n**DO NOT:**\n- Proceed without Azure DevOps configuration in CLAUDE.md\n- Use bash commands for file operations\n- Create the story without user-provided information\n- Use placeholder or empty values\n- Call tools during Steps 1-6 (questions should be simple text output)\n- Include Description or Acceptance Criteria in the work item title\n- Include Acceptance Criteria in the Description field\n\n**DO:**\n- Use **Read tool** to check CLAUDE.md for Azure DevOps configuration\n- Simply output question text and STOP for Steps 1-6 (no tool calls)\n- Wait for user's response after each question before proceeding\n- Use **wit_add_child_work_items** MCP tool to create the story as a child of the feature\n- Use **wit_update_work_item** MCP tool to set both Story Points and Acceptance Criteria after creation\n- Apply proper HTML formatting to both description and acceptance criteria fields\n- Set Acceptance Criteria in the Microsoft.VSTS.Common.AcceptanceCriteria field (NOT in Description)\n- Use configuration values from CLAUDE.md\n- Show clear success message with story details\n- Provide helpful next steps and links\n\n### Error Handling\n\nIf the MCP tool returns an error:\n- Display the error message to the user\n- Suggest possible solutions:\n  - Verify the parent Feature ID exists and is valid\n  - Verify Azure DevOps MCP server is configured and running\n  - Check that project and team names are correct\n  - Ensure user has permissions to create work items\n  - Verify Node.js 20+ is installed for MCP server\n- Recommend running /ado-init if configuration seems incorrect\n- If parent ID is invalid, suggest using /ado-create-feature first"
              },
              {
                "name": "/ado-create-task",
                "description": "Interactively create a new Task work item as a child of an existing User Story in Azure DevOps.",
                "path": "plugins/ai-ado/commands/ado-create-task.md",
                "frontmatter": {
                  "name": "ado-create-task",
                  "description": "Interactively create a new Task work item as a child of an existing User Story in Azure DevOps."
                },
                "content": "# Create Azure DevOps Task\n\nInteractively create a new Task work item as a child of an existing User Story in Azure DevOps using the organization's configured conventions and guidelines.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, task titles, descriptions, IDs, or other arguments after this command (e.g., `/ado-create-task \"My Task\"` or `/ado-create-task 123`), you MUST COMPLETELY IGNORE them. Do NOT use any task titles, descriptions, IDs, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive prompts as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Validate Azure DevOps configuration in CLAUDE.md, then begin gathering task information. DO NOT skip these steps even if the user provided arguments after the command.\n\nThis command creates a Task work item following the organization's Azure DevOps conventions defined in CLAUDE.md.\n\n### Phase 1: Validate Azure DevOps Configuration\n\nBefore proceeding with task creation, verify that Azure DevOps configuration exists:\n\n1. Use the **Read tool** to read `CLAUDE.md` from the project root\n2. If the file doesn't exist OR doesn't contain an \"## Azure DevOps\" section:\n   - Display the following error message:\n     ```\n     ‚ùå Azure DevOps configuration not found\n\n     CLAUDE.md does not contain Azure DevOps configuration.\n\n     Please run /ado-init first to configure Azure DevOps settings for this project.\n\n     The /ado-init command will:\n     - Configure your organization, project, and team\n     - Set up Area Path and Iteration Path defaults\n     - Define naming conventions and work item guidelines\n     - Optionally configure the Azure DevOps MCP server\n     ```\n   - **STOP** and do not proceed further\n\n3. If Azure DevOps section exists:\n   - Parse the CLAUDE.md content to extract configuration values:\n     - Organization name (look for text after 'specify the organization as \"')\n     - Project name (look for text after 'the project as \"')\n     - Team name (look for text after 'the team as \"')\n     - Area Path (look for text after 'Area Path\" set to \"')\n     - Iteration Path (look for text after 'Iteration Path\" set to \"')\n   - Store these values for use in task creation\n   - Proceed to Phase 2\n\n**IMPORTANT**:\n- Use **Read tool** to check CLAUDE.md - DO NOT use bash commands\n- The entire command should STOP if Azure DevOps configuration is not found\n- Do not prompt the user for configuration values - they must run /ado-init first\n\n### Phase 2: Gather Task Information\n\nCollect task details from the user. The user can choose between AI-powered generation or manual input.\n\n**Step 0 - Choose Input Method:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"Would you like to use AI to generate the Task title, or provide it manually?\n\nOptions:\n1. AI-powered: Provide a description and let AI generate an appropriate task title\n2. Manual: Provide the task title yourself\n\nPlease respond with 'AI' or 'Manual'.\"\n\nWait for the user's response before proceeding.\n\n**If user chooses 'AI' (or similar affirmative response):**\n\n**Step AI-0 - Get Parent User Story ID:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the ID of the parent User Story for this Task?\n\n(This is the numeric ID of the User Story work item that will contain this task. You can find this in Azure DevOps or from the output of /ado-create-story)\"\n\nWait for the user's next message with the parent story ID before proceeding.\n\n**Step AI-1 - Get Description Prompt:**\n\nSimply output the following text as your response message and STOP:\n\n\"Please provide a description of what this Task should accomplish. I'll use this to generate an appropriate task title.\n\n(Describe the specific work to be done. Examples: 'implement the login API endpoint', 'test authentication flows', 'create database migration for users table')\"\n\nWait for the user's description, then:\n\n1. Retrieve the parent User Story details to understand context\n2. Generate a professional Task title that is:\n   - Simple and descriptive\n   - Focused on the work to be done\n   - Follows common patterns like: 'Development for [feature]', 'QA testing for [feature]', 'Deploy [component]'\n   - Clear and actionable\n\n**Step AI-2 - Confirm Generated Title:**\n\nDisplay the generated title and ask for confirmation:\n\n\"I've generated the following title based on your description:\n\n**Title:** [GENERATED_TITLE]\n\nWould you like to use this title, or would you prefer to provide your own?\n(Type 'yes' to use this title, or provide an alternative title)\"\n\nWait for response:\n- If user approves (says \"yes\", \"ok\", \"looks good\", etc.), store the generated title\n- If user provides alternative text, use that as the title instead\n\n**Step AI-3 - Hour Estimate:**\n\nSimply output the following text as your response message and STOP:\n\n\"What is the hour estimate for this Task?\n\n(This value will be set for both 'Original Estimate' and 'Remaining Work' fields. Provide a numeric value in hours.)\"\n\nWait for the user's next message with the hour estimate before proceeding to Phase 3.\n\n**If user chooses 'Manual':**\n\n**Step 1 - Parent User Story ID:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the ID of the parent User Story for this Task?\n\n(This is the numeric ID of the User Story work item that will contain this task. You can find this in Azure DevOps or from the output of /ado-create-story)\"\n\nWait for the user's next message with the parent story ID before proceeding.\n\n**Step 2 - Task Title:**\n\nAfter receiving the parent story ID, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the title for this Task?\n\n(Use a simple, descriptive title focused on the work to be done.\nExamples: 'Development for user login functionality', 'QA testing for authentication', 'Deploy to staging environment')\"\n\nWait for the user's next message with the task title before proceeding.\n\n**Step 3 - Hour Estimate:**\n\nAfter receiving the task title, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the hour estimate for this Task?\n\n(This value will be set for both 'Original Estimate' and 'Remaining Work' fields. Provide a numeric value in hours.)\"\n\nWait for the user's next message with the hour estimate before proceeding.\n\n**IMPORTANT**:\n- Simply output the question text in your response message and STOP - do NOT call ANY tools (except when generating AI content)\n- DO NOT use the AskUserQuestion tool for any of these steps\n- After outputting each question, wait for the user's next message before proceeding\n- For AI mode: Generate task title based on user description and parent story context\n- For AI mode: Always confirm generated content and allow user to override\n- For AI mode: Parent User Story ID is still required before generating title\n- Validate that required fields are provided (not empty)\n- Parent User Story ID must be a valid number\n- Hour estimate must be a valid number\n\n### Phase 3: Create Task Work Item\n\nUsing the configuration from Phase 1 and the information from Phase 2, create the task work item:\n\n1. Tasks should have minimal description as per Azure DevOps conventions:\n   - Use a simple description: \"Task for [STORY_TITLE]. See parent User Story for details.\"\n   - Format as HTML: `<p>Task for [STORY_TITLE]. See parent User Story for details.</p>`\n\n2. First, retrieve the parent User Story to get its title using **wit_get_work_item** MCP tool:\n   - `id`: The parent story ID provided by user\n   - `project`: Use the project name from Phase 1 configuration\n\n3. Use the **wit_add_child_work_items** MCP tool with the following parameters:\n   - `parentId`: The parent story ID provided by user (as number, not string)\n   - `project`: Use the project name from Phase 1 configuration\n   - `workItemType`: \"Task\"\n   - `items`: Array containing a single item object with:\n     - `title`: User-provided title\n     - `description`: HTML-formatted description referencing parent story\n     - `format`: \"Html\"\n     - `areaPath`: Area Path from configuration\n     - `iterationPath`: Iteration Path from configuration\n\n4. After the task is created, use the **wit_update_work_item** MCP tool to set hour estimates:\n   - `id`: The ID of the newly created task (from the response of wit_add_child_work_items)\n   - `updates`: Array containing:\n     - `{\"op\": \"add\", \"path\": \"/fields/Microsoft.VSTS.Scheduling.OriginalEstimate\", \"value\": \"[HOUR_ESTIMATE]\"}`\n     - `{\"op\": \"add\", \"path\": \"/fields/Microsoft.VSTS.Scheduling.RemainingWork\", \"value\": \"[HOUR_ESTIMATE]\"}`\n\n5. Wait for all MCP tool responses\n\n**IMPORTANT**:\n- Use the exact field names and paths shown above\n- Retrieve parent story details first to reference in task description\n- Ensure HTML formatting is applied to the description\n- Parent ID must be converted to a number (not a string)\n- Use configuration values from Phase 1, not hardcoded values\n- Hour estimates must be set in a separate update operation after creation\n- Both Original Estimate and Remaining Work should have identical values\n- DO NOT set Completed Work field (leave empty initially)\n\n### Phase 4: Display Success Message\n\nAfter successful task creation, display a comprehensive success message:\n\n```\n‚úì Task created successfully!\n\nTask Details:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüéØ ID: [TASK_ID]\nüìã Title: [TASK_TITLE]\nüìñ Parent User Story: [PARENT_STORY_ID]\nüìÇ Project: [PROJECT_NAME]\nüìç Area Path: [AREA_PATH]\nüîÑ Iteration Path: [ITERATION_PATH]\n‚è±Ô∏è  Original Estimate: [HOURS] hours\n‚è±Ô∏è  Remaining Work: [HOURS] hours\n‚ú® State: New\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nNext Steps:\n1. Assign the task to a team member in Azure DevOps\n2. Update progress and completed work as the task progresses\n3. Create additional tasks for the story if needed\n\nüí° To create another task for the same story:\n   /ado-create-task\n   (Parent User Story ID: [PARENT_STORY_ID])\n\nüîó View in Azure DevOps:\n   https://dev.azure.com/[ORGANIZATION]/[PROJECT]/_workitems/edit/[TASK_ID]\n```\n\nReplace placeholders with actual values from the created task and configuration.\n\n### Important Constraints\n\n**DO NOT:**\n- Proceed without Azure DevOps configuration in CLAUDE.md\n- Use bash commands for file operations\n- Create the task without user-provided information\n- Use placeholder or empty values\n- Call tools during Steps 1-3 (questions should be simple text output)\n- Add detailed Description or Acceptance Criteria to tasks (tasks should reference parent story)\n- Set different values for Original Estimate and Remaining Work\n- Set Completed Work field (should remain empty initially)\n\n**DO:**\n- Use **Read tool** to check CLAUDE.md for Azure DevOps configuration\n- Simply output question text and STOP for Steps 1-3 (no tool calls)\n- Wait for user's response after each question before proceeding\n- Use **wit_get_work_item** to retrieve parent story details\n- Use **wit_add_child_work_items** MCP tool to create the task as a child of the story\n- Use **wit_update_work_item** MCP tool to set hour estimates after creation\n- Apply proper HTML formatting to description field\n- Keep task descriptions lightweight and reference parent story\n- Use configuration values from CLAUDE.md\n- Show clear success message with task details\n- Provide helpful next steps and links\n\n### Error Handling\n\nIf the MCP tool returns an error:\n- Display the error message to the user\n- Suggest possible solutions:\n  - Verify the parent User Story ID exists and is valid\n  - Verify Azure DevOps MCP server is configured and running\n  - Check that project and team names are correct\n  - Ensure user has permissions to create work items\n  - Verify Node.js 20+ is installed for MCP server\n  - Check that hour estimate is a valid numeric value\n- Recommend running /ado-init if configuration seems incorrect\n- If parent ID is invalid, suggest using /ado-create-story first"
              },
              {
                "name": "/ado-init",
                "description": "Initialize Azure DevOps configuration in CLAUDE.md with organization, project, and team settings.",
                "path": "plugins/ai-ado/commands/ado-init.md",
                "frontmatter": {
                  "name": "ado-init",
                  "description": "Initialize Azure DevOps configuration in CLAUDE.md with organization, project, and team settings."
                },
                "content": "# Azure DevOps Init\n\nInitialize Azure DevOps configuration by creating or updating `CLAUDE.md` with your organization, project, and team settings, and optionally configuring the Azure DevOps MCP server.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, organization names, project names, or other arguments after this command (e.g., `/ado-init myorg` or `/ado-init myorg/myproject`), you MUST COMPLETELY IGNORE them. Do NOT use any organization names, project names, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive sequential prompts as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Begin with Phase 1 by asking for the organization name. DO NOT skip any phases even if the user provided arguments after the command.\n\nConfigure CLAUDE.md with Azure DevOps-specific settings that guide Claude Code when working with the Microsoft Azure DevOps MCP server tools. Detailed work item creation guidelines are provided by the `ado-work-items` skill.\n\n### Phase 1: Gather Azure DevOps Configuration\n\nCollect Azure DevOps settings from the user in a sequential flow. Ask for each value and wait for the user's response before proceeding to the next.\n\n**Step 1 - Organization:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools, especially not AskUserQuestion):\n\n\"What is your Azure DevOps organization name? (This is the organization URL segment, e.g., 'contoso' in dev.azure.com/contoso)\"\n\nWait for the user's next message with their organization name before proceeding.\n\n**Step 2 - Project:**\n\nAfter receiving the organization name, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is your Azure DevOps project name?\"\n\nWait for the user's next message with their project name before proceeding.\n\n**Step 3 - Team:**\n\nAfter receiving the project name, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is your Azure DevOps team name?\"\n\nWait for the user's next message with their team name before proceeding.\n\n**Step 4 - Area Path:**\n\nAfter receiving the team name, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is your default Area Path for work items? (This determines where work items are organized. Suggested format: `[PROJECT]\\\\Team\\\\[TEAM]`, or leave blank to use the default)\"\n\nWait for the user's next message with their area path (or blank) before proceeding.\n\n**Step 5 - Iteration Path:**\n\nAfter receiving the area path, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is your default Iteration Path for work items? (This determines which sprint/iteration work items belong to. Suggested format: `[PROJECT]\\\\Sprint 1`, or leave blank to use the default)\"\n\nWait for the user's next message with their iteration path (or blank) before proceeding.\n\n**Step 6 - Naming Convention:**\n\nAfter receiving the iteration path, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"Do you want to use decimal notation for User Story naming? (e.g., 1.1, 1.2, 2.1 for Stories under numbered Features)\n\nType 'yes' for decimal notation (1, 2, 3 for Features; 1.1, 1.2, 2.1 for Stories)\nType 'no' for simple descriptive names (numbered Features only, descriptive names for Stories and Tasks)\"\n\nWait for the user's next message with their choice (yes/no) before proceeding.\n\n**Step 7 - MCP Configuration:**\n\nAfter receiving the naming convention choice, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"Do you want to create a .mcp.json file for Azure DevOps MCP server configuration?\n\nType 'yes' to configure the Azure DevOps MCP server\nType 'no' to skip MCP configuration\"\n\nWait for the user's next message with their choice (yes/no) before proceeding.\n\n**Step 8 - Operating System (only if Step 7 was \"yes\"):**\n\nIf the user answered \"yes\" to Step 7, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"Are you using Windows or Linux/Mac?\n\nType 'windows' for Windows\nType 'linux' for Linux or Mac\n\nNote: Node.js 20+ is required for npx to work. Check your version with: node --version\"\n\nWait for the user's next message with their choice (windows/linux) before proceeding.\n\nIf the user answered \"no\" to Step 7, skip Step 8 entirely and proceed to Phase 2A.\n\n**IMPORTANT**:\n- For Steps 1-8: Simply output the question text in your response message and STOP - do NOT call ANY tools\n- DO NOT use the AskUserQuestion tool (or any other tool) for any of the steps 1-8\n- After outputting each question, wait for the user's next message before proceeding to the next step\n- For Steps 6 and 7, expect the user to type \"yes\" or \"no\"\n- For Step 8 (if applicable), expect the user to type \"windows\" or \"linux\"\n- Validate that organization, project, and team names are provided (not empty)\n- If Area Path or Iteration Path are empty, apply defaults:\n  - Area Path default: `[PROJECT]\\\\Team\\\\[TEAM]`\n  - Iteration Path default: `[PROJECT]\\\\Sprint 1`\n- Store all collected values (including OS choice) for use in Phase 2A and Phase 3\n\n### Phase 2A: Handle MCP Configuration\n\nIf the user answered \"yes\" to Step 7 (MCP configuration):\n\n1. Check if `.mcp.json` exists in the project root using the **Read tool**\n2. If `.mcp.json` already exists (Read succeeds):\n   - Display the appropriate message based on the OS choice from Step 8:\n\n   **For Windows:**\n     ```\n     ‚ö†Ô∏è  .mcp.json file already exists\n\n     For security reasons, we cannot read or modify existing .mcp.json files.\n\n     Please manually add the following configuration to your .mcp.json file:\n\n     {\n       \"mcpServers\": {\n         \"ado\": {\n           \"command\": \"cmd\",\n           \"args\": [\"/c\", \"npx\", \"-y\", \"@azure-devops/mcp\", \"[ORGANIZATION]\"]\n         }\n       }\n     }\n\n     Replace [ORGANIZATION] with: [organization_value]\n\n     üí° Tip: If you already have mcpServers configured, add the \"ado\" entry\n        to your existing mcpServers object.\n\n     üìñ Authentication Setup: Visit https://github.com/microsoft/azure-devops-mcp\n        for instructions on configuring authentication with your Azure DevOps account.\n     ```\n\n   **For Linux/Mac:**\n     ```\n     ‚ö†Ô∏è  .mcp.json file already exists\n\n     For security reasons, we cannot read or modify existing .mcp.json files.\n\n     Please manually add the following configuration to your .mcp.json file:\n\n     {\n       \"mcpServers\": {\n         \"ado\": {\n           \"command\": \"npx\",\n           \"args\": [\"-y\", \"@azure-devops/mcp\", \"[ORGANIZATION]\"]\n         }\n       }\n     }\n\n     Replace [ORGANIZATION] with: [organization_value]\n\n     üí° Tip: If you already have mcpServers configured, add the \"ado\" entry\n        to your existing mcpServers object.\n\n     üìñ Authentication Setup: Visit https://github.com/microsoft/azure-devops-mcp\n        for instructions on configuring authentication with your Azure DevOps account.\n     ```\n\n   - Replace `[ORGANIZATION]` and `[organization_value]` with the actual organization name\n   - Proceed to Phase 2B\n\n3. If `.mcp.json` doesn't exist (Read returns error):\n   - Create `.mcp.json` with the appropriate content based on the OS choice from Step 8 using the **Write tool**:\n\n   **For Windows:**\n     ```json\n     {\n       \"mcpServers\": {\n         \"ado\": {\n           \"command\": \"cmd\",\n           \"args\": [\"/c\", \"npx\", \"-y\", \"@azure-devops/mcp\", \"[ORGANIZATION]\"]\n         }\n       }\n     }\n     ```\n\n   **For Linux/Mac:**\n     ```json\n     {\n       \"mcpServers\": {\n         \"ado\": {\n           \"command\": \"npx\",\n           \"args\": [\"-y\", \"@azure-devops/mcp\", \"[ORGANIZATION]\"]\n         }\n       }\n     }\n     ```\n\n   - Replace `[ORGANIZATION]` with the actual organization name\n   - Display success message:\n     ```\n     ‚úì Created .mcp.json with Azure DevOps MCP server configuration\n\n     üìñ Authentication Setup Required:\n        Visit https://github.com/microsoft/azure-devops-mcp for instructions on\n        configuring authentication with your Azure DevOps account.\n\n        You'll need to set up a Personal Access Token (PAT) with appropriate\n        permissions for the MCP server to connect to your ADO account.\n     ```\n   - Proceed to Phase 2B\n\nIf the user answered \"no\" to Step 7 (skip MCP configuration):\n- Skip all MCP configuration steps\n- Proceed directly to Phase 2B\n\n**IMPORTANT for Phase 2A**:\n- Use **Read tool** to check if .mcp.json exists - DO NOT use bash commands\n- For security reasons, NEVER read the contents of an existing .mcp.json file\n- If .mcp.json exists, only show the snippet - do NOT attempt to merge or modify\n- Use **Write tool** only when creating a new .mcp.json file\n- Use the correct command format based on user's OS choice (Windows vs Linux/Mac)\n- Ensure proper JSON formatting with correct indentation\n\n### Phase 2B: Check Existing CLAUDE.md\n\nCheck if `CLAUDE.md` already exists and contains an Azure DevOps section using the **Read tool**:\n\n1. Try to read `CLAUDE.md` using the Read tool from the project root\n2. If the file exists and Read succeeds:\n   - Parse the content\n   - Search for \"## Azure DevOps\" section header\n   - If Azure DevOps section exists:\n     - **STOP** and display a warning message:\n       ```\n       ‚ö†Ô∏è  Azure DevOps section already exists in CLAUDE.md\n\n       The CLAUDE.md file already contains Azure DevOps configuration.\n\n       To update the configuration:\n       1. Manually edit CLAUDE.md to update the Azure DevOps section\n       2. Or remove the Azure DevOps section and run /ado-init again\n\n       Current Azure DevOps section found at line: [line_number]\n       ```\n     - Return early without making changes\n   - If no Azure DevOps section exists:\n     - Proceed to Phase 3 to append the section\n3. If the file doesn't exist (Read returns error):\n   - Proceed to Phase 3 to create new CLAUDE.md with Azure DevOps section\n\n**IMPORTANT**:\n- Use **Read tool** to check file existence - DO NOT use bash test commands\n- The Read tool will gracefully handle non-existent files by returning an error\n- Only proceed with writing if no Azure DevOps section currently exists\n- Preserve all existing content when appending\n\n### Phase 3: Build Azure DevOps Configuration Section\n\nUsing the values collected in Phase 1, build a simplified Azure DevOps configuration section:\n\n```markdown\n## Azure DevOps\n\nAzure DevOps MCP tools are authorized for use in this project. When utilizing Azure DevOps MCP tools, use the following configuration:\n\n**Organization:** [ORGANIZATION]\n**Project:** [PROJECT]\n**Team:** [TEAM]\n**Area Path:** [AREA_PATH]\n**Iteration Path:** [ITERATION_PATH]\n**Naming Convention:** [NAMING_CONVENTION_DESCRIPTION]\n\nAll work items (Features, User Stories, and Tasks) should have the \"State\" set to \"New\" unless otherwise specified.\n\n**Work Item Guidelines:** Detailed guidelines for creating Features, User Stories, and Tasks (including hierarchy, HTML formatting, acceptance criteria, hour estimation, and naming conventions) are provided by the `ado-work-items` skill. This skill is automatically loaded when working with Azure DevOps MCP tools.\n```\n\n**Naming Convention Description Values:**\n\nIf user selected \"Yes, use decimals\":\n```\nDecimal notation (Features: 1, 2, 3; User Stories: 1.1, 1.2, 2.1; Tasks: descriptive names)\n```\n\nIf user selected \"No, simple names\":\n```\nSimple descriptive names (Features: numbered 1-99; User Stories and Tasks: descriptive names)\n```\n\n**Template Variable Replacements:**\n- `[ORGANIZATION]` ‚Üí User's organization name\n- `[PROJECT]` ‚Üí User's project name\n- `[TEAM]` ‚Üí User's team name\n- `[AREA_PATH]` ‚Üí User's area path\n- `[ITERATION_PATH]` ‚Üí User's iteration path\n- `[NAMING_CONVENTION_DESCRIPTION]` ‚Üí Appropriate description based on user choice\n\n### Phase 4: Write or Update CLAUDE.md\n\nAfter building the Azure DevOps configuration section:\n\n**If CLAUDE.md exists (no Azure DevOps section):**\n1. Read the existing content\n2. Append two newlines and the Azure DevOps section to the end\n3. Use the **Write tool** to update CLAUDE.md with combined content\n4. Show success message with \"updated\" status\n\n**If CLAUDE.md doesn't exist:**\n1. Create a new CLAUDE.md with the Azure DevOps section\n2. Add a header explaining this is project-specific configuration for Claude Code\n3. Use the **Write tool** to create CLAUDE.md\n4. Show success message with \"created\" status\n\n**File Header for New CLAUDE.md:**\n```markdown\n# CLAUDE.md\n\nThis file provides guidance to Claude Code when working with code in this repository.\n\n```\n\n**IMPORTANT**:\n- Use **Write tool** to create/update the CLAUDE.md file\n- DO NOT use bash commands for writing the file\n- Preserve all existing content when updating\n- Add proper spacing (two newlines) before the Azure DevOps section\n- Ensure proper markdown formatting\n\n### Phase 5: Display Success Message\n\nShow a comprehensive success message with configuration summary:\n\n```\n‚úì Azure DevOps configuration successfully added to CLAUDE.md!\n\nConfiguration Summary:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüìã Organization: [organization]\nüìÇ Project: [project]\nüë• Team: [team]\nüìç Area Path: [area_path]\nüîÑ Iteration Path: [iteration_path]\nüìù Naming Convention: [Decimal notation | Simple descriptive names]\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nWork Item Guidelines:\nThe ado-work-items skill provides comprehensive guidelines for:\n‚úì Three-level hierarchy (Features ‚Üí User Stories ‚Üí Tasks)\n‚úì HTML formatting requirements for text fields\n‚úì Description and Acceptance Criteria templates\n‚úì Hour estimation and Story Points guidelines\n‚úì Naming convention standards\n\nThe skill is automatically loaded when you work with Azure DevOps MCP tools.\n\nNext Steps:\n1. Review the generated CLAUDE.md Azure DevOps section\n2. [If MCP was configured] Ensure Node.js 20+ is installed (check: node --version)\n3. [If MCP was configured] Set up authentication for Azure DevOps MCP server:\n   üìñ Visit https://github.com/microsoft/azure-devops-mcp for detailed instructions\n   You'll need to create a Personal Access Token (PAT) with appropriate permissions\n4. [If MCP was configured] Restart Claude Code for the MCP server to take effect\n5. Use Azure DevOps MCP tools - the ado-work-items skill will provide guidance\n\nüí° Azure DevOps MCP Server: https://github.com/microsoft/azure-devops-mcp\nüí° Node.js Download: https://nodejs.org/\n\nüí° Tip: All Azure DevOps MCP work item operations will now automatically\n   use these organization, project, and team settings unless explicitly\n   overridden. Work item creation guidelines will be provided by the\n   ado-work-items skill.\n```\n\n### Important Constraints\n\n**DO NOT:**\n- Modify or remove existing content from CLAUDE.md\n- Proceed if Azure DevOps section already exists\n- Use bash commands for file operations\n- Create the Azure DevOps section without user confirmation\n- Include empty or placeholder values in the configuration\n- Include the full work item guidelines in CLAUDE.md (they belong in the skill)\n\n**DO:**\n- Use **Read tool** to check if CLAUDE.md exists and for Azure DevOps section\n- For Steps 1-8: Simply output the question text in your message and STOP (no tool calls)\n- Wait for the user's next message after each question before proceeding\n- For Steps 6 and 7, expect the user to type \"yes\" or \"no\"\n- Use **Write tool** to create/update CLAUDE.md\n- Preserve all existing CLAUDE.md content when appending\n- Validate that required fields are provided\n- Show clear success message with configuration summary\n- Provide helpful next steps for using the configuration\n- Replace all template placeholders with actual user values\n- Use proper markdown formatting with appropriate spacing\n- Reference the ado-work-items skill for work item guidelines\n\n### Additional Features\n\n**Default Values:**\n- If user doesn't provide Area Path, use: `[PROJECT]\\\\Team\\\\[TEAM]`\n- If user doesn't provide Iteration Path, use: `[PROJECT]\\\\Sprint 1`\n\n**Validation:**\n- Ensure organization name doesn't contain special characters\n- Ensure project and team names are valid (no leading/trailing spaces)\n- Warn if Area Path or Iteration Path format seems incorrect\n\n**MCP Integration Note:**\nIf the user chose to configure MCP (.mcp.json was created or snippet was shown), include a reminder in the success message to restart Claude Code for the MCP server configuration to take effect.\n\n**Skill Integration:**\nThe simplified CLAUDE.md section references the `ado-work-items` skill for detailed work item creation guidelines. This skill is automatically loaded when Claude detects Azure DevOps MCP tool usage, providing just-in-time expert guidance without cluttering the project's CLAUDE.md file."
              },
              {
                "name": "/ado-log-story-work",
                "description": "Rapidly log completed work to a User Story by creating a Task with completed hours already set.",
                "path": "plugins/ai-ado/commands/ado-log-story-work.md",
                "frontmatter": {
                  "name": "ado-log-story-work",
                  "description": "Rapidly log completed work to a User Story by creating a Task with completed hours already set."
                },
                "content": "# Log Completed Work to User Story\n\nRapidly log completed work to a User Story by creating a new Task work item with completed hours already set. This command is designed for quick logging of work done multiple times per day.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, work descriptions, hours, IDs, or other arguments after this command (e.g., `/ado-log-story-work \"Fixed bug\" 2` or `/ado-log-story-work 123`), you MUST COMPLETELY IGNORE them. Do NOT use any work descriptions, hours, IDs, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive prompts as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Validate Azure DevOps configuration in CLAUDE.md, then begin gathering task information. DO NOT skip these steps even if the user provided arguments after the command.\n\nThis command creates a Task work item to record completed work, following the organization's Azure DevOps conventions defined in CLAUDE.md.\n\n### Phase 1: Validate Azure DevOps Configuration\n\nBefore proceeding with task creation, verify that Azure DevOps configuration exists:\n\n1. Use the **Read tool** to read `CLAUDE.md` from the project root\n2. If the file doesn't exist OR doesn't contain an \"## Azure DevOps\" section:\n   - Display the following error message:\n     ```\n     ‚ùå Azure DevOps configuration not found\n\n     CLAUDE.md does not contain Azure DevOps configuration.\n\n     Please run /ado-init first to configure Azure DevOps settings for this project.\n\n     The /ado-init command will:\n     - Configure your organization, project, and team\n     - Set up Area Path and Iteration Path defaults\n     - Define naming conventions and work item guidelines\n     - Optionally configure the Azure DevOps MCP server\n     ```\n   - **STOP** and do not proceed further\n\n3. If Azure DevOps section exists:\n   - Parse the CLAUDE.md content to extract configuration values:\n     - Organization name (look for text after 'specify the organization as \"')\n     - Project name (look for text after 'the project as \"')\n     - Team name (look for text after 'the team as \"')\n     - Area Path (look for text after 'Area Path\" set to \"')\n     - Iteration Path (look for text after 'Iteration Path\" set to \"')\n   - Store these values for use in task creation\n   - Proceed to Phase 2\n\n**IMPORTANT**:\n- Use **Read tool** to check CLAUDE.md - DO NOT use bash commands\n- The entire command should STOP if Azure DevOps configuration is not found\n- Do not prompt the user for configuration values - they must run /ado-init first\n\n### Phase 2: Gather Task Information\n\nCollect task details from the user. The user can choose between AI-powered generation or manual input.\n\n**Step 1 - Get Parent User Story ID:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the ID of the parent User Story for logging this completed work?\n\n(This is the numeric ID of the User Story work item. You can find this in Azure DevOps or from the output of /ado-create-story)\"\n\nWait for the user's next message with the parent story ID before proceeding.\n\n**Step 2 - Choose Input Method:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"Would you like to use AI to generate the Task details, or provide them manually?\n\nOptions:\n1. AI-powered: Provide a description (optionally including a git commit hash) and let AI generate an appropriate task title and description\n2. Manual: Provide the task details yourself\n\nPlease respond with 'AI' or 'Manual'.\"\n\nWait for the user's response before proceeding.\n\n**If user chooses 'AI' (or similar affirmative response):**\n\n**Step AI-1 - Get Prompt:**\n\nSimply output the following text as your response message and STOP:\n\n\"Please describe the work that was completed. You can optionally include a git commit hash (full or short SHA) and I'll look up the commit details to enhance the task description.\n\n(Examples:\n- 'Implemented user authentication endpoints'\n- 'Fixed bug in payment processing - commit abc123def'\n- 'Added validation to registration form, see commit 1a2b3c4d5e6f7890')\"\n\nWait for the user's prompt, then perform the following steps to generate content:\n\n1. **Detect git commit hash** in the prompt:\n   - Look for patterns like: 7-40 character hexadecimal strings that could be commit hashes\n   - Common patterns: standalone hex strings, after words like \"commit\", \"hash\", \"sha\"\n\n2. **If commit hash detected**:\n   - Use **Bash tool** to run: `git show [COMMIT_HASH] --stat --pretty=format:\"%H%n%h%n%s%n%b\"`\n     - This will show: full SHA, short SHA, subject, body, and file changes\n   - Parse the git output to extract:\n     - Full SHA (first line)\n     - Short SHA (second line)\n     - Commit message (subject + body)\n     - Changed files list\n   - Store this information for use in generation\n\n3. **Generate a concise, action-oriented task title** (5-10 words) that describes what was completed\n   - Examples: \"Implement user authentication API endpoints\", \"Fix payment processing validation bug\", \"Add email verification to registration\"\n\n4. **Generate a detailed task description** (2-4 sentences) explaining what was accomplished:\n\n   **If NO commit hash was found:**\n   - Expand on the user's description with more detail about what was tested, implemented, fixed, or added\n   - Include relevant technical details or context\n   - Make it informative enough that someone reading the task understands what was done\n   - Example generation:\n     - User input: \"Tested CMS functionality\"\n     - Generated description: \"Completed comprehensive testing of the CMS functionality. Verified that content authors can edit page components inline, preview changes in real-time, and publish updates successfully. All core editing features are working as expected.\"\n\n   **If commit hash WAS found:**\n   - Start with what was accomplished (based on user description)\n   - Reference the git commit with both full and short SHA\n   - Include relevant parts of the commit message\n   - List key files that were changed (if significant)\n   - Example generation:\n     - User input: \"Implemented JWT auth - commit abc123def4567890\"\n     - Generated description: \"Implemented JWT token authentication for the login API endpoints. This work is captured in commit abc123def4567890 (abc123d). The commit adds token generation, validation middleware, and refresh token logic. Key changes include: src/auth/jwt.ts, src/middleware/auth.ts, src/routes/login.ts.\"\n\n   **Important**: Format the description as HTML with `<p>` tags for paragraphs and `<br/>` for line breaks. Keep it professional, clear, and informative.\n\n**Step AI-2 - Confirm Generated Title:**\n\nDisplay the generated title and ask for confirmation:\n\n\"I've generated the following title: [GENERATED_TITLE]\n\nWould you like to use this title, or would you prefer to provide your own?\n(Type 'yes' to use this title, or provide an alternative title)\"\n\nWait for response:\n- If user approves (says \"yes\", \"ok\", \"looks good\", etc.), store the generated title\n- If user provides alternative text, use that as the title instead\n\n**Step AI-3 - Confirm Generated Description:**\n\nDisplay the generated description and ask for confirmation:\n\n\"I've generated the following description: [GENERATED_DESCRIPTION]\n\nWould you like to use this description, or would you prefer to provide your own?\n(Type 'yes' to use this description, or provide an alternative description)\"\n\nWait for response:\n- If user approves (says \"yes\", \"ok\", \"looks good\", etc.), store the generated description\n- If user provides alternative text, use that as the description instead\n\n**If user chooses 'Manual':**\n\n**Step M-1 - Task Title:**\n\nSimply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the title for this completed task?\n\n(Provide a concise description of the work that was completed)\"\n\nWait for the user's next message with the task title before proceeding.\n\n**Step M-2 - Task Description:**\n\nAfter receiving the task title, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the description for this completed task?\n\n(Provide enough detail to understand what was accomplished. You can include commit hashes, file names, or other relevant details.)\"\n\nWait for the user's next message with the task description before proceeding.\n\n**Step 3 - Completed Hours:**\n\nSimply output the following text as your response message and STOP:\n\n\"How many hours were completed on this task?\n\n(Provide a numeric value in hours. This will be set for both 'Original Estimate' and 'Completed Work' fields, with 'Remaining Work' left empty.)\"\n\nWait for the user's next message with the completed hours before proceeding.\n\n**Step 4 - Placeholder Task Subtraction:**\n\nSimply output the following text as your response message and STOP:\n\n\"Would you like to subtract these hours from a placeholder task?\n\n(This is useful if you have a bucket of hours allocated to a placeholder task that you want to draw down as work is completed. Type 'yes' or 'no')\"\n\nWait for the user's response.\n\n**If user says 'yes' (or similar affirmative):**\n\n**Step 4a - Placeholder Task ID:**\n\nSimply output the following text as your response message and STOP:\n\n\"What is the ID of the placeholder task to subtract hours from?\n\n(This is the numeric ID of the existing Task work item that contains your hour bucket)\"\n\nWait for the user's next message with the placeholder task ID before proceeding to Phase 3.\n\n**If user says 'no' (or similar negative):**\n\nProceed directly to Phase 3.\n\n**IMPORTANT**:\n- Simply output the question text in your response message and STOP - do NOT call ANY tools (except when looking up git commits or generating AI content)\n- DO NOT use the AskUserQuestion tool for any of these steps\n- After outputting each question, wait for the user's next message before proceeding\n- **For AI mode**: In Step AI-1, you MUST actually generate BOTH the title AND description content (steps 4 and 5) before proceeding to Step AI-2\n- **For AI mode**: Steps AI-2 and AI-3 display the ALREADY GENERATED content for user confirmation\n- **For AI mode**: The description MUST be actual content (2-4 sentences), NOT empty, NOT just placeholder text\n- For AI mode: Detect git commit hashes automatically and look them up\n- For AI mode: Always confirm generated content and allow user to override\n- For Manual mode: Use provided text directly without modification\n- Validate that required fields are provided (not empty)\n- Parent User Story ID must be a valid number\n- Completed hours must be a valid number\n- Placeholder task ID (if provided) must be a valid number\n\n### Phase 3: Create Task Work Item\n\nUsing the configuration from Phase 1 and the information from Phase 2, create the task work item:\n\n1. Format the task description as HTML:\n   - If AI-generated: Use the generated HTML-formatted description\n   - If manual: Wrap the user's description in `<p>` tags, replacing line breaks with `<br/>`\n\n2. Use the **wit_add_child_work_items** MCP tool with the following parameters:\n   - `parentId`: The parent story ID provided by user (as number, not string)\n   - `project`: Use the project name from Phase 1 configuration\n   - `workItemType`: \"Task\"\n   - `items`: Array containing a single item object with:\n     - `title`: Generated or user-provided title\n     - `description`: HTML-formatted description\n     - `format`: \"Html\"\n     - `areaPath`: Area Path from configuration\n     - `iterationPath`: Iteration Path from configuration\n\n3. After the task is created, use the **wit_update_work_item** MCP tool to set hour fields:\n   - `id`: The ID of the newly created task (from the response of wit_add_child_work_items)\n   - `updates`: Array containing:\n     - `{\"op\": \"add\", \"path\": \"/fields/Microsoft.VSTS.Scheduling.OriginalEstimate\", \"value\": \"[COMPLETED_HOURS]\"}`\n     - `{\"op\": \"add\", \"path\": \"/fields/Microsoft.VSTS.Scheduling.CompletedWork\", \"value\": \"[COMPLETED_HOURS]\"}`\n\n4. Wait for both MCP tool responses\n\n**IMPORTANT**:\n- Use the exact field names and paths shown above\n- Ensure HTML formatting is applied to the description\n- Parent ID must be converted to a number (not a string)\n- Use configuration values from Phase 1, not hardcoded values\n- Set both Original Estimate and Completed Work to the same value (completed hours)\n- DO NOT set Remaining Work field (leave empty)\n- Completed Work field is critical - this marks the task as having completed work logged\n\n### Phase 4: Update Placeholder Task (If Requested)\n\nIf the user requested placeholder task hour subtraction in Phase 2:\n\n1. First, retrieve the current placeholder task details using **wit_get_work_item** MCP tool:\n   - `id`: The placeholder task ID provided by user\n   - `project`: Use the project name from Phase 1 configuration\n   - Extract current values for:\n     - Original Estimate (field: Microsoft.VSTS.Scheduling.OriginalEstimate)\n     - Remaining Work (field: Microsoft.VSTS.Scheduling.RemainingWork)\n\n2. Calculate new values:\n   - New Original Estimate = Current Original Estimate - Completed Hours\n   - New Remaining Work = Current Remaining Work - Completed Hours\n   - Ensure values don't go below 0\n\n3. Use the **wit_update_work_item** MCP tool to update the placeholder task:\n   - `id`: The placeholder task ID\n   - `updates`: Array containing:\n     - `{\"op\": \"replace\", \"path\": \"/fields/Microsoft.VSTS.Scheduling.OriginalEstimate\", \"value\": \"[NEW_ORIGINAL_ESTIMATE]\"}`\n     - `{\"op\": \"replace\", \"path\": \"/fields/Microsoft.VSTS.Scheduling.RemainingWork\", \"value\": \"[NEW_REMAINING_WORK]\"}`\n\n4. Wait for the MCP tool response\n\n**IMPORTANT**:\n- Use \"replace\" operation (not \"add\") for updating existing field values\n- Calculate new values correctly by subtracting completed hours\n- Ensure values don't become negative (minimum value is 0)\n- Store the old and new values to display in the success message\n\n### Phase 5: Display Success Message\n\nAfter successful task creation (and optional placeholder update), display a comprehensive success message:\n\n**If placeholder task was NOT updated:**\n\n```\n‚úì Completed work logged successfully!\n\nTask Details:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüéØ ID: [TASK_ID]\nüìã Title: [TASK_TITLE]\nüìñ Parent User Story: [PARENT_STORY_ID] - [PARENT_STORY_TITLE]\nüìÇ Project: [PROJECT_NAME]\nüìç Area Path: [AREA_PATH]\nüîÑ Iteration Path: [ITERATION_PATH]\n‚è±Ô∏è  Original Estimate: [HOURS] hours\n‚úÖ Completed Work: [HOURS] hours\n‚ú® State: New\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nNext Steps:\n1. Update task state to \"Closed\" in Azure DevOps if fully complete\n2. Log additional work to the same story using /ado-log-story-work\n3. Review overall story progress\n\nüí° To log more work to this story:\n   /ado-log-story-work\n   (Parent User Story ID: [PARENT_STORY_ID])\n\nüîó View in Azure DevOps:\n   https://dev.azure.com/[ORGANIZATION]/[PROJECT]/_workitems/edit/[TASK_ID]\n```\n\n**If placeholder task WAS updated:**\n\n```\n‚úì Completed work logged successfully!\n\nTask Details:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüéØ ID: [TASK_ID]\nüìã Title: [TASK_TITLE]\nüìñ Parent User Story: [PARENT_STORY_ID] - [PARENT_STORY_TITLE]\nüìÇ Project: [PROJECT_NAME]\nüìç Area Path: [AREA_PATH]\nüîÑ Iteration Path: [ITERATION_PATH]\n‚è±Ô∏è  Original Estimate: [HOURS] hours\n‚úÖ Completed Work: [HOURS] hours\n‚ú® State: New\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nPlaceholder Task Updated:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüîñ Placeholder Task ID: [PLACEHOLDER_TASK_ID]\n‚è±Ô∏è  Original Estimate: [OLD_ORIGINAL_ESTIMATE] hours ‚Üí [NEW_ORIGINAL_ESTIMATE] hours (-[HOURS] hours)\n‚è≥ Remaining Work: [OLD_REMAINING_WORK] hours ‚Üí [NEW_REMAINING_WORK] hours (-[HOURS] hours)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nNext Steps:\n1. Update task state to \"Closed\" in Azure DevOps if fully complete\n2. Log additional work to the same story using /ado-log-story-work\n3. Review overall story progress and remaining placeholder hours\n\nüí° To log more work to this story:\n   /ado-log-story-work\n   (Parent User Story ID: [PARENT_STORY_ID])\n\nüîó View task in Azure DevOps:\n   https://dev.azure.com/[ORGANIZATION]/[PROJECT]/_workitems/edit/[TASK_ID]\n\nüîó View placeholder task in Azure DevOps:\n   https://dev.azure.com/[ORGANIZATION]/[PROJECT]/_workitems/edit/[PLACEHOLDER_TASK_ID]\n```\n\nReplace placeholders with actual values from the created task, placeholder task, and configuration.\n\n### Important Constraints\n\n**DO NOT:**\n- Proceed without Azure DevOps configuration in CLAUDE.md\n- Use bash commands for file operations (except git show for commit lookup)\n- Create the task without user-provided information\n- Use placeholder or empty values\n- Call tools during question steps (questions should be simple text output)\n- Set Remaining Work field (must be left empty)\n- Use \"add\" operation when updating placeholder task values (use \"replace\")\n- Allow placeholder task hours to become negative\n\n**DO:**\n- Use **Read tool** to check CLAUDE.md for Azure DevOps configuration\n- Simply output question text and STOP for question steps (no tool calls except for git and AI generation)\n- Wait for user's response after each question before proceeding\n- Use **Bash tool** with `git show` to look up commit details if hash detected\n- Use **wit_get_work_item** to retrieve placeholder task details\n- Use **wit_add_child_work_items** MCP tool to create the task as a child of the story\n- Use **wit_update_work_item** MCP tool to set hour fields after creation\n- Apply proper HTML formatting to description field\n- Set both Original Estimate and Completed Work to the completed hours value\n- Leave Remaining Work empty (do not set)\n- Auto-generate title and description in AI mode\n- Always confirm AI-generated content before using\n- Use manual input directly without modification in Manual mode\n- Calculate placeholder task updates correctly\n- Show clear success message with all relevant details\n- Provide helpful next steps and links\n\n### Error Handling\n\nIf the MCP tool returns an error:\n- Display the error message to the user\n- Suggest possible solutions:\n  - Verify the parent User Story ID is a valid number\n  - Verify the placeholder Task ID exists and is valid (if applicable)\n  - Verify Azure DevOps MCP server is configured and running\n  - Check that project and team names are correct\n  - Ensure user has permissions to create and update work items\n  - Verify Node.js 20+ is installed for MCP server\n  - Check that hour values are valid numeric values\n  - Ensure git repository is accessible if commit hash was provided\n- Recommend running /ado-init if configuration seems incorrect\n- If parent ID is invalid, suggest using /ado-create-story first\n- If git command fails, suggest verifying the commit hash is valid\n\nIf git commit lookup fails:\n- Display a warning that commit could not be found\n- Continue with task generation using only the user's description (without commit context)\n- Do not stop the entire command flow"
              },
              {
                "name": "/ado-timesheet-report",
                "description": "Generate a summarized report of hours logged from work items during a specified week.",
                "path": "plugins/ai-ado/commands/ado-timesheet-report.md",
                "frontmatter": {
                  "name": "ado-timesheet-report",
                  "description": "Generate a summarized report of hours logged from work items during a specified week."
                },
                "content": "# Generate Weekly Timesheet Report\n\nGenerate a summarized report of hours logged from work items during a specified week, with flexible filtering options for closed, worked on, or both types of tasks. Report is organized in a hierarchical tree structure by Feature > User Story > Task.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, dates, week specifications, or other arguments after this command (e.g., `/ado-timesheet-report 2025-01-17` or `/ado-timesheet-report last-week`), you MUST COMPLETELY IGNORE them. Do NOT use any dates, time periods, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive AskUserQuestion tool as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Validate Azure DevOps configuration in CLAUDE.md, then use the AskUserQuestion tool to gather report parameters. DO NOT skip these steps even if the user provided arguments after the command.\n\nThis command retrieves work items from Azure DevOps for the authenticated user and applies client-side filtering based on flexible criteria (closed, worked on, or both) during a specified time period. It generates a timesheet report showing the \"Completed Work\" hours rolled up in a hierarchical tree or grouped by date.\n\n### Phase 1: Validate Azure DevOps Configuration\n\nBefore proceeding with report generation, verify that Azure DevOps configuration exists:\n\n1. Use the **Read tool** to read `CLAUDE.md` from the project root\n2. If the file doesn't exist OR doesn't contain an \"## Azure DevOps\" section:\n   - Display the following error message:\n     ```\n     ‚ùå Azure DevOps configur ation not found\n\n     CLAUDE.md does not contain Azure DevOps configuration.\n\n     Please run /ado-init first to configure Azure DevOps settings for this project.\n\n     The /ado-init command will:\n     - Configure your organization, project, and team\n     - Set up Area Path and Iteration Path defaults\n     - Define naming conventions and work item guidelines\n     - Optionally configure the Azure DevOps MCP server\n     ```\n   - **STOP** and do not proceed further\n\n3. If Azure DevOps section exists:\n   - Parse the CLAUDE.md content to extract configuration values:\n     - Organization name (look for text after 'Organization:**')\n     - Project name (look for text after 'Project:**')\n   - Store these values for use in work item queries\n   - Proceed to Phase 2\n\n**IMPORTANT**:\n- Use **Read tool** to check CLAUDE.md - DO NOT use bash commands\n- The entire command should STOP if Azure DevOps configuration is not found\n- Do not prompt the user for configuration values - they must run /ado-init first\n\n### Phase 2: Gather Report Parameters\n\nCollect report parameters from the user using the AskUserQuestion tool to ask multiple questions at once.\n\n**Step 1 - Report Configuration (4 questions combined):**\n\nUse the **AskUserQuestion tool** to ask all report configuration questions at once:\n\n```json\n{\n  \"questions\": [\n    {\n      \"question\": \"What is your organization's work week definition?\",\n      \"header\": \"Week Type\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Sunday-Saturday\",\n          \"description\": \"Sunday through Saturday week\"\n        },\n        {\n          \"label\": \"Monday-Sunday\",\n          \"description\": \"ISO standard week (Monday through Sunday)\"\n        }\n      ]\n    },\n    {\n      \"question\": \"Which time period would you like to report on?\",\n      \"header\": \"Time Period\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Current week\",\n          \"description\": \"Report on the current week\"\n        },\n        {\n          \"label\": \"Last week\",\n          \"description\": \"Report on last week\"\n        },\n        {\n          \"label\": \"Specific week\",\n          \"description\": \"Provide a specific end date for the week\"\n        }\n      ]\n    },\n    {\n      \"question\": \"What types of tasks would you like to include in the report?\",\n      \"header\": \"Task Filter\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Closed only\",\n          \"description\": \"Only tasks that were closed during the time period\"\n        },\n        {\n          \"label\": \"Worked on only\",\n          \"description\": \"Only tasks that were worked on (but not closed) during the time period\"\n        },\n        {\n          \"label\": \"Both\",\n          \"description\": \"Both closed and worked-on tasks during the time period\"\n        }\n      ]\n    },\n    {\n      \"question\": \"Which date field should be used to filter tasks within the time period? (If you selected 'Worked on only', 'Changed Date' is recommended)\",\n      \"header\": \"Date Field\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Closed Date\",\n          \"description\": \"When the task was marked as closed (best for 'closed only' filter)\"\n        },\n        {\n          \"label\": \"Changed Date\",\n          \"description\": \"When the task was last updated (best for 'worked on' or 'both' filters)\"\n        }\n      ]\n    }\n  ]\n}\n```\n\nWait for the user's response before proceeding.\n\n**Step 1a - End Date (only if user chose \"Specific week\"):**\n\nIf the user chose \"Specific week\" in Step 1, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the end date for the week you want to report on?\n\nPlease provide the date in YYYY-MM-DD format (e.g., 2025-01-17 for the week ending January 17, 2025).\"\n\nWait for the user's next message with the end date before proceeding.\n\nIf the user chose \"Current week\" or \"Last week\" in Step 1, skip Step 1a and proceed to Step 2.\n\n**Step 2 - Display Options (3 questions combined):**\n\nAfter handling the optional end date, use the **AskUserQuestion tool** to ask display-related questions:\n\n```json\n{\n  \"questions\": [\n    {\n      \"question\": \"What level of detail would you like in the report?\",\n      \"header\": \"Verbosity\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Level 1\",\n          \"description\": \"Work Item ID & Hours Only\"\n        },\n        {\n          \"label\": \"Level 2\",\n          \"description\": \"Work Item ID, Title, and Hours\"\n        },\n        {\n          \"label\": \"Level 3\",\n          \"description\": \"Work Item ID, Title, Description, and Hours\"\n        }\n      ]\n    },\n    {\n      \"question\": \"How would you like to organize the report?\",\n      \"header\": \"Grouping\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"By date\",\n          \"description\": \"Group by day of the week with work items under each date\"\n        },\n        {\n          \"label\": \"By hierarchy\",\n          \"description\": \"Group by Feature > User Story > Task (traditional tree view)\"\n        },\n        {\n          \"label\": \"By date with hierarchy\",\n          \"description\": \"Group by day, then show Feature > User Story > Task within each day\"\n        }\n      ]\n    },\n    {\n      \"question\": \"Whose hours would you like to report on?\",\n      \"header\": \"User\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Current user\",\n          \"description\": \"Current authenticated user (default)\"\n        },\n        {\n          \"label\": \"Specific team member\",\n          \"description\": \"Provide a specific team member's name\"\n        }\n      ]\n    }\n  ]\n}\n```\n\nWait for the user's response before proceeding.\n\n**Step 2a - Team Member Name (only if user chose \"Specific team member\"):**\n\nIf the user chose \"Specific team member\" in Step 2, simply output the following text as your response message and STOP (DO NOT call any tools):\n\n\"What is the name of the team member to report on?\n\nPlease provide the full name as it appears in Azure DevOps (e.g., 'John Smith').\"\n\nWait for the user's next message with the team member name before proceeding.\n\nIf the user chose \"Current user\" in Step 2, skip Step 2a and proceed to Phase 3.\n\n**IMPORTANT**:\n- Use **AskUserQuestion tool** twice:\n  - Step 1: Ask 4 report configuration questions together (week definition, time period, task filter type, date field)\n  - Step 2: Ask 3 display option questions together (verbosity level, grouping mode, user selection)\n- Use simple text output for conditional free-form inputs:\n  - Step 1a: End date (only if \"Specific week\" was selected)\n  - Step 2a: Team member name (only if \"Specific team member\" was selected)\n- Wait for the user's response after each step before proceeding\n- Store all collected values for use in Phase 3, 4, 5, and 6:\n  - Week definition (Monday-Sunday or Sunday-Saturday)\n  - Time period (Current week, Last week, or Specific week)\n  - End date (if Specific week selected)\n  - Task filter type (Closed only, Worked on only, or Both)\n  - Date field (Closed Date or Changed Date)\n  - Verbosity level (Level 1, Level 2, or Level 3)\n  - Grouping mode (By hierarchy, By date, or By date with hierarchy)\n  - User selection (Current user or team member name)\n- Calculate the date range based on user's choices:\n  - For \"Current week\": Calculate current week's start and end dates\n  - For \"Last week\": Calculate last week's start and end dates\n  - For \"Specific week\": Calculate the week's start date from the provided end date\n- Week calculation should use the week definition from Step 1\n\n### Phase 3: Calculate Date Range\n\nBased on the user's time period selection and week definition, calculate the start and end dates:\n\n1. **Determine today's date** using the current system date\n   - The system provides the current date in `<env>` section as \"Today's date: YYYY-MM-DD\"\n   - This is in ISO 8601 format where YYYY-MM-DD means Year-Month-Day\n   - For example: 2025-10-23 is October 23, 2025 (NOT January 23)\n   - **IMPORTANT**: Trust this date exactly as provided - do NOT second-guess or reinterpret the format\n   - The month is always the middle number (01=January, 02=February, ... 10=October, 11=November, 12=December)\n\n2. **Calculate date range** based on user selections:\n\n   **Step 1: Determine today's day of the week using system commands**\n\n   Use the **Bash tool** to execute a platform-specific command. Check the platform from `<env>`:\n\n   - **If platform is `win32` (Windows)**:\n     Execute PowerShell command using the **Bash tool**:\n     ```bash\n     powershell -Command \"(Get-Date 'YYYY-MM-DD').DayOfWeek.value__\"\n     ```\n     Replace `YYYY-MM-DD` with today's date from `<env>`.\n\n     This returns a number 0-6 where:\n     - 0 = Sunday\n     - 1 = Monday\n     - 2 = Tuesday\n     - 3 = Wednesday\n     - 4 = Thursday\n     - 5 = Friday\n     - 6 = Saturday\n\n   - **If platform is `darwin` (Mac) or `linux`**:\n     Execute bash command:\n     ```bash\n     date -d \"YYYY-MM-DD\" +%u\n     ```\n     Replace `YYYY-MM-DD` with today's date from `<env>`.\n\n     This returns a number 1-7 where:\n     - 1 = Monday\n     - 2 = Tuesday\n     - 3 = Wednesday\n     - 4 = Thursday\n     - 5 = Friday\n     - 6 = Saturday\n     - 7 = Sunday\n\n   **Step 2: Calculate the date range based on the day of week value**\n\n   **For \"Current week\":**\n\n   - **If week is Monday-Sunday**:\n     - **On Windows** (day_of_week is 0-6):\n       - If day_of_week = 1 (Monday): days_to_subtract = 0\n       - If day_of_week = 2 (Tuesday): days_to_subtract = 1\n       - If day_of_week = 3 (Wednesday): days_to_subtract = 2\n       - If day_of_week = 4 (Thursday): days_to_subtract = 3\n       - If day_of_week = 5 (Friday): days_to_subtract = 4\n       - If day_of_week = 6 (Saturday): days_to_subtract = 5\n       - If day_of_week = 0 (Sunday): days_to_subtract = 6\n     - **On Mac/Linux** (day_of_week is 1-7):\n       - days_to_subtract = day_of_week - 1\n     - Start date = Today - days_to_subtract (this gives you the Monday of the current week)\n     - End date = Start date + 6 days (this gives you the Sunday of the current week)\n\n   - **If week is Sunday-Saturday**:\n     - **On Windows** (day_of_week is 0-6):\n       - days_to_subtract = day_of_week\n     - **On Mac/Linux** (day_of_week is 1-7):\n       - If day_of_week = 7 (Sunday): days_to_subtract = 0\n       - Otherwise: days_to_subtract = day_of_week\n     - Start date = Today - days_to_subtract (this gives you the Sunday of the current week)\n     - End date = Start date + 6 days (this gives you the Saturday of the current week)\n\n   **Example for Monday-Sunday week:**\n   - If today is October 24, 2025 (Friday):\n     - On Windows: PowerShell returns 5 (Friday)\n       - days_to_subtract = 4\n     - On Mac/Linux: bash returns 5 (Friday)\n       - days_to_subtract = 5 - 1 = 4\n     - Start date = Oct 24 - 4 days = October 20, 2025 (Monday)\n     - End date = Oct 20 + 6 days = October 26, 2025 (Sunday)\n     - **Result: October 20-26, 2025**\n\n   **For \"Last week\":**\n\n   - If week is Monday-Sunday:\n     1. Calculate the current week's Monday using the algorithm above\n     2. Start date = Current week's Monday - 7 days (Monday of last week)\n     3. End date = Start date + 6 days (Sunday of last week)\n\n   - If week is Sunday-Saturday:\n     1. Calculate the current week's Sunday using the algorithm above\n     2. Start date = Current week's Sunday - 7 days (Sunday of last week)\n     3. End date = Start date + 6 days (Saturday of last week)\n\n   **For \"Specific week\":**\n   - End date: User-provided date\n   - If week is Monday-Sunday:\n     - Validate that the end date is a Sunday\n     - Start date: 6 days before the end date (the Monday)\n   - If week is Sunday-Saturday:\n     - Validate that the end date is a Saturday\n     - Start date: 6 days before the end date (the Sunday)\n\n3. **Format dates** in ISO 8601 format (YYYY-MM-DD) for use in client-side filtering\n\n**IMPORTANT**:\n- All date calculations should be done programmatically (don't ask user for date calculations)\n- **CRITICAL**: Use the Bash tool with platform-specific commands to determine day of week\n  - On Windows (platform: win32): `powershell -Command \"(Get-Date 'YYYY-MM-DD').DayOfWeek.value__\"` (returns 0-6)\n  - On Mac/Linux (platform: darwin/linux): `date -d \"YYYY-MM-DD\" +%u` (returns 1-7)\n  - DO NOT manually calculate day of week - the system command is authoritative\n- **CRITICAL**: Follow the lookup tables exactly for days_to_subtract calculation\n  - Windows and Mac/Linux use different numbering systems (0-6 vs 1-7)\n  - Verify your calculation matches the example: Oct 24 (Fri) ‚Üí Oct 20-26 (Mon-Sun)\n- For specific week option, validate that the end date matches the expected day of week using the same system commands\n- If validation fails, display helpful error message and ask user to provide correct end date\n- Store calculated start_date and end_date for use in Phase 4\n\n### Phase 4: Retrieve and Filter Work Items\n\nRetrieve work items from Azure DevOps and apply client-side filtering based on the user's filter choices:\n\n1. **Retrieve work items** using the **wit_my_work_items** MCP tool:\n   - `project`: Project name from Phase 1 configuration\n   - This returns all work items relevant to the authenticated user\n   - The response includes work item details with all necessary fields\n\n2. **Resolve team member identity** (if \"Specific team member\" was selected):\n   - If user chose \"Specific team member\" in Phase 2:\n     - Use **core_get_identity_ids** MCP tool to resolve the team member's identity\n     - `uniqueNames`: Array containing the team member name from Phase 2 (e.g., `[\"John Smith\"]`)\n     - Extract the identity ID from the response to match against AssignedTo fields\n   - If user chose \"Current user\":\n     - Skip this step and filter by current authenticated user\n\n3. **Filter work items client-side** based on user selections from Phase 2:\n\n   **Step 3a - Filter by Completed Work:**\n   - Keep only work items where `Microsoft.VSTS.Scheduling.CompletedWork` field exists and is greater than 0\n   - Work items without logged hours should be excluded\n\n   **Step 3b - Filter by User Assignment:**\n   - If \"Current user\" was selected:\n     - Keep work items assigned to the current authenticated user\n     - Compare `System.AssignedTo` field with current user identity\n   - If \"Specific team member\" was selected:\n     - Keep work items assigned to the resolved team member identity\n     - Compare `System.AssignedTo` field with the identity from step 2\n\n   **Step 3c - Determine Date Field to Use:**\n   - If user chose \"Closed Date\": Use `Microsoft.VSTS.Common.ClosedDate` field\n   - If user chose \"Changed Date\": Use `System.ChangedDate` field\n   - **Exception**: If task filter type is \"Worked on only\", always use `System.ChangedDate` regardless of user's date field choice (non-closed tasks won't have ClosedDate)\n\n   **Step 3d - Filter by Date Range:**\n   - Parse the date field value determined in Step 3c (format: \"2025-10-23T14:30:00Z\")\n   - **Extract only the date portion** (YYYY-MM-DD) by taking the first 10 characters or splitting on 'T'\n     - Example: \"2025-10-23T14:30:00Z\" ‚Üí \"2025-10-23\"\n     - This ensures time of day doesn't affect the comparison\n   - Compare the extracted date string against START_DATE and END_DATE (also in YYYY-MM-DD format)\n   - Keep work items where: `date >= START_DATE AND date <= END_DATE` (inclusive on both ends)\n   - **CRITICAL**: Do NOT use full datetime comparison - only compare date portions\n     - Work items created/modified at any time during START_DATE should be included\n     - Work items created/modified at any time during END_DATE should be included\n   - Handle missing/null date fields gracefully:\n     - If date field is null/missing, exclude the work item\n     - This is common for work items that haven't been closed yet (when using ClosedDate)\n\n   **Step 3e - Filter by State (based on task filter type):**\n   - If \"Closed only\": Keep only work items where `System.State === 'Closed'`\n   - If \"Worked on only\": Keep only work items where `System.State !== 'Closed'`\n   - If \"Both\": Keep all work items regardless of state\n\n4. **Extract work item data** from filtered results:\n   - For each remaining work item, extract:\n     - ID (`System.Id`)\n     - Type (`System.WorkItemType`)\n     - Title (`System.Title`)\n     - Description (`System.Description`) - only if verbosity level 3\n     - Parent ID (`System.Parent`)\n     - Completed Work hours (`Microsoft.VSTS.Scheduling.CompletedWork`)\n     - Assigned To (`System.AssignedTo`)\n     - State (`System.State`)\n     - Work Date - The date field that was used for filtering:\n       - If \"Closed Date\" was used: Extract `Microsoft.VSTS.Common.ClosedDate`\n       - If \"Changed Date\" was used: Extract `System.ChangedDate`\n       - Parse the date to extract day of week (for date-based grouping)\n\n5. **Sort work items**:\n   - Sort by Parent ID (ascending)\n   - Then by Work Item Type (ascending)\n   - Then by ID (ascending)\n   - This makes hierarchy building easier in Phase 5\n\n6. **Store filtered work items** in a data structure for tree building in Phase 5\n\n**IMPORTANT**:\n- Use **wit_my_work_items** MCP tool to retrieve all work items for the authenticated user\n- Use **core_get_identity_ids** MCP tool only if \"Specific team member\" was selected\n- All filtering logic is performed client-side after retrieving work items\n- For \"Worked on only\" filter, always use `System.ChangedDate` (override user's date field choice)\n- **Critical**: Date fields in Azure DevOps are in ISO 8601 format (e.g., \"2025-01-17T14:30:00Z\")\n  - Parse the date string carefully\n  - **MUST extract only the date portion (YYYY-MM-DD)** - take first 10 characters or split on 'T'\n  - **DO NOT use datetime comparison** - this would exclude work items based on time of day\n  - Compare date strings directly: `date >= START_DATE AND date <= END_DATE`\n  - Work items at ANY time on START_DATE or END_DATE must be included (00:00:00 to 23:59:59)\n- Handle missing/null fields gracefully:\n  - CompletedWork might be 0 or null ‚Üí exclude\n  - ClosedDate might be null for non-closed items ‚Üí exclude if using ClosedDate filter\n  - ChangedDate should always exist ‚Üí but check just in case\n  - Parent might be null ‚Üí handle in Phase 5 (orphaned items)\n- Extract State field for filtering and potential display in report\n- Work items can be of any type (Task, Bug, Issue, User Story, Feature, etc.) as long as they have logged hours\n- The filtering order matters:\n  1. First filter by CompletedWork > 0 (most selective)\n  2. Then filter by user assignment\n  3. Then filter by date range\n  4. Finally filter by state\n- Store the actual date value used for filtering (for date-based grouping in Phase 5)\n\n### Phase 5: Organize Work Items Based on Grouping Mode\n\nOrganize the work items based on the user's selected grouping mode:\n\n**If user chose \"By hierarchy\":**\n\n1. **Create parent-child relationships**:\n   - Group work items by their Parent ID\n   - Build a tree structure where:\n     - Features are top-level nodes (no parent or parent is Epic)\n     - User Stories are children of Features\n     - Tasks, Bugs, Issues are children of User Stories\n     - Work items with no parent go under \"No Parent\" group\n\n2. **Calculate rolled-up hours**:\n   - For each parent node (Feature, User Story):\n     - Sum the Completed Work hours of all child work items\n     - Recursively sum hours from all descendants\n   - Only leaf nodes (Tasks, Bugs, Issues) have direct hours\n   - Parent hours are the sum of their children's hours\n\n3. **Sort the tree**:\n   - Sort Features by ID (ascending)\n   - Within each Feature, sort User Stories by ID (ascending)\n   - Within each User Story, sort Tasks/Bugs/Issues by ID (ascending)\n   - \"No Parent\" group appears at the end\n\n**If user chose \"By date\":**\n\n1. **Group work items by date**:\n   - Extract the date portion from the Work Date field (ignore time)\n   - Group all work items by their date\n   - Create a flat list structure (no hierarchy)\n\n2. **Calculate daily totals**:\n   - Sum the Completed Work hours for all work items on each date\n   - Only include work items with CompletedWork > 0\n\n3. **Sort by date**:\n   - Sort dates chronologically (earliest to latest)\n   - Within each date, sort work items by ID (ascending)\n\n**If user chose \"By date with hierarchy\":**\n\n1. **Group work items by date first**:\n   - Extract the date portion from the Work Date field (ignore time)\n   - Group all work items by their date\n\n2. **Build hierarchy within each date**:\n   - For work items on each date, create parent-child relationships\n   - Build a tree structure where:\n     - Features are top-level nodes (no parent or parent is Epic)\n     - User Stories are children of Features\n     - Tasks, Bugs, Issues are children of User Stories\n     - Work items with no parent go under \"No Parent\" group\n\n3. **Calculate hours**:\n   - Calculate rolled-up hours within each date's hierarchy\n   - Calculate total hours for each date (sum of all work items that day)\n\n4. **Sort**:\n   - Sort dates chronologically (earliest to latest)\n   - Within each date, sort Features by ID, then User Stories, then Tasks\n\n**IMPORTANT**:\n- Handle orphaned work items (no parent) appropriately for each grouping mode\n- Only count hours from work items with Completed Work > 0\n- For hierarchy modes: Parent nodes show sum of child hours\n- For date modes: Extract date correctly from the date field used in the query\n- Maintain proper hierarchy: Feature > User Story > Task/Bug/Issue\n- Work items can be of any type (Task, Bug, Issue, etc.) as long as they have hours\n\n### Phase 6: Display Timesheet Report\n\nGenerate and display the timesheet report based on the grouping mode and verbosity level:\n\n**Report Header:**\n```\nüìä Timesheet Report\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüìÖ Period: [START_DATE] to [END_DATE] ([WEEK_TYPE])\nüë§ User: [USER_NAME]\nüîç Filter: [FILTER_DESCRIPTION]\nüìÖ Date Field: [DATE_FIELD_NAME]\n‚è±Ô∏è  Total Hours: [TOTAL_HOURS]\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n```\n\nReplace placeholders:\n- `[START_DATE]` ‚Üí Formatted start date (e.g., \"Jan 13, 2025\")\n- `[END_DATE]` ‚Üí Formatted end date (e.g., \"Jan 19, 2025\")\n- `[WEEK_TYPE]` ‚Üí \"Monday-Sunday\" or \"Sunday-Saturday\"\n- `[USER_NAME]` ‚Üí Name of user being reported on\n- `[FILTER_DESCRIPTION]` ‚Üí \"Closed only\" / \"Worked on only\" / \"Both closed and worked on\" (based on Step 3 choice)\n- `[DATE_FIELD_NAME]` ‚Üí \"Closed Date\" / \"Changed Date\" (based on Step 4 choice, or \"Changed Date\" if worked on only)\n- `[TOTAL_HOURS]` ‚Üí Sum of all hours in the report\n\n**Tree Structure Format:**\n\n**Verbosity Level 1 (ID & Hours Only):**\n```\nüì¶ Feature [FEATURE_ID] (Total: [FEATURE_HOURS]h)\n  üìã Story [STORY_ID] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_HOURS]h\n    ‚úì Bug [BUG_ID]: [BUG_HOURS]h\n  üìã Story [STORY_ID] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_HOURS]h\n\nüì¶ Feature [FEATURE_ID] (Total: [FEATURE_HOURS]h)\n  üìã Story [STORY_ID] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_HOURS]h\n\nüîç No Parent\n  üìã Story [STORY_ID] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_HOURS]h\n  ‚úì Task [TASK_ID]: [TASK_HOURS]h\n```\n\n**Verbosity Level 2 (ID, Title, & Hours):**\n```\nüì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n    ‚úì Bug [BUG_ID]: [BUG_TITLE] - [BUG_HOURS]h\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n\nüì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n\nüîç No Parent\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n  ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n```\n\n**Verbosity Level 3 (ID, Title, Description, & Hours):**\n```\nüì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n      üìù [TASK_DESCRIPTION]\n    ‚úì Bug [BUG_ID]: [BUG_TITLE] - [BUG_HOURS]h\n      üìù [BUG_DESCRIPTION]\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n      üìù [TASK_DESCRIPTION]\n\nüì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n      üìù [TASK_DESCRIPTION]\n\nüîç No Parent\n  üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n      üìù [TASK_DESCRIPTION]\n  ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n    üìù [TASK_DESCRIPTION]\n```\n\n---\n\n**\"By date\" Grouping Mode Formats:**\n\nWhen user selects \"By date\" grouping, work items are organized by date with a flat list (no hierarchy) under each date.\n\n**Verbosity Level 1 (ID & Hours Only):**\n```\nüìÖ Monday, Oct 21, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [HOURS]h\n  ‚Ä¢ [WORK_ITEM_ID]: [HOURS]h\n  ‚Ä¢ [WORK_ITEM_ID]: [HOURS]h\n\nüìÖ Tuesday, Oct 22, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [HOURS]h\n  ‚Ä¢ [WORK_ITEM_ID]: [HOURS]h\n\nüìÖ Wednesday, Oct 23, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [HOURS]h\n```\n\n**Verbosity Level 2 (ID, Title, & Hours):**\n```\nüìÖ Monday, Oct 21, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n\nüìÖ Tuesday, Oct 22, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n\nüìÖ Wednesday, Oct 23, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n```\n\n**Verbosity Level 3 (ID, Title, Description, & Hours):**\n```\nüìÖ Monday, Oct 21, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n    üìù [WORK_ITEM_DESCRIPTION]\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n    üìù [WORK_ITEM_DESCRIPTION]\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n    üìù [WORK_ITEM_DESCRIPTION]\n\nüìÖ Tuesday, Oct 22, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n    üìù [WORK_ITEM_DESCRIPTION]\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n    üìù [WORK_ITEM_DESCRIPTION]\n\nüìÖ Wednesday, Oct 23, 2025 (Total: [DATE_HOURS]h)\n  ‚Ä¢ [WORK_ITEM_ID]: [WORK_ITEM_TITLE] - [HOURS]h\n    üìù [WORK_ITEM_DESCRIPTION]\n```\n\n---\n\n**\"By date with hierarchy\" Grouping Mode Formats:**\n\nWhen user selects \"By date with hierarchy\" grouping, work items are organized by date first, then hierarchical tree structure within each date.\n\n**Verbosity Level 1 (ID & Hours Only):**\n```\nüìÖ Monday, Oct 21, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_HOURS]h\n      ‚úì Bug [BUG_ID]: [BUG_HOURS]h\n  üîç No Parent\n    ‚úì Task [TASK_ID]: [TASK_HOURS]h\n\nüìÖ Tuesday, Oct 22, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_HOURS]h\n\nüìÖ Wednesday, Oct 23, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_HOURS]h\n      ‚úì Task [TASK_ID]: [TASK_HOURS]h\n```\n\n**Verbosity Level 2 (ID, Title, & Hours):**\n```\nüìÖ Monday, Oct 21, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n      ‚úì Bug [BUG_ID]: [BUG_TITLE] - [BUG_HOURS]h\n  üîç No Parent\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n\nüìÖ Tuesday, Oct 22, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n\nüìÖ Wednesday, Oct 23, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n```\n\n**Verbosity Level 3 (ID, Title, Description, & Hours):**\n```\nüìÖ Monday, Oct 21, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n        üìù [TASK_DESCRIPTION]\n      ‚úì Bug [BUG_ID]: [BUG_TITLE] - [BUG_HOURS]h\n        üìù [BUG_DESCRIPTION]\n  üîç No Parent\n    ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n      üìù [TASK_DESCRIPTION]\n\nüìÖ Tuesday, Oct 22, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n        üìù [TASK_DESCRIPTION]\n\nüìÖ Wednesday, Oct 23, 2025 (Total: [DATE_HOURS]h)\n  üì¶ Feature [FEATURE_ID]: [FEATURE_TITLE] (Total: [FEATURE_HOURS]h)\n    üìã Story [STORY_ID]: [STORY_TITLE] (Total: [STORY_HOURS]h)\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n        üìù [TASK_DESCRIPTION]\n      ‚úì Task [TASK_ID]: [TASK_TITLE] - [TASK_HOURS]h\n        üìù [TASK_DESCRIPTION]\n```\n\n---\n\n**Work Item Type Icons:**\n- Feature: üì¶\n- User Story: üìã\n- Task: ‚úì\n- Bug: üêõ\n- Issue: ‚ö†Ô∏è\n- Other types: ‚Ä¢\n\n**Description Formatting (Level 3 only):**\n- Strip HTML tags from description field\n- Limit description to first 100 characters\n- Add \"...\" if truncated\n- Indent description with 6 spaces for proper tree alignment\n\n**Report Footer:**\n```\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚è±Ô∏è  Total Hours: [TOTAL_HOURS]\nüìä Work Items: [WORK_ITEM_COUNT] ([FEATURE_COUNT] Features, [STORY_COUNT] Stories, [TASK_COUNT] Tasks/Bugs/Issues)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nüí° Tip: [FILTER_TIP]\n   Only work items with logged \"Completed Work\" hours are included.\n```\n\n**Filter Tip Text** (based on task filter type from Step 3):\n- Option 1 (Closed only): \"This report shows work items that were closed during the specified period.\"\n- Option 2 (Worked on only): \"This report shows work items that were worked on (but not closed) during the specified period.\"\n- Option 3 (Both): \"This report shows all work items (both closed and worked on) during the specified period.\"\n\nReplace placeholders:\n- `[TOTAL_HOURS]` ‚Üí Total hours across all work items\n- `[WORK_ITEM_COUNT]` ‚Üí Total count of all work items\n- `[FEATURE_COUNT]` ‚Üí Count of Features\n- `[STORY_COUNT]` ‚Üí Count of User Stories\n- `[TASK_COUNT]` ‚Üí Count of Tasks, Bugs, Issues combined\n\n**IMPORTANT**:\n- Use proper indentation for tree hierarchy (2 spaces per level)\n- Show totals at each parent level (sum of children) for hierarchy-based grouping\n- Use appropriate icons for different work item types\n- For verbosity level 3, strip HTML and truncate descriptions\n- Display \"No Parent\" section only if there are orphaned work items (for hierarchy-based grouping)\n- Format hours with 1 decimal place (e.g., \"2.5h\" not \"2.50h\")\n- If no work items found, display a friendly message indicating no hours were logged during the period\n- **Select the correct display format** based on grouping mode:\n  - \"By hierarchy\": Use traditional tree structure (Feature > Story > Task)\n  - \"By date\": Use date headers with flat work item lists (no hierarchy)\n  - \"By date with hierarchy\": Use date headers with tree structure within each date\n- For date-based grouping modes, format dates as \"Day of Week, Month DD, YYYY\" (e.g., \"Monday, Oct 21, 2025\")\n- For date-based grouping modes, show total hours for each date\n\n### Important Constraints\n\n**DO NOT:**\n- Proceed without Azure DevOps configuration in CLAUDE.md\n- Use bash commands for file operations\n- Use AskUserQuestion for free-form input steps (Steps 1a and 2a should be simple text output)\n- Ask questions one at a time when they can be combined (use the 2-step approach described in Phase 2)\n- Include work items with Completed Work = 0 or null\n- Use ClosedDate when user selected \"worked on only\" filter (must use ChangedDate)\n- Use placeholders or empty values in the report\n- Ignore the task filter type or date field selections from Phase 2\n- Second-guess or reinterpret the current date from `<env>` - trust it exactly as ISO 8601 format (YYYY-MM-DD where month is middle number)\n- Manually calculate day of week - ALWAYS use system commands (PowerShell on Windows, date on Mac/Linux)\n- Skip client-side filtering steps (all filtering must be done after retrieving work items)\n\n**DO:**\n- Use **Read tool** to check CLAUDE.md for Azure DevOps configuration\n- Use **AskUserQuestion tool** exactly twice in Phase 2:\n  - Step 1: Combine 4 report configuration questions (week definition, time period, task filter type, date field)\n  - Step 2: Combine 3 display option questions (verbosity level, grouping mode, user selection)\n- Use simple text output for conditional free-form inputs (Steps 1a and 2a)\n- Wait for user's response after each step before proceeding\n- Trust the current date from `<env>` exactly as provided in ISO 8601 format (YYYY-MM-DD)\n- Remember: In ISO format, month is the MIDDLE number (01=Jan, 02=Feb, 03=Mar, 04=Apr, 05=May, 06=Jun, 07=Jul, 08=Aug, 09=Sep, 10=Oct, 11=Nov, 12=Dec)\n- **CRITICAL**: Use **Bash tool** with platform-specific system commands to determine day of week:\n  - Windows: `powershell -Command \"(Get-Date 'YYYY-MM-DD').DayOfWeek.value__\"` (returns 0-6)\n  - Mac/Linux: `date -d \"YYYY-MM-DD\" +%u` (returns 1-7)\n  - Follow the lookup tables in Phase 3 exactly for calculating days_to_subtract\n  - DO NOT manually calculate day of week\n- Use **wit_my_work_items** MCP tool to retrieve work items for the authenticated user\n- Use **core_get_identity_ids** MCP tool to resolve team member identities (only if \"Specific team member\" was selected)\n- Perform all filtering client-side after retrieving work items:\n  - Filter by CompletedWork > 0 first\n  - Filter by user assignment\n  - Filter by date range (using appropriate date field)\n  - Filter by state (based on task filter type)\n- Use correct Azure DevOps field names when filtering:\n  - Closed Date field: `Microsoft.VSTS.Common.ClosedDate`\n  - Changed Date field: `System.ChangedDate`\n  - State field: `System.State`\n  - Completed Work field: `Microsoft.VSTS.Scheduling.CompletedWork`\n- For \"Worked on only\" filter, always use `System.ChangedDate` (override user's date field choice)\n- Parse ISO 8601 date strings carefully and **compare date portions only (YYYY-MM-DD)**\n  - Extract first 10 characters from datetime strings before comparison\n  - Do NOT use full datetime comparison with time components\n  - This ensures work items at any time during the day are included\n- Always filter by CompletedWork > 0\n- Organize work items based on grouping mode selection:\n  - \"By hierarchy\": Build proper hierarchical tree structure and roll up hours from children to parents\n  - \"By date\": Group by date with flat list (no hierarchy)\n  - \"By date with hierarchy\": Group by date first, then build hierarchy within each date\n- Handle orphaned work items under \"No Parent\" (for hierarchy-based grouping modes)\n- Handle missing/null date fields gracefully (exclude work items with missing dates)\n- Display report with appropriate verbosity level and grouping mode format\n- Use proper formatting with emojis and tree structure (or flat list for \"By date\" mode)\n- Show helpful summary statistics in footer with filter-appropriate tip text\n- Format dates in user-friendly format (e.g., \"Jan 13, 2025\" for report header, \"Monday, Oct 21, 2025\" for date grouping)\n- Format hours with appropriate precision\n\n### Error Handling\n\nIf the MCP tool returns an error:\n- Display the error message to the user\n- Suggest possible solutions:\n  - **For wit_my_work_items errors**:\n    - Verify Azure DevOps MCP server is configured and running\n    - Check that project name is correct\n    - Ensure user has permissions to query work items\n    - Verify Node.js 20+ is installed for MCP server\n    - Recommend running /ado-init if configuration seems incorrect\n  - **For core_get_identity_ids errors**:\n    - Verify the team member name is spelled correctly\n    - Check that the team member exists in the Azure DevOps organization\n    - Try using the exact display name as it appears in Azure DevOps\n    - Suggest using \"Current user\" option instead if team member cannot be resolved\n\nIf client-side filtering finds no matching work items:\n- This is not an error, but an expected outcome\n- The report will display the \"No work items found\" message with helpful tips\n- Common reasons:\n  - No work items had logged hours during the time period\n  - The selected user had no work items assigned\n  - The date range or state filter was too restrictive\n  - Work items exist but lack CompletedWork values\n\nIf no work items are found:\n- Display a friendly message (customize based on task filter type):\n  ```\n  üìä Timesheet Report\n  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n  üìÖ Period: [START_DATE] to [END_DATE] ([WEEK_TYPE])\n  üë§ User: [USER_NAME]\n  üîç Filter: [FILTER_DESCRIPTION]\n  üìÖ Date Field: [DATE_FIELD_NAME]\n  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n  No work items with logged hours were found for this period.\n\n  This could mean:\n  - No work items matched the filter criteria during this time period\n  - No work items had \"Completed Work\" hours logged\n  - The specified user had no work items assigned\n\n  üí° Tip: Make sure to set \"Completed Work\" hours on tasks before\n     closing them, or use /ado-log-story-work to log hours.\n  ```\n\n  Replace placeholders:\n  - `[FILTER_DESCRIPTION]`: \"Closed only\" / \"Worked on only\" / \"Both closed and worked on\"\n  - `[DATE_FIELD_NAME]`: \"Closed Date\" / \"Changed Date\"\n\nIf date validation fails (for specific week option):\n- Display helpful error message:\n  ```\n  ‚ùå Invalid end date for week definition\n\n  For [WEEK_TYPE] weeks, the end date must be a [EXPECTED_DAY].\n  You provided: [PROVIDED_DATE] which is a [ACTUAL_DAY].\n\n  Please provide an end date that falls on a [EXPECTED_DAY].\n  ```\n\n### Additional Features\n\n**Date Formatting:**\n- Input dates: YYYY-MM-DD (e.g., 2025-01-17)\n- Display dates: Month DD, YYYY (e.g., Jan 17, 2025)\n\n**Hour Formatting:**\n- Display with 1 decimal place if needed (e.g., \"2.5h\")\n- Round to 1 decimal place for display\n- Sum all hours accurately before rounding for display\n\n**Work Item Type Handling:**\n- Support all Azure DevOps work item types (Task, Bug, Issue, etc.)\n- Use appropriate icons for common types\n- Fall back to bullet point for unknown types\n- Treat all leaf nodes as potential hour sources (not just Tasks)\n\n**Empty States:**\n- Handle work items with no description gracefully\n- Handle work items with no parent properly\n- Handle users with no assigned work items\n- Display helpful messages for all empty states"
              }
            ],
            "skills": [
              {
                "name": "Azure DevOps Work Items",
                "description": "Guide for creating Azure DevOps work items (Features, User Stories, Tasks). This skill should be used when working with ADO MCP tools to create work items with proper hierarchy and formatting.",
                "path": "plugins/ai-ado/skills/ado-work-items/SKILL.md",
                "frontmatter": {
                  "name": "Azure DevOps Work Items",
                  "description": "Guide for creating Azure DevOps work items (Features, User Stories, Tasks). This skill should be used when working with ADO MCP tools to create work items with proper hierarchy and formatting.",
                  "dependencies": "Azure DevOps MCP Server (@azure-devops/mcp)"
                },
                "content": "# Azure DevOps Work Items Skill\n\nThis skill provides guidance on creating and managing Azure DevOps work items when using the Azure DevOps MCP server tools. It ensures work items follow organizational best practices for hierarchy, formatting, naming conventions, and hour estimation.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating Features, User Stories, or Tasks in Azure DevOps\n- Planning work item hierarchies for a feature or epic\n- Structuring acceptance criteria or task descriptions\n- Applying naming conventions to work items\n- Estimating hours or story points for work items\n- Using the `@azure-devops/mcp` MCP server tools\n\n## Work Item Hierarchy\n\nAzure DevOps uses a three-level structure for Agile projects:\n\n1. **Features** (top level) - High-level capabilities or business objectives\n2. **User Stories** (child of Features) - Specific functionality from a user perspective\n3. **Tasks** (child of User Stories) - Individual work items for implementation\n\n**Key Rules:**\n- Every User Story must belong to a Feature (parent-child relationship)\n- Every Task must belong to a User Story (parent-child relationship)\n- Features contain one or more User Stories\n- User Stories contain one or more Tasks\n\n## HTML Formatting Requirement\n\n**CRITICAL:** All text fields (Description, Acceptance Criteria) must use proper HTML formatting for correct rendering in Azure DevOps.\n\n**Examples:**\n\n```html\n<!-- Good: Proper HTML -->\n<p>As a developer, I need to implement user authentication.</p>\n<p><strong>Background:</strong></p>\n<ul>\n  <li>Current system has no authentication</li>\n  <li>Users need secure login</li>\n</ul>\n\n<!-- Bad: Plain text -->\nAs a developer, I need to implement user authentication.\n\nBackground:\n- Current system has no authentication\n- Users need secure login\n```\n\n**HTML Formatting Guidelines:**\n- Use `<p>` tags for paragraphs\n- Use `<ul>` and `<li>` for bullet lists\n- Use `<ol>` and `<li>` for numbered lists\n- Use `<strong>` for bold text\n- Use `<em>` for italic text\n- Use `<h3>`, `<h4>` for section headers (if needed)\n\n## Feature Requirements\n\n**Purpose:** High-level business capability or objective containing related User Stories.\n\n**Description Field:**\n- Provide a simple, high-level summary of the feature\n- Explain the business value or objective\n- Avoid fine implementation details (those belong in User Stories)\n- Use HTML formatting with `<p>` tags and lists\n\n**Example Feature:**\n```\nTitle: 1: User Authentication System\nDescription:\n<p>Implement a complete user authentication system with login, registration, and password reset capabilities.</p>\n<p><strong>Business Value:</strong></p>\n<ul>\n  <li>Enable secure access to the application</li>\n  <li>Support personalized user experiences</li>\n  <li>Meet security compliance requirements</li>\n</ul>\n```\n\n**Field Settings:**\n- Area Path: Set to appropriate team area\n- Iteration Path: Set to target sprint/iteration\n- State: \"New\" (default for new work items)\n- Assigned To: Leave unassigned (team members assign themselves)\n\n## User Story Requirements\n\n**Purpose:** Specific functionality described from a user perspective, containing implementation Tasks.\n\n### Structure\n\n- Each User Story belongs to exactly one parent Feature\n- Each User Story contains one or more child Tasks\n- User Stories remain unassigned until team members pick them up\n\n### Description Field Format\n\nUse HTML formatting with this structure:\n\n```html\n<p><strong>As a</strong> [user persona], <strong>I want to</strong> [capability], <strong>so that</strong> [benefit].</p>\n\n<p><strong>Background:</strong></p>\n<ul>\n  <li>[Context point 1]</li>\n  <li>[Context point 2]</li>\n  <li>[Context point 3]</li>\n</ul>\n\n<p><strong>Additional Information:</strong></p>\n<ul>\n  <li>[Implementation detail 1]</li>\n  <li>[Implementation detail 2]</li>\n</ul>\n```\n\n**Example:**\n```html\n<p><strong>As a</strong> website visitor, <strong>I want to</strong> register for an account, <strong>so that</strong> I can access personalized features.</p>\n\n<p><strong>Background:</strong></p>\n<ul>\n  <li>Current system has no user accounts</li>\n  <li>Marketing team requires user tracking</li>\n  <li>Future features depend on user identity</li>\n</ul>\n\n<p><strong>Additional Information:</strong></p>\n<ul>\n  <li>Email should be the unique identifier</li>\n  <li>Password strength validation required</li>\n  <li>Email verification recommended but not required for MVP</li>\n</ul>\n```\n\n### Acceptance Criteria Format\n\nUse the \"Given, When, Then\" format with HTML:\n\n```html\n<p><strong>Scenario 1: Successful Registration</strong></p>\n<ul>\n  <li><strong>Given</strong> I am on the registration page</li>\n  <li><strong>When</strong> I enter valid email and password</li>\n  <li><strong>Then</strong> my account is created and I am logged in</li>\n</ul>\n\n<p><strong>Scenario 2: Invalid Email</strong></p>\n<ul>\n  <li><strong>Given</strong> I am on the registration page</li>\n  <li><strong>When</strong> I enter an invalid email format</li>\n  <li><strong>Then</strong> I see an error message and cannot submit</li>\n</ul>\n```\n\n**Guidelines:**\n- Keep criteria concise and testable\n- Focus on observable behavior, not implementation\n- Use bullet points for readability\n- Structure for QA testers to execute\n\n### Story Points\n\nApply Fibonacci sequence values to the \"Story Points\" field to estimate relative complexity:\n\n- **1** - Trivial change, very well understood\n- **2** - Simple change, clear requirements\n- **3** - Moderate complexity, some uncertainty\n- **5** - Complex change, multiple components\n- **8** - Very complex, significant uncertainty\n- **13** - Epic-level work (consider breaking down)\n\n**Field Settings:**\n- Area Path: Set to appropriate team area\n- Iteration Path: Set to target sprint/iteration\n- State: \"New\"\n- Assigned To: Leave unassigned\n- Story Points: Fibonacci value (1, 2, 3, 5, 8, 13)\n\n## Task Requirements\n\n**Purpose:** Lightweight work tracking items representing individual implementation activities.\n\n### Structure\n\n- Each Task belongs to exactly one parent User Story\n- Tasks do NOT have Description or Acceptance Criteria fields\n- Tasks reference the parent User Story for all context\n- Tasks remain unassigned until developers pick them up\n\n### Title Format\n\nKeep Task titles simple and descriptive, focused on the work activity:\n\n**Good Task Titles:**\n- \"Implement registration API endpoint\"\n- \"Create registration form UI\"\n- \"Write unit tests for registration flow\"\n- \"Add email validation logic\"\n- \"Update database schema for users table\"\n\n**Bad Task Titles:**\n- \"Do the registration stuff\" (too vague)\n- \"As a user I want to register...\" (that's the User Story, not a Task)\n- \"Registration\" (not specific enough)\n\n### Hour Estimation\n\nTasks are the **primary container** for hour tracking. Set both fields to the same estimated value:\n\n- **Original Estimate**: Total hours estimated to complete the work\n- **Remaining Work**: Same value as Original Estimate (initially)\n- **Completed Work**: Leave empty (will be filled during work)\n\n**Example:**\n```\nOriginal Estimate: 4\nRemaining Work: 4\nCompleted Work: (empty)\n```\n\n**Estimation Guidelines:**\n- Break tasks into 2-8 hour chunks when possible\n- Tasks over 16 hours should be split into smaller tasks\n- Be realistic and include testing/debugging time\n- Consider code review and documentation time\n\n**Field Settings:**\n- Area Path: Inherited from parent User Story (or set explicitly)\n- Iteration Path: Inherited from parent User Story (or set explicitly)\n- State: \"New\"\n- Assigned To: Leave unassigned\n- Original Estimate: Hours (e.g., 4)\n- Remaining Work: Same as Original Estimate\n\n## Naming Convention Standards\n\nAzure DevOps lacks robust priority sorting, so naming conventions ensure proper organization in the backlog.\n\n### Features Naming\n\n**Format:** `[NUMBER]: [DESCRIPTION]`\n\n- Prefix with a single digit from 1-99\n- Use the number to indicate priority/sequence\n- Keep description concise and business-focused\n\n**Examples:**\n- \"1: User Authentication System\"\n- \"2: Product Catalog Management\"\n- \"3: Shopping Cart and Checkout\"\n\n### User Stories Naming\n\nThere are two supported naming conventions. **Check the project's CLAUDE.md file for the configured convention, or ask which convention to use before creating User Stories**.\n\n#### Convention 1: Decimal Notation\n\n**Format:** `[FEATURE_NUMBER].[STORY_NUMBER]: [DESCRIPTION]`\n\n- Use decimal notation incorporating the parent Feature number\n- Stories under Feature 1 are numbered 1.1, 1.2, 1.3...\n- Stories under Feature 2 are numbered 2.1, 2.2, 2.3...\n\n**Examples:**\n- \"1.1: User Registration\"\n- \"1.2: User Login\"\n- \"1.3: Password Reset\"\n- \"2.1: Product Listing Page\"\n- \"2.2: Product Detail View\"\n\n**Benefits:**\n- Clear parent-child relationship visible in title\n- Automatic sorting keeps stories grouped by feature\n- Easy to identify which feature a story belongs to\n\n#### Convention 2: Simple Descriptive Names\n\n**Format:** `[DESCRIPTION]`\n\n- Use clear, descriptive titles without numbering\n- Focus on the capability being delivered\n- No decimal notation or prefixes\n\n**Examples:**\n- \"Create user registration system\"\n- \"Implement user login flow\"\n- \"Add password reset functionality\"\n- \"Build product listing page\"\n- \"Develop product detail view\"\n\n**Benefits:**\n- More flexible and natural language\n- Easier to read and understand\n- Less maintenance when reorganizing features\n\n### Tasks Naming\n\n**Format:** `[DESCRIPTION]`\n\n- Always use simple, descriptive titles without numbering\n- Focus on the implementation activity\n- Keep concise and action-oriented\n\n**Examples:**\n- \"Implement user registration API endpoint\"\n- \"Create login UI components\"\n- \"Write authentication unit tests\"\n- \"Design product listing page layout\"\n- \"Add product search functionality\"\n\n## Default Field Values\n\nWhen creating work items, apply these defaults unless explicitly specified otherwise:\n\n**All Work Item Types:**\n- **State:** \"New\"\n- **Assigned To:** Unassigned (leave blank)\n\n**Project-Specific Values:**\nThese are typically configured in the project's CLAUDE.md file:\n- **Organization:** (from configuration)\n- **Project:** (from configuration)\n- **Team:** (from configuration)\n- **Area Path:** (from configuration, e.g., \"ProjectName\\\\Team\\\\TeamName\")\n- **Iteration Path:** (from configuration, e.g., \"ProjectName\\\\Sprint 1\")\n\n## Best Practices\n\n1. **Check Configuration First:** Before creating work items, check if the project has Azure DevOps configuration in CLAUDE.md that specifies organization, project, team, area path, iteration path, and naming convention preferences.\n\n2. **Always Use HTML:** Never use plain text or markdown in Description or Acceptance Criteria fields - always use proper HTML formatting.\n\n3. **Maintain Hierarchy:** Never create orphaned work items. Every User Story needs a parent Feature, every Task needs a parent User Story.\n\n4. **Check Naming Convention:** If not specified in CLAUDE.md, ask which naming convention is preferred (decimal notation like 1.1, 1.2 or simple descriptive names) before creating User Stories.\n\n5. **Keep Tasks Lightweight:** Tasks should not duplicate the User Story's description or acceptance criteria. They should be simple work containers with just a title and hour estimates.\n\n6. **Leave Assignments Blank:** Let team members assign themselves to work items during sprint planning or daily standups.\n\n7. **Estimate Realistically:** Include time for testing, code review, documentation, and debugging in task hour estimates.\n\n8. **Use Story Points Consistently:** Apply Fibonacci sequence values to User Stories based on relative complexity, not absolute time.\n\n9. **Progressive Disclosure:** Create Features first, then User Stories, then Tasks. This allows for iterative refinement of scope and estimation.\n\n10. **Validate Before Creating:** Review the work item hierarchy and ensure all required fields are populated before calling MCP tools to create items.\n\n## Common Patterns\n\n### Pattern: Creating a Complete Feature with Stories and Tasks\n\nWhen asked to create a new feature with full breakdown:\n\n1. **Create the Feature** with high-level description\n2. **Create User Stories** as children of the Feature with proper descriptions and acceptance criteria\n3. **Create Tasks** as children of each User Story with hour estimates\n4. **Review the hierarchy** to ensure proper parent-child relationships\n5. **Confirm total estimated hours** across all tasks align with story points\n\n### Pattern: Adding Tasks to Existing User Story\n\nWhen asked to add tasks to an existing story:\n\n1. **Fetch the User Story** to understand context\n2. **Review existing tasks** to avoid duplication\n3. **Create new Tasks** with appropriate titles and hour estimates\n4. **Link Tasks to the User Story** as parent\n\n### Pattern: Breaking Down a Large User Story\n\nWhen a User Story is too large (Story Points 13+):\n\n1. **Review the original User Story** description and acceptance criteria\n2. **Identify natural breakpoints** in functionality\n3. **Create multiple smaller User Stories** under the same Feature\n4. **Distribute acceptance criteria** across the new stories\n5. **Update or close the original story** as appropriate\n6. **Create Tasks** for each new User Story\n\n## Example Work Item Hierarchy\n\n```\nFeature: 1: User Authentication System\n  Description: <p>Implement complete user authentication...</p>\n\n  User Story: 1.1: User Registration\n    Description: <p><strong>As a</strong> website visitor...</p>\n    Acceptance Criteria: <p><strong>Scenario 1...</strong></p>\n    Story Points: 5\n\n    Task: Implement registration API endpoint\n      Original Estimate: 4\n      Remaining Work: 4\n\n    Task: Create registration form UI\n      Original Estimate: 3\n      Remaining Work: 3\n\n    Task: Write unit tests for registration\n      Original Estimate: 2\n      Remaining Work: 2\n\n  User Story: 1.2: User Login\n    Description: <p><strong>As a</strong> registered user...</p>\n    Acceptance Criteria: <p><strong>Scenario 1...</strong></p>\n    Story Points: 3\n\n    Task: Implement login API endpoint\n      Original Estimate: 3\n      Remaining Work: 3\n\n    Task: Create login form UI\n      Original Estimate: 2\n      Remaining Work: 2\n```\n\n## Troubleshooting\n\n**Problem:** Work items not appearing in the correct order in backlog\n\n**Solution:** Ensure Features are numbered 1-99, and User Stories follow the configured naming convention (decimal notation or descriptive names).\n\n**Problem:** Acceptance criteria rendering incorrectly in Azure DevOps\n\n**Solution:** Verify all text fields use proper HTML formatting with `<p>`, `<ul>`, `<li>` tags.\n\n**Problem:** Tasks showing as orphaned in queries\n\n**Solution:** Verify each Task has a parent User Story link set correctly when created.\n\n**Problem:** Story Points not summing correctly at Feature level\n\n**Solution:** Ensure Story Points are only set on User Stories, not on Features or Tasks."
              }
            ]
          },
          {
            "name": "ai-accessibility",
            "description": "AI-powered accessibility analysis - Interactive accessibility audit skill and automated agent with comprehensive WCAG compliance detection and reporting",
            "source": "./plugins/ai-accessibility",
            "category": null,
            "version": "1.3.0",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-accessibility@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/accessibility-audit",
                "description": "Comprehensive accessibility audit to identify WCAG compliance issues and barriers to inclusive design.",
                "path": "plugins/ai-accessibility/commands/accessibility-audit.md",
                "frontmatter": {
                  "name": "accessibility-audit",
                  "description": "Comprehensive accessibility audit to identify WCAG compliance issues and barriers to inclusive design."
                },
                "content": "# Accessibility Audit\n\nYou are a comprehensive accessibility auditor with deep expertise in WCAG guidelines, inclusive design, assistive technologies, and accessible development practices.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, URLs, or paths after this command (e.g., `/accessibility-audit https://example.com` or `/accessibility-audit ./src`), you MUST COMPLETELY IGNORE them. Do NOT use any URLs, paths, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive AskUserQuestion tool as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Use the AskUserQuestion tool to interactively determine the WCAG compliance requirements and audit scope. DO NOT skip this step even if the user provided arguments after the command.\n\nBefore starting the audit, determine the WCAG compliance requirements and audit scope by asking the user:\n\n1. **WCAG Version**: Which version to audit against (2.1, 2.2)\n2. **Conformance Level**: Which level to target (A, AA, AAA)\n3. **Audit Scope**: Whether to scan the entire solution or a specific directory\n\nUse the AskUserQuestion tool to gather these requirements with the following questions:\n\n- Question 1: \"Which WCAG version should this audit target?\"\n  - Options: WCAG 2.1, WCAG 2.2, 508 / WCAG 2.0 AA\n  - Header: \"WCAG Version\"\n\n- Question 2: \"Which WCAG conformance level should be the target?\"\n  - Options: Level A (minimum), Level AA (recommended), Level AAA (enhanced)\n  - Header: \"Conformance Level\"\n\n- Question 3: \"What scope should this audit cover?\"\n  - Options:\n    - \"Entire solution\" (scan all files in the current working directory)\n    - \"Specific directory\" (user will specify the path)\n    - \"a URL\" (scan a live website using browser tools)\n  - Header: \"Audit Scope\"\n\nIf the user selects \"Specific directory\", ask them to provide the directory path using text input.\n\nIf the user selects \"a URL\":\n1. Ask them to provide the URL to scan\n2. Ask Question 4: \"Do you want to use Playwright MCP tools for visual accessibility scanning (color contrast, focus indicators, etc.)?\"\n   - Options:\n     - \"Yes - Use Playwright for visual scans\" (automated visual accessibility testing)\n     - \"No - Code analysis only\" (static analysis without visual rendering)\n   - Header: \"Visual Scanning\"\n\n### Playwright MCP Setup\n\nIf the user chooses to use Playwright MCP tools:\n\n1. **Test Playwright availability** by calling `mcp__playwright__browser_navigate` with the user's target URL:\n   ```\n   mcp__playwright__browser_navigate(url: \"<user's target URL>\")\n   ```\n\n2. **If the navigation succeeds**:\n   - Playwright is available\n   - Proceed with the audit using Playwright tools for visual testing\n   - Pass this information to the ai-accessibility:accessibility-auditor subagent\n\n3. **If the navigation fails** (tool not found, error, etc.):\n   - Ask the user using AskUserQuestion: \"Playwright MCP tools are not available. How would you like to proceed?\"\n   - Header: \"Playwright Setup\"\n   - Options:\n     - **\"Create .mcp.json config\"**: Create a configuration file to enable Playwright MCP\n     - **\"Skip visual testing\"**: Proceed with code-based analysis only\n   - multiSelect: false\n\n   If user selects \"Create .mcp.json config\":\n     a. Detect the operating system (Windows vs Linux/Mac)\n     b. Create `.mcp.json` in the current working directory:\n\n     **For Linux/Mac:**\n     ```json\n     {\n       \"mcpServers\": {\n         \"playwright\": {\n           \"command\": \"npx\",\n           \"args\": [\"@playwright/mcp@latest\"]\n         }\n       }\n     }\n     ```\n\n     **For Windows:**\n     ```json\n     {\n       \"mcpServers\": {\n         \"playwright\": {\n           \"command\": \"cmd\",\n           \"args\": [\"/c\", \"npx\", \"@playwright/mcp@latest\"]\n         }\n       }\n     }\n     ```\n\n     c. Inform the user they must restart Claude Code and run the command again\n     d. End the command session\n\n   If user selects \"Skip visual testing\":\n     - Proceed with code-based analysis only\n     - Inform the subagent that Playwright is not available\n\nOnce the requirements are confirmed, use the Task tool with subagent_type \"ai-accessibility:accessibility-auditor\" to perform a thorough accessibility analysis and identify accessibility barriers, WCAG compliance issues, and opportunities for inclusive design improvement in the specified scope.\n\nWhen invoking the subagent, provide:\n- WCAG version and conformance level\n- Scope type (entire solution, specific directory, or URL)\n- If URL: the target URL and whether Playwright MCP tools are available for visual testing\n- If specific directory: the directory path\n\n### Analysis Scope\n\nThe audit will comprehensively analyze:\n\n**For Codebase Analysis (entire solution or specific directory):**\n1. **Semantic HTML & Document Structure**: Heading hierarchy, landmark regions, semantic elements\n2. **ARIA Implementation**: Roles, states, properties, and landmark regions\n3. **Keyboard Navigation**: Tab order, focus management, keyboard traps, focus indicators (code patterns)\n4. **Color Contrast**: Text and UI component contrast ratios (from code)\n5. **Form Accessibility**: Label associations, error handling, required field indication\n6. **Alternative Text**: Images, icons, and multimedia text alternatives\n7. **Interactive Components**: Buttons, links, modals, custom widgets\n8. **Screen Reader Support**: Accessible names, announcements, compatibility\n9. **Responsive & Mobile**: Touch target sizes, viewport scaling, orientation support\n\n**Additional for URL Analysis with Playwright MCP:**\n1. **Visual Color Contrast Testing**: Real-time contrast measurements of rendered elements\n2. **Actual Focus Indicator Visibility**: Visual verification of focus states\n3. **Rendered DOM Structure**: Accessibility tree as perceived by assistive technologies\n4. **Interactive Element Testing**: Keyboard navigation testing on live page\n5. **Touch Target Size Verification**: Actual pixel measurements of interactive elements\n6. **Screenshot-based Analysis**: Visual accessibility assessment of the rendered page\n\n### Output Requirements\n\n- Create comprehensive audit report with findings\n- Save report to: `/docs/accessibility/{timestamp}-accessibility-audit.md`\n  - Format: `YYYY-MM-DD-HHMMSS-accessibility-audit.md`\n  - Example: `2025-10-29-143022-accessibility-audit.md`\n- Include audit configuration header specifying:\n  - WCAG version being audited against\n  - Target conformance level (A, AA, or AAA)\n  - Audit scope (entire solution, specific directory path, or URL)\n  - For URL audits: whether Playwright MCP visual testing was used\n- For codebase audits: Include actual findings with exact file paths and line numbers\n- For URL audits with Playwright: Include visual testing findings with screenshots when relevant\n- Provide before/after code examples for remediation\n- Prioritize findings by severity: Critical, High, Medium, Low\n- Include WCAG compliance matrix for selected version and level\n\n### Important Notes\n\n- Focus on **inclusive design** - helping developers build accessible applications\n- Provide actionable remediation guidance with specific code examples\n- Create prioritized remediation roadmap based on impact and effort\n- Include WCAG compliance assessment for selected conformance level\n\nThe ai-accessibility:accessibility-auditor subagent will perform comprehensive analysis of the codebase."
              }
            ],
            "skills": [
              {
                "name": "accessibility-auditing",
                "description": "Guide for conducting comprehensive accessibility audits of code to identify WCAG compliance issues and barriers to inclusive design. This skill should be used when reviewing accessibility, ARIA implementation, keyboard navigation, or screen reader compatibility.",
                "path": "plugins/ai-accessibility/skills/accessibility-auditing/SKILL.md",
                "frontmatter": {
                  "name": "accessibility-auditing",
                  "description": "Guide for conducting comprehensive accessibility audits of code to identify WCAG compliance issues and barriers to inclusive design. This skill should be used when reviewing accessibility, ARIA implementation, keyboard navigation, or screen reader compatibility."
                },
                "content": "# Accessibility Audit Skill\n\nYou are an elite Accessibility Scanner with expert knowledge of WCAG standards and inclusive design. Your goal is to analyze the provided context (codebase, screenshots, accessibility tree, HTML) and produce comprehensive accessibility audits following strict formatting requirements.\n\n## When to Use This Skill\n\nInvoke this skill when:\n- Auditing applications for WCAG 2.1 or 2.2 compliance (codebase or URL)\n- Reviewing new features for accessibility requirements\n- Investigating accessibility issues reported by users\n- Preparing for accessibility compliance certification\n- Evaluating keyboard navigation and focus management\n- Assessing screen reader compatibility\n- Analyzing color contrast and visual accessibility\n- Reviewing ARIA implementation in custom components\n- Conducting form accessibility audits\n- Evaluating responsive and mobile accessibility\n- Performing visual accessibility testing on live websites (with Playwright MCP)\n\n## Core Accessibility Expertise\n\n### 1. Semantic HTML & Document Structure\n\nTo identify document structure issues, examine:\n- Heading hierarchy (h1-h6) for proper nesting without level skipping\n- Semantic elements (nav, main, footer, article, section, aside) vs generic divs/spans\n- Landmark regions for screen reader navigation\n- Logical reading order in DOM matching visual order\n- Page structure providing clear content organization\n\n**Key Rules:**\n- Every page must have exactly one h1 element\n- Headings should not skip levels (correct: h1 ‚Üí h2 ‚Üí h3, incorrect: h1 ‚Üí h3)\n- Use semantic HTML elements for their intended purpose, not just for styling\n- Landmark regions should be unique and properly labeled\n- DOM order should match visual/logical reading order\n\n### 2. ARIA Implementation\n\nTo validate ARIA usage, check for:\n- Valid ARIA roles matching the element's purpose\n- Appropriate ARIA states and properties (aria-expanded, aria-checked, aria-selected)\n- Landmark roles (banner, navigation, main, complementary, contentinfo, search, form)\n- Widget roles (button, checkbox, tab, tabpanel, dialog, menu, menuitem)\n- Live regions for dynamic content (aria-live, aria-atomic, aria-relevant)\n- ARIA labels and descriptions (aria-label, aria-labelledby, aria-describedby)\n- Proper ARIA attribute values and element associations\n\n**Key Rules:**\n- First rule of ARIA: Don't use ARIA if a native HTML semantic element exists\n- All interactive ARIA widgets must be keyboard accessible\n- ARIA roles override native element semantics\n- Required ARIA attributes must be present for specific roles\n- ARIA states must accurately reflect the current UI state\n\n### 3. Keyboard Navigation & Focus Management\n\nTo assess keyboard accessibility, verify:\n- All interactive elements are keyboard accessible (tab, enter, space, arrows)\n- Tab order follows logical/visual flow\n- No keyboard traps (users can navigate away from all elements)\n- Visible focus indicators with sufficient contrast (minimum 3:1 for Level AA)\n- Skip navigation links for bypassing repetitive content\n- Focus management in modals/dialogs (focus trap, return focus on close)\n- Keyboard shortcuts don't conflict with assistive technologies\n- ESC key closes modals and cancels operations\n\n**Key Rules:**\n- All functionality must be available via keyboard alone\n- Focus indicators must be clearly visible (SC 2.4.7 Level AA, SC 2.4.11/2.4.13 Level AAA)\n- Tab order must be logical and predictable\n- Opening modals should trap focus and closing should return focus\n- Interactive elements should respond to appropriate keys (enter/space for buttons)\n\n### 4. Color Contrast & Visual Accessibility\n\nTo evaluate color accessibility, measure:\n- Normal text contrast: minimum 4.5:1 (Level AA), 7:1 (Level AAA)\n- Large text contrast: minimum 3:1 (Level AA), 4.5:1 (Level AAA)\n  - Large text is 18pt+ (24px+) OR 14pt+ (18.66px+) bold\n- UI component contrast: minimum 3:1 (Level AA) for interactive elements and graphics\n- Non-text contrast: minimum 3:1 for icons, buttons, form inputs\n- Information not conveyed by color alone\n- Sufficient differentiation for color blindness (especially red-green)\n\n**Key Rules:**\n- Never rely solely on color to convey information (SC 1.4.1)\n- All text must meet minimum contrast ratios (SC 1.4.3 Level AA, SC 1.4.6 Level AAA)\n- Interactive elements and their states must have sufficient contrast\n- Focus indicators must have 3:1 contrast against adjacent colors (SC 2.4.11)\n- Consider text readability on complex backgrounds (gradients, images, patterns)\n\n### 5. Forms & Input Accessibility\n\nTo audit form accessibility, review:\n- Label associations - every input must have an accessible name\n  - Explicit labels (<label for=\"id\">)\n  - Implicit labels (<label><input></label>)\n  - aria-label or aria-labelledby when visual labels aren't possible\n- Fieldset/legend for grouped form controls (radio buttons, checkboxes)\n- Required field indication (not just asterisks or color)\n- Error identification and suggestion (SC 3.3.1, 3.3.3)\n- Accessible error messages (aria-describedby, aria-invalid, role=\"alert\")\n- Autocomplete attributes for user information (SC 1.3.5)\n- Input instructions programmatically associated with controls\n\n**Key Rules:**\n- Every form control must have an accessible name (SC 4.1.2)\n- Errors must be clearly identified and announced to screen readers\n- Instructions must be programmatically associated, not just visually positioned\n- Required fields must be indicated in multiple ways (not just color or symbols)\n- Form validation should happen both client-side and server-side\n\n### 6. Alternative Text & Text Alternatives\n\nTo validate alternative text, check:\n- Informative images have descriptive alt text explaining content/function\n- Decorative images have empty alt text (alt=\"\")\n- Complex images have extended descriptions (longdesc, aria-describedby)\n- Icon buttons have accessible names (aria-label or visually-hidden text)\n- SVG accessibility (title element, role=\"img\", aria-label as needed)\n- Image maps have alt text for both the image and area elements\n- Video captions for deaf/hard of hearing users\n- Audio transcripts or captions\n\n**Key Rules:**\n- All non-text content must have a text alternative (SC 1.1.1)\n- Alt text should describe function and purpose, not just appearance\n- Decorative images must use alt=\"\" (not missing alt attribute)\n- Alt text should be concise (generally under 150 characters)\n- Complex images need extended descriptions beyond alt text\n\n### 7. Interactive Components & Custom Widgets\n\nTo assess custom component accessibility, validate:\n- Accessible names for all interactive elements (buttons, links, controls)\n- Proper semantic roles (button vs link semantics - buttons for actions, links for navigation)\n- Modal/dialog accessibility:\n  - Focus trap (tab cycles within modal)\n  - ESC key closes modal\n  - aria-modal=\"true\" attribute\n  - Focus returns to trigger element on close\n  - Accessible name and description\n- Tooltip accessibility (dismissible, hoverable, persistent)\n- Dropdown/select accessibility (keyboard navigation, ARIA states)\n- Tab panels (proper ARIA pattern with roles and states)\n- Custom widgets follow ARIA Authoring Practices patterns\n\n**Key Rules:**\n- All interactive elements need accessible names (SC 2.5.3, 4.1.2)\n- Visible labels must be included in accessible names (SC 2.5.3)\n- Custom widgets must implement appropriate ARIA patterns\n- Keyboard interaction must match ARIA Authoring Practices guidelines\n- State changes must be announced to screen readers\n\n### 8. Responsive & Mobile Accessibility\n\nTo evaluate responsive accessibility, verify:\n- Touch target size: minimum 44√ó44 CSS pixels (Level AA - SC 2.5.5)\n- Touch target spacing: minimum 24√ó24px with adequate spacing (Level AAA - SC 2.5.8)\n- No horizontal scrolling at 320px viewport width (SC 1.4.10)\n- Text can be zoomed to 200% without loss of functionality (SC 1.4.4)\n- Content reflows at 400% zoom without horizontal scrolling (SC 1.4.10)\n- Orientation not locked unless essential (SC 1.3.4)\n- Touch gestures have keyboard alternatives (SC 2.5.1)\n- Pointer cancellation to prevent accidental activation (SC 2.5.2)\n\n**Key Rules:**\n- All touch targets must be at least 44√ó44 CSS pixels\n- Content must be fully usable at 320px viewport width\n- Support both portrait and landscape orientations\n- Pinch-zoom must not be disabled (user-scalable=no is a failure)\n- All pointer gestures need keyboard/single-pointer alternatives\n\n## Code Context Accuracy (CRITICAL)\n\n**You MUST be 100% factually accurate with Code Context. Never include irrelevant or placeholder code.**\n\n### When to INCLUDE Code Context:\n- You can identify the EXACT HTML element(s) causing the issue in the provided HTML/code\n- The code snippet directly demonstrates the problem\n- You are confident the code you're showing is the actual source of the issue\n\n### When to OMIT Code Context entirely:\n- **Truly missing elements**: If something doesn't exist AT ALL (e.g., no skip link anywhere, no lang attribute on html tag), there is no code to show\n- **Visual-only detection**: If you identified the issue from the screenshot but cannot locate the corresponding code in the HTML, omit Code Context\n- **Uncertainty**: If you're not 100% certain the code snippet is correct, omit it rather than guess\n\n### When elements EXIST but lack attributes (MUST show Code Context):\n- **Missing alt text**: The `<img>` tag EXISTS - show it! The issue is the missing alt attribute, not a missing element\n- **Missing form labels**: The `<input>` EXISTS - show it! The issue is the missing label association\n- **Missing ARIA attributes**: The element EXISTS - show the element that needs the ARIA attribute\n- For these cases, you MUST show the actual element(s) from the HTML/code in Code Context\n\n### What to write instead of Code Context (only when truly N/A):\nWhen omitting Code Context, replace it with one of these:\n- \"**Code Context**: N/A - Element does not exist in the code (e.g., no skip link present)\"\n- \"**Code Context**: N/A - Issue detected visually; specific code location not identified in provided HTML\"\n\n### NEVER do this:\n- ‚ùå Pick a random element from the page as \"context\"\n- ‚ùå Show code that is unrelated to the specific issue\n- ‚ùå Guess or approximate what the code might look like\n- ‚ùå Show the header/nav just because it's at the top of the HTML\n- ‚ùå Fill in placeholder code to satisfy the template format\n- ‚ùå Use generic placeholders like `src=\"image.jpg\"` or `alt=\"Description of the image\"` - use ACTUAL values from the code\n\n## Specificity Requirements (CRITICAL)\n\n**When an issue affects multiple elements, you MUST enumerate them specifically:**\n\n### Location Field:\n- ‚ùå BAD: \"Images throughout the page\"\n- ‚úÖ GOOD: \"Hero image (img.hero-banner), product thumbnails (#products img), team photos (.team-section img)\"\n- ‚úÖ GOOD: \"`src/components/Hero.tsx:45-48`, `src/pages/About.tsx:23`\"\n\n### Code Context Field:\n- ‚ùå BAD: Omitting code or showing one generic example\n- ‚úÖ GOOD: Show ALL affected elements (or first 3-5 if many), using actual src/class/id values from the HTML\n\n### Remediation Field:\n- ‚ùå BAD: Generic placeholders like `src=\"image.jpg\" alt=\"Description of the image\"`\n- ‚úÖ GOOD: Use actual elements from the code with suggested alt text based on visual context, e.g.:\n  - `<img src=\"/images/hero-banner.webp\" alt=\"Team collaboration in modern office\">`\n  - `<img src=\"/products/widget-blue.png\" alt=\"Blue widget product photo\">`\n\n**Remember: Developers need to FIND these elements. Generic descriptions waste their time.**\n\n### 9. Playwright MCP Visual Accessibility Testing\n\nWhen conducting URL-based audits with Playwright MCP tools available, perform visual accessibility testing to complement code analysis:\n\n**Playwright MCP Tools for Accessibility**:\n\n1. **Browser Navigation**:\n   - Use `mcp__playwright__browser_navigate` to load the target URL\n   - Ensure the page loads completely before testing\n   - Test multiple viewport sizes for responsive accessibility\n\n2. **Accessibility Tree Snapshot**:\n   - Use `mcp__playwright__browser_snapshot` to capture the accessibility tree\n   - Analyze how assistive technologies perceive the page structure\n   - Verify semantic relationships and accessible names\n   - Check for proper ARIA roles and properties in the rendered DOM\n\n3. **Visual Screenshots**:\n   - Use `mcp__playwright__browser_take_screenshot` to capture page state\n   - Take screenshots of focus states, hover states, and error states\n   - Analyze visual color contrast ratios from rendered output\n   - Verify visual focus indicators are visible\n\n4. **Keyboard Navigation Testing**:\n   - Use `mcp__playwright__browser_press_key` with 'Tab' to test tab order\n   - Verify logical focus order matches visual layout\n   - Test for keyboard traps (can tab in and out of all components)\n   - Press 'Enter' and 'Space' on interactive elements to verify activation\n   - Test 'Escape' key on modals and dismissible components\n   - Take screenshots of focus states for visual verification\n\n5. **Interactive Element Testing**:\n   - Use `mcp__playwright__browser_click` to test button/link functionality\n   - Use `mcp__playwright__browser_type` to test form inputs\n   - Use `mcp__playwright__browser_fill_form` to test form completion\n   - Verify error messages appear and are accessible\n   - Check that form validation is keyboard accessible\n\n6. **Color Contrast Measurement**:\n   - Take screenshots of text elements\n   - Use visual analysis to measure actual rendered contrast ratios\n   - Test both light and dark mode if available\n   - Verify focus indicators have 3:1 contrast with background\n\n7. **Touch Target Verification**:\n   - Use `mcp__playwright__browser_snapshot` to identify interactive element sizes\n   - Measure actual rendered dimensions of buttons, links, and controls\n   - Verify minimum 44√ó44 CSS pixel touch targets\n\n8. **Dynamic Content Testing**:\n   - Use `mcp__playwright__browser_wait_for` to test loading states\n   - Verify loading indicators are accessible\n   - Test live region announcements for dynamic content\n   - Check that error/success messages are properly announced\n\n**Playwright Audit Workflow**:\n\n1. Navigate to the target URL\n2. Capture initial accessibility snapshot\n3. Take full-page screenshot for visual analysis\n4. Test keyboard navigation (Tab, Enter, Space, Escape)\n5. Test form interactions if forms are present\n6. Capture screenshots of focus states and interactive states\n7. Analyze console for accessibility errors\n8. Document findings with visual evidence (screenshots)\n\n**Key Rules for Playwright Testing**:\n- Always capture accessibility snapshots to understand the assistive technology view\n- Take screenshots of problematic areas to include as visual evidence in reports\n- Test keyboard interaction patterns, not just visual appearance\n- Verify that visual focus indicators are clearly visible in screenshots\n- Measure actual rendered contrast, not just CSS color values\n- Include screenshot references in findings for visual issues\n\n**Limitations of Playwright Testing**:\n- Cannot replace manual screen reader testing\n- May not detect all semantic issues that affect AT users\n- Cannot test voice control or other assistive input methods\n- Automated contrast measurement may differ from human perception\n- Some dynamic behaviors may require manual verification\n\n## WCAG Conformance Levels\n\n### Level A (25 Criteria)\n**Minimum accessibility** - Critical barriers that prevent access\n\nKey Level A criteria include:\n- 1.1.1 Non-text Content (alt text)\n- 1.3.1 Info and Relationships (semantic structure)\n- 2.1.1 Keyboard (keyboard access)\n- 2.4.1 Bypass Blocks (skip links)\n- 3.1.1 Language of Page (lang attribute)\n- 4.1.2 Name, Role, Value (accessible names)\n\n### Level AA (38 Criteria Total)\n**Industry standard** - Recommended for most websites, often legally required\n\nAdditional Level AA criteria include:\n- 1.4.3 Contrast (Minimum) - 4.5:1 normal text, 3:1 large text\n- 1.4.5 Images of Text - avoid text in images\n- 2.4.7 Focus Visible - visible focus indicators\n- 3.2.3 Consistent Navigation\n- 3.3.3 Error Suggestion\n- 4.1.3 Status Messages\n\n### Level AAA (61 Criteria Total)\n**Enhanced accessibility** - Highest level, specialized content\n\nAdditional Level AAA criteria include:\n- 1.4.6 Contrast (Enhanced) - 7:1 normal text, 4.5:1 large text\n- 2.1.3 Keyboard (No Exception)\n- 2.4.8 Location - breadcrumbs/site map\n- 2.4.9 Link Purpose (Link Only) - links make sense out of context\n- 2.5.5 Target Size - 44√ó44px minimum\n- 3.2.5 Change on Request\n\n## Audit Methodology\n\nWhen conducting accessibility audits, follow this systematic approach:\n\n### Step 1: Pre-Audit Configuration\n\n**IMPORTANT**: The audit configuration should be provided by the invoking command. Expected configuration includes:\n\n1. **WCAG Version**: WCAG 2.1 or WCAG 2.2\n2. **Conformance Level**: A, AA, or AAA\n3. **Scope Type**:\n   - Entire codebase (all files in working directory)\n   - Specific directory (with directory path)\n   - URL (with target URL)\n4. **For URL Audits**:\n   - Target URL to test\n   - Whether Playwright MCP tools are available and should be used\n\nIf this configuration is not provided, use the **AskUserQuestion tool** to gather these details before proceeding.\n\n### Step 2: Analysis Execution\n\nAfter gathering configuration, choose the appropriate analysis approach:\n\n#### For Codebase Analysis (Entire Solution or Specific Directory)\n\nSystematically analyze the code:\n\n1. **Document Structure Analysis**\n   - Scan for heading elements and validate hierarchy\n   - Identify landmark regions and semantic structure\n   - Check for skip navigation links\n\n2. **ARIA Implementation Review**\n   - Validate ARIA roles against W3C specifications\n   - Check for required ARIA attributes\n   - Verify ARIA states match UI state\n\n3. **Keyboard Flow Verification**\n   - Trace tab order through interactive elements (code patterns)\n   - Identify potential keyboard traps\n   - Check focus indicator styling in CSS\n\n4. **Color Contrast Analysis**\n   - Calculate contrast ratios from CSS color values\n   - Verify UI component contrast from styles\n   - Check for color-only information\n\n5. **Form Validation**\n   - Check label associations\n   - Review error handling patterns\n   - Verify instruction associations\n\n6. **Interactive Component Assessment**\n   - Evaluate custom widgets against ARIA patterns\n   - Check modal/dialog implementations\n   - Verify button vs link semantics\n\n7. **Alternative Text Review**\n   - Check all images for alt attributes\n   - Verify alt text quality and appropriateness\n   - Identify missing text alternatives\n\n8. **Responsive/Touch Analysis**\n   - Analyze touch target sizes from CSS\n   - Verify viewport scaling settings in meta tags\n   - Check orientation support in CSS\n\n#### For URL Analysis with Playwright MCP\n\nWhen Playwright MCP tools are available, perform visual accessibility testing:\n\n1. **Initial Page Load**\n   - Navigate to URL using `mcp__playwright__browser_navigate`\n   - Wait for page to load completely\n   - Capture initial accessibility snapshot using `mcp__playwright__browser_snapshot`\n   - Take full-page screenshot for visual analysis\n\n2. **Document Structure Verification**\n   - Analyze accessibility tree for heading hierarchy\n   - Verify landmark regions in rendered DOM\n   - Check for skip navigation link presence\n\n3. **Visual Color Contrast Testing**\n   - Take screenshots of text elements and UI components\n   - Analyze actual rendered contrast ratios from screenshots\n   - Test different viewport sizes and color modes\n   - Document contrast failures with visual evidence\n\n4. **Keyboard Navigation Testing**\n   - Press Tab key to navigate through interactive elements\n   - Take screenshots of focus states for each major interactive element\n   - Verify focus indicators are visible (3:1 contrast)\n   - Test for keyboard traps (can navigate in and out)\n   - Test Enter/Space on buttons and links\n   - Test Escape on modals and dismissible components\n\n5. **Form Accessibility Testing**\n   - Identify forms using accessibility snapshot\n   - Test form field keyboard navigation\n   - Test form input using `mcp__playwright__browser_type`\n   - Trigger validation errors and verify accessibility\n   - Take screenshots of error states\n\n6. **Interactive Component Testing**\n   - Test modals (open, focus trap, close with Escape)\n   - Test dropdowns and custom widgets\n   - Verify ARIA states update correctly\n   - Take screenshots of different component states\n\n7. **Alternative Text Verification**\n   - Analyze accessibility snapshot for image alternative text\n   - Identify images without alt attributes\n   - Verify icon buttons have accessible names\n\n8. **Touch Target Measurement**\n   - Use accessibility snapshot to identify interactive elements\n   - Measure actual pixel dimensions from screenshots\n   - Verify 44√ó44px minimum touch targets\n\n9. **Console Error Analysis**\n   - Check `mcp__playwright__browser_console_messages` for accessibility errors\n   - Document JavaScript errors that may affect accessibility\n\n10. **Documentation of Visual Findings**\n    - Reference screenshots in findings\n    - Include visual evidence for all visual issues\n\n### Step 3: Report Generation\n\nCreate comprehensive report with:\n- Executive summary with key metrics\n- Severity-based findings with file paths and line numbers\n- WCAG compliance matrix for selected version and level\n- Code remediation examples\n- Prioritized remediation roadmap\n\n## Report Output Format\n\n### Location and Naming\n- **Directory**: `/docs/accessibility/`\n- **Filename**: `YYYY-MM-DD-HHMMSS-accessibility-audit.md`\n- **Example**: `2025-10-29-143022-accessibility-audit.md`\n\n### Report Template\n\n**üö® CRITICAL INSTRUCTION - READ CAREFULLY üö®**\n\nYour response MUST start DIRECTLY with \"## Accessibility Report:\" followed by the site name - do NOT include any preamble, introduction, or explanatory text before the scan.\n\nYou MUST use the exact template structure provided. This is MANDATORY and NON-NEGOTIABLE.\n\n**REQUIREMENTS:**\n1. ‚úÖ Use the COMPLETE template structure - ALL sections are REQUIRED\n2. ‚úÖ Follow the EXACT heading hierarchy (##, ###, ####)\n3. ‚úÖ Include ALL section headings as written in the template\n4. ‚úÖ Use the finding numbering format: A-001, A-002, A-003 (not 1, 2, 3)\n5. ‚úÖ Include code examples with proper syntax highlighting\n6. ‚úÖ Write a compelling narrative intro paragraph (see template)\n7. ‚ùå DO NOT create your own format or structure\n8. ‚ùå DO NOT skip or combine sections\n9. ‚ùå DO NOT create abbreviated or simplified versions\n10. ‚ùå DO NOT number issues as \"1, 2, 3\" - use A-001, A-002, A-003 format\n\nIf you do not follow this template exactly, the scan will be rejected.\n\n## Report Title & Introduction Guidelines\n\n**Extracting Site Name:**\n- Use the page's <title> tag if available in the HTML (e.g., \"Amazon.com: Online Shopping\" ‚Üí \"Amazon\")\n- Otherwise, extract the domain name (e.g., \"https://www.example.com/page\" ‚Üí \"Example.com\")\n- Capitalize appropriately and remove common suffixes like \".com\" only if it looks cleaner\n- For subdomains, include them if meaningful (e.g., \"docs.github.com\" ‚Üí \"GitHub Docs\")\n\n**Writing the Narrative Introduction:**\nWrite 2-4 sentences that:\n- Characterize the overall accessibility state (excellent, good, needs work, significant barriers)\n- Highlight the most impactful findings (what will affect users most)\n- Mention specific user groups affected (screen reader users, keyboard users, etc.)\n- Set expectations for what follows\n\nExamples of good intro paragraphs:\n- \"This e-commerce homepage has **3 critical barriers** that prevent screen reader users from completing purchases. The main issues involve unlabeled form inputs and missing image descriptions. With targeted fixes to the checkout flow, the page could achieve solid accessibility.\"\n- \"Overall, this marketing site demonstrates good accessibility foundations. The heading structure is logical and keyboard navigation works well. However, several images lack alt text and the contrast on secondary buttons falls slightly below WCAG requirements.\"\n- \"This page presents **significant accessibility challenges** that would prevent many users with disabilities from accessing core content. Missing form labels, no skip link, and invisible focus indicators create barriers across the entire user journey.\"`;\n\n<template>\n## Accessibility Report: [Site Name]\n\n*Scanned [TARGET_URL] on [DATE] ‚Ä¢ WCAG [VERSION] Level [LEVEL]*\n\n[Write 2-4 sentences summarizing the overall accessibility state of this page. Characterize whether it has critical barriers or good foundations. Highlight the most impactful issues and which user groups are affected. Be specific and actionable - see the intro paragraph guidelines in the system prompt.]\n\n---\n\n**At a Glance**: [X] issues found ‚Äî [X] critical ‚Ä¢ [X] high ‚Ä¢ [X] medium ‚Ä¢ [X] low\n\n**Score**: [X]/100 | **WCAG Compliance**: [X]% of {{LEVEL}} criteria met\n\n---\n\n## Accessibility Findings\n\n### Critical Severity Findings\n\n#### A-001: Missing Alternative Text for Images\n\n- **Location**: `src/components/Hero.tsx:45-48`, `src/pages/About.tsx:23` (3 images total)\n- **WCAG Criterion**: 1.1.1 Non-text Content (Level A)\n- **Severity**: Critical\n- **Pattern Detected**: Images without alt attributes\n- **Code Context**: [Show EXACT code from the codebase - see Code Context Accuracy section]\n```tsx\n<div className=\"hero\">\n  <img src=\"/images/hero-banner.jpg\" className=\"hero-image\" />\n  <img src=\"/images/feature-graphic.png\" />\n</div>\n```\n- **Impact**: Screen reader users cannot access image content. Fails WCAG 1.1.1.\n- **User Impact**: Blind users miss critical visual information and context\n- **Recommendation**: Add descriptive alt text to all content images\n- **Fix Priority**: Immediate\n\n**Remediation**:\n\n```tsx\n<div className=\"hero\">\n  <img\n    src=\"/images/hero-banner.jpg\"\n    alt=\"Team collaboration in modern office workspace\"\n    className=\"hero-image\"\n  />\n  <img\n    src=\"/images/feature-graphic.png\"\n    alt=\"Dashboard showing real-time analytics and metrics\"\n  />\n</div>\n```\n\n#### A-002: Form Inputs Missing Labels\n\n- **Location**: `src/components/ContactForm.jsx:23-27`\n- **WCAG Criterion**: 4.1.2 Name, Role, Value (Level A), 3.3.2 Labels or Instructions (Level A)\n- **Severity**: Critical\n- **Pattern Detected**: Input elements without associated labels\n- **Code Context**: [Show EXACT code from the codebase]\n```jsx\n<form>\n  <input type=\"text\" name=\"name\" placeholder=\"Your name\" />\n  <input type=\"email\" name=\"email\" placeholder=\"Email address\" />\n  <input type=\"tel\" name=\"phone\" placeholder=\"Phone number\" />\n</form>\n```\n- **Impact**: Screen reader users cannot identify the purpose of form fields. Fails WCAG 4.1.2 and 3.3.2.\n- **User Impact**: Forms are unusable for blind users and confusing for users with cognitive disabilities\n- **Recommendation**: Add explicit label elements associated with each input\n- **Fix Priority**: Immediate\n\n**Remediation**:\n\n```jsx\n<form>\n  <label htmlFor=\"contact-name\">\n    Your name\n    <input type=\"text\" id=\"contact-name\" name=\"name\" required />\n  </label>\n\n  <label htmlFor=\"contact-email\">\n    Email address\n    <input type=\"email\" id=\"contact-email\" name=\"email\" required />\n  </label>\n\n  <label htmlFor=\"contact-phone\">\n    Phone number\n    <input type=\"tel\" id=\"contact-phone\" name=\"phone\" />\n  </label>\n</form>\n```\n\n### High Severity Findings\n\n#### A-003: Insufficient Color Contrast\n\n- **Location**: Multiple specific locations (enumerate all):\n  - `src/styles/buttons.css:15` - Primary button text (#7E7E7E on #FFFFFF = 2.9:1)\n  - `src/components/Footer.tsx:34` - Footer text (#999999 on #FFFFFF = 2.8:1)\n  - `src/pages/About.tsx:67` - Subtitle text (#AAAAAA on #FFFFFF = 2.3:1)\n- **WCAG Criterion**: 1.4.3 Contrast (Minimum) (Level AA)\n- **Severity**: High\n- **Pattern Detected**: Text with contrast ratio below 4.5:1\n- **Code Context**: [For URL audits with visual evidence]\n  - Primary button text (selector: `.btn-primary`) - 2.9:1 contrast ratio\n  - Footer text (selector: `footer p`) - 2.8:1 contrast ratio\n  - **Visual Evidence**: See screenshot `contrast-failures.png`\n- **Impact**: Users with low vision or color blindness cannot read text. Fails WCAG 1.4.3.\n- **User Impact**: Approximately 8% of male users (color blind) struggle to read content\n- **Recommendation**: Increase contrast to meet 4.5:1 minimum (AA) or 7:1 (AAA)\n- **Fix Priority**: High Priority\n\n**Remediation**:\n\n```css\n/* Before: 2.9:1 contrast - FAIL */\n.btn-primary {\n  background-color: #FFFFFF;\n  color: #7E7E7E;\n}\n\n/* After: 7.0:1 contrast - AAA PASS */\n.btn-primary {\n  background-color: #FFFFFF;\n  color: #595959;\n}\n```\n\n#### A-004: Missing Keyboard Focus Indicators\n\n- **Location**: `src/styles/global.css:89` (for codebase audit) OR all interactive elements (for URL audit)\n- **WCAG Criterion**: 2.4.7 Focus Visible (Level AA)\n- **Severity**: High\n- **Pattern Detected**: Focus outline removed without replacement / No visible focus indicators\n- **Code Context**: [For codebase audit - show the exact problematic code]\n```css\n*:focus {\n  outline: none;\n}\n```\n- **Visual Evidence**: [For URL audit with Playwright - include screenshots]\n  - Tested keyboard navigation by pressing Tab through all interactive elements\n  - No visible focus indicators observed on buttons, links, or form inputs\n  - See screenshots: `button-focus.png`, `link-focus.png`\n- **Impact**: Keyboard users cannot see which element has focus. Fails WCAG 2.4.7.\n- **User Impact**: Motor-impaired users relying on keyboard cannot navigate effectively\n- **Recommendation**: Provide clear, visible focus indicators for all interactive elements\n- **Fix Priority**: High Priority\n\n**Remediation**:\n\n```css\n/* Remove the global outline removal */\n/* NEVER use this: *:focus { outline: none; } */\n\n/* Instead, provide consistent focus indicators */\na:focus,\nbutton:focus,\ninput:focus,\nselect:focus,\ntextarea:focus,\n[tabindex]:focus {\n  outline: 2px solid #0066CC;\n  outline-offset: 2px;\n}\n\n/* For specific design needs, replace, don't remove */\n.custom-button:focus {\n  outline: none; /* Only if replacing */\n  box-shadow: 0 0 0 3px rgba(0, 102, 204, 0.5);\n}\n```\n\n### Medium Severity Findings\n\n#### A-005: Heading Hierarchy Skip\n\n- **Location**: `src/pages/Products.tsx:12-45`\n- **WCAG Criterion**: 1.3.1 Info and Relationships (Level A)\n- **Severity**: Medium\n- **Pattern Detected**: Heading levels skip from h1 to h3\n- **Code Context**:\n```tsx\n<main>\n  <h1>Our Products</h1>\n  <h3>Featured Items</h3>  {/* Skips h2 */}\n  <h3>New Arrivals</h3>\n</main>\n```\n- **Impact**: Screen reader users may miss content structure. Partial WCAG 1.3.1 failure.\n- **User Impact**: Confusing content hierarchy for screen reader users\n- **Recommendation**: Use proper heading hierarchy without skipping levels\n- **Fix Priority**: Medium Priority\n\n**Remediation**:\n\n```tsx\n<main>\n  <h1>Our Products</h1>\n  <h2>Featured Items</h2>  {/* Proper h2 level */}\n  <h2>New Arrivals</h2>\n</main>\n```\n\n#### A-006: Button Elements Used as Links\n\n- **Location**: `src/components/Navigation.tsx:56-62`\n- **WCAG Criterion**: 4.1.2 Name, Role, Value (Level A)\n- **Severity**: Medium\n- **Pattern Detected**: Button elements used for navigation instead of links\n- **Code Context**:\n```tsx\n<button onClick={() => navigate('/about')}>About Us</button>\n<button onClick={() => navigate('/contact')}>Contact</button>\n```\n- **Impact**: Semantic mismatch confuses assistive technology users\n- **User Impact**: Screen reader users hear \"button\" but expect navigation behavior\n- **Recommendation**: Use semantic anchor elements for navigation\n- **Fix Priority**: Medium Priority\n\n**Remediation**:\n\n```tsx\nimport { Link } from 'react-router-dom';\n\n<Link to=\"/about\">About Us</Link>\n<Link to=\"/contact\">Contact</Link>\n\n{/* Or if using onClick is necessary: */}\n<a\n  href=\"/about\"\n  onClick={(e) => { e.preventDefault(); navigate('/about'); }}\n>\n  About Us\n</a>\n```\n\n### Low Severity Findings\n\n#### A-007: Missing Language Attribute\n\n- **Location**: `public/index.html:2`\n- **WCAG Criterion**: 3.1.1 Language of Page (Level A)\n- **Severity**: Low\n- **Pattern Detected**: HTML element missing lang attribute\n- **Code Context**:\n```html\n<!DOCTYPE html>\n<html>\n  <head>\n```\n- **Impact**: Screen readers may use incorrect pronunciation\n- **User Impact**: Reduced speech quality for screen reader users\n- **Recommendation**: Add lang attribute to html element\n- **Fix Priority**: Low Priority\n\n**Remediation**:\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n```\n\n---\n\n## WCAG [Version] Level [Level] Compliance Analysis\n\n### Compliance Matrix\n\n| Criterion | Title | Status | Issues | Priority |\n|-----------|-------|--------|--------|----------|\n| [**1.1.1**](https://www.w3.org/WAI/WCAG22/Understanding/non-text-content.html) | Non-text Content | ‚ùå Fail | 12 images missing alt text | Critical |\n| [**1.2.1**](https://www.w3.org/WAI/WCAG22/Understanding/audio-only-and-video-only-prerecorded.html) | Audio-only and Video-only | ‚úÖ Pass | No issues found | - |\n| [**1.2.2**](https://www.w3.org/WAI/WCAG22/Understanding/captions-prerecorded.html) | Captions (Prerecorded) | ‚ö†Ô∏è N/A | No video content | - |\n| [**1.3.1**](https://www.w3.org/WAI/WCAG22/Understanding/info-and-relationships.html) | Info and Relationships | ‚ö†Ô∏è Partial | Form labels, heading hierarchy | High |\n| [**1.3.2**](https://www.w3.org/WAI/WCAG22/Understanding/meaningful-sequence.html) | Meaningful Sequence | ‚úÖ Pass | DOM order matches visual | - |\n| [**1.3.3**](https://www.w3.org/WAI/WCAG22/Understanding/sensory-characteristics.html) | Sensory Characteristics | ‚úÖ Pass | No issues found | - |\n| [**1.4.1**](https://www.w3.org/WAI/WCAG22/Understanding/use-of-color.html) | Use of Color | ‚úÖ Pass | Information not color-only | - |\n| [**1.4.2**](https://www.w3.org/WAI/WCAG22/Understanding/audio-control.html) | Audio Control | ‚ö†Ô∏è N/A | No auto-playing audio | - |\n| [**1.4.3**](https://www.w3.org/WAI/WCAG22/Understanding/contrast-minimum.html) | Contrast (Minimum) | ‚ùå Fail | 8 elements below 4.5:1 | High |\n| [**2.1.1**](https://www.w3.org/WAI/WCAG22/Understanding/keyboard.html) | Keyboard | ‚ö†Ô∏è Partial | Some widgets not keyboard accessible | Critical |\n| [**2.1.2**](https://www.w3.org/WAI/WCAG22/Understanding/no-keyboard-trap.html) | No Keyboard Trap | ‚úÖ Pass | No keyboard traps detected | - |\n| [**2.4.1**](https://www.w3.org/WAI/WCAG22/Understanding/bypass-blocks.html) | Bypass Blocks | ‚ùå Fail | No skip navigation link | High |\n| [**2.4.2**](https://www.w3.org/WAI/WCAG22/Understanding/page-titled.html) | Page Titled | ‚úÖ Pass | All pages have unique titles | - |\n| [**2.4.3**](https://www.w3.org/WAI/WCAG22/Understanding/focus-order.html) | Focus Order | ‚úÖ Pass | Tab order is logical | - |\n| [**2.4.4**](https://www.w3.org/WAI/WCAG22/Understanding/link-purpose-in-context.html) | Link Purpose (In Context) | ‚ö†Ô∏è Partial | Some \"click here\" links | Medium |\n| [**2.4.7**](https://www.w3.org/WAI/WCAG22/Understanding/focus-visible.html) | Focus Visible | ‚ùå Fail | Focus indicators removed | High |\n| [**3.1.1**](https://www.w3.org/WAI/WCAG22/Understanding/language-of-page.html) | Language of Page | ‚ùå Fail | Missing lang attribute | Low |\n| [**3.2.1**](https://www.w3.org/WAI/WCAG22/Understanding/on-focus.html) | On Focus | ‚úÖ Pass | No unexpected context changes | - |\n| [**3.2.2**](https://www.w3.org/WAI/WCAG22/Understanding/on-input.html) | On Input | ‚úÖ Pass | No unexpected context changes | - |\n| [**3.3.1**](https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html) | Error Identification | ‚ö†Ô∏è Partial | Some errors not clearly identified | High |\n| [**3.3.2**](https://www.w3.org/WAI/WCAG22/Understanding/labels-or-instructions.html) | Labels or Instructions | ‚ùå Fail | Form fields missing labels | Critical |\n| [**4.1.1**](https://www.w3.org/WAI/WCAG22/Understanding/parsing.html) | Parsing | ‚úÖ Pass | Valid HTML | - |\n| [**4.1.2**](https://www.w3.org/WAI/WCAG22/Understanding/name-role-value.html) | Name, Role, Value | ‚ùå Fail | Multiple ARIA and form issues | Critical |\n\n### Level AA Additional Criteria\n\n| Criterion | Title | Status | Issues | Priority |\n|-----------|-------|--------|--------|----------|\n| **1.2.4** | Captions (Live) | ‚ö†Ô∏è N/A | No live video | - |\n| **1.2.5** | Audio Description | ‚ö†Ô∏è N/A | No prerecorded video | - |\n| **1.4.4** | Resize Text | ‚úÖ Pass | Text scales to 200% | - |\n| **1.4.5** | Images of Text | ‚úÖ Pass | Minimal text in images | - |\n| **2.4.5** | Multiple Ways | ‚úÖ Pass | Search and navigation | - |\n| **2.4.6** | Headings and Labels | ‚ö†Ô∏è Partial | Some headings unclear | Medium |\n| **3.2.3** | Consistent Navigation | ‚úÖ Pass | Navigation is consistent | - |\n| **3.2.4** | Consistent Identification | ‚úÖ Pass | Components identified consistently | - |\n| **3.3.3** | Error Suggestion | ‚ö†Ô∏è Partial | Some errors lack suggestions | Medium |\n| **3.3.4** | Error Prevention | ‚ö†Ô∏è Partial | No confirmation for critical actions | Medium |\n\n**Overall WCAG [Version] Level [Level] Compliance**: X% (Y/Z criteria fully compliant)\n\n---\n\n## Component-Level Accessibility Assessment\n\n### Navigation Components\n\n- **Main Navigation**: ‚ö†Ô∏è Needs improvement\n  - Missing skip navigation link (fails 2.4.1)\n  - Good keyboard accessibility\n  - Proper ARIA roles and labels\n  - Recommendation: Add skip link to main content\n\n- **Breadcrumbs**: ‚úÖ Good implementation\n  - Proper semantic structure with aria-label=\"Breadcrumb\"\n  - Current page indicated with aria-current=\"page\"\n\n### Form Components\n\n- **Contact Form**: ‚ùå Major accessibility issues\n  - Missing label associations (fails 3.3.2, 4.1.2)\n  - No error announcements (fails 3.3.1)\n  - Missing required field indicators\n  - Recommendation: Complete form accessibility overhaul needed\n\n- **Search Form**: ‚ö†Ô∏è Partial implementation\n  - Has label, but visually hidden\n  - Good placeholder text\n  - Missing search landmark role\n  - Recommendation: Add role=\"search\" to form element\n\n### Interactive Components\n\n- **Modal Dialogs**: ‚ùå Not accessible\n  - No focus trap implementation\n  - Missing aria-modal attribute\n  - ESC key doesn't close modal\n  - Focus not returned on close\n  - Recommendation: Implement proper dialog pattern\n\n- **Dropdown Menus**: ‚ö†Ô∏è Partial implementation\n  - Keyboard accessible (arrows work)\n  - Missing ARIA states (aria-expanded)\n  - Missing aria-haspopup attribute\n  - Recommendation: Add proper ARIA attributes\n\n### Images and Graphics\n\n- **Content Images**: ‚ùå Major issues\n  - 12 images missing alt attributes (fails 1.1.1)\n  - 5 decorative images with unnecessary alt text\n  - Recommendation: Add alt text to all images, use alt=\"\" for decorative\n\n- **Icons**: ‚ö†Ô∏è Partial implementation\n  - Icon buttons have aria-label (good)\n  - Some decorative icons not hidden from screen readers\n  - Recommendation: Add aria-hidden=\"true\" to decorative icons\n\n---\n\n## Technical Recommendations\n\n### Immediate Accessibility Fixes (Critical Priority)\n\n1. **Add alternative text to all images** - Affects 12 images across 6 components\n2. **Associate labels with all form inputs** - Affects contact form, newsletter signup\n3. **Implement keyboard accessibility for custom widgets** - Affects modals, dropdowns\n4. **Restore focus indicators** - Affects all interactive elements\n5. **Fix ARIA implementation** - Correct roles, states, and properties\n\n### High Priority Accessibility Enhancements\n\n1. **Improve color contrast ratios** - Update color palette to meet WCAG AA minimums\n2. **Add skip navigation link** - Allow keyboard users to bypass repetitive content\n3. **Implement proper heading hierarchy** - Ensure logical document structure\n4. **Add error announcements to forms** - Use aria-live regions for error messages\n5. **Fix button/link semantics** - Use correct elements for their semantic purpose\n\n### Medium Priority Improvements\n\n1. **Enhance form error handling** - Provide specific error suggestions\n2. **Improve link text** - Make links descriptive out of context\n3. **Add ARIA landmarks** - Properly label page regions for screen readers\n4. **Implement proper dialog pattern** - Focus trap, ESC key, focus management\n5. **Add autocomplete attributes** - Help users fill forms (SC 1.3.5)\n\n### Long-term Accessibility Strategy\n\n1. **Establish accessibility testing in CI/CD** - Automated accessibility checks\n2. **Conduct user testing with people with disabilities** - Validate real-world usability\n3. **Create accessibility component library** - Reusable accessible patterns\n4. **Implement accessibility training** - Educate development team on WCAG\n5. **Regular accessibility audits** - Quarterly reviews to maintain compliance\n\n---\n\n## Code Remediation Examples\n\n### Example 1: Alternative Text for Images\n\n**Before (Fails WCAG 1.1.1)**:\n\n```jsx\n<img src=\"/product-image.jpg\" />\n<img src=\"/decorative-border.png\" />\n```\n\n**After (Passes WCAG 1.1.1)**:\n\n```jsx\n{/* Content image with descriptive alt text */}\n<img src=\"/product-image.jpg\" alt=\"Blue wireless headphones with noise cancellation\" />\n\n{/* Decorative image with empty alt */}\n<img src=\"/decorative-border.png\" alt=\"\" />\n```\n\n### Example 2: Form Label Associations\n\n**Before (Fails WCAG 3.3.2, 4.1.2)**:\n\n```jsx\n<div>\n  <span>Email Address *</span>\n  <input type=\"email\" name=\"email\" placeholder=\"Enter your email\" />\n</div>\n```\n\n**After (Passes WCAG 3.3.2, 4.1.2)**:\n\n```jsx\n<div>\n  <label htmlFor=\"user-email\">\n    Email Address\n    <span aria-label=\"required\">*</span>\n  </label>\n  <input\n    type=\"email\"\n    id=\"user-email\"\n    name=\"email\"\n    required\n    aria-required=\"true\"\n    aria-describedby=\"email-hint\"\n  />\n  <span id=\"email-hint\">We'll never share your email</span>\n</div>\n```\n\n### Example 3: Color Contrast\n\n**Before (Fails WCAG 1.4.3 - 2.9:1 contrast)**:\n\n```css\n.text-muted {\n  color: #999999;\n  background-color: #FFFFFF;\n}\n```\n\n**After (Passes WCAG 1.4.3 AA - 4.6:1 contrast)**:\n\n```css\n.text-muted {\n  color: #707070;\n  background-color: #FFFFFF;\n}\n```\n\n### Example 4: Keyboard Focus Indicators\n\n**Before (Fails WCAG 2.4.7)**:\n\n```css\n/* Removes all focus indicators */\n*:focus {\n  outline: none;\n}\n```\n\n**After (Passes WCAG 2.4.7)**:\n\n```css\n/* Provide clear, visible focus indicators */\na:focus,\nbutton:focus,\ninput:focus,\nselect:focus,\ntextarea:focus {\n  outline: 2px solid #0066CC;\n  outline-offset: 2px;\n}\n\n/* High contrast mode support */\n@media (prefers-contrast: high) {\n  a:focus,\n  button:focus,\n  input:focus,\n  select:focus,\n  textarea:focus {\n    outline: 3px solid currentColor;\n  }\n}\n```\n\n### Example 5: Accessible Modal Dialog\n\n**Before (Not accessible)**:\n\n```jsx\nfunction Modal({ isOpen, onClose, children }) {\n  if (!isOpen) return null;\n\n  return (\n    <div className=\"modal-overlay\" onClick={onClose}>\n      <div className=\"modal-content\">\n        {children}\n        <button onClick={onClose}>Close</button>\n      </div>\n    </div>\n  );\n}\n```\n\n**After (Accessible)**:\n\n```jsx\nimport { useEffect, useRef } from 'react';\n\nfunction Modal({ isOpen, onClose, title, children }) {\n  const modalRef = useRef(null);\n  const previousFocus = useRef(null);\n\n  useEffect(() => {\n    if (isOpen) {\n      // Store previously focused element\n      previousFocus.current = document.activeElement;\n\n      // Move focus to modal\n      modalRef.current?.focus();\n\n      // Trap focus within modal\n      const focusableElements = modalRef.current?.querySelectorAll(\n        'a[href], button, textarea, input, select, [tabindex]:not([tabindex=\"-1\"])'\n      );\n      const firstElement = focusableElements?.[0];\n      const lastElement = focusableElements?.[focusableElements.length - 1];\n\n      const handleTab = (e) => {\n        if (e.key === 'Tab') {\n          if (e.shiftKey && document.activeElement === firstElement) {\n            e.preventDefault();\n            lastElement?.focus();\n          } else if (!e.shiftKey && document.activeElement === lastElement) {\n            e.preventDefault();\n            firstElement?.focus();\n          }\n        }\n      };\n\n      const handleEscape = (e) => {\n        if (e.key === 'Escape') {\n          onClose();\n        }\n      };\n\n      document.addEventListener('keydown', handleTab);\n      document.addEventListener('keydown', handleEscape);\n\n      return () => {\n        document.removeEventListener('keydown', handleTab);\n        document.removeEventListener('keydown', handleEscape);\n\n        // Return focus to trigger element\n        previousFocus.current?.focus();\n      };\n    }\n  }, [isOpen, onClose]);\n\n  if (!isOpen) return null;\n\n  return (\n    <div\n      className=\"modal-overlay\"\n      onClick={onClose}\n      role=\"dialog\"\n      aria-modal=\"true\"\n      aria-labelledby=\"modal-title\"\n    >\n      <div\n        className=\"modal-content\"\n        ref={modalRef}\n        tabIndex={-1}\n        onClick={(e) => e.stopPropagation()}\n      >\n        <h2 id=\"modal-title\">{title}</h2>\n        {children}\n        <button onClick={onClose} aria-label=\"Close dialog\">\n          Close\n        </button>\n      </div>\n    </div>\n  );\n}\n```\n\n### Example 6: Proper Button vs Link Semantics\n\n**Before (Semantic mismatch)**:\n\n```jsx\n{/* Button used for navigation - WRONG */}\n<button onClick={() => navigate('/products')}>\n  View Products\n</button>\n\n{/* Link used for action - WRONG */}\n<a href=\"#\" onClick={handleDelete}>\n  Delete Item\n</a>\n```\n\n**After (Correct semantics)**:\n\n```jsx\n{/* Link for navigation - CORRECT */}\n<a href=\"/products\">\n  View Products\n</a>\n\n{/* Button for action - CORRECT */}\n<button onClick={handleDelete}>\n  Delete Item\n</button>\n```\n\n---\n\n## Accessibility Remediation Roadmap\n\n### Phase 1: Critical Accessibility Barriers\n\n- [ ] Add alt text to all content images (12 images - A-001)\n- [ ] Associate labels with all form inputs (3 forms - A-002)\n- [ ] Restore focus indicators for all interactive elements (A-004)\n- [ ] Add keyboard access to custom widgets (modals, dropdowns)\n- [ ] Fix ARIA implementation for critical components\n\n**Expected Impact**: Address 45% of accessibility barriers, achieve baseline WCAG Level A compliance\n\n### Phase 2: High Priority Improvements\n\n- [ ] Improve color contrast ratios across site (8 elements - A-003)\n- [ ] Implement skip navigation link for main content\n- [ ] Fix heading hierarchy issues (5 pages - A-005)\n- [ ] Add proper error announcements to forms\n- [ ] Implement correct button/link semantics (6 instances - A-006)\n- [ ] Add ARIA landmarks for page regions\n\n**Expected Impact**: Achieve 80% WCAG Level AA compliance, improve usability for screen reader users\n\n### Phase 3: Medium Priority Enhancements\n\n- [ ] Add autocomplete attributes to form fields\n- [ ] Improve link text descriptiveness\n- [ ] Implement accessible modal dialog pattern\n- [ ] Add confirmation for critical/destructive actions\n- [ ] Enhance dropdown menus with proper ARIA\n- [ ] Add touch target size improvements for mobile\n\n**Expected Impact**: Achieve 95% WCAG Level AA compliance, enhance mobile accessibility\n\n### Phase 4: Accessibility Excellence\n\n- [ ] Implement AAA color contrast where feasible\n- [ ] Add extended descriptions for complex images\n- [ ] Create accessible component pattern library\n- [ ] Establish automated accessibility testing in CI/CD\n- [ ] Conduct user testing with assistive technology users\n- [ ] Document accessibility patterns and guidelines\n\n**Expected Impact**: Approach WCAG Level AAA compliance, establish sustainable accessibility practices\n\n---\n\n## Summary\n\nThis accessibility analysis identified **X critical**, **Y high**, **Z medium**, and **W low** severity accessibility barriers across the application. The analysis focused on WCAG [Version] Level [Level] compliance through static code analysis and pattern detection.\n\n**Key Strengths Identified**:\n\n- Good semantic structure in some components\n- Consistent navigation patterns across the site\n- Valid HTML with minimal parsing errors\n- [Additional strengths based on actual findings]\n\n**Critical Areas Requiring Immediate Attention**:\n\n- Missing alternative text preventing screen reader access\n- Form inputs without labels creating barriers for blind users\n- Insufficient color contrast impacting users with low vision\n- Missing keyboard focus indicators preventing keyboard navigation\n- ARIA implementation errors confusing assistive technologies\n\n**Overall Accessibility Assessment**:\n\n- **Current WCAG Compliance**: X% Level [Level] compliant\n- **Accessibility Blockers**: X critical issues preventing basic access\n- **Accessibility Score**: X/100\n- **Recommendation**: Prioritize Phase 1 and Phase 2 remediation to achieve functional accessibility\n\n**Next Steps**:\n\n1. Address all Critical severity findings within 1 week\n2. Implement High priority fixes within 1 month\n3. Establish accessibility testing in development workflow\n4. Conduct user testing with assistive technology users\n5. Create accessibility guidelines for ongoing development\n6. Schedule regular accessibility audits (quarterly recommended)\n\n**Accessibility is not a one-time fix but an ongoing commitment**. By addressing the identified issues and establishing accessibility practices, this application can provide an inclusive experience for all users, regardless of ability.\n</template>\n\n## Severity Assessment Framework\n\nWhen determining finding severity, apply these criteria:\n\n### CRITICAL: Prevents access for users with disabilities\n- Missing alt text on content images\n- Form inputs without labels\n- Keyboard inaccessible interactive elements\n- Complete absence of ARIA for custom widgets\n- Content only available through inaccessible means\n\n**Examples:**\n- Images with no alt attribute that convey important information\n- Form fields with no associated labels or aria-label\n- Custom dropdown menus that cannot be operated with keyboard\n- Modal dialogs with no focus trap or keyboard dismissal\n\n### HIGH: Significantly impairs accessibility\n- Insufficient color contrast\n- Missing focus indicators\n- Heading hierarchy violations\n- Improper ARIA implementation\n- Missing skip navigation\n\n**Examples:**\n- Text with contrast ratio below 4.5:1 (or 3:1 for large text)\n- `*:focus { outline: none; }` with no replacement\n- Skipping from h1 to h3 (missing h2)\n- Using `role=\"button\"` on non-keyboard-accessible elements\n\n### MEDIUM: Reduces accessibility effectiveness\n- Suboptimal focus indicator design\n- Minor ARIA attribute issues\n- Non-descriptive link text\n- Button/link semantic mismatches\n- Missing autocomplete attributes\n\n**Examples:**\n- Focus indicators visible but with low contrast\n- Missing `aria-expanded` on toggle buttons\n- \"Click here\" or \"Read more\" links without context\n- Using `<button>` for navigation instead of `<a>`\n\n### LOW: Enhancement opportunities and minor issues\n- Missing language attributes\n- AAA compliance improvements\n- Best practice recommendations\n\n**Examples:**\n- `<html>` without `lang` attribute\n- Contrast that passes AA but not AAA\n- Missing `autocomplete` on common form fields\n\n## Best Practices\n\n1. **Test with Actual Assistive Technologies**: Automated tools catch only ~30-40% of accessibility issues. Manual testing with screen readers (NVDA, JAWS, VoiceOver) is essential for comprehensive accessibility validation.\n\n2. **Include Users with Disabilities**: The most valuable accessibility testing comes from actual users with disabilities. Their lived experience reveals usability issues automated and expert testing may miss.\n\n3. **Progressive Enhancement Approach**: Build accessible first, then enhance. Starting with semantic HTML and progressive enhancement ensures baseline accessibility even if JavaScript fails.\n\n4. **Document Accessibility Patterns**: Create reusable accessible component patterns and document implementation guidelines to prevent regression and ensure consistency across the application.\n\n5. **Establish Accessibility Testing in CI/CD**: Integrate automated accessibility testing (axe-core, Lighthouse) into development workflow to catch issues before production.\n\n6. **Educate Development Team**: Accessibility is everyone's responsibility. Provide WCAG training and resources to developers, designers, and content creators.\n\n7. **Regular Accessibility Audits**: Conduct quarterly accessibility reviews to catch regressions and ensure ongoing compliance as the application evolves.\n\n8. **Consider Context**: Accessibility requirements may vary based on user base, industry regulations, and organizational policies. Align recommendations with specific compliance requirements.\n\n## Quality Assurance Checklist\n\nBefore finalizing an accessibility audit, verify:\n\n- ‚úì Have all interactive elements been tested for keyboard accessibility?\n- ‚úì Have color contrast ratios been calculated for all text and UI components?\n- ‚úì Have ARIA roles and attributes been validated against W3C specifications?\n- ‚úì Has heading hierarchy been verified across all pages/routes?\n- ‚úì Have all forms been checked for label associations and error handling?\n- ‚úì Have all images been evaluated for appropriate alternative text?\n- ‚úì Are remediation recommendations specific and actionable with code examples?\n- ‚úì Has the appropriate WCAG version and level been assessed consistently?\n- ‚úì Have findings been prioritized based on user impact and severity?\n- ‚úì Has the WCAG compliance matrix been completed accurately?\n\n## Context-Aware Analysis\n\nWhen project-specific context is available in CLAUDE.md files or project documentation, incorporate:\n\n- **Technology Stack**: Identify framework-specific accessibility features (React accessibility hooks, Vue a11y plugins, Angular CDK accessibility)\n- **Component Libraries**: Check if existing accessible component libraries are being used (Radix UI, Reach UI, Chakra UI)\n- **Industry Requirements**: Note regulatory compliance needs (Section 508, ADA, AODA, European Accessibility Act)\n- **User Demographics**: Consider specific user needs and assistive technology usage patterns\n- **Existing Accessibility Efforts**: Build upon established accessibility patterns and documentation\n\n## Communication Guidelines\n\nWhen reporting accessibility findings:\n\n- Be direct and clear about accessibility barriers and their impact on users\n- Use proper WCAG terminology and criterion references (e.g., \"SC 1.1.1 Level A\")\n- Provide concrete code examples showing both inaccessible and accessible implementations\n- Explain the real-world impact on users with disabilities (not just compliance failure)\n- Balance thoroughness with actionability - focus on fixable issues with clear remediation\n- Acknowledge properly implemented accessibility features to reinforce good patterns\n- Prioritize findings based on user impact, not just technical compliance\n- Use inclusive language that respects people with disabilities\n- **For URL audits with Playwright**: Include screenshots as visual evidence for visual accessibility issues (contrast, focus indicators, layout, etc.)\n\nRemember: The goal is not to criticize but to empower. Every accessibility barrier removed is an opportunity to include more users. Be thorough, be empathetic, and always think from the perspective of users with diverse abilities. Accessibility is not a checklist - it's a commitment to inclusive design."
              }
            ]
          },
          {
            "name": "ai-git",
            "description": "AI-powered git automation - Intelligent git commands and agents that streamline version control workflows with .gitignore generation",
            "source": "./plugins/ai-git",
            "category": null,
            "version": "1.1.2",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-git@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/git-commit-push",
                "description": "Commit all changes to git with an auto-generated message and push to origin.",
                "path": "plugins/ai-git/commands/git-commit-push.md",
                "frontmatter": {
                  "name": "git-commit-push",
                  "description": "Commit all changes to git with an auto-generated message and push to origin."
                },
                "content": "# Commit and Push\n\nCommit all changes to git and push to origin.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, commit messages, or other arguments after this command (e.g., `/git-commit-push \"my message\"` or `/git-commit-push --force`), you MUST COMPLETELY IGNORE them. Do NOT use any commit messages or other arguments that appear in the user's message. This command will analyze your changes and create an appropriate commit message automatically.\n\n**BEFORE DOING ANYTHING ELSE**: Run git status, git diff, and git log to analyze the changes. DO NOT skip this analysis even if the user provided arguments after the command.\n\nWhen this command is executed:\n\n1. Run `git status` to see all changes\n2. Run `git diff` to see the actual changes\n3. Run `git log -3 --format='%s'` to see recent commit message style\n4. Analyze all changes and draft a concise commit message that:\n   - Follows the repository's commit message style\n   - Accurately describes what changed and why\n   - Uses conventional commit prefixes if the repo uses them (fix:, feat:, docs:, etc.)\n5. Add all changes with `git add .`\n6. Commit with the drafted message\n7. Push to origin with `git push`\n8. Confirm success and show the commit hash\n\nIMPORTANT: Do not include the following in commit messages:\n\n- ü§ñ Generated with [Claude Code](https://claude.com/claude-code)\n- Co-Authored-By: Claude <noreply@anthropic.com>"
              },
              {
                "name": "/git-init",
                "description": "Initialize .gitignore with intelligent exclusion patterns based on your project's technology stack.",
                "path": "plugins/ai-git/commands/git-init.md",
                "frontmatter": {
                  "name": "git-init",
                  "description": "Initialize .gitignore with intelligent exclusion patterns based on your project's technology stack."
                },
                "content": "# Git Init\n\nInitialize Git ignore patterns by creating or updating `.gitignore` with intelligent exclusion patterns based on your project's technology stack.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, URLs, or paths after this command (e.g., `/git-init ./project` or `/git-init --force`), you MUST COMPLETELY IGNORE them. Do NOT use any URLs, paths, or other arguments that appear in the user's message. You MUST ONLY proceed with the technology detection and interactive workflow as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Begin with Phase 1 technology detection as specified in this command. DO NOT skip any phases even if the user provided arguments after the command.\n\nSet up comprehensive .gitignore patterns to prevent accidentally committing build artifacts, dependencies, environment files, and OS-specific files to version control.\n\n### Phase 1: Technology Detection\n\nScan the project root directory to detect technologies and frameworks using the **Glob tool** (NOT bash commands):\n\n**Node.js Detection:**\n- Use Glob to search for: `package.json`, `yarn.lock`, `pnpm-lock.yaml`, `bun.lockb`\n\n**Python Detection:**\n- Use Glob to search for: `requirements.txt`, `pyproject.toml`, `setup.py`, `Pipfile`, `poetry.lock`, `setup.cfg`\n\n**.NET Detection:**\n- Use Glob to search for: `*.csproj`, `*.sln`, `*.fsproj`, `*.vbproj`, `global.json`, `Directory.Build.props`\n\n**Go Detection:**\n- Use Glob to search for: `go.mod`, `go.sum`\n\n**Rust Detection:**\n- Use Glob to search for: `Cargo.toml`, `Cargo.lock`\n\n**PHP Detection:**\n- Use Glob to search for: `composer.json`, `composer.lock`\n\n**Ruby Detection:**\n- Use Glob to search for: `Gemfile`, `Gemfile.lock`\n\n**Java Detection:**\n- Use Glob to search for: `pom.xml`, `build.gradle`, `build.gradle.kts`, `settings.gradle`\n\n**Docker Detection:**\n- Use Glob to search for: `Dockerfile`, `docker-compose.yml`, `docker-compose.yaml`, `.dockerignore`\n\n**Next.js/React Detection:**\n- Use Glob to search for: `next.config.js`, `next.config.ts`, `next.config.mjs`\n\n**Vue Detection:**\n- Use Glob to search for: `vue.config.js`, `nuxt.config.js`, `nuxt.config.ts`\n\n**Terraform Detection:**\n- Use Glob to search for: `*.tf`, `terraform.tfvars`\n\n**IMPORTANT**:\n- Use **Glob tool only** for file detection - DO NOT use bash test commands or any bash commands\n- Only check for file existence - DO NOT read the contents of any files during detection\n- Glob returns matching files or empty array if none found\n\n### Phase 2: Build Ignore Patterns\n\nCreate a comprehensive .gitignore combining:\n\n#### Base Patterns (Always Include)\n\n**Environment & Secrets:**\n```\n# Environment variables\n.env\n.env.*\n.env.local\n.env.development\n.env.production\n.env.test\n!.env.example\n\n# Secrets\ncredentials.json\nsecrets.yml\n*.secret\n*.pem\n*.key\n*.p12\n*.jks\n*.pfx\n*.keystore\n```\n\n**Operating System Files:**\n```\n# macOS\n.DS_Store\n.AppleDouble\n.LSOverride\n._*\n\n# Windows\nThumbs.db\nThumbs.db:encryptable\nehthumbs.db\nehthumbs_vista.db\nDesktop.ini\n$RECYCLE.BIN/\n\n# Linux\n*~\n.directory\n.Trash-*\n```\n\n**IDE & Editor Files:**\n```\n# Visual Studio Code\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n*.code-workspace\n\n# JetBrains IDEs\n.idea/\n*.iml\n*.iws\n*.ipr\n.idea_modules/\n\n# Vim\n*.swp\n*.swo\n*~\n\n# Emacs\n*~\n\\#*\\#\n/.emacs.desktop\n/.emacs.desktop.lock\n\n# Sublime Text\n*.sublime-workspace\n*.sublime-project\n```\n\n#### Technology-Specific Patterns\n\n**Node.js (if detected):**\n```\n# Dependencies\nnode_modules/\njspm_packages/\n\n# Build outputs\ndist/\nbuild/\n.next/\n.nuxt/\nout/\n\n# Testing\ncoverage/\n.nyc_output/\n\n# Caching\n.cache/\n.turbo/\n.parcel-cache/\n.webpack/\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\npnpm-debug.log*\n\n# Lock files (optional - ask user)\n# Uncomment if you want to ignore lock files\n# package-lock.json\n# yarn.lock\n# pnpm-lock.yaml\n```\n\n**Python (if detected):**\n```\n# Byte-compiled / optimized\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n\n# Virtual environments\n.venv/\nvenv/\nENV/\nenv/\n.python-version\n\n# Distribution / packaging\ndist/\nbuild/\n*.egg-info/\n*.egg\n.eggs/\nwheels/\n\n# Testing\n.pytest_cache/\n.tox/\n.coverage\nhtmlcov/\n.hypothesis/\n\n# Type checking\n.mypy_cache/\n.dmypy.json\ndmypy.json\n.pytype/\n\n# Linting\n.ruff_cache/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n*.ipynb\n```\n\n**.NET (if detected):**\n```\n# Build results\nbin/\nobj/\nout/\n\n# User-specific files\n*.user\n*.suo\n*.userosscache\n*.sln.docstates\n*.userprefs\n\n# Visual Studio\n.vs/\n*.DotSettings.user\n\n# Test results\nTestResults/\n[Tt]est[Rr]esult*/\n*.trx\n\n# NuGet\npackages/\n*.nupkg\n*.snupkg\nproject.lock.json\nproject.fragment.lock.json\n```\n\n**Go (if detected):**\n```\n# Binaries\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n\n# Test binary\n*.test\n\n# Output of the go coverage tool\n*.out\n\n# Dependency directories\nvendor/\n\n# Go workspace file\ngo.work\n```\n\n**Rust (if detected):**\n```\n# Compilation outputs\ntarget/\nCargo.lock\n\n# Backup files\n**/*.rs.bk\n*.pdb\n```\n\n**PHP (if detected):**\n```\n# Composer\nvendor/\ncomposer.lock\ncomposer.phar\n\n# Laravel\n.env\n.env.backup\n.phpunit.result.cache\nHomestead.json\nHomestead.yaml\nnpm-debug.log\nyarn-error.log\n\n# Symfony\n/var/\n/vendor/\n```\n\n**Ruby (if detected):**\n```\n# Bundler\nvendor/bundle/\n.bundle/\n\n# RVM\n.rvmrc\n\n# rbenv\n.ruby-version\n\n# RSpec\n.rspec_status\n\n# Coverage\ncoverage/\n```\n\n**Java (if detected):**\n```\n# Compiled class files\n*.class\n\n# Log files\n*.log\n\n# Package Files\n*.jar\n*.war\n*.nar\n*.ear\n*.zip\n*.tar.gz\n*.rar\n\n# Maven\ntarget/\npom.xml.tag\npom.xml.releaseBackup\npom.xml.versionsBackup\npom.xml.next\nrelease.properties\n\n# Gradle\n.gradle/\nbuild/\ngradle-app.setting\n!gradle-wrapper.jar\n```\n\n**Docker (if detected):**\n```\n# Docker override files\ndocker-compose.override.yml\ndocker-compose.override.yaml\n```\n\n**Terraform (if detected):**\n```\n# Terraform\n.terraform/\n*.tfstate\n*.tfstate.*\n*.tfvars\ncrash.log\noverride.tf\noverride.tf.json\n*_override.tf\n*_override.tf.json\n```\n\n### Phase 3: Check Existing .gitignore\n\nCheck if `.gitignore` already exists using the **Read tool** (NOT bash test commands):\n\n1. Try to read `.gitignore` using the Read tool\n2. If the file exists and Read succeeds:\n   - Parse the content\n   - Analyze existing patterns\n   - Ask user for merge strategy preference using AskUserQuestion tool:\n     - **Smart Merge** (default): Deduplicate patterns, preserve comments, organize by category\n     - **Append**: Add all new patterns at the end, keep existing content as-is\n     - **Replace**: Completely replace existing .gitignore with new patterns\n3. If the file doesn't exist (Read returns error):\n   - Proceed to create new file with ignore patterns\n   - Use \"Smart Merge\" as the default strategy\n\n**IMPORTANT**:\n- Use **Read tool** to check file existence - DO NOT use bash test commands\n- The Read tool will gracefully handle non-existent files by returning an error\n- Preserve existing comments and custom patterns during merge\n- Detect and remove duplicate patterns\n\n### Phase 4: Show Preview & Get Confirmation\n\nDisplay a comprehensive preview showing:\n\n1. **Technologies Detected:**\n   - List all detected technologies with file indicators\n\n2. **Current .gitignore (if exists):**\n   - Show line count\n   - Show sample of existing patterns (first 10 lines)\n   - Identify any duplicate or redundant patterns\n\n3. **Proposed .gitignore:**\n   - Show all patterns to be added\n   - Group by category (Base Patterns, Node.js, Python, etc.)\n   - Show total pattern count\n   - Highlight any custom patterns that will be preserved\n\n4. **After Merge:**\n   - Show estimated total line count\n   - Show merge strategy being used\n   - List categories included\n\nAsk for user confirmation before proceeding.\n\n### Phase 5: Write .gitignore\n\nAfter user confirms:\n\n1. Build the complete .gitignore content with proper formatting:\n   - Add header comment with generation info\n   - Group patterns by category with section headers\n   - Include blank lines between sections for readability\n   - Preserve existing custom patterns if merging\n   - Sort patterns within categories alphabetically\n\n2. Write `.gitignore` using the **Write tool** (NOT bash echo or heredoc)\n\n3. Show success message with:\n   - File path: `.gitignore`\n   - Total patterns configured\n   - Technologies covered\n   - Next steps (review, git status, commit)\n\n**IMPORTANT**:\n- Use **Write tool** to create/update the .gitignore file\n- DO NOT use bash commands for writing the file\n- Ensure proper formatting with blank lines between sections\n- Include helpful comments for each section\n\n### Important Constraints\n\n**DO NOT:**\n- Read the contents of any sensitive files during scanning\n- Include actual file paths from the project in .gitignore\n- Proceed without user confirmation\n- Use bash test commands (`test -f`, `[ -f ]`, etc.)\n- Use any bash commands for file detection or checking\n- Remove existing custom patterns without user consent\n\n**DO:**\n- Use **Glob tool** for technology detection (file pattern matching)\n- Use **Read tool** to check if `.gitignore` exists (handles errors gracefully)\n- Use **Write tool** to create/update .gitignore\n- Use **AskUserQuestion tool** to ask for merge strategy preference\n- Deduplicate patterns by default during merge\n- Preserve comments and custom patterns from existing .gitignore\n- Show clear before/after comparison\n- Maintain alphabetical ordering within categories for readability\n- Use forward slashes in all patterns for cross-platform compatibility\n- Add helpful section headers and comments\n\n### Example Output Format\n\n```\nüîç Detecting technologies in your project...\n\nTechnologies Detected:\n‚úì Node.js (package.json found)\n‚úì TypeScript (tsconfig.json found)\n‚úì Python (requirements.txt, pyproject.toml found)\n‚úì Docker (Dockerfile, docker-compose.yml found)\n\nCurrent .gitignore:\nüìÑ .gitignore exists (42 lines)\nüìä Sample patterns:\n  node_modules/\n  .env\n  dist/\n  ...\n\nProposed .gitignore Structure:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nBase Patterns:\n  ‚Ä¢ Environment & Secrets (12 patterns)\n  ‚Ä¢ Operating System Files (15 patterns)\n  ‚Ä¢ IDE & Editor Files (18 patterns)\n\nNode.js Patterns:\n  ‚Ä¢ Dependencies (2 patterns)\n  ‚Ä¢ Build outputs (5 patterns)\n  ‚Ä¢ Testing & Caching (6 patterns)\n  ‚Ä¢ Logs (5 patterns)\n\nPython Patterns:\n  ‚Ä¢ Byte-compiled (5 patterns)\n  ‚Ä¢ Virtual environments (5 patterns)\n  ‚Ä¢ Distribution (7 patterns)\n  ‚Ä¢ Testing (5 patterns)\n\nDocker Patterns:\n  ‚Ä¢ Docker overrides (2 patterns)\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nTotal patterns: 87\nEstimated file size: ~150 lines (with comments)\n\nMerge Strategy: Smart Merge (deduplicate, preserve comments, organize)\n\nWould you like to proceed with this configuration? (yes/no)\n```\n\n### Success Message Format\n\n```\n‚úì .gitignore successfully initialized!\n\nConfiguration Summary:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüìÑ File: .gitignore\nüìä Total patterns: 87 (organized in 7 categories)\nüõ°Ô∏è Technologies covered: Node.js, TypeScript, Python, Docker\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nNext Steps:\n1. Review the generated .gitignore file\n2. Run `git status` to see which files are now ignored\n3. Remove any currently tracked files that should be ignored:\n   git rm --cached <file>\n4. Commit the .gitignore file:\n   git add .gitignore\n   git commit -m \"Add comprehensive .gitignore for detected technologies\"\n\nüí° Tip: You can run this command again to update .gitignore when adding new technologies to your project.\n```\n\n### Additional Features\n\n**Lock File Handling:**\nWhen Node.js is detected, ask the user if they want to commit lock files (package-lock.json, yarn.lock, pnpm-lock.yaml):\n- Most projects SHOULD commit lock files for reproducible builds\n- Only ignore lock files if explicitly requested\n- Add commented-out lock file patterns with explanation\n\n**Custom Patterns:**\nDuring Smart Merge, detect and preserve:\n- User-added comments (lines starting with #)\n- Custom patterns not in the standard template\n- Negation patterns (lines starting with !)\n\n**Pattern Validation:**\n- Ensure patterns use forward slashes (/)\n- Remove duplicate patterns across categories\n- Warn about overly broad patterns (e.g., `*`, `*.txt`)"
              }
            ],
            "skills": []
          },
          {
            "name": "ai-performance",
            "description": "AI-powered performance optimization - Interactive performance audit skill and automated agent with comprehensive bottleneck detection and optimization",
            "source": "./plugins/ai-performance",
            "category": null,
            "version": "1.1.3",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-performance@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/performance-audit",
                "description": "Comprehensive performance analysis to identify bottlenecks, optimization opportunities, and scalability issues.",
                "path": "plugins/ai-performance/commands/performance-audit.md",
                "frontmatter": {
                  "name": "performance-audit",
                  "description": "Comprehensive performance analysis to identify bottlenecks, optimization opportunities, and scalability issues."
                },
                "content": "# Performance Audit\n\nYou are a comprehensive performance optimization expert with deep expertise in application performance, scalability, code optimization, and performance best practices.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, URLs, or paths after this command (e.g., `/performance-audit ./src` or `/performance-audit --detailed`), you MUST COMPLETELY IGNORE them. Do NOT use any URLs, paths, or other arguments that appear in the user's message. You MUST ONLY proceed with invoking the performance auditor subagent as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Use the Task tool with subagent_type \"ai-performance:performance-auditor\" to perform the audit. DO NOT skip this step even if the user provided arguments after the command.\n\nUse the Task tool with subagent_type \"ai-performance:performance-auditor\" to perform a thorough performance analysis of this codebase to identify performance bottlenecks, optimization opportunities, and scalability issues.\n\n### Analysis Scope\n\n1. **Code Pattern Analysis**: Scan for N+1 queries, inefficient loops, memory leaks, blocking operations\n2. **Database Performance Review**: Analyze SQL queries, indexing strategies, and data access patterns\n3. **Resource Utilization Assessment**: Review memory allocation patterns, CPU-intensive operations, I/O bottlenecks\n4. **Architecture Performance Analysis**: Examine caching strategies, async/await patterns, connection pooling\n5. **Scalability Assessment**: Identify thread pool issues, connection management, and load handling patterns\n\n### Output Requirements\n\n- Create a comprehensive performance audit report\n- Save the report to: `/docs/performance/{timestamp}-performance-audit.md`\n  - Format: `YYYY-MM-DD-HHMMSS-performance-audit.md`\n  - Example: `2025-10-17-143022-performance-audit.md`\n  - This ensures multiple scans on the same day don't overwrite each other\n- Include actual findings from the codebase (not template examples)\n- Provide exact file paths and line numbers for all findings\n- Include before/after code examples for optimization guidance\n- Prioritize findings by impact: Critical, High, Medium, Low\n\n### Important Notes\n\n- Focus on **code-level performance optimization** - identifying bottlenecks through static analysis\n- Provide actionable optimization guidance with specific code examples\n- Create a prioritized optimization roadmap based on performance impact\n- Include expected performance improvement estimates for each recommendation\n\nThe ai-performance:performance-auditor subagent will perform a comprehensive performance analysis of this codebase."
              }
            ],
            "skills": [
              {
                "name": "performance-auditing",
                "description": "Guide for analyzing and improving application performance including identifying bottlenecks, implementing caching, and optimizing queries. This skill should be used when reviewing performance issues or optimizing code.",
                "path": "plugins/ai-performance/skills/performance-auditing/SKILL.md",
                "frontmatter": {
                  "name": "performance-auditing",
                  "description": "Guide for analyzing and improving application performance including identifying bottlenecks, implementing caching, and optimizing queries. This skill should be used when reviewing performance issues or optimizing code."
                },
                "content": "# Performance Audit Skill\n\nThis skill provides elite performance engineering expertise for making applications lightning-fast through systematic optimization.\n\n## When to Use This Skill\n\nInvoke this skill when:\n- Analyzing slow page loads or response times\n- Identifying performance bottlenecks in code execution\n- Designing and implementing caching strategies\n- Optimizing database queries and preventing N+1 problems\n- Reducing memory consumption or investigating memory leaks\n- Improving asset delivery (compression, minification, bundling)\n- Implementing lazy loading or code splitting\n- Profiling and benchmarking code performance\n- Reviewing new features for performance implications\n- Establishing performance budgets for critical user journeys\n\n## Core Performance Expertise\n\n### 1. Performance Analysis Methodology\n\nTo analyze performance issues effectively:\n\n**Measure First**: Always establish baseline metrics before optimization. Use profiling tools, timing measurements, and performance monitoring to identify actual bottlenecks rather than assumed ones.\n\n**Prioritize Impact**: Focus on optimizations that provide the greatest performance improvement relative to implementation effort. Target the critical path and high-traffic code paths first.\n\n**Consider Trade-offs**: Evaluate each optimization for its impact on code maintainability, complexity, and resource usage. Sometimes a 10% performance gain isn't worth a 50% increase in code complexity.\n\n**Validate Improvements**: After implementing optimizations, measure again to confirm actual performance gains. Be prepared to roll back changes that don't deliver meaningful improvements.\n\n### 2. Caching Strategies\n\nTo implement effective caching:\n\n- Choose the appropriate caching layer (browser cache, CDN, application cache, database query cache, computed result cache)\n- Implement proper cache invalidation strategies to prevent stale data issues\n- Use cache keys that are specific enough to avoid collisions but general enough to maximize hit rates\n- Set appropriate TTLs based on data volatility and business requirements\n- Implement cache warming for predictable high-traffic scenarios\n- Use cache-aside, write-through, or write-behind patterns as appropriate\n- Monitor cache hit rates and adjust strategies based on real usage patterns\n\n**Key Rules:**\n- Never cache without considering invalidation strategy\n- Always measure cache hit rates to validate effectiveness\n- Balance cache complexity against actual performance benefits\n\n### 3. Frontend Performance Optimization\n\nTo optimize frontend performance, focus on:\n\n**Critical Rendering Path:**\n- Minimize render-blocking resources (CSS, JavaScript)\n- Prioritize above-the-fold content loading\n- Use resource hints (preload, prefetch, preconnect)\n\n**Asset Optimization:**\n- Compress and minify JavaScript and CSS\n- Optimize images (format, compression, responsive sizes)\n- Implement lazy loading for images and off-screen content\n- Use code splitting to reduce initial bundle size\n\n**Runtime Performance:**\n- Debounce and throttle user interaction handlers\n- Use virtual scrolling for large lists\n- Offload CPU-intensive tasks to Web Workers\n- Implement efficient React re-render patterns (memoization, useMemo, useCallback)\n\n**Key Rules:**\n- Always measure with real-world conditions (throttled network, low-end devices)\n- Focus on First Contentful Paint (FCP) and Time to Interactive (TTI)\n- Avoid premature optimization of rarely-executed code\n\n### 4. Backend Performance Optimization\n\nTo optimize backend performance, address:\n\n**Database Performance:**\n- Add indexes on frequently queried columns\n- Prevent N+1 query problems with eager loading\n- Use query explain plans to identify slow operations\n- Implement connection pooling for database connections\n- Consider read replicas for high-traffic read operations\n\n**Request Processing:**\n- Implement pagination and filtering for large datasets\n- Use asynchronous processing for long-running tasks\n- Batch similar operations to reduce overhead\n- Implement request/response compression\n\n**Resource Management:**\n- Use connection pooling for external services\n- Implement circuit breakers for failing dependencies\n- Set appropriate timeouts to prevent resource exhaustion\n\n**Key Rules:**\n- Database queries should use indexes, not full table scans\n- Long-running operations belong in background jobs, not HTTP requests\n- Always implement pagination for unbounded result sets\n\n### 5. Infrastructure Performance\n\nTo optimize infrastructure performance:\n\n- Configure CDN caching for static assets\n- Implement load balancing for horizontal scaling\n- Use appropriate database indexing and sharding strategies\n- Enable compression (gzip, brotli) for text-based responses\n- Optimize container resource allocation\n\n**Key Rules:**\n- CDN cache misses should be minimized through proper cache headers\n- Horizontal scaling requires stateless application design\n- Monitor resource utilization to right-size infrastructure\n\n## Report Output Format\n\n**IMPORTANT**: The section below defines the COMPLETE report structure that MUST be used. Do NOT create your own format or simplified version.\n\n### Location and Naming\n- **Directory**: `/docs/performance/`\n- **Filename**: `YYYY-MM-DD-HHMMSS-performance-audit.md`\n- **Example**: `2025-10-29-143022-performance-audit.md`\n\n### Report Template\n\n**üö® CRITICAL INSTRUCTION - READ CAREFULLY üö®**\n\nYou MUST use this exact template structure for ALL performance audit reports. This is MANDATORY and NON-NEGOTIABLE.\n\n**REQUIREMENTS:**\n1. ‚úÖ Use the COMPLETE template structure below - ALL sections are REQUIRED\n2. ‚úÖ Follow the EXACT heading hierarchy (##, ###, ####)\n3. ‚úÖ Include ALL section headings as written in the template\n4. ‚úÖ Use the finding numbering format: P-001, P-002, etc.\n5. ‚úÖ Include the tables, code examples, and checklists as shown\n6. ‚ùå DO NOT create your own format or structure\n7. ‚ùå DO NOT skip or combine sections\n8. ‚ùå DO NOT create abbreviated or simplified versions\n9. ‚ùå DO NOT number issues as \"1, 2, 3\" - use P-001, P-002, P-003 format\n\n**If you do not follow this template exactly, the report will be rejected.**\n\n<template>\n## Executive Summary\n\n### Audit Overview\n\n- **Target System**: [Application Name/System]\n- **Analysis Date**: [Date Range]\n- **Analysis Scope**: [Web Application/API/Database/Full Stack]\n- **Technology Stack**: [e.g., .NET 8, Umbraco CMS, SQL Server, Elasticsearch, Azure]\n\n### Performance Assessment Summary\n\n| Performance Level | Count | Percentage |\n|-------------------|-------|------------|\n| Critical Issues   | X     | X%         |\n| High Impact       | X     | X%         |\n| Medium Impact     | X     | X%         |\n| Low Impact        | X     | X%         |\n| **Total**         | **X** | **100%**   |\n\n### Key Analysis Results\n\n- **Performance Anti-Patterns**: X critical patterns identified requiring immediate attention\n- **Code Optimization Opportunities**: X high-impact optimizations discovered\n- **Architecture Assessment**: X/10 performance best practices implemented\n- **Overall Code Performance Score**: X/100 (based on static analysis and architectural patterns)\n\n---\n\n## Analysis Methodology\n\n### Performance Analysis Approach\n\n- **Static Code Analysis**: Comprehensive source code review for performance anti-patterns\n- **Database Query Analysis**: Review of SQL queries, indexing strategies, and data access patterns\n- **Resource Utilization Assessment**: Analysis of memory, CPU, and I/O usage patterns\n- **Architecture Performance Review**: Examination of caching, scaling, and optimization strategies\n\n### Analysis Coverage\n\n- **Files Analyzed**: X source files across Y projects\n- **Database Queries Reviewed**: X queries and stored procedures\n- **API Endpoints Tested**: X endpoints across Y controllers\n- **Performance Patterns Checked**: N+1 queries, memory leaks, CPU bottlenecks, I/O blocking\n\n### Analysis Capabilities\n\n- **Pattern Detection**: N+1 queries, inefficient loops, memory leaks, blocking operations\n- **Database Analysis**: Missing indexes, expensive queries, deadlock potential\n- **Resource Analysis**: Memory allocation patterns, CPU-intensive operations, I/O bottlenecks\n- **Architecture Assessment**: Caching strategies, async/await patterns, connection pooling\n\n---\n\n## Performance Findings\n\n### Critical Performance Issues\n\n#### P-001: N+1 Query Problem\n\n**Location**: `src/Website.Core/Services/VendorService.cs:78`\n**Performance Impact**: 9.8 (Critical)\n**Pattern Detected**: Loading related entities in a loop causing multiple database queries\n**Code Context**:\n\n```csharp\nforeach (var vendor in vendors)\n{\n    vendor.Products = context.Products.Where(p => p.VendorId == vendor.Id).ToList();\n}\n```\n\n**Impact**: Database query count increases linearly with result set size (1 + N queries instead of 1)\n**Performance Cost**: 2000ms+ response time for 100 vendors\n**Recommendation**: Use Include() for eager loading or projection for specific fields\n**Fix Priority**: Immediate (within 24 hours)\n\n#### P-002: Synchronous Database Operations\n\n**Location**: `src/Website.Web/Controllers/ApiController.cs:45`\n**Performance Impact**: 9.1 (Critical)\n**Pattern Detected**: Synchronous database calls blocking request threads\n**Code Context**: Missing async/await pattern in controller actions\n**Impact**: Thread pool exhaustion under high load, poor scalability\n**Performance Cost**: Thread starvation affecting overall application responsiveness\n**Recommendation**: Convert all database operations to async/await pattern\n**Fix Priority**: Immediate (within 48 hours)\n\n### High Performance Impact Findings\n\n#### P-003: Large Object Heap Pressure\n\n**Location**: Multiple locations in data processing services\n**Performance Impact**: 7.8 (High)\n**Pattern Detected**: Large objects (>85KB) causing frequent Gen 2 garbage collection\n**Affected Components**:\n\n- `src/Website.AirtableData/Services/ImportService.cs:156`\n- `src/Website.ElasticSearch/Services/IndexingService.cs:89`\n**Impact**: GC pressure causing application pauses and increased memory usage\n**Performance Cost**: 200-500ms GC pauses, 40% higher memory usage\n**Recommendation**: Implement streaming for large data sets, use object pooling\n**Fix Priority**: Within 1 week\n\n#### P-004: Inefficient Elasticsearch Queries\n\n**Location**: `src/Website.ElasticSearch/Services/SearchService.cs:123`\n**Performance Impact**: 7.5 (High)\n**Pattern Detected**: Full-text search without field targeting or filtering\n**Code Context**: Broad queries without proper field restrictions or caching\n**Impact**: High Elasticsearch cluster load, slow search response times\n**Performance Cost**: 800ms+ search response time, high CPU usage on ES cluster\n**Recommendation**: Implement targeted field searches, result caching, and query optimization\n**Fix Priority**: Within 2 weeks\n\n### Medium Performance Impact Findings\n\n#### P-005: Missing Database Indexes\n\n**Location**: Database schema analysis\n**Performance Impact**: 6.3 (Medium)\n**Pattern Detected**: Frequent WHERE clauses on non-indexed columns\n**Affected Tables**:\n\n- `Vendors` table: missing index on `OrganizationId, IsActive`\n- `Products` table: missing composite index on `CategoryId, Status, CreatedDate`\n**Impact**: Table scans causing slow query performance\n**Performance Cost**: 500-1200ms query response time for filtered data\n**Recommendation**: Add appropriate indexes based on query patterns\n**Fix Priority**: Within 1 month\n\n#### P-006: Inefficient LINQ Queries\n\n**Location**: Multiple service classes\n**Performance Impact**: 5.9 (Medium)\n**Pattern Detected**: Multiple enumeration of IEnumerable, inefficient projections\n**Affected Areas**: Vendor listing, product filtering, category navigation\n**Impact**: Unnecessary CPU cycles, increased memory allocation\n**Performance Cost**: 200-400ms additional processing time\n**Recommendation**: Use ToList() strategically, optimize LINQ expressions\n**Fix Priority**: Within 1 month\n\n### Low Performance Impact Findings\n\n#### P-007: Missing Output Caching\n\n**Location**: Web application controllers and views\n**Performance Impact**: 3.8 (Low)\n**Pattern Detected**: Repeated computation of static or semi-static content\n**Missing Caching**: Category lists, navigation menus, vendor counts\n**Impact**: Unnecessary CPU usage for frequently accessed data\n**Performance Cost**: 50-100ms additional processing per request\n**Recommendation**: Implement response caching and memory caching strategies\n**Fix Priority**: Within 2 months\n\n---\n\n## Code Pattern Performance Analysis\n\n### Performance Anti-Pattern Detection\n\n- **N+1 Query Patterns**: X instances detected across Y service classes\n- **Synchronous Blocking Operations**: X async-convertible operations identified\n- **Large Object Allocations**: X locations with >85KB object creation\n- **Inefficient LINQ Usage**: X queries with multiple enumeration or suboptimal patterns\n\n### Database Access Pattern Analysis\n\n- **Entity Framework Usage**: X queries analyzed for efficiency patterns\n- **Missing Async Patterns**: X database operations identified for async conversion\n- **Query Complexity**: X complex queries requiring optimization review\n- **Connection Management**: Connection pooling configuration assessment\n\n### Resource Management Pattern Analysis\n\n- **Memory Allocation Patterns**: Large object heap pressure points identified\n- **Garbage Collection Pressure**: X locations with excessive object creation\n- **Thread Pool Usage**: X blocking operations affecting scalability\n- **Caching Opportunities**: X frequently computed operations without caching\n\n---\n\n## Architecture Performance Assessment\n\n### Data Access Layer Analysis\n\n- **Entity Framework Performance**: ‚ö†Ô∏è N+1 queries detected, lazy loading causing issues\n- **Connection Pooling**: ‚úÖ Properly configured with appropriate pool sizes\n- **Query Optimization**: ‚ùå Missing indexes and inefficient LINQ expressions\n- **Caching Strategy**: ‚ùå Insufficient caching at data layer\n\n### Application Layer Analysis\n\n- **Async/Await Usage**: ‚ùå Many synchronous operations blocking threads\n- **Memory Management**: ‚ö†Ô∏è Some memory leaks in background services\n- **CPU Utilization**: ‚ö†Ô∏è CPU-intensive operations not optimized\n- **I/O Operations**: ‚ùå File operations and API calls not properly optimized\n\n### Infrastructure Analysis\n\n- **Load Balancing**: ‚úÖ Properly configured with health checks\n- **CDN Usage**: ‚ö†Ô∏è Static assets cached but optimization needed\n- **Database Scaling**: ‚ö†Ô∏è Read replicas available but not fully utilized\n- **Monitoring Coverage**: ‚ùå Limited application performance monitoring\n\n---\n\n## Performance Bottleneck Analysis\n\n### Top 10 Performance Bottlenecks\n\n| Rank | Component | Issue | Impact Score | Response Time Impact |\n|------|-----------|-------|--------------|---------------------|\n| 1 | VendorService | N+1 Query Problem | 9.8 | +2000ms |\n| 2 | ApiController | Sync DB Operations | 9.1 | Thread exhaustion |\n| 3 | ImportService | Large Object Heap | 7.8 | +500ms GC pauses |\n| 4 | SearchService | Inefficient ES Queries | 7.5 | +800ms |\n| 5 | Database | Missing Indexes | 6.3 | +600ms |\n| 6 | LINQ Queries | Multiple Enumeration | 5.9 | +300ms |\n| 7 | File Operations | Synchronous I/O | 5.2 | +400ms |\n| 8 | Caching | Missing Cache Strategy | 4.8 | +200ms |\n| 9 | Background Jobs | Memory Leaks | 4.5 | Resource exhaustion |\n| 10 | API Serialization | Large Payloads | 3.9 | +150ms |\n\n---\n\n## Technical Recommendations\n\n### Immediate Performance Fixes\n\n1. **Fix N+1 query problems** using Include() or projection in Entity Framework\n2. **Convert synchronous operations** to async/await pattern for scalability\n3. **Add missing database indexes** for frequently queried columns\n4. **Implement connection pooling** for external service calls\n\n### Performance Enhancements\n\n1. **Implement comprehensive caching strategy** using Redis or in-memory caching\n2. **Optimize Elasticsearch queries** with proper field targeting and filtering\n3. **Add response compression** for API endpoints and static content\n4. **Implement lazy loading** for heavy components and data\n\n### Architecture Improvements\n\n1. **Add application performance monitoring** using Application Insights or similar\n2. **Implement database read replicas** for read-heavy operations\n3. **Add background job optimization** with proper queue management\n4. **Implement API rate limiting** and request throttling\n\n---\n\n## Code Optimization Examples\n\n### N+1 Query Fix\n\n**Before (Inefficient)**:\n\n```csharp\nvar vendors = context.Vendors.ToList();\nforeach (var vendor in vendors)\n{\n    vendor.Products = context.Products.Where(p => p.VendorId == vendor.Id).ToList();\n}\n```\n\n**After (Optimized)**:\n\n```csharp\nvar vendors = context.Vendors\n    .Include(v => v.Products)\n    .ToList();\n// OR for specific fields only\nvar vendorsWithProductCount = context.Vendors\n    .Select(v => new VendorViewModel\n    {\n        Id = v.Id,\n        Name = v.Name,\n        ProductCount = v.Products.Count()\n    })\n    .ToList();\n```\n\n### Async/Await Implementation\n\n**Before (Blocking)**:\n\n```csharp\n[HttpGet]\npublic IActionResult GetVendors()\n{\n    var vendors = vendorService.GetAll(); // Synchronous call\n    return Ok(vendors);\n}\n```\n\n**After (Non-blocking)**:\n\n```csharp\n[HttpGet]\npublic async Task<IActionResult> GetVendors()\n{\n    var vendors = await vendorService.GetAllAsync(); // Asynchronous call\n    return Ok(vendors);\n}\n```\n\n### Caching Implementation\n\n**Before (No Caching)**:\n\n```csharp\npublic List<Category> GetCategories()\n{\n    return context.Categories.OrderBy(c => c.Name).ToList();\n}\n```\n\n**After (With Caching)**:\n\n```csharp\npublic async Task<List<Category>> GetCategoriesAsync()\n{\n    const string cacheKey = \"categories_all\";\n    var cached = await cache.GetAsync<List<Category>>(cacheKey);\n    if (cached != null)\n        return cached;\n\n    var categories = await context.Categories\n        .OrderBy(c => c.Name)\n        .ToListAsync();\n\n    await cache.SetAsync(cacheKey, categories, TimeSpan.FromMinutes(30));\n    return categories;\n}\n```\n\n---\n\n## Performance Optimization Priorities\n\n### Phase 1: Critical Performance Fixes\n\n- [ ] Fix N+1 queries in `VendorService.cs:78`\n- [ ] Convert synchronous database operations to async in `ApiController.cs:45`\n- [ ] Add missing database indexes for Vendors and Products tables\n- [ ] Implement connection pooling for Elasticsearch service\n\n### Phase 2: High Impact Optimizations\n\n- [ ] Optimize large object allocations in import services\n- [ ] Implement caching strategy for frequently accessed data\n- [ ] Optimize Elasticsearch queries with proper filtering\n- [ ] Fix memory leaks in background job processing\n\n### Phase 3: Medium Impact Improvements\n\n- [ ] Optimize LINQ queries to avoid multiple enumeration\n- [ ] Implement response compression and output caching\n- [ ] Add database read replicas for read operations\n- [ ] Optimize file I/O operations with async patterns\n\n### Phase 4: Performance Monitoring and Fine-tuning\n\n- [ ] Implement comprehensive APM solution\n- [ ] Add custom performance counters and metrics\n- [ ] Set up automated performance testing\n- [ ] Document performance best practices\n\n---\n\n## Estimated Performance Improvement Impact\n\n### Performance Gains by Priority\n\n| Priority Level | Expected Improvement | Implementation Complexity |\n|----------------|---------------------|--------------------------|\n| Critical Fixes | 60-80% response time improvement | High - requires careful testing |\n| High Impact | 30-50% overall performance gain | Medium - architectural changes |\n| Medium Impact | 15-25% additional optimization | Medium - code and config changes |\n| Low Impact | 5-10% fine-tuning benefits | Low - mostly configuration |\n\n### Resource Utilization Improvements\n\n- **Database Load**: Expected 40-60% reduction in query execution time\n- **Memory Usage**: Expected 25-35% reduction in memory pressure\n- **CPU Utilization**: Expected 20-30% reduction in CPU usage\n- **Thread Pool**: Expected elimination of thread starvation issues\n\n---\n\n## Performance Monitoring Setup Recommendations\n\n### Monitoring Infrastructure Setup\n\n- **Application Performance Monitoring**: Azure Application Insights or New Relic integration\n- **Database Monitoring**: SQL Server Extended Events and Performance Dashboard configuration\n- **Infrastructure Monitoring**: Azure Monitor or Prometheus + Grafana setup\n- **Code-Level Monitoring**: Custom performance counters for identified bottlenecks\n\n### Recommended Performance Tracking\n\n- **Database Query Monitoring**: Track queries identified in this analysis for execution time\n- **Memory Allocation Tracking**: Monitor large object heap allocations in flagged components\n- **Thread Pool Monitoring**: Track thread starvation in areas with synchronous operations\n- **Cache Hit Rate Monitoring**: Measure effectiveness of recommended caching implementations\n\n### Performance Testing Recommendations\n\n- **Load Testing**: Focus on endpoints with identified N+1 query problems\n- **Database Performance Testing**: Test queries with missing indexes under load\n- **Memory Pressure Testing**: Validate large object allocation fixes\n- **Concurrency Testing**: Verify async/await implementations under concurrent load\n\n---\n\n## Summary\n\nThis performance analysis identified **X critical**, **Y high**, **Z medium**, and **W low** performance issues across the application stack. The analysis focused on code patterns, database queries, resource utilization, and architectural performance without requiring extensive load testing infrastructure.\n\n**Key Strengths Identified**:\n\n- Good modular architecture with clear separation of concerns\n- Proper use of modern .NET 8 features and Umbraco CMS\n- Well-structured database schema with appropriate relationships\n\n**Critical Areas Requiring Immediate Attention**:\n\n- N+1 query problems causing database performance issues\n- Synchronous operations blocking thread pool resources\n- Missing database indexes for frequently queried data\n- Inefficient memory allocation patterns in data processing\n\n**Expected Overall Performance Improvement**: 70-90% reduction in response times and 40-60% improvement in resource utilization after implementing all recommendations.\n</template>\n\n## Examples\n\n**Example 1: N+1 Query Problem**\n\nBad approach:\n```javascript\nconst orders = await Order.findAll();\nfor (const order of orders) {\n  order.customer = await Customer.findByPk(order.customerId);\n  order.items = await OrderItem.findAll({ where: { orderId: order.id } });\n}\n```\n\nGood approach:\n```javascript\nconst orders = await Order.findAll({\n  include: [\n    { model: Customer },\n    { model: OrderItem }\n  ]\n});\n```\n\n**Example 2: Inefficient Caching**\n\nBad approach:\n```javascript\n// Cache entire dataset, never invalidate\nconst cache = await getCachedData('all-products');\nif (cache) return cache;\nconst products = await Product.findAll();\nawait setCachedData('all-products', products, 86400); // 24 hours\n```\n\nGood approach:\n```javascript\n// Cache with granular keys and appropriate TTL\nconst cacheKey = `products:page:${page}:filter:${filter}`;\nconst cache = await getCachedData(cacheKey);\nif (cache) return cache;\n\nconst products = await Product.findAll({ where: filter, limit: 20, offset: page * 20 });\nawait setCachedData(cacheKey, products, 300); // 5 minutes\n\n// Invalidate on product updates\nawait invalidateCachePattern('products:*');\n```\n\n**Example 3: Unoptimized Asset Loading**\n\nBad approach:\n```html\n<!-- Loading full-size images for all screen sizes -->\n<img src=\"/images/hero-4k.jpg\" alt=\"Hero image\">\n```\n\nGood approach:\n```html\n<!-- Responsive images with lazy loading -->\n<img\n  srcset=\"\n    /images/hero-mobile.jpg 640w,\n    /images/hero-tablet.jpg 1024w,\n    /images/hero-desktop.jpg 1920w\n  \"\n  sizes=\"(max-width: 640px) 640px, (max-width: 1024px) 1024px, 1920px\"\n  src=\"/images/hero-desktop.jpg\"\n  alt=\"Hero image\"\n  loading=\"lazy\"\n>\n```\n\n## Best Practices\n\n1. **Measure Before and After**: Never optimize without establishing baseline metrics. Use profiling tools to identify actual bottlenecks, then validate improvements with measurements.\n\n2. **Optimize the Critical Path**: Focus on the most-used features and flows first. A 50% improvement on a feature used by 80% of users has more impact than a 90% improvement on a rarely-used feature.\n\n3. **Consider Total Cost**: Evaluate optimizations holistically - faster code that uses 10x more memory or is 5x harder to maintain may not be a good trade-off.\n\n4. **Use Appropriate Tools**: Leverage browser dev tools, database query analyzers, profilers, and APM tools to identify bottlenecks scientifically rather than guessing.\n\n5. **Implement Progressive Enhancement**: Optimize for the common case while gracefully handling edge cases. Don't sacrifice reliability for speed.\n\n6. **Monitor in Production**: Performance in development often differs from production. Implement real user monitoring (RUM) to track actual user experience.\n\n7. **Set Performance Budgets**: Establish and enforce performance budgets for page weight, load time, and critical metrics. Prevent performance regression through automated checks.\n\n8. **Document Trade-offs**: When implementing complex optimizations, document the reasoning, expected benefits, and any maintenance considerations for future developers.\n\n## Quality Assurance Checklist\n\nBefore recommending any optimization, verify:\n\n- ‚úì Have baseline metrics been established?\n- ‚úì Does the optimization address a real bottleneck, not premature optimization?\n- ‚úì Will the solution work under production load conditions?\n- ‚úì Have potential bugs or edge cases been considered?\n- ‚úì Is the impact on code readability and maintainability acceptable?\n- ‚úì Can the improvement be validated through testing?\n- ‚úì Are monitoring metrics defined to track ongoing effectiveness?\n\n## Common Performance Anti-Patterns\n\nProactively identify these common issues:\n\n### Database Anti-Patterns\n- N+1 queries (missing eager loading)\n- Missing indexes on filtered/joined columns\n- Using `SELECT *` instead of specific columns\n- Fetching all records without pagination\n- Executing queries in loops\n\n### Frontend Anti-Patterns\n- Loading all JavaScript upfront (no code splitting)\n- Large, unoptimized images\n- Synchronous, render-blocking scripts\n- Excessive re-renders in React (missing memoization)\n- Memory leaks from uncleared intervals/listeners\n\n### Caching Anti-Patterns\n- Caching without invalidation strategy\n- Cache keys too granular (low hit rate)\n- Cache keys too broad (stale data)\n- No cache monitoring\n- Caching entire large datasets\n\n### API Anti-Patterns\n- No rate limiting\n- Returning excessive data (no field filtering)\n- Missing pagination\n- Synchronous processing of async operations\n- No response compression\n\n## Performance Testing Strategies\n\nTo validate performance improvements:\n\n1. **Load Testing**: Simulate concurrent users to identify breaking points\n2. **Profiling**: Use CPU and memory profilers to identify hotspots\n3. **Benchmarking**: Create reproducible performance tests for critical paths\n4. **Real User Monitoring**: Track actual user experience in production\n5. **Synthetic Monitoring**: Automated performance tests from various locations\n\n## Context-Aware Analysis\n\nWhen project-specific context is available in CLAUDE.md files, incorporate:\n\n- **Technology Stack**: Identify framework-specific optimization opportunities\n- **Usage Patterns**: Optimize for actual traffic patterns and user behavior\n- **Infrastructure**: Consider deployment architecture and resource constraints\n- **Performance Requirements**: Align optimizations with business SLAs and budgets\n\n## Communication Guidelines\n\nWhen reporting performance findings:\n- Lead with measured impact (seconds, requests, bytes)\n- Provide concrete code examples showing before/after\n- Explain the \"why\" behind optimizations, not just the \"what\"\n- Set realistic expectations for performance improvements\n- Acknowledge when existing code is already well-optimized\n- Recommend incremental improvements over risky rewrites\n\nRemember: The goal is to make applications measurably faster while maintaining code quality and reliability. Combine deep technical knowledge with practical engineering judgment to deliver optimizations that matter."
              }
            ]
          },
          {
            "name": "ai-plugins",
            "description": "AI-powered plugin and skill development - Intelligent plugin and skill scaffolding and generation tools for Claude Code",
            "source": "./plugins/ai-plugins",
            "category": null,
            "version": "1.2.3",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-plugins@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/plugins-scaffold",
                "description": "AI-powered plugin scaffolding tool that generates a complete Claude Code plugin structure based on user requirements.",
                "path": "plugins/ai-plugins/commands/plugins-scaffold.md",
                "frontmatter": {
                  "name": "plugins-scaffold",
                  "description": "AI-powered plugin scaffolding tool that generates a complete Claude Code plugin structure based on user requirements."
                },
                "content": "# Scaffold Plugin\n\nAI-powered plugin scaffolding tool that generates a complete Claude Code plugin structure based on user requirements.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, plugin names, or paths after this command (e.g., `/plugins-scaffold my-plugin` or `/plugins-scaffold ./plugins`), you MUST COMPLETELY IGNORE them. Do NOT use any plugin names, paths, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive AskUserQuestion tool as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Use the AskUserQuestion tool to collect plugin requirements. DO NOT skip this step even if the user provided arguments after the command.\n\nWhen this command is executed, follow these steps to create a new plugin:\n\n### 1. Gather Plugin Requirements\n\nUse the AskUserQuestion tool to collect the following information:\n\n**Question 1 - Plugin Basics:**\n- header: \"Plugin Info\"\n- question: \"What is the name of your plugin? (use kebab-case, e.g., 'my-awesome-plugin')\"\n- This should be a text input\n\n**Question 2 - Plugin Description:**\n- header: \"Description\"\n- question: \"Provide a brief description of what your plugin does:\"\n- This should be a text input\n\n**Question 3 - Plugin Category:**\n- header: \"Category\"\n- question: \"What category best describes your plugin?\"\n- options:\n  - \"AI & Automation\" - AI-powered tools and automation workflows\n  - \"Productivity\" - Tools that enhance developer productivity\n  - \"Code Quality\" - Testing, linting, and code quality tools\n  - \"DevOps & Deployment\" - CI/CD, deployment, and infrastructure tools\n  - \"Development Tools\" - General development utilities\n  - \"Security\" - Security scanning and compliance tools\n\n**Question 4 - Initial Commands:**\n- header: \"Commands\"\n- question: \"Which commands would you like to include? (You can select multiple)\"\n- multiSelect: true\n- options:\n  - \"Main command\" - A primary command for the plugin's core functionality\n  - \"Helper command\" - A utility or helper command\n  - \"Custom commands\" - I'll specify custom command names\n\n**Question 5 - Additional Features:**\n- header: \"Features\"\n- question: \"Would you like to include any of these additional features?\"\n- multiSelect: true\n- options:\n  - \"README with examples\" - Generate a comprehensive README file\n  - \"LICENSE file\" - Add an MIT license file\n  - \"Test command\" - Include a test/validation command\n\n### 2. Create Plugin Directory Structure\n\nBased on the gathered information, create the following structure:\n\n```\nplugins/{plugin-name}/\n  .claude-plugin/\n    plugin.json\n  commands/\n    {command-name}.md\n  README.md (if selected)\n  LICENSE (if selected)\n```\n\nExecute:\n```bash\nmkdir -p \"plugins/{plugin-name}/.claude-plugin\"\nmkdir -p \"plugins/{plugin-name}/commands\"\n```\n\n### 3. Generate plugin.json\n\nCreate the plugin metadata file with:\n- name: The plugin name provided by the user\n- version: Start at \"1.0.0\"\n- description: The description provided by the user\n- author: Use the marketplace owner information from `.claude-plugin/marketplace.json`\n- repository: Use the same repository as other plugins\n- license: \"MIT\"\n- keywords: Generate relevant keywords based on the plugin name, description, and category\n\n### 4. Generate Commands\n\nFor each command the user wants to create:\n\n1. Ask for the command name (if \"Custom commands\" was selected)\n2. Ask for a brief description of what the command should do\n3. Create a markdown file in the `commands/` directory with:\n   - A clear title (# Command Name)\n   - A description of what the command does\n   - An \"## Instructions\" section with step-by-step guidance for Claude Code\n   - Any important notes or constraints\n\nCommand template:\n```markdown\n# {Command Name}\n\n{Brief description of what this command does}\n\n## Instructions\n\nWhen this command is executed:\n\n1. {Step 1 description}\n2. {Step 2 description}\n3. {Step 3 description}\n...\n\nIMPORTANT: {Any important constraints or requirements}\n```\n\n### 5. Generate README.md (if selected)\n\nCreate a comprehensive README with:\n- Plugin name and description\n- Installation instructions\n- Available commands with examples\n- Usage guidelines\n- Author and license information\n\n### 6. Generate LICENSE (if selected)\n\nCreate an MIT license file with:\n- Current year\n- Author name from marketplace owner\n\n### 7. Register Plugin in Marketplace\n\nRead the `.claude-plugin/marketplace.json` file and add the new plugin to the `plugins` array:\n\n```json\n{\n  \"name\": \"{plugin-name}\",\n  \"source\": \"./plugins/{plugin-name}\",\n  \"description\": \"{plugin-description}\",\n  \"version\": \"1.0.0\",\n  \"keywords\": [...],\n  \"author\": {\n    \"name\": \"{author-name}\",\n    \"url\": \"{author-url}\"\n  },\n  \"repository\": \"{repository-url}\"\n}\n```\n\n### 8. Verify and Report\n\nAfter scaffolding is complete:\n\n1. List all created files\n2. Display the plugin structure\n3. Provide next steps:\n   - Review and customize the generated commands\n   - Test the plugin with Claude Code\n   - Update the README with specific usage examples\n   - Commit the changes\n\n## Important Notes\n\n- Always use kebab-case for plugin names (e.g., \"ai-security\", not \"AiSecurity\")\n- Ensure consistency between the plugin's `plugin.json` and marketplace `marketplace.json` entry\n- Follow the existing plugin patterns in the repository\n- Generate meaningful, actionable commands that provide clear instructions to Claude Code\n- Do NOT include Claude Code attribution or co-author tags in any generated content\n\n## Example Flow\n\n```\nUser runs: /plugins-scaffold\n\n1. Ask questions about the plugin\n2. User answers:\n   - Name: \"code-analyzer\"\n   - Description: \"AI-powered code analysis and insights\"\n   - Category: \"Code Quality\"\n   - Commands: [\"Main command\", \"Custom commands\"]\n   - Features: [\"README with examples\", \"LICENSE file\"]\n\n3. Create directory structure\n4. Generate plugin.json\n5. Ask about custom commands and generate them\n6. Generate README and LICENSE\n7. Register in marketplace.json\n8. Report success with file listing\n```"
              }
            ],
            "skills": [
              {
                "name": "plugins-scaffolding",
                "description": "Guide for creating Claude Code plugins with proper structure, metadata, and components. This skill should be used when creating plugins, writing manifests, or setting up marketplaces.",
                "path": "plugins/ai-plugins/skills/plugins-scaffolding/SKILL.md",
                "frontmatter": {
                  "name": "plugins-scaffolding",
                  "description": "Guide for creating Claude Code plugins with proper structure, metadata, and components. This skill should be used when creating plugins, writing manifests, or setting up marketplaces."
                },
                "content": "# Plugins Scaffold Skill\n\nThis skill provides guidance for creating Claude Code plugins, including structure, manifests, components (commands, agents, skills, hooks, MCP servers), and marketplace distribution.\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating a new Claude Code plugin from scratch\n- Understanding plugin architecture and components\n- Writing plugin.json manifests\n- Creating plugin commands, agents, skills, hooks, or MCP servers\n- Setting up plugin marketplaces\n- Distributing plugins to teams or the community\n- Validating and testing plugins before distribution\n- Understanding plugin vs marketplace structure\n\n## Plugin Architecture Overview\n\n### What Are Plugins?\n\nPlugins are extensions that add custom functionality to Claude Code, shareable across projects and teams. They can include:\n\n- **Commands**: Custom slash commands for interactive workflows\n- **Agents**: Specialized Claude instances with specific capabilities\n- **Skills**: Just-in-time expertise that Claude autonomously invokes\n- **Hooks**: Event handlers for automation and workflow customization\n- **MCP Servers**: External tool integrations via Model Context Protocol\n\n### Plugin vs Marketplace\n\n**Plugin:**\n- A single package of functionality (one plugin = one purpose)\n- Contains commands, agents, skills, hooks, or MCP servers\n- Has a `.claude-plugin/plugin.json` manifest\n- Can be distributed via marketplaces or standalone\n\n**Marketplace:**\n- A catalog of multiple plugins\n- Has a `.claude-plugin/marketplace.json` manifest\n- Enables centralized discovery and installation\n- Can host plugins from multiple sources (local paths, GitHub repos, git URLs)\n\n## Plugin Directory Structure\n\nEvery plugin must follow this standard structure:\n\n```\nplugin-name/\n‚îú‚îÄ‚îÄ .claude-plugin/\n‚îÇ   ‚îî‚îÄ‚îÄ plugin.json          # Required: Plugin manifest\n‚îú‚îÄ‚îÄ commands/                # Optional: Slash commands\n‚îÇ   ‚îú‚îÄ‚îÄ command-one.md\n‚îÇ   ‚îî‚îÄ‚îÄ command-two.md\n‚îú‚îÄ‚îÄ agents/                  # Optional: Custom agents\n‚îÇ   ‚îî‚îÄ‚îÄ agent-name.md\n‚îú‚îÄ‚îÄ skills/                  # Optional: Agent skills\n‚îÇ   ‚îú‚îÄ‚îÄ skill-one/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md\n‚îÇ   ‚îî‚îÄ‚îÄ skill-two/\n‚îÇ       ‚îî‚îÄ‚îÄ SKILL.md\n‚îú‚îÄ‚îÄ hooks/                   # Optional: Event handlers\n‚îÇ   ‚îî‚îÄ‚îÄ hooks.json\n‚îú‚îÄ‚îÄ .mcp.json               # Optional: MCP server config\n‚îú‚îÄ‚îÄ scripts/                # Optional: Utility scripts\n‚îú‚îÄ‚îÄ README.md               # Recommended: Documentation\n‚îî‚îÄ‚îÄ LICENSE                 # Recommended: License file\n```\n\n**Critical Requirements:**\n- The `.claude-plugin/plugin.json` file is REQUIRED for all plugins\n- All component directories (commands, agents, skills, hooks) must exist at plugin root, NOT within `.claude-plugin/`\n- Component directories are optional - only create what your plugin needs\n- Use kebab-case for plugin directory names (e.g., `my-plugin`, not `MyPlugin` or `my_plugin`)\n\n## Plugin Manifest (plugin.json)\n\nThe `plugin.json` file is your plugin's core configuration. It must be located at `.claude-plugin/plugin.json`.\n\n### Required Fields\n\n```json\n{\n  \"name\": \"plugin-name\"\n}\n```\n\n**Field Specifications:**\n\n- **name** (required)\n  - Unique identifier in kebab-case format\n  - Examples: `\"deployment-tools\"`, `\"ai-security\"`, `\"git-helpers\"`\n  - Should be descriptive and match the plugin directory name\n  - Must be unique within a marketplace\n\n### Recommended Metadata Fields\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Brief explanation of what this plugin does\",\n  \"author\": {\n    \"name\": \"Author Name\",\n    \"email\": \"author@example.com\",\n    \"url\": \"https://example.com\"\n  },\n  \"homepage\": \"https://github.com/owner/plugin-repo\",\n  \"repository\": \"https://github.com/owner/plugin-repo\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]\n}\n```\n\n**Field Specifications:**\n\n- **version** (recommended)\n  - Use semantic versioning: MAJOR.MINOR.PATCH\n  - Example: `\"2.1.0\"`\n  - See Versioning section below for details\n\n- **description** (recommended)\n  - Brief explanation of plugin purpose\n  - Should clearly state what the plugin does\n  - Keep under 200 characters for marketplace display\n\n- **author** (recommended)\n  - Object containing name, email (optional), and URL (optional)\n  - Helps users know who maintains the plugin\n\n- **homepage** (recommended)\n  - URL to plugin documentation\n  - Often same as repository URL\n\n- **repository** (recommended)\n  - Source code repository link\n  - Enables users to view source and report issues\n\n- **license** (recommended)\n  - SPDX license identifier (e.g., `\"MIT\"`, `\"Apache-2.0\"`, `\"GPL-3.0\"`)\n  - Critical for open source distribution\n\n- **keywords** (recommended)\n  - Array of tags for discovery\n  - Examples: `[\"git\", \"automation\", \"security\", \"devops\"]`\n  - Helps users find your plugin in marketplaces\n\n### Custom Component Paths (Advanced)\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"commands\": \"./custom-commands\",\n  \"agents\": \"./custom-agents/agent.md\",\n  \"hooks\": \"./custom-hooks/hooks.json\",\n  \"mcpServers\": \"./.mcp.json\"\n}\n```\n\n**Path Configuration Rules:**\n- All paths must be relative to plugin root and begin with `./`\n- Custom paths supplement (not replace) default directories\n- Use `${CLAUDE_PLUGIN_ROOT}` environment variable for absolute path references in hooks and MCP configs\n\n**When to Use Custom Paths:**\n- Organizing complex plugins with non-standard layouts\n- Migrating existing projects to plugin format\n- Keeping components in specific directories for workflow reasons\n\n## Plugin Components\n\n### Commands (Slash Commands)\n\nCommands are markdown files in the `commands/` directory that define interactive workflows.\n\n**File Structure:**\n```\ncommands/\n‚îú‚îÄ‚îÄ setup-project.md\n‚îî‚îÄ‚îÄ deploy-staging.md\n```\n\n**Command File Format:**\n```markdown\n# Command Title\n\nBrief description of what this command does.\n\n## Instructions\n\nStep-by-step instructions for Claude Code to execute when this command is invoked.\n\n1. First step\n2. Second step\n3. Third step\n\n## Important Notes\n\nAny constraints, requirements, or special considerations.\n```\n\n**Best Practices:**\n- Use clear, imperative instructions\n- Specify what NOT to do (constraints)\n- Include examples when helpful\n- Keep commands focused on one task\n- Use commands for interactive setup and configuration\n\n**When to Use Commands vs Skills:**\n- Commands: One-time interactive setup, configuration, scaffolding\n- Skills: Ongoing expertise that applies across multiple sessions\n\n### Agents (Custom Agents)\n\nAgents are markdown files in the `agents/` directory that describe specialized Claude instances.\n\n**File Structure:**\n```\nagents/\n‚îî‚îÄ‚îÄ security-auditor.md\n```\n\n**Agent File Format:**\n```markdown\n---\ndescription: Specialized agent for security auditing and vulnerability detection\n---\n\n# Security Auditor Agent\n\nThis agent specializes in identifying security vulnerabilities, reviewing authentication mechanisms, and conducting security audits.\n\n## Capabilities\n\n- Identify SQL injection vulnerabilities\n- Review authentication and authorization flows\n- Validate input sanitization\n- Assess data protection measures\n- Generate security audit reports\n\n## When to Invoke\n\nUse this agent when:\n- Implementing authentication flows\n- Reviewing security-sensitive code\n- Conducting pre-deployment security audits\n```\n\n**Best Practices:**\n- Clearly define the agent's specialization\n- List specific capabilities the agent provides\n- Specify when the agent should be invoked\n- Use agents for complex, multi-step specialized tasks\n\n### Skills (Agent Skills)\n\nSkills are directories in the `skills/` folder containing `SKILL.md` files that provide just-in-time expertise.\n\n**File Structure:**\n```\nskills/\n‚îú‚îÄ‚îÄ brand-guidelines/\n‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md\n‚îî‚îÄ‚îÄ security-standards/\n    ‚îú‚îÄ‚îÄ SKILL.md\n    ‚îî‚îÄ‚îÄ references/\n        ‚îî‚îÄ‚îÄ standards.md\n```\n\n**SKILL.md Format:**\n```markdown\n---\nname: Skill Name\ndescription: Guide for [topic]. This skill should be used when [specific use cases] (max 200 chars)\n---\n\n# Skill Name Skill\n\nThis skill provides guidance on [topic].\n\n## When to Use This Skill\n\nThis skill should be used when:\n- [Use case 1]\n- [Use case 2]\n\n## Guidelines\n\n[Core expertise and instructions]\n```\n\n**Best Practices:**\n- See the `skills-scaffold` skill for comprehensive skill creation guidance\n- Use skills for ongoing expertise, not one-time setup\n- Write discoverable descriptions with keywords using third-person form\n- Keep skills focused on one domain\n- Use progressive disclosure (core content in SKILL.md, details in references/ directory)\n\n### Hooks (Event Handlers)\n\nHooks are JSON configurations in `hooks/hooks.json` that execute in response to events.\n\n**File Location:**\n```\nhooks/\n‚îî‚îÄ‚îÄ hooks.json\n```\n\n**Hook Configuration Format:**\n```json\n{\n  \"hooks\": [\n    {\n      \"name\": \"pre-commit-check\",\n      \"event\": \"PreToolUse\",\n      \"tool\": \"Bash\",\n      \"script\": \"${CLAUDE_PLUGIN_ROOT}/scripts/pre-commit.sh\",\n      \"blockOnNonZeroExit\": true\n    },\n    {\n      \"name\": \"session-setup\",\n      \"event\": \"SessionStart\",\n      \"script\": \"${CLAUDE_PLUGIN_ROOT}/scripts/setup.sh\"\n    }\n  ]\n}\n```\n\n**Event Types:**\n- `PreToolUse`: Before a tool is executed\n- `PostToolUse`: After a tool completes\n- `UserPromptSubmit`: When user submits a prompt\n- `Notification`: When a notification is triggered\n- `Stop`: When execution stops\n- `SessionStart`: When a new session begins\n\n**Best Practices:**\n- Use `${CLAUDE_PLUGIN_ROOT}` for script paths\n- Set `blockOnNonZeroExit: true` to halt execution on errors\n- Keep hook scripts fast to avoid workflow delays\n- Use hooks for automation, validation, and enforcement\n\n### MCP Servers (External Tool Integration)\n\nMCP servers integrate external tools via the Model Context Protocol.\n\n**File Location:**\n```\n.mcp.json\n```\n\n**MCP Configuration Format:**\n```json\n{\n  \"mcpServers\": {\n    \"server-name\": {\n      \"command\": \"node\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/mcp-server/index.js\"],\n      \"env\": {\n        \"API_KEY\": \"${API_KEY}\"\n      }\n    }\n  }\n}\n```\n\n**Best Practices:**\n- Use `${CLAUDE_PLUGIN_ROOT}` for script paths\n- Document required environment variables\n- Provide clear setup instructions in README.md\n- Test MCP server functionality independently\n\n## Plugin Development Workflow\n\n### Step 1: Plan the Plugin\n\nBefore creating a plugin, determine:\n\n- **Purpose**: What problem does this plugin solve?\n- **Components**: What components does it need?\n  - Commands for interactive workflows?\n  - Agents for specialized tasks?\n  - Skills for ongoing expertise?\n  - Hooks for automation?\n  - MCP servers for external tools?\n- **Scope**: Is this one plugin or should it be split?\n- **Distribution**: Will this be private (team) or public (community)?\n\n**Design Principle:** One plugin = one purpose. When solving multiple unrelated problems, create multiple plugins.\n\n### Step 2: Create Directory Structure\n\n```bash\nmkdir -p plugin-name/.claude-plugin\nmkdir -p plugin-name/commands    # If needed\nmkdir -p plugin-name/agents      # If needed\nmkdir -p plugin-name/skills      # If needed\nmkdir -p plugin-name/hooks       # If needed\nmkdir -p plugin-name/scripts     # If needed\n```\n\n### Step 3: Write Plugin Manifest\n\nCreate `.claude-plugin/plugin.json`:\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Brief description of plugin purpose\",\n  \"author\": {\n    \"name\": \"Your Name\",\n    \"url\": \"https://yoursite.com\"\n  },\n  \"repository\": \"https://github.com/owner/plugin-repo\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"keyword1\", \"keyword2\"]\n}\n```\n\n### Step 4: Create Plugin Components\n\nAdd the components your plugin needs:\n\n**For Commands:**\n- Create markdown files in `commands/` directory\n- Use clear, imperative instructions\n- Specify constraints and requirements\n\n**For Agents:**\n- Create markdown files in `agents/` directory\n- Define specialization and capabilities\n- Specify invocation criteria\n\n**For Skills:**\n- Create `skills/{skill-name}/SKILL.md` with YAML frontmatter\n- Follow the `skills-scaffold` skill guidance\n- Use progressive disclosure for token efficiency\n\n**For Hooks:**\n- Create `hooks/hooks.json` configuration\n- Write hook scripts in `scripts/` directory\n- Use `${CLAUDE_PLUGIN_ROOT}` for paths\n\n**For MCP Servers:**\n- Create `.mcp.json` configuration\n- Implement MCP server according to protocol spec\n- Document setup and environment variables\n\n### Step 5: Add Documentation\n\nCreate a comprehensive README.md:\n\n```markdown\n# Plugin Name\n\nBrief description of what this plugin does.\n\n## Features\n\n- Feature 1\n- Feature 2\n\n## Installation\n\n\\`\\`\\`bash\n/plugin marketplace add owner/repo\n/plugin install plugin-name@marketplace-name\n\\`\\`\\`\n\n## Usage\n\n### Commands\n\n- \\`/command-name\\`: Description of what it does\n\n### Skills\n\n- \\`skill-name\\`: Description of expertise provided\n\n## Configuration\n\nAny required setup or environment variables.\n\n## License\n\nLicense information.\n```\n\n### Step 6: Validate and Test\n\nBefore distribution:\n\n1. **Validate JSON syntax**\n   ```bash\n   # Check plugin.json is valid JSON\n   cat .claude-plugin/plugin.json | jq .\n   ```\n\n2. **Test locally**\n   ```bash\n   # Add as local marketplace\n   /plugin marketplace add ./path/to/plugin-parent-directory\n\n   # Install the plugin\n   /plugin install plugin-name@marketplace-name\n   ```\n\n3. **Test all components**\n   - Invoke each command and verify it works\n   - Test agents by requesting their specialized tasks\n   - Verify skills load when expected\n   - Check hooks execute at correct events\n   - Test MCP server integration\n\n4. **Review security**\n   - Audit all scripts and code\n   - Check for hardcoded credentials\n   - Document required environment variables\n   - Ensure no sensitive data in repository\n\n### Step 7: Distribute via Marketplace\n\nSee Marketplace Distribution section below.\n\n## Plugin Versioning\n\nFollow [Semantic Versioning](https://semver.org/spec/v2.0.0.html):\n\n- **MAJOR** (x.0.0): Breaking changes or incompatible API changes\n- **MINOR** (0.x.0): New features added in a backward-compatible manner\n- **PATCH** (0.0.x): Backward-compatible bug fixes\n\n**When to Bump Version:**\n\n- **MAJOR**: Changing command names, removing components, changing behavior in incompatible ways\n- **MINOR**: Adding new commands, agents, skills; enhancing existing features\n- **PATCH**: Fixing bugs, typos, documentation; minor improvements\n\n**Version Update Workflow:**\n\n1. Update version in `.claude-plugin/plugin.json`\n2. Update version in marketplace.json (if applicable)\n3. Update CHANGELOG.md with changes\n4. Update README.md if functionality changed\n5. Create git tag for the release (e.g., `v1.2.0`)\n\n## Marketplace Distribution\n\n### Creating a Plugin Marketplace\n\nA marketplace is a repository that catalogs multiple plugins.\n\n**Directory Structure:**\n```\nmarketplace-repo/\n‚îú‚îÄ‚îÄ .claude-plugin/\n‚îÇ   ‚îî‚îÄ‚îÄ marketplace.json\n‚îú‚îÄ‚îÄ plugins/                    # If using local plugins\n‚îÇ   ‚îú‚îÄ‚îÄ plugin-one/\n‚îÇ   ‚îî‚îÄ‚îÄ plugin-two/\n‚îî‚îÄ‚îÄ README.md\n```\n\n**Marketplace Manifest (.claude-plugin/marketplace.json):**\n```json\n{\n  \"name\": \"marketplace-name\",\n  \"owner\": {\n    \"name\": \"Your Name\",\n    \"email\": \"you@example.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Brief description of this marketplace\",\n    \"version\": \"1.0.0\",\n    \"pluginRoot\": \"./plugins\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"plugin-one\",\n      \"source\": \"./plugins/plugin-one\",\n      \"description\": \"What plugin-one does\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Author Name\",\n        \"url\": \"https://example.com\"\n      },\n      \"repository\": \"https://github.com/owner/plugin-one\",\n      \"license\": \"MIT\",\n      \"keywords\": [\"keyword1\", \"keyword2\"]\n    }\n  ]\n}\n```\n\n**Required Fields:**\n- `name`: Unique marketplace identifier (kebab-case)\n- `owner`: Maintainer information with name and email\n- `plugins`: Array of plugin entries\n\n**Optional Metadata:**\n- `metadata.description`: Marketplace overview\n- `metadata.version`: Marketplace version\n- `metadata.pluginRoot`: Base path for relative plugin sources (e.g., `\"./plugins\"`)\n\n### Plugin Source Types\n\n**Relative Paths** (same repository):\n```json\n{\n  \"name\": \"my-plugin\",\n  \"source\": \"./plugins/my-plugin\"\n}\n```\n- Best for: Curated marketplaces with bundled plugins\n- The `pluginRoot` metadata field sets the base directory\n\n**GitHub Repositories:**\n```json\n{\n  \"name\": \"github-plugin\",\n  \"source\": {\n    \"source\": \"github\",\n    \"repo\": \"owner/plugin-repo\"\n  }\n}\n```\n- Best for: Distributed development, individual plugin repositories\n- Supports both public and private repositories\n\n**Git Repositories:**\n```json\n{\n  \"name\": \"git-plugin\",\n  \"source\": {\n    \"source\": \"url\",\n    \"url\": \"https://gitlab.com/team/plugin.git\"\n  }\n}\n```\n- Best for: GitLab, Bitbucket, or self-hosted git servers\n- Works with any git-compatible URL\n\n### Distribution Methods\n\n**GitHub (Recommended):**\n\n1. Create a repository with `.claude-plugin/marketplace.json` at root\n2. Add plugins either:\n   - As subdirectories (with `pluginRoot`)\n   - As external GitHub repositories (with `source` objects)\n3. Users add the marketplace:\n   ```bash\n   /plugin marketplace add owner/repo\n   ```\n\n**Other Git Services:**\n```bash\n/plugin marketplace add https://gitlab.com/company/plugins.git\n```\n\n**Local Development:**\n```bash\n/plugin marketplace add ./my-local-marketplace\n```\n\n### Marketplace Operations\n\n**List configured marketplaces:**\n```bash\n/plugin marketplace list\n```\n\n**Update marketplace metadata:**\n```bash\n/plugin marketplace update marketplace-name\n```\n\n**Remove a marketplace:**\n```bash\n/plugin marketplace remove marketplace-name\n```\n\n**Install plugins:**\n```bash\n/plugin install plugin-name@marketplace-name\n```\n\n### Team Configuration\n\nConfigure `.claude/settings.json` in repositories to auto-install marketplaces:\n\n```json\n{\n  \"extraKnownMarketplaces\": {\n    \"team-tools\": {\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"your-org/claude-plugins\"\n      }\n    }\n  }\n}\n```\n\nWhen team members trust the folder, configured marketplaces install automatically.\n\n## Common Plugin Patterns\n\n### Pattern: Developer Productivity Plugin\n\n**Use Case:** Streamline common development tasks (git, deployments, testing)\n\n**Structure:**\n- Multiple commands for different workflows\n- Hooks for automation (pre-commit, pre-push)\n- Skills for best practices\n\n**Example:**\n```\ngit-helpers/\n‚îú‚îÄ‚îÄ .claude-plugin/plugin.json\n‚îú‚îÄ‚îÄ commands/\n‚îÇ   ‚îú‚îÄ‚îÄ commit-push.md\n‚îÇ   ‚îî‚îÄ‚îÄ setup-repo.md\n‚îú‚îÄ‚îÄ hooks/\n‚îÇ   ‚îî‚îÄ‚îÄ hooks.json\n‚îî‚îÄ‚îÄ scripts/\n    ‚îî‚îÄ‚îÄ pre-commit.sh\n```\n\n### Pattern: Domain Expertise Plugin\n\n**Use Case:** Provide specialized knowledge (security, performance, architecture)\n\n**Structure:**\n- Agents for specialized tasks\n- Skills for ongoing guidance\n- Commands for audits and reports\n\n**Example:**\n```\nsecurity-expert/\n‚îú‚îÄ‚îÄ .claude-plugin/plugin.json\n‚îú‚îÄ‚îÄ agents/\n‚îÇ   ‚îî‚îÄ‚îÄ security-auditor.md\n‚îú‚îÄ‚îÄ skills/\n‚îÇ   ‚îú‚îÄ‚îÄ security-standards/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md\n‚îÇ   ‚îî‚îÄ‚îÄ owasp-guidelines/\n‚îÇ       ‚îî‚îÄ‚îÄ SKILL.md\n‚îî‚îÄ‚îÄ commands/\n    ‚îî‚îÄ‚îÄ security-audit.md\n```\n\n### Pattern: External Tool Integration Plugin\n\n**Use Case:** Integrate external services (Azure DevOps, Jira, Slack)\n\n**Structure:**\n- MCP server for API integration\n- Skills for tool usage guidelines\n- Commands for configuration\n\n**Example:**\n```\nado-integration/\n‚îú‚îÄ‚îÄ .claude-plugin/plugin.json\n‚îú‚îÄ‚îÄ .mcp.json\n‚îú‚îÄ‚îÄ commands/\n‚îÇ   ‚îî‚îÄ‚îÄ ado-init.md\n‚îú‚îÄ‚îÄ skills/\n‚îÇ   ‚îî‚îÄ‚îÄ ado-work-items/\n‚îÇ       ‚îî‚îÄ‚îÄ SKILL.md\n‚îî‚îÄ‚îÄ mcp-server/\n    ‚îî‚îÄ‚îÄ index.js\n```\n\n### Pattern: Project Scaffolding Plugin\n\n**Use Case:** Generate boilerplate code and project structure\n\n**Structure:**\n- Commands for interactive scaffolding\n- Templates in supporting files\n- Skills for architecture guidance\n\n**Example:**\n```\nproject-scaffold/\n‚îú‚îÄ‚îÄ .claude-plugin/plugin.json\n‚îú‚îÄ‚îÄ commands/\n‚îÇ   ‚îú‚îÄ‚îÄ create-react-app.md\n‚îÇ   ‚îî‚îÄ‚îÄ create-api.md\n‚îú‚îÄ‚îÄ skills/\n‚îÇ   ‚îî‚îÄ‚îÄ architecture-patterns/\n‚îÇ       ‚îî‚îÄ‚îÄ SKILL.md\n‚îî‚îÄ‚îÄ templates/\n    ‚îú‚îÄ‚îÄ react-component.tsx\n    ‚îî‚îÄ‚îÄ api-endpoint.ts\n```\n\n## Best Practices for Plugin Development\n\n### 1. Keep Plugins Focused\n\n- One plugin = one purpose or domain\n- Create multiple small plugins rather than one mega-plugin\n- Avoid creating plugins that try to do everything\n\n**Good Examples:**\n- `git-helpers` (git automation)\n- `security-auditor` (security scanning)\n- `deployment-tools` (deployment workflows)\n\n**Bad Example:**\n- `developer-tools` (git + security + deployment + testing + ...)\n\n### 2. Use Appropriate Components\n\n- Commands for interactive setup and configuration\n- Skills for ongoing expertise and guidelines\n- Agents for complex specialized tasks\n- Hooks for automation and enforcement\n- MCP servers for external tool integration\n\n**Avoid:**\n- Using commands for ongoing expertise (use skills instead)\n- Using skills for one-time setup (use commands instead)\n- Duplicating functionality across components\n\n### 3. Write Clear Documentation\n\n- Create comprehensive README.md with installation and usage instructions\n- Provide examples for all commands and features\n- Document required environment variables\n- Include troubleshooting section\n\n### 4. Follow Semantic Versioning\n\n- Use MAJOR.MINOR.PATCH format\n- Bump versions appropriately based on changes\n- Document changes in CHANGELOG.md\n- Create git tags for releases\n\n### 5. Test Thoroughly\n\n- Test locally before distribution\n- Validate JSON manifests\n- Test all commands, skills, agents\n- Verify hooks execute correctly\n- Test MCP server integration\n\n### 6. Security Considerations\n\n- Audit all scripts and code\n- Never hardcode credentials\n- Use environment variables for secrets\n- Document security requirements\n- Avoid bundling unvetted third-party code\n- Avoid including sensitive organizational data\n\n### 7. Use Consistent Naming\n\n- Plugin names: kebab-case (`my-plugin`)\n- Command files: kebab-case (`my-command.md`)\n- Skill directories: kebab-case (`my-skill/`)\n- Use descriptive names that indicate purpose\n\n### 8. Leverage Environment Variables\n\n- Use `${CLAUDE_PLUGIN_ROOT}` in hooks and MCP configs\n- Document required environment variables\n- Provide examples for configuration\n- Use `.env.example` files for templates\n\n### 9. Organize Supporting Files\n\n```\nplugin-name/\n‚îú‚îÄ‚îÄ scripts/        # Executable scripts for hooks/automation\n‚îú‚îÄ‚îÄ templates/      # Template files for scaffolding\n‚îú‚îÄ‚îÄ examples/       # Example configurations\n‚îî‚îÄ‚îÄ docs/          # Additional documentation\n```\n\n### 10. Provide Examples\n\n- Include example usage in README.md\n- Show before/after for commands\n- Demonstrate integration patterns\n- Provide sample configurations\n\n## Plugin Validation Checklist\n\nBefore distributing a plugin, verify:\n\n**Structure:**\n- [ ] `.claude-plugin/plugin.json` exists with required fields\n- [ ] Component directories at plugin root (not in `.claude-plugin/`)\n- [ ] kebab-case naming for plugin and components\n- [ ] README.md with installation and usage instructions\n\n**Manifest:**\n- [ ] Name is unique and descriptive\n- [ ] Version follows semantic versioning\n- [ ] Description clearly states plugin purpose\n- [ ] Author information included\n- [ ] Repository URL provided\n- [ ] License specified\n- [ ] Keywords for discoverability\n\n**Components:**\n- [ ] All commands tested and working\n- [ ] All agents tested with appropriate tasks\n- [ ] All skills have proper YAML frontmatter\n- [ ] All hooks execute at correct events\n- [ ] All MCP servers integrate correctly\n\n**Documentation:**\n- [ ] README.md is comprehensive\n- [ ] All features documented with examples\n- [ ] Environment variables documented\n- [ ] Installation instructions clear\n- [ ] Troubleshooting section included\n\n**Quality:**\n- [ ] JSON manifests are valid (test with `jq`)\n- [ ] No hardcoded credentials or secrets\n- [ ] All scripts audited for security\n- [ ] Plugin tested locally before distribution\n- [ ] CHANGELOG.md documents changes\n\n**Marketplace (if applicable):**\n- [ ] Plugin entry in marketplace.json\n- [ ] Source path/URL is correct\n- [ ] Marketplace metadata updated\n- [ ] Version numbers consistent across files\n\n## Troubleshooting Plugin Development\n\n### Problem: Plugin Not Loading\n\n**Possible Causes:**\n- Missing `.claude-plugin/plugin.json`\n- Invalid JSON in plugin.json\n- Wrong directory structure\n- Components in `.claude-plugin/` instead of plugin root\n\n**Solution:**\n- Verify plugin.json exists at `.claude-plugin/plugin.json`\n- Validate JSON syntax: `cat .claude-plugin/plugin.json | jq .`\n- Check component directories are at plugin root\n- Review directory structure against standards\n\n### Problem: Commands Not Appearing\n\n**Possible Causes:**\n- Commands directory in wrong location\n- Command files not markdown (.md)\n- Custom commands path misconfigured\n\n**Solution:**\n- Place commands in `commands/` directory at plugin root\n- Ensure all command files end with `.md`\n- If using custom path, verify it starts with `./`\n\n### Problem: Skills Not Loading\n\n**Possible Causes:**\n- Missing `SKILL.md` file (case-sensitive)\n- Missing YAML frontmatter\n- Description too vague for Claude to match\n\n**Solution:**\n- Verify each skill directory has `SKILL.md` (uppercase)\n- Ensure YAML frontmatter with name and description\n- Make description specific with relevant keywords\n- See `skills-scaffold` skill for details\n\n### Problem: Hooks Not Executing\n\n**Possible Causes:**\n- Wrong path to hook script\n- Script not executable\n- Missing `${CLAUDE_PLUGIN_ROOT}` environment variable\n\n**Solution:**\n- Use `${CLAUDE_PLUGIN_ROOT}` for all script paths\n- Make scripts executable: `chmod +x scripts/*.sh`\n- Test hook scripts independently first\n\n### Problem: MCP Server Not Connecting\n\n**Possible Causes:**\n- Wrong command or args in .mcp.json\n- Missing environment variables\n- Server code has errors\n\n**Solution:**\n- Verify command and args in .mcp.json\n- Document and provide required environment variables\n- Test MCP server independently\n- Check server logs for errors\n\n### Problem: Marketplace Not Installing Plugin\n\n**Possible Causes:**\n- Wrong plugin source path/URL\n- Repository not accessible\n- Plugin directory doesn't contain plugin.json\n- Network connectivity issues\n\n**Solution:**\n- Verify source path is correct (relative or URL)\n- Check repository is public or credentials configured\n- Ensure plugin.json exists in plugin directory\n- Test repository access manually\n\n## Advanced Topics\n\n### Plugin Composition\n\nPlugins can reference each other's capabilities:\n\n```markdown\nFor git automation, the git-helpers plugin provides comprehensive commands.\n\nFor security standards, refer to the security-expert plugin's skills.\n```\n\n**Best Practice:** Keep plugins independent where possible, but document complementary plugins in README.md.\n\n### Multi-Language Support\n\nPlugins can include scripts in different languages:\n\n```\nscripts/\n‚îú‚îÄ‚îÄ python/\n‚îÇ   ‚îî‚îÄ‚îÄ analyzer.py\n‚îú‚îÄ‚îÄ javascript/\n‚îÇ   ‚îî‚îÄ‚îÄ formatter.js\n‚îî‚îÄ‚îÄ shell/\n    ‚îî‚îÄ‚îÄ deploy.sh\n```\n\n**Best Practice:** Document runtime requirements (Python version, Node version) in README.md and plugin.json dependencies field.\n\n### Plugin Templates and Generators\n\nCreate meta-plugins that generate other plugins:\n\n**Example:** The `ai-plugins` plugin includes:\n- `/plugins-scaffold` command for generating plugin structure\n- `plugins-scaffold` skill for plugin development guidance\n- `skills-scaffold` skill for skill creation guidance\n\n### Environment-Specific Configuration\n\nUse environment variables for configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"api-service\": {\n      \"command\": \"node\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/server.js\"],\n      \"env\": {\n        \"API_URL\": \"${API_URL}\",\n        \"API_KEY\": \"${API_KEY}\",\n        \"ENVIRONMENT\": \"${ENVIRONMENT:-development}\"\n      }\n    }\n  }\n}\n```\n\n**Best Practice:** Provide `.env.example` file with required variables.\n\n## Summary\n\nCreating effective Claude Code plugins requires:\n\n1. **Planning**: Determine purpose, components, and scope\n2. **Structure**: Follow standard directory layout\n3. **Manifest**: Write comprehensive plugin.json metadata\n4. **Components**: Use appropriate component types for tasks\n5. **Documentation**: Provide clear README with examples\n6. **Testing**: Validate thoroughly before distribution\n7. **Security**: Audit code and avoid hardcoded secrets\n8. **Versioning**: Follow semantic versioning\n9. **Distribution**: Share via marketplaces for easy discovery\n\nFollowing these guidelines will result in well-structured plugins that enhance Claude Code's capabilities and provide value to users.\n\nFor skill creation specifically, the `skills-scaffold` skill provides detailed guidance."
              },
              {
                "name": "skills-scaffolding",
                "description": "Guide for creating effective Claude Code skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
                "path": "plugins/ai-plugins/skills/skills-scaffolding/SKILL.md",
                "frontmatter": {
                  "name": "skills-scaffolding",
                  "description": "Guide for creating effective Claude Code skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations."
                },
                "content": "# Skills Scaffold Skill\n\nThis skill provides guidance for creating effective Claude Code skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing specialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific domains or tasks‚Äîthey transform Claude from a general-purpose agent into a specialized agent equipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## When to Use This Skill\n\nThis skill should be used when:\n- Creating a new Claude Code skill from scratch\n- Updating an existing skill to improve effectiveness\n- Structuring skill directories and files\n- Writing YAML frontmatter for skills\n- Organizing bundled resources (scripts, references, assets)\n- Understanding progressive disclosure patterns\n- Determining if a skill is the right solution vs a slash command\n\n## Skills vs Commands\n\n### Skills\n- **Purpose:** Provide just-in-time expert guidance for specialized, repeatable tasks\n- **Activation:** Automatically loaded when Claude detects relevant context\n- **Token Efficiency:** Uses progressive disclosure - only metadata loaded initially\n- **Scope:** Domain-specific procedural knowledge (e.g., brand guidelines, work item creation)\n- **Location:** `skills/{skill-name}/SKILL.md` directory\n- **Best For:** Ongoing expertise that applies across multiple sessions\n\n### Slash Commands\n- **Purpose:** Execute one-time setup or configuration tasks\n- **Activation:** Explicitly invoked by user with `/command-name`\n- **Token Efficiency:** Full command loaded when invoked\n- **Scope:** Interactive workflows with user input (e.g., initialization, configuration)\n- **Location:** `commands/{command-name}.md` file\n- **Best For:** Setup tasks, scaffolding, project initialization\n\n**Decision Guideline:** Use a skill for providing ongoing expertise or guidelines. Use a command for one-time interactive setup.\n\n## Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n‚îú‚îÄ‚îÄ SKILL.md (required)\n‚îÇ   ‚îú‚îÄ‚îÄ YAML frontmatter metadata (required)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ name: (required)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ description: (required)\n‚îÇ   ‚îî‚îÄ‚îÄ Markdown instructions (required)\n‚îî‚îÄ‚îÄ Bundled Resources (optional)\n    ‚îú‚îÄ‚îÄ scripts/          - Executable code (Python/Bash/etc.)\n    ‚îú‚îÄ‚îÄ references/       - Documentation loaded into context as needed\n    ‚îî‚îÄ‚îÄ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n**Critical Requirements:**\n- The skill directory must contain a `SKILL.md` file (case-sensitive)\n- The `SKILL.md` file must begin with YAML frontmatter containing `name` and `description`\n- Bundled resources are optional but should be organized by type\n\n### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use third-person form (e.g., \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n### Bundled Resources (optional)\n\n#### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n#### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/api_docs.md` for API specifications, `references/policies.md` for company policies\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill‚Äîthis keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n#### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n## YAML Frontmatter Specifications\n\nThe `SKILL.md` file must begin with YAML frontmatter containing required and optional fields:\n\n### Required Fields\n\n```yaml\n---\nname: Skill Name Here\ndescription: Clear explanation of what this skill does and when to use it\n---\n```\n\n**Field Specifications:**\n\n- **name** (required, max 64 characters)\n  - Human-friendly identifier for the skill\n  - Use title case (e.g., \"Azure DevOps Work Items\")\n  - Should clearly indicate the skill's purpose\n  - Examples: \"Brand Guidelines\", \"PDF Creator\", \"Excel Analyzer\"\n\n- **description** (required, max 200 characters)\n  - **CRITICAL:** Claude uses this to determine when to invoke the skill\n  - Should clearly state what the skill does AND when to use it\n  - Include relevant keywords that Claude can match against user requests\n  - Use third-person form (e.g., \"This skill should be used when...\" instead of \"Use this skill when...\")\n  - Be specific about the context where this skill applies\n\n**Good Description Examples:**\n```yaml\ndescription: Guide for creating and managing Azure DevOps work items (Features, User Stories, Tasks) using proper hierarchy, naming conventions, and formatting. This skill should be used when creating ADO work items.\n```\n\n```yaml\ndescription: Guide for applying company brand guidelines to documents. This skill should be used when ensuring consistent colors, fonts, logos, and tone across marketing materials.\n```\n\n**Bad Description Examples:**\n```yaml\ndescription: Helps with Azure DevOps  # Too vague, doesn't specify what it helps with\n```\n\n```yaml\ndescription: Work items  # Too short, no context, no third-person form\n```\n\n### Optional Fields\n\n```yaml\n---\nname: Skill Name\ndescription: What it does and when to use it\ndependencies: python>=3.8, pandas>=1.5.0\n---\n```\n\n- **version** (optional)\n  - Track iterations using semantic versioning (e.g., 1.0.0)\n  - Useful for maintaining skill history\n\n- **dependencies** (optional)\n  - Required software packages or tools\n  - Examples: `python>=3.8, pandas>=1.5.0`, `node>=18.0.0`\n  - Note: For API skills, dependencies must be pre-installed in the container\n\n## Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n**Design Principle:** Structure the skill so that SKILL.md body provides everything needed for common cases, with bundled resources (references/, scripts/, assets/) for detailed specifications, deterministic operations, and output files.\n\n## Writing Effective Skill Content\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\nThe markdown content in SKILL.md should answer these key questions:\n\n1. **What is the purpose of the skill?** (a few sentences)\n2. **When should the skill be used?** (specific use cases)\n3. **How should Claude use the skill in practice?** (procedural instructions)\n\n### Recommended Structure\n\n```markdown\n# Skill Name\n\nThis skill provides [brief description of capability].\n\n## When to Use This Skill\n\nThis skill should be used when:\n- [Specific use case 1]\n- [Specific use case 2]\n- [Specific use case 3]\n\n## Core Guidelines\n\n### Primary Topic\n\nTo accomplish [task], follow these steps:\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\n**Key Rules:**\n- [Rule 1 with rationale]\n- [Rule 2 with rationale]\n\n### Using Bundled Resources\n\n**Scripts:** To [perform deterministic task], execute `scripts/script_name.py`\n\n**References:** For detailed [specifications/schemas/documentation], read `references/reference_name.md`\n\n**Assets:** To [create output], use the template at `assets/template_name.ext`\n\n## Examples\n\n**Good approach:**\n```\n[Example of correct approach]\n```\n\n**Bad approach:**\n```\n[Example of incorrect approach]\n```\n\n## Best Practices\n\n1. **Practice Name:** Why this matters and how to apply it\n2. **Practice Name:** Why this matters and how to apply it\n```\n\n## Naming Conventions\n\n### Skill Directory Names\n- Use kebab-case (lowercase with hyphens)\n- Be descriptive and specific\n- Examples: `ado-work-items`, `brand-guidelines`, `pdf-creator`\n\n### Skill Names (in YAML)\n- Use title case\n- Be clear and descriptive\n- Examples: \"Azure DevOps Work Items\", \"Brand Guidelines\", \"PDF Creator\"\n\n## Supporting Files\n\n### When to Use References Files\nCreate files in the `references/` directory when:\n- You have detailed specifications that aren't needed for common cases\n- The core SKILL.md would become too long (>5k words)\n- You need to separate high-level guidance from detailed reference\n- You have documentation that Claude should read only when needed\n\n**Reference from SKILL.md:**\n```markdown\nFor detailed field specifications, read references/field_specs.md.\n```\n\n### When to Use Scripts\nInclude executable scripts when:\n- The task requires deterministic operations (sorting, parsing, calculations)\n- Code provides more reliability than LLM generation\n- You want to bundle pre-tested utilities with the skill\n\n**Script Organization:**\n```\nskills/my-skill/\n  SKILL.md\n  scripts/\n    parse_data.py      # Python utilities\n    format_output.js   # JavaScript utilities\n```\n\n**Reference from SKILL.md:**\n```markdown\nTo parse the data, use the provided Python script at scripts/parse_data.py.\n```\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\n**Example:** When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\n**Example:** When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\n**Example:** When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Create the Skill Directory\n\nCreate the skill directory structure:\n\n```bash\nmkdir -p skills/{skill-name}\nmkdir -p skills/{skill-name}/scripts    # If needed\nmkdir -p skills/{skill-name}/references # If needed\nmkdir -p skills/{skill-name}/assets     # If needed\n```\n\n**Plugin Context:** When creating a skill within a Claude Code plugin, place it in `plugins/{plugin-name}/skills/{skill-name}/`\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified in Step 2: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\n#### Create SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language.\n\nTo complete SKILL.md, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used?\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n### Step 5: Test the Skill\n\nAfter creating the skill, test it with realistic scenarios:\n\n**Validation checklist:**\n- Is the description specific enough for Claude to know when to load it?\n- Does the SKILL.md body provide everything needed for common cases?\n- Are bundled resources properly referenced in SKILL.md?\n- Are examples clear and actionable?\n- Is the skill focused on one domain/task, or too broad?\n\n**Plugin Context:** If creating a skill within a Claude Code plugin, update plugin documentation to mention the skill.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n\n## Common Patterns\n\n### Pattern: Domain Expertise Skill\n\n**Use Case:** Providing expert knowledge for a specific domain (e.g., ADO work items, brand guidelines)\n\n**Structure:**\n```yaml\n---\nname: Domain Name Expert\ndescription: Expert guidance for [specific task] using [domain-specific concepts and rules]\n---\n\n# Domain Name Expert Skill\n\nThis skill provides expert guidance on [domain].\n\n## When to Use This Skill\n\nInvoke this skill when:\n- Working with [domain-specific tools]\n- Creating [domain-specific artifacts]\n- Following [domain-specific processes]\n\n## Core Concepts\n\n[Domain knowledge organized by topic]\n\n## Best Practices\n\n[Domain-specific best practices]\n```\n\n### Pattern: Document Processing Skill\n\n**Use Case:** Working with specific file formats (PDF, Excel, Word)\n\n**Structure:**\n```yaml\n---\nname: Format Name Processor\ndescription: Create, read, and manipulate [format] files with proper formatting and structure\ndependencies: [required packages]\n---\n\n# Format Name Processor Skill\n\nThis skill helps you work with [format] files.\n\n## When to Use This Skill\n\nInvoke this skill when:\n- Creating new [format] documents\n- Reading data from [format] files\n- Modifying existing [format] documents\n\n## File Format Specifications\n\n[Format-specific details]\n\n## Common Operations\n\n[How to perform common tasks]\n\n## Example Scripts\n\nUse the provided scripts at scripts/[script-name] for [purpose].\n```\n\n### Pattern: Workflow Automation Skill\n\n**Use Case:** Standardizing repeatable workflows (e.g., meeting notes, reports)\n\n**Structure:**\n```yaml\n---\nname: Workflow Name Automation\ndescription: Automate [workflow name] by following company standards for [specific outputs]\n---\n\n# Workflow Name Automation Skill\n\nThis skill automates [workflow].\n\n## When to Use This Skill\n\nInvoke this skill when:\n- Starting a new [workflow instance]\n- Following the standard [process name]\n\n## Workflow Steps\n\n1. **Step Name:** Description and guidelines\n2. **Step Name:** Description and guidelines\n\n## Templates\n\n[Provide templates or examples]\n```\n\n## Best Practices for Skill Development\n\n### 1. Keep Skills Focused\n- One skill = one domain or task area\n- Create multiple small skills rather than one mega-skill\n- If a skill covers multiple unrelated topics, split it\n\n### 2. Write Discoverable Descriptions\n- Include keywords Claude can match against user requests\n- Specify both WHAT it does and WHEN to use it\n- Use third-person form (\"This skill should be used when...\")\n- Avoid vague or overly technical descriptions\n\n### 3. Use Imperative/Infinitive Form\n- Write using verb-first instructions: \"To accomplish X, do Y\"\n- Avoid second person: Don't use \"you should\" or \"you can\"\n- Maintain objective, instructional language throughout\n\n### 4. Structure for Progressive Disclosure\n- Put common cases and essential procedures in SKILL.md (<5k words)\n- Move detailed specs and documentation to `references/`\n- Extract deterministic operations to `scripts/`\n- Place output templates and assets in `assets/`\n- Avoid duplication between SKILL.md and bundled resources\n\n### 5. Provide Clear Examples\n- Show both correct and incorrect approaches\n- Use realistic, complete examples\n- Explain why one approach is better than another\n\n### 6. Reference Bundled Resources Explicitly\n- Tell Claude when and how to use scripts\n- Direct Claude to read references for detailed information\n- Show how to use assets in output\n\n### 7. Test with Realistic Scenarios\n- Verify Claude loads the skill at the right time\n- Ensure the guidance is sufficient for common tasks\n- Test that bundled resources are accessible and functional\n- Iterate based on actual usage patterns\n\n### 8. Include Context for Decision-Making\n- Explain WHY rules exist, not just WHAT they are\n- Help Claude make contextual decisions\n- Provide rationale for best practices\n\n## Skill Validation Checklist\n\nBefore finalizing a skill, verify:\n\n**Frontmatter:**\n- [ ] Name is clear and under 64 characters\n- [ ] Description includes what it does AND when to use it\n- [ ] Description is under 200 characters\n- [ ] Version number included (if tracking versions)\n- [ ] Dependencies listed (if any required)\n\n**Content Structure:**\n- [ ] Introduction section explains the skill's purpose\n- [ ] \"When to Use This Skill\" section lists specific use cases\n- [ ] Core guidelines are organized by topic with clear headers\n- [ ] Examples show both good and bad patterns\n- [ ] Best practices section provides actionable guidance\n\n**Quality:**\n- [ ] Skill is focused on one domain/task area\n- [ ] Common cases are handled in core content\n- [ ] Supporting files used for detailed specs (if needed)\n- [ ] Examples are realistic and complete\n- [ ] Language is clear, imperative, and actionable\n\n**Integration:**\n- [ ] Skill placed in appropriate directory\n- [ ] Supporting files referenced correctly\n- [ ] Plugin documentation updated (if applicable)\n- [ ] Tested with realistic user requests\n\n## Example: Complete Skill Template\n\n```markdown\n---\nname: My Skill Name\ndescription: Brief description of what this skill does and when to use it (max 200 chars)\ndependencies: python>=3.8\n---\n\n# My Skill Name Skill\n\nThis skill provides [brief description of capability and purpose].\n\n## When to Use This Skill\n\nInvoke this skill when:\n- [Specific use case 1]\n- [Specific use case 2]\n- [Specific use case 3]\n\n## Core Guidelines\n\n### Primary Topic\n\n[Main instructions and guidelines]\n\n**Key Rules:**\n- [Rule 1 with rationale]\n- [Rule 2 with rationale]\n- [Rule 3 with rationale]\n\n### Secondary Topic\n\n[Additional instructions]\n\n## Examples\n\n**Example 1: Common Use Case**\n\nGood approach:\n```\n[Code or text showing correct approach]\n```\n\nBad approach:\n```\n[Code or text showing incorrect approach]\n```\n\n**Example 2: Edge Case**\n\n[Another example with explanation]\n\n## Best Practices\n\n1. **Practice Name:** Why this matters and how to apply it\n2. **Practice Name:** Why this matters and how to apply it\n3. **Practice Name:** Why this matters and how to apply it\n\n## Supporting Resources\n\nFor detailed specifications, read references/specifications.md.\nFor data processing utilities, execute scripts/process_data.py.\n\n## Troubleshooting\n\n**Problem:** Common issue description\n\n**Solution:** How to resolve it\n```\n\n## Creating a Skill: Step-by-Step\n\nWhen asked to create a new skill, follow these steps:\n\n### Step 1: Gather Requirements\n\nAsk the user:\n- What is the skill's purpose?\n- When should this skill be invoked?\n- What domain knowledge does it provide?\n- Are there examples of correct/incorrect approaches?\n- Are supporting files needed (scripts, references)?\n\n### Step 2: Create Directory Structure\n\n```bash\nmkdir -p skills/{skill-name}\n```\n\n### Step 3: Write SKILL.md with Frontmatter\n\nCreate the YAML frontmatter:\n- Name: Clear, descriptive, max 64 chars\n- Description: What it does + when to use it, max 200 chars\n- Dependencies: List if any required\n\n### Step 4: Write Core Content\n\nStructure the markdown:\n1. Title and introduction\n2. \"When to Use This Skill\" section\n3. Core guidelines organized by topic\n4. Examples (good and bad)\n5. Best practices\n6. Troubleshooting (optional)\n\n### Step 5: Create Supporting Files (If Needed)\n\nAdd:\n- references/ directory for detailed specifications and documentation\n- scripts/ directory for executable utilities\n- assets/ directory for output templates and files\n\n### Step 6: Validate and Test\n\nReview:\n- Is the description discoverable?\n- Are the guidelines clear and actionable?\n- Are examples realistic and helpful?\n- Is the skill focused and well-structured?\n\n### Step 7: Document the Skill\n\nIf part of a plugin:\n- Update plugin README to mention the skill\n- Update plugin.json version if significant addition\n- Update CHANGELOG.md with the new skill\n\n## Advanced Topics\n\n### Skill Composition\n\nSkills can reference each other:\n```markdown\nFor authentication guidelines, the authentication-standards skill provides detailed guidance.\n```\n\n### Conditional Logic\n\nSkills can provide context-dependent guidance:\n```markdown\nIf working in a production environment:\n- [Production-specific rules]\n\nIf working in a development environment:\n- [Development-specific rules]\n```\n\n### Integration with MCP Tools\n\nSkills can provide guidance for MCP tool usage:\n```markdown\nWhen using the Azure DevOps MCP server tools (mcp__ado__*):\n- [Tool-specific guidelines]\n```\n\n## Troubleshooting Skill Creation\n\n### Problem: Skill Not Loading When Expected\n\n**Possible Causes:**\n- Description doesn't include relevant keywords\n- Description is too vague or generic\n- Skill is too broad and Claude can't determine relevance\n\n**Solution:**\n- Revise description to include specific keywords and use cases\n- Make description more specific about when to invoke\n- Consider splitting into multiple focused skills\n\n### Problem: Skill Loading Too Often\n\n**Possible Causes:**\n- Description is too broad\n- Keywords match too many contexts\n\n**Solution:**\n- Narrow the description\n- Add specific qualifiers (e.g., \"when using Azure DevOps MCP tools\")\n- Make the \"When to Use This Skill\" section more restrictive\n\n### Problem: Skill Content Too Long\n\n**Possible Causes:**\n- Trying to cover too many topics\n- Including detailed specs that belong in references/ files\n- Not using bundled resources effectively\n\n**Solution:**\n- Split into multiple focused skills\n- Move detailed specs to references/ directory\n- Extract code into scripts/ directory\n- Focus core content on common cases only\n\n## Security Considerations\n\nWhen creating skills:\n\n- Only bundle code from trusted sources\n- Audit all scripts and dependencies\n- Avoid hardcoding credentials or secrets\n- Document any external network connections\n- Don't bundle unvetted third-party code\n- Don't include sensitive organizational data\n\nSkills execute in Claude Code's environment with file and code execution access - treat them with appropriate security caution.\n\n## Summary\n\nSkills are modular packages that extend Claude's capabilities with specialized knowledge, workflows, and tools. To create effective skills:\n\n1. **Understand concrete examples** - Gather specific use cases before building\n2. **Plan reusable contents** - Identify what scripts, references, and assets are needed\n3. **Create proper structure** - Use SKILL.md + bundled resources (scripts/, references/, assets/)\n4. **Write in imperative form** - Use objective, instructional language\n5. **Leverage progressive disclosure** - Keep SKILL.md lean (<5k words), move details to bundled resources\n6. **Write discoverable descriptions** - Use keywords and third-person form\n7. **Test and iterate** - Validate with realistic scenarios and improve based on feedback\n\nBy following the Skill Creation Process and these best practices, skills will enhance Claude Code's capabilities for specialized tasks while maintaining token efficiency and usability."
              }
            ]
          },
          {
            "name": "ai-security",
            "description": "AI-powered security auditing with interactive skill, automated agents, and web dependency scanning for comprehensive vulnerability detection and reporting",
            "source": "./plugins/ai-security",
            "category": null,
            "version": "1.3.3",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-security@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/security-audit",
                "description": "Comprehensive security audit to identify vulnerabilities, OWASP Top 10 issues, and security anti-patterns.",
                "path": "plugins/ai-security/commands/security-audit.md",
                "frontmatter": {
                  "name": "security-audit",
                  "description": "Comprehensive security audit to identify vulnerabilities, OWASP Top 10 issues, and security anti-patterns."
                },
                "content": "# Security Audit\n\nYou are a comprehensive security auditor with deep expertise in application security, OWASP Top 10 vulnerabilities, secure coding practices, and defensive security strategies.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, URLs, or paths after this command (e.g., `/security-audit https://example.com` or `/security-audit ./src`), you MUST COMPLETELY IGNORE them. Do NOT use any URLs, paths, or other arguments that appear in the user's message. You MUST ONLY proceed with the interactive workflow as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Check the security configuration and then invoke the security auditor subagent as specified in this command. DO NOT skip these steps even if the user provided arguments after the command.\n\n### Pre-Audit Check: Security Configuration\n\nBefore performing the security audit, check if `.claude/settings.json` exists and has proper file denial configurations using the **Read tool** (NOT bash test commands):\n\n1. Try to read `.claude/settings.json` using the Read tool\n2. If the file exists and Read succeeds:\n   - Parse the JSON content\n   - Verify it has a `permissions.deny` section\n   - Count the number of rules in the `permissions.deny` array\n3. If the file doesn't exist (Read returns error), proceed with warning about missing configuration\n\n**IMPORTANT**: Use **Read tool only** - DO NOT use bash test commands as they trigger permission prompts\n\n**If less than 4 deny rules are configured:**\n\nDisplay the following warning:\n\n```\n‚ö†Ô∏è  Security Configuration Warning\n\nYour .claude/settings.json file has fewer than 4 file denial rules configured.\n\nFor a comprehensive security audit, it's recommended to configure proper file\ndenial patterns to prevent Claude Code from accidentally reading sensitive files\nlike credentials, secrets, and environment variables.\n\nRecommendation: Run /security-init first to automatically configure file denial\npatterns based on your project's technology stack.\n\n‚ö†Ô∏è  Important: After running /security-init, you must restart Claude Code for\nthe settings to take effect before running this security audit.\n\nWould you like to:\n1. Continue with audit anyway (not recommended)\n2. Run /security-init first (recommended - requires restart after)\n```\n\nWait for user response. If user chooses to run `/security-init`, stop and tell them to:\n1. Run /security-init command\n2. Restart Claude Code for settings to take effect\n3. Then run /security-audit again\n\n### Security Analysis\n\nAfter verifying security configuration (or if user chooses to continue anyway), use the Task tool with subagent_type \"ai-security:security-auditor\" to perform a thorough security analysis of this codebase to identify vulnerabilities, security anti-patterns, and compliance issues.\n\n### Analysis Scope\n\n1. **Code Pattern Analysis**: Scan for SQL injection, XSS, authentication bypasses, insecure configurations\n2. **Architecture Review**: Analyze authentication, authorization, session management, and data protection patterns\n3. **Dependency Security**: Review packages for known vulnerabilities and outdated versions\n4. **OWASP Compliance**: Assess against OWASP Top 10 2021 categories\n5. **Configuration Security**: Check for hardcoded secrets, missing security headers, and misconfigurations\n\n### Output Requirements\n\n- Create a comprehensive security audit report\n- Save the report to: `/docs/security/{timestamp}-security-audit.md`\n  - Format: `YYYY-MM-DD-HHMMSS-security-audit.md`\n  - Example: `2025-10-17-143022-security-audit.md`\n  - This ensures multiple scans on the same day don't overwrite each other\n- Include actual findings from the codebase (not template examples)\n- Provide exact file paths and line numbers for all findings\n- Include before/after code examples for remediation guidance\n- Prioritize findings by severity: Critical, High, Medium, Low\n\n### Important Notes\n\n- Focus on **defensive security** - identifying vulnerabilities to help developers write secure code\n- Provide actionable remediation guidance with specific code examples\n- Create a prioritized remediation roadmap based on risk severity\n- Include OWASP compliance assessment with specific gap analysis\n\nThe ai-security:security-auditor subagent will perform a comprehensive security analysis of this codebase."
              },
              {
                "name": "/security-init",
                "description": "Initialize Claude Code security settings with intelligent file denial patterns based on your project's technology stack.",
                "path": "plugins/ai-security/commands/security-init.md",
                "frontmatter": {
                  "name": "security-init",
                  "description": "Initialize Claude Code security settings with intelligent file denial patterns based on your project's technology stack."
                },
                "content": "# Security Init\n\nInitialize Claude Code security settings by configuring `.claude/settings.json` with intelligent file denial patterns based on your project's technology stack.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, URLs, or paths after this command (e.g., `/security-init --force` or `/security-init ./config`), you MUST COMPLETELY IGNORE them. Do NOT use any URLs, paths, or other arguments that appear in the user's message. You MUST ONLY proceed with the technology detection and interactive workflow as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Begin with Phase 1 technology detection as specified in this command. DO NOT skip any phases even if the user provided arguments after the command.\n\nSet up comprehensive security permissions in `.claude/settings.json` to prevent Claude Code from reading sensitive files, credentials, and build artifacts.\n\n### Phase 1: Technology Detection\n\nScan the project root directory to detect technologies and frameworks using the **Glob tool** (NOT bash commands):\n\n**Node.js Detection:**\n- Use Glob to search for: `package.json`, `yarn.lock`, `pnpm-lock.yaml`, `bun.lockb`\n\n**Python Detection:**\n- Use Glob to search for: `requirements.txt`, `pyproject.toml`, `setup.py`, `Pipfile`, `poetry.lock`, `setup.cfg`\n\n**.NET Detection:**\n- Use Glob to search for: `*.csproj`, `*.sln`, `*.fsproj`, `*.vbproj`, `global.json`, `Directory.Build.props`\n\n**Go Detection:**\n- Use Glob to search for: `go.mod`, `go.sum`\n\n**Rust Detection:**\n- Use Glob to search for: `Cargo.toml`, `Cargo.lock`\n\n**PHP Detection:**\n- Use Glob to search for: `composer.json`, `composer.lock`\n\n**Ruby Detection:**\n- Use Glob to search for: `Gemfile`, `Gemfile.lock`\n\n**Java Detection:**\n- Use Glob to search for: `pom.xml`, `build.gradle`, `build.gradle.kts`, `settings.gradle`\n\n**Docker Detection:**\n- Use Glob to search for: `Dockerfile`, `docker-compose.yml`, `docker-compose.yaml`, `.dockerignore`\n\n**IMPORTANT**:\n- Use **Glob tool only** for file detection - DO NOT use bash test commands or any bash commands\n- Only check for file existence - DO NOT read the contents of any files during detection\n- Glob returns matching files or empty array if none found\n\n### Phase 2: Build Denial Patterns\n\nCreate a comprehensive deny list combining:\n\n#### Base Security Patterns (Always Include)\n\n**Environment Files:**\n- `Read(.env)`\n- `Read(**/.env)`\n- `Read(.env.*)`\n- `Read(**/.env.*)`\n- `Read(.env.local)`\n- `Read(.env.development)`\n- `Read(.env.production)`\n- `Read(.env.test)`\n\n**Version Control & IDE:**\n- `Read(.git/**)`\n- `Read(.vscode/**)`\n- `Read(.idea/**)`\n- `Read(.devcontainer/**)`\n- `Read(.github/workflows/**)`\n\n**Package Management:**\n- `Read(node_modules/**)`\n- `Read(package-lock.json)`\n\n**Credentials & Secrets:**\n- `Read(credentials.json)`\n- `Read(**/credentials.json)`\n- `Read(secrets.yml)`\n- `Read(**/secrets.yml)`\n- `Read(config/secrets.yml)`\n- `Read(.secret)`\n- `Read(**/.secret)`\n- `Read(*.secret)`\n\n**SSH & Certificate Files:**\n- `Read(id_rsa)`\n- `Read(id_rsa.pub)`\n- `Read(id_ed25519)`\n- `Read(id_ed25519.pub)`\n- `Read(*.pem)`\n- `Read(*.key)`\n- `Read(*.p12)`\n- `Read(*.jks)`\n- `Read(*.pfx)`\n- `Read(*.keystore)`\n- `Read(*.cer)`\n- `Read(*.crt)`\n\n**Cloud Provider Credentials:**\n- `Read(.aws/credentials)`\n- `Read(.aws/config)`\n- `Read(.gcp/credentials.json)`\n- `Read(.azure/credentials)`\n\n**Database Files:**\n- `Read(*.db)`\n- `Read(*.sqlite)`\n- `Read(*.sqlite3)`\n\n#### Technology-Specific Patterns\n\n**Python (if detected):**\n- `Read(.venv/**)`\n- `Read(venv/**)`\n- `Read(__pycache__/**)`\n- `Read(**/__pycache__/**)`\n- `Read(*.pyc)`\n- `Read(.pytest_cache/**)`\n- `Read(.tox/**)`\n- `Read(dist/**)`\n- `Read(build/**)`\n- `Read(*.egg-info/**)`\n- `Read(.mypy_cache/**)`\n- `Read(.ruff_cache/**)`\n\n**.NET (if detected):**\n- `Read(bin/**)`\n- `Read(obj/**)`\n- `Read(*.user)`\n- `Read(*.suo)`\n- `Read(.vs/**)`\n- `Read(*.DotSettings.user)`\n- `Read(TestResults/**)`\n- `Read(packages/**)`\n\n**Go (if detected):**\n- `Read(vendor/**)`\n\n**Rust (if detected):**\n- `Read(target/**)`\n\n**PHP (if detected):**\n- `Read(vendor/**)`\n- `Read(composer.lock)`\n\n**Ruby (if detected):**\n- `Read(vendor/bundle/**)`\n- `Read(.bundle/**)`\n\n**Java (if detected):**\n- `Read(target/**)`\n- `Read(*.class)`\n- `Read(.gradle/**)`\n- `Read(build/**)`\n\n**Node.js (if detected):**\n- `Read(node_modules/**)`\n- `Read(.next/**)`\n- `Read(.nuxt/**)`\n- `Read(dist/**)`\n- `Read(build/**)`\n- `Read(.cache/**)`\n- `Read(.turbo/**)`\n\n**Docker (if detected):**\n- `Read(docker-compose.override.yml)`\n- `Read(docker-compose.override.yaml)`\n\n### Phase 3: Check Existing Configuration\n\nCheck if `.claude/settings.json` already exists using the **Read tool** (NOT bash test commands):\n\n1. Try to read `.claude/settings.json` using the Read tool\n2. If the file exists and Read succeeds:\n   - Parse the JSON content\n   - Check for existing `permissions.deny` section\n   - Ask user for merge strategy preference using AskUserQuestion tool:\n     - **Deduplicate** (default): Remove duplicate patterns, add only new ones\n     - **Append**: Add all new patterns, keep duplicates\n     - **Replace**: Completely replace existing deny section with new patterns\n3. If the file doesn't exist (Read returns error):\n   - Proceed to create new file with deny patterns\n   - Use \"Deduplicate\" as the default strategy\n\n**IMPORTANT**:\n- Use **Read tool** to check file existence - DO NOT use bash test commands\n- The Read tool will gracefully handle non-existent files by returning an error\n- Parse existing JSON to preserve non-permission settings\n\n### Phase 4: Show Preview & Get Confirmation\n\nDisplay a comprehensive preview showing:\n\n1. **Technologies Detected:**\n   - List all detected technologies with file indicators\n\n2. **Current Configuration (if exists):**\n   - Show current deny patterns count\n   - Show sample of existing patterns (first 5)\n\n3. **Proposed Changes:**\n   - Show all new patterns to be added\n   - Group by category (Base Security, Python, .NET, etc.)\n   - Show total pattern count\n\n4. **After Configuration:**\n   - Show total pattern count after merge\n   - Show merge strategy being used\n\nAsk for user confirmation before proceeding.\n\n### Phase 5: Write Configuration\n\nAfter user confirms:\n\n1. Create `.claude/` directory if it doesn't exist using the Bash tool: `mkdir -p .claude`\n2. Write or update `settings.json` using the **Write tool** (NOT bash echo or heredoc)\n3. Preserve any other existing settings (don't overwrite non-permission settings)\n4. Format JSON with proper indentation (2 spaces)\n5. Show success message with:\n   - File path: `.claude/settings.json`\n   - Total deny patterns configured\n   - Technologies covered\n\n**IMPORTANT**:\n- Use **Write tool** to create/update the settings file\n- Use Bash tool only for creating the `.claude/` directory if needed\n- Ensure proper JSON formatting with 2-space indentation\n\n### Important Constraints\n\n**DO NOT:**\n- Read the contents of any sensitive files during scanning\n- Include file paths from the actual project in the deny list\n- Overwrite other settings in settings.json (preserve everything except permissions.deny)\n- Proceed without user confirmation\n- Use bash test commands (`test -f`, `[ -f ]`, etc.) - they trigger permission prompts\n- Use any bash commands for file detection or checking\n\n**DO:**\n- Use **Glob tool** for technology detection (file pattern matching)\n- Use **Read tool** to check if `.claude/settings.json` exists (handles errors gracefully)\n- Use **Write tool** to create/update settings.json\n- Use **AskUserQuestion tool** to ask for merge strategy preference\n- Deduplicate patterns by default during merge\n- Show clear before/after comparison\n- Maintain alphabetical ordering within categories for readability\n- Use forward slashes in all patterns for cross-platform compatibility\n\n### Example Output Format\n\n```\nüîç Detecting technologies in your project...\n\nTechnologies Detected:\n‚úì Node.js (package.json found)\n‚úì TypeScript (tsconfig.json found)\n‚úì Python (requirements.txt, pyproject.toml found)\n‚úì Docker (Dockerfile, docker-compose.yml found)\n\nCurrent Configuration:\nüìÑ .claude/settings.json exists\nüìä Current deny patterns: 8\n\nProposed Security Configuration:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nBase Security Patterns (25):\n  ‚Ä¢ Environment files (.env, .env.*)\n  ‚Ä¢ Version control (.git, .vscode, .idea)\n  ‚Ä¢ Credentials (credentials.json, secrets.yml)\n  ‚Ä¢ SSH & certificates (*.pem, *.key, id_rsa)\n  ‚Ä¢ Cloud provider configs (.aws/credentials, .gcp/*)\n  ‚Ä¢ Database files (*.db, *.sqlite)\n\nNode.js Patterns (8):\n  ‚Ä¢ node_modules/**\n  ‚Ä¢ .next/**, .nuxt/**\n  ‚Ä¢ dist/**, build/**\n  ‚Ä¢ .cache/**, .turbo/**\n\nPython Patterns (11):\n  ‚Ä¢ .venv/**, venv/**\n  ‚Ä¢ __pycache__/**, *.pyc\n  ‚Ä¢ .pytest_cache/**, .tox/**\n  ‚Ä¢ dist/**, *.egg-info/**\n\nDocker Patterns (2):\n  ‚Ä¢ docker-compose.override.yml\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nTotal new patterns to add: 46\nAfter merge: 54 total patterns\n\nMerge Strategy: Deduplicate (remove duplicates, add only new patterns)\n\nWould you like to proceed with this configuration? (yes/no)\n```\n\n### Success Message Format\n\n```\n‚úì Security configuration successfully initialized!\n\nConfiguration Summary:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\nüìÑ File: .claude/settings.json\nüìä Total deny patterns: 54\nüõ°Ô∏è Technologies covered: Node.js, TypeScript, Python, Docker\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n‚ö†Ô∏è  IMPORTANT: You must restart Claude Code for these settings to take effect.\n\nAfter restarting:\n- Claude Code will avoid reading sensitive files, credentials, and build artifacts\n- You can manually edit .claude/settings.json to customize these settings\n- Run /security-audit to perform a comprehensive security analysis\n```"
              },
              {
                "name": "/security-scan-dependencies",
                "description": "Scan a deployed website for outdated dependencies, known CVEs, and security misconfigurations.",
                "path": "plugins/ai-security/commands/security-scan-dependencies.md",
                "frontmatter": {
                  "name": "security-scan-dependencies",
                  "description": "Scan a deployed website for outdated dependencies, known CVEs, and security misconfigurations."
                },
                "content": "# Web Dependency Security Scan\n\nScan a deployed website for outdated dependencies, known CVEs, and security misconfigurations without requiring source code access.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text, URLs, or paths after this command (e.g., `/security-scan-dependencies https://example.com`), you MUST COMPLETELY IGNORE them. Do NOT use any URLs, paths, or other arguments that appear in the user's message. You MUST ONLY gather requirements through the interactive AskUserQuestion tool as specified below.\n\n**BEFORE DOING ANYTHING ELSE**: Use the AskUserQuestion tool to collect the target URL and scan scope. DO NOT skip this step even if the user provided arguments after the command.\n\n### Phase 1: Get Target URL\n\nUse the **AskUserQuestion tool** to collect the target website URL:\n\n```\nQuestion: \"What is the URL of the website you want to scan?\"\nHeader: \"Target URL\"\nOptions:\n  - Provide text input field for URL entry\n```\n\n**URL Validation**:\n- Ensure URL includes protocol (http:// or https://)\n- Accept both HTTP and HTTPS URLs\n- If user provides URL without protocol, prepend https://\n\n### Phase 2: Configure Scan Scope\n\nUse the **AskUserQuestion tool** to determine scan scope:\n\n```\nQuestion: \"What would you like to scan for?\"\nHeader: \"Scan Scope\"\nmultiSelect: true\nOptions:\n  1. \"Frontend libraries\" - \"jQuery, React, Vue, Angular, Bootstrap, Tailwind, etc.\"\n  2. \"CMS platforms\" - \"WordPress, Drupal, Joomla, Umbraco, Sitecore, Optimizely, Kentico\"\n  3. \"Security headers\" - \"CSP, HSTS, X-Frame-Options, and other HTTP security headers\"\n  4. \"All of the above\" - \"Comprehensive scan covering all categories\"\n```\n\n**Scope Interpretation**:\n- If user selects \"All of the above\", perform comprehensive scan across all categories\n- If user selects multiple specific options, scan only those categories\n- If user selects only one option, focus the scan on that specific area\n\n### Phase 3: Invoke Dependency Scanner Agent\n\nUse the **Task tool** with subagent_type \"ai-security:security-dependency-scanner\" to perform the security scan.\n\n**Important**: Pass the target URL and scan scope in the prompt to the agent.\n\n**üö® CRITICAL TOOL REQUIREMENT üö®**:\n- The agent MUST use ONLY the **WebFetch tool** or **curl** (via Bash tool) to fetch websites\n- DO NOT use Playwright, browser automation, or any other MCP tools for website scanning\n- **Reason**: HTTP security headers (especially Content-Security-Policy) can ONLY be retrieved via HTTP requests using WebFetch or curl. Playwright and other browser tools cannot access these critical security headers.\n- Using the wrong tool will result in incomplete security header analysis\n\n**Example Task Tool Invocation**:\n```\nTask tool:\n  subagent_type: \"ai-security:security-dependency-scanner\"\n  description: \"Scan website for dependencies\"\n  prompt: \"\n    Please scan the following website for security vulnerabilities:\n\n    Target URL: [user-provided URL]\n    Scan Scope: [user-selected scope]\n\n    Perform a comprehensive security dependency scan including:\n    - [Based on scope: Frontend library detection and version analysis]\n    - [Based on scope: CMS platform detection and version checking]\n    - [Based on scope: HTTP security headers audit]\n    - Context7 integration for latest version verification\n    - Known CVE identification for detected libraries\n    - Security risk assessment with CVSS scoring\n\n    Generate a detailed security report following the security-dependency-scanning\n    skill's mandatory template and save it to /docs/security/{timestamp}-dependency-scan.md\n  \"\n```\n\n**Agent Responsibilities**:\nThe ai-security:security-dependency-scanner agent will:\n1. Load the security-dependency-scanning skill\n2. Fetch the target website using **ONLY WebFetch tool or curl** (NOT Playwright or MCP tools)\n3. Parse HTML and detect dependencies based on scope\n4. Analyze HTTP security headers (requires WebFetch/curl to retrieve headers)\n5. Use Context7 to check for latest versions\n6. Identify known CVEs in detected versions\n7. Generate comprehensive security report with findings\n8. Save report to `/docs/security/YYYY-MM-DD-HHMMSS-dependency-scan.md`\n\n### Phase 4: Report Completion\n\nAfter the agent completes its analysis, inform the user:\n\n```\n‚úÖ Web dependency security scan completed!\n\nüìÑ Report saved to: /docs/security/{timestamp}-dependency-scan.md\n\nSummary:\n- Libraries Detected: X\n- CMS Platform: [Detected CMS or \"None\"]\n- Vulnerabilities Found: X (Y critical, Z high)\n- Security Headers: X/8 configured\n\nPlease review the detailed report for:\n- Complete list of detected dependencies and versions\n- Known CVEs with CVSS scores and remediation steps\n- Security header analysis and recommendations\n- Prioritized risk mitigation roadmap\n\nNext steps:\n1. Review critical and high-severity findings first\n2. Plan remediation based on the prioritized roadmap\n3. Test updates in staging environment before production\n4. Schedule follow-up scan after remediation\n```\n\n### Important Notes\n\n**Scan Capabilities**:\n- ‚úÖ Detects frontend libraries from HTML, scripts, and CDN URLs\n- ‚úÖ Identifies CMS platforms from meta tags, paths, cookies, and headers\n- ‚úÖ Analyzes HTTP security headers and configurations\n- ‚úÖ Checks for known CVEs in detected library versions\n- ‚úÖ Uses Context7 to verify latest versions\n\n**Scan Limitations**:\n- ‚ùå Cannot detect server-side vulnerabilities without source code access\n- ‚ùå Cannot assess authentication or authorization mechanisms\n- ‚ùå Cannot detect business logic flaws\n- ‚ùå Cannot scan password-protected or authenticated areas\n- ‚ùå Limited to publicly accessible client-side information\n\n**Use Cases**:\n- Third-party website security assessment\n- Pre-acquisition technical due diligence\n- Client-side dependency auditing\n- Supply chain security analysis\n- Comparison with client's internal security scan tools\n\n**Ethical Considerations**:\n- Only scan websites you have permission to analyze\n- This tool performs passive analysis of publicly accessible information\n- No intrusive testing or exploitation attempts are performed\n- Suitable for authorized security assessments and pentesting engagements\n\n**Comparison with /security-audit**:\n- `/security-audit`: Analyzes source code in current directory for vulnerabilities\n- `/security-scan-dependencies`: Scans deployed website URL without source code access\n- Use `/security-audit` for your own codebases\n- Use `/security-scan-dependencies` for analyzing deployed websites"
              }
            ],
            "skills": [
              {
                "name": "security-dependency-scanning",
                "description": "Guide for conducting comprehensive web dependency security scans to identify outdated libraries, CVEs, and security misconfigurations. Use when analyzing deployed websites for dependency vulnerabilities.",
                "path": "plugins/ai-security/skills/security-dependency-scanning/SKILL.md",
                "frontmatter": {
                  "name": "security-dependency-scanning",
                  "description": "Guide for conducting comprehensive web dependency security scans to identify outdated libraries, CVEs, and security misconfigurations. Use when analyzing deployed websites for dependency vulnerabilities."
                },
                "content": "# Web Dependency Security Scanning Skill\n\nThis skill provides expert guidance for scanning deployed websites to identify outdated dependencies, known vulnerabilities (CVEs), insecure configurations, and missing security controls.\n\n## When to Use This Skill\n\nInvoke this skill when:\n- Scanning a deployed website for outdated libraries and frameworks\n- Identifying CVEs in frontend dependencies (jQuery, React, Vue, Bootstrap, etc.)\n- Detecting CMS versions and known vulnerabilities (WordPress, Drupal, Umbraco, Sitecore, etc.)\n- Auditing HTTP security headers and configurations\n- Performing third-party website security assessments\n- Conducting pre-acquisition technical due diligence\n- Analyzing supply chain security risks in web applications\n- Evaluating client-side dependency security without source code access\n\n## Required Tools\n\n**üö® CRITICAL: Tool Requirements for Website Scanning üö®**\n\nYou MUST use ONLY these tools to fetch and analyze websites:\n- ‚úÖ **WebFetch tool** - Primary method for fetching HTML and HTTP headers\n- ‚úÖ **curl** (via Bash tool) - Alternative method: `curl -i https://example.com`\n\nYou MUST NOT use these tools:\n- ‚ùå **Playwright** or any MCP browser automation tools\n- ‚ùå **Any browser-based tools** (mcp__playwright__browser_navigate, etc.)\n- ‚ùå **Any other MCP web browsing tools**\n\n**Why This Matters**:\n- HTTP security headers (Content-Security-Policy, HSTS, X-Frame-Options, etc.) are ONLY available via raw HTTP responses\n- Playwright and browser tools **cannot access** these critical security headers\n- Using browser tools will result in **incomplete and inaccurate security header analysis**\n- WebFetch and curl provide the raw HTTP response headers required for comprehensive security auditing\n\n**If you use Playwright or browser tools, the security scan will be incomplete and the report will be invalid.**\n\n## Core Web Security Expertise\n\n### 1. Frontend Library Detection\n\nTo identify JavaScript and CSS libraries, analyze:\n- **CDN URL Patterns**: Extract library names and versions from CDN URLs\n  - jsDelivr: `cdn.jsdelivr.net/npm/{package}@{version}/{file}`\n  - unpkg: `unpkg.com/{package}@{version}/{file}`\n  - cdnjs: `cdnjs.cloudflare.com/ajax/libs/{library}/{version}/{file}`\n  - Google Hosted: `ajax.googleapis.com/ajax/libs/{library}/{version}/{file}`\n- **Script/Link Tag Analysis**: Parse `<script src>` and `<link href>` for versioned filenames\n  - Examples: `jquery-3.6.0.min.js`, `react.production.min.js`, `bootstrap.min.css`\n- **File Content Inspection**: Look for version comments in fetched files\n  - Examples: `/*! jQuery v3.6.0 */`, `/*! Bootstrap v4.3.1 */`\n- **Meta Tag Detection**: Extract version info from HTML meta tags\n  - Examples: `<meta name=\"generator\" content=\"Next.js 13.4.0\">`\n- **Global Variables**: Document detection of version-exposing globals\n  - Examples: `jQuery.fn.jquery`, `React.version`, `Vue.version`\n\n**Common Libraries to Detect**:\n- **UI Frameworks**: React, Vue.js, Angular, Svelte, Ember\n- **jQuery Family**: jQuery, jQuery UI, jQuery Mobile\n- **CSS Frameworks**: Bootstrap, Tailwind CSS, Foundation, Bulma, Materialize\n- **Build Tool Artifacts**: Webpack, Vite, Parcel (detected from bundle patterns)\n- **Server Frameworks**: Next.js, Nuxt.js, Gatsby (detected from client-side artifacts)\n- **Utility Libraries**: Lodash, Moment.js, Axios, date-fns\n- **Analytics**: Google Analytics, Google Tag Manager, Hotjar, Mixpanel\n\n### 2. CMS and Platform Detection\n\nTo identify content management systems and web platforms:\n\n**Open Source CMS**:\n- **WordPress**:\n  - Meta generator: `<meta name=\"generator\" content=\"WordPress X.Y.Z\">`\n  - Path patterns: `/wp-content/`, `/wp-includes/`, `/wp-admin/`\n  - RSS feed: Check `/feed/` endpoint for generator tag\n  - Version files: `readme.html`, `license.txt`\n- **Drupal**:\n  - Meta generator: `<meta name=\"Generator\" content=\"Drupal X\">`\n  - CHANGELOG.txt: Contains version information\n  - JavaScript: `Drupal.settings` object\n  - Path patterns: `/sites/default/`, `/modules/`, `/themes/`\n- **Joomla**:\n  - Meta generator: `<meta name=\"generator\" content=\"Joomla! X.Y\">`\n  - XML files with version info\n  - Path patterns: `/media/jui/`, `/components/`, `/modules/`\n\n**Enterprise .NET CMS**:\n- **Umbraco**:\n  - Path patterns: `/umbraco/`, `/umbraco_client/`\n  - Cookies: `Umbraco.Sys`, `UMB_UCONTEXT`\n  - HTTP headers: `X-Umbraco-Version` (if exposed)\n  - Meta generator: `<meta name=\"generator\" content=\"Umbraco CMS\">`\n  - JavaScript: `Umbraco` global object\n- **Sitecore**:\n  - Path patterns: `/sitecore/`, `/-/media/`, `/sitecore/shell/`\n  - Cookies: `SC_ANALYTICS_GLOBAL_COOKIE`, `.ASPXAUTH`\n  - Meta generator: May contain Sitecore reference\n  - Version info in: `/sitecore/service/version` endpoint (if accessible)\n- **Optimizely** (formerly EPiServer):\n  - Path patterns: `/episerver/`, `/EPiServer/`\n  - Cookies: `EPiServerLogin`, `ASP.NET_SessionId`\n  - HTTP headers: `X-Epi-ServerName`, `X-EpiContentLanguage`\n  - Meta generator: `<meta name=\"generator\" content=\"EPiServer\">`\n- **Kentico**:\n  - Path patterns: `/CMSPages/`, `/Kentico.Resource/`, `/CMSModules/`\n  - Cookies: `CMSPreferredCulture`, `CMSCurrentTheme`\n  - Meta generator: `<meta name=\"generator\" content=\"Kentico CMS\">`\n  - ViewState: Contains Kentico-specific identifiers\n\n**Detection Priority**:\n1. Meta generator tags (most reliable)\n2. HTTP headers (X-Powered-By, X-Generator, custom headers)\n3. Cookie patterns (CMS-specific cookie names)\n4. Path patterns (characteristic directory structures)\n5. HTML comments (version info, debug comments)\n\n### 3. HTTP Security Headers Analysis\n\nTo audit security header configurations, check for:\n\n**Critical Security Headers**:\n\n1. **Content-Security-Policy (CSP)**\n   - **Purpose**: Mitigate XSS attacks by restricting content sources\n   - **Best Practice**: Use nonce or hash-based CSP; avoid `'unsafe-inline'` and `'unsafe-eval'`\n   - **Severity if Missing**: HIGH (7.5)\n   - **Example**: `Content-Security-Policy: default-src 'self'; script-src 'self' 'nonce-{random}'`\n\n2. **Strict-Transport-Security (HSTS)**\n   - **Purpose**: Enforce HTTPS connections, prevent downgrade attacks\n   - **Best Practice**: Include `includeSubDomains`; minimum `max-age` of 31536000 (1 year)\n   - **Severity if Missing**: HIGH (7.0)\n   - **Example**: `Strict-Transport-Security: max-age=31536000; includeSubDomains; preload`\n\n3. **X-Frame-Options**\n   - **Purpose**: Prevent clickjacking attacks\n   - **Best Practice**: Use `DENY` or `SAMEORIGIN`\n   - **Severity if Missing**: MEDIUM (5.5)\n   - **Note**: CSP `frame-ancestors` directive is preferred but X-Frame-Options provides legacy support\n   - **Example**: `X-Frame-Options: DENY`\n\n4. **X-Content-Type-Options**\n   - **Purpose**: Prevent MIME type sniffing\n   - **Best Practice**: Always set to `nosniff`\n   - **Severity if Missing**: LOW (3.5)\n   - **Example**: `X-Content-Type-Options: nosniff`\n\n5. **Referrer-Policy**\n   - **Purpose**: Control referrer information leakage\n   - **Best Practice**: Use `strict-origin-when-cross-origin` or `no-referrer`\n   - **Severity if Missing**: LOW (2.5)\n   - **Example**: `Referrer-Policy: strict-origin-when-cross-origin`\n\n6. **Permissions-Policy** (formerly Feature-Policy)\n   - **Purpose**: Control browser features and APIs\n   - **Best Practice**: Disable unused features\n   - **Severity if Missing**: LOW (2.0)\n   - **Example**: `Permissions-Policy: geolocation=(), microphone=(), camera=()`\n\n**Deprecated Headers to Flag**:\n- **X-XSS-Protection**: DEPRECATED - Modern browsers no longer use XSS filtering\n  - **Recommendation**: Remove or set to `X-XSS-Protection: 0`\n  - **Reason**: Can introduce vulnerabilities; CSP is the modern replacement\n\n### 4. Context7 Integration for Version Checking\n\nTo check for latest versions and security documentation:\n\n**Workflow**:\n1. **Resolve Library ID**: Use `mcp__context7__resolve-library-id` to get Context7-compatible ID\n   - Input: Library name (e.g., \"react\", \"vue\", \"jquery\")\n   - Output: Library ID (e.g., \"/facebook/react\", \"/vuejs/core\")\n2. **Fetch Documentation**: Use `mcp__context7__get-library-docs` to retrieve version info\n   - Input: Library ID from step 1\n   - Optional: Set `topic: \"security\"` for security-focused docs\n   - Optional: Set `tokens: 3000` to limit response size\n3. **Extract Version**: Parse documentation for latest stable version\n4. **Compare Versions**: Document gap between detected version and latest version\n5. **Security Guidance**: Include any security recommendations from documentation\n\n**Common Library IDs** (for reference):\n- React: `/facebook/react`\n- Vue: `/vuejs/vue` or `/vuejs/core`\n- Angular: `/angular/angular`\n- jQuery: `/jquery/jquery`\n- Next.js: `/vercel/next.js`\n- Bootstrap: `/twbs/bootstrap`\n- Tailwind: `/tailwindlabs/tailwindcss`\n- Express: `/expressjs/express`\n\n**Error Handling**:\n- If library ID cannot be resolved, document version detection but note inability to verify latest version\n- Include recommendation to manually check official documentation\n\n### 5. CVE Identification and Risk Scoring\n\nTo identify known vulnerabilities:\n\n**CVSS v3.1 Severity Thresholds**:\n\n| Severity Level | CVSS Score Range | Priority | Fix Timeline | Finding Code |\n|----------------|------------------|----------|--------------|--------------|\n| **Critical**   | 9.0 - 10.0       | P0       | Immediate (24-48 hours) | C-001, C-002 |\n| **High**       | 7.0 - 8.9        | P1       | 1-2 weeks | H-001, H-002 |\n| **Medium**     | 4.0 - 6.9        | P2       | 1-2 months | M-001, M-002 |\n| **Low**        | 0.1 - 3.9        | P3       | 2-3 months | L-001, L-002 |\n| **None**       | 0.0              | P4       | Informational | I-001, I-002 |\n\n**CVE Documentation**:\n- Document CVE IDs for known vulnerabilities in detected versions\n- Note: Direct NVD API access not available; rely on known vulnerability databases\n- Include CVE details: ID, CVSS score, description, affected versions, remediation\n\n**Known Vulnerability Examples**:\n- jQuery < 3.5.0: XSS vulnerabilities (CVE-2020-11022, CVE-2020-11023)\n- Angular < 1.7.9: XSS and template injection\n- Bootstrap < 4.3.1: XSS vulnerabilities\n- React < 16.0: XSS in server-side rendering\n\n**Risk Assessment Factors**:\n1. CVSS base score\n2. Exploitability (public exploits available?)\n3. Attack complexity (low/high)\n4. Privileges required (none/low/high)\n5. User interaction (none/required)\n6. Impact scope (confidentiality, integrity, availability)\n\n## Scanning Methodology\n\nWhen scanning a deployed website, follow this systematic approach:\n\n### Phase 1: URL Validation and Fetch\n\n1. **Validate Target URL**: Ensure proper URL format (http:// or https://)\n2. **Fetch Website Content**: Use **ONLY WebFetch tool or curl** to retrieve:\n   - HTML content\n   - HTTP response headers (CRITICAL: Only available via WebFetch/curl)\n   - Status code\n   - **IMPORTANT**: DO NOT use Playwright, browser tools, or any MCP browser automation\n   - **REASON**: Security headers cannot be retrieved with browser automation tools\n3. **Handle Errors**: Document connection failures, timeouts, or HTTP errors\n\n**Example using WebFetch**:\n```\nWebFetch tool:\n  url: \"https://example.com\"\n  prompt: \"Extract the full HTML content and list all HTTP response headers\"\n```\n\n**Example using curl (alternative)**:\n```bash\ncurl -i -L https://example.com\n```\n\n### Phase 2: HTML Parsing and Library Detection\n\n1. **Parse HTML Structure**: Extract all `<script>`, `<link>`, and `<meta>` tags\n2. **CDN Pattern Matching**: Identify libraries from CDN URLs using regex patterns\n3. **Version Extraction**: Parse version numbers from:\n   - Filenames (e.g., `jquery-3.6.0.min.js`)\n   - CDN paths (e.g., `/ajax/libs/{library}/{version}/`)\n   - Meta tags\n4. **Document Findings**: Create table of detected libraries with versions\n\n### Phase 3: CMS and Framework Fingerprinting\n\n1. **Meta Generator Analysis**: Check for CMS identification in meta tags\n2. **Path Pattern Recognition**: Identify characteristic directory structures\n3. **Cookie Analysis**: Document CMS-specific cookies if visible in headers\n4. **HTTP Header Inspection**: Check for X-Powered-By, Server, X-Generator headers\n5. **Version Determination**: Extract CMS version if exposed\n\n### Phase 4: Security Headers Audit\n\n1. **Extract Response Headers**: Parse HTTP headers from WebFetch or curl response\n   - **CRITICAL**: This step REQUIRES WebFetch or curl - browser tools cannot provide headers\n   - Headers must include: Content-Security-Policy, Strict-Transport-Security, X-Frame-Options, etc.\n2. **Check Critical Headers**: Verify presence of CSP, HSTS, X-Frame-Options\n3. **Validate Configuration**: Assess header values for security best practices\n4. **Document Missing Headers**: List absent security headers with severity\n5. **Flag Deprecated Headers**: Identify X-XSS-Protection and other deprecated headers\n\n**Important**: If you cannot retrieve HTTP headers, the scan is incomplete and must not proceed. Always use WebFetch or curl to ensure header access.\n\n### Phase 5: Version Gap Analysis\n\n1. **Context7 Lookup**: For each detected library:\n   - Resolve library ID using `mcp__context7__resolve-library-id`\n   - Fetch latest version using `mcp__context7__get-library-docs`\n2. **Version Comparison**: Calculate version difference (e.g., \"3 major versions behind\")\n3. **End-of-Life Check**: Identify unsupported versions\n4. **Document Urgency**: Prioritize updates based on version age and known CVEs\n\n### Phase 6: Vulnerability Assessment\n\n1. **Known CVE Lookup**: Cross-reference detected versions with known CVEs\n2. **Severity Assignment**: Apply CVSS scores to findings\n3. **Impact Analysis**: Document potential security impact for each vulnerability\n4. **Remediation Guidance**: Provide specific upgrade recommendations\n\n### Phase 7: Report Generation\n\n1. **Compile Findings**: Aggregate all detected issues\n2. **Assign Finding Codes**: Use C-001, H-001, M-001, L-001 format\n3. **Create Remediation Plan**: Prioritize fixes by severity\n4. **Generate Report**: Use mandatory template structure (see below)\n5. **Save Report**: Write to `/docs/security/{timestamp}-dependency-scan.md`\n\n## Report Output Format\n\n**IMPORTANT**: The section below defines the COMPLETE report structure that MUST be used. Do NOT create your own format or simplified version.\n\n### Location and Naming\n\n- **Directory**: `/docs/security/`\n- **Filename**: `YYYY-MM-DD-HHMMSS-dependency-scan.md`\n- **Example**: `2025-11-01-143022-dependency-scan.md`\n\n### Report Template\n\n**üö® CRITICAL INSTRUCTION - READ CAREFULLY üö®**\n\nYou MUST use this exact template structure for ALL web dependency scan reports. This is MANDATORY and NON-NEGOTIABLE.\n\n**REQUIREMENTS:**\n1. ‚úÖ Use the COMPLETE template structure below - ALL sections are REQUIRED\n2. ‚úÖ Follow the EXACT heading hierarchy (##, ###, ####)\n3. ‚úÖ Include ALL section headings as written in the template\n4. ‚úÖ Use the finding numbering format: C-001, H-001, M-001, L-001, etc.\n5. ‚úÖ Include the tables and examples as shown\n6. ‚ùå DO NOT create your own format or structure\n7. ‚ùå DO NOT skip or combine sections\n8. ‚ùå DO NOT create abbreviated or simplified versions\n9. ‚ùå DO NOT number issues as \"1, 2, 3\" - use C-001, H-001, M-001 format\n\n**If you do not follow this template exactly, the report will be rejected.**\n\n<template>\n## Executive Summary\n\n### Scan Overview\n\n- **Target URL**: [Website URL scanned]\n- **Scan Date**: [Date and Time]\n- **Scan Scope**: [Frontend Libraries / CMS Detection / Security Headers / Comprehensive]\n- **Scanner**: Claude Code Security Dependency Scanner v1.0\n\n### Risk Assessment Summary\n\n| Risk Level | Count | Percentage |\n|------------|-------|------------|\n| Critical   | X     | X%         |\n| High       | X     | X%         |\n| Medium     | X     | X%         |\n| Low        | X     | X%         |\n| **Total**  | **X** | **100%**   |\n\n### Key Findings\n\n- **Libraries Detected**: X frontend libraries and frameworks\n- **CMS Platform**: [Detected CMS and version, or \"None detected\"]\n- **Outdated Dependencies**: X libraries with available updates\n- **Known CVEs**: X vulnerabilities identified\n- **Security Headers**: X/8 critical headers properly configured\n- **Overall Security Score**: X/100\n\n---\n\n## Detected Dependencies\n\n### Frontend Libraries and Frameworks\n\n| Library/Framework | Detected Version | Latest Version | Status | Version Gap | Severity |\n|-------------------|------------------|----------------|--------|-------------|----------|\n| jQuery            | 3.5.0           | 3.7.1          | ‚ö†Ô∏è Outdated | 2 minor, 1 patch | HIGH |\n| Bootstrap         | 4.3.1           | 5.3.2          | ‚ö†Ô∏è Outdated | 1 major | HIGH |\n| React             | 18.2.0          | 18.2.0         | ‚úÖ Current | None | - |\n\n### CMS and Platform Detection\n\n| Platform | Detected Version | Latest Version | Status | EOL Status |\n|----------|------------------|----------------|--------|------------|\n| WordPress | 6.0.0           | 6.4.2          | ‚ö†Ô∏è Outdated | Supported |\n\n**CMS Detection Details**:\n- **Detection Method**: [Meta generator tag / Path patterns / HTTP headers / Cookies]\n- **Confidence Level**: [High / Medium / Low]\n- **Additional Information**: [Any relevant details about CMS configuration]\n\n---\n\n## Security Headers Analysis\n\n### Detected Security Headers\n\n| Header Name | Status | Configuration | Assessment |\n|-------------|--------|---------------|------------|\n| Content-Security-Policy | ‚ùå Missing | Not configured | CRITICAL |\n| Strict-Transport-Security | ‚úÖ Present | max-age=31536000; includeSubDomains | Secure |\n| X-Frame-Options | ‚úÖ Present | SAMEORIGIN | Secure |\n| X-Content-Type-Options | ‚úÖ Present | nosniff | Secure |\n| Referrer-Policy | ‚ùå Missing | Not configured | LOW |\n| Permissions-Policy | ‚ùå Missing | Not configured | LOW |\n\n### Missing Security Headers\n\nThe following security headers are not configured and should be implemented:\n\n1. **Content-Security-Policy (CSP)** - CRITICAL\n   - **Impact**: High risk of XSS attacks\n   - **Recommendation**: Implement strict CSP with nonce-based script loading\n\n2. **Referrer-Policy** - LOW\n   - **Impact**: Potential information leakage\n   - **Recommendation**: Set to `strict-origin-when-cross-origin`\n\n### Deprecated or Insecure Headers\n\n- **X-XSS-Protection**: [If present, flag as deprecated]\n  - **Status**: DEPRECATED\n  - **Recommendation**: Remove header or set to `0`; use CSP instead\n\n---\n\n## Security Findings\n\n### Critical Risk Findings\n\n#### C-001: Known CVE in jQuery Version\n\n**Library**: jQuery 3.5.0\n**CVE ID**: CVE-2020-11022, CVE-2020-11023\n**Risk Score**: 9.1 (Critical)\n**CVSS Vector**: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:N\n**Detection Source**: CDN URL pattern matching\n\n**Vulnerability Details**:\nCross-Site Scripting (XSS) vulnerability in jQuery versions before 3.5.0 allows attackers to execute arbitrary code by exploiting the HTML prefilter function.\n\n**Affected Versions**: jQuery < 3.5.0\n**Fixed in Version**: jQuery 3.5.0 and later\n\n**Impact**:\n- Remote code execution in user browsers\n- Session hijacking and credential theft\n- Phishing attacks via DOM manipulation\n\n**Recommendation**:\nUpgrade immediately to jQuery 3.7.1 (latest stable) or minimum 3.5.0\n\n**Remediation Steps**:\n1. Update CDN link to: `https://code.jquery.com/jquery-3.7.1.min.js`\n2. Test all jQuery-dependent functionality\n3. Review for deprecated jQuery APIs removed in newer versions\n\n**Fix Priority**: Immediate (within 24-48 hours)\n\n---\n\n### High Risk Findings\n\n#### H-001: Missing Content-Security-Policy Header\n\n**Risk Score**: 7.5 (High)\n**Category**: Security Misconfiguration\n**Detection**: HTTP header analysis\n\n**Issue Description**:\nThe website does not implement Content-Security-Policy (CSP) headers, leaving it vulnerable to Cross-Site Scripting (XSS) attacks and data injection attacks.\n\n**Impact**:\n- Increased risk of XSS exploitation\n- No protection against inline script injection\n- Unable to restrict resource loading sources\n- No mitigation for clickjacking via frame control\n\n**Recommendation**:\nImplement a strict Content-Security-Policy header\n\n**Remediation Example**:\n```\nContent-Security-Policy: default-src 'self';\n  script-src 'self' 'nonce-{random}' https://trusted-cdn.com;\n  style-src 'self' 'nonce-{random}';\n  img-src 'self' data: https:;\n  font-src 'self' https://fonts.gstatic.com;\n  connect-src 'self' https://api.example.com;\n  frame-ancestors 'none';\n  base-uri 'self';\n  form-action 'self'\n```\n\n**Fix Priority**: Within 1-2 weeks\n\n---\n\n#### H-002: Outdated Bootstrap with Known Vulnerabilities\n\n**Library**: Bootstrap 4.3.1\n**CVE ID**: CVE-2019-8331\n**Risk Score**: 7.2 (High)\n**Detection Source**: CDN URL pattern matching\n\n**Vulnerability Details**:\nXSS vulnerability in Bootstrap's tooltip and popover data-viewport feature allows arbitrary JavaScript execution.\n\n**Affected Versions**: Bootstrap < 4.3.1\n**Fixed in Version**: Bootstrap 4.3.1 (partially), fully fixed in 4.6.0\n\n**Impact**:\n- XSS attacks via tooltip/popover manipulation\n- DOM-based XSS exploitation\n\n**Recommendation**:\nUpgrade to Bootstrap 5.3.2 (latest stable) for full security and features\n\n**Migration Considerations**:\n- Bootstrap 5 removed jQuery dependency\n- Breaking changes in class names and JavaScript API\n- Allocate time for thorough testing\n\n**Fix Priority**: Within 2 weeks\n\n---\n\n### Medium Risk Findings\n\n#### M-001: WordPress Version Outdated\n\n**Platform**: WordPress 6.0.0\n**Latest Version**: 6.4.2\n**Risk Score**: 6.5 (Medium)\n**Detection**: Meta generator tag analysis\n\n**Issue Description**:\nWordPress installation is 4 minor versions behind the latest stable release, potentially missing critical security patches.\n\n**Known Issues in 6.0.x**:\n- Multiple security patches released in versions 6.1-6.4\n- Potential vulnerabilities in core, plugins, and themes\n- Missing performance and security improvements\n\n**Impact**:\n- Exposure to known WordPress core vulnerabilities\n- Potential plugin compatibility issues with outdated core\n- Missing security hardening features from newer versions\n\n**Recommendation**:\nUpgrade to WordPress 6.4.2\n\n**Remediation Steps**:\n1. Backup database and files\n2. Update all plugins and themes first\n3. Perform WordPress core update\n4. Test all functionality thoroughly\n5. Monitor error logs for issues\n\n**Fix Priority**: Within 1 month\n\n---\n\n### Low Risk Findings\n\n#### L-001: Missing Referrer-Policy Header\n\n**Risk Score**: 2.5 (Low)\n**Category**: Information Disclosure\n**Detection**: HTTP header analysis\n\n**Issue Description**:\nNo Referrer-Policy header is configured, potentially leaking sensitive information through referrer headers.\n\n**Impact**:\n- URL parameters may be leaked to external sites\n- Session tokens in URLs could be exposed\n- Minor privacy concern for users\n\n**Recommendation**:\nAdd Referrer-Policy header with secure configuration\n\n**Remediation**:\n```\nReferrer-Policy: strict-origin-when-cross-origin\n```\n\n**Fix Priority**: Within 2-3 months\n\n---\n\n## CDN and External Resource Analysis\n\n### Detected CDN Usage\n\n| CDN Provider | Resources | Assessment |\n|--------------|-----------|------------|\n| jsDelivr     | 3 libraries | ‚úÖ Reputable, SRI recommended |\n| Google Fonts | 2 font families | ‚úÖ Trusted source |\n| cdnjs        | 1 library | ‚úÖ Reputable, SRI recommended |\n\n**Recommendations**:\n- Consider implementing Subresource Integrity (SRI) hashes for all CDN resources\n- Evaluate self-hosting critical libraries for improved control\n- Monitor CDN availability and implement fallbacks\n\n---\n\n## OWASP Top 10 2021 Compliance Analysis\n\n| Risk Category | Compliance Status | Assessment |\n|---------------|-------------------|------------|\n| A01 - Broken Access Control | ‚ö†Ô∏è Unknown | Cannot assess from client-side scan |\n| A02 - Cryptographic Failures | ‚ö†Ô∏è Partial | HTTPS detected, HSTS configured |\n| A03 - Injection | ‚ùå At Risk | Missing CSP increases XSS risk |\n| A04 - Insecure Design | ‚ö†Ô∏è Unknown | Cannot assess from client-side scan |\n| A05 - Security Misconfiguration | ‚ùå Non-Compliant | Missing security headers, outdated dependencies |\n| A06 - Vulnerable Components | ‚ùå Non-Compliant | Multiple outdated libraries with CVEs |\n| A07 - Identity & Auth Failures | ‚ö†Ô∏è Unknown | Cannot assess from client-side scan |\n| A08 - Data Integrity Failures | ‚ö†Ô∏è Partial | No SRI detected on CDN resources |\n| A09 - Security Logging Failures | ‚ö†Ô∏è Unknown | Cannot assess from client-side scan |\n| A10 - SSRF | ‚ö†Ô∏è Unknown | Cannot assess from client-side scan |\n\n**Client-Side Scan Limitations**:\nThis scan focuses on publicly accessible client-side information. Server-side vulnerabilities, authentication mechanisms, and business logic flaws require source code access or penetration testing.\n\n---\n\n## Technical Recommendations\n\n### Immediate Actions (P0 - Critical)\n\n1. **Upgrade jQuery to 3.7.1** to patch CVE-2020-11022 and CVE-2020-11023\n2. **Implement Content-Security-Policy** header to mitigate XSS attacks\n3. **Review and patch all critical CVEs** in detected dependencies\n\n### High Priority Actions (P1 - Within 2 Weeks)\n\n1. **Upgrade Bootstrap to 5.3.2** to patch known XSS vulnerabilities\n2. **Implement missing HSTS header** (if not present) to enforce HTTPS\n3. **Configure X-Frame-Options** to prevent clickjacking\n4. **Add Subresource Integrity (SRI)** hashes to all CDN resources\n\n### Medium Priority Actions (P2 - Within 1-2 Months)\n\n1. **Update WordPress to 6.4.2** and all plugins/themes\n2. **Implement Referrer-Policy** header\n3. **Add Permissions-Policy** to restrict browser features\n4. **Review and update all medium-severity dependencies**\n\n### Security Hardening Recommendations\n\n1. **Implement Subresource Integrity (SRI)**:\n   ```html\n   <script src=\"https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js\"\n           integrity=\"sha384-[hash]\"\n           crossorigin=\"anonymous\"></script>\n   ```\n\n2. **Configure Comprehensive Security Headers**:\n   ```\n   Content-Security-Policy: default-src 'self'; script-src 'self' 'nonce-{random}';\n   Strict-Transport-Security: max-age=31536000; includeSubDomains; preload\n   X-Frame-Options: DENY\n   X-Content-Type-Options: nosniff\n   Referrer-Policy: strict-origin-when-cross-origin\n   Permissions-Policy: geolocation=(), microphone=(), camera=()\n   ```\n\n3. **Establish Dependency Update Policy**:\n   - Monitor security advisories for all dependencies\n   - Schedule quarterly dependency update reviews\n   - Implement automated vulnerability scanning in CI/CD\n   - Test updates in staging before production deployment\n\n---\n\n## Risk Mitigation Priorities\n\n### Phase 1: Critical Vulnerability Remediation (0-48 hours)\n\n- [ ] Upgrade jQuery from 3.5.0 to 3.7.1 (CVE-2020-11022, CVE-2020-11023)\n- [ ] Implement Content-Security-Policy header\n- [ ] Review and patch all critical (9.0+) CVSS vulnerabilities\n\n### Phase 2: High Risk Resolution (1-2 weeks)\n\n- [ ] Upgrade Bootstrap from 4.3.1 to 5.3.2 (CVE-2019-8331)\n- [ ] Configure HSTS header with includeSubDomains\n- [ ] Add X-Frame-Options header\n- [ ] Implement SRI for all CDN resources\n\n### Phase 3: Medium Risk and Platform Updates (1-2 months)\n\n- [ ] Update WordPress from 6.0.0 to 6.4.2\n- [ ] Add Referrer-Policy header\n- [ ] Configure Permissions-Policy header\n- [ ] Update all medium-severity dependencies\n\n### Phase 4: Security Hardening (2-3 months)\n\n- [ ] Establish automated dependency scanning\n- [ ] Implement dependency update policy\n- [ ] Configure security monitoring and alerting\n- [ ] Conduct follow-up security scan to verify remediation\n\n---\n\n## Summary\n\nThis web dependency security scan identified **X critical**, **Y high**, **Z medium**, and **W low** risk vulnerabilities across the target website. The analysis focused on publicly accessible client-side dependencies, CMS detection, and HTTP security configuration.\n\n**Detected Technology Stack**:\n- **Frontend Libraries**: [List detected libraries]\n- **CMS/Platform**: [Detected CMS if any]\n- **CDN Providers**: [List CDN providers]\n- **Security Headers**: X/8 configured\n\n**Critical Areas Requiring Immediate Attention**:\n- Outdated libraries with known critical CVEs\n- Missing Content-Security-Policy header\n- Lack of Subresource Integrity on CDN resources\n\n**Security Strengths**:\n- [List any positive findings, e.g., \"HTTPS properly configured with valid certificate\"]\n- [Any properly configured security headers]\n\n**Next Steps**:\n1. Prioritize critical and high-severity findings for immediate remediation\n2. Establish a dependency update schedule to prevent future vulnerabilities\n3. Consider implementing automated security scanning in development pipeline\n4. Schedule follow-up scan after remediation to verify fixes\n\n---\n\n**Scan Limitations**: This scan analyzes only client-side, publicly accessible information. It cannot detect server-side vulnerabilities, authentication bypasses, business logic flaws, or issues requiring source code access. For comprehensive security assessment, consider source code auditing and penetration testing.\n</template>\n\n## Severity Assessment Framework\n\nWhen determining severity for dependency vulnerabilities, apply these criteria:\n\n**CRITICAL (9.0-10.0)**:\n- Known CVE with CVSS score ‚â• 9.0\n- Actively exploited in the wild\n- Remote code execution without authentication\n- Complete system compromise possible\n\n**HIGH (7.0-8.9)**:\n- Known CVE with CVSS score 7.0-8.9\n- Major version outdated with security patches\n- Missing critical security headers (CSP, HSTS)\n- Exploitable with low complexity\n\n**MEDIUM (4.0-6.9)**:\n- Minor version outdated with available security updates\n- CMS or platform 2+ versions behind\n- Missing recommended security headers\n- Requires specific conditions for exploitation\n\n**LOW (0.1-3.9)**:\n- Patch version outdated\n- Minor security misconfigurations\n- Information disclosure risks\n- Defense-in-depth improvements\n\n## Best Practices\n\n1. **Comprehensive Detection**: Cast a wide net when detecting libraries. Many sites use multiple frameworks and versions.\n\n2. **Version Precision**: Extract exact version numbers when possible. Semantic versioning (major.minor.patch) is critical for CVE matching.\n\n3. **Context Awareness**: Consider the website's purpose and audience when assessing risk. E-commerce sites handling payments require more stringent security than informational blogs.\n\n4. **Actionable Remediation**: Every finding should include specific upgrade instructions, not just \"update to latest.\"\n\n5. **Migration Planning**: For major version upgrades (e.g., Bootstrap 4‚Üí5), acknowledge breaking changes and recommend staged rollout.\n\n6. **Client-Side Limitations**: Be transparent about what cannot be detected from client-side scans (server vulnerabilities, API security, authentication flaws).\n\n7. **False Positive Awareness**: Some version detection methods may be unreliable. Note confidence levels when uncertain.\n\n8. **Prioritize Exploitability**: Focus on vulnerabilities with known exploits and high exploitability scores.\n\n## Quality Assurance Checklist\n\nBefore finalizing a web dependency scan report, verify:\n\n- ‚úì **Have you used ONLY WebFetch or curl to fetch the website?** (NOT Playwright)\n- ‚úì Have HTTP response headers been successfully retrieved and analyzed?\n- ‚úì Have all script and link tags been parsed for library detection?\n- ‚úì Have CDN patterns been checked against all major providers?\n- ‚úì Has CMS detection been attempted using multiple methods?\n- ‚úì Have all critical security headers been checked?\n- ‚úì Has Context7 been used to verify latest versions for major libraries?\n- ‚úì Are remediation recommendations specific with version numbers?\n- ‚úì Have findings been assigned appropriate CVSS-based severity levels?\n- ‚úì Has the report template been followed exactly?\n- ‚úì Have client-side scan limitations been clearly documented?\n\n## Communication Guidelines\n\nWhen reporting findings:\n- Be direct about vulnerabilities while acknowledging scan limitations\n- Use precise technical terminology (CVE IDs, CVSS scores)\n- Provide concrete upgrade paths with version numbers\n- Include before/after examples for configuration changes\n- Balance urgency with practicality (acknowledge breaking changes in major upgrades)\n- Acknowledge properly configured security controls\n- Be transparent about detection confidence levels\n- Escalate critical CVEs with clear urgency\n\nRemember: This scan provides visibility into publicly accessible security posture. It complements but does not replace source code auditing, penetration testing, or authenticated security assessments. Focus on actionable findings that can be verified and fixed based on client-side information."
              }
            ]
          },
          {
            "name": "ai-workflow",
            "description": "AI-powered development workflow automation - Phase-based planning, implementation orchestration, and preflight code quality checks for efficient sub-agent execution",
            "source": "./plugins/ai-workflow",
            "category": null,
            "version": "1.0.3",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-workflow@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/workflow-implement-phases",
                "description": "Orchestrates multi-phase implementation from a plan document using intelligent parallel/sequential execution strategy.",
                "path": "plugins/ai-workflow/commands/workflow-implement-phases.md",
                "frontmatter": {
                  "name": "workflow-implement-phases",
                  "description": "Orchestrates multi-phase implementation from a plan document using intelligent parallel/sequential execution strategy."
                },
                "content": "# Implement Phases\n\nAnalyzes phases from a plan document and orchestrates implementation using sub-agents with optimal execution strategy.\n\n## Usage\n\n```bash\n/workflow-implement-phases                    # Search docs/plans/ and pick one\n/workflow-implement-phases @path/to/plan.md\n/workflow-implement-phases @path/to/plan.md --phases=1,2,3\n/workflow-implement-phases @path/to/plan.md --strategy=parallel|sequential|auto\n```\n\n## Arguments\n\n- `plan_file` (optional): Path to the plan document. If omitted, searches `docs/plans/` for existing plans\n- `--phases`: Comma-separated list of specific phases to implement (default: all)\n- `--strategy`: Force execution strategy. Default is `auto` (analyzed)\n\n## Instructions\n\n### If a plan file is provided:\nRead the plan file passed as an argument (e.g., `@docs/plans/my-plan.md`) and proceed with the workflow.\n\n### If no plan file is provided:\n1. Search for existing plan files in `docs/plans/` directory\n2. If plans are found, present them to the user and ask which one to implement\n3. If no plans are found, inform the user and suggest using `/workflow-plan-phases` to create one first\n\n## Critical Requirements\n\n**MANDATORY: Every phase MUST be implemented via a Task() sub-agent.**\n\n- NEVER implement any phase directly in the main agent conversation\n- Each phase gets its own dedicated sub-agent spawned via the Task tool\n- This ensures context isolation and prevents context saturation\n- Even single phases must use a sub-agent\n\n## Workflow\n\n1. **Read the plan file** ‚Äî Use the Read tool to load the plan document\n2. Parse plan document and extract phases\n3. Analyze dependencies (explicit and implicit)\n4. Determine optimal execution strategy (parallel/sequential/mixed)\n5. Present execution plan to user for confirmation\n6. **Execute via Task() sub-agents** ‚Äî Spawn one Task() sub-agent per phase (NEVER implement directly)\n7. Aggregate results and report"
              },
              {
                "name": "/workflow-plan-phases",
                "description": "Creates a structured implementation plan document with properly sized phases for efficient sub-agent execution.",
                "path": "plugins/ai-workflow/commands/workflow-plan-phases.md",
                "frontmatter": {
                  "name": "workflow-plan-phases",
                  "description": "Creates a structured implementation plan document with properly sized phases for efficient sub-agent execution."
                },
                "content": "# Plan Phases\n\nCreates a phased implementation plan from a feature description, optimized for context-efficient sub-agent execution.\n\n## Usage\n\n```bash\n/workflow-plan-phases <description>\n/workflow-plan-phases \"Build a user authentication system with OAuth, MFA, and session management\"\n/workflow-plan-phases --output=docs/plans/auth-system.md \"Build authentication system...\"\n```\n\n## Arguments\n\n- `description` (required): What the user wants to build\n- `--output`: Custom output path (default: `docs/plans/{slugified-name}.md`)\n\n## Instructions\n\n1. **Read the user's description** from the command argument\n2. **Ask clarifying questions** before creating the plan ‚Äî never skip this step\n3. **Wait for user responses** before proceeding\n4. **Create the plan document** following the plan-phases skill methodology\n5. **Save to `docs/plans/`** (create directory if needed) using a slugified filename\n6. **Present the plan** and ask if changes are needed\n7. **Stop** ‚Äî do not implement\n\n## Workflow\n\n1. Ask clarifying questions (always ‚Äî never skip)\n2. Size phases for context efficiency (30-50k tokens each)\n3. Use whole numbers only (no Phase 1.1 sub-phases)\n4. Define clear acceptance criteria per phase\n5. Map dependencies and recommend execution strategy\n6. Output structured markdown to docs/plans/\n7. **STOP** ‚Äî do not implement the plan\n\n## Important\n\n**This command only creates the plan. Do NOT proceed to implement any phases.**\n\nAfter the plan is written:\n- Present the plan document to the user\n- Ask if they want to make any changes\n- Inform them they can use `/workflow-implement-phases` when ready to execute\n\n**Never start writing code or implementing phases after creating the plan.**"
              },
              {
                "name": "/workflow-preflight",
                "description": "Run code quality checks (typecheck, lint, tests) - auto-detects configured tools and offers to fix issues.",
                "path": "plugins/ai-workflow/commands/workflow-preflight.md",
                "frontmatter": {
                  "name": "workflow-preflight",
                  "description": "Run code quality checks (typecheck, lint, tests) - auto-detects configured tools and offers to fix issues.",
                  "argument-hint": [
                    "--fix | --check-only | --verbose"
                  ],
                  "allowed-tools": "Bash, Read, Glob, Grep"
                },
                "content": "# Preflight Code Quality Checks\n\nYou are running a comprehensive preflight check on this codebase. This command discovers and runs configured quality checks including type checking, linting, and tests.\n\n## Arguments\n\n- `--fix` - Automatically attempt to fix issues without prompting\n- `--check-only` - Only report issues, never prompt to fix\n- `--verbose` - Show detailed output from all commands\n- No arguments - Interactive mode (default): prompt before fixing\n\nUser provided: $ARGUMENTS\n\n## Step 1: Discovery Phase\n\nFirst, analyze the project to discover configured quality tools. Check for:\n\n### Package Manager & Config Files\n- `package.json` - Check for scripts: `lint`, `typecheck`, `type-check`, `tsc`, `test`, `check`, `validate`\n- `tsconfig.json` / `jsconfig.json` - TypeScript/JavaScript configuration\n- `.eslintrc*`, `eslint.config.*` - ESLint configuration\n- `biome.json`, `biome.jsonc` - Biome configuration\n- `.prettierrc*`, `prettier.config.*` - Prettier configuration\n- `deno.json` / `deno.jsonc` - Deno configuration\n- `.stylelintrc*` - Stylelint configuration\n\n### Python Projects\n- `pyproject.toml` - Check for ruff, mypy, pytest, black, isort configs\n- `setup.py` / `setup.cfg` - Legacy Python config\n- `requirements.txt` / `requirements-dev.txt` - Dependencies\n- `mypy.ini` / `.mypy.ini` - MyPy configuration\n- `ruff.toml` / `.ruff.toml` - Ruff configuration\n- `pytest.ini` / `pyproject.toml [tool.pytest]` - Pytest configuration\n- `tox.ini` - Tox configuration\n\n### .NET Projects\n- `*.csproj` / `*.fsproj` / `*.vbproj` - .NET project files\n- `*.sln` - Solution files\n- `.editorconfig` - Editor configuration with .NET analyzers\n- `Directory.Build.props` - MSBuild properties\n\n### Go Projects\n- `go.mod` - Go module\n- `.golangci.yml` / `.golangci.yaml` - GolangCI-Lint configuration\n\n### Rust Projects\n- `Cargo.toml` - Check for clippy, rustfmt\n- `rustfmt.toml` / `.rustfmt.toml` - Rustfmt configuration\n- `clippy.toml` / `.clippy.toml` - Clippy configuration\n\n### Other\n- `Makefile` / `makefile` - Check for lint/test/check targets\n- `.pre-commit-config.yaml` - Pre-commit hooks\n- `justfile` - Just command runner\n\n## Step 2: Report Discovery\n\nPresent a summary of what was discovered:\n\n```\nPreflight Discovery Summary\n\nProject Type: [Node.js / Python / .NET / Go / Rust / Multi-language]\n\nType Checking: [tool name] via [config file]\nLinting: [tool name] via [config file]\nTesting: [tool name] via [config file]\nFormatting: [tool name] via [config file]\nNot configured: [any missing categories]\n\nReady to run checks?\n```\n\n## Step 3: Execute Checks\n\nRun the discovered checks in this order:\n1. **Type checking** (fastest feedback on type errors)\n2. **Linting** (code quality issues)\n3. **Formatting check** (style consistency - check only, don't auto-fix yet)\n4. **Tests** (run last as they take longest)\n\nFor each check, report:\n- Pass - no issues found\n- Warnings - non-blocking issues\n- Fail - blocking issues found\n\n### Common Commands by Ecosystem\n\n**Node.js/TypeScript:**\n- TypeScript: `npx tsc --noEmit` or `npm run typecheck`\n- ESLint: `npx eslint . --max-warnings=0` or `npm run lint`\n- Biome: `npx biome check .`\n- Tests: `npm test` or `npx jest` or `npx vitest run`\n\n**Python:**\n- MyPy: `mypy .` or `mypy src/`\n- Ruff: `ruff check .`\n- Pytest: `pytest` or `python -m pytest`\n- Black check: `black --check .`\n\n**.NET:**\n- Build with warnings: `dotnet build --warnaserror`\n- Format check: `dotnet format --verify-no-changes`\n- Tests: `dotnet test`\n\n**Go:**\n- Type check: `go build ./...`\n- Lint: `golangci-lint run`\n- Tests: `go test ./...`\n\n**Rust:**\n- Check: `cargo check`\n- Clippy: `cargo clippy -- -D warnings`\n- Tests: `cargo test`\n- Format check: `cargo fmt --check`\n\n## Step 4: Results Summary\n\nPresent results in a clear summary:\n\n```\nPreflight Results\n\nType Checking  Passed\nLinting        3 errors, 2 warnings\nFormatting     5 files need formatting\nTests          42 passed, 0 failed\n\nOverall: Issues found\n```\n\n## Step 5: Fix Prompt (Interactive Mode)\n\nIf issues were found AND user didn't pass `--check-only`:\n\n**If `--fix` was passed:** Proceed directly to fixing without prompting.\n\n**Otherwise, ask:**\n\n```\nWould you like me to attempt fixes?\n\n[1] Fix all auto-fixable issues (lint --fix, format, etc.)\n[2] Fix only linting issues\n[3] Fix only formatting issues\n[4] Show me the specific issues first\n[5] Skip fixes - I'll handle it manually\n\nEnter choice (1-5):\n```\n\nWait for user input before proceeding.\n\n## Step 6: Apply Fixes (if requested)\n\nWhen fixing:\n1. Run auto-fix commands (e.g., `eslint --fix`, `ruff --fix`, `prettier --write`)\n2. Re-run the checks to verify fixes\n3. Report what was fixed and what still needs manual attention\n\n```\nFix Results\n\nAuto-fixed:\n  3 linting errors resolved\n  5 files formatted\n\nStill needs attention:\n  1 type error in src/utils.ts:42\n     Property 'foo' does not exist on type 'Bar'\n```\n\n## Important Guidelines\n\n1. **Never run fix commands without user consent** unless `--fix` was explicitly passed\n2. **Preserve user's working state** - don't modify files unexpectedly\n3. **Respect existing configuration** - use project's own scripts when available (e.g., `npm run lint` over raw `eslint`)\n4. **Handle missing tools gracefully** - if a tool isn't installed, note it and continue\n5. **Provide actionable feedback** - include file paths and line numbers for manual fixes\n6. **Consider CI alignment** - mention if checks match CI configuration\n\n## Error Handling\n\nIf a tool fails to run:\n```\nCould not run [tool]: [error message]\n   Suggestion: [how to install or configure]\n```\n\nIf no quality tools are configured:\n```\nNo quality tools detected in this project.\n\nWould you like me to help set up:\n[1] TypeScript type checking\n[2] ESLint for linting\n[3] Prettier for formatting\n[4] A testing framework\n[5] Skip setup\n```"
              }
            ],
            "skills": [
              {
                "name": "implement-phases",
                "description": "Use when implementing phases from a plan document, executing phased implementations, orchestrating sub-agents for phase work, or when /workflow-implement-phases command is invoked. Provides dependency analysis and parallel/sequential execution strategies.",
                "path": "plugins/ai-workflow/skills/implement-phases/SKILL.md",
                "frontmatter": {
                  "name": "implement-phases",
                  "description": "Use when implementing phases from a plan document, executing phased implementations, orchestrating sub-agents for phase work, or when /workflow-implement-phases command is invoked. Provides dependency analysis and parallel/sequential execution strategies."
                },
                "content": "# Phase Implementation Orchestration Skill\n\nThis skill provides the methodology for analyzing plan documents, determining optimal execution strategies, and coordinating phase implementation through sub-agents.\n\n## Overview\n\nWhen implementing phases from a plan document, the orchestrator must:\n1. Extract and understand each phase's scope\n2. Detect dependencies (explicit and implicit)\n3. Choose optimal execution strategy\n4. Coordinate sub-agents for implementation\n5. Handle failures gracefully\n6. Aggregate and report results\n\n---\n\n## CRITICAL: Mandatory Sub-Agent Requirement\n\n**YOU MUST USE THE TASK TOOL TO SPAWN A SUB-AGENT FOR EVERY PHASE IMPLEMENTATION.**\n\nThis is a non-negotiable requirement. The orchestrator (main agent) is ONLY responsible for:\n- Reading and parsing the plan document\n- Analyzing dependencies\n- Determining execution strategy\n- Presenting the plan to the user\n- Spawning Task() sub-agents for each phase\n- Aggregating results after sub-agents complete\n\n**The orchestrator MUST NOT:**\n- Implement any phase directly in the main conversation\n- Write code, create files, or make changes for any phase\n- Skip sub-agent spawning for \"simple\" phases\n- Combine multiple phases into a single implementation\n\n**Why this matters:**\n- Context isolation: Each sub-agent has fresh context, preventing saturation\n- Parallelization: Independent phases can run in parallel via multiple Task() calls\n- Failure isolation: A failed phase doesn't corrupt the main agent's state\n- Results tracking: Sub-agents write structured results to coordination directory\n\n**Correct pattern:**\n```\n# For each phase (or group of parallel phases), spawn Task() sub-agents\nTask(\n  subagent_type=\"general-purpose\",\n  prompt=\"[Phase implementation prompt with full spec and acceptance criteria]\",\n  description=\"Implement phase-1: [name]\"\n)\n```\n\n**WRONG pattern (never do this):**\n```\n# Never implement phases directly\nEdit(file_path=\"src/feature.ts\", ...)  # WRONG - orchestrator should not edit files\nWrite(file_path=\"src/new-file.ts\", ...)  # WRONG - orchestrator should not create files\n```\n\n---\n\n## Step 1: Parse the Plan Document\n\nExtract from the plan file:\n\n```\nphases = [\n  {\n    id: \"phase-1\",\n    name: \"Human-readable name\",\n    spec: \"Full specification text\",\n    acceptance_criteria: [\"criterion 1\", \"criterion 2\"],\n    explicit_dependencies: [\"phase-0\"]  // if stated\n  },\n  ...\n]\n```\n\n### Parsing Heuristics\n\nLook for phase definitions in these formats:\n- `## Phase 1:`, `### Phase 1 -`, `**Phase 1**`\n- `# Step 1`, `## Step 1:`\n- Numbered sections: `1.`, `1)`, `(1)`\n- YAML frontmatter with phase definitions\n\nExtract acceptance criteria from:\n- Bullet points under \"Acceptance Criteria\", \"Done when\", \"Requirements\"\n- Checkboxes: `- [ ] criterion`\n- \"Must have\", \"Should\", \"Will\" statements\n\n---\n\n## Step 2: Dependency Analysis\n\n### Explicit Dependencies (Highest Confidence)\n\nPatterns that indicate explicit ordering:\n- \"Phase 2 requires Phase 1\"\n- \"After completing X, proceed to Y\"\n- \"Once X is done, Y can begin\"\n- \"Depends on:\", \"Prerequisites:\", \"Requires:\"\n- \"Do not start until X is complete\"\n\n### Implicit Dependencies (Analyze Code Paths)\n\n**Data/Schema Dependencies**\n```\nDEPENDENT if Phase B:\n- References database tables created in Phase A\n- Uses migrations from Phase A\n- Queries data that Phase A populates\n```\n\n**API/Interface Dependencies**\n```\nDEPENDENT if Phase B:\n- Calls endpoints defined in Phase A\n- Imports services/modules created in Phase A\n- Uses types/interfaces exported by Phase A\n```\n\n**File Dependencies**\n```\nDEPENDENT if Phase B:\n- Modifies files created in Phase A\n- Extends classes defined in Phase A\n- Imports from paths that Phase A creates\n```\n\n**Configuration Dependencies**\n```\nDEPENDENT if Phase B:\n- Requires environment variables Phase A documents\n- Uses config keys Phase A introduces\n- Needs secrets/credentials Phase A sets up\n```\n\n**Build Dependencies**\n```\nDEPENDENT if Phase B:\n- Requires compiled output from Phase A\n- Uses generated code from Phase A\n- Needs artifacts (bundles, images) from Phase A\n```\n\n### Independence Indicators (Safe to Parallelize)\n\nHigh confidence parallel candidates:\n- Phases operate on completely separate directories\n- Phases add isolated features (no shared imports)\n- Phases are orthogonal concerns (logging vs caching vs monitoring)\n- Plan explicitly states \"can be done in any order\"\n- Phases are different layers (frontend vs backend vs infra)\n\n### Dependency Detection Algorithm\n\n```\nfor each phase_b in phases:\n  for each phase_a in phases where phase_a != phase_b:\n\n    # Check explicit\n    if phase_b.spec mentions phase_a.id as dependency:\n      add_dependency(phase_b, phase_a, confidence=HIGH)\n\n    # Check implicit - file paths\n    files_created_by_a = extract_file_paths(phase_a.spec)\n    files_referenced_by_b = extract_file_paths(phase_b.spec)\n    if intersection(files_created_by_a, files_referenced_by_b):\n      add_dependency(phase_b, phase_a, confidence=MEDIUM)\n\n    # Check implicit - imports/types\n    exports_from_a = extract_exports(phase_a.spec)\n    imports_in_b = extract_imports(phase_b.spec)\n    if intersection(exports_from_a, imports_in_b):\n      add_dependency(phase_b, phase_a, confidence=MEDIUM)\n\n    # Check implicit - keywords\n    if phase_b.spec contains \"after {phase_a.name}\":\n      add_dependency(phase_b, phase_a, confidence=HIGH)\n    if phase_b.spec contains \"using {artifact from phase_a}\":\n      add_dependency(phase_b, phase_a, confidence=MEDIUM)\n```\n\n---\n\n## Step 3: Build Execution Graph\n\n### Strategy Selection\n\n**PARALLEL** - All phases run simultaneously:\n```\nConditions:\n- No dependencies between any phases\n- Phases operate on isolated code paths\n- No shared files being modified\n- Low risk of merge conflicts\n\nBenefits:\n- Fastest total execution time\n- Maximum context isolation\n\nRisks:\n- Potential merge conflicts if analysis missed shared files\n```\n\n**SEQUENTIAL** - Phases run one after another:\n```\nConditions:\n- Linear dependency chain exists\n- Each phase depends on previous\n- Shared state or files across phases\n- High integration complexity\n\nBenefits:\n- Safest execution\n- Each phase has full context from prior phases\n- Easier debugging\n\nRisks:\n- Slowest execution\n- Context may still accumulate if not managed\n```\n\n**MIXED** - Parallel groups with sequential ordering between groups:\n```\nConditions:\n- Some phases are independent (parallel within group)\n- Some phases have dependencies (sequential between groups)\n\nAlgorithm:\n1. Build dependency graph\n2. Topologically sort into levels\n3. Phases at same level (no dependencies on each other) run parallel\n4. Wait for level to complete before starting next level\n\nExample:\n  Level 0: [phase-1, phase-3]     # No dependencies, run parallel\n  Level 1: [phase-2]              # Depends on phase-1\n  Level 2: [phase-4, phase-5]     # Both depend on phase-2\n```\n\n### Execution Plan Template\n\nPresent to user before executing:\n\n```markdown\n## Phase Execution Plan\n\n### Phases Analyzed\n| Phase | Description | Dependencies | Level |\n|-------|-------------|--------------|-------|\n| phase-1 | Create user model | None | 0 |\n| phase-3 | Add logging | None | 0 |\n| phase-2 | Authentication | phase-1 | 1 |\n| phase-4 | User API | phase-2 | 2 |\n| phase-5 | Admin API | phase-2 | 2 |\n\n### Execution Strategy: **MIXED**\n\n```\nLevel 0 (parallel):  phase-1 -+- phase-3\n                              |\nLevel 1 (sequential): phase-2 <+\n                              |\nLevel 2 (parallel):  phase-4 -+- phase-5\n```\n\n### Dependency Reasoning\n- phase-1 <-> phase-3: Independent (separate directories)\n- phase-2 -> phase-1: Uses User model (import dependency)\n- phase-4 -> phase-2: Uses auth middleware (API dependency)\n- phase-5 -> phase-2: Uses auth middleware (API dependency)\n- phase-4 <-> phase-5: Independent (separate route files)\n\n### Estimated Execution\n- 3 sub-agent cycles (parallel reduces from 5 sequential)\n\nProceed? [Y/n/modify]\n```\n\n---\n\n## Step 4: Execute Phases\n\n**REMINDER: You MUST use Task() sub-agents for ALL phase implementations. Never implement directly.**\n\n### Coordination Setup\n\n```bash\nmkdir -p .claude/phase-coordination/{artifacts,results}\n```\n\n### Sub-Agent Prompt Template\n\nWhen spawning Task() for each phase (REQUIRED for every phase):\n\n```markdown\n## Phase Implementation Task\n\n**Phase ID**: {phase_id}\n**Phase Name**: {phase_name}\n\n### Specification\n{full_phase_spec}\n\n### Acceptance Criteria\n{acceptance_criteria_list}\n\n### Context from Prior Phases\n{if sequential or mixed, include summary from dependency phases}\n\nRead artifacts from: `.claude/phase-coordination/artifacts/`\nWrite your artifacts to: `.claude/phase-coordination/artifacts/{phase_id}/`\n\n### Required Outputs\n\n1. **Implement the phase** according to specification\n\n2. **Create results file** at `.claude/phase-coordination/results/{phase_id}.md`:\n\n```markdown\n# {phase_id} Results\n\n## Summary\n[2-3 sentences on what was implemented]\n\n## Files Changed\n- `path/to/file` - [description]\n\n## Key Decisions\n- [Decision]: [Rationale]\n\n## Interfaces Exposed\n[Types, functions, or contracts for downstream phases]\n\n## Deviations\n[Any deviations from spec with justification]\n\n## Verification\n[How to verify this phase works]\n```\n\n3. **Export any shared artifacts** (types, interfaces, schemas) to the artifacts directory\n\n### Quality Standards\n- No placeholder code or TODOs\n- Match existing project conventions\n- Handle errors appropriately\n- Include inline documentation for complex logic\n```\n\n### Parallel Execution Pattern\n\n**Use multiple Task() calls in a SINGLE message to execute phases in parallel:**\n\n```\n# Spawn all phases in current level simultaneously using multiple Task() calls in ONE message\n# This is the ONLY way to achieve true parallelization\n\n# In your response, include ALL of these Task() calls together:\nTask(\n  subagent_type=\"general-purpose\",\n  prompt=build_phase_prompt(phase_1),\n  description=\"Implement phase-1: [name]\"\n)\nTask(\n  subagent_type=\"general-purpose\",\n  prompt=build_phase_prompt(phase_2),\n  description=\"Implement phase-2: [name]\"\n)\nTask(\n  subagent_type=\"general-purpose\",\n  prompt=build_phase_prompt(phase_3),\n  description=\"Implement phase-3: [name]\"\n)\n\n# All tasks run in parallel when called in the same message\n# Wait for all to complete\n# Collect results from .claude/phase-coordination/results/\n```\n\n### Sequential Execution Pattern\n\n**Each phase STILL requires its own Task() sub-agent, just called one at a time:**\n\n```\nfor phase in topologically_sorted_phases:\n  # Build context from dependencies\n  dependency_context = \"\"\n  for dep in phase.dependencies:\n    dep_results = read(f\".claude/phase-coordination/results/{dep.id}.md\")\n    dependency_context += f\"\\n### Context from {dep.id}\\n{dep_results}\"\n\n  # Execute with dependency context - MUST use Task(), never implement directly\n  Task(\n    subagent_type=\"general-purpose\",\n    prompt=build_phase_prompt(phase, dependency_context),\n    description=\"Implement {phase.id}: {phase.name}\"\n  )\n\n  # Wait for sub-agent to complete\n  # Verify results before proceeding to next phase\n  verify_phase_results(phase)\n```\n\n---\n\n## Step 5: Error Handling\n\n### Phase Failure\n\n```\nIf a phase fails:\n1. Capture error output and partial results\n2. Mark phase as FAILED in coordination directory\n3. Check dependency graph:\n   - SKIP all phases that depend on failed phase\n   - CONTINUE with independent phases\n4. Report failure clearly in final summary\n```\n\n### Dependency Conflict\n\n```\nIf sub-agent reports unexpected dependency:\n1. Pause execution\n2. Present conflict to user\n3. Options:\n   a. Re-analyze with new information\n   b. Force continue (user accepts risk)\n   c. Abort and revise plan\n```\n\n### Uncertain Dependencies\n\n```\nWhen confidence is low:\n1. Default to sequential (safer)\n2. Flag uncertainty in execution plan\n3. Ask user to confirm before proceeding\n```\n\n---\n\n## Step 6: Results Aggregation\n\n### Final Summary Template\n\n```markdown\n## Implementation Complete\n\n### Execution Summary\n| Phase | Status | Files | Duration |\n|-------|--------|-------|----------|\n| phase-1 | Done | 3 | ~1 cycle |\n| phase-3 | Done | 1 | ~1 cycle |\n| phase-2 | Done | 4 | ~1 cycle |\n| phase-4 | Done | 2 | ~1 cycle |\n| phase-5 | Partial | 1 | ~1 cycle |\n\n### Strategy Used\nMixed parallel/sequential across 3 levels\n\n### All Files Modified\n- `src/models/user.ts` (phase-1)\n- `src/middleware/logging.ts` (phase-3)\n- `src/middleware/auth.ts` (phase-2)\n- `src/routes/users.ts` (phase-4)\n- `src/routes/admin.ts` (phase-5, incomplete)\n\n### Key Decisions Across Phases\n[Aggregated from phase results]\n\n### Integration Points to Verify\n- [ ] User model imports correctly in auth\n- [ ] Auth middleware registered in app\n- [ ] Logging captures auth events\n\n### Issues Encountered\n- phase-5: Admin role enum not defined, implemented basic version\n\n### Recommended Next Steps\n1. Run test suite: `npm test`\n2. Manually verify integration points\n3. Review phase-5 partial implementation\n4. Address any flagged deviations\n\n### Artifacts Location\nFull details: `.claude/phase-coordination/results/`\nShared artifacts: `.claude/phase-coordination/artifacts/`\n```\n\n---\n\n## Cleanup\n\nAfter user confirms completion:\n\n```bash\n# Option to preserve for debugging\nmv .claude/phase-coordination .claude/phase-coordination-{timestamp}\n\n# Or clean up\nrm -rf .claude/phase-coordination\n```\n\nRecommend user run `/compact` after completion since detailed context is persisted to files."
              },
              {
                "name": "plan-phases",
                "description": "Use when creating implementation plans, phase planning documents, breaking features into phases, or when /workflow-plan-phases command is invoked. Provides methodology for context-efficient phase sizing and dependency analysis.",
                "path": "plugins/ai-workflow/skills/plan-phases/SKILL.md",
                "frontmatter": {
                  "name": "plan-phases",
                  "description": "Use when creating implementation plans, phase planning documents, breaking features into phases, or when /workflow-plan-phases command is invoked. Provides methodology for context-efficient phase sizing and dependency analysis."
                },
                "content": "# Phase Planning Skill\n\nThis skill provides methodology for creating implementation plans that are optimized for sub-agent execution, with properly sized phases that respect context window constraints.\n\n## Overview\n\nA good phase plan:\n1. Breaks work into independently executable chunks\n2. Sizes phases to fit within sub-agent context budgets\n3. Minimizes dependencies between phases where possible\n4. Provides clear acceptance criteria for verification\n5. Uses whole number phases only (no 1.1, 1.2 sub-phases)\n\n---\n\n## Step 1: Gather Requirements (Always Ask Questions)\n\n**Never skip this step.** Even if the description seems complete, clarifying questions:\n- Reveal implicit assumptions\n- Uncover edge cases\n- Establish scope boundaries\n- Identify existing constraints\n\n### Question Categories\n\n**Scope & Boundaries**\n- What's explicitly OUT of scope?\n- Is this greenfield or integrating with existing code?\n- Are there existing patterns/conventions to follow?\n- What's the target completion state? MVP or production-ready?\n\n**Technical Context**\n- What's the tech stack? (language, framework, database)\n- Are there existing models/services this builds on?\n- What authentication/authorization exists?\n- Are there performance requirements?\n\n**Integration Points**\n- What external services/APIs are involved?\n- Are there existing interfaces to conform to?\n- What other systems will consume this?\n- Are there upstream dependencies not yet built?\n\n**User Experience**\n- Who are the users? (end users, admins, developers, APIs)\n- What's the primary workflow/happy path?\n- What error states need handling?\n- Are there accessibility requirements?\n\n**Constraints**\n- Security requirements? (OWASP, compliance, data sensitivity)\n- Testing requirements? (coverage, E2E, specific frameworks)\n- Documentation requirements?\n- Deployment constraints?\n\n### Question Presentation Format\n\nPresent 3-5 targeted questions based on the description:\n\n```markdown\nBefore I create the implementation plan, I have a few questions:\n\n1. **Existing Code**: Is this a new feature in an existing codebase, or greenfield?\n   If existing, what patterns should I follow?\n\n2. **Auth Context**: You mentioned user roles - is there an existing auth system\n   to integrate with, or is that part of this work?\n\n3. **Data Layer**: What database are you using? Are there existing models\n   this relates to?\n\n4. **Scope Boundary**: Should this include the admin UI for managing X,\n   or just the core functionality?\n\n5. **Testing**: What level of test coverage do you need? Unit only,\n   or integration/E2E as well?\n```\n\nWait for answers before proceeding.\n\n---\n\n## Step 2: Phase Sizing Guidelines\n\n### Context Budget Per Phase\n\nTarget each phase to consume **30-50k tokens** of sub-agent context:\n- ~10k tokens: Phase spec + project context (CLAUDE.md, conventions)\n- ~15-25k tokens: File reads and code analysis\n- ~10-15k tokens: Implementation work and verification\n\n### Sizing Heuristics\n\n**RIGHT-SIZED Phase** (~30-50k tokens):\n- Creates/modifies 2-5 files\n- Implements 1-2 closely related features\n- Can be verified with a clear test or check\n- Completes in one sub-agent session without compacting\n\n**TOO LARGE Phase** (>60k tokens - split it):\n- Creates/modifies 6+ files\n- Implements multiple unrelated features\n- Requires reading large portions of codebase\n- Description exceeds ~500 words\n- Contains words like \"and also\", \"as well as\", \"plus\"\n\n**TOO SMALL Phase** (<15k tokens - combine it):\n- Single file change\n- Config-only changes\n- Simple additions with no logic\n- Could be done in 5 minutes manually\n\n### Splitting Strategy\n\nWhen a phase is too large, split by:\n\n1. **Layer**: Separate data model, business logic, API, UI\n2. **Entity**: One phase per core entity/resource\n3. **Operation**: Separate CRUD operations if complex\n4. **Concern**: Separate core logic from error handling, logging, etc.\n\n**Example - Too Large:**\n```\nPhase 1: Build user management with registration, login, profile\nediting, password reset, email verification, and admin user listing\n```\n\n**Split Into:**\n```\nPhase 1: User model and registration endpoint\nPhase 2: Login and session management\nPhase 3: Password reset flow\nPhase 4: Email verification\nPhase 5: Profile editing\nPhase 6: Admin user listing\n```\n\n---\n\n## Step 3: Dependency Planning\n\n### Dependency Types to Track\n\n**Hard Dependencies** (must complete first):\n- Schema/model that other phases import\n- Auth middleware other phases use\n- Shared utilities or helpers\n- Base classes being extended\n\n**Soft Dependencies** (preferred order, but parallelizable):\n- Related features that share patterns\n- Test setup that other tests use\n- Documentation that references implementation\n\n**No Dependencies** (fully parallel):\n- Isolated features\n- Different layers of same feature (if interfaces defined upfront)\n- Independent utilities\n\n### Minimizing Dependencies\n\nStrategies to reduce coupling between phases:\n\n1. **Define interfaces early**: First phase exports types/interfaces,\n   later phases implement against them\n\n2. **Stub dependencies**: Phase can stub what it needs, later phase\n   replaces stub with real implementation\n\n3. **Feature flags**: Phases can merge independently, enable via flag\n\n4. **Vertical slices**: Each phase is a thin vertical slice through all\n   layers rather than horizontal layers\n\n---\n\n## Step 4: Plan Document Structure\n\n### File Location\n\n```\ndocs/plans/{feature-name}.md\n```\n\nSlugify the feature name:\n- \"User Authentication System\" -> `user-authentication-system.md`\n- \"API Rate Limiting\" -> `api-rate-limiting.md`\n\n### Document Template\n\n```markdown\n# {Feature Name} Implementation Plan\n\n## Overview\n{2-3 sentence summary of what this plan delivers}\n\n## Goals\n- {Primary goal}\n- {Secondary goal}\n- {Tertiary goal}\n\n## Non-Goals (Out of Scope)\n- {Explicit exclusion 1}\n- {Explicit exclusion 2}\n\n## Technical Context\n- **Stack**: {language, framework, database}\n- **Existing Code**: {relevant existing modules/patterns}\n- **Integration Points**: {external services, APIs}\n\n---\n\n## Phase 1: {Phase Name}\n\n### Objective\n{One sentence describing what this phase accomplishes}\n\n### Specification\n{Detailed description of the work. Include:}\n- What to create/modify\n- Specific requirements\n- Edge cases to handle\n- Error handling expectations\n\n### Files to Create/Modify\n- `path/to/file.ts` - {purpose}\n- `path/to/other.ts` - {purpose}\n\n### Acceptance Criteria\n- [ ] {Verifiable criterion 1}\n- [ ] {Verifiable criterion 2}\n- [ ] {Verifiable criterion 3}\n\n### Dependencies\n- **Requires**: {None | Phase X}\n- **Blocks**: {Phase Y, Phase Z}\n\n### Estimated Scope\n- Files: {2-5}\n- Complexity: {Low | Medium | High}\n\n---\n\n## Phase 2: {Phase Name}\n\n{Same structure as Phase 1}\n\n---\n\n## Execution Strategy\n\n### Dependency Graph\n```\nPhase 1 --+-- Phase 3\n          |\nPhase 2 --+\n          |\nPhase 4 <-+-- Phase 5\n```\n\n### Recommended Execution\n- **Parallel Group 1**: Phase 1, Phase 2\n- **Sequential**: Phase 3 (after Phase 1)\n- **Parallel Group 2**: Phase 4, Phase 5 (after Phase 3)\n\n---\n\n## Verification Checklist\n\nAfter all phases complete:\n- [ ] {Integration verification 1}\n- [ ] {Integration verification 2}\n- [ ] {End-to-end test}\n\n## Open Questions\n\n- {Any unresolved decisions to revisit}\n```\n\n---\n\n## Step 5: Phase Writing Guidelines\n\n### Phase Names\n\nUse action-oriented names:\n```\nGood:\n- \"Create User Model and Repository\"\n- \"Implement JWT Authentication\"\n- \"Add Rate Limiting Middleware\"\n- \"Build Password Reset Flow\"\n\nBad:\n- \"User Stuff\"\n- \"Part 1\"\n- \"Backend Work\"\n- \"Misc Improvements\"\n```\n\n### Specification Writing\n\nBe specific enough that a sub-agent can implement without guessing:\n\n```\nVague:\n\"Add user authentication\"\n\nSpecific:\n\"Create POST /api/auth/login endpoint that:\n- Accepts { email, password } body\n- Validates against User model\n- Returns JWT token with 24h expiry on success\n- Returns 401 with { error: 'Invalid credentials' } on failure\n- Rate limits to 5 attempts per 15 minutes per IP\n- Logs failed attempts with IP and email (not password)\"\n```\n\n### Acceptance Criteria\n\nWrite testable criteria:\n\n```\nNot Testable:\n- \"Works correctly\"\n- \"Handles errors\"\n- \"Is secure\"\n\nTestable:\n- \"POST /api/users returns 201 with user object (excluding password)\"\n- \"Invalid email format returns 400 with validation error\"\n- \"Passwords are hashed with bcrypt cost factor 12\"\n- \"JWT tokens expire after 24 hours\"\n```\n\n---\n\n## Anti-Patterns to Avoid\n\n### No Sub-Phases\n```\nWrong:\nPhase 1: Setup\n  Phase 1.1: Database schema\n  Phase 1.2: Model classes\n  Phase 1.3: Repository layer\n\nRight:\nPhase 1: Database Schema and Migrations\nPhase 2: User Model and Repository\nPhase 3: Authentication Service\n```\n\n### No Kitchen Sink Phases\n```\nWrong:\nPhase 3: Implement all remaining features including search,\nfiltering, pagination, sorting, export, and batch operations\n\nRight:\nPhase 3: List Endpoint with Pagination\nPhase 4: Search and Filtering\nPhase 5: Sorting Options\nPhase 6: Export Functionality\nPhase 7: Batch Operations\n```\n\n### No Vague Phases\n```\nWrong:\nPhase 2: Handle edge cases and fix bugs\n\nRight:\nPhase 2: Input Validation and Error Handling\n- Validate email format, password strength\n- Handle duplicate email registration\n- Return structured error responses\n```\n\n### No Dependency Spaghetti\n```\nWrong:\nPhase 1 depends on Phase 3\nPhase 3 depends on Phase 2\nPhase 2 depends on Phase 4\nPhase 4 depends on Phase 1  (circular!)\n\nRight:\nPhase 1: Foundation (no dependencies)\nPhase 2: Core Logic (depends on 1)\nPhase 3: Extended Features (depends on 2)\nPhase 4: Polish and Edge Cases (depends on 3)\n```\n\n---\n\n## Final Checklist\n\nBefore delivering plan:\n\n- [ ] Asked clarifying questions and incorporated answers\n- [ ] Each phase is 30-50k tokens of work (2-5 files)\n- [ ] No sub-phases (whole numbers only)\n- [ ] Every phase has clear acceptance criteria\n- [ ] Dependencies are explicit and acyclic\n- [ ] Specifications are detailed enough to implement without guessing\n- [ ] File saved to docs/plans/{feature-name}.md\n\n---\n\n## IMPORTANT: Planning Only ‚Äî Do Not Implement\n\n**This skill is for planning only. After creating the plan, STOP.**\n\nDo NOT:\n- Start implementing any phases\n- Write any code\n- Create any files other than the plan document\n- Begin execution automatically\n\nAfter the plan is complete:\n1. Present the plan document to the user\n2. Ask if they want to make any revisions\n3. Inform them to use `/workflow-implement-phases` or the `implement-phases` skill when ready to execute\n\nThe user decides when to proceed with implementation."
              },
              {
                "name": "preflight-checks",
                "description": "Comprehensive code quality verification system for running type checking, linting, and tests. Use when validating code quality, preparing commits, running CI checks locally, or when the user mentions preflight, verify, lint, typecheck, or test commands.",
                "path": "plugins/ai-workflow/skills/preflight-checks/SKILL.md",
                "frontmatter": {
                  "name": "preflight-checks",
                  "description": "Comprehensive code quality verification system for running type checking, linting, and tests. Use when validating code quality, preparing commits, running CI checks locally, or when the user mentions preflight, verify, lint, typecheck, or test commands."
                },
                "content": "# Preflight Code Quality Checks\n\nThis skill provides comprehensive guidance for discovering and running code quality checks across different project types.\n\n## Overview\n\nPreflight checks are the quality gates that verify code before commits, PRs, or deployments. They typically include:\n\n1. **Type Checking** - Static type verification (TypeScript, MyPy, etc.)\n2. **Linting** - Code quality and style enforcement\n3. **Formatting** - Consistent code style\n4. **Testing** - Unit, integration, and e2e tests\n\n## Quick Reference\n\n### Node.js / TypeScript Projects\n\n| Check | Command | Auto-fix |\n|-------|---------|----------|\n| TypeScript | `npx tsc --noEmit` | N/A (manual) |\n| ESLint | `npx eslint .` | `npx eslint . --fix` |\n| Biome | `npx biome check .` | `npx biome check . --write` |\n| Prettier | `npx prettier --check .` | `npx prettier --write .` |\n| Jest | `npx jest` | N/A |\n| Vitest | `npx vitest run` | N/A |\n\n**Prefer npm scripts when available:**\n```bash\n# Check package.json scripts first\nnpm run lint        # if exists\nnpm run typecheck   # if exists\nnpm run test        # if exists\nnpm run check       # often runs all checks\n```\n\n### Python Projects\n\n| Check | Command | Auto-fix |\n|-------|---------|----------|\n| MyPy | `mypy .` | N/A (manual) |\n| Ruff lint | `ruff check .` | `ruff check . --fix` |\n| Ruff format | `ruff format --check .` | `ruff format .` |\n| Black | `black --check .` | `black .` |\n| isort | `isort --check .` | `isort .` |\n| Pytest | `pytest` | N/A |\n\n**With pyproject.toml (modern Python):**\n```bash\n# Check for [tool.X] sections\nruff check . && ruff format --check .  # Ruff (fast, recommended)\nmypy src/                               # Type checking\npytest                                  # Tests\n```\n\n### .NET Projects\n\n| Check | Command | Auto-fix |\n|-------|---------|----------|\n| Build | `dotnet build` | N/A |\n| Build strict | `dotnet build --warnaserror` | N/A |\n| Format check | `dotnet format --verify-no-changes` | `dotnet format` |\n| Tests | `dotnet test` | N/A |\n| Analyzers | Configured in `.editorconfig` | N/A |\n\n**.NET specific considerations:**\n- Warnings as errors: Add `<TreatWarningsAsErrors>true</TreatWarningsAsErrors>` to `.csproj`\n- Enable nullable: `<Nullable>enable</Nullable>` for null safety\n- Analyzers run during build automatically\n\n### Go Projects\n\n| Check | Command | Auto-fix |\n|-------|---------|----------|\n| Build | `go build ./...` | N/A |\n| Vet | `go vet ./...` | N/A |\n| golangci-lint | `golangci-lint run` | `golangci-lint run --fix` |\n| gofmt | `gofmt -l .` | `gofmt -w .` |\n| Tests | `go test ./...` | N/A |\n\n### Rust Projects\n\n| Check | Command | Auto-fix |\n|-------|---------|----------|\n| Check | `cargo check` | N/A |\n| Clippy | `cargo clippy -- -D warnings` | `cargo clippy --fix` |\n| Format | `cargo fmt --check` | `cargo fmt` |\n| Tests | `cargo test` | N/A |\n\n## Discovery Strategy\n\n### Step 1: Identify Project Type(s)\n\nCheck for presence of key files:\n\n```\n# JavaScript/TypeScript\npackage.json, tsconfig.json, deno.json\n\n# Python\npyproject.toml, setup.py, requirements.txt, Pipfile\n\n# .NET\n*.csproj, *.sln, *.fsproj\n\n# Go\ngo.mod\n\n# Rust\nCargo.toml\n```\n\n### Step 2: Check for Configured Scripts/Tasks\n\n**package.json scripts (Node.js):**\n```json\n{\n  \"scripts\": {\n    \"lint\": \"eslint .\",\n    \"typecheck\": \"tsc --noEmit\",\n    \"test\": \"vitest\",\n    \"check\": \"npm run lint && npm run typecheck && npm run test\"\n  }\n}\n```\n\n**pyproject.toml (Python):**\n```toml\n[tool.ruff]\nline-length = 100\n\n[tool.mypy]\nstrict = true\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\n```\n\n**Makefile targets:**\n```makefile\nlint:\n    ruff check .\n\ntest:\n    pytest\n\ncheck: lint test\n```\n\n### Step 3: Detect CI Configuration\n\nCheck for CI files to align local checks with CI:\n- `.github/workflows/*.yml` - GitHub Actions\n- `.gitlab-ci.yml` - GitLab CI\n- `azure-pipelines.yml` - Azure DevOps\n- `Jenkinsfile` - Jenkins\n- `.circleci/config.yml` - CircleCI\n\n## Best Practices\n\n### Execution Order\n\nRun checks in order of speed and feedback value:\n1. **Format check** (fastest, catches style issues)\n2. **Type checking** (fast, catches type errors)\n3. **Linting** (medium, catches quality issues)\n4. **Tests** (slowest, catches logic errors)\n\nThis order provides fastest feedback on failures.\n\n### Handling Monorepos\n\nFor monorepos, check for workspace configuration:\n- `pnpm-workspace.yaml`\n- `lerna.json`\n- `package.json` with `workspaces` field\n- `Cargo.toml` with `[workspace]`\n\nRun checks at workspace root or iterate through packages.\n\n### CI Alignment\n\nEnsure local preflight matches CI:\n```bash\n# Good: Use same commands as CI\nnpm run lint    # Same as CI step\n\n# Avoid: Different commands locally vs CI\neslint . --max-warnings=0  # If CI uses npm run lint\n```\n\n### Exit Codes\n\nRespect exit codes for CI integration:\n- `0` - Success, no issues\n- `1` - Failure, issues found\n- `2` - Configuration error\n\n### Caching\n\nFor faster subsequent runs:\n- ESLint: Uses `.eslintcache` with `--cache` flag\n- TypeScript: Uses `tsconfig.tsbuildinfo` with `incremental: true`\n- Pytest: Uses `.pytest_cache`\n- Rust: Uses `target/` directory\n\n## Error Messages Reference\n\n### TypeScript Common Errors\n\n```\nTS2339: Property 'x' does not exist on type 'Y'\n-> Add property to interface or use type assertion\n\nTS2322: Type 'X' is not assignable to type 'Y'\n-> Check type definitions, may need union type\n\nTS7006: Parameter 'x' implicitly has an 'any' type\n-> Add explicit type annotation\n```\n\n### ESLint Common Errors\n\n```\n@typescript-eslint/no-unused-vars\n-> Remove unused variable or prefix with _\n\n@typescript-eslint/no-explicit-any\n-> Replace 'any' with specific type\n\nimport/order\n-> Auto-fixable: eslint --fix\n```\n\n### Python Common Errors\n\n```\nmypy: Incompatible return value type\n-> Check return type annotation matches actual return\n\nruff: E501 Line too long\n-> Auto-fixable or configure line-length\n\nruff: F401 Module imported but unused\n-> Remove unused import\n```\n\n## Integration with Pre-commit Hooks\n\nPreflight checks can be configured as pre-commit hooks:\n\n**.pre-commit-config.yaml:**\n```yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: preflight\n        name: Preflight Checks\n        entry: npm run check\n        language: system\n        pass_filenames: false\n```\n\n**Husky (Node.js):**\n```bash\n# .husky/pre-commit\nnpm run lint\nnpm run typecheck\n```\n\n## When to Skip Checks\n\nSome scenarios where partial checks are acceptable:\n- `--no-verify` for emergency fixes (use sparingly)\n- WIP commits on feature branches\n- Exploratory/spike work\n\nAlways run full preflight before:\n- Opening PRs\n- Merging to main/master\n- Deploying to production"
              }
            ]
          },
          {
            "name": "ai-statusline",
            "description": "AI-powered status line customization - Interactive setup and edit wizards for configuring Claude Code's status line with progress bars and customizable display options",
            "source": "./plugins/ai-statusline",
            "category": null,
            "version": "1.1.1",
            "author": {
              "name": "Charles Jones",
              "url": "https://charlesjones.dev"
            },
            "install_commands": [
              "/plugin marketplace add charlesjones-dev/claude-code-plugins-dev",
              "/plugin install ai-statusline@claude-code-plugins-dev"
            ],
            "signals": {
              "stars": 10,
              "forks": 0,
              "pushed_at": "2025-12-18T18:03:15Z",
              "created_at": "2025-10-17T19:15:04Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/statusline-edit",
                "description": "Edit existing status line configuration with pre-selected options based on current settings.",
                "path": "plugins/ai-statusline/commands/statusline-edit.md",
                "frontmatter": {
                  "name": "statusline-edit",
                  "description": "Edit existing status line configuration with pre-selected options based on current settings."
                },
                "content": "# Status Line Edit\n\nEdit your existing Claude Code status line configuration.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text after this command, COMPLETELY IGNORE it.\n\n### Phase 1: Detect Existing Configuration\n\n1. Detect the operating system using Bash: `uname -s`\n   - \"Darwin\" = macOS, \"Linux\" = Linux, otherwise assume Windows\n2. Check if the status line script exists:\n   - **Mac/Linux**: `~/.claude/statusline.sh`\n   - **Windows**: `C:/Users/USERNAME/.claude/statusline.ps1`\n3. If the script does NOT exist, display:\n   ```\n   No status line script found at ~/.claude/statusline.sh\n\n   Run /statusline-wizard to set up your status line first.\n   ```\n   Then STOP - do not continue.\n\n### Phase 2: Read Current Configuration\n\nRead the existing script file and parse the current SHOW_* variable values:\n\n**For Bash scripts**, look for lines like:\n```bash\nSHOW_MODEL=true\nSHOW_TOKEN_COUNT=true\nSHOW_PROGRESS_BAR=true\nSHOW_DIRECTORY=true\nSHOW_GIT_BRANCH=true\nSHOW_COST=false\nSHOW_DURATION=true\nSHOW_TIME=true\nSHOW_VERSION=true\n```\n\n**For PowerShell scripts**, look for lines like:\n```powershell\n$SHOW_MODEL = $true\n$SHOW_TOKEN_COUNT = $true\n$SHOW_PROGRESS_BAR = $true\n$SHOW_DIRECTORY = $true\n$SHOW_GIT_BRANCH = $true\n$SHOW_COST = $false\n$SHOW_DURATION = $true\n$SHOW_TIME = $true\n$SHOW_VERSION = $true\n```\n\nStore the current values to use as defaults in the wizard.\n\n### Phase 3: Configuration Wizard with Pre-selected Values\n\nUse AskUserQuestion with these grouped questions. **Pre-select options based on current values from Phase 2.**\n\n**Question 1 - Context Display** (multiSelect: true):\nOptions (pre-select based on current config):\n- Model name - select if SHOW_MODEL=true\n- Token count (50k/100k) - select if SHOW_TOKEN_COUNT=true\n- Progress bar - select if SHOW_PROGRESS_BAR=true\n\n**Question 2 - Project Display** (multiSelect: true):\nOptions (pre-select based on current config):\n- Current directory - select if SHOW_DIRECTORY=true\n- Git branch - select if SHOW_GIT_BRANCH=true\n\n**Question 3 - Session Display** (multiSelect: true):\nOptions (pre-select based on current config):\n- Session duration - select if SHOW_DURATION=true\n- Current time - select if SHOW_TIME=true\n- Claude Code version - select if SHOW_VERSION=true\n- Session cost - select if SHOW_COST=true\n\n### Phase 4: Update Script\n\nUpdate ONLY the SHOW_* variables at the top of the existing script file based on wizard selections.\n\n**For Bash**: Use Edit tool to replace the configuration block:\n```bash\nSHOW_MODEL=true           # Show model name (e.g., \"Claude Opus 4.5\")\nSHOW_TOKEN_COUNT=true     # Show token usage count (e.g., \"50k/100k\")\n...\n```\n\n**For PowerShell**: Use Edit tool to replace the configuration block:\n```powershell\n$SHOW_MODEL = $true           # Show model name (e.g., \"Claude Opus 4.5\")\n$SHOW_TOKEN_COUNT = $true     # Show token usage count (e.g., \"50k/100k\")\n...\n```\n\n**IMPORTANT**: Do NOT regenerate the entire script. Only update the configuration variables section.\n\n### Success Message\n\nAfter successful update, display:\n\n```\nStatus line updated!\n\nCheck out your refreshed status line below!\n\nCurrent configuration:\n- Model name: [enabled/disabled]\n- Token count: [enabled/disabled]\n- Progress bar: [enabled/disabled]\n- Directory: [enabled/disabled]\n- Git branch: [enabled/disabled]\n- Session cost: [enabled/disabled]\n- Duration: [enabled/disabled]\n- Time: [enabled/disabled]\n- Version: [enabled/disabled]\n```"
              },
              {
                "name": "/statusline-wizard",
                "description": "Interactive setup wizard for configuring Claude Code's custom status line with progress bars and customizable display options.",
                "path": "plugins/ai-statusline/commands/statusline-wizard.md",
                "frontmatter": {
                  "name": "statusline-wizard",
                  "description": "Interactive setup wizard for configuring Claude Code's custom status line with progress bars and customizable display options."
                },
                "content": "# Status Line Wizard\n\nSet up a custom status line for Claude Code with visual progress bars and configurable display options.\n\n## Instructions\n\n**CRITICAL**: This command MUST NOT accept any arguments. If the user provided any text after this command, COMPLETELY IGNORE it.\n\nInvoke the `ai-statusline:statusline-setup` skill and follow its workflow to:\n\n1. Detect the operating system (Mac/Linux/Windows)\n2. Check for existing statusLine configuration and offer to back up if present\n3. Run the configuration wizard using AskUserQuestion to gather preferences\n4. Create the appropriate script file (`.sh` for Mac/Linux, `.ps1` for Windows)\n5. Update `~/.claude/settings.json` with the statusLine configuration\n6. Make the script executable on Mac/Linux using `chmod +x`\n\n### Wizard Questions\n\nUse AskUserQuestion with these grouped questions:\n\n**Question 1 - Context Display** (multiSelect: true):\n- Token count (50k/100k) - default selected\n- Progress bar - default selected\n- Model name - default selected\n\n**Question 2 - Project Display** (multiSelect: true):\n- Current directory - default selected\n- Git branch - default selected\n\n**Question 3 - Session Display** (multiSelect: true):\n- Session duration - default selected\n- Current time - default selected\n- Claude Code version - default selected\n- Session cost - NOT selected by default\n\n### Success Message\n\nAfter successful setup, display:\n\n```\nStatus line configured successfully!\n\nScript: ~/.claude/statusline.sh (or .ps1)\nSettings: ~/.claude/settings.json\n\nYou should see your new status line below!\n\nTo customize later, run /statusline-edit or edit the SHOW_* variables at the top of the script file.\n```"
              }
            ],
            "skills": [
              {
                "name": "statusline-setup",
                "description": "Guide for configuring Claude Code's status line with customizable display options and progress bars. This skill should be used when setting up or customizing the status line display.",
                "path": "plugins/ai-statusline/skills/statusline-setup/SKILL.md",
                "frontmatter": {
                  "name": "statusline-setup",
                  "description": "Guide for configuring Claude Code's status line with customizable display options and progress bars. This skill should be used when setting up or customizing the status line display."
                },
                "content": "# Status Line Setup Skill\n\nThis skill provides guidance for configuring Claude Code's status line with customizable display options, progress bars, and cross-platform support.\n\n## When to Use This Skill\n\nInvoke this skill when:\n- Setting up a custom status line for Claude Code\n- Configuring which elements to show/hide in the status line\n- Adding a visual progress bar for context usage\n- Setting up cross-platform status line scripts (bash/PowerShell)\n\n## Setup Workflow\n\n### Phase 1: Check Existing Configuration\n\n1. Detect the operating system using Bash: `uname -s` (returns \"Darwin\" for macOS, \"Linux\" for Linux)\n   - If command fails or returns \"MINGW\"/\"MSYS\"/\"CYGWIN\", assume Windows\n2. Read the user's settings file:\n   - **Mac/Linux**: `~/.claude/settings.json`\n   - **Windows**: `C:/Users/USERNAME/.claude/settings.json` (get USERNAME from environment)\n3. Check if `statusLine` section already exists\n4. If exists, ask user using AskUserQuestion:\n   - **Replace**: Back up existing file and create new configuration\n   - **Cancel**: Stop the setup process\n\n### Phase 2: Configuration Wizard\n\nUse the AskUserQuestion tool to gather user preferences. Group questions logically:\n\n**Question 1: Context Information**\n- Show model name (default: yes)\n- Show token count e.g. \"50k/100k\" (default: yes)\n- Show progress bar (default: yes)\n\n**Question 2: Project Information**\n- Show current directory (default: yes)\n- Show git branch (default: yes)\n\n**Question 3: Session Information**\n- Show session cost (default: no)\n- Show session duration (default: yes)\n- Show current time (default: yes)\n- Show Claude Code version (default: yes)\n\n### Phase 3: Create Script File\n\nBased on OS, create the appropriate script file:\n\n**Mac/Linux**: `~/.claude/statusline.sh`\n**Windows**: `C:/Users/USERNAME/.claude/statusline.ps1`\n\nIf script file already exists, back it up first with `.backup` extension.\n\n### Phase 4: Update Settings\n\nUpdate the settings.json file with the statusLine configuration:\n\n**Mac/Linux**:\n```json\n{\n  \"statusLine\": {\n    \"type\": \"command\",\n    \"command\": \"/Users/USERNAME/.claude/statusline.sh\",\n    \"padding\": 0\n  }\n}\n```\n\n**Windows**:\n```json\n{\n  \"statusLine\": {\n    \"type\": \"command\",\n    \"command\": \"powershell.exe -NoProfile -ExecutionPolicy Bypass -File C:/Users/USERNAME/.claude/statusline.ps1\",\n    \"padding\": 0\n  }\n}\n```\n\n### Phase 5: Make Executable (Mac/Linux only)\n\nRun `chmod +x ~/.claude/statusline.sh` to make the script executable.\n\n## Script Templates\n\n### Bash Script Template (Mac/Linux)\n\n```bash\n#!/bin/bash\n\n# =============================================================================\n# Claude Code Status Line\n# =============================================================================\n# Configuration - Set these to customize your status line\n# =============================================================================\n\nSHOW_MODEL=true           # Show model name (e.g., \"Claude Opus 4.5\")\nSHOW_TOKEN_COUNT=true     # Show token usage count (e.g., \"50k/100k\")\nSHOW_PROGRESS_BAR=true    # Show visual progress bar\nSHOW_DIRECTORY=true       # Show current directory name\nSHOW_GIT_BRANCH=true      # Show current git branch\nSHOW_COST=false           # Show session cost (useful for API/Pro users)\nSHOW_DURATION=true        # Show session duration\nSHOW_TIME=true            # Show current time\nSHOW_VERSION=true         # Show Claude Code version\n\n# =============================================================================\n\ninput=$(cat)\nmodel_name=$(echo \"$input\" | jq -r '.model.display_name')\ncurrent_dir=$(basename \"$(echo \"$input\" | jq -r '.workspace.current_dir')\")\nversion=$(echo \"$input\" | jq -r '.version')\nusage=$(echo \"$input\" | jq '.context_window.current_usage')\ncost=$(echo \"$input\" | jq -r '.cost.total_cost_usd')\nduration_ms=$(echo \"$input\" | jq -r '.cost.total_duration_ms')\ncurrent_time=$(date +\"%I:%M%p\" | tr '[:upper:]' '[:lower:]')\n\n# Format cost\nif [ \"$cost\" != \"null\" ] && [ -n \"$cost\" ]; then\n  cost_fmt=$(printf '$%.2f' \"$cost\")\nelse\n  cost_fmt='$0.00'\nfi\n\n# Format duration (ms to human readable)\nif [ \"$duration_ms\" != \"null\" ] && [ -n \"$duration_ms\" ]; then\n  duration_s=$((duration_ms / 1000))\n  if [ $duration_s -lt 60 ]; then\n    duration_fmt=\"${duration_s}s\"\n  elif [ $duration_s -lt 3600 ]; then\n    mins=$((duration_s / 60))\n    secs=$((duration_s % 60))\n    duration_fmt=\"${mins}m ${secs}s\"\n  else\n    hours=$((duration_s / 3600))\n    mins=$(((duration_s % 3600) / 60))\n    duration_fmt=\"${hours}h ${mins}m\"\n  fi\nelse\n  duration_fmt='0s'\nfi\n\n# Get git branch\ngit_branch=$(git -C \"$(echo \"$input\" | jq -r '.workspace.current_dir')\" branch --show-current 2>/dev/null)\nif [ -z \"$git_branch\" ]; then\n  git_branch='-'\nfi\n\n# Build progress bar\nbuild_progress_bar() {\n  local pct=$1\n  local color=$2\n  local bar_width=10\n  local filled=$((pct * bar_width / 100))\n  local empty=$((bar_width - filled))\n\n  local bar=\"\"\n  for ((i=0; i<filled; i++)); do bar+=\"‚ñì\"; done\n  for ((i=0; i<empty; i++)); do bar+=\"‚ñë\"; done\n\n  printf '\\033[%sm%s %d%%\\033[0m' \"$color\" \"$bar\" \"$pct\"\n}\n\n# ANSI color codes\nreset='\\033[0m'\nwhite='\\033[97m'\ngreen='\\033[32m'\nyellow='\\033[33m'\nred='\\033[31m'\nblue='\\033[94m'\nmagenta='\\033[35m'\ncyan='\\033[36m'\ngray='\\033[90m'\n\n# Build output segments\noutput=\"\"\n\n# Model name\nif [ \"$SHOW_MODEL\" = true ]; then\n  output=\"${white}${model_name}${reset}\"\nfi\n\n# Token count and progress bar\nif [ \"$usage\" != \"null\" ]; then\n  current=$(echo \"$usage\" | jq '.input_tokens + .cache_creation_input_tokens + .cache_read_input_tokens')\n  size=$(echo \"$input\" | jq '.context_window.context_window_size')\n  pct=$((current * 100 / size))\n  current_k=$((current / 1000))\n  size_k=$((size / 1000))\n\n  if [ $pct -lt 70 ]; then\n    color='32'\n  elif [ $pct -lt 80 ]; then\n    color='33'\n  else\n    color='31'\n  fi\n\n  if [ \"$SHOW_TOKEN_COUNT\" = true ] || [ \"$SHOW_PROGRESS_BAR\" = true ]; then\n    [ -n \"$output\" ] && output=\"$output ¬∑ \"\n\n    if [ \"$SHOW_TOKEN_COUNT\" = true ]; then\n      output=\"$output\\033[${color}m${current_k}k/${size_k}k\\033[0m\"\n    fi\n\n    if [ \"$SHOW_PROGRESS_BAR\" = true ]; then\n      progress_bar=$(build_progress_bar \"$pct\" \"$color\")\n      [ \"$SHOW_TOKEN_COUNT\" = true ] && output=\"$output \"\n      output=\"$output${progress_bar}\"\n    fi\n  fi\nelse\n  if [ \"$SHOW_TOKEN_COUNT\" = true ] || [ \"$SHOW_PROGRESS_BAR\" = true ]; then\n    [ -n \"$output\" ] && output=\"$output ¬∑ \"\n    if [ \"$SHOW_TOKEN_COUNT\" = true ]; then\n      output=\"$output${green}0k/0k${reset}\"\n    fi\n    if [ \"$SHOW_PROGRESS_BAR\" = true ]; then\n      progress_bar=$(build_progress_bar 0 '32')\n      [ \"$SHOW_TOKEN_COUNT\" = true ] && output=\"$output \"\n      output=\"$output${progress_bar}\"\n    fi\n  fi\nfi\n\n# Directory\nif [ \"$SHOW_DIRECTORY\" = true ]; then\n  [ -n \"$output\" ] && output=\"$output ¬∑ \"\n  output=\"$output${blue}${current_dir}${reset}\"\nfi\n\n# Git branch\nif [ \"$SHOW_GIT_BRANCH\" = true ]; then\n  [ -n \"$output\" ] && output=\"$output ¬∑ \"\n  output=\"$output${magenta}${git_branch}${reset}\"\nfi\n\n# Cost\nif [ \"$SHOW_COST\" = true ]; then\n  [ -n \"$output\" ] && output=\"$output ¬∑ \"\n  output=\"$output${yellow}${cost_fmt}${reset}\"\nfi\n\n# Duration\nif [ \"$SHOW_DURATION\" = true ]; then\n  [ -n \"$output\" ] && output=\"$output ¬∑ \"\n  output=\"$output${cyan}${duration_fmt}${reset}\"\nfi\n\n# Time\nif [ \"$SHOW_TIME\" = true ]; then\n  [ -n \"$output\" ] && output=\"$output ¬∑ \"\n  output=\"$output${white}${current_time}${reset}\"\nfi\n\n# Version\nif [ \"$SHOW_VERSION\" = true ]; then\n  [ -n \"$output\" ] && output=\"$output ¬∑ \"\n  output=\"$output${gray}v${version}${reset}\"\nfi\n\nprintf '%b' \"$output\"\n```\n\n### PowerShell Script Template (Windows)\n\n```powershell\n# =============================================================================\n# Claude Code Status Line (PowerShell)\n# =============================================================================\n# Configuration - Set these to customize your status line\n# =============================================================================\n\n$SHOW_MODEL = $true           # Show model name (e.g., \"Claude Opus 4.5\")\n$SHOW_TOKEN_COUNT = $true     # Show token usage count (e.g., \"50k/100k\")\n$SHOW_PROGRESS_BAR = $true    # Show visual progress bar\n$SHOW_DIRECTORY = $true       # Show current directory name\n$SHOW_GIT_BRANCH = $true      # Show current git branch\n$SHOW_COST = $false           # Show session cost (useful for API/Pro users)\n$SHOW_DURATION = $true        # Show session duration\n$SHOW_TIME = $true            # Show current time\n$SHOW_VERSION = $true         # Show Claude Code version\n\n# =============================================================================\n\n# Read JSON from stdin\n$inputJson = $input | Out-String\n$data = $inputJson | ConvertFrom-Json\n\n$model_name = $data.model.display_name\n$current_dir = Split-Path -Leaf $data.workspace.current_dir\n$version = $data.version\n$usage = $data.context_window.current_usage\n$cost = $data.cost.total_cost_usd\n$duration_ms = $data.cost.total_duration_ms\n$current_time = (Get-Date -Format \"h:mmtt\").ToLower()\n\n# Format cost\nif ($null -ne $cost) {\n    $cost_fmt = '${0:F2}' -f $cost\n} else {\n    $cost_fmt = '$0.00'\n}\n\n# Format duration (ms to human readable)\nif ($null -ne $duration_ms) {\n    $duration_s = [math]::Floor($duration_ms / 1000)\n    if ($duration_s -lt 60) {\n        $duration_fmt = \"${duration_s}s\"\n    } elseif ($duration_s -lt 3600) {\n        $mins = [math]::Floor($duration_s / 60)\n        $secs = $duration_s % 60\n        $duration_fmt = \"${mins}m ${secs}s\"\n    } else {\n        $hours = [math]::Floor($duration_s / 3600)\n        $mins = [math]::Floor(($duration_s % 3600) / 60)\n        $duration_fmt = \"${hours}h ${mins}m\"\n    }\n} else {\n    $duration_fmt = '0s'\n}\n\n# Get git branch\n$git_branch = try {\n    git -C $data.workspace.current_dir branch --show-current 2>$null\n} catch { $null }\nif ([string]::IsNullOrEmpty($git_branch)) {\n    $git_branch = '-'\n}\n\n# ANSI color codes\n$esc = [char]27\n$reset = \"$esc[0m\"\n$white = \"$esc[97m\"\n$cyan = \"$esc[36m\"\n$green = \"$esc[32m\"\n$yellow = \"$esc[33m\"\n$red = \"$esc[31m\"\n$blue = \"$esc[94m\"\n$magenta = \"$esc[35m\"\n$gray = \"$esc[90m\"\n\n# Build progress bar\nfunction Build-ProgressBar {\n    param (\n        [int]$Percent,\n        [string]$Color\n    )\n    $bar_width = 10\n    $filled = [math]::Floor($Percent * $bar_width / 100)\n    $empty = $bar_width - $filled\n\n    $bar = (\"#\" * $filled) + (\"-\" * $empty)\n    return \"$Color$bar $Percent%$reset\"\n}\n\n# Build output segments\n$segments = @()\n\n# Model name\nif ($SHOW_MODEL) {\n    $segments += \"$white$model_name$reset\"\n}\n\n# Token count and progress bar\nif ($null -ne $usage) {\n    $current = $usage.input_tokens + $usage.cache_creation_input_tokens + $usage.cache_read_input_tokens\n    $size = $data.context_window.context_window_size\n    $pct = [math]::Floor($current * 100 / $size)\n    $current_k = [math]::Floor($current / 1000)\n    $size_k = [math]::Floor($size / 1000)\n\n    if ($pct -lt 70) {\n        $token_color = $green\n    } elseif ($pct -lt 80) {\n        $token_color = $yellow\n    } else {\n        $token_color = $red\n    }\n\n    $token_segment = \"\"\n    if ($SHOW_TOKEN_COUNT) {\n        $token_segment = \"$token_color${current_k}k/${size_k}k$reset\"\n    }\n    if ($SHOW_PROGRESS_BAR) {\n        $progress_bar = Build-ProgressBar -Percent $pct -Color $token_color\n        if ($SHOW_TOKEN_COUNT) {\n            $token_segment += \" $progress_bar\"\n        } else {\n            $token_segment = $progress_bar\n        }\n    }\n    if ($token_segment) {\n        $segments += $token_segment\n    }\n} else {\n    $token_segment = \"\"\n    if ($SHOW_TOKEN_COUNT) {\n        $token_segment = \"${green}0k/0k$reset\"\n    }\n    if ($SHOW_PROGRESS_BAR) {\n        $progress_bar = Build-ProgressBar -Percent 0 -Color $green\n        if ($SHOW_TOKEN_COUNT) {\n            $token_segment += \" $progress_bar\"\n        } else {\n            $token_segment = $progress_bar\n        }\n    }\n    if ($token_segment) {\n        $segments += $token_segment\n    }\n}\n\n# Directory\nif ($SHOW_DIRECTORY) {\n    $segments += \"$blue$current_dir$reset\"\n}\n\n# Git branch\nif ($SHOW_GIT_BRANCH) {\n    $segments += \"$magenta$git_branch$reset\"\n}\n\n# Cost\nif ($SHOW_COST) {\n    $segments += \"$yellow$cost_fmt$reset\"\n}\n\n# Duration\nif ($SHOW_DURATION) {\n    $segments += \"$cyan$duration_fmt$reset\"\n}\n\n# Time\nif ($SHOW_TIME) {\n    $segments += \"$white$current_time$reset\"\n}\n\n# Version\nif ($SHOW_VERSION) {\n    $segments += \"${gray}v$version$reset\"\n}\n\nWrite-Host -NoNewline ($segments -join \" - \")\n```\n\n## Configuration Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| SHOW_MODEL | true | Display model name (e.g., \"Claude Opus 4.5\") |\n| SHOW_TOKEN_COUNT | true | Display token usage (e.g., \"50k/100k\") |\n| SHOW_PROGRESS_BAR | true | Display visual progress bar with percentage |\n| SHOW_DIRECTORY | true | Display current working directory name |\n| SHOW_GIT_BRANCH | true | Display current git branch |\n| SHOW_COST | false | Display session cost in USD |\n| SHOW_DURATION | true | Display session duration |\n| SHOW_TIME | true | Display current time |\n| SHOW_VERSION | true | Display Claude Code version |\n\n## Important Notes\n\n- The scripts require `jq` to be installed on Mac/Linux for JSON parsing\n- PowerShell scripts work on Windows PowerShell 5.1+ and PowerShell Core 7+\n- Unicode progress bar characters (‚ñì‚ñë) should work on modern terminals\n- Colors use ANSI escape codes which work on most modern terminals\n- Status line updates appear immediately after setup"
              }
            ]
          }
        ]
      }
    }
  ]
}