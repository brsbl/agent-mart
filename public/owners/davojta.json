{
  "owner": {
    "id": "davojta",
    "display_name": "Dzianis Sheka",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/893650?u=82fb6e9aae33b3662602981b41af03ea961ad226&v=4",
    "url": "https://github.com/davojta",
    "bio": "a software engineer and a p2p enthusiast  ",
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 5,
      "total_skills": 0,
      "total_stars": 4,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "davojta/easy-spec",
      "url": "https://github.com/davojta/easy-spec",
      "description": "simple spec driven workflow inspired by github spec-kit ",
      "homepage": null,
      "signals": {
        "stars": 4,
        "forks": 0,
        "pushed_at": "2025-12-20T15:06:22Z",
        "created_at": "2025-11-25T16:47:17Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1056
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/execute.md",
          "type": "blob",
          "size": 4723
        },
        {
          "path": ".claude/commands/plan.md",
          "type": "blob",
          "size": 8593
        },
        {
          "path": ".claude/commands/research.md",
          "type": "blob",
          "size": 5933
        },
        {
          "path": ".claude/commands/spec.md",
          "type": "blob",
          "size": 5345
        },
        {
          "path": ".claude/commands/tasks.md",
          "type": "blob",
          "size": 2179
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 2152
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1070
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 13682
        },
        {
          "path": "easy-spec",
          "type": "tree",
          "size": null
        },
        {
          "path": "easy-spec/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "easy-spec/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 242
        },
        {
          "path": "easy-spec/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "easy-spec/commands/execute.md",
          "type": "blob",
          "size": 4723
        },
        {
          "path": "easy-spec/commands/plan.md",
          "type": "blob",
          "size": 17136
        },
        {
          "path": "easy-spec/commands/research.md",
          "type": "blob",
          "size": 9240
        },
        {
          "path": "easy-spec/commands/spec.md",
          "type": "blob",
          "size": 8392
        },
        {
          "path": "easy-spec/commands/tasks.md",
          "type": "blob",
          "size": 7529
        },
        {
          "path": "examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/format-book",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/format-book/refactoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/format-book/refactoring/input.md",
          "type": "blob",
          "size": 331
        },
        {
          "path": "examples/format-book/refactoring/plan.md",
          "type": "blob",
          "size": 12147
        },
        {
          "path": "examples/format-book/refactoring/research.md",
          "type": "blob",
          "size": 8456
        },
        {
          "path": "examples/format-book/refactoring/spec.md",
          "type": "blob",
          "size": 5417
        },
        {
          "path": "examples/format-book/refactoring/tasks.md",
          "type": "blob",
          "size": 22911
        }
      ],
      "marketplace": {
        "name": "davojta",
        "version": null,
        "description": "A marketplace for easy-spec plugin and related development workflow tools",
        "owner_info": {
          "name": "Dzianis Sheka",
          "email": "dzianis.sheka@gmail.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "easy-spec",
            "description": "A simplified toolkit for generating research, specifications, plans, and tasks for feature development workflows",
            "source": "./easy-spec",
            "category": null,
            "version": "0.0.1",
            "author": {
              "name": "Dzianis Sheka"
            },
            "install_commands": [
              "/plugin marketplace add davojta/easy-spec",
              "/plugin install easy-spec@davojta"
            ],
            "signals": {
              "stars": 4,
              "forks": 0,
              "pushed_at": "2025-12-20T15:06:22Z",
              "created_at": "2025-11-25T16:47:17Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/execute",
                "description": null,
                "path": "easy-spec/commands/execute.md",
                "frontmatter": null,
                "content": "Execute tasks from tasks.md in a feature folder.\n\n## Process\n\n1. Read tasks.md from the specified feature folder (REQUIRED)\n2. Parse task list and identify:\n   - Task IDs (T001, T002, etc.)\n   - Task descriptions and file paths\n   - Task status (pending, in-progress, completed)\n   - Parallel execution markers [P]\n   - Dependencies between tasks\n3. Read supporting documents if available:\n   - spec.md (functional requirements)\n   - plan.md (technical approach)\n   - research.md (technical decisions)\n   - data-model.md (data structures)\n4. Read detailed task specifications from tasks.md:\n   - Objective and requirements\n   - Key components and code examples\n   - Implementation details\n   - Files to create/modify\n5. Execute tasks following the workflow:\n   - Start with pending tasks that have no blockers\n   - Follow dependency order (setup ‚Üí core ‚Üí integration ‚Üí polish)\n   - Run tasks marked [P] in parallel when possible\n   - Update task status in tasks.md as you progress:\n     - Mark task as in-progress when starting\n     - Mark task as completed when done\n     - Add implementation notes and progress summary\n6. After each task completion:\n   - Run code quality checks (lint, typecheck, format)\n   - Run tests if available\n   - Update Implementation Status section in tasks.md\n7. Continue until all pending tasks are completed or blocked\n\n## Task Execution Rules\n\n**Status Updates:**\n- Mark ONE task as in-progress before starting work\n- Mark task as completed IMMEDIATELY after finishing\n- Add implementation notes with key decisions and challenges\n- Update progress summary with completed milestones\n\n**Quality Checks:**\n- Run `make lint` after each task\n- Run `make typecheck` after each task\n- Run `make format` to auto-fix issues\n- Run tests: `make test` or `uv run pytest`\n- All checks must pass before marking task as completed\n\n**Dependency Management:**\n- Respect task dependencies (don't start T005 if T004 blocks it)\n- Tasks marked [P] can run in parallel (different files)\n- Sequential tasks must complete in order\n\n**Error Handling:**\n- If task fails or is blocked, keep status as in-progress\n- Create new task describing what needs resolution\n- Document blockers in implementation notes\n- Ask user for clarification if needed\n\n## Arguments Expected\n\nWhen using this command, provide:\n1. Feature folder path (e.g., `ai_tasks/another-big-project/ml-automation/features/download-geojsons/`)\n2. (Optional) Custom instructions or focus areas\n3. (Optional) Specific task ID to execute (e.g., `T005`)\n\nExample usage in chat:\n```\n/execute ai_tasks/another-big-project/ml-automation/features/download-geojsons/\n```\n\nWith custom prompt:\n```\n/execute ai_tasks/another-big-project/ml-automation/features/download-geojsons/ Focus on error handling and edge cases\n```\n\nExecute specific task:\n```\n/execute ai_tasks/another-big-project/ml-automation/features/download-geojsons/ T005\n```\n\n## Success Criteria\n\nSuccessful execution should:\n- Load tasks.md and parse all tasks correctly\n- Identify task dependencies and execution order\n- Execute tasks following dependency order\n- Update task status in real-time (in-progress ‚Üí completed)\n- Run quality checks after each task (lint, typecheck, format)\n- Run tests to verify implementation\n- Update Implementation Status section with progress\n- Add implementation notes with key decisions\n- Complete all pending tasks or identify blockers\n- Provide clear summary of completed work\n\n## Common Pitfalls to Avoid\n\n‚ùå **Don't**:\n- Start multiple tasks simultaneously (only ONE in-progress at a time)\n- Mark tasks as completed before quality checks pass\n- Skip dependencies (respect task ordering)\n- Forget to update Implementation Status section\n- Ignore test failures or lint errors\n- Batch multiple task completions\n\n‚úÖ **Do**:\n- Mark task in-progress BEFORE starting work\n- Run quality checks after each task\n- Update status IMMEDIATELY after completion\n- Document implementation decisions\n- Respect dependency order\n- Ask for clarification when blocked\n- Follow code quality standards\n\n## Task Status Format in tasks.md\n\nWhen updating tasks in tasks.md:\n\n**Checklist format:**\n```markdown\n- [x] T001 [P] Create project structure ‚úÖ\n- [ ] T002 Initialize dependencies\n```\n\n**Detailed status format:**\n```markdown\n### Task T001: Create Project Structure `‚úÖ COMPLETED`\n**Progress Summary:**\n- ‚úÖ Created directory structure\n- ‚úÖ Added package.json with dependencies\n- ‚úÖ Configured TypeScript\n\n**Implementation Notes:**\n- Used recommended tsconfig.json settings\n- Added strict type checking\n- Configured ESLint for code quality\n```\n\n**Now read the tasks.md file from the specified feature folder and begin executing tasks following the workflow above.**\n"
              },
              {
                "name": "/plan",
                "description": null,
                "path": "easy-spec/commands/plan.md",
                "frontmatter": null,
                "content": "Generate technical implementation plan (plan.md) from functional requirements specification.\n\n## Process\n\n1. **FIRST**: Check if the user already provided folder path in their message\n   - Look for absolute paths like /Users/... or relative paths like ai_tasks/...\n   - Only prompt if folder path is missing\n2. Read the spec.md from the specified feature folder (REQUIRED)\n3. Read research.md if available for technical decisions\n4. Use the embedded implementation plan template structure provided below\n5. Extract functional requirements and translate to technical approach\n6. Define technical context:\n   - Language/version and dependencies\n   - Storage and testing framework\n   - Target platform and performance goals\n   - Project structure and architecture\n7. Design implementation phases:\n   - Phase 0: Research & outline (resolve technical unknowns)\n   - Phase 1: Design & contracts (data models, APIs, tests)\n   - Phase 2: Task planning approach (execution strategy)\n   - Phase 3+: Implementation roadmap\n8. Define source code structure and file organization\n9. Create success criteria and integration points\n10. Output plan.md to the feature folder\n\n## Key Principles\n\n**Focus on HOW (technical implementation):**\n- ‚úÖ \"Use @mapbox/maps-snapshotter library for rendering\"\n- ‚úÖ \"Node.js 20+ with TypeScript 5.7+ strict mode\"\n- ‚úÖ \"Commander.js for CLI interface\"\n- ‚ùå \"System must render images\" (that's spec, not plan)\n\n**Translate requirements to architecture:**\n- Functional requirements ‚Üí Technical components\n- User scenarios ‚Üí Integration tests\n- Data requirements ‚Üí Data models and schemas\n- Performance targets ‚Üí Concrete metrics\n\n**Be specific about technology:**\n- Exact versions of languages and frameworks\n- Specific libraries and tools\n- File structure and organization\n- Testing strategy and tools\n\n## Plan Structure\n\n### 1. Summary\nExtract from spec.md:\n- Primary requirement (WHAT from spec)\n- Technical approach (HOW to implement)\n- Key outcomes expected\n\n### 2. Technical Context\nDefine technology stack:\n```\n**Language/Version**: Node.js 20+, TypeScript 5.7+\n**Primary Dependencies**: @mapbox/maps-snapshotter 11.15.1, commander.js\n**Storage**: File system (GeoJSON input, PNG output)\n**Testing**: Vitest for unit/integration tests\n**Target Platform**: macOS, Linux\n**Performance Goals**: <500ms for small files, <2s for medium\n**Constraints**: ~1500MB memory per instance\n**Scale/Scope**: Single CLI tool, batch processing support\n```\n\n### 3. Documentation Structure\n```\nai_tasks/[project]/[feature]/\n‚îú‚îÄ‚îÄ plan.md          # This file\n‚îú‚îÄ‚îÄ research.md      # Phase 0 technical research\n‚îú‚îÄ‚îÄ spec.md          # Input (functional requirements)\n‚îî‚îÄ‚îÄ tasks.md         # Phase 2 output (from /tasks command)\n```\n\n### 4. Source Structure\nDefine project layout:\n```\nproject-root/\n‚îú‚îÄ‚îÄ bin/              # CLI entry point\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ service/      # Business logic\n‚îÇ   ‚îú‚îÄ‚îÄ config/       # Configuration\n‚îÇ   ‚îî‚îÄ‚îÄ types.d.ts    # Type definitions\n‚îú‚îÄ‚îÄ config/           # Config files, templates\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îú‚îÄ‚îÄ unit/         # Unit tests\n‚îÇ   ‚îî‚îÄ‚îÄ integration/  # Integration tests\n‚îî‚îÄ‚îÄ package.json\n```\n\n### 5. Implementation Phases\n\n**Phase 0: Research & Outline**\n- Identify technical unknowns from spec\n- Research best practices for chosen tech stack\n- Validate technology choices\n- Resolve NEEDS CLARIFICATION items\n- Output: research.md\n\n**Phase 1: Design & Contracts**\n- Extract data models from functional requirements\n- Define input/output schemas (use JSON Schema)\n- Create test scenarios from user stories\n- Define API contracts/interfaces\n- Output: data-model.md, tests.md (optional)\n\n**Phase 2: Task Planning Approach**\n- Strategy for generating tasks.md\n- Task ordering (setup ‚Üí config ‚Üí core ‚Üí integration ‚Üí polish)\n- Identify parallel execution opportunities\n- Estimate task count (15-30 typical)\n- **NOTE**: Executed by /tasks command, not /plan\n\n**Phase 3+: Implementation Roadmap**\n- Brief outline of execution and validation phases\n- Integration approach\n- Deployment considerations\n\n### 6. Configuration & Setup\n- Package dependencies with versions\n- Environment setup commands\n- Development workflow\n- Build and deployment process\n\n### 7. Success Criteria\nOrganize by category:\n- ‚úÖ Core Functionality (features working)\n- ‚úÖ Quality & Reliability (tests passing)\n- ‚úÖ Operations (deployment ready)\n\n### 8. Integration Points\n- How feature connects to existing systems\n- External APIs and services used\n- Data flow and dependencies\n\n## Translation from Spec to Plan\n\n**Functional Requirements ‚Üí Technical Implementation:**\n\n| Spec (WHAT) | Plan (HOW) |\n|-------------|------------|\n| FR-001: Accept GeoJSON files | Use fs.readFileSync, validate with JSON.parse |\n| FR-009: Calculate bounding box | Implement recursive coordinate extraction |\n| FR-020: Use GL Native renderer | @mapbox/maps-snapshotter with setStyleURI |\n| FR-026: Support token resolution | CLI flag ‚Üí env var ‚Üí AWS Secrets (priority) |\n\n**User Scenarios ‚Üí Test Structure:**\n\n| Scenario | Test Implementation |\n|----------|-------------------|\n| Render Point with minimal style | Integration test with fixture point.geojson |\n| Handle invalid GeoJSON | Unit test expecting InvalidGeoJSONError |\n| Performance < 500ms | Performance test with timing assertions |\n\n## Technical Context Guidelines\n\nFill each field based on requirements:\n\n- **Language/Version**: Specific version (e.g., \"Python 3.11+\", \"Node.js 20+\")\n- **Primary Dependencies**: Core libraries with versions\n- **Storage**: Database, filesystem, or N/A\n- **Testing**: Test framework and approach\n- **Target Platform**: OS, runtime environment\n- **Performance Goals**: Concrete metrics from spec\n- **Constraints**: Memory, latency, size limits\n- **Scale/Scope**: Users, data size, request volume\n\nMark \"NEEDS CLARIFICATION\" if research is needed, then resolve in Phase 0.\n\n## Research Phase (Phase 0)\n\nIf Technical Context has NEEDS CLARIFICATION items:\n\n1. **Identify unknowns**:\n   - Technology choices not yet made\n   - Best practices to research\n   - Integration patterns to investigate\n\n2. **Research each unknown**:\n   - What are the options?\n   - What are the tradeoffs?\n   - What's the recommendation?\n\n3. **Document in research.md**:\n   ```\n   **Decision**: Chose [technology/approach]\n   **Rationale**: [Why this choice]\n   **Alternatives**: [What else was considered]\n   ```\n\n4. **Update Technical Context**: Replace NEEDS CLARIFICATION with decisions\n\n## Design Phase (Phase 1)\n\n**Data Models**:\n- Extract entities from spec requirements\n- Define schemas (prefer JSON Schema)\n- Separate input, output, intermediate models\n- Include validation rules\n\n**Test Scenarios**:\n- Map user stories to integration tests\n- Define test fixtures needed\n- Outline expected behaviors\n- Create quickstart validation steps\n\n## Arguments Expected\n\nWhen using this command, provide:\n1. Feature folder path (e.g., `ai_tasks/another-big-project/ml-automation/feature-snapshotter/`)\n2. (Optional) Custom instructions or technical focus areas\n\nExample usage:\n```\n/plan ai_tasks/another-big-project/ml-automation/feature-snapshotter/\n```\n\nWith custom prompt:\n```\n/plan ai_tasks/data-pipeline/etl-process/ Focus on scalability and error recovery patterns\n```\n\n## Success Criteria\n\nGenerated plan.md should:\n- Start from spec.md functional requirements\n- Define complete technical stack with versions\n- Include detailed project structure\n- Specify all major dependencies\n- Define clear implementation phases\n- Map spec requirements to technical components\n- Include concrete success criteria\n- Be actionable and specific (no ambiguity)\n- Follow the template structure\n- Use laconic, technical language\n\n## Common Pitfalls to Avoid\n\n‚ùå **Don't include**:\n- Business justifications (that's in spec)\n- Functional requirements lists (already in spec)\n- User scenarios verbatim (summarize technical approach)\n- Vague technology choices (\"use a database\" ‚Üí specify PostgreSQL 15+)\n\n‚úÖ **Do include**:\n- Specific technology versions\n- File paths and project structure\n- Implementation patterns and practices\n- Technical design decisions with rationale\n- Concrete success criteria\n\n**Now generate the plan.md file following the embedded template structure below, translating functional requirements from spec.md into technical implementation details.**\n\n---\n\n## Embedded Implementation Plan Template\n\nUse this template structure when generating plan.md files:\n\n```markdown\n# Implementation Plan Template for Claude Code\n\n**Created**: [DATE]\n**Status**: Draft\n**Input**: specification from *spec.md\n\n> Template for creating technical implementation details and plan for the functional requirements for use with Claude Code. Based on analysis of existing plans and Claude Code best practices.\n\n## Project Overview\n\n### Project Name\n`[Brief, descriptive name of the project/feature]`\n\n### Problem Statement\n`[Clear laconic description of the problem to be solved or feature to be implemented]`\n\n### Solution Summary\n`[High-level laconic approach and key outcomes expected]`\n\n---\n## Template Requirements\n### Execution Flow (main)\n```\n1. Parse user description from Input\n   ‚Üí If empty: ERROR \"No feature description provided\"\n2. Extract key concepts from description\n   ‚Üí Identify: actors, actions, data, constraints\n3. For each unclear aspect:\n   ‚Üí Mark with [NEEDS CLARIFICATION: specific question]\n4. Fill User Scenarios & Testing section\n   ‚Üí If no clear user flow: ERROR \"Cannot determine user scenarios\"\n5. Generate Functional Requirements\n   ‚Üí Each requirement must be testable\n   ‚Üí Mark ambiguous requirements\n6. Identify Key Entities (if data involved)\n7. Run Review Checklist\n   ‚Üí If any [NEEDS CLARIFICATION]: WARN \"Spec has uncertainties\"\n   ‚Üí If implementation details found: ERROR \"Remove tech details\"\n8. Return: SUCCESS (spec ready for planning)\n```\n## Summary\n[Extract from feature spec: primary requirement + technical approach from research]\n\n## Technical Implementation\n### Technical Context\n**Language/Version**: [e.g., Python 3.11, Swift 5.9, Rust 1.75 or NEEDS CLARIFICATION]\n**Primary Dependencies**: [e.g., FastAPI, UIKit, LLVM or NEEDS CLARIFICATION]\n**Storage**: [if applicable, e.g., PostgreSQL, CoreData, files or N/A]\n**Testing**: [e.g., pytest, XCTest, cargo test or NEEDS CLARIFICATION]\n**Target Platform**: [e.g., Linux server, iOS 15+, WASM or NEEDS CLARIFICATION]\n**Project Type**: [single/web/mobile - determines source structure]\n**Performance Goals**: [domain-specific, e.g., 1000 req/s, 10k lines/sec, 60 fps or NEEDS CLARIFICATION]\n**Constraints**: [domain-specific, e.g., <200ms p95, <100MB memory, offline-capable or NEEDS CLARIFICATION]\n**Scale/Scope**: [domain-specific, e.g., 10k users, 1M LOC, 50 screens or NEEDS CLARIFICATION]\n\n### Documentation (this feature)\n```\nai_tasks/[###project - one of pipeline, qa-tool, jira, icons-pipeline, routines, another-big-project]/[###-feature]/\n‚îú‚îÄ‚îÄ plan.md              # This file (/plan command output)\n‚îú‚îÄ‚îÄ research.md          # Phase 0 output (/plan command)\n‚îú‚îÄ‚îÄ quickstart.md        # Phase 1 output (/plan command)\n‚îî‚îÄ‚îÄ tasks.md             # Phase 2 output (/tasks command - NOT created by /plan)\n```\n\n### Source Code (repository root)\n```\nsrc/\n‚îú‚îÄ‚îÄ services/\n‚îú‚îÄ‚îÄ bin/\n‚îî‚îÄ‚îÄ utils/\n\ntests/\n‚îî‚îÄ‚îÄ unit/\n```\n\n## Phase 0: Outline & Research\n1. **Extract unknowns from Technical Context** above:\n    - For each NEEDS CLARIFICATION ‚Üí research task\n    - For each dependency ‚Üí best practices task\n    - For each integration ‚Üí patterns task\n\n2. **Generate and dispatch research agents**:\n   ```\n   For each unknown in Technical Context:\n     Task: \"Research {unknown} for {feature context}\"\n   For each technology choice:\n     Task: \"Find best practices for {tech} in {domain}\"\n   ```\n\n3. **Consolidate findings** in `research_for_plan.md` using format:\n    - Decision: [what was chosen]\n    - Rationale: [why chosen]\n    - Alternatives considered: [what else evaluated]\n\n**Output**: research.md with all NEEDS CLARIFICATION resolved\n\n## Phase 1: Design & Contracts\n*Prerequisites: research.md complete*\n\n1. **Extract entities from feature spec** ‚Üí `data-model.md`:\n    - Entity name, fields, relationships\n    - Validation rules from requirements\n    - State transitions if applicable\n    - Make separation for input and output models, outline the intermidiate models if needed\n    - Use JSON Schema for validation\n\n2**Extract test scenarios** from user stories ‚Üí `tests.md`:\n    - Each story ‚Üí integration test scenario\n    - Quickstart test = story validation steps\n\n**Output**: data-model.md, tests.md\n\n## Phase 2: Task Planning Approach\n\n**Task Generation Strategy**:\n- Load `.specify/templates/tasks-template.md` as base\n- Generate tasks from Phase 1 design docs (contracts, data model, quickstart)\n- Each contract ‚Üí contract test task [P]\n- Each entity ‚Üí model creation task [P]\n- Each user story ‚Üí integration test task\n- Implementation tasks to make tests pass\n\n**Ordering Strategy**:\n- TDD order: Tests before implementation\n- Dependency order: Models before services before UI\n- Mark [P] for parallel execution (independent files)\n\n**Estimated Output**: 25-30 numbered, ordered tasks in tasks.md\n\n**IMPORTANT**: This phase is executed by the /tasks command, NOT by /plan\n\n## Phase 3+: Future Implementation\n*These phases are beyond the scope of the /plan command*\n\n**Phase 3**: Task execution (/tasks command creates tasks.md)\n**Phase 4**: Implementation (execute tasks.md following constitutional principles)\n**Phase 5**: Validation (run tests, execute quickstart.md, performance validation)\n\n## Complexity Tracking\n*Fill ONLY if Constitution Check has violations that must be justified*\n\n| Violation | Why Needed | Simpler Alternative Rejected Because |\n|-----------|------------|-------------------------------------|\n| [e.g., 4th project] | [current need] | [why 3 projects insufficient] |\n| [e.g., Repository pattern] | [specific problem] | [why direct DB access insufficient] |\n\n\n## Tasks Breakdown\n\n### Task N: [Task Name]\n**Objective:** `[What this task accomplishes]`\n\n**Requirements:**\n- `[Specific requirement 1]`\n- `[Specific requirement 2]`\n- `[Integration points with existing systems]`\n- `[Performance/quality criteria]`\n\n**Key Components:**\n```language\n# Very Laconic pseudo code (or real code) examples or configuration snippets\n# Briefly show expected structure and patterns in very laconic form\n# Use plain English descriptions that Claude can understand and act on\n```\n\n**Files to Create/Modify:**``\n- ‚úÖ `path/to/file.ext` - Description of file purpose\n- ‚è≥ `path/to/other.ext` - Description of what needs implementation\n``\n---\n\n## Configuration & Setup\n\n**Project Structure:**\n```\nproject-root/\n‚îú‚îÄ‚îÄ config-files\n‚îú‚îÄ‚îÄ source-directories/\n‚îÇ   ‚îú‚îÄ‚îÄ module1/\n‚îÇ   ‚îî‚îÄ‚îÄ module2/\n‚îî‚îÄ‚îÄ documentation/\n```\n\n**Dependencies:**\n```toml\n# Package configuration examples\n[dependencies]\nkey-package = \"version\"\n```\n\n**Environment Setup:**\n```bash\n# Commands to set up the project\ncommand-to-install\ncommand-to-configure\n```\n\n---\n\n## Integration Points\n- `[How this integrates with existing systems]`\n- `[APIs or services used]`\n- `[Data flow and dependencies]`\n- `[Configuration management approach]`\n\n## Success Criteria\n\n### ‚úÖ Core Functionality\n- `[Primary feature working correctly]`\n- `[Error handling implemented]`\n- `[Performance meets requirements]`\n\n### ‚úÖ Quality & Reliability\n- `[Tests passing]`\n- `[Documentation complete]`\n- `[Code review requirements met]`\n\n### ‚úÖ Deployment & Operations\n- `[Configuration validated]`\n- `[Monitoring and logging in place]`\n- `[Rollback procedures documented]`\n\n---\n\n## Example Usage\n\n```bash\n# Basic usage examples\ncommand --option value\n\n# Advanced usage scenarios\ncommand --complex-option --with-parameters\n```\n\n**Expected Output:**\n```\nExample output showing what success looks like\n```\n\n## Additional Context\n\n### Design Decisions\n\n### Best Practices Applied\n- `[Coding standards followed]`\n- `[Security considerations addressed]`\n- `[Performance optimizations implemented]`\n\n### Reference Documentation\n- `[Links to relevant documentation]`\n- `[Related projects or examples]`\n- `[Technical specifications]`\n\n### Performance Considerations\n\n### Known Limitations\n\n---\n\n## Template Usage Notes\n\n**For Claude Code Users:**\n1. **Clear Requirements**: Specify exactly what needs to be built with concrete examples\n2. **Modular Tasks**: Break complex work into discrete, testable components\n4. **Code Examples**: Include expected more laconic patterns and structures to guide implementation\n5. **Success Criteria**: Define clear, measurable outcomes for each task\n\n**Best Practices:**\n- Use plain laconic English descriptions that Claude can understand and act on\n- Include specific file paths, commands, and configuration examples\n- Document integration points and dependencies clearly\n- Provide example usage and expected outputs\n- Reference existing patterns from similar projects when available\n```\n"
              },
              {
                "name": "/research",
                "description": null,
                "path": "easy-spec/commands/research.md",
                "frontmatter": null,
                "content": "Generate research document for investigating existing patterns and technical approaches.\n\n## Process\n\n1. **FIRST**: Check if the user already provided folder path and problem statement in their message\n   - Look for folder paths in the user's input (absolute paths like /Users/... or relative paths like ai_tasks/...)\n   - Look for problem/question descriptions (e.g., \"new night design for landmark icons\")\n   - Look for area of focus (e.g., \"bin/create-anki-cards.ts bin/format-book.ts\")\n   - Look for project paths to search (e.g., \"projects: /path/to/proj1/, /path/to/proj2/\")\n   - Only prompt if critical information (folder path and problem) is missing\n2. Use the embedded research template structure provided below\n3. Identify the relevant project context:\n   - If user provided project paths, use those directories for searching\n   - Otherwise, search in the current working directory and infer from context\n4. Search for existing patterns and reference implementations\n5. Investigate technical details and data flows\n6. Document findings with code references and file paths\n7. Analyze options and make recommendations\n8. Output research.md to the feature folder\n\n## Key Principles\n\n**Focus on existing code patterns:**\n- ‚úÖ Reference real file paths from the codebase\n- ‚úÖ Include actual code snippets showing patterns\n- ‚úÖ Compare similar implementations across projects\n- ‚ùå Don't invent solutions without checking existing code first\n\n**Laconic and practical:**\n- Brief problem statement (1-2 sentences)\n- Clear verification of findings (‚úÖ Verified, ‚ö†Ô∏è Assumptions, ‚ùå Gaps)\n- Concrete code references with file paths\n- Actionable implementation guidance\n\n**Deep investigation:**\n- Search for patterns in relevant projects\n- Analyze API contracts and data flows\n- Document decision rationale with trade-offs\n- Identify blockers and unknowns\n\n## Research Structure\n\n### 1. Problem / Question\nDefine what needs investigation:\n- Clear problem statement\n- Why it matters (business/technical reason)\n\n### 2. Existing Patterns\nFind and document reference implementations:\n- **Location**: Full file paths\n- **Project**: Which codebase (pipeline, qa-tool, etc.)\n- **Pattern**: What approach is used\n- **Code**: Laconic examples\n- **Analysis**: What works, what doesn't apply\n\n### 3. Investigation Results\nOrganize findings:\n- **‚úÖ Verified**: Confirmed with evidence\n- **‚ö†Ô∏è Assumptions**: Need validation\n- **‚ùå Gaps**: Missing information\n\n### 4. Technical Analysis\nDocument key details:\n- Data flow diagrams\n- API/Interface contracts\n- Dependencies and versions\n\n### 5. Decision Matrix\nCompare options:\n- Table with Pros/Cons/Effort\n- Final decision with rationale\n\n### 6. Implementation Guidance\nProvide actionable direction:\n- Recommended architecture\n- Key implementation points with references\n- Error handling strategies\n- Performance considerations\n\n### 7. Usage Example\nShow expected usage patterns\n\n### 8. Next Steps\nList concrete actions with checkboxes\n\n## Search Strategy\n\nWhen investigating, search for:\n1. Similar functionality (CLI commands, services, utilities)\n2. Similar tech stack (Node.js/TypeScript, Python, AWS)\n3. Similar data patterns (S3 downloads, Athena queries, rendering)\n4. Error handling and performance patterns\n\n**Project locations** should be provided by the user or inferred from their workspace. If not provided, search the current working directory and common project locations.\n\n## Verification Requirements\n\nFor each finding:\n- Include full file path\n- Reference specific line numbers if helpful\n- Show actual code (not pseudo-code)\n- Mark as ‚úÖ Verified only if confirmed from actual code\n\n## Arguments Expected\n\nWhen using this command, check the user's message for:\n1. **Folder path** - Look for absolute or relative paths (e.g., `ai_tasks/another-big-project/ml-automation/feature-name/`)\n2. **Problem statement** - Look for descriptions of what to investigate\n3. **Area of focus** - Look for mentions of specific files, components, or areas\n4. **Project paths** (optional) - Look for project directories to search in\n\nExample usage patterns:\n```\n/research ai_tasks/another-big-project/ml-automation/new-feature/\n```\n\nWith problem statement in same message:\n```\n/research\nInvestigate concurrent S3 download patterns in existing codebase\nfolder: ai_tasks/another-big-project/ml-automation/s3-downloads/\n```\n\nWith inline problem, folder, and focus:\n```\n/research new night design for landmark icons\nfolder: /path/to/folder\nfocus: bin/create-anki-cards.ts bin/format-book.ts\n```\n\nWith project paths to search:\n```\n/research new night design for landmark icons\nfolder: /path/to/folder\nfocus: bin/create-anki-cards.ts bin/format-book.ts\nprojects: /Users/dzianissheka/projects/dev/work/pipeline/, /Users/dzianissheka/projects/dev/work/qa-tool/\n```\n\n## Success Criteria\n\nGenerated research.md should:\n- Start with clear problem/question\n- Reference actual code with file paths\n- Include ‚úÖ Verified findings (not assumptions)\n- Provide decision matrix with rationale\n- Give implementation guidance with examples\n- List next steps with dependencies\n- Be laconic and actionable\n- Follow the template structure\n\n## Common Patterns to Look For\n\n**CLI Tools:**\n- Command structure (commander.js, typer)\n- Argument parsing patterns\n- Progress indicators (Rich, ora)\n\n**AWS Integration:**\n- S3 download patterns (concurrent, streaming)\n- Athena query execution\n- Secrets Manager access\n\n**Data Processing:**\n- GeoJSON handling\n- Parquet read/write\n- Schema validation (Pydantic, Zod)\n\n**Testing:**\n- Unit test patterns\n- Integration test setup\n- Mocking strategies\n\n**Now generate the research.md file following the embedded template structure below, focusing on existing patterns and verified findings from the codebase.**\n\n---\n\n## Embedded Research Template\n\nUse this template structure when generating research.md files:\n\n```markdown\n# Research: [Feature/Problem Name]\n\n**Date**: YYYY-MM-DD\n**Project**: [pipeline | data-pipeline | another-big-project | mobile-app-repo | qa-tool | map-pipeline | map-pipeline-common]\n**Status**: [Draft | In Progress | Complete]\n\n---\n\n## Problem / Question\n\n[Clear, very laconic statement of what needs to be investigated. One sentence if possible.]\n\n**Why this matters:**\n- [Business/technical reason]\n- [Impact on workflow/system]\n\n---\n\n## Existing Patterns\n\n### Reference Implementation\n\n**Location**: `/path/to/reference/code`\n**Project**: [project-name]\n**Pattern**: [What pattern/approach is used]\n\n**Key Files:**\n```\npath/to/file1.ts  # Purpose\npath/to/file2.ts  # Purpose\n```\n\n**Code Pattern:**\n```typescript\n// Laconic example showing the key pattern\n```\n\n**What works:**\n- [Strength 1]\n- [Strength 2]\n\n**What doesn't apply:**\n- [Limitation 1]\n- [Limitation 2]\n\n### Alternative Approaches\n\n**Option 1:** [Name]\n- **Where**: `/path/to/code`\n- **Pro**: [Key benefit]\n- **Con**: [Key limitation]\n\n**Option 2:** [Name]\n- **Where**: `/path/to/code`\n- **Pro**: [Key benefit]\n- **Con**: [Key limitation]\n\n---\n\n## Investigation Results\n\n### ‚úÖ Verified\n\n- [Confirmed finding 1 with evidence]\n- [Confirmed finding 2 with evidence]\n\n### ‚ö†Ô∏è Assumptions\n\n- [Assumption 1 that needs validation]\n- [Assumption 2 that needs validation]\n\n### ‚ùå Gaps\n\n- [Missing information 1]\n- [Unknown 2 - needs further investigation]\n\n---\n\n## Technical Analysis\n\n### Data Flow\n\n```\nInput ‚Üí [Process 1] ‚Üí [Process 2] ‚Üí Output\n```\n\n**Key Points:**\n- [Critical detail 1]\n- [Critical detail 2]\n\n### API/Interface Contract\n\n**Input:**\n```typescript\n// Expected input structure\n```\n\n**Output:**\n```typescript\n// Expected output structure\n```\n\n**Dependencies:**\n- [Dependency 1] - [Version/source]\n- [Dependency 2] - [Version/source]\n\n---\n\n## Decision Matrix\n\n| Approach | Pros | Cons | Effort | Recommendation |\n|----------|------|------|--------|----------------|\n| Option 1 | | | | |\n| Option 2 | | | | |\n| Option 3 | | | | |\n\n**Final Decision:** [Chosen approach]\n\n**Rationale:**\n- [Reason 1]\n- [Reason 2]\n\n---\n\n## Implementation Guidance\n\n### Architecture\n\n```\ncomponent1/\n‚îú‚îÄ‚îÄ file1.ts  # Purpose\n‚îî‚îÄ‚îÄ file2.ts  # Purpose\n```\n\n### Key Implementation Points\n\n1. **[Component 1]**\n   - Pattern: [Reference to existing code]\n   - Critical detail: [What must be done]\n\n2. **[Component 2]**\n   - Pattern: [Reference to existing code]\n   - Critical detail: [What must be done]\n\n### Error Handling\n\n- [Error case 1]: [Strategy]\n- [Error case 2]: [Strategy]\n\n### Performance Considerations\n\n- [Consideration 1]\n- [Consideration 2]\n\n---\n\n## Usage Example\n\n```bash\n# Basic usage\ncommand --input value --output result\n\n# Advanced usage\ncommand --flag1 --flag2 value\n```\n\n---\n\n## Next Steps\n\n1. [ ] [Action 1]\n2. [ ] [Action 2]\n3. [ ] [Action 3]\n\n**Blockers:**\n- [Blocker 1 if any]\n\n---\n\n## References\n\n### Code References\n- Project: `/Users/dzianissheka/projects/dev/work/[project]/path/to/file`\n- Pattern: `/Users/dzianissheka/projects/dev/work/[project]/path/to/pattern`\n\n### Documentation\n- [Doc link 1]\n- [Doc link 2]\n\n### Related Research\n- `ai_tasks/[project]/[feature]/research.md`\n\n---\n\n## Quick Summary\n\n**TL;DR:**\n- [Key finding 1]\n- [Key finding 2]\n- [Recommended approach]\n\n**Status:** [Ready for spec | Needs more investigation | Blocked]\n```\n```\n"
              },
              {
                "name": "/spec",
                "description": null,
                "path": "easy-spec/commands/spec.md",
                "frontmatter": null,
                "content": "Generate functional requirements specification (spec.md) from research documents.\n\n## Process\n\n1. **FIRST**: Check if the user already provided folder path in their message\n   - Look for absolute paths like /Users/... or relative paths like ai_tasks/...\n   - Only prompt if folder path is missing\n2. Read research documents from the specified feature folder:\n   - `research.md` or `*research*.md` files (primary source)\n   - Any other analysis or investigation documents\n3. Use the embedded spec template structure provided below\n4. Extract key information:\n   - Problem statement and solution approach\n   - User needs and scenarios\n   - Input/output data requirements\n   - Business logic and data transformations\n   - Edge cases and error scenarios\n5. Generate spec.md focused on WHAT (functional requirements), not HOW (implementation)\n6. Create numbered functional requirements (FR-001, FR-002, ...)\n7. Write acceptance scenarios in Given-When-Then format\n8. Output spec.md to the feature folder\n\n## Key Principles\n\n**Focus on WHAT, not HOW:**\n- ‚úÖ \"System MUST accept GeoJSON files in RFC 7946 format\"\n- ‚ùå \"Use @mapbox/maps-snapshotter library to render\"\n\n**Write for business stakeholders:**\n- Use plain, laconic English\n- Describe user needs and behaviors\n- Avoid technical implementation details\n- No code, APIs, or architecture\n\n**Be specific and testable:**\n- Each requirement must be verifiable\n- Use precise language (MUST, SHOULD, MAY)\n- Include measurable criteria where applicable\n- Mark ambiguities with [NEEDS CLARIFICATION: question]\n\n## Requirement Categories\n\nOrganize requirements by:\n\n1. **Input Data**: What data does the system accept?\n   - File formats, data structures\n   - Validation rules\n   - Size/scale requirements\n\n2. **Output Data**: What does the system produce?\n   - Output formats and naming\n   - Quality requirements\n   - Success criteria\n\n3. **Business Logic**: How is data transformed?\n   - Processing rules\n   - Calculations and algorithms\n   - User interactions\n   - Error handling behaviors\n\n4. **Performance & Scale**: Non-functional requirements\n   - Response time targets\n   - Throughput requirements\n   - Resource constraints\n\n## Functional Requirements Format\n\nEach requirement:\n- **FR-XXX**: System MUST/SHOULD/MAY [specific capability]\n- Use active voice and imperative mood\n- One requirement per line\n- Numbered sequentially (FR-001, FR-002, ...)\n\nExample:\n```\n- **FR-001**: System MUST accept GeoJSON files in standard RFC 7946 format\n- **FR-002**: System MUST support Point, LineString, Polygon, and Multi* geometries\n- **FR-003**: System MUST generate PNG images with configurable dimensions\n```\n\n## User Scenarios Format\n\n**Primary User Story** (1 sentence):\n```\nUser provides input file and configuration; system processes data and produces output with expected results.\n```\n\n**Acceptance Scenarios** (Given-When-Then):\n```\n1. **Given** valid input file, **When** user runs command with default settings, **Then** output file created with expected format\n2. **Given** invalid input, **When** user runs command, **Then** clear error message displayed\n```\n\n**Edge Cases** (questions):\n```\n- What happens when input file is empty?\n- What happens when input exceeds size limit?\n- How does system handle missing required parameters?\n```\n\n## Output Structure\n\nThe spec.md should include:\n\n1. **Project Overview**\n   - Project name (clear, descriptive)\n   - Problem statement (laconic, user-focused)\n   - Solution summary (high-level approach)\n\n2. **Functional Requirements**\n   - User scenarios and testing (mandatory)\n   - Requirements organized by category (mandatory)\n   - Input data requirements (FR-001+)\n   - Output data requirements (FR-010+)\n   - Business logic requirements (FR-020+)\n   - Error handling & logging (FR-030+)\n\n3. **Additional Context** (optional)\n   - Reference documentation\n   - Related projects or examples\n   - CLI interface examples (for tools)\n   - Performance targets\n\n## Common Pitfalls to Avoid\n\n‚ùå **Don't include**:\n- Technology choices (Node.js, Python, AWS)\n- Implementation details (classes, functions, APIs)\n- Code examples or structure\n- Architecture diagrams\n- Library/framework names\n\n‚úÖ **Do include**:\n- User needs and workflows\n- Data formats and validation rules\n- Expected behaviors and outcomes\n- Error handling requirements\n- Performance targets\n\n## Arguments Expected\n\nWhen using this command, provide:\n1. Feature folder path (e.g., `ai_tasks/another-big-project/ml-automation/feature-snapshotter/`)\n2. (Optional) Custom instructions or focus areas\n\nExample usage:\n```\n/spec ai_tasks/another-big-project/ml-automation/feature-snapshotter/\n```\n\nWith custom prompt:\n```\n/spec ai_tasks/data-pipeline/etl-process/ Focus on data validation and error recovery requirements\n```\n\n## Success Criteria\n\nGenerated spec.md should:\n- Be readable by non-technical stakeholders\n- Contain only functional requirements (WHAT)\n- Have numbered, testable requirements\n- Include user scenarios with clear acceptance criteria\n- Mark any ambiguities or assumptions\n- Follow the template structure\n- Use laconic, precise language\n\n**Now generate the spec.md file following the embedded template structure below.**\n\n---\n\n## Embedded Spec Template\n\nUse this template structure when generating spec.md files:\n\n```markdown\n# Functional Requirements Template for Claude Code\n\n**Created**: [DATE]\n**Status**: Draft\n**Input**: User description: \"$USER_RAW_PROMPT$\"\n\n> Template for creating comprehensive functional requirements for use with Claude Code. Based on analysis of the existing code base, user prompt, provided context, Claude Code best practices.\n\n## Project Overview\n\n### Project Name\n`[Brief, descriptive name of the project/feature]`\n\n### Problem Statement\n`[Clear laconic description of the problem to be solved or feature to be implemented]`\n\n### Solution Summary\n`[High-level laconic approach on how to solve the problem specified in functional requirements ]`\n\n---\n## Functional Requirements\n\n### ‚ö° Quick Guidelines\n- ‚úÖ Focus on WHAT users need and WHY\n- ‚ùå Avoid HOW to implement (no tech stack, APIs, code structure)\n- üë• Written for business stakeholders, not developers\n- Use more laconic style\n\n### Section Requirements\n- **Mandatory sections**: Must be completed for every feature\n\n### For AI Generation\nWhen creating this spec from a user prompt:\n1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] for any assumption you'd need to make\n2. **Don't guess**: If the prompt doesn't specify something (e.g., \"login system\" without auth method), mark it\n3. **Think like a tester**: Every vague requirement should fail the \"testable and unambiguous\" checklist item\n4. **Common underspecified areas**:\n    - Performance targets and scale\n    - Error handling behaviors\n    - Integration requirements\n### User Scenarios & Testing *(mandatory)*\n#### Primary User Story (main - 1 sentence)\n[Describe the main user journey in plain and more laconic English language]\n\n#### Acceptance Scenarios (1-5 main scenarios)\n1. **Given** [initial state], **When** [action], **Then** [expected outcome]\n2. **Given** [initial state], **When** [action], **Then** [expected outcome]\n\n#### Edge Cases (0-5 edge cases)\n- What happens when [edge case]?\n- What happens when [boundary condition]?\n- How does system handle [error scenario]?\n\n## Requirements *(mandatory)*\n\nAnalyze input data and provide a list of functional requirements.\nAnalyze output data and provide a list of functional requirements.\nAnalyze business logic (data transformation, user interaction, how we need to process the data to produce the desired output) and provide a list of functional requirements.\n\n### Functional Requirements\n- **FR-001**: System MUST [specific capability, e.g., \"allow users to create accounts\"]\n- **FR-002**: System MUST [specific capability, e.g., \"validate email addresses\"]\n- **FR-003**: Users MUST be able to [key interaction, e.g., \"reset their password\"]\n- **FR-004**: System MUST [data requirement, e.g., \"persist user preferences\"]\n- **FR-005**: System MUST [behavior, e.g., \"log all security events\"]\n---\n\n\n## Additional Context *(optional)*\n\n### Reference Documentation\n- `[Links to relevant documentation]`\n- `[Related projects or examples]`\n\n---\n\n## Template Usage Notes\n\n**Best Practices:**\n- Use plain and more laconic English descriptions that Claude can understand and act on\n```\n"
              },
              {
                "name": "/tasks",
                "description": null,
                "path": "easy-spec/commands/tasks.md",
                "frontmatter": null,
                "content": "Generate a comprehensive tasks.md file from an implementation plan.md using the tasks_template.md structure.\n\n## Process\n\n1. **FIRST**: Check if the user already provided folder path in their message\n   - Look for absolute paths like /Users/... or relative paths like ai_tasks/...\n   - Only prompt if folder path is missing\n2. Read the plan.md from the specified feature folder\n3. Read spec.md, research.md, data-model.md if available\n4. Use the embedded tasks template structure provided below\n5. Extract tech stack, project structure, and implementation details\n6. Generate numbered tasks (T001-T0XX) organized by phase:\n   - Phase 3.1: Setup (project init, dependencies, config)\n   - Phase 3.2: Configuration & Templates (if applicable)\n   - Phase 3.3: Core Implementation (services, models, business logic)\n   - Phase 3.4: Integration (external systems, middleware, error handling)\n   - Phase 3.5: Polish (tests, docs, performance)\n7. Mark [P] for parallel-safe tasks (different files, no dependencies)\n8. Create dependency graph showing task relationships\n9. Write detailed task specifications with objectives, requirements, code examples\n10. Output tasks.md to the feature folder\n\n## Task Format Requirements\n\nEach task must include:\n- Numbered ID (T001, T002, etc.)\n- [P] marker if can run in parallel\n- Clear description with exact file paths\n- Detailed specification section:\n  - Objective\n  - Requirements\n  - Key Components (with code examples)\n  - Implementation Details\n  - Files to Create/Modify\n\n## Arguments Expected\n\nWhen using this command, provide:\n1. Feature folder path (e.g., `ai_tasks/another-big-project/ml-automation/feature-snapshotter/`)\n2. (Optional) Custom instructions or focus areas\n\nExample usage in chat:\n```\nUse the /tasks command to generate tasks for ai_tasks/another-big-project/ml-automation/feature-snapshotter/\n```\n\nOr with custom prompt:\n```\nUse the /tasks command for ai_tasks/another-big-project/ml-automation/feature-name/ with focus on TypeScript best practices\n```\n\n---\n\n## Embedded Tasks Template\n\nUse this template structure when generating tasks.md files:\n\n```markdown\n# Tasks: [FEATURE NAME]\n\n**Created**: [DATE]\n**Status**: Draft\n**Input**: Design documents from `/specs/[###-feature-name]/`\n**Prerequisites**: spec.md, plan.md (required), research.md, data-model.md\n\n> Template for creating technical implementation details for the functional requirements for use with Claude Code. Based on analysis of existing plans and Claude Code best practices.\n\n\n## Execution Flow (main)\n```\n1. Load plan.md from feature directory\n   ‚Üí If not found: ERROR \"No implementation plan found\"\n   ‚Üí Extract: tech stack, libraries, structure\n2. Load optional design documents:\n   ‚Üí data-model.md: Extract entities ‚Üí model tasks\n   ‚Üí research_for_plan.md: Extract decisions ‚Üí setup tasks\n3. Generate tasks by category:\n   ‚Üí Setup: project init, dependencies, linting\n   ‚Üí Core: input and output models with schema, services, CLI commands\n   ‚Üí Integration: DB, middleware, logging\n   ‚Üí Polish: unit tests, performance, solution simplification, docs\n4. Apply task rules:\n   ‚Üí Different files = mark [P] for parallel\n   ‚Üí Same file = sequential (no [P])\n5. Number tasks sequentially (T001, T002...)\n6. Generate dependency graph\n7. Create parallel execution examples\n8. Return: SUCCESS (tasks ready for execution)\n```\n\n---\n\n## Format: `[ID] [P?] Description`\n- **[P]**: Can run in parallel (different files, no dependencies)\n- Include exact file paths in descriptions\n\n\n## Tasks Breakdown\n\n## Phase 3.1: Setup\n- [ ] T001 Create project structure per implementation plan\n- [ ] T002 Initialize [language] project with [framework] dependencies\n- [ ] T003 [P] Configure linting and formatting tools\n\n## Phase 3.3: Core Implementation\n- [ ] T008 [P] User model in src/models/user.py\n- [ ] T009 [P] UserService CRUD in src/services/user_service.py\n- [ ] T010 [P] CLI --create-user in src/cli/user_commands.py\n- [ ] T011 POST /api/users endpoint\n- [ ] T012 GET /api/users/{id} endpoint\n- [ ] T013 Input validation\n- [ ] T014 Error handling and logging\n\n## Phase 3.4: Integration\n- [ ] T015 Connect UserService to DB\n- [ ] T016 Auth middleware\n- [ ] T017 Request/response logging\n- [ ] T018 CORS and security headers\n\n## Phase 3.5: Polish\n- [ ] T019 [P] Unit tests for validation in tests/unit/test_validation.py\n- [ ] T020 Performance tests (<200ms)\n- [ ] T021 [P] Update docs/api.md\n- [ ] T022 Remove duplication\n- [ ] T023 Run manual-testing.md\n\n## Dependencies\n- Tests (T004-T007) before implementation (T008-T014)\n- T008 blocks T009, T015\n- T016 blocks T018\n- Implementation before polish (T019-T023)\n\n## Task Generation Rules\n*Applied during main() execution*\n\n\n1**From Data Model**:\n    - Each entity ‚Üí model creation task [P]\n    - Relationships ‚Üí service layer tasks\n\n2. **From User Stories**:\n    - Each story ‚Üí integration test [P]\n    - Test scenarios ‚Üí validation tasks\n\n3**Ordering**:\n    - Setup ‚Üí Models ‚Üí Services ‚Üí Integration ‚Üí Polish\n    - Dependencies block parallel execution\n\n\n### Task N: [Task Name]\n**Objective:** `[What this task accomplishes]`\n\n**Requirements:**\n- `[Specific requirement 1]`\n- `[Specific requirement 2]`\n- `[Integration points with existing systems]`\n\n**Key Components:**\n```language\n# Laconic code examples or configuration snippets\n# Show expected structure and patterns in very laconic form\n# Use plain English descriptions that Claude can understand and act on\n```\n\n**Implementation Details:**\n- `[Technical approach and methodology]`\n- `[Dependencies and prerequisites]`\n- `[Error handling considerations]`\n- `[Testing approach]`\n\n**Files to Create/Modify:**\n- ‚úÖ `path/to/file.ext` - Description of file purpose\n- ‚è≥ `path/to/other.ext` - Description of what needs implementation\n\n---\n\n## Implementation Status\n\n### Task N: [Task Name] `[STATUS: ‚úÖ COMPLETED | ‚è≥ PENDING | üîÑ IN PROGRESS]`\n**Progress Summary:**\n- ‚úÖ `[Completed milestone 1]`\n- ‚úÖ `[Completed milestone 2]`\n- ‚è≥ `[Pending work item]`\n\n**Implementation Notes:**\n- `[Key decisions made during implementation]`\n- `[Challenges encountered and solutions]`\n- `[Performance metrics or test results]`\n\n---\n\n## Configuration & Setup\n\n**Project Structure:**\n```\nproject-root/\n‚îú‚îÄ‚îÄ config-files\n‚îú‚îÄ‚îÄ source-directories/\n‚îÇ   ‚îú‚îÄ‚îÄ module1/\n‚îÇ   ‚îî‚îÄ‚îÄ module2/\n‚îî‚îÄ‚îÄ documentation/\n```\n\n**Dependencies:**\n```toml\n# Package configuration examples\n[dependencies]\nkey-package = \"version\"\n```\n\n**Environment Setup:**\n```bash\n# Commands to set up the project\ncommand-to-install\ncommand-to-configure\n```\n\n---\n\n## Implementation Notes\n\n### Current Status\n**Working Features:**\n- `[List of completed and tested features]`\n\n**Known Issues:**\n- `[Any current limitations or bugs]`\n\n**Next Steps:**\n- `[Immediate follow-up work needed]`\n\n---\n\n\n## Template Usage Notes\n\n**For Claude Code Users:**\n1. **Clear Requirements**: Specify exactly what needs to be built with concrete examples\n2. **Modular Tasks**: Break complex work into discrete, testable components\n3. **Status Tracking**: Use checkboxes and status indicators to track progress\n4. **Code Examples**: Include expected laconic patterns and structures to guide implementation\n\n\n**Best Practices:**\n- Use plain laconic English descriptions that Claude can understand and act on\n- Include specific file paths, commands, and configuration examples\n- Track implementation status with visual indicators (‚úÖ‚è≥üîÑ)\n- Reference existing patterns from similar projects when available\n```\n"
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}