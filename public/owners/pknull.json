{
  "owner": {
    "id": "pknull",
    "display_name": "Louis Grenzebach",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/894842?v=4",
    "url": "https://github.com/pknull",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 4,
      "total_commands": 9,
      "total_skills": 0,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "pknull/asha-marketplace",
      "url": "https://github.com/pknull/asha-marketplace",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-12T20:19:05Z",
        "created_at": "2025-11-13T08:36:22Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1640
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 281
        },
        {
          "path": ".tool-versions",
          "type": "blob",
          "size": 14
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 25193
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1063
        },
        {
          "path": "Memory",
          "type": "tree",
          "size": null
        },
        {
          "path": "Memory/sessions",
          "type": "tree",
          "size": null
        },
        {
          "path": "Memory/sessions/current-session.md",
          "type": "blob",
          "size": 1206
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5993
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 298
        },
        {
          "path": "plugins/asha/README.md",
          "type": "blob",
          "size": 3800
        },
        {
          "path": "plugins/asha/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/commands/cleanup.md",
          "type": "blob",
          "size": 3811
        },
        {
          "path": "plugins/asha/commands/index.md",
          "type": "blob",
          "size": 1695
        },
        {
          "path": "plugins/asha/commands/init.md",
          "type": "blob",
          "size": 3788
        },
        {
          "path": "plugins/asha/commands/note.md",
          "type": "blob",
          "size": 1416
        },
        {
          "path": "plugins/asha/commands/save.md",
          "type": "blob",
          "size": 2887
        },
        {
          "path": "plugins/asha/commands/status.md",
          "type": "blob",
          "size": 3029
        },
        {
          "path": "plugins/asha/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/hooks/handlers",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/hooks/handlers/common.sh",
          "type": "blob",
          "size": 2077
        },
        {
          "path": "plugins/asha/hooks/handlers/post-tool-use",
          "type": "blob",
          "size": 7629
        },
        {
          "path": "plugins/asha/hooks/handlers/session-end",
          "type": "blob",
          "size": 1430
        },
        {
          "path": "plugins/asha/hooks/handlers/session-start.sh",
          "type": "blob",
          "size": 1733
        },
        {
          "path": "plugins/asha/hooks/handlers/user-prompt-submit",
          "type": "blob",
          "size": 7447
        },
        {
          "path": "plugins/asha/hooks/handlers/violation-checker",
          "type": "blob",
          "size": 2319
        },
        {
          "path": "plugins/asha/hooks/hooks.json",
          "type": "blob",
          "size": 871
        },
        {
          "path": "plugins/asha/modules",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/modules/CORE.md",
          "type": "blob",
          "size": 4829
        },
        {
          "path": "plugins/asha/modules/code.md",
          "type": "blob",
          "size": 5364
        },
        {
          "path": "plugins/asha/modules/high-stakes.md",
          "type": "blob",
          "size": 3550
        },
        {
          "path": "plugins/asha/modules/memory-ops.md",
          "type": "blob",
          "size": 2872
        },
        {
          "path": "plugins/asha/modules/research.md",
          "type": "blob",
          "size": 3210
        },
        {
          "path": "plugins/asha/modules/verbalized-sampling.md",
          "type": "blob",
          "size": 4752
        },
        {
          "path": "plugins/asha/modules/writing.md",
          "type": "blob",
          "size": 6359
        },
        {
          "path": "plugins/asha/rules",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/rules/destructive-git.sh",
          "type": "blob",
          "size": 1412
        },
        {
          "path": "plugins/asha/rules/file-header.sh",
          "type": "blob",
          "size": 1782
        },
        {
          "path": "plugins/asha/rules/memory-protection.sh",
          "type": "blob",
          "size": 1282
        },
        {
          "path": "plugins/asha/rules/vault-structure.sh",
          "type": "blob",
          "size": 1177
        },
        {
          "path": "plugins/asha/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/templates/CLAUDE.md",
          "type": "blob",
          "size": 1933
        },
        {
          "path": "plugins/asha/templates/activeContext.md",
          "type": "blob",
          "size": 667
        },
        {
          "path": "plugins/asha/templates/communicationStyle.md",
          "type": "blob",
          "size": 390
        },
        {
          "path": "plugins/asha/templates/projectbrief.md",
          "type": "blob",
          "size": 1388
        },
        {
          "path": "plugins/asha/templates/scratchpad.md",
          "type": "blob",
          "size": 476
        },
        {
          "path": "plugins/asha/templates/techEnvironment.md",
          "type": "blob",
          "size": 1052
        },
        {
          "path": "plugins/asha/templates/workflowProtocols.md",
          "type": "blob",
          "size": 1998
        },
        {
          "path": "plugins/asha/tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/asha/tools/memory-search",
          "type": "blob",
          "size": 1062
        },
        {
          "path": "plugins/asha/tools/memory_index.py",
          "type": "blob",
          "size": 29774
        },
        {
          "path": "plugins/asha/tools/reasoning_bank.py",
          "type": "blob",
          "size": 24468
        },
        {
          "path": "plugins/asha/tools/requirements.txt",
          "type": "blob",
          "size": 181
        },
        {
          "path": "plugins/asha/tools/run-python.sh",
          "type": "blob",
          "size": 759
        },
        {
          "path": "plugins/asha/tools/save-session.sh",
          "type": "blob",
          "size": 12129
        },
        {
          "path": "plugins/local-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/local-review/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/local-review/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 266
        },
        {
          "path": "plugins/local-review/README.md",
          "type": "blob",
          "size": 1705
        },
        {
          "path": "plugins/local-review/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/local-review/commands/local-review.md",
          "type": "blob",
          "size": 3187
        },
        {
          "path": "plugins/output-styles",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/output-styles/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/output-styles/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 260
        },
        {
          "path": "plugins/output-styles/README.md",
          "type": "blob",
          "size": 1534
        },
        {
          "path": "plugins/output-styles/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/output-styles/commands/style.md",
          "type": "blob",
          "size": 1636
        },
        {
          "path": "plugins/output-styles/hooks-handlers",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/output-styles/hooks-handlers/session-start.sh",
          "type": "blob",
          "size": 1002
        },
        {
          "path": "plugins/output-styles/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/output-styles/hooks/hooks.json",
          "type": "blob",
          "size": 228
        },
        {
          "path": "plugins/output-styles/styles",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/output-styles/styles/bullet-points.md",
          "type": "blob",
          "size": 3554
        },
        {
          "path": "plugins/output-styles/styles/genui.md",
          "type": "blob",
          "size": 5957
        },
        {
          "path": "plugins/output-styles/styles/html-structured.md",
          "type": "blob",
          "size": 2595
        },
        {
          "path": "plugins/output-styles/styles/markdown-focused.md",
          "type": "blob",
          "size": 2249
        },
        {
          "path": "plugins/output-styles/styles/table-based.md",
          "type": "blob",
          "size": 1836
        },
        {
          "path": "plugins/output-styles/styles/tts-summary.md",
          "type": "blob",
          "size": 2083
        },
        {
          "path": "plugins/output-styles/styles/ultra-concise.md",
          "type": "blob",
          "size": 580
        },
        {
          "path": "plugins/output-styles/styles/yaml-structured.md",
          "type": "blob",
          "size": 1854
        },
        {
          "path": "plugins/panel",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/panel/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/panel/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 552
        },
        {
          "path": "plugins/panel/LICENSE",
          "type": "blob",
          "size": 1063
        },
        {
          "path": "plugins/panel/README.md",
          "type": "blob",
          "size": 13292
        },
        {
          "path": "plugins/panel/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/panel/agents/recruiter.md",
          "type": "blob",
          "size": 8077
        },
        {
          "path": "plugins/panel/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/panel/commands/panel.md",
          "type": "blob",
          "size": 14203
        },
        {
          "path": "plugins/panel/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/panel/docs/_template.md",
          "type": "blob",
          "size": 9493
        },
        {
          "path": "plugins/panel/docs/characters",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/panel/docs/characters/The Analyst.md",
          "type": "blob",
          "size": 7358
        },
        {
          "path": "plugins/panel/docs/characters/The Challenger.md",
          "type": "blob",
          "size": 7460
        },
        {
          "path": "plugins/panel/docs/characters/The Moderator.md",
          "type": "blob",
          "size": 3885
        },
        {
          "path": "plugins/panel/docs/file:\\\\\\home\\pknull\\Obsidian\\AAS\\.claude\\agents\\_template.md.desktop",
          "type": "blob",
          "size": 199
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/validate-plugins.sh",
          "type": "blob",
          "size": 5527
        }
      ],
      "marketplace": {
        "name": "asha-marketplace",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "pknull",
          "email": "noreply@example.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "panel-system",
            "description": "Dynamic multi-perspective analysis with 3 core roles + recruited specialists. Supports --format (github/json/markdown) and --context flags. Consensus tracking with percentage thresholds.",
            "source": "./plugins/panel",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add pknull/asha-marketplace",
              "/plugin install panel-system@asha-marketplace"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T20:19:05Z",
              "created_at": "2025-11-13T08:36:22Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/panel",
                "description": "Convene multi-perspective expert panel for analysis and decision-making",
                "path": "plugins/panel/commands/panel.md",
                "frontmatter": {
                  "description": "Convene multi-perspective expert panel for analysis and decision-making",
                  "argument-hint": "Topic or question to analyze",
                  "allowed-tools": [
                    "Task",
                    "Read",
                    "Write",
                    "Edit",
                    "Grep",
                    "Glob"
                  ]
                },
                "content": "# Panel - Expert Multi-Perspective Analysis\n\nConvene a panel with 3 core roles + dynamically recruited specialists who analyze your topic from distinct perspectives and produce a structured decision through an 11-phase protocol.\n\n## Usage\n\n```bash\n/panel How do we pimp fish\n/panel Should we implement GraphQL or REST for the new API\n/panel Evaluate Chapter 9's horror-erotica effectiveness\n```\n\n### Options\n\n```bash\n/panel --format=github \"Topic here\"     # Output as GitHub PR comment\n/panel --format=json \"Topic here\"       # Output as structured JSON\n/panel --context=docs/RFC.md \"Topic\"    # Inject reference material\n/panel --context=spec.md --format=github \"Evaluate this proposal\"\n```\n\n**Flags**:\n- `--format=<type>`: Output format (`markdown` default, `github`, `json`)\n- `--context=<file>`: Pre-load reference material into panel context\n\n**That's it.** The panel handles everything automatically:\n- The Recruiter analyzes topic and recruits 2-5 specialist agents from available library\n- Assigns specialists with evocative session-specific names\n- Infers goals from topic context\n- Applies consensus decision rule (unanimous for security topics)\n- The Adversary argues against proposals and demands proof of necessity\n- Asha moderates and compiles the decision report\n\n## Core Roles (Always Present)\n\n**Asha** (Moderator/Facilitator)\n- Manages 11-phase protocol execution\n- Ensures procedural integrity and timebox enforcement\n- Synthesizes final decision report\n- **Question**: \"What is the PROCESS?\"\n\n**The Recruiter** (Workforce Intelligence)\n- Analyzes topic to determine needed expertise\n- Scores available agent library (0-10) for capability match\n- Recruits 2-5 specialist agents with session-specific names\n- Deploys `agent-fabricator` if capability gaps detected\n- **Question**: \"Who has CAPABILITY?\"\n\n**The Adversary** (Opposition & Quality Gate)\n- **Default stance: OPPOSE** - argues against proposals and defends status quo\n- Demands evidence before changing working systems: \"Show me user complaints, failure data, metrics\"\n- Forces proponents to prove necessity: \"The current system works. Prove it doesn't.\"\n- Prevents premature action and consensus formed without data\n- **Question**: \"Why should we do this at all?\"\n\n## Dynamic Panelists (Recruited Per Topic)\n\nThe Recruiter assigns agents from `.claude/agents/*.md` with **evocative session-specific names** based on topic context.\n\n**Examples by Topic Type**:\n\n**Creative Writing Panel** (Callum Chapter 9 evaluation):\n- `prose-analysis` ‚Üí **\"The Editor\"** (craft assessment)\n- `intimacy-designer` ‚Üí **\"The Architect of Dread\"** (genre mechanics)\n- `narrative-architect` ‚Üí **\"The Structuralist\"** (story coherence)\n- `character-developer` ‚Üí **\"The Psychologist\"** (character authenticity)\n\n**Technical Architecture Panel** (GraphQL vs REST):\n- `research-assistant` ‚Üí **\"The Evidence Gatherer\"** (source validation)\n- `architect` ‚Üí **\"The Systems Designer\"** (architecture patterns)\n- `ml-engineer` ‚Üí **\"The Model Capability Analyst\"** (performance analysis)\n\n**Culinary Innovation Panel** (How do we pimp fish):\n- `research-assistant` ‚Üí **\"The Culinary Historian\"** (technique research)\n- `trend-analyst` ‚Üí **\"The Flavor Prophet\"** (emerging patterns)\n- `creative-director` ‚Üí **\"The Presentation Architect\"** (plating design)\n\n**Session-Specific Naming Convention**:\n- **Agent role** describes what it does (e.g., `prose-analysis`)\n- **Session name** describes who it becomes for this panel (e.g., \"The Editor\")\n- Names should be evocative, contextual, and domain-appropriate\n\n## 11-Phase Protocol\n\n**Phase -1: Topic Analysis & Workforce Recruitment** (The Recruiter)\n- Analyze topic domain (technical, creative, research-heavy, security-critical)\n- Determine required expertise areas (2-5 domains typical)\n- Search agent library systematically (`.claude/agents/*.md`)\n- Score agents 0-10 for topic capability match:\n  * 10: Perfect specialist match\n  * 7-9: Strong capabilities alignment\n  * 4-6: Partial match, can handle with coordination\n  * 1-3: Poor match, inefficient\n  * 0: No coverage, gap identified\n- Assign specialists with session-specific names (e.g., `prose-analysis` ‚Üí \"The Editor\")\n- Deploy `agent-fabricator` if gaps detected (no agent scores >4)\n- Set decision rule (consensus default, unanimous for security)\n- Infer primary goals from topic context\n\n**Phase 0: Goal Clarification** (Asha)\n- Request clarification if topic is ambiguous or underspecified\n- Formalize refined topic statement\n- Skip if topic is already well-specified\n\n**Phase 1: Framing** (Asha)\n- State topic, inferred goals, constraints, decision rule\n- Introduce panel composition:\n  * Core roles (Asha, Recruiter, Adversary)\n  * Recruited specialists with session names\n- Explain recruitment rationale (why these specialists for this topic)\n- Establish complete panel composition before Initial Positions\n\n**Phase 2: Infrastructure Check** (Asha)\n- Compare proposals against existing assets to avoid duplication:\n  * Memory files (workflowProtocols.md, activeContext.md)\n  * Commands (/panel, /save, /notes, /validate-vault)\n  * Agents (research-assistant, narrator, etc.)\n- Output \"Existing Infrastructure Comparison\"\n- Redirect to enhancement if duplicative\n\n**Phase 3: Initial Positions** (All Panelists)\n- Each specialist (via recruited agent) gathers information and analyzes from their domain\n- The Adversary takes opposition stance: \"DON'T do this because...\" and demands proof\n- Synthesize into 5-bullet brief: Position, Evidence, Risks, Unknowns, Recommendation\n- Present findings with citations\n\n**Phase 4: Cross-Examination** (The Adversary-led)\n- The Adversary challenges assumptions, finds contradictions and failure modes\n- Specialists respond from their domain perspectives\n- Recruiter may assign additional agents if challenges reveal capability gaps\n\n**Phase 5: Research Gate** (Asha)\n- If evidence gaps block decisions, authorize additional research\n- Direct specialists to run targeted queries using assigned agents\n- Recruiter may assign additional specialized agents if insufficient\n- Enforce Confidence Scoring: Relevance, Completeness, Confidence Score\n- Thresholds: <0.6 Insufficient | 0.6‚Äì0.79 Preliminary | ‚â•0.8 High confidence\n\n**Phase 6: Reflection Round** (All Panelists)\n- Review Cross-Examination arguments and Research Gate findings\n- Revise Initial Positions if persuaded by evidence or challenges\n- Submit updated briefs acknowledging what changed and why\n- Asha identifies convergence or remaining disagreements\n\n**Phase 7: Synthesis** (Recruited Architect or Asha)\n- Analyze updated briefs and structure viable options with tradeoffs\n- Articulate decision pathways and implications\n- If complex synthesis needed, Recruiter may assign architecture specialist\n\n**Phase 8: Decision** (Asha)\n- Apply decision rule (consensus/unanimous based on topic)\n- Calculate consensus percentage: (aligned panelists / total panelists) √ó 100\n- Record dissent with percentage weight and rationale\n- Threshold interpretation:\n  * **100%**: Unanimous agreement\n  * **80-99%**: Strong consensus (proceed with noted concerns)\n  * **60-79%**: Moderate consensus (address dissent before proceeding)\n  * **<60%**: Weak consensus (requires additional deliberation or escalation)\n- List Next Steps with owners, deliverables, due dates\n\n## Decision Report (Fixed Output)\n\nEvery panel produces a structured decision report:\n\n- **Topic** (including Phase 0 clarifications if applicable)\n- **Context Materials** (if `--context` used: file summaries and key points)\n- **Inferred Goals** (derived from topic analysis)\n- **Decision Rule** (consensus or unanimous)\n- **Panel Composition**:\n  * Core Roles (Asha, Recruiter, Adversary)\n  * Recruited Specialists (agent ‚Üí session name mapping with scores)\n  * Recruitment Rationale (why these specialists for this topic)\n- **Existing Infrastructure Comparison** (Phase 2 findings)\n- **Expert Briefs** (Phase 3 Initial Positions with agent-gathered evidence)\n- **Cross-Examination Findings** (Phase 4 challenges and responses)\n- **Research Findings** (Phase 5 sources, if Research Gate activated)\n- **Confidence Summary** (Relevance, Completeness, Score, Threshold)\n- **Reflection Round Summary** (Phase 6 revised positions, convergence)\n- **Synthesis** (Phase 7 options/tradeoffs)\n- **Decision** (Phase 8 final determination)\n- **Consensus** (percentage, threshold level, dissent summary)\n- **Next Steps** (actionable items with ownership)\n\n## Output Formats\n\n### Markdown (Default)\nStandard decision report as documented above. Suitable for Memory files, documentation, and general use.\n\n### GitHub PR Comment (`--format=github`)\nCondensed format optimized for GitHub pull request comments:\n\n```markdown\n## üéØ Panel Decision: [Topic]\n\n**Consensus**: 85% (Strong) | **Decision Rule**: Consensus\n\n### Summary\n[2-3 sentence executive summary]\n\n### Recommendation\n[Primary recommendation with rationale]\n\n<details>\n<summary>üìä Panel Composition</summary>\n\n- **Core**: Asha (Moderator), Recruiter, Adversary\n- **Specialists**: [Agent] ‚Üí \"Session Name\" (score)\n</details>\n\n<details>\n<summary>‚öñÔ∏è Key Trade-offs</summary>\n\n[Synthesis bullet points]\n</details>\n\n<details>\n<summary>üö´ Dissent (15%)</summary>\n\n**The Adversary**: [Dissent rationale]\n</details>\n\n### Next Steps\n- [ ] [Action item with owner]\n```\n\n### JSON (`--format=json`)\nStructured data for programmatic consumption:\n\n```json\n{\n  \"topic\": \"string\",\n  \"goals\": [\"string\"],\n  \"decision_rule\": \"consensus|unanimous\",\n  \"panel\": {\n    \"core\": [\"Asha\", \"Recruiter\", \"Adversary\"],\n    \"specialists\": [{\"agent\": \"string\", \"session_name\": \"string\", \"score\": 0-10}]\n  },\n  \"consensus\": {\n    \"percentage\": 85,\n    \"threshold\": \"strong|moderate|weak|unanimous\",\n    \"aligned\": 4,\n    \"total\": 5\n  },\n  \"decision\": \"string\",\n  \"dissent\": [{\"role\": \"string\", \"rationale\": \"string\", \"weight\": 15}],\n  \"next_steps\": [{\"action\": \"string\", \"owner\": \"string\", \"deliverable\": \"string\"}],\n  \"confidence\": {\"relevance\": 0.0-1.0, \"completeness\": 0.0-1.0, \"score\": 0.0-1.0}\n}\n```\n\n## Context Injection\n\nThe `--context` flag pre-loads reference material before panel deliberation:\n\n```bash\n/panel --context=docs/RFC-001.md \"Should we adopt this RFC?\"\n/panel --context=Memory/techEnvironment.md \"Evaluate caching strategy\"\n```\n\n**Behavior**:\n1. Read specified file(s) before Phase -1\n2. Include content summary in Phase 1 Framing\n3. Make content available to all panelists during deliberation\n4. Reference in Decision Report under \"Context Materials\"\n\n**Multiple contexts**:\n```bash\n/panel --context=spec.md --context=constraints.md \"Evaluate feasibility\"\n```\n\n**URL context** (if WebFetch available):\n```bash\n/panel --context=https://example.com/api-docs \"Design integration approach\"\n```\n\n## Dynamic Agent Recruitment Architecture\n\n**Core Roles vs Recruited Specialists**:\n- **Core Roles** = Persistent panel infrastructure (Asha, Recruiter, Adversary)\n- **Recruited Specialists** = Topic-specific experts from agent library with session names\n\n**Recruitment Flow**:\n1. **Phase -1**: Recruiter analyzes topic ‚Üí determines expertise needs ‚Üí scores agents ‚Üí assigns with session names\n2. **Phase 3**: Specialists deploy assigned agents for research and analysis\n3. **Phase 4-5**: Recruiter may assign additional agents if gaps detected\n4. **Phase 7**: Recruiter may assign architecture specialist for complex synthesis\n\n**Session-Specific Naming**:\n- Same agent becomes different \"character\" depending on context\n- `prose-analysis` ‚Üí \"The Editor\" (creative), \"The Code Reviewer\" (technical), \"The Stylist\" (marketing)\n- `research-assistant` ‚Üí \"The Archivist\" (historical), \"The Evidence Gatherer\" (legal), \"The Data Scout\" (analytics)\n- Names should reflect domain context and analytical role\n\n**Gap Detection & Agent Creation**:\nIf no agent scores >4 for required capability ‚Üí Recruiter deploys `agent-fabricator` to create new specialized agent during Phase -1.\n\n## Character Files\n\nCore roles have documented profiles in `plugins/panel/docs/characters/`:\n- **Asha.md** - Moderator/Facilitator\n- **The Recruiter.md** - Workforce Intelligence\n- **The Adversary.md** - Opposition & Quality Gate\n\nRecruited specialists are documented in `.claude/agents/*.md` (agent count varies by host project).\n\n## Logging\n\nPanel transcripts are automatically saved to:\n```\nWork/meetings/YYYY-MM-DD--panel--<slug>.md\n```\n\nSuggested frontmatter:\n```yaml\n---\ndate: YYYY-MM-DD\ntopic: \"<one-line topic>\"\nmode: \"inworld|outworld\"\ndecision_rule: \"consensus|unanimous\"\nexperts: [\"moderator\", \"adversary\", \"recruited-agent-1\", \"recruited-agent-2\", ...]\n---\n```\n\n## Notes\n\n- **Dynamic recruitment**: No static panelists‚ÄîRecruiter assigns 2-5 specialists per topic\n- **Session-specific names**: Agents given evocative contextual names for panel depth\n- **Evidence standards**: Use markers where appropriate: [Inference], [Speculation], [Unverified]\n- **Optional phases**: Skip Phase 0 if topic well-specified, skip Phase 6 for simple decisions\n- **Tool segregation**: Memory/Tools via filesystem; Vault via Obsidian tools; BookStack via MCP\n- **Core role consistency**: Asha, Recruiter, Adversary always present; specialists vary by topic\n\n## Pattern Implementation\n\nBased on CSIRO Agent Design Patterns (Liu et al. 2025):\n- **Passive Goal Creator** (Phase 0): Clarifies ambiguous topics\n- **Role-Based Cooperation**: Core roles with hierarchical workflow\n- **Debate-Based Cooperation**: Cross-Examination phase enables argument exchange\n- **Self-Reflection**: Reflection Round allows position revision\n- **Cross-Reflection**: Specialists review each other's arguments\n- **Human Reflection**: Decision Report enables user contestability\n\n**Reference**: Liu et al. (2025). \"Agent design pattern catalogue: A collection of architectural patterns for foundation model based agents.\" *The Journal of Systems and Software* 220, 112278.\n\n---\n\n**ARGUMENTS**: Free-form topic text (everything after `/panel` is the topic)"
              }
            ],
            "skills": []
          },
          {
            "name": "local-review",
            "description": "Parallel code review with 4 specialized reviewers (security, logic, edge cases, style) plus validation pass to filter false positives.",
            "source": "./plugins/local-review",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add pknull/asha-marketplace",
              "/plugin install local-review@asha-marketplace"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T20:19:05Z",
              "created_at": "2025-11-13T08:36:22Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/local-review",
                "description": null,
                "path": "plugins/local-review/commands/local-review.md",
                "frontmatter": null,
                "content": "# /local-review\n\nReview local code changes with parallel specialized reviewers and validation.\n\n## Usage\n\n```\n/local-review              # Review staged changes (git diff --cached)\n/local-review <path>       # Review specific file(s)\n/local-review --all        # Review all uncommitted changes (git diff)\n```\n\n## Execution\n\n### Step 1: Gather Changes\n\nBased on input:\n- **No args**: `git diff --cached` (staged changes only)\n- **Path provided**: Read the specified file(s)\n- **--all flag**: `git diff` (all uncommitted changes)\n\nIf no changes found, report and exit.\n\n### Step 2: Parallel Review\n\nLaunch 4 Task agents **in parallel** (single message, multiple tool calls), each with a specialized focus:\n\n#### Security Reviewer\n```\nReview this code for security issues:\n- Injection vulnerabilities (SQL, command, XSS)\n- Authentication/authorization flaws\n- Hardcoded secrets or credentials\n- Unsafe deserialization\n- Path traversal risks\n\nCode to review:\n{diff_content}\n\nList findings with file:line references. If none found, state \"No security issues identified.\"\n```\n\n#### Logic Reviewer\n```\nReview this code for logic errors:\n- Incorrect algorithms or calculations\n- Wrong conditionals or comparisons\n- Off-by-one errors\n- Incorrect state management\n- Broken control flow\n\nCode to review:\n{diff_content}\n\nList findings with file:line references. If none found, state \"No logic issues identified.\"\n```\n\n#### Edge Case Reviewer\n```\nReview this code for edge case handling:\n- Null/undefined/empty inputs\n- Boundary conditions (0, -1, MAX_INT)\n- Empty collections or strings\n- Race conditions or concurrency issues\n- Error paths and exception handling\n\nCode to review:\n{diff_content}\n\nList findings with file:line references. If none found, state \"No edge case issues identified.\"\n```\n\n#### Style Reviewer\n```\nReview this code for style and maintainability:\n- Unclear naming or confusing logic\n- Code duplication\n- Overly complex functions (consider splitting)\n- Missing or misleading comments\n- Inconsistent patterns with surrounding code\n\nCode to review:\n{diff_content}\n\nList findings with file:line references. If none found, state \"No style issues identified.\"\n```\n\n### Step 3: Validation Pass\n\nAfter all reviewers complete, validate each finding:\n\nFor each issue found, verify:\n1. **Existence**: Does the referenced code actually exist at that location?\n2. **Accuracy**: Does the finding correctly describe the issue?\n3. **Applicability**: Is this actually a problem in context, or a false positive?\n\nRemove findings that fail validation. Note any that were filtered.\n\n### Step 4: Present Results\n\nOutput format:\n\n```markdown\n## Local Review Results\n\n**Scope**: {what was reviewed}\n**Files**: {count} | **Lines**: {count}\n\n### Security\n{findings or \"No issues\"}\n\n### Logic\n{findings or \"No issues\"}\n\n### Edge Cases\n{findings or \"No issues\"}\n\n### Style\n{findings or \"No issues\"}\n\n---\n**Validation**: {N} findings filtered as false positives\n```\n\n## Notes\n\n- Uses Task tool with subagent_type appropriate for code review\n- Parallel execution minimizes wait time\n- Validation pass reduces noise from false positives\n- For very large diffs (>1000 lines), recommend splitting the review\n"
              }
            ],
            "skills": []
          },
          {
            "name": "output-styles",
            "description": "Switchable output styles for Claude Code responses. Includes 8 styles (ultra-concise, bullet-points, genui, html-structured, markdown-focused, table-based, tts-summary, yaml-structured) with /style command.",
            "source": "./plugins/output-styles",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add pknull/asha-marketplace",
              "/plugin install output-styles@asha-marketplace"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T20:19:05Z",
              "created_at": "2025-11-13T08:36:22Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/style",
                "description": null,
                "path": "plugins/output-styles/commands/style.md",
                "frontmatter": null,
                "content": "# /style\n\nSwitch between output styles for Claude Code responses.\n\n## Usage\n\n```\n/style                    # List available styles and show current\n/style <name>             # Switch to a specific style\n/style off                # Disable output styling\n```\n\n## Execution\n\n### List Styles (no argument)\n\nRead all `.md` files from `${CLAUDE_PLUGIN_ROOT}/styles/` directory and display:\n\n```markdown\n## Available Output Styles\n\n**Current**: {active style or \"none\"}\n\n| Style | Description |\n|-------|-------------|\n| ultra-concise | Minimal words, direct actions |\n| bullet-points | Hierarchical bullet points |\n| genui | Generative UI with HTML output |\n| html-structured | Clean semantic HTML |\n| markdown-focused | Full markdown features |\n| table-based | Table-based organization |\n| tts-summary | Audio TTS announcements |\n| yaml-structured | YAML structured output |\n\nUsage: `/style <name>` to switch, `/style off` to disable\n```\n\n### Switch Style\n\n1. Validate the style name exists in `${CLAUDE_PLUGIN_ROOT}/styles/{name}.md`\n2. Write the style name to `~/.claude/active-output-style`\n3. Confirm the switch:\n\n```markdown\nSwitched to **{name}** output style.\n\n{one-line description from style file}\n\nStyle will be active for new sessions. Restart or use `/clear` to apply.\n```\n\n### Disable Style\n\nWhen argument is `off`:\n1. Remove `~/.claude/active-output-style` file\n2. Confirm: \"Output styling disabled. Default formatting will be used.\"\n\n## Notes\n\n- Style persists across sessions via config file\n- SessionStart hook reads config and injects style instructions\n- Style files use YAML frontmatter for metadata (name, description)\n"
              }
            ],
            "skills": []
          },
          {
            "name": "asha",
            "description": "Cognitive scaffold framework for session coordination and memory persistence. Provides /asha:init, /asha:save, /asha:note, /asha:status, /asha:index, /asha:cleanup commands with scratchpad notes, session monitoring, and vector DB semantic search.",
            "source": "./plugins/asha",
            "category": null,
            "version": null,
            "author": null,
            "install_commands": [
              "/plugin marketplace add pknull/asha-marketplace",
              "/plugin install asha@asha-marketplace"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T20:19:05Z",
              "created_at": "2025-11-13T08:36:22Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/cleanup",
                "description": "Remove legacy asha/ nested repo installation files",
                "path": "plugins/asha/commands/cleanup.md",
                "frontmatter": {
                  "description": "Remove legacy asha/ nested repo installation files",
                  "argument-hint": "Optional: --dry-run (show what would be removed without removing)",
                  "allowed-tools": [
                    "Bash",
                    "Read"
                  ]
                },
                "content": "# Cleanup Legacy Asha Installation\n\nRemoves files from the old nested-repo installation pattern.\n\nArguments: $ARGUMENTS\n\n## What This Removes\n\nLegacy files from before Asha was a plugin:\n- `asha/` directory (nested repo or submodule)\n- `.claude/hooks/hooks.json` (if contains asha references)\n- `.claude/commands/*.md` symlinks (if point to asha/)\n- `.opencode/` directory (OpenCode support was dropped)\n- `.gitmodules` entry for asha (if was a submodule)\n\n## Protocol\n\n### Step 1: Detect Dry Run Mode\n\n```bash\nDRY_RUN=false\n[[ \"$ARGUMENTS\" == *\"--dry-run\"* ]] && DRY_RUN=true\n```\n\n### Step 2: Inventory Legacy Files\n\n```bash\necho \"Scanning for legacy Asha files...\"\n\n# Check for asha/ directory\nif [[ -d \"${CLAUDE_PROJECT_DIR}/asha\" ]]; then\n    echo \"Found: asha/ directory\"\nfi\n\n# Check for hooks.json with asha refs\nif [[ -f \"${CLAUDE_PROJECT_DIR}/.claude/hooks/hooks.json\" ]]; then\n    if grep -q \"asha/\" \"${CLAUDE_PROJECT_DIR}/.claude/hooks/hooks.json\" 2>/dev/null; then\n        echo \"Found: .claude/hooks/hooks.json (contains asha references)\"\n    fi\nfi\n\n# Check for command symlinks pointing to asha/\nfor cmd in \"${CLAUDE_PROJECT_DIR}/.claude/commands/\"*.md; do\n    if [[ -L \"$cmd\" ]] && [[ \"$(readlink \"$cmd\")\" == *\"asha/\"* ]]; then\n        echo \"Found: $cmd (symlink to asha/)\"\n    fi\ndone\n\n# Check for .opencode directory\nif [[ -d \"${CLAUDE_PROJECT_DIR}/.opencode\" ]]; then\n    echo \"Found: .opencode/ directory\"\nfi\n\n# Check for .gitmodules with asha\nif [[ -f \"${CLAUDE_PROJECT_DIR}/.gitmodules\" ]]; then\n    if grep -q \"asha\" \"${CLAUDE_PROJECT_DIR}/.gitmodules\" 2>/dev/null; then\n        echo \"Found: .gitmodules contains asha entry\"\n    fi\nfi\n```\n\n### Step 3: Remove Legacy Files (unless dry-run)\n\nIf `--dry-run`, just show what would be removed and exit.\n\nOtherwise:\n\n```bash\n# Remove asha/ directory\nif [[ -d \"${CLAUDE_PROJECT_DIR}/asha\" ]]; then\n    rm -rf \"${CLAUDE_PROJECT_DIR}/asha\"\n    echo \"Removed: asha/\"\nfi\n\n# Remove hooks.json if it contains asha refs\nif [[ -f \"${CLAUDE_PROJECT_DIR}/.claude/hooks/hooks.json\" ]]; then\n    if grep -q \"asha/\" \"${CLAUDE_PROJECT_DIR}/.claude/hooks/hooks.json\" 2>/dev/null; then\n        rm \"${CLAUDE_PROJECT_DIR}/.claude/hooks/hooks.json\"\n        echo \"Removed: .claude/hooks/hooks.json\"\n    fi\nfi\n\n# Remove command symlinks pointing to asha/\nfor cmd in \"${CLAUDE_PROJECT_DIR}/.claude/commands/\"*.md; do\n    if [[ -L \"$cmd\" ]] && [[ \"$(readlink \"$cmd\")\" == *\"asha/\"* ]]; then\n        rm \"$cmd\"\n        echo \"Removed: $cmd\"\n    fi\ndone\n\n# Remove .opencode directory\nif [[ -d \"${CLAUDE_PROJECT_DIR}/.opencode\" ]]; then\n    rm -rf \"${CLAUDE_PROJECT_DIR}/.opencode\"\n    echo \"Removed: .opencode/\"\nfi\n```\n\n### Step 4: Handle .gitmodules\n\nIf .gitmodules contains asha entry:\n\n```bash\nif [[ -f \"${CLAUDE_PROJECT_DIR}/.gitmodules\" ]]; then\n    if grep -q \"asha\" \"${CLAUDE_PROJECT_DIR}/.gitmodules\" 2>/dev/null; then\n        echo \"\"\n        echo \"WARNING: .gitmodules contains asha entry\"\n        echo \"Manual removal required:\"\n        echo \"  git submodule deinit asha\"\n        echo \"  git rm asha\"\n        echo \"  rm -rf .git/modules/asha\"\n    fi\nfi\n```\n\n### Step 5: Report\n\n```bash\necho \"\"\necho \"Cleanup complete!\"\necho \"\"\necho \"Next steps:\"\necho \"  1. Run /asha:init to set up plugin-based Asha\"\necho \"  2. Commit the cleanup: git add -A && git commit -m 'chore: migrate from nested asha to plugin'\"\n```\n\n## Safety Notes\n\n- This does NOT touch Memory/ files (those are preserved)\n- This does NOT remove .asha/ (that's the new plugin runtime directory)\n- Always run `--dry-run` first to see what will be removed\n- Git history is preserved; you can recover files if needed"
              },
              {
                "name": "/index",
                "description": "Index project files for semantic search",
                "path": "plugins/asha/commands/index.md",
                "frontmatter": {
                  "description": "Index project files for semantic search",
                  "argument-hint": "Optional: --full (complete reindex) or --check (verify dependencies)",
                  "allowed-tools": [
                    "Bash",
                    "Read"
                  ]
                },
                "content": "# Index Memory for Semantic Search\n\nRun the memory index tool to enable semantic search across project files.\n\nArguments: $ARGUMENTS\n\n## Protocol\n\n### Step 1: Verify Initialization\n\nCheck that the project has been initialized with Asha:\n\n```bash\n[[ -f \"${CLAUDE_PROJECT_DIR}/.asha/config.json\" ]] && echo \"Asha initialized\" || echo \"ERROR: Run /asha:init first\"\n```\n\nIf not initialized, instruct user to run `/asha:init`.\n\n### Step 2: Determine Mode\n\nBased on arguments:\n- `--full` ‚Üí Full reindex of all files\n- `--check` ‚Üí Verify dependencies only (Ollama running, packages installed)\n- No arguments ‚Üí Incremental update (changed files only, faster)\n\n### Step 3: Run Indexer\n\nUse the run-python.sh wrapper which auto-detects the virtual environment:\n\n```bash\n# Incremental (default - changed files only)\n\"${CLAUDE_PLUGIN_ROOT}/tools/run-python.sh\" \"${CLAUDE_PLUGIN_ROOT}/tools/memory_index.py\" ingest --changed\n\n# Full reindex\n\"${CLAUDE_PLUGIN_ROOT}/tools/run-python.sh\" \"${CLAUDE_PLUGIN_ROOT}/tools/memory_index.py\" ingest\n\n# Check dependencies\n\"${CLAUDE_PLUGIN_ROOT}/tools/run-python.sh\" \"${CLAUDE_PLUGIN_ROOT}/tools/memory_index.py\" check\n```\n\n### Step 4: Report Results\n\nSummarize:\n- Number of files indexed and chunks created\n- Any errors or warnings encountered\n- If dependencies are missing, provide install instructions\n\n## Requirements\n\n- Ollama running locally (`ollama serve`)\n- Embedding model available (`ollama pull nomic-embed-text`)\n- Python packages installed (run `/asha:init` to set up)"
              },
              {
                "name": "/init",
                "description": "Initialize Asha in current project - creates Memory/, .asha/, and databases",
                "path": "plugins/asha/commands/init.md",
                "frontmatter": {
                  "description": "Initialize Asha in current project - creates Memory/, .asha/, and databases",
                  "argument-hint": "Optional: --minimal (skip Vector DB) or --full (accept all defaults)",
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Write"
                  ]
                },
                "content": "# Initialize Asha in Project\n\nSets up Asha framework for the current project.\n\nArguments: $ARGUMENTS\n\n## What This Creates\n\n```\n${CLAUDE_PROJECT_DIR}/\n‚îú‚îÄ‚îÄ Memory/\n‚îÇ   ‚îú‚îÄ‚îÄ sessions/archive/\n‚îÇ   ‚îú‚îÄ‚îÄ reasoning_bank/\n‚îÇ   ‚îú‚îÄ‚îÄ vector_db/\n‚îÇ   ‚îú‚îÄ‚îÄ activeContext.md\n‚îÇ   ‚îú‚îÄ‚îÄ projectbrief.md\n‚îÇ   ‚îú‚îÄ‚îÄ communicationStyle.md\n‚îÇ   ‚îú‚îÄ‚îÄ workflowProtocols.md\n‚îÇ   ‚îî‚îÄ‚îÄ techEnvironment.md\n‚îú‚îÄ‚îÄ Work/markers/\n‚îú‚îÄ‚îÄ .asha/\n‚îÇ   ‚îú‚îÄ‚îÄ .venv/\n‚îÇ   ‚îî‚îÄ‚îÄ config.json\n‚îî‚îÄ‚îÄ CLAUDE.md\n```\n\n## Protocol\n\n### Step 1: Check Existing Installation\n\n```bash\nif [[ -f \"${CLAUDE_PROJECT_DIR}/.asha/config.json\" ]]; then\n    echo \"Asha already initialized in this project\"\n    echo \"To reinitialize, delete .asha/ and run again\"\n    exit 0\nfi\n```\n\nIf already initialized, inform user and stop.\n\n### Step 2: Create Directory Structure\n\n```bash\nmkdir -p \"${CLAUDE_PROJECT_DIR}/Memory/sessions/archive\"\nmkdir -p \"${CLAUDE_PROJECT_DIR}/Memory/reasoning_bank\"\nmkdir -p \"${CLAUDE_PROJECT_DIR}/Memory/vector_db\"\nmkdir -p \"${CLAUDE_PROJECT_DIR}/Work/markers\"\nmkdir -p \"${CLAUDE_PROJECT_DIR}/.asha\"\n```\n\n### Step 3: Copy Templates (if Memory files don't exist)\n\nFor each template in `${CLAUDE_PLUGIN_ROOT}/templates/`:\n- If `Memory/<filename>` doesn't exist, copy it\n- If it exists, skip (preserve user content)\n\nTemplates to copy:\n- `activeContext.md`\n- `projectbrief.md`\n- `communicationStyle.md`\n- `workflowProtocols.md`\n- `techEnvironment.md`\n- `scratchpad.md`\n\n```bash\nfor template in activeContext.md projectbrief.md communicationStyle.md workflowProtocols.md techEnvironment.md scratchpad.md; do\n    if [[ ! -f \"${CLAUDE_PROJECT_DIR}/Memory/$template\" ]]; then\n        cp \"${CLAUDE_PLUGIN_ROOT}/templates/$template\" \"${CLAUDE_PROJECT_DIR}/Memory/$template\"\n        echo \"Created Memory/$template\"\n    else\n        echo \"Skipped Memory/$template (exists)\"\n    fi\ndone\n```\n\n### Step 4: Create CLAUDE.md (if doesn't exist)\n\n```bash\nif [[ ! -f \"${CLAUDE_PROJECT_DIR}/CLAUDE.md\" ]]; then\n    cp \"${CLAUDE_PLUGIN_ROOT}/templates/CLAUDE.md\" \"${CLAUDE_PROJECT_DIR}/CLAUDE.md\"\n    echo \"Created CLAUDE.md\"\nelse\n    echo \"Skipped CLAUDE.md (exists)\"\nfi\n```\n\n### Step 5: Create Python Virtual Environment\n\nUnless `--minimal` is specified:\n\n```bash\npython3 -m venv \"${CLAUDE_PROJECT_DIR}/.asha/.venv\"\n\"${CLAUDE_PROJECT_DIR}/.asha/.venv/bin/pip\" install -r \"${CLAUDE_PLUGIN_ROOT}/tools/requirements.txt\"\n```\n\nIf venv creation fails, warn but continue (Vector DB will be unavailable).\n\n### Step 6: Initialize Databases\n\n```bash\n# ReasoningBank\n\"${CLAUDE_PLUGIN_ROOT}/tools/run-python.sh\" \"${CLAUDE_PLUGIN_ROOT}/tools/reasoning_bank.py\" stats\n\n# Vector DB check\n\"${CLAUDE_PLUGIN_ROOT}/tools/run-python.sh\" \"${CLAUDE_PLUGIN_ROOT}/tools/memory_index.py\" check\n```\n\n### Step 7: Create Config File\n\nWrite `.asha/config.json` to mark project as initialized:\n\n```bash\ncat > \"${CLAUDE_PROJECT_DIR}/.asha/config.json\" << 'EOF'\n{\n  \"version\": \"1.0.0\",\n  \"initialized\": \"$(date -Iseconds)\",\n  \"plugin\": \"asha@asha-marketplace\"\n}\nEOF\n```\n\n### Step 8: Report Status\n\nDisplay:\n- Directory structure created\n- Templates copied (list which ones)\n- Python venv status\n- Vector DB readiness\n- Next steps for user\n\n## Next Steps After Init\n\n1. **Edit Memory/projectbrief.md** - Define project scope\n2. **Edit Memory/activeContext.md** - Set current status\n3. **Run /asha:index** - Index files for semantic search (optional)\n4. **Add to .gitignore**:\n   ```\n   .asha/\n   Memory/sessions/\n   Memory/vector_db/\n   Memory/reasoning_bank/\n   ```"
              },
              {
                "name": "/note",
                "description": "Add timestamped note to Memory scratchpad",
                "path": "plugins/asha/commands/note.md",
                "frontmatter": {
                  "description": "Add timestamped note to Memory scratchpad",
                  "argument-hint": "<note text>",
                  "allowed-tools": [
                    "Bash",
                    "Write",
                    "Read"
                  ]
                },
                "content": "# Add Note to Scratchpad\n\nQuick capture of thoughts, decisions, discoveries, or blockers during a session.\n\nNote content: $ARGUMENTS\n\n## Protocol\n\n### Step 1: Validate Input\n\nIf no arguments provided, inform user:\n```\nUsage: /asha:note <your note text>\nExample: /asha:note Discovered auth tokens expire after 1 hour\n```\n\n### Step 2: Ensure Scratchpad Exists\n\n```bash\nSCRATCHPAD=\"${CLAUDE_PROJECT_DIR}/Memory/scratchpad.md\"\n\nif [[ ! -f \"$SCRATCHPAD\" ]]; then\n    cat > \"$SCRATCHPAD\" << 'EOF'\n---\nversion: \"1.0\"\nlastUpdated: \"$(date -u '+%Y-%m-%d %H:%M UTC')\"\npurpose: \"Quick capture of thoughts, decisions, and discoveries\"\n---\n\n# Scratchpad\n\nTimestamped notes captured during sessions. Review periodically and migrate important items to appropriate Memory files.\n\n---\n\nEOF\nfi\n```\n\n### Step 3: Append Note\n\nAppend the note with timestamp:\n\n```bash\necho \"\" >> \"$SCRATCHPAD\"\necho \"**$(date -u '+%Y-%m-%d %H:%M UTC')**: $ARGUMENTS\" >> \"$SCRATCHPAD\"\n```\n\n### Step 4: Confirm\n\nDisplay confirmation:\n```\nNote added to Memory/scratchpad.md\n```\n\n## Scratchpad Management Tips\n\n- Review scratchpad during `/asha:save` to migrate important items\n- Prune completed/obsolete notes periodically\n- Move recurring patterns to `workflowProtocols.md`\n- Move project decisions to `activeContext.md`"
              },
              {
                "name": "/save",
                "description": "Save current session context to Memory Bank with git commit and push",
                "path": "plugins/asha/commands/save.md",
                "frontmatter": {
                  "description": "Save current session context to Memory Bank with git commit and push",
                  "argument-hint": "Optional: --react (include pattern analysis) or commit message details",
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Edit",
                    "Write",
                    "TodoWrite"
                  ]
                },
                "content": "# Save Session Context\n\nSystematic session completion protocol using the Four Questions framework.\n\nAdditional context: $ARGUMENTS\n\n## Protocol\n\n### Step 1: Get Session Summary\n\nRun the save-session script to extract session activity:\n\n```bash\n\"${CLAUDE_PLUGIN_ROOT}/tools/save-session.sh\" --interactive\n```\n\nThis displays:\n- Significant operations (agents invoked, files modified, panels convened)\n- Decisions and clarifications made\n- The Four Questions framework prompts\n\nIf no session watching file exists, proceed to Step 3 (git commit only).\n\n### Step 2: Answer Four Questions & Update Memory\n\nBased on the session summary, update Memory Bank files:\n\n**Memory/activeContext.md** (always update):\n- Add session summary with timestamp\n- Record accomplishments\n- Note key learnings\n- Update Next Steps section\n- Increment version number in frontmatter\n\n**Memory/scratchpad.md** (review and migrate):\n- Check for notes captured via `/asha:note`\n- Migrate important items to appropriate Memory files\n- Prune completed or obsolete notes\n\n**Memory/workflowProtocols.md** (if patterns learned):\n- Add validated techniques\n- Document pitfalls with prevention\n\n**Memory/progress.md** (if significant milestones):\n- Record phase completion\n- Update project status\n\n**If activeContext.md exceeds ~500 lines**:\n- Preserve: Frontmatter, Current Status, Last 2-3 activities, Next Steps\n- Archive older activities\n- Target: ~150-300 lines\n\n### Step 3: Archive, Index, and Commit\n\nAfter Memory updates are complete, run:\n\n```bash\n\"${CLAUDE_PLUGIN_ROOT}/tools/save-session.sh\" --archive-only\n```\n\nThis will:\n- Archive the session watching file\n- Reset watching file for next session\n- Refresh vector DB index (incremental)\n\nThen commit (and push if remote exists):\n\n```bash\ngit add Memory/\ngit commit -m \"Session save: <brief summary>\"\ngit remote -v | grep -q . && git push || echo \"No remote configured, skipping push\"\n```\n\n## ReAct Analysis (--react flag)\n\nIf `--react` is specified in arguments, run pattern analysis before Step 2:\n\n```bash\n\"${CLAUDE_PLUGIN_ROOT}/tools/save-session.sh\" --analyze\n```\n\nThis provides:\n- Code pattern detection and repetitions\n- Redundancies with existing memory\n- Novel insights extraction\n- Abstraction and refactoring opportunities\n- Cross-project sharing suggestions\n\nUse insights to enhance Memory updates in Step 2.\n\n## Completion Validation\n\nIf TodoWrite tasks exist, review completion:\n- [ ] Goals fully achieved (not partially)\n- [ ] Deliverables tested/validated\n- [ ] Documentation updated\n- [ ] No critical blockers remaining\n\nUpdate TodoWrite: Mark truly complete tasks as completed; refine incomplete tasks."
              },
              {
                "name": "/status",
                "description": "Show current session status and captured activity",
                "path": "plugins/asha/commands/status.md",
                "frontmatter": {
                  "description": "Show current session status and captured activity",
                  "argument-hint": "",
                  "allowed-tools": [
                    "Bash",
                    "Read"
                  ]
                },
                "content": "# Session Status\n\nDisplay current session information and captured activity.\n\n## Protocol\n\n### Step 1: Check for Session Watching File\n\n```bash\nWATCHING_FILE=\"${CLAUDE_PROJECT_DIR}/Memory/sessions/current-session.md\"\n\nif [[ ! -f \"$WATCHING_FILE\" ]]; then\n    echo \"No active session found.\"\n    echo \"\"\n    echo \"Run /asha:init to initialize Asha in this project.\"\n    exit 0\nfi\n```\n\n### Step 2: Extract Session Metadata\n\nRead the frontmatter to get session start time and ID:\n\n```bash\nSESSION_START=$(grep '^sessionStart:' \"$WATCHING_FILE\" | cut -d' ' -f2-)\nSESSION_ID=$(grep '^sessionID:' \"$WATCHING_FILE\" | cut -d' ' -f2)\nFILE_SIZE=$(du -h \"$WATCHING_FILE\" | cut -f1)\nLAST_MODIFIED=$(stat -c '%y' \"$WATCHING_FILE\" 2>/dev/null || stat -f '%Sm' \"$WATCHING_FILE\" 2>/dev/null)\n```\n\n### Step 3: Count Captured Activity\n\nCount entries in each section (lines that aren't comments/headers/blank):\n\n```bash\n# Extract and count each section\ncount_section() {\n    local section=\"$1\"\n    sed -n \"/^## $section/,/^## /p\" \"$WATCHING_FILE\" | \\\n        grep -v '^##' | grep -v '^<!--' | grep -v '^---' | grep -v '^$' | wc -l\n}\n\nOPS_COUNT=$(count_section \"Significant Operations\")\nDECISIONS_COUNT=$(count_section \"Decisions & Clarifications\")\nERRORS_COUNT=$(count_section \"Errors & Anomalies\")\n```\n\n### Step 4: Calculate Duration\n\n```bash\n# Parse session start and calculate duration\nif [[ -n \"$SESSION_START\" ]]; then\n    START_EPOCH=$(date -d \"$SESSION_START\" +%s 2>/dev/null || date -j -f \"%Y-%m-%d %H:%M UTC\" \"$SESSION_START\" +%s 2>/dev/null)\n    NOW_EPOCH=$(date +%s)\n    DURATION_SECS=$((NOW_EPOCH - START_EPOCH))\n    DURATION_MINS=$((DURATION_SECS / 60))\n    DURATION_HRS=$((DURATION_MINS / 60))\n    REMAINING_MINS=$((DURATION_MINS % 60))\n\n    if [[ $DURATION_HRS -gt 0 ]]; then\n        DURATION=\"${DURATION_HRS}h ${REMAINING_MINS}m\"\n    else\n        DURATION=\"${DURATION_MINS}m\"\n    fi\nfi\n```\n\n### Step 5: Display Status Report\n\nOutput the status in a clean format:\n\n```\n## Current Session Status\n\n**Session ID**: $SESSION_ID\n**Started**: $SESSION_START\n**Duration**: $DURATION\n**File size**: $FILE_SIZE\n\n### Captured Activity\n\n| Section | Count |\n|---------|-------|\n| Significant Operations | $OPS_COUNT |\n| Decisions & Clarifications | $DECISIONS_COUNT |\n| Errors & Anomalies | $ERRORS_COUNT |\n\n**Last activity**: $LAST_MODIFIED\n```\n\n### Step 6: Show Recent Entries (Optional)\n\nIf there's captured activity, show the last few entries from Significant Operations:\n\n```bash\nif [[ $OPS_COUNT -gt 0 ]]; then\n    echo \"\"\n    echo \"### Recent Operations (last 5)\"\n    sed -n '/^## Significant Operations/,/^## /p' \"$WATCHING_FILE\" | \\\n        grep -v '^##' | grep -v '^<!--' | grep -v '^$' | tail -5\nfi\n```\n\n## Tips\n\n- Run before `/asha:save` to preview what will be synthesized\n- If counts are 0, hooks may not be capturing (check `.claude/hooks/`)\n- Use `/asha:save` when ready to archive and update Memory Bank"
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}